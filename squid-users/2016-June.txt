From squid3 at treenet.co.nz  Wed Jun  1 05:47:44 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 1 Jun 2016 17:47:44 +1200
Subject: [squid-users] Bug: Missing MemObject::storeId value
In-Reply-To: <e4d31056-6099-205e-06b4-80dd001fdcd8@cinbesa.com.br>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <c9f4b54a-7fd4-3355-a9cd-161b92e1ce15@cinbesa.com.br>
 <1464701636671-4677737.post@n4.nabble.com>
 <5d9049ba-b688-a22e-07d5-12b7da94dc8c@gmail.com>
 <931f91a3-51f4-6ff4-e781-4ed71964f527@cinbesa.com.br>
 <5cb41d75-387c-80af-fac6-e03a2570b0fa@gmail.com>
 <4fbad1c7-6a7f-b395-4824-08ec7add0a18@cinbesa.com.br>
 <6a67dd0e-80ae-ab5e-f353-2ec403ea6e75@gmail.com>
 <e21161a5-eef9-7b10-e4a5-0222d0e6756c@cinbesa.com.br>
 <4f72c4ab-6262-a62e-956b-a2721b0a59b7@gmail.com>
 <e4d31056-6099-205e-06b4-80dd001fdcd8@cinbesa.com.br>
Message-ID: <20e8aba7-7d60-95d4-344b-c5d6060a84e6@treenet.co.nz>

On 1/06/2016 4:36 a.m., Heiler Bemerguy wrote:
> 
> This is the parent proxy of another one (10.1.10.101).
> 
> It was receiveing requests like these:
> 
> 1464665138.326      0 10.1.10.101 UDP_MISS/000 72 ICP_QUERY
> http://img.olx.com.br/thumbs/51/517630000636766.jpg - HIER_NONE/- -
> 1464665138.331      0 10.1.10.101 UDP_MISS/000 72 ICP_QUERY
> http://img.olx.com.br/thumbs/51/515630006195751.jpg - HIER_NONE/- -

ICP was designed for HTTP/1.0 traffic. It only exchanges URI between the
peers. HTTP/1.1 things like the Vary header are not sent. So objects
have a high false-HIT rate which affects caching success.

For HTTP/1.1 proxies you should use HTCP instead if possible. It will
cope much better with Vary and refresh needs.


Also, if you are using Store-ID helpers be aware that ICP and HTCP
queries do not go through the Store-ID helper (yet). So failures will
occure for all things with locally altered Store-ID's.

Amos



From squid3 at treenet.co.nz  Wed Jun  1 05:54:12 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 1 Jun 2016 17:54:12 +1200
Subject: [squid-users] Vary object loop returns
In-Reply-To: <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
Message-ID: <04828faf-5f53-2f09-58ed-eac1b98b4257@treenet.co.nz>

On 1/06/2016 1:34 a.m., Yuri wrote:
> This is too expensive action. Cold out cache will decrease hit-ratio for
> weeks.
> 

You do not need to suffer from a simple test. Make a temporary empty
cache_dir and comment out the main one while testing.

That way you can revert to the larger main cache at any time, or after
you know the test results. You might get the same messages logged while
the broken content gets cleared out of the main cache, but by then you
know they are just remnants being cleaned out.

Amos



From schneelei at gmail.com  Wed Jun  1 06:20:56 2016
From: schneelei at gmail.com (SLeipold)
Date: Tue, 31 May 2016 23:20:56 -0700 (PDT)
Subject: [squid-users] redirect IP request to special cache_peer
Message-ID: <1464762056516-4677758.post@n4.nabble.com>

Dear squid-users,

at first:
thanks for adding me to your mailing list.
My question is about the cache_peer configuration directive.

In my config I have to use three cache_peer proxies:

To choose the cache_peer on the basis of the URL its responsible for I use
the cache_peer_access directive and created a .txt-file with the allowed
urls. This is working fine.

But when I request a IP address "http://1.2.3.4" this is not working. For
example:

http://test.best works over the responsible cache peer
http://1.2.3.4 isn?t working

The configuration looks the following:

acl parent1 url_regex -i "/etc/squid/parent1.txt

content of parent1.txt:
^http://test.best --> working
^http://1.2.3.4 --> not using the parent proxy and tries direct access.

cache_peer 10.1.2.3 parent 8080 name=parent1
cache_peer_access parent1 allow parent1
cache_peer_access parent1 deny all

Can you tell me where the fault is?

Kind regards and thanks for any help!







--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/redirect-IP-request-to-special-cache-peer-tp4677758.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Wed Jun  1 08:41:22 2016
From: yvoinov at gmail.com (Yuri)
Date: Wed, 1 Jun 2016 14:41:22 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <04828faf-5f53-2f09-58ed-eac1b98b4257@treenet.co.nz>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <04828faf-5f53-2f09-58ed-eac1b98b4257@treenet.co.nz>
Message-ID: <38eeae01-c417-b703-0042-304dd5257407@gmail.com>

Cleared cache with disabled collapsed forwarding:


2016/06/01 14:36:37 kid1| clientProcessHit: Vary object loop!
2016/06/01 14:36:37 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 'http://egov.kz/wps/theme/jq/mistakes.js' 
'accept-encoding="gzip,%20deflate"'
2016/06/01 14:36:37 kid1| clientProcessHit: Vary object loop!
2016/06/01 14:36:37 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 'http://egov.kz/wps/theme/jq/jquery.autocomplete.min.js' 
'accept-encoding="gzip,%20deflate"'
2016/06/01 14:36:37 kid1| clientProcessHit: Vary object loop!
2016/06/01 14:36:37 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 'http://egov.kz/wps/theme/jq/jsEgov.js' 
'accept-encoding="gzip,%20deflate"'


01.06.2016 11:54, Amos Jeffries ?????:
> On 1/06/2016 1:34 a.m., Yuri wrote:
>> This is too expensive action. Cold out cache will decrease hit-ratio for
>> weeks.
>>
> You do not need to suffer from a simple test. Make a temporary empty
> cache_dir and comment out the main one while testing.
>
> That way you can revert to the larger main cache at any time, or after
> you know the test results. You might get the same messages logged while
> the broken content gets cleared out of the main cache, but by then you
> know they are just remnants being cleaned out.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From belle at bazuin.nl  Wed Jun  1 08:52:03 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 1 Jun 2016 10:52:03 +0200
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
In-Reply-To: <OF059DEDF2.DD0EB7D2-ON80257FC4.006A0132-80257FC4.006A2AD0@tcs.com>
References: <OF6BC559F7.84283A07-ON80257FC0.004CFF22-80257FC0.004D9F23@LocalDomain>
Message-ID: <vmime.574ea233.3704.3945fd6521fef1e3@ms249-lin-003.rotterdam.bazuin.nl>

Wel first, great, you made it to install it, 

?

Yes, but your auth pop-up can be normal, but we need more info, this can be multple things. 

?

So, few small questions. 

?

1)?????? is the time in sync with the proxy and AD server? 

2)?????? Did you set the krb5.conf ?with or without the enctypes types? 

3)?????? Which browser are you using?

4)?????? Did you configure the browser to use the kerberos auth? 

5)?????? Did the PC join the domain, and are u using a domain user login? 

6)?????? Does kinit user at REALM work?? ( kdestroy to remove the user ticket ) 

7)?????? Last, does the proxy server have an A and PTR record? 

?

Also check this site, review your settings. 

https://ping.force.com/Support/PingFederate/Integrations/How-to-configure-supported-browsers-for-Kerberos-NTLM 

?

And last tip your auth line. 

auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s HTTP/hostname.domain.org at DOMAIN.ORG 

?

Can also be a problem so test, if the upn is setup incorrectly, then above does not work, below the should work. 

auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s GSS_C_NO_NAME

?

add ?-d to get more debug info. 

?

greetz, 

?

Louis

?


Van: Nilesh Gavali [mailto:nilesh.gavali at tcs.com] 
Verzonden: dinsdag 31 mei 2016 21:20
Aan: squid-users at lists.squid-cache.org
CC: L.P.H. van Belle
Onderwerp: missing negotiate_kerberos_auth on my squid


?

Hello All; 

Configured the steps require for kerberos authentication as given at http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
but instead of SSO to work when we try to open url; it is prompt for username and password, when passing credential it is not authenticating. 
attached is our squid config for your reference. 

Kindly let us know what went wrong. 

we are using windows 2012 AD. 



Thanks & Regards
Nilesh Suresh Gavali




From: ? ? ? ?Nilesh Gavali/MUM/TCS 
To: ? ? ? ?squid-users at lists.squid-cache.org, belle at bazuin.nl 
Date: ? ? ? ?27/05/2016 15:07 
Subject: ? ? ? ? missing negotiate_kerberos_auth on my squid 




Thanks louise for reply. 

but 

Should be include imo. -- not sure what is imo

?

Shoud be in any Squid-3.2 and later.

?

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth - check the path but it is not there on my linux box.

?

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? ?---- NO didn't gave this option while compilation

?

Run squid ?v to check it. -- we have"--enable-auth-negotiate" only and some other configured option. 

can you help me how to get hit recomipled with reuqire options. 


Thanks & Regards
Nilesh Suresh Gavali

----- Forwarded by Nilesh Gavali/MUM/TCS on 27/05/2016 15:01 ----- 

From: ? ? ? ?squid-users-request at lists.squid-cache.org 
To: ? ? ? ?squid-users at lists.squid-cache.org 
Date: ? ? ? ?27/05/2016 12:42 
Subject: ? ? ? ?squid-users Digest, Vol 21, Issue 101 
Sent by: ? ? ? ?"squid-users" <squid-users-bounces at lists.squid-cache.org> 





Send squid-users mailing list submissions to
? ? ? ? ? ? ? ? squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
? ? ? ? ? ? ? ? http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
? ? ? ? ? ? ? ? squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
? ? ? ? ? ? ? ? squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

? 1. NULL characters (joe)
? 2. Re: Looking for a way to route into cache_peer traffic
? ? ?dynamically. (Alex Rousskov)
? 3. The system returned: (111) Connection refused; (deepa ganu)
? 4. Re: NULL characters (Eliezer Croitoru)
? 5. missing negotiate_kerberos_auth on my squid (Nilesh Gavali)
? 6. Re: missing negotiate_kerberos_auth on my squid (L.P.H. van Belle)


----------------------------------------------------------------------

Message: 1
Date: Thu, 26 May 2016 07:30:16 -0700 (PDT)
From: joe <chip_pop at hotmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters
Message-ID: <1464273016183-4677691.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii

2016/05/26 06:41:28 kid1| ctx: enter level ?0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level ?0

is it bad ?????



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html
Sent from the Squid - Users mailing list archive at Nabble.com.


------------------------------

Message: 2
Date: Thu, 26 May 2016 09:16:52 -0600
From: Alex Rousskov <rousskov at measurement-factory.com>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Looking for a way to route into cache_peer
? ? ? ? ? ? ? ? traffic dynamically.
Message-ID: <57471364.4030007 at measurement-factory.com>
Content-Type: text/plain; charset=utf-8

On 05/26/2016 03:52 AM, Eliezer Croitoru wrote:

> I think that the best way is to use an ICAP meta header instead of altering
> the request itself 

Agreed.


> but I am not sure if it is possible

It is not possible today: Converting ICAP headers into annotations
understood by Squid ACLs is only supported for eCAP services.

IIRC, somebody posted a patch (on squid-dev) with a similar feature for
ICAP, but that implementation needed to be redone to be officially
accepted (IMO). I do not know whether the author will adjust their code
to follow my recommendations. Perhaps you can do it for them.

Alex.



------------------------------

Message: 3
Date: Fri, 27 May 2016 14:25:19 +0530
From: deepa ganu <deepaganu at gmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] The system returned: (111) Connection refused;
Message-ID:
? ? ? ? ? ? ? ? <CA+qV5k+cSUThvZYCS1JLcNuXsFCA8Vnk1Rmc5opK1w15W6asyg at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi
I am using squid as a reverse.

#http_port ?80 accel defaultsite=202.53.13.19
https_port 443 accel ?cert=/var/www/html/webrtc/imp/teleuniv.net.crt
key=/var/www/html/webrtc/imp/teleuniv.net.key
cafile=/var/www/html/webrtc/imp/intermediate.crt defaultsite=202.53.13.19
no-vhost


#this ACL is url path specific which accepts only portal urls and deny
others.
acl portal urlpath_regex ^/portal6may
cache_peer 172.20.36.144 parent 80 0 no-query originserver name=portalserver
cache_peer_access portalserver allow portal
cache_peer_access portalserver deny all
http_access allow portal


cache_peer 172.20.36.150 parent 443 0 no-query originserver ssl
sslflags=DONT_VERIFY_PEER login=PASS connection-auth=off name=teleuniv
acl our_sites dstdomain 202.53.13.19
http_access allow our_sites
cache_peer_access teleuniv allow our_sites
cache_peer_access teleuniv deny all

SO when i try to access the url MailScanner warning: numerical links are often malicious: https://202.53.13.19/ I get the following
error
"The following error was encountered while trying to retrieve the URL: The
system returned: (111) Connection refused; The remote host or network may
be down. Please try the request again."

It only gives for 172.20.36.144 not for the urlpath acl. But this happens
only sometimes. When I physically go to that server (172.20.36.150) and
click on the wired connection (one of the LAN options using linux). It
works again. I am very confused

-- 
Regards
Deepa Ganu
R&D Head(CSE) KMIT
Ph no : 9908036660
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/998e60f3/attachment-0001.html>

------------------------------

Message: 4
Date: Fri, 27 May 2016 14:17:17 +0300
From: "Eliezer Croitoru" <eliezer at ngtech.co.il>
To: "'joe'" <chip_pop at hotmail.com>,
? ? ? ? ? ? ? ? <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] NULL characters
Message-ID: <33b501d1b809$541a9620$fc4fc260$@ngtech.co.il>
Content-Type: text/plain; ? ? ? ? ? ? ? ? charset="utf-8"

If it ended with some kind of server issues else then the logs, then it would be considered not nice.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of joe
Sent: Thursday, May 26, 2016 5:30 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters

2016/05/26 06:41:28 kid1| ctx: enter level ?0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level ?0

is it bad ?????



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



------------------------------

Message: 5
Date: Fri, 27 May 2016 12:32:15 +0100
From: Nilesh Gavali <nilesh.gavali at tcs.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
? ? ? ? ? ? ? ? <OF9C6F8F89.5CF2ECB1-ON80257FC0.003EE232-80257FC0.003F5EF7 at tcs.com>
Content-Type: text/plain; charset="utf-8"

Hello ;
I have installed latest squid 3.5.19 on red hat Linux yesterday. That 
means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but 
facing issues.
followed the steps provided on 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
But unable to find negotiate_kerberos_auth ?on my Linux box at any 
location. 
now I need to know where i can find/download ?negotiate_kerberos_auth ?and 
compile it to make authentication successful.

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty. ? IT Services
? ? ? ? ? ? ? ? ? ? ? ?Business Solutions
? ? ? ? ? ? ? ? ? ? ? ?Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated ?with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 
Registered ?in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/b812d6ac/attachment-0001.html>

------------------------------

Message: 6
Date: Fri, 27 May 2016 13:41:34 +0200
From: L.P.H. van Belle <belle at bazuin.nl>
To: squid-users at squid-cache.org ?<squid-users at squid-cache.org>
Subject: Re: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
? ? ? ? ? ? ? ? <vmime.5748326e.63bf.32264d027089be4e at ms249-lin-003.rotterdam.bazuin.nl>
? ? ? ? ? ? ? ? 
Content-Type: text/plain; charset="windows-1252"

Should be include imo. 

?

Shoud be in any Squid-3.2 and later.

?

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth 

?

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? 

?

Run squid ?v to check it. 

?

Greetz, 

?

Louis

?

?


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Nilesh Gavali
Verzonden: vrijdag 27 mei 2016 13:32
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] missing negotiate_kerberos_auth on my squid


?

Hello ; 
?I have installed latest squid 3.5.19 on red hat Linux yesterday. That means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but facing issues. 
followed the steps provided on http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
But unable to find negotiate_kerberos_auth ?on my Linux box at any location. 
now I need to know where i can find/download ?negotiate_kerberos_auth ?and compile it to make authentication successful. 

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty. ? ? ? ?IT Services
? ? ? ? ? ? ? ? ? ? ? ?Business Solutions
? ? ? ? ? ? ? ? ? ? ? ?Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated ?with limited liability and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - ?Registered ?in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/bbeb60e2/attachment.html>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 21, Issue 101
********************************************


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160601/de2f2a15/attachment.htm>

From squid3 at treenet.co.nz  Wed Jun  1 10:38:43 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 1 Jun 2016 22:38:43 +1200
Subject: [squid-users] redirect IP request to special cache_peer
In-Reply-To: <1464762056516-4677758.post@n4.nabble.com>
References: <1464762056516-4677758.post@n4.nabble.com>
Message-ID: <33d741d0-8351-b7ee-c071-4c4d78535e6b@treenet.co.nz>

On 1/06/2016 6:20 p.m., SLeipold wrote:
> Dear squid-users,
> 
> at first:
> thanks for adding me to your mailing list.
> My question is about the cache_peer configuration directive.
> 

First problem. No. Your question is about acces controls and ACL processing.


> In my config I have to use three cache_peer proxies:
> 
> To choose the cache_peer on the basis of the URL its responsible for I use
> the cache_peer_access directive and created a .txt-file with the allowed
> urls. This is working fine.
> 
> But when I request a IP address "http://1.2.3.4" this is not working. For
> example:
> 
> http://test.best works over the responsible cache peer
> http://1.2.3.4 isn?t working


How exactly are you requesting a IP address?
Some tools will go directly to that IP instead of through the proxy.

If the request does go through the proxy. What is the http_port line
that received it?

Do you have any always_direct, preer_direct or never_direct lines in
your config?

> 
> The configuration looks the following:
> 
> acl parent1 url_regex -i "/etc/squid/parent1.txt
> 
> content of parent1.txt:
> ^http://test.best --> working
> ^http://1.2.3.4 --> not using the parent proxy and tries direct access.

You call the contents of the parent1.txt URLs. But you told Squid it
contains regex patterns to be matched against the actual URLs.

So its contents will only "work" if the entries you place in there are
valid regex patterns that also happen to match the effective-URLs of the
requests the proxy handles.

I suggest you use a dstdomain ACL type instead of url_regex. Then list
the domains that are expected to be handled by that peer.

Doing that will avoid problems with gettign teh regex correct, and
dstdomain is faster than regex.

> 
> cache_peer 10.1.2.3 parent 8080 name=parent1
> cache_peer_access parent1 allow parent1
> cache_peer_access parent1 deny all
> 
> Can you tell me where the fault is?

The problem is not clear from the details provided so far. The answer to
my earlier questsions above may provide more useful hints.

Amos



From squid3 at treenet.co.nz  Wed Jun  1 11:27:12 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 1 Jun 2016 23:27:12 +1200
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
In-Reply-To: <E3DA71A8-7F4C-493D-B7AF-1C89EFC1C68C@ncsu.edu>
References: <E3DA71A8-7F4C-493D-B7AF-1C89EFC1C68C@ncsu.edu>
Message-ID: <9e6f85c8-2989-53e6-b339-5b176092acd6@treenet.co.nz>

On 1/06/2016 9:05 a.m., Aashima Madaan wrote:
> Hey Amos,
> 
>> What is causing the problem is that ICAP services need to be working
>> *immediately* and do not wait for DNS results to come back. If they are
>> not available immediately then the service is not contactable for that
>> transaction.
> 
>> Adding /etc/hosts entries makes Squid load the name+IP details on
>> startup before ICAP is used. So the problem does not appear.
> Is there a configuration for squid where we can ask it to perform DNS lookup immediately rather than doing later when it sends an OPTIONS request again.
> 

No. DNS lookups are done when they are identified as being needed.

We could perhapse perform a 'seed' lookup while parsing the config.
Though that would be a bit tricky if DNS is differently configured later
in squid.conf than ICAP.

Does the attached patch resolve the issue for you?

Amos

-------------- next part --------------
=== modified file 'src/adaptation/ServiceConfig.cc'
--- src/adaptation/ServiceConfig.cc	2016-01-13 10:10:20 +0000
+++ src/adaptation/ServiceConfig.cc	2016-06-01 11:20:31 +0000
@@ -14,6 +14,8 @@
 #include "Debug.h"
 #include "globals.h"
 #include "ip/tools.h"
+#include "ipcache.h"
+
 #include <set>
 
 Adaptation::ServiceConfig::ServiceConfig():
@@ -234,6 +236,7 @@
     }
 
     host.limitInit(s, len);
+    (void)ipcache_gethostbyname(host.termedBuf(), IP_LOOKUP_IF_MISS);
 #if USE_OPENSSL
     if (secure.sslDomain.isEmpty())
         secure.sslDomain.assign(host.rawBuf(), host.size());


From squid3 at treenet.co.nz  Wed Jun  1 11:53:08 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 1 Jun 2016 23:53:08 +1200
Subject: [squid-users] pinger crash - Bad opcode: 112
In-Reply-To: <CAG6MAzQpEQNA1nv_GfNcWvQTccA7ZejyCoOiscsQS51C5FBcdQ@mail.gmail.com>
References: <CAG6MAzT+JQP0Bd+UDHN3zwigU6W8H6oGYxXdn3iVhuYqU=qZpg@mail.gmail.com>
 <bdb614cb-27fe-ad3a-5780-e6f9245e495d@treenet.co.nz>
 <CAG6MAzQpEQNA1nv_GfNcWvQTccA7ZejyCoOiscsQS51C5FBcdQ@mail.gmail.com>
Message-ID: <a176619d-3ca6-132b-f72e-40723be158ed@treenet.co.nz>

On 31/05/2016 9:56 p.m., Tomas Mozes wrote:
> On Thu, May 26, 2016 at 8:04 AM, Amos Jeffries wrote:
> 
>> On 24/05/2016 7:52 p.m., Tomas Mozes wrote:
>>> Hello,
>>> on two different squid servers I've observed a crash of pinger. First it
>>> appeared on version 3.5.15 and later on version 3.5.17.
>>>
>>> Cache.log contains these lines:
>>>
>>> (pinger): Address.cc:671: void Ip::Address::getAddrInfo(addrinfo*&, int)
>>> const: Assertion `false' failed.
>>> 2016/05/14 21:55:25 kid1| Bad opcode: 112 from
>>> [6661:6c73:6522:2061:7420:6c69:6e65:2036]
>>> 2016/05/14 21:59:13 kid1| recv: (111) Connection refused
>>> 2016/05/14 21:59:13 kid1| Closing Pinger socket on FD 17
>>>
>>> On both servers, that IPv6 address was the same -
>>> 6661:6c73:6522:2061:7420:6c69:6e65:2036
>>>
>>
>> That is the hexadecimal representation of the error:
>>  false" at line 6
>>
>> Which means that your kernel is producing garbage when asked to resolve
>> an IPv6 address or respond to an ICMPv6 packet.
>>
> 
> Cannot we prevent Squid from crashing in these cases?
> 

Squid is not crashing. The pinger is. Squid continues with degraded
service latency.

What kind of continued operations would you expect a program to do when
it discovers at least some portion of its RAM has been filled with
garbage by the system kernel?


Now cross your fingers and pray that no other programs on your whole
system (network, if you did the same "disable" on other machines) are
behaving badly in secret when given the garbage by the kernel like
Squid's pinger was.

Amos



From squid3 at treenet.co.nz  Wed Jun  1 12:26:20 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 2 Jun 2016 00:26:20 +1200
Subject: [squid-users] How to analyse squid memory usage
In-Reply-To: <5F7F29D5-F9E2-4FD2-9B9B-25DFE9E02E48@getbusi.com>
References: <B60DFE6C-9BA8-42CA-9B57-A2460517A35F@getbusi.com>
 <085044c5-9a62-8b6f-47e6-cee4410dfac9@treenet.co.nz>
 <421A4120-10F7-4694-94AF-B66C3CDF1D3E@getbusi.com>
 <E0EA512C-DC76-4D74-B95F-2635BF58C523@getbusi.com>
 <5F7F29D5-F9E2-4FD2-9B9B-25DFE9E02E48@getbusi.com>
Message-ID: <208c097a-5b42-da61-fc49-f4065b035833@treenet.co.nz>

On 24/05/2016 5:44 p.m., Dan Charlesworth wrote:
> Gentle bump ?
> 
> 

Hi Dan,
 sorry RL getting in the way these weeks.

Two things stand out for me.

Its a bit odd that exteral ACL entries shodul be so high. But your
"normal" report has more allocated than the "leaky" report. So thats
just a sign that your external ACLs are not working very efficiently
(results being fairly unique, so the lookup cache not being much use there).

In the "leaky" report there are 10K concurrent requests still active.
Normal report shows only 1K requests. So up to 10x the state data
storeage is needed by that proxy.


I'm a little suspicious you might be seeing another symptom of the issue
behind what others have been reporting as too many CLOSE_WAIT sockets
staying open with Squid not doing anything for them.

Amos



From nilesh.gavali at tcs.com  Wed Jun  1 12:27:51 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Wed, 1 Jun 2016 13:27:51 +0100
Subject: [squid-users] squid-users Digest, Vol 21, Issue 124
In-Reply-To: <mailman.23478.1464730359.2892.squid-users@lists.squid-cache.org>
References: <mailman.23478.1464730359.2892.squid-users@lists.squid-cache.org>
Message-ID: <OFFA5CD196.AE5A1581-ON80257FC5.00440EDB-80257FC5.00447714@tcs.com>

Hello Markus;

After adding -d comment, below error found cache.log

negotiate_kerberos_auth:ERROR: gss_accept_sec_context() failed: 
Unsepecified GSS failure. Minor code may provide more information.
Kid1 | ERROR: negotiate Authentication validating user. Error returned 'BH 
gss_accept_sec_context_() failed: Unspecified GSS failure. Minor code may 
provide more information.

Thanks & Regards
Nilesh Suresh Gavali





From:   squid-users-request at lists.squid-cache.org
To:     squid-users at lists.squid-cache.org
Date:   31/05/2016 22:33
Subject:        squid-users Digest, Vol 21, Issue 124
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org>



Send squid-users mailing list submissions to
                 squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
                 http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
                 squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
                 squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

   1. Re: DNS lookup fails initially for FQDN in squid (Aashima Madaan)
   2. Re: DNS lookup fails initially for FQDN in squid (Aashima Madaan)
   3. Re: missing negotiate_kerberos_auth on my squid (Markus Moeller)


----------------------------------------------------------------------

Message: 1
Date: Tue, 31 May 2016 16:02:57 -0400
From: Aashima Madaan <amadaan at ncsu.edu>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] DNS lookup fails initially for FQDN in
                 squid
Message-ID:
 <CAO4ouAazV-mvev9JpPwCLkE8Oj=eUzFUaO4sCLSpDvaxBbY78Q at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi Nishant,


>>>* (The last two commands in as quick succession as possible - 
preferably on a
*>>>* single line separated by a semi-colon)
*>>>>>>* yes the problem still exists
*>>>>

>Could it be because squid is trying to resolve and connect to IPv6 
address
>first?

>Try setting "dns_v4_first on" and try.


I tried setting this option but still the behavior is same.


Thanks

Aashima
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/d550af4d/attachment-0001.html
>

------------------------------

Message: 2
Date: Tue, 31 May 2016 17:05:40 -0400
From: Aashima Madaan <amadaan at ncsu.edu>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] DNS lookup fails initially for FQDN in
                 squid
Message-ID: <E3DA71A8-7F4C-493D-B7AF-1C89EFC1C68C at ncsu.edu>
Content-Type: text/plain; charset="utf-8"

Hey Amos,

>What is causing the problem is that ICAP services need to be working
>*immediately* and do not wait for DNS results to come back. If they are
>not available immediately then the service is not contactable for that
>transaction.

>Adding /etc/hosts entries makes Squid load the name+IP details on
>startup before ICAP is used. So the problem does not appear.
Is there a configuration for squid where we can ask it to perform DNS 
lookup immediately rather than doing later when it sends an OPTIONS 
request again.

Thanks
Aashima
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/92a57c07/attachment-0001.html
>

------------------------------

Message: 3
Date: Tue, 31 May 2016 22:31:20 +0100
From: "Markus Moeller" <huaraz at moeller.plus.com>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID: <nikvrp$3qr$1 at ger.gmane.org>
Content-Type: text/plain; charset="utf-8"

Hi Nilesh,

Just add a ?d to 


# enable kerberos authentication
auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s 
HTTP/hostname.domain.org at DOMAIN.ORG

like 

# enable kerberos authentication
auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s 
HTTP/hostname.domain.org at DOMAIN.ORG ?d 

Then you get debug output in your cache.log file.

Markus


"Markus Moeller" <huaraz at moeller.plus.com> wrote in message 
news:nikoqr$i2m$1 at ger.gmane.org...
What does the log say when you use the ?d option with the helper

Markus


"Nilesh Gavali" <nilesh.gavali at tcs.com> wrote in message 
news:OF059DEDF2.DD0EB7D2-ON80257FC4.006A0132-80257FC4.006A2AD0 at tcs.com...
Hello All; 

Configured the steps require for kerberos authentication as given at 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
but instead of SSO to work when we try to open url; it is prompt for 
username and password, when passing credential it is not authenticating. 
attached is our squid config for your reference. 

Kindly let us know what went wrong. 

we are using windows 2012 AD. 



Thanks & Regards
Nilesh Suresh Gavali




From:        Nilesh Gavali/MUM/TCS 
To:        squid-users at lists.squid-cache.org, belle at bazuin.nl 
Date:        27/05/2016 15:07 
Subject:        missing negotiate_kerberos_auth on my squid 

--------------------------------------------------------------------------------


Thanks louise for reply. 

but 

Should be include imo. -- not sure what is imo

 

Shoud be in any Squid-3.2 and later.

 

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth - check the path but it is not 
there on my linux box.

 

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? 
---- NO didn't gave this option while compilation

 

Run squid ?v to check it. -- we have"--enable-auth-negotiate" only and 
some other configured option. 

can you help me how to get hit recomipled with reuqire options. 


Thanks & Regards
Nilesh Suresh Gavali

----- Forwarded by Nilesh Gavali/MUM/TCS on 27/05/2016 15:01 ----- 

From:        squid-users-request at lists.squid-cache.org 
To:        squid-users at lists.squid-cache.org 
Date:        27/05/2016 12:42 
Subject:        squid-users Digest, Vol 21, Issue 101 
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org> 

--------------------------------------------------------------------------------



Send squid-users mailing list submissions to
                squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
                http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
                squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
                squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

  1. NULL characters (joe)
  2. Re: Looking for a way to route into cache_peer traffic
     dynamically. (Alex Rousskov)
  3. The system returned: (111) Connection refused; (deepa ganu)
  4. Re: NULL characters (Eliezer Croitoru)
  5. missing negotiate_kerberos_auth on my squid (Nilesh Gavali)
  6. Re: missing negotiate_kerberos_auth on my squid (L.P.H. van Belle)


----------------------------------------------------------------------

Message: 1
Date: Thu, 26 May 2016 07:30:16 -0700 (PDT)
From: joe <chip_pop at hotmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters
Message-ID: <1464273016183-4677691.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: 
http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html

Sent from the Squid - Users mailing list archive at Nabble.com.


------------------------------

Message: 2
Date: Thu, 26 May 2016 09:16:52 -0600
From: Alex Rousskov <rousskov at measurement-factory.com>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Looking for a way to route into cache_peer
                traffic dynamically.
Message-ID: <57471364.4030007 at measurement-factory.com>
Content-Type: text/plain; charset=utf-8

On 05/26/2016 03:52 AM, Eliezer Croitoru wrote:

> I think that the best way is to use an ICAP meta header instead of 
altering
> the request itself 

Agreed.


> but I am not sure if it is possible

It is not possible today: Converting ICAP headers into annotations
understood by Squid ACLs is only supported for eCAP services.

IIRC, somebody posted a patch (on squid-dev) with a similar feature for
ICAP, but that implementation needed to be redone to be officially
accepted (IMO). I do not know whether the author will adjust their code
to follow my recommendations. Perhaps you can do it for them.

Alex.



------------------------------

Message: 3
Date: Fri, 27 May 2016 14:25:19 +0530
From: deepa ganu <deepaganu at gmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] The system returned: (111) Connection refused;
Message-ID:
 <CA+qV5k+cSUThvZYCS1JLcNuXsFCA8Vnk1Rmc5opK1w15W6asyg at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi
I am using squid as a reverse.

#http_port  80 accel defaultsite=202.53.13.19
https_port 443 accel  cert=/var/www/html/webrtc/imp/teleuniv.net.crt
key=/var/www/html/webrtc/imp/teleuniv.net.key
cafile=/var/www/html/webrtc/imp/intermediate.crt defaultsite=202.53.13.19
no-vhost


#this ACL is url path specific which accepts only portal urls and deny
others.
acl portal urlpath_regex ^/portal6may
cache_peer 172.20.36.144 parent 80 0 no-query originserver 
name=portalserver
cache_peer_access portalserver allow portal
cache_peer_access portalserver deny all
http_access allow portal


cache_peer 172.20.36.150 parent 443 0 no-query originserver ssl
sslflags=DONT_VERIFY_PEER login=PASS connection-auth=off name=teleuniv
acl our_sites dstdomain 202.53.13.19
http_access allow our_sites
cache_peer_access teleuniv allow our_sites
cache_peer_access teleuniv deny all

SO when i try to access the url https://202.53.13.19/ I get the following
error
"The following error was encountered while trying to retrieve the URL: The
system returned: (111) Connection refused; The remote host or network may
be down. Please try the request again."

It only gives for 172.20.36.144 not for the urlpath acl. But this happens
only sometimes. When I physically go to that server (172.20.36.150) and
click on the wired connection (one of the LAN options using linux). It
works again. I am very confused

-- 
Regards
Deepa Ganu
R&D Head(CSE) KMIT
Ph no : 9908036660
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/998e60f3/attachment-0001.html
>

------------------------------

Message: 4
Date: Fri, 27 May 2016 14:17:17 +0300
From: "Eliezer Croitoru" <eliezer at ngtech.co.il>
To: "'joe'" <chip_pop at hotmail.com>,
                <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] NULL characters
Message-ID: <33b501d1b809$541a9620$fc4fc260$@ngtech.co.il>
Content-Type: text/plain;                 charset="utf-8"

If it ended with some kind of server issues else then the logs, then it 
would be considered not nice.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On 
Behalf Of joe
Sent: Thursday, May 26, 2016 5:30 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: 
http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html

Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



------------------------------

Message: 5
Date: Fri, 27 May 2016 12:32:15 +0100
From: Nilesh Gavali <nilesh.gavali at tcs.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
 <OF9C6F8F89.5CF2ECB1-ON80257FC0.003EE232-80257FC0.003F5EF7 at tcs.com>
Content-Type: text/plain; charset="utf-8"

Hello ;
I have installed latest squid 3.5.19 on red hat Linux yesterday. That 
means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but 
facing issues.
followed the steps provided on 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
But unable to find negotiate_kerberos_auth  on my Linux box at any 
location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and 

compile it to make authentication successful.

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.   IT Services
                       Business Solutions
                       Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 

Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/b812d6ac/attachment-0001.html
>

------------------------------

Message: 6
Date: Fri, 27 May 2016 13:41:34 +0200
From: L.P.H. van Belle <belle at bazuin.nl>
To: squid-users at squid-cache.org  <squid-users at squid-cache.org>
Subject: Re: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
 <vmime.5748326e.63bf.32264d027089be4e at ms249-lin-003.rotterdam.bazuin.nl>
 
Content-Type: text/plain; charset="windows-1252"

Should be include imo. 

 

Shoud be in any Squid-3.2 and later.

 

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth 

 

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? 

 

Run squid ?v to check it. 

 

Greetz, 

 

Louis

 

 


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens 
Nilesh Gavali
Verzonden: vrijdag 27 mei 2016 13:32
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] missing negotiate_kerberos_auth on my squid


 

Hello ; 
I have installed latest squid 3.5.19 on red hat Linux yesterday. That 
means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but 
facing issues. 
followed the steps provided on 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
But unable to find negotiate_kerberos_auth  on my Linux box at any 
location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and 
compile it to make authentication successful. 

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.        IT Services
                       Business Solutions
                       Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 
 Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/bbeb60e2/attachment.html
>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 21, Issue 101
********************************************




--------------------------------------------------------------------------------
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



--------------------------------------------------------------------------------
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/737abf12/attachment.html
>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 21, Issue 124
********************************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160601/c2c6033e/attachment.htm>

From nilesh.gavali at tcs.com  Wed Jun  1 12:44:52 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Wed, 1 Jun 2016 13:44:52 +0100
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
In-Reply-To: <vmime.574ea233.3704.3945fd6521fef1e3@ms249-lin-003.rotterdam.bazuin.nl>
References: <OF6BC559F7.84283A07-ON80257FC0.004CFF22-80257FC0.004D9F23@LocalDomain>
 <vmime.574ea233.3704.3945fd6521fef1e3@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <OFC1848285.4B4DEC15-ON80257FC5.00448EF1-80257FC5.004605B9@tcs.com>

Hi Louise;
refer the comment on below questions.

 
1)       is the time in sync with the proxy and AD server?  - YES
2)       Did you set the krb5.conf  with or without the enctypes types? it 
is set with enctypes
3)       Which browser are you using? we tried using IE and chorme.
4)       Did you configure the browser to use the kerberos auth? YES.
5)       Did the PC join the domain, and are u using a domain user login? 
YES.
6)       Does kinit user at REALM work?  ( kdestroy to remove the user ticket 
) YES. it shows the desire O/P
7)       Last, does the proxy server have an A and PTR record? YES.

below error got in cache.log

negotiate_kerberos_auth:ERROR: gss_accept_sec_context() failed: 
Unsepecified GSS failure. Minor code may provide more information.
Kid1 | ERROR: negotiate Authentication validating user. Error returned 'BH 
gss_accept_sec_context_() failed: Unspecified GSS failure. Minor code may 
provide more information.


Thanks & Regards
Nilesh Suresh Gavali






From:   L.P.H. van Belle <belle at bazuin.nl>
To:     Nilesh Gavali <nilesh.gavali at tcs.com>
Cc:     squid-users at squid-cache.org <squid-users at squid-cache.org>
Date:   01/06/2016 09:53
Subject:        RE: missing negotiate_kerberos_auth on my squid



Wel first, great, you made it to install it, 
 
Yes, but your auth pop-up can be normal, but we need more info, this can 
be multple things. 
 
So, few small questions. 
 
1)       is the time in sync with the proxy and AD server? 
2)       Did you set the krb5.conf  with or without the enctypes types? 
3)       Which browser are you using?
4)       Did you configure the browser to use the kerberos auth? 
5)       Did the PC join the domain, and are u using a domain user login? 
6)       Does kinit user at REALM work?  ( kdestroy to remove the user ticket 
) 
7)       Last, does the proxy server have an A and PTR record? 
 
Also check this site, review your settings. 
https://ping.force.com/Support/PingFederate/Integrations/How-to-configure-supported-browsers-for-Kerberos-NTLM 

 
And last tip your auth line. 
auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s 
HTTP/hostname.domain.org at DOMAIN.ORG 
 
Can also be a problem so test, if the upn is setup incorrectly, then above 
does not work, below the should work. 
auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s 
GSS_C_NO_NAME
 
add  -d to get more debug info. 
 
greetz, 
 
Louis
 

Van: Nilesh Gavali [mailto:nilesh.gavali at tcs.com] 
Verzonden: dinsdag 31 mei 2016 21:20
Aan: squid-users at lists.squid-cache.org
CC: L.P.H. van Belle
Onderwerp: missing negotiate_kerberos_auth on my squid
 
Hello All; 

Configured the steps require for kerberos authentication as given at 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
but instead of SSO to work when we try to open url; it is prompt for 
username and password, when passing credential it is not authenticating. 
attached is our squid config for your reference. 

Kindly let us know what went wrong. 

we are using windows 2012 AD. 



Thanks & Regards
Nilesh Suresh Gavali




From:        Nilesh Gavali/MUM/TCS 
To:        squid-users at lists.squid-cache.org, belle at bazuin.nl 
Date:        27/05/2016 15:07 
Subject:         missing negotiate_kerberos_auth on my squid 



Thanks louise for reply. 

but 

Should be include imo. -- not sure what is imo

 

Shoud be in any Squid-3.2 and later.

 

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth - check the path but it is not 
there on my linux box.

 

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? 
---- NO didn't gave this option while compilation

 

Run squid ?v to check it. -- we have"--enable-auth-negotiate" only and 
some other configured option. 

can you help me how to get hit recomipled with reuqire options. 


Thanks & Regards
Nilesh Suresh Gavali

----- Forwarded by Nilesh Gavali/MUM/TCS on 27/05/2016 15:01 ----- 

From:        squid-users-request at lists.squid-cache.org 
To:        squid-users at lists.squid-cache.org 
Date:        27/05/2016 12:42 
Subject:        squid-users Digest, Vol 21, Issue 101 
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org> 




Send squid-users mailing list submissions to
                squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
                http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
                squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
                squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

  1. NULL characters (joe)
  2. Re: Looking for a way to route into cache_peer traffic
     dynamically. (Alex Rousskov)
  3. The system returned: (111) Connection refused; (deepa ganu)
  4. Re: NULL characters (Eliezer Croitoru)
  5. missing negotiate_kerberos_auth on my squid (Nilesh Gavali)
  6. Re: missing negotiate_kerberos_auth on my squid (L.P.H. van Belle)


----------------------------------------------------------------------

Message: 1
Date: Thu, 26 May 2016 07:30:16 -0700 (PDT)
From: joe <chip_pop at hotmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters
Message-ID: <1464273016183-4677691.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: 
http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html

Sent from the Squid - Users mailing list archive at Nabble.com.


------------------------------

Message: 2
Date: Thu, 26 May 2016 09:16:52 -0600
From: Alex Rousskov <rousskov at measurement-factory.com>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Looking for a way to route into cache_peer
                traffic dynamically.
Message-ID: <57471364.4030007 at measurement-factory.com>
Content-Type: text/plain; charset=utf-8

On 05/26/2016 03:52 AM, Eliezer Croitoru wrote:

> I think that the best way is to use an ICAP meta header instead of 
altering
> the request itself 

Agreed.


> but I am not sure if it is possible

It is not possible today: Converting ICAP headers into annotations
understood by Squid ACLs is only supported for eCAP services.

IIRC, somebody posted a patch (on squid-dev) with a similar feature for
ICAP, but that implementation needed to be redone to be officially
accepted (IMO). I do not know whether the author will adjust their code
to follow my recommendations. Perhaps you can do it for them.

Alex.



------------------------------

Message: 3
Date: Fri, 27 May 2016 14:25:19 +0530
From: deepa ganu <deepaganu at gmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] The system returned: (111) Connection refused;
Message-ID:
 <CA+qV5k+cSUThvZYCS1JLcNuXsFCA8Vnk1Rmc5opK1w15W6asyg at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi
I am using squid as a reverse.

#http_port  80 accel defaultsite=202.53.13.19
https_port 443 accel  cert=/var/www/html/webrtc/imp/teleuniv.net.crt
key=/var/www/html/webrtc/imp/teleuniv.net.key
cafile=/var/www/html/webrtc/imp/intermediate.crt defaultsite=202.53.13.19
no-vhost


#this ACL is url path specific which accepts only portal urls and deny
others.
acl portal urlpath_regex ^/portal6may
cache_peer 172.20.36.144 parent 80 0 no-query originserver 
name=portalserver
cache_peer_access portalserver allow portal
cache_peer_access portalserver deny all
http_access allow portal


cache_peer 172.20.36.150 parent 443 0 no-query originserver ssl
sslflags=DONT_VERIFY_PEER login=PASS connection-auth=off name=teleuniv
acl our_sites dstdomain 202.53.13.19
http_access allow our_sites
cache_peer_access teleuniv allow our_sites
cache_peer_access teleuniv deny all

SO when i try to access the url MailScanner heeft een e-mail met mogelijk 
een poging tot fraude gevonden van "202.53.13.19" MailScanner warning: 
numerical links are often malicious: https://202.53.13.19/ I get the 
following
error
"The following error was encountered while trying to retrieve the URL: The
system returned: (111) Connection refused; The remote host or network may
be down. Please try the request again."

It only gives for 172.20.36.144 not for the urlpath acl. But this happens
only sometimes. When I physically go to that server (172.20.36.150) and
click on the wired connection (one of the LAN options using linux). It
works again. I am very confused

-- 
Regards
Deepa Ganu
R&D Head(CSE) KMIT
Ph no : 9908036660
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/998e60f3/attachment-0001.html
>

------------------------------

Message: 4
Date: Fri, 27 May 2016 14:17:17 +0300
From: "Eliezer Croitoru" <eliezer at ngtech.co.il>
To: "'joe'" <chip_pop at hotmail.com>,
                <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] NULL characters
Message-ID: <33b501d1b809$541a9620$fc4fc260$@ngtech.co.il>
Content-Type: text/plain;                 charset="utf-8"

If it ended with some kind of server issues else then the logs, then it 
would be considered not nice.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On 
Behalf Of joe
Sent: Thursday, May 26, 2016 5:30 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: 
http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html

Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



------------------------------

Message: 5
Date: Fri, 27 May 2016 12:32:15 +0100
From: Nilesh Gavali <nilesh.gavali at tcs.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
 <OF9C6F8F89.5CF2ECB1-ON80257FC0.003EE232-80257FC0.003F5EF7 at tcs.com>
Content-Type: text/plain; charset="utf-8"

Hello ;
I have installed latest squid 3.5.19 on red hat Linux yesterday. That 
means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but 
facing issues.
followed the steps provided on 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
But unable to find negotiate_kerberos_auth  on my Linux box at any 
location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and 

compile it to make authentication successful.

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.   IT Services
                       Business Solutions
                       Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 

Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/b812d6ac/attachment-0001.html
>

------------------------------

Message: 6
Date: Fri, 27 May 2016 13:41:34 +0200
From: L.P.H. van Belle <belle at bazuin.nl>
To: squid-users at squid-cache.org  <squid-users at squid-cache.org>
Subject: Re: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
 <vmime.5748326e.63bf.32264d027089be4e at ms249-lin-003.rotterdam.bazuin.nl>
 
Content-Type: text/plain; charset="windows-1252"

Should be include imo. 

 

Shoud be in any Squid-3.2 and later.

 

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth 

 

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? 

 

Run squid ?v to check it. 

 

Greetz, 

 

Louis

 

 


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens 
Nilesh Gavali
Verzonden: vrijdag 27 mei 2016 13:32
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] missing negotiate_kerberos_auth on my squid


 

Hello ; 
 I have installed latest squid 3.5.19 on red hat Linux yesterday. That 
means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but 
facing issues. 
followed the steps provided on 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
But unable to find negotiate_kerberos_auth  on my Linux box at any 
location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and 
compile it to make authentication successful. 

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.        IT Services
                       Business Solutions
                       Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 
 Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/bbeb60e2/attachment.html
>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 21, Issue 101
********************************************
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160601/046586d5/attachment.htm>

From belle at bazuin.nl  Wed Jun  1 14:18:28 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 1 Jun 2016 16:18:28 +0200
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
In-Reply-To: <OFC1848285.4B4DEC15-ON80257FC5.00448EF1-80257FC5.004605B9@tcs.com>
References: <vmime.574ea233.3704.3945fd6521fef1e3@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <vmime.574eeeb4.1821.1fbd4eec458867f4@ms249-lin-003.rotterdam.bazuin.nl>

Hai. 

?

First before you read through all. 

?

Please check if the squid user kan read the keytab file.

This can be a thing. And check the KVNO with the auth here can be a mismatch also. 

?

Second, test with in the negotiate wrapper. 

??? --kerberos /usr/lib/squid/negotiate_kerberos_auth -s GSS_C_NO_NAME 

?

I did read. 

http://wiki.squid-cache.org/ConfigExamples/Authenticate/WindowsActiveDirectory

This is not entry correct anymore due to last changed in samba, dont know how this applies to Win 2012 ADDC these patches also applied to windows. 

Sorry no windows here anymore, only samba.

?

Now, below is all tested on debian with samba 4.4.3 AD and squid 3.5.19. 

?

?

This needed te be added in smb.conf to make sure all auth is done over encrypted layers. 

?

??? server signing = mandatory

??? ntlm auth = no

?

??? #Add and Update TLS Key of your proxy and Root ) 

??? tls enabled = yes

??? tls keyfile = /etc/ssl/local/private/-proxy.key.pem

??? tls certfile = /etc/ssl/local/certs/proxy.cert.pem

??? tls cafile = /etc/ssl/certs/INTERNALROOT-ca.pem

?

Extra info? on? tls cafile = /etc/ssl/certs/INTERNALROOT-ca.pem. 

The original file is located in /usr/local/ca-certificates/companyname/ 

When the ?correct? ca setup is done, then you see a simlink in /etc/ssl/certs. 

?

The ?correct? way to setup the ROOT CA ?Look here. 

http://ram.kossboss.com/debian-install-trusted-ssl/ 

works fine also with own certs, thats what i use internal here also.

?

In /etc/ldap/ldap.conf

Make sure you have al least. 

# TLS certificates (needed for GnuTLS)

TLS_CACERT????? /etc/ssl/certs/ca-certificates.crt

TLS_REQCERT allow 

?

?

This is what i now use in squid auth. 

Kerberos , fallback to NTLM , fallback to basic LDAP(S) auth.

?

auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \

??? --kerberos /usr/lib/squid/negotiate_kerberos_auth -s HTTP/proxy1.internal.dnsdomain.tld at REALM \

??? --ntlm /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --domain=NTDOMAIN

?

# A NOT SSL HOST format ?h setup. 

#auth_param basic program /usr/lib/squid/basic_ldap_auth -R -v 3 \

#??? -b "ou=Office,dc=internal,dc=domain,dc=tld" \

#??? -D bind-user at REALM \

#??? -W /etc/squid/private/bind-user \

#??? -f (sAMAccountName=%s) \

#??? -h dc2.internal.dnsdomain.tld \

#??? -h dc1.internal.dnsdomain.tld

?

## A SSL enabled URI format -H ?setup

auth_param basic program /usr/lib/squid/basic_ldap_auth -R -v 3 \

??? -b "ou=Office,dc=internal,dc=domain,dc=tld" \

??? -D bind-user at REALM \

??? -W /etc/squid/private/bind-user \

??? -f sAMAccountName=%s \

??? -H ldaps:// dc2.internal.dnsdomain.tld \

??? -H ldaps://dc1.internal.dnsdomain.tld \

?

For /etc/krb5.conf ?i only have 

[libdefaults]

??? default_realm = REALM

??? dns_lookup_kdc = true

??? dns_lookup_realm = false

?

If above does not help, well then ask for more help here. ?

?

?

Greetz, 

?

Louis

?

?

?

?


Van: Nilesh Gavali [mailto:nilesh.gavali at tcs.com] 
Verzonden: woensdag 1 juni 2016 14:45
Aan: L.P.H. van Belle
CC: squid-users at squid-cache.org
Onderwerp: RE: missing negotiate_kerberos_auth on my squid


?

Hi Louise; 
refer the comment on below questions. 

? 
1) ? ? ? is the time in sync with the proxy and AD server? ?- YES 
2) ? ? ? Did you set the krb5.conf ?with or without the enctypes types? it is set with enctypes 
3) ? ? ? Which browser are you using? we tried using IE and chorme. 
4) ? ? ? Did you configure the browser to use the kerberos auth? YES. 
5) ? ? ? Did the PC join the domain, and are u using a domain user login? YES. 
6) ? ? ? Does kinit user at REALM work? ?( kdestroy to remove the user ticket ) YES. it shows the desire O/P 
7) ? ? ? Last, does the proxy server have an A and PTR record? YES. 

below error got in cache.log 

negotiate_kerberos_auth:ERROR: gss_accept_sec_context() failed: Unsepecified GSS failure. Minor code may provide more information. 
Kid1 | ERROR: negotiate Authentication validating user. Error returned 'BH gss_accept_sec_context_() failed: Unspecified GSS failure. Minor code may provide more information. 


Thanks & Regards
Nilesh Suresh Gavali






From: ? ? ? ?L.P.H. van Belle <belle at bazuin.nl> 
To: ? ? ? ?Nilesh Gavali <nilesh.gavali at tcs.com> 
Cc: ? ? ? ?squid-users at squid-cache.org <squid-users at squid-cache.org> 
Date: ? ? ? ?01/06/2016 09:53 
Subject: ? ? ? ?RE: missing negotiate_kerberos_auth on my squid 





Wel first, great, you made it to install it, 
? 
Yes, but your auth pop-up can be normal, but we need more info, this can be multple things. 
? 
So, few small questions. 
? 
1) ? ? ? is the time in sync with the proxy and AD server? 
2) ? ? ? Did you set the krb5.conf ?with or without the enctypes types? 
3) ? ? ? Which browser are you using? 
4) ? ? ? Did you configure the browser to use the kerberos auth? 
5) ? ? ? Did the PC join the domain, and are u using a domain user login? 
6) ? ? ? Does kinit user at REALM work? ?( kdestroy to remove the user ticket ) 
7) ? ? ? Last, does the proxy server have an A and PTR record? 
? 
Also check this site, review your settings. 
https://ping.force.com/Support/PingFederate/Integrations/How-to-configure-supported-browsers-for-Kerberos-NTLM 
? 
And last tip your auth line. 
auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s HTTP/hostname.domain.org at DOMAIN.ORG 
? 
Can also be a problem so test, if the upn is setup incorrectly, then above does not work, below the should work. 
auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s GSS_C_NO_NAME 
? 
add ?-d to get more debug info. 
? 
greetz, 
? 
Louis 
? 



Van: Nilesh Gavali [mailto:nilesh.gavali at tcs.com] 
Verzonden: dinsdag 31 mei 2016 21:20
Aan: squid-users at lists.squid-cache.org
CC: L.P.H. van Belle
Onderwerp: missing negotiate_kerberos_auth on my squid 
? 
Hello All; 

Configured the steps require for kerberos authentication as given at http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
but instead of SSO to work when we try to open url; it is prompt for username and password, when passing credential it is not authenticating. 
attached is our squid config for your reference. 

Kindly let us know what went wrong. 

we are using windows 2012 AD. 



Thanks & Regards
Nilesh Suresh Gavali




From: ? ? ? ?Nilesh Gavali/MUM/TCS 
To: ? ? ? ?squid-users at lists.squid-cache.org, belle at bazuin.nl 
Date: ? ? ? ?27/05/2016 15:07 
Subject: ? ? ? ? missing negotiate_kerberos_auth on my squid 





Thanks louise for reply. 

but 

Should be include imo. -- not sure what is imo



Shoud be in any Squid-3.2 and later.



And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth - check the path but it is not there on my linux box.



Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? ?---- NO didn't gave this option while compilation



Run squid ?v to check it. -- we have"--enable-auth-negotiate" only and some other configured option. 

can you help me how to get hit recomipled with reuqire options. 


Thanks & Regards
Nilesh Suresh Gavali

----- Forwarded by Nilesh Gavali/MUM/TCS on 27/05/2016 15:01 ----- 

From: ? ? ? ?squid-users-request at lists.squid-cache.org 
To: ? ? ? ?squid-users at lists.squid-cache.org 
Date: ? ? ? ?27/05/2016 12:42 
Subject: ? ? ? ?squid-users Digest, Vol 21, Issue 101 
Sent by: ? ? ? ?"squid-users" <squid-users-bounces at lists.squid-cache.org> 






Send squid-users mailing list submissions to
? ? ? ? ? ? ? ?squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
? ? ? ? ? ? ? ?http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
? ? ? ? ? ? ? ?squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
? ? ? ? ? ? ? ?squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

?1. NULL characters (joe)
?2. Re: Looking for a way to route into cache_peer traffic
? ? dynamically. (Alex Rousskov)
?3. The system returned: (111) Connection refused; (deepa ganu)
?4. Re: NULL characters (Eliezer Croitoru)
?5. missing negotiate_kerberos_auth on my squid (Nilesh Gavali)
?6. Re: missing negotiate_kerberos_auth on my squid (L.P.H. van Belle)


----------------------------------------------------------------------

Message: 1
Date: Thu, 26 May 2016 07:30:16 -0700 (PDT)
From: joe <chip_pop at hotmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters
Message-ID: <1464273016183-4677691.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii

2016/05/26 06:41:28 kid1| ctx: enter level ?0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level ?0

is it bad ?????



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html
Sent from the Squid - Users mailing list archive at Nabble.com.


------------------------------

Message: 2
Date: Thu, 26 May 2016 09:16:52 -0600
From: Alex Rousskov <rousskov at measurement-factory.com>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Looking for a way to route into cache_peer
? ? ? ? ? ? ? ?traffic dynamically.
Message-ID: <57471364.4030007 at measurement-factory.com>
Content-Type: text/plain; charset=utf-8

On 05/26/2016 03:52 AM, Eliezer Croitoru wrote:

> I think that the best way is to use an ICAP meta header instead of altering
> the request itself 

Agreed.


> but I am not sure if it is possible

It is not possible today: Converting ICAP headers into annotations
understood by Squid ACLs is only supported for eCAP services.

IIRC, somebody posted a patch (on squid-dev) with a similar feature for
ICAP, but that implementation needed to be redone to be officially
accepted (IMO). I do not know whether the author will adjust their code
to follow my recommendations. Perhaps you can do it for them.

Alex.



------------------------------

Message: 3
Date: Fri, 27 May 2016 14:25:19 +0530
From: deepa ganu <deepaganu at gmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] The system returned: (111) Connection refused;
Message-ID:
? ? ? ? ? ? ? ?<CA+qV5k+cSUThvZYCS1JLcNuXsFCA8Vnk1Rmc5opK1w15W6asyg at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi
I am using squid as a reverse.

#http_port ?80 accel defaultsite=202.53.13.19
https_port 443 accel ?cert=/var/www/html/webrtc/imp/teleuniv.net.crt
key=/var/www/html/webrtc/imp/teleuniv.net.key
cafile=/var/www/html/webrtc/imp/intermediate.crt defaultsite=202.53.13.19
no-vhost


#this ACL is url path specific which accepts only portal urls and deny
others.
acl portal urlpath_regex ^/portal6may
cache_peer 172.20.36.144 parent 80 0 no-query originserver name=portalserver
cache_peer_access portalserver allow portal
cache_peer_access portalserver deny all
http_access allow portal


cache_peer 172.20.36.150 parent 443 0 no-query originserver ssl
sslflags=DONT_VERIFY_PEER login=PASS connection-auth=off name=teleuniv
acl our_sites dstdomain 202.53.13.19
http_access allow our_sites
cache_peer_access teleuniv allow our_sites
cache_peer_access teleuniv deny all

SO when i try to access the url MailScanner heeft een e-mail met mogelijk een poging tot fraude gevonden van "202.53.13.19" MailScanner warning: numerical links are often malicious: https://202.53.13.19/ I get the following
error
"The following error was encountered while trying to retrieve the URL: The
system returned: (111) Connection refused; The remote host or network may
be down. Please try the request again."

It only gives for 172.20.36.144 not for the urlpath acl. But this happens
only sometimes. When I physically go to that server (172.20.36.150) and
click on the wired connection (one of the LAN options using linux). It
works again. I am very confused

-- 
Regards
Deepa Ganu
R&D Head(CSE) KMIT
Ph no : 9908036660
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/998e60f3/attachment-0001.html>

------------------------------

Message: 4
Date: Fri, 27 May 2016 14:17:17 +0300
From: "Eliezer Croitoru" <eliezer at ngtech.co.il>
To: "'joe'" <chip_pop at hotmail.com>,
? ? ? ? ? ? ? ?<squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] NULL characters
Message-ID: <33b501d1b809$541a9620$fc4fc260$@ngtech.co.il>
Content-Type: text/plain; ? ? ? ? ? ? ? ? charset="utf-8"

If it ended with some kind of server issues else then the logs, then it would be considered not nice.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of joe
Sent: Thursday, May 26, 2016 5:30 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters

2016/05/26 06:41:28 kid1| ctx: enter level ?0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level ?0

is it bad ?????



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



------------------------------

Message: 5
Date: Fri, 27 May 2016 12:32:15 +0100
From: Nilesh Gavali <nilesh.gavali at tcs.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
? ? ? ? ? ? ? ?<OF9C6F8F89.5CF2ECB1-ON80257FC0.003EE232-80257FC0.003F5EF7 at tcs.com>
Content-Type: text/plain; charset="utf-8"

Hello ;
I have installed latest squid 3.5.19 on red hat Linux yesterday. That 
means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but 
facing issues.
followed the steps provided on 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
But unable to find negotiate_kerberos_auth ?on my Linux box at any 
location. 
now I need to know where i can find/download ?negotiate_kerberos_auth ?and 
compile it to make authentication successful.

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty. ? IT Services
? ? ? ? ? ? ? ? ? ? ? Business Solutions
? ? ? ? ? ? ? ? ? ? ? Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated ?with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 
Registered ?in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/b812d6ac/attachment-0001.html>

------------------------------

Message: 6
Date: Fri, 27 May 2016 13:41:34 +0200
From: L.P.H. van Belle <belle at bazuin.nl>
To: squid-users at squid-cache.org ?<squid-users at squid-cache.org>
Subject: Re: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
? ? ? ? ? ? ? ?<vmime.5748326e.63bf.32264d027089be4e at ms249-lin-003.rotterdam.bazuin.nl>
? ? ? ? ? ? ? ?
Content-Type: text/plain; charset="windows-1252"

Should be include imo. 



Shoud be in any Squid-3.2 and later.



And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth 



Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? 



Run squid ?v to check it. 



Greetz, 



Louis






Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Nilesh Gavali
Verzonden: vrijdag 27 mei 2016 13:32
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] missing negotiate_kerberos_auth on my squid




Hello ; 
I have installed latest squid 3.5.19 on red hat Linux yesterday. That means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but facing issues. 
followed the steps provided on http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
But unable to find negotiate_kerberos_auth ?on my Linux box at any location. 
now I need to know where i can find/download ?negotiate_kerberos_auth ?and compile it to make authentication successful. 

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty. ? ? ? ?IT Services
? ? ? ? ? ? ? ? ? ? ? Business Solutions
? ? ? ? ? ? ? ? ? ? ? Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated ?with limited liability and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - ?Registered ?in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/bbeb60e2/attachment.html>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 21, Issue 101
******************************************** 


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160601/4b55aed1/attachment.htm>

From amadaan at ncsu.edu  Wed Jun  1 15:50:34 2016
From: amadaan at ncsu.edu (Aashima Madaan)
Date: Wed, 1 Jun 2016 11:50:34 -0400
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
Message-ID: <837C80AB-B8CD-4B31-8182-D65AEDAD5307@ncsu.edu>

Hey Amos,

I am trying to apply patch but it fails to apply for both hunks. It seems the source code is different .
I am using latest squid version src code 3.5.19

Can you send patch from the latest one or let me know which version you are using.

Thanks

From nilesh.gavali at tcs.com  Wed Jun  1 19:29:19 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Wed, 1 Jun 2016 20:29:19 +0100
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID: <OF67A1BEDE.D8307381-ON80257FC5.006ADE21-80257FC5.006B0CE3@tcs.com>

hello;
where can I define below -

KRB5_KTNAME=/etc/squid3/PROXY.keytab
export KRB5_KTNAME

Thanks & Regards
Nilesh Suresh Gavali

----- Forwarded by Nilesh Gavali/MUM/TCS on 01/06/2016 20:27 -----

From:   squid-users-request at lists.squid-cache.org
To:     squid-users at lists.squid-cache.org
Date:   01/06/2016 15:19
Subject:        squid-users Digest, Vol 22, Issue 5
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org>



Send squid-users mailing list submissions to
                 squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
                 http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
                 squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
                 squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

   1. Re: missing negotiate_kerberos_auth on my squid (L.P.H. van Belle)


----------------------------------------------------------------------

Message: 1
Date: Wed, 1 Jun 2016 16:18:28 +0200
From: L.P.H. van Belle <belle at bazuin.nl>
To: squid-users at squid-cache.org  <squid-users at squid-cache.org>
Subject: Re: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
 <vmime.574eeeb4.1821.1fbd4eec458867f4 at ms249-lin-003.rotterdam.bazuin.nl>
 
Content-Type: text/plain; charset="windows-1252"

Hai. 

 

First before you read through all. 

 

Please check if the squid user kan read the keytab file.

This can be a thing. And check the KVNO with the auth here can be a 
mismatch also. 

 

Second, test with in the negotiate wrapper. 

    --kerberos /usr/lib/squid/negotiate_kerberos_auth -s GSS_C_NO_NAME 

 

I did read. 

http://wiki.squid-cache.org/ConfigExamples/Authenticate/WindowsActiveDirectory


This is not entry correct anymore due to last changed in samba, dont know 
how this applies to Win 2012 ADDC these patches also applied to windows. 

Sorry no windows here anymore, only samba.

 

Now, below is all tested on debian with samba 4.4.3 AD and squid 3.5.19. 

 

 

This needed te be added in smb.conf to make sure all auth is done over 
encrypted layers. 

 

    server signing = mandatory

    ntlm auth = no

 

    #Add and Update TLS Key of your proxy and Root ) 

    tls enabled = yes

    tls keyfile = /etc/ssl/local/private/-proxy.key.pem

    tls certfile = /etc/ssl/local/certs/proxy.cert.pem

    tls cafile = /etc/ssl/certs/INTERNALROOT-ca.pem

 

Extra info  on  tls cafile = /etc/ssl/certs/INTERNALROOT-ca.pem. 

The original file is located in /usr/local/ca-certificates/companyname/ 

When the ?correct? ca setup is done, then you see a simlink in 
/etc/ssl/certs. 

 

The ?correct? way to setup the ROOT CA  Look here. 

http://ram.kossboss.com/debian-install-trusted-ssl/ 

works fine also with own certs, thats what i use internal here also.

 

In /etc/ldap/ldap.conf

Make sure you have al least. 

# TLS certificates (needed for GnuTLS)

TLS_CACERT      /etc/ssl/certs/ca-certificates.crt

TLS_REQCERT allow 

 

 

This is what i now use in squid auth. 

Kerberos , fallback to NTLM , fallback to basic LDAP(S) auth.

 

auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \

    --kerberos /usr/lib/squid/negotiate_kerberos_auth -s 
HTTP/proxy1.internal.dnsdomain.tld at REALM \

    --ntlm /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp 
--domain=NTDOMAIN

 

# A NOT SSL HOST format ?h setup. 

#auth_param basic program /usr/lib/squid/basic_ldap_auth -R -v 3 \

#    -b "ou=Office,dc=internal,dc=domain,dc=tld" \

#    -D bind-user at REALM \

#    -W /etc/squid/private/bind-user \

#    -f (sAMAccountName=%s) \

#    -h dc2.internal.dnsdomain.tld \

#    -h dc1.internal.dnsdomain.tld

 

## A SSL enabled URI format -H  setup

auth_param basic program /usr/lib/squid/basic_ldap_auth -R -v 3 \

    -b "ou=Office,dc=internal,dc=domain,dc=tld" \

    -D bind-user at REALM \

    -W /etc/squid/private/bind-user \

    -f sAMAccountName=%s \

    -H ldaps:// dc2.internal.dnsdomain.tld \

    -H ldaps://dc1.internal.dnsdomain.tld \

 

For /etc/krb5.conf  i only have 

[libdefaults]

    default_realm = REALM

    dns_lookup_kdc = true

    dns_lookup_realm = false

 

If above does not help, well then ask for more help here.  

 

 

Greetz, 

 

Louis

 

 

 

 


Van: Nilesh Gavali [mailto:nilesh.gavali at tcs.com] 
Verzonden: woensdag 1 juni 2016 14:45
Aan: L.P.H. van Belle
CC: squid-users at squid-cache.org
Onderwerp: RE: missing negotiate_kerberos_auth on my squid


 

Hi Louise; 
refer the comment on below questions. 

  
1)       is the time in sync with the proxy and AD server?  - YES 
2)       Did you set the krb5.conf  with or without the enctypes types? it 
is set with enctypes 
3)       Which browser are you using? we tried using IE and chorme. 
4)       Did you configure the browser to use the kerberos auth? YES. 
5)       Did the PC join the domain, and are u using a domain user login? 
YES. 
6)       Does kinit user at REALM work?  ( kdestroy to remove the user ticket 
) YES. it shows the desire O/P 
7)       Last, does the proxy server have an A and PTR record? YES. 

below error got in cache.log 

negotiate_kerberos_auth:ERROR: gss_accept_sec_context() failed: 
Unsepecified GSS failure. Minor code may provide more information. 
Kid1 | ERROR: negotiate Authentication validating user. Error returned 'BH 
gss_accept_sec_context_() failed: Unspecified GSS failure. Minor code may 
provide more information. 


Thanks & Regards
Nilesh Suresh Gavali






From:        L.P.H. van Belle <belle at bazuin.nl> 
To:        Nilesh Gavali <nilesh.gavali at tcs.com> 
Cc:        squid-users at squid-cache.org <squid-users at squid-cache.org> 
Date:        01/06/2016 09:53 
Subject:        RE: missing negotiate_kerberos_auth on my squid 





Wel first, great, you made it to install it, 
  
Yes, but your auth pop-up can be normal, but we need more info, this can 
be multple things. 
  
So, few small questions. 
  
1)       is the time in sync with the proxy and AD server? 
2)       Did you set the krb5.conf  with or without the enctypes types? 
3)       Which browser are you using? 
4)       Did you configure the browser to use the kerberos auth? 
5)       Did the PC join the domain, and are u using a domain user login? 
6)       Does kinit user at REALM work?  ( kdestroy to remove the user ticket 
) 
7)       Last, does the proxy server have an A and PTR record? 
  
Also check this site, review your settings. 
https://ping.force.com/Support/PingFederate/Integrations/How-to-configure-supported-browsers-for-Kerberos-NTLM 

  
And last tip your auth line. 
auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s 
HTTP/hostname.domain.org at DOMAIN.ORG 
  
Can also be a problem so test, if the upn is setup incorrectly, then above 
does not work, below the should work. 
auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s 
GSS_C_NO_NAME 
  
add  -d to get more debug info. 
  
greetz, 
  
Louis 
  



Van: Nilesh Gavali [mailto:nilesh.gavali at tcs.com] 
Verzonden: dinsdag 31 mei 2016 21:20
Aan: squid-users at lists.squid-cache.org
CC: L.P.H. van Belle
Onderwerp: missing negotiate_kerberos_auth on my squid 
  
Hello All; 

Configured the steps require for kerberos authentication as given at 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
but instead of SSO to work when we try to open url; it is prompt for 
username and password, when passing credential it is not authenticating. 
attached is our squid config for your reference. 

Kindly let us know what went wrong. 

we are using windows 2012 AD. 



Thanks & Regards
Nilesh Suresh Gavali




From:        Nilesh Gavali/MUM/TCS 
To:        squid-users at lists.squid-cache.org, belle at bazuin.nl 
Date:        27/05/2016 15:07 
Subject:         missing negotiate_kerberos_auth on my squid 





Thanks louise for reply. 

but 

Should be include imo. -- not sure what is imo



Shoud be in any Squid-3.2 and later.



And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth - check the path but it is not 
there on my linux box.



Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? 
 ---- NO didn't gave this option while compilation



Run squid ?v to check it. -- we have"--enable-auth-negotiate" only and 
some other configured option. 

can you help me how to get hit recomipled with reuqire options. 


Thanks & Regards
Nilesh Suresh Gavali

----- Forwarded by Nilesh Gavali/MUM/TCS on 27/05/2016 15:01 ----- 

From:        squid-users-request at lists.squid-cache.org 
To:        squid-users at lists.squid-cache.org 
Date:        27/05/2016 12:42 
Subject:        squid-users Digest, Vol 21, Issue 101 
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org> 






Send squid-users mailing list submissions to
               squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
               http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
               squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
               squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

 1. NULL characters (joe)
 2. Re: Looking for a way to route into cache_peer traffic
    dynamically. (Alex Rousskov)
 3. The system returned: (111) Connection refused; (deepa ganu)
 4. Re: NULL characters (Eliezer Croitoru)
 5. missing negotiate_kerberos_auth on my squid (Nilesh Gavali)
 6. Re: missing negotiate_kerberos_auth on my squid (L.P.H. van Belle)


----------------------------------------------------------------------

Message: 1
Date: Thu, 26 May 2016 07:30:16 -0700 (PDT)
From: joe <chip_pop at hotmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters
Message-ID: <1464273016183-4677691.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: 
http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html

Sent from the Squid - Users mailing list archive at Nabble.com.


------------------------------

Message: 2
Date: Thu, 26 May 2016 09:16:52 -0600
From: Alex Rousskov <rousskov at measurement-factory.com>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Looking for a way to route into cache_peer
               traffic dynamically.
Message-ID: <57471364.4030007 at measurement-factory.com>
Content-Type: text/plain; charset=utf-8

On 05/26/2016 03:52 AM, Eliezer Croitoru wrote:

> I think that the best way is to use an ICAP meta header instead of 
altering
> the request itself 

Agreed.


> but I am not sure if it is possible

It is not possible today: Converting ICAP headers into annotations
understood by Squid ACLs is only supported for eCAP services.

IIRC, somebody posted a patch (on squid-dev) with a similar feature for
ICAP, but that implementation needed to be redone to be officially
accepted (IMO). I do not know whether the author will adjust their code
to follow my recommendations. Perhaps you can do it for them.

Alex.



------------------------------

Message: 3
Date: Fri, 27 May 2016 14:25:19 +0530
From: deepa ganu <deepaganu at gmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] The system returned: (111) Connection refused;
Message-ID:
              
 <CA+qV5k+cSUThvZYCS1JLcNuXsFCA8Vnk1Rmc5opK1w15W6asyg at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi
I am using squid as a reverse.

#http_port  80 accel defaultsite=202.53.13.19
https_port 443 accel  cert=/var/www/html/webrtc/imp/teleuniv.net.crt
key=/var/www/html/webrtc/imp/teleuniv.net.key
cafile=/var/www/html/webrtc/imp/intermediate.crt defaultsite=202.53.13.19
no-vhost


#this ACL is url path specific which accepts only portal urls and deny
others.
acl portal urlpath_regex ^/portal6may
cache_peer 172.20.36.144 parent 80 0 no-query originserver 
name=portalserver
cache_peer_access portalserver allow portal
cache_peer_access portalserver deny all
http_access allow portal


cache_peer 172.20.36.150 parent 443 0 no-query originserver ssl
sslflags=DONT_VERIFY_PEER login=PASS connection-auth=off name=teleuniv
acl our_sites dstdomain 202.53.13.19
http_access allow our_sites
cache_peer_access teleuniv allow our_sites
cache_peer_access teleuniv deny all

SO when i try to access the url MailScanner heeft een e-mail met mogelijk 
een poging tot fraude gevonden van "202.53.13.19" MailScanner warning: 
numerical links are often malicious: https://202.53.13.19/ I get the 
following
error
"The following error was encountered while trying to retrieve the URL: The
system returned: (111) Connection refused; The remote host or network may
be down. Please try the request again."

It only gives for 172.20.36.144 not for the urlpath acl. But this happens
only sometimes. When I physically go to that server (172.20.36.150) and
click on the wired connection (one of the LAN options using linux). It
works again. I am very confused

-- 
Regards
Deepa Ganu
R&D Head(CSE) KMIT
Ph no : 9908036660
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/998e60f3/attachment-0001.html
>

------------------------------

Message: 4
Date: Fri, 27 May 2016 14:17:17 +0300
From: "Eliezer Croitoru" <eliezer at ngtech.co.il>
To: "'joe'" <chip_pop at hotmail.com>,
               <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] NULL characters
Message-ID: <33b501d1b809$541a9620$fc4fc260$@ngtech.co.il>
Content-Type: text/plain;                 charset="utf-8"

If it ended with some kind of server issues else then the logs, then it 
would be considered not nice.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On 
Behalf Of joe
Sent: Thursday, May 26, 2016 5:30 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: 
http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html

Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



------------------------------

Message: 5
Date: Fri, 27 May 2016 12:32:15 +0100
From: Nilesh Gavali <nilesh.gavali at tcs.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
              
 <OF9C6F8F89.5CF2ECB1-ON80257FC0.003EE232-80257FC0.003F5EF7 at tcs.com>
Content-Type: text/plain; charset="utf-8"

Hello ;
I have installed latest squid 3.5.19 on red hat Linux yesterday. That 
means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but 
facing issues.
followed the steps provided on 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
But unable to find negotiate_kerberos_auth  on my Linux box at any 
location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and 

compile it to make authentication successful.

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.   IT Services
                      Business Solutions
                      Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 

Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/b812d6ac/attachment-0001.html
>

------------------------------

Message: 6
Date: Fri, 27 May 2016 13:41:34 +0200
From: L.P.H. van Belle <belle at bazuin.nl>
To: squid-users at squid-cache.org  <squid-users at squid-cache.org>
Subject: Re: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
              
 <vmime.5748326e.63bf.32264d027089be4e at ms249-lin-003.rotterdam.bazuin.nl>
               
Content-Type: text/plain; charset="windows-1252"

Should be include imo. 



Shoud be in any Squid-3.2 and later.



And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth 



Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? 



Run squid ?v to check it. 



Greetz, 



Louis






Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens 
Nilesh Gavali
Verzonden: vrijdag 27 mei 2016 13:32
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] missing negotiate_kerberos_auth on my squid




Hello ; 
I have installed latest squid 3.5.19 on red hat Linux yesterday. That 
means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but 
facing issues. 
followed the steps provided on 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
But unable to find negotiate_kerberos_auth  on my Linux box at any 
location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and 
compile it to make authentication successful. 

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.        IT Services
                      Business Solutions
                      Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 
 Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/bbeb60e2/attachment.html
>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 21, Issue 101
******************************************** 


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160601/4b55aed1/attachment.html
>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 22, Issue 5
******************************************
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160601/78c8fb79/attachment.htm>

From dan at getbusi.com  Thu Jun  2 06:13:08 2016
From: dan at getbusi.com (Dan Charlesworth)
Date: Thu, 2 Jun 2016 16:13:08 +1000
Subject: [squid-users] How to analyse squid memory usage
In-Reply-To: <208c097a-5b42-da61-fc49-f4065b035833@treenet.co.nz>
References: <B60DFE6C-9BA8-42CA-9B57-A2460517A35F@getbusi.com>
 <085044c5-9a62-8b6f-47e6-cee4410dfac9@treenet.co.nz>
 <421A4120-10F7-4694-94AF-B66C3CDF1D3E@getbusi.com>
 <E0EA512C-DC76-4D74-B95F-2635BF58C523@getbusi.com>
 <5F7F29D5-F9E2-4FD2-9B9B-25DFE9E02E48@getbusi.com>
 <208c097a-5b42-da61-fc49-f4065b035833@treenet.co.nz>
Message-ID: <553AEA23-D6C9-446A-A903-698973563E40@getbusi.com>

No worries?thanks for following up on it!

That?s very interesting, about the concurrent requests, because the ?normal? report does around 80% more requests per day than the ?leaky? one ? a few hundred thousand vs a couple of million.

Does this CLOSE_WAIT sockets issue have a bug being tracked or anything like that? I?ve probably overlooked the discussion on the list.

> On 1 Jun 2016, at 10:26 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> Hi Dan,
> sorry RL getting in the way these weeks.
> 
> Two things stand out for me.
> 
> Its a bit odd that exteral ACL entries shodul be so high. But your
> "normal" report has more allocated than the "leaky" report. So thats
> just a sign that your external ACLs are not working very efficiently
> (results being fairly unique, so the lookup cache not being much use there).
> 
> In the "leaky" report there are 10K concurrent requests still active.
> Normal report shows only 1K requests. So up to 10x the state data
> storeage is needed by that proxy.
> 
> 
> I'm a little suspicious you might be seeing another symptom of the issue
> behind what others have been reporting as too many CLOSE_WAIT sockets
> staying open with Squid not doing anything for them.
> 
> Amos



From skupko.sk at gmail.com  Thu Jun  2 06:33:32 2016
From: skupko.sk at gmail.com (Peter Viskup)
Date: Thu, 2 Jun 2016 08:33:32 +0200
Subject: [squid-users] SSLBump non-HTTPs connections
Message-ID: <CAPa6PsFO4PrLcXocwW0zG4fZcwtB9dLpk24HAdi79XdRwaGNfQ@mail.gmail.com>

Hello all,
just wondering whether it is possible to perform SSLBump/SSLSplit for
non-HTTPs connections. At the moment we are interested in FTPs.
We are running Squid 3.4.2 version.

Configured the SSLBump and in that case not able to receive SSL Certificates

proxy:/etc/squid3# grep server-first squid.conf
ssl_bump server-first all
proxy:/etc/squid3# socat TCP-LISTEN:9999,reuseaddr,fork
PROXY:127.0.0.1:www.ftpsservicedomain.net:990,proxyport=8080
proxy:/etc/squid3# openssl s_client -connect localhost:9999 -showcerts
CONNECTED(00000003)
140535877478056:error:140790E5:SSL routines:SSL23_WRITE:ssl handshake
failure:s23_lib.c:177:
---
no peer certificate available
---
No client certificate CA names sent
---
SSL handshake has read 0 bytes and written 308 bytes
---
New, (NONE), Cipher is (NONE)
Secure Renegotiation IS NOT supported
Compression: NONE
Expansion: NONE
---

With ssl_bump disabled for the particular destination domain we are
able to receive SSL Certificates:

proxy:/etc/squid3# openssl s_client -connect localhost:9999 -showcerts
CONNECTED(00000003)
depth=1 C = US, ST = Washington, L = Redmond, O = Microsoft
Corporation, OU = Microsoft IT, CN = Microsoft IT SSL SHA2
verify error:num=20:unable to get local issuer certificate
verify return:0
---
Certificate chain
 0 s:/CN=www.ftpsservicedomain.net
   i:/C=US/ST=Washington/L=Redmond/O=Microsoft
Corporation/OU=Microsoft IT/CN=Microsoft IT SSL SHA2
-----BEGIN CERTIFICATE-----
MIIGQzCCBCugAwIBAgITWgAAuYCRJAQnIMZ1CwABAAC5gDANBgkqhkiG9w0BAQsF
....

In both cases the only log entry we see is the CONNECT request:
01/Jun/2016:10:16:23 +0200    681 127.0.0.1 TAG_NONE/200 0 CONNECT
www.ftpsservicedomain.net:990 - HIER_DIRECT/www.ftpsservicedomain.net
- [Host: www.ftpsservicedomain.net:990\r\n] [-]

Best regards,
-- 
Peter Viskup


From buechlerml at hdpnet.de  Thu Jun  2 09:01:40 2016
From: buechlerml at hdpnet.de (Paul Buechler)
Date: Thu, 2 Jun 2016 11:01:40 +0200
Subject: [squid-users] google drive up-/download size in squidlog
In-Reply-To: <009a89d8-79af-45e9-ee97-7baa5e24ceac@treenet.co.nz>
References: <57440D94.1080703@hdpnet.de>
 <009a89d8-79af-45e9-ee97-7baa5e24ceac@treenet.co.nz>
Message-ID: <efa39e35-91b4-979b-104c-d7d9cdf16131@hdpnet.de>

Hi,

@Yuri Voinov:

I've only tested it with the webclient.

@Amos Jeffries:

I've tested it with %st and the downloadsize is fine for me now, thanks.

Are there any plans to implement a format code to see the uploadsize?
It would be nice to have this feature.

best regards,

Paul

Am 24.05.2016 um 20:32 schrieb Amos Jeffries:
> On 24/05/2016 8:15 p.m., Paul Buechler wrote:
>> Hello there,
>>
>> i've got the problem that i can't see the size of uploades to google
>> drive in the access.log. Also the downloads aren't visible to me.
>> Is this a problem caused by HTTPS? I tried changing the logformat but
>> this didn't helped.
> All the normal logs are recording teh data transferred to client. NOt
> from client.
>
> You need to create a custom logformat of your own which uses the %st
> code instead of the %<st code.
> <http://www.squid-cache.org/Doc/config/logformat/>
>
>> best regards,
>> Paul
>>
>>
>> systeminformation:
>>
>> ubuntu 14.04.4 Server
>> squid: Version 3.3.8
>> squid logformat: logformat combined   %>a %[ui %[un [%tl] "%rm %ru
>> HTTP/%rv" %>Hs %<st "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
>> also tested:
>> logformat squid%ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un %Sh/%<a %mt
>> logformat common%>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st %Ss:%Sh
>> logformat referrer%ts.%03tu %>a %{Referer}>h %ru
>> logformat useragent%>a [%tl] "%{User-Agent}>h"
>>
> Please do not re-define the built in format names. Use a name of your
> own. Unexpected and probably not good things will happen.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160602/e4c5a6b3/attachment.htm>

From william.ivanski at gmail.com  Thu Jun  2 12:03:33 2016
From: william.ivanski at gmail.com (William Ivanski)
Date: Thu, 2 Jun 2016 09:03:33 -0300
Subject: [squid-users] Establishing secure conection problems (Chrome)
Message-ID: <CACaWZ9TD=1d_nrojzacdTaMZiopLy7Y1cU78KinzdXKb6g4JFQ@mail.gmail.com>

Good time of the day!

I've started experiencing some problems with Google Chrome after installing
Squid in my Network. It gets stuck into a loop of "Establishing secure
connection". Sometimes it succeeds loading the web pages, but usually it
cannot. It's really annoying and occurs just in Chrome. I've already tested
in Firefox and Microsoft Edge and it's alright.

Any suggestions?

Thanks and regards!


William Ivanski
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160602/893ff04f/attachment.htm>

From yvoinov at gmail.com  Thu Jun  2 12:09:44 2016
From: yvoinov at gmail.com (Yuri)
Date: Thu, 2 Jun 2016 18:09:44 +0600
Subject: [squid-users] Establishing secure conection problems (Chrome)
In-Reply-To: <CACaWZ9TD=1d_nrojzacdTaMZiopLy7Y1cU78KinzdXKb6g4JFQ@mail.gmail.com>
References: <CACaWZ9TD=1d_nrojzacdTaMZiopLy7Y1cU78KinzdXKb6g4JFQ@mail.gmail.com>
Message-ID: <2807b52a-88cc-fe2e-b5db-329f681e2e38@gmail.com>

Any useful info? Squid version, config, logs?

Thelepaty on vacation.


02.06.2016 18:03, William Ivanski ?????:
> Good time of the day!
>
> I've started experiencing some problems with Google Chrome after 
> installing Squid in my Network. It gets stuck into a loop of 
> "Establishing secure connection". Sometimes it succeeds loading the 
> web pages, but usually it cannot. It's really annoying and occurs just 
> in Chrome. I've already tested in Firefox and Microsoft Edge and it's 
> alright.
>
> Any suggestions?
>
> Thanks and regards!
>
>
> William Ivanski
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160602/0a2b9333/attachment.htm>

From Antony.Stone at squid.open.source.it  Thu Jun  2 12:11:40 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 2 Jun 2016 14:11:40 +0200
Subject: [squid-users] Establishing secure conection problems (Chrome)
In-Reply-To: <CACaWZ9TD=1d_nrojzacdTaMZiopLy7Y1cU78KinzdXKb6g4JFQ@mail.gmail.com>
References: <CACaWZ9TD=1d_nrojzacdTaMZiopLy7Y1cU78KinzdXKb6g4JFQ@mail.gmail.com>
Message-ID: <201606021411.40829.Antony.Stone@squid.open.source.it>

On Thursday 02 June 2016 at 14:03:33, William Ivanski wrote:

> I've started experiencing some problems with Google Chrome after installing
> Squid in my Network.

> Any suggestions?

Yes - tell us how you installed squid, which version you installed, which 
platform (O/S and version) you installed it on, show us your squid.conf file 
without comments or blank lines, and show us what shows up in the Squid 
access.log when you get the problems with Chrome.

Otherwise, as Yuri says, you'll need a telepath to help you.


Antony.

-- 
Most people have more than the average number of legs.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From sagarmalve91 at gmail.com  Thu Jun  2 12:16:45 2016
From: sagarmalve91 at gmail.com (Sagar Malve)
Date: Thu, 2 Jun 2016 17:46:45 +0530
Subject: [squid-users] Establishing secure conection problems (Chrome)
In-Reply-To: <2807b52a-88cc-fe2e-b5db-329f681e2e38@gmail.com>
References: <CACaWZ9TD=1d_nrojzacdTaMZiopLy7Y1cU78KinzdXKb6g4JFQ@mail.gmail.com>
 <2807b52a-88cc-fe2e-b5db-329f681e2e38@gmail.com>
Message-ID: <CAKQSiAVQLoHB+VjZ1U5kZtU2b5eXqSWuNbYkLJ_JfVX52FrOMQ@mail.gmail.com>

Try disabling QUIC Protocol in Chrome and check ... in Chrome Browser :
Type : chrome://flags/ ---> find QUIC and Disable it.

It will not accept the Squid SSL Certificate unless you disable this
Protocol ...

Let us know if it works ....

Regards
Sagar Malve

On Thu, Jun 2, 2016 at 5:39 PM, Yuri <yvoinov at gmail.com> wrote:

> Any useful info? Squid version, config, logs?
>
> Thelepaty on vacation.
>
> 02.06.2016 18:03, William Ivanski ?????:
>
> Good time of the day!
>
> I've started experiencing some problems with Google Chrome after
> installing Squid in my Network. It gets stuck into a loop of "Establishing
> secure connection". Sometimes it succeeds loading the web pages, but
> usually it cannot. It's really annoying and occurs just in Chrome. I've
> already tested in Firefox and Microsoft Edge and it's alright.
>
> Any suggestions?
>
> Thanks and regards!
>
>
> William Ivanski
>
>
> _______________________________________________
> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160602/7080b9ec/attachment.htm>

From yvoinov at gmail.com  Thu Jun  2 12:34:39 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 2 Jun 2016 18:34:39 +0600
Subject: [squid-users] Establishing secure conection problems (Chrome)
In-Reply-To: <CAKQSiAVQLoHB+VjZ1U5kZtU2b5eXqSWuNbYkLJ_JfVX52FrOMQ@mail.gmail.com>
References: <CACaWZ9TD=1d_nrojzacdTaMZiopLy7Y1cU78KinzdXKb6g4JFQ@mail.gmail.com>
 <2807b52a-88cc-fe2e-b5db-329f681e2e38@gmail.com>
 <CAKQSiAVQLoHB+VjZ1U5kZtU2b5eXqSWuNbYkLJ_JfVX52FrOMQ@mail.gmail.com>
Message-ID: <c1d2f252-0f76-c137-18f3-b3c89054b192@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
QUIC already unused by Google against HTTP/2. And better to do this (if
you need) at active network equipement level.

Otherwise you be forced to do this with hands on _every_ user Chrome by
legs.


02.06.2016 18:16, Sagar Malve ?????:
> Try disabling QUIC Protocol in Chrome and check ... in Chrome Browser : Type : chrome://flags/ --->
find QUIC and Disable it.
>
> It will not accept the Squid SSL Certificate unless you disable this
Protocol ...
>
> Let us know if it works ....
>
> Regards
> Sagar Malve
>
> On Thu, Jun 2, 2016 at 5:39 PM, Yuri <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>     Any useful info? Squid version, config, logs?
>
>     Thelepaty on vacation.
>
>
>     02.06.2016 18:03, William Ivanski ?????:
>>     Good time of the day!
>>
>>     I've started experiencing some problems with Google Chrome after
installing Squid in my Network. It gets stuck into a loop of
"Establishing secure connection". Sometimes it succeeds loading the web
pages, but usually it cannot. It's really annoying and occurs just in
Chrome. I've already tested in Firefox and Microsoft Edge and it's alright.
>>
>>     Any suggestions?
>>
>>     Thanks and regards!
>>
>>
>>     William Ivanski
>>
>>
>>     _______________________________________________
>>     squid-users mailing list
>>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>>     http://lists.squid-cache.org/listinfo/squid-users
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXUCffAAoJENNXIZxhPexGGJcIAI5KhV0CYzMgmTF8mXYbs2+z
UhuI2L1re4vnP/6xZW7cL+UNmIdNX1yZfDYYG476+dx8Tz18YQiMzalSD9U/hZdZ
6bIQFldbfMKdEz2WdrYJA03zBnLBZhqIo0SptdeCv4276S6W5wI5ruU95XVWV3yk
NLRHZMehHqOfyvkN1p9KrM9RvL3vhUtA2k40BPSDP6ABPXX+M0DrHK6Zx4OZIzCw
N/d6oenNrgAviFRzNwT50vbFHSpAciNJczvG7dQ58o6xWF4u8toI968sdKAGcFfu
8G1AMU7qWppduLA7U0r/uxT5XdvyuYDElecj31/q9rl/NKYk+iAJ786aEITMi0Q=
=zgTB
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160602/43bc2ee4/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160602/43bc2ee4/attachment.key>

From william.ivanski at gmail.com  Thu Jun  2 13:35:10 2016
From: william.ivanski at gmail.com (William Ivanski)
Date: Thu, 2 Jun 2016 10:35:10 -0300
Subject: [squid-users] Establishing secure conection problems (Chrome)
In-Reply-To: <CACaWZ9R99-NOswTuf6iOrc-bz-GeK9aemVeTGhmgaVCv+G4HWA@mail.gmail.com>
References: <CACaWZ9TD=1d_nrojzacdTaMZiopLy7Y1cU78KinzdXKb6g4JFQ@mail.gmail.com>
 <2807b52a-88cc-fe2e-b5db-329f681e2e38@gmail.com>
 <CAKQSiAVQLoHB+VjZ1U5kZtU2b5eXqSWuNbYkLJ_JfVX52FrOMQ@mail.gmail.com>
 <c1d2f252-0f76-c137-18f3-b3c89054b192@gmail.com>
 <CACaWZ9RLN4k0fBaHu+zjbt_EBYNn8bA-Xf-9MAwhAKGyGJjQkA@mail.gmail.com>
 <CACaWZ9R99-NOswTuf6iOrc-bz-GeK9aemVeTGhmgaVCv+G4HWA@mail.gmail.com>
Message-ID: <CACaWZ9RXL3_bf8LLnLnan_9yKGzvx8q9pnwN6wnHhxX=SS++kw@mail.gmail.com>

Thank you for your quick response.

First of all forgive me for the lack of information in the first
email. I've tried to disable QUIC a few minutes ago and the problem
persists. Follow the information requested:

-> Compilation:

I've installed squid using the following commands:

    cd /usr/src

    apt-get install squid3

    wget http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.15-20160330-r14015.tar.gz

    tar xvzf squid-3.5.15-20160330-r14015.tar.gz

    cd squid-3.5.15-20160330-r14015

    apt-get build-dep squid3 && apt-get install build-essential libssl-dev

    ./configure --enable-icap-client --enable-ssl --enable-ssl-crtd
--prefix=/usr --includedir=/usr/include --mandir=/usr/share/man
--infodir=/usr/share/info --sysconfdir=/etc --localstatedir=/var
--libexecdir=/lib/squid3 --srcdir=. --datadir=/usr/share/squid3
--sysconfdir=/etc/squid3 --mandir=/usr/share/man
--with-default-user=squid --with- cppunit-config-basedir=/usr
--with-logdir=/var/log/squid3 --with-pidfile=/var/run/squid3.pid
--with-openssl --disable-optimizations --disable-arch-native

    service squid3 stop

    make all && make install

    useradd squid && chown -R squid:squid /var/log/squid3

    mv /usr/sbin/squid3 /usr/sbin/squid3.old && mv/usr/sbin/squid
/usr/sbin/squid3

    /lib/squid3/ssl_crtd -c -s /var/lib/ssl_db -M 4 MB

    chown -R squid:squid /var/lib/ssl_db

    service squid3 restart && service squid3 stop && chmod 777
/var/spool/squid3 && squid3 -z && service squid3 restart

OBS: We're not using ssl_crtd/ssl_db anymore. Our previous squid conf
was using intercept, but the actual one isn't configured as
transparent proxy.

-> Platform of the gateway:

Distributor ID: Debian

Description:    Debian GNU/Linux 8.4 (jessie)

Release:        8.4

Codename:       jessie

-> Squid:

Squid Cache: Version 3.5.15-20160324-r14011

Service Name: squid

configure options:  '--enable-icap-client' '--enable-ssl'
'--enable-ssl-crtd' '--prefix=/usr' '--includedir=/usr/include'
'--infodir=/usr/share/info' '--sysconfdir=/etc' '--localstatedir=/var'
'--libexecdir=/lib/squid3' '--srcdir=.' '--datadir=/usr/share/squid3'
'--sysconfdir=/etc/squid3' '--mandir=/usr/share/man'
'--with-default-user=squid' '--with-cppunit-config-basedir=/usr'
'--with-logdir=/var/log/squid3' '--with-pidfile=/var/run/squid3.pid'
'--with-openssl' '--disable-arch-native'

-> Squid.conf:

http_port 3128

visible_hostname gateway

cache_mgr william at planningservice.com.br

error_directory /usr/share/squid3/errors/Portuguese

access_log /var/log/squid3/access.log

hierarchy_stoplist cgi-bin ?

cache_mem 2048 MB

maximum_object_size_in_memory 100 MB

cache_dir ufs /var/spool/squid3 307200 16 256

maximum_object_size 4096 MB

minimum_object_size 0 MB

cache_swap_low 90

cache_swap_high 95

refresh_pattern ^ftp:             360   20%     2280

refresh_pattern -i (/cgi-bin/|\?) 0     0%      0

refresh_pattern .                 0     20%     2280

cache_log /var/log/squid3/cache.log

acl localhost src 127.0.0.1/32

acl localnet src 192.168.0.0/24

acl localnetd dst 192.168.0.0/24

acl manager proto cache_object

http_access allow manager localhost

http_access deny manager

acl purge method PURGE

http_access allow purge localhost

http_access deny purge

acl Safe_ports port 21

acl Safe_ports port 70

acl Safe_ports port 80

acl Safe_ports port 210

acl Safe_ports port 280

acl Safe_ports port 443

acl Safe_ports port 488

acl Safe_ports port 563

acl Safe_ports port 591

acl Safe_ports port 631

acl Safe_ports port 777

acl Safe_ports port 873

acl Safe_ports port 901

acl Safe_ports port 1025-65535

http_access deny !Safe_ports

acl SSL_ports port 443

acl SSL_ports port 563

acl SSL_ports port 873

acl connect method CONNECT

http_access deny connect !SSL_ports

acl FTP proto FTP

always_direct allow FTP

acl reqliberacaotmp src "/etc/firewall/ips_liberados_tmp.txt"

acl reqliberacaofixo src "/etc/firewall/ips_liberados_fixo.txt"

http_access allow reqliberacaotmp reqliberacaofixo

acl sitesliberadosfixo dstdom_regex -i "/etc/firewall/sites_liberados_fixo.txt"

acl sitesliberadostmp dstdom_regex -i "/etc/firewall/sites_liberados_tmp.txt"

acl almoco time MTWHF 11:50-13:30

acl manha time MTWHF 00:01-08:30

acl noite time MTWHF 18:00-23:59

http_access allow localhost sitesliberadosfixo

http_access allow localhost sitesliberadostmp

http_access allow localnet sitesliberadosfixo

http_access allow localnet sitesliberadostmp

http_access allow localhost almoco

http_access allow localnet almoco

http_access allow localhost manha

http_access allow localnet manha

http_access allow localhost noite

http_access allow localnet noite

http_access deny !sitesliberadosfixo !sitesliberadostmp
!reqliberacaotmp !reqliberacaofixo

http_access allow localhost

http_access allow localnet

http_access allow localnetd

http_access deny !localhost !localnet !localnetd

http_access deny all



I'll send access.log in next e-mail, otherwise message body will be too big.



William Ivanski
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160602/22107335/attachment.htm>

From william.ivanski at gmail.com  Thu Jun  2 13:36:03 2016
From: william.ivanski at gmail.com (William Ivanski)
Date: Thu, 2 Jun 2016 10:36:03 -0300
Subject: [squid-users] Establishing secure conection problems (Chrome)
In-Reply-To: <CACaWZ9RXL3_bf8LLnLnan_9yKGzvx8q9pnwN6wnHhxX=SS++kw@mail.gmail.com>
References: <CACaWZ9TD=1d_nrojzacdTaMZiopLy7Y1cU78KinzdXKb6g4JFQ@mail.gmail.com>
 <2807b52a-88cc-fe2e-b5db-329f681e2e38@gmail.com>
 <CAKQSiAVQLoHB+VjZ1U5kZtU2b5eXqSWuNbYkLJ_JfVX52FrOMQ@mail.gmail.com>
 <c1d2f252-0f76-c137-18f3-b3c89054b192@gmail.com>
 <CACaWZ9RLN4k0fBaHu+zjbt_EBYNn8bA-Xf-9MAwhAKGyGJjQkA@mail.gmail.com>
 <CACaWZ9R99-NOswTuf6iOrc-bz-GeK9aemVeTGhmgaVCv+G4HWA@mail.gmail.com>
 <CACaWZ9RXL3_bf8LLnLnan_9yKGzvx8q9pnwN6wnHhxX=SS++kw@mail.gmail.com>
Message-ID: <CACaWZ9QRiPMqUKg3MSFoi9gCKyy0ZS9gZgr5_E-DXn1CMRB15w@mail.gmail.com>

-> Access.log (the host 192.168.0.52 belongs to acl reqliberacaofixo):

1464870540.039    495 192.168.0.52 TCP_MISS/301 675 GET
http://www.hotmail.com/ - HIER_DIRECT/65.55.65.188 text/html

1464870550.793  10206 192.168.0.52 TCP_MISS_ABORTED/000 0 POST
http://s2.symcb.com/ - HIER_DIRECT/2600:1419:8:18f::201a -

1464870554.259   2241 192.168.0.52 TCP_MISS_ABORTED/000 0 POST
http://sr.symcd.com/ - HIER_DIRECT/2600:1419:8:18f::201a -

1464870626.286 121662 192.168.0.52 TCP_MISS/200 2192 GET
http://s2.symcb.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBS56bKHAoUD%2BOyl%2B0LhPg9JxyQm4gQUf9Nlp8Ld7LvwMAnzQzn6Aq8zMTMCEH7hSm9v7%2FLTfz%2BtZU062rQ%3D
- HIER_DIRECT/23.4.43.27 application/ocsp-response

1464870746.296 119912 192.168.0.52 TCP_MISS/200 2192 GET
http://ocsp.verisign.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBS56bKHAoUD%2BOyl%2B0LhPg9JxyQm4gQUf9Nlp8Ld7LvwMAnzQzn6Aq8zMTMCEFIA5aolVvwahu2WydRLM8c%3D
- HIER_DIRECT/23.4.43.27 application/ocsp-response

1464870866.307 120000 192.168.0.52 TCP_MISS/200 2155 GET
http://sf.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBTSqZMG5M8TA9rdzkbCnNwuMAd5VgQUz5mp6nsm9EvJjo%2FX8AUm7%2BPSp50CEExA26X5iPrlelfWRXSV%2BYs%3D
- HIER_DIRECT/23.4.43.27 application/ocsp-response

1464870866.467    149 192.168.0.52 TCP_MISS/304 331 GET
http://www.download.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab
- HIER_DIRECT/2804:a8:c800:301::bd56:7a18 application/octet-stream

1464870986.300 119824 192.168.0.52 TCP_MISS/200 654 GET
http://crl.geotrust.com/crls/secureca.crl - HIER_DIRECT/23.4.37.163
application/pkix-crl

1464871457.106    312 192.168.0.52 TCP_MISS/301 419 GET
http://support.microsoft.com/ - HIER_DIRECT/172.224.183.89 -

1464871477.134     45 192.168.0.52 TCP_MISS/301 340 GET
http://www.itau.com.br/ - HIER_DIRECT/23.10.60.73 -

1464871487.149     41 192.168.0.52 TCP_MISS/204 184 GET
http://www.gstatic.com/generate_204 -
HIER_DIRECT/2800:3f0:4001:800::2003 -

1464871490.334    338 192.168.0.52 TCP_MISS/302 685 GET
http://c1.microsoft.com/c.gif? - HIER_DIRECT/131.253.40.50 -

1464871490.841    501 192.168.0.52 TCP_MISS/302 935 GET
http://c.bing.com/c.gif? - HIER_DIRECT/65.52.108.11 -

1464871491.004    159 192.168.0.52 TCP_MISS/200 885 GET
http://c1.microsoft.com/c.gif? - HIER_DIRECT/131.253.40.50 image/gif

1464871507.401  60167 192.168.0.52 TCP_MISS_ABORTED/000 0 GET
http://sr.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBR0JBRnBp%2F14Jg%2FXj4aa6BlKlQVdQQUAVmr5906C1mmZGPWzyAHV9WR52oCEGU3b%2BNLNLmDFl%2F0STiGxMc%3D
- HIER_DIRECT/2600:1419:8:191::201a -

1464871517.401  59969 192.168.0.52 TCP_MISS_ABORTED/000 0 GET
http://sr.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBR0JBRnBp%2F14Jg%2FXj4aa6BlKlQVdQQUAVmr5906C1mmZGPWzyAHV9WR52oCEG%2F6tqKxfdmg4KPDzqvBuK8%3D
- HIER_DIRECT/2600:1419:8:191::201a -

1464871522.402  60173 192.168.0.52 TCP_MISS_ABORTED/000 0 GET
http://sr.symcb.com/sr.crl - HIER_DIRECT/2600:1419:8:181::1abd -

1464871532.402  59968 192.168.0.52 TCP_MISS_ABORTED/000 0 GET
http://sr.symcb.com/sr.crl - HIER_DIRECT/2600:1419:8:181::1abd -

1464871676.152    839 192.168.0.52 TCP_MISS/301 675 GET
http://www.hotmail.com/ - HIER_DIRECT/65.55.65.172 text/html

1464871681.856   3654 192.168.0.52 TCP_MISS_ABORTED/000 0 GET
http://sr.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBR0JBRnBp%2F14Jg%2FXj4aa6BlKlQVdQQUAVmr5906C1mmZGPWzyAHV9WR52oCEGU3b%2BNLNLmDFl%2F0STiGxMc%3D
- HIER_DIRECT/2600:1419:8:191::201a -

1464871690.823     62 192.168.0.52 TCP_MISS/200 889 POST
http://ocsp.digicert.com/ - HIER_DIRECT/192.16.58.8
application/ocsp-response

1464871690.880     52 192.168.0.52 TCP_MISS/200 889 POST
http://ocsp.digicert.com/ - HIER_DIRECT/192.16.58.8
application/ocsp-response

1464871694.282    312 192.168.0.52 TCP_MISS/302 948 GET
http://www.google.com.br/ - HIER_DIRECT/2607:f8b0:4002:c0c::5e
text/html

1464871694.785    180 192.168.0.52 TCP_MISS/200 847 POST
http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e
application/ocsp-response

1464871704.519    186 192.168.0.52 TCP_MISS/200 847 POST
http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e
application/ocsp-response

1464871705.113    173 192.168.0.52 TCP_MISS/200 847 POST
http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e
application/ocsp-response

1464871705.485    183 192.168.0.52 TCP_MISS/200 847 POST
http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e
application/ocsp-response

1464871705.748    179 192.168.0.52 TCP_MISS/200 847 POST
http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e
application/ocsp-response

1464871707.725    177 192.168.0.52 TCP_MISS/200 847 POST
http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e
application/ocsp-response

1464871708.014    188 192.168.0.52 TCP_MISS/200 847 POST
http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e
application/ocsp-response

1464871708.768    186 192.168.0.52 TCP_MISS/200 847 POST
http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e
application/ocsp-response

1464871744.573     50 192.168.0.52 TCP_MISS/200 889 POST
http://ocsp.digicert.com/ - HIER_DIRECT/192.16.58.8
application/ocsp-response

1464871746.272     39 192.168.0.52 TCP_MISS/200 1981 POST
http://vassg142.ocsp.omniroot.com/ - HIER_DIRECT/189.86.122.11
application/ocsp-response

1464871749.966   1145 192.168.0.52 TCP_MISS/200 341701 GET
http://ciscobinary.openh264.org/openh264-win32-2706e36bf0a8b7c539c803ed877148c005ffca59.zip
- HIER_DIRECT/2600:1403:1::48f6:4070 application/zip

1464871763.636    145 192.168.0.52 TCP_MISS/302 945 HEAD
http://redirector.gvt1.com/edgedl/release2/4q5bp49e5hqoxn6kx4mnsg1knc0d6zmfyb1zzrw2utmcns77n9nuq1wj8dutbcg1fvvzulfi9uks07x9zue8525igkbwdt9k1k5/51.0.2704.79_chrome_installer_win64.exe
- HIER_DIRECT/2800:3f0:4001:800::200e text/html

1464871763.698     60 192.168.0.52 TCP_MISS/200 429 HEAD
http://r2---sn-xhcg5uxa-jfcl.gvt1.com/edgedl/release2/4q5bp49e5hqoxn6kx4mnsg1knc0d6zmfyb1zzrw2utmcns77n9nuq1wj8dutbcg1fvvzulfi9uks07x9zue8525igkbwdt9k1k5/51.0.2704.79_chrome_installer_win64.exe?
- HIER_DIRECT/2804:a8:c800:200::d application/octet-stream

1464871768.281   4550 192.168.0.52 TCP_MISS/200 52687693 GET
http://r2---sn-xhcg5uxa-jfcl.gvt1.com/edgedl/release2/4q5bp49e5hqoxn6kx4mnsg1knc0d6zmfyb1zzrw2utmcns77n9nuq1wj8dutbcg1fvvzulfi9uks07x9zue8525igkbwdt9k1k5/51.0.2704.79_chrome_installer_win64.exe?
- HIER_DIRECT/2804:a8:c800:200::d application/octet-stream

1464871797.113     82 192.168.0.52 TCP_MISS/302 1663 GET
http://redirector.gvt1.com/crx/blobs/QgAAAC6zw0qH2DJtnXe8Z7rUJP2Rb7215C34RRoAOYw9FMifYIKbQ8NQ4eJck316jhcVHOPhJi112xRZ24oxSFePD-fslt2YdyTrBxWUtp4L7gbUAMZSmuXeGbE9p5N8uch3Sy5nHol_Tjr_7w/extension_1_0_0_0.crx
- HIER_DIRECT/2800:3f0:4001:800::200e text/html

1464871797.249     92 192.168.0.52 TCP_MISS/200 185264 GET
http://r1---sn-xhcg5uxa-jfce.gvt1.com/crx/blobs/QgAAAC6zw0qH2DJtnXe8Z7rUJP2Rb7215C34RRoAOYw9FMifYIKbQ8NQ4eJck316jhcVHOPhJi112xRZ24oxSFePD-fslt2YdyTrBxWUtp4L7gbUAMZSmuXeGbE9p5N8uch3Sy5nHol_Tjr_7w/extension_1_0_0_0.crx?
- HIER_DIRECT/2804:a8:c800:100::c application/x-chrome-extension

1464871799.230    108 192.168.0.52 TCP_MISS/302 662 GET
http://tools.google.com/chrome/intl/pt-BR/welcome.html -
HIER_DIRECT/2800:3f0:4004:805::200e text/html

1464871861.524    335 192.168.0.52 TCP_MISS/301 675 GET
http://www.hotmail.com/ - HIER_DIRECT/65.55.65.172 text/html

1464871872.190    299 192.168.0.52 TCP_MISS/301 419 GET
http://support.microsoft.com/ - HIER_DIRECT/172.224.183.89 -

1464871893.795   1211 192.168.0.52 TCP_MISS/301 344 GET
http://itau.com.br/ - HIER_DIRECT/23.0.95.170 -

1464871902.240     46 192.168.0.52 TCP_MISS/204 184 GET
http://www.gstatic.com/generate_204 -
HIER_DIRECT/2800:3f0:4001:803::2003 -

1464871906.833    334 192.168.0.52 TCP_MISS/302 685 GET
http://c1.microsoft.com/c.gif? - HIER_DIRECT/131.253.40.50 -

1464871907.183    348


William Ivanski
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160602/25996c5f/attachment.htm>

From yvoinov at gmail.com  Thu Jun  2 14:27:44 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 2 Jun 2016 20:27:44 +0600
Subject: [squid-users] Establishing secure conection problems (Chrome)
In-Reply-To: <CACaWZ9QRiPMqUKg3MSFoi9gCKyy0ZS9gZgr5_E-DXn1CMRB15w@mail.gmail.com>
References: <CACaWZ9TD=1d_nrojzacdTaMZiopLy7Y1cU78KinzdXKb6g4JFQ@mail.gmail.com>
 <2807b52a-88cc-fe2e-b5db-329f681e2e38@gmail.com>
 <CAKQSiAVQLoHB+VjZ1U5kZtU2b5eXqSWuNbYkLJ_JfVX52FrOMQ@mail.gmail.com>
 <c1d2f252-0f76-c137-18f3-b3c89054b192@gmail.com>
 <CACaWZ9RLN4k0fBaHu+zjbt_EBYNn8bA-Xf-9MAwhAKGyGJjQkA@mail.gmail.com>
 <CACaWZ9R99-NOswTuf6iOrc-bz-GeK9aemVeTGhmgaVCv+G4HWA@mail.gmail.com>
 <CACaWZ9RXL3_bf8LLnLnan_9yKGzvx8q9pnwN6wnHhxX=SS++kw@mail.gmail.com>
 <CACaWZ9QRiPMqUKg3MSFoi9gCKyy0ZS9gZgr5_E-DXn1CMRB15w@mail.gmail.com>
Message-ID: <aecde531-998f-0a05-7d45-041ae0a6b625@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
cache.log require too


02.06.2016 19:36, William Ivanski ?????:
> -> Access.log (the host 192.168.0.52 belongs to acl reqliberacaofixo):
> 1464870540.039    495 192.168.0.52 TCP_MISS/301 675 GET
http://www.hotmail.com/ - HIER_DIRECT/65.55.65.188 <http://65.55.65.188>
text/html
> 1464870550.793  10206 192.168.0.52 TCP_MISS_ABORTED/000 0 POST
http://s2.symcb.com/ - HIER_DIRECT/2600:1419:8:18f::201a -
> 1464870554.259   2241 192.168.0.52 TCP_MISS_ABORTED/000 0 POST
http://sr.symcd.com/ - HIER_DIRECT/2600:1419:8:18f::201a -
> 1464870626.286 121662 192.168.0.52 TCP_MISS/200 2192 GET
http://s2.symcb.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBS56bKHAoUD%2BOyl%2B0LhPg9JxyQm4gQUf9Nlp8Ld7LvwMAnzQzn6Aq8zMTMCEH7hSm9v7%2FLTfz%2BtZU062rQ%3D
- HIER_DIRECT/23.4.43.27 <http://23.4.43.27> application/ocsp-response
> 1464870746.296 119912 192.168.0.52 TCP_MISS/200 2192 GET
http://ocsp.verisign.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBS56bKHAoUD%2BOyl%2B0LhPg9JxyQm4gQUf9Nlp8Ld7LvwMAnzQzn6Aq8zMTMCEFIA5aolVvwahu2WydRLM8c%3D
- HIER_DIRECT/23.4.43.27 <http://23.4.43.27> application/ocsp-response
> 1464870866.307 120000 192.168.0.52 TCP_MISS/200 2155 GET
http://sf.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBTSqZMG5M8TA9rdzkbCnNwuMAd5VgQUz5mp6nsm9EvJjo%2FX8AUm7%2BPSp50CEExA26X5iPrlelfWRXSV%2BYs%3D
- HIER_DIRECT/23.4.43.27 <http://23.4.43.27> application/ocsp-response
> 1464870866.467    149 192.168.0.52 TCP_MISS/304 331 GET
http://www.download.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab
- HIER_DIRECT/2804:a8:c800:301::bd56:7a18 application/octet-stream
> 1464870986.300 119824 192.168.0.52 TCP_MISS/200 654 GET
http://crl.geotrust.com/crls/secureca.crl - HIER_DIRECT/23.4.37.163
<http://23.4.37.163> application/pkix-crl
> 1464871457.106    312 192.168.0.52 TCP_MISS/301 419 GET
http://support.microsoft.com/ - HIER_DIRECT/172.224.183.89
<http://172.224.183.89> -
> 1464871477.134     45 192.168.0.52 TCP_MISS/301 340 GET
http://www.itau.com.br/ - HIER_DIRECT/23.10.60.73 <http://23.10.60.73> -
> 1464871487.149     41 192.168.0.52 TCP_MISS/204 184 GET
http://www.gstatic.com/generate_204 - HIER_DIRECT/2800:3f0:4001:800::2003 -
> 1464871490.334    338 192.168.0.52 TCP_MISS/302 685 GET
http://c1.microsoft.com/c.gif? - HIER_DIRECT/131.253.40.50
<http://131.253.40.50> -
> 1464871490.841    501 192.168.0.52 TCP_MISS/302 935 GET
http://c.bing.com/c.gif? - HIER_DIRECT/65.52.108.11 <http://65.52.108.11> -
> 1464871491.004    159 192.168.0.52 TCP_MISS/200 885 GET
http://c1.microsoft.com/c.gif? - HIER_DIRECT/131.253.40.50
<http://131.253.40.50> image/gif
> 1464871507.401  60167 192.168.0.52 TCP_MISS_ABORTED/000 0 GET
http://sr.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBR0JBRnBp%2F14Jg%2FXj4aa6BlKlQVdQQUAVmr5906C1mmZGPWzyAHV9WR52oCEGU3b%2BNLNLmDFl%2F0STiGxMc%3D
- HIER_DIRECT/2600:1419:8:191::201a -
> 1464871517.401  59969 192.168.0.52 TCP_MISS_ABORTED/000 0 GET
http://sr.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBR0JBRnBp%2F14Jg%2FXj4aa6BlKlQVdQQUAVmr5906C1mmZGPWzyAHV9WR52oCEG%2F6tqKxfdmg4KPDzqvBuK8%3D
- HIER_DIRECT/2600:1419:8:191::201a -
> 1464871522.402  60173 192.168.0.52 TCP_MISS_ABORTED/000 0 GET
http://sr.symcb.com/sr.crl - HIER_DIRECT/2600:1419:8:181::1abd -
> 1464871532.402  59968 192.168.0.52 TCP_MISS_ABORTED/000 0 GET
http://sr.symcb.com/sr.crl - HIER_DIRECT/2600:1419:8:181::1abd -
> 1464871676.152    839 192.168.0.52 TCP_MISS/301 675 GET
http://www.hotmail.com/ - HIER_DIRECT/65.55.65.172 <http://65.55.65.172>
text/html
> 1464871681.856   3654 192.168.0.52 TCP_MISS_ABORTED/000 0 GET
http://sr.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBR0JBRnBp%2F14Jg%2FXj4aa6BlKlQVdQQUAVmr5906C1mmZGPWzyAHV9WR52oCEGU3b%2BNLNLmDFl%2F0STiGxMc%3D
- HIER_DIRECT/2600:1419:8:191::201a -
> 1464871690.823     62 192.168.0.52 TCP_MISS/200 889 POST
http://ocsp.digicert.com/ - HIER_DIRECT/192.16.58.8 <http://192.16.58.8>
application/ocsp-response
> 1464871690.880     52 192.168.0.52 TCP_MISS/200 889 POST
http://ocsp.digicert.com/ - HIER_DIRECT/192.16.58.8 <http://192.16.58.8>
application/ocsp-response
> 1464871694.282    312 192.168.0.52 TCP_MISS/302 948 GET
http://www.google.com.br/ - HIER_DIRECT/2607:f8b0:4002:c0c::5e text/html
> 1464871694.785    180 192.168.0.52 TCP_MISS/200 847 POST
http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e
application/ocsp-response
> 1464871704.519    186 192.168.0.52 TCP_MISS/200 847 POST
http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e
application/ocsp-response
> 1464871705.113    173 192.168.0.52 TCP_MISS/200 847 POST
http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e
application/ocsp-response
> 1464871705.485    183 192.168.0.52 TCP_MISS/200 847 POST
http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e
application/ocsp-response
> 1464871705.748    179 192.168.0.52 TCP_MISS/200 847 POST
http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e
application/ocsp-response
> 1464871707.725    177 192.168.0.52 TCP_MISS/200 847 POST
http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e
application/ocsp-response
> 1464871708.014    188 192.168.0.52 TCP_MISS/200 847 POST
http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e
application/ocsp-response
> 1464871708.768    186 192.168.0.52 TCP_MISS/200 847 POST
http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e
application/ocsp-response
> 1464871744.573     50 192.168.0.52 TCP_MISS/200 889 POST
http://ocsp.digicert.com/ - HIER_DIRECT/192.16.58.8 <http://192.16.58.8>
application/ocsp-response
> 1464871746.272     39 192.168.0.52 TCP_MISS/200 1981 POST
http://vassg142.ocsp.omniroot.com/ - HIER_DIRECT/189.86.122.11
<http://189.86.122.11> application/ocsp-response
> 1464871749.966   1145 192.168.0.52 TCP_MISS/200 341701 GET
http://ciscobinary.openh264.org/openh264-win32-2706e36bf0a8b7c539c803ed877148c005ffca59.zip
- HIER_DIRECT/2600:1403:1::48f6:4070 application/zip
> 1464871763.636    145 192.168.0.52 TCP_MISS/302 945 HEAD
http://redirector.gvt1.com/edgedl/release2/4q5bp49e5hqoxn6kx4mnsg1knc0d6zmfyb1zzrw2utmcns77n9nuq1wj8dutbcg1fvvzulfi9uks07x9zue8525igkbwdt9k1k5/51.0.2704.79_chrome_installer_win64.exe
- HIER_DIRECT/2800:3f0:4001:800::200e text/html
> 1464871763.698     60 192.168.0.52 TCP_MISS/200 429 HEAD
http://r2---sn-xhcg5uxa-jfcl.gvt1.com/edgedl/release2/4q5bp49e5hqoxn6kx4mnsg1knc0d6zmfyb1zzrw2utmcns77n9nuq1wj8dutbcg1fvvzulfi9uks07x9zue8525igkbwdt9k1k5/51.0.2704.79_chrome_installer_win64.exe?
- HIER_DIRECT/2804:a8:c800:200::d application/octet-stream
> 1464871768.281   4550 192.168.0.52 TCP_MISS/200 52687693 GET
http://r2---sn-xhcg5uxa-jfcl.gvt1.com/edgedl/release2/4q5bp49e5hqoxn6kx4mnsg1knc0d6zmfyb1zzrw2utmcns77n9nuq1wj8dutbcg1fvvzulfi9uks07x9zue8525igkbwdt9k1k5/51.0.2704.79_chrome_installer_win64.exe?
- HIER_DIRECT/2804:a8:c800:200::d application/octet-stream
> 1464871797.113     82 192.168.0.52 TCP_MISS/302 1663 GET
http://redirector.gvt1.com/crx/blobs/QgAAAC6zw0qH2DJtnXe8Z7rUJP2Rb7215C34RRoAOYw9FMifYIKbQ8NQ4eJck316jhcVHOPhJi112xRZ24oxSFePD-fslt2YdyTrBxWUtp4L7gbUAMZSmuXeGbE9p5N8uch3Sy5nHol_Tjr_7w/extension_1_0_0_0.crx
- HIER_DIRECT/2800:3f0:4001:800::200e text/html
> 1464871797.249     92 192.168.0.52 TCP_MISS/200 185264 GET
http://r1---sn-xhcg5uxa-jfce.gvt1.com/crx/blobs/QgAAAC6zw0qH2DJtnXe8Z7rUJP2Rb7215C34RRoAOYw9FMifYIKbQ8NQ4eJck316jhcVHOPhJi112xRZ24oxSFePD-fslt2YdyTrBxWUtp4L7gbUAMZSmuXeGbE9p5N8uch3Sy5nHol_Tjr_7w/extension_1_0_0_0.crx?
- HIER_DIRECT/2804:a8:c800:100::c application/x-chrome-extension
> 1464871799.230    108 192.168.0.52 TCP_MISS/302 662 GET
http://tools.google.com/chrome/intl/pt-BR/welcome.html -
HIER_DIRECT/2800:3f0:4004:805::200e text/html
> 1464871861.524    335 192.168.0.52 TCP_MISS/301 675 GET
http://www.hotmail.com/ - HIER_DIRECT/65.55.65.172 <http://65.55.65.172>
text/html
> 1464871872.190    299 192.168.0.52 TCP_MISS/301 419 GET
http://support.microsoft.com/ - HIER_DIRECT/172.224.183.89
<http://172.224.183.89> -
> 1464871893.795   1211 192.168.0.52 TCP_MISS/301 344 GET
http://itau.com.br/ - HIER_DIRECT/23.0.95.170 <http://23.0.95.170> -
> 1464871902.240     46 192.168.0.52 TCP_MISS/204 184 GET
http://www.gstatic.com/generate_204 - HIER_DIRECT/2800:3f0:4001:803::2003 -
> 1464871906.833    334 192.168.0.52 TCP_MISS/302 685 GET
http://c1.microsoft.com/c.gif? - HIER_DIRECT/131.253.40.50
<http://131.253.40.50> -
> 1464871907.183    348
>
> William Ivanski
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXUEJgAAoJENNXIZxhPexGBN0IAMggOLzVqjI3AUj7WbZEQz3X
EAehFlpcsJaW0c5Miri5trAgzu1Em+614NqomJJDLQvicT/jU1JJFlgqDRaExHHJ
T5erFDzUB3SuH6ntvWpkOlDP4/lEJUp/+ZEIPNMluO0lmgdP4w25h0sPOm1XYTTd
lrqg6NwaQJPv91Dm5pdlfJQhy6YcBz9P0+8WiiQSwep8I1qIlbbQua4QYJOLrpIe
zaECAvj3vFR5cI4WkxbEXHD9HU64gQgfhjZne/c+jAZdtDDDamJrUKlN5PzMWKWf
csMSTmgqfPYsb6KKBomLCRPf2pseWeVXR1gUj+94veLPYKHg7x8HA8R4T4pUYOA=
=kyci
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160602/bdbabd43/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160602/bdbabd43/attachment.key>

From amadaan at ncsu.edu  Thu Jun  2 14:45:10 2016
From: amadaan at ncsu.edu (Aashima Madaan)
Date: Thu, 2 Jun 2016 10:45:10 -0400
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
Message-ID: <AC367CC1-146C-4FD7-B6F3-510FB1E74AE4@ncsu.edu>

Hi Amos,

After applying the patch I dont find any issues in make and make install, but running the file /usr/sbin/squid gives segmentation fault.

Thanks

From Antony.Stone at squid.open.source.it  Thu Jun  2 14:45:38 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 2 Jun 2016 16:45:38 +0200
Subject: [squid-users] Establishing secure conection problems (Chrome)
In-Reply-To: <CACaWZ9RXL3_bf8LLnLnan_9yKGzvx8q9pnwN6wnHhxX=SS++kw@mail.gmail.com>
References: <CACaWZ9TD=1d_nrojzacdTaMZiopLy7Y1cU78KinzdXKb6g4JFQ@mail.gmail.com>
 <CACaWZ9R99-NOswTuf6iOrc-bz-GeK9aemVeTGhmgaVCv+G4HWA@mail.gmail.com>
 <CACaWZ9RXL3_bf8LLnLnan_9yKGzvx8q9pnwN6wnHhxX=SS++kw@mail.gmail.com>
Message-ID: <201606021645.38753.Antony.Stone@squid.open.source.it>

On Thursday 02 June 2016 at 15:35:10, William Ivanski wrote:

> Thank you for your quick response.
> 
> First of all forgive me for the lack of information in the first
> email. I've tried to disable QUIC a few minutes ago and the problem
> persists. Follow the information requested:
> 
> -> Compilation:
> 
> I've installed squid using the following commands:
> 
>     cd /usr/src
> 
>     apt-get install squid3

So, that will install a working copy of Squid, and then...

>     wget
> http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.15-20160330-r14015.ta
> r.gz
> 
>     tar xvzf squid-3.5.15-20160330-r14015.tar.gz
> 
>     cd squid-3.5.15-20160330-r14015

...you download the latest source version and try to build it yourself...

>     apt-get build-dep squid3 && apt-get install build-essential libssl-dev

...unfortunately using the Debian commands to build from a source package, 
which you did not download (the Debian source package is not the same as the 
Squid tarball).

You then proceed to do the standard ./configure && make && make install for 
installation from a tarball.

I wouldn't like to guess what sort of state any installed Squid is in after 
doing this bizarre combination.


I recommend installing the Debian binary package, *or* install the Debian 
source package and build from that, *or* download the source tarball and build 
that.  Do not combine these.


Regards,


Antony.

-- 
I lay awake all night wondering where the sun went, and then it dawned on me.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From eliezer at ngtech.co.il  Thu Jun  2 14:49:17 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 2 Jun 2016 17:49:17 +0300
Subject: [squid-users] Establishing secure conection problems (Chrome)
In-Reply-To: <CACaWZ9QRiPMqUKg3MSFoi9gCKyy0ZS9gZgr5_E-DXn1CMRB15w@mail.gmail.com>
References: <CACaWZ9TD=1d_nrojzacdTaMZiopLy7Y1cU78KinzdXKb6g4JFQ@mail.gmail.com>
 <2807b52a-88cc-fe2e-b5db-329f681e2e38@gmail.com>
 <CAKQSiAVQLoHB+VjZ1U5kZtU2b5eXqSWuNbYkLJ_JfVX52FrOMQ@mail.gmail.com>
 <c1d2f252-0f76-c137-18f3-b3c89054b192@gmail.com>
 <CACaWZ9RLN4k0fBaHu+zjbt_EBYNn8bA-Xf-9MAwhAKGyGJjQkA@mail.gmail.com>
 <CACaWZ9R99-NOswTuf6iOrc-bz-GeK9aemVeTGhmgaVCv+G4HWA@mail.gmail.com>
 <CACaWZ9RXL3_bf8LLnLnan_9yKGzvx8q9pnwN6wnHhxX=SS++kw@mail.gmail.com>
 <CACaWZ9QRiPMqUKg3MSFoi9gCKyy0ZS9gZgr5_E-DXn1CMRB15w@mail.gmail.com>
Message-ID: <07ca01d1bcdd$f05dd2d0$d1197870$@ngtech.co.il>

Hey William,

 

It's not clear what connection from the logs you are talking about since I do not see any logs about a CONNECT request.

It might be because a CONNECT is being shown in the logs after the connection is ended.

To verify the issue I would to verify what squid does and if a cli command like wget or curl from the squid box are doing the same.

There are debug logs levels that can help but try to add "dns_v4_first on" into the squid.conf, reload\restart and try again to see how squid works.

I am almost sure that the connection issue is related to some kind of network layer, you can try to see what happens when you try to access:
https://www.ngtech.co.il/

 

After we will clear this issue out there are other things which you might need to change\add in your squid.conf.

 

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of William Ivanski
Sent: Thursday, June 2, 2016 4:36 PM
To: William Ivanski
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Establishing secure conection problems (Chrome)

 

-> Access.log (the host 192.168.0.52 belongs to acl reqliberacaofixo):
1464870540.039    495 192.168.0.52 TCP_MISS/301 675 GET  <http://www.hotmail.com/> http://www.hotmail.com/ - HIER_DIRECT/ <http://65.55.65.188> 65.55.65.188 text/html
1464870550.793  10206 192.168.0.52 TCP_MISS_ABORTED/000 0 POST  <http://s2.symcb.com/> http://s2.symcb.com/ - HIER_DIRECT/2600:1419:8:18f::201a -
1464870554.259   2241 192.168.0.52 TCP_MISS_ABORTED/000 0 POST  <http://sr.symcd.com/> http://sr.symcd.com/ - HIER_DIRECT/2600:1419:8:18f::201a -
1464870626.286 121662 192.168.0.52 TCP_MISS/200 2192 GET  <http://s2.symcb.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBS56bKHAoUD%2BOyl%2B0LhPg9JxyQm4gQUf9Nlp8Ld7LvwMAnzQzn6Aq8zMTMCEH7hSm9v7%2FLTfz%2BtZU062rQ%3D> http://s2.symcb.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBS56bKHAoUD%2BOyl%2B0LhPg9JxyQm4gQUf9Nlp8Ld7LvwMAnzQzn6Aq8zMTMCEH7hSm9v7%2FLTfz%2BtZU062rQ%3D - HIER_DIRECT/ <http://23.4.43.27> 23.4.43.27 application/ocsp-response
1464870746.296 119912 192.168.0.52 TCP_MISS/200 2192 GET  <http://ocsp.verisign.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBS56bKHAoUD%2BOyl%2B0LhPg9JxyQm4gQUf9Nlp8Ld7LvwMAnzQzn6Aq8zMTMCEFIA5aolVvwahu2WydRLM8c%3D> http://ocsp.verisign.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBS56bKHAoUD%2BOyl%2B0LhPg9JxyQm4gQUf9Nlp8Ld7LvwMAnzQzn6Aq8zMTMCEFIA5aolVvwahu2WydRLM8c%3D - HIER_DIRECT/ <http://23.4.43.27> 23.4.43.27 application/ocsp-response
1464870866.307 120000 192.168.0.52 TCP_MISS/200 2155 GET  <http://sf.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBTSqZMG5M8TA9rdzkbCnNwuMAd5VgQUz5mp6nsm9EvJjo%2FX8AUm7%2BPSp50CEExA26X5iPrlelfWRXSV%2BYs%3D> http://sf.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBTSqZMG5M8TA9rdzkbCnNwuMAd5VgQUz5mp6nsm9EvJjo%2FX8AUm7%2BPSp50CEExA26X5iPrlelfWRXSV%2BYs%3D - HIER_DIRECT/ <http://23.4.43.27> 23.4.43.27 application/ocsp-response
1464870866.467    149 192.168.0.52 TCP_MISS/304 331 GET  <http://www.download.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab> http://www.download.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab - HIER_DIRECT/2804:a8:c800:301::bd56:7a18 application/octet-stream
1464870986.300 119824 192.168.0.52 TCP_MISS/200 654 GET  <http://crl.geotrust.com/crls/secureca.crl> http://crl.geotrust.com/crls/secureca.crl - HIER_DIRECT/ <http://23.4.37.163> 23.4.37.163 application/pkix-crl
1464871457.106    312 192.168.0.52 TCP_MISS/301 419 GET  <http://support.microsoft.com/> http://support.microsoft.com/ - HIER_DIRECT/ <http://172.224.183.89> 172.224.183.89 -
1464871477.134     45 192.168.0.52 TCP_MISS/301 340 GET  <http://www.itau.com.br/> http://www.itau.com.br/ - HIER_DIRECT/ <http://23.10.60.73> 23.10.60.73 -
1464871487.149     41 192.168.0.52 TCP_MISS/204 184 GET  <http://www.gstatic.com/generate_204> http://www.gstatic.com/generate_204 - HIER_DIRECT/2800:3f0:4001:800::2003 -
1464871490.334    338 192.168.0.52 TCP_MISS/302 685 GET  <http://c1.microsoft.com/c.gif> http://c1.microsoft.com/c.gif? - HIER_DIRECT/ <http://131.253.40.50> 131.253.40.50 -
1464871490.841    501 192.168.0.52 TCP_MISS/302 935 GET  <http://c.bing.com/c.gif> http://c.bing.com/c.gif? - HIER_DIRECT/ <http://65.52.108.11> 65.52.108.11 -
1464871491.004    159 192.168.0.52 TCP_MISS/200 885 GET  <http://c1.microsoft.com/c.gif> http://c1.microsoft.com/c.gif? - HIER_DIRECT/ <http://131.253.40.50> 131.253.40.50 image/gif
1464871507.401  60167 192.168.0.52 TCP_MISS_ABORTED/000 0 GET  <http://sr.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBR0JBRnBp%2F14Jg%2FXj4aa6BlKlQVdQQUAVmr5906C1mmZGPWzyAHV9WR52oCEGU3b%2BNLNLmDFl%2F0STiGxMc%3D> http://sr.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBR0JBRnBp%2F14Jg%2FXj4aa6BlKlQVdQQUAVmr5906C1mmZGPWzyAHV9WR52oCEGU3b%2BNLNLmDFl%2F0STiGxMc%3D - HIER_DIRECT/2600:1419:8:191::201a -
1464871517.401  59969 192.168.0.52 TCP_MISS_ABORTED/000 0 GET  <http://sr.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBR0JBRnBp%2F14Jg%2FXj4aa6BlKlQVdQQUAVmr5906C1mmZGPWzyAHV9WR52oCEG%2F6tqKxfdmg4KPDzqvBuK8%3D> http://sr.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBR0JBRnBp%2F14Jg%2FXj4aa6BlKlQVdQQUAVmr5906C1mmZGPWzyAHV9WR52oCEG%2F6tqKxfdmg4KPDzqvBuK8%3D - HIER_DIRECT/2600:1419:8:191::201a -
1464871522.402  60173 192.168.0.52 TCP_MISS_ABORTED/000 0 GET  <http://sr.symcb.com/sr.crl> http://sr.symcb.com/sr.crl - HIER_DIRECT/2600:1419:8:181::1abd -
1464871532.402  59968 192.168.0.52 TCP_MISS_ABORTED/000 0 GET  <http://sr.symcb.com/sr.crl> http://sr.symcb.com/sr.crl - HIER_DIRECT/2600:1419:8:181::1abd -
1464871676.152    839 192.168.0.52 TCP_MISS/301 675 GET  <http://www.hotmail.com/> http://www.hotmail.com/ - HIER_DIRECT/ <http://65.55.65.172> 65.55.65.172 text/html
1464871681.856   3654 192.168.0.52 TCP_MISS_ABORTED/000 0 GET  <http://sr.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBR0JBRnBp%2F14Jg%2FXj4aa6BlKlQVdQQUAVmr5906C1mmZGPWzyAHV9WR52oCEGU3b%2BNLNLmDFl%2F0STiGxMc%3D> http://sr.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBR0JBRnBp%2F14Jg%2FXj4aa6BlKlQVdQQUAVmr5906C1mmZGPWzyAHV9WR52oCEGU3b%2BNLNLmDFl%2F0STiGxMc%3D - HIER_DIRECT/2600:1419:8:191::201a -
1464871690.823     62 192.168.0.52 TCP_MISS/200 889 POST  <http://ocsp.digicert.com/> http://ocsp.digicert.com/ - HIER_DIRECT/ <http://192.16.58.8> 192.16.58.8 application/ocsp-response
1464871690.880     52 192.168.0.52 TCP_MISS/200 889 POST  <http://ocsp.digicert.com/> http://ocsp.digicert.com/ - HIER_DIRECT/ <http://192.16.58.8> 192.16.58.8 application/ocsp-response
1464871694.282    312 192.168.0.52 TCP_MISS/302 948 GET  <http://www.google.com.br/> http://www.google.com.br/ - HIER_DIRECT/2607:f8b0:4002:c0c::5e text/html
1464871694.785    180 192.168.0.52 TCP_MISS/200 847 POST  <http://clients1.google.com/ocsp> http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e application/ocsp-response
1464871704.519    186 192.168.0.52 TCP_MISS/200 847 POST  <http://clients1.google.com/ocsp> http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e application/ocsp-response
1464871705.113    173 192.168.0.52 TCP_MISS/200 847 POST  <http://clients1.google.com/ocsp> http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e application/ocsp-response
1464871705.485    183 192.168.0.52 TCP_MISS/200 847 POST  <http://clients1.google.com/ocsp> http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e application/ocsp-response
1464871705.748    179 192.168.0.52 TCP_MISS/200 847 POST  <http://clients1.google.com/ocsp> http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e application/ocsp-response
1464871707.725    177 192.168.0.52 TCP_MISS/200 847 POST  <http://clients1.google.com/ocsp> http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e application/ocsp-response
1464871708.014    188 192.168.0.52 TCP_MISS/200 847 POST  <http://clients1.google.com/ocsp> http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e application/ocsp-response
1464871708.768    186 192.168.0.52 TCP_MISS/200 847 POST  <http://clients1.google.com/ocsp> http://clients1.google.com/ocsp - HIER_DIRECT/2800:3f0:4001:801::200e application/ocsp-response
1464871744.573     50 192.168.0.52 TCP_MISS/200 889 POST  <http://ocsp.digicert.com/> http://ocsp.digicert.com/ - HIER_DIRECT/ <http://192.16.58.8> 192.16.58.8 application/ocsp-response
1464871746.272     39 192.168.0.52 TCP_MISS/200 1981 POST  <http://vassg142.ocsp.omniroot.com/> http://vassg142.ocsp.omniroot.com/ - HIER_DIRECT/ <http://189.86.122.11> 189.86.122.11 application/ocsp-response
1464871749.966   1145 192.168.0.52 TCP_MISS/200 341701 GET  <http://ciscobinary.openh264.org/openh264-win32-2706e36bf0a8b7c539c803ed877148c005ffca59.zip> http://ciscobinary.openh264.org/openh264-win32-2706e36bf0a8b7c539c803ed877148c005ffca59.zip - HIER_DIRECT/2600:1403:1::48f6:4070 application/zip
1464871763.636    145 192.168.0.52 TCP_MISS/302 945 HEAD  <http://redirector.gvt1.com/edgedl/release2/4q5bp49e5hqoxn6kx4mnsg1knc0d6zmfyb1zzrw2utmcns77n9nuq1wj8dutbcg1fvvzulfi9uks07x9zue8525igkbwdt9k1k5/51.0.2704.79_chrome_installer_win64.exe> http://redirector.gvt1.com/edgedl/release2/4q5bp49e5hqoxn6kx4mnsg1knc0d6zmfyb1zzrw2utmcns77n9nuq1wj8dutbcg1fvvzulfi9uks07x9zue8525igkbwdt9k1k5/51.0.2704.79_chrome_installer_win64.exe - HIER_DIRECT/2800:3f0:4001:800::200e text/html
1464871763.698     60 192.168.0.52 TCP_MISS/200 429 HEAD  <http://r2---sn-xhcg5uxa-jfcl.gvt1.com/edgedl/release2/4q5bp49e5hqoxn6kx4mnsg1knc0d6zmfyb1zzrw2utmcns77n9nuq1wj8dutbcg1fvvzulfi9uks07x9zue8525igkbwdt9k1k5/51.0.2704.79_chrome_installer_win64.exe> http://r2---sn-xhcg5uxa-jfcl.gvt1.com/edgedl/release2/4q5bp49e5hqoxn6kx4mnsg1knc0d6zmfyb1zzrw2utmcns77n9nuq1wj8dutbcg1fvvzulfi9uks07x9zue8525igkbwdt9k1k5/51.0.2704.79_chrome_installer_win64.exe? - HIER_DIRECT/2804:a8:c800:200::d application/octet-stream
1464871768.281   4550 192.168.0.52 TCP_MISS/200 52687693 GET  <http://r2---sn-xhcg5uxa-jfcl.gvt1.com/edgedl/release2/4q5bp49e5hqoxn6kx4mnsg1knc0d6zmfyb1zzrw2utmcns77n9nuq1wj8dutbcg1fvvzulfi9uks07x9zue8525igkbwdt9k1k5/51.0.2704.79_chrome_installer_win64.exe> http://r2---sn-xhcg5uxa-jfcl.gvt1.com/edgedl/release2/4q5bp49e5hqoxn6kx4mnsg1knc0d6zmfyb1zzrw2utmcns77n9nuq1wj8dutbcg1fvvzulfi9uks07x9zue8525igkbwdt9k1k5/51.0.2704.79_chrome_installer_win64.exe? - HIER_DIRECT/2804:a8:c800:200::d application/octet-stream
1464871797.113     82 192.168.0.52 TCP_MISS/302 1663 GET  <http://redirector.gvt1.com/crx/blobs/QgAAAC6zw0qH2DJtnXe8Z7rUJP2Rb7215C34RRoAOYw9FMifYIKbQ8NQ4eJck316jhcVHOPhJi112xRZ24oxSFePD-fslt2YdyTrBxWUtp4L7gbUAMZSmuXeGbE9p5N8uch3Sy5nHol_Tjr_7w/extension_1_0_0_0.crx> http://redirector.gvt1.com/crx/blobs/QgAAAC6zw0qH2DJtnXe8Z7rUJP2Rb7215C34RRoAOYw9FMifYIKbQ8NQ4eJck316jhcVHOPhJi112xRZ24oxSFePD-fslt2YdyTrBxWUtp4L7gbUAMZSmuXeGbE9p5N8uch3Sy5nHol_Tjr_7w/extension_1_0_0_0.crx - HIER_DIRECT/2800:3f0:4001:800::200e text/html
1464871797.249     92 192.168.0.52 TCP_MISS/200 185264 GET  <http://r1---sn-xhcg5uxa-jfce.gvt1.com/crx/blobs/QgAAAC6zw0qH2DJtnXe8Z7rUJP2Rb7215C34RRoAOYw9FMifYIKbQ8NQ4eJck316jhcVHOPhJi112xRZ24oxSFePD-fslt2YdyTrBxWUtp4L7gbUAMZSmuXeGbE9p5N8uch3Sy5nHol_Tjr_7w/extension_1_0_0_0.crx> http://r1---sn-xhcg5uxa-jfce.gvt1.com/crx/blobs/QgAAAC6zw0qH2DJtnXe8Z7rUJP2Rb7215C34RRoAOYw9FMifYIKbQ8NQ4eJck316jhcVHOPhJi112xRZ24oxSFePD-fslt2YdyTrBxWUtp4L7gbUAMZSmuXeGbE9p5N8uch3Sy5nHol_Tjr_7w/extension_1_0_0_0.crx? - HIER_DIRECT/2804:a8:c800:100::c application/x-chrome-extension
1464871799.230    108 192.168.0.52 TCP_MISS/302 662 GET  <http://tools.google.com/chrome/intl/pt-BR/welcome.html> http://tools.google.com/chrome/intl/pt-BR/welcome.html - HIER_DIRECT/2800:3f0:4004:805::200e text/html
1464871861.524    335 192.168.0.52 TCP_MISS/301 675 GET  <http://www.hotmail.com/> http://www.hotmail.com/ - HIER_DIRECT/ <http://65.55.65.172> 65.55.65.172 text/html
1464871872.190    299 192.168.0.52 TCP_MISS/301 419 GET  <http://support.microsoft.com/> http://support.microsoft.com/ - HIER_DIRECT/ <http://172.224.183.89> 172.224.183.89 -
1464871893.795   1211 192.168.0.52 TCP_MISS/301 344 GET  <http://itau.com.br/> http://itau.com.br/ - HIER_DIRECT/ <http://23.0.95.170> 23.0.95.170 -
1464871902.240     46 192.168.0.52 TCP_MISS/204 184 GET  <http://www.gstatic.com/generate_204> http://www.gstatic.com/generate_204 - HIER_DIRECT/2800:3f0:4001:803::2003 -
1464871906.833    334 192.168.0.52 TCP_MISS/302 685 GET  <http://c1.microsoft.com/c.gif> http://c1.microsoft.com/c.gif? - HIER_DIRECT/ <http://131.253.40.50> 131.253.40.50 -
1464871907.183    348




William Ivanski

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160602/e1a3a7a6/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image002.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160602/e1a3a7a6/attachment.png>

From amadaan at ncsu.edu  Thu Jun  2 15:23:24 2016
From: amadaan at ncsu.edu (Aashima Madaan)
Date: Thu, 2 Jun 2016 11:23:24 -0400
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
Message-ID: <C1506728-8998-40A3-AF8D-1117BE92616E@ncsu.edu>

Hey,

The patch mentioned is applicable to 4.0.10 beta release . For older versions I was not able to merge the patch.
So even for beta release it throws segmentation fault. Let me know if am using wrong version of code

Backtrace from gdb tool if it can be of any help

Program received signal SIGSEGV, Segmentation fault.
hash_lookup (hid=0x0, k=0xcd4200) at hash.cc:152
152	    b = hid->hash(k, hid->size);
Missing separate debuginfos, use: debuginfo-install glibc-2.17-106.el7_2.6.x86_64 libattr-2.4.46-12.el7.x86_64 libcap-2.22-8.el7.x86_64 libgcc-4.8.5-4.el7.x86_64 libstdc++-4.8.5-4.el7.x86_64 libtool-ltdl-2.4.2-21.el7_2.x86_64 nss-softokn-freebl-3.16.2.3-13.el7_1.x86_64

(gdb) backtrace
#0  hash_lookup (hid=0x0, k=0xcd4200) at hash.cc:152
#1  0x000000000056059f in idnsCachedLookup (key=key at entry=0xcd4200 "atld-mcafee01.airwatch.dev", callback=callback at entry=0x5d96a0 <ipcacheHandleReply(void*, rfc1035_rr const*, int, char const*)>, 
    data=data at entry=0xcd4608) at dns_internal.cc:1675
#2  0x00000000005667ee in idnsALookup (name=0xcd4200 "atld-mcafee01.airwatch.dev", callback=callback at entry=0x5d96a0 <ipcacheHandleReply(void*, rfc1035_rr const*, int, char const*)>, data=data at entry=0xcd4608)
    at dns_internal.cc:1742
#3  0x00000000005d9033 in ipcache_nbgethostbyname (name=name at entry=0xcd3db0 "atld-mcafee01.airwatch.dev", handler=handler at entry=0x0, handlerData=handlerData at entry=0x0) at ipcache.cc:561
#4  0x00000000005d95cc in ipcache_gethostbyname (name=0xcd3db0 "atld-mcafee01.airwatch.dev", flags=flags at entry=1) at ipcache.cc:653
#5  0x00000000007fae8c in Adaptation::ServiceConfig::grokUri (this=this at entry=0xcd3ad0, value=value at entry=0xcd3cf0 "icap://atld-mcafee01.airwatch.dev:1344/") at ServiceConfig.cc:239
#6  0x00000000007fc41f in Adaptation::ServiceConfig::parse (this=0xcd3ad0) at ServiceConfig.cc:122
#7  0x00000000007f2773 in Adaptation::Config::parseService (this=0xcb57a0 <Adaptation::Icap::TheConfig>) at Config.cc:136
#8  0x000000000050737b in parse_icap_service_type (cfg=<optimized out>) at cache_cf.cc:4235
#9  parse_line (buff=<optimized out>) at cf_parser.cci:3185
#10 0x0000000000510e89 in parseOneConfigFile (file_name=file_name at entry=0xcc9860 "/etc/squid/squid.conf", depth=depth at entry=0) at cache_cf.cc:544
#11 0x000000000051190f in parseConfigFile (file_name=0xcc9860 "/etc/squid/squid.conf") at cache_cf.cc:585
#12 0x00000000005ddc97 in SquidMain (argc=<optimized out>, argv=0x7fffffffe478) at main.cc:1523
#13 0x00000000004e77ad in SquidMainSafe (argv=<optimized out>, argc=<optimized out>) at main.cc:1374
#14 main (argc=<optimized out>, argv=<optimized out>) at main.cc:1367

(gdb) frame 5
#5  0x00000000007fae8c in Adaptation::ServiceConfig::grokUri (this=this at entry=0xcd3ad0, value=value at entry=0xcd3cf0 "icap://atld-mcafee01.airwatch.dev:1344/") at ServiceConfig.cc:239
239	    (void)ipcache_gethostbyname(host.termedBuf(), IP_LOOKUP_IF_MISS);

(gdb) frame 4
#4  0x00000000005d95cc in ipcache_gethostbyname (name=0xcd3db0 "atld-mcafee01.airwatch.dev", flags=flags at entry=1) at ipcache.cc:653
653	        ipcache_nbgethostbyname(name, NULL, NULL);

(gdb) frame 3
#3  0x00000000005d9033 in ipcache_nbgethostbyname (name=name at entry=0xcd3db0 "atld-mcafee01.airwatch.dev", handler=handler at entry=0x0, handlerData=handlerData at entry=0x0) at ipcache.cc:561
561	    idnsALookup(hashKeyStr(&i->hash), ipcacheHandleReply, c);

(gdb) frame 2
#2  0x00000000005667ee in idnsALookup (name=0xcd4200 "atld-mcafee01.airwatch.dev", callback=callback at entry=0x5d96a0 <ipcacheHandleReply(void*, rfc1035_rr const*, int, char const*)>, data=data at entry=0xcd4608)
    at dns_internal.cc:1742
1742	    if (idnsCachedLookup(name, callback, data))

(gdb) frame 1
#1  0x000000000056059f in idnsCachedLookup (key=key at entry=0xcd4200 "atld-mcafee01.airwatch.dev", callback=callback at entry=0x5d96a0 <ipcacheHandleReply(void*, rfc1035_rr const*, int, char const*)>, 
    data=data at entry=0xcd4608) at dns_internal.cc:1675
1675	    idns_query *old = (idns_query *) hash_lookup(idns_lookup_hash, key);

(gdb) frame 0
#0  hash_lookup (hid=0x0, k=0xcd4200) at hash.cc:152
152	    b = hid->hash(k, hid->size);
(gdb) 


Thanks
Aashima

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160602/1c369fff/attachment.htm>

From hydrapolic at gmail.com  Thu Jun  2 15:47:55 2016
From: hydrapolic at gmail.com (Tomas Mozes)
Date: Thu, 2 Jun 2016 17:47:55 +0200
Subject: [squid-users] pinger crash - Bad opcode: 112
In-Reply-To: <a176619d-3ca6-132b-f72e-40723be158ed@treenet.co.nz>
References: <CAG6MAzT+JQP0Bd+UDHN3zwigU6W8H6oGYxXdn3iVhuYqU=qZpg@mail.gmail.com>
 <bdb614cb-27fe-ad3a-5780-e6f9245e495d@treenet.co.nz>
 <CAG6MAzQpEQNA1nv_GfNcWvQTccA7ZejyCoOiscsQS51C5FBcdQ@mail.gmail.com>
 <a176619d-3ca6-132b-f72e-40723be158ed@treenet.co.nz>
Message-ID: <CAG6MAzRSmL_9wxCYoVjhQggC-BXSGeeScpPtaMBgBN6M8uQ9yw@mail.gmail.com>

On Wed, Jun 1, 2016 at 1:53 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 31/05/2016 9:56 p.m., Tomas Mozes wrote:
> > On Thu, May 26, 2016 at 8:04 AM, Amos Jeffries wrote:
> >
> >> On 24/05/2016 7:52 p.m., Tomas Mozes wrote:
> >>> Hello,
> >>> on two different squid servers I've observed a crash of pinger. First
> it
> >>> appeared on version 3.5.15 and later on version 3.5.17.
> >>>
> >>> Cache.log contains these lines:
> >>>
> >>> (pinger): Address.cc:671: void Ip::Address::getAddrInfo(addrinfo*&,
> int)
> >>> const: Assertion `false' failed.
> >>> 2016/05/14 21:55:25 kid1| Bad opcode: 112 from
> >>> [6661:6c73:6522:2061:7420:6c69:6e65:2036]
> >>> 2016/05/14 21:59:13 kid1| recv: (111) Connection refused
> >>> 2016/05/14 21:59:13 kid1| Closing Pinger socket on FD 17
> >>>
> >>> On both servers, that IPv6 address was the same -
> >>> 6661:6c73:6522:2061:7420:6c69:6e65:2036
> >>>
> >>
> >> That is the hexadecimal representation of the error:
> >>  false" at line 6
> >>
> >> Which means that your kernel is producing garbage when asked to resolve
> >> an IPv6 address or respond to an ICMPv6 packet.
> >>
> >
> > Cannot we prevent Squid from crashing in these cases?
> >
>
> Squid is not crashing. The pinger is. Squid continues with degraded
> service latency.
>

Yes, sorry, I wasn't specific. I meant like some part of Squid, not the
Squid caching process itself.


> What kind of continued operations would you expect a program to do when
> it discovers at least some portion of its RAM has been filled with
> garbage by the system kernel?
>


In the worst case - wouldn't it be possible for the master process to
restart it?



>
> Now cross your fingers and pray that no other programs on your whole
> system (network, if you did the same "disable" on other machines) are
> behaving badly in secret when given the garbage by the kernel like
> Squid's pinger was.
>

You know, the strange thing is I only found those strings on google
attached with Squid. No other place. If it's a general issue in the Linux
kernel, then it's been there for years, unnoticed. And as I mentioned
before, it happened on two machines, separate from each other, in
completely different data-centers with the same error message.

What would you suggest?



>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160602/49ced2e8/attachment.htm>

From william.ivanski at gmail.com  Thu Jun  2 18:02:39 2016
From: william.ivanski at gmail.com (William Ivanski)
Date: Thu, 2 Jun 2016 15:02:39 -0300
Subject: [squid-users] Establishing secure conection problems (Chrome)
In-Reply-To: <201606021645.38753.Antony.Stone@squid.open.source.it>
References: <CACaWZ9TD=1d_nrojzacdTaMZiopLy7Y1cU78KinzdXKb6g4JFQ@mail.gmail.com>
 <CACaWZ9R99-NOswTuf6iOrc-bz-GeK9aemVeTGhmgaVCv+G4HWA@mail.gmail.com>
 <CACaWZ9RXL3_bf8LLnLnan_9yKGzvx8q9pnwN6wnHhxX=SS++kw@mail.gmail.com>
 <201606021645.38753.Antony.Stone@squid.open.source.it>
Message-ID: <CACaWZ9QYZ6=7aNLdDwZ2CLGi7jdRxvRif0RdX1qFk_2pqkxgJw@mail.gmail.com>

Guys,

Antony made me realize I really have a messed up Squid installation. That's
why I tried many different approaches (ssl_crtd/ssl_db, intercept), but the
actual installation isn't configured as transparent proxy.

So I agree I need to reinstall and reconfigure everything. As soon as I
manage to do it, I'll tell you guys if this solves the problem.

Thank you for now.


William Ivanski

2016-06-02 11:45 GMT-03:00 Antony Stone <Antony.Stone at squid.open.source.it>:

> On Thursday 02 June 2016 at 15:35:10, William Ivanski wrote:
>
> > Thank you for your quick response.
> >
> > First of all forgive me for the lack of information in the first
> > email. I've tried to disable QUIC a few minutes ago and the problem
> > persists. Follow the information requested:
> >
> > -> Compilation:
> >
> > I've installed squid using the following commands:
> >
> >     cd /usr/src
> >
> >     apt-get install squid3
>
> So, that will install a working copy of Squid, and then...
>
> >     wget
> >
> http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.15-20160330-r14015.ta
> > r.gz
> >
> >     tar xvzf squid-3.5.15-20160330-r14015.tar.gz
> >
> >     cd squid-3.5.15-20160330-r14015
>
> ...you download the latest source version and try to build it yourself...
>
> >     apt-get build-dep squid3 && apt-get install build-essential
> libssl-dev
>
> ...unfortunately using the Debian commands to build from a source package,
> which you did not download (the Debian source package is not the same as
> the
> Squid tarball).
>
> You then proceed to do the standard ./configure && make && make install for
> installation from a tarball.
>
> I wouldn't like to guess what sort of state any installed Squid is in after
> doing this bizarre combination.
>
>
> I recommend installing the Debian binary package, *or* install the Debian
> source package and build from that, *or* download the source tarball and
> build
> that.  Do not combine these.
>
>
> Regards,
>
>
> Antony.
>
> --
> I lay awake all night wondering where the sun went, and then it dawned on
> me.
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160602/5932277e/attachment.htm>

From squid3 at treenet.co.nz  Fri Jun  3 05:43:54 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 3 Jun 2016 17:43:54 +1200
Subject: [squid-users] Establishing secure conection problems (Chrome)
In-Reply-To: <CACaWZ9RXL3_bf8LLnLnan_9yKGzvx8q9pnwN6wnHhxX=SS++kw@mail.gmail.com>
References: <CACaWZ9TD=1d_nrojzacdTaMZiopLy7Y1cU78KinzdXKb6g4JFQ@mail.gmail.com>
 <2807b52a-88cc-fe2e-b5db-329f681e2e38@gmail.com>
 <CAKQSiAVQLoHB+VjZ1U5kZtU2b5eXqSWuNbYkLJ_JfVX52FrOMQ@mail.gmail.com>
 <c1d2f252-0f76-c137-18f3-b3c89054b192@gmail.com>
 <CACaWZ9RLN4k0fBaHu+zjbt_EBYNn8bA-Xf-9MAwhAKGyGJjQkA@mail.gmail.com>
 <CACaWZ9R99-NOswTuf6iOrc-bz-GeK9aemVeTGhmgaVCv+G4HWA@mail.gmail.com>
 <CACaWZ9RXL3_bf8LLnLnan_9yKGzvx8q9pnwN6wnHhxX=SS++kw@mail.gmail.com>
Message-ID: <1ca7252d-0b08-bafe-ae99-b4d0b4500b21@treenet.co.nz>

On 3/06/2016 1:35 a.m., William Ivanski wrote:
> Thank you for your quick response.
> 
> First of all forgive me for the lack of information in the first
> email. I've tried to disable QUIC a few minutes ago and the problem
> persists. Follow the information requested:
> 
> -> Compilation:
> 
> I've installed squid using the following commands:
> 
>     cd /usr/src
> 
>     apt-get install squid3
> 
>     wget http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.15-20160330-r14015.tar.gz
> 
>     tar xvzf squid-3.5.15-20160330-r14015.tar.gz
> 
>     cd squid-3.5.15-20160330-r14015
> 

NP: when building your own always build the latest. Today that would be
one of the 3.5.19 snapshots.


>     apt-get build-dep squid3 && apt-get install build-essential libssl-dev
> 
>     ./configure --enable-icap-client --enable-ssl --enable-ssl-crtd
> --prefix=/usr --includedir=/usr/include --mandir=/usr/share/man
> --infodir=/usr/share/info --sysconfdir=/etc --localstatedir=/var
> --libexecdir=/lib/squid3 --srcdir=. --datadir=/usr/share/squid3
> --sysconfdir=/etc/squid3 --mandir=/usr/share/man
> --with-default-user=squid --with- cppunit-config-basedir=/usr
> --with-logdir=/var/log/squid3 --with-pidfile=/var/run/squid3.pid
> --with-openssl --disable-optimizations --disable-arch-native
> 
>     service squid3 stop
> 
>     make all && make install
> 
>     useradd squid && chown -R squid:squid /var/log/squid3

Don't. The squid3 package install created the necessary user and
permissions for all required things.

You just need to build with the same default-user settings as Debian.
IIRC that is --with-default-user=proxy

> 
>     mv /usr/sbin/squid3 /usr/sbin/squid3.old && mv/usr/sbin/squid
> /usr/sbin/squid3
> 
>     /lib/squid3/ssl_crtd -c -s /var/lib/ssl_db -M 4 MB
> 
>     chown -R squid:squid /var/lib/ssl_db
> 
>     service squid3 restart && service squid3 stop && chmod 777
> /var/spool/squid3 && squid3 -z && service squid3 restart

Same here.

> 
> OBS: We're not using ssl_crtd/ssl_db anymore. Our previous squid conf
> was using intercept, but the actual one isn't configured as
> transparent proxy.

If that is so then any problems Chrome or other agents might be having
are not related to Squid.

They are just creating opaque tunnels through the proxy and doing TLS
stuff end-to-end. There is no reason for the proxy to have TLS/SSL
capabilities at all in that kind of setup.


The config you posted confirms. The OpenSSL abilities you custom
compiled to add to the proxy are not being used in any way.

Amos



From squid3 at treenet.co.nz  Fri Jun  3 05:53:58 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 3 Jun 2016 17:53:58 +1200
Subject: [squid-users] google drive up-/download size in squidlog
In-Reply-To: <efa39e35-91b4-979b-104c-d7d9cdf16131@hdpnet.de>
References: <57440D94.1080703@hdpnet.de>
 <009a89d8-79af-45e9-ee97-7baa5e24ceac@treenet.co.nz>
 <efa39e35-91b4-979b-104c-d7d9cdf16131@hdpnet.de>
Message-ID: <c8aaa441-8f3a-0f43-520a-caeeec8243cf@treenet.co.nz>

On 2/06/2016 9:01 p.m., Paul Buechler wrote:
> Hi,
> 
> @Yuri Voinov:
> 
> I've only tested it with the webclient.
> 
> @Amos Jeffries:
> 
> I've tested it with %st and the downloadsize is fine for me now, thanks.
> 
> Are there any plans to implement a format code to see the uploadsize?
> It would be nice to have this feature.

That would be the third 'st' tag, which logs *only* the outgoing
direction of traffic.

You really should look through the documentation which lists clearly
what tags are available:
 <http://www.squid-cache.org/Doc/config/logformat/>

Amos



From chip_pop at hotmail.com  Fri Jun  3 12:06:51 2016
From: chip_pop at hotmail.com (joe)
Date: Fri, 3 Jun 2016 05:06:51 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <38eeae01-c417-b703-0042-304dd5257407@gmail.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <04828faf-5f53-2f09-58ed-eac1b98b4257@treenet.co.nz>
 <38eeae01-c417-b703-0042-304dd5257407@gmail.com>
Message-ID: <1464955611234-4677790.post@n4.nabble.com>

chrome browser
'http://ajax.cloudflare.com/cdn-cgi/nexp/dok3v=e982913d31/cloudflare.min.js' 
'accept-encoding="gzip,%20deflate,%20sdch"'  <---befor
'accept-encoding="gzip"'    <--- after
-----------------
firefox browser
'http://ajax.cloudflare.com/cdn-cgi/nexp/dok3v=e982913d31/cloudflare.min.js' 
'accept-encoding="gzip,%20deflate"'  <---befor
'accept-encoding="gzip"'    <--- after

as i we said  filtering out anything start with %20  shuld be removed and
you will gain lots %  on hit object



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677790.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Fri Jun  3 17:28:17 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 3 Jun 2016 23:28:17 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1464955611234-4677790.post@n4.nabble.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <04828faf-5f53-2f09-58ed-eac1b98b4257@treenet.co.nz>
 <38eeae01-c417-b703-0042-304dd5257407@gmail.com>
 <1464955611234-4677790.post@n4.nabble.com>
Message-ID: <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Well, show me this patch.

PS. However I think this is dirty hack. :)


03.06.2016 18:06, joe ?????:
> chrome browser
>
'http://ajax.cloudflare.com/cdn-cgi/nexp/dok3v=e982913d31/cloudflare.min.js'

> 'accept-encoding="gzip,%20deflate,%20sdch"'  <---befor
> 'accept-encoding="gzip"'    <--- after
> -----------------
> firefox browser
>
'http://ajax.cloudflare.com/cdn-cgi/nexp/dok3v=e982913d31/cloudflare.min.js'

> 'accept-encoding="gzip,%20deflate"'  <---befor
> 'accept-encoding="gzip"'    <--- after
>
> as i we said  filtering out anything start with %20  shuld be removed and
> you will gain lots %  on hit object
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677790.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXUb4xAAoJENNXIZxhPexGAVIIAIg94fxNS3Oz5FvmIrGfal8G
WKpjUqMfQjqh2gAtpTrIHIDsegvNV0dqioUukyGtqavXF+IbLlGkBnGyGSqQqTQ2
v3S3kdDDnKNIqGKFPRLe2TV0zRh4cRgnTc8Qs7Xw4CGMZLk1/yYezJsPUp00uzs4
Q7NAkfIKSVhHbL78ALDvDQb6hpVHFSiV5QRF5xRNOD8KKg38HS7Ao1faoVsQeGol
fHs08lUWAV0ghQhLXsaVDi6x9bujvDNEuk0mS9k+0HN8M2nukG5fJRYuVUT063Cx
EoLswcx1sXnPp9CKrb1/URfpAXjl9B4ddG7freIRS9DdT/P4vQBYMYKP54E01eU=
=OATQ
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160603/1896fa12/attachment.key>

From chip_pop at hotmail.com  Fri Jun  3 17:37:59 2016
From: chip_pop at hotmail.com (joe)
Date: Fri, 3 Jun 2016 10:37:59 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>
References: <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <04828faf-5f53-2f09-58ed-eac1b98b4257@treenet.co.nz>
 <38eeae01-c417-b703-0042-304dd5257407@gmail.com>
 <1464955611234-4677790.post@n4.nabble.com>
 <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>
Message-ID: <1464975479587-4677792.post@n4.nabble.com>

i will just have to do patch i work direct on source if you want 
i post  and its not regx yet and the sbuf routine the dev guys shuld do it
its missing function str.erase in sbuf i gess
not good for production untill somone do regx match  on  -->    %20 filter
out

int
varyEvaluateMatch(StoreEntry * entry, HttpRequest * request)
{
    SBuf vary(request->vary_headers);
    int has_vary = entry->getReply()->header.has(HDR_VARY);
#if X_ACCELERATOR_VARY
    has_vary |=
        entry->getReply()->header.has(HDR_X_ACCELERATOR_VARY);
#endif


    if (!has_vary || entry->mem_obj->vary_headers.isEmpty()) {
        if (!vary.isEmpty()) {
            /* Oops... something odd is going on here.. */
            debugs(33, DBG_IMPORTANT, "varyEvaluateMatch: Oops. Not a Vary
object on second attempt, '" <<
                   entry->mem_obj->urlXXX() << "' '" << vary << "'");
            request->vary_headers.clear();
            return VARY_CANCEL;
        }

        if (!has_vary) {
            /* This is not a varying object */
            return VARY_NONE;
        }

        /* virtual "vary" object found. Calculate the vary key and
         * continue the search
         */
        vary = httpMakeVaryMark(request, entry->getReply());

        if (!vary.isEmpty()) {
            request->vary_headers = vary;
            return VARY_OTHER;
        } else {
            /* Ouch.. we cannot handle this kind of variance */
            /* XXX This cannot really happen, but just to be complete */
            return VARY_CANCEL;
        }
    } else {
        if (vary.isEmpty()) {
            vary = httpMakeVaryMark(request, entry->getReply());

            if (!vary.isEmpty())
                request->vary_headers = vary;
        }
if (!vary.isEmpty()) {
		std::string t = vary.c_str();

		std::string s = ",%20sdch";
		std::string::size_type i = t.find(s);
  if (i != std::string::npos){
     t.erase(i, s.length());
  }

		std::string s1 = ",%20deflate";
		std::string::size_type i1 = t.find(s1);

  if (i1 != std::string::npos){
     t.erase(i1, s1.length());
  }

		std::string s2 = ",%20gzip";
		std::string::size_type i2 = t.find(s2);

  if (i2 != std::string::npos){
     t.erase(i2, s2.length());
  }

		std::string s3 = ",%20identity";
		std::string::size_type i3 = t.find(s3);

  if (i3 != std::string::npos){
     t.erase(i3, s3.length());
  }
		vary=SBuf(t);
              return VARY_MATCH;
}
        if (vary.isEmpty()) {
            /* Ouch.. we cannot handle this kind of variance */
            /* XXX This cannot really happen, but just to be complete */
            return VARY_CANCEL;
        } else if (vary.cmp(entry->mem_obj->vary_headers) == 0) {
            return VARY_MATCH;
        } else {
            /* Oops.. we have already been here and still haven't
             * found the requested variant. Bail out
             */

            debugs(33, DBG_IMPORTANT, "varyEvaluateMatch: Oops. Not a Vary
match on second attempt, '" <<
                   entry->mem_obj->urlXXX() << "' '" << vary << "'");
            return VARY_CANCEL;
        }
    }
}



just replace the old function on client_side.cc  --> varyEvaluateMatch  with
the one i post  or i post later  the patch
dont lough im not pro but i do my home work



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677792.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Fri Jun  3 19:33:43 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 4 Jun 2016 01:33:43 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1464975479587-4677792.post@n4.nabble.com>
References: <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <04828faf-5f53-2f09-58ed-eac1b98b4257@treenet.co.nz>
 <38eeae01-c417-b703-0042-304dd5257407@gmail.com>
 <1464955611234-4677790.post@n4.nabble.com>
 <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>
 <1464975479587-4677792.post@n4.nabble.com>
Message-ID: <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Man, you right.

You change dramatically increases HIT. Some checked sites with
traditional low HIT ratio now caching.

Wow.


03.06.2016 23:37, joe ?????:
> i will just have to do patch i work direct on source if you want
> i post  and its not regx yet and the sbuf routine the dev guys shuld do it
> its missing function str.erase in sbuf i gess
> not good for production untill somone do regx match  on  -->    %20 filter
> out
>
> int
> varyEvaluateMatch(StoreEntry * entry, HttpRequest * request)
> {
>     SBuf vary(request->vary_headers);
>     int has_vary = entry->getReply()->header.has(HDR_VARY);
> #if X_ACCELERATOR_VARY
>     has_vary |=
>         entry->getReply()->header.has(HDR_X_ACCELERATOR_VARY);
> #endif
>
>
>     if (!has_vary || entry->mem_obj->vary_headers.isEmpty()) {
>         if (!vary.isEmpty()) {
>             /* Oops... something odd is going on here.. */
>             debugs(33, DBG_IMPORTANT, "varyEvaluateMatch: Oops. Not a Vary
> object on second attempt, '" <<
>                    entry->mem_obj->urlXXX() << "' '" << vary << "'");
>             request->vary_headers.clear();
>             return VARY_CANCEL;
>         }
>
>         if (!has_vary) {
>             /* This is not a varying object */
>             return VARY_NONE;
>         }
>
>         /* virtual "vary" object found. Calculate the vary key and
>          * continue the search
>          */
>         vary = httpMakeVaryMark(request, entry->getReply());
>
>         if (!vary.isEmpty()) {
>             request->vary_headers = vary;
>             return VARY_OTHER;
>         } else {
>             /* Ouch.. we cannot handle this kind of variance */
>             /* XXX This cannot really happen, but just to be complete */
>             return VARY_CANCEL;
>         }
>     } else {
>         if (vary.isEmpty()) {
>             vary = httpMakeVaryMark(request, entry->getReply());
>
>             if (!vary.isEmpty())
>                 request->vary_headers = vary;
>         }
> if (!vary.isEmpty()) {
>         std::string t = vary.c_str();
>
>         std::string s = ",%20sdch";
>         std::string::size_type i = t.find(s);
>   if (i != std::string::npos){
>      t.erase(i, s.length());
>   }
>
>         std::string s1 = ",%20deflate";
>         std::string::size_type i1 = t.find(s1);
>
>   if (i1 != std::string::npos){
>      t.erase(i1, s1.length());
>   }
>
>         std::string s2 = ",%20gzip";
>         std::string::size_type i2 = t.find(s2);
>
>   if (i2 != std::string::npos){
>      t.erase(i2, s2.length());
>   }
>
>         std::string s3 = ",%20identity";
>         std::string::size_type i3 = t.find(s3);
>
>   if (i3 != std::string::npos){
>      t.erase(i3, s3.length());
>   }
>         vary=SBuf(t);
>               return VARY_MATCH;
> }
>         if (vary.isEmpty()) {
>             /* Ouch.. we cannot handle this kind of variance */
>             /* XXX This cannot really happen, but just to be complete */
>             return VARY_CANCEL;
>         } else if (vary.cmp(entry->mem_obj->vary_headers) == 0) {
>             return VARY_MATCH;
>         } else {
>             /* Oops.. we have already been here and still haven't
>              * found the requested variant. Bail out
>              */
>
>             debugs(33, DBG_IMPORTANT, "varyEvaluateMatch: Oops. Not a Vary
> match on second attempt, '" <<
>                    entry->mem_obj->urlXXX() << "' '" << vary << "'");
>             return VARY_CANCEL;
>         }
>     }
> }
>
>
>
> just replace the old function on client_side.cc  -->
varyEvaluateMatch  with
> the one i post  or i post later  the patch
> dont lough im not pro but i do my home work
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677792.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXUduWAAoJENNXIZxhPexGP1QH/2Fx0TWZrviMgFavyUsR6jXv
LADswxk5iCEX20frmDCbIGXRgbmzvGwohYcAWR5aCPCyJxirvkmnSN4KP6it6D5b
DuwrLVDcxBGg5CeR7ajRO9+yg/0r/MwF2NG7aLSa/ao+sxjJi+D+fRjxy5vQ3Ucq
TrxjdZn119dbrVkiP8mljoK4pohvEFT07pbA30K0mf2olRg98TTQFOFSWTnnPnjf
Lhpp60+o9h67p4ELBvAJ8yCloiFRs/2fljCpqDUkwIY74aIX/wjTfbh3+0VLNrYn
V6GKJ0zpGyr7OcM9BawjfJcoyjMEUy1ZCN5Yf+vjtSqG/UydVbX9OwnhapSlk5U=
=enzv
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160604/766038c0/attachment.key>

From chip_pop at hotmail.com  Fri Jun  3 19:21:06 2016
From: chip_pop at hotmail.com (joe)
Date: Fri, 3 Jun 2016 12:21:06 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
References: <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <04828faf-5f53-2f09-58ed-eac1b98b4257@treenet.co.nz>
 <38eeae01-c417-b703-0042-304dd5257407@gmail.com>
 <1464955611234-4677790.post@n4.nabble.com>
 <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>
 <1464975479587-4677792.post@n4.nabble.com>
 <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
Message-ID: <1464981666806-4677794.post@n4.nabble.com>

how is the  speed any decrease noticeable or ??
it need to be done correct way using regx function and if possible from the
dev guys 
patern to be removed  "^,%20.*[,"]$"  minus one char.  so it wont erase last
char   [,"] 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677794.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Fri Jun  3 20:07:40 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 4 Jun 2016 02:07:40 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1464981666806-4677794.post@n4.nabble.com>
References: <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <04828faf-5f53-2f09-58ed-eac1b98b4257@treenet.co.nz>
 <38eeae01-c417-b703-0042-304dd5257407@gmail.com>
 <1464955611234-4677790.post@n4.nabble.com>
 <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>
 <1464975479587-4677792.post@n4.nabble.com>
 <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
 <1464981666806-4677794.post@n4.nabble.com>
Message-ID: <67052d2f-7d31-d563-a793-729ce4fa5ffa@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Now visible latency is increase approx.1-2 sec, but hit is higher.

Sometimes regex is slower comparing ordinal string functions and methods.


04.06.2016 1:21, joe ?????:
> how is the  speed any decrease noticeable or ??
> it need to be done correct way using regx function and if possible
from the
> dev guys
> patern to be removed  "^,%20.*[,"]$"  minus one char.  so it wont
erase last
> char   [,"]
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677794.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXUeOMAAoJENNXIZxhPexGKUcIAKu8Jw33QDGSHNXfwL4Ykfnc
J8WaJALJqZd+4ue6vtUNryBfMJ0drRkwtqW2zFdzf4+U2nHOUnirREGBwxYCjYqO
3v3lXiadW+9s83jasLo3q5o3W7feZ47OfhCKOG5oSForNGH1YrkHJSKdvY4JcbRi
byho3P5S/hmM7i2sPctm6FIcfFlZBnBKN1Z009oI/CLtC+TuBbIDWIN8cW7iUBWV
FUW7/FMUFWBfQqQz1PyndQgDG/Krh02rBBU+zI95DjbAntNoObCbhYnHjnQJEYzf
EPT1s45AoR1ljrqvGsRdQFX5x4/czsqk8WLbv3J+otwJMdKIFaWupe4q0QnKhVA=
=d5XR
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160604/06ab8965/attachment.key>

From chip_pop at hotmail.com  Fri Jun  3 19:35:10 2016
From: chip_pop at hotmail.com (joe)
Date: Fri, 3 Jun 2016 12:35:10 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <67052d2f-7d31-d563-a793-729ce4fa5ffa@gmail.com>
References: <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <04828faf-5f53-2f09-58ed-eac1b98b4257@treenet.co.nz>
 <38eeae01-c417-b703-0042-304dd5257407@gmail.com>
 <1464955611234-4677790.post@n4.nabble.com>
 <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>
 <1464975479587-4677792.post@n4.nabble.com>
 <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
 <1464981666806-4677794.post@n4.nabble.com>
 <67052d2f-7d31-d563-a793-729ce4fa5ffa@gmail.com>
Message-ID: <1464982510884-4677796.post@n4.nabble.com>

ya right   latency increase 1  to 2 sec is not mush  because to meny  if ()  
i think the  Sbuf function ar faster a bit lets wait for the guys to do it
correct way
hoop hehe 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677796.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From heiler.bemerguy at cinbesa.com.br  Fri Jun  3 21:20:23 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Fri, 3 Jun 2016 18:20:23 -0300
Subject: [squid-users] Bug: Missing MemObject::storeId value
In-Reply-To: <20e8aba7-7d60-95d4-344b-c5d6060a84e6@treenet.co.nz>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <c9f4b54a-7fd4-3355-a9cd-161b92e1ce15@cinbesa.com.br>
 <1464701636671-4677737.post@n4.nabble.com>
 <5d9049ba-b688-a22e-07d5-12b7da94dc8c@gmail.com>
 <931f91a3-51f4-6ff4-e781-4ed71964f527@cinbesa.com.br>
 <5cb41d75-387c-80af-fac6-e03a2570b0fa@gmail.com>
 <4fbad1c7-6a7f-b395-4824-08ec7add0a18@cinbesa.com.br>
 <6a67dd0e-80ae-ab5e-f353-2ec403ea6e75@gmail.com>
 <e21161a5-eef9-7b10-e4a5-0222d0e6756c@cinbesa.com.br>
 <4f72c4ab-6262-a62e-956b-a2721b0a59b7@gmail.com>
 <e4d31056-6099-205e-06b4-80dd001fdcd8@cinbesa.com.br>
 <20e8aba7-7d60-95d4-344b-c5d6060a84e6@treenet.co.nz>
Message-ID: <5e843758-f098-209b-8f7e-93e49765f60b@cinbesa.com.br>


Thanks Amos,

I switched to HTCP but the same problem happens..

2016/06/03 18:14:00 kid3| Bug: Missing MemObject::storeId value
2016/06/03 18:14:00 kid3| mem_hdr: 0x72d3610 nodes.start() 0x5fc30d0
2016/06/03 18:14:00 kid3| mem_hdr: 0x72d3610 nodes.finish() 0x5fc30d0
2016/06/03 18:14:00 kid3| MemObject->start_ping: 0.000000
2016/06/03 18:14:00 kid3| MemObject->inmem_hi: 1045
2016/06/03 18:14:00 kid3| MemObject->inmem_lo: 0
2016/06/03 18:14:00 kid3| MemObject->nclients: 0
2016/06/03 18:14:00 kid3| MemObject->reply: 0x5d6cfe0
2016/06/03 18:14:00 kid3| MemObject->request: 0
2016/06/03 18:14:00 kid3| MemObject->logUri:
2016/06/03 18:14:00 kid3| MemObject->storeId:
2016/06/03 18:14:09.181 kid2| clientProcessHit: URL mismatch, 
'[unknown_URI]' != 'http://www.agenciabelem.com.br/images/b_prev.png'
2016/06/03 18:14:20.965 kid3| clientProcessHit: URL mismatch, 
'[unknown_URI]' != 
'http://s2.glbimg.com/Pj7LKnj1D91oGqBNbB9SdBqMVho=/155xorig/smart/filters:strip_icc()/s2.glbimg.com/f-Jk42TOoCN-_Og4XgSa88NPkBw=/19x10:289x233/155x128/s.glbimg.com/en/ho/f/original/2016/06/03/silvio.jpg'
2016/06/03 18:14:21 kid3| storeClientReadHeader: URL mismatch
2016/06/03 18:14:21 kid3|       {[unknown_URI]} != 
{http://c.api.globo.com/soccer_teams/ab.css}

on access.log it shows this:
1464987925.060      0 10.1.10.101 UDP_HIT/000 0 HTCP_TST 
http://s2.glbimg.com/Pj7LKnj1D91oGqBNbB9SdBqMVho=/155xorig/smart/filters:strip_icc()/s2.glbimg.com/f-Jk42TOoCN-_Og4XgSa88NPkBw=/19x10:289x233/155x128/s.glbimg.com/en/ho/f/original/2016/06/03/silvio.jpg 
- HIER_NONE/- -
1464987925.062      1 10.1.10.101 TCP_IMS_HIT/304 256 GET 
http://s2.glbimg.com/Pj7LKnj1D91oGqBNbB9SdBqMVho=/155xorig/smart/filters:strip_icc()/s2.glbimg.com/f-Jk42TOoCN-_Og4XgSa88NPkBw=/19x10:289x233/155x128/s.glbimg.com/en/ho/f/original/2016/06/03/silvio.jpg 
- HIER_NONE/- image/jpeg

I'm using some rock stores and 3 workers..


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751



Em 01/06/2016 02:47, Amos Jeffries escreveu:
> On 1/06/2016 4:36 a.m., Heiler Bemerguy wrote:
>> This is the parent proxy of another one (10.1.10.101).
>>
>> It was receiveing requests like these:
>>
>> 1464665138.326      0 10.1.10.101 UDP_MISS/000 72 ICP_QUERY
>> http://img.olx.com.br/thumbs/51/517630000636766.jpg - HIER_NONE/- -
>> 1464665138.331      0 10.1.10.101 UDP_MISS/000 72 ICP_QUERY
>> http://img.olx.com.br/thumbs/51/515630006195751.jpg - HIER_NONE/- -
> ICP was designed for HTTP/1.0 traffic. It only exchanges URI between the
> peers. HTTP/1.1 things like the Vary header are not sent. So objects
> have a high false-HIT rate which affects caching success.
>
> For HTTP/1.1 proxies you should use HTCP instead if possible. It will
> cope much better with Vary and refresh needs.
>
>
> Also, if you are using Store-ID helpers be aware that ICP and HTCP
> queries do not go through the Store-ID helper (yet). So failures will
> occure for all things with locally altered Store-ID's.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Fri Jun  3 21:21:47 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 4 Jun 2016 03:21:47 +0600
Subject: [squid-users] Bug: Missing MemObject::storeId value
In-Reply-To: <5e843758-f098-209b-8f7e-93e49765f60b@cinbesa.com.br>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <c9f4b54a-7fd4-3355-a9cd-161b92e1ce15@cinbesa.com.br>
 <1464701636671-4677737.post@n4.nabble.com>
 <5d9049ba-b688-a22e-07d5-12b7da94dc8c@gmail.com>
 <931f91a3-51f4-6ff4-e781-4ed71964f527@cinbesa.com.br>
 <5cb41d75-387c-80af-fac6-e03a2570b0fa@gmail.com>
 <4fbad1c7-6a7f-b395-4824-08ec7add0a18@cinbesa.com.br>
 <6a67dd0e-80ae-ab5e-f353-2ec403ea6e75@gmail.com>
 <e21161a5-eef9-7b10-e4a5-0222d0e6756c@cinbesa.com.br>
 <4f72c4ab-6262-a62e-956b-a2721b0a59b7@gmail.com>
 <e4d31056-6099-205e-06b4-80dd001fdcd8@cinbesa.com.br>
 <20e8aba7-7d60-95d4-344b-c5d6060a84e6@treenet.co.nz>
 <5e843758-f098-209b-8f7e-93e49765f60b@cinbesa.com.br>
Message-ID: <a3f8b16f-751a-473e-b7b7-3dc866c3518b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
HTCP has the same function like ICP. So, this is predictable.


04.06.2016 3:20, Heiler Bemerguy ?????:
>
> Thanks Amos,
>
> I switched to HTCP but the same problem happens..
>
> 2016/06/03 18:14:00 kid3| Bug: Missing MemObject::storeId value
> 2016/06/03 18:14:00 kid3| mem_hdr: 0x72d3610 nodes.start() 0x5fc30d0
> 2016/06/03 18:14:00 kid3| mem_hdr: 0x72d3610 nodes.finish() 0x5fc30d0
> 2016/06/03 18:14:00 kid3| MemObject->start_ping: 0.000000
> 2016/06/03 18:14:00 kid3| MemObject->inmem_hi: 1045
> 2016/06/03 18:14:00 kid3| MemObject->inmem_lo: 0
> 2016/06/03 18:14:00 kid3| MemObject->nclients: 0
> 2016/06/03 18:14:00 kid3| MemObject->reply: 0x5d6cfe0
> 2016/06/03 18:14:00 kid3| MemObject->request: 0
> 2016/06/03 18:14:00 kid3| MemObject->logUri:
> 2016/06/03 18:14:00 kid3| MemObject->storeId:
> 2016/06/03 18:14:09.181 kid2| clientProcessHit: URL mismatch,
'[unknown_URI]' != 'http://www.agenciabelem.com.br/images/b_prev.png'
> 2016/06/03 18:14:20.965 kid3| clientProcessHit: URL mismatch,
'[unknown_URI]' !=
'http://s2.glbimg.com/Pj7LKnj1D91oGqBNbB9SdBqMVho=/155xorig/smart/filters:strip_icc()/s2.glbimg.com/f-Jk42TOoCN-_Og4XgSa88NPkBw=/19x10:289x233/155x128/s.glbimg.com/en/ho/f/original/2016/06/03/silvio.jpg'
> 2016/06/03 18:14:21 kid3| storeClientReadHeader: URL mismatch
> 2016/06/03 18:14:21 kid3|       {[unknown_URI]} !=
{http://c.api.globo.com/soccer_teams/ab.css}
>
> on access.log it shows this:
> 1464987925.060      0 10.1.10.101 UDP_HIT/000 0 HTCP_TST
http://s2.glbimg.com/Pj7LKnj1D91oGqBNbB9SdBqMVho=/155xorig/smart/filters:strip_icc()/s2.glbimg.com/f-Jk42TOoCN-_Og4XgSa88NPkBw=/19x10:289x233/155x128/s.glbimg.com/en/ho/f/original/2016/06/03/silvio.jpg
- HIER_NONE/- -
> 1464987925.062      1 10.1.10.101 TCP_IMS_HIT/304 256 GET
http://s2.glbimg.com/Pj7LKnj1D91oGqBNbB9SdBqMVho=/155xorig/smart/filters:strip_icc()/s2.glbimg.com/f-Jk42TOoCN-_Og4XgSa88NPkBw=/19x10:289x233/155x128/s.glbimg.com/en/ho/f/original/2016/06/03/silvio.jpg
- HIER_NONE/- image/jpeg
>
> I'm using some rock stores and 3 workers..
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXUfTqAAoJENNXIZxhPexGDmsH+wR1xkVXWlDkxVf06wR3fH8R
hoWGlth/IGd76aBRAWdsgQA+qKKj/nezBsQN8FDu+y/YgWomSlKMH6IaqLQMwqyA
tEfUsRmSpxv9RVNlqitPo9TuKxQIcPh2cJZPcEGmaPM5lbpF+6xjqzwJ8eiI1DUh
w5XuLJIvp4W7vHuwBRhcgisehVlcC9wq3WTHlj71Wx7C/1diJ80y9vI1oo7LVCUK
L4r2a4GL/spaENFMCzOi0jRlHQZIImYQy2U8z3SYtzaXDv2NoM2FY/6Vibv+SEII
feqOj2q18ye9gGMzqUe6Mkok/T3b8ws7ThuluFlLkg8q7IWNErehkyvCUFZ4fi8=
=917h
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160604/e50477a8/attachment.key>

From andrewm659 at yahoo.com  Fri Jun  3 22:51:48 2016
From: andrewm659 at yahoo.com (Andrew Meyer)
Date: Fri, 3 Jun 2016 22:51:48 +0000 (UTC)
Subject: [squid-users] logging and proxy pac file help
References: <2036326954.956510.1464994308430.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <2036326954.956510.1464994308430.JavaMail.yahoo@mail.yahoo.com>

So I have squid (latest) running in a a jail, and I am able to use it communicate with it via the browser. But I am trying to set it up so that I can use a proxy.pac file. I have the proxy.pac configured. Firefox is being used as my testbed. When I switch over the pac file I get nothing in the logs. Not sure why. ? Below is my config.
root at proxy:/usr/local/etc/squid # cat squid.conf
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8    # RFC1918 possible internal network
acl localnet src 172.16.0.0/12    # RFC1918 possible internal network
acl localnet src 192.168.0.0/16    # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80        # http
acl Safe_ports port 21        # ftp
acl Safe_ports port 443        # https
acl Safe_ports port 70        # gopher
acl Safe_ports port 210        # wais
acl Safe_ports port 1025-65535    # unregistered ports
acl Safe_ports port 280        # http-mgmt
acl Safe_ports port 488        # gss-http
acl Safe_ports port 591        # filemaker
acl Safe_ports port 777        # multiling http
acl CONNECT method CONNECT

acl our_networks src 10.150.1.0/24
#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager our_networks
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 3128

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /var/squid/cache 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/squid/cache

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:        1440    20%    10080
refresh_pattern ^gopher:    1440    0%    1440
refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
refresh_pattern .        0    20%    4320

visible_hostname proxy01.borg.local

access_log /var/log/squid/access.log squid
#logformat custom %{%Y-%m-%d %H:%M:%S}tl %03tu %>a %tr %ul %ui %>Hs %mt %rm %ru %rv %st %Sh %Ss
logformat squid %tl %6tr %>a %Ss/%03Hs %<st %rm %ru %un %Sh/%<A %mt
client_db on
dns_defnames on
httpd_suppress_version_string on
retry_on_error on
uri_whitespace strip
strip_query_terms off
#pipeline_prefetch on

cache deny all
#cache_dir null /tmp
ident_lookup_access deny all

## disable ads ( http://pgl.yoyo.org/adservers/ )
acl adsites url_regex -i "/usr/local/etc/squid/ad_block.txt"
http_access deny adsites
deny_info http://proxy.borg.local/blocked.html adsites
root at proxy:/usr/local/etc/squid # 

Proxy.pac

function FindProxyForURL(url, host) {
    //Don't proxy connections to the UTM web interface
    if (shExpMatch(url, "https://${asg_hostname}*")) return "DIRECT";
    if (shExpMatch(url, "https://" + dnsResolve(host) + "*")) return "DIRECT";
    //Exclude non-fqdn hosts from being proxied
    if (isPlainHostName(host)) return "DIRECT";
    //Don't proxy connections to the exempted URL matches
    if (shExpMatch(url, "*borg.local*")) return "DIRECT";
   if (isInNet(myIpAddress(), "10.150.0.0", "255.255.0.0"))        {return "PROXY proxy.borg.local:3128" ;}

    return "DIRECT";
}
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160603/5531127e/attachment.htm>

From yvoinov at gmail.com  Sat Jun  4 09:44:11 2016
From: yvoinov at gmail.com (Yuri)
Date: Sat, 4 Jun 2016 15:44:11 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
References: <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <04828faf-5f53-2f09-58ed-eac1b98b4257@treenet.co.nz>
 <38eeae01-c417-b703-0042-304dd5257407@gmail.com>
 <1464955611234-4677790.post@n4.nabble.com>
 <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>
 <1464975479587-4677792.post@n4.nabble.com>
 <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
Message-ID: <d5c74d63-9036-8f92-ed55-9d4e9a6561c9@gmail.com>

https://i1.someimage.com/rk2cwdN.png

Two times HIT increase on diagram - was client_side.cc changed.

But also some new problems occurs - partially, BBC video can't work 
after patch.

Need more research by dev team. If they want to made Squid which it must be.


04.06.2016 1:33, Yuri Voinov ?????:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>   
> Man, you right.
>
> You change dramatically increases HIT. Some checked sites with
> traditional low HIT ratio now caching.
>
> Wow.
>
>
> 03.06.2016 23:37, joe ?????:
>> i will just have to do patch i work direct on source if you want
>> i post  and its not regx yet and the sbuf routine the dev guys shuld do it
>> its missing function str.erase in sbuf i gess
>> not good for production untill somone do regx match  on  -->    %20 filter
>> out
>>
>> int
>> varyEvaluateMatch(StoreEntry * entry, HttpRequest * request)
>> {
>>      SBuf vary(request->vary_headers);
>>      int has_vary = entry->getReply()->header.has(HDR_VARY);
>> #if X_ACCELERATOR_VARY
>>      has_vary |=
>>          entry->getReply()->header.has(HDR_X_ACCELERATOR_VARY);
>> #endif
>>
>>
>>      if (!has_vary || entry->mem_obj->vary_headers.isEmpty()) {
>>          if (!vary.isEmpty()) {
>>              /* Oops... something odd is going on here.. */
>>              debugs(33, DBG_IMPORTANT, "varyEvaluateMatch: Oops. Not a Vary
>> object on second attempt, '" <<
>>                     entry->mem_obj->urlXXX() << "' '" << vary << "'");
>>              request->vary_headers.clear();
>>              return VARY_CANCEL;
>>          }
>>
>>          if (!has_vary) {
>>              /* This is not a varying object */
>>              return VARY_NONE;
>>          }
>>
>>          /* virtual "vary" object found. Calculate the vary key and
>>           * continue the search
>>           */
>>          vary = httpMakeVaryMark(request, entry->getReply());
>>
>>          if (!vary.isEmpty()) {
>>              request->vary_headers = vary;
>>              return VARY_OTHER;
>>          } else {
>>              /* Ouch.. we cannot handle this kind of variance */
>>              /* XXX This cannot really happen, but just to be complete */
>>              return VARY_CANCEL;
>>          }
>>      } else {
>>          if (vary.isEmpty()) {
>>              vary = httpMakeVaryMark(request, entry->getReply());
>>
>>              if (!vary.isEmpty())
>>                  request->vary_headers = vary;
>>          }
>> if (!vary.isEmpty()) {
>>          std::string t = vary.c_str();
>>
>>          std::string s = ",%20sdch";
>>          std::string::size_type i = t.find(s);
>>    if (i != std::string::npos){
>>       t.erase(i, s.length());
>>    }
>>
>>          std::string s1 = ",%20deflate";
>>          std::string::size_type i1 = t.find(s1);
>>
>>    if (i1 != std::string::npos){
>>       t.erase(i1, s1.length());
>>    }
>>
>>          std::string s2 = ",%20gzip";
>>          std::string::size_type i2 = t.find(s2);
>>
>>    if (i2 != std::string::npos){
>>       t.erase(i2, s2.length());
>>    }
>>
>>          std::string s3 = ",%20identity";
>>          std::string::size_type i3 = t.find(s3);
>>
>>    if (i3 != std::string::npos){
>>       t.erase(i3, s3.length());
>>    }
>>          vary=SBuf(t);
>>                return VARY_MATCH;
>> }
>>          if (vary.isEmpty()) {
>>              /* Ouch.. we cannot handle this kind of variance */
>>              /* XXX This cannot really happen, but just to be complete */
>>              return VARY_CANCEL;
>>          } else if (vary.cmp(entry->mem_obj->vary_headers) == 0) {
>>              return VARY_MATCH;
>>          } else {
>>              /* Oops.. we have already been here and still haven't
>>               * found the requested variant. Bail out
>>               */
>>
>>              debugs(33, DBG_IMPORTANT, "varyEvaluateMatch: Oops. Not a Vary
>> match on second attempt, '" <<
>>                     entry->mem_obj->urlXXX() << "' '" << vary << "'");
>>              return VARY_CANCEL;
>>          }
>>      }
>> }
>>
>>
>>
>> just replace the old function on client_side.cc  -->
> varyEvaluateMatch  with
>> the one i post  or i post later  the patch
>> dont lough im not pro but i do my home work
>>
>>
>>
>> --
>> View this message in context:
> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677792.html
>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>   
> iQEcBAEBCAAGBQJXUduWAAoJENNXIZxhPexGP1QH/2Fx0TWZrviMgFavyUsR6jXv
> LADswxk5iCEX20frmDCbIGXRgbmzvGwohYcAWR5aCPCyJxirvkmnSN4KP6it6D5b
> DuwrLVDcxBGg5CeR7ajRO9+yg/0r/MwF2NG7aLSa/ao+sxjJi+D+fRjxy5vQ3Ucq
> TrxjdZn119dbrVkiP8mljoK4pohvEFT07pbA30K0mf2olRg98TTQFOFSWTnnPnjf
> Lhpp60+o9h67p4ELBvAJ8yCloiFRs/2fljCpqDUkwIY74aIX/wjTfbh3+0VLNrYn
> V6GKJ0zpGyr7OcM9BawjfJcoyjMEUy1ZCN5Yf+vjtSqG/UydVbX9OwnhapSlk5U=
> =enzv
> -----END PGP SIGNATURE-----
>



From chip_pop at hotmail.com  Sat Jun  4 09:24:56 2016
From: chip_pop at hotmail.com (joe)
Date: Sat, 4 Jun 2016 02:24:56 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <d5c74d63-9036-8f92-ed55-9d4e9a6561c9@gmail.com>
References: <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <04828faf-5f53-2f09-58ed-eac1b98b4257@treenet.co.nz>
 <38eeae01-c417-b703-0042-304dd5257407@gmail.com>
 <1464955611234-4677790.post@n4.nabble.com>
 <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>
 <1464975479587-4677792.post@n4.nabble.com>
 <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
 <d5c74d63-9036-8f92-ed55-9d4e9a6561c9@gmail.com>
Message-ID: <1465032296833-4677801.post@n4.nabble.com>

any of those video link pls  i try it on bbc news video they work



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677801.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sat Jun  4 17:05:55 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 4 Jun 2016 23:05:55 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465032296833-4677801.post@n4.nabble.com>
References: <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <04828faf-5f53-2f09-58ed-eac1b98b4257@treenet.co.nz>
 <38eeae01-c417-b703-0042-304dd5257407@gmail.com>
 <1464955611234-4677790.post@n4.nabble.com>
 <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>
 <1464975479587-4677792.post@n4.nabble.com>
 <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
 <d5c74d63-9036-8f92-ed55-9d4e9a6561c9@gmail.com>
 <1465032296833-4677801.post@n4.nabble.com>
Message-ID: <c8b2e715-610a-4bd3-2ea9-b6f4a3712b65@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I suggests I know what is the reason to download video error. ;)


04.06.2016 15:24, joe ?????:
> any of those video link pls  i try it on bbc news video they work
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677801.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXUwpzAAoJENNXIZxhPexGY8QH/2apRTv0rOmiiqLWfnGy57Pt
CsPwr6XUD47nd+LFKI61IpIL9qaI9Y/4SdKM/TH5u/P28T+B7zdubbrL68oXiucj
8t+olerzMBVHXyap+jRiBalEg/2bNpynZTod16+d/6yunH6nI0dfOdoIm3D1ZsKT
l8xIjdgFhdIbt4EyXCv4M4Sgjh3fkhwihS8HExcsLRRrzZ/vd5etrmLFxZypJlb0
AAwKmbI5YVrf1cOkyoa6xyWObXMZ/FgDQXfDw3r3WbljYH/Eo8wvPvOwF/T7Rwgj
geRLxNyfwxiZ/2sPQnCtX6xFHz+jrPM6gsSM8XSGJTsLd02WZOSR2saF8fOkFsw=
=n1/B
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160604/2501041f/attachment.key>

From chip_pop at hotmail.com  Sat Jun  4 16:38:15 2016
From: chip_pop at hotmail.com (joe)
Date: Sat, 4 Jun 2016 09:38:15 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <c8b2e715-610a-4bd3-2ea9-b6f4a3712b65@gmail.com>
References: <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <04828faf-5f53-2f09-58ed-eac1b98b4257@treenet.co.nz>
 <38eeae01-c417-b703-0042-304dd5257407@gmail.com>
 <1464955611234-4677790.post@n4.nabble.com>
 <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>
 <1464975479587-4677792.post@n4.nabble.com>
 <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
 <d5c74d63-9036-8f92-ed55-9d4e9a6561c9@gmail.com>
 <1465032296833-4677801.post@n4.nabble.com>
 <c8b2e715-610a-4bd3-2ea9-b6f4a3712b65@gmail.com>
Message-ID: <1465058295328-4677804.post@n4.nabble.com>

what was it not my code right ??  i dont see anything to do with it



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677804.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sat Jun  4 17:24:05 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 4 Jun 2016 23:24:05 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465058295328-4677804.post@n4.nabble.com>
References: <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <04828faf-5f53-2f09-58ed-eac1b98b4257@treenet.co.nz>
 <38eeae01-c417-b703-0042-304dd5257407@gmail.com>
 <1464955611234-4677790.post@n4.nabble.com>
 <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>
 <1464975479587-4677792.post@n4.nabble.com>
 <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
 <d5c74d63-9036-8f92-ed55-9d4e9a6561c9@gmail.com>
 <1465032296833-4677801.post@n4.nabble.com>
 <c8b2e715-610a-4bd3-2ea9-b6f4a3712b65@gmail.com>
 <1465058295328-4677804.post@n4.nabble.com>
Message-ID: <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Code is right, need to make more clearly. Waiting for dev's. Results is
so good.

04.06.2016 22:38, joe ?????:
> what was it not my code right ??  i dont see anything to do with it
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677804.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXUw6zAAoJENNXIZxhPexGAUQH/1h5RF/WhiMnESEuhjlF3Oax
KGPZsvQ1dA/V3SGHXOCvLQaDRhvJ07bULqpzNT8dMWzGtzHlV2ta/aJS0AAgYRMS
97781g5O6Wxl2Xj1K4MgBg37n2i7r0TxKk1a6Kku1WU78jngTRS1+TMD2XKQ5+Nv
274J8svmWX2l5WGCDtwKPvnn3utmdes0NCbYp+jKjYpwzUhor6pAg0Xp56E+f45W
bYyvQM1l19F+bWL9jj1bky5Nt6rVX3BWZ6aLpWL6Oz5ixNd2SIAyt5gAG+/nEQgJ
628OR6RSoNX/QJA1SE5ukao6zItE0NIwCTWUH1N2h2ejPIamqz67GAakR5jzQxs=
=i3aG
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160604/32e4c611/attachment.key>

From chip_pop at hotmail.com  Sat Jun  4 16:51:33 2016
From: chip_pop at hotmail.com (joe)
Date: Sat, 4 Jun 2016 09:51:33 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
References: <38eeae01-c417-b703-0042-304dd5257407@gmail.com>
 <1464955611234-4677790.post@n4.nabble.com>
 <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>
 <1464975479587-4677792.post@n4.nabble.com>
 <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
 <d5c74d63-9036-8f92-ed55-9d4e9a6561c9@gmail.com>
 <1465032296833-4677801.post@n4.nabble.com>
 <c8b2e715-610a-4bd3-2ea9-b6f4a3712b65@gmail.com>
 <1465058295328-4677804.post@n4.nabble.com>
 <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
Message-ID: <1465059093431-4677806.post@n4.nabble.com>

im working on short regx i post wen i done  so will see if its faster :)



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677806.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sat Jun  4 17:37:59 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 4 Jun 2016 23:37:59 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465059093431-4677806.post@n4.nabble.com>
References: <38eeae01-c417-b703-0042-304dd5257407@gmail.com>
 <1464955611234-4677790.post@n4.nabble.com>
 <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>
 <1464975479587-4677792.post@n4.nabble.com>
 <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
 <d5c74d63-9036-8f92-ed55-9d4e9a6561c9@gmail.com>
 <1465032296833-4677801.post@n4.nabble.com>
 <c8b2e715-610a-4bd3-2ea9-b6f4a3712b65@gmail.com>
 <1465058295328-4677804.post@n4.nabble.com>
 <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
Message-ID: <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Hard luck. There is cool improvement which dev team must learn to.


04.06.2016 22:51, joe ?????:
> im working on short regx i post wen i done  so will see if its faster :)
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677806.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXUxH1AAoJENNXIZxhPexGzz8IAKbr0CHNeQu1SNoxkLakFzmJ
aYevCtTSn4IpBqstTlnxPRYiCt525vaDQ8Yau7O7gpiRlAR6SRj330qIx/Pj5qYE
BsMN9dgcKO13MHPS0GCPxFjikmtxp/x1tnGO7Bq/90sOqjJoqkMwLJlPtddrFb48
9qSEt5g7XANOTdGf3nwomHRYcFL3Xgz2KM2+YMVdmdKuMAbaDEoYo8EdAzlyRbKU
R/ps2KPYvbcwB1cqGvhZuB2CEDV1FKBSj/lz8fkF+BRHqT5keoW895DCS5+ZGhhO
y2cseOg46ui29lMJaCrvZRIN3UFXCZtONSxIaoe0XfxxIuk7n+noiigwrEsLypM=
=jC5f
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160604/73a72bb8/attachment.key>

From chip_pop at hotmail.com  Sat Jun  4 20:39:07 2016
From: chip_pop at hotmail.com (joe)
Date: Sat, 4 Jun 2016 13:39:07 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
References: <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>
 <1464975479587-4677792.post@n4.nabble.com>
 <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
 <d5c74d63-9036-8f92-ed55-9d4e9a6561c9@gmail.com>
 <1465032296833-4677801.post@n4.nabble.com>
 <c8b2e715-610a-4bd3-2ea9-b6f4a3712b65@gmail.com>
 <1465058295328-4677804.post@n4.nabble.com>
 <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
Message-ID: <1465072747768-4677808.post@n4.nabble.com>

Yuri can you test this pls if its better
--- src/client_side.cc	2016-05-25 02:27:13.000000000 +0300
+++ src/client_side.cc	2016-06-04 23:14:16.000000000 +0300
@@ -140,7 +140,7 @@
 #if LINGERING_CLOSE
 #define comm_close comm_lingering_close
 #endif
-
+#include <regex>
 /// dials clientListenerConnectionOpened call
 class ListeningStartedDialer: public CallDialer, public
Ipc::StartListeningCb
 {
@@ -4738,6 +4738,17 @@
             if (!vary.isEmpty())
                 request->vary_headers = vary;
         }
+        /* new test in vary header there is unwanted mark deed code wish is
marked with %20 tell the browser not to use */
+        /* and its affecting the cache for cache hit %   if you use 2
browser example Firefox and chrome and load object */
+        /* that has vary --> accept-encoding="gzip,%20deflate,%20sdch */
+        /* second browser use the same object link and has different
accept-encoding="gzip,%20deflate" */
+        /* as you notice they do not match so result miss and it delete the
previous object from the cache */
+        /* the new code should filter out those marked with %20 the
different is really big in % hit */ 
+        if (!vary.isEmpty()) {
+            std::regex e ("\\b(,%20)(.*)([,\"]$)");   
+            vary=SBuf(std::regex_replace (vary.c_str(),e,"")+"\"");
+             return VARY_MATCH;
+        }
 
         if (vary.isEmpty()) {
             /* Ouch.. we cannot handle this kind of variance */



please guys its not for production migh have a different affect or bug only
test wen the dev team approve it or make a better vertion 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677808.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sat Jun  4 21:20:27 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 5 Jun 2016 03:20:27 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465072747768-4677808.post@n4.nabble.com>
References: <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>
 <1464975479587-4677792.post@n4.nabble.com>
 <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
 <d5c74d63-9036-8f92-ed55-9d4e9a6561c9@gmail.com>
 <1465032296833-4677801.post@n4.nabble.com>
 <c8b2e715-610a-4bd3-2ea9-b6f4a3712b65@gmail.com>
 <1465058295328-4677804.post@n4.nabble.com>
 <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
Message-ID: <d5344d37-59f6-7f17-2fbd-4c53cf878277@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Well, will test.


05.06.2016 2:39, joe ?????:
> --- src/client_side.cc    2016-05-25 02:27:13.000000000 +0300
> +++ src/client_side.cc    2016-06-04 23:14:16.000000000 +0300
> @@ -140,7 +140,7 @@
>  #if LINGERING_CLOSE
>  #define comm_close comm_lingering_close
>  #endif
> -
> +#include <regex>
>  /// dials clientListenerConnectionOpened call
>  class ListeningStartedDialer: public CallDialer, public
> Ipc::StartListeningCb
>  {
> @@ -4738,6 +4738,17 @@
>              if (!vary.isEmpty())
>                  request->vary_headers = vary;
>          }
> +        /* new test in vary header there is unwanted mark deed code
wish is
> marked with %20 tell the browser not to use */
> +        /* and its affecting the cache for cache hit %   if you use 2
> browser example Firefox and chrome and load object */
> +        /* that has vary --> accept-encoding="gzip,%20deflate,%20sdch */
> +        /* second browser use the same object link and has different
> accept-encoding="gzip,%20deflate" */
> +        /* as you notice they do not match so result miss and it
delete the
> previous object from the cache */
> +        /* the new code should filter out those marked with %20 the
> different is really big in % hit */
> +        if (!vary.isEmpty()) {
> +            std::regex e ("\\b(,%20)(.*)([,\"]$)");  
> +            vary=SBuf(std::regex_replace (vary.c_str(),e,"")+"\"");
> +             return VARY_MATCH;
> +        }
> 
>          if (vary.isEmpty()) {
>              /* Ouch.. we cannot handle this kind of variance */

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXU0YbAAoJENNXIZxhPexGkJYIALjp4bMdOKGyR8zx2Rc+OeRF
hlg9YTDIhCPRL3fGqg1MktgZBAyiQzgZ+Nig72efKXTTXW6PU9mNskGYVfjsb45T
DBkUC0GnrIBNGQHMzdIniO1U+lYkl8H/7a+KnUutGsICJfUjJCkI+7fV9YGjQInl
fFv/D04au/da4Zd/bPzJTKRIbRrMNYj6I4LzXwBSxW+0ppWsya/utZX328Q73hFD
CnHf7YP1P2fW7mxsaBkbdVtlOKuLKJjnJHOh1KKgl5NZ3GWEHsyoElTkKeu9uU9+
h1M0cAkv39ryawYFywXhNqeSm+tUBBKKkFGge+UlOB/vjFPPT2WX2859UIid14M=
=KROn
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160605/91d9f503/attachment.key>

From yvoinov at gmail.com  Sun Jun  5 09:03:00 2016
From: yvoinov at gmail.com (Yuri)
Date: Sun, 5 Jun 2016 15:03:00 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465072747768-4677808.post@n4.nabble.com>
References: <afa6bcaa-024f-6321-de69-3f1f9e41d568@gmail.com>
 <1464975479587-4677792.post@n4.nabble.com>
 <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
 <d5c74d63-9036-8f92-ed55-9d4e9a6561c9@gmail.com>
 <1465032296833-4677801.post@n4.nabble.com>
 <c8b2e715-610a-4bd3-2ea9-b6f4a3712b65@gmail.com>
 <1465058295328-4677804.post@n4.nabble.com>
 <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
Message-ID: <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>

Build with this patch now.

Correctly formatted patch attached.

05.06.2016 2:39, joe ?????:
> Yuri can you test this pls if its better
> --- src/client_side.cc	2016-05-25 02:27:13.000000000 +0300
> +++ src/client_side.cc	2016-06-04 23:14:16.000000000 +0300
> @@ -140,7 +140,7 @@
>   #if LINGERING_CLOSE
>   #define comm_close comm_lingering_close
>   #endif
> -
> +#include <regex>
>   /// dials clientListenerConnectionOpened call
>   class ListeningStartedDialer: public CallDialer, public
> Ipc::StartListeningCb
>   {
> @@ -4738,6 +4738,17 @@
>               if (!vary.isEmpty())
>                   request->vary_headers = vary;
>           }
> +        /* new test in vary header there is unwanted mark deed code wish is
> marked with %20 tell the browser not to use */
> +        /* and its affecting the cache for cache hit %   if you use 2
> browser example Firefox and chrome and load object */
> +        /* that has vary --> accept-encoding="gzip,%20deflate,%20sdch */
> +        /* second browser use the same object link and has different
> accept-encoding="gzip,%20deflate" */
> +        /* as you notice they do not match so result miss and it delete the
> previous object from the cache */
> +        /* the new code should filter out those marked with %20 the
> different is really big in % hit */
> +        if (!vary.isEmpty()) {
> +            std::regex e ("\\b(,%20)(.*)([,\"]$)");
> +            vary=SBuf(std::regex_replace (vary.c_str(),e,"")+"\"");
> +             return VARY_MATCH;
> +        }
>   
>           if (vary.isEmpty()) {
>               /* Ouch.. we cannot handle this kind of variance */
>
>
>
> please guys its not for production migh have a different affect or bug only
> test wen the dev team approve it or make a better vertion
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677808.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
???--- src/client_side.cc	2016-05-25 02:27:13.000000000 +0300
+++ src/client_side.cc	2016-06-04 23:14:16.000000000 +0300
@@ -140,7 +140,7 @@
 #if LINGERING_CLOSE
 #define comm_close comm_lingering_close
 #endif
-
+#include <regex>
 /// dials clientListenerConnectionOpened call
 class ListeningStartedDialer: public CallDialer, public Ipc::StartListeningCb
 {
@@ -4738,6 +4738,17 @@
             if (!vary.isEmpty())
                 request->vary_headers = vary;
         }
+        /* new test in vary header there is unwanted mark deed code wish is marked with %20 tell the browser not to use */
+        /* and its affecting the cache for cache hit %   if you use 2 browser example Firefox and chrome and load object */
+        /* that has vary --> accept-encoding="gzip,%20deflate,%20sdch */
+        /* second browser use the same object link and has different accept-encoding="gzip,%20deflate" */
+        /* as you notice they do not match so result miss and it delete the previous object from the cache */
+        /* the new code should filter out those marked with %20 the different is really big in % hit */
+        if (!vary.isEmpty()) {
+            std::regex e ("\\b(,%20)(.*)([,\"]$)");
+            vary=SBuf(std::regex_replace (vary.c_str(),e,"")+"\"");
+             return VARY_MATCH;
+        }

         if (vary.isEmpty()) {
             /* Ouch.. we cannot handle this kind of variance */

From admin at dokter-squid.com  Sun Jun  5 08:31:20 2016
From: admin at dokter-squid.com (Dhani-Dhanu)
Date: Sun, 5 Jun 2016 01:31:20 -0700 (PDT)
Subject: [squid-users] Problem - Marking TOS HIT on SmpCarpCluster
In-Reply-To: <1464862706504-4677773.post@n4.nabble.com>
References: <1464862706504-4677773.post@n4.nabble.com>
Message-ID: <1465115480698-4677811.post@n4.nabble.com>

Up



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Problem-Marking-TOS-HIT-on-SmpCarpCluster-tp4677773p4677811.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From admin at dokter-squid.com  Sun Jun  5 08:37:56 2016
From: admin at dokter-squid.com (Dhani-Dhanu)
Date: Sun, 5 Jun 2016 01:37:56 -0700 (PDT)
Subject: [squid-users] How to mark HIT using qos_flow in squid mode
	SmpCarpCluster
Message-ID: <1465115876765-4677812.post@n4.nabble.com>

Hallo

First, i would to say thanks you for Support..

second, i have running squid 3.5.19 with SmpCarpCluster..And work very nice
and nothing problem.

But i need to Bypass Cache HIT with qos_flows. On Standar Config qos_flows
working as well, but on SmpCarpCluster qos_flow not work.

Can anyone would to help me to info regarding this issue?

Nb:
i just following running squid with this article
http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster


Thanks you for aswer

Regards 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-to-mark-HIT-using-qos-flow-in-squid-mode-SmpCarpCluster-tp4677812.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Sun Jun  5 09:10:36 2016
From: chip_pop at hotmail.com (joe)
Date: Sun, 5 Jun 2016 02:10:36 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
References: <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
 <d5c74d63-9036-8f92-ed55-9d4e9a6561c9@gmail.com>
 <1465032296833-4677801.post@n4.nabble.com>
 <c8b2e715-610a-4bd3-2ea9-b6f4a3712b65@gmail.com>
 <1465058295328-4677804.post@n4.nabble.com>
 <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
Message-ID: <1465117836635-4677813.post@n4.nabble.com>

what is the best way to create patch
im using this
diff -Naur /var/tmp/squid-3.5.19-20160524-r14057
/var/tmp/squid-3.5.19-20160524-r14057-tst > squid-3.5.19-vary-1.patch
any better way  ??



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677813.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sun Jun  5 10:13:38 2016
From: yvoinov at gmail.com (Yuri)
Date: Sun, 5 Jun 2016 16:13:38 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465117836635-4677813.post@n4.nabble.com>
References: <0de88873-53a5-14f6-5c98-93aa252c682b@gmail.com>
 <d5c74d63-9036-8f92-ed55-9d4e9a6561c9@gmail.com>
 <1465032296833-4677801.post@n4.nabble.com>
 <c8b2e715-610a-4bd3-2ea9-b6f4a3712b65@gmail.com>
 <1465058295328-4677804.post@n4.nabble.com>
 <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
Message-ID: <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>

Don't think so. Patch looks good and working. Now testing.

Results is perfect - byte HIT increases two times minimum.

Squid looks it must be. It is real CACHE now.


05.06.2016 15:10, joe ?????:
> what is the best way to create patch
> im using this
> diff -Naur /var/tmp/squid-3.5.19-20160524-r14057
> /var/tmp/squid-3.5.19-20160524-r14057-tst > squid-3.5.19-vary-1.patch
> any better way  ??
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677813.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From uhlar at fantomas.sk  Sun Jun  5 11:29:37 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sun, 5 Jun 2016 13:29:37 +0200
Subject: [squid-users] logging and proxy pac file help
In-Reply-To: <2036326954.956510.1464994308430.JavaMail.yahoo@mail.yahoo.com>
References: <2036326954.956510.1464994308430.JavaMail.yahoo.ref@mail.yahoo.com>
 <2036326954.956510.1464994308430.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <20160605112937.GA16573@fantomas.sk>

On 03.06.16 22:51, Andrew Meyer wrote:
>So I have squid (latest) running in a a jail, and I am able to use it
>communicate with it via the browser.  But I am trying to set it up so that
>I can use a proxy.pac file.  I have the proxy.pac configured.  Firefox is
>being used as my testbed.  When I switch over the pac file I get nothing in
>the logs.  Not sure why.  ? Below is my config. 

a PAC / WPAD file has nothing top do with squid, especially when you see
nothing in squid logs. you need to debug your pac file.
if you're using mosilla, check out javascript console if it reports any
problm with your PAC file.

>function FindProxyForURL(url, host) {
>    //Don't proxy connections to the UTM web interface
>    if (shExpMatch(url, "https://${asg_hostname}*")) return "DIRECT";
>    if (shExpMatch(url, "https://" + dnsResolve(host) + "*")) return "DIRECT";
>    //Exclude non-fqdn hosts from being proxied
>    if (isPlainHostName(host)) return "DIRECT";
>    //Don't proxy connections to the exempted URL matches
>    if (shExpMatch(url, "*borg.local*")) return "DIRECT";
>   if (isInNet(myIpAddress(), "10.150.0.0", "255.255.0.0"))        {return "PROXY proxy.borg.local:3128" ;}
>
>    return "DIRECT";
>}

what's ${asg_hostname} ?

...I find interesting that you use proxy for 10.150.0.0/16 but not for the
internet, I would expect just the opposite.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Micro$oft random number generator: 0, 0, 0, 4.33e+67, 0, 0, 0...


From chip_pop at hotmail.com  Sun Jun  5 11:58:59 2016
From: chip_pop at hotmail.com (joe)
Date: Sun, 5 Jun 2016 04:58:59 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
References: <1465032296833-4677801.post@n4.nabble.com>
 <c8b2e715-610a-4bd3-2ea9-b6f4a3712b65@gmail.com>
 <1465058295328-4677804.post@n4.nabble.com>
 <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
Message-ID: <1465127939005-4677816.post@n4.nabble.com>

tks   i found a smole bug  i will fix it on some vary its adding  extra  "  
at the end 

'accept-encoding="gzip"'            <-- this is fine
'accept="image%2Fwebp,image%2F*,*%2F*%3Bq%3D0.8""'   <--- this has extra
Quotation marks

i post the fix later



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677816.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Sun Jun  5 16:21:16 2016
From: chip_pop at hotmail.com (joe)
Date: Sun, 5 Jun 2016 09:21:16 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
References: <1465032296833-4677801.post@n4.nabble.com>
 <c8b2e715-610a-4bd3-2ea9-b6f4a3712b65@gmail.com>
 <1465058295328-4677804.post@n4.nabble.com>
 <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
Message-ID: <1465143676779-4677817.post@n4.nabble.com>

Quotation marks  at the end fixed

--- src/client_side.cc	2016-05-25 02:27:13.000000000 +0300
+++ src/client_side.cc	2016-06-05 18:57:50.000000000 +0300
@@ -140,7 +140,7 @@
 #if LINGERING_CLOSE
 #define comm_close comm_lingering_close
 #endif
-
+#include <regex>
 /// dials clientListenerConnectionOpened call
 class ListeningStartedDialer: public CallDialer, public
Ipc::StartListeningCb
 {
@@ -4738,6 +4738,22 @@
             if (!vary.isEmpty())
                 request->vary_headers = vary;
         }
+        /* new test in vary header there is unwanted mark deed code wish is
marked with %20 tell the browser not to use */
+        /* and its affecting the cache for cache hit %   if you use 2
browser example Firefox and chrome and load object */
+        /* that has vary --> accept-encoding="gzip,%20deflate,%20sdch */
+        /* second browser use the same object link and has different
accept-encoding="gzip,%20deflate" */
+        /* as you notice they do not match so result miss and it delete the
previous object from the cache */
+        /* the new code should filter out those marked with %20 the
different is really big in % hit */ 
+        if (!vary.isEmpty()) {
+            std::regex e ("\\b(,%20)(.*)([,\"]$)");  
+            std::string str1 = std::regex_replace (vary.c_str(),e,"")+"\"";
+            if (str1.find("\"\"") != std::string::npos) {
+               str1.erase(str1.begin() + str1.size() - 1);
+            } else {
+            vary=SBuf(str1);
+            }
+             return VARY_MATCH;
+        }
 
         if (vary.isEmpty()) {
             /* Ouch.. we cannot handle this kind of variance */




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677817.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Sun Jun  5 16:28:51 2016
From: chip_pop at hotmail.com (joe)
Date: Sun, 5 Jun 2016 09:28:51 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465127939005-4677816.post@n4.nabble.com>
References: <c8b2e715-610a-4bd3-2ea9-b6f4a3712b65@gmail.com>
 <1465058295328-4677804.post@n4.nabble.com>
 <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
Message-ID: <1465144131189-4677818.post@n4.nabble.com>

Quotation marks fix

--- src/client_side.cc	2016-05-25 02:27:13.000000000 +0300
+++ src/client_side.cc	2016-06-05 19:04:07.000000000 +0300
@@ -140,7 +140,7 @@
 #if LINGERING_CLOSE
 #define comm_close comm_lingering_close
 #endif
-
+#include <regex>
 /// dials clientListenerConnectionOpened call
 class ListeningStartedDialer: public CallDialer, public
Ipc::StartListeningCb
 {
@@ -4738,6 +4738,23 @@
             if (!vary.isEmpty())
                 request->vary_headers = vary;
         }
+        /* new test in vary header there is unwanted mark deed code wish is
marked with %20 tell the browser not to use */
+        /* and its affecting the cache for cache hit %   if you use 2
browser example Firefox and chrome and load object */
+        /* that has vary --> accept-encoding="gzip,%20deflate,%20sdch */
+        /* second browser use the same object link and has different
accept-encoding="gzip,%20deflate" */
+        /* as you notice they do not match so result miss and it delete the
previous object from the cache */
+        /* the new code should filter out those marked with %20 the
different is really big in % hit */ 
+        if (!vary.isEmpty()) {
+            std::regex e ("\\b(,%20)(.*)([,\"]$)");  
+            std::string str1 = std::regex_replace (vary.c_str(),e,"")+"\"";
+            if (str1.find("\"\"") != std::string::npos) {
+               str1.erase(str1.begin() + str1.size() - 1);
+               vary=SBuf(str1);
+            } else {
+               vary=SBuf(str1);
+            }
+             return VARY_MATCH;
+        }
 
         if (vary.isEmpty()) {
             /* Ouch.. we cannot handle this kind of variance */



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677818.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sun Jun  5 18:17:48 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 6 Jun 2016 00:17:48 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465144131189-4677818.post@n4.nabble.com>
References: <c8b2e715-610a-4bd3-2ea9-b6f4a3712b65@gmail.com>
 <1465058295328-4677804.post@n4.nabble.com>
 <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
Message-ID: <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Properly formatted patch.


05.06.2016 22:28, joe ?????:
> Quotation marks fix
>
> --- src/client_side.cc    2016-05-25 02:27:13.000000000 +0300
> +++ src/client_side.cc    2016-06-05 19:04:07.000000000 +0300
> @@ -140,7 +140,7 @@
>  #if LINGERING_CLOSE
>  #define comm_close comm_lingering_close
>  #endif
> -
> +#include <regex>
>  /// dials clientListenerConnectionOpened call
>  class ListeningStartedDialer: public CallDialer, public
> Ipc::StartListeningCb
>  {
> @@ -4738,6 +4738,23 @@
>              if (!vary.isEmpty())
>                  request->vary_headers = vary;
>          }
> +        /* new test in vary header there is unwanted mark deed code
wish is
> marked with %20 tell the browser not to use */
> +        /* and its affecting the cache for cache hit %   if you use 2
> browser example Firefox and chrome and load object */
> +        /* that has vary --> accept-encoding="gzip,%20deflate,%20sdch */
> +        /* second browser use the same object link and has different
> accept-encoding="gzip,%20deflate" */
> +        /* as you notice they do not match so result miss and it
delete the
> previous object from the cache */
> +        /* the new code should filter out those marked with %20 the
> different is really big in % hit */
> +        if (!vary.isEmpty()) {
> +            std::regex e ("\\b(,%20)(.*)([,\"]$)"); 
> +            std::string str1 = std::regex_replace
(vary.c_str(),e,"")+"\"";
> +            if (str1.find("\"\"") != std::string::npos) {
> +               str1.erase(str1.begin() + str1.size() - 1);
> +               vary=SBuf(str1);
> +            } else {
> +               vary=SBuf(str1);
> +            }
> +             return VARY_MATCH;
> +        }
> 
>          if (vary.isEmpty()) {
>              /* Ouch.. we cannot handle this kind of variance */
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677818.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVGzMAAoJENNXIZxhPexGji0H/2h991uHwX/wweYc7rgeqGwk
hT53tn0WrNWZxp2DKXT14Hq4m8HEbuP9KPLedEwbqDx/sXZOf/Flw9CxSEMLB16T
+SjMxCSDa9je6/3ego5aAg26jRwfebO6VD+BdOQs+ZYVb/RWcONCWZyhJbfuR5ik
PSwr8ar8tkpsolyCAPwdvnjEuFvnuESxfGVMdQCzDJEo8CUFrp3JaOK2TMsNG3a/
6z4QJ0SFJiRKq7fmkrV8Z4I2uaPE6I21KX4k9eYglz1771+CiegCjp/BslqBovuv
Bj0B+Pz98+6wC9eMguVviFqT2Huc16V8QWOwLfzkq+it/cYGnOKuSKh9L6dmGf0=
=gIpI
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: vary_experimental2.patch
Type: text/x-patch
Size: 1670 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/5e6a018b/attachment.bin>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/5e6a018b/attachment.key>

From squid.support at jumpstation.co.uk  Sun Jun  5 20:19:50 2016
From: squid.support at jumpstation.co.uk (squid.support at jumpstation.co.uk)
Date: Sun, 5 Jun 2016 21:19:50 +0100
Subject: [squid-users] can I turn a http transparent proxy into a https(self
	cert)?
In-Reply-To: <mailman.0.1465143102.17746.squid-users@lists.squid-cache.org>
References: <mailman.0.1465143102.17746.squid-users@lists.squid-cache.org>
Message-ID: <20160605211950.2eca67b0@phen264>

Hi,

Trying to use Squid 3.5 to filter a white list on wifi hotspot. Got
http support without issue.

Tried lots of things to get https to work but always kills http, all
the http requests time out.

So I am starting to think that maybe

http 3128 transparent

is not compatible with ssl_bump

is that true?

Squid 3.5 built from source with

./configure --prefix=/usr \
--localstatedir=/var \
--libexecdir=${prefix}/lib/squid3 \
--datadir=${prefix}/share/squid3 \
--sysconfdir=/etc/squid3 \
--with-default-user=proxy \
--with-logdir=/var/log/squid3 \
--with-pidfile=/var/run/squid3.pid \
--enable-ssl \
--with-openssl \
--enable-ssl-crtd \
--with-open-ssl=/etc/ssl/openssl.cnf 





From yvoinov at gmail.com  Sun Jun  5 20:26:02 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 6 Jun 2016 02:26:02 +0600
Subject: [squid-users] can I turn a http transparent proxy into a
 https(self cert)?
In-Reply-To: <20160605211950.2eca67b0@phen264>
References: <mailman.0.1465143102.17746.squid-users@lists.squid-cache.org>
 <20160605211950.2eca67b0@phen264>
Message-ID: <c6e4caf1-3e80-fb81-a5fa-6d1fb2f254d9@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
False. You doing it wrong.


06.06.2016 2:19, squid.support at jumpstation.co.uk ?????:
> Hi,
>
> Trying to use Squid 3.5 to filter a white list on wifi hotspot. Got
> http support without issue.
>
> Tried lots of things to get https to work but always kills http, all
> the http requests time out.
>
> So I am starting to think that maybe
>
> http 3128 transparent
>
> is not compatible with ssl_bump
>
> is that true?
>
> Squid 3.5 built from source with
>
> ./configure --prefix=/usr \
> --localstatedir=/var \
> --libexecdir=${prefix}/lib/squid3 \
> --datadir=${prefix}/share/squid3 \
> --sysconfdir=/etc/squid3 \
> --with-default-user=proxy \
> --with-logdir=/var/log/squid3 \
> --with-pidfile=/var/run/squid3.pid \
> --enable-ssl \
> --with-openssl \
> --enable-ssl-crtd \
> --with-open-ssl=/etc/ssl/openssl.cnf
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVIraAAoJENNXIZxhPexGWTkH/Rxj+F0KT0WBVxsNgcFCS5hW
ycMTq3bFQfpACLyhetfEahnR6EioYEwDgMQYE/MfUJaIa+U9yKAlAoXqftQ75QmK
krarLErbe2Y7cA/WEaoW83L8Arzh2Liz91tkSn/tXFWP3Jw1ZQnhOJj2jXIdabhy
76fU2Xh8K1C/RdMOil6yXvdu9HR5/Q4xHWHGYz/CjS5pDEF7Kbm0SNi1FtNF2DYl
i3N9o5JuAK7orgTwCHAGE0ARfNMbO7puBgOvs1aU4H9x3Wj9mFpoeJxFGuC/50Vv
LSymxQWc70G+yusZWLthTf92q3ehDb0bXYlpP0BsxIbWsSZR8Pm0a+yj37U2iJw=
=2+Kc
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/ab79698d/attachment.key>

From yvoinov at gmail.com  Sun Jun  5 20:31:20 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 6 Jun 2016 02:31:20 +0600
Subject: [squid-users] can I turn a http transparent proxy into a
 https(self cert)?
In-Reply-To: <20160605211950.2eca67b0@phen264>
References: <mailman.0.1465143102.17746.squid-users@lists.squid-cache.org>
 <20160605211950.2eca67b0@phen264>
Message-ID: <360a1a86-c607-a4e8-9235-9de1d929094a@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Start from here:

http://wiki.squid-cache.org/ConfigExamples#Interception

Wiki contains most you need. Just read it.


06.06.2016 2:19, squid.support at jumpstation.co.uk ?????:
> Hi,
>
> Trying to use Squid 3.5 to filter a white list on wifi hotspot. Got
> http support without issue.
>
> Tried lots of things to get https to work but always kills http, all
> the http requests time out.
>
> So I am starting to think that maybe
>
> http 3128 transparent
>
> is not compatible with ssl_bump
>
> is that true?
>
> Squid 3.5 built from source with
>
> ./configure --prefix=/usr \
> --localstatedir=/var \
> --libexecdir=${prefix}/lib/squid3 \
> --datadir=${prefix}/share/squid3 \
> --sysconfdir=/etc/squid3 \
> --with-default-user=proxy \
> --with-logdir=/var/log/squid3 \
> --with-pidfile=/var/run/squid3.pid \
> --enable-ssl \
> --with-openssl \
> --enable-ssl-crtd \
> --with-open-ssl=/etc/ssl/openssl.cnf
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVIwXAAoJENNXIZxhPexGX/oH/3BTOAE+SBl1JfSUjQhzUKru
ypoAdaoE5X4MTo0XRaqwZZWVDLaFtjc6jcUEDOF95yuzuyjFlDmmDSqHcjI6vgLt
5UkjEcYQNcstdOqyJeAX9sVBtdO6M9wubil0Qmg2UrT2M6nmkmFx00G1mKpiSTES
Qm9MKRXrO5QH3ks0qCqcsaZHlOdX9DxH5M4pAQtQTsVDVZWWneJvfCvxx76NvLt5
1eUDcOkmiVcj7jbuEO31smOBjJYQ0xaTBmw1KbFqqAHRn66/TvDihUIuJ+O54QIi
EqTHtZiYzsmfS90Z3w+YxsiIqSUlYIaMvv6Ave9KRwWpwvjHqGlZiSUno4DyNdc=
=mJlr
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/b3fe918a/attachment.key>

From chip_pop at hotmail.com  Sun Jun  5 20:42:09 2016
From: chip_pop at hotmail.com (joe)
Date: Sun, 5 Jun 2016 13:42:09 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
References: <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
Message-ID: <1465159329064-4677823.post@n4.nabble.com>

im re writing the varyEvaluateMatch function 
will see after i done test with new one 
for now last patch is good enough until the new function has less code
faster and no bug
hoop dev team give us more hint or beter way



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677823.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sun Jun  5 21:40:17 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 6 Jun 2016 03:40:17 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465159329064-4677823.post@n4.nabble.com>
References: <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
Message-ID: <7079d8ef-beb8-c46c-4e7c-a78cbeba65f8@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Sure. Current function works slower with collapsed_forwarding enabled.


06.06.2016 2:42, joe ?????:
> im re writing the varyEvaluateMatch function > will see after i done test with new one > for now last patch is good
enough until the new function has less code > faster and no bug > hoop
dev team give us more hint or beter way > > > > -- > View this message
in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677823.html
> Sent from the Squid - Users mailing list archive at Nabble.com. >
_______________________________________________ > squid-users mailing
list > squid-users at lists.squid-cache.org >
http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVJxAAAoJENNXIZxhPexGxqoH/0w0Ms7wTGl8kg25jgxkneb9
QfZft9bVAz4C/1MeTaWvYRMqJX79fYDQ+QJb+gHDyRXrZ1x1wFWgm2fnEGGQSEzO
JXWey/HRhiaC/GqSSNlwibKJM8fRh1tKsdmKtAeB4Py+X1Pm3MonbIbpd04z5rFR
7NprTM5bz41EfCy2rvkjKyyE0zVz2C7YT6OQr6rNASXBCvzoHEeomqUbHW+VZqiv
oMHiUqPH0oGYvnUgatUt0QB7r73DIOoT/Y2EytqCN6AWKvCRe0j7NNiT75Nm9s48
CFaFNRYqxkDCntoBEHGWpH+BIQQai4HxSKugGg1DiAfkTIh7BtpIEpI2JmFFSPA=
=7KVb
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/156a15eb/attachment.key>

From yvoinov at gmail.com  Sun Jun  5 21:40:17 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 6 Jun 2016 03:40:17 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465159329064-4677823.post@n4.nabble.com>
References: <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
Message-ID: <67ace30c-e491-318e-4cc0-5bcad25472e0@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Sure. Current function works slower with collapsed_forwarding enabled.


06.06.2016 2:42, joe ?????:
> im re writing the varyEvaluateMatch function
> will see after i done test with new one
> for now last patch is good enough until the new function has less code
> faster and no bug
> hoop dev team give us more hint or beter way
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677823.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVJxAAAoJENNXIZxhPexGxqoH/0w0Ms7wTGl8kg25jgxkneb9
QfZft9bVAz4C/1MeTaWvYRMqJX79fYDQ+QJb+gHDyRXrZ1x1wFWgm2fnEGGQSEzO
JXWey/HRhiaC/GqSSNlwibKJM8fRh1tKsdmKtAeB4Py+X1Pm3MonbIbpd04z5rFR
7NprTM5bz41EfCy2rvkjKyyE0zVz2C7YT6OQr6rNASXBCvzoHEeomqUbHW+VZqiv
oMHiUqPH0oGYvnUgatUt0QB7r73DIOoT/Y2EytqCN6AWKvCRe0j7NNiT75Nm9s48
CFaFNRYqxkDCntoBEHGWpH+BIQQai4HxSKugGg1DiAfkTIh7BtpIEpI2JmFFSPA=
=7KVb
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/18099481/attachment.key>

From squid3 at treenet.co.nz  Mon Jun  6 00:02:08 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 6 Jun 2016 12:02:08 +1200
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465159329064-4677823.post@n4.nabble.com>
References: <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
Message-ID: <87674423-4c25-0a90-2248-db64178025e5@treenet.co.nz>

On 6/06/2016 8:42 a.m., joe wrote:
> im re writing the varyEvaluateMatch function 
> will see after i done test with new one 
> for now last patch is good enough until the new function has less code
> faster and no bug
> hoop dev team give us more hint or beter way

Just deleting the Accept-* headers entirely on all incoming messages
will do the same thing and be faster.

Amos



From fredbmail at free.fr  Mon Jun  6 07:27:43 2016
From: fredbmail at free.fr (FredB)
Date: Mon, 6 Jun 2016 09:27:43 +0200 (CEST)
Subject: [squid-users] Squid high memory usage
In-Reply-To: <786462611.242504103.1464966199233.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <507114692.248903888.1465198063421.JavaMail.root@zimbra4-e1.priv.proxad.net>

Hello all,
 
I'm trying to use a server with 64 Go of ram, but I'm faced with a problem, squid can't works with more than 50% of memory
After that the swap is totally full and kswap process gone mad ...
I tried with vm.swappiness = 0 but same problem, perhaps a little better, I also tried memory_pool off without any change.

As you can see in this picture linux are using 22 Go of cached memory
http://image.noelshack.com/fichiers/2016/22/1464965449-capture-squid.png
  
I'm using two caches (133 G each)with a dedicated sata (15 k) disk for each cache
Any advice will be very appreciate
 
OS Debian Jessie 64 bits and squid 3.5.19

Fred


From yvoinov at gmail.com  Mon Jun  6 08:10:47 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 6 Jun 2016 14:10:47 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <87674423-4c25-0a90-2248-db64178025e5@treenet.co.nz>
References: <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <87674423-4c25-0a90-2248-db64178025e5@treenet.co.nz>
Message-ID: <82d90a89-b6ad-0d56-bfe6-4e7dcc19f23b@gmail.com>

Heh,

and breaking Internet...

So, for example, my Squid's built with ecap gzip support. What will be 
result?


06.06.2016 6:02, Amos Jeffries ?????:
> On 6/06/2016 8:42 a.m., joe wrote:
>> im re writing the varyEvaluateMatch function
>> will see after i done test with new one
>> for now last patch is good enough until the new function has less code
>> faster and no bug
>> hoop dev team give us more hint or beter way
> Just deleting the Accept-* headers entirely on all incoming messages
> will do the same thing and be faster.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From chip_pop at hotmail.com  Mon Jun  6 08:12:11 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 01:12:11 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <87674423-4c25-0a90-2248-db64178025e5@treenet.co.nz>
References: <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <87674423-4c25-0a90-2248-db64178025e5@treenet.co.nz>
Message-ID: <1465200731983-4677830.post@n4.nabble.com>

amos right but just removing  ,$20xxxxx  string  and keep the rest normal is
it better
so that way we wont fkp mobile app that depend on some info on vary
my concern is making every app and browser happy without error and have
beter caching %



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677830.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon Jun  6 09:02:06 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 6 Jun 2016 15:02:06 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465159329064-4677823.post@n4.nabble.com>
References: <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
Message-ID: <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>

Turning on collarsed_foarwarding decreases HIT ratio to previous low level.

Patch give high HIT only with disabled collapsed_forwarding.


06.06.2016 2:42, joe ?????:
> im re writing the varyEvaluateMatch function
> will see after i done test with new one
> for now last patch is good enough until the new function has less code
> faster and no bug
> hoop dev team give us more hint or beter way
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677823.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From chip_pop at hotmail.com  Mon Jun  6 09:14:47 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 02:14:47 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
References: <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
Message-ID: <1465204487541-4677832.post@n4.nabble.com>

has nothing to do with collarsed_foarwarding on  
shuld look into collarsed_foarwarding function not varyEvaluateMatch 


Yuri Voinov wrote
> Turning on collarsed_foarwarding decreases HIT ratio to previous low
> level.
> 
> Patch give high HIT only with disabled collapsed_forwarding.
> 
> 
> 06.06.2016 2:42, joe ?????:
>> im re writing the varyEvaluateMatch function
>> will see after i done test with new one
>> for now last patch is good enough until the new function has less code
>> faster and no bug
>> hoop dev team give us more hint or beter way
>>
>>
>>
>> --
>> View this message in context:
>> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677823.html
>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> _______________________________________________
>> squid-users mailing list
>> 

> squid-users at .squid-cache

>> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677832.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon Jun  6 09:54:56 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 6 Jun 2016 15:54:56 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465204487541-4677832.post@n4.nabble.com>
References: <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
Message-ID: <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>

Anyway effect is visible and reproduses.


06.06.2016 15:14, joe ?????:
> has nothing to do with collarsed_foarwarding on
> shuld look into collarsed_foarwarding function not varyEvaluateMatch
>
>
> Yuri Voinov wrote
>> Turning on collarsed_foarwarding decreases HIT ratio to previous low
>> level.
>>
>> Patch give high HIT only with disabled collapsed_forwarding.
>>
>>
>> 06.06.2016 2:42, joe ?????:
>>> im re writing the varyEvaluateMatch function
>>> will see after i done test with new one
>>> for now last patch is good enough until the new function has less code
>>> faster and no bug
>>> hoop dev team give us more hint or beter way
>>>
>>>
>>>
>>> --
>>> View this message in context:
>>> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677823.html
>>> Sent from the Squid - Users mailing list archive at Nabble.com.
>>> _______________________________________________
>>> squid-users mailing list
>>>
>> squid-users at .squid-cache
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at .squid-cache
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677832.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From marcus.kool at urlfilterdb.com  Mon Jun  6 09:57:06 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Mon, 6 Jun 2016 06:57:06 -0300
Subject: [squid-users] Squid high memory usage
In-Reply-To: <507114692.248903888.1465198063421.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <507114692.248903888.1465198063421.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <575548F2.7010607@urlfilterdb.com>



On 06/06/2016 04:27 AM, FredB wrote:
> Hello all,
>
> I'm trying to use a server with 64 Go of ram, but I'm faced with a problem, squid can't works with more than 50% of memory

What is cache_mem ?
See also http://wiki.squid-cache.org/SquidFaq/SquidMemory

> After that the swap is totally full and kswap process gone mad ...
> I tried with vm.swappiness = 0 but same problem, perhaps a little better, I also tried memory_pool off without any change.

I recommend vm.swappiness = 5 to have 5% of the memory be used for the file system cache and maintain good disk I/O.

> As you can see in this picture linux are using 22 Go of cached memory
> http://image.noelshack.com/fichiers/2016/22/1464965449-capture-squid.png

The values are too high (1024 times).  I think that you incorrectly set cache_mem.
Start with setting  cache_mem to 16 GB

Marcus

> I'm using two caches (133 G each)with a dedicated sata (15 k) disk for each cache
> Any advice will be very appreciate
>
> OS Debian Jessie 64 bits and squid 3.5.19
>
> Fred
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From chip_pop at hotmail.com  Mon Jun  6 09:36:33 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 02:36:33 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465195377702-4677827.post@n4.nabble.com>
References: <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <87674423-4c25-0a90-2248-db64178025e5@treenet.co.nz>
 <1465195377702-4677827.post@n4.nabble.com>
Message-ID: <1465205793853-4677835.post@n4.nabble.com>

not yet until its almost bug free and wen the dev team approve it


UT wrote
> Hi All,
> Any chance to see Joe's patch in the next build of Squid ?
> 
> Bye.





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677835.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Mon Jun  6 09:40:08 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 02:40:08 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
References: <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
Message-ID: <1465206008019-4677836.post@n4.nabble.com>

yup new test patch vary_experimental3.patch
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4677836/vary_experimental3.patch>  



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677836.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Mon Jun  6 09:42:22 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 02:42:22 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465206008019-4677836.post@n4.nabble.com>
References: <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
Message-ID: <1465206142767-4677837.post@n4.nabble.com>

lol my first time attachment ewwwwwwwwwwwwwww



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677837.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From fredbmail at free.fr  Mon Jun  6 10:27:39 2016
From: fredbmail at free.fr (FredB)
Date: Mon, 6 Jun 2016 12:27:39 +0200 (CEST)
Subject: [squid-users] Squid high memory usage
In-Reply-To: <575548F2.7010607@urlfilterdb.com>
Message-ID: <863161884.249366540.1465208859108.JavaMail.root@zimbra4-e1.priv.proxad.net>

Thanks for your answer

> What is cache_mem ?
> See also http://wiki.squid-cache.org/SquidFaq/SquidMemory
> 

Actually 25 Gb
I tried different values, but I guess no matter, the problem is that the squid limit is only 50% of ram

> > After that the swap is totally full and kswap process gone mad ...
> > I tried with vm.swappiness = 0 but same problem, perhaps a little
> > better, I also tried memory_pool off without any change.
> 
> I recommend vm.swappiness = 5 to have 5% of the memory be used for
> the file system cache and maintain good disk I/O.

More I increase vm.swappiness more I swap and more I have problems, but I will try your value

> 
> The values are too high (1024 times).  I think that you incorrectly
> set cache_mem.
> Start with setting  cache_mem to 16 GB
> 

Maybe I misunderstand your point, but when I reduce cache_mem yes there is no problem but Squid uses only 20/30 Go Max

With cache_men 15 Gb squid eats 36 % of memory
Htop and htops reports 30 Go of free memory

free -h
             total       used       free     shared    buffers     cached
Mem:           63G        62G       425M       122M       1,7G        27G
-/+ buffers/cache:        33G        30G
Swap:         1,9G       102M       1,8G

All my RAM is consumed by cache/buffers and seems not be freed when it is needed by Squid  
 




From chip_pop at hotmail.com  Mon Jun  6 10:02:10 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 03:02:10 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465206555834-4677838.post@n4.nabble.com>
References: <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <87674423-4c25-0a90-2248-db64178025e5@treenet.co.nz>
 <1465195377702-4677827.post@n4.nabble.com>
 <1465205793853-4677835.post@n4.nabble.com>
 <1465206555834-4677838.post@n4.nabble.com>
Message-ID: <1465207330624-4677840.post@n4.nabble.com>

thanks but you shuld thanks the dev team and other guys like yuri amos and
so++ they did realy hard work
i just done few im beginner 

UT wrote
> Hi Joe,
> Thanks for the reply, good luck for your patch, following progress of your
> great job 

> 
> bye





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677840.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon Jun  6 10:50:01 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 6 Jun 2016 16:50:01 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465206008019-4677836.post@n4.nabble.com>
References: <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
Message-ID: <0872722d-045f-04c1-ffc1-ac822d9e2f26@gmail.com>

Will test this patch version. Build with it now on production.


06.06.2016 15:40, joe ?????:
> yup new test patch vary_experimental3.patch
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4677836/vary_experimental3.patch>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677836.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Mon Jun  6 11:47:04 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 6 Jun 2016 17:47:04 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465206008019-4677836.post@n4.nabble.com>
References: <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
Message-ID: <96dc1086-085f-d460-9b0e-fd781f3761d4@gmail.com>

variant 3 produced lower HIT.


06.06.2016 15:40, joe ?????:
> yup new test patch vary_experimental3.patch
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4677836/vary_experimental3.patch>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677836.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Mon Jun  6 11:50:47 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 6 Jun 2016 17:50:47 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465206008019-4677836.post@n4.nabble.com>
References: <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
Message-ID: <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>

Also some flash news video has playback problems with variant 3


06.06.2016 15:40, joe ?????:
> yup new test patch vary_experimental3.patch
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4677836/vary_experimental3.patch>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677836.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From chip_pop at hotmail.com  Mon Jun  6 12:30:27 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 05:30:27 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
References: <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
Message-ID: <1465216227563-4677844.post@n4.nabble.com>

news video  is it https or http 
if its http please post link for me to test with it and see wat is the
problem to fix


Yuri Voinov wrote
> Also some flash news video has playback problems with variant 3
> 
> 
> 06.06.2016 15:40, joe ?????:
>> yup new test patch vary_experimental3.patch
>> &lt;http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4677836/vary_experimental3.patch&gt;
>>
>>
>>
>> --
>> View this message in context:
>> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677836.html
>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> _______________________________________________
>> squid-users mailing list
>> 

> squid-users at .squid-cache

>> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677844.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon Jun  6 13:20:37 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 6 Jun 2016 19:20:37 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465216227563-4677844.post@n4.nabble.com>
References: <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
Message-ID: <c9e99abf-a1f9-124b-b6a0-9c4736f07104@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Some of is http, YT is https


06.06.2016 18:30, joe ?????:
> news video  is it https or http
> if its http please post link for me to test with it and see wat is the
> problem to fix
>
>
> Yuri Voinov wrote
>> Also some flash news video has playback problems with variant 3
>>
>>
>> 06.06.2016 15:40, joe ?????:
>>> yup new test patch vary_experimental3.patch
>>>
&lt;http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4677836/vary_experimental3.patch&gt;
>>>
>>>
>>>
>>> --
>>> View this message in context:
>>>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677836.html
>>> Sent from the Squid - Users mailing list archive at Nabble.com.
>>> _______________________________________________
>>> squid-users mailing list
>>>
>
>> squid-users at .squid-cache
>
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> _______________________________________________
>> squid-users mailing list
>
>> squid-users at .squid-cache
>
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677844.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVXikAAoJENNXIZxhPexGmVEIAJZ7p1pArHEd8BwYyrwPPKoR
8Uy7y90ACTeApz4SvWfcMN1Sww7uferJkkzWY+Z3YNlGwz//WJY24r/4pNbfUw0w
uZ8IPC8PrH3vVpbZWbbVZrGQWdkJkkhMomggKM9Q000pafUvUmdugio58JpcS+Zr
VXKwXykb4QSL9pBE7ioii4ILzyE7BhaXM+3Ne/+hD+zAYhW+xMcotzuOUNbiF9mD
zeFh24ageOFI0vfRVVA5+eaG37QXQNyAh/0Zko7DtGqBcRG0JX/hKP9ZIyDP9ZmP
nBkEmnf8zQ3spq9htilo4V+AwS5689/o18KXPSBxtVbpM0MnRTkscl6gzjuntFg=
=GGeM
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/37732d4d/attachment.key>

From yvoinov at gmail.com  Mon Jun  6 13:21:00 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 6 Jun 2016 19:21:00 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465216227563-4677844.post@n4.nabble.com>
References: <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
Message-ID: <cd519c7e-5ba5-2ff2-6836-6b2efc777de3@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
http://bbcwshdod02-vh.akamaihd.net/z/russian/dps/2016/06/bookfest_ast_16x9_,lo,med,hi,.mp4.csmil/1_8057c05957735258_Seg1-Frag28


06.06.2016 18:30, joe ?????:
> news video  is it https or http
> if its http please post link for me to test with it and see wat is the
> problem to fix
>
>
> Yuri Voinov wrote
>> Also some flash news video has playback problems with variant 3
>>
>>
>> 06.06.2016 15:40, joe ?????:
>>> yup new test patch vary_experimental3.patch
>>>
&lt;http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4677836/vary_experimental3.patch&gt;
>>>
>>>
>>>
>>> --
>>> View this message in context:
>>>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677836.html
>>> Sent from the Squid - Users mailing list archive at Nabble.com.
>>> _______________________________________________
>>> squid-users mailing list
>>>
>
>> squid-users at .squid-cache
>
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> _______________________________________________
>> squid-users mailing list
>
>> squid-users at .squid-cache
>
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677844.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVXi8AAoJENNXIZxhPexGlVkH/12861vUS+4psC/Q7lEfK310
5Xt9605erMzADbW6pq1LEZUNTOqmWKwJ88+lSuyNLKGagm0pDl6VpxDhjVlWnKJm
lmPQZMyTFOATQGHNdqX8J7Fiid8CGPBhCN2nZt6gKychZX2CEvRYf8vPvtj5z1vb
nB2R87Te9CysGrC7Mn56SR8mHVZ7dLG2/hbZ6ahHJ6lRNqaAEglOpGaYJQG4K6bc
/24FInyuo2MhfO1RhxrtkxW6wMqRLSbsCzvNbQb51esWhsE2jZhw2UTrAo4BvDzW
lOdxall3gxGiiYLeo9tS5REozOAW2rA2ox6mhwv06Go5UQpTGg6R6UYbBLlRQuo=
=jbdF
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/740bf4e3/attachment.key>

From yvoinov at gmail.com  Mon Jun  6 13:23:34 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 6 Jun 2016 19:23:34 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465216227563-4677844.post@n4.nabble.com>
References: <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
Message-ID: <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Variant 2 looks like more safe and gives more HIT ratio.


06.06.2016 18:30, joe ?????:
> news video  is it https or http
> if its http please post link for me to test with it and see wat is the
> problem to fix
>
>
> Yuri Voinov wrote
>> Also some flash news video has playback problems with variant 3
>>
>>
>> 06.06.2016 15:40, joe ?????:
>>> yup new test patch vary_experimental3.patch
>>>
&lt;http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4677836/vary_experimental3.patch&gt;
>>>
>>>
>>>
>>> --
>>> View this message in context:
>>>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677836.html
>>> Sent from the Squid - Users mailing list archive at Nabble.com.
>>> _______________________________________________
>>> squid-users mailing list
>>>
>
>> squid-users at .squid-cache
>
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> _______________________________________________
>> squid-users mailing list
>
>> squid-users at .squid-cache
>
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677844.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVXlWAAoJENNXIZxhPexGFJMH/3WbJ/tOiypk4Yb4IisE64aF
h4fyx1WqOFt+QbyLs9ouLVtGWl2h3L+I32QrYhFU/aY+lOdxFlSxz8z7bA/y0fO5
jL2OuNsvsaxreutNFMAmi+JkenKIEnQQV3W1hFYJUQv1s4+BpotUp7gOR0XaVoH/
ibxU8x/59UrF/FHLhR7Rp2pJ/dCQj3NJ6meXLnA3FCxbF7pZc2t1tSOQfGVlw740
hlrl7vnEC9CTK90XJ3e3/8rBV04N3TOdkcWWqcqwzl0SMk6ds973FSZWSxEsJzOf
eCN5/GIDwAp8S5kKnXPopBhkdyg4PzsdJ5veFck3Q9mzyICEQAlCK3MycNKdr+E=
=B0fa
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/958094fa/attachment.key>

From chip_pop at hotmail.com  Mon Jun  6 12:45:28 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 05:45:28 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
References: <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
Message-ID: <1465217128251-4677847.post@n4.nabble.com>

http://www.bbc.com/news/world-australia-36442209
working fine playback forwerd  with cloaps on or off here is ok

any link ??


Yuri Voinov wrote
> Also some flash news video has playback problems with variant 3
> 
> 
> 06.06.2016 15:40, joe ?????:
>> yup new test patch vary_experimental3.patch
>> &lt;http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4677836/vary_experimental3.patch&gt;
>>
>>
>>
>> --
>> View this message in context:
>> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677836.html
>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> _______________________________________________
>> squid-users mailing list
>> 

> squid-users at .squid-cache

>> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677847.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Mon Jun  6 12:52:51 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 05:52:51 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <cd519c7e-5ba5-2ff2-6836-6b2efc777de3@gmail.com>
References: <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <cd519c7e-5ba5-2ff2-6836-6b2efc777de3@gmail.com>
Message-ID: <1465217571496-4677849.post@n4.nabble.com>

lol not that link it wont open to watch
copy the top url page of that news 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677849.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon Jun  6 13:31:40 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 6 Jun 2016 19:31:40 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465217128251-4677847.post@n4.nabble.com>
References: <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465217128251-4677847.post@n4.nabble.com>
Message-ID: <5227ae2f-cb6e-0474-a69a-68f4e9d92a4c@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
http://www.bbc.com/russian/multimedia/2016/06/160606_hoverboard_duru

I see only first video segment. Second try gives an error.

In access.log I see much memory hits for all video segments. URLs like this:

http://bbcwshdod02-vh.akamaihd.net/z/russian/dps/2016/06/bookfest_ast_16x9_,lo,med,hi,.mp4.csmil/1_8057c05957735258_Seg1-Frag28


06.06.2016 18:45, joe ?????:
> http://www.bbc.com/news/world-australia-36442209
> working fine playback forwerd  with cloaps on or off here is ok
>
> any link ??
>
>
> Yuri Voinov wrote
>> Also some flash news video has playback problems with variant 3
>>
>>
>> 06.06.2016 15:40, joe ?????:
>>> yup new test patch vary_experimental3.patch
>>>
&lt;http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4677836/vary_experimental3.patch&gt;
>>>
>>>
>>>
>>> --
>>> View this message in context:
>>>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677836.html
>>> Sent from the Squid - Users mailing list archive at Nabble.com.
>>> _______________________________________________
>>> squid-users mailing list
>>>
>
>> squid-users at .squid-cache
>
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> _______________________________________________
>> squid-users mailing list
>
>> squid-users at .squid-cache
>
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677847.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVXs8AAoJENNXIZxhPexG1ogIAIMUiF4YDmRkmfao5BXhjXuD
Hhpf1SVGqWXKAZT/M6LQotmt0CkQI+3s72pdD6nmd+O1Xze9xlPTTrFas1SFLt2B
nI4U9TdoXCGa7LvSfxd7Pwo5Z2wYJRKn4IAh6DImy2CO2938TZekQv5zywwX8V2A
gvvA9SCjtvEmLhgjVz0rK6SZkhGFxDpKmXVPTuaBf4Bt6JShJR79rHfbfoQvwocX
hJJlKoGjk3R7IFkUd0BPWatEFHTIyZWDqs1manAQDQbQ4APsF2hrCBB4PXm/wGy4
/bxDmwqmVbNtZiQK6ETSlaxOIlVbWPpCAzBSsWErBOJMH3xjGEiIi+yAowXIFDc=
=23a+
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/f3483fb3/attachment.key>

From chip_pop at hotmail.com  Mon Jun  6 12:54:42 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 05:54:42 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
References: <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
Message-ID: <1465217682486-4677851.post@n4.nabble.com>

ok then i will see wat can i do to speed that up



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677851.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon Jun  6 13:37:08 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 6 Jun 2016 19:37:08 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465217682486-4677851.post@n4.nabble.com>
References: <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
Message-ID: <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Third variant of patch seems not enough correct. Vary errors is absent,
but hit ratio lower. Variant 2 works ok, with acceptable hit ratio and
without visible problems with sites rendering.


06.06.2016 18:54, joe ?????:
> ok then i will see wat can i do to speed that up
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677851.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVXyDAAoJENNXIZxhPexGnaQH/i39xCVXq7cUE5WyaYVCwb6A
nWAEnmsOzVoPsx432Bw2dzE1mivRYRjkVf6SUJvEysH83/0XxS6wNNeLPKMQQlOw
NDjW+06N+QSfGOilEXLiguhzrWmKxKBgon7PlfgQ2Frjy/2FNnRoLpJItLpNKHzB
zHepPbISFyyJQd3QuKOifV6rNKDKpsZeN79ae625XT5t4JrzkMGHfkZo8VujdQgp
2OoseRoMp42wR32Rm/BqF3eZvWGAu3pEY4dEDCE1k3X5W2j/NDmVbGDTOsAMtQt7
wp04sZNWBldDVdpXVB7g1i5uD/vkJWDPCtzEUdD34C9v8h1fjud4U8DGeWm6i+8=
=ivUw
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/be717893/attachment.key>

From chip_pop at hotmail.com  Mon Jun  6 13:08:59 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 06:08:59 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
References: <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
Message-ID: <1465218539867-4677853.post@n4.nabble.com>

this link has no vary to be afected and why your video link is segment mmm
and akamaih lol

let me turn off colaps and see if i get any err
it play nice here 
any way i will work on patch 2

http://wsodprogrf.bbc.co.uk/russian/dps/2016/06/hoverboard%20paris%20duru_16x9_hi.mp4

GET /russian/dps/2016/06/hoverboard%20paris%20duru_16x9_hi.mp4 HTTP/1.1
Host: wsodprogrf.bbc.co.uk
User-Agent: Mozilla/5.0 (Windows NT 5.1; rv:46.0) Gecko/20100101
Firefox/46.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate
DNT: 1
Referer:
http://emp.bbci.co.uk/emp/SMPf/1.16.6/StandardMediaPlayerChromelessFlash.swf
Cookie:
BBC-UID=65067df42ce3419bbbc681ecd16bdcb6e236e3229714f406ea2037d28414c7800Mozilla/5.0%20(Windows%20NT%205.1%3b%20rv:43.0)%20Gecko/20100101%20Firefox/43.0;
s1=234.99.656D4C322009AC7002801ED2985;
BGUID=f5b61f31a50fa7bdf1e678085107040a1b548e842928e46b9e4147a797fcb048;
mm_random=1;
mm_pc=SignInState1st%3DLoggedOut%26SignInState%3DLoggedOut%26Language%3Den;
ckns_policy=111; ckns_policy_exp=1491250923338; mm_identity=false;
mmcore.tst=0.280; mm_.store.p.0=%7B%22mmparams.d%22%3A%7B%7D%7D;
ckns_orb_fig_cache={%22uk%22:0%2C%22ck%22:0%2C%22ad%22:1%2C%22ap%22:0%2C%22tb%22:0%2C%22mb%22:0%2C%22eu%22:0}
Connection: keep-alive

HTTP/1.1 200 OK
Server: Apache
Etag: "9eab2c9abf6eb936f6d82181125196db:1465202803"
Last-Modified: Mon, 06 Jun 2016 08:46:43 GMT
Accept-Ranges: bytes
Content-Length: 6647688
Content-Type: video/mp4
Date: Mon, 06 Jun 2016 13:34:45 GMT
X-Cache: MISS from proxy.netgatesss.com
Connection: keep-alive


Yuri Voinov wrote
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>  
> Third variant of patch seems not enough correct. Vary errors is absent,
> but hit ratio lower. Variant 2 works ok, with acceptable hit ratio and
> without visible problems with sites rendering.
> 
> 
> 06.06.2016 18:54, joe ?????:
>> ok then i will see wat can i do to speed that up
>>
>>
>>
>> --
>> View this message in context:
> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677851.html
>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> _______________________________________________
>> squid-users mailing list
>> 

> squid-users at .squid-cache

>> http://lists.squid-cache.org/listinfo/squid-users
> 
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>  
> iQEcBAEBCAAGBQJXVXyDAAoJENNXIZxhPexGnaQH/i39xCVXq7cUE5WyaYVCwb6A
> nWAEnmsOzVoPsx432Bw2dzE1mivRYRjkVf6SUJvEysH83/0XxS6wNNeLPKMQQlOw
> NDjW+06N+QSfGOilEXLiguhzrWmKxKBgon7PlfgQ2Frjy/2FNnRoLpJItLpNKHzB
> zHepPbISFyyJQd3QuKOifV6rNKDKpsZeN79ae625XT5t4JrzkMGHfkZo8VujdQgp
> 2OoseRoMp42wR32Rm/BqF3eZvWGAu3pEY4dEDCE1k3X5W2j/NDmVbGDTOsAMtQt7
> wp04sZNWBldDVdpXVB7g1i5uD/vkJWDPCtzEUdD34C9v8h1fjud4U8DGeWm6i+8=
> =ivUw
> -----END PGP SIGNATURE-----
> 
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> 0x613DEC46.asc (2K)
> &lt;http://squid-web-proxy-cache.1019090.n4.nabble.com/attachment/4677852/0/0x613DEC46.asc&gt;





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677853.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Mon Jun  6 14:10:17 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 07:10:17 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
References: <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
Message-ID: <1465222217407-4677854.post@n4.nabble.com>

fixed string  search better then    variant search   ,%20       caus some
mobile app has 
befor
'http://api.footballaddicts.com/matches?date=2016-06-06&utc_offset=%2B03%3A00'
'accept="application%2Fvnd.livescore_app.api.v4.android+json",
if-none-match="%223b23174cf97df7cb9fec26cdd9bac8ca%22",
if-modified-since="Mon,%2006%20Jun%202016%2014%3A31%3A32%20GMT",
accept-language="en", accept-encoding="gzip", x-client-locale="en_LB",
user-agent="se.footballaddicts.livescore%2F3.6.18", x-device="craterq3g"'

after
'http://api.footballaddicts.com/matches?date=2016-06-06&utc_offset=%2B03%3A00'
'accept="application%2Fvnd.livescore_app.api.v4.android+json",
if-none-match="%223b23174cf97df7cb9fec26cdd9bac8ca%22", if-modified-

if-modified-since="Mon,%2006%20Jun%202016%2014%3A31%3A32%20GMT"
bad :( it filter out the rest of the line ,%2006%20Jun   start with ,%20
so first test was fixed string going to work on that at least it wont fkp if
it detect any non related ,%20




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677854.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon Jun  6 14:50:57 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 6 Jun 2016 20:50:57 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465222217407-4677854.post@n4.nabble.com>
References: <1465159329064-4677823.post@n4.nabble.com>
 <4e2bd3fa-6b7e-2e87-9d6e-082c06b9c3da@gmail.com>
 <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
Message-ID: <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I offering simple strip %20. From whole string.


06.06.2016 20:10, joe ?????:
> fixed string  search better then    variant search   ,%20       caus some
> mobile app has
> befor
>
'http://api.footballaddicts.com/matches?date=2016-06-06&utc_offset=%2B03%3A00'
> 'accept="application%2Fvnd.livescore_app.api.v4.android+json",
> if-none-match="%223b23174cf97df7cb9fec26cdd9bac8ca%22",
> if-modified-since="Mon,%2006%20Jun%202016%2014%3A31%3A32%20GMT",
> accept-language="en", accept-encoding="gzip", x-client-locale="en_LB",
> user-agent="se.footballaddicts.livescore%2F3.6.18", x-device="craterq3g"'
>
> after
>
'http://api.footballaddicts.com/matches?date=2016-06-06&utc_offset=%2B03%3A00'
> 'accept="application%2Fvnd.livescore_app.api.v4.android+json",
> if-none-match="%223b23174cf97df7cb9fec26cdd9bac8ca%22", if-modified-
>
> if-modified-since="Mon,%2006%20Jun%202016%2014%3A31%3A32%20GMT"
> bad :( it filter out the rest of the line ,%2006%20Jun   start with ,%20
> so first test was fixed string going to work on that at least it wont
fkp if
> it detect any non related ,%20
>
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677854.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVY3QAAoJENNXIZxhPexG0Y8H+gLIv2mMB1aTpeRXx3S83GzX
8e1tJR6/2DpkLnXeuj+FixTX8RKUGq+QfAICWuAj9flYgTEpfd/ocBfo6ISpXlZy
4lTNHmguiFgO5LCDsDbwzaLBuwJYCk1Ln3NOAvKknC6Qtar8DcLCZv49u1M9ogiF
jTnJp1mBnlbzfU1lLLck9y0inxN/C2s6UgcbIR7KZ0mjmj17EYBYX9PRMExBOjRC
QD7wjbh64mECBnjO5CvKX29z9jbt80I5ZpLEhitJaVFMyC1PiCuWVk99eN7KDMre
hyZAIpJ/AHa/RDH6QtIibtQkRttZ4AssbULSZoDu0WCGzfDHzg93rgjumaFuvAs=
=2GRT
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/83dfd67a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/83dfd67a/attachment.key>

From chip_pop at hotmail.com  Mon Jun  6 14:27:18 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 07:27:18 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
Message-ID: <1465223238767-4677856.post@n4.nabble.com>

not good just to strip %20 lol as i post it remove also  string was belong to
the date 
we need to remove all of those string start with ,%20    as ,%20sdch so
its not eassy detection

it kill   if-modified-since="Mon,%2006%20Jun%202016%2014%3A31%3A32%20GMT",

if you notice this string in vary  has %20 so just wide search and clear it
remove those :( 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677856.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon Jun  6 15:08:41 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 6 Jun 2016 21:08:41 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465223238767-4677856.post@n4.nabble.com>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
Message-ID: <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Ok, why not to replace %20 to original space symbol?


06.06.2016 20:27, joe ?????:
> not good just to strip %20 lol as i post it remove also  string was belong to
> the date
> we need to remove all of those string start with ,%20    as ,%20sdch so
> its not eassy detection
>
> it kill   if-modified-since="Mon,%2006%20Jun%202016%2014%3A31%3A32%20GMT",
>
> if you notice this string in vary  has %20 so just wide search and
clear it
> remove those :(
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677856.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVZH5AAoJENNXIZxhPexG4w0IAJr6eWxVVostrUXcOaTHVKxC
Hg1p9MlRko/B+fPpNKZmWPStvklZL7jOwaLLKY6E2ZCHIOOotDV+L7WXlqb2tnml
M3E9aGWSpBPhX61Se1vDI9gCOEZmhf+GcriOdSysjJpqqlKVEIZVFNpnjE05I5Lc
6MBV0Lteag/nrRjSM46ajJjSKSVUY0dOcRtHPZkv3iCeh6WEALfB7jZ67GYiiAjy
BcBhI8i4bjWUu9yQwYUBvN+OIp2FlLoM7JQqPRDQn3i2b5Miq4MI4cdZ5Sntrt/n
yEgWXl90w16TASjbUQjs6wB8xSHeMYKFdpOlsI1o/m8/aqCa1kIANyDYPBIUiWg=
=DYz3
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/120fad53/attachment.key>

From andrewm659 at yahoo.com  Mon Jun  6 15:23:33 2016
From: andrewm659 at yahoo.com (Andrew Meyer)
Date: Mon, 6 Jun 2016 15:23:33 +0000 (UTC)
Subject: [squid-users] logging and proxy pac file help
In-Reply-To: <2036326954.956510.1464994308430.JavaMail.yahoo@mail.yahoo.com>
References: <2036326954.956510.1464994308430.JavaMail.yahoo.ref@mail.yahoo.com>
 <2036326954.956510.1464994308430.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <1437526911.1871207.1465226613615.JavaMail.yahoo@mail.yahoo.com>

Ok, so I made some changes to the proxy.pac file and it looks like this now.
function FindProxyForURL(url, host) {? ? //Don't proxy connections to the UTM web interface? ? if (shExpMatch(url, "https://borg.local*")) return "DIRECT";? ? if (shExpMatch(url, "https://" + dnsResolve(host) + "*")) return "DIRECT";? ? //Exclude non-fqdn hosts from being proxied? ? if (isPlainHostName(host)) return "DIRECT";? ? //Don't proxy connections to the exempted URL matches? ? if (shExpMatch(url, "*borg.local*")) return "DIRECT";? ?if (isInNet(myIpAddress(), "10.150.0.0", "255.255.0.0")) ? ? ? ? ? ? {return "PROXY proxy.borg.local:3128" ;}
? ? return "DIRECT";}
Still not seeing logs go into the squid access.log.
Thanks!

    On Friday, June 3, 2016 5:51 PM, Andrew Meyer <andrewm659 at yahoo.com> wrote:
 
 

 So I have squid (latest) running in a a jail, and I am able to use it communicate with it via the browser. But I am trying to set it up so that I can use a proxy.pac file. I have the proxy.pac configured. Firefox is being used as my testbed. When I switch over the pac file I get nothing in the logs. Not sure why. ? Below is my config.
root at proxy:/usr/local/etc/squid # cat squid.conf
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8    # RFC1918 possible internal network
acl localnet src 172.16.0.0/12    # RFC1918 possible internal network
acl localnet src 192.168.0.0/16    # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80        # http
acl Safe_ports port 21        # ftp
acl Safe_ports port 443        # https
acl Safe_ports port 70        # gopher
acl Safe_ports port 210        # wais
acl Safe_ports port 1025-65535    # unregistered ports
acl Safe_ports port 280        # http-mgmt
acl Safe_ports port 488        # gss-http
acl Safe_ports port 591        # filemaker
acl Safe_ports port 777        # multiling http
acl CONNECT method CONNECT

acl our_networks src 10.150.1.0/24
#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager our_networks
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 3128

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /var/squid/cache 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/squid/cache

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:        1440    20%    10080
refresh_pattern ^gopher:    1440    0%    1440
refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
refresh_pattern .        0    20%    4320

visible_hostname proxy01.borg.local

access_log /var/log/squid/access.log squid
#logformat custom %{%Y-%m-%d %H:%M:%S}tl %03tu %>a %tr %ul %ui %>Hs %mt %rm %ru %rv %st %Sh %Ss
logformat squid %tl %6tr %>a %Ss/%03Hs %<st %rm %ru %un %Sh/%<A %mt
client_db on
dns_defnames on
httpd_suppress_version_string on
retry_on_error on
uri_whitespace strip
strip_query_terms off
#pipeline_prefetch on

cache deny all
#cache_dir null /tmp
ident_lookup_access deny all

## disable ads ( http://pgl.yoyo.org/adservers/ )
acl adsites url_regex -i "/usr/local/etc/squid/ad_block.txt"
http_access deny adsites
deny_info http://proxy.borg.local/blocked.html adsites
root at proxy:/usr/local/etc/squid # 

Proxy.pac

function FindProxyForURL(url, host) {
    //Don't proxy connections to the UTM web interface
    if (shExpMatch(url, "https://${asg_hostname}*")) return "DIRECT";
    if (shExpMatch(url, "https://" + dnsResolve(host) + "*")) return "DIRECT";
    //Exclude non-fqdn hosts from being proxied
    if (isPlainHostName(host)) return "DIRECT";
    //Don't proxy connections to the exempted URL matches
    if (shExpMatch(url, "*borg.local*")) return "DIRECT";
   if (isInNet(myIpAddress(), "10.150.0.0", "255.255.0.0"))        {return "PROXY proxy.borg.local:3128" ;}

    return "DIRECT";
}

 
  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/3ce8324f/attachment.htm>

From chip_pop at hotmail.com  Mon Jun  6 14:56:13 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 07:56:13 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
References: <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
Message-ID: <1465224973726-4677859.post@n4.nabble.com>

it become same less hit caus firefox adding extra info and its marked out %20
so if u just take of %20 hit become low as original code that why we shuld
remove full string %20gzip   or anythink like that
that make all the object with vary    has same string  make hit %  higher
also i dont want to risk deleting string has nothing to do with those



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677859.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From marcus.kool at urlfilterdb.com  Mon Jun  6 15:36:29 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Mon, 6 Jun 2016 12:36:29 -0300
Subject: [squid-users] Squid high memory usage
In-Reply-To: <863161884.249366540.1465208859108.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <863161884.249366540.1465208859108.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <5755987D.9020401@urlfilterdb.com>



On 06/06/2016 07:27 AM, FredB wrote:
> Thanks for your answer
>
>> What is cache_mem ?
>> See also http://wiki.squid-cache.org/SquidFaq/SquidMemory
>>
>
> Actually 25 Gb
> I tried different values, but I guess no matter, the problem is that the squid limit is only 50% of ram
>
>>> After that the swap is totally full and kswap process gone mad ...
>>> I tried with vm.swappiness = 0 but same problem, perhaps a little
>>> better, I also tried memory_pool off without any change.
>>
>> I recommend vm.swappiness = 5 to have 5% of the memory be used for
>> the file system cache and maintain good disk I/O.
>
> More I increase vm.swappiness more I swap and more I have problems, but I will try your value
>
>>
>> The values are too high (1024 times).  I think that you incorrectly
>> set cache_mem.

ah, I misread the values. I interpreted the comma as a thousand separator.

>> Start with setting  cache_mem to 16 GB
>>
>
> Maybe I misunderstand your point, but when I reduce cache_mem yes there is no problem but Squid uses only 20/30 Go Max

As you can read in the memory FAQ, the value of cache_mem is a part (often 35%) of total memory use.
When you start with a clean install, you will see a "low memory use" since the disk cache is not yet fully populated
and perhaps because the number of connections is low.

> With cache_men 15 Gb squid eats 36 % of memory
> Htop and htops reports 30 Go of free memory
>
> free -h
>               total       used       free     shared    buffers     cached
> Mem:           63G        62G       425M       122M       1,7G        27G
> -/+ buffers/cache:        33G        30G
> Swap:         1,9G       102M       1,8G
>
> All my RAM is consumed by cache/buffers and seems not be freed when it is needed by Squid

This is a healthy start.
When your disk cache is fully populated and when there is still room (e.g. 'cached' column of free shows many gigabytes), you may increase cache_mem.
Note that connections and Squid buffers occupy memory so always be a bit conservative to prevent swapping.

2 GB swap for a 64 GB memory system is a bit small. If you only have Squid and no other applications on this system it may be sufficient.

Marcus



From heiler.bemerguy at cinbesa.com.br  Mon Jun  6 17:47:10 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Mon, 6 Jun 2016 14:47:10 -0300
Subject: [squid-users] Vary object loop returns
In-Reply-To: <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
Message-ID: <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>


These are the variations for the "accept-encoding" tag I found when 
sniffing my client's connections. And they're of all kind. Newer and 
older browsers, mobile phones, windows updates, whatever..

It got a total of 11.437 requests from clients to squid.


*accept-encoding: gzip, deflate**
**Accept-Encoding: gzip, deflate**
**Accept-Encoding: gzip,deflate**
**Accept-Encoding: gzip, deflate, lzma, sdch**
**Accept-Encoding: gzip, deflate, sdch**
**Accept-Encoding: gzip,deflate,sdch**
**Accept-Encoding: gzip, xeflate, sdch**
**Accept-Encoding: identity**
**Accept-Encoding: identity;q=1, *;q=0*


Notice that some have spaces, some not, but I haven't seen any "%20" 
representing a space. Is the "%20" put there by squid itself?


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751



Em 06/06/2016 12:08, Yuri Voinov escreveu:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>   
> Ok, why not to replace %20 to original space symbol?
>
>
> 06.06.2016 20:27, joe ?????:
>> not good just to strip %20 lol as i post it remove also  string was belong to
>> the date
>> we need to remove all of those string start with ,%20    as ,%20sdch so
>> its not eassy detection
>>
>> it kill   if-modified-since="Mon,%2006%20Jun%202016%2014%3A31%3A32%20GMT",
>>
>> if you notice this string in vary  has %20 so just wide search and
> clear it
>> remove those :(
>>
>>
>>
>> --
>> View this message in context:
> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677856.html
>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>   
> iQEcBAEBCAAGBQJXVZH5AAoJENNXIZxhPexG4w0IAJr6eWxVVostrUXcOaTHVKxC
> Hg1p9MlRko/B+fPpNKZmWPStvklZL7jOwaLLKY6E2ZCHIOOotDV+L7WXlqb2tnml
> M3E9aGWSpBPhX61Se1vDI9gCOEZmhf+GcriOdSysjJpqqlKVEIZVFNpnjE05I5Lc
> 6MBV0Lteag/nrRjSM46ajJjSKSVUY0dOcRtHPZkv3iCeh6WEALfB7jZ67GYiiAjy
> BcBhI8i4bjWUu9yQwYUBvN+OIp2FlLoM7JQqPRDQn3i2b5Miq4MI4cdZ5Sntrt/n
> yEgWXl90w16TASjbUQjs6wB8xSHeMYKFdpOlsI1o/m8/aqCa1kIANyDYPBIUiWg=
> =DYz3
> -----END PGP SIGNATURE-----
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/8d540a0d/attachment.htm>

From yvoinov at gmail.com  Mon Jun  6 17:55:31 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 6 Jun 2016 23:55:31 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
Message-ID: <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
So.

Squid DOES NOT and DON'T BE support gzip. The only way to do it - use
ecap + desupported ecap gzip adapter. Let's accept this. We can support
gzip. With restrictions. Ok.

any other compression - false. No. No way. Get out. and so on.

 identity - this is uncompressed type.

That's all, folks.

Finally. As Joe does, we can remain only gzip and identity in
Accept-Encoding and truncate all remaining.

Without any problem. Moreover, this type of can be push to all brunches
of squid without any problem, because of this dramatically increases
byte HIT.

As I said, this does Squid it must be.

06.06.2016 23:47, Heiler Bemerguy ?????:
>
>
> These are the variations for the "accept-encoding" tag I found when
sniffing my client's connections. And they're of all kind. Newer and
older browsers, mobile phones, windows updates, whatever..
>
> It got a total of 11.437 requests from clients to squid.
>
>
> *accept-encoding: gzip, deflate**
> **Accept-Encoding: gzip, deflate**
> **Accept-Encoding: gzip,deflate**
> **Accept-Encoding: gzip, deflate, lzma, sdch**
> **Accept-Encoding: gzip, deflate, sdch**
> **Accept-Encoding: gzip,deflate,sdch**
> **Accept-Encoding: gzip, xeflate, sdch**
> **Accept-Encoding: identity**
> **Accept-Encoding: identity;q=1, *;q=0*
>
>
> Notice that some have spaces, some not, but I haven't seen any "%20"
representing a space. Is the "%20" put there by squid itself?
>
>
> --
> Best Regards,
>
> Heiler Bemerguy
> Network Manager - CINBESA
> 55 91 98151-4894/3184-1751
>
>
> Em 06/06/2016 12:08, Yuri Voinov escreveu:
> Ok, why not to replace %20 to original space symbol?
>
>
> 06.06.2016 20:27, joe ?????:
> >>> not good just to strip %20 lol as i post it remove also  string
was belong to
> >>> the date
> >>> we need to remove all of those string start with ,%20    as
,%20sdch so
> >>> its not eassy detection
> >>>
> >>> it kill  
if-modified-since="Mon,%2006%20Jun%202016%2014%3A31%3A32%20GMT",
> >>>
> >>> if you notice this string in vary  has %20 so just wide search and
> clear it
> >>> remove those :(
> >>>
> >>>
> >>>
> >>> --
> >>> View this message in context:
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677856.html
> >>> Sent from the Squid - Users mailing list archive at Nabble.com.
> >>> _______________________________________________
> >>> squid-users mailing list
> >>> squid-users at lists.squid-cache.org
> >>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVbkTAAoJENNXIZxhPexGLN0H/A0lUTMgvb3xkJTYWu3kbgJS
wob2/TriqzMS01o7EUviaqUrZXmaexZJ3Qh8k9I0MQ/enAVUKDNtsAq0S+616XlK
szc3HEZjOzWV7S5y4hBGasMopOnml2PMfPIQyHC1KeoEuHoprNCFNPjhOtU0/YwM
Vhe3sPljNfEGjys/CCt38EqaDL3jGTKZLxjwwtn+iRlQMR8Mmo/c3RQJ6gAKFlKn
BRVTRtj1F3R5tNauuVl4d4xVKd+gQuAmLLCQAwhJ8FzhSPv0qkfBfsZpeZe9BmHy
jBmUO4ZnNtkBgaNmEdZgqxifitfH/eBaHfV0Q6n+ofyGEYW6S6jG2n2ZFocwP0s=
=l49S
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/304db298/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/304db298/attachment.key>

From yvoinov at gmail.com  Mon Jun  6 18:01:07 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 7 Jun 2016 00:01:07 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
Message-ID: <16a59d21-99ef-b4a0-9aed-8238b0e90fba@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


06.06.2016 23:47, Heiler Bemerguy ?????:
>
>
> These are the variations for the "accept-encoding" tag I found when
sniffing my client's connections. And they're of all kind. Newer and
older browsers, mobile phones, windows updates, whatever..
>
> It got a total of 11.437 requests from clients to squid.
>
>
> *accept-encoding: gzip, deflate**
> **Accept-Encoding: gzip, deflate**
> **Accept-Encoding: gzip,deflate**
> **Accept-Encoding: gzip, deflate, lzma, sdch**
> **Accept-Encoding: gzip, deflate, sdch**
> **Accept-Encoding: gzip,deflate,sdch**
> **Accept-Encoding: gzip, xeflate, sdch**
> **Accept-Encoding: identity**
> **Accept-Encoding: identity;q=1, *;q=0*
>
>
> Notice that some have spaces, some not, but I haven't seen any "%20"
representing a space. Is the "%20" put there by squid itself?

No. This comes from web-servers.

>
>
> --
> Best Regards,
>
> Heiler Bemerguy
> Network Manager - CINBESA
> 55 91 98151-4894/3184-1751
>
>
> Em 06/06/2016 12:08, Yuri Voinov escreveu:
> Ok, why not to replace %20 to original space symbol?
>
>
> 06.06.2016 20:27, joe ?????:
> >>> not good just to strip %20 lol as i post it remove also  string
was belong to
> >>> the date
> >>> we need to remove all of those string start with ,%20    as
,%20sdch so
> >>> its not eassy detection
> >>>
> >>> it kill  
if-modified-since="Mon,%2006%20Jun%202016%2014%3A31%3A32%20GMT",
> >>>
> >>> if you notice this string in vary  has %20 so just wide search and
> clear it
> >>> remove those :(
> >>>
> >>>
> >>>
> >>> --
> >>> View this message in context:
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677856.html
> >>> Sent from the Squid - Users mailing list archive at Nabble.com.
> >>> _______________________________________________
> >>> squid-users mailing list
> >>> squid-users at lists.squid-cache.org
> >>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVbpjAAoJENNXIZxhPexGShkIAIEL//pAaRcyCSQefZ0iyEEW
SLPZ6bTwhjuw/34xT1WvxbWxxOcXmFMliPgn1wBQ2E2RPm0Sbffb+cH50/yeMFo9
nseAgvkHQxX/uHso1lrlORPdCZOd/adtdRv0Ph3KddDjCfHthRco7tEJ//QHNNOn
+JN3B8KKndHH1Dm5XmTUyEPXMsCH9+p8tjIkwDxkhBLXO/n8HggPCSW7Mk85Zszh
n0LigARf0EWLOJnrGqrOz1kWtZpMWPi4e5SImo1vMW47eroTnJAfxiHlelO54wbA
FhRA8G4B66A3cNJCfTmEU/VRCxaR1nkbqKtEDwsw+3RF+L+7fQBQNC+KOTUxX9Y=
=DFXj
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/898740f2/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/898740f2/attachment.key>

From heiler.bemerguy at cinbesa.com.br  Mon Jun  6 18:09:26 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Mon, 6 Jun 2016 15:09:26 -0300
Subject: [squid-users] Vary object loop returns
In-Reply-To: <16a59d21-99ef-b4a0-9aed-8238b0e90fba@gmail.com>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <16a59d21-99ef-b4a0-9aed-8238b0e90fba@gmail.com>
Message-ID: <24a6a3c4-cf1c-4f14-c9b8-7e1b2a8a6ae2@cinbesa.com.br>


Web servers uses the "vary" tag, not "accept-encoding" tag exactly. Like 
these sniffed examples:

Vary: *
Vary: Accept
Vary: Accept-Encoding
Vary: Accept-Encoding
Vary: Accept-Encoding, Accept-Encoding
Vary: Accept-Encoding,Host
Vary: Accept-Encoding, User-Agent
Vary: Accept-Encoding,User-Agent
Vary: Accept-Encoding,X-Device-Type, Accept-Encoding
Vary: Accept-Encoding,X-UA-Device
Vary: If-None-Match, If-Modified-Since
Vary: Origin
Vary: Origin, Access-Control-Request-Headers, Access-Control-Request-Method
Vary: User-Agent
Vary: User-Agent,Accept

and all of them have no %20


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751

Em 06/06/2016 15:01, Yuri Voinov escreveu:
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
>
>
> 06.06.2016 23:47, Heiler Bemerguy ?????:
> > > > These are the variations for the "accept-encoding" tag I found 
> when sniffing my client's connections. And they're of all kind. Newer 
> and older browsers, mobile phones, windows updates, whatever.. > > It 
> got a total of 11.437 requests from clients to squid. > > > 
> *accept-encoding: gzip, deflate** > **Accept-Encoding: gzip, deflate** 
> > **Accept-Encoding: gzip,deflate** > **Accept-Encoding: gzip, 
> deflate, lzma, sdch** > **Accept-Encoding: gzip, deflate, sdch** > 
> **Accept-Encoding: gzip,deflate,sdch** > **Accept-Encoding: gzip, 
> xeflate, sdch** > **Accept-Encoding: identity** > **Accept-Encoding: 
> identity;q=1, *;q=0* > > > Notice that some have spaces, some not, but 
> I haven't seen any "%20" representing a space. Is the "%20" put there 
> by squid itself?
>
> No. This comes from web-servers.
>
> > > > -- > Best Regards, > > Heiler Bemerguy > Network Manager - 
> CINBESA > 55 91 98151-4894/3184-1751 > > > Em 06/06/2016 12:08, Yuri 
> Voinov escreveu: > Ok, why not to replace %20 to original space 
> symbol? > > > 06.06.2016 20:27, joe ?????: > >>> not good just to 
> strip %20 lol as i post it remove also  string was belong to > >>> the 
> date > >>> we need to remove all of those string start with ,%20    as 
> ,%20sdch so > >>> its not eassy detection > >>> > >>> it kill 
> if-modified-since="Mon,%2006%20Jun%202016%2014%3A31%3A32%20GMT", > >>> 
> > >>> if you notice this string in vary  has %20 so just wide search 
> and > clear it > >>> remove those :( > >>> > >>> > >>> > >>> -- > >>> 
> View this message in context: > 
> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677856.html 
> > >>> Sent from the Squid - Users mailing list archive at Nabble.com. 
> > >>> _______________________________________________ > >>> 
> squid-users mailing list > >>> squid-users at lists.squid-cache.org > >>> 
> http://lists.squid-cache.org/listinfo/squid-users >> >> >> >> 
> _______________________________________________ >> squid-users mailing 
> list >> squid-users at lists.squid-cache.org >> 
> http://lists.squid-cache.org/listinfo/squid-users > > > > 
> _______________________________________________ > squid-users mailing 
> list > squid-users at lists.squid-cache.org > 
> http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXVbpjAAoJENNXIZxhPexGShkIAIEL//pAaRcyCSQefZ0iyEEW
> SLPZ6bTwhjuw/34xT1WvxbWxxOcXmFMliPgn1wBQ2E2RPm0Sbffb+cH50/yeMFo9
> nseAgvkHQxX/uHso1lrlORPdCZOd/adtdRv0Ph3KddDjCfHthRco7tEJ//QHNNOn
> +JN3B8KKndHH1Dm5XmTUyEPXMsCH9+p8tjIkwDxkhBLXO/n8HggPCSW7Mk85Zszh
> n0LigARf0EWLOJnrGqrOz1kWtZpMWPi4e5SImo1vMW47eroTnJAfxiHlelO54wbA
> FhRA8G4B66A3cNJCfTmEU/VRCxaR1nkbqKtEDwsw+3RF+L+7fQBQNC+KOTUxX9Y=
> =DFXj
> -----END PGP SIGNATURE-----
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/82cdce3f/attachment.htm>

From chip_pop at hotmail.com  Mon Jun  6 17:36:24 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 10:36:24 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
References: <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
Message-ID: <1465234584830-4677865.post@n4.nabble.com>

right the acsess.log dose not show  those  %20 
20 ar space in real accept-encoding: gzip, deflate   <-- notice the space
wen it reach function
varyEvaluateMatch  it shange some how to 20   and the %  is mark  the one
internally wen its used by the destination server  it has no mark %20   
example  accept-encoding="gzip,%20deflate"  <--here the server use gzip
notice its not marked
accept-encoding="%20gzip,%20deflate,identity" <-- here identity used by the
destination sever sending this to squid with mark %20   depend i gess on
dest..server compression can handle
so those wen it come to squid they use the vary as extra key to save the
object in cache 
we dont need them   since there is many browser or app  asking the
dest...server for different compression
hit %  become low cause squid use vary with wat ever string as key to save
the object
now for us  its very bad caching and if we remove filtering out those with
%20 so other variant browser can benefit of those object from the cache  so
the 20 is hex converted from the string space to 20  and the %  is mark as i
understand it after lots a research 



Heiler Bemerguy wrote
> These are the variations for the "accept-encoding" tag I found when 
> sniffing my client's connections. And they're of all kind. Newer and 
> older browsers, mobile phones, windows updates, whatever..
> 
> It got a total of 11.437 requests from clients to squid.
> 
> 
> *accept-encoding: gzip, deflate**
> **Accept-Encoding: gzip, deflate**
> **Accept-Encoding: gzip,deflate**
> **Accept-Encoding: gzip, deflate, lzma, sdch**
> **Accept-Encoding: gzip, deflate, sdch**
> **Accept-Encoding: gzip,deflate,sdch**
> **Accept-Encoding: gzip, xeflate, sdch**
> **Accept-Encoding: identity**
> **Accept-Encoding: identity;q=1, *;q=0*
> 
> 
> Notice that some have spaces, some not, but I haven't seen any "%20" 
> representing a space. Is the "%20" put there by squid itself?
> 
> 
> -- 
> Best Regards,
> 
> Heiler Bemerguy
> Network Manager - CINBESA
> 55 91 98151-4894/3184-1751
> 
> 
> 
> Em 06/06/2016 12:08, Yuri Voinov escreveu:
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>>   
>> Ok, why not to replace %20 to original space symbol?
>>
>>
>> 06.06.2016 20:27, joe ?????:
>>> not good just to strip %20 lol as i post it remove also  string was
>>> belong to
>>> the date
>>> we need to remove all of those string start with ,%20    as ,%20sdch so
>>> its not eassy detection
>>>
>>> it kill  
>>> if-modified-since="Mon,%2006%20Jun%202016%2014%3A31%3A32%20GMT",
>>>
>>> if you notice this string in vary  has %20 so just wide search and
>> clear it
>>> remove those :(
>>>
>>>
>>>
>>> --
>>> View this message in context:
>> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677856.html
>>> Sent from the Squid - Users mailing list archive at Nabble.com.
>>> _______________________________________________
>>> squid-users mailing list
>>> 

> squid-users at .squid-cache

>>> http://lists.squid-cache.org/listinfo/squid-users
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v2
>>   
>> iQEcBAEBCAAGBQJXVZH5AAoJENNXIZxhPexG4w0IAJr6eWxVVostrUXcOaTHVKxC
>> Hg1p9MlRko/B+fPpNKZmWPStvklZL7jOwaLLKY6E2ZCHIOOotDV+L7WXlqb2tnml
>> M3E9aGWSpBPhX61Se1vDI9gCOEZmhf+GcriOdSysjJpqqlKVEIZVFNpnjE05I5Lc
>> 6MBV0Lteag/nrRjSM46ajJjSKSVUY0dOcRtHPZkv3iCeh6WEALfB7jZ67GYiiAjy
>> BcBhI8i4bjWUu9yQwYUBvN+OIp2FlLoM7JQqPRDQn3i2b5Miq4MI4cdZ5Sntrt/n
>> yEgWXl90w16TASjbUQjs6wB8xSHeMYKFdpOlsI1o/m8/aqCa1kIANyDYPBIUiWg=
>> =DYz3
>> -----END PGP SIGNATURE-----
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> 

> squid-users at .squid-cache

>> http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users


new patch vary_experimental4

vary_experimental4.patch
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4677865/vary_experimental4.patch>  




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677865.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Mon Jun  6 17:39:13 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 10:39:13 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
References: <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
Message-ID: <1465234753189-4677866.post@n4.nabble.com>

exactly squid dose not use compression but it use vary as key so it can find
the object in the cache


Yuri Voinov wrote
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>  
> So.
> 
> Squid DOES NOT and DON'T BE support gzip. The only way to do it - use
> ecap + desupported ecap gzip adapter. Let's accept this. We can support
> gzip. With restrictions. Ok.
> 
> any other compression - false. No. No way. Get out. and so on.
> 
>  identity - this is uncompressed type.
> 
> That's all, folks.
> 
> Finally. As Joe does, we can remain only gzip and identity in
> Accept-Encoding and truncate all remaining.
> 
> Without any problem. Moreover, this type of can be push to all brunches
> of squid without any problem, because of this dramatically increases
> byte HIT.
> 
> As I said, this does Squid it must be.
> 
> 06.06.2016 23:47, Heiler Bemerguy ?????:
>>
>>
>> These are the variations for the "accept-encoding" tag I found when
> sniffing my client's connections. And they're of all kind. Newer and
> older browsers, mobile phones, windows updates, whatever..
>>
>> It got a total of 11.437 requests from clients to squid.
>>
>>
>> *accept-encoding: gzip, deflate**
>> **Accept-Encoding: gzip, deflate**
>> **Accept-Encoding: gzip,deflate**
>> **Accept-Encoding: gzip, deflate, lzma, sdch**
>> **Accept-Encoding: gzip, deflate, sdch**
>> **Accept-Encoding: gzip,deflate,sdch**
>> **Accept-Encoding: gzip, xeflate, sdch**
>> **Accept-Encoding: identity**
>> **Accept-Encoding: identity;q=1, *;q=0*
>>
>>
>> Notice that some have spaces, some not, but I haven't seen any "%20"
> representing a space. Is the "%20" put there by squid itself?
>>
>>
>> --
>> Best Regards,
>>
>> Heiler Bemerguy
>> Network Manager - CINBESA
>> 55 91 98151-4894/3184-1751
>>
>>
>> Em 06/06/2016 12:08, Yuri Voinov escreveu:
>> Ok, why not to replace %20 to original space symbol?
>>
>>
>> 06.06.2016 20:27, joe ?????:
>> >>> not good just to strip %20 lol as i post it remove also  string
> was belong to
>> >>> the date
>> >>> we need to remove all of those string start with ,%20    as
> ,%20sdch so
>> >>> its not eassy detection
>> >>>
>> >>> it kill  
> if-modified-since="Mon,%2006%20Jun%202016%2014%3A31%3A32%20GMT",
>> >>>
>> >>> if you notice this string in vary  has %20 so just wide search and
>> clear it
>> >>> remove those :(
>> >>>
>> >>>
>> >>>
>> >>> --
>> >>> View this message in context:
>>
> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677856.html
>> >>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> >>> _______________________________________________
>> >>> squid-users mailing list
>> >>> 

> squid-users at .squid-cache

>> >>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> 

> squid-users at .squid-cache

>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> 

> squid-users at .squid-cache

>> http://lists.squid-cache.org/listinfo/squid-users
> 
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>  
> iQEcBAEBCAAGBQJXVbkTAAoJENNXIZxhPexGLN0H/A0lUTMgvb3xkJTYWu3kbgJS
> wob2/TriqzMS01o7EUviaqUrZXmaexZJ3Qh8k9I0MQ/enAVUKDNtsAq0S+616XlK
> szc3HEZjOzWV7S5y4hBGasMopOnml2PMfPIQyHC1KeoEuHoprNCFNPjhOtU0/YwM
> Vhe3sPljNfEGjys/CCt38EqaDL3jGTKZLxjwwtn+iRlQMR8Mmo/c3RQJ6gAKFlKn
> BRVTRtj1F3R5tNauuVl4d4xVKd+gQuAmLLCQAwhJ8FzhSPv0qkfBfsZpeZe9BmHy
> jBmUO4ZnNtkBgaNmEdZgqxifitfH/eBaHfV0Q6n+ofyGEYW6S6jG2n2ZFocwP0s=
> =l49S
> -----END PGP SIGNATURE-----
> 
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> 0x613DEC46.asc (2K)
> &lt;http://squid-web-proxy-cache.1019090.n4.nabble.com/attachment/4677862/0/0x613DEC46.asc&gt;





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677866.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon Jun  6 18:17:56 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 7 Jun 2016 00:17:56 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <24a6a3c4-cf1c-4f14-c9b8-7e1b2a8a6ae2@cinbesa.com.br>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <16a59d21-99ef-b4a0-9aed-8238b0e90fba@gmail.com>
 <24a6a3c4-cf1c-4f14-c9b8-7e1b2a8a6ae2@cinbesa.com.br>
Message-ID: <f1304a10-bbac-7e53-9662-5207f9740d7b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Heh, and what about contains Accept-Encoding, how do your think?

I know where you're going. :) They say that the spaces (%20) are not
there. Unfortunately, they just come through a Vary header. If it is
blocked via manipulation of headlines - we break internet and get a lot
of trouble.

Here the situation is slightly more complicated than it seems Joe.
Developers must write the correct Vary treatment, taking into account
today's reality. Unfortunately, they will not do it. Even given the fact
that correct processing greatly improves efficiency and makes cache
Squid what it actually should be - caching proxy. Of course, you can
just pay the team a few thousand dollars - and this will be done with
ease. However, I believe that such basic functionality must be
implemented by default.

It is enough that Squid does not support and will not support compression.

07.06.2016 0:09, Heiler Bemerguy ?????:
>
>
> Web servers uses the "vary" tag, not "accept-encoding" tag exactly.
Like these sniffed examples:
>
> Vary: *
> Vary: Accept
> Vary: Accept-Encoding
> Vary: Accept-Encoding
> Vary: Accept-Encoding, Accept-Encoding
> Vary: Accept-Encoding,Host
> Vary: Accept-Encoding, User-Agent
> Vary: Accept-Encoding,User-Agent
> Vary: Accept-Encoding,X-Device-Type, Accept-Encoding
> Vary: Accept-Encoding,X-UA-Device
> Vary: If-None-Match, If-Modified-Since
> Vary: Origin
> Vary: Origin, Access-Control-Request-Headers,
Access-Control-Request-Method
> Vary: User-Agent
> Vary: User-Agent,Accept
>
> and all of them have no %20
>
>
> --
> Best Regards,
>
> Heiler Bemerguy
> Network Manager - CINBESA
> 55 91 98151-4894/3184-1751
> Em 06/06/2016 15:01, Yuri Voinov escreveu:
>>
>
>
> 06.06.2016 23:47, Heiler Bemerguy ?????:
>
>
>
>
>       > These are the variations for the "accept-encoding" tag I
>       found when sniffing my client's connections. And they're of all
>       kind. Newer and older browsers, mobile phones, windows updates,
>       whatever..
>
>
>
>       > It got a total of 11.437 requests from clients to squid.
>
>
>
>
>
>       > *accept-encoding: gzip, deflate**
>
>       > **Accept-Encoding: gzip, deflate**
>
>       > **Accept-Encoding: gzip,deflate**
>
>       > **Accept-Encoding: gzip, deflate, lzma, sdch**
>
>       > **Accept-Encoding: gzip, deflate, sdch**
>
>       > **Accept-Encoding: gzip,deflate,sdch**
>
>       > **Accept-Encoding: gzip, xeflate, sdch**
>
>       > **Accept-Encoding: identity**
>
>       > **Accept-Encoding: identity;q=1, *;q=0*
>
>
>
>
>
>       > Notice that some have spaces, some not, but I haven't seen
>       any "%20" representing a space. Is the "%20" put there by squid
>       itself?
>
> No. This comes from web-servers.
>
>
>
>
>
>       > --
>
>       > Best Regards,
>
>
>
>       > Heiler Bemerguy
>
>       > Network Manager - CINBESA
>
>       > 55 91 98151-4894/3184-1751
>
>
>
>
>
>       > Em 06/06/2016 12:08, Yuri Voinov escreveu:
>
>       > Ok, why not to replace %20 to original space symbol?
>
>
>
>
>
>       > 06.06.2016 20:27, joe ?????:
>
>       > >>> not good just to strip %20 lol as i post it
>       remove also  string was belong to
>
>       > >>> the date
>
>       > >>> we need to remove all of those string start with
>       ,%20    as ,%20sdch so
>
>       > >>> its not eassy detection
>
>       > >>>
>
>       > >>> it kill 
>       if-modified-since="Mon,%2006%20Jun%202016%2014%3A31%3A32%20GMT",
>
>       > >>>
>
>       > >>> if you notice this string in vary  has %20 so
>       just wide search and
>
>       > clear it
>
>       > >>> remove those :(
>
>       > >>>
>
>       > >>>
>
>       > >>>
>
>       > >>> --
>
>       > >>> View this message in context:
>
>
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677856.html
>
>       > >>> Sent from the Squid - Users mailing list archive
>       at Nabble.com.
>
>       > >>> _______________________________________________
>
>       > >>> squid-users mailing list
>
>       > >>> squid-users at lists.squid-cache.org
>
>       > >>>
>       http://lists.squid-cache.org/listinfo/squid-users
>
>       >>
>
>       >>
>
>       >>
>
>       >> _______________________________________________
>
>       >> squid-users mailing list
>
>       >> squid-users at lists.squid-cache.org
>
>       >> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVb5TAAoJENNXIZxhPexG1rMH/2xIrVzEmiSCUWs5Hzgbue84
xTTKe8zzT4E65TVntmmtERVkClKhDS8r32a/yPOH7wmewbdKrhkGAXznZbL9a1jJ
hSEb7ArOizZ4Sifq/IrpfAqUOGuH2Sy9Fun1htvCVbAPXa6o8geYETixQssSkeTp
pjpcgQMlJIwzmKZFQwjdQSp0w9fbcGTElDRQZMMsI/Iqh/uYPAroU3Nm+J/EBMiG
95ROl4jJkl0tlG8WViDGBKQrz1GFA3d/eDJEd/7Owbe+3lt3sB7Qt3j/6Bjl3GCw
Nu8pCRkXsnVPBD3qlkHZEjzvX2zDFf0SXGimGi+WBMvFfOYIjlbgt+St7YfP/74=
=n3mJ
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/96b20bac/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/96b20bac/attachment.key>

From yvoinov at gmail.com  Mon Jun  6 18:20:55 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 7 Jun 2016 00:20:55 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <24a6a3c4-cf1c-4f14-c9b8-7e1b2a8a6ae2@cinbesa.com.br>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <16a59d21-99ef-b4a0-9aed-8238b0e90fba@gmail.com>
 <24a6a3c4-cf1c-4f14-c9b8-7e1b2a8a6ae2@cinbesa.com.br>
Message-ID: <f3d5efb4-7133-3de1-dc13-08252ad314f7@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
By the way, we have another problem. Caching is greatly reduced by the
presence of User-Agent header Vary. Although I know that Amos says - he
says, we should break the Internet and cached separately all types of
user agents. However, this leads to duplication of content. Significant
duplication. Accordingly, we are able to throw out Vary all but the
Accept-Encoding - at our own risk, through the manipulation of headlines.

07.06.2016 0:09, Heiler Bemerguy ?????:
>
>
> Web servers uses the "vary" tag, not "accept-encoding" tag exactly.
Like these sniffed examples:
>
> Vary: *
> Vary: Accept
> Vary: Accept-Encoding
> Vary: Accept-Encoding
> Vary: Accept-Encoding, Accept-Encoding
> Vary: Accept-Encoding,Host
> Vary: Accept-Encoding, User-Agent
> Vary: Accept-Encoding,User-Agent
> Vary: Accept-Encoding,X-Device-Type, Accept-Encoding
> Vary: Accept-Encoding,X-UA-Device
> Vary: If-None-Match, If-Modified-Since
> Vary: Origin
> Vary: Origin, Access-Control-Request-Headers,
Access-Control-Request-Method
> Vary: User-Agent
> Vary: User-Agent,Accept
>
> and all of them have no %20
>
>
> --
> Best Regards,
>
> Heiler Bemerguy
> Network Manager - CINBESA
> 55 91 98151-4894/3184-1751
> Em 06/06/2016 15:01, Yuri Voinov escreveu:
>>
>
>
> 06.06.2016 23:47, Heiler Bemerguy ?????:
>
>
>
>
>       > These are the variations for the "accept-encoding" tag I
>       found when sniffing my client's connections. And they're of all
>       kind. Newer and older browsers, mobile phones, windows updates,
>       whatever..
>
>
>
>       > It got a total of 11.437 requests from clients to squid.
>
>
>
>
>
>       > *accept-encoding: gzip, deflate**
>
>       > **Accept-Encoding: gzip, deflate**
>
>       > **Accept-Encoding: gzip,deflate**
>
>       > **Accept-Encoding: gzip, deflate, lzma, sdch**
>
>       > **Accept-Encoding: gzip, deflate, sdch**
>
>       > **Accept-Encoding: gzip,deflate,sdch**
>
>       > **Accept-Encoding: gzip, xeflate, sdch**
>
>       > **Accept-Encoding: identity**
>
>       > **Accept-Encoding: identity;q=1, *;q=0*
>
>
>
>
>
>       > Notice that some have spaces, some not, but I haven't seen
>       any "%20" representing a space. Is the "%20" put there by squid
>       itself?
>
> No. This comes from web-servers.
>
>
>
>
>
>       > --
>
>       > Best Regards,
>
>
>
>       > Heiler Bemerguy
>
>       > Network Manager - CINBESA
>
>       > 55 91 98151-4894/3184-1751
>
>
>
>
>
>       > Em 06/06/2016 12:08, Yuri Voinov escreveu:
>
>       > Ok, why not to replace %20 to original space symbol?
>
>
>
>
>
>       > 06.06.2016 20:27, joe ?????:
>
>       > >>> not good just to strip %20 lol as i post it
>       remove also  string was belong to
>
>       > >>> the date
>
>       > >>> we need to remove all of those string start with
>       ,%20    as ,%20sdch so
>
>       > >>> its not eassy detection
>
>       > >>>
>
>       > >>> it kill 
>       if-modified-since="Mon,%2006%20Jun%202016%2014%3A31%3A32%20GMT",
>
>       > >>>
>
>       > >>> if you notice this string in vary  has %20 so
>       just wide search and
>
>       > clear it
>
>       > >>> remove those :(
>
>       > >>>
>
>       > >>>
>
>       > >>>
>
>       > >>> --
>
>       > >>> View this message in context:
>
>
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677856.html
>
>       > >>> Sent from the Squid - Users mailing list archive
>       at Nabble.com.
>
>       > >>> _______________________________________________
>
>       > >>> squid-users mailing list
>
>       > >>> squid-users at lists.squid-cache.org
>
>       > >>>
>       http://lists.squid-cache.org/listinfo/squid-users
>
>       >>
>
>       >>
>
>       >>
>
>       >> _______________________________________________
>
>       >> squid-users mailing list
>
>       >> squid-users at lists.squid-cache.org
>
>       >> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVb8HAAoJENNXIZxhPexGLFYH+wYzHsa465++FyY/JxlAL10x
ztUCw+ciuEg3TYHWX84tFyL8ooX/CpxzVzf/cf4KbkEDGx6elOxHPnV1PljGXaut
aApM4yxIFA3R9nVAZbGzXkgM2InZ6mGfdI4xHp9aifklqG6Kjnhl6/zk3m2rJXIe
GLIAUnzkKKcDPW/g33vFCgiLAYKbVRnlf8vlgShu/NkgiYgWjhuonDUIQ6mOtlIj
nbDLKUzPVhIG8sfblYmYd1uH0vfonfGeGCbDabo66zaJHC9E4GhcphZan7gon6NF
aTDKw1E2wTN262UtFLSTkPsYjFZCl/TcIBhED/7EQ62LsuqqP+Mtr7NQQHFZdJg=
=KWYR
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/9bcb4189/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/9bcb4189/attachment.key>

From chip_pop at hotmail.com  Mon Jun  6 17:57:11 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 10:57:11 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <f3d5efb4-7133-3de1-dc13-08252ad314f7@gmail.com>
References: <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <16a59d21-99ef-b4a0-9aed-8238b0e90fba@gmail.com>
 <24a6a3c4-cf1c-4f14-c9b8-7e1b2a8a6ae2@cinbesa.com.br>
 <f3d5efb4-7133-3de1-dc13-08252ad314f7@gmail.com>
Message-ID: <1465235831719-4677869.post@n4.nabble.com>

yup  if user agents  exist in vary  that leads to many object same size i
dont know if the servers use the user agents to send to specific mobile a
smaller object same name  or different compression
but right now wat im doing is just tinny  peace of it saving us more hit %
it wont harm app mobile or browsers but they get benefit of the cache hit
that all




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677869.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon Jun  6 18:58:20 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 7 Jun 2016 00:58:20 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <24a6a3c4-cf1c-4f14-c9b8-7e1b2a8a6ae2@cinbesa.com.br>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <16a59d21-99ef-b4a0-9aed-8238b0e90fba@gmail.com>
 <24a6a3c4-cf1c-4f14-c9b8-7e1b2a8a6ae2@cinbesa.com.br>
Message-ID: <ec3362bd-da64-f23e-469e-49ca54c7a050@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
BTW, gyus. This is non-patched 3.5.19.

2016/06/06 23:08:24 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'https://connect.facebook.net/en_US/sdk.js'
'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
2016/06/06 23:08:24 kid1| clientProcessHit: Vary object loop!
2016/06/06 23:11:25 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'https://connect.facebook.net/en_US/sdk.js'
'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
2016/06/06 23:11:25 kid1| clientProcessHit: Vary object loop!
2016/06/06 23:12:13 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'https://connect.facebook.net/en_US/sdk.js'
'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
2016/06/06 23:12:13 kid1| clientProcessHit: Vary object loop!
2016/06/06 23:13:24 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'https://connect.facebook.net/en_US/sdk.js'
'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
2016/06/06 23:13:24 kid1| clientProcessHit: Vary object loop!
2016/06/07 00:00:23 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'https://connect.facebook.net/en_US/sdk.js'
'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
2016/06/07 00:00:23 kid1| clientProcessHit: Vary object loop!
2016/06/07 00:05:01 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'https://connect.facebook.net/en_US/sdk.js'
'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
2016/06/07 00:05:01 kid1| clientProcessHit: Vary object loop!

What an idiotic accept-encoding, right?

'accept-encoding="gzip,%20deflate,%20sdch,%20br"'

With unknown %20br tag at the end. Seems to be FB bug, yea? Hey, Mark!
Did you see this? Your programmers are stupid diletants! :))))))))

07.06.2016 0:09, Heiler Bemerguy ?????:
>
>
> Web servers uses the "vary" tag, not "accept-encoding" tag exactly.
Like these sniffed examples:
>
> Vary: *
> Vary: Accept
> Vary: Accept-Encoding
> Vary: Accept-Encoding
> Vary: Accept-Encoding, Accept-Encoding
> Vary: Accept-Encoding,Host
> Vary: Accept-Encoding, User-Agent
> Vary: Accept-Encoding,User-Agent
> Vary: Accept-Encoding,X-Device-Type, Accept-Encoding
> Vary: Accept-Encoding,X-UA-Device
> Vary: If-None-Match, If-Modified-Since
> Vary: Origin
> Vary: Origin, Access-Control-Request-Headers,
Access-Control-Request-Method
> Vary: User-Agent
> Vary: User-Agent,Accept
>
> and all of them have no %20
>
>
> --
> Best Regards,
>
> Heiler Bemerguy
> Network Manager - CINBESA
> 55 91 98151-4894/3184-1751
> Em 06/06/2016 15:01, Yuri Voinov escreveu:
>>
>
>
> 06.06.2016 23:47, Heiler Bemerguy ?????:
>
>
>
>
>       > These are the variations for the "accept-encoding" tag I
>       found when sniffing my client's connections. And they're of all
>       kind. Newer and older browsers, mobile phones, windows updates,
>       whatever..
>
>
>
>       > It got a total of 11.437 requests from clients to squid.
>
>
>
>
>
>       > *accept-encoding: gzip, deflate**
>
>       > **Accept-Encoding: gzip, deflate**
>
>       > **Accept-Encoding: gzip,deflate**
>
>       > **Accept-Encoding: gzip, deflate, lzma, sdch**
>
>       > **Accept-Encoding: gzip, deflate, sdch**
>
>       > **Accept-Encoding: gzip,deflate,sdch**
>
>       > **Accept-Encoding: gzip, xeflate, sdch**
>
>       > **Accept-Encoding: identity**
>
>       > **Accept-Encoding: identity;q=1, *;q=0*
>
>
>
>
>
>       > Notice that some have spaces, some not, but I haven't seen
>       any "%20" representing a space. Is the "%20" put there by squid
>       itself?
>
> No. This comes from web-servers.
>
>
>
>
>
>       > --
>
>       > Best Regards,
>
>
>
>       > Heiler Bemerguy
>
>       > Network Manager - CINBESA
>
>       > 55 91 98151-4894/3184-1751
>
>
>
>
>
>       > Em 06/06/2016 12:08, Yuri Voinov escreveu:
>
>       > Ok, why not to replace %20 to original space symbol?
>
>
>
>
>
>       > 06.06.2016 20:27, joe ?????:
>
>       > >>> not good just to strip %20 lol as i post it
>       remove also  string was belong to
>
>       > >>> the date
>
>       > >>> we need to remove all of those string start with
>       ,%20    as ,%20sdch so
>
>       > >>> its not eassy detection
>
>       > >>>
>
>       > >>> it kill 
>       if-modified-since="Mon,%2006%20Jun%202016%2014%3A31%3A32%20GMT",
>
>       > >>>
>
>       > >>> if you notice this string in vary  has %20 so
>       just wide search and
>
>       > clear it
>
>       > >>> remove those :(
>
>       > >>>
>
>       > >>>
>
>       > >>>
>
>       > >>> --
>
>       > >>> View this message in context:
>
>
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677856.html
>
>       > >>> Sent from the Squid - Users mailing list archive
>       at Nabble.com.
>
>       > >>> _______________________________________________
>
>       > >>> squid-users mailing list
>
>       > >>> squid-users at lists.squid-cache.org
>
>       > >>>
>       http://lists.squid-cache.org/listinfo/squid-users
>
>       >>
>
>       >>
>
>       >>
>
>       >> _______________________________________________
>
>       >> squid-users mailing list
>
>       >> squid-users at lists.squid-cache.org
>
>       >> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVcfKAAoJENNXIZxhPexG2QMIAK79moVhAfyKDeNz7CuRnUUB
3wUd8flCfLUtWqqbz/QKnma2ZsmepimmmiVfHCG1vilBlN3e4LUkw+5UA/ehjQNO
EfCSsOYTe9OPyiwV9L6gwsF/mourebdC8/Btyi/LFMF85wlvRjLuPEUaLPShQ6Zy
IrJzFicThQ4sIyG8WhriaRJWwC1j3XDtzxulG8Lo38NUWW5SXeA4H4vjauan8kt4
WOrrIRRGpjmSRtmvoI78tw3HXeHrY8rIPoCZRWmAwQmQmcw6mhKAuf/aB2Cxv38w
WF7svv5X2oyzjo4LXWq2YFo8MUodqmXukifZyybLcQzw4kg/mejrq2/dCrW9tXU=
=tVr0
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/cd8720cb/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/cd8720cb/attachment.key>

From chip_pop at hotmail.com  Mon Jun  6 18:21:35 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 11:21:35 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <f3d5efb4-7133-3de1-dc13-08252ad314f7@gmail.com>
References: <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <16a59d21-99ef-b4a0-9aed-8238b0e90fba@gmail.com>
 <24a6a3c4-cf1c-4f14-c9b8-7e1b2a8a6ae2@cinbesa.com.br>
 <f3d5efb4-7133-3de1-dc13-08252ad314f7@gmail.com>
Message-ID: <1465237295605-4677871.post@n4.nabble.com>

like this link use lots a fkp command lol
http://api.footballaddicts.com/teams' 

'accept="application%2Fvnd.livescore_app.api.v4.android+json",
if-none-match="%22306f685f7466a258d4884f92bdf8259a%22",
if-modified-since="Sun,%2005%20Jun%202016%2020%3A11%3A13%20GMT",
accept-language="en", accept-encoding="gzip", x-client-locale="en_LB",
user-agent="se.footballaddicts.livescore%2F3.6.18", x-device="craterq3g"'


'accept="application%2Fvnd.livescore_app.api.v4.android+json"
, if-none-match="%22306f685f7466a258d4884f92bdf8259a%22"
, if-modified-since="Sun,%2005%20Jun%202016%2020%3A11%3A13%20GMT"
, accept-language="en"
, accept-encoding="gzip"
, x-client-locale="en_LB"
, user-agent="se.footballaddicts.livescore%2F3.6.18"
, x-device="craterq3g"'

its android app football     caled forza
squid do cache those object but i dont know on other phone can benefit also
the date can kill the object
so its not usable after the date change

only  those standard we can save a bit hit %    gzip,%20deflate,%20sdch
and wow most of the cached vary ar those  in vary


last patch 4   ar good enough  it dose not brake the vary so fare so good
optimizing it depend on dev team so if they will add and fix my code or not
a bit of cache hit the better
i understand if they dont want to i will keep my work privet for me and i
wont post any more



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677871.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon Jun  6 19:02:15 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 7 Jun 2016 01:02:15 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465237295605-4677871.post@n4.nabble.com>
References: <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <16a59d21-99ef-b4a0-9aed-8238b0e90fba@gmail.com>
 <24a6a3c4-cf1c-4f14-c9b8-7e1b2a8a6ae2@cinbesa.com.br>
 <f3d5efb4-7133-3de1-dc13-08252ad314f7@gmail.com>
 <1465237295605-4677871.post@n4.nabble.com>
Message-ID: <7e16d243-e310-7046-be6f-e3dac48aefb9@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Joe, keep me linked. Your patches save my traffic.


07.06.2016 0:21, joe ?????:
> like this link use lots a fkp command lol
> http://api.footballaddicts.com/teams'
>
> 'accept="application%2Fvnd.livescore_app.api.v4.android+json",
> if-none-match="%22306f685f7466a258d4884f92bdf8259a%22",
> if-modified-since="Sun,%2005%20Jun%202016%2020%3A11%3A13%20GMT",
> accept-language="en", accept-encoding="gzip", x-client-locale="en_LB",
> user-agent="se.footballaddicts.livescore%2F3.6.18", x-device="craterq3g"'
>
>
> 'accept="application%2Fvnd.livescore_app.api.v4.android+json"
> , if-none-match="%22306f685f7466a258d4884f92bdf8259a%22"
> , if-modified-since="Sun,%2005%20Jun%202016%2020%3A11%3A13%20GMT"
> , accept-language="en"
> , accept-encoding="gzip"
> , x-client-locale="en_LB"
> , user-agent="se.footballaddicts.livescore%2F3.6.18"
> , x-device="craterq3g"'
>
> its android app football     caled forza
> squid do cache those object but i dont know on other phone can benefit
also
> the date can kill the object
> so its not usable after the date change
>
> only  those standard we can save a bit hit %    gzip,%20deflate,%20sdch
> and wow most of the cached vary ar those  in vary
>
>
> last patch 4   ar good enough  it dose not brake the vary so fare so good
> optimizing it depend on dev team so if they will add and fix my code
or not
> a bit of cache hit the better
> i understand if they dont want to i will keep my work privet for me and i
> wont post any more
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677871.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVci3AAoJENNXIZxhPexGpxAH/jyaZFOz/rcSrjp9aJS6ilqW
S9zt5JCLLlzDwCiqW8NcFA6svAHsTQBlfDQR5G3tIIK0wqM+7hmRVEevrZQALeMO
MU+CZgZLYatWDrTwWbwKpC01SX8iwtI0TEuRW1B74l2AZ5ABYmDeLsNTt1qmOSg1
ENiAbLbYbhM/vol0sXnrZquLdc+3guKM6ZnXGU+WdOmnwGuf+tSRUnu6swsXz/fV
U6bMzKcOElSeMjcijRrwYLJLKkUsXD54ISJlz6D40Y/kigu3zPiJu8uC9hrYnxTg
5Orif7SJIOP/G5Mys6xubz5Unr0biF+lyuq9yp53tno5l94B882OKennmKDQu9A=
=VW54
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/89db3ff8/attachment.key>

From squid3 at treenet.co.nz  Mon Jun  6 22:26:55 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 7 Jun 2016 10:26:55 +1200
Subject: [squid-users] Vary object loop returns
In-Reply-To: <82d90a89-b6ad-0d56-bfe6-4e7dcc19f23b@gmail.com>
References: <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <87674423-4c25-0a90-2248-db64178025e5@treenet.co.nz>
 <82d90a89-b6ad-0d56-bfe6-4e7dcc19f23b@gmail.com>
Message-ID: <c53a410f-fed6-038b-aa5e-f80489ec58e3@treenet.co.nz>

On 6/06/2016 8:10 p.m., Yuri wrote:
> Heh,
> 
> and breaking Internet...

No it does not. Every HTTP agent has mandatory support for un-encoded
objects. The use of encodings is optional.

> 
> So, for example, my Squid's built with ecap gzip support. What will be
> result?

Hmm. The ecap adaptor REQMOD actions should be doing all this
Accept-Encoding manipulation for you. If it was working correctly these
patches of joe's would not work.

Amos



From squid3 at treenet.co.nz  Mon Jun  6 22:38:30 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 7 Jun 2016 10:38:30 +1200
Subject: [squid-users] Vary object loop returns
In-Reply-To: <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
Message-ID: <70752175-46cb-22ea-ad49-f158c6cd2112@treenet.co.nz>

On 7/06/2016 5:47 a.m., Heiler Bemerguy wrote:
> 
> These are the variations for the "accept-encoding" tag I found when
> sniffing my client's connections. And they're of all kind. Newer and
> older browsers, mobile phones, windows updates, whatever..
> 
> It got a total of 11.437 requests from clients to squid.
> 
> 
> *accept-encoding: gzip, deflate**
> **Accept-Encoding: gzip, deflate**
> **Accept-Encoding: gzip,deflate**
> **Accept-Encoding: gzip, deflate, lzma, sdch**
> **Accept-Encoding: gzip, deflate, sdch**
> **Accept-Encoding: gzip,deflate,sdch**
> **Accept-Encoding: gzip, xeflate, sdch**
> **Accept-Encoding: identity**
> **Accept-Encoding: identity;q=1, *;q=0*
> 

Thanks.

> 
> Notice that some have spaces, some not, but I haven't seen any "%20"
> representing a space. Is the "%20" put there by squid itself?

Yes. joe and Yuri are playing around with the cache ID key produced from
combining Vary with request headers contents (the variant version of
Store-ID). Not the request message itself.

Which is part of why this is not being accepted. The server is still
delivered the same request headers. So a server that responds with SDCH
encoding to those requests with "sdch", will also be delivered to the
top for clients that dont support SDCH.

Amos



From yvoinov at gmail.com  Mon Jun  6 22:39:48 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 7 Jun 2016 04:39:48 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <c53a410f-fed6-038b-aa5e-f80489ec58e3@treenet.co.nz>
References: <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <87674423-4c25-0a90-2248-db64178025e5@treenet.co.nz>
 <82d90a89-b6ad-0d56-bfe6-4e7dcc19f23b@gmail.com>
 <c53a410f-fed6-038b-aa5e-f80489ec58e3@treenet.co.nz>
Message-ID: <28a37cec-826d-c030-68af-2aab8ba7e753@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


07.06.2016 4:26, Amos Jeffries ?????:
> On 6/06/2016 8:10 p.m., Yuri wrote:
>> Heh,
>>
>> and breaking Internet...
>
> No it does not. Every HTTP agent has mandatory support for un-encoded
> objects. The use of encodings is optional.
>
>>
>> So, for example, my Squid's built with ecap gzip support. What will be
>> result?
>
> Hmm. The ecap adaptor REQMOD actions should be doing all this
> Accept-Encoding manipulation for you. If it was working correctly these
> patches of joe's would not work.
But they works. Result is very significant.
Ecap Gzip we are talking about is only one, very old, and has long been
abandoned.

Others around the world do not have. We do not just repeatedly asked,
gzip support in squid whether implemented.
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVfuzAAoJENNXIZxhPexGw+YH/R7NPfX60QrZo7DCn/rLBnkn
r1vjPgYrAVVlg3Gx4t6IdUcQ1HRA4jjJ/NcQtQOAjBII6d/2q6rwNrGD+4iOctK2
7RcUG4xin0z/1FvevQOmBh8A67wh4wHA0+OkZ0qKJ3wk2o4hMGCNn1+8eJLV729F
3XjOprPK6Ug66iClfG2ZYYEM4ymZKzxbOdrP/JU/uYLnw1gwHT9pZibCTta7aWAV
myq1N3hNBEiDY3zPvkCdo1k/0sq9lb9vDgxjQKrfergJNgsEgvjZYBxxs1bOEsUM
HTKN1HouViv4wQKd8zNZw6RzJXT4xb5MuQt5H73Z/bujcRsrPKX15BJyWoDhLZ4=
=T230
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/e1e3fa7a/attachment.key>

From yvoinov at gmail.com  Mon Jun  6 22:45:19 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 7 Jun 2016 04:45:19 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <70752175-46cb-22ea-ad49-f158c6cd2112@treenet.co.nz>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <70752175-46cb-22ea-ad49-f158c6cd2112@treenet.co.nz>
Message-ID: <6c453902-484b-4d65-18ff-18c539bf0102@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
This is true. However, we have no one bothers to intercept the request
and tell the server that we only accept gzip encoding. What I personally do.

My config, partially, contains this:

request_header_access Accept-Encoding deny all
request_header_replace Accept-Encoding gzip;q=1.0, identity; q=0.5, *;q=0

and this:

reply_header_access Vary deny all
reply_header_replace Vary Accept-Encoding

So, my squid deals with Accept-Encoding=gzip and, with patches from Joe,
replies which contains _the same_ accept encoding.

This can explain my significant cache HIT increasing.

07.06.2016 4:38, Amos Jeffries ?????:
> Which is part of why this is not being accepted. The server is still
> delivered the same request headers. So a server that responds with SDCH
> encoding to those requests with "sdch", will also be delivered to the
> top for clients that dont support SDCH.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVfz/AAoJENNXIZxhPexGQN8IALbMi+BXTQOULoHXfac1q3Ux
yXtzo+W7cQRdOKN+bQq33BZUQiMDpjJYfHPUYFe2Rt8P9AgWr6nIlX4joUCs3e9g
M9a5iu2YtTxpVBQEwHWGGvvw1uGkLJdkCis7Fc6iHH2RpdqGgIItzjjpVFFZyayf
pPOmVw79oXZXNVw9eagYPEMcINrR+v9wMa3l1RPubr0vmrFQs0PsRmnKCWwDIDIb
skdrp5/07ua79bkeI3fmjTFBOfHfXIHI9T11w8WdeRvKyxamHb/Q5CSxHwEouyZD
zl61kqe2PBvRbtCM/NwctITsjzPA6GqHrsH94gi3JsvlX9FtZHsEGRSK78OypDk=
=gIAW
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/741f5b9c/attachment.key>

From squid3 at treenet.co.nz  Mon Jun  6 22:57:47 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 7 Jun 2016 10:57:47 +1200
Subject: [squid-users] Vary object loop returns
In-Reply-To: <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
Message-ID: <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>

On 7/06/2016 5:55 a.m., Yuri Voinov wrote:
> 
> So.
> 
> Squid DOES NOT and DON'T BE support gzip. The only way to do it - use
> ecap + desupported ecap gzip adapter. Let's accept this. We can support
> gzip. With restrictions. Ok.
> 
> any other compression - false. No. No way. Get out. and so on.
> 
>  identity - this is uncompressed type.
> 
> That's all, folks.
> 
> Finally. As Joe does, we can remain only gzip and identity in
> Accept-Encoding and truncate all remaining.

Locking the entire Internet to using your personal choice of gzip
compression or none.

gzip is the slowest and more resource hungry type of compression there
is. deflate is actually faster for clients and just as widely supported.

> 
> Without any problem. Moreover, this type of can be push to all brunches
> of squid without any problem, because of this dramatically increases
> byte HIT.

Responding with a single object to all requests makes your HIT ratio
100% guaranteed. The clients wont like you though if all they ever see
is the same cat picture.

It sounds ridiculous when put that way, but that is what these patches
are doing for a unknown number of those "gained" HITs. See my previous
post about how none of these patches are changing the request the server
gets.

You are once again sweeping asside the critical requirement of content
integrity to achieve high HIT ratio. Which is not something that I can
accept into Squid as a default action.

Amos


From squid3 at treenet.co.nz  Mon Jun  6 23:13:00 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 7 Jun 2016 11:13:00 +1200
Subject: [squid-users] Vary object loop returns
In-Reply-To: <f3d5efb4-7133-3de1-dc13-08252ad314f7@gmail.com>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <16a59d21-99ef-b4a0-9aed-8238b0e90fba@gmail.com>
 <24a6a3c4-cf1c-4f14-c9b8-7e1b2a8a6ae2@cinbesa.com.br>
 <f3d5efb4-7133-3de1-dc13-08252ad314f7@gmail.com>
Message-ID: <22f4cc36-ef1a-c566-4d26-24e70d4bb0cc@treenet.co.nz>

On 7/06/2016 6:20 a.m., Yuri Voinov wrote:
> 
> By the way, we have another problem. Caching is greatly reduced by the
> presence of User-Agent header Vary. Although I know that Amos says - he
> says, we should break the Internet and cached separately all types of
> user agents.

Please do not put your own beliefs into my mouth. I am very much in
favour of denying Vary:User-Agent from being cached *at all* until the
UA start sending sensible contents in the header. That would lower your
precious HIT ratio a tiny amount.

BTW: Do you know what "breaking the Internet" actually means? It's a bit
ironic that you would throw that insult at me while praising what these
patches currently do.

Amos


From chip_pop at hotmail.com  Mon Jun  6 22:47:23 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 15:47:23 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <70752175-46cb-22ea-ad49-f158c6cd2112@treenet.co.nz>
References: <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <70752175-46cb-22ea-ad49-f158c6cd2112@treenet.co.nz>
Message-ID: <1465253243818-4677879.post@n4.nabble.com>

right  but the way im doing it  dose not show you the same cat pic lol 
it just prevent caching identical object making it less   and beter hit
ratio .
before the cache id the way its dose it prevent other browser from having
cached object
that why you see that varyEvaluateMatch: Oops. Not a Vary match on second
attempt
cause it has different cache id and the object is 100% same used by chrome
or firefox or wat ever
so why not filtering a bit those extra waseting space in cache-dir and serve
the right shared object for almost all browsers   and i do my test on
desktop and mobile mac or android and i do ask my client if they ar facing
any issue with any http mobile app or browser to report it  so fare so good
>Yes. joe and Yuri are playing around with the cache ID



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677879.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Mon Jun  6 23:00:42 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 6 Jun 2016 16:00:42 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465253243818-4677879.post@n4.nabble.com>
References: <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <70752175-46cb-22ea-ad49-f158c6cd2112@treenet.co.nz>
 <1465253243818-4677879.post@n4.nabble.com>
Message-ID: <1465254042969-4677880.post@n4.nabble.com>

and by the way guys please dont use my patch for production they do have bug
it was experimental only
testing me and yuri  i did not know it was going to cause trouble sorry for
that good bye



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677880.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Tue Jun  7 01:04:39 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 7 Jun 2016 13:04:39 +1200
Subject: [squid-users] How to mark HIT using qos_flow in squid mode
 SmpCarpCluster
In-Reply-To: <1465115876765-4677812.post@n4.nabble.com>
References: <1465115876765-4677812.post@n4.nabble.com>
Message-ID: <1e426659-c3de-0002-66a2-7115203c72f2@treenet.co.nz>

On 5/06/2016 8:37 p.m., Dhani-Dhanu wrote:
> Hallo
> 
> First, i would to say thanks you for Support..
> 
> second, i have running squid 3.5.19 with SmpCarpCluster..And work very nice
> and nothing problem.
> 
> But i need to Bypass Cache HIT with qos_flows. On Standar Config qos_flows
> working as well, but on SmpCarpCluster qos_flow not work.
> 
> Can anyone would to help me to info regarding this issue?
> 

If you want the backend TOS value to be passed out to the client the
backend can use qos_flows but then the frontend must not over-write that
with its own value.

There is also no support in Linux for applications receiving the TOS
value on their inbound packets. So using the MARK instead of TOS is needed.

Amos



From yvoinov at gmail.com  Tue Jun  7 08:48:32 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 7 Jun 2016 14:48:32 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
Message-ID: <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


07.06.2016 4:57, Amos Jeffries ?????:
> On 7/06/2016 5:55 a.m., Yuri Voinov wrote:
>>
>> So.
>>
>> Squid DOES NOT and DON'T BE support gzip. The only way to do it - use
>> ecap + desupported ecap gzip adapter. Let's accept this. We can support
>> gzip. With restrictions. Ok.
>>
>> any other compression - false. No. No way. Get out. and so on.
>>
>>  identity - this is uncompressed type.
>>
>> That's all, folks.
>>
>> Finally. As Joe does, we can remain only gzip and identity in
>> Accept-Encoding and truncate all remaining.
>
> Locking the entire Internet to using your personal choice of gzip
> compression or none.
>
> gzip is the slowest and more resource hungry type of compression there
> is. deflate is actually faster for clients and just as widely supported.
Unfortunately, Amos, no one has written any other compression algorithms
support module. We have to eat what they give.
>
>
>>
>> Without any problem. Moreover, this type of can be push to all brunches
>> of squid without any problem, because of this dramatically increases
>> byte HIT.
>
> Responding with a single object to all requests makes your HIT ratio
> 100% guaranteed. The clients wont like you though if all they ever see
> is the same cat picture.
>
> It sounds ridiculous when put that way, but that is what these patches
> are doing for a unknown number of those "gained" HITs. See my previous
> post about how none of these patches are changing the request the server
> gets.
But no one asked the question - why Squid in production installations
has such a low hit ratio that raises the question of expediency of
application caching proxy. We do believe that this is a caching proxy?
>
>
> You are once again sweeping asside the critical requirement of content
> integrity to achieve high HIT ratio. Which is not something that I can
> accept into Squid as a default action.
I continue to believe that 20% is unacceptably low cache hit ratio,
given the very aggressive settings and the active use of Store ID. Which
brings us back to the idea of the feasibility of using the SQUID as a whole.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVopgAAoJENNXIZxhPexGTJYH/iYl6gaWEYqnqgAB7vPytR6D
m2zKnUgL9Rit+LWCmvO4rA6/f2tXEGYvNJDk87gzmYDsS0yuPBySM4OHhZW3JKTK
Ly1DfnPBownfnw38zprWL70iz8UZ4nrXJZTOuxqe5gJC77aU9X+iuqARXk5naYUh
D0LaOnDgTNy1omVOMfeDs2pQwQyRzweAlFzZ30Xktt8DFA9wWv/tRQitLB2ubdsh
tw34Z1sjLYAW7M4EkmHcdkqSf2gKYeAylqst/3pFYAJJq1EUXsqF/J88JcSDjLl9
Bqq+29AvxNlg2EiNayC1PJ8FET0R/X8bjw1+mnvhCDWLKlSnKE/wmlqU4swaEsk=
=UR/N
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/0031775b/attachment.key>

From yvoinov at gmail.com  Tue Jun  7 09:12:17 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 7 Jun 2016 15:12:17 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <22f4cc36-ef1a-c566-4d26-24e70d4bb0cc@treenet.co.nz>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <16a59d21-99ef-b4a0-9aed-8238b0e90fba@gmail.com>
 <24a6a3c4-cf1c-4f14-c9b8-7e1b2a8a6ae2@cinbesa.com.br>
 <f3d5efb4-7133-3de1-dc13-08252ad314f7@gmail.com>
 <22f4cc36-ef1a-c566-4d26-24e70d4bb0cc@treenet.co.nz>
Message-ID: <05d220bc-5b1e-e6d7-8bec-bad1c580bb82@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


07.06.2016 5:13, Amos Jeffries ?????:
> On 7/06/2016 6:20 a.m., Yuri Voinov wrote:
>>
>> By the way, we have another problem. Caching is greatly reduced by the
>> presence of User-Agent header Vary. Although I know that Amos says - he
>> says, we should break the Internet and cached separately all types of
>> user agents.
>
> Please do not put your own beliefs into my mouth. I am very much in
Sorry, Amos. This was sarcasm. May be, not too relevant.
>
> favour of denying Vary:User-Agent from being cached *at all* until the
> UA start sending sensible contents in the header. That would lower your
> precious HIT ratio a tiny amount.
Maybe. However, this greatly increases the content duplication. ?gree?
>
>
> BTW: Do you know what "breaking the Internet" actually means? It's a bit
> ironic that you would throw that insult at me while praising what these
> patches currently do.
:) Really sorry.

Sometimes our experiments scratching the hell out of the display content
in browsers. That's what I called "break the Internet". :) But
seriously, we're trying to find a compromise between a high cache and
the desire to satisfy customers. It seems to me, mutually exclusive things.

Meanwhile, Amos, I still believe that the team should now, in 2016, to
seriously reconsider attitude to compress the content and possibly
revise Vary processing algorithms in favor of more vysokgo cache hit
ratio. Under the conditions of high-speed Internet only a high hit ratio
justifies the use of caching proxy.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVo/wAAoJENNXIZxhPexGWV0H/1XCPMLjjqtv+qbT542QNJOs
HHic3Enomue0C6zc7+h0+a8B+WAgxlGrIf4TSc+usHQpQG0UE/sqvHY6XmRKcfDF
XnW6Vmyg6At6AiVim3ZxTMoZqnJvFckMKCal8YQSnv48x8j13KX4WrK9zkDfOCPI
HyzKWpuGTnjsNdwpYkfDNm04m+shk31jfd7V8Px5MrOlwpwUM467iSkPfmMKqUl0
PbUAnr0lm2uPj8fYppP2UraI/58kquiFeAYa4UbFSqXSzMmXanMZ3HClmq8zvD+D
3MMrSGRWbD7aJm4e+pMWb9ghqTniUpU2vnJY6cq+Rsjvh2ZqQED5aQ7Gq6ai2/s=
=Tt9h
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/f3684919/attachment.key>

From squid3 at treenet.co.nz  Tue Jun  7 10:04:26 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 7 Jun 2016 22:04:26 +1200
Subject: [squid-users] Vary object loop returns
In-Reply-To: <28a37cec-826d-c030-68af-2aab8ba7e753@gmail.com>
References: <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <87674423-4c25-0a90-2248-db64178025e5@treenet.co.nz>
 <82d90a89-b6ad-0d56-bfe6-4e7dcc19f23b@gmail.com>
 <c53a410f-fed6-038b-aa5e-f80489ec58e3@treenet.co.nz>
 <28a37cec-826d-c030-68af-2aab8ba7e753@gmail.com>
Message-ID: <e1461fed-2b0f-e050-6c58-538cc55ac759@treenet.co.nz>

On 7/06/2016 10:39 a.m., Yuri Voinov wrote:
> 
> 
> 
> 07.06.2016 4:26, Amos Jeffries ?????:
>> On 6/06/2016 8:10 p.m., Yuri wrote:
>>> Heh,
>>>
>>> and breaking Internet...
> 
>> No it does not. Every HTTP agent has mandatory support for un-encoded
>> objects. The use of encodings is optional.
> 
>>>
>>> So, for example, my Squid's built with ecap gzip support. What will be
>>> result?
> 
>> Hmm. The ecap adaptor REQMOD actions should be doing all this
>> Accept-Encoding manipulation for you. If it was working correctly these
>> patches of joe's would not work.
> But they works. Result is very significant.
> Ecap Gzip we are talking about is only one, very old, and has long been
> abandoned.

IIRC, some months back you volunteered to do something about that.

I did take a look through the adapter code yesterday after posting this
and see that its using the Accept-Encoding header to decide what it can
do. But not altering it to tell the server what it wants.

I've asked joe if he is interested in fixing that bug in the adapter.
Which will be a lot more beneficial than the current patches as it would
avoid the extra squid.conf.


> 
> Others around the world do not have. We do not just repeatedly asked,
> gzip support in squid whether implemented.
> 

I know. A lot of asking for things and very little in the way of
contributions to help achieve it.

Thank you for testing joe's patches, even though I think the direction
is wrong it has been a big step forward.

Amos


From yvoinov at gmail.com  Tue Jun  7 10:29:28 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 7 Jun 2016 16:29:28 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <e1461fed-2b0f-e050-6c58-538cc55ac759@treenet.co.nz>
References: <60ab87da-538c-b3f0-8f3a-7fc979da4a1b@gmail.com>
 <1465059093431-4677806.post@n4.nabble.com>
 <3fb91d3d-cc7e-723b-73e9-e3610b141b4e@gmail.com>
 <1465072747768-4677808.post@n4.nabble.com>
 <2961df83-dd53-0bc8-bccc-26aa631097eb@gmail.com>
 <1465117836635-4677813.post@n4.nabble.com>
 <1f66c015-6c73-0ea8-4bf9-57a7e330f56f@gmail.com>
 <1465127939005-4677816.post@n4.nabble.com>
 <1465144131189-4677818.post@n4.nabble.com>
 <11e911da-ca4b-f2ee-0a96-367fe5e4354f@gmail.com>
 <1465159329064-4677823.post@n4.nabble.com>
 <87674423-4c25-0a90-2248-db64178025e5@treenet.co.nz>
 <82d90a89-b6ad-0d56-bfe6-4e7dcc19f23b@gmail.com>
 <c53a410f-fed6-038b-aa5e-f80489ec58e3@treenet.co.nz>
 <28a37cec-826d-c030-68af-2aab8ba7e753@gmail.com>
 <e1461fed-2b0f-e050-6c58-538cc55ac759@treenet.co.nz>
Message-ID: <1e772a03-338f-6852-3a36-01a8af291e1e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
BTW, Amos.

As Gzip adapter in great demand due to the Squid,and it not maintained
right now,  maybe Alex will conjunct it to the other ecap adapters
within Measurement Factory? Somehow, as loadable part of eCap.

Compression is very popular on the Web, and this problem should be
solved one way or another. And this adapter is highly suited to becoming
part of the SQUID installations.


07.06.2016 16:04, Amos Jeffries ?????:
> On 7/06/2016 10:39 a.m., Yuri Voinov wrote:
>>
>>
>>
>> 07.06.2016 4:26, Amos Jeffries ?????:
>>> On 6/06/2016 8:10 p.m., Yuri wrote:
>>>> Heh,
>>>>
>>>> and breaking Internet...
>>
>>> No it does not. Every HTTP agent has mandatory support for un-encoded
>>> objects. The use of encodings is optional.
>>
>>>>
>>>> So, for example, my Squid's built with ecap gzip support. What will be
>>>> result?
>>
>>> Hmm. The ecap adaptor REQMOD actions should be doing all this
>>> Accept-Encoding manipulation for you. If it was working correctly these
>>> patches of joe's would not work.
>> But they works. Result is very significant.
>> Ecap Gzip we are talking about is only one, very old, and has long been
>> abandoned.
>
> IIRC, some months back you volunteered to do something about that.
>
> I did take a look through the adapter code yesterday after posting this
> and see that its using the Accept-Encoding header to decide what it can
> do. But not altering it to tell the server what it wants.
>
> I've asked joe if he is interested in fixing that bug in the adapter.
> Which will be a lot more beneficial than the current patches as it would
> avoid the extra squid.conf.
>
>
>>
>> Others around the world do not have. We do not just repeatedly asked,
>> gzip support in squid whether implemented.
>>
>
> I know. A lot of asking for things and very little in the way of
> contributions to help achieve it.
>
> Thank you for testing joe's patches, even though I think the direction
> is wrong it has been a big step forward.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVqIIAAoJENNXIZxhPexGcXgH/i36fqyyfUjpvuzwtxosFjI+
JnXsB/XCXr8vkfK9jfpjkZiPagxQDgzp7kZ18bWAY9x3PwVdmDaKhzd8H2BCRBgQ
jliaidwKGZDq2QI/ZQ+F1l9K3q+w4qfRkUX9KFNrs/Pkfrl8oi1x0Hb5AQCTa/eG
s2mdUi3a5GbPPRvhYxCYxv8YTmvdNImPOG8pFpNhdEEsIJPm6n8yfTuerADCbFsB
ANYb4YHiMEL8wSC5wsWA5fv63rCXbXhfte4o9u7Hxt5NhNvHRLeGo5NXLqMmLlFa
fyFVEauSJb4beaM381naKTrytio7+RBksNbHYlnYhZBlP7DoruK6pNcefhH56EE=
=fD01
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/c34ac40b/attachment.key>

From squid3 at treenet.co.nz  Tue Jun  7 10:36:16 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 7 Jun 2016 22:36:16 +1200
Subject: [squid-users] Vary object loop returns
In-Reply-To: <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
Message-ID: <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>

On 7/06/2016 8:48 p.m., Yuri Voinov wrote:
> 
> 07.06.2016 4:57, Amos Jeffries ?????:
>> On 7/06/2016 5:55 a.m., Yuri Voinov wrote:
>>>
>>> So.
>>>
>>> Squid DOES NOT and DON'T BE support gzip. The only way to do it - use
>>> ecap + desupported ecap gzip adapter. Let's accept this. We can support
>>> gzip. With restrictions. Ok.
>>>
>>> any other compression - false. No. No way. Get out. and so on.
>>>
>>>  identity - this is uncompressed type.
>>>
>>> That's all, folks.
>>>
>>> Finally. As Joe does, we can remain only gzip and identity in
>>> Accept-Encoding and truncate all remaining.
> 
>> Locking the entire Internet to using your personal choice of gzip
>> compression or none.
> 
>> gzip is the slowest and more resource hungry type of compression there
>> is. deflate is actually faster for clients and just as widely supported.
> Unfortunately, Amos, no one has written any other compression algorithms
> support module. We have to eat what they give.
> 

Like I said deflate is widely available. Heiler's recent info shows that
lzma is becomming more visible on the public web, which should help fix
the one issue deflate has.

And noone appears to be fixing the remaining issues in the Squid gzip
eCAP module.

There also seems to be a big push back from browser and some server
vendors about compression in general. We had a fairly major fight in
IETF to get HTTP/2 to contain data compression at all. It is still only
in there as an optional extension that some are openly refusing to
implement.


> 
>>>
>>> Without any problem. Moreover, this type of can be push to all brunches
>>> of squid without any problem, because of this dramatically increases
>>> byte HIT.
> 
>> Responding with a single object to all requests makes your HIT ratio
>> 100% guaranteed. The clients wont like you though if all they ever see
>> is the same cat picture.
> 
>> It sounds ridiculous when put that way, but that is what these patches
>> are doing for a unknown number of those "gained" HITs. See my previous
>> post about how none of these patches are changing the request the server
>> gets.
> But no one asked the question - why Squid in production installations
> has such a low hit ratio

Yes that has been asked, even investigated. The reason(s) are many
complex details and small issues adding together to a big loss.

They range from protocol things like Vary not being fine-grained enough
(Key header being developed fixes that), through to client behaviour
(Chrome sdch doubles the variant count - almost halving useful cache
space), to server behaviour (Apache changing Vary header).

What your testing of joes patches is showing is that the sdch effect
Chrome has is probably way bigger than one would expect to be reasonable.


> that raises the question of expediency of
> application caching proxy. We do believe that this is a caching proxy?
> 
> 
>> You are once again sweeping asside the critical requirement of content
>> integrity to achieve high HIT ratio. Which is not something that I can
>> accept into Squid as a default action.
> I continue to believe that 20% is unacceptably low cache hit ratio,
> given the very aggressive settings and the active use of Store ID. Which
> brings us back to the idea of the feasibility of using the SQUID as a whole.
> 

That kind of "unacceptable" statement simply cannot be made about cache
HIT ratio. It is what it is. One cannot change the speed of light
because it takes unacceptable long to travel through space.

Two properly working caches in serial will have extremely different
caching ratios. The one with most direct client connections trends
towards 50-100% and the upstream one towards the servers will trend
towards zero. The total cacheable ratio is unchanged, but each cache
sees a different proportion of it and so shows different HIT ratios
relative to their clients portion.


Also, don't forget that browser cache disk space available are
increasingly large as well. So their caches are growing in size and
taking up a larger share of the total achievable HIT ratios in recent years.

Amos


From yvoinov at gmail.com  Tue Jun  7 10:48:27 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 7 Jun 2016 16:48:27 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
 <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
Message-ID: <012e53d8-fb0c-1a75-71db-56a7a41e523a@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


07.06.2016 16:36, Amos Jeffries ?????:
> On 7/06/2016 8:48 p.m., Yuri Voinov wrote:
>>
>> 07.06.2016 4:57, Amos Jeffries ?????:
>>> On 7/06/2016 5:55 a.m., Yuri Voinov wrote:
>>>>
>>>> So.
>>>>
>>>> Squid DOES NOT and DON'T BE support gzip. The only way to do it - use
>>>> ecap + desupported ecap gzip adapter. Let's accept this. We can support
>>>> gzip. With restrictions. Ok.
>>>>
>>>> any other compression - false. No. No way. Get out. and so on.
>>>>
>>>>  identity - this is uncompressed type.
>>>>
>>>> That's all, folks.
>>>>
>>>> Finally. As Joe does, we can remain only gzip and identity in
>>>> Accept-Encoding and truncate all remaining.
>>
>>> Locking the entire Internet to using your personal choice of gzip
>>> compression or none.
>>
>>> gzip is the slowest and more resource hungry type of compression there
>>> is. deflate is actually faster for clients and just as widely supported.
>> Unfortunately, Amos, no one has written any other compression algorithms
>> support module. We have to eat what they give.
>>
>
> Like I said deflate is widely available. Heiler's recent info shows that
> lzma is becomming more visible on the public web, which should help fix
> the one issue deflate has.
>
> And noone appears to be fixing the remaining issues in the Squid gzip
> eCAP module.
>
> There also seems to be a big push back from browser and some server
> vendors about compression in general. We had a fairly major fight in
> IETF to get HTTP/2 to contain data compression at all. It is still only
> in there as an optional extension that some are openly refusing to
> implement.
>
>
>>
>>>>
>>>> Without any problem. Moreover, this type of can be push to all brunches
>>>> of squid without any problem, because of this dramatically increases
>>>> byte HIT.
>>
>>> Responding with a single object to all requests makes your HIT ratio
>>> 100% guaranteed. The clients wont like you though if all they ever see
>>> is the same cat picture.
>>
>>> It sounds ridiculous when put that way, but that is what these patches
>>> are doing for a unknown number of those "gained" HITs. See my previous
>>> post about how none of these patches are changing the request the server
>>> gets.
>> But no one asked the question - why Squid in production installations
>> has such a low hit ratio
>
> Yes that has been asked, even investigated. The reason(s) are many
> complex details and small issues adding together to a big loss.
>
> They range from protocol things like Vary not being fine-grained enough
> (Key header being developed fixes that), through to client behaviour
> (Chrome sdch doubles the variant count - almost halving useful cache
> space), to server behaviour (Apache changing Vary header).
>
> What your testing of joes patches is showing is that the sdch effect
> Chrome has is probably way bigger than one would expect to be reasonable.
>
>
>> that raises the question of expediency of
>> application caching proxy. We do believe that this is a caching proxy?
>>
>>
>>> You are once again sweeping asside the critical requirement of content
>>> integrity to achieve high HIT ratio. Which is not something that I can
>>> accept into Squid as a default action.
>> I continue to believe that 20% is unacceptably low cache hit ratio,
>> given the very aggressive settings and the active use of Store ID. Which
>> brings us back to the idea of the feasibility of using the SQUID as a
whole.
>>
>
> That kind of "unacceptable" statement simply cannot be made about cache
> HIT ratio. It is what it is. One cannot change the speed of light
> because it takes unacceptable long to travel through space.
Yes and no.

We're not just talking about the abstract ratio of cache hits. But,
above all, about the measured byte hit ratio. It is who gives the
maximum gain traffic. Even an increase in latency cache in many cases
can be neglected. Traffic is money. Often very large sum.
>
>
> Two properly working caches in serial will have extremely different
> caching ratios. The one with most direct client connections trends
> towards 50-100% and the upstream one towards the servers will trend
> towards zero. The total cacheable ratio is unchanged, but each cache
> sees a different proportion of it and so shows different HIT ratios
> relative to their clients portion.
Sure, but not all of us can afford two cache. In most installations,
only one box. And we, of course, desirable to have maximum possible
efficiency. In addition, I am currently working on the optimization of a
single installation with two storage arrays in order to obtain the best
possible hit rate by only one server Squid.
>
>
>
> Also, don't forget that browser cache disk space available are
> increasingly large as well. So their caches are growing in size and
> taking up a larger share of the total achievable HIT ratios in recent
years.
Browser's cache in this case, not quite. It still is not shared.

Which brings us to the fact that customers download the same content
multiple times, and for a shared cache that content is unique.
Duplication is a problem. Serious problem. Caches have become more
content increased quantitatively. We have a huge amount of duplicate
content, which, in many cases, is apparently identical. StoreID only
partially solves the problem, because it requires a huge amount of
manual work for maintenance, and continuous. For example, first I worked
Instagram own means, then went under Akamai. URL structure has changed
and needed to radically change the rewrite rule.

If we are at the level of application protocols to reduce the amount of
work for maintenance of shared cache, and it will increase the
efficiency of our work and solve a lot of problems for future changes in
the Web.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVqZ6AAoJENNXIZxhPexGneEIALt1pIyoti9R7iegTRnW1kQc
x3r/PeE9j4zx1xH+PayHvf+Wfr3QqBtIpxd9hvJ+epn9V//8D6NBwSGnUSJJKpxQ
DFWWOHV12du/BT3ZUEt3EY/rfE7xVj+tZ6vEBXRhKYSzzlbfARpB9rE6JXx2cuqG
Q/2vcKzpMfcItMsE8yqejcPBe+Lf8pSO1vvMut3m4QHkge4OQhhyzrnwzyh9QMwp
AXXD4SSBoMxCZ5Z2BFr1aqSZ1F+TRPW/nn5CB+pr3U+XEzIb8lp3XMz0ZeUwuYnh
Zgc1E7hIn/CEybT0IyMi24ojc1CB4YY7V1BaePYdsbGdXS0up58Ea6jP5bD0DTc=
=Dw5f
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/308b5300/attachment.key>

From squid3 at treenet.co.nz  Tue Jun  7 11:00:12 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 7 Jun 2016 23:00:12 +1200
Subject: [squid-users] Vary object loop returns
In-Reply-To: <05d220bc-5b1e-e6d7-8bec-bad1c580bb82@gmail.com>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <16a59d21-99ef-b4a0-9aed-8238b0e90fba@gmail.com>
 <24a6a3c4-cf1c-4f14-c9b8-7e1b2a8a6ae2@cinbesa.com.br>
 <f3d5efb4-7133-3de1-dc13-08252ad314f7@gmail.com>
 <22f4cc36-ef1a-c566-4d26-24e70d4bb0cc@treenet.co.nz>
 <05d220bc-5b1e-e6d7-8bec-bad1c580bb82@gmail.com>
Message-ID: <1efe1579-6386-0de8-25a1-d87437f27ded@treenet.co.nz>

On 7/06/2016 9:12 p.m., Yuri Voinov wrote:
> 
> 
> 
> 07.06.2016 5:13, Amos Jeffries ?????:
>> On 7/06/2016 6:20 a.m., Yuri Voinov wrote:
>>>
>>> By the way, we have another problem. Caching is greatly reduced by the
>>> presence of User-Agent header Vary. Although I know that Amos says - he
>>> says, we should break the Internet and cached separately all types of
>>> user agents.
> 
>> Please do not put your own beliefs into my mouth. I am very much in
> Sorry, Amos. This was sarcasm. May be, not too relevant.
> 
>> favour of denying Vary:User-Agent from being cached *at all* until the
>> UA start sending sensible contents in the header. That would lower your
>> precious HIT ratio a tiny amount.
> Maybe. However, this greatly increases the content duplication. ?gree?

I'm not sure what you are asking me to agree with there.

The Vary:User-Agent has three cases that can happen:

1) caching it properly results in huge number of probably duplicated
variants in the cache. Each response though is guaranteed to be correct
for that UA when HIT happen.
 I think we agree that situation is bad. Currently the store_miss
directive is the best way to avoid that. Which makes #2 happen instead
of this #1 case.

2) not caching it at all will lower the HIT ratio from sites using it.
However a potentially large amount of cache space will become available
for other better caching sites to use and raise their HIT ratio.
Again each response is guaranteed to be correct for that UA.

3) caching one random copy from the server and delivering it to all
clients regardless of their UA will produce a high HIT ratio. Something
like the HIT ratio from #1 plus ratio gained by #2.
 However, each response will randomy break a) clients expectations, b)
the servers expectations, and c) the site authors behaviour expectations
(ie security model).

I believe #2 is the best tradeoff. You seem to be arguing for #3 solely
on the IT ratio numbers, without considering the actual nasty side effect.


> 
>> BTW: Do you know what "breaking the Internet" actually means? It's a bit
>> ironic that you would throw that insult at me while praising what these
>> patches currently do.
> :) Really sorry.
> 
> Sometimes our experiments scratching the hell out of the display content
> in browsers. That's what I called "break the Internet". :) But
> seriously, we're trying to find a compromise between a high cache and
> the desire to satisfy customers. It seems to me, mutually exclusive things.

Ah. What I have been trying to get across is that they are not mutually
exclusive like that.

You have seen the display breakage. That is caused directly by things
like client requesting identity encoding but being delivered a cached
gzip object. Or worse, the garbage output from trying to decompress an
identity object with gzip decompressor. The display gets F*'d.

Note that the reason the wrong content came back in all the above
display problems was that it was a cache HIT and the proxy ignored part
of the Vary header when producing its response.


> 
> Meanwhile, Amos, I still believe that the team should now, in 2016, to
> seriously reconsider attitude to compress the content and possibly
> revise Vary processing algorithms in favor of more vysokgo cache hit
> ratio. Under the conditions of high-speed Internet only a high hit ratio
> justifies the use of caching proxy.

What attitude? For my part the response (to every submission) is that a
patch doing it right will go in, not another hacked up job.

Who is this "the team" ? It is all of us including you.

We cannot revise the Vary algorithm, it is RFC defined. The best we can
do for the forseeable future is hacked up tricks like filtering what
headers get sent through to the server. I am part-time working with the
Apache and Chrome devs in IETF to design a replacement Key header that
works far better.

Amos


From yvoinov at gmail.com  Tue Jun  7 11:17:34 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 7 Jun 2016 17:17:34 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1efe1579-6386-0de8-25a1-d87437f27ded@treenet.co.nz>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <16a59d21-99ef-b4a0-9aed-8238b0e90fba@gmail.com>
 <24a6a3c4-cf1c-4f14-c9b8-7e1b2a8a6ae2@cinbesa.com.br>
 <f3d5efb4-7133-3de1-dc13-08252ad314f7@gmail.com>
 <22f4cc36-ef1a-c566-4d26-24e70d4bb0cc@treenet.co.nz>
 <05d220bc-5b1e-e6d7-8bec-bad1c580bb82@gmail.com>
 <1efe1579-6386-0de8-25a1-d87437f27ded@treenet.co.nz>
Message-ID: <7030597c-3da7-d600-bbd6-2c76af22f162@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


07.06.2016 17:00, Amos Jeffries ?????:
> On 7/06/2016 9:12 p.m., Yuri Voinov wrote:
>>
>>
>>
>> 07.06.2016 5:13, Amos Jeffries ?????:
>>> On 7/06/2016 6:20 a.m., Yuri Voinov wrote:
>>>>
>>>> By the way, we have another problem. Caching is greatly reduced by the
>>>> presence of User-Agent header Vary. Although I know that Amos says - he
>>>> says, we should break the Internet and cached separately all types of
>>>> user agents.
>>
>>> Please do not put your own beliefs into my mouth. I am very much in
>> Sorry, Amos. This was sarcasm. May be, not too relevant.
>>
>>> favour of denying Vary:User-Agent from being cached *at all* until the
>>> UA start sending sensible contents in the header. That would lower your
>>> precious HIT ratio a tiny amount.
>> Maybe. However, this greatly increases the content duplication. ?gree?
>
> I'm not sure what you are asking me to agree with there.
>
> The Vary:User-Agent has three cases that can happen:
>
> 1) caching it properly results in huge number of probably duplicated
> variants in the cache. Each response though is guaranteed to be correct
> for that UA when HIT happen.
>  I think we agree that situation is bad. Currently the store_miss
> directive is the best way to avoid that. Which makes #2 happen instead
> of this #1 case.
>
> 2) not caching it at all will lower the HIT ratio from sites using it.
> However a potentially large amount of cache space will become available
> for other better caching sites to use and raise their HIT ratio.
> Again each response is guaranteed to be correct for that UA.
>
> 3) caching one random copy from the server and delivering it to all
> clients regardless of their UA will produce a high HIT ratio. Something
> like the HIT ratio from #1 plus ratio gained by #2.
>  However, each response will randomy break a) clients expectations, b)
> the servers expectations, and c) the site authors behaviour expectations
> (ie security model).
>
> I believe #2 is the best tradeoff. You seem to be arguing for #3 solely
> on the IT ratio numbers, without considering the actual nasty side effect.

It's understandable reasons, Amos. We discussed them previously. You
proceed from the presumption of good faith Webmasters. However,
experience has shown that it is not. Many - including especially Google!
- Actively oppose caching, using all possible mechanisms. Adding the
hash in the URL - and this is the most harmless! - URL encryption,
header modifications, including UA. Accordingly, I want to have a
mechanism for combating such unscrupulous webmasters. And if possible
without a huge amount of night work by hand. I have things to do, and
besides nightly reverse engineering sites.


>
>
>
>>
>>> BTW: Do you know what "breaking the Internet" actually means? It's a bit
>>> ironic that you would throw that insult at me while praising what these
>>> patches currently do.
>> :) Really sorry.
>>
>> Sometimes our experiments scratching the hell out of the display content
>> in browsers. That's what I called "break the Internet". :) But
>> seriously, we're trying to find a compromise between a high cache and
>> the desire to satisfy customers. It seems to me, mutually exclusive
things.
>
> Ah. What I have been trying to get across is that they are not mutually
> exclusive like that.
>
> You have seen the display breakage. That is caused directly by things
> like client requesting identity encoding but being delivered a cached
> gzip object. Or worse, the garbage output from trying to decompress an
> identity object with gzip decompressor. The display gets F*'d.
>
> Note that the reason the wrong content came back in all the above
> display problems was that it was a cache HIT and the proxy ignored part
> of the Vary header when producing its response.
Side effects in some cases, can be ignored. (By the way, I just have
reason to doubt the integrity of users with respect to me and my work,
to seriously worry about the invisible side effects. On the grave
violations in the sites notified me. Everything else is on my conscience).

In the case of a number of sites that create problems in caching for me,
I am ready to come to terms with some inaccuracy in the work - for
example, this applies to ad networks or Web sites opposing caching for
selfish purposes. I have often wondered what, in fact, the devil so
counteracts Google caching terabytes Youtube content. When the counting
of views was enough to make a tiny non-cached JS who have recorded the
client-side viewing.
>
>
>
>>
>> Meanwhile, Amos, I still believe that the team should now, in 2016, to
>> seriously reconsider attitude to compress the content and possibly
>> revise Vary processing algorithms in favor of more vysokgo cache hit
>> ratio. Under the conditions of high-speed Internet only a high hit ratio
>> justifies the use of caching proxy.
>
> What attitude? For my part the response (to every submission) is that a
> patch doing it right will go in, not another hacked up job.
>
> Who is this "the team" ? It is all of us including you.
>
> We cannot revise the Vary algorithm, it is RFC defined. The best we can
> do for the forseeable future is hacked up tricks like filtering what
> headers get sent through to the server. I am part-time working with the
> Apache and Chrome devs in IETF to design a replacement Key header that
> works far better.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVq1NAAoJENNXIZxhPexG/24H/Rq8gfS/eAs621wtx1kV0pGW
T68B0ov3ywkchtomlQVUfN5NqTBnvKj3t5Lfy4QppW+3W2K/OHO4C5Gbjlj2W8z1
+bJJ7t1ZJRlGHnY4MREeR//MqxuvAj0e17JcHjbOq0Me7mhKkMqaK8ZNdcPCeK8O
o+ori1mJnCgRldveqHA4JwLDGYawAU6ApBL/VbZlRZO206dqtgWjdNwGYRi7lgY7
xyduwAZiuvNVnGHSFZk9ikGMs4Wax0XEt1t33vY4VnesF0hKdQrT4OwAQ9xadJ/j
EychwK5+zjZ90dq0c3SkbPJkdCQlk3EOLTuuYE9Gh5fB7BDm7Zz9oh2y27S/e8g=
=QWqB
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/84d822d4/attachment.key>

From yvoinov at gmail.com  Tue Jun  7 11:23:21 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 7 Jun 2016 17:23:21 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1efe1579-6386-0de8-25a1-d87437f27ded@treenet.co.nz>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <16a59d21-99ef-b4a0-9aed-8238b0e90fba@gmail.com>
 <24a6a3c4-cf1c-4f14-c9b8-7e1b2a8a6ae2@cinbesa.com.br>
 <f3d5efb4-7133-3de1-dc13-08252ad314f7@gmail.com>
 <22f4cc36-ef1a-c566-4d26-24e70d4bb0cc@treenet.co.nz>
 <05d220bc-5b1e-e6d7-8bec-bad1c580bb82@gmail.com>
 <1efe1579-6386-0de8-25a1-d87437f27ded@treenet.co.nz>
Message-ID: <c58b6306-3416-cf45-f12f-7a57da9cd9fc@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
You see, Vary the standard, however, if you had to see how the site is
added to the garbage sequence response headers to prevent its cache? I
had very often.

What kind of standards we say, when the same scale Google deploys custom
protocol completely - completely, Carl! - Ignoring the existence of
caching proxies all over the world? Forcing us - you, me, Joe - the hack
spike find a solution? That is why I would like to have the opportunity
for their part to actively oppose such here gentlemen who wanted to spit
on the standards and rules of etiquette adopted in the industry.


07.06.2016 17:00, Amos Jeffries ?????:
> On 7/06/2016 9:12 p.m., Yuri Voinov wrote:
>>
>>
>>
>> 07.06.2016 5:13, Amos Jeffries ?????:
>>> On 7/06/2016 6:20 a.m., Yuri Voinov wrote:
>>>>
>>>> By the way, we have another problem. Caching is greatly reduced by the
>>>> presence of User-Agent header Vary. Although I know that Amos says - he
>>>> says, we should break the Internet and cached separately all types of
>>>> user agents.
>>
>>> Please do not put your own beliefs into my mouth. I am very much in
>> Sorry, Amos. This was sarcasm. May be, not too relevant.
>>
>>> favour of denying Vary:User-Agent from being cached *at all* until the
>>> UA start sending sensible contents in the header. That would lower your
>>> precious HIT ratio a tiny amount.
>> Maybe. However, this greatly increases the content duplication. ?gree?
>
> I'm not sure what you are asking me to agree with there.
>
> The Vary:User-Agent has three cases that can happen:
>
> 1) caching it properly results in huge number of probably duplicated
> variants in the cache. Each response though is guaranteed to be correct
> for that UA when HIT happen.
>  I think we agree that situation is bad. Currently the store_miss
> directive is the best way to avoid that. Which makes #2 happen instead
> of this #1 case.
>
> 2) not caching it at all will lower the HIT ratio from sites using it.
> However a potentially large amount of cache space will become available
> for other better caching sites to use and raise their HIT ratio.
> Again each response is guaranteed to be correct for that UA.
>
> 3) caching one random copy from the server and delivering it to all
> clients regardless of their UA will produce a high HIT ratio. Something
> like the HIT ratio from #1 plus ratio gained by #2.
>  However, each response will randomy break a) clients expectations, b)
> the servers expectations, and c) the site authors behaviour expectations
> (ie security model).
>
> I believe #2 is the best tradeoff. You seem to be arguing for #3 solely
> on the IT ratio numbers, without considering the actual nasty side effect.
>
>
>>
>>> BTW: Do you know what "breaking the Internet" actually means? It's a bit
>>> ironic that you would throw that insult at me while praising what these
>>> patches currently do.
>> :) Really sorry.
>>
>> Sometimes our experiments scratching the hell out of the display content
>> in browsers. That's what I called "break the Internet". :) But
>> seriously, we're trying to find a compromise between a high cache and
>> the desire to satisfy customers. It seems to me, mutually exclusive
things.
>
> Ah. What I have been trying to get across is that they are not mutually
> exclusive like that.
>
> You have seen the display breakage. That is caused directly by things
> like client requesting identity encoding but being delivered a cached
> gzip object. Or worse, the garbage output from trying to decompress an
> identity object with gzip decompressor. The display gets F*'d.
>
> Note that the reason the wrong content came back in all the above
> display problems was that it was a cache HIT and the proxy ignored part
> of the Vary header when producing its response.
>
>
>>
>> Meanwhile, Amos, I still believe that the team should now, in 2016, to
>> seriously reconsider attitude to compress the content and possibly
>> revise Vary processing algorithms in favor of more vysokgo cache hit
>> ratio. Under the conditions of high-speed Internet only a high hit ratio
>> justifies the use of caching proxy.
>
> What attitude? For my part the response (to every submission) is that a
> patch doing it right will go in, not another hacked up job.
>
> Who is this "the team" ? It is all of us including you.
>
> We cannot revise the Vary algorithm, it is RFC defined. The best we can
> do for the forseeable future is hacked up tricks like filtering what
> headers get sent through to the server. I am part-time working with the
> Apache and Chrome devs in IETF to design a replacement Key header that
> works far better.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVq6pAAoJENNXIZxhPexGq14H/0gMHDgfUEO714rX/iJvB6Ok
7a6z/rb1xRprWheqA1jhpOT6oiZObYCMt+TIG/5u2jebMjRTfjlgWKa49juuWb5i
URcBw1m3PQw+27tqrHhCyk2WlczTyvFHlw4BkQxGWTMPijzsLr7IebRqmiqfP/CE
lQrSlE9XowKzgiji55yVcS6dkblft6Ns7xhaE7UYGvVGD2onpS0KnNYuxTPCDW6Q
2tnoynBRWHLASOyJlvZVuWpRdS9SgOvDH2OYGczq1S5Tj5oP16W4GdY9iGBlVn31
6P4n8SMPGbFme7AYCjFVQgi6bzWJUtv7GSzouyoRpoaEkhJD2gZ+zxHwLQDxZ0M=
=S0ms
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/2d5ad71d/attachment.key>

From yvoinov at gmail.com  Tue Jun  7 11:29:37 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 7 Jun 2016 17:29:37 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1efe1579-6386-0de8-25a1-d87437f27ded@treenet.co.nz>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <16a59d21-99ef-b4a0-9aed-8238b0e90fba@gmail.com>
 <24a6a3c4-cf1c-4f14-c9b8-7e1b2a8a6ae2@cinbesa.com.br>
 <f3d5efb4-7133-3de1-dc13-08252ad314f7@gmail.com>
 <22f4cc36-ef1a-c566-4d26-24e70d4bb0cc@treenet.co.nz>
 <05d220bc-5b1e-e6d7-8bec-bad1c580bb82@gmail.com>
 <1efe1579-6386-0de8-25a1-d87437f27ded@treenet.co.nz>
Message-ID: <3fa15506-4a1f-63d2-b5fe-588f013f4123@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
The world is not perfect, unfortunately. The ivory tower is revered
standards and regulations. In the real world they spit when it is
profitable. Especially when this recommendation and not rigid protocol
requirements. :)

We are also talking about money. Traffic is money. Therefore, the more
we will be able to properly and efficiently to cache - the better.


07.06.2016 17:00, Amos Jeffries ?????:
> On 7/06/2016 9:12 p.m., Yuri Voinov wrote:
>>
>>
>>
>> 07.06.2016 5:13, Amos Jeffries ?????:
>>> On 7/06/2016 6:20 a.m., Yuri Voinov wrote:
>>>>
>>>> By the way, we have another problem. Caching is greatly reduced by the
>>>> presence of User-Agent header Vary. Although I know that Amos says - he
>>>> says, we should break the Internet and cached separately all types of
>>>> user agents.
>>
>>> Please do not put your own beliefs into my mouth. I am very much in
>> Sorry, Amos. This was sarcasm. May be, not too relevant.
>>
>>> favour of denying Vary:User-Agent from being cached *at all* until the
>>> UA start sending sensible contents in the header. That would lower your
>>> precious HIT ratio a tiny amount.
>> Maybe. However, this greatly increases the content duplication. ?gree?
>
> I'm not sure what you are asking me to agree with there.
>
> The Vary:User-Agent has three cases that can happen:
>
> 1) caching it properly results in huge number of probably duplicated
> variants in the cache. Each response though is guaranteed to be correct
> for that UA when HIT happen.
>  I think we agree that situation is bad. Currently the store_miss
> directive is the best way to avoid that. Which makes #2 happen instead
> of this #1 case.
>
> 2) not caching it at all will lower the HIT ratio from sites using it.
> However a potentially large amount of cache space will become available
> for other better caching sites to use and raise their HIT ratio.
> Again each response is guaranteed to be correct for that UA.
>
> 3) caching one random copy from the server and delivering it to all
> clients regardless of their UA will produce a high HIT ratio. Something
> like the HIT ratio from #1 plus ratio gained by #2.
>  However, each response will randomy break a) clients expectations, b)
> the servers expectations, and c) the site authors behaviour expectations
> (ie security model).
>
> I believe #2 is the best tradeoff. You seem to be arguing for #3 solely
> on the IT ratio numbers, without considering the actual nasty side effect.
>
>
>>
>>> BTW: Do you know what "breaking the Internet" actually means? It's a bit
>>> ironic that you would throw that insult at me while praising what these
>>> patches currently do.
>> :) Really sorry.
>>
>> Sometimes our experiments scratching the hell out of the display content
>> in browsers. That's what I called "break the Internet". :) But
>> seriously, we're trying to find a compromise between a high cache and
>> the desire to satisfy customers. It seems to me, mutually exclusive
things.
>
> Ah. What I have been trying to get across is that they are not mutually
> exclusive like that.
>
> You have seen the display breakage. That is caused directly by things
> like client requesting identity encoding but being delivered a cached
> gzip object. Or worse, the garbage output from trying to decompress an
> identity object with gzip decompressor. The display gets F*'d.
>
> Note that the reason the wrong content came back in all the above
> display problems was that it was a cache HIT and the proxy ignored part
> of the Vary header when producing its response.
>
>
>>
>> Meanwhile, Amos, I still believe that the team should now, in 2016, to
>> seriously reconsider attitude to compress the content and possibly
>> revise Vary processing algorithms in favor of more vysokgo cache hit
>> ratio. Under the conditions of high-speed Internet only a high hit ratio
>> justifies the use of caching proxy.
>
> What attitude? For my part the response (to every submission) is that a
> patch doing it right will go in, not another hacked up job.
>
> Who is this "the team" ? It is all of us including you.
>
> We cannot revise the Vary algorithm, it is RFC defined. The best we can
> do for the forseeable future is hacked up tricks like filtering what
> headers get sent through to the server. I am part-time working with the
> Apache and Chrome devs in IETF to design a replacement Key header that
> works far better.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVrAgAAoJENNXIZxhPexGTIoIAI6myhj+dmayOOtBkfZxZfV3
i6xIldv7rpYNCI4RbPSCKhzsuA2/J+CzXkdFaimP4QaiJPljYn+u5ZNe4P/SxM3f
8xVR9VBhvdccGI4RhL3gJ+3VGSv55/xeIi6f4F2Hgkj1BNozLzg8h5G6Z+NpHi4b
xJ1ZR/KHPDUEToX1nLa1H5iLyXFfaMO9GcjEaCPIUsUO0zuuIi43xc3U9jrV2IIX
9zJ2TiSyorG4uOQYmEaks170SX2osizmD2+jYx1zPSm8ap//pMR+2WchdoeA+l/K
CpN4as9UaB+05IQp0AiYpLomiqr8YRbwq4woqbYQ8Nqu/VAXW9rbGM7rgmYu03I=
=+lJH
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/e3c5e5c7/attachment.key>

From yvoinov at gmail.com  Tue Jun  7 11:59:42 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 7 Jun 2016 17:59:42 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
 <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
Message-ID: <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I want to give one example on the topic.

Here is from one of my cache:

/data/cache/d2/00/02/000004C3   0   102502
http://www.openoffice.org/favicon.ico
/data/cache/d2/00/01/0000031D   0   161421
http://rgho.st.squidinternal/favicon.ico
/data/cache/d1/00/2E/00005C04   0    33274
http://www.tcpiputils.com/favicon.ico

Just take a look on file sizes. This is only favicon. 100 kbytes for
favicon only! (on Microsoft I've seen 470 kbytes favicon once upon time).

When we take a look into access.log, we often see several URL's for favicon:

http://www.somesite.com/favicon.ico?v=1.44&id=41324134abcd123123123

Good site, isn't it? Loading 100 kbytes every time every client surf any
site page.

When I was doing research, it became clear that, in most cases, these
same favicon were one and the same content. As an example, a client with
a smartphone like to download 100 kB - and this is only a small portion
of the page! - everytime?

100 kb of mobile data traffic in most countries of the world - decent money.

Yes, usually from the client browser cache.

What about the number of clients and the access point, which pays
terabytes non-peering traffic?

The same tricks I've seen with a user-agent. With Vary.

07.06.2016 16:36, Amos Jeffries ?????:
> On 7/06/2016 8:48 p.m., Yuri Voinov wrote:
>>
>> 07.06.2016 4:57, Amos Jeffries ?????:
>>> On 7/06/2016 5:55 a.m., Yuri Voinov wrote:
>>>>
>>>> So.
>>>>
>>>> Squid DOES NOT and DON'T BE support gzip. The only way to do it - use
>>>> ecap + desupported ecap gzip adapter. Let's accept this. We can support
>>>> gzip. With restrictions. Ok.
>>>>
>>>> any other compression - false. No. No way. Get out. and so on.
>>>>
>>>>  identity - this is uncompressed type.
>>>>
>>>> That's all, folks.
>>>>
>>>> Finally. As Joe does, we can remain only gzip and identity in
>>>> Accept-Encoding and truncate all remaining.
>>
>>> Locking the entire Internet to using your personal choice of gzip
>>> compression or none.
>>
>>> gzip is the slowest and more resource hungry type of compression there
>>> is. deflate is actually faster for clients and just as widely supported.
>> Unfortunately, Amos, no one has written any other compression algorithms
>> support module. We have to eat what they give.
>>
>
> Like I said deflate is widely available. Heiler's recent info shows that
> lzma is becomming more visible on the public web, which should help fix
> the one issue deflate has.
>
> And noone appears to be fixing the remaining issues in the Squid gzip
> eCAP module.
>
> There also seems to be a big push back from browser and some server
> vendors about compression in general. We had a fairly major fight in
> IETF to get HTTP/2 to contain data compression at all. It is still only
> in there as an optional extension that some are openly refusing to
> implement.
>
>
>>
>>>>
>>>> Without any problem. Moreover, this type of can be push to all brunches
>>>> of squid without any problem, because of this dramatically increases
>>>> byte HIT.
>>
>>> Responding with a single object to all requests makes your HIT ratio
>>> 100% guaranteed. The clients wont like you though if all they ever see
>>> is the same cat picture.
>>
>>> It sounds ridiculous when put that way, but that is what these patches
>>> are doing for a unknown number of those "gained" HITs. See my previous
>>> post about how none of these patches are changing the request the server
>>> gets.
>> But no one asked the question - why Squid in production installations
>> has such a low hit ratio
>
> Yes that has been asked, even investigated. The reason(s) are many
> complex details and small issues adding together to a big loss.
>
> They range from protocol things like Vary not being fine-grained enough
> (Key header being developed fixes that), through to client behaviour
> (Chrome sdch doubles the variant count - almost halving useful cache
> space), to server behaviour (Apache changing Vary header).
>
> What your testing of joes patches is showing is that the sdch effect
> Chrome has is probably way bigger than one would expect to be reasonable.
>
>
>> that raises the question of expediency of
>> application caching proxy. We do believe that this is a caching proxy?
>>
>>
>>> You are once again sweeping asside the critical requirement of content
>>> integrity to achieve high HIT ratio. Which is not something that I can
>>> accept into Squid as a default action.
>> I continue to believe that 20% is unacceptably low cache hit ratio,
>> given the very aggressive settings and the active use of Store ID. Which
>> brings us back to the idea of the feasibility of using the SQUID as a
whole.
>>
>
> That kind of "unacceptable" statement simply cannot be made about cache
> HIT ratio. It is what it is. One cannot change the speed of light
> because it takes unacceptable long to travel through space.
>
> Two properly working caches in serial will have extremely different
> caching ratios. The one with most direct client connections trends
> towards 50-100% and the upstream one towards the servers will trend
> towards zero. The total cacheable ratio is unchanged, but each cache
> sees a different proportion of it and so shows different HIT ratios
> relative to their clients portion.
>
>
> Also, don't forget that browser cache disk space available are
> increasingly large as well. So their caches are growing in size and
> taking up a larger share of the total achievable HIT ratios in recent
years.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXVrctAAoJENNXIZxhPexGl8gIALRSaB3nC6fUjKM8GGL+ep3m
NZganwbvtkLLLDHQFuTA3K9gvl/GWieQ/3jj+Pp45kgNIeVNsbwYF6IANOT1/olc
XIGpHK0LICSeTA5kpSHU6hkdfao6AWSUFLci5WXl/Ay7qvzWI4h/NqPhyhoaJUSq
LTmOePc98oALu4oZpmdmKy1D5yduLmjDy8cbIJTRc/SVha5tt4Sre7z8dI9geX9L
PlrXBxbtH+oGAYu5qiuifQR9UZCoYL0wL30KzWLyIqmZJdT/NIshIRA1wHVdy9lL
d0CNwheIPTvstnx8uKOMk4vN/Z5y+A6LnTHHoJgfRCyNwD1IayoPRY1CJffWVRk=
=40f2
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/a0a1ef66/attachment.key>

From buechlerml at hdpnet.de  Tue Jun  7 14:12:31 2016
From: buechlerml at hdpnet.de (Paul Buechler)
Date: Tue, 7 Jun 2016 16:12:31 +0200
Subject: [squid-users] google drive up-/download size in squidlog
In-Reply-To: <c8aaa441-8f3a-0f43-520a-caeeec8243cf@treenet.co.nz>
References: <57440D94.1080703@hdpnet.de>
 <009a89d8-79af-45e9-ee97-7baa5e24ceac@treenet.co.nz>
 <efa39e35-91b4-979b-104c-d7d9cdf16131@hdpnet.de>
 <c8aaa441-8f3a-0f43-520a-caeeec8243cf@treenet.co.nz>
Message-ID: <ed9da6a1-5f63-5c01-a842-42a9a736c726@hdpnet.de>

I've tested every %st-tag and read the whole documentation.

What i want to see is, that if i upload 100Mb -> the log says 100000000 
caused by a tag. None of the %st-tags showed me this value. Neither 
%<st, nor %st, nor %>st.

So is there going to be a tag in the near future to show the complete 
size of an upload?

Paul


Am 03.06.2016 um 07:53 schrieb Amos Jeffries:
> On 2/06/2016 9:01 p.m., Paul Buechler wrote:
>> Hi,
>>
>> @Yuri Voinov:
>>
>> I've only tested it with the webclient.
>>
>> @Amos Jeffries:
>>
>> I've tested it with %st and the downloadsize is fine for me now, thanks.
>>
>> Are there any plans to implement a format code to see the uploadsize?
>> It would be nice to have this feature.
> That would be the third 'st' tag, which logs *only* the outgoing
> direction of traffic.
>
> You really should look through the documentation which lists clearly
> what tags are available:
>   <http://www.squid-cache.org/Doc/config/logformat/>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From adam at endpoint.com  Tue Jun  7 17:08:02 2016
From: adam at endpoint.com (Adam Vollrath)
Date: Tue, 7 Jun 2016 12:08:02 -0500
Subject: [squid-users] Response timeout for upstream HTTP servers
Message-ID: <5756FF72.8080000@endpoint.com>

Good morning! I'm having trouble with upstream HTTP servers not
responding for more than 30 seconds.  I'd like to just return an empty
response to the downstream client. Nothing is better than waiting.

I'm looking for a `squid3` configuration directive to timeout between an
HTTP request and response.  Here's the directive for `nginx`:
http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_read_timeout

	"Defines a timeout for reading a response from the proxied server. The
timeout is set only between two successive read operations, not for the
transmission of the whole response. If the proxied server does not
transmit anything within this time, the connection is closed."

Does `squid3` have a way to implement this?  Is this what the
`read_timeout` directive does if my upstream systems are configured as
`cache_peer`?

Thank you all for your time!


From squid3 at treenet.co.nz  Tue Jun  7 17:36:04 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 8 Jun 2016 05:36:04 +1200
Subject: [squid-users] google drive up-/download size in squidlog
In-Reply-To: <ed9da6a1-5f63-5c01-a842-42a9a736c726@hdpnet.de>
References: <57440D94.1080703@hdpnet.de>
 <009a89d8-79af-45e9-ee97-7baa5e24ceac@treenet.co.nz>
 <efa39e35-91b4-979b-104c-d7d9cdf16131@hdpnet.de>
 <c8aaa441-8f3a-0f43-520a-caeeec8243cf@treenet.co.nz>
 <ed9da6a1-5f63-5c01-a842-42a9a736c726@hdpnet.de>
Message-ID: <67b83658-bcd3-d350-3c29-bae91f9724b4@treenet.co.nz>

On 8/06/2016 2:12 a.m., Paul Buechler wrote:
> I've tested every %st-tag and read the whole documentation.
> 
> What i want to see is, that if i upload 100Mb -> the log says 100000000

100 Mb == 13,107,200 Bytes.

100 MB == 104,857,600 Bytes.

100,000,000 Bytes == 95.4 MB

100,000,000 bits == 11.9 MB

There is also content encoding, transfer encoding, and since its an
upload with a "file" there will be multipart mime form encoding as well.
Possibly 1xx status messages involved as well.

All of which can add up to significant % of extra (or less) data "on the
wire" making it different from the file/thing you are uploading.


> caused by a tag. None of the %st-tags showed me this value. Neither
> %<st, nor %st, nor %>st.
> 
> So is there going to be a tag in the near future to show the complete
> size of an upload?

Insufficient data. Those st codes log the traffic bytes they are
documented as logging. If you can demonstrate a bug in the latest
releases that should get fixed. Though it is more likely that the actual
traffic byte count is not what you have been thinking it was.

There are no plans to log anything more detailed about the payload than
the size of what got transfered on the connection if thats what you are
asking.

Amos



From uhlar at fantomas.sk  Tue Jun  7 18:31:18 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 7 Jun 2016 20:31:18 +0200
Subject: [squid-users] google drive up-/download size in squidlog
In-Reply-To: <67b83658-bcd3-d350-3c29-bae91f9724b4@treenet.co.nz>
References: <57440D94.1080703@hdpnet.de>
 <009a89d8-79af-45e9-ee97-7baa5e24ceac@treenet.co.nz>
 <efa39e35-91b4-979b-104c-d7d9cdf16131@hdpnet.de>
 <c8aaa441-8f3a-0f43-520a-caeeec8243cf@treenet.co.nz>
 <ed9da6a1-5f63-5c01-a842-42a9a736c726@hdpnet.de>
 <67b83658-bcd3-d350-3c29-bae91f9724b4@treenet.co.nz>
Message-ID: <20160607183118.GC1391@fantomas.sk>

>On 8/06/2016 2:12 a.m., Paul Buechler wrote:
>> I've tested every %st-tag and read the whole documentation.
>>
>> What i want to see is, that if i upload 100Mb -> the log says 100000000

On 08.06.16 05:36, Amos Jeffries wrote:
>100 Mb == 13,107,200 Bytes.
>
>100 MB == 104,857,600 Bytes.

Actually is Mib and Mib; 1Mi = 2^20 read "mebi" as binary mega
however many people and programs don't use this name often...

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
WinError #98652: Operation completed successfully.


From heiler.bemerguy at cinbesa.com.br  Tue Jun  7 20:21:08 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 7 Jun 2016 17:21:08 -0300
Subject: [squid-users] Vary object loop returns
In-Reply-To: <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
 <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
 <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>
Message-ID: <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>


Some servers will reply like this, trying to avoid caching at any cost 
(I think):

HTTP/1.1 200 OK
Server: nginx
Content-Type: image/x-icon
Last-Modified: Tue, 07 Jun 2016 11:16:55 GMT
ETag: "5756ad27-47e"
Content-Length: 1150
X-Suppressed-Cache-Control: max-age=600
Cache-Control: private, max-age=0, must-revalidate
X-Suppressed-Expires: Tue, 07 Jun 2016 20:07:36 GMT
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Date: Tue, 07 Jun 2016 19:57:36 GMT
X-Varnish: 510207311
*Vary: 
Accept,If-None-Match,If-Modified-Since,Accept-Language,Accept-Encoding,X-Client-Locale,User-Agent,X-Device*

Then our squid will create a vary object with all that information, 
giving this bomb: httpMakeVaryMark: 
accept="image%2Fpng,image%2F*%3Bq%3D0.8,*%2F*%3Bq%3D0.5", 
if-none-match="%225756ad27-47e%22", if-modified-since, 
accept-language="en-US,en%3Bq%3D0.8,pt-BR%3Bq%3D0.5,pt%3Bq%3D0.3", 
accept-encoding="none", x-client-locale, 
user-agent="Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A46.0)%20Gecko%2F20100101%20Firefox%2F46.0", 
x-device

It's squid "fault" to convert spaces and symbols to %values, and I think 
no sanity check is performed on it.. still, I don't see the code where 
it checks if all this info from the new client is identical to the 
stored one.. and I don't know where the "loop" comes from...

Now I think I'm confused... lol


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751


Em 07/06/2016 08:59, Yuri Voinov escreveu:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>   
> I want to give one example on the topic.
>
> Here is from one of my cache:
>
> /data/cache/d2/00/02/000004C3   0   102502
> http://www.openoffice.org/favicon.ico
> /data/cache/d2/00/01/0000031D   0   161421
> http://rgho.st.squidinternal/favicon.ico
> /data/cache/d1/00/2E/00005C04   0    33274
> http://www.tcpiputils.com/favicon.ico
>
> Just take a look on file sizes. This is only favicon. 100 kbytes for
> favicon only! (on Microsoft I've seen 470 kbytes favicon once upon time).
>
> When we take a look into access.log, we often see several URL's for favicon:
>
> http://www.somesite.com/favicon.ico?v=1.44&id=41324134abcd123123123
>
> Good site, isn't it? Loading 100 kbytes every time every client surf any
> site page.
>
> When I was doing research, it became clear that, in most cases, these
> same favicon were one and the same content. As an example, a client with
> a smartphone like to download 100 kB - and this is only a small portion
> of the page! - everytime?
>
> 100 kb of mobile data traffic in most countries of the world - decent money.
>
> Yes, usually from the client browser cache.
>
> What about the number of clients and the access point, which pays
> terabytes non-peering traffic?
>
> The same tricks I've seen with a user-agent. With Vary.
>
> 07.06.2016 16:36, Amos Jeffries ?????:
>> On 7/06/2016 8:48 p.m., Yuri Voinov wrote:
>>> 07.06.2016 4:57, Amos Jeffries ?????:
>>>> On 7/06/2016 5:55 a.m., Yuri Voinov wrote:
>>>>> So.
>>>>>
>>>>> Squid DOES NOT and DON'T BE support gzip. The only way to do it - use
>>>>> ecap + desupported ecap gzip adapter. Let's accept this. We can support
>>>>> gzip. With restrictions. Ok.
>>>>>
>>>>> any other compression - false. No. No way. Get out. and so on.
>>>>>
>>>>>   identity - this is uncompressed type.
>>>>>
>>>>> That's all, folks.
>>>>>
>>>>> Finally. As Joe does, we can remain only gzip and identity in
>>>>> Accept-Encoding and truncate all remaining.
>>>> Locking the entire Internet to using your personal choice of gzip
>>>> compression or none.
>>>> gzip is the slowest and more resource hungry type of compression there
>>>> is. deflate is actually faster for clients and just as widely supported.
>>> Unfortunately, Amos, no one has written any other compression algorithms
>>> support module. We have to eat what they give.
>>>
>> Like I said deflate is widely available. Heiler's recent info shows that
>> lzma is becomming more visible on the public web, which should help fix
>> the one issue deflate has.
>>
>> And noone appears to be fixing the remaining issues in the Squid gzip
>> eCAP module.
>>
>> There also seems to be a big push back from browser and some server
>> vendors about compression in general. We had a fairly major fight in
>> IETF to get HTTP/2 to contain data compression at all. It is still only
>> in there as an optional extension that some are openly refusing to
>> implement.
>>
>>
>>>>> Without any problem. Moreover, this type of can be push to all brunches
>>>>> of squid without any problem, because of this dramatically increases
>>>>> byte HIT.
>>>> Responding with a single object to all requests makes your HIT ratio
>>>> 100% guaranteed. The clients wont like you though if all they ever see
>>>> is the same cat picture.
>>>> It sounds ridiculous when put that way, but that is what these patches
>>>> are doing for a unknown number of those "gained" HITs. See my previous
>>>> post about how none of these patches are changing the request the server
>>>> gets.
>>> But no one asked the question - why Squid in production installations
>>> has such a low hit ratio
>> Yes that has been asked, even investigated. The reason(s) are many
>> complex details and small issues adding together to a big loss.
>>
>> They range from protocol things like Vary not being fine-grained enough
>> (Key header being developed fixes that), through to client behaviour
>> (Chrome sdch doubles the variant count - almost halving useful cache
>> space), to server behaviour (Apache changing Vary header).
>>
>> What your testing of joes patches is showing is that the sdch effect
>> Chrome has is probably way bigger than one would expect to be reasonable.
>>
>>
>>> that raises the question of expediency of
>>> application caching proxy. We do believe that this is a caching proxy?
>>>
>>>
>>>> You are once again sweeping asside the critical requirement of content
>>>> integrity to achieve high HIT ratio. Which is not something that I can
>>>> accept into Squid as a default action.
>>> I continue to believe that 20% is unacceptably low cache hit ratio,
>>> given the very aggressive settings and the active use of Store ID. Which
>>> brings us back to the idea of the feasibility of using the SQUID as a
> whole.
>> That kind of "unacceptable" statement simply cannot be made about cache
>> HIT ratio. It is what it is. One cannot change the speed of light
>> because it takes unacceptable long to travel through space.
>>
>> Two properly working caches in serial will have extremely different
>> caching ratios. The one with most direct client connections trends
>> towards 50-100% and the upstream one towards the servers will trend
>> towards zero. The total cacheable ratio is unchanged, but each cache
>> sees a different proportion of it and so shows different HIT ratios
>> relative to their clients portion.
>>
>>
>> Also, don't forget that browser cache disk space available are
>> increasingly large as well. So their caches are growing in size and
>> taking up a larger share of the total achievable HIT ratios in recent
> years.
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>   
> iQEcBAEBCAAGBQJXVrctAAoJENNXIZxhPexGl8gIALRSaB3nC6fUjKM8GGL+ep3m
> NZganwbvtkLLLDHQFuTA3K9gvl/GWieQ/3jj+Pp45kgNIeVNsbwYF6IANOT1/olc
> XIGpHK0LICSeTA5kpSHU6hkdfao6AWSUFLci5WXl/Ay7qvzWI4h/NqPhyhoaJUSq
> LTmOePc98oALu4oZpmdmKy1D5yduLmjDy8cbIJTRc/SVha5tt4Sre7z8dI9geX9L
> PlrXBxbtH+oGAYu5qiuifQR9UZCoYL0wL30KzWLyIqmZJdT/NIshIRA1wHVdy9lL
> d0CNwheIPTvstnx8uKOMk4vN/Z5y+A6LnTHHoJgfRCyNwD1IayoPRY1CJffWVRk=
> =40f2
> -----END PGP SIGNATURE-----
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/b552af57/attachment.htm>

From heiler.bemerguy at cinbesa.com.br  Tue Jun  7 22:27:49 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 7 Jun 2016 19:27:49 -0300
Subject: [squid-users] Vary object loop returns
In-Reply-To: <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
 <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
 <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>
 <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>
Message-ID: <fba85af5-eb5c-52b0-4c70-eac80c47e1bc@cinbesa.com.br>


I changed the source to debug a bit, started a fresh/clean squid.

accessed http://api.footballaddicts.com/favicon.ico

and look what it's trying to compare():

vary = 
'accept="text%2Fhtml,application%2Fxhtml+xml,application%2Fxml%3Bq%3D0.9,*%2F*%3Bq%3D0.8", 
if-none-match="%225756ad27-47e%22", 
if-modified-since="Tue,%2007%20Jun%202016%2011%3A16%3A55%20GMT", 
accept-language="en-US,en%3Bq%3D0.8,pt-BR%3Bq%3D0.5,pt%3Bq%3D0.3", 
accept-encoding="none", x-client-locale, 
user-agent="Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A46.0)%20Gecko%2F20100101%20Firefox%2F46.0", 
x-device'

entry->mem_obj->vary_headers = 
'accept="text%2Fhtml,application%2Fxhtml+xml,application%2Fxml%3Bq%3D0.9,*%2F*%3Bq%3D0.8", 
if-none-match, if-modified-since, 
accept-language="en-US,en%3Bq%3D0.8,pt-BR%3Bq%3D0.5,pt%3Bq%3D0.3", 
accept-encoding="none", x-client-locale, 
user-agent="Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A46.0)%20Gecko%2F20100101%20Firefox%2F46.0", 
x-device'

That's why it always gives vary object loop


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751

Em 07/06/2016 17:21, Heiler Bemerguy escreveu:
>
>
> Some servers will reply like this, trying to avoid caching at any cost 
> (I think):
>
> HTTP/1.1 200 OK
> Server: nginx
> Content-Type: image/x-icon
> Last-Modified: Tue, 07 Jun 2016 11:16:55 GMT
> ETag: "5756ad27-47e"
> Content-Length: 1150
> X-Suppressed-Cache-Control: max-age=600
> Cache-Control: private, max-age=0, must-revalidate
> X-Suppressed-Expires: Tue, 07 Jun 2016 20:07:36 GMT
> Expires: Thu, 01 Jan 1970 00:00:00 GMT
> Date: Tue, 07 Jun 2016 19:57:36 GMT
> X-Varnish: 510207311
> *Vary: 
> Accept,If-None-Match,If-Modified-Since,Accept-Language,Accept-Encoding,X-Client-Locale,User-Agent,X-Device*
>
> Then our squid will create a vary object with all that information, 
> giving this bomb: httpMakeVaryMark: 
> accept="image%2Fpng,image%2F*%3Bq%3D0.8,*%2F*%3Bq%3D0.5", 
> if-none-match="%225756ad27-47e%22", if-modified-since, 
> accept-language="en-US,en%3Bq%3D0.8,pt-BR%3Bq%3D0.5,pt%3Bq%3D0.3", 
> accept-encoding="none", x-client-locale, 
> user-agent="Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A46.0)%20Gecko%2F20100101%20Firefox%2F46.0", 
> x-device
>
> It's squid "fault" to convert spaces and symbols to %values, and I 
> think no sanity check is performed on it.. still, I don't see the code 
> where it checks if all this info from the new client is identical to 
> the stored one.. and I don't know where the "loop" comes from...
>
> Now I think I'm confused... lol
>
>
> -- 
> Best Regards,
>
> Heiler Bemerguy
> Network Manager - CINBESA
> 55 91 98151-4894/3184-1751
>
> Em 07/06/2016 08:59, Yuri Voinov escreveu:
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>>   
>> I want to give one example on the topic.
>>
>> Here is from one of my cache:
>>
>> /data/cache/d2/00/02/000004C3   0   102502
>> http://www.openoffice.org/favicon.ico
>> /data/cache/d2/00/01/0000031D   0   161421
>> http://rgho.st.squidinternal/favicon.ico
>> /data/cache/d1/00/2E/00005C04   0    33274
>> http://www.tcpiputils.com/favicon.ico
>>
>> Just take a look on file sizes. This is only favicon. 100 kbytes for
>> favicon only! (on Microsoft I've seen 470 kbytes favicon once upon time).
>>
>> When we take a look into access.log, we often see several URL's for favicon:
>>
>> http://www.somesite.com/favicon.ico?v=1.44&id=41324134abcd123123123
>>
>> Good site, isn't it? Loading 100 kbytes every time every client surf any
>> site page.
>>
>> When I was doing research, it became clear that, in most cases, these
>> same favicon were one and the same content. As an example, a client with
>> a smartphone like to download 100 kB - and this is only a small portion
>> of the page! - everytime?
>>
>> 100 kb of mobile data traffic in most countries of the world - decent money.
>>
>> Yes, usually from the client browser cache.
>>
>> What about the number of clients and the access point, which pays
>> terabytes non-peering traffic?
>>
>> The same tricks I've seen with a user-agent. With Vary.
>>
>> 07.06.2016 16:36, Amos Jeffries ?????:
>>> On 7/06/2016 8:48 p.m., Yuri Voinov wrote:
>>>> 07.06.2016 4:57, Amos Jeffries ?????:
>>>>> On 7/06/2016 5:55 a.m., Yuri Voinov wrote:
>>>>>> So.
>>>>>>
>>>>>> Squid DOES NOT and DON'T BE support gzip. The only way to do it - use
>>>>>> ecap + desupported ecap gzip adapter. Let's accept this. We can support
>>>>>> gzip. With restrictions. Ok.
>>>>>>
>>>>>> any other compression - false. No. No way. Get out. and so on.
>>>>>>
>>>>>>   identity - this is uncompressed type.
>>>>>>
>>>>>> That's all, folks.
>>>>>>
>>>>>> Finally. As Joe does, we can remain only gzip and identity in
>>>>>> Accept-Encoding and truncate all remaining.
>>>>> Locking the entire Internet to using your personal choice of gzip
>>>>> compression or none.
>>>>> gzip is the slowest and more resource hungry type of compression there
>>>>> is. deflate is actually faster for clients and just as widely supported.
>>>> Unfortunately, Amos, no one has written any other compression algorithms
>>>> support module. We have to eat what they give.
>>>>
>>> Like I said deflate is widely available. Heiler's recent info shows that
>>> lzma is becomming more visible on the public web, which should help fix
>>> the one issue deflate has.
>>>
>>> And noone appears to be fixing the remaining issues in the Squid gzip
>>> eCAP module.
>>>
>>> There also seems to be a big push back from browser and some server
>>> vendors about compression in general. We had a fairly major fight in
>>> IETF to get HTTP/2 to contain data compression at all. It is still only
>>> in there as an optional extension that some are openly refusing to
>>> implement.
>>>
>>>
>>>>>> Without any problem. Moreover, this type of can be push to all brunches
>>>>>> of squid without any problem, because of this dramatically increases
>>>>>> byte HIT.
>>>>> Responding with a single object to all requests makes your HIT ratio
>>>>> 100% guaranteed. The clients wont like you though if all they ever see
>>>>> is the same cat picture.
>>>>> It sounds ridiculous when put that way, but that is what these patches
>>>>> are doing for a unknown number of those "gained" HITs. See my previous
>>>>> post about how none of these patches are changing the request the server
>>>>> gets.
>>>> But no one asked the question - why Squid in production installations
>>>> has such a low hit ratio
>>> Yes that has been asked, even investigated. The reason(s) are many
>>> complex details and small issues adding together to a big loss.
>>>
>>> They range from protocol things like Vary not being fine-grained enough
>>> (Key header being developed fixes that), through to client behaviour
>>> (Chrome sdch doubles the variant count - almost halving useful cache
>>> space), to server behaviour (Apache changing Vary header).
>>>
>>> What your testing of joes patches is showing is that the sdch effect
>>> Chrome has is probably way bigger than one would expect to be reasonable.
>>>
>>>
>>>> that raises the question of expediency of
>>>> application caching proxy. We do believe that this is a caching proxy?
>>>>
>>>>
>>>>> You are once again sweeping asside the critical requirement of content
>>>>> integrity to achieve high HIT ratio. Which is not something that I can
>>>>> accept into Squid as a default action.
>>>> I continue to believe that 20% is unacceptably low cache hit ratio,
>>>> given the very aggressive settings and the active use of Store ID. Which
>>>> brings us back to the idea of the feasibility of using the SQUID as a
>> whole.
>>> That kind of "unacceptable" statement simply cannot be made about cache
>>> HIT ratio. It is what it is. One cannot change the speed of light
>>> because it takes unacceptable long to travel through space.
>>>
>>> Two properly working caches in serial will have extremely different
>>> caching ratios. The one with most direct client connections trends
>>> towards 50-100% and the upstream one towards the servers will trend
>>> towards zero. The total cacheable ratio is unchanged, but each cache
>>> sees a different proportion of it and so shows different HIT ratios
>>> relative to their clients portion.
>>>
>>>
>>> Also, don't forget that browser cache disk space available are
>>> increasingly large as well. So their caches are growing in size and
>>> taking up a larger share of the total achievable HIT ratios in recent
>> years.
>>> Amos
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v2
>>   
>> iQEcBAEBCAAGBQJXVrctAAoJENNXIZxhPexGl8gIALRSaB3nC6fUjKM8GGL+ep3m
>> NZganwbvtkLLLDHQFuTA3K9gvl/GWieQ/3jj+Pp45kgNIeVNsbwYF6IANOT1/olc
>> XIGpHK0LICSeTA5kpSHU6hkdfao6AWSUFLci5WXl/Ay7qvzWI4h/NqPhyhoaJUSq
>> LTmOePc98oALu4oZpmdmKy1D5yduLmjDy8cbIJTRc/SVha5tt4Sre7z8dI9geX9L
>> PlrXBxbtH+oGAYu5qiuifQR9UZCoYL0wL30KzWLyIqmZJdT/NIshIRA1wHVdy9lL
>> d0CNwheIPTvstnx8uKOMk4vN/Z5y+A6LnTHHoJgfRCyNwD1IayoPRY1CJffWVRk=
>> =40f2
>> -----END PGP SIGNATURE-----
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/a94669a6/attachment.htm>

From squid3 at treenet.co.nz  Wed Jun  8 06:13:53 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 8 Jun 2016 18:13:53 +1200
Subject: [squid-users] Response timeout for upstream HTTP servers
In-Reply-To: <5756FF72.8080000@endpoint.com>
References: <5756FF72.8080000@endpoint.com>
Message-ID: <210e1e74-afc5-0f06-534b-b6eaf189f204@treenet.co.nz>

On 8/06/2016 5:08 a.m., Adam Vollrath wrote:
> Good morning! I'm having trouble with upstream HTTP servers not
> responding for more than 30 seconds.  I'd like to just return an empty
> response to the downstream client. Nothing is better than waiting.
> 
> I'm looking for a `squid3` configuration directive to timeout between an
> HTTP request and response.  Here's the directive for `nginx`:
> http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_read_timeout
> 
> 	"Defines a timeout for reading a response from the proxied server. The
> timeout is set only between two successive read operations, not for the
> transmission of the whole response. If the proxied server does not
> transmit anything within this time, the connection is closed."
> 
> Does `squid3` have a way to implement this?  Is this what the
> `read_timeout` directive does if my upstream systems are configured as
> `cache_peer`?

I think you misunderstand what "proxy" means. Nginx primary design focus
as a web server like Apache. So proxied traffic is a special activity
for it.

Squid is a proxy. So by definition everything going through Squid is
proxied.


<http://www.squid-cache.org/Doc/config/read_timeout/> controls the
timeout for individual read(2) operations on a connection which is active.

<http://www.squid-cache.org/Doc/config/write_timeout/> controls the
timeout for individual write(2) operations on a connection which is active.

<http://www.squid-cache.org/Doc/config/server_idle_pconn_timeout/>
controls the timeout for connections in idle state between requests.

Other timeouts control specific actions like DNS, route selection,
connect(2), or client connection activities.

HTH
Amos



From squid3 at treenet.co.nz  Wed Jun  8 06:31:29 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 8 Jun 2016 18:31:29 +1200
Subject: [squid-users] Vary object loop returns
In-Reply-To: <fba85af5-eb5c-52b0-4c70-eac80c47e1bc@cinbesa.com.br>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
 <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
 <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>
 <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>
 <fba85af5-eb5c-52b0-4c70-eac80c47e1bc@cinbesa.com.br>
Message-ID: <2411132f-7d9e-08c8-0d7e-223c5575bd1f@treenet.co.nz>

On 8/06/2016 10:27 a.m., Heiler Bemerguy wrote:
> 
> I changed the source to debug a bit, started a fresh/clean squid.
> 
> accessed http://api.footballaddicts.com/favicon.ico
> 
> and look what it's trying to compare():
> 
> vary =
> 'accept="text%2Fhtml,application%2Fxhtml+xml,application%2Fxml%3Bq%3D0.9,*%2F*%3Bq%3D0.8",
> if-none-match="%225756ad27-47e%22",
> if-modified-since="Tue,%2007%20Jun%202016%2011%3A16%3A55%20GMT",
> accept-language="en-US,en%3Bq%3D0.8,pt-BR%3Bq%3D0.5,pt%3Bq%3D0.3",
> accept-encoding="none", x-client-locale,
> user-agent="Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A46.0)%20Gecko%2F20100101%20Firefox%2F46.0",
> x-device'
> 

AIUI, the above is the sub-key it generated for the active client
request based on the vary-marker object that was found by looking up the
request URL.

When looking up the above sub-key (not the URL) it found an object
stored with the below different sub-key. Which according to Vary
algorithm rules means the found one is not the same one being wanted.

I am thinking that collapsed_forwarding and SMP aspects of this are just
that the worker handling a request its some other URLs stored object on
the sub-key lookup.

> entry->mem_obj->vary_headers =
> 'accept="text%2Fhtml,application%2Fxhtml+xml,application%2Fxml%3Bq%3D0.9,*%2F*%3Bq%3D0.8",
> if-none-match, if-modified-since,
> accept-language="en-US,en%3Bq%3D0.8,pt-BR%3Bq%3D0.5,pt%3Bq%3D0.3",
> accept-encoding="none", x-client-locale,
> user-agent="Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A46.0)%20Gecko%2F20100101%20Firefox%2F46.0",
> x-device'
> 
> That's why it always gives vary object loop
> 

:-( Stupidity at its best with that sites designer.


Heres a little recipe that should raise the HIT ratio for that kind of
crap in 3.5:

 acl brokenVaryHeaders rep_header Vary -i \
    user-agent \
    if(-none)?-match \
    if-(un)?modified-since

 store_miss deny brokenVaryHeaders


Amos



From squid3 at treenet.co.nz  Wed Jun  8 06:48:02 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 8 Jun 2016 18:48:02 +1200
Subject: [squid-users] Vary object loop returns
In-Reply-To: <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
 <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
 <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>
 <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>
Message-ID: <8b616b59-3fdb-0428-9379-ab51e1f46c4c@treenet.co.nz>

On 8/06/2016 8:21 a.m., Heiler Bemerguy wrote:
> 
> Some servers will reply like this, trying to avoid caching at any cost
> (I think):
> 
> HTTP/1.1 200 OK
> Server: nginx
> Content-Type: image/x-icon
> Last-Modified: Tue, 07 Jun 2016 11:16:55 GMT
> ETag: "5756ad27-47e"
> Content-Length: 1150
> X-Suppressed-Cache-Control: max-age=600
> Cache-Control: private, max-age=0, must-revalidate
> X-Suppressed-Expires: Tue, 07 Jun 2016 20:07:36 GMT
> Expires: Thu, 01 Jan 1970 00:00:00 GMT
> Date: Tue, 07 Jun 2016 19:57:36 GMT
> X-Varnish: 510207311
> *Vary:
> Accept,If-None-Match,If-Modified-Since,Accept-Language,Accept-Encoding,X-Client-Locale,User-Agent,X-Device*
> 
> 
> Then our squid will create a vary object with all that information,
> giving this bomb: httpMakeVaryMark:
> accept="image%2Fpng,image%2F*%3Bq%3D0.8,*%2F*%3Bq%3D0.5",
> if-none-match="%225756ad27-47e%22", if-modified-since,
> accept-language="en-US,en%3Bq%3D0.8,pt-BR%3Bq%3D0.5,pt%3Bq%3D0.3",
> accept-encoding="none", x-client-locale,
> user-agent="Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A46.0)%20Gecko%2F20100101%20Firefox%2F46.0",
> x-device
> 
> It's squid "fault" to convert spaces and symbols to %values, and I think
> no sanity check is performed on it..

There are at least three sanity checks/protections performed.

 1) the client request headers must parse according to HTTP rules. If
any one of them dont Squid either wont get this far, or will be treating
that header as non-existent/empty.

 2) as of 3.5.19 the total length of the expansion must be short enough
to store in a limited string buffer (~64KB). The recent CVE-2016-* set
of issues happened because it was possible to get past this sometimes.

 3) the header field values are RFC1738 encoded as they are added to the
sub-key to ensure it complies with HTTP octet requirements and prevent
log based attacks. Thats the %-encoding you see in the logs.


> still, I don't see the code where
> it checks if all this info from the new client is identical to the
> stored one.. and I don't know where the "loop" comes from...

That is a set of separate checks deeper inside store itself which are
performed for every lookup, not just Vary sub-key lookups. One of which
is to compare the URL of the found object with the active request. The
second of which you found with your extra debug already.

Amos



From squid3 at treenet.co.nz  Wed Jun  8 09:20:52 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 8 Jun 2016 21:20:52 +1200
Subject: [squid-users] SSLBump non-HTTPs connections
In-Reply-To: <CAPa6PsFO4PrLcXocwW0zG4fZcwtB9dLpk24HAdi79XdRwaGNfQ@mail.gmail.com>
References: <CAPa6PsFO4PrLcXocwW0zG4fZcwtB9dLpk24HAdi79XdRwaGNfQ@mail.gmail.com>
Message-ID: <41ed6adb-ca43-e7b5-05c2-c57c05fe1ecb@treenet.co.nz>

On 2/06/2016 6:33 p.m., Peter Viskup wrote:
> Hello all,
> just wondering whether it is possible to perform SSLBump/SSLSplit for
> non-HTTPs connections. At the moment we are interested in FTPs.

Only protocols supported for regular proxying by Squid can be
SSL-Bumped. There is no point in doing it for a protocol that will just
get a TCP RST.

FTP is in a grey area since Squid now supports relaying it. But AFAIK we
only support regular un-encrypted FTP. I might be wrong though so you
could give it a go.


> We are running Squid 3.4.2 version.
> 

If you are going to MITM the TLS layer use the latest Squid version and
keep up to date. TLS is undergoing an arms race and older versions dont
work reliably for very long. Changes appear to have slowed a bit
recently, but still the oldest fully/properly working version is the
current 3.5.19.

Amos



From squid3 at treenet.co.nz  Wed Jun  8 09:25:26 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 8 Jun 2016 21:25:26 +1200
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
In-Reply-To: <OF67A1BEDE.D8307381-ON80257FC5.006ADE21-80257FC5.006B0CE3@tcs.com>
References: <OF67A1BEDE.D8307381-ON80257FC5.006ADE21-80257FC5.006B0CE3@tcs.com>
Message-ID: <ee465d52-b089-c85f-dab2-bab050f95b06@treenet.co.nz>

On 2/06/2016 7:29 a.m., Nilesh Gavali wrote:
> hello;
> where can I define below -
> 
> KRB5_KTNAME=/etc/squid3/PROXY.keytab
> export KRB5_KTNAME
> 
> Thanks & Regards
> Nilesh Suresh Gavali
> 

Usually in the init scripts of relevant programs that use it.

PS. please stop quoting the entire daily digest of squid-users messages
in your posts. It would also help if you switched your account settings
to non-digest for the time when you want to actively discuss things.

Amos



From squid3 at treenet.co.nz  Wed Jun  8 09:43:39 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 8 Jun 2016 21:43:39 +1200
Subject: [squid-users] server request timeout not working
In-Reply-To: <eb50b78f-b7d3-41e7-8a98-cbd914ad8490@cinbesa.com.br>
References: <eb50b78f-b7d3-41e7-8a98-cbd914ad8490@cinbesa.com.br>
Message-ID: <9a4f600d-bbae-4f0d-5b4c-b97e50f16ad0@treenet.co.nz>

On 25/05/2016 8:26 a.m., Heiler Bemerguy wrote:
> 
> If you connect to squid and ask it to get a file on a server which
> accepts the tcp connection but won't reply anything, the connection will
> never timeout.
> 
> Like this: (client side)
> 
> GET http://10.1.4.60:8080/pehasuzyjireohwwlik.txt HTTP/1.1
> Accept: */*
> Accept-Encoding: identity
> Range: bytes=20-80
> User-Agent: FakeUser/0.0
> Proxy-Connection: Keep-Alive
> Host: 10.1.4.60
> 
> Gives this on server side:
> 
> GET /pehasuzyjireohwwlik.txt HTTP/1.1
> Accept: */*
> Accept-Encoding: identity
> User-Agent: FakeUser/0.0
> Host: 10.1.4.60:8080
> Via: 1.1 jasperserver (squid)
> X-Forwarded-For: 10.1.4.60
> Cache-Control: max-age=29030400
> Connection: keep-alive
> 
> It does connect to 10.1.4.60:8080, this port is open and accepting
> connections.. but it won't reply anything to squid, and squid will
> remain connected to it and waiting forever

How long was the longest actual test you made?
 read_timeout is 15 minutes.


> 
> client_idle_pconn_timeout 30 seconds

 - how long to wait for the next client request to arrive on a
persistent connection.

 NP: ideally you want long-ish client persistence and short server
persistence.

This is because clients may be a browser waiting for user to read a page
before clicking onwards. CLosing them early means higher latency when
user clicks on web links, etc.

But server connections are multiplexed and shared for outgoing requests.
So many active clients will use them more frequently than a single
client. Holding onto these for long times also ties up the server
resources needlessly and risks being disconnected from the other end
which causes problems.


> 
> client_persistent_connections on
> server_persistent_connections on

 - enable "Connection:keep-alive" feature of HTTP on both client and
server connections.


> connect_timeout 60 seconds

 - how long to wait for TCP SYN ACK packet when making an outbound
connection to some server.


> request_timeout 30 seconds

 - how long to wait for *client* to *send us* the request headers after
is connects.

> persistent_request_timeout 30 seconds

 - An obsolete directive replaced by client_idle_pconn_timeout in Squid-3.2.


> collapsed_forwarding on
> 

Allow client requests to get a HIT on a transaction that has not yet
completed, or possibly only just started being sent to the server.


Notice how none of those settings is related to outgoing server request
timing.

Once the request is written (governed by write_timeout) the next thing
Squid does on that connection is wait for the response (governed by
read_timeout). When the response is finished it gets put back into the
idle pool (governed by server_idle_pconn_timeout).


Amos



From heiler.bemerguy at cinbesa.com.br  Wed Jun  8 13:34:34 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Wed, 8 Jun 2016 10:34:34 -0300
Subject: [squid-users] Vary object loop returns
In-Reply-To: <2411132f-7d9e-08c8-0d7e-223c5575bd1f@treenet.co.nz>
References: <1465204487541-4677832.post@n4.nabble.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
 <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
 <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>
 <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>
 <fba85af5-eb5c-52b0-4c70-eac80c47e1bc@cinbesa.com.br>
 <2411132f-7d9e-08c8-0d7e-223c5575bd1f@treenet.co.nz>
Message-ID: <1830582b-25a0-b222-81b7-6ba93a270727@cinbesa.com.br>


So.. with store_miss I could make squid store only some types of vary?
Wouldn't it "fix" the vary loop "bug" without messing with sources?


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751


Em 08/06/2016 03:31, Amos Jeffries escreveu:
>
>> entry->mem_obj->vary_headers =
>> 'accept="text%2Fhtml,application%2Fxhtml+xml,application%2Fxml%3Bq%3D0.9,*%2F*%3Bq%3D0.8",
>> if-none-match, if-modified-since,
>> accept-language="en-US,en%3Bq%3D0.8,pt-BR%3Bq%3D0.5,pt%3Bq%3D0.3",
>> accept-encoding="none", x-client-locale,
>> user-agent="Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A46.0)%20Gecko%2F20100101%20Firefox%2F46.0",
>> x-device'
>>
>> That's why it always gives vary object loop
>>
> :-( Stupidity at its best with that sites designer.
>
>
> Heres a little recipe that should raise the HIT ratio for that kind of
> crap in 3.5:
>
>   acl brokenVaryHeaders rep_header Vary -i \
>      user-agent \
>      if(-none)?-match \
>      if-(un)?modified-since
>
>   store_miss deny brokenVaryHeaders
>
>
> Amos
>



From heiler.bemerguy at cinbesa.com.br  Wed Jun  8 16:02:13 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Wed, 8 Jun 2016 13:02:13 -0300
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1830582b-25a0-b222-81b7-6ba93a270727@cinbesa.com.br>
References: <1465204487541-4677832.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
 <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
 <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>
 <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>
 <fba85af5-eb5c-52b0-4c70-eac80c47e1bc@cinbesa.com.br>
 <2411132f-7d9e-08c8-0d7e-223c5575bd1f@treenet.co.nz>
 <1830582b-25a0-b222-81b7-6ba93a270727@cinbesa.com.br>
Message-ID: <685dc66d-7765-cc25-b985-baef40f63ed1@cinbesa.com.br>


Hum.. Amos, that store_miss would just make the object with that Vary 
header to not be cached, right?

I've just tested it. But I think we need to choose what types of Vary 
are valid/usable or not.

Reading the source code since yesterday, I made a patch that seems to 
fix my vary loop problem and will increase HITs a lot.

It will only accept "accept-encoding" as a Vary statement and ignore all 
the other garbage servers are using as "Vary"...

A simple change on http.cc, not client_side.cc


Here it goes, use at your own risk:

*--- http.cc     2016-05-08 09:46:35.000000000 -0300**
**+++ http.cc.new 2016-06-08 12:25:16.000000000 -0300**
**@@ -595,6 +595,11 @@**
**         xstrncpy(name, item, ilen + 1);**
**         Tolower(name);**
****
**+        if (strcmp(name, "accept-encoding") != 0)  {**
**+           safe_free(name);**
**+            continue;**
**+       }**
**+**
**         if (strcmp(name, "*") == 0) {**
**             /* Can not handle "Vary: *" withtout ETag support */**
**             safe_free(name);*


Save this text as http.patch on "src" directory and then: patch < http.patch


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751



Em 08/06/2016 10:34, Heiler Bemerguy escreveu:
>
> So.. with store_miss I could make squid store only some types of vary?
> Wouldn't it "fix" the vary loop "bug" without messing with sources?
>
>
> -- 
> Best Regards,
>
> Heiler Bemerguy
> Network Manager - CINBESA
> 55 91 98151-4894/3184-1751
>
>
> Em 08/06/2016 03:31, Amos Jeffries escreveu:
>>
>>> entry->mem_obj->vary_headers =
>>> 'accept="text%2Fhtml,application%2Fxhtml+xml,application%2Fxml%3Bq%3D0.9,*%2F*%3Bq%3D0.8", 
>>>
>>> if-none-match, if-modified-since,
>>> accept-language="en-US,en%3Bq%3D0.8,pt-BR%3Bq%3D0.5,pt%3Bq%3D0.3",
>>> accept-encoding="none", x-client-locale,
>>> user-agent="Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A46.0)%20Gecko%2F20100101%20Firefox%2F46.0", 
>>>
>>> x-device'
>>>
>>> That's why it always gives vary object loop
>>>
>> :-( Stupidity at its best with that sites designer.
>>
>>
>> Heres a little recipe that should raise the HIT ratio for that kind of
>> crap in 3.5:
>>
>>   acl brokenVaryHeaders rep_header Vary -i \
>>      user-agent \
>>      if(-none)?-match \
>>      if-(un)?modified-since
>>
>>   store_miss deny brokenVaryHeaders
>>
>>
>> Amos
>>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160608/9d5a826d/attachment.htm>

From yvoinov at gmail.com  Wed Jun  8 16:03:47 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 8 Jun 2016 22:03:47 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <685dc66d-7765-cc25-b985-baef40f63ed1@cinbesa.com.br>
References: <1465204487541-4677832.post@n4.nabble.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
 <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
 <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>
 <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>
 <fba85af5-eb5c-52b0-4c70-eac80c47e1bc@cinbesa.com.br>
 <2411132f-7d9e-08c8-0d7e-223c5575bd1f@treenet.co.nz>
 <1830582b-25a0-b222-81b7-6ba93a270727@cinbesa.com.br>
 <685dc66d-7765-cc25-b985-baef40f63ed1@cinbesa.com.br>
Message-ID: <28b284dd-726e-89ae-3747-865a648f85c2@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
# Clean up Vary to increase caching
reply_header_access Vary deny all
reply_header_replace Vary Accept-Encoding

Hmmm? ;)


08.06.2016 22:02, Heiler Bemerguy ?????:
>
>
> Hum.. Amos, that store_miss would just make the object with that Vary
header to not be cached, right?
>
> I've just tested it. But I think we need to choose what types of Vary
are valid/usable or not.
>
> Reading the source code since yesterday, I made a patch that seems to
fix my vary loop problem and will increase HITs a lot.
>
> It will only accept "accept-encoding" as a Vary statement and ignore
all the other garbage servers are using as "Vary"...
>
> A simple change on http.cc, not client_side.cc
>
>
> Here it goes, use at your own risk:
>
> *--- http.cc     2016-05-08 09:46:35.000000000 -0300**
> **+++ http.cc.new 2016-06-08 12:25:16.000000000 -0300**
> **@@ -595,6 +595,11 @@**
> **         xstrncpy(name, item, ilen + 1);**
> **         Tolower(name);**
> ** **
> **+        if (strcmp(name, "accept-encoding") != 0)  {**
> **+           safe_free(name);**
> **+            continue;**
> **+       }**
> **+**
> **         if (strcmp(name, "*") == 0) {**
> **             /* Can not handle "Vary: *" withtout ETag support */**
> **             safe_free(name);*
>
>
> Save this text as http.patch on "src" directory and then: patch <
http.patch
>
>
> --
> Best Regards,
>
> Heiler Bemerguy
> Network Manager - CINBESA
> 55 91 98151-4894/3184-1751
>
>
> Em 08/06/2016 10:34, Heiler Bemerguy escreveu:
>>
>> So.. with store_miss I could make squid store only some types of vary?
>> Wouldn't it "fix" the vary loop "bug" without messing with sources?
>>
>>
>> --
>> Best Regards,
>>
>> Heiler Bemerguy
>> Network Manager - CINBESA
>> 55 91 98151-4894/3184-1751
>>
>>
>> Em 08/06/2016 03:31, Amos Jeffries escreveu:
>>>
>>>> entry->mem_obj->vary_headers =
>>>>
'accept="text%2Fhtml,application%2Fxhtml+xml,application%2Fxml%3Bq%3D0.9,*%2F*%3Bq%3D0.8",
>>>> if-none-match, if-modified-since,
>>>> accept-language="en-US,en%3Bq%3D0.8,pt-BR%3Bq%3D0.5,pt%3Bq%3D0.3",
>>>> accept-encoding="none", x-client-locale,
>>>>
user-agent="Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A46.0)%20Gecko%2F20100101%20Firefox%2F46.0",
>>>> x-device'
>>>>
>>>> That's why it always gives vary object loop
>>>>
>>> :-( Stupidity at its best with that sites designer.
>>>
>>>
>>> Heres a little recipe that should raise the HIT ratio for that kind of
>>> crap in 3.5:
>>>
>>>   acl brokenVaryHeaders rep_header Vary -i \
>>>      user-agent \
>>>      if(-none)?-match \
>>>      if-(un)?modified-since
>>>
>>>   store_miss deny brokenVaryHeaders
>>>
>>>
>>> Amos
>>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXWEHiAAoJENNXIZxhPexGsJkIAIwYPMIx8YBZjgusZvddQ6G+
NaGwcbVTrA+my2cgX6FpJLl5jHUF0Z/K8wiQbKAz73zmQSr0gkjSegKqCgqBf+mS
UrvdS/4Hg1dCSkdQVOkHeb6cRKOVI2VLiOOtMWDJdTeXjv/ELsn7PfIeOMujgGBm
3069k4mm+DwmQ4V/ozSOejBa7PB83UU80Ab6e5dnhiEpjnsN3MaZhMyCxyR8YMdK
4ikrmOaGkKLjoQEwcMGyVbkzKIOwe3eg5HCL/qr5v0Ickxn/adyHweL0KE8UjQXl
ghTKj2OpM4SWT9Tc8W0kZM8bpwzS5qgA/5rqJbDSbtjDFH03mH0R3eRjWtTVsik=
=5lo3
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160608/dca69796/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160608/dca69796/attachment.key>

From squid3 at treenet.co.nz  Wed Jun  8 16:58:13 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 9 Jun 2016 04:58:13 +1200
Subject: [squid-users] Vary object loop returns
In-Reply-To: <685dc66d-7765-cc25-b985-baef40f63ed1@cinbesa.com.br>
References: <1465204487541-4677832.post@n4.nabble.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
 <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
 <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>
 <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>
 <fba85af5-eb5c-52b0-4c70-eac80c47e1bc@cinbesa.com.br>
 <2411132f-7d9e-08c8-0d7e-223c5575bd1f@treenet.co.nz>
 <1830582b-25a0-b222-81b7-6ba93a270727@cinbesa.com.br>
 <685dc66d-7765-cc25-b985-baef40f63ed1@cinbesa.com.br>
Message-ID: <c0c4287a-2c91-9f19-a1ae-357cf558a7c9@treenet.co.nz>

On 9/06/2016 4:02 a.m., Heiler Bemerguy wrote:
> 
> Hum.. Amos, that store_miss would just make the object with that Vary
> header to not be cached, right?

It will prevent caching for any object using a Vary which matches any of
the ACLs regex patterns. The patterns being ones which match the headers
that are known to cause variant explosions.

> 
> I've just tested it. But I think we need to choose what types of Vary
> are valid/usable or not.

Huh?

> 
> Reading the source code since yesterday, I made a patch that seems to
> fix my vary loop problem and will increase HITs a lot.
> 
> It will only accept "accept-encoding" as a Vary statement and ignore all
> the other garbage servers are using as "Vary"...
> 
> A simple change on http.cc, not client_side.cc
> 

I think your patch is identical to hard-coding the config:

 acl vary rep_header Vary -i .
 acl varyAE rep_header Vary -i ^accept-encoding$
 store_miss deny vary !varyAE

It is not reasonable to hard-code these things in a widely used generic
HTTP proxy like Squid. If it can be configured do it that way, if it
can't then config needs to be added.

Amos



From squid3 at treenet.co.nz  Wed Jun  8 17:02:32 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 9 Jun 2016 05:02:32 +1200
Subject: [squid-users] Vary object loop returns
In-Reply-To: <28b284dd-726e-89ae-3747-865a648f85c2@gmail.com>
References: <1465204487541-4677832.post@n4.nabble.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
 <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
 <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>
 <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>
 <fba85af5-eb5c-52b0-4c70-eac80c47e1bc@cinbesa.com.br>
 <2411132f-7d9e-08c8-0d7e-223c5575bd1f@treenet.co.nz>
 <1830582b-25a0-b222-81b7-6ba93a270727@cinbesa.com.br>
 <685dc66d-7765-cc25-b985-baef40f63ed1@cinbesa.com.br>
 <28b284dd-726e-89ae-3747-865a648f85c2@gmail.com>
Message-ID: <bfb23d44-d49b-4541-3b15-617505884d78@treenet.co.nz>

On 9/06/2016 4:03 a.m., Yuri Voinov wrote:
> 
> # Clean up Vary to increase caching
> reply_header_access Vary deny all
> reply_header_replace Vary Accept-Encoding
> 
> Hmmm? ;)
> 

Mangling the outgoing headers sent to the client so they no longer
describe the payload/content correctly will not help Squid in any way.
Just make things worse for the client.

Amos


From yvoinov at gmail.com  Wed Jun  8 17:06:05 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 8 Jun 2016 23:06:05 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <bfb23d44-d49b-4541-3b15-617505884d78@treenet.co.nz>
References: <1465204487541-4677832.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
 <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
 <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>
 <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>
 <fba85af5-eb5c-52b0-4c70-eac80c47e1bc@cinbesa.com.br>
 <2411132f-7d9e-08c8-0d7e-223c5575bd1f@treenet.co.nz>
 <1830582b-25a0-b222-81b7-6ba93a270727@cinbesa.com.br>
 <685dc66d-7765-cc25-b985-baef40f63ed1@cinbesa.com.br>
 <28b284dd-726e-89ae-3747-865a648f85c2@gmail.com>
 <bfb23d44-d49b-4541-3b15-617505884d78@treenet.co.nz>
Message-ID: <4aa255f6-a7e1-8717-1c2e-9bbf06768139@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Ok, Amos.

How to correctly normalize headers?

I.e., to strip User-Agent, for example?


08.06.2016 23:02, Amos Jeffries ?????:
> On 9/06/2016 4:03 a.m., Yuri Voinov wrote:
>>
>> # Clean up Vary to increase caching
>> reply_header_access Vary deny all
>> reply_header_replace Vary Accept-Encoding
>>
>> Hmmm? ;)
>>
>
> Mangling the outgoing headers sent to the client so they no longer
> describe the payload/content correctly will not help Squid in any way.
> Just make things worse for the client.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXWFB9AAoJENNXIZxhPexGN6YH/2xNQDrYyHvqIzCmSrmb7rtB
D5ZztJe3ymIeEksynETXvB+b6MfmWPXrsDGkgjcyxvd1rNYz3Z27GKvUCW/5F4YE
o5uKTPTyffET+8uBIT7cKcTdN3/tl3xgPqt+ktEKeDtFDKTFZZ7BucfYkeARKWHb
7/YbkNC76KUdm1kecjXN0FJSCgqdDerRlIjNkna3UeZslYHIrR7NgFwz0YedZ5JO
7D/lgDczbQMpMm8obKUAxoSn3KYScop4o1+2zfTT5qNIsheKhs16NWV2+K9F9D6c
BBFyG57u9fhwxmQINAuVLD2SkB2NXZDqF8DmAI9Gx0ZIgZl+oT1wTKjXNpdGIQE=
=CDGN
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160608/8dcbb6cf/attachment.key>

From squid3 at treenet.co.nz  Wed Jun  8 17:16:37 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 9 Jun 2016 05:16:37 +1200
Subject: [squid-users] Vary object loop returns
In-Reply-To: <4aa255f6-a7e1-8717-1c2e-9bbf06768139@gmail.com>
References: <1465204487541-4677832.post@n4.nabble.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
 <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
 <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>
 <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>
 <fba85af5-eb5c-52b0-4c70-eac80c47e1bc@cinbesa.com.br>
 <2411132f-7d9e-08c8-0d7e-223c5575bd1f@treenet.co.nz>
 <1830582b-25a0-b222-81b7-6ba93a270727@cinbesa.com.br>
 <685dc66d-7765-cc25-b985-baef40f63ed1@cinbesa.com.br>
 <28b284dd-726e-89ae-3747-865a648f85c2@gmail.com>
 <bfb23d44-d49b-4541-3b15-617505884d78@treenet.co.nz>
 <4aa255f6-a7e1-8717-1c2e-9bbf06768139@gmail.com>
Message-ID: <b04bcb1d-1bec-50e0-0e5f-5fe0ddb709e5@treenet.co.nz>

On 9/06/2016 5:06 a.m., Yuri Voinov wrote:
> 
> Ok, Amos.
> 
> How to correctly normalize headers?
> 
> I.e., to strip User-Agent, for example?

Normalize what and how exactly? it differs by header.

Stripping UA header from outbound traffic is done with
request_header_access. (hint: not reply_...). Though note that there are
servers out there which wil either crash, or produce an error page
rejecting the request if a UA is absent or not a browser agent string.


Right now Squid code has a class for each specially handled header.
Which parses, normalizes, and prints for output the header value(s).

Most headers unrelated to proxying (such as User-Agent) are handled as
opaque string blobs. Adding normalization for them would be difficult
right now. The best option at present would be an eCAP module.

Amos


From chip_pop at hotmail.com  Wed Jun  8 16:47:58 2016
From: chip_pop at hotmail.com (joe)
Date: Wed, 8 Jun 2016 09:47:58 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <4aa255f6-a7e1-8717-1c2e-9bbf06768139@gmail.com>
References: <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
 <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>
 <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>
 <fba85af5-eb5c-52b0-4c70-eac80c47e1bc@cinbesa.com.br>
 <2411132f-7d9e-08c8-0d7e-223c5575bd1f@treenet.co.nz>
 <1830582b-25a0-b222-81b7-6ba93a270727@cinbesa.com.br>
 <685dc66d-7765-cc25-b985-baef40f63ed1@cinbesa.com.br>
 <28b284dd-726e-89ae-3747-865a648f85c2@gmail.com>
 <bfb23d44-d49b-4541-3b15-617505884d78@treenet.co.nz>
 <4aa255f6-a7e1-8717-1c2e-9bbf06768139@gmail.com>
Message-ID: <1465404478714-4677914.post@n4.nabble.com>

deny those will help

Strict-Transport-Security
Alternate-Protocol
alternate-protocol     <--- i seen lower case duno if squid handel tha or we
shuld deny both
Alt-Svc
alt-svc
X-Firefox-Spdy



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677914.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Wed Jun  8 17:31:03 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 8 Jun 2016 23:31:03 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1465404478714-4677914.post@n4.nabble.com>
References: <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
 <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>
 <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>
 <fba85af5-eb5c-52b0-4c70-eac80c47e1bc@cinbesa.com.br>
 <2411132f-7d9e-08c8-0d7e-223c5575bd1f@treenet.co.nz>
 <1830582b-25a0-b222-81b7-6ba93a270727@cinbesa.com.br>
 <685dc66d-7765-cc25-b985-baef40f63ed1@cinbesa.com.br>
 <28b284dd-726e-89ae-3747-865a648f85c2@gmail.com>
 <bfb23d44-d49b-4541-3b15-617505884d78@treenet.co.nz>
 <4aa255f6-a7e1-8717-1c2e-9bbf06768139@gmail.com>
 <1465404478714-4677914.post@n4.nabble.com>
Message-ID: <5c00f6ab-9511-83b6-2e57-596a97752e5b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Alternate-Protocol - agreed. With both directions, for request and replies.

Alt-Svc -can be discussed.

X-Firefox-Spdy - can be discussed.


08.06.2016 22:47, joe ?????:
> deny those will help
>
> Strict-Transport-Security
> Alternate-Protocol
> alternate-protocol     <--- i seen lower case duno if squid handel tha
or we
> shuld deny both
> Alt-Svc
> alt-svc
> X-Firefox-Spdy
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677914.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXWFZXAAoJENNXIZxhPexG/gUH+gLNdGCSaS2QPjI/CJbEV8dA
PsQ3gSJOfuE/MsqAu4Cyw5/1UaHnrzA1tjVFr0yDVQUgbYETAq0SYa4/VoeWNbPY
BfCgejkTg65rWyCH+V8dHQmgpLovtuLJ9szSPJXYkN05xvjLK64RT3618NPRauXp
lATzRjmxCQJ/sg1mkqIfFhWExSnptkjdnVLq5cSvdXdczk8ebma3wF0XFsprbePR
rcxf0W8zOrwr6Mmyh9xQ56YIGslcwJLeTHpaBYhrkuPjODnS1rXZI6iJz7mROQya
IuoAecUEPSem1QDSvbTXXqkMy9sM77W1Bza2RCSQMms9kqv+oPo+44QFGY3BuXQ=
=jvED
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160608/2ca826a4/attachment.key>

From squid3 at treenet.co.nz  Wed Jun  8 17:36:17 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 9 Jun 2016 05:36:17 +1200
Subject: [squid-users] Vary object loop returns
In-Reply-To: <012e53d8-fb0c-1a75-71db-56a7a41e523a@gmail.com>
References: <1465204487541-4677832.post@n4.nabble.com>
 <d367ad4c-1f78-11ac-ce88-782981d3e583@gmail.com>
 <1465206008019-4677836.post@n4.nabble.com>
 <2bf94d39-4716-55e1-0cca-6b4ac5cca2a8@gmail.com>
 <1465216227563-4677844.post@n4.nabble.com>
 <fc1718c3-87ab-baae-9e86-0a0ab942a131@gmail.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
 <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
 <012e53d8-fb0c-1a75-71db-56a7a41e523a@gmail.com>
Message-ID: <cb2cc863-92fe-4d43-652a-a1f7510d04fb@treenet.co.nz>

On 7/06/2016 10:48 p.m., Yuri Voinov wrote:
> 
> 
> 
> 07.06.2016 16:36, Amos Jeffries ?????:
>> On 7/06/2016 8:48 p.m., Yuri Voinov wrote:
>>>
>>> 07.06.2016 4:57, Amos Jeffries ?????:
>>>> On 7/06/2016 5:55 a.m., Yuri Voinov wrote:
>>>>>
>>>>> So.
>>>>>
>>>>> Squid DOES NOT and DON'T BE support gzip. The only way to do it - use
>>>>> ecap + desupported ecap gzip adapter. Let's accept this. We can support
>>>>> gzip. With restrictions. Ok.
>>>>>
>>>>> any other compression - false. No. No way. Get out. and so on.
>>>>>
>>>>>  identity - this is uncompressed type.
>>>>>
>>>>> That's all, folks.
>>>>>
>>>>> Finally. As Joe does, we can remain only gzip and identity in
>>>>> Accept-Encoding and truncate all remaining.
>>>
>>>> Locking the entire Internet to using your personal choice of gzip
>>>> compression or none.
>>>
>>>> gzip is the slowest and more resource hungry type of compression there
>>>> is. deflate is actually faster for clients and just as widely supported.
>>> Unfortunately, Amos, no one has written any other compression algorithms
>>> support module. We have to eat what they give.
>>>
> 
>> Like I said deflate is widely available. Heiler's recent info shows that
>> lzma is becomming more visible on the public web, which should help fix
>> the one issue deflate has.
> 
>> And noone appears to be fixing the remaining issues in the Squid gzip
>> eCAP module.
> 
>> There also seems to be a big push back from browser and some server
>> vendors about compression in general. We had a fairly major fight in
>> IETF to get HTTP/2 to contain data compression at all. It is still only
>> in there as an optional extension that some are openly refusing to
>> implement.
> 
> 
>>>
>>>>>
>>>>> Without any problem. Moreover, this type of can be push to all brunches
>>>>> of squid without any problem, because of this dramatically increases
>>>>> byte HIT.
>>>
>>>> Responding with a single object to all requests makes your HIT ratio
>>>> 100% guaranteed. The clients wont like you though if all they ever see
>>>> is the same cat picture.
>>>
>>>> It sounds ridiculous when put that way, but that is what these patches
>>>> are doing for a unknown number of those "gained" HITs. See my previous
>>>> post about how none of these patches are changing the request the server
>>>> gets.
>>> But no one asked the question - why Squid in production installations
>>> has such a low hit ratio
> 
>> Yes that has been asked, even investigated. The reason(s) are many
>> complex details and small issues adding together to a big loss.
> 
>> They range from protocol things like Vary not being fine-grained enough
>> (Key header being developed fixes that), through to client behaviour
>> (Chrome sdch doubles the variant count - almost halving useful cache
>> space), to server behaviour (Apache changing Vary header).
> 
>> What your testing of joes patches is showing is that the sdch effect
>> Chrome has is probably way bigger than one would expect to be reasonable.
> 
> 
>>> that raises the question of expediency of
>>> application caching proxy. We do believe that this is a caching proxy?
>>>
>>>
>>>> You are once again sweeping asside the critical requirement of content
>>>> integrity to achieve high HIT ratio. Which is not something that I can
>>>> accept into Squid as a default action.
>>> I continue to believe that 20% is unacceptably low cache hit ratio,
>>> given the very aggressive settings and the active use of Store ID. Which
>>> brings us back to the idea of the feasibility of using the SQUID as a
> whole.
>>>
> 
>> That kind of "unacceptable" statement simply cannot be made about cache
>> HIT ratio. It is what it is. One cannot change the speed of light
>> because it takes unacceptable long to travel through space.
> Yes and no.
> 
> We're not just talking about the abstract ratio of cache hits. But,
> above all, about the measured byte hit ratio. It is who gives the
> maximum gain traffic. Even an increase in latency cache in many cases
> can be neglected. Traffic is money. Often very large sum.

You are missing my point. The place of measurement matters as much as
the traffic content to what min and max limits the ratio will appear to
have.


> 
> 
>> Two properly working caches in serial will have extremely different
>> caching ratios. The one with most direct client connections trends
>> towards 50-100% and the upstream one towards the servers will trend
>> towards zero. The total cacheable ratio is unchanged, but each cache
>> sees a different proportion of it and so shows different HIT ratios
>> relative to their clients portion.
> Sure, but not all of us can afford two cache. In most installations,

A cache in the client browser. And one in your network. Bingo two caches.

A cache in your network and a client visiting CDN hosted site. Bingo two
caches.

Average request these days goes through something like 6 different HTTP
software installations - each of which might be caching in the
end-to-end message pathway.

> only one box. And we, of course, desirable to have maximum possible
> efficiency. In addition, I am currently working on the optimization of a
> single installation with two storage arrays in order to obtain the best
> possible hit rate by only one server Squid.
> 

Cool. :-)

> 
> 
>> Also, don't forget that browser cache disk space available are
>> increasingly large as well. So their caches are growing in size and
>> taking up a larger share of the total achievable HIT ratios in recent
> years.
> Browser's cache in this case, not quite. It still is not shared.

Well. That situation is getting very fuzzy in the past few years. 'apps'
can offload their activity to a browser with caching to do their things.
So while its still one person / user the embeded advertising re-used by
each app means the browser becomes a shared cache for at least the
advertising part of the traffic. Probably also graphics tiles and the
like as well.

> 
> Which brings us to the fact that customers download the same content
> multiple times, and for a shared cache that content is unique.
> Duplication is a problem. Serious problem. Caches have become more
> content increased quantitatively. We have a huge amount of duplicate
> content, which, in many cases, is apparently identical. StoreID only
> partially solves the problem, because it requires a huge amount of
> manual work for maintenance, and continuous. For example, first I worked
> Instagram own means, then went under Akamai. URL structure has changed
> and needed to radically change the rewrite rule.

Nod. And Vary is part of the problem with duplication. That is a known
thing. But Vary is set into the bedrock of the HTTP ecosystem, there is
no changing how it works without breaking a lot of things. The choice is
only whether or not one stores its variant cloud on a case-by-case basis.


> 
> If we are at the level of application protocols to reduce the amount of
> work for maintenance of shared cache, and it will increase the
> efficiency of our work and solve a lot of problems for future changes in
> the Web.
> 

Amos


From heiler.bemerguy at cinbesa.com.br  Wed Jun  8 19:00:24 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Wed, 8 Jun 2016 16:00:24 -0300
Subject: [squid-users] Vary object loop returns
In-Reply-To: <c0c4287a-2c91-9f19-a1ae-357cf558a7c9@treenet.co.nz>
References: <1465204487541-4677832.post@n4.nabble.com>
 <1465217682486-4677851.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
 <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
 <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>
 <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>
 <fba85af5-eb5c-52b0-4c70-eac80c47e1bc@cinbesa.com.br>
 <2411132f-7d9e-08c8-0d7e-223c5575bd1f@treenet.co.nz>
 <1830582b-25a0-b222-81b7-6ba93a270727@cinbesa.com.br>
 <685dc66d-7765-cc25-b985-baef40f63ed1@cinbesa.com.br>
 <c0c4287a-2c91-9f19-a1ae-357cf558a7c9@treenet.co.nz>
Message-ID: <e1757c28-a8b7-a199-2861-457f311d134a@cinbesa.com.br>


Of course it would be nice if we could configure which Vary elements we 
wanna store/use. But I'm afraid store_miss won't do this.

With this conf you're not caching any object that has any Vary elements 
that's not "accept-encoding", right?


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751

Em 08/06/2016 13:58, Amos Jeffries escreveu:
> I think your patch is identical to hard-coding the config:
>
>   acl vary rep_header Vary -i .
>   acl varyAE rep_header Vary -i ^accept-encoding$
>   store_miss deny vary !varyAE
>
> It is not reasonable to hard-code these things in a widely used generic
> HTTP proxy like Squid. If it can be configured do it that way, if it
> can't then config needs to be added.
>
> Amos
>



From sebelk at gmail.com  Wed Jun  8 20:05:49 2016
From: sebelk at gmail.com (Sergio Belkin)
Date: Wed, 8 Jun 2016 17:05:49 -0300
Subject: [squid-users] Somewhat OT: Content Filter with https
Message-ID: <CABZC=5zAyDEYtiHVzVe_Vo91h7xjXCQyV-9id4mKwuHQ3BeFJQ@mail.gmail.com>

Hi,

I've been using a few years ago squid+dansguardian. But nowadays, DG is not
maintained anymore. I know that exists squidGuard, ufdbGuard, and
e2guardian.

Features should be:

- Blocking https url's
- Not need of interception..... is that possible?
- Simple for configure  and good perfomance

What do you recommend me?

Thanks in advance!

-- 
--
Sergio Belkin
LPIC-2 Certified - http://www.lpi.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160608/a4385dac/attachment.htm>

From yvoinov at gmail.com  Wed Jun  8 20:27:26 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 9 Jun 2016 02:27:26 +0600
Subject: [squid-users] Somewhat OT: Content Filter with https
In-Reply-To: <CABZC=5zAyDEYtiHVzVe_Vo91h7xjXCQyV-9id4mKwuHQ3BeFJQ@mail.gmail.com>
References: <CABZC=5zAyDEYtiHVzVe_Vo91h7xjXCQyV-9id4mKwuHQ3BeFJQ@mail.gmail.com>
Message-ID: <bc5657a6-47fd-77a1-3b35-0a7c8bfe2f23@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
AFAIK ufdbguard has no alternative.


09.06.2016 2:05, Sergio Belkin ?????:
> Hi,
>
> I've been using a few years ago squid+dansguardian. But nowadays, DG
is not maintained anymore. I know that exists squidGuard, ufdbGuard, and
e2guardian.
>
> Features should be:
>
> - Blocking https url's
> - Not need of interception..... is that possible?
> - Simple for configure  and good perfomance
>
> What do you recommend me?
>
> Thanks in advance!
>
> --
> --
> Sergio Belkin
> LPIC-2 Certified - http://www.lpi.org
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXWH+uAAoJENNXIZxhPexGVUsH/0WDsdWb4F88uJJ0RfJBtPb9
azadz0FYNmAOpmYGlLRpSLIQJBa+i0nEmf59hIBx+nmnuAzfiPDoVhZk+xmrI+ZC
deD4HEABBLPjg33YiFFDAq4EoYosg2GD8Jel3Kjt6cCmkaZh8Pq2fESwqSo5s+DL
VEKDLLQcJgi75/MZI/geScfgNY5zDyGMddvi07VAtY+qBhcUclprlycI6JJGGCeS
26ylM2OUr5KOUAXbKNOPec1FdvUuYIcE7rJGEK2ouvBkx+4NZTd5SBsCWyzj3w86
VcaF0q84MbV7ecr+E9/qDvyE5RbqZcQKvxuxR2DSpVdJp6kEctGvmks3CHRmjxs=
=QZG5
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160609/028f8b76/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160609/028f8b76/attachment.key>

From marcus.kool at urlfilterdb.com  Wed Jun  8 20:37:15 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 8 Jun 2016 17:37:15 -0300
Subject: [squid-users] Somewhat OT: Content Filter with https
In-Reply-To: <CABZC=5zAyDEYtiHVzVe_Vo91h7xjXCQyV-9id4mKwuHQ3BeFJQ@mail.gmail.com>
References: <CABZC=5zAyDEYtiHVzVe_Vo91h7xjXCQyV-9id4mKwuHQ3BeFJQ@mail.gmail.com>
Message-ID: <575881FB.4010907@urlfilterdb.com>



On 06/08/2016 05:05 PM, Sergio Belkin wrote:
> Hi,
>
> I've been using a few years ago squid+dansguardian. But nowadays, DG is not maintained anymore. I know that exists squidGuard, ufdbGuard, and e2guardian.
>
> Features should be:
>
> - Blocking https url's

Blocking HTTPS URLs is easy.
However, providing an understandable message to the end user is a challenge.
This is because HTTPS, is designed to not be interfered with, and if a proxy interferes, a browser will display errors like "wrong certificate for this site".
If you want user-friendly error messages like "This site is blocked because ..." instead of the certificate errors,
one needs sslbump with peek+bump for all blocked sites. This is doable but not straightforward.

> - Not need of interception..... is that possible?

It depends.  If you support smartphones, you most likely need interception since not all apps can be configured to use a proxy.
With only desktops, interception is not required but you may need to install the Squid CA certificate on all desktops.

> - Simple for configure  and good perfomance

squidGuard is also not maintained for a long time so not recommendable.
ufdbGuard has regular updates, can be used with free and commercial URL databases, and is 3x faster than squidGuard.

Note that I am the author of ufdbGuard so you may find me biased :-)

Marcus

> What do you recommend me?
>
> Thanks in advance!
>
> --
> --
> Sergio Belkin
> LPIC-2 Certified - http://www.lpi.org


From yvoinov at gmail.com  Wed Jun  8 20:40:07 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 9 Jun 2016 02:40:07 +0600
Subject: [squid-users] Somewhat OT: Content Filter with https
In-Reply-To: <575881FB.4010907@urlfilterdb.com>
References: <CABZC=5zAyDEYtiHVzVe_Vo91h7xjXCQyV-9id4mKwuHQ3BeFJQ@mail.gmail.com>
 <575881FB.4010907@urlfilterdb.com>
Message-ID: <c7b29740-a719-396e-8144-4235c894ec8e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I confirm.

I've replaced squidGuard with ufdbguard significantly long time ago and
uses it in production. With SSL Bump.

It's very fast, has not unlimited memory consumption. And - this is
important - has client-server model.


09.06.2016 2:37, Marcus Kool ?????:
>
>
> On 06/08/2016 05:05 PM, Sergio Belkin wrote:
>> Hi,
>>
>> I've been using a few years ago squid+dansguardian. But nowadays, DG
is not maintained anymore. I know that exists squidGuard, ufdbGuard, and
e2guardian.
>>
>> Features should be:
>>
>> - Blocking https url's
>
> Blocking HTTPS URLs is easy.
> However, providing an understandable message to the end user is a
challenge.
> This is because HTTPS, is designed to not be interfered with, and if a
proxy interferes, a browser will display errors like "wrong certificate
for this site".
> If you want user-friendly error messages like "This site is blocked
because ..." instead of the certificate errors,
> one needs sslbump with peek+bump for all blocked sites. This is doable
but not straightforward.
>
>> - Not need of interception..... is that possible?
>
> It depends.  If you support smartphones, you most likely need
interception since not all apps can be configured to use a proxy.
> With only desktops, interception is not required but you may need to
install the Squid CA certificate on all desktops.
>
>> - Simple for configure  and good perfomance
>
> squidGuard is also not maintained for a long time so not recommendable.
> ufdbGuard has regular updates, can be used with free and commercial
URL databases, and is 3x faster than squidGuard.
>
> Note that I am the author of ufdbGuard so you may find me biased :-)
>
> Marcus
>
>> What do you recommend me?
>>
>> Thanks in advance!
>>
>> --
>> --
>> Sergio Belkin
>> LPIC-2 Certified - http://www.lpi.org
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXWIKmAAoJENNXIZxhPexGbFsH/jZCTyhl1HqirZfMf9X1F+c7
Cx1c3BzdCw3qRSMP9LW52Uj0Fw9MLYTQ6Pe/HNdJu2atvLU9OOXmXHNDd4NSjL54
qrJj/HHXrRt9PVp9GnGkgFKj9iNpUN1H44IanjMcfyx1h9hfJ4vbjhYnqgnunieT
H2yLfycu0oMnYtn7ju9T7Jp7GgLkNm9JFvJN0EKKCqB7HtB7eQjmACj1dUhP+pGi
R7wsuGov+lf0oVutxeuzvIsvbuXLdcsQIZB+eAfOuzTTai5yqrR/IqaZMAgubjeN
CnmAHtcbRitBCB18YGx0PcWJSdTu1X42Hmc2K+slwMv1KYi19CZe5r88+narN3w=
=YDWa
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160609/eeee866e/attachment.key>

From webmaster at squidblacklist.org  Wed Jun  8 20:50:43 2016
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Wed, 8 Jun 2016 15:50:43 -0500
Subject: [squid-users] Somewhat OT: Content Filter with https
In-Reply-To: <c7b29740-a719-396e-8144-4235c894ec8e@gmail.com>
References: <CABZC=5zAyDEYtiHVzVe_Vo91h7xjXCQyV-9id4mKwuHQ3BeFJQ@mail.gmail.com>
 <575881FB.4010907@urlfilterdb.com>
 <c7b29740-a719-396e-8144-4235c894ec8e@gmail.com>
Message-ID: <3da555c4-b48a-16db-7e7e-c8bbeaf99b57@squidblacklist.org>

We have many satisfied subscribers who use our blacklists with ufdbguard 
as their primary content filter and they seem to be quite satisfied.

Of course we are going to promote our services, but to be forthright 
with a response,

UfdbGuard seems to have gained quite a lot of traction and there is a 
reason for that.


And I would agree that should be the best choice.

-- 
Signed,

Benjamin E. Nichols
http://www.squidblacklist.org

1-405-397-1360




From sebelk at gmail.com  Wed Jun  8 20:54:04 2016
From: sebelk at gmail.com (Sergio Belkin)
Date: Wed, 8 Jun 2016 17:54:04 -0300
Subject: [squid-users] Somewhat OT: Content Filter with https
In-Reply-To: <575881FB.4010907@urlfilterdb.com>
References: <CABZC=5zAyDEYtiHVzVe_Vo91h7xjXCQyV-9id4mKwuHQ3BeFJQ@mail.gmail.com>
 <575881FB.4010907@urlfilterdb.com>
Message-ID: <CABZC=5w3C-cE6f1Du1a4BMYqJY1g2G=KVUhK-31zoNCjSzEDNw@mail.gmail.com>

2016-06-08 17:37 GMT-03:00 Marcus Kool <marcus.kool at urlfilterdb.com>:

>
>
> On 06/08/2016 05:05 PM, Sergio Belkin wrote:
>
>> Hi,
>>
>> I've been using a few years ago squid+dansguardian. But nowadays, DG is
>> not maintained anymore. I know that exists squidGuard, ufdbGuard, and
>> e2guardian.
>>
>> Features should be:
>>
>> - Blocking https url's
>>
>
> Blocking HTTPS URLs is easy.
> However, providing an understandable message to the end user is a
> challenge.
> This is because HTTPS, is designed to not be interfered with, and if a
> proxy interferes, a browser will display errors like "wrong certificate for
> this site".
> If you want user-friendly error messages like "This site is blocked
> because ..." instead of the certificate errors,
> one needs sslbump with peek+bump for all blocked sites. This is doable but
> not straightforward.
>


Yup, you've got it.


>
> - Not need of interception..... is that possible?
>>
>
> It depends.  If you support smartphones, you most likely need interception
> since not all apps can be configured to use a proxy.
> With only desktops, interception is not required but you may need to
> install the Squid CA certificate on all desktops.
>


And what about authentication? Can a user authenticate to Active Directory
at logon time to use squid?



>
> - Simple for configure  and good perfomance
>>
>
> squidGuard is also not maintained for a long time so not recommendable.
> ufdbGuard has regular updates, can be used with free and commercial URL
> databases, and is 3x faster than squidGuard.
>
> Note that I am the author of ufdbGuard so you may find me biased :-)
>


:-) OK, thanks for your sincerity


>
> Marcus
>
> What do you recommend me?
>>
>> Thanks in advance!
>>
>> --
>> --
>> Sergio Belkin
>> LPIC-2 Certified - http://www.lpi.org
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
--
Sergio Belkin
LPIC-2 Certified - http://www.lpi.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160608/b6a18ff5/attachment.htm>

From marcus.kool at urlfilterdb.com  Wed Jun  8 22:07:21 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 8 Jun 2016 19:07:21 -0300
Subject: [squid-users] Somewhat OT: Content Filter with https
In-Reply-To: <CABZC=5w3C-cE6f1Du1a4BMYqJY1g2G=KVUhK-31zoNCjSzEDNw@mail.gmail.com>
References: <CABZC=5zAyDEYtiHVzVe_Vo91h7xjXCQyV-9id4mKwuHQ3BeFJQ@mail.gmail.com>
 <575881FB.4010907@urlfilterdb.com>
 <CABZC=5w3C-cE6f1Du1a4BMYqJY1g2G=KVUhK-31zoNCjSzEDNw@mail.gmail.com>
Message-ID: <57589719.8040206@urlfilterdb.com>



On 06/08/2016 05:54 PM, Sergio Belkin wrote:
>
>         - Not need of interception..... is that possible?
>
>     It depends.  If you support smartphones, you most likely need interception since not all apps can be configured to use a proxy.
>     With only desktops, interception is not required but you may need to install the Squid CA certificate on all desktops.
>
> And what about authentication? Can a user authenticate to Active Directory at logon time to use squid?

With interception or regular proxy mode ?

Amos may correct me if I am wrong, but I understood that authentication is not compatible with interception.

Marcus


From eliezer at ngtech.co.il  Wed Jun  8 22:09:22 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 9 Jun 2016 01:09:22 +0300
Subject: [squid-users] Somewhat OT: Content Filter with https
In-Reply-To: <CABZC=5zAyDEYtiHVzVe_Vo91h7xjXCQyV-9id4mKwuHQ3BeFJQ@mail.gmail.com>
References: <CABZC=5zAyDEYtiHVzVe_Vo91h7xjXCQyV-9id4mKwuHQ3BeFJQ@mail.gmail.com>
Message-ID: <003501d1c1d2$69472c20$3bd58460$@ngtech.co.il>

Hey Sergio,

 

There are couple approaches to content filtering in the Linux world and in other spaces.

Squid is open source and gives a lot but there are other ideas and ways to perform content filtering.

Squid was designed for caching and does things in a specific way while other solution might give a feature that would work "without interception".

On http it is doable to perform filtering in a very efficient way that is similar to Squid's PEEK and SPLICE but there is a need in some level of Interception in one step or another to perform the actual "block" operation.

I do not know about Open Source products that offers everything and it is very simple to understand why.

What I know about are 

-          Squid + external tools(such as SquidGuard, ufdbguard, others)

-          Ntop layer 7 filtering

-          Custom DPI iptables modules

-          NFQUEUE based IPS\IDS which can act as a url filtering engine

 

Consider that if you require only filtering and not caching then you can get very high performance from many applications.

The fact that Squid was designed for Caching doesn't mean that you need to use it.
Also there are couple cases which caching will hold your line and users speed.

 

The best case scenario would be to not Intercept the traffic into squid while in many cases it is not possible.

 

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Sergio Belkin
Sent: Wednesday, June 8, 2016 11:06 PM
To: Squid Users
Subject: [squid-users] Somewhat OT: Content Filter with https

 

Hi,

I've been using a few years ago squid+dansguardian. But nowadays, DG is not maintained anymore. I know that exists squidGuard, ufdbGuard, and e2guardian.

Features should be:

 

- Blocking https url's

- Not need of interception..... is that possible?

- Simple for configure  and good perfomance

What do you recommend me?

Thanks in advance!



-- 

--
Sergio Belkin
LPIC-2 Certified - http://www.lpi.org

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160609/610e06fa/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image003.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160609/610e06fa/attachment.png>

From sebelk at gmail.com  Wed Jun  8 22:41:41 2016
From: sebelk at gmail.com (Sergio Belkin)
Date: Wed, 8 Jun 2016 19:41:41 -0300
Subject: [squid-users] Somewhat OT: Content Filter with https
In-Reply-To: <57589719.8040206@urlfilterdb.com>
References: <CABZC=5zAyDEYtiHVzVe_Vo91h7xjXCQyV-9id4mKwuHQ3BeFJQ@mail.gmail.com>
 <575881FB.4010907@urlfilterdb.com>
 <CABZC=5w3C-cE6f1Du1a4BMYqJY1g2G=KVUhK-31zoNCjSzEDNw@mail.gmail.com>
 <57589719.8040206@urlfilterdb.com>
Message-ID: <CABZC=5wp5fwC+4pinB5Wu2GARKa8S4JFS2HyTwpvn3z6NV6JUA@mail.gmail.com>

2016-06-08 19:07 GMT-03:00 Marcus Kool <marcus.kool at urlfilterdb.com>:

>
>
> On 06/08/2016 05:54 PM, Sergio Belkin wrote:
>
>>
>>         - Not need of interception..... is that possible?
>>
>>     It depends.  If you support smartphones, you most likely need
>> interception since not all apps can be configured to use a proxy.
>>     With only desktops, interception is not required but you may need to
>> install the Squid CA certificate on all desktops.
>>
>> And what about authentication? Can a user authenticate to Active
>> Directory at logon time to use squid?
>>
>
> With interception or regular proxy mode ?
>


I am talking about with interception


>
> Amos may correct me if I am wrong, but I understood that authentication is
> not compatible with interception.
>
> Marcus
>
>

-- 
--
Sergio Belkin
LPIC-2 Certified - http://www.lpi.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160608/7addee0d/attachment.htm>

From sebelk at gmail.com  Wed Jun  8 22:53:05 2016
From: sebelk at gmail.com (Sergio Belkin)
Date: Wed, 8 Jun 2016 19:53:05 -0300
Subject: [squid-users] Peek'n Splice (ssl_bump) and authentication
 Somewhat OT: Content Filter with https
Message-ID: <CABZC=5y8rWTheVxXKXy7k5us3uuixcxGz2ay=uYKPpjbNvK3xA@mail.gmail.com>

2016-06-08 19:09 GMT-03:00 Eliezer Croitoru <eliezer at ngtech.co.il>:

> Hey Sergio,
>
>
>
> There are couple approaches to content filtering in the Linux world and in
> other spaces.
>
> Squid is open source and gives a lot but there are other ideas and ways to
> perform content filtering.
>
> Squid was designed for caching and does things in a specific way while
> other solution might give a feature that would work "without interception".
>
> On http it is doable to perform filtering in a very efficient way that is
> similar to Squid's PEEK and SPLICE but there is a need in some level of
> Interception in one step or another to perform the actual "block" operation.
>
> I do not know about Open Source products that offers everything and it is
> very simple to understand why.
>
> What I know about are
>
> -          Squid + external tools(such as SquidGuard, ufdbguard, others)
>
> -          Ntop layer 7 filtering
>
> -          Custom DPI iptables modules
>
> -          NFQUEUE based IPS\IDS which can act as a url filtering engine
>
>
>
> Consider that if you require only filtering and not caching then you can
> get very high performance from many applications.
>
> The fact that Squid was designed for Caching doesn't mean that you need to
> use it.
> Also there are couple cases which caching will hold your line and users
> speed.
>
>
>
> The best case scenario would be to not Intercept the traffic into squid
> while in many cases it is not possible.
>
>
>
> Eliezer
>
>
>
> ----
>
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
>
> rg <http://www.lpi.org>
>


Thanks Eliezer, good summary. I've changed the subject to reflect better
the issue. As far I undestand from documention one can bump https only by
interception.
But what about if one Windows user login against an Active Directory, will
the authenticacion work to use the proxy?

I mean, what I'd want is:

- Only users of an Active Directory can use the proxy
- Block certains urls

Is that possible with squid+ufwdbguard?

Or should I use other tools/ways just like you mentioned?

Thanks in advance!

-- 
--
Sergio Belkin
LPIC-2 Certified - http://www.lpi.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160608/ecb5b8f4/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image003.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160608/ecb5b8f4/attachment.png>

From ahmed.zaeem at netstream.ps  Wed Jun  8 22:56:43 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Thu, 9 Jun 2016 01:56:43 +0300
Subject: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot bind
	socket FD 782 to [::]: (2) No such file or directory
Message-ID: <8B8C7545-E090-4014-AA00-7FCD55FE04C9@netstream.ps>

here is error when i run squid :
2016/06/08 18:48:29 kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory
2016/06/08 18:48:29 kid1| HTCP Disabled.
2016/06/08 18:48:29 kid1| Squid plugin modules loaded: 0
2016/06/08 18:48:29 kid1| Adaptation support is off.
2016/06/08 18:48:29 kid1| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory


I?m sure if i use it on centos 6 it work?...

but on centos 7 with same compile options it don?t allow me to use workers SMP

any help ?


Squid Cache: Version 3.5.2
Service Name: squid
configure options:  '--prefix=/usr' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc' '--enable-cachemgr-hostname=Ahmad-Allzaeem' '--localstatedir=/var' '--libexecdir=/lib/squid' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm' '--enable-digest-auth-helpers=ldap,password' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' '' '--with-large-files' '--with-default-user=squid' --with-openssl' '--enable-snmp' '--with-included-ltdl' '--disable-arch-native'
[root at localhost ~]# 




thank   you 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160609/f4ec85bb/attachment.htm>

From marcus.kool at urlfilterdb.com  Wed Jun  8 23:30:08 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 8 Jun 2016 20:30:08 -0300
Subject: [squid-users] Peek'n Splice (ssl_bump) and authentication
 Somewhat OT: Content Filter with https
In-Reply-To: <CABZC=5y8rWTheVxXKXy7k5us3uuixcxGz2ay=uYKPpjbNvK3xA@mail.gmail.com>
References: <CABZC=5y8rWTheVxXKXy7k5us3uuixcxGz2ay=uYKPpjbNvK3xA@mail.gmail.com>
Message-ID: <5758AA80.7090905@urlfilterdb.com>



On 06/08/2016 07:53 PM, Sergio Belkin wrote:
>
> Thanks Eliezer, good summary. I've changed the subject to reflect better the issue. As far I undestand from documention one can bump https only by interception.

No.  ssl-bump works very well with regular proxy mode, i.e. the browsers configure the address and port of the proxy or use PAC.

> But what about if one Windows user login against an Active Directory, will the authenticacion work to use the proxy?
>
> I mean, what I'd want is:
>
> - Only users of an Active Directory can use the proxy

In regular proxy mode, authentication and peek+splice works fine.
Note that peek+splice does not require Squid CA certificates on the clients.

> - Block certains urls
>
> Is that possible with squid+ufwdbguard?

ufdbGuard works always, independent if Squid uses interception or not.
The issue is the messages that a browser displays for the end user (see earlier email).

Marcus


From eliezer at ngtech.co.il  Thu Jun  9 00:11:34 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 9 Jun 2016 03:11:34 +0300
Subject: [squid-users] Peek'n Splice (ssl_bump) and authentication
	Somewhat OT: Content Filter with https
In-Reply-To: <CABZC=5y8rWTheVxXKXy7k5us3uuixcxGz2ay=uYKPpjbNvK3xA@mail.gmail.com>
References: <CABZC=5y8rWTheVxXKXy7k5us3uuixcxGz2ay=uYKPpjbNvK3xA@mail.gmail.com>
Message-ID: <009201d1c1e3$7b67c430$72374c90$@ngtech.co.il>

Hey Sergio,

 

It depends on couple aspects of the setup.

The basic rule is that in the case you require authentication you are required to use a configured proxy and without Interception.

For SSL BUMP to work you need the clients to either access the proxy directly or to Intercept their connections.(Interception is not a must..) 

If your setup doesn't have terminal servers for multiple clients then you can use an IP to USER authentication using a variety of options such as:

-          Web Authentication portal

-          DHCP level Authentication

-          Radius based Authentication

-          Couple others..

(all the above are based on IP level restrictions)

 

HTTPS and HTTP filtering are a bit different but if you have a basic "catch all" rule it would be much simpler to move on from there with the logic and implementation.

Specifically for HTTPS connections if you have a list of sites that you don't need to bump and you will be using a directly configured proxy(non intercept) then you would be able to minimize the noise that comes with fake certificates generation.


My suggestion in general is to first declare squid as a "first" trial and testing stage for a solution.

For some places Squid's breaking web-sockets are an overhead that cannot be tolerated while in other places it is acceptable as a security breach blocker.

If the place is not huge(200+ users) then I would start with a simple forward proxy with SSL BUMP but in a splice first(since peek and splice might not be needed due to the clients stating their target Domain Name) and later add the bump step.

It will help you to try and see how the proxy takes the load(with filtering but without caching).
Then move on to the next step of authentication, maybe Kerberos or if "transparent" authentication is required but if not then a simple LDAP based one.

If SquidGuard functionality is good for you then use it.

If not then ufdbguard or any other solution that is in your mind.

I tend to not publish my work too much here but if you want to take a peek and see how it works for you then:
http://new.ngtech.co.il/squidblocker_en.html 

 

I also think that others work such as:

-          http://www.quintolabs.com/  Diladele

-          https://www.clearos.com/

-          https://www.censornet.com/

is worth mentioning due to their high quality.( I have tested some of them myself)

 

About ufdbguard, it's not doing authentication but only url filtering as far as I know.

Squid's way of handling authentication is one and it's not on the same "channel" as filtering but an ICAP service can do that too.

 

Hope It Helps,

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: Sergio Belkin [mailto:sebelk at gmail.com] 
Sent: Thursday, June 9, 2016 1:53 AM
To: Eliezer Croitoru
Cc: Squid Users
Subject: Re: Peek'n Splice (ssl_bump) and authentication [squid-users] Somewhat OT: Content Filter with https

 

2016-06-08 19:09 GMT-03:00 Eliezer Croitoru <eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il> >:

Hey Sergio,

 

There are couple approaches to content filtering in the Linux world and in other spaces.

Squid is open source and gives a lot but there are other ideas and ways to perform content filtering.

Squid was designed for caching and does things in a specific way while other solution might give a feature that would work "without interception".

On http it is doable to perform filtering in a very efficient way that is similar to Squid's PEEK and SPLICE but there is a need in some level of Interception in one step or another to perform the actual "block" operation.

I do not know about Open Source products that offers everything and it is very simple to understand why.

What I know about are 

-          Squid + external tools(such as SquidGuard, ufdbguard, others)

-          Ntop layer 7 filtering

-          Custom DPI iptables modules

-          NFQUEUE based IPS\IDS which can act as a url filtering engine

 

Consider that if you require only filtering and not caching then you can get very high performance from many applications.

The fact that Squid was designed for Caching doesn't mean that you need to use it.
Also there are couple cases which caching will hold your line and users speed.

 

The best case scenario would be to not Intercept the traffic into squid while in many cases it is not possible.

 

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il> 



 

 

rg <http://www.lpi.org> 

 

Thanks Eliezer, good summary. I've changed the subject to reflect better the issue. As far I undestand from documention one can bump https only by interception. 

But what about if one Windows user login against an Active Directory, will the authenticacion work to use the proxy?

I mean, what I'd want is:

- Only users of an Active Directory can use the proxy

- Block certains urls

Is that possible with squid+ufwdbguard?

Or should I use other tools/ways just like you mentioned?

Thanks in advance!



-- 

--
Sergio Belkin
LPIC-2 Certified - http://www.lpi.org

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160609/319b1c51/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image003.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160609/319b1c51/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image004.png
Type: image/png
Size: 11317 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160609/319b1c51/attachment-0001.png>

From eliezer at ngtech.co.il  Thu Jun  9 00:14:10 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 9 Jun 2016 03:14:10 +0300
Subject: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot
	bind	socket FD 782 to [::]: (2) No such file or directory
In-Reply-To: <8B8C7545-E090-4014-AA00-7FCD55FE04C9@netstream.ps>
References: <8B8C7545-E090-4014-AA00-7FCD55FE04C9@netstream.ps>
Message-ID: <00a601d1c1e3$d8bd8110$8a388330$@ngtech.co.il>

Hey Ahmed,

 

Have you tried my RPMs for CentOS 7?

The latest version is 3.5.19 which is far more advanced then 3.5.2 and it works for me..

This issue you mentioned has lots of references in the mailing list history.

I assume it's a simple issue.

If you can try my RPMs and verify that you get the same error with them I will try to see if I can reproduce the issue.

 

Eliezer

 

----

Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of --Ahmad--
Sent: Thursday, June 9, 2016 1:57 AM
To: Squid Users
Subject: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory

 

here is error when i run squid :

2016/06/08 18:48:29 kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory

2016/06/08 18:48:29 kid1| HTCP Disabled.

2016/06/08 18:48:29 kid1| Squid plugin modules loaded: 0

2016/06/08 18:48:29 kid1| Adaptation support is off.

2016/06/08 18:48:29 kid1| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory

 

 

I?m sure if i use it on centos 6 it work?...

 

but on centos 7 with same compile options it don?t allow me to use workers SMP

 

any help ?

 

 

Squid Cache: Version 3.5.2

Service Name: squid

configure options:  '--prefix=/usr' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc' '--enable-cachemgr-hostname=Ahmad-Allzaeem' '--localstatedir=/var' '--libexecdir=/lib/squid' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm' '--enable-digest-auth-helpers=ldap,password' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' '' '--with-large-files' '--with-default-user=squid' --with-openssl' '--enable-snmp' '--with-included-ltdl' '--disable-arch-native'

[root at localhost ~]# 

 

 

 

 

thank   you 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160609/65a48548/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11295 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160609/65a48548/attachment.png>

From romulo at hscbrasil.com.br  Thu Jun  9 02:07:12 2016
From: romulo at hscbrasil.com.br (Romulo Boschetti)
Date: Wed, 8 Jun 2016 23:07:12 -0300 (BRT)
Subject: [squid-users] Somewhat OT: Content Filter with https
In-Reply-To: <CABZC=5zAyDEYtiHVzVe_Vo91h7xjXCQyV-9id4mKwuHQ3BeFJQ@mail.gmail.com>
Message-ID: <1031001645.130.1465438032516.JavaMail.root@hscbrasil.com.br>



HSC ISS FREE 


www.issfree.com 


;-) 


__________________________________________________________________ 
R?mulo Giordani Boschetti 
IT Analyst - HSC Brasil 

telefone 55 (51) 3 216-7007 ? Porto Alegre 
telefone 55 (11) 3522-8191 ? S?o Paulo 

fax : 55 (51) 3 216-7001 
site: www.hscbrasil.com.br 
email: romulo at hscbrasil.com.br 
__________________________________________________________________ 

_______________________________________________ ___________________ 
----- Mensagem original -----

De: "Sergio Belkin" <sebelk at gmail.com> 
Para: "Squid Users" <squid-users at squid-cache.org> 
Enviadas: Quarta-feira, 8 de Junho de 2016 17:05:49 
Assunto: [squid-users] Somewhat OT: Content Filter with https 









Hi, 

I've been using a few years ago squid+dansguardian. But nowadays, DG is not maintained anymore. I know that exists squidGuard, ufdbGuard, and e2guardian. 

Features should be: 


- Blocking https url's 
- Not need of interception..... is that possible? 
- Simple for configure and good perfomance 

What do you recommend me? 

Thanks in advance! 














-- 




-- 
Sergio Belkin 
LPIC-2 Certified - http://www.lpi.org 
_______________________________________________ 
squid-users mailing list 
squid-users at lists.squid-cache.org 
http://lists.squid-cache.org/listinfo/squid-users 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160608/f73337c5/attachment.htm>

From squid3 at treenet.co.nz  Thu Jun  9 04:02:00 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 9 Jun 2016 16:02:00 +1200
Subject: [squid-users] Vary object loop returns
In-Reply-To: <e1757c28-a8b7-a199-2861-457f311d134a@cinbesa.com.br>
References: <1465204487541-4677832.post@n4.nabble.com>
 <2207fae1-8e1a-a44f-ccf1-381fe5e2bafa@gmail.com>
 <1465222217407-4677854.post@n4.nabble.com>
 <dd97f0b1-0b43-11e9-d25b-41014f7e3863@gmail.com>
 <1465223238767-4677856.post@n4.nabble.com>
 <5f5442a4-6090-a72f-0ada-37760c9f4efb@gmail.com>
 <a30f68e7-65cf-5aea-a741-d45d542dadfe@cinbesa.com.br>
 <54fa905a-a761-fe7e-2393-67225fc60daf@gmail.com>
 <cbbcbf1f-ad64-723e-75ea-4a82de2c2174@treenet.co.nz>
 <a916acdb-30c9-8f85-624c-ba31ed8eb829@gmail.com>
 <f81cd644-5458-5eec-70e4-c8ad8364c8cb@treenet.co.nz>
 <62bf3051-6495-30a0-e4ee-4d4f7ea750a0@gmail.com>
 <d583f35d-98a6-14b6-976f-a9b0909f48ad@cinbesa.com.br>
 <fba85af5-eb5c-52b0-4c70-eac80c47e1bc@cinbesa.com.br>
 <2411132f-7d9e-08c8-0d7e-223c5575bd1f@treenet.co.nz>
 <1830582b-25a0-b222-81b7-6ba93a270727@cinbesa.com.br>
 <685dc66d-7765-cc25-b985-baef40f63ed1@cinbesa.com.br>
 <c0c4287a-2c91-9f19-a1ae-357cf558a7c9@treenet.co.nz>
 <e1757c28-a8b7-a199-2861-457f311d134a@cinbesa.com.br>
Message-ID: <5b862790-549a-8fb3-6dc1-48af4beebabb@treenet.co.nz>

On 9/06/2016 7:00 a.m., Heiler Bemerguy wrote:
> 
> Of course it would be nice if we could configure which Vary elements we
> wanna store/use. But I'm afraid store_miss won't do this.
> 

Proxy does not get to pick and choose what algorithm the server already
used for producing the variant. Vary does not tell what field-values
were significant, only the header name.

It's like eugenics. Possible to round people up and kill off everyone
with a certain hair color. But you cant rewind time and make their
parents decide not to have children. Clear?


> With this conf you're not caching any object that has any Vary elements
> that's not "accept-encoding", right?
> 

Correct.

Amos



From ahmed.zaeem at netstream.ps  Thu Jun  9 07:55:20 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Thu, 9 Jun 2016 10:55:20 +0300
Subject: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot
	bind	socket FD 782 to [::]: (2) No such file or directory
In-Reply-To: <00a601d1c1e3$d8bd8110$8a388330$@ngtech.co.il>
References: <8B8C7545-E090-4014-AA00-7FCD55FE04C9@netstream.ps>
 <00a601d1c1e3$d8bd8110$8a388330$@ngtech.co.il>
Message-ID: <43CF45E5-FA7D-432D-96EF-DA8DEA443667@netstream.ps>

hi Mr elieizer

i already check the mailing list  before i post here , but no luck with me .


i don?t think its a permissions issue 


i have the file /var/run/squid is missing 

and  there is /var/run/squid.pid

and it has the squid permissions 


kindly can you point to me  if i figure it out using compile options ? or from the os side ?


thank you 
> On Jun 9, 2016, at 3:14 AM, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> 
> Hey Ahmed,
>  
> Have you tried my RPMs for CentOS 7?
> The latest version is 3.5.19 which is far more advanced then 3.5.2 and it works for me..
> This issue you mentioned has lots of references in the mailing list history.
> I assume it's a simple issue.
> If you can try my RPMs and verify that you get the same error with them I will try to see if I can reproduce the issue.
>  
> Eliezer
>  
> ----
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>
> <image001.png>
>  
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of --Ahmad--
> Sent: Thursday, June 9, 2016 1:57 AM
> To: Squid Users
> Subject: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory
>  
> here is error when i run squid :
> 2016/06/08 18:48:29 kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory
> 2016/06/08 18:48:29 kid1| HTCP Disabled.
> 2016/06/08 18:48:29 kid1| Squid plugin modules loaded: 0
> 2016/06/08 18:48:29 kid1| Adaptation support is off.
> 2016/06/08 18:48:29 kid1| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory
>  
>  
> I?m sure if i use it on centos 6 it work?...
>  
> but on centos 7 with same compile options it don?t allow me to use workers SMP
>  
> any help ?
>  
>  
> Squid Cache: Version 3.5.2
> Service Name: squid
> configure options:  '--prefix=/usr' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc' '--enable-cachemgr-hostname=Ahmad-Allzaeem' '--localstatedir=/var' '--libexecdir=/lib/squid' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm' '--enable-digest-auth-helpers=ldap,password' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' '' '--with-large-files' '--with-default-user=squid' --with-openssl' '--enable-snmp' '--with-included-ltdl' '--disable-arch-native'
> [root at localhost ~]# 
>  
>  
>  
>  
> thank   you 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160609/f51e9f51/attachment.htm>

From asakura at ioc.dnp.co.jp  Thu Jun  9 08:09:48 2016
From: asakura at ioc.dnp.co.jp (asakura at ioc.dnp.co.jp)
Date: Thu, 09 Jun 2016 17:09:48 +0900 (JST)
Subject: [squid-users] squid-3.5.19 crash(Segment Violation)
Message-ID: <20160609.170948.1000278277145506719.asakura@ioc.dnp.co.jp>

Hello,

I need help about squid-3.5.19 crash(Segment Violation)

I posted question at 2016 March(attached last sentence)
And at last month, I upgrade squid 3.5.1 to 3.5.19, then solved this
issue(Thank you!)

But other problem occured.
When I change squid.conf and reconfigure squid, sometimes
squid crashed(Problem occured 3 times between 2016/6/6 to 2016/6/9)

Can we prevent crash of squid by thise problem?

Dying-message is below,
----
2016/06/07 13:09:23 kid1| Reconfiguring Squid Cache (version 3.5.19)...
2016/06/07 13:09:23 kid1| Closing HTTP port 0.0.0.0:8080
2016/06/07 13:09:23 kid1| Logfile: closing log daemon:/var/log/squid.dir/access.log
2016/06/07 13:09:23 kid1| Logfile Daemon: closing log daemon:/var/log/squid.dir/access.log
2016/06/07 13:09:23 kid1| Startup: Initializing Authentication Schemes ...
2016/06/07 13:09:23 kid1| Startup: Initialized Authentication Scheme 'basic'
2016/06/07 13:09:23 kid1| Startup: Initialized Authentication Scheme 'digest'
2016/06/07 13:09:23 kid1| Startup: Initialized Authentication Scheme 'negotiate'
2016/06/07 13:09:23 kid1| Startup: Initialized Authentication Scheme 'ntlm'
2016/06/07 13:09:23 kid1| Startup: Initialized Authentication.
2016/06/07 13:09:23 kid1| Processing Configuration File: /usr/local/squid-3.5.19-errorpage-follow-x-forwarded-for/etc/squid.conf (depth 0)
2016/06/07 13:09:23 kid1| WARNING: HTTP requires the use of Via
2016/06/07 13:09:23 kid1| Logfile: opening log daemon:/var/log/squid.dir/access.log
2016/06/07 13:09:23 kid1| Logfile Daemon: opening log /var/log/squid.dir/access.log
2016/06/07 13:09:23 kid1| Squid plugin modules loaded: 0
2016/06/07 13:09:23 kid1| Adaptation support is off.
2016/06/07 13:09:23 kid1| Store logging disabled
2016/06/07 13:09:23 kid1| DNS Socket created at 0.0.0.0, FD 12
2016/06/07 13:09:23 kid1| Adding domain (sorry, masked) from /etc/resolv.conf
2016/06/07 13:09:23 kid1| Adding nameserver (sorry, masked) from /etc/resolv.conf
2016/06/07 13:09:23 kid1| Adding nameserver (sorry, masked) from /etc/resolv.conf
2016/06/07 13:09:23 kid1| helperOpenServers: Starting 100/400 'negotiate_wrapper_auth' processes
2016/06/07 13:09:24 kid1| helperOpenServers: Starting 100/400 'ntlm_auth' processes
2016/06/07 13:09:25 kid1| helperOpenServers: Starting 15/100 'ext_ldap_group_acl' processes
2016/06/07 13:09:25 kid1| helperOpenServers: Starting 15/100 'ext_ldap_group_acl' processes
2016/06/07 13:09:25 kid1| HTCP Disabled.
2016/06/07 13:09:25 kid1| Configuring Parent (sorry, masked)/8080/7
2016/06/07 13:09:25 kid1| Configuring Parent (sorry, masked)/8080/7
2016/06/07 13:09:25 kid1| Configuring Parent (sorry, masked)/8080/7
2016/06/07 13:09:25 kid1| Configuring Parent (sorry, masked)/8080/7
2016/06/07 13:09:25 kid1| Configuring Parent (sorry, masked)/8080/7
2016/06/07 13:09:25 kid1| Configuring Parent (sorry, masked)/8080/7
2016/06/07 13:09:25 kid1| Finished loading MIME types and icons.
2016/06/07 13:09:25 kid1| Accepting HTTP Socket connections at local=0.0.0.0:8080 remote=[::] FD 1398 flags=9
FATAL: Received Segment Violation...dying.
2016/06/07 13:09:25 kid1| Closing HTTP port 0.0.0.0:8080
2016/06/07 13:09:25 kid1| storeDirWriteCleanLogs: Starting...
2016/06/07 13:09:25 kid1|   Finished.  Wrote 0 entries.
2016/06/07 13:09:25 kid1|   Took 0.00 seconds (  0.00 entries/sec).
CPU Usage: 9659.361 seconds = 2433.226 user + 7226.134 sys
Maximum Resident Size: 528736 KB
Page faults with physical i/o: 0
----

I confirmed coredump by gdb command.

----
# pwd /var/spool/abrt/ccpp-2016-06-07-13:09:25-11730
# ls -l
total 104720
-rw-r----- 1 abrt squid         5 Jun  7 13:09 abrt_version
-rw-r----- 1 abrt squid         4 Jun  7 13:09 analyzer
-rw-r----- 1 abrt squid         6 Jun  7 13:09 architecture
-rw-r----- 1 abrt squid         0 Jun  7 13:09 cgroup
-rw-r----- 1 abrt squid         9 Jun  7 13:09 cmdline
-rw-r----- 1 abrt squid 143380480 Jun  7 13:09 coredump
-rw-r----- 1 abrt squid         1 Jun  7 13:11 count
-rw-r----- 1 abrt squid      1681 Jun  7 13:11 dso_list
-rw-r----- 1 abrt squid       183 Jun  7 13:09 environ
-rw-r----- 1 abrt squid        67 Jun  7 13:09 executable
-rw-r----- 1 abrt squid        15 Jun  7 13:09 hostname
-rw-r----- 1 abrt squid        26 Jun  7 13:09 kernel
-rw-r----- 1 abrt squid        10 Jun  7 13:09 last_occurrence
-rw-r----- 1 abrt squid      1323 Jun  7 13:09 limits
-rw-r----- 1 abrt squid      8865 Jun  7 13:09 maps
-rw-r----- 1 abrt squid       416 Jun  7 13:09 open_fds
-rw-r----- 1 abrt squid        54 Jun  7 13:09 os_release
-rw-r----- 1 abrt squid         5 Jun  7 13:09 pid
-rw-r----- 1 abrt squid        56 Jun  7 13:09 pwd
-rw-r----- 1 abrt squid       108 Jun  7 13:09 reason
-rw-r----- 1 abrt squid   2352400 Jun  7 13:11 sosreport.tar.xz
-rw-r----- 1 abrt squid        10 Jun  7 13:09 time
-rw-r----- 1 abrt squid         5 Jun  7 13:09 uid
-rw-r----- 1 abrt squid         6 Jun  7 13:09 username
-rw-r----- 1 abrt squid        40 Jun  7 13:11 uuid
# gdb /usr/local/squid-3.5.19-errorpage-follow-x-forwarded-for/sbin/squid coredump
GNU gdb (GDB) Red Hat Enterprise Linux (7.2-75.el6)
Copyright (C) 2010 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-redhat-linux-gnu".
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>...
Reading symbols from /usr/local/squid-3.5.19-errorpage-follow-x-forwarded-for/sbin/squid...done.
[New Thread 11730]
Missing separate debuginfo for
Try: yum --enablerepo='*-debug*' install /usr/lib/debug/.build-id/b7/4f8095168b93495573fcca21245eb3900f05ea
Reading symbols from /lib64/libpthread.so.0...(no debugging symbols found)...done.
[Thread debugging using libthread_db enabled]
Loaded symbols for /lib64/libpthread.so.0
Reading symbols from /lib64/libcrypt.so.1...(no debugging symbols found)...done.
Loaded symbols for /lib64/libcrypt.so.1
Reading symbols from /lib64/libgssapi_krb5.so.2...(no debugging symbols found)...done.
Loaded symbols for /lib64/libgssapi_krb5.so.2
Reading symbols from /lib64/libkrb5.so.3...(no debugging symbols found)...done.
Loaded symbols for /lib64/libkrb5.so.3
Reading symbols from /lib64/libk5crypto.so.3...(no debugging symbols found)...done.
Loaded symbols for /lib64/libk5crypto.so.3
Reading symbols from /lib64/libcom_err.so.2...(no debugging symbols found)...done.
Loaded symbols for /lib64/libcom_err.so.2
Reading symbols from /lib64/libnsl.so.1...(no debugging symbols found)...done.
Loaded symbols for /lib64/libnsl.so.1
Reading symbols from /lib64/libresolv.so.2...(no debugging symbols found)...done.
Loaded symbols for /lib64/libresolv.so.2
Reading symbols from /lib64/librt.so.1...(no debugging symbols found)...done.
Loaded symbols for /lib64/librt.so.1
Reading symbols from /lib64/libdl.so.2...(no debugging symbols found)...done.
Loaded symbols for /lib64/libdl.so.2
Reading symbols from /usr/lib64/libstdc++.so.6...(no debugging symbols found)...done.
Loaded symbols for /usr/lib64/libstdc++.so.6
Reading symbols from /lib64/libm.so.6...(no debugging symbols found)...done.
Loaded symbols for /lib64/libm.so.6
Reading symbols from /lib64/libgcc_s.so.1...(no debugging symbols found)...done.
Loaded symbols for /lib64/libgcc_s.so.1
Reading symbols from /lib64/libc.so.6...(no debugging symbols found)...done.
Loaded symbols for /lib64/libc.so.6
Reading symbols from /lib64/ld-linux-x86-64.so.2...(no debugging symbols found)...done.
Loaded symbols for /lib64/ld-linux-x86-64.so.2
Reading symbols from /lib64/libfreebl3.so...(no debugging symbols found)...done.
Loaded symbols for /lib64/libfreebl3.so
Reading symbols from /lib64/libkrb5support.so.0...(no debugging symbols found)...done.
Loaded symbols for /lib64/libkrb5support.so.0
Reading symbols from /lib64/libkeyutils.so.1...(no debugging symbols found)...done.
Loaded symbols for /lib64/libkeyutils.so.1
Reading symbols from /lib64/libselinux.so.1...(no debugging symbols found)...done.
Loaded symbols for /lib64/libselinux.so.1
Reading symbols from /lib64/libnss_files.so.2...(no debugging symbols found)...done.
Loaded symbols for /lib64/libnss_files.so.2
Core was generated by `(squid-1)'.
Program terminated with signal 6, Aborted.
#0  0x000000353e432625 in raise () from /lib64/libc.so.6
Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.149.el6_6.7.x86_64 keyutils-libs-1.4-5.el6.x86_64 krb5-libs-1.10.3-37.el6_6.x86_64 libcom_err-1.41.12-21.el6.x86_64 libgcc-4.4.7-11.el6.x86_64 libselinux-2.0.94-5.8.el6.x86_64 libstdc++-4.4.7-11.el6.x86_64 nss-softokn-freebl-3.14.3-22.el6_6.x86_64
(gdb) bt full
#0  0x000000353e432625 in raise () from /lib64/libc.so.6
No symbol table info available.
#1  0x000000353e433e05 in abort () from /lib64/libc.so.6
No symbol table info available.
#2  0x00000000006676cf in death (sig=<value optimized out>) at tools.cc:356
No locals.
#3  <signal handler called>
No symbol table info available.
#4  0x000000000066fcac in TunnelStateData::handleConnectResponse (
    this=0x7d7f7c8, chunkSize=<value optimized out>) at tunnel.cc:478
        rep = {<HttpMsg> = {<Lock> = {_vptr.Lock = 0x853aa8, count_ = 0},
            _vptr.HttpMsg = 0x853a38, http_ver = {<AnyP::ProtocolVersion> = {
                protocol = AnyP::PROTO_HTTP, major = 1,
                minor = 0}, <No data fields>}, header = {
              entries = std::vector of length 0, capacity 0,
              mask = '\000' <repeats 11 times>, owner = hoReply, len = 0,
              conflictingContentLength_ = false}, cache_control = 0x0,
            hdr_sz = 39, content_length = -1, pstate = psParsed, body_pipe = {
              p_ = 0x0}}, date = -1, last_modified = -1, expires = -1,
          content_type = {static npos = 18446744073709551615, size_ = 0,
            len_ = 0, static SizeMax_ = 18446744073709551615, buf_ = 0x0},
          surrogate_control = 0x0, content_range = 0x0, keep_alive = 0,
          sline = {protocol = AnyP::PROTO_HTTP,
            version = {<AnyP::ProtocolVersion> = {protocol = AnyP::PROTO_HTTP,
                major = 1, minor = 0}, <No data fields>},
            status_ = Http::scOkay, reason_ = 0x0}, body = {mb = 0x48d2688},
          protoPrefix = {static npos = 18446744073709551615, size_ = 40,
            len_ = 5, static SizeMax_ = 18446744073709551615,
            buf_ = 0x37e3720 "HTTP/"}, do_clean = true, bodySizeMax = -2}
        parseErr = Http::scNone
        pwd = <value optimized out>
        relay = <value optimized out>
        eof = false
        parsed = <value optimized out>
#5  0x00000000006702cb in TunnelStateData::readConnectResponseDone (
    this=0x7d7f7c8, buf=<value optimized out>, len=39, errcode=Comm::OK,
    xerrno=0) at tunnel.cc:389
        __FUNCTION__ = "readConnectResponseDone"
#6  0x00000000006f6598 in AsyncCall::make (this=0x6c53d10) at AsyncCall.cc:40
        __FUNCTION__ = "make"
#7  0x00000000006f9c2e in AsyncCallQueue::fireNext (this=<value optimized out>)
    at AsyncCallQueue.cc:56
        call = {p_ = 0x6c53d10}
        __FUNCTION__ = "fireNext"
#8  0x00000000006f9fa0 in AsyncCallQueue::fire (this=0x2ab69f0)
    at AsyncCallQueue.cc:42
        made = true
#9  0x00000000005853fc in EventLoop::runOnce (this=0x7fffa0626350)
    at EventLoop.cc:120
        sawActivity = <value optimized out>
        waitingEngine = 0x7fffa0626400
        __FUNCTION__ = "runOnce"
#10 0x00000000005855a0 in EventLoop::run (this=0x7fffa0626350)
    at EventLoop.cc:82
No locals.
#11 0x00000000005ef5cd in SquidMain (argc=<value optimized out>,
    argv=<value optimized out>) at main.cc:1539
        WIN32_init_err = 0
        __FUNCTION__ = "SquidMain"
        signalEngine = {<AsyncEngine> = {
            _vptr.AsyncEngine = 0x856a90}, <No data fields>}
        store_engine = {<AsyncEngine> = {
            _vptr.AsyncEngine = 0x856af0}, <No data fields>}
        comm_engine = {<AsyncEngine> = {
            _vptr.AsyncEngine = 0xb251f0}, <No data fields>}
        mainLoop = {errcount = 0, static Running = 0x7fffa0626350,
          last_loop = false, engines = std::vector of length 4, capacity 4 = {
            0x7fffa0626420, 0xb50150, 0x7fffa0626410, 0x7fffa0626400},
          timeService = 0x7fffa06263f0, primaryEngine = 0x7fffa0626400,
          loop_delay = 0, error = false, runOnceResult = false}
        time_engine = {_vptr.TimeEngine = 0x865eb0}
#12 0x00000000005f02a8 in SquidMainSafe (argc=<value optimized out>,
    argv=<value optimized out>) at main.cc:1263
No locals.
#13 main (argc=<value optimized out>, argv=<value optimized out>)
    at main.cc:1256
No locals.
(gdb) quit
----

Our environment is below,
- squid-3.5.19 with squid_kerb_auth x10 server
  (currently, three server crashed by this problem)
- using BIG-IP LTM load balancer
- enable "follow_x_fowarded_for" option
- User ID number is about 6600
- IP address number is about 7600
- Most user authentication is ActiveDirectory(Kerberos), NTLM is only a little
- Normaly, CPU load is about 20%

Regards,
Kazuhiro


From: asakura at ioc.dnp.co.jp
Subject: Re: [squid-users] access from same ID and different IP addresses.
Date: Thu, 17 Mar 2016 21:50:43 +0900 (JST)

> Thank you Amos,
>
> I will consider squid version up of squid.
>
> By the way, the UserID and IP segment of problem is not currently used.
> They are scheduled to be used again in May 2016.
>
> It will report if there is any good news.
>
>
> Regards,
> Kazuhiro
>
>
> From: Amos Jeffries <squid3 at treenet.co.nz>
> Subject: Re: [squid-users] access from same ID and different IP addresses.
> Date: Thu, 17 Mar 2016 01:35:07 +1300
>
> > On 16/03/2016 5:06 p.m., asakura at ioc.dnp.co.jp wrote:
> > > Hello,
> > >
> > > Recently, in our environment, CPU load on the squid proxy server
> > > is happening trouble to become a 100%.
> > >
> > > example----
> > > PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND
> > > 29767 squid     20   0 1430m 1.3g 5332 R 99.1 17.4   6836:56 squid
> > > 16856 squid     20   0 29764 3280 1620 S  2.0  0.0  68:46.34 squid_kerb_auth
> > > 16860 squid     20   0 29760 3272 1616 S  1.7  0.0  43:53.67 squid_kerb_auth
> > > 16855 squid     20   0 22636 1244 1000 S  0.3  0.0   2:57.66 negotiate_wrapp
> > > 21437 asakura   20   0 15432 1632  932 R  0.3  0.0   0:01.02 top
> > > 26167 root      20   0 19088 2248 1060 S  0.3  0.0   1016:14 syslog-ng
> > > ---
> > >
> > > As a result of investigation, We suspect that CPU load become a 100%
> > > when user attempts to log in from more than different ip addresses.
> > >
> >
> > All that CPU has to be spent doing something. So what is that something?
> >
> >
> > > This time, squid has been accessed from 20 or more units of
> > > the PC with the same user ID.
> > > When we disable user authentication from target segment, CPU load be low.
> > >
> > > We want to know whether CPU load goes up when squid is accessed from
> > > a large number of different IP addresses with the same user ID.
> > >
> > > Our environment is below,
> > > - squid-3.5.1 with squid_kerb_auth(sorry old version...) x5 server
> >
> > First step is upgrading. So you can see if it is one of the thousand or
> > so bugs already fixed since that old version.
> >
> > There have been at least 2 bugs whose claimed symptom was "100% CPU
> > usage" that got fixed this past year.
> >
> >
> > Amos


From joni.kahara at gmail.com  Thu Jun  9 15:48:53 2016
From: joni.kahara at gmail.com (=?UTF-8?B?Sm9uaSBLw6Row6Ryw6Q=?=)
Date: Thu, 9 Jun 2016 18:48:53 +0300
Subject: [squid-users] Unable to IPv6 DNAT & intercept (Debian Stretch,
	Linux 3.16.0, Squid 3.5.19)
Message-ID: <CAE8g12H0VsdaOv2Xo54_h4HLCx7qyHVyBAYwgmtYW4QbrS-+2g@mail.gmail.com>

Hello list,

I'm approaching you with a question regarding intercept proxying and IPv6.
I have a working IPv4 setup that redirects port 80 traffic to a port that
Squid is listening on:

    -A PREROUTING -s <source-net> -p tcp -m tcp --dport 80 -j REDIRECT
--to-ports <squid-port>

When I try to duplicate this behaviour on IPv6 side, it does not work. This
does not seem to be an ACL issue as the symptoms are the same even with an
all-allowing ACL, and because I'm unable to get even an "access denied"
error from Squid. I can reach the IPv6 Squid port by accessing it directly
from the local machine.

Also, if the REDIRECT is changed to a DNAT, the behaviour is identical
(i.e. not working):

    -A PREROUTING -s <source-net> -p tcp -m tcp --dport 80 -j DNAT
--to-destination [<squid-ip>]:<squid-port>

By looking at ip6tables packet counters and tcpdump I have come to a
conclusion that a SYN packet hits the REDIRECT rule, but even if it ever
reaches Squid, it looks as if Squid is ignoring it and not returning
anything. Enabling debug sections 5 and 89 show nothing in cache.log while
the connection establishment is supposed to be happening. While trying to
figure out what is going on, I also tried the following in an attempt to
rule out e.g. firewall restrictions causing the failure (this works, TCP
handshake occurs and a web page is returned):

    -A PREROUTING -s <source-net> -p tcp -m tcp --dport 80 -j DNAT
--to-destination [<external-ip>]:80

Does anyone here have experience with anything resembling the above? Any
advice would be appreciated.


    Joni
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160609/14287e43/attachment.htm>

From eenghooda at yahoo.com  Thu Jun  9 18:09:14 2016
From: eenghooda at yahoo.com (Eng Hooda)
Date: Thu, 9 Jun 2016 18:09:14 +0000 (UTC)
Subject: [squid-users] Response Blocked from sites with multiple IPs (Host
	Header Forgery)
References: <1373286259.287025.1465495754713.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1373286259.287025.1465495754713.JavaMail.yahoo@mail.yahoo.com>

Hello Squid Users,
I have just started using squid less than a week ago .
My setup is a transparent proxy with sslbump , I peek for media streaming sites then terminate their connections then I splice all.
I noticed that some https sites (not all of the time) , does not respond , when Investigated I found the following in cache.log :

3105 2016/06/09 12:45:40.630 kid1| SECURITY ALERT: on URL: mail.live.com:443
3106 2016/06/09 12:45:40.631 kid1| SECURITY ALERT: Host header forgery detected on local=157.55.43.16:443 remote=10.3.1.80:58328 FD 94 flags=33 (local IP does not match any domain IP)
3330 2016/06/09 13:26:26.676 kid1| SECURITY ALERT: on URL: mail.live.com:443
3331 2016/06/09 13:26:26.676 kid1| SECURITY ALERT: Host header forgery detected on local=157.56.122.210:443 remote=10.3.1.80:58414 FD 141 flags=33 (local IP does not match any domain IP)
3530 2016/06/09 13:49:49.481 kid1| SECURITY ALERT: on URL: mail.live.com:443
3531 2016/06/09 13:49:49.481 kid1| SECURITY ALERT: Host header forgery detected on local=157.55.43.17:443 remote=10.3.1.80:58616 FD 119 flags=33 (local IP does not match any domain IP)

I searched for a solution which lead me to (1st result)  :  
http://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery

I read it and it seems to be a dead end .

What I understood that client requested page from a certain IP , reply came from another IP then it's blocked for security reasons.


Well I tried to nslookup the mentioned IPs , and all of them are sub domains of mail.live.com
nslookup 157.55.43.16
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Name:    origin.du111w.dub111.mail.live.com
Address:  157.55.43.16


nslookup 157.56.122.210
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Name:    origin.du125w.dub125.mail.live.com
Address:  157.56.122.210


nslookup 157.55.43.17
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Name:    origin.du112w.dub112.mail.live.com
Address:  157.55.43.17

also tried to nslookup mail.live.com , and every time I get different IPs

nslookup mail.live.com
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Non-authoritative answer:
Name:    dispatch.kahuna.glbdns2.microsoft.com
Addresses:  157.56.195.156
157.55.235.51
Aliases:  mail.live.com


nslookup mail.live.com
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Non-authoritative answer:
Name:    dispatch.kahuna.glbdns2.microsoft.com
Addresses:  157.55.235.49
157.56.122.210
Aliases:  mail.live.com


nslookup mail.live.com
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Non-authoritative answer:
Name:    dispatch.kahuna.glbdns2.microsoft.com
Addresses:  157.55.43.16
157.55.43.17
Aliases:  mail.live.com


nslookup mail.live.com
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Non-authoritative answer:
Name:    dispatch.kahuna.glbdns2.microsoft.com
Addresses:  157.55.235.51
157.56.122.208
Aliases:  mail.live.com


nslookup mail.live.com
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Non-authoritative answer:
Name:    dispatch.kahuna.glbdns2.microsoft.com
Addresses:  157.55.235.51
157.56.122.208
Aliases:  mail.live.com


nslookup mail.live.com
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Non-authoritative answer:
Name:    dispatch.kahuna.glbdns2.microsoft.com
Addresses:  157.55.235.48
157.55.235.49
Aliases:  mail.live.com


nslookup mail.live.com
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Non-authoritative answer:
Name:    dispatch.kahuna.glbdns2.microsoft.com
Addresses:  157.55.235.49
157.56.122.210
Aliases:  mail.live.com

So can't squid learn that big sites have a lot of IPs mapped as sub-domains of it , and they may reply from any of them ?

Or just provide an option to disable this problematic security feature ?

or Am I missing something here ?

Thanks You all in advance.


Best Regards,

Eng Hooda


From bruno.larini at riosoft.com.br  Thu Jun  9 19:20:49 2016
From: bruno.larini at riosoft.com.br (Bruno de Paula Larini)
Date: Thu, 9 Jun 2016 16:20:49 -0300
Subject: [squid-users] Skype makes Squid with ssl_bump crash
Message-ID: <d2f4711f-21ce-21bb-1f0d-f4071f8143b8@riosoft.com.br>

Hi list.

I'm experiencing some crashes on Squid workers and eventually on the 
parent process while using a mixed authenticated/intercepted ssl_bump + 
Skype (7.21.0.100). After searching for some clues, I've found this:

Changes to squid-3.5.9 (17 Sep 2015):
     ...
     - Bug 4309: crash during Skype login
     ...

I'm running the exact Squid 3.5.9, provided by official Fedora 23 (x64) 
repositories and noticed this behavior only while using Skype.

My squid.conf contains the section below. If Skype isn't open or if it 
managed to authenticate without crashing the Squid main process then 
everything works normally. If I comment these lines, Skype won't affect 
Squid at all (not a single worker exits) and everything also works 
normally in the authenticated, non-intercepted mode. So, this only 
happens for whathever reason when it is trying to authenticate the Skype 
user. All other concurrent connections are terminated during the 
authentication.

If the bug has been addressed then maybe it is something I'm doing 
wrong? Or maybe this is a different one?
Thanks everyone!


/etc/squid/squid.conf
...
     http_port 192.168.0.1:3128 intercept
     https_port 192.168.0.1:3129 cert=/etc/squid/ssl/squidCA.pem 
key=/etc/squid/ssl/squidCA.key ssl-bump intercept 
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
sslflags=NO_SESSION_REUSE

     acl http_intercept dstdom_regex -i "/etc/squid/allow-intercepted.txt"
     http_access allow SSL_ports
     http_access allow http_intercept
     http_access deny all

     acl step1 at_step SslBump1
     acl step2 at_step SslBump2
     acl step3 at_step SslBump3
     ssl_bump peek step1 all
     ssl_bump peek step2 all

     acl https_intercept ssl::server_name_regex 
"/etc/squid/allow-intercepted.txt"
     ssl_bump splice step3 https_intercept
     ssl_bump terminate all

     sslproxy_capath /etc/ssl/certs
     sslproxy_options ALL

     sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/squid/ssl_db 
-M 4MB
     sslcrtd_children 5

+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
/var/log/messages:

...
Jun  8 17:12:44 squidserver abrt-hook-ccpp: Process 23301 (squid) of 
user 23 killed by SIGABRT - dumping core
Jun  8 17:12:45 squidserver squid[23299]: Squid Parent: (squid-1) 
process 23301 exited due to signal 6 with status 0
Jun  8 17:12:45 squidserver abrt-server: Deleting problem directory 
ccpp-2016-06-08-17:12:44-23301 (dup of ccpp-2016-03-24-02:28:05-10168)
Jun  8 17:12:45 squidserver dbus[630]: [system] Activating service 
name='org.freedesktop.problems' (using servicehelper)
Jun  8 17:12:45 squidserver dbus[630]: [system] Successfully activated 
service 'org.freedesktop.problems'
Jun  8 17:12:48 squidserver squid[23299]: Squid Parent: (squid-1) 
process 23726 started
Jun  8 17:12:48 squidserver (squid-1): Ipc::Mem::Segment::open failed to 
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
Jun  8 17:12:48 squidserver squid[23299]: Squid Parent: (squid-1) 
process 23726 exited with status 1
Jun  8 17:12:51 squidserver squid[23299]: Squid Parent: (squid-1) 
process 23733 started
Jun  8 17:12:51 squidserver (squid-1): Ipc::Mem::Segment::open failed to 
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
Jun  8 17:12:51 squidserver squid[23299]: Squid Parent: (squid-1) 
process 23733 exited with status 1
Jun  8 17:12:54 squidserver squid[23299]: Squid Parent: (squid-1) 
process 23806 started
Jun  8 17:12:54 squidserver (squid-1): Ipc::Mem::Segment::open failed to 
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
Jun  8 17:12:54 squidserver squid[23299]: Squid Parent: (squid-1) 
process 23806 exited with status 1
Jun  8 17:12:57 squidserver squid[23299]: Squid Parent: (squid-1) 
process 23813 started
Jun  8 17:12:57 squidserver (squid-1): Ipc::Mem::Segment::open failed to 
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
Jun  8 17:12:57 squidserver squid[23299]: Squid Parent: (squid-1) 
process 23813 exited with status 1
Jun  8 17:13:00 squidserver squid[23299]: Squid Parent: (squid-1) 
process 23820 started
Jun  8 17:13:00 squidserver (squid-1): Ipc::Mem::Segment::open failed to 
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
Jun  8 17:13:00 squidserver squid[23299]: Squid Parent: (squid-1) 
process 23820 exited with status 1
Jun  8 17:13:00 squidserver squid[23299]: Squid Parent: (squid-1) 
process 23820 will not be restarted due to repeated, frequent failures
Jun  8 17:13:00 squidserver squid[23299]: Exiting due to repeated, 
frequent failures
Jun  8 17:13:00 squidserver systemd: squid.service: Main process exited, 
code=exited, status=1/FAILURE
Jun  8 17:13:00 squidserver squid: squid: ERROR: Could not send signal 
15 to process 23301: (3) No such process
Jun  8 17:13:00 squidserver systemd: squid.service: Control process 
exited, code=exited status=1
Jun  8 17:13:00 squidserver systemd: squid.service: Unit entered failed 
state.
Jun  8 17:13:00 squidserver systemd: squid.service: Failed with result 
'exit-code'.
...
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
/var/log/squid/cache.log

...
2016/06/08 17:12:43 kid1| hold write on SSL connection on FD 29
2016/06/08 17:12:44 kid1| Closing HTTP port 192.168.0.1:8080
2016/06/08 17:12:44 kid1| Closing HTTP port 127.0.0.1:8080
2016/06/08 17:12:44 kid1| Closing HTTP port 192.168.0.1:3128
2016/06/08 17:12:44 kid1| Closing HTTPS port 192.168.0.1:3129
2016/06/08 17:12:44 kid1| storeDirWriteCleanLogs: Starting...
2016/06/08 17:12:44 kid1|   Finished.  Wrote 61 entries.
2016/06/08 17:12:44 kid1|   Took 0.00 seconds (291866.03 entries/sec).
2016/06/08 17:12:48 kid1| Set Current Directory to /var/spool/squid
2016/06/08 17:12:48 kid1| Starting Squid Cache version 3.5.9 for 
x86_64-redhat-linux-gnu...
2016/06/08 17:12:48 kid1| Service Name: squid
2016/06/08 17:12:48 kid1| Process ID 23726
2016/06/08 17:12:48 kid1| Process Roles: worker
2016/06/08 17:12:48 kid1| With 16384 file descriptors available
2016/06/08 17:12:48 kid1| Initializing IP Cache...
2016/06/08 17:12:48 kid1| DNS Socket created at [::], FD 9
2016/06/08 17:12:48 kid1| DNS Socket created at 0.0.0.0, FD 11
2016/06/08 17:12:48 kid1| Adding domain riosoft.local from /etc/resolv.conf
2016/06/08 17:12:48 kid1| Adding nameserver 192.168.0.7 from 
/etc/resolv.conf
2016/06/08 17:12:48 kid1| Adding nameserver 192.168.0.8 from 
/etc/resolv.conf
2016/06/08 17:12:48 kid1| helperOpenServers: Starting 5/5 'ssl_crtd' 
processes
...
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
Squid version and build flags:

[root at squidserver ~]# squid -v
Squid Cache: Version 3.5.9
Service Name: squid
configure options:  '--build=x86_64-redhat-linux-gnu' 
'--host=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr' 
'--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin' 
'--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include' 
'--libdir=/usr/lib64' '--libexecdir=/usr/libexec' 
'--sharedstatedir=/var/lib' '--mandir=/usr/share/man' 
'--infodir=/usr/share/info' '--exec_prefix=/usr' 
'--libexecdir=/usr/lib64/squid' '--localstatedir=/var' 
'--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' 
'--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' 
'--disable-dependency-tracking' '--enable-eui' 
'--enable-follow-x-forwarded-for' '--enable-auth' 
'--enable-auth-basic=DB,LDAP,MSNT-multi-domain,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,getpwnam' 
'--enable-auth-ntlm=smb_lm,fake' '--enable-auth-digest=file,LDAP' 
'--enable-auth-negotiate=kerberos' 
'--enable-external-acl-helpers=LDAP_group,time_quota,session,unix_group,wbinfo_group' 
'--enable-storeid-rewrite-helpers=file' '--enable-cache-digests' 
'--enable-cachemgr-hostname=localhost' '--enable-delay-pools' 
'--enable-epoll' '--enable-icap-client' '--enable-ident-lookups' 
'--enable-linux-netfilter' '--enable-removal-policies=heap,lru' 
'--enable-snmp' '--enable-ssl' '--enable-ssl-crtd' 
'--enable-storeio=aufs,diskd,ufs,rock' '--enable-diskio' 
'--enable-wccpv2' '--enable-esi' '--enable-ecap' '--with-aio' 
'--with-default-user=squid' '--with-dl' '--with-openssl' 
'--with-pthreads' '--disable-arch-native' '--with-pic' 
'build_alias=x86_64-redhat-linux-gnu' 
'host_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall 
-Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fexceptions 
-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches 
-specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic 
-fPIC' 'LDFLAGS=-Wl,-z,relro 
-specs=/usr/lib/rpm/redhat/redhat-hardened-ld -pie -Wl,-z,relro 
-Wl,-z,now -Wl,--warn-shared-textrel' 'CXXFLAGS=-O2 -g -pipe -Wall 
-Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fexceptions 
-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches 
-specs=/usr/lib/rpm/redhat/redhat-hardened-cc1 -m64 -mtune=generic 
-fPIC' 'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig'

OpenSSL: openssl-1.0.2h-1.fc23.x86_64



From amadaan at ncsu.edu  Thu Jun  9 20:06:06 2016
From: amadaan at ncsu.edu (Aashima Madaan)
Date: Thu, 9 Jun 2016 16:06:06 -0400
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
Message-ID: <02D006C9-FAA5-4FEB-9DAE-B1E718B6639C@ncsu.edu>

Any updates on this issue? and regarding patch ?

Thanks
Aashima


From eliezer at ngtech.co.il  Thu Jun  9 21:23:40 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 10 Jun 2016 00:23:40 +0300
Subject: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot
	bind	socket FD 782 to [::]: (2) No such file or directory
In-Reply-To: <43CF45E5-FA7D-432D-96EF-DA8DEA443667@netstream.ps>
References: <8B8C7545-E090-4014-AA00-7FCD55FE04C9@netstream.ps>
 <00a601d1c1e3$d8bd8110$8a388330$@ngtech.co.il>
 <43CF45E5-FA7D-432D-96EF-DA8DEA443667@netstream.ps>
Message-ID: <04bd01d1c295$316b8260$94428720$@ngtech.co.il>

Hey Ahmad,

 

I do not why you are suffering from the issue.

The options are:

-          Selinux

-          Permission

-          Directory existence

-          Self compiled kernel withtou IPV6 support

-          And many more

>From my point of view I suggest first to try my RPMs as it works with many setups.

Second try to simplify your squid.conf and share it.
What addition to squid.conf make this issue appear?

Also have you tried looking at the SMP FAQ at:

http://wiki.squid-cache.org/Features/SmpScale#Cannot_bind_socket_FD_NN_to_.5B::.5D:_.2813.29_Permission_denied

 

If this and the RPMs do not help you to resolve the issue then share a very simplified squid.conf and we can try to see if there is some direction for help.

 

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: --Ahmad-- [mailto:ahmed.zaeem at netstream.ps] 
Sent: Thursday, June 9, 2016 10:55 AM
To: Eliezer Croitoru
Cc: Squid Users
Subject: Re: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory

 

hi Mr elieizer

 

i already check the mailing list  before i post here , but no luck with me .

 

 

i don?t think its a permissions issue 

 

 

i have the file /var/run/squid is missing 

 

and  there is /var/run/squid.pid

 

and it has the squid permissions 

 

 

kindly can you point to me  if i figure it out using compile options ? or from the os side ?

 

 

thank you 

On Jun 9, 2016, at 3:14 AM, Eliezer Croitoru <eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il> > wrote:

 

Hey Ahmed,

 

Have you tried my RPMs for CentOS 7?

The latest version is 3.5.19 which is far more advanced then 3.5.2 and it works for me..

This issue you mentioned has lots of references in the mailing list history.

I assume it's a simple issue.

If you can try my RPMs and verify that you get the same error with them I will try to see if I can reproduce the issue.

 

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email:  <mailto:eliezer at ngtech.co.il> eliezer at ngtech.co.il

<image001.png>

 

From: squid-users [ <mailto:squid-users-bounces at lists.squid-cache.org> mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of --Ahmad--
Sent: Thursday, June 9, 2016 1:57 AM
To: Squid Users
Subject: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory

 

here is error when i run squid :

2016/06/08 18:48:29 kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory

2016/06/08 18:48:29 kid1| HTCP Disabled.

2016/06/08 18:48:29 kid1| Squid plugin modules loaded: 0

2016/06/08 18:48:29 kid1| Adaptation support is off.

2016/06/08 18:48:29 kid1| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory

 

 

I?m sure if i use it on centos 6 it work?...

 

but on centos 7 with same compile options it don?t allow me to use workers SMP

 

any help ?

 

 

Squid Cache: Version 3.5.2

Service Name: squid

configure options:  '--prefix=/usr' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc' '--enable-cachemgr-hostname=Ahmad-Allzaeem' '--localstatedir=/var' '--libexecdir=/lib/squid' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm' '--enable-digest-auth-helpers=ldap,password' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' '' '--with-large-files' '--with-default-user=squid' --with-openssl' '--enable-snmp' '--with-included-ltdl' '--disable-arch-native'

[root at localhost ~]# 

 

 

 

 

thank   you 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160610/ba92ac8c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image003.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160610/ba92ac8c/attachment.png>

From eliezer at ngtech.co.il  Thu Jun  9 21:29:00 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 10 Jun 2016 00:29:00 +0300
Subject: [squid-users] Response Blocked from sites with multiple IPs
	(Host	Header Forgery)
In-Reply-To: <1373286259.287025.1465495754713.JavaMail.yahoo@mail.yahoo.com>
References: <1373286259.287025.1465495754713.JavaMail.yahoo.ref@mail.yahoo.com>
 <1373286259.287025.1465495754713.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <04d101d1c295$f037cf00$d0a76d00$@ngtech.co.il>

Hey,

There are couple basic missing parts about the setup.
-	What OS are you using?
-	How do you Intercept the connections? Tproxy? Intercept?
-	Do the client use the same DNS server as the proxy server?
-	Are you using some kind of local caching service? Such as Bind\Unbound\PowerDNS\else?
-	Is it a self compiled version of squid or from a package?
All the above can affect the way we can help you.

Eliezer


----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Eng Hooda
Sent: Thursday, June 9, 2016 9:09 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Response Blocked from sites with multiple IPs (Host Header Forgery)

Hello Squid Users,
I have just started using squid less than a week ago .
My setup is a transparent proxy with sslbump , I peek for media streaming sites then terminate their connections then I splice all.
I noticed that some https sites (not all of the time) , does not respond , when Investigated I found the following in cache.log :

3105 2016/06/09 12:45:40.630 kid1| SECURITY ALERT: on URL: mail.live.com:443
3106 2016/06/09 12:45:40.631 kid1| SECURITY ALERT: Host header forgery detected on local=157.55.43.16:443 remote=10.3.1.80:58328 FD 94 flags=33 (local IP does not match any domain IP)
3330 2016/06/09 13:26:26.676 kid1| SECURITY ALERT: on URL: mail.live.com:443
3331 2016/06/09 13:26:26.676 kid1| SECURITY ALERT: Host header forgery detected on local=157.56.122.210:443 remote=10.3.1.80:58414 FD 141 flags=33 (local IP does not match any domain IP)
3530 2016/06/09 13:49:49.481 kid1| SECURITY ALERT: on URL: mail.live.com:443
3531 2016/06/09 13:49:49.481 kid1| SECURITY ALERT: Host header forgery detected on local=157.55.43.17:443 remote=10.3.1.80:58616 FD 119 flags=33 (local IP does not match any domain IP)

I searched for a solution which lead me to (1st result)  :  
http://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery

I read it and it seems to be a dead end .

What I understood that client requested page from a certain IP , reply came from another IP then it's blocked for security reasons.


Well I tried to nslookup the mentioned IPs , and all of them are sub domains of mail.live.com nslookup 157.55.43.16
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Name:    origin.du111w.dub111.mail.live.com
Address:  157.55.43.16


nslookup 157.56.122.210
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Name:    origin.du125w.dub125.mail.live.com
Address:  157.56.122.210


nslookup 157.55.43.17
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Name:    origin.du112w.dub112.mail.live.com
Address:  157.55.43.17

also tried to nslookup mail.live.com , and every time I get different IPs

nslookup mail.live.com
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Non-authoritative answer:
Name:    dispatch.kahuna.glbdns2.microsoft.com
Addresses:  157.56.195.156
157.55.235.51
Aliases:  mail.live.com


nslookup mail.live.com
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Non-authoritative answer:
Name:    dispatch.kahuna.glbdns2.microsoft.com
Addresses:  157.55.235.49
157.56.122.210
Aliases:  mail.live.com


nslookup mail.live.com
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Non-authoritative answer:
Name:    dispatch.kahuna.glbdns2.microsoft.com
Addresses:  157.55.43.16
157.55.43.17
Aliases:  mail.live.com


nslookup mail.live.com
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Non-authoritative answer:
Name:    dispatch.kahuna.glbdns2.microsoft.com
Addresses:  157.55.235.51
157.56.122.208
Aliases:  mail.live.com


nslookup mail.live.com
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Non-authoritative answer:
Name:    dispatch.kahuna.glbdns2.microsoft.com
Addresses:  157.55.235.51
157.56.122.208
Aliases:  mail.live.com


nslookup mail.live.com
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Non-authoritative answer:
Name:    dispatch.kahuna.glbdns2.microsoft.com
Addresses:  157.55.235.48
157.55.235.49
Aliases:  mail.live.com


nslookup mail.live.com
Server:  google-public-dns-a.google.com
Address:  8.8.8.8

Non-authoritative answer:
Name:    dispatch.kahuna.glbdns2.microsoft.com
Addresses:  157.55.235.49
157.56.122.210
Aliases:  mail.live.com

So can't squid learn that big sites have a lot of IPs mapped as sub-domains of it , and they may reply from any of them ?

Or just provide an option to disable this problematic security feature ?

or Am I missing something here ?

Thanks You all in advance.


Best Regards,

Eng Hooda
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160610/bf2cdf4c/attachment.htm>

From squid3 at treenet.co.nz  Thu Jun  9 22:22:18 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 10 Jun 2016 10:22:18 +1200
Subject: [squid-users] Unable to IPv6 DNAT & intercept (Debian Stretch,
 Linux 3.16.0, Squid 3.5.19)
In-Reply-To: <CAE8g12H0VsdaOv2Xo54_h4HLCx7qyHVyBAYwgmtYW4QbrS-+2g@mail.gmail.com>
References: <CAE8g12H0VsdaOv2Xo54_h4HLCx7qyHVyBAYwgmtYW4QbrS-+2g@mail.gmail.com>
Message-ID: <b1ccacf8-e84d-5e48-ba0c-8148a6e02c30@treenet.co.nz>

On 10/06/2016 3:48 a.m., Joni K?h?r? wrote:
> Hello list,
> 
> I'm approaching you with a question regarding intercept proxying and IPv6.
> I have a working IPv4 setup that redirects port 80 traffic to a port that
> Squid is listening on:
> 
>     -A PREROUTING -s <source-net> -p tcp -m tcp --dport 80 -j REDIRECT
> --to-ports <squid-port>
> 
> When I try to duplicate this behaviour on IPv6 side, it does not work. This
> does not seem to be an ACL issue as the symptoms are the same even with an
> all-allowing ACL, and because I'm unable to get even an "access denied"
> error from Squid. I can reach the IPv6 Squid port by accessing it directly
> from the local machine.
> 
> Also, if the REDIRECT is changed to a DNAT, the behaviour is identical
> (i.e. not working):
> 
>     -A PREROUTING -s <source-net> -p tcp -m tcp --dport 80 -j DNAT
> --to-destination [<squid-ip>]:<squid-port>
> 
> By looking at ip6tables packet counters and tcpdump I have come to a
> conclusion that a SYN packet hits the REDIRECT rule, but even if it ever
> reaches Squid, it looks as if Squid is ignoring it and not returning
> anything. Enabling debug sections 5 and 89 show nothing in cache.log while
> the connection establishment is supposed to be happening. While trying to

Then the issue is in the kernel. That debug level always produces
output, starting with the NAT-mangled IP:port details given by the
accept(2) syscall triggered by SYN arrival.

If the kernel IPv6 NAT is not resulting in an accept(2) operation
something is buggy in the TCP stack.

Double-check that libcap-dev was used when Squid was built. That
rpfilter, SELinux, Apparmor etc. are not blocking the activity.

Amos



From squid3 at treenet.co.nz  Thu Jun  9 22:36:14 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 10 Jun 2016 10:36:14 +1200
Subject: [squid-users] Skype makes Squid with ssl_bump crash
In-Reply-To: <d2f4711f-21ce-21bb-1f0d-f4071f8143b8@riosoft.com.br>
References: <d2f4711f-21ce-21bb-1f0d-f4071f8143b8@riosoft.com.br>
Message-ID: <3d51f028-bc84-1e59-5066-2b6f9ab603e8@treenet.co.nz>

On 10/06/2016 7:20 a.m., Bruno de Paula Larini wrote:
> Hi list.
> 
> I'm experiencing some crashes on Squid workers and eventually on the
> parent process while using a mixed authenticated/intercepted ssl_bump +
> Skype (7.21.0.100). After searching for some clues, I've found this:
> 
> Changes to squid-3.5.9 (17 Sep 2015):
>     ...
>     - Bug 4309: crash during Skype login
>     ...
> 
> I'm running the exact Squid 3.5.9, provided by official Fedora 23 (x64)
> repositories and noticed this behavior only while using Skype.

Please update to 3.5.19, if that does not work you may need to update to
the 4.0.11 coming out today.

NP: the bug only relates to issues that were occuring in how Skype and
TLS operated in Sep 2015. The arms race has changed a lot month-on-month
since then.

Amos



From squid3 at treenet.co.nz  Thu Jun  9 22:54:57 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 10 Jun 2016 10:54:57 +1200
Subject: [squid-users] Response Blocked from sites with multiple IPs
 (Host Header Forgery)
In-Reply-To: <1373286259.287025.1465495754713.JavaMail.yahoo@mail.yahoo.com>
References: <1373286259.287025.1465495754713.JavaMail.yahoo.ref@mail.yahoo.com>
 <1373286259.287025.1465495754713.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <66291048-7e48-25d8-23aa-8fd2332a7cd6@treenet.co.nz>

On 10/06/2016 6:09 a.m., Eng Hooda wrote:
> Hello Squid Users,
> I have just started using squid less than a week ago .
> My setup is a transparent proxy with sslbump , I peek for media streaming sites then terminate their connections then I splice all.
> I noticed that some https sites (not all of the time) , does not respond , when Investigated I found the following in cache.log :
> 
> 3105 2016/06/09 12:45:40.630 kid1| SECURITY ALERT: on URL: mail.live.com:443
> 3106 2016/06/09 12:45:40.631 kid1| SECURITY ALERT: Host header forgery detected on local=157.55.43.16:443 remote=10.3.1.80:58328 FD 94 flags=33 (local IP does not match any domain IP)
> 3330 2016/06/09 13:26:26.676 kid1| SECURITY ALERT: on URL: mail.live.com:443
> 3331 2016/06/09 13:26:26.676 kid1| SECURITY ALERT: Host header forgery detected on local=157.56.122.210:443 remote=10.3.1.80:58414 FD 141 flags=33 (local IP does not match any domain IP)
> 3530 2016/06/09 13:49:49.481 kid1| SECURITY ALERT: on URL: mail.live.com:443
> 3531 2016/06/09 13:49:49.481 kid1| SECURITY ALERT: Host header forgery detected on local=157.55.43.17:443 remote=10.3.1.80:58616 FD 119 flags=33 (local IP does not match any domain IP)
> 
> I searched for a solution which lead me to (1st result)  :  
> http://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery
> 
> I read it and it seems to be a dead end .
> 
> What I understood that client requested page from a certain IP , reply came from another IP then it's blocked for security reasons.
> 
> 
> Well I tried to nslookup the mentioned IPs , and all of them are sub domains of mail.live.com

No, all of them claim to be in their reverse-DNS responses. That is just
the IP address owners view of things. In the case of an attack its the
attackers opinion about what you should believe. Not safe.

Forward-DNS results which provide the domain owners authoritative list
of what IPs they are using. Say a different message contradicting those
reverse-DNS results ...


> also tried to nslookup mail.live.com , and every time I get different IPs
> 

Exactly. So do Squid and the client. Which means Squid is almost always
unable to see the IP the client is contacting as being a valid one for
that domain.


> nslookup mail.live.com
> Server:  google-public-dns-a.google.com
> Address:  8.8.8.8
> 

It is a problem caused by Google DNS.

The best way to get around it is to setup a recursive resolver on your
network that is used by both Squid and clients. Diverting the client
port 53 traffic to it if necessary.

If you wish to use Google DNS after having that available, then 8.8.8.8
should be setup as a parent of that local resolver. Not as something
Squid or client contact separately.

That setup makes the google DNS results more often be cached in the
shared resolver for long enough that Squid can see it when it does the
validation steps.

NP: there are other causes of this known, related to connection
persistence, and SSL-Bump SNI being validated. They are bugs in Squid
and still being worked on fixing. So dont expect the above to solve all
instances of it.

Amos



From squid3 at treenet.co.nz  Thu Jun  9 23:26:43 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 10 Jun 2016 11:26:43 +1200
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
In-Reply-To: <02D006C9-FAA5-4FEB-9DAE-B1E718B6639C@ncsu.edu>
References: <02D006C9-FAA5-4FEB-9DAE-B1E718B6639C@ncsu.edu>
Message-ID: <88212108-afb7-65b0-679b-3cb6d7c08688@treenet.co.nz>

On 10/06/2016 8:06 a.m., Aashima Madaan wrote:
> Any updates on this issue? and regarding patch ?
> 

Is the reply-to function of yoru mailer working? This is the 11th unique
thread you started under this same name in the past few weeks.


The patch I came up with in thread #6 was an experiment to see if it
would be possible to do DNS during the configure stage.

The segfault you received tells the tale of DNS not being configured at
the time ICAP settings are loaded from squid.conf. Therefore, no it will
not be possible to seed Squid internal DNS with details of the service
hostname until after configuration has completed.

After config would be the point at which the first OPTIONS request is
being constructed and DNS looked up already. So duplicating DNS lookup
there is pointless.

The fix will have to be done some other way inside the ICAP client logic
and I'm not aware of anyone working on it.

Amos



From sebelk at gmail.com  Fri Jun 10 02:26:16 2016
From: sebelk at gmail.com (Sergio Belkin)
Date: Thu, 9 Jun 2016 23:26:16 -0300
Subject: [squid-users] Peek'n Splice (ssl_bump) and authentication
 Somewhat OT: Content Filter with https
In-Reply-To: <5758AA80.7090905@urlfilterdb.com>
References: <CABZC=5y8rWTheVxXKXy7k5us3uuixcxGz2ay=uYKPpjbNvK3xA@mail.gmail.com>
 <5758AA80.7090905@urlfilterdb.com>
Message-ID: <CABZC=5xiTELifcJyQJfg+_x+iBxAwu+gLKmypevr0ROd1OKfFg@mail.gmail.com>

2016-06-08 20:30 GMT-03:00 Marcus Kool <marcus.kool at urlfilterdb.com>:

>
>
> On 06/08/2016 07:53 PM, Sergio Belkin wrote:
>
>>
>> Thanks Eliezer, good summary. I've changed the subject to reflect better
>> the issue. As far I undestand from documention one can bump https only by
>> interception.
>>
>
> No.  ssl-bump works very well with regular proxy mode, i.e. the browsers
> configure the address and port of the proxy or use PAC.
>
> But what about if one Windows user login against an Active Directory, will
>> the authenticacion work to use the proxy?
>>
>> I mean, what I'd want is:
>>
>> - Only users of an Active Directory can use the proxy
>>
>
> In regular proxy mode, authentication and peek+splice works fine.
> Note that peek+splice does not require Squid CA certificates on the
> clients.
>



With peek+splce I block urls without CA certificates on the clients?
Remember I mean urls, not only domains!


>
> - Block certains urls
>>
>> Is that possible with squid+ufwdbguard?
>>
>
> ufdbGuard works always, independent if Squid uses interception or not.
> The issue is the messages that a browser displays for the end user (see
> earlier email).
>
> Marcus
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
--
Sergio Belkin
LPIC-2 Certified - http://www.lpi.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160609/a6a18297/attachment.htm>

From squid3 at treenet.co.nz  Fri Jun 10 03:12:28 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 10 Jun 2016 15:12:28 +1200
Subject: [squid-users] Peek'n Splice (ssl_bump) and authentication
 Somewhat OT: Content Filter with https
In-Reply-To: <CABZC=5xiTELifcJyQJfg+_x+iBxAwu+gLKmypevr0ROd1OKfFg@mail.gmail.com>
References: <CABZC=5y8rWTheVxXKXy7k5us3uuixcxGz2ay=uYKPpjbNvK3xA@mail.gmail.com>
 <5758AA80.7090905@urlfilterdb.com>
 <CABZC=5xiTELifcJyQJfg+_x+iBxAwu+gLKmypevr0ROd1OKfFg@mail.gmail.com>
Message-ID: <2e861581-30fa-6730-91b9-41d544fad7cd@treenet.co.nz>

On 10/06/2016 2:26 p.m., Sergio Belkin wrote:
> 2016-06-08 20:30 GMT-03:00 Marcus Kool <marcus.kool at urlfilterdb.com>:
> 
>>
>>
>> On 06/08/2016 07:53 PM, Sergio Belkin wrote:
>>
>>>
>>> Thanks Eliezer, good summary. I've changed the subject to reflect better
>>> the issue. As far I undestand from documention one can bump https only by
>>> interception.
>>>
>>
>> No.  ssl-bump works very well with regular proxy mode, i.e. the browsers
>> configure the address and port of the proxy or use PAC.
>>
>> But what about if one Windows user login against an Active Directory, will
>>> the authenticacion work to use the proxy?
>>>
>>> I mean, what I'd want is:
>>>
>>> - Only users of an Active Directory can use the proxy
>>>
>>
>> In regular proxy mode, authentication and peek+splice works fine.
>> Note that peek+splice does not require Squid CA certificates on the
>> clients.
>>
> 
> 
> 
> With peek+splce I block urls without CA certificates on the clients?
> Remember I mean urls, not only domains!

The *URL* is buried inside the encryption.

The server hostname (aka 'domain' to some) is available in the
plain-text metadata.

Peek+Splice only uses the metadata. No decryption.

So ... *URL* is never available when splice'ing traffic regardless of
what you do to the clients.


Amos



From ahmed.zaeem at netstream.ps  Fri Jun 10 08:54:16 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Fri, 10 Jun 2016 11:54:16 +0300
Subject: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot
	bind	socket FD 782 to [::]: (2) No such file or directory
In-Reply-To: <04bd01d1c295$316b8260$94428720$@ngtech.co.il>
References: <8B8C7545-E090-4014-AA00-7FCD55FE04C9@netstream.ps>
 <00a601d1c1e3$d8bd8110$8a388330$@ngtech.co.il>
 <43CF45E5-FA7D-432D-96EF-DA8DEA443667@netstream.ps>
 <04bd01d1c295$316b8260$94428720$@ngtech.co.il>
Message-ID: <F655691F-C599-4194-9530-FD03BC0CC850@netstream.ps>

hi eliezer
=============================================
1- selinux is disabled
[root at localhost ~]# sestatus
SELinux status:                 disabled
[root at localhost ~]# 

2-
i have the PID file with permission to squid
[root at localhost ~]# ls -l /var/run/squid.pid 
-rw-r--r-- 1 squid squid 5 Jun 10 04:45 /var/run/squid.pid
[root at localhost ~]# 

but here i don?t see the file /var/run/squid ??.i used to see file called /var/run/squid not /var/run/squid.pid

i also tried to add directive to squid.conf ==> pid_filename /var/run/squid.pid

but i have the same errror

3-im using kernel default for Centos 7 and it do support IPV6 , i didn?t compile any kernel 



agin the error that i have is :
kid2| commBind: Cannot bind	socket FD 782 to [::]: (2) No such file or directory


not 
kid2| commBind: Cannot bind	socket FD 782 to [::]: permission denied


here is again compile options :

>> Squid Cache: Version 3.5.2
>> Service Name: squid
>> configure options:  '--prefix=/usr' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc' '--enable-cachemgr-hostname=Ahmad-Allzaeem' '--localstatedir=/var' '--libexecdir=/lib/squid' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm' '--enable-digest-auth-helpers=ldap,password' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' '' '--with-large-files' '--with-default-user=squid' --with-openssl' '--enable-snmp' '--with-included-ltdl' '--disable-arch-native'
>> [root at localhost ~]# 


and here is squid.conf 

[root at localhost ~]# cat /etc/squid/squid.conf | less
cache deny all
#################
#pid_filename /var/run/squid.pid
####################
visible_hostname squid
cache_effective_user squid
cache_effective_group squid
####################################
#workers 2
########################################################################
# Lockdown Procedures
auth_param basic program /lib/squid/basic_ncsa_auth /etc/squid/squid_user
acl ncsa_users proxy_auth REQUIRED
http_access allow ncsa_users
############################
f
####################################
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
max_filedescriptors 131072
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 1234
##############################


thank you 
> On Jun 10, 2016, at 12:23 AM, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> 
> Hey Ahmad,
>  
> I do not why you are suffering from the issue.
> The options are:
> -          Selinux
> -          Permission
> -          Directory existence
> -          Self compiled kernel withtou IPV6 support
> -          And many more
> From my point of view I suggest first to try my RPMs as it works with many setups.
> Second try to simplify your squid.conf and share it.
> What addition to squid.conf make this issue appear?
> Also have you tried looking at the SMP FAQ at:
> http://wiki.squid-cache.org/Features/SmpScale#Cannot_bind_socket_FD_NN_to_.5B::.5D:_.2813.29_Permission_denied <http://wiki.squid-cache.org/Features/SmpScale#Cannot_bind_socket_FD_NN_to_.5B::.5D:_.2813.29_Permission_denied>
>  
> If this and the RPMs do not help you to resolve the issue then share a very simplified squid.conf and we can try to see if there is some direction for help.
>  
> Eliezer
>  
> ----
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>
> <image003.png>
>  
> From: --Ahmad-- [mailto:ahmed.zaeem at netstream.ps] 
> Sent: Thursday, June 9, 2016 10:55 AM
> To: Eliezer Croitoru
> Cc: Squid Users
> Subject: Re: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory
>  
> hi Mr elieizer
>  
> i already check the mailing list  before i post here , but no luck with me .
>  
>  
> i don?t think its a permissions issue 
>  
>  
> i have the file /var/run/squid is missing 
>  
> and  there is /var/run/squid.pid
>  
> and it has the squid permissions 
>  
>  
> kindly can you point to me  if i figure it out using compile options ? or from the os side ?
>  
>  
> thank you 
>> On Jun 9, 2016, at 3:14 AM, Eliezer Croitoru <eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>> wrote:
>>  
>> Hey Ahmed,
>>  
>> Have you tried my RPMs for CentOS 7?
>> The latest version is 3.5.19 which is far more advanced then 3.5.2 and it works for me..
>> This issue you mentioned has lots of references in the mailing list history.
>> I assume it's a simple issue.
>> If you can try my RPMs and verify that you get the same error with them I will try to see if I can reproduce the issue.
>>  
>> Eliezer
>>  
>> ----
>> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
>> Linux System Administrator
>> Mobile: +972-5-28704261
>> Email: eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>
>> <image001.png>
>>  
>> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org <mailto:squid-users-bounces at lists.squid-cache.org>] On Behalf Of --Ahmad--
>> Sent: Thursday, June 9, 2016 1:57 AM
>> To: Squid Users
>> Subject: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory
>>  
>> here is error when i run squid :
>> 2016/06/08 18:48:29 kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory
>> 2016/06/08 18:48:29 kid1| HTCP Disabled.
>> 2016/06/08 18:48:29 kid1| Squid plugin modules loaded: 0
>> 2016/06/08 18:48:29 kid1| Adaptation support is off.
>> 2016/06/08 18:48:29 kid1| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory
>>  
>>  
>> I?m sure if i use it on centos 6 it work?...
>>  
>> but on centos 7 with same compile options it don?t allow me to use workers SMP
>>  
>> any help ?
>>  
>>  
>> Squid Cache: Version 3.5.2
>> Service Name: squid
>> configure options:  '--prefix=/usr' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc' '--enable-cachemgr-hostname=Ahmad-Allzaeem' '--localstatedir=/var' '--libexecdir=/lib/squid' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm' '--enable-digest-auth-helpers=ldap,password' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' '' '--with-large-files' '--with-default-user=squid' --with-openssl' '--enable-snmp' '--with-included-ltdl' '--disable-arch-native'
>> [root at localhost ~]# 
>>  
>>  
>>  
>>  
>> thank   you 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160610/86b1d908/attachment.htm>

From ahmed.zaeem at netstream.ps  Fri Jun 10 09:13:33 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Fri, 10 Jun 2016 12:13:33 +0300
Subject: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot
	bind	socket FD 782 to [::]: (2) No such file or directory
In-Reply-To: <F655691F-C599-4194-9530-FD03BC0CC850@netstream.ps>
References: <8B8C7545-E090-4014-AA00-7FCD55FE04C9@netstream.ps>
 <00a601d1c1e3$d8bd8110$8a388330$@ngtech.co.il>
 <43CF45E5-FA7D-432D-96EF-DA8DEA443667@netstream.ps>
 <04bd01d1c295$316b8260$94428720$@ngtech.co.il>
 <F655691F-C599-4194-9530-FD03BC0CC850@netstream.ps>
Message-ID: <01C770D0-AE4C-4454-B585-23532AD232C3@netstream.ps>

again , if i use the  same steps below  on centos 6 is works fine  without any issue 

> On Jun 10, 2016, at 11:54 AM, --Ahmad-- <ahmed.zaeem at netstream.ps> wrote:
> 
> hi eliezer
> =============================================
> 1- selinux is disabled
> [root at localhost ~]# sestatus
> SELinux status:                 disabled
> [root at localhost ~]# 
> 
> 2-
> i have the PID file with permission to squid
> [root at localhost ~]# ls -l /var/run/squid.pid 
> -rw-r--r-- 1 squid squid 5 Jun 10 04:45 /var/run/squid.pid
> [root at localhost ~]# 
> 
> but here i don?t see the file /var/run/squid ??.i used to see file called /var/run/squid not /var/run/squid.pid
> 
> i also tried to add directive to squid.conf ==> pid_filename /var/run/squid.pid
> 
> but i have the same errror
> 
> 3-im using kernel default for Centos 7 and it do support IPV6 , i didn?t compile any kernel 
> 
> 
> 
> agin the error that i have is :
> kid2| commBind: Cannot bind	socket FD 782 to [::]: (2) No such file or directory
> 
> 
> not 
> kid2| commBind: Cannot bind	socket FD 782 to [::]: permission denied
> 
> 
> here is again compile options :
> 
>>> Squid Cache: Version 3.5.2
>>> Service Name: squid
>>> configure options:  '--prefix=/usr' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc' '--enable-cachemgr-hostname=Ahmad-Allzaeem' '--localstatedir=/var' '--libexecdir=/lib/squid' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm' '--enable-digest-auth-helpers=ldap,password' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' '' '--with-large-files' '--with-default-user=squid' --with-openssl' '--enable-snmp' '--with-included-ltdl' '--disable-arch-native'
>>> [root at localhost ~]# 
> 
> 
> and here is squid.conf 
> 
> [root at localhost ~]# cat /etc/squid/squid.conf | less
> cache deny all
> #################
> #pid_filename /var/run/squid.pid
> ####################
> visible_hostname squid
> cache_effective_user squid
> cache_effective_group squid
> ####################################
> #workers 2
> ########################################################################
> # Lockdown Procedures
> auth_param basic program /lib/squid/basic_ncsa_auth /etc/squid/squid_user
> acl ncsa_users proxy_auth REQUIRED
> http_access allow ncsa_users
> ############################
> f
> ####################################
> #
> # Recommended minimum configuration:
> #
> 
> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
> max_filedescriptors 131072
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> 
> #
> # Recommended minimum Access Permission configuration:
> #
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
> 
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
> 
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> #http_access deny to_localhost
> 
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> 
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
> 
> # And finally deny all other access to this proxy
> http_access deny all
> 
> # Squid normally listens to port 3128
> http_port 1234
> ##############################
> 
> 
> thank you 
>> On Jun 10, 2016, at 12:23 AM, Eliezer Croitoru <eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>> wrote:
>> 
>> Hey Ahmad,
>>  
>> I do not why you are suffering from the issue.
>> The options are:
>> -          Selinux
>> -          Permission
>> -          Directory existence
>> -          Self compiled kernel withtou IPV6 support
>> -          And many more
>> From my point of view I suggest first to try my RPMs as it works with many setups.
>> Second try to simplify your squid.conf and share it.
>> What addition to squid.conf make this issue appear?
>> Also have you tried looking at the SMP FAQ at:
>> http://wiki.squid-cache.org/Features/SmpScale#Cannot_bind_socket_FD_NN_to_.5B::.5D:_.2813.29_Permission_denied <http://wiki.squid-cache.org/Features/SmpScale#Cannot_bind_socket_FD_NN_to_.5B::.5D:_.2813.29_Permission_denied>
>>  
>> If this and the RPMs do not help you to resolve the issue then share a very simplified squid.conf and we can try to see if there is some direction for help.
>>  
>> Eliezer
>>  
>> ----
>> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
>> Linux System Administrator
>> Mobile: +972-5-28704261
>> Email: eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>
>> <image003.png>
>>  
>> From: --Ahmad-- [mailto:ahmed.zaeem at netstream.ps <mailto:ahmed.zaeem at netstream.ps>] 
>> Sent: Thursday, June 9, 2016 10:55 AM
>> To: Eliezer Croitoru
>> Cc: Squid Users
>> Subject: Re: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory
>>  
>> hi Mr elieizer
>>  
>> i already check the mailing list  before i post here , but no luck with me .
>>  
>>  
>> i don?t think its a permissions issue 
>>  
>>  
>> i have the file /var/run/squid is missing 
>>  
>> and  there is /var/run/squid.pid
>>  
>> and it has the squid permissions 
>>  
>>  
>> kindly can you point to me  if i figure it out using compile options ? or from the os side ?
>>  
>>  
>> thank you 
>>> On Jun 9, 2016, at 3:14 AM, Eliezer Croitoru <eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>> wrote:
>>>  
>>> Hey Ahmed,
>>>  
>>> Have you tried my RPMs for CentOS 7?
>>> The latest version is 3.5.19 which is far more advanced then 3.5.2 and it works for me..
>>> This issue you mentioned has lots of references in the mailing list history.
>>> I assume it's a simple issue.
>>> If you can try my RPMs and verify that you get the same error with them I will try to see if I can reproduce the issue.
>>>  
>>> Eliezer
>>>  
>>> ----
>>> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
>>> Linux System Administrator
>>> Mobile: +972-5-28704261
>>> Email: eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>
>>> <image001.png>
>>>  
>>> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org <mailto:squid-users-bounces at lists.squid-cache.org>] On Behalf Of --Ahmad--
>>> Sent: Thursday, June 9, 2016 1:57 AM
>>> To: Squid Users
>>> Subject: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory
>>>  
>>> here is error when i run squid :
>>> 2016/06/08 18:48:29 kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory
>>> 2016/06/08 18:48:29 kid1| HTCP Disabled.
>>> 2016/06/08 18:48:29 kid1| Squid plugin modules loaded: 0
>>> 2016/06/08 18:48:29 kid1| Adaptation support is off.
>>> 2016/06/08 18:48:29 kid1| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory
>>>  
>>>  
>>> I?m sure if i use it on centos 6 it work?...
>>>  
>>> but on centos 7 with same compile options it don?t allow me to use workers SMP
>>>  
>>> any help ?
>>>  
>>>  
>>> Squid Cache: Version 3.5.2
>>> Service Name: squid
>>> configure options:  '--prefix=/usr' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc' '--enable-cachemgr-hostname=Ahmad-Allzaeem' '--localstatedir=/var' '--libexecdir=/lib/squid' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm' '--enable-digest-auth-helpers=ldap,password' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' '' '--with-large-files' '--with-default-user=squid' --with-openssl' '--enable-snmp' '--with-included-ltdl' '--disable-arch-native'
>>> [root at localhost ~]# 
>>>  
>>>  
>>>  
>>>  
>>> thank   you 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160610/78f4ab7a/attachment.htm>

From marcus.kool at urlfilterdb.com  Fri Jun 10 10:26:46 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Fri, 10 Jun 2016 07:26:46 -0300
Subject: [squid-users] Peek'n Splice (ssl_bump) and authentication
 Somewhat OT: Content Filter with https
In-Reply-To: <CABZC=5xiTELifcJyQJfg+_x+iBxAwu+gLKmypevr0ROd1OKfFg@mail.gmail.com>
References: <CABZC=5y8rWTheVxXKXy7k5us3uuixcxGz2ay=uYKPpjbNvK3xA@mail.gmail.com>
 <5758AA80.7090905@urlfilterdb.com>
 <CABZC=5xiTELifcJyQJfg+_x+iBxAwu+gLKmypevr0ROd1OKfFg@mail.gmail.com>
Message-ID: <575A95E6.5060106@urlfilterdb.com>



On 06/09/2016 11:26 PM, Sergio Belkin wrote:
>
>
> 2016-06-08 20:30 GMT-03:00 Marcus Kool <marcus.kool at urlfilterdb.com <mailto:marcus.kool at urlfilterdb.com>>:
>
>
>
>     On 06/08/2016 07:53 PM, Sergio Belkin wrote:
>
>
>         Thanks Eliezer, good summary. I've changed the subject to reflect better the issue. As far I undestand from documention one can bump https only by interception.
>
>
>     No.  ssl-bump works very well with regular proxy mode, i.e. the browsers configure the address and port of the proxy or use PAC.
>
>         But what about if one Windows user login against an Active Directory, will the authenticacion work to use the proxy?
>
>         I mean, what I'd want is:
>
>         - Only users of an Active Directory can use the proxy
>
>
>     In regular proxy mode, authentication and peek+splice works fine.
>     Note that peek+splice does not require Squid CA certificates on the clients.
>
>
>
>
> With peek+splce I block urls without CA certificates on the clients? Remember I mean urls, not only domains!

No. To block HTTPS URLs one needs ssl_bump with peek+bump mode for all blocked URLs (see my message of June 8).
With peek+bump ufdbGuard can block anything you like and produce understandable messages to the end user.

Marcus

>         - Block certains urls
>
>         Is that possible with squid+ufwdbguard?
>
>
>     ufdbGuard works always, independent if Squid uses interception or not.
>     The issue is the messages that a browser displays for the end user (see earlier email).
>
>     Marcus


From squid3 at treenet.co.nz  Fri Jun 10 10:55:14 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 10 Jun 2016 22:55:14 +1200
Subject: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot
 bind socket FD 782 to [::]: (2) No such file or directory
In-Reply-To: <01C770D0-AE4C-4454-B585-23532AD232C3@netstream.ps>
References: <8B8C7545-E090-4014-AA00-7FCD55FE04C9@netstream.ps>
 <00a601d1c1e3$d8bd8110$8a388330$@ngtech.co.il>
 <43CF45E5-FA7D-432D-96EF-DA8DEA443667@netstream.ps>
 <04bd01d1c295$316b8260$94428720$@ngtech.co.il>
 <F655691F-C599-4194-9530-FD03BC0CC850@netstream.ps>
 <01C770D0-AE4C-4454-B585-23532AD232C3@netstream.ps>
Message-ID: <a08610af-2998-dbfd-e857-da6f790a5276@treenet.co.nz>

On 10/06/2016 9:13 p.m., --Ahmad-- wrote:
> again , if i use the  same steps below  on centos 6 is works fine  without any issue 
> 

That means nothing. CentOS is based on RHEL, whic on ly gets updated
periodically. There are about five years worth of changes across the
entire IOS and everything installed with it between v6 and v7.

Obviously something in those changes to CentOS does not work with that
very old version of Squid and seems to work fine with the newer Squid.


>> On Jun 10, 2016, at 11:54 AM, --Ahmad-- wrote:
>>
>> hi eliezer
>> =============================================
>> 1- selinux is disabled
>> [root at localhost ~]# sestatus
>> SELinux status:                 disabled
>> [root at localhost ~]# 
>>
>> 2-
>> i have the PID file with permission to squid
>> [root at localhost ~]# ls -l /var/run/squid.pid 
>> -rw-r--r-- 1 squid squid 5 Jun 10 04:45 /var/run/squid.pid
>> [root at localhost ~]# 

squid.pid should not exist when Squid is shutdown.

You should delete it and ensure that Squid is started by the root user,
which already should have permission to alter the /var/run directory and
create the squid.pid file correctly.

>>
>> but here i don?t see the file /var/run/squid ??.i used to see file called /var/run/squid not /var/run/squid.pid
>>

/var/run/squid should be a directory. Its where the state data gets
placed now. It may be unused in your installation or just not.

squid.pid may be under /var/run/squid or /var/run depending on your
installation.

/run may be used instead of /var/run if you have a new enough system.


** For pre-packaged Squid. Don't worry about these unless Squid
explicitly complains. Just go with what the package installation chose.


** For custom builds, the "make install" action should create
/var/run/squid directory. If for some reason it does not (such as newly
building an already deprecated old Squid version - which one shodul
never do anyway). You may need to create it yourself, and assign
squid:squid ownership.


>> i also tried to add directive to squid.conf ==> pid_filename /var/run/squid.pid
>>
>> but i have the same errror
>>
>> 3-im using kernel default for Centos 7 and it do support IPV6 , i didn?t compile any kernel 
>>
>>
>>
>> agin the error that i have is :
>> kid2| commBind: Cannot bind	socket FD 782 to [::]: (2) No such file or directory
>>

As mentioned in the URL Eliezer reference you to already
(<http://wiki.squid-cache.org/Features/SmpScale#Cannot_bind_socket_FD_NN_to_.5B::.5D:_.2813.29_Permission_denied>)
that error is about the SMP UDS sockets.
More specifically it is about the system shared memory device (/dev/shm).

* Some systems need the /dev/shm device to be explicitly turned on
during startup. Check if it is enabled in your system and if not, what
you have to do to fix that. Hints in the wiki.

* Check that /dev/shm path is owned by root. Only the OS itself should
be doing things in there. Programs like Squid use kernel syscalls to
make changes.

* Older Squid like yours could leave UDS sockets after a crash or broken
config abort. Check that /dev/shm/ does not contain any "files" starting
with "squid-" or owned by Squid when Squid is shutdown.
 If some exist use 'rm' to remove them and try restarting Squid.


>>
>> not 
>> kid2| commBind: Cannot bind	socket FD 782 to [::]: permission denied
>>
>>
>> here is again compile options :
>>
>>>> Squid Cache: Version 3.5.2
>>>> Service Name: squid
>>>> configure options:  '--prefix=/usr' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc'
>> '--enable-cachemgr-hostname=Ahmad-Allzaeem'

... unusual URL for accessing management reports:
     http://Ahmad-Allzaeem/squid-internal-mgr/

'cachemgr' means the Squid cache management API, specifically the
cachemgr.cgi tool. Not an administrators name.


>> '--localstatedir=/var' '--libexecdir=/lib/squid' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm' '--enable-digest-auth-helpers=ldap,password' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' '' '--with-large-files' '--with-default-user=squid' --with-openssl' '--enable-snmp' '--with-included-ltdl' '--disable-arch-native'
>>>> [root at localhost ~]# 
>>
>>
>> and here is squid.conf 
>>
>> [root at localhost ~]# cat /etc/squid/squid.conf | less
>> cache deny all
>> #################
>> #pid_filename /var/run/squid.pid
>> ####################
>> visible_hostname squid
>> cache_effective_user squid
>> cache_effective_group squid

You should not need to use cache_effective_group. Particularly if you
are wanting to use NTLM or Kerberos related functionality with Squid.


>> ####################################
>> #workers 2
>> ########################################################################
>> # Lockdown Procedures
>> auth_param basic program /lib/squid/basic_ncsa_auth /etc/squid/squid_user
>> acl ncsa_users proxy_auth REQUIRED
>> http_access allow ncsa_users
>> ############################
>> f

Please move the auth and http_access lines down to below where it says:
"
 # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
"

Doing complex things like auth up here at the top of the config your
proxy is made more vulnerable than it should be to various DoS and
traffic smuggling attacks.


<snip>
>> #
>> # Recommended minimum Access Permission configuration:
>> #
>> # Deny requests to certain unsafe ports
>> http_access deny !Safe_ports
>>
>> # Deny CONNECT to other than secure SSL ports
>> http_access deny CONNECT !SSL_ports
>>
>> # Only allow cachemgr access from localhost
>> http_access allow localhost manager
>> http_access deny manager
>>
>> # We strongly recommend the following be uncommented to protect innocent
>> # web applications running on the proxy server who think the only
>> # one who can access services on "localhost" is a local user
>> #http_access deny to_localhost
>>
>> #
>> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
>> #
>>
>> # Example rule allowing access from your local networks.
>> # Adapt localnet in the ACL section to list your (internal) IP networks
>> # from where browsing should be allowed
>> http_access allow localnet
>> http_access allow localhost
>>
>> # And finally deny all other access to this proxy
>> http_access deny all
>>
>> # Squid normally listens to port 3128
>> http_port 1234

Why 1234? 3128 has been formally registered for Squid use.


Amos


From ahmed.zaeem at netstream.ps  Fri Jun 10 13:57:36 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Fri, 10 Jun 2016 16:57:36 +0300
Subject: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot
	bind socket FD 782 to [::]: (2) No such file or directory
In-Reply-To: <a08610af-2998-dbfd-e857-da6f790a5276@treenet.co.nz>
References: <8B8C7545-E090-4014-AA00-7FCD55FE04C9@netstream.ps>
 <00a601d1c1e3$d8bd8110$8a388330$@ngtech.co.il>
 <43CF45E5-FA7D-432D-96EF-DA8DEA443667@netstream.ps>
 <04bd01d1c295$316b8260$94428720$@ngtech.co.il>
 <F655691F-C599-4194-9530-FD03BC0CC850@netstream.ps>
 <01C770D0-AE4C-4454-B585-23532AD232C3@netstream.ps>
 <a08610af-2998-dbfd-e857-da6f790a5276@treenet.co.nz>
Message-ID: <EC684244-FD63-48D7-970D-87700A331055@netstream.ps>


hi amos thanks for revision I?m willing to do those changes latter.


regarding to /dev/shm

it didn?t correct anything ?..

again 

my error is cache.log is ===> kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory

and its totally different  one than the errors in the SMP wiki


I?m sure its something regarding to the pid squid file !!


also during squid is working ? i don?t see the /var/run/squid file !!!

what does that mean ?

i still see /var/run/squid.pid with permission squid;squid


is there a method to see where is the pid file running and point squid to use it ?
may be changed on  centos  7 ???


cheers

> On Jun 10, 2016, at 1:55 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 10/06/2016 9:13 p.m., --Ahmad-- wrote:
>> again , if i use the  same steps below  on centos 6 is works fine  without any issue 
>> 
> 
> That means nothing. CentOS is based on RHEL, whic on ly gets updated
> periodically. There are about five years worth of changes across the
> entire IOS and everything installed with it between v6 and v7.
> 
> Obviously something in those changes to CentOS does not work with that
> very old version of Squid and seems to work fine with the newer Squid.
> 
> 
>>> On Jun 10, 2016, at 11:54 AM, --Ahmad-- wrote:
>>> 
>>> hi eliezer
>>> =============================================
>>> 1- selinux is disabled
>>> [root at localhost ~]# sestatus
>>> SELinux status:                 disabled
>>> [root at localhost ~]# 
>>> 
>>> 2-
>>> i have the PID file with permission to squid
>>> [root at localhost ~]# ls -l /var/run/squid.pid 
>>> -rw-r--r-- 1 squid squid 5 Jun 10 04:45 /var/run/squid.pid
>>> [root at localhost ~]# 
> 
> squid.pid should not exist when Squid is shutdown.
> 
> You should delete it and ensure that Squid is started by the root user,
> which already should have permission to alter the /var/run directory and
> create the squid.pid file correctly.
> 
>>> 
>>> but here i don?t see the file /var/run/squid ??.i used to see file called /var/run/squid not /var/run/squid.pid
>>> 
> 
> /var/run/squid should be a directory. Its where the state data gets
> placed now. It may be unused in your installation or just not.
> 
> squid.pid may be under /var/run/squid or /var/run depending on your
> installation.
> 
> /run may be used instead of /var/run if you have a new enough system.
> 
> 
> ** For pre-packaged Squid. Don't worry about these unless Squid
> explicitly complains. Just go with what the package installation chose.
> 
> 
> ** For custom builds, the "make install" action should create
> /var/run/squid directory. If for some reason it does not (such as newly
> building an already deprecated old Squid version - which one shodul
> never do anyway). You may need to create it yourself, and assign
> squid:squid ownership.
> 
> 
>>> i also tried to add directive to squid.conf ==> pid_filename /var/run/squid.pid
>>> 
>>> but i have the same errror
>>> 
>>> 3-im using kernel default for Centos 7 and it do support IPV6 , i didn?t compile any kernel 
>>> 
>>> 
>>> 
>>> agin the error that i have is :
>>> kid2| commBind: Cannot bind	socket FD 782 to [::]: (2) No such file or directory
>>> 
> 
> As mentioned in the URL Eliezer reference you to already
> (<http://wiki.squid-cache.org/Features/SmpScale#Cannot_bind_socket_FD_NN_to_.5B::.5D:_.2813.29_Permission_denied>)
> that error is about the SMP UDS sockets.
> More specifically it is about the system shared memory device (/dev/shm).
> 
> * Some systems need the /dev/shm device to be explicitly turned on
> during startup. Check if it is enabled in your system and if not, what
> you have to do to fix that. Hints in the wiki.
> 
> * Check that /dev/shm path is owned by root. Only the OS itself should
> be doing things in there. Programs like Squid use kernel syscalls to
> make changes.
> 
> * Older Squid like yours could leave UDS sockets after a crash or broken
> config abort. Check that /dev/shm/ does not contain any "files" starting
> with "squid-" or owned by Squid when Squid is shutdown.
> If some exist use 'rm' to remove them and try restarting Squid.
> 
> 
>>> 
>>> not 
>>> kid2| commBind: Cannot bind	socket FD 782 to [::]: permission denied
>>> 
>>> 
>>> here is again compile options :
>>> 
>>>>> Squid Cache: Version 3.5.2
>>>>> Service Name: squid
>>>>> configure options:  '--prefix=/usr' '--includedir=/include' '--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc'
>>> '--enable-cachemgr-hostname=Ahmad-Allzaeem'
> 
> ... unusual URL for accessing management reports:
>     http://Ahmad-Allzaeem/squid-internal-mgr/
> 
> 'cachemgr' means the Squid cache management API, specifically the
> cachemgr.cgi tool. Not an administrators name.
> 
> 
>>> '--localstatedir=/var' '--libexecdir=/lib/squid' '--disable-maintainer-mode' '--disable-dependency-tracking' '--disable-silent-rules' '--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' '--mandir=/usr/share/man' '--enable-inline' '--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap' '--enable-delay-pools' '--enable-cache-digests' '--enable-underscores' '--enable-icap-client' '--enable-follow-x-forwarded-for' '--enable-auth' '--enable-basic-auth-helpers=LDAP,MSNT,NCSA,PAM,SASL,SMB,YP,DB,POP3,getpwnam,squid_radius_auth,multi-domain-NTLM' '--enable-ntlm-auth-helpers=smb_lm' '--enable-digest-auth-helpers=ldap,password' '--enable-negotiate-auth-helpers=squid_kerb_auth' '--enable-esi' '--disable-translation' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' '' '--with-large-files' '--with-default-user=squid' --with-openssl' '--enable-snmp' '--with-included-ltdl' '--disable-arch-native'
>>>>> [root at localhost ~]# 
>>> 
>>> 
>>> and here is squid.conf 
>>> 
>>> [root at localhost ~]# cat /etc/squid/squid.conf | less
>>> cache deny all
>>> #################
>>> #pid_filename /var/run/squid.pid
>>> ####################
>>> visible_hostname squid
>>> cache_effective_user squid
>>> cache_effective_group squid
> 
> You should not need to use cache_effective_group. Particularly if you
> are wanting to use NTLM or Kerberos related functionality with Squid.
> 
> 
>>> ####################################
>>> #workers 2
>>> ########################################################################
>>> # Lockdown Procedures
>>> auth_param basic program /lib/squid/basic_ncsa_auth /etc/squid/squid_user
>>> acl ncsa_users proxy_auth REQUIRED
>>> http_access allow ncsa_users
>>> ############################
>>> f
> 
> Please move the auth and http_access lines down to below where it says:
> "
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> "
> 
> Doing complex things like auth up here at the top of the config your
> proxy is made more vulnerable than it should be to various DoS and
> traffic smuggling attacks.
> 
> 
> <snip>
>>> #
>>> # Recommended minimum Access Permission configuration:
>>> #
>>> # Deny requests to certain unsafe ports
>>> http_access deny !Safe_ports
>>> 
>>> # Deny CONNECT to other than secure SSL ports
>>> http_access deny CONNECT !SSL_ports
>>> 
>>> # Only allow cachemgr access from localhost
>>> http_access allow localhost manager
>>> http_access deny manager
>>> 
>>> # We strongly recommend the following be uncommented to protect innocent
>>> # web applications running on the proxy server who think the only
>>> # one who can access services on "localhost" is a local user
>>> #http_access deny to_localhost
>>> 
>>> #
>>> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
>>> #
>>> 
>>> # Example rule allowing access from your local networks.
>>> # Adapt localnet in the ACL section to list your (internal) IP networks
>>> # from where browsing should be allowed
>>> http_access allow localnet
>>> http_access allow localhost
>>> 
>>> # And finally deny all other access to this proxy
>>> http_access deny all
>>> 
>>> # Squid normally listens to port 3128
>>> http_port 1234
> 
> Why 1234? 3128 has been formally registered for Squid use.
> 
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160610/984745be/attachment.htm>

From squid3 at treenet.co.nz  Fri Jun 10 15:33:23 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 11 Jun 2016 03:33:23 +1200
Subject: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot
 bind socket FD 782 to [::]: (2) No such file or directory
In-Reply-To: <EC684244-FD63-48D7-970D-87700A331055@netstream.ps>
References: <8B8C7545-E090-4014-AA00-7FCD55FE04C9@netstream.ps>
 <00a601d1c1e3$d8bd8110$8a388330$@ngtech.co.il>
 <43CF45E5-FA7D-432D-96EF-DA8DEA443667@netstream.ps>
 <04bd01d1c295$316b8260$94428720$@ngtech.co.il>
 <F655691F-C599-4194-9530-FD03BC0CC850@netstream.ps>
 <01C770D0-AE4C-4454-B585-23532AD232C3@netstream.ps>
 <a08610af-2998-dbfd-e857-da6f790a5276@treenet.co.nz>
 <EC684244-FD63-48D7-970D-87700A331055@netstream.ps>
Message-ID: <6d66feff-f2ac-3ea6-2a2c-78a1f09c029b@treenet.co.nz>

On 11/06/2016 1:57 a.m., --Ahmad-- wrote:
> 
> hi amos thanks for revision I?m willing to do those changes latter.
> 
> 
> regarding to /dev/shm
> 
> it didn?t correct anything ?..
> 
> again 
> 
> my error is cache.log is ===> kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory
> 
> and its totally different  one than the errors in the SMP wiki
> 

It is a slight variation on the error listed in the wiki page as "Cannot
bind socket FD NNN [::]" everything else on the line is situation
variable texts.

> 
> I?m sure its something regarding to the pid squid file !!
> 
> 
> also during squid is working ? i don?t see the /var/run/squid file !!!
> 
> what does that mean ?

Means you are still using old Squid version and did not create it after
installing Squid:
 mkdir /var/run/squid && chown squid:squid /var/run/squid

That is all.

> 
> i still see /var/run/squid.pid with permission squid;squid
> 
> 
> is there a method to see where is the pid file running and point squid to use it ?
> may be changed on  centos  7 ???

The PID file goes where Squid creates it. Your problem is not related to it.


Amos



From ahmed.zaeem at netstream.ps  Fri Jun 10 16:15:04 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Fri, 10 Jun 2016 19:15:04 +0300
Subject: [squid-users] Centos 7 squid 3.5.2 / kid2| commBind: Cannot
	bind socket FD 782 to [::]: (2) No such file or directory
In-Reply-To: <6d66feff-f2ac-3ea6-2a2c-78a1f09c029b@treenet.co.nz>
References: <8B8C7545-E090-4014-AA00-7FCD55FE04C9@netstream.ps>
 <00a601d1c1e3$d8bd8110$8a388330$@ngtech.co.il>
 <43CF45E5-FA7D-432D-96EF-DA8DEA443667@netstream.ps>
 <04bd01d1c295$316b8260$94428720$@ngtech.co.il>
 <F655691F-C599-4194-9530-FD03BC0CC850@netstream.ps>
 <01C770D0-AE4C-4454-B585-23532AD232C3@netstream.ps>
 <a08610af-2998-dbfd-e857-da6f790a5276@treenet.co.nz>
 <EC684244-FD63-48D7-970D-87700A331055@netstream.ps>
 <6d66feff-f2ac-3ea6-2a2c-78a1f09c029b@treenet.co.nz>
Message-ID: <06B39509-FCAF-4AA7-925A-1F52FFD54FB5@netstream.ps>

Amos you rock 

thank you it worked 

appreciate your time much  much much you & eleiezer

kind regards




> On Jun 10, 2016, at 6:33 PM, Amos Jeffries <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>> wrote:
> 
> mkdir /var/run/squid && chown squid:squid /var/run/squid

> On Jun 10, 2016, at 6:33 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 11/06/2016 1:57 a.m., --Ahmad-- wrote:
>> 
>> hi amos thanks for revision I?m willing to do those changes latter.
>> 
>> 
>> regarding to /dev/shm
>> 
>> it didn?t correct anything ?..
>> 
>> again 
>> 
>> my error is cache.log is ===> kid2| commBind: Cannot bind socket FD 782 to [::]: (2) No such file or directory
>> 
>> and its totally different  one than the errors in the SMP wiki
>> 
> 
> It is a slight variation on the error listed in the wiki page as "Cannot
> bind socket FD NNN [::]" everything else on the line is situation
> variable texts.
> 
>> 
>> I?m sure its something regarding to the pid squid file !!
>> 
>> 
>> also during squid is working ? i don?t see the /var/run/squid file !!!
>> 
>> what does that mean ?
> 
> Means you are still using old Squid version and did not create it after
> installing Squid:
> mkdir /var/run/squid && chown squid:squid /var/run/squid
> 
> That is all.
> 
>> 
>> i still see /var/run/squid.pid with permission squid;squid
>> 
>> 
>> is there a method to see where is the pid file running and point squid to use it ?
>> may be changed on  centos  7 ???
> 
> The PID file goes where Squid creates it. Your problem is not related to it.
> 
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160610/ab600977/attachment.htm>

From bruno.larini at riosoft.com.br  Fri Jun 10 21:33:50 2016
From: bruno.larini at riosoft.com.br (Bruno de Paula Larini)
Date: Fri, 10 Jun 2016 18:33:50 -0300
Subject: [squid-users] Skype makes Squid with ssl_bump crash
In-Reply-To: <3d51f028-bc84-1e59-5066-2b6f9ab603e8@treenet.co.nz>
References: <d2f4711f-21ce-21bb-1f0d-f4071f8143b8@riosoft.com.br>
 <3d51f028-bc84-1e59-5066-2b6f9ab603e8@treenet.co.nz>
Message-ID: <8f3a4859-4b80-2e36-f637-547a2b010a4d@riosoft.com.br>

Em 09/06/2016 19:36, Amos Jeffries escreveu:
> On 10/06/2016 7:20 a.m., Bruno de Paula Larini wrote:
>> Hi list.
>>
>> I'm experiencing some crashes on Squid workers and eventually on the
>> parent process while using a mixed authenticated/intercepted ssl_bump +
>> Skype (7.21.0.100). After searching for some clues, I've found this:
>>
>> Changes to squid-3.5.9 (17 Sep 2015):
>>      ...
>>      - Bug 4309: crash during Skype login
>>      ...
>>
>> I'm running the exact Squid 3.5.9, provided by official Fedora 23 (x64)
>> repositories and noticed this behavior only while using Skype.
> Please update to 3.5.19, if that does not work you may need to update to
> the 4.0.11 coming out today.
>
> NP: the bug only relates to issues that were occuring in how Skype and
> TLS operated in Sep 2015. The arms race has changed a lot month-on-month
> since then.
>
> Amos

Hi Amos, thanks for the reply.
Updating to 3.5.19 seems to have solved the issue.
Thanks a lot!


From squid3 at treenet.co.nz  Sat Jun 11 05:14:26 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 11 Jun 2016 17:14:26 +1200
Subject: [squid-users] pinger crash - Bad opcode: 112
In-Reply-To: <CAG6MAzRSmL_9wxCYoVjhQggC-BXSGeeScpPtaMBgBN6M8uQ9yw@mail.gmail.com>
References: <CAG6MAzT+JQP0Bd+UDHN3zwigU6W8H6oGYxXdn3iVhuYqU=qZpg@mail.gmail.com>
 <bdb614cb-27fe-ad3a-5780-e6f9245e495d@treenet.co.nz>
 <CAG6MAzQpEQNA1nv_GfNcWvQTccA7ZejyCoOiscsQS51C5FBcdQ@mail.gmail.com>
 <a176619d-3ca6-132b-f72e-40723be158ed@treenet.co.nz>
 <CAG6MAzRSmL_9wxCYoVjhQggC-BXSGeeScpPtaMBgBN6M8uQ9yw@mail.gmail.com>
Message-ID: <aa120a29-edb0-52b8-375e-09cb1f0453ac@treenet.co.nz>

On 3/06/2016 3:47 a.m., Tomas Mozes wrote:
> On Wed, Jun 1, 2016 at 1:53 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
>> On 31/05/2016 9:56 p.m., Tomas Mozes wrote:
>>> On Thu, May 26, 2016 at 8:04 AM, Amos Jeffries wrote:
>>>
>>>> On 24/05/2016 7:52 p.m., Tomas Mozes wrote:
>>>>> Hello,
>>>>> on two different squid servers I've observed a crash of pinger. First
>> it
>>>>> appeared on version 3.5.15 and later on version 3.5.17.
>>>>>
>>>>> Cache.log contains these lines:
>>>>>
>>>>> (pinger): Address.cc:671: void Ip::Address::getAddrInfo(addrinfo*&,
>> int)
>>>>> const: Assertion `false' failed.
>>>>> 2016/05/14 21:55:25 kid1| Bad opcode: 112 from
>>>>> [6661:6c73:6522:2061:7420:6c69:6e65:2036]
>>>>> 2016/05/14 21:59:13 kid1| recv: (111) Connection refused
>>>>> 2016/05/14 21:59:13 kid1| Closing Pinger socket on FD 17
>>>>>
>>>>> On both servers, that IPv6 address was the same -
>>>>> 6661:6c73:6522:2061:7420:6c69:6e65:2036
>>>>>
>>>>
>>>> That is the hexadecimal representation of the error:
>>>>  false" at line 6
>>>>
>>>> Which means that your kernel is producing garbage when asked to resolve
>>>> an IPv6 address or respond to an ICMPv6 packet.
>>>>
>>>
>>> Cannot we prevent Squid from crashing in these cases?
>>>
>>
>> Squid is not crashing. The pinger is. Squid continues with degraded
>> service latency.
>>
> 
> Yes, sorry, I wasn't specific. I meant like some part of Squid, not the
> Squid caching process itself.
> 
> 
>> What kind of continued operations would you expect a program to do when
>> it discovers at least some portion of its RAM has been filled with
>> garbage by the system kernel?
>>
> 
> 
> In the worst case - wouldn't it be possible for the master process to
> restart it?
> 

For most helpers that is exacty what happens, but with frequent enough
failures killing Squid. That latter bit has been part of the problem
preventing this one being the same so far.

This paticular helper needs root permission to use ICMP sockets. It has
a long history of being installed with wrong ownership and access
permissions, which cause it to exit early. So the most common form of it
dying is not a situation in which Squid can reasonably restart it - or
risks almost certainly dying itself.

Thesituation has been improving in recent years though. So I'm hopeful
we will get there eventually. If you wish to sponsor some work to speed
that up it could be made a configurable action.


> 
>>
>> Now cross your fingers and pray that no other programs on your whole
>> system (network, if you did the same "disable" on other machines) are
>> behaving badly in secret when given the garbage by the kernel like
>> Squid's pinger was.
>>
> 
> You know, the strange thing is I only found those strings on google
> attached with Squid. No other place. If it's a general issue in the Linux
> kernel, then it's been there for years, unnoticed. And as I mentioned
> before, it happened on two machines, separate from each other, in
> completely different data-centers with the same error message.
> 
> What would you suggest?
> 

I suggest enabling IPv6 within your network. :-) It can be firewalled if
you want it not to be used, same as any other digital service.

That will also give you a way to measure whether you have reached
tipping point of it being useful. The global traffic passed 12% last
weekend and growth rate is somewhere between exponential and hyperbolic
despite a lot of networks still clinging to IPv4.

Amos



From squid3 at treenet.co.nz  Sat Jun 11 05:27:16 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 11 Jun 2016 17:27:16 +1200
Subject: [squid-users] How to analyse squid memory usage
In-Reply-To: <553AEA23-D6C9-446A-A903-698973563E40@getbusi.com>
References: <B60DFE6C-9BA8-42CA-9B57-A2460517A35F@getbusi.com>
 <085044c5-9a62-8b6f-47e6-cee4410dfac9@treenet.co.nz>
 <421A4120-10F7-4694-94AF-B66C3CDF1D3E@getbusi.com>
 <E0EA512C-DC76-4D74-B95F-2635BF58C523@getbusi.com>
 <5F7F29D5-F9E2-4FD2-9B9B-25DFE9E02E48@getbusi.com>
 <208c097a-5b42-da61-fc49-f4065b035833@treenet.co.nz>
 <553AEA23-D6C9-446A-A903-698973563E40@getbusi.com>
Message-ID: <6c350418-df9c-1752-88c2-d7fc9071312d@treenet.co.nz>

On 2/06/2016 6:13 p.m., Dan Charlesworth wrote:
> No worries?thanks for following up on it!
> 
> That?s very interesting, about the concurrent requests, because the ?normal? report does around 80% more requests per day than the ?leaky? one ? a few hundred thousand vs a couple of million.
> 
> Does this CLOSE_WAIT sockets issue have a bug being tracked or anything like that? I?ve probably overlooked the discussion on the list.
> 

If you have SSL-Bump operating, even just in peek+splice actions. Then
its probably <http://bugs.squid-cache.org/show_bug.cgi?id=4508>. But
might also be 3715 or 4526, or something not in bugzilla.

Amos



From eenghooda at yahoo.com  Sat Jun 11 16:41:55 2016
From: eenghooda at yahoo.com (Eng Hooda)
Date: Sat, 11 Jun 2016 16:41:55 +0000 (UTC)
Subject: [squid-users] Response Blocked from sites with multiple IPs
	(Host	Header Forgery)
References: <1099117872.1110445.1465663315984.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1099117872.1110445.1465663315984.JavaMail.yahoo@mail.yahoo.com>

Thank you for your response .
here is the details you requested.

OS : Debian 8
How I intercept : iptables , then http_port 3128 transparent  , https_port 3127 transparent ssl_bump ....
DNS is the same for proxy and client : 8.8.8.8 , 8.8.4.4 , no DNS caching service
squid version : latest self compiled (I ran make install)

Best Regards,
Eng Hooda

--------------------------------------------
On Thu, 6/9/16, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:

 Subject: RE: [squid-users] Response Blocked from sites with multiple IPs (Host	Header Forgery)
 To: "'Eng Hooda'" <eenghooda at yahoo.com>, squid-users at lists.squid-cache.org
 Date: Thursday, June 9, 2016, 11:29 PM
 
 RE: [squid-users]
 Response Blocked from sites with multiple IPs (Host	Header
 Forgery)
 
 
 Hey,
 
 There
 are couple basic missing parts about the
 setup.
 
 -?????? What OS are you
 using?
 
 -?????? How do you Intercept the
 connections? Tproxy? Intercept?
 
 -?????? Do
 the client use the same DNS server as the proxy
 server?
 
 -?????? Are you using some kind
 of local caching service? Such as
 Bind\Unbound\PowerDNS\else?
 
 -?????? Is it a self compiled
 version of squid or from a package?
 
 All the
 above can affect the way we can help you.
 
 Eliezer
 
 
 
 
 
 ----
 
 Eliezer
 Croitoru
 
 Linux
 System Administrator
 
 Mobile:
 +972-5-28704261
 
 Email:
 eliezer at ngtech.co.il
 
 
 
 
 
 -----Original
 Message-----
 
 From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
 On Behalf Of Eng Hooda
 
 Sent: Thursday, June 9, 2016 9:09 PM
 
 To: squid-users at lists.squid-cache.org
 
 Subject: [squid-users] Response Blocked from sites with
 multiple IPs (Host Header Forgery)
 
 Hello
 Squid Users,
 
 I have
 just started using squid less than a week ago
 .
 
 My
 setup is a transparent proxy with sslbump , I peek for media
 streaming sites then terminate their connections then I
 splice all.
 
 I
 noticed that some https sites (not all of the time) , does
 not respond , when Investigated I found the following in
 cache.log :
 
 
 
 3105
 2016/06/09 12:45:40.630 kid1| SECURITY ALERT: on URL:
 mail.live.com:443
 
 3106
 2016/06/09 12:45:40.631 kid1| SECURITY ALERT: Host header
 forgery detected on local=157.55.43.16:443
 remote=10.3.1.80:58328 FD 94 flags=33 (local IP does not
 match any domain IP)
 
 3330
 2016/06/09 13:26:26.676 kid1| SECURITY ALERT: on URL:
 mail.live.com:443
 
 3331
 2016/06/09 13:26:26.676 kid1| SECURITY ALERT: Host header
 forgery detected on local=157.56.122.210:443
 remote=10.3.1.80:58414 FD 141 flags=33 (local IP does not
 match any domain IP)
 
 3530
 2016/06/09 13:49:49.481 kid1| SECURITY ALERT: on URL:
 mail.live.com:443
 
 3531
 2016/06/09 13:49:49.481 kid1| SECURITY ALERT: Host header
 forgery detected on local=157.55.43.17:443
 remote=10.3.1.80:58616 FD 119 flags=33 (local IP does not
 match any domain IP)
 
 
 
 I
 searched for a solution which lead me to (1st result)? :?
 
 
 http://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery
 
 
 
 I read
 it and it seems to be a dead end .
 
 
 
 What I
 understood that client requested page from a certain IP ,
 reply came from another IP then it's blocked for
 security reasons.
 
 
 
 Well I
 tried to nslookup the mentioned IPs , and all of them are
 sub domains of mail.live.com nslookup
 157.55.43.16
 
 Server:?
 google-public-dns-a.google.com
 
 Address:? 8.8.8.8
 
 
 
 Name:???
 origin.du111w.dub111.mail.live.com
 
 Address:? 157.55.43.16
 
 
 
 nslookup 157.56.122.210
 
 Server:?
 google-public-dns-a.google.com
 
 Address:? 8.8.8.8
 
 
 
 Name:???
 origin.du125w.dub125.mail.live.com
 
 Address:? 157.56.122.210
 
 
 
 nslookup 157.55.43.17
 
 Server:?
 google-public-dns-a.google.com
 
 Address:? 8.8.8.8
 
 
 
 Name:???
 origin.du112w.dub112.mail.live.com
 
 Address:? 157.55.43.17
 
 
 
 also
 tried to nslookup mail.live.com , and every time I get
 different IPs
 
 
 
 nslookup mail.live.com
 
 Server:?
 google-public-dns-a.google.com
 
 Address:? 8.8.8.8
 
 
 
 Non-authoritative answer:
 
 Name:???
 dispatch.kahuna.glbdns2.microsoft.com
 
 Addresses:? 157.56.195.156
 
 157.55.235.51
 
 Aliases:? mail.live.com
 
 
 
 nslookup mail.live.com
 
 Server:?
 google-public-dns-a.google.com
 
 Address:? 8.8.8.8
 
 
 
 Non-authoritative answer:
 
 Name:???
 dispatch.kahuna.glbdns2.microsoft.com
 
 Addresses:? 157.55.235.49
 
 157.56.122.210
 
 Aliases:? mail.live.com
 
 
 
 nslookup mail.live.com
 
 Server:?
 google-public-dns-a.google.com
 
 Address:? 8.8.8.8
 
 
 
 Non-authoritative answer:
 
 Name:???
 dispatch.kahuna.glbdns2.microsoft.com
 
 Addresses:? 157.55.43.16
 
 157.55.43.17
 
 Aliases:? mail.live.com
 
 
 
 nslookup mail.live.com
 
 Server:?
 google-public-dns-a.google.com
 
 Address:? 8.8.8.8
 
 
 
 Non-authoritative answer:
 
 Name:???
 dispatch.kahuna.glbdns2.microsoft.com
 
 Addresses:? 157.55.235.51
 
 157.56.122.208
 
 Aliases:? mail.live.com
 
 
 
 nslookup mail.live.com
 
 Server:?
 google-public-dns-a.google.com
 
 Address:? 8.8.8.8
 
 
 
 Non-authoritative answer:
 
 Name:???
 dispatch.kahuna.glbdns2.microsoft.com
 
 Addresses:? 157.55.235.51
 
 157.56.122.208
 
 Aliases:? mail.live.com
 
 
 
 nslookup mail.live.com
 
 Server:?
 google-public-dns-a.google.com
 
 Address:? 8.8.8.8
 
 
 
 Non-authoritative answer:
 
 Name:???
 dispatch.kahuna.glbdns2.microsoft.com
 
 Addresses:? 157.55.235.48
 
 157.55.235.49
 
 Aliases:? mail.live.com
 
 
 
 nslookup mail.live.com
 
 Server:?
 google-public-dns-a.google.com
 
 Address:? 8.8.8.8
 
 
 
 Non-authoritative answer:
 
 Name:???
 dispatch.kahuna.glbdns2.microsoft.com
 
 Addresses:? 157.55.235.49
 
 157.56.122.210
 
 Aliases:? mail.live.com
 
 
 
 So
 can't squid learn that big sites have a lot of IPs
 mapped as sub-domains of it , and they may reply from any of
 them ?
 
 
 
 Or just
 provide an option to disable this problematic security
 feature ?
 
 
 
 or Am I
 missing something here ?
 
 
 
 Thanks
 You all in advance.
 
 
 
 Best
 Regards,
 
 
 
 Eng
 Hooda
 
 _______________________________________________
 
 squid-users mailing list
 
 squid-users at lists.squid-cache.org
 
 http://lists.squid-cache.org/listinfo/squid-users
 


From eenghooda at yahoo.com  Sat Jun 11 16:44:20 2016
From: eenghooda at yahoo.com (Eng Hooda)
Date: Sat, 11 Jun 2016 16:44:20 +0000 (UTC)
Subject: [squid-users] Response Blocked from sites with multiple IPs (Host
 Header Forgery)
References: <1035869449.1134290.1465663460094.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1035869449.1134290.1465663460094.JavaMail.yahoo@mail.yahoo.com>

Thank You for your response.
What is the best way to setup recursive resolver ?

Best Regards,
Eng Hooda

--------------------------------------------
On Fri, 6/10/16, Amos Jeffries <squid3 at treenet.co.nz> wrote:

 Subject: Re: [squid-users] Response Blocked from sites with multiple IPs (Host Header Forgery)
 To: squid-users at lists.squid-cache.org
 Date: Friday, June 10, 2016, 12:54 AM
 
 On 10/06/2016 6:09 a.m.,
 Eng Hooda wrote:
 > Hello Squid Users,
 > I have just started using squid less than
 a week ago .
 > My setup is a transparent
 proxy with sslbump , I peek for media streaming sites then
 terminate their connections then I splice all.
 > I noticed that some https sites (not all
 of the time) , does not respond , when Investigated I found
 the following in cache.log :
 > 
 > 3105 2016/06/09 12:45:40.630 kid1|
 SECURITY ALERT: on URL: mail.live.com:443
 > 3106 2016/06/09 12:45:40.631 kid1|
 SECURITY ALERT: Host header forgery detected on
 local=157.55.43.16:443 remote=10.3.1.80:58328 FD 94 flags=33
 (local IP does not match any domain IP)
 >
 3330 2016/06/09 13:26:26.676 kid1| SECURITY ALERT: on URL:
 mail.live.com:443
 > 3331 2016/06/09
 13:26:26.676 kid1| SECURITY ALERT: Host header forgery
 detected on local=157.56.122.210:443 remote=10.3.1.80:58414
 FD 141 flags=33 (local IP does not match any domain IP)
 > 3530 2016/06/09 13:49:49.481 kid1|
 SECURITY ALERT: on URL: mail.live.com:443
 > 3531 2016/06/09 13:49:49.481 kid1|
 SECURITY ALERT: Host header forgery detected on
 local=157.55.43.17:443 remote=10.3.1.80:58616 FD 119
 flags=33 (local IP does not match any domain IP)
 > 
 > I searched for a
 solution which lead me to (1st result)? :? 
 > http://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery
 > 
 > I read it and it
 seems to be a dead end .
 > 
 > What I understood that client requested
 page from a certain IP , reply came from another IP then
 it's blocked for security reasons.
 >
 
 > 
 > Well I tried to
 nslookup the mentioned IPs , and all of them are sub domains
 of mail.live.com
 
 No, all of
 them claim to be in their reverse-DNS responses. That is
 just
 the IP address owners view of things.
 In the case of an attack its the
 attackers
 opinion about what you should believe. Not safe.
 
 Forward-DNS results which
 provide the domain owners authoritative list
 of what IPs they are using. Say a different
 message contradicting those
 reverse-DNS
 results ...
 
 
 > also tried to nslookup mail.live.com , and
 every time I get different IPs
 > 
 
 Exactly. So do Squid and the
 client. Which means Squid is almost always
 unable to see the IP the client is contacting
 as being a valid one for
 that domain.
 
 
 > nslookup mail.live.com
 > Server:?
 google-public-dns-a.google.com
 >
 Address:? 8.8.8.8
 > 
 
 It is a problem caused by
 Google DNS.
 
 The best way to
 get around it is to setup a recursive resolver on your
 network that is used by both Squid and clients.
 Diverting the client
 port 53 traffic to it
 if necessary.
 
 If you wish
 to use Google DNS after having that available, then
 8.8.8.8
 should be setup as a parent of that
 local resolver. Not as something
 Squid or
 client contact separately.
 
 That setup makes the google DNS results more
 often be cached in the
 shared resolver for
 long enough that Squid can see it when it does the
 validation steps.
 
 NP: there are other causes of this known,
 related to connection
 persistence, and
 SSL-Bump SNI being validated. They are bugs in Squid
 and still being worked on fixing. So dont
 expect the above to solve all
 instances of
 it.
 
 Amos
 
 _______________________________________________
 squid-users mailing list
 squid-users at lists.squid-cache.org
 http://lists.squid-cache.org/listinfo/squid-users


From eenghooda at yahoo.com  Sun Jun 12 15:34:11 2016
From: eenghooda at yahoo.com (Eng Hooda)
Date: Sun, 12 Jun 2016 15:34:11 +0000 (UTC)
Subject: [squid-users] Redirect after sslbump teminate
References: <2030677513.1354103.1465745651092.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <2030677513.1354103.1465745651092.JavaMail.yahoo@mail.yahoo.com>

Hello Squid Users,
I have searched for this but I could not find an answer.
After I peek for media streaming sites using sslbump , I terminate the connection on match , which produces secure connection failed on the client browser .
Is there a way to redirect to another page like an error page or access denied page instead ?

Thank you all in advance.

Best Regards,
Eng Hooda


From marcus.kool at urlfilterdb.com  Sun Jun 12 18:37:00 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Sun, 12 Jun 2016 15:37:00 -0300
Subject: [squid-users] Redirect after sslbump teminate
In-Reply-To: <2030677513.1354103.1465745651092.JavaMail.yahoo@mail.yahoo.com>
References: <2030677513.1354103.1465745651092.JavaMail.yahoo.ref@mail.yahoo.com>
 <2030677513.1354103.1465745651092.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <575DABCC.7060800@urlfilterdb.com>



On 06/12/2016 12:34 PM, Eng Hooda wrote:
> Hello Squid Users,
> I have searched for this but I could not find an answer.
> After I peek for media streaming sites using sslbump , I terminate the connection on match , which produces secure connection failed on the client browser .
> Is there a way to redirect to another page like an error page or access denied page instead ?

Redirecting HTTPS is _only_ possible if you use ssl-bump in the peek+bump mode, meaning that all devices must have the Squid CA certificate.
On top of that, there are a number of sites which have several issues and do not work with peek+bump.

Marcus

> Thank you all in advance.
>
> Best Regards,
> Eng Hooda


From eliezer at ngtech.co.il  Sun Jun 12 18:59:34 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 12 Jun 2016 21:59:34 +0300
Subject: [squid-users] Response Blocked from sites with multiple IPs
	(Host Header Forgery)
In-Reply-To: <1035869449.1134290.1465663460094.JavaMail.yahoo@mail.yahoo.com>
References: <1035869449.1134290.1465663460094.JavaMail.yahoo.ref@mail.yahoo.com>
 <1035869449.1134290.1465663460094.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <036201d1c4dc$8f9682b0$aec38810$@ngtech.co.il>

Hey,

There are couple options to do that.
Since you are using Debian 8 the most used are:
-	Bind
-	Unbound
They both have a very simple installation and configuration.
The first step would be to let squid access the caching service.
If you can point your clients to this specific DNS host it would be good but if not and you are able to Intercept DNS traffic,
you can try to see how Interception of all 8.8.8.8 and other dns services works.
You can use the iptables REDIRECT which is similar to what you might use in\for squid.
The next tutorial is for CentOS but have the needed configuration snippets that would work with any Unbound installation:
http://www.tecmint.com/setup-dns-cache-server-in-centos-7/
And another one which looks a bit different
https://calomel.org/unbound_dns.html

And another guide for ubnutu on using Bind as a caching dns service:
https://www.digitalocean.com/community/tutorials/how-to-configure-bind-as-a-caching-or-forwarding-dns-server-on-ubuntu-14-04

Which should work almost the same for Debian.

If you need more details let me know.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Eng Hooda
Sent: Saturday, June 11, 2016 7:44 PM
To: squid-users at lists.squid-cache.org; Amos Jeffries
Subject: [squid-users] Response Blocked from sites with multiple IPs (Host Header Forgery)

Thank You for your response.
What is the best way to setup recursive resolver ?

Best Regards,
Eng Hooda

--------------------------------------------
On Fri, 6/10/16, Amos Jeffries <squid3 at treenet.co.nz> wrote:

 Subject: Re: [squid-users] Response Blocked from sites with multiple IPs (Host Header Forgery)
 To: squid-users at lists.squid-cache.org
 Date: Friday, June 10, 2016, 12:54 AM
 
 On 10/06/2016 6:09 a.m.,
 Eng Hooda wrote:
 > Hello Squid Users,
 > I have just started using squid less than  a week ago .
 > My setup is a transparent
 proxy with sslbump , I peek for media streaming sites then  terminate their connections then I splice all.
 > I noticed that some https sites (not all  of the time) , does not respond , when Investigated I found  the following in cache.log :
 >
 > 3105 2016/06/09 12:45:40.630 kid1|
 SECURITY ALERT: on URL: mail.live.com:443  > 3106 2016/06/09 12:45:40.631 kid1|  SECURITY ALERT: Host header forgery detected on
 local=157.55.43.16:443 remote=10.3.1.80:58328 FD 94 flags=33  (local IP does not match any domain IP)  >
 3330 2016/06/09 13:26:26.676 kid1| SECURITY ALERT: on URL:
 mail.live.com:443
 > 3331 2016/06/09
 13:26:26.676 kid1| SECURITY ALERT: Host header forgery  detected on local=157.56.122.210:443 remote=10.3.1.80:58414  FD 141 flags=33 (local IP does not match any domain IP)  > 3530 2016/06/09 13:49:49.481 kid1|  SECURITY ALERT: on URL: mail.live.com:443  > 3531 2016/06/09 13:49:49.481 kid1|  SECURITY ALERT: Host header forgery detected on
 local=157.55.43.17:443 remote=10.3.1.80:58616 FD 119
 flags=33 (local IP does not match any domain IP)  >  > I searched for a  solution which lead me to (1st result)  :  > http://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery
 >
 > I read it and it
 seems to be a dead end .
 >
 > What I understood that client requested  page from a certain IP , reply came from another IP then  it's blocked for security reasons.
 >
 
 >
 > Well I tried to
 nslookup the mentioned IPs , and all of them are sub domains  of mail.live.com
 
 No, all of
 them claim to be in their reverse-DNS responses. That is  just  the IP address owners view of things.
 In the case of an attack its the
 attackers
 opinion about what you should believe. Not safe.
 
 Forward-DNS results which
 provide the domain owners authoritative list  of what IPs they are using. Say a different  message contradicting those  reverse-DNS  results ...
 
 
 > also tried to nslookup mail.live.com , and  every time I get different IPs  > 
 
 Exactly. So do Squid and the
 client. Which means Squid is almost always  unable to see the IP the client is contacting  as being a valid one for  that domain.
 
 
 > nslookup mail.live.com
 > Server:
 google-public-dns-a.google.com
 >
 Address:  8.8.8.8
 > 
 
 It is a problem caused by
 Google DNS.
 
 The best way to
 get around it is to setup a recursive resolver on your  network that is used by both Squid and clients.
 Diverting the client
 port 53 traffic to it
 if necessary.
 
 If you wish
 to use Google DNS after having that available, then
 8.8.8.8
 should be setup as a parent of that
 local resolver. Not as something
 Squid or
 client contact separately.
 
 That setup makes the google DNS results more  often be cached in the  shared resolver for  long enough that Squid can see it when it does the  validation steps.
 
 NP: there are other causes of this known,  related to connection  persistence, and  SSL-Bump SNI being validated. They are bugs in Squid  and still being worked on fixing. So dont  expect the above to solve all  instances of  it.
 
 Amos
 
 _______________________________________________
 squid-users mailing list
 squid-users at lists.squid-cache.org
 http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160612/7da989f7/attachment.htm>

From eenghooda at yahoo.com  Mon Jun 13 08:51:35 2016
From: eenghooda at yahoo.com (Eng Hooda)
Date: Mon, 13 Jun 2016 08:51:35 +0000 (UTC)
Subject: [squid-users] Redirect after sslbump teminate
In-Reply-To: <575DABCC.7060800@urlfilterdb.com>
References: <2030677513.1354103.1465745651092.JavaMail.yahoo.ref@mail.yahoo.com>
 <2030677513.1354103.1465745651092.JavaMail.yahoo@mail.yahoo.com>
 <575DABCC.7060800@urlfilterdb.com>
Message-ID: <2036326368.1608396.1465807895700.JavaMail.yahoo@mail.yahoo.com>

Thank You for your response.
Using the certificate is something I want to avoid.
So I think it's acceptable as it is now.

I searched again and found an explanation , copied below FYI.

"
To serve an HTTP error to an SSL client, Squid has to establish an SSL
connection with that client.
"






On Sunday, June 12, 2016 8:37 PM, Marcus Kool <marcus.kool at urlfilterdb.com> wrote:


On 06/12/2016 12:34 PM, Eng Hooda wrote:
> Hello Squid Users,
> I have searched for this but I could not find an answer.
> After I peek for media streaming sites using sslbump , I terminate the connection on match , which produces secure connection failed on the client browser .
> Is there a way to redirect to another page like an error page or access denied page instead ?

Redirecting HTTPS is _only_ possible if you use ssl-bump in the peek+bump mode, meaning that all devices must have the Squid CA certificate.
On top of that, there are a number of sites which have several issues and do not work with peek+bump.

Marcus


> Thank you all in advance.
>
> Best Regards,
> Eng Hooda
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From Antony.Stone at squid.open.source.it  Mon Jun 13 09:01:34 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 13 Jun 2016 11:01:34 +0200
Subject: [squid-users] Redirect after sslbump teminate
In-Reply-To: <2036326368.1608396.1465807895700.JavaMail.yahoo@mail.yahoo.com>
References: <2030677513.1354103.1465745651092.JavaMail.yahoo.ref@mail.yahoo.com>
 <575DABCC.7060800@urlfilterdb.com>
 <2036326368.1608396.1465807895700.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <201606131101.34813.Antony.Stone@squid.open.source.it>

On Monday 13 June 2016 at 10:51:35, Eng Hooda wrote:

> Thank You for your response.
> Using the certificate is something I want to avoid.
> So I think it's acceptable as it is now.
> 
> I searched again and found an explanation , copied below FYI.
> 
> "To serve an HTTP error to an SSL client, Squid has to establish an SSL
> connection with that client."

Yes, but the point is that the client originally requested an SSL connection 
to a particular server, and if it gets a reply (even though it is an SSL 
reply) back from something with a certificate which doesn't match that server, 
the client will complain, showing a security alert to the user.


Antony.

-- 
"this restriction will not apply in the event of the occurrence (certified by 
the United States Centers for Disease Control or successor body) of a 
widespread viral infection transmitted via bites or contact with bodily fluids 
that causes human corpses to reanimate and seek to consume living human flesh, 
blood, brain or nerve tissue and is likely to result in the fall of organized 
civilization."

 - https://aws.amazon.com/service-terms/ paragraph 57.10

                                                   Please reply to the list;
                                                         please *don't* CC me.


From eenghooda at yahoo.com  Mon Jun 13 09:13:44 2016
From: eenghooda at yahoo.com (Eng Hooda)
Date: Mon, 13 Jun 2016 09:13:44 +0000 (UTC)
Subject: [squid-users] Response Blocked from sites with multiple IPs
 (Host Header Forgery)
In-Reply-To: <036201d1c4dc$8f9682b0$aec38810$@ngtech.co.il>
References: <1035869449.1134290.1465663460094.JavaMail.yahoo.ref@mail.yahoo.com>
 <1035869449.1134290.1465663460094.JavaMail.yahoo@mail.yahoo.com>
 <036201d1c4dc$8f9682b0$aec38810$@ngtech.co.il>
Message-ID: <525163454.1614890.1465809224974.JavaMail.yahoo@mail.yahoo.com>

Thank You Amos Jeffries & Eliezer Croitoru


Issue was resolved.

Here is how it's was resolved FYI.
I installed pdns_recursor and redirected all DNS queries to it.
But it didn't work directly , I have a MikroTik router in the path to squid that I discovered it replies to DNS queries even when allow-remote-requests is set to false.
MikroTik router used 8.8.8.8,8.8.4.4 as DNS so I changed it pdns_recursor.

and it worked !

Now nslookup from any where returns the same IPs Every time.

Thank you again.

Best Regards,
Eng Hooda





On Sunday, June 12, 2016 8:59 PM, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:



RE: [squid-users] Response Blocked from sites with multiple IPs (Host Header Forgery)
Hey,
There are couple options to do that.
Since you are using Debian8 the most used are:
-      Bind
-       Unbound
They both have a very simple installation and configuration.
The first step would be to let squid access the caching service.
If you can point your clients to this specific DNS host it would be good but if not and you are able toIntercept DNS traffic,
you can try to see how Interception of all8.8.8.8 and other dns services works.
You can use the iptables REDIRECT which is similar to what you might use in\for squid.
The next tutorial is for CentOS but have the needed configuration snippets that would work with any Unboundinstallation:
http://www.tecmint.com/setup-dns-cache-server-in-centos-7/
And another one which looks a bit different
https://calomel.org/unbound_dns.html
And another guide for ubnutu on using Bind as a caching dns service:
https://www.digitalocean.com/community/tutorials/how-to-configure-bind-as-a-caching-or-forwarding-dns-server-on-ubuntu-14-04
Which should work almost the same for Debian.
If you need more details let me know.
Eliezer
----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Eng Hooda
Sent: Saturday, June 11, 2016 7:44 PM
To: squid-users at lists.squid-cache.org; Amos Jeffries
Subject: [squid-users] Response Blocked from sites with multiple IPs (Host Header Forgery)
Thank You for your response.
What is the best way to setup recursive resolver ?
Best Regards,
Eng Hooda
--------------------------------------------
On Fri, 6/10/16, Amos Jeffries <squid3 at treenet.co.nz> wrote:
 Subject: Re: [squid-users] Response Blocked from sites with multiple IPs (Host Header Forgery)
 To: squid-users at lists.squid-cache.org
 Date: Friday, June 10, 2016, 12:54 AM
 
 On 10/06/2016 6:09 a.m.,
 Eng Hooda wrote:
 > Hello Squid Users,
 > I have just started using squid less than  a week ago .
 > My setup is a transparent
 proxy with sslbump , I peek for media streaming sites then  terminate their connections then I splice all.
 > I noticed that some https sites (not all  of the time) , does not respond , when Investigated I found  the following in cache.log :
 >
 > 3105 2016/06/09 12:45:40.630 kid1|
 SECURITY ALERT: on URL: mail.live.com:443  > 3106 2016/06/09 12:45:40.631 kid1|  SECURITY ALERT: Host header forgery detected on
 local=157.55.43.16:443 remote=10.3.1.80:58328 FD 94 flags=33  (local IP does not match any domain IP)  >
 3330 2016/06/09 13:26:26.676 kid1| SECURITY ALERT: on URL:
 mail.live.com:443
 > 3331 2016/06/09
 13:26:26.676 kid1| SECURITY ALERT: Host header forgery  detected on local=157.56.122.210:443 remote=10.3.1.80:58414  FD 141 flags=33 (local IP does not match any domain IP)  > 3530 2016/06/09 13:49:49.481 kid1|  SECURITY ALERT: on URL: mail.live.com:443  > 3531 2016/06/09 13:49:49.481 kid1|  SECURITY ALERT: Host header forgery detected on
 local=157.55.43.17:443 remote=10.3.1.80:58616 FD 119
 flags=33 (local IP does not match any domain IP)  >  > I searched for a  solution which lead me to (1st result)  :  > http://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery
 >
 > I read it and it
 seems to be a dead end .
 >
 > What I understood that client requested  page from a certain IP , reply came from another IP then  it's blocked for security reasons.
 >
 
 >
 > Well I tried to
 nslookup the mentioned IPs , and all of them are sub domains  of mail.live.com
 
 No, all of
 them claim to be in their reverse-DNS responses. That is  just  the IP address owners view of things.
 In the case of an attack its the
 attackers
 opinion about what you should believe. Not safe.
 
 Forward-DNS results which
 provide the domain owners authoritative list  of what IPs they are using. Say a different  message contradicting those  reverse-DNS  results ...
 
 
 > also tried to nslookup mail.live.com , and  every time I get different IPs  > 
 
 Exactly. So do Squid and the
 client. Which means Squid is almost always  unable to see the IP the client is contacting  as being a valid one for  that domain.
 
 
 > nslookup mail.live.com
 > Server:
 google-public-dns-a.google.com
 >
 Address:  8.8.8.8
 > 
 
 It is a problem caused by
 Google DNS.
 
 The best way to
 get around it is to setup a recursive resolver on your  network that is used by both Squid and clients.
 Diverting the client
 port 53 traffic to it
 if necessary.
 
 If you wish
 to use Google DNS after having that available, then
 8.8.8.8
 should be setup as a parent of that
 local resolver. Not as something
 Squid or
 client contact separately.
 
 That setup makes the google DNS results more  often be cached in the  shared resolver for  long enough that Squid can see it when it does the  validation steps.
 
 NP: there are other causes of this known,  related to connection  persistence, and  SSL-Bump SNI being validated. They are bugs in Squid  and still being worked on fixing. So dont  expect the above to solve all  instances of  it.
 
 Amos
 
 _______________________________________________
 squid-users mailing list
 squid-users at lists.squid-cache.org
 http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From fredbmail at free.fr  Mon Jun  6 11:23:17 2016
From: fredbmail at free.fr (FredB)
Date: Mon, 6 Jun 2016 13:23:17 +0200 (CEST)
Subject: [squid-users] Squid high memory usage
In-Reply-To: <863161884.249366540.1465208859108.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <706646918.249501891.1465212197439.JavaMail.root@zimbra4-e1.priv.proxad.net>


Capture with swap full 

             total       used       free     shared    buffers     cached
Mem:            63         62          0          0          2         19
-/+ buffers/cache:         40         22
Swap:            1          1          0
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Capture-squid.png
Type: image/png
Size: 115782 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160606/a0e5bbd0/attachment.png>

From squid3 at treenet.co.nz  Mon Jun 13 07:45:17 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 13 Jun 2016 19:45:17 +1200
Subject: [squid-users] [squid-announce] Squid 4.0.11 beta is available
Message-ID: <c89b122e-af2f-b8b2-24d5-1bb2dbe778d9@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-4.0.11 release!


This release is a bug fix release resolving several issues found in the
prior Squid releases.


The major changes to be aware of:


* HTTP/1.1: unfold mime header block

HTTP/1.0 allowed headers to be whitespace folded, which can lead to
problems like CVE-2016-4553 fixed in the previous release. RFC 7230 for
HTTP/1.1 now prohibits the practice and requires proxies to remove the
folding. This release of Squid does so and thus hardens all HTTP traffic
flowing through it against such attacks.

The squidclient tool -H option has also been extended to accept more
shell-escape characters which are useful in testing for those type of
issues.


* HTTP/1.1 chunked encoding improvements

 - Bug #4492: chunked parser needs to accept BWS after chunk size

This fixes issues interoperating with IBM servers which have been
identified as sending whitespace padding in the chunked encoding size
field when they should not.

 - Allow chunking the last HTTP response on a connection.

Previous Squid did not use chunked encoding when prior knowledge
indicated that the connection was to be closed immediately after the
message payload. This made some sense in reducing workload and delays,
but also leads to difficulty identifying connection related errors
sending those objects.

Squid will now always chunked encode messages with unknown length
payloads. This should reduce the number of unexpectedly hung connections
or truncated objects.


* TLS improvements

This release adds significant performance improvements to the SSL-Bump
features 'peek' action locating client handshake details such as SNI.

Initial experimental GnuTLS support for some functionality within the
squid binary has been turned on. squid.conf settings which have been
renamed in Squid-4 to begin with 'tls' rather than 'ssl' moniker have
GnuTLS support as well as OpenSSL support.
 However, be aware that only a very limited set of background actions
actually use GnuTLS. The most visible effect is squid.conf support.
Features such as listening https_port's, ssl-bump and TLS connections
still require OpenSSL.


* ie_refresh directive is removed

This directive was a workaround hack for MSIE 3, 4 and 5 behaviour.
Since those browser versions appear to be no longer in any significant
amount of use this hack has been removed to simplify HTTP message
processing.


* Deprecating SMB LanMan helpers

The SMB LanMan helpers have now been removed from the set which are
auto-detected and built by default. For the present their code is
retained and can be built by explicitly listing "SMB_LM" in the Basic or
NTLM authentication helpers list.

The LanMan authentication protocols were deprecated sometime around
1996. Any installations still using either of these helpers are
strongely encouraged to upgrade to another authentication system.


* Memory allocation bugs

Several more issues in the deep memory allocation layer of Squid have
been resolved. Most of these probably show up as error when free'ing
memory. We expect this to greatly stabilize Squid-4 in many environments
which have had memory related troubles with the Squid-3 series.



 All users of Squid-4.0.x are encouraged to upgrade to this release.

 All users of Squid-3 are encouraged to test this release out and plan
for upgrades where possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v4/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries

_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From Antony.Stone at squid.open.source.it  Mon Jun 13 10:53:11 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 13 Jun 2016 12:53:11 +0200
Subject: [squid-users] Squid high memory usage
In-Reply-To: <706646918.249501891.1465212197439.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <706646918.249501891.1465212197439.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <201606131253.11445.Antony.Stone@squid.open.source.it>

On Monday 06 June 2016 at 13:23:17, FredB wrote:

> Capture with swap full

> Tasks: 2740 total, 3 running, 2737 sleeping, 0 stopped, 0 zombie

Hm, isn't 2740 tasks rather a lot?  What are most of them?  With a load 
average of 0.81 it looks like maybe you have a very large number of child 
processes spawned and waiting for something to do, but no data for them to 
work on.

Maybe try reducing the number of processes (to something like 100-200 max.) 
and see if your machine still uses up all its swap space.



Antony.

-- 
Atheism is a non-prophet-making organisation.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Mon Jun 13 10:55:43 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 13 Jun 2016 16:55:43 +0600
Subject: [squid-users] Redirect after sslbump teminate
In-Reply-To: <201606131101.34813.Antony.Stone@squid.open.source.it>
References: <2030677513.1354103.1465745651092.JavaMail.yahoo.ref@mail.yahoo.com>
 <575DABCC.7060800@urlfilterdb.com>
 <2036326368.1608396.1465807895700.JavaMail.yahoo@mail.yahoo.com>
 <201606131101.34813.Antony.Stone@squid.open.source.it>
Message-ID: <71cd99d4-c101-0f27-a075-2a9a9ef5a409@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Yes no problem. Signs the certificate of the local web server with root
certificate the proxy, which is already in user's browser - and voila.


13.06.2016 15:01, Antony Stone ?????:
> On Monday 13 June 2016 at 10:51:35, Eng Hooda wrote:
>
>> Thank You for your response.
>> Using the certificate is something I want to avoid.
>> So I think it's acceptable as it is now.
>>
>> I searched again and found an explanation , copied below FYI.
>>
>> "To serve an HTTP error to an SSL client, Squid has to establish an SSL
>> connection with that client."
>
> Yes, but the point is that the client originally requested an SSL
connection
> to a particular server, and if it gets a reply (even though it is an SSL
> reply) back from something with a certificate which doesn't match that
server,
> the client will complain, showing a security alert to the user.
>
>
> Antony.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXXpEvAAoJENNXIZxhPexGbZUH/j0HGg0L3KWAbRIyGBQ1sa2b
X/oE+gU9gKZYaBfK7DOj+NbdR3zQ6hmxiONsmp7Be0L2S3Eis1816yP6Hyg9BHVb
HdtbIYL66akVULNev6TVf61KPAHNGVbeNGM6xjhMW/0jnRl/TJ/cVKsBzFFSvFg3
Gj5rEkOKsPEZLdkJccop/p99iufAtfwQW31FxRPFPOF6q2IgcIhgB5nm6T2yrnQV
kU/suCjsVQj2V35Y/ZDY88irvP1cn0NBbqyw870HV7WsOQYyh+5Kk3iOCwrQY4Mo
UWSLvDM/Qjm0YzESSng4tcs8XVPG6C0tbzzpLOOySlmB/gBhJimVfUS41s/QcIo=
=wiaW
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160613/64685322/attachment.key>

From Antony.Stone at squid.open.source.it  Mon Jun 13 10:59:16 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 13 Jun 2016 12:59:16 +0200
Subject: [squid-users] Redirect after sslbump teminate
In-Reply-To: <71cd99d4-c101-0f27-a075-2a9a9ef5a409@gmail.com>
References: <2030677513.1354103.1465745651092.JavaMail.yahoo.ref@mail.yahoo.com>
 <201606131101.34813.Antony.Stone@squid.open.source.it>
 <71cd99d4-c101-0f27-a075-2a9a9ef5a409@gmail.com>
Message-ID: <201606131259.16841.Antony.Stone@squid.open.source.it>

On Monday 13 June 2016 at 12:55:43, Yuri Voinov wrote:

> Yes no problem. Signs the certificate of the local web server with root
> certificate the proxy, which is already in user's browser - and voila.

True - or at least it would be if the OP hadn't said "Using the certificate is 
something I want to avoid."  :)


Antony.

> 13.06.2016 15:01, Antony Stone ?????:
> > On Monday 13 June 2016 at 10:51:35, Eng Hooda wrote:
> >> Thank You for your response.
> >> Using the certificate is something I want to avoid.
> >> So I think it's acceptable as it is now.
> >> 
> >> I searched again and found an explanation , copied below FYI.
> >> 
> >> "To serve an HTTP error to an SSL client, Squid has to establish an SSL
> >> connection with that client."
> > 
> > Yes, but the point is that the client originally requested an SSL
> > connection to a particular server, and if it gets a reply (even though it
> > is an SSL reply) back from something with a certificate which doesn't match
> > that server, the client will complain, showing a security alert to the
> > user.
> > 
> > 
> > Antony.

-- 
.evah I serutangis sseltniop tsom eht fo eno eb tsum sihT

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Mon Jun 13 11:10:01 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 13 Jun 2016 23:10:01 +1200
Subject: [squid-users] Squid high memory usage
In-Reply-To: <706646918.249501891.1465212197439.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <706646918.249501891.1465212197439.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <5f360fcd-2fe7-a11d-9c97-508936461553@treenet.co.nz>

On 6/06/2016 11:23 p.m., FredB wrote:
> 
> Capture with swap full 
> 
>              total       used       free     shared    buffers     cached
> Mem:            63         62          0          0          2         19
> -/+ buffers/cache:         40         22
> Swap:            1          1          0
> 

The image is showing the machine is nearing 64GB of RAM being used. With
~49% allocated to Squid and 50% allocated to other things.

Whatever that external memory user is you are lucky that Squid is not
using more. If it did the system would start swapping memory to disk,
and for Squid that is a very nasty situation leading directly to
terrible service times.

Amos



From jaap.dam at gmail.com  Mon Jun 13 12:29:33 2016
From: jaap.dam at gmail.com (Jaap Dam)
Date: Mon, 13 Jun 2016 14:29:33 +0200
Subject: [squid-users] Queue incoming requests when fetching from origin
Message-ID: <CAD0U=K13wKi4hytPvyBqUjdr+Thn90=R-RjE67ZG6ovE8QKo7w@mail.gmail.com>

Hi,

I've got a reliable but slow backend that sends cacheble responses. When I
run a manual test, I can see I miss the cache every one in a while and got
hits most of the time. This is also reflected in the response time, 200+ ms
for a miss, ~20ms for a hit.

However when I request the same resource multiple times at the same
instant, I see multiple requests at the origin server. Ideally I would like
to have only a single request to the origin server and queuing all other
incoming requests in Squid.

The 'collapsed_forwarding on' option seems to do exactly as I want, however
when I turned this option and restarted Squid I still see multiple requests
at the backend.

I've tried to add a cache_dir as suggested in section 'Known issues and
shortcomings' on  http://wiki.squid-cache.org/Features/CollapsedForwarding but
to no avail.

I've placed the config directive on multiple locations in the configuration
file, both before and after the http_port directive as well as the
cache_dir directive. Again no results.

Is the collapsed_forwarding directive the correct one to use for my
use-case or am i missing something?

I'm using the default configuration of version 3.5.19 with the following
changes:

#Queue incoming requests when a request is send to the backend. I.E.
collapse request into a single backend request.
collapsed_forwarding on

# Squid normally listens to port 3128
http_port 3128 accel no-vhost defaultsite=localhost ignore-cc

#Backend requires basic auth
cache_peer 127.0.0.1 parent 53142 0 no-query originserver name=myAccel
login=username:password

#Allow caching of files that have a ttl of 1 seconds
minimum_expiry_time 1 seconds

acl our_sites dstdomain localhost
http_access allow our_sites
cache_peer_access myAccel allow our_sites
cache_peer_access myAccel deny all

See also:
http://serverfault.com/questions/782877/on-multiple-request-to-squid-send-a-single-request-to-a-backend-and-queue-other
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160613/6f951b32/attachment.htm>

From nilesh.gavali at tcs.com  Mon Jun 13 13:01:02 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Mon, 13 Jun 2016 14:01:02 +0100
Subject: [squid-users] Squid not allowing HTTPS access
Message-ID: <OFA3C467A2.6066E3E3-ON80257FD1.00475107-80257FD1.0047810C@tcs.com>

Hello All;
Facing issue while accessing HTTPS via squid, normal http traffic working 
fine. I have squid 3.1.10 on RHEL.6.0

attached is my squid .conf for your reference,..help will be much 
appreciated.



Thanks & Regards
Nilesh Suresh Gavali
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160613/483c93ad/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.conf
Type: application/octet-stream
Size: 3149 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160613/483c93ad/attachment.obj>

From Antony.Stone at squid.open.source.it  Mon Jun 13 13:26:22 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 13 Jun 2016 15:26:22 +0200
Subject: [squid-users] Squid not allowing HTTPS access
In-Reply-To: <OFA3C467A2.6066E3E3-ON80257FD1.00475107-80257FD1.0047810C@tcs.com>
References: <OFA3C467A2.6066E3E3-ON80257FD1.00475107-80257FD1.0047810C@tcs.com>
Message-ID: <201606131526.22734.Antony.Stone@squid.open.source.it>

On Monday 13 June 2016 at 15:01:02, Nilesh Gavali wrote:

> Facing issue while accessing HTTPS via squid, normal http traffic working
> fine.

Please define "issue", with as much detail as possible:

 - what exactly are you trying to do when a problem occurs?

 - have you previously been able to do this without the problem occurring?  If 
so, what has changed between then and now (different squid config, different 
squid version, different browser...)?

 - what is the actual problem (what error message is displayed, if there is 
one)?

 - what appears in your access.log when the problem occurs?

 - any other information you think might be relevant to us in working out 
what's happening on your network?

> I have squid 3.1.10 on RHEL.6.0

For HTTPS traffic in particular you are strongly advised to upgrade.


Regards,

Antony.

-- 
In the Beginning there was nothing, which exploded.

 - Terry Pratchett

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Mon Jun 13 13:34:19 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 14 Jun 2016 01:34:19 +1200
Subject: [squid-users] Queue incoming requests when fetching from origin
In-Reply-To: <CAD0U=K13wKi4hytPvyBqUjdr+Thn90=R-RjE67ZG6ovE8QKo7w@mail.gmail.com>
References: <CAD0U=K13wKi4hytPvyBqUjdr+Thn90=R-RjE67ZG6ovE8QKo7w@mail.gmail.com>
Message-ID: <acc6da17-b5eb-5a37-2ec2-80b0ae4a7fa6@treenet.co.nz>

On 14/06/2016 12:29 a.m., Jaap Dam wrote:
> Is the collapsed_forwarding directive the correct one to use for my
> use-case or am i missing something?

Yes it is correct so far as I am understanding your need.

For further debugging about what is going on you will need the HTTP
messages involved. Add the directive "debug_options 11,2 20,3" to your
config to get them logged in cache.log.

Amos



From uhlar at fantomas.sk  Mon Jun 13 14:23:44 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Mon, 13 Jun 2016 16:23:44 +0200
Subject: [squid-users] Queue incoming requests when fetching from origin
In-Reply-To: <CAD0U=K13wKi4hytPvyBqUjdr+Thn90=R-RjE67ZG6ovE8QKo7w@mail.gmail.com>
References: <CAD0U=K13wKi4hytPvyBqUjdr+Thn90=R-RjE67ZG6ovE8QKo7w@mail.gmail.com>
Message-ID: <20160613142344.GA21115@fantomas.sk>

On 13.06.16 14:29, Jaap Dam wrote:
>I've got a reliable but slow backend that sends cacheble responses. When I
>run a manual test, I can see I miss the cache every one in a while and got
>hits most of the time. This is also reflected in the response time, 200+ ms
>for a miss, ~20ms for a hit.

how do you run the test?

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
You have the right to remain silent. Anything you say will be misquoted,
then used against you. 


From squid3 at treenet.co.nz  Tue Jun 14 01:55:58 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 14 Jun 2016 13:55:58 +1200
Subject: [squid-users] [squid-announce] Squid 4.0.11 beta is available
In-Reply-To: <042701d1c5d8$ed110b20$c7332160$@ngtech.co.il>
References: <c89b122e-af2f-b8b2-24d5-1bb2dbe778d9@treenet.co.nz>
 <042701d1c5d8$ed110b20$c7332160$@ngtech.co.il>
Message-ID: <8fa2dab9-61d8-2245-f7ca-67db179f1880@treenet.co.nz>

On 14/06/2016 1:06 p.m., Eliezer Croitoru wrote:
> Hey Amos,
> 
> I have just released the latest 4.0.11 beta RPMs for:
> - CentOS 7
> - Oracle Linux 7
> - SLES 12SP1
> - OpenSUSE leap
> (all for x86_64 only)
> I started testing on CentOS 7 and until now I do not see any visible regression.
> 

That reminds me I was supposed to mention an autoconf issue in the
release announcement.

Apparently autoconf version(s) from a few years ago can't handle a
certain way of using variables in automake conditionals. It shows up
when requiring the newly deprecated SMB_LM helpers. If anyone has this
trouble with the release, please use a snapshot r14703 or later tarball
instead.

Sorry, mea culpa.
Amos



From eliezer at ngtech.co.il  Tue Jun 14 07:34:22 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 14 Jun 2016 10:34:22 +0300
Subject: [squid-users] Skype makes Squid with ssl_bump crash
In-Reply-To: <8f3a4859-4b80-2e36-f637-547a2b010a4d@riosoft.com.br>
References: <d2f4711f-21ce-21bb-1f0d-f4071f8143b8@riosoft.com.br>
 <3d51f028-bc84-1e59-5066-2b6f9ab603e8@treenet.co.nz>
 <8f3a4859-4b80-2e36-f637-547a2b010a4d@riosoft.com.br>
Message-ID: <054701d1c60f$2bb6e2b0$8324a810$@ngtech.co.il>

Hey Bruno,

A bit late but I recompiled latest 3.5.19 squid RPMs for Fedora 23 x86_64 and it's available at:
http://ngtech.co.il/repo/fedora/23/x86_64/

I am planning to build 4.0.11 for Fedora 23 in the next weeks.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Bruno de Paula Larini
Sent: Saturday, June 11, 2016 12:34 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Skype makes Squid with ssl_bump crash

Em 09/06/2016 19:36, Amos Jeffries escreveu:
> On 10/06/2016 7:20 a.m., Bruno de Paula Larini wrote:
>> Hi list.
>>
>> I'm experiencing some crashes on Squid workers and eventually on the 
>> parent process while using a mixed authenticated/intercepted ssl_bump 
>> + Skype (7.21.0.100). After searching for some clues, I've found this:
>>
>> Changes to squid-3.5.9 (17 Sep 2015):
>>      ...
>>      - Bug 4309: crash during Skype login
>>      ...
>>
>> I'm running the exact Squid 3.5.9, provided by official Fedora 23 
>> (x64) repositories and noticed this behavior only while using Skype.
> Please update to 3.5.19, if that does not work you may need to update 
> to the 4.0.11 coming out today.
>
> NP: the bug only relates to issues that were occuring in how Skype and 
> TLS operated in Sep 2015. The arms race has changed a lot 
> month-on-month since then.
>
> Amos

Hi Amos, thanks for the reply.
Updating to 3.5.19 seems to have solved the issue.
Thanks a lot!
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From denizlist at denizeren.net  Tue Jun 14 08:07:29 2016
From: denizlist at denizeren.net (Deniz Eren)
Date: Tue, 14 Jun 2016 11:07:29 +0300
Subject: [squid-users] Excessive TCP memory usage
In-Reply-To: <CAHQdsZ-enqmicp4RKjLs-NoXUdky1-wU-PnHh5DZ44No65290A@mail.gmail.com>
References: <CAHQdsZ8ZE=KMC4ytuz7TdAd_=aHnpYPcxYxxst=qB01MPkLj3g@mail.gmail.com>
 <20948875-1d61-94eb-a6ec-f3d93ea716ec@treenet.co.nz>
 <CAHQdsZ9BWF42WjeXuNxDt3XdJq3JcO0XP1zQa8ebb0P8h9CDPg@mail.gmail.com>
 <CAHQdsZ-enqmicp4RKjLs-NoXUdky1-wU-PnHh5DZ44No65290A@mail.gmail.com>
Message-ID: <CAHQdsZ-iSDAWnoD5PHYJXB_n812zrWaKkS1h+VG2NBoEoHL4AQ@mail.gmail.com>

Little bump :)

I have posted bug report with steps to reproduce. The problem still
exists and I am curious whether anyone else is having the same
problem, too.

http://bugs.squid-cache.org/show_bug.cgi?id=4526

On Wed, May 25, 2016 at 1:18 PM, Deniz Eren <denizlist at denizeren.net> wrote:
> When I listen to connections between squid and icap using tcpdump I
> saw that after a while icap closes the connection but squid does not
> close, so connection stays in CLOSE_WAIT state:
>
> [root at test ~]# tcpdump -i any -n port 34693
> tcpdump: WARNING: Promiscuous mode not supported on the "any" device
> tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
> listening on any, link-type LINUX_SLL (Linux cooked), capture size 96 bytes
> 13:07:31.802238 IP 127.0.0.1.icap > 127.0.0.1.34693: F
> 2207817997:2207817997(0) ack 710772005 win 395 <nop,nop,timestamp
> 104616992 104016968>
> 13:07:31.842186 IP 127.0.0.1.34693 > 127.0.0.1.icap: . ack 1 win 3186
> <nop,nop,timestamp 104617032 104616992>
>
> [root at test ~]# netstat -tulnap|grep 34693
> tcp   215688      0 127.0.0.1:34693             127.0.0.1:1344
>      CLOSE_WAIT  19740/(squid-1)
>
> These CLOSE_WAIT connections do not timeout and stay until squid
> process is killed.
>
> 2016-05-25 10:37 GMT+03:00 Deniz Eren <denizlist at denizeren.net>:
>> 2016-05-24 21:47 GMT+03:00 Amos Jeffries <squid3 at treenet.co.nz>:
>>> On 25/05/2016 5:50 a.m., Deniz Eren wrote:
>>>> Hi,
>>>>
>>>> After upgrading to squid 3.5.16 I realized that squid started using
>>>> much of kernel's TCP memory.
>>>
>>> Upgrade from which version?
>>>
>> Upgrading from squid 3.1.14. I started using c-icap and ssl-bump.
>>
>>>>
>>>> When squid was running for a long time TCP memory usage is like below:
>>>> test at test:~$ cat /proc/net/sockstat
>>>> sockets: used *
>>>> TCP: inuse * orphan * tw * alloc * mem 200000
>>>> UDP: inuse * mem *
>>>> UDPLITE: inuse *
>>>> RAW: inuse *
>>>> FRAG: inuse * memory *
>>>>
>>>> When I restart squid the memory usage drops dramatically:
>>>
>>> Of course it does. By restarting you just erased all of the operational
>>> state for an unknown but large number of active network connections.
>>>
>> That's true but what I mean was squid's CLOSE_WAIT connections are
>> using too much memory and they are not timing out.
>>
>>> Whether many of those should have been still active or not is a
>>> different question. the answer to which depends on how you have your
>>> Squid configured, and what the traffic through it has been doing.
>>>
>>>
>>>> test at test:~$ cat /proc/net/sockstat
>>>> sockets: used *
>>>> TCP: inuse * orphan * tw * alloc * mem 10
>>>> UDP: inuse * mem *
>>>> UDPLITE: inuse *
>>>> RAW: inuse *
>>>> FRAG: inuse * memory *
>>>>
>>>
>>> The numbers you replaced with "*" are rather important for context.
>>>
>>>
>> Today again I saw the problem:
>>
>> test at test:~$ cat /proc/net/sockstat
>> sockets: used 1304
>> TCP: inuse 876 orphan 81 tw 17 alloc 906 mem 29726
>> UDP: inuse 17 mem 8
>> UDPLITE: inuse 0
>> RAW: inuse 1
>> FRAG: inuse 0 memory 0
>>
>>>> I'm using Squid 3.5.16.
>>>>
>>>
>>> Please upgrade to 3.5.19. Some important issues have been resolved. Some
>>> of them may be related to your TCP memory problem.
>>>
>>>
>> I have upgraded now and problem still exists.
>>
>>>> When I look with "netstat" and "ss" I see lots of CLOSE_WAIT
>>>> connections from squid to ICAP or from squid to upstream server.
>>>>
>>>> Do you have any idea about this problem?
>>>
>>> Memory use by the TCP system of your kernel has very little to do with
>>> Squid. Number of sockets in CLOSE_WAIT does have some relation to Squid
>>> or at least to how the traffic going through it is handled.
>>>
>>> If you have disabled persistent connections in squid.conf then lots of
>>> closed sockets and FD are to be expected.
>>>
>>> If you have persistent connections enabled, then fewer closures should
>>> happen. But some will so expectations depends on how high the traffic
>>> load is.
>>>
>> Persistent connection parameters are enabled in my conf, the problem
>> occurs especially with connections to c-icap service.
>>
>> My netstat output is like this:
>> netstat -tulnap|grep squid|grep CLOSE
>>
>> tcp   211742      0 127.0.0.1:55751             127.0.0.1:1344
>>      CLOSE_WAIT  17076/(squid-1)
>> tcp   215700      0 127.0.0.1:55679             127.0.0.1:1344
>>      CLOSE_WAIT  17076/(squid-1)
>> tcp   215704      0 127.0.0.1:55683             127.0.0.1:1344
>>      CLOSE_WAIT  17076/(squid-1)
>> ...(hundreds)
>> Above ones are connections to c-icap service.
>>
>> netstat -tulnap|grep squid|grep CLOSE
>> Active Internet connections (servers and established)
>> Proto Recv-Q Send-Q Local Address               Foreign Address
>>      State       PID/Program name
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:45182
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.2.177:50020
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.2.172:60028
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:44049
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:55054
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.2.137:52177
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:43542
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.155:39489
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.0.147:38939
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:38754
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.0.164:39602
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.0.147:54114
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:57857
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.0.156:43482
>>      CLOSE_WAIT  15245/(squid-1)
>> ...(about 50)
>> Above ones are connections from https port to client.
>>
>> As you can see recv-q for icap connections allocate more memory but
>> connections from https_port to upstream server connections allocate
>> only one byte.
>>
>>  What can be done to close these unused connections?
>>
>> The problem in this thread seems similar:
>> http://www.squid-cache.org/mail-archive/squid-users/201301/0092.html
>>
>>> Amos
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users


From jaap.dam at gmail.com  Tue Jun 14 08:51:57 2016
From: jaap.dam at gmail.com (Jaap Dam)
Date: Tue, 14 Jun 2016 10:51:57 +0200
Subject: [squid-users] Queue incoming requests when fetching from origin
In-Reply-To: <20160613142344.GA21115@fantomas.sk>
References: <CAD0U=K13wKi4hytPvyBqUjdr+Thn90=R-RjE67ZG6ovE8QKo7w@mail.gmail.com>
 <20160613142344.GA21115@fantomas.sk>
Message-ID: <CAD0U=K2MigW2r9HRaxyc0SeXyfW42u_1b39drTzvKXrRJ92tEQ@mail.gmail.com>

Hi,

I run the tests with SoapUI 5.2.1. I've created Rest project with a
test-step and a Load Test for that test step. I'm using the Simple
strategy, with 40 threads with a delay of 1000ms and a random factor of
0.5.

I've got Squid behind a Apache server which is available from the internet.
So the setup is SoapUI <-> Internet <-> Apache <-> Squid <-> Origin.
Apache, Squid and the origin run on the same machine.

Best regards

2016-06-13 16:23 GMT+02:00 Matus UHLAR - fantomas <uhlar at fantomas.sk>:

> On 13.06.16 14:29, Jaap Dam wrote:
>
>> I've got a reliable but slow backend that sends cacheble responses. When I
>> run a manual test, I can see I miss the cache every one in a while and got
>> hits most of the time. This is also reflected in the response time, 200+
>> ms
>> for a miss, ~20ms for a hit.
>>
>
> how do you run the test?
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> You have the right to remain silent. Anything you say will be misquoted,
> then used against you. _______________________________________________
>
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/32963eb8/attachment.htm>

From jaap.dam at gmail.com  Tue Jun 14 08:51:59 2016
From: jaap.dam at gmail.com (Jaap Dam)
Date: Tue, 14 Jun 2016 10:51:59 +0200
Subject: [squid-users] Queue incoming requests when fetching from origin
In-Reply-To: <acc6da17-b5eb-5a37-2ec2-80b0ae4a7fa6@treenet.co.nz>
References: <CAD0U=K13wKi4hytPvyBqUjdr+Thn90=R-RjE67ZG6ovE8QKo7w@mail.gmail.com>
 <acc6da17-b5eb-5a37-2ec2-80b0ae4a7fa6@treenet.co.nz>
Message-ID: <CAD0U=K1FYLNXWMn595RJD33DpetGhLU=qNz4QmqMwWdEpOFo8g@mail.gmail.com>

Hi Amos,

I've part of the logging as an attachment. I'm requesting a single URL in
this log. The log starts with a stale cache of the item.

Hope you can help.

Best regards

2016-06-13 15:34 GMT+02:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 14/06/2016 12:29 a.m., Jaap Dam wrote:
> > Is the collapsed_forwarding directive the correct one to use for my
> > use-case or am i missing something?
>
> Yes it is correct so far as I am understanding your need.
>
> For further debugging about what is going on you will need the HTTP
> messages involved. Add the directive "debug_options 11,2 20,3" to your
> config to get them logged in cache.log.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/f49ae189/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: cache.log.partial.gz
Type: application/x-gzip
Size: 48408 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/f49ae189/attachment.bin>

From eliezer at ngtech.co.il  Tue Jun 14 10:21:32 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 14 Jun 2016 13:21:32 +0300
Subject: [squid-users] Excessive TCP memory usage
In-Reply-To: <CAHQdsZ-iSDAWnoD5PHYJXB_n812zrWaKkS1h+VG2NBoEoHL4AQ@mail.gmail.com>
References: <CAHQdsZ8ZE=KMC4ytuz7TdAd_=aHnpYPcxYxxst=qB01MPkLj3g@mail.gmail.com>
 <20948875-1d61-94eb-a6ec-f3d93ea716ec@treenet.co.nz>
 <CAHQdsZ9BWF42WjeXuNxDt3XdJq3JcO0XP1zQa8ebb0P8h9CDPg@mail.gmail.com>
 <CAHQdsZ-enqmicp4RKjLs-NoXUdky1-wU-PnHh5DZ44No65290A@mail.gmail.com>
 <CAHQdsZ-iSDAWnoD5PHYJXB_n812zrWaKkS1h+VG2NBoEoHL4AQ@mail.gmail.com>
Message-ID: <05c801d1c626$85a97ff0$90fc7fd0$@ngtech.co.il>

Hey,

Steps to reproduce are not exactly everything since squid works fine in many other scenarios.
I do not know this specific system but if you are talking about 1-4k open connections it should not be a big problem for many servers.
The issue in hands is a bit different.
Have you tried tuning the ipv4\net using sysctl to see if it affects anything?
What I can offer is to build a tiny ICAP service that will use a 204 on every request and then moves on.
If the same happens with the dummy service it's probably a very bad scenario and if not then we can try to think
if there is something unique about your setup.

I have not seen this issue in my current testing setup which includes 3.5.19 + ICAP url filtering service.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Deniz Eren
Sent: Tuesday, June 14, 2016 11:07 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Excessive TCP memory usage

Little bump :)

I have posted bug report with steps to reproduce. The problem still exists and I am curious whether anyone else is having the same problem, too.

http://bugs.squid-cache.org/show_bug.cgi?id=4526

On Wed, May 25, 2016 at 1:18 PM, Deniz Eren <denizlist at denizeren.net> wrote:
> When I listen to connections between squid and icap using tcpdump I 
> saw that after a while icap closes the connection but squid does not 
> close, so connection stays in CLOSE_WAIT state:
>
> [root at test ~]# tcpdump -i any -n port 34693
> tcpdump: WARNING: Promiscuous mode not supported on the "any" device
> tcpdump: verbose output suppressed, use -v or -vv for full protocol 
> decode listening on any, link-type LINUX_SLL (Linux cooked), capture 
> size 96 bytes
> 13:07:31.802238 IP 127.0.0.1.icap > 127.0.0.1.34693: F
> 2207817997:2207817997(0) ack 710772005 win 395 <nop,nop,timestamp
> 104616992 104016968>
> 13:07:31.842186 IP 127.0.0.1.34693 > 127.0.0.1.icap: . ack 1 win 3186 
> <nop,nop,timestamp 104617032 104616992>
>
> [root at test ~]# netstat -tulnap|grep 34693
> tcp   215688      0 127.0.0.1:34693             127.0.0.1:1344
>      CLOSE_WAIT  19740/(squid-1)
>
> These CLOSE_WAIT connections do not timeout and stay until squid 
> process is killed.
>
> 2016-05-25 10:37 GMT+03:00 Deniz Eren <denizlist at denizeren.net>:
>> 2016-05-24 21:47 GMT+03:00 Amos Jeffries <squid3 at treenet.co.nz>:
>>> On 25/05/2016 5:50 a.m., Deniz Eren wrote:
>>>> Hi,
>>>>
>>>> After upgrading to squid 3.5.16 I realized that squid started using 
>>>> much of kernel's TCP memory.
>>>
>>> Upgrade from which version?
>>>
>> Upgrading from squid 3.1.14. I started using c-icap and ssl-bump.
>>
>>>>
>>>> When squid was running for a long time TCP memory usage is like below:
>>>> test at test:~$ cat /proc/net/sockstat
>>>> sockets: used *
>>>> TCP: inuse * orphan * tw * alloc * mem 200000
>>>> UDP: inuse * mem *
>>>> UDPLITE: inuse *
>>>> RAW: inuse *
>>>> FRAG: inuse * memory *
>>>>
>>>> When I restart squid the memory usage drops dramatically:
>>>
>>> Of course it does. By restarting you just erased all of the 
>>> operational state for an unknown but large number of active network connections.
>>>
>> That's true but what I mean was squid's CLOSE_WAIT connections are 
>> using too much memory and they are not timing out.
>>
>>> Whether many of those should have been still active or not is a 
>>> different question. the answer to which depends on how you have your 
>>> Squid configured, and what the traffic through it has been doing.
>>>
>>>
>>>> test at test:~$ cat /proc/net/sockstat
>>>> sockets: used *
>>>> TCP: inuse * orphan * tw * alloc * mem 10
>>>> UDP: inuse * mem *
>>>> UDPLITE: inuse *
>>>> RAW: inuse *
>>>> FRAG: inuse * memory *
>>>>
>>>
>>> The numbers you replaced with "*" are rather important for context.
>>>
>>>
>> Today again I saw the problem:
>>
>> test at test:~$ cat /proc/net/sockstat
>> sockets: used 1304
>> TCP: inuse 876 orphan 81 tw 17 alloc 906 mem 29726
>> UDP: inuse 17 mem 8
>> UDPLITE: inuse 0
>> RAW: inuse 1
>> FRAG: inuse 0 memory 0
>>
>>>> I'm using Squid 3.5.16.
>>>>
>>>
>>> Please upgrade to 3.5.19. Some important issues have been resolved. 
>>> Some of them may be related to your TCP memory problem.
>>>
>>>
>> I have upgraded now and problem still exists.
>>
>>>> When I look with "netstat" and "ss" I see lots of CLOSE_WAIT 
>>>> connections from squid to ICAP or from squid to upstream server.
>>>>
>>>> Do you have any idea about this problem?
>>>
>>> Memory use by the TCP system of your kernel has very little to do 
>>> with Squid. Number of sockets in CLOSE_WAIT does have some relation 
>>> to Squid or at least to how the traffic going through it is handled.
>>>
>>> If you have disabled persistent connections in squid.conf then lots 
>>> of closed sockets and FD are to be expected.
>>>
>>> If you have persistent connections enabled, then fewer closures 
>>> should happen. But some will so expectations depends on how high the 
>>> traffic load is.
>>>
>> Persistent connection parameters are enabled in my conf, the problem 
>> occurs especially with connections to c-icap service.
>>
>> My netstat output is like this:
>> netstat -tulnap|grep squid|grep CLOSE
>>
>> tcp   211742      0 127.0.0.1:55751             127.0.0.1:1344
>>      CLOSE_WAIT  17076/(squid-1)
>> tcp   215700      0 127.0.0.1:55679             127.0.0.1:1344
>>      CLOSE_WAIT  17076/(squid-1)
>> tcp   215704      0 127.0.0.1:55683             127.0.0.1:1344
>>      CLOSE_WAIT  17076/(squid-1)
>> ...(hundreds)
>> Above ones are connections to c-icap service.
>>
>> netstat -tulnap|grep squid|grep CLOSE Active Internet connections 
>> (servers and established)
>> Proto Recv-Q Send-Q Local Address               Foreign Address
>>      State       PID/Program name
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:45182
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.2.177:50020
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.2.172:60028
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:44049
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:55054
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.2.137:52177
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:43542
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.155:39489
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.0.147:38939
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:38754
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.0.164:39602
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.0.147:54114
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:57857
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.0.156:43482
>>      CLOSE_WAIT  15245/(squid-1)
>> ...(about 50)
>> Above ones are connections from https port to client.
>>
>> As you can see recv-q for icap connections allocate more memory but 
>> connections from https_port to upstream server connections allocate 
>> only one byte.
>>
>>  What can be done to close these unused connections?
>>
>> The problem in this thread seems similar:
>> http://www.squid-cache.org/mail-archive/squid-users/201301/0092.html
>>
>>> Amos
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From nilesh.gavali at tcs.com  Tue Jun 14 10:36:30 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Tue, 14 Jun 2016 11:36:30 +0100
Subject: [squid-users] Squid not allowing HTTPS access
In-Reply-To: <OFA3C467A2.6066E3E3-ON80257FD1.00475107-80257FD1.00477FB3@LocalDomain>
References: <OFA3C467A2.6066E3E3-ON80257FD1.00475107-80257FD1.00477FB3@LocalDomain>
Message-ID: <OF83BE7BF7.92EBA289-ON80257FD2.003A3940-80257FD2.003A455E@tcs.com>

Team;
kindly help on below issue.

Thanks & Regards
Nilesh Suresh Gavali



From:   Nilesh Gavali/MUM/TCS
To:     squid-users at lists.squid-cache.org
Date:   13/06/2016 14:00
Subject:        Squid not allowing HTTPS access



Hello All;
Facing issue while accessing HTTPS via squid, normal http traffic working 
fine. I have squid 3.1.10 on RHEL.6.0

attached is my squid .conf for your reference,..help will be much 
appreciated.



Thanks & Regards
Nilesh Suresh Gavali
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/79185c58/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.conf
Type: application/octet-stream
Size: 3149 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/79185c58/attachment.obj>

From Antony.Stone at squid.open.source.it  Tue Jun 14 10:40:14 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 14 Jun 2016 12:40:14 +0200
Subject: [squid-users] Squid not allowing HTTPS access
In-Reply-To: <OF83BE7BF7.92EBA289-ON80257FD2.003A3940-80257FD2.003A455E@tcs.com>
References: <OFA3C467A2.6066E3E3-ON80257FD1.00475107-80257FD1.00477FB3@LocalDomain>
 <OF83BE7BF7.92EBA289-ON80257FD2.003A3940-80257FD2.003A455E@tcs.com>
Message-ID: <201606141240.15034.Antony.Stone@squid.open.source.it>

On Tuesday 14 June 2016 at 12:36:30, Nilesh Gavali wrote:

> Team;
> kindly help on below issue.

Nilesh:
kindly respond to my reply below.

On Monday 13 June 2016 at 15:26:22, Antony Stone wrote:

> On Monday 13 June 2016 at 15:01:02, Nilesh Gavali wrote:
> > Facing issue while accessing HTTPS via squid, normal http traffic working
> > fine.
> 
> Please define "issue", with as much detail as possible:
> 
>  - what exactly are you trying to do when a problem occurs?
> 
>  - have you previously been able to do this without the problem occurring? 
> If so, what has changed between then and now (different squid config,
> different squid version, different browser...)?
> 
>  - what is the actual problem (what error message is displayed, if there is
> one)?
> 
>  - what appears in your access.log when the problem occurs?
> 
>  - any other information you think might be relevant to us in working out
> what's happening on your network?
> 
> > I have squid 3.1.10 on RHEL.6.0
> 
> For HTTPS traffic in particular you are strongly advised to upgrade.
> 
> 
> Regards,
> 
> Antony.

-- 
All generalisations are inaccurate.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From bruno.larini at riosoft.com.br  Tue Jun 14 12:17:13 2016
From: bruno.larini at riosoft.com.br (Bruno de Paula Larini)
Date: Tue, 14 Jun 2016 09:17:13 -0300
Subject: [squid-users] Skype makes Squid with ssl_bump crash
In-Reply-To: <054701d1c60f$2bb6e2b0$8324a810$@ngtech.co.il>
References: <d2f4711f-21ce-21bb-1f0d-f4071f8143b8@riosoft.com.br>
 <3d51f028-bc84-1e59-5066-2b6f9ab603e8@treenet.co.nz>
 <8f3a4859-4b80-2e36-f637-547a2b010a4d@riosoft.com.br>
 <054701d1c60f$2bb6e2b0$8324a810$@ngtech.co.il>
Message-ID: <ec38ff5e-b707-7b2a-acfd-3fc17e060d5b@riosoft.com.br>

Em 14/06/2016 04:34, Eliezer Croitoru escreveu:
> Hey Bruno,
>
> A bit late but I recompiled latest 3.5.19 squid RPMs for Fedora 23 x86_64 and it's available at:
> http://ngtech.co.il/repo/fedora/23/x86_64/
>
> I am planning to build 4.0.11 for Fedora 23 in the next weeks.
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Bruno de Paula Larini
> Sent: Saturday, June 11, 2016 12:34 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Skype makes Squid with ssl_bump crash
>
> Em 09/06/2016 19:36, Amos Jeffries escreveu:
>> On 10/06/2016 7:20 a.m., Bruno de Paula Larini wrote:
>>> Hi list.
>>>
>>> I'm experiencing some crashes on Squid workers and eventually on the
>>> parent process while using a mixed authenticated/intercepted ssl_bump
>>> + Skype (7.21.0.100). After searching for some clues, I've found this:
>>>
>>> Changes to squid-3.5.9 (17 Sep 2015):
>>>       ...
>>>       - Bug 4309: crash during Skype login
>>>       ...
>>>
>>> I'm running the exact Squid 3.5.9, provided by official Fedora 23
>>> (x64) repositories and noticed this behavior only while using Skype.
>> Please update to 3.5.19, if that does not work you may need to update
>> to the 4.0.11 coming out today.
>>
>> NP: the bug only relates to issues that were occuring in how Skype and
>> TLS operated in Sep 2015. The arms race has changed a lot
>> month-on-month since then.
>>
>> Amos
> Hi Amos, thanks for the reply.
> Updating to 3.5.19 seems to have solved the issue.
> Thanks a lot!
Hi Eliezer, thank you for your help.
The one that worked for me was the 3.5.19 package from Fedora 24 
repositories (which will be released officially next week). I got the 
SRPM and compiled it on Fedora 23.
Still, it would be nice to see a 4.x RPM.

Regards.


From nilesh.gavali at tcs.com  Tue Jun 14 12:25:46 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Tue, 14 Jun 2016 13:25:46 +0100
Subject: [squid-users] squid-users Digest, Vol 22, Issue 62
In-Reply-To: <mailman.5.1465905602.30366.squid-users@lists.squid-cache.org>
References: <mailman.5.1465905602.30366.squid-users@lists.squid-cache.org>
Message-ID: <OF432B7BFB.1C9A6074-ON80257FD2.0042ABFF-80257FD2.004445AC@tcs.com>

Hello Antony;
I have setup like below :-

end user >> LinuxProxy(3.1.10) >> External Proxy(3.4)>> Internet

when we configure external proxy ip in end user's IE, all HTTP & HTTPS 
site work properly.
when we configure Linux proxy ip in end user's IE, HTTP works fine but 
none of the HTTPS site open.
when we access https site from LinuxProxy, below logs are appearing in 
access.log 
        TCP_DENIED/407 CONNECT sitename:443 -  NONE/ text/html 
        TCP_MISS/503 0 CONNECT sitename:443 username at MYDOMAIN.COM DIRECT / 
- -
        TCP_MISS/200 23456 GET http://www.anysite.com 
username at MYDOMAIN.COM   DEFAULT_PARENT/10.10.x.x text/html


what I making out from log is ( I might be wrong) - HTTPS request are 
going directly instead .

attached is my Linux Proxy config-

=================
#
# Recommended minimum configuration:
#

#auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -d -s 
GSS_C_NO_NAME
auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
HTTP/proxy02.abcd.com at ABCD.COM -d
auth_param negotiate children 10
auth_param negotiate keep_alive on
auth_param basic credentialsttl 2 hours
acl ad_auth proxy_auth REQUIRED

acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Only allow cachemgr access from localhost
http_access allow manager localhost
http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
#
# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
#http_access allow localhost
http_access deny !ad_auth
http_access allow ad_auth


# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 8080

cache_peer xx.xx.2.108 parent 8080 0 default
#dns_nameservers ABCDNS.ABCD.COM
dns_nameservers xx.xx.2.108

# We recommend you to use at least the following line.
#hierarchy_stoplist cgi-bin ?

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/spool/squid 2048 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid
# Log forwarding to SysLog
access_log syslog:local1.info

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
-======================================

Thanks & Regards
Nilesh Suresh Gavali





From:   squid-users-request at lists.squid-cache.org
To:     squid-users at lists.squid-cache.org
Date:   14/06/2016 13:00
Subject:        squid-users Digest, Vol 22, Issue 62
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org>



Send squid-users mailing list submissions to
                 squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
                 http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
                 squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
                 squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

   1. Re: Excessive TCP memory usage (Eliezer Croitoru)
   2. Re: Squid not allowing HTTPS access (Nilesh Gavali)
   3. Re: Squid not allowing HTTPS access (Antony Stone)


----------------------------------------------------------------------

Message: 1
Date: Tue, 14 Jun 2016 13:21:32 +0300
From: "Eliezer Croitoru" <eliezer at ngtech.co.il>
To: "'Deniz Eren'" <denizlist at denizeren.net>,
                 <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Excessive TCP memory usage
Message-ID: <05c801d1c626$85a97ff0$90fc7fd0$@ngtech.co.il>
Content-Type: text/plain;                charset="utf-8"

Hey,

Steps to reproduce are not exactly everything since squid works fine in 
many other scenarios.
I do not know this specific system but if you are talking about 1-4k open 
connections it should not be a big problem for many servers.
The issue in hands is a bit different.
Have you tried tuning the ipv4\net using sysctl to see if it affects 
anything?
What I can offer is to build a tiny ICAP service that will use a 204 on 
every request and then moves on.
If the same happens with the dummy service it's probably a very bad 
scenario and if not then we can try to think
if there is something unique about your setup.

I have not seen this issue in my current testing setup which includes 
3.5.19 + ICAP url filtering service.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On 
Behalf Of Deniz Eren
Sent: Tuesday, June 14, 2016 11:07 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Excessive TCP memory usage

Little bump :)

I have posted bug report with steps to reproduce. The problem still exists 
and I am curious whether anyone else is having the same problem, too.

http://bugs.squid-cache.org/show_bug.cgi?id=4526

On Wed, May 25, 2016 at 1:18 PM, Deniz Eren <denizlist at denizeren.net> 
wrote:
> When I listen to connections between squid and icap using tcpdump I 
> saw that after a while icap closes the connection but squid does not 
> close, so connection stays in CLOSE_WAIT state:
>
> [root at test ~]# tcpdump -i any -n port 34693
> tcpdump: WARNING: Promiscuous mode not supported on the "any" device
> tcpdump: verbose output suppressed, use -v or -vv for full protocol 
> decode listening on any, link-type LINUX_SLL (Linux cooked), capture 
> size 96 bytes
> 13:07:31.802238 IP 127.0.0.1.icap > 127.0.0.1.34693: F
> 2207817997:2207817997(0) ack 710772005 win 395 <nop,nop,timestamp
> 104616992 104016968>
> 13:07:31.842186 IP 127.0.0.1.34693 > 127.0.0.1.icap: . ack 1 win 3186 
> <nop,nop,timestamp 104617032 104616992>
>
> [root at test ~]# netstat -tulnap|grep 34693
> tcp   215688      0 127.0.0.1:34693             127.0.0.1:1344
>      CLOSE_WAIT  19740/(squid-1)
>
> These CLOSE_WAIT connections do not timeout and stay until squid 
> process is killed.
>
> 2016-05-25 10:37 GMT+03:00 Deniz Eren <denizlist at denizeren.net>:
>> 2016-05-24 21:47 GMT+03:00 Amos Jeffries <squid3 at treenet.co.nz>:
>>> On 25/05/2016 5:50 a.m., Deniz Eren wrote:
>>>> Hi,
>>>>
>>>> After upgrading to squid 3.5.16 I realized that squid started using 
>>>> much of kernel's TCP memory.
>>>
>>> Upgrade from which version?
>>>
>> Upgrading from squid 3.1.14. I started using c-icap and ssl-bump.
>>
>>>>
>>>> When squid was running for a long time TCP memory usage is like 
below:
>>>> test at test:~$ cat /proc/net/sockstat
>>>> sockets: used *
>>>> TCP: inuse * orphan * tw * alloc * mem 200000
>>>> UDP: inuse * mem *
>>>> UDPLITE: inuse *
>>>> RAW: inuse *
>>>> FRAG: inuse * memory *
>>>>
>>>> When I restart squid the memory usage drops dramatically:
>>>
>>> Of course it does. By restarting you just erased all of the 
>>> operational state for an unknown but large number of active network 
connections.
>>>
>> That's true but what I mean was squid's CLOSE_WAIT connections are 
>> using too much memory and they are not timing out.
>>
>>> Whether many of those should have been still active or not is a 
>>> different question. the answer to which depends on how you have your 
>>> Squid configured, and what the traffic through it has been doing.
>>>
>>>
>>>> test at test:~$ cat /proc/net/sockstat
>>>> sockets: used *
>>>> TCP: inuse * orphan * tw * alloc * mem 10
>>>> UDP: inuse * mem *
>>>> UDPLITE: inuse *
>>>> RAW: inuse *
>>>> FRAG: inuse * memory *
>>>>
>>>
>>> The numbers you replaced with "*" are rather important for context.
>>>
>>>
>> Today again I saw the problem:
>>
>> test at test:~$ cat /proc/net/sockstat
>> sockets: used 1304
>> TCP: inuse 876 orphan 81 tw 17 alloc 906 mem 29726
>> UDP: inuse 17 mem 8
>> UDPLITE: inuse 0
>> RAW: inuse 1
>> FRAG: inuse 0 memory 0
>>
>>>> I'm using Squid 3.5.16.
>>>>
>>>
>>> Please upgrade to 3.5.19. Some important issues have been resolved. 
>>> Some of them may be related to your TCP memory problem.
>>>
>>>
>> I have upgraded now and problem still exists.
>>
>>>> When I look with "netstat" and "ss" I see lots of CLOSE_WAIT 
>>>> connections from squid to ICAP or from squid to upstream server.
>>>>
>>>> Do you have any idea about this problem?
>>>
>>> Memory use by the TCP system of your kernel has very little to do 
>>> with Squid. Number of sockets in CLOSE_WAIT does have some relation 
>>> to Squid or at least to how the traffic going through it is handled.
>>>
>>> If you have disabled persistent connections in squid.conf then lots 
>>> of closed sockets and FD are to be expected.
>>>
>>> If you have persistent connections enabled, then fewer closures 
>>> should happen. But some will so expectations depends on how high the 
>>> traffic load is.
>>>
>> Persistent connection parameters are enabled in my conf, the problem 
>> occurs especially with connections to c-icap service.
>>
>> My netstat output is like this:
>> netstat -tulnap|grep squid|grep CLOSE
>>
>> tcp   211742      0 127.0.0.1:55751             127.0.0.1:1344
>>      CLOSE_WAIT  17076/(squid-1)
>> tcp   215700      0 127.0.0.1:55679             127.0.0.1:1344
>>      CLOSE_WAIT  17076/(squid-1)
>> tcp   215704      0 127.0.0.1:55683             127.0.0.1:1344
>>      CLOSE_WAIT  17076/(squid-1)
>> ...(hundreds)
>> Above ones are connections to c-icap service.
>>
>> netstat -tulnap|grep squid|grep CLOSE Active Internet connections 
>> (servers and established)
>> Proto Recv-Q Send-Q Local Address               Foreign Address
>>      State       PID/Program name
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:45182
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.2.177:50020
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.2.172:60028
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:44049
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:55054
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.2.137:52177
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:43542
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.155:39489
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.0.147:38939
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:38754
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.0.164:39602
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.0.147:54114
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:57857
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.0.156:43482
>>      CLOSE_WAIT  15245/(squid-1)
>> ...(about 50)
>> Above ones are connections from https port to client.
>>
>> As you can see recv-q for icap connections allocate more memory but 
>> connections from https_port to upstream server connections allocate 
>> only one byte.
>>
>>  What can be done to close these unused connections?
>>
>> The problem in this thread seems similar:
>> http://www.squid-cache.org/mail-archive/squid-users/201301/0092.html
>>
>>> Amos
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



------------------------------

Message: 2
Date: Tue, 14 Jun 2016 11:36:30 +0100
From: Nilesh Gavali <nilesh.gavali at tcs.com>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid not allowing HTTPS access
Message-ID:
 <OF83BE7BF7.92EBA289-ON80257FD2.003A3940-80257FD2.003A455E at tcs.com>
Content-Type: text/plain; charset="utf-8"

Team;
kindly help on below issue.

Thanks & Regards
Nilesh Suresh Gavali



From:   Nilesh Gavali/MUM/TCS
To:     squid-users at lists.squid-cache.org
Date:   13/06/2016 14:00
Subject:        Squid not allowing HTTPS access



Hello All;
Facing issue while accessing HTTPS via squid, normal http traffic working 
fine. I have squid 3.1.10 on RHEL.6.0

attached is my squid .conf for your reference,..help will be much 
appreciated.



Thanks & Regards
Nilesh Suresh Gavali
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/79185c58/attachment-0001.html
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.conf
Type: application/octet-stream
Size: 3149 bytes
Desc: not available
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/79185c58/attachment-0001.obj
>

------------------------------

Message: 3
Date: Tue, 14 Jun 2016 12:40:14 +0200
From: Antony Stone <Antony.Stone at squid.open.source.it>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid not allowing HTTPS access
Message-ID: <201606141240.15034.Antony.Stone at squid.open.source.it>
Content-Type: Text/Plain;  charset="iso-8859-15"

On Tuesday 14 June 2016 at 12:36:30, Nilesh Gavali wrote:

> Team;
> kindly help on below issue.

Nilesh:
kindly respond to my reply below.

On Monday 13 June 2016 at 15:26:22, Antony Stone wrote:

> On Monday 13 June 2016 at 15:01:02, Nilesh Gavali wrote:
> > Facing issue while accessing HTTPS via squid, normal http traffic 
working
> > fine.
> 
> Please define "issue", with as much detail as possible:
> 
>  - what exactly are you trying to do when a problem occurs?
> 
>  - have you previously been able to do this without the problem 
occurring? 
> If so, what has changed between then and now (different squid config,
> different squid version, different browser...)?
> 
>  - what is the actual problem (what error message is displayed, if there 
is
> one)?
> 
>  - what appears in your access.log when the problem occurs?
> 
>  - any other information you think might be relevant to us in working 
out
> what's happening on your network?
> 
> > I have squid 3.1.10 on RHEL.6.0
> 
> For HTTPS traffic in particular you are strongly advised to upgrade.
> 
> 
> Regards,
> 
> Antony.

-- 
All generalisations are inaccurate.

                                                   Please reply to the 
list;
                                                         please *don't* CC 
me.


------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 22, Issue 62
*******************************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/91af202c/attachment.htm>

From Tommy.Craddock at bicgraphic.com  Tue Jun 14 12:31:39 2016
From: Tommy.Craddock at bicgraphic.com (Craddock, Tommy)
Date: Tue, 14 Jun 2016 12:31:39 +0000
Subject: [squid-users] squid-users Digest, Vol 22, Issue 62
In-Reply-To: <OF432B7BFB.1C9A6074-ON80257FD2.0042ABFF-80257FD2.004445AC@tcs.com>
References: <mailman.5.1465905602.30366.squid-users@lists.squid-cache.org>
 <OF432B7BFB.1C9A6074-ON80257FD2.0042ABFF-80257FD2.004445AC@tcs.com>
Message-ID: <CA86A9283AA07E478F6B0629521FFEE73AF25D@CLWSEXCMBX02.na.bicworld.com>

Nilesh

Please stop replying to the digest version of the mailing lists, per repeated previous requests.   You need to change your mailing list preferences so you get them one by one.

Otherwise, its makes it impossible to understand what you are replying to.




From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Nilesh Gavali
Sent: Tuesday, June 14, 2016 8:26 AM
To: squid-users at lists.squid-cache.org; Antony.Stone at squid.open.source.it
Subject: Re: [squid-users] squid-users Digest, Vol 22, Issue 62

Hello Antony;
I have setup like below :-

end user >> LinuxProxy(3.1.10) >> External Proxy(3.4)>> Internet

  *   when we configure external proxy ip in end user's IE, all HTTP & HTTPS site work properly.
  *   when we configure Linux proxy ip in end user's IE, HTTP works fine but none of the HTTPS site open.
  *   when we access https site from LinuxProxy, below logs are appearing in access.log
        TCP_DENIED/407 CONNECT sitename:443 -  NONE/ text/html
        TCP_MISS/503 0 CONNECT sitename:443 username at MYDOMAIN.COM<mailto:username at MYDOMAIN.COM>         DIRECT / - -
        TCP_MISS/200 23456 GET http://www.anysite.com<http://www.anysite.com/> username at MYDOMAIN.COM<mailto:username at MYDOMAIN.COM>         DEFAULT_PARENT/10.10.x.x text/html


what I making out from log is ( I might be wrong) - HTTPS request are going directly instead .

attached is my Linux Proxy config-

=================
#
# Recommended minimum configuration:
#

#auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -d -s GSS_C_NO_NAME
auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s HTTP/proxy02.abcd.com at ABCD.COM<mailto:HTTP/proxy02.abcd.com at ABCD.COM> -d
auth_param negotiate children 10
auth_param negotiate keep_alive on
auth_param basic credentialsttl 2 hours
acl ad_auth proxy_auth REQUIRED

acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8        # RFC1918 possible internal network
acl localnet src 172.16.0.0/12        # RFC1918 possible internal network
acl localnet src 192.168.0.0/16        # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80                # http
acl Safe_ports port 21                # ftp
acl Safe_ports port 443                # https
acl Safe_ports port 70                # gopher
acl Safe_ports port 210                # wais
acl Safe_ports port 1025-65535        # unregistered ports
acl Safe_ports port 280                # http-mgmt
acl Safe_ports port 488                # gss-http
acl Safe_ports port 591                # filemaker
acl Safe_ports port 777                # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Only allow cachemgr access from localhost
http_access allow manager localhost
http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
#
# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
#http_access allow localhost
http_access deny !ad_auth
http_access allow ad_auth


# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 8080

cache_peer xx.xx.2.108 parent 8080 0 default
#dns_nameservers ABCDNS.ABCD.COM
dns_nameservers xx.xx.2.108

# We recommend you to use at least the following line.
#hierarchy_stoplist cgi-bin ?

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/spool/squid 2048 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid
# Log forwarding to SysLog
access_log syslog:local1.info

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:                1440        20%        10080
refresh_pattern ^gopher:        1440        0%        1440
refresh_pattern -i (/cgi-bin/|\?) 0        0%        0
refresh_pattern .                0        20%        4320
-======================================

Thanks & Regards
Nilesh Suresh Gavali





From:        squid-users-request at lists.squid-cache.org<mailto:squid-users-request at lists.squid-cache.org>
To:        squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Date:        14/06/2016 13:00
Subject:        squid-users Digest, Vol 22, Issue 62
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org<mailto:squid-users-bounces at lists.squid-cache.org>>
________________________________



Send squid-users mailing list submissions to
                squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

To subscribe or unsubscribe via the World Wide Web, visit
                http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
                squid-users-request at lists.squid-cache.org<mailto:squid-users-request at lists.squid-cache.org>

You can reach the person managing the list at
                squid-users-owner at lists.squid-cache.org<mailto:squid-users-owner at lists.squid-cache.org>

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

  1. Re: Excessive TCP memory usage (Eliezer Croitoru)
  2. Re: Squid not allowing HTTPS access (Nilesh Gavali)
  3. Re: Squid not allowing HTTPS access (Antony Stone)


----------------------------------------------------------------------

Message: 1
Date: Tue, 14 Jun 2016 13:21:32 +0300
From: "Eliezer Croitoru" <eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>>
To: "'Deniz Eren'" <denizlist at denizeren.net<mailto:denizlist at denizeren.net>>,
                <squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>>
Subject: Re: [squid-users] Excessive TCP memory usage
Message-ID: <05c801d1c626$85a97ff0$90fc7fd0$@ngtech.co.il<mailto:05c801d1c626$85a97ff0$90fc7fd0$@ngtech.co.il>>
Content-Type: text/plain;                 charset="utf-8"

Hey,

Steps to reproduce are not exactly everything since squid works fine in many other scenarios.
I do not know this specific system but if you are talking about 1-4k open connections it should not be a big problem for many servers.
The issue in hands is a bit different.
Have you tried tuning the ipv4\net using sysctl to see if it affects anything?
What I can offer is to build a tiny ICAP service that will use a 204 on every request and then moves on.
If the same happens with the dummy service it's probably a very bad scenario and if not then we can try to think
if there is something unique about your setup.

I have not seen this issue in my current testing setup which includes 3.5.19 + ICAP url filtering service.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Deniz Eren
Sent: Tuesday, June 14, 2016 11:07 AM
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Excessive TCP memory usage

Little bump :)

I have posted bug report with steps to reproduce. The problem still exists and I am curious whether anyone else is having the same problem, too.

http://bugs.squid-cache.org/show_bug.cgi?id=4526

On Wed, May 25, 2016 at 1:18 PM, Deniz Eren <denizlist at denizeren.net<mailto:denizlist at denizeren.net>> wrote:
> When I listen to connections between squid and icap using tcpdump I
> saw that after a while icap closes the connection but squid does not
> close, so connection stays in CLOSE_WAIT state:
>
> [root at test ~]# tcpdump -i any -n port 34693
> tcpdump: WARNING: Promiscuous mode not supported on the "any" device
> tcpdump: verbose output suppressed, use -v or -vv for full protocol
> decode listening on any, link-type LINUX_SLL (Linux cooked), capture
> size 96 bytes
> 13:07:31.802238 IP 127.0.0.1.icap > 127.0.0.1.34693: F
> 2207817997:2207817997(0) ack 710772005 win 395 <nop,nop,timestamp
> 104616992 104016968>
> 13:07:31.842186 IP 127.0.0.1.34693 > 127.0.0.1.icap: . ack 1 win 3186
> <nop,nop,timestamp 104617032 104616992>
>
> [root at test ~]# netstat -tulnap|grep 34693
> tcp   215688      0 127.0.0.1:34693             127.0.0.1:1344
>      CLOSE_WAIT  19740/(squid-1)
>
> These CLOSE_WAIT connections do not timeout and stay until squid
> process is killed.
>
> 2016-05-25 10:37 GMT+03:00 Deniz Eren <denizlist at denizeren.net<mailto:denizlist at denizeren.net>>:
>> 2016-05-24 21:47 GMT+03:00 Amos Jeffries <squid3 at treenet.co.nz<mailto:squid3 at treenet.co.nz>>:
>>> On 25/05/2016 5:50 a.m., Deniz Eren wrote:
>>>> Hi,
>>>>
>>>> After upgrading to squid 3.5.16 I realized that squid started using
>>>> much of kernel's TCP memory.
>>>
>>> Upgrade from which version?
>>>
>> Upgrading from squid 3.1.14. I started using c-icap and ssl-bump.
>>
>>>>
>>>> When squid was running for a long time TCP memory usage is like below:
>>>> test at test:~$ cat /proc/net/sockstat
>>>> sockets: used *
>>>> TCP: inuse * orphan * tw * alloc * mem 200000
>>>> UDP: inuse * mem *
>>>> UDPLITE: inuse *
>>>> RAW: inuse *
>>>> FRAG: inuse * memory *
>>>>
>>>> When I restart squid the memory usage drops dramatically:
>>>
>>> Of course it does. By restarting you just erased all of the
>>> operational state for an unknown but large number of active network connections.
>>>
>> That's true but what I mean was squid's CLOSE_WAIT connections are
>> using too much memory and they are not timing out.
>>
>>> Whether many of those should have been still active or not is a
>>> different question. the answer to which depends on how you have your
>>> Squid configured, and what the traffic through it has been doing.
>>>
>>>
>>>> test at test:~$ cat /proc/net/sockstat
>>>> sockets: used *
>>>> TCP: inuse * orphan * tw * alloc * mem 10
>>>> UDP: inuse * mem *
>>>> UDPLITE: inuse *
>>>> RAW: inuse *
>>>> FRAG: inuse * memory *
>>>>
>>>
>>> The numbers you replaced with "*" are rather important for context.
>>>
>>>
>> Today again I saw the problem:
>>
>> test at test:~$ cat /proc/net/sockstat
>> sockets: used 1304
>> TCP: inuse 876 orphan 81 tw 17 alloc 906 mem 29726
>> UDP: inuse 17 mem 8
>> UDPLITE: inuse 0
>> RAW: inuse 1
>> FRAG: inuse 0 memory 0
>>
>>>> I'm using Squid 3.5.16.
>>>>
>>>
>>> Please upgrade to 3.5.19. Some important issues have been resolved.
>>> Some of them may be related to your TCP memory problem.
>>>
>>>
>> I have upgraded now and problem still exists.
>>
>>>> When I look with "netstat" and "ss" I see lots of CLOSE_WAIT
>>>> connections from squid to ICAP or from squid to upstream server.
>>>>
>>>> Do you have any idea about this problem?
>>>
>>> Memory use by the TCP system of your kernel has very little to do
>>> with Squid. Number of sockets in CLOSE_WAIT does have some relation
>>> to Squid or at least to how the traffic going through it is handled.
>>>
>>> If you have disabled persistent connections in squid.conf then lots
>>> of closed sockets and FD are to be expected.
>>>
>>> If you have persistent connections enabled, then fewer closures
>>> should happen. But some will so expectations depends on how high the
>>> traffic load is.
>>>
>> Persistent connection parameters are enabled in my conf, the problem
>> occurs especially with connections to c-icap service.
>>
>> My netstat output is like this:
>> netstat -tulnap|grep squid|grep CLOSE
>>
>> tcp   211742      0 127.0.0.1:55751             127.0.0.1:1344
>>      CLOSE_WAIT  17076/(squid-1)
>> tcp   215700      0 127.0.0.1:55679             127.0.0.1:1344
>>      CLOSE_WAIT  17076/(squid-1)
>> tcp   215704      0 127.0.0.1:55683             127.0.0.1:1344
>>      CLOSE_WAIT  17076/(squid-1)
>> ...(hundreds)
>> Above ones are connections to c-icap service.
>>
>> netstat -tulnap|grep squid|grep CLOSE Active Internet connections
>> (servers and established)
>> Proto Recv-Q Send-Q Local Address               Foreign Address
>>      State       PID/Program name
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:45182
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.2.177:50020
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.2.172:60028
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:44049
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:55054
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.2.137:52177
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:43542
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.155:39489
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.0.147:38939
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:38754
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.0.164:39602
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.0.147:54114
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.6.180:57857
>>      CLOSE_WAIT  15245/(squid-1)
>> tcp        1      0 192.168.2.1:8443            192.168.0.156:43482
>>      CLOSE_WAIT  15245/(squid-1)
>> ...(about 50)
>> Above ones are connections from https port to client.
>>
>> As you can see recv-q for icap connections allocate more memory but
>> connections from https_port to upstream server connections allocate
>> only one byte.
>>
>>  What can be done to close these unused connections?
>>
>> The problem in this thread seems similar:
>> http://www.squid-cache.org/mail-archive/squid-users/201301/0092.html
>>
>>> Amos
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
>>> http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users



------------------------------

Message: 2
Date: Tue, 14 Jun 2016 11:36:30 +0100
From: Nilesh Gavali <nilesh.gavali at tcs.com<mailto:nilesh.gavali at tcs.com>>
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Squid not allowing HTTPS access
Message-ID:
                <OF83BE7BF7.92EBA289-ON80257FD2.003A3940-80257FD2.003A455E at tcs.com<mailto:OF83BE7BF7.92EBA289-ON80257FD2.003A3940-80257FD2.003A455E at tcs.com>>
Content-Type: text/plain; charset="utf-8"

Team;
kindly help on below issue.

Thanks & Regards
Nilesh Suresh Gavali



From:   Nilesh Gavali/MUM/TCS
To:     squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Date:   13/06/2016 14:00
Subject:        Squid not allowing HTTPS access



Hello All;
Facing issue while accessing HTTPS via squid, normal http traffic working
fine. I have squid 3.1.10 on RHEL.6.0

attached is my squid .conf for your reference,..help will be much
appreciated.



Thanks & Regards
Nilesh Suresh Gavali
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain
confidential or privileged information. If you are
not the intended recipient, any dissemination, use,
review, distribution, printing or copying of the
information contained in this e-mail message
and/or attachments to it are strictly prohibited. If
you have received this communication in error,
please notify us by reply e-mail or telephone and
immediately and permanently delete the message
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/79185c58/attachment-0001.html>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.conf
Type: application/octet-stream
Size: 3149 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/79185c58/attachment-0001.obj>

------------------------------

Message: 3
Date: Tue, 14 Jun 2016 12:40:14 +0200
From: Antony Stone <Antony.Stone at squid.open.source.it<mailto:Antony.Stone at squid.open.source.it>>
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Squid not allowing HTTPS access
Message-ID: <201606141240.15034.Antony.Stone at squid.open.source.it<mailto:201606141240.15034.Antony.Stone at squid.open.source.it>>
Content-Type: Text/Plain;  charset="iso-8859-15"

On Tuesday 14 June 2016 at 12:36:30, Nilesh Gavali wrote:

> Team;
> kindly help on below issue.

Nilesh:
kindly respond to my reply below.

On Monday 13 June 2016 at 15:26:22, Antony Stone wrote:

> On Monday 13 June 2016 at 15:01:02, Nilesh Gavali wrote:
> > Facing issue while accessing HTTPS via squid, normal http traffic working
> > fine.
>
> Please define "issue", with as much detail as possible:
>
>  - what exactly are you trying to do when a problem occurs?
>
>  - have you previously been able to do this without the problem occurring?
> If so, what has changed between then and now (different squid config,
> different squid version, different browser...)?
>
>  - what is the actual problem (what error message is displayed, if there is
> one)?
>
>  - what appears in your access.log when the problem occurs?
>
>  - any other information you think might be relevant to us in working out
> what's happening on your network?
>
> > I have squid 3.1.10 on RHEL.6.0
>
> For HTTPS traffic in particular you are strongly advised to upgrade.
>
>
> Regards,
>
> Antony.

--
All generalisations are inaccurate.

                                                  Please reply to the list;
                                                        please *don't* CC me.


------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 22, Issue 62
*******************************************


______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________

______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/e478e7c6/attachment.htm>

From nilesh.gavali at tcs.com  Tue Jun 14 13:43:16 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Tue, 14 Jun 2016 14:43:16 +0100
Subject: [squid-users] Squid not allowing HTTPS access
Message-ID: <OFA95FEDE7.29BEDD81-ON80257FD2.004B406B-80257FD2.004B5EA1@tcs.com>

Hello Antony;
I have setup like below :-

end user >> LinuxProxy(3.1.10) >> External Proxy(3.4)>> Internet

when we configure external proxy ip in end user's IE, all HTTP & HTTPS 
site work properly.
when we configure Linux proxy ip in end user's IE, HTTP works fine but 
none of the HTTPS site open.
when we access https site from LinuxProxy, below logs are appearing in 
access.log 
        TCP_DENIED/407 CONNECT sitename:443 -  NONE/ text/html 
        TCP_MISS/503 0 CONNECT sitename:443 username at MYDOMAIN.COM DIRECT / 
- -
        TCP_MISS/200 23456 GET http://www.anysite.com 
username at MYDOMAIN.COM   DEFAULT_PARENT/10.10.x.x text/html


what I making out from log is ( I might be wrong) - HTTPS request are 
going directly instead .

attached is my Linux Proxy config-

=================
#
# Recommended minimum configuration:
#

#auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -d -s 
GSS_C_NO_NAME
auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
HTTP/proxy02.abcd.com at ABCD.COM -d
auth_param negotiate children 10
auth_param negotiate keep_alive on
auth_param basic credentialsttl 2 hours
acl ad_auth proxy_auth REQUIRED

acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Only allow cachemgr access from localhost
http_access allow manager localhost
http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
#
# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
#http_access allow localhost
http_access deny !ad_auth
http_access allow ad_auth


# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 8080

cache_peer xx.xx.2.108 parent 8080 0 default
#dns_nameservers ABCDNS.ABCD.COM
dns_nameservers xx.xx.2.108

# We recommend you to use at least the following line.
#hierarchy_stoplist cgi-bin ?

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/spool/squid 2048 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid
# Log forwarding to SysLog
access_log syslog:local1.info

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
-======================================


Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.   IT Services
                        Business Solutions
                        Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 
 Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627

----- Forwarded by Nilesh Gavali/MUM/TCS on 14/06/2016 14:41 -----

From:   Nilesh Gavali/MUM/TCS
To:     squid-users at lists.squid-cache.org
Date:   13/06/2016 14:00
Subject:        Squid not allowing HTTPS access



Hello All;
Facing issue while accessing HTTPS via squid, normal http traffic working 
fine. I have squid 3.1.10 on RHEL.6.0

attached is my squid .conf for your reference,..help will be much 
appreciated.



Thanks & Regards
Nilesh Suresh Gavali
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/f0633222/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.conf
Type: application/octet-stream
Size: 3149 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/f0633222/attachment.obj>

From eliezer at ngtech.co.il  Tue Jun 14 16:59:50 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 14 Jun 2016 19:59:50 +0300
Subject: [squid-users] Squid not allowing HTTPS access
In-Reply-To: <OFA95FEDE7.29BEDD81-ON80257FD2.004B406B-80257FD2.004B5EA1@tcs.com>
References: <OFA95FEDE7.29BEDD81-ON80257FD2.004B406B-80257FD2.004B5EA1@tcs.com>
Message-ID: <074401d1c65e$29f6ca40$7de45ec0$@ngtech.co.il>

Hey,

 

The issue is that CONNECT request can be passed only directly to the origin
server on 3.1.
Try to add:
never_direct allow all

 

To your squid.conf and see if it works.

I do not remember if it works for all versions.

 

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Nilesh Gavali
Sent: Tuesday, June 14, 2016 4:43 PM
To: squid-users at lists.squid-cache.org; Antony.Stone at squid.open.source.it
Subject: [squid-users] Squid not allowing HTTPS access

 

Hello Antony; 
I have setup like below :- 

end user >> LinuxProxy(3.1.10) >> External Proxy(3.4)>> Internet 

*	when we configure external proxy ip in end user's IE, all HTTP &
HTTPS site work properly. 
*	when we configure Linux proxy ip in end user's IE, HTTP works fine
but none of the HTTPS site open. 
*	when we access https site from LinuxProxy, below logs are appearing
in access.log 

        TCP_DENIED/407 CONNECT sitename:443 -  NONE/ text/html 
        TCP_MISS/503 0 CONNECT sitename:443 username at MYDOMAIN.COM
<mailto:username at MYDOMAIN.COM>          DIRECT / - - 
        TCP_MISS/200 23456 GET  <http://www.anysite.com/>
http://www.anysite.com username at MYDOMAIN.COM <mailto:username at MYDOMAIN.COM>
DEFAULT_PARENT/10.10.x.x text/html 


what I making out from log is ( I might be wrong) - HTTPS request are going
directly instead . 

attached is my Linux Proxy config- 

================= 
# 
# Recommended minimum configuration: 
# 

#auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -d -s
GSS_C_NO_NAME 
auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s
HTTP/proxy02.abcd.com at ABCD.COM <mailto:HTTP/proxy02.abcd.com at ABCD.COM>  -d 
auth_param negotiate children 10 
auth_param negotiate keep_alive on 
auth_param basic credentialsttl 2 hours 
acl ad_auth proxy_auth REQUIRED 

acl manager proto cache_object 
acl localhost src 127.0.0.1/32 ::1 
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1 

# Example rule allowing access from your local networks. 
# Adapt to list your (internal) IP networks from where browsing 
# should be allowed 
acl localnet src 10.0.0.0/8        # RFC1918 possible internal network 
acl localnet src 172.16.0.0/12        # RFC1918 possible internal network 
acl localnet src 192.168.0.0/16        # RFC1918 possible internal network 
acl localnet src fc00::/7       # RFC 4193 local private network range 
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines 

acl SSL_ports port 443 
acl Safe_ports port 80                # http 
acl Safe_ports port 21                # ftp 
acl Safe_ports port 443                # https 
acl Safe_ports port 70                # gopher 
acl Safe_ports port 210                # wais 
acl Safe_ports port 1025-65535        # unregistered ports 
acl Safe_ports port 280                # http-mgmt 
acl Safe_ports port 488                # gss-http 
acl Safe_ports port 591                # filemaker 
acl Safe_ports port 777                # multiling http 
acl CONNECT method CONNECT 

# 
# Recommended minimum Access Permission configuration: 
# 
# Only allow cachemgr access from localhost 
http_access allow manager localhost 
http_access deny manager 

# Deny requests to certain unsafe ports 
http_access deny !Safe_ports 

# Deny CONNECT to other than secure SSL ports 
http_access deny CONNECT !SSL_ports 

# We strongly recommend the following be uncommented to protect innocent 
# web applications running on the proxy server who think the only 
# one who can access services on "localhost" is a local user 
#http_access deny to_localhost 

# 
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS 
# 
# 
# Example rule allowing access from your local networks. 
# Adapt localnet in the ACL section to list your (internal) IP networks 
# from where browsing should be allowed 
#http_access allow localnet 
#http_access allow localhost 
http_access deny !ad_auth 
http_access allow ad_auth 


# And finally deny all other access to this proxy 
http_access deny all 

# Squid normally listens to port 3128 
http_port 8080 

cache_peer xx.xx.2.108 parent 8080 0 default 
#dns_nameservers ABCDNS.ABCD.COM 
dns_nameservers xx.xx.2.108 

# We recommend you to use at least the following line. 
#hierarchy_stoplist cgi-bin ? 

# Uncomment and adjust the following to add a disk cache directory. 
cache_dir ufs /var/spool/squid 2048 16 256 

# Leave coredumps in the first cache dir 
coredump_dir /var/spool/squid 
# Log forwarding to SysLog 
access_log syslog:local1.info 

# Add any of your own refresh_pattern entries above these. 
refresh_pattern ^ftp:                1440        20%        10080 
refresh_pattern ^gopher:        1440        0%        1440 
refresh_pattern -i (/cgi-bin/|\?) 0        0%        0 
refresh_pattern .                0        20%        4320 
-====================================== 


Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com <mailto:nilesh.gavali at tcs.com> 
Website:  <http://www.tcs.com/> http://www.tcs.com
____________________________________________
Experience certainty.        IT Services
                       Business Solutions
                       Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability and
registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India -
Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627

----- Forwarded by Nilesh Gavali/MUM/TCS on 14/06/2016 14:41 ----- 

From:        Nilesh Gavali/MUM/TCS 
To:        squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>  
Date:        13/06/2016 14:00 
Subject:        Squid not allowing HTTPS access 

  _____  




Hello All; 
Facing issue while accessing HTTPS via squid, normal http traffic working
fine. I have squid 3.1.10 on RHEL.6.0 

attached is my squid .conf for your reference,..help will be much
appreciated. 



Thanks & Regards
Nilesh Suresh Gavali

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/8853534f/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11307 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/8853534f/attachment.png>

From squid3 at treenet.co.nz  Tue Jun 14 17:13:41 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 15 Jun 2016 05:13:41 +1200
Subject: [squid-users] Squid not allowing HTTPS access
In-Reply-To: <074401d1c65e$29f6ca40$7de45ec0$@ngtech.co.il>
References: <OFA95FEDE7.29BEDD81-ON80257FD2.004B406B-80257FD2.004B5EA1@tcs.com>
 <074401d1c65e$29f6ca40$7de45ec0$@ngtech.co.il>
Message-ID: <84e6c6e1-2a1a-6502-2f34-f1a2aa29f89d@treenet.co.nz>

On 15/06/2016 4:59 a.m., Eliezer Croitoru wrote:
> Hey,
> 
>  
> 
> The issue is that CONNECT request can be passed only directly to the origin
> server on 3.1.
> Try to add:
> never_direct allow all
> 

Not quite. CONNECT is a type of message that makes no sense sending
through another proxy if its able to go direct.


So while the never_direct rule above will make it go through the peer.
It will also make everything go through the peer, always. If the peer
goes down traffic stops going anywhere.
  If you want that, then fine above is fine.


An alternative which leaves DIRECT, but only as a backup when the peer
is down is to configure:

 nonhierarchical_direct off
 prefer_direct on


Amos



From nilesh.gavali at tcs.com  Tue Jun 14 17:36:46 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Tue, 14 Jun 2016 18:36:46 +0100
Subject: [squid-users] Squid not allowing HTTPS access
In-Reply-To: <074401d1c65e$29f6ca40$7de45ec0$@ngtech.co.il>
References: <OFA95FEDE7.29BEDD81-ON80257FD2.004B406B-80257FD2.004B5EA1@tcs.com>
 <074401d1c65e$29f6ca40$7de45ec0$@ngtech.co.il>
Message-ID: <OF1029EE48.A3374641-ON80257FD2.0060A8E1-80257FD2.0060BEB3@tcs.com>

Hello Eliezer;

Many Thanks, It work for me on 3.1.10

Thanks & Regards
Nilesh Gavali



From:   Eliezer Croitoru <eliezer at ngtech.co.il>
To:     'Nilesh Gavali' <nilesh.gavali at tcs.com>, 
squid-users at lists.squid-cache.org, Antony.Stone at squid.open.source.it
Date:   14/06/2016 18:00
Subject:        RE: [squid-users] Squid not allowing HTTPS access



Hey,
 
The issue is that CONNECT request can be passed only directly to the 
origin server on 3.1.
Try to add:
never_direct allow all
 
To your squid.conf and see if it works.
I do not remember if it works for all versions.
 
Eliezer
 
----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il

 
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On 
Behalf Of Nilesh Gavali
Sent: Tuesday, June 14, 2016 4:43 PM
To: squid-users at lists.squid-cache.org; Antony.Stone at squid.open.source.it
Subject: [squid-users] Squid not allowing HTTPS access
 
Hello Antony; 
I have setup like below :- 

end user >> LinuxProxy(3.1.10) >> External Proxy(3.4)>> Internet 
when we configure external proxy ip in end user's IE, all HTTP & HTTPS 
site work properly. 
when we configure Linux proxy ip in end user's IE, HTTP works fine but 
none of the HTTPS site open. 
when we access https site from LinuxProxy, below logs are appearing in 
access.log 
        TCP_DENIED/407 CONNECT sitename:443 -  NONE/ text/html 
        TCP_MISS/503 0 CONNECT sitename:443 username at MYDOMAIN.COM DIRECT / 
- - 
        TCP_MISS/200 23456 GET http://www.anysite.com 
username at MYDOMAIN.COM         DEFAULT_PARENT/10.10.x.x text/html 


what I making out from log is ( I might be wrong) - HTTPS request are 
going directly instead . 

attached is my Linux Proxy config- 

================= 
# 
# Recommended minimum configuration: 
# 

#auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -d -s 
GSS_C_NO_NAME 
auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
HTTP/proxy02.abcd.com at ABCD.COM -d 
auth_param negotiate children 10 
auth_param negotiate keep_alive on 
auth_param basic credentialsttl 2 hours 
acl ad_auth proxy_auth REQUIRED 

acl manager proto cache_object 
acl localhost src 127.0.0.1/32 ::1 
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1 

# Example rule allowing access from your local networks. 
# Adapt to list your (internal) IP networks from where browsing 
# should be allowed 
acl localnet src 10.0.0.0/8        # RFC1918 possible internal network 
acl localnet src 172.16.0.0/12        # RFC1918 possible internal network 
acl localnet src 192.168.0.0/16        # RFC1918 possible internal network 

acl localnet src fc00::/7       # RFC 4193 local private network range 
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines 

acl SSL_ports port 443 
acl Safe_ports port 80                # http 
acl Safe_ports port 21                # ftp 
acl Safe_ports port 443                # https 
acl Safe_ports port 70                # gopher 
acl Safe_ports port 210                # wais 
acl Safe_ports port 1025-65535        # unregistered ports 
acl Safe_ports port 280                # http-mgmt 
acl Safe_ports port 488                # gss-http 
acl Safe_ports port 591                # filemaker 
acl Safe_ports port 777                # multiling http 
acl CONNECT method CONNECT 

# 
# Recommended minimum Access Permission configuration: 
# 
# Only allow cachemgr access from localhost 
http_access allow manager localhost 
http_access deny manager 

# Deny requests to certain unsafe ports 
http_access deny !Safe_ports 

# Deny CONNECT to other than secure SSL ports 
http_access deny CONNECT !SSL_ports 

# We strongly recommend the following be uncommented to protect innocent 
# web applications running on the proxy server who think the only 
# one who can access services on "localhost" is a local user 
#http_access deny to_localhost 

# 
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS 
# 
# 
# Example rule allowing access from your local networks. 
# Adapt localnet in the ACL section to list your (internal) IP networks 
# from where browsing should be allowed 
#http_access allow localnet 
#http_access allow localhost 
http_access deny !ad_auth 
http_access allow ad_auth 


# And finally deny all other access to this proxy 
http_access deny all 

# Squid normally listens to port 3128 
http_port 8080 

cache_peer xx.xx.2.108 parent 8080 0 default 
#dns_nameservers ABCDNS.ABCD.COM 
dns_nameservers xx.xx.2.108 

# We recommend you to use at least the following line. 
#hierarchy_stoplist cgi-bin ? 

# Uncomment and adjust the following to add a disk cache directory. 
cache_dir ufs /var/spool/squid 2048 16 256 

# Leave coredumps in the first cache dir 
coredump_dir /var/spool/squid 
# Log forwarding to SysLog 
access_log syslog:local1.info 

# Add any of your own refresh_pattern entries above these. 
refresh_pattern ^ftp:                1440        20%        10080 
refresh_pattern ^gopher:        1440        0%        1440 
refresh_pattern -i (/cgi-bin/|\?) 0        0%        0 
refresh_pattern .                0        20%        4320 
-====================================== 


Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.        IT Services
                       Business Solutions
                       Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 
 Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627

----- Forwarded by Nilesh Gavali/MUM/TCS on 14/06/2016 14:41 ----- 

From:        Nilesh Gavali/MUM/TCS 
To:        squid-users at lists.squid-cache.org 
Date:        13/06/2016 14:00 
Subject:        Squid not allowing HTTPS access 




Hello All; 
Facing issue while accessing HTTPS via squid, normal http traffic working 
fine. I have squid 3.1.10 on RHEL.6.0 

attached is my squid .conf for your reference,..help will be much 
appreciated. 



Thanks & Regards
Nilesh Suresh Gavali
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/f175dc50/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/png
Size: 11307 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/f175dc50/attachment.png>

From reqman at freemail.gr  Wed Jun 15 07:22:29 2016
From: reqman at freemail.gr (reqman)
Date: Wed, 15 Jun 2016 10:22:29 +0300
Subject: [squid-users] HTTPS issues with squidguard after upgrading from
	squid 2.7 to 3.5
Message-ID: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>

Hello all,

Hello all,

I have been running squid 2.7.X alongside squidguard 1.4 on a FreeBSD
8.x box for years. Started out some 10 years ago, with a much older
squid/squidguard/FreeBSD combination.

Having to upgrade to FreeBSD 10.3, I examined my option regarding
squid. 3.5.19 was available which I assumed would behave the same as
2.7, regarding compatibility. Squidguard 1.4 was also installed.

- Squid was configured to behave along the lines of what I had on 2.7.
- For squidguard I used the exact same blocklists and configurations.
Note that I do not employ an URL rewriting in squidguard, only
redirection.
- no SSL-bump or other SSL interception takes place
- the squidguard-related lines on squid are the following:

url_rewrite_program /usr/local/bin/squidGuard
url_rewrite_children 8 startup=4 idle=4 concurrency=0
url_rewrite_access allow all

- In squidGuard.conf, the typical redirect section is like:

 default {
                pass local-ok !block1 !block2 !blockN all
                redirect
301:http://localsite/block.htm?clientaddr=%a+clientname=%n+clientident=%i+srcclass=%s+targetclass=%t+url=%u
        }

I am now experiencing problems that I did not have. Specifically,
access to certain but *not* all HTTPS sites seems to timeout.
Furthermore, I see entries similar to the following in cache.log:

2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
remote=192.168.2.239:3446 FD 591 flags=1
2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
remote=192.168.2.239:3448 FD 592 flags=1
2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
remote=192.168.2.239:3452 FD 594 flags=1
2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
remote=192.168.2.239:3456 FD 596 flags=1
2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
remote=192.168.2.239:3454 FD 595 flags=1
2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
remote=192.168.2.239:3458 FD 597 flags=1
2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
remote=192.168.2.239:3462 FD 599 flags=1

Searching around, the closest I have come to an answer is the
following: http://www.squid-cache.org/mail-archive/squid-users/201211/0165.html
I am not sure though whether I am plagued by the same issue,
considering that the thread refers to a squid version dated 4 years
ago. And I definitely do not understand what the is meant by the
poster's proposal:

"If you can't alter the re-writer to perform redirection you can work
around that by using:

  acl foo ... some test to match the re-written URL ...
  deny_info 302:%s foo
  adapted_http_access deny foo "

Can someone help resolve this? Is the 2.7 series supported at all? As
is if everything fails, I'll have to go back to it if there's some
support.

BR,


Michael.-


From fredbmail at free.fr  Wed Jun 15 07:30:45 2016
From: fredbmail at free.fr (FredB)
Date: Wed, 15 Jun 2016 09:30:45 +0200 (CEST)
Subject: [squid-users] Squid high memory usage
In-Reply-To: <5f360fcd-2fe7-a11d-9c97-508936461553@treenet.co.nz>
Message-ID: <1421618068.277910691.1465975845716.JavaMail.root@zimbra4-e1.priv.proxad.net>

Maybe I'm wrong, but the server is also using many memories for TCP 

cat /proc/net/sockstat
sockets: used 13523
TCP: inuse 8612 orphan 49 tw 31196 alloc 8728 mem 18237
UDP: inuse 14 mem 6
UDPLITE: inuse 0
RAW: inuse 0
FRAG: inuse 0 memory 0

netstat -lataupen | wc -l
38780






From eliezer at ngtech.co.il  Wed Jun 15 08:45:43 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 15 Jun 2016 11:45:43 +0300
Subject: [squid-users] HTTPS issues with squidguard after upgrading
	from	squid 2.7 to 3.5
In-Reply-To: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>
References: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>
Message-ID: <027e01d1c6e2$4d583530$e8089f90$@ngtech.co.il>

Hey Michael,

I am missing couple details about the setup which might affect the way we would be able to understand what is causing the issue and how to resolve it.
There are changes from squid 2.7 to 3.5 and to my opinion these are mandatory to resolve and to not go one step back.
What version of SquidGuard 1.4 did you installed? The patched for squid 3.4+ compatibility?
More details about it here: http://bugs.squid-cache.org/show_bug.cgi?id=3978
Now if it is indeed patched and works as expected it from the 3.4+ computability level of things then lets move on.

Are you using Squid in intercept\transparent\trpoxy mode or is it defined in the browsers directly?
If you are using intercept mode, what have you defined on the FreeBSD pf\ipfw?

And about the quote from the mailing list:
SquidGuard was written to operate under the url_rewrite interface\protocol and not external_acl.
Due to this it has some disadvantages and the advised details are to modify the helper(SquidGuard or another) to operate in another way.
It is possible to use the patched version of SquidGuard under the external_acl interface and use squid options to deny\redirect the request.
It removes some things from the complexity of the issue.
I have just written an example on how to use use my software SquidBlocker under external_acl and here the adapted example that can be used with a patched SquidGuard:
## START OF SETTINGS
external_acl_type filter_url ipv4 concurrency=0 ttl=3 %URI %SRC/- %LOGIN %METHOD /usr/local/bin/squidGuard url_rewrite_children
acl filter_url_acl external filter_url
deny_info http://ngtech.co.il/block_page/?url=%u&domain=%H filter_url_acl
#or
# deny_info 302:http://ngtech.co.il/block_page/?url=%u&domain=%H filter_url_acl
http_access deny !filter_url_acl
http_access allow localnet filter_url_acl
## END OF SETTINGS

I have not tested this request format but if it doesn't work this way then a little cosmetics will make it work.

When more information will be available we can try to see where the issue is from.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of reqman
Sent: Wednesday, June 15, 2016 10:22 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] HTTPS issues with squidguard after upgrading from squid 2.7 to 3.5

Hello all,

I have been running squid 2.7.X alongside squidguard 1.4 on a FreeBSD 8.x box for years.
Started out some 10 years ago, with a much older squid/squidguard/FreeBSD combination.

Having to upgrade to FreeBSD 10.3, I examined my option regarding squid.
3.5.19 was available which I assumed would behave the same as 2.7, regarding compatibility.
Squidguard 1.4 was also installed.

- Squid was configured to behave along the lines of what I had on 2.7.
- For squidguard I used the exact same blocklists and configurations.
Note that I do not employ an URL rewriting in squidguard, only redirection.
- no SSL-bump or other SSL interception takes place
- the squidguard-related lines on squid are the following:

url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8 startup=4 idle=4 concurrency=0
url_rewrite_access allow all

- In squidGuard.conf, the typical redirect section is like:

 default {
                pass local-ok !block1 !block2 !blockN all
                redirect
301:http://localsite/block.htm?clientaddr=%a+clientname=%n+clientident=%i+srcclass=%s+targetclass=%t+url=%u
        }

I am now experiencing problems that I did not have. Specifically, access to certain but *not* all HTTPS sites seems to timeout.
Furthermore, I see entries similar to the following in cache.log:

2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
remote=192.168.2.239:3446 FD 591 flags=1
2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
remote=192.168.2.239:3448 FD 592 flags=1
2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
remote=192.168.2.239:3452 FD 594 flags=1
2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
remote=192.168.2.239:3456 FD 596 flags=1
2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
remote=192.168.2.239:3454 FD 595 flags=1
2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
remote=192.168.2.239:3458 FD 597 flags=1
2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
remote=192.168.2.239:3462 FD 599 flags=1

Searching around, the closest I have come to an answer is the
following: http://www.squid-cache.org/mail-archive/squid-users/201211/0165.html
I am not sure though whether I am plagued by the same issue, considering that the thread refers to a squid version dated 4 years ago. And I definitely do not understand what the is meant by the poster's proposal:

"If you can't alter the re-writer to perform redirection you can work around that by using:

  acl foo ... some test to match the re-written URL ...
  deny_info 302:%s foo
  adapted_http_access deny foo "

Can someone help resolve this?
Is the 2.7 series supported at all?
As is if everything fails, I'll have to go back to it if there's some support.

BR,


Michael.-
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From nilesh.gavali at tcs.com  Wed Jun 15 09:32:24 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Wed, 15 Jun 2016 10:32:24 +0100
Subject: [squid-users] Squid not allowing HTTPS access
In-Reply-To: <mailman.24795.1465925833.2892.squid-users@lists.squid-cache.org>
References: <mailman.24795.1465925833.2892.squid-users@lists.squid-cache.org>
Message-ID: <OFBCDC9673.C1AAE7FA-ON80257FD3.0033F968-80257FD3.003466A6@tcs.com>

Thanks Amos for update. I tried the same as explain by you in earlier 
reply.
but after this, Proxy response degraded like anything. also HTTPS site are 
not opening. So reverted back to the solution given by Eliezer.
 
Next, I want to restrict the URL access based on AD OU membership for 
users, can you quickly help me with some starting points.

regards;
Nilesh Gavali





From:   squid-users-request at lists.squid-cache.org
To:     squid-users at lists.squid-cache.org
Date:   14/06/2016 18:37
Subject:        squid-users Digest, Vol 22, Issue 66
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org>



Send squid-users mailing list submissions to
                 squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
                 http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
                 squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
                 squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

   1. Re: Squid not allowing HTTPS access (Amos Jeffries)
   2. Squid not allowing HTTPS access (Nilesh Gavali)


----------------------------------------------------------------------

Message: 1
Date: Wed, 15 Jun 2016 05:13:41 +1200
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid not allowing HTTPS access
Message-ID: <84e6c6e1-2a1a-6502-2f34-f1a2aa29f89d at treenet.co.nz>
Content-Type: text/plain; charset=utf-8

On 15/06/2016 4:59 a.m., Eliezer Croitoru wrote:
> Hey,
> 
> 
> 
> The issue is that CONNECT request can be passed only directly to the 
origin
> server on 3.1.
> Try to add:
> never_direct allow all
> 

Not quite. CONNECT is a type of message that makes no sense sending
through another proxy if its able to go direct.


So while the never_direct rule above will make it go through the peer.
It will also make everything go through the peer, always. If the peer
goes down traffic stops going anywhere.
  If you want that, then fine above is fine.


An alternative which leaves DIRECT, but only as a backup when the peer
is down is to configure:

 nonhierarchical_direct off
 prefer_direct on


Amos



------------------------------

Message: 2
Date: Tue, 14 Jun 2016 18:36:46 +0100
From: Nilesh Gavali <nilesh.gavali at tcs.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid not allowing HTTPS access
Message-ID:
 <OF1029EE48.A3374641-ON80257FD2.0060A8E1-80257FD2.0060BEB3 at tcs.com>
Content-Type: text/plain; charset="utf-8"

Hello Eliezer;

Many Thanks, It work for me on 3.1.10

Thanks & Regards
Nilesh Gavali



From:   Eliezer Croitoru <eliezer at ngtech.co.il>
To:     'Nilesh Gavali' <nilesh.gavali at tcs.com>, 
squid-users at lists.squid-cache.org, Antony.Stone at squid.open.source.it
Date:   14/06/2016 18:00
Subject:        RE: [squid-users] Squid not allowing HTTPS access



Hey,
 
The issue is that CONNECT request can be passed only directly to the 
origin server on 3.1.
Try to add:
never_direct allow all
 
To your squid.conf and see if it works.
I do not remember if it works for all versions.
 
Eliezer
 
----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il

 
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On 
Behalf Of Nilesh Gavali
Sent: Tuesday, June 14, 2016 4:43 PM
To: squid-users at lists.squid-cache.org; Antony.Stone at squid.open.source.it
Subject: [squid-users] Squid not allowing HTTPS access
 
Hello Antony; 
I have setup like below :- 

end user >> LinuxProxy(3.1.10) >> External Proxy(3.4)>> Internet 
when we configure external proxy ip in end user's IE, all HTTP & HTTPS 
site work properly. 
when we configure Linux proxy ip in end user's IE, HTTP works fine but 
none of the HTTPS site open. 
when we access https site from LinuxProxy, below logs are appearing in 
access.log 
        TCP_DENIED/407 CONNECT sitename:443 -  NONE/ text/html 
        TCP_MISS/503 0 CONNECT sitename:443 username at MYDOMAIN.COM DIRECT / 

- - 
        TCP_MISS/200 23456 GET http://www.anysite.com 
username at MYDOMAIN.COM         DEFAULT_PARENT/10.10.x.x text/html 


what I making out from log is ( I might be wrong) - HTTPS request are 
going directly instead . 

attached is my Linux Proxy config- 

================= 
# 
# Recommended minimum configuration: 
# 

#auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -d -s 
GSS_C_NO_NAME 
auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
HTTP/proxy02.abcd.com at ABCD.COM -d 
auth_param negotiate children 10 
auth_param negotiate keep_alive on 
auth_param basic credentialsttl 2 hours 
acl ad_auth proxy_auth REQUIRED 

acl manager proto cache_object 
acl localhost src 127.0.0.1/32 ::1 
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1 

# Example rule allowing access from your local networks. 
# Adapt to list your (internal) IP networks from where browsing 
# should be allowed 
acl localnet src 10.0.0.0/8        # RFC1918 possible internal network 
acl localnet src 172.16.0.0/12        # RFC1918 possible internal network 
acl localnet src 192.168.0.0/16        # RFC1918 possible internal network 


acl localnet src fc00::/7       # RFC 4193 local private network range 
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines 

acl SSL_ports port 443 
acl Safe_ports port 80                # http 
acl Safe_ports port 21                # ftp 
acl Safe_ports port 443                # https 
acl Safe_ports port 70                # gopher 
acl Safe_ports port 210                # wais 
acl Safe_ports port 1025-65535        # unregistered ports 
acl Safe_ports port 280                # http-mgmt 
acl Safe_ports port 488                # gss-http 
acl Safe_ports port 591                # filemaker 
acl Safe_ports port 777                # multiling http 
acl CONNECT method CONNECT 

# 
# Recommended minimum Access Permission configuration: 
# 
# Only allow cachemgr access from localhost 
http_access allow manager localhost 
http_access deny manager 

# Deny requests to certain unsafe ports 
http_access deny !Safe_ports 

# Deny CONNECT to other than secure SSL ports 
http_access deny CONNECT !SSL_ports 

# We strongly recommend the following be uncommented to protect innocent 
# web applications running on the proxy server who think the only 
# one who can access services on "localhost" is a local user 
#http_access deny to_localhost 

# 
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS 
# 
# 
# Example rule allowing access from your local networks. 
# Adapt localnet in the ACL section to list your (internal) IP networks 
# from where browsing should be allowed 
#http_access allow localnet 
#http_access allow localhost 
http_access deny !ad_auth 
http_access allow ad_auth 


# And finally deny all other access to this proxy 
http_access deny all 

# Squid normally listens to port 3128 
http_port 8080 

cache_peer xx.xx.2.108 parent 8080 0 default 
#dns_nameservers ABCDNS.ABCD.COM 
dns_nameservers xx.xx.2.108 

# We recommend you to use at least the following line. 
#hierarchy_stoplist cgi-bin ? 

# Uncomment and adjust the following to add a disk cache directory. 
cache_dir ufs /var/spool/squid 2048 16 256 

# Leave coredumps in the first cache dir 
coredump_dir /var/spool/squid 
# Log forwarding to SysLog 
access_log syslog:local1.info 

# Add any of your own refresh_pattern entries above these. 
refresh_pattern ^ftp:                1440        20%        10080 
refresh_pattern ^gopher:        1440        0%        1440 
refresh_pattern -i (/cgi-bin/|\?) 0        0%        0 
refresh_pattern .                0        20%        4320 
-====================================== 


Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.        IT Services
                       Business Solutions
                       Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 

 Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627

----- Forwarded by Nilesh Gavali/MUM/TCS on 14/06/2016 14:41 ----- 

From:        Nilesh Gavali/MUM/TCS 
To:        squid-users at lists.squid-cache.org 
Date:        13/06/2016 14:00 
Subject:        Squid not allowing HTTPS access 




Hello All; 
Facing issue while accessing HTTPS via squid, normal http traffic working 
fine. I have squid 3.1.10 on RHEL.6.0 

attached is my squid .conf for your reference,..help will be much 
appreciated. 



Thanks & Regards
Nilesh Suresh Gavali
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/f175dc50/attachment.html
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/png
Size: 11307 bytes
Desc: not available
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160614/f175dc50/attachment.png
>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 22, Issue 66
*******************************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160615/e2074ec1/attachment.htm>

From marcus.kool at urlfilterdb.com  Wed Jun 15 10:13:25 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 15 Jun 2016 07:13:25 -0300
Subject: [squid-users] Squid high memory usage
In-Reply-To: <1421618068.277910691.1465975845716.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1421618068.277910691.1465975845716.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <57612A45.20803@urlfilterdb.com>



On 06/15/2016 04:30 AM, FredB wrote:
> Maybe I'm wrong, but the server is also using many memories for TCP
>
> cat /proc/net/sockstat
> sockets: used 13523
> TCP: inuse 8612 orphan 49 tw 31196 alloc 8728 mem 18237
> UDP: inuse 14 mem 6
> UDPLITE: inuse 0
> RAW: inuse 0
> FRAG: inuse 0 memory 0
>
> netstat -lataupen | wc -l
> 38780

yes, and the OS also uses buffers for file system I/O.

I updated the memory FAQ to include these.

Marcus



From fredbmail at free.fr  Wed Jun 15 10:22:02 2016
From: fredbmail at free.fr (FredB)
Date: Wed, 15 Jun 2016 12:22:02 +0200 (CEST)
Subject: [squid-users] Squid high memory usage
In-Reply-To: <57612A45.20803@urlfilterdb.com>
Message-ID: <1833405531.278623560.1465986122380.JavaMail.root@zimbra4-e1.priv.proxad.net>

Yes I guess this is a good track for me (more or less 20000 now ...)
Maybe half_closed should be help but unfortunately it crashes squid, Bug 4156

Fred


From eliezer at ngtech.co.il  Wed Jun 15 10:23:49 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 15 Jun 2016 13:23:49 +0300
Subject: [squid-users] HTTPS issues with squidguard after
	upgrading	from	squid 2.7 to 3.5
In-Reply-To: <027e01d1c6e2$4d583530$e8089f90$@ngtech.co.il>
References: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>
 <027e01d1c6e2$4d583530$e8089f90$@ngtech.co.il>
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAANIlB21wPQZLlj2Y4QUZ/uABAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAD5IXq/WBO1RpFyeof/dnlgAQAAAAA=@ngtech.co.il>

OK so just to fix a typo and add an option to debug the issue.

## START OF SETTINGS

external_acl_type filter_url ipv4 concurrency=0 ttl=3 %URI %SRC %{-} %un
%METHOD /usr/local/bin/squidGuard

acl filter_url_acl external filter_url

deny_info http://ngtech.co.il/block_page/?url=%u&domain=%H filter_url_acl 

#or 

# deny_info 302:http://ngtech.co.il/block_page/?url=%u&domain=%H
filter_url_acl 

http_access deny filter_url_acl

http_access allow localnet !filter_url_acl 

## END OF SETTINGS

 

And I wrote two tiny wrapping scripts to verify that squidGuard needs
patching.

$ cat /opt/sg.sh

#!/usr/bin/env bash

 

/usr/bin/squidGuard | perl /opt/1.perl

#END

 

$ cat /opt/1.perl

#!/usr/bin/env perl

$|=1;  #turn autoflush on

 

while (my $string = <STDIN>) {

  if ($string =~ /^$/) {

    print STDOUT "ERR" . "\n";

  } elsif ($string =~ /^http/) {

    print STDOUT "OK" . "\n";

  } else {

    print STDERR "STDERR: ELSE [" . $string . "]\n";

        break;

  }

}

##END

#squid.conf

external_acl_type filter_url ipv4 concurrency=0 ttl=3 %URI %SRC %{-} %un
%METHOD /opt/sg.sh

acl filter_url_acl external filter_url

deny_info http://ngtech.co.il/block_page/?url=%u&domain=%H filter_url_acl

http_access deny all filter_url_acl
##END

 

The above scripts and settings are wrapping non patched version of
SquidGuard and uses the external_acl_type helper and the deny_info to
redirect the requests.

And since the last email was wrongfully reformatted a link to a text only
version:

http://paste.ngtech.co.il/pfh5uiiwz/ch12cw/raw

 

----

Eliezer Croitoru

Linux System Administrator

Mobile: +972-5-28704261

Email: eliezer at ngtech.co.il

 

 

-----Original Message-----

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Eliezer Croitoru

Sent: Wednesday, June 15, 2016 11:46 AM

To: 'reqman'

Cc: squid-users at lists.squid-cache.org

Subject: Re: [squid-users] HTTPS issues with squidguard after upgrading
from squid 2.7 to 3.5

 

Hey Michael,

 

I am missing couple details about the setup which might affect the way we
would be able to understand what is causing the issue and how to resolve it.

There are changes from squid 2.7 to 3.5 and to my opinion these are
mandatory to resolve and to not go one step back.

What version of SquidGuard 1.4 did you installed? The patched for squid
3.4+ compatibility?

More details about it here:
http://bugs.squid-cache.org/show_bug.cgi?id=3978

Now if it is indeed patched and works as expected it from the 3.4+
computability level of things then lets move on.

 

Are you using Squid in intercept\transparent\trpoxy mode or is it defined
in the browsers directly?

If you are using intercept mode, what have you defined on the FreeBSD
pf\ipfw?

 

And about the quote from the mailing list:

SquidGuard was written to operate under the url_rewrite interface\protocol
and not external_acl.

Due to this it has some disadvantages and the advised details are to modify
the helper(SquidGuard or another) to operate in another way.

It is possible to use the patched version of SquidGuard under the
external_acl interface and use squid options to deny\redirect the request.

It removes some things from the complexity of the issue.

I have just written an example on how to use use my software SquidBlocker
under external_acl and here the adapted example that can be used with a
patched SquidGuard:

## START OF SETTINGS

external_acl_type filter_url ipv4 concurrency=0 ttl=3 %URI %SRC/- %LOGIN
%METHOD /usr/local/bin/squidGuard url_rewrite_children acl filter_url_acl
external filter_url deny_info
http://ngtech.co.il/block_page/?url=%u&domain=%H filter_url_acl #or #
deny_info 302:http://ngtech.co.il/block_page/?url=%u&domain=%H
filter_url_acl http_access deny !filter_url_acl http_access allow localnet
filter_url_acl ## END OF SETTINGS

 

I have not tested this request format but if it doesn't work this way then
a little cosmetics will make it work.

 

When more information will be available we can try to see where the issue
is from.

 

Eliezer

 

----

Eliezer Croitoru

Linux System Administrator

Mobile: +972-5-28704261

Email: eliezer at ngtech.co.il

 

 

-----Original Message-----

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of reqman

Sent: Wednesday, June 15, 2016 10:22 AM

To: squid-users at lists.squid-cache.org

Subject: [squid-users] HTTPS issues with squidguard after upgrading from
squid 2.7 to 3.5

 

Hello all,

 

I have been running squid 2.7.X alongside squidguard 1.4 on a FreeBSD 8.x
box for years.

Started out some 10 years ago, with a much older squid/squidguard/FreeBSD
combination.

 

Having to upgrade to FreeBSD 10.3, I examined my option regarding squid.

3.5.19 was available which I assumed would behave the same as 2.7,
regarding compatibility.

Squidguard 1.4 was also installed.

 

- Squid was configured to behave along the lines of what I had on 2.7.

- For squidguard I used the exact same blocklists and configurations.

Note that I do not employ an URL rewriting in squidguard, only redirection.

- no SSL-bump or other SSL interception takes place

- the squidguard-related lines on squid are the following:

 

url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8
startup=4 idle=4 concurrency=0 url_rewrite_access allow all

 

- In squidGuard.conf, the typical redirect section is like:

 

default {

                pass local-ok !block1 !block2 !blockN all

                redirect

301:http://localsite/block.htm?clientaddr=%a+clientname=%n+clientident=%i+s
rcclass=%s+targetclass=%t+url=%u

        }

 

I am now experiencing problems that I did not have. Specifically, access to
certain but *not* all HTTPS sites seems to timeout.

Furthermore, I see entries similar to the following in cache.log:

 

2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128

remote=192.168.2.239:3446 FD 591 flags=1

2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128

remote=192.168.2.239:3448 FD 592 flags=1

2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128

remote=192.168.2.239:3452 FD 594 flags=1

2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128

remote=192.168.2.239:3456 FD 596 flags=1

2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128

remote=192.168.2.239:3454 FD 595 flags=1

2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128

remote=192.168.2.239:3458 FD 597 flags=1

2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128

remote=192.168.2.239:3462 FD 599 flags=1

 

Searching around, the closest I have come to an answer is the

following:
http://www.squid-cache.org/mail-archive/squid-users/201211/0165.html

I am not sure though whether I am plagued by the same issue, considering
that the thread refers to a squid version dated 4 years ago. And I
definitely do not understand what the is meant by the poster's proposal:

 

"If you can't alter the re-writer to perform redirection you can work
around that by using:

 

  acl foo ... some test to match the re-written URL ...

  deny_info 302:%s foo

  adapted_http_access deny foo "

 

Can someone help resolve this?

Is the 2.7 series supported at all?

As is if everything fails, I'll have to go back to it if there's some
support.

 

BR,

 

 

Michael.-

_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org

http://lists.squid-cache.org/listinfo/squid-users

 

_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org

http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 14982 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160615/70a8bd0c/attachment.bin>

From fredbmail at free.fr  Wed Jun 15 10:40:53 2016
From: fredbmail at free.fr (FredB)
Date: Wed, 15 Jun 2016 12:40:53 +0200 (CEST)
Subject: [squid-users] Squid high memory usage
In-Reply-To: <1833405531.278623560.1465986122380.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <360409014.278683318.1465987253649.JavaMail.root@zimbra4-e1.priv.proxad.net>


> 
> Yes I guess this is a good track for me (more or less 20000 now ...)
> Maybe half_closed should be help but unfortunately it crashes squid,
> Bug 4156
> 
> Fred
> _______________________________________________

Maybe this is also related with the post "Excessive TCP memory usage" because I'm using ICAP too 

netstat -lataupen | wc -l 
33683
netstat -lataupen | grep WAIT | wc -l 
28407

But I don't think, my case seems different 
I'm using E2guardian like front proxy 

Lan -> E2guardian (3128) -> Squid (8080)-> Net
With also Squid to load balancer ICAP (1025)

50% of TIME_WAIT - E2guardian to Squid
45% of TIME_WAIT - Squid to NET or Lan to E2Guardian 
5%  of TIME_WAIT - ICAP

Fred




From marcus.kool at urlfilterdb.com  Wed Jun 15 10:48:31 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 15 Jun 2016 07:48:31 -0300
Subject: [squid-users] HTTPS issues with squidguard after upgrading from
 squid 2.7 to 3.5
In-Reply-To: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>
References: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>
Message-ID: <5761327F.5010400@urlfilterdb.com>



On 06/15/2016 04:22 AM, reqman wrote:
> Hello all,
>
> I have been running squid 2.7.X alongside squidguard 1.4 on a FreeBSD
> 8.x box for years. Started out some 10 years ago, with a much older
> squid/squidguard/FreeBSD combination.
>
> Having to upgrade to FreeBSD 10.3, I examined my option regarding
> squid. 3.5.19 was available which I assumed would behave the same as
> 2.7, regarding compatibility. Squidguard 1.4 was also installed.

A great decision to go to Squid 3.5.19, but it is a large leap so
you might expect some compatibility issues.

Squidguard has no support nor maintenance for many years and the patch
for squidguard to become compatible with squid 3.4+ was written by a Squid
developer.
Hence I recommend to install ufdbGuard, which is a fork of squidGuard and
does have support and updates.  ufdbGuard is also 3x faster and uses less
memory, so plenty of reasons to say goodbye to squidGuard.

Marcus

> - Squid was configured to behave along the lines of what I had on 2.7.
> - For squidguard I used the exact same blocklists and configurations.
> Note that I do not employ an URL rewriting in squidguard, only
> redirection.
> - no SSL-bump or other SSL interception takes place
> - the squidguard-related lines on squid are the following:
>
> url_rewrite_program /usr/local/bin/squidGuard
> url_rewrite_children 8 startup=4 idle=4 concurrency=0
> url_rewrite_access allow all
>
> - In squidGuard.conf, the typical redirect section is like:
>
>   default {
>                  pass local-ok !block1 !block2 !blockN all
>                  redirect
> 301:http://localsite/block.htm?clientaddr=%a+clientname=%n+clientident=%i+srcclass=%s+targetclass=%t+url=%u
>          }
>
> I am now experiencing problems that I did not have. Specifically,
> access to certain but *not* all HTTPS sites seems to timeout.
> Furthermore, I see entries similar to the following in cache.log:
>
> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
> remote=192.168.2.239:3446 FD 591 flags=1
> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
> remote=192.168.2.239:3448 FD 592 flags=1
> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
> remote=192.168.2.239:3452 FD 594 flags=1
> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
> remote=192.168.2.239:3456 FD 596 flags=1
> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
> remote=192.168.2.239:3454 FD 595 flags=1
> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
> remote=192.168.2.239:3458 FD 597 flags=1
> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
> remote=192.168.2.239:3462 FD 599 flags=1
>
> Searching around, the closest I have come to an answer is the
> following: http://www.squid-cache.org/mail-archive/squid-users/201211/0165.html
> I am not sure though whether I am plagued by the same issue,
> considering that the thread refers to a squid version dated 4 years
> ago. And I definitely do not understand what the is meant by the
> poster's proposal:
>
> "If you can't alter the re-writer to perform redirection you can work
> around that by using:
>
>    acl foo ... some test to match the re-written URL ...
>    deny_info 302:%s foo
>    adapted_http_access deny foo "
>
> Can someone help resolve this? Is the 2.7 series supported at all? As
> is if everything fails, I'll have to go back to it if there's some
> support.
>
> BR,
>
>
> Michael.-



From reqman at freemail.gr  Wed Jun 15 11:18:57 2016
From: reqman at freemail.gr (reqman)
Date: Wed, 15 Jun 2016 14:18:57 +0300
Subject: [squid-users] HTTPS issues with squidguard after upgrading from
 squid 2.7 to 3.5
In-Reply-To: <027e01d1c6e2$4d583530$e8089f90$@ngtech.co.il>
References: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>
 <027e01d1c6e2$4d583530$e8089f90$@ngtech.co.il>
Message-ID: <CAAvSkVGnZK2RyDgu9XYJZXq=HeBad8SfhKTDp8Aq6oTer21D7A@mail.gmail.com>

Hello Eliezer,

2016-06-15 11:45 GMT+03:00 Eliezer Croitoru <eliezer at ngtech.co.il>:
> Hey Michael,
>
> I am missing couple details about the setup which might affect the way we would be able to understand what is causing the issue and how to resolve it.
> There are changes from squid 2.7 to 3.5 and to my opinion these are mandatory to resolve and to not go one step back.

Yes, I saw that 3.5 effectively disabled/obsoleted/deactivated various
options. I believe I took care in following through those
requirements.

> What version of SquidGuard 1.4 did you installed? The patched for squid 3.4+ compatibility?

I installed a ready to use package from FreeBSD. I presume that is is
ok with squid 3.4, according to its dependencies:

 # pkg query "%do%dv" squidGuard
www/squid3.5.19
databases/db55.3.28_3

Other information for squidGuard:

# pkg info squidGuard
squidGuard-1.4_15
Name           : squidGuard
Version        : 1.4_15
Installed on   : Mon May 30 08:24:17 2016 EEST
Origin         : www/squidguard
Architecture   : freebsd:10:x86:64
Prefix         : /usr/local
Categories     : www
Licenses       : GPLv2
Maintainer     : garga at FreeBSD.org
WWW            : http://www.squidguard.org/
Comment        : Fast redirector for squid
Options        :
       DNS_BL         : off
       DOCS           : on
       EXAMPLES       : on
       LDAP           : off
       QUOTE_STRING   : off
       STRIP_NTDOMAIN : off
Shared Libs required:
       libdb-5.3.so.0
Annotations    :
       repo_type      : binary
       repository     : FreeBSD
Flat size      : 2.24MiB

> More details about it here: http://bugs.squid-cache.org/show_bug.cgi?id=3978
> Now if it is indeed patched and works as expected it from the 3.4+ computability level of things then lets move on.

Checking the bug and if I understand correctly, if my squidGuard was
not patched then it wouldn't work. This is not the case. It works ok
for http urls, ie blocks fine and the user is correctly redirected to
the block page setup for this purpose. It's HTTPS I'm having issues
with: according to some talks, if something gets blocked by
squidguard, something is miscommunicated (or not communicated at all)
with squid. Instead of a block, the users waits endlessly for the
page.

> Are you using Squid in intercept\transparent\trpoxy mode or is it defined in the browsers directly?
> If you are using intercept mode, what have you defined on the FreeBSD pf\ipfw?

Squid operates in normal mode. I've configured a 10year old proxy
autodiscovery script, which is published through DHCP. All browsers
are set to configure everything automatically.

> And about the quote from the mailing list:
> SquidGuard was written to operate under the url_rewrite interface\protocol and not external_acl.

I've lost you here: why do I need squidGuard to operate under
external_acl? Can't I leave it running with url_rewrite?

> Due to this it has some disadvantages and the advised details are to modify the helper(SquidGuard or another) to operate in another way.
> It is possible to use the patched version of SquidGuard under the external_acl interface and use squid options to deny\redirect the request.

I saw your other email, but I again have to ask. My own squidguard
"seems" to work. What are the merits of doing things with external_acl
instead of the way I am doing things right now?

> It removes some things from the complexity of the issue.
> I have just written an example on how to use use my software SquidBlocker under external_acl and here the adapted example that can be used with a patched SquidGuard:
> ## START OF SETTINGS
> external_acl_type filter_url ipv4 concurrency=0 ttl=3 %URI %SRC/- %LOGIN %METHOD /usr/local/bin/squidGuard url_rewrite_children
> acl filter_url_acl external filter_url
> deny_info http://ngtech.co.il/block_page/?url=%u&domain=%H filter_url_acl
> #or
> # deny_info 302:http://ngtech.co.il/block_page/?url=%u&domain=%H filter_url_acl
> http_access deny !filter_url_acl
> http_access allow localnet filter_url_acl
> ## END OF SETTINGS
>
> I have not tested this request format but if it doesn't work this way then a little cosmetics will make it work.
>
> When more information will be available we can try to see where the issue is from.
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of reqman
> Sent: Wednesday, June 15, 2016 10:22 AM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] HTTPS issues with squidguard after upgrading from squid 2.7 to 3.5
>
> Hello all,
>
> I have been running squid 2.7.X alongside squidguard 1.4 on a FreeBSD 8.x box for years.
> Started out some 10 years ago, with a much older squid/squidguard/FreeBSD combination.
>
> Having to upgrade to FreeBSD 10.3, I examined my option regarding squid.
> 3.5.19 was available which I assumed would behave the same as 2.7, regarding compatibility.
> Squidguard 1.4 was also installed.
>
> - Squid was configured to behave along the lines of what I had on 2.7.
> - For squidguard I used the exact same blocklists and configurations.
> Note that I do not employ an URL rewriting in squidguard, only redirection.
> - no SSL-bump or other SSL interception takes place
> - the squidguard-related lines on squid are the following:
>
> url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8 startup=4 idle=4 concurrency=0
> url_rewrite_access allow all
>
> - In squidGuard.conf, the typical redirect section is like:
>
>  default {
>                 pass local-ok !block1 !block2 !blockN all
>                 redirect
> 301:http://localsite/block.htm?clientaddr=%a+clientname=%n+clientident=%i+srcclass=%s+targetclass=%t+url=%u
>         }
>
> I am now experiencing problems that I did not have. Specifically, access to certain but *not* all HTTPS sites seems to timeout.
> Furthermore, I see entries similar to the following in cache.log:
>
> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
> remote=192.168.2.239:3446 FD 591 flags=1
> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
> remote=192.168.2.239:3448 FD 592 flags=1
> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
> remote=192.168.2.239:3452 FD 594 flags=1
> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
> remote=192.168.2.239:3456 FD 596 flags=1
> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
> remote=192.168.2.239:3454 FD 595 flags=1
> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
> remote=192.168.2.239:3458 FD 597 flags=1
> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
> remote=192.168.2.239:3462 FD 599 flags=1
>
> Searching around, the closest I have come to an answer is the
> following: http://www.squid-cache.org/mail-archive/squid-users/201211/0165.html
> I am not sure though whether I am plagued by the same issue, considering that the thread refers to a squid version dated 4 years ago. And I definitely do not understand what the is meant by the poster's proposal:
>
> "If you can't alter the re-writer to perform redirection you can work around that by using:
>
>   acl foo ... some test to match the re-written URL ...
>   deny_info 302:%s foo
>   adapted_http_access deny foo "
>
> Can someone help resolve this?
> Is the 2.7 series supported at all?
> As is if everything fails, I'll have to go back to it if there's some support.
>
> BR,
>
>
> Michael.-
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From reqman at freemail.gr  Wed Jun 15 11:24:54 2016
From: reqman at freemail.gr (reqman)
Date: Wed, 15 Jun 2016 14:24:54 +0300
Subject: [squid-users] HTTPS issues with squidguard after upgrading from
 squid 2.7 to 3.5
In-Reply-To: <5761327F.5010400@urlfilterdb.com>
References: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>
 <5761327F.5010400@urlfilterdb.com>
Message-ID: <CAAvSkVEZD4K3nCKDEvsuQ-Gv9o-CEapC_0F=X3Huctb8WJjNgA@mail.gmail.com>

2016-06-15 13:48 GMT+03:00 Marcus Kool <marcus.kool at urlfilterdb.com>:
>
>
> On 06/15/2016 04:22 AM, reqman wrote:
>>
>> Hello all,
>>
>> I have been running squid 2.7.X alongside squidguard 1.4 on a FreeBSD
>> 8.x box for years. Started out some 10 years ago, with a much older
>> squid/squidguard/FreeBSD combination.
>>
>> Having to upgrade to FreeBSD 10.3, I examined my option regarding
>> squid. 3.5.19 was available which I assumed would behave the same as
>> 2.7, regarding compatibility. Squidguard 1.4 was also installed.
>
>
> A great decision to go to Squid 3.5.19, but it is a large leap so
> you might expect some compatibility issues.
>
> Squidguard has no support nor maintenance for many years and the patch
> for squidguard to become compatible with squid 3.4+ was written by a Squid
> developer.
> Hence I recommend to install ufdbGuard, which is a fork of squidGuard and
> does have support and updates.  ufdbGuard is also 3x faster and uses less
> memory, so plenty of reasons to say goodbye to squidGuard.

I have been using squidGuard for 10+ years. Not the best one could
have, but I am accustomed to its use and idiosyncrasies. Furthermore,
it is package well supported on FreeBSD.

You are mentioning ufdbGuard. Are its lists free for government use?
If not, then I can not use it, since we have very strict purchasing
requirements, even if it costs $1. And of course, I would have to go
through evaluation, the usual learning curve etc.

Don't get me wrong here, I'm not saying no. I'm just saying that even
though it seems to be easy to say "yes", reality is much different.

M.-

>
> Marcus
>
>
>> - Squid was configured to behave along the lines of what I had on 2.7.
>> - For squidguard I used the exact same blocklists and configurations.
>> Note that I do not employ an URL rewriting in squidguard, only
>> redirection.
>> - no SSL-bump or other SSL interception takes place
>> - the squidguard-related lines on squid are the following:
>>
>> url_rewrite_program /usr/local/bin/squidGuard
>> url_rewrite_children 8 startup=4 idle=4 concurrency=0
>> url_rewrite_access allow all
>>
>> - In squidGuard.conf, the typical redirect section is like:
>>
>>   default {
>>                  pass local-ok !block1 !block2 !blockN all
>>                  redirect
>>
>> 301:http://localsite/block.htm?clientaddr=%a+clientname=%n+clientident=%i+srcclass=%s+targetclass=%t+url=%u
>>          }
>>
>> I am now experiencing problems that I did not have. Specifically,
>> access to certain but *not* all HTTPS sites seems to timeout.
>> Furthermore, I see entries similar to the following in cache.log:
>>
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>> remote=192.168.2.239:3446 FD 591 flags=1
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>> remote=192.168.2.239:3448 FD 592 flags=1
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>> remote=192.168.2.239:3452 FD 594 flags=1
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>> remote=192.168.2.239:3456 FD 596 flags=1
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>> remote=192.168.2.239:3454 FD 595 flags=1
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>> remote=192.168.2.239:3458 FD 597 flags=1
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>> remote=192.168.2.239:3462 FD 599 flags=1
>>
>> Searching around, the closest I have come to an answer is the
>> following:
>> http://www.squid-cache.org/mail-archive/squid-users/201211/0165.html
>> I am not sure though whether I am plagued by the same issue,
>> considering that the thread refers to a squid version dated 4 years
>> ago. And I definitely do not understand what the is meant by the
>> poster's proposal:
>>
>> "If you can't alter the re-writer to perform redirection you can work
>> around that by using:
>>
>>    acl foo ... some test to match the re-written URL ...
>>    deny_info 302:%s foo
>>    adapted_http_access deny foo "
>>
>> Can someone help resolve this? Is the 2.7 series supported at all? As
>> is if everything fails, I'll have to go back to it if there's some
>> support.
>>
>> BR,
>>
>>
>> Michael.-
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From fredbmail at free.fr  Wed Jun 15 11:36:38 2016
From: fredbmail at free.fr (FredB)
Date: Wed, 15 Jun 2016 13:36:38 +0200 (CEST)
Subject: [squid-users] HTTPS issues with squidguard after upgrading from
 squid 2.7 to 3.5
In-Reply-To: <CAAvSkVEZD4K3nCKDEvsuQ-Gv9o-CEapC_0F=X3Huctb8WJjNgA@mail.gmail.com>
Message-ID: <1463336969.278847434.1465990598400.JavaMail.root@zimbra4-e1.priv.proxad.net>


> 
> You are mentioning ufdbGuard. Are its lists free for government use?
> If not, then I can not use it, since we have very strict purchasing
> requirements, even if it costs $1. And of course, I would have to go
> through evaluation, the usual learning curve etc.
> 
> Don't get me wrong here, I'm not saying no. I'm just saying that even
> though it seems to be easy to say "yes", reality is much different.
>

You can also use E2guardian, a free web url and content filtering proxy
There is a package for Freebsd 

Fred


From marcus.kool at urlfilterdb.com  Wed Jun 15 12:37:40 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 15 Jun 2016 09:37:40 -0300
Subject: [squid-users] HTTPS issues with squidguard after upgrading from
 squid 2.7 to 3.5
In-Reply-To: <CAAvSkVEZD4K3nCKDEvsuQ-Gv9o-CEapC_0F=X3Huctb8WJjNgA@mail.gmail.com>
References: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>
 <5761327F.5010400@urlfilterdb.com>
 <CAAvSkVEZD4K3nCKDEvsuQ-Gv9o-CEapC_0F=X3Huctb8WJjNgA@mail.gmail.com>
Message-ID: <57614C14.4010002@urlfilterdb.com>



On 06/15/2016 08:24 AM, reqman wrote:

> I have been using squidGuard for 10+ years. Not the best one could
> have, but I am accustomed to its use and idiosyncrasies. Furthermore,
> it is package well supported on FreeBSD.
>
> You are mentioning ufdbGuard. Are its lists free for government use?
> If not, then I can not use it, since we have very strict purchasing
> requirements, even if it costs $1. And of course, I would have to go
> through evaluation, the usual learning curve etc.

ufdbGard is free software.
You can use it with any database you desire...  the free ones, your own or
a commercial one.

There is little learning curve since it is a fork of squidguard and there
is a Reference Manual and email support from URLfilterDB, even for those
who use a free database.

Marcus


> Don't get me wrong here, I'm not saying no. I'm just saying that even
> though it seems to be easy to say "yes", reality is much different.
>
> M.-


From nilesh.gavali at tcs.com  Wed Jun 15 13:50:38 2016
From: nilesh.gavali at tcs.com (nilesh.gavali at tcs.com)
Date: Wed, 15 Jun 2016 14:50:38 +0100
Subject: [squid-users] URL access based on AD group membership
Message-ID: <OF29EE7DFD.2BD1A317-ON80257FD3.004390E8-80257FD3.004C0BDD@tcs.com>

Hi Team;
I have setup as below-
Squid Kerberos authentication with windows AD 2012r2. - works fine.
Now need to restrict access based on AD Group membership.

Below configuration done but no luck. when try to access with user who is 
not part of the group mention, still he is able to browse Internet.

================================
#
# Recommended minimum configuration:
#

#auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -d -s 
GSS_C_NO_NAME
auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
HTTP/proxy02.abcd.co.uk at abcd.co.uk -d
auth_param negotiate children 10
auth_param negotiate keep_alive on
auth_param basic credentialsttl 2 hours
acl ad_auth proxy_auth REQUIRED

external_acl_type Domain_Admin %LOGIN /usr/lib64/squid/squid_ldap_group -b 
"dc=abcd,dc=co,dc=uk" -D "cn=Nilesh Gavali,ou=Admin User,ou=TCS 
Users,ou=Staff,dc=abcd,dc=co,dc=uk" -w "123456" -f 
"(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=lgInternetAccess,ou=Internet 
Access,ou=Groups,dc=abcd,dc=co,dc=uk))" -h xx.xx.2.101
acl AllowDomainAdmin external Domain_Admin lgInternetAccess

acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Only allow cachemgr access from localhost
http_access allow manager localhost
http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports


# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
#
# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
#http_access allow localhost
http_access deny !ad_auth
http_access allow ad_auth
http_access deny !AllowDomainAdmin
http_access allow AllowDomainAdmin

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 8080
never_direct allow all

cache_peer xx.xx.2.108 parent 8080 0 default
dns_nameservers xx.xx.2.108

# We recommend you to use at least the following line.
#hierarchy_stoplist cgi-bin ?

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/spool/squid 2048 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

# Log forwarding to SysLog
access_log syslog:local1.info

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
=================================================



Thanks & Regards
Nilesh Suresh Gavali
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160615/a91ac994/attachment.htm>

From squid3 at treenet.co.nz  Wed Jun 15 14:21:54 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 16 Jun 2016 02:21:54 +1200
Subject: [squid-users] URL access based on AD group membership
In-Reply-To: <OF29EE7DFD.2BD1A317-ON80257FD3.004390E8-80257FD3.004C0BDD@tcs.com>
References: <OF29EE7DFD.2BD1A317-ON80257FD3.004390E8-80257FD3.004C0BDD@tcs.com>
Message-ID: <f7557bf2-bae0-e661-8368-6f4497454c89@treenet.co.nz>

On 16/06/2016 1:50 a.m., nilesh.gavali wrote:
> Hi Team;
> I have setup as below-
> Squid Kerberos authentication with windows AD 2012r2. - works fine.
> Now need to restrict access based on AD Group membership.
> 
> Below configuration done but no luck. when try to access with user who is 
> not part of the group mention, still he is able to browse Internet.
> 

This is because:

<snip>
Step 0) check the basic security rules that deny bad behaviour.

>
> http_access deny !ad_auth

Step 1) deny with a "require authentication" message if there are no
valid credentials sent.

> http_access allow ad_auth

Step 2) allow anyone who has valid credentials to use the proxy.

... Uh, Stop.

Users either sent valid credentials [2 happened] or they did not [1
happened]. There are no other possibilities.


> http_access deny !AllowDomainAdmin
> http_access allow AllowDomainAdmin
> 

As explained in the FAQ
<http://wiki.squid-cache.org/SquidFaq/SquidAcl#Access_Lists>

Amos



From rousskov at measurement-factory.com  Wed Jun 15 15:19:52 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 15 Jun 2016 09:19:52 -0600
Subject: [squid-users] Queue incoming requests when fetching from origin
In-Reply-To: <CAD0U=K1FYLNXWMn595RJD33DpetGhLU=qNz4QmqMwWdEpOFo8g@mail.gmail.com>
References: <CAD0U=K13wKi4hytPvyBqUjdr+Thn90=R-RjE67ZG6ovE8QKo7w@mail.gmail.com>
 <acc6da17-b5eb-5a37-2ec2-80b0ae4a7fa6@treenet.co.nz>
 <CAD0U=K1FYLNXWMn595RJD33DpetGhLU=qNz4QmqMwWdEpOFo8g@mail.gmail.com>
Message-ID: <57617218.5050802@measurement-factory.com>

On 06/14/2016 02:51 AM, Jaap Dam wrote:

> I've part of the logging as an attachment. I'm requesting a single URL
> in this log. The log starts with a stale cache of the item. 

Collapsed forwarding does not apply to cache revalidation requests yet.
Factory is working on implementing collapsed revalidations (in some
environments), but I cannot promise a specific delivery date or that
your particular environment will be covered.

Alex.




> 2016-06-13 15:34 GMT+02:00 Amos Jeffries:
> 
>     On 14/06/2016 12:29 a.m., Jaap Dam wrote:
>     > Is the collapsed_forwarding directive the correct one to use for my
>     > use-case or am i missing something?
> 
>     Yes it is correct so far as I am understanding your need.
> 
>     For further debugging about what is going on you will need the HTTP
>     messages involved. Add the directive "debug_options 11,2 20,3" to your
>     config to get them logged in cache.log.



From bruno.larini at riosoft.com.br  Wed Jun 15 17:27:14 2016
From: bruno.larini at riosoft.com.br (Bruno de Paula Larini)
Date: Wed, 15 Jun 2016 14:27:14 -0300
Subject: [squid-users] URL access based on AD group membership
In-Reply-To: <OF29EE7DFD.2BD1A317-ON80257FD3.004390E8-80257FD3.004C0BDD@tcs.com>
References: <OF29EE7DFD.2BD1A317-ON80257FD3.004390E8-80257FD3.004C0BDD@tcs.com>
Message-ID: <eb67a218-c749-aa16-4b00-941bdac1d0a5@riosoft.com.br>

Em 15/06/2016 10:50, nilesh.gavali at tcs.com escreveu:
> Hi Team;
> I have setup as below-
>
>   * Squid Kerberos authentication with windows AD 2012r2. - works fine.
>   * Now need to restrict access based on AD Group membership.
>
>
> Below configuration done but no luck. when try to access with user who 
> is not part of the group mention, still he is able to browse Internet.

The following works fine for me and in my opinion works better than 
LDAP. The authentication is integrated, so it doesn't keep asking for 
password (when the current user is a domain account). But you have to 
add the Squid server to the domain using 'smb.conf', 'krb5.conf' and 
then 'net ads join'. The service 'winbind' must be running too.
I'm using Squid 3.5.19.


     auth_param ntlm program /usr/bin/ntlm_auth 
--helper-protocol=squid-2.5-ntlmssp --domain=MYDOMAIN 
--enable-external-acl-helpers="ext_wbinfo_group_acl"
     auth_param ntlm children 10 startup=0 idle=2

     external_acl_type NTGroup children-startup=10 children-idle=2 
children-max=50 %LOGIN /usr/lib64/squid/ext_wbinfo_group_acl

     acl authenticated proxy_auth REQUIRED

     acl ad_group external NTGroup MYDOMAIN\AD_Group
     acl denied_websites dstdom_regex -i "/etc/squid/denied-websites.txt"
     http_access deny ad_group denied_websites


So all the members of MYDOMAIN\AD_Group won't have access to whatever 
the file contains.

Bruno
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160615/810a3d96/attachment.htm>

From eliezer at ngtech.co.il  Wed Jun 15 18:12:15 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 15 Jun 2016 21:12:15 +0300
Subject: [squid-users] HTTPS issues with squidguard after upgrading from
	squid 2.7 to 3.5
In-Reply-To: <CAAvSkVGnZK2RyDgu9XYJZXq=HeBad8SfhKTDp8Aq6oTer21D7A@mail.gmail.com>
References: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>
 <027e01d1c6e2$4d583530$e8089f90$@ngtech.co.il>
 <CAAvSkVGnZK2RyDgu9XYJZXq=HeBad8SfhKTDp8Aq6oTer21D7A@mail.gmail.com>
Message-ID: <047501d1c731$7224bbf0$566e33d0$@ngtech.co.il>

Hey Michael,

 

Well I have not tested FreeBSD dependencies and patches and I am not following them daily.

The issue itself with SquidGuard and the url_rewrite interface is more of an issue in most cases with CONNECT requests as you mentioned.

Since you are not using ssl_bump then you need to deny the traffic\requests in a way that will not leave squid or the clients and the session in an unknown or unexpected situation.

When the url_rewrite interface is used to "Deny" something it's not really denying but rather "rewriting" something due to it's nature.

 

On regular plain http requests some mangling to the request(affecting the response) is possible but when handling CONNECT requests it's a whole new story.

We don't know how the client will respond to a malformed response or squid to a malformed rewritten request, and it is possible that the client will expect a specific 50x\40x response code.

 

The external_acl interface was built as an ACL extension with the basic ability to overcome the limits of the url_rewrite interface.

Content or url filtering is an ACL level operation and not url rewriting\mangling and there for it is better(in squid) to do it in a way that the client can identify(30x).

 

The best possible way to deny such a connection(CONNECT) is using a 50x or 40x code.
I do not remember which one is accepted better by browsers and clients and you will be able to find it yourself easily adding couple lines or using the scripts I wrote before.

 

And more directly to the subject, I will say that if these network "issues" are might be because of any squid side of wrongly handling CONNECT requests that was mangled with a url_rewrite.
I would say that these specific cases is the proof of the wrongly used interface.

 

The url_rewrite might contain a bug when handling a CONNECT request but the bug is that it is handling these connections at all and not otherwise.

My suggestion is that you would try to see if you can use something like that:

## START

url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8 startup=4 idle=4 concurrency=0

url_rewrite_access deny CONNECT

url_rewrite_access allow all

## END

 

And  add another external_acl helper with the wrapper I gave you without any special deny_info for the ACL.
Squid will be able to handle these probably fine and will deny the connections using some right access deny code(don't expect fancy warning pages without using some level of ssl_bump).

 

I do not know if you need a fast solution or you are planning carefully with the available options.

The options are to either use a "fast" solution to mitigate an annoying issue or to find the right path.

The solution to either of the options is in your hands..

If for your squidGuard setup offers you the right solution from all the right aspects despite to the fact that it's working slower then other solutions then it is the solution for you!!

 

The technology of black and white listing was enhanced in the last decade but not too drastically.

The basic concept is that there are query and analysis components which are not forced to be one software.

There will always be false positives to this or another way but some categorizing systems are much stricter and sensitive about the subject then others.

All this leaving aside the sources of the lists you and since only you have a definition of the wanted\desired results with the available options.

 

You also stated that you have some funding issues, but just as a side note: the wanted result is eventually forcing the final product of work and the expense(any if at all).

I mean with these words that if you do not care about false positives and using some product satisfy the desire or need then I think it's ok for your case.

 

I will add that from my tests there are different results to basic pages\objects loading\access speed when using one software or another, and\or one protocol\interface or another.

 

Here if you need more help\advice handling the situation.

Eliezer

 

----

Eliezer Croitoru

Linux System Administrator

Mobile: +972-5-28704261

Email: eliezer at ngtech.co.il

 

 

-----Original Message-----
From: michail.pappas at gmail.com [mailto:michail.pappas at gmail.com] On Behalf Of reqman
Sent: Wednesday, June 15, 2016 2:19 PM
To: Eliezer Croitoru
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] HTTPS issues with squidguard after upgrading from squid 2.7 to 3.5

 

Hello Eliezer,

 

2016-06-15 11:45 GMT+03:00 Eliezer Croitoru < <mailto:eliezer at ngtech.co.il> eliezer at ngtech.co.il>:

> Hey Michael,

> 

> I am missing couple details about the setup which might affect the way we would be able to understand what is causing the issue and how to resolve it.

> There are changes from squid 2.7 to 3.5 and to my opinion these are mandatory to resolve and to not go one step back.

 

Yes, I saw that 3.5 effectively disabled/obsoleted/deactivated various options. I believe I took care in following through those requirements.

 

> What version of SquidGuard 1.4 did you installed? The patched for squid 3.4+ compatibility?

 

I installed a ready to use package from FreeBSD. I presume that is is ok with squid 3.4, according to its dependencies:

 

# pkg query "%do%dv" squidGuard

www/squid3.5.19

databases/db55.3.28_3

 

Other information for squidGuard:

 

# pkg info squidGuard

squidGuard-1.4_15

Name           : squidGuard

Version        : 1.4_15

Installed on   : Mon May 30 08:24:17 2016 EEST

Origin         : www/squidguard

Architecture   : freebsd:10:x86:64

Prefix         : /usr/local

Categories     : www

Licenses       : GPLv2

Maintainer     :  <mailto:garga at FreeBSD.org> garga at FreeBSD.org

WWW            :  <http://www.squidguard.org/> http://www.squidguard.org/

Comment        : Fast redirector for squid

Options        :

       DNS_BL         : off

       DOCS           : on

       EXAMPLES       : on

       LDAP           : off

       QUOTE_STRING   : off

       STRIP_NTDOMAIN : off

Shared Libs required:

       libdb-5.3.so.0

Annotations    :

       repo_type      : binary

       repository     : FreeBSD

Flat size      : 2.24MiB

 

> More details about it here: 

>  <http://bugs.squid-cache.org/show_bug.cgi?id=3978> http://bugs.squid-cache.org/show_bug.cgi?id=3978

> Now if it is indeed patched and works as expected it from the 3.4+ computability level of things then lets move on.

 

Checking the bug and if I understand correctly, if my squidGuard was not patched then it wouldn't work. This is not the case. It works ok for http urls, ie blocks fine and the user is correctly redirected to the block page setup for this purpose. It's HTTPS I'm having issues

with: according to some talks, if something gets blocked by squidguard, something is miscommunicated (or not communicated at all) with squid. Instead of a block, the users waits endlessly for the page.

 

> Are you using Squid in intercept\transparent\trpoxy mode or is it defined in the browsers directly?

> If you are using intercept mode, what have you defined on the FreeBSD pf\ipfw?

 

Squid operates in normal mode. I've configured a 10year old proxy autodiscovery script, which is published through DHCP. All browsers are set to configure everything automatically.

 

> And about the quote from the mailing list:

> SquidGuard was written to operate under the url_rewrite interface\protocol and not external_acl.

 

I've lost you here: why do I need squidGuard to operate under external_acl? Can't I leave it running with url_rewrite?

 

> Due to this it has some disadvantages and the advised details are to modify the helper(SquidGuard or another) to operate in another way.

> It is possible to use the patched version of SquidGuard under the external_acl interface and use squid options to deny\redirect the request.

 

I saw your other email, but I again have to ask. My own squidguard "seems" to work. What are the merits of doing things with external_acl instead of the way I am doing things right now?

 

> It removes some things from the complexity of the issue.

> I have just written an example on how to use use my software SquidBlocker under external_acl and here the adapted example that can be used with a patched SquidGuard:

> ## START OF SETTINGS

> external_acl_type filter_url ipv4 concurrency=0 ttl=3 %URI %SRC/- 

> %LOGIN %METHOD /usr/local/bin/squidGuard url_rewrite_children acl 

> filter_url_acl external filter_url deny_info 

>  <http://ngtech.co.il/block_page/?url=%25u&domain=%25H> http://ngtech.co.il/block_page/?url=%u&domain=%H filter_url_acl #or # 

> deny_info 302:http://ngtech.co.il/block_page/?url=%u&domain=%H 

> filter_url_acl http_access deny !filter_url_acl http_access allow 

> localnet filter_url_acl ## END OF SETTINGS

> 

> I have not tested this request format but if it doesn't work this way then a little cosmetics will make it work.

> 

> When more information will be available we can try to see where the issue is from.

> 

> Eliezer

> 

> ----

> Eliezer Croitoru

> Linux System Administrator

> Mobile: +972-5-28704261

> Email:  <mailto:eliezer at ngtech.co.il> eliezer at ngtech.co.il

> 

> 

> -----Original Message-----

> From: squid-users [ <mailto:squid-users-bounces at lists.squid-cache.org> mailto:squid-users-bounces at lists.squid-cache.org] 

> On Behalf Of reqman

> Sent: Wednesday, June 15, 2016 10:22 AM

> To:  <mailto:squid-users at lists.squid-cache.org> squid-users at lists.squid-cache.org

> Subject: [squid-users] HTTPS issues with squidguard after upgrading 

> from squid 2.7 to 3.5

> 

> Hello all,

> 

> I have been running squid 2.7.X alongside squidguard 1.4 on a FreeBSD 8.x box for years.

> Started out some 10 years ago, with a much older squid/squidguard/FreeBSD combination.

> 

> Having to upgrade to FreeBSD 10.3, I examined my option regarding squid.

> 3.5.19 was available which I assumed would behave the same as 2.7, regarding compatibility.

> Squidguard 1.4 was also installed.

> 

> - Squid was configured to behave along the lines of what I had on 2.7.

> - For squidguard I used the exact same blocklists and configurations.

> Note that I do not employ an URL rewriting in squidguard, only redirection.

> - no SSL-bump or other SSL interception takes place

> - the squidguard-related lines on squid are the following:

> 

> url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8 

> startup=4 idle=4 concurrency=0 url_rewrite_access allow all

> 

> - In squidGuard.conf, the typical redirect section is like:

> 

>  default {

>                 pass local-ok !block1 !block2 !blockN all

>                 redirect

> 301:http://localsite/block.htm?clientaddr=%a+clientname=%n+clientident=%i+srcclass=%s+targetclass=%t+url=%u

>         }

> 

> I am now experiencing problems that I did not have. Specifically, access to certain but *not* all HTTPS sites seems to timeout.

> Furthermore, I see entries similar to the following in cache.log:

> 

> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128

> remote=192.168.2.239:3446 FD 591 flags=1

> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128

> remote=192.168.2.239:3448 FD 592 flags=1

> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128

> remote=192.168.2.239:3452 FD 594 flags=1

> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128

> remote=192.168.2.239:3456 FD 596 flags=1

> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128

> remote=192.168.2.239:3454 FD 595 flags=1

> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128

> remote=192.168.2.239:3458 FD 597 flags=1

> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128

> remote=192.168.2.239:3462 FD 599 flags=1

> 

> Searching around, the closest I have come to an answer is the

> following: 

>  <http://www.squid-cache.org/mail-archive/squid-users/201211/0165.html> http://www.squid-cache.org/mail-archive/squid-users/201211/0165.html

> I am not sure though whether I am plagued by the same issue, considering that the thread refers to a squid version dated 4 years ago. And I definitely do not understand what the is meant by the poster's proposal:

> 

> "If you can't alter the re-writer to perform redirection you can work around that by using:

> 

>   acl foo ... some test to match the re-written URL ...

>   deny_info 302:%s foo

>   adapted_http_access deny foo "

> 

> Can someone help resolve this?

> Is the 2.7 series supported at all?

> As is if everything fails, I'll have to go back to it if there's some support.

> 

> BR,

> 

> 

> Michael.-

> _______________________________________________

> squid-users mailing list

>  <mailto:squid-users at lists.squid-cache.org> squid-users at lists.squid-cache.org

>  <http://lists.squid-cache.org/listinfo/squid-users> http://lists.squid-cache.org/listinfo/squid-users

> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160615/7f60c8ec/attachment.htm>

From nilesh.gavali at tcs.com  Wed Jun 15 19:14:05 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Wed, 15 Jun 2016 20:14:05 +0100
Subject: [squid-users] URL access based on AD group membership
In-Reply-To: <mailman.24918.1466011665.2892.squid-users@lists.squid-cache.org>
References: <mailman.24918.1466011665.2892.squid-users@lists.squid-cache.org>
Message-ID: <OF489A8730.CDB5F9EB-ON80257FD3.0068E26C-80257FD3.0069A7B8@tcs.com>

Thanks Amos, for reply;
My squid and AD kerberos authentication working as expected. users are 
getting authenticated and able to access internet via proxy. access logs 
also capturing user account details.

now I need to restrict user access based on AD group membership. 


Thanks & Regards
Nilesh Suresh Gavali




From:   squid-users-request at lists.squid-cache.org
To:     squid-users at lists.squid-cache.org
Date:   15/06/2016 18:27
Subject:        squid-users Digest, Vol 22, Issue 70
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org>



Send squid-users mailing list submissions to
                 squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
                 http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
                 squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
                 squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

   1. Re: HTTPS issues with squidguard after upgrading from squid
      2.7 to 3.5 (Marcus Kool)
   2. URL access based on AD group membership (nilesh.gavali at tcs.com)
   3. Re: URL access based on AD group membership (Amos Jeffries)
   4. Re: Queue incoming requests when fetching from origin
      (Alex Rousskov)
   5. Re: URL access based on AD group membership
      (Bruno de Paula Larini)


----------------------------------------------------------------------

Message: 1
Date: Wed, 15 Jun 2016 09:37:40 -0300
From: Marcus Kool <marcus.kool at urlfilterdb.com>
To: reqman <reqman at freemail.gr>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] HTTPS issues with squidguard after
                 upgrading from squid 2.7 to 3.5
Message-ID: <57614C14.4010002 at urlfilterdb.com>
Content-Type: text/plain; charset=utf-8; format=flowed



On 06/15/2016 08:24 AM, reqman wrote:

> I have been using squidGuard for 10+ years. Not the best one could
> have, but I am accustomed to its use and idiosyncrasies. Furthermore,
> it is package well supported on FreeBSD.
>
> You are mentioning ufdbGuard. Are its lists free for government use?
> If not, then I can not use it, since we have very strict purchasing
> requirements, even if it costs $1. And of course, I would have to go
> through evaluation, the usual learning curve etc.

ufdbGard is free software.
You can use it with any database you desire...  the free ones, your own or
a commercial one.

There is little learning curve since it is a fork of squidguard and there
is a Reference Manual and email support from URLfilterDB, even for those
who use a free database.

Marcus


> Don't get me wrong here, I'm not saying no. I'm just saying that even
> though it seems to be easy to say "yes", reality is much different.
>
> M.-


------------------------------

Message: 2
Date: Wed, 15 Jun 2016 14:50:38 +0100
From: nilesh.gavali at tcs.com
To: squid-users at lists.squid-cache.org
Subject: [squid-users] URL access based on AD group membership
Message-ID:
 <OF29EE7DFD.2BD1A317-ON80257FD3.004390E8-80257FD3.004C0BDD at tcs.com>
Content-Type: text/plain; charset="utf-8"

Hi Team;
I have setup as below-
Squid Kerberos authentication with windows AD 2012r2. - works fine.
Now need to restrict access based on AD Group membership.

Below configuration done but no luck. when try to access with user who is 
not part of the group mention, still he is able to browse Internet.

================================
#
# Recommended minimum configuration:
#

#auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -d -s 
GSS_C_NO_NAME
auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
HTTP/proxy02.abcd.co.uk at abcd.co.uk -d
auth_param negotiate children 10
auth_param negotiate keep_alive on
auth_param basic credentialsttl 2 hours
acl ad_auth proxy_auth REQUIRED

external_acl_type Domain_Admin %LOGIN /usr/lib64/squid/squid_ldap_group -b 

"dc=abcd,dc=co,dc=uk" -D "cn=Nilesh Gavali,ou=Admin User,ou=TCS 
Users,ou=Staff,dc=abcd,dc=co,dc=uk" -w "123456" -f 
"(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=lgInternetAccess,ou=Internet 

Access,ou=Groups,dc=abcd,dc=co,dc=uk))" -h xx.xx.2.101
acl AllowDomainAdmin external Domain_Admin lgInternetAccess

acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Only allow cachemgr access from localhost
http_access allow manager localhost
http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports


# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
#
# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
#http_access allow localhost
http_access deny !ad_auth
http_access allow ad_auth
http_access deny !AllowDomainAdmin
http_access allow AllowDomainAdmin

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 8080
never_direct allow all

cache_peer xx.xx.2.108 parent 8080 0 default
dns_nameservers xx.xx.2.108

# We recommend you to use at least the following line.
#hierarchy_stoplist cgi-bin ?

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/spool/squid 2048 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

# Log forwarding to SysLog
access_log syslog:local1.info

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
=================================================



Thanks & Regards
Nilesh Suresh Gavali
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160615/a91ac994/attachment-0001.html
>

------------------------------

Message: 3
Date: Thu, 16 Jun 2016 02:21:54 +1200
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] URL access based on AD group membership
Message-ID: <f7557bf2-bae0-e661-8368-6f4497454c89 at treenet.co.nz>
Content-Type: text/plain; charset=utf-8

On 16/06/2016 1:50 a.m., nilesh.gavali wrote:
> Hi Team;
> I have setup as below-
> Squid Kerberos authentication with windows AD 2012r2. - works fine.
> Now need to restrict access based on AD Group membership.
> 
> Below configuration done but no luck. when try to access with user who 
is 
> not part of the group mention, still he is able to browse Internet.
> 

This is because:

<snip>
Step 0) check the basic security rules that deny bad behaviour.

>
> http_access deny !ad_auth

Step 1) deny with a "require authentication" message if there are no
valid credentials sent.

> http_access allow ad_auth

Step 2) allow anyone who has valid credentials to use the proxy.

... Uh, Stop.

Users either sent valid credentials [2 happened] or they did not [1
happened]. There are no other possibilities.


> http_access deny !AllowDomainAdmin
> http_access allow AllowDomainAdmin
> 

As explained in the FAQ
<http://wiki.squid-cache.org/SquidFaq/SquidAcl#Access_Lists>

Amos



------------------------------

Message: 4
Date: Wed, 15 Jun 2016 09:19:52 -0600
From: Alex Rousskov <rousskov at measurement-factory.com>
To: Jaap Dam <jaap.dam at gmail.com>, Amos Jeffries
                 <squid3 at treenet.co.nz>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Queue incoming requests when fetching from
                 origin
Message-ID: <57617218.5050802 at measurement-factory.com>
Content-Type: text/plain; charset=utf-8

On 06/14/2016 02:51 AM, Jaap Dam wrote:

> I've part of the logging as an attachment. I'm requesting a single URL
> in this log. The log starts with a stale cache of the item. 

Collapsed forwarding does not apply to cache revalidation requests yet.
Factory is working on implementing collapsed revalidations (in some
environments), but I cannot promise a specific delivery date or that
your particular environment will be covered.

Alex.




> 2016-06-13 15:34 GMT+02:00 Amos Jeffries:
> 
>     On 14/06/2016 12:29 a.m., Jaap Dam wrote:
>     > Is the collapsed_forwarding directive the correct one to use for 
my
>     > use-case or am i missing something?
> 
>     Yes it is correct so far as I am understanding your need.
> 
>     For further debugging about what is going on you will need the HTTP
>     messages involved. Add the directive "debug_options 11,2 20,3" to 
your
>     config to get them logged in cache.log.



------------------------------

Message: 5
Date: Wed, 15 Jun 2016 14:27:14 -0300
From: Bruno de Paula Larini <bruno.larini at riosoft.com.br>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] URL access based on AD group membership
Message-ID: <eb67a218-c749-aa16-4b00-941bdac1d0a5 at riosoft.com.br>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

Em 15/06/2016 10:50, nilesh.gavali at tcs.com escreveu:
> Hi Team;
> I have setup as below-
>
>   * Squid Kerberos authentication with windows AD 2012r2. - works fine.
>   * Now need to restrict access based on AD Group membership.
>
>
> Below configuration done but no luck. when try to access with user who 
> is not part of the group mention, still he is able to browse Internet.

The following works fine for me and in my opinion works better than 
LDAP. The authentication is integrated, so it doesn't keep asking for 
password (when the current user is a domain account). But you have to 
add the Squid server to the domain using 'smb.conf', 'krb5.conf' and 
then 'net ads join'. The service 'winbind' must be running too.
I'm using Squid 3.5.19.


     auth_param ntlm program /usr/bin/ntlm_auth 
--helper-protocol=squid-2.5-ntlmssp --domain=MYDOMAIN 
--enable-external-acl-helpers="ext_wbinfo_group_acl"
     auth_param ntlm children 10 startup=0 idle=2

     external_acl_type NTGroup children-startup=10 children-idle=2 
children-max=50 %LOGIN /usr/lib64/squid/ext_wbinfo_group_acl

     acl authenticated proxy_auth REQUIRED

     acl ad_group external NTGroup MYDOMAIN\AD_Group
     acl denied_websites dstdom_regex -i "/etc/squid/denied-websites.txt"
     http_access deny ad_group denied_websites


So all the members of MYDOMAIN\AD_Group won't have access to whatever 
the file contains.

Bruno
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160615/810a3d96/attachment.html
>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 22, Issue 70
*******************************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160615/430896a2/attachment.htm>

From squid3 at treenet.co.nz  Wed Jun 15 22:21:53 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 16 Jun 2016 10:21:53 +1200
Subject: [squid-users] HTTPS issues with squidguard after upgrading from
 squid 2.7 to 3.5
In-Reply-To: <047501d1c731$7224bbf0$566e33d0$@ngtech.co.il>
References: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>
 <027e01d1c6e2$4d583530$e8089f90$@ngtech.co.il>
 <CAAvSkVGnZK2RyDgu9XYJZXq=HeBad8SfhKTDp8Aq6oTer21D7A@mail.gmail.com>
 <047501d1c731$7224bbf0$566e33d0$@ngtech.co.il>
Message-ID: <e27b0ed1-3b4c-9dba-cc8f-0639f8cc5bc3@treenet.co.nz>

On 16/06/2016 6:12 a.m., Eliezer Croitoru wrote:
> Hey Michael,
> 
>  
> 
> Well I have not tested FreeBSD dependencies and patches and I am not following them daily.
> 
> The issue itself with SquidGuard and the url_rewrite interface is more of an issue in most cases with CONNECT requests as you mentioned.
> 
> Since you are not using ssl_bump then you need to deny the traffic\requests in a way that will not leave squid or the clients and the session in an unknown or unexpected situation.
> 
> When the url_rewrite interface is used to "Deny" something it's not really denying but rather "rewriting" something due to it's nature.
> 

Well, sort of yes and sort of no.
 The url_rewrite_access allow/deny is allowing or denying the re-writer
ability to see that transaction at all. If its not even told about the
transaction it wont do anything to break it.

Amos



From reqman at freemail.gr  Thu Jun 16 05:19:09 2016
From: reqman at freemail.gr (reqman)
Date: Thu, 16 Jun 2016 08:19:09 +0300
Subject: [squid-users] HTTPS issues with squidguard after upgrading from
 squid 2.7 to 3.5
In-Reply-To: <1463336969.278847434.1465990598400.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <CAAvSkVEZD4K3nCKDEvsuQ-Gv9o-CEapC_0F=X3Huctb8WJjNgA@mail.gmail.com>
 <1463336969.278847434.1465990598400.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <CAAvSkVFW_ZD74p14VUXWZycHpFG58WvZ5FnmcpoWCvR8y2qtzA@mail.gmail.com>

Seems nice. But I did not find any concrete documentation howto.
Furthermore, answering back SSL requests without any SSL-bumping is an
issue there as well. I'll try to have a better look, time allowed.

M.-

2016-06-15 14:36 GMT+03:00 FredB <fredbmail at free.fr>:
>
>>
>> You are mentioning ufdbGuard. Are its lists free for government use?
>> If not, then I can not use it, since we have very strict purchasing
>> requirements, even if it costs $1. And of course, I would have to go
>> through evaluation, the usual learning curve etc.
>>
>> Don't get me wrong here, I'm not saying no. I'm just saying that even
>> though it seems to be easy to say "yes", reality is much different.
>>
>
> You can also use E2guardian, a free web url and content filtering proxy
> There is a package for Freebsd
>
> Fred
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From jaap.dam at gmail.com  Thu Jun 16 07:45:52 2016
From: jaap.dam at gmail.com (Jaap Dam)
Date: Thu, 16 Jun 2016 09:45:52 +0200
Subject: [squid-users] Queue incoming requests when fetching from origin
In-Reply-To: <57617218.5050802@measurement-factory.com>
References: <CAD0U=K13wKi4hytPvyBqUjdr+Thn90=R-RjE67ZG6ovE8QKo7w@mail.gmail.com>
 <acc6da17-b5eb-5a37-2ec2-80b0ae4a7fa6@treenet.co.nz>
 <CAD0U=K1FYLNXWMn595RJD33DpetGhLU=qNz4QmqMwWdEpOFo8g@mail.gmail.com>
 <57617218.5050802@measurement-factory.com>
Message-ID: <CAD0U=K2keq+foJQjbbq2Tunfp4t=z3rMfh3g1fsszqFu44oVYQ@mail.gmail.com>

Hi Alex,

Thanks for the information. Could you elaborate on when collapsed
forwarding does apply? With your extra information, my assumption would be
that it only applies on requests of a resource that has never been cached
before. Or does it make more sense in a distributed Squid setup? Not sure
if I'm missing something.

Secondly would you have a suggestion for solving the issue I'm facing?

Best regards


2016-06-15 17:19 GMT+02:00 Alex Rousskov <rousskov at measurement-factory.com>:

> On 06/14/2016 02:51 AM, Jaap Dam wrote:
>
> > I've part of the logging as an attachment. I'm requesting a single URL
> > in this log. The log starts with a stale cache of the item.
>
> Collapsed forwarding does not apply to cache revalidation requests yet.
> Factory is working on implementing collapsed revalidations (in some
> environments), but I cannot promise a specific delivery date or that
> your particular environment will be covered.
>
> Alex.
>
>
>
>
> > 2016-06-13 15:34 GMT+02:00 Amos Jeffries:
> >
> >     On 14/06/2016 12:29 a.m., Jaap Dam wrote:
> >     > Is the collapsed_forwarding directive the correct one to use for my
> >     > use-case or am i missing something?
> >
> >     Yes it is correct so far as I am understanding your need.
> >
> >     For further debugging about what is going on you will need the HTTP
> >     messages involved. Add the directive "debug_options 11,2 20,3" to
> your
> >     config to get them logged in cache.log.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160616/3bad7483/attachment.htm>

From reqman at freemail.gr  Thu Jun 16 07:54:40 2016
From: reqman at freemail.gr (reqman)
Date: Thu, 16 Jun 2016 10:54:40 +0300
Subject: [squid-users] HTTPS issues with squidguard after upgrading from
 squid 2.7 to 3.5
In-Reply-To: <047501d1c731$7224bbf0$566e33d0$@ngtech.co.il>
References: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>
 <027e01d1c6e2$4d583530$e8089f90$@ngtech.co.il>
 <CAAvSkVGnZK2RyDgu9XYJZXq=HeBad8SfhKTDp8Aq6oTer21D7A@mail.gmail.com>
 <047501d1c731$7224bbf0$566e33d0$@ngtech.co.il>
Message-ID: <CAAvSkVE442=9UqOxqa=dA3=bND=rdgg9p49TqG87vq0Zeo_uWg@mail.gmail.com>

Hello Eliezer,

first let me thank you for providing a complete and detailed
explanation, I think I understand now what gives here.

Minor note: Amos is correct in stating that url_rewrite_access
basically controls what is thrown into the redirector.

Now, before I opened this discussion I also came to the conclusion
that to get rid of these issues, I had to avoid throwing HTTPS through
a rewrite with squidguard. Indeed, setting the following solved the
issue...:

========================
url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8
startup=4 idle=4 concurrency=0
url_rewrite_access deny CONNECT
url_rewrite_access allow all
========================

... only to introduce another one: all HTTPS passes unfiltered.

So I tried to follow your advice to implement the same things, without
using url_rewrite_program. I have tested and have the patched version
of squidGuard (or so it seems). In doing so, I stumbled upon a couple
of issues that complicate the solution, specifically:

* My error redirect page can not be used when the original request was
a CONNECT one
* Even if it did, it would be complicated a bit to try and extract
additional information (ie class that registered a hit with) from
squidguard back to squid.

With your information, I was able to happily combine both the
functionality of url_rewrite_program, as well as using an external
acl.

In not so many words, the modifications to my original.
url_rewrite-based approach is to:
1) first do not use url_rewrite at all for CONNECT methods
2) modify http_access when made via CONNECT, to take into account the
external acl rule (again based on squidguard), and block via TCP_RESET

In coding this means that:
1) The initial handling with:
========================
url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8
startup=4 idle=4 concurrency=0
url_rewrite_access allow all
========================

... now becomes:
========================
url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8
startup=4 idle=4 concurrency=0
url_rewrite_access deny CONNECT
url_rewrite_access allow all
========================

2) To handle CONNECT, the existing block that handles CONNECT logic:
========================
acl CONNECT method CONNECT

http_access deny CONNECT !SSL_ports
http_access allow CONNECT
========================

becomes:

========================
acl CONNECT method CONNECT
external_acl_type filter_url ipv4 concurrency=0 ttl=3 %URI %SRC %{-}
%un %METHOD /usr/local/bin/squidGuard
acl filter_url_acl external filter_url

# Important: When an unwanted site appears in HTTPS, just forcefully
close the TCP connection!
deny_info TCP_RESET filter_url_acl

http_access deny CONNECT filter_url_acl
http_access deny CONNECT !SSL_ports

http_access allow CONNECT
========================

With this approach, some squidguard children are spawned as
redirectors (via url_rewrite_program), whereas some more are spawned
from "external_acl_type filter_url".

2016-06-15 21:12 GMT+03:00 Eliezer Croitoru <eliezer at ngtech.co.il>:
> Hey Michael,
>
>
>
> Well I have not tested FreeBSD dependencies and patches and I am not
> following them daily.
>
> The issue itself with SquidGuard and the url_rewrite interface is more of an
> issue in most cases with CONNECT requests as you mentioned.
>
> Since you are not using ssl_bump then you need to deny the traffic\requests
> in a way that will not leave squid or the clients and the session in an
> unknown or unexpected situation.
>
> When the url_rewrite interface is used to "Deny" something it's not really
> denying but rather "rewriting" something due to it's nature.
>
>
>
> On regular plain http requests some mangling to the request(affecting the
> response) is possible but when handling CONNECT requests it's a whole new
> story.
>
> We don't know how the client will respond to a malformed response or squid
> to a malformed rewritten request, and it is possible that the client will
> expect a specific 50x\40x response code.
>
>
>
> The external_acl interface was built as an ACL extension with the basic
> ability to overcome the limits of the url_rewrite interface.
>
> Content or url filtering is an ACL level operation and not url
> rewriting\mangling and there for it is better(in squid) to do it in a way
> that the client can identify(30x).
>
>
>
> The best possible way to deny such a connection(CONNECT) is using a 50x or
> 40x code.
> I do not remember which one is accepted better by browsers and clients and
> you will be able to find it yourself easily adding couple lines or using the
> scripts I wrote before.
>
>
>
> And more directly to the subject, I will say that if these network "issues"
> are might be because of any squid side of wrongly handling CONNECT requests
> that was mangled with a url_rewrite.
> I would say that these specific cases is the proof of the wrongly used
> interface.
>
>
>
> The url_rewrite might contain a bug when handling a CONNECT request but the
> bug is that it is handling these connections at all and not otherwise.
>
> My suggestion is that you would try to see if you can use something like
> that:
>
> ## START
>
> url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8
> startup=4 idle=4 concurrency=0
>
> url_rewrite_access deny CONNECT
>
> url_rewrite_access allow all
>
> ## END
>
>
>
> And  add another external_acl helper with the wrapper I gave you without any
> special deny_info for the ACL.
> Squid will be able to handle these probably fine and will deny the
> connections using some right access deny code(don't expect fancy warning
> pages without using some level of ssl_bump).
>
>
>
> I do not know if you need a fast solution or you are planning carefully with
> the available options.
>
> The options are to either use a "fast" solution to mitigate an annoying
> issue or to find the right path.
>
> The solution to either of the options is in your hands..
>
> If for your squidGuard setup offers you the right solution from all the
> right aspects despite to the fact that it's working slower then other
> solutions then it is the solution for you!!
>
>
>
> The technology of black and white listing was enhanced in the last decade
> but not too drastically.
>
> The basic concept is that there are query and analysis components which are
> not forced to be one software.
>
> There will always be false positives to this or another way but some
> categorizing systems are much stricter and sensitive about the subject then
> others.
>
> All this leaving aside the sources of the lists you and since only you have
> a definition of the wanted\desired results with the available options.
>
>
>
> You also stated that you have some funding issues, but just as a side note:
> the wanted result is eventually forcing the final product of work and the
> expense(any if at all).
>
> I mean with these words that if you do not care about false positives and
> using some product satisfy the desire or need then I think it's ok for your
> case.

I am taking care of false positives by whitelisting sites over this
last decade. My whitelisted sites are basically non-growing.

At some point I *will* have to look at something else. But first, I'll
have to examine:
1) Which software to use: e2guardian and ufdbguard were referenced.
I'll have to delve into some study here
2) Same thing on which free *lists* to use. Will definitely need some
reading here too.

Again, thanks for taking all this time to respond. HUGELY appreciated :)

> I will add that from my tests there are different results to basic
> pages\objects loading\access speed when using one software or another,
> and\or one protocol\interface or another.
>
>
>
> Here if you need more help\advice handling the situation.
>
> Eliezer
>
>
>
> ----
>
> Eliezer Croitoru
>
> Linux System Administrator
>
> Mobile: +972-5-28704261
>
> Email: eliezer at ngtech.co.il
>
>
>
>
>
> -----Original Message-----
> From: michail.pappas at gmail.com [mailto:michail.pappas at gmail.com] On Behalf
> Of reqman
> Sent: Wednesday, June 15, 2016 2:19 PM
> To: Eliezer Croitoru
> Cc: squid-users at lists.squid-cache.org
>
> Subject: Re: [squid-users] HTTPS issues with squidguard after upgrading from
> squid 2.7 to 3.5
>
>
>
> Hello Eliezer,
>
>
>
> 2016-06-15 11:45 GMT+03:00 Eliezer Croitoru <eliezer at ngtech.co.il>:
>
>> Hey Michael,
>
>>
>
>> I am missing couple details about the setup which might affect the way we
>> would be able to understand what is causing the issue and how to resolve it.
>
>> There are changes from squid 2.7 to 3.5 and to my opinion these are
>> mandatory to resolve and to not go one step back.
>
>
>
> Yes, I saw that 3.5 effectively disabled/obsoleted/deactivated various
> options. I believe I took care in following through those requirements.
>
>
>
>> What version of SquidGuard 1.4 did you installed? The patched for squid
>> 3.4+ compatibility?
>
>
>
> I installed a ready to use package from FreeBSD. I presume that is is ok
> with squid 3.4, according to its dependencies:
>
>
>
> # pkg query "%do%dv" squidGuard
>
> www/squid3.5.19
>
> databases/db55.3.28_3
>
>
>
> Other information for squidGuard:
>
>
>
> # pkg info squidGuard
>
> squidGuard-1.4_15
>
> Name           : squidGuard
>
> Version        : 1.4_15
>
> Installed on   : Mon May 30 08:24:17 2016 EEST
>
> Origin         : www/squidguard
>
> Architecture   : freebsd:10:x86:64
>
> Prefix         : /usr/local
>
> Categories     : www
>
> Licenses       : GPLv2
>
> Maintainer     : garga at FreeBSD.org
>
> WWW            : http://www.squidguard.org/
>
> Comment        : Fast redirector for squid
>
> Options        :
>
>        DNS_BL         : off
>
>        DOCS           : on
>
>        EXAMPLES       : on
>
>        LDAP           : off
>
>        QUOTE_STRING   : off
>
>        STRIP_NTDOMAIN : off
>
> Shared Libs required:
>
>        libdb-5.3.so.0
>
> Annotations    :
>
>        repo_type      : binary
>
>        repository     : FreeBSD
>
> Flat size      : 2.24MiB
>
>
>
>> More details about it here:
>
>> http://bugs.squid-cache.org/show_bug.cgi?id=3978
>
>> Now if it is indeed patched and works as expected it from the 3.4+
>> computability level of things then lets move on.
>
>
>
> Checking the bug and if I understand correctly, if my squidGuard was not
> patched then it wouldn't work. This is not the case. It works ok for http
> urls, ie blocks fine and the user is correctly redirected to the block page
> setup for this purpose. It's HTTPS I'm having issues
>
> with: according to some talks, if something gets blocked by squidguard,
> something is miscommunicated (or not communicated at all) with squid.
> Instead of a block, the users waits endlessly for the page.
>
>
>
>> Are you using Squid in intercept\transparent\trpoxy mode or is it defined
>> in the browsers directly?
>
>> If you are using intercept mode, what have you defined on the FreeBSD
>> pf\ipfw?
>
>
>
> Squid operates in normal mode. I've configured a 10year old proxy
> autodiscovery script, which is published through DHCP. All browsers are set
> to configure everything automatically.
>
>
>
>> And about the quote from the mailing list:
>
>> SquidGuard was written to operate under the url_rewrite interface\protocol
>> and not external_acl.
>
>
>
> I've lost you here: why do I need squidGuard to operate under external_acl?
> Can't I leave it running with url_rewrite?
>
>
>
>> Due to this it has some disadvantages and the advised details are to
>> modify the helper(SquidGuard or another) to operate in another way.
>
>> It is possible to use the patched version of SquidGuard under the
>> external_acl interface and use squid options to deny\redirect the request.
>
>
>
> I saw your other email, but I again have to ask. My own squidguard "seems"
> to work. What are the merits of doing things with external_acl instead of
> the way I am doing things right now?
>
>
>
>> It removes some things from the complexity of the issue.
>
>> I have just written an example on how to use use my software SquidBlocker
>> under external_acl and here the adapted example that can be used with a
>> patched SquidGuard:
>
>> ## START OF SETTINGS
>
>> external_acl_type filter_url ipv4 concurrency=0 ttl=3 %URI %SRC/-
>
>> %LOGIN %METHOD /usr/local/bin/squidGuard url_rewrite_children acl
>
>> filter_url_acl external filter_url deny_info
>
>> http://ngtech.co.il/block_page/?url=%u&domain=%H filter_url_acl #or #
>
>> deny_info 302:http://ngtech.co.il/block_page/?url=%u&domain=%H
>
>> filter_url_acl http_access deny !filter_url_acl http_access allow
>
>> localnet filter_url_acl ## END OF SETTINGS
>
>>
>
>> I have not tested this request format but if it doesn't work this way then
>> a little cosmetics will make it work.
>
>>
>
>> When more information will be available we can try to see where the issue
>> is from.
>
>>
>
>> Eliezer
>
>>
>
>> ----
>
>> Eliezer Croitoru
>
>> Linux System Administrator
>
>> Mobile: +972-5-28704261
>
>> Email: eliezer at ngtech.co.il
>
>>
>
>>
>
>> -----Original Message-----
>
>> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
>
>> On Behalf Of reqman
>
>> Sent: Wednesday, June 15, 2016 10:22 AM
>
>> To: squid-users at lists.squid-cache.org
>
>> Subject: [squid-users] HTTPS issues with squidguard after upgrading
>
>> from squid 2.7 to 3.5
>
>>
>
>> Hello all,
>
>>
>
>> I have been running squid 2.7.X alongside squidguard 1.4 on a FreeBSD 8.x
>> box for years.
>
>> Started out some 10 years ago, with a much older squid/squidguard/FreeBSD
>> combination.
>
>>
>
>> Having to upgrade to FreeBSD 10.3, I examined my option regarding squid.
>
>> 3.5.19 was available which I assumed would behave the same as 2.7,
>> regarding compatibility.
>
>> Squidguard 1.4 was also installed.
>
>>
>
>> - Squid was configured to behave along the lines of what I had on 2.7.
>
>> - For squidguard I used the exact same blocklists and configurations.
>
>> Note that I do not employ an URL rewriting in squidguard, only
>> redirection.
>
>> - no SSL-bump or other SSL interception takes place
>
>> - the squidguard-related lines on squid are the following:
>
>>
>
>> url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8
>
>> startup=4 idle=4 concurrency=0 url_rewrite_access allow all
>
>>
>
>> - In squidGuard.conf, the typical redirect section is like:
>
>>
>
>>  default {
>
>>                 pass local-ok !block1 !block2 !blockN all
>
>>                 redirect
>
>>
>> 301:http://localsite/block.htm?clientaddr=%a+clientname=%n+clientident=%i+srcclass=%s+targetclass=%t+url=%u
>
>>         }
>
>>
>
>> I am now experiencing problems that I did not have. Specifically, access
>> to certain but *not* all HTTPS sites seems to timeout.
>
>> Furthermore, I see entries similar to the following in cache.log:
>
>>
>
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>
>> remote=192.168.2.239:3446 FD 591 flags=1
>
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>
>> remote=192.168.2.239:3448 FD 592 flags=1
>
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>
>> remote=192.168.2.239:3452 FD 594 flags=1
>
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>
>> remote=192.168.2.239:3456 FD 596 flags=1
>
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>
>> remote=192.168.2.239:3454 FD 595 flags=1
>
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>
>> remote=192.168.2.239:3458 FD 597 flags=1
>
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>
>> remote=192.168.2.239:3462 FD 599 flags=1
>
>>
>
>> Searching around, the closest I have come to an answer is the
>
>> following:
>
>> http://www.squid-cache.org/mail-archive/squid-users/201211/0165.html
>
>> I am not sure though whether I am plagued by the same issue, considering
>> that the thread refers to a squid version dated 4 years ago. And I
>> definitely do not understand what the is meant by the poster's proposal:
>
>>
>
>> "If you can't alter the re-writer to perform redirection you can work
>> around that by using:
>
>>
>
>>   acl foo ... some test to match the re-written URL ...
>
>>   deny_info 302:%s foo
>
>>   adapted_http_access deny foo "
>
>>
>
>> Can someone help resolve this?
>
>> Is the 2.7 series supported at all?
>
>> As is if everything fails, I'll have to go back to it if there's some
>> support.
>
>>
>
>> BR,
>
>>
>
>>
>
>> Michael.-
>
>> _______________________________________________
>
>> squid-users mailing list
>
>> squid-users at lists.squid-cache.org
>
>> http://lists.squid-cache.org/listinfo/squid-users
>
>>


From nilesh.gavali at tcs.com  Thu Jun 16 08:57:43 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Thu, 16 Jun 2016 09:57:43 +0100
Subject: [squid-users] URL access based on AD group membership
In-Reply-To: <OF489A8730.CDB5F9EB-ON80257FD3.0068E26C-80257FD3.0069A74D@LocalDomain>
References: <mailman.24918.1466011665.2892.squid-users@lists.squid-cache.org>
 <OF489A8730.CDB5F9EB-ON80257FD3.0068E26C-80257FD3.0069A74D@LocalDomain>
Message-ID: <OF00EEB6B5.2CF01D59-ON80257FD4.00312616-80257FD4.00313974@tcs.com>

Hello Team/Amos;
can you pls...awaiting reply

Thanks & Regards
Nilesh Suresh Gavali




From:   Nilesh Gavali/MUM/TCS
To:     squid-users at lists.squid-cache.org, squid3 at treenet.co.nz
Date:   15/06/2016 20:14
Subject:        URL access based on AD group membership


Thanks Amos, for reply;
My squid and AD kerberos authentication working as expected. users are 
getting authenticated and able to access internet via proxy. access logs 
also capturing user account details.

now I need to restrict user access based on AD group membership. 


Thanks & Regards
Nilesh Suresh Gavali





From:   squid-users-request at lists.squid-cache.org
To:     squid-users at lists.squid-cache.org
Date:   15/06/2016 18:27
Subject:        squid-users Digest, Vol 22, Issue 70
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org>



Send squid-users mailing list submissions to
                 squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
                 http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
                 squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
                 squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

   1. Re: HTTPS issues with squidguard after upgrading from squid
      2.7 to 3.5 (Marcus Kool)
   2. URL access based on AD group membership (nilesh.gavali at tcs.com)
   3. Re: URL access based on AD group membership (Amos Jeffries)
   4. Re: Queue incoming requests when fetching from origin
      (Alex Rousskov)
   5. Re: URL access based on AD group membership
      (Bruno de Paula Larini)


----------------------------------------------------------------------

Message: 1
Date: Wed, 15 Jun 2016 09:37:40 -0300
From: Marcus Kool <marcus.kool at urlfilterdb.com>
To: reqman <reqman at freemail.gr>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] HTTPS issues with squidguard after
                 upgrading from squid 2.7 to 3.5
Message-ID: <57614C14.4010002 at urlfilterdb.com>
Content-Type: text/plain; charset=utf-8; format=flowed



On 06/15/2016 08:24 AM, reqman wrote:

> I have been using squidGuard for 10+ years. Not the best one could
> have, but I am accustomed to its use and idiosyncrasies. Furthermore,
> it is package well supported on FreeBSD.
>
> You are mentioning ufdbGuard. Are its lists free for government use?
> If not, then I can not use it, since we have very strict purchasing
> requirements, even if it costs $1. And of course, I would have to go
> through evaluation, the usual learning curve etc.

ufdbGard is free software.
You can use it with any database you desire...  the free ones, your own or
a commercial one.

There is little learning curve since it is a fork of squidguard and there
is a Reference Manual and email support from URLfilterDB, even for those
who use a free database.

Marcus


> Don't get me wrong here, I'm not saying no. I'm just saying that even
> though it seems to be easy to say "yes", reality is much different.
>
> M.-


------------------------------

Message: 2
Date: Wed, 15 Jun 2016 14:50:38 +0100
From: nilesh.gavali at tcs.com
To: squid-users at lists.squid-cache.org
Subject: [squid-users] URL access based on AD group membership
Message-ID:
 <OF29EE7DFD.2BD1A317-ON80257FD3.004390E8-80257FD3.004C0BDD at tcs.com>
Content-Type: text/plain; charset="utf-8"

Hi Team;
I have setup as below-
Squid Kerberos authentication with windows AD 2012r2. - works fine.
Now need to restrict access based on AD Group membership.

Below configuration done but no luck. when try to access with user who is 
not part of the group mention, still he is able to browse Internet.

================================
#
# Recommended minimum configuration:
#

#auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -d -s 
GSS_C_NO_NAME
auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
HTTP/proxy02.abcd.co.uk at abcd.co.uk -d
auth_param negotiate children 10
auth_param negotiate keep_alive on
auth_param basic credentialsttl 2 hours
acl ad_auth proxy_auth REQUIRED

external_acl_type Domain_Admin %LOGIN /usr/lib64/squid/squid_ldap_group -b 

"dc=abcd,dc=co,dc=uk" -D "cn=Nilesh Gavali,ou=Admin User,ou=TCS 
Users,ou=Staff,dc=abcd,dc=co,dc=uk" -w "123456" -f 
"(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=lgInternetAccess,ou=Internet 

Access,ou=Groups,dc=abcd,dc=co,dc=uk))" -h xx.xx.2.101
acl AllowDomainAdmin external Domain_Admin lgInternetAccess

acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Only allow cachemgr access from localhost
http_access allow manager localhost
http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports


# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
#
# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
#http_access allow localhost
http_access deny !ad_auth
http_access allow ad_auth
http_access deny !AllowDomainAdmin
http_access allow AllowDomainAdmin

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 8080
never_direct allow all

cache_peer xx.xx.2.108 parent 8080 0 default
dns_nameservers xx.xx.2.108

# We recommend you to use at least the following line.
#hierarchy_stoplist cgi-bin ?

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/spool/squid 2048 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

# Log forwarding to SysLog
access_log syslog:local1.info

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
=================================================



Thanks & Regards
Nilesh Suresh Gavali
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160615/a91ac994/attachment-0001.html
>

------------------------------

Message: 3
Date: Thu, 16 Jun 2016 02:21:54 +1200
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] URL access based on AD group membership
Message-ID: <f7557bf2-bae0-e661-8368-6f4497454c89 at treenet.co.nz>
Content-Type: text/plain; charset=utf-8

On 16/06/2016 1:50 a.m., nilesh.gavali wrote:
> Hi Team;
> I have setup as below-
> Squid Kerberos authentication with windows AD 2012r2. - works fine.
> Now need to restrict access based on AD Group membership.
> 
> Below configuration done but no luck. when try to access with user who 
is 
> not part of the group mention, still he is able to browse Internet.
> 

This is because:

<snip>
Step 0) check the basic security rules that deny bad behaviour.

>
> http_access deny !ad_auth

Step 1) deny with a "require authentication" message if there are no
valid credentials sent.

> http_access allow ad_auth

Step 2) allow anyone who has valid credentials to use the proxy.

... Uh, Stop.

Users either sent valid credentials [2 happened] or they did not [1
happened]. There are no other possibilities.


> http_access deny !AllowDomainAdmin
> http_access allow AllowDomainAdmin
> 

As explained in the FAQ
<http://wiki.squid-cache.org/SquidFaq/SquidAcl#Access_Lists>

Amos



------------------------------

Message: 4
Date: Wed, 15 Jun 2016 09:19:52 -0600
From: Alex Rousskov <rousskov at measurement-factory.com>
To: Jaap Dam <jaap.dam at gmail.com>, Amos Jeffries
                 <squid3 at treenet.co.nz>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Queue incoming requests when fetching from
                 origin
Message-ID: <57617218.5050802 at measurement-factory.com>
Content-Type: text/plain; charset=utf-8

On 06/14/2016 02:51 AM, Jaap Dam wrote:

> I've part of the logging as an attachment. I'm requesting a single URL
> in this log. The log starts with a stale cache of the item. 

Collapsed forwarding does not apply to cache revalidation requests yet.
Factory is working on implementing collapsed revalidations (in some
environments), but I cannot promise a specific delivery date or that
your particular environment will be covered.

Alex.




> 2016-06-13 15:34 GMT+02:00 Amos Jeffries:
> 
>     On 14/06/2016 12:29 a.m., Jaap Dam wrote:
>     > Is the collapsed_forwarding directive the correct one to use for 
my
>     > use-case or am i missing something?
> 
>     Yes it is correct so far as I am understanding your need.
> 
>     For further debugging about what is going on you will need the HTTP
>     messages involved. Add the directive "debug_options 11,2 20,3" to 
your
>     config to get them logged in cache.log.



------------------------------

Message: 5
Date: Wed, 15 Jun 2016 14:27:14 -0300
From: Bruno de Paula Larini <bruno.larini at riosoft.com.br>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] URL access based on AD group membership
Message-ID: <eb67a218-c749-aa16-4b00-941bdac1d0a5 at riosoft.com.br>
Content-Type: text/plain; charset="utf-8"; Format="flowed"

Em 15/06/2016 10:50, nilesh.gavali at tcs.com escreveu:
> Hi Team;
> I have setup as below-
>
>   * Squid Kerberos authentication with windows AD 2012r2. - works fine.
>   * Now need to restrict access based on AD Group membership.
>
>
> Below configuration done but no luck. when try to access with user who 
> is not part of the group mention, still he is able to browse Internet.

The following works fine for me and in my opinion works better than 
LDAP. The authentication is integrated, so it doesn't keep asking for 
password (when the current user is a domain account). But you have to 
add the Squid server to the domain using 'smb.conf', 'krb5.conf' and 
then 'net ads join'. The service 'winbind' must be running too.
I'm using Squid 3.5.19.


     auth_param ntlm program /usr/bin/ntlm_auth 
--helper-protocol=squid-2.5-ntlmssp --domain=MYDOMAIN 
--enable-external-acl-helpers="ext_wbinfo_group_acl"
     auth_param ntlm children 10 startup=0 idle=2

     external_acl_type NTGroup children-startup=10 children-idle=2 
children-max=50 %LOGIN /usr/lib64/squid/ext_wbinfo_group_acl

     acl authenticated proxy_auth REQUIRED

     acl ad_group external NTGroup MYDOMAIN\AD_Group
     acl denied_websites dstdom_regex -i "/etc/squid/denied-websites.txt"
     http_access deny ad_group denied_websites


So all the members of MYDOMAIN\AD_Group won't have access to whatever 
the file contains.

Bruno
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160615/810a3d96/attachment.html
>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 22, Issue 70
*******************************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160616/a1843db1/attachment.htm>

From afranoux at orange.fr  Thu Jun 16 09:54:37 2016
From: afranoux at orange.fr (afranoux)
Date: Thu, 16 Jun 2016 11:54:37 +0200
Subject: [squid-users] SSL Bump with valid CA
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAE5/wh9VY+xGl1QzRO9uZFcBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADj3tsFCn/zRKFQ6nSSsIjzAQAAAAA=@orange.fr>

Hello,

 

I'm student in computer lab and i finish a squid 3.5.19  with SSL-bump with
self signed certificat in intercept mode (work well).

Now i need to try to configurate squid with a non self-signed certificate

 

My gait:

 

openssl genrsa 2048 > redrocks.key

openssl req -new -key redrocks.key > redrocks.csr

 

after a visit to StartSSL in "Client S/MIME and Authentication Certificate"
i receive crt

 

openssl pkcs12 -export -in redrocks.crt -inkey redrocks.key -out
redrocks.p12

openssl pkcs12 -in redrocks.p12 -nodes -out redrocks.pem

 

 

squid.conf:

 

http_port 3128 intercept

https_port 3129 intercept ssl-bump \

                generate-host-certificates=on \

                dynamic_cert_mem_cache_size=4MB \

                cert=/etc/squid/ssl_cert/redrocks.pem \

                key=/etc/squid/ssl_cert/redrocks.pem

 

To read you, 

 

Cordially

 

Arnaud

 

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160616/16eec5d8/attachment.htm>

From marcus.kool at urlfilterdb.com  Thu Jun 16 10:24:13 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Thu, 16 Jun 2016 07:24:13 -0300
Subject: [squid-users] HTTPS issues with squidguard after upgrading from
 squid 2.7 to 3.5
In-Reply-To: <CAAvSkVFW_ZD74p14VUXWZycHpFG58WvZ5FnmcpoWCvR8y2qtzA@mail.gmail.com>
References: <CAAvSkVEZD4K3nCKDEvsuQ-Gv9o-CEapC_0F=X3Huctb8WJjNgA@mail.gmail.com>
 <1463336969.278847434.1465990598400.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <CAAvSkVFW_ZD74p14VUXWZycHpFG58WvZ5FnmcpoWCvR8y2qtzA@mail.gmail.com>
Message-ID: <57627E4D.9070800@urlfilterdb.com>



On 06/16/2016 02:19 AM, reqman wrote:
> Seems nice. But I did not find any concrete documentation howto.

There is a Reference Manual at the download section of ufdbGuard:
https://www.urlfilterdb.com/downloads/software_doc.html

There is also a mailing list for ufdbGuard at sourceforge and
you can email the support desk.  We do answer and usually within a few hours.

Marcus

> Furthermore, answering back SSL requests without any SSL-bumping is an
> issue there as well. I'll try to have a better look, time allowed.
>
> M.-
>
> 2016-06-15 14:36 GMT+03:00 FredB <fredbmail at free.fr>:
>>
>>>
>>> You are mentioning ufdbGuard. Are its lists free for government use?
>>> If not, then I can not use it, since we have very strict purchasing
>>> requirements, even if it costs $1. And of course, I would have to go
>>> through evaluation, the usual learning curve etc.
>>>
>>> Don't get me wrong here, I'm not saying no. I'm just saying that even
>>> though it seems to be easy to say "yes", reality is much different.
>>>
>>
>> You can also use E2guardian, a free web url and content filtering proxy
>> There is a package for Freebsd
>>
>> Fred
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From nilesh.gavali at tcs.com  Thu Jun 16 12:03:59 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Thu, 16 Jun 2016 13:03:59 +0100
Subject: [squid-users] URL access based on AD group membership
In-Reply-To: <OF29EE7DFD.2BD1A317-ON80257FD3.004390E8-80257FD3.004C0B12@LocalDomain>
References: <OF29EE7DFD.2BD1A317-ON80257FD3.004390E8-80257FD3.004C0B12@LocalDomain>
Message-ID: <OF6BB0068B.0EA71062-ON80257FD4.0041CB87-80257FD4.0042474E@tcs.com>

Team;
Further to me earlier mail , I did some test with LDAP group. but still no 
solution. 
I am able to authenticate with squid_ldap_auth helper but when I use 
squid_ldap_group helper it send error. pls let me know what i am doing 
wrong. Below is the o/p from the helper command.
Same use is able to authenticate with squid_ldap_auth but same is not 
accepting with squid_ldap_group.

=============================
[root at Proxy squid]# ./squid_ldap_auth -P -s sub -R -u cn -b 
"OU=Proxy,OU=Service Accounts,OU=TCS Users,OU=Staff,DC=ABCD,DC=GOV,DC=IN" 
-h ABCD.GOV.IN
svcproxy 123456789
OK

[root at Proxy squid]# ./squid_ldap_group -b "dc=Proxy,dc=Service 
Accounts,dc=TCS Users,dc=Staff,dc=ABCD,dc=GOV,dc=IN" -D 
"cn=svcproxy,ou=Proxy,ou=Service Accounts,ou=TCS 
Users,dc=Staff,dc=ABCD,dc=GOV,dc=IN" -w "123456789" -f 
"(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%a,ou=InternetAccess,ou=Groups,dc=ABCD,dc=GOV,dc=IN))" 
-h ABCD.GOV.IN
da.1234 InternetAccess
squid_ldap_group WARNING, could not bind to binddn 'Invalid credentials'
ERR
====================================




Thanks & Regards
Nilesh Suresh Gavali




From:   Nilesh Gavali/MUM/TCS
To:     squid-users at lists.squid-cache.org
Date:   15/06/2016 14:50
Subject:        URL access based on AD group membership


Hi Team;
I have setup as below-
Squid Kerberos authentication with windows AD 2012r2. - works fine.
Now need to restrict access based on AD Group membership.

Below configuration done but no luck. when try to access with user who is 
not part of the group mention, still he is able to browse Internet.

================================
#
# Recommended minimum configuration:
#

#auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -d -s 
GSS_C_NO_NAME
auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
HTTP/proxy02.abcd.co.uk at abcd.co.uk -d
auth_param negotiate children 10
auth_param negotiate keep_alive on
auth_param basic credentialsttl 2 hours
acl ad_auth proxy_auth REQUIRED

external_acl_type Domain_Admin %LOGIN /usr/lib64/squid/squid_ldap_group -b 
"dc=abcd,dc=co,dc=uk" -D "cn=Nilesh Gavali,ou=Admin User,ou=TCS 
Users,ou=Staff,dc=abcd,dc=co,dc=uk" -w "123456" -f 
"(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=lgInternetAccess,ou=Internet 
Access,ou=Groups,dc=abcd,dc=co,dc=uk))" -h xx.xx.2.101
acl AllowDomainAdmin external Domain_Admin lgInternetAccess

acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Only allow cachemgr access from localhost
http_access allow manager localhost
http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports


# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
#
# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
#http_access allow localhost
http_access deny !ad_auth
http_access allow ad_auth
http_access deny !AllowDomainAdmin
http_access allow AllowDomainAdmin

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 8080
never_direct allow all

cache_peer xx.xx.2.108 parent 8080 0 default
dns_nameservers xx.xx.2.108

# We recommend you to use at least the following line.
#hierarchy_stoplist cgi-bin ?

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/spool/squid 2048 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

# Log forwarding to SysLog
access_log syslog:local1.info

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
=================================================



Thanks & Regards
Nilesh Suresh Gavali

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160616/87644c85/attachment.htm>

From alex at nanogherkin.com  Thu Jun 16 14:48:13 2016
From: alex at nanogherkin.com (Alex Crow)
Date: Thu, 16 Jun 2016 15:48:13 +0100
Subject: [squid-users] SSL Bump with valid CA
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAE5/wh9VY+xGl1QzRO9uZFcBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADj3tsFCn/zRKFQ6nSSsIjzAQAAAAA=@orange.fr>
References: <!&!AAAAAAAAAAAuAAAAAAAAAE5/wh9VY+xGl1QzRO9uZFcBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADj3tsFCn/zRKFQ6nSSsIjzAQAAAAA=@orange.fr>
Message-ID: <5762BC2D.6010104@nanogherkin.com>




> 
> Now i need to try to configurate squid with a non self-signed certificate
> 

This is impossible, as you don't have access to the CA's signing key,
for very good reason (you could create certs for any site in the world
and it would be trusted by any browser that trusts StartSSL's CA).

You can ask them for it and see what they say, but be prepared for a
rude response!

Cheers

Alex




From rousskov at measurement-factory.com  Thu Jun 16 15:20:53 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 16 Jun 2016 09:20:53 -0600
Subject: [squid-users] Queue incoming requests when fetching from origin
In-Reply-To: <CAD0U=K2keq+foJQjbbq2Tunfp4t=z3rMfh3g1fsszqFu44oVYQ@mail.gmail.com>
References: <CAD0U=K13wKi4hytPvyBqUjdr+Thn90=R-RjE67ZG6ovE8QKo7w@mail.gmail.com>
 <acc6da17-b5eb-5a37-2ec2-80b0ae4a7fa6@treenet.co.nz>
 <CAD0U=K1FYLNXWMn595RJD33DpetGhLU=qNz4QmqMwWdEpOFo8g@mail.gmail.com>
 <57617218.5050802@measurement-factory.com>
 <CAD0U=K2keq+foJQjbbq2Tunfp4t=z3rMfh3g1fsszqFu44oVYQ@mail.gmail.com>
Message-ID: <5762C3D5.3070000@measurement-factory.com>

On 06/16/2016 01:45 AM, Jaap Dam wrote:

> Thanks for the information. Could you elaborate on when collapsed
> forwarding does apply?

Squid is currently able to collapse HTTP client [miss] requests (but not
internally generated HTTP requests triggered by HTTP client requests).
Furthermore, to be collapsable, the request must have no markings that
make the future response uncachable.


> With your extra information, my assumption would
> be that it only applies on requests of a resource that has never been
> cached before.

I would not phrase it like that because Squid does not remember was has
been cached before, only what is still cached at the query time. There
are three primary cases for an HTTP client request to consider here:

* pure cache hit: Collapsing is inapplicable because Squid does not send
any requests (there is nothing to collapse). Each HTTP client request is
satisfied from the Squid cache.

* pure cache miss: Multiple requests for the same missing object can be
collapsed if collapsed_forwarding is enabled. Collapsable requests have
no markings that make the future response uncachable.

* revalidation: The requested object was found in the cache but it was
stale. Squid sends an internal "revalidation" request to the origin
server or peer. These internal requests are currently not collapsed. We
are working on collapsing them as well.


> Secondly would you have a suggestion for solving the issue I'm facing?


I have not studied the issue you are facing, but if you think collapsing
revalidation requests would solve your problem, then either wait for us
to finish initial collapsed revalidation support (and then see if it
solves your problem) or co-sponsor that ongoing development (to make
sure it solves your problem).


HTH,

Alex.



> 2016-06-15 17:19 GMT+02:00 Alex Rousskov:
> 
>     On 06/14/2016 02:51 AM, Jaap Dam wrote:
> 
>     > I've part of the logging as an attachment. I'm requesting a single URL
>     > in this log. The log starts with a stale cache of the item.
> 
>     Collapsed forwarding does not apply to cache revalidation requests yet.
>     Factory is working on implementing collapsed revalidations (in some
>     environments), but I cannot promise a specific delivery date or that
>     your particular environment will be covered.
> 
>     Alex.
> 
> 
> 
> 
>     > 2016-06-13 15:34 GMT+02:00 Amos Jeffries:
>     >
>     >     On 14/06/2016 12:29 a.m., Jaap Dam wrote:
>     >     > Is the collapsed_forwarding directive the correct one to use
>     for my
>     >     > use-case or am i missing something?
>     >
>     >     Yes it is correct so far as I am understanding your need.
>     >
>     >     For further debugging about what is going on you will need the
>     HTTP
>     >     messages involved. Add the directive "debug_options 11,2 20,3"
>     to your
>     >     config to get them logged in cache.log.
> 
> 



From alfrenovsky at gmail.com  Thu Jun 16 19:11:50 2016
From: alfrenovsky at gmail.com (Alfredo Rezinovsky)
Date: Thu, 16 Jun 2016 16:11:50 -0300
Subject: [squid-users] Regex optimization
In-Reply-To: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
References: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
Message-ID: <CAMXC=WuPng+0G1d=sN6ps8XnBj=dsF8JzoLPwduftOYYxY2E9g@mail.gmail.com>

Well.. I tried.
I need to ban 8613 URLs. Because a law.

If I put one per line in a file and set the filename for an url_regex acl
it works. But when the traffic goes up the cpu load goes 100% (even using
workers) and the proxy turns unusable.

I tested and saw my squid can't parse regexes with more than 8192
characters.
I managed to combine the 8000 uris in 34 regexes using a ruby gem, and the
cpu load stays almost at the same level it is without any acl (same
traffic).

The problem is that of the 34 regexes 33 works fine and 1 matches
everything.

"http://something" matches.

the regex is:

^http:\/\/(m(i(n(i(\.free\-teen\-pussy\.com\/scj\/thumbs\/(0\/(253_Mini_Mini\.jpg|306_Mini_Mini\.jpg|468_Pree_Pree\.jpg|519_Models_Models\.jpg|688_Models_nn\.jpg|7(17_Models_Models\.jpg|22_Models_Mini\.jpg)|880_nn_Models\.jpg)|1\/(170_little_models\.jpg|271_Young_Young\.jpg|330_models_little\.jpg|412_little_models\.jpg|6(28_little_models\.jpg|43_little_little\.jpg)|742_Young_Young\.jpg|877_littlemodels_littlemodels\.jpg|903_littlemodels_littlemodels\.jpg)|2\/(0(47_models_little\.jpg|92_models_models\.jpg)|1(44_little_little\.jpg|75_Young_Young\.jpg)|2(04_littlemodels_littlemodels\.jpg|29_russian_russian\.jpg|76_russian_little\.jpg)))|girls\.biz)|t(ladies\.com\/|teens\.com\/))|ragetube\.com\/content\/(35\/907_un_pequena\.jpg|75\/939_sex_Simpsons\.jpg|95\/473_Babe_039\.jpg))|mmgay\.com\/|o(dels(\.world\-collections\.com\/index\.html\?(4[69]|7(34|7)|88)|\-(hot\.net\/|me\.com\/index\.html\?(23|838)))|e(img(1\.moesearch\.net\/imgs1\/01058000\/1058747\.jpg|2\.moesearch\.net\/imgs2\/(0(1058000\/1058604\.jpg|2095000\/2095432\.jpg|4027000\/4027262\.jpg)|12509000\/12509478\.jpg))|search\.net\/img\.php\?mode=view&id=1058747)|ist\.lolajunior\.com\/images\/cache\/240x180\/(1(00\.125\.1231425553\.jpg|11\.85\.1921663855\.jpg|40\.76\.1735890287\.jpg|50\.115\.1167057586\.jpg|6(1\.133\.2028798891\.jpg|6\.130\.165837020\.jpg|7\.111\.1548016707\.jpg)|72\.107\.88564122\.jpg)|2(42\.142\.777367129\.jpg|76\.170\.1873449959\.jpg)|95\.80\.959860653\.jpg)|n(dayporn\.com\/f\/teen\/|stercams\.in\/)|ppetdollz\.com\/|r(asmovie\.com\/|e\-porn\.net\/)|ther\.taboo\.cc\/images\/cache\/300x250\/191\.170\.32154737\.jpg|v(\.(18\-21\-teens\.com\/|ftvcash\.com\/Free\-Movies\/galleries\/FTV\/1\/165\/)|ie(1820\.com\/trifuns\/sabine\.61sec\.shtml|galls(1(\.t(eensexreality\.com\/665\/\?nats=MjgwOjI6NA|inseks\.com\/video2\/070\/\?nats=MjI6Mjo2,0,0,0,5506)|2\.teenburg\.com\/262\-265\/265\/070\/\?nats=Mjc6Mjox)|3\.teen(burg\.com\/videos15\/093\/\?nats=MTc6Mjox,0,0,0,4396|sexreality\.com\/videos3\/042\/\?nats=MjU6Mjo0))|pornshop\.com\/?|sroom\.net\/index2\.shtml)))|pxgirls\.com\/stream\/thumbs\/(196\/196614\.jpg|96\/96855\.jpg)|rpornsite\.com\/tube\/teen\/|snwhores\.com\/|u(lti(\.xnxx\.com\/gallery\/132750\/ad59\/|grab\.olimptraffic\.com\/thumbs\/(003a\/8e8675a8f2fb40dfedbde11abedb4685\.jpg|new(\/00(02\/1fe44498d20b8ca368b23b517f03af47\.jpg|14\/07df98c7a77ab7069dc236273948fe7d\.jpg|37\/a209f10ecc66fa95c4e5d0c56c6eb6b5\.jpg|52\/0a61ea933a3b7a5febcfc94f3e225c98\.jpg)|2\/0(0(07\/0bae6ad1630ca38eafe01383eeb0d860\.jpg|89\/(86365a52f500fd038170116e4026fe94\.jpg|a9bb7df30ede34bb568978495968ed7b\.jpg))|1(36\/e00a6e199a1655fb757448e857b63607\.jpg|59\/3434c873b5544bfef18c58518b89eb81\.jpg)))))|n\-da\.com\/\?ref=nuvilon\.com|s(etoons\.com\/|icnet\.sil\.at\/phpbb\/viewtopic\.php\?p=35246\#35246)|ychicas\.com\.ar\/imgoct2013\/17\.jpeg)|y(18teens\.com\/(movies\/(amazing\-teenage\-whore\-kacey\-gives\-head\/\?nats=NTM6Mjox,0,0,0,10461|brenda\-blowjob\/\?nats=NjY1OjI6MQ|gorgeous\-teen\-girl\-katya\-pornmovies\/\?nats=NTM6Mjox,0,0,0,10507|teenage\-model\-gina\-porn\-clips\/\?nats=NTM6Mjox,0,0,0,10492)|pictures\/(naked\-teen\-hoe\-sabrina\/\?nats=NTM6Mjox,0,0,0,10440|sweet\-teen\-babe\-sabrina\/\?nats=NTM6Mjox,0,0,0,10431|teen\-fuck\-movie\/\?nats=MTI6Mjox,0,0,0,1189))|3(dsex\.com\/|xxx\.com\/(dtr\/galls\/(03104b\/|6(0298a\/|64bda\/)))?)|boyssite\.com\/\?id=10gay\.com|crazyvids\.com\/mov\/best\/petite\-1\.html|e(mogirl\.com\/|xbaby\.com\/)|firstteens\.com\/|\-fruits\.info\/topics\/(HOT%20NEW%203D%20SITE%20!!%20Photos%20of%20young%20nonude%20models%20in%203D%20!%20%28Anaglyph%20and%20MPO%29\/|More%20young%20talents%20Vinka%20Model\/|NEW%20star%20Tiana%20Model\/|Preteen%20art%20from%20Talent%20Young%20%28NEW%29\/|S(ummer%20days%20\-%20best%20nonude%20preteen%20photos%20and%20videos%20from%20summer%20beaches\/|veta%20with%20piggy%20tails\/)|Talent%20Young%20very%20HOT%20preteens%20collection%20%28NEW%29\/)|idealgirl\.com\/archives\/1|juniorsister\.com\/videos\/(0(29\.jpg|61\.jpg)|1(3(7\.jpg|8\.jpg)|54\.jpg|88\.jpg)|2(4(4\.jpg|6\.jpg)|89\.jpg|98\.jpg)|375\.jpg)|s(ilverteens\.com\/index\.php|luts\.net\/(\?x=7106\.8911\.3297)?)|teen(ie\.com\/|pics\.co\.tv\/tgp\/|tv\.com\/|video\.com\/pictures\/(amateur\-teenage\-girl\-nesti\-sex\/\?nats=bogk84q9;827:notrials50:myteenvideo,0,0,0,19752|sweet\-teen\-babe\-aletta\/\?nats=NTM6Mjoz,0,0,0,10608))|youngsex\.com\/))|n(a(dia(31\.firstmo\.com\/|kristina\.firstmo\.com\/thumbs\/(0(5\.jpg|6\.jpg|8\.jpg)|1(2\.jpg|6\.jpg|7\.jpg|8\.jpg)|2(0\.jpg|1\.jpg)))|ked(\-(girls\-vids\.com\/|nude\.com\/|photos\.org\/)|teenspictures\.com\/str\/thumbs\/7\/7(168\.jpg|485\.jpg))|na\.legalmodolls\.com\/promo\/240x460_02\.jpg|onlinedee\.qipim\.ru\/twocj\.html|rutoepisodeporno\.com\/|sty(\.preteennonude\.com\/(\?ref=preteennonude\.com&x=9622\.8898\.|pic\/pic\.php\?285)|teensdesire\.com\/)|turistteenphotos\.com\/th\/thumb034\.jpg|ughtyteenvids\.com\/\?id=kind\-girls\.net)|c\-mcadd\.org\/model\-girls\-preteen\/tn\/(20952\.jpg|4086\.jpg|7905\.jpg)|e(mo\-glamour\.com\/|odet\.com\/\?id=(nonude\-modelcom|topnonude\-girlsinfo|virginstubenet)|w(\.(18onlygirls\.com\/4234c2e9\/MTE3NjU6NToyNA\/|beataporn\.com\/a31412b5\/Njg1MDo1OjMx\/|nonudeplace\.com\/(aida\.holymodels\.jpg|bella\.holymodels\.jpg|evie\.holymodels\.jpg|g(irls(1\.holymodels\.jpg|3\.holymodels\.jpg)|lenda\.holymodels\.jpg)|kamilla\.holymodels\.jpg|lia\.holymodels\.jpg|scj\/tmp\/0\/(2(29_preteen_model\.jpg|62_nonude_glenda\.jpg)|351_lolita_nude\.jpg|4(02_non_preteen\.jpg|50_prelolitas_prelolitas\.jpg)|511_nonude_pics\.jpg|6(03_lolita_lolita\.jpg|85_prelolitas_prelolitas\.jpg)|7(27_nn_model\.jpg|63_nude_preteen\.jpg)))|younglegalporn\.com\/(3f68aa4a\/Njg1MDo1OjI1\/|ee0598ed\/MzcyODo1OjI1\/))|\-(art\-nude\.net\/streamrotator\/thumbs\/(0\/(234\.jpg|32\.jpg|493\.jpg)|59\/59594\.jpg|65\/65515\.jpg)|content\.info\/cj\/g\/index\.php\?ft=gaybase\.biz|models\.in\/scj\/thumbs\/0\/(576_0053_0053\.jpg|733_From_From\.jpg)|teensex\.com\/(\?facename=indexpdl&updatestat=off)?)|estpornlinks\.com\/|n(nmodels\.com\/scj\/thumbs\/0\/300_Star_Preten\.jpg|ubiles\.net\/)|pornsite(\.org\/(\?x=0058\.4384\.|vids\/x09\/05\/26\/A\-nice\-Blowjob\/index\.html)?|s\.net\/)|yes\.moy\.su\/sixcj\.html)|zemnoykaif\.com\/(\?d=p1)?)|fsx\.com\/(\?x=(0693\.6976\.0182\.9567\.9074\.4120\.5480\.1010\.9410\.5849|2504\.9354\.5283\.5928\.5849\.|4113\.5849\.|5849\.?|7119\.5849nfsx\.com\/\?x=7119\.5849\.))?|i(c(exvideostube\.com\/dtr\/thumbs\/(0(82339\.jpg|92429\.jpg)|3c2af8\.jpg|4c9c39\.jpg|6(2ba29\.jpg|61782\.jpg)|76803f\.jpg|97c126\.jpg|b(46397\.jpg|65702\.jpg)|c(0ab58\.jpg|3d805\.jpg|9065b\.jpg)|d(799f4\.jpg|8b70c\.jpg))|hegalz\.com\/moviesgeneral\.php\?d=etvtube\.com&acc=arkan&in2=)|ghttubes\.com\/|neclips\.com\/(watch\.php\?tag=0glreYaIS9)?|vonog\.zonalibre\.org\/archives\/015324\.html)|n(\-(1\.com\/(ban_468\.jpg)?|art\.info\/(image\/8\.jpg|portal\/main\/index_files\/tn_(1\.jpg|reyna25\.jpg))|b(bs\.info\/(100150\.gif|ban\.gif)|eauties\.com\/)|girls\.biz\/sitesx\/(2\/stella\.jpg|4\/(bella\.jpg|evie\.jpg)|5\/mashamodel\.jpg)|l(ist\.in\/scj\/thumbs\/0\/394_and_5\.jpg|ola\.net\/index\.html\?44)|mods\.com\/index\.html\?36|sites\.com\/(nnmodels(3\.html|4\.html))?|t(een\.thumblogger\.com\/|op\.com\/100x150\.jpg))|100\.in\/(\?id=simply\-models\.net|s(cj\/thumbs\/1\/(3(09_Elba_Pretty\.jpg|31_young_models\.jpg)|68(3_Beautiful_Mara\.jpg|9_Hot_Young\.jpg)|7(03_Model_0071\.jpg|29_Other_Girls\.jpg|57_Model_Girls\.jpg|91_From_Models\.jpg)|8(28_From_Vilma\.jpg|43_Models_Models\.jpg|51_0068_5\.jpg|76_Model_Mara\.jpg))|ites\/(lila\/Lila\-ind\-400x600\.jpg|natasha\/Natasha\-ind\-400x600\.jpg)))|desire\.com\/bannersmall\.gif|elis\.com\/|lopics\.com\/(PC\-tn(alina6b\.jpg|daphne3b\.jpg|roxana2\-2b\.jpg))?|neversleeps\.info\/|preteen\.com\/index\.html\?18|t(eens\.com\/tgp\/my18teens\-arielfuck\/bunny\.htm|op\.org\/(100150\.gif|miniban\/inna\.jpg))|ville\.com\/(\?(ref=n(onudemodel\.net|uvilon\.com)|x=5608\.9251\.9012\.6426\.)|GALL\/art\/trixie\/)?)|o(chesexo\.com\/|n(\-nude\.tv\/non\-nude_room\/151\-3_gb_private_colection_jb_bonus\.html|nudesitescatalog\.com\/banner\.gif|stop\-nn\.info\/(\?ref=newnnmodels\.net|100150\.jpg|galls\/mnrv\/More%20preteen%20nonude%20models%20Dany%20and%20Camy\/)))))

Testing the regex in regex101 it should not match.

My squid was compiles with gnu regex

Squid Cache: Version 3.5.17
Service Name: squid
configure options:  '--prefix=/opt/sepia/distro/squid'
'--sysconfdir=/var/lib/sepia/' '--disable-auth' '--disable-auto-locale'
'--disable-cache-digests' '--disable-cpu-profiling'
'--disable-debug-cbdata' '--disable-delay-pools' '--disable-devpoll'
'--disable-ecap' '--disable-esi' '--disable-eui'
'--disable-external-acl-helpers' '--disable-follow-x-forwarded-for'
'--disable-forw-via-db' '--enable-gnuregex' '--disable-htcp'
'--enable-icap-client' '--disable-ident-lookups' '--enable-internal-dns'
'--disable-ipf-transparent' '--disable-ipfw-transparent' '--disable-ipv6'
'--disable-leakfinder' '--disable-pf-transparent' '--disable-poll'
'--disable-select' '--disable-snmp' '--with-openssl'
'--disable-stacktraces' '--disable-translation'
'--disable-url-rewrite-helpers' '--disable-wccp' '--disable-wccpv2'
'--disable-win32-service' '--disable-x-accelerator-vary' '--disable-icmp'
'--disable-storeid-rewrite-helpers' '--enable-async-io' '--enable-disk-io'
'--enable-epoll' '--enable-http-violations' '--enable-inline'
'--enable-kill-parent-hack' '--enable-linux-netfilter'
'--enable-log-daemon-helpers' '--enable-removal-policies'
'--enable-storeio' '--enable-unlinkd' '--enable-x-accelerator-vary'
'--enable-zph-qos' '--with-default-user=nobody'
'--with-logdir=/var/log/sepia' '--with-pthreads' '--with-included-ltdl'
'--with-pidfile=/var/lib/sepia/squid.pid' '--with-netfilter-conntrack'
'--disable-arch-native' --enable-ltdl-convenience

Testing with more lines of smaller regexes sometimes leads to the same
problem. One regex matching everything

2016-04-27 8:32 GMT-03:00 Alfredo Rezinovsky <alfrenovsky at gmail.com>:

> I saw in debug log that when an ACL has many regexes each one is compared
> sequentially.
>
> If I have
>
> www.facebook.com
> facebook.com
> www.google.com
> google.com
>
> If will be faster to check just ONE optimized regex like
> (www\.)?(facebook|google).com than the previous three?
>
> I'm really talking about optimizing about 3000 url regexes in one huge
> regex because comparing each and every url to 3000 regexes is too slow.
>
> I know using
> (www\.facebook\.com)|(facebook\.com)|(www\.google\.com)|(google\.com) with
> PCRE will produce the same optimized result as
> (www\.)?(facebook|google)\.com. Squid uses GnuRegex. Does GNURegex lib
> optimizes this as well ?
>
>
> --
> Alfrenovsky
>



-- 
Alfrenovsky
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160616/37882326/attachment.htm>

From yvoinov at gmail.com  Thu Jun 16 19:17:42 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 17 Jun 2016 01:17:42 +0600
Subject: [squid-users] Regex optimization
In-Reply-To: <CAMXC=WuPng+0G1d=sN6ps8XnBj=dsF8JzoLPwduftOYYxY2E9g@mail.gmail.com>
References: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
 <CAMXC=WuPng+0G1d=sN6ps8XnBj=dsF8JzoLPwduftOYYxY2E9g@mail.gmail.com>
Message-ID: <816813d0-40ee-2f7a-beac-55371e649342@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Heh. As usual.

The only solution is uses redirector + DB + blocklists.

For example, ufdbguard.

PS. What an stupid idea - uses regex for this task without CRAY....
:))))))))

17.06.2016 1:11, Alfredo Rezinovsky ?????:
> Well.. I tried.
> I need to ban 8613 URLs. Because a law.
>
> If I put one per line in a file and set the filename for an url_regex
acl it works. But when the traffic goes up the cpu load goes 100% (even
using workers) and the proxy turns unusable.
>
> I tested and saw my squid can't parse regexes with more than 8192
characters.
> I managed to combine the 8000 uris in 34 regexes using a ruby gem, and
the cpu load stays almost at the same level it is without any acl (same
traffic).
>
> The problem is that of the 34 regexes 33 works fine and 1 matches
everything.
>
> "http://something" matches.
>
> the regex is:
>
>
^http:\/\/(m(i(n(i(\.free\-teen\-pussy\.com\/scj\/thumbs\/(0\/(253_Mini_Mini\.jpg|306_Mini_Mini\.jpg|468_Pree_Pree\.jpg|519_Models_Models\.jpg|688_Models_nn\.jpg|7(17_Models_Models\.jpg|22_Models_Mini\.jpg)|880_nn_Models\.jpg)|1\/(170_little_models\.jpg|271_Young_Young\.jpg|330_models_little\.jpg|412_little_models\.jpg|6(28_little_models\.jpg|43_little_little\.jpg)|742_Young_Young\.jpg|877_littlemodels_littlemodels\.jpg|903_littlemodels_littlemodels\.jpg)|2\/(0(47_models_little\.jpg|92_models_models\.jpg)|1(44_little_little\.jpg|75_Young_Young\.jpg)|2(04_littlemodels_littlemodels\.jpg|29_russian_russian\.jpg|76_russian_little\.jpg)))|girls\.biz)|t(ladies\.com\/|teens\.com\/))|ragetube\.com\/content\/(35\/907_un_pequena\.jpg|75\/939_sex_Simpsons\.jpg|95\/473_Babe_039\.jpg))|mmgay\.com\/|o(dels(\.world\-collections\.com\/index\.html\?(4[69]|7(34|7)|88)|\-(hot\.net\/|me\.com\/index\.html\?(23|838)))|e(img(1\.moesearch\.net\/imgs1\/01058000\/1058747\.jpg|2\.moesearch\.net\/imgs2\/(0(1058000\/1058604\.jpg|2095000\/2095432\.jpg|4027000\/4027262\.jpg)|12509000\/12509478\.jpg))|search\.net\/img\.php\?mode=view&id=1058747)|ist\.lolajunior\.com\/images\/cache\/240x180\/(1(00\.125\.1231425553\.jpg|11\.85\.1921663855\.jpg|40\.76\.1735890287\.jpg|50\.115\.1167057586\.jpg|6(1\.133\.2028798891\.jpg|6\.130\.165837020\.jpg|7\.111\.1548016707\.jpg)|72\.107\.88564122\.jpg)|2(42\.142\.777367129\.jpg|76\.170\.1873449959\.jpg)|95\.80\.959860653\.jpg)|n(dayporn\.com\/f\/teen\/|stercams\.in\/)|ppetdollz\.com\/|r(asmovie\.com\/|e\-porn\.net\/)|ther\.taboo\.cc\/images\/cache\/300x250\/191\.170\.32154737\.jpg|v(\.(18\-21\-teens\.com\/|ftvcash\.com\/Free\-Movies\/galleries\/FTV\/1\/165\/)|ie(1820\.com\/trifuns\/sabine\.61sec\.shtml|galls(1(\.t(eensexreality\.com\/665\/\?nats=MjgwOjI6NA|inseks\.com\/video2\/070\/\?nats=MjI6Mjo2,0,0,0,5506)|2\.teenburg\.com\/262\-265\/265\/070\/\?nats=Mjc6Mjox)|3\.teen(burg\.com\/videos15\/093\/\?nats=MTc6Mjox,0,0,0,4396|sexreality\.com\/videos3\/042\/\?nats=MjU6Mjo0))|pornshop\.com\/?|sroom\.net\/index2\.shtml)))|pxgirls\.com\/stream\/thumbs\/(196\/196614\.jpg|96\/96855\.jpg)|rpornsite\.com\/tube\/teen\/|snwhores\.com\/|u(lti(\.xnxx\.com\/gallery\/132750\/ad59\/|grab\.olimptraffic\.com\/thumbs\/(003a\/8e8675a8f2fb40dfedbde11abedb4685\.jpg|new(\/00(02\/1fe44498d20b8ca368b23b517f03af47\.jpg|14\/07df98c7a77ab7069dc236273948fe7d\.jpg|37\/a209f10ecc66fa95c4e5d0c56c6eb6b5\.jpg|52\/0a61ea933a3b7a5febcfc94f3e225c98\.jpg)|2\/0(0(07\/0bae6ad1630ca38eafe01383eeb0d860\.jpg|89\/(86365a52f500fd038170116e4026fe94\.jpg|a9bb7df30ede34bb568978495968ed7b\.jpg))|1(36\/e00a6e199a1655fb757448e857b63607\.jpg|59\/3434c873b5544bfef18c58518b89eb81\.jpg)))))|n\-da\.com\/\?ref=nuvilon\.com|s(etoons\.com\/|icnet\.sil\.at\/phpbb\/viewtopic\.php\?p=35246\#35246)|ychicas\.com\.ar\/imgoct2013\/17\.jpeg)|y(18teens\.com\/(movies\/(amazing\-teenage\-whore\-kacey\-gives\-head\/\?nats=NTM6Mjox,0,0,0,10461|brenda\-blowjob\/\?nats=NjY1OjI6MQ|gorgeous\-teen\-girl\-katya\-pornmovies\/\?nats=NTM6Mjox,0,0,0,10507|teenage\-model\-gina\-porn\-clips\/\?nats=NTM6Mjox,0,0,0,10492)|pictures\/(naked\-teen\-hoe\-sabrina\/\?nats=NTM6Mjox,0,0,0,10440|sweet\-teen\-babe\-sabrina\/\?nats=NTM6Mjox,0,0,0,10431|teen\-fuck\-movie\/\?nats=MTI6Mjox,0,0,0,1189))|3(dsex\.com\/|xxx\.com\/(dtr\/galls\/(03104b\/|6(0298a\/|64bda\/)))?)|boyssite\.com\/\?id=10gay\.com|crazyvids\.com\/mov\/best\/petite\-1\.html|e(mogirl\.com\/|xbaby\.com\/)|firstteens\.com\/|\-fruits\.info\/topics\/(HOT%20NEW%203D%20SITE%20!!%20Photos%20of%20young%20nonude%20models%20in%203D%20!%20%28Anaglyph%20and%20MPO%29\/|More%20young%20talents%20Vinka%20Model\/|NEW%20star%20Tiana%20Model\/|Preteen%20art%20from%20Talent%20Young%20%28NEW%29\/|S(ummer%20days%20\-%20best%20nonude%20preteen%20photos%20and%20videos%20from%20summer%20beaches\/|veta%20with%20piggy%20tails\/)|Talent%20Young%20very%20HOT%20preteens%20collection%20%28NEW%29\/)|idealgirl\.com\/archives\/1|juniorsister\.com\/videos\/(0(29\.jpg|61\.jpg)|1(3(7\.jpg|8\.jpg)|54\.jpg|88\.jpg)|2(4(4\.jpg|6\.jpg)|89\.jpg|98\.jpg)|375\.jpg)|s(ilverteens\.com\/index\.php|luts\.net\/(\?x=7106\.8911\.3297)?)|teen(ie\.com\/|pics\.co\.tv\/tgp\/|tv\.com\/|video\.com\/pictures\/(amateur\-teenage\-girl\-nesti\-sex\/\?nats=bogk84q9;827:notrials50:myteenvideo,0,0,0,19752|sweet\-teen\-babe\-aletta\/\?nats=NTM6Mjoz,0,0,0,10608))|youngsex\.com\/))|n(a(dia(31\.firstmo\.com\/|kristina\.firstmo\.com\/thumbs\/(0(5\.jpg|6\.jpg|8\.jpg)|1(2\.jpg|6\.jpg|7\.jpg|8\.jpg)|2(0\.jpg|1\.jpg)))|ked(\-(girls\-vids\.com\/|nude\.com\/|photos\.org\/)|teenspictures\.com\/str\/thumbs\/7\/7(168\.jpg|485\.jpg))|na\.legalmodolls\.com\/promo\/240x460_02\.jpg|onlinedee\.qipim\.ru\/twocj\.html|rutoepisodeporno\.com\/|sty(\.preteennonude\.com\/(\?ref=preteennonude\.com&x=9622\.8898\.|pic\/pic\.php\?285)|teensdesire\.com\/)|turistteenphotos\.com\/th\/thumb034\.jpg|ughtyteenvids\.com\/\?id=kind\-girls\.net)|c\-mcadd\.org\/model\-girls\-preteen\/tn\/(20952\.jpg|4086\.jpg|7905\.jpg)|e(mo\-glamour\.com\/|odet\.com\/\?id=(nonude\-modelcom|topnonude\-girlsinfo|virginstubenet)|w(\.(18onlygirls\.com\/4234c2e9\/MTE3NjU6NToyNA\/|beataporn\.com\/a31412b5\/Njg1MDo1OjMx\/|nonudeplace\.com\/(aida\.holymodels\.jpg|bella\.holymodels\.jpg|evie\.holymodels\.jpg|g(irls(1\.holymodels\.jpg|3\.holymodels\.jpg)|lenda\.holymodels\.jpg)|kamilla\.holymodels\.jpg|lia\.holymodels\.jpg|scj\/tmp\/0\/(2(29_preteen_model\.jpg|62_nonude_glenda\.jpg)|351_lolita_nude\.jpg|4(02_non_preteen\.jpg|50_prelolitas_prelolitas\.jpg)|511_nonude_pics\.jpg|6(03_lolita_lolita\.jpg|85_prelolitas_prelolitas\.jpg)|7(27_nn_model\.jpg|63_nude_preteen\.jpg)))|younglegalporn\.com\/(3f68aa4a\/Njg1MDo1OjI1\/|ee0598ed\/MzcyODo1OjI1\/))|\-(art\-nude\.net\/streamrotator\/thumbs\/(0\/(234\.jpg|32\.jpg|493\.jpg)|59\/59594\.jpg|65\/65515\.jpg)|content\.info\/cj\/g\/index\.php\?ft=gaybase\.biz|models\.in\/scj\/thumbs\/0\/(576_0053_0053\.jpg|733_From_From\.jpg)|teensex\.com\/(\?facename=indexpdl&updatestat=off)?)|estpornlinks\.com\/|n(nmodels\.com\/scj\/thumbs\/0\/300_Star_Preten\.jpg|ubiles\.net\/)|pornsite(\.org\/(\?x=0058\.4384\.|vids\/x09\/05\/26\/A\-nice\-Blowjob\/index\.html)?|s\.net\/)|yes\.moy\.su\/sixcj\.html)|zemnoykaif\.com\/(\?d=p1)?)|fsx\.com\/(\?x=(0693\.6976\.0182\.9567\.9074\.4120\.5480\.1010\.9410\.5849|2504\.9354\.5283\.5928\.5849\.|4113\.5849\.|5849\.?|7119\.5849nfsx\.com\/\?x=7119\.5849\.))?|i(c(exvideostube\.com\/dtr\/thumbs\/(0(82339\.jpg|92429\.jpg)|3c2af8\.jpg|4c9c39\.jpg|6(2ba29\.jpg|61782\.jpg)|76803f\.jpg|97c126\.jpg|b(46397\.jpg|65702\.jpg)|c(0ab58\.jpg|3d805\.jpg|9065b\.jpg)|d(799f4\.jpg|8b70c\.jpg))|hegalz\.com\/moviesgeneral\.php\?d=etvtube\.com&acc=arkan&in2=)|ghttubes\.com\/|neclips\.com\/(watch\.php\?tag=0glreYaIS9)?|vonog\.zonalibre\.org\/archives\/015324\.html)|n(\-(1\.com\/(ban_468\.jpg)?|art\.info\/(image\/8\.jpg|portal\/main\/index_files\/tn_(1\.jpg|reyna25\.jpg))|b(bs\.info\/(100150\.gif|ban\.gif)|eauties\.com\/)|girls\.biz\/sitesx\/(2\/stella\.jpg|4\/(bella\.jpg|evie\.jpg)|5\/mashamodel\.jpg)|l(ist\.in\/scj\/thumbs\/0\/394_and_5\.jpg|ola\.net\/index\.html\?44)|mods\.com\/index\.html\?36|sites\.com\/(nnmodels(3\.html|4\.html))?|t(een\.thumblogger\.com\/|op\.com\/100x150\.jpg))|100\.in\/(\?id=simply\-models\.net|s(cj\/thumbs\/1\/(3(09_Elba_Pretty\.jpg|31_young_models\.jpg)|68(3_Beautiful_Mara\.jpg|9_Hot_Young\.jpg)|7(03_Model_0071\.jpg|29_Other_Girls\.jpg|57_Model_Girls\.jpg|91_From_Models\.jpg)|8(28_From_Vilma\.jpg|43_Models_Models\.jpg|51_0068_5\.jpg|76_Model_Mara\.jpg))|ites\/(lila\/Lila\-ind\-400x600\.jpg|natasha\/Natasha\-ind\-400x600\.jpg)))|desire\.com\/bannersmall\.gif|elis\.com\/|lopics\.com\/(PC\-tn(alina6b\.jpg|daphne3b\.jpg|roxana2\-2b\.jpg))?|neversleeps\.info\/|preteen\.com\/index\.html\?18|t(eens\.com\/tgp\/my18teens\-arielfuck\/bunny\.htm|op\.org\/(100150\.gif|miniban\/inna\.jpg))|ville\.com\/(\?(ref=n(onudemodel\.net|uvilon\.com)|x=5608\.9251\.9012\.6426\.)|GALL\/art\/trixie\/)?)|o(chesexo\.com\/|n(\-nude\.tv\/non\-nude_room\/151\-3_gb_private_colection_jb_bonus\.html|nudesitescatalog\.com\/banner\.gif|stop\-nn\.info\/(\?ref=newnnmodels\.net|100150\.jpg|galls\/mnrv\/More%20preteen%20nonude%20models%20Dany%20and%20Camy\/)))))
>
> Testing the regex in regex101 it should not match.
>
> My squid was compiles with gnu regex
>
> Squid Cache: Version 3.5.17
> Service Name: squid
> configure options:  '--prefix=/opt/sepia/distro/squid'
'--sysconfdir=/var/lib/sepia/' '--disable-auth' '--disable-auto-locale'
'--disable-cache-digests' '--disable-cpu-profiling'
'--disable-debug-cbdata' '--disable-delay-pools' '--disable-devpoll'
'--disable-ecap' '--disable-esi' '--disable-eui'
'--disable-external-acl-helpers' '--disable-follow-x-forwarded-for'
'--disable-forw-via-db' '--enable-gnuregex' '--disable-htcp'
'--enable-icap-client' '--disable-ident-lookups' '--enable-internal-dns'
'--disable-ipf-transparent' '--disable-ipfw-transparent'
'--disable-ipv6' '--disable-leakfinder' '--disable-pf-transparent'
'--disable-poll' '--disable-select' '--disable-snmp' '--with-openssl'
'--disable-stacktraces' '--disable-translation'
'--disable-url-rewrite-helpers' '--disable-wccp' '--disable-wccpv2'
'--disable-win32-service' '--disable-x-accelerator-vary'
'--disable-icmp' '--disable-storeid-rewrite-helpers' '--enable-async-io'
'--enable-disk-io' '--enable-epoll' '--enable-http-violations'
'--enable-inline' '--enable-kill-parent-hack' '--enable-linux-netfilter'
'--enable-log-daemon-helpers' '--enable-removal-policies'
'--enable-storeio' '--enable-unlinkd' '--enable-x-accelerator-vary'
'--enable-zph-qos' '--with-default-user=nobody'
'--with-logdir=/var/log/sepia' '--with-pthreads' '--with-included-ltdl'
'--with-pidfile=/var/lib/sepia/squid.pid' '--with-netfilter-conntrack'
'--disable-arch-native' --enable-ltdl-convenience
>
> Testing with more lines of smaller regexes sometimes leads to the same
problem. One regex matching everything
>
> 2016-04-27 8:32 GMT-03:00 Alfredo Rezinovsky <alfrenovsky at gmail.com
<mailto:alfrenovsky at gmail.com>>:
>
>     I saw in debug log that when an ACL has many regexes each one is
compared sequentially.
>
>     If I have
>
>     www.facebook.com <http://www.facebook.com>
>     facebook.com <http://facebook.com>
>     www.google.com <http://www.google.com>
>     google.com <http://google.com>
>
>     If will be faster to check just ONE optimized regex like
(www\.)?(facebook|google).com than the previous three?
>
>     I'm really talking about optimizing about 3000 url regexes in one
huge regex because comparing each and every url to 3000 regexes is too slow.
>
>     I know using
(www\.facebook\.com)|(facebook\.com)|(www\.google\.com)|(google\.com)
with PCRE will produce the same optimized result as
(www\.)?(facebook|google)\.com. Squid uses GnuRegex. Does GNURegex lib
optimizes this as well ?
>
>
>     --
>     Alfrenovsky
>
>
>
>
> --
> Alfrenovsky
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXYvtVAAoJENNXIZxhPexGMzQH/25lP8nVMYP7y5UDQdZbEAzg
MD5L/zwUK9XUzT4FlgpkJjYmV/mkADsIV7bgs3fjsK6mWTNwS+IaRoo/gnziFAE0
sS9k2Z5fm+LHkUxC6YaCC1kHSNC9WFKdl8DQLTlvnkjuootJkPvZFxmzDFsvPqtB
ZIqX/F+PfJtuS0vwAEO0j6YoI+XqsWk6GacAyAf55H+VUKf3yCqgNj502UQF8QYf
K9s/nXuydQ/7EBTMBHqmFqVyfuNc4lVtg/V4rVgB62M2sjeLrTvXU8zEQSUm0tLV
ea/CAv0runAzjfdKWOXn22aSkvzfoI13DV+wXEadshXWmU2QzdXQaQnyR8gkRG4=
=aHYr
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160617/7a021cf0/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160617/7a021cf0/attachment.key>

From Antony.Stone at squid.open.source.it  Thu Jun 16 19:20:45 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 16 Jun 2016 21:20:45 +0200
Subject: [squid-users] Regex optimization
In-Reply-To: <CAMXC=WuPng+0G1d=sN6ps8XnBj=dsF8JzoLPwduftOYYxY2E9g@mail.gmail.com>
References: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
 <CAMXC=WuPng+0G1d=sN6ps8XnBj=dsF8JzoLPwduftOYYxY2E9g@mail.gmail.com>
Message-ID: <201606162120.45927.Antony.Stone@squid.open.source.it>

On Thursday 16 June 2016 at 21:11:50, Alfredo Rezinovsky wrote:

> Well.. I tried.
> I need to ban 8613 URLs. Because a law.

Have you considered https://www.urlfilterdb.com/products/ufdbguard.html ?

> If I put one per line in a file and set the filename for an url_regex acl
> it works. But when the traffic goes up the cpu load goes 100% (even using
> workers) and the proxy turns unusable.

Er, I'm not surprised.

> I tested and saw my squid can't parse regexes with more than 8192
> characters.
> I managed to combine the 8000 uris in 34 regexes using a ruby gem, and the
> cpu load stays almost at the same level it is without any acl (same
> traffic).

That must be *way* past anything to be described as "maintainable".

> the regex is:

Er, thanks, that confirms my suspicions above :)


Antony.

-- 
Behind the counter a boy with a shaven head stared vacantly into space,
a dozen spikes of microsoft protruding from the socket behind his ear.

 - William Gibson, Neuromancer (1984)

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Thu Jun 16 20:28:44 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 17 Jun 2016 02:28:44 +0600
Subject: [squid-users] Regex optimization
In-Reply-To: <201606162120.45927.Antony.Stone@squid.open.source.it>
References: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
 <CAMXC=WuPng+0G1d=sN6ps8XnBj=dsF8JzoLPwduftOYYxY2E9g@mail.gmail.com>
 <201606162120.45927.Antony.Stone@squid.open.source.it>
Message-ID: <83376605-e0d2-a7db-882a-c0ad017258d3@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I propose to nominate for the second place of the contest "The most
inefficient use of computing resources - 2016." :-!:-D

Because first place already occuped. :-D 30 millions pornsites in one
squid's ACL and 7 minutes for squid -k refresh. 8-)


17.06.2016 1:20, Antony Stone ?????:
> On Thursday 16 June 2016 at 21:11:50, Alfredo Rezinovsky wrote:
>
>> Well.. I tried.
>> I need to ban 8613 URLs. Because a law.
>
> Have you considered https://www.urlfilterdb.com/products/ufdbguard.html ?
>
>> If I put one per line in a file and set the filename for an url_regex acl
>> it works. But when the traffic goes up the cpu load goes 100% (even using
>> workers) and the proxy turns unusable.
>
> Er, I'm not surprised.
>
>> I tested and saw my squid can't parse regexes with more than 8192
>> characters.
>> I managed to combine the 8000 uris in 34 regexes using a ruby gem,
and the
>> cpu load stays almost at the same level it is without any acl (same
>> traffic).
>
> That must be *way* past anything to be described as "maintainable".
>
>> the regex is:
>
> Er, thanks, that confirms my suspicions above :)
>
>
> Antony.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXYwv7AAoJENNXIZxhPexGn9QH/R2ino1lTfOWrd4E8Z+UUsuH
wjEfi4e96ptkkye57mcOTHXiLgrau+x+vXVS35CNgpwsB3daN1/E6DvAZz/XwABJ
O6/aqIn/JNKmkwLj/XPB0nD0lsrWXoOdknGpL7r/E9un2N2mfAdBVKUbItAuUM+G
DQeKfnRjCDS0Pgt4zlNIQjo0xxSxrjrHThKoWlAi00v2LzWkSmJtbZyW1WtzNbNf
qH8j1LlTbiOg9FmOpp+GVQ8XKEjGnWnhjnydKdVlPr9mXCA6XN5Kn5L6tmckqSc/
Snn9jKZfJAtTg97gTzOJpw9BuGw7pqSRyARcV0/t4PsySNTD/4NpJz/HVKhlT+E=
=Mgx4
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160617/9f0d8a82/attachment.key>

From webmaster at squidblacklist.org  Thu Jun 16 21:11:11 2016
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Thu, 16 Jun 2016 16:11:11 -0500
Subject: [squid-users] Regex optimization
In-Reply-To: <83376605-e0d2-a7db-882a-c0ad017258d3@gmail.com>
References: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
 <CAMXC=WuPng+0G1d=sN6ps8XnBj=dsF8JzoLPwduftOYYxY2E9g@mail.gmail.com>
 <201606162120.45927.Antony.Stone@squid.open.source.it>
 <83376605-e0d2-a7db-882a-c0ad017258d3@gmail.com>
Message-ID: <0d7da244-9d4a-74f1-fdcd-847dd289f99a@squidblacklist.org>



On 6/16/2016 3:28 PM, Yuri Voinov wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>   
> I propose to nominate for the second place of the contest "The most
> inefficient use of computing resources - 2016." :-!:-D
>
> Because first place already occuped. :-D 30 millions pornsites in one
> squid's ACL and 7 minutes for squid -k refresh. 8-)
Yeah and Ill bet about 27 Million of them are dead, expired, parked or 
redirected because your list sucks.

If you really intend to use blacklists tailored for Squid proxy Native 
ACL, we are the leading and only provider of such lists.
And we actually query each domain daily with batch updates, dead domains 
are placed into a holding pool to be queried again cyclically and re added
as necessary.

Shallalist is a joke, urlblacklist is garbage, if you are serious and 
need a better blacklist, we would be happy to serve you.

>
>
> 17.06.2016 1:20, Antony Stone ?????:
>> On Thursday 16 June 2016 at 21:11:50, Alfredo Rezinovsky wrote:
>>
>>> Well.. I tried.
>>> I need to ban 8613 URLs. Because a law.
>> Have you considered https://www.urlfilterdb.com/products/ufdbguard.html ?
>>
>>> If I put one per line in a file and set the filename for an url_regex acl
>>> it works. But when the traffic goes up the cpu load goes 100% (even using
>>> workers) and the proxy turns unusable.
>> Er, I'm not surprised.
>>
>>> I tested and saw my squid can't parse regexes with more than 8192
>>> characters.
>>> I managed to combine the 8000 uris in 34 regexes using a ruby gem,
> and the
>>> cpu load stays almost at the same level it is without any acl (same
>>> traffic).
>> That must be *way* past anything to be described as "maintainable".
>>
>>> the regex is:
>> Er, thanks, that confirms my suspicions above :)
>>
>>
>> Antony.
>>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>   
> iQEcBAEBCAAGBQJXYwv7AAoJENNXIZxhPexGn9QH/R2ino1lTfOWrd4E8Z+UUsuH
> wjEfi4e96ptkkye57mcOTHXiLgrau+x+vXVS35CNgpwsB3daN1/E6DvAZz/XwABJ
> O6/aqIn/JNKmkwLj/XPB0nD0lsrWXoOdknGpL7r/E9un2N2mfAdBVKUbItAuUM+G
> DQeKfnRjCDS0Pgt4zlNIQjo0xxSxrjrHThKoWlAi00v2LzWkSmJtbZyW1WtzNbNf
> qH8j1LlTbiOg9FmOpp+GVQ8XKEjGnWnhjnydKdVlPr9mXCA6XN5Kn5L6tmckqSc/
> Snn9jKZfJAtTg97gTzOJpw9BuGw7pqSRyARcV0/t4PsySNTD/4NpJz/HVKhlT+E=
> =Mgx4
> -----END PGP SIGNATURE-----
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Signed,

Benjamin E. Nichols
http://www.squidblacklist.org

1-405-397-1360

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160616/6bc095b9/attachment.htm>

From alfrenovsky at gmail.com  Thu Jun 16 22:23:38 2016
From: alfrenovsky at gmail.com (Alfredo Rezinovsky)
Date: Thu, 16 Jun 2016 19:23:38 -0300
Subject: [squid-users] Regex optimization
In-Reply-To: <816813d0-40ee-2f7a-beac-55371e649342@gmail.com>
References: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
 <CAMXC=WuPng+0G1d=sN6ps8XnBj=dsF8JzoLPwduftOYYxY2E9g@mail.gmail.com>
 <816813d0-40ee-2f7a-beac-55371e649342@gmail.com>
Message-ID: <CAMXC=Wtt0-3Ctbnr2QZ+Xf280mB43=deeeC3Ao_ehC1MrSKuWg@mail.gmail.com>

A small quantity of big regexes performs well. The CPU load is the same as
if there's no regex at all.

The thing I don't understand is why this specific regex matches every uri I
throw at it in squid, but not in linux grep, or regex101.com.

The generation of the big regexes takes seconds and is done only once.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160616/aedaf3cd/attachment.htm>

From eliezer at ngtech.co.il  Fri Jun 17 01:21:46 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 17 Jun 2016 04:21:46 +0300
Subject: [squid-users] HTTPS issues with squidguard after upgrading from
	squid 2.7 to 3.5
In-Reply-To: <CAAvSkVE442=9UqOxqa=dA3=bND=rdgg9p49TqG87vq0Zeo_uWg@mail.gmail.com>
References: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>
 <027e01d1c6e2$4d583530$e8089f90$@ngtech.co.il>
 <CAAvSkVGnZK2RyDgu9XYJZXq=HeBad8SfhKTDp8Aq6oTer21D7A@mail.gmail.com>
 <047501d1c731$7224bbf0$566e33d0$@ngtech.co.il>
 <CAAvSkVE442=9UqOxqa=dA3=bND=rdgg9p49TqG87vq0Zeo_uWg@mail.gmail.com>
Message-ID: <09d101d1c836$9daa06d0$d8fe1470$@ngtech.co.il>

Good to hear!!!
Indeed Amos is correct and now I think this thread will be used for many users as a very good example.
Eventually as I mentioned, if it works for you and others then great.
I have encountered couple cases which the squidGuard update was too "expensive" and riskey but it seems that squidGuard is still kicking despite to not being maintain.

I have a non-public question but if you can share it will be nice.
What is the users size\capacity of the system?
I am asking since I have seen that many squidGuard based systems have acted slower then with ICAP.
By slower I mean that the initial squidGuard lookup response caused slower page display by ms to couple secs.
I have not researched the exact reasons since I will not try to fix what is already fine for many.

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of reqman
Sent: Thursday, June 16, 2016 10:55 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] HTTPS issues with squidguard after upgrading from squid 2.7 to 3.5

Hello Eliezer,

first let me thank you for providing a complete and detailed explanation, I think I understand now what gives here.

Minor note: Amos is correct in stating that url_rewrite_access basically controls what is thrown into the redirector.

Now, before I opened this discussion I also came to the conclusion that to get rid of these issues, I had to avoid throwing HTTPS through a rewrite with squidguard. Indeed, setting the following solved the
issue...:

========================
url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8
startup=4 idle=4 concurrency=0
url_rewrite_access deny CONNECT
url_rewrite_access allow all
========================

... only to introduce another one: all HTTPS passes unfiltered.

So I tried to follow your advice to implement the same things, without using url_rewrite_program. I have tested and have the patched version of squidGuard (or so it seems). In doing so, I stumbled upon a couple of issues that complicate the solution, specifically:

* My error redirect page can not be used when the original request was a CONNECT one
* Even if it did, it would be complicated a bit to try and extract additional information (ie class that registered a hit with) from squidguard back to squid.

With your information, I was able to happily combine both the functionality of url_rewrite_program, as well as using an external acl.

In not so many words, the modifications to my original.
url_rewrite-based approach is to:
1) first do not use url_rewrite at all for CONNECT methods
2) modify http_access when made via CONNECT, to take into account the external acl rule (again based on squidguard), and block via TCP_RESET

In coding this means that:
1) The initial handling with:
========================
url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8
startup=4 idle=4 concurrency=0
url_rewrite_access allow all
========================

... now becomes:
========================
url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8
startup=4 idle=4 concurrency=0
url_rewrite_access deny CONNECT
url_rewrite_access allow all
========================

2) To handle CONNECT, the existing block that handles CONNECT logic:
========================
acl CONNECT method CONNECT

http_access deny CONNECT !SSL_ports
http_access allow CONNECT
========================

becomes:

========================
acl CONNECT method CONNECT
external_acl_type filter_url ipv4 concurrency=0 ttl=3 %URI %SRC %{-} %un %METHOD /usr/local/bin/squidGuard acl filter_url_acl external filter_url

# Important: When an unwanted site appears in HTTPS, just forcefully close the TCP connection!
deny_info TCP_RESET filter_url_acl

http_access deny CONNECT filter_url_acl
http_access deny CONNECT !SSL_ports

http_access allow CONNECT
========================

With this approach, some squidguard children are spawned as redirectors (via url_rewrite_program), whereas some more are spawned from "external_acl_type filter_url".

2016-06-15 21:12 GMT+03:00 Eliezer Croitoru <eliezer at ngtech.co.il>:
> Hey Michael,
>
>
>
> Well I have not tested FreeBSD dependencies and patches and I am not 
> following them daily.
>
> The issue itself with SquidGuard and the url_rewrite interface is more 
> of an issue in most cases with CONNECT requests as you mentioned.
>
> Since you are not using ssl_bump then you need to deny the 
> traffic\requests in a way that will not leave squid or the clients and 
> the session in an unknown or unexpected situation.
>
> When the url_rewrite interface is used to "Deny" something it's not 
> really denying but rather "rewriting" something due to it's nature.
>
>
>
> On regular plain http requests some mangling to the request(affecting 
> the
> response) is possible but when handling CONNECT requests it's a whole 
> new story.
>
> We don't know how the client will respond to a malformed response or 
> squid to a malformed rewritten request, and it is possible that the 
> client will expect a specific 50x\40x response code.
>
>
>
> The external_acl interface was built as an ACL extension with the 
> basic ability to overcome the limits of the url_rewrite interface.
>
> Content or url filtering is an ACL level operation and not url 
> rewriting\mangling and there for it is better(in squid) to do it in a 
> way that the client can identify(30x).
>
>
>
> The best possible way to deny such a connection(CONNECT) is using a 
> 50x or 40x code.
> I do not remember which one is accepted better by browsers and clients 
> and you will be able to find it yourself easily adding couple lines or 
> using the scripts I wrote before.
>
>
>
> And more directly to the subject, I will say that if these network "issues"
> are might be because of any squid side of wrongly handling CONNECT 
> requests that was mangled with a url_rewrite.
> I would say that these specific cases is the proof of the wrongly used 
> interface.
>
>
>
> The url_rewrite might contain a bug when handling a CONNECT request 
> but the bug is that it is handling these connections at all and not otherwise.
>
> My suggestion is that you would try to see if you can use something 
> like
> that:
>
> ## START
>
> url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8
> startup=4 idle=4 concurrency=0
>
> url_rewrite_access deny CONNECT
>
> url_rewrite_access allow all
>
> ## END
>
>
>
> And  add another external_acl helper with the wrapper I gave you 
> without any special deny_info for the ACL.
> Squid will be able to handle these probably fine and will deny the 
> connections using some right access deny code(don't expect fancy 
> warning pages without using some level of ssl_bump).
>
>
>
> I do not know if you need a fast solution or you are planning 
> carefully with the available options.
>
> The options are to either use a "fast" solution to mitigate an 
> annoying issue or to find the right path.
>
> The solution to either of the options is in your hands..
>
> If for your squidGuard setup offers you the right solution from all 
> the right aspects despite to the fact that it's working slower then 
> other solutions then it is the solution for you!!
>
>
>
> The technology of black and white listing was enhanced in the last 
> decade but not too drastically.
>
> The basic concept is that there are query and analysis components 
> which are not forced to be one software.
>
> There will always be false positives to this or another way but some 
> categorizing systems are much stricter and sensitive about the subject 
> then others.
>
> All this leaving aside the sources of the lists you and since only you 
> have a definition of the wanted\desired results with the available options.
>
>
>
> You also stated that you have some funding issues, but just as a side note:
> the wanted result is eventually forcing the final product of work and 
> the expense(any if at all).
>
> I mean with these words that if you do not care about false positives 
> and using some product satisfy the desire or need then I think it's ok 
> for your case.

I am taking care of false positives by whitelisting sites over this last decade. My whitelisted sites are basically non-growing.

At some point I *will* have to look at something else. But first, I'll have to examine:
1) Which software to use: e2guardian and ufdbguard were referenced.
I'll have to delve into some study here
2) Same thing on which free *lists* to use. Will definitely need some reading here too.

Again, thanks for taking all this time to respond. HUGELY appreciated :)

> I will add that from my tests there are different results to basic 
> pages\objects loading\access speed when using one software or another, 
> and\or one protocol\interface or another.
>
>
>
> Here if you need more help\advice handling the situation.
>
> Eliezer
>
>
>
> ----
>
> Eliezer Croitoru
>
> Linux System Administrator
>
> Mobile: +972-5-28704261
>
> Email: eliezer at ngtech.co.il
>
>
>
>
>
> -----Original Message-----
> From: michail.pappas at gmail.com [mailto:michail.pappas at gmail.com] On 
> Behalf Of reqman
> Sent: Wednesday, June 15, 2016 2:19 PM
> To: Eliezer Croitoru
> Cc: squid-users at lists.squid-cache.org
>
> Subject: Re: [squid-users] HTTPS issues with squidguard after 
> upgrading from squid 2.7 to 3.5
>
>
>
> Hello Eliezer,
>
>
>
> 2016-06-15 11:45 GMT+03:00 Eliezer Croitoru <eliezer at ngtech.co.il>:
>
>> Hey Michael,
>
>>
>
>> I am missing couple details about the setup which might affect the 
>> way we would be able to understand what is causing the issue and how to resolve it.
>
>> There are changes from squid 2.7 to 3.5 and to my opinion these are 
>> mandatory to resolve and to not go one step back.
>
>
>
> Yes, I saw that 3.5 effectively disabled/obsoleted/deactivated various 
> options. I believe I took care in following through those requirements.
>
>
>
>> What version of SquidGuard 1.4 did you installed? The patched for 
>> squid 3.4+ compatibility?
>
>
>
> I installed a ready to use package from FreeBSD. I presume that is is 
> ok with squid 3.4, according to its dependencies:
>
>
>
> # pkg query "%do%dv" squidGuard
>
> www/squid3.5.19
>
> databases/db55.3.28_3
>
>
>
> Other information for squidGuard:
>
>
>
> # pkg info squidGuard
>
> squidGuard-1.4_15
>
> Name           : squidGuard
>
> Version        : 1.4_15
>
> Installed on   : Mon May 30 08:24:17 2016 EEST
>
> Origin         : www/squidguard
>
> Architecture   : freebsd:10:x86:64
>
> Prefix         : /usr/local
>
> Categories     : www
>
> Licenses       : GPLv2
>
> Maintainer     : garga at FreeBSD.org
>
> WWW            : http://www.squidguard.org/
>
> Comment        : Fast redirector for squid
>
> Options        :
>
>        DNS_BL         : off
>
>        DOCS           : on
>
>        EXAMPLES       : on
>
>        LDAP           : off
>
>        QUOTE_STRING   : off
>
>        STRIP_NTDOMAIN : off
>
> Shared Libs required:
>
>        libdb-5.3.so.0
>
> Annotations    :
>
>        repo_type      : binary
>
>        repository     : FreeBSD
>
> Flat size      : 2.24MiB
>
>
>
>> More details about it here:
>
>> http://bugs.squid-cache.org/show_bug.cgi?id=3978
>
>> Now if it is indeed patched and works as expected it from the 3.4+ 
>> computability level of things then lets move on.
>
>
>
> Checking the bug and if I understand correctly, if my squidGuard was 
> not patched then it wouldn't work. This is not the case. It works ok 
> for http urls, ie blocks fine and the user is correctly redirected to 
> the block page setup for this purpose. It's HTTPS I'm having issues
>
> with: according to some talks, if something gets blocked by 
> squidguard, something is miscommunicated (or not communicated at all) with squid.
> Instead of a block, the users waits endlessly for the page.
>
>
>
>> Are you using Squid in intercept\transparent\trpoxy mode or is it 
>> defined in the browsers directly?
>
>> If you are using intercept mode, what have you defined on the FreeBSD 
>> pf\ipfw?
>
>
>
> Squid operates in normal mode. I've configured a 10year old proxy 
> autodiscovery script, which is published through DHCP. All browsers 
> are set to configure everything automatically.
>
>
>
>> And about the quote from the mailing list:
>
>> SquidGuard was written to operate under the url_rewrite 
>> interface\protocol and not external_acl.
>
>
>
> I've lost you here: why do I need squidGuard to operate under external_acl?
> Can't I leave it running with url_rewrite?
>
>
>
>> Due to this it has some disadvantages and the advised details are to 
>> modify the helper(SquidGuard or another) to operate in another way.
>
>> It is possible to use the patched version of SquidGuard under the 
>> external_acl interface and use squid options to deny\redirect the request.
>
>
>
> I saw your other email, but I again have to ask. My own squidguard "seems"
> to work. What are the merits of doing things with external_acl instead 
> of the way I am doing things right now?
>
>
>
>> It removes some things from the complexity of the issue.
>
>> I have just written an example on how to use use my software 
>> SquidBlocker under external_acl and here the adapted example that can 
>> be used with a patched SquidGuard:
>
>> ## START OF SETTINGS
>
>> external_acl_type filter_url ipv4 concurrency=0 ttl=3 %URI %SRC/-
>
>> %LOGIN %METHOD /usr/local/bin/squidGuard url_rewrite_children acl
>
>> filter_url_acl external filter_url deny_info
>
>> http://ngtech.co.il/block_page/?url=%u&domain=%H filter_url_acl #or #
>
>> deny_info 302:http://ngtech.co.il/block_page/?url=%u&domain=%H
>
>> filter_url_acl http_access deny !filter_url_acl http_access allow
>
>> localnet filter_url_acl ## END OF SETTINGS
>
>>
>
>> I have not tested this request format but if it doesn't work this way 
>> then a little cosmetics will make it work.
>
>>
>
>> When more information will be available we can try to see where the 
>> issue is from.
>
>>
>
>> Eliezer
>
>>
>
>> ----
>
>> Eliezer Croitoru
>
>> Linux System Administrator
>
>> Mobile: +972-5-28704261
>
>> Email: eliezer at ngtech.co.il
>
>>
>
>>
>
>> -----Original Message-----
>
>> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
>
>> On Behalf Of reqman
>
>> Sent: Wednesday, June 15, 2016 10:22 AM
>
>> To: squid-users at lists.squid-cache.org
>
>> Subject: [squid-users] HTTPS issues with squidguard after upgrading
>
>> from squid 2.7 to 3.5
>
>>
>
>> Hello all,
>
>>
>
>> I have been running squid 2.7.X alongside squidguard 1.4 on a FreeBSD 
>> 8.x box for years.
>
>> Started out some 10 years ago, with a much older 
>> squid/squidguard/FreeBSD combination.
>
>>
>
>> Having to upgrade to FreeBSD 10.3, I examined my option regarding squid.
>
>> 3.5.19 was available which I assumed would behave the same as 2.7, 
>> regarding compatibility.
>
>> Squidguard 1.4 was also installed.
>
>>
>
>> - Squid was configured to behave along the lines of what I had on 2.7.
>
>> - For squidguard I used the exact same blocklists and configurations.
>
>> Note that I do not employ an URL rewriting in squidguard, only 
>> redirection.
>
>> - no SSL-bump or other SSL interception takes place
>
>> - the squidguard-related lines on squid are the following:
>
>>
>
>> url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8
>
>> startup=4 idle=4 concurrency=0 url_rewrite_access allow all
>
>>
>
>> - In squidGuard.conf, the typical redirect section is like:
>
>>
>
>>  default {
>
>>                 pass local-ok !block1 !block2 !blockN all
>
>>                 redirect
>
>>
>> 301:http://localsite/block.htm?clientaddr=%a+clientname=%n+clientiden
>> t=%i+srcclass=%s+targetclass=%t+url=%u
>
>>         }
>
>>
>
>> I am now experiencing problems that I did not have. Specifically, 
>> access to certain but *not* all HTTPS sites seems to timeout.
>
>> Furthermore, I see entries similar to the following in cache.log:
>
>>
>
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>
>> remote=192.168.2.239:3446 FD 591 flags=1
>
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>
>> remote=192.168.2.239:3448 FD 592 flags=1
>
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>
>> remote=192.168.2.239:3452 FD 594 flags=1
>
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>
>> remote=192.168.2.239:3456 FD 596 flags=1
>
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>
>> remote=192.168.2.239:3454 FD 595 flags=1
>
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>
>> remote=192.168.2.239:3458 FD 597 flags=1
>
>> 2016/06/15 09:27:59 kid1| abandoning local=192.168.0.1:3128
>
>> remote=192.168.2.239:3462 FD 599 flags=1
>
>>
>
>> Searching around, the closest I have come to an answer is the
>
>> following:
>
>> http://www.squid-cache.org/mail-archive/squid-users/201211/0165.html
>
>> I am not sure though whether I am plagued by the same issue, 
>> considering that the thread refers to a squid version dated 4 years 
>> ago. And I definitely do not understand what the is meant by the poster's proposal:
>
>>
>
>> "If you can't alter the re-writer to perform redirection you can work 
>> around that by using:
>
>>
>
>>   acl foo ... some test to match the re-written URL ...
>
>>   deny_info 302:%s foo
>
>>   adapted_http_access deny foo "
>
>>
>
>> Can someone help resolve this?
>
>> Is the 2.7 series supported at all?
>
>> As is if everything fails, I'll have to go back to it if there's some 
>> support.
>
>>
>
>> BR,
>
>>
>
>>
>
>> Michael.-
>
>> _______________________________________________
>
>> squid-users mailing list
>
>> squid-users at lists.squid-cache.org
>
>> http://lists.squid-cache.org/listinfo/squid-users
>
>>
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From marcus.kool at urlfilterdb.com  Fri Jun 17 01:46:50 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Thu, 16 Jun 2016 22:46:50 -0300
Subject: [squid-users] HTTPS issues with squidguard after upgrading from
 squid 2.7 to 3.5
In-Reply-To: <09d101d1c836$9daa06d0$d8fe1470$@ngtech.co.il>
References: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>
 <027e01d1c6e2$4d583530$e8089f90$@ngtech.co.il>
 <CAAvSkVGnZK2RyDgu9XYJZXq=HeBad8SfhKTDp8Aq6oTer21D7A@mail.gmail.com>
 <047501d1c731$7224bbf0$566e33d0$@ngtech.co.il>
 <CAAvSkVE442=9UqOxqa=dA3=bND=rdgg9p49TqG87vq0Zeo_uWg@mail.gmail.com>
 <09d101d1c836$9daa06d0$d8fe1470$@ngtech.co.il>
Message-ID: <5763568A.20205@urlfilterdb.com>



On 06/16/2016 10:21 PM, Eliezer Croitoru wrote:
> I have a non-public question but if you can share it will be nice.
> What is the users size\capacity of the system?
> I am asking since I have seen that many squidGuard based systems have acted slower then with ICAP.
> By slower I mean that the initial squidGuard lookup response caused slower page display by ms to couple secs.
> I have not researched the exact reasons since I will not try to fix what is already fine for many.

squidGuard is slow since each process opens the database and
has a private cache of 15% of the database.
So if a squidGuard process does a URL lookup it does a lookup in the
database cache and may read from disk (or the OS file system cache).

ufdbGuard does it differently: the url_rewriter process is a lightweight
process that forwards a URL lookup to a multithreaded daemon that holds
a single copy of the URL database in memory.  The database format is
also optimised for in-memory lookups.
ufdbGuard does 50,000 URL lookups/second on an
Intel(R) Xeon(R) CPU E5-1620 v2 with 4 cores/8 threads.

Marcus


From blaxxton at yahoo.com  Fri Jun 17 01:47:24 2016
From: blaxxton at yahoo.com (Blaxton)
Date: Fri, 17 Jun 2016 01:47:24 +0000 (UTC)
Subject: [squid-users] SQUID and accessing https urls failing
References: <30223422.4668490.1466128044271.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <30223422.4668490.1466128044271.JavaMail.yahoo@mail.yahoo.com>

Hi
Squid is running with default and we can access HTTP URLsbut accessing to HTTPS URLs timing out and nothing is being logged in log file.
I was assuming connecting to HTTPS URLs should work the same as HTTP connections out of the box.

Thanks ??
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160617/aa374333/attachment.htm>

From squid3 at treenet.co.nz  Fri Jun 17 02:34:05 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 17 Jun 2016 14:34:05 +1200
Subject: [squid-users] HTTPS issues with squidguard after upgrading from
 squid 2.7 to 3.5
In-Reply-To: <CAAvSkVE442=9UqOxqa=dA3=bND=rdgg9p49TqG87vq0Zeo_uWg@mail.gmail.com>
References: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>
 <027e01d1c6e2$4d583530$e8089f90$@ngtech.co.il>
 <CAAvSkVGnZK2RyDgu9XYJZXq=HeBad8SfhKTDp8Aq6oTer21D7A@mail.gmail.com>
 <047501d1c731$7224bbf0$566e33d0$@ngtech.co.il>
 <CAAvSkVE442=9UqOxqa=dA3=bND=rdgg9p49TqG87vq0Zeo_uWg@mail.gmail.com>
Message-ID: <f9ee5a3f-7466-41cb-1ba0-c2374b3cff50@treenet.co.nz>

On 16/06/2016 7:54 p.m., reqman wrote:
> Hello Eliezer,
> 
> first let me thank you for providing a complete and detailed
> explanation, I think I understand now what gives here.
> 
> Minor note: Amos is correct in stating that url_rewrite_access
> basically controls what is thrown into the redirector.
> 
> Now, before I opened this discussion I also came to the conclusion
> that to get rid of these issues, I had to avoid throwing HTTPS through
> a rewrite with squidguard. Indeed, setting the following solved the
> issue...:
> 
> ========================
> url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8
> startup=4 idle=4 concurrency=0
> url_rewrite_access deny CONNECT
> url_rewrite_access allow all
> ========================

Just a warning to anyone reading this.

url_rewrite_program and url_rewrite_children are meant to be on
different lines.

Otherwise Squid will not obey the child process requirements defined by
url_rewrite_children.


The correct version of the above config snippet is:

 url_rewrite_program /usr/local/bin/squidGuard
 url_rewrite_children 8 startup=4 idle=4 concurrency=0
 url_rewrite_access deny CONNECT
 url_rewrite_access allow all

Amos



From squid3 at treenet.co.nz  Fri Jun 17 02:42:15 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 17 Jun 2016 14:42:15 +1200
Subject: [squid-users] SQUID and accessing https urls failing
In-Reply-To: <30223422.4668490.1466128044271.JavaMail.yahoo@mail.yahoo.com>
References: <30223422.4668490.1466128044271.JavaMail.yahoo.ref@mail.yahoo.com>
 <30223422.4668490.1466128044271.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <21cc2d23-1b48-461c-1b24-a3e2e1538289@treenet.co.nz>

On 17/06/2016 1:47 p.m., Blaxton wrote:
> Hi
> Squid is running with default and we can access HTTP URLsbut accessing to HTTPS URLs timing out and nothing is being logged in log file.
> I was assuming connecting to HTTPS URLs should work the same as HTTP connections out of the box.

They do not. The 'S' makes them different. Very different.

Squid currently has to be built with OpenSSL support in order to perform
the TLS protocol actions needed by https:// URLs and also HTTPS
protocol. Since OpenSSL software license is not compatible with GPL
license used by Squid some popular vendors are not providing HTTPS
enabled binaries on legal grounds (most notably Debian, Ubuntu and their
derivatives).

Any build of Squid though is capable of relaying HTTP CONNECT tunnels
containing HTTPS. But that requires the client software to do the tunnel
wrapping, and be using the proxy explicitly.

Amos



From squid3 at treenet.co.nz  Fri Jun 17 02:43:54 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 17 Jun 2016 14:43:54 +1200
Subject: [squid-users] Regex optimization
In-Reply-To: <CAMXC=Wtt0-3Ctbnr2QZ+Xf280mB43=deeeC3Ao_ehC1MrSKuWg@mail.gmail.com>
References: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
 <CAMXC=WuPng+0G1d=sN6ps8XnBj=dsF8JzoLPwduftOYYxY2E9g@mail.gmail.com>
 <816813d0-40ee-2f7a-beac-55371e649342@gmail.com>
 <CAMXC=Wtt0-3Ctbnr2QZ+Xf280mB43=deeeC3Ao_ehC1MrSKuWg@mail.gmail.com>
Message-ID: <04b1e2f1-9dee-65ed-7a7a-9ba5e15ef006@treenet.co.nz>

On 17/06/2016 10:23 a.m., Alfredo Rezinovsky wrote:
> A small quantity of big regexes performs well. The CPU load is the same as
> if there's no regex at all.
> 
> The thing I don't understand is why this specific regex matches every uri I
> throw at it in squid, but not in linux grep, or regex101.com.
> 
> The generation of the big regexes takes seconds and is done only once.

The size of this one compound regex is 8181 bytes. squid.conf has a
maximum line length of 4096 bytes.

I suggest you list the actual individual regex patterns and let Squid do
the compounding part. The current Squid do a much better job of that
than the old 2.7 etc would.

Amos



From squid3 at treenet.co.nz  Fri Jun 17 02:57:01 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 17 Jun 2016 14:57:01 +1200
Subject: [squid-users] Regex optimization
In-Reply-To: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
References: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
Message-ID: <330fe702-2bd8-e212-4f90-475191c5f7ec@treenet.co.nz>

On 27/04/2016 11:32 p.m., Alfredo Rezinovsky wrote:
> I saw in debug log that when an ACL has many regexes each one is compared
> sequentially.
> 
> If I have
> 
> www.facebook.com
> facebook.com
> www.google.com
> google.com
> 
> If will be faster to check just ONE optimized regex like
> (www\.)?(facebook|google).com than the previous three?
> 
> I'm really talking about optimizing about 3000 url regexes in one huge
> regex because comparing each and every url to 3000 regexes is too slow.
> 
> I know using
> (www\.facebook\.com)|(facebook\.com)|(www\.google\.com)|(google\.com) with
> PCRE will produce the same optimized result as
> (www\.)?(facebook|google)\.com. Squid uses GnuRegex. Does GNURegex lib
> optimizes this as well ?

1) It is kind of a myth that Squid uses GNURegex.

Squid *bundles* with a copy of GNURegex. For use on systems which do not
provide their own regex library.

Most of the time Squid uses the system -lregex. Which on some systems is
an updated version of GNURegex, sometimes is a Perl based library, and
others the PCRE library. On the latest OS the C++11 stdlib itself builds
in regex components, so those are possibly used as well.

AFAICT, the only system where the Squid bundled GNURegex library is
still actually used is Windows.


2) sort of. You are thinking it compacts down to a differnet textual
form. It does not.

All regex libraries compact the initial pattern down to a binary format
which is equivalent (but not the same) as the second pattern you wrote.
Squid uses the library API which does that compaction.

Current Squid versions will also load multiple sequential lines from
your config file and explicitly append them together. No need to do it
manually for regex ACLs.

Amos



From reqman at freemail.gr  Fri Jun 17 05:20:28 2016
From: reqman at freemail.gr (reqman)
Date: Fri, 17 Jun 2016 08:20:28 +0300
Subject: [squid-users] HTTPS issues with squidguard after upgrading from
 squid 2.7 to 3.5
In-Reply-To: <f9ee5a3f-7466-41cb-1ba0-c2374b3cff50@treenet.co.nz>
References: <CAAvSkVHWDrt5q0H7coeTyZt1VOShHSy6ah9FA-f8OnzyLkUzeg@mail.gmail.com>
 <027e01d1c6e2$4d583530$e8089f90$@ngtech.co.il>
 <CAAvSkVGnZK2RyDgu9XYJZXq=HeBad8SfhKTDp8Aq6oTer21D7A@mail.gmail.com>
 <047501d1c731$7224bbf0$566e33d0$@ngtech.co.il>
 <CAAvSkVE442=9UqOxqa=dA3=bND=rdgg9p49TqG87vq0Zeo_uWg@mail.gmail.com>
 <f9ee5a3f-7466-41cb-1ba0-c2374b3cff50@treenet.co.nz>
Message-ID: <CAAvSkVF72o0pktSEDOVEtv+ydTHG9ebTisF9BJhJSvYmPUzpmg@mail.gmail.com>

Amos you are absolutely correct, don't know why I eradicated the
newline between url_rewrite_program and url_rewrite_children.

And thanks again to all posters for their help!

2016-06-17 5:34 GMT+03:00 Amos Jeffries <squid3 at treenet.co.nz>:
> On 16/06/2016 7:54 p.m., reqman wrote:
>> Hello Eliezer,
>>
>> first let me thank you for providing a complete and detailed
>> explanation, I think I understand now what gives here.
>>
>> Minor note: Amos is correct in stating that url_rewrite_access
>> basically controls what is thrown into the redirector.
>>
>> Now, before I opened this discussion I also came to the conclusion
>> that to get rid of these issues, I had to avoid throwing HTTPS through
>> a rewrite with squidguard. Indeed, setting the following solved the
>> issue...:
>>
>> ========================
>> url_rewrite_program /usr/local/bin/squidGuard url_rewrite_children 8
>> startup=4 idle=4 concurrency=0
>> url_rewrite_access deny CONNECT
>> url_rewrite_access allow all
>> ========================
>
> Just a warning to anyone reading this.
>
> url_rewrite_program and url_rewrite_children are meant to be on
> different lines.
>
> Otherwise Squid will not obey the child process requirements defined by
> url_rewrite_children.
>
>
> The correct version of the above config snippet is:
>
>  url_rewrite_program /usr/local/bin/squidGuard
>  url_rewrite_children 8 startup=4 idle=4 concurrency=0
>  url_rewrite_access deny CONNECT
>  url_rewrite_access allow all
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From yvoinov at gmail.com  Fri Jun 17 08:00:25 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 17 Jun 2016 14:00:25 +0600
Subject: [squid-users] Regex optimization
In-Reply-To: <0d7da244-9d4a-74f1-fdcd-847dd289f99a@squidblacklist.org>
References: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
 <CAMXC=WuPng+0G1d=sN6ps8XnBj=dsF8JzoLPwduftOYYxY2E9g@mail.gmail.com>
 <201606162120.45927.Antony.Stone@squid.open.source.it>
 <83376605-e0d2-a7db-882a-c0ad017258d3@gmail.com>
 <0d7da244-9d4a-74f1-fdcd-847dd289f99a@squidblacklist.org>
Message-ID: <610f23a1-5734-187f-82f9-d31a2541abd1@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Shallalist seems most acceptable free blacklist. With fine grained
categories.

Of course, it require human power to maintain.

If this one does not will to do, just sit back and wait for someone to
do - as is usually done in open source software, of course, it will be a
joke. There is a form to send and revoke URL. They just need to use it.
They themselves are not required to maintain a list of current.

Personally, I have been actively taking part in updating the Shalla
blacklist of the last 5 years and I am happy with it. Especially
considering its price.

So.....

17.06.2016 3:11, Benjamin E. Nichols ?????:
>
>
>
> On 6/16/2016 3:28 PM, Yuri Voinov wrote:
> I propose to nominate for the second place of the contest "The most
> inefficient use of computing resources - 2016." :-!:-D
>
> Because first place already occuped. :-D 30 millions pornsites in one
> squid's ACL and 7 minutes for squid -k refresh. 8-)
> > Yeah and Ill bet about 27 Million of them are dead, expired, parked
or redirected because your list sucks.
>
> > If you really intend to use blacklists tailored for Squid proxy
Native ACL, we are the leading and only provider of such lists.
> > And we actually query each domain daily with batch updates, dead
domains are placed into a holding pool to be queried again cyclically
and re added
> > as necessary.
>
> > Shallalist is a joke, urlblacklist is garbage, if you are serious
and need a better blacklist, we would be happy to serve you.
>
>
>
> 17.06.2016 1:20, Antony Stone ?????:
> >>> On Thursday 16 June 2016 at 21:11:50, Alfredo Rezinovsky wrote:
> >>>
> >>>> Well.. I tried.
> >>>> I need to ban 8613 URLs. Because a law.
> >>> Have you considered
https://www.urlfilterdb.com/products/ufdbguard.html ?
> >>>
> >>>> If I put one per line in a file and set the filename for an
url_regex acl
> >>>> it works. But when the traffic goes up the cpu load goes 100%
(even using
> >>>> workers) and the proxy turns unusable.
> >>> Er, I'm not surprised.
> >>>
> >>>> I tested and saw my squid can't parse regexes with more than 8192
> >>>> characters.
> >>>> I managed to combine the 8000 uris in 34 regexes using a ruby gem,
> and the
> >>>> cpu load stays almost at the same level it is without any acl (same
> >>>> traffic).
> >>> That must be *way* past anything to be described as "maintainable".
> >>>
> >>>> the regex is:
> >>> Er, thanks, that confirms my suspicions above :)
> >>>
> >>>
> >>> Antony.
> >>>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> --
> Signed,
>
> Benjamin E. Nichols
> http://www.squidblacklist.org
>
> 1-405-397-1360
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXY64ZAAoJENNXIZxhPexGMhkIAK/hrf9wFVKwt83jRxl4T++/
2jgcuqaXb78MazN6wdNr5HZrshRGayxDZsLbF0xb7cdrA0lVYSQgnWX0SEomZZ8E
Y+gDaemoojE8d8Wqy3zLP57BzziLMs2ymVmQRnQ0265wRoCVkCLKAR4Dzod9eXS/
L115pErOcbZc0nZ3QkXfbuE1ol3gfHL1tQN5Gfm4IMxgtp1gdnxfg9BUCzMaicR+
Y7WkZqCdzA0kcLjOgvDVzudTBsKhRx+YHIjVr72seUMEu/EYXZjBWYZRKXCRDT7h
gHIzS+ESw91LCKs8VXZ9ZBEf2RclSvFWzK9qpbR2vgYFztjsFkXAmg5UNOkASX4=
=FKFP
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160617/473c7df4/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160617/473c7df4/attachment.key>

From yvoinov at gmail.com  Fri Jun 17 08:05:32 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 17 Jun 2016 14:05:32 +0600
Subject: [squid-users] Regex optimization
In-Reply-To: <0d7da244-9d4a-74f1-fdcd-847dd289f99a@squidblacklist.org>
References: <CAMXC=Wt5W6UK1-qfFEDb2gJ8HQceQDoU5vcsY4rWtKvcNOT0LQ@mail.gmail.com>
 <CAMXC=WuPng+0G1d=sN6ps8XnBj=dsF8JzoLPwduftOYYxY2E9g@mail.gmail.com>
 <201606162120.45927.Antony.Stone@squid.open.source.it>
 <83376605-e0d2-a7db-882a-c0ad017258d3@gmail.com>
 <0d7da244-9d4a-74f1-fdcd-847dd289f99a@squidblacklist.org>
Message-ID: <9d453e6c-7bd4-42bf-70ec-2e35f537b644@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
By the way, I do not care that there is the relevance of porn sites.
Rummage in this shit and check I somehow do not want to. I am satisfied
that blocked most of which are my users trying to surf.

17.06.2016 3:11, Benjamin E. Nichols ?????:
>
>
>
> On 6/16/2016 3:28 PM, Yuri Voinov wrote:
> I propose to nominate for the second place of the contest "The most
> inefficient use of computing resources - 2016." :-!:-D
>
> Because first place already occuped. :-D 30 millions pornsites in one
> squid's ACL and 7 minutes for squid -k refresh. 8-)
> > Yeah and Ill bet about 27 Million of them are dead, expired, parked
or redirected because your list sucks.
>
> > If you really intend to use blacklists tailored for Squid proxy
Native ACL, we are the leading and only provider of such lists.
> > And we actually query each domain daily with batch updates, dead
domains are placed into a holding pool to be queried again cyclically
and re added
> > as necessary.
>
> > Shallalist is a joke, urlblacklist is garbage, if you are serious
and need a better blacklist, we would be happy to serve you.
>
>
>
> 17.06.2016 1:20, Antony Stone ?????:
> >>> On Thursday 16 June 2016 at 21:11:50, Alfredo Rezinovsky wrote:
> >>>
> >>>> Well.. I tried.
> >>>> I need to ban 8613 URLs. Because a law.
> >>> Have you considered
https://www.urlfilterdb.com/products/ufdbguard.html ?
> >>>
> >>>> If I put one per line in a file and set the filename for an
url_regex acl
> >>>> it works. But when the traffic goes up the cpu load goes 100%
(even using
> >>>> workers) and the proxy turns unusable.
> >>> Er, I'm not surprised.
> >>>
> >>>> I tested and saw my squid can't parse regexes with more than 8192
> >>>> characters.
> >>>> I managed to combine the 8000 uris in 34 regexes using a ruby gem,
> and the
> >>>> cpu load stays almost at the same level it is without any acl (same
> >>>> traffic).
> >>> That must be *way* past anything to be described as "maintainable".
> >>>
> >>>> the regex is:
> >>> Er, thanks, that confirms my suspicions above :)
> >>>
> >>>
> >>> Antony.
> >>>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> --
> Signed,
>
> Benjamin E. Nichols
> http://www.squidblacklist.org
>
> 1-405-397-1360
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXY69LAAoJENNXIZxhPexGzbsH/Rjx5G5vP41dPwXAYGqyTEMP
g5uwVn5RLzEB1DOQZBnGp9uSQb9R1ZelNLitUocFdDYZcE9WNbSxrXMl7TfQLgor
UPje/vmONcxLGeNmpgiFQh/qnTouhtwjUN9v/cd55mNOa1KplrRVU9BlucGnzK+1
x9z0icdR3dfS+49LCPiEArysCFnxfINIaKAkYDBGZ4ovdjtegSY0amnG98VI01+J
j9PEeeumjAHI8xn3BgwuAaEZI/B9iPM3LBQRbMkjNfhBbvRqc0/iVLGJiZpjUGSf
Zo4S0BI4kT6p7OzRGqCZZyqLxyNm/onmPvTpW55ZEaeKZMUVaN0MMVtnXynD2lI=
=Mkgm
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160617/24a75d0f/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160617/24a75d0f/attachment.key>

From uhlar at fantomas.sk  Fri Jun 17 09:59:44 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Fri, 17 Jun 2016 11:59:44 +0200
Subject: [squid-users] SQUID and accessing https urls failing
In-Reply-To: <30223422.4668490.1466128044271.JavaMail.yahoo@mail.yahoo.com>
References: <30223422.4668490.1466128044271.JavaMail.yahoo.ref@mail.yahoo.com>
 <30223422.4668490.1466128044271.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <20160617095944.GB16466@fantomas.sk>

On 17.06.16 01:47, Blaxton wrote:
>Squid is running with default and we can access HTTP URLsbut accessing to
> HTTPS URLs timing out and nothing is being logged in log file.

apparently browsers are not configured to use proxy for https.

>I was assuming connecting to HTTPS URLs should work the same as HTTP
> connections out of the box.

no, many http(s) clients use https differently than http.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Remember half the people you know are below average. 


From jaap.dam at gmail.com  Fri Jun 17 11:33:42 2016
From: jaap.dam at gmail.com (Jaap Dam)
Date: Fri, 17 Jun 2016 13:33:42 +0200
Subject: [squid-users] Queue incoming requests when fetching from origin
In-Reply-To: <5762C3D5.3070000@measurement-factory.com>
References: <CAD0U=K13wKi4hytPvyBqUjdr+Thn90=R-RjE67ZG6ovE8QKo7w@mail.gmail.com>
 <acc6da17-b5eb-5a37-2ec2-80b0ae4a7fa6@treenet.co.nz>
 <CAD0U=K1FYLNXWMn595RJD33DpetGhLU=qNz4QmqMwWdEpOFo8g@mail.gmail.com>
 <57617218.5050802@measurement-factory.com>
 <CAD0U=K2keq+foJQjbbq2Tunfp4t=z3rMfh3g1fsszqFu44oVYQ@mail.gmail.com>
 <5762C3D5.3070000@measurement-factory.com>
Message-ID: <CAD0U=K3uX4aFEzhfSmEk0jmzuvBLdJsF9xZ_ozuJFMC-Dq7qTg@mail.gmail.com>

Hi Alex,

Thank you very much for your detailed explanation!

>From your explanation I would assume that my problem could be solved if the
re-validation would be treated as a pure miss. From what I understand,
re-validation is useful when done with If-Modified-Since or If-None-Match.
However my responses do not provide the E-Tag header nor the Last-Modified
header. Is it possible for Squid to never revalidate but always to assume
'pure cache-miss' when a resource is stale?

Best regards

2016-06-16 17:20 GMT+02:00 Alex Rousskov <rousskov at measurement-factory.com>:

> On 06/16/2016 01:45 AM, Jaap Dam wrote:
>
> > Thanks for the information. Could you elaborate on when collapsed
> > forwarding does apply?
>
> Squid is currently able to collapse HTTP client [miss] requests (but not
> internally generated HTTP requests triggered by HTTP client requests).
> Furthermore, to be collapsable, the request must have no markings that
> make the future response uncachable.
>
>
> > With your extra information, my assumption would
> > be that it only applies on requests of a resource that has never been
> > cached before.
>
> I would not phrase it like that because Squid does not remember was has
> been cached before, only what is still cached at the query time. There
> are three primary cases for an HTTP client request to consider here:
>
> * pure cache hit: Collapsing is inapplicable because Squid does not send
> any requests (there is nothing to collapse). Each HTTP client request is
> satisfied from the Squid cache.
>
> * pure cache miss: Multiple requests for the same missing object can be
> collapsed if collapsed_forwarding is enabled. Collapsable requests have
> no markings that make the future response uncachable.
>
> * revalidation: The requested object was found in the cache but it was
> stale. Squid sends an internal "revalidation" request to the origin
> server or peer. These internal requests are currently not collapsed. We
> are working on collapsing them as well.
>
>
> > Secondly would you have a suggestion for solving the issue I'm facing?
>
>
> I have not studied the issue you are facing, but if you think collapsing
> revalidation requests would solve your problem, then either wait for us
> to finish initial collapsed revalidation support (and then see if it
> solves your problem) or co-sponsor that ongoing development (to make
> sure it solves your problem).
>
>
> HTH,
>
> Alex.
>
>
>
> > 2016-06-15 17:19 GMT+02:00 Alex Rousskov:
> >
> >     On 06/14/2016 02:51 AM, Jaap Dam wrote:
> >
> >     > I've part of the logging as an attachment. I'm requesting a single
> URL
> >     > in this log. The log starts with a stale cache of the item.
> >
> >     Collapsed forwarding does not apply to cache revalidation requests
> yet.
> >     Factory is working on implementing collapsed revalidations (in some
> >     environments), but I cannot promise a specific delivery date or that
> >     your particular environment will be covered.
> >
> >     Alex.
> >
> >
> >
> >
> >     > 2016-06-13 15:34 GMT+02:00 Amos Jeffries:
> >     >
> >     >     On 14/06/2016 12:29 a.m., Jaap Dam wrote:
> >     >     > Is the collapsed_forwarding directive the correct one to use
> >     for my
> >     >     > use-case or am i missing something?
> >     >
> >     >     Yes it is correct so far as I am understanding your need.
> >     >
> >     >     For further debugging about what is going on you will need the
> >     HTTP
> >     >     messages involved. Add the directive "debug_options 11,2 20,3"
> >     to your
> >     >     config to get them logged in cache.log.
> >
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160617/fb296515/attachment.htm>

From rentorbuy at yahoo.com  Fri Jun 17 11:56:55 2016
From: rentorbuy at yahoo.com (Vieri)
Date: Fri, 17 Jun 2016 11:56:55 +0000 (UTC)
Subject: [squid-users] ext_wbinfo_group_acl.pl
References: <777268532.4854961.1466164615954.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <777268532.4854961.1466164615954.JavaMail.yahoo@mail.yahoo.com>

Hi,

I'm using the ext_wbinfo_group_acl.pl script in squid. However, it seems to generate lots of "uninitialized variable" messages in syslog.
I quickly fixed the issue by replacing
my $ans;
with
my $ans = "";
.
Is there another way to fix this without changing the code?
Should it be fixed upstream?

Thanks

Vieri

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160617/7246fe4b/attachment.htm>

From william.ivanski at gmail.com  Fri Jun 17 12:32:05 2016
From: william.ivanski at gmail.com (William Ivanski)
Date: Fri, 17 Jun 2016 09:32:05 -0300
Subject: [squid-users] Establishing secure conection problems (Chrome)
In-Reply-To: <201606021645.38753.Antony.Stone@squid.open.source.it>
References: <CACaWZ9TD=1d_nrojzacdTaMZiopLy7Y1cU78KinzdXKb6g4JFQ@mail.gmail.com>
 <CACaWZ9R99-NOswTuf6iOrc-bz-GeK9aemVeTGhmgaVCv+G4HWA@mail.gmail.com>
 <CACaWZ9RXL3_bf8LLnLnan_9yKGzvx8q9pnwN6wnHhxX=SS++kw@mail.gmail.com>
 <201606021645.38753.Antony.Stone@squid.open.source.it>
Message-ID: <5763EDC5.7080401@gmail.com>

Greetings,

As we had agreed, we formatted our gateway machine and installed squid 
(on Debian 8.3) this way:

apt-get install squid3
service squid3 stop
squid3 -z
service squid3 start

Also, we disabled QUIC and cleared cache on Google Chrome on all users' 
machines.

And now the problem is gone. Thank you all for your help!


Em 02/06/2016 11:45, Antony Stone escreveu:
> On Thursday 02 June 2016 at 15:35:10, William Ivanski wrote:
>
>> Thank you for your quick response.
>>
>> First of all forgive me for the lack of information in the first
>> email. I've tried to disable QUIC a few minutes ago and the problem
>> persists. Follow the information requested:
>>
>> -> Compilation:
>>
>> I've installed squid using the following commands:
>>
>>      cd /usr/src
>>
>>      apt-get install squid3
> So, that will install a working copy of Squid, and then...
>
>>      wget
>> http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.15-20160330-r14015.ta
>> r.gz
>>
>>      tar xvzf squid-3.5.15-20160330-r14015.tar.gz
>>
>>      cd squid-3.5.15-20160330-r14015
> ...you download the latest source version and try to build it yourself...
>
>>      apt-get build-dep squid3 && apt-get install build-essential libssl-dev
> ...unfortunately using the Debian commands to build from a source package,
> which you did not download (the Debian source package is not the same as the
> Squid tarball).
>
> You then proceed to do the standard ./configure && make && make install for
> installation from a tarball.
>
> I wouldn't like to guess what sort of state any installed Squid is in after
> doing this bizarre combination.
>
>
> I recommend installing the Debian binary package, *or* install the Debian
> source package and build from that, *or* download the source tarball and build
> that.  Do not combine these.
>
>
> Regards,
>
>
> Antony.
>



From nilesh.gavali at tcs.com  Fri Jun 17 14:24:30 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Fri, 17 Jun 2016 15:24:30 +0100
Subject: [squid-users] URL access based on AD group membership
Message-ID: <OF178A507A.21A17135-ON80257FD5.004D6739-80257FD5.004F24B2@tcs.com>

Team;
Need expert help here,
here is my set up - as of now squid integrated with Windows 2012R2 AD, SSO 
with kerberos - working fine. 
Now I want to restrict Internet access for user based on their AD group 
membership. I tried loads of options from various site but no luck. not 
sure what is going wrong.
here is my squid config, and cache.log o/p. 

=============================
#
# Recommended minimum configuration:
#

auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
HTTP/proxy02.abcd.gov.in at ABCD.GOV.IN
auth_param negotiate children 10
auth_param negotiate keep_alive on
auth_param basic credentialsttl 2 hours
acl ad_auth proxy_auth REQUIRED

#AD Group membership

external_acl_type AD_Group %LOGIN /usr/lib64/squid/squid_ldap_group -P -R 
-b "DC=ABCD,DC=GOV,DC=IN" -D svcproxy -w 123456789 -f 
"(&(objectclass=person)(userPrincipalName=%u)(memberof=cn=%g,ou=InternetAccess,ou=Groups,dc=ABCD,dc=GOV,dc=IN))" 
-h abcd.gov.in -s sub -v 3 -d

acl infrateam external AD_Group lgInternetAccess
acl windowsupdate dstdomain "/etc/squid/sitelist/infra_update_site"

acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Only allow cachemgr access from localhost
http_access allow manager localhost
http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports


# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
#
# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed

http_access deny infrateam windowsupdate
http_access allow ad_auth

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 8080
never_direct allow all

cache_peer xx.xx.2.108 parent 8080 0 default
#dns_nameservers DNSSVR.abcd.gov.in
dns_nameservers XX.XX.2.108

# We recommend you to use at least the following line.
#hierarchy_stoplist cgi-bin ?

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/spool/squid 2048 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

# Log forwarding to SysLog
access_log syslog:local1.info

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
======================================
cache.log o/p-
Connected OK
group filter 
'(&(objectclass=person)(userPrincipalName=da.853438 at ABCD.GOV.IN)(memberof=cn=lgInternetAccess,ou=InternetAccess,ou=Groups,dc=abcd,dc=gov,dc=in))', 
searchbase 'DC=ABCD,DC=GOV,DC=IN'
======================================


Thanks & Regards
Nilesh Suresh Gavali
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160617/84d0f594/attachment.htm>

From rousskov at measurement-factory.com  Fri Jun 17 15:21:38 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 17 Jun 2016 09:21:38 -0600
Subject: [squid-users] Queue incoming requests when fetching from origin
In-Reply-To: <CAD0U=K3uX4aFEzhfSmEk0jmzuvBLdJsF9xZ_ozuJFMC-Dq7qTg@mail.gmail.com>
References: <CAD0U=K13wKi4hytPvyBqUjdr+Thn90=R-RjE67ZG6ovE8QKo7w@mail.gmail.com>
 <acc6da17-b5eb-5a37-2ec2-80b0ae4a7fa6@treenet.co.nz>
 <CAD0U=K1FYLNXWMn595RJD33DpetGhLU=qNz4QmqMwWdEpOFo8g@mail.gmail.com>
 <57617218.5050802@measurement-factory.com>
 <CAD0U=K2keq+foJQjbbq2Tunfp4t=z3rMfh3g1fsszqFu44oVYQ@mail.gmail.com>
 <5762C3D5.3070000@measurement-factory.com>
 <CAD0U=K3uX4aFEzhfSmEk0jmzuvBLdJsF9xZ_ozuJFMC-Dq7qTg@mail.gmail.com>
Message-ID: <57641582.8010001@measurement-factory.com>

On 06/17/2016 05:33 AM, Jaap Dam wrote:

> From what I
> understand, re-validation is useful when done with If-Modified-Since or
> If-None-Match.

To revalidate stale objects, Squid uses conditional requests. That is
not the only way to revalidate, but that is what Squid does.


> However my responses do not provide the E-Tag header nor
> the Last-Modified header. 

IIRC, the If-Modified-Since field in a conditional request may use the
response Date header when Last-Modified is not available. If the origin
server supports checking resource modification times (without disclosing
them in responses for some reason), revalidation would still work as
intended.


> Is it possible for Squid to never revalidate
> but always to assume 'pure cache-miss' when a resource is stale?

I am not sure. Others may be able to answer this question
authoritatively. If you force me to guess, I would say "no".

Alex.



> 2016-06-16 17:20 GMT+02:00 Alex Rousskov
> <rousskov at measurement-factory.com
> <mailto:rousskov at measurement-factory.com>>:
> 
>     On 06/16/2016 01:45 AM, Jaap Dam wrote:
> 
>     > Thanks for the information. Could you elaborate on when collapsed
>     > forwarding does apply?
> 
>     Squid is currently able to collapse HTTP client [miss] requests (but not
>     internally generated HTTP requests triggered by HTTP client requests).
>     Furthermore, to be collapsable, the request must have no markings that
>     make the future response uncachable.
> 
> 
>     > With your extra information, my assumption would
>     > be that it only applies on requests of a resource that has never been
>     > cached before.
> 
>     I would not phrase it like that because Squid does not remember was has
>     been cached before, only what is still cached at the query time. There
>     are three primary cases for an HTTP client request to consider here:
> 
>     * pure cache hit: Collapsing is inapplicable because Squid does not send
>     any requests (there is nothing to collapse). Each HTTP client request is
>     satisfied from the Squid cache.
> 
>     * pure cache miss: Multiple requests for the same missing object can be
>     collapsed if collapsed_forwarding is enabled. Collapsable requests have
>     no markings that make the future response uncachable.
> 
>     * revalidation: The requested object was found in the cache but it was
>     stale. Squid sends an internal "revalidation" request to the origin
>     server or peer. These internal requests are currently not collapsed. We
>     are working on collapsing them as well.
> 
> 
>     > Secondly would you have a suggestion for solving the issue I'm facing?
> 
> 
>     I have not studied the issue you are facing, but if you think collapsing
>     revalidation requests would solve your problem, then either wait for us
>     to finish initial collapsed revalidation support (and then see if it
>     solves your problem) or co-sponsor that ongoing development (to make
>     sure it solves your problem).
> 
> 
>     HTH,
> 
>     Alex.
> 
> 
> 
>     > 2016-06-15 17:19 GMT+02:00 Alex Rousskov:
>     >
>     >     On 06/14/2016 02:51 AM, Jaap Dam wrote:
>     >
>     >     > I've part of the logging as an attachment. I'm requesting a
>     single URL
>     >     > in this log. The log starts with a stale cache of the item.
>     >
>     >     Collapsed forwarding does not apply to cache revalidation
>     requests yet.
>     >     Factory is working on implementing collapsed revalidations (in
>     some
>     >     environments), but I cannot promise a specific delivery date
>     or that
>     >     your particular environment will be covered.
>     >
>     >     Alex.
>     >
>     >
>     >
>     >
>     >     > 2016-06-13 15:34 GMT+02:00 Amos Jeffries:
>     >     >
>     >     >     On 14/06/2016 12:29 a.m., Jaap Dam wrote:
>     >     >     > Is the collapsed_forwarding directive the correct one
>     to use
>     >     for my
>     >     >     > use-case or am i missing something?
>     >     >
>     >     >     Yes it is correct so far as I am understanding your need.
>     >     >
>     >     >     For further debugging about what is going on you will
>     need the
>     >     HTTP
>     >     >     messages involved. Add the directive "debug_options 11,2
>     20,3"
>     >     to your
>     >     >     config to get them logged in cache.log.
>     >
>     >
> 
> 



From squid3 at treenet.co.nz  Sat Jun 18 07:04:10 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 18 Jun 2016 19:04:10 +1200
Subject: [squid-users] ext_wbinfo_group_acl.pl
In-Reply-To: <777268532.4854961.1466164615954.JavaMail.yahoo@mail.yahoo.com>
References: <777268532.4854961.1466164615954.JavaMail.yahoo.ref@mail.yahoo.com>
 <777268532.4854961.1466164615954.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <397a52c2-a8ea-e250-f290-36ab9a499c81@treenet.co.nz>

On 17/06/2016 11:56 p.m., Vieri wrote:
> Hi,
> 
> I'm using the ext_wbinfo_group_acl.pl script in squid. However, it seems to generate lots of "uninitialized variable" messages in syslog.
> I quickly fixed the issue by replacing
> my $ans;
> with
> my $ans = "";
> .
> Is there another way to fix this without changing the code?

Code problems generally cannot be fixed without changing some code.

> Should it be fixed upstream?

What do you mean by "upstream"?

Patch submissions are welcome on the squid-dev mailing list.
see <http://wiki.squid-cache.org/MergeProcedure#Submission_Format> for
details on how to prepare it.

Amos



From squid3 at treenet.co.nz  Sat Jun 18 07:18:22 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 18 Jun 2016 19:18:22 +1200
Subject: [squid-users] URL access based on AD group membership
In-Reply-To: <OF178A507A.21A17135-ON80257FD5.004D6739-80257FD5.004F24B2@tcs.com>
References: <OF178A507A.21A17135-ON80257FD5.004D6739-80257FD5.004F24B2@tcs.com>
Message-ID: <6a8915eb-ae48-7905-f51f-76c693713caa@treenet.co.nz>

On 18/06/2016 2:24 a.m., Nilesh Gavali wrote:
> Team;
> Need expert help here,
> here is my set up - as of now squid integrated with Windows 2012R2 AD, SSO 
> with kerberos - working fine. 
> Now I want to restrict Internet access for user based on their AD group 
> membership. I tried loads of options from various site but no luck. not 
> sure what is going wrong.

You are repeatedly making the same mistake and posting a new thread
asking the same question over and over. The answer already given won't
change much.

Perhapse you need to read the whole FAQ page from the beginning:
<http://wiki.squid-cache.org/SquidFaq/SquidAcl>

Amos



From yvoinov at gmail.com  Sat Jun 18 12:42:51 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 18 Jun 2016 18:42:51 +0600
Subject: [squid-users] ECDSA and SSL bump
Message-ID: <6685dba5-afff-7691-14ef-1dbe20ff461c@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Good weekend to all.

Gentlemen, somebody played with ECDSA-certificates and SSL bump with SQUID?

I have when trying to use ECDSA self-signed CA to bump, Squid (version
no matter) gives an error SSLv3 (for unknown reasons) and can not
establish a secure connection. With CIPHER/PROTOCOL negotiation error in
browser. Yea, latest Chrome.

Does this mean that Squid is not support ECDSA?

WBR, Yuri


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXZUHLAAoJENNXIZxhPexGIuYIAI/9zSbTSdAcR1aUGV1paYyt
FBRDDx0pCrDoqBGbKkN1hE342crBWwnFhqenQRucxdOgPrVFL6lm3gKB3L3ioXUP
l/L+W6dE4YQgd2QJeb6mgBklN8e5MacYc3ZGc/cJavPl+mw3IrZZZUlq/7AoYSqc
99ymT+fG/klOF9oJSsvSFaWqRlBBALOVVWtpj5ZYqOWPs+ZHiJoSkSbfZuiZQ1aL
i2G9+GPPsNDAcV7mFXRhUH358HSkuhGgQxh8vaU7bRUEbHVhIxhTYxJdHrxD23K5
m3B0x1/DwtMNCYUhavQQrTEJH7vD1/uCOcH3uJRNeUZ+rAK+U9IOSErtcI8Ze8U=
=VlgZ
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160618/10f09455/attachment.key>

From nilesh.gavali at tcs.com  Sat Jun 18 13:05:05 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Sat, 18 Jun 2016 14:05:05 +0100
Subject: [squid-users] URL access based on AD group membership
In-Reply-To: <mailman.3.1466251201.22523.squid-users@lists.squid-cache.org>
References: <mailman.3.1466251201.22523.squid-users@lists.squid-cache.org>
Message-ID: <OFD8B15FB3.AA67E3F3-ON80257FD6.00475773-80257FD6.0047DEBF@tcs.com>

Hello Amos;
I am able to configure the same as guided, Thanks for help. One query I 
have now.
Currently I have configure squid with AD kerberos auth. also url access 
restricted based on  AD group membership.

Now I observed, is that when I add any user to one of the AD group which 
allowed in squid.  it is not accepting the changes until I restart the 
squid service.
Is this the way squid behave or do I need to follow different procedure. 
So once user added to AD group it will recognised by squid on the fly 
without restarting squid service.

regards.
Nilesh G.



Date: Sat, 18 Jun 2016 19:18:22 +1200
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] URL access based on AD group membership
Message-ID: <6a8915eb-ae48-7905-f51f-76c693713caa at treenet.co.nz>
Content-Type: text/plain; charset=utf-8

On 18/06/2016 2:24 a.m., Nilesh Gavali wrote:
> Team;
> Need expert help here,
> here is my set up - as of now squid integrated with Windows 2012R2 AD, 
SSO 
> with kerberos - working fine. 
> Now I want to restrict Internet access for user based on their AD group 
> membership. I tried loads of options from various site but no luck. not 
> sure what is going wrong.

You are repeatedly making the same mistake and posting a new thread
asking the same question over and over. The answer already given won't
change much.

Perhapse you need to read the whole FAQ page from the beginning:
<http://wiki.squid-cache.org/SquidFaq/SquidAcl>

Amos



------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 22, Issue 83
*******************************************

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160618/1e763647/attachment.htm>

From eliezer at ngtech.co.il  Sun Jun 19 05:16:42 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 19 Jun 2016 08:16:42 +0300
Subject: [squid-users] Queue incoming requests when fetching from origin
In-Reply-To: <57641582.8010001@measurement-factory.com>
References: <CAD0U=K13wKi4hytPvyBqUjdr+Thn90=R-RjE67ZG6ovE8QKo7w@mail.gmail.com>
 <acc6da17-b5eb-5a37-2ec2-80b0ae4a7fa6@treenet.co.nz>
 <CAD0U=K1FYLNXWMn595RJD33DpetGhLU=qNz4QmqMwWdEpOFo8g@mail.gmail.com>
 <57617218.5050802@measurement-factory.com>
 <CAD0U=K2keq+foJQjbbq2Tunfp4t=z3rMfh3g1fsszqFu44oVYQ@mail.gmail.com>
 <5762C3D5.3070000@measurement-factory.com>
 <CAD0U=K3uX4aFEzhfSmEk0jmzuvBLdJsF9xZ_ozuJFMC-Dq7qTg@mail.gmail.com>
 <57641582.8010001@measurement-factory.com>
Message-ID: <004d01d1c9e9$c45988a0$4d0c99e0$@ngtech.co.il>

Hey Jaap, (not sure if it's the first name)

The issue is that there are consequences for cached objects not being revalidated.
Also if there are sites which needs to be targeted it would be a different story.
Some might not understand the difference between a cache and an archive or want it to act as one.
A cache is meant to be temporary while archive should last longer.
One example is Windows Updates which might needs to be archived since it's always needed.

If you have a specific targeted site, let me know and I will try to see if something can be done.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Alex Rousskov
Sent: Friday, June 17, 2016 6:22 PM
To: Jaap Dam
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Queue incoming requests when fetching from origin

On 06/17/2016 05:33 AM, Jaap Dam wrote:

> From what I
> understand, re-validation is useful when done with If-Modified-Since 
> or If-None-Match.

To revalidate stale objects, Squid uses conditional requests. That is not the only way to revalidate, but that is what Squid does.


> However my responses do not provide the E-Tag header nor the 
> Last-Modified header.

IIRC, the If-Modified-Since field in a conditional request may use the response Date header when Last-Modified is not available. If the origin server supports checking resource modification times (without disclosing them in responses for some reason), revalidation would still work as intended.


> Is it possible for Squid to never revalidate but always to assume 
> 'pure cache-miss' when a resource is stale?

I am not sure. Others may be able to answer this question authoritatively. If you force me to guess, I would say "no".

Alex.



> 2016-06-16 17:20 GMT+02:00 Alex Rousskov 
> <rousskov at measurement-factory.com
> <mailto:rousskov at measurement-factory.com>>:
> 
>     On 06/16/2016 01:45 AM, Jaap Dam wrote:
> 
>     > Thanks for the information. Could you elaborate on when collapsed
>     > forwarding does apply?
> 
>     Squid is currently able to collapse HTTP client [miss] requests (but not
>     internally generated HTTP requests triggered by HTTP client requests).
>     Furthermore, to be collapsable, the request must have no markings that
>     make the future response uncachable.
> 
> 
>     > With your extra information, my assumption would
>     > be that it only applies on requests of a resource that has never been
>     > cached before.
> 
>     I would not phrase it like that because Squid does not remember was has
>     been cached before, only what is still cached at the query time. There
>     are three primary cases for an HTTP client request to consider here:
> 
>     * pure cache hit: Collapsing is inapplicable because Squid does not send
>     any requests (there is nothing to collapse). Each HTTP client request is
>     satisfied from the Squid cache.
> 
>     * pure cache miss: Multiple requests for the same missing object can be
>     collapsed if collapsed_forwarding is enabled. Collapsable requests have
>     no markings that make the future response uncachable.
> 
>     * revalidation: The requested object was found in the cache but it was
>     stale. Squid sends an internal "revalidation" request to the origin
>     server or peer. These internal requests are currently not collapsed. We
>     are working on collapsing them as well.
> 
> 
>     > Secondly would you have a suggestion for solving the issue I'm facing?
> 
> 
>     I have not studied the issue you are facing, but if you think collapsing
>     revalidation requests would solve your problem, then either wait for us
>     to finish initial collapsed revalidation support (and then see if it
>     solves your problem) or co-sponsor that ongoing development (to make
>     sure it solves your problem).
> 
> 
>     HTH,
> 
>     Alex.
> 
> 
> 
>     > 2016-06-15 17:19 GMT+02:00 Alex Rousskov:
>     >
>     >     On 06/14/2016 02:51 AM, Jaap Dam wrote:
>     >
>     >     > I've part of the logging as an attachment. I'm requesting a
>     single URL
>     >     > in this log. The log starts with a stale cache of the item.
>     >
>     >     Collapsed forwarding does not apply to cache revalidation
>     requests yet.
>     >     Factory is working on implementing collapsed revalidations (in
>     some
>     >     environments), but I cannot promise a specific delivery date
>     or that
>     >     your particular environment will be covered.
>     >
>     >     Alex.
>     >
>     >
>     >
>     >
>     >     > 2016-06-13 15:34 GMT+02:00 Amos Jeffries:
>     >     >
>     >     >     On 14/06/2016 12:29 a.m., Jaap Dam wrote:
>     >     >     > Is the collapsed_forwarding directive the correct one
>     to use
>     >     for my
>     >     >     > use-case or am i missing something?
>     >     >
>     >     >     Yes it is correct so far as I am understanding your need.
>     >     >
>     >     >     For further debugging about what is going on you will
>     need the
>     >     HTTP
>     >     >     messages involved. Add the directive "debug_options 11,2
>     20,3"
>     >     to your
>     >     >     config to get them logged in cache.log.
>     >
>     >
> 
> 

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Sun Jun 19 09:18:36 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 19 Jun 2016 21:18:36 +1200
Subject: [squid-users] ECDSA and SSL bump
In-Reply-To: <6685dba5-afff-7691-14ef-1dbe20ff461c@gmail.com>
References: <6685dba5-afff-7691-14ef-1dbe20ff461c@gmail.com>
Message-ID: <dfc8d75a-9ba7-e941-db11-e13005f752c4@treenet.co.nz>

On 19/06/2016 12:42 a.m., Yuri Voinov wrote:
> 
> Good weekend to all.
> 
> Gentlemen, somebody played with ECDSA-certificates and SSL bump with SQUID?
> 
> I have when trying to use ECDSA self-signed CA to bump, Squid (version
> no matter) gives an error SSLv3 (for unknown reasons) and can not
> establish a secure connection. With CIPHER/PROTOCOL negotiation error in
> browser. Yea, latest Chrome.
> 
> Does this mean that Squid is not support ECDSA?
> 

It means your certificate was not created with the flags indicating
which Curve it is to be used with.
 <https://wiki.openssl.org/index.php/Elliptic_Curve_Cryptography#Named_Curves>

I can't find any evidence of the flag being set on generated
certificates. So that may also be adding to the problem.

Amos


From yvoinov at gmail.com  Sun Jun 19 09:42:25 2016
From: yvoinov at gmail.com (Yuri)
Date: Sun, 19 Jun 2016 15:42:25 +0600
Subject: [squid-users] ECDSA and SSL bump
In-Reply-To: <dfc8d75a-9ba7-e941-db11-e13005f752c4@treenet.co.nz>
References: <6685dba5-afff-7691-14ef-1dbe20ff461c@gmail.com>
 <dfc8d75a-9ba7-e941-db11-e13005f752c4@treenet.co.nz>
Message-ID: <9ca89ca8-0254-2868-0f6b-d6ccaa880faa@gmail.com>

That's just the point that everything was done according to the guidelines.

# First create EC parameters for selected curve
openssl ecparam -name secp384r1 -out secp384r1.pem
# Then generate dhparam with this EC params
openssl dhparam -in secp384r1.pem -outform PEM -out dhparam.pem 3072

# root CA 1
openssl ecparam -name secp384r1 -genkey -param_enc explicit -out rootCA.key
openssl req -new -x509 -sha256 -key rootCA.key -out rootCA.crt -days 10950

#Generate the CRL (both in PEM and DER):
openssl ca -config openssl.cfg -gencrl -keyfile rootCA.key -cert 
rootCA.crt -out rootCA.crl.pem
openssl crl -inform PEM -in rootCA.crl.pem -outform DER -out rootCA.crl

# root CA 2
openssl ecparam -name secp384r1 -genkey -param_enc explicit -out rootCA2.key
openssl req -new -sha256 -key rootCA2.key -out rootCA2.csr
openssl ca -keyfile rootCA.key -cert rootCA.crt -in rootCA2.csr -out 
rootCA2.crt -config openssl.cfg -days 9125

I do not see, where I could make a mistake so stupid.

19.06.2016 15:18, Amos Jeffries ?????:
> On 19/06/2016 12:42 a.m., Yuri Voinov wrote:
>> Good weekend to all.
>>
>> Gentlemen, somebody played with ECDSA-certificates and SSL bump with SQUID?
>>
>> I have when trying to use ECDSA self-signed CA to bump, Squid (version
>> no matter) gives an error SSLv3 (for unknown reasons) and can not
>> establish a secure connection. With CIPHER/PROTOCOL negotiation error in
>> browser. Yea, latest Chrome.
>>
>> Does this mean that Squid is not support ECDSA?
>>
> It means your certificate was not created with the flags indicating
> which Curve it is to be used with.
>   <https://wiki.openssl.org/index.php/Elliptic_Curve_Cryptography#Named_Curves>
>
> I can't find any evidence of the flag being set on generated
> certificates. So that may also be adding to the problem.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Sun Jun 19 09:55:08 2016
From: yvoinov at gmail.com (Yuri)
Date: Sun, 19 Jun 2016 15:55:08 +0600
Subject: [squid-users] ECDSA and SSL bump
In-Reply-To: <dfc8d75a-9ba7-e941-db11-e13005f752c4@treenet.co.nz>
References: <6685dba5-afff-7691-14ef-1dbe20ff461c@gmail.com>
 <dfc8d75a-9ba7-e941-db11-e13005f752c4@treenet.co.nz>
Message-ID: <a318b7ec-ef1a-78ec-14dd-3ab9ffbc08c6@gmail.com>

I agree with the diagnosis. However, this manual does not contain 
complete answer to the question - as, indeed, add that flag in a 
certificate?

Write a program on C? I do not see the command line options or 
configuration settings, something related to the ECDSA.

19.06.2016 15:18, Amos Jeffries ?????:
> On 19/06/2016 12:42 a.m., Yuri Voinov wrote:
>> Good weekend to all.
>>
>> Gentlemen, somebody played with ECDSA-certificates and SSL bump with SQUID?
>>
>> I have when trying to use ECDSA self-signed CA to bump, Squid (version
>> no matter) gives an error SSLv3 (for unknown reasons) and can not
>> establish a secure connection. With CIPHER/PROTOCOL negotiation error in
>> browser. Yea, latest Chrome.
>>
>> Does this mean that Squid is not support ECDSA?
>>
> It means your certificate was not created with the flags indicating
> which Curve it is to be used with.
>   <https://wiki.openssl.org/index.php/Elliptic_Curve_Cryptography#Named_Curves>
>
> I can't find any evidence of the flag being set on generated
> certificates. So that may also be adding to the problem.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Sun Jun 19 10:16:15 2016
From: yvoinov at gmail.com (Yuri)
Date: Sun, 19 Jun 2016 16:16:15 +0600
Subject: [squid-users] ECDSA and SSL bump
In-Reply-To: <dfc8d75a-9ba7-e941-db11-e13005f752c4@treenet.co.nz>
References: <6685dba5-afff-7691-14ef-1dbe20ff461c@gmail.com>
 <dfc8d75a-9ba7-e941-db11-e13005f752c4@treenet.co.nz>
Message-ID: <f1f57874-6660-274e-7f6a-b77ddbabb85f@gmail.com>

Aaaaaaaaaa, found my mistake. :)

Stupid openssl manuals. :)


19.06.2016 15:18, Amos Jeffries ?????:
> On 19/06/2016 12:42 a.m., Yuri Voinov wrote:
>> Good weekend to all.
>>
>> Gentlemen, somebody played with ECDSA-certificates and SSL bump with SQUID?
>>
>> I have when trying to use ECDSA self-signed CA to bump, Squid (version
>> no matter) gives an error SSLv3 (for unknown reasons) and can not
>> establish a secure connection. With CIPHER/PROTOCOL negotiation error in
>> browser. Yea, latest Chrome.
>>
>> Does this mean that Squid is not support ECDSA?
>>
> It means your certificate was not created with the flags indicating
> which Curve it is to be used with.
>   <https://wiki.openssl.org/index.php/Elliptic_Curve_Cryptography#Named_Curves>
>
> I can't find any evidence of the flag being set on generated
> certificates. So that may also be adding to the problem.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Sun Jun 19 10:17:26 2016
From: yvoinov at gmail.com (Yuri)
Date: Sun, 19 Jun 2016 16:17:26 +0600
Subject: [squid-users] ECDSA and SSL bump
In-Reply-To: <dfc8d75a-9ba7-e941-db11-e13005f752c4@treenet.co.nz>
References: <6685dba5-afff-7691-14ef-1dbe20ff461c@gmail.com>
 <dfc8d75a-9ba7-e941-db11-e13005f752c4@treenet.co.nz>
Message-ID: <336d5fb5-41ad-7497-e51d-634f6e347775@gmail.com>

Must be:

openssl ecparam -name secp384r1 -genkey -param_enc named_curve -out 
rootCA.key

:)

I.e. -param_enc can't be default, named_curve argument required :)


19.06.2016 15:18, Amos Jeffries ?????:
> On 19/06/2016 12:42 a.m., Yuri Voinov wrote:
>> Good weekend to all.
>>
>> Gentlemen, somebody played with ECDSA-certificates and SSL bump with SQUID?
>>
>> I have when trying to use ECDSA self-signed CA to bump, Squid (version
>> no matter) gives an error SSLv3 (for unknown reasons) and can not
>> establish a secure connection. With CIPHER/PROTOCOL negotiation error in
>> browser. Yea, latest Chrome.
>>
>> Does this mean that Squid is not support ECDSA?
>>
> It means your certificate was not created with the flags indicating
> which Curve it is to be used with.
>   <https://wiki.openssl.org/index.php/Elliptic_Curve_Cryptography#Named_Curves>
>
> I can't find any evidence of the flag being set on generated
> certificates. So that may also be adding to the problem.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Sun Jun 19 11:40:17 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 19 Jun 2016 23:40:17 +1200
Subject: [squid-users] ECDSA and SSL bump
In-Reply-To: <336d5fb5-41ad-7497-e51d-634f6e347775@gmail.com>
References: <6685dba5-afff-7691-14ef-1dbe20ff461c@gmail.com>
 <dfc8d75a-9ba7-e941-db11-e13005f752c4@treenet.co.nz>
 <336d5fb5-41ad-7497-e51d-634f6e347775@gmail.com>
Message-ID: <99d9f583-fc4b-ed58-cfc6-4402d7fc8cd0@treenet.co.nz>

On 19/06/2016 10:17 p.m., Yuri wrote:
> Must be:
> 
> openssl ecparam -name secp384r1 -genkey -param_enc named_curve -out
> rootCA.key
> 
> :)
> 
> I.e. -param_enc can't be default, named_curve argument required :)
> 

Aha.

Is it working for you now? or do we still have to alter the cert
generator part of Squid?

Amos



From yvoinov at gmail.com  Sun Jun 19 12:05:50 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 19 Jun 2016 18:05:50 +0600
Subject: [squid-users] ECDSA and SSL bump
In-Reply-To: <99d9f583-fc4b-ed58-cfc6-4402d7fc8cd0@treenet.co.nz>
References: <6685dba5-afff-7691-14ef-1dbe20ff461c@gmail.com>
 <dfc8d75a-9ba7-e941-db11-e13005f752c4@treenet.co.nz>
 <336d5fb5-41ad-7497-e51d-634f6e347775@gmail.com>
 <99d9f583-fc4b-ed58-cfc6-4402d7fc8cd0@treenet.co.nz>
Message-ID: <ee89b82e-9855-6357-8aea-f033d0e170d6@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


19.06.2016 17:40, Amos Jeffries ?????:
> On 19/06/2016 10:17 p.m., Yuri wrote:
>> Must be:
>>
>> openssl ecparam -name secp384r1 -genkey -param_enc named_curve -out
>> rootCA.key
>>
>> :)
>>
>> I.e. -param_enc can't be default, named_curve argument required :)
>>
>
> Aha.
>
> Is it working for you now? or do we still have to alter the cert
> generator part of Squid?
Will test now. I want to do a little research with ECDSA accordingly
with bug 4497. Will write results.
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXZoqaAAoJENNXIZxhPexG8RMH/A9bfKoUV2VrvWbXdiIj9wzd
hj9HoPv6DcLfZ8Pq8+6XO+QOb69jiDTNJIhsIgDlN5rgbWEtmXqAEN+GixHqy3aj
VlGLzc1IVuHrup+N0spXx8XeQb7qOglzwLiQIuB7xf3pAq2MSdYWclPuplOuHUa6
bA9xFzjyVe/dQ2IbfbqNEhFTH3njCqNNahMHaC5nyMrZe/mud0JWBcAObcSKEC+P
FiSGbZAMi8UoxVw7k9v4fqHGX72zAGqE5Ho8Zsvh25cgbDrdc+utDi1Zt3KTMEls
h0lJNarx5ooemU0kBC1vgrNtFwCCqklJeOv6dE9a+Y4RLeMwJ6uI6xP4eBa1WVE=
=VEU6
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160619/f0128d69/attachment.key>

From yvoinov at gmail.com  Sun Jun 19 12:44:11 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 19 Jun 2016 18:44:11 +0600
Subject: [squid-users] ECDSA and SSL bump
In-Reply-To: <dfc8d75a-9ba7-e941-db11-e13005f752c4@treenet.co.nz>
References: <6685dba5-afff-7691-14ef-1dbe20ff461c@gmail.com>
 <dfc8d75a-9ba7-e941-db11-e13005f752c4@treenet.co.nz>
Message-ID: <6d5e40bc-0d76-8f1d-0117-cbec96bab720@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Cert generator is ok.

Bug 4497 still not gone. So, it is irrelevant ECDSA. Sad.


19.06.2016 15:18, Amos Jeffries ?????:
> On 19/06/2016 12:42 a.m., Yuri Voinov wrote:
>>
>> Good weekend to all.
>>
>> Gentlemen, somebody played with ECDSA-certificates and SSL bump with
SQUID?
>>
>> I have when trying to use ECDSA self-signed CA to bump, Squid (version
>> no matter) gives an error SSLv3 (for unknown reasons) and can not
>> establish a secure connection. With CIPHER/PROTOCOL negotiation error in
>> browser. Yea, latest Chrome.
>>
>> Does this mean that Squid is not support ECDSA?
>>
>
> It means your certificate was not created with the flags indicating
> which Curve it is to be used with.
> 
<https://wiki.openssl.org/index.php/Elliptic_Curve_Cryptography#Named_Curves>
>
> I can't find any evidence of the flag being set on generated
> certificates. So that may also be adding to the problem.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXZpOaAAoJENNXIZxhPexGs3QIAKG1uufx/dOobMZjrpmA/9TT
KQTYCSFarH3P5i1tcVFZRc1HtdL/9bp30wWYJFqRTdqU5D6h608a64mgf6DHbtr0
E5JJVbNHvHPYlbK52+pue0K33sap58gL0R0ZCZUeAPOszh0UomMVNJDTCHUhV+F1
m2im44TZOzjwD9NQ+J3g6V5TbYZnv1nXw9EQCDPjgWpwJCPg01r7GbEsbT/A/ka6
WxtDgjw/p8wENzIE++BHC11G5iHt7/tEbzNJJ9HGV85/ly4VpZM4TvHkmnaNLAOq
A0gtZpWAuO9NtPNFkZBFbdaUyfLXUhc9+wvK0dtM5+iC4k0XXs+A8I9DyPgsp5Q=
=n9Au
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160619/18d559d8/attachment.key>

From yvoinov at gmail.com  Sun Jun 19 18:10:45 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 20 Jun 2016 00:10:45 +0600
Subject: [squid-users] ECDSA and SSL bump
In-Reply-To: <99d9f583-fc4b-ed58-cfc6-4402d7fc8cd0@treenet.co.nz>
References: <6685dba5-afff-7691-14ef-1dbe20ff461c@gmail.com>
 <dfc8d75a-9ba7-e941-db11-e13005f752c4@treenet.co.nz>
 <336d5fb5-41ad-7497-e51d-634f6e347775@gmail.com>
 <99d9f583-fc4b-ed58-cfc6-4402d7fc8cd0@treenet.co.nz>
Message-ID: <0907928b-e813-801a-3974-1bbf97837335@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
ECDSA works with any combination with RSA in CA-subordinate CA's.

Will check compatibility issues, if any.

19.06.2016 17:40, Amos Jeffries ?????:
> On 19/06/2016 10:17 p.m., Yuri wrote:
>> Must be:
>>
>> openssl ecparam -name secp384r1 -genkey -param_enc named_curve -out
>> rootCA.key
>>
>> :)
>>
>> I.e. -param_enc can't be default, named_curve argument required :)
>>
>
> Aha.
>
> Is it working for you now? or do we still have to alter the cert
> generator part of Squid?
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXZuAlAAoJENNXIZxhPexGSjsH/0PsS7IoltVqln9d7rP0v6Ai
EwO+x/SSAgWCLEC0Hh3u8O22NrJIml12ZieQHRr4qZ+2EctKDCdw4cKpGR1EAk6L
YVf9kugZGm0kcMcc0bE5nhDbQQhBYNbZskkccl8rNUpAx1eSelcoqurA9fyJFcJg
g4yGGojZHvriNLMUD7b6lPyLv8hX5KH9xzsCR9uRnidoqJ4fBc6ub9f+ukGkuPTp
Oehb1vLJwNw2g2OBhWHMtwwzj0W+hH/4+oPi2vRhXfgRx3IVXvi6T+EQ6Ov8WKk1
NMDvo99q8cIQfH4kZDRKkxoHaSFy/Y5npp1tmqYIgXCLMtoqTUvqkyFxHyxbJNk=
=Mpkw
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/bb1b3d81/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/bb1b3d81/attachment.key>

From eliezer at ngtech.co.il  Mon Jun 20 09:03:14 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 20 Jun 2016 12:03:14 +0300
Subject: [squid-users] URL access based on AD group membership
In-Reply-To: <OF178A507A.21A17135-ON80257FD5.004D6739-80257FD5.004F24B2@tcs.com>
References: <OF178A507A.21A17135-ON80257FD5.004D6739-80257FD5.004F24B2@tcs.com>
Message-ID: <020c01d1cad2$93cacf20$bb606d60$@ngtech.co.il>

Hey Nilesh,

 

Did you tried to test it in any way outside of squid?

Like in a command line as a self running program?

 

Eliezer

 

----

Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Nilesh Gavali
Sent: Friday, June 17, 2016 5:25 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] URL access based on AD group membership

 

Team; 
Need expert help here, 
here is my set up - as of now squid integrated with Windows 2012R2 AD, SSO
with kerberos - working fine. 
Now I want to restrict Internet access for user based on their AD group
membership. I tried loads of options from various site but no luck. not sure
what is going wrong. 
here is my squid config, and cache.log o/p. 

============================= 
# 
# Recommended minimum configuration: 
# 

auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s
HTTP/proxy02.abcd.gov.in at ABCD.GOV.IN
<mailto:HTTP/proxy02.abcd.gov.in at ABCD.GOV.IN>  
auth_param negotiate children 10 
auth_param negotiate keep_alive on 
auth_param basic credentialsttl 2 hours 
acl ad_auth proxy_auth REQUIRED 

#AD Group membership 

external_acl_type AD_Group %LOGIN /usr/lib64/squid/squid_ldap_group -P -R -b
"DC=ABCD,DC=GOV,DC=IN" -D svcproxy -w 123456789 -f
"(&(objectclass=person)(userPrincipalName=%u)(memberof=cn=%g,ou=InternetAcce
ss,ou=Groups,dc=ABCD,dc=GOV,dc=IN))" -h abcd.gov.in -s sub -v 3 -d 

acl infrateam external AD_Group lgInternetAccess 
acl windowsupdate dstdomain "/etc/squid/sitelist/infra_update_site" 

acl manager proto cache_object 
acl localhost src 127.0.0.1/32 ::1 
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1 

# Example rule allowing access from your local networks. 
# Adapt to list your (internal) IP networks from where browsing 
# should be allowed 
acl localnet src 10.0.0.0/8        # RFC1918 possible internal network 
acl localnet src 172.16.0.0/12        # RFC1918 possible internal network 
acl localnet src 192.168.0.0/16        # RFC1918 possible internal network 
acl localnet src fc00::/7       # RFC 4193 local private network range 
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines 

acl SSL_ports port 443 
acl Safe_ports port 80                # http 
acl Safe_ports port 21                # ftp 
acl Safe_ports port 443                # https 
acl Safe_ports port 70                # gopher 
acl Safe_ports port 210                # wais 
acl Safe_ports port 1025-65535        # unregistered ports 
acl Safe_ports port 280                # http-mgmt 
acl Safe_ports port 488                # gss-http 
acl Safe_ports port 591                # filemaker 
acl Safe_ports port 777                # multiling http 
acl CONNECT method CONNECT 

# 
# Recommended minimum Access Permission configuration: 
# 
# Only allow cachemgr access from localhost 
http_access allow manager localhost 
http_access deny manager 

# Deny requests to certain unsafe ports 
http_access deny !Safe_ports 

# Deny CONNECT to other than secure SSL ports 
http_access deny CONNECT !SSL_ports 


# We strongly recommend the following be uncommented to protect innocent 
# web applications running on the proxy server who think the only 
# one who can access services on "localhost" is a local user 
#http_access deny to_localhost 

# 
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS 
# 
# 
# Example rule allowing access from your local networks. 
# Adapt localnet in the ACL section to list your (internal) IP networks 
# from where browsing should be allowed 

http_access deny infrateam windowsupdate 
http_access allow ad_auth 

# And finally deny all other access to this proxy 
http_access deny all 

# Squid normally listens to port 3128 
http_port 8080 
never_direct allow all 

cache_peer xx.xx.2.108 parent 8080 0 default 
#dns_nameservers DNSSVR.abcd.gov.in 
dns_nameservers XX.XX.2.108 

# We recommend you to use at least the following line. 
#hierarchy_stoplist cgi-bin ? 

# Uncomment and adjust the following to add a disk cache directory. 
cache_dir ufs /var/spool/squid 2048 16 256 

# Leave coredumps in the first cache dir 
coredump_dir /var/spool/squid 

# Log forwarding to SysLog 
access_log syslog:local1.info 

# Add any of your own refresh_pattern entries above these. 
refresh_pattern ^ftp:                1440        20%        10080 
refresh_pattern ^gopher:        1440        0%        1440 
refresh_pattern -i (/cgi-bin/|\?) 0        0%        0 
refresh_pattern .                0        20%        4320 
====================================== 
cache.log o/p- 
Connected OK 
group filter
'(&(objectclass=person)(userPrincipalName=da.853438 at ABCD.GOV.IN)(memberof=cn
=lgInternetAccess,ou=InternetAccess,ou=Groups,dc=abcd,dc=gov,dc=in))
<mailto:userPrincipalName=da.853438 at ABCD.GOV.IN)(memberof=cn=lgInternetAcces
s,ou=InternetAccess,ou=Groups,dc=abcd,dc=gov,dc=in))> ', searchbase
'DC=ABCD,DC=GOV,DC=IN' 
====================================== 


Thanks & Regards
Nilesh Suresh Gavali

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/7d729cdc/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11297 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/7d729cdc/attachment.png>

From nilesh.gavali at tcs.com  Mon Jun 20 09:21:47 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Mon, 20 Jun 2016 10:21:47 +0100
Subject: [squid-users] URL access based on AD group membership
In-Reply-To: <020c01d1cad2$93cacf20$bb606d60$@ngtech.co.il>
References: <OF178A507A.21A17135-ON80257FD5.004D6739-80257FD5.004F24B2@tcs.com>
 <020c01d1cad2$93cacf20$bb606d60$@ngtech.co.il>
Message-ID: <OF330029D6.D7F5BA76-ON80257FD8.0032EF64-80257FD8.00336D20@tcs.com>

Thanks Eliezer for reply.
Its is working now for be perfectly with below command with -d option 
gives helpful debug info to troubleshoot.

external_acl_type AD_Group %LOGIN /usr/lib64/squid/squid_ldap_group -P -R 
-b "DC=ABCD,DC=GOV,DC=IN" -D svcproxy -w 123456789 -f 
"(&(objectclass=person)(userPrincipalName=%v)(memberof=cn=%a,ou=InternetAccess,ou=Groups,dc=ABCD,dc=GOV,dc=IN))" 
-h abcd.gov.in -s sub -v 3 -d

Currently I have configure squid with AD kerberos auth. also url access 
restricted based on  AD group membership.

Now I observed, is that when I add any user to one of the AD group which 
allowed in squid.  it is not accepting the changes until I restart the 
squid service.
Is this the way squid behave or do I need to follow different procedure. 
So as user added to AD group it will recognised by squid on the fly 
without restarting squid service.


Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.   IT Services
                        Business Solutions
                        Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 
 Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627




From:   Eliezer Croitoru <eliezer at ngtech.co.il>
To:     'Nilesh Gavali' <nilesh.gavali at tcs.com>
Cc:     squid-users at lists.squid-cache.org
Date:   20/06/2016 10:06
Subject:        RE: [squid-users] URL access based on AD group membership



Hey Nilesh,
 
Did you tried to test it in any way outside of squid?
Like in a command line as a self running program?
 
Eliezer
 
----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il

 
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On 
Behalf Of Nilesh Gavali
Sent: Friday, June 17, 2016 5:25 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] URL access based on AD group membership
 
Team; 
Need expert help here, 
here is my set up - as of now squid integrated with Windows 2012R2 AD, SSO 
with kerberos - working fine. 
Now I want to restrict Internet access for user based on their AD group 
membership. I tried loads of options from various site but no luck. not 
sure what is going wrong. 
here is my squid config, and cache.log o/p. 

============================= 
# 
# Recommended minimum configuration: 
# 

auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
HTTP/proxy02.abcd.gov.in at ABCD.GOV.IN 
auth_param negotiate children 10 
auth_param negotiate keep_alive on 
auth_param basic credentialsttl 2 hours 
acl ad_auth proxy_auth REQUIRED 

#AD Group membership 

external_acl_type AD_Group %LOGIN /usr/lib64/squid/squid_ldap_group -P -R 
-b "DC=ABCD,DC=GOV,DC=IN" -D svcproxy -w 123456789 -f 
"(&(objectclass=person)(userPrincipalName=%u)(memberof=cn=%g,ou=InternetAccess,ou=Groups,dc=ABCD,dc=GOV,dc=IN))" 
-h abcd.gov.in -s sub -v 3 -d 

acl infrateam external AD_Group lgInternetAccess 
acl windowsupdate dstdomain "/etc/squid/sitelist/infra_update_site" 

acl manager proto cache_object 
acl localhost src 127.0.0.1/32 ::1 
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1 

# Example rule allowing access from your local networks. 
# Adapt to list your (internal) IP networks from where browsing 
# should be allowed 
acl localnet src 10.0.0.0/8        # RFC1918 possible internal network 
acl localnet src 172.16.0.0/12        # RFC1918 possible internal network 
acl localnet src 192.168.0.0/16        # RFC1918 possible internal network 

acl localnet src fc00::/7       # RFC 4193 local private network range 
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines 

acl SSL_ports port 443 
acl Safe_ports port 80                # http 
acl Safe_ports port 21                # ftp 
acl Safe_ports port 443                # https 
acl Safe_ports port 70                # gopher 
acl Safe_ports port 210                # wais 
acl Safe_ports port 1025-65535        # unregistered ports 
acl Safe_ports port 280                # http-mgmt 
acl Safe_ports port 488                # gss-http 
acl Safe_ports port 591                # filemaker 
acl Safe_ports port 777                # multiling http 
acl CONNECT method CONNECT 

# 
# Recommended minimum Access Permission configuration: 
# 
# Only allow cachemgr access from localhost 
http_access allow manager localhost 
http_access deny manager 

# Deny requests to certain unsafe ports 
http_access deny !Safe_ports 

# Deny CONNECT to other than secure SSL ports 
http_access deny CONNECT !SSL_ports 


# We strongly recommend the following be uncommented to protect innocent 
# web applications running on the proxy server who think the only 
# one who can access services on "localhost" is a local user 
#http_access deny to_localhost 

# 
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS 
# 
# 
# Example rule allowing access from your local networks. 
# Adapt localnet in the ACL section to list your (internal) IP networks 
# from where browsing should be allowed 

http_access deny infrateam windowsupdate 
http_access allow ad_auth 

# And finally deny all other access to this proxy 
http_access deny all 

# Squid normally listens to port 3128 
http_port 8080 
never_direct allow all 

cache_peer xx.xx.2.108 parent 8080 0 default 
#dns_nameservers DNSSVR.abcd.gov.in 
dns_nameservers XX.XX.2.108 

# We recommend you to use at least the following line. 
#hierarchy_stoplist cgi-bin ? 

# Uncomment and adjust the following to add a disk cache directory. 
cache_dir ufs /var/spool/squid 2048 16 256 

# Leave coredumps in the first cache dir 
coredump_dir /var/spool/squid 

# Log forwarding to SysLog 
access_log syslog:local1.info 

# Add any of your own refresh_pattern entries above these. 
refresh_pattern ^ftp:                1440        20%        10080 
refresh_pattern ^gopher:        1440        0%        1440 
refresh_pattern -i (/cgi-bin/|\?) 0        0%        0 
refresh_pattern .                0        20%        4320 
====================================== 
cache.log o/p- 
Connected OK 
group filter '(&(objectclass=person)(
userPrincipalName=da.853438 at ABCD.GOV.IN)(memberof=cn=lgInternetAccess,ou=InternetAccess,ou=Groups,dc=abcd,dc=gov,dc=in))
', searchbase 'DC=ABCD,DC=GOV,DC=IN' 
====================================== 


Thanks & Regards
Nilesh Suresh Gavali
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/f5f1dadc/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/png
Size: 11297 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/f5f1dadc/attachment.png>

From jaap.dam at gmail.com  Mon Jun 20 09:43:27 2016
From: jaap.dam at gmail.com (Jaap Dam)
Date: Mon, 20 Jun 2016 11:43:27 +0200
Subject: [squid-users] Queue incoming requests when fetching from origin
In-Reply-To: <004d01d1c9e9$c45988a0$4d0c99e0$@ngtech.co.il>
References: <CAD0U=K13wKi4hytPvyBqUjdr+Thn90=R-RjE67ZG6ovE8QKo7w@mail.gmail.com>
 <acc6da17-b5eb-5a37-2ec2-80b0ae4a7fa6@treenet.co.nz>
 <CAD0U=K1FYLNXWMn595RJD33DpetGhLU=qNz4QmqMwWdEpOFo8g@mail.gmail.com>
 <57617218.5050802@measurement-factory.com>
 <CAD0U=K2keq+foJQjbbq2Tunfp4t=z3rMfh3g1fsszqFu44oVYQ@mail.gmail.com>
 <5762C3D5.3070000@measurement-factory.com>
 <CAD0U=K3uX4aFEzhfSmEk0jmzuvBLdJsF9xZ_ozuJFMC-Dq7qTg@mail.gmail.com>
 <57641582.8010001@measurement-factory.com>
 <004d01d1c9e9$c45988a0$4d0c99e0$@ngtech.co.il>
Message-ID: <CAD0U=K1m-K_ascpj0=pQZgrWEG19-_9s0RPXKpye-zgiTXcVFA@mail.gmail.com>

Hi Eliezer,

Yes, Jaap is my first name :)
I might have not mentioned this before, but I'm using Squid as a reverse
proxy / in acceleration mode. So as far as I know your comments are not
applicable. Thanks for your thoughts though!

Jaap

2016-06-19 7:16 GMT+02:00 Eliezer Croitoru <eliezer at ngtech.co.il>:

> Hey Jaap, (not sure if it's the first name)
>
> The issue is that there are consequences for cached objects not being
> revalidated.
> Also if there are sites which needs to be targeted it would be a different
> story.
> Some might not understand the difference between a cache and an archive or
> want it to act as one.
> A cache is meant to be temporary while archive should last longer.
> One example is Windows Updates which might needs to be archived since it's
> always needed.
>
> If you have a specific targeted site, let me know and I will try to see if
> something can be done.
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Alex Rousskov
> Sent: Friday, June 17, 2016 6:22 PM
> To: Jaap Dam
> Cc: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Queue incoming requests when fetching from
> origin
>
> On 06/17/2016 05:33 AM, Jaap Dam wrote:
>
> > From what I
> > understand, re-validation is useful when done with If-Modified-Since
> > or If-None-Match.
>
> To revalidate stale objects, Squid uses conditional requests. That is not
> the only way to revalidate, but that is what Squid does.
>
>
> > However my responses do not provide the E-Tag header nor the
> > Last-Modified header.
>
> IIRC, the If-Modified-Since field in a conditional request may use the
> response Date header when Last-Modified is not available. If the origin
> server supports checking resource modification times (without disclosing
> them in responses for some reason), revalidation would still work as
> intended.
>
>
> > Is it possible for Squid to never revalidate but always to assume
> > 'pure cache-miss' when a resource is stale?
>
> I am not sure. Others may be able to answer this question authoritatively.
> If you force me to guess, I would say "no".
>
> Alex.
>
>
>
> > 2016-06-16 17:20 GMT+02:00 Alex Rousskov
> > <rousskov at measurement-factory.com
> > <mailto:rousskov at measurement-factory.com>>:
> >
> >     On 06/16/2016 01:45 AM, Jaap Dam wrote:
> >
> >     > Thanks for the information. Could you elaborate on when collapsed
> >     > forwarding does apply?
> >
> >     Squid is currently able to collapse HTTP client [miss] requests (but
> not
> >     internally generated HTTP requests triggered by HTTP client
> requests).
> >     Furthermore, to be collapsable, the request must have no markings
> that
> >     make the future response uncachable.
> >
> >
> >     > With your extra information, my assumption would
> >     > be that it only applies on requests of a resource that has never
> been
> >     > cached before.
> >
> >     I would not phrase it like that because Squid does not remember was
> has
> >     been cached before, only what is still cached at the query time.
> There
> >     are three primary cases for an HTTP client request to consider here:
> >
> >     * pure cache hit: Collapsing is inapplicable because Squid does not
> send
> >     any requests (there is nothing to collapse). Each HTTP client
> request is
> >     satisfied from the Squid cache.
> >
> >     * pure cache miss: Multiple requests for the same missing object can
> be
> >     collapsed if collapsed_forwarding is enabled. Collapsable requests
> have
> >     no markings that make the future response uncachable.
> >
> >     * revalidation: The requested object was found in the cache but it
> was
> >     stale. Squid sends an internal "revalidation" request to the origin
> >     server or peer. These internal requests are currently not collapsed.
> We
> >     are working on collapsing them as well.
> >
> >
> >     > Secondly would you have a suggestion for solving the issue I'm
> facing?
> >
> >
> >     I have not studied the issue you are facing, but if you think
> collapsing
> >     revalidation requests would solve your problem, then either wait for
> us
> >     to finish initial collapsed revalidation support (and then see if it
> >     solves your problem) or co-sponsor that ongoing development (to make
> >     sure it solves your problem).
> >
> >
> >     HTH,
> >
> >     Alex.
> >
> >
> >
> >     > 2016-06-15 17:19 GMT+02:00 Alex Rousskov:
> >     >
> >     >     On 06/14/2016 02:51 AM, Jaap Dam wrote:
> >     >
> >     >     > I've part of the logging as an attachment. I'm requesting a
> >     single URL
> >     >     > in this log. The log starts with a stale cache of the item.
> >     >
> >     >     Collapsed forwarding does not apply to cache revalidation
> >     requests yet.
> >     >     Factory is working on implementing collapsed revalidations (in
> >     some
> >     >     environments), but I cannot promise a specific delivery date
> >     or that
> >     >     your particular environment will be covered.
> >     >
> >     >     Alex.
> >     >
> >     >
> >     >
> >     >
> >     >     > 2016-06-13 15:34 GMT+02:00 Amos Jeffries:
> >     >     >
> >     >     >     On 14/06/2016 12:29 a.m., Jaap Dam wrote:
> >     >     >     > Is the collapsed_forwarding directive the correct one
> >     to use
> >     >     for my
> >     >     >     > use-case or am i missing something?
> >     >     >
> >     >     >     Yes it is correct so far as I am understanding your need.
> >     >     >
> >     >     >     For further debugging about what is going on you will
> >     need the
> >     >     HTTP
> >     >     >     messages involved. Add the directive "debug_options 11,2
> >     20,3"
> >     >     to your
> >     >     >     config to get them logged in cache.log.
> >     >
> >     >
> >
> >
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/9094556e/attachment.htm>

From yvoinov at gmail.com  Mon Jun 20 11:19:59 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 20 Jun 2016 17:19:59 +0600
Subject: [squid-users] ECDSA and SSL bump
In-Reply-To: <0907928b-e813-801a-3974-1bbf97837335@gmail.com>
References: <6685dba5-afff-7691-14ef-1dbe20ff461c@gmail.com>
 <dfc8d75a-9ba7-e941-db11-e13005f752c4@treenet.co.nz>
 <336d5fb5-41ad-7497-e51d-634f6e347775@gmail.com>
 <99d9f583-fc4b-ed58-cfc6-4402d7fc8cd0@treenet.co.nz>
 <0907928b-e813-801a-3974-1bbf97837335@gmail.com>
Message-ID: <1b3f8d61-f133-4e06-068c-53467951bcce@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
akamaihd.net has compatibility issues with ECDSA squid's certs. fb.com
behind it, etc.

20.06.2016 0:10, Yuri Voinov ?????:
>
> ECDSA works with any combination with RSA in CA-subordinate CA's.
>
> Will check compatibility issues, if any.
>
> 19.06.2016 17:40, Amos Jeffries ?????:
> > On 19/06/2016 10:17 p.m., Yuri
>       wrote:
>
>       >> Must be:
>
>       >>
>
>       >> openssl ecparam -name secp384r1 -genkey -param_enc
>       named_curve -out
>
>       >> rootCA.key
>
>       >>
>
>       >> :)
>
>       >>
>
>       >> I.e. -param_enc can't be default, named_curve argument
>       required :)
>
>       >>
>
>
>
>       > Aha.
>
>
>
>       > Is it working for you now? or do we still have to alter the
>       cert
>
>       > generator part of Squid?
>
>
>
>       > Amos
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXZ9FfAAoJENNXIZxhPexGFXEH/07BOBYDsUwvtm+fTw9nwaH4
XlB4smmYVK+f2xW+HN6IQolnF5ro6gWUkJTxwc6me/Hb2FkNFPWplvxo4ozmmLcz
D6sRAKf+EQoF4o7Zev1WRLu54mg0kIb5QbSYyr97u5exai2a7xPN8d9vZqhzFUox
5lmlIs07PKI4HsjGjYg1/C5kVJdc8znA6OUrmtgqnOwpCPkInz8mY9xqrrxMfjmT
bX0EMbxwSiofekcKjN0LB98jY4ZRyo4qjEawea1gjuWPdiuuK8jVXEWnybdb7igt
KqeR3/ikh/sb4Pxc/nohaSF34JDwkGKg4G8f7KPFTVi28FonsIDSaIwGNEeDClQ=
=1vWI
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/78837255/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/78837255/attachment.key>

From yvoinov at gmail.com  Mon Jun 20 11:30:52 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 20 Jun 2016 17:30:52 +0600
Subject: [squid-users] ECDSA and SSL bump
In-Reply-To: <1b3f8d61-f133-4e06-068c-53467951bcce@gmail.com>
References: <6685dba5-afff-7691-14ef-1dbe20ff461c@gmail.com>
 <dfc8d75a-9ba7-e941-db11-e13005f752c4@treenet.co.nz>
 <336d5fb5-41ad-7497-e51d-634f6e347775@gmail.com>
 <99d9f583-fc4b-ed58-cfc6-4402d7fc8cd0@treenet.co.nz>
 <0907928b-e813-801a-3974-1bbf97837335@gmail.com>
 <1b3f8d61-f133-4e06-068c-53467951bcce@gmail.com>
Message-ID: <97751bf2-555d-8f69-a01d-b446d90fb11e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Windows Updates is also incompatible with ECDSA due to akamai behind. :)

20.06.2016 17:19, Yuri Voinov ?????:
>
> akamaihd.net has compatibility issues with ECDSA squid's certs. fb.com
behind it, etc.
>
> 20.06.2016 0:10, Yuri Voinov ?????:
>
>
>       > ECDSA works with any combination with RSA in CA-subordinate
>       CA's.
>
>
>
>       > Will check compatibility issues, if any.
>
>
>
>       > 19.06.2016 17:40, Amos Jeffries ?????:
>
>       > > On 19/06/2016 10:17 p.m., Yuri
>
>       >       wrote:
>
>
>
>       >       >> Must be:
>
>
>
>       >       >>
>
>
>
>       >       >> openssl ecparam -name secp384r1 -genkey
>       -param_enc
>
>       >       named_curve -out
>
>
>
>       >       >> rootCA.key
>
>
>
>       >       >>
>
>
>
>       >       >> :)
>
>
>
>       >       >>
>
>
>
>       >       >> I.e. -param_enc can't be default, named_curve
>       argument
>
>       >       required :)
>
>
>
>       >       >>
>
>
>
>
>
>
>
>       >       > Aha.
>
>
>
>
>
>
>
>       >       > Is it working for you now? or do we still have to
>       alter the
>
>       >       cert
>
>
>
>       >       > generator part of Squid?
>
>
>
>
>
>
>
>       >       > Amos
>
>
>
>
>
>
>
>       >       > _______________________________________________
>
>
>
>       >       > squid-users mailing list
>
>
>
>       >       > squid-users at lists.squid-cache.org
>
>
>
>       >       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXZ9PrAAoJENNXIZxhPexGUM0H/0Fwzs4XrryZ2LahnO4OZ2e7
DzWcXLtyNNkzOj3oKeOWvijjTuTH4F4nTIot5yiZqifngY1NHXbh1RkePYEy57YP
31lgJOBqm9pwHDMKdBwDRz28Ln03HzRimirrhNhJLEXRbdMXZHn4No+qXkfQHjI2
IoXcwM/ITVLgQ8cAW03SFLgUJwdVlbVjNq3vl0o0ZmJZ0MzYJ2/OlkuvNweNJXmQ
YTFWAUrNLXr9T0RYmWjoTH6JDHUQz83F6n7/ceuWkTwoRZ0hhlFzGCqCSHLD9V+B
P2C0d5a7ccBdNlJOMK3FQ1jOuuBTI999fX2HfQWy5Qtojm0V2y4izWrU5f+CQLg=
=VnZ2
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/c7d3fb62/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/c7d3fb62/attachment.key>

From squid3 at treenet.co.nz  Mon Jun 20 11:33:16 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 20 Jun 2016 23:33:16 +1200
Subject: [squid-users] URL access based on AD group membership
In-Reply-To: <OF330029D6.D7F5BA76-ON80257FD8.0032EF64-80257FD8.00336D20@tcs.com>
References: <OF178A507A.21A17135-ON80257FD5.004D6739-80257FD5.004F24B2@tcs.com>
 <020c01d1cad2$93cacf20$bb606d60$@ngtech.co.il>
 <OF330029D6.D7F5BA76-ON80257FD8.0032EF64-80257FD8.00336D20@tcs.com>
Message-ID: <48aa76c1-4499-444e-1837-8e1ce7685296@treenet.co.nz>

On 20/06/2016 9:21 p.m., Nilesh Gavali wrote:
> Thanks Eliezer for reply.
> Its is working now for be perfectly with below command with -d option 
> gives helpful debug info to troubleshoot.
> 
> external_acl_type AD_Group %LOGIN /usr/lib64/squid/squid_ldap_group -P -R 
> -b "DC=ABCD,DC=GOV,DC=IN" -D svcproxy -w 123456789 -f 
> "(&(objectclass=person)(userPrincipalName=%v)(memberof=cn=%a,ou=InternetAccess,ou=Groups,dc=ABCD,dc=GOV,dc=IN))" 
> -h abcd.gov.in -s sub -v 3 -d
> 
> Currently I have configure squid with AD kerberos auth. also url access 
> restricted based on  AD group membership.
> 
> Now I observed, is that when I add any user to one of the AD group which 
> allowed in squid.  it is not accepting the changes until I restart the 
> squid service.

Your external_acl_type has a 1 hour response cache. Meaning it will take
a minimum of 1 hour for any changes to the AD group settings to be
passed on to Squid.


> 
> auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
> HTTP/proxy02.abcd.gov.in at ABCD.GOV.IN 
> auth_param negotiate children 10 
> auth_param negotiate keep_alive on 
> auth_param basic credentialsttl 2 hours 

NP: settings for Basic authentication do not have any affect on
non-Basic types of authentication.

There is no TTL for Kerberos user credentials. They are valid for as
long as the TCP connection to the proxy is open. Any change in the
Kerberos security tokens sent by the client after authentication is
completed will terminate/close the TCP connection.


> 
> external_acl_type AD_Group %LOGIN /usr/lib64/squid/squid_ldap_group -P -R 
> -b "DC=ABCD,DC=GOV,DC=IN" -D svcproxy -w 123456789 -f 
> "(&(objectclass=person)(userPrincipalName=%u)(memberof=cn=%g,ou=InternetAccess,ou=Groups,dc=ABCD,dc=GOV,dc=IN))" 
> -h abcd.gov.in -s sub -v 3 -d 
> 

Since your helper names were outdated 6 years ago I assume you are using
Squid-3.1 or older:
<http://www.squid-cache.org/Versions/v3/3.1/cfgman/external_acl_type.html>

Note the default values for ttl= , negative_ttl=, and grace=

Amos



From gjobin at vmware.com  Mon Jun 20 14:02:01 2016
From: gjobin at vmware.com (Jobin George)
Date: Mon, 20 Jun 2016 14:02:01 +0000
Subject: [squid-users] Configuring squid to work as an HTTPS proxy
Message-ID: <SN2PR05MB2638027BA76D0900CDF93061A82A0@SN2PR05MB2638.namprd05.prod.outlook.com>

Hi,

I am trying to setup squid3 as an HTTPS proxy using the tutorial given [here][1]. I have properly setup the proxy settings in my browser and when I try to hit **HTTP** web sites, I am able to connect successfully. However, I keep getting a "Connection timed out error" whenever I hit an **HTTPS** protocol web site and the following error in my `/var/log/squid3/cache.log`:

    2016/06/20 19:12:47|  NF getsockopt(SO_ORIGINAL_DST) failed on local=<local_ip_address>:3129 remote=<remote_ip_address>:55209 FD 8 flags=33: (92) Protocol not available

Here is my /etc/squid3/squid.conf file (commented lines removed for brevity):

--------------------------------------------------------------------------------------------------------------------------------------------------------------

    auth_param basic program /usr/lib/squid3/basic_ncsa_auth /usr/etc/passwd
    auth_param basic casesensitive off
    auth_param basic credentialsttl 2 hours

    acl user_auth proxy_auth REQUIRED

    http_access allow user_auth

    acl SSL_ports port 443
    acl Safe_ports port 80          # http
    acl Safe_ports port 21          # ftp
    acl Safe_ports port 443         # https
    acl Safe_ports port 70          # gopher
    acl Safe_ports port 210         # wais
    acl Safe_ports port 1025-65535  # unregistered ports
    acl Safe_ports port 280         # http-mgmt
    acl Safe_ports port 488         # gss-http
    acl Safe_ports port 591         # filemaker
    acl Safe_ports port 777         # multiling http
    acl CONNECT method CONNECT

    http_access allow localhost
    http_access allow all
    http_port 3127

    https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB key=/etc/squid3/example.com.private cert=/etc/squid3/example.com.cert

    ssl_bump server-first all
    sslproxy_flags DONT_VERIFY_PEER
    sslproxy_cert_error deny all
    sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/lib/ssl_db -M 4MB sslcrtd_children 8 startup=1 idle=1
    coredump_dir /var/spool/squid3

    refresh_pattern ^ftp:           1440    20%     10080
    refresh_pattern ^gopher:        1440    0%      1440
    refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
    refresh_pattern (Release|Packages(.gz)*)$      0       20%     2880
    refresh_pattern .               0       20%     4320

    always_direct allow all

--------------------------------------------------------------------------------------------------------------------------------------------------------------


I have spent a lot of time googling this error but could not arrive at a solution which would configure squid as an HTTP proxy. How do I get this working?


[1]: https://smoothnet.org/squid-proxy-with-ssl-bump/

Thanks & Regards
Jobin

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/09ccc710/attachment.htm>

From yvoinov at gmail.com  Mon Jun 20 14:41:53 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 20 Jun 2016 20:41:53 +0600
Subject: [squid-users] Configuring squid to work as an HTTPS proxy
In-Reply-To: <SN2PR05MB2638027BA76D0900CDF93061A82A0@SN2PR05MB2638.namprd05.prod.outlook.com>
References: <SN2PR05MB2638027BA76D0900CDF93061A82A0@SN2PR05MB2638.namprd05.prod.outlook.com>
Message-ID: <9940fda8-e7bc-5a4a-59b6-8f778fbea1fb@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
You using wrong and extremal unspecific manual.

Feel free to use our good manuals:

http://wiki.squid-cache.org/ConfigExamples


20.06.2016 20:02, Jobin George ?????:
>
> Hi,
>
> 
>
> I am trying to setup squid3 as an HTTPS proxy using the tutorial given
[here][1]. I have properly setup the proxy settings in my browser and
when I try to hit **HTTP** web sites, I am able to connect successfully.
However, I keep getting a "Connection timed out error" whenever I hit an
**HTTPS** protocol web site and the following error in my
`/var/log/squid3/cache.log`:
>
> 
>
>     2016/06/20 19:12:47|  NF getsockopt(SO_ORIGINAL_DST) failed on
local=<local_ip_address>:3129 remote=<remote_ip_address>:55209 FD 8
flags=33: (92) Protocol not available
>
> 
>
> Here is my /etc/squid3/squid.conf file (commented lines removed for
brevity):
>
> 
>
>
--------------------------------------------------------------------------------------------------------------------------------------------------------------
>
> 
>
>     auth_param basic program /usr/lib/squid3/basic_ncsa_auth
/usr/etc/passwd
>
>     auth_param basic casesensitive off
>
>     auth_param basic credentialsttl 2 hours
>
> 
>
>     acl user_auth proxy_auth REQUIRED
>
> 
>
>     http_access allow user_auth
>
> 
>
>     acl SSL_ports port 443
>
>     acl Safe_ports port 80          # http
>
>     acl Safe_ports port 21          # ftp
>
>     acl Safe_ports port 443         # https
>
>     acl Safe_ports port 70          # gopher
>
>     acl Safe_ports port 210         # wais
>
>     acl Safe_ports port 1025-65535  # unregistered ports
>
>     acl Safe_ports port 280         # http-mgmt
>
>     acl Safe_ports port 488         # gss-http
>
>     acl Safe_ports port 591         # filemaker
>
>     acl Safe_ports port 777         # multiling http
>
>     acl CONNECT method CONNECT
>
> 
>
>     http_access allow localhost
>
>     http_access allow all
>
>     http_port 3127
>
> 
>
>     https_port 3129 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB key=/etc/squid3/example.com.private
cert=/etc/squid3/example.com.cert
>
> 
>
>     ssl_bump server-first all
>
>     sslproxy_flags DONT_VERIFY_PEER
>
>     sslproxy_cert_error deny all
>
>     sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/lib/ssl_db -M 4MB
sslcrtd_children 8 startup=1 idle=1
>
>     coredump_dir /var/spool/squid3
>
> 
>
>     refresh_pattern ^ftp:           1440    20%     10080
>
>     refresh_pattern ^gopher:        1440    0%      1440
>
>     refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
>
>     refresh_pattern (Release|Packages(.gz)*)$      0       20%     2880
>
>     refresh_pattern .               0       20%     4320
>
> 
>
>     always_direct allow all
>
>           
>
>
--------------------------------------------------------------------------------------------------------------------------------------------------------------
>
> 
>
> 
>
> I have spent a lot of time googling this error but could not arrive at
a solution which would configure squid as an HTTP proxy. How do I get
this working?
>
> 
>
> 
>
> [1]: https://smoothnet.org/squid-proxy-with-ssl-bump/
>
> 
>
> Thanks & Regards
>
> Jobin
>
> 
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEbBAEBCAAGBQJXaACxAAoJENNXIZxhPexGb7gH+Iq3mOmeCH6memj7NKb2Yazo
I1PfzpjOi5/sh0gGfGEw2KG0nknT7Y4G7G6V6QxLH00PSlauUZ9syzsYmdWiImvA
o0Q8Aw5xyMUjhxVvVjl/ExJZdhUj86m+kruav6osArPdJGaLOpXiyhhvNef3zD0A
3d2D1xJhZP/JLYQUzDxssLxuphPxv8rx44e9H2MpoRN7llLFOEzURInVHwUNPrOE
keY8fYjHYb2DKlvkI9fkkLj75j4tdQYmwQo+wiIbXIUOyejfIJKYR3DSR5zzXMxX
nLq1LiJ1cZt/exNUwQ/hpEdByfKC/J9NoCPn++9VRCBWHenoSDPrs90k3SQ4CQ==
=zzoL
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/41022c25/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/41022c25/attachment.key>

From bruno.larini at riosoft.com.br  Mon Jun 20 14:58:37 2016
From: bruno.larini at riosoft.com.br (Bruno de Paula Larini)
Date: Mon, 20 Jun 2016 11:58:37 -0300
Subject: [squid-users] Configuring squid to work as an HTTPS proxy
In-Reply-To: <SN2PR05MB2638027BA76D0900CDF93061A82A0@SN2PR05MB2638.namprd05.prod.outlook.com>
References: <SN2PR05MB2638027BA76D0900CDF93061A82A0@SN2PR05MB2638.namprd05.prod.outlook.com>
Message-ID: <9a2bd25f-c4d7-d8e8-fe63-1ef09cbf81e6@riosoft.com.br>

Em 20/06/2016 11:02, Jobin George escreveu:
>
> Hi,
>
> I am trying to setup squid3 as an HTTPS proxy using the tutorial given 
> [here][1]. I have properly setup the proxy settings in my browser and 
> when I try to hit **HTTP** web sites, I am able to connect 
> successfully. However, I keep getting a "Connection timed out error" 
> whenever I hit an **HTTPS** protocol web site and the following error 
> in my `/var/log/squid3/cache.log`:
>
>     2016/06/20 19:12:47|  NF getsockopt(SO_ORIGINAL_DST) failed on 
> local=<local_ip_address>:3129 remote=<remote_ip_address>:55209 FD 8 
> flags=33: (92) Protocol not available
>
Hi Jobin,
For the intercepted mode, the following example worked for me:

http://lists.squid-cache.org/pipermail/squid-users/2015-June/004471.html

Bruno
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/c0d9afae/attachment.htm>

From squid3 at treenet.co.nz  Mon Jun 20 15:34:02 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 21 Jun 2016 03:34:02 +1200
Subject: [squid-users] Configuring squid to work as an HTTPS proxy
In-Reply-To: <SN2PR05MB2638027BA76D0900CDF93061A82A0@SN2PR05MB2638.namprd05.prod.outlook.com>
References: <SN2PR05MB2638027BA76D0900CDF93061A82A0@SN2PR05MB2638.namprd05.prod.outlook.com>
Message-ID: <ae444d20-6e31-f328-5155-a6b1b256aa58@treenet.co.nz>

On 21/06/2016 2:02 a.m., Jobin George wrote:
> Hi,
> 
> I am trying to setup squid3 as an HTTPS proxy using the tutorial given [here][1]. I have properly setup the proxy settings in my browser and when I try to hit **HTTP** web sites, I am able to connect successfully. However, I keep getting a "Connection timed out error" whenever I hit an **HTTPS** protocol web site and the following error in my `/var/log/squid3/cache.log`:
> 
>     2016/06/20 19:12:47|  NF getsockopt(SO_ORIGINAL_DST) failed on local=<local_ip_address>:3129 remote=<remote_ip_address>:55209 FD 8 flags=33: (92) Protocol not available
> 

This error is about misconfigured NAT.

For interception proxy you MUST do the NAT on the same machine Squid is
running. *route* the packets to that machine, do not NAT or "port
forward" them.

<http://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect>


> Here is my /etc/squid3/squid.conf file (commented lines removed for brevity):
> 
> --------------------------------------------------------------------------------------------------------------------------------------------------------------
> 
>     auth_param basic program /usr/lib/squid3/basic_ncsa_auth /usr/etc/passwd
>     auth_param basic casesensitive off
>     auth_param basic credentialsttl 2 hours
> 
>     acl user_auth proxy_auth REQUIRED
> 
>     http_access allow user_auth
> 

Authentication and interception are mutually exclusive features.


> 
>     http_access allow localhost
>     http_access allow all

What is the point of authenticating if clients that passed garbage
credentials and failed authentication are allowed to use the proxy anyway?


>     http_port 3127

If your browser is configured to use Squid as its HTTP proxy then the
traffic will be going in through this port. Which has no ssl-bump
options telling Squid to bump the HTTPS CONNECT messages.


> 
>     https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB key=/etc/squid3/example.com.private cert=/etc/squid3/example.com.cert
> 
>     ssl_bump server-first all
>     sslproxy_flags DONT_VERIFY_PEER

Remove the "DONT_VERIFY_PEER".


>     sslproxy_cert_error deny all

That is the default setting for cert error handling. Remove the above line.


> 
>     always_direct allow all
> 

That has not been needed with bumping since Squid-3.1. Remove the above.

Amos



From nilesh.gavali at tcs.com  Mon Jun 20 17:57:53 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Mon, 20 Jun 2016 18:57:53 +0100
Subject: [squid-users] URL access based on AD group membership
Message-ID: <OF27286CFD.D33D8806-ON80257FD8.00628011-80257FD8.0062AD0A@tcs.com>

Hello Amos;
is there a simpler way to tackle this as I am not linux guy and not sure 
howto write any helper program which need to call.


Regards;
Nilesh Gavali



> Thanks Eliezer for reply.
> Its is working now for be perfectly with below command with -d option 
> gives helpful debug info to troubleshoot.
> 
> external_acl_type AD_Group %LOGIN /usr/lib64/squid/squid_ldap_group -P 
-R 
> -b "DC=ABCD,DC=GOV,DC=IN" -D svcproxy -w 123456789 -f 
> 
"(&(objectclass=person)(userPrincipalName=%v)(memberof=cn=%a,ou=InternetAccess,ou=Groups,dc=ABCD,dc=GOV,dc=IN))" 

> -h abcd.gov.in -s sub -v 3 -d
> 
> Currently I have configure squid with AD kerberos auth. also url access 
> restricted based on  AD group membership.
> 
> Now I observed, is that when I add any user to one of the AD group which 

> allowed in squid.  it is not accepting the changes until I restart the 
> squid service.

Your external_acl_type has a 1 hour response cache. Meaning it will take
a minimum of 1 hour for any changes to the AD group settings to be
passed on to Squid.


> 
> auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
> HTTP/proxy02.abcd.gov.in at ABCD.GOV.IN 
> auth_param negotiate children 10 
> auth_param negotiate keep_alive on 
> auth_param basic credentialsttl 2 hours 

NP: settings for Basic authentication do not have any affect on
non-Basic types of authentication.

There is no TTL for Kerberos user credentials. They are valid for as
long as the TCP connection to the proxy is open. Any change in the
Kerberos security tokens sent by the client after authentication is
completed will terminate/close the TCP connection.


> 
> external_acl_type AD_Group %LOGIN /usr/lib64/squid/squid_ldap_group -P 
-R 
> -b "DC=ABCD,DC=GOV,DC=IN" -D svcproxy -w 123456789 -f 
> 
"(&(objectclass=person)(userPrincipalName=%u)(memberof=cn=%g,ou=InternetAccess,ou=Groups,dc=ABCD,dc=GOV,dc=IN))" 

> -h abcd.gov.in -s sub -v 3 -d 
> 

Since your helper names were outdated 6 years ago I assume you are using
Squid-3.1 or older:
<http://www.squid-cache.org/Versions/v3/3.1/cfgman/external_acl_type.html>

Note the default values for ttl= , negative_ttl=, and grace=

Amos

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/46a9d3b3/attachment.htm>

From augustus_meyer at gmx.net  Mon Jun 20 17:30:04 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Mon, 20 Jun 2016 10:30:04 -0700 (PDT)
Subject: [squid-users] SECURITY ALARM, once more
Message-ID: <1466443804867-4678071.post@n4.nabble.com>

I see quite a few messages like this one in my logs:
 squid[1327]: SECURITY ALERT: on URL: sa.scorecardresearch.com:443
Running squid 3.5.19-20160524-r14057, https-intercept just for logging, so
no bump.
It is understood, that most likely this is because of squids DNS and
browsers DNS not to be in sync.
Besides some "big well known sites" especially ad servers are the problem. 
Having synced all my own  DNS-caches, used by squid or the browsers, finally
I could get rid of most "SECURITY ALARMS" by disabling browsers internal DNS
cache, and pre-fetching DNS, both for firefox and chrome.
Which makes some sense to me, as special DNS-caching policy (60s., fixed,
for firefox) violates TTL, and DNS-prefetch (both firefox and chrome)
_might_ elevate the porpability of using a stale IP, in case of fast
rotation of the IP.
Special settings for the browsers are a bit cumbersome, so the question: Is
it possible to create a new
option for squid, to ignore this type of error ?
If not: Where is the right source file to start some own hacking ?


 




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SECURITY-ALARM-once-more-tp4678071.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From bcook at poughkeepsieschools.org  Mon Jun 20 19:53:04 2016
From: bcook at poughkeepsieschools.org (B. Cook)
Date: Mon, 20 Jun 2016 15:53:04 -0400
Subject: [squid-users] dead gateway, not dead peer..
Message-ID: <CAOyb_Exz5F+eokSfqFUqSH5ADfy-ZJvURYAnpJ6bzBhWOzgzmw@mail.gmail.com>

Looking for a second opinion..

I think this is beyond the scope of squid, but I figured I would ask
anyway..

VZW FiOS link in one building (primary) and VZW FIOS link in a second
building (secondary).

the gateway for the primary link is sometimes unavailable.. squid is fine
on both ends..

0.30 is the host 'oasis', 32.99 'ogden' and 12.194 'sorrento'.

Oasis is where everyone connects to and ogen (secondary) sorrento (primary)
are the non-caching peers.

So sorrento isn't going down, sorrento's gateway is..

Again I also have DNS to worry about.. so I'm thinking this is an issue
lower than squid.. squid being (osi 4 at least), I'm looking to solve an
osi 3 issue..

Right?

Thanks for taking the time to read and comment.

-- 

This message may contain confidential information and is intended only for 
the individual(s) named. If you are not an intended recipient you are not 
authorized to disseminate, distribute or copy this e-mail. Please notify 
the sender immediately if you have received this e-mail by mistake and 
delete this e-mail from your system.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/4ceb100e/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Jun 20 20:04:48 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 20 Jun 2016 22:04:48 +0200
Subject: [squid-users] dead gateway, not dead peer..
In-Reply-To: <CAOyb_Exz5F+eokSfqFUqSH5ADfy-ZJvURYAnpJ6bzBhWOzgzmw@mail.gmail.com>
References: <CAOyb_Exz5F+eokSfqFUqSH5ADfy-ZJvURYAnpJ6bzBhWOzgzmw@mail.gmail.com>
Message-ID: <201606202204.49162.Antony.Stone@squid.open.source.it>

On Monday 20 June 2016 at 21:53:04, B. Cook wrote:

> Looking for a second opinion..
> 
> I think this is beyond the scope of squid, but I figured I would ask
> anyway..

Maybe it is, maybe it isn't - I don't think you've given anything like enough 
information for us to know.

> VZW FiOS link in one building (primary) and VZW FIOS link in a second
> building (secondary).

It's probably not important to the question (although that's a guess on my 
part), but what's a "VZW FIOS" link?

Also, what do you mean in this context by primary and secondary?

> the gateway for the primary link is sometimes unavailable.. squid is fine
> on both ends..

Er, where is squid?  What is your network layout?

> 0.30 is the host 'oasis', 32.99 'ogden' and 12.194 'sorrento'.

What do those numbers mean?

> Oasis is where everyone connects to and ogen (secondary) sorrento (primary)
> are the non-caching peers.

So, you have three squid servers?

> So sorrento isn't going down, sorrento's gateway is..

I *think* I understand this bit...

> Again I also have DNS to worry about..

'Again'?  And, why do you have to worry about DNS?

> so I'm thinking this is an issue lower than squid.. squid being (osi 4 at
> least), I'm looking to solve an osi 3 issue..

Maybe...

> Right?

Please answer the following questions:

1. How many squid servers do you have (in this setup)?

2. What are their IP addresses?

3. How are they arranged (in some sort of hierarchy or peer arrangement)?

4. Why do you have more than one squid server - what are you trying to achieve 
by this?

5. What problem do you encounter that you're asking for help with?

6. Can you give us any other additional information which might help us to 
understand what you're dealing with and what's going on?

> Thanks for taking the time to read and comment.

Thanks for taking the time to give us some more information :)


Antony.

-- 
I think broken pencils are pointless.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From bcook at poughkeepsieschools.org  Mon Jun 20 20:49:41 2016
From: bcook at poughkeepsieschools.org (B. Cook)
Date: Mon, 20 Jun 2016 16:49:41 -0400
Subject: [squid-users] dead gateway, not dead peer..
In-Reply-To: <201606202204.49162.Antony.Stone@squid.open.source.it>
References: <CAOyb_Exz5F+eokSfqFUqSH5ADfy-ZJvURYAnpJ6bzBhWOzgzmw@mail.gmail.com>
 <201606202204.49162.Antony.Stone@squid.open.source.it>
Message-ID: <CAOyb_EzqP2FG8J4zzHjH-2h_msuF3HRo8=9sGOzR5w4imu2trQ@mail.gmail.com>

On Mon, Jun 20, 2016 at 4:04 PM, Antony Stone <
Antony.Stone at squid.open.source.it> wrote:
>
>
> Please answer the following questions:
>
> 1. How many squid servers do you have (in this setup)?
>
?
I have three squid servers
?


>
> 2. What are their IP addresses?
>

?172.16.0.30/20 - Oasis, 172.16.32.99/20 - Ogden, 172.16.12.194/20 -
Sorrento
?


>
> 3. How are they arranged (in some sort of hierarchy or peer arrangement)?
>

Sorrento is connection to one /29 gateway (primary), and Ogden is attached
to another /29 gateway (secondary)
?


>
> 4. Why do you have more than one squid server - what are you trying to
> achieve
> by this?
>

?Making changes to different squid setups, trying out different versions..
etc.. having more than one squid server gives more flexibility.. was
running all fedora machines and now I have a mixture of Debian and Arch.?

?the 'workers' in fedora seems to not work.. worked perfectly with Debian
and Arch..
?

>
> 5. What problem do you encounter that you're asking for help with?
>
?
When the Internet provider (gateway) goes down on Sorrento, I would like
somehow for the traffic to switch over to Ogden. But as squid has not
failed, I see no way for squid to detect that there is a problem with the
functionality on Sorrento.?



>
> 6. Can you give us any other additional information which might help us to
> understand what you're dealing with and what's going on?
> ??
>

?
Planes would drop from the sky,
? ?
like tables.
Society would tear itself apart
? ?
like an angry child with a napkin.
Man's primeval instinct
? ?
to survive at any cost,
? ?
would lead to terrible violence
?..

This is what I'm dealing with ;)
?
https://www.youtube.com/watch?v=UTBsm0LzSP0


>
> > Thanks for taking the time to read and comment.
>
> Thanks for taking the time to give us some more information :)
> ??
>
>

-- 

This message may contain confidential information and is intended only for 
the individual(s) named. If you are not an intended recipient you are not 
authorized to disseminate, distribute or copy this e-mail. Please notify 
the sender immediately if you have received this e-mail by mistake and 
delete this e-mail from your system.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160620/fa2ba58b/attachment.htm>

From ahmed.zaeem at netstream.ps  Mon Jun 20 21:43:07 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 21 Jun 2016 00:43:07 +0300
Subject: [squid-users] Squid Peek/Splice   some issues
Message-ID: <42BDD0F7-1E8B-4B59-8BC1-55425E6543BE@netstream.ps>

Hi ,
i have squid that is working on 3.5 .
traffic of t 80 and 443 traffic to Squid via IPTables.

Squid then passes traffic to ClamAV via C-ICAP. Squid is configured to intercept all SSL traffic and PKI has been setup and distributed to all clients.

we have a problem in  Skype of Business (Office 365) and Slack (Chat app)  seems its broken from squid intercept.

current versions we have :
?       Squid 3.5.19

?       C-ICAP 0.4.2

?       SquidclamAV 6.15

?       ClamAV 0.99.2

=====================

      here is squid.conf :

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8	# RFC1918 possible internal network

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost
http_access allow localhost manager
http_access deny manager

# Squid normally listens to port 3128
http_port 3127
http_port 3128 intercept


coredump_dir /var/cache/squid

visible_hostname test1

cache_log /opt/var/log/squid/cache_log
cache_access_log /opt/var/log/squid/access_log


cache_effective_user squid
cache_effective_group squid

icap_enable on
icap_send_client_ip on
icap_service service_req reqmod_precache bypass=1 icap://127.0.0.1:1344/squidclamav <icap://127.0.0.1:1344/squidclamav>
adaptation_access service_req allow all
icap_service service_resp respmod_precache bypass=1 icap://127.0.0.1:1344/squidclamav <icap://127.0.0.1:1344/squidclamav>
adaptation_access service_resp allow all

acl test-header dstdomain	test.com <http://test.com/>
request_header_add X-TEST-GUID TEST test-header

#Custom Error Pages
error_directory /opt/www/squid

# Squid listen Port
https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB key=/opt/etc/pki/squid/ca-key.pem cert=/opt/etc/pki/squid/ca.pem options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE

# SSL Bump Config
always_direct allow all
ssl_bump server-first all 
sslcrtd_program /opt/libexec/ssl_crtd -s /opt/lib/ssl_db -M 4MB
sslcrtd_children 32 startup=5 idle=1


sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS


cache_dir aufs /var/cache/squid 40000 16 256
store_dir_select_algorithm round-robin
minimum_object_size 0 KB
maximum_object_size 96 MB
memory_pools off
quick_abort_min 0 KB
quick_abort_max 0 KB
log_icp_queries off
client_db off
cache_mem 1500 MB
buffered_logs on
half_closed_clients off
dns_nameservers 10.192.0.1
=======================================================


i think the best is we ACLs setup to bypass the interception for these applications like Skype of Business (Office 365) and Slack (Chat app) .


thank you 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160621/5c6dbe5a/attachment.htm>

From augustus_meyer at gmx.net  Tue Jun 21 01:05:58 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Mon, 20 Jun 2016 18:05:58 -0700 (PDT)
Subject: [squid-users] googles data compression proxy
Message-ID: <1466471158688-4678076.post@n4.nabble.com>

Any real experience, how to block this feature ? 
Actually, it allows to tunnel thru squid, because of special protocol.
In my logs, I see TCP_DENIED for http://check.googlezip.net/connect, because
of my ACL in squid.
However, traffic is still tunneled thru squid to goohles proxy.





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/googles-data-compression-proxy-tp4678076.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Tue Jun 21 06:46:59 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 21 Jun 2016 09:46:59 +0300
Subject: [squid-users] URL access based on AD group membership
In-Reply-To: <OF27286CFD.D33D8806-ON80257FD8.00628011-80257FD8.0062AD0A@tcs.com>
References: <OF27286CFD.D33D8806-ON80257FD8.00628011-80257FD8.0062AD0A@tcs.com>
Message-ID: <059701d1cb88$b58c0be0$20a423a0$@ngtech.co.il>

Hey,

 

The first place to find documents is at:

http://www.squid-cache.org/Versions/v3/3.5/cfgman/external_acl_type.html

 

But you are not the first to encounter squid and do not understand couple
basics.

Like any complex piece of software you can just ask publically or privately.

 

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Nilesh Gavali
Sent: Monday, June 20, 2016 8:58 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] URL access based on AD group membership

 

Hello Amos; 
is there a simpler way to tackle this as I am not linux guy and not sure
howto write any helper program which need to call. 


Regards; 
Nilesh Gavali 



> Thanks Eliezer for reply.
> Its is working now for be perfectly with below command with -d option 
> gives helpful debug info to troubleshoot.
> 
> external_acl_type AD_Group %LOGIN /usr/lib64/squid/squid_ldap_group -P -R 
> -b "DC=ABCD,DC=GOV,DC=IN" -D svcproxy -w 123456789 -f 
>
"(&(objectclass=person)(userPrincipalName=%v)(memberof=cn=%a,ou=InternetAcce
ss,ou=Groups,dc=ABCD,dc=GOV,dc=IN))" 
> -h abcd.gov.in -s sub -v 3 -d
> 
> Currently I have configure squid with AD kerberos auth. also url access 
> restricted based on  AD group membership.
> 
> Now I observed, is that when I add any user to one of the AD group which 
> allowed in squid.  it is not accepting the changes until I restart the 
> squid service.

Your external_acl_type has a 1 hour response cache. Meaning it will take
a minimum of 1 hour for any changes to the AD group settings to be
passed on to Squid.


> 
> auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
> HTTP/proxy02.abcd.gov.in at ABCD.GOV.IN
<mailto:HTTP/proxy02.abcd.gov.in at ABCD.GOV.IN>  
> auth_param negotiate children 10 
> auth_param negotiate keep_alive on 
> auth_param basic credentialsttl 2 hours 

NP: settings for Basic authentication do not have any affect on
non-Basic types of authentication.

There is no TTL for Kerberos user credentials. They are valid for as
long as the TCP connection to the proxy is open. Any change in the
Kerberos security tokens sent by the client after authentication is
completed will terminate/close the TCP connection.


> 
> external_acl_type AD_Group %LOGIN /usr/lib64/squid/squid_ldap_group -P -R 
> -b "DC=ABCD,DC=GOV,DC=IN" -D svcproxy -w 123456789 -f 
>
"(&(objectclass=person)(userPrincipalName=%u)(memberof=cn=%g,ou=InternetAcce
ss,ou=Groups,dc=ABCD,dc=GOV,dc=IN))" 
> -h abcd.gov.in -s sub -v 3 -d 
> 

Since your helper names were outdated 6 years ago I assume you are using
Squid-3.1 or older:
< <http://www.squid-cache.org/Versions/v3/3.1/cfgman/external_acl_type.html>
http://www.squid-cache.org/Versions/v3/3.1/cfgman/external_acl_type.html>

Note the default values for ttl= , negative_ttl=, and grace=

Amos

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160621/639d0f99/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11295 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160621/639d0f99/attachment.png>

From squid3 at treenet.co.nz  Tue Jun 21 07:38:53 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 21 Jun 2016 19:38:53 +1200
Subject: [squid-users] googles data compression proxy
In-Reply-To: <1466471158688-4678076.post@n4.nabble.com>
References: <1466471158688-4678076.post@n4.nabble.com>
Message-ID: <1b640c62-f617-d739-8d09-642877b6e999@treenet.co.nz>

On 21/06/2016 1:05 p.m., reinerotto wrote:
> Any real experience, how to block this feature ? 
> Actually, it allows to tunnel thru squid, because of special protocol.
> In my logs, I see TCP_DENIED for http://check.googlezip.net/connect, because
> of my ACL in squid.
> However, traffic is still tunneled thru squid to goohles proxy.

Do you know how it is being tunneled? You need to block that as well.

Amos



From squid3 at treenet.co.nz  Tue Jun 21 08:31:00 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 21 Jun 2016 20:31:00 +1200
Subject: [squid-users] Squid Peek/Splice some issues
In-Reply-To: <42BDD0F7-1E8B-4B59-8BC1-55425E6543BE@netstream.ps>
References: <42BDD0F7-1E8B-4B59-8BC1-55425E6543BE@netstream.ps>
Message-ID: <eda3e30c-5a6b-3b50-504a-d8a6ddfdc7b0@treenet.co.nz>

On 21/06/2016 9:43 a.m., --Ahmad-- wrote:
> Hi ,
> i have squid that is working on 3.5 .
> traffic of t 80 and 443 traffic to Squid via IPTables.
> 
> Squid then passes traffic to ClamAV via C-ICAP. Squid is configured to intercept all SSL traffic and PKI has been setup and distributed to all clients.
> 
> we have a problem in  Skype of Business (Office 365) and Slack (Chat app)  seems its broken from squid intercept.

* Skype uses a protocol which appears very much ike TLS/SSL. But is not.
So it usually breaks when treated as TLS.

* Office 365 uses a non-HTTP protocol (RTP, RPC) inside its TLS. So
Squid cannot SSL-Bump it.

* I imagine that Slack probably does not use HTTPS as well, but some
other chat protocol.

For all of the above you will probably need the on_unsupported_protocol
feature in Squid-4.

Amos



From eliezer at ngtech.co.il  Tue Jun 21 07:04:38 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 21 Jun 2016 10:04:38 +0300
Subject: [squid-users] googles data compression proxy
In-Reply-To: <1466471158688-4678076.post@n4.nabble.com>
References: <1466471158688-4678076.post@n4.nabble.com>
Message-ID: <05b901d1cb8b$2d0c0470$87240d50$@ngtech.co.il>

Hey,

The right way to find what happens is the "on-wire" information.
It will explain how they smuggle the packets either using squid or the firewall.
What is the basic policy of the system gateway and firewall?
Are you blocking any ports other then 80 and 443?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of reinerotto
Sent: Tuesday, June 21, 2016 4:06 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] googles data compression proxy

Any real experience, how to block this feature ? 
Actually, it allows to tunnel thru squid, because of special protocol.
In my logs, I see TCP_DENIED for http://check.googlezip.net/connect, because of my ACL in squid.
However, traffic is still tunneled thru squid to goohles proxy.





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/googles-data-compression-proxy-tp4678076.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Tue Jun 21 07:02:22 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 21 Jun 2016 10:02:22 +0300
Subject: [squid-users] Squid Peek/Splice   some issues
In-Reply-To: <42BDD0F7-1E8B-4B59-8BC1-55425E6543BE@netstream.ps>
References: <42BDD0F7-1E8B-4B59-8BC1-55425E6543BE@netstream.ps>
Message-ID: <05aa01d1cb8a$dc38cb50$94aa61f0$@ngtech.co.il>

Hey Ahmad,

 

Since these apps are having issues it means that squid or them are broken or ? both.

The basic issue is that from one side you want to Intercept while you don't want to break the passing traffic.

Squid task is to work with every piece of the OS and the traffic including parsing and "understanding" the passing traffic.

The issue is that currently(3.5) squid doesn't have any way to not break HTTPS once it was intercepted and was unwrapped.

The more deep issue is that many applications are using HTTP+HTTPS in a way that needs couple twists and causes security complications.

It would be kind of "simple" to resolve the issue by bypassing squid SSL unwrapping.

If you don't care about security and you care more about caching what is possible and not caching "everything" this is the right solution.

It is possible to use a technique which will collect information about the destination HOST to be a valid HTTPS service before splicing but..

It has it's own overheads but if you care less about caching and more about the service then it's the right solution.

Just to illustrate, an ACL and filtering proxy will be pretty "simple" compared to a one with caching overheads since all the resources would be dedicated to the actual decision part of the service rather then the disks IO and cached objects DB lookups.

 

>From what I remember squid 4 is supposed to have a basic option that will differentiate between STANDARD https to other protocols.

I have not tested it yet but I am in still processing 4 ideas in general.

 

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of --Ahmad--
Sent: Tuesday, June 21, 2016 12:43 AM
To: Squid Users
Subject: [squid-users] Squid Peek/Splice some issues

 

Hi ,

i have squid that is working on 3.5 .

traffic of t 80 and 443 traffic to Squid via IPTables.

Squid then passes traffic to ClamAV via C-ICAP. Squid is configured to intercept all SSL traffic and PKI has been setup and distributed to all clients.

we have a problem in  Skype of Business (Office 365) and Slack (Chat app)  seems its broken from squid intercept.

current versions we have :

*       Squid 3.5.19

*       C-ICAP 0.4.2

*       SquidclamAV 6.15

*       ClamAV 0.99.2

=====================

      here is squid.conf :

# Example rule allowing access from your local networks.

# Adapt to list your (internal) IP networks from where browsing

# should be allowed

acl localnet src 10.0.0.0/8        # RFC1918 possible internal network

 

# Example rule allowing access from your local networks.

# Adapt localnet in the ACL section to list your (internal) IP networks

# from where browsing should be allowed

http_access allow localnet

http_access allow localhost

http_access allow localhost manager

http_access deny manager

 

# Squid normally listens to port 3128

http_port 3127

http_port 3128 intercept

 

 

coredump_dir /var/cache/squid

 

visible_hostname test1

 

cache_log /opt/var/log/squid/cache_log

cache_access_log /opt/var/log/squid/access_log

 

 

cache_effective_user squid

cache_effective_group squid

 

icap_enable on

icap_send_client_ip on

icap_service service_req reqmod_precache bypass=1 icap://127.0.0.1:1344/squidclamav

adaptation_access service_req allow all

icap_service service_resp respmod_precache bypass=1 icap://127.0.0.1:1344/squidclamav

adaptation_access service_resp allow all

 

acl test-header dstdomain       test.com <http://test.com> 

request_header_add X-TEST-GUID TEST test-header

 

#Custom Error Pages

error_directory /opt/www/squid

 

# Squid listen Port

https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB key=/opt/etc/pki/squid/ca-key.pem cert=/opt/etc/pki/squid/ca.pem options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE

 

# SSL Bump Config

always_direct allow all

ssl_bump server-first all 

sslcrtd_program /opt/libexec/ssl_crtd -s /opt/lib/ssl_db -M 4MB

sslcrtd_children 32 startup=5 idle=1

 

 

sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

 

 

cache_dir aufs /var/cache/squid 40000 16 256

store_dir_select_algorithm round-robin

minimum_object_size 0 KB

maximum_object_size 96 MB

memory_pools off

quick_abort_min 0 KB

quick_abort_max 0 KB

log_icp_queries off

client_db off

cache_mem 1500 MB

buffered_logs on

half_closed_clients off

dns_nameservers 10.192.0.1

=======================================================

 

 

i think the best is we ACLs setup to bypass the interception for these applications like Skype of Business (Office 365) and Slack (Chat app) .

 

 

thank you 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160621/523d9ea8/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11307 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160621/523d9ea8/attachment.png>

From squid3 at treenet.co.nz  Tue Jun 21 07:18:56 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 21 Jun 2016 19:18:56 +1200
Subject: [squid-users] dead gateway, not dead peer..
In-Reply-To: <CAOyb_EzqP2FG8J4zzHjH-2h_msuF3HRo8=9sGOzR5w4imu2trQ@mail.gmail.com>
References: <CAOyb_Exz5F+eokSfqFUqSH5ADfy-ZJvURYAnpJ6bzBhWOzgzmw@mail.gmail.com>
 <201606202204.49162.Antony.Stone@squid.open.source.it>
 <CAOyb_EzqP2FG8J4zzHjH-2h_msuF3HRo8=9sGOzR5w4imu2trQ@mail.gmail.com>
Message-ID: <c6977f67-02c7-7b47-659c-dad636bb9352@treenet.co.nz>

On 21/06/2016 8:49 a.m., B. Cook wrote:
> On Mon, Jun 20, 2016 at 4:04 PM, Antony Stone wrote:
>>
>> 6. Can you give us any other additional information which might help us to
>> understand what you're dealing with and what's going on?
>> ??
>>
> 
> ?
> Planes would drop from the sky,
> ? ?
> like tables.
> Society would tear itself apart
> ? ?
> like an angry child with a napkin.
> Man's primeval instinct
> ? ?
> to survive at any cost,
> ? ?
> would lead to terrible violence
> ?..
> 
> This is what I'm dealing with ;)
> ?
> https://www.youtube.com/watch?v=UTBsm0LzSP0
> 

So you're trolling. The FAQ it is then:
 <http://wiki.squid-cache.org/Features/CacheHierarchy>
 <http://wiki.squid-cache.org/Features/LoadBalance>

Amos



From squid3 at treenet.co.nz  Tue Jun 21 09:09:01 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 21 Jun 2016 21:09:01 +1200
Subject: [squid-users] SECURITY ALARM, once more
In-Reply-To: <1466443804867-4678071.post@n4.nabble.com>
References: <1466443804867-4678071.post@n4.nabble.com>
Message-ID: <7aae7621-6888-9fec-aa05-405d09789a95@treenet.co.nz>

On 21/06/2016 5:30 a.m., reinerotto wrote:
> I see quite a few messages like this one in my logs:
>  squid[1327]: SECURITY ALERT: on URL: sa.scorecardresearch.com:443
> Running squid 3.5.19-20160524-r14057, https-intercept just for logging, so
> no bump.
> It is understood, that most likely this is because of squids DNS and
> browsers DNS not to be in sync.
> Besides some "big well known sites" especially ad servers are the problem. 
> Having synced all my own  DNS-caches, used by squid or the browsers, finally
> I could get rid of most "SECURITY ALARMS" by disabling browsers internal DNS
> cache, and pre-fetching DNS, both for firefox and chrome.
> Which makes some sense to me, as special DNS-caching policy (60s., fixed,
> for firefox) violates TTL, and DNS-prefetch (both firefox and chrome)
> _might_ elevate the porpability of using a stale IP, in case of fast
> rotation of the IP.

Complicated. All you should need do is setup a local DNS resolver in
your network. If everything uses that, then they all stay in sync
naturally 90-something percent of the time.

> Special settings for the browsers are a bit cumbersome, so the question: Is
> it possible to create a new
> option for squid, to ignore this type of error ?

Squid already does the closest actions to "ignore" that is possible to
safely do. If you think you can do better, you are welcome to try, but
be aware that there are a lot of subtle and complex details involved. So
its not as easy as first appears.

To quieten the log down to only showing critical issues:
  debug_options ALL,0

Amos



From augustus_meyer at gmx.net  Tue Jun 21 09:44:05 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Tue, 21 Jun 2016 02:44:05 -0700 (PDT)
Subject: [squid-users] SECURITY ALARM, once more
In-Reply-To: <7aae7621-6888-9fec-aa05-405d09789a95@treenet.co.nz>
References: <1466443804867-4678071.post@n4.nabble.com>
 <7aae7621-6888-9fec-aa05-405d09789a95@treenet.co.nz>
Message-ID: <1466502245489-4678084.post@n4.nabble.com>

>stay in sync 
naturally 90-something percent of the time. <
I have a local dnsmasq running. squid and all clients synced to it.
But the last 10% seem to cause the SECURITY ALERT.


2016/06/21 12:17:51.672 kid1| SECURITY ALERT: Host header forgery detected
on local=nn.nnn.nnn.nnn:443 remote=10.1.0.126:62222 FD 199 flags=33 (local
IP does not match any domain IP)
2016/06/21 12:17:51.672 kid1| SECURITY ALERT: on URL: ib.adnxs.com:443

In  case, this messages shows up, is the connection terminated ?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SECURITY-ALERT-once-more-tp4678071p4678084.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Tue Jun 21 10:43:46 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 21 Jun 2016 22:43:46 +1200
Subject: [squid-users] SECURITY ALARM, once more
In-Reply-To: <1466502245489-4678084.post@n4.nabble.com>
References: <1466443804867-4678071.post@n4.nabble.com>
 <7aae7621-6888-9fec-aa05-405d09789a95@treenet.co.nz>
 <1466502245489-4678084.post@n4.nabble.com>
Message-ID: <08e50d9d-60a1-4a24-63a8-5d10dd3ccfe1@treenet.co.nz>

On 21/06/2016 9:44 p.m., reinerotto wrote:
>> stay in sync 
> naturally 90-something percent of the time. <
> I have a local dnsmasq running. squid and all clients synced to it.
> But the last 10% seem to cause the SECURITY ALERT.
> 
> 
> 2016/06/21 12:17:51.672 kid1| SECURITY ALERT: Host header forgery detected
> on local=nn.nnn.nnn.nnn:443 remote=10.1.0.126:62222 FD 199 flags=33 (local
> IP does not match any domain IP)
> 2016/06/21 12:17:51.672 kid1| SECURITY ALERT: on URL: ib.adnxs.com:443
> 
> In  case, this messages shows up, is the connection terminated ?
> 

The request continues to be handled same as any other. Except that it is
not cached and only allowed to go upstream to the same destination IP
address the client was trying to use (ORIGINAL_DST).

I'm not completely sure what happens to the SSL-Bump fake CONNECT
requests when the SNI value causes the alert. The fake request has the
above settings flagged, but the SSL-Bump logic may or may not follow
through for the decrypted requests. Those sub-requests should have the
validation check applied separately for their particular Host's anyway,
so maybe different results at that point.

Amos



From nilesh.gavali at tcs.com  Tue Jun 21 11:43:18 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Tue, 21 Jun 2016 12:43:18 +0100
Subject: [squid-users] URL access based on AD group membership
In-Reply-To: <059701d1cb88$b58c0be0$20a423a0$@ngtech.co.il>
References: <OF27286CFD.D33D8806-ON80257FD8.00628011-80257FD8.0062AD0A@tcs.com>
 <059701d1cb88$b58c0be0$20a423a0$@ngtech.co.il>
Message-ID: <OF62815FB5.40248838-ON80257FD9.003F0981-80257FD9.00405F28@tcs.com>

Hello Eliezer, 
Able to achieve want require with below link, thank to you and Amos for 
support...


Thanks & Regards
Nilesh Suresh Gavali




From:   Eliezer Croitoru <eliezer at ngtech.co.il>
To:     'Nilesh Gavali' <nilesh.gavali at tcs.com>, 
squid-users at lists.squid-cache.org
Date:   21/06/2016 07:47
Subject:        RE: [squid-users] URL access based on AD group membership



Hey,
 
The first place to find documents is at:
http://www.squid-cache.org/Versions/v3/3.5/cfgman/external_acl_type.html
 
But you are not the first to encounter squid and do not understand couple 
basics.
Like any complex piece of software you can just ask publically or 
privately.
 
Eliezer
 
----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il

 
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On 
Behalf Of Nilesh Gavali
Sent: Monday, June 20, 2016 8:58 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] URL access based on AD group membership
 
Hello Amos; 
is there a simpler way to tackle this as I am not linux guy and not sure 
howto write any helper program which need to call. 


Regards; 
Nilesh Gavali 



> Thanks Eliezer for reply.
> Its is working now for be perfectly with below command with -d option 
> gives helpful debug info to troubleshoot.
> 
> external_acl_type AD_Group %LOGIN /usr/lib64/squid/squid_ldap_group -P 
-R 
> -b "DC=ABCD,DC=GOV,DC=IN" -D svcproxy -w 123456789 -f 
> 
"(&(objectclass=person)(userPrincipalName=%v)(memberof=cn=%a,ou=InternetAccess,ou=Groups,dc=ABCD,dc=GOV,dc=IN))" 

> -h abcd.gov.in -s sub -v 3 -d
> 
> Currently I have configure squid with AD kerberos auth. also url access 
> restricted based on  AD group membership.
> 
> Now I observed, is that when I add any user to one of the AD group which 

> allowed in squid.  it is not accepting the changes until I restart the 
> squid service.

Your external_acl_type has a 1 hour response cache. Meaning it will take
a minimum of 1 hour for any changes to the AD group settings to be
passed on to Squid.


> 
> auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
> HTTP/proxy02.abcd.gov.in at ABCD.GOV.IN 
> auth_param negotiate children 10 
> auth_param negotiate keep_alive on 
> auth_param basic credentialsttl 2 hours 

NP: settings for Basic authentication do not have any affect on
non-Basic types of authentication.

There is no TTL for Kerberos user credentials. They are valid for as
long as the TCP connection to the proxy is open. Any change in the
Kerberos security tokens sent by the client after authentication is
completed will terminate/close the TCP connection.


> 
> external_acl_type AD_Group %LOGIN /usr/lib64/squid/squid_ldap_group -P 
-R 
> -b "DC=ABCD,DC=GOV,DC=IN" -D svcproxy -w 123456789 -f 
> 
"(&(objectclass=person)(userPrincipalName=%u)(memberof=cn=%g,ou=InternetAccess,ou=Groups,dc=ABCD,dc=GOV,dc=IN))" 

> -h abcd.gov.in -s sub -v 3 -d 
> 

Since your helper names were outdated 6 years ago I assume you are using
Squid-3.1 or older:
<http://www.squid-cache.org/Versions/v3/3.1/cfgman/external_acl_type.html>

Note the default values for ttl= , negative_ttl=, and grace=

Amos
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160621/a292d246/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/png
Size: 11295 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160621/a292d246/attachment.png>

From ahmed.zaeem at netstream.ps  Tue Jun 21 12:18:34 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 21 Jun 2016 15:18:34 +0300
Subject: [squid-users] Squid Peek/Splice some issues
In-Reply-To: <eda3e30c-5a6b-3b50-504a-d8a6ddfdc7b0@treenet.co.nz>
References: <42BDD0F7-1E8B-4B59-8BC1-55425E6543BE@netstream.ps>
 <eda3e30c-5a6b-3b50-504a-d8a6ddfdc7b0@treenet.co.nz>
Message-ID: <993ADD76-DB8A-4A20-B249-417745F88058@netstream.ps>

Dear Amos & eliezer

all i need right now is just having it work , since I?m not interested in caching and i can accept the low security affect .

can i keep on squid 3.5 and  do the idea of eliezer  that is ?"bypassing squid SSL unwrapping.?? ??


thank you 


> On Jun 21, 2016, at 11:31 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 21/06/2016 9:43 a.m., --Ahmad-- wrote:
>> Hi ,
>> i have squid that is working on 3.5 .
>> traffic of t 80 and 443 traffic to Squid via IPTables.
>> 
>> Squid then passes traffic to ClamAV via C-ICAP. Squid is configured to intercept all SSL traffic and PKI has been setup and distributed to all clients.
>> 
>> we have a problem in  Skype of Business (Office 365) and Slack (Chat app)  seems its broken from squid intercept.
> 
> * Skype uses a protocol which appears very much ike TLS/SSL. But is not.
> So it usually breaks when treated as TLS.
> 
> * Office 365 uses a non-HTTP protocol (RTP, RPC) inside its TLS. So
> Squid cannot SSL-Bump it.
> 
> * I imagine that Slack probably does not use HTTPS as well, but some
> other chat protocol.
> 
> For all of the above you will probably need the on_unsupported_protocol
> feature in Squid-4.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160621/dfbdedaf/attachment.htm>

From bcook at poughkeepsieschools.org  Tue Jun 21 19:12:53 2016
From: bcook at poughkeepsieschools.org (B. Cook)
Date: Tue, 21 Jun 2016 15:12:53 -0400
Subject: [squid-users] dead gateway, not dead peer..
In-Reply-To: <c6977f67-02c7-7b47-659c-dad636bb9352@treenet.co.nz>
References: <CAOyb_Exz5F+eokSfqFUqSH5ADfy-ZJvURYAnpJ6bzBhWOzgzmw@mail.gmail.com>
 <201606202204.49162.Antony.Stone@squid.open.source.it>
 <CAOyb_EzqP2FG8J4zzHjH-2h_msuF3HRo8=9sGOzR5w4imu2trQ@mail.gmail.com>
 <c6977f67-02c7-7b47-659c-dad636bb9352@treenet.co.nz>
Message-ID: <CAOyb_Eyz6Nz8OnUzw+9f4FTH0=7aOgFo6Au5vfjfFiJRe=h7RA@mail.gmail.com>

On Tue, Jun 21, 2016 at 3:18 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

>
> So you're trolling. The FAQ it is then:
>  <http://wiki.squid-cache.org/Features/CacheHierarchy>
>  <http://wiki.squid-cache.org/Features/LoadBalance>
>
>
?Thank you the response..

squid.conf (3.5.19 debian host 192.168.10.115)
cache_peer 10.20.12.144 parent 3128 0 no-digest no-netdb-exchange
proxy-only
cache_peer 10.20.12.194 parent 3128 0 no-digest no-netdb-exchange
proxy-only
cache_peer 10.20.32.99 parent 3128 0 no-digest no-netdb-exchange proxy-only
default
prefer_direct off
nonhierarchical_direct off

Turing off squid on host 10.20.12.144 immediately got 10.115 to pass
connections over to 12.194 (great) as denoted in the logs below..

?2016/06/21 15:02:16 kid1| TCP connection to 10.20.12.144/3128 failed
2016/06/21 15:02:16 kid1| TCP connection to 10.20.12.144/3128 failed
2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
2016/06/21 15:02:24 kid1| Detected DEAD Parent: 10.20.12.144
2016/06/21 15:02:32 kid1| Detected REVIVED Parent: 10.20.12.144?

When I enabled squid on host 10.20.12.144 squid detected dead -> revived
and passed traffic again.. (also great)..

but when host 10.20.12.144 loses it's gateway, the default route on 12.144
is dead.. traffic is still to 12.144.. squid didn't die, the process is
still running..

Nothing is detected and 12.194 is never contacted..

How do I get squid to detect that no valid data is being returned from
12.144.. or am I missing something?

-- 

This message may contain confidential information and is intended only for 
the individual(s) named. If you are not an intended recipient you are not 
authorized to disseminate, distribute or copy this e-mail. Please notify 
the sender immediately if you have received this e-mail by mistake and 
delete this e-mail from your system.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160621/7bf4a69c/attachment.htm>

From jbaird at follett.com  Wed Jun 22 00:46:05 2016
From: jbaird at follett.com (Baird, Josh)
Date: Wed, 22 Jun 2016 00:46:05 +0000
Subject: [squid-users] Unable to increase max_filedescr
Message-ID: <SN1PR0301MB2014C07BDE2B7F98BF651599CF2C0@SN1PR0301MB2014.namprd03.prod.outlook.com>

Hi,

I'm running 2.6STABLE (yes, I know it's ancient) and I'm unable to increase max_filedescr beyond 16384.

# grep max_file /etc/squid/squid.conf
max_filedesc    32768

# ulimit -n
32678

# squidclient -p 80 mgr:info | grep 'Maximum number'
        Maximum number of file descriptors:   16384

I have restarted squid, re-logged back in, etc.  I'm able to modify it to be anything less than 16384.  Any idea what is preventing me from scaling beyond 16384?  This is RHEL5.

Thanks,

Josh


From jbaird at follett.com  Wed Jun 22 00:52:08 2016
From: jbaird at follett.com (Baird, Josh)
Date: Wed, 22 Jun 2016 00:52:08 +0000
Subject: [squid-users] Unable to increase max_filedescr
In-Reply-To: <SN1PR0301MB2014C07BDE2B7F98BF651599CF2C0@SN1PR0301MB2014.namprd03.prod.outlook.com>
References: <SN1PR0301MB2014C07BDE2B7F98BF651599CF2C0@SN1PR0301MB2014.namprd03.prod.outlook.com>
Message-ID: <SN1PR0301MB201424BE1B681E2C37D76C6CCF2C0@SN1PR0301MB2014.namprd03.prod.outlook.com>

Replying to myself, but it appears that this package was compiled using '--max-fd=16384'.

Is there anyway, other than re-compiling and building new packages, to increase beyond this?

Josh

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Baird, Josh
Sent: Tuesday, June 21, 2016 8:46 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Unable to increase max_filedescr

Hi,

I'm running 2.6STABLE (yes, I know it's ancient) and I'm unable to increase max_filedescr beyond 16384.

# grep max_file /etc/squid/squid.conf
max_filedesc    32768

# ulimit -n
32678

# squidclient -p 80 mgr:info | grep 'Maximum number'
        Maximum number of file descriptors:   16384

I have restarted squid, re-logged back in, etc.  I'm able to modify it to be anything less than 16384.  Any idea what is preventing me from scaling beyond 16384?  This is RHEL5.

Thanks,

Josh
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From kristopher at lalletti.ca  Wed Jun 22 03:14:54 2016
From: kristopher at lalletti.ca (Kristopher Lalletti)
Date: Wed, 22 Jun 2016 03:14:54 +0000
Subject: [squid-users] cache_peer directive with SNI
Message-ID: <BY2PR04MB1859D04E48B9332D95890922C02C0@BY2PR04MB1859.namprd04.prod.outlook.com>

Hi All,

I'm replacing an Apache setup as a reverse-proxy with Squid v3.5, and I've hit a small snag.  

Basically, I need to tell squid to pass the proper SSL SNI name to the backend webserver which is accessed via SSL, and naturally, the SSL SNI service-name (service.foo.com) is not the server-hostname (webserver1.foo.com), because I've got 3 servers providing for that service-name.

Valid Request to my backend server:
curl --verbose --resolve service.foo.com:10.10.10.10 https://service.foo.com/

Bad requests to my backend server:
curl --verbose --header 'Host: service.foo.com' https://webserver1.foo.com/
curl --verbose https://webserver1.foo.com/
curl --verbose https://10.10.10.10/

I've looked at the configuration that was generated for the cached_peer, and it came to this:

cache_peer webserver1.foo.com parent 443 0 proxy-only no-query no-digest originserver login=PASSTHRU connection-auth=on round-robin ssl sslflags=DONT_VERIFY_PEER front-end-https=auto name=rvp_webserver1

Unfortunately, cached_peer doesn't seem to have any directives about this, which leads me to believe there may be a magic SSL Squid ACL that would tell the cache_peer to transpose the requested hostname as part of the SSL SNI hello message, or something like this...

Any advice/orientation to approach the problem would be much appreciated.

Cheers
Kris


From squid3 at treenet.co.nz  Wed Jun 22 04:46:33 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 22 Jun 2016 16:46:33 +1200
Subject: [squid-users] dead gateway, not dead peer..
In-Reply-To: <CAOyb_Eyz6Nz8OnUzw+9f4FTH0=7aOgFo6Au5vfjfFiJRe=h7RA@mail.gmail.com>
References: <CAOyb_Exz5F+eokSfqFUqSH5ADfy-ZJvURYAnpJ6bzBhWOzgzmw@mail.gmail.com>
 <201606202204.49162.Antony.Stone@squid.open.source.it>
 <CAOyb_EzqP2FG8J4zzHjH-2h_msuF3HRo8=9sGOzR5w4imu2trQ@mail.gmail.com>
 <c6977f67-02c7-7b47-659c-dad636bb9352@treenet.co.nz>
 <CAOyb_Eyz6Nz8OnUzw+9f4FTH0=7aOgFo6Au5vfjfFiJRe=h7RA@mail.gmail.com>
Message-ID: <52b9139f-a4cc-c5a9-2c47-b663c18a9737@treenet.co.nz>

On 22/06/2016 7:12 a.m., B. Cook wrote:
> On Tue, Jun 21, 2016 at 3:18 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
>>
>> So you're trolling. The FAQ it is then:
>>  <http://wiki.squid-cache.org/Features/CacheHierarchy>
>>  <http://wiki.squid-cache.org/Features/LoadBalance>
>>
>>
> ?Thank you the response..
> 
> squid.conf (3.5.19 debian host 192.168.10.115)
> cache_peer 10.20.12.144 parent 3128 0 no-digest no-netdb-exchange
> proxy-only
> cache_peer 10.20.12.194 parent 3128 0 no-digest no-netdb-exchange
> proxy-only
> cache_peer 10.20.32.99 parent 3128 0 no-digest no-netdb-exchange proxy-only
> default
> prefer_direct off
> nonhierarchical_direct off
> 
> Turing off squid on host 10.20.12.144 immediately got 10.115 to pass
> connections over to 12.194 (great) as denoted in the logs below..
> 
> ?2016/06/21 15:02:16 kid1| TCP connection to 10.20.12.144/3128 failed
> 2016/06/21 15:02:16 kid1| TCP connection to 10.20.12.144/3128 failed
> 2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
> 2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
> 2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
> 2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
> 2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
> 2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
> 2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
> 2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
> 2016/06/21 15:02:24 kid1| Detected DEAD Parent: 10.20.12.144
> 2016/06/21 15:02:32 kid1| Detected REVIVED Parent: 10.20.12.144?
> 
> When I enabled squid on host 10.20.12.144 squid detected dead -> revived
> and passed traffic again.. (also great)..
> 
> but when host 10.20.12.144 loses it's gateway, the default route on 12.144
> is dead.. traffic is still to 12.144.. squid didn't die, the process is
> still running..
> 
> Nothing is detected and 12.194 is never contacted..
> 
> How do I get squid to detect that no valid data is being returned from
> 12.144.. or am I missing something?

You have a router misconfiguration somewhere. Probably ICMP is not
working on your network. Which is causing connnections to hang for long
periods instead of failing over to the other peer.

Attempts by Squid to contact 12.144 when there is no way to route
traffic to it should be getting an ICMP "no route to host" error back.

Amos



From squid3 at treenet.co.nz  Wed Jun 22 04:54:12 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 22 Jun 2016 16:54:12 +1200
Subject: [squid-users] Unable to increase max_filedescr
In-Reply-To: <SN1PR0301MB201424BE1B681E2C37D76C6CCF2C0@SN1PR0301MB2014.namprd03.prod.outlook.com>
References: <SN1PR0301MB2014C07BDE2B7F98BF651599CF2C0@SN1PR0301MB2014.namprd03.prod.outlook.com>
 <SN1PR0301MB201424BE1B681E2C37D76C6CCF2C0@SN1PR0301MB2014.namprd03.prod.outlook.com>
Message-ID: <12b295e5-c631-c2ee-ee3f-2753068b0b93@treenet.co.nz>

On 22/06/2016 12:52 p.m., Baird, Josh wrote:
> Replying to myself, but it appears that this package was compiled using '--max-fd=16384'.
> 
> Is there anyway, other than re-compiling and building new packages, to increase beyond this?

ulimit in the init script or OS setting might be restricting what
max_filedesc can do. Otherwise no.


Whats holding you to 2.6 anyway?
The number of CVE assigned issues affecting it is longer than I can
easily count even with the list in front of me. Squid up to 3.5 should
build and run without much trouble anywhere 2.6 is already in use.

Amos



From hectorchan at gmail.com  Wed Jun 22 05:09:21 2016
From: hectorchan at gmail.com (Hector Chan)
Date: Tue, 21 Jun 2016 22:09:21 -0700
Subject: [squid-users] cache_peer directive with SNI
In-Reply-To: <BY2PR04MB1859D04E48B9332D95890922C02C0@BY2PR04MB1859.namprd04.prod.outlook.com>
References: <BY2PR04MB1859D04E48B9332D95890922C02C0@BY2PR04MB1859.namprd04.prod.outlook.com>
Message-ID: <CAEhCwUxmk=sArPokS5fDsX8+ronKv=QqgN9BY8Gp+3DWssNXVQ@mail.gmail.com>

Have you looked at the options forceddomain and ssldomain under the
cache_peer directive?  Those may be just what you need.



On Tue, Jun 21, 2016 at 8:14 PM, Kristopher Lalletti <kristopher at lalletti.ca
> wrote:

> Hi All,
>
> I'm replacing an Apache setup as a reverse-proxy with Squid v3.5, and I've
> hit a small snag.
>
> Basically, I need to tell squid to pass the proper SSL SNI name to the
> backend webserver which is accessed via SSL, and naturally, the SSL SNI
> service-name (service.foo.com) is not the server-hostname (
> webserver1.foo.com), because I've got 3 servers providing for that
> service-name.
>
> Valid Request to my backend server:
> curl --verbose --resolve service.foo.com:10.10.10.10
> https://service.foo.com/
>
> Bad requests to my backend server:
> curl --verbose --header 'Host: service.foo.com'
> https://webserver1.foo.com/
> curl --verbose https://webserver1.foo.com/
> curl --verbose https://10.10.10.10/
>
> I've looked at the configuration that was generated for the cached_peer,
> and it came to this:
>
> cache_peer webserver1.foo.com parent 443 0 proxy-only no-query no-digest
> originserver login=PASSTHRU connection-auth=on round-robin ssl
> sslflags=DONT_VERIFY_PEER front-end-https=auto name=rvp_webserver1
>
> Unfortunately, cached_peer doesn't seem to have any directives about this,
> which leads me to believe there may be a magic SSL Squid ACL that would
> tell the cache_peer to transpose the requested hostname as part of the SSL
> SNI hello message, or something like this...
>
> Any advice/orientation to approach the problem would be much appreciated.
>
> Cheers
> Kris
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160621/175cca5b/attachment.htm>

From squid3 at treenet.co.nz  Wed Jun 22 05:31:43 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 22 Jun 2016 17:31:43 +1200
Subject: [squid-users] cache_peer directive with SNI
In-Reply-To: <BY2PR04MB1859D04E48B9332D95890922C02C0@BY2PR04MB1859.namprd04.prod.outlook.com>
References: <BY2PR04MB1859D04E48B9332D95890922C02C0@BY2PR04MB1859.namprd04.prod.outlook.com>
Message-ID: <f1316501-f300-8501-cd37-f521ca01aa77@treenet.co.nz>

On 22/06/2016 3:14 p.m., Kristopher Lalletti wrote:
> Hi All,
> 
> I'm replacing an Apache setup as a reverse-proxy with Squid v3.5, and
> I've hit a small snag.
> 
> Basically, I need to tell squid to pass the proper SSL SNI name to
> the backend webserver which is accessed via SSL, and naturally, the
> SSL SNI service-name (service.foo.com) is not the server-hostname
> (webserver1.foo.com), because I've got 3 servers providing for that
> service-name.
> 

You understanding of "proper" behaviour is not correct.

TLS is a point-to-point protocol.

For clients end-to-end and point-to-point are not distinguishable, so a
lot of misunderstanding exists. For a reverse-proxy / CDN the
distinction is critical for correct crytography.


That means the SNI (plus keys, ciphers and certificates etc) on the
connection between Squid and that origin peer are specifically and
exactly supposed to be the "webserver1" details. Because Squid is
talking to the Server Name(d) "webserver1.foo.com" not to itself.

 --> the client will never see the the TLS details the origin sent to
Squid. They are private to the Squid<->origin connection.


The SNI and crypto details between client and Squid is the only place
"service.foo.com" is proper in the TLS layer. Since outside your CDN /
reverse-proxy structure "service.foo.com" (aka Squid) is the Server Name.


Also be aware that the TLS details like SNI on the Squid<->origin
connection have *nothing* to do with the HTTP layer messages. That
should continue to be Host:service.foo.com or whatever the client is
requesting in its HTTP (S) messages.

SNI is not equivalent to HTTP virtual hosting despite what some known
bugs in Apache may have led you to believe.

Amos


From jblank at twu.net  Wed Jun 22 11:13:56 2016
From: jblank at twu.net (jblank at twu.net)
Date: Wed, 22 Jun 2016 06:13:56 -0500 (CDT)
Subject: [squid-users] Forward loop when intercepting mode to proxy traffic
	to local VM
Message-ID: <alpine.DEB.2.02.1606220543010.12819@eowyn.twu.net>

Hey all,

Thanks to a bizarre client requirement (don't ask, it's head-hurty), I am 
required to maintain a legacy server which only supports obsolete SHA-1 
encryption. To keep things relatively safe, I'm attempting to contain the 
problem within a VM and use Squid on the VM's host to "re-encrypt" 
incoming traffic.

That is:
Outside world talks SHA2 to Squid; Squid internally talks SHA1 to the VM; 
Squid gets the response from the VM and passes it along (re-encrypting it 
to SHA2).

At least, that's the idea. But forget about SSL/encryption for the moment; 
I can't even get this concept working with plain old unencrypted HTTP.

The VM is running locally, and accessible via host-only networking on 
192.168.1.101. I set up a local /etc/hosts alternative JUST for 
Squid's use, which tells Squid that "myhost.mydomain.com" is actually 
192.168.1.101. Yet Squid seems to be ignoring this. Incoming requests for 
http://myhost.mydomain.com/ throw a standard Squid "Access Denied." 
page. cache.log reveals the presence of a forward loop:

-------
2016/06/22 06:48:47 kid1| WARNING: Forwarding loop detected for:
GET /favicon.ico HTTP/1.1
Host: myhost.mydomain.com
Pragma: no-cache
User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) 
AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36
Accept: */*
Referer: http://myhost.mydomain.com/
Accept-Encoding: gzip, deflate, sdch
Accept-Language: en-US,en;q=0.8
Via: 1.1 myhost (squid/3.4.8)
X-Forwarded-For: 1.2.3.4
Cache-Control: no-cache
Connection: keep-alive


2016/06/22 06:48:47 kid1| ERROR: No forward-proxy ports configured.
2016/06/22 06:48:47 kid1| ERROR: No forward-proxy ports configured.
-------

access.log, meanwhile, reports:

1466592527.367      0 5.6.7.8 TCP_MISS/403 3917 GET 
http://myhost.mydomain.com/favicon.ico - HIER_NONE/- text/html
1466592527.367      0 1.2.3.4 TCP_MISS/403 4000 GET 
http://myhost.mydomain.com/favicon.ico - ORIGINAL_DST/5.6.7.8 text/html

(Here, "5.6.7.8" is the EXTERNAL IP address of the VM host-- i.e., the 
actual "outside world" IP of myhost.mydomain.com, as opposed to the 
internal-only 192.168.1.101 which it should be translated into. "1.2.3.4" 
is the IP of my workstation running my Web browser.)

Below is the ENTIRE text of my /etc/squid3/squid.conf; at one point in 
this process, I got so frustrated that I pared it down to the absolute 
minimum.

---
hosts_file /etc/squid3/squid_hosts
always_direct allow all
cache deny all
acl FROM_ALL src all
acl TO_LOCAL dst 127.0.0.1
acl TO_LOCAL dst 192.168.1.101
http_access allow FROM_ALL
http_access allow TO_LOCAL
http_access deny all
http_port 80 intercept
---

I've been bashing my head against this problem all evening to no effect. I 
am fairly sure I could simply solve my problem by writing a miniscule 
proxy script in PHP, Perl or Python, and using Apache's mod_rewrite rules 
to point all incoming Web requests through said proxy script. But I'd 
really rather not "re-invent the wheel"; I'd really rather use Squid.

Any help would be very much appreciated!

Best,

Jessica


From jblank at twu.net  Wed Jun 22 11:15:12 2016
From: jblank at twu.net (jblank at twu.net)
Date: Wed, 22 Jun 2016 06:15:12 -0500 (CDT)
Subject: [squid-users] Forward loop when intercepting mode to proxy
 traffic to local VM
In-Reply-To: <alpine.DEB.2.02.1606220543010.12819@eowyn.twu.net>
References: <alpine.DEB.2.02.1606220543010.12819@eowyn.twu.net>
Message-ID: <alpine.DEB.2.02.1606220614560.12819@eowyn.twu.net>

Slight correction on the Subject (my bad); I meant "when using intercept 
mode", not "when intercepting mode".

On Wed, 22 Jun 2016, jblank at twu.net wrote:

> Hey all,
>
> Thanks to a bizarre client requirement (don't ask, it's head-hurty), I am 
> required to maintain a legacy server which only supports obsolete SHA-1 
> encryption. To keep things relatively safe, I'm attempting to contain the 
> problem within a VM and use Squid on the VM's host to "re-encrypt" 
> incoming traffic.
>
> That is:
> Outside world talks SHA2 to Squid; Squid internally talks SHA1 to the VM; 
> Squid gets the response from the VM and passes it along (re-encrypting it 
> to SHA2).
>
> At least, that's the idea. But forget about SSL/encryption for the moment; 
> I can't even get this concept working with plain old unencrypted HTTP.
>
> The VM is running locally, and accessible via host-only networking on 
> 192.168.1.101. I set up a local /etc/hosts alternative JUST for 
> Squid's use, which tells Squid that "myhost.mydomain.com" is actually 
> 192.168.1.101. Yet Squid seems to be ignoring this. Incoming requests for 
> http://myhost.mydomain.com/ throw a standard Squid "Access Denied." 
> page. cache.log reveals the presence of a forward loop:
>
> -------
> 2016/06/22 06:48:47 kid1| WARNING: Forwarding loop detected for:
> GET /favicon.ico HTTP/1.1
> Host: myhost.mydomain.com
> Pragma: no-cache
> User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) 
> AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36
> Accept: */*
> Referer: http://myhost.mydomain.com/
> Accept-Encoding: gzip, deflate, sdch
> Accept-Language: en-US,en;q=0.8
> Via: 1.1 myhost (squid/3.4.8)
> X-Forwarded-For: 1.2.3.4
> Cache-Control: no-cache
> Connection: keep-alive
>
>
> 2016/06/22 06:48:47 kid1| ERROR: No forward-proxy ports configured.
> 2016/06/22 06:48:47 kid1| ERROR: No forward-proxy ports configured.
> -------
>
> access.log, meanwhile, reports:
>
> 1466592527.367      0 5.6.7.8 TCP_MISS/403 3917 GET 
> http://myhost.mydomain.com/favicon.ico - HIER_NONE/- text/html
> 1466592527.367      0 1.2.3.4 TCP_MISS/403 4000 GET 
> http://myhost.mydomain.com/favicon.ico - ORIGINAL_DST/5.6.7.8 text/html
>
> (Here, "5.6.7.8" is the EXTERNAL IP address of the VM host-- i.e., the 
> actual "outside world" IP of myhost.mydomain.com, as opposed to the 
> internal-only 192.168.1.101 which it should be translated into. "1.2.3.4" 
> is the IP of my workstation running my Web browser.)
>
> Below is the ENTIRE text of my /etc/squid3/squid.conf; at one point in 
> this process, I got so frustrated that I pared it down to the absolute 
> minimum.
>
> ---
> hosts_file /etc/squid3/squid_hosts
> always_direct allow all
> cache deny all
> acl FROM_ALL src all
> acl TO_LOCAL dst 127.0.0.1
> acl TO_LOCAL dst 192.168.1.101
> http_access allow FROM_ALL
> http_access allow TO_LOCAL
> http_access deny all
> http_port 80 intercept
> ---
>
> I've been bashing my head against this problem all evening to no effect. I 
> am fairly sure I could simply solve my problem by writing a miniscule 
> proxy script in PHP, Perl or Python, and using Apache's mod_rewrite rules 
> to point all incoming Web requests through said proxy script. But I'd 
> really rather not "re-invent the wheel"; I'd really rather use Squid.
>
> Any help would be very much appreciated!
>
> Best,
>
> Jessica
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From reqman at freemail.gr  Wed Jun 22 11:58:43 2016
From: reqman at freemail.gr (reqman)
Date: Wed, 22 Jun 2016 14:58:43 +0300
Subject: [squid-users] "unknown request" when configured to display custom
	logo
Message-ID: <CAAvSkVF9BN-RxQQtak1u36ahwbmn9jhD9_=b=BNSkOuesniqMQ@mail.gmail.com>

squid 3.5.19 on FreeBSD 10.3. The system has a LAN and WAN interface,
both in private address spaces. System's name is my.host.local,
listening on LAN at 192.168.0.1:3128. The system is not configured to
listen on localhost.

I am trying to replace the squid logo (SN.png) with the logo of my
agency. To do so:
1) I've copied mylogo.png to /usr/local/etc/squid/icons, alongside
SN.png. Same permissions for both files, same ownership:

 # ls -laF /usr/local/etc/squid/icons/
total 36
drwxr-xr-x  3 root  wheel    512 Jun 22 12:53 ./
drwxr-xr-x  4 root  squid    512 Jun 22 12:54 ../
-rw-r--r--  1 root  wheel  12716 May 19 16:15 SN.png
-rw-r--r--  1 root  wheel   7863 Jun 22 12:08 mylogo.png
drwxr-xr-x  2 root  wheel   1536 May 27 14:17 silk/

2) I've edited /usr/local/etc/squid/errorpage.css and replaced
/squid-internal-static/icons/SN.png with
/squid-internal-static/icons/mylogo.png

Details (filesize etc) of mylogo.png:

#file mylogo.png
mylogo.png: PNG image data, 82 x 72, 8-bit/color RGBA, non-interlaced

I've made both a squid -k reconfigure as well as a service squid
restart to make sure that the change propagates through. The problem
is that even though SN.png shows up just fine everywhere, the logo I
have created does not. The following errors appear when browsing FTP
sites (whereas the logo always appears) or when an HTTP error page has
to be displayed:

2016/06/22 12:57:38 kid1| internalStart: unknown request:
GET /squid-internal-static/icons/mylogo.png HTTP/1.1
Accept: */*
Referer: http://moystakas.gr/
Accept-Language: el
User-Agent: Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1;
Trident/4.0; .NET CLR 1.1.4322; .NET CLR 2.0.50727; .NET CLR
3.0.4506.2152; .NET CLR 3.5.30729)
Accept-Encoding: gzip, deflate
Proxy-Connection: Keep-Alive
Host: moystakas.gr

On access.log:

1466589376.848      1 192.168.0.209 TCP_MISS/404 5632 GET
http://my.host.local:3128/squid-internal-static/icons/mylogo.png -
HIER_NONE/- text/html

BR,


Michael.-


From eliezer at ngtech.co.il  Wed Jun 22 12:18:55 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 22 Jun 2016 15:18:55 +0300
Subject: [squid-users] "unknown request" when configured to display
	custom	logo
In-Reply-To: <CAAvSkVF9BN-RxQQtak1u36ahwbmn9jhD9_=b=BNSkOuesniqMQ@mail.gmail.com>
References: <CAAvSkVF9BN-RxQQtak1u36ahwbmn9jhD9_=b=BNSkOuesniqMQ@mail.gmail.com>
Message-ID: <0b6101d1cc80$3ee4fe90$bcaefbb0$@ngtech.co.il>

Hey,

What usually is being done is that in the errorpage.css you insert a fully qualified url of a "self hosted" web service and not squid.
There was a talk about allowing squid to act as a static files web service but I am not sure it it was done or not.
A simple nginx\apache\lighthttpd or another very lightweight local web service should be used instead of squid internals in many cases.

Hope It Helps,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of reqman
Sent: Wednesday, June 22, 2016 2:59 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] "unknown request" when configured to display custom logo

squid 3.5.19 on FreeBSD 10.3. The system has a LAN and WAN interface,
both in private address spaces. System's name is my.host.local,
listening on LAN at 192.168.0.1:3128. The system is not configured to
listen on localhost.

I am trying to replace the squid logo (SN.png) with the logo of my
agency. To do so:
1) I've copied mylogo.png to /usr/local/etc/squid/icons, alongside
SN.png. Same permissions for both files, same ownership:

 # ls -laF /usr/local/etc/squid/icons/
total 36
drwxr-xr-x  3 root  wheel    512 Jun 22 12:53 ./
drwxr-xr-x  4 root  squid    512 Jun 22 12:54 ../
-rw-r--r--  1 root  wheel  12716 May 19 16:15 SN.png
-rw-r--r--  1 root  wheel   7863 Jun 22 12:08 mylogo.png
drwxr-xr-x  2 root  wheel   1536 May 27 14:17 silk/

2) I've edited /usr/local/etc/squid/errorpage.css and replaced
/squid-internal-static/icons/SN.png with
/squid-internal-static/icons/mylogo.png

Details (filesize etc) of mylogo.png:

#file mylogo.png
mylogo.png: PNG image data, 82 x 72, 8-bit/color RGBA, non-interlaced

I've made both a squid -k reconfigure as well as a service squid
restart to make sure that the change propagates through. The problem
is that even though SN.png shows up just fine everywhere, the logo I
have created does not. The following errors appear when browsing FTP
sites (whereas the logo always appears) or when an HTTP error page has
to be displayed:

2016/06/22 12:57:38 kid1| internalStart: unknown request:
GET /squid-internal-static/icons/mylogo.png HTTP/1.1
Accept: */*
Referer: http://moystakas.gr/
Accept-Language: el
User-Agent: Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1;
Trident/4.0; .NET CLR 1.1.4322; .NET CLR 2.0.50727; .NET CLR
3.0.4506.2152; .NET CLR 3.5.30729)
Accept-Encoding: gzip, deflate
Proxy-Connection: Keep-Alive
Host: moystakas.gr

On access.log:

1466589376.848      1 192.168.0.209 TCP_MISS/404 5632 GET
http://my.host.local:3128/squid-internal-static/icons/mylogo.png -
HIER_NONE/- text/html

BR,


Michael.-
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From robertocarna36 at gmail.com  Wed Jun 22 12:53:23 2016
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Wed, 22 Jun 2016 09:53:23 -0300
Subject: [squid-users] Squid3 error: CHILD: hello write test failed logrotate
Message-ID: <CAG2Qp6vFPYshkxFa5d3uGN0zAW2L6z_nv9-TY8-iOyknofHUnw@mail.gmail.com>

Dear, I've implemented a Squid3 in reverse mode, and when I test it
with some web access from my PC, everything was OK. But when I put it
in production, there are a lot of web access and everything was OK
until the /var/log/squid3/access.log rotate to access.log.1. From this
moment, the access.log file is not present, and the squid3 daemon
doesn't respond...I'm not sure the cause.

Ia have to create the access.log by hand, and set up the owners. After
that I rebooted the server and squid3 daemon runs OK.

I have this error in /var/log/squid3/cache.log:

2016/06/22 06:25:06 kid1| logfileRotate: daemon:/var/log/squid3/access.log
2016/06/22 06:25:06 kid1| logfileRotate: daemon:/var/log/squid3/access.log
2016/06/22 06:25:06 kid1| sendto FD 14: (1) Operation not permitted
2016/06/22 06:25:06 kid1| ipcCreate: CHILD: hello write test failed

My OS is Debian 8 64 bits, the Squid 3.4.8-6+deb8u2 compiled by hand.

Can you help me ??? Thanks a lot

R.


From bcook at poughkeepsieschools.org  Wed Jun 22 13:25:06 2016
From: bcook at poughkeepsieschools.org (B. Cook)
Date: Wed, 22 Jun 2016 09:25:06 -0400
Subject: [squid-users] dead gateway, not dead peer..
In-Reply-To: <52b9139f-a4cc-c5a9-2c47-b663c18a9737@treenet.co.nz>
References: <CAOyb_Exz5F+eokSfqFUqSH5ADfy-ZJvURYAnpJ6bzBhWOzgzmw@mail.gmail.com>
 <201606202204.49162.Antony.Stone@squid.open.source.it>
 <CAOyb_EzqP2FG8J4zzHjH-2h_msuF3HRo8=9sGOzR5w4imu2trQ@mail.gmail.com>
 <c6977f67-02c7-7b47-659c-dad636bb9352@treenet.co.nz>
 <CAOyb_Eyz6Nz8OnUzw+9f4FTH0=7aOgFo6Au5vfjfFiJRe=h7RA@mail.gmail.com>
 <52b9139f-a4cc-c5a9-2c47-b663c18a9737@treenet.co.nz>
Message-ID: <CAOyb_Ez6S3_m25SmGEwuE2+N9rUSjBiH6ec3X3S7AMwyopQQtQ@mail.gmail.com>

?when the one of the proxies loses its internet connection.. the default
route is gone.  Not the route to the machine..

the 12.194 proxy then gives this message:

The following error was encountered while trying to retrieve the URL:
http://www.tmz.com/

Connection to 54.230.36.213 failed.

The system returned: (101) Network is unreachable

The remote host or network may be down. Please try the request again.?

12.194 can not get to 54.230.36.213 (tmz.com)..

I can still get to 12.194..

Squid is still running on 12.194, 12.194 has no gateway.. the Internet
connection FROM 12.194 TO the outside is dead and gone.

That is what I am trying to fix..

When a cache_peer has a connectivity problem..


On Wed, Jun 22, 2016 at 12:46 AM, Amos Jeffries <squid3 at treenet.co.nz>
wrote:

> On 22/06/2016 7:12 a.m., B. Cook wrote:
> > On Tue, Jun 21, 2016 at 3:18 AM, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
> >
> >>
> >> So you're trolling. The FAQ it is then:
> >>  <http://wiki.squid-cache.org/Features/CacheHierarchy>
> >>  <http://wiki.squid-cache.org/Features/LoadBalance>
> >>
> >>
> > ?Thank you the response..
> >
> > squid.conf (3.5.19 debian host 192.168.10.115)
> > cache_peer 10.20.12.144 parent 3128 0 no-digest no-netdb-exchange
> > proxy-only
> > cache_peer 10.20.12.194 parent 3128 0 no-digest no-netdb-exchange
> > proxy-only
> > cache_peer 10.20.32.99 parent 3128 0 no-digest no-netdb-exchange
> proxy-only
> > default
> > prefer_direct off
> > nonhierarchical_direct off
> >
> > Turing off squid on host 10.20.12.144 immediately got 10.115 to pass
> > connections over to 12.194 (great) as denoted in the logs below..
> >
> > ?2016/06/21 15:02:16 kid1| TCP connection to 10.20.12.144/3128 failed
> > 2016/06/21 15:02:16 kid1| TCP connection to 10.20.12.144/3128 failed
> > 2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
> > 2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
> > 2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
> > 2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
> > 2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
> > 2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
> > 2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
> > 2016/06/21 15:02:24 kid1| TCP connection to 10.20.12.144/3128 failed
> > 2016/06/21 15:02:24 kid1| Detected DEAD Parent: 10.20.12.144
> > 2016/06/21 15:02:32 kid1| Detected REVIVED Parent: 10.20.12.144?
> >
> > When I enabled squid on host 10.20.12.144 squid detected dead -> revived
> > and passed traffic again.. (also great)..
> >
> > but when host 10.20.12.144 loses it's gateway, the default route on
> 12.144
> > is dead.. traffic is still to 12.144.. squid didn't die, the process is
> > still running..
> >
> > Nothing is detected and 12.194 is never contacted..
> >
> > How do I get squid to detect that no valid data is being returned from
> > 12.144.. or am I missing something?
>
> You have a router misconfiguration somewhere. Probably ICMP is not
> working on your network. Which is causing connnections to hang for long
> periods instead of failing over to the other peer.
>
> Attempts by Squid to contact 12.144 when there is no way to route
> traffic to it should be getting an ICMP "no route to host" error back.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
Network Analyst
Poughkeepsie City School District
SMS & Mobile: (202) 810-5827
twitter.com/bcookatpcsd

If you can't explain it simply, you don't understand it well enough.

-- 

This message may contain confidential information and is intended only for 
the individual(s) named. If you are not an intended recipient you are not 
authorized to disseminate, distribute or copy this e-mail. Please notify 
the sender immediately if you have received this e-mail by mistake and 
delete this e-mail from your system.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/72a1585b/attachment.htm>

From Antony.Stone at squid.open.source.it  Wed Jun 22 13:29:38 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 22 Jun 2016 15:29:38 +0200
Subject: [squid-users] Squid3 error: CHILD: hello write test failed
	logrotate
In-Reply-To: <CAG2Qp6vFPYshkxFa5d3uGN0zAW2L6z_nv9-TY8-iOyknofHUnw@mail.gmail.com>
References: <CAG2Qp6vFPYshkxFa5d3uGN0zAW2L6z_nv9-TY8-iOyknofHUnw@mail.gmail.com>
Message-ID: <201606221529.38478.Antony.Stone@squid.open.source.it>

On Wednesday 22 June 2016 at 14:53:23, Roberto Carna wrote:

> everything was OK until the /var/log/squid3/access.log rotate to
> access.log.1. From this moment, the access.log file is not present, and the
> squid3 daemon doesn't respond...I'm not sure the cause.

Show us your log rotation script.


Antony.

-- 
If the human brain were so simple that we could understand it,
we'd be so simple that we couldn't.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From robertocarna36 at gmail.com  Wed Jun 22 13:44:42 2016
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Wed, 22 Jun 2016 10:44:42 -0300
Subject: [squid-users] Squid3 error: CHILD: hello write test failed
	logrotate
In-Reply-To: <201606221529.38478.Antony.Stone@squid.open.source.it>
References: <CAG2Qp6vFPYshkxFa5d3uGN0zAW2L6z_nv9-TY8-iOyknofHUnw@mail.gmail.com>
 <201606221529.38478.Antony.Stone@squid.open.source.it>
Message-ID: <CAG2Qp6sfMBY_i1r097LKce6hRNQb3m5F3QHq+BTBKPyEkDiTnQ@mail.gmail.com>

Dear Antony, thanks for your help..below is the
/etc/logrotate.d/squid3 file....but before I have to say I've seen in
the web that this problem is solved by enabling IPv6, and was reported
by a ticket (https://forum.opnsense.org/index.php?topic=879.0) ..can
this be true???

/var/log/squid3/*.log {
        daily
        compress
        delaycompress
        rotate 2
        missingok
        nocreate
        sharedscripts
        postrotate
                test ! -e /var/run/squid3.pid || test ! -x
/usr/sbin/squid3 || /usr/sbin/squid3 -k rotate
        endscript
}

Regards,

2016-06-22 10:29 GMT-03:00 Antony Stone <Antony.Stone at squid.open.source.it>:
> On Wednesday 22 June 2016 at 14:53:23, Roberto Carna wrote:
>
>> everything was OK until the /var/log/squid3/access.log rotate to
>> access.log.1. From this moment, the access.log file is not present, and the
>> squid3 daemon doesn't respond...I'm not sure the cause.
>
> Show us your log rotation script.
>
>
> Antony.
>
> --
> If the human brain were so simple that we could understand it,
> we'd be so simple that we couldn't.
>
>                                                    Please reply to the list;
>                                                          please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Wed Jun 22 13:49:02 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jun 2016 01:49:02 +1200
Subject: [squid-users] Forward loop when intercepting mode to proxy
 traffic to local VM
In-Reply-To: <alpine.DEB.2.02.1606220614560.12819@eowyn.twu.net>
References: <alpine.DEB.2.02.1606220543010.12819@eowyn.twu.net>
 <alpine.DEB.2.02.1606220614560.12819@eowyn.twu.net>
Message-ID: <9e96c8cd-7eb8-150a-15d5-fd3da970931e@treenet.co.nz>

On 22/06/2016 11:15 p.m., jblank wrote:
> Slight correction on the Subject (my bad); I meant "when using intercept
> mode", not "when intercepting mode".
> 
> On Wed, 22 Jun 2016, jblank wrote:
> 
>> Hey all,
>>
>> Thanks to a bizarre client requirement (don't ask, it's head-hurty), I
>> am required to maintain a legacy server which only supports obsolete
>> SHA-1 encryption. To keep things relatively safe, I'm attempting to
>> contain the problem within a VM and use Squid on the VM's host to
>> "re-encrypt" incoming traffic.
>>
>> That is:
>> Outside world talks SHA2 to Squid; Squid internally talks SHA1 to the
>> VM; Squid gets the response from the VM and passes it along
>> (re-encrypting it to SHA2).

Okay. That sounds simple. But the use of intercept implies things are a
bit more complex for Squids situation.

Is there a particular reason you are using interception?

The next TLS / HTTPS stages of your task would be much less headache to
do as a reverse-proxy.


>>
>> At least, that's the idea. But forget about SSL/encryption for the
>> moment; I can't even get this concept working with plain old
>> unencrypted HTTP.
>>
>> The VM is running locally, and accessible via host-only networking on
>> 192.168.1.101. I set up a local /etc/hosts alternative JUST for
>> Squid's use, which tells Squid that "myhost.mydomain.com" is actually
>> 192.168.1.101. Yet Squid seems to be ignoring this. Incoming requests
>> for http://myhost.mydomain.com/ throw a standard Squid "Access
>> Denied." page. cache.log reveals the presence of a forward loop:
>>
<snip>

Correct way to use a static link to a specific upstream is to use the
cache_peer directive to tell Squid about that link and any fancy stuff
about it.

So this config should just work for both http:// and https:// traffic
destined to the VM:

 # use the URL domain instead of raw-IPs
 acl VM_domains dstdomain example.com
 http_access allow VM_domains

 acl HTTPS proto HTTPS

 # The HTTP if you want it, remove these lines if not
 cache_peer 192.168.1.101 parent 80 0 originserver name=VM_http
 cache_peer_access VM_http allow HTTPS VM_domains
 cache_peer_access VM_http deny all

 # The HTTPS if you want it. Should work as-is but might need
 # other ssl* options for specific TLS/SSL tuning. see the TLS section
 # of http://www.squid-cache.org/Doc/config/cache_peer/ for details.
 cache_peer 192.168.1.101 parent 443 0 originserver ssl name=VM_https
 cache_peer_access VM_https allow !HTTPS VM_domains
 cache_peer_access VM_https deny all


Note that Squid does not need hosts file entries for this to work.

Also, the warning about forward proxy ports is because you dropped the
default "http_port 3128" line. Add it back (or use reverse-proxy) and
those will disappear.


Cheers
Amos


From robertocarna36 at gmail.com  Wed Jun 22 13:49:57 2016
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Wed, 22 Jun 2016 10:49:57 -0300
Subject: [squid-users] Squid3 error: CHILD: hello write test failed
	logrotate
In-Reply-To: <CAG2Qp6sfMBY_i1r097LKce6hRNQb3m5F3QHq+BTBKPyEkDiTnQ@mail.gmail.com>
References: <CAG2Qp6vFPYshkxFa5d3uGN0zAW2L6z_nv9-TY8-iOyknofHUnw@mail.gmail.com>
 <201606221529.38478.Antony.Stone@squid.open.source.it>
 <CAG2Qp6sfMBY_i1r097LKce6hRNQb3m5F3QHq+BTBKPyEkDiTnQ@mail.gmail.com>
Message-ID: <CAG2Qp6uZ+miWURbUz73u5w4jzo=MaTTfRyubgLBwe=izG-DEiw@mail.gmail.com>

Also I see in cache.log:

 pinger: Initialising ICMP pinger ...
2016/06/22 09:58:51| pinger: ICMP socket opened.
2016/06/22 09:58:51|  icmp_sock: (97) Address family not supported by protocol
2016/06/22 09:58:51| pinger: Unable to start ICMPv6 pinger.
2016/06/22 09:58:51| Pinger exiting.

2016-06-22 10:44 GMT-03:00 Roberto Carna <robertocarna36 at gmail.com>:
> Dear Antony, thanks for your help..below is the
> /etc/logrotate.d/squid3 file....but before I have to say I've seen in
> the web that this problem is solved by enabling IPv6, and was reported
> by a ticket (https://forum.opnsense.org/index.php?topic=879.0) ..can
> this be true???
>
> /var/log/squid3/*.log {
>         daily
>         compress
>         delaycompress
>         rotate 2
>         missingok
>         nocreate
>         sharedscripts
>         postrotate
>                 test ! -e /var/run/squid3.pid || test ! -x
> /usr/sbin/squid3 || /usr/sbin/squid3 -k rotate
>         endscript
> }
>
> Regards,
>
> 2016-06-22 10:29 GMT-03:00 Antony Stone <Antony.Stone at squid.open.source.it>:
>> On Wednesday 22 June 2016 at 14:53:23, Roberto Carna wrote:
>>
>>> everything was OK until the /var/log/squid3/access.log rotate to
>>> access.log.1. From this moment, the access.log file is not present, and the
>>> squid3 daemon doesn't respond...I'm not sure the cause.
>>
>> Show us your log rotation script.
>>
>>
>> Antony.
>>
>> --
>> If the human brain were so simple that we could understand it,
>> we'd be so simple that we couldn't.
>>
>>                                                    Please reply to the list;
>>                                                          please *don't* CC me.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users


From Antony.Stone at squid.open.source.it  Wed Jun 22 13:52:52 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 22 Jun 2016 15:52:52 +0200
Subject: [squid-users] Squid3 error: CHILD: hello write test failed
	logrotate
In-Reply-To: <CAG2Qp6uZ+miWURbUz73u5w4jzo=MaTTfRyubgLBwe=izG-DEiw@mail.gmail.com>
References: <CAG2Qp6vFPYshkxFa5d3uGN0zAW2L6z_nv9-TY8-iOyknofHUnw@mail.gmail.com>
 <CAG2Qp6sfMBY_i1r097LKce6hRNQb3m5F3QHq+BTBKPyEkDiTnQ@mail.gmail.com>
 <CAG2Qp6uZ+miWURbUz73u5w4jzo=MaTTfRyubgLBwe=izG-DEiw@mail.gmail.com>
Message-ID: <201606221552.52782.Antony.Stone@squid.open.source.it>

On Wednesday 22 June 2016 at 15:49:57, Roberto Carna wrote:

> Also I see in cache.log:
> 
>  pinger: Initialising ICMP pinger ...
> 2016/06/22 09:58:51| pinger: ICMP socket opened.
> 2016/06/22 09:58:51|  icmp_sock: (97) Address family not supported by
> protocol 2016/06/22 09:58:51| pinger: Unable to start ICMPv6 pinger.
> 2016/06/22 09:58:51| Pinger exiting.

In that case I recommend you undo whatever you did to try to disable IPv6 on 
this machine.

I can't guarantee that will resolve this problem, but at least it will keep 
your networking stack a lot happier.


Antony.

-- 
"Microsoft's profit margins require a monopoly lock on the market; thus, 
they're stuck with being predatory evil bastards. The moment they stop being 
predatory evil bastards, their stock price will tank and their options pyramid 
will crash and it will be all over."

 - Eric S Raymond

                                                   Please reply to the list;
                                                         please *don't* CC me.


From Antony.Stone at squid.open.source.it  Wed Jun 22 13:53:30 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 22 Jun 2016 15:53:30 +0200
Subject: [squid-users] Squid3 error: CHILD: hello write test failed
	logrotate
In-Reply-To: <CAG2Qp6sfMBY_i1r097LKce6hRNQb3m5F3QHq+BTBKPyEkDiTnQ@mail.gmail.com>
References: <CAG2Qp6vFPYshkxFa5d3uGN0zAW2L6z_nv9-TY8-iOyknofHUnw@mail.gmail.com>
 <201606221529.38478.Antony.Stone@squid.open.source.it>
 <CAG2Qp6sfMBY_i1r097LKce6hRNQb3m5F3QHq+BTBKPyEkDiTnQ@mail.gmail.com>
Message-ID: <201606221553.31204.Antony.Stone@squid.open.source.it>

On Wednesday 22 June 2016 at 15:44:42, Roberto Carna wrote:

> Dear Antony, thanks for your help..below is the
> /etc/logrotate.d/squid3 file....but before I have to say I've seen in
> the web that this problem is solved by enabling IPv6, and was reported
> by a ticket (https://forum.opnsense.org/index.php?topic=879.0) ..can
> this be true???

1. Have you tried to disable IPv6 on this machine?  (see my other reply to 
your other reply)

2. You said in your first posting that "I have to create the access.log by 
hand, and set up the owners. After that I rebooted the server and squid3 
daemon runs OK."  Do you really need to reboot the server, or is restarting 
Squid sufficient?

> /var/log/squid3/*.log {
>         daily
>         compress
>         delaycompress
>         rotate 2
>         missingok
>         nocreate
>         sharedscripts
>         postrotate
>                 test ! -e /var/run/squid3.pid || test ! -x
> /usr/sbin/squid3 || /usr/sbin/squid3 -k rotate
>         endscript
> }

Considering that you've found you have to create the file manually and set the 
correct permissions / ownerships, I would change the "nocreate" line in the 
above script so that it does create the file, with the correct ownership etc.


Regards,


Antony.

-- 
Never write it in Perl if you can do it in Awk.
Never do it in Awk if sed can handle it.
Never use sed when tr can do the job.
Never invoke tr when cat is sufficient.
Avoid using cat whenever possible.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Wed Jun 22 13:55:39 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jun 2016 01:55:39 +1200
Subject: [squid-users] dead gateway, not dead peer..
In-Reply-To: <CAOyb_Ez6S3_m25SmGEwuE2+N9rUSjBiH6ec3X3S7AMwyopQQtQ@mail.gmail.com>
References: <CAOyb_Exz5F+eokSfqFUqSH5ADfy-ZJvURYAnpJ6bzBhWOzgzmw@mail.gmail.com>
 <201606202204.49162.Antony.Stone@squid.open.source.it>
 <CAOyb_EzqP2FG8J4zzHjH-2h_msuF3HRo8=9sGOzR5w4imu2trQ@mail.gmail.com>
 <c6977f67-02c7-7b47-659c-dad636bb9352@treenet.co.nz>
 <CAOyb_Eyz6Nz8OnUzw+9f4FTH0=7aOgFo6Au5vfjfFiJRe=h7RA@mail.gmail.com>
 <52b9139f-a4cc-c5a9-2c47-b663c18a9737@treenet.co.nz>
 <CAOyb_Ez6S3_m25SmGEwuE2+N9rUSjBiH6ec3X3S7AMwyopQQtQ@mail.gmail.com>
Message-ID: <e0a91be5-7d81-8289-9a2b-da62ab1bf3f0@treenet.co.nz>

On 23/06/2016 1:25 a.m., B. Cook wrote:
> ?when the one of the proxies loses its internet connection.. the default
> route is gone.  Not the route to the machine..
> 
> the 12.194 proxy then gives this message:
> 
> The following error was encountered while trying to retrieve the URL:
> http://www.tmz.com/
> 
> Connection to 54.230.36.213 failed.
> 
> The system returned: (101) Network is unreachable
> 
> The remote host or network may be down. Please try the request again.?
> 
> 12.194 can not get to 54.230.36.213 (tmz.com)..
> 
> I can still get to 12.194..
> 
> Squid is still running on 12.194, 12.194 has no gateway.. the Internet
> connection FROM 12.194 TO the outside is dead and gone.
> 
> That is what I am trying to fix..
> 
> When a cache_peer has a connectivity problem..
> 

Aha. I thought you were talking about the routing between them.

The solution comes down to what HTTP response status code is being sent
back on that "Network is unreachable" error page created by the
cache_peer without connectivity.

Amos



From bcook at poughkeepsieschools.org  Wed Jun 22 14:00:00 2016
From: bcook at poughkeepsieschools.org (B. Cook)
Date: Wed, 22 Jun 2016 10:00:00 -0400
Subject: [squid-users] dead gateway, not dead peer..
In-Reply-To: <e0a91be5-7d81-8289-9a2b-da62ab1bf3f0@treenet.co.nz>
References: <CAOyb_Exz5F+eokSfqFUqSH5ADfy-ZJvURYAnpJ6bzBhWOzgzmw@mail.gmail.com>
 <201606202204.49162.Antony.Stone@squid.open.source.it>
 <CAOyb_EzqP2FG8J4zzHjH-2h_msuF3HRo8=9sGOzR5w4imu2trQ@mail.gmail.com>
 <c6977f67-02c7-7b47-659c-dad636bb9352@treenet.co.nz>
 <CAOyb_Eyz6Nz8OnUzw+9f4FTH0=7aOgFo6Au5vfjfFiJRe=h7RA@mail.gmail.com>
 <52b9139f-a4cc-c5a9-2c47-b663c18a9737@treenet.co.nz>
 <CAOyb_Ez6S3_m25SmGEwuE2+N9rUSjBiH6ec3X3S7AMwyopQQtQ@mail.gmail.com>
 <e0a91be5-7d81-8289-9a2b-da62ab1bf3f0@treenet.co.nz>
Message-ID: <CAOyb_EyjSoNUZE7QHmN-07whxUFKCU-8bThYxRk8iP78JSGfsw@mail.gmail.com>

...

What can I do about it?

(thank you for working through understanding the problem..)


On Wed, Jun 22, 2016 at 9:55 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 23/06/2016 1:25 a.m., B. Cook wrote:
> > ?when the one of the proxies loses its internet connection.. the default
> > route is gone.  Not the route to the machine..
> >
> > the 12.194 proxy then gives this message:
> >
> > The following error was encountered while trying to retrieve the URL:
> > http://www.tmz.com/
> >
> > Connection to 54.230.36.213 failed.
> >
> > The system returned: (101) Network is unreachable
> >
> > The remote host or network may be down. Please try the request again.?
> >
> > 12.194 can not get to 54.230.36.213 (tmz.com)..
> >
> > I can still get to 12.194..
> >
> > Squid is still running on 12.194, 12.194 has no gateway.. the Internet
> > connection FROM 12.194 TO the outside is dead and gone.
> >
> > That is what I am trying to fix..
> >
> > When a cache_peer has a connectivity problem..
> >
>
> Aha. I thought you were talking about the routing between them.
>
> The solution comes down to what HTTP response status code is being sent
> back on that "Network is unreachable" error page created by the
> cache_peer without connectivity.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
Network Analyst
Poughkeepsie City School District
SMS & Mobile: (202) 810-5827
twitter.com/bcookatpcsd

If you can't explain it simply, you don't understand it well enough.

-- 

This message may contain confidential information and is intended only for 
the individual(s) named. If you are not an intended recipient you are not 
authorized to disseminate, distribute or copy this e-mail. Please notify 
the sender immediately if you have received this e-mail by mistake and 
delete this e-mail from your system.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/bd749448/attachment.htm>

From squid3 at treenet.co.nz  Wed Jun 22 14:06:44 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jun 2016 02:06:44 +1200
Subject: [squid-users] "unknown request" when configured to display
 custom logo
In-Reply-To: <CAAvSkVF9BN-RxQQtak1u36ahwbmn9jhD9_=b=BNSkOuesniqMQ@mail.gmail.com>
References: <CAAvSkVF9BN-RxQQtak1u36ahwbmn9jhD9_=b=BNSkOuesniqMQ@mail.gmail.com>
Message-ID: <f0f92ae0-5026-f386-52d3-a86634951f03@treenet.co.nz>

On 22/06/2016 11:58 p.m., reqman wrote:
> squid 3.5.19 on FreeBSD 10.3. The system has a LAN and WAN interface,
> both in private address spaces. System's name is my.host.local,
> listening on LAN at 192.168.0.1:3128. The system is not configured to
> listen on localhost.
> 
> I am trying to replace the squid logo (SN.png) with the logo of my
> agency. To do so:
> 1) I've copied mylogo.png to /usr/local/etc/squid/icons, alongside
> SN.png. Same permissions for both files, same ownership:
> 
>  # ls -laF /usr/local/etc/squid/icons/
> total 36
> drwxr-xr-x  3 root  wheel    512 Jun 22 12:53 ./
> drwxr-xr-x  4 root  squid    512 Jun 22 12:54 ../
> -rw-r--r--  1 root  wheel  12716 May 19 16:15 SN.png
> -rw-r--r--  1 root  wheel   7863 Jun 22 12:08 mylogo.png
> drwxr-xr-x  2 root  wheel   1536 May 27 14:17 silk/
> 
> 2) I've edited /usr/local/etc/squid/errorpage.css and replaced
> /squid-internal-static/icons/SN.png with
> /squid-internal-static/icons/mylogo.png
> 

Okay, so far thats all correct.

The final step is to edit the /usr/local/etc/squid/mime.conf config file
and replace the "SN.png" listed there for internal-logo with your image
filename.
 Then squid -k reconfigure to load the change.

As Eliezer said Squid is not a generic web server. So getting it to
serve things up is a bit of arcane voodoo and this is close to the limit
of what is possible.

Amos



From hans.meyer0 at fn.de  Wed Jun 22 14:10:12 2016
From: hans.meyer0 at fn.de (hans.meyer0 at fn.de)
Date: Wed, 22 Jun 2016 16:10:12 +0200
Subject: [squid-users] https antivirus proxy necessary?
Message-ID: <aafca46690da29f048a319616b823c51@email.freenet.de>

Do you think it's necessary to have an additional https antivir proxy to normal client antivirus? We are using Avast Business that already offers a web protection. Can an additional antivir proxy significant higher the level of protection? In general I think two different antivirus programms see more then one. But on the other hand an HTTP/HTTPS antivirus proxy is an additional?attack surface. Especially because its?costly to build the latest squid version with https support from source on a debian jessi. So the proxy will not be ?up a proxy or not?


---
Mail & Cloud Made in Germany mit 3 GB Speicher! Jetzt kostenlos anmelden
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/2e90a88c/attachment.htm>

From 1int at list.ru  Wed Jun 22 14:21:08 2016
From: 1int at list.ru (Pavel Lint)
Date: Wed, 22 Jun 2016 17:21:08 +0300
Subject: [squid-users] Squid won't listen to ipv4
Message-ID: <2FE4043B-7B2D-47AE-AA2E-92E93FB7EA6B@list.ru>

Good evening, dear sirs. Please kindly assist me in resolving this issue.

After compiling and launching squid 3.5.12 on my Red Had Linux (3.10.0-327.13.1.el7.x86_64), I face the problem of Squid listening to ipv6 only. 

Here?s a related (I think) squid log entry:
> 2016/06/21 09:52:44.608 kid1| 33,2| AsyncCallQueue.cc <http://asynccallqueue.cc/>
> <http://AsyncCallQueue.cc <http://asynccallqueue.cc/>>(57) fireNext: leaving
> clientListenerConnectionOpened(local=[::]:3128 remote=[::] FD 9 flags=9,
> err=0, HTTP Socket port=0x18c3a80)


I see no errors in the log. 
Is there something I?ve missed?

Cheers,
Pavel Lint.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/bf822bcd/attachment.htm>

From Antony.Stone at squid.open.source.it  Wed Jun 22 14:29:33 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 22 Jun 2016 16:29:33 +0200
Subject: [squid-users] Squid won't listen to ipv4
In-Reply-To: <2FE4043B-7B2D-47AE-AA2E-92E93FB7EA6B@list.ru>
References: <2FE4043B-7B2D-47AE-AA2E-92E93FB7EA6B@list.ru>
Message-ID: <201606221629.33393.Antony.Stone@squid.open.source.it>

On Wednesday 22 June 2016 at 16:21:08, Pavel Lint wrote:

> After compiling and launching squid 3.5.12 on my Red Had Linux
> (3.10.0-327.13.1.el7.x86_64), I face the problem of Squid listening to
> ipv6 only.

How have you determined this?  Have you tried connecting to its IPv4 address 
and encountered an error?  If so, what is that error?

> Here?s a related (I think) squid log entry:
> > 2016/06/21 09:52:44.608 kid1| 33,2| AsyncCallQueue.cc
> > <http://asynccallqueue.cc/> <http://AsyncCallQueue.cc
> > <http://asynccallqueue.cc/>>(57) fireNext: leaving
> > clientListenerConnectionOpened(local=[::]:3128 remote=[::] FD 9 flags=9,
> > err=0, HTTP Socket port=0x18c3a80)
> 
> I see no errors in the log.

Nor do I.  What is wrong with the above?

> Is there something I?ve missed?

What does the output of "netstat -lptn | grep 3128" show?


Antony.

-- 
+++ Divide By Cucumber Error.  Please Reinstall Universe And Reboot +++

                                                   Please reply to the list;
                                                         please *don't* CC me.


From 1int at list.ru  Wed Jun 22 14:41:31 2016
From: 1int at list.ru (Pavel Lint)
Date: Wed, 22 Jun 2016 17:41:31 +0300
Subject: [squid-users] Squid won't listen to ipv4
In-Reply-To: <201606221629.33393.Antony.Stone@squid.open.source.it>
References: <2FE4043B-7B2D-47AE-AA2E-92E93FB7EA6B@list.ru>
 <201606221629.33393.Antony.Stone@squid.open.source.it>
Message-ID: <9327000C-3B5E-439E-B210-4319655D4115@list.ru>


> How have you determined this?  Have you tried connecting to its IPv4 address 
> and encountered an error?  If so, what is that error?
> 
> What does the output of "netstat -lptn | grep 3128" show?
> 

That?s exactly how I determined this. The output from netstat -ltpn is just one line:

tcp6       0      0 :::3128                 :::*                    LISTEN
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/22c6a7a3/attachment.htm>

From squid3 at treenet.co.nz  Wed Jun 22 14:42:23 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jun 2016 02:42:23 +1200
Subject: [squid-users] Squid3 error: CHILD: hello write test failed
 logrotate
In-Reply-To: <CAG2Qp6sfMBY_i1r097LKce6hRNQb3m5F3QHq+BTBKPyEkDiTnQ@mail.gmail.com>
References: <CAG2Qp6vFPYshkxFa5d3uGN0zAW2L6z_nv9-TY8-iOyknofHUnw@mail.gmail.com>
 <201606221529.38478.Antony.Stone@squid.open.source.it>
 <CAG2Qp6sfMBY_i1r097LKce6hRNQb3m5F3QHq+BTBKPyEkDiTnQ@mail.gmail.com>
Message-ID: <170232bb-117b-c395-d0d0-e8dcf73e7b52@treenet.co.nz>

On 23/06/2016 1:44 a.m., Roberto Carna wrote:
> Dear Antony, thanks for your help..below is the
> /etc/logrotate.d/squid3 file....but before I have to say I've seen in
> the web that this problem is solved by enabling IPv6, and was reported
> by a ticket (https://forum.opnsense.org/index.php?topic=879.0) ..can
> this be true???

You misread that ticket. It is not about logging. It is about other things.

If you are logging with the TCP or UDP log modules then IPv6 might
matter. For local files its not related.

> 
> /var/log/squid3/*.log {
>         daily
>         compress
>         delaycompress
>         rotate 2
>         missingok
>         nocreate
>         sharedscripts
>         postrotate
>                 test ! -e /var/run/squid3.pid || test ! -x
> /usr/sbin/squid3 || /usr/sbin/squid3 -k rotate
>         endscript
> }
> 

Okay, thats the script that used to be bundled with Squid in Debian.

However, you need to know that use of logrotate requires Squid to have
"logfile_rotate 0" configured. Debian packages patch that in as a
default config setting.

If you don't have that some weird things happen.

Amos



From squid3 at treenet.co.nz  Wed Jun 22 14:45:38 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jun 2016 02:45:38 +1200
Subject: [squid-users] dead gateway, not dead peer..
In-Reply-To: <CAOyb_EyjSoNUZE7QHmN-07whxUFKCU-8bThYxRk8iP78JSGfsw@mail.gmail.com>
References: <CAOyb_Exz5F+eokSfqFUqSH5ADfy-ZJvURYAnpJ6bzBhWOzgzmw@mail.gmail.com>
 <201606202204.49162.Antony.Stone@squid.open.source.it>
 <CAOyb_EzqP2FG8J4zzHjH-2h_msuF3HRo8=9sGOzR5w4imu2trQ@mail.gmail.com>
 <c6977f67-02c7-7b47-659c-dad636bb9352@treenet.co.nz>
 <CAOyb_Eyz6Nz8OnUzw+9f4FTH0=7aOgFo6Au5vfjfFiJRe=h7RA@mail.gmail.com>
 <52b9139f-a4cc-c5a9-2c47-b663c18a9737@treenet.co.nz>
 <CAOyb_Ez6S3_m25SmGEwuE2+N9rUSjBiH6ec3X3S7AMwyopQQtQ@mail.gmail.com>
 <e0a91be5-7d81-8289-9a2b-da62ab1bf3f0@treenet.co.nz>
 <CAOyb_EyjSoNUZE7QHmN-07whxUFKCU-8bThYxRk8iP78JSGfsw@mail.gmail.com>
Message-ID: <8e742a01-e13f-f4e3-c909-4cca319d17a6@treenet.co.nz>

On 23/06/2016 2:00 a.m., B. Cook wrote:
> ...
> 
> What can I do about it?
> 
> (thank you for working through understanding the problem..)
> 

What is the HTTP status code on that error page?

Amos



From squid3 at treenet.co.nz  Wed Jun 22 14:47:33 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jun 2016 02:47:33 +1200
Subject: [squid-users] Squid won't listen to ipv4
In-Reply-To: <9327000C-3B5E-439E-B210-4319655D4115@list.ru>
References: <2FE4043B-7B2D-47AE-AA2E-92E93FB7EA6B@list.ru>
 <201606221629.33393.Antony.Stone@squid.open.source.it>
 <9327000C-3B5E-439E-B210-4319655D4115@list.ru>
Message-ID: <ba75cf9a-3fb7-c847-3e6e-ab73ae940400@treenet.co.nz>

On 23/06/2016 2:41 a.m., Pavel Lint wrote:
> 
>> How have you determined this?  Have you tried connecting to its IPv4 address 
>> and encountered an error?  If so, what is that error?
>>
>> What does the output of "netstat -lptn | grep 3128" show?
>>
> 
> That?s exactly how I determined this. The output from netstat -ltpn is just one line:
> 
> tcp6       0      0 :::3128                 :::*                    LISTEN
> 

Linux contains a hybrid TCP stack. Those ports accept both IPv4 and IPv6
traffic.

Amos



From buechlerml at hdpnet.de  Wed Jun 22 14:58:41 2016
From: buechlerml at hdpnet.de (Paul Buechler)
Date: Wed, 22 Jun 2016 16:58:41 +0200
Subject: [squid-users] google drive up-/download size in squidlog
In-Reply-To: <20160607183118.GC1391@fantomas.sk>
References: <57440D94.1080703@hdpnet.de>
 <009a89d8-79af-45e9-ee97-7baa5e24ceac@treenet.co.nz>
 <efa39e35-91b4-979b-104c-d7d9cdf16131@hdpnet.de>
 <c8aaa441-8f3a-0f43-520a-caeeec8243cf@treenet.co.nz>
 <ed9da6a1-5f63-5c01-a842-42a9a736c726@hdpnet.de>
 <67b83658-bcd3-d350-3c29-bae91f9724b4@treenet.co.nz>
 <20160607183118.GC1391@fantomas.sk>
Message-ID: <383b4823-3828-7824-f015-4a47e2cc97ac@hdpnet.de>

the documentation says:

[http::]>st	Total size of request received from client. Excluding chunked encoding bytes.

so is it possible to have the chunked encoding bytes included?



From ahmed.zaeem at netstream.ps  Wed Jun 22 15:05:57 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Wed, 22 Jun 2016 18:05:57 +0300
Subject: [squid-users] Squid Peek/Splice some issues
In-Reply-To: <eda3e30c-5a6b-3b50-504a-d8a6ddfdc7b0@treenet.co.nz>
References: <42BDD0F7-1E8B-4B59-8BC1-55425E6543BE@netstream.ps>
 <eda3e30c-5a6b-3b50-504a-d8a6ddfdc7b0@treenet.co.nz>
Message-ID: <9680CFE8-A991-48FA-8447-F511A15DCC00@netstream.ps>


> On Jun 21, 2016, at 11:31 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 21/06/2016 9:43 a.m., --Ahmad-- wrote:
>> Hi ,
>> i have squid that is working on 3.5 .
>> traffic of t 80 and 443 traffic to Squid via IPTables.
>> 
>> Squid then passes traffic to ClamAV via C-ICAP. Squid is configured to intercept all SSL traffic and PKI has been setup and distributed to all clients.
>> 
>> we have a problem in  Skype of Business (Office 365) and Slack (Chat app)  seems its broken from squid intercept.
> 
> * Skype uses a protocol which appears very much ike TLS/SSL. But is not.
> So it usually breaks when treated as TLS.
> 
> * Office 365 uses a non-HTTP protocol (RTP, RPC) inside its TLS. So
> Squid cannot SSL-Bump it.
> 
> * I imagine that Slack probably does not use HTTPS as well, but some
> other chat protocol.
> 
> For all of the above you will probably need the on_unsupported_protocol
> feature in Squid-4.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From sebelk at gmail.com  Wed Jun 22 15:09:48 2016
From: sebelk at gmail.com (Sergio Belkin)
Date: Wed, 22 Jun 2016 12:09:48 -0300
Subject: [squid-users] Somewhat-OT: e2guardian
Message-ID: <CABZC=5yPHSnrWfDMYWTDYbbfuE24jXFkW5hei36mfr9c=swPjg@mail.gmail.com>

Hi,

I wonder if anyone is using e2guardian. If so, I'd like to hear experiences.

I used dans guardian some years ago

Thanks in advance!

-- 
--
Sergio Belkin
LPIC-2 Certified - http://www.lpi.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/46bebb7d/attachment.htm>

From bcook at poughkeepsieschools.org  Wed Jun 22 15:44:06 2016
From: bcook at poughkeepsieschools.org (B. Cook)
Date: Wed, 22 Jun 2016 11:44:06 -0400
Subject: [squid-users] dead gateway, not dead peer..
In-Reply-To: <8e742a01-e13f-f4e3-c909-4cca319d17a6@treenet.co.nz>
References: <CAOyb_Exz5F+eokSfqFUqSH5ADfy-ZJvURYAnpJ6bzBhWOzgzmw@mail.gmail.com>
 <201606202204.49162.Antony.Stone@squid.open.source.it>
 <CAOyb_EzqP2FG8J4zzHjH-2h_msuF3HRo8=9sGOzR5w4imu2trQ@mail.gmail.com>
 <c6977f67-02c7-7b47-659c-dad636bb9352@treenet.co.nz>
 <CAOyb_Eyz6Nz8OnUzw+9f4FTH0=7aOgFo6Au5vfjfFiJRe=h7RA@mail.gmail.com>
 <52b9139f-a4cc-c5a9-2c47-b663c18a9737@treenet.co.nz>
 <CAOyb_Ez6S3_m25SmGEwuE2+N9rUSjBiH6ec3X3S7AMwyopQQtQ@mail.gmail.com>
 <e0a91be5-7d81-8289-9a2b-da62ab1bf3f0@treenet.co.nz>
 <CAOyb_EyjSoNUZE7QHmN-07whxUFKCU-8bThYxRk8iP78JSGfsw@mail.gmail.com>
 <8e742a01-e13f-f4e3-c909-4cca319d17a6@treenet.co.nz>
Message-ID: <CAOyb_Eyp2-YrJOd9pkVX5h3+D54hMnJuoXD9oKsd0Vr766jjgQ@mail.gmail.com>

Looks to be 101..

Is that wrong?


> The following error was encountered while trying to retrieve the URL:
> http://www.tmz.com/
>
> Connection to 54.230.36.213 failed.
>
> The system returned: (101) Network is unreachable
>
> The remote host or network may be down. Please try the request again.?



On Wed, Jun 22, 2016 at 10:45 AM, Amos Jeffries <squid3 at treenet.co.nz>
wrote:

> On 23/06/2016 2:00 a.m., B. Cook wrote:
> > ...
> >
> > What can I do about it?
> >
> > (thank you for working through understanding the problem..)
> >
>
> What is the HTTP status code on that error page?
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

-- 

This message may contain confidential information and is intended only for 
the individual(s) named. If you are not an intended recipient you are not 
authorized to disseminate, distribute or copy this e-mail. Please notify 
the sender immediately if you have received this e-mail by mistake and 
delete this e-mail from your system.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/84acff87/attachment.htm>

From squid3 at treenet.co.nz  Wed Jun 22 15:50:00 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jun 2016 03:50:00 +1200
Subject: [squid-users] dead gateway, not dead peer..
In-Reply-To: <CAOyb_Eyp2-YrJOd9pkVX5h3+D54hMnJuoXD9oKsd0Vr766jjgQ@mail.gmail.com>
References: <CAOyb_Exz5F+eokSfqFUqSH5ADfy-ZJvURYAnpJ6bzBhWOzgzmw@mail.gmail.com>
 <201606202204.49162.Antony.Stone@squid.open.source.it>
 <CAOyb_EzqP2FG8J4zzHjH-2h_msuF3HRo8=9sGOzR5w4imu2trQ@mail.gmail.com>
 <c6977f67-02c7-7b47-659c-dad636bb9352@treenet.co.nz>
 <CAOyb_Eyz6Nz8OnUzw+9f4FTH0=7aOgFo6Au5vfjfFiJRe=h7RA@mail.gmail.com>
 <52b9139f-a4cc-c5a9-2c47-b663c18a9737@treenet.co.nz>
 <CAOyb_Ez6S3_m25SmGEwuE2+N9rUSjBiH6ec3X3S7AMwyopQQtQ@mail.gmail.com>
 <e0a91be5-7d81-8289-9a2b-da62ab1bf3f0@treenet.co.nz>
 <CAOyb_EyjSoNUZE7QHmN-07whxUFKCU-8bThYxRk8iP78JSGfsw@mail.gmail.com>
 <8e742a01-e13f-f4e3-c909-4cca319d17a6@treenet.co.nz>
 <CAOyb_Eyp2-YrJOd9pkVX5h3+D54hMnJuoXD9oKsd0Vr766jjgQ@mail.gmail.com>
Message-ID: <56c3f2fe-7675-9935-6f01-29196ab02ac5@treenet.co.nz>

On 23/06/2016 3:44 a.m., B. Cook wrote:
> Looks to be 101..
> 
> Is that wrong?
> 

Yeah. That is the OS code for the ICMP error on the remote machine.

The HTTP status code should be either at the top of the page, or in the
HTTP headers.

Amos



From squid3 at treenet.co.nz  Wed Jun 22 15:55:50 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jun 2016 03:55:50 +1200
Subject: [squid-users] dead gateway, not dead peer..
In-Reply-To: <56c3f2fe-7675-9935-6f01-29196ab02ac5@treenet.co.nz>
References: <CAOyb_Exz5F+eokSfqFUqSH5ADfy-ZJvURYAnpJ6bzBhWOzgzmw@mail.gmail.com>
 <201606202204.49162.Antony.Stone@squid.open.source.it>
 <CAOyb_EzqP2FG8J4zzHjH-2h_msuF3HRo8=9sGOzR5w4imu2trQ@mail.gmail.com>
 <c6977f67-02c7-7b47-659c-dad636bb9352@treenet.co.nz>
 <CAOyb_Eyz6Nz8OnUzw+9f4FTH0=7aOgFo6Au5vfjfFiJRe=h7RA@mail.gmail.com>
 <52b9139f-a4cc-c5a9-2c47-b663c18a9737@treenet.co.nz>
 <CAOyb_Ez6S3_m25SmGEwuE2+N9rUSjBiH6ec3X3S7AMwyopQQtQ@mail.gmail.com>
 <e0a91be5-7d81-8289-9a2b-da62ab1bf3f0@treenet.co.nz>
 <CAOyb_EyjSoNUZE7QHmN-07whxUFKCU-8bThYxRk8iP78JSGfsw@mail.gmail.com>
 <8e742a01-e13f-f4e3-c909-4cca319d17a6@treenet.co.nz>
 <CAOyb_Eyp2-YrJOd9pkVX5h3+D54hMnJuoXD9oKsd0Vr766jjgQ@mail.gmail.com>
 <56c3f2fe-7675-9935-6f01-29196ab02ac5@treenet.co.nz>
Message-ID: <87d0966f-0cb0-1e73-8c3c-056493b8b998@treenet.co.nz>

On 23/06/2016 3:50 a.m., Amos Jeffries wrote:
> On 23/06/2016 3:44 a.m., B. Cook wrote:
>> Looks to be 101..
>>
>> Is that wrong?
>>
> 
> Yeah. That is the OS code for the ICMP error on the remote machine.
> 
> The HTTP status code should be either at the top of the page, or in the
> HTTP headers.


You could also enable "debug_options 11,2" and see all the HTTP headers
in the cache.log.

Amos



From jbaird at follett.com  Wed Jun 22 16:09:19 2016
From: jbaird at follett.com (Baird, Josh)
Date: Wed, 22 Jun 2016 16:09:19 +0000
Subject: [squid-users] Unable to increase max_filedescr
In-Reply-To: <12b295e5-c631-c2ee-ee3f-2753068b0b93@treenet.co.nz>
References: <SN1PR0301MB2014C07BDE2B7F98BF651599CF2C0@SN1PR0301MB2014.namprd03.prod.outlook.com>
 <SN1PR0301MB201424BE1B681E2C37D76C6CCF2C0@SN1PR0301MB2014.namprd03.prod.outlook.com>
 <12b295e5-c631-c2ee-ee3f-2753068b0b93@treenet.co.nz>
Message-ID: <SN1PR0301MB20148FBE71DDBA7D175BD7BACF2C0@SN1PR0301MB2014.namprd03.prod.outlook.com>

Yeah, no go setting ulimit in the init script.

An ancient plugin for our web filtering solution is keeping us on 2.6.  We are moving to a new solution soon.

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Wednesday, June 22, 2016 12:54 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Unable to increase max_filedescr

On 22/06/2016 12:52 p.m., Baird, Josh wrote:
> Replying to myself, but it appears that this package was compiled using '--max-fd=16384'.
> 
> Is there anyway, other than re-compiling and building new packages, to increase beyond this?

ulimit in the init script or OS setting might be restricting what max_filedesc can do. Otherwise no.


Whats holding you to 2.6 anyway?
The number of CVE assigned issues affecting it is longer than I can easily count even with the list in front of me. Squid up to 3.5 should build and run without much trouble anywhere 2.6 is already in use.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From jlay at slave-tothe-box.net  Wed Jun 22 16:12:55 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Wed, 22 Jun 2016 10:12:55 -0600
Subject: [squid-users] Unknown Cipher Suite
Message-ID: <1466611975.2449.10.camel@slave-tothe-box.net>

Well this is new....started seeing this on Instagram. ?Message I get
when debugging:

2016/06/22 09:43:26| Error negotiating SSL on FD 14: error:140920F8:SSL
routines:SSL3_GET_SERVER_HELLO:unknown cipher returned (1/-1/0)

And sure enough...even Wireshark doesn't know what this is:


Any hints on how what this is/how to fix? ?Thanks all.

James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/24eaf0ad/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screenshot from 2016-06-22 10-12-10.png
Type: image/png
Size: 64635 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/24eaf0ad/attachment.png>

From robertocarna36 at gmail.com  Wed Jun 22 16:32:21 2016
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Wed, 22 Jun 2016 13:32:21 -0300
Subject: [squid-users] Squid3 error: CHILD: hello write test failed
	logrotate
In-Reply-To: <170232bb-117b-c395-d0d0-e8dcf73e7b52@treenet.co.nz>
References: <CAG2Qp6vFPYshkxFa5d3uGN0zAW2L6z_nv9-TY8-iOyknofHUnw@mail.gmail.com>
 <201606221529.38478.Antony.Stone@squid.open.source.it>
 <CAG2Qp6sfMBY_i1r097LKce6hRNQb3m5F3QHq+BTBKPyEkDiTnQ@mail.gmail.com>
 <170232bb-117b-c395-d0d0-e8dcf73e7b52@treenet.co.nz>
Message-ID: <CAG2Qp6t2j5VRreWg2Vz7D3bgLWOvFtwfsVUGkPpqVEVGaZLsJA@mail.gmail.com>

Amos and Antony, thanks a lot for your help.

At first, I'll enable IPv6 in my Debian box.

And for the log problem, I couldn't understand what yoy said
Amos...please can you detail what I have to do in order to avoid log
rotation problems???

And at last, why do you think the log problem arrives when several
clients access to my reverse proxy??? Because when I test it only from
2 or 3 PC's, everything was OK.

Thanks a lot, regards!!!

2016-06-22 11:42 GMT-03:00 Amos Jeffries <squid3 at treenet.co.nz>:
> On 23/06/2016 1:44 a.m., Roberto Carna wrote:
>> Dear Antony, thanks for your help..below is the
>> /etc/logrotate.d/squid3 file....but before I have to say I've seen in
>> the web that this problem is solved by enabling IPv6, and was reported
>> by a ticket (https://forum.opnsense.org/index.php?topic=879.0) ..can
>> this be true???
>
> You misread that ticket. It is not about logging. It is about other things.
>
> If you are logging with the TCP or UDP log modules then IPv6 might
> matter. For local files its not related.
>
>>
>> /var/log/squid3/*.log {
>>         daily
>>         compress
>>         delaycompress
>>         rotate 2
>>         missingok
>>         nocreate
>>         sharedscripts
>>         postrotate
>>                 test ! -e /var/run/squid3.pid || test ! -x
>> /usr/sbin/squid3 || /usr/sbin/squid3 -k rotate
>>         endscript
>> }
>>
>
> Okay, thats the script that used to be bundled with Squid in Debian.
>
> However, you need to know that use of logrotate requires Squid to have
> "logfile_rotate 0" configured. Debian packages patch that in as a
> default config setting.
>
> If you don't have that some weird things happen.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Wed Jun 22 16:48:58 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jun 2016 04:48:58 +1200
Subject: [squid-users] Unknown Cipher Suite
In-Reply-To: <1466611975.2449.10.camel@slave-tothe-box.net>
References: <1466611975.2449.10.camel@slave-tothe-box.net>
Message-ID: <a23bb9fe-7157-7556-207c-02202fe6ee65@treenet.co.nz>

On 23/06/2016 4:12 a.m., James Lay wrote:
> Well this is new....started seeing this on Instagram.  Message I get
> when debugging:
> 
> 2016/06/22 09:43:26| Error negotiating SSL on FD 14: error:140920F8:SSL
> routines:SSL3_GET_SERVER_HELLO:unknown cipher returned (1/-1/0)
> 
> And sure enough...even Wireshark doesn't know what this is:
> 
> 
> Any hints on how what this is/how to fix?  Thanks all.
> 

Thats the new ChaCha and Poly1305 ciphers being used.

Time to update your OpenSSL library version. Maybe your Squid as well if
you are using anything older than current latest.

Amos



From yvoinov at gmail.com  Wed Jun 22 16:58:58 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 22 Jun 2016 22:58:58 +0600
Subject: [squid-users] Unknown Cipher Suite
In-Reply-To: <a23bb9fe-7157-7556-207c-02202fe6ee65@treenet.co.nz>
References: <1466611975.2449.10.camel@slave-tothe-box.net>
 <a23bb9fe-7157-7556-207c-02202fe6ee65@treenet.co.nz>
Message-ID: <e4430f82-9cb2-6a44-0d41-ffeb259ed398@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
OpenSSL still not support ChaCha-Poly this days. And unknown when be
supported.

This time only exists unsupported patch from CloudFlare. And, as
alternative, LibreSSL. Which is not available for all platforms.

22.06.2016 22:48, Amos Jeffries ?????:
> On 23/06/2016 4:12 a.m., James Lay wrote:
>> Well this is new....started seeing this on Instagram.  Message I get
>> when debugging:
>>
>> 2016/06/22 09:43:26| Error negotiating SSL on FD 14: error:140920F8:SSL
>> routines:SSL3_GET_SERVER_HELLO:unknown cipher returned (1/-1/0)
>>
>> And sure enough...even Wireshark doesn't know what this is:
>>
>>
>> Any hints on how what this is/how to fix?  Thanks all.
>>
>
> Thats the new ChaCha and Poly1305 ciphers being used.
>
> Time to update your OpenSSL library version. Maybe your Squid as well if
> you are using anything older than current latest.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXasPRAAoJENNXIZxhPexG4VQH/2DwHdyrdfo9JHwDrpos/Hj/
6ZjJ30IFShPMPyLEAvTrkp3GrSvxaPHpn4VLBEa6LboW3ZA73dENfZmclBZPxPCx
76BOMFXameyNh/8QfYq72DyWwBnErxDTLlSHazikv7eNZDUYxuwHRUeTSWQdHOUs
ATjDwAseHFxpc0JygwjM+i4d0zM+owUm8IlkcSzrp7lqlajMEQa4LD0YIRbC3iDi
9JeI726nbKtZDwkrSylRIUZUiIEbN+ZwIx61aXi6EoxQa3U7+gcH33HxuynvxF8B
VzAfFrasLSI5XCV9AAt3J0sXxMqsFWzl0XKCIUA3Ki6uk0yaOm2/cKstPag5T+4=
=EQId
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/ce62970e/attachment.key>

From jblank at twu.net  Wed Jun 22 16:54:17 2016
From: jblank at twu.net (jblank at twu.net)
Date: Wed, 22 Jun 2016 11:54:17 -0500 (CDT)
Subject: [squid-users] Forward loop when intercepting mode to proxy
 traffic to local VM
In-Reply-To: <9e96c8cd-7eb8-150a-15d5-fd3da970931e@treenet.co.nz>
References: <alpine.DEB.2.02.1606220543010.12819@eowyn.twu.net>
 <alpine.DEB.2.02.1606220614560.12819@eowyn.twu.net>
 <9e96c8cd-7eb8-150a-15d5-fd3da970931e@treenet.co.nz>
Message-ID: <alpine.DEB.2.02.1606221152450.12819@eowyn.twu.net>

To be honest, I am not 100% clear on Squid's various modes. If reverse 
proxy mode is capable of doing the decrypt/re-encrypt stuff, I'm fine 
with using it. Any pointers to HOWTOs or FAQs that might help?

Best,

Jessica

On Thu, 23 Jun 2016, Amos Jeffries wrote:

> On 22/06/2016 11:15 p.m., jblank wrote:
>> Slight correction on the Subject (my bad); I meant "when using intercept
>> mode", not "when intercepting mode".
>> 
>> On Wed, 22 Jun 2016, jblank wrote:
>> 
>>> Hey all,
>>>
>>> Thanks to a bizarre client requirement (don't ask, it's head-hurty), I
>>> am required to maintain a legacy server which only supports obsolete
>>> SHA-1 encryption. To keep things relatively safe, I'm attempting to
>>> contain the problem within a VM and use Squid on the VM's host to
>>> "re-encrypt" incoming traffic.
>>>
>>> That is:
>>> Outside world talks SHA2 to Squid; Squid internally talks SHA1 to the
>>> VM; Squid gets the response from the VM and passes it along
>>> (re-encrypting it to SHA2).
>
> Okay. That sounds simple. But the use of intercept implies things are a
> bit more complex for Squids situation.
>
> Is there a particular reason you are using interception?
>
> The next TLS / HTTPS stages of your task would be much less headache to
> do as a reverse-proxy.
>
>
>>>
>>> At least, that's the idea. But forget about SSL/encryption for the
>>> moment; I can't even get this concept working with plain old
>>> unencrypted HTTP.
>>>
>>> The VM is running locally, and accessible via host-only networking on
>>> 192.168.1.101. I set up a local /etc/hosts alternative JUST for
>>> Squid's use, which tells Squid that "myhost.mydomain.com" is actually
>>> 192.168.1.101. Yet Squid seems to be ignoring this. Incoming requests
>>> for http://myhost.mydomain.com/ throw a standard Squid "Access
>>> Denied." page. cache.log reveals the presence of a forward loop:
>>>
> <snip>
>
> Correct way to use a static link to a specific upstream is to use the
> cache_peer directive to tell Squid about that link and any fancy stuff
> about it.
>
> So this config should just work for both http:// and https:// traffic
> destined to the VM:
>
> # use the URL domain instead of raw-IPs
> acl VM_domains dstdomain example.com
> http_access allow VM_domains
>
> acl HTTPS proto HTTPS
>
> # The HTTP if you want it, remove these lines if not
> cache_peer 192.168.1.101 parent 80 0 originserver name=VM_http
> cache_peer_access VM_http allow HTTPS VM_domains
> cache_peer_access VM_http deny all
>
> # The HTTPS if you want it. Should work as-is but might need
> # other ssl* options for specific TLS/SSL tuning. see the TLS section
> # of http://www.squid-cache.org/Doc/config/cache_peer/ for details.
> cache_peer 192.168.1.101 parent 443 0 originserver ssl name=VM_https
> cache_peer_access VM_https allow !HTTPS VM_domains
> cache_peer_access VM_https deny all
>
>
> Note that Squid does not need hosts file entries for this to work.
>
> Also, the warning about forward proxy ports is because you dropped the
> default "http_port 3128" line. Add it back (or use reverse-proxy) and
> those will disappear.
>
>
> Cheers
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Wed Jun 22 17:02:34 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jun 2016 05:02:34 +1200
Subject: [squid-users] Squid3 error: CHILD: hello write test failed
 logrotate
In-Reply-To: <CAG2Qp6t2j5VRreWg2Vz7D3bgLWOvFtwfsVUGkPpqVEVGaZLsJA@mail.gmail.com>
References: <CAG2Qp6vFPYshkxFa5d3uGN0zAW2L6z_nv9-TY8-iOyknofHUnw@mail.gmail.com>
 <201606221529.38478.Antony.Stone@squid.open.source.it>
 <CAG2Qp6sfMBY_i1r097LKce6hRNQb3m5F3QHq+BTBKPyEkDiTnQ@mail.gmail.com>
 <170232bb-117b-c395-d0d0-e8dcf73e7b52@treenet.co.nz>
 <CAG2Qp6t2j5VRreWg2Vz7D3bgLWOvFtwfsVUGkPpqVEVGaZLsJA@mail.gmail.com>
Message-ID: <29964478-2b7f-f97d-45e5-0d5858470f64@treenet.co.nz>

On 23/06/2016 4:32 a.m., Roberto Carna wrote:
> Amos and Antony, thanks a lot for your help.
> 
> At first, I'll enable IPv6 in my Debian box.
> 
> And for the log problem, I couldn't understand what yoy said
> Amos...please can you detail what I have to do in order to avoid log
> rotation problems???

Add this to your squid.conf:

 logfile_rotate 0

Amos



From jlay at slave-tothe-box.net  Wed Jun 22 17:20:19 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Wed, 22 Jun 2016 11:20:19 -0600
Subject: [squid-users] Unknown Cipher Suite
In-Reply-To: <e4430f82-9cb2-6a44-0d41-ffeb259ed398@gmail.com>
References: <1466611975.2449.10.camel@slave-tothe-box.net>
 <a23bb9fe-7157-7556-207c-02202fe6ee65@treenet.co.nz>
 <e4430f82-9cb2-6a44-0d41-ffeb259ed398@gmail.com>
Message-ID: <1466616019.2449.16.camel@slave-tothe-box.net>

Ah crud...well shoot...thanks for the information...means I'll have to
bypass it for now..and using latest Squid...always keep it updated ; -
) ?Thank you.
James
On Wed, 2016-06-22 at 22:58 +0600, Yuri Voinov wrote:
> OpenSSL still not support ChaCha-Poly this days. And unknown when be
> supported.
> 
> This time only exists unsupported patch from CloudFlare. And, as
> alternative, LibreSSL. Which is not available for all platforms.
> 
> 22.06.2016 22:48, Amos Jeffries ?????:
> > 
> > On 23/06/2016 4:12 a.m., James Lay wrote:
> > > 
> > > Well this is new....started seeing this on Instagram.??Message I
> > > get
> > > when debugging:
> > > 
> > > 2016/06/22 09:43:26| Error negotiating SSL on FD 14:
> > > error:140920F8:SSL
> > > routines:SSL3_GET_SERVER_HELLO:unknown cipher returned (1/-1/0)
> > > 
> > > And sure enough...even Wireshark doesn't know what this is:
> > > 
> > > 
> > > Any hints on how what this is/how to fix???Thanks all.
> > > 
> > Thats the new ChaCha and Poly1305 ciphers being used.
> > 
> > Time to update your OpenSSL library version. Maybe your Squid as
> > well if
> > you are using anything older than current latest.
> > 
> > Amos
> > 
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/8fff2e55/attachment.htm>

From Sebastien.Boulianne at cpu.ca  Wed Jun 22 19:07:05 2016
From: Sebastien.Boulianne at cpu.ca (Sebastien.Boulianne at cpu.ca)
Date: Wed, 22 Jun 2016 15:07:05 -0400
Subject: [squid-users] WTF ? SSL Certficate error: certificate issuer (CA)
	not known
Message-ID: <5FE0959288C73D448BB44CB7E9CC320F5837FD1BE5@CPUMAIL2.cpu.qc.ca>

Huuuuuuuuuuuuu ?

My CA is known... Where is the issue ? :(
The system returned:
(71) Protocol error (TLS code: X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
SSL Certficate error: certificate issuer (CA) not known: /C=US/ST=Arizona/L=Scottsdale/O=Starfield Technologies, Inc./OU=http://certs.starfieldtech.com/repository//CN=Starfield Secure Certificate Authority - G2
Sebastien
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/1ad2e164/attachment.htm>

From yvoinov at gmail.com  Wed Jun 22 19:10:14 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 23 Jun 2016 01:10:14 +0600
Subject: [squid-users] WTF ? SSL Certficate error: certificate issuer
 (CA) not known
In-Reply-To: <5FE0959288C73D448BB44CB7E9CC320F5837FD1BE5@CPUMAIL2.cpu.qc.ca>
References: <5FE0959288C73D448BB44CB7E9CC320F5837FD1BE5@CPUMAIL2.cpu.qc.ca>
Message-ID: <ec7a2d6e-d9c6-ef52-cb57-1f4698a1a3e2@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Unknown intermediate certificate, that's all.

Dig to the direction sslproxy_foreign_intermediate_certs parameter.


23.06.2016 1:07, Sebastien.Boulianne at cpu.ca ?????:
>
> Huuuuuuuuuuuuu ?
>
> 
>
> My CA is known? Where is the issue ? :(
>
> The system returned:
>
> (71) Protocol error (TLS code:
X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
>
> SSL Certficate error: certificate issuer (CA) not known:
/C=US/ST=Arizona/L=Scottsdale/O=Starfield Technologies,
Inc./OU=http://certs.starfieldtech.com/repository//CN=Starfield Secure
Certificate Authority - G2
>
> Sebastien
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXauKWAAoJENNXIZxhPexG9k8H/0mZ96kxDIcrdcYgPidsni09
2dncdG9kQi0mERqbtWYs75nmNVNTXHrMFIBHuzzgqQO3oCUrsCYkEpUi31j88Ll5
c86ldMNHa4YDFkuK1h9FjZzq1SQfES7M9HhTvVjeZKpRTx8WrZDyL4nE8OUD37eM
M9huaEl7UwrWuSVW4wy0OK8dopoDej+JzyBDWMVCz7h8wlLsprQMnWrZBbWt2WhT
2SM0ntO2ewPTMxeKIrqYRf9abDJrFlMdfNU9BjMZN6O2D5biM/lKt/nfcMjRDhlL
eWoSohM3xO2z8TqYUILNV4vd/6bWdApo97DI56Zi01fKi7ROiftom8OHNd16jNo=
=VHep
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160623/076c23c2/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160623/076c23c2/attachment.key>

From jlay at slave-tothe-box.net  Wed Jun 22 19:29:34 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Wed, 22 Jun 2016 13:29:34 -0600
Subject: [squid-users] Latest ssl and Squid stable compile issue
Message-ID: <1466623774.2449.31.camel@slave-tothe-box.net>

So yea...git pulled latest ssl, here's my results:

make[3]: Entering directory `/home/nobackup/build/squid-
3.5.19/src/anyp'
depbase=`echo PortCfg.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
	/bin/bash ../../libtool??--tag=CXX???--mode=compile g++
-DHAVE_CONFIG_H???-I../.. -I../../include -I../../lib -I../../src
-I../../include????-I/opt/openssl/include??-Wall -Wpointer-arith
-Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -Werror -pipe
-D_REENTRANT -m64???-g -O2 -march=native -std=c++11 -MT PortCfg.lo -MD
-MP -MF $depbase.Tpo -c -o PortCfg.lo PortCfg.cc &&\
	mv -f $depbase.Tpo $depbase.Plo
libtool: compile:??g++ -DHAVE_CONFIG_H -I../.. -I../../include
-I../../lib -I../../src -I../../include -I/opt/openssl/include -Wall
-Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Woverloaded-
virtual -Werror -pipe -D_REENTRANT -m64 -g -O2 -march=native -std=c++11
-MT PortCfg.lo -MD -MP -MF .deps/PortCfg.Tpo -c PortCfg.cc??-fPIC -DPIC
-o .libs/PortCfg.o
In file included from ../../src/anyp/PortCfg.h:18:0,
?????????????????from PortCfg.cc:10:
../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not
declared in this scope
?typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509>
X509_Pointer;
?????????????????????????????????????????????^
../../src/ssl/gadgets.h:83:61: error: template argument 3 is invalid
?typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509>
X509_Pointer;
?????????????????????????????????????????????????????????????^
../../src/ssl/gadgets.h:83:75: error: invalid type in declaration
before ?;? token
?typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509>
X509_Pointer;
???????????????????????????????????????????????????????????????????????
????^
../../src/ssl/gadgets.h:89:53: error: ?CRYPTO_LOCK_EVP_PKEY? was not
declared in this scope
?typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp,
CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;
?????????????????????????????????????????????????????^
../../src/ssl/gadgets.h:89:73: error: template argument 3 is invalid
?typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp,
CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;
???????????????????????????????????????????????????????????????????????
??^
../../src/ssl/gadgets.h:89:91: error: invalid type in declaration
before ?;? token
?typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp,
CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;
???????????????????????????????????????????????????????????????????????
????????????????????^
../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not
declared in this scope
?typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL>
SSL_Pointer;
???????????????????????????????????????????^
../../src/ssl/gadgets.h:116:58: error: template argument 3 is invalid
?typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL>
SSL_Pointer;
??????????????????????????????????????????????????????????^
../../src/ssl/gadgets.h:116:71: error: invalid type in declaration
before ?;? token
?typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL>
SSL_Pointer;
???????????????????????????????????????????????????????????????????????
^
make[3]: *** [PortCfg.lo] Error 1
make[3]: Leaving directory `/home/jlay/nobackup/build/squid-
3.5.19/src/anyp'
make[2]: *** [all-recursive] Error 1
make[2]: Leaving directory `/home/jlay/nobackup/build/squid-3.5.19/src'

make[1]: *** [all] Error 2
make[1]: Leaving directory `/home/jlay/nobackup/build/squid-3.5.19/src'

make: *** [all-recursive] Error 1

This is to hopefully compile in chacha support....should I go with dev
4.0.11 squid instead? ?Thank you.

James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/a45a894d/attachment.htm>

From robertocarna36 at gmail.com  Wed Jun 22 20:48:07 2016
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Wed, 22 Jun 2016 17:48:07 -0300
Subject: [squid-users] Squid3 error: CHILD: hello write test failed
	logrotate
In-Reply-To: <29964478-2b7f-f97d-45e5-0d5858470f64@treenet.co.nz>
References: <CAG2Qp6vFPYshkxFa5d3uGN0zAW2L6z_nv9-TY8-iOyknofHUnw@mail.gmail.com>
 <201606221529.38478.Antony.Stone@squid.open.source.it>
 <CAG2Qp6sfMBY_i1r097LKce6hRNQb3m5F3QHq+BTBKPyEkDiTnQ@mail.gmail.com>
 <170232bb-117b-c395-d0d0-e8dcf73e7b52@treenet.co.nz>
 <CAG2Qp6t2j5VRreWg2Vz7D3bgLWOvFtwfsVUGkPpqVEVGaZLsJA@mail.gmail.com>
 <29964478-2b7f-f97d-45e5-0d5858470f64@treenet.co.nz>
Message-ID: <CAG2Qp6t8nKiZe8O5bqfcaGpyo1FUBK8piQHsLoBeUcZZT2pOdg@mail.gmail.com>

OK, I'll do that.

And what about the "nocreate" option in the logrotate file for
squid3???Do I have to delete or change for waht option???

Thanks a lot again, this is my last question.

2016-06-22 14:02 GMT-03:00 Amos Jeffries <squid3 at treenet.co.nz>:
> On 23/06/2016 4:32 a.m., Roberto Carna wrote:
>> Amos and Antony, thanks a lot for your help.
>>
>> At first, I'll enable IPv6 in my Debian box.
>>
>> And for the log problem, I couldn't understand what yoy said
>> Amos...please can you detail what I have to do in order to avoid log
>> rotation problems???
>
> Add this to your squid.conf:
>
>  logfile_rotate 0
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From jlay at slave-tothe-box.net  Wed Jun 22 21:12:23 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Wed, 22 Jun 2016 15:12:23 -0600
Subject: [squid-users] Latest ssl and Squid stable compile issue
In-Reply-To: <1466623774.2449.31.camel@slave-tothe-box.net>
References: <1466623774.2449.31.camel@slave-tothe-box.net>
Message-ID: <25e989a8b49b8efbb0113ed20b3d3cf3@localhost>

Had zero issues when compiling against libressl-2.4.1.  I now have 
ChaCha Poly cipher support...happy days!

James

On 2016-06-22 13:29, James Lay wrote:
> So yea...git pulled latest ssl, here's my results:
> 
> make[3]: Entering directory
> `/home/nobackup/build/squid-3.5.19/src/anyp'
> depbase=`echo PortCfg.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
>  /bin/bash ../../libtool  --tag=CXX   --mode=compile g++
> -DHAVE_CONFIG_H   -I../.. -I../../include -I../../lib -I../../src
> -I../../include    -I/opt/openssl/include  -Wall -Wpointer-arith
> -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -Werror -pipe
> -D_REENTRANT -m64   -g -O2 -march=native -std=c++11 -MT PortCfg.lo -MD
> -MP -MF $depbase.Tpo -c -o PortCfg.lo PortCfg.cc &&\
>  mv -f $depbase.Tpo $depbase.Plo
> libtool: compile:  g++ -DHAVE_CONFIG_H -I../.. -I../../include
> -I../../lib -I../../src -I../../include -I/opt/openssl/include -Wall
> -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow
> -Woverloaded-virtual -Werror -pipe -D_REENTRANT -m64 -g -O2
> -march=native -std=c++11 -MT PortCfg.lo -MD -MP -MF .deps/PortCfg.Tpo
> -c PortCfg.cc  -fPIC -DPIC -o .libs/PortCfg.o
> In file included from ../../src/anyp/PortCfg.h:18:0,
>                  from PortCfg.cc:10:
> ../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not
> declared in this scope
>  typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509>
> X509_Pointer;
>                                              ^
> ../../src/ssl/gadgets.h:83:61: error: template argument 3 is invalid
>  typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509>
> X509_Pointer;
>                                                              ^
> ../../src/ssl/gadgets.h:83:75: error: invalid type in declaration
> before ?;? token
>  typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509>
> X509_Pointer;
> 
>     ^
> ../../src/ssl/gadgets.h:89:53: error: ?CRYPTO_LOCK_EVP_PKEY? was
> not declared in this scope
>  typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp,
> CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;
>                                                      ^
> ../../src/ssl/gadgets.h:89:73: error: template argument 3 is invalid
>  typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp,
> CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;
> 
>   ^
> ../../src/ssl/gadgets.h:89:91: error: invalid type in declaration
> before ?;? token
>  typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp,
> CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;
> 
>                     ^
> ../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not
> declared in this scope
>  typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL>
> SSL_Pointer;
>                                            ^
> ../../src/ssl/gadgets.h:116:58: error: template argument 3 is invalid
>  typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL>
> SSL_Pointer;
>                                                           ^
> ../../src/ssl/gadgets.h:116:71: error: invalid type in declaration
> before ?;? token
>  typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL>
> SSL_Pointer;
> 
> ^
> make[3]: *** [PortCfg.lo] Error 1
> make[3]: Leaving directory
> `/home/jlay/nobackup/build/squid-3.5.19/src/anyp'
> make[2]: *** [all-recursive] Error 1
> make[2]: Leaving directory
> `/home/jlay/nobackup/build/squid-3.5.19/src'
> make[1]: *** [all] Error 2
> make[1]: Leaving directory
> `/home/jlay/nobackup/build/squid-3.5.19/src'
> make: *** [all-recursive] Error 1
> 
> This is to hopefully compile in chacha support....should I go with dev
> 4.0.11 squid instead?  Thank you.
> 
> James
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From yvoinov at gmail.com  Wed Jun 22 21:17:51 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 23 Jun 2016 03:17:51 +0600
Subject: [squid-users] Latest ssl and Squid stable compile issue
In-Reply-To: <25e989a8b49b8efbb0113ed20b3d3cf3@localhost>
References: <1466623774.2449.31.camel@slave-tothe-box.net>
 <25e989a8b49b8efbb0113ed20b3d3cf3@localhost>
Message-ID: <49f1a0a0-8404-5a7d-713b-89dac460ca30@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I suggest this will not solve your unknown cipher issue. :)


23.06.2016 3:12, James Lay ?????:
> Had zero issues when compiling against libressl-2.4.1.  I now have ChaCha Poly cipher support...happy
days!
>
> James
>
> On 2016-06-22 13:29, James Lay wrote:
>> So yea...git pulled latest ssl, here's my results:
>>
>> make[3]: Entering directory
>> `/home/nobackup/build/squid-3.5.19/src/anyp'
>> depbase=`echo PortCfg.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
>>  /bin/bash ../../libtool  --tag=CXX   --mode=compile g++
>> -DHAVE_CONFIG_H   -I../.. -I../../include -I../../lib -I../../src
>> -I../../include    -I/opt/openssl/include  -Wall -Wpointer-arith
>> -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -Werror -pipe
>> -D_REENTRANT -m64   -g -O2 -march=native -std=c++11 -MT PortCfg.lo -MD
>> -MP -MF $depbase.Tpo -c -o PortCfg.lo PortCfg.cc &&\
>>  mv -f $depbase.Tpo $depbase.Plo
>> libtool: compile:  g++ -DHAVE_CONFIG_H -I../.. -I../../include
>> -I../../lib -I../../src -I../../include -I/opt/openssl/include -Wall
>> -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow
>> -Woverloaded-virtual -Werror -pipe -D_REENTRANT -m64 -g -O2
>> -march=native -std=c++11 -MT PortCfg.lo -MD -MP -MF .deps/PortCfg.Tpo
>> -c PortCfg.cc  -fPIC -DPIC -o .libs/PortCfg.o
>> In file included from ../../src/anyp/PortCfg.h:18:0,
>>                  from PortCfg.cc:10:
>> ../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not
>> declared in this scope
>>  typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509>
>> X509_Pointer;
>>                                              ^
>> ../../src/ssl/gadgets.h:83:61: error: template argument 3 is invalid
>>  typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509>
>> X509_Pointer;
>>                                                              ^
>> ../../src/ssl/gadgets.h:83:75: error: invalid type in declaration
>> before ?;? token
>>  typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509>
>> X509_Pointer;
>>
>>     ^
>> ../../src/ssl/gadgets.h:89:53: error: ?CRYPTO_LOCK_EVP_PKEY? was
>> not declared in this scope
>>  typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp,
>> CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;
>>                                                      ^
>> ../../src/ssl/gadgets.h:89:73: error: template argument 3 is invalid
>>  typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp,
>> CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;
>>
>>   ^
>> ../../src/ssl/gadgets.h:89:91: error: invalid type in declaration
>> before ?;? token
>>  typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp,
>> CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;
>>
>>                     ^
>> ../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not
>> declared in this scope
>>  typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL>
>> SSL_Pointer;
>>                                            ^
>> ../../src/ssl/gadgets.h:116:58: error: template argument 3 is invalid
>>  typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL>
>> SSL_Pointer;
>>                                                           ^
>> ../../src/ssl/gadgets.h:116:71: error: invalid type in declaration
>> before ?;? token
>>  typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL>
>> SSL_Pointer;
>>
>> ^
>> make[3]: *** [PortCfg.lo] Error 1
>> make[3]: Leaving directory
>> `/home/jlay/nobackup/build/squid-3.5.19/src/anyp'
>> make[2]: *** [all-recursive] Error 1
>> make[2]: Leaving directory
>> `/home/jlay/nobackup/build/squid-3.5.19/src'
>> make[1]: *** [all] Error 2
>> make[1]: Leaving directory
>> `/home/jlay/nobackup/build/squid-3.5.19/src'
>> make: *** [all-recursive] Error 1
>>
>> This is to hopefully compile in chacha support....should I go with dev
>> 4.0.11 squid instead?  Thank you.
>>
>> James
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXawB+AAoJENNXIZxhPexGzXwH/3WAFGluGUDHx1BAIHjzCNvM
zGB0qFQaLTcSNACG7B7bNs5oDErCdxH7BUhwWC082L4Tu0FhZAivUYgD3GZZKuzr
QLjZ7wYcocXQsa1EVyVQaiQg4MdIpO6PRZniBq6pKephJrTFj9b3l3MYNcECNF6F
7Qla/Cocyf5hJpN7U6WxyzXOBB4CbecViGwMyQIBZ4s+B6B3BAHZaFg54UNGstqA
/qjwlMehh5Al/WntrJ1Ozfa59r0efiIO/VrvOylQf8HoR9gYBULq7tsl3EFGrsV2
08pcmXzQSJausCcllBWBnXKKTi4CWo/apkPE4puxYEcHLGSklqbOl7MK4oHkW44=
=TjQy
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160623/a07545a7/attachment.key>

From jlay at slave-tothe-box.net  Wed Jun 22 21:22:12 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Wed, 22 Jun 2016 15:22:12 -0600
Subject: [squid-users] Latest ssl and Squid stable compile issue
In-Reply-To: <49f1a0a0-8404-5a7d-713b-89dac460ca30@gmail.com>
References: <1466623774.2449.31.camel@slave-tothe-box.net>
 <25e989a8b49b8efbb0113ed20b3d3cf3@localhost>
 <49f1a0a0-8404-5a7d-713b-89dac460ca30@gmail.com>
Message-ID: <e75174e86fde52c915df58c0d9fbf21c@localhost>

It already has :)

Jun 22 09:41:09 gateway (squid-1): 192.168.1.109 - - 
[22/Jun/2016:09:41:09 -0600] "CONNECT 31.13.76.84:443 HTTP/1.1" 
i.instagram.com - 200 0 TAG_NONE:ORIGINAL_DST
Jun 22 15:09:26 gateway (squid-1): 192.168.1.109 - - 
[22/Jun/2016:15:09:26 -0600] "CONNECT 31.13.76.84:443 HTTP/1.1" 
i.instagram.com - 200 43538 TCP_TUNNEL:ORIGINAL_DST

The ole before and after trick :)  And:

strings /opt/libressl/bin/openssl | grep chacha
EVP_aead_chacha20_poly1305
chacha
  chacha20-poly1305
chacha20 poly1305
EVP_aead_chacha20_poly1305
EVP_aead_chacha20_poly1305

Woo hoo!

James

On 2016-06-22 15:17, Yuri Voinov wrote:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
> 
> I suggest this will not solve your unknown cipher issue. :)
> 
> 
> 23.06.2016 3:12, James Lay ?????:
>> Had zero issues when compiling against libressl-2.4.1.  I now have 
>> ChaCha Poly cipher support...happy
> days!
>> 
>> James
>> 
>> On 2016-06-22 13:29, James Lay wrote:
>>> So yea...git pulled latest ssl, here's my results:
>>> 
>>> make[3]: Entering directory
>>> `/home/nobackup/build/squid-3.5.19/src/anyp'
>>> depbase=`echo PortCfg.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
>>>  /bin/bash ../../libtool  --tag=CXX   --mode=compile g++
>>> -DHAVE_CONFIG_H   -I../.. -I../../include -I../../lib -I../../src
>>> -I../../include    -I/opt/openssl/include  -Wall -Wpointer-arith
>>> -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -Werror 
>>> -pipe
>>> -D_REENTRANT -m64   -g -O2 -march=native -std=c++11 -MT PortCfg.lo 
>>> -MD
>>> -MP -MF $depbase.Tpo -c -o PortCfg.lo PortCfg.cc &&\
>>>  mv -f $depbase.Tpo $depbase.Plo
>>> libtool: compile:  g++ -DHAVE_CONFIG_H -I../.. -I../../include
>>> -I../../lib -I../../src -I../../include -I/opt/openssl/include -Wall
>>> -Wpointer-arith -Wwrite-strings -Wcomments -Wshadow
>>> -Woverloaded-virtual -Werror -pipe -D_REENTRANT -m64 -g -O2
>>> -march=native -std=c++11 -MT PortCfg.lo -MD -MP -MF .deps/PortCfg.Tpo
>>> -c PortCfg.cc  -fPIC -DPIC -o .libs/PortCfg.o
>>> In file included from ../../src/anyp/PortCfg.h:18:0,
>>>                  from PortCfg.cc:10:
>>> ../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not
>>> declared in this scope
>>>  typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509>
>>> X509_Pointer;
>>>                                              ^
>>> ../../src/ssl/gadgets.h:83:61: error: template argument 3 is invalid
>>>  typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509>
>>> X509_Pointer;
>>>                                                              ^
>>> ../../src/ssl/gadgets.h:83:75: error: invalid type in declaration
>>> before ?;? token
>>>  typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509>
>>> X509_Pointer;
>>> 
>>>     ^
>>> ../../src/ssl/gadgets.h:89:53: error: ?CRYPTO_LOCK_EVP_PKEY? was
>>> not declared in this scope
>>>  typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp,
>>> CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;
>>>                                                      ^
>>> ../../src/ssl/gadgets.h:89:73: error: template argument 3 is invalid
>>>  typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp,
>>> CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;
>>> 
>>>   ^
>>> ../../src/ssl/gadgets.h:89:91: error: invalid type in declaration
>>> before ?;? token
>>>  typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp,
>>> CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;
>>> 
>>>                     ^
>>> ../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not
>>> declared in this scope
>>>  typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL>
>>> SSL_Pointer;
>>>                                            ^
>>> ../../src/ssl/gadgets.h:116:58: error: template argument 3 is invalid
>>>  typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL>
>>> SSL_Pointer;
>>>                                                           ^
>>> ../../src/ssl/gadgets.h:116:71: error: invalid type in declaration
>>> before ?;? token
>>>  typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL>
>>> SSL_Pointer;
>>> 
>>> ^
>>> make[3]: *** [PortCfg.lo] Error 1
>>> make[3]: Leaving directory
>>> `/home/jlay/nobackup/build/squid-3.5.19/src/anyp'
>>> make[2]: *** [all-recursive] Error 1
>>> make[2]: Leaving directory
>>> `/home/jlay/nobackup/build/squid-3.5.19/src'
>>> make[1]: *** [all] Error 2
>>> make[1]: Leaving directory
>>> `/home/jlay/nobackup/build/squid-3.5.19/src'
>>> make: *** [all-recursive] Error 1
>>> 
>>> This is to hopefully compile in chacha support....should I go with 
>>> dev
>>> 4.0.11 squid instead?  Thank you.
>>> 
>>> James
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
> 
> iQEcBAEBCAAGBQJXawB+AAoJENNXIZxhPexGzXwH/3WAFGluGUDHx1BAIHjzCNvM
> zGB0qFQaLTcSNACG7B7bNs5oDErCdxH7BUhwWC082L4Tu0FhZAivUYgD3GZZKuzr
> QLjZ7wYcocXQsa1EVyVQaiQg4MdIpO6PRZniBq6pKephJrTFj9b3l3MYNcECNF6F
> 7Qla/Cocyf5hJpN7U6WxyzXOBB4CbecViGwMyQIBZ4s+B6B3BAHZaFg54UNGstqA
> /qjwlMehh5Al/WntrJ1Ozfa59r0efiIO/VrvOylQf8HoR9gYBULq7tsl3EFGrsV2
> 08pcmXzQSJausCcllBWBnXKKTi4CWo/apkPE4puxYEcHLGSklqbOl7MK4oHkW44=
> =TjQy
> -----END PGP SIGNATURE-----
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From robertocarna36 at gmail.com  Wed Jun 22 21:28:56 2016
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Wed, 22 Jun 2016 18:28:56 -0300
Subject: [squid-users] Squid3 error: CHILD: hello write test failed
	logrotate
In-Reply-To: <170232bb-117b-c395-d0d0-e8dcf73e7b52@treenet.co.nz>
References: <CAG2Qp6vFPYshkxFa5d3uGN0zAW2L6z_nv9-TY8-iOyknofHUnw@mail.gmail.com>
 <201606221529.38478.Antony.Stone@squid.open.source.it>
 <CAG2Qp6sfMBY_i1r097LKce6hRNQb3m5F3QHq+BTBKPyEkDiTnQ@mail.gmail.com>
 <170232bb-117b-c395-d0d0-e8dcf73e7b52@treenet.co.nz>
Message-ID: <CAG2Qp6uhmkAeYxdUNiiSfw-M=qGd6aMc31hZuV=bvN_qQT0ccg@mail.gmail.com>

Amos, just a last comment:

My squid.conf from Squid3 has this line:

#Default:
# logfile_rotate 0

So the parameter you mentiones it's just setup.

Any other thing relative to log problem?

2016-06-22 11:42 GMT-03:00 Amos Jeffries <squid3 at treenet.co.nz>:
> On 23/06/2016 1:44 a.m., Roberto Carna wrote:
>> Dear Antony, thanks for your help..below is the
>> /etc/logrotate.d/squid3 file....but before I have to say I've seen in
>> the web that this problem is solved by enabling IPv6, and was reported
>> by a ticket (https://forum.opnsense.org/index.php?topic=879.0) ..can
>> this be true???
>
> You misread that ticket. It is not about logging. It is about other things.
>
> If you are logging with the TCP or UDP log modules then IPv6 might
> matter. For local files its not related.
>
>>
>> /var/log/squid3/*.log {
>>         daily
>>         compress
>>         delaycompress
>>         rotate 2
>>         missingok
>>         nocreate
>>         sharedscripts
>>         postrotate
>>                 test ! -e /var/run/squid3.pid || test ! -x
>> /usr/sbin/squid3 || /usr/sbin/squid3 -k rotate
>>         endscript
>> }
>>
>
> Okay, thats the script that used to be bundled with Squid in Debian.
>
> However, you need to know that use of logrotate requires Squid to have
> "logfile_rotate 0" configured. Debian packages patch that in as a
> default config setting.
>
> If you don't have that some weird things happen.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From Antony.Stone at squid.open.source.it  Wed Jun 22 21:33:38 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 22 Jun 2016 23:33:38 +0200
Subject: [squid-users] Squid3 error: CHILD: hello write test failed
	logrotate
In-Reply-To: <CAG2Qp6uhmkAeYxdUNiiSfw-M=qGd6aMc31hZuV=bvN_qQT0ccg@mail.gmail.com>
References: <CAG2Qp6vFPYshkxFa5d3uGN0zAW2L6z_nv9-TY8-iOyknofHUnw@mail.gmail.com>
 <170232bb-117b-c395-d0d0-e8dcf73e7b52@treenet.co.nz>
 <CAG2Qp6uhmkAeYxdUNiiSfw-M=qGd6aMc31hZuV=bvN_qQT0ccg@mail.gmail.com>
Message-ID: <201606222333.38444.Antony.Stone@squid.open.source.it>

On Wednesday 22 June 2016 at 23:28:56, Roberto Carna wrote:

> My squid.conf from Squid3 has this line:
> 
> #Default:
> # logfile_rotate 0
> 
> So the parameter you mentiones it's just setup.

You do realise that # at the start of a line means it is a comment and has no 
effect, right?


Antony.

-- 
Police have found a cartoonist dead in his house.  They say that details are 
currently sketchy.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From robertocarna36 at gmail.com  Wed Jun 22 22:17:46 2016
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Wed, 22 Jun 2016 19:17:46 -0300
Subject: [squid-users] Squid3 error: CHILD: hello write test failed
	logrotate
In-Reply-To: <CAG2Qp6uhmkAeYxdUNiiSfw-M=qGd6aMc31hZuV=bvN_qQT0ccg@mail.gmail.com>
References: <CAG2Qp6vFPYshkxFa5d3uGN0zAW2L6z_nv9-TY8-iOyknofHUnw@mail.gmail.com>
 <201606221529.38478.Antony.Stone@squid.open.source.it>
 <CAG2Qp6sfMBY_i1r097LKce6hRNQb3m5F3QHq+BTBKPyEkDiTnQ@mail.gmail.com>
 <170232bb-117b-c395-d0d0-e8dcf73e7b52@treenet.co.nz>
 <CAG2Qp6uhmkAeYxdUNiiSfw-M=qGd6aMc31hZuV=bvN_qQT0ccg@mail.gmail.com>
Message-ID: <CAG2Qp6vshSnkSVkOHnHECPsTF91JHixeNmJHWVUJ7Ho4b-m0Kw@mail.gmail.com>

OK Antony thank you!!!!!!!!!!

2016-06-22 18:28 GMT-03:00 Roberto Carna <robertocarna36 at gmail.com>:
> Amos, just a last comment:
>
> My squid.conf from Squid3 has this line:
>
> #Default:
> # logfile_rotate 0
>
> So the parameter you mentiones it's just setup.
>
> Any other thing relative to log problem?
>
> 2016-06-22 11:42 GMT-03:00 Amos Jeffries <squid3 at treenet.co.nz>:
>> On 23/06/2016 1:44 a.m., Roberto Carna wrote:
>>> Dear Antony, thanks for your help..below is the
>>> /etc/logrotate.d/squid3 file....but before I have to say I've seen in
>>> the web that this problem is solved by enabling IPv6, and was reported
>>> by a ticket (https://forum.opnsense.org/index.php?topic=879.0) ..can
>>> this be true???
>>
>> You misread that ticket. It is not about logging. It is about other things.
>>
>> If you are logging with the TCP or UDP log modules then IPv6 might
>> matter. For local files its not related.
>>
>>>
>>> /var/log/squid3/*.log {
>>>         daily
>>>         compress
>>>         delaycompress
>>>         rotate 2
>>>         missingok
>>>         nocreate
>>>         sharedscripts
>>>         postrotate
>>>                 test ! -e /var/run/squid3.pid || test ! -x
>>> /usr/sbin/squid3 || /usr/sbin/squid3 -k rotate
>>>         endscript
>>> }
>>>
>>
>> Okay, thats the script that used to be bundled with Squid in Debian.
>>
>> However, you need to know that use of logrotate requires Squid to have
>> "logfile_rotate 0" configured. Debian packages patch that in as a
>> default config setting.
>>
>> If you don't have that some weird things happen.
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users


From aco1967 at gmail.com  Wed Jun 22 23:08:33 2016
From: aco1967 at gmail.com (Alejandro Cabrera Obed)
Date: Wed, 22 Jun 2016 20:08:33 -0300
Subject: [squid-users] Squid3: icmp_sock: (97) Address family not supported
 by protocol / pinger: Unable to start ICMPv6 pinger
Message-ID: <CAM0WvY7aZ526EUx3oZaG7MPy_xd=GQRw6Xj=n-QBo=C7oW636A@mail.gmail.com>

Hi people, when I start squid3 service, I have these lines in the
/var/log/squid3/cache.log file:

2016/06/22 19:56:35 kid1| Pinger socket opened on FD 12
2016/06/22 19:56:35| pinger: Initialising ICMP pinger ...
2016/06/22 19:56:35| pinger: ICMP socket opened.
2016/06/22 19:56:35|  icmp_sock: (97) Address family not supported by
protocol
2016/06/22 19:56:35| pinger: Unable to start ICMPv6 pinger.

But after that the squid3 daemon runs OK.

My pinger file is:

-rwsr-xr-x 1 root root 18224 March 22 10:50 /usr/lib/squid3/pinger

I use Debian 8 and  squid3 3.4.8-6+deb8u2 (amd64), and I haven't disabled
the IPv6 protocol, no references in /etc/default/grub neither in systcl
asociated file.

What do the pinger relative lines mean??? Do I have to pay attention or
just forget them ??

Really thanks

-- 
 //  Alejandro   //
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/859e91f6/attachment.htm>

From Antony.Stone at squid.open.source.it  Wed Jun 22 23:16:33 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 23 Jun 2016 01:16:33 +0200
Subject: [squid-users] Squid3: icmp_sock: (97) Address family not
	supported by protocol / pinger: Unable to start ICMPv6 pinger
In-Reply-To: <CAM0WvY7aZ526EUx3oZaG7MPy_xd=GQRw6Xj=n-QBo=C7oW636A@mail.gmail.com>
References: <CAM0WvY7aZ526EUx3oZaG7MPy_xd=GQRw6Xj=n-QBo=C7oW636A@mail.gmail.com>
Message-ID: <201606230116.33446.Antony.Stone@squid.open.source.it>

On Thursday 23 June 2016 at 01:08:33, Alejandro Cabrera Obed wrote:

> 2016/06/22 19:56:35| pinger: Unable to start ICMPv6 pinger.
> 
> But after that the squid3 daemon runs OK.

What's the output from "ifconfig" on that machine?

Antony.

-- 
It may not seem obvious, but (6 x 5 + 5) x 5 - 55 equals 5!

                                                   Please reply to the list;
                                                         please *don't* CC me.


From aco1967 at gmail.com  Wed Jun 22 23:22:45 2016
From: aco1967 at gmail.com (Alejandro Cabrera Obed)
Date: Wed, 22 Jun 2016 20:22:45 -0300
Subject: [squid-users] Squid3: icmp_sock: (97) Address family not
 supported by protocol / pinger: Unable to start ICMPv6 pinger
In-Reply-To: <201606230116.33446.Antony.Stone@squid.open.source.it>
References: <CAM0WvY7aZ526EUx3oZaG7MPy_xd=GQRw6Xj=n-QBo=C7oW636A@mail.gmail.com>
 <201606230116.33446.Antony.Stone@squid.open.source.it>
Message-ID: <CAM0WvY49gXPzL96GS_H6Fg-yddG21Ss2zKk0f2E1GdXWtFCTYA@mail.gmail.com>

#ifconfig

eth0      Link encap:Ethernet  HWaddr 00:50:53:b2:6e:88
          inet addr:10.17.133.114  Bcast:10.17.135.255  Mask:255.255.252.0
          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1
          RX packets:4488 errors:0 dropped:96 overruns:0 frame:0
          TX packets:986 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:1000
          RX bytes:328836 (321.1 KiB)  TX bytes:434907 (424.7 KiB)

lo        Link encap:Local Loopback
          inet addr:127.0.0.1  Mask:255.0.0.0
          UP LOOPBACK RUNNING  MTU:65536  Metric:1
          RX packets:78 errors:0 dropped:0 overruns:0 frame:0
          TX packets:78 errors:0 dropped:0 overruns:0 carrier:0
          collisions:0 txqueuelen:0
          RX bytes:10397 (10.1 KiB)  TX bytes:10397 (10.1 KiB)

May I have to avoid the use of pinger???

Because I have and older installation with Squid3 3.1.20 and no pinger is
present.

Thanks again!!!


2016-06-22 20:16 GMT-03:00 Antony Stone <Antony.Stone at squid.open.source.it>:

> On Thursday 23 June 2016 at 01:08:33, Alejandro Cabrera Obed wrote:
>
> > 2016/06/22 19:56:35| pinger: Unable to start ICMPv6 pinger.
> >
> > But after that the squid3 daemon runs OK.
>
> What's the output from "ifconfig" on that machine?
>
> Antony.
>
> --
> It may not seem obvious, but (6 x 5 + 5) x 5 - 55 equals 5!
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
 //  Alejandro   //
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/f948974b/attachment.htm>

From Antony.Stone at squid.open.source.it  Wed Jun 22 23:37:17 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 23 Jun 2016 01:37:17 +0200
Subject: [squid-users] Squid3: icmp_sock: (97) Address family not
	supported by protocol / pinger: Unable to start ICMPv6 pinger
In-Reply-To: <CAM0WvY49gXPzL96GS_H6Fg-yddG21Ss2zKk0f2E1GdXWtFCTYA@mail.gmail.com>
References: <CAM0WvY7aZ526EUx3oZaG7MPy_xd=GQRw6Xj=n-QBo=C7oW636A@mail.gmail.com>
 <201606230116.33446.Antony.Stone@squid.open.source.it>
 <CAM0WvY49gXPzL96GS_H6Fg-yddG21Ss2zKk0f2E1GdXWtFCTYA@mail.gmail.com>
Message-ID: <201606230137.17803.Antony.Stone@squid.open.source.it>

On Thursday 23 June 2016 at 01:22:45, Alejandro Cabrera Obed wrote:

> #ifconfig
> 
> eth0      Link encap:Ethernet  HWaddr 00:50:53:b2:6e:88
>           inet addr:10.17.133.114  Bcast:10.17.135.255  Mask:255.255.252.0
> 
> lo        Link encap:Local Loopback
>           inet addr:127.0.0.1  Mask:255.0.0.0

Well, that certainly confirms that IPv6 is disabled on your machine (from the 
lack of lines such as "inet6 addr:").

You say "I haven't disabled the IPv6 protocol, no references in 
/etc/default/grub neither in systcl asociated file."

Something (or someone) has certainly disabled IPv6 on this machine, though.

What are the outputs from:

	grep -v ^# /etc/default/networking

	cat /etc/network/interfaces

?

Antony.

-- 
"It is easy to be blinded to the essential uselessness of them by the sense of 
achievement you get from getting them to work at all. In other words - and 
this is the rock solid principle on which the whole of the Corporation's 
Galaxy-wide success is founded - their fundamental design flaws are completely 
hidden by their superficial design flaws."

 - Douglas Noel Adams

                                                   Please reply to the list;
                                                         please *don't* CC me.


From aco1967 at gmail.com  Thu Jun 23 00:29:11 2016
From: aco1967 at gmail.com (Alejandro Cabrera Obed)
Date: Wed, 22 Jun 2016 21:29:11 -0300
Subject: [squid-users] Squid3: icmp_sock: (97) Address family not
 supported by protocol / pinger: Unable to start ICMPv6 pinger
In-Reply-To: <201606230137.17803.Antony.Stone@squid.open.source.it>
References: <CAM0WvY7aZ526EUx3oZaG7MPy_xd=GQRw6Xj=n-QBo=C7oW636A@mail.gmail.com>
 <201606230116.33446.Antony.Stone@squid.open.source.it>
 <CAM0WvY49gXPzL96GS_H6Fg-yddG21Ss2zKk0f2E1GdXWtFCTYA@mail.gmail.com>
 <201606230137.17803.Antony.Stone@squid.open.source.it>
Message-ID: <CAM0WvY7Qdcqskei=rU0F3CgWrA=P7zU3yYEW3pbeomidyqRf6g@mail.gmail.com>

I can't see anything about IPv6:

*cat /etc/default/networking:*

# Configuration for networking init script being run during
# the boot sequence

# Set to 'no' to skip interfaces configuration on boot
#CONFIGURE_INTERFACES=yes

# Don't configure these interfaces. Shell wildcards supported/
#EXCLUDE_INTERFACES=

# Set to 'yes' to enable additional verbosity
#VERBOSE=no

*cat /etc/network/interfaces:*

# This file describes the network interfaces available on your system
# and how to activate them. For more information, see interfaces(5).

source /etc/network/interfaces.d/*    *(this path is empty)*

# The loopback network interface
auto lo
iface lo inet loopback

# The primary network interface
allow-hotplug eth0
iface eth0 inet static
        address x.x.x.x
        netmask 255.255.252.0
        network x.x.x.x
        broadcast x.x.x.x
        gateway x.x.x.x
        # dns-* options are implemented by the resolvconf package, if
installed
        dns-nameservers x.x.x.x



2016-06-22 20:37 GMT-03:00 Antony Stone <Antony.Stone at squid.open.source.it>:

> On Thursday 23 June 2016 at 01:22:45, Alejandro Cabrera Obed wrote:
>
> > #ifconfig
> >
> > eth0      Link encap:Ethernet  HWaddr 00:50:53:b2:6e:88
> >           inet addr:10.17.133.114  Bcast:10.17.135.255
> Mask:255.255.252.0
> >
> > lo        Link encap:Local Loopback
> >           inet addr:127.0.0.1  Mask:255.0.0.0
>
> Well, that certainly confirms that IPv6 is disabled on your machine (from
> the
> lack of lines such as "inet6 addr:").
>
> You say "I haven't disabled the IPv6 protocol, no references in
> /etc/default/grub neither in systcl asociated file."
>
> Something (or someone) has certainly disabled IPv6 on this machine, though.
>
> What are the outputs from:
>
>         grep -v ^# /etc/default/networking
>
>         cat /etc/network/interfaces
>
> ?
>
> Antony.
>
> --
> "It is easy to be blinded to the essential uselessness of them by the
> sense of
> achievement you get from getting them to work at all. In other words - and
> this is the rock solid principle on which the whole of the Corporation's
> Galaxy-wide success is founded - their fundamental design flaws are
> completely
> hidden by their superficial design flaws."
>
>  - Douglas Noel Adams
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
 //  Alejandro   //
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/3e941ed3/attachment.htm>

From aco1967 at gmail.com  Thu Jun 23 00:45:10 2016
From: aco1967 at gmail.com (Alejandro Cabrera Obed)
Date: Wed, 22 Jun 2016 21:45:10 -0300
Subject: [squid-users] Squid3: icmp_sock: (97) Address family not
 supported by protocol / pinger: Unable to start ICMPv6 pinger
In-Reply-To: <CAM0WvY7Qdcqskei=rU0F3CgWrA=P7zU3yYEW3pbeomidyqRf6g@mail.gmail.com>
References: <CAM0WvY7aZ526EUx3oZaG7MPy_xd=GQRw6Xj=n-QBo=C7oW636A@mail.gmail.com>
 <201606230116.33446.Antony.Stone@squid.open.source.it>
 <CAM0WvY49gXPzL96GS_H6Fg-yddG21Ss2zKk0f2E1GdXWtFCTYA@mail.gmail.com>
 <201606230137.17803.Antony.Stone@squid.open.source.it>
 <CAM0WvY7Qdcqskei=rU0F3CgWrA=P7zU3yYEW3pbeomidyqRf6g@mail.gmail.com>
Message-ID: <CAM0WvY61kAdNkZ-2E1wgNVmDdS65_DTM4=+wBz4E2u5DoGZkYg@mail.gmail.com>

I notice that I've comnpiled squid3 with --enable-icmp but I don't need
thsi option because I don't work eith parent caches.

So I will try to reconfigure squid3 withouth the ICMP option (no pinger at
all), and I expect not to see any IPv6 warning.

Regards,

2016-06-22 21:29 GMT-03:00 Alejandro Cabrera Obed <aco1967 at gmail.com>:

> I can't see anything about IPv6:
>
> *cat /etc/default/networking:*
>
> # Configuration for networking init script being run during
> # the boot sequence
>
> # Set to 'no' to skip interfaces configuration on boot
> #CONFIGURE_INTERFACES=yes
>
> # Don't configure these interfaces. Shell wildcards supported/
> #EXCLUDE_INTERFACES=
>
> # Set to 'yes' to enable additional verbosity
> #VERBOSE=no
>
> *cat /etc/network/interfaces:*
>
> # This file describes the network interfaces available on your system
> # and how to activate them. For more information, see interfaces(5).
>
> source /etc/network/interfaces.d/*    *(this path is empty)*
>
> # The loopback network interface
> auto lo
> iface lo inet loopback
>
> # The primary network interface
> allow-hotplug eth0
> iface eth0 inet static
>         address x.x.x.x
>         netmask 255.255.252.0
>         network x.x.x.x
>         broadcast x.x.x.x
>         gateway x.x.x.x
>         # dns-* options are implemented by the resolvconf package, if
> installed
>         dns-nameservers x.x.x.x
>
>
>
> 2016-06-22 20:37 GMT-03:00 Antony Stone <Antony.Stone at squid.open.source.it
> >:
>
>> On Thursday 23 June 2016 at 01:22:45, Alejandro Cabrera Obed wrote:
>>
>> > #ifconfig
>> >
>> > eth0      Link encap:Ethernet  HWaddr 00:50:53:b2:6e:88
>> >           inet addr:10.17.133.114  Bcast:10.17.135.255
>> Mask:255.255.252.0
>> >
>> > lo        Link encap:Local Loopback
>> >           inet addr:127.0.0.1  Mask:255.0.0.0
>>
>> Well, that certainly confirms that IPv6 is disabled on your machine (from
>> the
>> lack of lines such as "inet6 addr:").
>>
>> You say "I haven't disabled the IPv6 protocol, no references in
>> /etc/default/grub neither in systcl asociated file."
>>
>> Something (or someone) has certainly disabled IPv6 on this machine,
>> though.
>>
>> What are the outputs from:
>>
>>         grep -v ^# /etc/default/networking
>>
>>         cat /etc/network/interfaces
>>
>> ?
>>
>> Antony.
>>
>> --
>> "It is easy to be blinded to the essential uselessness of them by the
>> sense of
>> achievement you get from getting them to work at all. In other words - and
>> this is the rock solid principle on which the whole of the Corporation's
>> Galaxy-wide success is founded - their fundamental design flaws are
>> completely
>> hidden by their superficial design flaws."
>>
>>  - Douglas Noel Adams
>>
>>                                                    Please reply to the
>> list;
>>                                                          please *don't*
>> CC me.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
>
> --
>  //  Alejandro   //
>
>
>
>


-- 
 //  Alejandro   //
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160622/1431082c/attachment.htm>

From squid3 at treenet.co.nz  Thu Jun 23 01:26:12 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jun 2016 13:26:12 +1200
Subject: [squid-users] WTF ? SSL Certficate error: certificate issuer
 (CA) not known
In-Reply-To: <ec7a2d6e-d9c6-ef52-cb57-1f4698a1a3e2@gmail.com>
References: <5FE0959288C73D448BB44CB7E9CC320F5837FD1BE5@CPUMAIL2.cpu.qc.ca>
 <ec7a2d6e-d9c6-ef52-cb57-1f4698a1a3e2@gmail.com>
Message-ID: <475cc158-4917-42d6-c53b-fe47127183dc@treenet.co.nz>

On 23/06/2016 7:10 a.m., Yuri Voinov wrote:
> 
> Unknown intermediate certificate, that's all.
> 
> Dig to the direction sslproxy_foreign_intermediate_certs parameter.
> 

Maybe, or outdated ca-certificates info package. Every so often a big
updated happens and people find this happening.

AIUI, there is a push to remove SHA1 CA certs ongoing this year in the
global CA set.

Amos


From reqman at freemail.gr  Thu Jun 23 04:24:21 2016
From: reqman at freemail.gr (reqman)
Date: Thu, 23 Jun 2016 07:24:21 +0300
Subject: [squid-users] "unknown request" when configured to display
	custom logo
In-Reply-To: <f0f92ae0-5026-f386-52d3-a86634951f03@treenet.co.nz>
References: <CAAvSkVF9BN-RxQQtak1u36ahwbmn9jhD9_=b=BNSkOuesniqMQ@mail.gmail.com>
 <f0f92ae0-5026-f386-52d3-a86634951f03@treenet.co.nz>
Message-ID: <CAAvSkVEkUw-M5NxXJATOE1FMHPQP5gAQNABM+FhxPSFOtm4ePQ@mail.gmail.com>

2016-06-22 17:06 GMT+03:00 Amos Jeffries <squid3 at treenet.co.nz>:
> The final step is to edit the /usr/local/etc/squid/mime.conf config file
> and replace the "SN.png" listed there for internal-logo with your image
> filename.
>  Then squid -k reconfigure to load the change.

That did the trick, thank you!

> As Eliezer said Squid is not a generic web server. So getting it to
> serve things up is a bit of arcane voodoo and this is close to the limit
> of what is possible.

That's ok, if it didn't work I'd use the small server I have for
serving the .pad WPAD scripts anyway.

Thank you both for your help. Again!

BR,


Michael.-


From typo at ublun.com  Thu Jun 23 05:17:19 2016
From: typo at ublun.com (David)
Date: Thu, 23 Jun 2016 08:17:19 +0300
Subject: [squid-users] Preparing for shutdown after xxx requests
Message-ID: <86636a21-d59a-c3ef-a60d-9d7406da6fe9@ublun.com>

So far Squid worked nice, but recently it shutdown again and again with:

Preparing for shutdown after xxx requests

has someone a hint what that causes squid to shutdown

Squid Cache: Version 3.5.19
on Archlinux

free -h:
                        total          used        free      shared 
Puffer/Cache cached
Mem:              7.7G        3.4G        672M        333M 3.7G        3.7G
Swap:             4.0G         41M        4.0G

2016/06/23 07:45:06| Set Current Directory to /var/cache/squid
2016/06/23 07:45:06 kid1| Preparing for shutdown after 967 requests
2016/06/23 07:45:06 kid1| Waiting 10 seconds for active connections to 
finish
2016/06/23 07:45:06 kid1| Closing HTTP port [::]:3128
2016/06/23 07:45:06 kid1| Set Current Directory to /var/cache/squid
2016/06/23 07:45:06 kid1| Starting Squid Cache version 3.5.19 for 
x86_64-pc-linux-gnu...
2016/06/23 07:45:06 kid1| Service Name: squid
2016/06/23 07:45:06 kid1| Process ID 17879
2016/06/23 07:45:06 kid1| Process Roles: worker
2016/06/23 07:45:06 kid1| With 1024 file descriptors available
2016/06/23 07:45:06 kid1| Initializing IP Cache...
2016/06/23 07:45:06 kid1| DNS Socket created at [::], FD 8
2016/06/23 07:45:06 kid1| DNS Socket created at 0.0.0.0, FD 9
2016/06/23 07:45:06 kid1| Adding nameserver 192.168.2.1 from 
/etc/resolv.conf
2016/06/23 07:45:06 kid1| Logfile: opening log 
daemon:/var/log/squid/access.log
2016/06/23 07:45:06 kid1| Logfile Daemon: opening log 
/var/log/squid/access.log
2016/06/23 07:45:06 kid1| Local cache digest enabled; rebuild/rewrite 
every 3600/3600 sec
2016/06/23 07:45:06 kid1| Store logging disabled
2016/06/23 07:45:06 kid1| Swap maxSize 61440000 + 3072000 KB, estimated 
4962461 objects
2016/06/23 07:45:06 kid1| Target number of buckets: 248123
2016/06/23 07:45:06 kid1| Using 262144 Store buckets
2016/06/23 07:45:06 kid1| Max Mem  size: 3072000 KB
2016/06/23 07:45:06 kid1| Max Swap size: 61440000 KB
2016/06/23 07:45:06 kid1| Rebuilding storage in /var/cache/squid (dirty log)
2016/06/23 07:45:06 kid1| Using Least Load store dir selection
2016/06/23 07:45:06 kid1| Set Current Directory to /var/cache/squid
2016/06/23 07:45:06 kid1| Finished loading MIME types and icons.
2016/06/23 07:45:06 kid1| HTCP Disabled.
2016/06/23 07:45:06 kid1| Squid plugin modules loaded: 0
2016/06/23 07:45:06 kid1| Adaptation support is off.
2016/06/23 07:45:06 kid1| Accepting HTTP Socket connections at 
local=[::]:3128 remote=[::] FD 14 flags=9
2016/06/23 07:45:07 kid1| Store rebuilding is 53.75% complete
2016/06/23 07:45:07 kid1| Done reading /var/cache/squid swaplog (7441 
entries)
2016/06/23 07:45:07 kid1| Finished rebuilding storage from disk.
2016/06/23 07:45:07 kid1|      7422 Entries scanned
2016/06/23 07:45:07 kid1|         0 Invalid entries.
2016/06/23 07:45:07 kid1|         0 With invalid flags.
2016/06/23 07:45:07 kid1|      7403 Objects loaded.
2016/06/23 07:45:07 kid1|         0 Objects expired.
2016/06/23 07:45:07 kid1|         0 Objects cancelled.
2016/06/23 07:45:07 kid1|        19 Duplicate URLs purged.
2016/06/23 07:45:07 kid1|         0 Swapfile clashes avoided.
2016/06/23 07:45:07 kid1|   Took 0.07 seconds (100137.97 objects/sec).
2016/06/23 07:45:07 kid1| Beginning Validation Procedure
2016/06/23 07:45:07 kid1|   Completed Validation Procedure
2016/06/23 07:45:07 kid1|   Validated 7403 Entries
2016/06/23 07:45:07 kid1|   store_swap_size = 490076.00 KB
2016/06/23 07:45:07 kid1| storeLateRelease: released 0 objects
2016/06/23 07:51:30| Set Current Directory to /var/cache/squid
2016/06/23 07:51:30 kid1| Preparing for shutdown after 28 requests
2016/06/23 07:51:30 kid1| Waiting 10 seconds for active connections to 
finish
2016/06/23 07:51:30 kid1| Closing HTTP port [::]:3128



From squid3 at treenet.co.nz  Thu Jun 23 05:40:59 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jun 2016 17:40:59 +1200
Subject: [squid-users] Preparing for shutdown after xxx requests
In-Reply-To: <86636a21-d59a-c3ef-a60d-9d7406da6fe9@ublun.com>
References: <86636a21-d59a-c3ef-a60d-9d7406da6fe9@ublun.com>
Message-ID: <61f7f0e6-066b-a0ea-75be-0d1e0b7e3cd8@treenet.co.nz>

On 23/06/2016 5:17 p.m., David wrote:
> So far Squid worked nice, but recently it shutdown again and again with:
> 
> Preparing for shutdown after xxx requests
> 
> has someone a hint what that causes squid to shutdown
> 

That message only occurs in the case the some external command was sent
to Squid to shutdown. ie. a proper clean shutdown, not a crash.

For example;
* squid -k shutdown
* squid -k restart
* kill -SIGTERM ...
* squidclient mgr:shutdown
* squidclient mgr:restart
* cachemgr.cgi shutdown or restart request

The usual cause is an init script using -k shutdown or restart signals
where they actually only need reconfigure.

Far less common, but also possible is incorrect http_access permissinos
letting external visitors get to the manager control panel and somebody
playing with the shutdown "report" ability.
 - this might be because of old manager ACL definition from Squid-2
still being used. Squid-3.5 has a new definition.

HTH
Amos



From squid3 at treenet.co.nz  Thu Jun 23 05:47:12 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 23 Jun 2016 17:47:12 +1200
Subject: [squid-users] Latest ssl and Squid stable compile issue
In-Reply-To: <1466623774.2449.31.camel@slave-tothe-box.net>
References: <1466623774.2449.31.camel@slave-tothe-box.net>
Message-ID: <acc1a856-4d00-aa0e-495b-2b2419962e5e@treenet.co.nz>

Yay that you got it going with LibreSSL.

But I'm still interested in why you got the errors in the first place
with OpenSSL. It is supposed to be the better supported one :-P

So if you have the time to assist my edufication;

 what version OpenSSL was this exactly that you built against?
("git pulled latest" doesnt tell me much about what branch/version etc
you ended up with.)

And was it only the libssl you built with, or also the matching
libcrypto ? (libcrypto is what defines the OpenSSL CRYPTO_LOCK_* stuff).

Amos



From eliezer at ngtech.co.il  Thu Jun 23 07:48:11 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 23 Jun 2016 10:48:11 +0300
Subject: [squid-users] Preparing for shutdown after xxx requests
In-Reply-To: <86636a21-d59a-c3ef-a60d-9d7406da6fe9@ublun.com>
References: <86636a21-d59a-c3ef-a60d-9d7406da6fe9@ublun.com>
Message-ID: <0f6001d1cd23$9714fea0$c53efbe0$@ngtech.co.il>

Hey David,

Are you using a squid instance with some old config file?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of David
Sent: Thursday, June 23, 2016 8:17 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Preparing for shutdown after xxx requests

So far Squid worked nice, but recently it shutdown again and again with:

Preparing for shutdown after xxx requests

has someone a hint what that causes squid to shutdown

Squid Cache: Version 3.5.19
on Archlinux

free -h:
                        total          used        free      shared 
Puffer/Cache cached
Mem:              7.7G        3.4G        672M        333M 3.7G        3.7G
Swap:             4.0G         41M        4.0G

2016/06/23 07:45:06| Set Current Directory to /var/cache/squid
2016/06/23 07:45:06 kid1| Preparing for shutdown after 967 requests
2016/06/23 07:45:06 kid1| Waiting 10 seconds for active connections to 
finish
2016/06/23 07:45:06 kid1| Closing HTTP port [::]:3128
2016/06/23 07:45:06 kid1| Set Current Directory to /var/cache/squid
2016/06/23 07:45:06 kid1| Starting Squid Cache version 3.5.19 for 
x86_64-pc-linux-gnu...
2016/06/23 07:45:06 kid1| Service Name: squid
2016/06/23 07:45:06 kid1| Process ID 17879
2016/06/23 07:45:06 kid1| Process Roles: worker
2016/06/23 07:45:06 kid1| With 1024 file descriptors available
2016/06/23 07:45:06 kid1| Initializing IP Cache...
2016/06/23 07:45:06 kid1| DNS Socket created at [::], FD 8
2016/06/23 07:45:06 kid1| DNS Socket created at 0.0.0.0, FD 9
2016/06/23 07:45:06 kid1| Adding nameserver 192.168.2.1 from 
/etc/resolv.conf
2016/06/23 07:45:06 kid1| Logfile: opening log 
daemon:/var/log/squid/access.log
2016/06/23 07:45:06 kid1| Logfile Daemon: opening log 
/var/log/squid/access.log
2016/06/23 07:45:06 kid1| Local cache digest enabled; rebuild/rewrite 
every 3600/3600 sec
2016/06/23 07:45:06 kid1| Store logging disabled
2016/06/23 07:45:06 kid1| Swap maxSize 61440000 + 3072000 KB, estimated 
4962461 objects
2016/06/23 07:45:06 kid1| Target number of buckets: 248123
2016/06/23 07:45:06 kid1| Using 262144 Store buckets
2016/06/23 07:45:06 kid1| Max Mem  size: 3072000 KB
2016/06/23 07:45:06 kid1| Max Swap size: 61440000 KB
2016/06/23 07:45:06 kid1| Rebuilding storage in /var/cache/squid (dirty log)
2016/06/23 07:45:06 kid1| Using Least Load store dir selection
2016/06/23 07:45:06 kid1| Set Current Directory to /var/cache/squid
2016/06/23 07:45:06 kid1| Finished loading MIME types and icons.
2016/06/23 07:45:06 kid1| HTCP Disabled.
2016/06/23 07:45:06 kid1| Squid plugin modules loaded: 0
2016/06/23 07:45:06 kid1| Adaptation support is off.
2016/06/23 07:45:06 kid1| Accepting HTTP Socket connections at 
local=[::]:3128 remote=[::] FD 14 flags=9
2016/06/23 07:45:07 kid1| Store rebuilding is 53.75% complete
2016/06/23 07:45:07 kid1| Done reading /var/cache/squid swaplog (7441 
entries)
2016/06/23 07:45:07 kid1| Finished rebuilding storage from disk.
2016/06/23 07:45:07 kid1|      7422 Entries scanned
2016/06/23 07:45:07 kid1|         0 Invalid entries.
2016/06/23 07:45:07 kid1|         0 With invalid flags.
2016/06/23 07:45:07 kid1|      7403 Objects loaded.
2016/06/23 07:45:07 kid1|         0 Objects expired.
2016/06/23 07:45:07 kid1|         0 Objects cancelled.
2016/06/23 07:45:07 kid1|        19 Duplicate URLs purged.
2016/06/23 07:45:07 kid1|         0 Swapfile clashes avoided.
2016/06/23 07:45:07 kid1|   Took 0.07 seconds (100137.97 objects/sec).
2016/06/23 07:45:07 kid1| Beginning Validation Procedure
2016/06/23 07:45:07 kid1|   Completed Validation Procedure
2016/06/23 07:45:07 kid1|   Validated 7403 Entries
2016/06/23 07:45:07 kid1|   store_swap_size = 490076.00 KB
2016/06/23 07:45:07 kid1| storeLateRelease: released 0 objects
2016/06/23 07:51:30| Set Current Directory to /var/cache/squid
2016/06/23 07:51:30 kid1| Preparing for shutdown after 28 requests
2016/06/23 07:51:30 kid1| Waiting 10 seconds for active connections to 
finish
2016/06/23 07:51:30 kid1| Closing HTTP port [::]:3128

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Thu Jun 23 07:54:41 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 23 Jun 2016 10:54:41 +0300
Subject: [squid-users] Squid3: icmp_sock: (97) Address family not
	supported by protocol / pinger: Unable to start ICMPv6 pinger
In-Reply-To: <CAM0WvY61kAdNkZ-2E1wgNVmDdS65_DTM4=+wBz4E2u5DoGZkYg@mail.gmail.com>
References: <CAM0WvY7aZ526EUx3oZaG7MPy_xd=GQRw6Xj=n-QBo=C7oW636A@mail.gmail.com>
 <201606230116.33446.Antony.Stone@squid.open.source.it>
 <CAM0WvY49gXPzL96GS_H6Fg-yddG21Ss2zKk0f2E1GdXWtFCTYA@mail.gmail.com>
 <201606230137.17803.Antony.Stone@squid.open.source.it>
 <CAM0WvY7Qdcqskei=rU0F3CgWrA=P7zU3yYEW3pbeomidyqRf6g@mail.gmail.com>
 <CAM0WvY61kAdNkZ-2E1wgNVmDdS65_DTM4=+wBz4E2u5DoGZkYg@mail.gmail.com>
Message-ID: <0f6201d1cd24$7fd46e00$7f7d4a00$@ngtech.co.il>

Hey,

 

Pinger is not a must but a luxury piece of software.

It will make your and others life easier but you can avoid it playing with the configuration option:

http://www.squid-cache.org/Doc/config/pinger_enable/

 

And if you have disabled ipv6 in some way it would be probably wise to start thinking about just enabling it if not using it.

Since you have compiled squid by yourself(right?) then you need to disable ipv6 in the squid flags.

I do not think it's a very good idea these days but you are the user\admin\client.

 

All The Bests,

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Alejandro Cabrera Obed
Sent: Thursday, June 23, 2016 3:45 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid3: icmp_sock: (97) Address family not supported by protocol / pinger: Unable to start ICMPv6 pinger

 

I notice that I've comnpiled squid3 with --enable-icmp but I don't need thsi option because I don't work eith parent caches.

 

So I will try to reconfigure squid3 withouth the ICMP option (no pinger at all), and I expect not to see any IPv6 warning.

 

Regards,

 

2016-06-22 21:29 GMT-03:00 Alejandro Cabrera Obed <aco1967 at gmail.com <mailto:aco1967 at gmail.com> >:

I can't see anything about IPv6:

 

cat /etc/default/networking:

 

# Configuration for networking init script being run during

# the boot sequence

 

# Set to 'no' to skip interfaces configuration on boot

#CONFIGURE_INTERFACES=yes

 

# Don't configure these interfaces. Shell wildcards supported/

#EXCLUDE_INTERFACES=

 

# Set to 'yes' to enable additional verbosity

#VERBOSE=no

 

cat /etc/network/interfaces:

 

# This file describes the network interfaces available on your system

# and how to activate them. For more information, see interfaces(5).

 

source /etc/network/interfaces.d/*    (this path is empty)

 

# The loopback network interface

auto lo

iface lo inet loopback

 

# The primary network interface

allow-hotplug eth0

iface eth0 inet static

        address x.x.x.x

        netmask 255.255.252.0

        network x.x.x.x

        broadcast x.x.x.x

        gateway x.x.x.x

        # dns-* options are implemented by the resolvconf package, if installed

        dns-nameservers x.x.x.x

 

 

 

2016-06-22 20:37 GMT-03:00 Antony Stone <Antony.Stone at squid.open.source.it <mailto:Antony.Stone at squid.open.source.it> >:

On Thursday 23 June 2016 at 01:22:45, Alejandro Cabrera Obed wrote:

> #ifconfig
>
> eth0      Link encap:Ethernet  HWaddr 00:50:53:b2:6e:88
>           inet addr:10.17.133.114  Bcast:10.17.135.255  Mask:255.255.252.0
>
> lo        Link encap:Local Loopback
>           inet addr:127.0.0.1  Mask:255.0.0.0

Well, that certainly confirms that IPv6 is disabled on your machine (from the
lack of lines such as "inet6 addr:").

You say "I haven't disabled the IPv6 protocol, no references in
/etc/default/grub neither in systcl asociated file."

Something (or someone) has certainly disabled IPv6 on this machine, though.

What are the outputs from:

        grep -v ^# /etc/default/networking

        cat /etc/network/interfaces

?

Antony.

--
"It is easy to be blinded to the essential uselessness of them by the sense of
achievement you get from getting them to work at all. In other words - and
this is the rock solid principle on which the whole of the Corporation's
Galaxy-wide success is founded - their fundamental design flaws are completely
hidden by their superficial design flaws."

 - Douglas Noel Adams


                                                   Please reply to the list;
                                                         please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users





 

-- 

 //  Alejandro   //








 

-- 

 //  Alejandro   //




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160623/d88fc8e5/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ~WRD000.jpg
Type: image/jpeg
Size: 823 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160623/d88fc8e5/attachment.jpg>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160623/d88fc8e5/attachment.png>

From jlay at slave-tothe-box.net  Thu Jun 23 10:56:14 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Thu, 23 Jun 2016 04:56:14 -0600
Subject: [squid-users] Latest ssl and Squid stable compile issue
In-Reply-To: <acc1a856-4d00-aa0e-495b-2b2419962e5e@treenet.co.nz>
References: <1466623774.2449.31.camel@slave-tothe-box.net>
 <acc1a856-4d00-aa0e-495b-2b2419962e5e@treenet.co.nz>
Message-ID: <1466679374.2239.4.camel@slave-tothe-box.net>

On Thu, 2016-06-23 at 17:47 +1200, Amos Jeffries wrote:
> Yay that you got it going with LibreSSL.
> 
> But I'm still interested in why you got the errors in the first place
> with OpenSSL. It is supposed to be the better supported one :-P
> 
> So if you have the time to assist my edufication;
> 
> ?what version OpenSSL was this exactly that you built against?
> ("git pulled latest" doesnt tell me much about what branch/version
> etc
> you ended up with.)
> 
> And was it only the libssl you built with, or also the matching
> libcrypto ? (libcrypto is what defines the OpenSSL CRYPTO_LOCK_*
> stuff).
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
Ah...well I went with this repo:
git clone https://github.com/openssl/openssl.git
And the errors I posted were where I stopped....unfortunately I've
already nuked the repo off the drive otherwise I'd give you the exact
info. ?I can tell you I got the same errors with both 3.5.19 and
4.0.11. ?Also compile line:
./configure --prefix=/opt --with-openssl=/opt/libressl --enable-ssl --
enable-ssl-crtd --enable-linux-netfilter --enable-follow-x-forwarded-
for --with-large-files --sysconfdir=/opt/etc/squid --enable-external-
acl-helpers=none
Sorry Amos...the one time you ask me for information and I don't have
it for you..: - (
James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160623/275691dc/attachment.htm>

From kristopher at lalletti.ca  Thu Jun 23 12:31:50 2016
From: kristopher at lalletti.ca (Kristopher Lalletti)
Date: Thu, 23 Jun 2016 12:31:50 +0000
Subject: [squid-users] cache_peer directive with SNI
In-Reply-To: <CAEhCwUxmk=sArPokS5fDsX8+ronKv=QqgN9BY8Gp+3DWssNXVQ@mail.gmail.com>
References: <BY2PR04MB1859D04E48B9332D95890922C02C0@BY2PR04MB1859.namprd04.prod.outlook.com>
 <CAEhCwUxmk=sArPokS5fDsX8+ronKv=QqgN9BY8Gp+3DWssNXVQ@mail.gmail.com>
Message-ID: <BY2PR04MB18595D136210DA96C909719CC02D0@BY2PR04MB1859.namprd04.prod.outlook.com>

Tried both and individually; nothing doing.

I keep getting from Squid a TCP_MISS/503 to which the client page states:

(54) Connection reset by peer (TLS code: SQUID_ERR_SSL_HANDSHAKE)
Handshake with SSL server failed: [No Error]

I?m currently using:
Squid Cache version 3.5.19

I just tried substituting the service-name (service.foo.com) in my /etc/hosts, and define cache_peer to connect to service.foo.com, and even that doesn?t work.  It appears that the cache_peer directive, when SSL is enabled does not transmit SNI.

I did however, manage to get it working to some degree using ssl_bump (http://wiki.squid-cache.org/Features/SslPeekAndSplice) using peek, however, I?m also doing URI filtering with squid, and this defeats the purpose to URI filtering as it only checks the requested SNI header from the end-user, and transposes the connection to the cache_peer.

So I?m thinking that the absence of SNI on cache_peer is a ?bug? or a ?missing feature?, which I?m guessing my next viable option is to see if I can bridge the SNI gap with something like STUNNEL.

Anyone else have any thoughts?

From: Hector Chan [mailto:hectorchan at gmail.com]
Sent: June 22, 2016 1:09 AM
To: Kristopher Lalletti <kristopher at lalletti.ca>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] cache_peer directive with SNI

Have you looked at the options forceddomain and ssldomain under the cache_peer directive?  Those may be just what you need.


On Tue, Jun 21, 2016 at 8:14 PM, Kristopher Lalletti <kristopher at lalletti.ca<mailto:kristopher at lalletti.ca>> wrote:
Hi All,

I'm replacing an Apache setup as a reverse-proxy with Squid v3.5, and I've hit a small snag.

Basically, I need to tell squid to pass the proper SSL SNI name to the backend webserver which is accessed via SSL, and naturally, the SSL SNI service-name (service.foo.com<http://service.foo.com>) is not the server-hostname (webserver1.foo.com<http://webserver1.foo.com>), because I've got 3 servers providing for that service-name.

Valid Request to my backend server:
curl --verbose --resolve service.foo.com:10.10.10.10 https://service.foo.com/

Bad requests to my backend server:
curl --verbose --header 'Host: service.foo.com<http://service.foo.com>' https://webserver1.foo.com/
curl --verbose https://webserver1.foo.com/
curl --verbose https://10.10.10.10/

I've looked at the configuration that was generated for the cached_peer, and it came to this:

cache_peer webserver1.foo.com<http://webserver1.foo.com> parent 443 0 proxy-only no-query no-digest originserver login=PASSTHRU connection-auth=on round-robin ssl sslflags=DONT_VERIFY_PEER front-end-https=auto name=rvp_webserver1

Unfortunately, cached_peer doesn't seem to have any directives about this, which leads me to believe there may be a magic SSL Squid ACL that would tell the cache_peer to transpose the requested hostname as part of the SSL SNI hello message, or something like this...

Any advice/orientation to approach the problem would be much appreciated.

Cheers
Kris
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160623/1ed12e38/attachment.htm>

From aco1967 at gmail.com  Thu Jun 23 13:19:39 2016
From: aco1967 at gmail.com (Alejandro Cabrera Obed)
Date: Thu, 23 Jun 2016 10:19:39 -0300
Subject: [squid-users] Squid3: icmp_sock: (97) Address family not
 supported by protocol / pinger: Unable to start ICMPv6 pinger
In-Reply-To: <0f6201d1cd24$7fd46e00$7f7d4a00$@ngtech.co.il>
References: <CAM0WvY7aZ526EUx3oZaG7MPy_xd=GQRw6Xj=n-QBo=C7oW636A@mail.gmail.com>
 <201606230116.33446.Antony.Stone@squid.open.source.it>
 <CAM0WvY49gXPzL96GS_H6Fg-yddG21Ss2zKk0f2E1GdXWtFCTYA@mail.gmail.com>
 <201606230137.17803.Antony.Stone@squid.open.source.it>
 <CAM0WvY7Qdcqskei=rU0F3CgWrA=P7zU3yYEW3pbeomidyqRf6g@mail.gmail.com>
 <CAM0WvY61kAdNkZ-2E1wgNVmDdS65_DTM4=+wBz4E2u5DoGZkYg@mail.gmail.com>
 <0f6201d1cd24$7fd46e00$7f7d4a00$@ngtech.co.il>
Message-ID: <CAM0WvY7D1rvx=L=1rdzB9ciCQtVZvyG37cycLjWWzYb--qSZEA@mail.gmail.com>

OK Eliezer, thanks a lot....I will disable IPv6 and compile Squid3 again
disabling ICMP (pinger) also because I don't need these features at all.

Regards,

Alejandro

2016-06-23 4:54 GMT-03:00 Eliezer Croitoru <eliezer at ngtech.co.il>:

> Hey,
>
>
>
> Pinger is not a must but a luxury piece of software.
>
> It will make your and others life easier but you can avoid it playing with
> the configuration option:
>
> http://www.squid-cache.org/Doc/config/pinger_enable/
>
>
>
> And if you have disabled ipv6 in some way it would be probably wise to
> start thinking about just enabling it if not using it.
>
> Since you have compiled squid by yourself(right?) then you need to disable
> ipv6 in the squid flags.
>
> I do not think it's a very good idea these days but you are the
> user\admin\client.
>
>
>
> All The Bests,
>
> Eliezer
>
>
>
> ----
>
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
>
> *From:* squid-users [mailto:squid-users-bounces at lists.squid-cache.org] *On
> Behalf Of *Alejandro Cabrera Obed
> *Sent:* Thursday, June 23, 2016 3:45 AM
> *To:* squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Squid3: icmp_sock: (97) Address family not
> supported by protocol / pinger: Unable to start ICMPv6 pinger
>
>
>
> I notice that I've comnpiled squid3 with --enable-icmp but I don't need
> thsi option because I don't work eith parent caches.
>
>
>
> So I will try to reconfigure squid3 withouth the ICMP option (no pinger at
> all), and I expect not to see any IPv6 warning.
>
>
>
> Regards,
>
>
>
> 2016-06-22 21:29 GMT-03:00 Alejandro Cabrera Obed <aco1967 at gmail.com>:
>
> I can't see anything about IPv6:
>
>
>
> *cat /etc/default/networking:*
>
>
>
> # Configuration for networking init script being run during
>
> # the boot sequence
>
>
>
> # Set to 'no' to skip interfaces configuration on boot
>
> #CONFIGURE_INTERFACES=yes
>
>
>
> # Don't configure these interfaces. Shell wildcards supported/
>
> #EXCLUDE_INTERFACES=
>
>
>
> # Set to 'yes' to enable additional verbosity
>
> #VERBOSE=no
>
>
>
> *cat /etc/network/interfaces:*
>
>
>
> # This file describes the network interfaces available on your system
>
> # and how to activate them. For more information, see interfaces(5).
>
>
>
> source /etc/network/interfaces.d/*    *(this path is empty)*
>
>
>
> # The loopback network interface
>
> auto lo
>
> iface lo inet loopback
>
>
>
> # The primary network interface
>
> allow-hotplug eth0
>
> iface eth0 inet static
>
>         address x.x.x.x
>
>         netmask 255.255.252.0
>
>         network x.x.x.x
>
>         broadcast x.x.x.x
>
>         gateway x.x.x.x
>
>         # dns-* options are implemented by the resolvconf package, if
> installed
>
>         dns-nameservers x.x.x.x
>
>
>
>
>
>
>
> 2016-06-22 20:37 GMT-03:00 Antony Stone <Antony.Stone at squid.open.source.it
> >:
>
> On Thursday 23 June 2016 at 01:22:45, Alejandro Cabrera Obed wrote:
>
> > #ifconfig
> >
> > eth0      Link encap:Ethernet  HWaddr 00:50:53:b2:6e:88
> >           inet addr:10.17.133.114  Bcast:10.17.135.255
> Mask:255.255.252.0
> >
> > lo        Link encap:Local Loopback
> >           inet addr:127.0.0.1  Mask:255.0.0.0
>
> Well, that certainly confirms that IPv6 is disabled on your machine (from
> the
> lack of lines such as "inet6 addr:").
>
> You say "I haven't disabled the IPv6 protocol, no references in
> /etc/default/grub neither in systcl asociated file."
>
> Something (or someone) has certainly disabled IPv6 on this machine, though.
>
> What are the outputs from:
>
>         grep -v ^# /etc/default/networking
>
>         cat /etc/network/interfaces
>
> ?
>
> Antony.
>
> --
> "It is easy to be blinded to the essential uselessness of them by the
> sense of
> achievement you get from getting them to work at all. In other words - and
> this is the rock solid principle on which the whole of the Corporation's
> Galaxy-wide success is founded - their fundamental design flaws are
> completely
> hidden by their superficial design flaws."
>
>  - Douglas Noel Adams
>
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
> --
>
>  //  Alejandro   //
> [image: Image removed by sender.]
>
>
>
>
>
> --
>
>  //  Alejandro   //
> [image: Image removed by sender.]
>
>


-- 
 //  Alejandro   //
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160623/d909274c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160623/d909274c/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ~WRD000.jpg
Type: image/jpeg
Size: 823 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160623/d909274c/attachment.jpg>

From eliezer at ngtech.co.il  Thu Jun 23 13:22:02 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 23 Jun 2016 16:22:02 +0300
Subject: [squid-users] Squid in Air Planes WiFi system,
	how should it be used?
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAANIlB21wPQZLlj2Y4QUZ/uABAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABGVPTOZa5tQ4+OMqt2IZvXAQAAAAA=@ngtech.co.il>

Since Internet is starting to flow into the "Flying ships" industry I
started to wonder what are the limits?
In the air the network connections are very low quality despite to the fact
that they can transfer lots of data.
So the OS will probably handle all the lower network issues and will leave
to the proxy software all the fun stuff.
The basic services on a Flying WiFi network would be:
-	FW + NAT
-	DNS proxy + local
-	DHCP
-	Authorization and Authentication services(Radius, token based\OTP),
I don't expect any form of AD or LDAP based.
-	Internet Service Payments portal (maybe can be used as an
alternative or extension to pre-paid tickets)
-	VOD
-	Digital Book Shelf
-	VOIP services
-	And probably couple other services which many require

Then I asked myself: What squid can offer for this system? Where squid can
be plugged inside this list of services?
>From where is see it, the proxy can take over the application stack from the
client to the server. 
Since the OS will be designed to handle the network level issue(both fabric
and protocol) it will simplify for the clients the need to overcome network
level issues.
The clients will need to just be clients using  WiFi(leaving aside the
700KMPH radio\physics layer).
The flight will be much nicer from the technology perspective of it.
I do however think that one of the main issues with so many technological
"comforts" would be the human to human in-flight relationship.

Two examples to special scenarios I know from the Anime world are:
-	Accel World
-	Ghost In The Shell
Which gives an image of a world which humans are bypassing the real world
for the favor of a Virtual world.
What do you think? 

Eliezer

Links:
-	http://myanimelist.net/anime/11759/Accel_World
-	http://myanimelist.net/anime/43/Ghost_in_the_Shell

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 66373 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160623/785b5538/attachment.bin>

From eliezer at ngtech.co.il  Thu Jun 23 14:08:21 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 23 Jun 2016 17:08:21 +0300
Subject: [squid-users] https antivirus proxy necessary?
In-Reply-To: <aafca46690da29f048a319616b823c51@email.freenet.de>
References: <aafca46690da29f048a319616b823c51@email.freenet.de>
Message-ID: <113901d1cd58$b2da4480$188ecd80$@ngtech.co.il>

Hey,

Sorry for not responding earlier.
Your question regarding having two layers of AV technically depends on what
both are offering as a product.
We can spate the question of unwrapping HTTPS\TLS connections from
inspecting the HTTPS content using an AV.
If you have a trusted source and as an example I would take Microsoft.
Microsoft is known to secure it's infrastructure despite some rumors from
security "experts" so you won't need to inspect their updates.
You might want to cache them but not check them with AV. The day you will
need to inspect them with AV things will probably start falling from the
sky..
If you have a defined business web usage policy it minimizes the options to
malice software download but it only fits for special cases with high risk
for theft or other crime related sensitive data\info.

Building Latest squid from sources for Debian Jessie can cost money and in
some cases it's not worth it.
The answer regarding the price would be the level of QA and other
development and integration stages.
Depends on the business size the HTTPS url inspection by itself can be
worth a lot.

Can you define what can be costly when building squid for Jessie?
I am asking since I am in the middle of working on a version of latest
squid with SSL-BUMP support.(it takes quite some time to automate it)

Eliezer

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of hans.meyer0 at fn.de
Sent: Wednesday, June 22, 2016 5:10 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] https antivirus proxy necessary?

Do you think it's necessary to have an additional https antivir proxy to
normal client antivirus?
We are using Avast Business that already offers a web protection.
Can an additional antivir proxy significant higher the level of protection?
In general I think two different antivirus programms see more then one.
But on the other hand an HTTP/HTTPS antivirus proxy is an additional attack
surface.
Especially because its costly to build the latest squid version with https
support from source on a debian jessie.
So the proxy will not be up a proxy or not?


---
Mail & Cloud Made in Germany mit 3 GB Speicher! Jetzt kostenlos anmelden
<https://email.freenet.de/mail/Uebersicht?epid=e9900000450> 
-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 65101 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160623/2d511e25/attachment.bin>

From marcus.kool at urlfilterdb.com  Thu Jun 23 14:35:50 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Thu, 23 Jun 2016 11:35:50 -0300
Subject: [squid-users] https antivirus proxy necessary?
In-Reply-To: <aafca46690da29f048a319616b823c51@email.freenet.de>
References: <aafca46690da29f048a319616b823c51@email.freenet.de>
Message-ID: <576BF3C6.5070404@urlfilterdb.com>



On 06/22/2016 11:10 AM, hans.meyer0 at fn.de wrote:
> Do you think it's necessary to have an additional https antivir proxy to normal client antivirus? We are using Avast Business that already offers a web protection. Can an additional antivir proxy
> significant higher the level of protection? In general I think two different antivirus programms see more then one. But on the other hand an HTTP/HTTPS antivirus proxy is an additional attack surface.
> Especially because its costly to build the latest squid version with https support from source on a debian jessi. So the proxy will not be  up a proxy or not?

There is not a single antivirus vendor that catches all viruses, especially not new or mutated viruses, so it is definitely recommendable to use two vendors.
One can use brand-1 on the PC and brand-2 on the web proxies and email servers.

Marcus



From rafael.akchurin at diladele.com  Thu Jun 23 15:17:21 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 23 Jun 2016 15:17:21 +0000
Subject: [squid-users] https antivirus proxy necessary?
In-Reply-To: <113901d1cd58$b2da4480$188ecd80$@ngtech.co.il>
References: <aafca46690da29f048a319616b823c51@email.freenet.de>
 <113901d1cd58$b2da4480$188ecd80$@ngtech.co.il>
Message-ID: <VI1PR04MB135911EC0F9DA3F47C7877888F2D0@VI1PR04MB1359.eurprd04.prod.outlook.com>

Hello Eliezer and Hans,

Our github.com repo has all the scripts necessary to rebuild latest Squid 3.5.19 with SSL Bump and latest ecap on Ubuntu 14.04 see https://github.com/diladele/squid-ubuntu.

We reuse the Debian Testing package and apply some simple patches on it. I am pretty sure this is as easy to do in Debian Jessy.
Hope this will help to build the Jessy package easier.

Best regards,
Rafael Akchurin
Diladele B.V.

--
Please take a look at Web Safety - our ICAP based web filter server for Squid proxy at http://www.diladele.com


_____________________________________________
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Eliezer Croitoru
Sent: Thursday, June 23, 2016 4:08 PM
To: hans.meyer0 at fn.de
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] https antivirus proxy necessary?


Hey,

Sorry for not responding earlier.
Your question regarding having two layers of AV technically depends on what both are offering as a product.
We can spate the question of unwrapping HTTPS\TLS connections from inspecting the HTTPS content using an AV.
If you have a trusted source and as an example I would take Microsoft.
Microsoft is known to secure it's infrastructure despite some rumors from security "experts" so you won't need to inspect their updates.
You might want to cache them but not check them with AV. The day you will need to inspect them with AV things will probably start falling from the sky..
If you have a defined business web usage policy it minimizes the options to malice software download but it only fits for special cases with high risk for theft or other crime related sensitive data\info.

Building Latest squid from sources for Debian Jessie can cost money and in some cases it's not worth it.
The answer regarding the price would be the level of QA and other development and integration stages.
Depends on the business size the HTTPS url inspection by itself can be worth a lot.

Can you define what can be costly when building squid for Jessie?
I am asking since I am in the middle of working on a version of latest squid with SSL-BUMP support.(it takes quite some time to automate it)

Eliezer

----
Eliezer Croitoru<http://ngtech.co.il/lmgtfy/>
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
 << File: ATT00001.txt >>

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of hans.meyer0 at fn.de
Sent: Wednesday, June 22, 2016 5:10 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] https antivirus proxy necessary?

Do you think it's necessary to have an additional https antivir proxy to normal client antivirus?
We are using Avast Business that already offers a web protection.
Can an additional antivir proxy significant higher the level of protection?
In general I think two different antivirus programms see more then one.
But on the other hand an HTTP/HTTPS antivirus proxy is an additional attack surface.
Especially because its costly to build the latest squid version with https support from source on a debian jessie.
So the proxy will not be up a proxy or not?


---
Mail & Cloud Made in Germany mit 3 GB Speicher! Jetzt kostenlos anmelden<https://email.freenet.de/mail/Uebersicht?epid=e9900000450> << OLE Object: Picture (Device Independent Bitmap) >>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160623/e5bad727/attachment.htm>

From hectorchan at gmail.com  Thu Jun 23 15:40:17 2016
From: hectorchan at gmail.com (Hector Chan)
Date: Thu, 23 Jun 2016 08:40:17 -0700
Subject: [squid-users] cache_peer directive with SNI
In-Reply-To: <BY2PR04MB18595D136210DA96C909719CC02D0@BY2PR04MB1859.namprd04.prod.outlook.com>
References: <BY2PR04MB1859D04E48B9332D95890922C02C0@BY2PR04MB1859.namprd04.prod.outlook.com>
 <CAEhCwUxmk=sArPokS5fDsX8+ronKv=QqgN9BY8Gp+3DWssNXVQ@mail.gmail.com>
 <BY2PR04MB18595D136210DA96C909719CC02D0@BY2PR04MB1859.namprd04.prod.outlook.com>
Message-ID: <CAEhCwUycZaFdNV6Bxp1By2XMy1FCox7GAFMHC=48Kf3ODFmyaw@mail.gmail.com>

Yes, you are right. I ran into the same problem as you did, and now I
remember how I got it to work. I manually patched the version of squid I
was using to send SNI. Let me if you are interested in going that route.
If I remember right, it was just a 1 to 3 line-patch.

On Thu, Jun 23, 2016 at 5:31 AM, Kristopher Lalletti <kristopher at lalletti.ca
> wrote:

> Tried both and individually; nothing doing.
>
>
>
> I keep getting from Squid a TCP_MISS/503 to which the client page states:
>
>
>
> (54) Connection reset by peer (TLS code: SQUID_ERR_SSL_HANDSHAKE)
>
> Handshake with SSL server failed: [No Error]
>
>
>
> I?m currently using:
>
> Squid Cache version 3.5.19
>
>
>
> I just tried substituting the service-name (service.foo.com) in my
> /etc/hosts, and define cache_peer to connect to service.foo.com, and even
> that doesn?t work.  It appears that the cache_peer directive, when SSL is
> enabled does not transmit SNI.
>
>
>
> I did however, manage to get it working to some degree using ssl_bump (
> http://wiki.squid-cache.org/Features/SslPeekAndSplice) using peek,
> however, I?m also doing URI filtering with squid, and this defeats the
> purpose to URI filtering as it only checks the requested SNI header from
> the end-user, and transposes the connection to the cache_peer.
>
>
>
> So I?m thinking that the absence of SNI on cache_peer is a ?bug? or a
> ?missing feature?, which I?m guessing my next viable option is to see if I
> can bridge the SNI gap with something like STUNNEL.
>
>
>
> Anyone else have any thoughts?
>
>
>
> *From:* Hector Chan [mailto:hectorchan at gmail.com]
> *Sent:* June 22, 2016 1:09 AM
> *To:* Kristopher Lalletti <kristopher at lalletti.ca>
> *Cc:* squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] cache_peer directive with SNI
>
>
>
> Have you looked at the options forceddomain and ssldomain under the
> cache_peer directive?  Those may be just what you need.
>
>
>
> On Tue, Jun 21, 2016 at 8:14 PM, Kristopher Lalletti <
> kristopher at lalletti.ca> wrote:
>
> Hi All,
>
> I'm replacing an Apache setup as a reverse-proxy with Squid v3.5, and I've
> hit a small snag.
>
> Basically, I need to tell squid to pass the proper SSL SNI name to the
> backend webserver which is accessed via SSL, and naturally, the SSL SNI
> service-name (service.foo.com) is not the server-hostname (
> webserver1.foo.com), because I've got 3 servers providing for that
> service-name.
>
> Valid Request to my backend server:
> curl --verbose --resolve service.foo.com:10.10.10.10
> https://service.foo.com/
>
> Bad requests to my backend server:
> curl --verbose --header 'Host: service.foo.com'
> https://webserver1.foo.com/
> curl --verbose https://webserver1.foo.com/
> curl --verbose https://10.10.10.10/
>
> I've looked at the configuration that was generated for the cached_peer,
> and it came to this:
>
> cache_peer webserver1.foo.com parent 443 0 proxy-only no-query no-digest
> originserver login=PASSTHRU connection-auth=on round-robin ssl
> sslflags=DONT_VERIFY_PEER front-end-https=auto name=rvp_webserver1
>
> Unfortunately, cached_peer doesn't seem to have any directives about this,
> which leads me to believe there may be a magic SSL Squid ACL that would
> tell the cache_peer to transpose the requested hostname as part of the SSL
> SNI hello message, or something like this...
>
> Any advice/orientation to approach the problem would be much appreciated.
>
> Cheers
> Kris
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160623/9af04485/attachment.htm>

From bruno.larini at riosoft.com.br  Thu Jun 23 17:16:49 2016
From: bruno.larini at riosoft.com.br (Bruno de Paula Larini)
Date: Thu, 23 Jun 2016 14:16:49 -0300
Subject: [squid-users] Squid in Air Planes WiFi system,
 how should it be used?
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAANIlB21wPQZLlj2Y4QUZ/uABAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABGVPTOZa5tQ4+OMqt2IZvXAQAAAAA=@ngtech.co.il>
References: <!&!AAAAAAAAAAAuAAAAAAAAANIlB21wPQZLlj2Y4QUZ/uABAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABGVPTOZa5tQ4+OMqt2IZvXAQAAAAA=@ngtech.co.il>
Message-ID: <3596f7a2-6340-2259-7a13-a42455aac403@riosoft.com.br>

Em 23/06/2016 10:22, Eliezer Croitoru escreveu:
> Since Internet is starting to flow into the "Flying ships" industry I
> started to wonder what are the limits?
> In the air the network connections are very low quality despite to the fact
> that they can transfer lots of data.
> So the OS will probably handle all the lower network issues and will leave
> to the proxy software all the fun stuff.
> The basic services on a Flying WiFi network would be:
> -	FW + NAT
> -	DNS proxy + local
> -	DHCP
> -	Authorization and Authentication services(Radius, token based\OTP),
> I don't expect any form of AD or LDAP based.
> -	Internet Service Payments portal (maybe can be used as an
> alternative or extension to pre-paid tickets)
> -	VOD
> -	Digital Book Shelf
> -	VOIP services
> -	And probably couple other services which many require
>
> Then I asked myself: What squid can offer for this system? Where squid can
> be plugged inside this list of services?
> >From where is see it, the proxy can take over the application stack from the
> client to the server.
> Since the OS will be designed to handle the network level issue(both fabric
> and protocol) it will simplify for the clients the need to overcome network
> level issues.
> The clients will need to just be clients using  WiFi(leaving aside the
> 700KMPH radio\physics layer).
> The flight will be much nicer from the technology perspective of it.
> I do however think that one of the main issues with so many technological
> "comforts" would be the human to human in-flight relationship.
>
> Two examples to special scenarios I know from the Anime world are:
> -	Accel World
> -	Ghost In The Shell
> Which gives an image of a world which humans are bypassing the real world
> for the favor of a Virtual world.
> What do you think?
>
> Eliezer
>
> Links:
> -	http://myanimelist.net/anime/11759/Accel_World
> -	http://myanimelist.net/anime/43/Ghost_in_the_Shell
I'm sorry to post unrelated comments on the list but... How high are 
you? Pun intended.
It is something I'm missing?


From squid3 at treenet.co.nz  Thu Jun 23 17:30:33 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 24 Jun 2016 05:30:33 +1200
Subject: [squid-users] Latest ssl and Squid stable compile issue
In-Reply-To: <1466679374.2239.4.camel@slave-tothe-box.net>
References: <1466623774.2449.31.camel@slave-tothe-box.net>
 <acc1a856-4d00-aa0e-495b-2b2419962e5e@treenet.co.nz>
 <1466679374.2239.4.camel@slave-tothe-box.net>
Message-ID: <9115f814-9763-d3af-2c22-0eb93d1aeabb@treenet.co.nz>

On 23/06/2016 10:56 p.m., James Lay wrote:
> Ah...well I went with this repo:
> git clone https://github.com/openssl/openssl.git
> And the errors I posted were where I stopped....unfortunately I've
> already nuked the repo off the drive otherwise I'd give you the exact
> info.  I can tell you I got the same errors with both 3.5.19 and
> 4.0.11.  Also compile line:
> ./configure --prefix=/opt --with-openssl=/opt/libressl --enable-ssl --
> enable-ssl-crtd --enable-linux-netfilter --enable-follow-x-forwarded-
> for --with-large-files --sysconfdir=/opt/etc/squid --enable-external-
> acl-helpers=none
> Sorry Amos...the one time you ask me for information and I don't have
> it for you..: - (
> James
> 

No worries. Just my interest.

Amos



From squid3 at treenet.co.nz  Thu Jun 23 17:36:56 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 24 Jun 2016 05:36:56 +1200
Subject: [squid-users] Squid3: icmp_sock: (97) Address family not
 supported by protocol / pinger: Unable to start ICMPv6 pinger
In-Reply-To: <CAM0WvY7D1rvx=L=1rdzB9ciCQtVZvyG37cycLjWWzYb--qSZEA@mail.gmail.com>
References: <CAM0WvY7aZ526EUx3oZaG7MPy_xd=GQRw6Xj=n-QBo=C7oW636A@mail.gmail.com>
 <201606230116.33446.Antony.Stone@squid.open.source.it>
 <CAM0WvY49gXPzL96GS_H6Fg-yddG21Ss2zKk0f2E1GdXWtFCTYA@mail.gmail.com>
 <201606230137.17803.Antony.Stone@squid.open.source.it>
 <CAM0WvY7Qdcqskei=rU0F3CgWrA=P7zU3yYEW3pbeomidyqRf6g@mail.gmail.com>
 <CAM0WvY61kAdNkZ-2E1wgNVmDdS65_DTM4=+wBz4E2u5DoGZkYg@mail.gmail.com>
 <0f6201d1cd24$7fd46e00$7f7d4a00$@ngtech.co.il>
 <CAM0WvY7D1rvx=L=1rdzB9ciCQtVZvyG37cycLjWWzYb--qSZEA@mail.gmail.com>
Message-ID: <8073262d-6d60-6f6f-b621-71983f32163e@treenet.co.nz>

On 24/06/2016 1:19 a.m., Alejandro Cabrera Obed wrote:
> OK Eliezer, thanks a lot....I will disable IPv6 and compile Squid3 again
> disabling ICMP (pinger) also because I don't need these features at all.
> 

Maybe yes. Maybe no. pinger is a tricky one. It is used to record RTT
for each server connection Squid might possibly make (each IP for each
server a request might go to) so the fastest one can be selected as
first choice when theres a set of destinations.

In theory its great for preventing long-latency connections. But it dont
work often enough yet for it to be a desired thing. The distance
weighted load balancing between cache_peer's algorithm gets most gain.

Amos



From squid3 at treenet.co.nz  Thu Jun 23 17:48:53 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 24 Jun 2016 05:48:53 +1200
Subject: [squid-users] cache_peer directive with SNI
In-Reply-To: <CAEhCwUycZaFdNV6Bxp1By2XMy1FCox7GAFMHC=48Kf3ODFmyaw@mail.gmail.com>
References: <BY2PR04MB1859D04E48B9332D95890922C02C0@BY2PR04MB1859.namprd04.prod.outlook.com>
 <CAEhCwUxmk=sArPokS5fDsX8+ronKv=QqgN9BY8Gp+3DWssNXVQ@mail.gmail.com>
 <BY2PR04MB18595D136210DA96C909719CC02D0@BY2PR04MB1859.namprd04.prod.outlook.com>
 <CAEhCwUycZaFdNV6Bxp1By2XMy1FCox7GAFMHC=48Kf3ODFmyaw@mail.gmail.com>
Message-ID: <b56e3504-5354-e259-65ee-af67acdfe15f@treenet.co.nz>

On 24/06/2016 3:40 a.m., Hector Chan wrote:
> Yes, you are right. I ran into the same problem as you did, and now I
> remember how I got it to work. I manually patched the version of squid I
> was using to send SNI. Let me if you are interested in going that route.
> If I remember right, it was just a 1 to 3 line-patch.
> 

Patch submissions are welcome on the squid-dev mailing list.
see <http://wiki.squid-cache.org/MergeProcedure#Submission_Format> for
details on how to prepare it.

We may have quibbles about what gets sent. But not sending anything at
all is a missing feature problem.

Amos



From squid3 at treenet.co.nz  Thu Jun 23 18:11:23 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 24 Jun 2016 06:11:23 +1200
Subject: [squid-users] Forward loop when intercepting mode to proxy
 traffic to local VM
In-Reply-To: <alpine.DEB.2.02.1606221152450.12819@eowyn.twu.net>
References: <alpine.DEB.2.02.1606220543010.12819@eowyn.twu.net>
 <alpine.DEB.2.02.1606220614560.12819@eowyn.twu.net>
 <9e96c8cd-7eb8-150a-15d5-fd3da970931e@treenet.co.nz>
 <alpine.DEB.2.02.1606221152450.12819@eowyn.twu.net>
Message-ID: <2ffe9054-7ceb-9754-788a-dfd7e44c7658@treenet.co.nz>

On 23/06/2016 4:54 a.m., jblank wrote:
> To be honest, I am not 100% clear on Squid's various modes. If reverse
> proxy mode is capable of doing the decrypt/re-encrypt stuff, I'm fine
> with using it. Any pointers to HOWTOs or FAQs that might help?

<http://wiki.squid-cache.org/SquidFaq> has a section on the main traffic
handling modes.

The big distinction between intercept and accel modes is that intercept
is for at ISP type situations and accel is for CDN type situations.

One Squid can do both jobs at once. Just through different http(s)_port
directives.

NAT can introduce a lot of problems, particularly with HTTPS
connections. So if your Squid is being a frontend (aka CDN) for this VM
host its probably better to do that as accel mode rather than intercept.

Amos



From typo at ublun.com  Fri Jun 24 06:08:35 2016
From: typo at ublun.com (David)
Date: Fri, 24 Jun 2016 09:08:35 +0300
Subject: [squid-users] Preparing for shutdown after xxx requests
In-Reply-To: <0f6001d1cd23$9714fea0$c53efbe0$@ngtech.co.il>
References: <86636a21-d59a-c3ef-a60d-9d7406da6fe9@ublun.com>
 <0f6001d1cd23$9714fea0$c53efbe0$@ngtech.co.il>
Message-ID: <b02e6b3f-35cb-1051-12e0-f3200d50f3ae@ublun.com>

we have reinstalled cleanly Squid, have squid -z and it works for some 
time, then squid terminates with:

DiskThreadsDiskFile::openDone: (2) No such file or directory

the original config file is the one below.

thank you - David


2016/06/24 06:26:53 kid1| Set Current Directory to /var/cache/squid
2016/06/24 06:26:53 kid1| Starting Squid Cache version 3.5.19 for 
x86_64-pc-linux-gnu...
2016/06/24 06:26:53 kid1| Service Name: squid
2016/06/24 06:26:53 kid1| Process ID 7914
2016/06/24 06:26:53 kid1| Process Roles: worker
2016/06/24 06:26:53 kid1| With 1024 file descriptors available
2016/06/24 06:26:53 kid1| Initializing IP Cache...
2016/06/24 06:26:53 kid1| DNS Socket created at [::], FD 8
2016/06/24 06:26:53 kid1| DNS Socket created at 0.0.0.0, FD 9
2016/06/24 06:26:53 kid1| Adding nameserver 192.168.2.1 from 
/etc/resolv.conf
2016/06/24 06:26:53 kid1| Logfile: opening log 
daemon:/var/log/squid/access.log
2016/06/24 06:26:53 kid1| Logfile Daemon: opening log 
/var/log/squid/access.log
2016/06/24 06:26:53 kid1| Local cache digest enabled; rebuild/rewrite 
every 3600/3600 sec
2016/06/24 06:26:53 kid1| Store logging disabled
2016/06/24 06:26:53 kid1| Swap maxSize 1024000 + 262144 KB, estimated 
98934 objects
2016/06/24 06:26:53 kid1| Target number of buckets: 4946
2016/06/24 06:26:53 kid1| Using 8192 Store buckets
2016/06/24 06:26:53 kid1| Max Mem  size: 262144 KB
2016/06/24 06:26:53 kid1| Max Swap size: 1024000 KB
2016/06/24 06:26:53 kid1| Rebuilding storage in /var/cache/squid (dirty log)
2016/06/24 06:26:53 kid1| Using Least Load store dir selection
2016/06/24 06:26:53 kid1| Set Current Directory to /var/cache/squid
2016/06/24 06:26:53 kid1| Finished loading MIME types and icons.
2016/06/24 06:26:53 kid1| HTCP Disabled.
2016/06/24 06:26:53 kid1| Squid plugin modules loaded: 0
2016/06/24 06:26:53 kid1| Adaptation support is off.
2016/06/24 06:26:53 kid1| Accepting HTTP Socket connections at 
local=[::]:3128 remote=[::] FD 14 flags=9
2016/06/24 06:26:53 kid1| Done reading /var/cache/squid swaplog (705 
entries)
2016/06/24 06:26:53 kid1| Finished rebuilding storage from disk.
2016/06/24 06:26:53 kid1|       705 Entries scanned
2016/06/24 06:26:53 kid1|         0 Invalid entries.
2016/06/24 06:26:53 kid1|         0 With invalid flags.
2016/06/24 06:26:53 kid1|       705 Objects loaded.
2016/06/24 06:26:53 kid1|         0 Objects expired.
2016/06/24 06:26:53 kid1|         0 Objects cancelled.
2016/06/24 06:26:53 kid1|         0 Duplicate URLs purged.
2016/06/24 06:26:53 kid1|         0 Swapfile clashes avoided.
2016/06/24 06:26:53 kid1|   Took 0.03 seconds (22704.58 objects/sec).
2016/06/24 06:26:53 kid1| Beginning Validation Procedure
2016/06/24 06:26:53 kid1|   Completed Validation Procedure
2016/06/24 06:26:53 kid1|   Validated 705 Entries
2016/06/24 06:26:53 kid1|   store_swap_size = 67156.00 KB
2016/06/24 06:26:54 kid1| storeLateRelease: released 0 objects
2016/06/24 06:32:50 kid1| DiskThreadsDiskFile::openDone: (2) No such 
file or directory
2016/06/24 06:32:50 kid1|     /var/cache/squid/00/00/0000000C
2016/06/24 06:56:49| Set Current Directory to /var/cache/squid
2016/06/24 06:56:49 kid1| Preparing for shutdown after 390 requests
2016/06/24 06:56:49 kid1| Waiting 30 seconds for active connections to 
finish
2016/06/24 06:56:49 kid1| Closing HTTP port [::]:3128

-------------------------------------------------------------------------------------------------------

#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8    # RFC1918 possible internal network
acl localnet src 172.16.0.0/12    # RFC1918 possible internal network
acl localnet src 192.168.0.0/16    # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines

acl SSL_ports port 443
acl Safe_ports port 80        # http
acl Safe_ports port 21        # ftp
acl Safe_ports port 443        # https
acl Safe_ports port 70        # gopher
acl Safe_ports port 210        # wais
acl Safe_ports port 1025-65535    # unregistered ports
acl Safe_ports port 280        # http-mgmt
acl Safe_ports port 488        # gss-http
acl Safe_ports port 591        # filemaker
acl Safe_ports port 777        # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 3128

# Uncomment and adjust the following to add a disk cache directory.
cache_dir aufs /var/cache/squid 1000 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern -i \.(gif|png|jpg|jpeg|ico)$ 10080 90% 43200 
override-expire ignore-no-cache ignore-no-store ignore-private
refresh_pattern -i \.(iso|avi|mkv|wav|mp3|mp4|mpeg|swf|flv|x-flv)$ 43200 
90% 432000 override-expire ignore-no-cache ignore-no-store ignore-private
refresh_pattern -i 
\.(tar|run|deb|pkg|bz2|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff)$ 
10080 90% 43200 override-expire ignore-no-cache ignore-no-store 
ignore-private
refresh_pattern -i \.index.(html|htm)$ 0 40% 10080
refresh_pattern -i \.(html|htm|css|js)$ 1440 40% 40320
refresh_pattern . 0 40% 40320

Am 23.06.2016 um 10:48 schrieb Eliezer Croitoru:
> Hey David,
>
> Are you using a squid instance with some old config file?
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of David
> Sent: Thursday, June 23, 2016 8:17 AM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Preparing for shutdown after xxx requests
>
> So far Squid worked nice, but recently it shutdown again and again with:
>
> Preparing for shutdown after xxx requests
>
> has someone a hint what that causes squid to shutdown
>
> Squid Cache: Version 3.5.19
> on Archlinux
>
> free -h:
>                          total          used        free      shared
> Puffer/Cache cached
> Mem:              7.7G        3.4G        672M        333M 3.7G        3.7G
> Swap:             4.0G         41M        4.0G
>
> 2016/06/23 07:45:06| Set Current Directory to /var/cache/squid
> 2016/06/23 07:45:06 kid1| Preparing for shutdown after 967 requests
> 2016/06/23 07:45:06 kid1| Waiting 10 seconds for active connections to
> finish
> 2016/06/23 07:45:06 kid1| Closing HTTP port [::]:3128
> 2016/06/23 07:45:06 kid1| Set Current Directory to /var/cache/squid
> 2016/06/23 07:45:06 kid1| Starting Squid Cache version 3.5.19 for
> x86_64-pc-linux-gnu...
> 2016/06/23 07:45:06 kid1| Service Name: squid
> 2016/06/23 07:45:06 kid1| Process ID 17879
> 2016/06/23 07:45:06 kid1| Process Roles: worker
> 2016/06/23 07:45:06 kid1| With 1024 file descriptors available
> 2016/06/23 07:45:06 kid1| Initializing IP Cache...
> 2016/06/23 07:45:06 kid1| DNS Socket created at [::], FD 8
> 2016/06/23 07:45:06 kid1| DNS Socket created at 0.0.0.0, FD 9
> 2016/06/23 07:45:06 kid1| Adding nameserver 192.168.2.1 from
> /etc/resolv.conf
> 2016/06/23 07:45:06 kid1| Logfile: opening log
> daemon:/var/log/squid/access.log
> 2016/06/23 07:45:06 kid1| Logfile Daemon: opening log
> /var/log/squid/access.log
> 2016/06/23 07:45:06 kid1| Local cache digest enabled; rebuild/rewrite
> every 3600/3600 sec
> 2016/06/23 07:45:06 kid1| Store logging disabled
> 2016/06/23 07:45:06 kid1| Swap maxSize 61440000 + 3072000 KB, estimated
> 4962461 objects
> 2016/06/23 07:45:06 kid1| Target number of buckets: 248123
> 2016/06/23 07:45:06 kid1| Using 262144 Store buckets
> 2016/06/23 07:45:06 kid1| Max Mem  size: 3072000 KB
> 2016/06/23 07:45:06 kid1| Max Swap size: 61440000 KB
> 2016/06/23 07:45:06 kid1| Rebuilding storage in /var/cache/squid (dirty log)
> 2016/06/23 07:45:06 kid1| Using Least Load store dir selection
> 2016/06/23 07:45:06 kid1| Set Current Directory to /var/cache/squid
> 2016/06/23 07:45:06 kid1| Finished loading MIME types and icons.
> 2016/06/23 07:45:06 kid1| HTCP Disabled.
> 2016/06/23 07:45:06 kid1| Squid plugin modules loaded: 0
> 2016/06/23 07:45:06 kid1| Adaptation support is off.
> 2016/06/23 07:45:06 kid1| Accepting HTTP Socket connections at
> local=[::]:3128 remote=[::] FD 14 flags=9
> 2016/06/23 07:45:07 kid1| Store rebuilding is 53.75% complete
> 2016/06/23 07:45:07 kid1| Done reading /var/cache/squid swaplog (7441
> entries)
> 2016/06/23 07:45:07 kid1| Finished rebuilding storage from disk.
> 2016/06/23 07:45:07 kid1|      7422 Entries scanned
> 2016/06/23 07:45:07 kid1|         0 Invalid entries.
> 2016/06/23 07:45:07 kid1|         0 With invalid flags.
> 2016/06/23 07:45:07 kid1|      7403 Objects loaded.
> 2016/06/23 07:45:07 kid1|         0 Objects expired.
> 2016/06/23 07:45:07 kid1|         0 Objects cancelled.
> 2016/06/23 07:45:07 kid1|        19 Duplicate URLs purged.
> 2016/06/23 07:45:07 kid1|         0 Swapfile clashes avoided.
> 2016/06/23 07:45:07 kid1|   Took 0.07 seconds (100137.97 objects/sec).
> 2016/06/23 07:45:07 kid1| Beginning Validation Procedure
> 2016/06/23 07:45:07 kid1|   Completed Validation Procedure
> 2016/06/23 07:45:07 kid1|   Validated 7403 Entries
> 2016/06/23 07:45:07 kid1|   store_swap_size = 490076.00 KB
> 2016/06/23 07:45:07 kid1| storeLateRelease: released 0 objects
> 2016/06/23 07:51:30| Set Current Directory to /var/cache/squid
> 2016/06/23 07:51:30 kid1| Preparing for shutdown after 28 requests
> 2016/06/23 07:51:30 kid1| Waiting 10 seconds for active connections to
> finish
> 2016/06/23 07:51:30 kid1| Closing HTTP port [::]:3128
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



From ozgurbtr at gmail.com  Fri Jun 24 12:14:16 2016
From: ozgurbtr at gmail.com (Ozgur Batur)
Date: Fri, 24 Jun 2016 15:14:16 +0300
Subject: [squid-users] flickr.com redirect error
Message-ID: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>

I receive too many redirects(301 responses with same page URL) error
on browser when opening https://www.flickr.com via Squid 3.5 proxy
with SSL interception. If I connect to flickr website directly without
Squid error does not happen.


I tested it on two different systems one is Centos other is Ubuntu.
There is no acl, redirect or any other configuration in squid.conf
except enabling SSL interception.


I opened http://bugs.squid-cache.org/show_bug.cgi?id=4537 for this
issue but later thought it is better to ask if you also experience the
same issue.



Ozgur
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160624/8223ef3c/attachment.htm>

From yvoinov at gmail.com  Fri Jun 24 12:50:02 2016
From: yvoinov at gmail.com (Yuri)
Date: Fri, 24 Jun 2016 18:50:02 +0600
Subject: [squid-users] flickr.com redirect error
In-Reply-To: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
References: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
Message-ID: <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>

Try to do something like:


# 301 loop
acl text_mime rep_mime_type text/html text/plain

acl http301 http_status 301

store_miss deny text_mime http301
send_hit deny text_mime http301


24.06.2016 18:14, Ozgur Batur ?????:
> I receive too many redirects(301 responses with same page URL) error 
> on browser when opening https://www.flickr.com via Squid 3.5 proxy 
> with SSL interception. If I connect to flickr website directly without 
> Squid error does not happen.
> I tested it on two different systems one is Centos other is Ubuntu. 
> There is no acl, redirect or any other configuration in squid.conf 
> except enabling SSL interception.
> I opened http://bugs.squid-cache.org/show_bug.cgi?id=4537 for this 
> issue but later thought it is better to ask if you also experience the 
> same issue.
>
>
> Ozgur
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160624/12565413/attachment.htm>

From chip_pop at hotmail.com  Fri Jun 24 12:31:13 2016
From: chip_pop at hotmail.com (joe)
Date: Fri, 24 Jun 2016 05:31:13 -0700 (PDT)
Subject: [squid-users] ecap adaper
Message-ID: <1466771473974-4678171.post@n4.nabble.com>

hi wen using ecap adapter
ecap_enable on
acl HTTP_STATUS_OK http_status 200
loadable_modules /usr/local/lib/ecap_adapter_gzip.so
ecap_service gzip_service respmod_precache ecap://www.vigos.com/ecap_gzip
bypass=off
adaptation_access gzip_service allow HTTP_STATUS_OK 
wen the link has status 200   and its  POST not GET
the adapeter or ecap or squid some how wen a link has POST and the adapeter
change it to GET or its refusing POST i dont know exactly wats happening 
but the app in phone freez waiting
is there a way to bypass POST not to go trough ecap or anythink i can do
????
this is the link that freez has post other then that its working fine

1466763366.861   1059 10.4.4.61 TCP_MISS/200 30516 POST
http://prod2.dominationsgame.com/snc/api2?app_version=41010000&hash=1&userid=6897921&st=/PU=&bh=28&sd=636023599967637129&hs=7497&rm=683627205y683627355&bmj=683627355&bmi=683627200
- ORIGINAL_DST/54.225.199.115 application/json 
[Content-Type: application/x-www-form-urlencoded\r\n
Accept-Encoding: gzip, identity\r\n
Connection: Keep-Alive, TE\r\n
TE: identity\r\n
User-Agent: BestHTTP\r\nContent-Length: 720\r\n
Host: prod2.dominationsgame.com\r\n] 
------------------------------------------------
[HTTP/1.1 200 OK\r\n
Server: Apache-Coyote/1.1\r\n
Pragma: no-cache\r\n
Expires: Thu, 01 Jan 1970 00:00:00 GMT\r\n
Cache-Control: no-cache\r\n
Cache-Control: no-store\r\n
Set-Cookie: JSESSIONID=EF31B93DC2F43C30BEF805EA91CE2B92; Path=/snc/;
HttpOnly\r\n
Content-Type: application/json;charset=UTF-8\r\n
Content-Length: 30112\r\n
Date: Fri, 24 Jun 2016 10:13:18 GMT\r\n\r]




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/ecap-adaper-tp4678171.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From ozgurbtr at gmail.com  Fri Jun 24 14:23:26 2016
From: ozgurbtr at gmail.com (Ozgur Batur)
Date: Fri, 24 Jun 2016 17:23:26 +0300
Subject: [squid-users] flickr.com redirect error
In-Reply-To: <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>
References: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
 <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>
Message-ID: <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>

Hi Yuri,

Thank you. I put the #301 loop directives and restarted squid unfortunately
result is the same. Here is the access logs:

1466777191.791    235 ::1 TCP_MISS/301 987 GET https://www.flickr.com/ -
HIER_DIRECT/188.125.93.100 text/html
1466777192.031    237 ::1 TCP_MISS/301 987 GET https://www.flickr.com/ -
HIER_DIRECT/188.125.93.100 text/html
1466777192.386    352 ::1 TCP_MISS/301 987 GET https://www.flickr.com/ -
HIER_DIRECT/188.125.93.100 text/html
1466777192.612    223 ::1 TCP_MISS/301 987 GET https://www.flickr.com/ -
HIER_DIRECT/188.125.93.100 text/html
...

As I understand all responses are from origin server, there is no cache hit
with or without store_miss and send_hit. Confusing part is when directly
connected to server without proxy, flickr server does not send 301
response. When squid sends the same request somehow flickr server returns
301 with same URL.

Ozgur


On Fri, Jun 24, 2016 at 3:50 PM, Yuri <yvoinov at gmail.com> wrote:

> Try to do something like:
>
>
> # 301 loop
> acl text_mime rep_mime_type text/html text/plain
>
> acl http301 http_status 301
>
> store_miss deny text_mime http301
> send_hit deny text_mime http301
>
>
> 24.06.2016 18:14, Ozgur Batur ?????:
>
> I receive too many redirects(301 responses with same page URL) error on browser when opening https://www.flickr.com via Squid 3.5 proxy with SSL interception. If I connect to flickr website directly without Squid error does not happen.
>
>
> I tested it on two different systems one is Centos other is Ubuntu. There is no acl, redirect or any other configuration in squid.conf except enabling SSL interception.
>
>
> I opened http://bugs.squid-cache.org/show_bug.cgi?id=4537 for this issue but later thought it is better to ask if you also experience the same issue.
>
>
>
> Ozgur
>
>
> _______________________________________________
> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160624/552babca/attachment.htm>

From yvoinov at gmail.com  Fri Jun 24 14:41:14 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 24 Jun 2016 20:41:14 +0600
Subject: [squid-users] flickr.com redirect error
In-Reply-To: <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>
References: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
 <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>
 <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>
Message-ID: <5a3f71a4-1556-7afb-04f8-1668f4d72871@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Hm. My opinion is the same - this is redirection loop. Just need to
localize it.


24.06.2016 20:23, Ozgur Batur ?????:
> Hi Yuri,
>
> Thank you. I put the #301 loop directives and restarted squid
unfortunately result is the same. Here is the access logs:
>
> 1466777191.791    235 ::1 TCP_MISS/301 987 GET https://www.flickr.com/
- HIER_DIRECT/188.125.93.100 <http://188.125.93.100> text/html
> 1466777192.031    237 ::1 TCP_MISS/301 987 GET https://www.flickr.com/
- HIER_DIRECT/188.125.93.100 <http://188.125.93.100> text/html
> 1466777192.386    352 ::1 TCP_MISS/301 987 GET https://www.flickr.com/
- HIER_DIRECT/188.125.93.100 <http://188.125.93.100> text/html
> 1466777192.612    223 ::1 TCP_MISS/301 987 GET https://www.flickr.com/
- HIER_DIRECT/188.125.93.100 <http://188.125.93.100> text/html
> ...
>
> As I understand all responses are from origin server, there is no
cache hit with or without store_miss and send_hit. Confusing part is
when directly connected to server without proxy, flickr server does not
send 301 response. When squid sends the same request somehow flickr
server returns 301 with same URL.
>
> Ozgur
>
>
> On Fri, Jun 24, 2016 at 3:50 PM, Yuri <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>     Try to do something like:
>
>
>     # 301 loop
>     acl text_mime rep_mime_type text/html text/plain
>
>     acl http301 http_status 301
>
>     store_miss deny text_mime http301
>     send_hit deny text_mime http301
>
>
>     24.06.2016 18:14, Ozgur Batur ?????:
>>     I receive too many redirects(301 responses with same page URL)
error on browser when opening https://www.flickr.com via Squid 3.5 proxy
with SSL interception. If I connect to flickr website directly without
Squid error does not happen.
>>
>>     I tested it on two different systems one is Centos other is
Ubuntu. There is no acl, redirect or any other configuration in
squid.conf except enabling SSL interception.
>>
>>     I opened http://bugs.squid-cache.org/show_bug.cgi?id=4537 for
this issue but later thought it is better to ask if you also experience
the same issue.
>>
>>
>>     Ozgur
>>
>>
>>     _______________________________________________
>>     squid-users mailing list
>>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>>     http://lists.squid-cache.org/listinfo/squid-users
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXbUaJAAoJENNXIZxhPexGGpwIAK4mYSAoZbIU96VbS3L/Xq+f
6taPqkZrvy9JPU3aS92qE0bSuJFjtQrJ9lz8W8zAygeljyhCgwct9/9qBCy1gX25
7Z6qJj4UTfS7dIxb5NnAq2CHovuKiqvv6HThBqQ9J8/bq3jYk7u3rNK60ZEMK2Wg
sHaVLDiJMVu9gFCiYWlaPnBpFvse20gqybwhrhysjdM94HWAGOT9Oe+YWxIdB+Fj
lq1Udt3i4EvHrz4tOOgf5gggUVTBk7VttcKhgko9hI+KnfL3S2Yk2phzWX4apVt4
aDV/LKzb8vU33jOR9fV/sIOS0TyeBcIm3lokDWNfjB1SEjxQxXNPI1iOVggQv0Q=
=Sr78
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160624/085d625a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160624/085d625a/attachment.key>

From rafael.akchurin at diladele.com  Fri Jun 24 15:29:29 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Fri, 24 Jun 2016 15:29:29 +0000
Subject: [squid-users] flickr.com redirect error
In-Reply-To: <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>
References: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
 <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>
 <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>
Message-ID: <VI1PR04MB1359499FE2D9A57B3C0C33638F2E0@VI1PR04MB1359.eurprd04.prod.outlook.com>

Hello Ozgur, Yuri,

I also see this error. Actually it is even present on videos.yahoo.com if I am not mistaken.
The reason for this is unclear for me (incorrect handling of ?Via? header by some of back office servers of Yahoo???)

I was able to fix it by setting ?via off? in squid.conf. I am not sure if this is the recommended way ( I presume not) and how to disable Via only for yahoo servers. Hopefully Amos has better answers.

Via looks like:

Via:"http/1.1 fts110.flickr.bf1.yahoo.com (ApacheTrafficServer [cMs f ]), http/1.1 r02.ycpi.ams.yahoo.net (ApacheTrafficServer [cMsSf ]), 1.1 qlproxy (squid/3.3.8)"

Best regards,
Rafael Akchurin
Diladele B.V.

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Ozgur Batur
Sent: Friday, June 24, 2016 4:23 PM
To: Yuri <yvoinov at gmail.com>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] flickr.com redirect error

Hi Yuri,

Thank you. I put the #301 loop directives and restarted squid unfortunately result is the same. Here is the access logs:

1466777191.791    235 ::1 TCP_MISS/301 987 GET https://www.flickr.com/ - HIER_DIRECT/188.125.93.100<http://188.125.93.100> text/html
1466777192.031    237 ::1 TCP_MISS/301 987 GET https://www.flickr.com/ - HIER_DIRECT/188.125.93.100<http://188.125.93.100> text/html
1466777192.386    352 ::1 TCP_MISS/301 987 GET https://www.flickr.com/ - HIER_DIRECT/188.125.93.100<http://188.125.93.100> text/html
1466777192.612    223 ::1 TCP_MISS/301 987 GET https://www.flickr.com/ - HIER_DIRECT/188.125.93.100<http://188.125.93.100> text/html
...

As I understand all responses are from origin server, there is no cache hit with or without store_miss and send_hit. Confusing part is when directly connected to server without proxy, flickr server does not send 301 response. When squid sends the same request somehow flickr server returns 301 with same URL.

Ozgur


On Fri, Jun 24, 2016 at 3:50 PM, Yuri <yvoinov at gmail.com<mailto:yvoinov at gmail.com>> wrote:

Try to do something like:



# 301 loop
acl text_mime rep_mime_type text/html text/plain

acl http301 http_status 301

store_miss deny text_mime http301
send_hit deny text_mime http301

24.06.2016 18:14, Ozgur Batur ?????:

I receive too many redirects(301 responses with same page URL) error on browser when opening https://www.flickr.com via Squid 3.5 proxy with SSL interception. If I connect to flickr website directly without Squid error does not happen.



I tested it on two different systems one is Centos other is Ubuntu. There is no acl, redirect or any other configuration in squid.conf except enabling SSL interception.



I opened http://bugs.squid-cache.org/show_bug.cgi?id=4537 for this issue but later thought it is better to ask if you also experience the same issue.


Ozgur


_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

http://lists.squid-cache.org/listinfo/squid-users


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160624/6b230df6/attachment.htm>

From ozgurbtr at gmail.com  Fri Jun 24 15:40:02 2016
From: ozgurbtr at gmail.com (Ozgur Batur)
Date: Fri, 24 Jun 2016 18:40:02 +0300
Subject: [squid-users] flickr.com redirect error
In-Reply-To: <VI1PR04MB1359499FE2D9A57B3C0C33638F2E0@VI1PR04MB1359.eurprd04.prod.outlook.com>
References: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
 <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>
 <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>
 <VI1PR04MB1359499FE2D9A57B3C0C33638F2E0@VI1PR04MB1359.eurprd04.prod.outlook.com>
Message-ID: <CAAFc9FhiXeMc=J5SECc-MjF4hBDjXRZyS9zDtgMPjSz_iMEkKw@mail.gmail.com>

Hi Rafael, Yuri,

Thank you very much, "via off" did the trick. It is probably a server
specific issue as you said.

Best Regards,

On Fri, Jun 24, 2016 at 6:29 PM, Rafael Akchurin <
rafael.akchurin at diladele.com> wrote:

> Hello Ozgur, Yuri,
>
>
>
> I also see this error. Actually it is even present on videos.yahoo.com if
> I am not mistaken.
>
> The reason for this is unclear for me (incorrect handling of ?Via? header
> by some of back office servers of Yahoo???)
>
>
>
> I was able to fix it by setting ?via off? in squid.conf. I am not sure if
> this is the recommended way ( I presume not) and how to disable Via only
> for yahoo servers. Hopefully Amos has better answers.
>
>
>
> Via looks like:
>
>
>
> Via:"http/1.1 fts110.flickr.bf1.yahoo.com (ApacheTrafficServer [cMs f ]),
> http/1.1 r02.ycpi.ams.yahoo.net (ApacheTrafficServer [cMsSf ]), 1.1
> qlproxy (squid/3.3.8)"
>
>
>
> Best regards,
>
> Rafael Akchurin
>
> Diladele B.V.
>
>
>
> *From:* squid-users [mailto:squid-users-bounces at lists.squid-cache.org] *On
> Behalf Of *Ozgur Batur
> *Sent:* Friday, June 24, 2016 4:23 PM
> *To:* Yuri <yvoinov at gmail.com>
> *Cc:* squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] flickr.com redirect error
>
>
>
> Hi Yuri,
>
>
>
> Thank you. I put the #301 loop directives and restarted squid
> unfortunately result is the same. Here is the access logs:
>
>
>
> 1466777191.791    235 ::1 TCP_MISS/301 987 GET https://www.flickr.com/ -
> HIER_DIRECT/188.125.93.100 text/html
>
> 1466777192.031    237 ::1 TCP_MISS/301 987 GET https://www.flickr.com/ -
> HIER_DIRECT/188.125.93.100 text/html
>
> 1466777192.386    352 ::1 TCP_MISS/301 987 GET https://www.flickr.com/ -
> HIER_DIRECT/188.125.93.100 text/html
>
> 1466777192.612    223 ::1 TCP_MISS/301 987 GET https://www.flickr.com/ -
> HIER_DIRECT/188.125.93.100 text/html
>
> ...
>
>
>
> As I understand all responses are from origin server, there is no cache
> hit with or without store_miss and send_hit. Confusing part is when
> directly connected to server without proxy, flickr server does not send 301
> response. When squid sends the same request somehow flickr server returns
> 301 with same URL.
>
>
>
> Ozgur
>
>
>
>
>
> On Fri, Jun 24, 2016 at 3:50 PM, Yuri <yvoinov at gmail.com> wrote:
>
> Try to do something like:
>
>
>
> # 301 loop
> acl text_mime rep_mime_type text/html text/plain
>
> acl http301 http_status 301
>
> store_miss deny text_mime http301
> send_hit deny text_mime http301
>
>
>
> 24.06.2016 18:14, Ozgur Batur ?????:
>
> I receive too many redirects(301 responses with same page URL) error on browser when opening https://www.flickr.com via Squid 3.5 proxy with SSL interception. If I connect to flickr website directly without Squid error does not happen.
>
>
>
> I tested it on two different systems one is Centos other is Ubuntu. There is no acl, redirect or any other configuration in squid.conf except enabling SSL interception.
>
>
>
> I opened http://bugs.squid-cache.org/show_bug.cgi?id=4537 for this issue but later thought it is better to ask if you also experience the same issue.
>
>
>
>
>
> Ozgur
>
>
>
> _______________________________________________
>
> squid-users mailing list
>
> squid-users at lists.squid-cache.org
>
> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
>



-- 
H ?zg?r Batur
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160624/71b17e94/attachment.htm>

From yvoinov at gmail.com  Fri Jun 24 16:02:49 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 24 Jun 2016 22:02:49 +0600
Subject: [squid-users] flickr.com redirect error
In-Reply-To: <CAAFc9FhiXeMc=J5SECc-MjF4hBDjXRZyS9zDtgMPjSz_iMEkKw@mail.gmail.com>
References: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
 <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>
 <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>
 <VI1PR04MB1359499FE2D9A57B3C0C33638F2E0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <CAAFc9FhiXeMc=J5SECc-MjF4hBDjXRZyS9zDtgMPjSz_iMEkKw@mail.gmail.com>
Message-ID: <e98e89ff-cb01-51a1-c6ca-6c9a714ddecb@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Be careful, guys. Via is reauired to HTTP by RFC.


24.06.2016 21:40, Ozgur Batur ?????:
> Hi Rafael, Yuri,
>
> Thank you very much, "via off" did the trick. It is probably a server
specific issue as you said.
>
> Best Regards,
>
> On Fri, Jun 24, 2016 at 6:29 PM, Rafael Akchurin
<rafael.akchurin at diladele.com <mailto:rafael.akchurin at diladele.com>> wrote:
>
>     Hello Ozgur, Yuri,
>
>     
>
>     I also see this error. Actually it is even present on
videos.yahoo.com <http://videos.yahoo.com> if I am not mistaken.
>
>     The reason for this is unclear for me (incorrect handling of ?Via?
header by some of back office servers of Yahoo???)
>
>     
>
>     I was able to fix it by setting ?via off? in squid.conf. I am not
sure if this is the recommended way ( I presume not) and how to disable
Via only for yahoo servers. Hopefully Amos has better answers.
>
>     
>
>     Via looks like:
>
>     
>
>     Via:"http/1.1 fts110.flickr.bf1.yahoo.com
<http://fts110.flickr.bf1.yahoo.com> (ApacheTrafficServer [cMs f ]),
http/1.1 r02.ycpi.ams.yahoo.net <http://r02.ycpi.ams.yahoo.net>
(ApacheTrafficServer [cMsSf ]), 1.1 qlproxy (squid/3.3.8)"
>
>     
>
>     Best regards,
>
>     Rafael Akchurin
>
>     Diladele B.V.
>
>     
>
>     *From:*squid-users
[mailto:squid-users-bounces at lists.squid-cache.org
<mailto:squid-users-bounces at lists.squid-cache.org>] *On Behalf Of *Ozgur
Batur
>     *Sent:* Friday, June 24, 2016 4:23 PM
>     *To:* Yuri <yvoinov at gmail.com <mailto:yvoinov at gmail.com>>
>     *Cc:* squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     *Subject:* Re: [squid-users] flickr.com <http://flickr.com>
redirect error
>
>     
>
>     Hi Yuri,
>
>     
>
>     Thank you. I put the #301 loop directives and restarted squid
unfortunately result is the same. Here is the access logs:
>
>     
>
>     1466777191.791    235 ::1 TCP_MISS/301 987 GET
https://www.flickr.com/ - HIER_DIRECT/188.125.93.100
<http://188.125.93.100> text/html
>
>     1466777192.031    237 ::1 TCP_MISS/301 987 GET
https://www.flickr.com/ - HIER_DIRECT/188.125.93.100
<http://188.125.93.100> text/html
>
>     1466777192.386    352 ::1 TCP_MISS/301 987 GET
https://www.flickr.com/ - HIER_DIRECT/188.125.93.100
<http://188.125.93.100> text/html
>
>     1466777192.612    223 ::1 TCP_MISS/301 987 GET
https://www.flickr.com/ - HIER_DIRECT/188.125.93.100
<http://188.125.93.100> text/html
>
>     ...
>
>     
>
>     As I understand all responses are from origin server, there is no
cache hit with or without store_miss and send_hit. Confusing part is
when directly connected to server without proxy, flickr server does not
send 301 response. When squid sends the same request somehow flickr
server returns 301 with same URL.
>
>     
>
>     Ozgur
>
>     
>
>     
>
>     On Fri, Jun 24, 2016 at 3:50 PM, Yuri <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>         Try to do something like:
>
>         
>
>         # 301 loop
>         acl text_mime rep_mime_type text/html text/plain
>
>         acl http301 http_status 301
>
>         store_miss deny text_mime http301
>         send_hit deny text_mime http301
>
>         
>
>         24.06.2016 18:14, Ozgur Batur ?????:
>
>             I receive too many redirects(301 responses with same page
URL) error on browser when opening https://www.flickr.com via Squid 3.5
proxy with SSL interception. If I connect to flickr website directly
without Squid error does not happen.
>
>             
>
>             I tested it on two different systems one is Centos other
is Ubuntu. There is no acl, redirect or any other configuration in
squid.conf except enabling SSL interception.
>
>             
>
>             I opened http://bugs.squid-cache.org/show_bug.cgi?id=4537
for this issue but later thought it is better to ask if you also
experience the same issue.
>
>             
>
>             
>
>             Ozgur
>
>             
>
>             _______________________________________________
>
>             squid-users mailing list
>
>             squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>             http://lists.squid-cache.org/listinfo/squid-users
>
>         
>
>
>         _______________________________________________
>         squid-users mailing list
>         squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>         http://lists.squid-cache.org/listinfo/squid-users
>
>     
>
>
>
>
> --
> H ?zg?r Batur

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXbVmoAAoJENNXIZxhPexGPFgH/ib6RKjQ/JhhnvTtBQnM6euV
+F6e/rrf6B295OpsrUgqFdogmCshJZGivdSBd8266KPOlvxE3I0F01SNBtAt96wC
1pL3Sam+TmFwbOGa5vYStQ+ZAkn5ReiSHppKVdeR1lXxBlMuhcDJovIxDtXvVV5G
SZcmJWT1q+LS8vcS+mGybXOt0H7J32sSUyor+qJ0CZEfG5HEPb1XKjave1mJNxUj
JEwsL0/B5zVw8LtL2yOzZY7E3ERY0r2ieGqQ4GpzYUVoDwoc5q8xwKaU08j5qyrP
iS2fW8wbAZ2RoZmvJRxnFpFKel0NgzwrAOUeSAs8hPONUUpWaklFTL55lezNY+A=
=t07f
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160624/a81be37d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160624/a81be37d/attachment.key>

From cbidwell at usgs.gov  Fri Jun 24 16:48:00 2016
From: cbidwell at usgs.gov (Bidwell, Christopher)
Date: Fri, 24 Jun 2016 10:48:00 -0600
Subject: [squid-users] Squid question with letsencrypt
Message-ID: <CAJN-FKmSPS2xo+RMMYjNsUa3hqnd_C++q4cVwjsXezVrCzSaFw@mail.gmail.com>

Hi all,

I'm very new to squid and we are wanting to implement letsencrypt for our
ssl certificates.

Here's the scenario:

We've got several frontend servers running squid that are caching from the
backend systems.

i.e. test.com -> 10.0.0.1, 10.0.1.1, 10.0.2.1 (all physically separated
from one another)

Each internal server also has its own dns name:

web1.test.com -> 10.0.0.1
web2.test.com -> 10.0.1.1
web3.test.com -> 10.0.2.1

Note that these are all public. Using 10. as examples.

I'd like to create a SAN certificate naming the 3 internal systems in
addition to the public name:

test.com, web1.test.com, web2.test.com, and web3.test.com.

On the letsencrypt forum they said that I could do a HTTP 301 redirect from
the squid servers to the backend letsencrypt server where any match for:
 /.well-known/acme-challenge/* would redirect with an HTTP 301 to that
backend letsencrypt server.  I'm not sure how to do this and the squid
documentation is not easy to comprehend.

Let me know if this isn't clear how I've explained this.


Thanks!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160624/472a5765/attachment.htm>

From chip_pop at hotmail.com  Fri Jun 24 16:52:03 2016
From: chip_pop at hotmail.com (joe)
Date: Fri, 24 Jun 2016 09:52:03 -0700 (PDT)
Subject: [squid-users] ecap adaper
In-Reply-To: <1466771473974-4678171.post@n4.nabble.com>
References: <1466771473974-4678171.post@n4.nabble.com>
Message-ID: <1466787123118-4678178.post@n4.nabble.com>

if i do with regex it work it bypass it
acl redirecturls url_regex -i \/snc\/api2
adaptation_access gzip_service allow HTTP_STATUS_OK !redirecturls

this preventing method dose not work
acl nomethod method POST
adaptation_access gzip_service allow HTTP_STATUS_OK !nomethod 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/ecap-adaper-tp4678171p4678178.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From stefan at hoelzle.work  Fri Jun 24 18:27:41 2016
From: stefan at hoelzle.work (=?UTF-8?Q?Stefan_H=c3=b6lzle?=)
Date: Fri, 24 Jun 2016 20:27:41 +0200
Subject: [squid-users] Conditional IPv6 usage
Message-ID: <576D7B9D.4050406@hoelzle.work>

Hello,

I'm having trouble configuring a forward proxy.
My goal is the following:
Only for one destination domain IPv6 should be used, otherwise IPv4.

The proxy has multiple incoming IPs and multiple outgoing IPs, here is
the relevant part of the squid.conf:

acl port80 localport 80
acl port88 localport 88
acl port443 localport 443

http_port 10.0.0.54:80
http_port 10.0.0.54:443
http_port 10.0.0.59:80
http_port 10.0.0.59:443
http_port 10.0.0.59:88

acl ipA localip 10.0.0.54
acl ipB localip 10.0.0.59

# only somedomain.asdf via IPv6
acl domain_acl dstdom_regex -i \.somedomain\.asdf

tcp_outgoing_address 10.0.0.93 ipB port88
tcp_outgoing_address 2001:cdba::3257:9652 ipB port88 domain_acl

tcp_outgoing_address 10.0.0.54 ipA port80
tcp_outgoing_address 10.0.0.63 ipA port443
tcp_outgoing_address 10.0.0.59 ipB port80
tcp_outgoing_address 10.0.0.93 ipB port443

dns_v4_first on

Expected behavior:
A connection on http_port 10.0.0.59:88 is requesting a domain matching
regex "\.somedomain\.asdf", then the first matching tcp_outgoing_address
is used, namely

tcp_outgoing_address 2001:cdba::3257:9652 ipB port88 domain_acl


Actual behavior:
A connection on http_port 10.0.0.59:88 is requesting a domain matching
regex "\.somedomain\.net" and

tcp_outgoing_address 10.0.1.54 ipA port80

is used.
If I change dns_v4_first from on to off,

tcp_outgoing_address 2001:cdba::3257:9652 ipB port88 domain_acl

is used for any incoming http_port.


Does anyone know why squid behaves the way it does ?

Thanks and best regards

-- 
Stefan 



From cbidwell at usgs.gov  Fri Jun 24 18:39:29 2016
From: cbidwell at usgs.gov (Bidwell, Christopher)
Date: Fri, 24 Jun 2016 12:39:29 -0600
Subject: [squid-users] Squid Rewrites
Message-ID: <CAJN-FKmkvA7xFXxpg7wqk=c14FzbMJ-WXkCoG0CMJhmA96hFxA@mail.gmail.com>

Hi all,

Just curious if you could help me figure out what the equivalent of this
apache rule would be for squid:

RewriteRule      ^/dyfi/?$             http://servername.com/data/dyfi/
 [R=301,L]
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160624/bc1cfdfc/attachment.htm>

From squid3 at treenet.co.nz  Sat Jun 25 05:35:23 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 25 Jun 2016 17:35:23 +1200
Subject: [squid-users] Conditional IPv6 usage
In-Reply-To: <576D7B9D.4050406@hoelzle.work>
References: <576D7B9D.4050406@hoelzle.work>
Message-ID: <1e0703b4-3fff-62f9-f215-1d2a9b2bf33b@treenet.co.nz>

On 25/06/2016 6:27 a.m., Stefan H?lzle wrote:
> Hello,
> 
> I'm having trouble configuring a forward proxy.
> My goal is the following:
> Only for one destination domain IPv6 should be used, otherwise IPv4.

This is not how the Internet Protocol (IP) works. If a domain is
advertising IPv6 addresses, then it can and should be contacted using
those addresses.

> 
> The proxy has multiple incoming IPs and multiple outgoing IPs, here is
> the relevant part of the squid.conf:
> 
> acl port80 localport 80
> acl port88 localport 88
> acl port443 localport 443
> 
> http_port 10.0.0.54:80
> http_port 10.0.0.54:443
> http_port 10.0.0.59:80
> http_port 10.0.0.59:443
> http_port 10.0.0.59:88

Problem #1: you are configuring a forward proxy on port 80 and 443 which
are registered ports for reverse-proxy traffic syntax.

This is not necessarily a big problem. But other software in the
environment that handles port 80 and 443 traffic may interpret the
format wrongly and scew things up.


> 
> acl ipA localip 10.0.0.54
> acl ipB localip 10.0.0.59
> 
> # only somedomain.asdf via IPv6
> acl domain_acl dstdom_regex -i \.somedomain\.asdf
> 
> tcp_outgoing_address 10.0.0.93 ipB port88
> tcp_outgoing_address 2001:cdba::3257:9652 ipB port88 domain_acl
> 
> tcp_outgoing_address 10.0.0.54 ipA port80
> tcp_outgoing_address 10.0.0.63 ipA port443
> tcp_outgoing_address 10.0.0.59 ipB port80
> tcp_outgoing_address 10.0.0.93 ipB port443
> 
> dns_v4_first on
> 
> Expected behavior:
> A connection on http_port 10.0.0.59:88 is requesting a domain matching
> regex "\.somedomain\.asdf", then the first matching tcp_outgoing_address
> is used, namely
> 
> tcp_outgoing_address 2001:cdba::3257:9652 ipB port88 domain_acl
> 

Expectation is a bit wrong.

tcp_outgoing_address configures _which address to use the type of
traffic that server requires. The connection has already been allowed by
tha http_access rules - which do not distinguish whether IPv4 or IPv6 is
used to contact any particular server.


You literally cannot send traffic to an IPv6 addressed server using IPv4
packet format. Nor vice versa. Squid knows that and does not attempt to
use the wrong family of IP for any outgoing traffic.

So:
- The server destination *has already been selected for use* by
determining in various *_access lists that the client is allowed to
contact that *domain*.

- IPv6 entries are ignored for IPv4 server destinations.

- IPv4 entries are ignored for IPv6 server destinations.

> 
> Actual behavior:
> A connection on http_port 10.0.0.59:88 is requesting a domain matching
> regex "\.somedomain\.net" and
> 

Incoming port has nothing to do with outgoing IP format.

* DNS tells Squid a set of IP addresses that the domain can be contacted at.

** "dns_v4_first on" tells Squid to use the servers A address(es) as
first choice before attempting IPv6 contact.

That domain *does* have an A address. So...

> tcp_outgoing_address 10.0.1.54 ipA port80
> 
> is used.

If that fails it might fail over to another IPv4 or to the domains IPv6
address.


> If I change dns_v4_first from on to off,
> 

** then "dns_v4_first on" tells Squid to use the servers AAAA address as
first choice before attempting IPv6 contact.

** That domain *does* have an AAAA address. So ...

> tcp_outgoing_address 2001:cdba::3257:9652 ipB port88 domain_acl
> 

... or the machines default IPv6 addresss is used when contacting the
servers AAAA address(es).

If that fails then Squid might failover to another of the servers IPv6
addresses, or to its IPv4 address.




You can choose a particular IP from amongst the appropriate v4/v6 types
available. But you cannot force a particular type to be used.
 (though you might configure an IPv4/IPv6 address which will force
breakage on the connection).


It is the network firewalls job to determine whether *Squid* is allowed
contact from IP A to IP B. If it blocks unwanted IPv6 traffic properly,
then the normal ICMPv6 packet that comes back from the firewall will
tell Squid to try the next IP on the list for the server being contacted.


HTH
Amos



From squid3 at treenet.co.nz  Sat Jun 25 05:40:09 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 25 Jun 2016 17:40:09 +1200
Subject: [squid-users] Squid Rewrites
In-Reply-To: <CAJN-FKmkvA7xFXxpg7wqk=c14FzbMJ-WXkCoG0CMJhmA96hFxA@mail.gmail.com>
References: <CAJN-FKmkvA7xFXxpg7wqk=c14FzbMJ-WXkCoG0CMJhmA96hFxA@mail.gmail.com>
Message-ID: <69175650-08cb-bc52-5148-a41ae57c0339@treenet.co.nz>

On 25/06/2016 6:39 a.m., Bidwell, Christopher wrote:
> Hi all,
> 
> Just curious if you could help me figure out what the equivalent of this
> apache rule would be for squid:
> 
> RewriteRule      ^/dyfi/?$             http://servername.com/data/dyfi/
>  [R=301,L]
> 

Below, with the comments describing the meaning in context...

 # the regex pattern to match on a URL-path
 acl dyfi urlpath_regex ^/dyfi/?$

 # these matches are not allowed to continue as-is
 http_access deny dyfi

 # when a dyfi match causes a deny, redirect to this URL as 301
 deny_info 301:http://servername.com/data/dyfi/ dyfi


Amos



From squid3 at treenet.co.nz  Sat Jun 25 06:05:26 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 25 Jun 2016 18:05:26 +1200
Subject: [squid-users] flickr.com redirect error
In-Reply-To: <CAAFc9FhiXeMc=J5SECc-MjF4hBDjXRZyS9zDtgMPjSz_iMEkKw@mail.gmail.com>
References: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
 <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>
 <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>
 <VI1PR04MB1359499FE2D9A57B3C0C33638F2E0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <CAAFc9FhiXeMc=J5SECc-MjF4hBDjXRZyS9zDtgMPjSz_iMEkKw@mail.gmail.com>
Message-ID: <a97ea350-c237-2859-7c2a-cbf4d552ad5c@treenet.co.nz>

On 25/06/2016 3:40 a.m., Ozgur Batur wrote:
> Hi Rafael, Yuri,
> 
> Thank you very much, "via off" did the trick. It is probably a server
> specific issue as you said.
> 

Hmm. What was the Via header emitted by your proxy?

There are some common misconfigurations that can lead to a broken Via
being sent and various resulting strange behaviour.

Amos



From squid3 at treenet.co.nz  Sat Jun 25 06:10:16 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 25 Jun 2016 18:10:16 +1200
Subject: [squid-users] flickr.com redirect error
In-Reply-To: <e98e89ff-cb01-51a1-c6ca-6c9a714ddecb@gmail.com>
References: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
 <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>
 <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>
 <VI1PR04MB1359499FE2D9A57B3C0C33638F2E0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <CAAFc9FhiXeMc=J5SECc-MjF4hBDjXRZyS9zDtgMPjSz_iMEkKw@mail.gmail.com>
 <e98e89ff-cb01-51a1-c6ca-6c9a714ddecb@gmail.com>
Message-ID: <cda1da69-60b9-0efe-7672-e75cd71ccfcd@treenet.co.nz>

On 25/06/2016 4:02 a.m., Yuri Voinov wrote:
> 
> Be careful, guys. Via is reauired to HTTP by RFC.
> 

As of RFC 7230 et al, it is officially now optional. Yay!

As of Squid-3.2 emitting HTTP/1.1, its use in preventing 1.1<->1.0
translation errors is greatly reduced. Yay!

It is still important to avoid forwarding loops though. So interceptors
and complex hierarchy installations are advised to enable it where
possible. Just for safety though, not RFC compliance.

[somewhere down on my to-do list is making Squid be a bit more flexible
that on vs off for that header].

Amos


From rafael.akchurin at diladele.com  Sat Jun 25 06:14:11 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Sat, 25 Jun 2016 06:14:11 +0000
Subject: [squid-users] flickr.com redirect error
In-Reply-To: <a97ea350-c237-2859-7c2a-cbf4d552ad5c@treenet.co.nz>
References: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
 <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>
 <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>
 <VI1PR04MB1359499FE2D9A57B3C0C33638F2E0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <CAAFc9FhiXeMc=J5SECc-MjF4hBDjXRZyS9zDtgMPjSz_iMEkKw@mail.gmail.com>
 <a97ea350-c237-2859-7c2a-cbf4d552ad5c@treenet.co.nz>
Message-ID: <VI1PR04MB13599620DC40C00E14432EE88F2F0@VI1PR04MB1359.eurprd04.prod.outlook.com>

Hello Amos,

The Via from mine is:

Via:"http/1.1 fts110.flickr.bf1.yahoo.com (ApacheTrafficServer [cMs f ]), http/1.1 r02.ycpi.ams.yahoo.net (ApacheTrafficServer [cMsSf ]), 1.1 qlproxy (squid/3.3.8)"

Might it be the error when constructing via contents in squid? As it starts with 1.1 while other constructed by Yahoo all start with http/1.1 ?

Best regards,
Rafael

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Saturday, June 25, 2016 8:05 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] flickr.com redirect error

On 25/06/2016 3:40 a.m., Ozgur Batur wrote:
> Hi Rafael, Yuri,
> 
> Thank you very much, "via off" did the trick. It is probably a server 
> specific issue as you said.
> 

Hmm. What was the Via header emitted by your proxy?

There are some common misconfigurations that can lead to a broken Via being sent and various resulting strange behaviour.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From squid3 at treenet.co.nz  Sat Jun 25 06:17:29 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 25 Jun 2016 18:17:29 +1200
Subject: [squid-users] ecap adaper
In-Reply-To: <1466771473974-4678171.post@n4.nabble.com>
References: <1466771473974-4678171.post@n4.nabble.com>
Message-ID: <f0b04851-d800-3c3a-e674-f1368897f0d3@treenet.co.nz>

On 25/06/2016 12:31 a.m., joe wrote:
> hi wen using ecap adapter
> ecap_enable on
> acl HTTP_STATUS_OK http_status 200
> loadable_modules /usr/local/lib/ecap_adapter_gzip.so
> ecap_service gzip_service respmod_precache ecap://www.vigos.com/ecap_gzip
> bypass=off
> adaptation_access gzip_service allow HTTP_STATUS_OK 
> wen the link has status 200   and its  POST not GET
> the adapeter or ecap or squid some how wen a link has POST and the adapeter
> change it to GET or its refusing POST i dont know exactly wats happening 

Please add "debug_options 11,2" to your squid.conf and see what happens
in the HTTP traffic. The log snippet below is only a third of the story.

the method you posted in yoru followup:
> 
> this preventing method dose not work
> acl nomethod method POST
> adaptation_access gzip_service allow HTTP_STATUS_OK !nomethod 
> 

Is supposed to be what you do. If thats not working there is possibly a
bug somewhere. Just have to find it.


Also, what Squid version are you using? (in the squid -v output)

Amos



From squid3 at treenet.co.nz  Sat Jun 25 06:51:11 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 25 Jun 2016 18:51:11 +1200
Subject: [squid-users] Squid question with letsencrypt
In-Reply-To: <CAJN-FKmSPS2xo+RMMYjNsUa3hqnd_C++q4cVwjsXezVrCzSaFw@mail.gmail.com>
References: <CAJN-FKmSPS2xo+RMMYjNsUa3hqnd_C++q4cVwjsXezVrCzSaFw@mail.gmail.com>
Message-ID: <70332e91-3b59-1d02-4ade-f215d2d99957@treenet.co.nz>

On 25/06/2016 4:48 a.m., Bidwell, Christopher wrote:
> Hi all,
> 
> I'm very new to squid and we are wanting to implement letsencrypt for our
> ssl certificates.
> 
> Here's the scenario:
> 
> We've got several frontend servers running squid that are caching from the
> backend systems.

Ok,

> 
> i.e. test.com -> 10.0.0.1, 10.0.1.1, 10.0.2.1 (all physically separated
> from one another)
> 

Ok,

> Each internal server also has its own dns name:
> 
> web1.test.com -> 10.0.0.1
> web2.test.com -> 10.0.1.1
> web3.test.com -> 10.0.2.1
> 
> Note that these are all public. Using 10. as examples.

Ok, but dangerous. That allows the frontend to be bypassed whenever a
client wants. So you will need to ensure security to the backend stays
in sync with the frontend. If you don't have to, its best to avoid that
trouble and filter everything consistently through the frontend.

That also allows the backends to avoid public CAs like LetsEncrypt
entirely. You can use a single custom CA exclusively for the
frontend<->backend traffic and have much better security settings on
those internal links since you no longer have to worry about random
visitors capabilities.

> 
> I'd like to create a SAN certificate naming the 3 internal systems in
> addition to the public name:
> 
> test.com, web1.test.com, web2.test.com, and web3.test.com.
> 
> On the letsencrypt forum they said that I could do a HTTP 301 redirect from
> the squid servers to the backend letsencrypt server where any match for:
>  /.well-known/acme-challenge/* would redirect with an HTTP 301 to that
> backend letsencrypt server.  I'm not sure how to do this and the squid
> documentation is not easy to comprehend.
> 
> Let me know if this isn't clear how I've explained this.
> 

If LetsEncrypt are contacting web1 for example. They should be going to
the backend directly. Since http://web1.test.* is not a frontend request.

Whatever server is performing the LetsEncrypt for the frontend needs to
know its doing it for the generic domain as well as itself. Squid is not
a web server, so you need to nominate a backend to do that (could be a
new one just of LetsEncrypt stuff).

For example doing it on web1 would mean fitting these lines into your
existing config (this order, but not necesarily together like this):

 acl acme urlpath_regex ^/.well-known/acme-challenge
 cache_peer_access web1 allow acme
 cache_peer_access web2 deny acme
 cache_peer_access web3 deny acme

No "redirect" involved. Just tell Squid that server is where those URL
are handled.


Amos



From chip_pop at hotmail.com  Sat Jun 25 10:06:11 2016
From: chip_pop at hotmail.com (joe)
Date: Sat, 25 Jun 2016 03:06:11 -0700 (PDT)
Subject: [squid-users] ecap adaper
In-Reply-To: <f0b04851-d800-3c3a-e674-f1368897f0d3@treenet.co.nz>
References: <1466771473974-4678171.post@n4.nabble.com>
 <f0b04851-d800-3c3a-e674-f1368897f0d3@treenet.co.nz>
Message-ID: <1466849171195-4678188.post@n4.nabble.com>

thank for the debug option
without deny the POST i dont see any POST packet lol!!and it supose to to go
trough ecap right ??
since all acl HTTP_STATUS_OK http_status 200  without any restriction should
present POST or GET im right or missing something

---
root at proxy:~# squid -v
Squid Cache: Version 3.5.19-20160618-r14061
Service Name: squid
configure options:  '--build=x86_64-linux-gnu' '--prefix=/usr'
'--bindir=/usr/bin' '--sbindir=/usr/sbin' '--libexecdir=/usr/lib/squid'
'--sysconfdir=/etc/squid' '--localstatedir=/var' '--libdir=/usr/lib'
'--includedir=/usr/include' '--datadir=/usr/share/squid'
'--infodir=/usr/share/info' '--mandir=/usr/share/man' '--with-pthreads'
'--enable-storeio=ufs,aufs,diskd' '--enable-removal-policies=lru,heap'
'--disable-icmp' '--enable-linux-netfilter' '--disable-wccp'
'--enable-wccpv2' '--enable-http-violations' '--enable-eui'
'--enable-follow-x-forwarded-for' '--enable-zph-qos'
'--with-default-user=proxy' '--with-logdir=/var/log/squid'
'--with-pidfile=/var/run/squid.pid' '--disable-ipv6'
'--with-filedescriptors=200000' '--enable-snmp' '--disable-auth'
'--enable-epoll' '--enable-ecap' 'PKG_CONFIG_PATH=/usr/local/lib/pkgconfig'
'build_alias=x86_64-linux-gnu'
root at proxy:~# 
--------
and the debug
--
2016/06/25 13:42:46.640 kid1| 11,2| client_side.cc(2346) parseHttpRequest:
HTTP Client local=2.21.69.58:80 remote=10.4.4.61:58805 FD 11 flags=33
2016/06/25 13:42:46.640 kid1| 11,2| client_side.cc(2347) parseHttpRequest:
HTTP Client REQUEST:
---------
GET /XignCode/PatchReal/oGHcjbcstNrSKR/List/current.rev HTTP/1.1
Host: cdn.dominationsgame.com
Accept: */*


----------
2016/06/25 13:42:46.773 kid1| 11,2| http.cc(2234) sendRequest: HTTP Server
local=192.192.192.212:7094 remote=2.21.69.58:80 FD 13 flags=1
2016/06/25 13:42:46.773 kid1| 11,2| http.cc(2235) sendRequest: HTTP Server
REQUEST:
---------
GET /XignCode/PatchReal/oGHcjbcstNrSKR/List/current.rev HTTP/1.1
Accept: */*
Host: cdn.dominationsgame.com
Cache-Control: max-age=259200
Connection: keep-alive


----------
2016/06/25 13:42:46.910 kid1| ctx: enter level  0:
'http://cdn.dominationsgame.com/XignCode/PatchReal/oGHcjbcstNrSKR/List/current.rev'
2016/06/25 13:42:46.910 kid1| 11,2| http.cc(750) processReplyHeader: HTTP
Server local=192.192.192.212:7094 remote=2.21.69.58:80 FD 13 flags=1
2016/06/25 13:42:46.910 kid1| 11,2| http.cc(751) processReplyHeader: HTTP
Server REPLY:
---------
HTTP/1.1 200 OK
x-amz-id-2:
0kZbFX/56ksGKWKfBEsiCKQQMH6LONNsToIeISz0AQY2sfxuJLAje6nI4U1IkjevBmQdemAzOZw=
x-amz-request-id: 990B4F024415C7E3
Last-Modified: Tue, 03 Nov 2015 10:59:15 GMT
ETag: "61a2ab4075af321649ce5c9b0a29b2da"
Accept-Ranges: bytes
Content-Type: application/octet-stream
Content-Length: 4
Server: AmazonS3
Date: Sat, 25 Jun 2016 10:39:59 GMT
Connection: keep-alive

???
----------
2016/06/25 13:42:46.910 kid1| ctx: exit level  0
2016/06/25 13:42:46.911 kid1| 11,2| client_side.cc(1392) sendStartOfMessage:
HTTP Client local=2.21.69.58:80 remote=10.4.4.61:58805 FD 11 flags=33
2016/06/25 13:42:46.911 kid1| 11,2| client_side.cc(1393) sendStartOfMessage:
HTTP Client REPLY:
---------
HTTP/1.1 200 OK
x-amz-id-2:
0kZbFX/56ksGKWKfBEsiCKQQMH6LONNsToIeISz0AQY2sfxuJLAje6nI4U1IkjevBmQdemAzOZw=
x-amz-request-id: 990B4F024415C7E3
Last-Modified: Tue, 03 Nov 2015 10:59:15 GMT
ETag: "61a2ab4075af321649ce5c9b0a29b2da"
Accept-Ranges: bytes
Content-Type: application/octet-stream
Content-Length: 4
Server: AmazonS3
Date: Sat, 25 Jun 2016 10:39:59 GMT
X-Cache: MISS from proxy.netgatesss.com
Connection: keep-alive


----------
2016/06/25 13:42:46.921 kid1| 11,2| client_side.cc(2346) parseHttpRequest:
HTTP Client local=2.21.69.58:80 remote=10.4.4.61:58806 FD 11 flags=33
2016/06/25 13:42:46.921 kid1| 11,2| client_side.cc(2347) parseHttpRequest:
HTTP Client REQUEST:
---------
GET /XignCode/PatchReal/oGHcjbcstNrSKR/List/51864/xrl/oGHcjbcstNrSKR_R.xrl
HTTP/1.1
Host: cdn.dominationsgame.com
Accept: */*


----------
2016/06/25 13:42:46.922 kid1| 11,2| http.cc(2234) sendRequest: HTTP Server
local=192.192.192.212:7094 remote=2.21.69.58:80 FD 13 flags=1
2016/06/25 13:42:46.922 kid1| 11,2| http.cc(2235) sendRequest: HTTP Server
REQUEST:
---------
GET /XignCode/PatchReal/oGHcjbcstNrSKR/List/51864/xrl/oGHcjbcstNrSKR_R.xrl
HTTP/1.1
Accept: */*
Host: cdn.dominationsgame.com
Cache-Control: max-age=259200
Connection: keep-alive


----------
2016/06/25 13:42:47.045 kid1| ctx: enter level  0:
'http://cdn.dominationsgame.com/XignCode/PatchReal/oGHcjbcstNrSKR/List/51864/xrl/oGHcjbcstNrSKR_R.xrl'
2016/06/25 13:42:47.045 kid1| 11,2| http.cc(750) processReplyHeader: HTTP
Server local=192.192.192.212:7094 remote=2.21.69.58:80 FD 13 flags=1
2016/06/25 13:42:47.045 kid1| 11,2| http.cc(751) processReplyHeader: HTTP
Server REPLY:
---------
HTTP/1.1 200 OK
x-amz-id-2:
KhEvFmnafvSnMTGJ5Ymfk28IcPuFDgv6wwlYaBPZcUG2n+t2LRc4wmljEO5YZfYi6AOSJxGtFWg=
x-amz-request-id: 21054A1239E26A81
Last-Modified: Tue, 03 Nov 2015 10:59:15 GMT
ETag: "2ed95faebb5bbce4e71f5380a9aef782"
Accept-Ranges: bytes
Content-Type: application/octet-stream
Content-Length: 289
Server: AmazonS3
Date: Sat, 25 Jun 2016 10:39:59 GMT
Connection: keep-alive

?
----------
2016/06/25 13:42:47.046 kid1| ctx: exit level  0
2016/06/25 13:42:47.046 kid1| 11,2| client_side.cc(1392) sendStartOfMessage:
HTTP Client local=2.21.69.58:80 remote=10.4.4.61:58806 FD 11 flags=33
2016/06/25 13:42:47.046 kid1| 11,2| client_side.cc(1393) sendStartOfMessage:
HTTP Client REPLY:
---------
HTTP/1.1 200 OK
x-amz-id-2:
KhEvFmnafvSnMTGJ5Ymfk28IcPuFDgv6wwlYaBPZcUG2n+t2LRc4wmljEO5YZfYi6AOSJxGtFWg=
x-amz-request-id: 21054A1239E26A81
Last-Modified: Tue, 03 Nov 2015 10:59:15 GMT
ETag: "2ed95faebb5bbce4e71f5380a9aef782"
Accept-Ranges: bytes
Content-Type: application/octet-stream
Content-Length: 289
Server: AmazonS3
Date: Sat, 25 Jun 2016 10:39:59 GMT
X-Cache: MISS from proxy.netgatesss.com
Connection: keep-alive


----------
2016/06/25 13:42:47.069 kid1| 11,2| client_side.cc(2346) parseHttpRequest:
HTTP Client local=2.21.69.58:80 remote=10.4.4.61:58807 FD 11 flags=33
2016/06/25 13:42:47.069 kid1| 11,2| client_side.cc(2347) parseHttpRequest:
HTTP Client REQUEST:
---------
GET
/XignCode/PatchReal/oGHcjbcstNrSKR/List/51864/xdna.xem/aa2ea08d4cbd79168995ec779602e567/xdna.xem
HTTP/1.1
Host: cdn.dominationsgame.com
Accept: */*


----------
2016/06/25 13:42:47.069 kid1| 11,2| http.cc(2234) sendRequest: HTTP Server
local=192.192.192.212:7094 remote=2.21.69.58:80 FD 13 flags=1
2016/06/25 13:42:47.069 kid1| 11,2| http.cc(2235) sendRequest: HTTP Server
REQUEST:
---------
GET
/XignCode/PatchReal/oGHcjbcstNrSKR/List/51864/xdna.xem/aa2ea08d4cbd79168995ec779602e567/xdna.xem
HTTP/1.1
Accept: */*
Host: cdn.dominationsgame.com
Cache-Control: max-age=259200
Connection: keep-alive


----------
2016/06/25 13:42:47.193 kid1| ctx: enter level  0:
'http://cdn.dominationsgame.com/XignCode/PatchReal/oGHcjbcstNrSKR/List/51864/xdna.xem/aa2ea08d4cbd79168995ec779602e567/xdna.xem'
2016/06/25 13:42:47.193 kid1| 11,2| http.cc(750) processReplyHeader: HTTP
Server local=192.192.192.212:7094 remote=2.21.69.58:80 FD 13 flags=1
2016/06/25 13:42:47.193 kid1| 11,2| http.cc(751) processReplyHeader: HTTP
Server REPLY:
---------
HTTP/1.1 200 OK
x-amz-id-2:
UjBho6a0n04GHn08BEJLRp3YAF9GaksFIUNiWumuAaUjYJVhEHnnDAwV8qrv0yCV88ghGM5BBtQ=
x-amz-request-id: 882557884FF2EF91
Last-Modified: Tue, 03 Nov 2015 10:59:14 GMT
ETag: "aa2ea08d4cbd79168995ec779602e567"
Accept-Ranges: bytes
Content-Type: application/octet-stream
Content-Length: 780
Server: AmazonS3
Date: Sat, 25 Jun 2016 10:39:59 GMT
Connection: keep-alive

Dominations_KR.dna
----------
2016/06/25 13:42:47.193 kid1| ctx: exit level  0
2016/06/25 13:42:47.193 kid1| 11,2| client_side.cc(1392) sendStartOfMessage:
HTTP Client local=2.21.69.58:80 remote=10.4.4.61:58807 FD 11 flags=33
2016/06/25 13:42:47.193 kid1| 11,2| client_side.cc(1393) sendStartOfMessage:
HTTP Client REPLY:
---------
HTTP/1.1 200 OK
x-amz-id-2:
UjBho6a0n04GHn08BEJLRp3YAF9GaksFIUNiWumuAaUjYJVhEHnnDAwV8qrv0yCV88ghGM5BBtQ=
x-amz-request-id: 882557884FF2EF91
Last-Modified: Tue, 03 Nov 2015 10:59:14 GMT
ETag: "aa2ea08d4cbd79168995ec779602e567"
Accept-Ranges: bytes
Content-Type: application/octet-stream
Content-Length: 780
Server: AmazonS3
Date: Sat, 25 Jun 2016 10:39:59 GMT
X-Cache: MISS from proxy.netgatesss.com
Connection: keep-alive


----------
2016/06/25 13:42:47.204 kid1| 11,2| client_side.cc(2346) parseHttpRequest:
HTTP Client local=2.21.69.58:80 remote=10.4.4.61:58808 FD 11 flags=33
2016/06/25 13:42:47.204 kid1| 11,2| client_side.cc(2347) parseHttpRequest:
HTTP Client REQUEST:
---------
GET
/XignCode/PatchReal/oGHcjbcstNrSKR/List/51864/spo.xem/052e63797a57023b34cefc673e4ec133/spo.xem
HTTP/1.1
Host: cdn.dominationsgame.com
Accept: */*


----------
2016/06/25 13:42:47.204 kid1| 11,2| http.cc(2234) sendRequest: HTTP Server
local=192.192.192.212:7094 remote=2.21.69.58:80 FD 13 flags=1
2016/06/25 13:42:47.204 kid1| 11,2| http.cc(2235) sendRequest: HTTP Server
REQUEST:
---------
GET
/XignCode/PatchReal/oGHcjbcstNrSKR/List/51864/spo.xem/052e63797a57023b34cefc673e4ec133/spo.xem
HTTP/1.1
Accept: */*
Host: cdn.dominationsgame.com
Cache-Control: max-age=259200
Connection: keep-alive


----------
2016/06/25 13:42:47.330 kid1| ctx: enter level  0:
'http://cdn.dominationsgame.com/XignCode/PatchReal/oGHcjbcstNrSKR/List/51864/spo.xem/052e63797a57023b34cefc673e4ec133/spo.xem'
2016/06/25 13:42:47.330 kid1| 11,2| http.cc(750) processReplyHeader: HTTP
Server local=192.192.192.212:7094 remote=2.21.69.58:80 FD 13 flags=1
2016/06/25 13:42:47.330 kid1| 11,2| http.cc(751) processReplyHeader: HTTP
Server REPLY:
---------
HTTP/1.1 200 OK
x-amz-id-2: fjrVLD3qnn/lghAGlWSkyFZi1ZtxVHOIrxTA0035YGvBYfCYAQKxeKT7Kqcf0T/9
x-amz-request-id: 0C01CEEF7B1DB35C
Last-Modified: Tue, 03 Nov 2015 10:59:14 GMT
ETag: "052e63797a57023b34cefc673e4ec133"
Accept-Ranges: bytes
Content-Type: application/octet-stream
Content-Length: 8864
Server: AmazonS3
Date: Sat, 25 Jun 2016 10:39:59 GMT
Connection: keep-alive

TARA
----------
2016/06/25 13:42:47.331 kid1| ctx: exit level  0
2016/06/25 13:42:47.331 kid1| 11,2| client_side.cc(1392) sendStartOfMessage:
HTTP Client local=2.21.69.58:80 remote=10.4.4.61:58808 FD 11 flags=33
2016/06/25 13:42:47.331 kid1| 11,2| client_side.cc(1393) sendStartOfMessage:
HTTP Client REPLY:
---------
HTTP/1.1 200 OK
x-amz-id-2: fjrVLD3qnn/lghAGlWSkyFZi1ZtxVHOIrxTA0035YGvBYfCYAQKxeKT7Kqcf0T/9
x-amz-request-id: 0C01CEEF7B1DB35C
Last-Modified: Tue, 03 Nov 2015 10:59:14 GMT
ETag: "052e63797a57023b34cefc673e4ec133"
Accept-Ranges: bytes
Content-Type: application/octet-stream
Content-Length: 8864
Server: AmazonS3
Date: Sat, 25 Jun 2016 10:39:59 GMT
X-Cache: MISS from proxy.netgatesss.com
Connection: keep-alive


----------
2016/06/25 13:42:47.379 kid1| 11,2| client_side.cc(2346) parseHttpRequest:
HTTP Client local=2.21.69.58:80 remote=10.4.4.61:58809 FD 11 flags=33
2016/06/25 13:42:47.379 kid1| 11,2| client_side.cc(2347) parseHttpRequest:
HTTP Client REQUEST:
---------
GET
/XignCode/PatchReal/oGHcjbcstNrSKR/List/51864/xraphael.xem/550a030a408aba81f2d20d14af3a9f66/xraphael.xem
HTTP/1.1
Host: cdn.dominationsgame.com
Accept: */*


----------
2016/06/25 13:42:47.379 kid1| 11,2| http.cc(2234) sendRequest: HTTP Server
local=192.192.192.212:7094 remote=2.21.69.58:80 FD 13 flags=1
2016/06/25 13:42:47.379 kid1| 11,2| http.cc(2235) sendRequest: HTTP Server
REQUEST:
---------
GET
/XignCode/PatchReal/oGHcjbcstNrSKR/List/51864/xraphael.xem/550a030a408aba81f2d20d14af3a9f66/xraphael.xem
HTTP/1.1
Accept: */*
Host: cdn.dominationsgame.com
Cache-Control: max-age=259200
Connection: keep-alive


----------
2016/06/25 13:42:47.502 kid1| ctx: enter level  0:
'http://cdn.dominationsgame.com/XignCode/PatchReal/oGHcjbcstNrSKR/List/51864/xraphael.xem/550a030a408aba81f2d20d14af3a9f66/xraphael.xem'
2016/06/25 13:42:47.502 kid1| 11,2| http.cc(750) processReplyHeader: HTTP
Server local=192.192.192.212:7094 remote=2.21.69.58:80 FD 13 flags=1
2016/06/25 13:42:47.502 kid1| 11,2| http.cc(751) processReplyHeader: HTTP
Server REPLY:
---------
HTTP/1.1 200 OK
x-amz-id-2: kl7wHvMQyxW1tR4SoXECx1unSLl9e2Ee6gr3+k7XLwt9UbSvccCB2CxQmWn4d3hq
x-amz-request-id: 0E4C50CFAA884078
Last-Modified: Tue, 03 Nov 2015 10:59:14 GMT
ETag: "550a030a408aba81f2d20d14af3a9f66"
Accept-Ranges: bytes
Content-Type: application/octet-stream
Content-Length: 1007496
Server: AmazonS3
Date: Sat, 25 Jun 2016 10:39:59 GMT
Connection: keep-alive

ELF
----------
2016/06/25 13:42:47.503 kid1| ctx: exit level  0
2016/06/25 13:42:47.503 kid1| 11,2| client_side.cc(1392) sendStartOfMessage:
HTTP Client local=2.21.69.58:80 remote=10.4.4.61:58809 FD 11 flags=33
2016/06/25 13:42:47.503 kid1| 11,2| client_side.cc(1393) sendStartOfMessage:
HTTP Client REPLY:
---------
HTTP/1.1 200 OK
x-amz-id-2: kl7wHvMQyxW1tR4SoXECx1unSLl9e2Ee6gr3+k7XLwt9UbSvccCB2CxQmWn4d3hq
x-amz-request-id: 0E4C50CFAA884078
Last-Modified: Tue, 03 Nov 2015 10:59:14 GMT
ETag: "550a030a408aba81f2d20d14af3a9f66"
Accept-Ranges: bytes
Content-Type: application/octet-stream
Content-Length: 1007496
Server: AmazonS3
Date: Sat, 25 Jun 2016 10:39:59 GMT
X-Cache: MISS from proxy.netgatesss.com
Connection: keep-alive


----------
2016/06/25 13:42:55.326 kid1| 11,2| client_side.cc(2346) parseHttpRequest:
HTTP Client local=8.253.13.141:80 remote=10.4.4.61:49001 FD 18 flags=33
2016/06/25 13:42:55.326 kid1| 11,2| client_side.cc(2347) parseHttpRequest:
HTTP Client REQUEST:
---------
GET
/videos/thumbs/df/41/f2/df41f2228fc6ea5f858206685c1f1eb6/mozaiquehome.jpg
HTTP/1.1
Host: img-l3.xvideos.com
Connection: keep-alive
Accept: image/webp,image/*,*/*;q=0.8
User-Agent: Mozilla/5.0 (Linux; Android 4.3; GT-I9300 Build/JSS15J)
AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.89 Mobile
Safari/537.36
Referer: http://www.xnxx.com/
Accept-Encoding: gzip, deflate, sdch
Accept-Language: en-US,en;q=0.8


----------
2016/06/25 13:42:55.398 kid1| 11,2| http.cc(2234) sendRequest: HTTP Server
local=192.192.192.212:47158 remote=8.253.13.141:80 FD 19 flags=1
2016/06/25 13:42:55.398 kid1| 11,2| http.cc(2235) sendRequest: HTTP Server
REQUEST:
---------
GET
/videos/thumbs/df/41/f2/df41f2228fc6ea5f858206685c1f1eb6/mozaiquehome.jpg
HTTP/1.1
Accept: image/webp,image/*,*/*;q=0.8
User-Agent: Mozilla/5.0 (Linux; Android 4.3; GT-I9300 Build/JSS15J)
AppleWebKit/537.36 (KHTML, like Gecko) Chrome/50.0.2661.89 Mobile
Safari/537.36
Referer: http://www.xnxx.com/
Accept-Encoding: gzip, deflate;q=0, sdch;q=0
Accept-Language: en-US,en;q=0.8
Host: img-l3.xvideos.com
Cache-Control: max-age=7776000
Connection: keep-alive


----------
2016/06/25 13:42:55.484 kid1| ctx: enter level  0:
'http://img-l3.xvideos.com/videos/thumbs/df/41/f2/df41f2228fc6ea5f858206685c1f1eb6/mozaiquehome.jpg'
2016/06/25 13:42:55.484 kid1| 11,2| http.cc(750) processReplyHeader: HTTP
Server local=192.192.192.212:47158 remote=8.253.13.141:80 FD 19 flags=1
2016/06/25 13:42:55.484 kid1| 11,2| http.cc(751) processReplyHeader: HTTP
Server REPLY:
---------
HTTP/1.1 200 OK
Date: Fri, 06 May 2016 22:49:58 GMT
Content-Type: image/jpeg
Content-Length: 56345
Connection: keep-alive
Last-Modified: Tue, 15 Mar 2016 00:18:21 GMT
Expires: Sat, 21 May 2016 17:00:58 GMT
Cache-Control: max-age=5184000, public
Server: nginx
Age: 4276209
Accept-Ranges: bytes

????
----------
2016/06/25 13:42:55.484 kid1| ctx: exit level  0
2016/06/25 13:42:55.485 kid1| 11,2| client_side.cc(1392) sendStartOfMessage:
HTTP Client local=8.253.13.141:80 remote=10.4.4.61:49001 FD 18 flags=33
2016/06/25 13:42:55.485 kid1| 11,2| client_side.cc(1393) sendStartOfMessage:
HTTP Client REPLY:
---------
HTTP/1.1 200 OK
Date: Fri, 06 May 2016 22:49:58 GMT
Content-Type: image/jpeg
Last-Modified: Tue, 15 Mar 2016 00:18:21 GMT
Expires: Sat, 21 May 2016 17:00:58 GMT
Cache-Control: max-age=5184000, public
Server: nginx
Age: 4276209
Accept-Ranges: bytes
Vary: Accept-Encoding
Content-Encoding: gzip
X-Cache: MISS from proxy.netgatesss.com
Transfer-Encoding: chunked
Connection: keep-alive


----------
2016/06/25 13:42:55.888 kid1| 11,2| client_side.cc(2346) parseHttpRequest:
HTTP Client local=54.227.236.59:80 remote=10.4.4.61:34560 FD 18 flags=33
2016/06/25 13:42:55.888 kid1| 11,2| client_side.cc(2347) parseHttpRequest:
HTTP Client REQUEST:
---------
GET /snc/ping HTTP/1.1
X-Unity-Version: 5.3.3p1
User-Agent: Dalvik/1.6.0 (Linux; U; Android 4.3; GT-I9152P Build/JLS36C)
Host: prod2.dominationsgame.com
Connection: Keep-Alive
Accept-Encoding: gzip


----------
2016/06/25 13:42:56.044 kid1| 11,2| http.cc(2234) sendRequest: HTTP Server
local=192.192.192.212:62948 remote=54.227.236.59:80 FD 22 flags=1
2016/06/25 13:42:56.044 kid1| 11,2| http.cc(2235) sendRequest: HTTP Server
REQUEST:
---------
GET /snc/ping HTTP/1.1
X-Unity-Version: 5.3.3p1
User-Agent: Dalvik/1.6.0 (Linux; U; Android 4.3; GT-I9152P Build/JLS36C)
Accept-Encoding: gzip, deflate;q=0, sdch;q=0
Host: prod2.dominationsgame.com
Cache-Control: max-age=259200
Connection: keep-alive


----------
2016/06/25 13:42:56.208 kid1| ctx: enter level  0:
'http://prod2.dominationsgame.com/snc/ping'
2016/06/25 13:42:56.208 kid1| 11,2| http.cc(750) processReplyHeader: HTTP
Server local=192.192.192.212:62948 remote=54.227.236.59:80 FD 22 flags=1
2016/06/25 13:42:56.208 kid1| 11,2| http.cc(751) processReplyHeader: HTTP
Server REPLY:
---------
HTTP/1.1 200 OK
Server: Apache-Coyote/1.1
Pragma: no-cache
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Cache-Control: no-cache
Cache-Control: no-store
Content-Type: text/plain;charset=ISO-8859-1
Content-Length: 2
Date: Sat, 25 Jun 2016 10:40:07 GMT

ok
----------
2016/06/25 13:42:56.209 kid1| ctx: exit level  0
2016/06/25 13:42:56.209 kid1| 11,2| client_side.cc(1392) sendStartOfMessage:
HTTP Client local=54.227.236.59:80 remote=10.4.4.61:34560 FD 18 flags=33
2016/06/25 13:42:56.209 kid1| 11,2| client_side.cc(1393) sendStartOfMessage:
HTTP Client REPLY:
---------
HTTP/1.1 200 OK
Server: Apache-Coyote/1.1
Pragma: no-cache
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Cache-Control: no-cache
Cache-Control: no-store
Content-Type: text/plain;charset=ISO-8859-1
Date: Sat, 25 Jun 2016 10:40:07 GMT
Vary: Accept-Encoding
Content-Encoding: gzip
X-Cache: MISS from proxy.netgatesss.com
Transfer-Encoding: chunked
Connection: keep-alive


----------







--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/ecap-adaper-tp4678171p4678188.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Sat Jun 25 12:10:42 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 26 Jun 2016 00:10:42 +1200
Subject: [squid-users] flickr.com redirect error
In-Reply-To: <VI1PR04MB13599620DC40C00E14432EE88F2F0@VI1PR04MB1359.eurprd04.prod.outlook.com>
References: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
 <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>
 <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>
 <VI1PR04MB1359499FE2D9A57B3C0C33638F2E0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <CAAFc9FhiXeMc=J5SECc-MjF4hBDjXRZyS9zDtgMPjSz_iMEkKw@mail.gmail.com>
 <a97ea350-c237-2859-7c2a-cbf4d552ad5c@treenet.co.nz>
 <VI1PR04MB13599620DC40C00E14432EE88F2F0@VI1PR04MB1359.eurprd04.prod.outlook.com>
Message-ID: <950cb95d-5e47-d51c-4ab3-d67d5437364e@treenet.co.nz>

On 25/06/2016 6:14 p.m., Rafael Akchurin wrote:
> Hello Amos,
> 
> The Via from mine is:
> 
> Via:"http/1.1 fts110.flickr.bf1.yahoo.com (ApacheTrafficServer [cMs f ]), http/1.1 r02.ycpi.ams.yahoo.net (ApacheTrafficServer [cMsSf ]), 1.1 qlproxy (squid/3.3.8)"
> 
> Might it be the error when constructing via contents in squid? As it starts with 1.1 while other constructed by Yahoo all start with http/1.1 ?
> 

I think thats the Via on the reply coming back, not the request going out.

If that is actually your outgoing Via header *to* Yahoo. Then it says
the message has already been through their service. Thus a loop.

If Yahoo have any machine whose private hostname is "qlproxy" then your
Via header will match that machine (or qlproxy.*.yahoo.com) and again
they will detect a loop.

==> this will be true on whatever the outgoing Via really is from your
"qlproxy" proxies.

==> This is one of several reasons why I keep saying the
visible_hostname is *required* to be a FQDN, not a local one-label name.
And why Squid attempts to validate any auto-detected value in DNS before
using them.


What I'm expecting to see in Ozgur's header is either "localhost" or a
simple one-label name like yours which might match something inside the
private portion of the recipients CDN network.

Amos



From squid3 at treenet.co.nz  Sat Jun 25 12:20:35 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 26 Jun 2016 00:20:35 +1200
Subject: [squid-users] ecap adaper
In-Reply-To: <1466849171195-4678188.post@n4.nabble.com>
References: <1466771473974-4678171.post@n4.nabble.com>
 <f0b04851-d800-3c3a-e674-f1368897f0d3@treenet.co.nz>
 <1466849171195-4678188.post@n4.nabble.com>
Message-ID: <bb05c89a-cfd0-2f75-67fa-7205ea8d6a21@treenet.co.nz>

On 25/06/2016 10:06 p.m., joe wrote:
> thank for the debug option
> without deny the POST i dont see any POST packet lol!!and it supose to to go
> trough ecap right ??

Maybe yes, maybe no.

> since all acl HTTP_STATUS_OK http_status 200  without any restriction should
> present POST or GET im right or missing something

That is correct.

> and the debug
> --
> 2016/06/25 13:42:46.640 kid1| 11,2| client_side.cc(2346) parseHttpRequest:
> HTTP Client local=2.21.69.58:80 remote=10.4.4.61:58805 FD 11 flags=33
> 2016/06/25 13:42:46.640 kid1| 11,2| client_side.cc(2347) parseHttpRequest:
> HTTP Client REQUEST:
> ---------
> GET /XignCode/PatchReal/oGHcjbcstNrSKR/List/current.rev HTTP/1.1
> Host: cdn.dominationsgame.com
> Accept: */*
> 
> 
> ----------
> 2016/06/25 13:42:46.773 kid1| 11,2| http.cc(2234) sendRequest: HTTP Server
> local=192.192.192.212:7094 remote=2.21.69.58:80 FD 13 flags=1
> 2016/06/25 13:42:46.773 kid1| 11,2| http.cc(2235) sendRequest: HTTP Server
> REQUEST:
> ---------
> GET /XignCode/PatchReal/oGHcjbcstNrSKR/List/current.rev HTTP/1.1
> Accept: */*
> Host: cdn.dominationsgame.com
> Cache-Control: max-age=259200
> Connection: keep-alive
> 

You see how these are a "Client REQUEST" on arrival and a "Server
REQUEST" on outgoing?
 The replies are the same, just in the other order.

What we are looking for in that log now is the POST requests arriving,
and what they look like on outgoing after eCAP (or not) has done its
thing to them.
 You want to catch one that worked and one that did not and see what the
difference is (if any). By that I mean the difference in both what Squid
is changing and what the eCAP adapter is changing.

Amos



From chip_pop at hotmail.com  Sat Jun 25 11:45:58 2016
From: chip_pop at hotmail.com (joe)
Date: Sat, 25 Jun 2016 04:45:58 -0700 (PDT)
Subject: [squid-users] ecap adaper
In-Reply-To: <bb05c89a-cfd0-2f75-67fa-7205ea8d6a21@treenet.co.nz>
References: <1466771473974-4678171.post@n4.nabble.com>
 <f0b04851-d800-3c3a-e674-f1368897f0d3@treenet.co.nz>
 <1466849171195-4678188.post@n4.nabble.com>
 <bb05c89a-cfd0-2f75-67fa-7205ea8d6a21@treenet.co.nz>
Message-ID: <1466855158145-4678191.post@n4.nabble.com>

ok tks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/ecap-adaper-tp4678171p4678191.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From renjop at gmail.com  Sat Jun 25 13:19:53 2016
From: renjop at gmail.com (Renato Jop)
Date: Sat, 25 Jun 2016 07:19:53 -0600
Subject: [squid-users] Skype Issues
Message-ID: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>

Hello,
I've configured squid to filter both HTTP and HTTPS traffic and for the
most part the squid server is working correctly, however, I am always
unable to login with skype.  Skype does send all the requests through the
suid server, but looking into the cache.log I always get a Error
negotiating SSL connection on FD 12: error:1408A0C1:SSL
routines:SSL3_GET_CLIENT_HELLO:no shared cipher.
If I run: openssl s_client -crlf -connect 157.55.56.164:443 I get exactly
the same error. However if I run: openssl s_client -crlf -connect
157.55.56.164:443 -tls1_2 -ssl2 I am able to connect.
If I disable HTTPS, skype logins with no problems.
I've searched on the mailing list archive and found that other people have
had the same issues but none have been able to fix them. Is this a known
issue with squid? Any help would be greatly appreciated.

My openssl version is: OpenSSL 1.0.1s-freebsd  1 Mar 2016 and my squid
version is: Squid Cache: Version 3.5.19 configured with:
'--with-default-user=squid' '--bindir=/usr/local/sbin'
'--sbindir=/usr/local/sbin' '--datadir=/usr/local/etc/squid'
'--libexecdir=/usr/local/libexec/squid' '--localstatedir=/var'
'--sysconfdir=/usr/local/etc/squid' '--with-logdir=/var/log/squid'
'--with-pidfile=/var/run/squid/squid.pid' '--with-swapdir=/var/squid/cache'
'--without-gnutls' '--enable-auth' '--enable-build-info'
'--enable-loadable-modules' '--enable-removal-policies=lru heap'
'--disable-epoll' '--disable-linux-netfilter' '--disable-linux-tproxy'
'--disable-translation' '--disable-arch-native' '--enable-eui'
'--enable-cache-digests' '--enable-delay-pools' '--disable-ecap'
'--disable-esi' '--enable-follow-x-forwarded-for' '--enable-htcp'
'--enable-icap-client' '--enable-icmp' '--enable-ident-lookups'
'--enable-ipv6' '--enable-kqueue' '--with-large-files'
'--enable-http-violations' '--without-nettle' '--enable-snmp'
'--enable-ssl' '--with-openssl=/usr' 'LIBOPENSSL_CFLAGS=-I/usr/include'
'LIBOPENSSL_LIBS=-lcrypto -lssl' '--enable-ssl-crtd'
'--disable-stacktraces' '--disable-ipf-transparent'
'--disable-ipfw-transparent' '--enable-pf-transparent' '--with-nat-devpf'
'--disable-forw-via-db' '--enable-wccp' '--enable-wccpv2'
'--with-mit-krb5=/usr/local' 'CFLAGS=-I/usr/local/include -O2 -pipe
-I/usr/local/include -I/usr/local/include -fstack-protector
-DLDAP_DEPRECATED -fno-strict-aliasing' 'LDFLAGS=-L/usr/local/lib  -pthread
-L/usr/local/lib -L/usr/local/lib  -Wl,-rpath,/usr/local/lib:/usr/lib
-fstack-protector' 'LIBS=-lkrb5 -lgssapi_krb5 '
'KRB5CONFIG=/usr/local/bin/krb5-config' '--enable-auth-basic=LDAP SASL DB
SMB_LM MSNT-multi-domain NCSA PAM POP3 RADIUS fake getpwnam NIS'
'--enable-auth-digest=file' '--enable-external-acl-helpers=LDAP_group
file_userip time_quota unix_group kerberos_ldap_group'
'--enable-auth-negotiate=kerberos wrapper' '--enable-auth-ntlm=fake smb_lm'
'--enable-storeio=aufs diskd ufs' '--enable-disk-io=DiskThreads DiskDaemon
AIO Blocking IpcIo Mmapped' '--enable-log-daemon-helpers=file'
'--enable-url-rewrite-helpers=fake' '--enable-storeid-rewrite-helpers=file'
'--prefix=/usr/local' '--mandir=/usr/local/man'
'--infodir=/usr/local/info/' '--build=amd64-portbld-freebsd10.3'
'build_alias=amd64-portbld-freebsd10.3' 'CC=cc'
'CPPFLAGS=-I/usr/local/include' 'CXX=c++' 'CXXFLAGS=-O2 -pipe
-I/usr/local/include -I/usr/local/include -fstack-protector
-DLDAP_DEPRECATED -fno-strict-aliasing ' 'CPP=cpp' --enable-ltdl-convenience
My current configuration is as follows:
http_port 175.15.2.239:8080 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=100MB cert=/usr/local/etc/squid/serverkey.pem
capath=/usr/local/share/certs/
cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE

http_port 127.0.0.1:8080 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=100MB cert=/usr/local/etc/squid/serverkey.pem
capath=/usr/local/share/certs/
cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE

https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=100MB cert=/usr/local/etc/squid/serverkey.pem
capath=/usr/local/share/certs/
cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE

icp_port 0
dns_v4_first on
pid_filename /var/run/squid/squid.pid
cache_effective_user squid
cache_effective_group proxy
error_default_language en
icon_directory /usr/local/etc/squid/icons
visible_hostname hidden
cache_mgr admin at localhost
access_log /var/squid/logs/access.log
cache_log /var/squid/logs/cache.log
cache_store_log none
netdb_filename /var/squid/logs/netdb.state
pinger_enable off
pinger_program /usr/local/libexec/squid/pinger
sslcrtd_program /usr/local/libexec/squid/ssl_crtd -s /var/squid/lib/ssl_db
-M 4MB -b 2048
sslcrtd_children 50
sslproxy_capath /usr/local/share/certs/
sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
sslproxy_cipher
EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
sslproxy_cert_error allow all

#SKYPE according to: http://wiki.squid-cache.org/ConfigExamples/Chat/Skype
acl numeric_IPs dstdom_regex
^(([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)|(\[([0-9a-f]+)?:([0-9a-f:]+)?:([0-9a-f]+|0-9\.]+)?\])):443
acl Skype_UA browser ^skype
http_access allow CONNECT localnet numeric_IPS Skype_UA
#END SKYPE
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160625/be611b39/attachment.htm>

From squid3 at treenet.co.nz  Sat Jun 25 14:22:30 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 26 Jun 2016 02:22:30 +1200
Subject: [squid-users] Skype Issues
In-Reply-To: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>
References: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>
Message-ID: <8ff3bffe-47b7-8b0d-148d-cd3254344fd1@treenet.co.nz>

On 26/06/2016 1:19 a.m., Renato Jop wrote:
> Hello,
> I've configured squid to filter both HTTP and HTTPS traffic and for the
> most part the squid server is working correctly, however, I am always
> unable to login with skype.  Skype does send all the requests through the
> suid server, but looking into the cache.log I always get a Error
> negotiating SSL connection on FD 12: error:1408A0C1:SSL
> routines:SSL3_GET_CLIENT_HELLO:no shared cipher.
> If I run: openssl s_client -crlf -connect 157.55.56.164:443 I get exactly
> the same error. However if I run: openssl s_client -crlf -connect
> 157.55.56.164:443 -tls1_2 -ssl2 I am able to connect.
> If I disable HTTPS, skype logins with no problems.
> I've searched on the mailing list archive and found that other people have
> had the same issues but none have been able to fix them. Is this a known
> issue with squid? Any help would be greatly appreciated.

Yes its known. Well two problems are known with Skype...

1) Handling Skype cleanly through Squid with HTTPS interception (aka
SSL-Bump) currently requires features from Squid-4. Specifically the
on_unsupported_protocol feature to avoid having to bypass each IP
address your clients connect to manually (PITA) for the connections at
least some versions of it make that dont use TLS/SSL on port 443.

 This does not seem to be your particular problem though. Maybe you will
hit it only after solving the "no shared cipher" problem.


2) Recently a few people have been finding the "no shared cipher" issue
appearing with other software or domains. Last sighting of it turned out
to be the new ChaCha and Poly1305 ciphers. Which required a migration to
LibreSSL since OpenSSL implementation was still finding bugs as recently
as March this year.

But wait, theres more ...



> http_port 175.15.2.239:8080 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=100MB cert=/usr/local/etc/squid/serverkey.pem
> capath=/usr/local/share/certs/
> cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
> 
> http_port 127.0.0.1:8080 intercept ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=100MB cert=/usr/local/etc/squid/serverkey.pem
> capath=/usr/local/share/certs/
> cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
> 
> https_port 127.0.0.1:3129 intercept ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=100MB cert=/usr/local/etc/squid/serverkey.pem
> capath=/usr/local/share/certs/
> cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
> 

It is easy to think that the above enables a lot of ciphers.

HOWEVER, most of them involve "EC" and that requires a curve to be
configured as well. You are using the dhparams= option instead of
tls-dh= option. Thus have not told Squid what Curve to use for any EC.
So most of those "allowed" ciphers are thus not working.

Which means you effectively have configured only this:

cipher=EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

I'm not sure right now how many ciphers "HIGH" enables with those
following rejections, but I'd bet its also not many.

That limited number of ciphers on your side of the TLS handshake may be
at least a big part of what is leading to "no shared cipher" situation.


You have a few things that might help there. In the order you should try
them:

* Using the tls-dh= option with a curve name. It might start working
with an EC cipher.

* Using an updated library with ChaCha and Poly1305 ciphers. In case the
other end only wants one of those. This should not require a rebuild of
Squid, but it might.

* An upgrade to Squid-4.



> sslproxy_capath /usr/local/share/certs/
> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
> sslproxy_cipher
> EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

Note: The outgoing connections might actually do the Elliptic Curves.
Since the server tells Squid what curve to use.

> sslproxy_cert_error allow all

Nasty. Anyone is allowed to hack your proxies outgoing connections and
do what they like to the TLS. You will ignore any security alerts or
errors TLS/SSL protocol uses to protect you.

So, whats the point of extending the acceptable CA with sslproxy_capath
if you are going to ignore the verification results?

Whats the point of TLS if anyone is allowed to break into the "secure"
connections?


Amos



From carlopmart at gmail.com  Sat Jun 25 16:10:11 2016
From: carlopmart at gmail.com (C. L. Martinez)
Date: Sat, 25 Jun 2016 16:10:11 +0000
Subject: [squid-users] Problem with certificates and SSLBump
Message-ID: <20160625161011.GA18133@beagle.bcn.sia.es>

Hi all,

 I have some problems with my squid config when I use certificates generated with my internal CA. First, my ssl-bump config:

acl DiscoverSNIHost at_step SslBump1
acl NoSSLIntercept ssl::server_name_regex -i "/etc/squid/acls/domains.nobump"
ssl_bump peek DiscoverSNIHost
ssl_bump splice NoSSLIntercept
ssl_bump bump all

 With this config, all works as expected (I need to add some domains to domains.nobump, but gmail or google works without problems) only when I use a self-signed certificate in squid generated using the following commands:

openssl genrsa -out server.key 4096
openssl req -new -key server.key -x509 -days 365 -out server.crt

 But when I sign squid's request certificate with my internal CA (based on OpenBSD's LibreSSL), nothing works: gmail fails, google fails, startpage fails, etc ... My internal CA is configured to use elliptic cryptographic curve (secp384r1 for CA and prime256v1 for host's certifcates).

 Maybe is this the problem? Why when I use self-signed certificate all works ok and not when I sign squid's certificate with my Internal CA?

Thanks.

-- 
Greetings,
C. L. Martinez


From yvoinov at gmail.com  Sat Jun 25 16:32:18 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 25 Jun 2016 22:32:18 +0600
Subject: [squid-users] Skype Issues
In-Reply-To: <8ff3bffe-47b7-8b0d-148d-cd3254344fd1@treenet.co.nz>
References: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>
 <8ff3bffe-47b7-8b0d-148d-cd3254344fd1@treenet.co.nz>
Message-ID: <a30b3e16-5209-8240-359a-0cf736fe129f@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Amos, you are a wrong.

No Squid-4. It's unstable and not ready for production. Whenever it's
features.

Some time ago I have the same issue and know what happens exactly.

Skype initial connection site uses RC4 cipher. Which is disabled in most
squid's configuration.

To make it works (as by as most M$ update sites) it's require simple use
this cipher's suite:

HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS

That works for me in 5 SSL bumped setups. There is no matter which squid
version installed.


25.06.2016 20:22, Amos Jeffries ?????:
> On 26/06/2016 1:19 a.m., Renato Jop wrote:
>> Hello,
>> I've configured squid to filter both HTTP and HTTPS traffic and for the
>> most part the squid server is working correctly, however, I am always
>> unable to login with skype.  Skype does send all the requests through the
>> suid server, but looking into the cache.log I always get a Error
>> negotiating SSL connection on FD 12: error:1408A0C1:SSL
>> routines:SSL3_GET_CLIENT_HELLO:no shared cipher.
>> If I run: openssl s_client -crlf -connect 157.55.56.164:443 I get exactly
>> the same error. However if I run: openssl s_client -crlf -connect
>> 157.55.56.164:443 -tls1_2 -ssl2 I am able to connect.
>> If I disable HTTPS, skype logins with no problems.
>> I've searched on the mailing list archive and found that other people
have
>> had the same issues but none have been able to fix them. Is this a known
>> issue with squid? Any help would be greatly appreciated.
>
> Yes its known. Well two problems are known with Skype...
>
> 1) Handling Skype cleanly through Squid with HTTPS interception (aka
> SSL-Bump) currently requires features from Squid-4. Specifically the
> on_unsupported_protocol feature to avoid having to bypass each IP
> address your clients connect to manually (PITA) for the connections at
> least some versions of it make that dont use TLS/SSL on port 443.
>
>  This does not seem to be your particular problem though. Maybe you will
> hit it only after solving the "no shared cipher" problem.
>
>
> 2) Recently a few people have been finding the "no shared cipher" issue
> appearing with other software or domains. Last sighting of it turned out
> to be the new ChaCha and Poly1305 ciphers. Which required a migration to
> LibreSSL since OpenSSL implementation was still finding bugs as recently
> as March this year.
>
> But wait, theres more ...
>
>
>
>> http_port 175.15.2.239:8080 ssl-bump generate-host-certificates=on
>> dynamic_cert_mem_cache_size=100MB cert=/usr/local/etc/squid/serverkey.pem
>> capath=/usr/local/share/certs/
>>
cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>> dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>>
>> http_port 127.0.0.1:8080 intercept ssl-bump generate-host-certificates=on
>> dynamic_cert_mem_cache_size=100MB cert=/usr/local/etc/squid/serverkey.pem
>> capath=/usr/local/share/certs/
>>
cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>> dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>>
>> https_port 127.0.0.1:3129 intercept ssl-bump
generate-host-certificates=on
>> dynamic_cert_mem_cache_size=100MB cert=/usr/local/etc/squid/serverkey.pem
>> capath=/usr/local/share/certs/
>>
cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>> dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>>
>
> It is easy to think that the above enables a lot of ciphers.
>
> HOWEVER, most of them involve "EC" and that requires a curve to be
> configured as well. You are using the dhparams= option instead of
> tls-dh= option. Thus have not told Squid what Curve to use for any EC.
> So most of those "allowed" ciphers are thus not working.
>
> Which means you effectively have configured only this:
>
>
cipher=EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>
> I'm not sure right now how many ciphers "HIGH" enables with those
> following rejections, but I'd bet its also not many.
>
> That limited number of ciphers on your side of the TLS handshake may be
> at least a big part of what is leading to "no shared cipher" situation.
>
>
> You have a few things that might help there. In the order you should try
> them:
>
> * Using the tls-dh= option with a curve name. It might start working
> with an EC cipher.
>
> * Using an updated library with ChaCha and Poly1305 ciphers. In case the
> other end only wants one of those. This should not require a rebuild of
> Squid, but it might.
>
> * An upgrade to Squid-4.
>
>
>
>> sslproxy_capath /usr/local/share/certs/
>> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>> sslproxy_cipher
>>
EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>
> Note: The outgoing connections might actually do the Elliptic Curves.
> Since the server tells Squid what curve to use.
>
>> sslproxy_cert_error allow all
>
> Nasty. Anyone is allowed to hack your proxies outgoing connections and
> do what they like to the TLS. You will ignore any security alerts or
> errors TLS/SSL protocol uses to protect you.
>
> So, whats the point of extending the acceptable CA with sslproxy_capath
> if you are going to ignore the verification results?
>
> Whats the point of TLS if anyone is allowed to break into the "secure"
> connections?
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXbrIRAAoJENNXIZxhPexGirEH/AzlKxZRG7dBgzHTrFNwAJdS
kO4Q1a18TsFRQLgC7nYuA2BQVVY7ORBDFYJ0z++Jb+wWFqqXYCWBrfeH0XSjPCoQ
uTMJoKRBzIqb5ZXGs5/GlRvRvWBW2Q8wOPk9Ig4fPVJS9fMulXyaukemD+h8Nu1/
UUzoZKtEQxH6ICLVgkJWrQSWvJNWzOSQ6vS9GZYxW4Pu7qnjNiXhx+mDN+ZUH6tf
rCMKqBSIOOL1axf7Gt6wUn9ctu2Y9d/avYim5rsqRbJ4Th4P31QWhw3DOXKW/vDw
avhXgThQgq2PsHcijeSZEccJUdD4vNlgPWJIxVDkjj6Ypy8TX+4fChpnMlXKa3Y=
=Gvwa
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160625/77e1535a/attachment.key>

From yvoinov at gmail.com  Sat Jun 25 16:33:56 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 25 Jun 2016 22:33:56 +0600
Subject: [squid-users] Problem with certificates and SSLBump
In-Reply-To: <20160625161011.GA18133@beagle.bcn.sia.es>
References: <20160625161011.GA18133@beagle.bcn.sia.es>
Message-ID: <370895f6-32a9-1fc3-e720-1dfb428c79ba@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Use search.

Some days agi I've played around with ECDSA certs and drop it due to
extremal incompatibility with clients. Here was this thread.


25.06.2016 22:10, C. L. Martinez ?????:
> Hi all,
>
>  I have some problems with my squid config when I use certificates
generated with my internal CA. First, my ssl-bump config:
>
> acl DiscoverSNIHost at_step SslBump1
> acl NoSSLIntercept ssl::server_name_regex -i
"/etc/squid/acls/domains.nobump"
> ssl_bump peek DiscoverSNIHost
> ssl_bump splice NoSSLIntercept
> ssl_bump bump all
>
>  With this config, all works as expected (I need to add some domains
to domains.nobump, but gmail or google works without problems) only when
I use a self-signed certificate in squid generated using the following
commands:
>
> openssl genrsa -out server.key 4096
> openssl req -new -key server.key -x509 -days 365 -out server.crt
>
>  But when I sign squid's request certificate with my internal CA
(based on OpenBSD's LibreSSL), nothing works: gmail fails, google fails,
startpage fails, etc ... My internal CA is configured to use elliptic
cryptographic curve (secp384r1 for CA and prime256v1 for host's
certifcates).
>
>  Maybe is this the problem? Why when I use self-signed certificate all
works ok and not when I sign squid's certificate with my Internal CA?
>
> Thanks.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXbrJ0AAoJENNXIZxhPexGxwUH/R1KurnKCQEbat6YwHQOTo7K
TvuvOoYKPpcmN/xNVhbfWTDAOrTd9uotDOZc8HU6mS+9V9L4dhGiwiIKM6iI0J08
invXAYNlG/Jayfqie2owdrsT++qr/0mqG1Ciz/aPlKxJWhgDqecvSLM7+Uig1NRR
YgeNZloON6wZI7WBKHZQ1wo91F6AtyeNzuXz/WX4JbPjS5XCuF/SUXTR4Z1VQhy6
uIrWsoZgJF0nWkkb9fvOpv3gKTfPE9NEMmPvbXPT9Nbh9wfQlXIRVIl/g5G2j1eI
gNV0fRmbdHXxYV94FXW5nJd8gK5Rv3TnFw3hgR/tdUke4eFwwVpjbqseNOqydk4=
=vlsj
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160625/8b03b18a/attachment.key>

From carlopmart at gmail.com  Sat Jun 25 16:46:51 2016
From: carlopmart at gmail.com (C. L. Martinez)
Date: Sat, 25 Jun 2016 16:46:51 +0000
Subject: [squid-users] Problem with certificates and SSLBump
In-Reply-To: <370895f6-32a9-1fc3-e720-1dfb428c79ba@gmail.com>
References: <20160625161011.GA18133@beagle.bcn.sia.es>
 <370895f6-32a9-1fc3-e720-1dfb428c79ba@gmail.com>
Message-ID: <20160625164651.GA19876@beagle.bcn.sia.es>

On Sat 25.Jun'16 at 22:33:56 +0600, Yuri Voinov wrote:
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>  
> Use search.
> 
> Some days agi I've played around with ECDSA certs and drop it due to
> extremal incompatibility with clients. Here was this thread.
> 
> 

Is this the thread: http://marc.info/?l=squid-users&m=146625379320785&w=2?

-- 
Greetings,
C. L. Martinez


From renjop at gmail.com  Sat Jun 25 17:02:53 2016
From: renjop at gmail.com (Renato Jop)
Date: Sat, 25 Jun 2016 11:02:53 -0600
Subject: [squid-users] Skype Issues
In-Reply-To: <a30b3e16-5209-8240-359a-0cf736fe129f@gmail.com>
References: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>
 <8ff3bffe-47b7-8b0d-148d-cd3254344fd1@treenet.co.nz>
 <a30b3e16-5209-8240-359a-0cf736fe129f@gmail.com>
Message-ID: <CAHha_zX80eAjNmehS44O4WXmF8MqaubbFfXxC_pUS9baP_w+Uw@mail.gmail.com>

Thanks both for you help.
I'll try to make this changes and see if this solves my issues.


Renato Jop

On Sat, Jun 25, 2016 at 10:32 AM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> Amos, you are a wrong.
>
> No Squid-4. It's unstable and not ready for production. Whenever it's
> features.
>
> Some time ago I have the same issue and know what happens exactly.
>
> Skype initial connection site uses RC4 cipher. Which is disabled in most
> squid's configuration.
>
> To make it works (as by as most M$ update sites) it's require simple use
> this cipher's suite:
>
> HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>
> That works for me in 5 SSL bumped setups. There is no matter which squid
> version installed.
>
>
> 25.06.2016 20:22, Amos Jeffries ?????:
> > On 26/06/2016 1:19 a.m., Renato Jop wrote:
> >> Hello,
> >> I've configured squid to filter both HTTP and HTTPS traffic and for the
> >> most part the squid server is working correctly, however, I am always
> >> unable to login with skype.  Skype does send all the requests through
> the
> >> suid server, but looking into the cache.log I always get a Error
> >> negotiating SSL connection on FD 12: error:1408A0C1:SSL
> >> routines:SSL3_GET_CLIENT_HELLO:no shared cipher.
> >> If I run: openssl s_client -crlf -connect 157.55.56.164:443 I get
> exactly
> >> the same error. However if I run: openssl s_client -crlf -connect
> >> 157.55.56.164:443 -tls1_2 -ssl2 I am able to connect.
> >> If I disable HTTPS, skype logins with no problems.
> >> I've searched on the mailing list archive and found that other people
> have
> >> had the same issues but none have been able to fix them. Is this a known
> >> issue with squid? Any help would be greatly appreciated.
> >
> > Yes its known. Well two problems are known with Skype...
> >
> > 1) Handling Skype cleanly through Squid with HTTPS interception (aka
> > SSL-Bump) currently requires features from Squid-4. Specifically the
> > on_unsupported_protocol feature to avoid having to bypass each IP
> > address your clients connect to manually (PITA) for the connections at
> > least some versions of it make that dont use TLS/SSL on port 443.
> >
> >  This does not seem to be your particular problem though. Maybe you will
> > hit it only after solving the "no shared cipher" problem.
> >
> >
> > 2) Recently a few people have been finding the "no shared cipher" issue
> > appearing with other software or domains. Last sighting of it turned out
> > to be the new ChaCha and Poly1305 ciphers. Which required a migration to
> > LibreSSL since OpenSSL implementation was still finding bugs as recently
> > as March this year.
> >
> > But wait, theres more ...
> >
> >
> >
> >> http_port 175.15.2.239:8080 ssl-bump generate-host-certificates=on
> >> dynamic_cert_mem_cache_size=100MB
> cert=/usr/local/etc/squid/serverkey.pem
> >> capath=/usr/local/share/certs/
> >>
>
> cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> >> dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
> >>
> >> http_port 127.0.0.1:8080 intercept ssl-bump
> generate-host-certificates=on
> >> dynamic_cert_mem_cache_size=100MB
> cert=/usr/local/etc/squid/serverkey.pem
> >> capath=/usr/local/share/certs/
> >>
>
> cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> >> dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
> >>
> >> https_port 127.0.0.1:3129 intercept ssl-bump
> generate-host-certificates=on
> >> dynamic_cert_mem_cache_size=100MB
> cert=/usr/local/etc/squid/serverkey.pem
> >> capath=/usr/local/share/certs/
> >>
>
> cipher=EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> >> dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
> >>
> >
> > It is easy to think that the above enables a lot of ciphers.
> >
> > HOWEVER, most of them involve "EC" and that requires a curve to be
> > configured as well. You are using the dhparams= option instead of
> > tls-dh= option. Thus have not told Squid what Curve to use for any EC.
> > So most of those "allowed" ciphers are thus not working.
> >
> > Which means you effectively have configured only this:
> >
> >
> cipher=EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> >
> > I'm not sure right now how many ciphers "HIGH" enables with those
> > following rejections, but I'd bet its also not many.
> >
> > That limited number of ciphers on your side of the TLS handshake may be
> > at least a big part of what is leading to "no shared cipher" situation.
> >
> >
> > You have a few things that might help there. In the order you should try
> > them:
> >
> > * Using the tls-dh= option with a curve name. It might start working
> > with an EC cipher.
> >
> > * Using an updated library with ChaCha and Poly1305 ciphers. In case the
> > other end only wants one of those. This should not require a rebuild of
> > Squid, but it might.
> >
> > * An upgrade to Squid-4.
> >
> >
> >
> >> sslproxy_capath /usr/local/share/certs/
> >> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
> >> sslproxy_cipher
> >>
>
> EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> >
> > Note: The outgoing connections might actually do the Elliptic Curves.
> > Since the server tells Squid what curve to use.
> >
> >> sslproxy_cert_error allow all
> >
> > Nasty. Anyone is allowed to hack your proxies outgoing connections and
> > do what they like to the TLS. You will ignore any security alerts or
> > errors TLS/SSL protocol uses to protect you.
> >
> > So, whats the point of extending the acceptable CA with sslproxy_capath
> > if you are going to ignore the verification results?
> >
> > Whats the point of TLS if anyone is allowed to break into the "secure"
> > connections?
> >
> >
> > Amos
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXbrIRAAoJENNXIZxhPexGirEH/AzlKxZRG7dBgzHTrFNwAJdS
> kO4Q1a18TsFRQLgC7nYuA2BQVVY7ORBDFYJ0z++Jb+wWFqqXYCWBrfeH0XSjPCoQ
> uTMJoKRBzIqb5ZXGs5/GlRvRvWBW2Q8wOPk9Ig4fPVJS9fMulXyaukemD+h8Nu1/
> UUzoZKtEQxH6ICLVgkJWrQSWvJNWzOSQ6vS9GZYxW4Pu7qnjNiXhx+mDN+ZUH6tf
> rCMKqBSIOOL1axf7Gt6wUn9ctu2Y9d/avYim5rsqRbJ4Th4P31QWhw3DOXKW/vDw
> avhXgThQgq2PsHcijeSZEccJUdD4vNlgPWJIxVDkjj6Ypy8TX+4fChpnMlXKa3Y=
> =Gvwa
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160625/8f89dc90/attachment.htm>

From squid3 at treenet.co.nz  Sat Jun 25 17:09:50 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 26 Jun 2016 05:09:50 +1200
Subject: [squid-users] Skype Issues
In-Reply-To: <a30b3e16-5209-8240-359a-0cf736fe129f@gmail.com>
References: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>
 <8ff3bffe-47b7-8b0d-148d-cd3254344fd1@treenet.co.nz>
 <a30b3e16-5209-8240-359a-0cf736fe129f@gmail.com>
Message-ID: <6e208cda-cb22-e48d-c0ee-0a6db04448e0@treenet.co.nz>

On 26/06/2016 4:32 a.m., Yuri Voinov wrote:
> 
> Amos, you are a wrong.
> 
> No Squid-4. It's unstable and not ready for production. Whenever it's
> features.

So some beta software has bugs therefore nobody should ever use it for
anything. I find that to be a strange and sad view of the world.

Care to guess why I listed it as the last option amongst several?
 Or why 4.0.11 exists as a beta still?
It *is* an option for the mentioned problem(s) though whatever its utility.


> 
> Some time ago I have the same issue and know what happens exactly.
> 
> Skype initial connection site uses RC4 cipher. Which is disabled in most
> squid's configuration.

Your "know what happens exactly" differs from at least two other peoples
debugging experiences with Skype.

RC4 is on the hitlist for most of the big vendors for the past year or
so. IIRC there were several Windows Updates to remove it and other
broken bits from a lot of things over the past year.
If Skype is still using RC4 it might be part of this problem.

> 
> To make it works (as by as most M$ update sites) it's require simple use
> this cipher's suite:
> 
> HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
> 
> That works for me in 5 SSL bumped setups. There is no matter which squid
> version installed.

Thank you. Thats another option then. I'd rate that below trying the EC
ciphers, and above library updates.

Amos


From squid3 at treenet.co.nz  Sat Jun 25 17:22:31 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 26 Jun 2016 05:22:31 +1200
Subject: [squid-users] Problem with certificates and SSLBump
In-Reply-To: <20160625164651.GA19876@beagle.bcn.sia.es>
References: <20160625161011.GA18133@beagle.bcn.sia.es>
 <370895f6-32a9-1fc3-e720-1dfb428c79ba@gmail.com>
 <20160625164651.GA19876@beagle.bcn.sia.es>
Message-ID: <b99a5c17-d2ed-7f60-bb92-be49bac5c367@treenet.co.nz>

On 26/06/2016 4:46 a.m., C. L. Martinez wrote:
> On Sat 25.Jun'16 at 22:33:56 +0600, Yuri Voinov wrote:
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>>  
>> Use search.
>>
>> Some days agi I've played around with ECDSA certs and drop it due to
>> extremal incompatibility with clients. Here was this thread.
>>
>>
> 
> Is this the thread: http://marc.info/?l=squid-users&m=146625379320785&w=2?
> 

Thats the one that came to my mind when reading your problem description.

Here is the solution he found to the cert content error:
 <http://marc.info/?l=squid-users&m=146633146001650&w=2>

YMMV, on the bug 4497 issue. So far no-one has been able to replicate
the problem Yuri has. But if you do we would certainly like to know that
in the bug report.

(Yuri: sorry, I just noticed the captures you provided a week ago. Not
sure how I missed that. I hope to have the time to look them over later
today and see if some progress can finally happen on that bug.)

Amos



From yvoinov at gmail.com  Sat Jun 25 17:34:49 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 25 Jun 2016 23:34:49 +0600
Subject: [squid-users] Skype Issues
In-Reply-To: <6e208cda-cb22-e48d-c0ee-0a6db04448e0@treenet.co.nz>
References: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>
 <8ff3bffe-47b7-8b0d-148d-cd3254344fd1@treenet.co.nz>
 <a30b3e16-5209-8240-359a-0cf736fe129f@gmail.com>
 <6e208cda-cb22-e48d-c0ee-0a6db04448e0@treenet.co.nz>
Message-ID: <5153128f-ddd0-c134-22f1-158aa97575b4@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


25.06.2016 23:09, Amos Jeffries ?????:
> On 26/06/2016 4:32 a.m., Yuri Voinov wrote:
>>
>> Amos, you are a wrong.
>>
>> No Squid-4. It's unstable and not ready for production. Whenever it's
>> features.
>
> So some beta software has bugs therefore nobody should ever use it for
> anything. I find that to be a strange and sad view of the world.
>
> Care to guess why I listed it as the last option amongst several?
>  Or why 4.0.11 exists as a beta still?
> It *is* an option for the mentioned problem(s) though whatever its
utility.
Agreed.
>
>
>
>>
>> Some time ago I have the same issue and know what happens exactly.
>>
>> Skype initial connection site uses RC4 cipher. Which is disabled in most
>> squid's configuration.
>
> Your "know what happens exactly" differs from at least two other peoples
> debugging experiences with Skype.
>
> RC4 is on the hitlist for most of the big vendors for the past year or
> so. IIRC there were several Windows Updates to remove it and other
> broken bits from a lot of things over the past year.
> If Skype is still using RC4 it might be part of this problem.
I'm sure this is problem and this problem exists. MS do nothing to make
they sites/services more secure. BTW, MS Updates uses RC4 ciphers itself
this time. With strong siphers there is no way to setup WU via Squid.
I've spent much time to identify this problem in my setup and find
working workaround.

Another part of problem is: MS often uses it's own self-signed roots,
which is exists in Windows, but nowhere else. And which has not
cross-signed by well-known root CA's. They think it make MS services
more secure. They wrong. But we can't do anything with it. So, this is
forced us to add self-signed MS roots to our Squid's CA bundles to
bump/splice.
>
>
>>
>> To make it works (as by as most M$ update sites) it's require simple use
>> this cipher's suite:
>>
>> HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>>
>> That works for me in 5 SSL bumped setups. There is no matter which squid
>> version installed.
>
> Thank you. Thats another option then. I'd rate that below trying the EC
> ciphers, and above library updates.
You are welcome.

Just for information: MS has own IT infrastructure, with some strange
configured and non well-managed elements. I can't guarantee this
workaround will work everywhere or for every MS service.

When I made my research, I've seen some strange security TLS
combinations on MS sites/services. I.e., for example, RC4+ECDSA+TLSv1.2.
Or, for example, RC4+MD5+TLSv1. And some similar. Very idiotic and
potentially dangerous combinations. And - they support ignores all
requests. As usual.

To my regret, I can not order all of its users to abandon the use of
Windows. So far, in my infrastructure have machines with Windows XP.

With this nothing can be done, it is necessary only to weaken the
security - for the sake of compatibility.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXbsC5AAoJENNXIZxhPexGiFoH/jrtimBNppF1uHpVTNwOO10z
yF2APMA56S8woNZzhUNjT8+oJFPrthnMoQFrqgicjS77SBAFp9KcOV+SxOKl9+sW
OdAHDPuCD7dGnKzAdFDR1YR7Vp5IpElP1rFO5rqKXeBc3iKjq65BfF+T6atHy6cS
0VAaluvqvHQps2wVKoYxGURDf3Y2K0lJn+qF+s2CaBwEufhzgKSvG0aUIDqTfHfK
3EMQTpPtlTqm+pcexR+oZM1WE1hlES1khOXs51fgo6puPryqWJiHGvO4EBEfWoXF
Skval2COzcdzMvC5jjfGbMEPNGNJrYUeq/KNgppRvE2wQJ+gCLYG317decKHty0=
=8BTp
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160625/5502bc69/attachment.key>

From yvoinov at gmail.com  Sat Jun 25 17:40:29 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 25 Jun 2016 23:40:29 +0600
Subject: [squid-users] Problem with certificates and SSLBump
In-Reply-To: <b99a5c17-d2ed-7f60-bb92-be49bac5c367@treenet.co.nz>
References: <20160625161011.GA18133@beagle.bcn.sia.es>
 <370895f6-32a9-1fc3-e720-1dfb428c79ba@gmail.com>
 <20160625164651.GA19876@beagle.bcn.sia.es>
 <b99a5c17-d2ed-7f60-bb92-be49bac5c367@treenet.co.nz>
Message-ID: <84b43061-614d-0629-630d-315e5b9c6817@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


25.06.2016 23:22, Amos Jeffries ?????:
> On 26/06/2016 4:46 a.m., C. L. Martinez wrote:
>> On Sat 25.Jun'16 at 22:33:56 +0600, Yuri Voinov wrote:
>>>
>>> -----BEGIN PGP SIGNED MESSAGE-----
>>> Hash: SHA256
>>> 
>>> Use search.
>>>
>>> Some days agi I've played around with ECDSA certs and drop it due to
>>> extremal incompatibility with clients. Here was this thread.
>>>
>>>
>>
>> Is this the thread:
http://marc.info/?l=squid-users&m=146625379320785&w=2?
>>
>
> Thats the one that came to my mind when reading your problem description.
>
> Here is the solution he found to the cert content error:
>  <http://marc.info/?l=squid-users&m=146633146001650&w=2>
>
> YMMV, on the bug 4497 issue. So far no-one has been able to replicate
> the problem Yuri has. But if you do we would certainly like to know that
> in the bug report.
We, in turn, did not find any apparent reason, no satisfactory theory to
explain this bug. It is still present in two of our infrastructures, and
we find more and more sites that can not be opened with a similar error.
The only common place for both problem infrastructures - they utilizes
ISP without IPv6 and haven't IPv6 support itself therefore.
>
>
> (Yuri: sorry, I just noticed the captures you provided a week ago. Not
> sure how I missed that. I hope to have the time to look them over later
> today and see if some progress can finally happen on that bug.)
No problem, Amos. We are continue our research also, I hope we can found
as the reason and solution. Together.
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXbsIMAAoJENNXIZxhPexGQJ8H+gK+OAOZTD93LJxyIofSjWnc
QbemENAZPDeAqFx8EKBAfWzt+BBonUsu4OD+TPCIHk4e0UOdpIy4Ig4zhwXi3bbw
7diMhavM8jIThh9uLiBBzr1W0MxHbm+C8BErpw13kdsue4fm3wLVvwXoXzuH6jST
+u1QjNL8JeHeOU9qvL4PuvsnZn8rgkH/eIHfeoMx8VAC9hTAW0ye2x0F3kr+vKgc
teAja3pQT+0wf8gNlN2QZ7shGUyQI/FidI3vFvzxb2D/jwtA7umEhFvjaS0VueUU
BNin9I+VkLBPkmpnYkLc3I4rv6+d1n9L3YUCUcM9Ogti00M5P2FtdjsD/hceQNU=
=vB8W
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160625/9a60ab04/attachment.key>

From carlopmart at gmail.com  Sat Jun 25 17:47:54 2016
From: carlopmart at gmail.com (C. L. Martinez)
Date: Sat, 25 Jun 2016 17:47:54 +0000
Subject: [squid-users] Problem with certificates and SSLBump
In-Reply-To: <b99a5c17-d2ed-7f60-bb92-be49bac5c367@treenet.co.nz>
References: <20160625161011.GA18133@beagle.bcn.sia.es>
 <370895f6-32a9-1fc3-e720-1dfb428c79ba@gmail.com>
 <20160625164651.GA19876@beagle.bcn.sia.es>
 <b99a5c17-d2ed-7f60-bb92-be49bac5c367@treenet.co.nz>
Message-ID: <20160625174754.GB19876@beagle.bcn.sia.es>

On Sun 26.Jun'16 at  5:22:31 +1200, Amos Jeffries wrote:
> On 26/06/2016 4:46 a.m., C. L. Martinez wrote:
> > On Sat 25.Jun'16 at 22:33:56 +0600, Yuri Voinov wrote:
> >>
> >> -----BEGIN PGP SIGNED MESSAGE-----
> >> Hash: SHA256
> >>  
> >> Use search.
> >>
> >> Some days agi I've played around with ECDSA certs and drop it due to
> >> extremal incompatibility with clients. Here was this thread.
> >>
> >>
> > 
> > Is this the thread: http://marc.info/?l=squid-users&m=146625379320785&w=2?
> > 
> 
> Thats the one that came to my mind when reading your problem description.
> 
> Here is the solution he found to the cert content error:
>  <http://marc.info/?l=squid-users&m=146633146001650&w=2>
> 
> YMMV, on the bug 4497 issue. So far no-one has been able to replicate
> the problem Yuri has. But if you do we would certainly like to know that
> in the bug report.
> 
> (Yuri: sorry, I just noticed the captures you provided a week ago. Not
> sure how I missed that. I hope to have the time to look them over later
> today and see if some progress can finally happen on that bug.)
> 
> Amos
> 

Thanks Amos. In my case, I am using LibreSSL from OpenBSD. I have used the following commands to create the Root CA:

openssl ecparam -out private/ec-secp384r1.pem -name secp384r1
openssl req -config ../openssl.cnf -new -x509 -days 3652 -extensions v3_ca -sha512 -newkey ec:ec-secp384r1.pem -keyout ec-ca.key -out ../certs/ec-ca.crt

 And works without problems.

 I have done another test: I have created a csr for squid's host without using ECDSA, using the following commands:

openssl genrsa -out server.key 4096
openssl req -nodes -key server.key -new -out server.csr

 .. with the same result: fails.


 Arrived to this I don't know if it could be a best solution to deploy another CA without ECDSA ...

-- 
Greetings,
C. L. Martinez


From yvoinov at gmail.com  Sat Jun 25 18:04:41 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 26 Jun 2016 00:04:41 +0600
Subject: [squid-users] Problem with certificates and SSLBump
In-Reply-To: <20160625174754.GB19876@beagle.bcn.sia.es>
References: <20160625161011.GA18133@beagle.bcn.sia.es>
 <370895f6-32a9-1fc3-e720-1dfb428c79ba@gmail.com>
 <20160625164651.GA19876@beagle.bcn.sia.es>
 <b99a5c17-d2ed-7f60-bb92-be49bac5c367@treenet.co.nz>
 <20160625174754.GB19876@beagle.bcn.sia.es>
Message-ID: <c070e5a0-6db1-91d0-634e-4b07a5b5df3b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


25.06.2016 23:47, C. L. Martinez ?????:
> On Sun 26.Jun'16 at  5:22:31 +1200, Amos Jeffries wrote:
>> On 26/06/2016 4:46 a.m., C. L. Martinez wrote:
>>> On Sat 25.Jun'16 at 22:33:56 +0600, Yuri Voinov wrote:
>>>>
>>>> -----BEGIN PGP SIGNED MESSAGE-----
>>>> Hash: SHA256
>>>> 
>>>> Use search.
>>>>
>>>> Some days agi I've played around with ECDSA certs and drop it due to
>>>> extremal incompatibility with clients. Here was this thread.
>>>>
>>>>
>>>
>>> Is this the thread:
http://marc.info/?l=squid-users&m=146625379320785&w=2?
>>>
>>
>> Thats the one that came to my mind when reading your problem description.
>>
>> Here is the solution he found to the cert content error:
>>  <http://marc.info/?l=squid-users&m=146633146001650&w=2>
>>
>> YMMV, on the bug 4497 issue. So far no-one has been able to replicate
>> the problem Yuri has. But if you do we would certainly like to know that
>> in the bug report.
>>
>> (Yuri: sorry, I just noticed the captures you provided a week ago. Not
>> sure how I missed that. I hope to have the time to look them over later
>> today and see if some progress can finally happen on that bug.)
>>
>> Amos
>>
>
> Thanks Amos. In my case, I am using LibreSSL from OpenBSD. I have used
the following commands to create the Root CA:
>
> openssl ecparam -out private/ec-secp384r1.pem -name secp384r1
> openssl req -config ../openssl.cnf -new -x509 -days 3652 -extensions
v3_ca -sha512 -newkey ec:ec-secp384r1.pem -keyout ec-ca.key -out
../certs/ec-ca.crt
>
>  And works without problems.
>
>  I have done another test: I have created a csr for squid's host
without using ECDSA, using the following commands:
>
> openssl genrsa -out server.key 4096
> openssl req -nodes -key server.key -new -out server.csr
>
>  .. with the same result: fails.
I've tried a bit different. Root CA without ECDSA (RSA4096+SHA256),
intermediate CA with ECDSA, signed by first root. This works on my
testing setups.
>
>
>
>  Arrived to this I don't know if it could be a best solution to deploy
another CA without ECDSA ...
>
"Compatibility is more important than performance." (c)

Experience has shown that the compatibility of these certificates is
very questionable and is not supported by all, without exception,
possible clients. That is, in turn, to problems in the support.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXbse5AAoJENNXIZxhPexGKegH/iMc7esyZ7ULeDF/ZQhiidd0
NV4JsIkIlwL5olbYgM3aDb1Il9ihkVfpcWuz4hPDPvAOz9xwxQbnjbvVeK7boiyE
pEHBomJhS0ZtHCYo3dH8B1AQj06bJCVjtb7gNFyakLVxs0GFF6qmbh/nzn/xG/ny
4inMclgurGcnBn1ejjm+x6l4q+0Tq5pKr3g7GHzcQUCfK06k09Nu35m9CkeDrda9
QBO2V8QT/B5QMVajwYVkGEHt6YQGtz2OmA8lWaR+HR8ftVm9QhgP4tpuSnmx3lRl
0CKzjhzbPZh4zj9ikrBH6TdlD7XTrIRodFhvhGO9xkrD3LaEQeTdx9NPdhlKvt0=
=K0na
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160626/31da36eb/attachment.key>

From info at ublun.com  Sun Jun 26 19:33:57 2016
From: info at ublun.com (Ublun)
Date: Sun, 26 Jun 2016 22:33:57 +0300
Subject: [squid-users] Preparing for shutdown after xxx requests
In-Reply-To: <0f6001d1cd23$9714fea0$c53efbe0$@ngtech.co.il>
References: <86636a21-d59a-c3ef-a60d-9d7406da6fe9@ublun.com>
 <0f6001d1cd23$9714fea0$c53efbe0$@ngtech.co.il>
Message-ID: <862f00a7-7405-f7de-722e-474b247e7d79@ublun.com>

Hi there, I having still that problem, but it maybe Archlinux related, 
not sure. Have also with Docker a Squid container tested and it results 
in the same way. squid -zN creates all the directories and Squid works 
also nice for some time, but at once Squid shutdown.

any idea - regards David

acl localnet src 10.0.0.0/8    # RFC1918 possible internal network
acl localnet src 172.16.0.0/12 # RFC1918 possible internal network
acl localnet src 192.168.0.0/16        # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines

http_access allow localnet

acl SSL_ports port 443
acl SSL_ports port 10000
acl SSL_ports port 20000
acl Safe_ports port 80        # http
acl Safe_ports port 21        # ftp
acl Safe_ports port 443        # https
acl Safe_ports port 70        # gopher
acl Safe_ports port 210        # wais
acl Safe_ports port 1025-65535    # unregistered ports
acl Safe_ports port 280        # http-mgmt
acl Safe_ports port 488        # gss-http
acl Safe_ports port 591        # filemaker
acl Safe_ports port 777        # multiling http
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localhost
http_access deny all
http_port 3128
maximum_object_size 140 MB
cache_dir aufs /var/cache/squid 10000 32 256
coredump_dir /var/cache/squid
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern -i \.(gif|png|jpg|jpeg|ico)$ 10080 90% 43200 
override-expire ignore-no-cache ignore-no-store ignore-private
refresh_pattern -i \.(iso|avi|mkv|wav|mp3|mp4|mpeg|swf|flv|x-flv)$ 43200 
90% 432000 override-expire ignore-no-cache ignore-no-store ignore-private
refresh_pattern -i 
\.(tar|xz|run|deb|pkg|bz2|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff)$ 
10080 90% 43200 override-expire ignore-no-cache ignore-no-store 
ignore-private
refresh_pattern -i \.index.(html|htm)$ 0 40% 10080
refresh_pattern -i \.(html|htm|css|js)$ 1440 40% 40320
refresh_pattern . 0 40% 40320

--------------

? squid.service - Web Proxy Cache Server
    Loaded: loaded (/usr/lib/systemd/system/squid.service; disabled; 
vendor preset: disabled)
    Active: inactive (dead)

Jun 26 22:05:08 bigbox squid[2988]: /var/cache/squid/00/01/00000100
Jun 26 22:05:09 bigbox squid[2988]: DiskThreadsDiskFile::openDone: (2) 
No such file or directory
Jun 26 22:05:09 bigbox squid[2988]: /var/cache/squid/00/00/000000FB
Jun 26 22:05:09 bigbox squid[2988]: DiskThreadsDiskFile::openDone: (2) 
No such file or directory
Jun 26 22:05:09 bigbox squid[2988]: /var/cache/squid/00/01/00000104
Jun 26 22:19:01 bigbox systemd[1]: Stopping Web Proxy Cache Server...
Jun 26 22:19:01 bigbox squid[2988]: Preparing for shutdown after 774 
requests
Jun 26 22:19:01 bigbox squid[2988]: Waiting 30 seconds for active 
connections to finish
Jun 26 22:19:01 bigbox squid[2988]: Closing HTTP port [::]:3128
Jun 26 22:19:01 bigbox systemd[1]: Stopped Web Proxy Cache Server.


Am 23.06.2016 um 10:48 schrieb Eliezer Croitoru:
> Hey David,
>
> Are you using a squid instance with some old config file?
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of David
> Sent: Thursday, June 23, 2016 8:17 AM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Preparing for shutdown after xxx requests
>
> So far Squid worked nice, but recently it shutdown again and again with:
>
> Preparing for shutdown after xxx requests
>
> has someone a hint what that causes squid to shutdown
>
> Squid Cache: Version 3.5.19
> on Archlinux
>
> free -h:
>                          total          used        free      shared
> Puffer/Cache cached
> Mem:              7.7G        3.4G        672M        333M 3.7G        3.7G
> Swap:             4.0G         41M        4.0G
>
> 2016/06/23 07:45:06| Set Current Directory to /var/cache/squid
> 2016/06/23 07:45:06 kid1| Preparing for shutdown after 967 requests
> 2016/06/23 07:45:06 kid1| Waiting 10 seconds for active connections to
> finish
> 2016/06/23 07:45:06 kid1| Closing HTTP port [::]:3128
> 2016/06/23 07:45:06 kid1| Set Current Directory to /var/cache/squid
> 2016/06/23 07:45:06 kid1| Starting Squid Cache version 3.5.19 for
> x86_64-pc-linux-gnu...
> 2016/06/23 07:45:06 kid1| Service Name: squid
> 2016/06/23 07:45:06 kid1| Process ID 17879
> 2016/06/23 07:45:06 kid1| Process Roles: worker
> 2016/06/23 07:45:06 kid1| With 1024 file descriptors available
> 2016/06/23 07:45:06 kid1| Initializing IP Cache...
> 2016/06/23 07:45:06 kid1| DNS Socket created at [::], FD 8
> 2016/06/23 07:45:06 kid1| DNS Socket created at 0.0.0.0, FD 9
> 2016/06/23 07:45:06 kid1| Adding nameserver 192.168.2.1 from
> /etc/resolv.conf
> 2016/06/23 07:45:06 kid1| Logfile: opening log
> daemon:/var/log/squid/access.log
> 2016/06/23 07:45:06 kid1| Logfile Daemon: opening log
> /var/log/squid/access.log
> 2016/06/23 07:45:06 kid1| Local cache digest enabled; rebuild/rewrite
> every 3600/3600 sec
> 2016/06/23 07:45:06 kid1| Store logging disabled
> 2016/06/23 07:45:06 kid1| Swap maxSize 61440000 + 3072000 KB, estimated
> 4962461 objects
> 2016/06/23 07:45:06 kid1| Target number of buckets: 248123
> 2016/06/23 07:45:06 kid1| Using 262144 Store buckets
> 2016/06/23 07:45:06 kid1| Max Mem  size: 3072000 KB
> 2016/06/23 07:45:06 kid1| Max Swap size: 61440000 KB
> 2016/06/23 07:45:06 kid1| Rebuilding storage in /var/cache/squid (dirty log)
> 2016/06/23 07:45:06 kid1| Using Least Load store dir selection
> 2016/06/23 07:45:06 kid1| Set Current Directory to /var/cache/squid
> 2016/06/23 07:45:06 kid1| Finished loading MIME types and icons.
> 2016/06/23 07:45:06 kid1| HTCP Disabled.
> 2016/06/23 07:45:06 kid1| Squid plugin modules loaded: 0
> 2016/06/23 07:45:06 kid1| Adaptation support is off.
> 2016/06/23 07:45:06 kid1| Accepting HTTP Socket connections at
> local=[::]:3128 remote=[::] FD 14 flags=9
> 2016/06/23 07:45:07 kid1| Store rebuilding is 53.75% complete
> 2016/06/23 07:45:07 kid1| Done reading /var/cache/squid swaplog (7441
> entries)
> 2016/06/23 07:45:07 kid1| Finished rebuilding storage from disk.
> 2016/06/23 07:45:07 kid1|      7422 Entries scanned
> 2016/06/23 07:45:07 kid1|         0 Invalid entries.
> 2016/06/23 07:45:07 kid1|         0 With invalid flags.
> 2016/06/23 07:45:07 kid1|      7403 Objects loaded.
> 2016/06/23 07:45:07 kid1|         0 Objects expired.
> 2016/06/23 07:45:07 kid1|         0 Objects cancelled.
> 2016/06/23 07:45:07 kid1|        19 Duplicate URLs purged.
> 2016/06/23 07:45:07 kid1|         0 Swapfile clashes avoided.
> 2016/06/23 07:45:07 kid1|   Took 0.07 seconds (100137.97 objects/sec).
> 2016/06/23 07:45:07 kid1| Beginning Validation Procedure
> 2016/06/23 07:45:07 kid1|   Completed Validation Procedure
> 2016/06/23 07:45:07 kid1|   Validated 7403 Entries
> 2016/06/23 07:45:07 kid1|   store_swap_size = 490076.00 KB
> 2016/06/23 07:45:07 kid1| storeLateRelease: released 0 objects
> 2016/06/23 07:51:30| Set Current Directory to /var/cache/squid
> 2016/06/23 07:51:30 kid1| Preparing for shutdown after 28 requests
> 2016/06/23 07:51:30 kid1| Waiting 10 seconds for active connections to
> finish
> 2016/06/23 07:51:30 kid1| Closing HTTP port [::]:3128
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



From trustgig at gmail.com  Sun Jun 26 21:53:48 2016
From: trustgig at gmail.com (Adam Wright)
Date: Mon, 27 Jun 2016 00:53:48 +0300
Subject: [squid-users] Some websites doesn't work with squid anymore
Message-ID: <CAFU=CpdbHOqSmozVfWBHV-jJEr2hat9h-aNKxF-EhtBx0Z6mQw@mail.gmail.com>

I have been successfully using squid on my vps for years (Ubuntu 12.04) But
for about two weeks, I'm not being able to access some certain adult
websites (like redt***, xhams***, ***nhub, chaturb***.com). Some adult
websites still works though.

I can ping and download those websites with wget.

-------------------------------
root at server1:~# wget xhams***.com
--2016-06-24 21:13:05--  http://xhams***.com/
Resolving xhams***.com (xhams***.com)... 88.208.18.30, 88.208.29.24,
2a02:b48:4000:d::1, ...
Connecting to xhams***.com (xhams***.com)|88.208.18.30|:80... connected.
HTTP request sent, awaiting response... 200 OK
Length: unspecified [text/html]
Saving to: `index.html.3'

    [ <=>                                   ] 57,565       341K/s   in 0.2s

2016-06-24 21:13:05 (341 KB/s) - `index.html.3' saved [57565]
-------------------------------

But when I try to open those websites with squid, the browser gives me
errors.

-------------------------------
Cannot connect to the website Please make sure:

- You have entered the correct URL.
- You are connected to the Internet.
- Your firewall is properly configured.
- The website is not encountering any technical problem at the moment.

Error code 324 (net::ERR_EMPTY_RESPONSE)
-------------------------------

When I alter the browser connection settings to allow for a direct
connection with the Internet I can access these sites without problems. Why
is this happening?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160627/7a1e57a3/attachment.htm>

From squid3 at treenet.co.nz  Mon Jun 27 02:06:50 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 27 Jun 2016 14:06:50 +1200
Subject: [squid-users] Preparing for shutdown after xxx requests
In-Reply-To: <862f00a7-7405-f7de-722e-474b247e7d79@ublun.com>
References: <86636a21-d59a-c3ef-a60d-9d7406da6fe9@ublun.com>
 <0f6001d1cd23$9714fea0$c53efbe0$@ngtech.co.il>
 <862f00a7-7405-f7de-722e-474b247e7d79@ublun.com>
Message-ID: <3149014e-2a0c-258d-7412-51fbd0a3d38f@treenet.co.nz>

On 27/06/2016 7:33 a.m., Ublun wrote:
> Hi there, I having still that problem, but it maybe Archlinux related,
> not sure. Have also with Docker a Squid container tested and it results
> in the same way. squid -zN creates all the directories and Squid works
> also nice for some time, but at once Squid shutdown.
> 
>
> ? squid.service - Web Proxy Cache Server
>    Loaded: loaded (/usr/lib/systemd/system/squid.service; disabled;
> vendor preset: disabled)
>    Active: inactive (dead)
> 
<snip>
> Jun 26 22:19:01 bigbox systemd[1]: Stopping Web Proxy Cache Server...
> Jun 26 22:19:01 bigbox squid[2988]: Preparing for shutdown after 774
> requests
> Jun 26 22:19:01 bigbox squid[2988]: Waiting 30 seconds for active
> connections to finish
> Jun 26 22:19:01 bigbox squid[2988]: Closing HTTP port [::]:3128
> Jun 26 22:19:01 bigbox systemd[1]: Stopped Web Proxy Cache Server.
> 

There you go. systemd is explicitly shutting Squid down.

Amos



From squid3 at treenet.co.nz  Mon Jun 27 02:39:56 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 27 Jun 2016 14:39:56 +1200
Subject: [squid-users] Some websites doesn't work with squid anymore
In-Reply-To: <CAFU=CpdbHOqSmozVfWBHV-jJEr2hat9h-aNKxF-EhtBx0Z6mQw@mail.gmail.com>
References: <CAFU=CpdbHOqSmozVfWBHV-jJEr2hat9h-aNKxF-EhtBx0Z6mQw@mail.gmail.com>
Message-ID: <34616003-f25a-38d9-2e5f-ea0987b8cafa@treenet.co.nz>

On 27/06/2016 9:53 a.m., Adam Wright wrote:
> I have been successfully using squid on my vps for years (Ubuntu 12.04) But
> for about two weeks, I'm not being able to access some certain adult
> websites (like redt***, xhams***, ***nhub, chaturb***.com). Some adult
> websites still works though.
> 

So what software changed?


> I can ping and download those websites with wget.
> 
> -------------------------------
> root at server1:~# wget xhams***.com
> --2016-06-24 21:13:05--  http://xhams***.com/
> Resolving xhams***.com (xhams***.com)... 88.208.18.30, 88.208.29.24,
> 2a02:b48:4000:d::1, ...
> Connecting to xhams***.com (xhams***.com)|88.208.18.30|:80... connected.
> HTTP request sent, awaiting response... 200 OK
> Length: unspecified [text/html]
> Saving to: `index.html.3'
> 
>     [ <=>                                   ] 57,565       341K/s   in 0.2s
> 
> 2016-06-24 21:13:05 (341 KB/s) - `index.html.3' saved [57565]
> -------------------------------
> 
> But when I try to open those websites with squid, the browser gives me
> errors.

You have then changed two things between the tests.
 a) started going through a proxy, and
 b) started using a browser.

The error is a browser generated error message, not a proxy error
message. That is usually a big hint that the browser is where the
problem occurs.

> 
> -------------------------------
> Cannot connect to the website Please make sure:
> 
> - You have entered the correct URL.
> - You are connected to the Internet.
> - Your firewall is properly configured.
> - The website is not encountering any technical problem at the moment.
> 
> Error code 324 (net::ERR_EMPTY_RESPONSE)
> -------------------------------
> 
> When I alter the browser connection settings to allow for a direct
> connection with the Internet I can access these sites without problems. Why
> is this happening?

So Chrome, from about early 2012 ?

What do your proxy logs say is going on for those browser transactions?

Amos



From ozgurbtr at gmail.com  Mon Jun 27 09:04:15 2016
From: ozgurbtr at gmail.com (Ozgur Batur)
Date: Mon, 27 Jun 2016 12:04:15 +0300
Subject: [squid-users] flickr.com redirect error
In-Reply-To: <950cb95d-5e47-d51c-4ab3-d67d5437364e@treenet.co.nz>
References: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
 <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>
 <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>
 <VI1PR04MB1359499FE2D9A57B3C0C33638F2E0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <CAAFc9FhiXeMc=J5SECc-MjF4hBDjXRZyS9zDtgMPjSz_iMEkKw@mail.gmail.com>
 <a97ea350-c237-2859-7c2a-cbf4d552ad5c@treenet.co.nz>
 <VI1PR04MB13599620DC40C00E14432EE88F2F0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <950cb95d-5e47-d51c-4ab3-d67d5437364e@treenet.co.nz>
Message-ID: <CAAFc9FiDM8_13Zq_OD37FdY_hm6hb431OREbZVwdyaeYxJRjDA@mail.gmail.com>

Hello Amos,

This is the via header sent by my local proxy as part of the request.
*Via: 1.1 ubuntuozgen (squid/3.5.19)*

It is not fqdn but ubuntu concatanated with a Turkish name so it is highly
unlikely that yahoo have such named reverse proxy. I could not decrypt the
squid <--> flicker traffic yet this is from pcap output from another http
site but i think it should be same right?

Thanks.

On Sat, Jun 25, 2016 at 3:10 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 25/06/2016 6:14 p.m., Rafael Akchurin wrote:
> > Hello Amos,
> >
> > The Via from mine is:
> >
> > Via:"http/1.1 fts110.flickr.bf1.yahoo.com (ApacheTrafficServer [cMs f
> ]), http/1.1 r02.ycpi.ams.yahoo.net (ApacheTrafficServer [cMsSf ]), 1.1
> qlproxy (squid/3.3.8)"
> >
> > Might it be the error when constructing via contents in squid? As it
> starts with 1.1 while other constructed by Yahoo all start with http/1.1 ?
> >
>
> I think thats the Via on the reply coming back, not the request going out.
>
> If that is actually your outgoing Via header *to* Yahoo. Then it says
> the message has already been through their service. Thus a loop.
>
> If Yahoo have any machine whose private hostname is "qlproxy" then your
> Via header will match that machine (or qlproxy.*.yahoo.com) and again
> they will detect a loop.
>
> ==> this will be true on whatever the outgoing Via really is from your
> "qlproxy" proxies.
>
> ==> This is one of several reasons why I keep saying the
> visible_hostname is *required* to be a FQDN, not a local one-label name.
> And why Squid attempts to validate any auto-detected value in DNS before
> using them.
>
>
> What I'm expecting to see in Ozgur's header is either "localhost" or a
> simple one-label name like yours which might match something inside the
> private portion of the recipients CDN network.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
H ?zg?r Batur
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160627/fdf7c8dc/attachment.htm>

From Silamael at coronamundi.de  Mon Jun 27 09:16:35 2016
From: Silamael at coronamundi.de (Silamael)
Date: Mon, 27 Jun 2016 11:16:35 +0200
Subject: [squid-users] [PATCH] Squid 3.5.19 SMP under OpenBSD - setsockopt
	for UDS
Message-ID: <5770EEF3.5060306@coronamundi.de>

Hi,

I'm playing around with the SMP feature on OpenBSD 5.9 and noticed that
Squid does not run due to hard coded limits for the receive and send
buffer sizes of Unix Domain Sockets. In contrary to other OSes these
limits cannot be adjusted by a sysctl.
The attached patch adds some setsockopt() calls to comm.cc which sets
the buffer sizes to 256kb.

PS: Also i noticed that if squid is called with -z for creating the
cache directories, that ${process_number} macro is not expanded but
always set to 0. squid -z only creates one cache dir although in the
configuration
cache_dir ufs /var/squid/cache/cache-foo-${process_number} 700 8 16
is set.

Greetings,
Matthias
-------------- next part --------------
--- src/comm.cc.orig	Thu Jun 23 14:52:52 2016
+++ src/comm.cc	Thu Jun 23 14:54:34 2016
@@ -1937,6 +1937,20 @@ comm_open_uds(int sock_type,
     if (Config.tcpRcvBufsz > 0 && sock_type == SOCK_STREAM)
         commSetTcpRcvbuf(new_socket, Config.tcpRcvBufsz);
 
+#ifdef _SQUID_OPENBSD_
+    /* Set socket buffer size on Unix domain dgram sockets as OpenBSD defaults
+     * to 2k send and 4k recv buffer size
+     */
+    if (sock_type == SOCK_DGRAM) {
+	int size = 262144;
+	int error = 0;
+	if ((error = setsockopt(new_socket, SOL_SOCKET, SO_RCVBUF, &size, sizeof(size))) < 0)
+	    debugs(50, DBG_IMPORTANT, "Error setting rcv buffer size to " << size << ": " << xstrerr(error));
+	if ((error = setsockopt(new_socket, SOL_SOCKET, SO_SNDBUF, &size, sizeof(size))) < 0)
+	    debugs(50, DBG_IMPORTANT, "Error setting send buffer size to " << size << ": " << xstrerr(error));
+    }
+#endif
+
     PROF_stop(comm_open);
 
     return new_socket;

From squid3 at treenet.co.nz  Mon Jun 27 10:39:57 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 27 Jun 2016 22:39:57 +1200
Subject: [squid-users] flickr.com redirect error
In-Reply-To: <CAAFc9FiDM8_13Zq_OD37FdY_hm6hb431OREbZVwdyaeYxJRjDA@mail.gmail.com>
References: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
 <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>
 <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>
 <VI1PR04MB1359499FE2D9A57B3C0C33638F2E0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <CAAFc9FhiXeMc=J5SECc-MjF4hBDjXRZyS9zDtgMPjSz_iMEkKw@mail.gmail.com>
 <a97ea350-c237-2859-7c2a-cbf4d552ad5c@treenet.co.nz>
 <VI1PR04MB13599620DC40C00E14432EE88F2F0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <950cb95d-5e47-d51c-4ab3-d67d5437364e@treenet.co.nz>
 <CAAFc9FiDM8_13Zq_OD37FdY_hm6hb431OREbZVwdyaeYxJRjDA@mail.gmail.com>
Message-ID: <3f174bff-49bd-1acf-7bb5-3e52c3dccd51@treenet.co.nz>

On 27/06/2016 9:04 p.m., Ozgur Batur wrote:
> Hello Amos,
> 
> This is the via header sent by my local proxy as part of the request.
> *Via: 1.1 ubuntuozgen (squid/3.5.19)*
> 
> It is not fqdn but ubuntu concatanated with a Turkish name so it is highly
> unlikely that yahoo have such named reverse proxy. I could not decrypt the
> squid <--> flicker traffic yet this is from pcap output from another http
> site but i think it should be same right?

Yes pcap (with full packet data) should contain the same needed details
yes. cache.log with debug level 11,2 is the easier way to get the
headers though since the crypto is removed by Squid.

Amos



From ozgurbtr at gmail.com  Mon Jun 27 11:01:16 2016
From: ozgurbtr at gmail.com (Ozgur Batur)
Date: Mon, 27 Jun 2016 14:01:16 +0300
Subject: [squid-users] flickr.com redirect error
In-Reply-To: <3f174bff-49bd-1acf-7bb5-3e52c3dccd51@treenet.co.nz>
References: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
 <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>
 <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>
 <VI1PR04MB1359499FE2D9A57B3C0C33638F2E0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <CAAFc9FhiXeMc=J5SECc-MjF4hBDjXRZyS9zDtgMPjSz_iMEkKw@mail.gmail.com>
 <a97ea350-c237-2859-7c2a-cbf4d552ad5c@treenet.co.nz>
 <VI1PR04MB13599620DC40C00E14432EE88F2F0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <950cb95d-5e47-d51c-4ab3-d67d5437364e@treenet.co.nz>
 <CAAFc9FiDM8_13Zq_OD37FdY_hm6hb431OREbZVwdyaeYxJRjDA@mail.gmail.com>
 <3f174bff-49bd-1acf-7bb5-3e52c3dccd51@treenet.co.nz>
Message-ID: <CAAFc9Fh21bXOc8=YhDqcOvu3XiNNPpwDWhK30=Q5XgtmJjuv9g@mail.gmail.com>

Yes that is much easier, thank you.

Rafaels line is response header, I received the same. Here is the related
cachelog:

2016/06/27 13:52:49.194 kid1| 11,2| http.cc(2235) sendRequest: HTTP Server
REQUEST:
GET / HTTP/1.1
Accept:
text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
Upgrade-Insecure-Requests: 1
User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like
Gecko) Ubuntu Chromium/50.0.2661.102 Chrome/50.0.2661.102 Safari/537.36
Accept-Encoding: gzip, deflate, sdch
Accept-Language: tr,en-US;q=0.8,en;q=0.6
...
Host: www.flickr.com
Via: 1.1 ubuntuozgen (squid/3.5.19)
Surrogate-Capability: ubuntuozgen="Surrogate/1.0 ESI/1.0"
X-Forwarded-For: ::1
Cache-Control: max-age=0
Connection: keep-alive

..
2016/06/27 13:52:49.477 kid1| 11,2| http.cc(751) processReplyHeader: HTTP
Server REPLY:
---------
HTTP/1.1 301 Moved Permanently
X-Frame-Options: SAMEORIGIN
X-Content-Type-Options: nosniff
X-XSS-Protection: 1; mode=block
X-Served-By: pprd1-node552-lh1.manhattan.bf1.yahoo.com
X-Instance: flickr.v1.production.manhattan.bf1.yahoo.com
Cache-Control: no-cache, max-age=0, must-revalidate, no-store
Pragma: no-cache
X-Request-Id: 36e709a2
Location: https://www.flickr.com/
Vary: Accept
Content-Type: text/html; charset=utf-8
Content-Length: 102
Server: ATS
Date: Mon, 27 Jun 2016 10:52:40 GMT
Age: 0
Via: http/1.1 fts111.flickr.bf1.yahoo.com (ApacheTrafficServer [cMs f ]),
http/1.1 r11.ycpi.dea.yahoo.net (ApacheTrafficServer [cMs f ])
Connection: keep-alive
..

And this repeats on and on. As I understand disabling Via header is an
acceptable solution. If I could disable the header only for problematic
domains that would be better of course.

Thank you all.

On Mon, Jun 27, 2016 at 1:39 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 27/06/2016 9:04 p.m., Ozgur Batur wrote:
> > Hello Amos,
> >
> > This is the via header sent by my local proxy as part of the request.
> > *Via: 1.1 ubuntuozgen (squid/3.5.19)*
> >
> > It is not fqdn but ubuntu concatanated with a Turkish name so it is
> highly
> > unlikely that yahoo have such named reverse proxy. I could not decrypt
> the
> > squid <--> flicker traffic yet this is from pcap output from another http
> > site but i think it should be same right?
>
> Yes pcap (with full packet data) should contain the same needed details
> yes. cache.log with debug level 11,2 is the easier way to get the
> headers though since the crypto is removed by Squid.
>
> Amos
>
>


-- 
H ?zg?r Batur
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160627/4959b0d2/attachment.htm>

From squid3 at treenet.co.nz  Mon Jun 27 11:19:57 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 27 Jun 2016 23:19:57 +1200
Subject: [squid-users] [PATCH] Squid 3.5.19 SMP under OpenBSD -
 setsockopt for UDS
In-Reply-To: <5770EEF3.5060306@coronamundi.de>
References: <5770EEF3.5060306@coronamundi.de>
Message-ID: <98490fa4-2a7e-e9a1-1b71-4995e7a6ac0b@treenet.co.nz>

On 27/06/2016 9:16 p.m., Silamael wrote:
> Hi,
> 
> I'm playing around with the SMP feature on OpenBSD 5.9 and noticed that
> Squid does not run due to hard coded limits for the receive and send
> buffer sizes of Unix Domain Sockets. In contrary to other OSes these
> limits cannot be adjusted by a sysctl.

Is that a new regression in 5.9?
Can you provide a reference please?

We have had Squid working just fine with SMP on OpenBSD before.


> The attached patch adds some setsockopt() calls to comm.cc which sets
> the buffer sizes to 256kb.

Please submit patchs to the squid-dev mailing list.

Please also include an example of the errors that are visible to users
with your squid-dev submission so we can refer people complaining about
specific error messages to the appropriate fix.

And detail of where the 2K/4K limit you mention is located. So we can
verify if you are looking at the right limitation and what else it affects.
 AFAIK, the UDS limitations are about the size of objects which are used
over UDS sockets. Reading 256KB into a 4KB object does not have pretty
results. Likewise a blocking queue of up to 64 time-critical SMP actions
awaiting the first one getting its synchronous UDS response does not
have good side effects.

We no longer accept #ifdef construction in squid coding guidelines. Use
#if instead. If you can please also identify what other *BSD are needing
this and add them to the #if condition.
 Though if this is accepted the change may be relevant to all OS and not
needing a wrapper at all.


> 
> PS: Also i noticed that if squid is called with -z for creating the
> cache directories, that ${process_number} macro is not expanded but
> always set to 0. squid -z only creates one cache dir although in the
> configuration
> cache_dir ufs /var/squid/cache/cache-foo-${process_number} 700 8 16
> is set.

That sounds more like the behaviour of "-N -z".

Just "-z" spawns the SMP workers and each worker generates its own cache
directories before exiting. That is needed in Squid-3 since only the
worker knows what its cache_dir expansions are.

Note that the master -z process may exit far faster than any of the
workers during a SMP aware -z execution since it has nothing to do. Your
script may not be waiting long enough for the cache dir creation to
happen in workers. YMMV, but I give -z at least 10 seconds to complete.

If a worker is still running when you start the normal Squid process
then UDS socket errors are almost guaranteed. Timing races mean it may
not happen reliably, but usually does.

Squid-4 has the --foreground command line option to avoid these problems.

Amos



From squid3 at treenet.co.nz  Mon Jun 27 11:27:26 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 27 Jun 2016 23:27:26 +1200
Subject: [squid-users] flickr.com redirect error
In-Reply-To: <CAAFc9Fh21bXOc8=YhDqcOvu3XiNNPpwDWhK30=Q5XgtmJjuv9g@mail.gmail.com>
References: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
 <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>
 <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>
 <VI1PR04MB1359499FE2D9A57B3C0C33638F2E0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <CAAFc9FhiXeMc=J5SECc-MjF4hBDjXRZyS9zDtgMPjSz_iMEkKw@mail.gmail.com>
 <a97ea350-c237-2859-7c2a-cbf4d552ad5c@treenet.co.nz>
 <VI1PR04MB13599620DC40C00E14432EE88F2F0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <950cb95d-5e47-d51c-4ab3-d67d5437364e@treenet.co.nz>
 <CAAFc9FiDM8_13Zq_OD37FdY_hm6hb431OREbZVwdyaeYxJRjDA@mail.gmail.com>
 <3f174bff-49bd-1acf-7bb5-3e52c3dccd51@treenet.co.nz>
 <CAAFc9Fh21bXOc8=YhDqcOvu3XiNNPpwDWhK30=Q5XgtmJjuv9g@mail.gmail.com>
Message-ID: <3be92fc1-3cfc-cf51-82e0-9d34aa8ca0cd@treenet.co.nz>

On 27/06/2016 11:01 p.m., Ozgur Batur wrote:
> Yes that is much easier, thank you.
> 
> Rafaels line is response header, I received the same. Here is the related
> cachelog:
> 

What is the content of the line above this one. With the IP:port details ?

> 2016/06/27 13:52:49.194 kid1| 11,2| http.cc(2235) sendRequest: HTTP Server
> REQUEST:
> GET / HTTP/1.1
> Accept:
> text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
> Upgrade-Insecure-Requests: 1
> User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like
> Gecko) Ubuntu Chromium/50.0.2661.102 Chrome/50.0.2661.102 Safari/537.36
> Accept-Encoding: gzip, deflate, sdch
> Accept-Language: tr,en-US;q=0.8,en;q=0.6
> ...
> Host: www.flickr.com
> Via: 1.1 ubuntuozgen (squid/3.5.19)
> Surrogate-Capability: ubuntuozgen="Surrogate/1.0 ESI/1.0"
> X-Forwarded-For: ::1

You said this was using interception. But Squid XFF is telling Yahoo
that its receiving localhost traffic.

Try "forwarded_for transparent" in your squid.conf, and find out why
that ::1 is happening on an intercepted proxy. There may be a bug in
your NAT or routing configuration.


> Cache-Control: max-age=0
> Connection: keep-alive
> 
> ..
> 2016/06/27 13:52:49.477 kid1| 11,2| http.cc(751) processReplyHeader: HTTP
> Server REPLY:
> ---------
> HTTP/1.1 301 Moved Permanently
> X-Frame-Options: SAMEORIGIN
> X-Content-Type-Options: nosniff
> X-XSS-Protection: 1; mode=block
> X-Served-By: pprd1-node552-lh1.manhattan.bf1.yahoo.com
> X-Instance: flickr.v1.production.manhattan.bf1.yahoo.com
> Cache-Control: no-cache, max-age=0, must-revalidate, no-store
> Pragma: no-cache
> X-Request-Id: 36e709a2
> Location: https://www.flickr.com/
> Vary: Accept
> Content-Type: text/html; charset=utf-8
> Content-Length: 102
> Server: ATS
> Date: Mon, 27 Jun 2016 10:52:40 GMT
> Age: 0
> Via: http/1.1 fts111.flickr.bf1.yahoo.com (ApacheTrafficServer [cMs f ]),
> http/1.1 r11.ycpi.dea.yahoo.net (ApacheTrafficServer [cMs f ])
> Connection: keep-alive
> ..
> 
> And this repeats on and on. As I understand disabling Via header is an
> acceptable solution. If I could disable the header only for problematic
> domains that would be better of course.

Okay. Unfortunately not possible. If that forwarded_for change works it
would be better than disabling Via.

Amos



From Silamael at coronamundi.de  Mon Jun 27 11:35:48 2016
From: Silamael at coronamundi.de (Silamael)
Date: Mon, 27 Jun 2016 13:35:48 +0200
Subject: [squid-users] [PATCH] Squid 3.5.19 SMP under OpenBSD -
 setsockopt for UDS
In-Reply-To: <98490fa4-2a7e-e9a1-1b71-4995e7a6ac0b@treenet.co.nz>
References: <5770EEF3.5060306@coronamundi.de>
 <98490fa4-2a7e-e9a1-1b71-4995e7a6ac0b@treenet.co.nz>
Message-ID: <57710F94.2000405@coronamundi.de>

On 27.06.2016 13:19, Amos Jeffries wrote:
> On 27/06/2016 9:16 p.m., Silamael wrote:
>> Hi,
>>
>> I'm playing around with the SMP feature on OpenBSD 5.9 and noticed that
>> Squid does not run due to hard coded limits for the receive and send
>> buffer sizes of Unix Domain Sockets. In contrary to other OSes these
>> limits cannot be adjusted by a sysctl.
> 
> Is that a new regression in 5.9?
> Can you provide a reference please?

Haven't tested it with a prior version than 5.9.
But as the buffer limits haven't changed for a long time I don't think
that's a regression in 5.9.

> 
> We have had Squid working just fine with SMP on OpenBSD before.

That's interesting. Without the patch with no disk cache at all
configured and 4 workers, Squid seem to run a short time until the
children terminate due to a registration timeout.

> 
>> The attached patch adds some setsockopt() calls to comm.cc which sets
>> the buffer sizes to 256kb.
> 
> Please submit patchs to the squid-dev mailing list.
> 
> Please also include an example of the errors that are visible to users
> with your squid-dev submission so we can refer people complaining about
> specific error messages to the appropriate fix.

The error I got was a write failed on the UDS socket. Error code was
EMSGSIZE. Squid tried to write 4320 bytes on the socket.

> 
> And detail of where the 2K/4K limit you mention is located. So we can
> verify if you are looking at the right limitation and what else it affects.
>  AFAIK, the UDS limitations are about the size of objects which are used
> over UDS sockets. Reading 256KB into a 4KB object does not have pretty
> results. Likewise a blocking queue of up to 64 time-critical SMP actions
> awaiting the first one getting its synchronous UDS response does not
> have good side effects.

The limits can be found in /usr/src/sys/kern/uipc_usrreq.c:
u_long unpdg_sendspace = 2*1024;
u_long unpdg_recvspace = 4*1024;

Quick check against OpenBSD 5.2 showed no difference.
The value of 256kb is just taken from the Squid SMP FAQ page.

> 
> We no longer accept #ifdef construction in squid coding guidelines. Use
> #if instead. If you can please also identify what other *BSD are needing
> this and add them to the #if condition.
>  Though if this is accepted the change may be relevant to all OS and not
> needing a wrapper at all.

Ok, I can change the #ifdef into an #if. But I don't have other BSDs for
testing.

> 
>>
>> PS: Also i noticed that if squid is called with -z for creating the
>> cache directories, that ${process_number} macro is not expanded but
>> always set to 0. squid -z only creates one cache dir although in the
>> configuration
>> cache_dir ufs /var/squid/cache/cache-foo-${process_number} 700 8 16
>> is set.
> 
> That sounds more like the behaviour of "-N -z".

Ah, that explains a lot. Our wrapper scripts are using -N when creating
the cache directories...


From carlopmart at gmail.com  Mon Jun 27 13:30:08 2016
From: carlopmart at gmail.com (C. L. Martinez)
Date: Mon, 27 Jun 2016 13:30:08 +0000
Subject: [squid-users] Cipher suites errors
Message-ID: <20160627133008.GB9391@beagle.bcn.sia.es>

Hi all,

 After some tunning to configure my squid's host with ssl_bump and intermediate CA (many thanks Yuri), I have tested my setup against https://www.ssllabs.com and https://howsmyssl.com and both sites returns me the following error:

Some unknown cipher suite: 0xff85 (SSLLabs says UNKNOWN (0xff85)   WEAK)
Some unknown cipher suite: 0x0081

 My relevant config is:

sslproxy_options SINGLE_DH_USE,SINGLE_ECDH_USE
sslproxy_cipher HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
https_port 127.0.0.1:5145 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/certs/server.crt \
        key=/etc/squid/certs/server.key tls-dh=prime256v1:/etc/squid/certs/dhparam.pem \
                options=SINGLE_DH_USE,SINGLE_ECDH_USE cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

 Am I doing something wrong?? I am using squid's wiki suggested config ...

Thanks.

-- 
Greetings,
C. L. Martinez


From squid3 at treenet.co.nz  Mon Jun 27 13:30:14 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 28 Jun 2016 01:30:14 +1200
Subject: [squid-users] Some websites doesn't work with squid anymore
In-Reply-To: <CAFU=CpeiNxgafmvpLmC=5oTG06G5UcRLHFn2xTa6kiRMZChbkg@mail.gmail.com>
References: <CAFU=CpdbHOqSmozVfWBHV-jJEr2hat9h-aNKxF-EhtBx0Z6mQw@mail.gmail.com>
 <34616003-f25a-38d9-2e5f-ea0987b8cafa@treenet.co.nz>
 <CAFU=CpeiNxgafmvpLmC=5oTG06G5UcRLHFn2xTa6kiRMZChbkg@mail.gmail.com>
Message-ID: <b85d3dee-9cb6-82f0-8304-da2f59fca5e2@treenet.co.nz>

On 28/06/2016 1:13 a.m., Adam Wright wrote:
> Nothing changed, I'm still trying to understand what's going on. I'm trying
> different scenarios. I ended up something very interesting.
> 
> When I use the 4g internet of my mobile phone with squid, those websites
> works! But with my adsl connection, those websites doesn't work.
> 
> Is it possible for an ISP to filter and block a website even using squid
> proxy server?

Yes it is possible for your ISP to be doing things even when you use
Squid. To them its almost no difference than you not using Squid.

Some of the reports I saw about this error turned out to be Chrome
bypassing the proxy and being blocked doing its proprietary things on
private channels. Thats why I asked what your access.log mentioned.

It might also be IPv6 related. Mobile networking is a lot more advanced
in use of IPv6 than many DSL type ISPs. If the ISP is dropping (not
rejecting) some traffic, then you could easily see connection hanging
behaviour which the browser reports as zero-sized reply [request went
out, nothing came back].

Amos



From yvoinov at gmail.com  Mon Jun 27 13:38:27 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 27 Jun 2016 19:38:27 +0600
Subject: [squid-users] Some websites doesn't work with squid anymore
In-Reply-To: <b85d3dee-9cb6-82f0-8304-da2f59fca5e2@treenet.co.nz>
References: <CAFU=CpdbHOqSmozVfWBHV-jJEr2hat9h-aNKxF-EhtBx0Z6mQw@mail.gmail.com>
 <34616003-f25a-38d9-2e5f-ea0987b8cafa@treenet.co.nz>
 <CAFU=CpeiNxgafmvpLmC=5oTG06G5UcRLHFn2xTa6kiRMZChbkg@mail.gmail.com>
 <b85d3dee-9cb6-82f0-8304-da2f59fca5e2@treenet.co.nz>
Message-ID: <0bfa2e2c-83fb-2d18-c6c1-1361298ba6ed@gmail.com>

One note:

I have the same issue with *supportforums.cisco.com*.


It also blocked/filter by ISP? Every time via Squid I has this issue. 
Directly connected browser still works.


27.06.2016 19:30, Amos Jeffries ?????:
> On 28/06/2016 1:13 a.m., Adam Wright wrote:
>> Nothing changed, I'm still trying to understand what's going on. I'm trying
>> different scenarios. I ended up something very interesting.
>>
>> When I use the 4g internet of my mobile phone with squid, those websites
>> works! But with my adsl connection, those websites doesn't work.
>>
>> Is it possible for an ISP to filter and block a website even using squid
>> proxy server?
> Yes it is possible for your ISP to be doing things even when you use
> Squid. To them its almost no difference than you not using Squid.
>
> Some of the reports I saw about this error turned out to be Chrome
> bypassing the proxy and being blocked doing its proprietary things on
> private channels. Thats why I asked what your access.log mentioned.
>
> It might also be IPv6 related. Mobile networking is a lot more advanced
> in use of IPv6 than many DSL type ISPs. If the ISP is dropping (not
> rejecting) some traffic, then you could easily see connection hanging
> behaviour which the browser reports as zero-sized reply [request went
> out, nothing came back].
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160627/c7ff5b1b/attachment.htm>

From yvoinov at gmail.com  Mon Jun 27 13:39:20 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 27 Jun 2016 19:39:20 +0600
Subject: [squid-users] Cipher suites errors
In-Reply-To: <20160627133008.GB9391@beagle.bcn.sia.es>
References: <20160627133008.GB9391@beagle.bcn.sia.es>
Message-ID: <27ec0452-3624-0ee8-2442-3058c036f2b9@gmail.com>

This is GOST-based ciphers included in LibreSSL. Don't worry about it.


27.06.2016 19:30, C. L. Martinez ?????:
> Hi all,
>
>   After some tunning to configure my squid's host with ssl_bump and intermediate CA (many thanks Yuri), I have tested my setup against https://www.ssllabs.com and https://howsmyssl.com and both sites returns me the following error:
>
> Some unknown cipher suite: 0xff85 (SSLLabs says UNKNOWN (0xff85)   WEAK)
> Some unknown cipher suite: 0x0081
>
>   My relevant config is:
>
> sslproxy_options SINGLE_DH_USE,SINGLE_ECDH_USE
> sslproxy_cipher HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> https_port 127.0.0.1:5145 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/certs/server.crt \
>          key=/etc/squid/certs/server.key tls-dh=prime256v1:/etc/squid/certs/dhparam.pem \
>                  options=SINGLE_DH_USE,SINGLE_ECDH_USE cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>
>   Am I doing something wrong?? I am using squid's wiki suggested config ...
>
> Thanks.
>



From squid at borrill.org.uk  Mon Jun 27 13:55:23 2016
From: squid at borrill.org.uk (Stephen Borrill)
Date: Mon, 27 Jun 2016 14:55:23 +0100
Subject: [squid-users] [PATCH] Squid 3.5.19 SMP under OpenBSD -
 setsockopt for UDS
In-Reply-To: <57710F94.2000405@coronamundi.de>
References: <5770EEF3.5060306@coronamundi.de>
 <98490fa4-2a7e-e9a1-1b71-4995e7a6ac0b@treenet.co.nz>
 <57710F94.2000405@coronamundi.de>
Message-ID: <86f17aa1-88a5-ba82-51c3-f46a8c7e39a1@borrill.org.uk>

On 27/06/2016 12:35, Silamael wrote:
> On 27.06.2016 13:19, Amos Jeffries wrote:
>> On 27/06/2016 9:16 p.m., Silamael wrote:
>>> Hi,
>>>
>>> I'm playing around with the SMP feature on OpenBSD 5.9 and noticed that
>>> Squid does not run due to hard coded limits for the receive and send
>>> buffer sizes of Unix Domain Sockets. In contrary to other OSes these
>>> limits cannot be adjusted by a sysctl.
>>
>> Is that a new regression in 5.9?
>> Can you provide a reference please?
> 
> Haven't tested it with a prior version than 5.9.
> But as the buffer limits haven't changed for a long time I don't think
> that's a regression in 5.9.
> 
>>
>> We have had Squid working just fine with SMP on OpenBSD before.
> 
> That's interesting. Without the patch with no disk cache at all
> configured and 4 workers, Squid seem to run a short time until the
> children terminate due to a registration timeout.
> 
>>
>>> The attached patch adds some setsockopt() calls to comm.cc which sets
>>> the buffer sizes to 256kb.
>>
>> Please submit patchs to the squid-dev mailing list.
>>
>> Please also include an example of the errors that are visible to users
>> with your squid-dev submission so we can refer people complaining about
>> specific error messages to the appropriate fix.
> 
> The error I got was a write failed on the UDS socket. Error code was
> EMSGSIZE. Squid tried to write 4320 bytes on the socket.
> 
>>
>> And detail of where the 2K/4K limit you mention is located. So we can
>> verify if you are looking at the right limitation and what else it affects.
>>  AFAIK, the UDS limitations are about the size of objects which are used
>> over UDS sockets. Reading 256KB into a 4KB object does not have pretty
>> results. Likewise a blocking queue of up to 64 time-critical SMP actions
>> awaiting the first one getting its synchronous UDS response does not
>> have good side effects.
> 
> The limits can be found in /usr/src/sys/kern/uipc_usrreq.c:
> u_long unpdg_sendspace = 2*1024;
> u_long unpdg_recvspace = 4*1024;
> 
> Quick check against OpenBSD 5.2 showed no difference.
> The value of 256kb is just taken from the Squid SMP FAQ page.

Yes, namely:

Squid workers exchange Unix Domain Sockets (UDS) messages (not to be
confused with UDP messages or System V IPC messages). These messages
should be smaller than 16KB in size, but even that creates problems in
some environments because of very low default UDS message size and
buffer size limits.

Usually, the limits can be adjusted using sysctl but exact control names
are not documented and vary from one OS to another. Here is one known
variant with recommended minimum settings (please add more if you know
them!):


net.local.dgram.recvspace: 262144
net.local.dgram.maxdgram: 16384

>> We no longer accept #ifdef construction in squid coding guidelines. Use
>> #if instead. If you can please also identify what other *BSD are needing
>> this and add them to the #if condition.
>>  Though if this is accepted the change may be relevant to all OS and not
>> needing a wrapper at all.
> 
> Ok, I can change the #ifdef into an #if. But I don't have other BSDs for
> testing.

I can help you there :-)

>From NetBSD:
FATAL: kid2 registration timed out
Squid Cache (Version 3.5.19): Terminated abnormally.
CPU Usage: 0.169 seconds = 0.074 user + 0.095 sys
Maximum Resident Size: 0 KB
Page faults with physical i/o: 55


/usr/src/sys/kern/uipc_usrreq.c is the same as OpenBSD:

/*
 * Both send and receive buffers are allocated PIPSIZ bytes of buffering
 * for stream sockets, although the total for sender and receiver is
 * actually only PIPSIZ.
 * Datagram sockets really use the sendspace as the maximum datagram size,
 * and don't really want to reserve the sendspace.  Their recvspace should
 * be large enough for at least one max-size datagram plus address.
 */
#define PIPSIZ  4096
u_long  unpst_sendspace = PIPSIZ;
u_long  unpst_recvspace = PIPSIZ;
u_long  unpdg_sendspace = 2*1024;       /* really max datagram size */
u_long  unpdg_recvspace = 4*1024;




From squid3 at treenet.co.nz  Mon Jun 27 13:56:06 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 28 Jun 2016 01:56:06 +1200
Subject: [squid-users] Some websites doesn't work with squid anymore
In-Reply-To: <CAFU=Cpe7Zi-bZ73gA91vDQR6_wyKcJc=UgpZwQC3nTFzCvZiVw@mail.gmail.com>
References: <CAFU=CpdbHOqSmozVfWBHV-jJEr2hat9h-aNKxF-EhtBx0Z6mQw@mail.gmail.com>
 <34616003-f25a-38d9-2e5f-ea0987b8cafa@treenet.co.nz>
 <CAFU=CpeiNxgafmvpLmC=5oTG06G5UcRLHFn2xTa6kiRMZChbkg@mail.gmail.com>
 <b85d3dee-9cb6-82f0-8304-da2f59fca5e2@treenet.co.nz>
 <CAFU=Cpe7Zi-bZ73gA91vDQR6_wyKcJc=UgpZwQC3nTFzCvZiVw@mail.gmail.com>
Message-ID: <9c0e34b6-974a-cf07-1316-561af0b908a5@treenet.co.nz>

On 28/06/2016 1:43 a.m., Adam Wright wrote:
> I always thought for years, using a proxy server hides me from my isp to
> see which websites I'm using etc... Because I'm only connecting to my vps
> server with the help of squid.

You need a VPN or similar encrypted tunnel for that use case. Use of
interception and Squid to direct traffic over the VPN can avoid ISP. But
just using the proxy to connect to an external server does not. The ISP
will just see regular HTTP happening on a different port.


> 
> I checked /var/log/squid3/access.log it shows gmail and other websites. Not
> showing those blocked websites.

Then the browser is not even using the proxy. That is probably the issue
right there.


> 
> I'm using firefox and maxthon.
> 

Strange. "Error code 324 (net::ERR_EMPTY_RESPONSE)" is a Chrome error.

Amos



From renjop at gmail.com  Mon Jun 27 14:25:35 2016
From: renjop at gmail.com (Renato Jop)
Date: Mon, 27 Jun 2016 08:25:35 -0600
Subject: [squid-users] Skype Issues
In-Reply-To: <5153128f-ddd0-c134-22f1-158aa97575b4@gmail.com>
References: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>
 <8ff3bffe-47b7-8b0d-148d-cd3254344fd1@treenet.co.nz>
 <a30b3e16-5209-8240-359a-0cf736fe129f@gmail.com>
 <6e208cda-cb22-e48d-c0ee-0a6db04448e0@treenet.co.nz>
 <5153128f-ddd0-c134-22f1-158aa97575b4@gmail.com>
Message-ID: <CAHha_zUDd__ZyMUCDQDcJ4KQouk++2OoZiEMptHY=Ty08D549A@mail.gmail.com>

Thank you both for your valuable help.
I've configured the tls-dh param with a strong Diffie-Hellman group (2048
bits) and configured the cipher as Yuri specified and I was able to get
pass the unknown cipher, however now I get a "SSL
routines:SSL3_GET_RECORD:wrong version number". Here's the configuration I
changed:
 cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
tls-dh=/usr/local/etc/squid/dhparams.pem



Renato Jop

On Sat, Jun 25, 2016 at 11:34 AM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
>
>
> 25.06.2016 23:09, Amos Jeffries ?????:
> > On 26/06/2016 4:32 a.m., Yuri Voinov wrote:
> >>
> >> Amos, you are a wrong.
> >>
> >> No Squid-4. It's unstable and not ready for production. Whenever it's
> >> features.
> >
> > So some beta software has bugs therefore nobody should ever use it for
> > anything. I find that to be a strange and sad view of the world.
> >
> > Care to guess why I listed it as the last option amongst several?
> >  Or why 4.0.11 exists as a beta still?
> > It *is* an option for the mentioned problem(s) though whatever its
> utility.
> Agreed.
> >
> >
> >
> >>
> >> Some time ago I have the same issue and know what happens exactly.
> >>
> >> Skype initial connection site uses RC4 cipher. Which is disabled in most
> >> squid's configuration.
> >
> > Your "know what happens exactly" differs from at least two other peoples
> > debugging experiences with Skype.
> >
> > RC4 is on the hitlist for most of the big vendors for the past year or
> > so. IIRC there were several Windows Updates to remove it and other
> > broken bits from a lot of things over the past year.
> > If Skype is still using RC4 it might be part of this problem.
> I'm sure this is problem and this problem exists. MS do nothing to make
> they sites/services more secure. BTW, MS Updates uses RC4 ciphers itself
> this time. With strong siphers there is no way to setup WU via Squid.
> I've spent much time to identify this problem in my setup and find
> working workaround.
>
> Another part of problem is: MS often uses it's own self-signed roots,
> which is exists in Windows, but nowhere else. And which has not
> cross-signed by well-known root CA's. They think it make MS services
> more secure. They wrong. But we can't do anything with it. So, this is
> forced us to add self-signed MS roots to our Squid's CA bundles to
> bump/splice.
> >
> >
> >>
> >> To make it works (as by as most M$ update sites) it's require simple use
> >> this cipher's suite:
> >>
> >> HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
> >>
> >> That works for me in 5 SSL bumped setups. There is no matter which squid
> >> version installed.
> >
> > Thank you. Thats another option then. I'd rate that below trying the EC
> > ciphers, and above library updates.
> You are welcome.
>
> Just for information: MS has own IT infrastructure, with some strange
> configured and non well-managed elements. I can't guarantee this
> workaround will work everywhere or for every MS service.
>
> When I made my research, I've seen some strange security TLS
> combinations on MS sites/services. I.e., for example, RC4+ECDSA+TLSv1.2.
> Or, for example, RC4+MD5+TLSv1. And some similar. Very idiotic and
> potentially dangerous combinations. And - they support ignores all
> requests. As usual.
>
> To my regret, I can not order all of its users to abandon the use of
> Windows. So far, in my infrastructure have machines with Windows XP.
>
> With this nothing can be done, it is necessary only to weaken the
> security - for the sake of compatibility.
> >
> >
> > Amos
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXbsC5AAoJENNXIZxhPexGiFoH/jrtimBNppF1uHpVTNwOO10z
> yF2APMA56S8woNZzhUNjT8+oJFPrthnMoQFrqgicjS77SBAFp9KcOV+SxOKl9+sW
> OdAHDPuCD7dGnKzAdFDR1YR7Vp5IpElP1rFO5rqKXeBc3iKjq65BfF+T6atHy6cS
> 0VAaluvqvHQps2wVKoYxGURDf3Y2K0lJn+qF+s2CaBwEufhzgKSvG0aUIDqTfHfK
> 3EMQTpPtlTqm+pcexR+oZM1WE1hlES1khOXs51fgo6puPryqWJiHGvO4EBEfWoXF
> Skval2COzcdzMvC5jjfGbMEPNGNJrYUeq/KNgppRvE2wQJ+gCLYG317decKHty0=
> =8BTp
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160627/f6ca47f3/attachment.htm>

From yvoinov at gmail.com  Mon Jun 27 14:29:46 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 27 Jun 2016 20:29:46 +0600
Subject: [squid-users] Skype Issues
In-Reply-To: <CAHha_zUDd__ZyMUCDQDcJ4KQouk++2OoZiEMptHY=Ty08D549A@mail.gmail.com>
References: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>
 <8ff3bffe-47b7-8b0d-148d-cd3254344fd1@treenet.co.nz>
 <a30b3e16-5209-8240-359a-0cf736fe129f@gmail.com>
 <6e208cda-cb22-e48d-c0ee-0a6db04448e0@treenet.co.nz>
 <5153128f-ddd0-c134-22f1-158aa97575b4@gmail.com>
 <CAHha_zUDd__ZyMUCDQDcJ4KQouk++2OoZiEMptHY=Ty08D549A@mail.gmail.com>
Message-ID: <b3abc44d-7abf-aa9a-ebd3-a775c4a81854@gmail.com>

Try to remove NO_SSLv2,NO_SSLv3 from options. SSLv2 already not 
supported everywhere, RC4/3DES is SSLv3 ciphers, so it can be confuse 
software. I.e., you use custom ciphers/protocols combinations, which can 
lead issue.


27.06.2016 20:25, Renato Jop ?????:
> Thank you both for your valuable help.
> I've configured the tls-dh param with a strong Diffie-Hellman group 
> (2048 bits) and configured the cipher as Yuri specified and I was able 
> to get pass the unknown cipher, however now I get a "SSL 
> routines:SSL3_GET_RECORD:wrong version number". Here's the 
> configuration I changed:
>  cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS 
> dhparams=/etc/dh-parameters.2048 
> options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE 
> tls-dh=/usr/local/etc/squid/dhparams.pem
>
>
>
> Renato Jop
>
> On Sat, Jun 25, 2016 at 11:34 AM, Yuri Voinov <yvoinov at gmail.com 
> <mailto:yvoinov at gmail.com>> wrote:
>
>
>     -----BEGIN PGP SIGNED MESSAGE-----
>     Hash: SHA256
>
>
>
>     25.06.2016 <tel:25.06.2016> 23:09, Amos Jeffries ?????:
>     > On 26/06/2016 4:32 a.m., Yuri Voinov wrote:
>     >>
>     >> Amos, you are a wrong.
>     >>
>     >> No Squid-4. It's unstable and not ready for production.
>     Whenever it's
>     >> features.
>     >
>     > So some beta software has bugs therefore nobody should ever use
>     it for
>     > anything. I find that to be a strange and sad view of the world.
>     >
>     > Care to guess why I listed it as the last option amongst several?
>     >  Or why 4.0.11 exists as a beta still?
>     > It *is* an option for the mentioned problem(s) though whatever its
>     utility.
>     Agreed.
>     >
>     >
>     >
>     >>
>     >> Some time ago I have the same issue and know what happens exactly.
>     >>
>     >> Skype initial connection site uses RC4 cipher. Which is
>     disabled in most
>     >> squid's configuration.
>     >
>     > Your "know what happens exactly" differs from at least two other
>     peoples
>     > debugging experiences with Skype.
>     >
>     > RC4 is on the hitlist for most of the big vendors for the past
>     year or
>     > so. IIRC there were several Windows Updates to remove it and other
>     > broken bits from a lot of things over the past year.
>     > If Skype is still using RC4 it might be part of this problem.
>     I'm sure this is problem and this problem exists. MS do nothing to
>     make
>     they sites/services more secure. BTW, MS Updates uses RC4 ciphers
>     itself
>     this time. With strong siphers there is no way to setup WU via Squid.
>     I've spent much time to identify this problem in my setup and find
>     working workaround.
>
>     Another part of problem is: MS often uses it's own self-signed roots,
>     which is exists in Windows, but nowhere else. And which has not
>     cross-signed by well-known root CA's. They think it make MS services
>     more secure. They wrong. But we can't do anything with it. So, this is
>     forced us to add self-signed MS roots to our Squid's CA bundles to
>     bump/splice.
>     >
>     >
>     >>
>     >> To make it works (as by as most M$ update sites) it's require
>     simple use
>     >> this cipher's suite:
>     >>
>     >> HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>     >>
>     >> That works for me in 5 SSL bumped setups. There is no matter
>     which squid
>     >> version installed.
>     >
>     > Thank you. Thats another option then. I'd rate that below trying
>     the EC
>     > ciphers, and above library updates.
>     You are welcome.
>
>     Just for information: MS has own IT infrastructure, with some strange
>     configured and non well-managed elements. I can't guarantee this
>     workaround will work everywhere or for every MS service.
>
>     When I made my research, I've seen some strange security TLS
>     combinations on MS sites/services. I.e., for example,
>     RC4+ECDSA+TLSv1.2.
>     Or, for example, RC4+MD5+TLSv1. And some similar. Very idiotic and
>     potentially dangerous combinations. And - they support ignores all
>     requests. As usual.
>
>     To my regret, I can not order all of its users to abandon the use of
>     Windows. So far, in my infrastructure have machines with Windows XP.
>
>     With this nothing can be done, it is necessary only to weaken the
>     security - for the sake of compatibility.
>     >
>     >
>     > Amos
>     > _______________________________________________
>     > squid-users mailing list
>     > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     > http://lists.squid-cache.org/listinfo/squid-users
>
>     -----BEGIN PGP SIGNATURE-----
>     Version: GnuPG v2
>
>     iQEcBAEBCAAGBQJXbsC5AAoJENNXIZxhPexGiFoH/jrtimBNppF1uHpVTNwOO10z
>     yF2APMA56S8woNZzhUNjT8+oJFPrthnMoQFrqgicjS77SBAFp9KcOV+SxOKl9+sW
>     OdAHDPuCD7dGnKzAdFDR1YR7Vp5IpElP1rFO5rqKXeBc3iKjq65BfF+T6atHy6cS
>     0VAaluvqvHQps2wVKoYxGURDf3Y2K0lJn+qF+s2CaBwEufhzgKSvG0aUIDqTfHfK
>     3EMQTpPtlTqm+pcexR+oZM1WE1hlES1khOXs51fgo6puPryqWJiHGvO4EBEfWoXF
>     Skval2COzcdzMvC5jjfGbMEPNGNJrYUeq/KNgppRvE2wQJ+gCLYG317decKHty0=
>     =8BTp
>     -----END PGP SIGNATURE-----
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160627/273f98f6/attachment.htm>

From squid3 at treenet.co.nz  Mon Jun 27 14:32:36 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 28 Jun 2016 02:32:36 +1200
Subject: [squid-users] Some websites doesn't work with squid anymore
In-Reply-To: <CAFU=CpfVrROQ3=rhH+6c1h3+M+UPQs3iT_vLGn7v8Tb3V1oHOQ@mail.gmail.com>
References: <CAFU=CpdbHOqSmozVfWBHV-jJEr2hat9h-aNKxF-EhtBx0Z6mQw@mail.gmail.com>
 <34616003-f25a-38d9-2e5f-ea0987b8cafa@treenet.co.nz>
 <CAFU=CpeiNxgafmvpLmC=5oTG06G5UcRLHFn2xTa6kiRMZChbkg@mail.gmail.com>
 <b85d3dee-9cb6-82f0-8304-da2f59fca5e2@treenet.co.nz>
 <CAFU=Cpe7Zi-bZ73gA91vDQR6_wyKcJc=UgpZwQC3nTFzCvZiVw@mail.gmail.com>
 <9c0e34b6-974a-cf07-1316-561af0b908a5@treenet.co.nz>
 <CAFU=CpfVrROQ3=rhH+6c1h3+M+UPQs3iT_vLGn7v8Tb3V1oHOQ@mail.gmail.com>
Message-ID: <17c781aa-8768-f58b-2308-8120ecac7826@treenet.co.nz>

[ Please reply to the mailing list I dont do private support except for
paying customers. And you have not arranged for that in advance. ]

On 28/06/2016 2:06 a.m., Adam Wright wrote:
> - Ok, ISP will see my http traffic, but will the ISP see which websites I'm
> surfing?

If anyone can see HTTP traffic they can see what the traffic is about.


> 
> - Browser is using the proxy. But access.log only shows the websites which
> the browser connected successfully. For example I see cisco.com which I
> entered minutes ago for Yuri.
> 
> 1467035091.072  15004 85.107.208.29 TCP_MISS/200 246 CONNECT
> supportforums.cisco.com:443 yeni DIRECT/141.101.115.192

The proxy log records every transaction through the proxy, at the time
that transaction completed. Whether it succeeded or not. Anything that
get started is prone to being logged.

In the case above it was a CONNECT tunnel transferring some TLS wrapped
protocol - probably HTTPS, SPDY or WebSockets on port 443. It took
15.004 seconds to do whatever took 246 bytes to transfer.

So nothing in the log indicates either the browser is *not* using the
proxy for those transactions, or they are still ongoing as far as Squid
is concerned.

It could be a case of browser using SPDY, QUICK or WebSockets protocols
instead of HTTP inside a TLS tunnel, or directly without the proxy.
Particularly if Chrome is involved.

The case of ongoing connections is unfortunate. You can tune Squid
timeouts somewhat to make the proxy more sensitive and do its failover
to working destinations faster. But otherwise its a browser specific
problem that can only be fixed by the browser.

It might be that whatever was happening inside that tunnel above got
stuck and timed out. To Squid the tunnel is opaque, so any type of error
in there is strictly between the browser and server.

The tiny size on that log entry makes me suspect its TLS handshake
hanging and a 15sec timeout somewhere closes it down. If so the issue is
not Squid, its whatever in the server or browser is causing the TLS to hang.

> 
> - Right now I'm using maxthon, it also says "Error code 101
> (net::ERR_CONNECTION_RESET)" while I try to connect to those xxx websites.
> 

That seems to mean the proxy is closing the connection. But that would
mean the proxy is aware of it ending and record in the log what
transaction finished with aborting the connection.

If there no log record, thats a very strong sign that the browser is not
using the proxy for that request.

Amos



From yvoinov at gmail.com  Mon Jun 27 14:38:10 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 27 Jun 2016 20:38:10 +0600
Subject: [squid-users] Some websites doesn't work with squid anymore
In-Reply-To: <17c781aa-8768-f58b-2308-8120ecac7826@treenet.co.nz>
References: <CAFU=CpdbHOqSmozVfWBHV-jJEr2hat9h-aNKxF-EhtBx0Z6mQw@mail.gmail.com>
 <34616003-f25a-38d9-2e5f-ea0987b8cafa@treenet.co.nz>
 <CAFU=CpeiNxgafmvpLmC=5oTG06G5UcRLHFn2xTa6kiRMZChbkg@mail.gmail.com>
 <b85d3dee-9cb6-82f0-8304-da2f59fca5e2@treenet.co.nz>
 <CAFU=Cpe7Zi-bZ73gA91vDQR6_wyKcJc=UgpZwQC3nTFzCvZiVw@mail.gmail.com>
 <9c0e34b6-974a-cf07-1316-561af0b908a5@treenet.co.nz>
 <CAFU=CpfVrROQ3=rhH+6c1h3+M+UPQs3iT_vLGn7v8Tb3V1oHOQ@mail.gmail.com>
 <17c781aa-8768-f58b-2308-8120ecac7826@treenet.co.nz>
Message-ID: <1002ee32-504c-d481-0730-aad37006bc4c@gmail.com>

Yet another non-porn site: reddit.com

Let's check.

root @ cthulhu / # dig reddit.com

; <<>> DiG 9.6-ESV-R11-P6 <<>> reddit.com
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 21722
;; flags: qr rd ra; QUERY: 1, ANSWER: 15, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:
;reddit.com.                    IN      A

;; ANSWER SECTION:
reddit.com.             86398   IN      A       198.41.209.143
reddit.com.             86398   IN      A       198.41.208.138
reddit.com.             86398   IN      A       198.41.209.136
reddit.com.             86398   IN      A       198.41.209.139
reddit.com.             86398   IN      A       198.41.208.141
reddit.com.             86398   IN      A       198.41.208.137
reddit.com.             86398   IN      A       198.41.208.139
reddit.com.             86398   IN      A       198.41.208.143
reddit.com.             86398   IN      A       198.41.208.140
reddit.com.             86398   IN      A       198.41.209.137
reddit.com.             86398   IN      A       198.41.209.138
reddit.com.             86398   IN      A       198.41.209.140
reddit.com.             86398   IN      A       198.41.209.141
reddit.com.             86398   IN      A       198.41.208.142
reddit.com.             86398   IN      A       198.41.209.142

;; Query time: 0 msec
;; SERVER: 127.0.0.1#53(127.0.0.1)
;; WHEN: Mon Jun 27 20:32:22 ALMT 2016
;; MSG SIZE  rcvd: 268

root @ cthulhu / # ping reddit.com
reddit.com is alive

Seems all ok, right?

Well, le'ts check TCP connectivity:

Test with telnet:
root @ cthulhu / # telnet reddit.com 443
Trying 198.41.208.142...
Connected to reddit.com.
Escape character is '^]'.
^C^]
telnet>

I.e., tcp socket opens.

root @ cthulhu / # wget -S http://reddit.com
--2016-06-27 20:33:13--  http://reddit.com/
Connecting to 127.0.0.1:3128... connected.
Proxy request sent, awaiting response...
   HTTP/1.1 301 Moved Permanently
   Date: Mon, 27 Jun 2016 14:33:13 GMT
   Set-Cookie: __cfduid=d486371096ba68bc7f5ba663e5d723bf21467037993; 
expires=Tue, 27-Jun-17 14:33:13 GMT; path=/; domain=.reddit.com; HttpOnly
   Location: https://www.reddit.com/
   X-Content-Type-Options: nosniff
   Server: cloudflare-nginx
   CF-RAY: 2b999ce3a5854f08-DME
   Via: ICAP/1.0 cthulhu (C-ICAP/0.4.3 SquidClamav/Antivirus service )
   X-Cache: MISS from cthulhu
   X-Cache-Lookup: MISS from cthulhu:3128
   Transfer-Encoding: chunked
   Connection: keep-alive
Location: https://www.reddit.com/ [following]
--2016-06-27 20:33:13--  https://www.reddit.com/
Connecting to 127.0.0.1:3128... connected.

.... and long-long time waiting for unknown.......


Browser says: ERR_TIMED_OUT


How to explain this?

27.06.2016 20:32, Amos Jeffries ?????:
> [ Please reply to the mailing list I dont do private support except for
> paying customers. And you have not arranged for that in advance. ]
>
> On 28/06/2016 2:06 a.m., Adam Wright wrote:
>> - Ok, ISP will see my http traffic, but will the ISP see which websites I'm
>> surfing?
> If anyone can see HTTP traffic they can see what the traffic is about.
>
>
>> - Browser is using the proxy. But access.log only shows the websites which
>> the browser connected successfully. For example I see cisco.com which I
>> entered minutes ago for Yuri.
>>
>> 1467035091.072  15004 85.107.208.29 TCP_MISS/200 246 CONNECT
>> supportforums.cisco.com:443 yeni DIRECT/141.101.115.192
> The proxy log records every transaction through the proxy, at the time
> that transaction completed. Whether it succeeded or not. Anything that
> get started is prone to being logged.
>
> In the case above it was a CONNECT tunnel transferring some TLS wrapped
> protocol - probably HTTPS, SPDY or WebSockets on port 443. It took
> 15.004 seconds to do whatever took 246 bytes to transfer.
>
> So nothing in the log indicates either the browser is *not* using the
> proxy for those transactions, or they are still ongoing as far as Squid
> is concerned.
>
> It could be a case of browser using SPDY, QUICK or WebSockets protocols
> instead of HTTP inside a TLS tunnel, or directly without the proxy.
> Particularly if Chrome is involved.
>
> The case of ongoing connections is unfortunate. You can tune Squid
> timeouts somewhat to make the proxy more sensitive and do its failover
> to working destinations faster. But otherwise its a browser specific
> problem that can only be fixed by the browser.
>
> It might be that whatever was happening inside that tunnel above got
> stuck and timed out. To Squid the tunnel is opaque, so any type of error
> in there is strictly between the browser and server.
>
> The tiny size on that log entry makes me suspect its TLS handshake
> hanging and a 15sec timeout somewhere closes it down. If so the issue is
> not Squid, its whatever in the server or browser is causing the TLS to hang.
>
>> - Right now I'm using maxthon, it also says "Error code 101
>> (net::ERR_CONNECTION_RESET)" while I try to connect to those xxx websites.
>>
> That seems to mean the proxy is closing the connection. But that would
> mean the proxy is aware of it ending and record in the log what
> transaction finished with aborting the connection.
>
> If there no log record, thats a very strong sign that the browser is not
> using the proxy for that request.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160627/ce190e22/attachment.htm>

From yvoinov at gmail.com  Mon Jun 27 14:40:33 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 27 Jun 2016 20:40:33 +0600
Subject: [squid-users] Some websites doesn't work with squid anymore
In-Reply-To: <17c781aa-8768-f58b-2308-8120ecac7826@treenet.co.nz>
References: <CAFU=CpdbHOqSmozVfWBHV-jJEr2hat9h-aNKxF-EhtBx0Z6mQw@mail.gmail.com>
 <34616003-f25a-38d9-2e5f-ea0987b8cafa@treenet.co.nz>
 <CAFU=CpeiNxgafmvpLmC=5oTG06G5UcRLHFn2xTa6kiRMZChbkg@mail.gmail.com>
 <b85d3dee-9cb6-82f0-8304-da2f59fca5e2@treenet.co.nz>
 <CAFU=Cpe7Zi-bZ73gA91vDQR6_wyKcJc=UgpZwQC3nTFzCvZiVw@mail.gmail.com>
 <9c0e34b6-974a-cf07-1316-561af0b908a5@treenet.co.nz>
 <CAFU=CpfVrROQ3=rhH+6c1h3+M+UPQs3iT_vLGn7v8Tb3V1oHOQ@mail.gmail.com>
 <17c781aa-8768-f58b-2308-8120ecac7826@treenet.co.nz>
Message-ID: <67a13029-c2e3-a9a3-d266-6dbf040f976e@gmail.com>

Forgot about it: during testing reddit connectivity via squid squid 
itself got errors in cache.log:

2016/06/27 20:37:21 kid1| Error negotiating SSL on FD 7: 
error:00000000:lib(0):func(0):reason(0) (5/0/0)
2016/06/27 20:37:22 kid1| Error negotiating SSL on FD 10: 
error:00000000:lib(0):func(0):reason(0) (5/0/0)
2016/06/27 20:37:36 kid1| Error negotiating SSL on FD 7: 
error:00000000:lib(0):func(0):reason(0) (5/0/0)
2016/06/27 20:37:51 kid1| Error negotiating SSL on FD 7: 
error:00000000:lib(0):func(0):reason(0) (5/0/0)
2016/06/27 20:38:06 kid1| Error negotiating SSL on FD 7: 
error:00000000:lib(0):func(0):reason(0) (5/0/0)
2016/06/27 20:38:21 kid1| Error negotiating SSL on FD 7: 
error:00000000:lib(0):func(0):reason(0) (5/0/0)

Of course, this can be bug 4497. But it not visible to any excluding me. :)

27.06.2016 20:32, Amos Jeffries ?????:
> [ Please reply to the mailing list I dont do private support except for
> paying customers. And you have not arranged for that in advance. ]
>
> On 28/06/2016 2:06 a.m., Adam Wright wrote:
>> - Ok, ISP will see my http traffic, but will the ISP see which websites I'm
>> surfing?
> If anyone can see HTTP traffic they can see what the traffic is about.
>
>
>> - Browser is using the proxy. But access.log only shows the websites which
>> the browser connected successfully. For example I see cisco.com which I
>> entered minutes ago for Yuri.
>>
>> 1467035091.072  15004 85.107.208.29 TCP_MISS/200 246 CONNECT
>> supportforums.cisco.com:443 yeni DIRECT/141.101.115.192
> The proxy log records every transaction through the proxy, at the time
> that transaction completed. Whether it succeeded or not. Anything that
> get started is prone to being logged.
>
> In the case above it was a CONNECT tunnel transferring some TLS wrapped
> protocol - probably HTTPS, SPDY or WebSockets on port 443. It took
> 15.004 seconds to do whatever took 246 bytes to transfer.
>
> So nothing in the log indicates either the browser is *not* using the
> proxy for those transactions, or they are still ongoing as far as Squid
> is concerned.
>
> It could be a case of browser using SPDY, QUICK or WebSockets protocols
> instead of HTTP inside a TLS tunnel, or directly without the proxy.
> Particularly if Chrome is involved.
>
> The case of ongoing connections is unfortunate. You can tune Squid
> timeouts somewhat to make the proxy more sensitive and do its failover
> to working destinations faster. But otherwise its a browser specific
> problem that can only be fixed by the browser.
>
> It might be that whatever was happening inside that tunnel above got
> stuck and timed out. To Squid the tunnel is opaque, so any type of error
> in there is strictly between the browser and server.
>
> The tiny size on that log entry makes me suspect its TLS handshake
> hanging and a 15sec timeout somewhere closes it down. If so the issue is
> not Squid, its whatever in the server or browser is causing the TLS to hang.
>
>> - Right now I'm using maxthon, it also says "Error code 101
>> (net::ERR_CONNECTION_RESET)" while I try to connect to those xxx websites.
>>
> That seems to mean the proxy is closing the connection. But that would
> mean the proxy is aware of it ending and record in the log what
> transaction finished with aborting the connection.
>
> If there no log record, thats a very strong sign that the browser is not
> using the proxy for that request.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From renjop at gmail.com  Mon Jun 27 14:42:10 2016
From: renjop at gmail.com (Renato Jop)
Date: Mon, 27 Jun 2016 08:42:10 -0600
Subject: [squid-users] Skype Issues
In-Reply-To: <b3abc44d-7abf-aa9a-ebd3-a775c4a81854@gmail.com>
References: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>
 <8ff3bffe-47b7-8b0d-148d-cd3254344fd1@treenet.co.nz>
 <a30b3e16-5209-8240-359a-0cf736fe129f@gmail.com>
 <6e208cda-cb22-e48d-c0ee-0a6db04448e0@treenet.co.nz>
 <5153128f-ddd0-c134-22f1-158aa97575b4@gmail.com>
 <CAHha_zUDd__ZyMUCDQDcJ4KQouk++2OoZiEMptHY=Ty08D549A@mail.gmail.com>
 <b3abc44d-7abf-aa9a-ebd3-a775c4a81854@gmail.com>
Message-ID: <CAHha_zUDWQEFJjWgupS55gibNxSZ=gy--CfvQesYoPv6akciDQ@mail.gmail.com>

I removed the NO_SSLv2, NO_SSLv3 however, right before the
SSL3_GET_RECORD:wrong version number the SSL
routines:SSL23_GET_SERVER_HELLO:unknown protocol is shown.

Renato Jop

On Mon, Jun 27, 2016 at 8:29 AM, Yuri <yvoinov at gmail.com> wrote:

> Try to remove NO_SSLv2,NO_SSLv3 from options. SSLv2 already not supported
> everywhere, RC4/3DES is SSLv3 ciphers, so it can be confuse software. I.e.,
> you use custom ciphers/protocols combinations, which can lead issue.
>
> 27.06.2016 20:25, Renato Jop ?????:
>
> Thank you both for your valuable help.
> I've configured the tls-dh param with a strong Diffie-Hellman group (2048
> bits) and configured the cipher as Yuri specified and I was able to get
> pass the unknown cipher, however now I get a "SSL routines:SSL3_GET_
> RECORD:wrong version number". Here's the configuration I changed:
>  cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
> dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
> tls-dh=/usr/local/etc/squid/dhparams.pem
>
>
>
> Renato Jop
>
> On Sat, Jun 25, 2016 at 11:34 AM, Yuri Voinov <yvoinov at gmail.com> wrote:
>
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>>
>>
>>
>> 25.06.2016 23:09, Amos Jeffries ?????:
>> > On 26/06/2016 4:32 a.m., Yuri Voinov wrote:
>> >>
>> >> Amos, you are a wrong.
>> >>
>> >> No Squid-4. It's unstable and not ready for production. Whenever it's
>> >> features.
>> >
>> > So some beta software has bugs therefore nobody should ever use it for
>> > anything. I find that to be a strange and sad view of the world.
>> >
>> > Care to guess why I listed it as the last option amongst several?
>> >  Or why 4.0.11 exists as a beta still?
>> > It *is* an option for the mentioned problem(s) though whatever its
>> utility.
>> Agreed.
>> >
>> >
>> >
>> >>
>> >> Some time ago I have the same issue and know what happens exactly.
>> >>
>> >> Skype initial connection site uses RC4 cipher. Which is disabled in
>> most
>> >> squid's configuration.
>> >
>> > Your "know what happens exactly" differs from at least two other peoples
>> > debugging experiences with Skype.
>> >
>> > RC4 is on the hitlist for most of the big vendors for the past year or
>> > so. IIRC there were several Windows Updates to remove it and other
>> > broken bits from a lot of things over the past year.
>> > If Skype is still using RC4 it might be part of this problem.
>> I'm sure this is problem and this problem exists. MS do nothing to make
>> they sites/services more secure. BTW, MS Updates uses RC4 ciphers itself
>> this time. With strong siphers there is no way to setup WU via Squid.
>> I've spent much time to identify this problem in my setup and find
>> working workaround.
>>
>> Another part of problem is: MS often uses it's own self-signed roots,
>> which is exists in Windows, but nowhere else. And which has not
>> cross-signed by well-known root CA's. They think it make MS services
>> more secure. They wrong. But we can't do anything with it. So, this is
>> forced us to add self-signed MS roots to our Squid's CA bundles to
>> bump/splice.
>> >
>> >
>> >>
>> >> To make it works (as by as most M$ update sites) it's require simple
>> use
>> >> this cipher's suite:
>> >>
>> >> HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>> >>
>> >> That works for me in 5 SSL bumped setups. There is no matter which
>> squid
>> >> version installed.
>> >
>> > Thank you. Thats another option then. I'd rate that below trying the EC
>> > ciphers, and above library updates.
>> You are welcome.
>>
>> Just for information: MS has own IT infrastructure, with some strange
>> configured and non well-managed elements. I can't guarantee this
>> workaround will work everywhere or for every MS service.
>>
>> When I made my research, I've seen some strange security TLS
>> combinations on MS sites/services. I.e., for example, RC4+ECDSA+TLSv1.2.
>> Or, for example, RC4+MD5+TLSv1. And some similar. Very idiotic and
>> potentially dangerous combinations. And - they support ignores all
>> requests. As usual.
>>
>> To my regret, I can not order all of its users to abandon the use of
>> Windows. So far, in my infrastructure have machines with Windows XP.
>>
>> With this nothing can be done, it is necessary only to weaken the
>> security - for the sake of compatibility.
>> >
>> >
>> > Amos
>> > _______________________________________________
>> > squid-users mailing list
>> > squid-users at lists.squid-cache.org
>> > http://lists.squid-cache.org/listinfo/squid-users
>>
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v2
>>
>> iQEcBAEBCAAGBQJXbsC5AAoJENNXIZxhPexGiFoH/jrtimBNppF1uHpVTNwOO10z
>> yF2APMA56S8woNZzhUNjT8+oJFPrthnMoQFrqgicjS77SBAFp9KcOV+SxOKl9+sW
>> OdAHDPuCD7dGnKzAdFDR1YR7Vp5IpElP1rFO5rqKXeBc3iKjq65BfF+T6atHy6cS
>> 0VAaluvqvHQps2wVKoYxGURDf3Y2K0lJn+qF+s2CaBwEufhzgKSvG0aUIDqTfHfK
>> 3EMQTpPtlTqm+pcexR+oZM1WE1hlES1khOXs51fgo6puPryqWJiHGvO4EBEfWoXF
>> Skval2COzcdzMvC5jjfGbMEPNGNJrYUeq/KNgppRvE2wQJ+gCLYG317decKHty0=
>> =8BTp
>> -----END PGP SIGNATURE-----
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160627/dc672aac/attachment.htm>

From yvoinov at gmail.com  Mon Jun 27 14:43:55 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 27 Jun 2016 20:43:55 +0600
Subject: [squid-users] Skype Issues
In-Reply-To: <CAHha_zUDWQEFJjWgupS55gibNxSZ=gy--CfvQesYoPv6akciDQ@mail.gmail.com>
References: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>
 <8ff3bffe-47b7-8b0d-148d-cd3254344fd1@treenet.co.nz>
 <a30b3e16-5209-8240-359a-0cf736fe129f@gmail.com>
 <6e208cda-cb22-e48d-c0ee-0a6db04448e0@treenet.co.nz>
 <5153128f-ddd0-c134-22f1-158aa97575b4@gmail.com>
 <CAHha_zUDd__ZyMUCDQDcJ4KQouk++2OoZiEMptHY=Ty08D549A@mail.gmail.com>
 <b3abc44d-7abf-aa9a-ebd3-a775c4a81854@gmail.com>
 <CAHha_zUDWQEFJjWgupS55gibNxSZ=gy--CfvQesYoPv6akciDQ@mail.gmail.com>
Message-ID: <0b950720-77ad-170d-55d3-295f028dfa92@gmail.com>

Looks like your SSL library does not contain SSLv3 protocol support 
already, but site announce it.


27.06.2016 20:42, Renato Jop ?????:
> I removed the NO_SSLv2, NO_SSLv3 however, right before the 
> SSL3_GET_RECORD:wrong version number the SSL 
> routines:SSL23_GET_SERVER_HELLO:unknown protocol is shown.
>
> Renato Jop
>
> On Mon, Jun 27, 2016 at 8:29 AM, Yuri <yvoinov at gmail.com 
> <mailto:yvoinov at gmail.com>> wrote:
>
>     Try to remove NO_SSLv2,NO_SSLv3 from options. SSLv2 already not
>     supported everywhere, RC4/3DES is SSLv3 ciphers, so it can be
>     confuse software. I.e., you use custom ciphers/protocols
>     combinations, which can lead issue.
>
>
>     27.06.2016 20:25, Renato Jop ?????:
>>     Thank you both for your valuable help.
>>     I've configured the tls-dh param with a strong Diffie-Hellman
>>     group (2048 bits) and configured the cipher as Yuri specified and
>>     I was able to get pass the unknown cipher, however now I get a
>>     "SSL routines:SSL3_GET_RECORD:wrong version number". Here's the
>>     configuration I changed:
>>      cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>>     dhparams=/etc/dh-parameters.2048
>>     options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>>     tls-dh=/usr/local/etc/squid/dhparams.pem
>>
>>
>>
>>     Renato Jop
>>
>>     On Sat, Jun 25, 2016 at 11:34 AM, Yuri Voinov <yvoinov at gmail.com
>>     <mailto:yvoinov at gmail.com>> wrote:
>>
>>
>>         -----BEGIN PGP SIGNED MESSAGE-----
>>         Hash: SHA256
>>
>>
>>
>>         25.06.2016 <tel:25.06.2016> 23:09, Amos Jeffries ?????:
>>         > On 26/06/2016 4:32 a.m., Yuri Voinov wrote:
>>         >>
>>         >> Amos, you are a wrong.
>>         >>
>>         >> No Squid-4. It's unstable and not ready for production.
>>         Whenever it's
>>         >> features.
>>         >
>>         > So some beta software has bugs therefore nobody should ever
>>         use it for
>>         > anything. I find that to be a strange and sad view of the
>>         world.
>>         >
>>         > Care to guess why I listed it as the last option amongst
>>         several?
>>         >  Or why 4.0.11 exists as a beta still?
>>         > It *is* an option for the mentioned problem(s) though
>>         whatever its
>>         utility.
>>         Agreed.
>>         >
>>         >
>>         >
>>         >>
>>         >> Some time ago I have the same issue and know what happens
>>         exactly.
>>         >>
>>         >> Skype initial connection site uses RC4 cipher. Which is
>>         disabled in most
>>         >> squid's configuration.
>>         >
>>         > Your "know what happens exactly" differs from at least two
>>         other peoples
>>         > debugging experiences with Skype.
>>         >
>>         > RC4 is on the hitlist for most of the big vendors for the
>>         past year or
>>         > so. IIRC there were several Windows Updates to remove it
>>         and other
>>         > broken bits from a lot of things over the past year.
>>         > If Skype is still using RC4 it might be part of this problem.
>>         I'm sure this is problem and this problem exists. MS do
>>         nothing to make
>>         they sites/services more secure. BTW, MS Updates uses RC4
>>         ciphers itself
>>         this time. With strong siphers there is no way to setup WU
>>         via Squid.
>>         I've spent much time to identify this problem in my setup and
>>         find
>>         working workaround.
>>
>>         Another part of problem is: MS often uses it's own
>>         self-signed roots,
>>         which is exists in Windows, but nowhere else. And which has not
>>         cross-signed by well-known root CA's. They think it make MS
>>         services
>>         more secure. They wrong. But we can't do anything with it.
>>         So, this is
>>         forced us to add self-signed MS roots to our Squid's CA
>>         bundles to
>>         bump/splice.
>>         >
>>         >
>>         >>
>>         >> To make it works (as by as most M$ update sites) it's
>>         require simple use
>>         >> this cipher's suite:
>>         >>
>>         >>
>>         HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>>         >>
>>         >> That works for me in 5 SSL bumped setups. There is no
>>         matter which squid
>>         >> version installed.
>>         >
>>         > Thank you. Thats another option then. I'd rate that below
>>         trying the EC
>>         > ciphers, and above library updates.
>>         You are welcome.
>>
>>         Just for information: MS has own IT infrastructure, with some
>>         strange
>>         configured and non well-managed elements. I can't guarantee this
>>         workaround will work everywhere or for every MS service.
>>
>>         When I made my research, I've seen some strange security TLS
>>         combinations on MS sites/services. I.e., for example,
>>         RC4+ECDSA+TLSv1.2.
>>         Or, for example, RC4+MD5+TLSv1. And some similar. Very
>>         idiotic and
>>         potentially dangerous combinations. And - they support
>>         ignores all
>>         requests. As usual.
>>
>>         To my regret, I can not order all of its users to abandon the
>>         use of
>>         Windows. So far, in my infrastructure have machines with
>>         Windows XP.
>>
>>         With this nothing can be done, it is necessary only to weaken the
>>         security - for the sake of compatibility.
>>         >
>>         >
>>         > Amos
>>         > _______________________________________________
>>         > squid-users mailing list
>>         > squid-users at lists.squid-cache.org
>>         <mailto:squid-users at lists.squid-cache.org>
>>         > http://lists.squid-cache.org/listinfo/squid-users
>>
>>         -----BEGIN PGP SIGNATURE-----
>>         Version: GnuPG v2
>>
>>         iQEcBAEBCAAGBQJXbsC5AAoJENNXIZxhPexGiFoH/jrtimBNppF1uHpVTNwOO10z
>>         yF2APMA56S8woNZzhUNjT8+oJFPrthnMoQFrqgicjS77SBAFp9KcOV+SxOKl9+sW
>>         OdAHDPuCD7dGnKzAdFDR1YR7Vp5IpElP1rFO5rqKXeBc3iKjq65BfF+T6atHy6cS
>>         0VAaluvqvHQps2wVKoYxGURDf3Y2K0lJn+qF+s2CaBwEufhzgKSvG0aUIDqTfHfK
>>         3EMQTpPtlTqm+pcexR+oZM1WE1hlES1khOXs51fgo6puPryqWJiHGvO4EBEfWoXF
>>         Skval2COzcdzMvC5jjfGbMEPNGNJrYUeq/KNgppRvE2wQJ+gCLYG317decKHty0=
>>         =8BTp
>>         -----END PGP SIGNATURE-----
>>
>>
>>         _______________________________________________
>>         squid-users mailing list
>>         squid-users at lists.squid-cache.org
>>         <mailto:squid-users at lists.squid-cache.org>
>>         http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160627/220b7033/attachment.htm>

From yvoinov at gmail.com  Mon Jun 27 14:55:05 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 27 Jun 2016 20:55:05 +0600
Subject: [squid-users] Some websites doesn't work with squid anymore
In-Reply-To: <67a13029-c2e3-a9a3-d266-6dbf040f976e@gmail.com>
References: <CAFU=CpdbHOqSmozVfWBHV-jJEr2hat9h-aNKxF-EhtBx0Z6mQw@mail.gmail.com>
 <34616003-f25a-38d9-2e5f-ea0987b8cafa@treenet.co.nz>
 <CAFU=CpeiNxgafmvpLmC=5oTG06G5UcRLHFn2xTa6kiRMZChbkg@mail.gmail.com>
 <b85d3dee-9cb6-82f0-8304-da2f59fca5e2@treenet.co.nz>
 <CAFU=Cpe7Zi-bZ73gA91vDQR6_wyKcJc=UgpZwQC3nTFzCvZiVw@mail.gmail.com>
 <9c0e34b6-974a-cf07-1316-561af0b908a5@treenet.co.nz>
 <CAFU=CpfVrROQ3=rhH+6c1h3+M+UPQs3iT_vLGn7v8Tb3V1oHOQ@mail.gmail.com>
 <17c781aa-8768-f58b-2308-8120ecac7826@treenet.co.nz>
 <67a13029-c2e3-a9a3-d266-6dbf040f976e@gmail.com>
Message-ID: <9c72bf65-e391-c4e1-9999-49278ba5b940@gmail.com>

And finally:

root @ cthulhu / # ping s.yimg.com
s.yimg.com is alive
root @ cthulhu / # telnet s.yimg.com 443
Trying 66.196.65.111...
Connected to s.gycs.b.yahoodns.net.
Escape character is '^]'.
^]
telnet> quit
Connection to s.gycs.b.yahoodns.net closed.

root @ cthulhu / # wget -S s.yimg.com
--2016-06-27 20:51:22--  http://s.yimg.com/
Connecting to 127.0.0.1:3128... connected.
Proxy request sent, awaiting response...
   HTTP/1.1 404 Not Found
   Date: Mon, 27 Jun 2016 14:51:22 GMT
   Via: http/1.1 l1.ycs.ams.yahoo.com (ApacheTrafficServer [c s f ])
   Server: ATS
   Cache-Control: no-store
   Content-Type: text/html
   Content-Language: en
   Y-Trace: 
BAEAQAAAAACLMdgmMGHAiwAAAAAAAAAAhCR03RQcuP8AAAAAAAAAAAAFNkOnXjC6AAU2Q6deMogWmZJXAAAAAA--
   Content-Length: 2823
   X-Cache: MISS from cthulhu
   X-Cache-Lookup: MISS from cthulhu:3128
   Connection: keep-alive
2016-06-27 20:51:22 ERROR 404: Not Found.

Aha! Using wget we can connect!

But browser pointed to www.yahoo.com shown only HTML page without any 
image, JS or CSS.

Look at this shit: https://i1.someimage.com/7SX2FRB.png

Yes, ISP can block sites. But only yimg.com and not whole yahoo? :) Ok, 
let's disable squid - viola! All opens right now like charm.

Something wrong with squid, right?


27.06.2016 20:40, Yuri ?????:
> Forgot about it: during testing reddit connectivity via squid squid 
> itself got errors in cache.log:
>
> 2016/06/27 20:37:21 kid1| Error negotiating SSL on FD 7: 
> error:00000000:lib(0):func(0):reason(0) (5/0/0)
> 2016/06/27 20:37:22 kid1| Error negotiating SSL on FD 10: 
> error:00000000:lib(0):func(0):reason(0) (5/0/0)
> 2016/06/27 20:37:36 kid1| Error negotiating SSL on FD 7: 
> error:00000000:lib(0):func(0):reason(0) (5/0/0)
> 2016/06/27 20:37:51 kid1| Error negotiating SSL on FD 7: 
> error:00000000:lib(0):func(0):reason(0) (5/0/0)
> 2016/06/27 20:38:06 kid1| Error negotiating SSL on FD 7: 
> error:00000000:lib(0):func(0):reason(0) (5/0/0)
> 2016/06/27 20:38:21 kid1| Error negotiating SSL on FD 7: 
> error:00000000:lib(0):func(0):reason(0) (5/0/0)
>
> Of course, this can be bug 4497. But it not visible to any excluding 
> me. :)
>
> 27.06.2016 20:32, Amos Jeffries ?????:
>> [ Please reply to the mailing list I dont do private support except for
>> paying customers. And you have not arranged for that in advance. ]
>>
>> On 28/06/2016 2:06 a.m., Adam Wright wrote:
>>> - Ok, ISP will see my http traffic, but will the ISP see which 
>>> websites I'm
>>> surfing?
>> If anyone can see HTTP traffic they can see what the traffic is about.
>>
>>
>>> - Browser is using the proxy. But access.log only shows the websites 
>>> which
>>> the browser connected successfully. For example I see cisco.com which I
>>> entered minutes ago for Yuri.
>>>
>>> 1467035091.072  15004 85.107.208.29 TCP_MISS/200 246 CONNECT
>>> supportforums.cisco.com:443 yeni DIRECT/141.101.115.192
>> The proxy log records every transaction through the proxy, at the time
>> that transaction completed. Whether it succeeded or not. Anything that
>> get started is prone to being logged.
>>
>> In the case above it was a CONNECT tunnel transferring some TLS wrapped
>> protocol - probably HTTPS, SPDY or WebSockets on port 443. It took
>> 15.004 seconds to do whatever took 246 bytes to transfer.
>>
>> So nothing in the log indicates either the browser is *not* using the
>> proxy for those transactions, or they are still ongoing as far as Squid
>> is concerned.
>>
>> It could be a case of browser using SPDY, QUICK or WebSockets protocols
>> instead of HTTP inside a TLS tunnel, or directly without the proxy.
>> Particularly if Chrome is involved.
>>
>> The case of ongoing connections is unfortunate. You can tune Squid
>> timeouts somewhat to make the proxy more sensitive and do its failover
>> to working destinations faster. But otherwise its a browser specific
>> problem that can only be fixed by the browser.
>>
>> It might be that whatever was happening inside that tunnel above got
>> stuck and timed out. To Squid the tunnel is opaque, so any type of error
>> in there is strictly between the browser and server.
>>
>> The tiny size on that log entry makes me suspect its TLS handshake
>> hanging and a 15sec timeout somewhere closes it down. If so the issue is
>> not Squid, its whatever in the server or browser is causing the TLS 
>> to hang.
>>
>>> - Right now I'm using maxthon, it also says "Error code 101
>>> (net::ERR_CONNECTION_RESET)" while I try to connect to those xxx 
>>> websites.
>>>
>> That seems to mean the proxy is closing the connection. But that would
>> mean the proxy is aware of it ending and record in the log what
>> transaction finished with aborting the connection.
>>
>> If there no log record, thats a very strong sign that the browser is not
>> using the proxy for that request.
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>



From cbidwell at usgs.gov  Mon Jun 27 15:01:09 2016
From: cbidwell at usgs.gov (Bidwell, Christopher)
Date: Mon, 27 Jun 2016 09:01:09 -0600
Subject: [squid-users] Squid question with letsencrypt
In-Reply-To: <70332e91-3b59-1d02-4ade-f215d2d99957@treenet.co.nz>
References: <CAJN-FKmSPS2xo+RMMYjNsUa3hqnd_C++q4cVwjsXezVrCzSaFw@mail.gmail.com>
 <70332e91-3b59-1d02-4ade-f215d2d99957@treenet.co.nz>
Message-ID: <CAJN-FKmDMq6-2S77tW2BZpvY9afq5JqjkVpg8R2ENu+Zeq8XPA@mail.gmail.com>

Thanks so much for your help on this.  So I'm changing it up a little bit.
Disregard the backend server certificates.  I'm using 3 frontend servers
but I want to use LetsEncrypt to create the SAN certificate for them. Is
the concept the same with how you described this?  Just as I mentioned, one
of the servers is running the letsencrypt process which communicates with
letsencrypt and then tries to resolve all of the dns names and
correspondingly checks the /.well-known/acme-challenge directory.  This is
what I've got in my config:

# LetsEncrypt Cache-peer-access
cache_peer dev02-server.com parent 80 0 no-query originserver default
name=dev02-server_80
cache_peer dev02-server01.com parent 80 0 no-query originserver default
 name=dev02-server01_80
cache_peer dev02-server02.com parent 80 0 no-query originserver default
 name=dev02-server02_80

acl acme urlpath_regex ^/.well-known/acme-challenge

cache_peer_access dev02-server_80 allow acme
cache_peer_access dev02-server01_80 deny acme
cache_peer_access dev02-server02_80 deny acme

Where dev02-server_80 is running letsencrypt and the other two are the
squid servers.

What I'm expecting to do here is a wget (to test this) on
dev02-server-main.com which resolves to the IP's of server01.com and
server02.com.  I'm still getting an error 403 Forbidden.


On Sat, Jun 25, 2016 at 12:51 AM, Amos Jeffries <squid3 at treenet.co.nz>
wrote:

> On 25/06/2016 4:48 a.m., Bidwell, Christopher wrote:
> > Hi all,
> >
> > I'm very new to squid and we are wanting to implement letsencrypt for our
> > ssl certificates.
> >
> > Here's the scenario:
> >
> > We've got several frontend servers running squid that are caching from
> the
> > backend systems.
>
> Ok,
>
> >
> > i.e. test.com -> 10.0.0.1, 10.0.1.1, 10.0.2.1 (all physically separated
> > from one another)
> >
>
> Ok,
>
> > Each internal server also has its own dns name:
> >
> > web1.test.com -> 10.0.0.1
> > web2.test.com -> 10.0.1.1
> > web3.test.com -> 10.0.2.1
> >
> > Note that these are all public. Using 10. as examples.
>
> Ok, but dangerous. That allows the frontend to be bypassed whenever a
> client wants. So you will need to ensure security to the backend stays
> in sync with the frontend. If you don't have to, its best to avoid that
> trouble and filter everything consistently through the frontend.
>
> That also allows the backends to avoid public CAs like LetsEncrypt
> entirely. You can use a single custom CA exclusively for the
> frontend<->backend traffic and have much better security settings on
> those internal links since you no longer have to worry about random
> visitors capabilities.
>
> >
> > I'd like to create a SAN certificate naming the 3 internal systems in
> > addition to the public name:
> >
> > test.com, web1.test.com, web2.test.com, and web3.test.com.
> >
> > On the letsencrypt forum they said that I could do a HTTP 301 redirect
> from
> > the squid servers to the backend letsencrypt server where any match for:
> >  /.well-known/acme-challenge/* would redirect with an HTTP 301 to that
> > backend letsencrypt server.  I'm not sure how to do this and the squid
> > documentation is not easy to comprehend.
> >
> > Let me know if this isn't clear how I've explained this.
> >
>
> If LetsEncrypt are contacting web1 for example. They should be going to
> the backend directly. Since http://web1.test.* is not a frontend request.
>
> Whatever server is performing the LetsEncrypt for the frontend needs to
> know its doing it for the generic domain as well as itself. Squid is not
> a web server, so you need to nominate a backend to do that (could be a
> new one just of LetsEncrypt stuff).
>
> For example doing it on web1 would mean fitting these lines into your
> existing config (this order, but not necesarily together like this):
>
>  acl acme urlpath_regex ^/.well-known/acme-challenge
>  cache_peer_access web1 allow acme
>  cache_peer_access web2 deny acme
>  cache_peer_access web3 deny acme
>
> No "redirect" involved. Just tell Squid that server is where those URL
> are handled.
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160627/da9e1fdf/attachment.htm>

From ozgurbtr at gmail.com  Mon Jun 27 15:01:38 2016
From: ozgurbtr at gmail.com (Ozgur Batur)
Date: Mon, 27 Jun 2016 18:01:38 +0300
Subject: [squid-users] flickr.com redirect error
In-Reply-To: <3be92fc1-3cfc-cf51-82e0-9d34aa8ca0cd@treenet.co.nz>
References: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
 <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>
 <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>
 <VI1PR04MB1359499FE2D9A57B3C0C33638F2E0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <CAAFc9FhiXeMc=J5SECc-MjF4hBDjXRZyS9zDtgMPjSz_iMEkKw@mail.gmail.com>
 <a97ea350-c237-2859-7c2a-cbf4d552ad5c@treenet.co.nz>
 <VI1PR04MB13599620DC40C00E14432EE88F2F0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <950cb95d-5e47-d51c-4ab3-d67d5437364e@treenet.co.nz>
 <CAAFc9FiDM8_13Zq_OD37FdY_hm6hb431OREbZVwdyaeYxJRjDA@mail.gmail.com>
 <3f174bff-49bd-1acf-7bb5-3e52c3dccd51@treenet.co.nz>
 <CAAFc9Fh21bXOc8=YhDqcOvu3XiNNPpwDWhK30=Q5XgtmJjuv9g@mail.gmail.com>
 <3be92fc1-3cfc-cf51-82e0-9d34aa8ca0cd@treenet.co.nz>
Message-ID: <CAAFc9Fh+wdNT5uKvwgHp_oLGNPSBLnfyhjUpc_Pi7K=bizbk6A@mail.gmail.com>

Browser i used to test runs on same machine with squid,  i changed it to
explicit mode(no intercept - I set proxy ip in browser) during my attempts
for ssl interception. Sorry I forgot to mention that in my last post of
logs. So xff localhost is normal I guess. Here is the request log with
 port info:

----------

2016/06/27 15:49:40.909 kid1| 11,2| http.cc(2234) sendRequest: HTTP Server
local=10.100.136.56:47772 remote=188.125.93.100:443 FD 47 flags=1

2016/06/27 15:49:40.909 kid1| 11,2| http.cc(2235) sendRequest: HTTP Server
REQUEST:

---------

GET / HTTP/1.1

Accept:
text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8

Upgrade-Insecure-Requests: 1

User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like
Gecko) Ubuntu Chromium/50.0.2661.102 Chrome/50.0.2661.102 Safari/537.36

Accept-Encoding: gzip, deflate, sdch

Accept-Language: tr,en-US;q=0.8,en;q=0.6

..

Host: www.flickr.com

Via: 1.1 ubuntuozgen (squid/3.5.19)

Surrogate-Capability: ubuntuozgen="Surrogate/1.0 ESI/1.0"

X-Forwarded-For: ::1

Cache-Control: max-age=259200

Connection: keep-alive


On Mon, Jun 27, 2016 at 2:27 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 27/06/2016 11:01 p.m., Ozgur Batur wrote:
> > Yes that is much easier, thank you.
> >
> > Rafaels line is response header, I received the same. Here is the related
> > cachelog:
> >
>
> What is the content of the line above this one. With the IP:port details ?
>
> > 2016/06/27 13:52:49.194 kid1| 11,2| http.cc(2235) sendRequest: HTTP
> Server
> > REQUEST:
> > GET / HTTP/1.1
> > Accept:
> >
> text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
> > Upgrade-Insecure-Requests: 1
> > User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML,
> like
> > Gecko) Ubuntu Chromium/50.0.2661.102 Chrome/50.0.2661.102 Safari/537.36
> > Accept-Encoding: gzip, deflate, sdch
> > Accept-Language: tr,en-US;q=0.8,en;q=0.6
> > ...
> > Host: www.flickr.com
> > Via: 1.1 ubuntuozgen (squid/3.5.19)
> > Surrogate-Capability: ubuntuozgen="Surrogate/1.0 ESI/1.0"
> > X-Forwarded-For: ::1
>
> You said this was using interception. But Squid XFF is telling Yahoo
> that its receiving localhost traffic.
>
> Try "forwarded_for transparent" in your squid.conf, and find out why
> that ::1 is happening on an intercepted proxy. There may be a bug in
> your NAT or routing configuration.
>
>
> > Cache-Control: max-age=0
> > Connection: keep-alive
> >
> > ..
> > 2016/06/27 13:52:49.477 kid1| 11,2| http.cc(751) processReplyHeader: HTTP
> > Server REPLY:
> > ---------
> > HTTP/1.1 301 Moved Permanently
> > X-Frame-Options: SAMEORIGIN
> > X-Content-Type-Options: nosniff
> > X-XSS-Protection: 1; mode=block
> > X-Served-By: pprd1-node552-lh1.manhattan.bf1.yahoo.com
> > X-Instance: flickr.v1.production.manhattan.bf1.yahoo.com
> > Cache-Control: no-cache, max-age=0, must-revalidate, no-store
> > Pragma: no-cache
> > X-Request-Id: 36e709a2
> > Location: https://www.flickr.com/
> > Vary: Accept
> > Content-Type: text/html; charset=utf-8
> > Content-Length: 102
> > Server: ATS
> > Date: Mon, 27 Jun 2016 10:52:40 GMT
> > Age: 0
> > Via: http/1.1 fts111.flickr.bf1.yahoo.com (ApacheTrafficServer [cMs f
> ]),
> > http/1.1 r11.ycpi.dea.yahoo.net (ApacheTrafficServer [cMs f ])
> > Connection: keep-alive
> > ..
> >
> > And this repeats on and on. As I understand disabling Via header is an
> > acceptable solution. If I could disable the header only for problematic
> > domains that would be better of course.
>
> Okay. Unfortunately not possible. If that forwarded_for change works it
> would be better than disabling Via.
>
> Amos
>
>


-- 
H ?zg?r Batur
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160627/61131063/attachment.htm>

From carlopmart at gmail.com  Mon Jun 27 15:02:01 2016
From: carlopmart at gmail.com (C. L. Martinez)
Date: Mon, 27 Jun 2016 15:02:01 +0000
Subject: [squid-users] Cipher suites errors
In-Reply-To: <27ec0452-3624-0ee8-2442-3058c036f2b9@gmail.com>
References: <20160627133008.GB9391@beagle.bcn.sia.es>
 <27ec0452-3624-0ee8-2442-3058c036f2b9@gmail.com>
Message-ID: <20160627150201.GC9391@beagle.bcn.sia.es>

Thanks Yuri.

On Mon 27.Jun'16 at 19:39:20 +0600, Yuri wrote:
> This is GOST-based ciphers included in LibreSSL. Don't worry about it.
> 
> 
> 27.06.2016 19:30, C. L. Martinez ?????:
> > Hi all,
> > 
> >   After some tunning to configure my squid's host with ssl_bump and intermediate CA (many thanks Yuri), I have tested my setup against https://www.ssllabs.com and https://howsmyssl.com and both sites returns me the following error:
> > 
> > Some unknown cipher suite: 0xff85 (SSLLabs says UNKNOWN (0xff85)   WEAK)
> > Some unknown cipher suite: 0x0081
> > 
> >   My relevant config is:
> > 
> > sslproxy_options SINGLE_DH_USE,SINGLE_ECDH_USE
> > sslproxy_cipher HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> > https_port 127.0.0.1:5145 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/certs/server.crt \
> >          key=/etc/squid/certs/server.key tls-dh=prime256v1:/etc/squid/certs/dhparam.pem \
> >                  options=SINGLE_DH_USE,SINGLE_ECDH_USE cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> > 
> >   Am I doing something wrong?? I am using squid's wiki suggested config ...
> > 
> > Thanks.
> > 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Greetings,
C. L. Martinez


From renjop at gmail.com  Mon Jun 27 15:36:38 2016
From: renjop at gmail.com (Renato Jop)
Date: Mon, 27 Jun 2016 09:36:38 -0600
Subject: [squid-users] Skype Issues
In-Reply-To: <0b950720-77ad-170d-55d3-295f028dfa92@gmail.com>
References: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>
 <8ff3bffe-47b7-8b0d-148d-cd3254344fd1@treenet.co.nz>
 <a30b3e16-5209-8240-359a-0cf736fe129f@gmail.com>
 <6e208cda-cb22-e48d-c0ee-0a6db04448e0@treenet.co.nz>
 <5153128f-ddd0-c134-22f1-158aa97575b4@gmail.com>
 <CAHha_zUDd__ZyMUCDQDcJ4KQouk++2OoZiEMptHY=Ty08D549A@mail.gmail.com>
 <b3abc44d-7abf-aa9a-ebd3-a775c4a81854@gmail.com>
 <CAHha_zUDWQEFJjWgupS55gibNxSZ=gy--CfvQesYoPv6akciDQ@mail.gmail.com>
 <0b950720-77ad-170d-55d3-295f028dfa92@gmail.com>
Message-ID: <CAHha_zX+oDsFT7b6qfirB17v0C-iDMq7p1XdLG4z=++6V5_JeA@mail.gmail.com>

Is there a way to verify that the SSL library doesn't support SSLv3?

Renato Jop

On Mon, Jun 27, 2016 at 8:43 AM, Yuri <yvoinov at gmail.com> wrote:

> Looks like your SSL library does not contain SSLv3 protocol support
> already, but site announce it.
>
> 27.06.2016 20:42, Renato Jop ?????:
>
> I removed the NO_SSLv2, NO_SSLv3 however, right before the SSL3_GET_
> RECORD:wrong version number the SSL
> routines:SSL23_GET_SERVER_HELLO:unknown protocol is shown.
>
> Renato Jop
>
> On Mon, Jun 27, 2016 at 8:29 AM, Yuri <yvoinov at gmail.com> wrote:
>
>> Try to remove NO_SSLv2,NO_SSLv3 from options. SSLv2 already not supported
>> everywhere, RC4/3DES is SSLv3 ciphers, so it can be confuse software. I.e.,
>> you use custom ciphers/protocols combinations, which can lead issue.
>>
>> 27.06.2016 20:25, Renato Jop ?????:
>>
>> Thank you both for your valuable help.
>> I've configured the tls-dh param with a strong Diffie-Hellman group (2048
>> bits) and configured the cipher as Yuri specified and I was able to get
>> pass the unknown cipher, however now I get a "SSL routines:SSL3_GET_
>> RECORD:wrong version number". Here's the configuration I changed:
>>  cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>> dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>> tls-dh=/usr/local/etc/squid/dhparams.pem
>>
>>
>>
>> Renato Jop
>>
>> On Sat, Jun 25, 2016 at 11:34 AM, Yuri Voinov < <yvoinov at gmail.com>
>> yvoinov at gmail.com> wrote:
>>
>>>
>>> -----BEGIN PGP SIGNED MESSAGE-----
>>> Hash: SHA256
>>>
>>>
>>>
>>> 25.06.2016 23:09, Amos Jeffries ?????:
>>> > On 26/06/2016 4:32 a.m., Yuri Voinov wrote:
>>> >>
>>> >> Amos, you are a wrong.
>>> >>
>>> >> No Squid-4. It's unstable and not ready for production. Whenever it's
>>> >> features.
>>> >
>>> > So some beta software has bugs therefore nobody should ever use it for
>>> > anything. I find that to be a strange and sad view of the world.
>>> >
>>> > Care to guess why I listed it as the last option amongst several?
>>> >  Or why 4.0.11 exists as a beta still?
>>> > It *is* an option for the mentioned problem(s) though whatever its
>>> utility.
>>> Agreed.
>>> >
>>> >
>>> >
>>> >>
>>> >> Some time ago I have the same issue and know what happens exactly.
>>> >>
>>> >> Skype initial connection site uses RC4 cipher. Which is disabled in
>>> most
>>> >> squid's configuration.
>>> >
>>> > Your "know what happens exactly" differs from at least two other
>>> peoples
>>> > debugging experiences with Skype.
>>> >
>>> > RC4 is on the hitlist for most of the big vendors for the past year or
>>> > so. IIRC there were several Windows Updates to remove it and other
>>> > broken bits from a lot of things over the past year.
>>> > If Skype is still using RC4 it might be part of this problem.
>>> I'm sure this is problem and this problem exists. MS do nothing to make
>>> they sites/services more secure. BTW, MS Updates uses RC4 ciphers itself
>>> this time. With strong siphers there is no way to setup WU via Squid.
>>> I've spent much time to identify this problem in my setup and find
>>> working workaround.
>>>
>>> Another part of problem is: MS often uses it's own self-signed roots,
>>> which is exists in Windows, but nowhere else. And which has not
>>> cross-signed by well-known root CA's. They think it make MS services
>>> more secure. They wrong. But we can't do anything with it. So, this is
>>> forced us to add self-signed MS roots to our Squid's CA bundles to
>>> bump/splice.
>>> >
>>> >
>>> >>
>>> >> To make it works (as by as most M$ update sites) it's require simple
>>> use
>>> >> this cipher's suite:
>>> >>
>>> >> HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>>> >>
>>> >> That works for me in 5 SSL bumped setups. There is no matter which
>>> squid
>>> >> version installed.
>>> >
>>> > Thank you. Thats another option then. I'd rate that below trying the EC
>>> > ciphers, and above library updates.
>>> You are welcome.
>>>
>>> Just for information: MS has own IT infrastructure, with some strange
>>> configured and non well-managed elements. I can't guarantee this
>>> workaround will work everywhere or for every MS service.
>>>
>>> When I made my research, I've seen some strange security TLS
>>> combinations on MS sites/services. I.e., for example, RC4+ECDSA+TLSv1.2.
>>> Or, for example, RC4+MD5+TLSv1. And some similar. Very idiotic and
>>> potentially dangerous combinations. And - they support ignores all
>>> requests. As usual.
>>>
>>> To my regret, I can not order all of its users to abandon the use of
>>> Windows. So far, in my infrastructure have machines with Windows XP.
>>>
>>> With this nothing can be done, it is necessary only to weaken the
>>> security - for the sake of compatibility.
>>> >
>>> >
>>> > Amos
>>> > _______________________________________________
>>> > squid-users mailing list
>>> > squid-users at lists.squid-cache.org
>>> > http://lists.squid-cache.org/listinfo/squid-users
>>>
>>> -----BEGIN PGP SIGNATURE-----
>>> Version: GnuPG v2
>>>
>>> iQEcBAEBCAAGBQJXbsC5AAoJENNXIZxhPexGiFoH/jrtimBNppF1uHpVTNwOO10z
>>> yF2APMA56S8woNZzhUNjT8+oJFPrthnMoQFrqgicjS77SBAFp9KcOV+SxOKl9+sW
>>> OdAHDPuCD7dGnKzAdFDR1YR7Vp5IpElP1rFO5rqKXeBc3iKjq65BfF+T6atHy6cS
>>> 0VAaluvqvHQps2wVKoYxGURDf3Y2K0lJn+qF+s2CaBwEufhzgKSvG0aUIDqTfHfK
>>> 3EMQTpPtlTqm+pcexR+oZM1WE1hlES1khOXs51fgo6puPryqWJiHGvO4EBEfWoXF
>>> Skval2COzcdzMvC5jjfGbMEPNGNJrYUeq/KNgppRvE2wQJ+gCLYG317decKHty0=
>>> =8BTp
>>> -----END PGP SIGNATURE-----
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160627/78c06b3e/attachment.htm>

From ozgurbtr at gmail.com  Mon Jun 27 16:23:29 2016
From: ozgurbtr at gmail.com (Ozgur Batur)
Date: Mon, 27 Jun 2016 19:23:29 +0300
Subject: [squid-users] Websocket content adaptation
Message-ID: <CAAFc9Fg4jNed1kZHe-0p2EbKHTQEP=y3eZhsTvy+mkvWC7Xkuw@mail.gmail.com>

Hi,

ICAP handles plain HTTP very well but it is not possible to filter/change
or even log content of websocket communication after websocket upgrade over
HTTP as far as I know. Is there any plan or interest in developing some
capability for Squid to control websocket communication content?

There is no defined request/response protocol since websocket is basically
a socket but regexp matching in incoming and outgoing content(json,
xml,raw) with URL and client metadata info may have some application like
data leak prevention or achieving in corporate environment.

Thanks,

Ozgur
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160627/7d495b15/attachment.htm>

From rousskov at measurement-factory.com  Mon Jun 27 16:57:09 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 27 Jun 2016 10:57:09 -0600
Subject: [squid-users] Websocket content adaptation
In-Reply-To: <CAAFc9Fg4jNed1kZHe-0p2EbKHTQEP=y3eZhsTvy+mkvWC7Xkuw@mail.gmail.com>
References: <CAAFc9Fg4jNed1kZHe-0p2EbKHTQEP=y3eZhsTvy+mkvWC7Xkuw@mail.gmail.com>
Message-ID: <57715AE5.8090904@measurement-factory.com>

On 06/27/2016 10:23 AM, Ozgur Batur wrote:

> ICAP handles plain HTTP very well but it is not possible to
> filter/change or even log content of websocket communication after
> websocket upgrade over HTTP as far as I know. Is there any plan or
> interest in developing some capability for Squid to control websocket
> communication content? 

There is interest but no specific plan or sponsor.


> There is no defined request/response protocol since websocket is
> basically a socket but regexp matching in incoming and outgoing
> content(json, xml,raw) with URL and client metadata info may have some
> application like data leak prevention or achieving in corporate environment.

I am not sure regex would be a good idea in general, but passing
tunneled traffic to eCAP/ICAP services is indeed useful in several
environments, including WebSocket tunnels. The adaptation service will
decide whether to use regex or something else to match raw data. Some
existing services simply log (or relay/replay via TCP) received traffic
without analyzing it so regex is just one of many possibilities here.

FWIW, several things are needed to move forward, including:

1. Adequate development time and skills (or sponsorship to pay for
   them). The development of an essentially new adaptation vectoring
   point is not a trivial project.

2. A specific proposal on how to map raw/tunnel data to HTTP messages
   that eCAP and ICAP interfaces expect. The biggest difficulty here
   may be mapping server-speaks-first protocols.

3. A project lead to organize/manage the project and guide the results
   through the Squid Project review. This person could be the
   primary developer and/or the specs writer, but does not have to be.

Alex.



From michael.pelletier at palmbeachschools.org  Mon Jun 27 17:06:17 2016
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Mon, 27 Jun 2016 13:06:17 -0400
Subject: [squid-users] Good Home Cable Modem Blacklist
Message-ID: <CAEnCSG4XeAdHk9VzF+Pmwz9XHcRkwCqowynRDEzByrFbU+Y--g@mail.gmail.com>

Hello,
Does anyone know of a good blacklist of home cable modems?

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160627/e598491f/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Jun 27 17:21:26 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 27 Jun 2016 19:21:26 +0200
Subject: [squid-users] Good Home Cable Modem Blacklist
In-Reply-To: <CAEnCSG4XeAdHk9VzF+Pmwz9XHcRkwCqowynRDEzByrFbU+Y--g@mail.gmail.com>
References: <CAEnCSG4XeAdHk9VzF+Pmwz9XHcRkwCqowynRDEzByrFbU+Y--g@mail.gmail.com>
Message-ID: <201606271921.26414.Antony.Stone@squid.open.source.it>

On Monday 27 June 2016 at 19:06:17, Michael Pelletier wrote:

> Does anyone know of a good blacklist of home cable modems?

I don't think you'll get any list of *home* cable modems, which excludes small 
business connections as well.

Also, with a lot of ISPs, I don't think you'll get a list of *cable* modems, 
separate from DSL modems; many of them use combined DHCP pools for both.

However, depending on what your reason for needing such a list is, you might 
find that a sufficiently effective solution is to do a reverse DNS lookup on an IP 
address and look for any of:

	cable
	dsl
	dynamic
	pool

as discrete words (often in a format such as "cable-79-35-42-183.isp.com").


Hope that helps,


Antony.

-- 
Is it venison for dinner again?  Oh deer.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From webmaster at squidblacklist.org  Mon Jun 27 17:27:31 2016
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Mon, 27 Jun 2016 12:27:31 -0500
Subject: [squid-users] Good Home Cable Modem Blacklist
In-Reply-To: <201606271921.26414.Antony.Stone@squid.open.source.it>
References: <CAEnCSG4XeAdHk9VzF+Pmwz9XHcRkwCqowynRDEzByrFbU+Y--g@mail.gmail.com>
 <201606271921.26414.Antony.Stone@squid.open.source.it>
Message-ID: <64339e45-023b-53a6-ddce-6a020e5f278f@squidblacklist.org>

It would also be trivial to gather up all known ip ranges issued to 
consumer cable isps and convert them to a domain name acl compatible format.

I will put it on the whiteboard.


On 6/27/2016 12:21 PM, Antony Stone wrote:
> On Monday 27 June 2016 at 19:06:17, Michael Pelletier wrote:
>
>> Does anyone know of a good blacklist of home cable modems?
> I don't think you'll get any list of *home* cable modems, which excludes small
> business connections as well.
>
> Also, with a lot of ISPs, I don't think you'll get a list of *cable* modems,
> separate from DSL modems; many of them use combined DHCP pools for both.
>
> However, depending on what your reason for needing such a list is, you might
> find that a sufficiently effective solution is to do a reverse DNS lookup on an IP
> address and look for any of:
>
> 	cable
> 	dsl
> 	dynamic
> 	pool
>
> as discrete words (often in a format such as "cable-79-35-42-183.isp.com").


>
>
> Hope that helps,
>
>
> Antony.
>

-- 
Signed,

Benjamin E. Nichols
http://www.squidblacklist.org

1-405-397-1360



From mailinglist at cd.kcfam.net  Mon Jun 27 17:30:35 2016
From: mailinglist at cd.kcfam.net (Casey Daniels)
Date: Mon, 27 Jun 2016 13:30:35 -0400
Subject: [squid-users] Good Home Cable Modem Blacklist
In-Reply-To: <64339e45-023b-53a6-ddce-6a020e5f278f@squidblacklist.org>
References: <CAEnCSG4XeAdHk9VzF+Pmwz9XHcRkwCqowynRDEzByrFbU+Y--g@mail.gmail.com>
 <201606271921.26414.Antony.Stone@squid.open.source.it>
 <64339e45-023b-53a6-ddce-6a020e5f278f@squidblacklist.org>
Message-ID: <c13bd4d0-5226-82ce-8b4d-7d09c074695c@cd.kcfam.net>

My question is what is the purpose of this?  What are you trying to 
accomplish.  There maybe a different (read easier) way to accomplish 
your end goal.


On 6/27/2016 1:27 PM, Benjamin E. Nichols wrote:
> It would also be trivial to gather up all known ip ranges issued to 
> consumer cable isps and convert them to a domain name acl compatible 
> format.
>
> I will put it on the whiteboard.
>
>
> On 6/27/2016 12:21 PM, Antony Stone wrote:
>> On Monday 27 June 2016 at 19:06:17, Michael Pelletier wrote:
>>
>>> Does anyone know of a good blacklist of home cable modems?
>> I don't think you'll get any list of *home* cable modems, which 
>> excludes small
>> business connections as well.
>>
>> Also, with a lot of ISPs, I don't think you'll get a list of *cable* 
>> modems,
>> separate from DSL modems; many of them use combined DHCP pools for both.
>>
>> However, depending on what your reason for needing such a list is, 
>> you might
>> find that a sufficiently effective solution is to do a reverse DNS 
>> lookup on an IP
>> address and look for any of:
>>
>>     cable
>>     dsl
>>     dynamic
>>     pool
>>
>> as discrete words (often in a format such as 
>> "cable-79-35-42-183.isp.com").
>
>
>>
>>
>> Hope that helps,
>>
>>
>> Antony.
>>
>



From ataro at protonmail.ch  Mon Jun 27 20:45:19 2016
From: ataro at protonmail.ch (Ataro)
Date: Mon, 27 Jun 2016 16:45:19 -0400
Subject: [squid-users] Running squid on a machine with only one network
	interface.
Message-ID: <km0veN2AohDivh1p8WaGCSUiXPJ8Ryh1kP7Nwqne7MHgFAlMbdO46-rLEJbnyQPKIpPTsVsjQFOBW1s1WXhpGw==@protonmail.ch>

Hi there,


I've set up a FreeBSD machine inside a VirtualBox machine and used IPFW to forward all the requests to the internet through a squid server running on the same machine in port 3128 in intercept mode.

The problem is that I get 403 http responses on every site I try to access to, even on the sites that I've explicitly allowed in the squid.conf file.


I also get a warning message on the tty that squid is running on (I've run squid in no daemon mode) which says: Warning: Forwarding loop detected for:.....


I guess that this error occurs since the squid server and the IPFW firewall are running on the same machine which have only one network interface.


Am I right?


Regards,


ataro.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160627/19dc48f3/attachment.htm>

From webmaster at squidblacklist.org  Mon Jun 27 20:51:30 2016
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Mon, 27 Jun 2016 15:51:30 -0500
Subject: [squid-users] Running squid on a machine with only one network
 interface.
In-Reply-To: <km0veN2AohDivh1p8WaGCSUiXPJ8Ryh1kP7Nwqne7MHgFAlMbdO46-rLEJbnyQPKIpPTsVsjQFOBW1s1WXhpGw==@protonmail.ch>
References: <km0veN2AohDivh1p8WaGCSUiXPJ8Ryh1kP7Nwqne7MHgFAlMbdO46-rLEJbnyQPKIpPTsVsjQFOBW1s1WXhpGw==@protonmail.ch>
Message-ID: <3616c33d-606b-3d58-6134-480e88268950@squidblacklist.org>

Did you add a firewall rule to allow your squid box/ip to go direct?

You need to, otherwise youll be sending your traffic in a loop.


On 6/27/2016 3:45 PM, Ataro wrote:
>
> Hi there,
>
>
> I've set up a FreeBSD machine inside a VirtualBox machine and used 
> IPFW to forward all the requests to the internet through a squid 
> server running on the same machine in port 3128 in intercept mode.
>
> The problem is that I get 403 http responses on every site I try to 
> access to, even on the sites that I've explicitly allowed in the 
> squid.conf file.
>
>
> I also get a warning message on the tty that squid is running on (I've 
> run squid in no daemon mode) which says: Warning: Forwarding loop 
> detected for:.....
>
>
> I guess that this error occurs since the squid server and the IPFW 
> firewall are running on the same machine which have only one  network 
> interface.
>
>
> Am I right?
>
>
> Regards,
>
>
> ataro.
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Signed,

Benjamin E. Nichols
http://www.squidblacklist.org

1-405-397-1360

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160627/261ed705/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Jun 27 20:57:26 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 27 Jun 2016 22:57:26 +0200
Subject: [squid-users] Running squid on a machine with only one network
	interface.
Message-ID: <201606272257.26270.Antony.Stone@squid.open.source.it>

On Monday 27 June 2016 at 22:45:19, Ataro wrote:

> Hi there,
> 
> I've set up a FreeBSD machine inside a VirtualBox machine and used IPFW to
> forward all the requests to the internet through a squid server running on
> the same machine in port 3128 in intercept mode.

Please show us your IPFW rules.

> The problem is that I get 403 http responses on every site I try to access
> to, even on the sites that I've explicitly allowed in the squid.conf file.

Maybe show us your squid.conf as well (without comments or blank lines).

> I also get a warning message on the tty that squid is running on (I've run
> squid in no daemon mode) which says: Warning: Forwarding loop detected
> for:.....

So, NAT is not working correctly...

> I guess that this error occurs since the squid server and the IPFW firewall
> are running on the same machine which have only one network interface.
> 
> Am I right?

Not in the sense that "you can't do this with only one interface", no.

However, quite possibly in the sense that you haven't told IPFW how to 
distinguish between requests in from your clients, and requests out from your 
squid instance.

The former need to go to squid, the latter need to go to the Internet.


Give us a bit more information and we might be able to give you a bit more 
help.



Antony.

-- 
I don't know, maybe if we all waited then cosmic rays would write all our 
software for us. Of course it might take a while.

 - Ron Minnich, Los Alamos National Laboratory

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Tue Jun 28 02:20:04 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 28 Jun 2016 14:20:04 +1200
Subject: [squid-users] Websocket content adaptation
In-Reply-To: <CAAFc9Fg4jNed1kZHe-0p2EbKHTQEP=y3eZhsTvy+mkvWC7Xkuw@mail.gmail.com>
References: <CAAFc9Fg4jNed1kZHe-0p2EbKHTQEP=y3eZhsTvy+mkvWC7Xkuw@mail.gmail.com>
Message-ID: <ceada36d0f65e8883243f7ba4d0a3bf5@treenet.co.nz>

On 2016-06-28 04:23, Ozgur Batur wrote:
> Hi,
> 
> ICAP handles plain HTTP very well but it is not possible to
> filter/change or even log content of websocket communication after
> websocket upgrade over HTTP as far as I know. Is there any plan or
> interest in developing some capability for Squid to control websocket
> communication content?

Not for adaptation. I plan to look into implementing WebSocket over 
HTTP/2 support.

But ICAP is not designed for non-HTTP protocols, and WebSockets is 
designed to transfer essentially random data with protection against 
modification. So there is not likely to be any adaptation possibility.

> 
> There is no defined request/response protocol since websocket is
> basically a socket but regexp matching in incoming and outgoing
> content(json, xml,raw) with URL and client metadata info may have some
> application like data leak prevention or achieving in corporate
> environment.
> 

http_access type controls for WebSocket connection. Yes I hope those can 
be added once Squid is adjusted to understand how WebSockets frames 
operate. Right now there is only http_access for the HTTP message that 
WS uses to get through HTTP-only proxies.

Amos



From squid3 at treenet.co.nz  Tue Jun 28 02:26:14 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 28 Jun 2016 14:26:14 +1200
Subject: [squid-users] Running squid on a machine with only one network
	interface.
In-Reply-To: <201606272257.26270.Antony.Stone@squid.open.source.it>
References: <201606272257.26270.Antony.Stone@squid.open.source.it>
Message-ID: <9b4a8999cb6d17fbfa45643d48304b0c@treenet.co.nz>

On 2016-06-28 08:57, Antony Stone wrote:
> On Monday 27 June 2016 at 22:45:19, Ataro wrote:
> 
>> Hi there,
>> 
>> I've set up a FreeBSD machine inside a VirtualBox machine and used 
>> IPFW to
>> forward all the requests to the internet through a squid server 
>> running on
>> the same machine in port 3128 in intercept mode.
> 
> Please show us your IPFW rules.
> 
>> The problem is that I get 403 http responses on every site I try to 
>> access
>> to, even on the sites that I've explicitly allowed in the squid.conf 
>> file.
> 
> Maybe show us your squid.conf as well (without comments or blank 
> lines).
> 
>> I also get a warning message on the tty that squid is running on (I've 
>> run
>> squid in no daemon mode) which says: Warning: Forwarding loop detected
>> for:.....
> 
> So, NAT is not working correctly...
> 

I think that is the problem right there.

 From the description given it sounds like the NAT rules are on the 
'outer' machine. The requirement that NAT be performed on the same 
machine as Squid applies to VM as much as to hardware. The NAT *must* be 
performed on the VM where Squid is running, the outer machine must only 
route packets - not port forward or NAT them to the VM.

>> I guess that this error occurs since the squid server and the IPFW 
>> firewall
>> are running on the same machine which have only one network interface.
>> 
>> Am I right?
> 
> Not in the sense that "you can't do this with only one interface", no.
> 

Nod. Squid does not know nor care about interfaces.

> However, quite possibly in the sense that you haven't told IPFW how to
> distinguish between requests in from your clients, and requests out 
> from your
> squid instance.
> 
> The former need to go to squid, the latter need to go to the Internet.
> 
> 
> Give us a bit more information and we might be able to give you a bit 
> more
> help.
> 
> Antony.

Amos



From webmaster at squidblacklist.org  Tue Jun 28 02:29:31 2016
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Mon, 27 Jun 2016 21:29:31 -0500
Subject: [squid-users] Running squid on a machine with only one network
 interface.
In-Reply-To: <9b4a8999cb6d17fbfa45643d48304b0c@treenet.co.nz>
References: <201606272257.26270.Antony.Stone@squid.open.source.it>
 <9b4a8999cb6d17fbfa45643d48304b0c@treenet.co.nz>
Message-ID: <e1fc1cf0-d2f5-d095-7081-09287bb2a6b1@squidblacklist.org>

You clowns are over complicating this.

Simply add a firewall rule allowing the ip of the squid box to bypass 
your redirect rule.

( squid has to be able to bypass your port 80 redirect rule to fetch 
http data from the web, hence, forward loop error )

-- 
Signed,

Benjamin E. Nichols
http://www.squidblacklist.org

1-405-397-1360



From drcimino at email.it  Tue Jun 28 06:14:34 2016
From: drcimino at email.it (drcimino drcimino)
Date: Tue, 28 Jun 2016 08:14:34 +0200
Subject: [squid-users] Strange NTLM problem.
Message-ID: <77b351c584e272d8fb9ec0f637e6ef79@wm10.email.it>

Dear all,


&nbsp;


i have a strange problem with my squid 3.5.19 and authentication NTLM.


On my configuration i have 2 auth method:


&nbsp;


NTLM negotiated with ntlm_auth from samba 3


&nbsp;


auth_param ntlm program /usr/local/samba/bin/ntlm_auth
--helper-protocol=squid-2.5-ntlmssp

auth_param ntlm children 200 startup=100 idle=10 concurrency=0

auth_param ntlm keep_alive on




and as a fallback basic ntlm


&nbsp;


auth_param basic program /usr/local/samba/bin/ntlm_auth
--helper-protocol=squid-2.5-basic

auth_param basic children 25 startup=15 idle=5 concurrency=0

auth_param basic realm PROXY AUTHORIZATION REQUIRED

auth_param basic credentialsttl 30 minutes


&nbsp;


TTL




authenticate_cache_garbage_interval 1 hours

authenticate_ttl 30 minutes

authenticate_ip_ttl 30 minutes




Groups identification with LDAPS


&nbsp;


external_acl_type NAV children-max=200 children-startup=100 children-idle=10
ttl=1800 %LOGIN

/usr/local/squid/libexec/ext_ldap_group_acl -s sub -b "dc=domain,dc=xxx" -D
"cn=squid,cn=Users,dc

=domain,dc=xxx" -w "password" -f
"(&amp;(objectclass=person)(sAMAccountName=%v)(membero

f=cn=%a,ou=INTERNET,ou=AAA,dc=domain,dc=xxx))" -S -K -H
ldaps://domain.xxx:3269


&nbsp;


... and all work very well.


Sometimes and randomly, my users reported to me that squid cannot do ntlm
transparent authentication and request for user/password pair (falling back
to ntlm basic).


Entering right credential does not work and to proceed further&nbsp; users
need to click on "abort" button many times.


&nbsp;


On my cache.log i see:


&nbsp;


Login for user [DOMAIN]\[userx]@[PC_XXX] failed due to [Access denied]

NTLMSSP BH: NT_STATUS_ACCESS_DENIED

2016/06/27 22:59:06 kid1| ERROR: NTLM Authentication validating user.
Result: {result=BH, notes={mes

sage: NT_STATUS_ACCESS_DENIED; }}

2016/06/27 23:00:02| Set Current Directory to /squid/log

2016/06/27 23:10:01| Set Current Directory to /squid/log

2016/06/27 23:20:01| Set Current Directory to /squid/log

2016/06/27 23:21:09 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state

2016/06/27 23:21:09 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state


&nbsp;


every times a user receive credential request.


After aborting each requests squid do, users can surf the internet without
problems and i cannot replicate the issue.


Trying to close the browser, clear cache, and going to the same site does
not produce same error.


Stopping squid, remove cache, starting squid does not produce same error.


It's totally random and i'm going mad to understand why.


Can someone help me to debug and understand the problem?


Any help will be appreciated.


&nbsp;


Many thanks.


Giulius.




 
 
 --
 ZE-Light e ZE-Pro: servizi zimbra per caselle con dominio email.it, per tutti i dettagli 
Clicca qui http://posta.email.it/caselle-di-posta-z-email-it/?utm_campaign=email_Zimbra_102014=main_footer/f
 
 Sponsor:
 Registra i domini che desideri ed inizia a creare il tuo sito web
 Clicca qui: http://adv.email.it/cgi-bin/foclick.cgi?mid=13323&d=28-6
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160628/17414eef/attachment.htm>

From ahmed.zaeem at netstream.ps  Tue Jun 28 07:39:30 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 28 Jun 2016 10:39:30 +0300
Subject: [squid-users] squid with HTTPS and some APPs not working
Message-ID: <EB9E6998-A8D4-48D0-86B6-D53BA1953D75@netstream.ps>

Hi ,
i have squid that is working on 3.5 .
traffic of t 80 and 443 traffic to Squid via IPTables.

Squid then passes traffic to ClamAV via C-ICAP. Squid is configured to intercept all SSL traffic and PKI has been setup and distributed to all clients.

we have a problem in  Skype of Business (Office 365) and Slack (Chat app)  seems its broken from squid intercept.


i tried to do exception for ssl for the domains that shown on the ACCess.log file when i use the APPs , but no luck 

i tried to execlide the websites below :

skype.com
lync.com
todyl.com
fastly\.net
.slack-msgs.com
.amazonaws.com
.slack.com <http://slack.com/>


#########################################################
but  it still not working and the APPS (( Skype of Business (Office 365) and Slack (Chat app))) are not working .

again , here is my nobump file :


 cat /opt/etc/squid.doms.nobump

\.skype\.com$
\.lync\.com$
\.todyl\.com$
\.fastly\.net$
\.slack-msgs\.com$
\.amazonaws\.com$
\.slack\.com$

##############################################################

current versions we have :
?       Squid 3.5.19

?       C-ICAP 0.4.2

?       SquidclamAV 6.15

?       ClamAV 0.99.2

######################################################################

      here is squid.conf :

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8	# RFC1918 possible internal network

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost
http_access allow localhost manager
http_access deny manager

# Squid normally listens to port 3128
http_port 3127
http_port 3128 intercept

# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid

visible_hostname shield.TodylInc.shield

cache_log /opt/var/log/squid/cache_log
cache_access_log /opt/var/log/squid/access_log

#user and group
cache_effective_user squid
cache_effective_group squid

acl todyl dstdomain	todyl.com
request_header_add X-TODYL-GUID 1e46dccd2 todyl

#Custom Error Pages
error_directory /opt/www/squid

# Squid listen Port
https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB key=/opt/etc/pki/squid/ca-key.pem cert=/opt/etc/pki/squid/ca.pem options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE

# SSL Bump Config
always_direct allow all
ssl_bump server-first all 
sslcrtd_program /opt/libexec/ssl_crtd -s /opt/lib/ssl_db -M 4MB
sslcrtd_children 32 startup=5 idle=1

##############################################
acl DiscoverSNIHost at_step SslBump1
acl NoSSLIntercept ssl::server_name_regex -i "/opt/etc/squid.doms.nobump"
 
ssl_bump splice NoSSLIntercept
ssl_bump peek DiscoverSNIHost
ssl_bump bump all
 
##################

#Hardening
sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

# TUNING
cache_dir aufs /var/cache/squid 40000 16 256
store_dir_select_algorithm round-robin
minimum_object_size 0 KB
maximum_object_size 96 MB
memory_pools off
quick_abort_min 0 KB
quick_abort_max 0 KB
log_icp_queries off
client_db off
cache_mem 1500 MB
buffered_logs on
half_closed_clients off

dns_nameservers 10.192.0.1
##################################################################


here is squid -k parse :

[root at 1e46dccd2 var]# squid -k parse
2016/06/27 08:06:08| Startup: Initializing Authentication Schemes ...
2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 'basic'
2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 'digest'
2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 'negotiate'
2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 'ntlm'
2016/06/27 08:06:08| Startup: Initialized Authentication.
2016/06/27 08:06:08| Processing Configuration File: /opt/etc/squid.conf (depth 0)
2016/06/27 08:06:08| Processing: acl localnet src 10.0.0.0/8 # RFC1918 possible internal network
2016/06/27 08:06:08| Processing: http_access allow localnet
2016/06/27 08:06:08| Processing: http_access allow localhost
2016/06/27 08:06:08| Processing: http_access allow localhost manager
2016/06/27 08:06:08| Processing: http_access deny manager
2016/06/27 08:06:08| Processing: http_port 3127
2016/06/27 08:06:08| Processing: http_port 3128 intercept
2016/06/27 08:06:08| Starting Authentication on port [::]:3128
2016/06/27 08:06:08| Disabling Authentication on port [::]:3128 (interception enabled)
2016/06/27 08:06:08| Processing: coredump_dir /var/cache/squid
2016/06/27 08:06:08| Processing: visible_hostname shield.TodylInc.shield
2016/06/27 08:06:08| Processing: cache_log /opt/var/log/squid/cache_log
2016/06/27 08:06:08| Processing: cache_access_log /opt/var/log/squid/access_log
2016/06/27 08:06:08| Processing: cache_effective_user squid
2016/06/27 08:06:08| Processing: cache_effective_group squid
2016/06/27 08:06:08| Processing: acl todyl dstdomain todyl.com
2016/06/27 08:06:08| Processing: request_header_add X-TODYL-GUID 1e46dccd2 todyl
2016/06/27 08:06:08| Processing: error_directory /opt/www/squid
2016/06/27 08:06:08| Processing: https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB key=/opt/etc/pki/squid/ca-key.pem cert=/opt/etc/pki/squid/ca.pem options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
2016/06/27 08:06:08| Starting Authentication on port [::]:3129
2016/06/27 08:06:08| Disabling Authentication on port [::]:3129 (interception enabled)
2016/06/27 08:06:08| Processing: always_direct allow all
2016/06/27 08:06:08| Processing: ssl_bump server-first all
2016/06/27 08:06:08| Processing: sslcrtd_program /opt/libexec/ssl_crtd -s /opt/lib/ssl_db -M 4MB
2016/06/27 08:06:08| Processing: sslcrtd_children 32 startup=5 idle=1
2016/06/27 08:06:08| Processing: acl DiscoverSNIHost at_step SslBump1
2016/06/27 08:06:08| Processing: acl NoSSLIntercept ssl::server_name_regex -i "/opt/etc/squid.doms.nobump"
2016/06/27 08:06:08| Processing: ssl_bump splice NoSSLIntercept
2016/06/27 08:06:08| Processing: ssl_bump peek DiscoverSNIHost
2016/06/27 08:06:08| Processing: ssl_bump bump all
2016/06/27 08:06:08| Processing: sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
2016/06/27 08:06:08| Processing: sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
2016/06/27 08:06:08| Processing: cache_dir aufs /var/cache/squid 40000 16 256
2016/06/27 08:06:08| Processing: store_dir_select_algorithm round-robin
2016/06/27 08:06:08| Processing: minimum_object_size 0 KB
2016/06/27 08:06:08| Processing: maximum_object_size 96 MB
2016/06/27 08:06:08| Processing: memory_pools off
2016/06/27 08:06:08| Processing: quick_abort_min 0 KB
2016/06/27 08:06:08| Processing: quick_abort_max 0 KB
2016/06/27 08:06:08| Processing: log_icp_queries off
2016/06/27 08:06:08| Processing: client_db off
2016/06/27 08:06:08| Processing: cache_mem 1500 MB
2016/06/27 08:06:08| Processing: buffered_logs on
2016/06/27 08:06:08| Processing: half_closed_clients off
2016/06/27 08:06:08| Processing: dns_nameservers 10.192.0.1
2016/06/27 08:06:08| Initializing https proxy context
2016/06/27 08:06:08| Initializing https_port [::]:3129 SSL context
2016/06/27 08:06:08| Using certificate in /opt/etc/pki/squid/ca.pem
?????????????????????????????????



here is access.log


1467029265.989     50 10.192.0.12 TAG_NONE/200 0 CONNECT 52.84.29.139:443 - ORIGINAL_DST/52.84.29.139 -
1467029265.999     59 10.192.0.12 TAG_NONE/200 0 CONNECT 52.84.29.139:443 - ORIGINAL_DST/52.84.29.139 -
1467029266.070     59 10.192.0.12 TCP_MISS/200 13171 GET https://slack.com/help/test - ORIGINAL_DST/52.84.29.139 text/html
1467029266.222     53 10.192.0.12 TAG_NONE/200 0 CONNECT 172.217.5.14:443 - ORIGINAL_DST/172.217.5.14 -
1467029266.234     66 10.192.0.12 TCP_MISS/200 598 GET https://slack.com/beacon/track/? - ORIGINAL_DST/52.84.29.139 image/gif
1467029266.274     26 10.192.0.12 TCP_MISS/200 557 GET https://www.google-analytics.com/r/collect? - ORIGINAL_DST/172.217.5.14 image/gif
1467029266.314     66 10.192.0.12 TAG_NONE/200 0 CONNECT 169.54.33.172:443 - ORIGINAL_DST/169.54.33.172 -
1467029266.368     21 10.192.0.12 TCP_MISS/200 547 GET https://api.mixpanel.com/track/? - ORIGINAL_DST/169.54.33.172 application/json
1467029266.469     42 10.192.0.12 TAG_NONE/200 0 CONNECT 199.27.76.249:443 - ORIGINAL_DST/199.27.76.249 -
1467029266.722    231 10.192.0.12 TCP_MISS/200 11968 GET https://slack.global.ssl.fastly.net/beacons/boomerang1/image-0.png? - ORIGINAL_DST/199.27.76.249 image/png
1467029267.044    303 10.192.0.12 TAG_NONE/200 0 CONNECT 54.231.161.8:443 - ORIGINAL_DST/54.231.161.8 -
1467029267.231    170 10.192.0.12 TCP_MISS/200 11994 GET https://s3-us-west-2.amazonaws.com/slack-files2/beacons/boomerang1/image-0.png? - ORIGINAL_DST/54.231.161.8 image/png
1467029267.482    145 10.192.0.12 TAG_NONE/200 0 CONNECT 54.172.232.15:443 - ORIGINAL_DST/54.172.232.15 -
1467029267.563     63 10.192.0.12 TCP_MISS_ABORTED/000 0 GET https://mpmulti-y6oq.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_ - ORIGINAL_DST/54.172.232.15 -
1467029267.771    167 10.192.0.12 TAG_NONE/200 0 CONNECT 52.91.147.164:443 - ORIGINAL_DST/52.91.147.164 -
1467029267.891    110 10.192.0.12 TCP_MISS_ABORTED/000 0 GET https://mpmulti-f4bz.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_ - ORIGINAL_DST/52.91.147.164 -
1467029268.106    153 10.192.0.12 TAG_NONE/200 0 CONNECT 52.23.253.30:443 - ORIGINAL_DST/52.23.253.30 -
1467029268.194     79 10.192.0.12 TCP_MISS_ABORTED/000 0 GET https://mpmulti-zdjz.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_ - ORIGINAL_DST/52.23.253.30 -
1467029268.449    160 10.192.0.12 TAG_NONE/200 0 CONNECT 52.201.253.102:443 - ORIGINAL_DST/52.201.253.102 -
1467029268.567    110 10.192.0.12 TCP_MISS_ABORTED/000 0 GET https://mpmulti-2pbf.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_ - ORIGINAL_DST/52.201.253.102 -
1467029268.764    149 10.192.0.12 TAG_NONE/200 0 CONNECT 52.91.121.224:443 - ORIGINAL_DST/52.91.121.224 -
1467029268.845     74 10.192.0.12 TCP_MISS_ABORTED/000 0 GET https://mpmulti-x1if.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_ - ORIGINAL_DST/52.91.121.224 -
1467029268.967    108 10.192.0.12 TCP_MISS/200 516 GET https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - ORIGINAL_DST/199.27.76.249 image/gif
1467029269.169    187 10.192.0.12 TCP_MISS/200 517 GET https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - ORIGINAL_DST/199.27.76.249 image/gif
1467029269.285    101 10.192.0.12 TCP_MISS/200 516 GET https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - ORIGINAL_DST/199.27.76.249 image/gif
1467029269.467    167 10.192.0.12 TCP_MISS/200 517 GET https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - ORIGINAL_DST/199.27.76.249 image/gif
1467029269.643    160 10.192.0.12 TCP_MISS/200 517 GET https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - ORIGINAL_DST/199.27.76.249 image/gif
1467029269.824    165 10.192.0.12 TCP_MISS/200 517 GET https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - ORIGINAL_DST/199.27.76.249 image/gif
1467029270.004    164 10.192.0.12 TCP_MISS/200 517 GET https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - ORIGINAL_DST/199.27.76.249 image/gif
1467029270.186    165 10.192.0.12 TCP_MISS/200 517 GET https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - ORIGINAL_DST/199.27.76.249 image/gif
1467029270.295     94 10.192.0.12 TCP_MISS/200 516 GET https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - ORIGINAL_DST/199.27.76.249 image/gif
1467029270.489    173 10.192.0.12 TCP_MISS/200 517 GET https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - ORIGINAL_DST/199.27.76.249 image/gif
1467029270.656    151 10.192.0.12 TCP_MISS_ABORTED/000 0 GET https://slack.global.ssl.fastly.net/beacons/boomerang1/image-0.png? - ORIGINAL_DST/199.27.76.249 -
1467029273.699     57 10.192.0.12 TCP_MISS/200 951 GET http://lyncdiscover.todyl.com/? - ORIGINAL_DST/131.253.163.205 application/vnd.microsoft.rtc.autodiscover+xml
1467029273.713     72 10.192.0.12 TAG_NONE/200 0 CONNECT 131.253.163.205:443 - ORIGINAL_DST/131.253.163.205 -
1467029273.797     73 10.192.0.12 TAG_NONE/200 0 CONNECT 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
1467029273.874     70 10.192.0.12 TCP_MISS/200 1453 GET https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root? - ORIGINAL_DST/131.253.161.142 application/vnd.microsoft.rtc.autodiscover+xml
1467029273.952     74 10.192.0.12 TAG_NONE/200 0 CONNECT 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
1467029273.985     25 10.192.0.12 TCP_MISS/401 2206 GET https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user? - ORIGINAL_DST/131.253.161.142 text/html
1467029274.077     76 10.192.0.12 TAG_NONE/200 0 CONNECT 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
1467029274.217    132 10.192.0.12 TCP_MISS/200 18842 POST https://webdir2a.online.lync.com/WebTicket/WebTicketService.svc/mex - ORIGINAL_DST/131.253.161.142 application/soap+xml
1467029274.430    152 10.192.0.12 TAG_NONE/200 0 CONNECT 23.96.208.238:443 - ORIGINAL_DST/23.96.208.238 -
1467029274.631    180 10.192.0.12 TCP_MISS/200 16835 POST https://login.microsoftonline.com/RST2.srf - ORIGINAL_DST/23.96.208.238 application/soap+xml
1467029274.720     75 10.192.0.12 TAG_NONE/200 0 CONNECT 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
1467029274.858    131 10.192.0.12 TCP_MISS/200 6107 POST https://webdir2a.online.lync.com/WebTicket/WebTicketAdvancedService.svc/WsFed_bearer - ORIGINAL_DST/131.253.161.142 text/xml
1467029274.936     73 10.192.0.12 TAG_NONE/200 0 CONNECT 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
1467029274.998     55 10.192.0.12 TCP_MISS/200 2507 GET https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user? - ORIGINAL_DST/131.253.161.142 application/vnd.microsoft.rtc.autodiscover+xml
1467029275.099     72 10.192.0.12 TAG_NONE/200 0 CONNECT 131.253.161.139:443 - ORIGINAL_DST/131.253.161.139 -
1467029275.216     70 10.192.0.12 TAG_NONE/200 0 CONNECT 131.253.161.147:443 - ORIGINAL_DST/131.253.161.147 -
1467029275.524    107 10.192.0.12 TAG_NONE/200 0 CONNECT 134.170.113.218:443 - ORIGINAL_DST/134.170.113.218 -
1467029279.731     24 10.192.0.12 TCP_MISS/200 951 GET http://lyncdiscover.todyl.com/? - ORIGINAL_DST/131.253.163.205 application/vnd.microsoft.rtc.autodiscover+xml
1467029279.778     71 10.192.0.12 TAG_NONE/200 0 CONNECT 131.253.163.205:443 - ORIGINAL_DST/131.253.163.205 -
1467029279.814     76 10.192.0.12 TAG_NONE/200 0 CONNECT 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
1467029279.847     27 10.192.0.12 TCP_MISS/200 1453 GET https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root? - ORIGINAL_DST/131.253.161.142 application/vnd.microsoft.rtc.autodiscover+xml
1467029279.922     70 10.192.0.12 TAG_NONE/200 0 CONNECT 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
1467029279.952     24 10.192.0.12 TCP_MISS/401 2206 GET https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user? - ORIGINAL_DST/131.253.161.142 text/html
1467029280.032     73 10.192.0.12 TAG_NONE/200 0 CONNECT 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
1467029280.092     54 10.192.0.12 TCP_MISS/200 2507 GET https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user? - ORIGINAL_DST/131.253.161.142 application/vnd.microsoft.rtc.autodiscover+xml
1467029280.180     73 10.192.0.12 TAG_NONE/200 0 CONNECT 131.253.161.139:443 - ORIGINAL_DST/131.253.161.139 -
1467029280.270     73 10.192.0.12 TAG_NONE/200 0 CONNECT 131.253.161.147:443 - ORIGINAL_DST/131.253.161.147 -
1467029280.396    107 10.192.0.12 TAG_NONE/200 0 CONNECT 134.170.113.218:443 - ORIGINAL_DST/134.170.113.218 -
1467029287.555     75 10.192.0.12 TAG_NONE/200 0 CONNECT 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
1467029287.673     92 10.192.0.12 TAG_NONE/200 0 CONNECT 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
1467029287.681     41 10.192.0.12 TCP_MISS/200 607 GET http://login.live.com/ppcrlcheck.srf - ORIGINAL_DST/131.253.61.68 text/html
1467029287.729     41 10.192.0.12 TAG_NONE/200 0 CONNECT 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
1467029287.784     46 10.192.0.12 TAG_NONE/200 0 CONNECT 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
1467029287.801     92 10.192.0.12 TAG_NONE/200 0 CONNECT 131.253.61.68:443 - ORIGINAL_DST/131.253.61.68 -
1467029287.859     61 10.192.0.12 TAG_NONE/200 0 CONNECT 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
1467029287.926     52 10.192.0.12 TAG_NONE/200 0 CONNECT 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
1467029287.964    134 10.192.0.12 TCP_MISS/200 10828 POST https://login.live.com/RST2.srf - ORIGINAL_DST/131.253.61.68 application/soap+xml
1467029287.998     56 10.192.0.12 TAG_NONE/200 0 CONNECT 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
1467029288.051     40 10.192.0.12 TAG_NONE/200 0 CONNECT 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
1467029288.204     46 10.192.0.12 TCP_MISS/302 538 GET http://go.microsoft.com/fwlink/? - ORIGINAL_DST/23.66.120.244 -
1467029288.389    147 10.192.0.12 TCP_MISS/302 1786 GET http://www.microsoft.com/security/encyclopedia/adlpackages.aspx? - ORIGINAL_DST/23.203.90.59 text/html
1467029288.422     48 10.192.0.12 TAG_NONE/200 0 CONNECT 13.90.208.215:443 - ORIGINAL_DST/13.90.208.215 -
1467029288.882    311 10.192.0.12 TAG_NONE/200 0 CONNECT 104.41.32.78:443 - ORIGINAL_DST/104.41.32.78 -












Any Help ????


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160628/c94aca2a/attachment.htm>

From yvoinov at gmail.com  Tue Jun 28 07:53:30 2016
From: yvoinov at gmail.com (Yuri)
Date: Tue, 28 Jun 2016 13:53:30 +0600
Subject: [squid-users] squid with HTTPS and some APPs not working
In-Reply-To: <EB9E6998-A8D4-48D0-86B6-D53BA1953D75@netstream.ps>
References: <EB9E6998-A8D4-48D0-86B6-D53BA1953D75@netstream.ps>
Message-ID: <edb9e787-5d61-a9fc-a045-843b166291db@gmail.com>



28.06.2016 13:39, --Ahmad-- ?????:
> Hi ,
> i have squid that is working on 3.5 .
>
> traffic of t 80 and 443 traffic to Squid via IPTables.
>
> Squid then passes traffic to ClamAV via C-ICAP. Squid is configured to 
> intercept all SSL traffic and PKI has been setup and distributed to 
> all clients.
>
> we have a problem in  Skype of Business (Office 365) and Slack (Chat 
> app)  seems its broken from squid intercept.
>
>
> i tried to do exception for ssl for the domains that shown on the 
> ACCess.log file when i use the APPs , but no luck
>
> i tried to execlide the websites below :
>
> skype.com <http://skype.com>
> lync.com
> todyl.com
> fastly\.net
> .slack-msgs.com
> .amazonaws.com
> .slack.com <http://slack.com>
>
>
> #########################################################
> but  it still not working and the APPS (( Skype of Business (Office 
> 365) and Slack (Chat app))) are not working .
>
> again , here is my nobump file :
>
>
> cat /opt/etc/squid.doms.nobump
>
> \.skype\.com$
> \.lync\.com$
> \.todyl\.com$
> \.fastly\.net$
> \.slack-msgs\.com$
> \.amazonaws\.com$
> \.slack\.com$
Man, $ at the end of regex means you finish row scan here.
You no-bumps only domains and no one URL argument. Wny you expect it 
must work?
>
> ##############################################################
>
> current versions we have :
>
> ?Squid 3.5.19
>
> ?C-ICAP 0.4.2
>
> ?SquidclamAV 6.15
>
> ?ClamAV 0.99.2
>
> ######################################################################
>
>   here is squid.conf :
>
> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl localnet src 10.0.0.0/8# RFC1918 possible internal network
>
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
> http_access allow localhost manager
> http_access deny manager
>
> # Squid normally listens to port 3128
> http_port 3127
> http_port 3128 intercept
>
> # Leave coredumps in the first cache dir
> coredump_dir /var/cache/squid
>
> visible_hostname shield.TodylInc.shield
>
> cache_log /opt/var/log/squid/cache_log
> cache_access_log /opt/var/log/squid/access_log
>
> #user and group
> cache_effective_user squid
> cache_effective_group squid
>
> acl todyl dstdomaintodyl.com <http://todyl.com>
> request_header_add X-TODYL-GUID 1e46dccd2 todyl
>
> #Custom Error Pages
> error_directory /opt/www/squid
>
> # Squid listen Port
> https_port 3129 intercept ssl-bump generate-host-certificates=on 
> dynamic_cert_mem_cache_size=4MB key=/opt/etc/pki/squid/ca-key.pem 
> cert=/opt/etc/pki/squid/ca.pem options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>
> # SSL Bump Config
> always_direct allow all
> ssl_bump server-first all
> sslcrtd_program /opt/libexec/ssl_crtd -s /opt/lib/ssl_db -M 4MB
> sslcrtd_children 32 startup=5 idle=1
>
> ##############################################
> acl DiscoverSNIHost at_step SslBump1
> acl NoSSLIntercept ssl::server_name_regex -i "/opt/etc/squid.doms.nobump"
> ssl_bump splice NoSSLIntercept
> ssl_bump peek DiscoverSNIHost
> ssl_bump bump all
> ##################
>
> #Hardening
> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> sslproxy_cipher 
> EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>
> # TUNING
> cache_dir aufs /var/cache/squid 40000 16 256
> store_dir_select_algorithm round-robin
> minimum_object_size 0 KB
> maximum_object_size 96 MB
> memory_pools off
> quick_abort_min 0 KB
> quick_abort_max 0 KB
> log_icp_queries off
> client_db off
> cache_mem 1500 MB
> buffered_logs on
> half_closed_clients off
>
> dns_nameservers 10.192.0.1
> ##################################################################
>
>
> here is squid -k parse :
>
> [root at 1e46dccd2 var]# squid -k parse
> 2016/06/27 08:06:08| Startup: Initializing Authentication Schemes ...
> 2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 'basic'
> 2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 'digest'
> 2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 
> 'negotiate'
> 2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 'ntlm'
> 2016/06/27 08:06:08| Startup: Initialized Authentication.
> 2016/06/27 08:06:08| Processing Configuration File: 
> /opt/etc/squid.conf (depth 0)
> 2016/06/27 08:06:08| Processing: acl localnet src 10.0.0.0/8 # RFC1918 
> possible internal network
> 2016/06/27 08:06:08| Processing: http_access allow localnet
> 2016/06/27 08:06:08| Processing: http_access allow localhost
> 2016/06/27 08:06:08| Processing: http_access allow localhost manager
> 2016/06/27 08:06:08| Processing: http_access deny manager
> 2016/06/27 08:06:08| Processing: http_port 3127
> 2016/06/27 08:06:08| Processing: http_port 3128 intercept
> 2016/06/27 08:06:08| Starting Authentication on port [::]:3128
> 2016/06/27 08:06:08| Disabling Authentication on port [::]:3128 
> (interception enabled)
> 2016/06/27 08:06:08| Processing: coredump_dir /var/cache/squid
> 2016/06/27 08:06:08| Processing: visible_hostname shield.TodylInc.shield
> 2016/06/27 08:06:08| Processing: cache_log /opt/var/log/squid/cache_log
> 2016/06/27 08:06:08| Processing: cache_access_log 
> /opt/var/log/squid/access_log
> 2016/06/27 08:06:08| Processing: cache_effective_user squid
> 2016/06/27 08:06:08| Processing: cache_effective_group squid
> 2016/06/27 08:06:08| Processing: acl todyl dstdomain todyl.com 
> <http://todyl.com>
> 2016/06/27 08:06:08| Processing: request_header_add X-TODYL-GUID 
> 1e46dccd2 todyl
> 2016/06/27 08:06:08| Processing: error_directory /opt/www/squid
> 2016/06/27 08:06:08| Processing: https_port 3129 intercept ssl-bump 
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
> key=/opt/etc/pki/squid/ca-key.pem cert=/opt/etc/pki/squid/ca.pem 
> options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
> 2016/06/27 08:06:08| Starting Authentication on port [::]:3129
> 2016/06/27 08:06:08| Disabling Authentication on port [::]:3129 
> (interception enabled)
> 2016/06/27 08:06:08| Processing: always_direct allow all
> 2016/06/27 08:06:08| Processing: ssl_bump server-first all
> 2016/06/27 08:06:08| Processing: sslcrtd_program /opt/libexec/ssl_crtd 
> -s /opt/lib/ssl_db -M 4MB
> 2016/06/27 08:06:08| Processing: sslcrtd_children 32 startup=5 idle=1
> 2016/06/27 08:06:08| Processing: acl DiscoverSNIHost at_step SslBump1
> 2016/06/27 08:06:08| Processing: acl NoSSLIntercept 
> ssl::server_name_regex -i "/opt/etc/squid.doms.nobump"
> 2016/06/27 08:06:08| Processing: ssl_bump splice NoSSLIntercept
> 2016/06/27 08:06:08| Processing: ssl_bump peek DiscoverSNIHost
> 2016/06/27 08:06:08| Processing: ssl_bump bump all
> 2016/06/27 08:06:08| Processing: sslproxy_options 
> NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 2016/06/27 08:06:08| Processing: sslproxy_cipher 
> EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> 2016/06/27 08:06:08| Processing: cache_dir aufs /var/cache/squid 40000 
> 16 256
> 2016/06/27 08:06:08| Processing: store_dir_select_algorithm round-robin
> 2016/06/27 08:06:08| Processing: minimum_object_size 0 KB
> 2016/06/27 08:06:08| Processing: maximum_object_size 96 MB
> 2016/06/27 08:06:08| Processing: memory_pools off
> 2016/06/27 08:06:08| Processing: quick_abort_min 0 KB
> 2016/06/27 08:06:08| Processing: quick_abort_max 0 KB
> 2016/06/27 08:06:08| Processing: log_icp_queries off
> 2016/06/27 08:06:08| Processing: client_db off
> 2016/06/27 08:06:08| Processing: cache_mem 1500 MB
> 2016/06/27 08:06:08| Processing: buffered_logs on
> 2016/06/27 08:06:08| Processing: half_closed_clients off
> 2016/06/27 08:06:08| Processing: dns_nameservers 10.192.0.1
> 2016/06/27 08:06:08| Initializing https proxy context
> 2016/06/27 08:06:08| Initializing https_port [::]:3129 SSL context
> 2016/06/27 08:06:08| Using certificate in /opt/etc/pki/squid/ca.pem
> ?????????????????????????????????
>
>
>
> here is access.log
>
>
> 1467029265.989     50 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 52.84.29.139:443 - ORIGINAL_DST/52.84.29.139 -
> 1467029265.999     59 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 52.84.29.139:443 - ORIGINAL_DST/52.84.29.139 -
> 1467029266.070     59 10.192.0.12 TCP_MISS/200 13171 GET 
> https://slack.com/help/test - ORIGINAL_DST/52.84.29.139 text/html
> 1467029266.222     53 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 172.217.5.14:443 - ORIGINAL_DST/172.217.5.14 -
> 1467029266.234     66 10.192.0.12 TCP_MISS/200 598 GET 
> https://slack.com/beacon/track/? - ORIGINAL_DST/52.84.29.139 image/gif
> 1467029266.274     26 10.192.0.12 TCP_MISS/200 557 GET 
> https://www.google-analytics.com/r/collect? - 
> ORIGINAL_DST/172.217.5.14 image/gif
> 1467029266.314     66 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 169.54.33.172:443 - ORIGINAL_DST/169.54.33.172 -
> 1467029266.368     21 10.192.0.12 TCP_MISS/200 547 GET 
> https://api.mixpanel.com/track/? - ORIGINAL_DST/169.54.33.172 
> application/json
> 1467029266.469     42 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 199.27.76.249:443 - ORIGINAL_DST/199.27.76.249 -
> 1467029266.722    231 10.192.0.12 TCP_MISS/200 11968 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-0.png? - 
> ORIGINAL_DST/199.27.76.249 image/png
> 1467029267.044    303 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 54.231.161.8:443 - ORIGINAL_DST/54.231.161.8 -
> 1467029267.231    170 10.192.0.12 TCP_MISS/200 11994 GET 
> https://s3-us-west-2.amazonaws.com/slack-files2/beacons/boomerang1/image-0.png? 
> - ORIGINAL_DST/54.231.161.8 image/png
> 1467029267.482    145 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 54.172.232.15:443 - ORIGINAL_DST/54.172.232.15 -
> 1467029267.563     63 10.192.0.12 TCP_MISS_ABORTED/000 0 GET 
> https://mpmulti-y6oq.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_ 
> - ORIGINAL_DST/54.172.232.15 -
> 1467029267.771    167 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 52.91.147.164:443 - ORIGINAL_DST/52.91.147.164 -
> 1467029267.891    110 10.192.0.12 TCP_MISS_ABORTED/000 0 GET 
> https://mpmulti-f4bz.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_ 
> - ORIGINAL_DST/52.91.147.164 -
> 1467029268.106    153 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 52.23.253.30:443 - ORIGINAL_DST/52.23.253.30 -
> 1467029268.194     79 10.192.0.12 TCP_MISS_ABORTED/000 0 GET 
> https://mpmulti-zdjz.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_ 
> - ORIGINAL_DST/52.23.253.30 -
> 1467029268.449    160 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 52.201.253.102:443 - ORIGINAL_DST/52.201.253.102 -
> 1467029268.567    110 10.192.0.12 TCP_MISS_ABORTED/000 0 GET 
> https://mpmulti-2pbf.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_ 
> - ORIGINAL_DST/52.201.253.102 -
> 1467029268.764    149 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 52.91.121.224:443 - ORIGINAL_DST/52.91.121.224 -
> 1467029268.845     74 10.192.0.12 TCP_MISS_ABORTED/000 0 GET 
> https://mpmulti-x1if.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_ 
> - ORIGINAL_DST/52.91.121.224 -
> 1467029268.967    108 10.192.0.12 TCP_MISS/200 516 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029269.169    187 10.192.0.12 TCP_MISS/200 517 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029269.285    101 10.192.0.12 TCP_MISS/200 516 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029269.467    167 10.192.0.12 TCP_MISS/200 517 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029269.643    160 10.192.0.12 TCP_MISS/200 517 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029269.824    165 10.192.0.12 TCP_MISS/200 517 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029270.004    164 10.192.0.12 TCP_MISS/200 517 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029270.186    165 10.192.0.12 TCP_MISS/200 517 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029270.295     94 10.192.0.12 TCP_MISS/200 516 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029270.489    173 10.192.0.12 TCP_MISS/200 517 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029270.656    151 10.192.0.12 TCP_MISS_ABORTED/000 0 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-0.png? - 
> ORIGINAL_DST/199.27.76.249 -
> 1467029273.699     57 10.192.0.12 TCP_MISS/200 951 GET 
> http://lyncdiscover.todyl.com/? - ORIGINAL_DST/131.253.163.205 
> application/vnd.microsoft.rtc.autodiscover+xml
> 1467029273.713     72 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.163.205:443 - ORIGINAL_DST/131.253.163.205 -
> 1467029273.797     73 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
> 1467029273.874     70 10.192.0.12 TCP_MISS/200 1453 GET 
> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root? 
> - ORIGINAL_DST/131.253.161.142 
> application/vnd.microsoft.rtc.autodiscover+xml
> 1467029273.952     74 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
> 1467029273.985     25 10.192.0.12 TCP_MISS/401 2206 GET 
> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user? 
> - ORIGINAL_DST/131.253.161.142 text/html
> 1467029274.077     76 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
> 1467029274.217    132 10.192.0.12 TCP_MISS/200 18842 POST 
> https://webdir2a.online.lync.com/WebTicket/WebTicketService.svc/mex - 
> ORIGINAL_DST/131.253.161.142 application/soap+xml
> 1467029274.430    152 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 23.96.208.238:443 - ORIGINAL_DST/23.96.208.238 -
> 1467029274.631    180 10.192.0.12 TCP_MISS/200 16835 POST 
> https://login.microsoftonline.com/RST2.srf - 
> ORIGINAL_DST/23.96.208.238 application/soap+xml
> 1467029274.720     75 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
> 1467029274.858    131 10.192.0.12 TCP_MISS/200 6107 POST 
> https://webdir2a.online.lync.com/WebTicket/WebTicketAdvancedService.svc/WsFed_bearer 
> - ORIGINAL_DST/131.253.161.142 text/xml
> 1467029274.936     73 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
> 1467029274.998     55 10.192.0.12 TCP_MISS/200 2507 GET 
> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user? 
> - ORIGINAL_DST/131.253.161.142 
> application/vnd.microsoft.rtc.autodiscover+xml
> 1467029275.099     72 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.139:443 - ORIGINAL_DST/131.253.161.139 -
> 1467029275.216     70 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.147:443 - ORIGINAL_DST/131.253.161.147 -
> 1467029275.524    107 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 134.170.113.218:443 - ORIGINAL_DST/134.170.113.218 -
> 1467029279.731     24 10.192.0.12 TCP_MISS/200 951 GET 
> http://lyncdiscover.todyl.com/? - ORIGINAL_DST/131.253.163.205 
> application/vnd.microsoft.rtc.autodiscover+xml
> 1467029279.778     71 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.163.205:443 - ORIGINAL_DST/131.253.163.205 -
> 1467029279.814     76 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
> 1467029279.847     27 10.192.0.12 TCP_MISS/200 1453 GET 
> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root? 
> - ORIGINAL_DST/131.253.161.142 
> application/vnd.microsoft.rtc.autodiscover+xml
> 1467029279.922     70 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
> 1467029279.952     24 10.192.0.12 TCP_MISS/401 2206 GET 
> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user? 
> - ORIGINAL_DST/131.253.161.142 text/html
> 1467029280.032     73 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
> 1467029280.092     54 10.192.0.12 TCP_MISS/200 2507 GET 
> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user? 
> - ORIGINAL_DST/131.253.161.142 
> application/vnd.microsoft.rtc.autodiscover+xml
> 1467029280.180     73 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.139:443 - ORIGINAL_DST/131.253.161.139 -
> 1467029280.270     73 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.147:443 - ORIGINAL_DST/131.253.161.147 -
> 1467029280.396    107 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 134.170.113.218:443 - ORIGINAL_DST/134.170.113.218 -
> 1467029287.555     75 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
> 1467029287.673     92 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
> 1467029287.681     41 10.192.0.12 TCP_MISS/200 607 GET 
> http://login.live.com/ppcrlcheck.srf - ORIGINAL_DST/131.253.61.68 
> text/html
> 1467029287.729     41 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
> 1467029287.784     46 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
> 1467029287.801     92 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.61.68:443 - ORIGINAL_DST/131.253.61.68 -
> 1467029287.859     61 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
> 1467029287.926     52 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
> 1467029287.964    134 10.192.0.12 TCP_MISS/200 10828 POST 
> https://login.live.com/RST2.srf - ORIGINAL_DST/131.253.61.68 
> application/soap+xml
> 1467029287.998     56 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
> 1467029288.051     40 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
> 1467029288.204     46 10.192.0.12 TCP_MISS/302 538 GET 
> http://go.microsoft.com/fwlink/? - ORIGINAL_DST/23.66.120.244 -
> 1467029288.389    147 10.192.0.12 TCP_MISS/302 1786 GET 
> http://www.microsoft.com/security/encyclopedia/adlpackages.aspx? - 
> ORIGINAL_DST/23.203.90.59 text/html
> 1467029288.422     48 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 13.90.208.215:443 - ORIGINAL_DST/13.90.208.215 -
> 1467029288.882    311 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 104.41.32.78:443 - ORIGINAL_DST/104.41.32.78 -
>
>
>
>
>
>
>
>
>
>
>
>
> Any Help ????
>
> *
> *
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160628/e281c13d/attachment.htm>

From yvoinov at gmail.com  Tue Jun 28 08:00:12 2016
From: yvoinov at gmail.com (Yuri)
Date: Tue, 28 Jun 2016 14:00:12 +0600
Subject: [squid-users] squid with HTTPS and some APPs not working
In-Reply-To: <EB9E6998-A8D4-48D0-86B6-D53BA1953D75@netstream.ps>
References: <EB9E6998-A8D4-48D0-86B6-D53BA1953D75@netstream.ps>
Message-ID: <8840f7dd-cf2f-3077-9f44-1446480d5eab@gmail.com>



28.06.2016 13:39, --Ahmad-- ?????:
> Hi ,
> i have squid that is working on 3.5 .
>
> traffic of t 80 and 443 traffic to Squid via IPTables.
>
> Squid then passes traffic to ClamAV via C-ICAP. Squid is configured to 
> intercept all SSL traffic and PKI has been setup and distributed to 
> all clients.
>
> we have a problem in  Skype of Business (Office 365) and Slack (Chat 
> app)  seems its broken from squid intercept.
>
>
> i tried to do exception for ssl for the domains that shown on the 
> ACCess.log file when i use the APPs , but no luck
>
> i tried to execlide the websites below :
>
> skype.com <http://skype.com>
> lync.com
> todyl.com
> fastly\.net
> .slack-msgs.com
> .amazonaws.com
> .slack.com <http://slack.com>
>
>
> #########################################################
> but  it still not working and the APPS (( Skype of Business (Office 
> 365) and Slack (Chat app))) are not working .
>
> again , here is my nobump file :
>
>
> cat /opt/etc/squid.doms.nobump
>
> \.skype\.com$
> \.lync\.com$
> \.todyl\.com$
> \.fastly\.net$
> \.slack-msgs\.com$
> \.amazonaws\.com$
> \.slack\.com$
>
> ##############################################################
>
> current versions we have :
>
> ?Squid 3.5.19
>
> ?C-ICAP 0.4.2
>
> ?SquidclamAV 6.15
>
> ?ClamAV 0.99.2
>
> ######################################################################
>
>   here is squid.conf :
>
> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl localnet src 10.0.0.0/8# RFC1918 possible internal network
>
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
> http_access allow localhost manager
> http_access deny manager
>
> # Squid normally listens to port 3128
> http_port 3127
> http_port 3128 intercept
>
> # Leave coredumps in the first cache dir
> coredump_dir /var/cache/squid
>
> visible_hostname shield.TodylInc.shield
>
> cache_log /opt/var/log/squid/cache_log
> cache_access_log /opt/var/log/squid/access_log
>
> #user and group
> cache_effective_user squid
> cache_effective_group squid
>
> acl todyl dstdomaintodyl.com <http://todyl.com>
> request_header_add X-TODYL-GUID 1e46dccd2 todyl
>
> #Custom Error Pages
> error_directory /opt/www/squid
>
> # Squid listen Port
> https_port 3129 intercept ssl-bump generate-host-certificates=on 
> dynamic_cert_mem_cache_size=4MB key=/opt/etc/pki/squid/ca-key.pem 
> cert=/opt/etc/pki/squid/ca.pem options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE

Search list "Skype issue" thread, some day ago.

>
> # SSL Bump Config
> always_direct allow all
> ssl_bump server-first all
> sslcrtd_program /opt/libexec/ssl_crtd -s /opt/lib/ssl_db -M 4MB
> sslcrtd_children 32 startup=5 idle=1
>
> ##############################################
> acl DiscoverSNIHost at_step SslBump1
> acl NoSSLIntercept ssl::server_name_regex -i "/opt/etc/squid.doms.nobump"
> ssl_bump splice NoSSLIntercept
> ssl_bump peek DiscoverSNIHost
> ssl_bump bump all
> ##################
>
> #Hardening
> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE

#                SINGLE_ECDH_USE
#                      Enable ephemeral ECDH key exchange.
#                      The adopted curve should be specified
#                      using the tls-dh option.


#       tls-dh=[curve:]file
#            File containing DH parameters for temporary/ephemeral DH key
#            exchanges, optionally prefixed by a curve for ephemeral ECDH
#            key exchanges.
#            See OpenSSL documentation for details on how to create the
#            DH parameter file. Supported curves for ECDH can be listed
#            using the "openssl ecparam -list_curves" command.
#            WARNING: EDH and EECDH ciphers will be silently disabled if
#                 this option is not set.

> sslproxy_cipher 
> EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

#       tls-dh=[curve:]file
#            File containing DH parameters for temporary/ephemeral DH key
#            exchanges, optionally prefixed by a curve for ephemeral ECDH
#            key exchanges.
#            See OpenSSL documentation for details on how to create the
#            DH parameter file. Supported curves for ECDH can be listed
#            using the "openssl ecparam -list_curves" command.
#            WARNING: EDH and EECDH ciphers will be silently disabled if
#                 this option is not set.

>
> # TUNING
> cache_dir aufs /var/cache/squid 40000 16 256
> store_dir_select_algorithm round-robin
> minimum_object_size 0 KB
> maximum_object_size 96 MB
> memory_pools off
> quick_abort_min 0 KB
> quick_abort_max 0 KB
> log_icp_queries off
> client_db off
> cache_mem 1500 MB
> buffered_logs on
> half_closed_clients off
>
> dns_nameservers 10.192.0.1
> ##################################################################
>
>
> here is squid -k parse :
>
> [root at 1e46dccd2 var]# squid -k parse
> 2016/06/27 08:06:08| Startup: Initializing Authentication Schemes ...
> 2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 'basic'
> 2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 'digest'
> 2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 
> 'negotiate'
> 2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 'ntlm'
> 2016/06/27 08:06:08| Startup: Initialized Authentication.
> 2016/06/27 08:06:08| Processing Configuration File: 
> /opt/etc/squid.conf (depth 0)
> 2016/06/27 08:06:08| Processing: acl localnet src 10.0.0.0/8 # RFC1918 
> possible internal network
> 2016/06/27 08:06:08| Processing: http_access allow localnet
> 2016/06/27 08:06:08| Processing: http_access allow localhost
> 2016/06/27 08:06:08| Processing: http_access allow localhost manager
> 2016/06/27 08:06:08| Processing: http_access deny manager
> 2016/06/27 08:06:08| Processing: http_port 3127
> 2016/06/27 08:06:08| Processing: http_port 3128 intercept
> 2016/06/27 08:06:08| Starting Authentication on port [::]:3128
> 2016/06/27 08:06:08| Disabling Authentication on port [::]:3128 
> (interception enabled)
> 2016/06/27 08:06:08| Processing: coredump_dir /var/cache/squid
> 2016/06/27 08:06:08| Processing: visible_hostname shield.TodylInc.shield
> 2016/06/27 08:06:08| Processing: cache_log /opt/var/log/squid/cache_log
> 2016/06/27 08:06:08| Processing: cache_access_log 
> /opt/var/log/squid/access_log
> 2016/06/27 08:06:08| Processing: cache_effective_user squid
> 2016/06/27 08:06:08| Processing: cache_effective_group squid
> 2016/06/27 08:06:08| Processing: acl todyl dstdomain todyl.com 
> <http://todyl.com>
> 2016/06/27 08:06:08| Processing: request_header_add X-TODYL-GUID 
> 1e46dccd2 todyl
> 2016/06/27 08:06:08| Processing: error_directory /opt/www/squid
> 2016/06/27 08:06:08| Processing: https_port 3129 intercept ssl-bump 
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
> key=/opt/etc/pki/squid/ca-key.pem cert=/opt/etc/pki/squid/ca.pem 
> options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
> 2016/06/27 08:06:08| Starting Authentication on port [::]:3129
> 2016/06/27 08:06:08| Disabling Authentication on port [::]:3129 
> (interception enabled)
> 2016/06/27 08:06:08| Processing: always_direct allow all
> 2016/06/27 08:06:08| Processing: ssl_bump server-first all
> 2016/06/27 08:06:08| Processing: sslcrtd_program /opt/libexec/ssl_crtd 
> -s /opt/lib/ssl_db -M 4MB
> 2016/06/27 08:06:08| Processing: sslcrtd_children 32 startup=5 idle=1
> 2016/06/27 08:06:08| Processing: acl DiscoverSNIHost at_step SslBump1
> 2016/06/27 08:06:08| Processing: acl NoSSLIntercept 
> ssl::server_name_regex -i "/opt/etc/squid.doms.nobump"
> 2016/06/27 08:06:08| Processing: ssl_bump splice NoSSLIntercept
> 2016/06/27 08:06:08| Processing: ssl_bump peek DiscoverSNIHost
> 2016/06/27 08:06:08| Processing: ssl_bump bump all
> 2016/06/27 08:06:08| Processing: sslproxy_options 
> NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> 2016/06/27 08:06:08| Processing: sslproxy_cipher 
> EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> 2016/06/27 08:06:08| Processing: cache_dir aufs /var/cache/squid 40000 
> 16 256
> 2016/06/27 08:06:08| Processing: store_dir_select_algorithm round-robin
> 2016/06/27 08:06:08| Processing: minimum_object_size 0 KB
> 2016/06/27 08:06:08| Processing: maximum_object_size 96 MB
> 2016/06/27 08:06:08| Processing: memory_pools off
> 2016/06/27 08:06:08| Processing: quick_abort_min 0 KB
> 2016/06/27 08:06:08| Processing: quick_abort_max 0 KB
> 2016/06/27 08:06:08| Processing: log_icp_queries off
> 2016/06/27 08:06:08| Processing: client_db off
> 2016/06/27 08:06:08| Processing: cache_mem 1500 MB
> 2016/06/27 08:06:08| Processing: buffered_logs on
> 2016/06/27 08:06:08| Processing: half_closed_clients off
> 2016/06/27 08:06:08| Processing: dns_nameservers 10.192.0.1
> 2016/06/27 08:06:08| Initializing https proxy context
> 2016/06/27 08:06:08| Initializing https_port [::]:3129 SSL context
> 2016/06/27 08:06:08| Using certificate in /opt/etc/pki/squid/ca.pem
> ?????????????????????????????????
>
>
>
> here is access.log
>
>
> 1467029265.989     50 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 52.84.29.139:443 - ORIGINAL_DST/52.84.29.139 -
> 1467029265.999     59 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 52.84.29.139:443 - ORIGINAL_DST/52.84.29.139 -
> 1467029266.070     59 10.192.0.12 TCP_MISS/200 13171 GET 
> https://slack.com/help/test - ORIGINAL_DST/52.84.29.139 text/html
> 1467029266.222     53 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 172.217.5.14:443 - ORIGINAL_DST/172.217.5.14 -
> 1467029266.234     66 10.192.0.12 TCP_MISS/200 598 GET 
> https://slack.com/beacon/track/? - ORIGINAL_DST/52.84.29.139 image/gif
> 1467029266.274     26 10.192.0.12 TCP_MISS/200 557 GET 
> https://www.google-analytics.com/r/collect? - 
> ORIGINAL_DST/172.217.5.14 image/gif
> 1467029266.314     66 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 169.54.33.172:443 - ORIGINAL_DST/169.54.33.172 -
> 1467029266.368     21 10.192.0.12 TCP_MISS/200 547 GET 
> https://api.mixpanel.com/track/? - ORIGINAL_DST/169.54.33.172 
> application/json
> 1467029266.469     42 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 199.27.76.249:443 - ORIGINAL_DST/199.27.76.249 -
> 1467029266.722    231 10.192.0.12 TCP_MISS/200 11968 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-0.png? - 
> ORIGINAL_DST/199.27.76.249 image/png
> 1467029267.044    303 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 54.231.161.8:443 - ORIGINAL_DST/54.231.161.8 -
> 1467029267.231    170 10.192.0.12 TCP_MISS/200 11994 GET 
> https://s3-us-west-2.amazonaws.com/slack-files2/beacons/boomerang1/image-0.png? 
> - ORIGINAL_DST/54.231.161.8 image/png
> 1467029267.482    145 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 54.172.232.15:443 - ORIGINAL_DST/54.172.232.15 -
> 1467029267.563     63 10.192.0.12 TCP_MISS_ABORTED/000 0 GET 
> https://mpmulti-y6oq.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_ 
> - ORIGINAL_DST/54.172.232.15 -
> 1467029267.771    167 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 52.91.147.164:443 - ORIGINAL_DST/52.91.147.164 -
> 1467029267.891    110 10.192.0.12 TCP_MISS_ABORTED/000 0 GET 
> https://mpmulti-f4bz.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_ 
> - ORIGINAL_DST/52.91.147.164 -
> 1467029268.106    153 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 52.23.253.30:443 - ORIGINAL_DST/52.23.253.30 -
> 1467029268.194     79 10.192.0.12 TCP_MISS_ABORTED/000 0 GET 
> https://mpmulti-zdjz.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_ 
> - ORIGINAL_DST/52.23.253.30 -
> 1467029268.449    160 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 52.201.253.102:443 - ORIGINAL_DST/52.201.253.102 -
> 1467029268.567    110 10.192.0.12 TCP_MISS_ABORTED/000 0 GET 
> https://mpmulti-2pbf.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_ 
> - ORIGINAL_DST/52.201.253.102 -
> 1467029268.764    149 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 52.91.121.224:443 - ORIGINAL_DST/52.91.121.224 -
> 1467029268.845     74 10.192.0.12 TCP_MISS_ABORTED/000 0 GET 
> https://mpmulti-x1if.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_ 
> - ORIGINAL_DST/52.91.121.224 -
> 1467029268.967    108 10.192.0.12 TCP_MISS/200 516 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029269.169    187 10.192.0.12 TCP_MISS/200 517 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029269.285    101 10.192.0.12 TCP_MISS/200 516 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029269.467    167 10.192.0.12 TCP_MISS/200 517 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029269.643    160 10.192.0.12 TCP_MISS/200 517 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029269.824    165 10.192.0.12 TCP_MISS/200 517 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029270.004    164 10.192.0.12 TCP_MISS/200 517 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029270.186    165 10.192.0.12 TCP_MISS/200 517 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029270.295     94 10.192.0.12 TCP_MISS/200 516 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029270.489    173 10.192.0.12 TCP_MISS/200 517 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? - 
> ORIGINAL_DST/199.27.76.249 image/gif
> 1467029270.656    151 10.192.0.12 TCP_MISS_ABORTED/000 0 GET 
> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-0.png? - 
> ORIGINAL_DST/199.27.76.249 -
> 1467029273.699     57 10.192.0.12 TCP_MISS/200 951 GET 
> http://lyncdiscover.todyl.com/? - ORIGINAL_DST/131.253.163.205 
> application/vnd.microsoft.rtc.autodiscover+xml
> 1467029273.713     72 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.163.205:443 - ORIGINAL_DST/131.253.163.205 -
> 1467029273.797     73 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
> 1467029273.874     70 10.192.0.12 TCP_MISS/200 1453 GET 
> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root? 
> - ORIGINAL_DST/131.253.161.142 
> application/vnd.microsoft.rtc.autodiscover+xml
> 1467029273.952     74 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
> 1467029273.985     25 10.192.0.12 TCP_MISS/401 2206 GET 
> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user? 
> - ORIGINAL_DST/131.253.161.142 text/html
> 1467029274.077     76 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
> 1467029274.217    132 10.192.0.12 TCP_MISS/200 18842 POST 
> https://webdir2a.online.lync.com/WebTicket/WebTicketService.svc/mex - 
> ORIGINAL_DST/131.253.161.142 application/soap+xml
> 1467029274.430    152 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 23.96.208.238:443 - ORIGINAL_DST/23.96.208.238 -
> 1467029274.631    180 10.192.0.12 TCP_MISS/200 16835 POST 
> https://login.microsoftonline.com/RST2.srf - 
> ORIGINAL_DST/23.96.208.238 application/soap+xml
> 1467029274.720     75 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
> 1467029274.858    131 10.192.0.12 TCP_MISS/200 6107 POST 
> https://webdir2a.online.lync.com/WebTicket/WebTicketAdvancedService.svc/WsFed_bearer 
> - ORIGINAL_DST/131.253.161.142 text/xml
> 1467029274.936     73 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
> 1467029274.998     55 10.192.0.12 TCP_MISS/200 2507 GET 
> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user? 
> - ORIGINAL_DST/131.253.161.142 
> application/vnd.microsoft.rtc.autodiscover+xml
> 1467029275.099     72 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.139:443 - ORIGINAL_DST/131.253.161.139 -
> 1467029275.216     70 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.147:443 - ORIGINAL_DST/131.253.161.147 -
> 1467029275.524    107 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 134.170.113.218:443 - ORIGINAL_DST/134.170.113.218 -
> 1467029279.731     24 10.192.0.12 TCP_MISS/200 951 GET 
> http://lyncdiscover.todyl.com/? - ORIGINAL_DST/131.253.163.205 
> application/vnd.microsoft.rtc.autodiscover+xml
> 1467029279.778     71 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.163.205:443 - ORIGINAL_DST/131.253.163.205 -
> 1467029279.814     76 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
> 1467029279.847     27 10.192.0.12 TCP_MISS/200 1453 GET 
> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root? 
> - ORIGINAL_DST/131.253.161.142 
> application/vnd.microsoft.rtc.autodiscover+xml
> 1467029279.922     70 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
> 1467029279.952     24 10.192.0.12 TCP_MISS/401 2206 GET 
> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user? 
> - ORIGINAL_DST/131.253.161.142 text/html
> 1467029280.032     73 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
> 1467029280.092     54 10.192.0.12 TCP_MISS/200 2507 GET 
> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user? 
> - ORIGINAL_DST/131.253.161.142 
> application/vnd.microsoft.rtc.autodiscover+xml
> 1467029280.180     73 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.139:443 - ORIGINAL_DST/131.253.161.139 -
> 1467029280.270     73 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.161.147:443 - ORIGINAL_DST/131.253.161.147 -
> 1467029280.396    107 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 134.170.113.218:443 - ORIGINAL_DST/134.170.113.218 -
> 1467029287.555     75 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
> 1467029287.673     92 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
> 1467029287.681     41 10.192.0.12 TCP_MISS/200 607 GET 
> http://login.live.com/ppcrlcheck.srf - ORIGINAL_DST/131.253.61.68 
> text/html
> 1467029287.729     41 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
> 1467029287.784     46 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
> 1467029287.801     92 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 131.253.61.68:443 - ORIGINAL_DST/131.253.61.68 -
> 1467029287.859     61 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
> 1467029287.926     52 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
> 1467029287.964    134 10.192.0.12 TCP_MISS/200 10828 POST 
> https://login.live.com/RST2.srf - ORIGINAL_DST/131.253.61.68 
> application/soap+xml
> 1467029287.998     56 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
> 1467029288.051     40 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
> 1467029288.204     46 10.192.0.12 TCP_MISS/302 538 GET 
> http://go.microsoft.com/fwlink/? - ORIGINAL_DST/23.66.120.244 -
> 1467029288.389    147 10.192.0.12 TCP_MISS/302 1786 GET 
> http://www.microsoft.com/security/encyclopedia/adlpackages.aspx? - 
> ORIGINAL_DST/23.203.90.59 text/html
> 1467029288.422     48 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 13.90.208.215:443 - ORIGINAL_DST/13.90.208.215 -
> 1467029288.882    311 10.192.0.12 TAG_NONE/200 0 CONNECT 
> 104.41.32.78:443 - ORIGINAL_DST/104.41.32.78 -
>
>
>
>
>
>
>
>
>
>
>
>
> Any Help ????
Finally. Where is you specify following parameters in squid.conf:

sslproxy_cafile /usr/local/squid/etc/ca-bundle.crt
sslproxy_foreign_intermediate_certs /usr/local/squid/etc/intermediate_ca.pem

???

>
> *
> *
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160628/91929761/attachment.htm>

From anand at visolve.com  Tue Jun 28 08:31:35 2016
From: anand at visolve.com (Anand Palani)
Date: Tue, 28 Jun 2016 14:01:35 +0530
Subject: [squid-users] squid-users Digest, Vol 22, Issue 136
In-Reply-To: <mailman.621.1467100807.2992.squid-users@lists.squid-cache.org>
References: <mailman.621.1467100807.2992.squid-users@lists.squid-cache.org>
Message-ID: <19d5480d-e66c-6897-e548-f59d641559bd@visolve.com>

Hello,

can you use some IP address instead of domain names (skype.com & 
chatapp) for No SSLBUMP.


On 6/28/2016 1:30 PM, squid-users-request at lists.squid-cache.org wrote:
> Send squid-users mailing list submissions to
> 	squid-users at lists.squid-cache.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
> 	http://lists.squid-cache.org/listinfo/squid-users
> or, via email, send a message with subject or body 'help' to
> 	squid-users-request at lists.squid-cache.org
>
> You can reach the person managing the list at
> 	squid-users-owner at lists.squid-cache.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of squid-users digest..."
>
>
> Today's Topics:
>
>     1. Re: squid with HTTPS and some APPs not working (Yuri)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Tue, 28 Jun 2016 14:00:12 +0600
> From: Yuri <yvoinov at gmail.com>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] squid with HTTPS and some APPs not working
> Message-ID: <8840f7dd-cf2f-3077-9f44-1446480d5eab at gmail.com>
> Content-Type: text/plain; charset="utf-8"; Format="flowed"
>
>
>
> 28.06.2016 13:39, --Ahmad-- ?????:
>> Hi ,
>> i have squid that is working on 3.5 .
>>
>> traffic of t 80 and 443 traffic to Squid via IPTables.
>>
>> Squid then passes traffic to ClamAV via C-ICAP. Squid is configured to
>> intercept all SSL traffic and PKI has been setup and distributed to
>> all clients.
>>
>> we have a problem in  Skype of Business (Office 365) and Slack (Chat
>> app)  seems its broken from squid intercept.
>>
>>
>> i tried to do exception for ssl for the domains that shown on the
>> ACCess.log file when i use the APPs , but no luck
>>
>> i tried to execlide the websites below :
>>
>> skype.com <http://skype.com>
>> lync.com
>> todyl.com
>> fastly\.net
>> .slack-msgs.com
>> .amazonaws.com
>> .slack.com <http://slack.com>
>>
>>
>> #########################################################
>> but  it still not working and the APPS (( Skype of Business (Office
>> 365) and Slack (Chat app))) are not working .
>>
>> again , here is my nobump file :
>>
>>
>> cat /opt/etc/squid.doms.nobump
>>
>> \.skype\.com$
>> \.lync\.com$
>> \.todyl\.com$
>> \.fastly\.net$
>> \.slack-msgs\.com$
>> \.amazonaws\.com$
>> \.slack\.com$
>>
>> ##############################################################
>>
>> current versions we have :
>>
>> ?Squid 3.5.19
>>
>> ?C-ICAP 0.4.2
>>
>> ?SquidclamAV 6.15
>>
>> ?ClamAV 0.99.2
>>
>> ######################################################################
>>
>>    here is squid.conf :
>>
>> # Example rule allowing access from your local networks.
>> # Adapt to list your (internal) IP networks from where browsing
>> # should be allowed
>> acl localnet src 10.0.0.0/8# RFC1918 possible internal network
>>
>> # Example rule allowing access from your local networks.
>> # Adapt localnet in the ACL section to list your (internal) IP networks
>> # from where browsing should be allowed
>> http_access allow localnet
>> http_access allow localhost
>> http_access allow localhost manager
>> http_access deny manager
>>
>> # Squid normally listens to port 3128
>> http_port 3127
>> http_port 3128 intercept
>>
>> # Leave coredumps in the first cache dir
>> coredump_dir /var/cache/squid
>>
>> visible_hostname shield.TodylInc.shield
>>
>> cache_log /opt/var/log/squid/cache_log
>> cache_access_log /opt/var/log/squid/access_log
>>
>> #user and group
>> cache_effective_user squid
>> cache_effective_group squid
>>
>> acl todyl dstdomaintodyl.com <http://todyl.com>
>> request_header_add X-TODYL-GUID 1e46dccd2 todyl
>>
>> #Custom Error Pages
>> error_directory /opt/www/squid
>>
>> # Squid listen Port
>> https_port 3129 intercept ssl-bump generate-host-certificates=on
>> dynamic_cert_mem_cache_size=4MB key=/opt/etc/pki/squid/ca-key.pem
>> cert=/opt/etc/pki/squid/ca.pem options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
> Search list "Skype issue" thread, some day ago.
>
>> # SSL Bump Config
>> always_direct allow all
>> ssl_bump server-first all
>> sslcrtd_program /opt/libexec/ssl_crtd -s /opt/lib/ssl_db -M 4MB
>> sslcrtd_children 32 startup=5 idle=1
>>
>> ##############################################
>> acl DiscoverSNIHost at_step SslBump1
>> acl NoSSLIntercept ssl::server_name_regex -i "/opt/etc/squid.doms.nobump"
>> ssl_bump splice NoSSLIntercept
>> ssl_bump peek DiscoverSNIHost
>> ssl_bump bump all
>> ##################
>>
>> #Hardening
>> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
> #                SINGLE_ECDH_USE
> #                      Enable ephemeral ECDH key exchange.
> #                      The adopted curve should be specified
> #                      using the tls-dh option.
>
>
> #       tls-dh=[curve:]file
> #            File containing DH parameters for temporary/ephemeral DH key
> #            exchanges, optionally prefixed by a curve for ephemeral ECDH
> #            key exchanges.
> #            See OpenSSL documentation for details on how to create the
> #            DH parameter file. Supported curves for ECDH can be listed
> #            using the "openssl ecparam -list_curves" command.
> #            WARNING: EDH and EECDH ciphers will be silently disabled if
> #                 this option is not set.
>
>> sslproxy_cipher
>> EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> #       tls-dh=[curve:]file
> #            File containing DH parameters for temporary/ephemeral DH key
> #            exchanges, optionally prefixed by a curve for ephemeral ECDH
> #            key exchanges.
> #            See OpenSSL documentation for details on how to create the
> #            DH parameter file. Supported curves for ECDH can be listed
> #            using the "openssl ecparam -list_curves" command.
> #            WARNING: EDH and EECDH ciphers will be silently disabled if
> #                 this option is not set.
>
>> # TUNING
>> cache_dir aufs /var/cache/squid 40000 16 256
>> store_dir_select_algorithm round-robin
>> minimum_object_size 0 KB
>> maximum_object_size 96 MB
>> memory_pools off
>> quick_abort_min 0 KB
>> quick_abort_max 0 KB
>> log_icp_queries off
>> client_db off
>> cache_mem 1500 MB
>> buffered_logs on
>> half_closed_clients off
>>
>> dns_nameservers 10.192.0.1
>> ##################################################################
>>
>>
>> here is squid -k parse :
>>
>> [root at 1e46dccd2 var]# squid -k parse
>> 2016/06/27 08:06:08| Startup: Initializing Authentication Schemes ...
>> 2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 'basic'
>> 2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 'digest'
>> 2016/06/27 08:06:08| Startup: Initialized Authentication Scheme
>> 'negotiate'
>> 2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 'ntlm'
>> 2016/06/27 08:06:08| Startup: Initialized Authentication.
>> 2016/06/27 08:06:08| Processing Configuration File:
>> /opt/etc/squid.conf (depth 0)
>> 2016/06/27 08:06:08| Processing: acl localnet src 10.0.0.0/8 # RFC1918
>> possible internal network
>> 2016/06/27 08:06:08| Processing: http_access allow localnet
>> 2016/06/27 08:06:08| Processing: http_access allow localhost
>> 2016/06/27 08:06:08| Processing: http_access allow localhost manager
>> 2016/06/27 08:06:08| Processing: http_access deny manager
>> 2016/06/27 08:06:08| Processing: http_port 3127
>> 2016/06/27 08:06:08| Processing: http_port 3128 intercept
>> 2016/06/27 08:06:08| Starting Authentication on port [::]:3128
>> 2016/06/27 08:06:08| Disabling Authentication on port [::]:3128
>> (interception enabled)
>> 2016/06/27 08:06:08| Processing: coredump_dir /var/cache/squid
>> 2016/06/27 08:06:08| Processing: visible_hostname shield.TodylInc.shield
>> 2016/06/27 08:06:08| Processing: cache_log /opt/var/log/squid/cache_log
>> 2016/06/27 08:06:08| Processing: cache_access_log
>> /opt/var/log/squid/access_log
>> 2016/06/27 08:06:08| Processing: cache_effective_user squid
>> 2016/06/27 08:06:08| Processing: cache_effective_group squid
>> 2016/06/27 08:06:08| Processing: acl todyl dstdomain todyl.com
>> <http://todyl.com>
>> 2016/06/27 08:06:08| Processing: request_header_add X-TODYL-GUID
>> 1e46dccd2 todyl
>> 2016/06/27 08:06:08| Processing: error_directory /opt/www/squid
>> 2016/06/27 08:06:08| Processing: https_port 3129 intercept ssl-bump
>> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>> key=/opt/etc/pki/squid/ca-key.pem cert=/opt/etc/pki/squid/ca.pem
>> options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>> 2016/06/27 08:06:08| Starting Authentication on port [::]:3129
>> 2016/06/27 08:06:08| Disabling Authentication on port [::]:3129
>> (interception enabled)
>> 2016/06/27 08:06:08| Processing: always_direct allow all
>> 2016/06/27 08:06:08| Processing: ssl_bump server-first all
>> 2016/06/27 08:06:08| Processing: sslcrtd_program /opt/libexec/ssl_crtd
>> -s /opt/lib/ssl_db -M 4MB
>> 2016/06/27 08:06:08| Processing: sslcrtd_children 32 startup=5 idle=1
>> 2016/06/27 08:06:08| Processing: acl DiscoverSNIHost at_step SslBump1
>> 2016/06/27 08:06:08| Processing: acl NoSSLIntercept
>> ssl::server_name_regex -i "/opt/etc/squid.doms.nobump"
>> 2016/06/27 08:06:08| Processing: ssl_bump splice NoSSLIntercept
>> 2016/06/27 08:06:08| Processing: ssl_bump peek DiscoverSNIHost
>> 2016/06/27 08:06:08| Processing: ssl_bump bump all
>> 2016/06/27 08:06:08| Processing: sslproxy_options
>> NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>> 2016/06/27 08:06:08| Processing: sslproxy_cipher
>> EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>> 2016/06/27 08:06:08| Processing: cache_dir aufs /var/cache/squid 40000
>> 16 256
>> 2016/06/27 08:06:08| Processing: store_dir_select_algorithm round-robin
>> 2016/06/27 08:06:08| Processing: minimum_object_size 0 KB
>> 2016/06/27 08:06:08| Processing: maximum_object_size 96 MB
>> 2016/06/27 08:06:08| Processing: memory_pools off
>> 2016/06/27 08:06:08| Processing: quick_abort_min 0 KB
>> 2016/06/27 08:06:08| Processing: quick_abort_max 0 KB
>> 2016/06/27 08:06:08| Processing: log_icp_queries off
>> 2016/06/27 08:06:08| Processing: client_db off
>> 2016/06/27 08:06:08| Processing: cache_mem 1500 MB
>> 2016/06/27 08:06:08| Processing: buffered_logs on
>> 2016/06/27 08:06:08| Processing: half_closed_clients off
>> 2016/06/27 08:06:08| Processing: dns_nameservers 10.192.0.1
>> 2016/06/27 08:06:08| Initializing https proxy context
>> 2016/06/27 08:06:08| Initializing https_port [::]:3129 SSL context
>> 2016/06/27 08:06:08| Using certificate in /opt/etc/pki/squid/ca.pem
>> ?????????????????????????????????
>>
>>
>>
>> here is access.log
>>
>>
>> 1467029265.989     50 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 52.84.29.139:443 - ORIGINAL_DST/52.84.29.139 -
>> 1467029265.999     59 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 52.84.29.139:443 - ORIGINAL_DST/52.84.29.139 -
>> 1467029266.070     59 10.192.0.12 TCP_MISS/200 13171 GET
>> https://slack.com/help/test - ORIGINAL_DST/52.84.29.139 text/html
>> 1467029266.222     53 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 172.217.5.14:443 - ORIGINAL_DST/172.217.5.14 -
>> 1467029266.234     66 10.192.0.12 TCP_MISS/200 598 GET
>> https://slack.com/beacon/track/? - ORIGINAL_DST/52.84.29.139 image/gif
>> 1467029266.274     26 10.192.0.12 TCP_MISS/200 557 GET
>> https://www.google-analytics.com/r/collect? -
>> ORIGINAL_DST/172.217.5.14 image/gif
>> 1467029266.314     66 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 169.54.33.172:443 - ORIGINAL_DST/169.54.33.172 -
>> 1467029266.368     21 10.192.0.12 TCP_MISS/200 547 GET
>> https://api.mixpanel.com/track/? - ORIGINAL_DST/169.54.33.172
>> application/json
>> 1467029266.469     42 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 199.27.76.249:443 - ORIGINAL_DST/199.27.76.249 -
>> 1467029266.722    231 10.192.0.12 TCP_MISS/200 11968 GET
>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-0.png? -
>> ORIGINAL_DST/199.27.76.249 image/png
>> 1467029267.044    303 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 54.231.161.8:443 - ORIGINAL_DST/54.231.161.8 -
>> 1467029267.231    170 10.192.0.12 TCP_MISS/200 11994 GET
>> https://s3-us-west-2.amazonaws.com/slack-files2/beacons/boomerang1/image-0.png?
>> - ORIGINAL_DST/54.231.161.8 image/png
>> 1467029267.482    145 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 54.172.232.15:443 - ORIGINAL_DST/54.172.232.15 -
>> 1467029267.563     63 10.192.0.12 TCP_MISS_ABORTED/000 0 GET
>> https://mpmulti-y6oq.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_
>> - ORIGINAL_DST/54.172.232.15 -
>> 1467029267.771    167 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 52.91.147.164:443 - ORIGINAL_DST/52.91.147.164 -
>> 1467029267.891    110 10.192.0.12 TCP_MISS_ABORTED/000 0 GET
>> https://mpmulti-f4bz.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_
>> - ORIGINAL_DST/52.91.147.164 -
>> 1467029268.106    153 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 52.23.253.30:443 - ORIGINAL_DST/52.23.253.30 -
>> 1467029268.194     79 10.192.0.12 TCP_MISS_ABORTED/000 0 GET
>> https://mpmulti-zdjz.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_
>> - ORIGINAL_DST/52.23.253.30 -
>> 1467029268.449    160 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 52.201.253.102:443 - ORIGINAL_DST/52.201.253.102 -
>> 1467029268.567    110 10.192.0.12 TCP_MISS_ABORTED/000 0 GET
>> https://mpmulti-2pbf.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_
>> - ORIGINAL_DST/52.201.253.102 -
>> 1467029268.764    149 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 52.91.121.224:443 - ORIGINAL_DST/52.91.121.224 -
>> 1467029268.845     74 10.192.0.12 TCP_MISS_ABORTED/000 0 GET
>> https://mpmulti-x1if.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_
>> - ORIGINAL_DST/52.91.121.224 -
>> 1467029268.967    108 10.192.0.12 TCP_MISS/200 516 GET
>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>> ORIGINAL_DST/199.27.76.249 image/gif
>> 1467029269.169    187 10.192.0.12 TCP_MISS/200 517 GET
>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>> ORIGINAL_DST/199.27.76.249 image/gif
>> 1467029269.285    101 10.192.0.12 TCP_MISS/200 516 GET
>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>> ORIGINAL_DST/199.27.76.249 image/gif
>> 1467029269.467    167 10.192.0.12 TCP_MISS/200 517 GET
>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>> ORIGINAL_DST/199.27.76.249 image/gif
>> 1467029269.643    160 10.192.0.12 TCP_MISS/200 517 GET
>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>> ORIGINAL_DST/199.27.76.249 image/gif
>> 1467029269.824    165 10.192.0.12 TCP_MISS/200 517 GET
>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>> ORIGINAL_DST/199.27.76.249 image/gif
>> 1467029270.004    164 10.192.0.12 TCP_MISS/200 517 GET
>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>> ORIGINAL_DST/199.27.76.249 image/gif
>> 1467029270.186    165 10.192.0.12 TCP_MISS/200 517 GET
>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>> ORIGINAL_DST/199.27.76.249 image/gif
>> 1467029270.295     94 10.192.0.12 TCP_MISS/200 516 GET
>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>> ORIGINAL_DST/199.27.76.249 image/gif
>> 1467029270.489    173 10.192.0.12 TCP_MISS/200 517 GET
>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>> ORIGINAL_DST/199.27.76.249 image/gif
>> 1467029270.656    151 10.192.0.12 TCP_MISS_ABORTED/000 0 GET
>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-0.png? -
>> ORIGINAL_DST/199.27.76.249 -
>> 1467029273.699     57 10.192.0.12 TCP_MISS/200 951 GET
>> http://lyncdiscover.todyl.com/? - ORIGINAL_DST/131.253.163.205
>> application/vnd.microsoft.rtc.autodiscover+xml
>> 1467029273.713     72 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 131.253.163.205:443 - ORIGINAL_DST/131.253.163.205 -
>> 1467029273.797     73 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
>> 1467029273.874     70 10.192.0.12 TCP_MISS/200 1453 GET
>> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root?
>> - ORIGINAL_DST/131.253.161.142
>> application/vnd.microsoft.rtc.autodiscover+xml
>> 1467029273.952     74 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
>> 1467029273.985     25 10.192.0.12 TCP_MISS/401 2206 GET
>> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user?
>> - ORIGINAL_DST/131.253.161.142 text/html
>> 1467029274.077     76 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
>> 1467029274.217    132 10.192.0.12 TCP_MISS/200 18842 POST
>> https://webdir2a.online.lync.com/WebTicket/WebTicketService.svc/mex -
>> ORIGINAL_DST/131.253.161.142 application/soap+xml
>> 1467029274.430    152 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 23.96.208.238:443 - ORIGINAL_DST/23.96.208.238 -
>> 1467029274.631    180 10.192.0.12 TCP_MISS/200 16835 POST
>> https://login.microsoftonline.com/RST2.srf -
>> ORIGINAL_DST/23.96.208.238 application/soap+xml
>> 1467029274.720     75 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
>> 1467029274.858    131 10.192.0.12 TCP_MISS/200 6107 POST
>> https://webdir2a.online.lync.com/WebTicket/WebTicketAdvancedService.svc/WsFed_bearer
>> - ORIGINAL_DST/131.253.161.142 text/xml
>> 1467029274.936     73 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
>> 1467029274.998     55 10.192.0.12 TCP_MISS/200 2507 GET
>> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user?
>> - ORIGINAL_DST/131.253.161.142
>> application/vnd.microsoft.rtc.autodiscover+xml
>> 1467029275.099     72 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 131.253.161.139:443 - ORIGINAL_DST/131.253.161.139 -
>> 1467029275.216     70 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 131.253.161.147:443 - ORIGINAL_DST/131.253.161.147 -
>> 1467029275.524    107 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 134.170.113.218:443 - ORIGINAL_DST/134.170.113.218 -
>> 1467029279.731     24 10.192.0.12 TCP_MISS/200 951 GET
>> http://lyncdiscover.todyl.com/? - ORIGINAL_DST/131.253.163.205
>> application/vnd.microsoft.rtc.autodiscover+xml
>> 1467029279.778     71 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 131.253.163.205:443 - ORIGINAL_DST/131.253.163.205 -
>> 1467029279.814     76 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
>> 1467029279.847     27 10.192.0.12 TCP_MISS/200 1453 GET
>> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root?
>> - ORIGINAL_DST/131.253.161.142
>> application/vnd.microsoft.rtc.autodiscover+xml
>> 1467029279.922     70 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
>> 1467029279.952     24 10.192.0.12 TCP_MISS/401 2206 GET
>> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user?
>> - ORIGINAL_DST/131.253.161.142 text/html
>> 1467029280.032     73 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
>> 1467029280.092     54 10.192.0.12 TCP_MISS/200 2507 GET
>> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user?
>> - ORIGINAL_DST/131.253.161.142
>> application/vnd.microsoft.rtc.autodiscover+xml
>> 1467029280.180     73 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 131.253.161.139:443 - ORIGINAL_DST/131.253.161.139 -
>> 1467029280.270     73 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 131.253.161.147:443 - ORIGINAL_DST/131.253.161.147 -
>> 1467029280.396    107 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 134.170.113.218:443 - ORIGINAL_DST/134.170.113.218 -
>> 1467029287.555     75 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
>> 1467029287.673     92 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
>> 1467029287.681     41 10.192.0.12 TCP_MISS/200 607 GET
>> http://login.live.com/ppcrlcheck.srf - ORIGINAL_DST/131.253.61.68
>> text/html
>> 1467029287.729     41 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
>> 1467029287.784     46 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
>> 1467029287.801     92 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 131.253.61.68:443 - ORIGINAL_DST/131.253.61.68 -
>> 1467029287.859     61 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
>> 1467029287.926     52 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
>> 1467029287.964    134 10.192.0.12 TCP_MISS/200 10828 POST
>> https://login.live.com/RST2.srf - ORIGINAL_DST/131.253.61.68
>> application/soap+xml
>> 1467029287.998     56 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
>> 1467029288.051     40 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
>> 1467029288.204     46 10.192.0.12 TCP_MISS/302 538 GET
>> http://go.microsoft.com/fwlink/? - ORIGINAL_DST/23.66.120.244 -
>> 1467029288.389    147 10.192.0.12 TCP_MISS/302 1786 GET
>> http://www.microsoft.com/security/encyclopedia/adlpackages.aspx? -
>> ORIGINAL_DST/23.203.90.59 text/html
>> 1467029288.422     48 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 13.90.208.215:443 - ORIGINAL_DST/13.90.208.215 -
>> 1467029288.882    311 10.192.0.12 TAG_NONE/200 0 CONNECT
>> 104.41.32.78:443 - ORIGINAL_DST/104.41.32.78 -
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>> Any Help ????
> Finally. Where is you specify following parameters in squid.conf:
>
> sslproxy_cafile /usr/local/squid/etc/ca-bundle.crt
> sslproxy_foreign_intermediate_certs /usr/local/squid/etc/intermediate_ca.pem
>
> ???
>
>> *
>> *
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160628/91929761/attachment.html>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> ------------------------------
>
> End of squid-users Digest, Vol 22, Issue 136
> ********************************************



From yvoinov at gmail.com  Tue Jun 28 08:36:18 2016
From: yvoinov at gmail.com (Yuri)
Date: Tue, 28 Jun 2016 14:36:18 +0600
Subject: [squid-users] squid-users Digest, Vol 22, Issue 136
In-Reply-To: <19d5480d-e66c-6897-e548-f59d641559bd@visolve.com>
References: <mailman.621.1467100807.2992.squid-users@lists.squid-cache.org>
 <19d5480d-e66c-6897-e548-f59d641559bd@visolve.com>
Message-ID: <65be13e7-2fff-6220-932e-67cd9ace0f57@gmail.com>



28.06.2016 14:31, Anand Palani ?????:
> Hello,
>
> can you use some IP address instead of domain names (skype.com & 
> chatapp) for No SSLBUMP.
This works only for squid 3.4. 3.5 and above uses different scheme to 
execute peek-n-splice/bump. IP addresses exists only at CONNECT phase.
>
>
> On 6/28/2016 1:30 PM, squid-users-request at lists.squid-cache.org wrote:
>> Send squid-users mailing list submissions to
>>     squid-users at lists.squid-cache.org
>>
>> To subscribe or unsubscribe via the World Wide Web, visit
>>     http://lists.squid-cache.org/listinfo/squid-users
>> or, via email, send a message with subject or body 'help' to
>>     squid-users-request at lists.squid-cache.org
>>
>> You can reach the person managing the list at
>>     squid-users-owner at lists.squid-cache.org
>>
>> When replying, please edit your Subject line so it is more specific
>> than "Re: Contents of squid-users digest..."
>>
>>
>> Today's Topics:
>>
>>     1. Re: squid with HTTPS and some APPs not working (Yuri)
>>
>>
>> ----------------------------------------------------------------------
>>
>> Message: 1
>> Date: Tue, 28 Jun 2016 14:00:12 +0600
>> From: Yuri <yvoinov at gmail.com>
>> To: squid-users at lists.squid-cache.org
>> Subject: Re: [squid-users] squid with HTTPS and some APPs not working
>> Message-ID: <8840f7dd-cf2f-3077-9f44-1446480d5eab at gmail.com>
>> Content-Type: text/plain; charset="utf-8"; Format="flowed"
>>
>>
>>
>> 28.06.2016 13:39, --Ahmad-- ?????:
>>> Hi ,
>>> i have squid that is working on 3.5 .
>>>
>>> traffic of t 80 and 443 traffic to Squid via IPTables.
>>>
>>> Squid then passes traffic to ClamAV via C-ICAP. Squid is configured to
>>> intercept all SSL traffic and PKI has been setup and distributed to
>>> all clients.
>>>
>>> we have a problem in  Skype of Business (Office 365) and Slack (Chat
>>> app)  seems its broken from squid intercept.
>>>
>>>
>>> i tried to do exception for ssl for the domains that shown on the
>>> ACCess.log file when i use the APPs , but no luck
>>>
>>> i tried to execlide the websites below :
>>>
>>> skype.com <http://skype.com>
>>> lync.com
>>> todyl.com
>>> fastly\.net
>>> .slack-msgs.com
>>> .amazonaws.com
>>> .slack.com <http://slack.com>
>>>
>>>
>>> #########################################################
>>> but  it still not working and the APPS (( Skype of Business (Office
>>> 365) and Slack (Chat app))) are not working .
>>>
>>> again , here is my nobump file :
>>>
>>>
>>> cat /opt/etc/squid.doms.nobump
>>>
>>> \.skype\.com$
>>> \.lync\.com$
>>> \.todyl\.com$
>>> \.fastly\.net$
>>> \.slack-msgs\.com$
>>> \.amazonaws\.com$
>>> \.slack\.com$
>>>
>>> ##############################################################
>>>
>>> current versions we have :
>>>
>>> ?Squid 3.5.19
>>>
>>> ?C-ICAP 0.4.2
>>>
>>> ?SquidclamAV 6.15
>>>
>>> ?ClamAV 0.99.2
>>>
>>> ######################################################################
>>>
>>>    here is squid.conf :
>>>
>>> # Example rule allowing access from your local networks.
>>> # Adapt to list your (internal) IP networks from where browsing
>>> # should be allowed
>>> acl localnet src 10.0.0.0/8# RFC1918 possible internal network
>>>
>>> # Example rule allowing access from your local networks.
>>> # Adapt localnet in the ACL section to list your (internal) IP networks
>>> # from where browsing should be allowed
>>> http_access allow localnet
>>> http_access allow localhost
>>> http_access allow localhost manager
>>> http_access deny manager
>>>
>>> # Squid normally listens to port 3128
>>> http_port 3127
>>> http_port 3128 intercept
>>>
>>> # Leave coredumps in the first cache dir
>>> coredump_dir /var/cache/squid
>>>
>>> visible_hostname shield.TodylInc.shield
>>>
>>> cache_log /opt/var/log/squid/cache_log
>>> cache_access_log /opt/var/log/squid/access_log
>>>
>>> #user and group
>>> cache_effective_user squid
>>> cache_effective_group squid
>>>
>>> acl todyl dstdomaintodyl.com <http://todyl.com>
>>> request_header_add X-TODYL-GUID 1e46dccd2 todyl
>>>
>>> #Custom Error Pages
>>> error_directory /opt/www/squid
>>>
>>> # Squid listen Port
>>> https_port 3129 intercept ssl-bump generate-host-certificates=on
>>> dynamic_cert_mem_cache_size=4MB key=/opt/etc/pki/squid/ca-key.pem
>>> cert=/opt/etc/pki/squid/ca.pem options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>> Search list "Skype issue" thread, some day ago.
>>
>>> # SSL Bump Config
>>> always_direct allow all
>>> ssl_bump server-first all
>>> sslcrtd_program /opt/libexec/ssl_crtd -s /opt/lib/ssl_db -M 4MB
>>> sslcrtd_children 32 startup=5 idle=1
>>>
>>> ##############################################
>>> acl DiscoverSNIHost at_step SslBump1
>>> acl NoSSLIntercept ssl::server_name_regex -i 
>>> "/opt/etc/squid.doms.nobump"
>>> ssl_bump splice NoSSLIntercept
>>> ssl_bump peek DiscoverSNIHost
>>> ssl_bump bump all
>>> ##################
>>>
>>> #Hardening
>>> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>> #                SINGLE_ECDH_USE
>> #                      Enable ephemeral ECDH key exchange.
>> #                      The adopted curve should be specified
>> #                      using the tls-dh option.
>>
>>
>> #       tls-dh=[curve:]file
>> #            File containing DH parameters for temporary/ephemeral DH 
>> key
>> #            exchanges, optionally prefixed by a curve for ephemeral 
>> ECDH
>> #            key exchanges.
>> #            See OpenSSL documentation for details on how to create the
>> #            DH parameter file. Supported curves for ECDH can be listed
>> #            using the "openssl ecparam -list_curves" command.
>> #            WARNING: EDH and EECDH ciphers will be silently disabled if
>> #                 this option is not set.
>>
>>> sslproxy_cipher
>>> EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS 
>>>
>> #       tls-dh=[curve:]file
>> #            File containing DH parameters for temporary/ephemeral DH 
>> key
>> #            exchanges, optionally prefixed by a curve for ephemeral 
>> ECDH
>> #            key exchanges.
>> #            See OpenSSL documentation for details on how to create the
>> #            DH parameter file. Supported curves for ECDH can be listed
>> #            using the "openssl ecparam -list_curves" command.
>> #            WARNING: EDH and EECDH ciphers will be silently disabled if
>> #                 this option is not set.
>>
>>> # TUNING
>>> cache_dir aufs /var/cache/squid 40000 16 256
>>> store_dir_select_algorithm round-robin
>>> minimum_object_size 0 KB
>>> maximum_object_size 96 MB
>>> memory_pools off
>>> quick_abort_min 0 KB
>>> quick_abort_max 0 KB
>>> log_icp_queries off
>>> client_db off
>>> cache_mem 1500 MB
>>> buffered_logs on
>>> half_closed_clients off
>>>
>>> dns_nameservers 10.192.0.1
>>> ##################################################################
>>>
>>>
>>> here is squid -k parse :
>>>
>>> [root at 1e46dccd2 var]# squid -k parse
>>> 2016/06/27 08:06:08| Startup: Initializing Authentication Schemes ...
>>> 2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 'basic'
>>> 2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 
>>> 'digest'
>>> 2016/06/27 08:06:08| Startup: Initialized Authentication Scheme
>>> 'negotiate'
>>> 2016/06/27 08:06:08| Startup: Initialized Authentication Scheme 'ntlm'
>>> 2016/06/27 08:06:08| Startup: Initialized Authentication.
>>> 2016/06/27 08:06:08| Processing Configuration File:
>>> /opt/etc/squid.conf (depth 0)
>>> 2016/06/27 08:06:08| Processing: acl localnet src 10.0.0.0/8 # RFC1918
>>> possible internal network
>>> 2016/06/27 08:06:08| Processing: http_access allow localnet
>>> 2016/06/27 08:06:08| Processing: http_access allow localhost
>>> 2016/06/27 08:06:08| Processing: http_access allow localhost manager
>>> 2016/06/27 08:06:08| Processing: http_access deny manager
>>> 2016/06/27 08:06:08| Processing: http_port 3127
>>> 2016/06/27 08:06:08| Processing: http_port 3128 intercept
>>> 2016/06/27 08:06:08| Starting Authentication on port [::]:3128
>>> 2016/06/27 08:06:08| Disabling Authentication on port [::]:3128
>>> (interception enabled)
>>> 2016/06/27 08:06:08| Processing: coredump_dir /var/cache/squid
>>> 2016/06/27 08:06:08| Processing: visible_hostname 
>>> shield.TodylInc.shield
>>> 2016/06/27 08:06:08| Processing: cache_log /opt/var/log/squid/cache_log
>>> 2016/06/27 08:06:08| Processing: cache_access_log
>>> /opt/var/log/squid/access_log
>>> 2016/06/27 08:06:08| Processing: cache_effective_user squid
>>> 2016/06/27 08:06:08| Processing: cache_effective_group squid
>>> 2016/06/27 08:06:08| Processing: acl todyl dstdomain todyl.com
>>> <http://todyl.com>
>>> 2016/06/27 08:06:08| Processing: request_header_add X-TODYL-GUID
>>> 1e46dccd2 todyl
>>> 2016/06/27 08:06:08| Processing: error_directory /opt/www/squid
>>> 2016/06/27 08:06:08| Processing: https_port 3129 intercept ssl-bump
>>> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>>> key=/opt/etc/pki/squid/ca-key.pem cert=/opt/etc/pki/squid/ca.pem
>>> options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>>> 2016/06/27 08:06:08| Starting Authentication on port [::]:3129
>>> 2016/06/27 08:06:08| Disabling Authentication on port [::]:3129
>>> (interception enabled)
>>> 2016/06/27 08:06:08| Processing: always_direct allow all
>>> 2016/06/27 08:06:08| Processing: ssl_bump server-first all
>>> 2016/06/27 08:06:08| Processing: sslcrtd_program /opt/libexec/ssl_crtd
>>> -s /opt/lib/ssl_db -M 4MB
>>> 2016/06/27 08:06:08| Processing: sslcrtd_children 32 startup=5 idle=1
>>> 2016/06/27 08:06:08| Processing: acl DiscoverSNIHost at_step SslBump1
>>> 2016/06/27 08:06:08| Processing: acl NoSSLIntercept
>>> ssl::server_name_regex -i "/opt/etc/squid.doms.nobump"
>>> 2016/06/27 08:06:08| Processing: ssl_bump splice NoSSLIntercept
>>> 2016/06/27 08:06:08| Processing: ssl_bump peek DiscoverSNIHost
>>> 2016/06/27 08:06:08| Processing: ssl_bump bump all
>>> 2016/06/27 08:06:08| Processing: sslproxy_options
>>> NO_SSLv2,NO_SSLv3,SINGLE_DH_USE,SINGLE_ECDH_USE
>>> 2016/06/27 08:06:08| Processing: sslproxy_cipher
>>> EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS 
>>>
>>> 2016/06/27 08:06:08| Processing: cache_dir aufs /var/cache/squid 40000
>>> 16 256
>>> 2016/06/27 08:06:08| Processing: store_dir_select_algorithm round-robin
>>> 2016/06/27 08:06:08| Processing: minimum_object_size 0 KB
>>> 2016/06/27 08:06:08| Processing: maximum_object_size 96 MB
>>> 2016/06/27 08:06:08| Processing: memory_pools off
>>> 2016/06/27 08:06:08| Processing: quick_abort_min 0 KB
>>> 2016/06/27 08:06:08| Processing: quick_abort_max 0 KB
>>> 2016/06/27 08:06:08| Processing: log_icp_queries off
>>> 2016/06/27 08:06:08| Processing: client_db off
>>> 2016/06/27 08:06:08| Processing: cache_mem 1500 MB
>>> 2016/06/27 08:06:08| Processing: buffered_logs on
>>> 2016/06/27 08:06:08| Processing: half_closed_clients off
>>> 2016/06/27 08:06:08| Processing: dns_nameservers 10.192.0.1
>>> 2016/06/27 08:06:08| Initializing https proxy context
>>> 2016/06/27 08:06:08| Initializing https_port [::]:3129 SSL context
>>> 2016/06/27 08:06:08| Using certificate in /opt/etc/pki/squid/ca.pem
>>> ?????????????????????????????????
>>>
>>>
>>>
>>> here is access.log
>>>
>>>
>>> 1467029265.989     50 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 52.84.29.139:443 - ORIGINAL_DST/52.84.29.139 -
>>> 1467029265.999     59 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 52.84.29.139:443 - ORIGINAL_DST/52.84.29.139 -
>>> 1467029266.070     59 10.192.0.12 TCP_MISS/200 13171 GET
>>> https://slack.com/help/test - ORIGINAL_DST/52.84.29.139 text/html
>>> 1467029266.222     53 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 172.217.5.14:443 - ORIGINAL_DST/172.217.5.14 -
>>> 1467029266.234     66 10.192.0.12 TCP_MISS/200 598 GET
>>> https://slack.com/beacon/track/? - ORIGINAL_DST/52.84.29.139 image/gif
>>> 1467029266.274     26 10.192.0.12 TCP_MISS/200 557 GET
>>> https://www.google-analytics.com/r/collect? -
>>> ORIGINAL_DST/172.217.5.14 image/gif
>>> 1467029266.314     66 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 169.54.33.172:443 - ORIGINAL_DST/169.54.33.172 -
>>> 1467029266.368     21 10.192.0.12 TCP_MISS/200 547 GET
>>> https://api.mixpanel.com/track/? - ORIGINAL_DST/169.54.33.172
>>> application/json
>>> 1467029266.469     42 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 199.27.76.249:443 - ORIGINAL_DST/199.27.76.249 -
>>> 1467029266.722    231 10.192.0.12 TCP_MISS/200 11968 GET
>>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-0.png? -
>>> ORIGINAL_DST/199.27.76.249 image/png
>>> 1467029267.044    303 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 54.231.161.8:443 - ORIGINAL_DST/54.231.161.8 -
>>> 1467029267.231    170 10.192.0.12 TCP_MISS/200 11994 GET
>>> https://s3-us-west-2.amazonaws.com/slack-files2/beacons/boomerang1/image-0.png? 
>>>
>>> - ORIGINAL_DST/54.231.161.8 image/png
>>> 1467029267.482    145 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 54.172.232.15:443 - ORIGINAL_DST/54.172.232.15 -
>>> 1467029267.563     63 10.192.0.12 TCP_MISS_ABORTED/000 0 GET
>>> https://mpmulti-y6oq.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_
>>> - ORIGINAL_DST/54.172.232.15 -
>>> 1467029267.771    167 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 52.91.147.164:443 - ORIGINAL_DST/52.91.147.164 -
>>> 1467029267.891    110 10.192.0.12 TCP_MISS_ABORTED/000 0 GET
>>> https://mpmulti-f4bz.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_
>>> - ORIGINAL_DST/52.91.147.164 -
>>> 1467029268.106    153 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 52.23.253.30:443 - ORIGINAL_DST/52.23.253.30 -
>>> 1467029268.194     79 10.192.0.12 TCP_MISS_ABORTED/000 0 GET
>>> https://mpmulti-zdjz.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_
>>> - ORIGINAL_DST/52.23.253.30 -
>>> 1467029268.449    160 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 52.201.253.102:443 - ORIGINAL_DST/52.201.253.102 -
>>> 1467029268.567    110 10.192.0.12 TCP_MISS_ABORTED/000 0 GET
>>> https://mpmulti-2pbf.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_
>>> - ORIGINAL_DST/52.201.253.102 -
>>> 1467029268.764    149 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 52.91.121.224:443 - ORIGINAL_DST/52.91.121.224 -
>>> 1467029268.845     74 10.192.0.12 TCP_MISS_ABORTED/000 0 GET
>>> https://mpmulti-x1if.slack-msgs.com/websocket/_CONNECTION_TEST_TOKEN_
>>> - ORIGINAL_DST/52.91.121.224 -
>>> 1467029268.967    108 10.192.0.12 TCP_MISS/200 516 GET
>>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>>> ORIGINAL_DST/199.27.76.249 image/gif
>>> 1467029269.169    187 10.192.0.12 TCP_MISS/200 517 GET
>>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>>> ORIGINAL_DST/199.27.76.249 image/gif
>>> 1467029269.285    101 10.192.0.12 TCP_MISS/200 516 GET
>>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>>> ORIGINAL_DST/199.27.76.249 image/gif
>>> 1467029269.467    167 10.192.0.12 TCP_MISS/200 517 GET
>>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>>> ORIGINAL_DST/199.27.76.249 image/gif
>>> 1467029269.643    160 10.192.0.12 TCP_MISS/200 517 GET
>>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>>> ORIGINAL_DST/199.27.76.249 image/gif
>>> 1467029269.824    165 10.192.0.12 TCP_MISS/200 517 GET
>>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>>> ORIGINAL_DST/199.27.76.249 image/gif
>>> 1467029270.004    164 10.192.0.12 TCP_MISS/200 517 GET
>>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>>> ORIGINAL_DST/199.27.76.249 image/gif
>>> 1467029270.186    165 10.192.0.12 TCP_MISS/200 517 GET
>>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>>> ORIGINAL_DST/199.27.76.249 image/gif
>>> 1467029270.295     94 10.192.0.12 TCP_MISS/200 516 GET
>>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>>> ORIGINAL_DST/199.27.76.249 image/gif
>>> 1467029270.489    173 10.192.0.12 TCP_MISS/200 517 GET
>>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-l.gif? -
>>> ORIGINAL_DST/199.27.76.249 image/gif
>>> 1467029270.656    151 10.192.0.12 TCP_MISS_ABORTED/000 0 GET
>>> https://slack.global.ssl.fastly.net/beacons/boomerang1/image-0.png? -
>>> ORIGINAL_DST/199.27.76.249 -
>>> 1467029273.699     57 10.192.0.12 TCP_MISS/200 951 GET
>>> http://lyncdiscover.todyl.com/? - ORIGINAL_DST/131.253.163.205
>>> application/vnd.microsoft.rtc.autodiscover+xml
>>> 1467029273.713     72 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 131.253.163.205:443 - ORIGINAL_DST/131.253.163.205 -
>>> 1467029273.797     73 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
>>> 1467029273.874     70 10.192.0.12 TCP_MISS/200 1453 GET
>>> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root? 
>>>
>>> - ORIGINAL_DST/131.253.161.142
>>> application/vnd.microsoft.rtc.autodiscover+xml
>>> 1467029273.952     74 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
>>> 1467029273.985     25 10.192.0.12 TCP_MISS/401 2206 GET
>>> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user? 
>>>
>>> - ORIGINAL_DST/131.253.161.142 text/html
>>> 1467029274.077     76 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
>>> 1467029274.217    132 10.192.0.12 TCP_MISS/200 18842 POST
>>> https://webdir2a.online.lync.com/WebTicket/WebTicketService.svc/mex -
>>> ORIGINAL_DST/131.253.161.142 application/soap+xml
>>> 1467029274.430    152 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 23.96.208.238:443 - ORIGINAL_DST/23.96.208.238 -
>>> 1467029274.631    180 10.192.0.12 TCP_MISS/200 16835 POST
>>> https://login.microsoftonline.com/RST2.srf -
>>> ORIGINAL_DST/23.96.208.238 application/soap+xml
>>> 1467029274.720     75 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
>>> 1467029274.858    131 10.192.0.12 TCP_MISS/200 6107 POST
>>> https://webdir2a.online.lync.com/WebTicket/WebTicketAdvancedService.svc/WsFed_bearer 
>>>
>>> - ORIGINAL_DST/131.253.161.142 text/xml
>>> 1467029274.936     73 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
>>> 1467029274.998     55 10.192.0.12 TCP_MISS/200 2507 GET
>>> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user? 
>>>
>>> - ORIGINAL_DST/131.253.161.142
>>> application/vnd.microsoft.rtc.autodiscover+xml
>>> 1467029275.099     72 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 131.253.161.139:443 - ORIGINAL_DST/131.253.161.139 -
>>> 1467029275.216     70 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 131.253.161.147:443 - ORIGINAL_DST/131.253.161.147 -
>>> 1467029275.524    107 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 134.170.113.218:443 - ORIGINAL_DST/134.170.113.218 -
>>> 1467029279.731     24 10.192.0.12 TCP_MISS/200 951 GET
>>> http://lyncdiscover.todyl.com/? - ORIGINAL_DST/131.253.163.205
>>> application/vnd.microsoft.rtc.autodiscover+xml
>>> 1467029279.778     71 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 131.253.163.205:443 - ORIGINAL_DST/131.253.163.205 -
>>> 1467029279.814     76 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
>>> 1467029279.847     27 10.192.0.12 TCP_MISS/200 1453 GET
>>> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root? 
>>>
>>> - ORIGINAL_DST/131.253.161.142
>>> application/vnd.microsoft.rtc.autodiscover+xml
>>> 1467029279.922     70 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
>>> 1467029279.952     24 10.192.0.12 TCP_MISS/401 2206 GET
>>> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user? 
>>>
>>> - ORIGINAL_DST/131.253.161.142 text/html
>>> 1467029280.032     73 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 131.253.161.142:443 - ORIGINAL_DST/131.253.161.142 -
>>> 1467029280.092     54 10.192.0.12 TCP_MISS/200 2507 GET
>>> https://webdir2a.online.lync.com/Autodiscover/AutodiscoverService.svc/root/user? 
>>>
>>> - ORIGINAL_DST/131.253.161.142
>>> application/vnd.microsoft.rtc.autodiscover+xml
>>> 1467029280.180     73 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 131.253.161.139:443 - ORIGINAL_DST/131.253.161.139 -
>>> 1467029280.270     73 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 131.253.161.147:443 - ORIGINAL_DST/131.253.161.147 -
>>> 1467029280.396    107 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 134.170.113.218:443 - ORIGINAL_DST/134.170.113.218 -
>>> 1467029287.555     75 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
>>> 1467029287.673     92 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
>>> 1467029287.681     41 10.192.0.12 TCP_MISS/200 607 GET
>>> http://login.live.com/ppcrlcheck.srf - ORIGINAL_DST/131.253.61.68
>>> text/html
>>> 1467029287.729     41 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
>>> 1467029287.784     46 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
>>> 1467029287.801     92 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 131.253.61.68:443 - ORIGINAL_DST/131.253.61.68 -
>>> 1467029287.859     61 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
>>> 1467029287.926     52 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
>>> 1467029287.964    134 10.192.0.12 TCP_MISS/200 10828 POST
>>> https://login.live.com/RST2.srf - ORIGINAL_DST/131.253.61.68
>>> application/soap+xml
>>> 1467029287.998     56 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
>>> 1467029288.051     40 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 157.55.133.204:443 - ORIGINAL_DST/157.55.133.204 -
>>> 1467029288.204     46 10.192.0.12 TCP_MISS/302 538 GET
>>> http://go.microsoft.com/fwlink/? - ORIGINAL_DST/23.66.120.244 -
>>> 1467029288.389    147 10.192.0.12 TCP_MISS/302 1786 GET
>>> http://www.microsoft.com/security/encyclopedia/adlpackages.aspx? -
>>> ORIGINAL_DST/23.203.90.59 text/html
>>> 1467029288.422     48 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 13.90.208.215:443 - ORIGINAL_DST/13.90.208.215 -
>>> 1467029288.882    311 10.192.0.12 TAG_NONE/200 0 CONNECT
>>> 104.41.32.78:443 - ORIGINAL_DST/104.41.32.78 -
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>>
>>> Any Help ????
>> Finally. Where is you specify following parameters in squid.conf:
>>
>> sslproxy_cafile /usr/local/squid/etc/ca-bundle.crt
>> sslproxy_foreign_intermediate_certs 
>> /usr/local/squid/etc/intermediate_ca.pem
>>
>> ???
>>
>>> *
>>> *
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> -------------- next part --------------
>> An HTML attachment was scrubbed...
>> URL: 
>> <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160628/91929761/attachment.html>
>>
>> ------------------------------
>>
>> Subject: Digest Footer
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>> ------------------------------
>>
>> End of squid-users Digest, Vol 22, Issue 136
>> ********************************************
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From emz at norma.perm.ru  Tue Jun 28 08:46:01 2016
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Tue, 28 Jun 2016 13:46:01 +0500
Subject: [squid-users] large downloads got interrupted
Message-ID: <57723949.1060504@norma.perm.ru>

Hi,

recently I started to get the problem when large downloads via squid are
often interrupted. I tried to investigate it, but, to be honest, got
nowhere. However, I took two tcpdump captures, and it seems to me that
for some reason squid sends FIN to it's client and correctly closes the
connection (wget reports that connection is closed), and in the same
time for some reason it sends like tonns of RSTs towards the server. No
errors in logs are reported (at least on a  ALL,1 loglevel).

Screenshots of wireshark interpreting the tcpdump capture are here:

Squid(2a00:7540:1::4) to target server(2a02:6b8::183):

http://static.enaza.ru/userupload/gyazo/e5b976bf6f3d0cb666f0d504de04.png
(here you can see that all of a sudden squid starts sending RSTs, that
come long way down the screen, then connection reestablishes (not on the
screenshot taken))

Squid(fd00::301) to client(fd00::73d):

http://static.enaza.ru/userupload/gyazo/ccf4982593dc6047edb5d734160e.png  (here
you can see the client connection got closed)
I'm open to any idea that will help me to get rid of this issue.

Thanks.
Eugene.


From eliezer at ngtech.co.il  Tue Jun 28 10:58:45 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 28 Jun 2016 13:58:45 +0300
Subject: [squid-users] flickr.com redirect error
In-Reply-To: <CAAFc9Fh+wdNT5uKvwgHp_oLGNPSBLnfyhjUpc_Pi7K=bizbk6A@mail.gmail.com>
References: <CAAFc9Fg03TKYFv-0yFyNbrBHmqi83ZGVzosS7gSMksRgeA6WiA@mail.gmail.com>
 <04fdf91a-2741-9996-b69b-cdddbd507e26@gmail.com>
 <CAAFc9FjesKGpGAyOSjPaX1fM0Dam+z0T1xa8AaDrqqcMcRdH4g@mail.gmail.com>
 <VI1PR04MB1359499FE2D9A57B3C0C33638F2E0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <CAAFc9FhiXeMc=J5SECc-MjF4hBDjXRZyS9zDtgMPjSz_iMEkKw@mail.gmail.com>
 <a97ea350-c237-2859-7c2a-cbf4d552ad5c@treenet.co.nz>
 <VI1PR04MB13599620DC40C00E14432EE88F2F0@VI1PR04MB1359.eurprd04.prod.outlook.com>
 <950cb95d-5e47-d51c-4ab3-d67d5437364e@treenet.co.nz>
 <CAAFc9FiDM8_13Zq_OD37FdY_hm6hb431OREbZVwdyaeYxJRjDA@mail.gmail.com>
 <3f174bff-49bd-1acf-7bb5-3e52c3dccd51@treenet.co.nz>
 <CAAFc9Fh21bXOc8=YhDqcOvu3XiNNPpwDWhK30=Q5XgtmJjuv9g@mail.gmail.com>
 <3be92fc1-3cfc-cf51-82e0-9d34aa8ca0cd@treenet.co.nz>
 <CAAFc9Fh+wdNT5uKvwgHp_oLGNPSBLnfyhjUpc_Pi7K=bizbk6A@mail.gmail.com>
Message-ID: <064801d1d12c$0a651d20$1f2f5760$@ngtech.co.il>

Hey,

 

Can you test if the details at bug 4253:

http://bugs.squid-cache.org/show_bug.cgi?id=4253#c13

 

Helps you to resolve the issue?


Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Ozgur Batur
Sent: Monday, June 27, 2016 6:02 PM
To: Amos Jeffries
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] flickr.com redirect error

 

Browser i used to test runs on same machine with squid,  i changed it to explicit mode(no intercept - I set proxy ip in browser) during my attempts for ssl interception. Sorry I forgot to mention that in my last post of logs. So xff localhost is normal I guess. Here is the request log with  port info:

----------

2016/06/27 15:49:40.909 kid1| 11,2| http.cc(2234) sendRequest: HTTP Server local=10.100.136.56:47772 <http://10.100.136.56:47772/>  remote=188.125.93.100:443 <http://188.125.93.100:443/>  FD 47 flags=1

2016/06/27 15:49:40.909 kid1| 11,2| http.cc(2235) sendRequest: HTTP Server REQUEST:

---------

GET / HTTP/1.1

Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8

Upgrade-Insecure-Requests: 1

User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Ubuntu Chromium/50.0.2661.102 Chrome/50.0.2661.102 Safari/537.36

Accept-Encoding: gzip, deflate, sdch

Accept-Language: tr,en-US;q=0.8,en;q=0.6

..

Host: www.flickr.com <http://www.flickr.com/> 

Via: 1.1 ubuntuozgen (squid/3.5.19)

Surrogate-Capability: ubuntuozgen="Surrogate/1.0 ESI/1.0"

X-Forwarded-For: ::1

Cache-Control: max-age=259200

Connection: keep-alive

 

 

On Mon, Jun 27, 2016 at 2:27 PM, Amos Jeffries <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz> > wrote:

On 27/06/2016 11:01 p.m., Ozgur Batur wrote:
> Yes that is much easier, thank you.
>
> Rafaels line is response header, I received the same. Here is the related
> cachelog:
>

What is the content of the line above this one. With the IP:port details ?

> 2016/06/27 13:52:49.194 kid1| 11,2| http.cc(2235) sendRequest: HTTP Server
> REQUEST:
> GET / HTTP/1.1
> Accept:
> text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8
> Upgrade-Insecure-Requests: 1
> User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like
> Gecko) Ubuntu Chromium/50.0.2661.102 Chrome/50.0.2661.102 Safari/537.36
> Accept-Encoding: gzip, deflate, sdch
> Accept-Language: tr,en-US;q=0.8,en;q=0.6
> ...
> Host: www.flickr.com <http://www.flickr.com> 
> Via: 1.1 ubuntuozgen (squid/3.5.19)
> Surrogate-Capability: ubuntuozgen="Surrogate/1.0 ESI/1.0"
> X-Forwarded-For: ::1

You said this was using interception. But Squid XFF is telling Yahoo
that its receiving localhost traffic.

Try "forwarded_for transparent" in your squid.conf, and find out why
that ::1 is happening on an intercepted proxy. There may be a bug in
your NAT or routing configuration.



> Cache-Control: max-age=0
> Connection: keep-alive
>
> ..
> 2016/06/27 13:52:49.477 kid1| 11,2| http.cc(751) processReplyHeader: HTTP
> Server REPLY:
> ---------
> HTTP/1.1 301 Moved Permanently
> X-Frame-Options: SAMEORIGIN
> X-Content-Type-Options: nosniff
> X-XSS-Protection: 1; mode=block
> X-Served-By: pprd1-node552-lh1.manhattan.bf1.yahoo.com <http://pprd1-node552-lh1.manhattan.bf1.yahoo.com> 
> X-Instance: flickr.v1.production.manhattan.bf1.yahoo.com <http://flickr.v1.production.manhattan.bf1.yahoo.com> 
> Cache-Control: no-cache, max-age=0, must-revalidate, no-store
> Pragma: no-cache
> X-Request-Id: 36e709a2
> Location: https://www.flickr.com/
> Vary: Accept
> Content-Type: text/html; charset=utf-8
> Content-Length: 102
> Server: ATS
> Date: Mon, 27 Jun 2016 10:52:40 GMT
> Age: 0
> Via: http/1.1 fts111.flickr.bf1.yahoo.com <http://fts111.flickr.bf1.yahoo.com>  (ApacheTrafficServer [cMs f ]),
> http/1.1 r11.ycpi.dea.yahoo.net <http://r11.ycpi.dea.yahoo.net>  (ApacheTrafficServer [cMs f ])
> Connection: keep-alive
> ..
>
> And this repeats on and on. As I understand disabling Via header is an
> acceptable solution. If I could disable the header only for problematic
> domains that would be better of course.

Okay. Unfortunately not possible. If that forwarded_for change works it
would be better than disabling Via.

Amos





 

-- 

H ?zg?r Batur

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160628/db7a535c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11295 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160628/db7a535c/attachment.png>

From stefan at hoelzle.work  Tue Jun 28 11:32:04 2016
From: stefan at hoelzle.work (=?UTF-8?Q?Stefan_H=c3=b6lzle?=)
Date: Tue, 28 Jun 2016 13:32:04 +0200
Subject: [squid-users] Conditional IPv6 usage
In-Reply-To: <1e0703b4-3fff-62f9-f215-1d2a9b2bf33b@treenet.co.nz>
References: <576D7B9D.4050406@hoelzle.work>
 <1e0703b4-3fff-62f9-f215-1d2a9b2bf33b@treenet.co.nz>
Message-ID: <57726034.9070609@hoelzle.work>

Hello,

I inserted an iptables rule which rejects outgoing tcp packets from the
default IPv4 address to the ip of somedomain.asdf.
This causes Squid to fall back to IPv6.

I'd like to change Squid's behavior in this case to immediately fall
back to IPv6 instead of falling back to the default IPv4 address first.
Can this behavior easily be changed in the source code ?

--
Best Regards
Stefan

On 25.06.2016 07:35, Amos Jeffries wrote:
> On 25/06/2016 6:27 a.m., Stefan H?lzle wrote:
>> Hello,
>>
>> I'm having trouble configuring a forward proxy.
>> My goal is the following:
>> Only for one destination domain IPv6 should be used, otherwise IPv4.
> This is not how the Internet Protocol (IP) works. If a domain is
> advertising IPv6 addresses, then it can and should be contacted using
> those addresses.
>
>> The proxy has multiple incoming IPs and multiple outgoing IPs, here is
>> the relevant part of the squid.conf:
>>
>> acl port80 localport 80
>> acl port88 localport 88
>> acl port443 localport 443
>>
>> http_port 10.0.0.54:80
>> http_port 10.0.0.54:443
>> http_port 10.0.0.59:80
>> http_port 10.0.0.59:443
>> http_port 10.0.0.59:88
> Problem #1: you are configuring a forward proxy on port 80 and 443 which
> are registered ports for reverse-proxy traffic syntax.
>
> This is not necessarily a big problem. But other software in the
> environment that handles port 80 and 443 traffic may interpret the
> format wrongly and scew things up.
>
>
>> acl ipA localip 10.0.0.54
>> acl ipB localip 10.0.0.59
>>
>> # only somedomain.asdf via IPv6
>> acl domain_acl dstdom_regex -i \.somedomain\.asdf
>>
>> tcp_outgoing_address 10.0.0.93 ipB port88
>> tcp_outgoing_address 2001:cdba::3257:9652 ipB port88 domain_acl
>>
>> tcp_outgoing_address 10.0.0.54 ipA port80
>> tcp_outgoing_address 10.0.0.63 ipA port443
>> tcp_outgoing_address 10.0.0.59 ipB port80
>> tcp_outgoing_address 10.0.0.93 ipB port443
>>
>> dns_v4_first on
>>
>> Expected behavior:
>> A connection on http_port 10.0.0.59:88 is requesting a domain matching
>> regex "\.somedomain\.asdf", then the first matching tcp_outgoing_address
>> is used, namely
>>
>> tcp_outgoing_address 2001:cdba::3257:9652 ipB port88 domain_acl
>>
> Expectation is a bit wrong.
>
> tcp_outgoing_address configures _which address to use the type of
> traffic that server requires. The connection has already been allowed by
> tha http_access rules - which do not distinguish whether IPv4 or IPv6 is
> used to contact any particular server.
>
>
> You literally cannot send traffic to an IPv6 addressed server using IPv4
> packet format. Nor vice versa. Squid knows that and does not attempt to
> use the wrong family of IP for any outgoing traffic.
>
> So:
> - The server destination *has already been selected for use* by
> determining in various *_access lists that the client is allowed to
> contact that *domain*.
>
> - IPv6 entries are ignored for IPv4 server destinations.
>
> - IPv4 entries are ignored for IPv6 server destinations.
>
>> Actual behavior:
>> A connection on http_port 10.0.0.59:88 is requesting a domain matching
>> regex "\.somedomain\.net" and
>>
> Incoming port has nothing to do with outgoing IP format.
>
> * DNS tells Squid a set of IP addresses that the domain can be contacted at.
>
> ** "dns_v4_first on" tells Squid to use the servers A address(es) as
> first choice before attempting IPv6 contact.
>
> That domain *does* have an A address. So...
>
>> tcp_outgoing_address 10.0.1.54 ipA port80
>>
>> is used.
> If that fails it might fail over to another IPv4 or to the domains IPv6
> address.
>
>
>> If I change dns_v4_first from on to off,
>>
> ** then "dns_v4_first on" tells Squid to use the servers AAAA address as
> first choice before attempting IPv6 contact.
>
> ** That domain *does* have an AAAA address. So ...
>
>> tcp_outgoing_address 2001:cdba::3257:9652 ipB port88 domain_acl
>>
> ... or the machines default IPv6 addresss is used when contacting the
> servers AAAA address(es).
>
> If that fails then Squid might failover to another of the servers IPv6
> addresses, or to its IPv4 address.
>
>
>
>
> You can choose a particular IP from amongst the appropriate v4/v6 types
> available. But you cannot force a particular type to be used.
>  (though you might configure an IPv4/IPv6 address which will force
> breakage on the connection).
>
>
> It is the network firewalls job to determine whether *Squid* is allowed
> contact from IP A to IP B. If it blocks unwanted IPv6 traffic properly,
> then the normal ICMPv6 packet that comes back from the firewall will
> tell Squid to try the next IP on the list for the server being contacted.
>
>
> HTH
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From eduardoocarneiro at gmail.com  Tue Jun 28 11:58:14 2016
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Tue, 28 Jun 2016 04:58:14 -0700 (PDT)
Subject: [squid-users] Squid's cache management
Message-ID: <1467115094575-4678255.post@n4.nabble.com>

Hello everyone. 

First of all, sorry my english. It's not very good.

I'm using squid 3.5.19 with dynamic cache content with url rewrite. My cache
directory is 90% full. I noticed that it doesn't exceed the value set in
cache_dir. This is a good thing.

My doubt is: How squid manages that? What is the criterion to delete these
files?

Sorry if the answer is here in another topic. I searched but I did not find.

Best regards,
Eduardo Carneiro



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-s-cache-management-tp4678255.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Tue Jun 28 12:42:46 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 28 Jun 2016 14:42:46 +0200
Subject: [squid-users] Squid's cache management
In-Reply-To: <1467115094575-4678255.post@n4.nabble.com>
References: <1467115094575-4678255.post@n4.nabble.com>
Message-ID: <201606281442.46734.Antony.Stone@squid.open.source.it>

On Tuesday 28 June 2016 at 13:58:14, Eduardo Carneiro wrote:

> I'm using squid 3.5.19 with dynamic cache content with url rewrite. My
> cache directory is 90% full. I noticed that it doesn't exceed the value
> set in cache_dir. This is a good thing.
> 
> My doubt is: How squid manages that? What is the criterion to delete these
> files?

http://www.squid-cache.org/Doc/config/cache_replacement_policy/


Antony.

-- 
I want to build a machine that will be proud of me.

 - Danny Hillis, creator of The Connection Machine

                                                   Please reply to the list;
                                                         please *don't* CC me.


From ozgurbtr at gmail.com  Tue Jun 28 12:43:58 2016
From: ozgurbtr at gmail.com (Ozgur Batur)
Date: Tue, 28 Jun 2016 15:43:58 +0300
Subject: [squid-users] Websocket content adaptation
In-Reply-To: <57715AE5.8090904@measurement-factory.com>
References: <CAAFc9Fg4jNed1kZHe-0p2EbKHTQEP=y3eZhsTvy+mkvWC7Xkuw@mail.gmail.com>
 <57715AE5.8090904@measurement-factory.com>
Message-ID: <CAAFc9FhuPYA=o+hEY689RBBonOYYxkk7qvvtmoZhqSdzpjmRuw@mail.gmail.com>

On Mon, Jun 27, 2016 at 7:57 PM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 06/27/2016 10:23 AM, Ozgur Batur wrote:
>
> > ICAP handles plain HTTP very well but it is not possible to
> > filter/change or even log content of websocket communication after
> > websocket upgrade over HTTP as far as I know. Is there any plan or
> > interest in developing some capability for Squid to control websocket
> > communication content?
>
> There is interest but no specific plan or sponsor.
>
>
> > There is no defined request/response protocol since websocket is
> > basically a socket but regexp matching in incoming and outgoing
> > content(json, xml,raw) with URL and client metadata info may have some
> > application like data leak prevention or achieving in corporate
> environment.
>
> I am not sure regex would be a good idea in general, but passing
> tunneled traffic to eCAP/ICAP services is indeed useful in several
> environments, including WebSocket tunnels. The adaptation service will
> decide whether to use regex or something else to match raw data. Some
> existing services simply log (or relay/replay via TCP) received traffic
> without analyzing it so regex is just one of many possibilities here.
>
> FWIW, several things are needed to move forward, including:
>
> 1. Adequate development time and skills (or sponsorship to pay for
>    them). The development of an essentially new adaptation vectoring
>    point is not a trivial project.
>
>
I have involved in development of several ICAP services around Squid but
have not had the chance to work on Squid code base directly. We may attempt
implement a proof of concept with a few friends to better specify the task
at hand current and learn about adaptation infrastructure of Squid.


> 2. A specific proposal on how to map raw/tunnel data to HTTP messages
>    that eCAP and ICAP interfaces expect. The biggest difficulty here
>    may be mapping server-speaks-first protocols.
>

I am not sure if it is possible to map websocket data to current adaptation
services. Actually it may or may not be related but I am curious how Squid
handles Comet(Ajax/HTTP Server Push) during ICAP processing. Maybe server
data push can be mapped like Comet responses. About server first protocols,
current ICAP services expecting encapsulated valid HTTP responses for
requests will break of course. Maybe a mechanism like Allow 204 negotiation
can be implemented between adaptation service and proxy. If adaptation
service does not support server first pushes it can be bypassed.

>
> 3. A project lead to organize/manage the project and guide the results
>    through the Squid Project review. This person could be the
>    primary developer and/or the specs writer, but does not have to be.
>
> Alex.
>

Thanks,

Ozgur
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160628/e6f6f7ce/attachment.htm>

From bruno.larini at riosoft.com.br  Tue Jun 28 12:45:17 2016
From: bruno.larini at riosoft.com.br (Bruno de Paula Larini)
Date: Tue, 28 Jun 2016 09:45:17 -0300
Subject: [squid-users] Strange NTLM problem.
In-Reply-To: <77b351c584e272d8fb9ec0f637e6ef79@wm10.email.it>
References: <77b351c584e272d8fb9ec0f637e6ef79@wm10.email.it>
Message-ID: <b560a5e4-8e8c-eed1-5573-523e17f707e4@riosoft.com.br>

Em 28/06/2016 03:14, drcimino drcimino escreveu:
> Dear all,
> i have a strange problem with my squid 3.5.19 and authentication NTLM.
> On my configuration i have 2 auth method:
> NTLM negotiated with ntlm_auth from samba 3
> auth_param ntlm program /usr/local/samba/bin/ntlm_auth 
> --helper-protocol=squid-2.5-ntlmssp
> auth_param ntlm children 200 startup=100 idle=10 concurrency=0
> auth_param ntlm keep_alive on
>
> and as a fallback basic ntlm
> auth_param basic program /usr/local/samba/bin/ntlm_auth 
> --helper-protocol=squid-2.5-basic
> auth_param basic children 25 startup=15 idle=5 concurrency=0
> auth_param basic realm PROXY AUTHORIZATION REQUIRED
> auth_param basic credentialsttl 30 minutes
> TTL
>
> authenticate_cache_garbage_interval 1 hours
> authenticate_ttl 30 minutes
> authenticate_ip_ttl 30 minutes
>
> Groups identification with LDAPS
> external_acl_type NAV children-max=200 children-startup=100 
> children-idle=10 ttl=1800 %LOGIN
> /usr/local/squid/libexec/ext_ldap_group_acl -s sub -b 
> "dc=domain,dc=xxx" -D "cn=squid,cn=Users,dc
> =domain,dc=xxx" -w "password" -f 
> "(&(objectclass=person)(sAMAccountName=%v)(membero
> f=cn=%a,ou=INTERNET,ou=AAA,dc=domain,dc=xxx))" -S -K -H 
> ldaps://domain.xxx:3269

I've been using the helper "ext_wbinfo_group_acl" to work with AD groups 
and transparent authentication for domain members. The config below also 
makes the auth pop-up to show when the machine isn't member of the 
domain - no need to use the fallback part. You just have to configure 
Kerberos, Samba, join the Squid machine to the domain with "net ads 
join" and enable winbind.


     auth_param ntlm program /usr/bin/ntlm_auth 
--helper-protocol=squid-2.5-ntlmssp --domain=MYDOMAIN 
--enable-external-acl-helpers="ext_wbinfo_group_acl"
     auth_param ntlm children 10 startup=0 idle=2

     external_acl_type NTGroup children-startup=10 children-idle=2 
children-max=50 %LOGIN /usr/lib64/squid/ext_wbinfo_group_acl

     acl authenticated proxy_auth REQUIRED

     acl ad_group external NTGroup MYDOMAIN\AD_Group
     acl denied_websites dstdom_regex -i "/etc/squid/denied-websites.txt"
     http_access deny ad_group denied_websites

In my set of acls, the pop-up was also appearing in specific sites. 
Changing the order of acls made it stop appearing for me.
This:

     http_access allow website_list user_list

seems to work differently from this:

     http_access allow user_list website_list


Bruno


From eduardoocarneiro at gmail.com  Tue Jun 28 12:42:39 2016
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Tue, 28 Jun 2016 05:42:39 -0700 (PDT)
Subject: [squid-users] Squid's cache management
In-Reply-To: <201606281442.46734.Antony.Stone@squid.open.source.it>
References: <1467115094575-4678255.post@n4.nabble.com>
 <201606281442.46734.Antony.Stone@squid.open.source.it>
Message-ID: <1467117759102-4678259.post@n4.nabble.com>

Thank you very much Antony! You answer was very helpful.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-s-cache-management-tp4678255p4678259.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Tue Jun 28 13:43:09 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 29 Jun 2016 01:43:09 +1200
Subject: [squid-users] Strange NTLM problem.
In-Reply-To: <b560a5e4-8e8c-eed1-5573-523e17f707e4@riosoft.com.br>
References: <77b351c584e272d8fb9ec0f637e6ef79@wm10.email.it>
 <b560a5e4-8e8c-eed1-5573-523e17f707e4@riosoft.com.br>
Message-ID: <17d8ae3a-9365-b8da-2311-eeabdda0f638@treenet.co.nz>

On 29/06/2016 12:45 a.m., Bruno de Paula Larini wrote:
> Em 28/06/2016 03:14, drcimino drcimino escreveu:
>> Dear all,
>> i have a strange problem with my squid 3.5.19 and authentication NTLM.
>> On my configuration i have 2 auth method:
>> NTLM negotiated with ntlm_auth from samba 3
>> auth_param ntlm program /usr/local/samba/bin/ntlm_auth
>> --helper-protocol=squid-2.5-ntlmssp
>> auth_param ntlm children 200 startup=100 idle=10 concurrency=0
>> auth_param ntlm keep_alive on
>>
>> and as a fallback basic ntlm
>> auth_param basic program /usr/local/samba/bin/ntlm_auth
>> --helper-protocol=squid-2.5-basic
>> auth_param basic children 25 startup=15 idle=5 concurrency=0
>> auth_param basic realm PROXY AUTHORIZATION REQUIRED
>> auth_param basic credentialsttl 30 minutes
>> TTL
>>
>> authenticate_cache_garbage_interval 1 hours
>> authenticate_ttl 30 minutes
>> authenticate_ip_ttl 30 minutes
>>
>> Groups identification with LDAPS
>> external_acl_type NAV children-max=200 children-startup=100
>> children-idle=10 ttl=1800 %LOGIN
>> /usr/local/squid/libexec/ext_ldap_group_acl -s sub -b
>> "dc=domain,dc=xxx" -D "cn=squid,cn=Users,dc
>> =domain,dc=xxx" -w "password" -f
>> "(&(objectclass=person)(sAMAccountName=%v)(membero
>> f=cn=%a,ou=INTERNET,ou=AAA,dc=domain,dc=xxx))" -S -K -H
>> ldaps://domain.xxx:3269
> 
> I've been using the helper "ext_wbinfo_group_acl" to work with AD groups
> and transparent authentication for domain members. The config below also
> makes the auth pop-up to show when the machine isn't member of the
> domain - no need to use the fallback part. You just have to configure
> Kerberos, Samba, join the Squid machine to the domain with "net ads
> join" and enable winbind.

You are not using Negotiate/Kerberos, so I'm not sure why that is related.

Winbind is needed for the particular wbinfo helper. Note that winbind
has much more several issues with concurrent number of connections to AD
being only 256.


> 
>     auth_param ntlm program /usr/bin/ntlm_auth
> --helper-protocol=squid-2.5-ntlmssp --domain=MYDOMAIN
> --enable-external-acl-helpers="ext_wbinfo_group_acl"
>     auth_param ntlm children 10 startup=0 idle=2
> 
>     external_acl_type NTGroup children-startup=10 children-idle=2
> children-max=50 %LOGIN /usr/lib64/squid/ext_wbinfo_group_acl
> 
>     acl authenticated proxy_auth REQUIRED
> 
>     acl ad_group external NTGroup MYDOMAIN\AD_Group
>     acl denied_websites dstdom_regex -i "/etc/squid/denied-websites.txt"
>     http_access deny ad_group denied_websites
> 
> In my set of acls, the pop-up was also appearing in specific sites.
> Changing the order of acls made it stop appearing for me.
> This:
> 
>     http_access allow website_list user_list
> 
> seems to work differently from this:
> 
>     http_access allow user_list website_list
> 

Not seem to. It does. Intentionally.
<http://wiki.squid-cache.org/SquidFaq/OrderIsImportant>

Having something like website_list, which I guess is a dstdomain or such
ACL at the end of the line prevents auth or group test mis-matches from
re-authenticating to get credentials that might pass the ACL test.

Preventing these ACLs triggering authentication activity is probably a
large part of what actually got fixed in your situation. NTLM related
auth takes a relatively long time so reducing the number of auth and
re-auth tests needed to check a users access permissions can be a big win.

Amos



From squid3 at treenet.co.nz  Tue Jun 28 13:45:56 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 29 Jun 2016 01:45:56 +1200
Subject: [squid-users] Strange NTLM problem.
In-Reply-To: <77b351c584e272d8fb9ec0f637e6ef79@wm10.email.it>
References: <77b351c584e272d8fb9ec0f637e6ef79@wm10.email.it>
Message-ID: <b28f3b80-d73c-3f5d-e43a-9fa1a4395791@treenet.co.nz>

On 28/06/2016 6:14 p.m., drcimino drcimino wrote:
> Dear all,
> 
> 
> &nbsp;
> 
> 
> i have a strange problem with my squid 3.5.19 and authentication NTLM.
> 
> 
> On my configuration i have 2 auth method:
> 
> 
> &nbsp;
> 
> 
> NTLM negotiated with ntlm_auth from samba 3
> 
> 
> &nbsp;
> 
> 
> auth_param ntlm program /usr/local/samba/bin/ntlm_auth
> --helper-protocol=squid-2.5-ntlmssp
> 
> auth_param ntlm children 200 startup=100 idle=10 concurrency=0
> 
> auth_param ntlm keep_alive on
> 
> 
> 
> 
> and as a fallback basic ntlm
> 

Just to be clear. There is no such thing as "basic ntlm".

What you have configured is Basic authentication (user:password in the
clear over the network.
It just happens that the Samba helper is called "ntlm_auth". That name
does not make it NTLM protocol in any way.

> 
> &nbsp;
> 
> 
> auth_param basic program /usr/local/samba/bin/ntlm_auth
> --helper-protocol=squid-2.5-basic
> 
> auth_param basic children 25 startup=15 idle=5 concurrency=0
> 
> auth_param basic realm PROXY AUTHORIZATION REQUIRED
> 
> auth_param basic credentialsttl 30 minutes
> 
> 
> &nbsp;
> 
> 
> TTL
> 
> 
> 
> 
> authenticate_cache_garbage_interval 1 hours
> 
> authenticate_ttl 30 minutes
> 
> authenticate_ip_ttl 30 minutes
> 
> 
> 
> 
> Groups identification with LDAPS
> 
> 
> &nbsp;
> 
> 
> external_acl_type NAV children-max=200 children-startup=100 children-idle=10
> ttl=1800 %LOGIN
> 
> /usr/local/squid/libexec/ext_ldap_group_acl -s sub -b "dc=domain,dc=xxx" -D
> "cn=squid,cn=Users,dc
> 
> =domain,dc=xxx" -w "password" -f
> "(&amp;(objectclass=person)(sAMAccountName=%v)(membero
> 
> f=cn=%a,ou=INTERNET,ou=AAA,dc=domain,dc=xxx))" -S -K -H
> ldaps://domain.xxx:3269
> 
> 
> &nbsp;
> 
> 
> ... and all work very well.
> 
> 
> Sometimes and randomly, my users reported to me that squid cannot do ntlm
> transparent authentication and request for user/password pair (falling back
> to ntlm basic).

No. It is falling back *past* the Basic authentication to user input.


> Entering right credential does not work and to proceed further&nbsp; users
> need to click on "abort" button many times.
> 

One popup for each connection which the browser has opened and not been
able to authenticate.

NTLM is both slow and has a limited number of connections that it can
make to AD simultaneously for authentication. All those popups for one
user, multiplied by the number of users currently doing authentication
across the whole time period that NTLM handshakes take up and its easy
to get very large numbers of concurrent authentication actions.
 And when the system gets bogged down, users start to feel the impact
either in longer latency or outright ejected logins.


> 
> On my cache.log i see:
> 
> Login for user [DOMAIN]\[userx]@[PC_XXX] failed due to [Access denied]
> 
> NTLMSSP BH: NT_STATUS_ACCESS_DENIED
> 
> 2016/06/27 22:59:06 kid1| ERROR: NTLM Authentication validating user.
> Result: {result=BH, notes={mes
> 
> sage: NT_STATUS_ACCESS_DENIED; }}

Means the credentials were not correct like you said. It can be tricky
since the browser does not give much in the way of hints about which
auth protocol the popup details will be used in. You could need to enter
the Basic user + password, or Basic DOMAIN\user + password, or NTLM user
+ password, or NTLM DOMAIN\user + password, or NTLM MACHINE\user + password.
 About the only thing that you can use to provide any hints which one is
needed is the "realm" string Squid provides for each auth type.

> 
> every times a user receive credential request.
> 
> 
> After aborting each requests squid do, users can surf the internet without
> problems and i cannot replicate the issue.
> 
> 
> Trying to close the browser, clear cache, and going to the same site does
> not produce same error.
> 
> 
> Stopping squid, remove cache, starting squid does not produce same error.
> 
> 
> It's totally random and i'm going mad to understand why.
> 
> 
> Can someone help me to debug and understand the problem?
> 

You will likely need to enable debugging on the helper to see what it
has to say about the rejection.


Bruno already mentioned Kerberos. I second that. Kerberos can be a bit
of a learning curve, but is worth it for the extra speed and security
gained.

Amos



From rousskov at measurement-factory.com  Tue Jun 28 13:48:49 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 28 Jun 2016 07:48:49 -0600
Subject: [squid-users] Websocket content adaptation
In-Reply-To: <CAAFc9FhuPYA=o+hEY689RBBonOYYxkk7qvvtmoZhqSdzpjmRuw@mail.gmail.com>
References: <CAAFc9Fg4jNed1kZHe-0p2EbKHTQEP=y3eZhsTvy+mkvWC7Xkuw@mail.gmail.com>
 <57715AE5.8090904@measurement-factory.com>
 <CAAFc9FhuPYA=o+hEY689RBBonOYYxkk7qvvtmoZhqSdzpjmRuw@mail.gmail.com>
Message-ID: <57728041.1010406@measurement-factory.com>

On 06/28/2016 06:43 AM, Ozgur Batur wrote:
> On Mon, Jun 27, 2016 at 7:57 PM, Alex Rousskov wrote:
>     FWIW, several things are needed to move forward, including:
> 
>     1. Adequate development time and skills (or sponsorship to pay for
>        them). The development of an essentially new adaptation vectoring
>        point is not a trivial project.


> I have involved in development of several ICAP services around Squid but
> have not had the chance to work on Squid code base directly. We may
> attempt implement a proof of concept with a few friends to better
> specify the task at hand current and learn about adaptation
> infrastructure of Squid.

I recommend starting with the proposal described in my item #2. A proof
of concept is usually needed when there is doubt that the concept can
work in principle. There is no such doubt here IMO.


>     2. A specific proposal on how to map raw/tunnel data to HTTP messages
>        that eCAP and ICAP interfaces expect. The biggest difficulty here
>        may be mapping server-speaks-first protocols.


> I am not sure if it is possible to map websocket data to current
> adaptation services.

It is possible to map virtually anything to HTTP messages and, hence, to
eCAP/ICAP. For example, Squid maps FTP transactions to HTTP messages! A
better mapping would preserve more information, make it easier to access
that information by services that understand the protocol being mapped,
have lower overhead, etc. However, it is clearly "possible" to come up
with some mapping.


> Actually it may or may not be related but I am
> curious how Squid handles Comet(Ajax/HTTP Server Push) during ICAP
> processing. 

Squid proxies regular HTTP/1 and FTP. That excludes pure server push
until we add HTTP/2 support.


> About server first protocols, current ICAP services expecting
> encapsulated valid HTTP responses for requests will break of course.

I do not think so. A proper mapping could present that spontaneous
from-server message as an HTTP response to a trivial fake request
(enough to identify the protocol and the server address).

Needless to say, the WebSockets:HTTP mapping (and overall Squid
functionality) can be improved if Squid understands WebSockets (as Amos
has noted in his response), but I do not think such understanding is
_required_ to accommodate many useful adaptation use cases.


> Maybe a mechanism like Allow 204 negotiation can be implemented between
> adaptation service and proxy. If adaptation service does not support
> server first pushes it can be bypassed. 

It is always possible to extend ICAP and eCAP, but, with all other
factors being equal, extending should be a last-resort solution because
most adaptation services will not support the extension and many of
those services could work fine without that extension.


HTH,

Alex.



From ataro at protonmail.ch  Tue Jun 28 13:49:46 2016
From: ataro at protonmail.ch (Ataro)
Date: Tue, 28 Jun 2016 09:49:46 -0400
Subject: [squid-users] Running squid on a machine with only one network
	interface.
In-Reply-To: <201606272256.40878.Antony.Stone@squid.open.source.it>
References: <km0veN2AohDivh1p8WaGCSUiXPJ8Ryh1kP7Nwqne7MHgFAlMbdO46-rLEJbnyQPKIpPTsVsjQFOBW1s1WXhpGw==@protonmail.ch>
 <201606272256.40878.Antony.Stone@squid.open.source.it>
Message-ID: <c6xAIjgM5eCdqy4186XDx3IpvobaoFMKp4idALuNuhv01NXHblYftbJDiNiDIcvbGpTPYvou2Uoe6EE4l8-KQw==@protonmail.ch>

Hi and thanks for your help.

as for your request, here's the content of my IPFW rules and my squid configuration:

IPFW rules:

ipfw -f flush
ipfw add 50 pass all from any to any via lo0
ipfw add 100 pass all from any to any proto udp
ipfw add 150 pass icmp from any to any
ipfw add 200 fwd 127.0.0.1,3128 tag 1111 tcp from me to any
ipfw add 250 pass all from 10.0.2.15 to any tagged 1111

squid.conf:

acl my_machine src 10.0.2.15 # this is the ip of my machine.
http_access allow my_machine

acl localnet src 10.0.0.0/8 # RFC1918 possible internal network
acl localnet src 172.16.0.0/12 # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7 # RFC 4193 local private network range
acl localnet src fe80::/10 # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl CONNECT method CONNECT

http_access deny !Safe_ports

http_access deny CONNECT !SSL_ports


http_access allow localhost manager
http_access deny manager

visible_hostname mynet.mydomain
acl MYSITE dstdomain cnn.com
acl MYSITE dstdomain 10.0.2.15
http_access allow MYSITE

http_access allow localnet
http_access allow localhost

http_access deny all

http_port 127.0.0.1:3128 intercept
http_port 3129

coredump_dir /var/squid/cache

refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320

I'm almost surely that the problem is that as other people said here, the firewall redirect the traffic originated from the squid server back to squid and hence the forwarding loop.

I've tried to allow the traffic originated from the squid server by using the "tag/tagged" feature in the IPFW rules but this doesn't work, apparently because squid issue a new connection that is not tagged.
since squid and the firewall resides on the same machine I've no idea how to tell the firewall to allow the traffic which squid initiate.

Regards,

Ataro.


-------- Original Message --------
Subject: Re: [squid-users] Running squid on a machine with only one network interface.
Local Time: June 27, 2016 11:56 PM
UTC Time: June 27, 2016 8:56 PM
From: Antony.Stone at squid.open.source.it
To: ataro at protonmail.ch

On Monday 27 June 2016 at 22:45:19, Ataro wrote:

> Hi there,
>
> I've set up a FreeBSD machine inside a VirtualBox machine and used IPFW to
> forward all the requests to the internet through a squid server running on
> the same machine in port 3128 in intercept mode.

Please show us your IPFW rules.

> The problem is that I get 403 http responses on every site I try to access
> to, even on the sites that I've explicitly allowed in the squid.conf file.

Maybe show us your squid.conf as well (without comments or blank lines).

> I also get a warning message on the tty that squid is running on (I've run
> squid in no daemon mode) which says: Warning: Forwarding loop detected
> for:.....

So, NAT is not working correctly...

> I guess that this error occurs since the squid server and the IPFW firewall
> are running on the same machine which have only one network interface.
>
> Am I right?

Not in the sense that "you can't do this with only one interface", no.

However, quite possibly in the sense that you haven't told IPFW how to
distinguish between requests in from your clients, and requests out from your
squid instance.

The former need to go to squid, the latter need to go to the Internet.


Give us a bit more information and we might be able to give you a bit more
help.



Antony.

--
I don't know, maybe if we all waited then cosmic rays would write all our
software for us. Of course it might take a while.

- Ron Minnich, Los Alamos National Laboratory

Please reply to the list;
please *don't* CC me.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160628/121756ff/attachment.htm>

From squid3 at treenet.co.nz  Tue Jun 28 13:52:22 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 29 Jun 2016 01:52:22 +1200
Subject: [squid-users] Websocket content adaptation
In-Reply-To: <CAAFc9FhuPYA=o+hEY689RBBonOYYxkk7qvvtmoZhqSdzpjmRuw@mail.gmail.com>
References: <CAAFc9Fg4jNed1kZHe-0p2EbKHTQEP=y3eZhsTvy+mkvWC7Xkuw@mail.gmail.com>
 <57715AE5.8090904@measurement-factory.com>
 <CAAFc9FhuPYA=o+hEY689RBBonOYYxkk7qvvtmoZhqSdzpjmRuw@mail.gmail.com>
Message-ID: <9ec6080b-4d73-d9f5-9409-1e02350269ee@treenet.co.nz>

On 29/06/2016 12:43 a.m., Ozgur Batur wrote:
> On Mon, Jun 27, 2016 at 7:57 PM, Alex Rousskov wrote:
> 
>> 2. A specific proposal on how to map raw/tunnel data to HTTP messages
>>    that eCAP and ICAP interfaces expect. The biggest difficulty here
>>    may be mapping server-speaks-first protocols.
>>
> 
> I am not sure if it is possible to map websocket data to current adaptation
> services. Actually it may or may not be related but I am curious how Squid
> handles Comet(Ajax/HTTP Server Push) during ICAP processing.

Last time I looked at those they were just using regular HTTP
long-pollinng techniques. Though some may have moved to WebSockets or
HTTP/2 now.

Squid does not have to do anything for those. The clients and server
involved do the mapping of their data into various HTTP requests and
replies. So as far as Squid is concerned they are just regular long
duration GET or POST requests. Which since they are HTTP messages can be
passed to the ICAP service in the normal ways.

Amos



From stan.prescott at gmail.com  Tue Jun 28 14:02:48 2016
From: stan.prescott at gmail.com (Stanford Prescott)
Date: Tue, 28 Jun 2016 09:02:48 -0500
Subject: [squid-users] Squid 3.5.19 how to find banking server name for no
	bump
Message-ID: <CANLNtGQecOFjb9H+4MbOu7Fu8NFHNooLxKFLhh8sBEu=vNzQuA@mail.gmail.com>

I have the proper peek and splice and bump configuration of acls setup in
my squid.conf file for no-bump of some web sites. I need help how to enter
the banking hosts and or server names in a way that the peek and splice
configuration will determine it is a banking site that I don't want bumped.

For example, if a user enters www.wellsfargo.com for online banking my
current config still bumps wellsfargo.com. What would I need to enter for
wellsfargo.com so that banking server will not be bumped?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160628/66184e78/attachment.htm>

From carlopmart at gmail.com  Tue Jun 28 14:18:43 2016
From: carlopmart at gmail.com (C. L. Martinez)
Date: Tue, 28 Jun 2016 14:18:43 +0000
Subject: [squid-users] Problems with ACL's using squid as intercept proxy
Message-ID: <20160628141843.GA14458@beagle.bcn.sia.es>

Hi all,

 I am trying to configure a second squid proxy as an intercept proxy but this time under FreeBSD instead of OpenBSD. Doing my first tests I have a problem with acl's that I don't understand. To isolate the problem, I have started with a simple squid.conf file:

#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
acl localnet src 172.16.0.0/12	# RFC1918 possible internal network
acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80		# http
acl Safe_ports port 21		# ftp
acl Safe_ports port 443		# https
acl Safe_ports port 70		# gopher
acl Safe_ports port 210		# wais
acl Safe_ports port 1025-65535	# unregistered ports
acl Safe_ports port 280		# http-mgmt
acl Safe_ports port 488		# gss-http
acl Safe_ports port 591		# filemaker
acl Safe_ports port 777		# multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 3128
http_port 127.0.0.1:5144 intercept

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /var/squid/cache 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/squid/cache

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320

 As you can see, I have configured only one port for intercept http requests ... I have configured new PF rules in this new FreeBSD host:

rdr pass on $vpnif proto tcp from $int_network to any port http tag intlans-to-inet -> lo0 port 5144

 .. And the result is:

1467122773.928      0 127.0.0.1 TCP_MISS/403 4357 GET http://www.osnews.com/ - HIER_NONE/- text/html
1467122773.928     35 172.22.55.1 TCP_MISS/403 4489 GET http://www.osnews.com/ - ORIGINAL_DST/127.0.0.1 text/html
1467122774.068      0 172.22.55.1 TCP_MEM_HIT/200 13096 GET http://fbsdprx.my.domain.com:3128/squid-internal-static/icons/SN.png - HIER_NONE/- image/png
1467122774.102      0 127.0.0.1 TCP_MISS/403 4314 GET http://www.osnews.com/favicon.ico - HIER_NONE/- text/html
1467122774.103      2 172.22.55.1 TCP_MISS/403 4446 GET http://www.osnews.com/favicon.ico - ORIGINAL_DST/127.0.0.1 text/html

 .. What is the problem?? Are ACL's wrong?? Why?? At first stage, I was thinking about a problem with the pf rules ... but, now, I am not sure because packets arrives to squid ...

 Any idea??

Thanks.

-- 
Greetings,
C. L. Martinez


From squid3 at treenet.co.nz  Tue Jun 28 14:27:32 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 29 Jun 2016 02:27:32 +1200
Subject: [squid-users] Conditional IPv6 usage
In-Reply-To: <57726034.9070609@hoelzle.work>
References: <576D7B9D.4050406@hoelzle.work>
 <1e0703b4-3fff-62f9-f215-1d2a9b2bf33b@treenet.co.nz>
 <57726034.9070609@hoelzle.work>
Message-ID: <1801b18f-c110-6337-5ff6-72dbeb4a410a@treenet.co.nz>

On 28/06/2016 11:32 p.m., Stefan H?lzle wrote:
> Hello,
> 
> I inserted an iptables rule which rejects outgoing tcp packets from the
> default IPv4 address to the ip of somedomain.asdf.
> This causes Squid to fall back to IPv6.
> 
> I'd like to change Squid's behavior in this case to immediately fall
> back to IPv6 instead of falling back to the default IPv4 address first.

Falling back to something "first" does not make any sense. The first has
to be tried and fail before a fallback is needed.


> Can this behavior easily be changed in the source code ?

There is an old patch in the feature request that might help you:
<http://bugs.squid-cache.org/show_bug.cgi?id=3901>

YMMV on whether it applies cleanly. It has been a long while since it
was created.

Amos



From squid3 at treenet.co.nz  Tue Jun 28 14:56:35 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 29 Jun 2016 02:56:35 +1200
Subject: [squid-users] Squid 3.5.19 how to find banking server name for
 no bump
In-Reply-To: <CANLNtGQecOFjb9H+4MbOu7Fu8NFHNooLxKFLhh8sBEu=vNzQuA@mail.gmail.com>
References: <CANLNtGQecOFjb9H+4MbOu7Fu8NFHNooLxKFLhh8sBEu=vNzQuA@mail.gmail.com>
Message-ID: <84e35d81-1e53-83ed-b2b8-9f34f1497aad@treenet.co.nz>

On 29/06/2016 2:02 a.m., Stanford Prescott wrote:
> I have the proper peek and splice and bump configuration of acls setup in
> my squid.conf file for no-bump of some web sites. I need help how to enter
> the banking hosts and or server names in a way that the peek and splice
> configuration will determine it is a banking site that I don't want bumped.
> 
> For example, if a user enters www.wellsfargo.com for online banking my
> current config still bumps wellsfargo.com. What would I need to enter for
> wellsfargo.com so that banking server will not be bumped?
> 

Depends on what you mean by "enter".

Are you asking for the ACL value?
  .wellfargo.com

Are you asking for the ACL definition?
 acl banks ssl::server_name .wellsfargo.com

Or are you asking for a whole SSL-Bump configuration example?
 <http://wiki.squid-cache.org/Features/SslPeekAndSplice> has a few.

Amos



From ozgurbtr at gmail.com  Tue Jun 28 14:58:47 2016
From: ozgurbtr at gmail.com (Ozgur Batur)
Date: Tue, 28 Jun 2016 17:58:47 +0300
Subject: [squid-users] Websocket content adaptation
In-Reply-To: <9ec6080b-4d73-d9f5-9409-1e02350269ee@treenet.co.nz>
References: <CAAFc9Fg4jNed1kZHe-0p2EbKHTQEP=y3eZhsTvy+mkvWC7Xkuw@mail.gmail.com>
 <57715AE5.8090904@measurement-factory.com>
 <CAAFc9FhuPYA=o+hEY689RBBonOYYxkk7qvvtmoZhqSdzpjmRuw@mail.gmail.com>
 <9ec6080b-4d73-d9f5-9409-1e02350269ee@treenet.co.nz>
Message-ID: <CAAFc9Fg7+qyOUJ2QuGbrKLWVewoweC_nUfrApjsy9hhpy6n2ww@mail.gmail.com>

Thank you very much for explanation Amos.

On Tue, Jun 28, 2016 at 4:52 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 29/06/2016 12:43 a.m., Ozgur Batur wrote:
> > On Mon, Jun 27, 2016 at 7:57 PM, Alex Rousskov wrote:
> >
> >> 2. A specific proposal on how to map raw/tunnel data to HTTP messages
> >>    that eCAP and ICAP interfaces expect. The biggest difficulty here
> >>    may be mapping server-speaks-first protocols.
> >>
> >
> > I am not sure if it is possible to map websocket data to current
> adaptation
> > services. Actually it may or may not be related but I am curious how
> Squid
> > handles Comet(Ajax/HTTP Server Push) during ICAP processing.
>
> Last time I looked at those they were just using regular HTTP
> long-pollinng techniques. Though some may have moved to WebSockets or
> HTTP/2 now.
>
> Squid does not have to do anything for those. The clients and server
> involved do the mapping of their data into various HTTP requests and
> replies. So as far as Squid is concerned they are just regular long
> duration GET or POST requests. Which since they are HTTP messages can be
> passed to the ICAP service in the normal ways.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160628/9f104e73/attachment.htm>

From ozgurbtr at gmail.com  Tue Jun 28 15:18:36 2016
From: ozgurbtr at gmail.com (Ozgur Batur)
Date: Tue, 28 Jun 2016 18:18:36 +0300
Subject: [squid-users] Websocket content adaptation
In-Reply-To: <57728041.1010406@measurement-factory.com>
References: <CAAFc9Fg4jNed1kZHe-0p2EbKHTQEP=y3eZhsTvy+mkvWC7Xkuw@mail.gmail.com>
 <57715AE5.8090904@measurement-factory.com>
 <CAAFc9FhuPYA=o+hEY689RBBonOYYxkk7qvvtmoZhqSdzpjmRuw@mail.gmail.com>
 <57728041.1010406@measurement-factory.com>
Message-ID: <CAAFc9Fj3yD_VDBYPRbrVzdmyz1T-t84XERWLvi95EYLwbmJiDg@mail.gmail.com>

On Tue, Jun 28, 2016 at 4:48 PM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 06/28/2016 06:43 AM, Ozgur Batur wrote:
> > On Mon, Jun 27, 2016 at 7:57 PM, Alex Rousskov wrote:
> >     FWIW, several things are needed to move forward, including:
> >
> >     1. Adequate development time and skills (or sponsorship to pay for
> >        them). The development of an essentially new adaptation vectoring
> >        point is not a trivial project.
>
>
> > I have involved in development of several ICAP services around Squid but
> > have not had the chance to work on Squid code base directly. We may
> > attempt implement a proof of concept with a few friends to better
> > specify the task at hand current and learn about adaptation
> > infrastructure of Squid.
>
> I recommend starting with the proposal described in my item #2. A proof
> of concept is usually needed when there is doubt that the concept can
> work in principle. There is no such doubt here IMO.
>

That's great to hear that it is doable. But a solid proposal will require
some preliminary work, at least if it comes from my side :)


>
> >     2. A specific proposal on how to map raw/tunnel data to HTTP messages
> >        that eCAP and ICAP interfaces expect. The biggest difficulty here
> >        may be mapping server-speaks-first protocols.
>
>
> > I am not sure if it is possible to map websocket data to current
> > adaptation services.
>
> It is possible to map virtually anything to HTTP messages and, hence, to
> eCAP/ICAP. For example, Squid maps FTP transactions to HTTP messages! A
> better mapping would preserve more information, make it easier to access
> that information by services that understand the protocol being mapped,
> have lower overhead, etc. However, it is clearly "possible" to come up
> with some mapping.
>
>
This is http://wiki.squid-cache.org/Features/FtpRelay feature right?
Previously Squid only supported FTP over HTTP, great improvement!


>
> > Actually it may or may not be related but I am
> > curious how Squid handles Comet(Ajax/HTTP Server Push) during ICAP
> > processing.
>
> Squid proxies regular HTTP/1 and FTP. That excludes pure server push
> until we add HTTP/2 support.
>
>
> > About server first protocols, current ICAP services expecting
> > encapsulated valid HTTP responses for requests will break of course.
>
> I do not think so. A proper mapping could present that spontaneous
> from-server message as an HTTP response to a trivial fake request
> (enough to identify the protocol and the server address).
>
> Needless to say, the WebSockets:HTTP mapping (and overall Squid
> functionality) can be improved if Squid understands WebSockets (as Amos
> has noted in his response), but I do not think such understanding is
> _required_ to accommodate many useful adaptation use cases.
>
>
> > Maybe a mechanism like Allow 204 negotiation can be implemented between
> > adaptation service and proxy. If adaptation service does not support
> > server first pushes it can be bypassed.
>
> It is always possible to extend ICAP and eCAP, but, with all other
> factors being equal, extending should be a last-resort solution because
> most adaptation services will not support the extension and many of
> those services could work fine without that extension.
>
>
> HTH,
>
> Alex.
>
>
Thank you very much Alex, Amos. I will discuss this issue with other
interested people, maybe I can find some resources. Also I need to do some
homework.

Best Regards,

Ozgur
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160628/93307496/attachment.htm>

From cbidwell at usgs.gov  Tue Jun 28 21:19:10 2016
From: cbidwell at usgs.gov (Bidwell, Christopher)
Date: Tue, 28 Jun 2016 15:19:10 -0600
Subject: [squid-users] Config changes between 2.7 and 3.5
Message-ID: <CAJN-FKnGJwYvzurgjB=ad+hO4qMXdTBzpdf-HQAaHuxsPHZSbA@mail.gmail.com>

Hi all,

I'm trying to find what's used to replace these:

squid 2.7                           squid 3.5
--------------------------------------------------
zero_buffers                      ???
refresh_stale_hit               ???
ignore_ims_on_miss         ???

Thanks!

I'm getting these error messages when trying to upgrade to 3.5:

2016/06/28 21:10:00| ERROR: Directive 'zero_buffers' is obsolete.
2016/06/28 21:10:00| ERROR: Directive 'refresh_stale_hit' is obsolete.
2016/06/28 21:10:00| ERROR: Directive 'ignore_ims_on_miss' is obsolete.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160628/61991925/attachment.htm>

From stan.prescott at gmail.com  Tue Jun 28 23:47:47 2016
From: stan.prescott at gmail.com (Stanford Prescott)
Date: Tue, 28 Jun 2016 18:47:47 -0500
Subject: [squid-users] Squid 3.5.19 how to find banking server name for
	no bump
In-Reply-To: <84e35d81-1e53-83ed-b2b8-9f34f1497aad@treenet.co.nz>
References: <CANLNtGQecOFjb9H+4MbOu7Fu8NFHNooLxKFLhh8sBEu=vNzQuA@mail.gmail.com>
 <84e35d81-1e53-83ed-b2b8-9f34f1497aad@treenet.co.nz>
Message-ID: <CANLNtGQAMssG976sXt+5SK+ddDGBBYzPdcr5qDSSNWKRb5H76A@mail.gmail.com>

When I enter .wellsfargo.com in

*acl tls_s1_connect at_step SslBump1*
*acl tls_s2_client_hello at_step SslBump2*
*acl tls_s3_server_hello at_step SslBump3*

*acl tls_server_name_is_ip ssl::server_name_regex
^[0-9]+.[0-9]+.[0-9]+.[0-9]+n*
*acl tls_allowed_hsts ssl::server_name .akamaihd.net <http://akamaihd.net>*
*acl tls_server_is_bank ssl::server_name .wellsfargo.com
<http://wellsfargo.com>*
*acl tls_to_splice any-of tls_allowed_hsts tls_server_is_bank*

*ssl_bump peek tls_s1_connect all*
*ssl_bump splice tls_s2_client_hello tls_to_splice*
*ssl_bump stare tls_s2_client_hello all*
*ssl_bump bump tls_s3_server_hello all*


it appears that the banking site is still getting bumped i.e.like in this
access.log snippet

*1467156887.817    257 10.40.40.100 TAG_NONE/200 0 CONNECT
54.149.224.177:443 <http://54.149.224.177:443> -
ORIGINAL_DST/54.149.224.177 <http://54.149.224.177> -*
*1467156888.008     94 10.40.40.100 TCP_MISS/200 213 POST
https://tiles.services.mozilla.com/v2/links/view
<https://tiles.services.mozilla.com/v2/links/view> -
ORIGINAL_DST/54.149.224.177 <http://54.149.224.177> application/json*
*1467156893.774     75 10.40.40.100 TAG_NONE/200 0 CONNECT
172.230.102.185:443 <http://172.230.102.185:443> -
ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
*1467156893.847    117 10.40.40.100 TAG_NONE/200 0 CONNECT
172.230.102.185:443 <http://172.230.102.185:443> -
ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
*1467156893.875    120 10.40.40.100 TAG_NONE/200 0 CONNECT
172.230.221.75:443 <http://172.230.221.75:443> -
ORIGINAL_DST/172.230.221.75 <http://172.230.221.75> -*
*1467156893.875    111 10.40.40.100 TAG_NONE/200 0 CONNECT
172.230.102.185:443 <http://172.230.102.185:443> -
ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
*1467156893.875    117 10.40.40.100 TAG_NONE/200 0 CONNECT
172.230.221.75:443 <http://172.230.221.75:443> -
ORIGINAL_DST/172.230.221.75 <http://172.230.221.75> -*
*1467156893.875    117 10.40.40.100 TAG_NONE/200 0 CONNECT
172.230.221.75:443 <http://172.230.221.75:443> -
ORIGINAL_DST/172.230.221.75 <http://172.230.221.75> -*
*1467156893.875    112 10.40.40.100 TAG_NONE/200 0 CONNECT
172.230.102.185:443 <http://172.230.102.185:443> -
ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
*1467156893.875    111 10.40.40.100 TAG_NONE/200 0 CONNECT
172.230.102.185:443 <http://172.230.102.185:443> -
ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
*1467156894.109    307 10.40.40.100 TAG_NONE/200 0 CONNECT
172.230.102.185:443 <http://172.230.102.185:443> -
ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
*1467156894.109    306 10.40.40.100 TAG_NONE/200 0 CONNECT
172.230.102.185:443 <http://172.230.102.185:443> -
ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
*1467156894.109    307 10.40.40.100 TAG_NONE/200 0 CONNECT
172.230.102.185:443 <http://172.230.102.185:443> -
ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
*1467156894.109    308 10.40.40.100 TAG_NONE/200 0 CONNECT
172.230.102.185:443 <http://172.230.102.185:443> -
ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
*1467156895.488     72 10.40.40.100 TAG_NONE/200 0 CONNECT
216.58.194.98:443 <http://216.58.194.98:443> - ORIGINAL_DST/216.58.194.98
<http://216.58.194.98> -*
*1467156895.513     98 10.40.40.100 TAG_NONE/200 0 CONNECT
216.58.194.70:443 <http://216.58.194.70:443> - ORIGINAL_DST/216.58.194.70
<http://216.58.194.70> -*
*1467156895.648     66 10.40.40.100 TCP_MISS/302 739 GET
https://googleads.g.doubleclick.net/pagead/viewthroughconversion/974108101/?value=0&guid=ON&script=0&data.prod=&data.subprod=&data.pageid=
<https://googleads.g.doubleclick.net/pagead/viewthroughconversion/974108101/?value=0&guid=ON&script=0&data.prod=&data.subprod=&data.pageid=>
- ORIGINAL_DST/216.58.194.98 <http://216.58.194.98> image/gif*
*1467156895.664     82 10.40.40.100 TCP_MISS/200 649 GET
https://ad.doubleclick.net/activity;src=2549153;type=allv40;cat=all_a00;u1=11201507281102291611922021;ord=6472043235332.808
<https://ad.doubleclick.net/activity;src=2549153;type=allv40;cat=all_a00;u1=11201507281102291611922021;ord=6472043235332.808>?
- ORIGINAL_DST/216.58.194.70 <http://216.58.194.70> image/gif*
*1467156895.920    250 10.40.40.100 TAG_NONE/200 0 CONNECT 24.155.92.60:443
<http://24.155.92.60:443> - ORIGINAL_DST/24.155.92.60 <http://24.155.92.60>
-*
*1467156896.061     79 10.40.40.100 TCP_MISS/200 503 GET
https://www.google.com/ads/user-lists/974108101/?script=0&random=2433874630
<https://www.google.com/ads/user-lists/974108101/?script=0&random=2433874630>
- ORIGINAL_DST/24.155.92.60 <http://24.155.92.60> image/gif*
*1467156899.837   5727 10.40.40.100 TAG_NONE/200 0 CONNECT
159.45.66.156:443 <http://159.45.66.156:443> - HIER_NONE/- -*
*1467156899.837   5587 10.40.40.100 TCP_TUNNEL/200 165 CONNECT
connect.secure.wellsfargo.com:443
<http://connect.secure.wellsfargo.com:443> - ORIGINAL_DST/159.45.66.156
<http://159.45.66.156> -*
*1467156899.837   5679 10.40.40.100 TAG_NONE/200 0 CONNECT
159.45.66.156:443 <http://159.45.66.156:443> - HIER_NONE/- -*
*1467156899.837   5587 10.40.40.100 TCP_TUNNEL/200 165 CONNECT
connect.secure.wellsfargo.com:443
<http://connect.secure.wellsfargo.com:443> - ORIGINAL_DST/159.45.66.156
<http://159.45.66.156> -*
*1467156899.838   5680 10.40.40.100 TAG_NONE/200 0 CONNECT
159.45.66.156:443 <http://159.45.66.156:443> - HIER_NONE/- -*
*1467156899.838   5588 10.40.40.100 TCP_TUNNEL/200 165 CONNECT
connect.secure.wellsfargo.com:443
<http://connect.secure.wellsfargo.com:443> - ORIGINAL_DST/159.45.66.156
<http://159.45.66.156> -*
*1467156900.836   5421 10.40.40.100 TAG_NONE/200 0 CONNECT
159.45.170.145:443 <http://159.45.170.145:443> - HIER_NONE/- -*
*1467156900.836   5042 10.40.40.100 TCP_TUNNEL/200 4631 CONNECT
www.wellsfargo.com:443 <http://www.wellsfargo.com:443> -
ORIGINAL_DST/159.45.170.145 <http://159.45.170.145> -*
*1467156900.837   5423 10.40.40.100 TAG_NONE/200 0 CONNECT 159.45.2.142:443
<http://159.45.2.142:443> - HIER_NONE/- -*
*1467156900.837   5139 10.40.40.100 TCP_TUNNEL/200 4043 CONNECT
static.wellsfargo.com:443 <http://static.wellsfargo.com:443> -
ORIGINAL_DST/159.45.2.142 <http://159.45.2.142> -*
*1467156900.838   5423 10.40.40.100 TAG_NONE/200 0 CONNECT
159.45.170.145:443 <http://159.45.170.145:443> - HIER_NONE/- -*
*1467156900.838   5088 10.40.40.100 TCP_TUNNEL/200 4631 CONNECT
www.wellsfargo.com:443 <http://www.wellsfargo.com:443> -
ORIGINAL_DST/159.45.170.145 <http://159.45.170.145> -*

If I disable sslbumping then the bank site does not get bumped, of course.

1467157349.321    230 10.40.40.100 TCP_MISS/301 243 GET
http://wellsfargo.com/ - ORIGINAL_DST/159.45.66.143 -

Here is my squid.conf with bumping enabled.

visible_hostname smoothwall

# Uncomment the following to send debug info to /var/log/squid/cache.log
#debug_options ALL,1 33,2 28,9

# ACCESS CONTROLS
# ----------------------------------------------------------------
acl localhostgreen src 10.40.40.1
acl localnetgreen src 10.40.40.0/24
acl SWE_subnets          src
"/var/smoothwall/mods/proxy/acls/src_subnets.acl"

acl SSL_ports port 445 443 441 563
acl Safe_ports port 80     # http
acl Safe_ports port 81     # smoothwall http
acl Safe_ports port 21     # ftp
acl Safe_ports port 445 443 441 563 # https, snews
acl Safe_ports port 70     # gopher
acl Safe_ports port 210       # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280       # http-mgmt
acl Safe_ports port 488       # gss-http
acl Safe_ports port 591       # filemaker
acl Safe_ports port 777       # multiling http

acl CONNECT method CONNECT

# TAG: http_access
# ----------------------------------------------------------------

http_access allow SWE_subnets


http_access allow localhost
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports

http_access allow localnetgreen
http_access allow CONNECT localnetgreen

http_access allow localhostgreen
http_access allow CONNECT localhostgreen

# http_port and https_port
#----------------------------------------------------------------------------

# For forward-proxy port. Squid uses this port to serve error pages, ftp
icons and communication with other proxies.
#----------------------------------------------------------------------------
http_port 3127

http_port 10.40.40.1:800 intercept
https_port 10.40.40.1:808 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB
cert=/var/smoothwall/mods/proxy/ssl_cert/squidCA.pem
sslflags=VERIFY_CRL_ALL options=NO_SSLv2,NO_SSLv3,No_Compression
dhparams=/var/smoothwall/mods/proxy/ssl_cert/dhparam.pem


http_port 127.0.0.1:800 intercept

sslproxy_session_cache_size 4 MB

ssl_bump none localhostgreen

sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression
sslproxy_cipher
ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:!aNULL:!eNULL

acl tls_s1_connect at_step SslBump1
acl tls_s2_client_hello at_step SslBump2
acl tls_s3_server_hello at_step SslBump3

acl tls_allowed_hsts ssl::server_name .akamaihd.net
acl tls_server_is_bank ssl::server_name .wellsfargo.com
acl tls_to_splice any-of tls_allowed_hsts tls_server_is_bank

ssl_bump peek tls_s1_connect all
ssl_bump splice tls_s2_client_hello tls_to_splice
ssl_bump stare tls_s2_client_hello all
ssl_bump bump tls_s3_server_hello all

sslproxy_cert_error deny all
sslproxy_flags DONT_VERIFY_PEER
sslcrtd_program /var/smoothwall/mods/proxy/libexec/ssl_crtd -s
/var/smoothwall/mods/proxy/lib/ssl_db -M 4MB
sslcrtd_children 5

http_access deny all

cache_replacement_policy heap GDSF
memory_replacement_policy heap GDSF

# CACHE OPTIONS
#
----------------------------------------------------------------------------
cache_effective_user squid
cache_effective_group squid

cache_swap_high 100
cache_swap_low 80

cache_access_log stdio:/var/log/squid/access.log
cache_log /var/log/squid/cache.log
cache_mem 64 MB

cache_dir aufs /var/spool/squid/cache 1024 16 256

maximum_object_size 33 MB

minimum_object_size 0 KB


request_body_max_size 0 KB

# OTHER OPTIONS
#
----------------------------------------------------------------------------
#via off
forwarded_for off

pid_filename /var/run/squid.pid

shutdown_lifetime 10 seconds
#icp_port 3130

half_closed_clients off

umask 022

logfile_rotate 0

strip_query_terms off





On Tue, Jun 28, 2016 at 9:56 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 29/06/2016 2:02 a.m., Stanford Prescott wrote:
> > I have the proper peek and splice and bump configuration of acls setup in
> > my squid.conf file for no-bump of some web sites. I need help how to
> enter
> > the banking hosts and or server names in a way that the peek and splice
> > configuration will determine it is a banking site that I don't want
> bumped.
> >
> > For example, if a user enters www.wellsfargo.com for online banking my
> > current config still bumps wellsfargo.com. What would I need to enter
> for
> > wellsfargo.com so that banking server will not be bumped?
> >
>
> Depends on what you mean by "enter".
>
> Are you asking for the ACL value?
>   .wellfargo.com
>
> Are you asking for the ACL definition?
>  acl banks ssl::server_name .wellsfargo.com
>
> Or are you asking for a whole SSL-Bump configuration example?
>  <http://wiki.squid-cache.org/Features/SslPeekAndSplice> has a few.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160628/bc409bc1/attachment.htm>

From stan.prescott at gmail.com  Tue Jun 28 23:56:11 2016
From: stan.prescott at gmail.com (Stanford Prescott)
Date: Tue, 28 Jun 2016 18:56:11 -0500
Subject: [squid-users] Squid 3.5.19 how to find banking server name for
	no bump
In-Reply-To: <CANLNtGQAMssG976sXt+5SK+ddDGBBYzPdcr5qDSSNWKRb5H76A@mail.gmail.com>
References: <CANLNtGQecOFjb9H+4MbOu7Fu8NFHNooLxKFLhh8sBEu=vNzQuA@mail.gmail.com>
 <84e35d81-1e53-83ed-b2b8-9f34f1497aad@treenet.co.nz>
 <CANLNtGQAMssG976sXt+5SK+ddDGBBYzPdcr5qDSSNWKRb5H76A@mail.gmail.com>
Message-ID: <CANLNtGSLiJ3KJ8WGG+S_cF7Wn-6ofAEGt_7k_0QdncirxAxeqQ@mail.gmail.com>

I forgot to mention, I am using squid 3.5.19

On Tue, Jun 28, 2016 at 6:47 PM, Stanford Prescott <stan.prescott at gmail.com>
wrote:

> When I enter .wellsfargo.com in
>
> *acl tls_s1_connect at_step SslBump1*
> *acl tls_s2_client_hello at_step SslBump2*
> *acl tls_s3_server_hello at_step SslBump3*
>
> *acl tls_server_name_is_ip ssl::server_name_regex
> ^[0-9]+.[0-9]+.[0-9]+.[0-9]+n*
> *acl tls_allowed_hsts ssl::server_name .akamaihd.net <http://akamaihd.net>*
> *acl tls_server_is_bank ssl::server_name .wellsfargo.com
> <http://wellsfargo.com>*
> *acl tls_to_splice any-of tls_allowed_hsts tls_server_is_bank*
>
> *ssl_bump peek tls_s1_connect all*
> *ssl_bump splice tls_s2_client_hello tls_to_splice*
> *ssl_bump stare tls_s2_client_hello all*
> *ssl_bump bump tls_s3_server_hello all*
>
>
> it appears that the banking site is still getting bumped i.e.like in this
> access.log snippet
>
> *1467156887.817    257 10.40.40.100 TAG_NONE/200 0 CONNECT
> 54.149.224.177:443 <http://54.149.224.177:443> -
> ORIGINAL_DST/54.149.224.177 <http://54.149.224.177> -*
> *1467156888.008     94 10.40.40.100 TCP_MISS/200 213 POST
> https://tiles.services.mozilla.com/v2/links/view
> <https://tiles.services.mozilla.com/v2/links/view> -
> ORIGINAL_DST/54.149.224.177 <http://54.149.224.177> application/json*
> *1467156893.774     75 10.40.40.100 TAG_NONE/200 0 CONNECT
> 172.230.102.185:443 <http://172.230.102.185:443> -
> ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
> *1467156893.847    117 10.40.40.100 TAG_NONE/200 0 CONNECT
> 172.230.102.185:443 <http://172.230.102.185:443> -
> ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
> *1467156893.875    120 10.40.40.100 TAG_NONE/200 0 CONNECT
> 172.230.221.75:443 <http://172.230.221.75:443> -
> ORIGINAL_DST/172.230.221.75 <http://172.230.221.75> -*
> *1467156893.875    111 10.40.40.100 TAG_NONE/200 0 CONNECT
> 172.230.102.185:443 <http://172.230.102.185:443> -
> ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
> *1467156893.875    117 10.40.40.100 TAG_NONE/200 0 CONNECT
> 172.230.221.75:443 <http://172.230.221.75:443> -
> ORIGINAL_DST/172.230.221.75 <http://172.230.221.75> -*
> *1467156893.875    117 10.40.40.100 TAG_NONE/200 0 CONNECT
> 172.230.221.75:443 <http://172.230.221.75:443> -
> ORIGINAL_DST/172.230.221.75 <http://172.230.221.75> -*
> *1467156893.875    112 10.40.40.100 TAG_NONE/200 0 CONNECT
> 172.230.102.185:443 <http://172.230.102.185:443> -
> ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
> *1467156893.875    111 10.40.40.100 TAG_NONE/200 0 CONNECT
> 172.230.102.185:443 <http://172.230.102.185:443> -
> ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
> *1467156894.109    307 10.40.40.100 TAG_NONE/200 0 CONNECT
> 172.230.102.185:443 <http://172.230.102.185:443> -
> ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
> *1467156894.109    306 10.40.40.100 TAG_NONE/200 0 CONNECT
> 172.230.102.185:443 <http://172.230.102.185:443> -
> ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
> *1467156894.109    307 10.40.40.100 TAG_NONE/200 0 CONNECT
> 172.230.102.185:443 <http://172.230.102.185:443> -
> ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
> *1467156894.109    308 10.40.40.100 TAG_NONE/200 0 CONNECT
> 172.230.102.185:443 <http://172.230.102.185:443> -
> ORIGINAL_DST/172.230.102.185 <http://172.230.102.185> -*
> *1467156895.488     72 10.40.40.100 TAG_NONE/200 0 CONNECT
> 216.58.194.98:443 <http://216.58.194.98:443> - ORIGINAL_DST/216.58.194.98
> <http://216.58.194.98> -*
> *1467156895.513     98 10.40.40.100 TAG_NONE/200 0 CONNECT
> 216.58.194.70:443 <http://216.58.194.70:443> - ORIGINAL_DST/216.58.194.70
> <http://216.58.194.70> -*
> *1467156895.648     66 10.40.40.100 TCP_MISS/302 739 GET
> https://googleads.g.doubleclick.net/pagead/viewthroughconversion/974108101/?value=0&guid=ON&script=0&data.prod=&data.subprod=&data.pageid=
> <https://googleads.g.doubleclick.net/pagead/viewthroughconversion/974108101/?value=0&guid=ON&script=0&data.prod=&data.subprod=&data.pageid=>
> - ORIGINAL_DST/216.58.194.98 <http://216.58.194.98> image/gif*
> *1467156895.664     82 10.40.40.100 TCP_MISS/200 649 GET
> https://ad.doubleclick.net/activity;src=2549153;type=allv40;cat=all_a00;u1=11201507281102291611922021;ord=6472043235332.808
> <https://ad.doubleclick.net/activity;src=2549153;type=allv40;cat=all_a00;u1=11201507281102291611922021;ord=6472043235332.808>?
> - ORIGINAL_DST/216.58.194.70 <http://216.58.194.70> image/gif*
> *1467156895.920    250 10.40.40.100 TAG_NONE/200 0 CONNECT
> 24.155.92.60:443 <http://24.155.92.60:443> - ORIGINAL_DST/24.155.92.60
> <http://24.155.92.60> -*
> *1467156896.061     79 10.40.40.100 TCP_MISS/200 503 GET
> https://www.google.com/ads/user-lists/974108101/?script=0&random=2433874630
> <https://www.google.com/ads/user-lists/974108101/?script=0&random=2433874630>
> - ORIGINAL_DST/24.155.92.60 <http://24.155.92.60> image/gif*
> *1467156899.837   5727 10.40.40.100 TAG_NONE/200 0 CONNECT
> 159.45.66.156:443 <http://159.45.66.156:443> - HIER_NONE/- -*
> *1467156899.837   5587 10.40.40.100 TCP_TUNNEL/200 165 CONNECT
> connect.secure.wellsfargo.com:443
> <http://connect.secure.wellsfargo.com:443> - ORIGINAL_DST/159.45.66.156
> <http://159.45.66.156> -*
> *1467156899.837   5679 10.40.40.100 TAG_NONE/200 0 CONNECT
> 159.45.66.156:443 <http://159.45.66.156:443> - HIER_NONE/- -*
> *1467156899.837   5587 10.40.40.100 TCP_TUNNEL/200 165 CONNECT
> connect.secure.wellsfargo.com:443
> <http://connect.secure.wellsfargo.com:443> - ORIGINAL_DST/159.45.66.156
> <http://159.45.66.156> -*
> *1467156899.838   5680 10.40.40.100 TAG_NONE/200 0 CONNECT
> 159.45.66.156:443 <http://159.45.66.156:443> - HIER_NONE/- -*
> *1467156899.838   5588 10.40.40.100 TCP_TUNNEL/200 165 CONNECT
> connect.secure.wellsfargo.com:443
> <http://connect.secure.wellsfargo.com:443> - ORIGINAL_DST/159.45.66.156
> <http://159.45.66.156> -*
> *1467156900.836   5421 10.40.40.100 TAG_NONE/200 0 CONNECT
> 159.45.170.145:443 <http://159.45.170.145:443> - HIER_NONE/- -*
> *1467156900.836   5042 10.40.40.100 TCP_TUNNEL/200 4631 CONNECT
> www.wellsfargo.com:443 <http://www.wellsfargo.com:443> -
> ORIGINAL_DST/159.45.170.145 <http://159.45.170.145> -*
> *1467156900.837   5423 10.40.40.100 TAG_NONE/200 0 CONNECT
> 159.45.2.142:443 <http://159.45.2.142:443> - HIER_NONE/- -*
> *1467156900.837   5139 10.40.40.100 TCP_TUNNEL/200 4043 CONNECT
> static.wellsfargo.com:443 <http://static.wellsfargo.com:443> -
> ORIGINAL_DST/159.45.2.142 <http://159.45.2.142> -*
> *1467156900.838   5423 10.40.40.100 TAG_NONE/200 0 CONNECT
> 159.45.170.145:443 <http://159.45.170.145:443> - HIER_NONE/- -*
> *1467156900.838   5088 10.40.40.100 TCP_TUNNEL/200 4631 CONNECT
> www.wellsfargo.com:443 <http://www.wellsfargo.com:443> -
> ORIGINAL_DST/159.45.170.145 <http://159.45.170.145> -*
>
> If I disable sslbumping then the bank site does not get bumped, of course.
>
> 1467157349.321    230 10.40.40.100 TCP_MISS/301 243 GET
> http://wellsfargo.com/ - ORIGINAL_DST/159.45.66.143 -
>
> Here is my squid.conf with bumping enabled.
>
> visible_hostname smoothwall
>
> # Uncomment the following to send debug info to /var/log/squid/cache.log
> #debug_options ALL,1 33,2 28,9
>
> # ACCESS CONTROLS
> # ----------------------------------------------------------------
> acl localhostgreen src 10.40.40.1
> acl localnetgreen src 10.40.40.0/24
> acl SWE_subnets          src
> "/var/smoothwall/mods/proxy/acls/src_subnets.acl"
>
> acl SSL_ports port 445 443 441 563
> acl Safe_ports port 80     # http
> acl Safe_ports port 81     # smoothwall http
> acl Safe_ports port 21     # ftp
> acl Safe_ports port 445 443 441 563 # https, snews
> acl Safe_ports port 70     # gopher
> acl Safe_ports port 210       # wais
> acl Safe_ports port 1025-65535 # unregistered ports
> acl Safe_ports port 280       # http-mgmt
> acl Safe_ports port 488       # gss-http
> acl Safe_ports port 591       # filemaker
> acl Safe_ports port 777       # multiling http
>
> acl CONNECT method CONNECT
>
> # TAG: http_access
> # ----------------------------------------------------------------
>
> http_access allow SWE_subnets
>
>
> http_access allow localhost
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
>
> http_access allow localnetgreen
> http_access allow CONNECT localnetgreen
>
> http_access allow localhostgreen
> http_access allow CONNECT localhostgreen
>
> # http_port and https_port
>
> #----------------------------------------------------------------------------
>
> # For forward-proxy port. Squid uses this port to serve error pages, ftp
> icons and communication with other proxies.
>
> #----------------------------------------------------------------------------
> http_port 3127
>
> http_port 10.40.40.1:800 intercept
> https_port 10.40.40.1:808 intercept ssl-bump
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> cert=/var/smoothwall/mods/proxy/ssl_cert/squidCA.pem
> sslflags=VERIFY_CRL_ALL options=NO_SSLv2,NO_SSLv3,No_Compression
> dhparams=/var/smoothwall/mods/proxy/ssl_cert/dhparam.pem
>
>
> http_port 127.0.0.1:800 intercept
>
> sslproxy_session_cache_size 4 MB
>
> ssl_bump none localhostgreen
>
> sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression
> sslproxy_cipher
> ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:!aNULL:!eNULL
>
> acl tls_s1_connect at_step SslBump1
> acl tls_s2_client_hello at_step SslBump2
> acl tls_s3_server_hello at_step SslBump3
>
> acl tls_allowed_hsts ssl::server_name .akamaihd.net
> acl tls_server_is_bank ssl::server_name .wellsfargo.com
> acl tls_to_splice any-of tls_allowed_hsts tls_server_is_bank
>
> ssl_bump peek tls_s1_connect all
> ssl_bump splice tls_s2_client_hello tls_to_splice
> ssl_bump stare tls_s2_client_hello all
> ssl_bump bump tls_s3_server_hello all
>
> sslproxy_cert_error deny all
> sslproxy_flags DONT_VERIFY_PEER
> sslcrtd_program /var/smoothwall/mods/proxy/libexec/ssl_crtd -s
> /var/smoothwall/mods/proxy/lib/ssl_db -M 4MB
> sslcrtd_children 5
>
> http_access deny all
>
> cache_replacement_policy heap GDSF
> memory_replacement_policy heap GDSF
>
> # CACHE OPTIONS
> #
> ----------------------------------------------------------------------------
> cache_effective_user squid
> cache_effective_group squid
>
> cache_swap_high 100
> cache_swap_low 80
>
> cache_access_log stdio:/var/log/squid/access.log
> cache_log /var/log/squid/cache.log
> cache_mem 64 MB
>
> cache_dir aufs /var/spool/squid/cache 1024 16 256
>
> maximum_object_size 33 MB
>
> minimum_object_size 0 KB
>
>
> request_body_max_size 0 KB
>
> # OTHER OPTIONS
> #
> ----------------------------------------------------------------------------
> #via off
> forwarded_for off
>
> pid_filename /var/run/squid.pid
>
> shutdown_lifetime 10 seconds
> #icp_port 3130
>
> half_closed_clients off
>
> umask 022
>
> logfile_rotate 0
>
> strip_query_terms off
>
>
>
>
>
> On Tue, Jun 28, 2016 at 9:56 AM, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
>
>> On 29/06/2016 2:02 a.m., Stanford Prescott wrote:
>> > I have the proper peek and splice and bump configuration of acls setup
>> in
>> > my squid.conf file for no-bump of some web sites. I need help how to
>> enter
>> > the banking hosts and or server names in a way that the peek and splice
>> > configuration will determine it is a banking site that I don't want
>> bumped.
>> >
>> > For example, if a user enters www.wellsfargo.com for online banking my
>> > current config still bumps wellsfargo.com. What would I need to enter
>> for
>> > wellsfargo.com so that banking server will not be bumped?
>> >
>>
>> Depends on what you mean by "enter".
>>
>> Are you asking for the ACL value?
>>   .wellfargo.com
>>
>> Are you asking for the ACL definition?
>>  acl banks ssl::server_name .wellsfargo.com
>>
>> Or are you asking for a whole SSL-Bump configuration example?
>>  <http://wiki.squid-cache.org/Features/SslPeekAndSplice> has a few.
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160628/1ef8c887/attachment.htm>

From squid3 at treenet.co.nz  Wed Jun 29 00:26:42 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 29 Jun 2016 12:26:42 +1200
Subject: [squid-users] large downloads got interrupted
In-Reply-To: <57723949.1060504@norma.perm.ru>
References: <57723949.1060504@norma.perm.ru>
Message-ID: <16f57ceb-f22e-25e8-ee5c-dfc3e9eeb7fa@treenet.co.nz>

On 28/06/2016 8:46 p.m., Eugene M. Zheganin wrote:
> Hi,
> 
> recently I started to get the problem when large downloads via squid are
> often interrupted. I tried to investigate it, but, to be honest, got
> nowhere. However, I took two tcpdump captures, and it seems to me that
> for some reason squid sends FIN to it's client and correctly closes the
> connection (wget reports that connection is closed), and in the same
> time for some reason it sends like tonns of RSTs towards the server. No
> errors in logs are reported (at least on a  ALL,1 loglevel).
> 

It sounds like a timeout or such has happened inside Squid. We'd need to
see your squid.conf to see if that was it.

What version are you using? there have been a few bugs found that can
cause unrelated connections to be closed early like this.

> Screenshots of wireshark interpreting the tcpdump capture are here:
> 

?? URL sems not to have made it to the mailing list.


> Squid(2a00:7540:1::4) to target server(2a02:6b8::183):
> 
> http://static.enaza.ru/userupload/gyazo/e5b976bf6f3d0cb666f0d504de04.png
> (here you can see that all of a sudden squid starts sending RSTs, that
> come long way down the screen, then connection reestablishes (not on the
> screenshot taken))

Screen dump of packet capture does not usually help. We usually only ask
for packet captures when one of the dev needs to personally analyse the
full traffic behaviour.

A cache.log trace at debug level 11,2 shows all the HTTP messages going
through in an easier format to read. There might be hints in there, but
if it is a timeout like I suspect probably not.

> 
> Squid(fd00::301) to client(fd00::73d):
> 
> http://static.enaza.ru/userupload/gyazo/ccf4982593dc6047edb5d734160e.png  (here
> you can see the client connection got closed)

So Squid is closing both connections from the middle. That is pointing
strongly at a timeout, bug, or error in the data transfer.

Amos



From squid3 at treenet.co.nz  Wed Jun 29 01:02:46 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 29 Jun 2016 13:02:46 +1200
Subject: [squid-users] Running squid on a machine with only one network
 interface.
In-Reply-To: <c6xAIjgM5eCdqy4186XDx3IpvobaoFMKp4idALuNuhv01NXHblYftbJDiNiDIcvbGpTPYvou2Uoe6EE4l8-KQw==@protonmail.ch>
References: <km0veN2AohDivh1p8WaGCSUiXPJ8Ryh1kP7Nwqne7MHgFAlMbdO46-rLEJbnyQPKIpPTsVsjQFOBW1s1WXhpGw==@protonmail.ch>
 <201606272256.40878.Antony.Stone@squid.open.source.it>
 <c6xAIjgM5eCdqy4186XDx3IpvobaoFMKp4idALuNuhv01NXHblYftbJDiNiDIcvbGpTPYvou2Uoe6EE4l8-KQw==@protonmail.ch>
Message-ID: <e339451b-1310-a689-7f75-b69c6fc5afff@treenet.co.nz>

On 29/06/2016 1:49 a.m., Ataro wrote:
> Hi and thanks for your help.
> 
> as for your request, here's the content of my IPFW rules and my squid configuration:
> 
> IPFW rules:
> 
> ipfw -f flush
> ipfw add 50 pass all from any to any via lo0
> ipfw add 100 pass all from any to any proto udp
> ipfw add 150 pass icmp from any to any
> ipfw add 200 fwd 127.0.0.1,3128 tag 1111 tcp from me to any
> ipfw add 250 pass all from 10.0.2.15 to any tagged 1111
> 

You said earlier there was a VM running Squid.

Do not use localhost IP addresses for any of this. Use the globally
routable IP assigned to the VM.

Do not tag the traffic in IPFW. Squid uses tcp_outgoing_tos or *_mark
directives to tag its outgoing the traffic. The firewall just uses those
tags for tags exceptions.



> squid.conf:
> 
> acl my_machine src 10.0.2.15 # this is the ip of my machine.

So what?..

> http_access allow my_machine
> 

... Ah. Open proxy!

And since this is in 10.*/8 the localnet ACL will also allow the traffic
through, but after some basic safety checks.

Which means the above ACL and rule are not useful.


> acl localnet src 10.0.0.0/8 # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12 # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl localnet src fc00::/7 # RFC 4193 local private network range
> acl localnet src fe80::/10 # RFC 4291 link-local (directly plugged) machines
> 
<snip ...>
> 
> http_access deny !Safe_ports
> 
> http_access deny CONNECT !SSL_ports
> 
> 
> http_access allow localhost manager
> http_access deny manager
> 
> visible_hostname mynet.mydomain
> acl MYSITE dstdomain cnn.com


Matches http://cnn.com/* URLs.

I'm pointing that out to highlight that it wont match sub-domains like
www.cnn.com etc.

> acl MYSITE dstdomain 10.0.2.15

Matches http://10.0.2.15/* URLs.

> http_access allow MYSITE
> 

The MYSITE stuff is also not needed since traffic comes from a 10.*
machine. The "allow localnet" line right below will let that traffic
through, and much more.

> http_access allow localnet
> http_access allow localhost
> 
> http_access deny all
> 
> http_port 127.0.0.1:3128 intercept
> http_port 3129

Replace that with:
  http_port 3129 intercept
  http_port 3128

Why? 3128 is a well known port for proxy traffic. It can be very
dangerous to use a known port for intercept. There are also some changes
coming in future Squid that will prevent the registered ports being used
for special modes like intercept.


Notice that after the above changes that the only thing different from
the default squid.conf is your new "intercept" port line.

> 
> I'm almost surely that the problem is that as other people said here, the firewall redirect the traffic originated from the squid server back to squid and hence the forwarding loop.
> 
> I've tried to allow the traffic originated from the squid server by using the "tag/tagged" feature in the IPFW rules but this doesn't work, apparently because squid issue a new connection that is not tagged.

Yes.

> since squid and the firewall resides on the same machine I've no idea how to tell the firewall to allow the traffic which squid initiate.

You spoke earlier about Squid being inside a VM. In the above sentence
do you mean "same machine" as in hardware machine, or both are in the VM
? there is an important difference, and for this setup to work you need
to treat them as if they were different hardware communicating via
TCP/IP over a LAN.

Amos



From squid-cache at pixelrebel.com  Wed Jun 29 01:04:42 2016
From: squid-cache at pixelrebel.com (squid-cache at pixelrebel.com)
Date: Tue, 28 Jun 2016 18:04:42 -0700
Subject: [squid-users] Subject: Bandwidth Ceiling
Message-ID: <57731eaa.+aPVUTpJuDI54/wc%squid-cache@pixelrebel.com>

My squid server has 1Gbps connectivity to the internet and it routinely gets 600 Mbps up/down to speedtest.net.

When a client computer on the same network has a direct connection to the internet it, too, gets 600 Mbps up/down.

However, when that client computer connects through the squid server, it can't seem to do any better than 120 Mbps down, 60 Mbps up. 

I've tried things like disabling disk cache, increasing maximum_object_size*, etc. Nothing I change in the config seems to increase or decrease my clients' bandwidth.

Any tips for getting better bandwidth to clients in a proxy-only setup?

Thanks,
Jamie



From squid3 at treenet.co.nz  Wed Jun 29 01:11:20 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 29 Jun 2016 13:11:20 +1200
Subject: [squid-users] Problems with ACL's using squid as intercept proxy
In-Reply-To: <20160628141843.GA14458@beagle.bcn.sia.es>
References: <20160628141843.GA14458@beagle.bcn.sia.es>
Message-ID: <3bc90495-7b2e-024b-57a0-acb0a12a95da@treenet.co.nz>

On 29/06/2016 2:18 a.m., C. L. Martinez wrote:
> I have configured new PF rules in this new FreeBSD host:
> 
> rdr pass on $vpnif proto tcp from $int_network to any port http tag intlans-to-inet -> lo0 port 5144
> 
>  .. And the result is:
> 
> 1467122773.928      0 127.0.0.1 TCP_MISS/403 4357 GET http://www.osnews.com/ - HIER_NONE/- text/html
> 1467122773.928     35 172.22.55.1 TCP_MISS/403 4489 GET http://www.osnews.com/ - ORIGINAL_DST/127.0.0.1 text/html
> 1467122774.068      0 172.22.55.1 TCP_MEM_HIT/200 13096 GET http://fbsdprx.my.domain.com:3128/squid-internal-static/icons/SN.png - HIER_NONE/- image/png
> 1467122774.102      0 127.0.0.1 TCP_MISS/403 4314 GET http://www.osnews.com/favicon.ico - HIER_NONE/- text/html
> 1467122774.103      2 172.22.55.1 TCP_MISS/403 4446 GET http://www.osnews.com/favicon.ico - ORIGINAL_DST/127.0.0.1 text/html
> 
>  .. What is the problem?? Are ACL's wrong?? Why?? At first stage, I was thinking about a problem with the pf rules ... but, now, I am not sure because packets arrives to squid ...
> 

The current releases of Squid need to be built with:
  ./configure --with-nat-devpf

for the old PF version on FreeBSD or NetBSD to work.
<http://www.squid-cache.org/Versions/v3/3.4/RELEASENOTES.html#ss2.4>

Amos



From squid3 at treenet.co.nz  Wed Jun 29 01:47:23 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 29 Jun 2016 13:47:23 +1200
Subject: [squid-users] Config changes between 2.7 and 3.5
In-Reply-To: <CAJN-FKnGJwYvzurgjB=ad+hO4qMXdTBzpdf-HQAaHuxsPHZSbA@mail.gmail.com>
References: <CAJN-FKnGJwYvzurgjB=ad+hO4qMXdTBzpdf-HQAaHuxsPHZSbA@mail.gmail.com>
Message-ID: <f24b2de7-394a-41b1-5428-5c54796edb1b@treenet.co.nz>

On 29/06/2016 9:19 a.m., Bidwell, Christopher wrote:
> Hi all,
> 
> I'm trying to find what's used to replace these:
> 
> squid 2.7                           squid 3.5
> --------------------------------------------------
> zero_buffers                      ???

An experiment in 2.7. It ceased to be an experiment a while back and the
directive to disable was dropped.


> refresh_stale_hit               ???

This Squid-2 feature has been superceeded by the HTTP/1.1
stale-while-revalidate mechanism at the protocol level. So a port to
Squid-3 is not planned.

But Squid-3 does not implement the stale-while-revalidate yet.

There is currently some work underway an Measurement Factory to make the
Squid-3 collapsed_forwarding feature operate properly with revalidation,
which will get halfway there.

If you need this directives behaviour and would like to assist with
development, testing, or sponsorship please drop a message in to
squid-dev mailing list.


> ignore_ims_on_miss         ???

The behaviour of this directive was a naive and simplistic duplicate of
the request_header_access directive with a very limited amount of
usefulness.

Consider removal, but if you need the behaviour still use
"request_header_access If-Modified-Since deny all" instead.

The request_header_access is also more powerful in that it is ACL driven
and can strip other If-* headers as well for other types of IMS/INM request.

Amos



From squid3 at treenet.co.nz  Wed Jun 29 02:10:57 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 29 Jun 2016 14:10:57 +1200
Subject: [squid-users] Subject: Bandwidth Ceiling
In-Reply-To: <57731eaa.+aPVUTpJuDI54/wc%squid-cache@pixelrebel.com>
References: <57731eaa.+aPVUTpJuDI54/wc%squid-cache@pixelrebel.com>
Message-ID: <c01a293b-595c-388d-ee8a-60c4dc68dabf@treenet.co.nz>

On 29/06/2016 1:04 p.m., squid-cache wrote:
> My squid server has 1Gbps connectivity to the internet and it
> routinely gets 600 Mbps up/down to speedtest.net.
> 
> When a client computer on the same network has a direct connection to
> the internet it, too, gets 600 Mbps up/down.
> 
> However, when that client computer connects through the squid server,
> it can't seem to do any better than 120 Mbps down, 60 Mbps up.
> 
> I've tried things like disabling disk cache, increasing
> maximum_object_size*, etc. Nothing I change in the config seems to
> increase or decrease my clients' bandwidth.
> 
> Any tips for getting better bandwidth to clients in a proxy-only
> setup?
> 

Sadly, that is kind of expected at present for any single client
connection. We have some evidence that Squid is artificially lowering
packet sizes in a few annoying ways. Used to make sense on slower
networks, but not nowdays.

Nathan Hoad has been putting a lot of work into this recently to figure
out what can be done and has a performance fix in Squid-4. That is not
going to make it into 3.5 because it relies on some major restructuring
done only in Squid-4 code.


But, if you are okay with playing around in the code his initial patch
submission shows the key value to change:
<http://lists.squid-cache.org/pipermail/squid-dev/2016-March/005518.html>
which should be the same in Squid-3. The 64KB bump in that patch leads
to some pain so dont just apply that. In the end we went with 16KB to
avoid huge per-connection memory requirements. It should really be tuned
to about 1/2 or 1/4 the TCP buffer size on your system.
After bumping up that read_ahead_gap directive also needs to be bumped
up to a minimum of whatever value you choose there.

HTH
Amos



From squid3 at treenet.co.nz  Wed Jun 29 02:33:03 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 29 Jun 2016 14:33:03 +1200
Subject: [squid-users] Squid 3.5.19 how to find banking server name for
 no bump
In-Reply-To: <CANLNtGQAMssG976sXt+5SK+ddDGBBYzPdcr5qDSSNWKRb5H76A@mail.gmail.com>
References: <CANLNtGQecOFjb9H+4MbOu7Fu8NFHNooLxKFLhh8sBEu=vNzQuA@mail.gmail.com>
 <84e35d81-1e53-83ed-b2b8-9f34f1497aad@treenet.co.nz>
 <CANLNtGQAMssG976sXt+5SK+ddDGBBYzPdcr5qDSSNWKRb5H76A@mail.gmail.com>
Message-ID: <8a859575-540f-2a6e-4309-b935afe851d0@treenet.co.nz>

On 29/06/2016 11:47 a.m., Stanford Prescott wrote:
> When I enter .wellsfargo.com in
> 
> *acl tls_s1_connect at_step SslBump1*
> *acl tls_s2_client_hello at_step SslBump2*
> *acl tls_s3_server_hello at_step SslBump3*
> 
> *acl tls_server_name_is_ip ssl::server_name_regex
> ^[0-9]+.[0-9]+.[0-9]+.[0-9]+n*
> *acl tls_allowed_hsts ssl::server_name .akamaihd.net <http://akamaihd.net>*
> *acl tls_server_is_bank ssl::server_name .wellsfargo.com
> <http://wellsfargo.com>*
> *acl tls_to_splice any-of tls_allowed_hsts tls_server_is_bank*
> 
> *ssl_bump peek tls_s1_connect all*
> *ssl_bump splice tls_s2_client_hello tls_to_splice*
> *ssl_bump stare tls_s2_client_hello all*
> *ssl_bump bump tls_s3_server_hello all*
> 
> 
> it appears that the banking site is still getting bumped i.e.like in this
> access.log snippet
> 

Most of the log entries have a) a raw-IP and no SNI, b) a non-wellsfargo
domain name [Google advertising].

All uses of CONNECT *.wellsfargo.com I have spotted in there also have a
"TCP_TUNNEL" tag - which means splice was done in accordance with your
above config.


For example; To follow one client:

Initial raw-TCP connection handling (TAG_NONE). No SNI available yet ...

> *1467156900.838   5423 10.40.40.100 TAG_NONE/200 0 CONNECT
> 159.45.170.145:443 <http://159.45.170.145:443> - HIER_NONE/- -*

... begin step-1 processing ...

[ Matches: ssl_bump peek tls_s1_connect all ]

[ Note that the wellsfargo ACL is not even reached at this stage. ]
[ If it did the string "159.45.170.145" != "*.wellsfargo.com" anyway ]

... which says to get the clientHello and SNI (if any) ...


> *1467156900.838   5088 10.40.40.100 TCP_TUNNEL/200 4631 CONNECT
> www.wellsfargo.com:443 <http://www.wellsfargo.com:443> -
> ORIGINAL_DST/159.45.170.145 <http://159.45.170.145> -*

... begin step 2 processing. SNI available ...

[ The string "www.wellsfargo.com" ~= "*.wellsfargo.com" ]
[ Matches: ssl_bump splice tls_s2_client_hello tls_to_splice ]

... connection spliced (TCP_TUNNEL).

> 
> If I disable sslbumping then the bank site does not get bumped, of course.
> 
> 1467157349.321    230 10.40.40.100 TCP_MISS/301 243 GET
> http://wellsfargo.com/ - ORIGINAL_DST/159.45.66.143 -
> 

That is http://, not HTTPS. ssl_bump has no relevance for plain-text
traffic.
The same thing would be done for that request regardless of what your
ssl_bump settings are.

Amos



From eliezer at ngtech.co.il  Wed Jun 29 07:57:10 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 29 Jun 2016 10:57:10 +0300
Subject: [squid-users] Squid 3.5.19 how to find banking server name
	for	no bump
In-Reply-To: <CANLNtGSLiJ3KJ8WGG+S_cF7Wn-6ofAEGt_7k_0QdncirxAxeqQ@mail.gmail.com>
References: <CANLNtGQecOFjb9H+4MbOu7Fu8NFHNooLxKFLhh8sBEu=vNzQuA@mail.gmail.com>
 <84e35d81-1e53-83ed-b2b8-9f34f1497aad@treenet.co.nz>
 <CANLNtGQAMssG976sXt+5SK+ddDGBBYzPdcr5qDSSNWKRb5H76A@mail.gmail.com>
 <CANLNtGSLiJ3KJ8WGG+S_cF7Wn-6ofAEGt_7k_0QdncirxAxeqQ@mail.gmail.com>
Message-ID: <01cf01d1d1db$d7102ea0$85308be0$@ngtech.co.il>

Hey,

 

I have seen that you are using squid in intercept mode either on Linux or some BSD.

If there is a site\server that you don't want to enter squid at all you will need to bypass it in the FW\IPTABLES level.

In linux you would be able to use some ipset list that will be bypassed from being intercepted.

If you are interested reply and I will try to give you an example how to use it.

 

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Stanford Prescott
Sent: Wednesday, June 29, 2016 2:56 AM
To: Amos Jeffries
Cc: squid-users
Subject: Re: [squid-users] Squid 3.5.19 how to find banking server name for no bump

 

I forgot to mention, I am using squid 3.5.19

 

On Tue, Jun 28, 2016 at 6:47 PM, Stanford Prescott <stan.prescott at gmail.com <mailto:stan.prescott at gmail.com> > wrote:

When I enter .wellsfargo.com <http://wellsfargo.com>  in

 

acl tls_s1_connect at_step SslBump1

acl tls_s2_client_hello at_step SslBump2

acl tls_s3_server_hello at_step SslBump3

 

acl tls_server_name_is_ip ssl::server_name_regex ^[0-9]+.[0-9]+.[0-9]+.[0-9]+n

acl tls_allowed_hsts ssl::server_name .akamaihd.net <http://akamaihd.net> 

acl tls_server_is_bank ssl::server_name .wellsfargo.com <http://wellsfargo.com> 

acl tls_to_splice any-of tls_allowed_hsts tls_server_is_bank

 

ssl_bump peek tls_s1_connect all

ssl_bump splice tls_s2_client_hello tls_to_splice

ssl_bump stare tls_s2_client_hello all

ssl_bump bump tls_s3_server_hello all

 

it appears that the banking site is still getting bumped i.e.like in this access.log snippet

 

1467156887.817    257 10.40.40.100 TAG_NONE/200 0 CONNECT 54.149.224.177:443 <http://54.149.224.177:443>  - ORIGINAL_DST/54.149.224.177 <http://54.149.224.177>  -

1467156888.008     94 10.40.40.100 TCP_MISS/200 213 POST https://tiles.services.mozilla.com/v2/links/view - ORIGINAL_DST/54.149.224.177 <http://54.149.224.177>  application/json

1467156893.774     75 10.40.40.100 TAG_NONE/200 0 CONNECT 172.230.102.185:443 <http://172.230.102.185:443>  - ORIGINAL_DST/172.230.102.185 <http://172.230.102.185>  -

1467156893.847    117 10.40.40.100 TAG_NONE/200 0 CONNECT 172.230.102.185:443 <http://172.230.102.185:443>  - ORIGINAL_DST/172.230.102.185 <http://172.230.102.185>  -

1467156893.875    120 10.40.40.100 TAG_NONE/200 0 CONNECT 172.230.221.75:443 <http://172.230.221.75:443>  - ORIGINAL_DST/172.230.221.75 <http://172.230.221.75>  -

1467156893.875    111 10.40.40.100 TAG_NONE/200 0 CONNECT 172.230.102.185:443 <http://172.230.102.185:443>  - ORIGINAL_DST/172.230.102.185 <http://172.230.102.185>  -

1467156893.875    117 10.40.40.100 TAG_NONE/200 0 CONNECT 172.230.221.75:443 <http://172.230.221.75:443>  - ORIGINAL_DST/172.230.221.75 <http://172.230.221.75>  -

1467156893.875    117 10.40.40.100 TAG_NONE/200 0 CONNECT 172.230.221.75:443 <http://172.230.221.75:443>  - ORIGINAL_DST/172.230.221.75 <http://172.230.221.75>  -

1467156893.875    112 10.40.40.100 TAG_NONE/200 0 CONNECT 172.230.102.185:443 <http://172.230.102.185:443>  - ORIGINAL_DST/172.230.102.185 <http://172.230.102.185>  -

1467156893.875    111 10.40.40.100 TAG_NONE/200 0 CONNECT 172.230.102.185:443 <http://172.230.102.185:443>  - ORIGINAL_DST/172.230.102.185 <http://172.230.102.185>  -

1467156894.109    307 10.40.40.100 TAG_NONE/200 0 CONNECT 172.230.102.185:443 <http://172.230.102.185:443>  - ORIGINAL_DST/172.230.102.185 <http://172.230.102.185>  -

1467156894.109    306 10.40.40.100 TAG_NONE/200 0 CONNECT 172.230.102.185:443 <http://172.230.102.185:443>  - ORIGINAL_DST/172.230.102.185 <http://172.230.102.185>  -

1467156894.109    307 10.40.40.100 TAG_NONE/200 0 CONNECT 172.230.102.185:443 <http://172.230.102.185:443>  - ORIGINAL_DST/172.230.102.185 <http://172.230.102.185>  -

1467156894.109    308 10.40.40.100 TAG_NONE/200 0 CONNECT 172.230.102.185:443 <http://172.230.102.185:443>  - ORIGINAL_DST/172.230.102.185 <http://172.230.102.185>  -

1467156895.488     72 10.40.40.100 TAG_NONE/200 0 CONNECT 216.58.194.98:443 <http://216.58.194.98:443>  - ORIGINAL_DST/216.58.194.98 <http://216.58.194.98>  -

1467156895.513     98 10.40.40.100 TAG_NONE/200 0 CONNECT 216.58.194.70:443 <http://216.58.194.70:443>  - ORIGINAL_DST/216.58.194.70 <http://216.58.194.70>  -

1467156895.648     66 10.40.40.100 TCP_MISS/302 739 GET https://googleads.g.doubleclick.net/pagead/viewthroughconversion/974108101/?value=0 <https://googleads.g.doubleclick.net/pagead/viewthroughconversion/974108101/?value=0&guid=ON&script=0&data.prod=&data.subprod=&data.pageid=> &guid=ON&script=0&data.prod=&data.subprod=&data.pageid= - ORIGINAL_DST/216.58.194.98 <http://216.58.194.98>  image/gif

1467156895.664     82 10.40.40.100 TCP_MISS/200 649 GET https://ad.doubleclick.net/activity;src=2549153;type=allv40;cat=all_a00;u1=11201507281102291611922021;ord=6472043235332.808? - ORIGINAL_DST/216.58.194.70 <http://216.58.194.70>  image/gif

1467156895.920    250 10.40.40.100 TAG_NONE/200 0 CONNECT 24.155.92.60:443 <http://24.155.92.60:443>  - ORIGINAL_DST/24.155.92.60 <http://24.155.92.60>  -

1467156896.061     79 10.40.40.100 TCP_MISS/200 503 GET https://www.google.com/ads/user-lists/974108101/?script=0 <https://www.google.com/ads/user-lists/974108101/?script=0&random=2433874630> &random=2433874630 - ORIGINAL_DST/24.155.92.60 <http://24.155.92.60>  image/gif

1467156899.837   5727 10.40.40.100 TAG_NONE/200 0 CONNECT 159.45.66.156:443 <http://159.45.66.156:443>  - HIER_NONE/- -

1467156899.837   5587 10.40.40.100 TCP_TUNNEL/200 165 CONNECT connect.secure.wellsfargo.com:443 <http://connect.secure.wellsfargo.com:443>  - ORIGINAL_DST/159.45.66.156 <http://159.45.66.156>  -

1467156899.837   5679 10.40.40.100 TAG_NONE/200 0 CONNECT 159.45.66.156:443 <http://159.45.66.156:443>  - HIER_NONE/- -

1467156899.837   5587 10.40.40.100 TCP_TUNNEL/200 165 CONNECT connect.secure.wellsfargo.com:443 <http://connect.secure.wellsfargo.com:443>  - ORIGINAL_DST/159.45.66.156 <http://159.45.66.156>  -

1467156899.838   5680 10.40.40.100 TAG_NONE/200 0 CONNECT 159.45.66.156:443 <http://159.45.66.156:443>  - HIER_NONE/- -

1467156899.838   5588 10.40.40.100 TCP_TUNNEL/200 165 CONNECT connect.secure.wellsfargo.com:443 <http://connect.secure.wellsfargo.com:443>  - ORIGINAL_DST/159.45.66.156 <http://159.45.66.156>  -

1467156900.836   5421 10.40.40.100 TAG_NONE/200 0 CONNECT 159.45.170.145:443 <http://159.45.170.145:443>  - HIER_NONE/- -

1467156900.836   5042 10.40.40.100 TCP_TUNNEL/200 4631 CONNECT www.wellsfargo.com:443 <http://www.wellsfargo.com:443>  - ORIGINAL_DST/159.45.170.145 <http://159.45.170.145>  -

1467156900.837   5423 10.40.40.100 TAG_NONE/200 0 CONNECT 159.45.2.142:443 <http://159.45.2.142:443>  - HIER_NONE/- -

1467156900.837   5139 10.40.40.100 TCP_TUNNEL/200 4043 CONNECT static.wellsfargo.com:443 <http://static.wellsfargo.com:443>  - ORIGINAL_DST/159.45.2.142 <http://159.45.2.142>  -

1467156900.838   5423 10.40.40.100 TAG_NONE/200 0 CONNECT 159.45.170.145:443 <http://159.45.170.145:443>  - HIER_NONE/- -

1467156900.838   5088 10.40.40.100 TCP_TUNNEL/200 4631 CONNECT www.wellsfargo.com:443 <http://www.wellsfargo.com:443>  - ORIGINAL_DST/159.45.170.145 <http://159.45.170.145>  -

 

If I disable sslbumping then the bank site does not get bumped, of course.

 

1467157349.321    230 10.40.40.100 TCP_MISS/301 243 GET http://wellsfargo.com/ - ORIGINAL_DST/159.45.66.143 <http://159.45.66.143>  -

 

Here is my squid.conf with bumping enabled.

 

visible_hostname smoothwall

 

# Uncomment the following to send debug info to /var/log/squid/cache.log

#debug_options ALL,1 33,2 28,9

 

# ACCESS CONTROLS

# ----------------------------------------------------------------

acl localhostgreen src 10.40.40.1

acl localnetgreen src 10.40.40.0/24 <http://10.40.40.0/24> 

acl SWE_subnets          src "/var/smoothwall/mods/proxy/acls/src_subnets.acl"

 

acl SSL_ports port 445 443 441 563

acl Safe_ports port 80     # http

acl Safe_ports port 81     # smoothwall http

acl Safe_ports port 21     # ftp 

acl Safe_ports port 445 443 441 563 # https, snews

acl Safe_ports port 70     # gopher

acl Safe_ports port 210       # wais  

acl Safe_ports port 1025-65535 # unregistered ports

acl Safe_ports port 280       # http-mgmt

acl Safe_ports port 488       # gss-http 

acl Safe_ports port 591       # filemaker

acl Safe_ports port 777       # multiling http

 

acl CONNECT method CONNECT

 

# TAG: http_access

# ----------------------------------------------------------------

 

http_access allow SWE_subnets

 

 

http_access allow localhost

http_access deny !Safe_ports

http_access deny CONNECT !SSL_ports

 

http_access allow localnetgreen

http_access allow CONNECT localnetgreen

 

http_access allow localhostgreen

http_access allow CONNECT localhostgreen

 

# http_port and https_port

#----------------------------------------------------------------------------

 

# For forward-proxy port. Squid uses this port to serve error pages, ftp icons and communication with other proxies.

#----------------------------------------------------------------------------

http_port 3127

 

http_port 10.40.40.1:800 <http://10.40.40.1:800>  intercept

https_port 10.40.40.1:808 <http://10.40.40.1:808>  intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/var/smoothwall/mods/proxy/ssl_cert/squidCA.pem sslflags=VERIFY_CRL_ALL options=NO_SSLv2,NO_SSLv3,No_Compression dhparams=/var/smoothwall/mods/proxy/ssl_cert/dhparam.pem

 

 

http_port 127.0.0.1:800 <http://127.0.0.1:800>  intercept

 

sslproxy_session_cache_size 4 MB

 

ssl_bump none localhostgreen

 

sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression

sslproxy_cipher ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:!aNULL:!eNULL

 

acl tls_s1_connect at_step SslBump1

acl tls_s2_client_hello at_step SslBump2

acl tls_s3_server_hello at_step SslBump3

 

acl tls_allowed_hsts ssl::server_name .akamaihd.net <http://akamaihd.net> 

acl tls_server_is_bank ssl::server_name .wellsfargo.com <http://wellsfargo.com> 

acl tls_to_splice any-of tls_allowed_hsts tls_server_is_bank

 

ssl_bump peek tls_s1_connect all

ssl_bump splice tls_s2_client_hello tls_to_splice

ssl_bump stare tls_s2_client_hello all

ssl_bump bump tls_s3_server_hello all

 

sslproxy_cert_error deny all

sslproxy_flags DONT_VERIFY_PEER

sslcrtd_program /var/smoothwall/mods/proxy/libexec/ssl_crtd -s /var/smoothwall/mods/proxy/lib/ssl_db -M 4MB

sslcrtd_children 5

 

http_access deny all

 

cache_replacement_policy heap GDSF

memory_replacement_policy heap GDSF

 

# CACHE OPTIONS

# ----------------------------------------------------------------------------

cache_effective_user squid

cache_effective_group squid

 

cache_swap_high 100

cache_swap_low 80

 

cache_access_log stdio:/var/log/squid/access.log

cache_log /var/log/squid/cache.log

cache_mem 64 MB

 

cache_dir aufs /var/spool/squid/cache 1024 16 256

 

maximum_object_size 33 MB

 

minimum_object_size 0 KB

 

 

request_body_max_size 0 KB

 

# OTHER OPTIONS

# ----------------------------------------------------------------------------

#via off

forwarded_for off

 

pid_filename /var/run/squid.pid

 

shutdown_lifetime 10 seconds

#icp_port 3130

 

half_closed_clients off

 

umask 022

 

logfile_rotate 0

 

strip_query_terms off

 

 

 

 

 

On Tue, Jun 28, 2016 at 9:56 AM, Amos Jeffries <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz> > wrote:

On 29/06/2016 2:02 a.m., Stanford Prescott wrote:
> I have the proper peek and splice and bump configuration of acls setup in
> my squid.conf file for no-bump of some web sites. I need help how to enter
> the banking hosts and or server names in a way that the peek and splice
> configuration will determine it is a banking site that I don't want bumped.
>
> For example, if a user enters www.wellsfargo.com <http://www.wellsfargo.com>  for online banking my
> current config still bumps wellsfargo.com <http://wellsfargo.com> . What would I need to enter for
> wellsfargo.com <http://wellsfargo.com>  so that banking server will not be bumped?
>

Depends on what you mean by "enter".

Are you asking for the ACL value?
  .wellfargo.com <http://wellfargo.com> 

Are you asking for the ACL definition?
 acl banks ssl::server_name .wellsfargo.com <http://wellsfargo.com> 

Or are you asking for a whole SSL-Bump configuration example?
 <http://wiki.squid-cache.org/Features/SslPeekAndSplice> has a few.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160629/95e1c75d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11295 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160629/95e1c75d/attachment.png>

From bruce.rosenberg.au at gmail.com  Wed Jun 29 10:01:33 2016
From: bruce.rosenberg.au at gmail.com (Bruce Rosenberg)
Date: Wed, 29 Jun 2016 20:01:33 +1000
Subject: [squid-users] cafile and capath not working as expected with SSL
	bump
Message-ID: <CAHaxnUKy2W2Q=3cmou=uPgo8sQapaMTkPvsPjswHMoMcFS-a9Q@mail.gmail.com>

Hi,

I'm using squid 3.5.19 on RHEL6 and have configured SSL bump, which for the
most part is working great.
The issue I have is I need to install some additional CA certs that are not
provided by the ca-certificates-2015 RPM in the /etc/pki/tls/cert.pem file
(symlinked to /etc/pki/tls/certs/ca-bundle.crt).
I've tried adding both the cafile and capath options to the http_port entry
but neither seems to have any affect.
With the cafile option I can see squid open the file via an strace but when
I connect to the server it fails with a 503 as the SSL session to the
remote side is failing to verify.
With the capath option, strace shows that squid never attempts to open any
files in that directory.
Dynamic certificate generation between squid and the client is working fine
however.


cafile strace (strace -fp <squid_pid> -e trace=open):

[pid 27532] open("/var/lib/ssl_db/index.txt", O_RDWR) = 3
[pid 27532] open("/var/lib/ssl_db/index.txt", O_RDONLY) = 4
[pid 27532] open("/etc/localtime", O_RDONLY) = 4
[pid 27532]
open("/var/lib/ssl_db/certs/3EA5A8686DE52F6FBED1CD16F119603FF223563F.pem",
O_RDONLY) = 4
[pid 27532]
open("/var/lib/ssl_db/certs/3EA5A8686DE52F6FBED1CD16F119603FF223563F.pem",
O_RDONLY) = 4
[pid 27528] open("/etc/squid/ssl/cafile.pem", O_RDONLY) = 13
[pid 27528] open("/etc/pki/tls/cert.pem", O_RDONLY) = 13
[pid 27532] open("/var/lib/ssl_db/index.txt", O_RDWR) = 3
[pid 27532] open("/var/lib/ssl_db/index.txt", O_RDONLY) = 4
[pid 27532]
open("/var/lib/ssl_db/certs/666F7FE36508EC9B6E154D4FA0AE36DAFE9AC520.pem",
O_RDONLY) = 4
[pid 27532]
open("/var/lib/ssl_db/certs/666F7FE36508EC9B6E154D4FA0AE36DAFE9AC520.pem",
O_RDONLY) = 4
[pid 27528] open("/etc/squid/ssl/cafile.pem", O_RDONLY) = 13
[pid 27528] open("/etc/pki/tls/cert.pem", O_RDONLY) = 13
[pid 27528] open("/etc/squid/ssl/cafile.pem", O_RDONLY) = 13
[pid 27528] open("/etc/pki/tls/cert.pem", O_RDONLY) = 13


Subsequent error in the access log:

[29/Jun/2016:18:46:30 +1000] 198.142.126.173 TAG_NONE:HIER_DIRECT/200
"CONNECT www.example.com:443 HTTP/1.1" - www.example.com 130 0 - 14
[29/Jun/2016:18:46:30 +1000] 198.142.126.173 TAG_NONE:HIER_NONE/503 "GET
https://www.example.com/postorders/postorders.php HTTP/1.1" - - 249 4699 - -


Relevant config:

sslproxy_options NO_SSLv2
sslproxy_cert_sign signTrusted
sslproxy_cert_sign_hash sha1
sslcrtd_children 8 startup=1 idle=1

acl step1 at_step SslBump1
ssl_bump peek step1 sslbump_src
ssl_bump bump sslbump_dst sslbump_src

ssl_bump none all

#http_port 3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=8MB capath=/etc/squid/ssl/cacerts/
key=/etc/squid/ssl_cert/mitm_root_ca.key
 cert=/etc/squid/ssl_cert/mitm_root_ca.crt
http_port 3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=8MB cafile=/etc/squid/ssl/cafile.pem
key=/etc/squid/ssl_cert/mitm_root_ca.key
 cert=/etc/squid/ssl_cert/mitm_root_ca.crt


I can work around the issue by appending the additional CA certs to the
Redhat managed /etc/pki/tls/certs/ca-bundle.crt file but this is not ideal.

Are the cafile and capath options supposed to work like this i.e. do they
allow you to complement the OS supplied CA certs for remote site
verification or have I completely misread the documentation?

cafile= File containing additional CA certificates to
use when verifying client certificates. If unset
clientca will be used.

capath= Directory containing additional CA certificates
and CRL lists to use when verifying client certificates.

Many thanks and any help greatly appreciated,
Bruce
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160629/a7ed0b27/attachment.htm>

From carlopmart at gmail.com  Wed Jun 29 10:19:25 2016
From: carlopmart at gmail.com (C. L. Martinez)
Date: Wed, 29 Jun 2016 10:19:25 +0000
Subject: [squid-users] Problems with ACL's using squid as intercept proxy
In-Reply-To: <3bc90495-7b2e-024b-57a0-acb0a12a95da@treenet.co.nz>
References: <20160628141843.GA14458@beagle.bcn.sia.es>
 <3bc90495-7b2e-024b-57a0-acb0a12a95da@treenet.co.nz>
Message-ID: <20160629101925.GA8727@beagle.bcn.sia.es>

On Wed 29.Jun'16 at 13:11:20 +1200, Amos Jeffries wrote:
> On 29/06/2016 2:18 a.m., C. L. Martinez wrote:
> > I have configured new PF rules in this new FreeBSD host:
> > 
> > rdr pass on $vpnif proto tcp from $int_network to any port http tag intlans-to-inet -> lo0 port 5144
> > 
> >  .. And the result is:
> > 
> > 1467122773.928      0 127.0.0.1 TCP_MISS/403 4357 GET http://www.osnews.com/ - HIER_NONE/- text/html
> > 1467122773.928     35 172.22.55.1 TCP_MISS/403 4489 GET http://www.osnews.com/ - ORIGINAL_DST/127.0.0.1 text/html
> > 1467122774.068      0 172.22.55.1 TCP_MEM_HIT/200 13096 GET http://fbsdprx.my.domain.com:3128/squid-internal-static/icons/SN.png - HIER_NONE/- image/png
> > 1467122774.102      0 127.0.0.1 TCP_MISS/403 4314 GET http://www.osnews.com/favicon.ico - HIER_NONE/- text/html
> > 1467122774.103      2 172.22.55.1 TCP_MISS/403 4446 GET http://www.osnews.com/favicon.ico - ORIGINAL_DST/127.0.0.1 text/html
> > 
> >  .. What is the problem?? Are ACL's wrong?? Why?? At first stage, I was thinking about a problem with the pf rules ... but, now, I am not sure because packets arrives to squid ...
> > 
> 
> The current releases of Squid need to be built with:
>   ./configure --with-nat-devpf
> 
> for the old PF version on FreeBSD or NetBSD to work.
> <http://www.squid-cache.org/Versions/v3/3.4/RELEASENOTES.html#ss2.4>
> 
> Amos
> 
Thanks Amos, but squid is compiled with --with-nat-devpf option:

Squid Cache: Version 3.5.19
Service Name: squid
configure options:  '--with-default-user=squid' '--bindir=/usr/local/sbin' '--sbindir=/usr/local/sbin' '--datadir=/usr/local/etc/squid' '--libexecdir=/usr/local/libexec/squid' '--localstatedir=/var' '--sysconfdir=/usr/local/etc/squid' '--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid/squid.pid' '--with-swapdir=/var/squid/cache' '--without-gnutls' '--enable-auth' '--enable-build-info' '--enable-loadable-modules' '--enable-removal-policies=lru heap' '--disable-epoll' '--disable-linux-netfilter' '--disable-linux-tproxy' '--disable-translation' '--disable-arch-native' '--enable-eui' '--enable-cache-digests' '--enable-delay-pools' '--disable-ecap' '--disable-esi' '--enable-follow-x-forwarded-for' '--enable-htcp' '--enable-icap-client' '--enable-icmp' '--enable-ident-lookups' '--enable-ipv6' '--enable-kqueue' '--with-large-files' '--enable-http-violations' '--without-nettle' '--enable-snmp' '--enable-ssl' '--with-openssl=/usr' 'LIBOPENSSL_CFLAGS=-I/usr/include' 'LIBOPENSSL_LIBS=-lcrypto -lssl' '--enable-ssl-crtd' '--disable-stacktraces' '--enable-ipf-transparent' '--enable-ipfw-transparent' '--enable-pf-transparent' '--with-nat-devpf' '--enable-forw-via-db' '--enable-wccp' '--enable-wccpv2' '--with-heimdal-krb5=/usr' 'CFLAGS=-I/usr/include -O2 -pipe  -fstack-protector -fno-strict-aliasing' 'LDFLAGS=-L/usr/lib  -pthread  -fstack-protector' 'LIBS=-lkrb5 -lgssapi -lgssapi_krb5 ' 'KRB5CONFIG=/usr/bin/krb5-config' '--enable-auth-basic=DB SMB_LM MSNT-multi-domain NCSA PAM POP3 RADIUS fake getpwnam NIS' '--enable-auth-digest=file' '--enable-external-acl-helpers=file_userip time_quota unix_group' '--enable-auth-negotiate=kerberos wrapper' '--enable-auth-ntlm=fake smb_lm' '--enable-storeio=aufs diskd rock ufs' '--enable-disk-io=DiskThreads DiskDaemon AIO Blocking IpcIo Mmapped' '--enable-log-daemon-helpers=file' '--enable-url-rewrite-helpers=fake' '--enable-storeid-rewrite-helpers=file' '--prefix=/usr/local' '--mandir=/usr/local/man' '--infodir=/usr/local/info/' '--build=amd64-portbld-freebsd10.1' 'build_alias=amd64-portbld-freebsd10.1' 'CC=cc' 'CPPFLAGS=' 'CXX=c++' 'CXXFLAGS=-O2 -pipe -fstack-protector -fno-strict-aliasing ' 'CPP=cpp' --enable-ltdl-convenience


-- 
Greetings,
C. L. Martinez


From squid3 at treenet.co.nz  Wed Jun 29 14:17:35 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 30 Jun 2016 02:17:35 +1200
Subject: [squid-users] cafile and capath not working as expected with
 SSL bump
In-Reply-To: <CAHaxnUKy2W2Q=3cmou=uPgo8sQapaMTkPvsPjswHMoMcFS-a9Q@mail.gmail.com>
References: <CAHaxnUKy2W2Q=3cmou=uPgo8sQapaMTkPvsPjswHMoMcFS-a9Q@mail.gmail.com>
Message-ID: <75746789-774a-0d96-5606-2282d0e9bb29@treenet.co.nz>

On 29/06/2016 10:01 p.m., Bruce Rosenberg wrote:
> Hi,
> 
> I'm using squid 3.5.19 on RHEL6 and have configured SSL bump, which for the
> most part is working great.
> The issue I have is I need to install some additional CA certs that are not
> provided by the ca-certificates-2015 RPM in the /etc/pki/tls/cert.pem file
> (symlinked to /etc/pki/tls/certs/ca-bundle.crt).
> I've tried adding both the cafile and capath options to the http_port entry
> but neither seems to have any affect.
> With the cafile option I can see squid open the file via an strace but when
> I connect to the server it fails with a 503 as the SSL session to the
> remote side is failing to verify.
> With the capath option, strace shows that squid never attempts to open any
> files in that directory.
> Dynamic certificate generation between squid and the client is working fine
> however.
> 
...
> 
> Are the cafile and capath options supposed to work like this i.e. do they
> allow you to complement the OS supplied CA certs for remote site
> verification or have I completely misread the documentation?

The options *on http_port* are supposed to act like that, yes.

I think you have just mistaken the distinction between the three types
of connection Squid has to juggle.


http(s)_port is for links between client and Squid. Those parameters
used for verifying *client certificates*.

sslproxy_* set of directives are for direct Squid->server links. The
sslproxy_cafile and/or sslproxy_capath load the extra special CA you
want to add to the system default ones.

cache_peer is for static links to a known server/peer. It has its own
cafile= and capath= options for CA to verify that specific server.
Ideally the system CAs would not be used here.


If I'm understanding your needs correctly then you want to be
configuring sslproxy_cafile and/or sslproxy_capath.


Amos


From renjop at gmail.com  Wed Jun 29 14:21:25 2016
From: renjop at gmail.com (Renato Jop)
Date: Wed, 29 Jun 2016 08:21:25 -0600
Subject: [squid-users] Skype Issues
In-Reply-To: <CAHha_zX+oDsFT7b6qfirB17v0C-iDMq7p1XdLG4z=++6V5_JeA@mail.gmail.com>
References: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>
 <8ff3bffe-47b7-8b0d-148d-cd3254344fd1@treenet.co.nz>
 <a30b3e16-5209-8240-359a-0cf736fe129f@gmail.com>
 <6e208cda-cb22-e48d-c0ee-0a6db04448e0@treenet.co.nz>
 <5153128f-ddd0-c134-22f1-158aa97575b4@gmail.com>
 <CAHha_zUDd__ZyMUCDQDcJ4KQouk++2OoZiEMptHY=Ty08D549A@mail.gmail.com>
 <b3abc44d-7abf-aa9a-ebd3-a775c4a81854@gmail.com>
 <CAHha_zUDWQEFJjWgupS55gibNxSZ=gy--CfvQesYoPv6akciDQ@mail.gmail.com>
 <0b950720-77ad-170d-55d3-295f028dfa92@gmail.com>
 <CAHha_zX+oDsFT7b6qfirB17v0C-iDMq7p1XdLG4z=++6V5_JeA@mail.gmail.com>
Message-ID: <CAHha_zUZvUf2sBUXuoHdXi=s1CdnRR8YsOTWct1UPTrh4+N3Rw@mail.gmail.com>

I've installed LibreSSL 2.2.9 and the issue still persists.
I think I am going to have install squid4 even if it's still in beta to
solve this issues.
Thanks for your help.


Renato Jop

On Mon, Jun 27, 2016 at 9:36 AM, Renato Jop <renjop at gmail.com> wrote:

> Is there a way to verify that the SSL library doesn't support SSLv3?
>
> Renato Jop
>
> On Mon, Jun 27, 2016 at 8:43 AM, Yuri <yvoinov at gmail.com> wrote:
>
>> Looks like your SSL library does not contain SSLv3 protocol support
>> already, but site announce it.
>>
>> 27.06.2016 20:42, Renato Jop ?????:
>>
>> I removed the NO_SSLv2, NO_SSLv3 however, right before the SSL3_GET_
>> RECORD:wrong version number the SSL
>> routines:SSL23_GET_SERVER_HELLO:unknown protocol is shown.
>>
>> Renato Jop
>>
>> On Mon, Jun 27, 2016 at 8:29 AM, Yuri <yvoinov at gmail.com> wrote:
>>
>>> Try to remove NO_SSLv2,NO_SSLv3 from options. SSLv2 already not
>>> supported everywhere, RC4/3DES is SSLv3 ciphers, so it can be confuse
>>> software. I.e., you use custom ciphers/protocols combinations, which can
>>> lead issue.
>>>
>>> 27.06.2016 20:25, Renato Jop ?????:
>>>
>>> Thank you both for your valuable help.
>>> I've configured the tls-dh param with a strong Diffie-Hellman group
>>> (2048 bits) and configured the cipher as Yuri specified and I was able to
>>> get pass the unknown cipher, however now I get a "SSL routines:SSL3_GET_
>>> RECORD:wrong version number". Here's the configuration I changed:
>>>  cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>>> dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>>> tls-dh=/usr/local/etc/squid/dhparams.pem
>>>
>>>
>>>
>>> Renato Jop
>>>
>>> On Sat, Jun 25, 2016 at 11:34 AM, Yuri Voinov < <yvoinov at gmail.com>
>>> yvoinov at gmail.com> wrote:
>>>
>>>>
>>>> -----BEGIN PGP SIGNED MESSAGE-----
>>>> Hash: SHA256
>>>>
>>>>
>>>>
>>>> 25.06.2016 23:09, Amos Jeffries ?????:
>>>> > On 26/06/2016 4:32 a.m., Yuri Voinov wrote:
>>>> >>
>>>> >> Amos, you are a wrong.
>>>> >>
>>>> >> No Squid-4. It's unstable and not ready for production. Whenever it's
>>>> >> features.
>>>> >
>>>> > So some beta software has bugs therefore nobody should ever use it for
>>>> > anything. I find that to be a strange and sad view of the world.
>>>> >
>>>> > Care to guess why I listed it as the last option amongst several?
>>>> >  Or why 4.0.11 exists as a beta still?
>>>> > It *is* an option for the mentioned problem(s) though whatever its
>>>> utility.
>>>> Agreed.
>>>> >
>>>> >
>>>> >
>>>> >>
>>>> >> Some time ago I have the same issue and know what happens exactly.
>>>> >>
>>>> >> Skype initial connection site uses RC4 cipher. Which is disabled in
>>>> most
>>>> >> squid's configuration.
>>>> >
>>>> > Your "know what happens exactly" differs from at least two other
>>>> peoples
>>>> > debugging experiences with Skype.
>>>> >
>>>> > RC4 is on the hitlist for most of the big vendors for the past year or
>>>> > so. IIRC there were several Windows Updates to remove it and other
>>>> > broken bits from a lot of things over the past year.
>>>> > If Skype is still using RC4 it might be part of this problem.
>>>> I'm sure this is problem and this problem exists. MS do nothing to make
>>>> they sites/services more secure. BTW, MS Updates uses RC4 ciphers itself
>>>> this time. With strong siphers there is no way to setup WU via Squid.
>>>> I've spent much time to identify this problem in my setup and find
>>>> working workaround.
>>>>
>>>> Another part of problem is: MS often uses it's own self-signed roots,
>>>> which is exists in Windows, but nowhere else. And which has not
>>>> cross-signed by well-known root CA's. They think it make MS services
>>>> more secure. They wrong. But we can't do anything with it. So, this is
>>>> forced us to add self-signed MS roots to our Squid's CA bundles to
>>>> bump/splice.
>>>> >
>>>> >
>>>> >>
>>>> >> To make it works (as by as most M$ update sites) it's require simple
>>>> use
>>>> >> this cipher's suite:
>>>> >>
>>>> >> HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>>>> >>
>>>> >> That works for me in 5 SSL bumped setups. There is no matter which
>>>> squid
>>>> >> version installed.
>>>> >
>>>> > Thank you. Thats another option then. I'd rate that below trying the
>>>> EC
>>>> > ciphers, and above library updates.
>>>> You are welcome.
>>>>
>>>> Just for information: MS has own IT infrastructure, with some strange
>>>> configured and non well-managed elements. I can't guarantee this
>>>> workaround will work everywhere or for every MS service.
>>>>
>>>> When I made my research, I've seen some strange security TLS
>>>> combinations on MS sites/services. I.e., for example, RC4+ECDSA+TLSv1.2.
>>>> Or, for example, RC4+MD5+TLSv1. And some similar. Very idiotic and
>>>> potentially dangerous combinations. And - they support ignores all
>>>> requests. As usual.
>>>>
>>>> To my regret, I can not order all of its users to abandon the use of
>>>> Windows. So far, in my infrastructure have machines with Windows XP.
>>>>
>>>> With this nothing can be done, it is necessary only to weaken the
>>>> security - for the sake of compatibility.
>>>> >
>>>> >
>>>> > Amos
>>>> > _______________________________________________
>>>> > squid-users mailing list
>>>> > squid-users at lists.squid-cache.org
>>>> > http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>> -----BEGIN PGP SIGNATURE-----
>>>> Version: GnuPG v2
>>>>
>>>> iQEcBAEBCAAGBQJXbsC5AAoJENNXIZxhPexGiFoH/jrtimBNppF1uHpVTNwOO10z
>>>> yF2APMA56S8woNZzhUNjT8+oJFPrthnMoQFrqgicjS77SBAFp9KcOV+SxOKl9+sW
>>>> OdAHDPuCD7dGnKzAdFDR1YR7Vp5IpElP1rFO5rqKXeBc3iKjq65BfF+T6atHy6cS
>>>> 0VAaluvqvHQps2wVKoYxGURDf3Y2K0lJn+qF+s2CaBwEufhzgKSvG0aUIDqTfHfK
>>>> 3EMQTpPtlTqm+pcexR+oZM1WE1hlES1khOXs51fgo6puPryqWJiHGvO4EBEfWoXF
>>>> Skval2COzcdzMvC5jjfGbMEPNGNJrYUeq/KNgppRvE2wQJ+gCLYG317decKHty0=
>>>> =8BTp
>>>> -----END PGP SIGNATURE-----
>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>>
>>>
>>>
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160629/9caf74b7/attachment.htm>

From emz at norma.perm.ru  Wed Jun 29 14:24:59 2016
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Wed, 29 Jun 2016 19:24:59 +0500
Subject: [squid-users] large downloads got interrupted
In-Reply-To: <16f57ceb-f22e-25e8-ee5c-dfc3e9eeb7fa@treenet.co.nz>
References: <57723949.1060504@norma.perm.ru>
 <16f57ceb-f22e-25e8-ee5c-dfc3e9eeb7fa@treenet.co.nz>
Message-ID: <5773DA3B.60409@norma.perm.ru>

Hi.

On 29.06.16 05:26, Amos Jeffries wrote:
> On 28/06/2016 8:46 p.m., Eugene M. Zheganin wrote:
>> Hi,
>>
>> recently I started to get the problem when large downloads via squid are
>> often interrupted. I tried to investigate it, but, to be honest, got
>> nowhere. However, I took two tcpdump captures, and it seems to me that
>> for some reason squid sends FIN to it's client and correctly closes the
>> connection (wget reports that connection is closed), and in the same
>> time for some reason it sends like tonns of RSTs towards the server. No
>> errors in logs are reported (at least on a  ALL,1 loglevel).
>>
> It sounds like a timeout or such has happened inside Squid. We'd need to
> see your squid.conf to see if that was it.
Well... it quite long, since it's at large production site. I guess you
don't need the acl and auth lines, so without them it's as follows
(nothing secret in them, just that they are really numerous):

===Cut===
# cat /usr/local/etc/squid/squid.conf | grep -v http_access | grep -v
acl | grep -v http_reply_access | egrep -v '^#' | egrep -v '^$'
visible_hostname proxy1.domain1.com
debug_options ALL,1
http_port [fd00::301]:3128 ssl-bump
cert=/usr/local/etc/squid/certs/squid.cert.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
dhparams=/usr/local/etc/squid/certs/dhparam.pem
http_port [fd00::316]:3128 ssl-bump
cert=/usr/local/etc/squid/certs/squid.cert.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
dhparams=/usr/local/etc/squid/certs/dhparam.pem
http_port 192.168.3.1:3128 ssl-bump
cert=/usr/local/etc/squid/certs/squid.cert.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
dhparams=/usr/local/etc/squid/certs/dhparam.pem
http_port 127.0.0.1:3128 ssl-bump
cert=/usr/local/etc/squid/certs/squid.cert.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
dhparams=/usr/local/etc/squid/certs/dhparam.pem
http_port 127.0.0.1:3129 intercept
http_port [::1]:3128
http_port [::1]:3129 intercept
https_port 127.0.0.1:3131 intercept ssl-bump
cert=/usr/local/etc/squid/certs/squid.cert.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
dhparams=/usr/local/etc/squid/certs/dhparam.pem
https_port [::1]:3131 intercept ssl-bump
cert=/usr/local/etc/squid/certs/squid.cert.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
dhparams=/usr/local/etc/squid/certs/dhparam.pem
icp_port 3130
dns_v4_first off
shutdown_lifetime 5 seconds
workers 2
no_cache deny QUERY
cache_mem 256 MB
cache_dir rock /var/squid/cache 1100
cache_access_log stdio:/var/log/squid/access.fifo
cache_log /var/log/squid/cache.log
cache_store_log none
cache_peer localhost parent 8118 0 no-query defaultauth_param negotiate
program /usr/local/libexec/squid/negotiate_wrapper_auth --ntlm
/usr/local/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --kerberos
/usr/local
authenticate_ip_ttl 60 seconds
positive_dns_ttl 20 minutes
negative_dns_ttl 120 seconds
negative_ttl 30 seconds
pid_filename /var/run/squid/squid.pid
ftp_user anonymous
ftp_passive on
ipcache_size 16384
fqdncache_size 16384
redirect_children 10
refresh_pattern -i . 0 20% 4320
sslcrtd_program /usr/local/libexec/squid/ssl_crtd -s /var/squid/ssl -M 4MB
sslcrtd_children 15
auth_param negotiate program
/usr/local/libexec/squid/negotiate_wrapper_auth --ntlm
/usr/local/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --kerberos
/usr/local/libexec/squid/negotiate_kerberos_auth -s
HTTP/proxy1.domain1.com at DOMAIN.COM
auth_param negotiate children 40 startup=5 idle=5
auth_param negotiate keep_alive on
auth_param ntlm program /usr/local/bin/ntlm_auth -d 0
--helper-protocol=squid-2.5-ntlmssp
auth_param ntlm children 60
auth_param basic program /usr/local/libexec/squid/basic_pam_auth
auth_param basic children 35 startup=5 idle=2
auth_param basic realm Squid
auth_param basic credentialsttl 10 minute
auth_param basic casesensitive off
authenticate_ttl 10 minute
authenticate_cache_garbage_interval 10 minute
snmp_access allow fromintranet
snmp_access allow localhost
snmp_access deny all
snmp_port 340${process_number}
snmp_incoming_address 192.168.3.22
tcp_outgoing_address 192.168.3.22 intranet
tcp_outgoing_address fd00::316 intranet6
tcp_outgoing_address 86.109.196.3 ad-megafon
redirector_access deny localhost
redirector_access deny SSL_ports
icp_access allow children
icp_access deny all
always_direct deny fuck-the-system-dstdomain
always_direct deny fuck-the-system
always_direct deny onion
always_direct allow all
never_direct allow fuck-the-system-dstdomain
never_direct allow fuck-the-system
never_direct allow onion
never_direct deny all
miss_access allow manager
miss_access allow all
cache_mgr emz at domain1.com
cache_effective_user squid
cache_effective_group squid
sslproxy_cafile /usr/local/etc/squid/certs/ca.pem
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER
deny_info ERR_NO_BANNER banner
deny_info ERR_UNAUTHORIZED unauthorized
deny_info ERR_OVERQUOTA overquotasall
deny_info ERR_ENTERTAINMENT entertainment
deny_info ERR_ENTERTAINMENT entertainmentssl
deny_info ERR_ACCESS_DENIED_TS ts
deny_info ERR_ACCESS_DENIED all
ssl_bump splice step1 lastfm-dst
ssl_bump splice step1 kasperskyssl
ssl_bump splice step1 wart
ssl_bump splice step1 telegram-dst
ssl_bump splice step1 icq
ssl_bump splice step1 icqip icqport
ssl_bump splice children
ssl_bump splice sbol
ssl_bump bump interceptedssl
ssl_bump peek step1
ssl_bump bump unauthorized
ssl_bump terminate unauthorized
ssl_bump bump entertainmentssl
ssl_bump bump googlevideo
ssl_bump splice all
forwarded_for off
cachemgr_passwd sabbre all
error_directory /usr/local/etc/squid/errors/domain1
delay_pools 1
delay_class 1 1
delay_parameters 1 16000/16000
delay_access 1 deny all
===Cut===

The download I test this issue on is:
- a large iso file, 4G from Yandex mirror
- goes via plain http (so no sslBump)
- client is authenticated using basic authentication
- you can see a delay pools in squid.config, but this is just a
definition, no clients are assigned into it


When connection is closed the client receives FIN sequence, and squid
sends a loooot of RSTs towards target server I'm downloading the file from.

>
> What version are you using? there have been a few bugs found that can
> cause unrelated connections to be closed early like this.
I noticed this problem on squid 3.5.11, but it's reproducible on 3.5.19
as well.

> Screen dump of packet capture does not usually help. We usually only ask
> for packet captures when one of the dev needs to personally analyse the
> full traffic behaviour.
>
> A cache.log trace at debug level 11,2 shows all the HTTP messages going
> through in an easier format to read. There might be hints in there, but
> if it is a timeout like I suspect probably not.
Well... do you need it already ? I should say that it will be way huge.
May be there's a way to grep only the interesting parts ?

Thanks.
Eugene.


From renjop at gmail.com  Wed Jun 29 16:58:46 2016
From: renjop at gmail.com (Renato Jop)
Date: Wed, 29 Jun 2016 10:58:46 -0600
Subject: [squid-users] Skype Issues
In-Reply-To: <CAHha_zUZvUf2sBUXuoHdXi=s1CdnRR8YsOTWct1UPTrh4+N3Rw@mail.gmail.com>
References: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>
 <8ff3bffe-47b7-8b0d-148d-cd3254344fd1@treenet.co.nz>
 <a30b3e16-5209-8240-359a-0cf736fe129f@gmail.com>
 <6e208cda-cb22-e48d-c0ee-0a6db04448e0@treenet.co.nz>
 <5153128f-ddd0-c134-22f1-158aa97575b4@gmail.com>
 <CAHha_zUDd__ZyMUCDQDcJ4KQouk++2OoZiEMptHY=Ty08D549A@mail.gmail.com>
 <b3abc44d-7abf-aa9a-ebd3-a775c4a81854@gmail.com>
 <CAHha_zUDWQEFJjWgupS55gibNxSZ=gy--CfvQesYoPv6akciDQ@mail.gmail.com>
 <0b950720-77ad-170d-55d3-295f028dfa92@gmail.com>
 <CAHha_zX+oDsFT7b6qfirB17v0C-iDMq7p1XdLG4z=++6V5_JeA@mail.gmail.com>
 <CAHha_zUZvUf2sBUXuoHdXi=s1CdnRR8YsOTWct1UPTrh4+N3Rw@mail.gmail.com>
Message-ID: <CAHha_zV5R4CNe+q82=MBS+qKH=fe9UYC5Rm0zj_3CE+FC=zpww@mail.gmail.com>

I've installed squid4 and the problems still persists. I've added the
following acl:
# define what Squid errors indicate receiving non-HTTP traffic:
acl foreignProtocol squid_error ERR_PROTOCOL_UNKNOWN ERR_TOO_BIG
# define what Squid errors indicate receiving nothing:
acl serverTalksFirstProtocol squid_error ERR_REQUEST_START_TIMEOUT
# tunnel everything that does not look like HTTP:
on_unsupported_protocol tunnel foreignProtocol
# tunnel if we think the client waits for the server to talk first:
on_unsupported_protocol tunnel serverTalksFirstProtocol
# in all other error cases, just send an HTTP "error page" response:
on_unsupported_protocol respond all

Renato Jop

On Wed, Jun 29, 2016 at 8:21 AM, Renato Jop <renjop at gmail.com> wrote:

> I've installed LibreSSL 2.2.9 and the issue still persists.
> I think I am going to have install squid4 even if it's still in beta to
> solve this issues.
> Thanks for your help.
>
>
> Renato Jop
>
> On Mon, Jun 27, 2016 at 9:36 AM, Renato Jop <renjop at gmail.com> wrote:
>
>> Is there a way to verify that the SSL library doesn't support SSLv3?
>>
>> Renato Jop
>>
>> On Mon, Jun 27, 2016 at 8:43 AM, Yuri <yvoinov at gmail.com> wrote:
>>
>>> Looks like your SSL library does not contain SSLv3 protocol support
>>> already, but site announce it.
>>>
>>> 27.06.2016 20:42, Renato Jop ?????:
>>>
>>> I removed the NO_SSLv2, NO_SSLv3 however, right before the SSL3_GET_
>>> RECORD:wrong version number the SSL
>>> routines:SSL23_GET_SERVER_HELLO:unknown protocol is shown.
>>>
>>> Renato Jop
>>>
>>> On Mon, Jun 27, 2016 at 8:29 AM, Yuri <yvoinov at gmail.com> wrote:
>>>
>>>> Try to remove NO_SSLv2,NO_SSLv3 from options. SSLv2 already not
>>>> supported everywhere, RC4/3DES is SSLv3 ciphers, so it can be confuse
>>>> software. I.e., you use custom ciphers/protocols combinations, which can
>>>> lead issue.
>>>>
>>>> 27.06.2016 20:25, Renato Jop ?????:
>>>>
>>>> Thank you both for your valuable help.
>>>> I've configured the tls-dh param with a strong Diffie-Hellman group
>>>> (2048 bits) and configured the cipher as Yuri specified and I was able to
>>>> get pass the unknown cipher, however now I get a "SSL routines:SSL3_GET_
>>>> RECORD:wrong version number". Here's the configuration I changed:
>>>>  cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>>>> dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>>>> tls-dh=/usr/local/etc/squid/dhparams.pem
>>>>
>>>>
>>>>
>>>> Renato Jop
>>>>
>>>> On Sat, Jun 25, 2016 at 11:34 AM, Yuri Voinov < <yvoinov at gmail.com>
>>>> yvoinov at gmail.com> wrote:
>>>>
>>>>>
>>>>> -----BEGIN PGP SIGNED MESSAGE-----
>>>>> Hash: SHA256
>>>>>
>>>>>
>>>>>
>>>>> 25.06.2016 23:09, Amos Jeffries ?????:
>>>>> > On 26/06/2016 4:32 a.m., Yuri Voinov wrote:
>>>>> >>
>>>>> >> Amos, you are a wrong.
>>>>> >>
>>>>> >> No Squid-4. It's unstable and not ready for production. Whenever
>>>>> it's
>>>>> >> features.
>>>>> >
>>>>> > So some beta software has bugs therefore nobody should ever use it
>>>>> for
>>>>> > anything. I find that to be a strange and sad view of the world.
>>>>> >
>>>>> > Care to guess why I listed it as the last option amongst several?
>>>>> >  Or why 4.0.11 exists as a beta still?
>>>>> > It *is* an option for the mentioned problem(s) though whatever its
>>>>> utility.
>>>>> Agreed.
>>>>> >
>>>>> >
>>>>> >
>>>>> >>
>>>>> >> Some time ago I have the same issue and know what happens exactly.
>>>>> >>
>>>>> >> Skype initial connection site uses RC4 cipher. Which is disabled in
>>>>> most
>>>>> >> squid's configuration.
>>>>> >
>>>>> > Your "know what happens exactly" differs from at least two other
>>>>> peoples
>>>>> > debugging experiences with Skype.
>>>>> >
>>>>> > RC4 is on the hitlist for most of the big vendors for the past year
>>>>> or
>>>>> > so. IIRC there were several Windows Updates to remove it and other
>>>>> > broken bits from a lot of things over the past year.
>>>>> > If Skype is still using RC4 it might be part of this problem.
>>>>> I'm sure this is problem and this problem exists. MS do nothing to make
>>>>> they sites/services more secure. BTW, MS Updates uses RC4 ciphers
>>>>> itself
>>>>> this time. With strong siphers there is no way to setup WU via Squid.
>>>>> I've spent much time to identify this problem in my setup and find
>>>>> working workaround.
>>>>>
>>>>> Another part of problem is: MS often uses it's own self-signed roots,
>>>>> which is exists in Windows, but nowhere else. And which has not
>>>>> cross-signed by well-known root CA's. They think it make MS services
>>>>> more secure. They wrong. But we can't do anything with it. So, this is
>>>>> forced us to add self-signed MS roots to our Squid's CA bundles to
>>>>> bump/splice.
>>>>> >
>>>>> >
>>>>> >>
>>>>> >> To make it works (as by as most M$ update sites) it's require
>>>>> simple use
>>>>> >> this cipher's suite:
>>>>> >>
>>>>> >> HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
>>>>> >>
>>>>> >> That works for me in 5 SSL bumped setups. There is no matter which
>>>>> squid
>>>>> >> version installed.
>>>>> >
>>>>> > Thank you. Thats another option then. I'd rate that below trying the
>>>>> EC
>>>>> > ciphers, and above library updates.
>>>>> You are welcome.
>>>>>
>>>>> Just for information: MS has own IT infrastructure, with some strange
>>>>> configured and non well-managed elements. I can't guarantee this
>>>>> workaround will work everywhere or for every MS service.
>>>>>
>>>>> When I made my research, I've seen some strange security TLS
>>>>> combinations on MS sites/services. I.e., for example,
>>>>> RC4+ECDSA+TLSv1.2.
>>>>> Or, for example, RC4+MD5+TLSv1. And some similar. Very idiotic and
>>>>> potentially dangerous combinations. And - they support ignores all
>>>>> requests. As usual.
>>>>>
>>>>> To my regret, I can not order all of its users to abandon the use of
>>>>> Windows. So far, in my infrastructure have machines with Windows XP.
>>>>>
>>>>> With this nothing can be done, it is necessary only to weaken the
>>>>> security - for the sake of compatibility.
>>>>> >
>>>>> >
>>>>> > Amos
>>>>> > _______________________________________________
>>>>> > squid-users mailing list
>>>>> > squid-users at lists.squid-cache.org
>>>>> > http://lists.squid-cache.org/listinfo/squid-users
>>>>>
>>>>> -----BEGIN PGP SIGNATURE-----
>>>>> Version: GnuPG v2
>>>>>
>>>>> iQEcBAEBCAAGBQJXbsC5AAoJENNXIZxhPexGiFoH/jrtimBNppF1uHpVTNwOO10z
>>>>> yF2APMA56S8woNZzhUNjT8+oJFPrthnMoQFrqgicjS77SBAFp9KcOV+SxOKl9+sW
>>>>> OdAHDPuCD7dGnKzAdFDR1YR7Vp5IpElP1rFO5rqKXeBc3iKjq65BfF+T6atHy6cS
>>>>> 0VAaluvqvHQps2wVKoYxGURDf3Y2K0lJn+qF+s2CaBwEufhzgKSvG0aUIDqTfHfK
>>>>> 3EMQTpPtlTqm+pcexR+oZM1WE1hlES1khOXs51fgo6puPryqWJiHGvO4EBEfWoXF
>>>>> Skval2COzcdzMvC5jjfGbMEPNGNJrYUeq/KNgppRvE2wQJ+gCLYG317decKHty0=
>>>>> =8BTp
>>>>> -----END PGP SIGNATURE-----
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>
>>>>>
>>>>
>>>>
>>>
>>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160629/f89f1252/attachment.htm>

From zaza1851983ml at googlemail.com  Wed Jun 29 17:12:28 2016
From: zaza1851983ml at googlemail.com (Moataz Elmasry)
Date: Wed, 29 Jun 2016 19:12:28 +0200
Subject: [squid-users] url_rewrite_program is ignored by squid
Message-ID: <CAJ_yQBm+2tBYOEwVA+Vi_uFEHU+HJWMFL0GPZSViR6Y+=xMmWw@mail.gmail.com>

Hi all,

I'm trying to use squid with squidguard, but it seems that squid3 is
somehow ignoring the url_rewrite_program completely. While starting squid
I'm getting the message:

"
helperOpenServers: Starting 0/20 'squidGuard' processes
helperOpenServers: No 'squidGuard' processes needed
"

And nothing is being directed to squidguard.
Just to be sure, I tried a simple bash program as well as a php program to
handle the redirection, and I'm receiving a similar message and nothing is
being redirected.
Config files are listed below. All files are owned by the user "proxy"
OS: ubuntu 16.04
squid: 3.5.12-1ubuntu7.2
squidguard: 1.5-5

Here's  squid.conf

"
pinger_enable off
url_rewrite_access allow all
url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 443         # https
acl Safe_ports port 1025-65535  # unregistered ports
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localhost
acl whitelist dstdomain play.google.com
http_access allow whitelist
http_access deny all
http_port 3128
coredump_dir /var/spool/squid

"

And here's squidGuard.conf

"
dbhome /var/lib/squidguard/db
logdir /var/log/squidguard

dest ads {
        domainlist ads/domains
}

dest whitelist {
domainlist whitelist/domains
}

acl {
        default {
                pass whitelist none
                redirect http://www.contensi.com
        }
}

"

Any ideas what the problem is?

Thanks
Moataz
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160629/618fdc99/attachment.htm>

From yvoinov at gmail.com  Wed Jun 29 17:19:12 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 29 Jun 2016 23:19:12 +0600
Subject: [squid-users] Skype Issues
In-Reply-To: <CAHha_zV5R4CNe+q82=MBS+qKH=fe9UYC5Rm0zj_3CE+FC=zpww@mail.gmail.com>
References: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>
 <8ff3bffe-47b7-8b0d-148d-cd3254344fd1@treenet.co.nz>
 <a30b3e16-5209-8240-359a-0cf736fe129f@gmail.com>
 <6e208cda-cb22-e48d-c0ee-0a6db04448e0@treenet.co.nz>
 <5153128f-ddd0-c134-22f1-158aa97575b4@gmail.com>
 <CAHha_zUDd__ZyMUCDQDcJ4KQouk++2OoZiEMptHY=Ty08D549A@mail.gmail.com>
 <b3abc44d-7abf-aa9a-ebd3-a775c4a81854@gmail.com>
 <CAHha_zUDWQEFJjWgupS55gibNxSZ=gy--CfvQesYoPv6akciDQ@mail.gmail.com>
 <0b950720-77ad-170d-55d3-295f028dfa92@gmail.com>
 <CAHha_zX+oDsFT7b6qfirB17v0C-iDMq7p1XdLG4z=++6V5_JeA@mail.gmail.com>
 <CAHha_zUZvUf2sBUXuoHdXi=s1CdnRR8YsOTWct1UPTrh4+N3Rw@mail.gmail.com>
 <CAHha_zV5R4CNe+q82=MBS+qKH=fe9UYC5Rm0zj_3CE+FC=zpww@mail.gmail.com>
Message-ID: <1b2b1219-18f3-1711-0cb0-b8b67a65d19e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
No, the problem in another place.

This option about ICQ, not about Skype.

29.06.2016 22:58, Renato Jop ?????:
> I've installed squid4 and the problems still persists. I've added the following acl:
> # define what Squid errors indicate receiving non-HTTP traffic:
> acl foreignProtocol squid_error ERR_PROTOCOL_UNKNOWN ERR_TOO_BIG
> # define what Squid errors indicate receiving nothing:
> acl serverTalksFirstProtocol squid_error ERR_REQUEST_START_TIMEOUT
> # tunnel everything that does not look like HTTP:
> on_unsupported_protocol tunnel foreignProtocol
> # tunnel if we think the client waits for the server to talk first:
> on_unsupported_protocol tunnel serverTalksFirstProtocol
> # in all other error cases, just send an HTTP "error page" response:
> on_unsupported_protocol respond all
>
> Renato Jop
>
> On Wed, Jun 29, 2016 at 8:21 AM, Renato Jop <renjop at gmail.com
<mailto:renjop at gmail.com>> wrote:
>
>     I've installed LibreSSL 2.2.9 and the issue still persists.
>     I think I am going to have install squid4 even if it's still in
beta to solve this issues.
>     Thanks for your help.
>
>
>     Renato Jop
>
>     On Mon, Jun 27, 2016 at 9:36 AM, Renato Jop <renjop at gmail.com
<mailto:renjop at gmail.com>> wrote:
>
>         Is there a way to verify that the SSL library doesn't support
SSLv3?
>
>         Renato Jop
>
>         On Mon, Jun 27, 2016 at 8:43 AM, Yuri <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>             Looks like your SSL library does not contain SSLv3
protocol support already, but site announce it.
>
>
>             27.06.2016 20:42, Renato Jop ?????:
>>             I removed the NO_SSLv2, NO_SSLv3 however, right before
the SSL3_GET_RECORD:wrong version number the SSL
routines:SSL23_GET_SERVER_HELLO:unknown protocol is shown.
>>
>>             Renato Jop
>>
>>             On Mon, Jun 27, 2016 at 8:29 AM, Yuri <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>>
>>                 Try to remove NO_SSLv2,NO_SSLv3 from options. SSLv2
already not supported everywhere, RC4/3DES is SSLv3 ciphers, so it can
be confuse software. I.e., you use custom ciphers/protocols
combinations, which can lead issue.
>>
>>
>>                 27.06.2016 20:25, Renato Jop ?????:
>>>                 Thank you both for your valuable help.
>>>                 I've configured the tls-dh param with a strong
Diffie-Hellman group (2048 bits) and configured the cipher as Yuri
specified and I was able to get pass the unknown cipher, however now I
get a "SSL routines:SSL3_GET_RECORD:wrong version number". Here's the
configuration I changed:
>>>                 
cipher=HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
dhparams=/etc/dh-parameters.2048 options=NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
tls-dh=/usr/local/etc/squid/dhparams.pem
>>>
>>>
>>>
>>>                 Renato Jop
>>>
>>>                 On Sat, Jun 25, 2016 at 11:34 AM, Yuri Voinov
<yvoinov at gmail.com <mailto:yvoinov at gmail.com>> wrote:
>>>
>>>
>
>
> 25.06.2016 <tel:25.06.2016> 23:09, Amos Jeffries ?????:
> > On 26/06/2016 4:32 a.m., Yuri Voinov wrote:
> >>
> >> Amos, you are a wrong.
> >>
> >> No Squid-4. It's unstable and not ready for production. Whenever it's
> >> features.
>
> > So some beta software has bugs therefore nobody should ever use it for
> > anything. I find that to be a strange and sad view of the world.
>
> > Care to guess why I listed it as the last option amongst several?
> >  Or why 4.0.11 exists as a beta still?
> > It *is* an option for the mentioned problem(s) though whatever its
> utility.
> Agreed.
>
>
>
> >>
> >> Some time ago I have the same issue and know what happens exactly.
> >>
> >> Skype initial connection site uses RC4 cipher. Which is disabled in
most
> >> squid's configuration.
>
> > Your "know what happens exactly" differs from at least two other peoples
> > debugging experiences with Skype.
>
> > RC4 is on the hitlist for most of the big vendors for the past year or
> > so. IIRC there were several Windows Updates to remove it and other
> > broken bits from a lot of things over the past year.
> > If Skype is still using RC4 it might be part of this problem.
> I'm sure this is problem and this problem exists. MS do nothing to make
> they sites/services more secure. BTW, MS Updates uses RC4 ciphers itself
> this time. With strong siphers there is no way to setup WU via Squid.
> I've spent much time to identify this problem in my setup and find
> working workaround.
>
> Another part of problem is: MS often uses it's own self-signed roots,
> which is exists in Windows, but nowhere else. And which has not
> cross-signed by well-known root CA's. They think it make MS services
> more secure. They wrong. But we can't do anything with it. So, this is
> forced us to add self-signed MS roots to our Squid's CA bundles to
> bump/splice.
>
>
> >>
> >> To make it works (as by as most M$ update sites) it's require
simple use
> >> this cipher's suite:
> >>
> >> HIGH:MEDIUM:RC4:3DES:!aNULL:!eNULL:!LOW:!MD5:!EXP:!PSK:!SRP:!DSS
> >>
> >> That works for me in 5 SSL bumped setups. There is no matter which
squid
> >> version installed.
>
> > Thank you. Thats another option then. I'd rate that below trying the EC
> > ciphers, and above library updates.
> You are welcome.
>
> Just for information: MS has own IT infrastructure, with some strange
> configured and non well-managed elements. I can't guarantee this
> workaround will work everywhere or for every MS service.
>
> When I made my research, I've seen some strange security TLS
> combinations on MS sites/services. I.e., for example, RC4+ECDSA+TLSv1.2.
> Or, for example, RC4+MD5+TLSv1. And some similar. Very idiotic and
> potentially dangerous combinations. And - they support ignores all
> requests. As usual.
>
> To my regret, I can not order all of its users to abandon the use of
> Windows. So far, in my infrastructure have machines with Windows XP.
>
> With this nothing can be done, it is necessary only to weaken the
> security - for the sake of compatibility.
>
>
> > Amos
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
> > http://lists.squid-cache.org/listinfo/squid-users
>
>>>
>>>
>>>                     _______________________________________________
>>>                     squid-users mailing list
>>>                     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>>>                     http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>
>>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdAMLAAoJENNXIZxhPexG418IAMQwpVRq1iFSGRCVAA9mIcHc
1ru7T00FRr3wKNrm6hCaeI3TgW9eAMguYG7wYbFqbOOZMWp0k/sFYqAGWwxhZGA4
+lEB/P5/+PJbg89MSYvTPjRrmf0XYtgwwCuZD+7oC0VSmdldhhaXgJYTi+lfVKZQ
p+P0X41y2Alfzjl2NqqJGN7Oyc35Av617YzsrjKN3MgSH6LDh+h7vhin75q/zXD8
TsRYAlqxsXAA5pvTbUrjVG7lruuavTGmKFpa79jZpkzlbkMEUW+088LeunkdP+V9
e2L6MlY6J10Jir3vwHFHYJJh4hbGYkJf4TdnZuV3itD937GebNOjqChMm8h7ER8=
=ThrU
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160629/d024605c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160629/d024605c/attachment.key>

From yvoinov at gmail.com  Wed Jun 29 17:20:16 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 29 Jun 2016 23:20:16 +0600
Subject: [squid-users] url_rewrite_program is ignored by squid
In-Reply-To: <CAJ_yQBm+2tBYOEwVA+Vi_uFEHU+HJWMFL0GPZSViR6Y+=xMmWw@mail.gmail.com>
References: <CAJ_yQBm+2tBYOEwVA+Vi_uFEHU+HJWMFL0GPZSViR6Y+=xMmWw@mail.gmail.com>
Message-ID: <4fa75648-92e2-9a46-4c51-314c4bac36d7@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Squidguard abandoned for years. Drop it out.


29.06.2016 23:12, Moataz Elmasry ?????:
> Hi all,
>
> I'm trying to use squid with squidguard, but it seems that squid3 is
somehow ignoring the url_rewrite_program completely. While starting
squid I'm getting the message:
>
> "
> helperOpenServers: Starting 0/20 'squidGuard' processes
> helperOpenServers: No 'squidGuard' processes needed
> "
>
> And nothing is being directed to squidguard.
> Just to be sure, I tried a simple bash program as well as a php
program to handle the redirection, and I'm receiving a similar message
and nothing is being redirected.
> Config files are listed below. All files are owned by the user "proxy"
> OS: ubuntu 16.04
> squid: 3.5.12-1ubuntu7.2
> squidguard: 1.5-5
>
> Here's  squid.conf
>
> "
> pinger_enable off
> url_rewrite_access allow all
> url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 443         # https
> acl Safe_ports port 1025-65535  # unregistered ports
> acl CONNECT method CONNECT
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access allow localhost
> acl whitelist dstdomain play.google.com <http://play.google.com>
> http_access allow whitelist
> http_access deny all
> http_port 3128
> coredump_dir /var/spool/squid
>
> "
>
> And here's squidGuard.conf
>
> "
> dbhome /var/lib/squidguard/db
> logdir /var/log/squidguard
>
> dest ads {
>         domainlist ads/domains
> }
>
> dest whitelist {
>     domainlist    whitelist/domains
> }
>
> acl {
>         default {
>                 pass whitelist none
>                 redirect http://www.contensi.com
>         }
> }
>
> "
>
> Any ideas what the problem is?
>
> Thanks
> Moataz
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdANQAAoJENNXIZxhPexGR3wH/RPyuwxWqbSvIHnjSpUMoXBd
muVKH3FDM61X2sB0qOHt5vNQneNkGvQctnRAzJHQFm3ljtPV0W+YmNGR9z7ie1XW
CO0eREMLfKtCcmkIaXJA5GwRwV4qWh6I9/J9dDOokocila1SXudXwNW8nH4etaKd
kKOloVER1MsPNBJOp3QZ9PbJU4vSj4o56iyfPn9nnnaTGOeKmqhnKBycC/t71TjC
NnVlLh5NndW6Jvd59fjNLuJkd6XxxXVAF0rvoBUi5WtdHOFXf7gKuIC+4IzvOUAi
wnT9HJKZzLYoejMeA/rKsK8v6qzYM6NO/iZRwHCYOcbBQYurQtqrgSor7vrtPzc=
=5u95
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160629/92c8c70f/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160629/92c8c70f/attachment.key>

From eduardoocarneiro at gmail.com  Wed Jun 29 18:29:55 2016
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Wed, 29 Jun 2016 11:29:55 -0700 (PDT)
Subject: [squid-users] Cache economy calculation
Message-ID: <1467224995882-4678292.post@n4.nabble.com>

Hello everyone.

I am using Squid 3.5.19 with dynamic and static caching feature activated.
It's working very well. All entries of the access.log are in a postgres
database. I am looking for the best way to calculate the cache economy. 

Someone could tell me how to do this?

Best regards.
Eduardo



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Cache-economy-calculation-tp4678292.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Wed Jun 29 19:13:08 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 30 Jun 2016 01:13:08 +0600
Subject: [squid-users] Cache economy calculation
In-Reply-To: <1467224995882-4678292.post@n4.nabble.com>
References: <1467224995882-4678292.post@n4.nabble.com>
Message-ID: <ad089a41-36e9-de42-0e00-77242fcfcf54@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Hhhhhhhhhhhhhhh....... billing system?


30.06.2016 0:29, Eduardo Carneiro ?????:
> Hello everyone.
>
> I am using Squid 3.5.19 with dynamic and static caching feature activated.
> It's working very well. All entries of the access.log are in a postgres
> database. I am looking for the best way to calculate the cache economy.
>
> Someone could tell me how to do this?
>
> Best regards.
> Eduardo
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Cache-economy-calculation-tp4678292.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdB3EAAoJENNXIZxhPexGYWcIAInezRTelGnP3rzrsBLWkdZB
XqjUFU/9YBPCEqoXiBnO4c3VH4iAyj1pBlZPM5aFhfQOi1Sp3CZksITomckwE0jU
xgtafGOudrc8UaOeLwRyEftre6E6yfzEFnKadv+gg4yFOLk0sUKuBAdjqHI13BPx
9BxPc4xN7opmsXow97+q7u/oQyb7f3trvNqJRKKw1KOWgeW2PMh/847v5z7eM0v5
zQ0Z4ueAFNRWIUxC5+OxO9bwrNpGLkG3uUw2ZPlZaZdvTM3OcgaX3Y5s8VhbUxea
3A7v7mbzpgwY7rKfi8jvROPNI3hITYwiKPn3TpuBa7W6kDat3NxPZUwhMPE59+I=
=p1Aq
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/45eb5f11/attachment.key>

From eduardoocarneiro at gmail.com  Wed Jun 29 18:34:21 2016
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Wed, 29 Jun 2016 11:34:21 -0700 (PDT)
Subject: [squid-users] Cache economy calculation
In-Reply-To: <ad089a41-36e9-de42-0e00-77242fcfcf54@gmail.com>
References: <1467224995882-4678292.post@n4.nabble.com>
 <ad089a41-36e9-de42-0e00-77242fcfcf54@gmail.com>
Message-ID: <1467225261982-4678294.post@n4.nabble.com>

No, no. Only for management purposes.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Cache-economy-calculation-tp4678292p4678294.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Wed Jun 29 19:16:12 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 30 Jun 2016 01:16:12 +0600
Subject: [squid-users] Cache economy calculation
In-Reply-To: <1467224995882-4678292.post@n4.nabble.com>
References: <1467224995882-4678292.post@n4.nabble.com>
Message-ID: <c1cdda25-a4d0-8bfa-1132-0c8219e4a295@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Eh, if you have access.log in SQL database, you cah simple write SQL
query - viola!

select (TCP_HIT/TCP_MISS)*100 from access_log; // Cache hit

select (field_with_bytes_from_access_log_table *
TCP_HIT_count/field_with_bytes_from_access_log_table *
TCP_MISS)*1024*1024 from access_log; // Byte hit


30.06.2016 0:29, Eduardo Carneiro ?????:
> Hello everyone.
>
> I am using Squid 3.5.19 with dynamic and static caching feature activated.
> It's working very well. All entries of the access.log are in a postgres
> database. I am looking for the best way to calculate the cache economy.
>
> Someone could tell me how to do this?
>
> Best regards.
> Eduardo
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Cache-economy-calculation-tp4678292.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdB58AAoJENNXIZxhPexGBA8H/0mojJPon2kX2PH+uUf2sDxU
7/e3FBTjWrUT44SRZxL4CJ3voCZYKmLx5B5Zp/fSMmUGdtIOWxbQjMX3F9/YGcIr
t/aLW5VozvD8coGhACzYk+3pyCVwwmDWnfw7YwvLF1dMrlNpgPpscJWrhEQK9Qc0
khmvzCXqIoFJvYgY9W38bViWZKhIGRTRTFoDU1o8l+p+5aR3x/y/PN4kCUzqykxH
rCw6QuB4QaYlAEUaOVc9E9tOHuc5LJE6MlkMWgToHntL099KwHR16NvR10xGzItL
hnNxMZKwJp1lh1wNpPEjHeXJsVphP1OCPOKGm/+iZTz+W28nCuJU/OAA3qUfuQQ=
=BHnu
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/e8cca64f/attachment.key>

From yvoinov at gmail.com  Wed Jun 29 19:18:51 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 30 Jun 2016 01:18:51 +0600
Subject: [squid-users] Cache economy calculation
In-Reply-To: <c1cdda25-a4d0-8bfa-1132-0c8219e4a295@gmail.com>
References: <1467224995882-4678292.post@n4.nabble.com>
 <c1cdda25-a4d0-8bfa-1132-0c8219e4a295@gmail.com>
Message-ID: <cf0e3e92-668b-ef47-d7bc-4cb5eb35e781@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Ah,

there is better solution exists. You can re-write Calamaris to get
source data from DB - it written on perl, simple. Just add DB adapter
from CPAN. :)

P.S. I think, you will be surprised, how low is your _real_ byte hit
:)))))))))))

30.06.2016 1:16, Yuri Voinov ?????:
>
> Eh, if you have access.log in SQL database, you cah simple write SQL
> query - viola!
>
> select (TCP_HIT/TCP_MISS)*100 from access_log; // Cache hit
>
> select (field_with_bytes_from_access_log_table *
> TCP_HIT_count/field_with_bytes_from_access_log_table *
> TCP_MISS)*1024*1024 from access_log; // Byte hit
>
>
> 30.06.2016 0:29, Eduardo Carneiro ?????:
> > Hello everyone.
>
> > I am using Squid 3.5.19 with dynamic and static caching feature
activated.
> > It's working very well. All entries of the access.log are in a postgres
> > database. I am looking for the best way to calculate the cache economy.
>
> > Someone could tell me how to do this?
>
> > Best regards.
> > Eduardo
>
>
>
> > --
> > View this message in context:
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Cache-economy-calculation-tp4678292.html
> > Sent from the Squid - Users mailing list archive at Nabble.com.
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdB8bAAoJENNXIZxhPexG8o4H/2EUtBMEnLH+ewMhdJRhsoOW
jG7XCO9NqqSC+bxLX6Y1dHBj7MFS5RBvUs/a4piDGLnOZM7/La57/WK9UU9OmTmw
vWjxD/LU7M1yUt9pgCe6K4PRDPJaionnheKNHtY///Xih9G9IgIzOWJgzmVa39pZ
hrXdT0qKf/7lAdYIjZPW5Tlm/yxEab3LBWBj823AjJgiXBpPUuMD1G0VMaBz4KG0
5GbgYBLQE57N8pl5ufrOIQY0PFRaaWpr6Ct0Y65feXz3Hm0ax0P6VIlU3Suh3nQg
8YU6H8PQniGWy+Mj1MebrVqZwLID4YYbQ8w+b6F9+Un8Z5cExBIVQd6cm8pl+eo=
=m5mo
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/98c158a6/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/98c158a6/attachment.key>

From eduardoocarneiro at gmail.com  Wed Jun 29 18:45:40 2016
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Wed, 29 Jun 2016 11:45:40 -0700 (PDT)
Subject: [squid-users] Cache economy calculation
In-Reply-To: <cf0e3e92-668b-ef47-d7bc-4cb5eb35e781@gmail.com>
References: <1467224995882-4678292.post@n4.nabble.com>
 <c1cdda25-a4d0-8bfa-1132-0c8219e4a295@gmail.com>
 <cf0e3e92-668b-ef47-d7bc-4cb5eb35e781@gmail.com>
Message-ID: <1467225940923-4678297.post@n4.nabble.com>

Thank you Yuri. But, the other action types like "TCP_DENIED" per example,
shall be calculated too? Or only "MISS" an "HIT" like you said before?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Cache-economy-calculation-tp4678292p4678297.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid-cache at pixelrebel.com  Wed Jun 29 19:29:38 2016
From: squid-cache at pixelrebel.com (squid-cache at pixelrebel.com)
Date: Wed, 29 Jun 2016 12:29:38 -0700
Subject: [squid-users] Subject: Bandwidth Ceiling
Message-ID: <577421a2.ndUrcfi6D7zcFBSH%squid-cache@pixelrebel.com>

Thanks for the tip Amos.  I tried compiling my own version with BUFSIZ set to 32KB, but 
it didn't seem to help.  The TCP buffer size on my system is 212992 bytes, I tried
64KB too, but that also didn't improve my situation.  Aside from adjsting the 
read_ahead_gap, is there anything else I'm missing?  I'm sort of out of my league here
so I may just quit and wait for v4. ;)

Thanks,
Jamie

>Sadly, that is kind of expected at present for any single client
>connection. We have some evidence that Squid is artificially lowering
>packet sizes in a few annoying ways. Used to make sense on slower
>networks, but not nowdays.
>
>Nathan Hoad has been putting a lot of work into this recently to figure
>out what can be done and has a performance fix in Squid-4. That is not
>going to make it into 3.5 because it relies on some major restructuring
>done only in Squid-4 code.
>
>
>But, if you are okay with playing around in the code his initial patch
>submission shows the key value to change:
><http://lists.squid-cache.org/pipermail/squid-dev/2016-March/005518.html>
>which should be the same in Squid-3. The 64KB bump in that patch leads
>to some pain so dont just apply that. In the end we went with 16KB to
>avoid huge per-connection memory requirements. It should really be tuned
>to about 1/2 or 1/4 the TCP buffer size on your system.
>After bumping up that read_ahead_gap directive also needs to be bumped
>up to a minimum of whatever value you choose there.
>
>HTH
>Amos




From yvoinov at gmail.com  Wed Jun 29 19:31:59 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 30 Jun 2016 01:31:59 +0600
Subject: [squid-users] Cache economy calculation
In-Reply-To: <1467225940923-4678297.post@n4.nabble.com>
References: <1467224995882-4678292.post@n4.nabble.com>
 <c1cdda25-a4d0-8bfa-1132-0c8219e4a295@gmail.com>
 <cf0e3e92-668b-ef47-d7bc-4cb5eb35e781@gmail.com>
 <1467225940923-4678297.post@n4.nabble.com>
Message-ID: <cd934b56-a26b-d1e0-3a3a-0c4dd1e7d3b7@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
You can extend your SQL query as you required, of course. This was only
an direction, idea.

Or, possible to write several different queries, like existing
script-based reporting tool.


30.06.2016 0:45, Eduardo Carneiro ?????:
> Thank you Yuri. But, the other action types like "TCP_DENIED" per example,
> shall be calculated too? Or only "MISS" an "HIT" like you said before?
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Cache-economy-calculation-tp4678292p4678297.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdCIvAAoJENNXIZxhPexGrWsIALoHyCHfnxQprJsoFkLZy4tJ
CtiygQT4PF8ly8LomHRgkQ+OyYJZ49/QXAJR2AQQ02t+ddGCKG6zRGAUVOakIwXk
D/SJuFoCaSXeNyEv8P9dGbRozXj++mLhijK2QqEMNoccW2B3yao/OefRY7VURQYj
QNHhYRRT/Clrk0YQ3q1rGzCuDhDXvlw1SLYDob1xqqSMx4gm39HDtfKI+fcK7aa6
WMZKe0eiDMzTuR6MB7e/6WUh+W/tBCDCX8jVIc7WOgUJ4ggvndinrgKkXz+QQ5kg
Nru7cYv0LADxGqQh6gHPCnHerSldYJrOCdzJ44wcWSEjJt1eDV7DzvllruawqjM=
=UujZ
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/18011c4a/attachment.key>

From eduardoocarneiro at gmail.com  Wed Jun 29 18:57:59 2016
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Wed, 29 Jun 2016 11:57:59 -0700 (PDT)
Subject: [squid-users] Cache economy calculation
In-Reply-To: <cd934b56-a26b-d1e0-3a3a-0c4dd1e7d3b7@gmail.com>
References: <1467224995882-4678292.post@n4.nabble.com>
 <c1cdda25-a4d0-8bfa-1132-0c8219e4a295@gmail.com>
 <cf0e3e92-668b-ef47-d7bc-4cb5eb35e781@gmail.com>
 <1467225940923-4678297.post@n4.nabble.com>
 <cd934b56-a26b-d1e0-3a3a-0c4dd1e7d3b7@gmail.com>
Message-ID: <1467226679813-4678300.post@n4.nabble.com>

Thank you again. In this case, I think that I'll exclude the "DENIED" of my
query. Theoretically this access don't go to the internet. That's correct?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Cache-economy-calculation-tp4678292p4678300.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Wed Jun 29 20:14:44 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 30 Jun 2016 02:14:44 +0600
Subject: [squid-users] Cache economy calculation
In-Reply-To: <1467226679813-4678300.post@n4.nabble.com>
References: <1467224995882-4678292.post@n4.nabble.com>
 <c1cdda25-a4d0-8bfa-1132-0c8219e4a295@gmail.com>
 <cf0e3e92-668b-ef47-d7bc-4cb5eb35e781@gmail.com>
 <1467225940923-4678297.post@n4.nabble.com>
 <cd934b56-a26b-d1e0-3a3a-0c4dd1e7d3b7@gmail.com>
 <1467226679813-4678300.post@n4.nabble.com>
Message-ID: <b3d77421-3d5a-c416-f902-af0327bf3e0a@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Yep. Sure.


30.06.2016 0:57, Eduardo Carneiro ?????:
> Thank you again. In this case, I think that I'll exclude the "DENIED" of my
> query. Theoretically this access don't go to the internet. That's correct?
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Cache-economy-calculation-tp4678292p4678300.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdCw0AAoJENNXIZxhPexGETUIALFvZVmQ4TAsubu2zgWvee/j
kx/8y8gL+GBBW7C+DiwhrDdwKTCCHH8TeG9WEfzzjPDAenFd1hmuZKsxweEAQxsK
ptZ/08Zc9hIhwNLoa3FoFqvXmsGEMStnqVgiqdcznCo/m55UgalmxufVjc3RrGPO
pn1wzIyHDMUsluhcLUTzVCSZOxpLTiSWRI9Rp6AvFu/r3u25ZVvM9GRpKsLULryq
kOE5B7G4M9kme2KJGDF/Oa2kWyy2PiRssbaRMWy0YnnCHGX8Yt22L3pTpZjbvK+v
GMhIL7R3v075TYW528vMKiaFhAxvwTgRtT+r6egoIxlXRieIlT4Tu7a32288HPI=
=UoUt
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/babd4f43/attachment.key>

From eliezer at ngtech.co.il  Wed Jun 29 20:34:50 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 29 Jun 2016 23:34:50 +0300
Subject: [squid-users] url_rewrite_program is ignored by squid
In-Reply-To: <4fa75648-92e2-9a46-4c51-314c4bac36d7@gmail.com>
References: <CAJ_yQBm+2tBYOEwVA+Vi_uFEHU+HJWMFL0GPZSViR6Y+=xMmWw@mail.gmail.com>
 <4fa75648-92e2-9a46-4c51-314c4bac36d7@gmail.com>
Message-ID: <02a501d1d245$afa7ef50$0ef7cdf0$@ngtech.co.il>

Hey Moataz,( is this the first name?)

 

I would be able to test it later next week on a testing machine.

It's not clear what you expect to happen.

What are seeing in the squid access.log file at the same time you are using the proxy?

It should show something when you load a simple HTTP page such as:

http://www.squid-cache.org/

 

And Yuri,

As was mentioned here in another thread.

Indeed SquidGuard is not maintained anymore for at least 2 years but it works for more then once place.

If it works and does good work for the users, then what is the blocker from using it?

If it will work, what then?

 

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
Sent: Wednesday, June 29, 2016 8:20 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] url_rewrite_program is ignored by squid

 


-----BEGIN PGP SIGNED MESSAGE----- 
Hash: SHA256 
 
Squidguard abandoned for years. Drop it out.


29.06.2016 23:12, Moataz Elmasry ?????:
> Hi all,



      >



      > I'm trying to use squid with squidguard, but it seems that

      squid3 is somehow ignoring the url_rewrite_program completely.

      While starting squid I'm getting the message: 



      >



      > "



      > helperOpenServers: Starting 0/20 'squidGuard' processes



      > helperOpenServers: No 'squidGuard' processes needed



      > "



      >



      > And nothing is being directed to squidguard. 



      > Just to be sure, I tried a simple bash program as well as a

      php program to handle the redirection, and I'm receiving a similar

      message and nothing is being redirected. 



      > Config files are listed below. All files are owned by the

      user "proxy"



      > OS: ubuntu 16.04



      > squid: 3.5.12-1ubuntu7.2



      > squidguard: 1.5-5



      >



      > Here's  squid.conf



      >



      > "



      > pinger_enable off



      > url_rewrite_access allow all



      > url_rewrite_program /usr/bin/squidGuard -c

      /etc/squidguard/squidGuard.conf



      > acl SSL_ports port 443



      > acl Safe_ports port 80          # http



      > acl Safe_ports port 443         # https



      > acl Safe_ports port 1025-65535  # unregistered ports



      > acl CONNECT method CONNECT



      > http_access deny !Safe_ports



      > http_access deny CONNECT !SSL_ports



      > http_access allow localhost manager



      > http_access deny manager



      > http_access allow localhost



      > acl whitelist dstdomain play.google.com

       <http://play.google.com> <http://play.google.com>



      > http_access allow whitelist



      > http_access deny all



      > http_port 3128



      > coredump_dir /var/spool/squid



      >



      > "



      >



      > And here's squidGuard.conf



      >



      > "



      > dbhome /var/lib/squidguard/db



      > logdir /var/log/squidguard



      >



      > dest ads {



      >         domainlist ads/domains



      > }



      >



      > dest whitelist {



      >     domainlist    whitelist/domains



      > }



      >



      > acl {



      >         default {



      >                 pass whitelist none



      >                 redirect http://www.contensi.com



      >         }



      > }



      >



      > "



      >



      > Any ideas what the problem is?



      >



      > Thanks 



      > Moataz



      >



      >



      > _______________________________________________



      > squid-users mailing list



      > squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 



      > http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE----- 
Version: GnuPG v2 
 
iQEcBAEBCAAGBQJXdANQAAoJENNXIZxhPexGR3wH/RPyuwxWqbSvIHnjSpUMoXBd 
muVKH3FDM61X2sB0qOHt5vNQneNkGvQctnRAzJHQFm3ljtPV0W+YmNGR9z7ie1XW 
CO0eREMLfKtCcmkIaXJA5GwRwV4qWh6I9/J9dDOokocila1SXudXwNW8nH4etaKd 
kKOloVER1MsPNBJOp3QZ9PbJU4vSj4o56iyfPn9nnnaTGOeKmqhnKBycC/t71TjC 
NnVlLh5NndW6Jvd59fjNLuJkd6XxxXVAF0rvoBUi5WtdHOFXf7gKuIC+4IzvOUAi 
wnT9HJKZzLYoejMeA/rKsK8v6qzYM6NO/iZRwHCYOcbBQYurQtqrgSor7vrtPzc= 
=5u95 
-----END PGP SIGNATURE----- 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160629/1c0dbd7a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11307 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160629/1c0dbd7a/attachment.png>

From yvoinov at gmail.com  Wed Jun 29 21:30:20 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 30 Jun 2016 03:30:20 +0600
Subject: [squid-users] url_rewrite_program is ignored by squid
In-Reply-To: <02a501d1d245$afa7ef50$0ef7cdf0$@ngtech.co.il>
References: <CAJ_yQBm+2tBYOEwVA+Vi_uFEHU+HJWMFL0GPZSViR6Y+=xMmWw@mail.gmail.com>
 <4fa75648-92e2-9a46-4c51-314c4bac36d7@gmail.com>
 <02a501d1d245$afa7ef50$0ef7cdf0$@ngtech.co.il>
Message-ID: <5622fd59-ce43-095e-9d8b-d0ac1a4142b4@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


30.06.2016 2:34, Eliezer Croitoru ?????:
>
> Hey Moataz,( is this the first name?)
>
> 
>
> I would be able to test it later next week on a testing machine.
>
> It's not clear what you expect to happen.
>
> What are seeing in the squid access.log file at the same time you are
using the proxy?
>
> It should show something when you load a simple HTTP page such as:
>
> http://www.squid-cache.org/
>
> 
>
> And Yuri,
>
> As was mentioned here in another thread.
>
> Indeed SquidGuard is not maintained anymore for at least 2 years but
it works for more then once place.
>
> If it works and does good work for the users, then what is the blocker
from using it?
Actually, it uses copy all databases for every helper instance. Thus it
absorbs all the RAM, no matter how much it was not, especially with
large lists.
>
> If it will work, what then?
Second. It does not work with HTTPS. Absolutely. What in the world, with
80% consisting of HTTPS - as something silly, is not it? And reduce its
value to nearly zero.

Of course, someone mare - bride .... But really - why not? If only the
mare was too happy. :-D
>
> 
>
> Eliezer
>
> 
>
> ----
>
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
> 
>
> *From:*squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
*On Behalf Of *Yuri Voinov
> *Sent:* Wednesday, June 29, 2016 8:20 PM
> *To:* squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] url_rewrite_program is ignored by squid
>
> 
>
>
> Squidguard abandoned for years. Drop it out.
>
>
> 29.06.2016 23:12, Moataz Elmasry ?????:
> > Hi all,
>
>
>
>       > I'm trying to use squid with squidguard, but it seems that
>
>       squid3 is somehow ignoring the url_rewrite_program completely.
>
>       While starting squid I'm getting the message:
>
>
>
>       > "
>
>       > helperOpenServers: Starting 0/20 'squidGuard' processes
>
>       > helperOpenServers: No 'squidGuard' processes needed
>
>       > "
>
>
>
>       > And nothing is being directed to squidguard.
>
>       > Just to be sure, I tried a simple bash program as well as a
>
>       php program to handle the redirection, and I'm receiving a similar
>
>       message and nothing is being redirected.
>
>       > Config files are listed below. All files are owned by the
>
>       user "proxy"
>
>       > OS: ubuntu 16.04
>
>       > squid: 3.5.12-1ubuntu7.2
>
>       > squidguard: 1.5-5
>
>
>
>       > Here's  squid.conf
>
>
>
>       > "
>
>       > pinger_enable off
>
>       > url_rewrite_access allow all
>
>       > url_rewrite_program /usr/bin/squidGuard -c
>
>       /etc/squidguard/squidGuard.conf
>
>       > acl SSL_ports port 443
>
>       > acl Safe_ports port 80          # http
>
>       > acl Safe_ports port 443         # https
>
>       > acl Safe_ports port 1025-65535  # unregistered ports
>
>       > acl CONNECT method CONNECT
>
>       > http_access deny !Safe_ports
>
>       > http_access deny CONNECT !SSL_ports
>
>       > http_access allow localhost manager
>
>       > http_access deny manager
>
>       > http_access allow localhost
>
>       > acl whitelist dstdomain play.google.com
>
>       <http://play.google.com> <http://play.google.com>
>
>       > http_access allow whitelist
>
>       > http_access deny all
>
>       > http_port 3128
>
>       > coredump_dir /var/spool/squid
>
>
>
>       > "
>
>
>
>       > And here's squidGuard.conf
>
>
>
>       > "
>
>       > dbhome /var/lib/squidguard/db
>
>       > logdir /var/log/squidguard
>
>
>
>       > dest ads {
>
>       >         domainlist ads/domains
>
>       > }
>
>
>
>       > dest whitelist {
>
>       >     domainlist    whitelist/domains
>
>       > }
>
>
>
>       > acl {
>
>       >         default {
>
>       >                 pass whitelist none
>
>       >                 redirect http://www.contensi.com
>
>       >         }
>
>       > }
>
>
>
>       > "
>
>
>
>       > Any ideas what the problem is?
>
>
>
>       > Thanks
>
>       > Moataz
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdD3rAAoJENNXIZxhPexGs70H/RNa45xO/L3PlNTpHbX4bgea
9csGDMx3+grzn5bocmKSXU1bMekEhp6ty20LZZb8PYXhwAuuzBGPJ6/wnp4e41fj
4+e3tQwZiVrBf6pl1uM4MsjiMIcfkT77MYPNea8VktMWRp7TmFRQqa5zhGcqzKsz
T+zdHkgJspYsfJsEguYy2lNknsPtifD5uX6jlo8//eiIuS4dBje1YaQjUZDDtXsp
7pZ4GBw65ezEA1pdv6g1r9p7InXDKsf4+La/CAi0nWRDehbrmbvfC0UW04mCFG3L
r419KdWcTRnK/AwYgpe1JWCJPYfVzKrYaHA+TL8iRpvIIysE6JLW/sW28pYzxSM=
=mM3G
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/f7a85b29/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/f7a85b29/attachment.key>

From yvoinov at gmail.com  Wed Jun 29 21:31:29 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 30 Jun 2016 03:31:29 +0600
Subject: [squid-users] url_rewrite_program is ignored by squid
In-Reply-To: <5622fd59-ce43-095e-9d8b-d0ac1a4142b4@gmail.com>
References: <CAJ_yQBm+2tBYOEwVA+Vi_uFEHU+HJWMFL0GPZSViR6Y+=xMmWw@mail.gmail.com>
 <4fa75648-92e2-9a46-4c51-314c4bac36d7@gmail.com>
 <02a501d1d245$afa7ef50$0ef7cdf0$@ngtech.co.il>
 <5622fd59-ce43-095e-9d8b-d0ac1a4142b4@gmail.com>
Message-ID: <60641176-5dee-fefe-7bd2-0d452dc2f993@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


30.06.2016 3:30, Yuri Voinov ?????:
>
>
>
> 30.06.2016 2:34, Eliezer Croitoru ?????:
>
>
>       > Hey Moataz,( is this the first name?)
>
>
>
>
>
>
>
>       > I would be able to test it later next week on a testing
>       machine.
>
>
>
>       > It's not clear what you expect to happen.
>
>
>
>       > What are seeing in the squid access.log file at the same time
>       you are using the proxy?
>
>
>
>       > It should show something when you load a simple HTTP page
>       such as:
>
>
>
>       > http://www.squid-cache.org/
>
>
>
>
>
>
>
>       > And Yuri,
>
>
>
>       > As was mentioned here in another thread.
>
>
>
>       > Indeed SquidGuard is not maintained anymore for at least 2
>       years but it works for more then once place.
>
>
>
>       > If it works and does good work for the users, then what is
>       the blocker from using it?
> Actually, it uses copy all databases for every helper instance. Thus
it absorbs all the RAM, no matter how much it was not, especially with
large lists.
Personally, I think this is a major drawback, even in a world where a
memory module is cheaper shovel shit.
>
>
>       > If it will work, what then?
> Second. It does not work with HTTPS. Absolutely. What in the world,
with 80% consisting of HTTPS - as something silly, is not it? And reduce
its value to nearly zero.
>
> Of course, someone mare - bride .... But really - why not? If only the
mare was too happy. :-D
>
>
>
>
>
>
>       > Eliezer
>
>
>
>
>
>
>
>       > ----
>
>
>
>       > Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
>
>       > Linux System Administrator
>
>       > Mobile: +972-5-28704261
>
>       > Email: eliezer at ngtech.co.il
>
>
>
>
>
>
>
>       > *From:*squid-users
>       [mailto:squid-users-bounces at lists.squid-cache.org] *On Behalf Of
>       *Yuri Voinov
>
>       > *Sent:* Wednesday, June 29, 2016 8:20 PM
>
>       > *To:* squid-users at lists.squid-cache.org
>
>       > *Subject:* Re: [squid-users] url_rewrite_program is ignored
>       by squid
>
>
>
>
>
>
>
>
>
>       > Squidguard abandoned for years. Drop it out.
>
>
>
>
>
>       > 29.06.2016 23:12, Moataz Elmasry ?????:
>
>       > > Hi all,
>
>
>
>
>
>
>
>       >       > I'm trying to use squid with squidguard, but it
>       seems that
>
>
>
>       >       squid3 is somehow ignoring the url_rewrite_program
>       completely.
>
>
>
>       >       While starting squid I'm getting the message:
>
>
>
>
>
>
>
>       >       > "
>
>
>
>       >       > helperOpenServers: Starting 0/20 'squidGuard'
>       processes
>
>
>
>       >       > helperOpenServers: No 'squidGuard' processes
>       needed
>
>
>
>       >       > "
>
>
>
>
>
>
>
>       >       > And nothing is being directed to squidguard.
>
>
>
>       >       > Just to be sure, I tried a simple bash program as
>       well as a
>
>
>
>       >       php program to handle the redirection, and I'm
>       receiving a similar
>
>
>
>       >       message and nothing is being redirected.
>
>
>
>       >       > Config files are listed below. All files are owned
>       by the
>
>
>
>       >       user "proxy"
>
>
>
>       >       > OS: ubuntu 16.04
>
>
>
>       >       > squid: 3.5.12-1ubuntu7.2
>
>
>
>       >       > squidguard: 1.5-5
>
>
>
>
>
>
>
>       >       > Here's  squid.conf
>
>
>
>
>
>
>
>       >       > "
>
>
>
>       >       > pinger_enable off
>
>
>
>       >       > url_rewrite_access allow all
>
>
>
>       >       > url_rewrite_program /usr/bin/squidGuard -c
>
>
>
>       >       /etc/squidguard/squidGuard.conf
>
>
>
>       >       > acl SSL_ports port 443
>
>
>
>       >       > acl Safe_ports port 80          # http
>
>
>
>       >       > acl Safe_ports port 443         # https
>
>
>
>       >       > acl Safe_ports port 1025-65535  # unregistered
>       ports
>
>
>
>       >       > acl CONNECT method CONNECT
>
>
>
>       >       > http_access deny !Safe_ports
>
>
>
>       >       > http_access deny CONNECT !SSL_ports
>
>
>
>       >       > http_access allow localhost manager
>
>
>
>       >       > http_access deny manager
>
>
>
>       >       > http_access allow localhost
>
>
>
>       >       > acl whitelist dstdomain play.google.com
>
>
>
>       >       <http://play.google.com>
>       <http://play.google.com>
>
>
>
>       >       > http_access allow whitelist
>
>
>
>       >       > http_access deny all
>
>
>
>       >       > http_port 3128
>
>
>
>       >       > coredump_dir /var/spool/squid
>
>
>
>
>
>
>
>       >       > "
>
>
>
>
>
>
>
>       >       > And here's squidGuard.conf
>
>
>
>
>
>
>
>       >       > "
>
>
>
>       >       > dbhome /var/lib/squidguard/db
>
>
>
>       >       > logdir /var/log/squidguard
>
>
>
>
>
>
>
>       >       > dest ads {
>
>
>
>       >       >         domainlist ads/domains
>
>
>
>       >       > }
>
>
>
>
>
>
>
>       >       > dest whitelist {
>
>
>
>       >       >     domainlist    whitelist/domains
>
>
>
>       >       > }
>
>
>
>
>
>
>
>       >       > acl {
>
>
>
>       >       >         default {
>
>
>
>       >       >                 pass whitelist none
>
>
>
>       >       >                 redirect http://www.contensi.com
>
>
>
>       >       >         }
>
>
>
>       >       > }
>
>
>
>
>
>
>
>       >       > "
>
>
>
>
>
>
>
>       >       > Any ideas what the problem is?
>
>
>
>
>
>
>
>       >       > Thanks
>
>
>
>       >       > Moataz
>
>
>
>
>
>
>
>
>
>
>
>       >       > _______________________________________________
>
>
>
>       >       > squid-users mailing list
>
>
>
>       >       > squid-users at lists.squid-cache.org
>       <mailto:squid-users at lists.squid-cache.org>
>
>
>
>       >       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdD4xAAoJENNXIZxhPexGjC4IALrbi8NkXc8XeC8hl71eYPcW
oZgff2D6OTqtoC36W/fPfADjrwTS5fOfJTrN0ofZeh3u4K5mGxLSS5+jcOPotHVa
30FRKiTCMr1ycywToDKpAzfI3s2qr8lhONeEDko07zYKH3ZewpP70AOzVUsbd9D8
zL7b+qicsx8lr+qV35/pustgniBu97YYS82T/xumQcxkDFKB0gglAvC9VSt4goYq
vTGjRG7uYweBGg6vj2wbNN8hPA6wligoI3MQ6/H5FPUIO3XwxxQBHHzU6be2GwAl
xxEAdJpHTHSqQjPXGNLI0p7Soo0+4h+asog5RXkDLNtNEkWzKrEtVo94TXNyLfk=
=TRpC
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/7de6ec82/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/7de6ec82/attachment.key>

From bruce.rosenberg.au at gmail.com  Wed Jun 29 22:47:16 2016
From: bruce.rosenberg.au at gmail.com (Bruce Rosenberg)
Date: Thu, 30 Jun 2016 08:47:16 +1000
Subject: [squid-users] cafile and capath not working as expected with
	SSL bump
In-Reply-To: <75746789-774a-0d96-5606-2282d0e9bb29@treenet.co.nz>
References: <CAHaxnUKy2W2Q=3cmou=uPgo8sQapaMTkPvsPjswHMoMcFS-a9Q@mail.gmail.com>
 <75746789-774a-0d96-5606-2282d0e9bb29@treenet.co.nz>
Message-ID: <CAHaxnULh1=T3j9Hk3HPBKciyW8c+Ha2tF+kwm2zBH-Fqxgukng@mail.gmail.com>

Ah after reading your reply that makes perfect sense.
Thanks so much Amos, you nailed it.

On Thu, Jun 30, 2016 at 12:17 AM, Amos Jeffries <squid3 at treenet.co.nz>
wrote:

> On 29/06/2016 10:01 p.m., Bruce Rosenberg wrote:
> > Hi,
> >
> > I'm using squid 3.5.19 on RHEL6 and have configured SSL bump, which for
> the
> > most part is working great.
> > The issue I have is I need to install some additional CA certs that are
> not
> > provided by the ca-certificates-2015 RPM in the /etc/pki/tls/cert.pem
> file
> > (symlinked to /etc/pki/tls/certs/ca-bundle.crt).
> > I've tried adding both the cafile and capath options to the http_port
> entry
> > but neither seems to have any affect.
> > With the cafile option I can see squid open the file via an strace but
> when
> > I connect to the server it fails with a 503 as the SSL session to the
> > remote side is failing to verify.
> > With the capath option, strace shows that squid never attempts to open
> any
> > files in that directory.
> > Dynamic certificate generation between squid and the client is working
> fine
> > however.
> >
> ...
> >
> > Are the cafile and capath options supposed to work like this i.e. do they
> > allow you to complement the OS supplied CA certs for remote site
> > verification or have I completely misread the documentation?
>
> The options *on http_port* are supposed to act like that, yes.
>
> I think you have just mistaken the distinction between the three types
> of connection Squid has to juggle.
>
>
> http(s)_port is for links between client and Squid. Those parameters
> used for verifying *client certificates*.
>
> sslproxy_* set of directives are for direct Squid->server links. The
> sslproxy_cafile and/or sslproxy_capath load the extra special CA you
> want to add to the system default ones.
>
> cache_peer is for static links to a known server/peer. It has its own
> cafile= and capath= options for CA to verify that specific server.
> Ideally the system CAs would not be used here.
>
>
> If I'm understanding your needs correctly then you want to be
> configuring sslproxy_cafile and/or sslproxy_capath.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/170c94dc/attachment.htm>

From rousskov at measurement-factory.com  Thu Jun 30 00:00:51 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 29 Jun 2016 18:00:51 -0600
Subject: [squid-users] Subject: Bandwidth Ceiling
In-Reply-To: <577421a2.ndUrcfi6D7zcFBSH%squid-cache@pixelrebel.com>
References: <577421a2.ndUrcfi6D7zcFBSH%squid-cache@pixelrebel.com>
Message-ID: <57746133.4050406@measurement-factory.com>

On 06/29/2016 01:29 PM, squid-cache at pixelrebel.com wrote:
> I'm sort of out of my league here so I may just quit and wait for v4.

Squid v4 may suffer from similar performance problems unless you test it
now, when it is still not too late to fix v4.

Please do not _assume_ that others observe, care about, and/or fix
performance problems that you observe and care about. A large number of
different deployment environments/requirements combined with poor
understanding of change side-effects often result in performance
surprises. If you do not have a concrete evidence that your specific
problem has been addressed, then do your own testing and bug reporting.


Thank you,

Alex.



From zaza1851983ml at googlemail.com  Thu Jun 30 00:16:26 2016
From: zaza1851983ml at googlemail.com (Moataz Elmasry)
Date: Thu, 30 Jun 2016 02:16:26 +0200
Subject: [squid-users] url_write_program: redirecting fails when
	intercepting https
Message-ID: <CAJ_yQB=0sBydwL-8k3R2j0GoEm513D5WkbBAaABKTQExTsnGzw@mail.gmail.com>

Hi all,

I'm writing a small bash program script to redirect any request to say
www.google.com. This script is able to redirect any http script to
google.com, but not https requests.
I read the documentation
http://wiki.squid-cache.org/Features/HTTPS
But this seem quite complex for my task. Basically I just want to redirect
any domain, without looking into the full path. Knowing the domain name
should not be counted as violation or interception of https I hope

Here's the script which works with http but not https:

"
#!/bin/bash
while true;
do
  read input;
  if [[ "$old_url" =~ ".google.com" ]]; then
    echo "ERB"
  else
    echo "echo '303:https://www.google.com"
  fi
done
"

Any ideas how to solve that?

Regards and thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/5967dfa7/attachment.htm>

From jlay at slave-tothe-box.net  Thu Jun 30 01:33:56 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Wed, 29 Jun 2016 19:33:56 -0600
Subject: [squid-users] Yet another new cipher?
Message-ID: <1467250436.2485.3.camel@slave-tothe-box.net>

Yugh...starting around 10:00 facebook no longer works via peek/splice.
?pcap contents show:

1QTV01...CHLO....SNI.....VERS....scontent.xx.fbcdn.netQTV1

after the threeway handshake and an instant reset. ?Anyone know what
this is? ?Cause I haven't a clue....screenshot of success after
bypassing included. ?Thank you.

James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160629/d91eb7c2/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screenshot from 2016-06-29 19-32-43.png
Type: image/png
Size: 58978 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160629/d91eb7c2/attachment.png>

From eliezer at ngtech.co.il  Thu Jun 30 06:13:14 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 30 Jun 2016 09:13:14 +0300
Subject: [squid-users] url_write_program: redirecting fails
	when	intercepting https
In-Reply-To: <CAJ_yQB=0sBydwL-8k3R2j0GoEm513D5WkbBAaABKTQExTsnGzw@mail.gmail.com>
References: <CAJ_yQB=0sBydwL-8k3R2j0GoEm513D5WkbBAaABKTQExTsnGzw@mail.gmail.com>
Message-ID: <014801d1d296$7c845630$758d0290$@ngtech.co.il>

What squid.conf are you using with this script?

 

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Moataz Elmasry
Sent: Thursday, June 30, 2016 3:16 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] url_write_program: redirecting fails when intercepting https

 

Hi all,

 

I'm writing a small bash program script to redirect any request to say www.google.com <http://www.google.com> . This script is able to redirect any http script to google.com <http://google.com> , but not https requests. 

I read the documentation

http://wiki.squid-cache.org/Features/HTTPS

But this seem quite complex for my task. Basically I just want to redirect any domain, without looking into the full path. Knowing the domain name should not be counted as violation or interception of https I hope

 

Here's the script which works with http but not https:

 

"

#!/bin/bash

while true;

do

  read input;

  if [[ "$old_url" =~ ".google.com <http://google.com> " ]]; then

    echo "ERB"

  else

    echo "echo '303:https://www.google.com"

  fi

done

"

 

Any ideas how to solve that?

 

Regards and thanks

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/6db4296e/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11297 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/6db4296e/attachment.png>

From info at comunicacionesman.com  Thu Jun 30 08:53:57 2016
From: info at comunicacionesman.com (info at comunicacionesman.com)
Date: Thu, 30 Jun 2016 10:53:57 +0200
Subject: [squid-users] Squid Proxy SSL Bump Certificates
In-Reply-To: <a2efae59da7e535d6a33b2a57c55591a@comunicacionesman.com>
References: <a2efae59da7e535d6a33b2a57c55591a@comunicacionesman.com>
Message-ID: <20c320499d586b32017f4d90154939ed@comunicacionesman.com>

Hi.

I've configured a firewall in our company with pfSense using Squid as 
proxy server. I made it work combined with Diladele to show graphs, 
filter logs, configure blocked sites, etc.

What I'm trying to do now is to use an external certificate from a 
trusted certificate authority (in this case I'm using a free SSL 
certificate from comodo), but I can't see my certificate in the 
certificates list when enabling SSL Man in the middle. I can only see 
CA's, which are certificate authorities, but when I upload comodo's Root 
CA certificate and select it, service does not start. Throws this error:

Jun 30 08:52:40	squid		No valid signing SSL certificate configured for 
HTTP_port 192.168.1.1:3128

Does Squid not accept a SSL Certificate from external authorities or am 
I missing something?

Thanks in advance.

Best regards.


From Antony.Stone at squid.open.source.it  Thu Jun 30 09:04:38 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 30 Jun 2016 11:04:38 +0200
Subject: [squid-users] Squid Proxy SSL Bump Certificates
In-Reply-To: <20c320499d586b32017f4d90154939ed@comunicacionesman.com>
References: <a2efae59da7e535d6a33b2a57c55591a@comunicacionesman.com>
 <20c320499d586b32017f4d90154939ed@comunicacionesman.com>
Message-ID: <201606301104.38546.Antony.Stone@squid.open.source.it>

On Thursday 30 June 2016 at 10:53:57, info at comunicacionesman.com wrote:

> What I'm trying to do now is to use an external certificate from a
> trusted certificate authority (in this case I'm using a free SSL
> certificate from comodo), but I can't see my certificate in the
> certificates list when enabling SSL Man in the middle. I can only see
> CA's, which are certificate authorities, but when I upload comodo's Root
> CA certificate and select it, service does not start. Throws this error:
> 
> Jun 30 08:52:40	squid		No valid signing SSL certificate configured
> for HTTP_port 192.168.1.1:3128
> 
> Does Squid not accept a SSL Certificate from external authorities or am
> I missing something?

Squid would be quite happy to accept a certificate from external authorities, 
but you will never get one.

You're missing the significance of the word "signing" in that error message.

What you have from Comodo is a signED certificate (and you also have the CA 
certificate to prove that they signed it).

What you do not have is a signING certificate (together with the accompanying 
private key) to be able to create and sign certificates on the fly, which is 
what Squid does for SSL MITM interception.

You will never get an appropriate key and certificate for this purpose from an 
external CA, because if they gave you those, you could forge certificates for 
any website on the Internet and their trust model would collapse.

SSL MITM has to be done with a self-signed certificate, and a self-generated CA 
certificate on the clients.


Antony.

-- 
Python is executable pseudocode.
Perl is executable line noise.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From emz at norma.perm.ru  Thu Jun 30 09:21:22 2016
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Thu, 30 Jun 2016 14:21:22 +0500
Subject: [squid-users] NOTICE: Authentication not applicable on intercepted
	requests.
Message-ID: <5774E492.5060002@norma.perm.ru>

Hi,

Could this message be moved on loglevel 2 instead of 1 ?
I think that this message does 95% of the logs of the intercept-enabled
caches with authentication.

At least some switch would be nice, to switch this off instead of
switching the while facility to 0.

Thanks.
Eugene.


From squid3 at treenet.co.nz  Thu Jun 30 12:03:07 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 1 Jul 2016 00:03:07 +1200
Subject: [squid-users] url_write_program: redirecting fails when
 intercepting https
In-Reply-To: <CAJ_yQB=0sBydwL-8k3R2j0GoEm513D5WkbBAaABKTQExTsnGzw@mail.gmail.com>
References: <CAJ_yQB=0sBydwL-8k3R2j0GoEm513D5WkbBAaABKTQExTsnGzw@mail.gmail.com>
Message-ID: <083e327a-e461-34c8-ea4d-9797935b5da1@treenet.co.nz>

On 30/06/2016 12:16 p.m., Moataz Elmasry wrote:
> Hi all,
> 
> I'm writing a small bash program script to redirect any request to say
> www.google.com. This script is able to redirect any http script to
> google.com, but not https requests.
> I read the documentation
> http://wiki.squid-cache.org/Features/HTTPS
> But this seem quite complex for my task. Basically I just want to redirect
> any domain, without looking into the full path. Knowing the domain name
> should not be counted as violation or interception of https I hope

What you want and reality do not match. Encryption is not plain ASCII text.

If you want to play around with the plain-text form of encrypted
services like Google and are not the valid owner osf that service, then
you have to MITM / hijack and decrypt the crypto in real-time. Which is
not a simple process.

Amos



From squid3 at treenet.co.nz  Thu Jun 30 12:04:28 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 1 Jul 2016 00:04:28 +1200
Subject: [squid-users] NOTICE: Authentication not applicable on
 intercepted requests.
In-Reply-To: <5774E492.5060002@norma.perm.ru>
References: <5774E492.5060002@norma.perm.ru>
Message-ID: <3dd5ef30-2cfb-d009-553a-b5a0816dea95@treenet.co.nz>

On 30/06/2016 9:21 p.m., Eugene M. Zheganin wrote:
> Hi,
> 
> Could this message be moved on loglevel 2 instead of 1 ?
> I think that this message does 95% of the logs of the intercept-enabled
> caches with authentication.
> 
> At least some switch would be nice, to switch this off instead of
> switching the while facility to 0.

This message only happens when your proxy is misconfigured.

Use a myportname ACL to prevent Squid attempting impossible things like
authentication on intercepted traffic.

Amos



From squid3 at treenet.co.nz  Thu Jun 30 12:10:17 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 1 Jul 2016 00:10:17 +1200
Subject: [squid-users] Skype Issues
In-Reply-To: <1b2b1219-18f3-1711-0cb0-b8b67a65d19e@gmail.com>
References: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>
 <8ff3bffe-47b7-8b0d-148d-cd3254344fd1@treenet.co.nz>
 <a30b3e16-5209-8240-359a-0cf736fe129f@gmail.com>
 <6e208cda-cb22-e48d-c0ee-0a6db04448e0@treenet.co.nz>
 <5153128f-ddd0-c134-22f1-158aa97575b4@gmail.com>
 <CAHha_zUDd__ZyMUCDQDcJ4KQouk++2OoZiEMptHY=Ty08D549A@mail.gmail.com>
 <b3abc44d-7abf-aa9a-ebd3-a775c4a81854@gmail.com>
 <CAHha_zUDWQEFJjWgupS55gibNxSZ=gy--CfvQesYoPv6akciDQ@mail.gmail.com>
 <0b950720-77ad-170d-55d3-295f028dfa92@gmail.com>
 <CAHha_zX+oDsFT7b6qfirB17v0C-iDMq7p1XdLG4z=++6V5_JeA@mail.gmail.com>
 <CAHha_zUZvUf2sBUXuoHdXi=s1CdnRR8YsOTWct1UPTrh4+N3Rw@mail.gmail.com>
 <CAHha_zV5R4CNe+q82=MBS+qKH=fe9UYC5Rm0zj_3CE+FC=zpww@mail.gmail.com>
 <1b2b1219-18f3-1711-0cb0-b8b67a65d19e@gmail.com>
Message-ID: <a6a87272-5864-11b8-9713-1adfee649600@treenet.co.nz>

On 30/06/2016 5:19 a.m., Yuri Voinov wrote:
> 
> No, the problem in another place.
> 
> This option about ICQ, not about Skype.
> 
> 29.06.2016 22:58, Renato Jop ?????:
>> I've installed squid4 and the problems still persists. I've added the following acl:
>> # define what Squid errors indicate receiving non-HTTP traffic:
>> acl foreignProtocol squid_error ERR_PROTOCOL_UNKNOWN ERR_TOO_BIG
>> # define what Squid errors indicate receiving nothing:
>> acl serverTalksFirstProtocol squid_error ERR_REQUEST_START_TIMEOUT
>> # tunnel everything that does not look like HTTP:
>> on_unsupported_protocol tunnel foreignProtocol
>> # tunnel if we think the client waits for the server to talk first:
>> on_unsupported_protocol tunnel serverTalksFirstProtocol
>> # in all other error cases, just send an HTTP "error page" response:
>> on_unsupported_protocol respond all
> 


What are you on today Yuri?
 The on_unsupported_protocol directive is about what its name says *any*
unsupported protocol. Not ICQ specific.

I think the issue here is that Skype looks at the binary level like TLS.
TLS being a supported protocol if it looks close enough then it would be
seen as invalid/broken TLS, not some non-TLS.

Sory Renato, with that not working I'm not sure where to go next.

Amos


From squid3 at treenet.co.nz  Thu Jun 30 12:19:02 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 1 Jul 2016 00:19:02 +1200
Subject: [squid-users] large downloads got interrupted
In-Reply-To: <5773DA3B.60409@norma.perm.ru>
References: <57723949.1060504@norma.perm.ru>
 <16f57ceb-f22e-25e8-ee5c-dfc3e9eeb7fa@treenet.co.nz>
 <5773DA3B.60409@norma.perm.ru>
Message-ID: <bad52c96-20d6-c538-4fde-8f7c5e9326e8@treenet.co.nz>

On 30/06/2016 2:24 a.m., Eugene M. Zheganin wrote:
> Hi.
> 
> On 29.06.16 05:26, Amos Jeffries wrote:
>> On 28/06/2016 8:46 p.m., Eugene M. Zheganin wrote:
>>> Hi,
>>>
>>> recently I started to get the problem when large downloads via squid are
>>> often interrupted. I tried to investigate it, but, to be honest, got
>>> nowhere. However, I took two tcpdump captures, and it seems to me that
>>> for some reason squid sends FIN to it's client and correctly closes the
>>> connection (wget reports that connection is closed), and in the same
>>> time for some reason it sends like tonns of RSTs towards the server. No
>>> errors in logs are reported (at least on a  ALL,1 loglevel).
>>>
>> It sounds like a timeout or such has happened inside Squid. We'd need to
>> see your squid.conf to see if that was it.
> Well... it quite long, since it's at large production site. I guess you
> don't need the acl and auth lines, so without them it's as follows
> (nothing secret in them, just that they are really numerous):

Okay. I was kind of hoping you had set some of the timeouts to a
unusually low value. Since its all default, then I think its one of the
much more difficult bug related issues.

<snip>
> 
> The download I test this issue on is:
> - a large iso file, 4G from Yandex mirror
> - goes via plain http (so no sslBump)
> - client is authenticated using basic authentication
> - you can see a delay pools in squid.config, but this is just a
> definition, no clients are assigned into it
> 
> 
> When connection is closed the client receives FIN sequence, and squid
> sends a loooot of RSTs towards target server I'm downloading the file from.
> 
>>
>> What version are you using? there have been a few bugs found that can
>> cause unrelated connections to be closed early like this.
> I noticed this problem on squid 3.5.11, but it's reproducible on 3.5.19
> as well.
> 
>> Screen dump of packet capture does not usually help. We usually only ask
>> for packet captures when one of the dev needs to personally analyse the
>> full traffic behaviour.
>>
>> A cache.log trace at debug level 11,2 shows all the HTTP messages going
>> through in an easier format to read. There might be hints in there, but
>> if it is a timeout like I suspect probably not.
> Well... do you need it already ? I should say that it will be way huge.
> May be there's a way to grep only the interesting parts ?
> 

Okay, I wasn't suggesting you post it here. Its likely to be too big for
that.

I would look for the messages about the large object, and its FD. Then,
for anthing about why it was closed by Squid. Not sure what tha would be
at this point though.
There are some scripts in the Squid sources scripts/ directory that
might help wade through the log. Or the grep tool.

Amos



From jlay at slave-tothe-box.net  Thu Jun 30 12:43:45 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Thu, 30 Jun 2016 06:43:45 -0600
Subject: [squid-users] Yet another new cipher?
In-Reply-To: <1467250436.2485.3.camel@slave-tothe-box.net>
References: <1467250436.2485.3.camel@slave-tothe-box.net>
Message-ID: <1467290625.2355.0.camel@slave-tothe-box.net>

On Wed, 2016-06-29 at 19:33 -0600, James Lay wrote:
> Yugh...starting around 10:00 facebook no longer works via
> peek/splice. ?pcap contents show:
> 
> 1QTV01...CHLO....SNI.....VERS....scontent.xx.fbcdn.netQTV1
> 
> after the threeway handshake and an instant reset. ?Anyone know what
> this is? ?Cause I haven't a clue....screenshot of success after
> bypassing included. ?Thank you.
> 
> James
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
I guess I should also say that this is from the official Facebook app
on Android...just updated on Tuesday.
James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/6a46eaa0/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Screenshot from 2016-06-29 19-32-43.png
Type: image/png
Size: 58978 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/6a46eaa0/attachment.png>

From squid3 at treenet.co.nz  Thu Jun 30 13:04:50 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 1 Jul 2016 01:04:50 +1200
Subject: [squid-users] Yet another new cipher?
In-Reply-To: <1467290625.2355.0.camel@slave-tothe-box.net>
References: <1467250436.2485.3.camel@slave-tothe-box.net>
 <1467290625.2355.0.camel@slave-tothe-box.net>
Message-ID: <3a5f6cb9-d5ff-99db-804d-9cac78ca86e9@treenet.co.nz>

On 1/07/2016 12:43 a.m., James Lay wrote:
> On Wed, 2016-06-29 at 19:33 -0600, James Lay wrote:
>> Yugh...starting around 10:00 facebook no longer works via
>> peek/splice.  pcap contents show:
>>
>> 1QTV01...CHLO....SNI.....VERS....scontent.xx.fbcdn.netQTV1
>>
>> after the threeway handshake and an instant reset.  Anyone know what
>> this is?  Cause I haven't a clue....screenshot of success after
>> bypassing included.  Thank you.
>>
> I guess I should also say that this is from the official Facebook app
> on Android...just updated on Tuesday.

FWIW: I identified the last one from your posted wireshark details.
Looking at the "Unknown Ciphers:" list and looking up the hex codes
listed there in the IANA registry.

The details posted so far about this issue tells me nothing except that
FB suddenly stopped working.

Amos


From jlay at slave-tothe-box.net  Thu Jun 30 13:18:54 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Thu, 30 Jun 2016 07:18:54 -0600
Subject: [squid-users] Yet another new cipher?
In-Reply-To: <3a5f6cb9-d5ff-99db-804d-9cac78ca86e9@treenet.co.nz>
References: <1467250436.2485.3.camel@slave-tothe-box.net>
 <1467290625.2355.0.camel@slave-tothe-box.net>
 <3a5f6cb9-d5ff-99db-804d-9cac78ca86e9@treenet.co.nz>
Message-ID: <1467292734.2355.2.camel@slave-tothe-box.net>

On Fri, 2016-07-01 at 01:04 +1200, Amos Jeffries wrote:
> On 1/07/2016 12:43 a.m., James Lay wrote:
> > 
> > On Wed, 2016-06-29 at 19:33 -0600, James Lay wrote:
> > > 
> > > Yugh...starting around 10:00 facebook no longer works via
> > > peek/splice.??pcap contents show:
> > > 
> > > 1QTV01...CHLO....SNI.....VERS....scontent.xx.fbcdn.netQTV1
> > > 
> > > after the threeway handshake and an instant reset.??Anyone know
> > > what
> > > this is???Cause I haven't a clue....screenshot of success after
> > > bypassing included.??Thank you.
> > > 
> > I guess I should also say that this is from the official Facebook
> > app
> > on Android...just updated on Tuesday.
> FWIW: I identified the last one from your posted wireshark details.
> Looking at the "Unknown Ciphers:" list and looking up the hex codes
> listed there in the IANA registry.
> 
> The details posted so far about this issue tells me nothing except
> that
> FB suddenly stopped working.
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
That's fair...I'm including a successful handshake...wireshark just
sees this as data. ?Thanks Amos!
James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/44121d07/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 192.168.1.101-stream5.pcapng
Type: application/x-pcapng
Size: 34000 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/44121d07/attachment.bin>

From marcus.kool at urlfilterdb.com  Thu Jun 30 13:38:28 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Thu, 30 Jun 2016 10:38:28 -0300
Subject: [squid-users] Skype Issues
In-Reply-To: <a6a87272-5864-11b8-9713-1adfee649600@treenet.co.nz>
References: <CAHha_zXLamheKh8J-G8zgPDFDispf7ekWGNykuMH1fa511BD0w@mail.gmail.com>
 <8ff3bffe-47b7-8b0d-148d-cd3254344fd1@treenet.co.nz>
 <a30b3e16-5209-8240-359a-0cf736fe129f@gmail.com>
 <6e208cda-cb22-e48d-c0ee-0a6db04448e0@treenet.co.nz>
 <5153128f-ddd0-c134-22f1-158aa97575b4@gmail.com>
 <CAHha_zUDd__ZyMUCDQDcJ4KQouk++2OoZiEMptHY=Ty08D549A@mail.gmail.com>
 <b3abc44d-7abf-aa9a-ebd3-a775c4a81854@gmail.com>
 <CAHha_zUDWQEFJjWgupS55gibNxSZ=gy--CfvQesYoPv6akciDQ@mail.gmail.com>
 <0b950720-77ad-170d-55d3-295f028dfa92@gmail.com>
 <CAHha_zX+oDsFT7b6qfirB17v0C-iDMq7p1XdLG4z=++6V5_JeA@mail.gmail.com>
 <CAHha_zUZvUf2sBUXuoHdXi=s1CdnRR8YsOTWct1UPTrh4+N3Rw@mail.gmail.com>
 <CAHha_zV5R4CNe+q82=MBS+qKH=fe9UYC5Rm0zj_3CE+FC=zpww@mail.gmail.com>
 <1b2b1219-18f3-1711-0cb0-b8b67a65d19e@gmail.com>
 <a6a87272-5864-11b8-9713-1adfee649600@treenet.co.nz>
Message-ID: <577520D4.8090209@urlfilterdb.com>



On 06/30/2016 09:10 AM, Amos Jeffries wrote:
...
>   The on_unsupported_protocol directive is about what its name says *any*
> unsupported protocol. Not ICQ specific.
>
> I think the issue here is that Skype looks at the binary level like TLS.
> TLS being a supported protocol if it looks close enough then it would be
> seen as invalid/broken TLS, not some non-TLS.

Applications may use any protocol that they desire to tunnel through a proxy.
They may use TLS+SMTP, TLS+HTTP, TLS+XYZ, RC4+FOO, SSH, VPN, BAR, TXT and
many others.
Since bumping is intended to only interfere with TLS+HTTP, Squid should bump
_only_ TLS+HTTP and not interfere with all other protocols.

Squid 3.5 finally made a lot of progress with bumping TLS+HTTP and the
missing piece to be able to use it in many environments is a
mechanism to deal with all other protocols (non TLS+HTTP).
The first step is to not break applications. The second step is
to have mechanisms to decide what to do with the other
protocols, since most admins want to block SSH and VPN,
while allowing Skype and BAR.

Marcus

> Sory Renato, with that not working I'm not sure where to go next.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From jlay at slave-tothe-box.net  Thu Jun 30 14:35:53 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Thu, 30 Jun 2016 08:35:53 -0600
Subject: [squid-users] Yet another new cipher?
In-Reply-To: <1467292734.2355.2.camel@slave-tothe-box.net>
References: <1467250436.2485.3.camel@slave-tothe-box.net>
 <1467290625.2355.0.camel@slave-tothe-box.net>
 <3a5f6cb9-d5ff-99db-804d-9cac78ca86e9@treenet.co.nz>
 <1467292734.2355.2.camel@slave-tothe-box.net>
Message-ID: <5249af8ab561cda0d6b5ac286ef49e20@localhost>

On 2016-06-30 07:18, James Lay wrote:
> On Fri, 2016-07-01 at 01:04 +1200, Amos Jeffries wrote:
> 
>> On 1/07/2016 12:43 a.m., James Lay wrote: On Wed, 2016-06-29 at
>> 19:33 -0600, James Lay wrote: Yugh...starting around 10:00 facebook
>> no longer works via peek/splice. pcap contents show:
>> 1QTV01...CHLO....SNI.....VERS....scontent.xx.fbcdn.netQTV1 after the
>> threeway handshake and an instant reset. Anyone know what this is?
>> Cause I haven't a clue....screenshot of success after bypassing
>> included. Thank you. I guess I should also say that this is from the
>> official Facebook app on Android...just updated on Tuesday.
>  FWIW: I identified the last one from your posted wireshark details.
> Looking at the "Unknown Ciphers:" list and looking up the hex codes
> listed there in the IANA registry. The details posted so far about
> this issue tells me nothing except that FB suddenly stopped working.
> Amos _______________________________________________ squid-users
> mailing list squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users [1]
> 
> That's fair...I'm including a successful handshake...wireshark just
> sees this as data.  Thanks Amos!
> 
> James
> 
> Links:
> ------
> [1] http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


Meh...this is QUIC Crypto:

https://docs.google.com/document/d/1g5nIXAIkN_Y-7XJW5K45IblHd_L2f5LTaDUDwvZ5L6g/edit

James


From ameen.nazar at gmail.com  Thu Jun 30 15:38:32 2016
From: ameen.nazar at gmail.com (Henry7)
Date: Thu, 30 Jun 2016 08:38:32 -0700 (PDT)
Subject: [squid-users] static caching for specific website for specific
	time
In-Reply-To: <1392811888955-4664943.post@n4.nabble.com>
References: <1392811888955-4664943.post@n4.nabble.com>
Message-ID: <1467301112380-4678322.post@n4.nabble.com>

Sometimes a  WiFi Blocker Jammer
<http://www.jammerspro.com/radio-frequency-uhf-vhf-WiFi-jammers.htm>   is
all you need. People are so obnoxious these days. They do whatever they want
without caring about what others feels and that's not good at all. A jammer
can help you to solve the problem and you're good to go. 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/static-caching-for-specific-website-for-specific-time-tp4664943p4678322.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Thu Jun 30 16:27:41 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 30 Jun 2016 18:27:41 +0200
Subject: [squid-users] static caching for specific website for specific
	time
In-Reply-To: <1467301112380-4678322.post@n4.nabble.com>
References: <1392811888955-4664943.post@n4.nabble.com>
 <1467301112380-4678322.post@n4.nabble.com>
Message-ID: <201606301827.41754.Antony.Stone@squid.open.source.it>

On Thursday 30 June 2016 at 17:38:32, Henry7 wrote:

> Sometimes a  WiFi Blocker Jammer
> <http://www.jammerspro.com/radio-frequency-uhf-vhf-WiFi-jammers.htm>   is
> all you need. People are so obnoxious these days. They do whatever they
> want without caring about what others feels and that's not good at all. A
> jammer can help you to solve the problem and you're good to go.

I cannot find the original question which this is a response to.

Please enlighten us to what problem with squid this is a proposed solution 
for?


Thanks,


Antony.

-- 
Users don't know what they want until they see what they get.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From zerbey at gmail.com  Thu Jun 30 17:21:28 2016
From: zerbey at gmail.com (Chris Horry)
Date: Thu, 30 Jun 2016 13:21:28 -0400
Subject: [squid-users] Force DNS queries over TCP?
Message-ID: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>

Hello,

My ISP have started forcing DNS queries to pass through their own DNS
server, which appears to have many issues (can't resolve twitter.com for
one).  I won't bore the list with my conversations with them over that part.

They are not actively blocking TCP DNS queries so I have a workaround.

Recognising that DNS over TCP is not an ideal solution....

1. Can Squid be configured to use TCP by default for DNS inquiries?  If
not consider this a feature request :)
2. Is there a DNS caching server that can do this instead (BIND9 doesn't
seem to have it as an option)

Any help appreciated.

Thanks,

Chris

-- 
Chris Horry
zerbey at gmail.com
http://www.twitter.com/zerbey
PGP:638C3E7A

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/a18cf233/attachment.sig>

From acrow at integrafin.co.uk  Thu Jun 30 17:34:32 2016
From: acrow at integrafin.co.uk (Alex Crow)
Date: Thu, 30 Jun 2016 18:34:32 +0100
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>
References: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>
Message-ID: <57755828.4080401@integrafin.co.uk>

I'd suggest changing IP as this practice is

a) a violation of trust, forcing you to use a potentially compromised
resource you have no control over
b) a clear violation of net-neutrality
c) a violation of standards (as it's probably one of those that instead
of returning NXDOMAIN as required sends you to an advertising page.
)
I'm pretty sure you /can/ configure BIND to work like that. I should
imagine you could set up forwarders to TCP-based DNS servers.

The other option is to get a DNS server set up on a VPS and tunnel your
requests to it via IPSEC.

Alex

On 30/06/16 18:21, Chris Horry wrote:
> Hello,
>
> My ISP have started forcing DNS queries to pass through their own DNS
> server, which appears to have many issues (can't resolve twitter.com for
> one).  I won't bore the list with my conversations with them over that part.
>
> They are not actively blocking TCP DNS queries so I have a workaround.
>
> Recognising that DNS over TCP is not an ideal solution....
>
> 1. Can Squid be configured to use TCP by default for DNS inquiries?  If
> not consider this a feature request :)
> 2. Is there a DNS caching server that can do this instead (BIND9 doesn't
> seem to have it as an option)
>
> Any help appreciated.
>
> Thanks,
>
> Chris
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


--
This message is intended only for the addressee and may contain
confidential information. Unless you are that person, you may not
disclose its contents or use it in any way and are requested to delete
the message along with any attachments and notify us immediately.
This email is not intended to, nor should it be taken to, constitute advice.
The information provided is correct to our knowledge & belief and must not
be used as a substitute for obtaining tax, regulatory, investment, legal or
any other appropriate advice.

"Transact" is operated by Integrated Financial Arrangements Ltd.
29 Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900 Fax: (020) 7608 5300.
(Registered office: as above; Registered in England and Wales under
number: 3727592). Authorised and regulated by the Financial Conduct
Authority (entered on the Financial Services Register; no. 190856).

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/502fe266/attachment.htm>

From zerbey at gmail.com  Thu Jun 30 18:20:53 2016
From: zerbey at gmail.com (Chris Horry)
Date: Thu, 30 Jun 2016 14:20:53 -0400
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <57755828.4080401@integrafin.co.uk>
References: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>
 <57755828.4080401@integrafin.co.uk>
Message-ID: <51177c9c-baeb-eb16-3a52-da9af742bd20@gmail.com>



On 06/30/2016 13:34, Alex Crow wrote:
> I'd suggest changing IP as this practice is
> 
> a) a violation of trust, forcing you to use a potentially compromised
> resource you have no control over
> b) a clear violation of net-neutrality
> c) a violation of standards (as it's probably one of those that instead
> of returning NXDOMAIN as required sends you to an advertising page.
> )

Tell me about it.  My ISP and I are having a pitched battle about it
now.  Unfortunately my options are limited in my current area but at
least it's not Comcast!

> I'm pretty sure you /can/ configure BIND to work like that. I should
> imagine you could set up forwarders to TCP-based DNS servers.
> 
> The other option is to get a DNS server set up on a VPS and tunnel your
> requests to it via IPSEC.

Sounds like a good idea, time to learn IPSEC!

Thanks,

Chris

-- 
Chris Horry
zerbey at gmail.com
http://www.twitter.com/zerbey
PGP:638C3E7A

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/4f375a87/attachment.sig>

From bpk678 at gmail.com  Thu Jun 30 18:40:15 2016
From: bpk678 at gmail.com (brendan kearney)
Date: Thu, 30 Jun 2016 14:40:15 -0400
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <51177c9c-baeb-eb16-3a52-da9af742bd20@gmail.com>
References: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>
 <57755828.4080401@integrafin.co.uk>
 <51177c9c-baeb-eb16-3a52-da9af742bd20@gmail.com>
Message-ID: <CAARxGtg+YGi=aNjJWz5da8vo8xESO5xsLwG85KiyH4C_QWF54g@mail.gmail.com>

Nscd or name server caching daemon may be of help.  I believe you can run
your own bind instqnce and point it at the roots, instead of using your
isp's broken implementation
On Jun 30, 2016 2:21 PM, "Chris Horry" <zerbey at gmail.com> wrote:

>
>
> On 06/30/2016 13:34, Alex Crow wrote:
> > I'd suggest changing IP as this practice is
> >
> > a) a violation of trust, forcing you to use a potentially compromised
> > resource you have no control over
> > b) a clear violation of net-neutrality
> > c) a violation of standards (as it's probably one of those that instead
> > of returning NXDOMAIN as required sends you to an advertising page.
> > )
>
> Tell me about it.  My ISP and I are having a pitched battle about it
> now.  Unfortunately my options are limited in my current area but at
> least it's not Comcast!
>
> > I'm pretty sure you /can/ configure BIND to work like that. I should
> > imagine you could set up forwarders to TCP-based DNS servers.
> >
> > The other option is to get a DNS server set up on a VPS and tunnel your
> > requests to it via IPSEC.
>
> Sounds like a good idea, time to learn IPSEC!
>
> Thanks,
>
> Chris
>
> --
> Chris Horry
> zerbey at gmail.com
> http://www.twitter.com/zerbey
> PGP:638C3E7A
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/efe4e263/attachment.htm>

From acrow at integrafin.co.uk  Thu Jun 30 18:43:05 2016
From: acrow at integrafin.co.uk (Alex Crow)
Date: Thu, 30 Jun 2016 19:43:05 +0100
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <51177c9c-baeb-eb16-3a52-da9af742bd20@gmail.com>
References: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>
 <57755828.4080401@integrafin.co.uk>
 <51177c9c-baeb-eb16-3a52-da9af742bd20@gmail.com>
Message-ID: <57756839.7010404@integrafin.co.uk>

Packt Publishing has a book about FreeSWAN (don't use that) which is
almost all applicable to LibreSWAN (do use this, it's a newer fork).

Easiest is to set up a tunnel with PSKs, more secure is with RSA keys or
X509 certs.

Alex

On 30/06/16 19:20, Chris Horry wrote:
>
> On 06/30/2016 13:34, Alex Crow wrote:
>> I'd suggest changing IP as this practice is
>>
>> a) a violation of trust, forcing you to use a potentially compromised
>> resource you have no control over
>> b) a clear violation of net-neutrality
>> c) a violation of standards (as it's probably one of those that instead
>> of returning NXDOMAIN as required sends you to an advertising page.
>> )
> Tell me about it.  My ISP and I are having a pitched battle about it
> now.  Unfortunately my options are limited in my current area but at
> least it's not Comcast!
>
>> I'm pretty sure you /can/ configure BIND to work like that. I should
>> imagine you could set up forwarders to TCP-based DNS servers.
>>
>> The other option is to get a DNS server set up on a VPS and tunnel your
>> requests to it via IPSEC.
> Sounds like a good idea, time to learn IPSEC!
>
> Thanks,
>
> Chris
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


--
This message is intended only for the addressee and may contain
confidential information. Unless you are that person, you may not
disclose its contents or use it in any way and are requested to delete
the message along with any attachments and notify us immediately.
This email is not intended to, nor should it be taken to, constitute advice.
The information provided is correct to our knowledge & belief and must not
be used as a substitute for obtaining tax, regulatory, investment, legal or
any other appropriate advice.

"Transact" is operated by Integrated Financial Arrangements Ltd.
29 Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900 Fax: (020) 7608 5300.
(Registered office: as above; Registered in England and Wales under
number: 3727592). Authorised and regulated by the Financial Conduct
Authority (entered on the Financial Services Register; no. 190856).

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/54c6bf78/attachment.htm>

From acrow at integrafin.co.uk  Thu Jun 30 18:55:52 2016
From: acrow at integrafin.co.uk (Alex Crow)
Date: Thu, 30 Jun 2016 19:55:52 +0100
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <CAARxGtg+YGi=aNjJWz5da8vo8xESO5xsLwG85KiyH4C_QWF54g@mail.gmail.com>
References: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>
 <57755828.4080401@integrafin.co.uk>
 <51177c9c-baeb-eb16-3a52-da9af742bd20@gmail.com>
 <CAARxGtg+YGi=aNjJWz5da8vo8xESO5xsLwG85KiyH4C_QWF54g@mail.gmail.com>
Message-ID: <57756B38.6050704@integrafin.co.uk>



On 30/06/16 19:40, brendan kearney wrote:
>
> Nscd or name server caching daemon may be of help.  I believe you can
> run your own bind instqnce and point it at the roots, instead of using
> your isp's broken implementation
>
> On Jun 30, 2016 2:21 PM, "Chris Horry" <zerbey at gmail.com
> <mailto:zerbey at gmail.com>> wrote:

If the ISP is intercepting and redirecting all connections to UDP/53,
which seems to be the case, I'm not sure this would help, unless the
roots support TCP access.

Chris, can you confirm this seems to be your ISP's behaviour? If so,
avoiding sending *any* queries in cleartext via UDP/53 is the only way
to do it.

Alex



--
This message is intended only for the addressee and may contain
confidential information. Unless you are that person, you may not
disclose its contents or use it in any way and are requested to delete
the message along with any attachments and notify us immediately.
This email is not intended to, nor should it be taken to, constitute advice.
The information provided is correct to our knowledge & belief and must not
be used as a substitute for obtaining tax, regulatory, investment, legal or
any other appropriate advice.

"Transact" is operated by Integrated Financial Arrangements Ltd.
29 Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900 Fax: (020) 7608 5300.
(Registered office: as above; Registered in England and Wales under
number: 3727592). Authorised and regulated by the Financial Conduct
Authority (entered on the Financial Services Register; no. 190856).
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/e10753c2/attachment.htm>

From zerbey at gmail.com  Thu Jun 30 19:07:00 2016
From: zerbey at gmail.com (Chris Horry)
Date: Thu, 30 Jun 2016 15:07:00 -0400
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <57756B38.6050704@integrafin.co.uk>
References: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>
 <57755828.4080401@integrafin.co.uk>
 <51177c9c-baeb-eb16-3a52-da9af742bd20@gmail.com>
 <CAARxGtg+YGi=aNjJWz5da8vo8xESO5xsLwG85KiyH4C_QWF54g@mail.gmail.com>
 <57756B38.6050704@integrafin.co.uk>
Message-ID: <05aecadf-44b5-f379-933e-d316e1831dd3@gmail.com>



On 06/30/2016 14:55, Alex Crow wrote:
> 
> 
> On 30/06/16 19:40, brendan kearney wrote:
>>
>> Nscd or name server caching daemon may be of help.  I believe you can
>> run your own bind instqnce and point it at the roots, instead of using
>> your isp's broken implementation
>>
>> On Jun 30, 2016 2:21 PM, "Chris Horry" <zerbey at gmail.com
>> <mailto:zerbey at gmail.com>> wrote:
> 
> If the ISP is intercepting and redirecting all connections to UDP/53,
> which seems to be the case, I'm not sure this would help, unless the
> roots support TCP access.
> 
> Chris, can you confirm this seems to be your ISP's behaviour? If so,
> avoiding sending *any* queries in cleartext via UDP/53 is the only way
> to do it.

That is indeed my ISP's behaviour, they force redirect UDP/53 to their
broken implementation so the only option I have is to use TCP.

Chris

-- 
Chris Horry
zerbey at gmail.com
http://www.twitter.com/zerbey
PGP:638C3E7A

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/be41bc61/attachment.sig>

From yvoinov at gmail.com  Thu Jun 30 19:16:53 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 1 Jul 2016 01:16:53 +0600
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <05aecadf-44b5-f379-933e-d316e1831dd3@gmail.com>
References: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>
 <57755828.4080401@integrafin.co.uk>
 <51177c9c-baeb-eb16-3a52-da9af742bd20@gmail.com>
 <CAARxGtg+YGi=aNjJWz5da8vo8xESO5xsLwG85KiyH4C_QWF54g@mail.gmail.com>
 <57756B38.6050704@integrafin.co.uk>
 <05aecadf-44b5-f379-933e-d316e1831dd3@gmail.com>
Message-ID: <2b56fc5c-dea0-88d6-16e5-d3e3676e8d8e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Consider TCP/UDP/53 Cisco interception + Unbound + dnscrypt. And
127.0.0.1:53 as your squid's DNS resolver finally.


01.07.2016 1:07, Chris Horry ?????:
>
>
> On 06/30/2016 14:55, Alex Crow wrote:
>>
>>
>> On 30/06/16 19:40, brendan kearney wrote:
>>>
>>> Nscd or name server caching daemon may be of help.  I believe you can
>>> run your own bind instqnce and point it at the roots, instead of using
>>> your isp's broken implementation
>>>
>>> On Jun 30, 2016 2:21 PM, "Chris Horry" <zerbey at gmail.com
>>> <mailto:zerbey at gmail.com>> wrote:
>>
>> If the ISP is intercepting and redirecting all connections to UDP/53,
>> which seems to be the case, I'm not sure this would help, unless the
>> roots support TCP access.
>>
>> Chris, can you confirm this seems to be your ISP's behaviour? If so,
>> avoiding sending *any* queries in cleartext via UDP/53 is the only way
>> to do it.
>
> That is indeed my ISP's behaviour, they force redirect UDP/53 to their
> broken implementation so the only option I have is to use TCP.
>
> Chris
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdXAkAAoJENNXIZxhPexGYlAH/A8NZGERE0+0i6N3IWQsvR1o
LV9GIrmHZ6fBuMTgYWdul7YUDcUV5OT1kZ6GslbHdG/cfT7EqXDmWEUOy36kdTc6
50sIDLDGgD4XU3J0AFDyKV+yma1kuO8D3ZcE3nYMbSveX/MmdSZkoatIKwVKJkIP
W1DFWFhHICC9Xzxia2t+qnRQ3TpXNnTEQbg2j4uMVbgeeYqOWkjg2VG/RcaxIrk6
AQsXfPzwHC4Dy1GmDSEEEzu2+Q5lfL/IXStLENi9x4izmy+236/5ZOybv3Co6NRG
2EQdOoSeLvz2MgEbrNbHYABDkqt4Pjo7JKjONdAbnEBAAIgNKwW5pUSCBQok5+4=
=paVE
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/d0b6155b/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/d0b6155b/attachment.key>

From emz at norma.perm.ru  Thu Jun 30 19:19:54 2016
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Fri, 1 Jul 2016 00:19:54 +0500
Subject: [squid-users] NOTICE: Authentication not applicable on
 intercepted requests.
In-Reply-To: <3dd5ef30-2cfb-d009-553a-b5a0816dea95@treenet.co.nz>
References: <5774E492.5060002@norma.perm.ru>
 <3dd5ef30-2cfb-d009-553a-b5a0816dea95@treenet.co.nz>
Message-ID: <03d9c77d-8b62-9879-9e1a-fe964ee6c890@norma.perm.ru>

Hi.

On 30.06.2016 17:04, Amos Jeffries wrote:
> On 30/06/2016 9:21 p.m., Eugene M. Zheganin wrote:
>> Hi,
>>
>> Could this message be moved on loglevel 2 instead of 1 ?
>> I think that this message does 95% of the logs of the intercept-enabled
>> caches with authentication.
>>
>> At least some switch would be nice, to switch this off instead of
>> switching the while facility to 0.
> This message only happens when your proxy is misconfigured.
Well, it may be.

> Use a myportname ACL to prevent Squid attempting impossible things like
> authentication on intercepted traffic.

Sorry, but I still didn't get the idea. I have one port that squid is configured to intercept traffic on, and another for plain proxy requests. How do I tell squid not to authenticate anyone on the intercept one ? From what I know, squid will send the authentication sequence as soon as it encounters the authentication-related ACL in the ACL list for the request given. Do have to add myportname ACL with non-intercepting port for all the occurences of the auth-enabled ACLs, or may be there's a simplier way ?

Thanks.
Eugene.



From yvoinov at gmail.com  Thu Jun 30 19:22:06 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 1 Jul 2016 01:22:06 +0600
Subject: [squid-users] NOTICE: Authentication not applicable on
 intercepted requests.
In-Reply-To: <03d9c77d-8b62-9879-9e1a-fe964ee6c890@norma.perm.ru>
References: <5774E492.5060002@norma.perm.ru>
 <3dd5ef30-2cfb-d009-553a-b5a0816dea95@treenet.co.nz>
 <03d9c77d-8b62-9879-9e1a-fe964ee6c890@norma.perm.ru>
Message-ID: <0d98273a-8cc0-1a88-bc87-13fd40acf7b3@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


01.07.2016 1:19, Eugene M. Zheganin ?????:

Interceprion proxy don't support auth. By default. End of discussion.


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdXErAAoJENNXIZxhPexGHuwIAIlMz0C0PIyIQ1iL3eS71M0d
85SHy+iET55da6R2qn8rVtEaoQmBWERyITR7GRhZ6b0OiRz35fh9MKjfCTZVSCW4
fWLqk0Z9ZU2hlUEfeezS22oVWSNqQh6nTnFB/C2yfJTFk9sslC/WGO8xoXr89r5r
lj2Spmg/apP3FvhIqMSVFXIfUtx24ASinL/Xt26y4dsowwfQwO13K/KnJ3kEFJfb
A/YEYlsb809ptTA5ZmL6qJ7MKS+juWo0sruOhmtCOPGJw7eBFjVNG5uOYQB3Mru9
4wq6qr1BbY+kw0f3fvWWuK67ouAUX9P5422Y5ih6l7GXNFCiLCHp4JmfLyOW70I=
=hAVC
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/0eae04ba/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/0eae04ba/attachment.key>

From yvoinov at gmail.com  Thu Jun 30 19:22:05 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 1 Jul 2016 01:22:05 +0600
Subject: [squid-users] NOTICE: Authentication not applicable on
 intercepted requests.
In-Reply-To: <03d9c77d-8b62-9879-9e1a-fe964ee6c890@norma.perm.ru>
References: <5774E492.5060002@norma.perm.ru>
 <3dd5ef30-2cfb-d009-553a-b5a0816dea95@treenet.co.nz>
 <03d9c77d-8b62-9879-9e1a-fe964ee6c890@norma.perm.ru>
Message-ID: <7333e46c-3563-8d8c-c494-eac3c8fa552d@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


01.07.2016 1:19, Eugene M. Zheganin ?????:
> Hi.
>
> On 30.06.2016 17:04, Amos Jeffries wrote:
>> On 30/06/2016 9:21 p.m., Eugene M. Zheganin wrote:
>>> Hi,
>>>
>>> Could this message be moved on loglevel 2 instead of 1 ?
>>> I think that this message does 95% of the logs of the intercept-enabled
>>> caches with authentication.
>>>
>>> At least some switch would be nice, to switch this off instead of
>>> switching the while facility to 0.
>> This message only happens when your proxy is misconfigured.
> Well, it may be.
>
>> Use a myportname ACL to prevent Squid attempting impossible things like
>> authentication on intercepted traffic.
>
> Sorry, but I still didn't get the idea. I have one port that squid is
configured to intercept traffic on, and another for plain proxy
requests. How do I tell squid not to authenticate anyone on the
intercept one ? From what I know, squid will send the authentication
sequence as soon as it encounters the authentication-related ACL in the
ACL list for the request given. Do have to add myportname ACL with
non-intercepting port for all the occurences of the auth-enabled ACLs,
or may be there's a simplier way ?
Interceprion proxy don't support auth. By default. End of discussion.
>
> Thanks.
> Eugene.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdXFcAAoJENNXIZxhPexGq+sIAJdkdtgHjkcO0MfGmXHq7h2p
g/DiEs+DtgMiqS0jxyoMFRhauybi2G2KaBKSAeZE53VLhVXwopTnhoeeOsUT+Khv
6dLyx3Qa4G2JHy1eM3CP0DCzoeFg/jHesPhiNc/3oeiDInjWanEpEC9Y4GJ0Vr87
dYIxox8CzxzHlwH3mOCkq5lB/B3q4OFO3xifDPl94Oby5vGA9yjL6rN/RL4JLaTn
HoTqyPf7vUqOShxjVnd7ZQypzCql9xEiUG1xZboaw2zFuXlkY2kOnb/zrvgXJVS1
xnkx0EMJI+EZNvIKtKpwhFjOZNlSDqkV8pSs//+Sw/oVSd/cXGPuh3EZS0Dh+Vg=
=668p
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/2207e067/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/2207e067/attachment.key>

From jorgeley at gmail.com  Thu Jun 30 19:26:05 2016
From: jorgeley at gmail.com (Jorgeley Junior)
Date: Thu, 30 Jun 2016 16:26:05 -0300
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <2b56fc5c-dea0-88d6-16e5-d3e3676e8d8e@gmail.com>
References: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>
 <57755828.4080401@integrafin.co.uk>
 <51177c9c-baeb-eb16-3a52-da9af742bd20@gmail.com>
 <CAARxGtg+YGi=aNjJWz5da8vo8xESO5xsLwG85KiyH4C_QWF54g@mail.gmail.com>
 <57756B38.6050704@integrafin.co.uk>
 <05aecadf-44b5-f379-933e-d316e1831dd3@gmail.com>
 <2b56fc5c-dea0-88d6-16e5-d3e3676e8d8e@gmail.com>
Message-ID: <CAMeoTHnA23HjyYSfJTxK02qtuNf9-sRK8Am93t9d=d+TqkVsVw@mail.gmail.com>

I'm not sure, but, if your ISP is intercepting your DNS queries, maybe you
could use the mangle netfilter table to change your DNS queries and so
deceive your ISP, but I'm almost sure that the root servers will not
recognize. It was just an idea.

2016-06-30 16:16 GMT-03:00 Yuri Voinov <yvoinov at gmail.com>:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> Consider TCP/UDP/53 Cisco interception + Unbound + dnscrypt. And
> 127.0.0.1:53 as your squid's DNS resolver finally.
>
>
> 01.07.2016 1:07, Chris Horry ?????:
> >
> >
> > On 06/30/2016 14:55, Alex Crow wrote:
> >>
> >>
> >> On 30/06/16 19:40, brendan kearney wrote:
> >>>
> >>> Nscd or name server caching daemon may be of help.  I believe you can
> >>> run your own bind instqnce and point it at the roots, instead of using
> >>> your isp's broken implementation
> >>>
> >>> On Jun 30, 2016 2:21 PM, "Chris Horry" <zerbey at gmail.com
> >>> <mailto:zerbey at gmail.com> <zerbey at gmail.com>> wrote:
> >>
> >> If the ISP is intercepting and redirecting all connections to UDP/53,
> >> which seems to be the case, I'm not sure this would help, unless the
> >> roots support TCP access.
> >>
> >> Chris, can you confirm this seems to be your ISP's behaviour? If so,
> >> avoiding sending *any* queries in cleartext via UDP/53 is the only way
> >> to do it.
> >
> > That is indeed my ISP's behaviour, they force redirect UDP/53 to their
> > broken implementation so the only option I have is to use TCP.
> >
> > Chris
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXdXAkAAoJENNXIZxhPexGYlAH/A8NZGERE0+0i6N3IWQsvR1o
> LV9GIrmHZ6fBuMTgYWdul7YUDcUV5OT1kZ6GslbHdG/cfT7EqXDmWEUOy36kdTc6
> 50sIDLDGgD4XU3J0AFDyKV+yma1kuO8D3ZcE3nYMbSveX/MmdSZkoatIKwVKJkIP
> W1DFWFhHICC9Xzxia2t+qnRQ3TpXNnTEQbg2j4uMVbgeeYqOWkjg2VG/RcaxIrk6
> AQsXfPzwHC4Dy1GmDSEEEzu2+Q5lfL/IXStLENi9x4izmy+236/5ZOybv3Co6NRG
> 2EQdOoSeLvz2MgEbrNbHYABDkqt4Pjo7JKjONdAbnEBAAIgNKwW5pUSCBQok5+4=
> =paVE
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>


--
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/a9d3608d/attachment.htm>

From yvoinov at gmail.com  Thu Jun 30 19:27:49 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 1 Jul 2016 01:27:49 +0600
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <CAMeoTHnA23HjyYSfJTxK02qtuNf9-sRK8Am93t9d=d+TqkVsVw@mail.gmail.com>
References: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>
 <57755828.4080401@integrafin.co.uk>
 <51177c9c-baeb-eb16-3a52-da9af742bd20@gmail.com>
 <CAARxGtg+YGi=aNjJWz5da8vo8xESO5xsLwG85KiyH4C_QWF54g@mail.gmail.com>
 <57756B38.6050704@integrafin.co.uk>
 <05aecadf-44b5-f379-933e-d316e1831dd3@gmail.com>
 <2b56fc5c-dea0-88d6-16e5-d3e3676e8d8e@gmail.com>
 <CAMeoTHnA23HjyYSfJTxK02qtuNf9-sRK8Am93t9d=d+TqkVsVw@mail.gmail.com>
Message-ID: <614a8e53-eb45-5e4a-4041-0f8d6844ecdf@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
This is no f*cking problem. Intercept DNS queries first, resolve it by
DNSCrypt, output for your users. Viola, profit!

01.07.2016 1:26, Jorgeley Junior ?????:
> I'm not sure, but, if your ISP is intercepting your DNS queries, maybe you could use the mangle
netfilter table to change your DNS queries and so deceive your ISP, but
I'm almost sure that the root servers will not recognize. It was just an
idea.
>
> 2016-06-30 16:16 GMT-03:00 Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>>:
>
>
> Consider TCP/UDP/53 Cisco interception + Unbound + dnscrypt. And
127.0.0.1:53 <http://127.0.0.1:53> as your squid's DNS resolver finally.
>
>
> 01.07.2016 1:07, Chris Horry ?????:
>
>
>
>
>       > On 06/30/2016 14:55, Alex Crow wrote:
>
>       >>
>
>       >>
>
>       >> On 30/06/16 19:40, brendan kearney wrote:
>
>       >>>
>
>       >>> Nscd or name server caching daemon may be of help.  I
>       believe you can
>
>       >>> run your own bind instqnce and point it at the roots,
>       instead of using
>
>       >>> your isp's broken implementation
>
>       >>>
>
>       >>> On Jun 30, 2016 2:21 PM, "Chris Horry"
>       <zerbey at gmail.com <mailto:zerbey at gmail.com>
>
>       >>> <mailto:zerbey at gmail.com> <mailto:zerbey at gmail.com>> wrote:
>
>       >>
>
>       >> If the ISP is intercepting and redirecting all
>       connections to UDP/53,
>
>       >> which seems to be the case, I'm not sure this would help,
>       unless the
>
>       >> roots support TCP access.
>
>       >>
>
>       >> Chris, can you confirm this seems to be your ISP's
>       behaviour? If so,
>
>       >> avoiding sending *any* queries in cleartext via UDP/53 is
>       the only way
>
>       >> to do it.
>
>
>
>       > That is indeed my ISP's behaviour, they force redirect UDP/53
>       to their
>
>       > broken implementation so the only option I have is to use
>       TCP.
>
>
>
>       > Chris
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
> --
> *_
> _*
> *_
> _*

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdXK0AAoJENNXIZxhPexG18QIALd3PhGiRehrvqSEVE+x7i29
VNLJzkAgswlKB5HSIkyF1LPwFzJ5hErfdN8gEY/QAyEEi7XbDLN63CzKmMHfuwJY
LxGWEYlWN26eciJtchpA7wM3s1yGDXRO7jnsGPwUV6Ctm5g72Q/Hpyr5Lr5dUZX5
6zdNCKnMlbO//PS943YBJHCAUbl1xxgQwGIowDYjUnEcXhuMBGZXqrErNQfNFAoi
ymoKleAmqOb2BAlvCloo2ZyLIzsoslWxhKktNEnfPb5hBh9XXGRmrRQ3ikSyKXKW
nSbhQlwXbu/GJJQkmuXEvKS/WfaAjDzggBX4j7+4APnmfxQTriVB4VJ3iTEXk3A=
=XMR0
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/cb519258/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/cb519258/attachment.key>

From yvoinov at gmail.com  Thu Jun 30 19:29:04 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 1 Jul 2016 01:29:04 +0600
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <CAMeoTHnA23HjyYSfJTxK02qtuNf9-sRK8Am93t9d=d+TqkVsVw@mail.gmail.com>
References: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>
 <57755828.4080401@integrafin.co.uk>
 <51177c9c-baeb-eb16-3a52-da9af742bd20@gmail.com>
 <CAARxGtg+YGi=aNjJWz5da8vo8xESO5xsLwG85KiyH4C_QWF54g@mail.gmail.com>
 <57756B38.6050704@integrafin.co.uk>
 <05aecadf-44b5-f379-933e-d316e1831dd3@gmail.com>
 <2b56fc5c-dea0-88d6-16e5-d3e3676e8d8e@gmail.com>
 <CAMeoTHnA23HjyYSfJTxK02qtuNf9-sRK8Am93t9d=d+TqkVsVw@mail.gmail.com>
Message-ID: <4436c1c6-7811-3840-343a-2a9dcf64dc62@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Just no forward queries to roots, what's the problem with Unbound?

01.07.2016 1:26, Jorgeley Junior ?????:
> I'm not sure, but, if your ISP is intercepting your DNS queries, maybe you could use the mangle
netfilter table to change your DNS queries and so deceive your ISP, but
I'm almost sure that the root servers will not recognize. It was just an
idea.
>
> 2016-06-30 16:16 GMT-03:00 Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>>:
>
>
> Consider TCP/UDP/53 Cisco interception + Unbound + dnscrypt. And
127.0.0.1:53 <http://127.0.0.1:53> as your squid's DNS resolver finally.
>
>
> 01.07.2016 1:07, Chris Horry ?????:
>
>
>
>
>       > On 06/30/2016 14:55, Alex Crow wrote:
>
>       >>
>
>       >>
>
>       >> On 30/06/16 19:40, brendan kearney wrote:
>
>       >>>
>
>       >>> Nscd or name server caching daemon may be of help.  I
>       believe you can
>
>       >>> run your own bind instqnce and point it at the roots,
>       instead of using
>
>       >>> your isp's broken implementation
>
>       >>>
>
>       >>> On Jun 30, 2016 2:21 PM, "Chris Horry"
>       <zerbey at gmail.com <mailto:zerbey at gmail.com>
>
>       >>> <mailto:zerbey at gmail.com> <mailto:zerbey at gmail.com>> wrote:
>
>       >>
>
>       >> If the ISP is intercepting and redirecting all
>       connections to UDP/53,
>
>       >> which seems to be the case, I'm not sure this would help,
>       unless the
>
>       >> roots support TCP access.
>
>       >>
>
>       >> Chris, can you confirm this seems to be your ISP's
>       behaviour? If so,
>
>       >> avoiding sending *any* queries in cleartext via UDP/53 is
>       the only way
>
>       >> to do it.
>
>
>
>       > That is indeed my ISP's behaviour, they force redirect UDP/53
>       to their
>
>       > broken implementation so the only option I have is to use
>       TCP.
>
>
>
>       > Chris
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
> --
> *_
> _*
> *_
> _*

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdXMAAAoJENNXIZxhPexGzgcH/29x5bFlTT8tVo9Jer1zUehL
RekQo3cTUI7KLPm290rThIYxBsbT91YvffeJADs4cd/jlZJiZjt9HNjX694XKZVj
4goPul66CWHMdT9VkTsRrcIRaAK2eTBE3TRF8cVXv72o0Fv6bofvdVITU4ePe03t
uU6K7Sw2e2FDCjNRCNvrgPxr4/70NUK5QaRWwHEjDWABb2n+j1k9phraUqcD18w5
bWJmQkmfmZLQiDMWekOgsnk1dtNb/bMTqpyf1QccUp3ZDBMWWix0XY/6xQGWsFRw
TTVUpgM1hZMygHfOlUcb2120XRbx3OnrEOYn1rmdso68aGEM/cQ/57ocHXZAIJs=
=6MXo
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/b8b3da3f/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/b8b3da3f/attachment.key>

From yvoinov at gmail.com  Thu Jun 30 19:30:27 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 1 Jul 2016 01:30:27 +0600
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <4436c1c6-7811-3840-343a-2a9dcf64dc62@gmail.com>
References: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>
 <57755828.4080401@integrafin.co.uk>
 <51177c9c-baeb-eb16-3a52-da9af742bd20@gmail.com>
 <CAARxGtg+YGi=aNjJWz5da8vo8xESO5xsLwG85KiyH4C_QWF54g@mail.gmail.com>
 <57756B38.6050704@integrafin.co.uk>
 <05aecadf-44b5-f379-933e-d316e1831dd3@gmail.com>
 <2b56fc5c-dea0-88d6-16e5-d3e3676e8d8e@gmail.com>
 <CAMeoTHnA23HjyYSfJTxK02qtuNf9-sRK8Am93t9d=d+TqkVsVw@mail.gmail.com>
 <4436c1c6-7811-3840-343a-2a9dcf64dc62@gmail.com>
Message-ID: <e5553744-2fc5-9cd0-8e26-cdb731c6327a@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I've google-fu for you:

!
http://serverfault.com/questions/295819/cisco-router-redirect-any-dns-request-to-my-own-dns-server

ip access-list extended transparent_dns
permit udp any any eq 53

route-map redirect_dns permit 10
match ip address transparent_dns
set ip next-hop ip.of.your.server
route-map redirect_dns permit 20

interface fax/x
ip address xxx.xxx.xxx.xxx xxx.xxx.xxx.xxx
ip policy route-map redirect_dns


01.07.2016 1:29, Yuri Voinov ?????:
>
> Just no forward queries to roots, what's the problem with Unbound?
>
> 01.07.2016 1:26, Jorgeley Junior ?????:
> > I'm not sure, but, if your ISP
>       is intercepting your DNS queries, maybe you could use the mangle
>       netfilter table to change your DNS queries and so deceive your
>       ISP, but I'm almost sure that the root servers will not recognize.
>       It was just an idea.
>
>
>
>       > 2016-06-30 16:16 GMT-03:00 Yuri Voinov <yvoinov at gmail.com
>       <mailto:yvoinov at gmail.com>>:
>
>
>
>
>
>       > Consider TCP/UDP/53 Cisco interception + Unbound + dnscrypt.
>       And 127.0.0.1:53 <http://127.0.0.1:53> as your squid's DNS
>       resolver finally.
>
>
>
>
>
>       > 01.07.2016 1:07, Chris Horry ?????:
>
>
>
>
>
>
>
>
>
>       >       > On 06/30/2016 14:55, Alex Crow wrote:
>
>
>
>       >       >>
>
>
>
>       >       >>
>
>
>
>       >       >> On 30/06/16 19:40, brendan kearney wrote:
>
>
>
>       >       >>>
>
>
>
>       >       >>> Nscd or name server caching daemon may be
>       of help.  I
>
>       >       believe you can
>
>
>
>       >       >>> run your own bind instqnce and point it at
>       the roots,
>
>       >       instead of using
>
>
>
>       >       >>> your isp's broken implementation
>
>
>
>       >       >>>
>
>
>
>       >       >>> On Jun 30, 2016 2:21 PM, "Chris Horry"
>
>       >       <zerbey at gmail.com <mailto:zerbey at gmail.com>
>
>
>
>       >       >>> <mailto:zerbey at gmail.com>
>       <mailto:zerbey at gmail.com>> wrote:
>
>
>
>       >       >>
>
>
>
>       >       >> If the ISP is intercepting and redirecting all
>
>       >       connections to UDP/53,
>
>
>
>       >       >> which seems to be the case, I'm not sure this
>       would help,
>
>       >       unless the
>
>
>
>       >       >> roots support TCP access.
>
>
>
>       >       >>
>
>
>
>       >       >> Chris, can you confirm this seems to be your
>       ISP's
>
>       >       behaviour? If so,
>
>
>
>       >       >> avoiding sending *any* queries in cleartext
>       via UDP/53 is
>
>       >       the only way
>
>
>
>       >       >> to do it.
>
>
>
>
>
>
>
>       >       > That is indeed my ISP's behaviour, they force
>       redirect UDP/53
>
>       >       to their
>
>
>
>       >       > broken implementation so the only option I have is
>       to use
>
>       >       TCP.
>
>
>
>
>
>
>
>       >       > Chris
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > _______________________________________________
>
>
>
>       >       > squid-users mailing list
>
>
>
>       >       > squid-users at lists.squid-cache.org
>       <mailto:squid-users at lists.squid-cache.org>
>
>
>
>       >       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>       >     _______________________________________________
>
>       >     squid-users mailing list
>
>       >     squid-users at lists.squid-cache.org
>       <mailto:squid-users at lists.squid-cache.org>
>
>       >     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>
>
>       > --
>
>       > *_
>
>       > _*
>
>       > *_
>
>       > _*
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdXNSAAoJENNXIZxhPexGsAQH/iBYOYkDKok5CHsQsjQ8HLZX
bgm7Lj8Ivcn2oa0jRlh5JAMbqYvzDgBvryPR/9Hz2B1rOggNpdK70W7q3+DLhjRU
TKC7+TlyklLy9TEjGl0ntAXT9s/zetr6Y47FgCOycqxE6jEByZcbnwkch/jnACGz
/qRa1P9nLop7cAXU7Lo1be27tDatYbhBXuhHsyUVKLnmyTRUbC/wtRGtYZ6gsxU1
Clp6sIhM656SVK79cN2JGQCEuECtalGIuJsi5DpmdlUJrizEStc7IfJKznyKVaAs
ATh5VmTCERuzylzSd5rsGOw6wkKwN/zfbuS9DwzUFgLyT2aeJhm7djsJjVNO3I4=
=lZ7H
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/0a035046/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/0a035046/attachment.key>

From zerbey at gmail.com  Thu Jun 30 19:33:04 2016
From: zerbey at gmail.com (Chris Horry)
Date: Thu, 30 Jun 2016 15:33:04 -0400
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <e5553744-2fc5-9cd0-8e26-cdb731c6327a@gmail.com>
References: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>
 <57755828.4080401@integrafin.co.uk>
 <51177c9c-baeb-eb16-3a52-da9af742bd20@gmail.com>
 <CAARxGtg+YGi=aNjJWz5da8vo8xESO5xsLwG85KiyH4C_QWF54g@mail.gmail.com>
 <57756B38.6050704@integrafin.co.uk>
 <05aecadf-44b5-f379-933e-d316e1831dd3@gmail.com>
 <2b56fc5c-dea0-88d6-16e5-d3e3676e8d8e@gmail.com>
 <CAMeoTHnA23HjyYSfJTxK02qtuNf9-sRK8Am93t9d=d+TqkVsVw@mail.gmail.com>
 <4436c1c6-7811-3840-343a-2a9dcf64dc62@gmail.com>
 <e5553744-2fc5-9cd0-8e26-cdb731c6327a@gmail.com>
Message-ID: <cc1eeb87-eb7d-560b-2b9e-2c526caeab37@gmail.com>



On 06/30/2016 15:30, Yuri Voinov wrote:
> 
> I've google-fu for you:
> 
> !
> http://serverfault.com/questions/295819/cisco-router-redirect-any-dns-request-to-my-own-dns-server
> 
> ip access-list extended transparent_dns
> permit udp any any eq 53
> 
> route-map redirect_dns permit 10
> match ip address transparent_dns
> set ip next-hop ip.of.your.server
> route-map redirect_dns permit 20
> 
> interface fax/x
> ip address xxx.xxx.xxx.xxx xxx.xxx.xxx.xxx
> ip policy route-map redirect_dns
> 

I implemented something very similar to this but using SSH (since I
don't have a Cisco router, this is a home setup!).

Chris

-- 
Chris Horry
zerbey at gmail.com
http://www.twitter.com/zerbey
PGP:638C3E7A

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 819 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160630/0fc90494/attachment.sig>

From yvoinov at gmail.com  Thu Jun 30 19:34:31 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 1 Jul 2016 01:34:31 +0600
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <cc1eeb87-eb7d-560b-2b9e-2c526caeab37@gmail.com>
References: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>
 <57755828.4080401@integrafin.co.uk>
 <51177c9c-baeb-eb16-3a52-da9af742bd20@gmail.com>
 <CAARxGtg+YGi=aNjJWz5da8vo8xESO5xsLwG85KiyH4C_QWF54g@mail.gmail.com>
 <57756B38.6050704@integrafin.co.uk>
 <05aecadf-44b5-f379-933e-d316e1831dd3@gmail.com>
 <2b56fc5c-dea0-88d6-16e5-d3e3676e8d8e@gmail.com>
 <CAMeoTHnA23HjyYSfJTxK02qtuNf9-sRK8Am93t9d=d+TqkVsVw@mail.gmail.com>
 <4436c1c6-7811-3840-343a-2a9dcf64dc62@gmail.com>
 <e5553744-2fc5-9cd0-8e26-cdb731c6327a@gmail.com>
 <cc1eeb87-eb7d-560b-2b9e-2c526caeab37@gmail.com>
Message-ID: <6b0caa07-a9a4-7d0d-38f4-812fb088feaa@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
DNScrypt is not required any crypto. it encrypted itself. Just Google-fu
it. :)


01.07.2016 1:33, Chris Horry ?????:
>
>
> On 06/30/2016 15:30, Yuri Voinov wrote:
>>
>> I've google-fu for you:
>>
>> !
>>
http://serverfault.com/questions/295819/cisco-router-redirect-any-dns-request-to-my-own-dns-server
>>
>> ip access-list extended transparent_dns
>> permit udp any any eq 53
>>
>> route-map redirect_dns permit 10
>> match ip address transparent_dns
>> set ip next-hop ip.of.your.server
>> route-map redirect_dns permit 20
>>
>> interface fax/x
>> ip address xxx.xxx.xxx.xxx xxx.xxx.xxx.xxx
>> ip policy route-map redirect_dns
>>
>
> I implemented something very similar to this but using SSH (since I
> don't have a Cisco router, this is a home setup!).
>
> Chris
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdXRGAAoJENNXIZxhPexG4pQH/iQikKeQnzZQVoiafEa0sfAh
Wsnnk3A28QJaofgoL2BbvDY9oDV6K5StIWEu8S/GwJeb+KufcTC5YHNS1DgPFNbp
gvfBD5ARV2nlTM2ZTJJdrneDwEzEu9opqqswb2PRDE8UhNmabyl/M7DDCCM/fckB
zWcsGyalzp2rj8Hn4DKHigfaBN8YzQDjccerhF3Tw2V8IRF6K3ctQpWR26fFwoJt
F8hiRfUH9OsE46l4mNG7SFpHVMZGDJ7t9y+4TK9oHX7CW6+FPlVUZWp+YUnuKXlJ
FFGLXRVTRWxmgFieLNh11uv1tPnrFFBbk0FezvMKbK3tnJz6L7Qn38yRQ7vTpss=
=9XH8
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/384452bb/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/384452bb/attachment.key>

From yvoinov at gmail.com  Thu Jun 30 19:35:33 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 1 Jul 2016 01:35:33 +0600
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <cc1eeb87-eb7d-560b-2b9e-2c526caeab37@gmail.com>
References: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>
 <57755828.4080401@integrafin.co.uk>
 <51177c9c-baeb-eb16-3a52-da9af742bd20@gmail.com>
 <CAARxGtg+YGi=aNjJWz5da8vo8xESO5xsLwG85KiyH4C_QWF54g@mail.gmail.com>
 <57756B38.6050704@integrafin.co.uk>
 <05aecadf-44b5-f379-933e-d316e1831dd3@gmail.com>
 <2b56fc5c-dea0-88d6-16e5-d3e3676e8d8e@gmail.com>
 <CAMeoTHnA23HjyYSfJTxK02qtuNf9-sRK8Am93t9d=d+TqkVsVw@mail.gmail.com>
 <4436c1c6-7811-3840-343a-2a9dcf64dc62@gmail.com>
 <e5553744-2fc5-9cd0-8e26-cdb731c6327a@gmail.com>
 <cc1eeb87-eb7d-560b-2b9e-2c526caeab37@gmail.com>
Message-ID: <81b5e11d-1546-73ac-f0a0-f47e3ca2a5a0@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
PS. Initial level Cisco router cost at eBay is less than 40$. It's a
garbage.


01.07.2016 1:33, Chris Horry ?????:
>
>
> On 06/30/2016 15:30, Yuri Voinov wrote:
>>
>> I've google-fu for you:
>>
>> !
>>
http://serverfault.com/questions/295819/cisco-router-redirect-any-dns-request-to-my-own-dns-server
>>
>> ip access-list extended transparent_dns
>> permit udp any any eq 53
>>
>> route-map redirect_dns permit 10
>> match ip address transparent_dns
>> set ip next-hop ip.of.your.server
>> route-map redirect_dns permit 20
>>
>> interface fax/x
>> ip address xxx.xxx.xxx.xxx xxx.xxx.xxx.xxx
>> ip policy route-map redirect_dns
>>
>
> I implemented something very similar to this but using SSH (since I
> don't have a Cisco router, this is a home setup!).
>
> Chris
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdXSFAAoJENNXIZxhPexGYvsIALYc+IjGOcxdRIjfACXHOj9l
JozmL/VQGjpfDkvEWB+OVhhEB+DgfM5/1BlUQ4ZlVaUtSdRiXvstrN5Us+PtP7lq
vX2aEs/8GX9LZQMcYMZiqFhaHe71gNOoDSsUx2cqiV2L2T45XzIx9DK8QbXxKuut
BNPIrqlMpUtpNf647IGsJ3WFWzpwULy1AnnluSm57CZqNQb469PDhwjTAkpoh17X
I0DU78LAOmAidlE8KS2NuEDp314O3n95pil9PL39Fc+ZbSUjnRQv1Tt+eQm/BlC8
De559O44QApg3hQqQtX36ATZqWgeHzXe/5l8SSveRkc5vt8KayIoy81obNADBKg=
=ya8i
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/6c40d860/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/6c40d860/attachment.key>

From yvoinov at gmail.com  Thu Jun 30 19:37:38 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 1 Jul 2016 01:37:38 +0600
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <81b5e11d-1546-73ac-f0a0-f47e3ca2a5a0@gmail.com>
References: <07807287-64ab-50f8-1f2d-65fa7a823883@gmail.com>
 <57755828.4080401@integrafin.co.uk>
 <51177c9c-baeb-eb16-3a52-da9af742bd20@gmail.com>
 <CAARxGtg+YGi=aNjJWz5da8vo8xESO5xsLwG85KiyH4C_QWF54g@mail.gmail.com>
 <57756B38.6050704@integrafin.co.uk>
 <05aecadf-44b5-f379-933e-d316e1831dd3@gmail.com>
 <2b56fc5c-dea0-88d6-16e5-d3e3676e8d8e@gmail.com>
 <CAMeoTHnA23HjyYSfJTxK02qtuNf9-sRK8Am93t9d=d+TqkVsVw@mail.gmail.com>
 <4436c1c6-7811-3840-343a-2a9dcf64dc62@gmail.com>
 <e5553744-2fc5-9cd0-8e26-cdb731c6327a@gmail.com>
 <cc1eeb87-eb7d-560b-2b9e-2c526caeab37@gmail.com>
 <81b5e11d-1546-73ac-f0a0-f47e3ca2a5a0@gmail.com>
Message-ID: <82e2d52f-0fb8-b3c7-9f83-ded1b82edb24@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I'm wrong. 11,50$
http://www.ebay.com/itm/Cisco-1800-Series-1841-Router-With-64MB-Flash-Card-w-Power-Cord-/142035497145

01.07.2016 1:35, Yuri Voinov ?????:
>
> PS. Initial level Cisco router cost at eBay is less than 40$. It's a
garbage.
>
>
> 01.07.2016 1:33, Chris Horry ?????:
>
>
>
>
>       > On 06/30/2016 15:30, Yuri Voinov wrote:
>
>       >>
>
>       >> I've google-fu for you:
>
>       >>
>
>       >> !
>
>       >>
>
http://serverfault.com/questions/295819/cisco-router-redirect-any-dns-request-to-my-own-dns-server
>
>       >>
>
>       >> ip access-list extended transparent_dns
>
>       >> permit udp any any eq 53
>
>       >>
>
>       >> route-map redirect_dns permit 10
>
>       >> match ip address transparent_dns
>
>       >> set ip next-hop ip.of.your.server
>
>       >> route-map redirect_dns permit 20
>
>       >>
>
>       >> interface fax/x
>
>       >> ip address xxx.xxx.xxx.xxx xxx.xxx.xxx.xxx
>
>       >> ip policy route-map redirect_dns
>
>       >>
>
>
>
>       > I implemented something very similar to this but using SSH
>       (since I
>
>       > don't have a Cisco router, this is a home setup!).
>
>
>
>       > Chris
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdXUBAAoJENNXIZxhPexGtDcH/3ooFSdpZnSnkp6OtQPs48Bm
enKgEazSDkBR84VymCTcRsMRz3z0v2yc3qT6S1ebOxzhDAFuHna6T229eNdiOKxS
G+dBW6ZX7dpQbyAE+N6F7+BUWy/ZIEqzFwEiBLE4FMzTaNoaIEZQc1w50UJfBrOH
SRZaT5t54JvYL/PJ4v+z1vAYzvAeAi88mUmcEzB2oGu1hDEEhBad2AMKZZXC8wMG
pjOFTV7TgEcGGFWnbKoMHl3r0DxhJ2YVVIw+qHC7OSG8fl8KJEhZx1aX00PMO2WW
3fihokSU9Fw7eERVJc3rlTe8ZF/RTgU3AUCoovm6AnePPbmXQzyKDVwIpIGRifo=
=gNk+
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/4bf99c8f/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/4bf99c8f/attachment.key>

From augustus_meyer at gmx.net  Thu Jun 30 20:05:40 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Thu, 30 Jun 2016 13:05:40 -0700 (PDT)
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <82e2d52f-0fb8-b3c7-9f83-ded1b82edb24@gmail.com>
References: <CAARxGtg+YGi=aNjJWz5da8vo8xESO5xsLwG85KiyH4C_QWF54g@mail.gmail.com>
 <57756B38.6050704@integrafin.co.uk>
 <05aecadf-44b5-f379-933e-d316e1831dd3@gmail.com>
 <2b56fc5c-dea0-88d6-16e5-d3e3676e8d8e@gmail.com>
 <CAMeoTHnA23HjyYSfJTxK02qtuNf9-sRK8Am93t9d=d+TqkVsVw@mail.gmail.com>
 <4436c1c6-7811-3840-343a-2a9dcf64dc62@gmail.com>
 <e5553744-2fc5-9cd0-8e26-cdb731c6327a@gmail.com>
 <cc1eeb87-eb7d-560b-2b9e-2c526caeab37@gmail.com>
 <81b5e11d-1546-73ac-f0a0-f47e3ca2a5a0@gmail.com>
 <82e2d52f-0fb8-b3c7-9f83-ded1b82edb24@gmail.com>
Message-ID: <1467317140741-4678343.post@n4.nabble.com>

There is no need for cisco stuff. 
dnscrypt-proxy+dnsmasq, for example, to be used + one of the many open
dnscrypt servers form this list:
https://github.com/jedisct1/dnscrypt-proxy/blob/master/dnscrypt-resolvers.csv

In principle, run dnsmasq on your squid box, and use dnscrypt-proxy to
connect dnsmasq to upstream open dnscrypt-enabled dns-server fom list above.
Make sure, squid uses this local dnsmasq as dns server. 
Finally, use iptables to redirect all dns-requsts from clients to your
dnsmasq. 








--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Force-DNS-queries-over-TCP-tp4678324p4678343.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Thu Jun 30 20:52:05 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 1 Jul 2016 02:52:05 +0600
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <1467317140741-4678343.post@n4.nabble.com>
References: <CAARxGtg+YGi=aNjJWz5da8vo8xESO5xsLwG85KiyH4C_QWF54g@mail.gmail.com>
 <57756B38.6050704@integrafin.co.uk>
 <05aecadf-44b5-f379-933e-d316e1831dd3@gmail.com>
 <2b56fc5c-dea0-88d6-16e5-d3e3676e8d8e@gmail.com>
 <CAMeoTHnA23HjyYSfJTxK02qtuNf9-sRK8Am93t9d=d+TqkVsVw@mail.gmail.com>
 <4436c1c6-7811-3840-343a-2a9dcf64dc62@gmail.com>
 <e5553744-2fc5-9cd0-8e26-cdb731c6327a@gmail.com>
 <cc1eeb87-eb7d-560b-2b9e-2c526caeab37@gmail.com>
 <81b5e11d-1546-73ac-f0a0-f47e3ca2a5a0@gmail.com>
 <82e2d52f-0fb8-b3c7-9f83-ded1b82edb24@gmail.com>
 <1467317140741-4678343.post@n4.nabble.com>
Message-ID: <84105512-1ab0-3cfb-b52c-f0fe208a8354@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
IDK when user is only one :) There is no Cisco required :)


01.07.2016 2:05, reinerotto ?????:
> There is no need for cisco stuff.
> dnscrypt-proxy+dnsmasq, for example, to be used + one of the many open
> dnscrypt servers form this list:
>
https://github.com/jedisct1/dnscrypt-proxy/blob/master/dnscrypt-resolvers.csv
>
> In principle, run dnsmasq on your squid box, and use dnscrypt-proxy to
> connect dnsmasq to upstream open dnscrypt-enabled dns-server fom list
above.
> Make sure, squid uses this local dnsmasq as dns server.
> Finally, use iptables to redirect all dns-requsts from clients to your
> dnsmasq.
>
>
>
>
>
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Force-DNS-queries-over-TCP-tp4678324p4678343.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdYZ1AAoJENNXIZxhPexGBpQIAM2Bc+6spxFL4ROPBxXFYYCv
7jpTfRXJkzZtqRxMPpCBWN2/zuV8Xhwaf30O2pS0B6WhnY9usblpazScnER3NYF2
zBy7W4OOmKiaeOO3aEV7AgK/zmaxqZ8nSWt+rGCpvs+8Af2kxFpmn5vfI/pj9wiJ
jIckvxMUANqtjPIfDsc0+Xs1qw297xada40TMB3YqozeZmTYSzobSm9fCTreeVwY
3+SF+vhTY+BGJhb6CgyY3quyoWMdfJ9T8GU5k0kIF1JPSc/yArHjAt2Qj/xkcRSC
BYyJPPoRf92cF7bLi9TZt5idAVwmXHhi4z6EsKdEtMcaAb+SbzxFuPFzgqKBKGE=
=3wyd
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/29eed0dc/attachment.key>

From yvoinov at gmail.com  Thu Jun 30 20:56:07 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 1 Jul 2016 02:56:07 +0600
Subject: [squid-users] Force DNS queries over TCP?
In-Reply-To: <84105512-1ab0-3cfb-b52c-f0fe208a8354@gmail.com>
References: <CAARxGtg+YGi=aNjJWz5da8vo8xESO5xsLwG85KiyH4C_QWF54g@mail.gmail.com>
 <57756B38.6050704@integrafin.co.uk>
 <05aecadf-44b5-f379-933e-d316e1831dd3@gmail.com>
 <2b56fc5c-dea0-88d6-16e5-d3e3676e8d8e@gmail.com>
 <CAMeoTHnA23HjyYSfJTxK02qtuNf9-sRK8Am93t9d=d+TqkVsVw@mail.gmail.com>
 <4436c1c6-7811-3840-343a-2a9dcf64dc62@gmail.com>
 <e5553744-2fc5-9cd0-8e26-cdb731c6327a@gmail.com>
 <cc1eeb87-eb7d-560b-2b9e-2c526caeab37@gmail.com>
 <81b5e11d-1546-73ac-f0a0-f47e3ca2a5a0@gmail.com>
 <82e2d52f-0fb8-b3c7-9f83-ded1b82edb24@gmail.com>
 <1467317140741-4678343.post@n4.nabble.com>
 <84105512-1ab0-3cfb-b52c-f0fe208a8354@gmail.com>
Message-ID: <8e939bfe-8d2b-a866-28f2-9822de72fb8a@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Just fantasy required :) :) :)
And Google-fu :)

01.07.2016 2:52, Yuri Voinov ?????:
>
> IDK when user is only one :) There is no Cisco required :)
>
>
> 01.07.2016 2:05, reinerotto ?????:
> > There is no need for cisco stuff.
> > dnscrypt-proxy+dnsmasq, for example, to be used + one of the many open
> > dnscrypt servers form this list:
>
>
https://github.com/jedisct1/dnscrypt-proxy/blob/master/dnscrypt-resolvers.csv
>
> > In principle, run dnsmasq on your squid box, and use dnscrypt-proxy to
> > connect dnsmasq to upstream open dnscrypt-enabled dns-server fom list
> above.
> > Make sure, squid uses this local dnsmasq as dns server.
> > Finally, use iptables to redirect all dns-requsts from clients to your
> > dnsmasq.
>
>
>
>
>
>
>
>
> > --
> > View this message in context:
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Force-DNS-queries-over-TCP-tp4678324p4678343.html
> > Sent from the Squid - Users mailing list archive at Nabble.com.
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXdYdmAAoJENNXIZxhPexGb/YH/2AGFrKlobnL7fVQRBRDmwA2
wCuByAha0RjVEKGPvZoiC741GeFVKMXhqNTwsiAsCH1xXjHDdlMekA595ofdonPP
KYdJByCuCqKOaPXLWcJkfmc+KpcTO7rHcq1Lm5yyZG6Y76TjpRqa1uFFwigrk9Tb
sCrrHZDL4C0+x1V+zPQMP0apf6fLiuWwv+nFzF59yzUNpJUYMRXk52Y2q/AqaQS0
r5Pc3oUcGWV0BUYU41HfAgn3MfYnjY9hGsqolwi0YlGjrXAjBFyIwi+1rJgtz1JA
fzyq4GwNfWLhC5NNoYOCmXoEdLmXTwykYXWjl3rDV+vPZ5AXNjgG1oOZIfBtRQw=
=Biv4
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/62aebcbe/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160701/62aebcbe/attachment.key>

