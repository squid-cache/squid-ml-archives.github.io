<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] Vary object loop returns
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20Vary%20object%20loop%20returns&In-Reply-To=%3Cd583f35d-98a6-14b6-976f-a9b0909f48ad%40cinbesa.com.br%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="010943.html">
   <LINK REL="Next"  HREF="010949.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] Vary object loop returns</H1>
    <B>Heiler Bemerguy</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20Vary%20object%20loop%20returns&In-Reply-To=%3Cd583f35d-98a6-14b6-976f-a9b0909f48ad%40cinbesa.com.br%3E"
       TITLE="[squid-users] Vary object loop returns">heiler.bemerguy at cinbesa.com.br
       </A><BR>
    <I>Tue Jun  7 20:21:08 UTC 2016</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="010943.html">[squid-users] Vary object loop returns
</A></li>
        <LI>Next message (by thread): <A HREF="010949.html">[squid-users] Vary object loop returns
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#10948">[ date ]</a>
              <a href="thread.html#10948">[ thread ]</a>
              <a href="subject.html#10948">[ subject ]</a>
              <a href="author.html#10948">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>
Some servers will reply like this, trying to avoid caching at any cost 
(I think):

HTTP/1.1 200 OK
Server: nginx
Content-Type: image/x-icon
Last-Modified: Tue, 07 Jun 2016 11:16:55 GMT
ETag: &quot;5756ad27-47e&quot;
Content-Length: 1150
X-Suppressed-Cache-Control: max-age=600
Cache-Control: private, max-age=0, must-revalidate
X-Suppressed-Expires: Tue, 07 Jun 2016 20:07:36 GMT
Expires: Thu, 01 Jan 1970 00:00:00 GMT
Date: Tue, 07 Jun 2016 19:57:36 GMT
X-Varnish: 510207311
*Vary: 
Accept,If-None-Match,If-Modified-Since,Accept-Language,Accept-Encoding,X-Client-Locale,User-Agent,X-Device*

Then our squid will create a vary object with all that information, 
giving this bomb: httpMakeVaryMark: 
accept=&quot;image%2Fpng,image%2F*%3Bq%3D0.8,*%2F*%3Bq%3D0.5&quot;, 
if-none-match=&quot;%225756ad27-47e%22&quot;, if-modified-since, 
accept-language=&quot;en-US,en%3Bq%3D0.8,pt-BR%3Bq%3D0.5,pt%3Bq%3D0.3&quot;, 
accept-encoding=&quot;none&quot;, x-client-locale, 
user-agent=&quot;Mozilla%2F5.0%20(Windows%20NT%2010.0%3B%20WOW64%3B%20rv%3A46.0)%20Gecko%2F20100101%20Firefox%2F46.0&quot;, 
x-device

It's squid &quot;fault&quot; to convert spaces and symbols to %values, and I think 
no sanity check is performed on it.. still, I don't see the code where 
it checks if all this info from the new client is identical to the 
stored one.. and I don't know where the &quot;loop&quot; comes from...

Now I think I'm confused... lol


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751


Em 07/06/2016 08:59, Yuri Voinov escreveu:
&gt;<i> -----BEGIN PGP SIGNED MESSAGE-----
</I>&gt;<i> Hash: SHA256
</I>&gt;<i>   
</I>&gt;<i> I want to give one example on the topic.
</I>&gt;<i>
</I>&gt;<i> Here is from one of my cache:
</I>&gt;<i>
</I>&gt;<i> /data/cache/d2/00/02/000004C3   0   102502
</I>&gt;<i> <A HREF="http://www.openoffice.org/favicon.ico">http://www.openoffice.org/favicon.ico</A>
</I>&gt;<i> /data/cache/d2/00/01/0000031D   0   161421
</I>&gt;<i> <A HREF="http://rgho.st.squidinternal/favicon.ico">http://rgho.st.squidinternal/favicon.ico</A>
</I>&gt;<i> /data/cache/d1/00/2E/00005C04   0    33274
</I>&gt;<i> <A HREF="http://www.tcpiputils.com/favicon.ico">http://www.tcpiputils.com/favicon.ico</A>
</I>&gt;<i>
</I>&gt;<i> Just take a look on file sizes. This is only favicon. 100 kbytes for
</I>&gt;<i> favicon only! (on Microsoft I've seen 470 kbytes favicon once upon time).
</I>&gt;<i>
</I>&gt;<i> When we take a look into access.log, we often see several URL's for favicon:
</I>&gt;<i>
</I>&gt;<i> <A HREF="http://www.somesite.com/favicon.ico?v=1.44&amp;id=41324134abcd123123123">http://www.somesite.com/favicon.ico?v=1.44&amp;id=41324134abcd123123123</A>
</I>&gt;<i>
</I>&gt;<i> Good site, isn't it? Loading 100 kbytes every time every client surf any
</I>&gt;<i> site page.
</I>&gt;<i>
</I>&gt;<i> When I was doing research, it became clear that, in most cases, these
</I>&gt;<i> same favicon were one and the same content. As an example, a client with
</I>&gt;<i> a smartphone like to download 100 kB - and this is only a small portion
</I>&gt;<i> of the page! - everytime?
</I>&gt;<i>
</I>&gt;<i> 100 kb of mobile data traffic in most countries of the world - decent money.
</I>&gt;<i>
</I>&gt;<i> Yes, usually from the client browser cache.
</I>&gt;<i>
</I>&gt;<i> What about the number of clients and the access point, which pays
</I>&gt;<i> terabytes non-peering traffic?
</I>&gt;<i>
</I>&gt;<i> The same tricks I've seen with a user-agent. With Vary.
</I>&gt;<i>
</I>&gt;<i> 07.06.2016 16:36, Amos Jeffries &#1087;&#1080;&#1096;&#1077;&#1090;:
</I>&gt;&gt;<i> On 7/06/2016 8:48 p.m., Yuri Voinov wrote:
</I>&gt;&gt;&gt;<i> 07.06.2016 4:57, Amos Jeffries &#1087;&#1080;&#1096;&#1077;&#1090;:
</I>&gt;&gt;&gt;&gt;<i> On 7/06/2016 5:55 a.m., Yuri Voinov wrote:
</I>&gt;&gt;&gt;&gt;&gt;<i> So.
</I>&gt;&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;&gt;<i> Squid DOES NOT and DON'T BE support gzip. The only way to do it - use
</I>&gt;&gt;&gt;&gt;&gt;<i> ecap + desupported ecap gzip adapter. Let's accept this. We can support
</I>&gt;&gt;&gt;&gt;&gt;<i> gzip. With restrictions. Ok.
</I>&gt;&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;&gt;<i> any other compression - false. No. No way. Get out. and so on.
</I>&gt;&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;&gt;<i>   identity - this is uncompressed type.
</I>&gt;&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;&gt;<i> That's all, folks.
</I>&gt;&gt;&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;&gt;<i> Finally. As Joe does, we can remain only gzip and identity in
</I>&gt;&gt;&gt;&gt;&gt;<i> Accept-Encoding and truncate all remaining.
</I>&gt;&gt;&gt;&gt;<i> Locking the entire Internet to using your personal choice of gzip
</I>&gt;&gt;&gt;&gt;<i> compression or none.
</I>&gt;&gt;&gt;&gt;<i> gzip is the slowest and more resource hungry type of compression there
</I>&gt;&gt;&gt;&gt;<i> is. deflate is actually faster for clients and just as widely supported.
</I>&gt;&gt;&gt;<i> Unfortunately, Amos, no one has written any other compression algorithms
</I>&gt;&gt;&gt;<i> support module. We have to eat what they give.
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;<i> Like I said deflate is widely available. Heiler's recent info shows that
</I>&gt;&gt;<i> lzma is becomming more visible on the public web, which should help fix
</I>&gt;&gt;<i> the one issue deflate has.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> And noone appears to be fixing the remaining issues in the Squid gzip
</I>&gt;&gt;<i> eCAP module.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> There also seems to be a big push back from browser and some server
</I>&gt;&gt;<i> vendors about compression in general. We had a fairly major fight in
</I>&gt;&gt;<i> IETF to get HTTP/2 to contain data compression at all. It is still only
</I>&gt;&gt;<i> in there as an optional extension that some are openly refusing to
</I>&gt;&gt;<i> implement.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;&gt;<i> Without any problem. Moreover, this type of can be push to all brunches
</I>&gt;&gt;&gt;&gt;&gt;<i> of squid without any problem, because of this dramatically increases
</I>&gt;&gt;&gt;&gt;&gt;<i> byte HIT.
</I>&gt;&gt;&gt;&gt;<i> Responding with a single object to all requests makes your HIT ratio
</I>&gt;&gt;&gt;&gt;<i> 100% guaranteed. The clients wont like you though if all they ever see
</I>&gt;&gt;&gt;&gt;<i> is the same cat picture.
</I>&gt;&gt;&gt;&gt;<i> It sounds ridiculous when put that way, but that is what these patches
</I>&gt;&gt;&gt;&gt;<i> are doing for a unknown number of those &quot;gained&quot; HITs. See my previous
</I>&gt;&gt;&gt;&gt;<i> post about how none of these patches are changing the request the server
</I>&gt;&gt;&gt;&gt;<i> gets.
</I>&gt;&gt;&gt;<i> But no one asked the question - why Squid in production installations
</I>&gt;&gt;&gt;<i> has such a low hit ratio
</I>&gt;&gt;<i> Yes that has been asked, even investigated. The reason(s) are many
</I>&gt;&gt;<i> complex details and small issues adding together to a big loss.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> They range from protocol things like Vary not being fine-grained enough
</I>&gt;&gt;<i> (Key header being developed fixes that), through to client behaviour
</I>&gt;&gt;<i> (Chrome sdch doubles the variant count - almost halving useful cache
</I>&gt;&gt;<i> space), to server behaviour (Apache changing Vary header).
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> What your testing of joes patches is showing is that the sdch effect
</I>&gt;&gt;<i> Chrome has is probably way bigger than one would expect to be reasonable.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;&gt;<i> that raises the question of expediency of
</I>&gt;&gt;&gt;<i> application caching proxy. We do believe that this is a caching proxy?
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;<i>
</I>&gt;&gt;&gt;&gt;<i> You are once again sweeping asside the critical requirement of content
</I>&gt;&gt;&gt;&gt;<i> integrity to achieve high HIT ratio. Which is not something that I can
</I>&gt;&gt;&gt;&gt;<i> accept into Squid as a default action.
</I>&gt;&gt;&gt;<i> I continue to believe that 20% is unacceptably low cache hit ratio,
</I>&gt;&gt;&gt;<i> given the very aggressive settings and the active use of Store ID. Which
</I>&gt;&gt;&gt;<i> brings us back to the idea of the feasibility of using the SQUID as a
</I>&gt;<i> whole.
</I>&gt;&gt;<i> That kind of &quot;unacceptable&quot; statement simply cannot be made about cache
</I>&gt;&gt;<i> HIT ratio. It is what it is. One cannot change the speed of light
</I>&gt;&gt;<i> because it takes unacceptable long to travel through space.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Two properly working caches in serial will have extremely different
</I>&gt;&gt;<i> caching ratios. The one with most direct client connections trends
</I>&gt;&gt;<i> towards 50-100% and the upstream one towards the servers will trend
</I>&gt;&gt;<i> towards zero. The total cacheable ratio is unchanged, but each cache
</I>&gt;&gt;<i> sees a different proportion of it and so shows different HIT ratios
</I>&gt;&gt;<i> relative to their clients portion.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Also, don't forget that browser cache disk space available are
</I>&gt;&gt;<i> increasingly large as well. So their caches are growing in size and
</I>&gt;&gt;<i> taking up a larger share of the total achievable HIT ratios in recent
</I>&gt;<i> years.
</I>&gt;&gt;<i> Amos
</I>&gt;&gt;<i> _______________________________________________
</I>&gt;&gt;<i> squid-users mailing list
</I>&gt;&gt;<i> <A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid-users at lists.squid-cache.org</A>
</I>&gt;&gt;<i> <A HREF="http://lists.squid-cache.org/listinfo/squid-users">http://lists.squid-cache.org/listinfo/squid-users</A>
</I>&gt;<i> -----BEGIN PGP SIGNATURE-----
</I>&gt;<i> Version: GnuPG v2
</I>&gt;<i>   
</I>&gt;<i> iQEcBAEBCAAGBQJXVrctAAoJENNXIZxhPexGl8gIALRSaB3nC6fUjKM8GGL+ep3m
</I>&gt;<i> NZganwbvtkLLLDHQFuTA3K9gvl/GWieQ/3jj+Pp45kgNIeVNsbwYF6IANOT1/olc
</I>&gt;<i> XIGpHK0LICSeTA5kpSHU6hkdfao6AWSUFLci5WXl/Ay7qvzWI4h/NqPhyhoaJUSq
</I>&gt;<i> LTmOePc98oALu4oZpmdmKy1D5yduLmjDy8cbIJTRc/SVha5tt4Sre7z8dI9geX9L
</I>&gt;<i> PlrXBxbtH+oGAYu5qiuifQR9UZCoYL0wL30KzWLyIqmZJdT/NIshIRA1wHVdy9lL
</I>&gt;<i> d0CNwheIPTvstnx8uKOMk4vN/Z5y+A6LnTHHoJgfRCyNwD1IayoPRY1CJffWVRk=
</I>&gt;<i> =40f2
</I>&gt;<i> -----END PGP SIGNATURE-----
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i>
</I>&gt;<i> _______________________________________________
</I>&gt;<i> squid-users mailing list
</I>&gt;<i> <A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid-users at lists.squid-cache.org</A>
</I>&gt;<i> <A HREF="http://lists.squid-cache.org/listinfo/squid-users">http://lists.squid-cache.org/listinfo/squid-users</A>
</I>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: &lt;<A HREF="http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/b552af57/attachment.htm">http://lists.squid-cache.org/pipermail/squid-users/attachments/20160607/b552af57/attachment.htm</A>&gt;
</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="010943.html">[squid-users] Vary object loop returns
</A></li>
	<LI>Next message (by thread): <A HREF="010949.html">[squid-users] Vary object loop returns
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#10948">[ date ]</a>
              <a href="thread.html#10948">[ thread ]</a>
              <a href="subject.html#10948">[ subject ]</a>
              <a href="author.html#10948">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
