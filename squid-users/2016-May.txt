From uhlar at fantomas.sk  Sun May  1 07:42:26 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sun, 1 May 2016 09:42:26 +0200
Subject: [squid-users] runing squid on second processor
In-Reply-To: <1462025121146-4677315.post@n4.nabble.com>
References: <1461968276793-4677313.post@n4.nabble.com>
 <20160430140810.GB18421@fantomas.sk>
 <1462025121146-4677315.post@n4.nabble.com>
Message-ID: <20160501074226.GB6392@fantomas.sk>

On 30.04.16 07:05, joe wrote:
>i have it running  tks
>cause every time i run Calamaris Log first cpu get hi 100% and squid work
>slow until the calamaris finish
>so i moved squid to use second processor now its OK not affected by that or
>anything else
>running nice now

the OS should distribute all processes across processors, unless you force
it handle processes differently.

With 8 cores calamaris should not slow down squid much, unless it uses many
threads (or processes) in parallel.

Lowering calamaris' priority or reducing the number of thrads/processes
should have the same result.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Fucking windows! Bring Bill Gates! (Southpark the movie)


From yvoinov at gmail.com  Sun May  1 11:37:05 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 1 May 2016 17:37:05 +0600
Subject: [squid-users] runing squid on second processor
In-Reply-To: <20160501074226.GB6392@fantomas.sk>
References: <1461968276793-4677313.post@n4.nabble.com>
 <20160430140810.GB18421@fantomas.sk>
 <1462025121146-4677315.post@n4.nabble.com>
 <20160501074226.GB6392@fantomas.sk>
Message-ID: <738d1511-41e0-2a41-b2c6-8d30b591cbb5@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I do admit I do not understand how ?alamaris may slow Squid. My
Calamaris runs once a day, at night, I do not see any significant load
on the server with four cores. No, of course, if it is run with each
rotation of the log, every hour, on the highly active proxy - it may be,
but it is can be solved by scheduler settings or process affinity, if
you want.

But I think it is better to give the operating system. Or, finally, to
refactor Calamaris code to make it more efficient and less devouring CPU
cycles.


01.05.16 13:42, Matus UHLAR - fantomas ?????:
> On 30.04.16 07:05, joe wrote:
>> i have it running  tks
>> cause every time i run Calamaris Log first cpu get hi 100% and squid work
>> slow until the calamaris finish
>> so i moved squid to use second processor now its OK not affected by
that or
>> anything else
>> running nice now
>
> the OS should distribute all processes across processors, unless you force
> it handle processes differently.
>
> With 8 cores calamaris should not slow down squid much, unless it uses
many
> threads (or processes) in parallel.
>
> Lowering calamaris' priority or reducing the number of thrads/processes
> should have the same result.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXJepgAAoJENNXIZxhPexGSU4H/RXv9y0gbujSKFgo/AgG5PBS
KGuQG0MnNuVQVWU1ZEXP/Xd+z270t4XGLjTqY/0jKaOZYQZRrC+i7TbNuSxTE3RJ
xVJj1xpQxRw8NEkeRpVheMj6mJu14nU4XxTV0OLCvXFIluJFPn69j1BRjee+5Kj5
GgG0o1OOVXcduD5NBVrSHy9KnYvO8EPWxmPoAjT+aIAJRw5lKUL4wXZRHUrub2HH
K/GAhqKB6GJ5nIBfKRqCuGuuReUaNeA0brX1a3tcC63QBzAmu4pVWpjI5UcZLl3n
owwUNiyHqYvTPG3PoTKb1Oii1VR2dExoJJoZIpzud3u63DATBR+KKg7v7s4t6bg=
=sZqZ
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160501/dc9bec78/attachment.key>

From rousskov at measurement-factory.com  Sun May  1 18:56:32 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 1 May 2016 12:56:32 -0600
Subject: [squid-users] runing squid on second processor
In-Reply-To: <1461968276793-4677313.post@n4.nabble.com>
References: <1461968276793-4677313.post@n4.nabble.com>
Message-ID: <57265160.9070702@measurement-factory.com>

On 04/29/2016 04:17 PM, joe wrote:
> hi i have 2 cpu 4 core each
>  i need to leave alone first processor and use the second one for squid and
> its helper
> is that will do ???   taskset 0x000000f0 squid -YC -f /etc/squid/squid.conf
> or other way around ??

SMP Squid has cpu_affinity_map to accomplish similar task. However, it
does not apply to helpers AFAIK. Also, be careful not to assign two busy
Squid workers to two _sibling_ hyper cores. Give them hyper-cores on
different physical cores instead.


> so i can keep the kernel and other program running on first cpu not
> interfere  with squid

I do not know of a good solution to that. The solution I know is to tell
each active process or kernel task (e.g., NIC interrupts processing)
where to run, which is tedious when you have more than one or two such
activities to worry about.


> cause wen i run Calamaris Log Analysis on cpl large log it take cpu % very
> hi and it slow delay squid performance until it finish :(

Yes, it can be a real problem. AFAICT, the previous responses on this
thread essentially ignore the [sad] fact that Linux kernels are not very
good at CPU scheduling in high-performance SMP Squid environments.


HTH,

Alex.



From yvoinov at gmail.com  Sun May  1 18:58:47 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 2 May 2016 00:58:47 +0600
Subject: [squid-users] runing squid on second processor
In-Reply-To: <57265160.9070702@measurement-factory.com>
References: <1461968276793-4677313.post@n4.nabble.com>
 <57265160.9070702@measurement-factory.com>
Message-ID: <0951e0f5-70a9-d876-08ef-6647704655cb@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


02.05.16 0:56, Alex Rousskov ?????:
> On 04/29/2016 04:17 PM, joe wrote:
>> hi i have 2 cpu 4 core each
>>  i need to leave alone first processor and use the second one for
squid and
>> its helper
>> is that will do ???   taskset 0x000000f0 squid -YC -f
/etc/squid/squid.conf
>> or other way around ??
>
> SMP Squid has cpu_affinity_map to accomplish similar task. However, it
> does not apply to helpers AFAIK. Also, be careful not to assign two busy
> Squid workers to two _sibling_ hyper cores. Give them hyper-cores on
> different physical cores instead.
>
>
>> so i can keep the kernel and other program running on first cpu not
>> interfere  with squid
>
> I do not know of a good solution to that. The solution I know is to tell
> each active process or kernel task (e.g., NIC interrupts processing)
> where to run, which is tedious when you have more than one or two such
> activities to worry about.
>
>
>> cause wen i run Calamaris Log Analysis on cpl large log it take cpu %
very
>> hi and it slow delay squid performance until it finish :(
>
> Yes, it can be a real problem. AFAICT, the previous responses on this
> thread essentially ignore the [sad] fact that Linux kernels are not very
> good at CPU scheduling in high-performance SMP Squid environments.
Linux is not only last OS on the planet. There is another operating
systems with more better kernel/scheduling.... ;)
>
>
>
> HTH,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXJlHnAAoJENNXIZxhPexGmtcIAL4IKqj8L9q6pecI/FYeYZGR
mOnS17pfbUVKE5b1s4BK3dIo5aHQTx8uUCgujmD8XCeWVnZ/i/air7SvZp9/HspB
Zhm4CVk1fBzcbVG4DOjbYDnXvsgaD1qAMSlMKy39JwD4FSTPt8BHHp1RBwDhZEGE
woTAGFfsINcbIRuKXnh0wLjWUkPS2Eb3EdBZ8ALuZFPgPbY1CR5VRsVYv2eWhpwi
Gad9oImJb3nHykdUbxIvqUtjQJQKMj/5MDk+GIIOUiMopEgxwDuriLfEnw6X1ilh
eyxKJt/HqweGwhm796C9gRqqgy/6KLq8Ns6/sguJKpw2YT5QEl2ruui4LTs530M=
=LVvG
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160502/a85e5daa/attachment.key>

From yvoinov at gmail.com  Sun May  1 20:34:10 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 2 May 2016 02:34:10 +0600
Subject: [squid-users] runing squid on second processor
In-Reply-To: <57265160.9070702@measurement-factory.com>
References: <1461968276793-4677313.post@n4.nabble.com>
 <57265160.9070702@measurement-factory.com>
Message-ID: <68e99276-573f-bbf3-b2a5-7fe63bd9524e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


02.05.16 0:56, Alex Rousskov ?????:
> On 04/29/2016 04:17 PM, joe wrote:
>> hi i have 2 cpu 4 core each
>>  i need to leave alone first processor and use the second one for
squid and
>> its helper
>> is that will do ???   taskset 0x000000f0 squid -YC -f
/etc/squid/squid.conf
>> or other way around ??
>
> SMP Squid has cpu_affinity_map to accomplish similar task. However, it
> does not apply to helpers AFAIK. Also, be careful not to assign two busy
> Squid workers to two _sibling_ hyper cores. Give them hyper-cores on
> different physical cores instead.
>
>
>> so i can keep the kernel and other program running on first cpu not
>> interfere  with squid
>
> I do not know of a good solution to that. The solution I know is to tell
> each active process or kernel task (e.g., NIC interrupts processing)
> where to run, which is tedious when you have more than one or two such
> activities to worry about.
>
>
>> cause wen i run Calamaris Log Analysis on cpl large log it take cpu %
very
>> hi and it slow delay squid performance until it finish :(
>
> Yes, it can be a real problem. AFAICT, the previous responses on this
> thread essentially ignore the [sad] fact that Linux kernels are not very
> good at CPU scheduling in high-performance SMP Squid environments.
AFAIK we are speaking not about Linux, but FreeBSD. There is so much
another operating systems. So strange, is it? :)
>
>
>
> HTH,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXJmhCAAoJENNXIZxhPexGIaYIAK/3ZXfKihyh4RgtAC0KwGnq
nf115hhC+ID6SpI5pW2ghUCK+vqtOddyA44D7xf6IWC1GEVemckXGMcZGcR7QH74
Fnc8G0USB/7rr3WKvKyEj9IW29lQDviaiL0WT6ALYQGNuSDqn1vc3zyHp1Jxl4k/
zLGk9pnof8jIIIkzQIfSvP7L0I5YiOkS8T1bEqDZlkr+WS5GTnUcOAZc55m7cmak
cPQTUIaghVs62vHbVbAYpZ9lTsuJ3fL2KTlLaEp6u4Yi3h44DXwMcmoDT8pjQJkZ
WrgXrEl3TOE/3Vs6reZ181CfkPyqKNTwtIf6zvclKZ3o7Efj0wyOnagXNSbIQ9E=
=cT+L
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160502/c0a11719/attachment.key>

From yvoinov at gmail.com  Sun May  1 20:36:30 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 2 May 2016 02:36:30 +0600
Subject: [squid-users] runing squid on second processor
In-Reply-To: <57265160.9070702@measurement-factory.com>
References: <1461968276793-4677313.post@n4.nabble.com>
 <57265160.9070702@measurement-factory.com>
Message-ID: <fa7db1dc-b2ca-507c-1f6f-30823d9e3d12@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
And moreover - we are talking not about Squid in SMP environment.

:)

Too bad not to have Fair Share Scheduler, is it? :)

https://en.wikipedia.org/wiki/Fair-share_scheduling


02.05.16 0:56, Alex Rousskov ?????:
> On 04/29/2016 04:17 PM, joe wrote:
>> hi i have 2 cpu 4 core each
>>  i need to leave alone first processor and use the second one for
squid and
>> its helper
>> is that will do ???   taskset 0x000000f0 squid -YC -f
/etc/squid/squid.conf
>> or other way around ??
>
> SMP Squid has cpu_affinity_map to accomplish similar task. However, it
> does not apply to helpers AFAIK. Also, be careful not to assign two busy
> Squid workers to two _sibling_ hyper cores. Give them hyper-cores on
> different physical cores instead.
>
>
>> so i can keep the kernel and other program running on first cpu not
>> interfere  with squid
>
> I do not know of a good solution to that. The solution I know is to tell
> each active process or kernel task (e.g., NIC interrupts processing)
> where to run, which is tedious when you have more than one or two such
> activities to worry about.
>
>
>> cause wen i run Calamaris Log Analysis on cpl large log it take cpu %
very
>> hi and it slow delay squid performance until it finish :(
>
> Yes, it can be a real problem. AFAICT, the previous responses on this
> thread essentially ignore the [sad] fact that Linux kernels are not very
> good at CPU scheduling in high-performance SMP Squid environments.
>
>
> HTH,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXJmjNAAoJENNXIZxhPexGByYH/RpJWR8x4W13pkOaSF/6s5tW
h50kPt68hQnoM/VRAvE3Xu2uBsWmrrw28qpc2tXIiMpX2Y2zM31BIZPDpe3oPbPq
1aHczPwq/DoOc07uLc19CleZnFxM+LRy4QF7+FOjjIvpK82456Ip6gveIEfgHLIu
1nae+RnIzWXDAVVyWokTyLLGAYHqoyZAbVCHnbLyYtltvWQcT/SOhndklHhI4LMe
wiAeqKp32Jw0aijARwY7Sxd2NDAaZqD9T8fZ6Muy2CDtqcYM2MjH6reVKqan1xvT
pP3cNHieSfW9SLq682HJhmrKBhvGsGfyL/rGEhHo8F6ZL0QykH+z5BPu7SI21tA=
=HsBf
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160502/5fd9c883/attachment.key>

From yvoinov at gmail.com  Sun May  1 20:45:24 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 2 May 2016 02:45:24 +0600
Subject: [squid-users] runing squid on second processor
In-Reply-To: <57265160.9070702@measurement-factory.com>
References: <1461968276793-4677313.post@n4.nabble.com>
 <57265160.9070702@measurement-factory.com>
Message-ID: <81c5c10f-ed9f-069f-6e1c-8cd184ffbb7a@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


02.05.16 0:56, Alex Rousskov ?????:
> On 04/29/2016 04:17 PM, joe wrote:
>> hi i have 2 cpu 4 core each
>>  i need to leave alone first processor and use the second one for
squid and
>> its helper
>> is that will do ???   taskset 0x000000f0 squid -YC -f
/etc/squid/squid.conf
>> or other way around ??
>
> SMP Squid has cpu_affinity_map to accomplish similar task. However, it
Only on _some_OSes. What is the meddle to make this available for ANY OS?
>
> does not apply to helpers AFAIK. Also, be careful not to assign two busy
> Squid workers to two _sibling_ hyper cores. Give them hyper-cores on
> different physical cores instead.
>
>
>> so i can keep the kernel and other program running on first cpu not
>> interfere  with squid
>
> I do not know of a good solution to that. The solution I know is to tell
A good solution has Solaris OS. It also knows as FSS (Fair Share
Scheduler) and projects/tasks.
>
> each active process or kernel task (e.g., NIC interrupts processing)
Solaris also has possibility assign CPU cores as non-interruptable. In
addition to FSS. Thisfunctionality known approx. from Solaris 8 and
since 1993.
>
> where to run, which is tedious when you have more than one or two such
> activities to worry about.
>
>
>> cause wen i run Calamaris Log Analysis on cpl large log it take cpu %
very
>> hi and it slow delay squid performance until it finish :(
>
> Yes, it can be a real problem. AFAICT, the previous responses on this
We have NO problem on REAL OS. There is the problem only for self-made
...... (censored) 'systems' which is pretend to be OS. In normal OS we
have scheduling table which has no real problem in the similar cases. Never.
>
> thread essentially ignore the [sad] fact that Linux kernels are not very
> good at CPU scheduling in high-performance SMP Squid environments.
Linux is [censored]. No more.
>
>
>
> HTH,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXJmrjAAoJENNXIZxhPexGqqEIALFvL1Ms9uyQobyyCObe6ZEw
R1rsATe++2DC0zggZYLP5GOepZlayAoaKi6uA766B47iGk/IvLeB75CVju/LiG7H
qiLv2aekIuCUUYsrk8gImV2ohqTQ9B4wXJHWtSAy9tGnyWYcK4gCmnVb9ZCDW9Bm
g96k8Or9DnjO8djRrIA++poF2wL9Y2LOy90dj05CAOQXSe+Fv+/fg19ZE+/ceEtg
Ay1txAf0Wa8DbIv1M9Pjy9hH6VX45DZPravhrlOgGGgGUxOtKWbUiUW+PT0WIvqd
+0CzuHAJPnERGUO26K2/U+y8S3/GpfxkGIa383PzVERuAe/0CsflBVj26zffVvU=
=Thfa
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160502/b18947e1/attachment.key>

From yvoinov at gmail.com  Sun May  1 20:47:03 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 2 May 2016 02:47:03 +0600
Subject: [squid-users] runing squid on second processor
In-Reply-To: <57265160.9070702@measurement-factory.com>
References: <1461968276793-4677313.post@n4.nabble.com>
 <57265160.9070702@measurement-factory.com>
Message-ID: <99619468-11a1-50f5-5b2f-b507889c4ff3@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Just as a possibility of solution:

https://docs.oracle.com/cd/E22645_01/html/817-1592/rmfss-1.html


02.05.16 0:56, Alex Rousskov ?????:
> On 04/29/2016 04:17 PM, joe wrote:
>> hi i have 2 cpu 4 core each
>>  i need to leave alone first processor and use the second one for
squid and
>> its helper
>> is that will do ???   taskset 0x000000f0 squid -YC -f
/etc/squid/squid.conf
>> or other way around ??
>
> SMP Squid has cpu_affinity_map to accomplish similar task. However, it
> does not apply to helpers AFAIK. Also, be careful not to assign two busy
> Squid workers to two _sibling_ hyper cores. Give them hyper-cores on
> different physical cores instead.
>
>
>> so i can keep the kernel and other program running on first cpu not
>> interfere  with squid
>
> I do not know of a good solution to that. The solution I know is to tell
> each active process or kernel task (e.g., NIC interrupts processing)
> where to run, which is tedious when you have more than one or two such
> activities to worry about.
>
>
>> cause wen i run Calamaris Log Analysis on cpl large log it take cpu %
very
>> hi and it slow delay squid performance until it finish :(
>
> Yes, it can be a real problem. AFAICT, the previous responses on this
> thread essentially ignore the [sad] fact that Linux kernels are not very
> good at CPU scheduling in high-performance SMP Squid environments.
>
>
> HTH,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXJmtHAAoJENNXIZxhPexGn+wIAJFWApLrbTb3uTmT0aIr4F2j
xn/u9Y5sZxs2pFkwRr/5a81bXBGMwzJ6WWPwgeE8W0jNX3nq2d260KolXe2Dnk6J
9aH567wTioUMHE+t0zIQB5WF3zBZfqntBI5z+nvO9Gw/3gS+lVYstPcfxjd8d0O2
v00CMvAxX+ovtIh5cu8uLM4GygbP6n8ZNyzFA6RbCMEbNcN1Jt8CohL+hR+KBidj
0tyT9QH0w7vkyMj+WtYp9MBzGd0wneBuSbhDeZ5lj+wBn5rY8MkaTg2wIMWOpdtB
WRemUTLxop+BN1fH7ycnoKWzHGFY/BVUDI4Sxc2jvjNpkXTshLe8yT1bxqlgxJU=
=Ry7n
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160502/ea8ba33c/attachment.key>

From marcus.kool at urlfilterdb.com  Sun May  1 23:03:53 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Sun, 1 May 2016 20:03:53 -0300
Subject: [squid-users] runing squid on second processor
In-Reply-To: <1461968276793-4677313.post@n4.nabble.com>
References: <1461968276793-4677313.post@n4.nabble.com>
Message-ID: <57268B59.2090301@urlfilterdb.com>



On 04/29/2016 07:17 PM, joe wrote:
> hi i have 2 cpu 4 core each
>   i need to leave alone first processor and use the second one for squid and
> its helper
> is that will do ???   taskset 0x000000f0 squid -YC -f /etc/squid/squid.conf
> or other way around ??
> so i can keep the kernel and other program running on first cpu not
> interfere  with squid
> cause wen i run Calamaris Log Analysis on cpl large log it take cpu % very
> hi and it slow delay squid performance until it finish :(
>
> tks

If you use Linux, I suggest to use numactl, e.g.
    numactl -m 1 -N 1 /full/path/to/squid ...
this makes sure that squid and all children run on CPU cores of node 1 only and use memory from node 1 only

Marcus


From reet.vyas28 at gmail.com  Mon May  2 05:24:46 2016
From: reet.vyas28 at gmail.com (Reet Vyas)
Date: Mon, 2 May 2016 10:54:46 +0530
Subject: [squid-users] Block VPN access like hola.org ,ultrasurf
In-Reply-To: <cf6dc2fd-a185-c609-8459-c6a239694360@gmail.com>
References: <CAA8ViV8odKb5N2PUR4XPoK4B6Z8gWf9fafBX4nendt+GppWcfw@mail.gmail.com>
 <bcd5bd78-6bd6-0cf9-6e73-c3c7be7b6c85@gmail.com>
 <cf6dc2fd-a185-c609-8459-c6a239694360@gmail.com>
Message-ID: <CAA8ViV_LfD8u5EDLVU8cpQ=X7LFizMXCKWRN7mxuoyuQ6M_KkQ@mail.gmail.com>

Thanks so much for detailed explanation, will try cisco thing and will
check if it gets working

On Sat, Apr 30, 2016 at 3:34 AM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> AFAIK,
>
> every proxy admin faced with excessively smart users who want to bypass a
> proxy. If you think that this is not true in your case - it means you not
> know yet. While you suffer prince Hamlet's ethical dilemma - "To bump or
> not to bump - that is a serious matter", your smart-ass users will
> shamelessly use every possible tools and methods to step over you and wipe
> they feet on the your proxy.
>
> I am deeply sorry for you, but to solve this problem by means of a Squid
> is not possible. It is necessary to take into account the existence of Tor,
> VPN, URL shorteners, Google Translate (Yea, it also uses for bypassing
> proxy!), SOCKS, http/https anonymizers etc. This is not easy and not
> simple. This battle occurs every day.
>
> I deliberately do not mention really advanced techniques of hiding one
> type of traffic inside the other and another hacker's tools. VPN is a
> strong, but not the last tool to ignore the proxy server if it does not
> exist at all. And you can be sure your users will not miss them.
>
> And in the fight against shield and sword sword usually wins.
>
> Only a proxy in this issue is not worth little or nothing. Only trained
> administrator with experienced network administrator and two pairs bodied
> brain can more or less hinder the  life of these smart-ass users.
>
> This day-by-day battle is significant part of IT security, which is not
> product, but process.
>
> Hard luck,
>                  Yuri
>
> 29.04.16 22:07, Yuri Voinov ?????:
> >
> > The another option is using advanced DPI with database. Like China
> government uses.
> >
> > Squid itself can't.
> >
> > 29.04.16 16:33, Reet Vyas ?????:
> > > Hi,
> >
> >
> >
> >       > I have working trasparent squid , Some users are using proxy
> >       vpn in moziilla as addon and bypassing my squid, Please tell me
> >       how to block all hola.org <http://hola.org> <http://hola.org> vpn
> and ulrta
> >       surf, I have already blocked websites,but seems not working.
> >
> >
> >
> >       > Please let me know how to block these vpn access.
> >
> >
> >
> >
> >
> >
> >
> >       > _______________________________________________
> >
> >       > squid-users mailing list
> >
> >       > squid-users at lists.squid-cache.org
> >
> >       > http://lists.squid-cache.org/listinfo/squid-users
> >
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXI9qIAAoJENNXIZxhPexGISAH/ivV0JV6zUhN5C85GubgI3or
> EZJgL706JL+Q6CasmYF/88gau/j7EwYW+mtJ9EzdMGVo5lGkQW3Y/y6SjAmCdtI3
> J4eJMGIqi8mQRzfx55HGEv2cXHsYh3hxcBcBay4YHM9NFcXW/xMqsnwrkICULI6b
> mu91LERDiH5iBn9cT1qquKoTV8rg5E1eb6ZATA8r6VYRoZutzHN5/v4eww1ogxmc
> cE+DVzEcK5VJYFtfUHEyOCO785Xu1TSCctmmvzjrv2SpBQcgxJJ6pSrDrk+Qw614
> g50IJz26t0zqlrC/Z+LU0SeAgW7iboPID5yA/3bxWLSnupex3W93lwlPSJu48Pg=
> =V6pf
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160502/da5ceadb/attachment.htm>

From sampei02 at tiscali.it  Mon May  2 06:39:06 2016
From: sampei02 at tiscali.it (Sampei)
Date: Mon, 02 May 2016 08:39:06 +0200
Subject: [squid-users] ldap authentication with encrypted credentials
Message-ID: <76022224f8c7d2b77223069db3b461e2@tiscali.it>

  I'm going to configure Squid 2.7 Stable3 to authenticate clients
(Windows XP/7/10) in Active Directory environment (Windows 2000 server).

I used directive "auth_param basic program /usr/lib/squid/ldap_auth -v3
..." but I read basic authentication is extremely weak and It transmits
user passwords as cleartext.
How can I transmit encrypted credentials? 



Connetti gratis il mondo con la nuova indoona:  hai la chat, le chiamate, le video chiamate e persino le chiamate di gruppo.
E chiami gratis anche i numeri fissi e mobili nel mondo!
Scarica subito l?app Vai su https://www.indoona.com/

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160502/de63f3f1/attachment.htm>

From magiclink at outlook.com  Mon May  2 09:52:13 2016
From: magiclink at outlook.com (Magic Link)
Date: Mon, 2 May 2016 11:52:13 +0200
Subject: [squid-users] Delay pool class 2
Message-ID: <DUB130-W953B93752734A53A270F64BD790@phx.gbl>

 Hi,
 
i want to use delay pool with class 2. I don't understand how requests are handled on each bucket. There are 2 type of buckets in class 2, one aggregate and 256 individuals buckets. When aggregate bucket is used ? Is there a priority between each type ?
I want to limit bandwith for each IP so how do i configure the aggregate bucket compared to individual buckets ?
 
Thank you very much !
 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160502/ae5a0cb1/attachment.htm>

From squid3 at treenet.co.nz  Mon May  2 11:43:41 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 2 May 2016 23:43:41 +1200
Subject: [squid-users] ldap authentication with encrypted credentials
In-Reply-To: <76022224f8c7d2b77223069db3b461e2@tiscali.it>
References: <76022224f8c7d2b77223069db3b461e2@tiscali.it>
Message-ID: <f94e0f42-11b6-6489-03b7-220e289cf61f@treenet.co.nz>

On 2/05/2016 6:39 p.m., Sampei wrote:
>   I'm going to configure Squid 2.7 Stable3 to authenticate clients
> (Windows XP/7/10) in Active Directory environment (Windows 2000 server).

You have my most sincere condolences.

Squid-3.5 is available for Windows. see
<http://wiki.squid-cache.org/KnowledgeBase/Windows#Squid-3.5>. At least
you can update that component.

That is assuming Squid is running on a Windows box at all. There is no
need for it to do so. You might find it better to run Squid on a
non-Windows machine with Samba integration to the AD server. There are
socket limitations imposed by Windows that can make Squid peak service
x10 slower than on any other OS.


> 
> I used directive "auth_param basic program /usr/lib/squid/ldap_auth -v3
> ..." but I read basic authentication is extremely weak and It transmits
> user passwords as cleartext.

Lets put it this way. Clear text password in Basic authentication is
slightly more secure today than the encrypted NTLM implemented in that
Windows 2000 server you are using.

(And neither one is a good choice unless the transport itself is
encrypted, ie TLS / HTTPS).


> How can I transmit encrypted credentials? 
> 

Microsoft AD LDAP interface requires Basic authentication with cleartext
passwords. It is a limit imposed by the Microsoft implementation of AD.
Nobody I'm aware of has ever been able to adequately explain why, but
use of secure credentials was never implemented for their LDAP interface.

There are other AD interfaces than LDAP though, and they actually allow
more secure credentials to be used. Look into Negotiate/Kerberos
authentication. You will need that for the Win7 and Win10 clients anyway.

Amos



From squid3 at treenet.co.nz  Mon May  2 11:57:59 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 2 May 2016 23:57:59 +1200
Subject: [squid-users] Delay pool class 2
In-Reply-To: <DUB130-W953B93752734A53A270F64BD790@phx.gbl>
References: <DUB130-W953B93752734A53A270F64BD790@phx.gbl>
Message-ID: <32d9730d-5a67-bf4e-58d9-f0dc331b6be7@treenet.co.nz>

On 2/05/2016 9:52 p.m., Magic Link wrote:
> Hi,
> 
> i want to use delay pool with class 2. I don't understand how
> requests are handled on each bucket. There are 2 type of buckets in
> class 2, one aggregate and 256 individuals buckets. When aggregate
> bucket is used ? Is there a priority between each type ? I want to
> limit bandwith for each IP so how do i configure the aggregate bucket
> compared to individual buckets ?

When the aggregate bucket is enabled everything going through that delay
pool gets counted against it.

When the individual bucket is configured each client IP has a unique
bucket. Traffic sent by a server to a client gets counted against that
clients bucket.

Each byte going through the proxy gets counted in *both* buckets
relevant to the request. So at any one time a client is only able to use
up to the smaller of the two buckets available amounts.

Thats the theory at least, delay pools has some strange bugs which make
this not true for some things. If you can it is usually best to use the
OS provided QoS controls (maybe with TOS marking by Squid) instead of
Squid delay pools.

You can disable the aggregate bucket by configuring it as "-1/-1" or in
Squid-3.5+ the keyword "none" (meaning no limit for that bucket).

Amos



From chip_pop at hotmail.com  Mon May  2 11:42:01 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 2 May 2016 04:42:01 -0700 (PDT)
Subject: [squid-users] runing squid on second processor
In-Reply-To: <57268B59.2090301@urlfilterdb.com>
References: <1461968276793-4677313.post@n4.nabble.com>
 <57268B59.2090301@urlfilterdb.com>
Message-ID: <1462189321917-4677332.post@n4.nabble.com>

tks bro



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/runing-squid-on-second-processor-tp4677313p4677332.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From sampei02 at tiscali.it  Mon May  2 13:37:18 2016
From: sampei02 at tiscali.it (Sampei)
Date: Mon, 02 May 2016 15:37:18 +0200
Subject: [squid-users] ldap authentication with encrypted credentials
In-Reply-To: <f94e0f42-11b6-6489-03b7-220e289cf61f@treenet.co.nz>
References: <76022224f8c7d2b77223069db3b461e2@tiscali.it>
 <f94e0f42-11b6-6489-03b7-220e289cf61f@treenet.co.nz>
Message-ID: <eb9380f198ecedd65ea2f3bb8c36d3b3@tiscali.it>

Squid is running on old Linux fedora server

Il 02.05.2016 13:43 Amos Jeffries ha scritto:
> On 2/05/2016 6:39 p.m., Sampei wrote:
>>   I'm going to configure Squid 2.7 Stable3 to authenticate clients
>> (Windows XP/7/10) in Active Directory environment (Windows 2000 
>> server).
>
> You have my most sincere condolences.
>
> Squid-3.5 is available for Windows. see
> <http://wiki.squid-cache.org/KnowledgeBase/Windows#Squid-3.5>. At 
> least
> you can update that component.
>
> That is assuming Squid is running on a Windows box at all. There is 
> no
> need for it to do so. You might find it better to run Squid on a
> non-Windows machine with Samba integration to the AD server. There 
> are
> socket limitations imposed by Windows that can make Squid peak 
> service
> x10 slower than on any other OS.
>
>
>>
>> I used directive "auth_param basic program /usr/lib/squid/ldap_auth 
>> -v3
>> ..." but I read basic authentication is extremely weak and It 
>> transmits
>> user passwords as cleartext.
>
> Lets put it this way. Clear text password in Basic authentication is
> slightly more secure today than the encrypted NTLM implemented in 
> that
> Windows 2000 server you are using.
>
> (And neither one is a good choice unless the transport itself is
> encrypted, ie TLS / HTTPS).
>
>
>> How can I transmit encrypted credentials?
>>
>
> Microsoft AD LDAP interface requires Basic authentication with 
> cleartext
> passwords. It is a limit imposed by the Microsoft implementation of 
> AD.
> Nobody I'm aware of has ever been able to adequately explain why, but
> use of secure credentials was never implemented for their LDAP 
> interface.
>
> There are other AD interfaces than LDAP though, and they actually 
> allow
> more secure credentials to be used. Look into Negotiate/Kerberos
> authentication. You will need that for the Win7 and Win10 clients 
> anyway.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From Frank.Trifiletti at developpement-durable.gouv.fr  Mon May  2 14:07:34 2016
From: Frank.Trifiletti at developpement-durable.gouv.fr (TRIFILETTI Frank (Adjoint au chef du DO Sud-Est / Chef du groupe
 expertise technique) - SG/SPSSI/CPII/DOSE/ET)
Date: Mon, 02 May 2016 16:07:34 +0200
Subject: [squid-users] change between squid 3.1 and 3.3.8
In-Reply-To: <571E612D.1030008@treenet.co.nz>
References: <1461336059437-4677229.post@n4.nabble.com>
 <571AEC15.70007@treenet.co.nz> <571E48D3.90204@developpement-durable.gouv.fr>
 <571E612D.1030008@treenet.co.nz>
Message-ID: <57275F26.7070006@developpement-durable.gouv.fr>

Hello Amos,

i have this error in my cache.log (no helper entry available)

2016/05/02 14:35:37.732| external_acl.cc(793) aclMatchExternal: acl="ldap_group"
2016/05/02 14:35:37.732| external_acl.cc(822) aclMatchExternal: No helper entry 
available
2016/05/02 14:35:37.732| external_acl.cc(826) aclMatchExternal: ldap_group check 
user authenticated.
2016/05/02 14:35:37.732| external_acl.cc(832) aclMatchExternal: ldap_group user 
is authenticated.
2


and i read you link
<http://wiki.squid-cache.org/SquidFaq/SquidAcl#Fast_and_Slow_ACLs>

in my squid.conf i use a slow ACLs (external)
with one SLOW access clauses (http_access) and another one which is FAST access 
clauses (cache_peer_access)

but i made another test with the same squid.conf with squid 3.1.20 on an Ubuntu 
12.04.5 LTS it works (no DUNNO error in cache.log)

but it doesn't with squid 3.3.8 on an Ubuntu 14.04.4 LTS

the only differencies are the change of the external helper use :

1/in squid 3.3
	/usr/lib/squid3/digest_file_auth
for squid 3.1
	/usr/lib/squid3/basic_ldap_auth
2/in squid 3.3
	/usr/lib/squid3/ext_ldap_group_acl
for squid 3.1
	/usr/lib/squid3/squid_ldap_group

with same parameters, the point 1 for authentification works both 3.1 and 3.3
and for the ldap_group request

in squid 3.3
external_acl_type ldap_group ipv4 %LOGIN /usr/lib/squid3/ext_ldap_group_acl -d 
-b dc=eq,dc=fr -f "(&(objectclass=person)(mineqAccesInternet=%g)(uid=%u))" 
myldapserver

in squid 3.1
external_acl_type ldap_group ipv4 %LOGIN /usr/lib/squid3/squid_ldap_group -d -b 
dc=eq,dc=fr -f "(&(objectclass=person)(mineqAccesInternet=%g)(uid=%u))" myldapserver


thanks for reading me

Frank


Le 25/04/2016 20:25, "> Amos Jeffries (par Internet, d?p?t 
squid-users-bounces at lists.squid-cache.org)" a ?crit :
> On 26/04/2016 4:41 a.m., TRIFILETTI Frank (Adjoint au chef du DO Sud-Est
> / Chef du groupe expertise technique) - SG/SPSSI/CPII/DOSE/ET wrote:
>> Hello Amos,
>>
>> thanks for your answer
>>
>> my answer in the body of the message below
>>
>> Frank
>>
>> Le 23/04/2016 05:29, "> Amos Jeffries (par Internet, d?p?t
>> squid-users-bounces at lists.squid-cache.org)" a ?crit :
>>> On 23/04/2016 2:40 a.m., FTRIF wrote:
>>>> Hello,
>>>> i have a problem using /usr/lib/squid3/ext_ldap_group_acl which
>>>> appears in
>>>> 3.3.8
>>>>
>>>> i have a ldap attribut called InternetAccess which contains the value
>>>> "ACCESSINTER"
>>>>
>>>> i want to make an ACL to authorize such people to surf on the net by
>>>> using a
>>>> ldap_group, built with the people who had the value ACCESSINTER in
>>>> the ldap
>>>> attribut called InternetAccess
>>>>
>>>> in command line it works both with squid 3.1 and 3.3.8, the answer is
>>>> OK:
>>>>
>>>> /usr/lib/squid3/ext_ldap_group_acl -d -b dc=eq,dc=fr -f
>>>> "(&(objectclass=person)(InternetAccess=%a)(uid=%u))" myLdapDNSname
>>>>
>>>> fk.tf ACCESSINTER
>>>> ext_ldap_group_acl.cc(587): pid=25599 :Connected OK
>>>> ext_ldap_group_acl.cc(726): pid=25599 :group filter
>>>> '(&(objectclass=person)(InternetAccess=ACCESSINTER)(uid=fk.tf))',
>>>> searchbase
>>>> 'dc=eq,dc=fr'
>>>> OK
>>>
>>> Use '%g' macro for group. It will not to collide with URL-encoding of
>>> the parameters.
>>>
>>
>> in the squid.conf i forget indicate that i have a line
>> acl profil_ACCESSINTERNET external ldap_group ACCESSINTER
>>
>> in command line i replace %a by '%g' in command line but it doesn't work
>> only if i put %g
>>
>> but in squid.conf i put '%g' instead of %a and i have the same result
>> with in the cache.log
>>
>> 2016/04/25 18:17:25.835| Acl.cc(319) checklistMatches:
>> ACL::checklistMatches: checking 'profil_ACCESSINTERNET'
>> 2016/04/25 18:17:25.835| external_acl.cc(793) aclMatchExternal:
>> acl="ldap_group"
>> 2016/04/25 18:17:25.835| external_acl.cc(822) aclMatchExternal: No
>> helper entry available
>> 2016/04/25 18:17:25.835| external_acl.cc(826) aclMatchExternal:
>> ldap_group check user authenticated.
>> 2016/04/25 18:17:25.835| external_acl.cc(832) aclMatchExternal:
>> ldap_group user is authenticated.
>> 2016/04/25 18:17:25.835| external_acl.cc(856) aclMatchExternal:
>> ldap_group("fk.tf ACCESSINTER") = lookup needed
>> 2016/04/25 18:17:25.835| external_acl.cc(858) aclMatchExternal: "fk.tf
>> ACCESSINTER": entry=@0, age=0
>> 2016/04/25 18:17:25.835| external_acl.cc(861) aclMatchExternal: "fk.tf
>> ACCESSINTER": queueing a call.
>> 2016/04/25 18:17:25.835| external_acl.cc(863) aclMatchExternal: "fk.tf
>> ACCESSINTER": return -1.
>> 2016/04/25 18:17:25.835| Acl.cc(321) checklistMatches:
>> ACL::ChecklistMatches: result for 'profil_ACCESSINTERNET' is -1
>
> These lines are important:
>
>> 2016/04/25 18:17:25.835| Acl.cc(346) matches: profil_ACCESSINTERNET
>> needs async lookup
>> 2016/04/25 18:17:25.835| Acl.cc(354) matches: profil_ACCESSINTERNET
>> result is false
>> 2016/04/25 18:30:36.709| Checklist.cc(275) matchNode: 0x7ffdc7f66fb0
>> matched=0 async=1 finished=0
>> 2016/04/25 18:30:36.709| Checklist.cc(146) markFinished: 0x7ffdc7f66fb0
>> answer DUNNO for async required but prohibited
>> 2016/04/25 18:30:36.709| Checklist.cc(308) matchNode: 0x7ffdc7f66fb0
>> DUNNO because cannot async
>> 2016/04/25 18:30:36.709| FilledChecklist.cc(77) ~ACLFilledChecklist:
>> ACLFilledChecklist destroyed 0x7ffdc7f66fb0
>> 2016/04/25 18:30:36.709| Checklist.cc(334) ~ACLChecklist:
>> ACLChecklist::~ACLChecklist: destroyed 0x7ffdc7f66fb0
>> 2016/04/25 18:30:36.709| Checklist.cc(153) preCheck: 0x7ffdc7f66fb0
>> checking fast rules
>> 2016/04/25 18:30:36.709| Checklist.cc(414) fastCheck: aclCheckFast:
>> list: 0x56353080b548
>>
>> is it these last lines indicate the followup where the helper responds
>> you asked for ?
>
> Better. Those lines are saying you are using the group lookup in an
> access control list which cannot do group lookups or any other kind of
> delayed (async) data lookup.
>
> The answer is needed immediately by the access control and all Squid has
> to work with is DUNNO / "insufficient data".
>
> See <http://wiki.squid-cache.org/SquidFaq/SquidAcl#Fast_and_Slow_ACLs>
>
>>
>> if not which type of text i have to search ?
>>
>> my debug_options 28,9 82,9 84,9
>> section 82 External AC
>> section 84 Helper process maintenance
>> section 28 Access Control
>>
>
> Okay.
>
> The -d parameter on the helper command line for Squid helpers produces
> their internal debug.
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From a.alii85 at gmail.com  Mon May  2 14:51:51 2016
From: a.alii85 at gmail.com (asad)
Date: Mon, 2 May 2016 19:51:51 +0500
Subject: [squid-users] what it means by publishing ?
In-Reply-To: <CAP3=H7txqkB9MWE9Ayeod01C-F4PWCBdFpHL07bD=aKdBAyA4g@mail.gmail.com>
References: <CAP3=H7vFvXYHHKvK1wK-cR0OKzryPhQL3enk-v25UqZ8hTBdwA@mail.gmail.com>
 <CAP3=H7u7OLNgPxBwN1hbYYpmx6vrYC9yLEE=GMX5ANC0yFOKog@mail.gmail.com>
 <CAP3=H7uEt_9sOgH7hWO1aia3uawOUEnj5gvmymQfgddU-xcnLA@mail.gmail.com>
 <CAP3=H7v20RKPxtSYPrp692D+wqDJzsPaBvYtqGH0hHsFd8o5+g@mail.gmail.com>
 <CAP3=H7txqkB9MWE9Ayeod01C-F4PWCBdFpHL07bD=aKdBAyA4g@mail.gmail.com>
Message-ID: <CAP3=H7uDFrbLkEqbYM5hAqs06oVfCbwa9dYbw1TPRdJmasqi4w@mail.gmail.com>

hello,

I want to know accurate understanding of term "publishing" means ,
Microsoft TMG confuses me. I need this info to reply a proposal for a bank
which is requesting publishing support.

stating "to make avaiable a web request over net through a inspection
component I.e tmg or squid".

How is this different from opening a open on firewall and letting request
come in?

Why is not publishing term used in hw firewall concepts why limited to
proxies.

regards
Asad.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160502/2fd8fb82/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon May  2 15:00:48 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 2 May 2016 17:00:48 +0200
Subject: [squid-users] what it means by publishing ?
In-Reply-To: <CAP3=H7uDFrbLkEqbYM5hAqs06oVfCbwa9dYbw1TPRdJmasqi4w@mail.gmail.com>
References: <CAP3=H7vFvXYHHKvK1wK-cR0OKzryPhQL3enk-v25UqZ8hTBdwA@mail.gmail.com>
 <CAP3=H7txqkB9MWE9Ayeod01C-F4PWCBdFpHL07bD=aKdBAyA4g@mail.gmail.com>
 <CAP3=H7uDFrbLkEqbYM5hAqs06oVfCbwa9dYbw1TPRdJmasqi4w@mail.gmail.com>
Message-ID: <201605021700.48233.Antony.Stone@squid.open.source.it>

On Monday 02 May 2016 at 16:51:51, asad wrote:

> I want to know accurate understanding of term "publishing" means ,
> Microsoft TMG confuses me. I need this info to reply a proposal for a bank
> which is requesting publishing support.
> 
> stating "to make avaiable a web request over net through a inspection
> component I.e tmg or squid".
> 
> How is this different from opening a open on firewall and letting request
> come in?

You might be better off asking the person who is stating that as a requirement 
- find out exactly what *they* mean by it, and what they want you to do.


Antony.

-- 
"A person lives in the UK, but commutes to France daily for work.
He belongs in the UK."

 - From UK Revenue & Customs notice 741, page 13, paragraph 3.5.1
 - http://tinyurl.com/o7gnm4

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Mon May  2 15:07:50 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 3 May 2016 03:07:50 +1200
Subject: [squid-users] change between squid 3.1 and 3.3.8
In-Reply-To: <57275F26.7070006@developpement-durable.gouv.fr>
References: <1461336059437-4677229.post@n4.nabble.com>
 <571AEC15.70007@treenet.co.nz> <571E48D3.90204@developpement-durable.gouv.fr>
 <571E612D.1030008@treenet.co.nz>
 <57275F26.7070006@developpement-durable.gouv.fr>
Message-ID: <c908766a-b792-ed8e-a0e0-4aa3adb08a25@treenet.co.nz>

On 3/05/2016 2:07 a.m., TRIFILETTI Frank (Adjoint au chef du DO Sud-Est
/ Chef du groupe expertise technique) - SG/SPSSI/CPII/DOSE/ET wrote:
> Hello Amos,
> 
> i have this error in my cache.log (no helper entry available)
> 
> 2016/05/02 14:35:37.732| external_acl.cc(793) aclMatchExternal:
> acl="ldap_group"
> 2016/05/02 14:35:37.732| external_acl.cc(822) aclMatchExternal: No
> helper entry available
> 2016/05/02 14:35:37.732| external_acl.cc(826) aclMatchExternal:
> ldap_group check user authenticated.
> 2016/05/02 14:35:37.732| external_acl.cc(832) aclMatchExternal:
> ldap_group user is authenticated.
> 2
> 

That is the external ACL detecting that it has the username required by
%LOGIN macro, but still needs to do a lookup for the helpe response
somewhere.
The next thing it would do is a helper cache lookup to see if it already
knows the response that would come back.
 Only if that cache check produces nothing, or stale entry would it
DUNNO. Otherwise it would tell you what it found and match.

> 
> and i read you link
> <http://wiki.squid-cache.org/SquidFaq/SquidAcl#Fast_and_Slow_ACLs>
> 
> in my squid.conf i use a slow ACLs (external)
> with one SLOW access clauses (http_access) and another one which is FAST
> access clauses (cache_peer_access)
> 
> but i made another test with the same squid.conf with squid 3.1.20 on an
> Ubuntu 12.04.5 LTS it works (no DUNNO error in cache.log)

FYI: DUNNO used to be logged as "-1" in 3.1.

> 
> but it doesn't with squid 3.3.8 on an Ubuntu 14.04.4 LTS
>

It is a matter of timing and caching of the helper response. The trick
with using http_access as well as cache_peer_access is to get the helper
lookup done and the response into the helper cache, so that the FAST
lookup can find it there without needing to do a slow lookup.

But that relies heavily on the entry still being cached when
cache_peer_access needs it. Sometimes it will not be.

Amos



From tmblue at gmail.com  Tue May  3 23:12:46 2016
From: tmblue at gmail.com (Tory M Blue)
Date: Tue, 3 May 2016 16:12:46 -0700
Subject: [squid-users] Only listening to ipv6 (bug) still present? http_port
Message-ID: <CAEaSS0ZmRYtvKUkdQZWQtptkgqXvFBzGE4uVn2=pC0ZY7dve8g@mail.gmail.com>

My configs have always consisted of http_port 80 accel vhost.. With
the latest 3.5.17 (I guess) if you don't list 0.0.0.0:80 squid won't
even attempt to listen, talk on ivp4..

So adding 0.0.0.0:80 allows it to at least talk via ipv4.

This seems wrong, odd.

I understand you are removing methods to disable ipv6, however forcing
folks to us only ipv6 seems like a stretch :)

Thanks
Tory

CentOS 7
squid-3.5.17-1.el7.centos.x86_64


From squid3 at treenet.co.nz  Wed May  4 00:58:27 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 4 May 2016 12:58:27 +1200
Subject: [squid-users] Only listening to ipv6 (bug) still present?
 http_port
In-Reply-To: <CAEaSS0ZmRYtvKUkdQZWQtptkgqXvFBzGE4uVn2=pC0ZY7dve8g@mail.gmail.com>
References: <CAEaSS0ZmRYtvKUkdQZWQtptkgqXvFBzGE4uVn2=pC0ZY7dve8g@mail.gmail.com>
Message-ID: <9978cc13-cf2b-bee4-d835-b02ddd11c788@treenet.co.nz>

On 4/05/2016 11:12 a.m., Tory M Blue wrote:
> My configs have always consisted of http_port 80 accel vhost.. With
> the latest 3.5.17 (I guess) if you don't list 0.0.0.0:80 squid won't
> even attempt to listen, talk on ivp4..
> 
> So adding 0.0.0.0:80 allows it to at least talk via ipv4.
> 
> This seems wrong, odd.
> 
> I understand you are removing methods to disable ipv6, however forcing
> folks to us only ipv6 seems like a stretch :)
> 
> Thanks
> Tory
> 
> CentOS 7
> squid-3.5.17-1.el7.centos.x86_64


What is Squid saying on startup about the stack type detected?
 (may have to set debug_options 3,2)

Linux has a hybrid TCP stack. Which means IPv6 ports can receive IPv4
traffic unless you change something. Have you got any custom config in
your TCP/IP settings that might have changed the stacks v4-mapping
behaviour?

Amos



From tmblue at gmail.com  Wed May  4 03:22:04 2016
From: tmblue at gmail.com (Tory M Blue)
Date: Tue, 3 May 2016 20:22:04 -0700
Subject: [squid-users] Only listening to ipv6 (bug) still present?
 http_port IGNORE PEBCAK
Message-ID: <CAEaSS0bwmh1c9_0DZZR3K-P_kJqKt9nYNOBB-X=TqQzyqFvwYA@mail.gmail.com>

On Tue, May 3, 2016 at 5:58 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 4/05/2016 11:12 a.m., Tory M Blue wrote:
>> My configs have always consisted of http_port 80 accel vhost.. With
>> the latest 3.5.17 (I guess) if you don't list 0.0.0.0:80 squid won't
>> even attempt to listen, talk on ivp4..
>>
>> So adding 0.0.0.0:80 allows it to at least talk via ipv4.
>>
>> This seems wrong, odd.
>>
>> I understand you are removing methods to disable ipv6, however forcing
>> folks to us only ipv6 seems like a stretch :)
>>
>> Thanks
>> Tory
>>
>> CentOS 7
>> squid-3.5.17-1.el7.centos.x86_64
>
>
> What is Squid saying on startup about the stack type detected?
>  (may have to set debug_options 3,2)
>
> Linux has a hybrid TCP stack. Which means IPv6 ports can receive IPv4
> traffic unless you change something. Have you got any custom config in
> your TCP/IP settings that might have changed the stacks v4-mapping
> behaviour?
>
> Amos
>

Hey Amos

Other than disabling ipv6, there are no other tweaks.  The output of
netstat showed [::] 80 (what my squid servers listen on), but it
didn't seem to want to respond when I hit the squid server with a
request via ipv4.

As I mentioned I added 0.0.0.0:80 and it worked, worked with
my.ip.address.here:80 as well.. But just having port 80 there I got
nothing.

Let me test again, before I hit send.... <elevator music of the most
annoying kind......>

Well #$%#%$#%$#%$ it's working now. I must have had the issues before
I made some other "network related changes" and didn't correlate the
behaviour.

tcp6       0      0 :::80                   :::*                    LISTEN

Allows for my port 80 requests as you stated..

Please pardon me for this interruption. I even stopped the service and
restarted, it works. I sent this so early with so many other changes,
I just didn't correlate my other actions.

My apologies

Tory


From squid3 at treenet.co.nz  Wed May  4 03:57:11 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 4 May 2016 15:57:11 +1200
Subject: [squid-users] Only listening to ipv6 (bug) still present?
 http_port IGNORE PEBCAK
In-Reply-To: <CAEaSS0bwmh1c9_0DZZR3K-P_kJqKt9nYNOBB-X=TqQzyqFvwYA@mail.gmail.com>
References: <CAEaSS0bwmh1c9_0DZZR3K-P_kJqKt9nYNOBB-X=TqQzyqFvwYA@mail.gmail.com>
Message-ID: <2e58f062-dda4-7831-8c0b-6016e8744440@treenet.co.nz>

On 4/05/2016 3:22 p.m., Tory M Blue wrote:
> On Tue, May 3, 2016 at 5:58 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>> On 4/05/2016 11:12 a.m., Tory M Blue wrote:
>>> My configs have always consisted of http_port 80 accel vhost.. With
>>> the latest 3.5.17 (I guess) if you don't list 0.0.0.0:80 squid won't
>>> even attempt to listen, talk on ivp4..
>>>
>>> So adding 0.0.0.0:80 allows it to at least talk via ipv4.
>>>
>>> This seems wrong, odd.
>>>
>>> I understand you are removing methods to disable ipv6, however forcing
>>> folks to us only ipv6 seems like a stretch :)
>>>
>>> Thanks
>>> Tory
>>>
>>> CentOS 7
>>> squid-3.5.17-1.el7.centos.x86_64
>>
>>
>> What is Squid saying on startup about the stack type detected?
>>  (may have to set debug_options 3,2)
>>
>> Linux has a hybrid TCP stack. Which means IPv6 ports can receive IPv4
>> traffic unless you change something. Have you got any custom config in
>> your TCP/IP settings that might have changed the stacks v4-mapping
>> behaviour?
>>
>> Amos
>>
> 
> Hey Amos
> 
> Other than disabling ipv6, there are no other tweaks.

Um. "disabling ipv6" is not possible in any Linux or BSD based OS. All
the tutorials and advice that claim to mention ways to do so are
actually just screwing up the internal TCP stack state so the IPv6 fails
on various ways.

I think what is going on is that your chosen method of disable is/was
breaking the v4-mapping ability in the stack but not in a way Squid can
detect.

FYI: the "Right Way" to stop IPv6 being used is to configure ip6tables
firewall to REJECT all IPv6 traffic attempting to arrive or leave the
box. Treat v6 (and v6 variants of common protocols) as just another
protocol to block or permit at the firewall and you should be fine.

Some people like DROP in the firewall, but that is just another way to
cause breakage. It results in connections hanging.

Amos


From tmblue at gmail.com  Wed May  4 04:00:44 2016
From: tmblue at gmail.com (Tory M Blue)
Date: Tue, 3 May 2016 21:00:44 -0700
Subject: [squid-users] Only listening to ipv6 (bug) still present?
 http_port IGNORE PEBCAK
In-Reply-To: <2e58f062-dda4-7831-8c0b-6016e8744440@treenet.co.nz>
References: <CAEaSS0bwmh1c9_0DZZR3K-P_kJqKt9nYNOBB-X=TqQzyqFvwYA@mail.gmail.com>
 <2e58f062-dda4-7831-8c0b-6016e8744440@treenet.co.nz>
Message-ID: <CAEaSS0bP1rzjVmDAFtbeMJ8ZrvswjtkL+H_LPPYdHLcNZLDQDw@mail.gmail.com>

Interesting,

I do the sysctl settings and have no ipv6 interfaces showing up under
eth0/em0 or anything.. Been doing that for years, because I don't have
not taken the time to fix my DNS infrastructure and the pauses due to
ipv6 resolution attempts kill me

Thank you sir

Tory

On Tue, May 3, 2016 at 8:57 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 4/05/2016 3:22 p.m., Tory M Blue wrote:
>> On Tue, May 3, 2016 at 5:58 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>> On 4/05/2016 11:12 a.m., Tory M Blue wrote:
>>>> My configs have always consisted of http_port 80 accel vhost.. With
>>>> the latest 3.5.17 (I guess) if you don't list 0.0.0.0:80 squid won't
>>>> even attempt to listen, talk on ivp4..
>>>>
>>>> So adding 0.0.0.0:80 allows it to at least talk via ipv4.
>>>>
>>>> This seems wrong, odd.
>>>>
>>>> I understand you are removing methods to disable ipv6, however forcing
>>>> folks to us only ipv6 seems like a stretch :)
>>>>
>>>> Thanks
>>>> Tory
>>>>
>>>> CentOS 7
>>>> squid-3.5.17-1.el7.centos.x86_64
>>>
>>>
>>> What is Squid saying on startup about the stack type detected?
>>>  (may have to set debug_options 3,2)
>>>
>>> Linux has a hybrid TCP stack. Which means IPv6 ports can receive IPv4
>>> traffic unless you change something. Have you got any custom config in
>>> your TCP/IP settings that might have changed the stacks v4-mapping
>>> behaviour?
>>>
>>> Amos
>>>
>>
>> Hey Amos
>>
>> Other than disabling ipv6, there are no other tweaks.
>
> Um. "disabling ipv6" is not possible in any Linux or BSD based OS. All
> the tutorials and advice that claim to mention ways to do so are
> actually just screwing up the internal TCP stack state so the IPv6 fails
> on various ways.
>
> I think what is going on is that your chosen method of disable is/was
> breaking the v4-mapping ability in the stack but not in a way Squid can
> detect.
>
> FYI: the "Right Way" to stop IPv6 being used is to configure ip6tables
> firewall to REJECT all IPv6 traffic attempting to arrive or leave the
> box. Treat v6 (and v6 variants of common protocols) as just another
> protocol to block or permit at the firewall and you should be fine.
>
> Some people like DROP in the firewall, but that is just another way to
> cause breakage. It results in connections hanging.
>
> Amos


From eliezer at ngtech.co.il  Wed May  4 04:19:14 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 4 May 2016 07:19:14 +0300
Subject: [squid-users] Only listening to ipv6 (bug) still present?
 http_port
In-Reply-To: <CAEaSS0ZmRYtvKUkdQZWQtptkgqXvFBzGE4uVn2=pC0ZY7dve8g@mail.gmail.com>
References: <CAEaSS0ZmRYtvKUkdQZWQtptkgqXvFBzGE4uVn2=pC0ZY7dve8g@mail.gmail.com>
Message-ID: <5ae2b9df-c94a-94bf-06bb-cf84b0702a4b@ngtech.co.il>

Hey Tory,

I am not aware of such changes from 3.5.16 to 3.5.17.
I have not tested for this case yet and it seems a bit weird for me to 
see such behavior from squid.
I will be able to add it to the set of tests I already have later, until 
now 3.5.17 looks pretty working to me and without known regressions.

Eliezer

On 04/05/2016 02:12, Tory M Blue wrote:
> My configs have always consisted of http_port 80 accel vhost.. With
> the latest 3.5.17 (I guess) if you don't list 0.0.0.0:80 squid won't
> even attempt to listen, talk on ivp4..
>
> So adding 0.0.0.0:80 allows it to at least talk via ipv4.
>
> This seems wrong, odd.
>
> I understand you are removing methods to disable ipv6, however forcing
> folks to us only ipv6 seems like a stretch :)
>
> Thanks
> Tory
>
> CentOS 7
> squid-3.5.17-1.el7.centos.x86_64
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Wed May  4 06:15:34 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 4 May 2016 18:15:34 +1200
Subject: [squid-users] Only listening to ipv6 (bug) still present?
 http_port IGNORE PEBCAK
In-Reply-To: <CAEaSS0bP1rzjVmDAFtbeMJ8ZrvswjtkL+H_LPPYdHLcNZLDQDw@mail.gmail.com>
References: <CAEaSS0bwmh1c9_0DZZR3K-P_kJqKt9nYNOBB-X=TqQzyqFvwYA@mail.gmail.com>
 <2e58f062-dda4-7831-8c0b-6016e8744440@treenet.co.nz>
 <CAEaSS0bP1rzjVmDAFtbeMJ8ZrvswjtkL+H_LPPYdHLcNZLDQDw@mail.gmail.com>
Message-ID: <15d4b8aa-b3e9-c153-2ca6-b5c04a1a7d39@treenet.co.nz>

On 4/05/2016 4:00 p.m., Tory M Blue wrote:
> Interesting,
> 
> I do the sysctl settings and have no ipv6 interfaces showing up under
> eth0/em0 or anything.. Been doing that for years, because I don't have
> not taken the time to fix my DNS infrastructure and the pauses due to
> ipv6 resolution attempts kill me
> 

If you mean net.ipv6.conf.all.disable_ipv6=1, that just prevents the
interfaces doing the IP assignment dance. IPv6 is still present and
almost fully functional. Without the IP dance the machine is not
advertised as existing to remote IPv6 machinery and incoming connections
dont have anywhere to go. Outgoing connects can't use the system default
IP for the interface because there is none.

However, as you noticed Squid can still open a v6 socket and listen
there for passing traffic of either IP type. It should also still be
able to make outbound IPv6 connections if you configure
tcp_outgoing_addr explicitly with an IPv6 to use instead of relying on
the iface address.

NP: one important implication is that v6-enabled malware can do similar
and use IPv6 with its own self-assigned address out of your control. So
you need to do the firewall dance anyway.

Amos



From serdebronce at gmail.com  Wed May  4 11:20:50 2016
From: serdebronce at gmail.com (Ser de Bronce)
Date: Wed, 4 May 2016 14:20:50 +0300
Subject: [squid-users] Is there a way to allow connection according to user
	certificate?
Message-ID: <CABzQUcSexB8JAwGq92mAv4KBJheWZaKFcmrWgKQxBavw7W0XkA@mail.gmail.com>

Hi there,


Maybe someone already knows any solution:


I have transparent proxy and according to some reasons I can?t use
login/password authentication. However I still need to control who can
access my proxy.


I can install certificates to my users. Is it possible to allow connection
only if a user has the certificate issued by my CA?


Best Regards,

Sergey
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160504/a19cea29/attachment.htm>

From yvoinov at gmail.com  Wed May  4 11:34:40 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 4 May 2016 17:34:40 +0600
Subject: [squid-users] Is there a way to allow connection according to
 user certificate?
In-Reply-To: <CABzQUcSexB8JAwGq92mAv4KBJheWZaKFcmrWgKQxBavw7W0XkA@mail.gmail.com>
References: <CABzQUcSexB8JAwGq92mAv4KBJheWZaKFcmrWgKQxBavw7W0XkA@mail.gmail.com>
Message-ID: <41262264-db51-9675-231f-7abf81ed8dd6@gmail.com>



04.05.16 17:20, Ser de Bronce ?????:
>
> Hi there,
>
>
> Maybe someone already knows any solution:
>
>
> I have transparent proxy and according to some reasons I can?t use 
> login/password authentication. However I still need to control who can 
> access my proxy.
>
Transparent proxy can't use any authentification definitely.

However you still can control who can access your proxy by user 
IP/networks or MAC address.
>
>
> I can install certificates to my users. Is it possible to allow 
> connection only if a user has the certificate issued by my CA?
>
Don't think so.
>
>
> Best Regards,
>
> Sergey
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160504/7f05cff6/attachment.htm>

From sampei02 at tiscali.it  Wed May  4 11:56:15 2016
From: sampei02 at tiscali.it (Sampei)
Date: Wed, 04 May 2016 13:56:15 +0200
Subject: [squid-users] ldap authentication with encrypted credentials
In-Reply-To: <f94e0f42-11b6-6489-03b7-220e289cf61f@treenet.co.nz>
References: <76022224f8c7d2b77223069db3b461e2@tiscali.it>
 <f94e0f42-11b6-6489-03b7-220e289cf61f@treenet.co.nz>
Message-ID: <580d1f7f1067229df5608be32af98124@tiscali.it>

I'll explain better:
Squid is running on Debian 5 older server and every Windows (XP/7/10) 
client uses it to surf on web.
Clients are configured in outofdate Microsoft domain where Domain 
Controllers are based on Windows 2000 server.
So far I permit Internet access to clients by specify IP address of 
computers in squid.conf file but now I'd like to manage internet access 
by asking to user its AD credentials.
Now I'm not able to update systems so I have to schedule it upgrade for 
next year.

>>>Look into Negotiate/Kerberos authentication. You will need that for 
>>> the Win7 and Win10 clients anyway
For Windows 7/10 clients, the Basic authentication (Squid 2.7) with 
LDAP helper will not able to work ?
While Kerberos will work both with older clients and newer ones?




Il 02.05.2016 13:43 Amos Jeffries ha scritto:

> On 2/05/2016 6:39 p.m., Sampei wrote:
>
>> I'm going to configure Squid 2.7 Stable3 to authenticate clients
>> (Windows XP/7/10) in Active Directory environment (Windows 2000
>> server).
>
> You have my most sincere condolences.
>
> Squid-3.5 is available for Windows. see
> . At least
> you can update that component.
>
> That is assuming Squid is running on a Windows box at all. There is 
> no
> need for it to do so. You might find it better to run Squid on a
> non-Windows machine with Samba integration to the AD server. There 
> are
> socket limitations imposed by Windows that can make Squid peak 
> service
> x10 slower than on any other OS.
>
>> I used directive "auth_param basic program /usr/lib/squid/ldap_auth 
>> -v3
>> ..." but I read basic authentication is extremely weak and It 
>> transmits
>> user passwords as cleartext.
>
> Lets put it this way. Clear text password in Basic authentication is
> slightly more secure today than the encrypted NTLM implemented in 
> that
> Windows 2000 server you are using.
>
> (And neither one is a good choice unless the transport itself is
> encrypted, ie TLS / HTTPS).
>
>>> How can I transmit encrypted credentials
>>
>
> Microsoft AD LDAP interface requires Basic authentication with 
> cleartext
> passwords. It is a limit imposed by the Microsoft implementation of 
> AD.
> Nobody I'm aware of has ever been able to adequately explain why, but
> use of secure credentials was never implemented for their LDAP 
> interface.
>
> There are other AD interfaces than LDAP though, and they actually 
> allow
> more secure credentials to be used. Look into Negotiate/Kerberos
> authentication. You will need that for the Win7 and Win10 clients 
> anyway.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org [2]
> http://lists.squid-cache.org/listinfo/squid-users [3]


Links:
------
[1] http://wiki.squid-cache.org/KnowledgeBase/Windows#Squid-3.5
[2] mailto:squid-users at lists.squid-cache.org
[3] http://lists.squid-cache.org/listinfo/squid-users



Con Tutto Incluso Light navighi fino a 20 Mega senza limiti e chiami a 
0 cent/minuto verso tutti i fissi e i mobili in Italia a 19,95 euro/mese 
per sempre. In piu' ora l'attivazione e' Gratis! http://casa.tiscali.it/




From squid3 at treenet.co.nz  Wed May  4 12:05:06 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 5 May 2016 00:05:06 +1200
Subject: [squid-users] Is there a way to allow connection according to
 user certificate?
In-Reply-To: <CABzQUcSexB8JAwGq92mAv4KBJheWZaKFcmrWgKQxBavw7W0XkA@mail.gmail.com>
References: <CABzQUcSexB8JAwGq92mAv4KBJheWZaKFcmrWgKQxBavw7W0XkA@mail.gmail.com>
Message-ID: <7dd98650-0b67-dc19-3437-b507d6590e85@treenet.co.nz>

On 4/05/2016 11:20 p.m., Ser de Bronce wrote:
> Hi there,
> 
> 
> Maybe someone already knows any solution:
> 
> 
> I have transparent proxy and according to some reasons I can?t use
> login/password authentication. However I still need to control who can
> access my proxy.
> 
> 
> I can install certificates to my users. Is it possible to allow connection
> only if a user has the certificate issued by my CA?

You seem not to quite understand what the "some reasons" actually are.
If you did you would not have to ask.


Firstly, there is only one reason behind it all.

The reason is that the client thinks it's talking to some service that
is *not your proxy*. That is very important.


Secondly, there is one criteria that determines what works and what fails.

That criteria is "authentication". Specifically in-band authentication.
Any type of in-band authentication WILL fail. Any type. Not just passwords.

TLS client certificate is just another type of in-band authentication.
 * Which answers your question: No. It wont work the way you want.


If you can install certificates that easily. Then surely you can just as
easily assign explicit proxy settings. Doing that would avoid all the
issues with interception.


Also, Think about all the passive details / metadata you get from the
client traffic and how you can use it to authorize access without
actively engaging the client across the intercepted connection.

There are quite a lot of things you can do. Methods like RADIUS or DHCP
assigned IP addresses. Static IPs, or MAC address registrations a proxy
external ACL helper can lookup to identify the client account.

Amos



From yvoinov at gmail.com  Wed May  4 12:09:06 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 4 May 2016 18:09:06 +0600
Subject: [squid-users] Is there a way to allow connection according to
 user certificate?
In-Reply-To: <7dd98650-0b67-dc19-3437-b507d6590e85@treenet.co.nz>
References: <CABzQUcSexB8JAwGq92mAv4KBJheWZaKFcmrWgKQxBavw7W0XkA@mail.gmail.com>
 <7dd98650-0b67-dc19-3437-b507d6590e85@treenet.co.nz>
Message-ID: <4f0d4c4f-b841-23df-2c50-007b3cd82fef@gmail.com>



04.05.16 18:05, Amos Jeffries ?????:
> On 4/05/2016 11:20 p.m., Ser de Bronce wrote:
>> Hi there,
>>
>>
>> Maybe someone already knows any solution:
>>
>>
>> I have transparent proxy and according to some reasons I can?t use
>> login/password authentication. However I still need to control who can
>> access my proxy.
>>
>>
>> I can install certificates to my users. Is it possible to allow connection
>> only if a user has the certificate issued by my CA?
> You seem not to quite understand what the "some reasons" actually are.
> If you did you would not have to ask.
>
>
> Firstly, there is only one reason behind it all.
>
> The reason is that the client thinks it's talking to some service that
> is *not your proxy*. That is very important.
>
>
> Secondly, there is one criteria that determines what works and what fails.
>
> That criteria is "authentication". Specifically in-band authentication.
> Any type of in-band authentication WILL fail. Any type. Not just passwords.
>
> TLS client certificate is just another type of in-band authentication.
>   * Which answers your question: No. It wont work the way you want.
>
>
> If you can install certificates that easily. Then surely you can just as
> easily assign explicit proxy settings. Doing that would avoid all the
> issues with interception.
>
>
> Also, Think about all the passive details / metadata you get from the
> client traffic and how you can use it to authorize access without
> actively engaging the client across the intercepted connection.
>
> There are quite a lot of things you can do. Methods like RADIUS or DHCP
> assigned IP addresses. Static IPs, or MAC address registrations a proxy
> external ACL helper can lookup to identify the client account.
Just in addition. DHCP with infinite lease, or static binding, or IDENT 
;) Or, yes, RADIUS....
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Wed May  4 12:23:03 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 5 May 2016 00:23:03 +1200
Subject: [squid-users] ldap authentication with encrypted credentials
In-Reply-To: <580d1f7f1067229df5608be32af98124@tiscali.it>
References: <76022224f8c7d2b77223069db3b461e2@tiscali.it>
 <f94e0f42-11b6-6489-03b7-220e289cf61f@treenet.co.nz>
 <580d1f7f1067229df5608be32af98124@tiscali.it>
Message-ID: <658f257a-554a-3752-ae29-bc967d6fb091@treenet.co.nz>

On 4/05/2016 11:56 p.m., Sampei wrote:
> I'll explain better:
> Squid is running on Debian 5 older server and every Windows (XP/7/10)
> client uses it to surf on web.
> Clients are configured in outofdate Microsoft domain where Domain
> Controllers are based on Windows 2000 server.
> So far I permit Internet access to clients by specify IP address of
> computers in squid.conf file but now I'd like to manage internet access
> by asking to user its AD credentials.
> Now I'm not able to update systems so I have to schedule it upgrade for
> next year.

I've been in those shoes myself, and recommed you may want to keep the
IP based authorization until you can get a better AD system.

> 
>>>> Look into Negotiate/Kerberos authentication. You will need that for
>>>> the Win7 and Win10 clients anyway
> For Windows 7/10 clients, the Basic authentication (Squid 2.7) with LDAP
> helper will not able to work ?
> While Kerberos will work both with older clients and newer ones?
> 

Yes they all still support Basic, but you said that was not desirable.

The secure methods that leaves you with are NTLMv2 (definitely *not*
NTLMv1) or Negotiate/Kerberos.

NTLM was deprecated by MS in 2006. All software produced by MS since
then is increasingly hostile to NTLM being used and preferring Kerberos.
XP can handle Kerberos with maybe a little config. And it is both more
secure and faster so a double-win once you get over the learning curve
for its management tools.

I'm not sure if or how the Win2k server can handle Kerberos. You will
need to find that out.

Amos



From belle at bazuin.nl  Wed May  4 12:46:01 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 4 May 2016 14:46:01 +0200
Subject: [squid-users] ldap authentication with encrypted credentials
In-Reply-To: <658f257a-554a-3752-ae29-bc967d6fb091@treenet.co.nz>
References: <580d1f7f1067229df5608be32af98124@tiscali.it>
Message-ID: <vmime.5729ef09.2c64.306d933f69de0d19@ms249-lin-003.rotterdam.bazuin.nl>

In addition, due to last samba and windows security fixes there was a behavior change. 

So beware with squid and samba/winbind/ldap/windows auth. 
Read : https://www.samba.org/samba/history/samba-4.4.2.html 
This was a big impact.. 

BUt beware, use samba 4.2.12 4.3.9 or 4.4.3
All version bug release (4.4.2 4.3.8 4.2.11 ) had some nasty bugs. 

I had to reconfigure my squid auth. 
I've tested with latest squid 3.5.17 on my debian jessie, all fine again. 

And to Sampei, add a samba 4 AD ( preffered 4.4.3 ) to you domain, 
Move FSMO roles to samba, and drop your unsupported windows AD. 
I dropped all my windows servers, only samba now. 


Greetz, 

Louis



> -----Oorspronkelijk bericht-----
> Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens
> Amos Jeffries
> Verzonden: woensdag 4 mei 2016 14:23
> Aan: Sampei; squid-users at lists.squid-cache.org
> Onderwerp: Re: [squid-users] ldap authentication with encrypted
> credentials
> 
> On 4/05/2016 11:56 p.m., Sampei wrote:
> > I'll explain better:
> > Squid is running on Debian 5 older server and every Windows (XP/7/10)
> > client uses it to surf on web.
> > Clients are configured in outofdate Microsoft domain where Domain
> > Controllers are based on Windows 2000 server.
> > So far I permit Internet access to clients by specify IP address of
> > computers in squid.conf file but now I'd like to manage internet access
> > by asking to user its AD credentials.
> > Now I'm not able to update systems so I have to schedule it upgrade for
> > next year.
> 
> I've been in those shoes myself, and recommed you may want to keep the
> IP based authorization until you can get a better AD system.
> 
> >
> >>>> Look into Negotiate/Kerberos authentication. You will need that for
> >>>> the Win7 and Win10 clients anyway
> > For Windows 7/10 clients, the Basic authentication (Squid 2.7) with LDAP
> > helper will not able to work ?
> > While Kerberos will work both with older clients and newer ones?
> >
> 
> Yes they all still support Basic, but you said that was not desirable.
> 
> The secure methods that leaves you with are NTLMv2 (definitely *not*
> NTLMv1) or Negotiate/Kerberos.
> 
> NTLM was deprecated by MS in 2006. All software produced by MS since
> then is increasingly hostile to NTLM being used and preferring Kerberos.
> XP can handle Kerberos with maybe a little config. And it is both more
> secure and faster so a double-win once you get over the learning curve
> for its management tools.
> 
> I'm not sure if or how the Win2k server can handle Kerberos. You will
> need to find that out.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From jester at optimera.us  Wed May  4 13:01:22 2016
From: jester at optimera.us (Jester Purtteman)
Date: Wed, 4 May 2016 06:01:22 -0700
Subject: [squid-users] quick_abort_min by acl?
Message-ID: <011c01d1a605$138e1160$3aaa3420$@optimera.us>

Greetings!

 

Is there a way I'm not seeing to apply ACLs to quick_abort_min?  It seems
like it would be handy to be able to tell squid to finish downloads for
specific sites, and not others. 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160504/a2f10e61/attachment.htm>

From squid3 at treenet.co.nz  Wed May  4 13:07:43 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 5 May 2016 01:07:43 +1200
Subject: [squid-users] quick_abort_min by acl?
In-Reply-To: <011c01d1a605$138e1160$3aaa3420$@optimera.us>
References: <011c01d1a605$138e1160$3aaa3420$@optimera.us>
Message-ID: <5c41ec3d-11c2-f780-fb48-95e9e31999f8@treenet.co.nz>

On 5/05/2016 1:01 a.m., Jester Purtteman wrote:
> Greetings!
> 
>  
> 
> Is there a way I'm not seeing to apply ACLs to quick_abort_min?  It seems
> like it would be handy to be able to tell squid to finish downloads for
> specific sites, and not others. 

No, the quick_abort_* directives do not support ACLs in any current Squid.

Amos



From maile.halatuituia at tcc.to  Wed May  4 21:04:44 2016
From: maile.halatuituia at tcc.to (Maile Halatuituia)
Date: Wed, 4 May 2016 21:04:44 +0000
Subject: [squid-users] URL/P2P blocking
Message-ID: <c8632cc0ab24487489fa93e3270630a2@mail.tcc.to>

?Someone with ideas on how to block Facebook,Youtube, P2P Traffic though my squid box. Facebook seems to be working but likely some users bypass to youtube.com and the rest are blocked. Also am looking to block P2P traffic , BITS proticols, etc etc

Cheers


Confidentiality Notice: This email (including any attachment) is intended for internal use only. Any unauthorized use, dissemination or copying of the content is prohibited. If you are not the intended recipient and have received this e-mail in error, please notify the sender by email and delete this email and any attachment.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160504/0056fca6/attachment.htm>

From yvoinov at gmail.com  Wed May  4 21:11:39 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 5 May 2016 03:11:39 +0600
Subject: [squid-users] URL/P2P blocking
In-Reply-To: <c8632cc0ab24487489fa93e3270630a2@mail.tcc.to>
References: <c8632cc0ab24487489fa93e3270630a2@mail.tcc.to>
Message-ID: <f5770cc1-65a5-15ab-6f7e-5e582566bd18@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Facebook uses Akamai as background CDN, so you need to block Akamai
(related URL's, which can be difficult, so consider to use Cisco NBAR
DPI functionality). too in case to completely block FB.

YT still uses QUIC/SPDY, so read this

http://wiki.squid-cache.org/KnowledgeBase/Block%20QUIC%20protocol

About P2P/Torrents said enough here

http://wiki.squid-cache.org/ConfigExamples/TorrentFiltering

Note: Using Cisco NBAR required valid service contract. Protocol packs
is not lying at all angles, and are updated monthly.


05.05.16 3:04, Maile Halatuituia ?????:
>
> ?Someone with ideas on how to block Facebook,Youtube, P2P Traffic
though my squid box. Facebook seems to be working but likely some users
bypass to youtube.com and the rest are blocked. Also am looking to block
P2P traffic , BITS proticols, etc etc
>
> Cheers
>
> Confidentiality Notice: This email (including any attachment) is
intended for internal use only. Any unauthorized use, dissemination or
copying of the content is prohibited. If you are not the intended
recipient and have received this e-mail in error, please notify the
sender by email and delete this email and any attachment.
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXKmWLAAoJENNXIZxhPexGqEYH/2a7JzZZ14barKq+RT5gv7Tj
0i6uF79DYmgupYhcoLyN5dErAq4Pi6AQh/03puxfIIV3LFFuGc3Qp1ZEJUkIMIGR
QLAIhHbdc+0fqwdEeh+NUwnppp56WoQVcW5rXSWLP+mjeAysUGKn5ftAZdCxRqVR
tFtWRj7K/dnIpJYlM+QSGxbcasv6c142+CJ5/4Iaa5ufpb7uTWtbOfvWm0c7YgYa
7+FLOwh520qqGrMX0Ue8mdABfSS/H3B4cKqxSTQ0bHq/977/dhSdDYuIIQ/Q1w/C
GIXTIJNYAF5ZuLQXUoipN3NiYfJSpajIwtU2M7t5m0MzzB4QRVuCEdxANJkx5Qc=
=tfMf
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160505/c5ca4190/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160505/c5ca4190/attachment.key>

From yvoinov at gmail.com  Wed May  4 21:18:28 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 5 May 2016 03:18:28 +0600
Subject: [squid-users] URL/P2P blocking
In-Reply-To: <f5770cc1-65a5-15ab-6f7e-5e582566bd18@gmail.com>
References: <c8632cc0ab24487489fa93e3270630a2@mail.tcc.to>
 <f5770cc1-65a5-15ab-6f7e-5e582566bd18@gmail.com>
Message-ID: <1960db35-8fb9-44b9-d6f3-f481e8a041ed@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Generally, for effective blocking of everything better design would
first consider - as everyone and everything is engeneered,
and then look for the magic button "to disable all to hell."

Then it becomes clear what is possible and what means - and what is not.

Especially P2P - this is at all not about Squid.

05.05.16 3:11, Yuri Voinov ?????:
>
> Facebook uses Akamai as background CDN, so you need to block Akamai
(related URL's, which can be difficult, so consider to use Cisco NBAR
DPI functionality). too in case to completely block FB.
>
> YT still uses QUIC/SPDY, so read this
>
> http://wiki.squid-cache.org/KnowledgeBase/Block%20QUIC%20protocol
>
> About P2P/Torrents said enough here
>
> http://wiki.squid-cache.org/ConfigExamples/TorrentFiltering
>
> Note: Using Cisco NBAR required valid service contract. Protocol packs
is not lying at all angles, and are updated monthly.
>
>
> 05.05.16 3:04, Maile Halatuituia ?????:
>
>
>       > ?Someone with ideas on how to block Facebook,Youtube, P2P
>       Traffic though my squid box. Facebook seems to be working but
>       likely some users bypass to youtube.com and the rest are blocked.
>       Also am looking to block P2P traffic , BITS proticols, etc etc
>
>
>
>       > Cheers
>
>
>
>       > Confidentiality Notice: This email (including any attachment)
>       is intended for internal use only. Any unauthorized use,
>       dissemination or copying of the content is prohibited. If you are
>       not the intended recipient and have received this e-mail in error,
>       please notify the sender by email and delete this email and any
>       attachment.
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXKmckAAoJENNXIZxhPexGyi8H/0NyB8++RvYU7b1x5EVbkaxL
uMZT8P6dGvKeQdYIBPrZyTXPwOuefSkNGtH3BeAQ/YbRktOptYqr6tyQIVVzT4M9
4O4TlhGt9E9VlGyAZf9cVhjzlryioDvYBg05pp0Sft+h0Wa1b4+fvp4hflfE15KQ
CdNQs+yrmWfSZ4Lk5AFGag5R28wsBZeIyxodChQmpmkyfIGzUH9Dn7p6IdQFW0Ke
qbJXGrxqdzIFJoHsnANtxo2vxEB34fFo1reDBBSh3RSbWytpyS9uoLJy9Nr9Bkfc
KKIUxTH0gubMEMIuVr2KzRTS49dfZ9bztZINWETnInowMDRLsXD2gBIbTg2pNQw=
=VZCI
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160505/81050800/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160505/81050800/attachment.key>

From yvoinov at gmail.com  Wed May  4 21:26:12 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 5 May 2016 03:26:12 +0600
Subject: [squid-users] URL/P2P blocking
In-Reply-To: <1960db35-8fb9-44b9-d6f3-f481e8a041ed@gmail.com>
References: <c8632cc0ab24487489fa93e3270630a2@mail.tcc.to>
 <f5770cc1-65a5-15ab-6f7e-5e582566bd18@gmail.com>
 <1960db35-8fb9-44b9-d6f3-f481e8a041ed@gmail.com>
Message-ID: <4c034864-da21-cb7d-3fc3-8de5f4108b9b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
As a part of solution I recommend (by my own experience) consider to use
this:

https://www.urlfilterdb.com/products/ufdbguard.html

But I repeat: this is NOT magic button "Disable all". This is relatively
effective tool to block categories.

This is only URL/HTTP based tool, which required some more forces to use
it with HTTPS.
And this can't be other means to replace when it comes to other protocols.

Squid is only HTTP/HTTPS proxy. Not at all existing protocols.

05.05.16 3:18, Yuri Voinov ?????:
>
> Generally, for effective blocking of everything better design would
first consider - as everyone and everything is engeneered,
> and then look for the magic button "to disable all to hell."
>
> Then it becomes clear what is possible and what means - and what is not.
>
> Especially P2P - this is at all not about Squid.
>
> 05.05.16 3:11, Yuri Voinov ?????:
>
>
>       > Facebook uses Akamai as background CDN, so you need to block
>       Akamai (related URL's, which can be difficult, so consider to use
>       Cisco NBAR DPI functionality). too in case to completely block FB.
>
>
>
>       > YT still uses QUIC/SPDY, so read this
>
>
>
>
>       http://wiki.squid-cache.org/KnowledgeBase/Block%20QUIC%20protocol
>
>
>
>       > About P2P/Torrents said enough here
>
>
>
>       > http://wiki.squid-cache.org/ConfigExamples/TorrentFiltering
>
>
>
>       > Note: Using Cisco NBAR required valid service contract.
>       Protocol packs is not lying at all angles, and are updated
>       monthly.
>
>
>
>
>
>       > 05.05.16 3:04, Maile Halatuituia ?????:
>
>
>
>
>
>       >       > ?Someone with ideas on how to block
>       Facebook,Youtube, P2P
>
>       >       Traffic though my squid box. Facebook seems to be
>       working but
>
>       >       likely some users bypass to youtube.com and the rest
>       are blocked.
>
>       >       Also am looking to block P2P traffic , BITS proticols,
>       etc etc
>
>
>
>
>
>
>
>       >       > Cheers
>
>
>
>
>
>
>
>       >       > Confidentiality Notice: This email (including any
>       attachment)
>
>       >       is intended for internal use only. Any unauthorized
>       use,
>
>       >       dissemination or copying of the content is prohibited.
>       If you are
>
>       >       not the intended recipient and have received this
>       e-mail in error,
>
>       >       please notify the sender by email and delete this email
>       and any
>
>       >       attachment.
>
>
>
>
>
>
>
>
>
>
>
>       >       > _______________________________________________
>
>
>
>       >       > squid-users mailing list
>
>
>
>       >       > squid-users at lists.squid-cache.org
>
>
>
>       >       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXKmjzAAoJENNXIZxhPexGb+QH/iHk6tT2poZdpt0wgfjUmRaK
nHwSQIBvt1K5ntbB948AGQb+mcbLTn74oLafdmiV41CirSs4v/ZRT4c1gQ9mY3Pp
xm5tLX9L9180KOMWShqALjtFUedM7lgN85whB+JDk4SPJjz4LmYsn/6sbzauo4kN
PaGlyGYkvwFGmfNcalzrmlVFMxHQGrxSkw6j0vqICPd448/arJDNuWJOIbUbaAP5
YP76XQI9DlolwofYewB0t8675mSbq+ehJCwf2bA2t6331kVXjy4NyoLMxA63Ef33
bGzrhenBFj5fMx/KexRkEm9/qpAv1NP91DgwSW5R15XpgtKyrNVpOdkJMsnHGU8=
=Q7Aj
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160505/20d8a265/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160505/20d8a265/attachment.key>

From yvoinov at gmail.com  Wed May  4 21:28:50 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 5 May 2016 03:28:50 +0600
Subject: [squid-users] URL/P2P blocking
In-Reply-To: <4c034864-da21-cb7d-3fc3-8de5f4108b9b@gmail.com>
References: <c8632cc0ab24487489fa93e3270630a2@mail.tcc.to>
 <f5770cc1-65a5-15ab-6f7e-5e582566bd18@gmail.com>
 <1960db35-8fb9-44b9-d6f3-f481e8a041ed@gmail.com>
 <4c034864-da21-cb7d-3fc3-8de5f4108b9b@gmail.com>
Message-ID: <fa999fb7-afea-d8a3-a5e8-3fe44c97f1d4@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Finally,

read this thread too:

http://www.spinics.net/lists/squid/msg81113.html

Some questions already answered here.

05.05.16 3:26, Yuri Voinov ?????:
>
> As a part of solution I recommend (by my own experience) consider to
use this:
>
> https://www.urlfilterdb.com/products/ufdbguard.html
>
> But I repeat: this is NOT magic button "Disable all". This is
relatively effective tool to block categories.
>
> This is only URL/HTTP based tool, which required some more forces to
use it with HTTPS.
> And this can't be other means to replace when it comes to other protocols.
>
> Squid is only HTTP/HTTPS proxy. Not at all existing protocols.
>
> 05.05.16 3:18, Yuri Voinov ?????:
>
>
>       > Generally, for effective blocking of everything better design
>       would first consider - as everyone and everything is engeneered,
>
>       > and then look for the magic button "to disable all to hell."
>
>
>
>       > Then it becomes clear what is possible and what means - and
>       what is not.
>
>
>
>       > Especially P2P - this is at all not about Squid.
>
>
>
>       > 05.05.16 3:11, Yuri Voinov ?????:
>
>
>
>
>
>       >       > Facebook uses Akamai as background CDN, so you
>       need to block
>
>       >       Akamai (related URL's, which can be difficult, so
>       consider to use
>
>       >       Cisco NBAR DPI functionality). too in case to
>       completely block FB.
>
>
>
>
>
>
>
>       >       > YT still uses QUIC/SPDY, so read this
>
>
>
>
>
>
>
>
>
>
>       http://wiki.squid-cache.org/KnowledgeBase/Block%20QUIC%20protocol
>
>
>
>
>
>
>
>       >       > About P2P/Torrents said enough here
>
>
>
>
>
>
>
>       >       >
>       http://wiki.squid-cache.org/ConfigExamples/TorrentFiltering
>
>
>
>
>
>
>
>       >       > Note: Using Cisco NBAR required valid service
>       contract.
>
>       >       Protocol packs is not lying at all angles, and are
>       updated
>
>       >       monthly.
>
>
>
>
>
>
>
>
>
>
>
>       >       > 05.05.16 3:04, Maile Halatuituia ?????:
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > ?Someone with ideas on how to block
>
>       >       Facebook,Youtube, P2P
>
>
>
>       >       >       Traffic though my squid box. Facebook seems
>       to be
>
>       >       working but
>
>
>
>       >       >       likely some users bypass to youtube.com and
>       the rest
>
>       >       are blocked.
>
>
>
>       >       >       Also am looking to block P2P traffic , BITS
>       proticols,
>
>       >       etc etc
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > Cheers
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > Confidentiality Notice: This email
>       (including any
>
>       >       attachment)
>
>
>
>       >       >       is intended for internal use only. Any
>       unauthorized
>
>       >       use,
>
>
>
>       >       >       dissemination or copying of the content is
>       prohibited.
>
>       >       If you are
>
>
>
>       >       >       not the intended recipient and have received
>       this
>
>       >       e-mail in error,
>
>
>
>       >       >       please notify the sender by email and delete
>       this email
>
>       >       and any
>
>
>
>       >       >       attachment.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >
>       _______________________________________________
>
>
>
>
>
>
>
>       >       >       > squid-users mailing list
>
>
>
>
>
>
>
>       >       >       > squid-users at lists.squid-cache.org
>
>
>
>
>
>
>
>       >       >       >
>       http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>
>
>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXKmmSAAoJENNXIZxhPexG2jQIAJ5pQcfnv12LW2wg7ygamFZt
+ms5HjYM+/vB0k7Zg5lxp/cnJeKEFV3cGH4fPFHekh0Qt3sL1ttzauqfnf0rOELA
xFg+7XuQ8VgXF7+eBqmnvu2k7yjDqE8OjJUcssiBEmBvRQFFLSclAuyM9gWIKBDT
VPN9XkvwPN2zo5NsBg/7zgFUmKfant1pWNh/2bObBoUo3+kL4bGzPfDUoO251RxU
mrZLff3rgAw9RdYhy5JX3AICYXke9CDrLZcQHJ/4BSlSpmYOq0YBHWqd+rqMEeZO
Zn7hQcpKd1Dw4XaEo6BuVy6Pg7aFXFiaPzzXsSPzKIWSYOIT9AcEppDBQKNppa8=
=tkwj
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160505/56c6f287/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160505/56c6f287/attachment.key>

From yvoinov at gmail.com  Wed May  4 21:42:48 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 5 May 2016 03:42:48 +0600
Subject: [squid-users] URL/P2P blocking
In-Reply-To: <fa999fb7-afea-d8a3-a5e8-3fe44c97f1d4@gmail.com>
References: <c8632cc0ab24487489fa93e3270630a2@mail.tcc.to>
 <f5770cc1-65a5-15ab-6f7e-5e582566bd18@gmail.com>
 <1960db35-8fb9-44b9-d6f3-f481e8a041ed@gmail.com>
 <4c034864-da21-cb7d-3fc3-8de5f4108b9b@gmail.com>
 <fa999fb7-afea-d8a3-a5e8-3fe44c97f1d4@gmail.com>
Message-ID: <6e5c3563-d725-7846-873f-54eb241ecf66@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Just for information:

http://pastebin.com/dBYV9Zzb

Here is completely actual Cisco NBAR filtering capabilities from one of
my front 2901 with IOS 15.5 + actual NBAR2 protocol pack.

Just take a look. You can see there P2P, Torrents, FB, YT, etc.etc.etc.

Not as Squid's antagonist - but just as attitional tools to filter.

Note: Cisco also has time-based ACL's.

05.05.16 3:28, Yuri Voinov ?????:
>
> Finally,
>
> read this thread too:
>
> http://www.spinics.net/lists/squid/msg81113.html
>
> Some questions already answered here.
>
> 05.05.16 3:26, Yuri Voinov ?????:
>
>
>       > As a part of solution I recommend (by my own experience)
>       consider to use this:
>
>
>
>       > https://www.urlfilterdb.com/products/ufdbguard.html
>
>
>
>       > But I repeat: this is NOT magic button "Disable all". This is
>       relatively effective tool to block categories.
>
>
>
>       > This is only URL/HTTP based tool, which required some more
>       forces to use it with HTTPS.
>
>       > And this can't be other means to replace when it comes to
>       other protocols.
>
>
>
>       > Squid is only HTTP/HTTPS proxy. Not at all existing
>       protocols.
>
>
>
>       > 05.05.16 3:18, Yuri Voinov ?????:
>
>
>
>
>
>       >       > Generally, for effective blocking of everything
>       better design
>
>       >       would first consider - as everyone and everything is
>       engeneered,
>
>
>
>       >       > and then look for the magic button "to disable all
>       to hell."
>
>
>
>
>
>
>
>       >       > Then it becomes clear what is possible and what
>       means - and
>
>       >       what is not.
>
>
>
>
>
>
>
>       >       > Especially P2P - this is at all not about Squid.
>
>
>
>
>
>
>
>       >       > 05.05.16 3:11, Yuri Voinov ?????:
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > Facebook uses Akamai as background CDN,
>       so you
>
>       >       need to block
>
>
>
>       >       >       Akamai (related URL's, which can be
>       difficult, so
>
>       >       consider to use
>
>
>
>       >       >       Cisco NBAR DPI functionality). too in case
>       to
>
>       >       completely block FB.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > YT still uses QUIC/SPDY, so read this
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       http://wiki.squid-cache.org/KnowledgeBase/Block%20QUIC%20protocol
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > About P2P/Torrents said enough here
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >
>
>
>       http://wiki.squid-cache.org/ConfigExamples/TorrentFiltering
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > Note: Using Cisco NBAR required valid
>       service
>
>       >       contract.
>
>
>
>       >       >       Protocol packs is not lying at all angles,
>       and are
>
>       >       updated
>
>
>
>       >       >       monthly.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > 05.05.16 3:04, Maile Halatuituia ?????:
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > ?Someone with ideas on how
>       to block
>
>
>
>       >       >       Facebook,Youtube, P2P
>
>
>
>
>
>
>
>       >       >       >       Traffic though my squid box.
>       Facebook seems
>
>       >       to be
>
>
>
>       >       >       working but
>
>
>
>
>
>
>
>       >       >       >       likely some users bypass to
>       youtube.com and
>
>       >       the rest
>
>
>
>       >       >       are blocked.
>
>
>
>
>
>
>
>       >       >       >       Also am looking to block P2P
>       traffic , BITS
>
>       >       proticols,
>
>
>
>       >       >       etc etc
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > Cheers
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > Confidentiality Notice: This
>       email
>
>       >       (including any
>
>
>
>       >       >       attachment)
>
>
>
>
>
>
>
>       >       >       >       is intended for internal use
>       only. Any
>
>       >       unauthorized
>
>
>
>       >       >       use,
>
>
>
>
>
>
>
>       >       >       >       dissemination or copying of the
>       content is
>
>       >       prohibited.
>
>
>
>       >       >       If you are
>
>
>
>
>
>
>
>       >       >       >       not the intended recipient and
>       have received
>
>       >       this
>
>
>
>       >       >       e-mail in error,
>
>
>
>
>
>
>
>       >       >       >       please notify the sender by email
>       and delete
>
>       >       this email
>
>
>
>       >       >       and any
>
>
>
>
>
>
>
>       >       >       >       attachment.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >
>
>       >       _______________________________________________
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       > squid-users mailing list
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >
>       squid-users at lists.squid-cache.org
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >       >
>
>       >       http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXKmzYAAoJENNXIZxhPexGPB4H/1YUfoeFVgVChaD1qj/8EEhE
apmfM15P+5Aia3qJQLWCMTTgnA206sj8KglnxBWPS/LsC+kMEFW/d62W2BAH9POv
xDfsZ/qn4N2YbiKbqa+2ul3lY2OGCEb3nZY/ZiRy9JBfK+vrh3ZArcapEuWwMrKw
mDqC/EAtbaWvJz+m/zy1mPCfOHEe59N1CV/PZuqOp20a4KsISLxvWXEyTZ2vXt9a
P2DDhl1+VeTE48NSv8p8WB6Aam7tdp3wxpN8mMubMhOYs6Bf+KOHEZmKm25ZrpgE
4WVXbO3OBb3Zs73tF1LKmu3p/Hm46AUn733NDPFI9+CUp3QxN0QYdh1C23H8GYA=
=aCxH
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160505/604da674/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160505/604da674/attachment.key>

From serdebronce at gmail.com  Thu May  5 13:06:22 2016
From: serdebronce at gmail.com (Ser de Bronce)
Date: Thu, 5 May 2016 16:06:22 +0300
Subject: [squid-users] Is there a way to allow connection according to
 user certificate?
In-Reply-To: <4f0d4c4f-b841-23df-2c50-007b3cd82fef@gmail.com>
References: <CABzQUcSexB8JAwGq92mAv4KBJheWZaKFcmrWgKQxBavw7W0XkA@mail.gmail.com>
 <7dd98650-0b67-dc19-3437-b507d6590e85@treenet.co.nz>
 <4f0d4c4f-b841-23df-2c50-007b3cd82fef@gmail.com>
Message-ID: <CABzQUcRNrfGeX8nkLAUEpyeGYT-FJOfJcjROHz6qBvWOskO_Lg@mail.gmail.com>

Dear Amos and Yuri, thanks a lot for your answers.

Sorry for the mess, I'm novice here.
As it turned out my proxy is not transparent...

By "some reasons" I meant clients' experience reasons, let me explain.

I use explicit proxy and my clients connect to proxy using iPhone only.
I installed self-signed certificate on every iPhone and made login/pass
authentication.
It works perfect for wi-fi connection, because in this case iPhone gives a
possibility to specify proxy domain, port, login and password.
However to make them connect to proxy using mobile internet I had to
install APN profile on each iPhone. Inside APN profile I can specify domain
and port, but not login and pass (APN doesn't have such settings). So when
client opens browser using mobile internet he is asked for login/pass every
time. This situation is not appropriate for me so I can't use login/pass.

I'm thinking that maybe it's possible to replace login/pass authentication
with certificate authentication.
I want to authenticate users using a digital certificate they already have
on their iPhone.

I found some articles about certificate authentication for reverse proxy,
but can't find anything about explicit one.
Is it possible?

Best Regards,
Sergey
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160505/cffc1dc6/attachment.htm>

From yvoinov at gmail.com  Thu May  5 13:13:50 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 5 May 2016 19:13:50 +0600
Subject: [squid-users] Is there a way to allow connection according to
 user certificate?
In-Reply-To: <CABzQUcRNrfGeX8nkLAUEpyeGYT-FJOfJcjROHz6qBvWOskO_Lg@mail.gmail.com>
References: <CABzQUcSexB8JAwGq92mAv4KBJheWZaKFcmrWgKQxBavw7W0XkA@mail.gmail.com>
 <7dd98650-0b67-dc19-3437-b507d6590e85@treenet.co.nz>
 <4f0d4c4f-b841-23df-2c50-007b3cd82fef@gmail.com>
 <CABzQUcRNrfGeX8nkLAUEpyeGYT-FJOfJcjROHz6qBvWOskO_Lg@mail.gmail.com>
Message-ID: <ce4d615e-c3a9-9d04-ba3a-2b88b0e1a368@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


05.05.16 19:06, Ser de Bronce ?????:
> Dear Amos and Yuri, thanks a lot for your answers.
>
> Sorry for the mess, I'm novice here.
> As it turned out my proxy is not transparent...
>
> By "some reasons" I meant clients' experience reasons, let me explain.
>
> I use explicit proxy and my clients connect to proxy using iPhone only.
> I installed self-signed certificate on every iPhone and made
login/pass authentication.
> It works perfect for wi-fi connection, because in this case iPhone
gives a possibility to specify proxy domain, port, login and password.
> However to make them connect to proxy using mobile internet I had to
install APN profile on each iPhone. Inside APN profile I can specify
domain and port, but not login and pass (APN doesn't have such
settings). So when client opens browser using mobile internet he is
asked for login/pass every time. This situation is not appropriate for
me so I can't use login/pass.
But this is the default behaviour for proxy with auth.

I still do not understand the purpose for which authentication is required?
>
> I'm thinking that maybe it's possible to replace login/pass
authentication with certificate authentication.
> I want to authenticate users using a digital certificate they already
have on their iPhone.
>
> I found some articles about certificate authentication for reverse
proxy, but can't find anything about explicit one.

Reverse proxy is different thing against forwarding/transparent proxy.

AFAIK there is no solution you asked.

But you can be first.

I see this:

1. You can write external auth helper, with Perl/Pyton/etc. for
authentification.
2. You can setup DHCP with 252 option for push proxy.pac to your clients.
3. You can tell us about success ;)


> Is it possible?
In theory, everything is possible, which does not contradict the laws of
physics. :)
>
> Best Regards,
> Sergey
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXK0cOAAoJENNXIZxhPexGUG4H/3uMpUgrRnO1kILD+jGr96+4
7JVAm6NUrmnzseYLz2BkXtWPCb2fWxsOoQOWXdwHZR9YtpsM6aSFG+zG0nRzGWFs
/nicGIThegKRfD6ONhumRPKzDKdIhEx+XSKcoaxB0q157ncTsgrazvoyLYetza+5
iTNSR30WNdqoslR5GlJDW4etTO88xfCu+trrhFI3yKFevzbq9xkrfBC06K0+RX2U
twaAHJToGRoiAhEsrhD9MwxxGj4E8NUYGvhaAfINyqSjXNJhQ0d4eTwTp18Dok13
ae/ake0f0aSnrCN7riBMS5iIINvwKMf/bTCibMGSJ1TVnr7B5K6RNVR3eqtQ0lU=
=pQ4f
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160505/c546a27b/attachment.key>

From squid3 at treenet.co.nz  Thu May  5 13:19:03 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 6 May 2016 01:19:03 +1200
Subject: [squid-users] Is there a way to allow connection according to
 user certificate?
In-Reply-To: <CABzQUcRNrfGeX8nkLAUEpyeGYT-FJOfJcjROHz6qBvWOskO_Lg@mail.gmail.com>
References: <CABzQUcSexB8JAwGq92mAv4KBJheWZaKFcmrWgKQxBavw7W0XkA@mail.gmail.com>
 <7dd98650-0b67-dc19-3437-b507d6590e85@treenet.co.nz>
 <4f0d4c4f-b841-23df-2c50-007b3cd82fef@gmail.com>
 <CABzQUcRNrfGeX8nkLAUEpyeGYT-FJOfJcjROHz6qBvWOskO_Lg@mail.gmail.com>
Message-ID: <8dd15635-c3a0-377d-692a-cddd8b739fae@treenet.co.nz>

On 6/05/2016 1:06 a.m., Ser de Bronce wrote:
> Dear Amos and Yuri, thanks a lot for your answers.
> 
> Sorry for the mess, I'm novice here.
> As it turned out my proxy is not transparent...
> 
> By "some reasons" I meant clients' experience reasons, let me explain.
> 
> I use explicit proxy and my clients connect to proxy using iPhone only.
> I installed self-signed certificate on every iPhone and made login/pass
> authentication.
> It works perfect for wi-fi connection, because in this case iPhone gives a
> possibility to specify proxy domain, port, login and password.
> However to make them connect to proxy using mobile internet I had to
> install APN profile on each iPhone. Inside APN profile I can specify domain
> and port, but not login and pass (APN doesn't have such settings). So when
> client opens browser using mobile internet he is asked for login/pass every
> time. This situation is not appropriate for me so I can't use login/pass.
> 
> I'm thinking that maybe it's possible to replace login/pass authentication
> with certificate authentication.
> I want to authenticate users using a digital certificate they already have
> on their iPhone.
> 
> I found some articles about certificate authentication for reverse proxy,
> but can't find anything about explicit one.
> Is it possible?

Squid can listen on an https_port for connections. The TLS settings to
challenge for client cert are the same for explicit proxy as you would
find for reverse-proxy.

What you will also find however is that browsers do not do TLS to
proxies, or if they do not without jumping through some other hoops
which are browser dependent.

IIRC;
* Chrome requires that it is started with certain command line options,
AND that a PAC file is used with https:// URI for the proxy detail.

* Firefox requires that PAC file are used with https:// URI for the
proxy detail AND limits the protocol spoken to those proxy to HTTP/2.

* Safari and IE - seem not to support TLS proxy at all yet AFAIK.

Amos



From yvoinov at gmail.com  Thu May  5 14:01:47 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 5 May 2016 20:01:47 +0600
Subject: [squid-users] Is there a way to allow connection according to
 user certificate?
In-Reply-To: <8dd15635-c3a0-377d-692a-cddd8b739fae@treenet.co.nz>
References: <CABzQUcSexB8JAwGq92mAv4KBJheWZaKFcmrWgKQxBavw7W0XkA@mail.gmail.com>
 <7dd98650-0b67-dc19-3437-b507d6590e85@treenet.co.nz>
 <4f0d4c4f-b841-23df-2c50-007b3cd82fef@gmail.com>
 <CABzQUcRNrfGeX8nkLAUEpyeGYT-FJOfJcjROHz6qBvWOskO_Lg@mail.gmail.com>
 <8dd15635-c3a0-377d-692a-cddd8b739fae@treenet.co.nz>
Message-ID: <91ffd35a-ec6c-ff31-0d8e-432352f516eb@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


05.05.16 19:19, Amos Jeffries ?????:
> On 6/05/2016 1:06 a.m., Ser de Bronce wrote:
>> Dear Amos and Yuri, thanks a lot for your answers.
>>
>> Sorry for the mess, I'm novice here.
>> As it turned out my proxy is not transparent...
>>
>> By "some reasons" I meant clients' experience reasons, let me explain.
>>
>> I use explicit proxy and my clients connect to proxy using iPhone only.
>> I installed self-signed certificate on every iPhone and made login/pass
>> authentication.
>> It works perfect for wi-fi connection, because in this case iPhone
gives a
>> possibility to specify proxy domain, port, login and password.
>> However to make them connect to proxy using mobile internet I had to
>> install APN profile on each iPhone. Inside APN profile I can specify
domain
>> and port, but not login and pass (APN doesn't have such settings). So
when
>> client opens browser using mobile internet he is asked for login/pass
every
>> time. This situation is not appropriate for me so I can't use login/pass.
>>
>> I'm thinking that maybe it's possible to replace login/pass
authentication
>> with certificate authentication.
>> I want to authenticate users using a digital certificate they already
have
>> on their iPhone.
>>
>> I found some articles about certificate authentication for reverse proxy,
>> but can't find anything about explicit one.
>> Is it possible?
>
> Squid can listen on an https_port for connections. The TLS settings to
> challenge for client cert are the same for explicit proxy as you would
> find for reverse-proxy.
>
> What you will also find however is that browsers do not do TLS to
> proxies, or if they do not without jumping through some other hoops
> which are browser dependent.
>
> IIRC;
> * Chrome requires that it is started with certain command line options,
> AND that a PAC file is used with https:// URI for the proxy detail.
>
> * Firefox requires that PAC file are used with https:// URI for the
> proxy detail AND limits the protocol spoken to those proxy to HTTP/2.
In my personal opinion, that everywhere for the crazy idea to push HTTPS
- and where it is necessary and where it is not necessary. If a hammer -
everything looks like a nail.
>
>
> * Safari and IE - seem not to support TLS proxy at all yet AFAIK.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXK1JLAAoJENNXIZxhPexGW/MIAM0aKjIOY4/3o8iYisQIQQjX
e10w0d7ygLbX4cHabzURwcR5J1qaoPE1VnK5tugybsEBUYLdj4EMRQ/FEqUIhC/+
aWodGOWneZ8QEFh7U+56g+fZLzUolbtJidjl/9JwmB8iWKSNgffLEgrTG3GIh4Jt
o7AfkqNejKqyaSio0iY1QygqI+LKBUVTpPdQIQ4950Ulql+rN55k7mktia04ZC35
bxM3p060aE5SG6YmEqjxOi1mAceMW1SmAESMKAN/GzuRc3CK4TUzqlXcxfScLEwQ
Il6HH0r+ovh19cj5dBZIVAS3cVgK1zvdsVREoZ4HUJIS/0n3dDUgbnP3hpXvGtI=
=2GpD
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160505/5308d8c0/attachment.key>

From serdebronce at gmail.com  Thu May  5 16:07:35 2016
From: serdebronce at gmail.com (Ser de Bronce)
Date: Thu, 5 May 2016 19:07:35 +0300
Subject: [squid-users] Is there a way to allow connection according to
 user certificate?
In-Reply-To: <91ffd35a-ec6c-ff31-0d8e-432352f516eb@gmail.com>
References: <CABzQUcSexB8JAwGq92mAv4KBJheWZaKFcmrWgKQxBavw7W0XkA@mail.gmail.com>
 <7dd98650-0b67-dc19-3437-b507d6590e85@treenet.co.nz>
 <4f0d4c4f-b841-23df-2c50-007b3cd82fef@gmail.com>
 <CABzQUcRNrfGeX8nkLAUEpyeGYT-FJOfJcjROHz6qBvWOskO_Lg@mail.gmail.com>
 <8dd15635-c3a0-377d-692a-cddd8b739fae@treenet.co.nz>
 <91ffd35a-ec6c-ff31-0d8e-432352f516eb@gmail.com>
Message-ID: <CABzQUcRqX2c0MNTcCKP-c3N2dWubQ1YTrRbWZ3fgUhCVGSVELg@mail.gmail.com>

Yuri,

> But this is the default behaviour for proxy with auth

I didn't know that.
Initially I tested on iPhone using wi-fi connection and as I said earlier
there are wi-fi proxy settings on iPhone so user should type them only once
and then each browser and app works without asking login/pass.

> I still do not understand the purpose for which authentication is
required?

This proxy will be available from anywhere, but I need to prevent usage of
this proxy by anyone, except my clients. This is the main purpose.
I had a plan to give login and password to each client, but as I said
earlier this is not possible because of user experience reasons.
Also I can't rely on MAC, IP or other indirect attributes.

So I try to find other ways to check if user who is connecting to proxy is
my client or not.
Right now I see only two ways here:
1) authentication by proxy server using certificates
2) authentication by some other server which accept certificates and then
redirecting connections to proxy.

As I said I'm novice and didn't use proxy earlier. Maybe you know better
solution.

Best regards,
Sergey
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160505/e2063cec/attachment.htm>

From yvoinov at gmail.com  Thu May  5 16:17:13 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 5 May 2016 22:17:13 +0600
Subject: [squid-users] Is there a way to allow connection according to
 user certificate?
In-Reply-To: <CABzQUcRqX2c0MNTcCKP-c3N2dWubQ1YTrRbWZ3fgUhCVGSVELg@mail.gmail.com>
References: <CABzQUcSexB8JAwGq92mAv4KBJheWZaKFcmrWgKQxBavw7W0XkA@mail.gmail.com>
 <7dd98650-0b67-dc19-3437-b507d6590e85@treenet.co.nz>
 <4f0d4c4f-b841-23df-2c50-007b3cd82fef@gmail.com>
 <CABzQUcRNrfGeX8nkLAUEpyeGYT-FJOfJcjROHz6qBvWOskO_Lg@mail.gmail.com>
 <8dd15635-c3a0-377d-692a-cddd8b739fae@treenet.co.nz>
 <91ffd35a-ec6c-ff31-0d8e-432352f516eb@gmail.com>
 <CABzQUcRqX2c0MNTcCKP-c3N2dWubQ1YTrRbWZ3fgUhCVGSVELg@mail.gmail.com>
Message-ID: <acf0c189-dd1f-0a14-7428-75961734d65c@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


05.05.16 22:07, Ser de Bronce ?????:
> Yuri,
>
> > But this is the default behaviour for proxy with auth
>
> I didn't know that.
> Initially I tested on iPhone using wi-fi connection and as I said
earlier there are wi-fi proxy settings on iPhone so user should type
them only once and then each browser and app works without asking
login/pass.
>
> > I still do not understand the purpose for which authentication is
required?
>
> This proxy will be available from anywhere, but I need to prevent
usage of this proxy by anyone, except my clients. This is the main purpose.
> I had a plan to give login and password to each client, but as I said
earlier this is not possible because of user experience reasons.
> Also I can't rely on MAC, IP or other indirect attributes.
Now understand. I see no better solution except external auth helper.
The only thing: there is not exists now in Squid with ready-to-use. It
contains only template.

>
> So I try to find other ways to check if user who is connecting to
proxy is my client or not.
> Right now I see only two ways here:
> 1) authentication by proxy server using certificates
> 2) authentication by some other server which accept certificates and
then redirecting connections to proxy.
Yep, something like OpenLDAP, OpenVPN or combination.
>
> As I said I'm novice and didn't use proxy earlier. Maybe you know
better solution.
Hm. Consider this:
http://wiki.squid-cache.org/ConfigExamples#Captive_Portal_features
>
> Best regards,
> Sergey

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXK3IJAAoJENNXIZxhPexGKmwH/1JGpw1jD/GYGbuRHlOwuAP7
QU69ZZh0qd2T188Vs2gFgd9tc0dvVbxhkYljQPjdK2stDyQ5Ahzu/x8ke/Wp8Hhr
vHa7xVx1l4IP1tD9oEzfST7CovldVXjsHJ9/VLyIap2Cfszjhg4JRXwTblJjfOAM
r7qUSgUlHDDGcTxhEjXFp0pnVbJzN3NZXjLhyiuSUFESabxcyGXQUOHQMatjrLBu
XuZ9zwUu+1tUW3o72nYUytdB1gYMwgQePezDIYm+TX51fGu96SBN3qLyO96iQtzl
Iz8gNrqvJ1gWHgXLiMWznEckbHEBI3VTck38/VFyIs2P2Fzv+5hBOTp9s15APCI=
=R0my
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160505/828ec2a8/attachment.key>

From fourtrials at gmail.com  Fri May  6 04:05:07 2016
From: fourtrials at gmail.com (Victor Hugo)
Date: Fri, 6 May 2016 14:05:07 +1000
Subject: [squid-users] Filtering HTTPS URLs
In-Reply-To: <56BD4EF5.6050904@treenet.co.nz>
References: <CAN-hnF2ajC7zHpdxbw0jKMaHn9LStK_Ef-B3=9vr7fP=hKvZdw@mail.gmail.com>
 <56BC4D7D.6070505@treenet.co.nz>
 <CAAa1tfEXPqrpx-8XqdG_4Gip0ZHFz+mpSEJuCYSnSFTo5HzSTQ@mail.gmail.com>
 <CAN-hnF3CBA4smqroAcZ2o=7SXB7OM3NNHFxvXtSWon8cjay6YA@mail.gmail.com>
 <56BD4EF5.6050904@treenet.co.nz>
Message-ID: <CAN-hnF3H180fbrGSd_TWPcN0XERoyXUAVELuE-X1X0QoEg86iA@mail.gmail.com>

Hi,

I have now tested this with squid 4.0.9 and can confirm that I encounter
the same problem and get the same results.

Victor

On Fri, Feb 12, 2016 at 1:18 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 12/02/2016 11:37 a.m., Victor Hugo wrote:
> > Hi Panda,
> >
> > Thanks for the suggestion.
> >
> > I'm assuming from Panda and Amos's responses that what I'm trying to
> > achieve should actually be possible?
>
> Yes. Once the request message has been bumped there is no difference to
> Squid between it and a regular plain-text message with https:// URL.
>
> So... its probably somethign related to the bump. But why that says
> DENIED then has a followup is weird.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160506/70277012/attachment.htm>

From squid3 at treenet.co.nz  Fri May  6 05:02:41 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 6 May 2016 17:02:41 +1200
Subject: [squid-users] Is there a way to allow connection according to
 user certificate?
In-Reply-To: <CABzQUcRqX2c0MNTcCKP-c3N2dWubQ1YTrRbWZ3fgUhCVGSVELg@mail.gmail.com>
References: <CABzQUcSexB8JAwGq92mAv4KBJheWZaKFcmrWgKQxBavw7W0XkA@mail.gmail.com>
 <7dd98650-0b67-dc19-3437-b507d6590e85@treenet.co.nz>
 <4f0d4c4f-b841-23df-2c50-007b3cd82fef@gmail.com>
 <CABzQUcRNrfGeX8nkLAUEpyeGYT-FJOfJcjROHz6qBvWOskO_Lg@mail.gmail.com>
 <8dd15635-c3a0-377d-692a-cddd8b739fae@treenet.co.nz>
 <91ffd35a-ec6c-ff31-0d8e-432352f516eb@gmail.com>
 <CABzQUcRqX2c0MNTcCKP-c3N2dWubQ1YTrRbWZ3fgUhCVGSVELg@mail.gmail.com>
Message-ID: <a6e9da06-c59c-b9ac-c3bf-908185c9d1ff@treenet.co.nz>

On 6/05/2016 4:07 a.m., Ser de Bronce wrote:
> Yuri,
> 
>> But this is the default behaviour for proxy with auth
> 
> I didn't know that.
> Initially I tested on iPhone using wi-fi connection and as I said earlier
> there are wi-fi proxy settings on iPhone so user should type them only once
> and then each browser and app works without asking login/pass.

Well, Yuri is only half-right there. It is and it isn't.

The browser initial request may or not have credentials (secure clients
do not send any up front, insecure clients do). If it doesn't the proxy
responds with a 407 requesting them.

The browser then is expected to find some. How is left up to the browser
- but the expectation is that it will try the APN assigned credentials
and/or its own credentials store *before* bothering the user with a popup.



> 
>> I still do not understand the purpose for which authentication is
> required?
> 
> This proxy will be available from anywhere, but I need to prevent usage of
> this proxy by anyone, except my clients. This is the main purpose.
> I had a plan to give login and password to each client, but as I said
> earlier this is not possible because of user experience reasons.


That is a device/browser bug. The above described sequence should be
happening, but apparently isn't. Since it is the browser part of the
auth which is falling down there is very little Squid can do.
 The few things Squid can do require all this happening over a LAN
environment and do not work across WAN / Internet connections.

Sounds like you are stuck between a rock and a hard place. I'm a bit
puzzled about how you expect APN settings to be pushed to devices
connected via another service provider across the Internet.


> Also I can't rely on MAC, IP or other indirect attributes.
> 
> So I try to find other ways to check if user who is connecting to proxy is
> my client or not.
> Right now I see only two ways here:
> 1) authentication by proxy server using certificates
> 2) authentication by some other server which accept certificates and then
> redirecting connections to proxy.
> 
> As I said I'm novice and didn't use proxy earlier. Maybe you know better
> solution.

No, those are your choices.

Amos



From fourtrials at gmail.com  Fri May  6 05:51:06 2016
From: fourtrials at gmail.com (Victor Hugo)
Date: Fri, 6 May 2016 15:51:06 +1000
Subject: [squid-users] Filtering HTTPS URLs
In-Reply-To: <CAN-hnF2ajC7zHpdxbw0jKMaHn9LStK_Ef-B3=9vr7fP=hKvZdw@mail.gmail.com>
References: <CAN-hnF2ajC7zHpdxbw0jKMaHn9LStK_Ef-B3=9vr7fP=hKvZdw@mail.gmail.com>
Message-ID: <CAN-hnF3hOSVHbJ6HHP5d16uXU9HeCyg6ff9oCj-fmoE-LkLREQ@mail.gmail.com>

Here's a strange one for you though, if I change:
acl whitelist-regex url_regex -i reddit.com/r/news

to:
acl whitelist-regex url_regex -i reddit\.com\/r\/news www\.reddit\.com\:443

it works every 2nd time but the match is too greedy and allows
www.reddit.com/r/anything every 2nd time.

Victor

it

On Thu, Feb 11, 2016 at 10:05 AM, Victor Hugo <fourtrials at gmail.com> wrote:

> Hi,
>
> I was wondering if it is possible to filter HTTPS URLs using squid (for
> example to blacklist reddit.com but allow https://www.reddit.com/r/news/)?
>
> I thought this may be possible using ssl_bump and url_regex. I have been
> trying this using squid 3.5.13 but with no success.
>
> Here is the squid configuration that I have tried but doesn't seem to work
> (it works for http sites though):
>
> acl localnet src 10.0.0.0/8 # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12 # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
> machines
>
> acl SSL_ports port 443
> acl Safe_ports port 80 # http
> acl Safe_ports port 21 # ftp
> acl Safe_ports port 443 # https
> acl Safe_ports port 70 # gopher
> acl Safe_ports port 210 # wais
> acl Safe_ports port 1025-65535 # unregistered ports
> acl Safe_ports port 280 # http-mgmt
> acl Safe_ports port 488 # gss-http
> acl Safe_ports port 591 # filemaker
> acl Safe_ports port 777 # multiling http
> acl CONNECT method CONNECT
>
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
>
> acl whitelist-regex url_regex -i reddit.com/r/news
> http_port 3129 ssl-bump
> cert=/opt/squid-3.5.13/etc/squid3/ssl_cert/myCA.pem
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> acl bump_sites ssl::server_name .reddit.com
> ssl_bump bump bump_sites
> ssl_bump splice !bump_sites
> http_access allow whitelist-regex
> http_access allow localhost
> http_access deny all
> coredump_dir /opt/squid-3.5.13/var/spool/squid3
> refresh_pattern ^ftp: 1440 20% 10080
> refresh_pattern ^gopher: 1440 0% 1440
> refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
> refresh_pattern . 0 20% 4320
> pinger_enable off
> Relevant access.log output (IP addresses redacted to x.x.x.x):
> 1455145755.589      0 x.x.x.x TCP_DENIED/200 0 CONNECT www.reddit.com:443
> - HIER_NONE/- -
> 1455145755.669      0 x.x.x.x TAG_NONE/403 4011 GET
> https://www.reddit.com/r/news - HIER_NONE/- text/html
> 1455145755.782      0 x.x.x.x TCP_DENIED/200 0 CONNECT www.reddit.com:443
> - HIER_NONE/- -
>
> I don't want to whitelist the dstdomain .reddit.com
> (i.e whitelist-ssldomain dstdomain .reddit.com) as that would allow
> access to all of the other subreddits.
>
> Appreciate any help or suggestions you have. Thanks.
>
> Victor
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160506/8a654dda/attachment.htm>

From squid3 at treenet.co.nz  Fri May  6 07:00:17 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 6 May 2016 19:00:17 +1200
Subject: [squid-users] Filtering HTTPS URLs
In-Reply-To: <CAN-hnF3hOSVHbJ6HHP5d16uXU9HeCyg6ff9oCj-fmoE-LkLREQ@mail.gmail.com>
References: <CAN-hnF2ajC7zHpdxbw0jKMaHn9LStK_Ef-B3=9vr7fP=hKvZdw@mail.gmail.com>
 <CAN-hnF3hOSVHbJ6HHP5d16uXU9HeCyg6ff9oCj-fmoE-LkLREQ@mail.gmail.com>
Message-ID: <93793088-1b0b-ef4c-181b-4c991deef87b@treenet.co.nz>

On 6/05/2016 5:51 p.m., Victor Hugo wrote:
> Here's a strange one for you though, if I change:
> acl whitelist-regex url_regex -i reddit.com/r/news
> 
> to:
> acl whitelist-regex url_regex -i reddit\.com\/r\/news www\.reddit\.com\:443
> 
> it works every 2nd time but the match is too greedy and allows
> www.reddit.com/r/anything every 2nd time.
> 

That first regex pattern requires a path "/r/news" to exist. CONNECT
messages do not have paths.

That second pattern you are now adding matches (and thus allows) the
CONNECT message authority-URI built from the traffic SNI details.

They are two different regex patterns so if *either one* matches the ACL
test will be a match.


Try adding this line *after* the default "deny CONNECT !SSL_ports" line:
 acl reddit dstdomain .reddit.com
 http_access allow CONNECT SSL_ports reddit

That should allow the CONNECT's stuff to happen and your ssl_bump and
http_access rules then handle the HTTPS.


Amos


> Victor
> 
> it
> 
> On Thu, Feb 11, 2016 at 10:05 AM, Victor Hugo <fourtrials at gmail.com> wrote:
> 
>> Hi,
>>
>> I was wondering if it is possible to filter HTTPS URLs using squid (for
>> example to blacklist reddit.com but allow https://www.reddit.com/r/news/)?
>>
>> I thought this may be possible using ssl_bump and url_regex. I have been
>> trying this using squid 3.5.13 but with no success.
>>
>> Here is the squid configuration that I have tried but doesn't seem to work
>> (it works for http sites though):
>>
>> acl localnet src 10.0.0.0/8 # RFC1918 possible internal network
>> acl localnet src 172.16.0.0/12 # RFC1918 possible internal network
>> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
>> acl localnet src fc00::/7       # RFC 4193 local private network range
>> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
>> machines
>>
>> acl SSL_ports port 443
>> acl Safe_ports port 80 # http
>> acl Safe_ports port 21 # ftp
>> acl Safe_ports port 443 # https
>> acl Safe_ports port 70 # gopher
>> acl Safe_ports port 210 # wais
>> acl Safe_ports port 1025-65535 # unregistered ports
>> acl Safe_ports port 280 # http-mgmt
>> acl Safe_ports port 488 # gss-http
>> acl Safe_ports port 591 # filemaker
>> acl Safe_ports port 777 # multiling http
>> acl CONNECT method CONNECT
>>
>> http_access deny !Safe_ports
>> http_access deny CONNECT !SSL_ports
>> http_access allow localhost manager
>> http_access deny manager
>>
>> acl whitelist-regex url_regex -i reddit.com/r/news
>> http_port 3129 ssl-bump
>> cert=/opt/squid-3.5.13/etc/squid3/ssl_cert/myCA.pem
>> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>> acl bump_sites ssl::server_name .reddit.com
>> ssl_bump bump bump_sites
>> ssl_bump splice !bump_sites
>> http_access allow whitelist-regex
>> http_access allow localhost
>> http_access deny all
>> coredump_dir /opt/squid-3.5.13/var/spool/squid3
>> refresh_pattern ^ftp: 1440 20% 10080
>> refresh_pattern ^gopher: 1440 0% 1440
>> refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
>> refresh_pattern . 0 20% 4320
>> pinger_enable off
>> Relevant access.log output (IP addresses redacted to x.x.x.x):
>> 1455145755.589      0 x.x.x.x TCP_DENIED/200 0 CONNECT www.reddit.com:443
>> - HIER_NONE/- -
>> 1455145755.669      0 x.x.x.x TAG_NONE/403 4011 GET
>> https://www.reddit.com/r/news - HIER_NONE/- text/html
>> 1455145755.782      0 x.x.x.x TCP_DENIED/200 0 CONNECT www.reddit.com:443
>> - HIER_NONE/- -
>>
>> I don't want to whitelist the dstdomain .reddit.com
>> (i.e whitelist-ssldomain dstdomain .reddit.com) as that would allow
>> access to all of the other subreddits.
>>
>> Appreciate any help or suggestions you have. Thanks.
>>
>> Victor
>>
> 



From sampei02 at tiscali.it  Fri May  6 12:31:42 2016
From: sampei02 at tiscali.it (Sampei)
Date: Fri, 06 May 2016 14:31:42 +0200
Subject: [squid-users] ldap authentication with encrypted credentials
In-Reply-To: <658f257a-554a-3752-ae29-bc967d6fb091@treenet.co.nz>
References: <76022224f8c7d2b77223069db3b461e2@tiscali.it>
 <f94e0f42-11b6-6489-03b7-220e289cf61f@treenet.co.nz>
 <580d1f7f1067229df5608be32af98124@tiscali.it>
 <658f257a-554a-3752-ae29-bc967d6fb091@treenet.co.nz>
Message-ID: <1f8d2934596ba382031630622a55bcb7@tiscali.it>

  I'm thinking to implement Basic authentication for all clients
because it's easier with my outdated systems.
In squid.conf can I use
one of these three access methods for http_access for each_client? 

1-
only based on AD user authentication
2- only based on IP address
3- both
based both on AD user authentication and on IP address (both 1 and 2
options)

Il 04.05.2016 14:23 Amos Jeffries ha scritto: 

>>>>> Look
into Negotiate/Kerberos authentication. You will need that for the Win7
and Win10 clients anyway
>> For Windows 7/10 clients, the Basic
authentication (Squid 2.7) with LDAP helper will not able to work ?
While Kerberos will work both with older clients and newer ones?
> 
>
Yes they all still support Basic, but you said that was not desirable.
>

> Amos
  


Con Tutto Incluso Light navighi fino a 20 Mega senza limiti e chiami a 0 cent/minuto verso tutti i fissi e i mobili in Italia a 19,95 euro/mese per sempre. In piu' ora l'attivazione e' Gratis! http://casa.tiscali.it/

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160506/f072a2fd/attachment.htm>

From reet.vyas28 at gmail.com  Fri May  6 13:09:09 2016
From: reet.vyas28 at gmail.com (Reet Vyas)
Date: Fri, 6 May 2016 18:39:09 +0530
Subject: [squid-users] SSL certifcate on android device not working
Message-ID: <CAA8ViV9Y5BXySMYBGXuCbm9YNH4W2sn2=m4sN4+N8GSmt2g6Aw@mail.gmail.com>

Hi

I have squid ssl bump working but when I added squid.crt  to my android ,
it not working but working with Iphone cause they have certificate
installer app , I dont know exact issue cause my apps are on working . I
have installed squid.crt on mobile browsers ,internet is working but not
any app like youtube, instagram etc

Please let know what issue with certificate installation on Android devices
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160506/214005f8/attachment.htm>

From acrow at integrafin.co.uk  Fri May  6 13:11:54 2016
From: acrow at integrafin.co.uk (Alex Crow)
Date: Fri, 6 May 2016 14:11:54 +0100
Subject: [squid-users] SSL certifcate on android device not working
In-Reply-To: <CAA8ViV9Y5BXySMYBGXuCbm9YNH4W2sn2=m4sN4+N8GSmt2g6Aw@mail.gmail.com>
References: <CAA8ViV9Y5BXySMYBGXuCbm9YNH4W2sn2=m4sN4+N8GSmt2g6Aw@mail.gmail.com>
Message-ID: <572C981A.6070307@integrafin.co.uk>

On 06/05/16 14:09, Reet Vyas wrote:
> Hi
>
> I have squid ssl bump working but when I added squid.crt  to my 
> android , it not working but working with Iphone cause they have 
> certificate installer app , I dont know exact issue cause my apps are 
> on working . I have installed squid.crt on mobile browsers ,internet 
> is working but not any app like youtube, instagram etc
>
> Please let know what issue with certificate installation on Android 
> devices
>

I think the problem is simply that CA cert management on Android simply 
sucks. That is my experience, YMMV.

:-)

Alex

--
This message is intended only for the addressee and may contain
confidential information. Unless you are that person, you may not
disclose its contents or use it in any way and are requested to delete
the message along with any attachments and notify us immediately.
This email is not intended to, nor should it be taken to, constitute advice.
The information provided is correct to our knowledge & belief and must not
be used as a substitute for obtaining tax, regulatory, investment, legal or
any other appropriate advice.

"Transact" is operated by Integrated Financial Arrangements Ltd.
29 Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900 Fax: (020) 7608 5300.
(Registered office: as above; Registered in England and Wales under
number: 3727592). Authorised and regulated by the Financial Conduct
Authority (entered on the Financial Services Register; no. 190856).


From yvoinov at gmail.com  Fri May  6 13:21:40 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 6 May 2016 19:21:40 +0600
Subject: [squid-users] SSL certifcate on android device not working
In-Reply-To: <572C981A.6070307@integrafin.co.uk>
References: <CAA8ViV9Y5BXySMYBGXuCbm9YNH4W2sn2=m4sN4+N8GSmt2g6Aw@mail.gmail.com>
 <572C981A.6070307@integrafin.co.uk>
Message-ID: <05bb9084-31d5-309c-80b3-33bae38f15d5@gmail.com>

Android sucks and must die, yes :)


06.05.16 19:11, Alex Crow ?????:
> On 06/05/16 14:09, Reet Vyas wrote:
>> Hi
>>
>> I have squid ssl bump working but when I added squid.crt  to my 
>> android , it not working but working with Iphone cause they have 
>> certificate installer app , I dont know exact issue cause my apps are 
>> on working . I have installed squid.crt on mobile browsers ,internet 
>> is working but not any app like youtube, instagram etc
>>
>> Please let know what issue with certificate installation on Android 
>> devices
>>
>
> I think the problem is simply that CA cert management on Android 
> simply sucks. That is my experience, YMMV.
>
> :-)
>
> Alex
>
> -- 
> This message is intended only for the addressee and may contain
> confidential information. Unless you are that person, you may not
> disclose its contents or use it in any way and are requested to delete
> the message along with any attachments and notify us immediately.
> This email is not intended to, nor should it be taken to, constitute 
> advice.
> The information provided is correct to our knowledge & belief and must 
> not
> be used as a substitute for obtaining tax, regulatory, investment, 
> legal or
> any other appropriate advice.
>
> "Transact" is operated by Integrated Financial Arrangements Ltd.
> 29 Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900 Fax: (020) 
> 7608 5300.
> (Registered office: as above; Registered in England and Wales under
> number: 3727592). Authorised and regulated by the Financial Conduct
> Authority (entered on the Financial Services Register; no. 190856).
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From reet.vyas28 at gmail.com  Fri May  6 13:26:59 2016
From: reet.vyas28 at gmail.com (Reet Vyas)
Date: Fri, 6 May 2016 18:56:59 +0530
Subject: [squid-users] SSL certifcate on android device not working
In-Reply-To: <05bb9084-31d5-309c-80b3-33bae38f15d5@gmail.com>
References: <CAA8ViV9Y5BXySMYBGXuCbm9YNH4W2sn2=m4sN4+N8GSmt2g6Aw@mail.gmail.com>
 <572C981A.6070307@integrafin.co.uk>
 <05bb9084-31d5-309c-80b3-33bae38f15d5@gmail.com>
Message-ID: <CAA8ViV983e86V+Xo-PpAXhX-EWgZtbttouAZg7hFnjS8ZwQykw@mail.gmail.com>

Please let me know if this possible or not?

On Fri, May 6, 2016 at 6:51 PM, Yuri Voinov <yvoinov at gmail.com> wrote:

> Android sucks and must die, yes :)
>
>
> 06.05.16 19:11, Alex Crow ?????:
>
> On 06/05/16 14:09, Reet Vyas wrote:
>>
>>> Hi
>>>
>>> I have squid ssl bump working but when I added squid.crt  to my android
>>> , it not working but working with Iphone cause they have certificate
>>> installer app , I dont know exact issue cause my apps are on working . I
>>> have installed squid.crt on mobile browsers ,internet is working but not
>>> any app like youtube, instagram etc
>>>
>>> Please let know what issue with certificate installation on Android
>>> devices
>>>
>>>
>> I think the problem is simply that CA cert management on Android simply
>> sucks. That is my experience, YMMV.
>>
>> :-)
>>
>> Alex
>>
>> --
>> This message is intended only for the addressee and may contain
>> confidential information. Unless you are that person, you may not
>> disclose its contents or use it in any way and are requested to delete
>> the message along with any attachments and notify us immediately.
>> This email is not intended to, nor should it be taken to, constitute
>> advice.
>> The information provided is correct to our knowledge & belief and must not
>> be used as a substitute for obtaining tax, regulatory, investment, legal
>> or
>> any other appropriate advice.
>>
>> "Transact" is operated by Integrated Financial Arrangements Ltd.
>> 29 Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900 Fax: (020) 7608
>> 5300.
>> (Registered office: as above; Registered in England and Wales under
>> number: 3727592). Authorised and regulated by the Financial Conduct
>> Authority (entered on the Financial Services Register; no. 190856).
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160506/843762e1/attachment.htm>

From rafael.akchurin at diladele.com  Fri May  6 14:01:59 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Fri, 6 May 2016 14:01:59 +0000
Subject: [squid-users] SSL certifcate on android device not working
In-Reply-To: <CAA8ViV983e86V+Xo-PpAXhX-EWgZtbttouAZg7hFnjS8ZwQykw@mail.gmail.com>
References: <CAA8ViV9Y5BXySMYBGXuCbm9YNH4W2sn2=m4sN4+N8GSmt2g6Aw@mail.gmail.com>
 <572C981A.6070307@integrafin.co.uk>
 <05bb9084-31d5-309c-80b3-33bae38f15d5@gmail.com>,
 <CAA8ViV983e86V+Xo-PpAXhX-EWgZtbttouAZg7hFnjS8ZwQykw@mail.gmail.com>
Message-ID: <595A02A7-1557-4DFD-8C50-79087C003FAB@diladele.com>

Not possible, see SSL certificate pinning in wikipedia, or at
http://docs.diladele.com/faq/squid/dropbox.html


Best regards,
Rafael

Op 6 mei 2016 om 14:27 heeft Reet Vyas <reet.vyas28 at gmail.com<mailto:reet.vyas28 at gmail.com>> het volgende geschreven:

Please let me know if this possible or not?

On Fri, May 6, 2016 at 6:51 PM, Yuri Voinov <yvoinov at gmail.com<mailto:yvoinov at gmail.com>> wrote:
Android sucks and must die, yes :)


06.05.16 19:11, Alex Crow ?????:

On 06/05/16 14:09, Reet Vyas wrote:
Hi

I have squid ssl bump working but when I added squid.crt  to my android , it not working but working with Iphone cause they have certificate installer app , I dont know exact issue cause my apps are on working . I have installed squid.crt on mobile browsers ,internet is working but not any app like youtube, instagram etc

Please let know what issue with certificate installation on Android devices


I think the problem is simply that CA cert management on Android simply sucks. That is my experience, YMMV.

:-)

Alex

--
This message is intended only for the addressee and may contain
confidential information. Unless you are that person, you may not
disclose its contents or use it in any way and are requested to delete
the message along with any attachments and notify us immediately.
This email is not intended to, nor should it be taken to, constitute advice.
The information provided is correct to our knowledge & belief and must not
be used as a substitute for obtaining tax, regulatory, investment, legal or
any other appropriate advice.

"Transact" is operated by Integrated Financial Arrangements Ltd.
29 Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900 Fax: (020) 7608 5300.
(Registered office: as above; Registered in England and Wales under
number: 3727592). Authorised and regulated by the Financial Conduct
Authority (entered on the Financial Services Register; no. 190856).
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160506/9cf6c6bb/attachment.htm>

From reet.vyas28 at gmail.com  Fri May  6 14:08:58 2016
From: reet.vyas28 at gmail.com (Reet Vyas)
Date: Fri, 6 May 2016 19:38:58 +0530
Subject: [squid-users] SSL certifcate on android device not working
In-Reply-To: <595A02A7-1557-4DFD-8C50-79087C003FAB@diladele.com>
References: <CAA8ViV9Y5BXySMYBGXuCbm9YNH4W2sn2=m4sN4+N8GSmt2g6Aw@mail.gmail.com>
 <572C981A.6070307@integrafin.co.uk>
 <05bb9084-31d5-309c-80b3-33bae38f15d5@gmail.com>
 <CAA8ViV983e86V+Xo-PpAXhX-EWgZtbttouAZg7hFnjS8ZwQykw@mail.gmail.com>
 <595A02A7-1557-4DFD-8C50-79087C003FAB@diladele.com>
Message-ID: <CAA8ViV-UqdBq94sAvxE7ZXatdQoiBKC84MuAKHMHNyEuXet3ZQ@mail.gmail.com>

Same certificate is working with iphone and I can access using ssl bump.
Why not android device?

On Fri, May 6, 2016 at 7:31 PM, Rafael Akchurin <
rafael.akchurin at diladele.com> wrote:

> Not possible, see SSL certificate pinning in wikipedia, or at
> http://docs.diladele.com/faq/squid/dropbox.html
>
>
> Best regards,
> Rafael
>
> Op 6 mei 2016 om 14:27 heeft Reet Vyas <reet.vyas28 at gmail.com> het
> volgende geschreven:
>
> Please let me know if this possible or not?
>
> On Fri, May 6, 2016 at 6:51 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>
>> Android sucks and must die, yes :)
>>
>>
>> 06.05.16 19:11, Alex Crow ?????:
>>
>> On 06/05/16 14:09, Reet Vyas wrote:
>>>
>>>> Hi
>>>>
>>>> I have squid ssl bump working but when I added squid.crt  to my android
>>>> , it not working but working with Iphone cause they have certificate
>>>> installer app , I dont know exact issue cause my apps are on working . I
>>>> have installed squid.crt on mobile browsers ,internet is working but not
>>>> any app like youtube, instagram etc
>>>>
>>>> Please let know what issue with certificate installation on Android
>>>> devices
>>>>
>>>>
>>> I think the problem is simply that CA cert management on Android simply
>>> sucks. That is my experience, YMMV.
>>>
>>> :-)
>>>
>>> Alex
>>>
>>> --
>>> This message is intended only for the addressee and may contain
>>> confidential information. Unless you are that person, you may not
>>> disclose its contents or use it in any way and are requested to delete
>>> the message along with any attachments and notify us immediately.
>>> This email is not intended to, nor should it be taken to, constitute
>>> advice.
>>> The information provided is correct to our knowledge & belief and must
>>> not
>>> be used as a substitute for obtaining tax, regulatory, investment, legal
>>> or
>>> any other appropriate advice.
>>>
>>> "Transact" is operated by Integrated Financial Arrangements Ltd.
>>> 29 Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900 Fax: (020) 7608
>>> 5300.
>>> (Registered office: as above; Registered in England and Wales under
>>> number: 3727592). Authorised and regulated by the Financial Conduct
>>> Authority (entered on the Financial Services Register; no. 190856).
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160506/efb210d1/attachment.htm>

From yvoinov at gmail.com  Fri May  6 14:43:47 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 6 May 2016 20:43:47 +0600
Subject: [squid-users] SSL certifcate on android device not working
In-Reply-To: <595A02A7-1557-4DFD-8C50-79087C003FAB@diladele.com>
References: <CAA8ViV9Y5BXySMYBGXuCbm9YNH4W2sn2=m4sN4+N8GSmt2g6Aw@mail.gmail.com>
 <572C981A.6070307@integrafin.co.uk>
 <05bb9084-31d5-309c-80b3-33bae38f15d5@gmail.com>
 <CAA8ViV983e86V+Xo-PpAXhX-EWgZtbttouAZg7hFnjS8ZwQykw@mail.gmail.com>
 <595A02A7-1557-4DFD-8C50-79087C003FAB@diladele.com>
Message-ID: <288cf8e4-105d-636a-52cb-cd5615b7da63@gmail.com>

Raf, this is not about pinning. This is about CA store in mobile devices.


06.05.16 20:01, Rafael Akchurin ?????:
> Not possible, see SSL certificate pinning in wikipedia, or at
> http://docs.diladele.com/faq/squid/dropbox.html
>
>
> Best regards,
> Rafael
>
> Op 6 mei 2016 om 14:27 heeft Reet Vyas <reet.vyas28 at gmail.com 
> <mailto:reet.vyas28 at gmail.com>> het volgende geschreven:
>
>> Please let me know if this possible or not?
>>
>> On Fri, May 6, 2016 at 6:51 PM, Yuri Voinov <yvoinov at gmail.com 
>> <mailto:yvoinov at gmail.com>> wrote:
>>
>>     Android sucks and must die, yes :)
>>
>>
>>     06.05.16 19:11, Alex Crow ?????:
>>
>>         On 06/05/16 14:09, Reet Vyas wrote:
>>
>>             Hi
>>
>>             I have squid ssl bump working but when I added squid.crt 
>>             to my android , it not working but working with Iphone
>>             cause they have certificate installer app , I dont know
>>             exact issue cause my apps are on working . I have
>>             installed squid.crt on mobile browsers ,internet is
>>             working but not any app like youtube, instagram etc
>>
>>             Please let know what issue with certificate installation
>>             on Android devices
>>
>>
>>         I think the problem is simply that CA cert management on
>>         Android simply sucks. That is my experience, YMMV.
>>
>>         :-)
>>
>>         Alex
>>
>>         -- 
>>         This message is intended only for the addressee and may contain
>>         confidential information. Unless you are that person, you may not
>>         disclose its contents or use it in any way and are requested
>>         to delete
>>         the message along with any attachments and notify us immediately.
>>         This email is not intended to, nor should it be taken to,
>>         constitute advice.
>>         The information provided is correct to our knowledge & belief
>>         and must not
>>         be used as a substitute for obtaining tax, regulatory,
>>         investment, legal or
>>         any other appropriate advice.
>>
>>         "Transact" is operated by Integrated Financial Arrangements Ltd.
>>         29 Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900 Fax:
>>         (020) 7608 5300.
>>         (Registered office: as above; Registered in England and Wales
>>         under
>>         number: 3727592). Authorised and regulated by the Financial
>>         Conduct
>>         Authority (entered on the Financial Services Register; no.
>>         190856).
>>         _______________________________________________
>>         squid-users mailing list
>>         squid-users at lists.squid-cache.org
>>         <mailto:squid-users at lists.squid-cache.org>
>>         http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>     _______________________________________________
>>     squid-users mailing list
>>     squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org>
>>     http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org 
>> <mailto:squid-users at lists.squid-cache.org>
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160506/66bc0c19/attachment.htm>

From yvoinov at gmail.com  Fri May  6 14:46:43 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 6 May 2016 20:46:43 +0600
Subject: [squid-users] SSL certifcate on android device not working
In-Reply-To: <CAA8ViV-UqdBq94sAvxE7ZXatdQoiBKC84MuAKHMHNyEuXet3ZQ@mail.gmail.com>
References: <CAA8ViV9Y5BXySMYBGXuCbm9YNH4W2sn2=m4sN4+N8GSmt2g6Aw@mail.gmail.com>
 <572C981A.6070307@integrafin.co.uk>
 <05bb9084-31d5-309c-80b3-33bae38f15d5@gmail.com>
 <CAA8ViV983e86V+Xo-PpAXhX-EWgZtbttouAZg7hFnjS8ZwQykw@mail.gmail.com>
 <595A02A7-1557-4DFD-8C50-79087C003FAB@diladele.com>
 <CAA8ViV-UqdBq94sAvxE7ZXatdQoiBKC84MuAKHMHNyEuXet3ZQ@mail.gmail.com>
Message-ID: <91895232-84ce-67f6-f4cf-f65da0d9588d@gmail.com>

I'm not sure, but can suggest, that android apps can contains it's own 
CA - built in or own CA stores.


06.05.16 20:08, Reet Vyas ?????:
> Same certificate is working with iphone and I can access using ssl 
> bump. Why not android device?
>
> On Fri, May 6, 2016 at 7:31 PM, Rafael Akchurin 
> <rafael.akchurin at diladele.com <mailto:rafael.akchurin at diladele.com>> 
> wrote:
>
>     Not possible, see SSL certificate pinning in wikipedia, or at
>     http://docs.diladele.com/faq/squid/dropbox.html
>
>
>     Best regards,
>     Rafael
>
>     Op 6 mei 2016 om 14:27 heeft Reet Vyas <reet.vyas28 at gmail.com
>     <mailto:reet.vyas28 at gmail.com>> het volgende geschreven:
>
>>     Please let me know if this possible or not?
>>
>>     On Fri, May 6, 2016 at 6:51 PM, Yuri Voinov <yvoinov at gmail.com
>>     <mailto:yvoinov at gmail.com>> wrote:
>>
>>         Android sucks and must die, yes :)
>>
>>
>>         06.05.16 19:11, Alex Crow ?????:
>>
>>             On 06/05/16 14:09, Reet Vyas wrote:
>>
>>                 Hi
>>
>>                 I have squid ssl bump working but when I added
>>                 squid.crt  to my android , it not working but working
>>                 with Iphone cause they have certificate installer app
>>                 , I dont know exact issue cause my apps are on
>>                 working . I have installed squid.crt on mobile
>>                 browsers ,internet is working but not any app like
>>                 youtube, instagram etc
>>
>>                 Please let know what issue with certificate
>>                 installation on Android devices
>>
>>
>>             I think the problem is simply that CA cert management on
>>             Android simply sucks. That is my experience, YMMV.
>>
>>             :-)
>>
>>             Alex
>>
>>             -- 
>>             This message is intended only for the addressee and may
>>             contain
>>             confidential information. Unless you are that person, you
>>             may not
>>             disclose its contents or use it in any way and are
>>             requested to delete
>>             the message along with any attachments and notify us
>>             immediately.
>>             This email is not intended to, nor should it be taken to,
>>             constitute advice.
>>             The information provided is correct to our knowledge &
>>             belief and must not
>>             be used as a substitute for obtaining tax, regulatory,
>>             investment, legal or
>>             any other appropriate advice.
>>
>>             "Transact" is operated by Integrated Financial
>>             Arrangements Ltd.
>>             29 Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900
>>             Fax: (020) 7608 5300.
>>             (Registered office: as above; Registered in England and
>>             Wales under
>>             number: 3727592). Authorised and regulated by the
>>             Financial Conduct
>>             Authority (entered on the Financial Services Register;
>>             no. 190856).
>>             _______________________________________________
>>             squid-users mailing list
>>             squid-users at lists.squid-cache.org
>>             <mailto:squid-users at lists.squid-cache.org>
>>             http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>         _______________________________________________
>>         squid-users mailing list
>>         squid-users at lists.squid-cache.org
>>         <mailto:squid-users at lists.squid-cache.org>
>>         http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>     _______________________________________________
>>     squid-users mailing list
>>     squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org>
>>     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160506/b97dede3/attachment.htm>

From yvoinov at gmail.com  Fri May  6 20:18:52 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 7 May 2016 02:18:52 +0600
Subject: [squid-users] SSL certifcate on android device not working
In-Reply-To: <91895232-84ce-67f6-f4cf-f65da0d9588d@gmail.com>
References: <CAA8ViV9Y5BXySMYBGXuCbm9YNH4W2sn2=m4sN4+N8GSmt2g6Aw@mail.gmail.com>
 <572C981A.6070307@integrafin.co.uk>
 <05bb9084-31d5-309c-80b3-33bae38f15d5@gmail.com>
 <CAA8ViV983e86V+Xo-PpAXhX-EWgZtbttouAZg7hFnjS8ZwQykw@mail.gmail.com>
 <595A02A7-1557-4DFD-8C50-79087C003FAB@diladele.com>
 <CAA8ViV-UqdBq94sAvxE7ZXatdQoiBKC84MuAKHMHNyEuXet3ZQ@mail.gmail.com>
 <91895232-84ce-67f6-f4cf-f65da0d9588d@gmail.com>
Message-ID: <ac5c9f51-3029-def7-bc45-3eedd1b70034@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Hey,

http://wiki.cacert.org/FAQ/ImportRootCert?action=show&redirect=ImportRootCert#Android_Phones

can be answer?


06.05.16 20:46, Yuri Voinov ?????:
>
> I'm not sure, but can suggest, that android apps can contains it's own
CA - built in or own CA stores.
>
>
> 06.05.16 20:08, Reet Vyas ?????:
>> Same certificate is working with iphone and I can access using ssl
bump. Why not android device?
>>
>> On Fri, May 6, 2016 at 7:31 PM, Rafael Akchurin
<rafael.akchurin at diladele.com <mailto:rafael.akchurin at diladele.com>> wrote:
>>
>>     Not possible, see SSL certificate pinning in wikipedia, or at
>>     http://docs.diladele.com/faq/squid/dropbox.html
>>
>>
>>     Best regards,
>>     Rafael
>>
>>     Op 6 mei 2016 om 14:27 heeft Reet Vyas <reet.vyas28 at gmail.com>
het volgende geschreven:
>>
>>>     Please let me know if this possible or not?
>>>
>>>     On Fri, May 6, 2016 at 6:51 PM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>>>
>>>         Android sucks and must die, yes :)
>>>
>>>
>>>         06.05.16 19:11, Alex Crow ?????:
>>>
>>>             On 06/05/16 14:09, Reet Vyas wrote:
>>>
>>>                 Hi
>>>
>>>                 I have squid ssl bump working but when I added
squid.crt  to my android , it not working but working with Iphone cause
they have certificate installer app , I dont know exact issue cause my
apps are on working . I have installed squid.crt on mobile browsers
,internet is working but not any app like youtube, instagram etc
>>>
>>>                 Please let know what issue with certificate
installation on Android devices
>>>
>>>
>>>             I think the problem is simply that CA cert management on
Android simply sucks. That is my experience, YMMV.
>>>
>>>             :-)
>>>
>>>             Alex
>>>
>>>             --
>>>             This message is intended only for the addressee and may
contain
>>>             confidential information. Unless you are that person,
you may not
>>>             disclose its contents or use it in any way and are
requested to delete
>>>             the message along with any attachments and notify us
immediately.
>>>             This email is not intended to, nor should it be taken
to, constitute advice.
>>>             The information provided is correct to our knowledge &
belief and must not
>>>             be used as a substitute for obtaining tax, regulatory,
investment, legal or
>>>             any other appropriate advice.
>>>
>>>             "Transact" is operated by Integrated Financial
Arrangements Ltd.
>>>             29 Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900
Fax: (020) 7608 5300.
>>>             (Registered office: as above; Registered in England and
Wales under
>>>             number: 3727592). Authorised and regulated by the
Financial Conduct
>>>             Authority (entered on the Financial Services Register;
no. 190856).
>>>             _______________________________________________
>>>             squid-users mailing list
>>>             squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>>>             http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>>         _______________________________________________
>>>         squid-users mailing list
>>>         squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>>>         http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>>     _______________________________________________
>>>     squid-users mailing list
>>>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>>>     http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXLPwrAAoJENNXIZxhPexGT2wH/3wtf4rk9UiS1jCYs5rMjgRr
wkZG7A12V673Y069ilYSrQ1dEZLNNtVuk5Ap2S4mfgIy5btlm/eOJLtM4CUHW3by
51HtUGRk7F3kFYUP6ZKN3InjWAUD4RehSMpYcMkSLyjU9bCcCVjkr0+VtL2bRdHF
KmdmkU14BjE4a9R2tax0rzKiszTeEBVt7rehM84oUksboruYGgsTbgl/Ds6KUTMT
BurtKRdHgNqHviVJ76OZzt+HKS6HImFwo66IqeBYCkTn+Dqclwn+J5m6afsjuJZ0
6a+XcGuqJm7GVNkJ6D/6tInOLK/PmhQMPJR6y6jlmfRSYB9YR3r9INKpExVynUM=
=dels
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160507/e24562ff/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160507/e24562ff/attachment.key>

From yvoinov at gmail.com  Fri May  6 20:23:32 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 7 May 2016 02:23:32 +0600
Subject: [squid-users] SSL certifcate on android device not working
In-Reply-To: <ac5c9f51-3029-def7-bc45-3eedd1b70034@gmail.com>
References: <CAA8ViV9Y5BXySMYBGXuCbm9YNH4W2sn2=m4sN4+N8GSmt2g6Aw@mail.gmail.com>
 <572C981A.6070307@integrafin.co.uk>
 <05bb9084-31d5-309c-80b3-33bae38f15d5@gmail.com>
 <CAA8ViV983e86V+Xo-PpAXhX-EWgZtbttouAZg7hFnjS8ZwQykw@mail.gmail.com>
 <595A02A7-1557-4DFD-8C50-79087C003FAB@diladele.com>
 <CAA8ViV-UqdBq94sAvxE7ZXatdQoiBKC84MuAKHMHNyEuXet3ZQ@mail.gmail.com>
 <91895232-84ce-67f6-f4cf-f65da0d9588d@gmail.com>
 <ac5c9f51-3029-def7-bc45-3eedd1b70034@gmail.com>
Message-ID: <d14a75de-07cc-7bbf-66c8-2eb4e8fa38f8@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Or here

http://wiki.pcprobleemloos.nl/android/cacert

Google still rulezzzzzzz! :)

PS. I haven't either iPhone or Android to verify :) because I'm not
cyborg :) So...... try and tell us about results :)

07.05.16 2:18, Yuri Voinov ?????:
>
> Hey,
>
>
http://wiki.cacert.org/FAQ/ImportRootCert?action=show&redirect=ImportRootCert#Android_Phones
>
> can be answer?
>
>
> 06.05.16 20:46, Yuri Voinov ?????:
>
>
>       > I'm not sure, but can suggest, that android apps can contains
>       it's own CA - built in or own CA stores.
>
>
>
>
>
>       > 06.05.16 20:08, Reet Vyas ?????:
>
>       >> Same certificate is working with iphone and I can access
>       using ssl bump. Why not android device?
>
>       >>
>
>       >> On Fri, May 6, 2016 at 7:31 PM, Rafael Akchurin
>       <rafael.akchurin at diladele.com
>       <mailto:rafael.akchurin at diladele.com>> wrote:
>
>       >>
>
>       >>     Not possible, see SSL certificate pinning in
>       wikipedia, or at
>
>       >>     http://docs.diladele.com/faq/squid/dropbox.html
>
>       >>
>
>       >>
>
>       >>     Best regards,
>
>       >>     Rafael
>
>       >>
>
>       >>     Op 6 mei 2016 om 14:27 heeft Reet Vyas
>       <reet.vyas28 at gmail.com> het volgende geschreven:
>
>       >>
>
>       >>>     Please let me know if this possible or not?
>
>       >>>
>
>       >>>     On Fri, May 6, 2016 at 6:51 PM, Yuri Voinov
>       <yvoinov at gmail.com <mailto:yvoinov at gmail.com>> wrote:
>
>       >>>
>
>       >>>         Android sucks and must die, yes :)
>
>       >>>
>
>       >>>
>
>       >>>         06.05.16 19:11, Alex Crow ?????:
>
>       >>>
>
>       >>>             On 06/05/16 14:09, Reet Vyas wrote:
>
>       >>>
>
>       >>>                 Hi
>
>       >>>
>
>       >>>                 I have squid ssl bump working but
>       when I added squid.crt  to my android , it not working but working
>       with Iphone cause they have certificate installer app , I dont
>       know exact issue cause my apps are on working . I have installed
>       squid.crt on mobile browsers ,internet is working but not any app
>       like youtube, instagram etc
>
>       >>>
>
>       >>>                 Please let know what issue with
>       certificate installation on Android devices
>
>       >>>
>
>       >>>
>
>       >>>             I think the problem is simply that CA
>       cert management on Android simply sucks. That is my experience,
>       YMMV.
>
>       >>>
>
>       >>>             :-)
>
>       >>>
>
>       >>>             Alex
>
>       >>>
>
>       >>>             --
>
>       >>>             This message is intended only for the
>       addressee and may contain
>
>       >>>             confidential information. Unless you are
>       that person, you may not
>
>       >>>             disclose its contents or use it in any
>       way and are requested to delete
>
>       >>>             the message along with any attachments
>       and notify us immediately.
>
>       >>>             This email is not intended to, nor should
>       it be taken to, constitute advice.
>
>       >>>             The information provided is correct to
>       our knowledge & belief and must not
>
>       >>>             be used as a substitute for obtaining
>       tax, regulatory, investment, legal or
>
>       >>>             any other appropriate advice.
>
>       >>>
>
>       >>>             "Transact" is operated by Integrated
>       Financial Arrangements Ltd.
>
>       >>>             29 Clement's Lane, London EC4N 7AE. Tel:
>       (020) 7608 4900 Fax: (020) 7608 5300.
>
>       >>>             (Registered office: as above; Registered
>       in England and Wales under
>
>       >>>             number: 3727592). Authorised and
>       regulated by the Financial Conduct
>
>       >>>             Authority (entered on the Financial
>       Services Register; no. 190856).
>
>       >>>           
>       _______________________________________________
>
>       >>>             squid-users mailing list
>
>       >>>             squid-users at lists.squid-cache.org
>       <mailto:squid-users at lists.squid-cache.org>
>
>       >>>           
>       http://lists.squid-cache.org/listinfo/squid-users
>
>       >>>
>
>       >>>
>
>       >>>       
>       _______________________________________________
>
>       >>>         squid-users mailing list
>
>       >>>         squid-users at lists.squid-cache.org
>       <mailto:squid-users at lists.squid-cache.org>
>
>       >>>       
>       http://lists.squid-cache.org/listinfo/squid-users
>
>       >>>
>
>       >>>
>
>       >>>     _______________________________________________
>
>       >>>     squid-users mailing list
>
>       >>>     squid-users at lists.squid-cache.org
>       <mailto:squid-users at lists.squid-cache.org>
>
>       >>>     http://lists.squid-cache.org/listinfo/squid-users
>
>       >>
>
>       >>
>
>       >>
>
>       >>
>
>       >> _______________________________________________
>
>       >> squid-users mailing list
>
>       >> squid-users at lists.squid-cache.org
>
>       >> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXLP1EAAoJENNXIZxhPexGw0wIALCpdb5yhWy4Gzl68j3sAryq
ozE1xblc4hP4DHkQLHD/+R7tze+t+I3gHxsyUj3pNni1HnRVWLu/AxvLvBQOIUcT
rbavCYvI8Vl1KqO6LqwJkHVq7kiPB3+XaJbZkUgLaDbY5zVCeLn3yfi5mYjE+wCQ
xxDqZ1NhXDZchBsogbQR4+5iKpYEowBXmB7tkUaMwDethszib5fGRXKVqhsJnp4z
Nf7/0lHZQZO8C0dkQxNjI/zd1FU6XiFGWduRGBqMHj8y9QXTaZ4mjcLQJhwVvIMW
UAK5dAT9T0UuA9y1LS/SwuewV1TWbEKpcIm04GNlOmpZBaR/IpRnppG3Dyl+Nwg=
=ASQ5
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160507/132bf62a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160507/132bf62a/attachment.key>

From deepaganu at gmail.com  Sat May  7 01:33:54 2016
From: deepaganu at gmail.com (deepa ganu)
Date: Sat, 7 May 2016 07:03:54 +0530
Subject: [squid-users] load balancer as squid
Message-ID: <CA+qV5kK=5R3b1KU141mtTezEsw_TMz9tUTDj=PR1Xsr4B0D3Vg@mail.gmail.com>

Hi
I have been using squid as a reverse proxy


http_port 80 accel defaultsite=202.53.13.20 vhost
cache_peer 172.20.36.162 parent 80 0 proxy-only no-query no-digest
originserver name=server1
cache_peer 172.20.36.41 parent 80 0 proxy-only no-query no-digest
originserver name=server2

acl sites_server1 dstdomain 172.20.36.162
acl sites_server2 dstdomain 172.20.36.41


cache_peer_access server1 allow sites_server1
cache_peer_access server2 allow sites_server2

#cache_peer 172.20.36.41 parent 80 0 proxy-only name=telescope
#cache_peer 172.20.36.41 parent 80 0 proxy-only name=portal
http_access allow sites_server1
http_access allow sites_server2

Please let me know if this is correct, also how can I use it as a load
balancer , if my one more server is at 172.20.36.42 ?







-- 
Regards
Deepa Ganu
R&D Head(CSE) KMIT
Ph no : 9908036660
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160507/feb5d413/attachment.htm>

From squid3 at treenet.co.nz  Sat May  7 03:09:49 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 7 May 2016 15:09:49 +1200
Subject: [squid-users] ldap authentication with encrypted credentials
In-Reply-To: <1f8d2934596ba382031630622a55bcb7@tiscali.it>
References: <76022224f8c7d2b77223069db3b461e2@tiscali.it>
 <f94e0f42-11b6-6489-03b7-220e289cf61f@treenet.co.nz>
 <580d1f7f1067229df5608be32af98124@tiscali.it>
 <658f257a-554a-3752-ae29-bc967d6fb091@treenet.co.nz>
 <1f8d2934596ba382031630622a55bcb7@tiscali.it>
Message-ID: <43090cf4-a35b-2dae-0cd9-adf889930b85@treenet.co.nz>

On 7/05/2016 12:31 a.m., Sampei wrote:
>   I'm thinking to implement Basic authentication for all clients
> because it's easier with my outdated systems.
> In squid.conf can I use
> one of these three access methods for http_access for each_client? 
> 
> 1-
> only based on AD user authentication
> 2- only based on IP address
> 3- both
> based both on AD user authentication and on IP address (both 1 and 2
> options)
> 

Authorization (authz not authn) is very flexible. The order of ACL
checks you configure determines what Squid does and the order it happens.

So in general the answer is "yes", but the specifics will vary depending
on what exact policy permissions you are trying to enforce.

Amos



From squid3 at treenet.co.nz  Sat May  7 03:13:34 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 7 May 2016 15:13:34 +1200
Subject: [squid-users] SSL certifcate on android device not working
In-Reply-To: <288cf8e4-105d-636a-52cb-cd5615b7da63@gmail.com>
References: <CAA8ViV9Y5BXySMYBGXuCbm9YNH4W2sn2=m4sN4+N8GSmt2g6Aw@mail.gmail.com>
 <572C981A.6070307@integrafin.co.uk>
 <05bb9084-31d5-309c-80b3-33bae38f15d5@gmail.com>
 <CAA8ViV983e86V+Xo-PpAXhX-EWgZtbttouAZg7hFnjS8ZwQykw@mail.gmail.com>
 <595A02A7-1557-4DFD-8C50-79087C003FAB@diladele.com>
 <288cf8e4-105d-636a-52cb-cd5615b7da63@gmail.com>
Message-ID: <2342ae2b-0fc4-d890-8455-5666432013be@treenet.co.nz>

On 7/05/2016 2:43 a.m., Yuri Voinov wrote:
> Raf, this is not about pinning. This is about CA store in mobile devices.
> 

Pinning at its core is just hard-coded entries in those stores or the app.

A pinned cert can be considered like the CA equivalent of having a
non-editable /etc/hosts file entry for DNS. Lookups happen but dont go
past the hard-coded entry unless the app bypasses it specially.

Amos



From squid3 at treenet.co.nz  Sat May  7 03:19:33 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 7 May 2016 15:19:33 +1200
Subject: [squid-users] load balancer as squid
In-Reply-To: <CA+qV5kK=5R3b1KU141mtTezEsw_TMz9tUTDj=PR1Xsr4B0D3Vg@mail.gmail.com>
References: <CA+qV5kK=5R3b1KU141mtTezEsw_TMz9tUTDj=PR1Xsr4B0D3Vg@mail.gmail.com>
Message-ID: <81c93bb5-46a3-ac4f-3c4b-866c49d5a4ff@treenet.co.nz>

On 7/05/2016 1:33 p.m., deepa ganu wrote:
> Hi
> I have been using squid as a reverse proxy
> 
> 
> http_port 80 accel defaultsite=202.53.13.20 vhost
> cache_peer 172.20.36.162 parent 80 0 proxy-only no-query no-digest
> originserver name=server1
> cache_peer 172.20.36.41 parent 80 0 proxy-only no-query no-digest
> originserver name=server2
> 
> acl sites_server1 dstdomain 172.20.36.162
> acl sites_server2 dstdomain 172.20.36.41
> 
> 
> cache_peer_access server1 allow sites_server1
> cache_peer_access server2 allow sites_server2
> 
> #cache_peer 172.20.36.41 parent 80 0 proxy-only name=telescope
> #cache_peer 172.20.36.41 parent 80 0 proxy-only name=portal
> http_access allow sites_server1
> http_access allow sites_server2
> 
> Please let me know if this is correct, also how can I use it as a load
> balancer , if my one more server is at 172.20.36.42 ?
> 

Squid load balances between cache_peer by default.

Right now it is using virtual host details (dstdomain ACL) in
cache_peer_access to explicitly route to the specific originserver
instead of LB.

If you can describe clearly in words the details of exactly what you
want Squid to do that should turn out to be what you need to configure.

Amos



From bryan.mabra at gmail.com  Sat May  7 15:06:22 2016
From: bryan.mabra at gmail.com (mabraFoo)
Date: Sat, 7 May 2016 11:06:22 -0400
Subject: [squid-users] youtube videos take 60 seconds to start
Message-ID: <CAPSJP+JhDVUiNHtoH0MCOT8PstPgGj8B=s+eMcWETw6ntgnbCg@mail.gmail.com>

I started working with squid a few months back.  First of all, if you are a
squid developer.  THANK YOU for this awesome software.

I am using ssl_bump in transparent mode.  When I use my ipad with safari
and go to youtube there is a 60+ second delay before the video starts.  My
guess is that squid is downloading the entire video and is not sending
until the entire download is complete.  Does anyone know if there is
something I could change in my config to get the video to start without
that delay?

If you see anything off in my config, please explain.

Squid Cache: Version 3.5.17
Service Name: squid
configure options:  '--build=x86_64-redhat-linux-gnu'
'--host=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr'
'--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin'
'--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include'
'--libdir=/usr/lib64' '--libexecdir=/usr/libexec'
'--sharedstatedir=/var/lib' '--mandir=/usr/share/man'
'--infodir=/usr/share/info' '--verbose' '--exec_prefix=/usr'
'--libexecdir=/usr/lib64/squid' '--localstatedir=/var'
'--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
'--with-logdir=$(localstatedir)/log/squid'
'--with-pidfile=$(localstatedir)/run/squid.pid'
'--disable-dependency-tracking' '--enable-follow-x-forwarded-for'
'--enable-auth'
'--enable-auth-basic=DB,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,getpwnam,fake'
'--enable-auth-ntlm=smb_lm,fake'
'--enable-auth-digest=file,LDAP,eDirectory'
'--enable-auth-negotiate=kerberos,wrapper'
'--enable-external-acl-helpers=wbinfo_group,kerberos_ldap_group,LDAP_group,delayer,file_userip,SQL_session,unix_group,session,time_quota'
'--enable-cache-digests' '--enable-cachemgr-hostname=localhost'
'--enable-delay-pools' '--enable-epoll' '--enable-icap-client'
'--enable-ident-lookups' '--enable-linux-netfilter'
'--enable-removal-policies=heap,lru' '--enable-snmp'
'--enable-storeio=aufs,diskd,ufs,rock' '--enable-wccpv2' '--enable-esi'
'--enable-ssl-crtd' '--enable-icmp' '--with-aio'
'--with-default-user=squid' '--with-filedescriptors=16384' '--with-dl'
'--with-openssl' '--with-pthreads' '--with-included-ltdl'
'--disable-arch-native' '--enable-ecap' '--without-nettle'
'build_alias=x86_64-redhat-linux-gnu' 'host_alias=x86_64-redhat-linux-gnu'
'CFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions
-fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches
-m64 -mtune=generic' 'LDFLAGS=-Wl,-z,relro ' 'CXXFLAGS=-O2 -g -pipe -Wall
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong
--param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic
-fPIC' 'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig'
--enable-ltdl-convenience



acl CONNECT method CONNECT
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 210         # wais
acl Safe_ports port 21          # ftp
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 443         # https
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 70          # gopher
acl Safe_ports port 777         # multiling http
acl Safe_ports port 80          # http
acl SSL_ports port 443

coredump_dir /var/spool/squid
strip_query_terms off

forward_max_tries 25
http_access allow all
http_access deny CONNECT !SSL_ports
http_access deny !Safe_ports

http_port  3126 intercept
http_port  3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/sslcert/myca.pem
https_port 3127 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/sslcert/myca.pem
key=/etc/squid/sslcert/myca.pem

refresh_pattern .               0       20%     4320
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
shutdown_lifetime 3 seconds

acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl nobumpSites ssl::server_name .netflix.com

ssl_bump peek step1 all
ssl_bump splice step2 nobumpSites
ssl_bump bump


sslcrtd_children 8 startup=1 idle=1
sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/spool/squid_ssldb -M 4MB
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160507/d5784f44/attachment.htm>

From chip_pop at hotmail.com  Sat May  7 19:49:02 2016
From: chip_pop at hotmail.com (joe)
Date: Sat, 7 May 2016 12:49:02 -0700 (PDT)
Subject: [squid-users] youtube videos take 60 seconds to start
In-Reply-To: <CAPSJP+JhDVUiNHtoH0MCOT8PstPgGj8B=s+eMcWETw6ntgnbCg@mail.gmail.com>
References: <CAPSJP+JhDVUiNHtoH0MCOT8PstPgGj8B=s+eMcWETw6ntgnbCg@mail.gmail.com>
Message-ID: <1462650542998-4677387.post@n4.nabble.com>

youtube app or browser ??
i gess youtube app if so yes dose not work right also movie freeze in middle
i suggest bypass bump to youtube app using acl  useragent detection for the
app   



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/youtube-videos-take-60-seconds-to-start-tp4677386p4677387.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sat May  7 21:08:40 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 8 May 2016 03:08:40 +0600
Subject: [squid-users] youtube videos take 60 seconds to start
In-Reply-To: <1462650542998-4677387.post@n4.nabble.com>
References: <CAPSJP+JhDVUiNHtoH0MCOT8PstPgGj8B=s+eMcWETw6ntgnbCg@mail.gmail.com>
 <1462650542998-4677387.post@n4.nabble.com>
Message-ID: <3db18970-3fff-19ef-38b4-d7d7cf5c8cbf@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
# No-cache
acl dont_cache_url url_regex "/usr/local/squid/etc/url.nocache"

# No cache directives
cache deny dont_cache_url

cat /usr/local/squid/etc/url.nocache:

.googlevideo\.com

I recommed do not cache googlevideo CDN.

Nobody can't cacne YT. So better do not cache YT video.

Here is the details:

http://wiki.squid-cache.org/ConfigExamples/DynamicContent/YouTube/Discussion

I have no  any issue with this YT config.


08.05.16 1:49, joe ?????:
> youtube app or browser ??
> i gess youtube app if so yes dose not work right also movie freeze in
middle
> i suggest bypass bump to youtube app using acl  useragent detection
for the
> app  
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/youtube-videos-take-60-seconds-to-start-tp4677386p4677387.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXLllYAAoJENNXIZxhPexGRSYH/0C8j2P6IZ68L5MqHSjTN/P9
UmcMC4JVFAvP/tzGgQB5CG7j/2t0H/6vkNchkNvTOVNsul5JFRvYUwBwMz8BApLE
3BiA3A53MIITJxm1GdSzrrzMJ2n6ZmvqWNXZzE+SE0hTTAVLFSqSTSUFTCmLmpC4
BX/HcOjiKCEKUI21RjhJ0Jycnr3r9MtRGrnmSUJHb8Vl4H4a8tVwHChCzdOj/tP9
WrmG7FBHugdGlox1nLyHxZ7UzI0Ebb/pGtxcu/NCQBBwG7od4psXNyT3oYYWMdjC
LsqrhYMcU38PoSsquLNV/c74FnObPe9cyMoHSmjN6MO9r8jTFoKHzrhMbj+VKrg=
=gsvc
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160508/a7dce710/attachment.key>

From yvoinov at gmail.com  Sat May  7 21:18:57 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 8 May 2016 03:18:57 +0600
Subject: [squid-users] youtube videos take 60 seconds to start
In-Reply-To: <3db18970-3fff-19ef-38b4-d7d7cf5c8cbf@gmail.com>
References: <CAPSJP+JhDVUiNHtoH0MCOT8PstPgGj8B=s+eMcWETw6ntgnbCg@mail.gmail.com>
 <1462650542998-4677387.post@n4.nabble.com>
 <3db18970-3fff-19ef-38b4-d7d7cf5c8cbf@gmail.com>
Message-ID: <5d30742b-7180-de01-e22c-234dd0988bfb@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I want to say:

Do not try to preload YT clips.

Deliver ot almost at download. And do not try to cache. It's impossible.

08.05.16 3:08, Yuri Voinov ?????:
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
> 
> # No-cache
> acl dont_cache_url url_regex "/usr/local/squid/etc/url.nocache"
>
> # No cache directives
> cache deny dont_cache_url
>
> cat /usr/local/squid/etc/url.nocache:
>
> .googlevideo\.com
>
> I recommed do not cache googlevideo CDN.
>
> Nobody can't cacne YT. So better do not cache YT video.
>
> Here is the details:
>
>
http://wiki.squid-cache.org/ConfigExamples/DynamicContent/YouTube/Discussion
>
> I have no  any issue with this YT config.
>
>
> 08.05.16 1:49, joe ?????:
>> youtube app or browser ??
>> i gess youtube app if so yes dose not work right also movie freeze in
> middle
>> i suggest bypass bump to youtube app using acl  useragent detection
> for the
>> app 
>>
>>
>>
>> --
>> View this message in context:
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/youtube-videos-take-60-seconds-to-start-tp4677386p4677387.html
>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
> 
> iQEcBAEBCAAGBQJXLllYAAoJENNXIZxhPexGRSYH/0C8j2P6IZ68L5MqHSjTN/P9
> UmcMC4JVFAvP/tzGgQB5CG7j/2t0H/6vkNchkNvTOVNsul5JFRvYUwBwMz8BApLE
> 3BiA3A53MIITJxm1GdSzrrzMJ2n6ZmvqWNXZzE+SE0hTTAVLFSqSTSUFTCmLmpC4
> BX/HcOjiKCEKUI21RjhJ0Jycnr3r9MtRGrnmSUJHb8Vl4H4a8tVwHChCzdOj/tP9
> WrmG7FBHugdGlox1nLyHxZ7UzI0Ebb/pGtxcu/NCQBBwG7od4psXNyT3oYYWMdjC
> LsqrhYMcU38PoSsquLNV/c74FnObPe9cyMoHSmjN6MO9r8jTFoKHzrhMbj+VKrg=
> =gsvc
> -----END PGP SIGNATURE-----
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXLlvBAAoJENNXIZxhPexGG2YH/0wKYMxNWnsnkbVD9K4yn8wa
5lWqA+HD1VnDl9JQUyc5OG5EQ+a4376dIC8tpq3pOqXNN5E183VgJz3oPh8i89g4
J1DjIICyBQxcXkhwMBVMh8GIq7aGHGIpDapC2W3ArtgxVTEs7Qe8J8pfqLtjO30s
nfP+6mZ/BkCHop8347+kXFnBA/E+M6sVi7Z3ROKFSFYk+GjmK2mckclymSd+KcjS
z/xL8ZpNBAhSXo/YQaLDnhJ5jYDW28Ascy+nKPsl8FFXYLfPmsRtC4D/a2cP/aRr
ECL9mHYpc+FYubm7C+xj2l92k9QzS2BMyPEg+oTEUZRYJAuXPYYoi3bG55SSHbc=
=LPxs
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160508/6559ec18/attachment.key>

From yvoinov at gmail.com  Sat May  7 21:45:22 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 8 May 2016 03:45:22 +0600
Subject: [squid-users] youtube videos take 60 seconds to start
In-Reply-To: <1462650542998-4677387.post@n4.nabble.com>
References: <CAPSJP+JhDVUiNHtoH0MCOT8PstPgGj8B=s+eMcWETw6ntgnbCg@mail.gmail.com>
 <1462650542998-4677387.post@n4.nabble.com>
Message-ID: <ee4ff2bd-8547-2294-f8b9-017c3e8f3b2a@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
YT issue is not bump. YT is bump without any issue.

YT issue is tries to cache.

You can't cache YT. Now. Never.

Forgot about YT cache. This is fake. And impossible. Now. YT is not
cache-friendly. Whenever HTML5 or not.

08.05.16 1:49, joe ?????:
> youtube app or browser ??
> i gess youtube app if so yes dose not work right also movie freeze in
middle
> i suggest bypass bump to youtube app using acl  useragent detection
for the
> app  
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/youtube-videos-take-60-seconds-to-start-tp4677386p4677387.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXLmHyAAoJENNXIZxhPexGB1YH/3P3y1cQtuxls0zQ8lQiYWom
f+4CbmIa+gBxVIZDZbNDbaC90nJQcEvBN3YGMXeh6MQapJs464rypwhWzN4+au1s
KVFU1mMJuYY8QCqSz6baAo1x0CFSXRrY4AwRFf1EflZ3XahssFdPifeAhsANYY/R
GVdM2DN1LpO2B+tm/k6XExsw/ND8Jkxvvg8NeX3sbbm//FYlM+IOEUF8U/2Le93Y
hMA2kyoBcv+Afp0dwWWVTgkWM937DJGquv+h4vPr7NPKwR48L995MrXo+mZ8QPr6
1AeUWvrGABMRg6wbHoq14el3NX7olZoPubTgT/1bH0yFLvhqqxEwYGgiOqRKids=
=FWsJ
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160508/c35173b2/attachment.key>

From bryan.mabra at gmail.com  Sun May  8 13:06:32 2016
From: bryan.mabra at gmail.com (mabraFoo)
Date: Sun, 8 May 2016 09:06:32 -0400
Subject: [squid-users] youtube videos take 60 seconds to start
Message-ID: <CAPSJP++JSy2DQxeQX4wP_wG+6DOpeZ9NhVNzxSoP2R7kBOfviQ@mail.gmail.com>

I agree with you about not caching youtube.   Thanks for the config help.



-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

YT issue is not bump. YT is bump without any issue.

YT issue is tries to cache.

You can't cache YT. Now. Never.

Forgot about YT cache. This is fake. And impossible. Now. YT is not
cache-friendly. Whenever HTML5 or not.

08.05.16 1:49, joe ?????:
> youtube app or browser ??
> i gess youtube app if so yes dose not work right also movie freeze in
middle
> i suggest bypass bump to youtube app using acl  useragent detection
for the
> app
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/youtube-videos-take-60-seconds-to-start-tp4677386p4677387.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBCAAGBQJXLmHyAAoJENNXIZxhPexGB1YH/3P3y1cQtuxls0zQ8lQiYWom
f+4CbmIa+gBxVIZDZbNDbaC90nJQcEvBN3YGMXeh6MQapJs464rypwhWzN4+au1s
KVFU1mMJuYY8QCqSz6baAo1x0CFSXRrY4AwRFf1EflZ3XahssFdPifeAhsANYY/R
GVdM2DN1LpO2B+tm/k6XExsw/ND8Jkxvvg8NeX3sbbm//FYlM+IOEUF8U/2Le93Y
hMA2kyoBcv+Afp0dwWWVTgkWM937DJGquv+h4vPr7NPKwR48L995MrXo+mZ8QPr6
1AeUWvrGABMRg6wbHoq14el3NX7olZoPubTgT/1bH0yFLvhqqxEwYGgiOqRKids=
=FWsJ
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160508/c35173b2/attachment-0001.key
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160508/8cef466b/attachment.htm>

From fourtrials at gmail.com  Mon May  9 00:31:39 2016
From: fourtrials at gmail.com (Victor Hugo)
Date: Mon, 9 May 2016 10:31:39 +1000
Subject: [squid-users] Filtering HTTPS URLs
In-Reply-To: <93793088-1b0b-ef4c-181b-4c991deef87b@treenet.co.nz>
References: <CAN-hnF2ajC7zHpdxbw0jKMaHn9LStK_Ef-B3=9vr7fP=hKvZdw@mail.gmail.com>
 <CAN-hnF3hOSVHbJ6HHP5d16uXU9HeCyg6ff9oCj-fmoE-LkLREQ@mail.gmail.com>
 <93793088-1b0b-ef4c-181b-4c991deef87b@treenet.co.nz>
Message-ID: <CAN-hnF3koq1fvY-H=01Pb2G2C8yb5h4Af1WwzpCy9SeZt3GrrQ@mail.gmail.com>

Wow that worked!

Thanks!

On Fri, May 6, 2016 at 5:00 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 6/05/2016 5:51 p.m., Victor Hugo wrote:
> > Here's a strange one for you though, if I change:
> > acl whitelist-regex url_regex -i reddit.com/r/news
> >
> > to:
> > acl whitelist-regex url_regex -i reddit\.com\/r\/news
> www\.reddit\.com\:443
> >
> > it works every 2nd time but the match is too greedy and allows
> > www.reddit.com/r/anything every 2nd time.
> >
>
> That first regex pattern requires a path "/r/news" to exist. CONNECT
> messages do not have paths.
>
> That second pattern you are now adding matches (and thus allows) the
> CONNECT message authority-URI built from the traffic SNI details.
>
> They are two different regex patterns so if *either one* matches the ACL
> test will be a match.
>
>
> Try adding this line *after* the default "deny CONNECT !SSL_ports" line:
>  acl reddit dstdomain .reddit.com
>  http_access allow CONNECT SSL_ports reddit
>
> That should allow the CONNECT's stuff to happen and your ssl_bump and
> http_access rules then handle the HTTPS.
>
>
> Amos
>
>
> > Victor
> >
> > it
> >
> > On Thu, Feb 11, 2016 at 10:05 AM, Victor Hugo <fourtrials at gmail.com>
> wrote:
> >
> >> Hi,
> >>
> >> I was wondering if it is possible to filter HTTPS URLs using squid (for
> >> example to blacklist reddit.com but allow
> https://www.reddit.com/r/news/)?
> >>
> >> I thought this may be possible using ssl_bump and url_regex. I have been
> >> trying this using squid 3.5.13 but with no success.
> >>
> >> Here is the squid configuration that I have tried but doesn't seem to
> work
> >> (it works for http sites though):
> >>
> >> acl localnet src 10.0.0.0/8 # RFC1918 possible internal network
> >> acl localnet src 172.16.0.0/12 # RFC1918 possible internal network
> >> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> >> acl localnet src fc00::/7       # RFC 4193 local private network range
> >> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
> >> machines
> >>
> >> acl SSL_ports port 443
> >> acl Safe_ports port 80 # http
> >> acl Safe_ports port 21 # ftp
> >> acl Safe_ports port 443 # https
> >> acl Safe_ports port 70 # gopher
> >> acl Safe_ports port 210 # wais
> >> acl Safe_ports port 1025-65535 # unregistered ports
> >> acl Safe_ports port 280 # http-mgmt
> >> acl Safe_ports port 488 # gss-http
> >> acl Safe_ports port 591 # filemaker
> >> acl Safe_ports port 777 # multiling http
> >> acl CONNECT method CONNECT
> >>
> >> http_access deny !Safe_ports
> >> http_access deny CONNECT !SSL_ports
> >> http_access allow localhost manager
> >> http_access deny manager
> >>
> >> acl whitelist-regex url_regex -i reddit.com/r/news
> >> http_port 3129 ssl-bump
> >> cert=/opt/squid-3.5.13/etc/squid3/ssl_cert/myCA.pem
> >> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> >> acl bump_sites ssl::server_name .reddit.com
> >> ssl_bump bump bump_sites
> >> ssl_bump splice !bump_sites
> >> http_access allow whitelist-regex
> >> http_access allow localhost
> >> http_access deny all
> >> coredump_dir /opt/squid-3.5.13/var/spool/squid3
> >> refresh_pattern ^ftp: 1440 20% 10080
> >> refresh_pattern ^gopher: 1440 0% 1440
> >> refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
> >> refresh_pattern . 0 20% 4320
> >> pinger_enable off
> >> Relevant access.log output (IP addresses redacted to x.x.x.x):
> >> 1455145755.589      0 x.x.x.x TCP_DENIED/200 0 CONNECT
> www.reddit.com:443
> >> - HIER_NONE/- -
> >> 1455145755.669      0 x.x.x.x TAG_NONE/403 4011 GET
> >> https://www.reddit.com/r/news - HIER_NONE/- text/html
> >> 1455145755.782      0 x.x.x.x TCP_DENIED/200 0 CONNECT
> www.reddit.com:443
> >> - HIER_NONE/- -
> >>
> >> I don't want to whitelist the dstdomain .reddit.com
> >> (i.e whitelist-ssldomain dstdomain .reddit.com) as that would allow
> >> access to all of the other subreddits.
> >>
> >> Appreciate any help or suggestions you have. Thanks.
> >>
> >> Victor
> >>
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160509/78b49591/attachment.htm>

From reet.vyas28 at gmail.com  Mon May  9 05:14:10 2016
From: reet.vyas28 at gmail.com (Reet Vyas)
Date: Mon, 9 May 2016 10:44:10 +0530
Subject: [squid-users] SSL certifcate on android device not working
In-Reply-To: <2342ae2b-0fc4-d890-8455-5666432013be@treenet.co.nz>
References: <CAA8ViV9Y5BXySMYBGXuCbm9YNH4W2sn2=m4sN4+N8GSmt2g6Aw@mail.gmail.com>
 <572C981A.6070307@integrafin.co.uk>
 <05bb9084-31d5-309c-80b3-33bae38f15d5@gmail.com>
 <CAA8ViV983e86V+Xo-PpAXhX-EWgZtbttouAZg7hFnjS8ZwQykw@mail.gmail.com>
 <595A02A7-1557-4DFD-8C50-79087C003FAB@diladele.com>
 <288cf8e4-105d-636a-52cb-cd5615b7da63@gmail.com>
 <2342ae2b-0fc4-d890-8455-5666432013be@treenet.co.nz>
Message-ID: <CAA8ViV9Hd7tdhEaQOU8SD-3G28jVHHUiNCsBnVwp-Hze0ihDmA@mail.gmail.com>

Thank You so much for link will try today and will post results

On Sat, May 7, 2016 at 8:43 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 7/05/2016 2:43 a.m., Yuri Voinov wrote:
> > Raf, this is not about pinning. This is about CA store in mobile devices.
> >
>
> Pinning at its core is just hard-coded entries in those stores or the app.
>
> A pinned cert can be considered like the CA equivalent of having a
> non-editable /etc/hosts file entry for DNS. Lookups happen but dont go
> past the hard-coded entry unless the app bypasses it specially.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160509/ab5d6426/attachment.htm>

From mark.carey at gmail.com  Mon May  9 05:19:34 2016
From: mark.carey at gmail.com (Mark Carey)
Date: Mon, 9 May 2016 17:19:34 +1200
Subject: [squid-users] debug_options appears to change squid behaviour
Message-ID: <CA+ffBu7UV4wuc6Z_01rvc=OZikLhvUefBx+EMzDef8UN1tzawg@mail.gmail.com>

Hi,

Running squid 3.1.19-1ubuntu3.12.04.2.

acl sefup dst massing-uploads.s3.amazonaws.com
acl sefairauser src 192.168.10.54/32
http_access allow sefairauser sefup
http_access allow CONNECT sefairauser sefup

When run "normally" and my application (or browser) tries to access
the site I get, TCP_DENIED

1462769200.720      6 192.168.10.54 TCP_DENIED/403 3737 CONNECT
massing-uploads.s3.amazonaws.com:443 - NONE/- text/html

If I enable debugging

debug_options 28,1

The application seems to start working

1462769557.248  10409 192.168.10.54 TCP_MISS/200 4026 CONNECT
massing-uploads.s3.amazonaws.com:443 - DIRECT/54.231.14.9 -

Now the server owner could be having problems at their end and dishing
out different responses from different hosts in their pool of hosts in
their Amazon AWS cloud.

Is there any reason why squid would use different code paths with
debug_options set?

Thank you.

Mark Carey


From squid3 at treenet.co.nz  Mon May  9 07:20:21 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 9 May 2016 19:20:21 +1200
Subject: [squid-users] debug_options appears to change squid behaviour
In-Reply-To: <CA+ffBu7UV4wuc6Z_01rvc=OZikLhvUefBx+EMzDef8UN1tzawg@mail.gmail.com>
References: <CA+ffBu7UV4wuc6Z_01rvc=OZikLhvUefBx+EMzDef8UN1tzawg@mail.gmail.com>
Message-ID: <a59be123-aa9e-2d3b-726c-4fb896869554@treenet.co.nz>

On 9/05/2016 5:19 p.m., Mark Carey wrote:
> Hi,
> 
> Running squid 3.1.19-1ubuntu3.12.04.2.
> 

Please ugrade. Both your Squid and Ubuntu are very much past their
end-of-life dates.

> acl sefup dst massing-uploads.s3.amazonaws.com
> acl sefairauser src 192.168.10.54/32
> http_access allow sefairauser sefup
> http_access allow CONNECT sefairauser sefup
> 
> When run "normally" and my application (or browser) tries to access
> the site I get, TCP_DENIED
> 
> 1462769200.720      6 192.168.10.54 TCP_DENIED/403 3737 CONNECT
> massing-uploads.s3.amazonaws.com:443 - NONE/- text/html
> 
> If I enable debugging
> 
> debug_options 28,1
> 
> The application seems to start working
> 
> 1462769557.248  10409 192.168.10.54 TCP_MISS/200 4026 CONNECT
> massing-uploads.s3.amazonaws.com:443 - DIRECT/54.231.14.9 -
> 
> Now the server owner could be having problems at their end and dishing
> out different responses from different hosts in their pool of hosts in
> their Amazon AWS cloud.
> 
> Is there any reason why squid would use different code paths with
> debug_options set?

Not with 28,1.

I expect it is your use of dst ACL type. Domain and host names used in
IP based ACLs are resolved on startup or reconfigure.

Use dstdomain for name-based access control.

Amos



From squid3 at treenet.co.nz  Mon May  9 08:24:24 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 9 May 2016 20:24:24 +1200
Subject: [squid-users] [squid-announce] Squid 4.0.10 beta is available
Message-ID: <dca8f7c4-04dc-c4d5-9338-31b45bb9efab@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-4.0.10 release!


This release is a security and bug fix release resolving several
vulnerabilities and issues found in the prior Squid releases.


The major changes to be aware of:


* SQUID-2016:7 - Cache poisoning issue in HTTP Request handling

    http://www.squid-cache.org/Advisories/SQUID-2016_7.txt
    aka. CVE-2016-4553

 Due to incorrect data validation of intercepted HTTP Request
 messages Squid is vulnerable to clients bypassing the protection
 against CVE-2009-0801 related issues. This leads to cache
 poisoning.


* SQUID-2016:9 - Multiple Denial of Service issues in ESI.

    http://www.squid-cache.org/Advisories/SQUID-2016_9.txt
    aka. CVE-2016-4555 and CVE-2016-4556.

 These problems allow a remote server delivering certain ESI
 response syntax to trigger a denial of service for all clients
 accessing the Squid service.


* Accumulate fewer unknown-size responses to avoid overwhelming disks.

Earlier Squid had the behaviour of accumulating large amounts of data in
RAM for unknown-size objects before deciding where to cache them. That
could result in the disk I/O controller and CPU being overwhelmed with
data write operations. In outward appearance Squid would 'hang' for a
short time, then recover. If the overall traffic loading was also very
high the traffic speed could drop noticeably.

This release improves the descision making process. It should result in
lower RAM requirements for some client transactions, and also smoother
disk I/O and CPU usage under high loads.


* Fix a shared memory corruption when storing multi-slot (>32KB) MISS

This is a recent regression in Squid-4.0.8. Other Squid releases are not
affected. It could have resulted in corrupt objects being stored into
disk cache, so erasing and rebuilding disk caches used by affected
Squid-4 is recommended.


 All users of Squid-4.0.x are urged to upgrade to this release as soon
as possible.

 All users of Squid-3 are encouraged to test this release out and plan
for upgrades where possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v4/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries

_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Mon May  9 08:24:39 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 9 May 2016 20:24:39 +1200
Subject: [squid-users] [squid-announce] Squid 3.5.19 is available
Message-ID: <ada87683-be2f-86f6-9dfa-79d049f971bd@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-3.5.19 release!


This release is a security and bug fix release resolving several
vulnerabilities and issues found in the prior Squid releases.


The major changes to be aware of:


* SQUID-2016:7 - Cache poisoning issue in HTTP Request handling

    http://www.squid-cache.org/Advisories/SQUID-2016_7.txt
    aka. CVE-2016-4553

 Due to incorrect data validation of intercepted HTTP Request
 messages Squid is vulnerable to clients bypassing the protection
 against CVE-2009-0801 related issues. This leads to cache
 poisoning.


* SQUID-2016:8 - Header smuggling issue in HTTP Request processing

    http://www.squid-cache.org/Advisories/SQUID-2016_8.txt
    aka. CVE-2016-4554

 This problem allows a client to smuggle Host header value past
 same-origin security protections to cause Squid operating as
 interception or reverse-proxy to contact the wrong origin
 server. Also poisoning any downstream cache which stores the
 response.

 However, the cache poisoning is only possible if the caching
 agent (browser or explicit/forward proxy) is not following RFC
 7230 processing guidelines and lets the smuggled value through.

 Note that all releases of Squid up to and including this one do not
 follow that recently added RFC guideline.


* SQUID-2016:9 - Multiple Denial of Service issues in ESI.

    http://www.squid-cache.org/Advisories/SQUID-2016_9.txt
    aka. CVE-2016-4555 and CVE-2016-4556.

 These problems allow a remote server delivering certain ESI
 response syntax to trigger a denial of service for all clients
 accessing the Squid service.

 Due to unrelated changes Squid-3.5 has become vulnerable to some
 regular ESI server responses also triggering one or more of these
 issues.


* Bug 4498: URL-unescape the login-info after extraction from URI

This bug shows up as the encoded form of credentials that are
URL-escaped being delivered to the authentication helpers or relayed to
FTP servers if in ftp:// URL when the un-escaped form is needed. It
commonly affects credentials which contain characters other than plain
ASCII alphanumerics.


* TLS: Fix SSL alert message and session resume handling

Pevious Squid did not handle SSL/TLS server responses that start with an
SSL Alert Record and also fails to detect and handle resuming sessions.


* Prevent Squid forcing -b 2048 into the arguments for sslcrtd_program

Previous Squid would always send the "-b" command line option to its
certificate generator helper. If the installation was using a custom
helper, this could lead to very annoying issues.



 All users of Squid-3 or older are urged to upgrade to this release as
soon as possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v3/3.5/RELEASENOTES.html
when you are ready to make the switch to Squid-3.5

Upgrade tip:
  "squid -k parse" is starting to display even more
   useful hints about squid.conf changes.

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v3/3.5/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/3.5/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries

_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Mon May  9 08:24:58 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 9 May 2016 20:24:58 +1200
Subject: [squid-users] [squid-announce] [ADVISORY] SQUID-2016:7 Cache
 poisoning issue in HTTP Request handling
Message-ID: <357b94df-6d53-0c77-b2a5-35ccc7a95394@treenet.co.nz>

__________________________________________________________________

    Squid Proxy Cache Security Update Advisory SQUID-2016:7
__________________________________________________________________

Advisory ID:        SQUID-2016:7
Date:               May 06, 2016
Summary:            Cache poisoning issue
                    in HTTP Request handling
Affected versions:  Squid 3.2.0.11 -> 3.5.17
                    Squid 4.x -> 4.0.9
Fixed in version:   Squid 3.5.18, 4.0.10
__________________________________________________________________

    http://www.squid-cache.org/Advisories/SQUID-2016_7.txt
    http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-4553
__________________________________________________________________

Problem Description:

 Due to incorrect data validation of intercepted HTTP Request
 messages Squid is vulnerable to clients bypassing the protection
 against CVE-2009-0801 related issues. This leads to cache
 poisoning.

__________________________________________________________________

Severity:

 This problem is serious because it allows any client, including
 browser scripts, to bypass local security and poison the proxy
 cache and any downstream caches with content from an arbitrary
 source.

__________________________________________________________________

Updated Packages:

 This bug is fixed by Squid version 3.5.18 and 4.0.10.

 In addition, a patch addressing this problem for the stable
 release can be found in our patch archives:

Squid 3.5:
 <http://www.squid-cache.org/Versions/v3/3.5/changesets/squid-3.5-14039.patch>

 If you are using a prepackaged version of Squid then please refer
 to the package vendor for availability information on updated
 packages.

__________________________________________________________________

Determining if your version is vulnerable:

Use the command 'squid -v' to view version and build details of
your proxy;

 All Squid 2.x are not vulnerable.

 All Squid-3.x up to and including 3.2.0.10 are not vulnerable.

 All Squid-3.2.0.11 and later versions up to and including 3.5.17
 are vulnerable.

 All Squid-4.x up to and including 4.0.9 are vulnerable.

__________________________________________________________________

Workaround:

 Add to squid.conf:
   client_dst_passthru off

And,

 Remove any use of "host_verify_strict" directive.

__________________________________________________________________

Contact details for the Squid project:

 For installation / upgrade support on binary packaged versions
 of Squid: Your first point of contact should be your binary
 package vendor.

 If you install and build Squid from the original Squid sources
 then the squid-users at squid-cache.org mailing list is your
 primary support point. For subscription details see
 http://www.squid-cache.org/Support/mailing-lists.html.

 For reporting of non-security bugs in the latest release
 the squid bugzilla database should be used
 http://bugs.squid-cache.org/.

 For reporting of security sensitive bugs send an email to the
 squid-bugs at squid-cache.org mailing list. It is a closed list
 (though anyone can post) and security related bug reports are
 treated in confidence until the impact has been established.

__________________________________________________________________

Credits:

 The vulnerability was reported by Jianjun Chen from Tsinghua
 University.

 Fixed by Amos Jeffries from Treehouse Networks Ltd.

__________________________________________________________________

Revision history:

 2016-04-15 10:54:39 UTC Initial Report
 2016-05-02 10:51:18 UTC Patch Released
 2016-05-06 13:12:00 UTC Packages Released
 2016-05-06 14:46:41 UTC CVE Assignment
__________________________________________________________________
END
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Mon May  9 08:25:23 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 9 May 2016 20:25:23 +1200
Subject: [squid-users] [squid-announce] [ADVISORY] SQUID-2016:8 Header
 smuggling issue in HTTP Request processing
Message-ID: <2d8dbaeb-6adc-2bae-4c4f-c3e4ec40c19b@treenet.co.nz>

__________________________________________________________________

    Squid Proxy Cache Security Update Advisory SQUID-2016:8
__________________________________________________________________

Advisory ID:        SQUID-2016:8
Date:               May 06, 2016
Summary:            Header smuggling issue
                    in HTTP Request processing
Affected versions:  Squid 1.x -> 3.5.17
Fixed in version:   Squid 3.5.18
__________________________________________________________________

    http://www.squid-cache.org/Advisories/SQUID-2016_8.txt
    http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-4554
__________________________________________________________________

Problem Description:

 Due to incorrect input validation Squid is vulnerable to a header
 smuggling attack leading to cache poisoning and to bypass of
 same-origin security policy in Squid and some client browsers.

__________________________________________________________________

Severity:

 This problem allows a client to smuggle Host header value past
 same-origin security protections to cause Squid operating as
 interception or reverse-proxy to contact the wrong origin
 server. Also poisoning any downstream cache which stores the
 response.

 However, the cache poisoning is only possible if the caching
 agent (browser or explicit/forward proxy) is not following RFC
 7230 processing guidelines and lets the smuggled value through.

__________________________________________________________________

Updated Packages:

 This bug is fixed by Squid version 3.5.18

 In addition, patches addressing this problem for stable releases
 can be found in our patch archives:

Squid 3.1:
 <http://www.squid-cache.org/Versions/v3/3.1/changesets/SQUID-2016_8.patch>

Squid 3.2:
 <http://www.squid-cache.org/Versions/v3/3.2/changesets/SQUID-2016_8.patch>

Squid 3.3:
 <http://www.squid-cache.org/Versions/v3/3.3/changesets/SQUID-2016_8.patch>

Squid 3.4:
 <http://www.squid-cache.org/Versions/v3/3.4/changesets/SQUID-2016_8.patch>

Squid 3.5:
 <http://www.squid-cache.org/Versions/v3/3.5/changesets/SQUID-2016_8.patch>

 If you are using a prepackaged version of Squid then please refer
 to the package vendor for availability information on updated
 packages.

__________________________________________________________________

Determining if your version is vulnerable:

  All 2.x versions up to and including 2.7.STABLE9 are vulnerable.

  All 3.x versions up to and including 3.5.17 are vulnerable.

  All 4.x versions are not vulnerable.

__________________________________________________________________

Workaround:

 There are no workarounds for this problem.

__________________________________________________________________

Contact details for the Squid project:

 For installation / upgrade support on binary packaged versions
 of Squid: Your first point of contact should be your binary
 package vendor.

 If you install and build Squid from the original Squid sources
 then the squid-users at squid-cache.org mailing list is your
 primary support point. For subscription details see
 http://www.squid-cache.org/Support/mailing-lists.html.

 For reporting of non-security bugs in the latest release
 the squid bugzilla database should be used
 http://bugs.squid-cache.org/.

 For reporting of security sensitive bugs send an email to the
 squid-bugs at squid-cache.org mailing list. It is a closed list
 (though anyone can post) and security related bug reports are
 treated in confidence until the impact has been established.

__________________________________________________________________

Credits:

 The vulnerability was reported by Jianjun Chen from Tsinghua
 University.

 Fixed by Amos Jeffries from Treehouse Networks Ltd.

__________________________________________________________________

Revision history:

 2016-04-26 09:29:13 UTC Initial Report
 2016-05-02 03:39:35 UTC Patches Released
 2016-05-06 13:12:00 UTC Packages Released
 2016-05-06 14:46:41 UTC CVE Assignment
 2016-05-08 12:45:58 UTC Patches Updated
__________________________________________________________________
END
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Mon May  9 08:25:41 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 9 May 2016 20:25:41 +1200
Subject: [squid-users] [squid-announce] [ADVISORY] SQUID-2016:9 Multiple
 Denial of Service issues in ESI Response processing.
Message-ID: <465d0707-f819-db65-5fb0-bd189526a481@treenet.co.nz>

__________________________________________________________________

    Squid Proxy Cache Security Update Advisory SQUID-2016:9
__________________________________________________________________

Advisory ID:        SQUID-2016:9
Date:               May 06, 2016
Summary:            Multiple Denial of Service issues
                    in ESI Response processing.
Affected versions:  Squid 3.x -> 3.5.17
                    Squid 4.x -> 4.0.9
Fixed in version:   Squid 4.0.10, 3.5.18
__________________________________________________________________

    http://www.squid-cache.org/Advisories/SQUID-2016_9.txt
    http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-4555
    http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2016-4556
__________________________________________________________________

Problem Description:

 Due to incorrect pointer handling and reference counting Squid is
 vulnerable to a denial of service attack when processing ESI
 responses.

__________________________________________________________________

Severity:

 These problems allow a remote server delivering certain ESI
 response syntax to trigger a denial of service for all clients
 accessing the Squid service.

 Due to unrelated changes Squid-3.5 has become vulnerable to some
 regular ESI server responses also triggering one or more of these
 issues.

__________________________________________________________________

Updated Packages:

 This bug is fixed by Squid version 3.5.18 and 4.0.10.

 In addition, patches addressing this problem for the stable
 releases can be found in our patch archives:

Squid 3.4:
 <http://www.squid-cache.org/Versions/v3/3.4/changesets/SQUID-2016_9.patch>

Squid 3.5:
 <http://www.squid-cache.org/Versions/v3/3.5/changesets/SQUID-2016_9.patch>

 If you are using a prepackaged version of Squid then please refer
 to the package vendor for availability information on updated
 packages.

__________________________________________________________________

Determining if your version is vulnerable:

 All Squid-2.x are not vulnerable.

 All Squid built with --disable-esi are not vulnerable.

 All Squid-3.0 versions built without --enable-esi are not
 vulnerable.

 All Squid-3.0 versions built with --enable-esi and used for
 reverse-proxy are vulnerable.

 All Squid-3.1 and later versions up to and including
 Squid-3.5.17 being used for reverse-proxy are vulnerable.

 All Squid-3.1 and later versions up to and including
 Squid-3.5.17 being used for TLS / HTTPS interception are
 vulnerable.

 All unpatched Squid-4.0 up to and including Squid-4.0.9
 being used as reverse-proxy are vulnerable.

 All unpatched Squid-4.0 up to and including Squid-4.0.9
 being used as TLS/HTTPS intercept proxy are vulnerable.

__________________________________________________________________

Workaround:

 Build Squid with --disable-esi

__________________________________________________________________

Contact details for the Squid project:

 For installation / upgrade support on binary packaged versions
 of Squid: Your first point of contact should be your binary
 package vendor.

 If your install and build Squid from the original Squid sources
 then the squid-users at lists.squid-cache.org mailing list is your
 primary support point. For subscription details see
 <http://www.squid-cache.org/Support/mailing-lists.html>.

 For reporting of non-security bugs in the latest STABLE release
 the squid bugzilla database should be used
 <http://bugs.squid-cache.org/>.

 For reporting of security sensitive bugs send an email to the
 squid-bugs at lists.squid-cache.org mailing list. It's a closed
 list (though anyone can post) and security related bug reports
 are treated in confidence until the impact has been established.

__________________________________________________________________

Credits:

 The initial issue was reported by "bfek-18".

 Additional issues and attack vector was reported by "@vftable".

 Fixed by Amos Jeffries from Treehouse Networks Ltd.

__________________________________________________________________

Revision history:

 2016-03-02 15:12:12 UTC Initial Report
 2016-05-01 23:48:27 UTC Additional Issue Report
 2016-05-06 09:39:48 UTC Patches Released
 2016-05-06 13:12:00 UTC Packages Released
 2016-05-06 14:46:41 UTC CVE Assignment
__________________________________________________________________
END
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From Adam.Cohen-Rose at sky.uk  Mon May  9 10:05:43 2016
From: Adam.Cohen-Rose at sky.uk (Cohen-Rose, Adam)
Date: Mon, 9 May 2016 10:05:43 +0000
Subject: [squid-users] SSL Bump missing facebook app traffic (resumed SSL
	sessions?)
Message-ID: <D3561F85.535B7%adam.cohen-rose@sky.uk>

Hi there,

We?re running squid with SSL bump as a transparent proxy in order to
control access to particular SSL sites.

We?ve noticed an issue with access to facebook from within the facebook
app -- specifically it can get through the proxy even though it is *not*
listed as a domain to splice. Accessing the facebook site from a web
browser is blocked as expected.

Looking at packets in Wireshark, the app traffic that gets through seems
to use a different style of SSL handshake from the web traffic as follows:

App traffic:
> client hello
< server hello, change cipher spec
  - change cipher spec message: this session reuses previously negotiated
keys (session resumption)
< encrypted handshake message
> change cipher spec, encrypted handshake message, application data
> application data


Web traffic:
> client hello
< server hello
< certificate
< server key exchange
> client key exchange
> change cipher spec
> encryped handshake message
< new session ticket, change cipher spec, encrypted handshake message
> application data



I suspect this may be the same or a similar issue referred to in the
3.5.19 release changes (TLS: Fix SSL alert message and session resume
handling) -- would someone please confirm or deny?

And if we were to upgrade to 3.5.19, is the build on Centos 6 a relatively
easy one? We?ve been using Eliezer Croitoru?s builds so far, but I don?t
think he?s had time to make the latest build yet!


For reference, the relevant parts of our squid configuration are as
follows:

https_port {squid-ip}:443 cert=/path/to/cert key=/path/to/key
sslflags=NO_DEFAULT_CA intercept ssl-bump
acl to_teads_tv_ssl ssl::server_name .teads.tv
ssl_bump splice to_teads_tv_ssl

acl hello at_step SslBump1 SslBump2
ssl_bump peek hello
ssl_bump terminate all



Thank you for your help!

Adam

Information in this email including any attachments may be privileged, confidential and is intended exclusively for the addressee. The views expressed may not be official policy, but the personal views of the originator. If you have received it in error, please notify the sender by return e-mail and delete it from your system. You should not reproduce, distribute, store, retransmit, use or disclose its contents to anyone. Please note we reserve the right to monitor all e-mail communication through our internal and external networks. SKY and the SKY marks are trademarks of Sky plc and Sky International AG and are used under licence. Sky UK Limited (Registration No. 2906991), Sky-In-Home Service Limited (Registration No. 2067075) and Sky Subscribers Services Limited (Registration No. 2340150) are direct or indirect subsidiaries of Sky plc (Registration No. 2247735). All of the companies mentioned in this paragraph are incorporated in England and Wales and share the same registered office at Grant Way, Isleworth, Middlesex TW7 5QD.


From corpengineer at gmail.com  Mon May  9 17:07:00 2016
From: corpengineer at gmail.com (J Green)
Date: Mon, 9 May 2016 10:07:00 -0700
Subject: [squid-users] Can Traffic Management Settings be configured for
	other TCP protocols?
Message-ID: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>

Hello all:

Can Traffic Management Settings be configured for TCP protocols other than
HTTP?

Would like to limit maximum upload and download sizes for other TCP
protocols:  SMB, NFS, FTP, and RDP.

Is this possible?  If so, how?

Thank you.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160509/1e82e901/attachment.htm>

From yvoinov at gmail.com  Mon May  9 17:12:33 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 9 May 2016 23:12:33 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
Message-ID: <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Squid is not a proxy server every imaginable the TCP-usage protocol.

AFAIK HTTP/HTTPS/FTP. That's all, folks.


09.05.16 23:07, J Green ?????:
> Hello all:
>
> Can Traffic Management Settings be configured for TCP protocols other
than HTTP?
>
> Would like to limit maximum upload and download sizes for other TCP
protocols:  SMB, NFS, FTP, and RDP.
>
> Is this possible?  If so, how?
>
> Thank you.
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMMUAAAoJENNXIZxhPexGOy8IAMs2DbmNAopj7jqL5Z9KEg6z
GpRL7y207VkSaz12Bhcdf2PsAy+xCnHzJ6SMeR4MNKeTrfImSQoyJbS4UuFHygcR
v+9618vUKfpcYaTUc09DTJUh49F0PwJX/lJQxNiDtb/AHEkX+WdDbuFL2S8+AzJm
ZhNA1FigXzuhGpwaxqhh2uB0zL5wec7IQuSO24POPvBf/hgvzSmBuH6u1SuBLvpp
RPObRULHTaWhyvMQgufHWm1H0ejpvCZgCqEEcXSW4MbqCatr8DBSmkP28EfweocD
4mdpKTWu6HX9EX3ZZ96dKqsOjEBXlKU8BUqlK2irMQgM09IIXCjCRc5W00Qv8tA=
=v0m2
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160509/408765b2/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160509/408765b2/attachment.key>

From yvoinov at gmail.com  Mon May  9 17:14:17 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 9 May 2016 23:14:17 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
Message-ID: <fa5e0a0f-e488-9e53-0d5d-3da215344c12@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
https://i1.someimage.com/DTMWEmc.png


09.05.16 23:07, J Green ?????:
> Hello all:
>
> Can Traffic Management Settings be configured for TCP protocols other
than HTTP?
>
> Would like to limit maximum upload and download sizes for other TCP
protocols:  SMB, NFS, FTP, and RDP.
>
> Is this possible?  If so, how?
>
> Thank you.
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMMVpAAoJENNXIZxhPexGxlEIAIofKgK4Q+imEidyjDusR/QA
aQRVSma4gskz1LpHpGt0aK+BVKfKCZNsiX8gEiD/oU29N91Cc5ubixcdPj6bKji6
SqmdCykZp1XLgTPxtQz1sLuw0nlARn6KU6P3RlZTVX2CdRLN3Olm7FM9ywldqP8e
jwJYQXwnWE5xpv7SeGc9T/5/kciAUClJ7rc6Ci3ndHqH0KpWcmzKjIhbgHzhGvIb
PhyNWzhHc2M3sPAlAh47f3QdBZEco4eCgkShRXMiGoZZCVixjSJBZE+YTfCqHa65
84q6CCEw/MtRSIby3bAq6sSYc+JMbJ3buWUq3B4QF6RiNXx2Q5wAfmCd07L+uUU=
=V0iK
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160509/8b08d0d7/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160509/8b08d0d7/attachment.key>

From corpengineer at gmail.com  Mon May  9 18:05:38 2016
From: corpengineer at gmail.com (J Green)
Date: Mon, 9 May 2016 11:05:38 -0700
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
Message-ID: <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>

Appreciate the response.  Thought it might work if I added those ports to
the safe list.

If not Squid, any idea how to accomplish this?

Thank you.

On Mon, May 9, 2016 at 10:12 AM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> Squid is not a proxy server every imaginable the TCP-usage protocol.
>
> AFAIK HTTP/HTTPS/FTP. That's all, folks.
>
>
> 09.05.16 23:07, J Green ?????:
> > Hello all:
> >
> > Can Traffic Management Settings be configured for TCP protocols other
> than HTTP?
> >
> > Would like to limit maximum upload and download sizes for other TCP
> protocols:  SMB, NFS, FTP, and RDP.
> >
> > Is this possible?  If so, how?
> >
> > Thank you.
> >
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXMMUAAAoJENNXIZxhPexGOy8IAMs2DbmNAopj7jqL5Z9KEg6z
> GpRL7y207VkSaz12Bhcdf2PsAy+xCnHzJ6SMeR4MNKeTrfImSQoyJbS4UuFHygcR
> v+9618vUKfpcYaTUc09DTJUh49F0PwJX/lJQxNiDtb/AHEkX+WdDbuFL2S8+AzJm
> ZhNA1FigXzuhGpwaxqhh2uB0zL5wec7IQuSO24POPvBf/hgvzSmBuH6u1SuBLvpp
> RPObRULHTaWhyvMQgufHWm1H0ejpvCZgCqEEcXSW4MbqCatr8DBSmkP28EfweocD
> 4mdpKTWu6HX9EX3ZZ96dKqsOjEBXlKU8BUqlK2irMQgM09IIXCjCRc5W00Qv8tA=
> =v0m2
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160509/2e0b245e/attachment.htm>

From yvoinov at gmail.com  Mon May  9 18:16:56 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 May 2016 00:16:56 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>
Message-ID: <ba022856-d2ca-d54d-59ff-5614b6e665e9@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


10.05.16 0:05, J Green ?????:
> Appreciate the response.  Thought it might work if I added those ports to the safe list.

That "may, after a series of distortions and violations of the
recommendations" does not mean "designed".

>
> If not Squid, any idea how to accomplish this?

The first time I hear that someone may come to mind to proxy SMB, NFS, RDP.

>
> Thank you.
>
> On Mon, May 9, 2016 at 10:12 AM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> Squid is not a proxy server every imaginable the TCP-usage protocol.
>
> AFAIK HTTP/HTTPS/FTP. That's all, folks.
>
>
> 09.05.16 23:07, J Green ?????:
> > Hello all:
>
>
>
>       > Can Traffic Management Settings be configured for TCP
>       protocols other than HTTP?
>
>
>
>       > Would like to limit maximum upload and download sizes for
>       other TCP protocols:  SMB, NFS, FTP, and RDP.
>
>
>
>       > Is this possible?  If so, how?
>
>
>
>       > Thank you.
>
>
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMNQXAAoJENNXIZxhPexGdN4H+wZWwXfHxTtI2F1hmon5g+/0
PIbJbb8ZxcCIPl1VyAej7gFi+VSOf6W+k7Ya3uaFVYL6xWRXAOGQzEX1PovPfE8z
brH7rW7/ukZK3K8/3Y7K3E/J7rcwdYpIW2r37cbxl/DXASfQz/f150zgvQvfUi77
KsU45KCcScTfUlZ7rpSU87ynXnYUfEUG/iiAzP/97gjotsKqTHhgj/UZI9m5LVJ7
PNuBNOazMQMdLa6jB9nCXnjPeZUyD/YDmhQ8cHUwnGfLFBaQDE/V7OML1ovWv2x5
dpAOUZMGzMS5+3/aTNfC1me0rm2gjBpMq2N1pIylYoaPnGSZ9DT9hsTlkTL88kI=
=pPbM
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/158375b9/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/158375b9/attachment.key>

From yvoinov at gmail.com  Mon May  9 18:18:15 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 May 2016 00:18:15 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>
Message-ID: <d08dd83b-fd64-3479-1772-ab934a4ea468@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
As I know, even this solution can not:

https://www.bluecoat.com/products-and-solutions/on-premise-secure-web-gateway

10.05.16 0:05, J Green ?????:
> Appreciate the response.  Thought it might work if I added those ports to the safe list.
>
> If not Squid, any idea how to accomplish this?
>
> Thank you.
>
> On Mon, May 9, 2016 at 10:12 AM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> Squid is not a proxy server every imaginable the TCP-usage protocol.
>
> AFAIK HTTP/HTTPS/FTP. That's all, folks.
>
>
> 09.05.16 23:07, J Green ?????:
> > Hello all:
>
>
>
>       > Can Traffic Management Settings be configured for TCP
>       protocols other than HTTP?
>
>
>
>       > Would like to limit maximum upload and download sizes for
>       other TCP protocols:  SMB, NFS, FTP, and RDP.
>
>
>
>       > Is this possible?  If so, how?
>
>
>
>       > Thank you.
>
>
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMNRnAAoJENNXIZxhPexGgg4H/2kd0y7hhypCWMlOnvzDUiOq
otgreU9Z1tnPi/U8b+qmL+woXT6oy2d25CRMBZa8N38le0OS1zkH9e/XiagAJefK
gv2IWdDlO1F/ibPzhTG4nGMMT4HzXgDYGCdJCLe33E5Q/1nRFCzAeabfHPQeeLwD
Xl/qbKA6b1gUusmH4PAdl/oANNW10RrPC2X39Ei2k7BQVPXRB/kU599sd13S2F44
s2RlGIKb4N4eQMkIUM+cffZ8e9URnoad/m7HkKs5ZUrZOb4Ayt67kE5YVt98oyuJ
+zGafGwOm+A06Hpa/LMbpb21WOajStq3h5hX9QZSROsiL0xsWOPT07pf6sTSfXY=
=4zKK
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/219a032e/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/219a032e/attachment.key>

From corpengineer at gmail.com  Mon May  9 18:21:32 2016
From: corpengineer at gmail.com (J Green)
Date: Mon, 9 May 2016 11:21:32 -0700
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <d08dd83b-fd64-3479-1772-ab934a4ea468@gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>
 <d08dd83b-fd64-3479-1772-ab934a4ea468@gmail.com>
Message-ID: <CANUpZyyByB6wJauyJrJPj4kkH+s+fFnXTLvP2r07vc-s=2rONw@mail.gmail.com>

Thank you.  Yes, I am having a difficult time trying to find a solution for
this.

On Mon, May 9, 2016 at 11:18 AM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> As I know, even this solution can not:
>
>
> https://www.bluecoat.com/products-and-solutions/on-premise-secure-web-gateway
>
> 10.05.16 0:05, J Green ?????:
> > Appreciate the response.  Thought it might work if I added those ports
> to the safe list.
> >
> > If not Squid, any idea how to accomplish this?
> >
> > Thank you.
> >
> > On Mon, May 9, 2016 at 10:12 AM, Yuri Voinov <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com> <yvoinov at gmail.com>> wrote:
> >
> >
> > Squid is not a proxy server every imaginable the TCP-usage protocol.
> >
> > AFAIK HTTP/HTTPS/FTP. That's all, folks.
> >
> >
> > 09.05.16 23:07, J Green ?????:
> > > Hello all:
> >
> >
> >
> >       > Can Traffic Management Settings be configured for TCP
> >       protocols other than HTTP?
> >
> >
> >
> >       > Would like to limit maximum upload and download sizes for
> >       other TCP protocols:  SMB, NFS, FTP, and RDP.
> >
> >
> >
> >       > Is this possible?  If so, how?
> >
> >
> >
> >       > Thank you.
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >       > _______________________________________________
> >
> >       > squid-users mailing list
> >
> >       > squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> >
> >       > http://lists.squid-cache.org/listinfo/squid-users
> >
> >
> >
> >     _______________________________________________
> >     squid-users mailing list
> >     squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> >     http://lists.squid-cache.org/listinfo/squid-users
> >
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXMNRnAAoJENNXIZxhPexGgg4H/2kd0y7hhypCWMlOnvzDUiOq
> otgreU9Z1tnPi/U8b+qmL+woXT6oy2d25CRMBZa8N38le0OS1zkH9e/XiagAJefK
> gv2IWdDlO1F/ibPzhTG4nGMMT4HzXgDYGCdJCLe33E5Q/1nRFCzAeabfHPQeeLwD
> Xl/qbKA6b1gUusmH4PAdl/oANNW10RrPC2X39Ei2k7BQVPXRB/kU599sd13S2F44
> s2RlGIKb4N4eQMkIUM+cffZ8e9URnoad/m7HkKs5ZUrZOb4Ayt67kE5YVt98oyuJ
> +zGafGwOm+A06Hpa/LMbpb21WOajStq3h5hX9QZSROsiL0xsWOPT07pf6sTSfXY=
> =4zKK
> -----END PGP SIGNATURE-----
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160509/af8bf87a/attachment.htm>

From yvoinov at gmail.com  Mon May  9 18:53:00 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 May 2016 00:53:00 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZyyByB6wJauyJrJPj4kkH+s+fFnXTLvP2r07vc-s=2rONw@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>
 <d08dd83b-fd64-3479-1772-ab934a4ea468@gmail.com>
 <CANUpZyyByB6wJauyJrJPj4kkH+s+fFnXTLvP2r07vc-s=2rONw@mail.gmail.com>
Message-ID: <bc4f9ad0-9021-abd3-30f9-5c9670c11707@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
You are welcome.

Just to clarify. For proxying anything (protocol or service), the proxy
server must be at the same time also act as the client of a protocol or
service - and as a server. It is known for at least several hundreds of
protocols. It is hard to imagine that such a comprehensive proxy anyone
ever wrote. Especially for the protocols that do not need to cache, or
even more so, in principle, to proxy.


10.05.16 0:21, J Green ?????:
> Thank you.  Yes, I am having a difficult time trying to find a solution for this.
>
> On Mon, May 9, 2016 at 11:18 AM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> As I know, even this solution can not:
>
>
https://www.bluecoat.com/products-and-solutions/on-premise-secure-web-gateway
>
> 10.05.16 0:05, J Green ?????:
> > Appreciate the response.
>       Thought it might work if I added those ports to the safe list.
>
>
>
>       > If not Squid, any idea how to accomplish this?
>
>
>
>       > Thank you.
>
>
>
>       > On Mon, May 9, 2016 at 10:12 AM, Yuri Voinov
>       <yvoinov at gmail.com <mailto:yvoinov at gmail.com>
<mailto:yvoinov at gmail.com> <mailto:yvoinov at gmail.com>> wrote:
>
>
>
>
>
>       > Squid is not a proxy server every imaginable the TCP-usage
>       protocol.
>
>
>
>       > AFAIK HTTP/HTTPS/FTP. That's all, folks.
>
>
>
>
>
>       > 09.05.16 23:07, J Green ?????:
>
>       > > Hello all:
>
>
>
>
>
>
>
>       >       > Can Traffic Management Settings be configured for
>       TCP
>
>       >       protocols other than HTTP?
>
>
>
>
>
>
>
>       >       > Would like to limit maximum upload and download
>       sizes for
>
>       >       other TCP protocols:  SMB, NFS, FTP, and RDP.
>
>
>
>
>
>
>
>       >       > Is this possible?  If so, how?
>
>
>
>
>
>
>
>       >       > Thank you.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > _______________________________________________
>
>
>
>       >       > squid-users mailing list
>
>
>
>       >       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>       <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>
>
>       >       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>       >     _______________________________________________
>
>       >     squid-users mailing list
>
>       >     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>       <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>       >     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMNyLAAoJENNXIZxhPexGJ4cH/RW18n14O3DVcNugV7PjLqVs
VoC/BKtzdNQTnstS/8leC1N8eUfCAtgQuSW1esZsdjm/F5V9JagCuZ617v6c2Z9w
m36XuH86SUVYLxd/pTHX8LBEzWxlcfU5v68wPEPXtHK0RfagHruYnRpcsT23Mt5X
WZFM6jOhRD3pECQYnLYlKKizDjQzTPc/jiLzS6E8fJGI4oZfcx6pd1j2h+XyecGv
scNDUogBWoqOB3ZyNw2CODVE9ehWaL7ghb8bkd4cbreCvcI5kFQ51k3CWgY0nRH1
R6GgJ0rE0y5ADArhJLMsVhQmmiEBj1Dhcy9vKZMnDgS7il65xZKb8rbdwJnYmrs=
=Yqac
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/a4d3b39f/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/a4d3b39f/attachment.key>

From rousskov at measurement-factory.com  Mon May  9 19:15:30 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 9 May 2016 13:15:30 -0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <bc4f9ad0-9021-abd3-30f9-5c9670c11707@gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>
 <d08dd83b-fd64-3479-1772-ab934a4ea468@gmail.com>
 <CANUpZyyByB6wJauyJrJPj4kkH+s+fFnXTLvP2r07vc-s=2rONw@mail.gmail.com>
 <bc4f9ad0-9021-abd3-30f9-5c9670c11707@gmail.com>
Message-ID: <5730E1D2.8090901@measurement-factory.com>

On 05/09/2016 12:53 PM, Yuri Voinov wrote:

> Just to clarify. For proxying anything (protocol or service), the proxy
> server must be at the same time also act as the client of a protocol or
> service - and as a server.


It all depends on the definition of "upload and download sizes" in the
OP question. If the intent is to understand and restrict individual
protocol messages, then you are right. If the intent is just to limit
the aggregate number of TCP bytes transferred, then protocol
understanding (in a "transparent" setup) is not required.

Needless to say, Squid is unlikely to be the best solution for the
latter "dumb traffic limits" problem, but if an "all-in-one executable"
is a critical requirement, one can make modern Squids to limit tunneled
TCP traffic that it does not understand.

Alex.


> J Green:
>>> Would like to limit maximum upload and download sizes for
>>>       other TCP protocols:  SMB, NFS, FTP, and RDP.


From yvoinov at gmail.com  Mon May  9 19:27:30 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 May 2016 01:27:30 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <5730E1D2.8090901@measurement-factory.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>
 <d08dd83b-fd64-3479-1772-ab934a4ea468@gmail.com>
 <CANUpZyyByB6wJauyJrJPj4kkH+s+fFnXTLvP2r07vc-s=2rONw@mail.gmail.com>
 <bc4f9ad0-9021-abd3-30f9-5c9670c11707@gmail.com>
 <5730E1D2.8090901@measurement-factory.com>
Message-ID: <e30f0de8-2025-1051-d6b6-19961760b270@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
For such task enough put Cisco router with TCP traffic policies .....

And please - any protocol, any speed limits, any ACL's, any SLA .....


10.05.16 1:15, Alex Rousskov ?????:
> On 05/09/2016 12:53 PM, Yuri Voinov wrote:
>
>> Just to clarify. For proxying anything (protocol or service), the proxy
>> server must be at the same time also act as the client of a protocol or
>> service - and as a server.
>
>
> It all depends on the definition of "upload and download sizes" in the
> OP question. If the intent is to understand and restrict individual
> protocol messages, then you are right. If the intent is just to limit
> the aggregate number of TCP bytes transferred, then protocol
> understanding (in a "transparent" setup) is not required.
>
> Needless to say, Squid is unlikely to be the best solution for the
> latter "dumb traffic limits" problem, but if an "all-in-one executable"
> is a critical requirement, one can make modern Squids to limit tunneled
> TCP traffic that it does not understand.
>
> Alex.
>
>
>> J Green:
>>>> Would like to limit maximum upload and download sizes for
>>>>       other TCP protocols:  SMB, NFS, FTP, and RDP.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMOSiAAoJENNXIZxhPexGmOAIAJhNvgZRR5ehoj/UBiqPQJQa
rOxzPE52Z2iw7jlN+Iy3R9yW/noJyi7SQ91ll1p/rtEUbDhoObCPwClg/BIb45Ah
J8T2UrvqkebVLjKOkNVmH9BlZ0cioiLcsI/vATSg6cEIdD4ZxHIV99VigKWx4tk1
NxGBKQats5fOTsrqrH4dPsRIyQgCgjAwF9IgAjU5Hxy4Xrbe8sFNxjOh6tabIB4q
WUaBhch6eaxZEKw8aR9G6fxYRrTlMUHhxhHT15O52CSt6kwl+HVTRdlt5acQRxvN
0dTDxKOn1PUMix13WtbhpausAC54VJTCfUgmukB3TSWWXQYeA7/S/Bj2L0REgM8=
=LcoZ
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/469477ff/attachment.key>

From corpengineer at gmail.com  Mon May  9 21:15:43 2016
From: corpengineer at gmail.com (J Green)
Date: Mon, 9 May 2016 14:15:43 -0700
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <e30f0de8-2025-1051-d6b6-19961760b270@gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>
 <d08dd83b-fd64-3479-1772-ab934a4ea468@gmail.com>
 <CANUpZyyByB6wJauyJrJPj4kkH+s+fFnXTLvP2r07vc-s=2rONw@mail.gmail.com>
 <bc4f9ad0-9021-abd3-30f9-5c9670c11707@gmail.com>
 <5730E1D2.8090901@measurement-factory.com>
 <e30f0de8-2025-1051-d6b6-19961760b270@gmail.com>
Message-ID: <CANUpZyxf9f4TzzD5D4JiBJKiSHCo_yLOsoYG70AQNPaOwcWaXw@mail.gmail.com>

Here, re 'upload and download sizes', I meant the later 'dumb traffic
limits'.

We do have a Cisco firewall in place, and I have setup 'traffic policing'.
However, the results are inconsistent.  Sometimes it seems to work, other
times it blocks everything, or it blocks nothing.

Appreciate all the feedback, thank you all for your time.

On Mon, May 9, 2016 at 12:27 PM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> For such task enough put Cisco router with TCP traffic policies .....
>
> And please - any protocol, any speed limits, any ACL's, any SLA .....
>
>
> 10.05.16 1:15, Alex Rousskov ?????:
> > On 05/09/2016 12:53 PM, Yuri Voinov wrote:
> >
> >> Just to clarify. For proxying anything (protocol or service), the proxy
> >> server must be at the same time also act as the client of a protocol or
> >> service - and as a server.
> >
> >
> > It all depends on the definition of "upload and download sizes" in the
> > OP question. If the intent is to understand and restrict individual
> > protocol messages, then you are right. If the intent is just to limit
> > the aggregate number of TCP bytes transferred, then protocol
> > understanding (in a "transparent" setup) is not required.
> >
> > Needless to say, Squid is unlikely to be the best solution for the
> > latter "dumb traffic limits" problem, but if an "all-in-one executable"
> > is a critical requirement, one can make modern Squids to limit tunneled
> > TCP traffic that it does not understand.
> >
> > Alex.
> >
> >
> >> J Green:
> >>>> Would like to limit maximum upload and download sizes for
> >>>>       other TCP protocols:  SMB, NFS, FTP, and RDP.
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXMOSiAAoJENNXIZxhPexGmOAIAJhNvgZRR5ehoj/UBiqPQJQa
> rOxzPE52Z2iw7jlN+Iy3R9yW/noJyi7SQ91ll1p/rtEUbDhoObCPwClg/BIb45Ah
> J8T2UrvqkebVLjKOkNVmH9BlZ0cioiLcsI/vATSg6cEIdD4ZxHIV99VigKWx4tk1
> NxGBKQats5fOTsrqrH4dPsRIyQgCgjAwF9IgAjU5Hxy4Xrbe8sFNxjOh6tabIB4q
> WUaBhch6eaxZEKw8aR9G6fxYRrTlMUHhxhHT15O52CSt6kwl+HVTRdlt5acQRxvN
> 0dTDxKOn1PUMix13WtbhpausAC54VJTCfUgmukB3TSWWXQYeA7/S/Bj2L0REgM8=
> =LcoZ
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160509/b7783ade/attachment.htm>

From yvoinov at gmail.com  Mon May  9 21:28:05 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 May 2016 03:28:05 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZyxf9f4TzzD5D4JiBJKiSHCo_yLOsoYG70AQNPaOwcWaXw@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>
 <d08dd83b-fd64-3479-1772-ab934a4ea468@gmail.com>
 <CANUpZyyByB6wJauyJrJPj4kkH+s+fFnXTLvP2r07vc-s=2rONw@mail.gmail.com>
 <bc4f9ad0-9021-abd3-30f9-5c9670c11707@gmail.com>
 <5730E1D2.8090901@measurement-factory.com>
 <e30f0de8-2025-1051-d6b6-19961760b270@gmail.com>
 <CANUpZyxf9f4TzzD5D4JiBJKiSHCo_yLOsoYG70AQNPaOwcWaXw@mail.gmail.com>
Message-ID: <3b104d9b-d502-a5a1-279c-5540301a70d5@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
No-no, not policing. This is too blunt instrument.

Try to dig in direction of policy-map, bandwidth, service policy, QoS
and control-plane.

Unfortunately, this is offtopic here. This is a completely different
proprietary tool. This is not the time nor the place to discuss these
issues.

> We do have a Cisco firewall in place, and I have setup 'traffic policing'.  However, the results are
inconsistent.  Sometimes it seems to work, other times it blocks
everything, or it blocks nothing.
>
> Appreciate all the feedback, thank you all for your time.
>
> On Mon, May 9, 2016 at 12:27 PM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> For such task enough put Cisco router with TCP traffic policies .....
>
> And please - any protocol, any speed limits, any ACL's, any SLA .....
>
>
> 10.05.16 1:15, Alex Rousskov ?????:
> > On 05/09/2016 12:53 PM, Yuri Voinov wrote:
>
> >> Just to clarify. For proxying anything (protocol or service), the proxy
> >> server must be at the same time also act as the client of a protocol or
> >> service - and as a server.
>
>
> > It all depends on the definition of "upload and download sizes" in the
> > OP question. If the intent is to understand and restrict individual
> > protocol messages, then you are right. If the intent is just to limit
> > the aggregate number of TCP bytes transferred, then protocol
> > understanding (in a "transparent" setup) is not required.
>
> > Needless to say, Squid is unlikely to be the best solution for the
> > latter "dumb traffic limits" problem, but if an "all-in-one executable"
> > is a critical requirement, one can make modern Squids to limit tunneled
> > TCP traffic that it does not understand.
>
> > Alex.
>
>
> >> J Green:
> >>>> Would like to limit maximum upload and download sizes for
> >>>>       other TCP protocols:  SMB, NFS, FTP, and RDP.
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMQDkAAoJENNXIZxhPexGuh0H/A5EqyONyPmmfC+Ql2rATcJ2
tmXtx847qNlL0v5Hjy8ZPUpNyh7oN/UQwD71I7+5AXwpN0eSVwQnn/a5IqTVLOz3
ki1ks2G1O/vHT+Kb9+BtCm48MMqpRF/+ODvVc54zj74sJbwh7HtEkaCBHYVW8NZg
ztmz0QXRFW5WUa3ASqehpWJApemEBM7Nev5OTTR4mqTPrYSfXrXFk8vy9B01wzMy
lLd+PenxmzByIVy3PRHZ/di9qUL5QM4d6cXBC1JiJgjDnzErAan76fgjjQBkR6zr
KTCA+/zKi5+XHfI4nqvHG1LbQelTcfT45PFil0YAaAbUkKkRpVhywdY8PSWnrPc=
=Wla5
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/917864cd/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/917864cd/attachment.key>

From yvoinov at gmail.com  Mon May  9 21:31:18 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 May 2016 03:31:18 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZyxf9f4TzzD5D4JiBJKiSHCo_yLOsoYG70AQNPaOwcWaXw@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>
 <d08dd83b-fd64-3479-1772-ab934a4ea468@gmail.com>
 <CANUpZyyByB6wJauyJrJPj4kkH+s+fFnXTLvP2r07vc-s=2rONw@mail.gmail.com>
 <bc4f9ad0-9021-abd3-30f9-5c9670c11707@gmail.com>
 <5730E1D2.8090901@measurement-factory.com>
 <e30f0de8-2025-1051-d6b6-19961760b270@gmail.com>
 <CANUpZyxf9f4TzzD5D4JiBJKiSHCo_yLOsoYG70AQNPaOwcWaXw@mail.gmail.com>
Message-ID: <df50bfcf-4da3-1e7a-585a-3f66e0012f3d@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I'm afraid Cisco firewall is not enough here.

You need something more advanced. Like integrated service router,
i.e.2901 or 2911, or something similar. With iOS 15.5 and complete
hardware support.

10.05.16 3:15, J Green ?????:
> Here, re 'upload and download sizes', I meant the later 'dumb traffic limits'.
>
> We do have a Cisco firewall in place, and I have setup 'traffic
policing'.  However, the results are inconsistent.  Sometimes it seems
to work, other times it blocks everything, or it blocks nothing.
>
> Appreciate all the feedback, thank you all for your time.
>
> On Mon, May 9, 2016 at 12:27 PM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> For such task enough put Cisco router with TCP traffic policies .....
>
> And please - any protocol, any speed limits, any ACL's, any SLA .....
>
>
> 10.05.16 1:15, Alex Rousskov ?????:
> > On 05/09/2016 12:53 PM, Yuri Voinov wrote:
>
> >> Just to clarify. For proxying anything (protocol or service), the proxy
> >> server must be at the same time also act as the client of a protocol or
> >> service - and as a server.
>
>
> > It all depends on the definition of "upload and download sizes" in the
> > OP question. If the intent is to understand and restrict individual
> > protocol messages, then you are right. If the intent is just to limit
> > the aggregate number of TCP bytes transferred, then protocol
> > understanding (in a "transparent" setup) is not required.
>
> > Needless to say, Squid is unlikely to be the best solution for the
> > latter "dumb traffic limits" problem, but if an "all-in-one executable"
> > is a critical requirement, one can make modern Squids to limit tunneled
> > TCP traffic that it does not understand.
>
> > Alex.
>
>
> >> J Green:
> >>>> Would like to limit maximum upload and download sizes for
> >>>>       other TCP protocols:  SMB, NFS, FTP, and RDP.
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMQGlAAoJENNXIZxhPexGUrUIAJPB/z0efUrIg/MQNdt/rhYh
xc4S+0y1E0uDooctFOrHxsRaFq8QoegHRpAQ8EOR9jH2sTkKeLWzT7q4RGNzjVK8
Zmq/lb2W4TG4tdpfEwt07/46koLd47EIlYfmm9sqck+Lez2JgHZ9+y8Il9fbEGqY
mUL9qwNtK9Wp2VjaNMZ447oOIShZj6nDELo9raVDkknpluFl37M0WFkmShR076Rw
NvhA9pto1u+Sx9STSkFz7AgkU4vp4Nzetlqg1cjoklmQTN/iAgyQK+2FRYoYgtJO
rZxjcC1iFkTV+J0xwS9iWBfktRDTi247oLhDCxK9jL6SDhs771sGJmuGJaJ8Mnw=
=jTlc
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/c367046c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/c367046c/attachment.key>

From yvoinov at gmail.com  Mon May  9 21:33:23 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 May 2016 03:33:23 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZyxf9f4TzzD5D4JiBJKiSHCo_yLOsoYG70AQNPaOwcWaXw@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>
 <d08dd83b-fd64-3479-1772-ab934a4ea468@gmail.com>
 <CANUpZyyByB6wJauyJrJPj4kkH+s+fFnXTLvP2r07vc-s=2rONw@mail.gmail.com>
 <bc4f9ad0-9021-abd3-30f9-5c9670c11707@gmail.com>
 <5730E1D2.8090901@measurement-factory.com>
 <e30f0de8-2025-1051-d6b6-19961760b270@gmail.com>
 <CANUpZyxf9f4TzzD5D4JiBJKiSHCo_yLOsoYG70AQNPaOwcWaXw@mail.gmail.com>
Message-ID: <ef4a75cd-593e-e4b7-9039-c0ac0dafb5f4@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I mean this, for example:

haribda(config)#policy-map Net_Limit
haribda(config-pmap)#class alternate
haribda(config-pmap-c)#?
Policy-map class configuration commands:
  admit            Admit the request for
  bandwidth        Bandwidth
  compression      Activate Compression
  drop             Drop all packets
  exit             Exit from class action configuration mode
  fair-queue       Enable Flow-based Fair Queuing in this Class
  flow             Flow subcommands
  log              Log IPv4 and ARP packets
  measure          Measure
  netflow-sampler  NetFlow action
  no               Negate or set default values of a command
  police           Police
  priority         Strict Scheduling Priority for this Class
  queue-limit      Queue Max Threshold for Tail Drop
  random-detect    Enable Random Early Detection as drop policy
  service-policy   Configure QoS Service Policy
  set              Set QoS values
  shape            Traffic Shaping

haribda(config-pmap-c)#bandwidth ?
  <1-2000000>  Kilo Bits per second
  percent      % of total Bandwidth
  remaining    percent/ratio of the remaining bandwidth

This is 2901, ISR G-2.

10.05.16 3:15, J Green ?????:
> Here, re 'upload and download sizes', I meant the later 'dumb traffic limits'.
>
> We do have a Cisco firewall in place, and I have setup 'traffic
policing'.  However, the results are inconsistent.  Sometimes it seems
to work, other times it blocks everything, or it blocks nothing.
>
> Appreciate all the feedback, thank you all for your time.
>
> On Mon, May 9, 2016 at 12:27 PM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> For such task enough put Cisco router with TCP traffic policies .....
>
> And please - any protocol, any speed limits, any ACL's, any SLA .....
>
>
> 10.05.16 1:15, Alex Rousskov ?????:
> > On 05/09/2016 12:53 PM, Yuri Voinov wrote:
>
> >> Just to clarify. For proxying anything (protocol or service), the proxy
> >> server must be at the same time also act as the client of a protocol or
> >> service - and as a server.
>
>
> > It all depends on the definition of "upload and download sizes" in the
> > OP question. If the intent is to understand and restrict individual
> > protocol messages, then you are right. If the intent is just to limit
> > the aggregate number of TCP bytes transferred, then protocol
> > understanding (in a "transparent" setup) is not required.
>
> > Needless to say, Squid is unlikely to be the best solution for the
> > latter "dumb traffic limits" problem, but if an "all-in-one executable"
> > is a critical requirement, one can make modern Squids to limit tunneled
> > TCP traffic that it does not understand.
>
> > Alex.
>
>
> >> J Green:
> >>>> Would like to limit maximum upload and download sizes for
> >>>>       other TCP protocols:  SMB, NFS, FTP, and RDP.
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMQIjAAoJENNXIZxhPexGC9YIAIXbLAOqQMTNmawXVrSpK2rP
zwW4RmwsmDOZzqFgldMlEJRkSH+H3UXiF6Zw994Ys3pYliB5o55qN3DYB2fGlu4H
Me3bq71PoZo+qes15l9ePpWq+0jK9B06fMGgWdBeSuVjRwC72hq0k2cPCpg9Hcd3
KqytNCaM6kb7CFfxhm8g5w0lSHwQkoKM8XDbtVzrKjT0VbFcYRXR6SP5tzRwDW9D
ZHFQ8hX19RBof8JqWQo6UbhXZBZGtDjoOaGQ/EBMLjzl6guUdKt9Xi8pF+rkBgSk
S0Y2JZypIxAeMuj9STfRs54ZCId9NtZfA76o5M7PH0OrCfz1oXA+m0kzCQfEZtY=
=tSMD
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/5be7f97a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/5be7f97a/attachment.key>

From hpj at urpla.net  Mon May  9 21:56:45 2016
From: hpj at urpla.net (Hans-Peter Jansen)
Date: Mon, 09 May 2016 23:56:45 +0200
Subject: [squid-users] New StoreID helper: squid_dedup
Message-ID: <7702897.VvIrWcf3ht@xrated>

Hi,

I'm pleased to announce the availability of squid_dedup, a helper for 
deduplicating CDN accesses, implementing the squid 3 StoreID protocol.

It is a multi-threaded tool, written in python3, with no further dependencies,
hosted at: https://github.com/frispete/squid_dedup
available at: https://pypi.python.org/pypi/squid-dedup

For openSUSE users, a ready made rpm package is available here:
https://build.opensuse.org/package/show/home:frispete:python3/squid_dedup

Any feedback is greatly appreciated.

Cheers,
Pete


From corpengineer at gmail.com  Mon May  9 22:40:29 2016
From: corpengineer at gmail.com (J Green)
Date: Mon, 9 May 2016 15:40:29 -0700
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <ef4a75cd-593e-e4b7-9039-c0ac0dafb5f4@gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>
 <d08dd83b-fd64-3479-1772-ab934a4ea468@gmail.com>
 <CANUpZyyByB6wJauyJrJPj4kkH+s+fFnXTLvP2r07vc-s=2rONw@mail.gmail.com>
 <bc4f9ad0-9021-abd3-30f9-5c9670c11707@gmail.com>
 <5730E1D2.8090901@measurement-factory.com>
 <e30f0de8-2025-1051-d6b6-19961760b270@gmail.com>
 <CANUpZyxf9f4TzzD5D4JiBJKiSHCo_yLOsoYG70AQNPaOwcWaXw@mail.gmail.com>
 <ef4a75cd-593e-e4b7-9039-c0ac0dafb5f4@gmail.com>
Message-ID: <CANUpZywdrXYxcMuiiYHb2Vg-iQ4+JgVcC3nfOK+nBKMu5K49Hw@mail.gmail.com>

Sorry to derail off topic, though I appreciate the feedback.  Trying to get
this to work through a Cisco ASA.  If not, I probably have an old 2900
series router somewhere.

Thank you again.

On Mon, May 9, 2016 at 2:33 PM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> I mean this, for example:
>
> haribda(config)#policy-map Net_Limit
> haribda(config-pmap)#class alternate
> haribda(config-pmap-c)#?
> Policy-map class configuration commands:
>   admit            Admit the request for
>   bandwidth        Bandwidth
>   compression      Activate Compression
>   drop             Drop all packets
>   exit             Exit from class action configuration mode
>   fair-queue       Enable Flow-based Fair Queuing in this Class
>   flow             Flow subcommands
>   log              Log IPv4 and ARP packets
>   measure          Measure
>   netflow-sampler  NetFlow action
>   no               Negate or set default values of a command
>   police           Police
>   priority         Strict Scheduling Priority for this Class
>   queue-limit      Queue Max Threshold for Tail Drop
>   random-detect    Enable Random Early Detection as drop policy
>   service-policy   Configure QoS Service Policy
>   set              Set QoS values
>   shape            Traffic Shaping
>
> haribda(config-pmap-c)#bandwidth ?
>   <1-2000000>  Kilo Bits per second
>   percent      % of total Bandwidth
>   remaining    percent/ratio of the remaining bandwidth
>
> This is 2901, ISR G-2.
>
> 10.05.16 3:15, J Green ?????:
> > Here, re 'upload and download sizes', I meant the later 'dumb traffic
> limits'.
> >
> > We do have a Cisco firewall in place, and I have setup 'traffic
> policing'.  However, the results are inconsistent.  Sometimes it seems to
> work, other times it blocks everything, or it blocks nothing.
> >
> > Appreciate all the feedback, thank you all for your time.
> >
> > On Mon, May 9, 2016 at 12:27 PM, Yuri Voinov <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com> <yvoinov at gmail.com>> wrote:
> >
> >
> > For such task enough put Cisco router with TCP traffic policies .....
> >
> > And please - any protocol, any speed limits, any ACL's, any SLA .....
> >
> >
> > 10.05.16 1:15, Alex Rousskov ?????:
> > > On 05/09/2016 12:53 PM, Yuri Voinov wrote:
> >
> > >> Just to clarify. For proxying anything (protocol or service), the
> proxy
> > >> server must be at the same time also act as the client of a protocol
> or
> > >> service - and as a server.
> >
> >
> > > It all depends on the definition of "upload and download sizes" in the
> > > OP question. If the intent is to understand and restrict individual
> > > protocol messages, then you are right. If the intent is just to limit
> > > the aggregate number of TCP bytes transferred, then protocol
> > > understanding (in a "transparent" setup) is not required.
> >
> > > Needless to say, Squid is unlikely to be the best solution for the
> > > latter "dumb traffic limits" problem, but if an "all-in-one executable"
> > > is a critical requirement, one can make modern Squids to limit tunneled
> > > TCP traffic that it does not understand.
> >
> > > Alex.
> >
> >
> > >> J Green:
> > >>>> Would like to limit maximum upload and download sizes for
> > >>>>       other TCP protocols:  SMB, NFS, FTP, and RDP.
> > > _______________________________________________
> > > squid-users mailing list
> > > squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> > > http://lists.squid-cache.org/listinfo/squid-users
> >
> >
> >
> >     _______________________________________________
> >     squid-users mailing list
> >     squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> >     http://lists.squid-cache.org/listinfo/squid-users
> >
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXMQIjAAoJENNXIZxhPexGC9YIAIXbLAOqQMTNmawXVrSpK2rP
> zwW4RmwsmDOZzqFgldMlEJRkSH+H3UXiF6Zw994Ys3pYliB5o55qN3DYB2fGlu4H
> Me3bq71PoZo+qes15l9ePpWq+0jK9B06fMGgWdBeSuVjRwC72hq0k2cPCpg9Hcd3
> KqytNCaM6kb7CFfxhm8g5w0lSHwQkoKM8XDbtVzrKjT0VbFcYRXR6SP5tzRwDW9D
> ZHFQ8hX19RBof8JqWQo6UbhXZBZGtDjoOaGQ/EBMLjzl6guUdKt9Xi8pF+rkBgSk
> S0Y2JZypIxAeMuj9STfRs54ZCId9NtZfA76o5M7PH0OrCfz1oXA+m0kzCQfEZtY=
> =tSMD
> -----END PGP SIGNATURE-----
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160509/af263a65/attachment.htm>

From dan at getbusi.com  Tue May 10 02:35:23 2016
From: dan at getbusi.com (Dan Charlesworth)
Date: Tue, 10 May 2016 12:35:23 +1000
Subject: [squid-users] How to analyse squid memory usage
Message-ID: <B60DFE6C-9BA8-42CA-9B57-A2460517A35F@getbusi.com>

A small percentage of deployments of our squid-based product are using oodles of memory?there doesn?t seem to be a limit to it.

I?m wondering what the best way might be to analyse what squid is reserving it all for in the latest 3.5 release?

The output of squidclient mgr:cache_mem is completely incomprehensible to me.

Thanks!

From squid3 at treenet.co.nz  Tue May 10 05:06:05 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 May 2016 17:06:05 +1200
Subject: [squid-users] Can Traffic Management Settings be configured for
	other TCP protocols?
In-Reply-To: <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>
Message-ID: <3405e72853cadeaf0a57c6f6b6359a86@treenet.co.nz>

On 2016-05-10 06:05, J Green wrote:
> Appreciate the response.  Thought it might work if I added those ports
> to the safe list.

The Safe_ports list is the ports it is considered safe to send traffic 
to from an HTTP proxy. The ports not on that list are for protocols that 
can have crafted messages that look like HTTP to the proxy and non-HTTP 
to the server. Enabling server attacks through HTTP relays. Email SMTP 
ports are particularly vulnerable to spam being delivered in this way.

> 
> If not Squid, any idea how to accomplish this?
> 

With your systems regular QoS settings.

Amos



From squid3 at treenet.co.nz  Tue May 10 08:02:30 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 May 2016 20:02:30 +1200
Subject: [squid-users] How to analyse squid memory usage
In-Reply-To: <B60DFE6C-9BA8-42CA-9B57-A2460517A35F@getbusi.com>
References: <B60DFE6C-9BA8-42CA-9B57-A2460517A35F@getbusi.com>
Message-ID: <085044c5-9a62-8b6f-47e6-cee4410dfac9@treenet.co.nz>

On 10/05/2016 2:35 p.m., Dan Charlesworth wrote:
> A small percentage of deployments of our squid-based product are using oodles of memory?there doesn?t seem to be a limit to it.
> 
> I?m wondering what the best way might be to analyse what squid is reserving it all for in the latest 3.5 release?
> 
> The output of squidclient mgr:cache_mem is completely incomprehensible to me.

Try mgr:mem report. It is TSV (tab-separated values) file format.

  squidclient mgr:mem > mem.tsv

... and load mem.tsv using your favourite spreadsheet program. The
column titles should then be self-explanatory.

Amos



From alesironi at yahoo.it  Tue May 10 08:31:49 2016
From: alesironi at yahoo.it (alesironi)
Date: Tue, 10 May 2016 01:31:49 -0700 (PDT)
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
Message-ID: <1462869109249-4677427.post@n4.nabble.com>

Hello everyone

sorry if it's a stupid question but I'm a newbie of SQUID and PROXIES as
well.

I have SQUID installed on UBUNTU, working fine, only authorized users can
use the proxy.

Some users are watching youtube videos (I can see from the log files); our
rules are pretty simple and basic, youtube videos are allowed but only if
they are for working related purposes.
IN order to understand that I need to check from access.log which kind of
video they watch (we do this randomly, not for every video, for obvious
reasons).

The problem is that on Squid log file (ACCESS.LOG) the URL I see is similar
to this:

r10---sn-4g57knd7.googlevideo.com:443

...which is not telling me anything about the content of the youtube video
(it does not work at all...).

Do you have any suggestion on how to understand the content of the video
starting from that URL? Or any suggestion on how to achieve my goal?




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Understand-GOOGLEVIDEO-Url-from-access-log-tp4677427.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Ralf.Hildebrandt at charite.de  Tue May 10 09:10:42 2016
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 10 May 2016 11:10:42 +0200
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <1462869109249-4677427.post@n4.nabble.com>
References: <1462869109249-4677427.post@n4.nabble.com>
Message-ID: <20160510091042.GC17915@charite.de>

* alesironi <alesironi at yahoo.it>:

> The problem is that on Squid log file (ACCESS.LOG) the URL I see is similar
> to this:
> 
> r10---sn-4g57knd7.googlevideo.com:443

443 = https = encrypted

meaning: You cannot know.

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
http://www.charite.de              Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From bjoern.meier at gmail.com  Tue May 10 09:16:46 2016
From: bjoern.meier at gmail.com (Bjoern Meier)
Date: Tue, 10 May 2016 09:16:46 +0000
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <20160510091042.GC17915@charite.de>
References: <1462869109249-4677427.post@n4.nabble.com>
 <20160510091042.GC17915@charite.de>
Message-ID: <CAGMPS57aOv1L1DsU3-pj9_XXKrMeHMDVuzc8F3k1WGamTkLkHg@mail.gmail.com>

hi,

Ralf Hildebrandt <Ralf.Hildebrandt at charite.de> schrieb am Di., 10. Mai 2016
um 11:10 Uhr:

> * alesironi <alesironi at yahoo.it>:
>
> > The problem is that on Squid log file (ACCESS.LOG) the URL I see is
> similar
> > to this:
> >
> > r10---sn-4g57knd7.googlevideo.com:443
>
> 443 = https = encrypted
>
> meaning: You cannot know.


Wait. Since when track Squid  data?  Squid only track connections in the
access.log (that's why it is called access.log).
So, it is not importent if the data is encrypted, the connection data can't
be encrypted.

Why shouldn't he see the URL in the access.log?
Greetings,
Bj?rn
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/6e94054e/attachment.htm>

From alesironi at yahoo.it  Tue May 10 08:48:26 2016
From: alesironi at yahoo.it (alesironi)
Date: Tue, 10 May 2016 01:48:26 -0700 (PDT)
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <CAGMPS57aOv1L1DsU3-pj9_XXKrMeHMDVuzc8F3k1WGamTkLkHg@mail.gmail.com>
References: <1462869109249-4677427.post@n4.nabble.com>
 <20160510091042.GC17915@charite.de>
 <CAGMPS57aOv1L1DsU3-pj9_XXKrMeHMDVuzc8F3k1WGamTkLkHg@mail.gmail.com>
Message-ID: <1462870106128-4677430.post@n4.nabble.com>

Bjoern Meier wrote
> hi,
> 
> Ralf Hildebrandt &lt;

> Ralf.Hildebrandt@

> &gt; schrieb am Di., 10. Mai 2016
> um 11:10 Uhr:
> 
>> * alesironi &lt;

> alesironi@

> &gt;:
>>
>> > The problem is that on Squid log file (ACCESS.LOG) the URL I see is
>> similar
>> > to this:
>> >
>> > r10---sn-4g57knd7.googlevideo.com:443
>>
>> 443 = https = encrypted
>>
>> meaning: You cannot know.
> 
> 
> Wait. Since when track Squid  data?  Squid only track connections in the
> access.log (that's why it is called access.log).
> So, it is not importent if the data is encrypted, the connection data
> can't
> be encrypted.
> 
> Why shouldn't he see the URL in the access.log?
> Greetings,
> Bj?rn
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users

maybe I do not understand....but this is HTTPS and you can see it (#33legend
:) )
https://www.youtube.com/watch?v=pI470DZhojA





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Understand-GOOGLEVIDEO-Url-from-access-log-tp4677427p4677430.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Ralf.Hildebrandt at charite.de  Tue May 10 09:26:22 2016
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 10 May 2016 11:26:22 +0200
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <CAGMPS57aOv1L1DsU3-pj9_XXKrMeHMDVuzc8F3k1WGamTkLkHg@mail.gmail.com>
References: <1462869109249-4677427.post@n4.nabble.com>
 <20160510091042.GC17915@charite.de>
 <CAGMPS57aOv1L1DsU3-pj9_XXKrMeHMDVuzc8F3k1WGamTkLkHg@mail.gmail.com>
Message-ID: <20160510092622.GE17915@charite.de>

* Bjoern Meier <bjoern.meier at gmail.com>:
> hi,
> 
> Ralf Hildebrandt <Ralf.Hildebrandt at charite.de> schrieb am Di., 10. Mai 2016
> um 11:10 Uhr:
> 
> > * alesironi <alesironi at yahoo.it>:
> >
> > > The problem is that on Squid log file (ACCESS.LOG) the URL I see is
> > similar
> > > to this:
> > >
> > > r10---sn-4g57knd7.googlevideo.com:443
> >
> > 443 = https = encrypted
> >
> > meaning: You cannot know.
> 
> 
> Wait. Since when track Squid  data?  Squid only track connections in the
> access.log (that's why it is called access.log).
> So, it is not importent if the data is encrypted, the connection data can't
> be encrypted.

With HTTPS, all you see is CONNECT requests and target hosts:

1462872328.675 059737 10.x.x.x TCP_TUNNEL/200 2987 CONNECT www.adsensecustomsearchads.com:443 - HIER_DIRECT/216.58.213.238 - 31123
1462872362.553 058061 141.42.x.x TCP_TUNNEL/200 752 CONNECT www.google-analytics.com:443 - HIER_DIRECT/216.58.213.238 - 34542

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
http://www.charite.de              Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From walter.h at mathemainzel.info  Tue May 10 09:29:10 2016
From: walter.h at mathemainzel.info (Walter H.)
Date: Tue, 10 May 2016 11:29:10 +0200
Subject: [squid-users] DNS-Errors ... squid-cache.org
Message-ID: <e07422452bab30cfcddf6a5bd5ac67d7.1462872550@squirrel.mail>

Hello,

has anybody an idea where this errors come from,
or what is causing them?

May 10 11:21:00 lxwaldivm-001 named[30098]: error (unexpected RCODE REFUSED)
resolving 'lists.squid-cache.org/MX/IN': 173.255.241.90#53
May 10 11:21:01 lxwaldivm-001 named[30098]: error (connection refused)
resolving 'lists.squid-cache.org/MX/IN': 209.169.10.132#53
May 10 11:21:04 lxwaldivm-001 named[30098]: error (unexpected RCODE REFUSED)
resolving 'lists.squid-cache.org/A/IN': 173.255.241.90#53
May 10 11:21:04 lxwaldivm-001 named[30098]: error (unexpected RCODE REFUSED)
resolving 'lists.squid-cache.org/AAAA/IN': 173.255.241.90#53
May 10 11:21:05 lxwaldivm-001 named[30098]: error (unexpected RCODE REFUSED)
resolving 'lists.squid-cache.org/NS/IN': 173.255.241.90#53
May 10 11:21:05 lxwaldivm-001 named[30098]: error (unexpected RCODE REFUSED)
resolving 'squid-cache.org/NS/IN': 173.255.241.90#53
May 10 11:21:09 lxwaldivm-001 named[30098]: error (unexpected RCODE REFUSED)
resolving 'eu.squid-cache.org/A/IN': 173.255.241.90#53
May 10 11:21:09 lxwaldivm-001 named[30098]: error (unexpected RCODE REFUSED)
resolving 'ns1.squid-cache.org/AAAA/IN': 173.255.241.90#53
May 10 11:21:09 lxwaldivm-001 named[30098]: error (unexpected RCODE REFUSED)
resolving 'ns1.squid-cache.org/A/IN': 173.255.241.90#53
May 10 11:21:09 lxwaldivm-001 named[30098]: error (unexpected RCODE REFUSED)
resolving 'eu.squid-cache.org/AAAA/IN': 173.255.241.90#53
May 10 11:21:09 lxwaldivm-001 named[30098]: error (unexpected RCODE REFUSED)
resolving 'ns2.squid-cache.org/A/IN': 173.255.241.90#53
May 10 11:21:09 lxwaldivm-001 named[30098]: error (unexpected RCODE REFUSED)
resolving 'ns2.squid-cache.org/AAAA/IN': 173.255.241.90#53

these are listed quite often at /var/log/messages on my DNS-machine ...

Thanks,
Walter



From bjoern.meier at gmail.com  Tue May 10 09:29:25 2016
From: bjoern.meier at gmail.com (Bjoern Meier)
Date: Tue, 10 May 2016 09:29:25 +0000
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <20160510092622.GE17915@charite.de>
References: <1462869109249-4677427.post@n4.nabble.com>
 <20160510091042.GC17915@charite.de>
 <CAGMPS57aOv1L1DsU3-pj9_XXKrMeHMDVuzc8F3k1WGamTkLkHg@mail.gmail.com>
 <20160510092622.GE17915@charite.de>
Message-ID: <CAGMPS57HOiakhCZx3_sDGddWYH-1_kP7F=F1RgWgAhXz1HuSrA@mail.gmail.com>

hi,


   1.

Ralf Hildebrandt <Ralf.Hildebrandt at charite.de> schrieb am Di., 10. Mai 2016
um 11:26 Uhr:

> * Bjoern Meier <bjoern.meier at gmail.com>:
> > hi,
> >
> > Ralf Hildebrandt <Ralf.Hildebrandt at charite.de> schrieb am Di., 10. Mai
> 2016
> > um 11:10 Uhr:
> >
> > > * alesironi <alesironi at yahoo.it>:
> > >
> > > > The problem is that on Squid log file (ACCESS.LOG) the URL I see is
> > > similar
> > > > to this:
> > > >
> > > > r10---sn-4g57knd7.googlevideo.com:443
> > >
> > > 443 = https = encrypted
> > >
> > > meaning: You cannot know.
> >
> >
> > Wait. Since when track Squid  data?  Squid only track connections in the
> > access.log (that's why it is called access.log).
> > So, it is not importent if the data is encrypted, the connection data
> can't
> > be encrypted.
>
> With HTTPS, all you see is CONNECT requests and target hosts:
>
> 1462872328.675 059737 10.x.x.x TCP_TUNNEL/200 2987 CONNECT
> www.adsensecustomsearchads.com:443 - HIER_DIRECT/216.58.213.238 - 31123
> 1462872362.553 058061 141.42.x.x TCP_TUNNEL/200 752 CONNECT
> www.google-analytics.com:443 - HIER_DIRECT/216.58.213.238 - 34542
>

So? I can see the CONNECT URL as I mentioned. So he can see the URL.
As I read:  "The problem is that on Squid log file (ACCESS.LOG) the URL I
see is"

He will understand the URL and those can he see.

Greetings,
Bj?rn
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/cbabd507/attachment.htm>

From alesironi at yahoo.it  Tue May 10 08:58:22 2016
From: alesironi at yahoo.it (alesironi)
Date: Tue, 10 May 2016 01:58:22 -0700 (PDT)
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <20160510092622.GE17915@charite.de>
References: <1462869109249-4677427.post@n4.nabble.com>
 <20160510091042.GC17915@charite.de>
 <CAGMPS57aOv1L1DsU3-pj9_XXKrMeHMDVuzc8F3k1WGamTkLkHg@mail.gmail.com>
 <20160510092622.GE17915@charite.de>
Message-ID: <1462870702231-4677434.post@n4.nabble.com>

Ralf Hildebrandt wrote
> * Bjoern Meier &lt;

> bjoern.meier@

> &gt;:
>> hi,
>> 
>> Ralf Hildebrandt &lt;

> Ralf.Hildebrandt@

> &gt; schrieb am Di., 10. Mai 2016
>> um 11:10 Uhr:
>> 
>> > * alesironi &lt;

> alesironi@

> &gt;:
>> >
>> > > The problem is that on Squid log file (ACCESS.LOG) the URL I see is
>> > similar
>> > > to this:
>> > >
>> > > r10---sn-4g57knd7.googlevideo.com:443
>> >
>> > 443 = https = encrypted
>> >
>> > meaning: You cannot know.
>> 
>> 
>> Wait. Since when track Squid  data?  Squid only track connections in the
>> access.log (that's why it is called access.log).
>> So, it is not importent if the data is encrypted, the connection data
>> can't
>> be encrypted.
> 
> With HTTPS, all you see is CONNECT requests and target hosts:
> 
> 1462872328.675 059737 10.x.x.x TCP_TUNNEL/200 2987 CONNECT
> www.adsensecustomsearchads.com:443 - HIER_DIRECT/216.58.213.238 - 31123
> 1462872362.553 058061 141.42.x.x TCP_TUNNEL/200 752 CONNECT
> www.google-analytics.com:443 - HIER_DIRECT/216.58.213.238 - 34542
> 
> -- 
> Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin

> ralf.hildebrandt@

>         Campus Benjamin Franklin
> http://www.charite.de              Hindenburgdamm 30, 12203 Berlin
> Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users

I'm assuming then that there's no way to understand the content of the
youtube video? Even if it's publicly available?




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Understand-GOOGLEVIDEO-Url-from-access-log-tp4677427p4677434.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From alesironi at yahoo.it  Tue May 10 08:59:52 2016
From: alesironi at yahoo.it (alesironi)
Date: Tue, 10 May 2016 01:59:52 -0700 (PDT)
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <CAGMPS57HOiakhCZx3_sDGddWYH-1_kP7F=F1RgWgAhXz1HuSrA@mail.gmail.com>
References: <1462869109249-4677427.post@n4.nabble.com>
 <20160510091042.GC17915@charite.de>
 <CAGMPS57aOv1L1DsU3-pj9_XXKrMeHMDVuzc8F3k1WGamTkLkHg@mail.gmail.com>
 <20160510092622.GE17915@charite.de>
 <CAGMPS57HOiakhCZx3_sDGddWYH-1_kP7F=F1RgWgAhXz1HuSrA@mail.gmail.com>
Message-ID: <1462870792441-4677435.post@n4.nabble.com>

Bjoern Meier wrote
> hi,
> 
> 
>    1.
> 
> Ralf Hildebrandt &lt;

> Ralf.Hildebrandt@

> &gt; schrieb am Di., 10. Mai 2016
> um 11:26 Uhr:
> 
>> * Bjoern Meier &lt;

> bjoern.meier@

> &gt;:
>> > hi,
>> >
>> > Ralf Hildebrandt &lt;

> Ralf.Hildebrandt@

> &gt; schrieb am Di., 10. Mai
>> 2016
>> > um 11:10 Uhr:
>> >
>> > > * alesironi &lt;

> alesironi@

> &gt;:
>> > >
>> > > > The problem is that on Squid log file (ACCESS.LOG) the URL I see is
>> > > similar
>> > > > to this:
>> > > >
>> > > > r10---sn-4g57knd7.googlevideo.com:443
>> > >
>> > > 443 = https = encrypted
>> > >
>> > > meaning: You cannot know.
>> >
>> >
>> > Wait. Since when track Squid  data?  Squid only track connections in
>> the
>> > access.log (that's why it is called access.log).
>> > So, it is not importent if the data is encrypted, the connection data
>> can't
>> > be encrypted.
>>
>> With HTTPS, all you see is CONNECT requests and target hosts:
>>
>> 1462872328.675 059737 10.x.x.x TCP_TUNNEL/200 2987 CONNECT
>> www.adsensecustomsearchads.com:443 - HIER_DIRECT/216.58.213.238 - 31123
>> 1462872362.553 058061 141.42.x.x TCP_TUNNEL/200 752 CONNECT
>> www.google-analytics.com:443 - HIER_DIRECT/216.58.213.238 - 34542
>>
> 
> So? I can see the CONNECT URL as I mentioned. So he can see the URL.
> As I read:  "The problem is that on Squid log file (ACCESS.LOG) the URL I
> see is"
> 
> He will understand the URL and those can he see.
> 
> Greetings,
> Bj?rn
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users

Thanks but back to my problem , my goal is to understand the YOUTUBE video
watched by the user (given that is publicly available). Do you have any
suggestion on that?




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Understand-GOOGLEVIDEO-Url-from-access-log-tp4677427p4677435.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Ralf.Hildebrandt at charite.de  Tue May 10 09:43:13 2016
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 10 May 2016 11:43:13 +0200
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <1462870792441-4677435.post@n4.nabble.com>
References: <1462869109249-4677427.post@n4.nabble.com>
 <20160510091042.GC17915@charite.de>
 <CAGMPS57aOv1L1DsU3-pj9_XXKrMeHMDVuzc8F3k1WGamTkLkHg@mail.gmail.com>
 <20160510092622.GE17915@charite.de>
 <CAGMPS57HOiakhCZx3_sDGddWYH-1_kP7F=F1RgWgAhXz1HuSrA@mail.gmail.com>
 <1462870792441-4677435.post@n4.nabble.com>
Message-ID: <20160510094313.GF17915@charite.de>

> Thanks but back to my problem , my goal is to understand the YOUTUBE video
> watched by the user (given that is publicly available). Do you have any
> suggestion on that?

You can't. It's all encrypted.

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
http://www.charite.de              Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From Ralf.Hildebrandt at charite.de  Tue May 10 09:45:51 2016
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 10 May 2016 11:45:51 +0200
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <1462870106128-4677430.post@n4.nabble.com>
References: <1462869109249-4677427.post@n4.nabble.com>
 <20160510091042.GC17915@charite.de>
 <CAGMPS57aOv1L1DsU3-pj9_XXKrMeHMDVuzc8F3k1WGamTkLkHg@mail.gmail.com>
 <1462870106128-4677430.post@n4.nabble.com>
Message-ID: <20160510094551.GG17915@charite.de>

* alesironi <alesironi at yahoo.it>:

> maybe I do not understand....but this is HTTPS and you can see it (#33legend
> :) )
> https://www.youtube.com/watch?v=pI470DZhojA

Really? On my proxy I cannot see the URL, hm.
But anyway: You cannot deduce the CONTENTS of the video from the URL
(unless you'd look at the video yourself)

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
http://www.charite.de              Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From squid3 at treenet.co.nz  Tue May 10 09:52:32 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 May 2016 21:52:32 +1200
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <1462869109249-4677427.post@n4.nabble.com>
References: <1462869109249-4677427.post@n4.nabble.com>
Message-ID: <f9900d48-ae1c-d107-60b7-c1d2578c9287@treenet.co.nz>

On 10/05/2016 8:31 p.m., alesironi wrote:
> Hello everyone
> 
> sorry if it's a stupid question but I'm a newbie of SQUID and PROXIES as
> well.

Well, firstly. Please dont shout :-P

Seriously though; Some of the words you are upper-casing are trademarks
or technical terms and the case used is relevant to what you are
speaking about.
(not picking on you specifically, others on the list have been getting
very sloppy too recently - this message is a perfect example of the
problem).

 SQUID and Squid are different things. Both used in networking. But
thankfully SQUID is a layer-1 device not commonly spoken about around
here so not much confusion.

However; proxy and PROXY are also two different things. For extra
difficulty both relate to things about Squid. PROXY (all upper case and
no pluralisation) being one of the protocols that Squid can use nowdays.

> 
> I have SQUID installed on UBUNTU, working fine, only authorized users can
> use the proxy.

Squid, Ubuntu, YouTube and GoogleVideo are trademarks with specific
spelling when used outside of URLs.

/rant

> 
> Some users are watching youtube videos (I can see from the log files); our
> rules are pretty simple and basic, youtube videos are allowed but only if
> they are for working related purposes.
> IN order to understand that I need to check from access.log which kind of
> video they watch (we do this randomly, not for every video, for obvious
> reasons).
> 
> The problem is that on Squid log file (ACCESS.LOG) the URL I see is similar
> to this:
> 
> r10---sn-4g57knd7.googlevideo.com:443
> 
> ...which is not telling me anything about the content of the youtube video
> (it does not work at all...).
> 

The best explanation for the URI (not URL) if you really want to know
why it looks like that (and why its not a URL) is in
<http://tools.ietf.org/html/rfc7230#section-5.3>.


The ":443" part means port 443 ... TLS encrypted traffic. That is all.

To misquote The Matrix "there is no video". What your Squid is being
asked to proxy is a two-way opaque stream of TLS encrypted data to/from
that named server:port.

The encrypted data on port 443 is supposed to contain a whole different
layer of HTTP messages commonly referred to as HTTPS, and having
https:// URLs. There may be one or more messages, there may (or not) be
a video stream as one of those messages.

So to be accurate; the stream may contain a video, but it also may not
and even when it does there is more than the video happening in there.


> Do you have any suggestion on how to understand the content of the video
> starting from that URL? Or any suggestion on how to achieve my goal?

What do you mean by "kind"? Your description implies that you mean the
actual visual content of it. You will not be able to see that without
downloading and viewing it yourself.

The most you will ever be able to see from HTTP layer logs was that it
was a video and the URL that it was stored at. Which is usually just a
random unique character sequence for an ID. To even get that much
information you will have to intercept and decrypt the users traffic.

Please check with your companies legal department about whether you can
do that encryption legally. There are some countries where doing so on
any network is completely prohibited or requires a government license.
Other places that policy you mention might be enough so long as your
users have signed agreement to it.

Once you know the legal situation look into
<http://wiki.squid-cache.org/Features/SslPeekAndSplice>. You will also
need to be using the latest Squid packages (3.5.19 or 4.0.10 today) and
regularly updating. TLS interception is an arms race situation that is
constantly changing both the security encryption and the attack methods
to break into it.

Amos



From Ralf.Hildebrandt at charite.de  Tue May 10 09:56:05 2016
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Tue, 10 May 2016 11:56:05 +0200
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <f9900d48-ae1c-d107-60b7-c1d2578c9287@treenet.co.nz>
References: <1462869109249-4677427.post@n4.nabble.com>
 <f9900d48-ae1c-d107-60b7-c1d2578c9287@treenet.co.nz>
Message-ID: <20160510095605.GH17915@charite.de>

> Once you know the legal situation look into
> <http://wiki.squid-cache.org/Features/SslPeekAndSplice>. You will also
> need to be using the latest Squid packages (3.5.19 or 4.0.10 today) and
> regularly updating. TLS interception is an arms race situation that is
> constantly changing both the security encryption and the attack methods
> to break into it.

Does that even work with Chrome (certificate pinning for google sites)?
(just curious)

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
http://www.charite.de              Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From squid3 at treenet.co.nz  Tue May 10 10:05:04 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 May 2016 22:05:04 +1200
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <1462870702231-4677434.post@n4.nabble.com>
References: <1462869109249-4677427.post@n4.nabble.com>
 <20160510091042.GC17915@charite.de>
 <CAGMPS57aOv1L1DsU3-pj9_XXKrMeHMDVuzc8F3k1WGamTkLkHg@mail.gmail.com>
 <20160510092622.GE17915@charite.de>
 <1462870702231-4677434.post@n4.nabble.com>
Message-ID: <dee81f41-c6d2-7404-a073-d20817af8a05@treenet.co.nz>

On 10/05/2016 8:58 p.m., alesironi wrote:
> 
> I'm assuming then that there's no way to understand the content of the
> youtube video? Even if it's publicly available?

You misunderstand the scope of what is publicly visible.

The only thing that is publicly visible is the https:// URL.

Firstly, that is an HTML page. Not a video.

Secondly, even the bytes that make the page up are not publicly visible.

Those and everything it references are only privately visible. On 1:1
tunneled and encrypted connection(s) between the person viewing that URL
and one of Google servers.

Amos



From squid3 at treenet.co.nz  Tue May 10 10:07:06 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 May 2016 22:07:06 +1200
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <20160510095605.GH17915@charite.de>
References: <1462869109249-4677427.post@n4.nabble.com>
 <f9900d48-ae1c-d107-60b7-c1d2578c9287@treenet.co.nz>
 <20160510095605.GH17915@charite.de>
Message-ID: <57c3a4d8-b664-fd91-c1e8-a24b6dcb1206@treenet.co.nz>

On 10/05/2016 9:56 p.m., Ralf Hildebrandt wrote:
>> Once you know the legal situation look into
>> <http://wiki.squid-cache.org/Features/SslPeekAndSplice>. You will also
>> need to be using the latest Squid packages (3.5.19 or 4.0.10 today) and
>> regularly updating. TLS interception is an arms race situation that is
>> constantly changing both the security encryption and the attack methods
>> to break into it.
> 
> Does that even work with Chrome (certificate pinning for google sites)?
> (just curious)
> 

Maybe. They document that manually inserted CA certs override pinning.
But I'm not sure they follow that documented practice 100% of the time.

Amos



From squid3 at treenet.co.nz  Tue May 10 10:15:18 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 May 2016 22:15:18 +1200
Subject: [squid-users] DNS-Errors ... squid-cache.org
In-Reply-To: <e07422452bab30cfcddf6a5bd5ac67d7.1462872550@squirrel.mail>
References: <e07422452bab30cfcddf6a5bd5ac67d7.1462872550@squirrel.mail>
Message-ID: <98c7a29e-f8aa-6882-7c10-c80b07741a3b@treenet.co.nz>

On 10/05/2016 9:29 p.m., Walter H. wrote:
> Hello,
> 
> has anybody an idea where this errors come from,
> or what is causing them?
> 
> May 10 11:21:00 lxwaldivm-001 named[30098]: error (unexpected RCODE REFUSED)
> resolving 'lists.squid-cache.org/MX/IN': 173.255.241.90#53

173.255.241.90 is one of our squid-cache.org DNS mirrors. It seems to be
refusing to serve the domain any more.

Thanks for pointing it out.

Amos



From turgut at kalfaoglu.com  Tue May 10 10:34:02 2016
From: turgut at kalfaoglu.com (=?UTF-8?Q?turgut_kalfao=c4=9flu?=)
Date: Tue, 10 May 2016 13:34:02 +0300
Subject: [squid-users] sahibinden.com fails with https bump
Message-ID: <27b82992-9525-6a5e-5e36-b53ac8e13744@kalfaoglu.com>

Hello everyone..

My setup -- this is for speeding up the home ADSL..

https_port 3129 intercept ssl-bump \
        generate-host-certificates=on dynamic_cert_mem_cache_size=4MB \
        cert=/etc/squid/ssl_cert/myca.pem key=/etc/squid/ssl_cert/myca.pem
sslproxy_cert_adapt setCommonName ssl::certDomainMismatch
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER
sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
sslcrtd_children 20 startup=3 idle=1
ssl_bump server-first  all

This works well for facebook, gmail, google, and probably others..
But https://sahibinden.com , whatever they are doing fails - the page
appears broken.
I tried  broken_sites acl trick, did not help.

acl broken_sites ssl::server_name .sahibinden.com
acl broken_sites ssl::server_name image5.sahibinden.com
acl broken_sites ssl::server_name .shbdn.com
ssl_bump none broken_sites

Does anyone have any ideas what else I can try?
Many thanks, -tk



From yvoinov at gmail.com  Tue May 10 11:11:34 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 May 2016 17:11:34 +0600
Subject: [squid-users] sahibinden.com fails with https bump
In-Reply-To: <27b82992-9525-6a5e-5e36-b53ac8e13744@kalfaoglu.com>
References: <27b82992-9525-6a5e-5e36-b53ac8e13744@kalfaoglu.com>
Message-ID: <75174ea7-95a0-918e-bf35-88d60d451ab0@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
My Squid gives the following error:

https://i1.someimage.com/xnPCOFO.png

Need more research, but seems better to write site's webmaster.


10.05.16 16:34, turgut kalfao?lu ?????:
> Hello everyone..
>
> My setup -- this is for speeding up the home ADSL..
>
> https_port 3129 intercept ssl-bump \
>         generate-host-certificates=on dynamic_cert_mem_cache_size=4MB \
>         cert=/etc/squid/ssl_cert/myca.pem key=/etc/squid/ssl_cert/myca.pem
> sslproxy_cert_adapt setCommonName ssl::certDomainMismatch
> sslproxy_cert_error allow all
> sslproxy_flags DONT_VERIFY_PEER
> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
> sslcrtd_children 20 startup=3 idle=1
> ssl_bump server-first  all
>
> This works well for facebook, gmail, google, and probably others..
> But https://sahibinden.com , whatever they are doing fails - the page
> appears broken.
> I tried  broken_sites acl trick, did not help.
>
> acl broken_sites ssl::server_name .sahibinden.com
> acl broken_sites ssl::server_name image5.sahibinden.com
> acl broken_sites ssl::server_name .shbdn.com
> ssl_bump none broken_sites
>
> Does anyone have any ideas what else I can try?
> Many thanks, -tk
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMcHmAAoJENNXIZxhPexGiNUH/jJA0u5XvqFZss9zTNHKK7ba
8fT+wCsOOE7m68KnCGHdwmiBnCCCzdat11afrHUh9rXClJt8Hir9jSfYhOuMfI/H
juveesgCb4fS77h7F+Pz6XGcKGcfn2za9GTOrAWHlgmheb3DHFeP+Oc53aCX4jZy
N+s3Gtc9iOlWCyr8O0u7rupDv/k7tDJzcaR7hWfy35WPUHapjC5JK/Pk1BoHe6Gz
qCwGVDzCAXi2P1oFQ/RIwIno2KmvWh6YtZdE56eEOT8IfaLGg/PQ6WZsIZYuQIFr
q4QSgK7ET1gr6NlhQU6fTCyJ/NjgDrk2L+/yiyIzpF1EK37y7gUYQ8ezYh9gmKo=
=LYjq
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/f511c222/attachment.key>

From yvoinov at gmail.com  Tue May 10 11:12:28 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 May 2016 17:12:28 +0600
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <57c3a4d8-b664-fd91-c1e8-a24b6dcb1206@treenet.co.nz>
References: <1462869109249-4677427.post@n4.nabble.com>
 <f9900d48-ae1c-d107-60b7-c1d2578c9287@treenet.co.nz>
 <20160510095605.GH17915@charite.de>
 <57c3a4d8-b664-fd91-c1e8-a24b6dcb1206@treenet.co.nz>
Message-ID: <67305521-ed75-878d-7276-dd3dfabf087d@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


10.05.16 16:07, Amos Jeffries ?????:
> On 10/05/2016 9:56 p.m., Ralf Hildebrandt wrote:
>>> Once you know the legal situation look into
>>> <http://wiki.squid-cache.org/Features/SslPeekAndSplice>. You will also
>>> need to be using the latest Squid packages (3.5.19 or 4.0.10 today) and
>>> regularly updating. TLS interception is an arms race situation that is
>>> constantly changing both the security encryption and the attack methods
>>> to break into it.
>>
>> Does that even work with Chrome (certificate pinning for google sites)?
>> (just curious)
>>
>
> Maybe. They document that manually inserted CA certs override pinning.
> But I'm not sure they follow that documented practice 100% of the time.
AFAIK not. Chrome on PC seems not using certificate pinning as well.
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMcIcAAoJENNXIZxhPexGDygH/jeKcbR4Uk0JuOIPDC5NUi5e
QAnUA69adzfriS5F5v//cIzAtRz9FsWJ15bHgKxEXT1F22N2i11i28vhs9kdoxK+
mTpzpj48YXqL2df4jOe0EhLsGe532QtfN5axf04zStum4rXhyXyu0buAodvIj1l6
6UXFLHWUmilHr4A2kLKLxAyPItVcjSKR2M4SIwBb/vKyu/7CQabf+b+9lCEY855q
SaIWiBpcOiLA0SMn9Lxe8h2M1HanD+e3yMNo0JhaqFpRx2IHguE2iAgnVyBKpiSL
0Ft9AP/U683go9y3KWkYjFsoCyb34UeIRn94IkYix0Nia60j+GewGp6sTizwF9U=
=zvDM
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/08f4a820/attachment.key>

From yvoinov at gmail.com  Tue May 10 11:22:44 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 May 2016 17:22:44 +0600
Subject: [squid-users] sahibinden.com fails with https bump
In-Reply-To: <27b82992-9525-6a5e-5e36-b53ac8e13744@kalfaoglu.com>
References: <27b82992-9525-6a5e-5e36-b53ac8e13744@kalfaoglu.com>
Message-ID: <1eb9779b-6edf-2007-4edf-4005ee082455@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Direct connect with bypass squid gives following error:

ssl_error_unrecognized_name_alert

I.e. server certificate has no CN for this FQDN, or has different CN.

In this and in another case, the problem of the site and the webmaster.

Please contact the website owners and inform them of this problem.

10.05.16 16:34, turgut kalfao?lu ?????:
> Hello everyone..
>
> My setup -- this is for speeding up the home ADSL..
>
> https_port 3129 intercept ssl-bump \
>         generate-host-certificates=on dynamic_cert_mem_cache_size=4MB \
>         cert=/etc/squid/ssl_cert/myca.pem key=/etc/squid/ssl_cert/myca.pem
> sslproxy_cert_adapt setCommonName ssl::certDomainMismatch
> sslproxy_cert_error allow all
> sslproxy_flags DONT_VERIFY_PEER
> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
> sslcrtd_children 20 startup=3 idle=1
> ssl_bump server-first  all
>
> This works well for facebook, gmail, google, and probably others..
> But https://sahibinden.com , whatever they are doing fails - the page
> appears broken.
> I tried  broken_sites acl trick, did not help.
>
> acl broken_sites ssl::server_name .sahibinden.com
> acl broken_sites ssl::server_name image5.sahibinden.com
> acl broken_sites ssl::server_name .shbdn.com
> ssl_bump none broken_sites
>
> Does anyone have any ideas what else I can try?
> Many thanks, -tk
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMcSEAAoJENNXIZxhPexGOcoH+wSehhPUL0Gmw/G/03aYINIb
Z2jPrpxcLuQwAKJDVSQ1fDYwCVTmIDYpgUNamIu8qxP9mIOTQOlL7ciLLfD7+vLP
fgx1DneVNZogyQJAk4CutXvnS+D429RnXvU8DAcXelEzIdz7Vuv3l3G3hvrbIikl
wCxVme4oORssHT7IhfF6Y+do2GGVI1erAnRd+81nxYwFUCUYxh6a8moVxNyUEg7e
yF/QiGPBjXHJ/aODcpbhAMe+XMLha4OKJg1q3CXCX1VHIG+hsDwsM9T5UUViGvab
ArzdnVKx81Iu2fPTVxEZ9ThaVORkQYD/XimUgt6aqH8ADSkNf9QZrV4of7sW1yY=
=W+ch
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/defbf23c/attachment.key>

From squid3 at treenet.co.nz  Tue May 10 11:29:50 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 10 May 2016 23:29:50 +1200
Subject: [squid-users] sahibinden.com fails with https bump
In-Reply-To: <27b82992-9525-6a5e-5e36-b53ac8e13744@kalfaoglu.com>
References: <27b82992-9525-6a5e-5e36-b53ac8e13744@kalfaoglu.com>
Message-ID: <12076bfc-5246-beb7-1ee5-3dd335b41efd@treenet.co.nz>

On 10/05/2016 10:34 p.m., turgut kalfao?lu wrote:
> Hello everyone..
> 
> My setup -- this is for speeding up the home ADSL..
> 
> https_port 3129 intercept ssl-bump \
>         generate-host-certificates=on dynamic_cert_mem_cache_size=4MB \
>         cert=/etc/squid/ssl_cert/myca.pem key=/etc/squid/ssl_cert/myca.pem
> sslproxy_cert_adapt setCommonName ssl::certDomainMismatch

Are you sure Squid is actually running this config file?

Where is the definition for this ACL you named "ssl::certDomainMismatch".

Note that name and type of ACL are different things. Name is a text
string usually assigned by you. Type is how and what it matches against
when used.


> sslproxy_cert_error allow all

TLS is security. Ignoring all security errors is not good.


> sslproxy_flags DONT_VERIFY_PEER

The above flag should not be used outside some very specific debugging
circumstances. It breaks the other config settings about what to do with
errors.


> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
> sslcrtd_children 20 startup=3 idle=1
> ssl_bump server-first  all
> 
> This works well for facebook, gmail, google, and probably others..
> But https://sahibinden.com , whatever they are doing fails - the page
> appears broken.
> I tried  broken_sites acl trick, did not help.
> 

Two reasons possibly for that:

1) Order is important.

The exact ordering of the ssl_bump rules will determine which gets
applied. If "server-first all" is listed about "non broken_sites". Then
the broken sites workaround will never be attempted.

2) you are intercepting traffic.

This means that the destination server name is not available to either
of server-first or "none" ations. All you have to work with is the
server raw-IP presented by TCP layer.

You need to upgrade to the peek-and-splice configuration actions for
server name and other TLS detail based workarounds to be useful.



> acl broken_sites ssl::server_name .sahibinden.com
> acl broken_sites ssl::server_name image5.sahibinden.com

This second entry should not be. The top entry overlaps.


> acl broken_sites ssl::server_name .shbdn.com
> ssl_bump none broken_sites
> 
> Does anyone have any ideas what else I can try?


Are you using the very latest 3.5.19 release?
If not please upgrade your Squid.
If you are please upgrade your config rules.

Amos



From uhlar at fantomas.sk  Tue May 10 12:17:23 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 10 May 2016 14:17:23 +0200
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <CAGMPS57aOv1L1DsU3-pj9_XXKrMeHMDVuzc8F3k1WGamTkLkHg@mail.gmail.com>
References: <1462869109249-4677427.post@n4.nabble.com>
 <20160510091042.GC17915@charite.de>
 <CAGMPS57aOv1L1DsU3-pj9_XXKrMeHMDVuzc8F3k1WGamTkLkHg@mail.gmail.com>
Message-ID: <20160510121723.GA18485@fantomas.sk>

>> * alesironi <alesironi at yahoo.it>:
>> > The problem is that on Squid log file (ACCESS.LOG) the URL I see is
>> > similar to this:
>> >
>> > r10---sn-4g57knd7.googlevideo.com:443

>Ralf Hildebrandt <Ralf.Hildebrandt at charite.de> schrieb am Di., 10. Mai 2016
>um 11:10 Uhr:
>> 443 = https = encrypted
>>
>> meaning: You cannot know.

On 10.05.16 09:16, Bjoern Meier wrote:
>Wait. Since when track Squid  data?  Squid only track connections in the
>access.log (that's why it is called access.log).
>So, it is not importent if the data is encrypted, the connection data can't
>be encrypted.

how did you get this?
The data _are_ encrypted. SQUID only sees host:port, nothing more.

>Why shouldn't he see the URL in the access.log?

because the URL is encrypted in the stream.

the "s" in https stands for "secure", which means encrypted and
authenticated (at least with working certs).

That means, the data are encrypted between browser and remote (youtube) server
so the others only see which host and port the connection goes to, but no
details like the URL.

Once again, browser and server know the URL, but nobody between.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
The 3 biggets disasters: Hiroshima 45, Tschernobyl 86, Windows 95


From yvoinov at gmail.com  Tue May 10 12:19:49 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 May 2016 18:19:49 +0600
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <20160510121723.GA18485@fantomas.sk>
References: <1462869109249-4677427.post@n4.nabble.com>
 <20160510091042.GC17915@charite.de>
 <CAGMPS57aOv1L1DsU3-pj9_XXKrMeHMDVuzc8F3k1WGamTkLkHg@mail.gmail.com>
 <20160510121723.GA18485@fantomas.sk>
Message-ID: <d85427a5-015c-7ddc-ed29-d3b7d13011a8@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
It is exists not only splice, but bump also.....


10.05.16 18:17, Matus UHLAR - fantomas ?????:
>>> * alesironi <alesironi at yahoo.it>:
>>> > The problem is that on Squid log file (ACCESS.LOG) the URL I see is
>>> > similar to this:
>>> >
>>> > r10---sn-4g57knd7.googlevideo.com:443
>
>> Ralf Hildebrandt <Ralf.Hildebrandt at charite.de> schrieb am Di., 10.
Mai 2016
>> um 11:10 Uhr:
>>> 443 = https = encrypted
>>>
>>> meaning: You cannot know.
>
> On 10.05.16 09:16, Bjoern Meier wrote:
>> Wait. Since when track Squid  data?  Squid only track connections in the
>> access.log (that's why it is called access.log).
>> So, it is not importent if the data is encrypted, the connection data
can't
>> be encrypted.
>
> how did you get this?
> The data _are_ encrypted. SQUID only sees host:port, nothing more.
>
>> Why shouldn't he see the URL in the access.log?
>
> because the URL is encrypted in the stream.
>
> the "s" in https stands for "secure", which means encrypted and
> authenticated (at least with working certs).
>
> That means, the data are encrypted between browser and remote
(youtube) server
> so the others only see which host and port the connection goes to, but no
> details like the URL.
>
> Once again, browser and server know the URL, but nobody between.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMdHlAAoJENNXIZxhPexGwrMIAIw3IG++vbGoEJOsD35XdGHQ
IftADgArIOSyfhia96w9Cp7R6NEQ+kDRS5r3rzxL6JjIu48mYQPfJpoRSCwbUrYg
LGRb9fRk2pjtI3lSHrh7LAXw6qtMqGprPTOCi6PYnCwRQfRJ9KrjEeBh8OWY+Fcj
j8hXZ2qe03PKLUc6FYjcSYAyXGhssOw0yImmu1og885Wy+jE8hMmsOxzxgO1sXyw
i2eeHrI35Y/T42nfbz2xzBCQnGaoqEkx2Eqo4h8esfZns/NyioKFu68fauDlWxwM
JqgDaS2dTnYExHpW22DT3iE78LUllhyOA/I8TSD/FRK38LHyxqWPOCfzHiaU2pk=
=K9CV
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/d5f04f4c/attachment.key>

From yvoinov at gmail.com  Tue May 10 12:34:18 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 May 2016 18:34:18 +0600
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <20160510121723.GA18485@fantomas.sk>
References: <1462869109249-4677427.post@n4.nabble.com>
 <20160510091042.GC17915@charite.de>
 <CAGMPS57aOv1L1DsU3-pj9_XXKrMeHMDVuzc8F3k1WGamTkLkHg@mail.gmail.com>
 <20160510121723.GA18485@fantomas.sk>
Message-ID: <e53da3eb-5522-d8db-2b81-fb7d662157a6@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
.... and with bump we can see:

https://i1.someimage.com/dG6Y2S9.png

:)

Secure, heh? :)


10.05.16 18:17, Matus UHLAR - fantomas ?????:
>>> * alesironi <alesironi at yahoo.it>:
>>> > The problem is that on Squid log file (ACCESS.LOG) the URL I see is
>>> > similar to this:
>>> >
>>> > r10---sn-4g57knd7.googlevideo.com:443
>
>> Ralf Hildebrandt <Ralf.Hildebrandt at charite.de> schrieb am Di., 10.
Mai 2016
>> um 11:10 Uhr:
>>> 443 = https = encrypted
>>>
>>> meaning: You cannot know.
>
> On 10.05.16 09:16, Bjoern Meier wrote:
>> Wait. Since when track Squid  data?  Squid only track connections in the
>> access.log (that's why it is called access.log).
>> So, it is not importent if the data is encrypted, the connection data
can't
>> be encrypted.
>
> how did you get this?
> The data _are_ encrypted. SQUID only sees host:port, nothing more.
>
>> Why shouldn't he see the URL in the access.log?
>
> because the URL is encrypted in the stream.
>
> the "s" in https stands for "secure", which means encrypted and
> authenticated (at least with working certs).
>
> That means, the data are encrypted between browser and remote
(youtube) server
> so the others only see which host and port the connection goes to, but no
> details like the URL.
>
> Once again, browser and server know the URL, but nobody between.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMdVJAAoJENNXIZxhPexGKSkH/RcZMe4IHFc8Mqk/FGbpVqWY
O4mGWQTXD5O5FwpTJaM3SA0laQ22RzmE8WVTIQ9SyBaH8sk6UmARnO2IVxKlMtm1
AvczwEUmll//L3kCrDKPkIdf7Ei5KAELGm/BJjRVgSK69m2KpUekVBUNgUWryCCw
GFoduh3G9Y/wsMSwsSA++6zCGaYHiLy07tkv0r8peCqVyWJr4jNXgcpoxKewmsWI
sKja8dIzWTcjZ7JzvHxmzBeT2GdJiayj8v5SMdzNE9wVYJlm8efMiLfj7U12P3fX
XlmiNRrycGQcW4xsF0mOZB5fG2xeN0u02MhUyGsNNtcUH5c5UOW/0pSSzZiqEpQ=
=bc0C
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/32e57dc2/attachment.key>

From squid3 at treenet.co.nz  Tue May 10 12:41:30 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 May 2016 00:41:30 +1200
Subject: [squid-users] SSL Bump missing facebook app traffic (resumed
 SSL sessions?)
In-Reply-To: <D3561F85.535B7%adam.cohen-rose@sky.uk>
References: <D3561F85.535B7%adam.cohen-rose@sky.uk>
Message-ID: <f435a75d-ee78-c8d5-05ed-6d10bc0dbb11@treenet.co.nz>

On 9/05/2016 10:05 p.m., Cohen-Rose, Adam wrote:
> Hi there,
> 
> We?re running squid with SSL bump as a transparent proxy in order to
> control access to particular SSL sites.
> 
> We?ve noticed an issue with access to facebook from within the facebook
> app -- specifically it can get through the proxy even though it is *not*
> listed as a domain to splice. Accessing the facebook site from a web
> browser is blocked as expected.
> 
> Looking at packets in Wireshark, the app traffic that gets through seems
> to use a different style of SSL handshake from the web traffic as follows:
> 
> App traffic:
>> client hello
> < server hello, change cipher spec
>   - change cipher spec message: this session reuses previously negotiated
> keys (session resumption)
> < encrypted handshake message
>> change cipher spec, encrypted handshake message, application data
>> application data
> 
> 
> Web traffic:
>> client hello
> < server hello
> < certificate
> < server key exchange
>> client key exchange
>> change cipher spec
>> encryped handshake message
> < new session ticket, change cipher spec, encrypted handshake message
>> application data
> 
> 
> 
> I suspect this may be the same or a similar issue referred to in the
> 3.5.19 release changes (TLS: Fix SSL alert message and session resume
> handling) -- would someone please confirm or deny?
> 

Not sure enough to answer that Q sorry. But if you are bumping at all
you should upgrade anyway. The problem(s) that it fixes are relatively
common even if they are not the specific one you noticed.


> And if we were to upgrade to 3.5.19, is the build on Centos 6 a relatively
> easy one? We?ve been using Eliezer Croitoru?s builds so far, but I don?t
> think he?s had time to make the latest build yet!

He should be doing it real soon now, if not already done and just
testing to make sure it works okay.

> 
> For reference, the relevant parts of our squid configuration are as
> follows:
> 
> https_port {squid-ip}:443 cert=/path/to/cert key=/path/to/key
> sslflags=NO_DEFAULT_CA intercept ssl-bump

FYI: "intercept ssl-bump" should be the first options on the line after
the port. It doesn't matter in 3.x, but will in the future versions as
the mode determines how the following cert/key options are interpreted
and ssl-bump determines what type of properties the cert requires.

Amos



From tarotapprentice at yahoo.com  Tue May 10 12:53:15 2016
From: tarotapprentice at yahoo.com (TarotApprentice)
Date: Tue, 10 May 2016 12:53:15 +0000 (UTC)
Subject: [squid-users] Use arp and time acls to control access
References: <1288604536.1423666.1462884795079.JavaMail.yahoo.ref@mail.yahoo.com>
Message-ID: <1288604536.1423666.1462884795079.JavaMail.yahoo@mail.yahoo.com>

I'm trying to restrict internet access of certain devices to certain times of the day. My config looks like:
acl devicename1 arp aa:bb:cc:dd:ee:ffacl devicename2 arp aa:bb:cc:ff:ee:ddacl usertime time MTWHF 06:30-08:00acl usertime time MTWHF 18:00-22:30
http_access allow devicename1 usertimehttp_access allow devicename2 usertimehttp_access deny devicename
I'm using squid 3.5.17 (the latest in Debian Stretch). The client devices are using the proxy in explicit mode.
devicename1 and devicename2 currently are getting dynamic IP's but I can set the router up to give a static IPv4 address?and use that instead of the mac address.
>From reading the docs it seems arp (the mac address) isn't available if they use IPv6. Also if they're using an https site it isn't going to work unless I start peeking. Is there a better way of restricting the access to the allowed times for both http and https traffic?
MarkJ
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/6d737cd4/attachment.htm>

From alesironi at yahoo.it  Tue May 10 12:34:28 2016
From: alesironi at yahoo.it (alesironi)
Date: Tue, 10 May 2016 05:34:28 -0700 (PDT)
Subject: [squid-users] Understand GOOGLEVIDEO Url from access.log
In-Reply-To: <20160510094551.GG17915@charite.de>
References: <1462869109249-4677427.post@n4.nabble.com>
 <20160510091042.GC17915@charite.de>
 <CAGMPS57aOv1L1DsU3-pj9_XXKrMeHMDVuzc8F3k1WGamTkLkHg@mail.gmail.com>
 <1462870106128-4677430.post@n4.nabble.com>
 <20160510094551.GG17915@charite.de>
Message-ID: <1462883668426-4677453.post@n4.nabble.com>

Ralf Hildebrandt wrote
> * alesironi &lt;

> alesironi@

> &gt;:
> 
>> maybe I do not understand....but this is HTTPS and you can see it
>> (#33legend
>> :) )
>> https://www.youtube.com/watch?v=pI470DZhojA
> 
> Really? On my proxy I cannot see the URL, hm.
> But anyway: You cannot deduce the CONTENTS of the video from the URL
> (unless you'd look at the video yourself)
> 
> -- 
> Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin

> ralf.hildebrandt@

>         Campus Benjamin Franklin
> http://www.charite.de              Hindenburgdamm 30, 12203 Berlin
> Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users

Maybe I was not clear enought, but that was exactly my plan. On your proxy
you can't find for the same reason I can't on mine, there's a GoogleVideo
link (hope is written right this time) and not a Youtube one.

I think the reason has been clarified by Amos (thanks).



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Understand-GOOGLEVIDEO-Url-from-access-log-tp4677427p4677453.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Tue May 10 13:32:40 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 May 2016 01:32:40 +1200
Subject: [squid-users] Use arp and time acls to control access
In-Reply-To: <1288604536.1423666.1462884795079.JavaMail.yahoo@mail.yahoo.com>
References: <1288604536.1423666.1462884795079.JavaMail.yahoo.ref@mail.yahoo.com>
 <1288604536.1423666.1462884795079.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <27f78e39-6621-55c0-5ded-647b0af2a8ee@treenet.co.nz>

On 11/05/2016 12:53 a.m., TarotApprentice wrote:
> I'm trying to restrict internet access of certain devices to certain
> times of the day. My config looks like: acl devicename1 arp
> aa:bb:cc:dd:ee:ffacl devicename2 arp aa:bb:cc:ff:ee:ddacl usertime
> time MTWHF 06:30-08:00acl usertime time MTWHF 18:00-22:30 http_access
> allow devicename1 usertimehttp_access allow devicename2
> usertimehttp_access deny devicename
> I'm using squid 3.5.17 (the
> latest in Debian Stretch). The client devices are using the proxy in
> explicit mode. devicename1 and devicename2 currently are getting
> dynamic IP's but I can set the router up to give a static IPv4
> address and use that instead of the mac address.
> From reading the
> docs it seems arp (the mac address) isn't available if they use
> IPv6.

Correct. Sort of. ARP does not exist in IPv6, but EUI does.

If your network uses SLAAC or DHCPv6 assignments based on the MAC /
EUI-64 then Squid can grab the EUI from the IPv6 address. The arp ACL
uses that for v6 clients when available.

Otherwise you will need static DHCPv6 assignments and src ACL.


> Also if they're using an https site it isn't going to work unless I
> start peeking.

Neither time nor arp types depend on TLS. So the ACLs should work okay
for what they do - just not ideal for what you want to achieve.

HTTPS without bumping just means that your ability to reject is at the
connection/tunnel level rather than individual requests. At present it
should be a reasonable approximation as most browsers dont send many
requests through before closing. That will change as HTTP/2 rollout
increases, since it is designed to maximize connection re-use.



> Is there a better way of restricting the access to the
> allowed times for both http and https traffic?

Not without bumping to get at the individual HTTPS requests.

Amos


From uhlar at fantomas.sk  Tue May 10 13:36:17 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 10 May 2016 15:36:17 +0200
Subject: [squid-users] Use arp and time acls to control access
In-Reply-To: <1288604536.1423666.1462884795079.JavaMail.yahoo@mail.yahoo.com>
References: <1288604536.1423666.1462884795079.JavaMail.yahoo.ref@mail.yahoo.com>
 <1288604536.1423666.1462884795079.JavaMail.yahoo@mail.yahoo.com>
Message-ID: <20160510133617.GB18485@fantomas.sk>

On 10.05.16 12:53, TarotApprentice wrote:
>I'm trying to restrict internet access of certain devices to certain times of the day. My config looks like:
>acl devicename1 arp aa:bb:cc:dd:ee:ffacl devicename2 arp aa:bb:cc:ff:ee:ddacl usertime time MTWHF 06:30-08:00acl usertime time MTWHF 18:00-22:30

I see yahoo converts html to plaintext very badly - joins lines by
converting line breaks to no whte space at all (gmail does similar stuff too)

>http_access allow devicename1 usertimehttp_access allow devicename2 usertimehttp_access deny devicename

... (use real mail client instead of yahoo's if possible)

>I'm using squid 3.5.17 (the latest in Debian Stretch). The client devices are using the proxy in explicit mode.
>devicename1 and devicename2 currently are getting dynamic IP's but I can set the router up to give a static IPv4 address?and use that instead of the mac address.
>>From reading the docs it seems arp (the mac address) isn't available if they use IPv6.

Incorrect. mac address can't be used behind router, because it's only
visible on local network. Behing router, you only see IP Address, but mac
address already belongs to the router (that's the point of routing)

> Also if they're using an https site it isn't going to work unless I start
> peeking. 

without peeking, you only see where the connection goes to, not the URL
since it's encrypted in the data stream.

> Is there a better way of restricting the access to the allowed
> times for both http and https traffic?

no, in order to log more about HTTPS connections, you must effectively be
the attacker who does MITM.
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Linux is like a teepee: no Windows, no Gates and an apache inside...


From corpengineer at gmail.com  Tue May 10 17:19:56 2016
From: corpengineer at gmail.com (J Green)
Date: Tue, 10 May 2016 10:19:56 -0700
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <3405e72853cadeaf0a57c6f6b6359a86@treenet.co.nz>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyxrQ3K7hNqD6hxzh+pUwwhPs3a9iEACuhWBoovEh+s7kQ@mail.gmail.com>
 <3405e72853cadeaf0a57c6f6b6359a86@treenet.co.nz>
Message-ID: <CANUpZywGsADydjEQznm6bC1dNuo=HsOXKbCCP6wpyifU7Fv8Fg@mail.gmail.com>

At the host level?  Was hoping for something at the network level.

On Mon, May 9, 2016 at 10:06 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 2016-05-10 06:05, J Green wrote:
>
>> Appreciate the response.  Thought it might work if I added those ports
>> to the safe list.
>>
>
> The Safe_ports list is the ports it is considered safe to send traffic to
> from an HTTP proxy. The ports not on that list are for protocols that can
> have crafted messages that look like HTTP to the proxy and non-HTTP to the
> server. Enabling server attacks through HTTP relays. Email SMTP ports are
> particularly vulnerable to spam being delivered in this way.
>
>
>> If not Squid, any idea how to accomplish this?
>>
>>
> With your systems regular QoS settings.
>
> Amos
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/b7a78753/attachment.htm>

From corpengineer at gmail.com  Tue May 10 17:25:33 2016
From: corpengineer at gmail.com (J Green)
Date: Tue, 10 May 2016 10:25:33 -0700
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
Message-ID: <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>

So back to the intended use cases for HTTP, HTTPS, & FTP , how can you log
violations of maximum download/upload size?  I see an error message
generated on the client system, but not w/in Squid.  Thank you.

On Mon, May 9, 2016 at 10:12 AM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> Squid is not a proxy server every imaginable the TCP-usage protocol.
>
> AFAIK HTTP/HTTPS/FTP. That's all, folks.
>
>
> 09.05.16 23:07, J Green ?????:
> > Hello all:
> >
> > Can Traffic Management Settings be configured for TCP protocols other
> than HTTP?
> >
> > Would like to limit maximum upload and download sizes for other TCP
> protocols:  SMB, NFS, FTP, and RDP.
> >
> > Is this possible?  If so, how?
> >
> > Thank you.
> >
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXMMUAAAoJENNXIZxhPexGOy8IAMs2DbmNAopj7jqL5Z9KEg6z
> GpRL7y207VkSaz12Bhcdf2PsAy+xCnHzJ6SMeR4MNKeTrfImSQoyJbS4UuFHygcR
> v+9618vUKfpcYaTUc09DTJUh49F0PwJX/lJQxNiDtb/AHEkX+WdDbuFL2S8+AzJm
> ZhNA1FigXzuhGpwaxqhh2uB0zL5wec7IQuSO24POPvBf/hgvzSmBuH6u1SuBLvpp
> RPObRULHTaWhyvMQgufHWm1H0ejpvCZgCqEEcXSW4MbqCatr8DBSmkP28EfweocD
> 4mdpKTWu6HX9EX3ZZ96dKqsOjEBXlKU8BUqlK2irMQgM09IIXCjCRc5W00Qv8tA=
> =v0m2
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/3c6831da/attachment.htm>

From yvoinov at gmail.com  Tue May 10 17:29:12 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 May 2016 23:29:12 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
Message-ID: <51d8f7ad-29c8-2f00-6b83-4483b637ef56@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
First, upload is PUT method usage. Most common HTTP/HTTPS is GET/HEAD
methods.

Second, logging of all things is not my goal.

For me, it is sufficient that the restrictions imposed by me in
accordance with the policy. The amount of downloads for my count
analyzers logs, if management is interesting to read the reports
independently.

10.05.16 23:25, J Green ?????:
> So back to the intended use cases for HTTP, HTTPS, & FTP , how can you log violations of maximum
download/upload size?  I see an error message generated on the client
system, but not w/in Squid.  Thank you.
>
> On Mon, May 9, 2016 at 10:12 AM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> Squid is not a proxy server every imaginable the TCP-usage protocol.
>
> AFAIK HTTP/HTTPS/FTP. That's all, folks.
>
>
> 09.05.16 23:07, J Green ?????:
> > Hello all:
>
>
>
>       > Can Traffic Management Settings be configured for TCP
>       protocols other than HTTP?
>
>
>
>       > Would like to limit maximum upload and download sizes for
>       other TCP protocols:  SMB, NFS, FTP, and RDP.
>
>
>
>       > Is this possible?  If so, how?
>
>
>
>       > Thank you.
>
>
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMhpnAAoJENNXIZxhPexG3ZkH/RXEyeJFjGECUV7S6ebQg0SZ
31A82FNRApaHOLZWPHYZ0u1tpyISYK2t+2ZpAI+lAuMocUtRIW6gKHIPiWP66SdZ
xLU5PeSvEbvlncoChajChD+3SDmrlADJD7WpMfw/4RqwDZqNznKX6jLRv3ApoCwu
JRl+6S2PQ2UARmUEEyeAJLIfZQLKI3EqyUphaVeTaO6una1RXQgavRePjU3zuVBX
9Yw0c8cRxtTuo9GePjPsQVIn7QZTSp6EHJ9ExHiLFFi1USdf51qSpc5VKS5HpOkL
U8wdp59yDb9fa15rrqBSFhXCTwhe5qbyDuxdOq6tozHN5BTm3zMNICv1En1dUig=
=x2f0
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/f1252892/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/f1252892/attachment.key>

From yvoinov at gmail.com  Tue May 10 17:30:17 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 May 2016 23:30:17 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
Message-ID: <cb4be726-58b8-7b76-1945-cecb76e0b53e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Furthermore, the proxy server itself is not a billing system. Accounting
as task can be solved by the third software analyzing access logs.

10.05.16 23:25, J Green ?????:
> So back to the intended use cases for HTTP, HTTPS, & FTP , how can you log violations of maximum
download/upload size?  I see an error message generated on the client
system, but not w/in Squid.  Thank you.
>
> On Mon, May 9, 2016 at 10:12 AM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> Squid is not a proxy server every imaginable the TCP-usage protocol.
>
> AFAIK HTTP/HTTPS/FTP. That's all, folks.
>
>
> 09.05.16 23:07, J Green ?????:
> > Hello all:
>
>
>
>       > Can Traffic Management Settings be configured for TCP
>       protocols other than HTTP?
>
>
>
>       > Would like to limit maximum upload and download sizes for
>       other TCP protocols:  SMB, NFS, FTP, and RDP.
>
>
>
>       > Is this possible?  If so, how?
>
>
>
>       > Thank you.
>
>
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMhqoAAoJENNXIZxhPexGeBgIAMzXGW+GXUBvCdvXghZ+7tmg
WXoXjUZfRu/2A8yUrh2nq3wh8gFqsXMmt1POVXaqgnTSJiPBqjfOzYP8zYFuVwBo
ZxgdAnOdNIYI/6jAhVeBPV+fq8MrlE1nWmLZNdwOo3DGaGnluuSBgk4XPIzsPVF3
apEPqLJlHqTlRA5flwivr2t2ZCtMKmOwe1uI3REwmeH4pkYBDCw1g4pIyNjn8c3z
D+Bpti8exMPGMarVyzR/rqx7D1W7x9548KthXWo/F3PRx44YlF0VUeoG1adovCtp
8WW3oNRceHOfgTefmbPm7tMD8ivH1LpIZVZEdJd/EyNQpbHbb3F85Sg7Kky3ypk=
=gZLy
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/24267e2d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/24267e2d/attachment.key>

From corpengineer at gmail.com  Tue May 10 17:41:55 2016
From: corpengineer at gmail.com (J Green)
Date: Tue, 10 May 2016 10:41:55 -0700
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <51d8f7ad-29c8-2f00-6b83-4483b637ef56@gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
 <51d8f7ad-29c8-2f00-6b83-4483b637ef56@gmail.com>
Message-ID: <CANUpZyyRbNR938ZHpYe2d2XCACcxepjcH6auX++E6MOwMve4cA@mail.gmail.com>

That is fair, re intended use.  But yes, management want to know if users
are attempting to circumvent policy.  Re analyzing logs, I did not see this
logged anywhere.  Is there perhaps a debug mode which I need to enable?

Thank you.

On Tue, May 10, 2016 at 10:29 AM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> First, upload is PUT method usage. Most common HTTP/HTTPS is GET/HEAD
> methods.
>
> Second, logging of all things is not my goal.
>
> For me, it is sufficient that the restrictions imposed by me in accordance
> with the policy. The amount of downloads for my count analyzers logs, if
> management is interesting to read the reports independently.
>
> 10.05.16 23:25, J Green ?????:
> > So back to the intended use cases for HTTP, HTTPS, & FTP , how can you
> log violations of maximum download/upload size?  I see an error message
> generated on the client system, but not w/in Squid.  Thank you.
> >
> > On Mon, May 9, 2016 at 10:12 AM, Yuri Voinov <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com> <yvoinov at gmail.com>> wrote:
> >
> >
> > Squid is not a proxy server every imaginable the TCP-usage protocol.
> >
> > AFAIK HTTP/HTTPS/FTP. That's all, folks.
> >
> >
> > 09.05.16 23:07, J Green ?????:
> > > Hello all:
> >
> >
> >
> >       > Can Traffic Management Settings be configured for TCP
> >       protocols other than HTTP?
> >
> >
> >
> >       > Would like to limit maximum upload and download sizes for
> >       other TCP protocols:  SMB, NFS, FTP, and RDP.
> >
> >
> >
> >       > Is this possible?  If so, how?
> >
> >
> >
> >       > Thank you.
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >       > _______________________________________________
> >
> >       > squid-users mailing list
> >
> >       > squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> >
> >       > http://lists.squid-cache.org/listinfo/squid-users
> >
> >
> >
> >     _______________________________________________
> >     squid-users mailing list
> >     squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> >     http://lists.squid-cache.org/listinfo/squid-users
> >
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXMhpnAAoJENNXIZxhPexG3ZkH/RXEyeJFjGECUV7S6ebQg0SZ
> 31A82FNRApaHOLZWPHYZ0u1tpyISYK2t+2ZpAI+lAuMocUtRIW6gKHIPiWP66SdZ
> xLU5PeSvEbvlncoChajChD+3SDmrlADJD7WpMfw/4RqwDZqNznKX6jLRv3ApoCwu
> JRl+6S2PQ2UARmUEEyeAJLIfZQLKI3EqyUphaVeTaO6una1RXQgavRePjU3zuVBX
> 9Yw0c8cRxtTuo9GePjPsQVIn7QZTSp6EHJ9ExHiLFFi1USdf51qSpc5VKS5HpOkL
> U8wdp59yDb9fa15rrqBSFhXCTwhe5qbyDuxdOq6tozHN5BTm3zMNICv1En1dUig=
> =x2f0
> -----END PGP SIGNATURE-----
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/d7d9f0b8/attachment.htm>

From yvoinov at gmail.com  Tue May 10 17:46:03 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 10 May 2016 23:46:03 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZyyRbNR938ZHpYe2d2XCACcxepjcH6auX++E6MOwMve4cA@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
 <51d8f7ad-29c8-2f00-6b83-4483b637ef56@gmail.com>
 <CANUpZyyRbNR938ZHpYe2d2XCACcxepjcH6auX++E6MOwMve4cA@mail.gmail.com>
Message-ID: <1893fb7d-4e92-f7d9-d23a-f79b9bfccdf6@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
SARG or SquidAnalyzer, in general, has reports with denied and donwloads
logging.

This information (excluding the access restrictions) are usually not
found in the logs immediately, it takes some processing.

10.05.16 23:41, J Green ?????:
> That is fair, re intended use.  But yes, management want to know if users are attempting to circumvent
policy.  Re analyzing logs, I did not see this logged anywhere.  Is
there perhaps a debug mode which I need to enable?
>
> Thank you.
>
> On Tue, May 10, 2016 at 10:29 AM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> First, upload is PUT method usage. Most common HTTP/HTTPS is GET/HEAD
methods.
>
> Second, logging of all things is not my goal.
>
> For me, it is sufficient that the restrictions imposed by me in
accordance with the policy. The amount of downloads for my count
analyzers logs, if management is interesting to read the reports
independently.
>
> 10.05.16 23:25, J Green ?????:
> > So back to the intended use
>       cases for HTTP, HTTPS, & FTP , how can you log violations of
>       maximum download/upload size?  I see an error message generated on
>       the client system, but not w/in Squid.  Thank you.
>
>
>
>       > On Mon, May 9, 2016 at 10:12 AM, Yuri Voinov
>       <yvoinov at gmail.com <mailto:yvoinov at gmail.com>
<mailto:yvoinov at gmail.com> <mailto:yvoinov at gmail.com>> wrote:
>
>
>
>
>
>       > Squid is not a proxy server every imaginable the TCP-usage
>       protocol.
>
>
>
>       > AFAIK HTTP/HTTPS/FTP. That's all, folks.
>
>
>
>
>
>       > 09.05.16 23:07, J Green ?????:
>
>       > > Hello all:
>
>
>
>
>
>
>
>       >       > Can Traffic Management Settings be configured for
>       TCP
>
>       >       protocols other than HTTP?
>
>
>
>
>
>
>
>       >       > Would like to limit maximum upload and download
>       sizes for
>
>       >       other TCP protocols:  SMB, NFS, FTP, and RDP.
>
>
>
>
>
>
>
>       >       > Is this possible?  If so, how?
>
>
>
>
>
>
>
>       >       > Thank you.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > _______________________________________________
>
>
>
>       >       > squid-users mailing list
>
>
>
>       >       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>       <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>
>
>       >       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>       >     _______________________________________________
>
>       >     squid-users mailing list
>
>       >     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>       <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>       >     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMh5bAAoJENNXIZxhPexGCBQH/jN03pgdWzZq9mxFlXGYDLmC
L94Fl8RMSGgAInJuB4o/QqMpp69yB1WwHlXfWuohz7R/Ao0nU4PEKFlsdIvYt0Sq
oSLK3VSROJzpBn473M1Dk02FLEG1KfEpJk4DqDACB1W6vshZhwudLcc0gNUSmqC7
go1IFown+hYg3Hw1yDHeDeHsmVxhPkLHnybo9iJ+FsD/xQxRcydPbYefKkVb1x9Z
460wEGNNhCvjxbLXku2nj1t8fzLoMXTnhVqlw7PTIXx1eQb6rgTZzec4pfGukUCU
YtHNQo7+wv+//K9G9DNR3LT/mYPQfeJjDdNw2R6dq9Tl944Z3acMzLqtzW/Ttyw=
=wO1H
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/f174ced9/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/f174ced9/attachment.key>

From rafael.akchurin at diladele.com  Tue May 10 18:18:10 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 10 May 2016 18:18:10 +0000
Subject: [squid-users] Squid 3.5.19 for Microsoft Windows 64-bit is available
Message-ID: <VI1PR04MB13597FA4B6B4BFAA42AE13528F710@VI1PR04MB1359.eurprd04.prod.outlook.com>

Greetings everyone,



The CygWin based build of Squid proxy for Microsoft Windows version 3.5.19 is now available (amd64 only!).



* Original release notes are at http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.19-RELEASENOTES.html.

* Ready to use MSI package can be downloaded from http://squid.diladele.com.

* List of open issues for the installer - https://github.com/diladele/squid3-windows/issues



Thanks a lot for Squid developers for making this great software!



Please join our humble efforts to provide ready to run MSI installer for Squid on Microsoft Windows with all required dependencies at GitHub -

https://github.com/diladele/squid3-windows. Please report all issues/bugs/feature requests at GitHub project. Issues about the *MSI installer only* can also be reported to support at diladele.com<mailto:support at diladele.com>.



NOTE: for those who are interested in Docker - we plan to make Squid available as Docker container (including our ICAP web filter). You can track the progress at https://github.com/diladele/docker-cluster (clustered version) or https://github.com/diladele/docker-websafety (non clustered version when everything runs in one container).



Best regards,

Rafael Akchurin

Diladele B.V.

http://www.quintolabs.com

http://www.diladele.com



--

Please take a look at Web Safety - our ICAP based web filter server for Squid proxy.





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/44e17a12/attachment.htm>

From colonelforbin74 at gmail.com  Tue May 10 19:45:22 2016
From: colonelforbin74 at gmail.com (Adam W. Dace)
Date: Tue, 10 May 2016 19:45:22 +0000
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
Message-ID: <CALKvBnaa06XU+jh19vNZOzZEskqsQWJ=VXTK96Jjv76t987L1A@mail.gmail.com>

Back in the day, I used "traffic shaping" on the Cisco router to achieve
that sort of thing.  It actually changes the traffic to fit your Internet
link, versus limiting per-connection speed.

Still, this is off-topic.  Anyways, consult your CIOS documentation and
good luck!  :)

Regards,

Adam

On Mon, May 9, 2016 at 12:07 PM J Green <corpengineer at gmail.com> wrote:

> Hello all:
>
> Can Traffic Management Settings be configured for TCP protocols other than
> HTTP?
>
> Would like to limit maximum upload and download sizes for other TCP
> protocols:  SMB, NFS, FTP, and RDP.
>
> Is this possible?  If so, how?
>
> Thank you.
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/86858791/attachment.htm>

From yvoinov at gmail.com  Tue May 10 19:49:58 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 May 2016 01:49:58 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CALKvBnaa06XU+jh19vNZOzZEskqsQWJ=VXTK96Jjv76t987L1A@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <CALKvBnaa06XU+jh19vNZOzZEskqsQWJ=VXTK96Jjv76t987L1A@mail.gmail.com>
Message-ID: <53976a17-fbd5-9459-b4da-da4250d25f9d@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
You can not pull the owl on the globe. )

By the way, I'm not sure what he was trying to achieve this :)


11.05.16 1:45, Adam W. Dace ?????:
> Back in the day, I used "traffic shaping" on the Cisco router to achieve that sort of thing. 
It actually changes the traffic to fit your Internet link, versus
limiting per-connection speed.
>
> Still, this is off-topic.  Anyways, consult your CIOS documentation
and good luck!  :)
>
> Regards,
>
> Adam
>
> On Mon, May 9, 2016 at 12:07 PM J Green <corpengineer at gmail.com
<mailto:corpengineer at gmail.com>> wrote:
>
>     Hello all:
>
>     Can Traffic Management Settings be configured for TCP protocols
other than HTTP?
>
>     Would like to limit maximum upload and download sizes for other
TCP protocols:  SMB, NFS, FTP, and RDP.
>
>     Is this possible?  If so, how?
>
>     Thank you.
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMjtlAAoJENNXIZxhPexGUFMIAIMCYqcc72KRyx3Z6brNmq+x
i1eKyhOcUfjnVW+LpJLZBgLQuER3wIdzXF68TBU+9oDl7bsMAfIlu9RH0bvngM+m
/jM16z9qkAcRaeY0iCAn5V/znFQ+9GKL0eC8d17O9DlyVBgiy0xEMrzpUDmfK4wF
dW/UBoOfrAJESbS7uuh9VmBYuFc8Gse+G58fb8G/mwpNgvGxyHHq3tqs0ZSUGUzV
TkwbcS+qU9D3c9sZhlhR+XvqXl6b7vYumB5dVPG5sjgO/CLOsji8wokL0ep3mInG
VnOaDggzCA6sy0jrhd9uR+f1xZvU/AzGwfUJlyIn3hM+3r6cWDPOmkccHDt6cp8=
=qni2
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/93669590/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/93669590/attachment.key>

From yvoinov at gmail.com  Tue May 10 19:55:30 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 May 2016 01:55:30 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <53976a17-fbd5-9459-b4da-da4250d25f9d@gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <CALKvBnaa06XU+jh19vNZOzZEskqsQWJ=VXTK96Jjv76t987L1A@mail.gmail.com>
 <53976a17-fbd5-9459-b4da-da4250d25f9d@gmail.com>
Message-ID: <b378ae1f-eb4c-5432-2fe3-89c0c29a7880@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
And, incidentally, smoke manuals - Cisco either enables traffic shaping
or limit the speed on ports, protocols, networks, clients and so on. :)
As you wish. :)

Its possibilities are limited only version of the software platform, and
your ability to smoke manuals. :)

11.05.16 1:49, Yuri Voinov ?????:
>
> You can not pull the owl on the globe. )
>
> By the way, I'm not sure what he was trying to achieve this :)
>
>
> 11.05.16 1:45, Adam W. Dace ?????:
> > Back in the day, I used
>       "traffic shaping" on the Cisco router to achieve that sort of
>       thing.  It actually changes the traffic to fit your Internet link,
>       versus limiting per-connection speed.
>
>
>
>       > Still, this is off-topic.  Anyways, consult your CIOS
>       documentation and good luck!  :)
>
>
>
>       > Regards,
>
>
>
>       > Adam
>
>
>
>       > On Mon, May 9, 2016 at 12:07 PM J Green
>       <corpengineer at gmail.com
>       <mailto:corpengineer at gmail.com>> wrote:
>
>
>
>       >     Hello all:
>
>
>
>       >     Can Traffic Management Settings be configured for TCP
>       protocols other than HTTP?
>
>
>
>       >     Would like to limit maximum upload and download sizes for
>       other TCP protocols:  SMB, NFS, FTP, and RDP.
>
>
>
>       >     Is this possible?  If so, how?
>
>
>
>       >     Thank you.
>
>
>
>
>
>       >     _______________________________________________
>
>       >     squid-users mailing list
>
>       >     squid-users at lists.squid-cache.org
>       <mailto:squid-users at lists.squid-cache.org>
>
>       >     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMjyyAAoJENNXIZxhPexGH+gH/A2Ma7A+LqIP34jWqLK2LUvY
GLtzDh8KZuHgucg6dXlsCUIP+odUcm1RFhyxDBQMto4J5i+1C3qWQ+AVhj2SaWn7
RyS3NPAtOAcoN7aAFbghsHXPv9UZVa5AG5qqNkr6HDv9TlpcOWAQK2kzfDQL8TZs
SBtADRFWYwHpr3lK5bU50E5LYJ0+IePLEuHiltj+Q2hh26zRfixNmIWDr1awxIUP
izg4rHLg7Zl8i2M3dGW50jf0SGf2sPUm3ZK6W8HLusBv0tsNn1Z/4eVzl9F6n9XE
nvx5wVLNA4wurZDAuDn8Tca+QeBIbZ78RiAooT+1dxMTmOEY33+PZOykRI8y80U=
=y3cz
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/0a3cdd2f/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/0a3cdd2f/attachment.key>

From corpengineer at gmail.com  Tue May 10 19:59:05 2016
From: corpengineer at gmail.com (J Green)
Date: Tue, 10 May 2016 12:59:05 -0700
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <b378ae1f-eb4c-5432-2fe3-89c0c29a7880@gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <CALKvBnaa06XU+jh19vNZOzZEskqsQWJ=VXTK96Jjv76t987L1A@mail.gmail.com>
 <53976a17-fbd5-9459-b4da-da4250d25f9d@gmail.com>
 <b378ae1f-eb4c-5432-2fe3-89c0c29a7880@gmail.com>
Message-ID: <CANUpZyw+-DiAC93rzijTTk9+bGMi1pnXEYp2RnAA7U5AZ+j68w@mail.gmail.com>

>From what I understand, it is traffic policing, as opposed to traffic
shaping.

The goal is to block transfer of large files over various TCP protocols,
while allowing small files.

Thank you all, for your input.



On Tue, May 10, 2016 at 12:55 PM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> And, incidentally, smoke manuals - Cisco either enables traffic shaping or
> limit the speed on ports, protocols, networks, clients and so on. :) As you
> wish. :)
>
> Its possibilities are limited only version of the software platform, and
> your ability to smoke manuals. :)
>
> 11.05.16 1:49, Yuri Voinov ?????:
>
> >
> > You can not pull the owl on the globe. )
> >
> > By the way, I'm not sure what he was trying to achieve this :)
> >
> >
> > 11.05.16 1:45, Adam W. Dace ?????:
> > > Back in the day, I used
> >       "traffic shaping" on the Cisco router to achieve that sort of
> >       thing.  It actually changes the traffic to fit your Internet link,
> >       versus limiting per-connection speed.
> >
> >
> >
> >       > Still, this is off-topic.  Anyways, consult your CIOS
> >       documentation and good luck!  :)
> >
> >
> >
> >       > Regards,
> >
> >
> >
> >       > Adam
> >
> >
> >
> >       > On Mon, May 9, 2016 at 12:07 PM J Green
> >       <corpengineer at gmail.com
> >       <mailto:corpengineer at gmail.com> <corpengineer at gmail.com>> wrote:
> >
> >
> >
> >       >     Hello all:
> >
> >
> >
> >       >     Can Traffic Management Settings be configured for TCP
> >       protocols other than HTTP?
> >
> >
> >
> >       >     Would like to limit maximum upload and download sizes for
> >       other TCP protocols:  SMB, NFS, FTP, and RDP.
> >
> >
> >
> >       >     Is this possible?  If so, how?
> >
> >
> >
> >       >     Thank you.
> >
> >
> >
> >
> >
> >       >     _______________________________________________
> >
> >       >     squid-users mailing list
> >
> >       >     squid-users at lists.squid-cache.org
> >       <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> >
> >       >     http://lists.squid-cache.org/listinfo/squid-users
> >
> >
> >
> >
> >
> >
> >
> >       > _______________________________________________
> >
> >       > squid-users mailing list
> >
> >       > squid-users at lists.squid-cache.org
> >
> >       > http://lists.squid-cache.org/listinfo/squid-users
> >
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXMjyyAAoJENNXIZxhPexGH+gH/A2Ma7A+LqIP34jWqLK2LUvY
> GLtzDh8KZuHgucg6dXlsCUIP+odUcm1RFhyxDBQMto4J5i+1C3qWQ+AVhj2SaWn7
> RyS3NPAtOAcoN7aAFbghsHXPv9UZVa5AG5qqNkr6HDv9TlpcOWAQK2kzfDQL8TZs
> SBtADRFWYwHpr3lK5bU50E5LYJ0+IePLEuHiltj+Q2hh26zRfixNmIWDr1awxIUP
> izg4rHLg7Zl8i2M3dGW50jf0SGf2sPUm3ZK6W8HLusBv0tsNn1Z/4eVzl9F6n9XE
> nvx5wVLNA4wurZDAuDn8Tca+QeBIbZ78RiAooT+1dxMTmOEY33+PZOykRI8y80U=
> =y3cz
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/38ee8fb9/attachment.htm>

From yvoinov at gmail.com  Tue May 10 20:03:14 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 May 2016 02:03:14 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZyw+-DiAC93rzijTTk9+bGMi1pnXEYp2RnAA7U5AZ+j68w@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <CALKvBnaa06XU+jh19vNZOzZEskqsQWJ=VXTK96Jjv76t987L1A@mail.gmail.com>
 <53976a17-fbd5-9459-b4da-da4250d25f9d@gmail.com>
 <b378ae1f-eb4c-5432-2fe3-89c0c29a7880@gmail.com>
 <CANUpZyw+-DiAC93rzijTTk9+bGMi1pnXEYp2RnAA7U5AZ+j68w@mail.gmail.com>
Message-ID: <126efe66-beff-4ece-ad86-31e8c615a7f9@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I think change is posing the problem. "Big" and "small", it seems to me,
is too vague a criterion. Plus direct solution assumes continious
control of each connection at all and accounting at all. What, in my
opinion, a bit crazy.

11.05.16 1:59, J Green ?????:
> From what I understand, it is traffic policing, as opposed to traffic shaping.
>
> The goal is to block transfer of large files over various TCP
protocols, while allowing small files.
>
> Thank you all, for your input.
>
> 
>
> On Tue, May 10, 2016 at 12:55 PM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> And, incidentally, smoke manuals - Cisco either enables traffic
shaping or limit the speed on ports, protocols, networks, clients and so
on. :) As you wish. :)
>
> Its possibilities are limited only version of the software platform,
and your ability to smoke manuals. :)
>
> 11.05.16 1:49, Yuri Voinov ?????:
>
>
>
>       > You can not pull the owl on the globe. )
>
>
>
>       > By the way, I'm not sure what he was trying to achieve this
>       :)
>
>
>
>
>
>       > 11.05.16 1:45, Adam W. Dace ?????:
>
>       > > Back in the day, I used
>
>       >       "traffic shaping" on the Cisco router to achieve that
>       sort of
>
>       >       thing.  It actually changes the traffic to fit your
>       Internet link,
>
>       >       versus limiting per-connection speed.
>
>
>
>
>
>
>
>       >       > Still, this is off-topic.  Anyways, consult your
>       CIOS
>
>       >       documentation and good luck!  :)
>
>
>
>
>
>
>
>       >       > Regards,
>
>
>
>
>
>
>
>       >       > Adam
>
>
>
>
>
>
>
>       >       > On Mon, May 9, 2016 at 12:07 PM J Green
>
>       >       <corpengineer at gmail.com <mailto:corpengineer at gmail.com>
>
>       >       <mailto:corpengineer at gmail.com>
<mailto:corpengineer at gmail.com>> wrote:
>
>
>
>
>
>
>
>       >       >     Hello all:
>
>
>
>
>
>
>
>       >       >     Can Traffic Management Settings be configured
>       for TCP
>
>       >       protocols other than HTTP?
>
>
>
>
>
>
>
>       >       >     Would like to limit maximum upload and
>       download sizes for
>
>       >       other TCP protocols:  SMB, NFS, FTP, and RDP.
>
>
>
>
>
>
>
>       >       >     Is this possible?  If so, how?
>
>
>
>
>
>
>
>       >       >     Thank you.
>
>
>
>
>
>
>
>
>
>
>
>       >       >   
>       _______________________________________________
>
>
>
>       >       >     squid-users mailing list
>
>
>
>       >       >     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       >       <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>
>
>       >       >   
>       http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > _______________________________________________
>
>
>
>       >       > squid-users mailing list
>
>
>
>       >       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>
>
>       >       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMj6CAAoJENNXIZxhPexG4P4H/iampGAgQXQik3ZgbDwgDn22
CNB4/KFcrv1Sdjst6b3pzko/XRpvOhuYSbJ2tUOfasP7gF5bTqUTYl1jCWxd07kA
VXmSbY5ynM3hgHVZowiL/6wksxQyTiqNEA86ae77gDig0SWu8NbNHZ058iN/sCRn
9F363nYdpj4LffHYXe16XLn/lGLF3yG0kpDZI+dSVy2QS57aOisc0lADTbKvzSOJ
RpfUfUI4EHcQoOVYlk91c6LckZGxy6N1lYEQbdCy+Y0OwM25crCaiaEuiaB8RTSi
kKcJk16L5UFGYQiKchyUq9r73D4+0hLlloOTCJ+HwNYQzbLFPn+rTrLo6tI47pg=
=Y3mu
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/60eb40c2/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/60eb40c2/attachment.key>

From corpengineer at gmail.com  Tue May 10 20:11:47 2016
From: corpengineer at gmail.com (J Green)
Date: Tue, 10 May 2016 13:11:47 -0700
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <126efe66-beff-4ece-ad86-31e8c615a7f9@gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <CALKvBnaa06XU+jh19vNZOzZEskqsQWJ=VXTK96Jjv76t987L1A@mail.gmail.com>
 <53976a17-fbd5-9459-b4da-da4250d25f9d@gmail.com>
 <b378ae1f-eb4c-5432-2fe3-89c0c29a7880@gmail.com>
 <CANUpZyw+-DiAC93rzijTTk9+bGMi1pnXEYp2RnAA7U5AZ+j68w@mail.gmail.com>
 <126efe66-beff-4ece-ad86-31e8c615a7f9@gmail.com>
Message-ID: <CANUpZyyBzJVAdPDUp6i_PBhMJY4vMMXj5Myzibsmew-xD4J_3Q@mail.gmail.com>

Fair criticisms, yes.  But an interesting problem, no?   And I think I am
close to getting something somewhat functional, using various pieces of
hardware and software.  Is it a slick solution?  Not at all.  But it just
might work more or less.  Small could be 10MB.  Large is larger.

On Tue, May 10, 2016 at 1:03 PM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> I think change is posing the problem. "Big" and "small", it seems to me,
> is too vague a criterion. Plus direct solution assumes continious control
> of each connection at all and accounting at all. What, in my opinion, a bit
> crazy.
>
> 11.05.16 1:59, J Green ?????:
> > From what I understand, it is traffic policing, as opposed to traffic
> shaping.
> >
> > The goal is to block transfer of large files over various TCP protocols,
> while allowing small files.
> >
> > Thank you all, for your input.
> >
> >
> >
> > On Tue, May 10, 2016 at 12:55 PM, Yuri Voinov <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com> <yvoinov at gmail.com>> wrote:
> >
> >
> > And, incidentally, smoke manuals - Cisco either enables traffic shaping
> or limit the speed on ports, protocols, networks, clients and so on. :) As
> you wish. :)
> >
> > Its possibilities are limited only version of the software platform, and
> your ability to smoke manuals. :)
> >
> > 11.05.16 1:49, Yuri Voinov ?????:
> >
> >
> >
> >       > You can not pull the owl on the globe. )
> >
> >
> >
> >       > By the way, I'm not sure what he was trying to achieve this
> >       :)
> >
> >
> >
> >
> >
> >       > 11.05.16 1:45, Adam W. Dace ?????:
> >
> >       > > Back in the day, I used
> >
> >       >       "traffic shaping" on the Cisco router to achieve that
> >       sort of
> >
> >       >       thing.  It actually changes the traffic to fit your
> >       Internet link,
> >
> >       >       versus limiting per-connection speed.
> >
> >
> >
> >
> >
> >
> >
> >       >       > Still, this is off-topic.  Anyways, consult your
> >       CIOS
> >
> >       >       documentation and good luck!  :)
> >
> >
> >
> >
> >
> >
> >
> >       >       > Regards,
> >
> >
> >
> >
> >
> >
> >
> >       >       > Adam
> >
> >
> >
> >
> >
> >
> >
> >       >       > On Mon, May 9, 2016 at 12:07 PM J Green
> >
> >       >       <corpengineer at gmail.com <mailto:corpengineer at gmail.com>
> <corpengineer at gmail.com>
> >
> >       >       <mailto:corpengineer at gmail.com> <corpengineer at gmail.com>
> <mailto:corpengineer at gmail.com> <corpengineer at gmail.com>> wrote:
> >
> >
> >
> >
> >
> >
> >
> >       >       >     Hello all:
> >
> >
> >
> >
> >
> >
> >
> >       >       >     Can Traffic Management Settings be configured
> >       for TCP
> >
> >       >       protocols other than HTTP?
> >
> >
> >
> >
> >
> >
> >
> >       >       >     Would like to limit maximum upload and
> >       download sizes for
> >
> >       >       other TCP protocols:  SMB, NFS, FTP, and RDP.
> >
> >
> >
> >
> >
> >
> >
> >       >       >     Is this possible?  If so, how?
> >
> >
> >
> >
> >
> >
> >
> >       >       >     Thank you.
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >       >       >
> >       _______________________________________________
> >
> >
> >
> >       >       >     squid-users mailing list
> >
> >
> >
> >       >       >     squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> >
> >       >       <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> >
> >
> >
> >       >       >
> >       http://lists.squid-cache.org/listinfo/squid-users
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >
> >       >       > _______________________________________________
> >
> >
> >
> >       >       > squid-users mailing list
> >
> >
> >
> >       >       > squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> >
> >
> >
> >       >       > http://lists.squid-cache.org/listinfo/squid-users
> >
> >
> >
> >
> >
> >
> >
> >     _______________________________________________
> >     squid-users mailing list
> >     squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> >     http://lists.squid-cache.org/listinfo/squid-users
> >
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXMj6CAAoJENNXIZxhPexG4P4H/iampGAgQXQik3ZgbDwgDn22
> CNB4/KFcrv1Sdjst6b3pzko/XRpvOhuYSbJ2tUOfasP7gF5bTqUTYl1jCWxd07kA
> VXmSbY5ynM3hgHVZowiL/6wksxQyTiqNEA86ae77gDig0SWu8NbNHZ058iN/sCRn
> 9F363nYdpj4LffHYXe16XLn/lGLF3yG0kpDZI+dSVy2QS57aOisc0lADTbKvzSOJ
> RpfUfUI4EHcQoOVYlk91c6LckZGxy6N1lYEQbdCy+Y0OwM25crCaiaEuiaB8RTSi
> kKcJk16L5UFGYQiKchyUq9r73D4+0hLlloOTCJ+HwNYQzbLFPn+rTrLo6tI47pg=
> =Y3mu
> -----END PGP SIGNATURE-----
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/3c3eac22/attachment.htm>

From eliezer at ngtech.co.il  Tue May 10 20:57:20 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 10 May 2016 23:57:20 +0300
Subject: [squid-users] Can Traffic Management Settings be configured for
	other TCP protocols?
In-Reply-To: <CANUpZyyRbNR938ZHpYe2d2XCACcxepjcH6auX++E6MOwMve4cA@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
 <51d8f7ad-29c8-2f00-6b83-4483b637ef56@gmail.com>
 <CANUpZyyRbNR938ZHpYe2d2XCACcxepjcH6auX++E6MOwMve4cA@mail.gmail.com>
Message-ID: <01d601d1aafe$8b230c00$a1692400$@ngtech.co.il>

Hey,

 

You can always use a TOS from squid to mark connections and\or users and to somehow create some policy case on that.

I have used more then once the Linux "tc" to "jail" a user which was abusing his unbound bandwidth policy.

I do not like the idea but I have asked couple networking experts about the most used approach compared to the most efficient and it's seems pretty reasonable from the business aspect of networking to slow(not hog) a user.
Specifically there are places which defines the Internet as a WEB only ie port 80 and 443 and for HTTP only traffic.

For these purposes squid is great while there are other approaches to the subject.

 

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of J Green
Sent: Tuesday, May 10, 2016 8:42 PM
To: Yuri Voinov
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Can Traffic Management Settings be configured for other TCP protocols?

 

That is fair, re intended use.  But yes, management want to know if users are attempting to circumvent policy.  Re analyzing logs, I did not see this logged anywhere.  Is there perhaps a debug mode which I need to enable?

Thank you.

 

On Tue, May 10, 2016 at 10:29 AM, Yuri Voinov <yvoinov at gmail.com <mailto:yvoinov at gmail.com> > wrote:


-----BEGIN PGP SIGNED MESSAGE----- 
Hash: SHA256 
 
First, upload is PUT method usage. Most common HTTP/HTTPS is GET/HEAD methods.

Second, logging of all things is not my goal.

For me, it is sufficient that the restrictions imposed by me in accordance with the policy. The amount of downloads for my count analyzers logs, if management is interesting to read the reports independently.

10.05.16 23:25, J Green ?????:
> So back to the intended use cases for HTTP, HTTPS, & FTP , how can you log violations of maximum download/upload size?  I see an error message generated on the client system, but not w/in Squid.  Thank you.
>
> On Mon, May 9, 2016 at 10:12 AM, Yuri Voinov <yvoinov at gmail.com <mailto:yvoinov at gmail.com>   <mailto:yvoinov at gmail.com> <mailto:yvoinov at gmail.com>> wrote:
>
>
> Squid is not a proxy server every imaginable the TCP-usage protocol.
>
> AFAIK HTTP/HTTPS/FTP. That's all, folks.
>
>
> 09.05.16 23:07, J Green ?????:
> > Hello all:
>
>
>
>       > Can Traffic Management Settings be configured for TCP
>       protocols other than HTTP?
>
>
>
>       > Would like to limit maximum upload and download sizes for
>       other TCP protocols:  SMB, NFS, FTP, and RDP.
>
>
>
>       > Is this possible?  If so, how?
>
>
>
>       > Thank you.
>
>
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>   <mailto:squid-users at lists.squid-cache.org> <mailto:squid-users at lists.squid-cache.org>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>   <mailto:squid-users at lists.squid-cache.org> <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE----- 
Version: GnuPG v2 
 
iQEcBAEBCAAGBQJXMhpnAAoJENNXIZxhPexG3ZkH/RXEyeJFjGECUV7S6ebQg0SZ 
31A82FNRApaHOLZWPHYZ0u1tpyISYK2t+2ZpAI+lAuMocUtRIW6gKHIPiWP66SdZ 
xLU5PeSvEbvlncoChajChD+3SDmrlADJD7WpMfw/4RqwDZqNznKX6jLRv3ApoCwu 
JRl+6S2PQ2UARmUEEyeAJLIfZQLKI3EqyUphaVeTaO6una1RXQgavRePjU3zuVBX 
9Yw0c8cRxtTuo9GePjPsQVIn7QZTSp6EHJ9ExHiLFFi1USdf51qSpc5VKS5HpOkL 
U8wdp59yDb9fa15rrqBSFhXCTwhe5qbyDuxdOq6tozHN5BTm3zMNICv1En1dUig= 
=x2f0 
-----END PGP SIGNATURE----- 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/8d724340/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/8d724340/attachment.png>

From yvoinov at gmail.com  Tue May 10 21:22:09 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 May 2016 03:22:09 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZyyBzJVAdPDUp6i_PBhMJY4vMMXj5Myzibsmew-xD4J_3Q@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <CALKvBnaa06XU+jh19vNZOzZEskqsQWJ=VXTK96Jjv76t987L1A@mail.gmail.com>
 <53976a17-fbd5-9459-b4da-da4250d25f9d@gmail.com>
 <b378ae1f-eb4c-5432-2fe3-89c0c29a7880@gmail.com>
 <CANUpZyw+-DiAC93rzijTTk9+bGMi1pnXEYp2RnAA7U5AZ+j68w@mail.gmail.com>
 <126efe66-beff-4ece-ad86-31e8c615a7f9@gmail.com>
 <CANUpZyyBzJVAdPDUp6i_PBhMJY4vMMXj5Myzibsmew-xD4J_3Q@mail.gmail.com>
Message-ID: <4155c941-17fd-d1a0-b702-6ff311a743df@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


11.05.16 2:11, J Green ?????:
> Fair criticisms, yes.  But an interesting problem, no?   And I think I am close to getting something
somewhat functional, using various pieces of hardware and software.  Is
it a slick solution?  Not at all.  But it just might work more or less. 
Small could be 10MB.  Large is larger.

Yes, this is interesting and a bit complex problem.

In many cases it is necessary to formulate a different formulation of
the problem, or to use a variety of tools.

By the way, today there is no satisfactory solution to the open source
software for access control and accounting is based on it to be used in
conjunction with a SQUID. SAMS has long abandoned. New solutions I
personally have not seen.

>
> On Tue, May 10, 2016 at 1:03 PM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> I think change is posing the problem. "Big" and "small", it seems to
me, is too vague a criterion. Plus direct solution assumes continious
control of each connection at all and accounting at all. What, in my
opinion, a bit crazy.
>
> 11.05.16 1:59, J Green ?????:
> > From what I understand, it is
>       traffic policing, as opposed to traffic shaping.
>
>
>
>       > The goal is to block transfer of large files over various TCP
>       protocols, while allowing small files.
>
>
>
>       > Thank you all, for your input.
>
>
>
>
>
>
>
>       > On Tue, May 10, 2016 at 12:55 PM, Yuri Voinov
>       <yvoinov at gmail.com <mailto:yvoinov at gmail.com>
<mailto:yvoinov at gmail.com> <mailto:yvoinov at gmail.com>> wrote:
>
>
>
>
>
>       > And, incidentally, smoke manuals - Cisco either enables
>       traffic shaping or limit the speed on ports, protocols, networks,
>       clients and so on. :) As you wish. :)
>
>
>
>       > Its possibilities are limited only version of the software
>       platform, and your ability to smoke manuals. :)
>
>
>
>       > 11.05.16 1:49, Yuri Voinov ?????:
>
>
>
>
>
>
>
>       >       > You can not pull the owl on the globe. )
>
>
>
>
>
>
>
>       >       > By the way, I'm not sure what he was trying to
>       achieve this
>
>       >       :)
>
>
>
>
>
>
>
>
>
>
>
>       >       > 11.05.16 1:45, Adam W. Dace ?????:
>
>
>
>       >       > > Back in the day, I used
>
>
>
>       >       >       "traffic shaping" on the Cisco router to
>       achieve that
>
>       >       sort of
>
>
>
>       >       >       thing.  It actually changes the traffic to
>       fit your
>
>       >       Internet link,
>
>
>
>       >       >       versus limiting per-connection speed.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > Still, this is off-topic.  Anyways,
>       consult your
>
>       >       CIOS
>
>
>
>       >       >       documentation and good luck!  :)
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > Regards,
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > Adam
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > On Mon, May 9, 2016 at 12:07 PM J Green
>
>
>
>       >       >       <corpengineer at gmail.com
<mailto:corpengineer at gmail.com>
>       <mailto:corpengineer at gmail.com> <mailto:corpengineer at gmail.com>
>
>
>
>       >       >       <mailto:corpengineer at gmail.com>
<mailto:corpengineer at gmail.com>
>       <mailto:corpengineer at gmail.com> <mailto:corpengineer at gmail.com>>
wrote:
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >     Hello all:
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >     Can Traffic Management Settings be
>       configured
>
>       >       for TCP
>
>
>
>       >       >       protocols other than HTTP?
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >     Would like to limit maximum upload
>       and
>
>       >       download sizes for
>
>
>
>       >       >       other TCP protocols:  SMB, NFS, FTP, and
>       RDP.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >     Is this possible?  If so, how?
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >     Thank you.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >   
>
>       >       _______________________________________________
>
>
>
>
>
>
>
>       >       >       >     squid-users mailing list
>
>
>
>
>
>
>
>       >       >       >     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>       <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>
>
>       >       >     
>       <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>       <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>
>
>
>
>
>
>       >       >       >   
>
>       >       http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >
>       _______________________________________________
>
>
>
>
>
>
>
>       >       >       > squid-users mailing list
>
>
>
>
>
>
>
>       >       >       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>       <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>
>
>
>
>
>
>       >       >       >
>       http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >     _______________________________________________
>
>       >     squid-users mailing list
>
>       >     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>       <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>       >     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMlEBAAoJENNXIZxhPexGNYUIAItaiZt06/Ejkk50gCaXSS4s
rH8JbCqyC3rOYj+3iIN+fcGU9ovMi/9JazRQHkLlixMmUfgS33DK6zlpOJN1aHc9
KMbQ7qhIzzVtGWxYzPwTGq6KL69On/vYVUAYgDCeR+nqTKeO4zixU7Di3iU8MIK7
kZh7aFTbh8wfGeQiSu/jUh67KKaGHG1aTe1QF+9O7beYM90gE+uiX+I8l+vb24Mr
r83F8nNbdkKxKK3hqIiLgt5Zujx3DNM3VXsHo8L408hcxR6Hkd/VbDn6wnJD4q/O
zUPMJGD94ufJuwjCVtTRmNmdNaXjycbAyYRBnL9FSonQESo2obug0Qn/1gZ/+KY=
=Yb6z
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/3a6f9f7d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/3a6f9f7d/attachment.key>

From yvoinov at gmail.com  Tue May 10 21:23:17 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 May 2016 03:23:17 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <01d601d1aafe$8b230c00$a1692400$@ngtech.co.il>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
 <51d8f7ad-29c8-2f00-6b83-4483b637ef56@gmail.com>
 <CANUpZyyRbNR938ZHpYe2d2XCACcxepjcH6auX++E6MOwMve4cA@mail.gmail.com>
 <01d601d1aafe$8b230c00$a1692400$@ngtech.co.il>
Message-ID: <cc65f5ea-20a6-9dcc-6aac-f5057df161a1@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


11.05.16 2:57, Eliezer Croitoru ?????:
>
> Hey,
>
> 
>
> You can always use a TOS from squid to mark connections and\or users
and to somehow create some policy case on that.

Sure, Eliezer. I've forgot about TOS. Good point.
>
> I have used more then once the Linux "tc" to "jail" a user which was
abusing his unbound bandwidth policy.
>
> I do not like the idea but I have asked couple networking experts
about the most used approach compared to the most efficient and it's
seems pretty reasonable from the business aspect of networking to
slow(not hog) a user.
> Specifically there are places which defines the Internet as a WEB only
ie port 80 and 443 and for HTTP only traffic.
>
> For these purposes squid is great while there are other approaches to
the subject.
>
> 
>
> Eliezer
>
> 
>
> ----
>
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
> 
>
> *From:*squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
*On Behalf Of *J Green
> *Sent:* Tuesday, May 10, 2016 8:42 PM
> *To:* Yuri Voinov
> *Cc:* squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Can Traffic Management Settings be
configured for other TCP protocols?
>
> 
>
> That is fair, re intended use.  But yes, management want to know if
users are attempting to circumvent policy.  Re analyzing logs, I did not
see this logged anywhere.  Is there perhaps a debug mode which I need to
enable?
>
> Thank you.
>
> 
>
> On Tue, May 10, 2016 at 10:29 AM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
> First, upload is PUT method usage. Most common HTTP/HTTPS is GET/HEAD
methods.
>
> Second, logging of all things is not my goal.
>
> For me, it is sufficient that the restrictions imposed by me in
accordance with the policy. The amount of downloads for my count
analyzers logs, if management is interesting to read the reports
independently.
>
> 10.05.16 23:25, J Green ?????:
> > So back to the intended use cases for HTTP, HTTPS, & FTP , how can
you log violations of maximum download/upload size?  I see an error
message generated on the client system, but not w/in Squid.  Thank you.
>
> > On Mon, May 9, 2016 at 10:12 AM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com> <mailto:yvoinov at gmail.com>
<mailto:yvoinov at gmail.com>> wrote:
>
>
> > Squid is not a proxy server every imaginable the TCP-usage protocol.
>
> > AFAIK HTTP/HTTPS/FTP. That's all, folks.
>
>
> > 09.05.16 23:07, J Green ?????:
> > > Hello all:
>
>
>
> >       > Can Traffic Management Settings be configured for TCP
> >       protocols other than HTTP?
>
>
>
> >       > Would like to limit maximum upload and download sizes for
> >       other TCP protocols:  SMB, NFS, FTP, and RDP.
>
>
>
> >       > Is this possible?  If so, how?
>
>
>
> >       > Thank you.
>
>
>
>
>
>
>
>
>
> >       > _______________________________________________
>
> >       > squid-users mailing list
>
> >       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
> >       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> >     _______________________________________________
> >     squid-users mailing list
> >     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
> >     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
> 
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXMlFEAAoJENNXIZxhPexGO6AH/RsDrJKihobs93E9OLhT7uuB
6KjX5eSfcNzYmTX1QsTn4SDf2l3HaItZ5jPuSFGSBMTuGo0RaHc0Y+YIcRO8CuOG
PQDBPXff2Vg16o06Ty78XLUAfWUr1q4uu6G5Vp8F2cLWSjk7thuFu9XoYe5Q2z1V
yN99aV/Kol+Om//eSPOf3hre3ONYRFn2lR+GJET9QNfogiRakpFOzeeGp3fXQgzA
S6n2MfhyhYRO3lDtjGcrWDoR5Tz8OdKlReuwHqtkuQi/OA95O9CpfwnEnORGLVN6
G4H0pG7MrXBbl5zRhspkr9BNvtunkFsSnUlcUhBtKj1RhsC7H9g7lvkE8QKphIU=
=kDA0
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/de24278b/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/de24278b/attachment.key>

From eliezer at ngtech.co.il  Tue May 10 21:25:05 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 11 May 2016 00:25:05 +0300
Subject: [squid-users] Would it be possible to run a http to https gateway
	using squid?
Message-ID: <020001d1ab02$6b7e0400$427a0c00$@ngtech.co.il>

I was wondering to myself, If I can generate certificates and bump the
connection, I can use a 302\308 to redirect all traffic from https to a
http(intercepatble) connection.

Then on the http interceptor rewrite the request into https.

I have a working setup which uses a redirection "attack" to authenticate
users over http+https.

Now the issue is that if all browsers will deny a redirection from https to
http(a downgrading attack) then the http world would look a bit weird.


I was thinking about such a downgrade attack on couple sites but I am unsure
how good it will be.

I have seen couple years ago that some ISPs used a redirection attack when
youtube used plain http, this was in order to allow a "pre-fetch" of a tiny
GET request.

Now since many others up-graded their security it's another story.

 

And as an addition I have seen that Microsoft use and "FTP" like transfer
protocol in their software.

They have a "secured" control channel which has certificates pinning or
something else as a safe guard,
and in more then one case they use another channel to fetch the request over
plain HTTP( when a proxy is defined).

 

Would it be reasonable to write and publish such a tool? Or is it a security
risk to publish such a tool to the public?

 

Eliezer

 

----

Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/a36b3008/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image003.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/a36b3008/attachment.png>

From corpengineer at gmail.com  Tue May 10 21:43:19 2016
From: corpengineer at gmail.com (J Green)
Date: Tue, 10 May 2016 14:43:19 -0700
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <cc65f5ea-20a6-9dcc-6aac-f5057df161a1@gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
 <51d8f7ad-29c8-2f00-6b83-4483b637ef56@gmail.com>
 <CANUpZyyRbNR938ZHpYe2d2XCACcxepjcH6auX++E6MOwMve4cA@mail.gmail.com>
 <01d601d1aafe$8b230c00$a1692400$@ngtech.co.il>
 <cc65f5ea-20a6-9dcc-6aac-f5057df161a1@gmail.com>
Message-ID: <CANUpZyzsq8UCOdsom_GBG84VOr3cYyzNpcaLxeLw-_cHg=GrzQ@mail.gmail.com>

Very interesting, thank you both.

On Tue, May 10, 2016 at 2:23 PM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
>
>
> 11.05.16 2:57, Eliezer Croitoru ?????:
> >
> > Hey,
> >
> >
> >
> > You can always use a TOS from squid to mark connections and\or users and
> to somehow create some policy case on that.
>
> Sure, Eliezer. I've forgot about TOS. Good point.
> >
> > I have used more then once the Linux "tc" to "jail" a user which was
> abusing his unbound bandwidth policy.
> >
> > I do not like the idea but I have asked couple networking experts about
> the most used approach compared to the most efficient and it's seems pretty
> reasonable from the business aspect of networking to slow(not hog) a user.
> > Specifically there are places which defines the Internet as a WEB only
> ie port 80 and 443 and for HTTP only traffic.
> >
> > For these purposes squid is great while there are other approaches to
> the subject.
> >
> >
> >
> > Eliezer
> >
> >
> >
> > ----
> >
> > Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> <http://ngtech.co.il/lmgtfy/>
> > Linux System Administrator
> > Mobile: +972-5-28704261
> > Email: eliezer at ngtech.co.il
> >
> >
> >
> > *From:*squid-users [mailto:squid-users-bounces at lists.squid-cache.org
> <squid-users-bounces at lists.squid-cache.org>] *On Behalf Of *J Green
> > *Sent:* Tuesday, May 10, 2016 8:42 PM
> > *To:* Yuri Voinov
> > *Cc:* squid-users at lists.squid-cache.org
> > *Subject:* Re: [squid-users] Can Traffic Management Settings be
> configured for other TCP protocols?
> >
> >
> >
> > That is fair, re intended use.  But yes, management want to know if
> users are attempting to circumvent policy.  Re analyzing logs, I did not
> see this logged anywhere.  Is there perhaps a debug mode which I need to
> enable?
> >
> > Thank you.
> >
> >
> >
> > On Tue, May 10, 2016 at 10:29 AM, Yuri Voinov <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com> <yvoinov at gmail.com>> wrote:
> >
> >
> > First, upload is PUT method usage. Most common HTTP/HTTPS is GET/HEAD
> methods.
> >
> > Second, logging of all things is not my goal.
> >
> > For me, it is sufficient that the restrictions imposed by me in
> accordance with the policy. The amount of downloads for my count analyzers
> logs, if management is interesting to read the reports independently.
> >
> > 10.05.16 23:25, J Green ?????:
> > > So back to the intended use cases for HTTP, HTTPS, & FTP , how can you
> log violations of maximum download/upload size?  I see an error message
> generated on the client system, but not w/in Squid.  Thank you.
> >
> > > On Mon, May 9, 2016 at 10:12 AM, Yuri Voinov <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com> <yvoinov at gmail.com> <mailto:yvoinov at gmail.com>
> <yvoinov at gmail.com> <mailto:yvoinov at gmail.com> <yvoinov at gmail.com>> wrote:
> >
> >
> > > Squid is not a proxy server every imaginable the TCP-usage protocol.
> >
> > > AFAIK HTTP/HTTPS/FTP. That's all, folks.
> >
> >
> > > 09.05.16 23:07, J Green ?????:
> > > > Hello all:
> >
> >
> >
> > >       > Can Traffic Management Settings be configured for TCP
> > >       protocols other than HTTP?
> >
> >
> >
> > >       > Would like to limit maximum upload and download sizes for
> > >       other TCP protocols:  SMB, NFS, FTP, and RDP.
> >
> >
> >
> > >       > Is this possible?  If so, how?
> >
> >
> >
> > >       > Thank you.
> >
> >
> >
> >
> >
> >
> >
> >
> >
> > >       > _______________________________________________
> >
> > >       > squid-users mailing list
> >
> > >       > squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> >
> > >       > http://lists.squid-cache.org/listinfo/squid-users
> >
> >
> >
> > >     _______________________________________________
> > >     squid-users mailing list
> > >     squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>
> <squid-users at lists.squid-cache.org>
> > >     http://lists.squid-cache.org/listinfo/squid-users
> >
> >
> >
> >
> >
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXMlFEAAoJENNXIZxhPexGO6AH/RsDrJKihobs93E9OLhT7uuB
> 6KjX5eSfcNzYmTX1QsTn4SDf2l3HaItZ5jPuSFGSBMTuGo0RaHc0Y+YIcRO8CuOG
> PQDBPXff2Vg16o06Ty78XLUAfWUr1q4uu6G5Vp8F2cLWSjk7thuFu9XoYe5Q2z1V
> yN99aV/Kol+Om//eSPOf3hre3ONYRFn2lR+GJET9QNfogiRakpFOzeeGp3fXQgzA
> S6n2MfhyhYRO3lDtjGcrWDoR5Tz8OdKlReuwHqtkuQi/OA95O9CpfwnEnORGLVN6
> G4H0pG7MrXBbl5zRhspkr9BNvtunkFsSnUlcUhBtKj1RhsC7H9g7lvkE8QKphIU=
> =kDA0
> -----END PGP SIGNATURE-----
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160510/a7e60599/attachment.htm>

From dan at getbusi.com  Wed May 11 04:37:40 2016
From: dan at getbusi.com (Dan Charlesworth)
Date: Wed, 11 May 2016 14:37:40 +1000
Subject: [squid-users] How to analyse squid memory usage
In-Reply-To: <085044c5-9a62-8b6f-47e6-cee4410dfac9@treenet.co.nz>
References: <B60DFE6C-9BA8-42CA-9B57-A2460517A35F@getbusi.com>
 <085044c5-9a62-8b6f-47e6-cee4410dfac9@treenet.co.nz>
Message-ID: <421A4120-10F7-4694-94AF-B66C3CDF1D3E@getbusi.com>

Thanks Amos -

Not sure how self-explanatory the output is, though.

I?ve attached the output from a site with a 12GB server where top was showing 2.9GB allocated to squid (this is normal e.g. ?the control"). But the mem output shows the allocated total as ~1GB, apparently?

Maybe things will become clearer once I have a ?leaky? server?s output to compare with it.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: bdc-mem.tsv
Type: text/tab-separated-values
Size: 18774 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/3f1ca643/attachment.tsv>
-------------- next part --------------


> On 10 May 2016, at 6:02 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 10/05/2016 2:35 p.m., Dan Charlesworth wrote:
>> A small percentage of deployments of our squid-based product are using oodles of memory?there doesn?t seem to be a limit to it.
>> 
>> I?m wondering what the best way might be to analyse what squid is reserving it all for in the latest 3.5 release?
>> 
>> The output of squidclient mgr:cache_mem is completely incomprehensible to me.
> 
> Try mgr:mem report. It is TSV (tab-separated values) file format.
> 
>  squidclient mgr:mem > mem.tsv
> 
> ... and load mem.tsv using your favourite spreadsheet program. The
> column titles should then be self-explanatory.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From timp87 at gmail.com  Wed May 11 05:35:38 2016
From: timp87 at gmail.com (Pavel Timofeev)
Date: Wed, 11 May 2016 08:35:38 +0300
Subject: [squid-users] Linking with *SSL
Message-ID: <CAAoTqfsUKHvo90u6KfcQf0MMHCS_xJAHO=_Pug6q2uxHM6Bzkw@mail.gmail.com>

Hi!
When we worked on squid port on FreeBSD one of the FreeBSD user
(Bernard Spil) noticed:



When working on this, I ran into another issue. Perhaps maintainer can
fix that with upstream. I've now added LIBOPENSSL_LIBS="-lcrypto
-lssl" because of configure failing in configure.ac line 1348.

> AC_CHECK_LIB(ssl,[SSL_library_init],[LIBOPENSSL_LIBS="-lssl $LIBOPENSSL_LIBS"],[AC_MSG_ERROR([library 'ssl' is required for OpenSSL])

You cannot link against libssl when not linking libcrypto as well
leading to an error with LibreSSL. This check should add -lcrypto in
addition to -lssl to pass.



Is this something someone could take a look at?


From squid3 at treenet.co.nz  Wed May 11 05:40:05 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 May 2016 17:40:05 +1200
Subject: [squid-users] Would it be possible to run a http to https
 gateway using squid?
In-Reply-To: <020001d1ab02$6b7e0400$427a0c00$@ngtech.co.il>
References: <020001d1ab02$6b7e0400$427a0c00$@ngtech.co.il>
Message-ID: <8ed68e4f-c06d-76a5-8316-2a36fcce7add@treenet.co.nz>

On 11/05/2016 9:25 a.m., Eliezer Croitoru wrote:
> I was wondering to myself, If I can generate certificates and bump the
> connection, I can use a 302\308 to redirect all traffic from https to a
> http(intercepatble) connection.
> 
> Then on the http interceptor rewrite the request into https.

What would be the point? You already had to decrypt to do the bump and
redirect.

> 
> I have a working setup which uses a redirection "attack" to authenticate
> users over http+https.
> 
> Now the issue is that if all browsers will deny a redirection from https to
> http(a downgrading attack) then the http world would look a bit weird.
> 

Not that weird. It is called HTTP Strict Transport Security (HSTS).


> 
> And as an addition I have seen that Microsoft use and "FTP" like transfer
> protocol in their software.
> 
> They have a "secured" control channel which has certificates pinning or
> something else as a safe guard,
> and in more then one case they use another channel to fetch the request over
> plain HTTP( when a proxy is defined).
> 

You will note that this is a very cache friendly way to do crypto. The
bulky part of the content is cacheable by anyone who needs to reduce
bandwith, but remains securely verifiable and integrity checked using
the off-band details.

However, it is not what you are talking about for your tool. The above
method by MS requires intentional design in the web service with
integrity checking actually performed by the endpoints.

 Under downgrade attack conditions the endpoints would not know that the
extra work was needed so one cannot assume that it is getting done. One
of the reasons browsers are so into TLS is that the transport layer does
all the verification and leaves them able to skip perceived slow
security checks at higher levels.

> 
> Would it be reasonable to write and publish such a tool? Or is it a security
> risk to publish such a tool to the public?
> 

Up to you. AIUI is illegal in most of the world to make use of it. Like
most hacking tools if used other than for permitted penetration testing
and research purposes.

Amos



From squid3 at treenet.co.nz  Wed May 11 06:30:59 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 May 2016 18:30:59 +1200
Subject: [squid-users] How to analyse squid memory usage
In-Reply-To: <421A4120-10F7-4694-94AF-B66C3CDF1D3E@getbusi.com>
References: <B60DFE6C-9BA8-42CA-9B57-A2460517A35F@getbusi.com>
 <085044c5-9a62-8b6f-47e6-cee4410dfac9@treenet.co.nz>
 <421A4120-10F7-4694-94AF-B66C3CDF1D3E@getbusi.com>
Message-ID: <ecf5502a-73c1-a39c-141f-a61db41697f7@treenet.co.nz>

On 11/05/2016 4:37 p.m., Dan Charlesworth wrote:
> Thanks Amos -
> 
> Not sure how self-explanatory the output is, though.
> 
> I?ve attached the output from a site with a 12GB server where top was showing 2.9GB allocated to squid (this is normal e.g. ?the control"). But the mem output shows the allocated total as ~1GB, apparently?
> 

That ~1GB looks like correct interpretation to me.

One thing to be aware of is that some OS allocate memory in multiples of
4KB. So objects like mem_node which are just a few bytes over use 8KB -
twice as much memory as Squid is aware of. mem_node is know to hit this
problem, other objects get pooled in larger batches so Squid use tends
to self-correct that. In this case the number of mem_node allocated does
not account for more than a tiny slice of 12 vs 1 GB difference.

Another thing is that virtual memory accounting by top etc is useless as
a metric. Squid uses fork() for its child processes, each time it forks
the virtual memory "size" gets doubled. So 12GB could just mean Squid is
running 11 helpers (1GB RAM used by Squid, 100KB by each of 11 helpers
== 1GB RAM aka. 12 x 1GB virtual memory !).

 ==> I see cbdata helper_server has 12 objects (ie 12 helpers running).
Which does almost exactly account for the 1 vs 12 scale of the
difference you see between mgr:mem and top.

NP: there are also STL objects and stuff not using Squid memory pools.
So there can be some MB of difference between mgr:mem report and
external tools. But that should not grow very big.


> Maybe things will become clearer once I have a ?leaky? server?s output to compare with it.
> 

Leaks show up in the mem report looking a lot like the ClientInfo line
in that one you provided. Objects allocated, all in use, and none or
very few savings.
 ClientInfo here is only some KB. So probably not an actual leak, but
thats how they usually show up. The same signature in a popular object
like mem_node or HttpRequest it would be a leak.

If you need to we also have a build option for embedding valgrind hooks
into Squid between the custom pool allocators and the general code. That
allows valgrind to be run and trace leaks in its normal way, unlike the
allocator OpenSSL got a bad rep from.

Amos



From info at itcrowd72.ru  Wed May 11 06:35:22 2016
From: info at itcrowd72.ru (=?UTF-8?Q?=D0=9A=D0=BE=D0=BC=D0=BF=D0=B0=D0=BD=D0=B8=D1=8F_=D0=90?= =?UTF-8?Q?=D0=B9=D0=A2=D0=B8_=D0=9A=D1=80=D0=B0=D1=83=D0=B4?=)
Date: Wed, 11 May 2016 11:35:22 +0500
Subject: [squid-users] Squid 4.0.10 https intercept
Message-ID: <1b53817243fd1ddc614d77e747613cab@itcrowd72.ru>

hi!

I use squid 4.0.10 in INTERCEPT mode. If I deny some users 
(ip-addresses) with

acl users_no_inet src "/etc/squid/ip-groups/no-inet"
http_access deny users_no_inet

ERR_ACCESS_DENIED is displayed then go to HTTP. If go to HTTPS then 
first I see browser's NET::ERR_CERT_AUTHORITY_INVALID, and then click 
"unsecure" see ERR_ACCESS_DENIED.

How to make that right display ERR_ACCESS_DENIED on HTTPS for deny user 
in Squid 4.0 ?

Sorry for my English.

My config:

#
# Recommended minimum configuration:
#

acl localnet src 192.168.1.0/24	# RFC1918 possible internal network

acl SSL_ports port 443
acl Safe_ports port 80		# http
acl Safe_ports port 21		# ftp
acl Safe_ports port 443		# https
acl Safe_ports port 70		# gopher
acl Safe_ports port 210		# wais
acl Safe_ports port 1025-65535	# unregistered ports
acl Safe_ports port 280		# http-mgmt
acl Safe_ports port 488		# gss-http
acl Safe_ports port 591		# filemaker
acl Safe_ports port 777		# multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# ??????? ?????????? HTTP
acl blocked_http dstdomain "/etc/squid/urls/block-url"
#http_access deny blocked_http
# ??????? ?????????? HTTPS (?????? URL)
acl blocked_https ssl::server_name  "/etc/squid/urls/block-url"

# ??????? ?????????? IP ?? ????????? ????
acl users_no_inet src "/etc/squid/ip-groups/no-inet"

http_port 3130
http_port 3128 intercept
https_port 3129 intercept ssl-bump options=ALL:NO_SSLv3:NO_SSLv2 
connection-auth=off cert=/etc/squid/squidCA.pem

# ?
#always_direct allow all
# ?
#sslproxy_cert_error allow all
# ?
#sslproxy_flags DONT_VERIFY_PEER

acl step1 at_step SslBump1
# ??????? ?????????? HTTPS (????? ?????????? HTTPS ??? ???, ? ???? 
?????? ???????? ????????)
ssl_bump peek step1

# ??????? ?????????? HTTPS (?????????? ?? ?????? URL)
#ssl_bump terminate blocked_https !users_trusted
#ssl_bump terminate blocked_https
# ?
#ssl_bump splice all

http_access deny users_no_inet

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

#sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB

cache_dir aufs /var/spool/squid 20000 49 256
coredump_dir /var/spool/squid
error_directory /usr/share/squid/errors/ru

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320


From o.calvano at gmail.com  Wed May 11 08:08:30 2016
From: o.calvano at gmail.com (Olivier CALVANO)
Date: Wed, 11 May 2016 10:08:30 +0200
Subject: [squid-users] Squid and AD => That' s don't work !
Message-ID: <CAJajPedyie8VBYfwR7oiW90p5so_i94wFh_TM8QrFMjddMcXyw@mail.gmail.com>

Hi

is that someone has actually used squid with ntlm AD authentication?
because it don't works really well and no there is no one who reponds to
problems, it's a shame.

there is commercial support a squid?

Regards
Olivier
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/a8b49a57/attachment.htm>

From eliezer at ngtech.co.il  Wed May 11 08:13:27 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 11 May 2016 11:13:27 +0300
Subject: [squid-users] Squid and AD => That' s don't work !
In-Reply-To: <CAJajPedyie8VBYfwR7oiW90p5so_i94wFh_TM8QrFMjddMcXyw@mail.gmail.com>
References: <CAJajPedyie8VBYfwR7oiW90p5so_i94wFh_TM8QrFMjddMcXyw@mail.gmail.com>
Message-ID: <036e01d1ab5c$ff0d55e0$fd2801a0$@ngtech.co.il>

Hey Oliver,

 

What version of AD are you trying to authenticate against?

What is the client Operating System?

The more details you will give on the system the more possible you will get an answer(in general not from me specifically..)

 

Eliezer

 

----

Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Olivier CALVANO
Sent: Wednesday, May 11, 2016 11:09 AM
To: Squid Users
Subject: [squid-users] Squid and AD => That' s don't work !

 

Hi

 

is that someone has actually used squid with ntlm AD authentication?

because it don't works really well and no there is no one who reponds to problems, it's a shame.

 

there is commercial support a squid?

 

Regards

Olivier

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/4f8d760a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11295 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/4f8d760a/attachment.png>

From Antony.Stone at squid.open.source.it  Wed May 11 08:18:31 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 11 May 2016 10:18:31 +0200
Subject: [squid-users] Squid and AD => That' s don't work !
In-Reply-To: <CAJajPedyie8VBYfwR7oiW90p5so_i94wFh_TM8QrFMjddMcXyw@mail.gmail.com>
References: <CAJajPedyie8VBYfwR7oiW90p5so_i94wFh_TM8QrFMjddMcXyw@mail.gmail.com>
Message-ID: <201605111018.31733.Antony.Stone@squid.open.source.it>

On Wednesday 11 May 2016 at 10:08:30, Olivier CALVANO wrote:

> Hi
> 
> is that someone has actually used squid with ntlm AD authentication?

Yes.

> because it don't works really well

It would be helpful if you could give us a clearer error report.

Useful information for someone to be able to help you:

 - what version of Squid are you running?
 - what platform (O/S, distro, 32/64 bit) are you running it on?
 - what version of Windows are you running AD on?
 - what version of AD are you using?
 - what problems do your users experience when they try to authenticate?

> and no there is no one who reponds to problems, it's a shame.

I see you've posted several messages to this list between November 2015 and 
April 1st this year, and you've had many replies to those messages (many from 
Amos Jeffries, the primary current developer of Squid), so I think your 
complaint that "no-one responds to problems" is quite unreasonable.

> there is commercial support a squid?

http://www.squid-cache.org/Support/services.html

By all means continue to ask here on this list - provided you give sufficient 
information, there may well be someone who can provide sufficient help.

Alternatively, as you can see, there are several opportunities for commercial 
support contracts.


Good luck,


Regards,


Antony.

-- 
I thought I had type A blood, but it turned out to be a typo.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From denizlist at denizeren.net  Wed May 11 08:19:54 2016
From: denizlist at denizeren.net (Deniz Eren)
Date: Wed, 11 May 2016 11:19:54 +0300
Subject: [squid-users] Mark outgoing connection mark same as client side mark
Message-ID: <CAHQdsZ9sN_H1R1U8CZ4ib6Xc2ArpbG86f8K+quQqGcLjx9Fqtg@mail.gmail.com>

Hi,

In my system I am using netfilter marks to shape traffic(SNAT, QoS,
etc.) however when I redirect traffic to Squid using Tproxy I lose the
mark value(obviously). I saw configuration directive qos_flow but it's
only applicable for incoming connections( some website -> squid ->
client PC), what I need is the opposite one I want to pass mark of
outgoing connections( client PC -> squid -> some website ). I want to
mark packet in mangle PREROUTING and then redirect packet to TPROXY
and after packets coming out of squid I want to use the same mark in
mangle OUTPUT or POSTROUTING chains. Is there a way to do that?

Discussed in this thread, but no solution is given:
http://www.squid-cache.org/mail-archive/squid-users/201403/0132.html

Regards,


From belle at bazuin.nl  Wed May 11 08:23:32 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 11 May 2016 10:23:32 +0200
Subject: [squid-users] Squid and AD => That' s don't work !
In-Reply-To: <CAJajPedyie8VBYfwR7oiW90p5so_i94wFh_TM8QrFMjddMcXyw@mail.gmail.com>
References: <CAJajPedyie8VBYfwR7oiW90p5so_i94wFh_TM8QrFMjddMcXyw@mail.gmail.com>
Message-ID: <vmime.5732ec04.2877.5d5c1c714a3244@ms249-lin-003.rotterdam.bazuin.nl>

Yes and it works great. 

?

My setup Debian Jessie,

Squid tested : 3.4.8 upto 3.5.19 

I use kerberos and ntlm and ldap auto in that order. 

?

Samba 4.4.3 AD DC

?

So what do you want to know? 

?

Greetz, 

?

Louis

?

?


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Olivier CALVANO
Verzonden: woensdag 11 mei 2016 10:08
Aan: Squid Users
Onderwerp: [squid-users] Squid and AD => That' s don't work !


?

Hi


?


is that someone has actually used squid with ntlm AD authentication?


because it don't works really well and no there is no one who reponds to problems, it's a shame.


?


there is commercial support a squid?


?


Regards


Olivier




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/a3a21117/attachment.htm>

From o.calvano at gmail.com  Wed May 11 08:30:51 2016
From: o.calvano at gmail.com (Olivier CALVANO)
Date: Wed, 11 May 2016 10:30:51 +0200
Subject: [squid-users] Squid and AD => That' s don't work !
In-Reply-To: <036e01d1ab5c$ff0d55e0$fd2801a0$@ngtech.co.il>
References: <CAJajPedyie8VBYfwR7oiW90p5so_i94wFh_TM8QrFMjddMcXyw@mail.gmail.com>
 <036e01d1ab5c$ff0d55e0$fd2801a0$@ngtech.co.il>
Message-ID: <CAJajPec+PRyCct6P3t2s_obFw-kZr41+y-vQmRUWiCifxaf8WA@mail.gmail.com>

Hi

Squid 3.5.17 on Centos 7.2
Windows Server 2008 R2.
Client Operating System: Windows 7



Regards
Olivier

2016-05-11 10:13 GMT+02:00 Eliezer Croitoru <eliezer at ngtech.co.il>:

> Hey Oliver,
>
>
>
> What version of AD are you trying to authenticate against?
>
> What is the client Operating System?
>
> The more details you will give on the system the more possible you will
> get an answer(in general not from me specifically..)
>
>
>
> Eliezer
>
>
>
> ----
>
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
>
> *From:* squid-users [mailto:squid-users-bounces at lists.squid-cache.org] *On
> Behalf Of *Olivier CALVANO
> *Sent:* Wednesday, May 11, 2016 11:09 AM
> *To:* Squid Users
> *Subject:* [squid-users] Squid and AD => That' s don't work !
>
>
>
> Hi
>
>
>
> is that someone has actually used squid with ntlm AD authentication?
>
> because it don't works really well and no there is no one who reponds to
> problems, it's a shame.
>
>
>
> there is commercial support a squid?
>
>
>
> Regards
>
> Olivier
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/d2d9d8fe/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11295 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/d2d9d8fe/attachment.png>

From dzaczek at sysop.cat  Wed May 11 10:43:11 2016
From: dzaczek at sysop.cat (Jacek Zaleski)
Date: Wed, 11 May 2016 06:43:11 -0400
Subject: [squid-users] Can`t cache  always TCP_MISS
Message-ID: <vIwfiejOsanU2XFGnwv-eEdHCxAW_E7F4oNyYjP1mfYd_sNblwFOzbvPAPv87aZQtJwRpX52vqkD6RiFEXdodg==@sysop.cat>

Hi
i try use squid in my centos7 in 99% request i have TCP_MISS/200

Debugging
2016/05/11 10:45:20.752 kid1| 87,3| clientStream.cc(202) clientStreamDetach: clientStreamDetach: Detaching node 0x186e1a8
2016/05/11 10:45:20.752 kid1| 87,3| clientStream.cc(287) clientStreamFree: Freeing clientStreamNode 0x186e1a8
2016/05/11 10:45:20.752 kid1| 33,3| client_side_request.cc(246) ~ClientHttpRequest: httpRequestFree: [http://...../comment_0YDv8xlTGc73vg9AR6jf5WDDmoyydKOd.jpg](http://x3.cdn03.imgwykop.pl/c3201142/comment_0YDv8xlTGc73vg9AR6jf5WDDmoyydKOd.jpg)
2016/05/11 10:45:20.752 kid1| 28,3| Checklist.cc(70) preCheck: 0x7ffc45e07fb0 checking fast ACLs
2016/05/11 10:45:20.752 kid1| 28,3| Acl.cc(158) matches: checked: (access_log daemon:/var/log/squid/access.log line) = 1
2016/05/11 10:45:20.752 kid1| 28,3| Acl.cc(158) matches: checked: access_log daemon:/var/log/squid/access.log = 1
2016/05/11 10:45:20.752 kid1| 28,3| Checklist.cc(63) markFinished: 0x7ffc45e07fb0 answer ALLOWED for match
2016/05/11 10:45:20.752 kid1| 50,3| ModDaemon.cc(172) logfile_mod_daemon_append: logfile_mod_daemon_append: daemon:/var/log/squid/access.log: appending 1 bytes
2016/05/11 10:45:20.752 kid1| 50,3| ModDaemon.cc(176) logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 0 of 32768 bytes before append
2016/05/11 10:45:20.752 kid1| 50,3| ModDaemon.cc(172) logfile_mod_daemon_append: logfile_mod_daemon_append: daemon:/var/log/squid/access.log: appending 181 bytes
2016/05/11 10:45:20.752 kid1| 50,3| ModDaemon.cc(176) logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 1 of 32768 bytes before append
2016/05/11 10:45:20.752 kid1| 20,3| store.cc(522) unlock: ClientHttpRequest::loggingEntry unlocking key BFEF2FA9F34CA1BA1A2D2366AC5469A6 e:=sp2DV/0x144d060*2
2016/05/11 10:45:20.752 kid1| 87,3| clientStream.cc(247) clientStreamAbort: clientStreamAbort: Aborting stream with tail 0x1891888
2016/05/11 10:45:20.752 kid1| 87,3| clientStream.cc(202) clientStreamDetach: clientStreamDetach: Detaching node 0x1891888
2016/05/11 10:45:20.752 kid1| 87,3| clientStream.cc(223) clientStreamDetach: clientStreamDetach: Calling 1 with cbdata 0x18a9b60
2016/05/11 10:45:20.752 kid1| 87,3| clientStream.cc(287) clientStreamFree: Freeing clientStreamNode 0x1891888
2016/05/11 10:45:20.752 kid1| 90,3| store_client.cc(664) storeUnregister: storeUnregister: called for 'BFEF2FA9F34CA1BA1A2D2366AC5469A6'
2016/05/11 10:45:20.752 kid1| 20,3| store_swapout.cc(356) mayStartSwapOut: already rejected
2016/05/11 10:45:20.752 kid1| 20,3| store.cc(484) lock: storeUnregister locked key BFEF2FA9F34CA1BA1A2D2366AC5469A6 e:=sp2DV/0x144d060*2
2016/05/11 10:45:20.752 kid1| 90,3| store_client.cc(758) storePendingNClients: storePendingNClients: returning 0
2016/05/11 10:45:20.752 kid1| 20,3| store.cc(522) unlock: storeUnregister unlocking key BFEF2FA9F34CA1BA1A2D2366AC5469A6 e:=sp2DV/0x144d060*2
2016/05/11 10:45:20.752 kid1| 20,3| store.cc(522) unlock: clientReplyContext::removeStoreReference unlocking key BFEF2FA9F34CA1BA1A2D2366AC5469A6 e:=sp2DV/0x144d060*1
2016/05/11 10:45:20.752 kid1| 90,3| store_client.cc(758) storePendingNClients: storePendingNClients: returning 0
2016/05/11 10:45:20.752 kid1| 33,3| client_side.cc(1611) keepaliveNextRequest: local=10.150.22.235:3121 remote=10.150.21.23:53074 FD 11 flags=1: calling conn->readNextRequest()
2016/05/11 10:45:20.752 kid1| 5,3| comm.cc(553) commSetConnTimeout: local=10.150.22.235:3121 remote=10.150.21.23:53074 FD 11 flags=1 timeout 120

My config pats

cache dir :
98 cache_mem 800 MB
99 logfile_rotate 10
100 memory_pools off
101 minimum_object_size 0 bytes
102 maximum_object_size 200 MB
103 maximum_object_size_in_memory 512 KB
104 #quick_abort_min 0 KB
105 #quick_abort_max 0 KB
106 log_icp_queries off
107 client_db off
108 buffered_logs on
109 half_closed_clients off
110 cache_log /var/log/squid/cache1.log
111
112 # Uncomment and adjust the following to add a disk cache directory.
113 cache_dir aufs /squid-cache 65536 128 256 min-size=512000
114
115 # Leave coredumps in the first cache dir
116 coredump_dir /var/spool/squid
117
118 #error_directory /usr/share/nginx/404site
119 #Special Options for 0365
120 forward_max_tries 25
121 #



patterns :

124 refresh_pattern ^ftp: 1440 20% 10080
125 refresh_pattern ^gopher: 1440 0% 1440
126 refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
127 refresh_pattern -i \.(gif|png|jpg|jpeg|ico)$ 10080 90% 160000 override-expire ignore-no-cache ignore-no-store ignore-private
128 refresh_pattern -i \.(iso|avi|wav|mp3|mp4|mpeg|swf|flv|x-flv)$ 43200 90% 160000 override-expire ignore-no-cache ignore-no-store ignore-private
129 refresh_pattern -i \.(deb|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff)$ 10080 90% 160000 override-expire ignore-no-cache ignore-no-store ignore-private
130 refresh_pattern -i \.index.(html|htm)$ 0 40% 10080
131 refresh_pattern . 600 40% 40320 ignore-no-store override-expire
132 cache allow all
133 cache_effective_user squid
134 cache_effective_group squid
135 ## allow replies to client requests
136 http_reply_access allow all
Sent from [ProtonMail](https://protonmail.ch), encrypted email based in Switzerland.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/4392dc81/attachment.htm>

From squid3 at treenet.co.nz  Wed May 11 11:43:52 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 May 2016 23:43:52 +1200
Subject: [squid-users] Squid 4.0.10 https intercept
In-Reply-To: <1b53817243fd1ddc614d77e747613cab@itcrowd72.ru>
References: <1b53817243fd1ddc614d77e747613cab@itcrowd72.ru>
Message-ID: <542c7b43-0288-2356-f5e7-95615491805e@treenet.co.nz>

On 11/05/2016 6:35 p.m., ???????? ???? ????? wrote:
> hi!
> 
> I use squid 4.0.10 in INTERCEPT mode. If I deny some users
> (ip-addresses) with
> 
> acl users_no_inet src "/etc/squid/ip-groups/no-inet"
> http_access deny users_no_inet
> 
> ERR_ACCESS_DENIED is displayed then go to HTTP. If go to HTTPS then
> first I see browser's NET::ERR_CERT_AUTHORITY_INVALID, and then click
> "unsecure" see ERR_ACCESS_DENIED.
> 
> How to make that right display ERR_ACCESS_DENIED on HTTPS for deny user
> in Squid 4.0 ?
> 

What you describe above is correct behaviour. The browser does not trust
your proxy's CA.

The only way to get around the browser warning about TLS security issue
is to install the CA used by the proxy into the browser trusted CA set.

Amos



From squid3 at treenet.co.nz  Wed May 11 11:53:57 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 11 May 2016 23:53:57 +1200
Subject: [squid-users] Mark outgoing connection mark same as client side
 mark
In-Reply-To: <CAHQdsZ9sN_H1R1U8CZ4ib6Xc2ArpbG86f8K+quQqGcLjx9Fqtg@mail.gmail.com>
References: <CAHQdsZ9sN_H1R1U8CZ4ib6Xc2ArpbG86f8K+quQqGcLjx9Fqtg@mail.gmail.com>
Message-ID: <48cee11c-bcfe-ef83-086a-9d0d95c8600d@treenet.co.nz>

On 11/05/2016 8:19 p.m., Deniz Eren wrote:
> Hi,
> 
> In my system I am using netfilter marks to shape traffic(SNAT, QoS,
> etc.) however when I redirect traffic to Squid using Tproxy I lose the
> mark value(obviously).

Not obvious at all. The MARK vaue is available to Squid, and if
configured to look it up Squid should be doing so.

> I saw configuration directive qos_flow but it's
> only applicable for incoming connections( some website -> squid ->
> client PC), what I need is the opposite one I want to pass mark of
> outgoing connections( client PC -> squid -> some website ). I want to
> mark packet in mangle PREROUTING and then redirect packet to TPROXY
> and after packets coming out of squid I want to use the same mark in
> mangle OUTPUT or POSTROUTING chains. Is there a way to do that?
> 

tcp_outgoing_mark or qos_flows mark.

The problem you will find however is that HTTP is both stateless and
multiplexing. One incoming request may generate zero or several outgoing
requests. The outbound connection may also be shared by several requests
with differnet incoming connection MARK values.

So you need to design your system not to rely on an outbound connection
existing, and to handle MARK being changed mid-connection.

Amos



From belle at bazuin.nl  Wed May 11 12:02:26 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 11 May 2016 14:02:26 +0200
Subject: [squid-users] Squid and AD => That' s don't work !
In-Reply-To: <CAJajPed_+Un4FfxgpMxrw+NobEwjVhpMWY+nJs_6Rhqg9N+7KQ@mail.gmail.com>
References: <vmime.5732ec04.2877.5d5c1c714a3244@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <vmime.57331f52.2fe4.7bbe6f3e13794f72@ms249-lin-003.rotterdam.bazuin.nl>

Ok, well. Its not only the squid conf you need, so here is what you need in total. 

https, yes works to, but im dont use sslbump etc. 

?

below is all based on debian packages 0 source installs are used. 

( if you need squid 3.5.19 in debian jessie amd64 i can share them to, ssl is enabled in my build ) 

Read through is, see what you can use, and mail if you dont get it. 

?

Below works as of debian 3.4.8 up to 3.5.19 ( tested ) 

?

Squid: 

This is what i have in the auth lines : 

?

auth_param negotiate program /usr/lib/squid/negotiate_wrapper_auth \

??? --kerberos /usr/lib/squid/negotiate_kerberos_auth -s HTTP/proxy1.internal.domain.tld at REALM \

??? --ntlm /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp --domain=NTDOMAIN

?

auth_param negotiate children 50 startup=10 idle=1

auth_param negotiate keep_alive on 

?

auth_param basic program /usr/lib/squid/basic_ldap_auth -R -v 3 \

??? -b "ou=Company,dc=internal,dc=domain,dc=tld" \

??? -D ldap-bind at internal.domain.tld \

??? -W /etc/squid/private/ldap-bind \

??? -f sAMAccountName=%s \

??? -H ldaps://ad-dc2.internal.domain.tld \

??? -H ldaps://ad-dc1.internal.domain.tld

?

auth_param basic children 5 startup=5 idle=1

auth_param basic realm Internet Proxy Auth

auth_param basic credentialsttl 2 hours

?

?

The samba smb.conf im using with it. 

About samba, last update is a complex one, you must configure this correctly for samba and ldap. 

I?ll explain that below. 

?

[global]

??? workgroup = NTDOMAIN

??? security = ads

??? realm = REALM

?

??? netbios name = PROXY

??? preferred master = no

??? domain master = no

??? host msdfs = no

?

??? dns proxy = yes

?

??? server signing = mandatory

??? ntlm auth = no

?

??? #Add and Update TLS Key

??? tls enabled = yes

??? tls keyfile = /etc/ssl/local/private/proxy.key.pem

??? tls certfile = /etc/ssl/local/certs/proxy.cert.pem

??? tls cafile = /etc/ssl/certs/personal-ca.pem

?

??? ## map id's outside to domain to tdb files.

??? idmap config *:backend = tdb

??? idmap config *:range = 2000-9999

?

??? ## map ids from the domain? the range may not overlap !

??? idmap config NTDOMAIN : backend = ad

??? idmap config NTDOMAIN : schema_mode = rfc2307

??? idmap config NTDOMAIN : range = 10000-3999999

?

??? dedicated keytab file = /etc/krb5.keytab

??? kerberos method = secrets and keytab

?

??? # renew the kerberos ticket

??? winbind refresh tickets = yes

?

??? # Use home directory and shell information from AD

??? winbind nss info = rfc2307

?

??? winbind trusted domains only = no

??? winbind use default domain = yes

?

??? winbind enum users? = yes

??? winbind enum groups = yes

?

??? # enable offline logins

??? winbind offline logon = yes

?

??? # check depth of nested groups, ! slows down you samba, if to much groups depth

??? winbind expand groups = 4

?

??? # disable usershares creating, when set empty no error log messages.

??? usershare path =

?

??? # Disable printing completely

??? load printers = no

??? printing = bsd

??? printcap name = /dev/null

??? disable spoolss = yes

?

the krb5.conf for this: 

[libdefaults]

??? default_realm = REALM

??? dns_lookup_kdc = true

??? dns_lookup_realm = false

??? ticket_lifetime = 24h

??? ccache_type = 4

?

; for Windows 2003

;??? default_tgs_enctypes = rc4-hmac des-cbc-crc des-cbc-md5

;??? default_tkt_enctypes = rc4-hmac des-cbc-crc des-cbc-md5

;??? permitted_enctypes = rc4-hmac des-cbc-crc des-cbc-md5

?

; for Windows 2008 with AES

;??? default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5

; ???default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5

;??? permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc des-cbc-md5

?

?

For /etc/ldap/ldap.conf ( client conf )

?

A ?correcty? ca-root and client certs setup. Needed for samba and ldap clients 

?

Add in /etc/ldap/ldap.conf ( minimal )

TLS_CACERT????? /etc/ssl/certs/ca-certificates.crt

TLS_REQCERT allow

?

Setup your own "rootCA" like this.

?

( if not done, apt-get install ca-certificates )

?

?

?

mkdir -p /usr/local/share/ca-certificates/yourCArootFolder 

copy your root CA cert (.crt or it wont be detected) ?in /usr/local/share/ca-certificates/yourCArootFolder 

run : update-ca-certificates

?

! MUST BE /usr/local/share/ca-certificates else its not picked up with the update-ca-certificates command.

?

you should see:

update-ca-certificates

Updating certificates in /etc/ssl/certs... 1 added, 0 removed; done.

Running hooks in /etc/ca-certificates/update.d....done.

?

?

Now after done above your CA Cert is hashed in /etc/ssl/certs

And its added in /etc/ssl/certs/ca-certificates.crt

?

For windows, now setup a GPO to deploy the rootCa to your pc's and your good to go. 

How : 

https://technet.microsoft.com/nl-nl/library/cc770315(v=ws.10).aspx 

?

This folder : /etc/ssl/local is adviced for your personal certificates. 

Try to avoid mixing personal/(un)official certificates in /etc/ssl/certs.

?

So create a folders 

/etc/ssl/local/certs

/etc/ssl/local/private

Much easier to maintain this way. 

?

?

Some advice on samba/winbind. 

?

Above only needs winbind installed and i do advice 4.4.3 recompile it from debian SID.

Of if your on debian jessie amd64, you can use my deb files. 

Found here ?http://downloads.van-belle.nl/samba4/

Please do read the README.txt 

?

?

Greetz, 

?

Louis

?

?


Van: Olivier CALVANO [mailto:o.calvano at gmail.com] 
Verzonden: woensdag 11 mei 2016 13:34
Aan: L.P.H. van Belle
Onderwerp: Re: [squid-users] Squid and AD => That' s don't work !


?

Hi

?


thanks for your answer.?


Https work too ?


?


because before we use 3.3.8 but NTLM/Kerberos?walking randomly, that's work very good 1 or 2 days but after


a lot of user can't connect.


?


We update in 3.5.x and now, all https don't work :<


?


can you help me ? if you have a sample of your squid.conf


?


regards


olivier



?

2016-05-11 10:23 GMT+02:00 L.P.H. van Belle <belle at bazuin.nl>:

Yes and it works great. 

?

My setup Debian Jessie,

Squid tested : 3.4.8 upto 3.5.19 

I use kerberos and ntlm and ldap auto in that order. 

?

Samba 4.4.3 AD DC

?

So what do you want to know? 

?

Greetz, 

?

Louis

?

?


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Olivier CALVANO
Verzonden: woensdag 11 mei 2016 10:08
Aan: Squid Users
Onderwerp: [squid-users] Squid and AD => That' s don't work !


?

Hi


?


is that someone has actually used squid with ntlm AD authentication?


because it don't works really well and no there is no one who reponds to problems, it's a shame.


?


there is commercial support a squid?


?


Regards


Olivier









_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


?



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/9f84d7b8/attachment.htm>

From denizlist at denizeren.net  Wed May 11 12:21:11 2016
From: denizlist at denizeren.net (Deniz Eren)
Date: Wed, 11 May 2016 15:21:11 +0300
Subject: [squid-users] Fwd: Mark outgoing connection mark same as client
	side mark
In-Reply-To: <CAHQdsZ9Xr1mBcE8kU7AE7Wday9xykxzRfbB1W7qwRpvEvxLboA@mail.gmail.com>
References: <CAHQdsZ9sN_H1R1U8CZ4ib6Xc2ArpbG86f8K+quQqGcLjx9Fqtg@mail.gmail.com>
 <48cee11c-bcfe-ef83-086a-9d0d95c8600d@treenet.co.nz>
 <CAHQdsZ9Xr1mBcE8kU7AE7Wday9xykxzRfbB1W7qwRpvEvxLboA@mail.gmail.com>
Message-ID: <CAHQdsZ_J580sndVQO_DBPoiw-PU1+g7yTZgihzOMgqxwzVq3jA@mail.gmail.com>

> On 11/05/2016 8:19 p.m., Deniz Eren wrote:
>> Hi,
>>
>> In my system I am using netfilter marks to shape traffic(SNAT, QoS,
>> etc.) however when I redirect traffic to Squid using Tproxy I lose the
>> mark value(obviously).
>
> Not obvious at all. The MARK vaue is available to Squid, and if
> configured to look it up Squid should be doing so.
>
By saying obviously I meant that if squid doesn't mark the packet its
not available in OUTPUT chain.

>> I saw configuration directive qos_flow but it's
>> only applicable for incoming connections( some website -> squid ->
>> client PC), what I need is the opposite one I want to pass mark of
>> outgoing connections( client PC -> squid -> some website ). I want to
>> mark packet in mangle PREROUTING and then redirect packet to TPROXY
>> and after packets coming out of squid I want to use the same mark in
>> mangle OUTPUT or POSTROUTING chains. Is there a way to do that?
>>
>
> tcp_outgoing_mark or qos_flows mark.
http://www.squid-cache.org/Doc/config/qos_flows/
"to mark outgoing connections to the client, based on where the reply
was sourced."
>From here I understand that marking process is like this:
Web Site -> |  -> mark -> squid -> mark -> | -> Client PC
And in my tests I saw this behavior, the opposite did not work. Is the
opposite one possible:
ClientPC -> |  -> mark -> squid -> mark -> | -> Web Site

>
> The problem you will find however is that HTTP is both stateless and
> multiplexing. One incoming request may generate zero or several outgoing
> requests. The outbound connection may also be shared by several requests
> with differnet incoming connection MARK values.
Do you mean two sources A,B going both to C can share same outgoing
connection? Is there a way to change this behavior?

>
> So you need to design your system not to rely on an outbound connection
> existing, and to handle MARK being changed mid-connection.
>

> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Wed May 11 12:30:08 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 May 2016 00:30:08 +1200
Subject: [squid-users] Can`t cache always TCP_MISS
In-Reply-To: <vIwfiejOsanU2XFGnwv-eEdHCxAW_E7F4oNyYjP1mfYd_sNblwFOzbvPAPv87aZQtJwRpX52vqkD6RiFEXdodg==@sysop.cat>
References: <vIwfiejOsanU2XFGnwv-eEdHCxAW_E7F4oNyYjP1mfYd_sNblwFOzbvPAPv87aZQtJwRpX52vqkD6RiFEXdodg==@sysop.cat>
Message-ID: <67d499ba-901f-cc05-1cf7-04279191c815@treenet.co.nz>

On 11/05/2016 10:43 p.m., Jacek Zaleski wrote:
> Hi
> i try use squid in my centos7 in 99% request i have TCP_MISS/200
> 
> Debugging

NP: the debug log snippet you posted contains nothing relevant to the
issue described.
Please configure:
  debug_options ALL,1 20,2

and look for lines "checkCachable" and stating why each objects is not
stored.


> My config pats
> 
> cache dir :
> 98 cache_mem 800 MB
> 99 logfile_rotate 10
> 100 memory_pools off
> 101 minimum_object_size 0 bytes
> 102 maximum_object_size 200 MB
> 103 maximum_object_size_in_memory 512 KB
> 104 #quick_abort_min 0 KB
> 105 #quick_abort_max 0 KB
> 106 log_icp_queries off
> 107 client_db off
> 108 buffered_logs on
> 109 half_closed_clients off
> 110 cache_log /var/log/squid/cache1.log
> 111
> 112 # Uncomment and adjust the following to add a disk cache directory.
> 113 cache_dir aufs /squid-cache 65536 128 256 min-size=512000
> 114
> 115 # Leave coredumps in the first cache dir
> 116 coredump_dir /var/spool/squid
> 117
> 118 #error_directory /usr/share/nginx/404site
> 119 #Special Options for 0365
> 120 forward_max_tries 25
> 121 #
> 
> 
> 
> patterns :
> 
> 124 refresh_pattern ^ftp: 1440 20% 10080
> 125 refresh_pattern ^gopher: 1440 0% 1440
> 126 refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
> 127 refresh_pattern -i \.(gif|png|jpg|jpeg|ico)$ 10080 90% 160000 override-expire ignore-no-cache ignore-no-store ignore-private
> 128 refresh_pattern -i \.(iso|avi|wav|mp3|mp4|mpeg|swf|flv|x-flv)$ 43200 90% 160000 override-expire ignore-no-cache ignore-no-store ignore-private
> 129 refresh_pattern -i \.(deb|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff)$ 10080 90% 160000 override-expire ignore-no-cache ignore-no-store ignore-private
> 130 refresh_pattern -i \.index.(html|htm)$ 0 40% 10080
> 131 refresh_pattern . 600 40% 40320 ignore-no-store override-expire

ignore-no-cache is obsolete. Please remove all uses of it.

ignore-no-stre and ignore-private are highly dangerous. Please also
remove those.


> 132 cache allow all
> 133 cache_effective_user squid
> 134 cache_effective_group squid
> 135 ## allow replies to client requests
> 136 http_reply_access allow all

Amos



From carlopmart at gmail.com  Wed May 11 14:41:05 2016
From: carlopmart at gmail.com (C. L. Martinez)
Date: Wed, 11 May 2016 14:41:05 +0000
Subject: [squid-users] Problems configuring Squid with C-ICAP+Squidclamav
Message-ID: <20160511144105.GA15424@beagle.bcn.sia.es>

Hi all,

 I am installing a new squid proxy server under OpenBSD 5.9 with C-ICAP+Squidclamav, and I am having some troubles. When squid start up and I request some web page, it is returning the following error:

 2016/05/11 14:22:06 kid1| essential ICAP service is down after an options fetch failure: icap://localhost:1344/squidclamav [down,!opt]
 2016/05/11 14:23:54 kid1| suspending ICAP service for too many failures

 I've read Squid's wiki page about this and I don't see any error in my config. Squid's config is:

icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_header X-Authenticated-User
icap_preview_enable on
icap_preview_size 1024
#icap_service_failure_limit -1
icap_service service_avi_req reqmod_precache icap://localhost:1344/squidclamav bypass=off
adaptation_access service_avi_req allow all
icap_service service_avi_resp respmod_precache icap://localhost:1344/squidclamav bypass=on
adaptation_access service_avi_resp allow all

 And c-icap's config is:

PidFile /var/run/c-icap/c-icap.pid
CommandsSocket /var/run/c-icap/c-icap.ctl
Timeout 300
MaxKeepAliveRequests 100
KeepAliveTimeout 600
StartServers 3
MaxServers 10
MinSpareThreads     10
MaxSpareThreads     20
ThreadsPerChild     10
MaxRequestsPerChild  0
Port 1344
TmpDir /var/tmp
MaxMemObject 131072
DebugLevel 1
Pipelining on
ModulesDir /usr/local/lib/c_icap
ServicesDir /usr/local/lib/c_icap
TemplateDir /usr/local/share/c_icap/templates/
LoadMagicFile /etc/c-icap/c-icap.magic
RemoteProxyUsers off
RemoteProxyUserHeader X-Authenticated-User
RemoteProxyUserHeaderEncoded on
acl localhost src 127.0.0.1/255.255.255.255
acl ALLREQUESTS type RESPMOD REQMOD
icap_access allow localhost ALLREQUESTS
icap_access deny all
ServerLog /var/log/c-icap/server.log
AccessLog /var/log/c-icap/access.log
Logger file_logger
Module logger sys_logger.so
Service squidclamav squidclamav.so

 Any idea what am I doing wrong?? How can I do a simple test against c-icap server from command line??

Thanks.

-- 
Greetings,
C. L. Martinez



From yvoinov at gmail.com  Wed May 11 14:47:23 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 May 2016 20:47:23 +0600
Subject: [squid-users] Problems configuring Squid with C-ICAP+Squidclamav
In-Reply-To: <20160511144105.GA15424@beagle.bcn.sia.es>
References: <20160511144105.GA15424@beagle.bcn.sia.es>
Message-ID: <5812c3e6-d051-bed5-1ba5-2dfb8feb8e89@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
First check c-icap log.


/var/log/c-icap/server.log


11.05.16 20:41, C. L. Martinez ?????:


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXM0X5AAoJENNXIZxhPexGOKgIAJps1HP2IPsh53mMfR8NLzju
7ejfDkvD6dEAZrdvbLHJDECgnvvZFRyTaH2nvucHw+yUPLOo2lPQN4L6ZcfyGwSA
2JdEHeVw9Lk5E6KB6A75XX3ayg+48eSjDryY7J2mRkrzENGfIqSwUWs8wJsLF6BW
momIIDz0Rq7wibKEY5k5TsFOY+YlTkpZrLmVCUlH6hqDEnHwImWUb6asd6eQeTmN
bAYrOSyTXOJd/Wx5t93In7AFnIXUcEAx/FAVoJMDEy+sl+49JTuV+6ElGf3aLlv9
yznMGrBEtFt+lTNlsVEfMEFBpHAfJV9GGR+iWaNKh8voXtxT8kN6InPd9DkJwro=
=BSN9
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/f3f9b2ad/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/f3f9b2ad/attachment.key>

From yvoinov at gmail.com  Wed May 11 14:47:23 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 May 2016 20:47:23 +0600
Subject: [squid-users] Problems configuring Squid with C-ICAP+Squidclamav
In-Reply-To: <20160511144105.GA15424@beagle.bcn.sia.es>
References: <20160511144105.GA15424@beagle.bcn.sia.es>
Message-ID: <1d9e1f9d-ab69-3a49-ba96-08ca0e2c7ace@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
First check c-icap log.


/var/log/c-icap/server.log


11.05.16 20:41, C. L. Martinez ?????:
> Hi all,
>
>  I am installing a new squid proxy server under OpenBSD 5.9 with
C-ICAP+Squidclamav, and I am having some troubles. When squid start up
and I request some web page, it is returning the following error:
>
>  2016/05/11 14:22:06 kid1| essential ICAP service is down after an
options fetch failure: icap://localhost:1344/squidclamav [down,!opt]
>  2016/05/11 14:23:54 kid1| suspending ICAP service for too many failures
>
>  I've read Squid's wiki page about this and I don't see any error in
my config. Squid's config is:
>
> icap_enable on
> icap_send_client_ip on
> icap_send_client_username on
> icap_client_username_header X-Authenticated-User
> icap_preview_enable on
> icap_preview_size 1024
> #icap_service_failure_limit -1
> icap_service service_avi_req reqmod_precache
icap://localhost:1344/squidclamav bypass=off
> adaptation_access service_avi_req allow all
> icap_service service_avi_resp respmod_precache
icap://localhost:1344/squidclamav bypass=on
> adaptation_access service_avi_resp allow all
>
>  And c-icap's config is:
>
> PidFile /var/run/c-icap/c-icap.pid
> CommandsSocket /var/run/c-icap/c-icap.ctl
> Timeout 300
> MaxKeepAliveRequests 100
> KeepAliveTimeout 600
> StartServers 3
> MaxServers 10
> MinSpareThreads     10
> MaxSpareThreads     20
> ThreadsPerChild     10
> MaxRequestsPerChild  0
> Port 1344
> TmpDir /var/tmp
> MaxMemObject 131072
> DebugLevel 1
> Pipelining on
> ModulesDir /usr/local/lib/c_icap
> ServicesDir /usr/local/lib/c_icap
> TemplateDir /usr/local/share/c_icap/templates/
> LoadMagicFile /etc/c-icap/c-icap.magic
> RemoteProxyUsers off
> RemoteProxyUserHeader X-Authenticated-User
> RemoteProxyUserHeaderEncoded on
> acl localhost src 127.0.0.1/255.255.255.255
> acl ALLREQUESTS type RESPMOD REQMOD
> icap_access allow localhost ALLREQUESTS
> icap_access deny all
> ServerLog /var/log/c-icap/server.log
> AccessLog /var/log/c-icap/access.log
> Logger file_logger
> Module logger sys_logger.so
> Service squidclamav squidclamav.so
>
>  Any idea what am I doing wrong?? How can I do a simple test against
c-icap server from command line??
>
> Thanks.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXM0X7AAoJENNXIZxhPexGOqwH/1WJ3K1ATlDOU+ZvtzJxZZ9m
1augL6CaAfo1GNsKnbZpRkJ+VfPceT0DKD2a9YinJEBXjdFNmicmlf52ngE6YEeE
D7v1hIyeei06b4388FIwHneCy5VKARAp87QE9jPpveg98ZXwAOMSFe7PkRwIsNnB
31DlcEO8zL5qzAY9frX3RLyFSHItukU0CQxzW/W9TdHNZyO1VF0Dtu/+9AvvOeoa
6IOQ4+HR9s+P68w3c61ju9W+BjWpqpDvQP7dxprSdyKatg2HFidBI6as9gFyZfrD
6YSygOlpeBiIfk2aL5ytG+4e94ZLOtK0PCvhqf5Z6psGmj39hG12JE9zk9IjQiE=
=ZS1D
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/d9f123f1/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/d9f123f1/attachment.key>

From yvoinov at gmail.com  Wed May 11 14:53:56 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 May 2016 20:53:56 +0600
Subject: [squid-users] Problems configuring Squid with C-ICAP+Squidclamav
In-Reply-To: <20160511144105.GA15424@beagle.bcn.sia.es>
References: <20160511144105.GA15424@beagle.bcn.sia.es>
Message-ID: <e68e0bb7-20c9-1323-b800-7b53e19bef39@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Second try to check changelog for your version squidclamav. Looks like
you are using version still support method OPTIONS redirection which you
not permit in c-icap.conf. Which is desupported in squidclamav starting
version 6.14, as described here: http://squidclamav.darold.net/news.html


11.05.16 20:41, C. L. Martinez ?????:
> Hi all,
>
>  I am installing a new squid proxy server under OpenBSD 5.9 with
C-ICAP+Squidclamav, and I am having some troubles. When squid start up
and I request some web page, it is returning the following error:
>
>  2016/05/11 14:22:06 kid1| essential ICAP service is down after an
options fetch failure: icap://localhost:1344/squidclamav [down,!opt]
>  2016/05/11 14:23:54 kid1| suspending ICAP service for too many failures
>
>  I've read Squid's wiki page about this and I don't see any error in
my config. Squid's config is:
>
> icap_enable on
> icap_send_client_ip on
> icap_send_client_username on
> icap_client_username_header X-Authenticated-User
> icap_preview_enable on
> icap_preview_size 1024
> #icap_service_failure_limit -1
> icap_service service_avi_req reqmod_precache
icap://localhost:1344/squidclamav bypass=off
> adaptation_access service_avi_req allow all
> icap_service service_avi_resp respmod_precache
icap://localhost:1344/squidclamav bypass=on
> adaptation_access service_avi_resp allow all
>
>  And c-icap's config is:
>
> PidFile /var/run/c-icap/c-icap.pid
> CommandsSocket /var/run/c-icap/c-icap.ctl
> Timeout 300
> MaxKeepAliveRequests 100
> KeepAliveTimeout 600
> StartServers 3
> MaxServers 10
> MinSpareThreads     10
> MaxSpareThreads     20
> ThreadsPerChild     10
> MaxRequestsPerChild  0
> Port 1344
> TmpDir /var/tmp
> MaxMemObject 131072
> DebugLevel 1
> Pipelining on
> ModulesDir /usr/local/lib/c_icap
> ServicesDir /usr/local/lib/c_icap
> TemplateDir /usr/local/share/c_icap/templates/
> LoadMagicFile /etc/c-icap/c-icap.magic
> RemoteProxyUsers off
> RemoteProxyUserHeader X-Authenticated-User
> RemoteProxyUserHeaderEncoded on
> acl localhost src 127.0.0.1/255.255.255.255
> acl ALLREQUESTS type RESPMOD REQMOD
> icap_access allow localhost ALLREQUESTS
> icap_access deny all
> ServerLog /var/log/c-icap/server.log
> AccessLog /var/log/c-icap/access.log
> Logger file_logger
> Module logger sys_logger.so
> Service squidclamav squidclamav.so
>
>  Any idea what am I doing wrong?? How can I do a simple test against
c-icap server from command line??
>
> Thanks.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXM0eEAAoJENNXIZxhPexGNBQH/00JYsgcaV3QzWVfG3w+mqhk
J/zdX6coYA4r+gS87uhBO8QGiDg8lg88doYYb41JnL9gkqA+6bcCxmqTzAceJMyT
G5UChZ/jvG764pkSB6xW423CqTzgvuObkm9zUS83CPMhw0rG5OMaz7iqmvZsvBAq
qZhLVWKEk1G9oG8i8okY88UPO/L6/PRvo05w1tpYFTW3vwRg1GjFSks5eatb1HZc
PZIJXA84Osh93M7fe0Xb78MCkgca2Rdjk0vMJWJZIH24OcrXZPk3o8LM3NfpS12N
HuRn6uIKPFhpSTZQOcPasKHfO7TLpdvbYcilZ+VtBZ2TZOOTo34bHvNLUh55xaI=
=uD/E
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/46c9bcd5/attachment.key>

From belle at bazuin.nl  Wed May 11 15:04:37 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 11 May 2016 17:04:37 +0200
Subject: [squid-users] Problems configuring Squid with C-ICAP+Squidclamav
In-Reply-To: <20160511144105.GA15424@beagle.bcn.sia.es>
References: <20160511144105.GA15424@beagle.bcn.sia.es>
Message-ID: <vmime.57334a05.13bb.1acc2823515f11d5@ms249-lin-003.rotterdam.bazuin.nl>

Hai, 

?

I reviewd your config, thing whats different in c-icap.conf compared to me.

RemoteProxyUsers off ( for you ) on for me. 

?

Whats the content of /etc/c-icap/squidclamav.conf ? 

The important part for me of the file : 

#clamd_local /var/run/clamd.socket ! change/check this

clamd_ip 127.0.0.1

clamd_port 3310

?

If you use socket make sure your rights are correct and icap is added to the clamav group. 

?

?

And my c-icap part of the squid.conf 

## Tested with Squid 3.4.8 and 3.5.x + squidclamav 6.14 and 6.15 

icap_enable on

icap_send_client_ip on

icap_send_client_username on

icap_client_username_header X-Authenticated-User

icap_persistent_connections on

icap_preview_enable on

icap_preview_size 1024

icap_service service_req reqmod_precache bypass=1 icap://127.0.0.1:1344/squidclamav

adaptation_access service_req allow all

icap_service service_resp respmod_precache bypass=1 icap://127.0.0.1:1344/squidclamav

adaptation_access service_resp allow all

?

I think you changed to much in the example. 

?

Im reffering to these in the squid.conf 

> adaptation_access service_avi_resp allow all

service_avi_resp? 

?

?

Greetz, 

?

Louis

?

?

> -----Oorspronkelijk bericht-----

> Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens

> C. L. Martinez

> Verzonden: woensdag 11 mei 2016 16:41

> Aan: squid-users at lists.squid-cache.org

> Onderwerp: [squid-users] Problems configuring Squid with C-

> ICAP+Squidclamav

> 

> Hi all,

> 

> ?I am installing a new squid proxy server under OpenBSD 5.9 with C-

> ICAP+Squidclamav, and I am having some troubles. When squid start up and I

> request some web page, it is returning the following error:

> 

> ?2016/05/11 14:22:06 kid1| essential ICAP service is down after an options

> fetch failure: icap://localhost:1344/squidclamav [down,!opt]

> ?2016/05/11 14:23:54 kid1| suspending ICAP service for too many failures

> 

> ?I've read Squid's wiki page about this and I don't see any error in my

> config. Squid's config is:

> 

> icap_enable on

> icap_send_client_ip on

> icap_send_client_username on

> icap_client_username_header X-Authenticated-User

> icap_preview_enable on

> icap_preview_size 1024

> #icap_service_failure_limit -1

> icap_service service_avi_req reqmod_precache

> icap://localhost:1344/squidclamav bypass=off

> adaptation_access service_avi_req allow all

> icap_service service_avi_resp respmod_precache

> icap://localhost:1344/squidclamav bypass=on

> adaptation_access service_avi_resp allow all

> 

> ?And c-icap's config is:

> 

> PidFile /var/run/c-icap/c-icap.pid

> CommandsSocket /var/run/c-icap/c-icap.ctl

> Timeout 300

> MaxKeepAliveRequests 100

> KeepAliveTimeout 600

> StartServers 3

> MaxServers 10

> MinSpareThreads???? 10

> MaxSpareThreads???? 20

> ThreadsPerChild???? 10

> MaxRequestsPerChild? 0

> Port 1344

> TmpDir /var/tmp

> MaxMemObject 131072

> DebugLevel 1

> Pipelining on

> ModulesDir /usr/local/lib/c_icap

> ServicesDir /usr/local/lib/c_icap

> TemplateDir /usr/local/share/c_icap/templates/

> LoadMagicFile /etc/c-icap/c-icap.magic

> RemoteProxyUsers off

> RemoteProxyUserHeader X-Authenticated-User

> RemoteProxyUserHeaderEncoded on

> acl localhost src 127.0.0.1/255.255.255.255

> acl ALLREQUESTS type RESPMOD REQMOD

> icap_access allow localhost ALLREQUESTS

> icap_access deny all

> ServerLog /var/log/c-icap/server.log

> AccessLog /var/log/c-icap/access.log

> Logger file_logger

> Module logger sys_logger.so

> Service squidclamav squidclamav.so

> 

> ?Any idea what am I doing wrong?? How can I do a simple test against c-

> icap server from command line??

> 

> Thanks.

> 

> --

> Greetings,

> C. L. Martinez

> 

> _______________________________________________

> squid-users mailing list

> squid-users at lists.squid-cache.org

> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/b7490c9d/attachment.htm>

From carlopmart at gmail.com  Wed May 11 15:04:49 2016
From: carlopmart at gmail.com (C. L. Martinez)
Date: Wed, 11 May 2016 15:04:49 +0000
Subject: [squid-users] Problems configuring Squid with C-ICAP+Squidclamav
In-Reply-To: <e68e0bb7-20c9-1323-b800-7b53e19bef39@gmail.com>
References: <20160511144105.GA15424@beagle.bcn.sia.es>
 <e68e0bb7-20c9-1323-b800-7b53e19bef39@gmail.com>
Message-ID: <20160511150449.GB15424@beagle.bcn.sia.es>

On Wed 11.May'16 at 20:53:56 +0600, Yuri Voinov wrote:
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>  
> Second try to check changelog for your version squidclamav. Looks like
> you are using version still support method OPTIONS redirection which you
> not permit in c-icap.conf. Which is desupported in squidclamav starting
> version 6.14, as described here: http://squidclamav.darold.net/news.html
> 
> 

Thanks Yuri. There is not anything relevant in c-icap's logs:

Wed May 11 14:19:24 2016, main proc, squidclamav.c(258) squidclamav_post_init_service: Wed May 11 14:19:24 2016, main proc, DEBUG squidguard not defined, good
Wed May 11 14:20:29 2016, main proc, Possibly a term signal received. Monitor process going to term all children
Wed May 11 14:20:31 2016, 10986/3923614016, squidclamav.c(273) squidclamav_close_service: Wed May 11 14:20:31 2016, 10986/3923614016, DEBUG clean all memory!
Wed May 11 14:20:31 2016, 8143/3923614016, squidclamav.c(273) squidclamav_close_service: Wed May 11 14:20:31 2016, 8143/3923614016, DEBUG clean all memory!
Wed May 11 14:20:31 2016, 9458/3923614016, squidclamav.c(273) squidclamav_close_service: Wed May 11 14:20:31 2016, 9458/3923614016, DEBUG clean all memory!
Wed May 11 14:20:31 2016, main proc, squidclamav.c(273) squidclamav_close_service: Wed May 11 14:20:31 2016, main proc, DEBUG clean all memory!
Wed May 11 14:20:55 2016, main proc, squidclamav.c(258) squidclamav_post_init_service: Wed May 11 14:20:55 2016, main proc, DEBUG squidguard not defined, good
Wed May 11 14:20:55 2016, main proc, Create shared mem, qsize=20 stat_block_size=560 childshared data:1120

 My squidclamav's version is 6.15:

bzip2-1.0.6p7       block-sorting file compressor, unencumbered
c-icap-0.4.2p1      ICAP server for use with web proxies
clamav-0.99p0       virus scanner
curl-7.47.0         get files from FTP, Gopher, HTTP or HTTPS servers
db-4.6.21p1v0       Berkeley DB package, revision 4
dnscrypt-proxy-1.6.1p0 secure communications between a DNS client and resolver
gettext-0.19.7      GNU gettext runtime libraries and programs
gmp-5.0.2p3         library for arbitrary precision arithmetic
gnutls-3.3.21       GNU Transport Layer Security library
libexecinfo-0.2p5v0 clone of backtrace facility found in the GNU libc
libffi-3.2.1p0      Foreign Function Interface
libiconv-1.14p3     character set conversion library
libidn-1.32         internationalized string handling
libltdl-2.4.2p1     GNU libtool system independent dlopen wrapper
libmilter-8.15.2    mail filter support library for sendmail
libnettle-3.2       cryptographic library
libsodium-1.0.8     library for network communications and cryptography
libtasn1-4.7        Abstract Syntax Notation One structure parser library
libxml-2.9.3        XML parsing library
nghttp2-1.6.0       library for HTTP/2
p11-kit-0.22.1p1    library for loading and enumurating of PKCS#11 modules
pcre-8.38           perl-compatible regular expression library
quirks-2.197        exceptions to pkg_add rules
squid-3.5.14        WWW and FTP proxy cache and accelerator
squidclamav-6.15    clamd-based virus scanner for c-icap
xz-5.2.2p0          LZMA compression and decompression tools

 Yes, Yes, I know, squid is outdated, but it is the default version for OpenBSD 5.9

-- 
Greetings,
C. L. Martinez


From yvoinov at gmail.com  Wed May 11 15:14:08 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 May 2016 21:14:08 +0600
Subject: [squid-users] Problems configuring Squid with C-ICAP+Squidclamav
In-Reply-To: <vmime.57334a05.13bb.1acc2823515f11d5@ms249-lin-003.rotterdam.bazuin.nl>
References: <20160511144105.GA15424@beagle.bcn.sia.es>
 <vmime.57334a05.13bb.1acc2823515f11d5@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <2f4d9530-b06c-b3e2-40b3-937e776f05ec@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 

11.05.16 21:04, L.P.H. van Belle ?????:
>
> Hai,
>
> 
>
> I reviewd your config, thing whats different in c-icap.conf compared
to me.
>
Obviously, the mindless copying and pasting the config - very bad
practice, is not it?
>
> RemoteProxyUsers off ( for you ) on for me.
>
# TAG: RemoteProxyUsers
# Format: RemoteProxyUsers onoff
# Description:
#    Set it to on if you want to use username provided by the proxy server.
#    This is the recomended way to use users in c-icap.
#    If the RemoteProxyUsers is off and c-icap configured to use users or
#    groups the internal authentication mechanism will be used.
# Default:
#    RemoteProxyUsers off
RemoteProxyUsers off

This is depending proxy configuration. And irrelevant current case.
>
> 
>
> Whats the content of /etc/c-icap/squidclamav.conf ?
>
> The important part for me of the file :
>
> #clamd_local /var/run/clamd.socket ! change/check this
>
This is OS-dependent, as obvious.
>
> clamd_ip 127.0.0.1
>
> clamd_port 3310
>
> 
>
> If you use socket make sure your rights are correct and icap is added
to the clamav group.
>
Wrong. Squid group, not clamav.
>
> 
>
> 
>
> And my c-icap part of the squid.conf
>
> ## Tested with Squid 3.4.8 and 3.5.x + squidclamav 6.14 and 6.15
>
> icap_enable on
>
> icap_send_client_ip on
>
> icap_send_client_username on
>
> icap_client_username_header X-Authenticated-User
>
> icap_persistent_connections on
>
> icap_preview_enable on
>
> icap_preview_size 1024
>
> icap_service service_req reqmod_precache bypass=1
icap://127.0.0.1:1344/squidclamav
>
> adaptation_access service_req allow all
>
> icap_service service_resp respmod_precache bypass=1
icap://127.0.0.1:1344/squidclamav
>
> adaptation_access service_resp allow all
>
> 
>
> I think you changed to much in the example.
>
> 
>
> Im reffering to these in the squid.conf
>
> > adaptation_access service_avi_resp allow all
>
> service_avi_resp?
>
> 
>
Complete squid.conf fragment:

icap_service service_avi_req reqmod_precache
icap://localhost:1344/squidclamav bypass=off
adaptation_access service_avi_req allow all
icap_service service_avi_resp respmod_precache
icap://localhost:1344/squidclamav bypass=on
adaptation_access service_avi_resp allow all

Please, PLEASE, do not make recommendation when you not understand what
does config lines means!
 
>
> Greetz,
>
> 
>
> Louis
>
> 
>
> 
>
> > -----Oorspronkelijk bericht-----
>
> > Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
Namens
>
> > C. L. Martinez
>
> > Verzonden: woensdag 11 mei 2016 16:41
>
> > Aan: squid-users at lists.squid-cache.org
>
> > Onderwerp: [squid-users] Problems configuring Squid with C-
>
> > ICAP+Squidclamav
>
> >
>
> > Hi all,
>
> >
>
> >  I am installing a new squid proxy server under OpenBSD 5.9 with C-
>
> > ICAP+Squidclamav, and I am having some troubles. When squid start up
and I
>
> > request some web page, it is returning the following error:
>
> >
>
> >  2016/05/11 14:22:06 kid1| essential ICAP service is down after an
options
>
> > fetch failure: icap://localhost:1344/squidclamav [down,!opt]
>
> >  2016/05/11 14:23:54 kid1| suspending ICAP service for too many failures
>
> >
>
> >  I've read Squid's wiki page about this and I don't see any error in my
>
> > config. Squid's config is:
>
> >
>
> > icap_enable on
>
> > icap_send_client_ip on
>
> > icap_send_client_username on
>
> > icap_client_username_header X-Authenticated-User
>
> > icap_preview_enable on
>
> > icap_preview_size 1024
>
> > #icap_service_failure_limit -1
>
> > icap_service service_avi_req reqmod_precache
>
> > icap://localhost:1344/squidclamav bypass=off
>
> > adaptation_access service_avi_req allow all
>
> > icap_service service_avi_resp respmod_precache
>
> > icap://localhost:1344/squidclamav bypass=on
>
> > adaptation_access service_avi_resp allow all
>
> >
>
> >  And c-icap's config is:
>
> >
>
> > PidFile /var/run/c-icap/c-icap.pid
>
> > CommandsSocket /var/run/c-icap/c-icap.ctl
>
> > Timeout 300
>
> > MaxKeepAliveRequests 100
>
> > KeepAliveTimeout 600
>
> > StartServers 3
>
> > MaxServers 10
>
> > MinSpareThreads     10
>
> > MaxSpareThreads     20
>
> > ThreadsPerChild     10
>
> > MaxRequestsPerChild  0
>
> > Port 1344
>
> > TmpDir /var/tmp
>
> > MaxMemObject 131072
>
> > DebugLevel 1
>
> > Pipelining on
>
> > ModulesDir /usr/local/lib/c_icap
>
> > ServicesDir /usr/local/lib/c_icap
>
> > TemplateDir /usr/local/share/c_icap/templates/
>
> > LoadMagicFile /etc/c-icap/c-icap.magic
>
> > RemoteProxyUsers off
>
> > RemoteProxyUserHeader X-Authenticated-User
>
> > RemoteProxyUserHeaderEncoded on
>
> > acl localhost src 127.0.0.1/255.255.255.255
>
> > acl ALLREQUESTS type RESPMOD REQMOD
>
> > icap_access allow localhost ALLREQUESTS
>
> > icap_access deny all
>
> > ServerLog /var/log/c-icap/server.log
>
> > AccessLog /var/log/c-icap/access.log
>
> > Logger file_logger
>
> > Module logger sys_logger.so
>
> > Service squidclamav squidclamav.so
>
> >
>
> >  Any idea what am I doing wrong?? How can I do a simple test against c-
>
> > icap server from command line??
>
> >
>
> > Thanks.
>
> >
>
> > --
>
> > Greetings,
>
> > C. L. Martinez
>
> >
>
> > _______________________________________________
>
> > squid-users mailing list
>
> > squid-users at lists.squid-cache.org
>
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXM0xAAAoJENNXIZxhPexG77QIAJ483bwvMjlcTrOZAWm40brN
dP+Kv0esWjr6o/VuIpFdY346eqxxMYZjtkIWXMZyd5ZR9qpQMOM2daeq2Payl6pJ
WAzbr0vItTm9/EiQOx4fvUABeWabwX+5T3ifazhoeurF7XdWoibRXb8VfEGVfrjg
Zjxbpow3FnqNZvkSjSpCdUPw5wnojCjq/WMHhkHh790M6PODbbq3lrEt/6Vnj5nq
2yeejXhGJZc0kXLK2Hql61qRgz8+uAMH9atorLfTrYY9yOq5VL63in8rnKN2y6ML
be8kaQB7+DAuz4nh30s5go3AgtqZAbVisoNjy7ib8MU8M6OqWHyWvXBkbzLkUlQ=
=gzb9
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/7f369669/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/7f369669/attachment.key>

From yvoinov at gmail.com  Wed May 11 15:15:20 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 May 2016 21:15:20 +0600
Subject: [squid-users] Problems configuring Squid with C-ICAP+Squidclamav
In-Reply-To: <20160511150449.GB15424@beagle.bcn.sia.es>
References: <20160511144105.GA15424@beagle.bcn.sia.es>
 <e68e0bb7-20c9-1323-b800-7b53e19bef39@gmail.com>
 <20160511150449.GB15424@beagle.bcn.sia.es>
Message-ID: <3f7fae2f-8cec-5b5c-85b2-c5b3333181c9@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
As obvious, problem in squidclamav most probably. Turn debug for
squidclamav then show log again.


11.05.16 21:04, C. L. Martinez ?????:
> On Wed 11.May'16 at 20:53:56 +0600, Yuri Voinov wrote:
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>> 
>> Second try to check changelog for your version squidclamav. Looks like
>> you are using version still support method OPTIONS redirection which you
>> not permit in c-icap.conf. Which is desupported in squidclamav starting
>> version 6.14, as described here: http://squidclamav.darold.net/news.html
>>
>>
>
> Thanks Yuri. There is not anything relevant in c-icap's logs:
>
> Wed May 11 14:19:24 2016, main proc, squidclamav.c(258)
squidclamav_post_init_service: Wed May 11 14:19:24 2016, main proc,
DEBUG squidguard not defined, good
> Wed May 11 14:20:29 2016, main proc, Possibly a term signal received.
Monitor process going to term all children
> Wed May 11 14:20:31 2016, 10986/3923614016, squidclamav.c(273)
squidclamav_close_service: Wed May 11 14:20:31 2016, 10986/3923614016,
DEBUG clean all memory!
> Wed May 11 14:20:31 2016, 8143/3923614016, squidclamav.c(273)
squidclamav_close_service: Wed May 11 14:20:31 2016, 8143/3923614016,
DEBUG clean all memory!
> Wed May 11 14:20:31 2016, 9458/3923614016, squidclamav.c(273)
squidclamav_close_service: Wed May 11 14:20:31 2016, 9458/3923614016,
DEBUG clean all memory!
> Wed May 11 14:20:31 2016, main proc, squidclamav.c(273)
squidclamav_close_service: Wed May 11 14:20:31 2016, main proc, DEBUG
clean all memory!
> Wed May 11 14:20:55 2016, main proc, squidclamav.c(258)
squidclamav_post_init_service: Wed May 11 14:20:55 2016, main proc,
DEBUG squidguard not defined, good
> Wed May 11 14:20:55 2016, main proc, Create shared mem, qsize=20
stat_block_size=560 childshared data:1120
>
>  My squidclamav's version is 6.15:
>
> bzip2-1.0.6p7       block-sorting file compressor, unencumbered
> c-icap-0.4.2p1      ICAP server for use with web proxies
> clamav-0.99p0       virus scanner
> curl-7.47.0         get files from FTP, Gopher, HTTP or HTTPS servers
> db-4.6.21p1v0       Berkeley DB package, revision 4
> dnscrypt-proxy-1.6.1p0 secure communications between a DNS client and
resolver
> gettext-0.19.7      GNU gettext runtime libraries and programs
> gmp-5.0.2p3         library for arbitrary precision arithmetic
> gnutls-3.3.21       GNU Transport Layer Security library
> libexecinfo-0.2p5v0 clone of backtrace facility found in the GNU libc
> libffi-3.2.1p0      Foreign Function Interface
> libiconv-1.14p3     character set conversion library
> libidn-1.32         internationalized string handling
> libltdl-2.4.2p1     GNU libtool system independent dlopen wrapper
> libmilter-8.15.2    mail filter support library for sendmail
> libnettle-3.2       cryptographic library
> libsodium-1.0.8     library for network communications and cryptography
> libtasn1-4.7        Abstract Syntax Notation One structure parser library
> libxml-2.9.3        XML parsing library
> nghttp2-1.6.0       library for HTTP/2
> p11-kit-0.22.1p1    library for loading and enumurating of PKCS#11 modules
> pcre-8.38           perl-compatible regular expression library
> quirks-2.197        exceptions to pkg_add rules
> squid-3.5.14        WWW and FTP proxy cache and accelerator
> squidclamav-6.15    clamd-based virus scanner for c-icap
> xz-5.2.2p0          LZMA compression and decompression tools
>
>  Yes, Yes, I know, squid is outdated, but it is the default version
for OpenBSD 5.9
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXM0yIAAoJENNXIZxhPexG77YH/ibv9rMCsxh+5opE3zcoqs1G
hNaJO4FUwl2PnPQCwYqp3CZfDYjjcNtGWZEpMh2yBcVjPtiOq764Ol+7H0Y/FWYy
lGtAr/HUmeNycTm3byZt/uEvM6c6qT4rb6bS4ZLy32xvc5rmbvVr9w9RJrwUOTYE
Xpc7HNrtfxZSh8MJA2xMtfsR5GukmG0Lw+h163vwpdQSl9NL49vyINlu32k9m2c/
hO/tkd15KRrAfEY2PiV+77QpRQ8MThg2cpffe4GZeH7PXyzNdxBKkBcIt1yYihkK
bTx8rbOOhwNIO29A5RRxiu3RppGwGNAlEp9vwWXM6XKlABvTiqgHIp4KPExZP50=
=gDRT
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/a8ff4363/attachment.key>

From yvoinov at gmail.com  Wed May 11 15:16:26 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 May 2016 21:16:26 +0600
Subject: [squid-users] Problems configuring Squid with C-ICAP+Squidclamav
In-Reply-To: <20160511150449.GB15424@beagle.bcn.sia.es>
References: <20160511144105.GA15424@beagle.bcn.sia.es>
 <e68e0bb7-20c9-1323-b800-7b53e19bef39@gmail.com>
 <20160511150449.GB15424@beagle.bcn.sia.es>
Message-ID: <d3d5a1ce-f782-ce44-fc26-292a33fcc52d@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Problem is not in squid.


11.05.16 21:04, C. L. Martinez ?????:
> On Wed 11.May'16 at 20:53:56 +0600, Yuri Voinov wrote:
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>> 
>> Second try to check changelog for your version squidclamav. Looks like
>> you are using version still support method OPTIONS redirection which you
>> not permit in c-icap.conf. Which is desupported in squidclamav starting
>> version 6.14, as described here: http://squidclamav.darold.net/news.html
>>
>>
>
> Thanks Yuri. There is not anything relevant in c-icap's logs:
>
> Wed May 11 14:19:24 2016, main proc, squidclamav.c(258)
squidclamav_post_init_service: Wed May 11 14:19:24 2016, main proc,
DEBUG squidguard not defined, good
> Wed May 11 14:20:29 2016, main proc, Possibly a term signal received.
Monitor process going to term all children
> Wed May 11 14:20:31 2016, 10986/3923614016, squidclamav.c(273)
squidclamav_close_service: Wed May 11 14:20:31 2016, 10986/3923614016,
DEBUG clean all memory!
> Wed May 11 14:20:31 2016, 8143/3923614016, squidclamav.c(273)
squidclamav_close_service: Wed May 11 14:20:31 2016, 8143/3923614016,
DEBUG clean all memory!
> Wed May 11 14:20:31 2016, 9458/3923614016, squidclamav.c(273)
squidclamav_close_service: Wed May 11 14:20:31 2016, 9458/3923614016,
DEBUG clean all memory!
> Wed May 11 14:20:31 2016, main proc, squidclamav.c(273)
squidclamav_close_service: Wed May 11 14:20:31 2016, main proc, DEBUG
clean all memory!
> Wed May 11 14:20:55 2016, main proc, squidclamav.c(258)
squidclamav_post_init_service: Wed May 11 14:20:55 2016, main proc,
DEBUG squidguard not defined, good
> Wed May 11 14:20:55 2016, main proc, Create shared mem, qsize=20
stat_block_size=560 childshared data:1120
>
>  My squidclamav's version is 6.15:
>
> bzip2-1.0.6p7       block-sorting file compressor, unencumbered
> c-icap-0.4.2p1      ICAP server for use with web proxies
> clamav-0.99p0       virus scanner
> curl-7.47.0         get files from FTP, Gopher, HTTP or HTTPS servers
> db-4.6.21p1v0       Berkeley DB package, revision 4
> dnscrypt-proxy-1.6.1p0 secure communications between a DNS client and
resolver
> gettext-0.19.7      GNU gettext runtime libraries and programs
> gmp-5.0.2p3         library for arbitrary precision arithmetic
> gnutls-3.3.21       GNU Transport Layer Security library
> libexecinfo-0.2p5v0 clone of backtrace facility found in the GNU libc
> libffi-3.2.1p0      Foreign Function Interface
> libiconv-1.14p3     character set conversion library
> libidn-1.32         internationalized string handling
> libltdl-2.4.2p1     GNU libtool system independent dlopen wrapper
> libmilter-8.15.2    mail filter support library for sendmail
> libnettle-3.2       cryptographic library
> libsodium-1.0.8     library for network communications and cryptography
> libtasn1-4.7        Abstract Syntax Notation One structure parser library
> libxml-2.9.3        XML parsing library
> nghttp2-1.6.0       library for HTTP/2
> p11-kit-0.22.1p1    library for loading and enumurating of PKCS#11 modules
> pcre-8.38           perl-compatible regular expression library
> quirks-2.197        exceptions to pkg_add rules
> squid-3.5.14        WWW and FTP proxy cache and accelerator
> squidclamav-6.15    clamd-based virus scanner for c-icap
> xz-5.2.2p0          LZMA compression and decompression tools
>
>  Yes, Yes, I know, squid is outdated, but it is the default version
for OpenBSD 5.9
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXM0zJAAoJENNXIZxhPexG7EwIAMhqaMXtyDikL4UNcr/BA2/n
nDeJGtd4uby7b7vlA1ZjZRiy7Vul5vLRtz8244Iic1u9EDw1kSZbsacHukN0AEiB
OEB7UYQlqBwJmfA7Ro51AO/9CmmW+Ixk0JNIFhF/ODst8LPnqJp2DYAT8Ii1b07O
OlxlVep92KOYL6Yw/eHbo7Sg8bDYhCOxBcIFFAiuruOqPC1xRDrYSKW1JjBuSFvE
4Gysy/PT77rCatDNye6T4LwhCCO1cbaEboK2drCJZToKpTdLpVhNM1v76sYJw0O/
acljsYZ7S4JnkUlSo7MBk4FekbBQ8aaXjLOfZnoGWU5sjoeonI4wfrhYxSYNtBI=
=tmGe
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/a91df413/attachment.key>

From yvoinov at gmail.com  Wed May 11 15:53:13 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 11 May 2016 21:53:13 +0600
Subject: [squid-users] Problems configuring Squid with C-ICAP+Squidclamav
In-Reply-To: <20160511150449.GB15424@beagle.bcn.sia.es>
References: <20160511144105.GA15424@beagle.bcn.sia.es>
 <e68e0bb7-20c9-1323-b800-7b53e19bef39@gmail.com>
 <20160511150449.GB15424@beagle.bcn.sia.es>
Message-ID: <1ffda9bc-7b95-591a-7f92-b01ec2c0e52a@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Try to increase debug level in c_icap.conf:

# TAG: DebugLevel
# Format: DebugLevel level
# Description:
#    The level of debugging information to be logged.
#    The acceptable range of levels is between 0 and 10.
# Default:
#    DebugLevel 1
DebugLevel 3

and look at c_icap server log again.


11.05.16 21:04, C. L. Martinez ?????:
> On Wed 11.May'16 at 20:53:56 +0600, Yuri Voinov wrote:
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>> 
>> Second try to check changelog for your version squidclamav. Looks like
>> you are using version still support method OPTIONS redirection which you
>> not permit in c-icap.conf. Which is desupported in squidclamav starting
>> version 6.14, as described here: http://squidclamav.darold.net/news.html
>>
>>
>
> Thanks Yuri. There is not anything relevant in c-icap's logs:
>
> Wed May 11 14:19:24 2016, main proc, squidclamav.c(258)
squidclamav_post_init_service: Wed May 11 14:19:24 2016, main proc,
DEBUG squidguard not defined, good
> Wed May 11 14:20:29 2016, main proc, Possibly a term signal received.
Monitor process going to term all children
> Wed May 11 14:20:31 2016, 10986/3923614016, squidclamav.c(273)
squidclamav_close_service: Wed May 11 14:20:31 2016, 10986/3923614016,
DEBUG clean all memory!
> Wed May 11 14:20:31 2016, 8143/3923614016, squidclamav.c(273)
squidclamav_close_service: Wed May 11 14:20:31 2016, 8143/3923614016,
DEBUG clean all memory!
> Wed May 11 14:20:31 2016, 9458/3923614016, squidclamav.c(273)
squidclamav_close_service: Wed May 11 14:20:31 2016, 9458/3923614016,
DEBUG clean all memory!
> Wed May 11 14:20:31 2016, main proc, squidclamav.c(273)
squidclamav_close_service: Wed May 11 14:20:31 2016, main proc, DEBUG
clean all memory!
> Wed May 11 14:20:55 2016, main proc, squidclamav.c(258)
squidclamav_post_init_service: Wed May 11 14:20:55 2016, main proc,
DEBUG squidguard not defined, good
> Wed May 11 14:20:55 2016, main proc, Create shared mem, qsize=20
stat_block_size=560 childshared data:1120
>
>  My squidclamav's version is 6.15:
>
> bzip2-1.0.6p7       block-sorting file compressor, unencumbered
> c-icap-0.4.2p1      ICAP server for use with web proxies
> clamav-0.99p0       virus scanner
> curl-7.47.0         get files from FTP, Gopher, HTTP or HTTPS servers
> db-4.6.21p1v0       Berkeley DB package, revision 4
> dnscrypt-proxy-1.6.1p0 secure communications between a DNS client and
resolver
> gettext-0.19.7      GNU gettext runtime libraries and programs
> gmp-5.0.2p3         library for arbitrary precision arithmetic
> gnutls-3.3.21       GNU Transport Layer Security library
> libexecinfo-0.2p5v0 clone of backtrace facility found in the GNU libc
> libffi-3.2.1p0      Foreign Function Interface
> libiconv-1.14p3     character set conversion library
> libidn-1.32         internationalized string handling
> libltdl-2.4.2p1     GNU libtool system independent dlopen wrapper
> libmilter-8.15.2    mail filter support library for sendmail
> libnettle-3.2       cryptographic library
> libsodium-1.0.8     library for network communications and cryptography
> libtasn1-4.7        Abstract Syntax Notation One structure parser library
> libxml-2.9.3        XML parsing library
> nghttp2-1.6.0       library for HTTP/2
> p11-kit-0.22.1p1    library for loading and enumurating of PKCS#11 modules
> pcre-8.38           perl-compatible regular expression library
> quirks-2.197        exceptions to pkg_add rules
> squid-3.5.14        WWW and FTP proxy cache and accelerator
> squidclamav-6.15    clamd-based virus scanner for c-icap
> xz-5.2.2p0          LZMA compression and decompression tools
>
>  Yes, Yes, I know, squid is outdated, but it is the default version
for OpenBSD 5.9
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXM1VpAAoJENNXIZxhPexG8XIH/2pBFI7tDqxYsVBppKtFGQHP
t4uZVIQ1r97FEFiIRHIYKtpsPORZvChBCJAhTm/Y9+vWwFJN5vfrxQkLLrsukqXu
YhmboRzOXu2/SvU1116O8/+XyHtDb+iY/3iXLrgFUUHcSBcrXFQCtES1iDZweKcE
tNqVS1dMKIK7bjPqoXzv4+LCAfyay1OSsNRC4Eanh5SMT7XC1Pgco2g9um6eX5zp
esN+rq4XPQOPpx/SSw95cI3/rN/nH8G/J9BGpHRQhYYm5GgWSSuVPxDWi7s85JGa
w/+pklw+8TAGAturtQIq/86vu3MWPtpMJhN5D//WKUDgiAAXIASuERSiFZFDtKg=
=9ALt
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/d529548b/attachment.key>

From rafael.akchurin at diladele.com  Wed May 11 16:15:40 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Wed, 11 May 2016 16:15:40 +0000
Subject: [squid-users] Squid 3.5.19-1 is available for Ubuntu 14.04 LTS
 (online repo ubuntu.diladele.com)
Message-ID: <VI1PR04MB13594A817BDC78B41F8659428F720@VI1PR04MB1359.eurprd04.prod.outlook.com>

Greetings everyone,



The Squid 3.5.19-1 package for Ubuntu 14.04 LTS is now available. This version is recompiled using Squid DEB source from Debian Testing with some changes required to support SSL bump / libecap3 on Ubuntu 14.04 LTS.



* Original release notes are at http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.19-RELEASENOTES.html

* The online repo is at http://ubuntu.diladele.com

* Tutorial showing how we rebuilt Squid 3.5.19 on Ubuntu 14.04 LTS http://docs.diladele.com/tutorials/build_squid_ubuntu14/index.html

* Scripts we used to build it are at https://github.com/diladele/squid-ubuntu



If you have installed previous version from this repo then please run "sudo apt-get update && sudo apt-get upgrade".  Please also check that your current squid.conf file from previous version is not overwritten.

If you are installing this version for the first time run the following commands:



    # add repo

    echo "deb http://ubuntu.diladele.com/ubuntu/ trusty main" > /etc/apt/sources.list.d/ubuntu.diladele.com.list



    # update the apt cache

   apt-get update



   # install

   apt-get install libecap3

   apt-get install squid-common

   apt-get install squid

   apt-get install squidclient



All questions/comments and suggestions are welcome at support at diladele.com<mailto:support at diladele.com> or here in the mailing list.



Best regards,

Rafael Akchurin

Diladele B.V.

http://www.quintolabs.com

http://www.diladele.com



--

Please take a look at Web Safety - our ICAP based web filter server for Squid proxy at http://www.diladele.com.




-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/bd36f81c/attachment.htm>

From heiler.bemerguy at cinbesa.com.br  Thu May 12 00:37:17 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Wed, 11 May 2016 21:37:17 -0300
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
Message-ID: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>


Hey guys,

First take a look at the log:

root at proxy:/var/log/squid# tail -f access.log |grep 
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-BR/firefox-45.0.1.complete.mar
1463011781.572   8776 10.1.3.236 TCP_MISS/206 300520 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-BR/firefox-45.0.1.complete.mar 
- HIER_DIRECT/200.216.8.9 application/octet-stream
1463011851.008   9347 10.1.3.236 TCP_MISS/206 300520 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-BR/firefox-45.0.1.complete.mar 
- HIER_DIRECT/200.216.8.32 application/octet-stream
1463011920.683   9645 10.1.3.236 TCP_MISS/206 300520 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-BR/firefox-45.0.1.complete.mar 
- HIER_DIRECT/200.216.8.9 application/octet-stream
1463012000.144  19154 10.1.3.236 TCP_MISS/206 300520 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-BR/firefox-45.0.1.complete.mar 
- HIER_DIRECT/200.216.8.32 application/octet-stream
1463012072.276  12121 10.1.3.236 TCP_MISS/206 300520 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-BR/firefox-45.0.1.complete.mar 
- HIER_DIRECT/200.216.8.32 application/octet-stream
1463012145.643  13358 10.1.3.236 TCP_MISS/206 300520 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-BR/firefox-45.0.1.complete.mar 
- HIER_DIRECT/200.216.8.32 application/octet-stream
1463012217.472  11772 10.1.3.236 TCP_MISS/206 300520 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-BR/firefox-45.0.1.complete.mar 
- HIER_DIRECT/200.216.8.32 application/octet-stream
1463012294.676  17148 10.1.3.236 TCP_MISS/206 300520 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-BR/firefox-45.0.1.complete.mar 
- HIER_DIRECT/200.216.8.32 application/octet-stream
1463012370.131  15272 10.1.3.236 TCP_MISS/206 300520 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-BR/firefox-45.0.1.complete.mar 
- HIER_DIRECT/200.216.8.32 application/octet-stream

Now think: An user is just doing a segmented/ranged download, right? 
Squid won't cache the file because it is a range-download, not a full 
file download.
But I WANT squid to cache it. So I decide to use "range_offset_limit 
-1", but then on every GET squid will re-download the file from the 
beginning, opening LOTs of simultaneous connections and using too much 
bandwidth, doing just the OPPOSITE it's meant to!

Is there a smart way to allow squid to download it from the beginning to 
the end (to actually cache it), but only on the FIRST request/get? Even 
if it makes the user wait for the full download, or cancel it 
temporarily, or.. whatever!! Anything!!

Best Regards,

-- 
Heiler Bemerguy - (91) 98151-4894
Assessor T?cnico - CINBESA (91) 3184-1751

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160511/be4f9ff0/attachment.htm>

From dan at getbusi.com  Thu May 12 01:37:43 2016
From: dan at getbusi.com (Dan Charlesworth)
Date: Thu, 12 May 2016 11:37:43 +1000
Subject: [squid-users] How to analyse squid memory usage
In-Reply-To: <421A4120-10F7-4694-94AF-B66C3CDF1D3E@getbusi.com>
References: <B60DFE6C-9BA8-42CA-9B57-A2460517A35F@getbusi.com>
 <085044c5-9a62-8b6f-47e6-cee4410dfac9@treenet.co.nz>
 <421A4120-10F7-4694-94AF-B66C3CDF1D3E@getbusi.com>
Message-ID: <E0EA512C-DC76-4D74-B95F-2635BF58C523@getbusi.com>

I?ve now got mgr:mem output from a leaky box for comparison but I?m having a hard time spotting where the problem might be.

Would anyone more experienced mind taking at these and seeing if anything jumps out as a source of the high memory usage?

  - The leaky example has 8GB of server memory and 5.7GB was allocated to squid when the snapshot was taken.

  - The normal example has 12GB of server memory and 2.9GB was allocated to Squid when the snapshot was taken.

-------------- next part --------------
A non-text attachment was scrubbed...
Name: leaky-mem.tsv
Type: text/tab-separated-values
Size: 17652 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/4a185e23/attachment.tsv>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: normal-mem.tsv
Type: text/tab-separated-values
Size: 18774 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/4a185e23/attachment-0001.tsv>
-------------- next part --------------


Thanks!

> On 11 May 2016, at 2:37 PM, Dan Charlesworth <dan at getbusi.com> wrote:
> 
> Thanks Amos -
> 
> Not sure how self-explanatory the output is, though.
> 
> I?ve attached the output from a site with a 12GB server where top was showing 2.9GB allocated to squid (this is normal e.g. ?the control"). But the mem output shows the allocated total as ~1GB, apparently?
> 
> Maybe things will become clearer once I have a ?leaky? server?s output to compare with it.
> 
> <bdc-mem.tsv>
> 
>> On 10 May 2016, at 6:02 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>> 
>> On 10/05/2016 2:35 p.m., Dan Charlesworth wrote:
>>> A small percentage of deployments of our squid-based product are using oodles of memory?there doesn?t seem to be a limit to it.
>>> 
>>> I?m wondering what the best way might be to analyse what squid is reserving it all for in the latest 3.5 release?
>>> 
>>> The output of squidclient mgr:cache_mem is completely incomprehensible to me.
>> 
>> Try mgr:mem report. It is TSV (tab-separated values) file format.
>> 
>> squidclient mgr:mem > mem.tsv
>> 
>> ... and load mem.tsv using your favourite spreadsheet program. The
>> column titles should then be self-explanatory.
>> 
>> Amos
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 


From admin at tisiz72.ru  Thu May 12 03:00:56 2016
From: admin at tisiz72.ru (admin)
Date: Thu, 12 May 2016 08:00:56 +0500
Subject: [squid-users] Squid 4.0.10 https intercept
In-Reply-To: <b5f76697-7a90-a95e-d7f6-0c4ce8ce57f2@treenet.co.nz>
References: <1b53817243fd1ddc614d77e747613cab@itcrowd72.ru>
 <542c7b43-0288-2356-f5e7-95615491805e@treenet.co.nz>
 <9d2c835fe1f622aaa5a013a07cee914f@tisiz72.ru>
 <b5f76697-7a90-a95e-d7f6-0c4ce8ce57f2@treenet.co.nz>
Message-ID: <491fa0715f007a302479eea003daac4a@tisiz72.ru>

I create cert:

openssl req -new -newkey rsa:1024 -days 365 -nodes -x509 -keyout 
squidCA.pem -out squidCA.pem

And export it:

openssl x509 -in squidCA.pem -outform DER -out squidCA.crt

Wrong?



Amos Jeffries ????? 2016-05-11 17:18:

> On 11/05/2016 11:59 p.m., admin wrote:
> 
>> I just thought! I runs the
>> 
>> openssl x509 -in squidCA.pem -outform DER -out squidCA.crt
>> 
>> import cert and now get ERR_CERT_COMMON_NAME_INVALID
>> 
>> where did I go wrong?
> 
> Hmm. I'm not sure that one is you. If it is getting past the CA trust
> check then what you did earlier was okay.
> 
> This one sounds like either the CA was generated with something for CN
> field that was not right. Or that the cert generated by Squid is broken
> in that way.
> 
> There are two reasons the Squid generated cert might be broken. In this
> order of relevance:
> 
> 1) the server the client was tryign to contact had a broken cert. Mimic
> feature in Squid will copy cert breakages so the client can make its
> security decisions on as fully accurate information as possible.
> 
> 2) a bug in Squid.
> 
> Some more research to find out what exactly is being identified as
> invalid, and where it comes from will be needed to discover whch case 
> is
> relevant.
> 
> Amos
> 
> Amos Jeffries ????? 2016-05-11 16:43:
> 
> On 11/05/2016 6:35 p.m., ???????? ???? ????? wrote:
> 
> hi!
> 
> I use squid 4.0.10 in INTERCEPT mode. If I deny some users
> (ip-addresses) with
> 
> acl users_no_inet src "/etc/squid/ip-groups/no-inet"
> http_access deny users_no_inet
> 
> ERR_ACCESS_DENIED is displayed then go to HTTP. If go to HTTPS then
> first I see browser's NET::ERR_CERT_AUTHORITY_INVALID, and then click
> "unsecure" see ERR_ACCESS_DENIED.
> 
> How to make that right display ERR_ACCESS_DENIED on HTTPS for deny user
> in Squid 4.0 ?
> What you describe above is correct behaviour. The browser does not 
> trust
> your proxy's CA.
> 
> The only way to get around the browser warning about TLS security issue
> is to install the CA used by the proxy into the browser trusted CA set.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From garryd at comnet.uz  Thu May 12 04:01:19 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Thu, 12 May 2016 09:01:19 +0500
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
Message-ID: <1463025679.14398.4.camel@comnet.uz>

On Wed, 2016-05-11 at 21:37 -0300, Heiler Bemerguy wrote:
> 
> Hey guys,
> First take a look at the log:
> root at proxy:/var/log/squid# tail -f access.log |grep http://download.c
> dn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
> BR/firefox-45.0.1.complete.mar
> 1463011781.572?? 8776 10.1.3.236 TCP_MISS/206 300520 GET http://downl
> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.9
> application/octet-stream
> 1463011851.008?? 9347 10.1.3.236 TCP_MISS/206 300520 GET http://downl
> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
> application/octet-stream
> 1463011920.683?? 9645 10.1.3.236 TCP_MISS/206 300520 GET http://downl
> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.9
> application/octet-stream
> 1463012000.144? 19154 10.1.3.236 TCP_MISS/206 300520 GET http://downl
> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
> application/octet-stream
> 1463012072.276? 12121 10.1.3.236 TCP_MISS/206 300520 GET http://downl
> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
> application/octet-stream
> 1463012145.643? 13358 10.1.3.236 TCP_MISS/206 300520 GET http://downl
> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
> application/octet-stream
> 1463012217.472? 11772 10.1.3.236 TCP_MISS/206 300520 GET http://downl
> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
> application/octet-stream
> 1463012294.676? 17148 10.1.3.236 TCP_MISS/206 300520 GET http://downl
> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
> application/octet-stream
> 1463012370.131? 15272 10.1.3.236 TCP_MISS/206 300520 GET http://downl
> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
> application/octet-stream
> Now think: An user is just doing a segmented/ranged download, right?
> Squid won't cache the file because it is a range-download, not a full
> file download.
> But I WANT squid to cache it. So I decide to use "range_offset_limit
> -1", but then on every GET squid will re-download the file from the
> beginning, opening LOTs of simultaneous connections and using too
> much bandwidth, doing just the OPPOSITE it's meant to!
> 
> Is there a smart way to allow squid to download it from the beginning
> to the end (to actually cache it), but only on the FIRST request/get?
> Even if it makes the user wait for the full download, or cancel it
> temporarily, or.. whatever!! Anything!!
> 
> Best Regards,
> --?
> Heiler Bemerguy - (91) 98151-4894
> Assessor T?cnico - CINBESA (91) 3184-1751
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Hi, I believe, you describe the bug?http://bugs.squid-cache.org/show_bu
g.cgi?id=4469

I tried to reproduce the problem and have found that the problem
appears only with rock storage configurations. Can you try with
ufs/aufs storage?


From uhlar at fantomas.sk  Thu May 12 06:55:49 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 12 May 2016 08:55:49 +0200
Subject: [squid-users] Squid 4.0.10 https intercept
In-Reply-To: <491fa0715f007a302479eea003daac4a@tisiz72.ru>
References: <1b53817243fd1ddc614d77e747613cab@itcrowd72.ru>
 <542c7b43-0288-2356-f5e7-95615491805e@treenet.co.nz>
 <9d2c835fe1f622aaa5a013a07cee914f@tisiz72.ru>
 <b5f76697-7a90-a95e-d7f6-0c4ce8ce57f2@treenet.co.nz>
 <491fa0715f007a302479eea003daac4a@tisiz72.ru>
Message-ID: <20160512065549.GA6692@fantomas.sk>

On 12.05.16 08:00, admin wrote:
>openssl req -new -newkey rsa:1024 -days 365 -nodes -x509 -keyout 
>squidCA.pem -out squidCA.pem

1024-bit keys? too low for today...

>And export it:
>
>openssl x509 -in squidCA.pem -outform DER -out squidCA.crt

I'm not sure if this doesn't only transfer the certificate part to
squidCA.crt (not the key). Also, doesn't squid work with squidCA.pem ?

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
REALITY.SYS corrupted. Press any key to reboot Universe.


From carlopmart at gmail.com  Thu May 12 07:54:13 2016
From: carlopmart at gmail.com (C. L. Martinez)
Date: Thu, 12 May 2016 07:54:13 +0000
Subject: [squid-users] Problems configuring Squid with C-ICAP+Squidclamav
In-Reply-To: <1ffda9bc-7b95-591a-7f92-b01ec2c0e52a@gmail.com>
References: <20160511144105.GA15424@beagle.bcn.sia.es>
 <e68e0bb7-20c9-1323-b800-7b53e19bef39@gmail.com>
 <20160511150449.GB15424@beagle.bcn.sia.es>
 <1ffda9bc-7b95-591a-7f92-b01ec2c0e52a@gmail.com>
Message-ID: <20160512075413.GA5002@beagle.bcn.sia.es>

On Wed 11.May'16 at 21:53:13 +0600, Yuri Voinov wrote:
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>  
> Try to increase debug level in c_icap.conf:
> 
> # TAG: DebugLevel
> # Format: DebugLevel level
> # Description:
> #    The level of debugging information to be logged.
> #    The acceptable range of levels is between 0 and 10.
> # Default:
> #    DebugLevel 1
> DebugLevel 3
> 
> and look at c_icap server log again.
> 
> 
Thanks Yuri. I have enabled debug, but nothing:

root at obsd:/var/log/c-icap# c-icap -N -D -d 10
Setting parameter :-d=10
Searching 0x109580a21bb8 for default value
Setting parameter :PidFile=/var/run/c-icap/c-icap.pid
Searching 0x109580a21bc0 for default value
Setting parameter :CommandsSocket=/var/run/c-icap/c-icap.ctl
Searching 0x109580a21b38 for default value
Setting parameter :Timeout=300
Searching 0x109580a21b40 for default value
Setting parameter :MaxKeepAliveRequests=100
Searching 0x109580a21b3c for default value
Setting parameter :KeepAliveTimeout=600
Searching 0x109580a21c10 for default value
Setting parameter :StartServers=3
Searching 0x109580a21c14 for default value
Setting parameter :MaxServers=10
Searching 0x109580a21c1c for default value
Setting parameter :MinSpareThreads=10
Searching 0x109580a21c20 for default value
Setting parameter :MaxSpareThreads=20
Searching 0x109580a21c18 for default value
Setting parameter :ThreadsPerChild=10
Searching 0x109580a21b4c for default value
Setting parameter :MaxRequestsPerChild=0
Searching 0x109580a21ba8 for default value
Setting parameter :Port=1344
Searching 0x109580a21c00 for default value
Setting parameter :ServerAdmin=squid at domain.com
Searching 0x109580a21bb0 for default value
Setting parameter :TmpDir=/var/tmp
Searching 0x1097e5919290 for default value
Setting parameter :MaxMemObject=131072
Searching 0x109580a21b60 for default value
Setting parameter :Pipelining=1
Searching 0x109580a21b64 for default value
Setting parameter :SupportBuggyClients=0
Searching 0x109580a21bf8 for default value
Setting parameter :ModulesDir=/usr/local/lib/c_icap
Searching 0x109580a21bf0 for default value
Setting parameter :ServicesDir=/usr/local/lib/c_icap
Searching 0x1097e591a698 for default value
Setting parameter :TemplateDir=/usr/local/share/c_icap/templates/
Searching 0x1097e591a6c0 for default value
Setting parameter :TemplateDefaultLanguage=en
The db file /etc/c-icap/c-icap.magic is the same as default. Ignoring...
Searching 0x109580a22408 for default value
Setting parameter :RemoteProxyUsers=0
Searching 0x109580a22440 for default value
Setting parameter :RemoteProxyUserHeader=X-Authenticated-User
Searching 0x109580a2240c for default value
Setting parameter :RemoteProxyUserHeaderEncoded=1
Adding to acl localhost the data 127.0.0.1/255.255.255.255
In search specs list 0x0,name localhost
New ACL with name:localhost and  ACL Type: src
Adding to acl ALLREQUESTS the data RESPMOD
In search specs list 0x10978ca90b00,name ALLREQUESTS
Checking name:ALLREQUESTS with specname localhost
Adding to acl ALLREQUESTS the data REQMOD
In search specs list 0x10978ca90b00,name ALLREQUESTS
Checking name:ALLREQUESTS with specname localhost
Checking name:ALLREQUESTS with specname ALLREQUESTS
New ACL with name:ALLREQUESTS and  ACL Type: type
Creating new access entry as allow with specs:
In search specs list 0x10978ca90b00,name localhost
Checking name:localhost with specname localhost
In search specs list 0x10978ca90b00,name localhost
Checking name:localhost with specname localhost
        Adding acl spec: localhost
In search specs list 0x10978ca90b00,name ALLREQUESTS
Checking name:ALLREQUESTS with specname localhost
Checking name:ALLREQUESTS with specname ALLREQUESTS
In search specs list 0x10978ca90b00,name ALLREQUESTS
Checking name:ALLREQUESTS with specname localhost
Checking name:ALLREQUESTS with specname ALLREQUESTS
        Adding acl spec: ALLREQUESTS
Creating new access entry as deny with specs:
In search specs list 0x10978ca90b00,name all
Checking name:all with specname localhost
Checking name:all with specname ALLREQUESTS
In search specs list 0x10978ca90b00,name all
Checking name:all with specname localhost
Checking name:all with specname ALLREQUESTS
The acl spec all does not exists!
        Adding acl spec: all
Adding the logformat myFormat: %tl, %a %im %iu %is %I %O %Ib %Ob %{10}bph
Searching 0x109580a22678 for default value
Setting parameter :ServerLog=/var/log/c-icap/server.log
Adding the access logfile /var/log/c-icap/access.log
Setting parameter :Logger=file_logger
Loading service :echo path srv_echo.so
Found handler C_handler for service with extension:.so
Initialization of echo module......
Registering conf table:echo
Warning, alias is the same as service_name, not adding
Loading service :logger path sys_logger.so
Registering conf table:sys_logger
Loading service :squidclamav path squidclamav.so
Found handler C_handler for service with extension:.so
squidclamav.c(183) squidclamav_init_service: DEBUG Going to initialize squidclamav
squidclamav.c(708) set_istag: DEBUG setting istag to -1-squidclamav-10
Command squidclamav:cfgreload registered
LOG Reading configuration from /etc/squidclamav.conf
LOG Reading directive maxsize with value 5000000
LOG Reading directive redirect with value http://proxy.domain.dom/cgi-bin/clwarn.cgi
LOG Reading directive clamd_ip with value 127.0.0.1
LOG Reading directive clamd_port with value 3310
LOG Reading directive timeout with value 1
LOG Reading directive logredir with value 0
LOG Reading directive dnslookup with value 1
LOG Reading directive safebrowsing with value 0
Registering conf table:squidclamav
Warning, alias is the same as service_name, not adding
My hostname is:obsd.domain.com
Command relog registered
squidclamav.c(258) squidclamav_post_init_service: DEBUG squidguard not defined, good
Create shared mem, qsize=20 stat_block_size=560 childshared data:1120
Command stop registered
Command reconfigure registered
Command dump_statistics registered
pool hits:0 allocations: 3
Geting buffer from pool 992:15
Command test registered
Register in shared mem, qsize=20 stat_block_size=560 childshared data:1120
Register in shared mem, qsize=20 stat_block_size=560 childshared data:1120
Register in shared mem, qsize=20 stat_block_size=560 childshared data:1120
Going to execute child commands
Going to execute child commands
Going to execute child commands
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Waiting for a request....
Check command:test, type: 3 
Check command:test, type: 3 
Check command:test, type: 3 
Waiting for a request....
Waiting for a request....
Waiting for a request....
Check command:dump_statistics, type: 1 
Check command:dump_statistics, type: 1 
Check command:reconfigure, type: 1 
Check command:stop, type: 1 
Check command:relog, type: 3 
Check command:squidclamav:cfgreload, type: 3 
Check command:dump_statistics, type: 1 
Check command:reconfigure, type: 1 
Check command:stop, type: 1 
Check command:relog, type: 3 
Check command:squidclamav:cfgreload, type: 3 
Check command:reconfigure, type: 1 
Check command:stop, type: 1 
Check command:relog, type: 3 
Check command:squidclamav:cfgreload, type: 3 
Child 23458 getting requests now ...
Server stats: 
         Children: 3
         Free servers: 30
        Used servers:0
        Requests served:0
Going to execute child commands
Going to execute child commands
Going to execute child commands
Server stats: 
         Children: 3
         Free servers: 30
        Used servers:0
        Requests served:0
Going to execute child commands
Going to execute child commands
Going to execute child commands
Server stats: 
         Children: 3
         Free servers: 30
        Used servers:0
        Requests served:0
Going to execute child commands
Going to execute child commands
Going to execute child commands
Server stats: 
         Children: 3
         Free servers: 30
        Used servers:0
        Requests served:0
Going to execute child commands
Going to execute child commands
Going to execute child commands
Server stats: 
         Children: 3
         Free servers: 30
        Used servers:0
        Requests served:0

 I don't see any errors ... Maybe squid can't connect to ICAP service?? But all services are running in the same machine....
-- 
Greetings,
C. L. Martinez


From carlopmart at gmail.com  Thu May 12 08:42:39 2016
From: carlopmart at gmail.com (C. L. Martinez)
Date: Thu, 12 May 2016 08:42:39 +0000
Subject: [squid-users] Problems configuring Squid with
 C-ICAP+Squidclamav (SOLVED)
In-Reply-To: <2f4d9530-b06c-b3e2-40b3-937e776f05ec@gmail.com>
References: <20160511144105.GA15424@beagle.bcn.sia.es>
 <vmime.57334a05.13bb.1acc2823515f11d5@ms249-lin-003.rotterdam.bazuin.nl>
 <2f4d9530-b06c-b3e2-40b3-937e776f05ec@gmail.com>
Message-ID: <20160512084239.GB5002@beagle.bcn.sia.es>

On Wed 11.May'16 at 21:14:08 +0600, Yuri Voinov wrote:
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>  
> 
> 11.05.16 21:04, L.P.H. van Belle ?????:
> >
> > Hai,
> >
> > 
> >
> > I reviewd your config, thing whats different in c-icap.conf compared
> to me.
> >
> Obviously, the mindless copying and pasting the config - very bad
> practice, is not it?
> >
> > RemoteProxyUsers off ( for you ) on for me.
> >
> # TAG: RemoteProxyUsers
> # Format: RemoteProxyUsers onoff
> # Description:
> #    Set it to on if you want to use username provided by the proxy server.
> #    This is the recomended way to use users in c-icap.
> #    If the RemoteProxyUsers is off and c-icap configured to use users or
> #    groups the internal authentication mechanism will be used.
> # Default:
> #    RemoteProxyUsers off
> RemoteProxyUsers off
> 
> This is depending proxy configuration. And irrelevant current case.
> >
> > 
> >
> > Whats the content of /etc/c-icap/squidclamav.conf ?
> >
> > The important part for me of the file :
> >
> > #clamd_local /var/run/clamd.socket ! change/check this
> >
> This is OS-dependent, as obvious.
> >
> > clamd_ip 127.0.0.1
> >
> > clamd_port 3310
> >
> > 
> >
> > If you use socket make sure your rights are correct and icap is added
> to the clamav group.
> >
> Wrong. Squid group, not clamav.
> >
> > 
> >
> > 
> >
> > And my c-icap part of the squid.conf
> >
> > ## Tested with Squid 3.4.8 and 3.5.x + squidclamav 6.14 and 6.15
> >
> > icap_enable on
> >
> > icap_send_client_ip on
> >
> > icap_send_client_username on
> >
> > icap_client_username_header X-Authenticated-User
> >
> > icap_persistent_connections on
> >
> > icap_preview_enable on
> >
> > icap_preview_size 1024
> >
> > icap_service service_req reqmod_precache bypass=1
> icap://127.0.0.1:1344/squidclamav
> >
> > adaptation_access service_req allow all
> >
> > icap_service service_resp respmod_precache bypass=1
> icap://127.0.0.1:1344/squidclamav
> >
> > adaptation_access service_resp allow all
> >
> > 
> >
> > I think you changed to much in the example.
> >
> > 
> >
> > Im reffering to these in the squid.conf
> >
> > > adaptation_access service_avi_resp allow all
> >
> > service_avi_resp?
> >
> > 
> >
> Complete squid.conf fragment:
> 
> icap_service service_avi_req reqmod_precache
> icap://localhost:1344/squidclamav bypass=off
> adaptation_access service_avi_req allow all
> icap_service service_avi_resp respmod_precache
> icap://localhost:1344/squidclamav bypass=on
> adaptation_access service_avi_resp allow all
> 
> Please, PLEASE, do not make recommendation when you not understand what
> does config lines means!
>  

Ok, problem is solved. Seems there is some problem between squid and my unbound DNS server. Changing the following lines:

icap_service service_avi_req reqmod_precache icap://localhost:1344/squidclamav bypass=off
icap_service service_avi_resp respmod_precache icap://localhost:1344/squidclamav bypass=on

to:

icap_service service_avi_req reqmod_precache icap://127.0.0.1:1344/squidclamav bypass=off
icap_service service_avi_resp respmod_precache icap://127.0.0.1:1344/squidclamav bypass=on

all works as expected. As you can see I have changed "localhost" for "127.0.0.1" ... localhost entry exists inside my /etc/hosts file, and OpenBSD resolves correctly, but under unbound's config I have enabled "do-not-query-localhost: no" because unbound is configured to work with dnscrypt-proxy service...

I am not sure about this, but it is the only answer that explains this problem ... or it is a bug (but I don't think so).

What do you think??


-- 
Greetings,
C. L. Martinez


From squid3 at treenet.co.nz  Thu May 12 10:20:47 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 12 May 2016 22:20:47 +1200
Subject: [squid-users] Problems configuring Squid with
 C-ICAP+Squidclamav (SOLVED)
In-Reply-To: <20160512084239.GB5002@beagle.bcn.sia.es>
References: <20160511144105.GA15424@beagle.bcn.sia.es>
 <vmime.57334a05.13bb.1acc2823515f11d5@ms249-lin-003.rotterdam.bazuin.nl>
 <2f4d9530-b06c-b3e2-40b3-937e776f05ec@gmail.com>
 <20160512084239.GB5002@beagle.bcn.sia.es>
Message-ID: <b19cbee9-41ce-b25a-59d5-0c856f832acb@treenet.co.nz>

On 12/05/2016 8:42 p.m., C. L. Martinez wrote:
> On Wed 11.May'16 at 21:14:08 +0600, Yuri Voinov wrote:
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>>  
>>
>> 11.05.16 21:04, L.P.H. van Belle ?????:
>>>
>>> Hai,
>>>
>>>
>>>
>>> I reviewd your config, thing whats different in c-icap.conf compared
>> to me.
>>>
>> Obviously, the mindless copying and pasting the config - very bad
>> practice, is not it?
>>>
>>> RemoteProxyUsers off ( for you ) on for me.
>>>
>> # TAG: RemoteProxyUsers
>> # Format: RemoteProxyUsers onoff
>> # Description:
>> #    Set it to on if you want to use username provided by the proxy server.
>> #    This is the recomended way to use users in c-icap.
>> #    If the RemoteProxyUsers is off and c-icap configured to use users or
>> #    groups the internal authentication mechanism will be used.
>> # Default:
>> #    RemoteProxyUsers off
>> RemoteProxyUsers off
>>
>> This is depending proxy configuration. And irrelevant current case.
>>>
>>>
>>>
>>> Whats the content of /etc/c-icap/squidclamav.conf ?
>>>
>>> The important part for me of the file :
>>>
>>> #clamd_local /var/run/clamd.socket ! change/check this
>>>
>> This is OS-dependent, as obvious.
>>>
>>> clamd_ip 127.0.0.1
>>>
>>> clamd_port 3310
>>>
>>>
>>>
>>> If you use socket make sure your rights are correct and icap is added
>> to the clamav group.
>>>
>> Wrong. Squid group, not clamav.
>>>
>>>
>>>
>>>
>>>
>>> And my c-icap part of the squid.conf
>>>
>>> ## Tested with Squid 3.4.8 and 3.5.x + squidclamav 6.14 and 6.15
>>>
>>> icap_enable on
>>>
>>> icap_send_client_ip on
>>>
>>> icap_send_client_username on
>>>
>>> icap_client_username_header X-Authenticated-User
>>>
>>> icap_persistent_connections on
>>>
>>> icap_preview_enable on
>>>
>>> icap_preview_size 1024
>>>
>>> icap_service service_req reqmod_precache bypass=1
>> icap://127.0.0.1:1344/squidclamav
>>>
>>> adaptation_access service_req allow all
>>>
>>> icap_service service_resp respmod_precache bypass=1
>> icap://127.0.0.1:1344/squidclamav
>>>
>>> adaptation_access service_resp allow all
>>>
>>>
>>>
>>> I think you changed to much in the example.
>>>
>>>
>>>
>>> Im reffering to these in the squid.conf
>>>
>>>> adaptation_access service_avi_resp allow all
>>>
>>> service_avi_resp?
>>>
>>>
>>>
>> Complete squid.conf fragment:
>>
>> icap_service service_avi_req reqmod_precache
>> icap://localhost:1344/squidclamav bypass=off
>> adaptation_access service_avi_req allow all
>> icap_service service_avi_resp respmod_precache
>> icap://localhost:1344/squidclamav bypass=on
>> adaptation_access service_avi_resp allow all
>>
>> Please, PLEASE, do not make recommendation when you not understand what
>> does config lines means!
>>  
> 
> Ok, problem is solved. Seems there is some problem between squid and my unbound DNS server. Changing the following lines:
> 
> icap_service service_avi_req reqmod_precache icap://localhost:1344/squidclamav bypass=off
> icap_service service_avi_resp respmod_precache icap://localhost:1344/squidclamav bypass=on
> 
> to:
> 
> icap_service service_avi_req reqmod_precache icap://127.0.0.1:1344/squidclamav bypass=off
> icap_service service_avi_resp respmod_precache icap://127.0.0.1:1344/squidclamav bypass=on
> 
> all works as expected. As you can see I have changed "localhost" for "127.0.0.1" ... localhost entry exists inside my /etc/hosts file, and OpenBSD resolves correctly, but under unbound's config I have enabled "do-not-query-localhost: no" because unbound is configured to work with dnscrypt-proxy service...
> 
> I am not sure about this, but it is the only answer that explains this problem ... or it is a bug (but I don't think so).
> 
> What do you think??
> 

I think that Squid told you it was sending an OPTIONS request to ICAP
service, which failed. So it marked the service down. The service was
not allowed to be bypassed (bypass=off), so cannot cope with being down.

It is possible "localhost" had to be resolved to do that OPTIONS
request. However, if as you say it already has an entry in your
/etc/hosts file then Squid should have loaded that entry as a permanent
record and never be looking it up in DNS.

Amos



From yvoinov at gmail.com  Thu May 12 11:07:36 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 12 May 2016 17:07:36 +0600
Subject: [squid-users] Problems configuring Squid with
 C-ICAP+Squidclamav (SOLVED)
In-Reply-To: <20160512084239.GB5002@beagle.bcn.sia.es>
References: <20160511144105.GA15424@beagle.bcn.sia.es>
 <vmime.57334a05.13bb.1acc2823515f11d5@ms249-lin-003.rotterdam.bazuin.nl>
 <2f4d9530-b06c-b3e2-40b3-937e776f05ec@gmail.com>
 <20160512084239.GB5002@beagle.bcn.sia.es>
Message-ID: <fd361481-10a7-6a51-309d-e67d78fa6fcb@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Hm. Rare case.

In general, any OS TCP stack can resolve localhost itself to 127.0.0.1
with /etc/hosts or whatever.


12.05.16 14:42, C. L. Martinez ?????:
> On Wed 11.May'16 at 21:14:08 +0600, Yuri Voinov wrote:
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>> 
>>
>> 11.05.16 21:04, L.P.H. van Belle ?????:
>>>
>>> Hai,
>>>
>>>
>>>
>>> I reviewd your config, thing whats different in c-icap.conf compared
>> to me.
>>>
>> Obviously, the mindless copying and pasting the config - very bad
>> practice, is not it?
>>>
>>> RemoteProxyUsers off ( for you ) on for me.
>>>
>> # TAG: RemoteProxyUsers
>> # Format: RemoteProxyUsers onoff
>> # Description:
>> #    Set it to on if you want to use username provided by the proxy
server.
>> #    This is the recomended way to use users in c-icap.
>> #    If the RemoteProxyUsers is off and c-icap configured to use users or
>> #    groups the internal authentication mechanism will be used.
>> # Default:
>> #    RemoteProxyUsers off
>> RemoteProxyUsers off
>>
>> This is depending proxy configuration. And irrelevant current case.
>>>
>>>
>>>
>>> Whats the content of /etc/c-icap/squidclamav.conf ?
>>>
>>> The important part for me of the file :
>>>
>>> #clamd_local /var/run/clamd.socket ! change/check this
>>>
>> This is OS-dependent, as obvious.
>>>
>>> clamd_ip 127.0.0.1
>>>
>>> clamd_port 3310
>>>
>>>
>>>
>>> If you use socket make sure your rights are correct and icap is added
>> to the clamav group.
>>>
>> Wrong. Squid group, not clamav.
>>>
>>>
>>>
>>>
>>>
>>> And my c-icap part of the squid.conf
>>>
>>> ## Tested with Squid 3.4.8 and 3.5.x + squidclamav 6.14 and 6.15
>>>
>>> icap_enable on
>>>
>>> icap_send_client_ip on
>>>
>>> icap_send_client_username on
>>>
>>> icap_client_username_header X-Authenticated-User
>>>
>>> icap_persistent_connections on
>>>
>>> icap_preview_enable on
>>>
>>> icap_preview_size 1024
>>>
>>> icap_service service_req reqmod_precache bypass=1
>> icap://127.0.0.1:1344/squidclamav
>>>
>>> adaptation_access service_req allow all
>>>
>>> icap_service service_resp respmod_precache bypass=1
>> icap://127.0.0.1:1344/squidclamav
>>>
>>> adaptation_access service_resp allow all
>>>
>>>
>>>
>>> I think you changed to much in the example.
>>>
>>>
>>>
>>> Im reffering to these in the squid.conf
>>>
>>>> adaptation_access service_avi_resp allow all
>>>
>>> service_avi_resp?
>>>
>>>
>>>
>> Complete squid.conf fragment:
>>
>> icap_service service_avi_req reqmod_precache
>> icap://localhost:1344/squidclamav bypass=off
>> adaptation_access service_avi_req allow all
>> icap_service service_avi_resp respmod_precache
>> icap://localhost:1344/squidclamav bypass=on
>> adaptation_access service_avi_resp allow all
>>
>> Please, PLEASE, do not make recommendation when you not understand what
>> does config lines means!
>> 
>
> Ok, problem is solved. Seems there is some problem between squid and
my unbound DNS server. Changing the following lines:
>
> icap_service service_avi_req reqmod_precache
icap://localhost:1344/squidclamav bypass=off
> icap_service service_avi_resp respmod_precache
icap://localhost:1344/squidclamav bypass=on
>
> to:
>
> icap_service service_avi_req reqmod_precache
icap://127.0.0.1:1344/squidclamav bypass=off
> icap_service service_avi_resp respmod_precache
icap://127.0.0.1:1344/squidclamav bypass=on
>
> all works as expected. As you can see I have changed "localhost" for
"127.0.0.1" ... localhost entry exists inside my /etc/hosts file, and
OpenBSD resolves correctly, but under unbound's config I have enabled
"do-not-query-localhost: no" because unbound is configured to work with
dnscrypt-proxy service...
>
> I am not sure about this, but it is the only answer that explains this
problem ... or it is a bug (but I don't think so).
>
> What do you think??
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEbBAEBCAAGBQJXNGP4AAoJENNXIZxhPexGTs4H+KjRaCUYCnTjEeHf/EUDMP8S
FHfDKK4nCRbTL/KDn8i4vp1NnZjUjE/t/MfyfEnWNAO1SFknLqAFmlIX/P2Tm6b9
EzSB6XZKMfSg9PrzZxKJkRqF3tRzBXOs0lK2pEVyTd5i2xKkTCsMGw6eHOp8dveG
4DjG1OW3oGCQELJLuj+kPjnjGzYRHRL3Ck+z4ao+CWnIpCUsy0EEtT8+qhyukPkG
Z4kJZzACLq5eR3Pl6moOIsQjSxch5j6ppuOd2tvgqyelAa2VmOECIhp/E8R68QCl
EbmFT2V6xKBKtj2bMiHnYiRVRnlVd6Sd9jsFjhSyrbj2P6XeyWg/03RlOgwYiA==
=Qv20
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/19ac91a0/attachment.key>

From carlopmart at gmail.com  Thu May 12 11:13:44 2016
From: carlopmart at gmail.com (C. L. Martinez)
Date: Thu, 12 May 2016 11:13:44 +0000
Subject: [squid-users] Problems configuring Squid with
 C-ICAP+Squidclamav (SOLVED)
In-Reply-To: <b19cbee9-41ce-b25a-59d5-0c856f832acb@treenet.co.nz>
References: <20160511144105.GA15424@beagle.bcn.sia.es>
 <vmime.57334a05.13bb.1acc2823515f11d5@ms249-lin-003.rotterdam.bazuin.nl>
 <2f4d9530-b06c-b3e2-40b3-937e776f05ec@gmail.com>
 <20160512084239.GB5002@beagle.bcn.sia.es>
 <b19cbee9-41ce-b25a-59d5-0c856f832acb@treenet.co.nz>
Message-ID: <20160512111318.GA18713@beagle.bcn.sia.es>

On Thu 12.May'16 at 22:20:47 +1200, Amos Jeffries wrote:
> On 12/05/2016 8:42 p.m., C. L. Martinez wrote:
> > On Wed 11.May'16 at 21:14:08 +0600, Yuri Voinov wrote:
> >>
> >> -----BEGIN PGP SIGNED MESSAGE-----
> >> Hash: SHA256
> >>  
> >>
> >> 11.05.16 21:04, L.P.H. van Belle ?????:
> >>>
> >>> Hai,
> >>>
> >>>
> >>>
> >>> I reviewd your config, thing whats different in c-icap.conf compared
> >> to me.
> >>>
> >> Obviously, the mindless copying and pasting the config - very bad
> >> practice, is not it?
> >>>
> >>> RemoteProxyUsers off ( for you ) on for me.
> >>>
> >> # TAG: RemoteProxyUsers
> >> # Format: RemoteProxyUsers onoff
> >> # Description:
> >> #    Set it to on if you want to use username provided by the proxy server.
> >> #    This is the recomended way to use users in c-icap.
> >> #    If the RemoteProxyUsers is off and c-icap configured to use users or
> >> #    groups the internal authentication mechanism will be used.
> >> # Default:
> >> #    RemoteProxyUsers off
> >> RemoteProxyUsers off
> >>
> >> This is depending proxy configuration. And irrelevant current case.
> >>>
> >>>
> >>>
> >>> Whats the content of /etc/c-icap/squidclamav.conf ?
> >>>
> >>> The important part for me of the file :
> >>>
> >>> #clamd_local /var/run/clamd.socket ! change/check this
> >>>
> >> This is OS-dependent, as obvious.
> >>>
> >>> clamd_ip 127.0.0.1
> >>>
> >>> clamd_port 3310
> >>>
> >>>
> >>>
> >>> If you use socket make sure your rights are correct and icap is added
> >> to the clamav group.
> >>>
> >> Wrong. Squid group, not clamav.
> >>>
> >>>
> >>>
> >>>
> >>>
> >>> And my c-icap part of the squid.conf
> >>>
> >>> ## Tested with Squid 3.4.8 and 3.5.x + squidclamav 6.14 and 6.15
> >>>
> >>> icap_enable on
> >>>
> >>> icap_send_client_ip on
> >>>
> >>> icap_send_client_username on
> >>>
> >>> icap_client_username_header X-Authenticated-User
> >>>
> >>> icap_persistent_connections on
> >>>
> >>> icap_preview_enable on
> >>>
> >>> icap_preview_size 1024
> >>>
> >>> icap_service service_req reqmod_precache bypass=1
> >> icap://127.0.0.1:1344/squidclamav
> >>>
> >>> adaptation_access service_req allow all
> >>>
> >>> icap_service service_resp respmod_precache bypass=1
> >> icap://127.0.0.1:1344/squidclamav
> >>>
> >>> adaptation_access service_resp allow all
> >>>
> >>>
> >>>
> >>> I think you changed to much in the example.
> >>>
> >>>
> >>>
> >>> Im reffering to these in the squid.conf
> >>>
> >>>> adaptation_access service_avi_resp allow all
> >>>
> >>> service_avi_resp?
> >>>
> >>>
> >>>
> >> Complete squid.conf fragment:
> >>
> >> icap_service service_avi_req reqmod_precache
> >> icap://localhost:1344/squidclamav bypass=off
> >> adaptation_access service_avi_req allow all
> >> icap_service service_avi_resp respmod_precache
> >> icap://localhost:1344/squidclamav bypass=on
> >> adaptation_access service_avi_resp allow all
> >>
> >> Please, PLEASE, do not make recommendation when you not understand what
> >> does config lines means!
> >>  
> > 
> > Ok, problem is solved. Seems there is some problem between squid and my unbound DNS server. Changing the following lines:
> > 
> > icap_service service_avi_req reqmod_precache icap://localhost:1344/squidclamav bypass=off
> > icap_service service_avi_resp respmod_precache icap://localhost:1344/squidclamav bypass=on
> > 
> > to:
> > 
> > icap_service service_avi_req reqmod_precache icap://127.0.0.1:1344/squidclamav bypass=off
> > icap_service service_avi_resp respmod_precache icap://127.0.0.1:1344/squidclamav bypass=on
> > 
> > all works as expected. As you can see I have changed "localhost" for "127.0.0.1" ... localhost entry exists inside my /etc/hosts file, and OpenBSD resolves correctly, but under unbound's config I have enabled "do-not-query-localhost: no" because unbound is configured to work with dnscrypt-proxy service...
> > 
> > I am not sure about this, but it is the only answer that explains this problem ... or it is a bug (but I don't think so).
> > 
> > What do you think??
> > 
> 
> I think that Squid told you it was sending an OPTIONS request to ICAP
> service, which failed. So it marked the service down. The service was
> not allowed to be bypassed (bypass=off), so cannot cope with being down.
> 
> It is possible "localhost" had to be resolved to do that OPTIONS
> request. However, if as you say it already has an entry in your
> /etc/hosts file then Squid should have loaded that entry as a permanent
> record and never be looking it up in DNS.
> 
> Amos

But when squid sents an OPTIONS request to ICAP, why works when I use 127.0.0.1 and not localhost?? Maybe it is a problem with openbsd's package ...

-- 
Greetings,
C. L. Martinez


From squid3 at treenet.co.nz  Thu May 12 12:00:05 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 May 2016 00:00:05 +1200
Subject: [squid-users] Problems configuring Squid with
 C-ICAP+Squidclamav (SOLVED)
In-Reply-To: <20160512111318.GA18713@beagle.bcn.sia.es>
References: <20160511144105.GA15424@beagle.bcn.sia.es>
 <vmime.57334a05.13bb.1acc2823515f11d5@ms249-lin-003.rotterdam.bazuin.nl>
 <2f4d9530-b06c-b3e2-40b3-937e776f05ec@gmail.com>
 <20160512084239.GB5002@beagle.bcn.sia.es>
 <b19cbee9-41ce-b25a-59d5-0c856f832acb@treenet.co.nz>
 <20160512111318.GA18713@beagle.bcn.sia.es>
Message-ID: <dc535419-e24f-b6ee-00ac-45970ec67304@treenet.co.nz>

On 12/05/2016 11:13 p.m., C. L. Martinez wrote:
> 
> But when squid sents an OPTIONS request to ICAP, why works when I use 127.0.0.1 and not localhost?? Maybe it is a problem with openbsd's package ...
> 

It is quite possible. 127.0.0.1 is not the only address modern computers
use for localhost. Double check what your hosts file contains.

Amos



From spil.oss at gmail.com  Thu May 12 13:33:30 2016
From: spil.oss at gmail.com (Spil Oss)
Date: Thu, 12 May 2016 15:33:30 +0200
Subject: [squid-users] Linking with *SSL
Message-ID: <CAEJyAvM8O6uVCgSipvzXAK1OsUrH3izc7BVTgaS0kPkWmAn3BQ@mail.gmail.com>

> Hi!
> When we worked on squid port on FreeBSD one of the FreeBSD user
> (Bernard Spil) noticed:
>
> When working on this, I ran into another issue. Perhaps maintainer can
> fix that with upstream. I've now added LIBOPENSSL_LIBS="-lcrypto
> -lssl" because of configure failing in configure.ac line 1348.
>
> > AC_CHECK_LIB(ssl,[SSL_library_init],[LIBOPENSSL_LIBS="-lssl $LIBOPENSSL_LIBS"],[AC_MSG_ERROR([library 'ssl' is required for OpenSSL])
>
> You cannot link against libssl when not linking libcrypto as well
> leading to an error with LibreSSL. This check should add -lcrypto in
> addition to -lssl to pass.
>
> Is this something someone could take a look at?

Hi All,

Sorry for replying out-of-thread.

What happens is that the check for SSL_library_init fails as -lcrypto
is missing.

Output from configure

> checking for CRYPTO_new_ex_data in -lcrypto... yes
> checking for SSL_library_init in -lssl... no
> configure: error: library 'ssl' is required for OpenSSL
> ===>  Script "configure" failed unexpectedly.

What I usually see in autoconf scripts is that temp CFLAGS etc are set
before the test for SSL libs and reversed after the test.

Adding LIBOPENSSL_LIBS="-lcrypto -lssl" to configure works as well

Would be great if you can fix this!

Thanks,

Bernard Spil.
https://wiki.freebsd.org/BernardSpil
https://wiki.freebsd.org/LibreSSL
https://wiki.freebsd.org/OpenSSL


From hpj at urpla.net  Thu May 12 14:06:40 2016
From: hpj at urpla.net (Hans-Peter Jansen)
Date: Thu, 12 May 2016 16:06:40 +0200
Subject: [squid-users] Getting the full file content on a range request,
	but not on EVERY get ...
In-Reply-To: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
Message-ID: <2575073.4c7f0552JP@xrated>

On Mittwoch, 11. Mai 2016 21:37:17 Heiler Bemerguy wrote:
> Hey guys,
> 
> First take a look at the log:
> 
> root at proxy:/var/log/squid# tail -f access.log |grep
> http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-> BR/firefox-45.0.1.complete.mar 1463011781.572   8776 10.1.3.236 TCP_MISS/206
> 300520 GET
[...] 
> Now think: An user is just doing a segmented/ranged download, right?
> Squid won't cache the file because it is a range-download, not a full
> file download.
> But I WANT squid to cache it. So I decide to use "range_offset_limit
> -1", but then on every GET squid will re-download the file from the
> beginning, opening LOTs of simultaneous connections and using too much
> bandwidth, doing just the OPPOSITE it's meant to!
> 
> Is there a smart way to allow squid to download it from the beginning to
> the end (to actually cache it), but only on the FIRST request/get? Even
> if it makes the user wait for the full download, or cancel it
> temporarily, or.. whatever!! Anything!!

Well, this is exactly, what my squid_dedup helper was created for!

See my announcement: 

	Subject: [squid-users] New StoreID helper: squid_dedup
	Date: Mon, 09 May 2016 23:56:45 +0200

My openSUSE environment is fetching _all_ updates with byte-ranges from many 
servers. Therefor, I created squid_dedup.

Your specific config could look like this:

/etc/squid/dedup/mozilla.conf:
[mozilla]
match: http\:\/\/download\.cdn\.mozilla\.net/(.*)
replace: http://download.cdn.mozilla.net.%(intdomain)s/\1
fetch: true

The fetch parameter is unique among the other StoreID helper (AFAIK): it is 
fetching the object after a certain delay with a pool of fetcher threads.

The idea is: after the first access for an object, wait a bit (global setting, 
default: 15 secs), and then fetch the whole thing once. It won't solve 
anything for the first client, but for all subsequent accesses. 

The fetcher avoids fetching anything more than once by checking the http 
headers.

This is a pretty new project, but be assured, that the basic functions are 
working fine, and I will do my best to solve any upcoming issues. It is 
implemented with Python3 and prepared for supporting additional features 
easily, while keeping a good part of an eye on efficiency.

Let me know, if you're going to try it.

Pete


From nilesh.gavali at tcs.com  Thu May 12 16:46:36 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Thu, 12 May 2016 17:46:36 +0100
Subject: [squid-users] Windows Squid with AD authentication
Message-ID: <OFC3392A46.462F0184-ON80257FB1.00598D57-80257FB1.0059AB8F@tcs.com>

Team;
we have squid running on Windows and need to integrate it with Windows AD 
.can anyone help me with steps to be perform to get this done.

Thanks & Regards
Nilesh Suresh Gavali
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/327a38cb/attachment.htm>

From heiler.bemerguy at cinbesa.com.br  Thu May 12 16:28:00 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Thu, 12 May 2016 13:28:00 -0300
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <2575073.4c7f0552JP@xrated>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
Message-ID: <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>


Hi Pete, thanks for replying... let me see if I got it right..

Will I need to specify every url/domain I want it to act on ? I want 
squid to do it for every range-request downloads that should/would be 
cached (based on other rules, pattern_refreshs etc)

It doesn't need to delay any downloads as long as it isn't a dupe of 
what's already being downloaded.....


Best Regards,


-- 
Heiler Bemerguy - (91) 98151-4894
Assessor T?cnico - CINBESA (91) 3184-1751


Em 12/05/2016 11:06, Hans-Peter Jansen escreveu:
> On Mittwoch, 11. Mai 2016 21:37:17 Heiler Bemerguy wrote:
>> Hey guys,
>>
>> First take a look at the log:
>>
>> root at proxy:/var/log/squid# tail -f access.log |grep
>> http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-> BR/firefox-45.0.1.complete.mar 1463011781.572   8776 10.1.3.236 TCP_MISS/206
>> 300520 GET
> [...]
>> Now think: An user is just doing a segmented/ranged download, right?
>> Squid won't cache the file because it is a range-download, not a full
>> file download.
>> But I WANT squid to cache it. So I decide to use "range_offset_limit
>> -1", but then on every GET squid will re-download the file from the
>> beginning, opening LOTs of simultaneous connections and using too much
>> bandwidth, doing just the OPPOSITE it's meant to!
>>
>> Is there a smart way to allow squid to download it from the beginning to
>> the end (to actually cache it), but only on the FIRST request/get? Even
>> if it makes the user wait for the full download, or cancel it
>> temporarily, or.. whatever!! Anything!!
> Well, this is exactly, what my squid_dedup helper was created for!
>
> See my announcement:
>
> 	Subject: [squid-users] New StoreID helper: squid_dedup
> 	Date: Mon, 09 May 2016 23:56:45 +0200
>
> My openSUSE environment is fetching _all_ updates with byte-ranges from many
> servers. Therefor, I created squid_dedup.
>
> Your specific config could look like this:
>
> /etc/squid/dedup/mozilla.conf:
> [mozilla]
> match: http\:\/\/download\.cdn\.mozilla\.net/(.*)
> replace: http://download.cdn.mozilla.net.%(intdomain)s/\1
> fetch: true
>
> The fetch parameter is unique among the other StoreID helper (AFAIK): it is
> fetching the object after a certain delay with a pool of fetcher threads.
>
> The idea is: after the first access for an object, wait a bit (global setting,
> default: 15 secs), and then fetch the whole thing once. It won't solve
> anything for the first client, but for all subsequent accesses.
>
> The fetcher avoids fetching anything more than once by checking the http
> headers.
>
> This is a pretty new project, but be assured, that the basic functions are
> working fine, and I will do my best to solve any upcoming issues. It is
> implemented with Python3 and prepared for supporting additional features
> easily, while keeping a good part of an eye on efficiency.
>
> Let me know, if you're going to try it.
>
> Pete
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/44b7d9df/attachment.htm>

From Antony.Stone at squid.open.source.it  Thu May 12 16:34:08 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 12 May 2016 18:34:08 +0200
Subject: [squid-users] Windows Squid with AD authentication
In-Reply-To: <OFC3392A46.462F0184-ON80257FB1.00598D57-80257FB1.0059AB8F@tcs.com>
References: <OFC3392A46.462F0184-ON80257FB1.00598D57-80257FB1.0059AB8F@tcs.com>
Message-ID: <201605121834.08490.Antony.Stone@squid.open.source.it>

On Thursday 12 May 2016 at 18:46:36, Nilesh Gavali wrote:

> Team;
> we have squid running on Windows and need to integrate it with Windows AD
> .can anyone help me with steps to be perform to get this done.

This specific question has appeared a few times on this list only recently.

Have you so far:

 - searched the list archives for likely answers to your question?

http://lists.squid-cache.org/pipermail/squid-users/

 - consulted the Squid documentation for guidance?

http://www.squid-cache.org/Doc/

 - looked for any independent HOWTOs etc which show how people have done this 
in the past?

http://www.google.com/search?q=squid+active+directory+authentication


Here's some friendly advice:

1. The more information you give us (such as: which version of Squid are you 
using, which version of Windows are you running under, which form of 
authentication are you using?), the easier it is for people here to help.

2. If you have tried something already and run into problems, tell us what you 
have tried and what problems (log file extracts, complete client error message, 
etc) you encountered, so we can offer specific suggestions.

3. If you haven't yet tried to implement anything, at least let us know what 
documentation you have looked up and what problems you encountered when 
following it, so we can try to fill in the gaps.


Regards,


Antony.

-- 
Most people have more than the average number of legs.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From nilesh.gavali at tcs.com  Thu May 12 17:15:44 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Thu, 12 May 2016 18:15:44 +0100
Subject: [squid-users] squid-users Digest, Vol 21, Issue 54
In-Reply-To: <mailman.21441.1463070882.2892.squid-users@lists.squid-cache.org>
References: <mailman.21441.1463070882.2892.squid-users@lists.squid-cache.org>
Message-ID: <OF9B951B84.6929A4FD-ON80257FB1.005C1CE1-80257FB1.005C5699@tcs.com>

Hello Antony;
we have Squid 3.5 on Windows 2012 R2 OS & for which I need to integrate 
squid with AD. I search online but all of the link are based on linux 
platform squid.
I am looking for squid running on Windows Platform which need to integrate 
with AD authentication.

Thanks & Regards
Nilesh Suresh Gavali



From:   squid-users-request at lists.squid-cache.org
To:     squid-users at lists.squid-cache.org
Date:   12/05/2016 17:33
Subject:        squid-users Digest, Vol 21, Issue 54
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org>



Send squid-users mailing list submissions to
                 squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
                 http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
                 squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
                 squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

   1. Re: Problems configuring Squid with C-ICAP+Squidclamav
      (SOLVED) (Amos Jeffries)
   2. Re: Linking with *SSL (Spil Oss)
   3. Re: Getting the full file content on a range request, but not
      on EVERY get ... (Hans-Peter Jansen)
   4. Windows Squid with AD authentication (Nilesh Gavali)
   5. Re: Getting the full file content on a range request, but not
      on EVERY get ... (Heiler Bemerguy)
   6. Re: Windows Squid with AD authentication (Antony Stone)


----------------------------------------------------------------------

Message: 1
Date: Fri, 13 May 2016 00:00:05 +1200
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Problems configuring Squid with
                 C-ICAP+Squidclamav (SOLVED)
Message-ID: <dc535419-e24f-b6ee-00ac-45970ec67304 at treenet.co.nz>
Content-Type: text/plain; charset=utf-8

On 12/05/2016 11:13 p.m., C. L. Martinez wrote:
> 
> But when squid sents an OPTIONS request to ICAP, why works when I use 
127.0.0.1 and not localhost?? Maybe it is a problem with openbsd's package 
...
> 

It is quite possible. 127.0.0.1 is not the only address modern computers
use for localhost. Double check what your hosts file contains.

Amos



------------------------------

Message: 2
Date: Thu, 12 May 2016 15:33:30 +0200
From: Spil Oss <spil.oss at gmail.com>
To: squid-users at lists.squid-cache.org, timp87 at gmail.com
Subject: Re: [squid-users] Linking with *SSL
Message-ID:
 <CAEJyAvM8O6uVCgSipvzXAK1OsUrH3izc7BVTgaS0kPkWmAn3BQ at mail.gmail.com>
Content-Type: text/plain; charset=UTF-8

> Hi!
> When we worked on squid port on FreeBSD one of the FreeBSD user
> (Bernard Spil) noticed:
>
> When working on this, I ran into another issue. Perhaps maintainer can
> fix that with upstream. I've now added LIBOPENSSL_LIBS="-lcrypto
> -lssl" because of configure failing in configure.ac line 1348.
>
> > AC_CHECK_LIB(ssl,[SSL_library_init],[LIBOPENSSL_LIBS="-lssl 
$LIBOPENSSL_LIBS"],[AC_MSG_ERROR([library 'ssl' is required for OpenSSL])
>
> You cannot link against libssl when not linking libcrypto as well
> leading to an error with LibreSSL. This check should add -lcrypto in
> addition to -lssl to pass.
>
> Is this something someone could take a look at?

Hi All,

Sorry for replying out-of-thread.

What happens is that the check for SSL_library_init fails as -lcrypto
is missing.

Output from configure

> checking for CRYPTO_new_ex_data in -lcrypto... yes
> checking for SSL_library_init in -lssl... no
> configure: error: library 'ssl' is required for OpenSSL
> ===>  Script "configure" failed unexpectedly.

What I usually see in autoconf scripts is that temp CFLAGS etc are set
before the test for SSL libs and reversed after the test.

Adding LIBOPENSSL_LIBS="-lcrypto -lssl" to configure works as well

Would be great if you can fix this!

Thanks,

Bernard Spil.
https://wiki.freebsd.org/BernardSpil
https://wiki.freebsd.org/LibreSSL
https://wiki.freebsd.org/OpenSSL


------------------------------

Message: 3
Date: Thu, 12 May 2016 16:06:40 +0200
From: Hans-Peter Jansen <hpj at urpla.net>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Getting the full file content on a range
                 request,                but not on EVERY get ...
Message-ID: <2575073.4c7f0552JP at xrated>
Content-Type: text/plain; charset="us-ascii"

On Mittwoch, 11. Mai 2016 21:37:17 Heiler Bemerguy wrote:
> Hey guys,
> 
> First take a look at the log:
> 
> root at proxy:/var/log/squid# tail -f access.log |grep
> 
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
> BR/firefox-45.0.1.complete.mar 1463011781.572   8776 10.1.3.236 
TCP_MISS/206
> 300520 GET
[...] 
> Now think: An user is just doing a segmented/ranged download, right?
> Squid won't cache the file because it is a range-download, not a full
> file download.
> But I WANT squid to cache it. So I decide to use "range_offset_limit
> -1", but then on every GET squid will re-download the file from the
> beginning, opening LOTs of simultaneous connections and using too much
> bandwidth, doing just the OPPOSITE it's meant to!
> 
> Is there a smart way to allow squid to download it from the beginning to
> the end (to actually cache it), but only on the FIRST request/get? Even
> if it makes the user wait for the full download, or cancel it
> temporarily, or.. whatever!! Anything!!

Well, this is exactly, what my squid_dedup helper was created for!

See my announcement: 

                 Subject: [squid-users] New StoreID helper: squid_dedup
                 Date: Mon, 09 May 2016 23:56:45 +0200

My openSUSE environment is fetching _all_ updates with byte-ranges from 
many 
servers. Therefor, I created squid_dedup.

Your specific config could look like this:

/etc/squid/dedup/mozilla.conf:
[mozilla]
match: http\:\/\/download\.cdn\.mozilla\.net/(.*)
replace: http://download.cdn.mozilla.net.%(intdomain)s/\1
fetch: true

The fetch parameter is unique among the other StoreID helper (AFAIK): it 
is 
fetching the object after a certain delay with a pool of fetcher threads.

The idea is: after the first access for an object, wait a bit (global 
setting, 
default: 15 secs), and then fetch the whole thing once. It won't solve 
anything for the first client, but for all subsequent accesses. 

The fetcher avoids fetching anything more than once by checking the http 
headers.

This is a pretty new project, but be assured, that the basic functions are 

working fine, and I will do my best to solve any upcoming issues. It is 
implemented with Python3 and prepared for supporting additional features 
easily, while keeping a good part of an eye on efficiency.

Let me know, if you're going to try it.

Pete


------------------------------

Message: 4
Date: Thu, 12 May 2016 17:46:36 +0100
From: Nilesh Gavali <nilesh.gavali at tcs.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Windows Squid with AD authentication
Message-ID:
 <OFC3392A46.462F0184-ON80257FB1.00598D57-80257FB1.0059AB8F at tcs.com>
Content-Type: text/plain; charset="utf-8"

Team;
we have squid running on Windows and need to integrate it with Windows AD 
.can anyone help me with steps to be perform to get this done.

Thanks & Regards
Nilesh Suresh Gavali
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/327a38cb/attachment-0001.html
>

------------------------------

Message: 5
Date: Thu, 12 May 2016 13:28:00 -0300
From: Heiler Bemerguy <heiler.bemerguy at cinbesa.com.br>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Getting the full file content on a range
                 request, but not on EVERY get ...
Message-ID: <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c at cinbesa.com.br>
Content-Type: text/plain; charset="utf-8"; Format="flowed"


Hi Pete, thanks for replying... let me see if I got it right..

Will I need to specify every url/domain I want it to act on ? I want 
squid to do it for every range-request downloads that should/would be 
cached (based on other rules, pattern_refreshs etc)

It doesn't need to delay any downloads as long as it isn't a dupe of 
what's already being downloaded.....


Best Regards,


-- 
Heiler Bemerguy - (91) 98151-4894
Assessor T?cnico - CINBESA (91) 3184-1751


Em 12/05/2016 11:06, Hans-Peter Jansen escreveu:
> On Mittwoch, 11. Mai 2016 21:37:17 Heiler Bemerguy wrote:
>> Hey guys,
>>
>> First take a look at the log:
>>
>> root at proxy:/var/log/squid# tail -f access.log |grep
>> 
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
> BR/firefox-45.0.1.complete.mar 1463011781.572   8776 10.1.3.236 
TCP_MISS/206
>> 300520 GET
> [...]
>> Now think: An user is just doing a segmented/ranged download, right?
>> Squid won't cache the file because it is a range-download, not a full
>> file download.
>> But I WANT squid to cache it. So I decide to use "range_offset_limit
>> -1", but then on every GET squid will re-download the file from the
>> beginning, opening LOTs of simultaneous connections and using too much
>> bandwidth, doing just the OPPOSITE it's meant to!
>>
>> Is there a smart way to allow squid to download it from the beginning 
to
>> the end (to actually cache it), but only on the FIRST request/get? Even
>> if it makes the user wait for the full download, or cancel it
>> temporarily, or.. whatever!! Anything!!
> Well, this is exactly, what my squid_dedup helper was created for!
>
> See my announcement:
>
>                Subject: [squid-users] New StoreID helper: squid_dedup
>                Date: Mon, 09 May 2016 23:56:45 +0200
>
> My openSUSE environment is fetching _all_ updates with byte-ranges from 
many
> servers. Therefor, I created squid_dedup.
>
> Your specific config could look like this:
>
> /etc/squid/dedup/mozilla.conf:
> [mozilla]
> match: http\:\/\/download\.cdn\.mozilla\.net/(.*)
> replace: http://download.cdn.mozilla.net.%(intdomain)s/\1
> fetch: true
>
> The fetch parameter is unique among the other StoreID helper (AFAIK): it 
is
> fetching the object after a certain delay with a pool of fetcher 
threads.
>
> The idea is: after the first access for an object, wait a bit (global 
setting,
> default: 15 secs), and then fetch the whole thing once. It won't solve
> anything for the first client, but for all subsequent accesses.
>
> The fetcher avoids fetching anything more than once by checking the http
> headers.
>
> This is a pretty new project, but be assured, that the basic functions 
are
> working fine, and I will do my best to solve any upcoming issues. It is
> implemented with Python3 and prepared for supporting additional features
> easily, while keeping a good part of an eye on efficiency.
>
> Let me know, if you're going to try it.
>
> Pete
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/44b7d9df/attachment-0001.html
>

------------------------------

Message: 6
Date: Thu, 12 May 2016 18:34:08 +0200
From: Antony Stone <Antony.Stone at squid.open.source.it>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Windows Squid with AD authentication
Message-ID: <201605121834.08490.Antony.Stone at squid.open.source.it>
Content-Type: Text/Plain;  charset="iso-8859-15"

On Thursday 12 May 2016 at 18:46:36, Nilesh Gavali wrote:

> Team;
> we have squid running on Windows and need to integrate it with Windows 
AD
> .can anyone help me with steps to be perform to get this done.

This specific question has appeared a few times on this list only 
recently.

Have you so far:

 - searched the list archives for likely answers to your question?

http://lists.squid-cache.org/pipermail/squid-users/

 - consulted the Squid documentation for guidance?

http://www.squid-cache.org/Doc/

 - looked for any independent HOWTOs etc which show how people have done 
this 
in the past?

http://www.google.com/search?q=squid+active+directory+authentication


Here's some friendly advice:

1. The more information you give us (such as: which version of Squid are 
you 
using, which version of Windows are you running under, which form of 
authentication are you using?), the easier it is for people here to help.

2. If you have tried something already and run into problems, tell us what 
you 
have tried and what problems (log file extracts, complete client error 
message, 
etc) you encountered, so we can offer specific suggestions.

3. If you haven't yet tried to implement anything, at least let us know 
what 
documentation you have looked up and what problems you encountered when 
following it, so we can try to fill in the gaps.


Regards,


Antony.

-- 
Most people have more than the average number of legs.

                                                   Please reply to the 
list;
                                                         please *don't* CC 
me.


------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 21, Issue 54
*******************************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/0fd99a76/attachment.htm>

From yvoinov at gmail.com  Thu May 12 16:55:47 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 12 May 2016 22:55:47 +0600
Subject: [squid-users] squid-users Digest, Vol 21, Issue 54
In-Reply-To: <OF9B951B84.6929A4FD-ON80257FB1.005C1CE1-80257FB1.005C5699@tcs.com>
References: <mailman.21441.1463070882.2892.squid-users@lists.squid-cache.org>
 <OF9B951B84.6929A4FD-ON80257FB1.005C1CE1-80257FB1.005C5699@tcs.com>
Message-ID: <27d6af04-7c67-0b8e-968f-2b3e7828200c@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Condolences. Windows is not the most common platform for Squid.

But personally I do not see a fundamental difference in the
implementation of authentication with AD on Windows or Unix. You have
already tried something to do or so, looking ready-to-use configuration?


12.05.16 23:15, Nilesh Gavali ?????:
> Hello Antony;
> we have Squid 3.5 on Windows 2012 R2 OS & for which I need to
integrate squid with AD. I search online but all of the link are based
on linux platform squid.
> I am looking for squid running on Windows Platform which need to
integrate with AD authentication.
>
> Thanks & Regards
> Nilesh Suresh Gavali
>
>
>
> From:        squid-users-request at lists.squid-cache.org
> To:        squid-users at lists.squid-cache.org
> Date:        12/05/2016 17:33
> Subject:        squid-users Digest, Vol 21, Issue 54
> Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org>
> -------------------------
>
>
>
> Send squid-users mailing list submissions to
>                 squid-users at lists.squid-cache.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>                 http://lists.squid-cache.org/listinfo/squid-users
> or, via email, send a message with subject or body 'help' to
>                 squid-users-request at lists.squid-cache.org
>
> You can reach the person managing the list at
>                 squid-users-owner at lists.squid-cache.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of squid-users digest..."
>
>
> Today's Topics:
>
>   1. Re: Problems configuring Squid with C-ICAP+Squidclamav
>      (SOLVED) (Amos Jeffries)
>   2. Re: Linking with *SSL (Spil Oss)
>   3. Re: Getting the full file content on a range
request,                 but not
>      on EVERY get ... (Hans-Peter Jansen)
>   4. Windows Squid with AD authentication (Nilesh Gavali)
>   5. Re: Getting the full file content on a range request, but not
>      on EVERY get ... (Heiler Bemerguy)
>   6. Re: Windows Squid with AD authentication (Antony Stone)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Fri, 13 May 2016 00:00:05 +1200
> From: Amos Jeffries <squid3 at treenet.co.nz>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Problems configuring Squid with
>                 C-ICAP+Squidclamav (SOLVED)
> Message-ID: <dc535419-e24f-b6ee-00ac-45970ec67304 at treenet.co.nz>
> Content-Type: text/plain; charset=utf-8
>
> On 12/05/2016 11:13 p.m., C. L. Martinez wrote:
> >
> > But when squid sents an OPTIONS request to ICAP, why works when I
use 127.0.0.1 and not localhost?? Maybe it is a problem with openbsd's
package ...
> >
>
> It is quite possible. 127.0.0.1 is not the only address modern computers
> use for localhost. Double check what your hosts file contains.
>
> Amos
>
>
>
> ------------------------------
>
> Message: 2
> Date: Thu, 12 May 2016 15:33:30 +0200
> From: Spil Oss <spil.oss at gmail.com>
> To: squid-users at lists.squid-cache.org, timp87 at gmail.com
> Subject: Re: [squid-users] Linking with *SSL
> Message-ID:
>                
<CAEJyAvM8O6uVCgSipvzXAK1OsUrH3izc7BVTgaS0kPkWmAn3BQ at mail.gmail.com>
> Content-Type: text/plain; charset=UTF-8
>
> > Hi!
> > When we worked on squid port on FreeBSD one of the FreeBSD user
> > (Bernard Spil) noticed:
> >
> > When working on this, I ran into another issue. Perhaps maintainer can
> > fix that with upstream. I've now added LIBOPENSSL_LIBS="-lcrypto
> > -lssl" because of configure failing in configure.ac line 1348.
> >
> > > AC_CHECK_LIB(ssl,[SSL_library_init],[LIBOPENSSL_LIBS="-lssl
$LIBOPENSSL_LIBS"],[AC_MSG_ERROR([library 'ssl' is required for OpenSSL])
> >
> > You cannot link against libssl when not linking libcrypto as well
> > leading to an error with LibreSSL. This check should add -lcrypto in
> > addition to -lssl to pass.
> >
> > Is this something someone could take a look at?
>
> Hi All,
>
> Sorry for replying out-of-thread.
>
> What happens is that the check for SSL_library_init fails as -lcrypto
> is missing.
>
> Output from configure
>
> > checking for CRYPTO_new_ex_data in -lcrypto... yes
> > checking for SSL_library_init in -lssl... no
> > configure: error: library 'ssl' is required for OpenSSL
> > ===>  Script "configure" failed unexpectedly.
>
> What I usually see in autoconf scripts is that temp CFLAGS etc are set
> before the test for SSL libs and reversed after the test.
>
> Adding LIBOPENSSL_LIBS="-lcrypto -lssl" to configure works as well
>
> Would be great if you can fix this!
>
> Thanks,
>
> Bernard Spil.
> https://wiki.freebsd.org/BernardSpil
> https://wiki.freebsd.org/LibreSSL
> https://wiki.freebsd.org/OpenSSL
>
>
> ------------------------------
>
> Message: 3
> Date: Thu, 12 May 2016 16:06:40 +0200
> From: Hans-Peter Jansen <hpj at urpla.net>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Getting the full file content on a range
>                 request,                 but not on EVERY get ...
> Message-ID: <2575073.4c7f0552JP at xrated>
> Content-Type: text/plain; charset="us-ascii"
>
> On Mittwoch, 11. Mai 2016 21:37:17 Heiler Bemerguy wrote:
> > Hey guys,
> >
> > First take a look at the log:
> >
> > root at proxy:/var/log/squid# tail -f access.log |grep
> >
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt->
BR/firefox-45.0.1.complete.mar 1463011781.572   8776 10.1.3.236 TCP_MISS/206
> > 300520 GET
> [...]
> > Now think: An user is just doing a segmented/ranged download, right?
> > Squid won't cache the file because it is a range-download, not a full
> > file download.
> > But I WANT squid to cache it. So I decide to use "range_offset_limit
> > -1", but then on every GET squid will re-download the file from the
> > beginning, opening LOTs of simultaneous connections and using too much
> > bandwidth, doing just the OPPOSITE it's meant to!
> >
> > Is there a smart way to allow squid to download it from the beginning to
> > the end (to actually cache it), but only on the FIRST request/get? Even
> > if it makes the user wait for the full download, or cancel it
> > temporarily, or.. whatever!! Anything!!
>
> Well, this is exactly, what my squid_dedup helper was created for!
>
> See my announcement:
>
>                 Subject: [squid-users] New StoreID helper: squid_dedup
>                 Date: Mon, 09 May 2016 23:56:45 +0200
>
> My openSUSE environment is fetching _all_ updates with byte-ranges
from many
> servers. Therefor, I created squid_dedup.
>
> Your specific config could look like this:
>
> /etc/squid/dedup/mozilla.conf:
> [mozilla]
> match: http\:\/\/download\.cdn\.mozilla\.net/(.*)
> replace: http://download.cdn.mozilla.net.%(intdomain)s/\1
<http://download.cdn.mozilla.net.%(intdomain)s//1>
> fetch: true
>
> The fetch parameter is unique among the other StoreID helper (AFAIK):
it is
> fetching the object after a certain delay with a pool of fetcher threads.
>
> The idea is: after the first access for an object, wait a bit (global
setting,
> default: 15 secs), and then fetch the whole thing once. It won't solve
> anything for the first client, but for all subsequent accesses.
>
> The fetcher avoids fetching anything more than once by checking the http
> headers.
>
> This is a pretty new project, but be assured, that the basic functions are
> working fine, and I will do my best to solve any upcoming issues. It is
> implemented with Python3 and prepared for supporting additional features
> easily, while keeping a good part of an eye on efficiency.
>
> Let me know, if you're going to try it.
>
> Pete
>
>
> ------------------------------
>
> Message: 4
> Date: Thu, 12 May 2016 17:46:36 +0100
> From: Nilesh Gavali <nilesh.gavali at tcs.com>
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Windows Squid with AD authentication
> Message-ID:
>                
<OFC3392A46.462F0184-ON80257FB1.00598D57-80257FB1.0059AB8F at tcs.com>
> Content-Type: text/plain; charset="utf-8"
>
> Team;
> we have squid running on Windows and need to integrate it with Windows AD
> .can anyone help me with steps to be perform to get this done.
>
> Thanks & Regards
> Nilesh Suresh Gavali
> =====-----=====-----=====
> Notice: The information contained in this e-mail
> message and/or attachments to it may contain
> confidential or privileged information. If you are
> not the intended recipient, any dissemination, use,
> review, distribution, printing or copying of the
> information contained in this e-mail message
> and/or attachments to it are strictly prohibited. If
> you have received this communication in error,
> please notify us by reply e-mail or telephone and
> immediately and permanently delete the message
> and any attachments. Thank you
>
>
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL:
<http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/327a38cb/attachment-0001.html>
>
> ------------------------------
>
> Message: 5
> Date: Thu, 12 May 2016 13:28:00 -0300
> From: Heiler Bemerguy <heiler.bemerguy at cinbesa.com.br>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Getting the full file content on a range
>                 request, but not on EVERY get ...
> Message-ID: <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c at cinbesa.com.br>
> Content-Type: text/plain; charset="utf-8"; Format="flowed"
>
>
> Hi Pete, thanks for replying... let me see if I got it right..
>
> Will I need to specify every url/domain I want it to act on ? I want
> squid to do it for every range-request downloads that should/would be
> cached (based on other rules, pattern_refreshs etc)
>
> It doesn't need to delay any downloads as long as it isn't a dupe of
> what's already being downloaded.....
>
>
> Best Regards,
>
>
> --
> Heiler Bemerguy - (91) 98151-4894
> Assessor T?cnico - CINBESA (91) 3184-1751
>
>
> Em 12/05/2016 11:06, Hans-Peter Jansen escreveu:
> > On Mittwoch, 11. Mai 2016 21:37:17 Heiler Bemerguy wrote:
> >> Hey guys,
> >>
> >> First take a look at the log:
> >>
> >> root at proxy:/var/log/squid# tail -f access.log |grep
> >>
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt->
BR/firefox-45.0.1.complete.mar 1463011781.572   8776 10.1.3.236 TCP_MISS/206
> >> 300520 GET
> > [...]
> >> Now think: An user is just doing a segmented/ranged download, right?
> >> Squid won't cache the file because it is a range-download, not a full
> >> file download.
> >> But I WANT squid to cache it. So I decide to use "range_offset_limit
> >> -1", but then on every GET squid will re-download the file from the
> >> beginning, opening LOTs of simultaneous connections and using too much
> >> bandwidth, doing just the OPPOSITE it's meant to!
> >>
> >> Is there a smart way to allow squid to download it from the
beginning to
> >> the end (to actually cache it), but only on the FIRST request/get? Even
> >> if it makes the user wait for the full download, or cancel it
> >> temporarily, or.. whatever!! Anything!!
> > Well, this is exactly, what my squid_dedup helper was created for!
> >
> > See my announcement:
> >
> >                  Subject: [squid-users] New StoreID helper: squid_dedup
> >                  Date: Mon, 09 May 2016 23:56:45 +0200
> >
> > My openSUSE environment is fetching _all_ updates with byte-ranges
from many
> > servers. Therefor, I created squid_dedup.
> >
> > Your specific config could look like this:
> >
> > /etc/squid/dedup/mozilla.conf:
> > [mozilla]
> > match: http\:\/\/download\.cdn\.mozilla\.net/(.*)
> > replace: http://download.cdn.mozilla.net.%(intdomain)s/\1
<http://download.cdn.mozilla.net.%(intdomain)s//1>
> > fetch: true
> >
> > The fetch parameter is unique among the other StoreID helper
(AFAIK): it is
> > fetching the object after a certain delay with a pool of fetcher
threads.
> >
> > The idea is: after the first access for an object, wait a bit
(global setting,
> > default: 15 secs), and then fetch the whole thing once. It won't solve
> > anything for the first client, but for all subsequent accesses.
> >
> > The fetcher avoids fetching anything more than once by checking the http
> > headers.
> >
> > This is a pretty new project, but be assured, that the basic
functions are
> > working fine, and I will do my best to solve any upcoming issues. It is
> > implemented with Python3 and prepared for supporting additional features
> > easily, while keeping a good part of an eye on efficiency.
> >
> > Let me know, if you're going to try it.
> >
> > Pete
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL:
<http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/44b7d9df/attachment-0001.html>
>
> ------------------------------
>
> Message: 6
> Date: Thu, 12 May 2016 18:34:08 +0200
> From: Antony Stone <Antony.Stone at squid.open.source.it>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Windows Squid with AD authentication
> Message-ID: <201605121834.08490.Antony.Stone at squid.open.source.it>
> Content-Type: Text/Plain;  charset="iso-8859-15"
>
> On Thursday 12 May 2016 at 18:46:36, Nilesh Gavali wrote:
>
> > Team;
> > we have squid running on Windows and need to integrate it with
Windows AD
> > .can anyone help me with steps to be perform to get this done.
>
> This specific question has appeared a few times on this list only
recently.
>
> Have you so far:
>
> - searched the list archives for likely answers to your question?
>
> http://lists.squid-cache.org/pipermail/squid-users/
>
> - consulted the Squid documentation for guidance?
>
> http://www.squid-cache.org/Doc/
>
> - looked for any independent HOWTOs etc which show how people have
done this
> in the past?
>
> http://www.google.com/search?q=squid+active+directory+authentication
>
>
> Here's some friendly advice:
>
> 1. The more information you give us (such as: which version of Squid
are you
> using, which version of Windows are you running under, which form of
> authentication are you using?), the easier it is for people here to help.
>
> 2. If you have tried something already and run into problems, tell us
what you
> have tried and what problems (log file extracts, complete client error
message,
> etc) you encountered, so we can offer specific suggestions.
>
> 3. If you haven't yet tried to implement anything, at least let us
know what
> documentation you have looked up and what problems you encountered when
> following it, so we can try to fill in the gaps.
>
>
> Regards,
>
>
> Antony.
>
> --
> Most people have more than the average number of legs.
>
>                                                   Please reply to the
list;
>                                                         please *don't*
CC me.
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> ------------------------------
>
> End of squid-users Digest, Vol 21, Issue 54
> *******************************************
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXNLWTAAoJENNXIZxhPexGLs4IAIxzjIvko7Qcgr5sYPuSOl16
fpMti5wfA6jj5J+F3YuobYdzHIp20U08gNR4hWm/9cE1NEfOi1x08m87MEFyb/Nf
Ix2/S1Hfa34HCaEZpJbouk/27Ym5sgTIOF4x19IhJTaEiTiHKV4jq92uxvHZ1vNv
4R539OludR3iVDERhcIo8CeKh2KwfIMxLw/mlpZPMcm0+HdNV19tqUdsVyrWlmJ/
H6FIHsLEXTFM7Z4RlDDnaaRCI5pZJKikD87LjEkOe5a93e7IejpYM8yGKsDtk+zV
tnZr4vloal/xRC9LqRcrZi6EtEz1eB4DhMEjtJMwx59mbjNoJLxJaHocBj+ce/0=
=+Y8y
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/db5c07e2/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/db5c07e2/attachment.key>

From nilesh.gavali at tcs.com  Thu May 12 17:27:01 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Thu, 12 May 2016 18:27:01 +0100
Subject: [squid-users] Windows Squid with AD authentication
In-Reply-To: <mailman.21448.1463072178.2892.squid-users@lists.squid-cache.org>
References: <mailman.21448.1463072178.2892.squid-users@lists.squid-cache.org>
Message-ID: <OFF2576C43.D873058A-ON80257FB1.005D1DA9-80257FB1.005D5EF7@tcs.com>

Hello yuri;
I haven't tried it as didn't know from where to start, So need some 
documentation to start with , Squid on Widnows to be integrated with AD 
authentication..

Thanks & Regards
Nilesh Suresh Gavali




From:   squid-users-request at lists.squid-cache.org
To:     squid-users at lists.squid-cache.org
Date:   12/05/2016 17:55
Subject:        squid-users Digest, Vol 21, Issue 56
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org>



Send squid-users mailing list submissions to
                 squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
                 http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
                 squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
                 squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

   1. Re: squid-users Digest, Vol 21, Issue 54 (Yuri Voinov)


----------------------------------------------------------------------

Message: 1
Date: Thu, 12 May 2016 22:55:47 +0600
From: Yuri Voinov <yvoinov at gmail.com>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] squid-users Digest, Vol 21, Issue 54
Message-ID: <27d6af04-7c67-0b8e-968f-2b3e7828200c at gmail.com>
Content-Type: text/plain; charset="utf-8"


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Condolences. Windows is not the most common platform for Squid.

But personally I do not see a fundamental difference in the
implementation of authentication with AD on Windows or Unix. You have
already tried something to do or so, looking ready-to-use configuration?


12.05.16 23:15, Nilesh Gavali ?????:
> Hello Antony;
> we have Squid 3.5 on Windows 2012 R2 OS & for which I need to
integrate squid with AD. I search online but all of the link are based
on linux platform squid.
> I am looking for squid running on Windows Platform which need to
integrate with AD authentication.
>
> Thanks & Regards
> Nilesh Suresh Gavali
>
>
>
> From:        squid-users-request at lists.squid-cache.org
> To:        squid-users at lists.squid-cache.org
> Date:        12/05/2016 17:33
> Subject:        squid-users Digest, Vol 21, Issue 54
> Sent by:        "squid-users" 
<squid-users-bounces at lists.squid-cache.org>
> -------------------------
>
>
>
> Send squid-users mailing list submissions to
>                 squid-users at lists.squid-cache.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>                 http://lists.squid-cache.org/listinfo/squid-users
> or, via email, send a message with subject or body 'help' to
>                 squid-users-request at lists.squid-cache.org
>
> You can reach the person managing the list at
>                 squid-users-owner at lists.squid-cache.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of squid-users digest..."
>
>
> Today's Topics:
>
>   1. Re: Problems configuring Squid with C-ICAP+Squidclamav
>      (SOLVED) (Amos Jeffries)
>   2. Re: Linking with *SSL (Spil Oss)
>   3. Re: Getting the full file content on a range
request,                 but not
>      on EVERY get ... (Hans-Peter Jansen)
>   4. Windows Squid with AD authentication (Nilesh Gavali)
>   5. Re: Getting the full file content on a range request, but not
>      on EVERY get ... (Heiler Bemerguy)
>   6. Re: Windows Squid with AD authentication (Antony Stone)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Fri, 13 May 2016 00:00:05 +1200
> From: Amos Jeffries <squid3 at treenet.co.nz>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Problems configuring Squid with
>                 C-ICAP+Squidclamav (SOLVED)
> Message-ID: <dc535419-e24f-b6ee-00ac-45970ec67304 at treenet.co.nz>
> Content-Type: text/plain; charset=utf-8
>
> On 12/05/2016 11:13 p.m., C. L. Martinez wrote:
> >
> > But when squid sents an OPTIONS request to ICAP, why works when I
use 127.0.0.1 and not localhost?? Maybe it is a problem with openbsd's
package ...
> >
>
> It is quite possible. 127.0.0.1 is not the only address modern computers
> use for localhost. Double check what your hosts file contains.
>
> Amos
>
>
>
> ------------------------------
>
> Message: 2
> Date: Thu, 12 May 2016 15:33:30 +0200
> From: Spil Oss <spil.oss at gmail.com>
> To: squid-users at lists.squid-cache.org, timp87 at gmail.com
> Subject: Re: [squid-users] Linking with *SSL
> Message-ID:
> 
<CAEJyAvM8O6uVCgSipvzXAK1OsUrH3izc7BVTgaS0kPkWmAn3BQ at mail.gmail.com>
> Content-Type: text/plain; charset=UTF-8
>
> > Hi!
> > When we worked on squid port on FreeBSD one of the FreeBSD user
> > (Bernard Spil) noticed:
> >
> > When working on this, I ran into another issue. Perhaps maintainer can
> > fix that with upstream. I've now added LIBOPENSSL_LIBS="-lcrypto
> > -lssl" because of configure failing in configure.ac line 1348.
> >
> > > AC_CHECK_LIB(ssl,[SSL_library_init],[LIBOPENSSL_LIBS="-lssl
$LIBOPENSSL_LIBS"],[AC_MSG_ERROR([library 'ssl' is required for OpenSSL])
> >
> > You cannot link against libssl when not linking libcrypto as well
> > leading to an error with LibreSSL. This check should add -lcrypto in
> > addition to -lssl to pass.
> >
> > Is this something someone could take a look at?
>
> Hi All,
>
> Sorry for replying out-of-thread.
>
> What happens is that the check for SSL_library_init fails as -lcrypto
> is missing.
>
> Output from configure
>
> > checking for CRYPTO_new_ex_data in -lcrypto... yes
> > checking for SSL_library_init in -lssl... no
> > configure: error: library 'ssl' is required for OpenSSL
> > ===>  Script "configure" failed unexpectedly.
>
> What I usually see in autoconf scripts is that temp CFLAGS etc are set
> before the test for SSL libs and reversed after the test.
>
> Adding LIBOPENSSL_LIBS="-lcrypto -lssl" to configure works as well
>
> Would be great if you can fix this!
>
> Thanks,
>
> Bernard Spil.
> https://wiki.freebsd.org/BernardSpil
> https://wiki.freebsd.org/LibreSSL
> https://wiki.freebsd.org/OpenSSL
>
>
> ------------------------------
>
> Message: 3
> Date: Thu, 12 May 2016 16:06:40 +0200
> From: Hans-Peter Jansen <hpj at urpla.net>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Getting the full file content on a range
>                 request,                 but not on EVERY get ...
> Message-ID: <2575073.4c7f0552JP at xrated>
> Content-Type: text/plain; charset="us-ascii"
>
> On Mittwoch, 11. Mai 2016 21:37:17 Heiler Bemerguy wrote:
> > Hey guys,
> >
> > First take a look at the log:
> >
> > root at proxy:/var/log/squid# tail -f access.log |grep
> >
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>
BR/firefox-45.0.1.complete.mar 1463011781.572   8776 10.1.3.236 
TCP_MISS/206
> > 300520 GET
> [...]
> > Now think: An user is just doing a segmented/ranged download, right?
> > Squid won't cache the file because it is a range-download, not a full
> > file download.
> > But I WANT squid to cache it. So I decide to use "range_offset_limit
> > -1", but then on every GET squid will re-download the file from the
> > beginning, opening LOTs of simultaneous connections and using too much
> > bandwidth, doing just the OPPOSITE it's meant to!
> >
> > Is there a smart way to allow squid to download it from the beginning 
to
> > the end (to actually cache it), but only on the FIRST request/get? 
Even
> > if it makes the user wait for the full download, or cancel it
> > temporarily, or.. whatever!! Anything!!
>
> Well, this is exactly, what my squid_dedup helper was created for!
>
> See my announcement:
>
>                 Subject: [squid-users] New StoreID helper: squid_dedup
>                 Date: Mon, 09 May 2016 23:56:45 +0200
>
> My openSUSE environment is fetching _all_ updates with byte-ranges
from many
> servers. Therefor, I created squid_dedup.
>
> Your specific config could look like this:
>
> /etc/squid/dedup/mozilla.conf:
> [mozilla]
> match: http\:\/\/download\.cdn\.mozilla\.net/(.*)
> replace: http://download.cdn.mozilla.net.%(intdomain)s/\1
<http://download.cdn.mozilla.net.%(intdomain)s//1>
> fetch: true
>
> The fetch parameter is unique among the other StoreID helper (AFAIK):
it is
> fetching the object after a certain delay with a pool of fetcher 
threads.
>
> The idea is: after the first access for an object, wait a bit (global
setting,
> default: 15 secs), and then fetch the whole thing once. It won't solve
> anything for the first client, but for all subsequent accesses.
>
> The fetcher avoids fetching anything more than once by checking the http
> headers.
>
> This is a pretty new project, but be assured, that the basic functions 
are
> working fine, and I will do my best to solve any upcoming issues. It is
> implemented with Python3 and prepared for supporting additional features
> easily, while keeping a good part of an eye on efficiency.
>
> Let me know, if you're going to try it.
>
> Pete
>
>
> ------------------------------
>
> Message: 4
> Date: Thu, 12 May 2016 17:46:36 +0100
> From: Nilesh Gavali <nilesh.gavali at tcs.com>
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Windows Squid with AD authentication
> Message-ID:
> 
<OFC3392A46.462F0184-ON80257FB1.00598D57-80257FB1.0059AB8F at tcs.com>
> Content-Type: text/plain; charset="utf-8"
>
> Team;
> we have squid running on Windows and need to integrate it with Windows 
AD
> .can anyone help me with steps to be perform to get this done.
>
> Thanks & Regards
> Nilesh Suresh Gavali
> =====-----=====-----=====
> Notice: The information contained in this e-mail
> message and/or attachments to it may contain
> confidential or privileged information. If you are
> not the intended recipient, any dissemination, use,
> review, distribution, printing or copying of the
> information contained in this e-mail message
> and/or attachments to it are strictly prohibited. If
> you have received this communication in error,
> please notify us by reply e-mail or telephone and
> immediately and permanently delete the message
> and any attachments. Thank you
>
>
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL:
<
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/327a38cb/attachment-0001.html
>
>
> ------------------------------
>
> Message: 5
> Date: Thu, 12 May 2016 13:28:00 -0300
> From: Heiler Bemerguy <heiler.bemerguy at cinbesa.com.br>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Getting the full file content on a range
>                 request, but not on EVERY get ...
> Message-ID: <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c at cinbesa.com.br>
> Content-Type: text/plain; charset="utf-8"; Format="flowed"
>
>
> Hi Pete, thanks for replying... let me see if I got it right..
>
> Will I need to specify every url/domain I want it to act on ? I want
> squid to do it for every range-request downloads that should/would be
> cached (based on other rules, pattern_refreshs etc)
>
> It doesn't need to delay any downloads as long as it isn't a dupe of
> what's already being downloaded.....
>
>
> Best Regards,
>
>
> --
> Heiler Bemerguy - (91) 98151-4894
> Assessor T?cnico - CINBESA (91) 3184-1751
>
>
> Em 12/05/2016 11:06, Hans-Peter Jansen escreveu:
> > On Mittwoch, 11. Mai 2016 21:37:17 Heiler Bemerguy wrote:
> >> Hey guys,
> >>
> >> First take a look at the log:
> >>
> >> root at proxy:/var/log/squid# tail -f access.log |grep
> >>
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>
BR/firefox-45.0.1.complete.mar 1463011781.572   8776 10.1.3.236 
TCP_MISS/206
> >> 300520 GET
> > [...]
> >> Now think: An user is just doing a segmented/ranged download, right?
> >> Squid won't cache the file because it is a range-download, not a full
> >> file download.
> >> But I WANT squid to cache it. So I decide to use "range_offset_limit
> >> -1", but then on every GET squid will re-download the file from the
> >> beginning, opening LOTs of simultaneous connections and using too 
much
> >> bandwidth, doing just the OPPOSITE it's meant to!
> >>
> >> Is there a smart way to allow squid to download it from the
beginning to
> >> the end (to actually cache it), but only on the FIRST request/get? 
Even
> >> if it makes the user wait for the full download, or cancel it
> >> temporarily, or.. whatever!! Anything!!
> > Well, this is exactly, what my squid_dedup helper was created for!
> >
> > See my announcement:
> >
> >                  Subject: [squid-users] New StoreID helper: 
squid_dedup
> >                  Date: Mon, 09 May 2016 23:56:45 +0200
> >
> > My openSUSE environment is fetching _all_ updates with byte-ranges
from many
> > servers. Therefor, I created squid_dedup.
> >
> > Your specific config could look like this:
> >
> > /etc/squid/dedup/mozilla.conf:
> > [mozilla]
> > match: http\:\/\/download\.cdn\.mozilla\.net/(.*)
> > replace: http://download.cdn.mozilla.net.%(intdomain)s/\1
<http://download.cdn.mozilla.net.%(intdomain)s//1>
> > fetch: true
> >
> > The fetch parameter is unique among the other StoreID helper
(AFAIK): it is
> > fetching the object after a certain delay with a pool of fetcher
threads.
> >
> > The idea is: after the first access for an object, wait a bit
(global setting,
> > default: 15 secs), and then fetch the whole thing once. It won't solve
> > anything for the first client, but for all subsequent accesses.
> >
> > The fetcher avoids fetching anything more than once by checking the 
http
> > headers.
> >
> > This is a pretty new project, but be assured, that the basic
functions are
> > working fine, and I will do my best to solve any upcoming issues. It 
is
> > implemented with Python3 and prepared for supporting additional 
features
> > easily, while keeping a good part of an eye on efficiency.
> >
> > Let me know, if you're going to try it.
> >
> > Pete
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL:
<
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/44b7d9df/attachment-0001.html
>
>
> ------------------------------
>
> Message: 6
> Date: Thu, 12 May 2016 18:34:08 +0200
> From: Antony Stone <Antony.Stone at squid.open.source.it>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Windows Squid with AD authentication
> Message-ID: <201605121834.08490.Antony.Stone at squid.open.source.it>
> Content-Type: Text/Plain;  charset="iso-8859-15"
>
> On Thursday 12 May 2016 at 18:46:36, Nilesh Gavali wrote:
>
> > Team;
> > we have squid running on Windows and need to integrate it with
Windows AD
> > .can anyone help me with steps to be perform to get this done.
>
> This specific question has appeared a few times on this list only
recently.
>
> Have you so far:
>
> - searched the list archives for likely answers to your question?
>
> http://lists.squid-cache.org/pipermail/squid-users/
>
> - consulted the Squid documentation for guidance?
>
> http://www.squid-cache.org/Doc/
>
> - looked for any independent HOWTOs etc which show how people have
done this
> in the past?
>
> http://www.google.com/search?q=squid+active+directory+authentication
>
>
> Here's some friendly advice:
>
> 1. The more information you give us (such as: which version of Squid
are you
> using, which version of Windows are you running under, which form of
> authentication are you using?), the easier it is for people here to 
help.
>
> 2. If you have tried something already and run into problems, tell us
what you
> have tried and what problems (log file extracts, complete client error
message,
> etc) you encountered, so we can offer specific suggestions.
>
> 3. If you haven't yet tried to implement anything, at least let us
know what
> documentation you have looked up and what problems you encountered when
> following it, so we can try to fill in the gaps.
>
>
> Regards,
>
>
> Antony.
>
> --
> Most people have more than the average number of legs.
>
>                                                   Please reply to the
list;
>                                                         please *don't*
CC me.
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> ------------------------------
>
> End of squid-users Digest, Vol 21, Issue 54
> *******************************************
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXNLWTAAoJENNXIZxhPexGLs4IAIxzjIvko7Qcgr5sYPuSOl16
fpMti5wfA6jj5J+F3YuobYdzHIp20U08gNR4hWm/9cE1NEfOi1x08m87MEFyb/Nf
Ix2/S1Hfa34HCaEZpJbouk/27Ym5sgTIOF4x19IhJTaEiTiHKV4jq92uxvHZ1vNv
4R539OludR3iVDERhcIo8CeKh2KwfIMxLw/mlpZPMcm0+HdNV19tqUdsVyrWlmJ/
H6FIHsLEXTFM7Z4RlDDnaaRCI5pZJKikD87LjEkOe5a93e7IejpYM8yGKsDtk+zV
tnZr4vloal/xRC9LqRcrZi6EtEz1eB4DhMEjtJMwx59mbjNoJLxJaHocBj+ce/0=
=+Y8y
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/db5c07e2/attachment.html
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/db5c07e2/attachment.key
>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 21, Issue 56
*******************************************


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/cbc27ad4/attachment.htm>

From heiler.bemerguy at cinbesa.com.br  Thu May 12 17:02:31 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Thu, 12 May 2016 14:02:31 -0300
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <1463025679.14398.4.camel@comnet.uz>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <1463025679.14398.4.camel@comnet.uz>
Message-ID: <b1a15d16-acdd-7009-f790-90e35ed9734b@cinbesa.com.br>


Hi Garri,

That bug report is mine.. lol

But I couldn't keep testing it to confirm if the problem was about 
ABORTING downloads or just trying to download what's already being 
downloaded...

When you use quick_abort_min -1, it seems to "fix" the caching issue 
itself, but it won't prevent the concurrent downloads, which sucks up 
the link..

I don't know if it won't happen with aufs/ufs, I'm using only rock 
store.....


-- 
Heiler Bemerguy - (91) 98151-4894
Assessor T?cnico - CINBESA (91) 3184-1751


Em 12/05/2016 01:01, Garri Djavadyan escreveu:
> On Wed, 2016-05-11 at 21:37 -0300, Heiler Bemerguy wrote:
>> Hey guys,
>> First take a look at the log:
>> root at proxy:/var/log/squid# tail -f access.log |grep http://download.c
>> dn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>> BR/firefox-45.0.1.complete.mar
>> 1463011781.572   8776 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.9
>> application/octet-stream
>> 1463011851.008   9347 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
>> application/octet-stream
>> 1463011920.683   9645 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.9
>> application/octet-stream
>> 1463012000.144  19154 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
>> application/octet-stream
>> 1463012072.276  12121 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
>> application/octet-stream
>> 1463012145.643  13358 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
>> application/octet-stream
>> 1463012217.472  11772 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
>> application/octet-stream
>> 1463012294.676  17148 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
>> application/octet-stream
>> 1463012370.131  15272 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
>> application/octet-stream
>> Now think: An user is just doing a segmented/ranged download, right?
>> Squid won't cache the file because it is a range-download, not a full
>> file download.
>> But I WANT squid to cache it. So I decide to use "range_offset_limit
>> -1", but then on every GET squid will re-download the file from the
>> beginning, opening LOTs of simultaneous connections and using too
>> much bandwidth, doing just the OPPOSITE it's meant to!
>>
>> Is there a smart way to allow squid to download it from the beginning
>> to the end (to actually cache it), but only on the FIRST request/get?
>> Even if it makes the user wait for the full download, or cancel it
>> temporarily, or.. whatever!! Anything!!
>>
>> Best Regards,
>> -- 
>> Heiler Bemerguy - (91) 98151-4894
>> Assessor T?cnico - CINBESA (91) 3184-1751
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> Hi, I believe, you describe the bug http://bugs.squid-cache.org/show_bu
> g.cgi?id=4469
>
> I tried to reproduce the problem and have found that the problem
> appears only with rock storage configurations. Can you try with
> ufs/aufs storage?
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/172c08dd/attachment.htm>

From yvoinov at gmail.com  Thu May 12 17:09:20 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 12 May 2016 23:09:20 +0600
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <b1a15d16-acdd-7009-f790-90e35ed9734b@cinbesa.com.br>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <1463025679.14398.4.camel@comnet.uz>
 <b1a15d16-acdd-7009-f790-90e35ed9734b@cinbesa.com.br>
Message-ID: <bfe2bf6b-089a-796e-1220-b22d2ffaa18c@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
IMO better to use

range_offset_limit none !dont_cache_url all

to improve selectivity between non-cached and cached URL's with ACL's....


12.05.16 23:02, Heiler Bemerguy ?????:
>
>
> Hi Garri,
>
> That bug report is mine.. lol
>
> But I couldn't keep testing it to confirm if the problem was about
ABORTING downloads or just trying to download what's already being
downloaded...
>
> When you use quick_abort_min -1, it seems to "fix" the caching issue
itself, but it won't prevent the concurrent downloads, which sucks up
the link..
>
> I don't know if it won't happen with aufs/ufs, I'm using only rock
store.....
>
>
> --
> Heiler Bemerguy - (91) 98151-4894
> Assessor T?cnico - CINBESA (91) 3184-1751
>
> Em 12/05/2016 01:01, Garri Djavadyan escreveu:
>> On Wed, 2016-05-11 at 21:37 -0300, Heiler Bemerguy wrote:
>>> Hey guys,
>>> First take a look at the log:
>>> root at proxy:/var/log/squid# tail -f access.log |grep http://download.c
>>> dn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>>> BR/firefox-45.0.1.complete.mar
>>> 1463011781.572   8776 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.9
>>> application/octet-stream
>>> 1463011851.008   9347 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
>>> application/octet-stream
>>> 1463011920.683   9645 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.9
>>> application/octet-stream
>>> 1463012000.144  19154 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
>>> application/octet-stream
>>> 1463012072.276  12121 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
>>> application/octet-stream
>>> 1463012145.643  13358 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
>>> application/octet-stream
>>> 1463012217.472  11772 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
>>> application/octet-stream
>>> 1463012294.676  17148 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
>>> application/octet-stream
>>> 1463012370.131  15272 10.1.3.236 TCP_MISS/206 300520 GET http://downl
>>> oad.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt-
>>> BR/firefox-45.0.1.complete.mar - HIER_DIRECT/200.216.8.32
>>> application/octet-stream
>>> Now think: An user is just doing a segmented/ranged download, right?
>>> Squid won't cache the file because it is a range-download, not a full
>>> file download.
>>> But I WANT squid to cache it. So I decide to use "range_offset_limit
>>> -1", but then on every GET squid will re-download the file from the
>>> beginning, opening LOTs of simultaneous connections and using too
>>> much bandwidth, doing just the OPPOSITE it's meant to!
>>>
>>> Is there a smart way to allow squid to download it from the beginning
>>> to the end (to actually cache it), but only on the FIRST request/get?
>>> Even if it makes the user wait for the full download, or cancel it
>>> temporarily, or.. whatever!! Anything!!
>>>
>>> Best Regards,
>>> --
>>> Heiler Bemerguy - (91) 98151-4894
>>> Assessor T?cnico - CINBESA (91) 3184-1751
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> Hi, I believe, you describe the bug http://bugs.squid-cache.org/show_bu
>> g.cgi?id=4469
>>
>> I tried to reproduce the problem and have found that the problem
>> appears only with rock storage configurations. Can you try with
>> ufs/aufs storage?
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXNLi/AAoJENNXIZxhPexG5aAH/juZyvly/aSIguez9dAKPbbb
AHpPxoky36FYOjlPbqmXjdrMPs9qNGT+Ns7WDxsNZFM0Cfbh5UgBfQc64kFoV0k/
qKseFzDLfSqbL6ppEAg3yh4/NUsBYtjT7hwBzNIUso+OM++vAQ5dJygtIWwFMRmC
nSDgjTaYD/7r2JPOTEtfW8mhbC148tVaq/jAZqsefYji90vnXyLtIW5hUCcTw3nG
L3PWJVhYOgSixD3K2tWu1rpgoK0F0+sqp0xqfh2Vz6BUvNIrB40k3qL7cEUnAPsH
CV/O39f+yr/ggoyOmKcsVv4oQ6i2Q+eEDdy4ML7ed0mNO8nXWx1ORkgMzcxHm6Q=
=NO6/
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/8ab7f52d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/8ab7f52d/attachment.key>

From yvoinov at gmail.com  Thu May 12 17:23:24 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 12 May 2016 23:23:24 +0600
Subject: [squid-users] Windows Squid with AD authentication
In-Reply-To: <OFF2576C43.D873058A-ON80257FB1.005D1DA9-80257FB1.005D5EF7@tcs.com>
References: <mailman.21448.1463072178.2892.squid-users@lists.squid-cache.org>
 <OFF2576C43.D873058A-ON80257FB1.005D1DA9-80257FB1.005D5EF7@tcs.com>
Message-ID: <4c4883d4-bcef-9c64-19f1-8d66dd919716@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Hm.

We have Wiki: http://wiki.squid-cache.org/ConfigExamples#Authentication

with some examples. Is this hepls?

12.05.16 23:27, Nilesh Gavali ?????:
> Hello yuri;
> I haven't tried it as didn't know from where to start, So need some
documentation to start with , Squid on Widnows to be integrated with AD
authentication..
>
> Thanks & Regards
> Nilesh Suresh Gavali
>
>
>
>
> From:        squid-users-request at lists.squid-cache.org
> To:        squid-users at lists.squid-cache.org
> Date:        12/05/2016 17:55
> Subject:        squid-users Digest, Vol 21, Issue 56
> Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org>
> -------------------------
>
>
>
> Send squid-users mailing list submissions to
>                 squid-users at lists.squid-cache.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>                 http://lists.squid-cache.org/listinfo/squid-users
> or, via email, send a message with subject or body 'help' to
>                 squid-users-request at lists.squid-cache.org
>
> You can reach the person managing the list at
>                 squid-users-owner at lists.squid-cache.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of squid-users digest..."
>
>
> Today's Topics:
>
>   1. Re: squid-users Digest, Vol 21, Issue 54 (Yuri Voinov)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Thu, 12 May 2016 22:55:47 +0600
> From: Yuri Voinov <yvoinov at gmail.com>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] squid-users Digest, Vol 21, Issue 54
> Message-ID: <27d6af04-7c67-0b8e-968f-2b3e7828200c at gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
>
> Condolences. Windows is not the most common platform for Squid.
>
> But personally I do not see a fundamental difference in the
> implementation of authentication with AD on Windows or Unix. You have
> already tried something to do or so, looking ready-to-use configuration?
>
>
> 12.05.16 23:15, Nilesh Gavali ?????:
> > Hello Antony;
> > we have Squid 3.5 on Windows 2012 R2 OS & for which I need to
> integrate squid with AD. I search online but all of the link are based
> on linux platform squid.
> > I am looking for squid running on Windows Platform which need to
> integrate with AD authentication.
>
> > Thanks & Regards
> > Nilesh Suresh Gavali
>
>
>
> > From:        squid-users-request at lists.squid-cache.org
> > To:        squid-users at lists.squid-cache.org
> > Date:        12/05/2016 17:33
> > Subject:        squid-users Digest, Vol 21, Issue 54
> > Sent by:        "squid-users"
<squid-users-bounces at lists.squid-cache.org>
> > -------------------------
>
>
>
> > Send squid-users mailing list submissions to
> >                 squid-users at lists.squid-cache.org
>
> > To subscribe or unsubscribe via the World Wide Web, visit
> >                 http://lists.squid-cache.org/listinfo/squid-users
> > or, via email, send a message with subject or body 'help' to
> >                 squid-users-request at lists.squid-cache.org
>
> > You can reach the person managing the list at
> >                 squid-users-owner at lists.squid-cache.org
>
> > When replying, please edit your Subject line so it is more specific
> > than "Re: Contents of squid-users digest..."
>
>
> > Today's Topics:
>
> >   1. Re: Problems configuring Squid with C-ICAP+Squidclamav
> >      (SOLVED) (Amos Jeffries)
> >   2. Re: Linking with *SSL (Spil Oss)
> >   3. Re: Getting the full file content on a range
> request,                 but not
> >      on EVERY get ... (Hans-Peter Jansen)
> >   4. Windows Squid with AD authentication (Nilesh Gavali)
> >   5. Re: Getting the full file content on a range request, but not
> >      on EVERY get ... (Heiler Bemerguy)
> >   6. Re: Windows Squid with AD authentication (Antony Stone)
>
>
> > ----------------------------------------------------------------------
>
> > Message: 1
> > Date: Fri, 13 May 2016 00:00:05 +1200
> > From: Amos Jeffries <squid3 at treenet.co.nz>
> > To: squid-users at lists.squid-cache.org
> > Subject: Re: [squid-users] Problems configuring Squid with
> >                 C-ICAP+Squidclamav (SOLVED)
> > Message-ID: <dc535419-e24f-b6ee-00ac-45970ec67304 at treenet.co.nz>
> > Content-Type: text/plain; charset=utf-8
>
> > On 12/05/2016 11:13 p.m., C. L. Martinez wrote:
> > >
> > > But when squid sents an OPTIONS request to ICAP, why works when I
> use 127.0.0.1 and not localhost?? Maybe it is a problem with openbsd's
> package ...
> > >
>
> > It is quite possible. 127.0.0.1 is not the only address modern computers
> > use for localhost. Double check what your hosts file contains.
>
> > Amos
>
>
>
> > ------------------------------
>
> > Message: 2
> > Date: Thu, 12 May 2016 15:33:30 +0200
> > From: Spil Oss <spil.oss at gmail.com>
> > To: squid-users at lists.squid-cache.org, timp87 at gmail.com
> > Subject: Re: [squid-users] Linking with *SSL
> > Message-ID:
>
> <CAEJyAvM8O6uVCgSipvzXAK1OsUrH3izc7BVTgaS0kPkWmAn3BQ at mail.gmail.com>
> > Content-Type: text/plain; charset=UTF-8
>
> > > Hi!
> > > When we worked on squid port on FreeBSD one of the FreeBSD user
> > > (Bernard Spil) noticed:
> > >
> > > When working on this, I ran into another issue. Perhaps maintainer can
> > > fix that with upstream. I've now added LIBOPENSSL_LIBS="-lcrypto
> > > -lssl" because of configure failing in configure.ac line 1348.
> > >
> > > > AC_CHECK_LIB(ssl,[SSL_library_init],[LIBOPENSSL_LIBS="-lssl
> $LIBOPENSSL_LIBS"],[AC_MSG_ERROR([library 'ssl' is required for OpenSSL])
> > >
> > > You cannot link against libssl when not linking libcrypto as well
> > > leading to an error with LibreSSL. This check should add -lcrypto in
> > > addition to -lssl to pass.
> > >
> > > Is this something someone could take a look at?
>
> > Hi All,
>
> > Sorry for replying out-of-thread.
>
> > What happens is that the check for SSL_library_init fails as -lcrypto
> > is missing.
>
> > Output from configure
>
> > > checking for CRYPTO_new_ex_data in -lcrypto... yes
> > > checking for SSL_library_init in -lssl... no
> > > configure: error: library 'ssl' is required for OpenSSL
> > > ===>  Script "configure" failed unexpectedly.
>
> > What I usually see in autoconf scripts is that temp CFLAGS etc are set
> > before the test for SSL libs and reversed after the test.
>
> > Adding LIBOPENSSL_LIBS="-lcrypto -lssl" to configure works as well
>
> > Would be great if you can fix this!
>
> > Thanks,
>
> > Bernard Spil.
> > https://wiki.freebsd.org/BernardSpil
> > https://wiki.freebsd.org/LibreSSL
> > https://wiki.freebsd.org/OpenSSL
>
>
> > ------------------------------
>
> > Message: 3
> > Date: Thu, 12 May 2016 16:06:40 +0200
> > From: Hans-Peter Jansen <hpj at urpla.net>
> > To: squid-users at lists.squid-cache.org
> > Subject: Re: [squid-users] Getting the full file content on a range
> >                 request,                 but not on EVERY get ...
> > Message-ID: <2575073.4c7f0552JP at xrated>
> > Content-Type: text/plain; charset="us-ascii"
>
> > On Mittwoch, 11. Mai 2016 21:37:17 Heiler Bemerguy wrote:
> > > Hey guys,
> > >
> > > First take a look at the log:
> > >
> > > root at proxy:/var/log/squid# tail -f access.log |grep
> > >
>
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt->
> BR/firefox-45.0.1.complete.mar 1463011781.572   8776 10.1.3.236
TCP_MISS/206
> > > 300520 GET
> > [...]
> > > Now think: An user is just doing a segmented/ranged download, right?
> > > Squid won't cache the file because it is a range-download, not a full
> > > file download.
> > > But I WANT squid to cache it. So I decide to use "range_offset_limit
> > > -1", but then on every GET squid will re-download the file from the
> > > beginning, opening LOTs of simultaneous connections and using too much
> > > bandwidth, doing just the OPPOSITE it's meant to!
> > >
> > > Is there a smart way to allow squid to download it from the
beginning to
> > > the end (to actually cache it), but only on the FIRST request/get?
Even
> > > if it makes the user wait for the full download, or cancel it
> > > temporarily, or.. whatever!! Anything!!
>
> > Well, this is exactly, what my squid_dedup helper was created for!
>
> > See my announcement:
>
> >                 Subject: [squid-users] New StoreID helper: squid_dedup
> >                 Date: Mon, 09 May 2016 23:56:45 +0200
>
> > My openSUSE environment is fetching _all_ updates with byte-ranges
> from many
> > servers. Therefor, I created squid_dedup.
>
> > Your specific config could look like this:
>
> > /etc/squid/dedup/mozilla.conf:
> > [mozilla]
> > match: http\:\/\/download\.cdn\.mozilla\.net/(.*)
> > replace: http://download.cdn.mozilla.net.%(intdomain)s/\1
<http://download.cdn.mozilla.net.%(intdomain)s//1>
> <http://download.cdn.mozilla.net.%(intdomain)s//1>
> > fetch: true
>
> > The fetch parameter is unique among the other StoreID helper (AFAIK):
> it is
> > fetching the object after a certain delay with a pool of fetcher
threads.
>
> > The idea is: after the first access for an object, wait a bit (global
> setting,
> > default: 15 secs), and then fetch the whole thing once. It won't solve
> > anything for the first client, but for all subsequent accesses.
>
> > The fetcher avoids fetching anything more than once by checking the http
> > headers.
>
> > This is a pretty new project, but be assured, that the basic
functions are
> > working fine, and I will do my best to solve any upcoming issues. It is
> > implemented with Python3 and prepared for supporting additional features
> > easily, while keeping a good part of an eye on efficiency.
>
> > Let me know, if you're going to try it.
>
> > Pete
>
>
> > ------------------------------
>
> > Message: 4
> > Date: Thu, 12 May 2016 17:46:36 +0100
> > From: Nilesh Gavali <nilesh.gavali at tcs.com>
> > To: squid-users at lists.squid-cache.org
> > Subject: [squid-users] Windows Squid with AD authentication
> > Message-ID:
>
> <OFC3392A46.462F0184-ON80257FB1.00598D57-80257FB1.0059AB8F at tcs.com>
> > Content-Type: text/plain; charset="utf-8"
>
> > Team;
> > we have squid running on Windows and need to integrate it with
Windows AD
> > .can anyone help me with steps to be perform to get this done.
>
> > Thanks & Regards
> > Nilesh Suresh Gavali
> > =====-----=====-----=====
> > Notice: The information contained in this e-mail
> > message and/or attachments to it may contain
> > confidential or privileged information. If you are
> > not the intended recipient, any dissemination, use,
> > review, distribution, printing or copying of the
> > information contained in this e-mail message
> > and/or attachments to it are strictly prohibited. If
> > you have received this communication in error,
> > please notify us by reply e-mail or telephone and
> > immediately and permanently delete the message
> > and any attachments. Thank you
>
>
> > -------------- next part --------------
> > An HTML attachment was scrubbed...
> > URL:
>
<http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/327a38cb/attachment-0001.html>
>
> > ------------------------------
>
> > Message: 5
> > Date: Thu, 12 May 2016 13:28:00 -0300
> > From: Heiler Bemerguy <heiler.bemerguy at cinbesa.com.br>
> > To: squid-users at lists.squid-cache.org
> > Subject: Re: [squid-users] Getting the full file content on a range
> >                 request, but not on EVERY get ...
> > Message-ID: <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c at cinbesa.com.br>
> > Content-Type: text/plain; charset="utf-8"; Format="flowed"
>
>
> > Hi Pete, thanks for replying... let me see if I got it right..
>
> > Will I need to specify every url/domain I want it to act on ? I want
> > squid to do it for every range-request downloads that should/would be
> > cached (based on other rules, pattern_refreshs etc)
>
> > It doesn't need to delay any downloads as long as it isn't a dupe of
> > what's already being downloaded.....
>
>
> > Best Regards,
>
>
> > --
> > Heiler Bemerguy - (91) 98151-4894
> > Assessor T?cnico - CINBESA (91) 3184-1751
>
>
> > Em 12/05/2016 11:06, Hans-Peter Jansen escreveu:
> > > On Mittwoch, 11. Mai 2016 21:37:17 Heiler Bemerguy wrote:
> > >> Hey guys,
> > >>
> > >> First take a look at the log:
> > >>
> > >> root at proxy:/var/log/squid# tail -f access.log |grep
> > >>
>
http://download.cdn.mozilla.net/pub/firefox/releases/45.0.1/update/win32/pt->
> BR/firefox-45.0.1.complete.mar 1463011781.572   8776 10.1.3.236
TCP_MISS/206
> > >> 300520 GET
> > > [...]
> > >> Now think: An user is just doing a segmented/ranged download, right?
> > >> Squid won't cache the file because it is a range-download, not a full
> > >> file download.
> > >> But I WANT squid to cache it. So I decide to use "range_offset_limit
> > >> -1", but then on every GET squid will re-download the file from the
> > >> beginning, opening LOTs of simultaneous connections and using too
much
> > >> bandwidth, doing just the OPPOSITE it's meant to!
> > >>
> > >> Is there a smart way to allow squid to download it from the
> beginning to
> > >> the end (to actually cache it), but only on the FIRST
request/get? Even
> > >> if it makes the user wait for the full download, or cancel it
> > >> temporarily, or.. whatever!! Anything!!
> > > Well, this is exactly, what my squid_dedup helper was created for!
> > >
> > > See my announcement:
> > >
> > >                  Subject: [squid-users] New StoreID helper:
squid_dedup
> > >                  Date: Mon, 09 May 2016 23:56:45 +0200
> > >
> > > My openSUSE environment is fetching _all_ updates with byte-ranges
> from many
> > > servers. Therefor, I created squid_dedup.
> > >
> > > Your specific config could look like this:
> > >
> > > /etc/squid/dedup/mozilla.conf:
> > > [mozilla]
> > > match: http\:\/\/download\.cdn\.mozilla\.net/(.*)
> > > replace: http://download.cdn.mozilla.net.%(intdomain)s/\1
<http://download.cdn.mozilla.net.%(intdomain)s//1>
> <http://download.cdn.mozilla.net.%(intdomain)s//1>
> > > fetch: true
> > >
> > > The fetch parameter is unique among the other StoreID helper
> (AFAIK): it is
> > > fetching the object after a certain delay with a pool of fetcher
> threads.
> > >
> > > The idea is: after the first access for an object, wait a bit
> (global setting,
> > > default: 15 secs), and then fetch the whole thing once. It won't solve
> > > anything for the first client, but for all subsequent accesses.
> > >
> > > The fetcher avoids fetching anything more than once by checking
the http
> > > headers.
> > >
> > > This is a pretty new project, but be assured, that the basic
> functions are
> > > working fine, and I will do my best to solve any upcoming issues.
It is
> > > implemented with Python3 and prepared for supporting additional
features
> > > easily, while keeping a good part of an eye on efficiency.
> > >
> > > Let me know, if you're going to try it.
> > >
> > > Pete
> > > _______________________________________________
> > > squid-users mailing list
> > > squid-users at lists.squid-cache.org
> > > http://lists.squid-cache.org/listinfo/squid-users
>
> > -------------- next part --------------
> > An HTML attachment was scrubbed...
> > URL:
>
<http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/44b7d9df/attachment-0001.html>
>
> > ------------------------------
>
> > Message: 6
> > Date: Thu, 12 May 2016 18:34:08 +0200
> > From: Antony Stone <Antony.Stone at squid.open.source.it>
> > To: squid-users at lists.squid-cache.org
> > Subject: Re: [squid-users] Windows Squid with AD authentication
> > Message-ID: <201605121834.08490.Antony.Stone at squid.open.source.it>
> > Content-Type: Text/Plain;  charset="iso-8859-15"
>
> > On Thursday 12 May 2016 at 18:46:36, Nilesh Gavali wrote:
>
> > > Team;
> > > we have squid running on Windows and need to integrate it with
> Windows AD
> > > .can anyone help me with steps to be perform to get this done.
>
> > This specific question has appeared a few times on this list only
> recently.
>
> > Have you so far:
>
> > - searched the list archives for likely answers to your question?
>
> > http://lists.squid-cache.org/pipermail/squid-users/
>
> > - consulted the Squid documentation for guidance?
>
> > http://www.squid-cache.org/Doc/
>
> > - looked for any independent HOWTOs etc which show how people have
> done this
> > in the past?
>
> > http://www.google.com/search?q=squid+active+directory+authentication
>
>
> > Here's some friendly advice:
>
> > 1. The more information you give us (such as: which version of Squid
> are you
> > using, which version of Windows are you running under, which form of
> > authentication are you using?), the easier it is for people here to
help.
>
> > 2. If you have tried something already and run into problems, tell us
> what you
> > have tried and what problems (log file extracts, complete client error
> message,
> > etc) you encountered, so we can offer specific suggestions.
>
> > 3. If you haven't yet tried to implement anything, at least let us
> know what
> > documentation you have looked up and what problems you encountered when
> > following it, so we can try to fill in the gaps.
>
>
> > Regards,
>
>
> > Antony.
>
> > --
> > Most people have more than the average number of legs.
>
> >                                                   Please reply to the
> list;
> >                                                         please *don't*
> CC me.
>
>
> > ------------------------------
>
> > Subject: Digest Footer
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
> > ------------------------------
>
> > End of squid-users Digest, Vol 21, Issue 54
> > *******************************************
>
>
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL:
<http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/db5c07e2/attachment.html>
> -------------- next part --------------
> A non-text attachment was scrubbed...
> Name: 0x613DEC46.asc
> Type: application/pgp-keys
> Size: 2437 bytes
> Desc: not available
> URL:
<http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/db5c07e2/attachment.key>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> ------------------------------
>
> End of squid-users Digest, Vol 21, Issue 56
> *******************************************
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXNLwMAAoJENNXIZxhPexGVLkH/20BtQFa3MdE4+2HtbkEj/kv
VTaY6qmmZ8iPcqrrs5BscgbdMeUGI/FN0EQp+Z7v3Ex2LDyHhwXsKEdgDvv/zjjq
m0nuosdwTFaNoxYVAOR0LpvAyVsCTYgKoroS0+OhCzTWMkdNn3okpimEowLqykTo
Vm9Pln2ly2FX0Kyr8t6sHYEC4eHcyzcyIy2SUqimHscTMsUWCvaNKvKSyrXijz91
cFFpkjJ48+y7diWAHF9bJnjbFNyuOWf56Kvo59Ss6qZBpFr7VPb/txcuVTtqlGts
PN4IOu1u1Gy40tCNNhD9V/HRC0HRZrO3n1/ZKwTqGpWu0maMX+4LyZ/7SEy6ZVM=
=F9CD
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/5f6966ca/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/5f6966ca/attachment.key>

From hpj at urpla.net  Thu May 12 18:57:53 2016
From: hpj at urpla.net (Hans-Peter Jansen)
Date: Thu, 12 May 2016 20:57:53 +0200
Subject: [squid-users] Getting the full file content on a range request,
	but not on EVERY get ...
In-Reply-To: <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
 <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
Message-ID: <2050051.gqqp5FEbAA@xrated>

Hi Heiler,

On Donnerstag, 12. Mai 2016 13:28:00 Heiler Bemerguy wrote:
> Hi Pete, thanks for replying... let me see if I got it right..
> 
> Will I need to specify every url/domain I want it to act on ? I want
> squid to do it for every range-request downloads that should/would be
> cached (based on other rules, pattern_refreshs etc)

Yup, that's right. At least, that's the common approach to deal with CDNs.
I think, that disallowing range requests is too drastic to work fine on the 
long run, but let us know, if you get to satisfactory solution this way.

> It doesn't need to delay any downloads as long as it isn't a dupe of
> what's already being downloaded.....

You can set to delay to zero of course.

This is only one side of the issues with CDNs. The other, more problematic 
side of it is, that many server with different URLs provide the same files.
Every new address will result in a new download of otherwise identical 
content.
 
Here's an example of openSUSE:

#
# this file was generated by gen_openSUSE_dedups
# from http://mirrors.opensuse.org/list/all.html
# with timestamp Thu, 12 May 2016 05:30:18 +0200
#
[openSUSE]
match:
    # openSUSE Headquarter
    http\:\/\/[a-z0-9]+\.opensuse\.org\/(.*)
    # South Africa (za)
    http\:\/\/ftp\.up\.ac\.za\/mirrors\/opensuse\/opensuse\/(.*)
    # Bangladesh (bd)
    http\:\/\/mirror\.dhakacom\.com\/opensuse\/(.*)
    http\:\/\/mirrors\.ispros\.com\.bd\/opensuse\/(.*)
    # China (cn)
    http\:\/\/mirror\.bjtu\.edu\.cn\/opensuse\/(.*)
    http\:\/\/fundawang\.lcuc\.org\.cn\/opensuse\/(.*)
    http\:\/\/mirrors\.tuna\.tsinghua\.edu\.cn\/opensuse\/(.*)
    http\:\/\/mirrors\.skyshe\.cn\/opensuse\/(.*)
    http\:\/\/mirrors\.hust\.edu\.cn\/opensuse\/(.*)
    http\:\/\/c\.mirrors\.lanunion\.org\/opensuse\/(.*)
    http\:\/\/mirrors\.hustunique\.com\/opensuse\/(.*)
    http\:\/\/mirrors\.sohu\.com\/opensuse\/(.*)
    http\:\/\/mirrors\.ustc\.edu\.cn\/opensuse\/(.*)
    # Hong Kong (hk)
    http\:\/\/mirror\.rackspace\.hk\/openSUSE\/(.*)
    # Indonesia (id)
    http\:\/\/mirror\.linux\.or\.id\/linux\/opensuse\/(.*)
    http\:\/\/buaya\.klas\.or\.id\/opensuse\/(.*)
    http\:\/\/kartolo\.sby\.datautama\.net\.id\/openSUSE\/(.*)
    http\:\/\/opensuse\.idrepo\.or\.id\/opensuse\/(.*)
    http\:\/\/mirror\.unej\.ac\.id\/opensuse\/(.*)
    http\:\/\/download\.opensuse\.or\.id\/(.*)
    http\:\/\/repo\.ugm\.ac\.id\/opensuse\/(.*)
    http\:\/\/dl2\.foss\-id\.web\.id\/opensuse\/(.*)
    # Israel (il)
    http\:\/\/mirror\.isoc\.org\.il\/pub\/opensuse\/(.*)
	
	[...] -> this list contains about 180 entries

replace: http://download.opensuse.org.%(intdomain)s/\1
# fetch all redirected objects explicitly
fetch: true


This is, how CDNs work, but it's a nightmare for caching proxies.
In such scenarios squid_dedup comes to rescue.

Cheers,
Pete


From yvoinov at gmail.com  Thu May 12 19:09:39 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 May 2016 01:09:39 +0600
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <2050051.gqqp5FEbAA@xrated>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
 <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated>
Message-ID: <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I suggest it is very bad idea to transform caching proxy to linux
distro's or something else archive.

As Amos said, "Squid is a cache, not an archive".


13.05.16 0:57, Hans-Peter Jansen ?????:
> Hi Heiler,
>
> On Donnerstag, 12. Mai 2016 13:28:00 Heiler Bemerguy wrote:
>> Hi Pete, thanks for replying... let me see if I got it right..
>>
>> Will I need to specify every url/domain I want it to act on ? I want
>> squid to do it for every range-request downloads that should/would be
>> cached (based on other rules, pattern_refreshs etc)
>
> Yup, that's right. At least, that's the common approach to deal with CDNs.
> I think, that disallowing range requests is too drastic to work fine
on the
> long run, but let us know, if you get to satisfactory solution this way.
>
>> It doesn't need to delay any downloads as long as it isn't a dupe of
>> what's already being downloaded.....
>
> You can set to delay to zero of course.
>
> This is only one side of the issues with CDNs. The other, more
problematic
> side of it is, that many server with different URLs provide the same
files.
> Every new address will result in a new download of otherwise identical
> content.
> 
> Here's an example of openSUSE:
>
> #
> # this file was generated by gen_openSUSE_dedups
> # from http://mirrors.opensuse.org/list/all.html
> # with timestamp Thu, 12 May 2016 05:30:18 +0200
> #
> [openSUSE]
> match:
>     # openSUSE Headquarter
>     http\:\/\/[a-z0-9]+\.opensuse\.org\/(.*)
>     # South Africa (za)
>     http\:\/\/ftp\.up\.ac\.za\/mirrors\/opensuse\/opensuse\/(.*)
>     # Bangladesh (bd)
>     http\:\/\/mirror\.dhakacom\.com\/opensuse\/(.*)
>     http\:\/\/mirrors\.ispros\.com\.bd\/opensuse\/(.*)
>     # China (cn)
>     http\:\/\/mirror\.bjtu\.edu\.cn\/opensuse\/(.*)
>     http\:\/\/fundawang\.lcuc\.org\.cn\/opensuse\/(.*)
>     http\:\/\/mirrors\.tuna\.tsinghua\.edu\.cn\/opensuse\/(.*)
>     http\:\/\/mirrors\.skyshe\.cn\/opensuse\/(.*)
>     http\:\/\/mirrors\.hust\.edu\.cn\/opensuse\/(.*)
>     http\:\/\/c\.mirrors\.lanunion\.org\/opensuse\/(.*)
>     http\:\/\/mirrors\.hustunique\.com\/opensuse\/(.*)
>     http\:\/\/mirrors\.sohu\.com\/opensuse\/(.*)
>     http\:\/\/mirrors\.ustc\.edu\.cn\/opensuse\/(.*)
>     # Hong Kong (hk)
>     http\:\/\/mirror\.rackspace\.hk\/openSUSE\/(.*)
>     # Indonesia (id)
>     http\:\/\/mirror\.linux\.or\.id\/linux\/opensuse\/(.*)
>     http\:\/\/buaya\.klas\.or\.id\/opensuse\/(.*)
>     http\:\/\/kartolo\.sby\.datautama\.net\.id\/openSUSE\/(.*)
>     http\:\/\/opensuse\.idrepo\.or\.id\/opensuse\/(.*)
>     http\:\/\/mirror\.unej\.ac\.id\/opensuse\/(.*)
>     http\:\/\/download\.opensuse\.or\.id\/(.*)
>     http\:\/\/repo\.ugm\.ac\.id\/opensuse\/(.*)
>     http\:\/\/dl2\.foss\-id\.web\.id\/opensuse\/(.*)
>     # Israel (il)
>     http\:\/\/mirror\.isoc\.org\.il\/pub\/opensuse\/(.*)
>    
>     [...] -> this list contains about 180 entries
>
> replace: http://download.opensuse.org.%(intdomain)s/\1
> # fetch all redirected objects explicitly
> fetch: true
>
>
> This is, how CDNs work, but it's a nightmare for caching proxies.
> In such scenarios squid_dedup comes to rescue.
>
> Cheers,
> Pete
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXNNTzAAoJENNXIZxhPexG8XIIAKal+I1GMvTS9QDdJT6pxi7n
IL/d33/YUelZJ9ok1bLAiI1DNOJR6xwK6OZ+LefPOrxH1Q14quGJ5m873065jE+H
/1qhYs8rVVQ8qlLQyMI+aacEA9FV7j6OpWMteM+54SSjLlW4z0pJkw+vSsMwCnI5
Sy3qryieIImtmYnT1wbVM5Pop3lrLA/t1jza619ioxIxWa4M4bSO2EAR+Qj5HiUg
BT8ki8t1GIO12RatjqDwSouU+yDMK85amUKZBjRFXhyOxi1Cg+5uleI4C2lUjqM2
f1n3KBC7mlF6snAT74kc+JWLsNd2ohlkmJB8tSIhkxvkgmaWDpCpwaGaUmtkuXg=
=/fDD
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/c156677a/attachment.key>

From yvoinov at gmail.com  Thu May 12 19:13:59 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 May 2016 01:13:59 +0600
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
 <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
Message-ID: <fd0b00ff-8600-7e30-0460-2f742a6b405e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Moreover,

sometimes it is not an archive, but cemetery.

But - somebody's see no difference.

So, watch what's your caching in.

13.05.16 1:09, Yuri Voinov ?????:
>
> I suggest it is very bad idea to transform caching proxy to linux
> distro's or something else archive.
>
> As Amos said, "Squid is a cache, not an archive".
>
>
> 13.05.16 0:57, Hans-Peter Jansen ?????:
> > Hi Heiler,
>
> > On Donnerstag, 12. Mai 2016 13:28:00 Heiler Bemerguy wrote:
> >> Hi Pete, thanks for replying... let me see if I got it right..
> >>
> >> Will I need to specify every url/domain I want it to act on ? I want
> >> squid to do it for every range-request downloads that should/would be
> >> cached (based on other rules, pattern_refreshs etc)
>
> > Yup, that's right. At least, that's the common approach to deal with
CDNs.
> > I think, that disallowing range requests is too drastic to work fine
> on the
> > long run, but let us know, if you get to satisfactory solution this way.
>
> >> It doesn't need to delay any downloads as long as it isn't a dupe of
> >> what's already being downloaded.....
>
> > You can set to delay to zero of course.
>
> > This is only one side of the issues with CDNs. The other, more
> problematic
> > side of it is, that many server with different URLs provide the same
> files.
> > Every new address will result in a new download of otherwise identical
> > content.
>
> > Here's an example of openSUSE:
>
> > #
> > # this file was generated by gen_openSUSE_dedups
> > # from http://mirrors.opensuse.org/list/all.html
> > # with timestamp Thu, 12 May 2016 05:30:18 +0200
> > #
> > [openSUSE]
> > match:
> >     # openSUSE Headquarter
> >     http\:\/\/[a-z0-9]+\.opensuse\.org\/(.*)
> >     # South Africa (za)
> >     http\:\/\/ftp\.up\.ac\.za\/mirrors\/opensuse\/opensuse\/(.*)
> >     # Bangladesh (bd)
> >     http\:\/\/mirror\.dhakacom\.com\/opensuse\/(.*)
> >     http\:\/\/mirrors\.ispros\.com\.bd\/opensuse\/(.*)
> >     # China (cn)
> >     http\:\/\/mirror\.bjtu\.edu\.cn\/opensuse\/(.*)
> >     http\:\/\/fundawang\.lcuc\.org\.cn\/opensuse\/(.*)
> >     http\:\/\/mirrors\.tuna\.tsinghua\.edu\.cn\/opensuse\/(.*)
> >     http\:\/\/mirrors\.skyshe\.cn\/opensuse\/(.*)
> >     http\:\/\/mirrors\.hust\.edu\.cn\/opensuse\/(.*)
> >     http\:\/\/c\.mirrors\.lanunion\.org\/opensuse\/(.*)
> >     http\:\/\/mirrors\.hustunique\.com\/opensuse\/(.*)
> >     http\:\/\/mirrors\.sohu\.com\/opensuse\/(.*)
> >     http\:\/\/mirrors\.ustc\.edu\.cn\/opensuse\/(.*)
> >     # Hong Kong (hk)
> >     http\:\/\/mirror\.rackspace\.hk\/openSUSE\/(.*)
> >     # Indonesia (id)
> >     http\:\/\/mirror\.linux\.or\.id\/linux\/opensuse\/(.*)
> >     http\:\/\/buaya\.klas\.or\.id\/opensuse\/(.*)
> >     http\:\/\/kartolo\.sby\.datautama\.net\.id\/openSUSE\/(.*)
> >     http\:\/\/opensuse\.idrepo\.or\.id\/opensuse\/(.*)
> >     http\:\/\/mirror\.unej\.ac\.id\/opensuse\/(.*)
> >     http\:\/\/download\.opensuse\.or\.id\/(.*)
> >     http\:\/\/repo\.ugm\.ac\.id\/opensuse\/(.*)
> >     http\:\/\/dl2\.foss\-id\.web\.id\/opensuse\/(.*)
> >     # Israel (il)
> >     http\:\/\/mirror\.isoc\.org\.il\/pub\/opensuse\/(.*)
>
> >     [...] -> this list contains about 180 entries
>
> > replace: http://download.opensuse.org.%(intdomain)s/\1
> > # fetch all redirected objects explicitly
> > fetch: true
>
>
> > This is, how CDNs work, but it's a nightmare for caching proxies.
> > In such scenarios squid_dedup comes to rescue.
>
> > Cheers,
> > Pete
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXNNX3AAoJENNXIZxhPexGpeQH/2RlvCmJ8q5lAwGoRnrpkDOQ
d2qmZbTXBycllJ/ajTzVQfW3WGpqm73iOCQSja91AgP9ID/VFvrp3yFcmLpbnfkO
YzqGHOy4vMNTF6GsCVI/JvMiA5jG00BxAtEnanBvuzkwAXG+dZPNPrJDd/UKtqnI
nzsGH9nhQAFypiHLzX1jeqGrQ8oKdZCtraImI9ONrZVBSaI/dUZoPl8T2w5jE1nc
njN/IEnyx8wYgpO5dDj22Sfuev3S/wIoMmgzKeXGEpS2VPRBT2N2dGsbdFnSucm3
hwQHaX6yVcT/Vpfr8rUHH1l3VlUrcoH5EoBJqgK0Ct/XRONkNUPVgSZLaUJaI3M=
=AsWm
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/e6a94f1f/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/e6a94f1f/attachment.key>

From heiler.bemerguy at cinbesa.com.br  Thu May 12 19:17:30 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Thu, 12 May 2016 16:17:30 -0300
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
 <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
Message-ID: <2b955257-003f-7b4a-b9d1-7d9aea6bfd86@cinbesa.com.br>


I also don't care too much about duplicated cached files.. but trying to 
cache "ranged" requests is topping my link and in the end it seems it's 
not caching anything lol

EVEN if I only allow range_offset to some urls or file extensions....


Best Regards,


-- 
Heiler Bemerguy - (91) 98151-4894
Assessor T?cnico - CINBESA (91) 3184-1751


Em 12/05/2016 16:09, Yuri Voinov escreveu:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>   
> I suggest it is very bad idea to transform caching proxy to linux
> distro's or something else archive.
>
> As Amos said, "Squid is a cache, not an archive".
>
>
> 13.05.16 0:57, Hans-Peter Jansen ?????:
>> Hi Heiler,
>>
>> On Donnerstag, 12. Mai 2016 13:28:00 Heiler Bemerguy wrote:
>>> Hi Pete, thanks for replying... let me see if I got it right..
>>>
>>> Will I need to specify every url/domain I want it to act on ? I want
>>> squid to do it for every range-request downloads that should/would be
>>> cached (based on other rules, pattern_refreshs etc)
>> Yup, that's right. At least, that's the common approach to deal with CDNs.
>> I think, that disallowing range requests is too drastic to work fine
> on the
>> long run, but let us know, if you get to satisfactory solution this way.
>>
>>> It doesn't need to delay any downloads as long as it isn't a dupe of
>>> what's already being downloaded.....
>> You can set to delay to zero of course.
>>
>> This is only one side of the issues with CDNs. The other, more
> problematic
>> side of it is, that many server with different URLs provide the same
> files.
>> Every new address will result in a new download of otherwise identical
>> content.
>>
>> Here's an example of openSUSE:
>>
>> #
>> # this file was generated by gen_openSUSE_dedups
>> # from http://mirrors.opensuse.org/list/all.html
>> # with timestamp Thu, 12 May 2016 05:30:18 +0200
>> #
>> [openSUSE]
>> match:
>>      # openSUSE Headquarter
>>      http\:\/\/[a-z0-9]+\.opensuse\.org\/(.*)
>>      # South Africa (za)
>>      http\:\/\/ftp\.up\.ac\.za\/mirrors\/opensuse\/opensuse\/(.*)
>>      # Bangladesh (bd)
>>      http\:\/\/mirror\.dhakacom\.com\/opensuse\/(.*)
>>      http\:\/\/mirrors\.ispros\.com\.bd\/opensuse\/(.*)
>>      # China (cn)
>>      http\:\/\/mirror\.bjtu\.edu\.cn\/opensuse\/(.*)
>>      http\:\/\/fundawang\.lcuc\.org\.cn\/opensuse\/(.*)
>>      http\:\/\/mirrors\.tuna\.tsinghua\.edu\.cn\/opensuse\/(.*)
>>      http\:\/\/mirrors\.skyshe\.cn\/opensuse\/(.*)
>>      http\:\/\/mirrors\.hust\.edu\.cn\/opensuse\/(.*)
>>      http\:\/\/c\.mirrors\.lanunion\.org\/opensuse\/(.*)
>>      http\:\/\/mirrors\.hustunique\.com\/opensuse\/(.*)
>>      http\:\/\/mirrors\.sohu\.com\/opensuse\/(.*)
>>      http\:\/\/mirrors\.ustc\.edu\.cn\/opensuse\/(.*)
>>      # Hong Kong (hk)
>>      http\:\/\/mirror\.rackspace\.hk\/openSUSE\/(.*)
>>      # Indonesia (id)
>>      http\:\/\/mirror\.linux\.or\.id\/linux\/opensuse\/(.*)
>>      http\:\/\/buaya\.klas\.or\.id\/opensuse\/(.*)
>>      http\:\/\/kartolo\.sby\.datautama\.net\.id\/openSUSE\/(.*)
>>      http\:\/\/opensuse\.idrepo\.or\.id\/opensuse\/(.*)
>>      http\:\/\/mirror\.unej\.ac\.id\/opensuse\/(.*)
>>      http\:\/\/download\.opensuse\.or\.id\/(.*)
>>      http\:\/\/repo\.ugm\.ac\.id\/opensuse\/(.*)
>>      http\:\/\/dl2\.foss\-id\.web\.id\/opensuse\/(.*)
>>      # Israel (il)
>>      http\:\/\/mirror\.isoc\.org\.il\/pub\/opensuse\/(.*)
>>     
>>      [...] -> this list contains about 180 entries
>>
>> replace: http://download.opensuse.org.%(intdomain)s/\1
>> # fetch all redirected objects explicitly
>> fetch: true
>>
>>
>> This is, how CDNs work, but it's a nightmare for caching proxies.
>> In such scenarios squid_dedup comes to rescue.
>>
>> Cheers,
>> Pete
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>   
> iQEcBAEBCAAGBQJXNNTzAAoJENNXIZxhPexG8XIIAKal+I1GMvTS9QDdJT6pxi7n
> IL/d33/YUelZJ9ok1bLAiI1DNOJR6xwK6OZ+LefPOrxH1Q14quGJ5m873065jE+H
> /1qhYs8rVVQ8qlLQyMI+aacEA9FV7j6OpWMteM+54SSjLlW4z0pJkw+vSsMwCnI5
> Sy3qryieIImtmYnT1wbVM5Pop3lrLA/t1jza619ioxIxWa4M4bSO2EAR+Qj5HiUg
> BT8ki8t1GIO12RatjqDwSouU+yDMK85amUKZBjRFXhyOxi1Cg+5uleI4C2lUjqM2
> f1n3KBC7mlF6snAT74kc+JWLsNd2ohlkmJB8tSIhkxvkgmaWDpCpwaGaUmtkuXg=
> =/fDD
> -----END PGP SIGNATURE-----
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/2b03110c/attachment.htm>

From yvoinov at gmail.com  Thu May 12 19:19:12 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 May 2016 01:19:12 +0600
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <2b955257-003f-7b4a-b9d1-7d9aea6bfd86@cinbesa.com.br>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
 <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
 <2b955257-003f-7b4a-b9d1-7d9aea6bfd86@cinbesa.com.br>
Message-ID: <56ac89ec-d630-c34d-17bd-7344fc2a79c4@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
And I did not promise a silver bullet :) This is just a small
workaround, which does not work in all cases. :)

13.05.16 1:17, Heiler Bemerguy ?????:
>
>
> I also don't care too much about duplicated cached files.. but trying
to cache "ranged" requests is topping my link and in the end it seems
it's not caching anything lol
>
> EVEN if I only allow range_offset to some urls or file extensions....
>
>
> Best Regards,
>
>
> --
> Heiler Bemerguy - (91) 98151-4894
> Assessor T?cnico - CINBESA (91) 3184-1751
>
> Em 12/05/2016 16:09, Yuri Voinov escreveu:
> I suggest it is very bad idea to transform caching proxy to linux
> distro's or something else archive.
>
> As Amos said, "Squid is a cache, not an archive".
>
>
> 13.05.16 0:57, Hans-Peter Jansen ?????:
> >>> Hi Heiler,
> >>>
> >>> On Donnerstag, 12. Mai 2016 13:28:00 Heiler Bemerguy wrote:
> >>>> Hi Pete, thanks for replying... let me see if I got it right..
> >>>>
> >>>> Will I need to specify every url/domain I want it to act on ? I want
> >>>> squid to do it for every range-request downloads that should/would be
> >>>> cached (based on other rules, pattern_refreshs etc)
> >>> Yup, that's right. At least, that's the common approach to deal
with CDNs.
> >>> I think, that disallowing range requests is too drastic to work fine
> on the
> >>> long run, but let us know, if you get to satisfactory solution
this way.
> >>>
> >>>> It doesn't need to delay any downloads as long as it isn't a dupe of
> >>>> what's already being downloaded.....
> >>> You can set to delay to zero of course.
> >>>
> >>> This is only one side of the issues with CDNs. The other, more
> problematic
> >>> side of it is, that many server with different URLs provide the same
> files.
> >>> Every new address will result in a new download of otherwise identical
> >>> content.
> >>>
> >>> Here's an example of openSUSE:
> >>>
> >>> #
> >>> # this file was generated by gen_openSUSE_dedups
> >>> # from http://mirrors.opensuse.org/list/all.html
> >>> # with timestamp Thu, 12 May 2016 05:30:18 +0200
> >>> #
> >>> [openSUSE]
> >>> match:
> >>>     # openSUSE Headquarter
> >>>     http\:\/\/[a-z0-9]+\.opensuse\.org\/(.*)
> >>>     # South Africa (za)
> >>>     http\:\/\/ftp\.up\.ac\.za\/mirrors\/opensuse\/opensuse\/(.*)
> >>>     # Bangladesh (bd)
> >>>     http\:\/\/mirror\.dhakacom\.com\/opensuse\/(.*)
> >>>     http\:\/\/mirrors\.ispros\.com\.bd\/opensuse\/(.*)
> >>>     # China (cn)
> >>>     http\:\/\/mirror\.bjtu\.edu\.cn\/opensuse\/(.*)
> >>>     http\:\/\/fundawang\.lcuc\.org\.cn\/opensuse\/(.*)
> >>>     http\:\/\/mirrors\.tuna\.tsinghua\.edu\.cn\/opensuse\/(.*)
> >>>     http\:\/\/mirrors\.skyshe\.cn\/opensuse\/(.*)
> >>>     http\:\/\/mirrors\.hust\.edu\.cn\/opensuse\/(.*)
> >>>     http\:\/\/c\.mirrors\.lanunion\.org\/opensuse\/(.*)
> >>>     http\:\/\/mirrors\.hustunique\.com\/opensuse\/(.*)
> >>>     http\:\/\/mirrors\.sohu\.com\/opensuse\/(.*)
> >>>     http\:\/\/mirrors\.ustc\.edu\.cn\/opensuse\/(.*)
> >>>     # Hong Kong (hk)
> >>>     http\:\/\/mirror\.rackspace\.hk\/openSUSE\/(.*)
> >>>     # Indonesia (id)
> >>>     http\:\/\/mirror\.linux\.or\.id\/linux\/opensuse\/(.*)
> >>>     http\:\/\/buaya\.klas\.or\.id\/opensuse\/(.*)
> >>>     http\:\/\/kartolo\.sby\.datautama\.net\.id\/openSUSE\/(.*)
> >>>     http\:\/\/opensuse\.idrepo\.or\.id\/opensuse\/(.*)
> >>>     http\:\/\/mirror\.unej\.ac\.id\/opensuse\/(.*)
> >>>     http\:\/\/download\.opensuse\.or\.id\/(.*)
> >>>     http\:\/\/repo\.ugm\.ac\.id\/opensuse\/(.*)
> >>>     http\:\/\/dl2\.foss\-id\.web\.id\/opensuse\/(.*)
> >>>     # Israel (il)
> >>>     http\:\/\/mirror\.isoc\.org\.il\/pub\/opensuse\/(.*)
> >>>   
> >>>     [...] -> this list contains about 180 entries
> >>>
> >>> replace: http://download.opensuse.org.%(intdomain)s/\1
> >>> # fetch all redirected objects explicitly
> >>> fetch: true
> >>>
> >>>
> >>> This is, how CDNs work, but it's a nightmare for caching proxies.
> >>> In such scenarios squid_dedup comes to rescue.
> >>>
> >>> Cheers,
> >>> Pete
> >>> _______________________________________________
> >>> squid-users mailing list
> >>> squid-users at lists.squid-cache.org
> >>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXNNcvAAoJENNXIZxhPexGLGsH/jilasMtRp499QJS+G5O9lHv
z1MtLbZnExrzVcmqb69jsbaZWjwnhvUF1Ng7fZbep5q6pky3DGcwxQu/EBVhD3+p
tTliArKa45dmhbOm5a0ljJcq73hBtUrlS0UrGDV6CMRrXjHjSUzy6+BwwsI1mClp
dtOos3NoSDlQmazkEDA6+f3iuYykjinmTsFlJRgQipluXnUUlmvbnpwZHqUhTA0R
X2I6j3zdTDHGszlXkoFrKg+Vj0gOzeGfA5IPx7/vnruShlYSPWuvoVfvi4ZLYV2y
8NZ8Q9L1MvBoMUa1WphE2NZeKpVPbK/d1inNCjOtpymxmNX/JYHTCs3aB8Gr8pU=
=9RTQ
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/f6fbf20d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/f6fbf20d/attachment.key>

From derk at muenchhausen.de  Thu May 12 19:43:50 2016
From: derk at muenchhausen.de (derk at muenchhausen.de)
Date: Thu, 12 May 2016 19:43:50 +0000
Subject: [squid-users] squid,
	squidguard and elk - simply combined as docker containers
Message-ID: <39D40242-AE0C-4795-8D21-6A42E174CAC7@muenchhausen.de>

Dear Squid enthusiasts !

Squid is fine ? it simply works since years at home.
Squidguard helps me to block malicious websites.
kibana visualizes from where my Browser retrieves data
? and Docker combines everything in a simple way :)

I published a small Docker Compose project on Github. Feel free to try it ? feedback is very welcome!
https://github.com/muenchhausen/docker-squidguard-elk

Best regards,
Derk



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/87a77074/attachment.htm>

From hpj at urpla.net  Thu May 12 19:56:08 2016
From: hpj at urpla.net (Hans-Peter Jansen)
Date: Thu, 12 May 2016 21:56:08 +0200
Subject: [squid-users] Getting the full file content on a range request,
	but not on EVERY get ...
In-Reply-To: <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
Message-ID: <1568581.UxCcF2ljDL@xrated>

On Freitag, 13. Mai 2016 01:09:39 Yuri Voinov wrote:
> I suggest it is very bad idea to transform caching proxy to linux
> distro's or something else archive.

Yuri, if I wanted an archive, I would mirror all stuff and use local repos. 
I went that route for a long time - it's a lot of work to keep up everywhere, 
and generates an awful amount of traffic (and I did it the sanest way possible 
- with a custom script, that was using rsync..)

> As Amos said, "Squid is a cache, not an archive".

Yes, updating 20 similar machines makes a significant difference with the 
squid as a deduplicated cache - with no recurring work at all.

Pete


From yvoinov at gmail.com  Thu May 12 20:02:07 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 May 2016 02:02:07 +0600
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <1568581.UxCcF2ljDL@xrated>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
 <1568581.UxCcF2ljDL@xrated>
Message-ID: <b0334a38-b122-6a82-93d4-8e38bccffeba@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Updates,

in conjunction with hundreds OS's and distros, better to do with
separate dedicated update server. IMHO.


13.05.16 1:56, Hans-Peter Jansen ?????:
> On Freitag, 13. Mai 2016 01:09:39 Yuri Voinov wrote:
>> I suggest it is very bad idea to transform caching proxy to linux
>> distro's or something else archive.
>
> Yuri, if I wanted an archive, I would mirror all stuff and use local
repos.
It was sarcasm. And yes - local mirror is the best approach.
>
> I went that route for a long time - it's a lot of work to keep up
everywhere,
> and generates an awful amount of traffic (and I did it the sanest way
possible
My condolences.
>  
> - with a custom script, that was using rsync..)
>
>> As Amos said, "Squid is a cache, not an archive".
>
> Yes, updating 20 similar machines makes a significant difference with the
> squid as a deduplicated cache - with no recurring work at all.
Agree. Partially. With Solaris I've does it one JumpStart network
server..... Of course, the same technology is rara avis in modern
world.... :)

I now wonder - to sharpen the pencil you too millstone ask? :)  My
condolences again.
>
>
> Pete
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXNOE/AAoJENNXIZxhPexGSMsIAItiHicVTsVSI1u1Dn5Bb0M4
RjsQB3eG7ISoJKTe2nBBAeaRfoqcJxlahJ1Yabk+FP25zl+hmp0E1Yba2VTZvDFX
8BKwsNKuGPRdOgI5t69XLfgdQT21hnHNsYtH08pTSvvQeOYE9UA488jqHZKC20y7
J+3MU7aJiDZuSwfMsX5M9g1Wz6gQtgjuF4CL7ur7ssvhs+BD8ZUctJ7AjJ9JU2bf
Z4uIIzKYhkNWZklPpB/ZVRr9qDfhiOpbit4oeI2ELrgU7ro4EcggNY24Nxel6CGX
WzU3NDsv2mm3I5u3mW6KkWHYd2k/5uqE+cAXZSdRBBz2WTj2YJoMePnyMQIUowE=
=i8rv
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/1676effb/attachment.key>

From yvoinov at gmail.com  Thu May 12 20:07:37 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 May 2016 02:07:37 +0600
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <b0334a38-b122-6a82-93d4-8e38bccffeba@gmail.com>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
 <1568581.UxCcF2ljDL@xrated> <b0334a38-b122-6a82-93d4-8e38bccffeba@gmail.com>
Message-ID: <fd4490bb-555c-bd03-b097-4b1cb8a1a86e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I recently expressed the idea of caching torrents using SQUID. :) What's
an idea! I'm still impressed! :)

13.05.16 2:02, Yuri Voinov ?????:
>
> Updates,
>
> in conjunction with hundreds OS's and distros, better to do with
> separate dedicated update server. IMHO.
>
>
> 13.05.16 1:56, Hans-Peter Jansen ?????:
> > On Freitag, 13. Mai 2016 01:09:39 Yuri Voinov wrote:
> >> I suggest it is very bad idea to transform caching proxy to linux
> >> distro's or something else archive.
>
> > Yuri, if I wanted an archive, I would mirror all stuff and use local
> repos.
> It was sarcasm. And yes - local mirror is the best approach.
>
> > I went that route for a long time - it's a lot of work to keep up
> everywhere,
> > and generates an awful amount of traffic (and I did it the sanest way
> possible
> My condolences.
>
> > - with a custom script, that was using rsync..)
>
> >> As Amos said, "Squid is a cache, not an archive".
>
> > Yes, updating 20 similar machines makes a significant difference
with the
> > squid as a deduplicated cache - with no recurring work at all.
> Agree. Partially. With Solaris I've does it one JumpStart network
> server..... Of course, the same technology is rara avis in modern
> world.... :)
>
> I now wonder - to sharpen the pencil you too millstone ask? :)  My
> condolences again.
>
>
> > Pete
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXNOKJAAoJENNXIZxhPexGWxMH+QEBHNNidx9Ar5Ec52bGz/Mm
qpvkklZ3Tq6QPv2fimh8G7vXQghs29MfWCi6Q2ZRtWDBTbwXOBHAmhnkVt+VrzOH
G7w61dmgmv9MfiotQu2f0g+v3v/MFWKjwEHU602SI8hMS4908Zw4z8Z6oGDzTi44
AdkoUX2J1SRLlVTuniVZJRGALnazHGTPiYHdvf5VpLnkWs1UtnugbrxLHDDRuVKi
KsyIJvNv0NfvXa2HBGk7pgM4RWuuSc/bK1fZ6NzF7IccfqbqCUXZTo55IhzjS0kV
fZKUIPk8Hm3Z2GaWvXO/9qtZiw4jMxGFmIDZCUjVDykJZFgdJZdsc87n0Lzbubw=
=T9vF
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/a84934c1/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/a84934c1/attachment.key>

From yvoinov at gmail.com  Thu May 12 20:08:51 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 May 2016 02:08:51 +0600
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <fd4490bb-555c-bd03-b097-4b1cb8a1a86e@gmail.com>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
 <1568581.UxCcF2ljDL@xrated> <b0334a38-b122-6a82-93d4-8e38bccffeba@gmail.com>
 <fd4490bb-555c-bd03-b097-4b1cb8a1a86e@gmail.com>
Message-ID: <b67496e5-4465-c3b2-4e46-8b3a1030623c@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
In comparison, the cache of thousands of Linux distributions, regardless
of the purpose, of course, a trifle :)

13.05.16 2:07, Yuri Voinov ?????:
>
> I recently expressed the idea of caching torrents using SQUID. :)
What's an idea! I'm still impressed! :)
>
> 13.05.16 2:02, Yuri Voinov ?????:
>
>
>       > Updates,
>
>
>
>       > in conjunction with hundreds OS's and distros, better to do
>       with
>
>       > separate dedicated update server. IMHO.
>
>
>
>
>
>       > 13.05.16 1:56, Hans-Peter Jansen ?????:
>
>       > > On Freitag, 13. Mai 2016 01:09:39 Yuri Voinov wrote:
>
>       > >> I suggest it is very bad idea to transform caching
>       proxy to linux
>
>       > >> distro's or something else archive.
>
>
>
>       > > Yuri, if I wanted an archive, I would mirror all stuff
>       and use local
>
>       > repos.
>
>       > It was sarcasm. And yes - local mirror is the best approach.
>
>
>
>       > > I went that route for a long time - it's a lot of work
>       to keep up
>
>       > everywhere,
>
>       > > and generates an awful amount of traffic (and I did it
>       the sanest way
>
>       > possible
>
>       > My condolences.
>
>
>
>       > > - with a custom script, that was using rsync..)
>
>
>
>       > >> As Amos said, "Squid is a cache, not an archive".
>
>
>
>       > > Yes, updating 20 similar machines makes a significant
>       difference with the
>
>       > > squid as a deduplicated cache - with no recurring work
>       at all.
>
>       > Agree. Partially. With Solaris I've does it one JumpStart
>       network
>
>       > server..... Of course, the same technology is rara avis in
>       modern
>
>       > world.... :)
>
>
>
>       > I now wonder - to sharpen the pencil you too millstone ask?
>       :)  My
>
>       > condolences again.
>
>
>
>
>
>       > > Pete
>
>       > > _______________________________________________
>
>       > > squid-users mailing list
>
>       > > squid-users at lists.squid-cache.org
>
>       > > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXNOLSAAoJENNXIZxhPexGrL8H/2CENrZvFX4fUaZeCM55p88z
ROVWCMpsx4YsD1zZieOIvUwBsBZlY35iBQ2R0gxEY8vrnNZE5eAt1+BK2zSxX2fZ
us/JZ4yWeSlDYZ+foztnSDcPhqikdkaNXM12KjP7usnybx/dN2KaHdq8nc1xbOeN
A1NCT4mnxiUNeycFOFfAHASvh4rCSii6MMqCS1Pf8PMwdTcKk/UudEBooytGlA7K
gN39HWu+MCd1uUX2Mt9KRfSYQVx7OMjwWzNTH5Rpjk7gBd9a2oQGJrHoZ62xn0Pb
7ZCbZOgTJwovqWycf3Yv+6hb2m4g3xhJ9jBoM3RJjC4oRMynZ+Ls/QyBDfeUD0Q=
=7c66
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/34bc1c7a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/34bc1c7a/attachment.key>

From yvoinov at gmail.com  Thu May 12 20:09:52 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 May 2016 02:09:52 +0600
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <b67496e5-4465-c3b2-4e46-8b3a1030623c@gmail.com>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
 <1568581.UxCcF2ljDL@xrated> <b0334a38-b122-6a82-93d4-8e38bccffeba@gmail.com>
 <fd4490bb-555c-bd03-b097-4b1cb8a1a86e@gmail.com>
 <b67496e5-4465-c3b2-4e46-8b3a1030623c@gmail.com>
Message-ID: <18a437de-04a8-2ccc-9b59-e8e7d14c6908@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
If a hammer, all, of course, is the nails :)

13.05.16 2:08, Yuri Voinov ?????:
>
> In comparison, the cache of thousands of Linux distributions,
regardless of the purpose, of course, a trifle :)
>
> 13.05.16 2:07, Yuri Voinov ?????:
>
>
>       > I recently expressed the idea of caching torrents using
>       SQUID. :) What's an idea! I'm still impressed! :)
>
>
>
>       > 13.05.16 2:02, Yuri Voinov ?????:
>
>
>
>
>
>       >       > Updates,
>
>
>
>
>
>
>
>       >       > in conjunction with hundreds OS's and distros,
>       better to do
>
>       >       with
>
>
>
>       >       > separate dedicated update server. IMHO.
>
>
>
>
>
>
>
>
>
>
>
>       >       > 13.05.16 1:56, Hans-Peter Jansen ?????:
>
>
>
>       >       > > On Freitag, 13. Mai 2016 01:09:39 Yuri Voinov
>       wrote:
>
>
>
>       >       > >> I suggest it is very bad idea to
>       transform caching
>
>       >       proxy to linux
>
>
>
>       >       > >> distro's or something else archive.
>
>
>
>
>
>
>
>       >       > > Yuri, if I wanted an archive, I would mirror
>       all stuff
>
>       >       and use local
>
>
>
>       >       > repos.
>
>
>
>       >       > It was sarcasm. And yes - local mirror is the best
>       approach.
>
>
>
>
>
>
>
>       >       > > I went that route for a long time - it's a
>       lot of work
>
>       >       to keep up
>
>
>
>       >       > everywhere,
>
>
>
>       >       > > and generates an awful amount of traffic (and
>       I did it
>
>       >       the sanest way
>
>
>
>       >       > possible
>
>
>
>       >       > My condolences.
>
>
>
>
>
>
>
>       >       > > - with a custom script, that was using
>       rsync..)
>
>
>
>
>
>
>
>       >       > >> As Amos said, "Squid is a cache, not an
>       archive".
>
>
>
>
>
>
>
>       >       > > Yes, updating 20 similar machines makes a
>       significant
>
>       >       difference with the
>
>
>
>       >       > > squid as a deduplicated cache - with no
>       recurring work
>
>       >       at all.
>
>
>
>       >       > Agree. Partially. With Solaris I've does it one
>       JumpStart
>
>       >       network
>
>
>
>       >       > server..... Of course, the same technology is rara
>       avis in
>
>       >       modern
>
>
>
>       >       > world.... :)
>
>
>
>
>
>
>
>       >       > I now wonder - to sharpen the pencil you too
>       millstone ask?
>
>       >       :)  My
>
>
>
>       >       > condolences again.
>
>
>
>
>
>
>
>
>
>
>
>       >       > > Pete
>
>
>
>       >       > >
>       _______________________________________________
>
>
>
>       >       > > squid-users mailing list
>
>
>
>       >       > > squid-users at lists.squid-cache.org
>
>
>
>       >       > >
>       http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>
>
>
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXNOMQAAoJENNXIZxhPexGQiQIAMX1XwoIr6WVtoSTpG8Jf8Vy
+8jdMQzGMvG7DUkd+PUXu/b28HqcKm5yyTh8LkBt1tPYfetv5VBIY21yN8G/48Rb
U9C+yYeLzQVUxikd5muel9G19khJ7XXqzJHSBNtPzlyN8+ylNX9TFFhmJZu4s6sq
el05x/xtmlNkrW4AIbYF4Zz5HVxOResJS7yCvAuQw7LB010Hwed1PYyFw2baKVRO
BZkiG8E8kxTPT6j+KB/nFZC2l0qmblPa2Tk3sjhKkngJx5rSbKTomZI075KRQilv
VJgdYNp8/hDlvGszpi0/PSV8onia0ekF8jYU/7fkTsYqRJJ1P9G5f4ezZcr4Bos=
=MaNc
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/866c4ac3/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/866c4ac3/attachment.key>

From Walter.H at mathemainzel.info  Thu May 12 20:20:00 2016
From: Walter.H at mathemainzel.info (Walter H.)
Date: Thu, 12 May 2016 22:20:00 +0200
Subject: [squid-users] Regular expressions with dstdom_regex ACL
Message-ID: <5734E570.7080802@mathemainzel.info>

Hello,

can someone please tell me which regular expression(s) would really block
domains which are IP hosts

for IPv4 this is my regexp:
^[12]?[0-9]{1,2}\.[12]?[0-9]{1,2}\.[12]?[0-9]{1,2}\.[12]?[0-9]{1,2}$
and this works as expected

acl block_domains_iphost dstdom_regex 
^[12]?[0-9]{1,2}\.[12]?[0-9]{1,2}\.[12]?[0-9]{1,2}\.[12]?[0-9]{1,2}$
deny_info ERR_IPHOST_BLOCKED block_domains_iphost
http_access deny block_domains_iphost

BUT, I tried and tried and failed with IPv6

this section in squid.conf

acl block_domains_ip6host dstdomain [ipv6]
deny_info ERR_IPHOST_BLOCKED block_domains_iphost6
http_access deny block_domains_iphost6

doesn't work for exact this given IPv6 address ...

I want any IPv6 address

can someone please tell me how I can achive this?

the result should be that
any URL like this
http(s)://ip-address/ should be blocked by the specified error page

Thanks and Greetings from Austria,
Walter


-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4312 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/25032cde/attachment.bin>

From squid3 at treenet.co.nz  Thu May 12 20:36:53 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 May 2016 08:36:53 +1200
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <2b955257-003f-7b4a-b9d1-7d9aea6bfd86@cinbesa.com.br>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
 <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
 <2b955257-003f-7b4a-b9d1-7d9aea6bfd86@cinbesa.com.br>
Message-ID: <bc769369-02f1-42b3-efb9-73c367c57de9@treenet.co.nz>

On 13/05/2016 7:17 a.m., Heiler Bemerguy wrote:
> 
> I also don't care too much about duplicated cached files.. but trying to
> cache "ranged" requests is topping my link and in the end it seems it's
> not caching anything lol
> 
> EVEN if I only allow range_offset to some urls or file extensions....
> 

Have you given collapsed_forwarding a try? Its supposed to prevent all
the duplicate requests making all those extra upstream connections unti
at least the first one has finished getting the object. Combined with
the range_offset_limit and qick_abort_max to make that first request be
a full-fetch it might be able to solve your issue.

Amos



From yvoinov at gmail.com  Thu May 12 20:59:41 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 13 May 2016 02:59:41 +0600
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <bc769369-02f1-42b3-efb9-73c367c57de9@treenet.co.nz>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
 <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
 <2b955257-003f-7b4a-b9d1-7d9aea6bfd86@cinbesa.com.br>
 <bc769369-02f1-42b3-efb9-73c367c57de9@treenet.co.nz>
Message-ID: <fa4fa9d1-2d27-4ac8-1b6d-b98ff0b07720@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Amos, you're a genius! I had forgotten completely about this setting, oh
my Idiotti .....


13.05.16 2:36, Amos Jeffries ?????:
> On 13/05/2016 7:17 a.m., Heiler Bemerguy wrote:
>>
>> I also don't care too much about duplicated cached files.. but trying to
>> cache "ranged" requests is topping my link and in the end it seems it's
>> not caching anything lol
>>
>> EVEN if I only allow range_offset to some urls or file extensions....
>>
>
> Have you given collapsed_forwarding a try? Its supposed to prevent all
> the duplicate requests making all those extra upstream connections unti
> at least the first one has finished getting the object. Combined with
> the range_offset_limit and qick_abort_max to make that first request be
> a full-fetch it might be able to solve your issue.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXNO68AAoJENNXIZxhPexGQzcH/iulc1g/5hxya2gcLe0+FQsV
6Wtfl/DlpMkhwpKxPMMZMtcafyv7Umbbl2H7ErfcVGCVmZAWOZ0TYmA5dAu8NQ3X
d8dQXAoKycNq3ZgKjpDIju33M4yJnPBrBb9M7oz1fXhj3WKo+LCapxX5nb9wYBgn
CyrFcQf1rRSto2ly14w+j8XLJhyoUeBFoclJjksXbSycQmB0jPQtG9PkL3KOJNEv
lYyTqbu0FUBoiek4oI0uOC2E9CjRPMyRdAWxkV5jEyqlRSfFo6bByEF9rKmk9CxH
J0FOjpTvq5Bhrr4UVPp0jTpcuRebbLt6IxIdghU+fx6Fv33eRQwmSvxzHix0i0Y=
=30FJ
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/f8e58a96/attachment.key>

From rousskov at measurement-factory.com  Thu May 12 21:21:26 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 12 May 2016 15:21:26 -0600
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <bc769369-02f1-42b3-efb9-73c367c57de9@treenet.co.nz>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
 <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
 <2b955257-003f-7b4a-b9d1-7d9aea6bfd86@cinbesa.com.br>
 <bc769369-02f1-42b3-efb9-73c367c57de9@treenet.co.nz>
Message-ID: <5734F3D6.2020205@measurement-factory.com>

On 05/12/2016 02:36 PM, Amos Jeffries wrote:

> Have you given collapsed_forwarding a try? Its supposed to prevent all
> the duplicate requests making all those extra upstream connections unti
> at least the first one has finished getting the object.

For the record, collapsed forwarding collapses requests _before_ there
is any response [header], not after the "first" request got the object
[body]. Once there is a response [header], the usual caching code path
kicks in and no collapsing is needed.

Cache hits on that "usual caching code path" read from a "public" cache
entry. Normally, those public entries are created when Squid receives a
response [header]. Collapsed forwarding creates that entry before Squids
gets the response [header], and, hence, before Squid can know for sure
whether the response is going to be cachable, with all the risks that
entails.


Please do not misinterpret my email as a recommendation to give (or not
to give) collapsed forwarding a try. I have _not_ analyzed the problems
discussed on this thread. I just wanted to correct the description
above. Nothing more.


HTH,

Alex.



From david at articatech.com  Thu May 12 22:04:23 2016
From: david at articatech.com (David Touzeau)
Date: Fri, 13 May 2016 00:04:23 +0200
Subject: [squid-users] ACL is used in context without an HTTP response.
	Assuming mismatch
Message-ID: <005001d1ac9a$3fe7c530$bfb74f90$@articatech.com>

Hi 

 

I did not want squid to log it's TCP_DENIED/407 when sending authentication
to browsers

 

I think this acl should work

 

acl CODE_TCP_DENIED http_status 407

access_log none CODE_TCP_DENIED

 

But squid claim :

 

2016/05/12 23:44:07 kid1| WARNING: CODE_TCP_DENIED ACL is used in context
without an HTTP response. Assuming mismatch.

 

Why this rule is wrong ?

 

Best regards

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/bc41b2c6/attachment.htm>

From heiler.bemerguy at cinbesa.com.br  Thu May 12 22:34:39 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Thu, 12 May 2016 19:34:39 -0300
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <5734F3D6.2020205@measurement-factory.com>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
 <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
 <2b955257-003f-7b4a-b9d1-7d9aea6bfd86@cinbesa.com.br>
 <bc769369-02f1-42b3-efb9-73c367c57de9@treenet.co.nz>
 <5734F3D6.2020205@measurement-factory.com>
Message-ID: <ffc2f0bf-5268-42cc-e42f-9f9ffe8b110a@cinbesa.com.br>


Hi guys


I just enabled "collapsed_forwarding"  and noticed a lot of "Vary object 
loop!" that wasn't there before..

2016/05/12 19:17:22 kid3| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 
'http://ego.globo.com/paparazzo/noticia/2016/05/tulio-maravilha-fala-de-video-intimo-com-mulher-gente-ve-e-deleta.html' 
'accept-encoding="gzip,%20deflate,%20sdch", 
user-agent="Mozilla%2F5.0%20(Windows%20NT%206.1)%20AppleWebKit%2F537.36%20(KHTML,%20like%20Gecko)%20Chrome%2F50.0.2661.102%20Safari%2F537.36"'
2016/05/12 19:17:22 kid3| clientProcessHit: Vary object loop!
2016/05/12 19:17:22 kid3| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 'http://ego.globo.com/fonts/typography.css' 
'accept-encoding="gzip,%20deflate,%20sdch", 
user-agent="Mozilla%2F5.0%20(Windows%20NT%206.1)%20AppleWebKit%2F537.36%20(KHTML,%20like%20Gecko)%20Chrome%2F50.0.2661.102%20Safari%2F537.36"'
2016/05/12 19:17:22 kid3| clientProcessHit: Vary object loop!
2016/05/12 19:17:22 kid3| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 
'http://ego.globo.com/dynamo/scripts/js/glb.recaptcha.js' 
'accept-encoding="gzip,%20deflate,%20sdch", 
user-agent="Mozilla%2F5.0%20(Windows%20NT%206.1)%20AppleWebKit%2F537.36%20(KHTML,%20like%20Gecko)%20Chrome%2F50.0.2661.102%20Safari%2F537.36"'


I don't know if it's helping with the segmented downloads (that this 
thread is about...) though.


Best Regards,


-- 
Heiler Bemerguy - (91) 98151-4894
Assessor T?cnico - CINBESA (91) 3184-1751



Em 12/05/2016 18:21, Alex Rousskov escreveu:
> On 05/12/2016 02:36 PM, Amos Jeffries wrote:
>
>> Have you given collapsed_forwarding a try? Its supposed to prevent all
>> the duplicate requests making all those extra upstream connections unti
>> at least the first one has finished getting the object.
> For the record, collapsed forwarding collapses requests _before_ there
> is any response [header], not after the "first" request got the object
> [body]. Once there is a response [header], the usual caching code path
> kicks in and no collapsing is needed.
>
> Cache hits on that "usual caching code path" read from a "public" cache
> entry. Normally, those public entries are created when Squid receives a
> response [header]. Collapsed forwarding creates that entry before Squids
> gets the response [header], and, hence, before Squid can know for sure
> whether the response is going to be cachable, with all the risks that
> entails.
>
>
> Please do not misinterpret my email as a recommendation to give (or not
> to give) collapsed forwarding a try. I have _not_ analyzed the problems
> discussed on this thread. I just wanted to correct the description
> above. Nothing more.
>
>
> HTH,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160512/99518d52/attachment.htm>

From rousskov at measurement-factory.com  Thu May 12 22:39:41 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 12 May 2016 16:39:41 -0600
Subject: [squid-users] ACL is used in context without an HTTP response.
 Assuming mismatch
In-Reply-To: <005001d1ac9a$3fe7c530$bfb74f90$@articatech.com>
References: <005001d1ac9a$3fe7c530$bfb74f90$@articatech.com>
Message-ID: <5735062D.2090902@measurement-factory.com>

On 05/12/2016 04:04 PM, David Touzeau wrote:
> 
> acl CODE_TCP_DENIED http_status 407
> access_log none CODE_TCP_DENIED
> 
>  
> 
> But squid claim :  
> 
> 2016/05/12 23:44:07 kid1| WARNING: CODE_TCP_DENIED ACL is used in
> context without an HTTP response. Assuming mismatch.
>  
> 
> Why this rule is wrong ?

Squid attempts to log every access(*). Sometimes, Squid is accessed, but
there is no response to log(**). Your rule assumes that there is always
a response. Squid warns that your assumption is wrong for the specific
access it is logging.

If there is no ACL that can be used to test the presence of a response
(and a request) in a master transaction [without triggering such
warnings], then we should add it.


Also, some Squids have bugs where there _is_ a response but Squid
logging code does not know about it. If you are running a relatively
recent Squid v4 release, you might be hitting one of those bugs
(although I would expect more/different error messages in that case).


Endnotes:

(*) Squid fails to log certain accesses. We are fixing one of those bugs
right now.

(**) Imagine, for example, a client that starts sending an HTTP request
but closes the connection to Squid before finishing. Depending on what
state Squid was in when the connection got closed, there may be no
response created for that unfinished request.


HTH,

Alex.



From chip_pop at hotmail.com  Thu May 12 23:21:46 2016
From: chip_pop at hotmail.com (joe)
Date: Thu, 12 May 2016 16:21:46 -0700 (PDT)
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <ffc2f0bf-5268-42cc-e42f-9f9ffe8b110a@cinbesa.com.br>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
 <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
 <2b955257-003f-7b4a-b9d1-7d9aea6bfd86@cinbesa.com.br>
 <bc769369-02f1-42b3-efb9-73c367c57de9@treenet.co.nz>
 <5734F3D6.2020205@measurement-factory.com>
 <ffc2f0bf-5268-42cc-e42f-9f9ffe8b110a@cinbesa.com.br>
Message-ID: <1463095306599-4677543.post@n4.nabble.com>

do not worry about vary  its not a bug its the way its setup the vary
handling yet it need plenty of work this is my guess after i look at the
code 

for a range_offset_limit use this test im using it long time and its
wonderful

collapsed_forwarding on
acl range_list_path urlpath_regex \.(mar|msp|esd|pkg\?)
range_offset_limit -1 windows_list_path 

range_offset_limit 16 KB all !range_list_path    #<---if you need this 
quick_abort_min 0 KB
quick_abort_max 0 KB
quick_abort_pct 100

im caching the above extension perfectly you can add to it 




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Getting-the-full-file-content-on-a-range-request-but-not-on-EVERY-get-tp4677503p4677543.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Walter.H at mathemainzel.info  Fri May 13 03:44:51 2016
From: Walter.H at mathemainzel.info (Walter H.)
Date: Fri, 13 May 2016 05:44:51 +0200
Subject: [squid-users] Regular expressions with dstdom_regex ACL
In-Reply-To: <5734E570.7080802@mathemainzel.info>
References: <5734E570.7080802@mathemainzel.info>
Message-ID: <57354DB3.9050608@mathemainzel.info>

On 12.05.2016 22:20, Walter H. wrote:
> Hello,
> can someone please tell me how I can achive this?
>
> the result should be that
> any URL like this
> http(s)://ip-address/ should be blocked by the specified error page
>
> Thanks and Greetings from Austria,
> Walter
p.s.
the sample here
http://wiki.squid-cache.org/ConfigExamples/Chat/Skype
doesn't work, too

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4312 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/952cd902/attachment.bin>

From squid3 at treenet.co.nz  Fri May 13 05:32:26 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 May 2016 17:32:26 +1200
Subject: [squid-users] Regular expressions with dstdom_regex ACL
In-Reply-To: <57354DB3.9050608@mathemainzel.info>
References: <5734E570.7080802@mathemainzel.info>
 <57354DB3.9050608@mathemainzel.info>
Message-ID: <4096a7bb-ee97-40f4-3755-11d6ddbc5e63@treenet.co.nz>

On 13/05/2016 3:44 p.m., Walter H. wrote:
> On 12.05.2016 22:20, Walter H. wrote:
>> Hello,
>> can someone please tell me how I can achive this?
>>
>> the result should be that
>> any URL like this
>> http(s)://ip-address/ should be blocked by the specified error page
>>
>> Thanks and Greetings from Austria,
>> Walter
> p.s.
> the sample here
> http://wiki.squid-cache.org/ConfigExamples/Chat/Skype
> doesn't work, too
> 

The skype pattern is matching the port Skype uses. You need to drop that
off the pattern. But it should match if you use just the raw-IP part.

Amos



From reet.vyas28 at gmail.com  Fri May 13 05:58:34 2016
From: reet.vyas28 at gmail.com (Reet Vyas)
Date: Fri, 13 May 2016 11:28:34 +0530
Subject: [squid-users] Squid Peek and splice
Message-ID: <CAA8ViV9-S_skfmrBMws8N6BCUkr9Uf6BoeLo3aLzpOgkSzt7Ew@mail.gmail.com>

Hi Amos/Yuri,

Currently my squid is configured with ssl bump, now I want to use peek and
splice. I read in some forum that we don't need to install certificate on
client's machine.

As I have already asked before in mailing list to install SSL certificate
on Android devices, which is not working.

So my question is If I want to use peek and splice for example I want https
filtering for  proxy websites  and I dont want ssl for bank websites and
facebook youtube and gmail. how will it work? Do i need to install SSL
certifcate on client or not, I am bit confused with peek and splice thing.

Please let me know is that possible to configure squid 3.5.19 in such a way
so that it will bump  only proxy websites not FB youtube etc.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/bf99d49f/attachment.htm>

From garryd at comnet.uz  Fri May 13 07:06:10 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Fri, 13 May 2016 12:06:10 +0500
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <b1a15d16-acdd-7009-f790-90e35ed9734b@cinbesa.com.br>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <1463025679.14398.4.camel@comnet.uz>
 <b1a15d16-acdd-7009-f790-90e35ed9734b@cinbesa.com.br>
Message-ID: <1463123170.1242.18.camel@comnet.uz>

On Thu, 2016-05-12 at 14:02 -0300, Heiler Bemerguy wrote:
>?
> Hi Garri,
> That bug report is mine.. lol

Hi Heiler,
Yes, I know it. I just tried to answer to the following question.

> > > Is there a smart way to allow squid to download it from the
> > > beginning
> > > to the end (to actually cache it), but only on the FIRST
> > > request/get?
> > > Even if it makes the user wait for the full download, or cancel
> > > it
> > > temporarily, or.. whatever!! Anything!!

The config option 'range_offset_limit none' (or -1) forces exactly that
behavior. It fetches whole object from the beginning to the end on
first range request. The problems you have encountered are consequences
of the bug 4469 you reported. I encountered the same problems using
Rock store. UFS/AUFS stores are not affected by the bug.

So, to fix the problem more quickly, the best way is to provide to
developers more information. For example, full debug log (ALL,9) for
isolated requests.

Thanks. Garri


From david at articatech.com  Fri May 13 07:06:46 2016
From: david at articatech.com (David Touzeau)
Date: Fri, 13 May 2016 09:06:46 +0200
Subject: [squid-users] ACL is used in context without an HTTP response.
	Assuming mismatch
In-Reply-To: <5735062D.2090902@measurement-factory.com>
References: <005001d1ac9a$3fe7c530$bfb74f90$@articatech.com>
 <5735062D.2090902@measurement-factory.com>
Message-ID: <001001d1ace6$034b7f30$09e27d90$@articatech.com>

Thanks Alex

Any ACLs  tips to avoid these warning ? or just assume it's normal in this situation... ?


-----Message d'origine-----
De : Alex Rousskov [mailto:rousskov at measurement-factory.com] 
Envoy? : vendredi 13 mai 2016 00:40
? : squid-users at lists.squid-cache.org
Cc : David Touzeau <david at articatech.com>
Objet : Re: [squid-users] ACL is used in context without an HTTP response. Assuming mismatch

On 05/12/2016 04:04 PM, David Touzeau wrote:
> 
> acl CODE_TCP_DENIED http_status 407
> access_log none CODE_TCP_DENIED
> 
>  
> 
> But squid claim :  
> 
> 2016/05/12 23:44:07 kid1| WARNING: CODE_TCP_DENIED ACL is used in 
> context without an HTTP response. Assuming mismatch.
>  
> 
> Why this rule is wrong ?

Squid attempts to log every access(*). Sometimes, Squid is accessed, but there is no response to log(**). Your rule assumes that there is always a response. Squid warns that your assumption is wrong for the specific access it is logging.

If there is no ACL that can be used to test the presence of a response (and a request) in a master transaction [without triggering such warnings], then we should add it.


Also, some Squids have bugs where there _is_ a response but Squid logging code does not know about it. If you are running a relatively recent Squid v4 release, you might be hitting one of those bugs (although I would expect more/different error messages in that case).


Endnotes:

(*) Squid fails to log certain accesses. We are fixing one of those bugs right now.

(**) Imagine, for example, a client that starts sending an HTTP request but closes the connection to Squid before finishing. Depending on what state Squid was in when the connection got closed, there may be no response created for that unfinished request.


HTH,

Alex.




From walter.h at mathemainzel.info  Fri May 13 08:22:12 2016
From: walter.h at mathemainzel.info (Walter H.)
Date: Fri, 13 May 2016 10:22:12 +0200
Subject: [squid-users] Regular expressions with dstdom_regex ACL
In-Reply-To: <4096a7bb-ee97-40f4-3755-11d6ddbc5e63@treenet.co.nz>
References: <5734E570.7080802@mathemainzel.info>
 <57354DB3.9050608@mathemainzel.info>
 <4096a7bb-ee97-40f4-3755-11d6ddbc5e63@treenet.co.nz>
Message-ID: <1613477bc245da2f8e0fc2a893a5e0ed.1463127732@squirrel.mail>

On Fri, May 13, 2016 07:32, Amos Jeffries wrote:
> On 13/05/2016 3:44 p.m., Walter H. wrote:
>> p.s.
>> the sample here
>> http://wiki.squid-cache.org/ConfigExamples/Chat/Skype
>> doesn't work, too
>>
>
> The skype pattern is matching the port Skype uses. You need to drop that
> off the pattern. But it should match if you use just the raw-IP part.

it is somewhat weired, because
wget http://[2a00:1a68:3:1::c5a5:8590]/
isn't blocked and the following are
all blocked as they should:
wget http://[2a00:1a68:3::c5a5:8590]/
wget http://[2a00:1a68:3:1::c5a:8590]/
wget http://[2a00:1a68:3:1::c5a5:859]/
wget http://[2a00:1a68:2:1::c5a5:8590]/

here this part in access.log

parentproxy.local - - [13/May/2016:09:44:10 +0200] "GET
http://[2a00:1a68:2:1::c5a5:8590]/ HTTP/1.0" 403 1578
"-" "Wget/1.12 (linux-gnu)" TCP_DENIED:HIER_NONE
parentproxy.local - - [13/May/2016:09:46:53 +0200] "GET
http://[2a00:1a68:3:1::c5a5:8590]/ HTTP/1.0" 301 590 "
-" "Wget/1.12 (linux-gnu)" TCP_MISS:HIER_DIRECT
parentproxy.local - - [13/May/2016:09:46:54 +0200] "GET
http://mathemainzel.info/ HTTP/1.0" 200 2662 "-" "Wget
/1.12 (linux-gnu)" TCP_MISS:HIER_DIRECT
parentproxy.local - - [13/May/2016:09:47:03 +0200] "GET
http://[2a00:1a68:2:1::c5a5:8590]/ HTTP/1.0" 403 1578
"-" "Wget/1.12 (linux-gnu)" TCP_DENIED:HIER_NONE
parentproxy.local - - [13/May/2016:09:47:14 +0200] "GET
http://[2a00:1a68:3::c5a5:8590]/ HTTP/1.0" 403 1574 "-
" "Wget/1.12 (linux-gnu)" TCP_DENIED:HIER_NONE
parentproxy.local - - [13/May/2016:09:47:37 +0200] "GET
http://[2a00:1a68:3:1::c5a:8590]/ HTTP/1.0" 403 1576 "
-" "Wget/1.12 (linux-gnu)" TCP_DENIED:HIER_NONE
parentproxy.local - - [13/May/2016:09:47:45 +0200] "GET
http://[2a00:1a68:3:1::c5a5:859]/ HTTP/1.0" 403 1576 "
-" "Wget/1.12 (linux-gnu)" TCP_DENIED:HIER_NONE

here the ACL

acl block_domains_iphost dstdom_regex "/etc/squid/iphost-acl.squid"
deny_info ERR_DOMAIN_IPHOST_BLOCKED block_domains_iphost
http_access deny block_domains_iphost

and iphost-acl.squid has the following content:

^[12]?[0-9]{1,2}\.[12]?[0-9]{1,2}\.[12]?[0-9]{1,2}\.[12]?[0-9]{1,2}$
^\[([0-9a-f]{0,4})(:|[0-9a-f]{0,4}){1,7}\]$
^\[::1\]$
^\[.*\]$
^([0-9a-f]{0,4})(:|[0-9a-f]{0,4}){1,7}$
^::1$
^.*$

some part above I have this in squid.conf

acl allow_domains dstdom_regex "/etc/squid/domain_regex-acl.squid"
http_access allow allow_domains

and domain_regex-acl.squid has the following content:

...
\.mathemainzel\.info$
...

what is this mystic, that
wget http://[2a00:1a68:3:1::c5a5:8590]/
isn't blocked, even it should ...

by the way  wget http://81.19.145.52/ is blocked as you see in the log

parentproxy.local - - [13/May/2016:10:12:53 +0200] "GET
http://81.19.145.52/ HTTP/1.0" 403 1550 "-" "Wget/1.12 (li
nux-gnu)" TCP_DENIED:HIER_NONE

just as an experiment, if I remove this one entry of domain_regex-acl.squid
then
wget http://[2a00:1a68:3:1::c5a5:8590]/
is blocked, why not with this entry?

Thanks and greetings from Austria,
Walter




From dzaczek at sysop.cat  Fri May 13 10:30:32 2016
From: dzaczek at sysop.cat (Dzaczek)
Date: Fri, 13 May 2016 06:30:32 -0400
Subject: [squid-users] Fw: Re:  Can`t cache always TCP_MISS
In-Reply-To: <67d499ba-901f-cc05-1cf7-04279191c815@treenet.co.nz>
References: <vIwfiejOsanU2XFGnwv-eEdHCxAW_E7F4oNyYjP1mfYd_sNblwFOzbvPAPv87aZQtJwRpX52vqkD6RiFEXdodg==@sysop.cat>
 <67d499ba-901f-cc05-1cf7-04279191c815@treenet.co.nz>
Message-ID: <ovmOW5pLI8cFjtPmpxmaVy8-9cHtAv3lwOVA273YbX3fM9YGPl9QCMov00XuiJm0-CEGFII4iVvsnlGVp5-NyA==@sysop.cat>

changed aufs to ufs

access log:
1463135303.983 370 10.150.21.23 TCP_MISS/200 85386 GET http://x3.cdn03.imgwykop.pl/c3201142/comment_SqqWeOgh3ilDsHNY4goI2JJOrYJ8uX9V.jpg - HIER_DIRECT/213.189.55.117 image/jpeg
1463135305.547 107 10.150.21.23 TCP_MISS/200 85386 GET http://x3.cdn03.imgwykop.pl/c3201142/comment_SqqWeOgh3ilDsHNY4goI2JJOrYJ8uX9V.jpg - HIER_DIRECT/213.189.55.117 image/jpeg
1463135306.925 96 10.150.21.23 TCP_MISS/200 85386 GET http://x3.cdn03.imgwykop.pl/c3201142/comment_SqqWeOgh3ilDsHNY4goI2JJOrYJ8uX9V.jpg - HIER_DIRECT/213.189.55.117 image/jpeg


cachelog
2016/05/13 11:28:23.878 kid1| 20,2| store_io.cc(42) storeCreate: storeCreate: Selected dir 0 for e:=w1p2DV/0x2dd9610*4
2016/05/13 11:28:25.496 kid1| 20,2| store_io.cc(42) storeCreate: storeCreate: Selected dir 0 for e:=w1p2DV/0x286b850*4
2016/05/13 11:28:26.873 kid1| 20,2| store_io.cc(42) storeCreate: storeCreate: Selected dir 0 for e:=w1p2DV/0x2683c60*4



Linux is like wigwam: no Gates, no Windows and Apache inside.



-------- Original Message --------
Subject: Re: [squid-users] Can`t cache always TCP_MISS
Local Time: 11 maja 2016 2:30 PM
UTC Time: 11 maja 2016 12:30
From
To: squid-users at lists.squid-cache.org

On 11/05/2016 10:43 p.m., Jacek Zaleski wrote:
> Hi
> i try use squid in my centos7 in 99% request i have TCP_MISS/200
>
> Debugging

NP: the debug log snippet you posted contains nothing relevant to the
issue described.
Please configure:
debug_options ALL,1 20,2

and look for lines "checkCachable" and stating why each objects is not
stored.


> My config pats
>
> cache dir :
> 98 cache_mem 800 MB
> 99 logfile_rotate 10
> 100 memory_pools off
> 101 minimum_object_size 0 bytes
> 102 maximum_object_size 200 MB
> 103 maximum_object_size_in_memory 512 KB
> 104 #quick_abort_min 0 KB
> 105 #quick_abort_max 0 KB
> 106 log_icp_queries off
> 107 client_db off
> 108 buffered_logs on
> 109 half_closed_clients off
> 110 cache_log /var/log/squid/cache1.log
> 111
> 112 # Uncomment and adjust the following to add a disk cache directory.
> 113 cache_dir aufs /squid-cache 65536 128 256 min-size=512000
> 114
> 115 # Leave coredumps in the first cache dir
> 116 coredump_dir /var/spool/squid
> 117
> 118 #error_directory /usr/share/nginx/404site
> 119 #Special Options for 0365
> 120 forward_max_tries 25
> 121 #
>
>
>
> patterns :
>
> 124 refresh_pattern ^ftp: 1440 20% 10080
> 125 refresh_pattern ^gopher: 1440 0% 1440
> 126 refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
> 127 refresh_pattern -i \.(gif|png|jpg|jpeg|ico)$ 10080 90% 160000 override-expire ignore-no-cache ignore-no-store ignore-private
> 128 refresh_pattern -i \.(iso|avi|wav|mp3|mp4|mpeg|swf|flv|x-flv)$ 43200 90% 160000 override-expire ignore-no-cache ignore-no-store ignore-private
> 129 refresh_pattern -i \.(deb|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff)$ 10080 90% 160000 override-expire ignore-no-cache ignore-no-store ignore-private
> 130 refresh_pattern -i \.index.(html|htm)$ 0 40% 10080
> 131 refresh_pattern . 600 40% 40320 ignore-no-store override-expire

ignore-no-cache is obsolete. Please remove all uses of it.

ignore-no-stre and ignore-private are highly dangerous. Please also
remove those.


> 132 cache allow all
> 133 cache_effective_user squid
> 134 cache_effective_group squid
> 135 ## allow replies to client requests
> 136 http_reply_access allow all

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/ce0f601d/attachment.htm>

From squid3 at treenet.co.nz  Fri May 13 11:07:56 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 May 2016 23:07:56 +1200
Subject: [squid-users] Squid Peek and splice
In-Reply-To: <CAA8ViV9-S_skfmrBMws8N6BCUkr9Uf6BoeLo3aLzpOgkSzt7Ew@mail.gmail.com>
References: <CAA8ViV9-S_skfmrBMws8N6BCUkr9Uf6BoeLo3aLzpOgkSzt7Ew@mail.gmail.com>
Message-ID: <1834a08e-7e03-cf08-0d15-e84ee63cd200@treenet.co.nz>

On 13/05/2016 5:58 p.m., Reet Vyas wrote:
> Hi Amos/Yuri,
> 
> Currently my squid is configured with ssl bump, now I want to use peek and
> splice. I read in some forum that we don't need to install certificate on
> client's machine.
> 

Splice does not require it. But what you want to do with Squid may
prevent splice being used. So "it depends" ...


> As I have already asked before in mailing list to install SSL certificate
> on Android devices, which is not working.
> 
> So my question is If I want to use peek and splice for example I want https
> filtering for 

 ... on how you define "filter".

> proxy websites 

Not sure what you mean by that term.

> and I dont want ssl for bank websites and
> facebook youtube and gmail. how will it work? Do i need to install SSL
> certifcate on client or not, I am bit confused with peek and splice thing.

When you intercept port 443 normally only the raw-IP is available from
TCP. Peek allows Squid to get the server name the client was trying to
connect to out of the TLS. So that Squid can handle the intercepted
connection as if it had received a CONNECT message (which usually have
server/domain names).

Splicing can be thought of as handling a intercepted port 443 connection
as if it were a CONNECT message, with no decryption. It is treated as a
single "thing", with some limited control possibilities.


So...

In order to bump (decrypt) some traffic and splice (not decrypt) other
traffic you need to have a way to decide which type is being dealt with.
That is the peek or stare actions - to get data out of the TLS handshake
for you to use in ACL decisions.

You might now want to re-read the SslPeekAndSplice documentation again
to see if you understand it better. I skipped a lot of important details
to make the description clear.


> 
> Please let me know is that possible to configure squid 3.5.19 in such a way
> so that it will bump  only proxy websites not FB youtube etc.
> 

Ah. So what are these "proxy websites" you speak of ?

One thing you need to be clear about is that once the TCP packets enter
Squid they *have* to be "proxied". There is no way to undo TCP accept()
and read() operations. But there are many ways of handling them that
Squid can do.

PS. you could post your existing config so we can suggest alterations to
it that will lead to it doing your new policy. That can be another way
to learn how the relevant-to-you part of the features work without
diving into the full complexity of what *might* be doable.

Amos



From chip_pop at hotmail.com  Fri May 13 10:43:18 2016
From: chip_pop at hotmail.com (joe)
Date: Fri, 13 May 2016 03:43:18 -0700 (PDT)
Subject: [squid-users] Fw: Re:  Can`t cache always TCP_MISS
In-Reply-To: <ovmOW5pLI8cFjtPmpxmaVy8-9cHtAv3lwOVA273YbX3fM9YGPl9QCMov00XuiJm0-CEGFII4iVvsnlGVp5-NyA==@sysop.cat>
References: <vIwfiejOsanU2XFGnwv-eEdHCxAW_E7F4oNyYjP1mfYd_sNblwFOzbvPAPv87aZQtJwRpX52vqkD6RiFEXdodg==@sysop.cat>
 <67d499ba-901f-cc05-1cf7-04279191c815@treenet.co.nz>
 <ovmOW5pLI8cFjtPmpxmaVy8-9cHtAv3lwOVA273YbX3fM9YGPl9QCMov00XuiJm0-CEGFII4iVvsnlGVp5-NyA==@sysop.cat>
Message-ID: <1463136198982-4677552.post@n4.nabble.com>

the img link has smale object size the one you post
i dont know if this has to do with you problem try

113 cache_dir aufs /squid-cache 65536 128 256 
without      min-size=512000 

check and see the object size 

if you want to control the min  size use this instead
minimum_object_size 0 bytes         <--- change to min size u want

first try without   min-size=512000       and see if you get hit on smale
obj



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Can-t-cache-always-TCP-MISS-tp4677485p4677552.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Fri May 13 11:27:28 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 May 2016 23:27:28 +1200
Subject: [squid-users] ACL is used in context without an HTTP response.
 Assuming mismatch
In-Reply-To: <001001d1ace6$034b7f30$09e27d90$@articatech.com>
References: <005001d1ac9a$3fe7c530$bfb74f90$@articatech.com>
 <5735062D.2090902@measurement-factory.com>
 <001001d1ace6$034b7f30$09e27d90$@articatech.com>
Message-ID: <df968238-a9a3-c977-e4d8-1b96fd45f22e@treenet.co.nz>

On 13/05/2016 7:06 p.m., David Touzeau wrote:
> Thanks Alex
> 
> Any ACLs  tips to avoid these warning ? or just assume it's normal in this situation... ?
> 

Yes and no. It was added to be a type of canary to unexpected behaviours
in the config. So in that regard it has done its job well by making you
look and ask about why its happening.

What Alex describes there as potential causes could be a sign of clients
having bad experiences with the proxy. Or just browser "Happy Eyeballs"
doing its annoying thing. It'll have to be a judgement call for you
whether to do much more investigation or not.

The answer is also very specific to that one named ACL and how it was
used. So other similar looking warnings could have very different
impacts and severity.


The only way to completely silence the warning right now is to not use
that ACL for that access control. If its annoying we are open to adding
a throttle to it.

HTH
Amos



From squid3 at treenet.co.nz  Fri May 13 11:46:53 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 13 May 2016 23:46:53 +1200
Subject: [squid-users] Regular expressions with dstdom_regex ACL
In-Reply-To: <1613477bc245da2f8e0fc2a893a5e0ed.1463127732@squirrel.mail>
References: <5734E570.7080802@mathemainzel.info>
 <57354DB3.9050608@mathemainzel.info>
 <4096a7bb-ee97-40f4-3755-11d6ddbc5e63@treenet.co.nz>
 <1613477bc245da2f8e0fc2a893a5e0ed.1463127732@squirrel.mail>
Message-ID: <1a7027ad-dfe8-9363-3e0e-e494e2d0200c@treenet.co.nz>

On 13/05/2016 8:22 p.m., Walter H. wrote:
> On Fri, May 13, 2016 07:32, Amos Jeffries wrote:
>> On 13/05/2016 3:44 p.m., Walter H. wrote:
>>> p.s.
>>> the sample here
>>> http://wiki.squid-cache.org/ConfigExamples/Chat/Skype
>>> doesn't work, too
>>>
>>
>> The skype pattern is matching the port Skype uses. You need to drop that
>> off the pattern. But it should match if you use just the raw-IP part.
> 
> it is somewhat weired, because
> wget http://[2a00:1a68:3:1::c5a5:8590]/
> isn't blocked and the following are
> all blocked as they should:
> wget http://[2a00:1a68:3::c5a5:8590]/
> wget http://[2a00:1a68:3:1::c5a:8590]/
> wget http://[2a00:1a68:3:1::c5a5:859]/
> wget http://[2a00:1a68:2:1::c5a5:8590]/
> 
> here this part in access.log
> 
> parentproxy.local - - [13/May/2016:09:44:10 +0200] "GET
> http://[2a00:1a68:2:1::c5a5:8590]/ HTTP/1.0" 403 1578
> "-" "Wget/1.12 (linux-gnu)" TCP_DENIED:HIER_NONE
> parentproxy.local - - [13/May/2016:09:46:53 +0200] "GET
> http://[2a00:1a68:3:1::c5a5:8590]/ HTTP/1.0" 301 590 "
> -" "Wget/1.12 (linux-gnu)" TCP_MISS:HIER_DIRECT
> parentproxy.local - - [13/May/2016:09:46:54 +0200] "GET
> http://mathemainzel.info/ HTTP/1.0" 200 2662 "-" "Wget
> /1.12 (linux-gnu)" TCP_MISS:HIER_DIRECT
> parentproxy.local - - [13/May/2016:09:47:03 +0200] "GET
> http://[2a00:1a68:2:1::c5a5:8590]/ HTTP/1.0" 403 1578
> "-" "Wget/1.12 (linux-gnu)" TCP_DENIED:HIER_NONE
> parentproxy.local - - [13/May/2016:09:47:14 +0200] "GET
> http://[2a00:1a68:3::c5a5:8590]/ HTTP/1.0" 403 1574 "-
> " "Wget/1.12 (linux-gnu)" TCP_DENIED:HIER_NONE
> parentproxy.local - - [13/May/2016:09:47:37 +0200] "GET
> http://[2a00:1a68:3:1::c5a:8590]/ HTTP/1.0" 403 1576 "
> -" "Wget/1.12 (linux-gnu)" TCP_DENIED:HIER_NONE
> parentproxy.local - - [13/May/2016:09:47:45 +0200] "GET
> http://[2a00:1a68:3:1::c5a5:859]/ HTTP/1.0" 403 1576 "
> -" "Wget/1.12 (linux-gnu)" TCP_DENIED:HIER_NONE
> 
> here the ACL
> 
> acl block_domains_iphost dstdom_regex "/etc/squid/iphost-acl.squid"
> deny_info ERR_DOMAIN_IPHOST_BLOCKED block_domains_iphost
> http_access deny block_domains_iphost
> 
> and iphost-acl.squid has the following content:
> 
> ^[12]?[0-9]{1,2}\.[12]?[0-9]{1,2}\.[12]?[0-9]{1,2}\.[12]?[0-9]{1,2}$
> ^\[([0-9a-f]{0,4})(:|[0-9a-f]{0,4}){1,7}\]$
> ^\[::1\]$
> ^\[.*\]$
> ^([0-9a-f]{0,4})(:|[0-9a-f]{0,4}){1,7}$
> ^::1$
> ^.*$

This last pattern overlaps with all the previous ones and any possible
following as well. Squid takes short patterns and merges them in to one
pattern if it can to pass to that optimizer. They might all just be
optimized away by the regex compile step.

Your block_domains_iphost should thus be an alias for "all".

> 
> some part above I have this in squid.conf
> 
> acl allow_domains dstdom_regex "/etc/squid/domain_regex-acl.squid"
> http_access allow allow_domains
> 
> and domain_regex-acl.squid has the following content:
> 
> ...
> \.mathemainzel\.info$
> ...
> 
> what is this mystic, that
> wget http://[2a00:1a68:3:1::c5a5:8590]/
> isn't blocked, even it should ...
> 
> by the way  wget http://81.19.145.52/ is blocked as you see in the log
> 
> parentproxy.local - - [13/May/2016:10:12:53 +0200] "GET
> http://81.19.145.52/ HTTP/1.0" 403 1550 "-" "Wget/1.12 (li
> nux-gnu)" TCP_DENIED:HIER_NONE
> 
> just as an experiment, if I remove this one entry of domain_regex-acl.squid
> then
> wget http://[2a00:1a68:3:1::c5a5:8590]/
> is blocked, why not with this entry?

Nobody can answer that question without actually seeing your whole
squid.conf http_access set and all ACLs used there.

You are correct in that those regex patterns should match the domains an
URLs passed to the proxy. But we have no way to know if those particular
lines are even relevant / reachable when processing those requests.
 Since these ACL types are very old and well tested logic. I suggest
that they are probably not.

Amos



From squid3 at treenet.co.nz  Fri May 13 12:02:47 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 May 2016 00:02:47 +1200
Subject: [squid-users] Fw: Re: Can`t cache always TCP_MISS
In-Reply-To: <1463136198982-4677552.post@n4.nabble.com>
References: <vIwfiejOsanU2XFGnwv-eEdHCxAW_E7F4oNyYjP1mfYd_sNblwFOzbvPAPv87aZQtJwRpX52vqkD6RiFEXdodg==@sysop.cat>
 <67d499ba-901f-cc05-1cf7-04279191c815@treenet.co.nz>
 <ovmOW5pLI8cFjtPmpxmaVy8-9cHtAv3lwOVA273YbX3fM9YGPl9QCMov00XuiJm0-CEGFII4iVvsnlGVp5-NyA==@sysop.cat>
 <1463136198982-4677552.post@n4.nabble.com>
Message-ID: <f09c6dd1-f65c-bd7a-9633-338e3815cef8@treenet.co.nz>

On 13/05/2016 10:43 p.m., joe wrote:
> the img link has smale object size the one you post
> i dont know if this has to do with you problem try
> 
> 113 cache_dir aufs /squid-cache 65536 128 256 
> without      min-size=512000 
> 
> check and see the object size 
> 
> if you want to control the min  size use this instead
> minimum_object_size 0 bytes         <--- change to min size u want
> 
> first try without   min-size=512000       and see if you get hit on smale
> obj

Yes that might be a good test.

Though the way I'm reading that config (and Squid should be) is objects
under 512KB are stored in memory, 512000 bytes - 512KB are store in
either memory or disk, and over-512KB are stored only on disk.


The debug log is indicating that something in the active logic is
explicitly requesting that the object not be stored. The store is not
going on to do any figuring out of whether its cacheable because it has
already been explicitly told not to.

What does the rest of your config contain?
 Are you intercepting the traffic and using Google DNS perhapse? that
particular combo can easily make the traffic not cacheable.

Amos



From dzaczek at sysop.cat  Fri May 13 12:05:21 2016
From: dzaczek at sysop.cat (Dzaczek)
Date: Fri, 13 May 2016 08:05:21 -0400
Subject: [squid-users] Fw: Re:  Can`t cache always TCP_MISS
In-Reply-To: <1463136198982-4677552.post@n4.nabble.com>
References: <vIwfiejOsanU2XFGnwv-eEdHCxAW_E7F4oNyYjP1mfYd_sNblwFOzbvPAPv87aZQtJwRpX52vqkD6RiFEXdodg==@sysop.cat>
 <67d499ba-901f-cc05-1cf7-04279191c815@treenet.co.nz>
 <ovmOW5pLI8cFjtPmpxmaVy8-9cHtAv3lwOVA273YbX3fM9YGPl9QCMov00XuiJm0-CEGFII4iVvsnlGVp5-NyA==@sysop.cat>
 <1463136198982-4677552.post@n4.nabble.com>
Message-ID: <Pe81bAkB0YaHIILNKuoFEMBMv7FbePXMlgVob7KOqtCGUUTPG1RVf8ZThcylFoZ84ww_vBDwneVBNONjXbOwvA==@sysop.cat>

Again miss
i check on smaller picture and change cache minimum_obejc_size 0 and removed min-size

1463141030.059 39 10.150.21.23 TCP_REFRESH_UNMODIFIED/304 539 GET http://miscmedia-9gag-fun.9cache.com/images/featured/1462860779.7596_WaQy8A_300.jpg - HIER_DIRECT/108.161.188.132 -
1463141030.108 18 10.150.21.23 TCP_CLIENT_REFRESH_MISS/200 693 GET http://miscmedia-9gag-fun.9cache.com/favicon.ico - HIER_DIRECT/108.161.188.132 image/x-icon

2016/05/13 13:03:50.058 kid1| 20,2| store.cc(954) checkCachable: StoreEntry::checkCachable: NO: not cachable
2016/05/13 13:03:50.059 kid1| 20,2| store.cc(954) checkCachable: StoreEntry::checkCachable: NO: not cachable
2016/05/13 13:03:50.059 kid1| 20,2| store.cc(954) checkCachable: StoreEntry::checkCachable: NO: not cachable
2016/05/13 13:03:50.059 kid1| 20,2| store.cc(954) checkCachable: StoreEntry::checkCachable: NO: not cachable
2016/05/13 13:03:50.059 kid1| 20,2| store.cc(954) checkCachable: StoreEntry::checkCachable: NO: not cachable
2016/05/13 13:03:50.108 kid1| 20,2| store_io.cc(42) storeCreate: storeCreate: Selected dir 0 for e:=sw1p2DV/0x291a860*4


...
Linux is like wigwam: no Gates, no Windows and Apache inside.



-------- Original Message --------
Subject: Re: [squid-users] Fw: Re: Can`t cache always TCP_MISS
Local Time: 13 maja 2016 12:43 PM
UTC Time: 13 maja 2016 10:43
From:
To: squid-users at lists.squid-cache.org

the img link has smale object size the one you post
i dont know if this has to do with you problem try

113 cache_dir aufs /squid-cache 65536 128 256
without min-size=512000

check and see the object size

if you want to control the min size use this instead
minimum_object_size 0 bytes <--- change to min size u want

first try without min-size=512000 and see if you get hit on smale
obj



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Can-t-cache-always-TCP-MISS-tp4677485p4677552.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/c5d0adee/attachment.htm>

From dzaczek at sysop.cat  Fri May 13 12:14:48 2016
From: dzaczek at sysop.cat (Dzaczek)
Date: Fri, 13 May 2016 08:14:48 -0400
Subject: [squid-users] Fw: Re: Can`t cache always TCP_MISS
In-Reply-To: <f09c6dd1-f65c-bd7a-9633-338e3815cef8@treenet.co.nz>
References: <vIwfiejOsanU2XFGnwv-eEdHCxAW_E7F4oNyYjP1mfYd_sNblwFOzbvPAPv87aZQtJwRpX52vqkD6RiFEXdodg==@sysop.cat>
 <67d499ba-901f-cc05-1cf7-04279191c815@treenet.co.nz>
 <ovmOW5pLI8cFjtPmpxmaVy8-9cHtAv3lwOVA273YbX3fM9YGPl9QCMov00XuiJm0-CEGFII4iVvsnlGVp5-NyA==@sysop.cat>
 <1463136198982-4677552.post@n4.nabble.com>
 <f09c6dd1-f65c-bd7a-9633-338e3815cef8@treenet.co.nz>
Message-ID: <wg-OIer8OEHBVL5AMe3gbUSVp1ncysS268WmE5obCDQvIVaMM5aaoiPwveyNgX_oap0OmiiFwP1ya8RK0jlp2w==@sysop.cat>

http://codepaste.net/pvx4j1


...
Linux is like wigwam: no Gates, no Windows and Apache inside.



-------- Original Message --------
Subject: Re: [squid-users] Fw: Re: Can`t cache always TCP_MISS
Local Time: 13 maja 2016 2:02 PM
UTC Time: 13 maja 2016 12:02
From: squid3 at treenet.co.nz
To: squid-users at lists.squid-cache.org

On 13/05/2016 10:43 p.m., joe wrote:
> the img link has smale object size the one you post
> i dont know if this has to do with you problem try
>
> 113 cache_dir aufs /squid-cache 65536 128 256
> without min-size=512000
>
> check and see the object size
>
> if you want to control the min size use this instead
> minimum_object_size 0 bytes <--- change to min size u want
>
> first try without min-size=512000 and see if you get hit on smale
> obj

Yes that might be a good test.

Though the way I'm reading that config (and Squid should be) is objects
under 512KB are stored in memory, 512000 bytes - 512KB are store in
either memory or disk, and over-512KB are stored only on disk.


The debug log is indicating that something in the active logic is
explicitly requesting that the object not be stored. The store is not
going on to do any figuring out of whether its cacheable because it has
already been explicitly told not to.

What does the rest of your config contain?
Are you intercepting the traffic and using Google DNS perhapse? that
particular combo can easily make the traffic not cacheable.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/02904f09/attachment.htm>

From asakura at ioc.dnp.co.jp  Fri May 13 12:26:36 2016
From: asakura at ioc.dnp.co.jp (asakura at ioc.dnp.co.jp)
Date: Fri, 13 May 2016 21:26:36 +0900 (JST)
Subject: [squid-users] authenticate_ip_ttl does not work
Message-ID: <20160513.212636.1000278277145491810.asakura@ioc.dnp.co.jp>

Hello,

Thank you always for your kind support.

I testing squid-3.5.19 "max_user_ip/authenticate_ip_ttl" feature.
but, access control not work well.
(Value of authenticate_ip_ttl is not enable)

I investigating, and tried to change as follows.

src/auth/User.cc
----
# diff User.cc.org User.cc
287c287
<             ipdata->ip_expiretime = squid_curtime;
---
>             ipdata->ip_expiretime = squid_curtime + ::Config.authenticateIpTTL;
----

Is this would be correct change?

Sorry my poor English.

regards,
Kazuhiro


From garryd at comnet.uz  Fri May 13 12:38:32 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Fri, 13 May 2016 17:38:32 +0500
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <bc769369-02f1-42b3-efb9-73c367c57de9@treenet.co.nz>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
 <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated>
 <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
 <2b955257-003f-7b4a-b9d1-7d9aea6bfd86@cinbesa.com.br>
 <bc769369-02f1-42b3-efb9-73c367c57de9@treenet.co.nz>
Message-ID: <1463143112.1242.26.camel@comnet.uz>

On Fri, 2016-05-13 at 08:36 +1200, Amos Jeffries wrote:
> Have you given collapsed_forwarding a try? Its supposed to prevent
> all
> the duplicate requests making all those extra upstream connections
> unti
> at least the first one has finished getting the object.

Amos, I believe that the above quote describes default Squid's action,
which does not require collapsed_forwarding. The details of my
experiments can be found here?http://bugs.squid-cache.org/show_bug.cgi?
id=4511#c0. Thanks.

Garri


From squid3 at treenet.co.nz  Fri May 13 12:52:35 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 May 2016 00:52:35 +1200
Subject: [squid-users] Fw: Re: Can`t cache always TCP_MISS
In-Reply-To: <Pe81bAkB0YaHIILNKuoFEMBMv7FbePXMlgVob7KOqtCGUUTPG1RVf8ZThcylFoZ84ww_vBDwneVBNONjXbOwvA==@sysop.cat>
References: <vIwfiejOsanU2XFGnwv-eEdHCxAW_E7F4oNyYjP1mfYd_sNblwFOzbvPAPv87aZQtJwRpX52vqkD6RiFEXdodg==@sysop.cat>
 <67d499ba-901f-cc05-1cf7-04279191c815@treenet.co.nz>
 <ovmOW5pLI8cFjtPmpxmaVy8-9cHtAv3lwOVA273YbX3fM9YGPl9QCMov00XuiJm0-CEGFII4iVvsnlGVp5-NyA==@sysop.cat>
 <1463136198982-4677552.post@n4.nabble.com>
 <Pe81bAkB0YaHIILNKuoFEMBMv7FbePXMlgVob7KOqtCGUUTPG1RVf8ZThcylFoZ84ww_vBDwneVBNONjXbOwvA==@sysop.cat>
Message-ID: <8210668d-35f2-def9-b535-a1768bc84806@treenet.co.nz>

On 14/05/2016 12:05 a.m., Dzaczek wrote:
> Again miss
> i check on smaller picture and change cache minimum_obejc_size 0 and removed min-size
> 
> 1463141030.059 39 10.150.21.23 TCP_REFRESH_UNMODIFIED/304 539 GET http://miscmedia-9gag-fun.9cache.com/images/featured/1462860779.7596_WaQy8A_300.jpg - HIER_DIRECT/108.161.188.132 -
> 1463141030.108 18 10.150.21.23 TCP_CLIENT_REFRESH_MISS/200 693 GET http://miscmedia-9gag-fun.9cache.com/favicon.ico - HIER_DIRECT/108.161.188.132 image/x-icon
> 

These are not MISS. Despite what that second one looks like.

The first one was stale, but on revalidate the server informed Squid it
was still the latest copy ('UNMODIFIED/304').

The second one was for a client who required a revalidation. The server
delivered a whole new object (the 'MISS/200' bit).


> 2016/05/13 13:03:50.058 kid1| 20,2| store.cc(954) checkCachable: StoreEntry::checkCachable: NO: not cachable
> 2016/05/13 13:03:50.059 kid1| 20,2| store.cc(954) checkCachable: StoreEntry::checkCachable: NO: not cachable
> 2016/05/13 13:03:50.059 kid1| 20,2| store.cc(954) checkCachable: StoreEntry::checkCachable: NO: not cachable
> 2016/05/13 13:03:50.059 kid1| 20,2| store.cc(954) checkCachable: StoreEntry::checkCachable: NO: not cachable
> 2016/05/13 13:03:50.059 kid1| 20,2| store.cc(954) checkCachable: StoreEntry::checkCachable: NO: not cachable

The 304 response message itself is not cacheable. Also, the object it is
updating is already in cache so does not need re-saving there. It might
have had some timestamp updates etc, but bug #7 still affects Squid-3.


> 2016/05/13 13:03:50.108 kid1| 20,2| store_io.cc(42) storeCreate: storeCreate: Selected dir 0 for e:=sw1p2DV/0x291a860*4
> 

The new object received in the 200 response message was saved to cache.


That looks as expected for these two.

Amos



From jonathan.f at wobiz.com  Fri May 13 13:15:17 2016
From: jonathan.f at wobiz.com (Jonathan Filogna)
Date: Fri, 13 May 2016 10:15:17 -0300
Subject: [squid-users] Squid: Caching Google Drive Files?
Message-ID: <CAA5u_zMPX5-knj2iTuekbxNKYNhY2ADi_SMe65JVAMCiC7ROFw@mail.gmail.com>

Hello all. Here's a question: Can Squid do a cach? for some files storaged
on googledrive with ssl intercept?

-- 
Jonathan Filogna
SysAdmin
NeoSitios http://www.neositios.com/
Wobiz http://www.wobiz.com/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/60616353/attachment.htm>

From squid3 at treenet.co.nz  Fri May 13 13:40:56 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 May 2016 01:40:56 +1200
Subject: [squid-users] Fw: Re: Can`t cache always TCP_MISS
In-Reply-To: <wg-OIer8OEHBVL5AMe3gbUSVp1ncysS268WmE5obCDQvIVaMM5aaoiPwveyNgX_oap0OmiiFwP1ya8RK0jlp2w==@sysop.cat>
References: <vIwfiejOsanU2XFGnwv-eEdHCxAW_E7F4oNyYjP1mfYd_sNblwFOzbvPAPv87aZQtJwRpX52vqkD6RiFEXdodg==@sysop.cat>
 <67d499ba-901f-cc05-1cf7-04279191c815@treenet.co.nz>
 <ovmOW5pLI8cFjtPmpxmaVy8-9cHtAv3lwOVA273YbX3fM9YGPl9QCMov00XuiJm0-CEGFII4iVvsnlGVp5-NyA==@sysop.cat>
 <1463136198982-4677552.post@n4.nabble.com>
 <f09c6dd1-f65c-bd7a-9633-338e3815cef8@treenet.co.nz>
 <wg-OIer8OEHBVL5AMe3gbUSVp1ncysS268WmE5obCDQvIVaMM5aaoiPwveyNgX_oap0OmiiFwP1ya8RK0jlp2w==@sysop.cat>
Message-ID: <34461eb2-38eb-234e-1c8a-524b80e87425@treenet.co.nz>

On 14/05/2016 12:14 a.m., Dzaczek wrote:
> http://codepaste.net/pvx4j1
> 

Doesn't seem to be anything obviously relating to your problem in there.



Though I have a few recommendations for improvements:

* use of always_direct is deviously the opposite of what one might
expecte from reading the config file.

I suggest replacing it with:
   http_access deny !whitelist

which better describes what it actually does currently: cause denial of
anything not on the whitelist.

Note that since nobody can get *out* of the proxy to any other site
there can't be any cached content for those requests to use. So no point
at all in even letting them into Squid. Which brings up...


* Your Squid could be doing a lot of work internally for things that are
not allowed to happen anyway.

Get better performance out of your proxy by doing the security checks on
traffic ingress (http_access) not on traffic egress (miss_access /
always_direct, request_header_access).


* the workday_site ACL is very dangerous.

It currently allows anyone to put the word "workday" into any URL to
bypass the other proxy ingress security.

I cant actually see any reason why this ACL and http_access exist.
localnet and localhost are permitted to do what they like anyway within
the whitelisted sites set.
 Ditto for the FTP / ftp ACL and http_access lines



* You have lost the default security check "http_access deny CONNECT
!SSL_ports"

 That one is particularly important seeing as CONNECT tunnels are not
subject to always_direct which is your main access control currently.
AND you have several http_access control allowing


* you have several things above the basic port security checks.

I know we used to say that was okay, but the world has moved on. Please
make sure "http_access deny !Safe_ports" is at the top of the
http_access list, and reinstate the above mentioned CONNECT rule right
after it.

Instead of placing things above these rules, adjust the Safe_ports and
SSL_ports lists as needed and only after careful consideration of
whether you have to.



* ignore-no-cache is obsolete since Squid-3.2.

It also does the opposite of what most people want to use it for. As in:
it _prevents_ caching of things in HTTP/1.1, or at least it would if
Squid did not ignore the obsolete config.

Likewise ignore-no-store and ignore-private are highly dangerous, but
for privacy breach reasons. Current releases of Squid the ignore-private
will make CC:private response headers operate as if they were
CC:must-revalidate.


* "header_replace Accept" does nothing unless you also
"request_header_access Accept deny ..."


* request_header_access does nothing useful on response headers.

Have a look through
<http://www.iana.org/assignments/message-headers/message-headers.xhtml>
referenced RFCs to see which ones are actually request headers. RFC 723x
(x being 0, 1, 2, 3, 4, 5, 8) are the main HTTP documents.

There are some like Transfer-Encoding, If-Match, If-None-Match,
If-Unodified-Since that you are causing to be removed but are needed by
Squid.

* there are quite a few directives being set to their current default
values.

You could simplify the config file a bit by removing those lines. In
Squid-3 you only need to configure things that you are changing from
their default behaviour.


Phew, hope thats the lot.

HTH
Amos


From squid3 at treenet.co.nz  Fri May 13 13:44:35 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 May 2016 01:44:35 +1200
Subject: [squid-users] Squid: Caching Google Drive Files?
In-Reply-To: <CAA5u_zMPX5-knj2iTuekbxNKYNhY2ADi_SMe65JVAMCiC7ROFw@mail.gmail.com>
References: <CAA5u_zMPX5-knj2iTuekbxNKYNhY2ADi_SMe65JVAMCiC7ROFw@mail.gmail.com>
Message-ID: <31c59553-7fd9-159e-34bc-b441f35700c6@treenet.co.nz>

On 14/05/2016 1:15 a.m., Jonathan Filogna wrote:
> Hello all. Here's a question: Can Squid do a cach? for some files storaged
> on googledrive with ssl intercept?
> 

1) Are the HTTP transactions used to ftech those files cacheable?

 - this determines whether the caching part of your question will work
or fail.


2) are they being accessed with Google software or other software?

 - this will determine whether certificate pinning tat Google love so
much will prevent the intercept working.


Amos



From squid3 at treenet.co.nz  Fri May 13 13:52:11 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 May 2016 01:52:11 +1200
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <1463143112.1242.26.camel@comnet.uz>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
 <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
 <2b955257-003f-7b4a-b9d1-7d9aea6bfd86@cinbesa.com.br>
 <bc769369-02f1-42b3-efb9-73c367c57de9@treenet.co.nz>
 <1463143112.1242.26.camel@comnet.uz>
Message-ID: <6af1d850-03d4-33bd-25d8-bf9ca202afd9@treenet.co.nz>

On 14/05/2016 12:38 a.m., Garri Djavadyan wrote:
> On Fri, 2016-05-13 at 08:36 +1200, Amos Jeffries wrote:
>> Have you given collapsed_forwarding a try? Its supposed to prevent
>> all
>> the duplicate requests making all those extra upstream connections
>> unti
>> at least the first one has finished getting the object.
> 
> Amos, I believe that the above quote describes default Squid's action,
> which does not require collapsed_forwarding. The details of my
> experiments can be found here http://bugs.squid-cache.org/show_bug.cgi?
> id=4511#c0. Thanks.
> 

The default action should be to fetch each range request separately and
in parallel. Not caching the results.

When admin has set only the range offset & quick-abort to force full
object retrieval the behaviour Heiler mentions happens - lots of
upstream bandwidth used for N copies.
 The first one to complete starts to be used as a HIT for future
reuqests. But as each of the initial transfers completes it replaces the
previously cached object as the one being hit on.

So timing is critical, if Squid happens to delay any of the parallel
requests just long enough in its TCP accept() queue, auth or ACL
processing they could become HITs on an already finished object.

Amos



From squid3 at treenet.co.nz  Fri May 13 14:01:12 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 May 2016 02:01:12 +1200
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <1463143112.1242.26.camel@comnet.uz>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
 <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
 <2b955257-003f-7b4a-b9d1-7d9aea6bfd86@cinbesa.com.br>
 <bc769369-02f1-42b3-efb9-73c367c57de9@treenet.co.nz>
 <1463143112.1242.26.camel@comnet.uz>
Message-ID: <1d100058-b38b-8fca-cb73-49911b80cc93@treenet.co.nz>

On 14/05/2016 12:38 a.m., Garri Djavadyan wrote:
> On Fri, 2016-05-13 at 08:36 +1200, Amos Jeffries wrote:
>> Have you given collapsed_forwarding a try? Its supposed to prevent
>> all
>> the duplicate requests making all those extra upstream connections
>> unti
>> at least the first one has finished getting the object.
> 
> Amos, I believe that the above quote describes default Squid's action,
> which does not require collapsed_forwarding. The details of my
> experiments can be found here http://bugs.squid-cache.org/show_bug.cgi?
> id=4511#c0. Thanks.

What you are describing i that report is more along the lines of what
can happen with collapsed_forwarding, shared cache by two workers, or
such features linking the two requests which are supposed to be
differently delay pooled.


Heiler's problem is almost the opposite - the transactions *not* being
linked, so they use upstream bandwidth over N connections for N times
the bandwidth usage despite any per-message controls. Not just one
connection using more data than expected.

Amos


From squid3 at treenet.co.nz  Fri May 13 14:31:27 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 14 May 2016 02:31:27 +1200
Subject: [squid-users] authenticate_ip_ttl does not work
In-Reply-To: <20160513.212636.1000278277145491810.asakura@ioc.dnp.co.jp>
References: <20160513.212636.1000278277145491810.asakura@ioc.dnp.co.jp>
Message-ID: <f577d0b7-d115-6271-c69f-25d03d18042f@treenet.co.nz>

On 14/05/2016 12:26 a.m., asakura at ioc.dnp.co.jp wrote:
> Hello,
> 
> Thank you always for your kind support.
> 
> I testing squid-3.5.19 "max_user_ip/authenticate_ip_ttl" feature.
> but, access control not work well.
> (Value of authenticate_ip_ttl is not enable)
> 
> I investigating, and tried to change as follows.
> 
> src/auth/User.cc
> ----
> # diff User.cc.org User.cc
> 287c287
> <             ipdata->ip_expiretime = squid_curtime;
> ---
>>             ipdata->ip_expiretime = squid_curtime + ::Config.authenticateIpTTL;
> ----
> 
> Is this would be correct change?

No. That particular data cache is one in Squid that works on a very
weird staleness orientation rather than freshness.

Caches that work on freshness behave like one would expect. Things start
out fresh and grow towards some TTL 0 point where the flip to being
stale and can be removed or replaced.

But these weird staleness oriented things start out at some origin point
in time (squid_curtime) and just continue to get more and more stale.
Operations that need to be done on them can use multiple and different
TTL offsets, which change over time (for example on reconfigure) without
affecting the cached objects. It is up to the logic doing that operation
to check the staleness against the right TTL.

You can see this in Auth::User::cacheCleanup() which applies
authenticate_ip_ttl to see what can be erased. Compared to the
Auth::User::absorb() which compares two lists of objects against each
other and drops from one list anything that is not brand new (current
second).

I suspect bugs you are seeing are in that absorb operation since it is
timing-critical and happens with an async delay in the middle of the
list being created and method happening.


If you want to help out with that whole mess there, please discuss
intended changes on squid-dev mailing list where the other dev are sure
to see your proposals.


Amos



From garryd at comnet.uz  Fri May 13 15:01:52 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Fri, 13 May 2016 20:01:52 +0500
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <6af1d850-03d4-33bd-25d8-bf9ca202afd9@treenet.co.nz>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
 <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated>
 <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
 <2b955257-003f-7b4a-b9d1-7d9aea6bfd86@cinbesa.com.br>
 <bc769369-02f1-42b3-efb9-73c367c57de9@treenet.co.nz>
 <1463143112.1242.26.camel@comnet.uz>
 <6af1d850-03d4-33bd-25d8-bf9ca202afd9@treenet.co.nz>
Message-ID: <1463151712.1242.39.camel@comnet.uz>

On Sat, 2016-05-14 at 01:52 +1200, Amos Jeffries wrote:
> The default action should be to fetch each range request separately
> and
> in parallel. Not caching the results.
> 
> When admin has set only the range offset & quick-abort to force full
> object retrieval the behaviour Heiler mentions happens - lots of
> upstream bandwidth used for N copies.
> ?The first one to complete starts to be used as a HIT for future
> reuqests. But as each of the initial transfers completes it replaces
> the
> previously cached object as the one being hit on.
> 
> So timing is critical, if Squid happens to delay any of the parallel
> requests just long enough in its TCP accept() queue, auth or ACL
> processing they could become HITs on an already finished object.
> 
> Amos

Yes, you was right! Timing is very critical. I've simulated two
concurrent transfers (without 'collapsed_forwarding on' and with
'range_offset_limit none') using this code:

---
#!/bin/bash

export http_proxy="127.0.0.1:3128"
curl --range $((1024 * 1024 * 1))-$((1024 * 1024 * 2)) http://mirror.co
mnet.uz/centos/7/os/x86_64/images/efiboot.img > /dev/null &
curl --range $((1024 * 1024 * 3))-$((1024 * 1024 * 4)) http://mirror.co
mnet.uz/centos/7/os/x86_64/images/efiboot.img > /dev/null
---

And got two MISS':

1463150025.340????987 127.0.0.1 TCP_MISS/206 1048943 GET http://mirror.
comnet.uz/centos/7/os/x86_64/images/efiboot.img -
HIER_DIRECT/91.196.76.102 application/octet-stream
1463150026.315???1963 127.0.0.1 TCP_MISS/206 1048943 GET http://mirror.
comnet.uz/centos/7/os/x86_64/images/efiboot.img -
HIER_DIRECT/91.196.76.102 application/octet-stream

Then, I purged the object repeated with 'collapsed_forwarding on' and
got MISS and HIT:

1463150169.010????370 127.0.0.1 TCP_MISS/206 1048943 GET http://mirror.
comnet.uz/centos/7/os/x86_64/images/efiboot.img -
HIER_DIRECT/91.196.76.102 application/octet-stream
1463150169.476????836 127.0.0.1 TCP_HIT/206 1048950 GET http://mirror.c
omnet.uz/centos/7/os/x86_64/images/efiboot.img - HIER_NONE/-
application/octet-stream


Amos, thank you very much for the detailed explanation.
collapsed_forwarding is really useful option for this situation.


From heiler.bemerguy at cinbesa.com.br  Fri May 13 15:25:32 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Fri, 13 May 2016 12:25:32 -0300
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <1463095306599-4677543.post@n4.nabble.com>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
 <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
 <2b955257-003f-7b4a-b9d1-7d9aea6bfd86@cinbesa.com.br>
 <bc769369-02f1-42b3-efb9-73c367c57de9@treenet.co.nz>
 <5734F3D6.2020205@measurement-factory.com>
 <ffc2f0bf-5268-42cc-e42f-9f9ffe8b110a@cinbesa.com.br>
 <1463095306599-4677543.post@n4.nabble.com>
Message-ID: <1a73ed91-2614-c62d-9bdd-be6da9c58ef2@cinbesa.com.br>


Ok but after enabling *collapsed_forwarding*, EVEN when disabling it 
again, the cache.log are full of *clientProcessHit: Vary object loop!*

What happened ? My cache was modified ? collapsed is off now and even 
after restarting squid I'm still getting a flood of these messages which 
*were not there before*.

About the acl with "range_list_path", I've already done that to test.. 
it really alleviates the problem but it's still there.


Best Regards,

-- 
Heiler Bemerguy - (91) 98151-4894
Assessor T?cnico - CINBESA (91) 3184-1751


Em 12/05/2016 20:21, joe escreveu:
> do not worry about vary  its not a bug its the way its setup the vary
> handling yet it need plenty of work this is my guess after i look at the
> code
>
> for a range_offset_limit use this test im using it long time and its
> wonderful
>
> collapsed_forwarding on
> acl range_list_path urlpath_regex \.(mar|msp|esd|pkg\?)
> range_offset_limit -1 windows_list_path
>
> range_offset_limit 16 KB all !range_list_path    #<---if you need this
> quick_abort_min 0 KB
> quick_abort_max 0 KB
> quick_abort_pct 100
>
> im caching the above extension perfectly you can add to it
>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Getting-the-full-file-content-on-a-range-request-but-not-on-EVERY-get-tp4677503p4677543.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160513/8d75b730/attachment.htm>

From david at articatech.com  Fri May 13 15:26:40 2016
From: david at articatech.com (David Touzeau)
Date: Fri, 13 May 2016 17:26:40 +0200
Subject: [squid-users] ACL is used in context without an HTTP response.
	Assuming mismatch
In-Reply-To: <df968238-a9a3-c977-e4d8-1b96fd45f22e@treenet.co.nz>
References: <005001d1ac9a$3fe7c530$bfb74f90$@articatech.com>
 <5735062D.2090902@measurement-factory.com>
 <001001d1ace6$034b7f30$09e27d90$@articatech.com>
 <df968238-a9a3-c977-e4d8-1b96fd45f22e@treenet.co.nz>
Message-ID: <00e001d1ad2b$dacecd00$906c6700$@articatech.com>

You are right Amos....

Without loosing the original canary need :=) :

 [ for better I/O performance ] do not write  in access.log some squid http
status result codes.

Example : not write in access.log 407, 403, 301, 302 squid status code.

By reading docs and several discuss the only way to have this behavior is to
use this kind of ACL.

If you have an another way , i'm hearding you :)

Best regards.

-----Message d'origine-----
De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la 
part de Amos Jeffries
Envoy? : vendredi 13 mai 2016 13:27
? : squid-users at lists.squid-cache.org
Objet : Re: [squid-users] ACL is used in context without an HTTP response. 
Assuming mismatch

On 13/05/2016 7:06 p.m., David Touzeau wrote:
> Thanks Alex
>
> Any ACLs  tips to avoid these warning ? or just assume it's normal in this 
> situation... ?
>

Yes and no. It was added to be a type of canary to unexpected behaviours in 
the config. So in that regard it has done its job well by making you look 
and ask about why its happening.

What Alex describes there as potential causes could be a sign of clients 
having bad experiences with the proxy. Or just browser "Happy Eyeballs"
doing its annoying thing. It'll have to be a judgement call for you whether 
to do much more investigation or not.

The answer is also very specific to that one named ACL and how it was used. 
So other similar looking warnings could have very different impacts and 
severity.


The only way to completely silence the warning right now is to not use that 
ACL for that access control. If its annoying we are open to adding a 
throttle to it.

HTH
Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Fri May 13 18:51:13 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 14 May 2016 00:51:13 +0600
Subject: [squid-users] Getting the full file content on a range request,
 but not on EVERY get ...
In-Reply-To: <1a73ed91-2614-c62d-9bdd-be6da9c58ef2@cinbesa.com.br>
References: <2ae7cd43-a08d-ceb0-68bb-6b0deb41eb3f@cinbesa.com.br>
 <2575073.4c7f0552JP@xrated>
 <61bf3ff3-c8b2-647f-9b5e-3112b2f43d6c@cinbesa.com.br>
 <2050051.gqqp5FEbAA@xrated> <bb977153-9b63-abcd-5e9d-452c10d6f539@gmail.com>
 <2b955257-003f-7b4a-b9d1-7d9aea6bfd86@cinbesa.com.br>
 <bc769369-02f1-42b3-efb9-73c367c57de9@treenet.co.nz>
 <5734F3D6.2020205@measurement-factory.com>
 <ffc2f0bf-5268-42cc-e42f-9f9ffe8b110a@cinbesa.com.br>
 <1463095306599-4677543.post@n4.nabble.com>
 <1a73ed91-2614-c62d-9bdd-be6da9c58ef2@cinbesa.com.br>
Message-ID: <d990e426-b9ab-4f55-8bb3-905745678e82@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


13.05.16 21:25, Heiler Bemerguy ?????:
>
>
> Ok but after enabling *collapsed_forwarding*, EVEN when disabling it
again, the cache.log are full of *clientProcessHit: Vary object loop!*
>
Heh, I confirm. I see this when change Squid's binaries to 4.x when
enabled collapsed_forwarding
>
> What happened ? My cache was modified ? collapsed is off now and even
after restarting squid I'm still getting a flood of these messages which
*were not there before*.
>
I suggest some cache contents changed. Also I suggest need to wipe out
cache when change this setting. Or, another way, wait when content be
replaced during time with native replacement policy...
>
> About the acl with "range_list_path", I've already done that to test..
it really alleviates the problem but it's still there.
>
>
> Best Regards,
>
> --
> Heiler Bemerguy - (91) 98151-4894
> Assessor T?cnico - CINBESA (91) 3184-1751
>
>
> Em 12/05/2016 20:21, joe escreveu:
>> do not worry about vary  its not a bug its the way its setup the vary
>> handling yet it need plenty of work this is my guess after i look at the
>> code
>>
>> for a range_offset_limit use this test im using it long time and its
>> wonderful
>>
>> collapsed_forwarding on
>> acl range_list_path urlpath_regex \.(mar|msp|esd|pkg\?)
>> range_offset_limit -1 windows_list_path
>>
>> range_offset_limit 16 KB all !range_list_path    #<---if you need this
>> quick_abort_min 0 KB
>> quick_abort_max 0 KB
>> quick_abort_pct 100
>>
>> im caching the above extension perfectly you can add to it
>>
>>
>>
>>
>> --
>> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Getting-the-full-file-content-on-a-range-request-but-not-on-EVERY-get-tp4677503p4677543.html
>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXNiIhAAoJENNXIZxhPexGus8IAKC2/iEobccG4Tkhs2zJb7Pd
1qFSDsnZRHHuz69cA29OrYKaH7qkvdtJo1k9becYbqdrcNLPprJgkUT/Qx/XIy0q
NezsoGxMFDwJqbvS4tZLCI2u8/G8n2UvyjYsvUbzq7r6xViykOnOmKZLOh2z5m4H
hwhBJsUJKyQxgHh3qk/ImHhmbM62vWOMID5cM2ibmjNLGKyWkGMA9VzIIVZl9TPw
4f6FuVy+CzA4NP7FuV85/Pqc91u2GGz6ZHojT9hL82hCR8iwhqdbwHA/w6gvP17i
uZE5bq2Pl4IBw0fPbM/QneLHBMfIVBH5+apZJLM5DGKp2SAXc+g0rHRKZPT24cg=
=rHna
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160514/fd37dd66/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160514/fd37dd66/attachment.key>

From tin at new-life.org.au  Sat May 14 09:36:18 2016
From: tin at new-life.org.au (Tim Bates)
Date: Sat, 14 May 2016 19:36:18 +1000
Subject: [squid-users] Are there any distros with SSL Bump compiled by
	default?
Message-ID: <5736F192.2090902@new-life.org.au>

Are there any Linux distros with pre-compiled versions of Squid with SSL 
Bump support compiled in?

Alternatively, does anyone reputable do a 3rd party repo for 
Debian/Ubuntu that includes SSL Bump?

TB


From garryd at comnet.uz  Sat May 14 10:59:00 2016
From: garryd at comnet.uz (garryd at comnet.uz)
Date: Sat, 14 May 2016 15:59:00 +0500
Subject: [squid-users]
 =?utf-8?q?Are_there_any_distros_with_SSL_Bump_compi?=
 =?utf-8?q?led_by_default=3F?=
In-Reply-To: <5736F192.2090902@new-life.org.au>
References: <5736F192.2090902@new-life.org.au>
Message-ID: <3bd768abdda73cc1ae883a6c2ff4ea83@comnet.uz>

On 2016-05-14 14:36, Tim Bates wrote:
> Are there any Linux distros with pre-compiled versions of Squid with
> SSL Bump support compiled in?
> 
> Alternatively, does anyone reputable do a 3rd party repo for
> Debian/Ubuntu that includes SSL Bump?

Squid's SSL Bump support improves very fast, so it is recommended to 
always use newest version. Here, you can find packages for different 
distros http://wiki.squid-cache.org/SquidFaq/BinaryPackages. Most 
advanced SSL bump feature Peek and Splice requires configure options 
'--with-openssl' and '--enable-ssl-crtd'. For example, Eliezer's newest 
package (squid 3.5.19) for CentOS compiled with these options.

HTH
Garri


From rafael.akchurin at diladele.com  Sat May 14 11:41:57 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Sat, 14 May 2016 11:41:57 +0000
Subject: [squid-users] Are there any distros with SSL Bump compiled
	by	default?
In-Reply-To: <5736F192.2090902@new-life.org.au>
References: <5736F192.2090902@new-life.org.au>
Message-ID: <VI1PR04MB135939AE13CBC5CD45D096318F750@VI1PR04MB1359.eurprd04.prod.outlook.com>

Hello Tim,

By default Squid that is part of well known distributions is not compiled with SSL filtering support. This is due to some license restrictions as may be better explained by Amos. Default versions are also very old (except for Debian testing which is at the latest but still without SSL filtering capabilities compiled in).

For CentOS 6 and 7 elizier's package has everything required. 
For Debian 8 you might need to recompile it yourself as described in http://docs.diladele.com/administrator_guide_4_5/install/debian8/squid.html

For Ubuntu 14 LTS we humbly propose to use our repository at ubuntu.diladele.com. The recompilation is quite easy btw, the following github project shows how we do it https://github.com/diladele/squid-ubuntu. 

This tutorial may also be of interest http://docs.diladele.com/tutorials/build_squid_ubuntu14/index.html.

Best regards,
Rafael Akchurin
Diladele B.V.

--
Please take a look at Web Safety - our ICAP based web filter server for Squid proxy at http://www.diladele.com.







-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Tim Bates
Sent: Saturday, May 14, 2016 11:36 AM
To: squid-users at squid-cache.org
Subject: [squid-users] Are there any distros with SSL Bump compiled by default?

Are there any Linux distros with pre-compiled versions of Squid with SSL Bump support compiled in?

Alternatively, does anyone reputable do a 3rd party repo for Debian/Ubuntu that includes SSL Bump?

TB
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From tin at new-life.org.au  Sun May 15 03:11:15 2016
From: tin at new-life.org.au (Tim Bates)
Date: Sun, 15 May 2016 13:11:15 +1000
Subject: [squid-users] Are there any distros with SSL Bump compiled by
 default?
In-Reply-To: <VI1PR04MB135939AE13CBC5CD45D096318F750@VI1PR04MB1359.eurprd04.prod.outlook.com>
References: <5736F192.2090902@new-life.org.au>
 <VI1PR04MB135939AE13CBC5CD45D096318F750@VI1PR04MB1359.eurprd04.prod.outlook.com>
Message-ID: <5737E8D3.6030702@new-life.org.au>

On 14/05/2016 9:41 PM, Rafael Akchurin wrote:
>The recompilation is quite easy btw

Oh, yeah... I know it's easy. I've already done it once on Debian. My 
concern is that I won't be able to find time to keep it up to date. 
Asking a package manager to download available updates takes about 10 
minutes a week (across a dozen or so virtual servers). Downloading the 
source and compiling took ages.

I will probably take up the idea of Ubuntu 14 and use your packages, 
Rafael... Seems easiest, and I can include a Ubuntu server in my 
ClusterSSH group for "apt-get update"  :)

TB


From eliezer at ngtech.co.il  Mon May 16 00:44:29 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 16 May 2016 03:44:29 +0300
Subject: [squid-users] New StoreID helper: squid_dedup
In-Reply-To: <7702897.VvIrWcf3ht@xrated>
References: <7702897.VvIrWcf3ht@xrated>
Message-ID: <74314a7c-622b-88e2-a908-cb0513bc0b7b@ngtech.co.il>

Thanks for sharing!

I didn't had enough time to understand the tool structure since I am not 
a python expert but,
This is the first squid helper I have seen which is based on python and 
implements concurrency.

Thanks!!
Eliezer Croitoru

On 10/05/2016 00:56, Hans-Peter Jansen wrote:
> Hi,
>
> I'm pleased to announce the availability of squid_dedup, a helper for
> deduplicating CDN accesses, implementing the squid 3 StoreID protocol.
>
> It is a multi-threaded tool, written in python3, with no further dependencies,
> hosted at: https://github.com/frispete/squid_dedup
> available at: https://pypi.python.org/pypi/squid-dedup
>
> For openSUSE users, a ready made rpm package is available here:
> https://build.opensuse.org/package/show/home:frispete:python3/squid_dedup
>
> Any feedback is greatly appreciated.
>
> Cheers,
> Pete
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Mon May 16 00:53:45 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 16 May 2016 03:53:45 +0300
Subject: [squid-users] Would it be possible to run a http to https
 gateway using squid?
In-Reply-To: <8ed68e4f-c06d-76a5-8316-2a36fcce7add@treenet.co.nz>
References: <020001d1ab02$6b7e0400$427a0c00$@ngtech.co.il>
 <8ed68e4f-c06d-76a5-8316-2a36fcce7add@treenet.co.nz>
Message-ID: <8b74b8f5-0ccb-1fb7-c800-fab5621e8266@ngtech.co.il>

Hey Amos,

You are right that it seems like there is no point since you already 
decrypt the connection.
But in the real world the price of maintaining an encrypted session for 
many users for a long period is not the same as maintaining them for 
short burst.

Since all YouTube traffic is done on HTTPS it would be pretty simple 
with these days tools to use some kind of a "https to http bridge" 
software that would
fetch the pages for the clients(most of the pages are tiny) and it will 
help the clients to be able to handle less secured traffic.

I know that with these days hardware it's almost not needed but inside a 
trusted network there is no point for using end to end HTTPS.(to my 
understanding)
Some will might not believe that there are trusted networks in the wild 
but I know that these do exist and in many of these such a GW is required.

Eliezer

On 11/05/2016 08:40, Amos Jeffries wrote:
> On 11/05/2016 9:25 a.m., Eliezer Croitoru wrote:
>> I was wondering to myself, If I can generate certificates and bump the
>> connection, I can use a 302\308 to redirect all traffic from https to a
>> http(intercepatble) connection.
>>
>> Then on the http interceptor rewrite the request into https.
> What would be the point? You already had to decrypt to do the bump and
> redirect.
>
>> I have a working setup which uses a redirection "attack" to authenticate
>> users over http+https.
>>
>> Now the issue is that if all browsers will deny a redirection from https to
>> http(a downgrading attack) then the http world would look a bit weird.
>>
> Not that weird. It is called HTTP Strict Transport Security (HSTS).
>
>
>> And as an addition I have seen that Microsoft use and "FTP" like transfer
>> protocol in their software.
>>
>> They have a "secured" control channel which has certificates pinning or
>> something else as a safe guard,
>> and in more then one case they use another channel to fetch the request over
>> plain HTTP( when a proxy is defined).
>>
> You will note that this is a very cache friendly way to do crypto. The
> bulky part of the content is cacheable by anyone who needs to reduce
> bandwith, but remains securely verifiable and integrity checked using
> the off-band details.
>
> However, it is not what you are talking about for your tool. The above
> method by MS requires intentional design in the web service with
> integrity checking actually performed by the endpoints.
>
>   Under downgrade attack conditions the endpoints would not know that the
> extra work was needed so one cannot assume that it is getting done. One
> of the reasons browsers are so into TLS is that the transport layer does
> all the verification and leaves them able to skip perceived slow
> security checks at higher levels.
>
>> Would it be reasonable to write and publish such a tool? Or is it a security
>> risk to publish such a tool to the public?
>>
> Up to you. AIUI is illegal in most of the world to make use of it. Like
> most hacking tools if used other than for permitted penetration testing
> and research purposes.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From admin at tisiz72.ru  Mon May 16 05:36:02 2016
From: admin at tisiz72.ru (admin)
Date: Mon, 16 May 2016 10:36:02 +0500
Subject: [squid-users] Are there any distros with SSL Bump compiled by
 default?
In-Reply-To: <5736F192.2090902@new-life.org.au>
References: <5736F192.2090902@new-life.org.au>
Message-ID: <5601a5675b7f26d5cd86524a0d3d9883@tisiz72.ru>

I make deb's compiled squid in Debian 8: 

3.5.8 

3.5.17 

4.0.10

Tim Bates ????? 2016-05-14 14:36:

> Are there any Linux distros with pre-compiled versions of Squid with SSL Bump support compiled in?
> 
> Alternatively, does anyone reputable do a 3rd party repo for Debian/Ubuntu that includes SSL Bump?
> 
> TB
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160516/b3fedc99/attachment.htm>

From admin at tisiz72.ru  Mon May 16 05:48:24 2016
From: admin at tisiz72.ru (admin)
Date: Mon, 16 May 2016 10:48:24 +0500
Subject: [squid-users] Squid 3.5.17 SSL-Bump Step1
Message-ID: <89b6865755fa57c09cefb235afc00b52@tisiz72.ru>

Hi!

Squid 3.5.17 with SSL, intercept.

I use SSL-Bump only step1 that get SNI and terminate HTTPS sites by 
domain name. The certificate's is not replaced !

acl blocked_https ssl::server_name  "/etc/squid/urls/block-url"
https_port 3129 intercept ssl-bump options=ALL:NO_SSLv3:NO_SSLv2 
connection-auth=off cert=/etc/squid/squidCA.pem
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump terminate blocked_https

It works.

But if I use

acl users_no_inet src "/etc/squid/ip-groups/no-inet"
http_access deny users_no_inet

I see NET::ERR_CERT_AUTHORITY_INVALID in browser. I import my squid 
cert, but I see NET::ERR_CERT_COMMON_NAME_INVALID

Why in this case, the squid trying to replace the certificate?



From uhlar at fantomas.sk  Mon May 16 06:55:34 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Mon, 16 May 2016 08:55:34 +0200
Subject: [squid-users] Are there any distros with SSL Bump compiled by
 default?
In-Reply-To: <5601a5675b7f26d5cd86524a0d3d9883@tisiz72.ru>
References: <5736F192.2090902@new-life.org.au>
 <5601a5675b7f26d5cd86524a0d3d9883@tisiz72.ru>
Message-ID: <20160516065534.GA15430@fantomas.sk>

On 16.05.16 10:36, admin wrote:
>I make deb's compiled squid in Debian 8:
>
>3.5.8
>
>3.5.17
>
>4.0.10

OpenSSL?

>Tim Bates ????? 2016-05-14 14:36:
>
>> Are there any Linux distros with pre-compiled versions of Squid with SSL Bump support compiled in?
>>
>> Alternatively, does anyone reputable do a 3rd party repo for Debian/Ubuntu that includes SSL Bump?

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
WinError #99999: Out of error messages.


From admin at tisiz72.ru  Mon May 16 07:05:45 2016
From: admin at tisiz72.ru (admin)
Date: Mon, 16 May 2016 12:05:45 +0500
Subject: [squid-users] Are there any distros with SSL Bump compiled by
 default?
In-Reply-To: <20160516065534.GA15430@fantomas.sk>
References: <5736F192.2090902@new-life.org.au>
 <5601a5675b7f26d5cd86524a0d3d9883@tisiz72.ru>
 <20160516065534.GA15430@fantomas.sk>
Message-ID: <221cdd15150709b5a463c02ff2fb516d@tisiz72.ru>

Yes 

Can send to email if needed 

Matus UHLAR - fantomas ????? 2016-05-16 11:55:

> On 16.05.16 10:36, admin wrote: 
> 
>> I make deb's compiled squid in Debian 8:
>> 
>> 3.5.8
>> 
>> 3.5.17
>> 
>> 4.0.10
> 
> OpenSSL?
> 
> Tim Bates ????? 2016-05-14 14:36:
> 
> Are there any Linux distros with pre-compiled versions of Squid with SSL Bump support compiled in?
> 
> Alternatively, does anyone reputable do a 3rd party repo for Debian/Ubuntu that includes SSL Bump?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160516/5e460b16/attachment.htm>

From uhlar at fantomas.sk  Mon May 16 07:20:10 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Mon, 16 May 2016 09:20:10 +0200
Subject: [squid-users] Are there any distros with SSL Bump compiled by
 default?
In-Reply-To: <221cdd15150709b5a463c02ff2fb516d@tisiz72.ru>
References: <5736F192.2090902@new-life.org.au>
 <5601a5675b7f26d5cd86524a0d3d9883@tisiz72.ru>
 <20160516065534.GA15430@fantomas.sk>
 <221cdd15150709b5a463c02ff2fb516d@tisiz72.ru>
Message-ID: <20160516072010.GC15430@fantomas.sk>

>> Tim Bates ????? 2016-05-14 14:36:
>>
>> Are there any Linux distros with pre-compiled versions of Squid with SSL
>> Bump support compiled in?
>>
>> Alternatively, does anyone reputable do a 3rd party repo for
>> Debian/Ubuntu that includes SSL Bump?

>> On 16.05.16 10:36, admin wrote:
>>> I make deb's compiled squid in Debian 8:
>>> 3.5.8
>>> 3.5.17
>>> 4.0.10

>Matus UHLAR - fantomas ????? 2016-05-16 11:55:
>> OpenSSL?

On 16.05.16 12:05, admin wrote:
>Yes

>Can send to email if needed

I just wanted to point out that distrib uting GPL'ed software (squid)
depending on (linked with) non-GPL/LGPL libraries is AFAIK GPL violation and
therefore illegal copying...
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
"One World. One Web. One Program." - Microsoft promotional advertisement
"Ein Volk, ein Reich, ein Fuhrer!" - Adolf Hitler


From squid3 at treenet.co.nz  Mon May 16 08:21:30 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 16 May 2016 20:21:30 +1200
Subject: [squid-users] Would it be possible to run a http to https
 gateway using squid?
In-Reply-To: <8b74b8f5-0ccb-1fb7-c800-fab5621e8266@ngtech.co.il>
References: <020001d1ab02$6b7e0400$427a0c00$@ngtech.co.il>
 <8ed68e4f-c06d-76a5-8316-2a36fcce7add@treenet.co.nz>
 <8b74b8f5-0ccb-1fb7-c800-fab5621e8266@ngtech.co.il>
Message-ID: <ac1d65fb-6635-81ad-b9e0-8c97212a6d30@treenet.co.nz>

On 16/05/2016 12:53 p.m., Eliezer Croitoru wrote:
> Hey Amos,
> 
> You are right that it seems like there is no point since you already
> decrypt the connection.
> But in the real world the price of maintaining an encrypted session for
> many users for a long period is not the same as maintaining them for
> short burst.

Yes, the short connections have higher cost on almost all metrics.

The maintenance cost of either TCP or TLS connectison is a fixed
per-packet cost in both memory holding connection state and CPU cycles
handling the packet. The number of handshakes and open/close cycles adds
a burst of extra cost.


> 
> Since all YouTube traffic is done on HTTPS it would be pretty simple
> with these days tools to use some kind of a "https to http bridge"
> software that would
> fetch the pages for the clients(most of the pages are tiny) and it will
> help the clients to be able to handle less secured traffic.
> 

YT is secured as an attempt to protect privacy. You are ignoring the
most annoying part of the privacy equation.

For any piece of privacy critical information A, there is another piece
of metadata information B = uses(A) which can be correlated and thus
needs to be treated as equivalent in privacy to A itself.
 And of course that makes the start of a slippery slope in the
definition of privacy: B is private so it has its own C = uses(B), etc, etc.

So for example; given a YouTube video of some baby saying their first word:
 * That video as private,
 * meaning where its stored is private,
 * meaning who accessed that URL is private,
 * meaning pages containing the URL is private,
 * meaning who accesses YT pages is private,
 * meaning who tries to contact YT is private,
 * ... and is gets more paranoid from there.

There is a similar chain from other details about the video; the timing
of the video creation, who posted it, what type it is, how long it is,
file size, etc. It is all metadata and enough of that can be correlated.

In a world like ours where mass surveillance exists if those minor
details are not all 100% secured then privacy is lost.

<https://www.youtube.com/watch?v=7G1LjQSYM5Q>


> I know that with these days hardware it's almost not needed but inside a
> trusted network there is no point for using end to end HTTPS.(to my
> understanding)
> Some will might not believe that there are trusted networks in the wild
> but I know that these do exist and in many of these such a GW is required.

The Internet is not qualifying as a trusted network.

If you are talking about inbound connections from Internet / WAN into a
trusted network. That is the definition of a CDN / reverse-proxy and
"https_port 443 accel" has been doing that securely and very well since
Squid-2.6.


Amos



From squid3 at treenet.co.nz  Mon May 16 08:34:29 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 16 May 2016 20:34:29 +1200
Subject: [squid-users] Squid 3.5.17 SSL-Bump Step1
In-Reply-To: <89b6865755fa57c09cefb235afc00b52@tisiz72.ru>
References: <89b6865755fa57c09cefb235afc00b52@tisiz72.ru>
Message-ID: <b2edf9ca-40a3-c529-6694-98231996d722@treenet.co.nz>

On 16/05/2016 5:48 p.m., admin wrote:
> Hi!
> 
> Squid 3.5.17 with SSL, intercept.

Please upgrade to 3.5.19.

> 
> I use SSL-Bump only step1 that get SNI and terminate HTTPS sites by
> domain name. The certificate's is not replaced !

The certificate is never replaced. Though if you dont know how TLS works
and look at it only from the client perspective it can appear to be so.
The reality is you either have one TLS connection or two with different
certificates on each.

> 
> acl blocked_https ssl::server_name  "/etc/squid/urls/block-url"
> https_port 3129 intercept ssl-bump options=ALL:NO_SSLv3:NO_SSLv2
> connection-auth=off cert=/etc/squid/squidCA.pem
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump terminate blocked_https
> 
> It works.

Obviously not. There is no instruction what to do other than terminate.
Squid is left to other circumstances to decide what is needed...

> 
> But if I use
> 
> acl users_no_inet src "/etc/squid/ip-groups/no-inet"
> http_access deny users_no_inet

... you force bumping to happen in order to deliver the HTTP error message.

Try adding this rule above the peek (and the ACL line too):
  ssl_bump terminate users_no_inet


> 
> I see NET::ERR_CERT_AUTHORITY_INVALID in browser. I import my squid
> cert, but I see NET::ERR_CERT_COMMON_NAME_INVALID
> 
> Why in this case, the squid trying to replace the certificate?

There is no server connection or certificate in existence. So nothing
exists to be replaced.

What you are seeing is Squid using its own certificate to get a TLS
connection it can deliver the HTTP error message through.


Amos



From squid3 at treenet.co.nz  Mon May 16 09:25:23 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 16 May 2016 21:25:23 +1200
Subject: [squid-users] Are there any distros with SSL Bump compiled by
 default?
In-Reply-To: <20160516072010.GC15430@fantomas.sk>
References: <5736F192.2090902@new-life.org.au>
 <5601a5675b7f26d5cd86524a0d3d9883@tisiz72.ru>
 <20160516065534.GA15430@fantomas.sk>
 <221cdd15150709b5a463c02ff2fb516d@tisiz72.ru>
 <20160516072010.GC15430@fantomas.sk>
Message-ID: <7fcaac5c-52d3-1378-f56f-e083950a346c@treenet.co.nz>

On 16/05/2016 7:20 p.m., Matus UHLAR - fantomas wrote:
>>> Tim Bates ????? 2016-05-14 14:36:
>>>
>>> Are there any Linux distros with pre-compiled versions of Squid with SSL
>>> Bump support compiled in?
>>>
>>> Alternatively, does anyone reputable do a 3rd party repo for
>>> Debian/Ubuntu that includes SSL Bump?
> 
>>> On 16.05.16 10:36, admin wrote:
>>>> I make deb's compiled squid in Debian 8:
>>>> 3.5.8
>>>> 3.5.17

Please update those to 3.5.19. A dozen CVE's went out these past few
months. :-(

>>>> 4.0.10
> 
>> Matus UHLAR - fantomas ????? 2016-05-16 11:55:
>>> OpenSSL?
> 
> On 16.05.16 12:05, admin wrote:
>> Yes
> 
>> Can send to email if needed
> 
> I just wanted to point out that distrib uting GPL'ed software (squid)
> depending on (linked with) non-GPL/LGPL libraries is AFAIK GPL violation
> and
> therefore illegal copying...


What is being attempted above is not a GPL violation AFAIK. So long as
the Squid ./configure && make system is used to construct the binary and
Squid source is not altered in any way by the builder.

* GPL permits linking against OpenSSL because both softwares sources are
available publicly.

* It is GPL violation to distribute the OpenSSL and Squid sources
together as parts of someting else. In source form.

Thus distributors like Diladele can provide binary-only formats with no
source changes to Squid or OpenSSL.
  Each component of the offering is publicly available (GPL compliant)
and the pieces of OpenSSL, Squid and the packaging source code are
distributed via separate channels (OpenSSL compliant).

Debian and Ubuntu distribute sources of all binaries as part of their OS
repository. The very act of adding package install scripts causes the
issue here. The repository would contain all of Squid + OpenSSL +
packaging scripts source code.


But, but, but....

* It is OpenSSL violation to distribute any binary that does not
advertise OpenSSL usage. In the binary outputs, even those not using
OpenSSL logic (Ouch!). Unless the OS provides the library as part of its
core system.

Debian and Ubuntu use GnuTLS as the system preferrd library. OpenSSL
license not being GPL compliant also makes it not DFSG compliant and so
not part of the core OS repository. It and anything using it are in the
non-free optional extras repository instead.
 There are some suggestions to build and put a version of Squid in
there. But that still collides with the previous GPL issue about sources
being together in the repo.


Adding advertising clauses in the way required by OpenSSL would make
Squid binaries no longer be GPL compliant unless we got explicit written
permission from everyone who contributed patches. A lot of contributors
have long-dead emails, requested anonimity or some in fact are now
physically deceased. So we are stuck at our end as well even with that.

I am working on GnuTLS support as a side project, and the OpenSSL people
are apparently working on fixing their license to be GPL compliant. It
is a lot of work and going quite slow on both fronts. You can see some
of my work reflected in the squid.conf changes of Squid-4, and the
latest Debian/Ubuntu squidclient packages :-)

Amos



From admin at tisiz72.ru  Mon May 16 10:09:16 2016
From: admin at tisiz72.ru (admin)
Date: Mon, 16 May 2016 15:09:16 +0500
Subject: [squid-users] Are there any distros with SSL Bump compiled by
 default?
In-Reply-To: <7fcaac5c-52d3-1378-f56f-e083950a346c@treenet.co.nz>
References: <5736F192.2090902@new-life.org.au>
 <5601a5675b7f26d5cd86524a0d3d9883@tisiz72.ru>
 <20160516065534.GA15430@fantomas.sk>
 <221cdd15150709b5a463c02ff2fb516d@tisiz72.ru>
 <20160516072010.GC15430@fantomas.sk>
 <7fcaac5c-52d3-1378-f56f-e083950a346c@treenet.co.nz>
Message-ID: <8a765de7e13cd5057f329a8546ff6567@tisiz72.ru>

https://itcrowd72.ru/cloud/index.php/s/W4Sv8ojnf5dVKvc

squid 3.5.19 with SSL. Compiled and build deb in Debian 8. Enjoy :)



Amos Jeffries ????? 2016-05-16 14:25:

> Please update those to 3.5.19. A dozen CVE's went out these past few
> months. :-(
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From eliezer at ngtech.co.il  Mon May 16 10:15:25 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 16 May 2016 13:15:25 +0300
Subject: [squid-users] Are there any distros with SSL Bump compiled
	by	default?
In-Reply-To: <5736F192.2090902@new-life.org.au>
References: <5736F192.2090902@new-life.org.au>
Message-ID: <032401d1af5b$dd573620$9805a260$@ngtech.co.il>

Hey Tim,

I have been working for quite some time on packages for couple Linux distributions and in them Ubuntu and Debian.
I was planning to publish them(Ubuntu + Debian) inside a tar.xz and to attach them a tiny "update\install" script.
This is since I was trying to use the deb packaging system for quite some time and to try and build using them but compared to RPMs I keep forgetting every time what I did last time.
So in the next couple weeks I will try to publish the next tar.xz
- Ubuntu 14.04 32+64 bit
- Ubuntu 16.04 32+64 bit
- Debian 8 32+64 bit
- Debian 7 32+64 bit

This is a part of my trial to somehow publish a binary version of squid per release.
I hope to have some time and to make it possible so also squid 4.X will also get the same attention.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Tim Bates
Sent: Saturday, May 14, 2016 12:36 PM
To: squid-users at squid-cache.org
Subject: [squid-users] Are there any distros with SSL Bump compiled by default?

Are there any Linux distros with pre-compiled versions of Squid with SSL Bump support compiled in?

Alternatively, does anyone reputable do a 3rd party repo for Debian/Ubuntu that includes SSL Bump?

TB
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From admin at tisiz72.ru  Mon May 16 10:47:55 2016
From: admin at tisiz72.ru (admin)
Date: Mon, 16 May 2016 15:47:55 +0500
Subject: [squid-users] Squid 3.5.17 SSL-Bump Step1
In-Reply-To: <b2edf9ca-40a3-c529-6694-98231996d722@treenet.co.nz>
References: <89b6865755fa57c09cefb235afc00b52@tisiz72.ru>
 <b2edf9ca-40a3-c529-6694-98231996d722@treenet.co.nz>
Message-ID: <5e22c5485af2e34b24ad801acf1c5614@tisiz72.ru>

Amos Jeffries ????? 2016-05-16 13:34:

> Please upgrade to 3.5.19.

Upgrade to 3.5.19

>> acl blocked_https ssl::server_name  "/etc/squid/urls/block-url"
>> https_port 3129 intercept ssl-bump options=ALL:NO_SSLv3:NO_SSLv2
>> connection-auth=off cert=/etc/squid/squidCA.pem
>> acl step1 at_step SslBump1
>> ssl_bump peek step1
>> ssl_bump terminate blocked_https
>> 
>> It works.
> 
> Obviously not. There is no instruction what to do other than terminate.
> Squid is left to other circumstances to decide what is needed...

it works! :) if you have the opportunity to check on the virtual machine

>> But if I use
>> 
>> acl users_no_inet src "/etc/squid/ip-groups/no-inet"
>> http_access deny users_no_inet
> 
> ... you force bumping to happen in order to deliver the HTTP error message.
> 
> Try adding this rule above the peek (and the ACL line too):
> ssl_bump terminate users_no_inet

trying, no success :(

I just do not understand the reason for such behavior. Why, if access is
allowed everything works, and if the ban on access to HTTP, you must
first see a message stating that my certificate has not been able to
match, and then later ERR_ACCESS_DENIED. Sorry for my English
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160516/695e32a5/attachment.htm>

From hpj at urpla.net  Mon May 16 12:35:03 2016
From: hpj at urpla.net (Hans-Peter Jansen)
Date: Mon, 16 May 2016 14:35:03 +0200
Subject: [squid-users] New StoreID helper: squid_dedup
In-Reply-To: <74314a7c-622b-88e2-a908-cb0513bc0b7b@ngtech.co.il>
References: <7702897.VvIrWcf3ht@xrated>
 <74314a7c-622b-88e2-a908-cb0513bc0b7b@ngtech.co.il>
Message-ID: <28146135.Sq5WfK6EsW@xrated>

Hi Eliezer,

Thanks for your feedback, much appreciated, /especially/ from you.

The most important part is in dedup.py. I've kept an eye on efficiency without 
sacrificing readability (much) and extendability:

	https://github.com/frispete/squid_dedup/blob/master/squid_dedup/dedup.py

A big part of the rest is related to configuration management, which tries to 
maximize convenience (as many config files as wanted, automatic reload option 
on changes, etc..)

Depending on public interest, it would be cool to create a public CDN 
collection, that is shared among users, or even distributed automatically.

Pete

On Montag, 16. Mai 2016 03:44:29 Eliezer Croitoru wrote:
> Thanks for sharing!
> 
> I didn't had enough time to understand the tool structure since I am not
> a python expert but,
> This is the first squid helper I have seen which is based on python and
> implements concurrency.
> 
> Thanks!!
> Eliezer Croitoru
> 
> On 10/05/2016 00:56, Hans-Peter Jansen wrote:
> > Hi,
> > 
> > I'm pleased to announce the availability of squid_dedup, a helper for
> > deduplicating CDN accesses, implementing the squid 3 StoreID protocol.
> > 
> > It is a multi-threaded tool, written in python3, with no further
> > dependencies, hosted at: https://github.com/frispete/squid_dedup
> > available at: https://pypi.python.org/pypi/squid-dedup
> > 
> > For openSUSE users, a ready made rpm package is available here:
> > https://build.opensuse.org/package/show/home:frispete:python3/squid_dedup
> > 
> > Any feedback is greatly appreciated.
> > 
> > Cheers,
> > Pete



From rangasai.manduva at in.unisys.com  Mon May 16 13:02:32 2016
From: rangasai.manduva at in.unisys.com (Manduva, Ranga Sai)
Date: Mon, 16 May 2016 13:02:32 +0000
Subject: [squid-users] squid_ldap_auth: WARNING, LDAP search error 'Referral'
Message-ID: <36b4b8106c3346b1b2b6677622bd1d78@AU-EXCH13-4.ap.uis.unisys.com>

Hello,

I am receiving this error while authenticating a user with the AD and the internet access is denied. I know there is a switch '-R' to explicitly enable do not follow referrals which I am not using here.

Did anyone faced similar issue ? My AD is using nested groups between domains where the users and groups are from different domains.

Got stuck with this issue for a while.. appreciate anyone's help in this regard.

Thank you.

Regards,
Ranga




From Walter.H at mathemainzel.info  Mon May 16 16:47:56 2016
From: Walter.H at mathemainzel.info (Walter H.)
Date: Mon, 16 May 2016 18:47:56 +0200
Subject: [squid-users] SSL-Bump and generated certificates ...
Message-ID: <5739F9BC.5070808@mathemainzel.info>

Hello,

I updated squid 3.4.10 to 3.5.19 on my CentOS VM, I noticed that the 
generated certificates are now SHA2 and not SHA1,
can I influence somewhere to generate still SHA1 certificates?
(I have devices which use this proxy and are not able to handle SHA2)

Thanks,
Walter


-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4312 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160516/e8146fe9/attachment.bin>

From eliezer at ngtech.co.il  Mon May 16 18:20:04 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 16 May 2016 21:20:04 +0300
Subject: [squid-users] SSL-Bump and generated certificates ...
In-Reply-To: <5739F9BC.5070808@mathemainzel.info>
References: <5739F9BC.5070808@mathemainzel.info>
Message-ID: <051401d1af9f$91c0fd60$b542f820$@ngtech.co.il>

Hey Walter,

I am not sure if it's the ssl_crtd which does such a thing but this is my
main suspect.
If you can extract the ssl_crtd binary from 3.4.X(newest) and test it before
maybe Alex will respond then it will verify some of the doubt.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Walter H.
Sent: Monday, May 16, 2016 7:48 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] SSL-Bump and generated certificates ...

Hello,

I updated squid 3.4.10 to 3.5.19 on my CentOS VM, I noticed that the
generated certificates are now SHA2 and not SHA1, can I influence somewhere
to generate still SHA1 certificates?
(I have devices which use this proxy and are not able to handle SHA2)

Thanks,
Walter





From emz at norma.perm.ru  Mon May 16 18:27:06 2016
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Mon, 16 May 2016 23:27:06 +0500
Subject: [squid-users] squid,
	SMP and authentication and service regression over time
Message-ID: <573A10FA.1040801@norma.perm.ru>

Hi.

I'm using squid for a long time, I'm using it to authenticate/authorize 
users accessing the Internet with LDAP in a Windows corporate 
enviromnent (Basic/NTLM/GSS-SPNEGO) and recently (about several months 
ago) I had to switch to the SMP scheme, because one process started to 
eat the whole core sometimes, thus bottlenecking users on it. Situation 
with CPU effectiveness improved, however I discovered several issues. 
The first I was aware of, it's the non-functional SNMP (since there's no 
solution, I just had to sacrifice it). But the second one is more 
disturbing. I discovered that after a several uptime (usually couple of 
weeks, a month at it's best) squid somehow degrades and stops 
authorizing users. I have about active 600 users on my biggest site 
(withount SNMP I'm not sure how many simultaneous users I got) but 
usually this starts like this: someone (this starts with one person) 
complains that he lost his access to the internet - not entirely, no. At 
first the access is very slow, and the victim has to wait several 
minutes for the page to load. Others are unaffected at this time. From 
time to time the victim is able to load one of two tabs in the browser, 
eventually, but at the end of the day this becomes unuseable, and my 
support has to come in. Then this gots escalated to me. First I was 
debugging various kerberos stuff, NTLM, victim's machine domain 
membership and so on. But today I managed to figure out that all I have 
to do is just restart squid, yeah (sounds silly, but I don't like to 
restart things, like in the "IT Crowd" TV Series, this is kinda last 
resort measure, when I'm desperate). If I'm stubborn enough to continue 
the investigation, soon I got 2 users complaining, then 3, then more. 
During previous outages eventually I used to restart squid (to change 
the domain controller in kerberos config, if I blame one; to disable the 
external Kerberos/LDAP helper connection pooling, if I blame one) - so 
each time there was a candidate to blame. But this time I just decided 
to restart squid, since I started to think it's the main reason, et 
voila. I should also mention that I run this AAA scheme in squid for 
years, and I didn't have this issue previously. I also have like dozen 
of other squids running same (very similar) config, - same AAA stuff - 
Basic/NTLM/GSS-SpNego, same AD group checking, but only for the 
different groups membership - and none of it has this issue. I'm 
thinking there's SMP involved, really.

I realize this is a poor problem report. "Something degrades, I restart 
squid, please help, I think it's SMP-related". But the thing is - I 
don't know where to start to narrow this stuff. If anyone's having a 
good idea please let me know.

Thanks.
Eugene.


From corpengineer at gmail.com  Mon May 16 18:37:20 2016
From: corpengineer at gmail.com (J Green)
Date: Mon, 16 May 2016 11:37:20 -0700
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZyzsq8UCOdsom_GBG84VOr3cYyzNpcaLxeLw-_cHg=GrzQ@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
 <51d8f7ad-29c8-2f00-6b83-4483b637ef56@gmail.com>
 <CANUpZyyRbNR938ZHpYe2d2XCACcxepjcH6auX++E6MOwMve4cA@mail.gmail.com>
 <01d601d1aafe$8b230c00$a1692400$@ngtech.co.il>
 <cc65f5ea-20a6-9dcc-6aac-f5057df161a1@gmail.com>
 <CANUpZyzsq8UCOdsom_GBG84VOr3cYyzNpcaLxeLw-_cHg=GrzQ@mail.gmail.com>
Message-ID: <CANUpZyz7W4+x7_c9iPPZCwKzPVxP+sH6-Bv1zKh63t5byNnG7g@mail.gmail.com>

Re logging, does this eventually get logged by Squid, somewhere?

For this implementation, I was going to use pfSense.  Turns out that Sarg
is no longer included in the package list for pfSense (current version).



On Tue, May 10, 2016 at 2:43 PM, J Green <corpengineer at gmail.com> wrote:

> Very interesting, thank you both.
>
> On Tue, May 10, 2016 at 2:23 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>>
>>
>>
>> 11.05.16 2:57, Eliezer Croitoru ?????:
>> >
>> > Hey,
>> >
>> >
>> >
>> > You can always use a TOS from squid to mark connections and\or users
>> and to somehow create some policy case on that.
>>
>> Sure, Eliezer. I've forgot about TOS. Good point.
>> >
>> > I have used more then once the Linux "tc" to "jail" a user which was
>> abusing his unbound bandwidth policy.
>> >
>> > I do not like the idea but I have asked couple networking experts about
>> the most used approach compared to the most efficient and it's seems pretty
>> reasonable from the business aspect of networking to slow(not hog) a user.
>> > Specifically there are places which defines the Internet as a WEB only
>> ie port 80 and 443 and for HTTP only traffic.
>> >
>> > For these purposes squid is great while there are other approaches to
>> the subject.
>> >
>> >
>> >
>> > Eliezer
>> >
>> >
>> >
>> > ----
>> >
>> > Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
>> <http://ngtech.co.il/lmgtfy/>
>> > Linux System Administrator
>> > Mobile: +972-5-28704261
>> > Email: eliezer at ngtech.co.il
>> >
>> >
>> >
>> > *From:*squid-users [mailto:squid-users-bounces at lists.squid-cache.org
>> <squid-users-bounces at lists.squid-cache.org>] *On Behalf Of *J Green
>> > *Sent:* Tuesday, May 10, 2016 8:42 PM
>> > *To:* Yuri Voinov
>> > *Cc:* squid-users at lists.squid-cache.org
>> > *Subject:* Re: [squid-users] Can Traffic Management Settings be
>> configured for other TCP protocols?
>> >
>> >
>> >
>> > That is fair, re intended use.  But yes, management want to know if
>> users are attempting to circumvent policy.  Re analyzing logs, I did not
>> see this logged anywhere.  Is there perhaps a debug mode which I need to
>> enable?
>> >
>> > Thank you.
>> >
>> >
>> >
>> > On Tue, May 10, 2016 at 10:29 AM, Yuri Voinov <yvoinov at gmail.com
>> <mailto:yvoinov at gmail.com> <yvoinov at gmail.com>> wrote:
>> >
>> >
>> > First, upload is PUT method usage. Most common HTTP/HTTPS is GET/HEAD
>> methods.
>> >
>> > Second, logging of all things is not my goal.
>> >
>> > For me, it is sufficient that the restrictions imposed by me in
>> accordance with the policy. The amount of downloads for my count analyzers
>> logs, if management is interesting to read the reports independently.
>> >
>> > 10.05.16 23:25, J Green ?????:
>> > > So back to the intended use cases for HTTP, HTTPS, & FTP , how can
>> you log violations of maximum download/upload size?  I see an error message
>> generated on the client system, but not w/in Squid.  Thank you.
>> >
>> > > On Mon, May 9, 2016 at 10:12 AM, Yuri Voinov <yvoinov at gmail.com
>> <mailto:yvoinov at gmail.com> <yvoinov at gmail.com> <mailto:yvoinov at gmail.com>
>> <yvoinov at gmail.com> <mailto:yvoinov at gmail.com> <yvoinov at gmail.com>>
>> wrote:
>> >
>> >
>> > > Squid is not a proxy server every imaginable the TCP-usage protocol.
>> >
>> > > AFAIK HTTP/HTTPS/FTP. That's all, folks.
>> >
>> >
>> > > 09.05.16 23:07, J Green ?????:
>> > > > Hello all:
>> >
>> >
>> >
>> > >       > Can Traffic Management Settings be configured for TCP
>> > >       protocols other than HTTP?
>> >
>> >
>> >
>> > >       > Would like to limit maximum upload and download sizes for
>> > >       other TCP protocols:  SMB, NFS, FTP, and RDP.
>> >
>> >
>> >
>> > >       > Is this possible?  If so, how?
>> >
>> >
>> >
>> > >       > Thank you.
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> > >       > _______________________________________________
>> >
>> > >       > squid-users mailing list
>> >
>> > >       > squid-users at lists.squid-cache.org
>> <mailto:squid-users at lists.squid-cache.org>
>> <squid-users at lists.squid-cache.org>
>> <mailto:squid-users at lists.squid-cache.org>
>> <squid-users at lists.squid-cache.org>
>> <mailto:squid-users at lists.squid-cache.org>
>> <squid-users at lists.squid-cache.org>
>> >
>> > >       > http://lists.squid-cache.org/listinfo/squid-users
>> >
>> >
>> >
>> > >     _______________________________________________
>> > >     squid-users mailing list
>> > >     squid-users at lists.squid-cache.org
>> <mailto:squid-users at lists.squid-cache.org>
>> <squid-users at lists.squid-cache.org>
>> <mailto:squid-users at lists.squid-cache.org>
>> <squid-users at lists.squid-cache.org>
>> <mailto:squid-users at lists.squid-cache.org>
>> <squid-users at lists.squid-cache.org>
>> > >     http://lists.squid-cache.org/listinfo/squid-users
>> >
>> >
>> >
>> >
>> >
>> >
>>
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v2
>>
>> iQEcBAEBCAAGBQJXMlFEAAoJENNXIZxhPexGO6AH/RsDrJKihobs93E9OLhT7uuB
>> 6KjX5eSfcNzYmTX1QsTn4SDf2l3HaItZ5jPuSFGSBMTuGo0RaHc0Y+YIcRO8CuOG
>> PQDBPXff2Vg16o06Ty78XLUAfWUr1q4uu6G5Vp8F2cLWSjk7thuFu9XoYe5Q2z1V
>> yN99aV/Kol+Om//eSPOf3hre3ONYRFn2lR+GJET9QNfogiRakpFOzeeGp3fXQgzA
>> S6n2MfhyhYRO3lDtjGcrWDoR5Tz8OdKlReuwHqtkuQi/OA95O9CpfwnEnORGLVN6
>> G4H0pG7MrXBbl5zRhspkr9BNvtunkFsSnUlcUhBtKj1RhsC7H9g7lvkE8QKphIU=
>> =kDA0
>> -----END PGP SIGNATURE-----
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160516/7453c891/attachment.htm>

From rousskov at measurement-factory.com  Mon May 16 19:24:52 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 16 May 2016 13:24:52 -0600
Subject: [squid-users] Squid 3.5.17 SSL-Bump Step1
In-Reply-To: <5e22c5485af2e34b24ad801acf1c5614@tisiz72.ru>
References: <89b6865755fa57c09cefb235afc00b52@tisiz72.ru>
 <b2edf9ca-40a3-c529-6694-98231996d722@treenet.co.nz>
 <5e22c5485af2e34b24ad801acf1c5614@tisiz72.ru>
Message-ID: <573A1E84.1070100@measurement-factory.com>

On 05/16/2016 04:47 AM, admin wrote:
>>> acl blocked_https ssl::server_name  "/etc/squid/urls/block-url"
>>> https_port 3129 intercept ssl-bump options=ALL:NO_SSLv3:NO_SSLv2
>>> connection-auth=off cert=/etc/squid/squidCA.pem
>>> acl step1 at_step SslBump1
>>> ssl_bump peek step1
>>> ssl_bump terminate blocked_https
>>>
>>> It works.

>> Obviously not. There is no instruction what to do other than terminate.
>> Squid is left to other circumstances to decide what is needed...

> it works! :) if you have the opportunity to check on the virtual machine

Your configuration works by accident. You should not expect it to work
across Squid upgrades, for example. It may continue to work or may stop
working. To fix the problem, be explicit regarding what to do when the
terminate rule does not match:

  ssl_bump peek step1
  ssl_bump terminate blocked_https
  ssl_bump splice all



> http_access deny users_no_inet

> Why, if access is
> allowed everything works, and if the ban on access to HTTP, you must
> first see a message stating that my certificate has not been able to
> match, and then later ERR_ACCESS_DENIED.


When access is allowed, Squid works as a TCP relay. Client bytes are
sent to the origin server. Server bytes are sent to the client. No
errors or certificates to worry about.

When access is prohibited via http_access deny, Squid needs to send an
"Access Denied" error response to the user (this is how http_access
works). To send that error to the user, Squid needs to establish a
secure connection with the user (this is how HTTPS works). To do that,
Squid has to use its own SSL certificate (this is how SSL works).


If you want to use a splice-or-terminate design, do not deny access via
http_access. Limit yourself to "ssl_bump terminate" rules.


HTH,

Alex.





From rousskov at measurement-factory.com  Mon May 16 19:32:24 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 16 May 2016 13:32:24 -0600
Subject: [squid-users] SSL-Bump and generated certificates ...
In-Reply-To: <5739F9BC.5070808@mathemainzel.info>
References: <5739F9BC.5070808@mathemainzel.info>
Message-ID: <573A2048.1060307@measurement-factory.com>

On 05/16/2016 10:47 AM, Walter H. wrote:

> I updated squid 3.4.10 to 3.5.19 on my CentOS VM, I noticed that the
> generated certificates are now SHA2 and not SHA1,
> can I influence somewhere to generate still SHA1 certificates?

Yes, you can:
http://www.squid-cache.org/Doc/config/sslproxy_cert_sign_hash/

Alex.



From rousskov at measurement-factory.com  Mon May 16 19:39:23 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 16 May 2016 13:39:23 -0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZyz7W4+x7_c9iPPZCwKzPVxP+sH6-Bv1zKh63t5byNnG7g@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
 <51d8f7ad-29c8-2f00-6b83-4483b637ef56@gmail.com>
 <CANUpZyyRbNR938ZHpYe2d2XCACcxepjcH6auX++E6MOwMve4cA@mail.gmail.com>
 <01d601d1aafe$8b230c00$a1692400$@ngtech.co.il>
 <cc65f5ea-20a6-9dcc-6aac-f5057df161a1@gmail.com>
 <CANUpZyzsq8UCOdsom_GBG84VOr3cYyzNpcaLxeLw-_cHg=GrzQ@mail.gmail.com>
 <CANUpZyz7W4+x7_c9iPPZCwKzPVxP+sH6-Bv1zKh63t5byNnG7g@mail.gmail.com>
Message-ID: <573A21EB.7010301@measurement-factory.com>

On 05/16/2016 12:37 PM, J Green wrote:
> Re logging, does this eventually get logged by Squid, somewhere?

All transactions accessing Squid must be logged in access.log. If a
transaction is not logged, it is a Squid bug.

Please note that Squid logs transactions when they complete, not when
they start. Thus, tunneled transactions should be logged when the tunnel
is closed, which may take a very long time in some cases.

Alex.


From corpengineer at gmail.com  Mon May 16 19:49:10 2016
From: corpengineer at gmail.com (J Green)
Date: Mon, 16 May 2016 12:49:10 -0700
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <573A21EB.7010301@measurement-factory.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
 <51d8f7ad-29c8-2f00-6b83-4483b637ef56@gmail.com>
 <CANUpZyyRbNR938ZHpYe2d2XCACcxepjcH6auX++E6MOwMve4cA@mail.gmail.com>
 <01d601d1aafe$8b230c00$a1692400$@ngtech.co.il>
 <cc65f5ea-20a6-9dcc-6aac-f5057df161a1@gmail.com>
 <CANUpZyzsq8UCOdsom_GBG84VOr3cYyzNpcaLxeLw-_cHg=GrzQ@mail.gmail.com>
 <CANUpZyz7W4+x7_c9iPPZCwKzPVxP+sH6-Bv1zKh63t5byNnG7g@mail.gmail.com>
 <573A21EB.7010301@measurement-factory.com>
Message-ID: <CANUpZyyOFvL=ZoWM6nh30EYPKXDHNEcnrvjDj=tDJtYCMf2APA@mail.gmail.com>

Sorry, I was looking for logging of traffic management events, where
maximum download/upload size has been violated.  Thank you.

On Mon, May 16, 2016 at 12:39 PM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 05/16/2016 12:37 PM, J Green wrote:
> > Re logging, does this eventually get logged by Squid, somewhere?
>
> All transactions accessing Squid must be logged in access.log. If a
> transaction is not logged, it is a Squid bug.
>
> Please note that Squid logs transactions when they complete, not when
> they start. Thus, tunneled transactions should be logged when the tunnel
> is closed, which may take a very long time in some cases.
>
> Alex.
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160516/6568c2d5/attachment.htm>

From amadaan at ncsu.edu  Mon May 16 20:23:36 2016
From: amadaan at ncsu.edu (Aashima Madaan)
Date: Mon, 16 May 2016 16:23:36 -0400
Subject: [squid-users] Squid unable to send full PNG file
Message-ID: <CAO4ouAZZRjR1n+i-7k158eeu8CEUKAviF560WrzU+N7fTdPFGg@mail.gmail.com>

Hi,

I have a PNG file uploaded on server.
As part of Download process, it passes through SQUID to another server for
scanning and then to Client .

When I send request to Download , the response sends only 27kb of image
back from server of of 700kb file

But when I turn off the respmod in squid.conf file

#adaptation_access service_resp allow all

The client gets full file. This is happening only with PNG files. Did
anyone encounter this kind of issue and has suggestions in this case?

Appreciate your help.


Thanks

Aashima
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160516/ee036c1a/attachment.htm>

From yvoinov at gmail.com  Mon May 16 20:44:45 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 17 May 2016 02:44:45 +0600
Subject: [squid-users] Squid unable to send full PNG file
In-Reply-To: <CAO4ouAZZRjR1n+i-7k158eeu8CEUKAviF560WrzU+N7fTdPFGg@mail.gmail.com>
References: <CAO4ouAZZRjR1n+i-7k158eeu8CEUKAviF560WrzU+N7fTdPFGg@mail.gmail.com>
Message-ID: <73bf1fc9-6e25-8d73-86eb-b0e4b4df5739@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Which side to this refers squid? Check the need to configure another server.

17.05.16 2:23, Aashima Madaan ?????:
> Hi,
>
> I have a PNG file uploaded on server.
> As part of Download process, it passes through SQUID to another server
for scanning and then to Client .
>
> When I send request to Download , the response sends only 27kb of
image back from server of of 700kb file
>
> But when I turn off the respmod in squid.conf file
>
> #adaptation_access service_resp allow all
>
> The client gets full file. This is happening only with PNG files. Did
anyone encounter this kind of issue and has suggestions in this case?
>
> Appreciate your help.
>
>
> Thanks
>
> Aashima
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXOjE9AAoJENNXIZxhPexGkBcH/RJiKqsngYCiXJ7EhWCbYyMw
RNvrG/g0FWC1vF7cIJiTyplrKPWEcOo4fdPStrlDzfpnK/RgW9dTADA9sjqGmkxh
DMdh/QMeQuVpYIEGU73sOzwcReDBDWUirxnw1CyJXHS14+Q3Bni1RabXsj9fe4TJ
eNnsIRhp18AI/LNLLobAP8GrUKDl8Hlc2mp8Fmy/+lGrJuT7nmjjTZDhhpXyy+nY
x9SiyiAbwkd7eD+Orfedpvnq7kVazAmWZW4A0SXtzvXW6JMradXosfrh6pRsD8Az
lRuK58HqIawOU0cUa7+i61AlUizgEB+RSpHdM52cfIzMw+/a70xEbsfXdL2SMBc=
=LMY3
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160517/e8267935/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160517/e8267935/attachment.key>

From rousskov at measurement-factory.com  Mon May 16 20:47:23 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 16 May 2016 14:47:23 -0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZyyOFvL=ZoWM6nh30EYPKXDHNEcnrvjDj=tDJtYCMf2APA@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
 <51d8f7ad-29c8-2f00-6b83-4483b637ef56@gmail.com>
 <CANUpZyyRbNR938ZHpYe2d2XCACcxepjcH6auX++E6MOwMve4cA@mail.gmail.com>
 <01d601d1aafe$8b230c00$a1692400$@ngtech.co.il>
 <cc65f5ea-20a6-9dcc-6aac-f5057df161a1@gmail.com>
 <CANUpZyzsq8UCOdsom_GBG84VOr3cYyzNpcaLxeLw-_cHg=GrzQ@mail.gmail.com>
 <CANUpZyz7W4+x7_c9iPPZCwKzPVxP+sH6-Bv1zKh63t5byNnG7g@mail.gmail.com>
 <573A21EB.7010301@measurement-factory.com>
 <CANUpZyyOFvL=ZoWM6nh30EYPKXDHNEcnrvjDj=tDJtYCMf2APA@mail.gmail.com>
Message-ID: <573A31DB.4020206@measurement-factory.com>

On 05/16/2016 01:49 PM, J Green wrote:
> Sorry, I was looking for logging of traffic management events, where
> maximum download/upload size has been violated.

When it comes to logging, I recommend that you think in terms of
transactions rather than traffic management events because Squid logs
transactions, not events (except for extraordinary events logged in
cache.log that should not be abused for your purposes).

If Squid abnormally terminates a transaction for any reason, including
exceeding size restrictions, the corresponding access log entry should
reflect that. I do not know whether the logged details would be
sufficient to identify the particular events you are interested in.


Furthermore, if you can express "maximum download/upload size has been
violated" condition using existing Squid ACLs, then you can log all
transactions that meet that condition to a special access log (and/or
log no other transactions).

  http://www.squid-cache.org/Doc/config/access_log/

If you cannot express that condition using existing Squid ACLs, you may
facilitate adding new Squid ACLs that would allow you to do so. If you
have to go this route, please define exactly what transactions each new
ACLs will match. The more transactions an ACL can apply to (i.e., can be
evaluated against), the better.

Alex.


> On Mon, May 16, 2016 at 12:39 PM, Alex Rousskov wrote:
> 
>     On 05/16/2016 12:37 PM, J Green wrote:
>     > Re logging, does this eventually get logged by Squid, somewhere?
> 
>     All transactions accessing Squid must be logged in access.log. If a
>     transaction is not logged, it is a Squid bug.
> 
>     Please note that Squid logs transactions when they complete, not when
>     they start. Thus, tunneled transactions should be logged when the tunnel
>     is closed, which may take a very long time in some cases.
> 
>     Alex.
> 
> 



From admin at tisiz72.ru  Tue May 17 03:08:05 2016
From: admin at tisiz72.ru (admin)
Date: Tue, 17 May 2016 08:08:05 +0500
Subject: [squid-users] Squid 3.5.17 SSL-Bump Step1
In-Reply-To: <573A1E84.1070100@measurement-factory.com>
References: <89b6865755fa57c09cefb235afc00b52@tisiz72.ru>
 <b2edf9ca-40a3-c529-6694-98231996d722@treenet.co.nz>
 <5e22c5485af2e34b24ad801acf1c5614@tisiz72.ru>
 <573A1E84.1070100@measurement-factory.com>
Message-ID: <6c7efd3e5917f519b676125afa7682a8@tisiz72.ru>

Thanks for answer, Alex! 

Alex Rousskov ????? 2016-05-17 00:24:

> When access is prohibited via http_access deny, Squid needs to send an
> "Access Denied" error response to the user (this is how http_access
> works). To send that error to the user, Squid needs to establish a
> secure connection with the user (this is how HTTPS works). To do that,
> Squid has to use its own SSL certificate (this is how SSL works).
> 
> If you want to use a splice-or-terminate design, do not deny access via
> http_access. Limit yourself to "ssl_bump terminate" rules.

Is feature planned to squid gave when ERR_ACCESS_DENIED then terminate?

What are some other ways to deny HTTPS in intercept mode?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160517/75b480d8/attachment.htm>

From squid3 at treenet.co.nz  Tue May 17 04:37:56 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 17 May 2016 16:37:56 +1200
Subject: [squid-users] Can Traffic Management Settings be configured for
	other TCP protocols?
In-Reply-To: <CANUpZyyOFvL=ZoWM6nh30EYPKXDHNEcnrvjDj=tDJtYCMf2APA@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
 <51d8f7ad-29c8-2f00-6b83-4483b637ef56@gmail.com>
 <CANUpZyyRbNR938ZHpYe2d2XCACcxepjcH6auX++E6MOwMve4cA@mail.gmail.com>
 <01d601d1aafe$8b230c00$a1692400$@ngtech.co.il>
 <cc65f5ea-20a6-9dcc-6aac-f5057df161a1@gmail.com>
 <CANUpZyzsq8UCOdsom_GBG84VOr3cYyzNpcaLxeLw-_cHg=GrzQ@mail.gmail.com>
 <CANUpZyz7W4+x7_c9iPPZCwKzPVxP+sH6-Bv1zKh63t5byNnG7g@mail.gmail.com>
 <573A21EB.7010301@measurement-factory.com>
 <CANUpZyyOFvL=ZoWM6nh30EYPKXDHNEcnrvjDj=tDJtYCMf2APA@mail.gmail.com>
Message-ID: <901e478a6ecb094fa138485aedfcd866@treenet.co.nz>

On 2016-05-17 07:49, J Green wrote:
> Sorry, I was looking for logging of traffic management events, where
> maximum download/upload size has been violated.  Thank you.
> 

The Squid native format logs size of things delivered to the client, not 
the upload/request size.

You will need to define a custom log format. See the "SIZE COUNTERS" 
section of <http://www.squid-cache.org/Doc/config/logformat/> for the 
available size measurement codes. You probably want %st.

And as Alex said tunnels and large uploads will not be logged and 
reported until they are finished. You cannot catch someone in the act 
using logs.

Amos



From garryd at comnet.uz  Tue May 17 08:39:23 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Tue, 17 May 2016 13:39:23 +0500
Subject: [squid-users] Squid transfers much not requested data from uplink
 in specific cases
Message-ID: <1463474363.19289.67.camel@comnet.uz>

Hello Squid community,

According to the bug report 4511 [1], Squid may transfer much useless,
not requested data from uplink after specific sequence of actions.

For example, slow client (access rate 128Kb/s) may begin transfer of
big cacheable object (4GB). After some time, another client (access
rate 1Mb/s) may begin to transfer the same object. Depending on time
interval between the requests (or the volume to data cached to disk by
the first transfer), after some time, transfer rate of the second
client will be limited to 128Kb/s too [2]. If after some time the first
client aborts the transfer, the second client's rate recovers to 1Mb/s
and Squid begin to transfer the object from origin server to disk cache
at maximum rate the uplink permits (let's assume 100Mb/s).

If the second client also aborts the transfer after some time, it may
results in much not requested data transferred from uplink. Also, if
Squid doesn't finish to transfer the object to the disk cache, the
object won't be cached finally.

For example, if the first client aborts the transfer after downloading
100MB, Squid begins to transfer the object at rate 100Mb/s. If after 4
minutes, the second client also aborts the transfer, Squid would
terminate the transfer from origin server and we get is the following
statistics:

Client #1 - 100MB
Client #2 - 100MB + 1Mb/s / 8 bits * 240 seconds = 130MB
Squid - 100MB + 100Mb/s / 8 bits * 240 seconds = 3100MB
Not requested / useless data = 3100MB - (100MB + 130MB) = 2870MB

In that scenario, Squid would get 2870MB useless data that would not be
cached (object's size 4GB). During these 4 minutes, 'Hits as % bytes
sent' counter would show extremely low value.

[1]?http://bugs.squid-cache.org/show_bug.cgi?id=4511
[2]?http://bugs.squid-cache.org/show_bug.cgi?id=4520

------------

So, I want to ask community to share ideas, best practice to cope with
the problem. Many thank in advance!

-- 
Garri Djavadyan <garryd at comnet.uz>
Comnet ISP



From reet.vyas28 at gmail.com  Tue May 17 09:47:34 2016
From: reet.vyas28 at gmail.com (Reet Vyas)
Date: Tue, 17 May 2016 15:17:34 +0530
Subject: [squid-users] Squid Peek and splice
In-Reply-To: <1834a08e-7e03-cf08-0d15-e84ee63cd200@treenet.co.nz>
References: <CAA8ViV9-S_skfmrBMws8N6BCUkr9Uf6BoeLo3aLzpOgkSzt7Ew@mail.gmail.com>
 <1834a08e-7e03-cf08-0d15-e84ee63cd200@treenet.co.nz>
Message-ID: <CAA8ViV8L-RW2jC0rcWpkB0JnxHtX2M5CB5ZVNU+vJzWxQOkjdw@mail.gmail.com>

Hi

Below is my squid configuration

Squid : 3.5.13
OS ubuntu 14.04


http_port 3128
http_port 3127 intercept
https_port 3129 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_certs/squid.crt
key=/etc/squid/ssl_certs/squid.key
cipher=ECDHE-RSA-RC4-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES128-SHA:DHE-RSA-CAMELLIA128-SHA:AES128-SHA:RC4-SHA:HIGH:!aNULL:!MD5:!ADH

always_direct allow all
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER
acl blocked ssl::server_name  "/etc/squid/blocked_https.txt"
acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump terminate blocked
ssl_bump splice all
sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB
sslcrtd_children 16 startup=1 idle=1
sslproxy_capath /etc/ssl/certs
sslproxy_cert_error allow all
ssl_unclean_shutdown on

I want to block facebook.com so I have added url in .txt file.

Its not blocking anything.

Please let me know what I have to change in this configuration

I getting below logs in squid


1463478160.585    551 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443
- HIER_NONE/- -
1463478160.585    550 192.168.0.66 TAG_NONE/503 0 CONNECT
freevideodownloader.co:443 - HIER_NONE/- -
1463478161.147    562 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443
- HIER_NONE/- -
1463478161.147    561 192.168.0.66 TAG_NONE/503 0 CONNECT
freevideodownloader.co:443 - HIER_NONE/- -
1463478163.982    553 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443
- HIER_NONE/- -
1463478163.982    552 192.168.0.66 TAG_NONE/503 0 CONNECT
freevideodownloader.co:443 - HIER_NONE/- -
1463478163.994    565 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443
- HIER_NONE/- -
1463478163.994    564 192.168.0.66 TAG_NONE/503 0 CONNECT
freevideodownloader.co:443 - HIER_NONE/- -
1463478184.338 182900 192.168.0.66 TAG_NONE/200 0 CONNECT 106.10.137.175:443
- HIER_NONE/- -
1463478184.338 182898 192.168.0.66 TCP_TUNNEL/200 6040 CONNECT
geo.query.yahoo.com:443 - ORIGINAL_DST/106.10.137.175 -


1463478194.373     61 192.168.0.66 TCP_MISS/204 233 GET
http://www.gstatic.com/generate_204 - ORIGINAL_DST/216.58.199.163 -
1463478209.166 240232 192.168.0.66 TAG_NONE/200 0 CONNECT 74.125.200.239:443
- HIER_NONE/- -
1463478209.166 240231 192.168.0.66 TCP_TUNNEL/200 5603 CONNECT
translate.googleapis.com:443 - ORIGINAL_DST/74.125.200.239 -
1463478209.200 240267 192.168.0.66 TAG_NONE/200 0 CONNECT 216.58.199.142:443
- HIER_NONE/- -
1463478209.200 240266 192.168.0.66 TCP_TUNNEL/200 4962 CONNECT
clients4.google.com:443 - ORIGINAL_DST/216.58.199.142 -
1463478213.443 181611 192.168.0.66 TAG_NONE/200 0 CONNECT 31.13.79.246:443
- HIER_NONE/- -
1463478213.443 181611 192.168.0.66 TCP_TUNNEL/200 8547 CONNECT
graph.facebook.com:443 - ORIGINAL_DST/31.13.79.246 -
1463478224.432     33 192.168.0.66 TCP_MISS/204 233 GET
http://www.gstatic.com/generate_204 - ORIGINAL_DST/216.58.199.131 -
1463478231.727    555 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443
- HIER_NONE/- -
1463478231.727    555 192.168.0.66 TAG_NONE/503 0 CONNECT
freevideodownloader.co:443 - HIER_NONE/- -
1463478232.311    572 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443
- HIER_NONE/- -
1463478232.311    571 192.168.0.66 TAG_NONE/503 0 CONNECT
freevideodownloader.co:443 - HIER_NONE/- -
1463478246.369  13073 192.168.0.66 TAG_NONE/200 0 CONNECT 74.125.200.189:443
- HIER_NONE/- -
1463478246.369  13072 192.168.0.66 TCP_TUNNEL/200 4546 CONNECT
0.client-channel.google.com:443 - ORIGINAL_DST/74.125.200.189 -
1463478246.369  13806 192.168.0.66 TAG_NONE/200 0 CONNECT 216.58.199.142:443
- HIER_NONE/- -
1463478246.369  13805 192.168.0.66 TCP_TUNNEL/200 4604 CONNECT
clients5.google.com:443 - ORIGINAL_DST/216.58.199.142 -
1463478265.935 119576 192.168.0.66 TAG_NONE/200 0 CONNECT 106.10.199.11:443
- HIER_NONE/- -
1463478265.935 119576 192.168.0.66 TCP_TUNNEL/200 8586 CONNECT
geo.yahoo.com:443 - ORIGINAL_DST/106.10.199.11 -
1463478327.555     41 192.168.0.66 TCP_MISS/200 2323 GET
http://www.gstatic.com/chrome/crlset/3006/crl-set-delta-3005-260733898557562236.crx.data
- ORIGINAL_DST/216.58.220.3 text/html


On Fri, May 13, 2016 at 4:37 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 13/05/2016 5:58 p.m., Reet Vyas wrote:
> > Hi Amos/Yuri,
> >
> > Currently my squid is configured with ssl bump, now I want to use peek
> and
> > splice. I read in some forum that we don't need to install certificate on
> > client's machine.
> >
>
> Splice does not require it. But what you want to do with Squid may
> prevent splice being used. So "it depends" ...
>
>
> > As I have already asked before in mailing list to install SSL certificate
> > on Android devices, which is not working.
> >
> > So my question is If I want to use peek and splice for example I want
> https
> > filtering for
>
>  ... on how you define "filter".
>
> > proxy websites
>
> Not sure what you mean by that term.
>
> > and I dont want ssl for bank websites and
> > facebook youtube and gmail. how will it work? Do i need to install SSL
> > certifcate on client or not, I am bit confused with peek and splice
> thing.
>
> When you intercept port 443 normally only the raw-IP is available from
> TCP. Peek allows Squid to get the server name the client was trying to
> connect to out of the TLS. So that Squid can handle the intercepted
> connection as if it had received a CONNECT message (which usually have
> server/domain names).
>
> Splicing can be thought of as handling a intercepted port 443 connection
> as if it were a CONNECT message, with no decryption. It is treated as a
> single "thing", with some limited control possibilities.
>
>
> So...
>
> In order to bump (decrypt) some traffic and splice (not decrypt) other
> traffic you need to have a way to decide which type is being dealt with.
> That is the peek or stare actions - to get data out of the TLS handshake
> for you to use in ACL decisions.
>
> You might now want to re-read the SslPeekAndSplice documentation again
> to see if you understand it better. I skipped a lot of important details
> to make the description clear.
>
>
> >
> > Please let me know is that possible to configure squid 3.5.19 in such a
> way
> > so that it will bump  only proxy websites not FB youtube etc.
> >
>
> Ah. So what are these "proxy websites" you speak of ?
>
> One thing you need to be clear about is that once the TCP packets enter
> Squid they *have* to be "proxied". There is no way to undo TCP accept()
> and read() operations. But there are many ways of handling them that
> Squid can do.
>
> PS. you could post your existing config so we can suggest alterations to
> it that will lead to it doing your new policy. That can be another way
> to learn how the relevant-to-you part of the features work without
> diving into the full complexity of what *might* be doable.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160517/5a7d6b0b/attachment.htm>

From admin at tisiz72.ru  Tue May 17 09:51:11 2016
From: admin at tisiz72.ru (admin)
Date: Tue, 17 May 2016 14:51:11 +0500
Subject: [squid-users] Squid Peek and splice
In-Reply-To: <CAA8ViV8L-RW2jC0rcWpkB0JnxHtX2M5CB5ZVNU+vJzWxQOkjdw@mail.gmail.com>
References: <CAA8ViV9-S_skfmrBMws8N6BCUkr9Uf6BoeLo3aLzpOgkSzt7Ew@mail.gmail.com>
 <1834a08e-7e03-cf08-0d15-e84ee63cd200@treenet.co.nz>
 <CAA8ViV8L-RW2jC0rcWpkB0JnxHtX2M5CB5ZVNU+vJzWxQOkjdw@mail.gmail.com>
Message-ID: <8aaf4f0906db71e6d8bb7bab7624e473@tisiz72.ru>

get your blocked_https.txt 

Reet Vyas ????? 2016-05-17 14:47:

> Hi 
> 
> Below is my squid configuration  
> 
> Squid : 3.5.13 
> OS ubuntu 14.04 
> 
> http_port 3128 
> http_port 3127 intercept 
> https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_certs/squid.crt key=/etc/squid/ssl_certs/squid.key cipher=ECDHE-RSA-RC4-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES128-SHA:DHE-RSA-CAMELLIA128-SHA:AES128-SHA:RC4-SHA:HIGH:!aNULL:!MD5:!ADH 
> 
> always_direct allow all 
> sslproxy_cert_error allow all 
> sslproxy_flags DONT_VERIFY_PEER 
> acl blocked ssl::server_name  "/etc/squid/blocked_https.txt" 
> acl step1 at_step SslBump1 
> ssl_bump peek step1 
> ssl_bump terminate blocked 
> ssl_bump splice all 
> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB 
> sslcrtd_children 16 startup=1 idle=1 
> sslproxy_capath /etc/ssl/certs 
> sslproxy_cert_error allow all 
> ssl_unclean_shutdown on 
> 
> I want to block facebook.com [1] so I have added url in .txt file. 
> 
> Its not blocking anything. 
> 
> Please let me know what I have to change in this configuration 
> 
> I getting below logs in squid 
> 
> 1463478160.585    551 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443 [2] - HIER_NONE/- - 
> 1463478160.585    550 192.168.0.66 TAG_NONE/503 0 CONNECT freevideodownloader.co:443 [3] - HIER_NONE/- - 
> 1463478161.147    562 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443 [2] - HIER_NONE/- - 
> 1463478161.147    561 192.168.0.66 TAG_NONE/503 0 CONNECT freevideodownloader.co:443 [3] - HIER_NONE/- - 
> 1463478163.982    553 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443 [2] - HIER_NONE/- - 
> 1463478163.982    552 192.168.0.66 TAG_NONE/503 0 CONNECT freevideodownloader.co:443 [3] - HIER_NONE/- - 
> 1463478163.994    565 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443 [2] - HIER_NONE/- - 
> 1463478163.994    564 192.168.0.66 TAG_NONE/503 0 CONNECT freevideodownloader.co:443 [3] - HIER_NONE/- - 
> 1463478184.338 182900 192.168.0.66 TAG_NONE/200 0 CONNECT 106.10.137.175:443 [4] - HIER_NONE/- - 
> 1463478184.338 182898 192.168.0.66 TCP_TUNNEL/200 6040 CONNECT geo.query.yahoo.com:443 [5] - ORIGINAL_DST/106.10.137.175 [6] - 
> 
> 1463478194.373     61 192.168.0.66 TCP_MISS/204 233 GET http://www.gstatic.com/generate_204 - ORIGINAL_DST/216.58.199.163 [7] - 
> 1463478209.166 240232 192.168.0.66 TAG_NONE/200 0 CONNECT 74.125.200.239:443 [8] - HIER_NONE/- - 
> 1463478209.166 240231 192.168.0.66 TCP_TUNNEL/200 5603 CONNECT translate.googleapis.com:443 [9] - ORIGINAL_DST/74.125.200.239 [10] - 
> 1463478209.200 240267 192.168.0.66 TAG_NONE/200 0 CONNECT 216.58.199.142:443 [11] - HIER_NONE/- - 
> 1463478209.200 240266 192.168.0.66 TCP_TUNNEL/200 4962 CONNECT clients4.google.com:443 [12] - ORIGINAL_DST/216.58.199.142 [13] - 
> 1463478213.443 181611 192.168.0.66 TAG_NONE/200 0 CONNECT 31.13.79.246:443 [14] - HIER_NONE/- - 
> 1463478213.443 181611 192.168.0.66 TCP_TUNNEL/200 8547 CONNECT graph.facebook.com:443 [15] - ORIGINAL_DST/31.13.79.246 [16] - 
> 1463478224.432     33 192.168.0.66 TCP_MISS/204 233 GET http://www.gstatic.com/generate_204 - ORIGINAL_DST/216.58.199.131 [17] - 
> 1463478231.727    555 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443 [2] - HIER_NONE/- - 
> 1463478231.727    555 192.168.0.66 TAG_NONE/503 0 CONNECT freevideodownloader.co:443 [3] - HIER_NONE/- - 
> 1463478232.311    572 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443 [2] - HIER_NONE/- - 
> 1463478232.311    571 192.168.0.66 TAG_NONE/503 0 CONNECT freevideodownloader.co:443 [3] - HIER_NONE/- - 
> 1463478246.369  13073 192.168.0.66 TAG_NONE/200 0 CONNECT 74.125.200.189:443 [18] - HIER_NONE/- - 
> 1463478246.369  13072 192.168.0.66 TCP_TUNNEL/200 4546 CONNECT 0.client-channel.google.com:443 [19] - ORIGINAL_DST/74.125.200.189 [20] - 
> 1463478246.369  13806 192.168.0.66 TAG_NONE/200 0 CONNECT 216.58.199.142:443 [11] - HIER_NONE/- - 
> 1463478246.369  13805 192.168.0.66 TCP_TUNNEL/200 4604 CONNECT clients5.google.com:443 [21] - ORIGINAL_DST/216.58.199.142 [13] - 
> 1463478265.935 119576 192.168.0.66 TAG_NONE/200 0 CONNECT 106.10.199.11:443 [22] - HIER_NONE/- - 
> 1463478265.935 119576 192.168.0.66 TCP_TUNNEL/200 8586 CONNECT geo.yahoo.com:443 [23] - ORIGINAL_DST/106.10.199.11 [24] - 
> 1463478327.555     41 192.168.0.66 TCP_MISS/200 2323 GET http://www.gstatic.com/chrome/crlset/3006/crl-set-delta-3005-260733898557562236.crx.data - ORIGINAL_DST/216.58.220.3 [25] text/html 
> 
> On Fri, May 13, 2016 at 4:37 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
>> On 13/05/2016 5:58 p.m., Reet Vyas wrote:
>>> Hi Amos/Yuri,
>>> 
>>> Currently my squid is configured with ssl bump, now I want to use peek and
>>> splice. I read in some forum that we don't need to install certificate on
>>> client's machine.
>>> 
>> 
>> Splice does not require it. But what you want to do with Squid may
>> prevent splice being used. So "it depends" ...
>> 
>>> As I have already asked before in mailing list to install SSL certificate
>>> on Android devices, which is not working.
>>> 
>>> So my question is If I want to use peek and splice for example I want https
>>> filtering for
>> 
>> ... on how you define "filter".
>> 
>>> proxy websites
>> 
>> Not sure what you mean by that term.
>> 
>>> and I dont want ssl for bank websites and
>>> facebook youtube and gmail. how will it work? Do i need to install SSL
>>> certifcate on client or not, I am bit confused with peek and splice thing.
>> 
>> When you intercept port 443 normally only the raw-IP is available from
>> TCP. Peek allows Squid to get the server name the client was trying to
>> connect to out of the TLS. So that Squid can handle the intercepted
>> connection as if it had received a CONNECT message (which usually have
>> server/domain names).
>> 
>> Splicing can be thought of as handling a intercepted port 443 connection
>> as if it were a CONNECT message, with no decryption. It is treated as a
>> single "thing", with some limited control possibilities.
>> 
>> So...
>> 
>> In order to bump (decrypt) some traffic and splice (not decrypt) other
>> traffic you need to have a way to decide which type is being dealt with.
>> That is the peek or stare actions - to get data out of the TLS handshake
>> for you to use in ACL decisions.
>> 
>> You might now want to re-read the SslPeekAndSplice documentation again
>> to see if you understand it better. I skipped a lot of important details
>> to make the description clear.
>> 
>>> 
>>> Please let me know is that possible to configure squid 3.5.19 in such a way
>>> so that it will bump  only proxy websites not FB youtube etc.
>>> 
>> 
>> Ah. So what are these "proxy websites" you speak of ?
>> 
>> One thing you need to be clear about is that once the TCP packets enter
>> Squid they *have* to be "proxied". There is no way to undo TCP accept()
>> and read() operations. But there are many ways of handling them that
>> Squid can do.
>> 
>> PS. you could post your existing config so we can suggest alterations to
>> it that will lead to it doing your new policy. That can be another way
>> to learn how the relevant-to-you part of the features work without
>> diving into the full complexity of what *might* be doable.
>> 
>> Amos
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
 

Links:
------
[1] http://facebook.com
[2] http://107.170.47.181:443
[3] http://freevideodownloader.co:443
[4] http://106.10.137.175:443
[5] http://geo.query.yahoo.com:443
[6] http://106.10.137.175
[7] http://216.58.199.163
[8] http://74.125.200.239:443
[9] http://translate.googleapis.com:443
[10] http://74.125.200.239
[11] http://216.58.199.142:443
[12] http://clients4.google.com:443
[13] http://216.58.199.142
[14] http://31.13.79.246:443
[15] http://graph.facebook.com:443
[16] http://31.13.79.246
[17] http://216.58.199.131
[18] http://74.125.200.189:443
[19] http://0.client-channel.google.com:443
[20] http://74.125.200.189
[21] http://clients5.google.com:443
[22] http://106.10.199.11:443
[23] http://geo.yahoo.com:443
[24] http://106.10.199.11
[25] http://216.58.220.3
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160517/2939d4e5/attachment.htm>

From reet.vyas28 at gmail.com  Tue May 17 10:48:00 2016
From: reet.vyas28 at gmail.com (Reet Vyas)
Date: Tue, 17 May 2016 16:18:00 +0530
Subject: [squid-users] Squid Peek and splice
In-Reply-To: <CAA8ViV_sXRtBocFwFreuRG5oy_AwCb7qvQ1Np59XaggXkj68sA@mail.gmail.com>
References: <CAA8ViV9-S_skfmrBMws8N6BCUkr9Uf6BoeLo3aLzpOgkSzt7Ew@mail.gmail.com>
 <1834a08e-7e03-cf08-0d15-e84ee63cd200@treenet.co.nz>
 <CAA8ViV8L-RW2jC0rcWpkB0JnxHtX2M5CB5ZVNU+vJzWxQOkjdw@mail.gmail.com>
 <8aaf4f0906db71e6d8bb7bab7624e473@tisiz72.ru>
 <CAA8ViV_sXRtBocFwFreuRG5oy_AwCb7qvQ1Np59XaggXkj68sA@mail.gmail.com>
Message-ID: <CAA8ViV-5dEeCka1EfJ_MQYPh18PZAoO-okSEoTrgnXKLM=usCQ@mail.gmail.com>

Here is my txt file, as of now its working but I am getting secure
connection failed, I want to know if we can customize error message like
Access Denied .

In logs I am not getting  full URL PFA logs for same. What I have to change
 in peek and splice  ssl bump to get full URL ?

Logs:

3481340.025      0 192.168.0.66 TAG_NONE/200 0 CONNECT 31.13.79.220:443 -
HIER_NONE/- -
1463481340.037      0 192.168.0.66 TAG_NONE/200 0 CONNECT 31.13.79.220:443
- HIER_NONE/- -
1463481352.675  98653 192.168.0.11 TCP_TUNNEL/200 4567 CONNECT
74.125.68.100:443 - ORIGINAL_DST/74.125.68.100 -
1463481403.492 240049 192.168.0.188 TCP_TUNNEL/200 244 CONNECT
216.58.199.133:443 - ORIGINAL_DST/216.58.199.133 -
1463481403.519 240205 192.168.0.188 TCP_TUNNEL/200 244 CONNECT
74.125.130.189:443 - ORIGINAL_DST/74.125.130.189 -
1463481411.577 240235 192.168.0.66 TCP_TUNNEL/200 1832 CONNECT
74.125.68.239:443 - ORIGINAL_DST/74.125.68.239 -
1463481411.688 240430 192.168.0.66 TCP_TUNNEL/200 766 CONNECT
74.125.68.100:443 - ORIGINAL_DST/74.125.68.100 -
1463481411.940 240038 192.168.0.66 TCP_TUNNEL/200 502 CONNECT
216.58.199.141:443 - ORIGINAL_DST/216.58.199.141 -
1463481415.391 240029 192.168.0.66 TCP_TUNNEL/200 502 CONNECT
216.58.220.5:443 - ORIGINAL_DST/216.58.220.5 -
1463481418.469 240252 192.168.0.66 TCP_TUNNEL/200 518 CONNECT
74.125.68.132:443 - ORIGINAL_DST/74.125.68.132 -
1463481419.003 240197 192.168.0.66 TCP_TUNNEL/200 502 CONNECT
74.125.200.138:443 - ORIGINAL_DST/74.125.200.138 -
1463481421.151 240041 192.168.0.66 TCP_TUNNEL/200 143096 CONNECT
216.58.199.131:443 - ORIGINAL_DST/216.58.199.131 -
1463481421.196  59328 192.168.0.11 TCP_TUNNEL/200 786 CONNECT
216.58.199.142:443 - ORIGINAL_DST/216.58.199.142 -
1463481421.758 240647 192.168.0.66 TCP_TUNNEL/200 464 CONNECT
216.58.199.131:443 - ORIGINAL_DST/216.58.199.131 -
1463481445.844 282774 192.168.0.188 TCP_TUNNEL/200 1423 CONNECT
74.125.130.189:443 - ORIGINAL_DST/74.125.130.189 -
1463481446.091 282893 192.168.0.188 TCP_TUNNEL/200 2418 CONNECT
216.58.199.133:443 - ORIGINAL_DST/216.58.199.133 -
1463481470.715  59069 192.168.0.11 TCP_TUNNEL/200 1395 CONNECT
216.58.199.206:443 - ORIGINAL_DST/216.58.199.206 -
1463481470.729  58778 192.168.0.11 TCP_TUNNEL/200 7609 CONNECT
216.58.199.206:443 - ORIGINAL_DST/216.58.199.206 -
1463481482.663  62472 192.168.0.11 TCP_TUNNEL/200 3000 CONNECT
216.58.199.165:443 - ORIGINAL_DST/216.58.199.165 -
1463481505.775 334542 192.168.0.66 TCP_TUNNEL/200 59071 CONNECT
216.58.199.131:443 - ORIGINAL_DST/216.58.199.131 -
1463481512.946 240206 192.168.0.66 TCP_TUNNEL/200 470 CONNECT
74.125.130.101:443 - ORIGINAL_DST/74.125.130.101 -
1463481513.057 240084 192.168.0.66 TCP_TUNNEL/200 886 CONNECT
216.58.199.142:443 - ORIGINAL_DST/216.58.199.142 -
1463481513.574 240132 192.168.0.66 TCP_TUNNEL/200 1116 CONNECT
216.58.199.142:443 - ORIGINAL_DST/216.58.199.142 -
1463481514.156 240036 192.168.0.66 TCP_TUNNEL/200 454 CONNECT
216.58.199.129:443 - ORIGINAL_DST/216.58.199.129 -
1463481542.096   5675 192.168.0.11 TCP_TUNNEL/200 686 CONNECT
162.213.33.48:443 - ORIGINAL_DST/162.213.33.48 -
1463481546.586  59549 192.168.0.11 TCP_TUNNEL/200 493 CONNECT
216.58.199.131:443 - ORIGINAL_DST/216.58.199.131 -
1463481569.729 398494 192.168.0.66 TCP_TUNNEL/200 2523 CONNECT
216.58.199.142:443 - ORIGINAL_DST/216.58.199.142 -
1463481574.930 240032 192.168.0.66 TCP_TUNNEL/200 464 CONNECT
216.58.220.3:443 - ORIGINAL_DST/216.58.220.3 -
1463481578.959 240248 192.168.0.66 TCP_TUNNEL/200 1220 CONNECT
74.125.130.94:443 - ORIGINAL_DST/74.125.130.94 -
1463481614.460 444470 192.168.0.66 TCP_TUNNEL/200 13976 CONNECT
216.58.199.133:443 - ORIGINAL_DST/216.58.199.133 -
1463481631.174 460024 192.168.0.66 TCP_TUNNEL/200 5641 CONNECT
74.125.200.189:443 - ORIGINAL_DST/74.125.200.189 -
1463481753.303 303648 192.168.0.11 TCP_TUNNEL/200 2801 CONNECT
216.58.199.142:443 - ORIGINAL_DST/216.58.199.142 -
1463481759.694 240237 192.168.0.11 TCP_TUNNEL/200 829 CONNECT
216.58.199.206:443 - ORIGINAL_DST/216.58.199.206 -
1463481761.126 261752 192.168.0.11 TCP_TUNNEL/200 205262 CONNECT
216.58.199.129:443 - ORIGINAL_DST/216.58.199.129 -
1463481762.066 269470 192.168.0.11 TCP_TUNNEL/200 177618 CONNECT
216.58.199.129:443 - ORIGINAL_DST/216.58.199.129 -
1463481762.241 276758 192.168.0.11 TCP_TUNNEL/200 1451680 CONNECT
216.58.199.165:443 - ORIGINAL_DST/216.58.199.16





On Tue, May 17, 2016 at 3:33 PM, Reet Vyas <reet.vyas28 at gmail.com> wrote:

> Here is my txt file, as of now its working but I am getting secure
> connection failed, I want to know if we can customize error message like
> Access Denied .
>
> In logs I am not getting  full URL PFA logs for same. What I have to
> change  in peek and splice  ssl bump to get full URL ?
>
> On Tue, May 17, 2016 at 3:21 PM, admin <admin at tisiz72.ru> wrote:
>
>>
>>
>> get your blocked_https.txt
>>
>>
>>
>>
>> Reet Vyas ????? 2016-05-17 14:47:
>>
>> Hi
>>
>> Below is my squid configuration
>>
>> Squid : 3.5.13
>> OS ubuntu 14.04
>>
>>
>> http_port 3128
>> http_port 3127 intercept
>> https_port 3129 intercept ssl-bump generate-host-certificates=on
>> dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_certs/squid.crt
>> key=/etc/squid/ssl_certs/squid.key
>> cipher=ECDHE-RSA-RC4-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES128-SHA:DHE-RSA-CAMELLIA128-SHA:AES128-SHA:RC4-SHA:HIGH:!aNULL:!MD5:!ADH
>>
>> always_direct allow all
>> sslproxy_cert_error allow all
>> sslproxy_flags DONT_VERIFY_PEER
>> acl blocked ssl::server_name  "/etc/squid/blocked_https.txt"
>> acl step1 at_step SslBump1
>> ssl_bump peek step1
>> ssl_bump terminate blocked
>> ssl_bump splice all
>> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB
>> sslcrtd_children 16 startup=1 idle=1
>> sslproxy_capath /etc/ssl/certs
>> sslproxy_cert_error allow all
>> ssl_unclean_shutdown on
>>
>> I want to block facebook.com so I have added url in .txt file.
>>
>> Its not blocking anything.
>>
>> Please let me know what I have to change in this configuration
>>
>> I getting below logs in squid
>>
>>
>> 1463478160.585    551 192.168.0.66 TAG_NONE/200 0 CONNECT
>> 107.170.47.181:443 - HIER_NONE/- -
>> 1463478160.585    550 192.168.0.66 TAG_NONE/503 0 CONNECT
>> freevideodownloader.co:443 - HIER_NONE/- -
>> 1463478161.147    562 192.168.0.66 TAG_NONE/200 0 CONNECT
>> 107.170.47.181:443 - HIER_NONE/- -
>> 1463478161.147    561 192.168.0.66 TAG_NONE/503 0 CONNECT
>> freevideodownloader.co:443 - HIER_NONE/- -
>> 1463478163.982    553 192.168.0.66 TAG_NONE/200 0 CONNECT
>> 107.170.47.181:443 - HIER_NONE/- -
>> 1463478163.982    552 192.168.0.66 TAG_NONE/503 0 CONNECT
>> freevideodownloader.co:443 - HIER_NONE/- -
>> 1463478163.994    565 192.168.0.66 TAG_NONE/200 0 CONNECT
>> 107.170.47.181:443 - HIER_NONE/- -
>> 1463478163.994    564 192.168.0.66 TAG_NONE/503 0 CONNECT
>> freevideodownloader.co:443 - HIER_NONE/- -
>> 1463478184.338 182900 192.168.0.66 TAG_NONE/200 0 CONNECT
>> 106.10.137.175:443 - HIER_NONE/- -
>> 1463478184.338 182898 192.168.0.66 TCP_TUNNEL/200 6040 CONNECT
>> geo.query.yahoo.com:443 - ORIGINAL_DST/106.10.137.175 -
>>
>>
>> 1463478194.373     61 192.168.0.66 TCP_MISS/204 233 GET
>> http://www.gstatic.com/generate_204 - ORIGINAL_DST/216.58.199.163 -
>> 1463478209.166 240232 192.168.0.66 TAG_NONE/200 0 CONNECT
>> 74.125.200.239:443 - HIER_NONE/- -
>> 1463478209.166 240231 192.168.0.66 TCP_TUNNEL/200 5603 CONNECT
>> translate.googleapis.com:443 - ORIGINAL_DST/74.125.200.239 -
>> 1463478209.200 240267 192.168.0.66 TAG_NONE/200 0 CONNECT
>> 216.58.199.142:443 - HIER_NONE/- -
>> 1463478209.200 240266 192.168.0.66 TCP_TUNNEL/200 4962 CONNECT
>> clients4.google.com:443 - ORIGINAL_DST/216.58.199.142 -
>> 1463478213.443 181611 192.168.0.66 TAG_NONE/200 0 CONNECT
>> 31.13.79.246:443 - HIER_NONE/- -
>> 1463478213.443 181611 192.168.0.66 TCP_TUNNEL/200 8547 CONNECT
>> graph.facebook.com:443 - ORIGINAL_DST/31.13.79.246 -
>> 1463478224.432     33 192.168.0.66 TCP_MISS/204 233 GET
>> http://www.gstatic.com/generate_204 - ORIGINAL_DST/216.58.199.131 -
>> 1463478231.727    555 192.168.0.66 TAG_NONE/200 0 CONNECT
>> 107.170.47.181:443 - HIER_NONE/- -
>> 1463478231.727    555 192.168.0.66 TAG_NONE/503 0 CONNECT
>> freevideodownloader.co:443 - HIER_NONE/- -
>> 1463478232.311    572 192.168.0.66 TAG_NONE/200 0 CONNECT
>> 107.170.47.181:443 - HIER_NONE/- -
>> 1463478232.311    571 192.168.0.66 TAG_NONE/503 0 CONNECT
>> freevideodownloader.co:443 - HIER_NONE/- -
>> 1463478246.369  13073 192.168.0.66 TAG_NONE/200 0 CONNECT
>> 74.125.200.189:443 - HIER_NONE/- -
>> 1463478246.369  13072 192.168.0.66 TCP_TUNNEL/200 4546 CONNECT
>> 0.client-channel.google.com:443 - ORIGINAL_DST/74.125.200.189 -
>> 1463478246.369  13806 192.168.0.66 TAG_NONE/200 0 CONNECT
>> 216.58.199.142:443 - HIER_NONE/- -
>> 1463478246.369  13805 192.168.0.66 TCP_TUNNEL/200 4604 CONNECT
>> clients5.google.com:443 - ORIGINAL_DST/216.58.199.142 -
>> 1463478265.935 119576 192.168.0.66 TAG_NONE/200 0 CONNECT
>> 106.10.199.11:443 - HIER_NONE/- -
>> 1463478265.935 119576 192.168.0.66 TCP_TUNNEL/200 8586 CONNECT
>> geo.yahoo.com:443 - ORIGINAL_DST/106.10.199.11 -
>> 1463478327.555     41 192.168.0.66 TCP_MISS/200 2323 GET
>> http://www.gstatic.com/chrome/crlset/3006/crl-set-delta-3005-260733898557562236.crx.data
>> - ORIGINAL_DST/216.58.220.3 text/html
>>
>>
>> On Fri, May 13, 2016 at 4:37 PM, Amos Jeffries <squid3 at treenet.co.nz>
>> wrote:
>>
>>> On 13/05/2016 5:58 p.m., Reet Vyas wrote:
>>> > Hi Amos/Yuri,
>>> >
>>> > Currently my squid is configured with ssl bump, now I want to use peek
>>> and
>>> > splice. I read in some forum that we don't need to install certificate
>>> on
>>> > client's machine.
>>> >
>>>
>>> Splice does not require it. But what you want to do with Squid may
>>> prevent splice being used. So "it depends" ...
>>>
>>>
>>> > As I have already asked before in mailing list to install SSL
>>> certificate
>>> > on Android devices, which is not working.
>>> >
>>> > So my question is If I want to use peek and splice for example I want
>>> https
>>> > filtering for
>>>
>>>  ... on how you define "filter".
>>>
>>> > proxy websites
>>>
>>> Not sure what you mean by that term.
>>>
>>> > and I dont want ssl for bank websites and
>>> > facebook youtube and gmail. how will it work? Do i need to install SSL
>>> > certifcate on client or not, I am bit confused with peek and splice
>>> thing.
>>>
>>> When you intercept port 443 normally only the raw-IP is available from
>>> TCP. Peek allows Squid to get the server name the client was trying to
>>> connect to out of the TLS. So that Squid can handle the intercepted
>>> connection as if it had received a CONNECT message (which usually have
>>> server/domain names).
>>>
>>> Splicing can be thought of as handling a intercepted port 443 connection
>>> as if it were a CONNECT message, with no decryption. It is treated as a
>>> single "thing", with some limited control possibilities.
>>>
>>>
>>> So...
>>>
>>> In order to bump (decrypt) some traffic and splice (not decrypt) other
>>> traffic you need to have a way to decide which type is being dealt with.
>>> That is the peek or stare actions - to get data out of the TLS handshake
>>> for you to use in ACL decisions.
>>>
>>> You might now want to re-read the SslPeekAndSplice documentation again
>>> to see if you understand it better. I skipped a lot of important details
>>> to make the description clear.
>>>
>>>
>>> >
>>> > Please let me know is that possible to configure squid 3.5.19 in such
>>> a way
>>> > so that it will bump  only proxy websites not FB youtube etc.
>>> >
>>>
>>> Ah. So what are these "proxy websites" you speak of ?
>>>
>>> One thing you need to be clear about is that once the TCP packets enter
>>> Squid they *have* to be "proxied". There is no way to undo TCP accept()
>>> and read() operations. But there are many ways of handling them that
>>> Squid can do.
>>>
>>> PS. you could post your existing config so we can suggest alterations to
>>> it that will lead to it doing your new policy. That can be another way
>>> to learn how the relevant-to-you part of the features work without
>>> diving into the full complexity of what *might* be doable.
>>>
>>> Amos
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160517/5f51713d/attachment.htm>

From admin at tisiz72.ru  Tue May 17 10:51:41 2016
From: admin at tisiz72.ru (admin)
Date: Tue, 17 May 2016 15:51:41 +0500
Subject: [squid-users] Squid Peek and splice
In-Reply-To: <CAA8ViV-5dEeCka1EfJ_MQYPh18PZAoO-okSEoTrgnXKLM=usCQ@mail.gmail.com>
References: <CAA8ViV9-S_skfmrBMws8N6BCUkr9Uf6BoeLo3aLzpOgkSzt7Ew@mail.gmail.com>
 <1834a08e-7e03-cf08-0d15-e84ee63cd200@treenet.co.nz>
 <CAA8ViV8L-RW2jC0rcWpkB0JnxHtX2M5CB5ZVNU+vJzWxQOkjdw@mail.gmail.com>
 <8aaf4f0906db71e6d8bb7bab7624e473@tisiz72.ru>
 <CAA8ViV_sXRtBocFwFreuRG5oy_AwCb7qvQ1Np59XaggXkj68sA@mail.gmail.com>
 <CAA8ViV-5dEeCka1EfJ_MQYPh18PZAoO-okSEoTrgnXKLM=usCQ@mail.gmail.com>
Message-ID: <e468c276c47c21d8d588b3684a96e31e@tisiz72.ru>

I have the same config, but in my logs domain names 

Reet Vyas ????? 2016-05-17 15:48:

> Here is my txt file, as of now its working but I am getting secure connection failed, I want to know if we can customize error message like Access Denied . 
> 
> In logs I am not getting  full URL PFA logs for same. What I have to change  in peek and splice  ssl bump to get full URL ? 
> 
> Logs: 
> 
> 3481340.025      0 192.168.0.66 TAG_NONE/200 0 CONNECT 31.13.79.220:443 [1] - HIER_NONE/- - 
> 1463481340.037      0 192.168.0.66 TAG_NONE/200 0 CONNECT 31.13.79.220:443 [1] - HIER_NONE/- - 
> 1463481352.675  98653 192.168.0.11 TCP_TUNNEL/200 4567 CONNECT 74.125.68.100:443 [2] - ORIGINAL_DST/74.125.68.100 [3] - 
> 1463481403.492 240049 192.168.0.188 TCP_TUNNEL/200 244 CONNECT 216.58.199.133:443 [4] - ORIGINAL_DST/216.58.199.133 [5] - 
> 1463481403.519 240205 192.168.0.188 TCP_TUNNEL/200 244 CONNECT 74.125.130.189:443 [6] - ORIGINAL_DST/74.125.130.189 [7] - 
> 1463481411.577 240235 192.168.0.66 TCP_TUNNEL/200 1832 CONNECT 74.125.68.239:443 [8] - ORIGINAL_DST/74.125.68.239 [9] - 
> 1463481411.688 240430 192.168.0.66 TCP_TUNNEL/200 766 CONNECT 74.125.68.100:443 [2] - ORIGINAL_DST/74.125.68.100 [3] - 
> 1463481411.940 240038 192.168.0.66 TCP_TUNNEL/200 502 CONNECT 216.58.199.141:443 [10] - ORIGINAL_DST/216.58.199.141 [11] - 
> 1463481415.391 240029 192.168.0.66 TCP_TUNNEL/200 502 CONNECT 216.58.220.5:443 [12] - ORIGINAL_DST/216.58.220.5 [13] - 
> 1463481418.469 240252 192.168.0.66 TCP_TUNNEL/200 518 CONNECT 74.125.68.132:443 [14] - ORIGINAL_DST/74.125.68.132 [15] - 
> 1463481419.003 240197 192.168.0.66 TCP_TUNNEL/200 502 CONNECT 74.125.200.138:443 [16] - ORIGINAL_DST/74.125.200.138 [17] - 
> 1463481421.151 240041 192.168.0.66 TCP_TUNNEL/200 143096 CONNECT 216.58.199.131:443 [18] - ORIGINAL_DST/216.58.199.131 [19] - 
> 1463481421.196  59328 192.168.0.11 TCP_TUNNEL/200 786 CONNECT 216.58.199.142:443 [20] - ORIGINAL_DST/216.58.199.142 [21] - 
> 1463481421.758 240647 192.168.0.66 TCP_TUNNEL/200 464 CONNECT 216.58.199.131:443 [18] - ORIGINAL_DST/216.58.199.131 [19] - 
> 1463481445.844 282774 192.168.0.188 TCP_TUNNEL/200 1423 CONNECT 74.125.130.189:443 [6] - ORIGINAL_DST/74.125.130.189 [7] - 
> 1463481446.091 282893 192.168.0.188 TCP_TUNNEL/200 2418 CONNECT 216.58.199.133:443 [4] - ORIGINAL_DST/216.58.199.133 [5] - 
> 1463481470.715  59069 192.168.0.11 TCP_TUNNEL/200 1395 CONNECT 216.58.199.206:443 [22] - ORIGINAL_DST/216.58.199.206 [23] - 
> 1463481470.729  58778 192.168.0.11 TCP_TUNNEL/200 7609 CONNECT 216.58.199.206:443 [22] - ORIGINAL_DST/216.58.199.206 [23] - 
> 1463481482.663  62472 192.168.0.11 TCP_TUNNEL/200 3000 CONNECT 216.58.199.165:443 [24] - ORIGINAL_DST/216.58.199.165 [25] - 
> 1463481505.775 334542 192.168.0.66 TCP_TUNNEL/200 59071 CONNECT 216.58.199.131:443 [18] - ORIGINAL_DST/216.58.199.131 [19] - 
> 1463481512.946 240206 192.168.0.66 TCP_TUNNEL/200 470 CONNECT 74.125.130.101:443 [26] - ORIGINAL_DST/74.125.130.101 [27] - 
> 1463481513.057 240084 192.168.0.66 TCP_TUNNEL/200 886 CONNECT 216.58.199.142:443 [20] - ORIGINAL_DST/216.58.199.142 [21] - 
> 1463481513.574 240132 192.168.0.66 TCP_TUNNEL/200 1116 CONNECT 216.58.199.142:443 [20] - ORIGINAL_DST/216.58.199.142 [21] - 
> 1463481514.156 240036 192.168.0.66 TCP_TUNNEL/200 454 CONNECT 216.58.199.129:443 [28] - ORIGINAL_DST/216.58.199.129 [29] - 
> 1463481542.096   5675 192.168.0.11 TCP_TUNNEL/200 686 CONNECT 162.213.33.48:443 [30] - ORIGINAL_DST/162.213.33.48 [31] - 
> 1463481546.586  59549 192.168.0.11 TCP_TUNNEL/200 493 CONNECT 216.58.199.131:443 [18] - ORIGINAL_DST/216.58.199.131 [19] - 
> 1463481569.729 398494 192.168.0.66 TCP_TUNNEL/200 2523 CONNECT 216.58.199.142:443 [20] - ORIGINAL_DST/216.58.199.142 [21] - 
> 1463481574.930 240032 192.168.0.66 TCP_TUNNEL/200 464 CONNECT 216.58.220.3:443 [32] - ORIGINAL_DST/216.58.220.3 [33] - 
> 1463481578.959 240248 192.168.0.66 TCP_TUNNEL/200 1220 CONNECT 74.125.130.94:443 [34] - ORIGINAL_DST/74.125.130.94 [35] - 
> 1463481614.460 444470 192.168.0.66 TCP_TUNNEL/200 13976 CONNECT 216.58.199.133:443 [4] - ORIGINAL_DST/216.58.199.133 [5] - 
> 1463481631.174 460024 192.168.0.66 TCP_TUNNEL/200 5641 CONNECT 74.125.200.189:443 [36] - ORIGINAL_DST/74.125.200.189 [37] - 
> 1463481753.303 303648 192.168.0.11 TCP_TUNNEL/200 2801 CONNECT 216.58.199.142:443 [20] - ORIGINAL_DST/216.58.199.142 [21] - 
> 1463481759.694 240237 192.168.0.11 TCP_TUNNEL/200 829 CONNECT 216.58.199.206:443 [22] - ORIGINAL_DST/216.58.199.206 [23] - 
> 1463481761.126 261752 192.168.0.11 TCP_TUNNEL/200 205262 CONNECT 216.58.199.129:443 [28] - ORIGINAL_DST/216.58.199.129 [29] - 
> 1463481762.066 269470 192.168.0.11 TCP_TUNNEL/200 177618 CONNECT 216.58.199.129:443 [28] - ORIGINAL_DST/216.58.199.129 [29] - 
> 1463481762.241 276758 192.168.0.11 TCP_TUNNEL/200 1451680 CONNECT 216.58.199.165:443 [24] - ORIGINAL_DST/216.58.199.16 [38] 
> 
> On Tue, May 17, 2016 at 3:33 PM, Reet Vyas <reet.vyas28 at gmail.com> wrote:
> 
> Here is my txt file, as of now its working but I am getting secure connection failed, I want to know if we can customize error message like Access Denied . 
> 
> In logs I am not getting  full URL PFA logs for same. What I have to change  in peek and splice  ssl bump to get full URL ? 
> 
> On Tue, May 17, 2016 at 3:21 PM, admin <admin at tisiz72.ru> wrote:
> 
> get your blocked_https.txt 
> 
> Reet Vyas ????? 2016-05-17 14:47:
> 
> Hi 
> 
> Below is my squid configuration  
> 
> Squid : 3.5.13 
> OS ubuntu 14.04 
> 
> http_port 3128 
> http_port 3127 intercept 
> https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_certs/squid.crt key=/etc/squid/ssl_certs/squid.key cipher=ECDHE-RSA-RC4-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES128-SHA:DHE-RSA-CAMELLIA128-SHA:AES128-SHA:RC4-SHA:HIGH:!aNULL:!MD5:!ADH 
> 
> always_direct allow all 
> sslproxy_cert_error allow all 
> sslproxy_flags DONT_VERIFY_PEER 
> acl blocked ssl::server_name  "/etc/squid/blocked_https.txt" 
> acl step1 at_step SslBump1 
> ssl_bump peek step1 
> ssl_bump terminate blocked 
> ssl_bump splice all 
> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB 
> sslcrtd_children 16 startup=1 idle=1 
> sslproxy_capath /etc/ssl/certs 
> sslproxy_cert_error allow all 
> ssl_unclean_shutdown on 
> 
> I want to block facebook.com [39] so I have added url in .txt file. 
> 
> Its not blocking anything. 
> 
> Please let me know what I have to change in this configuration 
> 
> I getting below logs in squid 
> 
> 1463478160.585    551 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443 [40] - HIER_NONE/- - 
> 1463478160.585    550 192.168.0.66 TAG_NONE/503 0 CONNECT freevideodownloader.co:443 [41] - HIER_NONE/- - 
> 1463478161.147    562 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443 [40] - HIER_NONE/- - 
> 1463478161.147    561 192.168.0.66 TAG_NONE/503 0 CONNECT freevideodownloader.co:443 [41] - HIER_NONE/- - 
> 1463478163.982    553 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443 [40] - HIER_NONE/- - 
> 1463478163.982    552 192.168.0.66 TAG_NONE/503 0 CONNECT freevideodownloader.co:443 [41] - HIER_NONE/- - 
> 1463478163.994    565 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443 [40] - HIER_NONE/- - 
> 1463478163.994    564 192.168.0.66 TAG_NONE/503 0 CONNECT freevideodownloader.co:443 [41] - HIER_NONE/- - 
> 1463478184.338 182900 192.168.0.66 TAG_NONE/200 0 CONNECT 106.10.137.175:443 [42] - HIER_NONE/- - 
> 1463478184.338 182898 192.168.0.66 TCP_TUNNEL/200 6040 CONNECT geo.query.yahoo.com:443 [43] - ORIGINAL_DST/106.10.137.175 [44] - 
> 
> 1463478194.373     61 192.168.0.66 TCP_MISS/204 233 GET http://www.gstatic.com/generate_204 - ORIGINAL_DST/216.58.199.163 [45] - 
> 1463478209.166 240232 192.168.0.66 TAG_NONE/200 0 CONNECT 74.125.200.239:443 [46] - HIER_NONE/- - 
> 1463478209.166 240231 192.168.0.66 TCP_TUNNEL/200 5603 CONNECT translate.googleapis.com:443 [47] - ORIGINAL_DST/74.125.200.239 [48] - 
> 1463478209.200 240267 192.168.0.66 TAG_NONE/200 0 CONNECT 216.58.199.142:443 [20] - HIER_NONE/- - 
> 1463478209.200 240266 192.168.0.66 TCP_TUNNEL/200 4962 CONNECT clients4.google.com:443 [49] - ORIGINAL_DST/216.58.199.142 [21] - 
> 1463478213.443 181611 192.168.0.66 TAG_NONE/200 0 CONNECT 31.13.79.246:443 [50] - HIER_NONE/- - 
> 1463478213.443 181611 192.168.0.66 TCP_TUNNEL/200 8547 CONNECT graph.facebook.com:443 [51] - ORIGINAL_DST/31.13.79.246 [52] - 
> 1463478224.432     33 192.168.0.66 TCP_MISS/204 233 GET http://www.gstatic.com/generate_204 - ORIGINAL_DST/216.58.199.131 [19] - 
> 1463478231.727    555 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443 [40] - HIER_NONE/- - 
> 1463478231.727    555 192.168.0.66 TAG_NONE/503 0 CONNECT freevideodownloader.co:443 [41] - HIER_NONE/- - 
> 1463478232.311    572 192.168.0.66 TAG_NONE/200 0 CONNECT 107.170.47.181:443 [40] - HIER_NONE/- - 
> 1463478232.311    571 192.168.0.66 TAG_NONE/503 0 CONNECT freevideodownloader.co:443 [41] - HIER_NONE/- - 
> 1463478246.369  13073 192.168.0.66 TAG_NONE/200 0 CONNECT 74.125.200.189:443 [36] - HIER_NONE/- - 
> 1463478246.369  13072 192.168.0.66 TCP_TUNNEL/200 4546 CONNECT 0.client-channel.google.com:443 [53] - ORIGINAL_DST/74.125.200.189 [37] - 
> 1463478246.369  13806 192.168.0.66 TAG_NONE/200 0 CONNECT 216.58.199.142:443 [20] - HIER_NONE/- - 
> 1463478246.369  13805 192.168.0.66 TCP_TUNNEL/200 4604 CONNECT clients5.google.com:443 [54] - ORIGINAL_DST/216.58.199.142 [21] - 
> 1463478265.935 119576 192.168.0.66 TAG_NONE/200 0 CONNECT 106.10.199.11:443 [55] - HIER_NONE/- - 
> 1463478265.935 119576 192.168.0.66 TCP_TUNNEL/200 8586 CONNECT geo.yahoo.com:443 [56] - ORIGINAL_DST/106.10.199.11 [57] - 
> 1463478327.555     41 192.168.0.66 TCP_MISS/200 2323 GET http://www.gstatic.com/chrome/crlset/3006/crl-set-delta-3005-260733898557562236.crx.data - ORIGINAL_DST/216.58.220.3 [33] text/html 
> 
> On Fri, May 13, 2016 at 4:37 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 13/05/2016 5:58 p.m., Reet Vyas wrote:
>> Hi Amos/Yuri,
>> 
>> Currently my squid is configured with ssl bump, now I want to use peek and
>> splice. I read in some forum that we don't need to install certificate on
>> client's machine.
>> 
> 
> Splice does not require it. But what you want to do with Squid may
> prevent splice being used. So "it depends" ...
> 
>> As I have already asked before in mailing list to install SSL certificate
>> on Android devices, which is not working.
>> 
>> So my question is If I want to use peek and splice for example I want https
>> filtering for
> 
> ... on how you define "filter".
> 
>> proxy websites
> 
> Not sure what you mean by that term.
> 
>> and I dont want ssl for bank websites and
>> facebook youtube and gmail. how will it work? Do i need to install SSL
>> certifcate on client or not, I am bit confused with peek and splice thing.
> 
> When you intercept port 443 normally only the raw-IP is available from
> TCP. Peek allows Squid to get the server name the client was trying to
> connect to out of the TLS. So that Squid can handle the intercepted
> connection as if it had received a CONNECT message (which usually have
> server/domain names).
> 
> Splicing can be thought of as handling a intercepted port 443 connection
> as if it were a CONNECT message, with no decryption. It is treated as a
> single "thing", with some limited control possibilities.
> 
> So...
> 
> In order to bump (decrypt) some traffic and splice (not decrypt) other
> traffic you need to have a way to decide which type is being dealt with.
> That is the peek or stare actions - to get data out of the TLS handshake
> for you to use in ACL decisions.
> 
> You might now want to re-read the SslPeekAndSplice documentation again
> to see if you understand it better. I skipped a lot of important details
> to make the description clear.
> 
>> 
>> Please let me know is that possible to configure squid 3.5.19 in such a way
>> so that it will bump  only proxy websites not FB youtube etc.
>> 
> 
> Ah. So what are these "proxy websites" you speak of ?
> 
> One thing you need to be clear about is that once the TCP packets enter
> Squid they *have* to be "proxied". There is no way to undo TCP accept()
> and read() operations. But there are many ways of handling them that
> Squid can do.
> 
> PS. you could post your existing config so we can suggest alterations to
> it that will lead to it doing your new policy. That can be another way
> to learn how the relevant-to-you part of the features work without
> diving into the full complexity of what *might* be doable.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 

Links:
------
[1] http://31.13.79.220:443
[2] http://74.125.68.100:443
[3] http://74.125.68.100
[4] http://216.58.199.133:443
[5] http://216.58.199.133
[6] http://74.125.130.189:443
[7] http://74.125.130.189
[8] http://74.125.68.239:443
[9] http://74.125.68.239
[10] http://216.58.199.141:443
[11] http://216.58.199.141
[12] http://216.58.220.5:443
[13] http://216.58.220.5
[14] http://74.125.68.132:443
[15] http://74.125.68.132
[16] http://74.125.200.138:443
[17] http://74.125.200.138
[18] http://216.58.199.131:443
[19] http://216.58.199.131
[20] http://216.58.199.142:443
[21] http://216.58.199.142
[22] http://216.58.199.206:443
[23] http://216.58.199.206
[24] http://216.58.199.165:443
[25] http://216.58.199.165
[26] http://74.125.130.101:443
[27] http://74.125.130.101
[28] http://216.58.199.129:443
[29] http://216.58.199.129
[30] http://162.213.33.48:443
[31] http://162.213.33.48
[32] http://216.58.220.3:443
[33] http://216.58.220.3
[34] http://74.125.130.94:443
[35] http://74.125.130.94
[36] http://74.125.200.189:443
[37] http://74.125.200.189
[38] http://216.58.199.16
[39] http://facebook.com
[40] http://107.170.47.181:443
[41] http://freevideodownloader.co:443
[42] http://106.10.137.175:443
[43] http://geo.query.yahoo.com:443
[44] http://106.10.137.175
[45] http://216.58.199.163
[46] http://74.125.200.239:443
[47] http://translate.googleapis.com:443
[48] http://74.125.200.239
[49] http://clients4.google.com:443
[50] http://31.13.79.246:443
[51] http://graph.facebook.com:443
[52] http://31.13.79.246
[53] http://0.client-channel.google.com:443
[54] http://clients5.google.com:443
[55] http://106.10.199.11:443
[56] http://geo.yahoo.com:443
[57] http://106.10.199.11
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160517/f9a570f4/attachment.htm>

From reet.vyas28 at gmail.com  Tue May 17 10:56:00 2016
From: reet.vyas28 at gmail.com (Reet Vyas)
Date: Tue, 17 May 2016 16:26:00 +0530
Subject: [squid-users] Squid Peek and splice
In-Reply-To: <e468c276c47c21d8d588b3684a96e31e@tisiz72.ru>
References: <CAA8ViV9-S_skfmrBMws8N6BCUkr9Uf6BoeLo3aLzpOgkSzt7Ew@mail.gmail.com>
 <1834a08e-7e03-cf08-0d15-e84ee63cd200@treenet.co.nz>
 <CAA8ViV8L-RW2jC0rcWpkB0JnxHtX2M5CB5ZVNU+vJzWxQOkjdw@mail.gmail.com>
 <8aaf4f0906db71e6d8bb7bab7624e473@tisiz72.ru>
 <CAA8ViV_sXRtBocFwFreuRG5oy_AwCb7qvQ1Np59XaggXkj68sA@mail.gmail.com>
 <CAA8ViV-5dEeCka1EfJ_MQYPh18PZAoO-okSEoTrgnXKLM=usCQ@mail.gmail.com>
 <e468c276c47c21d8d588b3684a96e31e@tisiz72.ru>
Message-ID: <CAA8ViV-u4OC6H=Hrq4LgVT8QmLk6J91mOfNNZVVQxGBz2gVxYw@mail.gmail.com>

I have installed squid as my router and below are my iptable rules

 675 39972 DNAT       tcp  --  eth1   *       0.0.0.0/0            0.0.0.0/0
           tcp dpt:80 to:192.168.0.200:3127
    0     0 REDIRECT   tcp  --  eth0   *       0.0.0.0/0
0.0.0.0/0            tcp dpt:80 redir ports 3127
    0     0 REDIRECT   tcp  --  eth0   *       0.0.0.0/0
0.0.0.0/0            tcp dpt:443 redir ports 3129
 2022  120K DNAT       tcp  --  eth1   *       0.0.0.0/0
0.0.0.0/0            tcp dpt:443 to:192.168.0.200:3129

Chain INPUT (policy ACCEPT 7028 packets, 770K bytes)
 pkts bytes target     prot opt in     out     source
destination

Chain OUTPUT (policy ACCEPT 2317 packets, 146K bytes)
 pkts bytes target     prot opt in     out     source
destination

Chain POSTROUTING (policy ACCEPT 2317 packets, 146K bytes)
 pkts bytes target     prot opt in     out     source
destination
 5923  688K MASQUERADE  all  --  *      eth0    192.168.0.0/24
0.0.0.0/0


On Tue, May 17, 2016 at 4:21 PM, admin <admin at tisiz72.ru> wrote:

> I have the same config, but in my logs domain names
>
>
>
>
>
>
> Reet Vyas ????? 2016-05-17 15:48:
>
> Here is my txt file, as of now its working but I am getting secure
> connection failed, I want to know if we can customize error message like
> Access Denied .
>
> In logs I am not getting  full URL PFA logs for same. What I have to
> change  in peek and splice  ssl bump to get full URL ?
>
> Logs:
>
> 3481340.025      0 192.168.0.66 TAG_NONE/200 0 CONNECT 31.13.79.220:443 -
> HIER_NONE/- -
> 1463481340.037      0 192.168.0.66 TAG_NONE/200 0 CONNECT 31.13.79.220:443
> - HIER_NONE/- -
> 1463481352.675  98653 192.168.0.11 TCP_TUNNEL/200 4567 CONNECT
> 74.125.68.100:443 - ORIGINAL_DST/74.125.68.100 -
> 1463481403.492 240049 192.168.0.188 TCP_TUNNEL/200 244 CONNECT
> 216.58.199.133:443 - ORIGINAL_DST/216.58.199.133 -
> 1463481403.519 240205 192.168.0.188 TCP_TUNNEL/200 244 CONNECT
> 74.125.130.189:443 - ORIGINAL_DST/74.125.130.189 -
> 1463481411.577 240235 192.168.0.66 TCP_TUNNEL/200 1832 CONNECT
> 74.125.68.239:443 - ORIGINAL_DST/74.125.68.239 -
> 1463481411.688 240430 192.168.0.66 TCP_TUNNEL/200 766 CONNECT
> 74.125.68.100:443 - ORIGINAL_DST/74.125.68.100 -
> 1463481411.940 240038 192.168.0.66 TCP_TUNNEL/200 502 CONNECT
> 216.58.199.141:443 - ORIGINAL_DST/216.58.199.141 -
> 1463481415.391 240029 192.168.0.66 TCP_TUNNEL/200 502 CONNECT
> 216.58.220.5:443 - ORIGINAL_DST/216.58.220.5 -
> 1463481418.469 240252 192.168.0.66 TCP_TUNNEL/200 518 CONNECT
> 74.125.68.132:443 - ORIGINAL_DST/74.125.68.132 -
> 1463481419.003 240197 192.168.0.66 TCP_TUNNEL/200 502 CONNECT
> 74.125.200.138:443 - ORIGINAL_DST/74.125.200.138 -
> 1463481421.151 240041 192.168.0.66 TCP_TUNNEL/200 143096 CONNECT
> 216.58.199.131:443 - ORIGINAL_DST/216.58.199.131 -
> 1463481421.196  59328 192.168.0.11 TCP_TUNNEL/200 786 CONNECT
> 216.58.199.142:443 - ORIGINAL_DST/216.58.199.142 -
> 1463481421.758 240647 192.168.0.66 TCP_TUNNEL/200 464 CONNECT
> 216.58.199.131:443 - ORIGINAL_DST/216.58.199.131 -
> 1463481445.844 282774 192.168.0.188 TCP_TUNNEL/200 1423 CONNECT
> 74.125.130.189:443 - ORIGINAL_DST/74.125.130.189 -
> 1463481446.091 282893 192.168.0.188 TCP_TUNNEL/200 2418 CONNECT
> 216.58.199.133:443 - ORIGINAL_DST/216.58.199.133 -
> 1463481470.715  59069 192.168.0.11 TCP_TUNNEL/200 1395 CONNECT
> 216.58.199.206:443 - ORIGINAL_DST/216.58.199.206 -
> 1463481470.729  58778 192.168.0.11 TCP_TUNNEL/200 7609 CONNECT
> 216.58.199.206:443 - ORIGINAL_DST/216.58.199.206 -
> 1463481482.663  62472 192.168.0.11 TCP_TUNNEL/200 3000 CONNECT
> 216.58.199.165:443 - ORIGINAL_DST/216.58.199.165 -
> 1463481505.775 334542 192.168.0.66 TCP_TUNNEL/200 59071 CONNECT
> 216.58.199.131:443 - ORIGINAL_DST/216.58.199.131 -
> 1463481512.946 240206 192.168.0.66 TCP_TUNNEL/200 470 CONNECT
> 74.125.130.101:443 - ORIGINAL_DST/74.125.130.101 -
> 1463481513.057 240084 192.168.0.66 TCP_TUNNEL/200 886 CONNECT
> 216.58.199.142:443 - ORIGINAL_DST/216.58.199.142 -
> 1463481513.574 240132 192.168.0.66 TCP_TUNNEL/200 1116 CONNECT
> 216.58.199.142:443 - ORIGINAL_DST/216.58.199.142 -
> 1463481514.156 240036 192.168.0.66 TCP_TUNNEL/200 454 CONNECT
> 216.58.199.129:443 - ORIGINAL_DST/216.58.199.129 -
> 1463481542.096   5675 192.168.0.11 TCP_TUNNEL/200 686 CONNECT
> 162.213.33.48:443 - ORIGINAL_DST/162.213.33.48 -
> 1463481546.586  59549 192.168.0.11 TCP_TUNNEL/200 493 CONNECT
> 216.58.199.131:443 - ORIGINAL_DST/216.58.199.131 -
> 1463481569.729 398494 192.168.0.66 TCP_TUNNEL/200 2523 CONNECT
> 216.58.199.142:443 - ORIGINAL_DST/216.58.199.142 -
> 1463481574.930 240032 192.168.0.66 TCP_TUNNEL/200 464 CONNECT
> 216.58.220.3:443 - ORIGINAL_DST/216.58.220.3 -
> 1463481578.959 240248 192.168.0.66 TCP_TUNNEL/200 1220 CONNECT
> 74.125.130.94:443 - ORIGINAL_DST/74.125.130.94 -
> 1463481614.460 444470 192.168.0.66 TCP_TUNNEL/200 13976 CONNECT
> 216.58.199.133:443 - ORIGINAL_DST/216.58.199.133 -
> 1463481631.174 460024 192.168.0.66 TCP_TUNNEL/200 5641 CONNECT
> 74.125.200.189:443 - ORIGINAL_DST/74.125.200.189 -
> 1463481753.303 303648 192.168.0.11 TCP_TUNNEL/200 2801 CONNECT
> 216.58.199.142:443 - ORIGINAL_DST/216.58.199.142 -
> 1463481759.694 240237 192.168.0.11 TCP_TUNNEL/200 829 CONNECT
> 216.58.199.206:443 - ORIGINAL_DST/216.58.199.206 -
> 1463481761.126 261752 192.168.0.11 TCP_TUNNEL/200 205262 CONNECT
> 216.58.199.129:443 - ORIGINAL_DST/216.58.199.129 -
> 1463481762.066 269470 192.168.0.11 TCP_TUNNEL/200 177618 CONNECT
> 216.58.199.129:443 - ORIGINAL_DST/216.58.199.129 -
> 1463481762.241 276758 192.168.0.11 TCP_TUNNEL/200 1451680 CONNECT
> 216.58.199.165:443 - ORIGINAL_DST/216.58.199.16
>
>
>
>
>
> On Tue, May 17, 2016 at 3:33 PM, Reet Vyas <reet.vyas28 at gmail.com> wrote:
>
>> Here is my txt file, as of now its working but I am getting secure
>> connection failed, I want to know if we can customize error message like
>> Access Denied .
>>
>> In logs I am not getting  full URL PFA logs for same. What I have to
>> change  in peek and splice  ssl bump to get full URL ?
>>
>> On Tue, May 17, 2016 at 3:21 PM, admin <admin at tisiz72.ru> wrote:
>>
>>>
>>>
>>> get your blocked_https.txt
>>>
>>>
>>>
>>>
>>> Reet Vyas ????? 2016-05-17 14:47:
>>>
>>> Hi
>>>
>>> Below is my squid configuration
>>>
>>> Squid : 3.5.13
>>> OS ubuntu 14.04
>>>
>>>
>>> http_port 3128
>>> http_port 3127 intercept
>>> https_port 3129 intercept ssl-bump generate-host-certificates=on
>>> dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_certs/squid.crt
>>> key=/etc/squid/ssl_certs/squid.key
>>> cipher=ECDHE-RSA-RC4-SHA:ECDHE-RSA-AES128-SHA:DHE-RSA-AES128-SHA:DHE-RSA-CAMELLIA128-SHA:AES128-SHA:RC4-SHA:HIGH:!aNULL:!MD5:!ADH
>>>
>>> always_direct allow all
>>> sslproxy_cert_error allow all
>>> sslproxy_flags DONT_VERIFY_PEER
>>> acl blocked ssl::server_name  "/etc/squid/blocked_https.txt"
>>> acl step1 at_step SslBump1
>>> ssl_bump peek step1
>>> ssl_bump terminate blocked
>>> ssl_bump splice all
>>> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB
>>> sslcrtd_children 16 startup=1 idle=1
>>> sslproxy_capath /etc/ssl/certs
>>> sslproxy_cert_error allow all
>>> ssl_unclean_shutdown on
>>>
>>> I want to block facebook.com so I have added url in .txt file.
>>>
>>> Its not blocking anything.
>>>
>>> Please let me know what I have to change in this configuration
>>>
>>> I getting below logs in squid
>>>
>>>
>>> 1463478160.585    551 192.168.0.66 TAG_NONE/200 0 CONNECT
>>> 107.170.47.181:443 - HIER_NONE/- -
>>> 1463478160.585    550 192.168.0.66 TAG_NONE/503 0 CONNECT
>>> freevideodownloader.co:443 - HIER_NONE/- -
>>> 1463478161.147    562 192.168.0.66 TAG_NONE/200 0 CONNECT
>>> 107.170.47.181:443 - HIER_NONE/- -
>>> 1463478161.147    561 192.168.0.66 TAG_NONE/503 0 CONNECT
>>> freevideodownloader.co:443 - HIER_NONE/- -
>>> 1463478163.982    553 192.168.0.66 TAG_NONE/200 0 CONNECT
>>> 107.170.47.181:443 - HIER_NONE/- -
>>> 1463478163.982    552 192.168.0.66 TAG_NONE/503 0 CONNECT
>>> freevideodownloader.co:443 - HIER_NONE/- -
>>> 1463478163.994    565 192.168.0.66 TAG_NONE/200 0 CONNECT
>>> 107.170.47.181:443 - HIER_NONE/- -
>>> 1463478163.994    564 192.168.0.66 TAG_NONE/503 0 CONNECT
>>> freevideodownloader.co:443 - HIER_NONE/- -
>>> 1463478184.338 182900 192.168.0.66 TAG_NONE/200 0 CONNECT
>>> 106.10.137.175:443 - HIER_NONE/- -
>>> 1463478184.338 182898 192.168.0.66 TCP_TUNNEL/200 6040 CONNECT
>>> geo.query.yahoo.com:443 - ORIGINAL_DST/106.10.137.175 -
>>>
>>>
>>> 1463478194.373     61 192.168.0.66 TCP_MISS/204 233 GET
>>> http://www.gstatic.com/generate_204 - ORIGINAL_DST/216.58.199.163 -
>>> 1463478209.166 240232 192.168.0.66 TAG_NONE/200 0 CONNECT
>>> 74.125.200.239:443 - HIER_NONE/- -
>>> 1463478209.166 240231 192.168.0.66 TCP_TUNNEL/200 5603 CONNECT
>>> translate.googleapis.com:443 - ORIGINAL_DST/74.125.200.239 -
>>> 1463478209.200 240267 192.168.0.66 TAG_NONE/200 0 CONNECT
>>> 216.58.199.142:443 - HIER_NONE/- -
>>> 1463478209.200 240266 192.168.0.66 TCP_TUNNEL/200 4962 CONNECT
>>> clients4.google.com:443 - ORIGINAL_DST/216.58.199.142 -
>>> 1463478213.443 181611 192.168.0.66 TAG_NONE/200 0 CONNECT
>>> 31.13.79.246:443 - HIER_NONE/- -
>>> 1463478213.443 181611 192.168.0.66 TCP_TUNNEL/200 8547 CONNECT
>>> graph.facebook.com:443 - ORIGINAL_DST/31.13.79.246 -
>>> 1463478224.432     33 192.168.0.66 TCP_MISS/204 233 GET
>>> http://www.gstatic.com/generate_204 - ORIGINAL_DST/216.58.199.131 -
>>> 1463478231.727    555 192.168.0.66 TAG_NONE/200 0 CONNECT
>>> 107.170.47.181:443 - HIER_NONE/- -
>>> 1463478231.727    555 192.168.0.66 TAG_NONE/503 0 CONNECT
>>> freevideodownloader.co:443 - HIER_NONE/- -
>>> 1463478232.311    572 192.168.0.66 TAG_NONE/200 0 CONNECT
>>> 107.170.47.181:443 - HIER_NONE/- -
>>> 1463478232.311    571 192.168.0.66 TAG_NONE/503 0 CONNECT
>>> freevideodownloader.co:443 - HIER_NONE/- -
>>> 1463478246.369  13073 192.168.0.66 TAG_NONE/200 0 CONNECT
>>> 74.125.200.189:443 - HIER_NONE/- -
>>> 1463478246.369  13072 192.168.0.66 TCP_TUNNEL/200 4546 CONNECT
>>> 0.client-channel.google.com:443 - ORIGINAL_DST/74.125.200.189 -
>>> 1463478246.369  13806 192.168.0.66 TAG_NONE/200 0 CONNECT
>>> 216.58.199.142:443 - HIER_NONE/- -
>>> 1463478246.369  13805 192.168.0.66 TCP_TUNNEL/200 4604 CONNECT
>>> clients5.google.com:443 - ORIGINAL_DST/216.58.199.142 -
>>> 1463478265.935 119576 192.168.0.66 TAG_NONE/200 0 CONNECT
>>> 106.10.199.11:443 - HIER_NONE/- -
>>> 1463478265.935 119576 192.168.0.66 TCP_TUNNEL/200 8586 CONNECT
>>> geo.yahoo.com:443 - ORIGINAL_DST/106.10.199.11 -
>>> 1463478327.555     41 192.168.0.66 TCP_MISS/200 2323 GET
>>> http://www.gstatic.com/chrome/crlset/3006/crl-set-delta-3005-260733898557562236.crx.data
>>> - ORIGINAL_DST/216.58.220.3 text/html
>>>
>>>
>>> On Fri, May 13, 2016 at 4:37 PM, Amos Jeffries <squid3 at treenet.co.nz>
>>> wrote:
>>>
>>>> On 13/05/2016 5:58 p.m., Reet Vyas wrote:
>>>> > Hi Amos/Yuri,
>>>> >
>>>> > Currently my squid is configured with ssl bump, now I want to use
>>>> peek and
>>>> > splice. I read in some forum that we don't need to install
>>>> certificate on
>>>> > client's machine.
>>>> >
>>>>
>>>> Splice does not require it. But what you want to do with Squid may
>>>> prevent splice being used. So "it depends" ...
>>>>
>>>>
>>>> > As I have already asked before in mailing list to install SSL
>>>> certificate
>>>> > on Android devices, which is not working.
>>>> >
>>>> > So my question is If I want to use peek and splice for example I want
>>>> https
>>>> > filtering for
>>>>
>>>>  ... on how you define "filter".
>>>>
>>>> > proxy websites
>>>>
>>>> Not sure what you mean by that term.
>>>>
>>>> > and I dont want ssl for bank websites and
>>>> > facebook youtube and gmail. how will it work? Do i need to install SSL
>>>> > certifcate on client or not, I am bit confused with peek and splice
>>>> thing.
>>>>
>>>> When you intercept port 443 normally only the raw-IP is available from
>>>> TCP. Peek allows Squid to get the server name the client was trying to
>>>> connect to out of the TLS. So that Squid can handle the intercepted
>>>> connection as if it had received a CONNECT message (which usually have
>>>> server/domain names).
>>>>
>>>> Splicing can be thought of as handling a intercepted port 443 connection
>>>> as if it were a CONNECT message, with no decryption. It is treated as a
>>>> single "thing", with some limited control possibilities.
>>>>
>>>>
>>>> So...
>>>>
>>>> In order to bump (decrypt) some traffic and splice (not decrypt) other
>>>> traffic you need to have a way to decide which type is being dealt with.
>>>> That is the peek or stare actions - to get data out of the TLS handshake
>>>> for you to use in ACL decisions.
>>>>
>>>> You might now want to re-read the SslPeekAndSplice documentation again
>>>> to see if you understand it better. I skipped a lot of important details
>>>> to make the description clear.
>>>>
>>>>
>>>> >
>>>> > Please let me know is that possible to configure squid 3.5.19 in such
>>>> a way
>>>> > so that it will bump  only proxy websites not FB youtube etc.
>>>> >
>>>>
>>>> Ah. So what are these "proxy websites" you speak of ?
>>>>
>>>> One thing you need to be clear about is that once the TCP packets enter
>>>> Squid they *have* to be "proxied". There is no way to undo TCP accept()
>>>> and read() operations. But there are many ways of handling them that
>>>> Squid can do.
>>>>
>>>> PS. you could post your existing config so we can suggest alterations to
>>>> it that will lead to it doing your new policy. That can be another way
>>>> to learn how the relevant-to-you part of the features work without
>>>> diving into the full complexity of what *might* be doable.
>>>>
>>>> Amos
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160517/cb951a2d/attachment.htm>

From squid3 at treenet.co.nz  Tue May 17 14:10:50 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 18 May 2016 02:10:50 +1200
Subject: [squid-users] Squid unable to send full PNG file
In-Reply-To: <CAO4ouAZZRjR1n+i-7k158eeu8CEUKAviF560WrzU+N7fTdPFGg@mail.gmail.com>
References: <CAO4ouAZZRjR1n+i-7k158eeu8CEUKAviF560WrzU+N7fTdPFGg@mail.gmail.com>
Message-ID: <2fafe3c2-1250-70d0-bc9e-9898d011e955@treenet.co.nz>

On 17/05/2016 8:23 a.m., Aashima Madaan wrote:
> Hi,
> 
> I have a PNG file uploaded on server.
> As part of Download process, it passes through SQUID to another server for
> scanning and then to Client .
> 
> When I send request to Download , the response sends only 27kb of image
> back from server of of 700kb file
> 
> But when I turn off the respmod in squid.conf file
> 
> #adaptation_access service_resp allow all
> 
> The client gets full file. This is happening only with PNG files. Did
> anyone encounter this kind of issue and has suggestions in this case?

Can you tell if Squid actually has more than 27KB of the object received
back from ICAP service?
 If now there is your answer, Squid cannot deliver more than it has.

Amos



From squid3 at treenet.co.nz  Tue May 17 14:14:08 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 18 May 2016 02:14:08 +1200
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZyz7W4+x7_c9iPPZCwKzPVxP+sH6-Bv1zKh63t5byNnG7g@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
 <51d8f7ad-29c8-2f00-6b83-4483b637ef56@gmail.com>
 <CANUpZyyRbNR938ZHpYe2d2XCACcxepjcH6auX++E6MOwMve4cA@mail.gmail.com>
 <01d601d1aafe$8b230c00$a1692400$@ngtech.co.il>
 <cc65f5ea-20a6-9dcc-6aac-f5057df161a1@gmail.com>
 <CANUpZyzsq8UCOdsom_GBG84VOr3cYyzNpcaLxeLw-_cHg=GrzQ@mail.gmail.com>
 <CANUpZyz7W4+x7_c9iPPZCwKzPVxP+sH6-Bv1zKh63t5byNnG7g@mail.gmail.com>
Message-ID: <16136e86-e249-f0d9-ab32-b5a592855ffe@treenet.co.nz>

On 17/05/2016 6:37 a.m., J Green wrote:
> Re logging, does this eventually get logged by Squid, somewhere?
> 

I assume by "this" you mean the TOS values?

There are the %>qos and %<qos logformat codes in Squid-3.4 and later.

Amos


From maile.halatuituia at tcc.to  Tue May 17 19:44:21 2016
From: maile.halatuituia at tcc.to (Maile Halatuituia)
Date: Tue, 17 May 2016 19:44:21 +0000
Subject: [squid-users] Squid unable to send full PNG file
In-Reply-To: <2fafe3c2-1250-70d0-bc9e-9898d011e955@treenet.co.nz>
References: <CAO4ouAZZRjR1n+i-7k158eeu8CEUKAviF560WrzU+N7fTdPFGg@mail.gmail.com>,
 <2fafe3c2-1250-70d0-bc9e-9898d011e955@treenet.co.nz>
Message-ID: <12c08020e6d04800a3a96fd1ddba8769@mail.tcc.to>

Yuri/Amos
I have a situation. I suspect it is my gre tunnel idle time or something but not sure. Every time like after 6 hrs, 4hrs it's not constant but after sometime i have to tear down the tunnel and re established it again in order for packet to be redirected from the router , at the same time i see with the ip wccp command that packets are being redirected but it does not reflect on wccp0 interface on the squid box when use ifconfig. I hope i  expalin it clear ...
thanks in advance
________________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Amos Jeffries <squid3 at treenet.co.nz>
Sent: Wednesday, May 18, 2016 3:10 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid unable to send full PNG file

On 17/05/2016 8:23 a.m., Aashima Madaan wrote:
> Hi,
>
> I have a PNG file uploaded on server.
> As part of Download process, it passes through SQUID to another server for
> scanning and then to Client .
>
> When I send request to Download , the response sends only 27kb of image
> back from server of of 700kb file
>
> But when I turn off the respmod in squid.conf file
>
> #adaptation_access service_resp allow all
>
> The client gets full file. This is happening only with PNG files. Did
> anyone encounter this kind of issue and has suggestions in this case?

Can you tell if Squid actually has more than 27KB of the object received
back from ICAP service?
 If now there is your answer, Squid cannot deliver more than it has.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
Confidentiality Notice: This email (including any attachment) is intended for internal use only. Any unauthorized use, dissemination or copying of the content is prohibited. If you are not the intended recipient and have received this e-mail in error, please notify the sender by email and delete this email and any attachment.
Confidentiality Notice: This email (including any attachment) is intended for internal use only. Any unauthorized use, dissemination or copying of the content is prohibited. If you are not the intended recipient and have received this e-mail in error, please notify the sender by email and delete this email and any attachment.


From yvoinov at gmail.com  Tue May 17 20:29:22 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 18 May 2016 02:29:22 +0600
Subject: [squid-users] Squid unable to send full PNG file
In-Reply-To: <12c08020e6d04800a3a96fd1ddba8769@mail.tcc.to>
References: <CAO4ouAZZRjR1n+i-7k158eeu8CEUKAviF560WrzU+N7fTdPFGg@mail.gmail.com>
 <2fafe3c2-1250-70d0-bc9e-9898d011e955@treenet.co.nz>
 <12c08020e6d04800a3a96fd1ddba8769@mail.tcc.to>
Message-ID: <5587c3c3-c87b-6c5a-ae88-cdc29838a27d@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
We need more information. Enable debug wccp gre and the router. See what
happens. You may need to redirect the router debugging to the syslogd.

This may be as a bug in the router and in Linux - yes, and there are
spots in the Sun.

Usually wccp works perfectly - or a dull dead.

18.05.16 1:44, Maile Halatuituia ?????:


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXO38aAAoJENNXIZxhPexGB/cH/1GhY40ehr54FOXV0NyxbM2q
BPsZRBaQ+BMTEok02ATxzXnvNpxy4vUiVG2+ZBKEZ2JL7kCdgcCEo9YSuSAuXo8h
LCKAUH0gP/twXvbSQ1m8gPour9wRQgnARrBIDAKJgc6Sv9l7wZ5arKHWHdCkMZNX
EUmH3A9z9l1BHP9El5nhQhGsgZb4HDcWeDgszj6WWVHoJDMhbTuXQ2L2GzuBXZso
SA8pzqL3vRA/9rWA9nNDtjFKpDBp62oucYVfDGGsXd50om7H933ZOsnAkFVK8j5X
VsEU6nQkUKVljLNYKJKdIg2YXQnuMN1h+iwGS1nv6sahBr2ff3islVkrEkzkSa8=
=Argm
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160518/36b669de/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160518/36b669de/attachment.key>

From yvoinov at gmail.com  Tue May 17 20:29:22 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 18 May 2016 02:29:22 +0600
Subject: [squid-users] Squid unable to send full PNG file
In-Reply-To: <12c08020e6d04800a3a96fd1ddba8769@mail.tcc.to>
References: <CAO4ouAZZRjR1n+i-7k158eeu8CEUKAviF560WrzU+N7fTdPFGg@mail.gmail.com>
 <2fafe3c2-1250-70d0-bc9e-9898d011e955@treenet.co.nz>
 <12c08020e6d04800a3a96fd1ddba8769@mail.tcc.to>
Message-ID: <cada6a0d-1b0f-dc4b-130b-85cfefd5f2e2@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
We need more information. Enable debug wccp gre and the router. See what
happens. You may need to redirect the router debugging to the syslogd.

This may be as a bug in the router and in Linux - yes, and there are
spots in the Sun.

Usually wccp works perfectly - or a dull dead.

18.05.16 1:44, Maile Halatuituia ?????:
> Yuri/Amos
> I have a situation. I suspect it is my gre tunnel idle time or
something but not sure. Every time like after 6 hrs, 4hrs it's not
constant but after sometime i have to tear down the tunnel and re
established it again in order for packet to be redirected from the
router , at the same time i see with the ip wccp command that packets
are being redirected but it does not reflect on wccp0 interface on the
squid box when use ifconfig. I hope i  expalin it clear ...
> thanks in advance
> ________________________________________
> From: squid-users <squid-users-bounces at lists.squid-cache.org> on
behalf of Amos Jeffries <squid3 at treenet.co.nz>
> Sent: Wednesday, May 18, 2016 3:10 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid unable to send full PNG file
>
> On 17/05/2016 8:23 a.m., Aashima Madaan wrote:
>> Hi,
>>
>> I have a PNG file uploaded on server.
>> As part of Download process, it passes through SQUID to another
server for
>> scanning and then to Client .
>>
>> When I send request to Download , the response sends only 27kb of image
>> back from server of of 700kb file
>>
>> But when I turn off the respmod in squid.conf file
>>
>> #adaptation_access service_resp allow all
>>
>> The client gets full file. This is happening only with PNG files. Did
>> anyone encounter this kind of issue and has suggestions in this case?
>
> Can you tell if Squid actually has more than 27KB of the object received
> back from ICAP service?
>  If now there is your answer, Squid cannot deliver more than it has.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> Confidentiality Notice: This email (including any attachment) is
intended for internal use only. Any unauthorized use, dissemination or
copying of the content is prohibited. If you are not the intended
recipient and have received this e-mail in error, please notify the
sender by email and delete this email and any attachment.
> Confidentiality Notice: This email (including any attachment) is
intended for internal use only. Any unauthorized use, dissemination or
copying of the content is prohibited. If you are not the intended
recipient and have received this e-mail in error, please notify the
sender by email and delete this email and any attachment.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXO38hAAoJENNXIZxhPexG7agH/Ap+m9xOKkTew0Avw65Mz4Fb
/n/ZgQOv7ONL7xr9iPsSagzA1FHNy+WZhIZCXBX9OIFMA5xBwpLXWGi56OnA4/J/
5Eq4Ld3XTL0zxqp1LuMjKVnjSnop8uDGdUqdC2eGcefGp02OTJJNUdf5Gk608AzL
GTUmXKAIVmQbvU1zYZevLtxNpANjYpJkSpHc3nGX7Vx5qCYIYEujIFQkPYNKfO1d
im3Ws8zoGP8MqVNLc6TVz6CHYhUqzpUebma5Ub7MXYCRnMBkPLAcnDRAo2Png1CZ
SsE6SdKV0fIfGzCwDOfOCGbTxT+Hk3gCii8KCF72/p+9LZw5WmQpQj1lcflOP9s=
=jpyo
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160518/c9d22666/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160518/c9d22666/attachment.key>

From corpengineer at gmail.com  Tue May 17 20:40:08 2016
From: corpengineer at gmail.com (J Green)
Date: Tue, 17 May 2016 13:40:08 -0700
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <16136e86-e249-f0d9-ab32-b5a592855ffe@treenet.co.nz>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
 <51d8f7ad-29c8-2f00-6b83-4483b637ef56@gmail.com>
 <CANUpZyyRbNR938ZHpYe2d2XCACcxepjcH6auX++E6MOwMve4cA@mail.gmail.com>
 <01d601d1aafe$8b230c00$a1692400$@ngtech.co.il>
 <cc65f5ea-20a6-9dcc-6aac-f5057df161a1@gmail.com>
 <CANUpZyzsq8UCOdsom_GBG84VOr3cYyzNpcaLxeLw-_cHg=GrzQ@mail.gmail.com>
 <CANUpZyz7W4+x7_c9iPPZCwKzPVxP+sH6-Bv1zKh63t5byNnG7g@mail.gmail.com>
 <16136e86-e249-f0d9-ab32-b5a592855ffe@treenet.co.nz>
Message-ID: <CANUpZyzsg66zYU+zscQKmXutkQzqq429WZPa5Yc-fKvcVetwJw@mail.gmail.com>

That could work, I would just need to know at some point, if this event was
triggered.

Been playing with %st , %>qos , & %<qos .  The qos one's seem to just yield
'0x0' .  At least it seems to be logging something.

Would another way to go about this be to log %Se , for Squid errors?  In
this case, ERR_TOO_BIG ?  Couldn't get this option to work either.

This implementation of Squid is w/in pfSense, so it seems I have limited
options for logging, etc.

Thank you.



On Tue, May 17, 2016 at 7:14 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 17/05/2016 6:37 a.m., J Green wrote:
> > Re logging, does this eventually get logged by Squid, somewhere?
> >
>
> I assume by "this" you mean the TOS values?
>
> There are the %>qos and %<qos logformat codes in Squid-3.4 and later.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160517/30570911/attachment.htm>

From yvoinov at gmail.com  Tue May 17 20:54:01 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 18 May 2016 02:54:01 +0600
Subject: [squid-users] Can Traffic Management Settings be configured for
 other TCP protocols?
In-Reply-To: <CANUpZyzsg66zYU+zscQKmXutkQzqq429WZPa5Yc-fKvcVetwJw@mail.gmail.com>
References: <CANUpZywHrQoEzk_jP8PgdkzY5aDcCc80NmvvZo4WLEbSM3AZ_g@mail.gmail.com>
 <e5108d2c-cf9d-0f0d-863a-a732a0bc5a3b@gmail.com>
 <CANUpZyy5RZFUA0vcGY_uOm-mb-1g1qMBCj3dHAFRP+Dz+1w87Q@mail.gmail.com>
 <51d8f7ad-29c8-2f00-6b83-4483b637ef56@gmail.com>
 <CANUpZyyRbNR938ZHpYe2d2XCACcxepjcH6auX++E6MOwMve4cA@mail.gmail.com>
 <01d601d1aafe$8b230c00$a1692400$@ngtech.co.il>
 <cc65f5ea-20a6-9dcc-6aac-f5057df161a1@gmail.com>
 <CANUpZyzsq8UCOdsom_GBG84VOr3cYyzNpcaLxeLw-_cHg=GrzQ@mail.gmail.com>
 <CANUpZyz7W4+x7_c9iPPZCwKzPVxP+sH6-Bv1zKh63t5byNnG7g@mail.gmail.com>
 <16136e86-e249-f0d9-ab32-b5a592855ffe@treenet.co.nz>
 <CANUpZyzsg66zYU+zscQKmXutkQzqq429WZPa5Yc-fKvcVetwJw@mail.gmail.com>
Message-ID: <7edf0c11-5e53-ac92-b814-7d3fece12f2b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Heh, qos need to be configured with squid.conf to be something different
from 0x0 :)


18.05.16 2:40, J Green ?????:
> That could work, I would just need to know at some point, if this event was triggered.
>
> Been playing with %st , %>qos , & %<qos .  The qos one's seem to just
yield '0x0' .  At least it seems to be logging something.
>
> Would another way to go about this be to log %Se , for Squid errors? 
In this case, ERR_TOO_BIG ?  Couldn't get this option to work either.
>
> This implementation of Squid is w/in pfSense, so it seems I have
limited options for logging, etc.
>
> Thank you.
>
>
>
> On Tue, May 17, 2016 at 7:14 AM, Amos Jeffries <squid3 at treenet.co.nz
<mailto:squid3 at treenet.co.nz>> wrote:
>
>     On 17/05/2016 6:37 a.m., J Green wrote:
>     > Re logging, does this eventually get logged by Squid, somewhere?
>     >
>
>     I assume by "this" you mean the TOS values?
>
>     There are the %>qos and %<qos logformat codes in Squid-3.4 and later.
>
>     Amos
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXO4TpAAoJENNXIZxhPexGGhYIAMAVOr1JS7gnQBaPlTfeXDMn
nFzOy+j2Bf9il+Ptnd1JdIC7l0bOwoa4EpckHhfp9C67nK+71ZlpNpFtgQndt/AU
j3CDzXcHn/7cuIFR1nhcDrtV4RKPZCvr/uOVvU2RdqboNatiSUWviXZgQzT3B81e
Akf0llrk3Bc7M05z4bOuE58fysNSzh++kGf/nNyUsspnBv8msMwG+kdmxS4HRxz5
S7JrlcEvxnUjC28ObJsWLsY7xwf/Q5J4Q3KSKU9MCcrws6chczhNSTIe48VOi5XF
vrhMLsevcoI9mO23TU7EcTvVGI6Q31stdAJiph69nR3JOzZZEnth0/12+3rK7pA=
=esCB
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160518/bf8bfd91/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160518/bf8bfd91/attachment.key>

From woody.weaver at us.ibm.com  Tue May 17 21:11:37 2016
From: woody.weaver at us.ibm.com (Robert W Weaver)
Date: Tue, 17 May 2016 17:11:37 -0400
Subject: [squid-users] explicit forward proxy to server requring client
	authentication
Message-ID: <201605172112.u4HLCBDU004054@d03av04.boulder.ibm.com>

Greetings, squid users and devs,

I think this is usual, but I can't find examples, and I can't make it 
work. :-)

The issue is I need to connect to a site that requires client 
authentication.  Don't want to put the key and cert on each individual 
user, so instead want the key and cert on the proxy.

Diagram:

User A ---> Squid S ---> Server B
        ^            ^
        |            +-- TLS client authentication
        +-- cleartext okay

I'm able to bump, but the client authentication to server B isn't working. 
 Configured cert and key on S with ssl-bump cert= .. key= .. but that 
isn't working.

Is this not possible?

--woody


-- 
"I used to wish the universe were fair. Then one day it hit me: What if
the universe were fair? Then all the awful things that happen to us in
life, would happen because we deserved them. So now I take great pleasure
in the general hostility and unfairness of things."
-- Marcus, on Babylon 5

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160517/386ef3ef/attachment.htm>

From yvoinov at gmail.com  Tue May 17 22:02:30 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 18 May 2016 04:02:30 +0600
Subject: [squid-users] explicit forward proxy to server requring client
 authentication
In-Reply-To: <201605172112.u4HLCBDU004054@d03av04.boulder.ibm.com>
References: <201605172112.u4HLCBDU004054@d03av04.boulder.ibm.com>
Message-ID: <4d8f5665-1990-368b-f570-70d1c724afd2@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


18.05.16 3:11, Robert W Weaver ?????:
> Greetings, squid users and devs,
>
> I think this is usual, but I can't find examples, and I can't make it
work. :-)
>
> The issue is I need to connect to a site that requires client
authentication.  Don't want to put the key and cert on each individual
user, so instead want the key and cert on the proxy.
>
> Diagram:
>
> User A ---> Squid S ---> Server B
>         ^            ^
>         |            +-- TLS client authentication
>         +-- cleartext okay
>
> I'm able to bump, but the client authentication to server B isn't
working.  Configured cert and key on S with ssl-bump cert= .. key= ..
but that isn't working.
Because these parameters is for bump, from squid to server. Not for
client certificate.
>
> Is this not possible?
You doing it wrong.

When we read squid.conf.documented, a bit below we can see:

#       clientca=    File containing the list of CAs to use when
#            requesting a client certificate.
#

>
> --woody
>
>
> /-- 
> "I used to wish the universe were fair. Then one day it hit me: What if
> the universe were fair? Then all the awful things that happen to us in
> life, would happen because we deserved them. So now I take great pleasure
> in the general hostility and unfairness of things."
> -- Marcus, on Babylon 5/
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXO5T2AAoJENNXIZxhPexGzrwH/2Sk8ins4kzXjWX55mvE10nh
HSd4T5e4inQihmPlV6xPB/+HugHcBU1Zuxi9Mmy/BuvB1axMW7BRfC+COSenxpaI
4eekoPx4ndlW7s6vxkzlnHIfjgI0Y0TLYL3/f+15DdlXfduqai17GHT58t3yrhO7
GnskQVYrQ7Rje2MzmQ/bfmEBZjGRFYFbwnceCnkXxG1P42aBqLF0GLuuHhKAbsEm
IGnfkXlvhmlTsG3i4+ZDaVRku6QzsChpp1hjAkF+slZJ3IogTq5Dgym3kbnQXrYE
2Jjqrri3Stw7xWRheVFF4JlMtgii3HzSCMGcsdON9WpGvDRvOu+wwPNxBWXUtGE=
=uJQV
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160518/d9ff071a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160518/d9ff071a/attachment.key>

From yvoinov at gmail.com  Tue May 17 22:05:49 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 18 May 2016 04:05:49 +0600
Subject: [squid-users] explicit forward proxy to server requring client
 authentication
In-Reply-To: <201605172112.u4HLCBDU004054@d03av04.boulder.ibm.com>
References: <201605172112.u4HLCBDU004054@d03av04.boulder.ibm.com>
Message-ID: <e0e12898-fb2c-d8f7-3195-bb3de0a87d02@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
..... and a bit below in squid.conf.documented we can see.....

# SSL OPTIONS
#
-----------------------------------------------------------------------------

#  TAG: sslproxy_client_certificate
#    Client SSL Certificate to use when proxying https:// URLs
#Default:
# none

#  TAG: sslproxy_client_key
#    Client SSL Key to use when proxying https:// URLs
#Default:
# none

Ta-daaaaaaaa!


18.05.16 3:11, Robert W Weaver ?????:
> Greetings, squid users and devs,
>
> I think this is usual, but I can't find examples, and I can't make it
work. :-)
>
> The issue is I need to connect to a site that requires client
authentication.  Don't want to put the key and cert on each individual
user, so instead want the key and cert on the proxy.
>
> Diagram:
>
> User A ---> Squid S ---> Server B
>         ^            ^
>         |            +-- TLS client authentication
>         +-- cleartext okay
>
> I'm able to bump, but the client authentication to server B isn't
working.  Configured cert and key on S with ssl-bump cert= .. key= ..
but that isn't working.
>
> Is this not possible?
>
> --woody
>
>
> /-- 
> "I used to wish the universe were fair. Then one day it hit me: What if
> the universe were fair? Then all the awful things that happen to us in
> life, would happen because we deserved them. So now I take great pleasure
> in the general hostility and unfairness of things."
> -- Marcus, on Babylon 5/
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXO5W9AAoJENNXIZxhPexG94UH/AvnmThl9LLLY8WN61iYpMNl
YxemSMMLgw6OkDSuZvZ9m/IW2ErjqYwCgAaRRj8HFeswFYTpEgMz/gRB84JjvZ7k
xY+e2HRPXlFbwiWf/QxU9F5RjRpn3aAE+6Eh2mlae7WKPwcFUFbOmDy2fZOd+/B5
SIFYGnNtySFu7yQt4awIBlSPc0piEAZFn7+Wwis7NenRcsugkOO2hfCG95Yj3Htm
7OCvlBZvh/sDY4yguFgFNlDYt/0ux6LmTrkGHrNRgWWgtqesRdLSg2cAG+Xoh/ns
IILv3YSiTB9l8b80o3Jlp0dIPU0Y6d6B2ZBvVW9HOzXCI8uswYqIKGTT6qiBZSI=
=uzzn
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160518/b5a7d64a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160518/b5a7d64a/attachment.key>

From yvoinov at gmail.com  Tue May 17 22:07:06 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 18 May 2016 04:07:06 +0600
Subject: [squid-users] explicit forward proxy to server requring client
 authentication
In-Reply-To: <201605172112.u4HLCBDU004054@d03av04.boulder.ibm.com>
References: <201605172112.u4HLCBDU004054@d03av04.boulder.ibm.com>
Message-ID: <6110963e-8972-151b-9f7b-3d51c7fb566d@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
PS. I read the manual out loud. With an expression. Expensive. :-!:-D


18.05.16 3:11, Robert W Weaver ?????:
> Greetings, squid users and devs,
>
> I think this is usual, but I can't find examples, and I can't make it
work. :-)
>
> The issue is I need to connect to a site that requires client
authentication.  Don't want to put the key and cert on each individual
user, so instead want the key and cert on the proxy.
>
> Diagram:
>
> User A ---> Squid S ---> Server B
>         ^            ^
>         |            +-- TLS client authentication
>         +-- cleartext okay
>
> I'm able to bump, but the client authentication to server B isn't
working.  Configured cert and key on S with ssl-bump cert= .. key= ..
but that isn't working.
>
> Is this not possible?
>
> --woody
>
>
> /-- 
> "I used to wish the universe were fair. Then one day it hit me: What if
> the universe were fair? Then all the awful things that happen to us in
> life, would happen because we deserved them. So now I take great pleasure
> in the general hostility and unfairness of things."
> -- Marcus, on Babylon 5/
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXO5YKAAoJENNXIZxhPexGnoQIAKZMTM+BM0OFepgUf6EiegYc
/ppZf32vaoQllYwDO9osOXJaQ9CoViOIIWLyd5G+IkoDFN8H2wXLxOe2T7BGH6+Q
13x4LvBX7ul5y4ESwsnJFrWg7WbhwjXkQs4peLmgNsAj6KiSlLP0cVYU7fQy2qXj
AY0seun4L7UszCNV25hrjbVZGT2qGTyELIFXKwj42vTBx56sMBF5+NcYEDNYPUFF
whh0ykM0VKaoy/LN5JDsFqeb7FkMOEtwEa3dPvtv8xgUTidQiBXqKVIyGCmXcoib
Dv5ONhsjMEES3eh70yxpkQFJd2OoGCpp+kOBxX6ZCgl+iwofWbdRc6NoIqgdJbY=
=27Xu
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160518/802f324e/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160518/802f324e/attachment.key>

From azzialink at gmail.com  Wed May 18 01:10:34 2016
From: azzialink at gmail.com (zodyo)
Date: Tue, 17 May 2016 18:10:34 -0700 (PDT)
Subject: [squid-users] explicit forward proxy to server requring client
	authentication
In-Reply-To: <6110963e-8972-151b-9f7b-3d51c7fb566d@gmail.com>
References: <201605172112.u4HLCBDU004054@d03av04.boulder.ibm.com>
 <6110963e-8972-151b-9f7b-3d51c7fb566d@gmail.com>
Message-ID: <1463533834776-4677621.post@n4.nabble.com>

Dear all,

I have same problem here, client cant login to a server with auth like LDAP
via transparent/static squid.
i have try with lusca and the newer squid 3.5.17



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/explicit-forward-proxy-to-server-requring-client-authentication-tp4677617p4677621.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed May 18 05:48:26 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 18 May 2016 17:48:26 +1200
Subject: [squid-users] explicit forward proxy to server requring client
 authentication
In-Reply-To: <e0e12898-fb2c-d8f7-3195-bb3de0a87d02@gmail.com>
References: <201605172112.u4HLCBDU004054@d03av04.boulder.ibm.com>
 <e0e12898-fb2c-d8f7-3195-bb3de0a87d02@gmail.com>
Message-ID: <622d7a81-4b63-eaed-9859-fcd2db3c7b45@treenet.co.nz>

On 18/05/2016 10:05 a.m., Yuri Voinov wrote:
> 
> ..... and a bit below in squid.conf.documented we can see.....
> 
> # SSL OPTIONS
> #
> -----------------------------------------------------------------------------
> 
> #  TAG: sslproxy_client_certificate
> #    Client SSL Certificate to use when proxying https:// URLs
> #Default:
> # none
> 
> #  TAG: sslproxy_client_key
> #    Client SSL Key to use when proxying https:// URLs
> #Default:
> # none
> 
> Ta-daaaaaaaa!
> 

You are the one getting it wrong here Yuri :-(

* clientca= is for listening ports. He wants that conectio to be cleartext.

* sslproxy_* directives are for generic DIRECT connections. He wants a
specific proxy<->server connection to be TLS authenticated.

For the S<->B connection to use client certificates. cert= and key= on
the cache_peer directive defining that link are correct.

But there are twe other details that need to happen for it to work:
* the server actually challenge for the proxies 'client' cert, and
* the server trust the CA which signed that cert.

The world of "not working" is a very big place. We need more details of
*how* its not working in order to have any guideposts towards what the
problem actually is. As Yuri used to say a lot, my psychic friend is on
holiday.

Amos

> 
> 18.05.16 3:11, Robert W Weaver ?????:
>> Greetings, squid users and devs,
> 
>> I think this is usual, but I can't find examples, and I can't make it
> work. :-)
> 
>> The issue is I need to connect to a site that requires client
> authentication.  Don't want to put the key and cert on each individual
> user, so instead want the key and cert on the proxy.
> 
>> Diagram:
> 
>> User A ---> Squid S ---> Server B
>>         ^            ^
>>         |            +-- TLS client authentication
>>         +-- cleartext okay
> 
>> I'm able to bump, but the client authentication to server B isn't
> working.  Configured cert and key on S with ssl-bump cert= .. key= ..
> but that isn't working.
> 
>> Is this not possible?
> 
>> --woody
> 
> 
>> /-- 
>> "I used to wish the universe were fair. Then one day it hit me: What if
>> the universe were fair? Then all the awful things that happen to us in
>> life, would happen because we deserved them. So now I take great pleasure
>> in the general hostility and unfairness of things."
>> -- Marcus, on Babylon 5/
> 
> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From emz at norma.perm.ru  Wed May 18 05:57:28 2016
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Wed, 18 May 2016 10:57:28 +0500
Subject: [squid-users] ext_kerberos_ldap_group_acl and Kerberos cache
Message-ID: <573C0448.5020900@norma.perm.ru>

Hi.

I've just checked that squid 3.5.19 sources, and discovered the
following fact that is really disturbing:
(first some explanation)
Markus Moeller, the author of the external kerberos group helper, has
implemented the Kerberos credentials cache in the
ext_kerberos_ldap_group_acl  helper back in the 2014. The idea is to
cache the credentials inside the helper instance, so when it encounters
a request with user id and group that are already in the cache, the
helper can skip the kerberos initialization sequence for this set of
credentials. This cached version is times faster than original one, that
doesn't use the cache.

(now the disturbing fact)
Surprisingly, the cached version didn't make it to the main tree for 2
past years.
Could this situation be corrected please ?

Thanks.
Eugene.


From uhlar at fantomas.sk  Wed May 18 06:57:46 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 18 May 2016 08:57:46 +0200
Subject: [squid-users] explicit forward proxy to server requring client
 authentication
In-Reply-To: <1463533834776-4677621.post@n4.nabble.com>
References: <201605172112.u4HLCBDU004054@d03av04.boulder.ibm.com>
 <6110963e-8972-151b-9f7b-3d51c7fb566d@gmail.com>
 <1463533834776-4677621.post@n4.nabble.com>
Message-ID: <20160518065746.GA17118@fantomas.sk>

On 17.05.16 18:10, zodyo wrote:
>I have same problem here, client cant login to a server with auth like LDAP
>via transparent/static squid.
>i have try with lusca and the newer squid 3.5.17

how can this be the same problem? It's very different problem.


when talking about "transparent" proxy, you apparently mean "intercepting"
proxy - client tries to connect to a server, but the connection is
redirected to proxy.

Now, the client can _not_ log onto a proxy, if it believes it connects to
the server, not to the proxy - it does not know there's a proxy.

You must configure proxy (explicitly, or using WPAD protocol) if you want
your clients to authenticate on them.

Or, you must use out-of-band authentication protocol (external program that
will check who is the client, e.g. who is logged on the client computer.
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Save the whales. Collect the whole set.


From uhlar at fantomas.sk  Wed May 18 07:04:39 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 18 May 2016 09:04:39 +0200
Subject: [squid-users] explicit forward proxy to server requring client
 authentication
In-Reply-To: <201605172112.u4HLCBDU004054@d03av04.boulder.ibm.com>
References: <201605172112.u4HLCBDU004054@d03av04.boulder.ibm.com>
Message-ID: <20160518070439.GB17118@fantomas.sk>

On 17.05.16 17:11, Robert W Weaver wrote:
>The issue is I need to connect to a site that requires client
>authentication.  Don't want to put the key and cert on each individual
>user, so instead want the key and cert on the proxy.
>
>Diagram:
>
>User A ---> Squid S ---> Server B
>        ^            ^
>        |            +-- TLS client authentication
>        +-- cleartext okay
>
>I'm able to bump, but the client authentication to server B isn't working.

...of course it's not working. When you bump a connection, you are effectively
doing the MITM attack. The client talks to a proxy and the proxy talks to a
server. Squid can't use clients' certificate because it does not have the
clients' private key (the whole point of SSL is to avoid these situations)

SSL authentication can work between client and proxy, and another one
between proxy and the server.

If you have certification authority, you can create fake clients' key and
authenticate with it, but the server (site) must accept your authority.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
A day without sunshine is like, night.


From sagarmalve91 at gmail.com  Wed May 18 11:05:08 2016
From: sagarmalve91 at gmail.com (Sagar Malve)
Date: Wed, 18 May 2016 16:35:08 +0530
Subject: [squid-users] Internet Browsing very slow after implementing Squid
 peek & splice + Access log not tracing full URL
Message-ID: <CAKQSiAUtj3m0V7-_dn6+SUAzbSdrtmA=FHSOaP1yUhLS8gKRDA@mail.gmail.com>

Scenario :  I want to block certain HTTPS website using SSL Bump and
without installing any SSL Certificate on Clients End as I will be
distributing this Same Network for Mobile Devices so I don't want to keep
installing certificate in each Mobile Device like Android / IOS / Windows
etc phones .......

*I have installed Squid 3.5.13 and we have Broadband Connection with speed
50 Mb/sec. I have gone through lots of document where I found that we can
Block Https Traffic without installing Certificate by enabling Peek &
Splice feature.*

------------------- Below is the Configuration file of Squid
---------------------------------------

# -------------------------------------
# Access Control Lists
# -------------------------------------
acl localnet src 192.168.0.0/24    # RFC1918 possible internal network

acl SSL_ports port 443
acl SSL_ports port 8443        # Telecom exclusion
acl Safe_ports port 80        # http
acl Safe_ports port 21        # ftp
acl Safe_ports port 443        # https
acl Safe_ports port 70        # gopher
acl Safe_ports port 210        # wais
acl Safe_ports port 280        # http-mgmt
acl Safe_ports port 488        # gss-http
acl Safe_ports port 591        # filemaker
acl Safe_ports port 777        # multiling http

# Common methods
acl CONNECT method CONNECT
acl PURGE method PURGE
acl GET method GET

# Windows update acls
acl windowsupdate dstdomain sls.update.microsoft.com.akadns.net
acl windowsupdate dstdomain windowsupdate.microsoft.com
acl windowsupdate dstdomain .update.microsoft.com
acl windowsupdate dstdomain download.windowsupdate.com
acl windowsupdate dstdomain redir.metaservices.microsoft.com
acl windowsupdate dstdomain images.metaservices.microsoft.com
acl windowsupdate dstdomain c.microsoft.com
acl windowsupdate dstdomain www.download.windowsupdate.com
acl windowsupdate dstdomain wustat.windows.com
acl windowsupdate dstdomain crl.microsoft.com
acl windowsupdate dstdomain sls.microsoft.com
acl windowsupdate dstdomain productactivation.one.microsoft.com
acl windowsupdate dstdomain ntservicepack.microsoft.com

# Windows update methods
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com


# SSL bump acl
acl net_bump src "/etc/squid/net.bump"

# TLD acl
acl block_tld dstdomain "/etc/squid/dstdom.tld"

# -------------------------------------
# Access parameters
# -------------------------------------
# Deny requests to unsafe ports
http_access deny !Safe_ports
# Deny CONNECT to other than SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager
http_access deny to_localhost
# Allow purge from localhost
http_access allow PURGE localhost
http_access deny PURGE

# Normalize Accept-Encoding to support compression via eCAP
request_header_access Accept-Encoding deny all
request_header_replace Accept-Encoding gzip;q=1.0, identity;q=0.5, *;q=0
# Disable alternate protocols
request_header_access Alternate-Protocol deny all
reply_header_access Alternate-Protocol deny all
# Disable HSTS
reply_header_access Strict-Transport-Security deny all
reply_header_replace Strict-Transport-Security max-age=0; includeSubDomains
# Remove User-Agent from Vary
reply_header_access Vary deny all
reply_header_replace Vary Accept-Encoding
# Workaround 4253
request_header_access Surrogate-Capability deny all

# Block top level domains
http_access deny block_tld
deny_info TCP_RESET block_tld

# Rule allowing access from local networks
http_access allow localnet
http_access allow localhost


# ICP/HTCP access
icp_access allow localnet
icp_access deny all
htcp_access allow localnet
htcp_access deny all

# 302 loop
acl text_mime rep_mime_type text/html text/plain
acl http302 http_status 302
store_miss deny text_mime http302
send_hit deny text_mime http302

# Windows updates rules
http_access allow CONNECT wuCONNECT localnet
http_access allow CONNECT wuCONNECT localhost
http_access allow windowsupdate localnet
http_access allow windowsupdate localhost

# SSL bump rules
acl DiscoverSNIHost at_step SslBump1
# ICQ/MRA must splice first
acl NoSSLIntercept ssl::server_name_regex -i "/etc/squid/url.nobump"
ssl_bump splice NoSSLIntercept
ssl_bump bump net_bump
#ssl_bump terminate deny_https_sites
#ssl_bump peek all
acl tls_s3_server_hello at_step SslBump3

# TLS/SSL bumping steps
ssl_bump peek   tls_s1_connect      all      # peek at the incoming TLS/SSL
connect data
ssl_bump splice all                          # splice the stream:
pass-through mode

# And finally deny all other access to this proxy
http_access deny all

# -------------------------------------
# HTTP parameters
# -------------------------------------
# Local Privoxy is cache parent
cache_peer 127.0.0.1 parent 8118 0 no-query no-digest default

cache_peer_access 127.0.0.1 deny all

# Don't cache 404 long time
negative_ttl 5 minutes
positive_dns_ttl 15 hours
negative_dns_ttl 1 minutes

# -------------------------------------
# Cache parameters
# -------------------------------------
# dhparams is before squid-3.5.12-20151222-r13967
# tls-dh is AFTER squid-3.5.12-20151222-r13967
#http_port 3126 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_certs/squid.crt
key=/etc/squid/ssl_certs/squid.key options=NO_SSLv3
tls-dh=/etc/squid/dhparam.pem
http_port 3127
http_port 3128 intercept
# dhparams is before squid-3.5.12-20151222-r13967
# tls-dh is AFTER squid-3.5.12-20151222-r13967
https_port 3129 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_certs/squid.crt
key=/etc/squid/ssl_certs/squid.key options=NO_SSLv3
tls-dh=/etc/squid/dhparam.pem
sslproxy_capath /etc/ssl/certs
# SINGLE_DH_USE is 3.5 before squid-3.5.12-20151222-r13967
#sslproxy_options NO_SSLv3,SINGLE_DH_USE
# SINGLE_ECDH_USE is AFTER squid-3.5.12-20151222-r13967
sslproxy_options NO_SSLv3,SINGLE_ECDH_USE
sslproxy_cipher
EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB

# Specify ICP/HTCP explicity
icp_port 3130
htcp_port 4827

# Cache manager
cache_mgr mymail at gmail.com



# Forces reload-into-ims
reload_into_ims on

# Hide internal networks details outside
via off
forwarded_for delete

# Do not show Squid version
httpd_suppress_version_string on


# Prioritization of local hits
qos_flows tos local-hit=0x68

# Specify local DNS cache
dns_nameservers 8.8.8.8

dns_v4_first on
ipcache_size 4096


# -------------------------------------
# Memory parameters
# -------------------------------------
cache_mem 512 Mb

#memory_pools off

maximum_object_size_in_memory 1 MB

# -------------------------------------
# Tuning parameters
# -------------------------------------
memory_replacement_policy heap LRU
cache_replacement_policy heap LFUDA

store_avg_object_size 85 KB
# Default is 20
store_objects_per_bucket 32

# Shutdown delay before terminate connections
shutdown_lifetime 15 second

# SMP
#workers 2

# -------------------------------------
# Store parameters
# -------------------------------------
maximum_object_size 8 Gb

cache_dir aufs /usr/local/cache 250000 16 256

# -------------------------------------
# Process/log parameters
# -------------------------------------
#logformat my_squid %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un %Sh/%<a %mt
#access_log daemon:/data/cache/log/access.log buffer-size=256KB
access_log daemon:/var/log/squid/access.log buffer-size=256KB
# Don't log ICP queries
log_icp_queries off

# Turn off internal log rotation
logfile_rotate 0

cache_log /var/log/squid/cache.log
#cache_log /data/cache/log/cache${process_number}.log
cache_store_log none

# Default is off
buffered_logs on

coredump_dir /var/core

pid_filename /tmp/squid.pid

strip_query_terms off

# -------------------------------------
# Content parameters
# -------------------------------------
#range_offset_limit none store_rewrite_list
#range_offset_limit none store_rewrite_list_web
#range_offset_limit none store_rewrite_list_web_cdn
#range_offset_limit none adobe_java_updates
#range_offset_limit none windowsupdate
range_offset_limit none all

# Updates: Windows, Adobe, Java
refresh_pattern -i
microsoft.com.*\.(cab|exe|ms[i|u|f|p]|asf|wm[v|a]|dat|zip)    4320 80%
43200    reload-into-ims
refresh_pattern -i
windowsupdate.com.*\.(cab|exe|ms[i|u|f|p]|asf|wm[v|a]|dat|zip)    4320 80%
43200    reload-into-ims
refresh_pattern -i
my.windowsupdate.website.com.*\.(cab|exe|ms[i|u|f|p]|asf|wm[v|a]|dat|zip)
4320 80% 43200    reload-into-ims
refresh_pattern -i adobe.com.*\.(zip|exe)    4320    80%    43200
reload-into-ims
refresh_pattern -i java.com.*\.(zip|exe)    4320    80%    43200
reload-into-ims
refresh_pattern -i sun.com.*\.(zip|exe)        4320    80%    43200
reload-into-ims
refresh_pattern -i google\.com.*\.(zip|exe)    4320    80%    43200
reload-into-ims
refresh_pattern -i macromedia\.com.*\.(zip|exe)    4320    80% 43200
reload-into-ims
# Other setups and updates
refresh_pattern -i \.(zip|(g|b)z2?|exe|msi|cvd)$    4320    80% 43200
reload-into-ims
# Cacle squidinternal
refresh_pattern -i video-srv\.youtube\.squidinternal    0    0%    0
refresh_pattern -i squidinternal    14400    100%    518400 override-expire
override-lastmod refresh-ims reload-into-ims ignore-private ignore-auth
ignore-must-revalidate store-stale ignore-no-store
# Keep swf in cache
refresh_pattern -i \.swf$    10080    100%    43200    override-expire
reload-into-ims ignore-private
# .NET cache
refresh_pattern -i \.((a|m)s(h|p)x?)$        10080    100%    43200
reload-into-ims ignore-private
# Other long-lived items
refresh_pattern -i
\.(jp(e?g|e|2)|gif|png|bmp|ico|svg|web(p|m)|wm(v|a)|flv|f4f|mp(3|4)|ttf|eot|woff2?|(c|x|j)ss|js(t?|px?))(\?.*)?$
14400    100%    518400    override-expire override-lastmod reload-into-ims
ignore-private ignore-no-store ignore-must-revalidate
refresh_pattern -i
\.((cs|d?|m?|p?|r?|s?|w?|x?|z?)h?t?m?(l?)|php(3?|5?)|rss|atom|vr(t|ml))(\?.*)?$
10080    100%    86400    override-expire override-lastmod reload-into-ims
ignore-private ignore-no-store ignore-must-revalidate
# Default patterns
refresh_pattern -i (/cgi-bin/|\?)    0    0%    0
refresh_pattern    .    0    20%    4320    reload-into-ims

------------------------- Squid Configuration End
----------------------------------------------

When we give Network Connection Dirtectly through the Router then Internet
is working fine but when we pass the Network through Squid the Internet
work very slow .......


---------------- IPTables ---------------------

Chain PREROUTING (policy ACCEPT 25461 packets, 3444K bytes)
 pkts bytes target     prot opt in     out     source
destination
  996 55869 DNAT       tcp  --  eth1   *       0.0.0.0/0
0.0.0.0/0            tcp dpt:80 to:192.168.0.200:3128
    0     0 REDIRECT   tcp  --  eth0   *       0.0.0.0/0
0.0.0.0/0            tcp dpt:80 redir ports 3128
 3597  211K DNAT       tcp  --  eth1   *       0.0.0.0/0
0.0.0.0/0            tcp dpt:443 to:192.168.0.200:3129
    0     0 REDIRECT   tcp  --  eth0   *       0.0.0.0/0
0.0.0.0/0            tcp dpt:443 redir ports 3129

Chain INPUT (policy ACCEPT 11351 packets, 1166K bytes)
 pkts bytes target     prot opt in     out     source
destination

Chain OUTPUT (policy ACCEPT 2490 packets, 154K bytes)
 pkts bytes target     prot opt in     out     source
destination

Chain POSTROUTING (policy ACCEPT 2490 packets, 154K bytes)
 pkts bytes target     prot opt in     out     source
destination
10029 1452K MASQUERADE  all  --  *      eth0    192.168.0.0/24
0.0.0.0/0

---------------------------------------------------------------------------------------------------------------------------------
Access Logs:
1463478680.312  33025 192.168.0.66 TCP_TUNNEL/200 3865 CONNECT
216.58.199.165:443 - ORIGINAL_DST/216.58.199.165 -
1463478680.317  27194 192.168.0.66 TCP_TUNNEL/200 641 CONNECT
216.58.220.4:443 - ORIGINAL_DST/216.58.220.4 -
1463478680.318  27195 192.168.0.66 TCP_TUNNEL/200 872 CONNECT
216.58.199.142:443 - ORIGINAL_DST/216.58.199.142 -
1463478680.323  27096 192.168.0.66 TCP_TUNNEL/200 823 CONNECT
216.58.199.142:443 - ORIGINAL_DST/216.58.199.142 -
1463478680.376  27266 192.168.0.66 TCP_TUNNEL/200 1912 CONNECT
74.125.200.189:443 - ORIGINAL_DST/74.125.200.189 -
1463478680.528   5110 192.168.0.66 TCP_TUNNEL/200 17448 CONNECT
125.99.55.72:443 - ORIGINAL_DST/125.99.55.72 -
1463478680.528   4772 192.168.0.66 TCP_TUNNEL/200 1358 CONNECT
95.101.34.18:443 - ORIGINAL_DST/95.101.34.18 -
1463478680.528   3707 192.168.0.66 TCP_TUNNEL/200 1172 CONNECT
31.13.79.246:443 - ORIGINAL_DST/31.13.79.246 -
1463478680.528   5178 192.168.0.66 TCP_TUNNEL/200 44054 CONNECT
184.86.250.32:443 - ORIGINAL_DST/184.86.250.32 -
1463478680.528  29346 192.168.0.66 TCP_TUNNEL/200 439 CONNECT
216.58.199.142:443 - ORIGINAL_DST/216.58.199.142 -
1463478680.556   9869 192.168.0.66 TCP_TUNNEL/200 58963 CONNECT
216.58.220.3:443 - ORIGINAL_DST/216.58.220.3 -
1463478680.556  31783 192.168.0.66 TCP_TUNNEL/200 1073 CONNECT
216.58.220.4:443 - ORIGINAL_DST/216.58.220.4 -
1463478680.584   6543 192.168.0.66 TCP_TUNNEL/200 193204 CONNECT
31.13.79.220:443 - ORIGINAL_DST/31.13.79.220 -
1463478680.702    223 192.168.0.66 TCP_TUNNEL/200 206 CONNECT
31.13.79.220:443 - ORIGINAL_DST/31.13.79.220 -
1463478681.710   1216 192.168.0.66 TCP_TUNNEL/200 587 CONNECT
216.58.199.165:443 - ORIGINAL_DST/216.58.199.165 -
1463478681.775   1369 192.168.0.66 TCP_TUNNEL/200 587 CONNECT
74.125.130.189:443 - ORIGINAL_DST/74.125.130.189 -
1463478685.128     37 192.168.0.66 TCP_TUNNEL/200 267 CONNECT
125.99.55.75:443 - ORIGINAL_DST/125.99.55.75 -
1463478686.862     40 192.168.0.66 TCP_REFRESH_MODIFIED/200 539 GET
http://kerastasesalonlocator.com/ - ORIGINAL_DST/103.21.58.154 text/html
1463478686.880      5 192.168.0.66 TCP_MISS_ABORTED/000 0 GET
http://kerastasesalonlocator.com/cgi-sys/defaultwebpage.cgi - ORIGINAL_DST/
103.21.58.154 -
-----------------------------------------------------------------------------------------------------------------------------------------


We have installed Squid on Ubuntu Server 14.04  Ram: 32 GB HDD: 1TB




*Also I am not getting full URL for HTTPS Traffic in Access Logs ........*
We have tried to implement Caching DNS Server (Local) but still it didn't
work then we have given the Google Public DNS .......

Could you please let us know where we are doing mistake .......



Regards
Sagar Malve
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160518/c66a0345/attachment.htm>

From squid3 at treenet.co.nz  Wed May 18 11:29:17 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 18 May 2016 23:29:17 +1200
Subject: [squid-users] ext_kerberos_ldap_group_acl and Kerberos cache
In-Reply-To: <573C0448.5020900@norma.perm.ru>
References: <573C0448.5020900@norma.perm.ru>
Message-ID: <43025b84-9ea4-16e6-a81c-eb153ac498b0@treenet.co.nz>

On 18/05/2016 5:57 p.m., Eugene M. Zheganin wrote:
> Hi.
> 
> I've just checked that squid 3.5.19 sources, and discovered the
> following fact that is really disturbing:
> (first some explanation)
> Markus Moeller, the author of the external kerberos group helper, has
> implemented the Kerberos credentials cache in the
> ext_kerberos_ldap_group_acl  helper back in the 2014. The idea is to
> cache the credentials inside the helper instance, so when it encounters
> a request with user id and group that are already in the cache, the
> helper can skip the kerberos initialization sequence for this set of
> credentials. This cached version is times faster than original one, that
> doesn't use the cache.
> 
> (now the disturbing fact)
> Surprisingly, the cached version didn't make it to the main tree for 2
> past years.
> Could this situation be corrected please ?


I don't know what you mean by "the main tree". But The feature you
describe does not qualify for adding to the 3.5 production release
series. The only features added to a series after is goes to "stable"
production releases are ones which resolve non-feature bugs or can be
done without affecting existing installations.

By changing the helper behaviour in all cases this clearly affects
existing installations. So only qualifies for including into the next
series, which is Squid-4.

It is a bit disappointing that 4.x is not yet in stable series itself.
But we need to get the major bugs in the new code fixed before that can
happen.

Amos



From rangasai.manduva at in.unisys.com  Wed May 18 12:25:23 2016
From: rangasai.manduva at in.unisys.com (Manduva, Ranga Sai)
Date: Wed, 18 May 2016 12:25:23 +0000
Subject: [squid-users] squid_ldap_auth: WARNING,
	LDAP search error 'Referral'
Message-ID: <1ecfa5a9a05f463bae92e207c19db65c@AU-EXCH13-4.ap.uis.unisys.com>

Hi,

Does anyone had similar issue ?? Is there any workaround for it ? Something like configure squid to follow referral etc..

Thanks.

Regards,
Ranga


-----Original Message-----
From: Manduva, Ranga Sai 
Sent: Monday, May 16, 2016 6:32 PM
To: 'squid-users at lists.squid-cache.org' <squid-users at lists.squid-cache.org>
Subject: squid_ldap_auth: WARNING, LDAP search error 'Referral'

Hello,

I am receiving this error while authenticating a user with the AD and the internet access is denied. I know there is a switch '-R' to explicitly enable do not follow referrals which I am not using here.

Did anyone faced similar issue ? My AD is using nested groups between domains where the users and groups are from different domains.

Got stuck with this issue for a while.. appreciate anyone's help in this regard.

Thank you.

Regards,
Ranga




From woody.weaver at us.ibm.com  Wed May 18 12:29:29 2016
From: woody.weaver at us.ibm.com (Robert W Weaver)
Date: Wed, 18 May 2016 08:29:29 -0400
Subject: [squid-users] explicit forward proxy to server requring client
 authentication
In-Reply-To: <mailman.21951.1463550544.2892.squid-users@lists.squid-cache.org>
References: <mailman.21951.1463550544.2892.squid-users@lists.squid-cache.org>
Message-ID: <201605181229.u4ICTY9p003702@d03av01.boulder.ibm.com>

>> 18.05.16 3:11, Robert W Weaver ?????:
>>> The issue is I need to connect to a site that requires client
>>> authentication.  Don't want to put the key and cert on each individual
>>> user, so instead want the key and cert on the proxy.
>>> Diagram:

>>> User A ---> Squid S ---> Server B
>>>         ^            ^
>>>         |            +-- TLS client authentication
>>>         +-- cleartext okay

On Wed, 18 May 2016 17:48:26 +1200, Amos Jeffries <squid3 at treenet.co.nz> 
wrote:

> On 18/05/2016 10:05 a.m., Yuri Voinov wrote:
>> 
>> ..... and a bit below in squid.conf.documented we can see.....
>> 
>> # SSL OPTIONS
>> #
>> 
-----------------------------------------------------------------------------
>> 
>> #  TAG: sslproxy_client_certificate
>> #    Client SSL Certificate to use when proxying https:// URLs
>> #Default:
>> # none
>> 
>> #  TAG: sslproxy_client_key
>> #    Client SSL Key to use when proxying https:// URLs
>> #Default:
>> # none
>> 
>> Ta-daaaaaaaa!
> 

> You are the one getting it wrong here Yuri :-(

I am celebrating Yuri's ta dah.  The clue to squid.config.documented was 
crucial, and the specific hint to sslproxy_client_* was what was missing.

From S to B is now working properly.  Squid is now in the middle, and is 
performing authentication to server B properly.

> * clientca= is for listening ports. He wants that conectio to be 
cleartext.

> * sslproxy_* directives are for generic DIRECT connections. He wants a
> specific proxy<->server connection to be TLS authenticated.

> For the S<->B connection to use client certificates. cert= and key= on
> the cache_peer directive defining that link are correct.

> But there are twe other details that need to happen for it to work:
> * the server actually challenge for the proxies 'client' cert, and
> * the server trust the CA which signed that cert.

This is happening.  I'd generated a CSR and had the CA that is the "owner" 
of server B sign it for me.  We are cool.

> The world of "not working" is a very big place. We need more details of
> *how* its not working in order to have any guideposts towards what the
> problem actually is. As Yuri used to say a lot, my psychic friend is on
> holiday.

It is now working to an acceptable point, although there is an enhancement 
that would be nice.  Right now,

1.  A connects to S, requests https://B/some/image.png
2.  S connects to B over TLS, performs client authentication, gets 
/some/image.png (or pulls from cache)
3.  A converts to TLS to S, pulls down data.

This is fine, its just that there is an unnecessary encrypt/decrypt 
between A and S.  The connection is inside a controlled data center (on 
the same switch, perhaps on the same ESX host) so I'm not concerned about 
security -- not to mention the cached data isn't especially sensitive. 

So this last bit is just an enhancement, a nice to have.  Its the opposite 
of SSL termination for accelerators, so I suspect its possible, just don't 
know how to do it.

Coffee (or a favorite beverage) all around!

--woody

-- 
Doubt is not a pleasant condition, but certainty is absurd.
-- Voltaire


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160518/b4f0e808/attachment.htm>

From squid3 at treenet.co.nz  Wed May 18 12:39:46 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 19 May 2016 00:39:46 +1200
Subject: [squid-users] Internet Browsing very slow after implementing
 Squid peek & splice + Access log not tracing full URL
In-Reply-To: <CAKQSiAUtj3m0V7-_dn6+SUAzbSdrtmA=FHSOaP1yUhLS8gKRDA@mail.gmail.com>
References: <CAKQSiAUtj3m0V7-_dn6+SUAzbSdrtmA=FHSOaP1yUhLS8gKRDA@mail.gmail.com>
Message-ID: <cc51a531-9d11-d8cc-17c8-34e06a4105f5@treenet.co.nz>

On 18/05/2016 11:05 p.m., Sagar Malve wrote:
> Scenario :  I want to block certain HTTPS website using SSL Bump and
> without installing any SSL Certificate on Clients End as I will be
> distributing this Same Network for Mobile Devices so I don't want to keep
> installing certificate in each Mobile Device like Android / IOS / Windows
> etc phones .......
> 
> *I have installed Squid 3.5.13 and we have Broadband Connection with speed

Please upgrade. 3.5.19 is now the minimum version to use with SSL-Bump
feature. Due to almost a dozen CVE issues fixed recently most of which
are only bad when SSL-Bump is used.


> 50 Mb/sec. I have gone through lots of document where I found that we can
> Block Https Traffic without installing Certificate by enabling Peek &
> Splice feature.*
> 

Lets be accurate:

* You can *terminate* TLS connections with "ssl_bump terminate" rules.

* You cannot send the client errors or rejection notices unless they
trust the Squid cert generators' CA.


>
> *Also I am not getting full URL for HTTPS Traffic in Access Logs ........*
> We have tried to implement Caching DNS Server (Local) but still it didn't
> work then we have given the Google Public DNS .......
>
> Could you please let us know where we are doing mistake .......
>

The URL for HTTPS requests is encrypted. Squid cannot get access to even
see what it is without decrypting the connection. Which is the action
that requires the CA be installed on the clients.





> ------------------- Below is the Configuration file of Squid
> ---------------------------------------
> 
> # -------------------------------------
> # Access Control Lists
> # -------------------------------------
> acl localnet src 192.168.0.0/24    # RFC1918 possible internal network
> 
> acl SSL_ports port 443
> acl SSL_ports port 8443        # Telecom exclusion
> acl Safe_ports port 80        # http
> acl Safe_ports port 21        # ftp
> acl Safe_ports port 443        # https
> acl Safe_ports port 70        # gopher
> acl Safe_ports port 210        # wais
> acl Safe_ports port 280        # http-mgmt
> acl Safe_ports port 488        # gss-http
> acl Safe_ports port 591        # filemaker
> acl Safe_ports port 777        # multiling http
> 
> # Common methods
> acl CONNECT method CONNECT
> acl PURGE method PURGE
> acl GET method GET
> 
> # Windows update acls
> acl windowsupdate dstdomain sls.update.microsoft.com.akadns.net
> acl windowsupdate dstdomain windowsupdate.microsoft.com
> acl windowsupdate dstdomain .update.microsoft.com
> acl windowsupdate dstdomain download.windowsupdate.com
> acl windowsupdate dstdomain redir.metaservices.microsoft.com
> acl windowsupdate dstdomain images.metaservices.microsoft.com
> acl windowsupdate dstdomain c.microsoft.com
> acl windowsupdate dstdomain www.download.windowsupdate.com
> acl windowsupdate dstdomain wustat.windows.com
> acl windowsupdate dstdomain crl.microsoft.com
> acl windowsupdate dstdomain sls.microsoft.com
> acl windowsupdate dstdomain productactivation.one.microsoft.com
> acl windowsupdate dstdomain ntservicepack.microsoft.com
> 
> # Windows update methods
> acl wuCONNECT dstdomain www.update.microsoft.com
> acl wuCONNECT dstdomain sls.microsoft.com
> 
> 
> # SSL bump acl
> acl net_bump src "/etc/squid/net.bump"
> 
> # TLD acl
> acl block_tld dstdomain "/etc/squid/dstdom.tld"
> 
> # -------------------------------------
> # Access parameters
> # -------------------------------------
> # Deny requests to unsafe ports
> http_access deny !Safe_ports
> # Deny CONNECT to other than SSL ports
> http_access deny CONNECT !SSL_ports
> 
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
> http_access deny to_localhost
> # Allow purge from localhost
> http_access allow PURGE localhost
> http_access deny PURGE
> 
> # Normalize Accept-Encoding to support compression via eCAP
> request_header_access Accept-Encoding deny all
> request_header_replace Accept-Encoding gzip;q=1.0, identity;q=0.5, *;q=0
> # Disable alternate protocols
> request_header_access Alternate-Protocol deny all
> reply_header_access Alternate-Protocol deny all
> # Disable HSTS
> reply_header_access Strict-Transport-Security deny all
> reply_header_replace Strict-Transport-Security max-age=0; includeSubDomains
> # Remove User-Agent from Vary
> reply_header_access Vary deny all
> reply_header_replace Vary Accept-Encoding
> # Workaround 4253
> request_header_access Surrogate-Capability deny all
> 
> # Block top level domains
> http_access deny block_tld
> deny_info TCP_RESET block_tld
> 
> # Rule allowing access from local networks
> http_access allow localnet
> http_access allow localhost
> 
> 
> # ICP/HTCP access
> icp_access allow localnet
> icp_access deny all
> htcp_access allow localnet
> htcp_access deny all
> 
> # 302 loop
> acl text_mime rep_mime_type text/html text/plain
> acl http302 http_status 302
> store_miss deny text_mime http302
> send_hit deny text_mime http302
> 
> # Windows updates rules
> http_access allow CONNECT wuCONNECT localnet
> http_access allow CONNECT wuCONNECT localhost
> http_access allow windowsupdate localnet
> http_access allow windowsupdate localhost
> 
> # SSL bump rules
> acl DiscoverSNIHost at_step SslBump1
> # ICQ/MRA must splice first
> acl NoSSLIntercept ssl::server_name_regex -i "/etc/squid/url.nobump"

> ssl_bump splice NoSSLIntercept
> ssl_bump bump net_bump

This will decrypt at step 1 using Squids CA and generated certificate.
*NO* details from the serverHello or the clientHello are available at
that point. The probablility of having problems is very high. The client
getting a TLS warning alert is almost guaranteed.


> acl tls_s3_server_hello at_step SslBump3
> 
> # TLS/SSL bumping steps

This is the second time you have a comment like that. This is a sign of
someone copy-n-pasting config snippets from many sources without
understanding what they do.
I also recognise pieces of three config examples myself and Yuri have
given over the past year to different people with *very* different
behaviours they needed out of the proxy.


> ssl_bump peek   tls_s1_connect      all      # peek at the incoming TLS/SSL
> connect data
> ssl_bump splice all                          # splice the stream:
> pass-through mode
> 

Not a good idea to put comments on lines with directives like that. Some
Squid versions and some individual directives do not support it and will
try to check any ACLs matching words in the comment.

BTW, HTTP authentication happening is not a problem in ssl_bump. You can
remove the "all" from that peek line.


> # And finally deny all other access to this proxy
> http_access deny all
> 
> # -------------------------------------
> # HTTP parameters
> # -------------------------------------
> # Local Privoxy is cache parent
> cache_peer 127.0.0.1 parent 8118 0 no-query no-digest default
> 
> cache_peer_access 127.0.0.1 deny all


WTF? what is the point of configuring a peer that nothing is ever
allowed to go through?

> 
> # Don't cache 404 long time
> negative_ttl 5 minutes
> positive_dns_ttl 15 hours
> negative_dns_ttl 1 minutes

Very likely the DNS problems created by altering these from the web
services own DNS TTL is part of your problem.


> 
> # -------------------------------------
> # Cache parameters
> # -------------------------------------
> # dhparams is before squid-3.5.12-20151222-r13967
> # tls-dh is AFTER squid-3.5.12-20151222-r13967
> #http_port 3126 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_certs/squid.crt
> key=/etc/squid/ssl_certs/squid.key options=NO_SSLv3
> tls-dh=/etc/squid/dhparam.pem
> http_port 3127
> http_port 3128 intercept
> # dhparams is before squid-3.5.12-20151222-r13967
> # tls-dh is AFTER squid-3.5.12-20151222-r13967
> https_port 3129 intercept ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_certs/squid.crt
> key=/etc/squid/ssl_certs/squid.key options=NO_SSLv3
> tls-dh=/etc/squid/dhparam.pem
> sslproxy_capath /etc/ssl/certs
> # SINGLE_DH_USE is 3.5 before squid-3.5.12-20151222-r13967
> #sslproxy_options NO_SSLv3,SINGLE_DH_USE
> # SINGLE_ECDH_USE is AFTER squid-3.5.12-20151222-r13967
> sslproxy_options NO_SSLv3,SINGLE_ECDH_USE
> sslproxy_cipher
> EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB
> 
> # Specify ICP/HTCP explicity
> icp_port 3130
> htcp_port 4827
> 
> # Cache manager
> cache_mgr mymail at gmail.com
> 
> 
> 
> # Forces reload-into-ims
> reload_into_ims on
> 
> # Hide internal networks details outside
> via off
> forwarded_for delete
> 
> # Do not show Squid version
> httpd_suppress_version_string on
> 
> 
> # Prioritization of local hits
> qos_flows tos local-hit=0x68
> 
> # Specify local DNS cache
> dns_nameservers 8.8.8.8
> 

This has been demonstrated as a very effective way to make all your
traffic turn into cache MISS' and go very slowly.

The requirements for interception are that the client and the proxy use
the same DNS resolver. This is needed to ensure the *same* results are
seen by both. Google have some fancy logic to detect different sources
of queries and return different results. You can see how this is going
to go wrong?

The best way to operate is to run a recursive resolver of your own. Make
the proxy use it and direct client DNS traffic through it as well.

If you want to Google DNS could be configured as an upstream resolver of
that. Though why you would need to make all your systems rely on access
to Google when you now have a properly functioning recursive resolver of
your own anyway is a puzzle.

> # Cacle squidinternal
> refresh_pattern -i video-srv\.youtube\.squidinternal    0    0%    0
> refresh_pattern -i squidinternal    14400    100%    518400 override-expire
> override-lastmod refresh-ims reload-into-ims ignore-private ignore-auth
> ignore-must-revalidate store-stale ignore-no-store

Using ignore-private and ignore-must-revalidate on the same
refresh_pattern is *extremely* dangerous. Just asking to get your cache
pwned.

Also ignore-auth makes things *not* be cacheable in all the auth related
cases when it would normally be stored by Squid.


> # Keep swf in cache
> refresh_pattern -i \.swf$    10080    100%    43200    override-expire
> reload-into-ims ignore-private
> # .NET cache
> refresh_pattern -i \.((a|m)s(h|p)x?)$        10080    100%    43200
> reload-into-ims ignore-private
> # Other long-lived items
> refresh_pattern -i
> \.(jp(e?g|e|2)|gif|png|bmp|ico|svg|web(p|m)|wm(v|a)|flv|f4f|mp(3|4)|ttf|eot|woff2?|(c|x|j)ss|js(t?|px?))(\?.*)?$
> 14400    100%    518400    override-expire override-lastmod reload-into-ims
> ignore-private ignore-no-store ignore-must-revalidate
> refresh_pattern -i
> \.((cs|d?|m?|p?|r?|s?|w?|x?|z?)h?t?m?(l?)|php(3?|5?)|rss|atom|vr(t|ml))(\?.*)?$
> 10080    100%    86400    override-expire override-lastmod reload-into-ims
> ignore-private ignore-no-store ignore-must-revalidate

see above.

> # Default patterns
> refresh_pattern -i (/cgi-bin/|\?)    0    0%    0
> refresh_pattern    .    0    20%    4320    reload-into-ims
> 
> ------------------------- Squid Configuration End
> ----------------------------------------------
> 
> When we give Network Connection Dirtectly through the Router then Internet
> is working fine but when we pass the Network through Squid the Internet
> work very slow .......

Be aware that Squid is doing some, and possibly a lot of extra
processing on each and every packet. Raw speed gain is not one of the
benefits of an intercepting proxy. Which is why accel(erator) mode is
something entirely different.


> 
> ---------------- IPTables ---------------------
> 
> Chain PREROUTING (policy ACCEPT 25461 packets, 3444K bytes)
>  pkts bytes target     prot opt in     out     source
> destination
>   996 55869 DNAT       tcp  --  eth1   *       0.0.0.0/0
> 0.0.0.0/0            tcp dpt:80 to:192.168.0.200:3128
>     0     0 REDIRECT   tcp  --  eth0   *       0.0.0.0/0
> 0.0.0.0/0            tcp dpt:80 redir ports 3128
>  3597  211K DNAT       tcp  --  eth1   *       0.0.0.0/0
> 0.0.0.0/0            tcp dpt:443 to:192.168.0.200:3129
>     0     0 REDIRECT   tcp  --  eth0   *       0.0.0.0/0
> 0.0.0.0/0            tcp dpt:443 redir ports 3129

NP: your "REDIRECT" rules are not doing anything because you have DNAT
rules that do the same thing(s) to the same packets beforehand.
 DNAT or REDIRECT - pick one.

> 
> ---------------------------------------------------------------------------------------------------------------------------------
> Access Logs:
> 1463478680.312  33025 192.168.0.66 TCP_TUNNEL/200 3865 CONNECT
> 216.58.199.165:443 - ORIGINAL_DST/216.58.199.165 -

a) A TLS connection to 216.58.199.165:443 was intercepted.
b) It was allowed into the proxy ("http_access allow localnet").
c.1) "splice NoSSLIntercept" matched
OR,
c.2) no SNI was present and "splice all" matched.

What were you expecting?

> 1463478686.862     40 192.168.0.66 TCP_REFRESH_MODIFIED/200 539 GET
> http://kerastasesalonlocator.com/ - ORIGINAL_DST/103.21.58.154 text/html
> 1463478686.880      5 192.168.0.66 TCP_MISS_ABORTED/000 0 GET
> http://kerastasesalonlocator.com/cgi-sys/defaultwebpage.cgi - ORIGINAL_DST/
> 103.21.58.154 -

Client aborted after just 5 milliseconds. Would not seem to be a problem
unless it happens a lot. And probably not a Squid problem even then.

> -----------------------------------------------------------------------------------------------------------------------------------------
> 
> 
> We have installed Squid on Ubuntu Server 14.04  Ram: 32 GB HDD: 1TB
> 


Amos



From squid3 at treenet.co.nz  Wed May 18 12:43:37 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 19 May 2016 00:43:37 +1200
Subject: [squid-users] squid_ldap_auth: WARNING,
 LDAP search error 'Referral'
In-Reply-To: <1ecfa5a9a05f463bae92e207c19db65c@AU-EXCH13-4.ap.uis.unisys.com>
References: <1ecfa5a9a05f463bae92e207c19db65c@AU-EXCH13-4.ap.uis.unisys.com>
Message-ID: <e29e2496-740f-1ae9-9958-2c3878919e8f@treenet.co.nz>

On 19/05/2016 12:25 a.m., Manduva, Ranga Sai wrote:
> Hi,
> 
> Does anyone had similar issue ?? Is there any workaround for it ? Something like configure squid to follow referral etc..
> 

Squid has nothing to do with those layers of operations. The closest it
gets is to pass the helper command line options when it starts.

I can suggest that you try an upgrade though. The Squid bundled helper
has not had that name in many years. So it could be one of the bugs
fixed already.

Amos



From belle at bazuin.nl  Wed May 18 12:50:34 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 18 May 2016 14:50:34 +0200
Subject: [squid-users] squid_ldap_auth: WARNING,
 LDAP search error 'Referral'
In-Reply-To: <e29e2496-740f-1ae9-9958-2c3878919e8f@treenet.co.nz>
References: <1ecfa5a9a05f463bae92e207c19db65c@AU-EXCH13-4.ap.uis.unisys.com>
Message-ID: <vmime.573c651a.1c31.36cea7b639649dba@ms249-lin-003.rotterdam.bazuin.nl>

This has probely todo with the latest samba/windows updates.
But your giving so little info. 

You can confirm it by testing the ldap. Connect to ldaps (port 636).
Does that work? No, try adding in /etc/ldap/ldap.conf

TLS_REQCERT allow 

And make sure your AD Root CA cert is know in :
TLS_CACERT      /etc/ssl/certs/ca-certificates.crt 
( or point above to your AD Root CA cert. ) 


Greetz, 

Louis

> -----Oorspronkelijk bericht-----
> Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens
> Amos Jeffries
> Verzonden: woensdag 18 mei 2016 14:44
> Aan: squid-users at lists.squid-cache.org
> Onderwerp: Re: [squid-users] squid_ldap_auth: WARNING, LDAP search error
> 'Referral'
> 
> On 19/05/2016 12:25 a.m., Manduva, Ranga Sai wrote:
> > Hi,
> >
> > Does anyone had similar issue ?? Is there any workaround for it ?
> Something like configure squid to follow referral etc..
> >
> 
> Squid has nothing to do with those layers of operations. The closest it
> gets is to pass the helper command line options when it starts.
> 
> I can suggest that you try an upgrade though. The Squid bundled helper
> has not had that name in many years. So it could be one of the bugs
> fixed already.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From se at kpa.gr  Wed May 18 14:14:12 2016
From: se at kpa.gr (se at kpa.gr)
Date: Wed, 18 May 2016 16:14:12 +0200
Subject: [squid-users] Transparent Mode w/ Peek and Splice trouble
Message-ID: <b9a3486352a7beafc5a439c75cbbbdc0@kpa.gr>

Hello!

I am currently setting up a squid server, which should serve as a 
transparent proxy in our network.

We mainly need it to do the following:
Allow and Block Domains on HTTP and HTTPS protocol (withOUT bumping the 
traffic). We only want to allow domain names on the SSL port, no URLs.

It actually works fine for HTTP, but I can't configure the "peek and 
splice" method for the HTTPS traffic.

I have come to a point, where HTTP access is being filtered exactly as I 
wanted to, but following odd error occures when visiting HTTPS sites:

When using "https_port 10.0.0.222:3130 cert=/root/cert.pem 
key=/root/key.pem ssl-bump intercept"
I get an Access Denied Error for any Website I try to access, which 
occured while "trying to retrieve the URL: 10.0.0.222:3130"!

If I configure the https_port option with "accel vhost allow-direct" 
like the http_port, the allowed Pages work fine but with squid's 
certificate.


Somewhere the Squid seems to redirect his actual https traffic back to 
itself when using the "intercept" option and that is why I cannot use 
the splice method.

You can find my configuration files on http://kpa.gr/squid-conf/

Thanks very much in advance,

Pantelis W


From garryd at comnet.uz  Wed May 18 14:21:10 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Wed, 18 May 2016 19:21:10 +0500
Subject: [squid-users] Internet Browsing very slow after implementing
 Squid peek & splice + Access log not tracing full URL
In-Reply-To: <cc51a531-9d11-d8cc-17c8-34e06a4105f5@treenet.co.nz>
References: <CAKQSiAUtj3m0V7-_dn6+SUAzbSdrtmA=FHSOaP1yUhLS8gKRDA@mail.gmail.com>
 <cc51a531-9d11-d8cc-17c8-34e06a4105f5@treenet.co.nz>
Message-ID: <1463581270.3633.13.camel@comnet.uz>

On Thu, 2016-05-19 at 00:39 +1200, Amos Jeffries wrote:
> Using ignore-private and ignore-must-revalidate on the same
> refresh_pattern is *extremely* dangerous. Just asking to get your
> cache pwned.

I'm also using the both options on the same refresh_pattern for several
years. Can you explain the consequences? I couldn't find enough
information in Squid's reference and RFC2616. Thanks in advance!


> Also ignore-auth makes things *not* be cacheable in all the auth
> related cases when it would normally be stored by Squid.

I always thought that the purpose of the option is exact opposite.
Squid's reference any trivial test confirmed my thoughts. Sorry, but
maybe I understood the quote incorrectly?


Garri


From rousskov at measurement-factory.com  Wed May 18 14:37:40 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 18 May 2016 08:37:40 -0600
Subject: [squid-users] Internet Browsing very slow after implementing
 Squid peek & splice + Access log not tracing full URL
In-Reply-To: <CAKQSiAUtj3m0V7-_dn6+SUAzbSdrtmA=FHSOaP1yUhLS8gKRDA@mail.gmail.com>
References: <CAKQSiAUtj3m0V7-_dn6+SUAzbSdrtmA=FHSOaP1yUhLS8gKRDA@mail.gmail.com>
Message-ID: <573C7E34.1010309@measurement-factory.com>

On 05/18/2016 05:05 AM, Sagar Malve wrote:

> when we pass the Network through Squid the
> Internet work very slow 


In addition to other comments on this thread, please note that,
according to my _ballpark_ estimates, Squid "ssl_bump bump" performance
is about 10% of regular plain traffic forwarding performance and
"ssl_bump splice step2" performance is about 30%.

FWIW, we are working on significantly improving the latter:

  http://lists.squid-cache.org/pipermail/squid-dev/2016-May/005659.html
  http://lists.squid-cache.org/pipermail/squid-dev/2016-May/005660.html


HTH,

Alex.



From jlay at slave-tothe-box.net  Wed May 18 15:19:25 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Wed, 18 May 2016 09:19:25 -0600
Subject: [squid-users] Transparent Mode w/ Peek and Splice trouble
In-Reply-To: <b9a3486352a7beafc5a439c75cbbbdc0@kpa.gr>
References: <b9a3486352a7beafc5a439c75cbbbdc0@kpa.gr>
Message-ID: <8e5ca69e93e105313dec07b3d9ce836c@localhost>

On 2016-05-18 08:14, se at kpa.gr wrote:
> Hello!
> 
> I am currently setting up a squid server, which should serve as a
> transparent proxy in our network.
> 
> We mainly need it to do the following:
> Allow and Block Domains on HTTP and HTTPS protocol (withOUT bumping
> the traffic). We only want to allow domain names on the SSL port, no
> URLs.
> 
> It actually works fine for HTTP, but I can't configure the "peek and
> splice" method for the HTTPS traffic.
> 
> I have come to a point, where HTTP access is being filtered exactly as
> I wanted to, but following odd error occures when visiting HTTPS
> sites:
> 
> When using "https_port 10.0.0.222:3130 cert=/root/cert.pem
> key=/root/key.pem ssl-bump intercept"
> I get an Access Denied Error for any Website I try to access, which
> occured while "trying to retrieve the URL: 10.0.0.222:3130"!
> 
> If I configure the https_port option with "accel vhost allow-direct"
> like the http_port, the allowed Pages work fine but with squid's
> certificate.
> 
> 
> Somewhere the Squid seems to redirect his actual https traffic back to
> itself when using the "intercept" option and that is why I cannot use
> the splice method.
> 
> You can find my configuration files on http://kpa.gr/squid-conf/
> 
> Thanks very much in advance,
> 
> Pantelis W
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


Read:

http://thread.gmane.org/gmane.comp.web.squid.general/114384/focus=114389

I'm doing exactly what you're wanting.

James


From squid3 at treenet.co.nz  Wed May 18 16:46:04 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 19 May 2016 04:46:04 +1200
Subject: [squid-users] Transparent Mode w/ Peek and Splice trouble
In-Reply-To: <b9a3486352a7beafc5a439c75cbbbdc0@kpa.gr>
References: <b9a3486352a7beafc5a439c75cbbbdc0@kpa.gr>
Message-ID: <b15d9e00-a416-fbd3-3833-dfead5576b45@treenet.co.nz>

On 19/05/2016 2:14 a.m., se at kpa.gr wrote:
> Hello!
> 
> I am currently setting up a squid server, which should serve as a
> transparent proxy in our network.
> 
> We mainly need it to do the following:
> Allow and Block Domains on HTTP and HTTPS protocol (withOUT bumping the
> traffic). We only want to allow domain names on the SSL port, no URLs.
> 
> It actually works fine for HTTP, but I can't configure the "peek and
> splice" method for the HTTPS traffic.
> 
> I have come to a point, where HTTP access is being filtered exactly as I
> wanted to, but following odd error occures when visiting HTTPS sites:
> 
> When using "https_port 10.0.0.222:3130 cert=/root/cert.pem
> key=/root/key.pem ssl-bump intercept"
> I get an Access Denied Error for any Website I try to access, which
> occured while "trying to retrieve the URL: 10.0.0.222:3130"!
> 

It appears you are not doing NAT on the Squid machine. That is mandatory
for interception.


> If I configure the https_port option with "accel vhost allow-direct"
> like the http_port, the allowed Pages work fine but with squid's
> certificate.

'accel' mode is very much *not* transparent, nor equivalent to intercept
mode.

Using 'accel' mode tells Squid *it* is supposed to be the public origin
server for the received web request. The behaviour differences are not
very visible in plain-text HTTP - though there are some. In TLS the
differences are very much visible in the way the certificates are used.
Which you are now seeing.

> 
> Somewhere the Squid seems to redirect his actual https traffic back to
> itself when using the "intercept" option and that is why I cannot use
> the splice method.

'intercept' mode tells Squid to lookup the NAT details and obey the
requirements of acting "transparent" with regards to traffic delivery.
Delivering it to the same place it was originally going to when it
entered the machine.

If you are doing NAT external to the Squid machine it is your NAT setup
which is causing the problem. Not Squid.


Your message reads to me like Squid is behaving correctly for the modes
of operation you configured it to follow.

You need to fix the NAT setup. Route or tunnel the trafic to the Squid
machine and do the NAT there. Then intercept and SSL-Bump will start
working, for both http_port and https_port.

Amos



From squid3 at treenet.co.nz  Wed May 18 17:27:53 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 19 May 2016 05:27:53 +1200
Subject: [squid-users] Internet Browsing very slow after implementing
 Squid peek & splice + Access log not tracing full URL
In-Reply-To: <1463581270.3633.13.camel@comnet.uz>
References: <CAKQSiAUtj3m0V7-_dn6+SUAzbSdrtmA=FHSOaP1yUhLS8gKRDA@mail.gmail.com>
 <cc51a531-9d11-d8cc-17c8-34e06a4105f5@treenet.co.nz>
 <1463581270.3633.13.camel@comnet.uz>
Message-ID: <bd8b242b-0fb7-9504-54cd-ff922a3c73ca@treenet.co.nz>

On 19/05/2016 2:21 a.m., Garri Djavadyan wrote:
> On Thu, 2016-05-19 at 00:39 +1200, Amos Jeffries wrote:
>> Using ignore-private and ignore-must-revalidate on the same
>> refresh_pattern is *extremely* dangerous. Just asking to get your
>> cache pwned.
> 
> I'm also using the both options on the same refresh_pattern for several
> years. Can you explain the consequences? I couldn't find enough
> information in Squid's reference and RFC2616. Thanks in advance!
> 

The 'private' cache-control is supposed to only be used when the
response contains sensitive credentials or private data.

ignore-private has a long history of causing (not allowing. *causing*)
people to login to other peoples accounts on various services. One might
have heard about the recent Steam account login having "an issue with
our proxy settings". I'd bet a lot it was somebody turing on
"ignore-private" or the equivalent in their systems.

With the HTTP/1.1 changes I made it tell Squid to treat 'private' the
same as 'must-revalidate', so that private stuff could still be forced
to cache but much more safely.

Ignoring both brings back all the security and privacy breach problems.

One should not be afraid of revalidation. It is the backbone of most of
the mechanisms that make HTTP/1.1 more performant than 1.0.

So IMO, stay away from ignore-private like it was plague. If you really
have a reason to use it. At least dont use ignore-revalidate on the same
traffic.

(I've similar advice for ignore-no-store. But at least no-store does not
have the same security/privacy/credentials tie-in as private.)

> 
>> Also ignore-auth makes things *not* be cacheable in all the auth
>> related cases when it would normally be stored by Squid.
> 
> I always thought that the purpose of the option is exact opposite.
> Squid's reference any trivial test confirmed my thoughts. Sorry, but
> maybe I understood the quote incorrectly?
> 

It tells Squid to ignore the auth headers in a request.

In HTTP/1.0 messages the presence of auth meant the object was
non-cacheable due to sensitive credentials. So the control let people
make that traffic cache.

In HTTP/1.1 messages the presence of auth is often equivalent to
must-revalidate. So ignoring the headers makes the alternative controls
in the headers kick in and force non-caching. The opposite of what is
usually intended.


(FYI: both ignore-auth and ignore-must-revalidate are gone in Squid-4.
For the above reasons.)

Amos



From emz at norma.perm.ru  Wed May 18 18:11:01 2016
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Wed, 18 May 2016 23:11:01 +0500
Subject: [squid-users] ext_kerberos_ldap_group_acl and Kerberos cache
In-Reply-To: <43025b84-9ea4-16e6-a81c-eb153ac498b0@treenet.co.nz>
References: <573C0448.5020900@norma.perm.ru>
 <43025b84-9ea4-16e6-a81c-eb153ac498b0@treenet.co.nz>
Message-ID: <573CB035.1070307@norma.perm.ru>

Hi.

On 18.05.2016 16:29, Amos Jeffries wrote:
>
> I don't know what you mean by "the main tree". But The feature you
> describe does not qualify for adding to the 3.5 production release
> series. The only features added to a series after is goes to "stable"
> production releases are ones which resolve non-feature bugs or can be
> done without affecting existing installations.
Well, you can treat kerberos cache in the kerberos group ACL helper as 
both. It doesn't affect current installations in any way: neither it 
doesn't change the configuration syntax, nor adds new caveats. In the 
same way it can be considered as a bugfix: as far as I know it was 
supposed to exist in the helper from the start, but was misimplemented. 
All it adds is the cache: it caches the credentials up to their TTL, 
which is defined by the ticket (not by squid, not by helper).
> By changing the helper behaviour in all cases this clearly affects
> existing installations. So only qualifies for including into the next
> series, which is Squid-4.
It doesn't change helper behaviour, it fixes it.

Eugene.


From rworsnop at gmail.com  Wed May 18 21:56:06 2016
From: rworsnop at gmail.com (Rob Worsnop)
Date: Wed, 18 May 2016 17:56:06 -0400
Subject: [squid-users] Problem talking ICAP to McAfee Web Gateway
Message-ID: <CAMiSdg7GhKurqWmidbcBEavtQPhv7rt3S3C0zj+QpDPiATMeaQ@mail.gmail.com>

I'm having  a problem talking ICAP with McAfee Web Gateway (MWG).

In certain circumstances, MWG will start streaming the RESPMOD response
before Squid has finished sending all the chunks in the RESPMOD request.

Squid does not like this. It seems to interpret the arrival of response
traffic as a signal that the request should have finished. So it stops
reading from the origin resource, and consequently stops writing to MWG.
The result is that the HTTP client sees only a fraction of the file it's
requested.

As far as I can tell, ICAP is no different from HTTP in that it expects a
response to follow a request, not the request and response to be
transmitted at the same time in a full-duplex style.

Are my assumptions correct, and is this Squid behavior by design? If so I'm
going to have take it up with the McAfee people.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160518/402fc56a/attachment.htm>

From rousskov at measurement-factory.com  Wed May 18 22:46:22 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 18 May 2016 16:46:22 -0600
Subject: [squid-users] Problem talking ICAP to McAfee Web Gateway
In-Reply-To: <CAMiSdg7GhKurqWmidbcBEavtQPhv7rt3S3C0zj+QpDPiATMeaQ@mail.gmail.com>
References: <CAMiSdg7GhKurqWmidbcBEavtQPhv7rt3S3C0zj+QpDPiATMeaQ@mail.gmail.com>
Message-ID: <573CF0BE.5070207@measurement-factory.com>

On 05/18/2016 03:56 PM, Rob Worsnop wrote:

> In certain circumstances, MWG will start streaming the RESPMOD response
> before Squid has finished sending all the chunks in the RESPMOD request.
> 
> Squid does not like this.

If Squid does not like this, it is a Squid bug IMO.


> As far as I can tell, ICAP is no different from HTTP 

In both protocols, a server may start sending the response before the
entire request has been received, and a robust client implementation
ought to accept such "early" responses even if the protocol does not
explicitly require their support. An early response has to comply with
all the other protocol rules, of course, but there are cases where such
compliance is not a problem.

In HTTP, early responses are usually errors because the server is
unlikely to know that the request will be successful until seeing the
end of the request.

In ICAP, early responses are much more useful (and common) because an
ICAP server can "pipeline" the HTTP message back to the ICAP client,
drastically reducing message buffering requirements and user delays.
IIRC, Squid used to support early responses well.


HTH,

Alex.



From garryd at comnet.uz  Thu May 19 04:12:40 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Thu, 19 May 2016 09:12:40 +0500
Subject: [squid-users] Internet Browsing very slow after implementing
 Squid peek & splice + Access log not tracing full URL
In-Reply-To: <bd8b242b-0fb7-9504-54cd-ff922a3c73ca@treenet.co.nz>
References: <CAKQSiAUtj3m0V7-_dn6+SUAzbSdrtmA=FHSOaP1yUhLS8gKRDA@mail.gmail.com>
 <cc51a531-9d11-d8cc-17c8-34e06a4105f5@treenet.co.nz>
 <1463581270.3633.13.camel@comnet.uz>
 <bd8b242b-0fb7-9504-54cd-ff922a3c73ca@treenet.co.nz>
Message-ID: <1463631160.3294.2.camel@comnet.uz>

On Thu, 2016-05-19 at 05:27 +1200, Amos Jeffries wrote:
> On 19/05/2016 2:21 a.m., Garri Djavadyan wrote:
> > 
> > On Thu, 2016-05-19 at 00:39 +1200, Amos Jeffries wrote:
> > > 
> > > Using ignore-private and ignore-must-revalidate on the same
> > > refresh_pattern is *extremely* dangerous. Just asking to get your
> > > cache pwned.
> > I'm also using the both options on the same refresh_pattern for
> > several
> > years. Can you explain the consequences? I couldn't find enough
> > information in Squid's reference and RFC2616. Thanks in advance!
> > 
> The 'private' cache-control is supposed to only be used when the
> response contains sensitive credentials or private data.
> 
> ignore-private has a long history of causing (not allowing.
> *causing*)
> people to login to other peoples accounts on various services. One
> might
> have heard about the recent Steam account login having "an issue with
> our proxy settings". I'd bet a lot it was somebody turing on
> "ignore-private" or the equivalent in their systems.
> 
> With the HTTP/1.1 changes I made it tell Squid to treat 'private' the
> same as 'must-revalidate', so that private stuff could still be
> forced
> to cache but much more safely.
> 
> Ignoring both brings back all the security and privacy breach
> problems.
> 
> One should not be afraid of revalidation. It is the backbone of most
> of
> the mechanisms that make HTTP/1.1 more performant than 1.0.
> 
> So IMO, stay away from ignore-private like it was plague. If you
> really
> have a reason to use it. At least dont use ignore-revalidate on the
> same
> traffic.
> 
> (I've similar advice for ignore-no-store. But at least no-store does
> not
> have the same security/privacy/credentials tie-in as private.)
> 
> > 
> > 
> > > 
> > > Also ignore-auth makes things *not* be cacheable in all the auth
> > > related cases when it would normally be stored by Squid.
> > I always thought that the purpose of the option is exact opposite.
> > Squid's reference any trivial test confirmed my thoughts. Sorry,
> > but
> > maybe I understood the quote incorrectly?
> > 
> It tells Squid to ignore the auth headers in a request.
> 
> In HTTP/1.0 messages the presence of auth meant the object was
> non-cacheable due to sensitive credentials. So the control let people
> make that traffic cache.
> 
> In HTTP/1.1 messages the presence of auth is often equivalent to
> must-revalidate. So ignoring the headers makes the alternative
> controls
> in the headers kick in and force non-caching. The opposite of what is
> usually intended.
> 
> 
> (FYI: both ignore-auth and ignore-must-revalidate are gone in Squid-
> 4.
> For the above reasons.)
> 
> Amos

Amos, thank you very much for the clarification!


From sagarmalve91 at gmail.com  Thu May 19 11:08:19 2016
From: sagarmalve91 at gmail.com (Sagar Malve)
Date: Thu, 19 May 2016 16:38:19 +0530
Subject: [squid-users] Internet Browsing very slow after implementing
 Squid peek & splice + Access log not tracing full URL
In-Reply-To: <573C7E34.1010309@measurement-factory.com>
References: <CAKQSiAUtj3m0V7-_dn6+SUAzbSdrtmA=FHSOaP1yUhLS8gKRDA@mail.gmail.com>
 <573C7E34.1010309@measurement-factory.com>
Message-ID: <CAKQSiAWC_QHwxqCFH24=D7VPi_xB+DQPwh9t3+kJ7BEWGeAo3g@mail.gmail.com>

Hi Team,

I have done some modification as per thread and temporary removed Refresh
pattern and have kept the Default refresh pattern ...

This is how my Configuration looks like .....



# -------------------------------------
# Access Control Lists
# -------------------------------------
acl localnet src 192.168.0.0/24    # RFC1918 possible internal network

acl SSL_ports port 443
acl SSL_ports port 8443        # Telecom exclusion
acl Safe_ports port 80        # http
acl Safe_ports port 21        # ftp
acl Safe_ports port 443        # https
acl Safe_ports port 70        # gopher
acl Safe_ports port 210        # wais
acl Safe_ports port 280        # http-mgmt
acl Safe_ports port 488        # gss-http
acl Safe_ports port 591        # filemaker
acl Safe_ports port 777        # multiling http

# Common methods
acl CONNECT method CONNECT
acl PURGE method PURGE
acl GET method GET

# Windows update acls
acl windowsupdate dstdomain sls.update.microsoft.com.akadns.net
acl windowsupdate dstdomain windowsupdate.microsoft.com
acl windowsupdate dstdomain .update.microsoft.com
acl windowsupdate dstdomain download.windowsupdate.com
acl windowsupdate dstdomain redir.metaservices.microsoft.com
acl windowsupdate dstdomain images.metaservices.microsoft.com
acl windowsupdate dstdomain c.microsoft.com
acl windowsupdate dstdomain www.download.windowsupdate.com
acl windowsupdate dstdomain wustat.windows.com
acl windowsupdate dstdomain crl.microsoft.com
acl windowsupdate dstdomain sls.microsoft.com
acl windowsupdate dstdomain productactivation.one.microsoft.com
acl windowsupdate dstdomain ntservicepack.microsoft.com

# Windows update methods
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com


# SSL bump acl
acl net_bump src "/etc/squid/net.bump"

# TLD acl
acl block_tld url_regex "/etc/squid/dstdom.tld"

# -------------------------------------
# Access parameters
# -------------------------------------
# Deny requests to unsafe ports
http_access deny !Safe_ports
# Deny CONNECT to other than SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager
http_access deny to_localhost
# Allow purge from localhost
http_access allow PURGE localhost
http_access deny PURGE


# Block top level domains
http_access deny block_tld
deny_info TCP_RESET block_tld

# Rule allowing access from local networks
http_access allow localnet
http_access allow localhost


# ICP/HTCP access
icp_access allow localnet
icp_access deny all
htcp_access allow localnet
htcp_access deny all

# 302 loop
acl text_mime rep_mime_type text/html text/plain
acl http302 http_status 302
store_miss deny text_mime http302
send_hit deny text_mime http302

# Windows updates rules
http_access allow CONNECT wuCONNECT localnet
http_access allow CONNECT wuCONNECT localhost
http_access allow windowsupdate localnet
http_access allow windowsupdate localhost

# SSL bump rules
acl DiscoverSNIHost at_step SslBump1
# ICQ/MRA must splice first
acl NoSSLIntercept ssl::server_name_regex -i "/etc/squid/url.nobump"
ssl_bump splice NoSSLIntercept
ssl_bump bump net_bump
acl tls_s1_connect      at_step SslBump1
acl tls_s3_server_hello at_step SslBump3

# TLS/SSL bumping steps
ssl_bump peek   tls_s1_connect        # peek at the incoming TLS/SSL
connect data
ssl_bump splice all                          # splice the stream:
pass-through mode

# And finally deny all other access to this proxy
http_access deny all

# -------------------------------------
# HTTP parameters
# -------------------------------------

# dhparams is before squid-3.5.12-20151222-r13967
# tls-dh is AFTER squid-3.5.12-20151222-r13967
http_port 3127
http_port 3128 intercept
# dhparams is before squid-3.5.12-20151222-r13967
# tls-dh is AFTER squid-3.5.12-20151222-r13967
https_port 3129 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_certs/squid.crt
key=/etc/squid/ssl_certs/squid.key options=NO_SSLv3
tls-dh=/etc/squid/dhparam.pem
sslproxy_capath /etc/ssl/certs
# SINGLE_DH_USE is 3.5 before squid-3.5.12-20151222-r13967
#sslproxy_options NO_SSLv3,SINGLE_DH_USE
# SINGLE_ECDH_USE is AFTER squid-3.5.12-20151222-r13967
sslproxy_options NO_SSLv3,SINGLE_ECDH_USE
sslproxy_cipher
EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:HIGH:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/squid/ssl_db -M 4MB


# Cache manager
cache_mgr mymail at gmail.com



# Forces reload-into-ims
reload_into_ims on

# Hide internal networks details outside
via off
forwarded_for delete

# Do not show Squid version
httpd_suppress_version_string on


# Prioritization of local hits
qos_flows tos local-hit=0x68

# Specify local DNS cache
dns_nameservers 8.8.8.8

dns_v4_first on
ipcache_size 4096


# -------------------------------------
# Memory parameters
# -------------------------------------
cache_mem 512 Mb

#memory_pools off

maximum_object_size_in_memory 1 MB

# -------------------------------------
# Tuning parameters
# -------------------------------------
memory_replacement_policy heap LRU
cache_replacement_policy heap LFUDA

store_avg_object_size 85 KB
# Default is 20
store_objects_per_bucket 32

# Shutdown delay before terminate connections
shutdown_lifetime 15 second

# SMP
#workers 2

# -------------------------------------
# Store parameters
# -------------------------------------
maximum_object_size 8 Gb

cache_dir aufs /usr/local/cache 250000 16 256

# -------------------------------------
# Process/log parameters
# -------------------------------------
#logformat my_squid %tl %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un %Sh/%<a %mt
access_log daemon:/var/log/squid/access.log buffer-size=256KB
# Don't log ICP queries
log_icp_queries off

# Turn off internal log rotation
logfile_rotate 0

cache_log /var/log/squid/cache.log
cache_store_log none

# Default is off
buffered_logs on

coredump_dir /var/core

pid_filename /tmp/squid.pid

strip_query_terms off

# -------------------------------------
# Content parameters
# -------------------------------------
range_offset_limit none all

# Default patterns
refresh_pattern -i (/cgi-bin/|\?)    0    0%    0
refresh_pattern    .    0    20%    4320    reload-into-ims


-------------Config End ---------------

------------net.bump File -------------------

google.com
youtube.com
reddit.com
-------------------------------

------------dstdom.tld file --------------

yahoo.com
facebook.com

---------------------------------------


--------------- Url.nobump--------

axisbank.com
hdfcbank.com

------------------------------------------


Now issue is that I need to block yahoo and facebook but I am able to
access the facebook website and yahoo is getting blocked ....

And also all Google website like google, gmail, youtube are working very
slow it takes lots of time to load this websites but other Https websites
like axisbank / hdfc etc are working properly ....

Also somtime website does not work with Chrome browser like Gmail but same
is working in Mozilla Firefox but take time to load ......



On Wed, May 18, 2016 at 8:07 PM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 05/18/2016 05:05 AM, Sagar Malve wrote:
>
> > when we pass the Network through Squid the
> > Internet work very slow
>
>
> In addition to other comments on this thread, please note that,
> according to my _ballpark_ estimates, Squid "ssl_bump bump" performance
> is about 10% of regular plain traffic forwarding performance and
> "ssl_bump splice step2" performance is about 30%.
>
> FWIW, we are working on significantly improving the latter:
>
>   http://lists.squid-cache.org/pipermail/squid-dev/2016-May/005659.html
>   http://lists.squid-cache.org/pipermail/squid-dev/2016-May/005660.html
>
>
> HTH,
>
> Alex.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160519/c24fde19/attachment.htm>

From squid3 at treenet.co.nz  Thu May 19 12:03:07 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 May 2016 00:03:07 +1200
Subject: [squid-users] Internet Browsing very slow after implementing
 Squid peek & splice + Access log not tracing full URL
In-Reply-To: <CAKQSiAWC_QHwxqCFH24=D7VPi_xB+DQPwh9t3+kJ7BEWGeAo3g@mail.gmail.com>
References: <CAKQSiAUtj3m0V7-_dn6+SUAzbSdrtmA=FHSOaP1yUhLS8gKRDA@mail.gmail.com>
 <573C7E34.1010309@measurement-factory.com>
 <CAKQSiAWC_QHwxqCFH24=D7VPi_xB+DQPwh9t3+kJ7BEWGeAo3g@mail.gmail.com>
Message-ID: <085dc4db-d597-08d3-9f90-537e3b8cc717@treenet.co.nz>

On 19/05/2016 11:08 p.m., Sagar Malve wrote:
> Hi Team,
> 
> I have done some modification as per thread and temporary removed Refresh
> pattern and have kept the Default refresh pattern ...
> 
> This is how my Configuration looks like .....
> 
> 

> # SSL bump acl
> acl net_bump src "/etc/squid/net.bump"
> 
> # TLD acl
> acl block_tld url_regex "/etc/squid/dstdom.tld"
> 

You called the file "dstdom", but it is not a dstdomain ACL type.

To match when the domain is listed in the path or query string sections
of URL this is right as-is. Though it would be worth making a note of
that in the config so it doesn't get undone.


To match only the URL domain section with regex use dstdom_regex as the
ACL type. Or, since the unknown part of the listed domains is all the
sub-domain section. Use dstdomain which is faster.


> 
> # Block top level domains
> http_access deny block_tld
> deny_info TCP_RESET block_tld
> 
> # Rule allowing access from local networks
> http_access allow localnet
> http_access allow localhost
> 

Notice how localnet and localhost are allowed through the proxy above
without any further ACL conditions.

That means the below "Windows Update rules" have nothing to do and never
match any request which reaches them. You can remove.

> # Windows updates rules
> http_access allow CONNECT wuCONNECT localnet
> http_access allow CONNECT wuCONNECT localhost
> http_access allow windowsupdate localnet
> http_access allow windowsupdate localhost


> 
> # SSL bump rules
> acl DiscoverSNIHost at_step SslBump1

DiscoverSNIHost is never being used. You can remove it.

> # ICQ/MRA must splice first
> acl NoSSLIntercept ssl::server_name_regex -i "/etc/squid/url.nobump"
> ssl_bump splice NoSSLIntercept
> ssl_bump bump net_bump
> acl tls_s1_connect      at_step SslBump1
> acl tls_s3_server_hello at_step SslBump3
> 

tls_s3_server_hello is never being used. You can remove it.

> # TLS/SSL bumping steps
> ssl_bump peek   tls_s1_connect        # peek at the incoming TLS/SSL
> connect data
> ssl_bump splice all                          # splice the stream:
> pass-through mode
> 
> # And finally deny all other access to this proxy
> http_access deny all
>

<snip>

> -------------Config End ---------------
> 
> ------------net.bump File -------------------
> 
> google.com
> youtube.com
> reddit.com

This file is being loaded into a 'src' ACL.

Firstly, why are the Google, YouTube, and Reddit servers making requests
through your proxy? they are your customers?

I think you meant 'dst' ACL for this. Your cutomers going *to* Google,
YouTube, or Reddit.


Secondly, the IP addresses of the listed hosts will be resolved on Squid
startup *only* (applies to both src and dst ACL types).

Any other IPs which the site rotates into its DNS RR set after the
single resolve that Squid does for config loading will not match.



> -------------------------------
> 
> ------------dstdom.tld file --------------
> 
> yahoo.com
> facebook.com
> 
> ---------------------------------------
> 
> 
> --------------- Url.nobump--------
> 
> axisbank.com
> hdfcbank.com
> 

This file is being used by an ACL which has nothing to do with URLs.
That name is really confusing.


> ------------------------------------------
> 
> 
> Now issue is that I need to block yahoo and facebook but I am able to
> access the facebook website and yahoo is getting blocked ....
> 

Hint: The facebook website does not always use the domain "facebook.com"
except in the URL part visible to people. Most people dont type URLs in
to their address bar anyway, so most access to FB will be through Google
etc. straight to the other domain name used for content display.


> And also all Google website like google, gmail, youtube are working very
> slow it takes lots of time to load this websites but other Https websites
> like axisbank / hdfc etc are working properly ....

Think about that. The domains that your net_bump ACL has told Squid to
bump (decrypt) are going slow, the ones you have told it to splice
(bypass decryption) are going "properly" (whatever that means).

> 
> Also somtime website does not work with Chrome browser like Gmail but same
> is working in Mozilla Firefox but take time to load ......
> 

1) Same as above.

2) Chrome is a Google app. It has the TLS certs for Gmail and other
Google services pinned (hard-coded) into it. If your Squid happens to
try decrypting its traffic without having the Squid CA custom installed
in a way that overrides that pinning, it refuses to work.

3) Sometimes (usually?) Chrome does not use HTTP or HTTPS to contact
Gmail and other Google properties. Even if the URL in the address bar
makes you think thats what its doing. There are 5 different protocols
that can be used to contact servers and fetch https:// URLs.


Amos



From yvoinov at gmail.com  Thu May 19 13:56:39 2016
From: yvoinov at gmail.com (Yuri)
Date: Thu, 19 May 2016 19:56:39 +0600
Subject: [squid-users] Internet Browsing very slow after implementing
 Squid peek & splice + Access log not tracing full URL
In-Reply-To: <085dc4db-d597-08d3-9f90-537e3b8cc717@treenet.co.nz>
References: <CAKQSiAUtj3m0V7-_dn6+SUAzbSdrtmA=FHSOaP1yUhLS8gKRDA@mail.gmail.com>
 <573C7E34.1010309@measurement-factory.com>
 <CAKQSiAWC_QHwxqCFH24=D7VPi_xB+DQPwh9t3+kJ7BEWGeAo3g@mail.gmail.com>
 <085dc4db-d597-08d3-9f90-537e3b8cc717@treenet.co.nz>
Message-ID: <33dd4adf-24bc-fd31-14f2-307397bd9580@gmail.com>



19.05.2016 18:03, Amos Jeffries ?????:
> On 19/05/2016 11:08 p.m., Sagar Malve wrote:
>> Hi Team,
>>
>> I have done some modification as per thread and temporary removed Refresh
>> pattern and have kept the Default refresh pattern ...
>>
>> This is how my Configuration looks like .....
>>
>>
>> # SSL bump acl
>> acl net_bump src "/etc/squid/net.bump"
>>
>> # TLD acl
>> acl block_tld url_regex "/etc/squid/dstdom.tld"
>>
> You called the file "dstdom", but it is not a dstdomain ACL type.
>
> To match when the domain is listed in the path or query string sections
> of URL this is right as-is. Though it would be worth making a note of
> that in the config so it doesn't get undone.
>
>
> To match only the URL domain section with regex use dstdom_regex as the
> ACL type. Or, since the unknown part of the listed domains is all the
> sub-domain section. Use dstdomain which is faster.
NB: Original ACL was:

# TLD acl
acl block_tld dstdomain "/usr/local/squid/etc/dstdom.tld"

NB2: This is brainless copy-n-paste from my config I've accidentally 
shared here in the past.

NB3: facebook.com (and etc.) is NOT TLD (Top Level Domain). This is 
SECOND level domain. Originally this part of my config uses for block 
REAL TLD, like .tv, .xxx.
>
>
>> # Block top level domains
>> http_access deny block_tld
>> deny_info TCP_RESET block_tld
>>
>> # Rule allowing access from local networks
>> http_access allow localnet
>> http_access allow localhost
>>
> Notice how localnet and localhost are allowed through the proxy above
> without any further ACL conditions.
>
> That means the below "Windows Update rules" have nothing to do and never
> match any request which reaches them. You can remove.
>
>> # Windows updates rules
>> http_access allow CONNECT wuCONNECT localnet
>> http_access allow CONNECT wuCONNECT localhost
>> http_access allow windowsupdate localnet
>> http_access allow windowsupdate localhost
>
>> # SSL bump rules
>> acl DiscoverSNIHost at_step SslBump1
> DiscoverSNIHost is never being used. You can remove it.
>
>> # ICQ/MRA must splice first
>> acl NoSSLIntercept ssl::server_name_regex -i "/etc/squid/url.nobump"
>> ssl_bump splice NoSSLIntercept
>> ssl_bump bump net_bump
>> acl tls_s1_connect      at_step SslBump1
>> acl tls_s3_server_hello at_step SslBump3
>>
> tls_s3_server_hello is never being used. You can remove it.
>
>> # TLS/SSL bumping steps
>> ssl_bump peek   tls_s1_connect        # peek at the incoming TLS/SSL
>> connect data
>> ssl_bump splice all                          # splice the stream:
>> pass-through mode
>>
>> # And finally deny all other access to this proxy
>> http_access deny all
>>
> <snip>
>
>> -------------Config End ---------------
>>
>> ------------net.bump File -------------------
>>
>> google.com
>> youtube.com
>> reddit.com
> This file is being loaded into a 'src' ACL.
>
> Firstly, why are the Google, YouTube, and Reddit servers making requests
> through your proxy? they are your customers?
>
> I think you meant 'dst' ACL for this. Your cutomers going *to* Google,
> YouTube, or Reddit.
>
>
> Secondly, the IP addresses of the listed hosts will be resolved on Squid
> startup *only* (applies to both src and dst ACL types).
>
> Any other IPs which the site rotates into its DNS RR set after the
> single resolve that Squid does for config loading will not match.
>
>
>
>> -------------------------------
>>
>> ------------dstdom.tld file --------------
>>
>> yahoo.com
>> facebook.com
>>
>> ---------------------------------------
>>
>>
>> --------------- Url.nobump--------
>>
>> axisbank.com
>> hdfcbank.com
>>
> This file is being used by an ACL which has nothing to do with URLs.
> That name is really confusing.
>
>
>> ------------------------------------------
>>
>>
>> Now issue is that I need to block yahoo and facebook but I am able to
>> access the facebook website and yahoo is getting blocked ....
>>
> Hint: The facebook website does not always use the domain "facebook.com"
> except in the URL part visible to people. Most people dont type URLs in
> to their address bar anyway, so most access to FB will be through Google
> etc. straight to the other domain name used for content display.
>
>
>> And also all Google website like google, gmail, youtube are working very
>> slow it takes lots of time to load this websites but other Https websites
>> like axisbank / hdfc etc are working properly ....
> Think about that. The domains that your net_bump ACL has told Squid to
> bump (decrypt) are going slow, the ones you have told it to splice
> (bypass decryption) are going "properly" (whatever that means).
>
>> Also somtime website does not work with Chrome browser like Gmail but same
>> is working in Mozilla Firefox but take time to load ......
>>
> 1) Same as above.
>
> 2) Chrome is a Google app. It has the TLS certs for Gmail and other
> Google services pinned (hard-coded) into it. If your Squid happens to
> try decrypting its traffic without having the Squid CA custom installed
> in a way that overrides that pinning, it refuses to work.
>
> 3) Sometimes (usually?) Chrome does not use HTTP or HTTPS to contact
> Gmail and other Google properties. Even if the URL in the address bar
> makes you think thats what its doing. There are 5 different protocols
> that can be used to contact servers and fetch https:// URLs.
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

I cursed everything that once posted my config. They mindlessly copy, 
mangling the parameters and hoping that it will work. I am a thousand 
times told those fanboys of Linux that can not do this.


From tin at new-life.org.au  Fri May 20 10:35:52 2016
From: tin at new-life.org.au (Tim Bates)
Date: Fri, 20 May 2016 20:35:52 +1000
Subject: [squid-users] Are there any distros with SSL Bump compiled by
 default?
In-Reply-To: <7fcaac5c-52d3-1378-f56f-e083950a346c@treenet.co.nz>
References: <5736F192.2090902@new-life.org.au>
 <5601a5675b7f26d5cd86524a0d3d9883@tisiz72.ru>
 <20160516065534.GA15430@fantomas.sk>
 <221cdd15150709b5a463c02ff2fb516d@tisiz72.ru>
 <20160516072010.GC15430@fantomas.sk>
 <7fcaac5c-52d3-1378-f56f-e083950a346c@treenet.co.nz>
Message-ID: <573EE888.8060500@new-life.org.au>

I'd seen this licensing issue mentioned briefly before, but now I 
actually understand what's going on. Thanks for explaining it in detail.

Good to know there's 2 paths moving along to solve the distro problem. I 
feel more confident in moving forward with my little project now that I 
know it's only going to be a temporary annoyance to recompile.

Thanks everyone who answered.

TB


On 16/05/2016 7:25 PM, Amos Jeffries wrote:
> What is being attempted above is not a GPL violation AFAIK. So long as
> the Squid ./configure && make system is used to construct the binary and
> Squid source is not altered in any way by the builder.
>
> * GPL permits linking against OpenSSL because both softwares sources are
> available publicly.
>
> * It is GPL violation to distribute the OpenSSL and Squid sources
> together as parts of someting else. In source form.
>
> Thus distributors like Diladele can provide binary-only formats with no
> source changes to Squid or OpenSSL.
>    Each component of the offering is publicly available (GPL compliant)
> and the pieces of OpenSSL, Squid and the packaging source code are
> distributed via separate channels (OpenSSL compliant).
>
> Debian and Ubuntu distribute sources of all binaries as part of their OS
> repository. The very act of adding package install scripts causes the
> issue here. The repository would contain all of Squid + OpenSSL +
> packaging scripts source code.
>
>
> But, but, but....
>
> * It is OpenSSL violation to distribute any binary that does not
> advertise OpenSSL usage. In the binary outputs, even those not using
> OpenSSL logic (Ouch!). Unless the OS provides the library as part of its
> core system.
>
> Debian and Ubuntu use GnuTLS as the system preferrd library. OpenSSL
> license not being GPL compliant also makes it not DFSG compliant and so
> not part of the core OS repository. It and anything using it are in the
> non-free optional extras repository instead.
>   There are some suggestions to build and put a version of Squid in
> there. But that still collides with the previous GPL issue about sources
> being together in the repo.
>
>
> Adding advertising clauses in the way required by OpenSSL would make
> Squid binaries no longer be GPL compliant unless we got explicit written
> permission from everyone who contributed patches. A lot of contributors
> have long-dead emails, requested anonimity or some in fact are now
> physically deceased. So we are stuck at our end as well even with that.
>
> I am working on GnuTLS support as a side project, and the OpenSSL people
> are apparently working on fixing their license to be GPL compliant. It
> is a lot of work and going quite slow on both fronts. You can see some
> of my work reflected in the squid.conf changes of Squid-4, and the
> latest Debian/Ubuntu squidclient packages :-)
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



From squid3 at treenet.co.nz  Fri May 20 10:40:00 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 20 May 2016 22:40:00 +1200
Subject: [squid-users] squid,
 SMP and authentication and service regression over time
In-Reply-To: <573A10FA.1040801@norma.perm.ru>
References: <573A10FA.1040801@norma.perm.ru>
Message-ID: <1c5ed718-390f-d277-1dfe-f57ddc7920f4@treenet.co.nz>

On 17/05/2016 6:27 a.m., Eugene M. Zheganin wrote:
> Hi.
> 

I dont see any mention of the Squid version. Which one are you having
this issue in?

> I'm using squid for a long time, I'm using it to authenticate/authorize
> users accessing the Internet with LDAP in a Windows corporate
> enviromnent (Basic/NTLM/GSS-SPNEGO) and recently (about several months
> ago) I had to switch to the SMP scheme, because one process started to
> eat the whole core sometimes, thus bottlenecking users on it.

This might be a version-specific problem. We've had a few bugs solved
that could match that description.

> Situation
> with CPU effectiveness improved, however I discovered several issues.
> The first I was aware of, it's the non-functional SNMP (since there's no
> solution, I just had to sacrifice it).

Do you mean its fully non-functional?

Or that you are just getting randomly different responses from different
workers when they share an SNMP receiving port?

That latter is worked around by configuring per-worker SNMP ports and
querying each individually for its details.


> But the second one is more
> disturbing. I discovered that after a several uptime (usually couple of
> weeks, a month at it's best) squid somehow degrades and stops
> authorizing users.

Which auth scheme are those users using?

> I have about active 600 users on my biggest site
> (withount SNMP I'm not sure how many simultaneous users I got) but

The mgr:client_db report can help give a good ballpark number there if
you have it enabled.

> usually this starts like this: someone (this starts with one person)
> complains that he lost his access to the internet - not entirely, no. At
> first the access is very slow, and the victim has to wait several
> minutes for the page to load. Others are unaffected at this time. From
> time to time the victim is able to load one of two tabs in the browser,
> eventually, but at the end of the day this becomes unuseable, and my
> support has to come in. Then this gots escalated to me. First I was
> debugging various kerberos stuff, NTLM, victim's machine domain
> membership and so on. But today I managed to figure out that all I have
> to do is just restart squid, yeah (sounds silly, but I don't like to
> restart things, like in the "IT Crowd" TV Series, this is kinda last
> resort measure, when I'm desperate).

That could be either one of four bugs I'm aware of:

1) NTLM connection limit to AD.
 Winbind access to AD cannot make more than concurrent 256 connections
to any given AD. Thats aggregate across all the NTLM + Negotiate helpers
and any other proceses also running on the Squid machine.
 This can result in an ever growing queue of pending auth requests until
the proxy is treading water just trying to catch up on which clients
have not yet disconnected.

2) NTLM helper limits exceeded.
 NTLM handshake duration is not limited. If for any reason it pauses for
a long time between the multiple HTTP requests involved, that helper is
blocked from use by any other users.
 This can result in both an ever growing queue, and ever fewer helpers
available to service that queue.

Don't you just love NTLM?


3) NTLM and Negotiate involve the helper passing Squid a unique token
with every HTTP request made on an new connection. The annotations
feature in Squid for quite a few releases was adding these to each
username's auth state.
 The number of these unique token Notes could build up over a few hours
to a day or two depending on the clients activity rate - to a number big
enough to cause noticable delays on every request they made, and others.

4) Recent versions of Firefox are known to begin NTLM handshakes badly.
They work find for Kerberos handshakes, and sometimes for NTLM. But for
certain requests they advertise keep-alive on the type-1 message then
just hang.

Fortunately this is a behaviour seen with MSIE 5.x back in the day, so
the auth_param "keepalive off" setting is already available to resolve
that. Though it does mean the NTLM handshakes require a TCP teardown and
reconnect, which can make issue (2) above hurt more.



> If I'm stubborn enough to continue
> the investigation, soon I got 2 users complaining, then 3, then more.
> During previous outages eventually I used to restart squid (to change
> the domain controller in kerberos config, if I blame one; to disable the
> external Kerberos/LDAP helper connection pooling, if I blame one) - so
> each time there was a candidate to blame. But this time I just decided
> to restart squid, since I started to think it's the main reason, et
> voila. I should also mention that I run this AAA scheme in squid for
> years, and I didn't have this issue previously.

Keep in mind that if you have been keeping up with important
patches/updates to Squid AD and/or Samba. Or just client OS updates.
Then a lot of things have been changing from all sides of the process
across those years.


> I also have like dozen
> of other squids running same (very similar) config, - same AAA stuff -
> Basic/NTLM/GSS-SpNego, same AD group checking, but only for the
> different groups membership - and none of it has this issue. I'm
> thinking there's SMP involved, really.

Maybe. Each worker does its own auth, with no sharing. So they should be
operating same as if they were different instances which happened to
have identical config.
 That itself can make problem (1) happen as the Winbind count multiplies
by the number of workers.

Other than that each TCP connection might end up going to a different
worker. BUT, re-auth is always needed on new TCP connections anyway. So
if the client is using HTTP properly that should not be causing any
issue. Might be a big "IF" there though.
 I have to keep reassuring myself that NTLM can handle the TCP
re-connect going to a different worker. The bits prior to type-1
handshake doesn't need a helper, so it should not have issues, but Im
not completely confident about it.

> 
> I realize this is a poor problem report. "Something degrades, I restart
> squid, please help, I think it's SMP-related". But the thing is - I
> don't know where to start to narrow this stuff. If anyone's having a
> good idea please let me know.

The above might give you ideas. Otherwise I can only suggest turning on
debug for the authentication section and see if anything odd shows up.
 debug_options ALl,1 29,4

Amos



From squid3 at treenet.co.nz  Fri May 20 14:06:48 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 May 2016 02:06:48 +1200
Subject: [squid-users] Linking with *SSL
In-Reply-To: <CAEJyAvM8O6uVCgSipvzXAK1OsUrH3izc7BVTgaS0kPkWmAn3BQ@mail.gmail.com>
References: <CAEJyAvM8O6uVCgSipvzXAK1OsUrH3izc7BVTgaS0kPkWmAn3BQ@mail.gmail.com>
Message-ID: <5817fad5-df52-b997-fbb3-c6c3dab9df04@treenet.co.nz>

On 13/05/2016 1:33 a.m., Spil Oss wrote:
>> Hi!
>> When we worked on squid port on FreeBSD one of the FreeBSD user
>> (Bernard Spil) noticed:
>>
>> When working on this, I ran into another issue. Perhaps maintainer can
>> fix that with upstream. I've now added LIBOPENSSL_LIBS="-lcrypto
>> -lssl" because of configure failing in configure.ac line 1348.
>>
>>> AC_CHECK_LIB(ssl,[SSL_library_init],[LIBOPENSSL_LIBS="-lssl $LIBOPENSSL_LIBS"],[AC_MSG_ERROR([library 'ssl' is required for OpenSSL])
>>
>> You cannot link against libssl when not linking libcrypto as well
>> leading to an error with LibreSSL. This check should add -lcrypto in
>> addition to -lssl to pass.
>>
>> Is this something someone could take a look at?
> 
> Hi All,
> 
> Sorry for replying out-of-thread.
> 
> What happens is that the check for SSL_library_init fails as -lcrypto
> is missing.
> 
> Output from configure
> 
>> checking for CRYPTO_new_ex_data in -lcrypto... yes
>> checking for SSL_library_init in -lssl... no
>> configure: error: library 'ssl' is required for OpenSSL
>> ===>  Script "configure" failed unexpectedly.
> 
> What I usually see in autoconf scripts is that temp CFLAGS etc are set
> before the test for SSL libs and reversed after the test.
> 
> Adding LIBOPENSSL_LIBS="-lcrypto -lssl" to configure works as well
> 
> Would be great if you can fix this!
> 

Hi, sorry for the long delay. Its been an interesting month.

It seems we need to now stop relying on LIBS being set correctly by
autoconf when consecutive AC_CHECK_LIB are done. I'm trying out a fix
now and which should be in the next releases.

FYI: Squid is increasingly using the pkg-config tool for resolving odd
library dependencies. If it is available this broken check will never be
reached.


Amos



From timp87 at gmail.com  Fri May 20 14:28:59 2016
From: timp87 at gmail.com (Pavel Timofeev)
Date: Fri, 20 May 2016 17:28:59 +0300
Subject: [squid-users] Linking with *SSL
In-Reply-To: <5817fad5-df52-b997-fbb3-c6c3dab9df04@treenet.co.nz>
References: <CAEJyAvM8O6uVCgSipvzXAK1OsUrH3izc7BVTgaS0kPkWmAn3BQ@mail.gmail.com>
 <5817fad5-df52-b997-fbb3-c6c3dab9df04@treenet.co.nz>
Message-ID: <CAAoTqft=vCQgXrd5DMppX-OAcFRK1jWfnETqp7M2PK11Xt_ixg@mail.gmail.com>

2016-05-20 17:06 GMT+03:00 Amos Jeffries <squid3 at treenet.co.nz>:
> On 13/05/2016 1:33 a.m., Spil Oss wrote:
>>> Hi!
>>> When we worked on squid port on FreeBSD one of the FreeBSD user
>>> (Bernard Spil) noticed:
>>>
>>> When working on this, I ran into another issue. Perhaps maintainer can
>>> fix that with upstream. I've now added LIBOPENSSL_LIBS="-lcrypto
>>> -lssl" because of configure failing in configure.ac line 1348.
>>>
>>>> AC_CHECK_LIB(ssl,[SSL_library_init],[LIBOPENSSL_LIBS="-lssl $LIBOPENSSL_LIBS"],[AC_MSG_ERROR([library 'ssl' is required for OpenSSL])
>>>
>>> You cannot link against libssl when not linking libcrypto as well
>>> leading to an error with LibreSSL. This check should add -lcrypto in
>>> addition to -lssl to pass.
>>>
>>> Is this something someone could take a look at?
>>
>> Hi All,
>>
>> Sorry for replying out-of-thread.
>>
>> What happens is that the check for SSL_library_init fails as -lcrypto
>> is missing.
>>
>> Output from configure
>>
>>> checking for CRYPTO_new_ex_data in -lcrypto... yes
>>> checking for SSL_library_init in -lssl... no
>>> configure: error: library 'ssl' is required for OpenSSL
>>> ===>  Script "configure" failed unexpectedly.
>>
>> What I usually see in autoconf scripts is that temp CFLAGS etc are set
>> before the test for SSL libs and reversed after the test.
>>
>> Adding LIBOPENSSL_LIBS="-lcrypto -lssl" to configure works as well
>>
>> Would be great if you can fix this!
>>
>
> Hi, sorry for the long delay. Its been an interesting month.
>
> It seems we need to now stop relying on LIBS being set correctly by
> autoconf when consecutive AC_CHECK_LIB are done. I'm trying out a fix
> now and which should be in the next releases.
>
> FYI: Squid is increasingly using the pkg-config tool for resolving odd
> library dependencies. If it is available this broken check will never be
> reached.
>
>
> Amos
>

Hi, Amos!
Thank you! Should we create a bug report to track it?


From squid3 at treenet.co.nz  Fri May 20 14:44:14 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 May 2016 02:44:14 +1200
Subject: [squid-users] Linking with *SSL
In-Reply-To: <CAAoTqft=vCQgXrd5DMppX-OAcFRK1jWfnETqp7M2PK11Xt_ixg@mail.gmail.com>
References: <CAEJyAvM8O6uVCgSipvzXAK1OsUrH3izc7BVTgaS0kPkWmAn3BQ@mail.gmail.com>
 <5817fad5-df52-b997-fbb3-c6c3dab9df04@treenet.co.nz>
 <CAAoTqft=vCQgXrd5DMppX-OAcFRK1jWfnETqp7M2PK11Xt_ixg@mail.gmail.com>
Message-ID: <804a9e7d-b711-9b59-4be5-6f54cf0c7c7d@treenet.co.nz>

On 21/05/2016 2:28 a.m., Pavel Timofeev wrote:
> 
> Hi, Amos!
> Thank you! Should we create a bug report to track it?
> 

No need, I think.

Amos


From Walter.H at mathemainzel.info  Fri May 20 14:44:23 2016
From: Walter.H at mathemainzel.info (Walter H.)
Date: Fri, 20 May 2016 16:44:23 +0200
Subject: [squid-users] Ciphersuites with SSL bump [squid 3.5.19]
Message-ID: <573F22C7.5000909@mathemainzel.info>

Hello,

I'd like to disable some ciphersuites when connecting with web servers;

when I go there: https://cc.dcsec.uni-hannover.de/
I'm shown this (only the column with ciphersuite names):

ECDHE-RSA-AES256-GCM-SHA384
ECDHE-ECDSA-AES256-GCM-SHA384
ECDHE-RSA-AES256-SHA384
ECDHE-ECDSA-AES256-SHA384
ECDHE-RSA-AES256-SHA
ECDHE-ECDSA-AES256-SHA
DHE-RSA-AES256-GCM-SHA384
DHE-RSA-AES256-SHA256
DHE-RSA-AES256-SHA
DHE-RSA-CAMELLIA256-SHA
ECDH-RSA-AES256-GCM-SHA384
ECDH-ECDSA-AES256-GCM-SHA384
ECDH-RSA-AES256-SHA384
ECDH-ECDSA-AES256-SHA384
ECDH-RSA-AES256-SHA
ECDH-ECDSA-AES256-SHA
RSA-AES256-GCM-SHA384
DH-RSA-MISTY1-SHA  (*)
RSA-AES256-SHA
RSA-CAMELLIA256-SHA
ECDHE-RSA-AES128-GCM-SHA256
ECDHE-ECDSA-AES128-GCM-SHA256
ECDHE-RSA-AES128-SHA256
ECDHE-ECDSA-AES128-SHA256
ECDHE-RSA-AES128-SHA
ECDHE-ECDSA-AES128-SHA
DHE-RSA-AES128-GCM-SHA256
DHE-RSA-AES128-SHA256
DHE-RSA-AES128-SHA
DHE-RSA-CAMELLIA128-SHA
ECDH-RSA-AES128-GCM-SHA256
ECDH-ECDSA-AES128-GCM-SHA256
ECDH-RSA-AES128-SHA256
ECDH-ECDSA-AES128-SHA256
ECDH-RSA-AES128-SHA
ECDH-ECDSA-AES128-SHA
RSA-AES128-GCM-SHA256
DH-DSS-MISTY1-SHA  (*)
RSA-AES128-SHA
RSA-CAMELLIA128-SHA
ECDHE-RSA-3DES-EDE-SHA
ECDHE-ECDSA-3DES-EDE-SHA
DHE-RSA-3DES-EDE-SHA
ECDH-RSA-3DES-EDE-SHA
ECDH-ECDSA-3DES-EDE-SHA
RSA-3DES-EDE-SHA
EMPTY-RENEGOTIATION-INFO-SCSV

and these are the lines in my squid.conf

sslproxy_cafile /etc/squid/ca-bundle.trust.crt
sslproxy_cipher 
!SSLv2:+SSLv3:!AECDH:!ADH:!DES:HIGH:+3DES:!RC4:!MD5:!aNULL:!eNULL:!LOW:!EXP:!DSS:!PSK:!SEED:!SRP
sslproxy_options NO_SSLv2 NO_SSLv3 TLSv1 TLSv1_1 TLSv1_2

and I would like to disable the ciphersuites marked with (*), but how 
would I do this?

any hint would be nice;

Thanks and greetings from Austria,
Walter


-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 4312 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160520/58654e93/attachment.bin>

From timp87 at gmail.com  Fri May 20 14:53:19 2016
From: timp87 at gmail.com (Pavel Timofeev)
Date: Fri, 20 May 2016 17:53:19 +0300
Subject: [squid-users] Linking with *SSL
In-Reply-To: <804a9e7d-b711-9b59-4be5-6f54cf0c7c7d@treenet.co.nz>
References: <CAEJyAvM8O6uVCgSipvzXAK1OsUrH3izc7BVTgaS0kPkWmAn3BQ@mail.gmail.com>
 <5817fad5-df52-b997-fbb3-c6c3dab9df04@treenet.co.nz>
 <CAAoTqft=vCQgXrd5DMppX-OAcFRK1jWfnETqp7M2PK11Xt_ixg@mail.gmail.com>
 <804a9e7d-b711-9b59-4be5-6f54cf0c7c7d@treenet.co.nz>
Message-ID: <CAAoTqfvhSZd5est9-oFmo+j17JqpmXt++4JaOFz_Zwau-3CwBg@mail.gmail.com>

20 ??? 2016 ?. 17:44 ???????????? "Amos Jeffries" <squid3 at treenet.co.nz>
???????:
>
> On 21/05/2016 2:28 a.m., Pavel Timofeev wrote:
> >
> > Hi, Amos!
> > Thank you! Should we create a bug report to track it?
> >
>
> No need, I think.

I just wanted to look at something and understand that it's done and it's
time to test
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160520/f9aa2bc3/attachment.htm>

From squid3 at treenet.co.nz  Fri May 20 15:31:10 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 21 May 2016 03:31:10 +1200
Subject: [squid-users] Linking with *SSL
In-Reply-To: <CAAoTqfvhSZd5est9-oFmo+j17JqpmXt++4JaOFz_Zwau-3CwBg@mail.gmail.com>
References: <CAEJyAvM8O6uVCgSipvzXAK1OsUrH3izc7BVTgaS0kPkWmAn3BQ@mail.gmail.com>
 <5817fad5-df52-b997-fbb3-c6c3dab9df04@treenet.co.nz>
 <CAAoTqft=vCQgXrd5DMppX-OAcFRK1jWfnETqp7M2PK11Xt_ixg@mail.gmail.com>
 <804a9e7d-b711-9b59-4be5-6f54cf0c7c7d@treenet.co.nz>
 <CAAoTqfvhSZd5est9-oFmo+j17JqpmXt++4JaOFz_Zwau-3CwBg@mail.gmail.com>
Message-ID: <d85a1d0c-e77a-d1f4-96ea-fab50e966b9b@treenet.co.nz>

On 21/05/2016 2:53 a.m., Pavel Timofeev wrote:
> 20 ??? 2016 ?. 17:44 ???????????? "Amos Jeffries" ???????:
>>
>> On 21/05/2016 2:28 a.m., Pavel Timofeev wrote:
>>>
>>> Hi, Amos!
>>> Thank you! Should we create a bug report to track it?
>>>
>>
>> No need, I think.
> 
> I just wanted to look at something and understand that it's done and it's
> time to test
> 

I've just applied it to trunk as rev.14679. A snapshot tarball should be
available in a couple of hours. Hopefully I'll have time to get it into
3.5 tomorrow. If not then the day after.

Amos



From timp87 at gmail.com  Fri May 20 15:39:03 2016
From: timp87 at gmail.com (Pavel Timofeev)
Date: Fri, 20 May 2016 18:39:03 +0300
Subject: [squid-users] Linking with *SSL
In-Reply-To: <d85a1d0c-e77a-d1f4-96ea-fab50e966b9b@treenet.co.nz>
References: <CAEJyAvM8O6uVCgSipvzXAK1OsUrH3izc7BVTgaS0kPkWmAn3BQ@mail.gmail.com>
 <5817fad5-df52-b997-fbb3-c6c3dab9df04@treenet.co.nz>
 <CAAoTqft=vCQgXrd5DMppX-OAcFRK1jWfnETqp7M2PK11Xt_ixg@mail.gmail.com>
 <804a9e7d-b711-9b59-4be5-6f54cf0c7c7d@treenet.co.nz>
 <CAAoTqfvhSZd5est9-oFmo+j17JqpmXt++4JaOFz_Zwau-3CwBg@mail.gmail.com>
 <d85a1d0c-e77a-d1f4-96ea-fab50e966b9b@treenet.co.nz>
Message-ID: <CAAoTqfungX8o6qEsVrXjCykR4c1hFenVwpwy=CjzMkYqh+gXyA@mail.gmail.com>

20 ??? 2016 ?. 18:31 ???????????? "Amos Jeffries" <squid3 at treenet.co.nz>
???????:
>
> On 21/05/2016 2:53 a.m., Pavel Timofeev wrote:
> > 20 ??? 2016 ?. 17:44 ???????????? "Amos Jeffries" ???????:
> >>
> >> On 21/05/2016 2:28 a.m., Pavel Timofeev wrote:
> >>>
> >>> Hi, Amos!
> >>> Thank you! Should we create a bug report to track it?
> >>>
> >>
> >> No need, I think.
> >
> > I just wanted to look at something and understand that it's done and
it's
> > time to test
> >
>
> I've just applied it to trunk as rev.14679. A snapshot tarball should be
> available in a couple of hours. Hopefully I'll have time to get it into
> 3.5 tomorrow. If not then the day after.
>
> Amos

Thanks a lot!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160520/2ae3bad7/attachment.htm>

From yvoinov at gmail.com  Fri May 20 16:09:07 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 20 May 2016 22:09:07 +0600
Subject: [squid-users] Linking with *SSL
In-Reply-To: <d85a1d0c-e77a-d1f4-96ea-fab50e966b9b@treenet.co.nz>
References: <CAEJyAvM8O6uVCgSipvzXAK1OsUrH3izc7BVTgaS0kPkWmAn3BQ@mail.gmail.com>
 <5817fad5-df52-b997-fbb3-c6c3dab9df04@treenet.co.nz>
 <CAAoTqft=vCQgXrd5DMppX-OAcFRK1jWfnETqp7M2PK11Xt_ixg@mail.gmail.com>
 <804a9e7d-b711-9b59-4be5-6f54cf0c7c7d@treenet.co.nz>
 <CAAoTqfvhSZd5est9-oFmo+j17JqpmXt++4JaOFz_Zwau-3CwBg@mail.gmail.com>
 <d85a1d0c-e77a-d1f4-96ea-fab50e966b9b@treenet.co.nz>
Message-ID: <d81fc442-4ceb-93df-2225-08d25aad183b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Amos, a paradoxical situation. Changes accumulate and accumulate, and no
new releases at least two weeks.
And these changes appear in the subspace - in the source of their past
is definitely not. So conceived?
20.05.16 21:31, Amos Jeffries ?????:
> On 21/05/2016 2:53 a.m., Pavel Timofeev wrote:
>> 20 ??? 2016 ?. 17:44 ???????????? "Amos Jeffries" ???????:
>>>
>>> On 21/05/2016 2:28 a.m., Pavel Timofeev wrote:
>>>>
>>>> Hi, Amos!
>>>> Thank you! Should we create a bug report to track it?
>>>>
>>>
>>> No need, I think.
>>
>> I just wanted to look at something and understand that it's done and it's
>> time to test
>>
>
> I've just applied it to trunk as rev.14679. A snapshot tarball should be
> available in a couple of hours. Hopefully I'll have time to get it into
> 3.5 tomorrow. If not then the day after.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXPzajAAoJENNXIZxhPexGrNAH/128xceZNuBIR/7PqLdjP771
Y0aw8H8AtqJCCR9pqWc4QrEZQm7wl4zsf6rUaTqkZ04BHh5NPL4aeMTTPV9PM0Oe
WMtR4knd/XmbT4EMol2lomAF+1Apwvs+0xH1mq7V/viMCeuc7RhKF8IFE6eETBkJ
LRFGgVEEOZFc9rdEkki0LXoC5Ed1yhvtfFwc9ptDrxmX/e4jzpwa2lHbsmbfDive
lCkT3yBOLiPQnkSKSbY8pt1eUCWG2xpENdMzJTgPc6IWWqcfF/4G3074A3HpVW+u
GgCTdpQiYy2Wi9MfLXuXJtMpu0+FnYSFWL9pkkVoErEdovJSokYhLbeEknHkr1g=
=nQqT
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160520/7dd60fb0/attachment.key>

From rworsnop at gmail.com  Fri May 20 18:41:15 2016
From: rworsnop at gmail.com (Rob Worsnop)
Date: Fri, 20 May 2016 14:41:15 -0400
Subject: [squid-users] Problem talking ICAP to McAfee Web Gateway
In-Reply-To: <573CF0BE.5070207@measurement-factory.com>
References: <CAMiSdg7GhKurqWmidbcBEavtQPhv7rt3S3C0zj+QpDPiATMeaQ@mail.gmail.com>
 <573CF0BE.5070207@measurement-factory.com>
Message-ID: <CAMiSdg7FPW+FUMDysXNiB=8mdcFv7Hhx3tw_iQ2XCFfM3L4PCw@mail.gmail.com>

Quick update: The problem isn't with Squid.

When MWG decides it wants to send an early response, it seems it also
decides to send garbage data after a few KB of valid data. Squid
notices that MWG is trying to send a chunk bigger than advertised and
promptly closes the connection.

On Wed, May 18, 2016 at 6:46 PM, Alex Rousskov
<rousskov at measurement-factory.com> wrote:
> On 05/18/2016 03:56 PM, Rob Worsnop wrote:
>
>> In certain circumstances, MWG will start streaming the RESPMOD response
>> before Squid has finished sending all the chunks in the RESPMOD request.
>>
>> Squid does not like this.
>
> If Squid does not like this, it is a Squid bug IMO.
>
>
>> As far as I can tell, ICAP is no different from HTTP
>
> In both protocols, a server may start sending the response before the
> entire request has been received, and a robust client implementation
> ought to accept such "early" responses even if the protocol does not
> explicitly require their support. An early response has to comply with
> all the other protocol rules, of course, but there are cases where such
> compliance is not a problem.
>
> In HTTP, early responses are usually errors because the server is
> unlikely to know that the request will be successful until seeing the
> end of the request.
>
> In ICAP, early responses are much more useful (and common) because an
> ICAP server can "pipeline" the HTTP message back to the ICAP client,
> drastically reducing message buffering requirements and user delays.
> IIRC, Squid used to support early responses well.
>
>
> HTH,
>
> Alex.
>


From yvoinov at gmail.com  Fri May 20 21:20:58 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 21 May 2016 03:20:58 +0600
Subject: [squid-users] Problem talking ICAP to McAfee Web Gateway
In-Reply-To: <CAMiSdg7FPW+FUMDysXNiB=8mdcFv7Hhx3tw_iQ2XCFfM3L4PCw@mail.gmail.com>
References: <CAMiSdg7GhKurqWmidbcBEavtQPhv7rt3S3C0zj+QpDPiATMeaQ@mail.gmail.com>
 <573CF0BE.5070207@measurement-factory.com>
 <CAMiSdg7FPW+FUMDysXNiB=8mdcFv7Hhx3tw_iQ2XCFfM3L4PCw@mail.gmail.com>
Message-ID: <510940dc-6943-5180-6672-4c6875fb4810@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
The problem is always with the DNA. The main question - by whom;)


21.05.16 0:41, Rob Worsnop ?????:
> Quick update: The problem isn't with Squid.
>
> When MWG decides it wants to send an early response, it seems it also
> decides to send garbage data after a few KB of valid data. Squid
> notices that MWG is trying to send a chunk bigger than advertised and
> promptly closes the connection.
>
> On Wed, May 18, 2016 at 6:46 PM, Alex Rousskov
> <rousskov at measurement-factory.com> wrote:
>> On 05/18/2016 03:56 PM, Rob Worsnop wrote:
>>
>>> In certain circumstances, MWG will start streaming the RESPMOD response
>>> before Squid has finished sending all the chunks in the RESPMOD request.
>>>
>>> Squid does not like this.
>>
>> If Squid does not like this, it is a Squid bug IMO.
>>
>>
>>> As far as I can tell, ICAP is no different from HTTP
>>
>> In both protocols, a server may start sending the response before the
>> entire request has been received, and a robust client implementation
>> ought to accept such "early" responses even if the protocol does not
>> explicitly require their support. An early response has to comply with
>> all the other protocol rules, of course, but there are cases where such
>> compliance is not a problem.
>>
>> In HTTP, early responses are usually errors because the server is
>> unlikely to know that the request will be successful until seeing the
>> end of the request.
>>
>> In ICAP, early responses are much more useful (and common) because an
>> ICAP server can "pipeline" the HTTP message back to the ICAP client,
>> drastically reducing message buffering requirements and user delays.
>> IIRC, Squid used to support early responses well.
>>
>>
>> HTH,
>>
>> Alex.
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXP3+6AAoJENNXIZxhPexGUt4H/1IeLUNGMzYmGurgvj7qpY7Q
6mA9UTHv9NaYEHE8XembSTWbqe/UuWiFzUv/YM+jWCs3Rl7ZCLFYtp2g9eVqXDJb
Hew0Mo8fy3t9uMwoRzsk0A0euJMRG10x4659az0TVPR/jeinXck9hIuQ/XwiUxAX
lTx30h0wmTRNn9snJxIkcouCbI26/QkT8YFgu10Rz0Z3mjXiqt+ytpyFEjpBPzHj
3RUfDoZTp/uh/fAfkq/JrDI+2vi3hIyi8qTywcCyfPdaR6+Wh8Dt3x30K+BGzuqy
5Q1fkMFkDmSte+VfOHXj7Rml/G6lgnEP75mazGSnWQjtSLiaHecRYcZgR4qcEdI=
=7BuE
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160521/e7b82b2c/attachment.key>

From mark at ecs.vuw.ac.nz  Mon May 23 04:41:13 2016
From: mark at ecs.vuw.ac.nz (Mark Davies)
Date: Mon, 23 May 2016 16:41:13 +1200
Subject: [squid-users] squid 3.5.19, wccp2, pf and forwarding loop
Message-ID: <1919047.7upNBdQFDu@city-art.ecs.vuw.ac.nz>

I know this comes up repeatedly but I'm now hitting this and can't see why.

I have a traditional squid setup that works fine for clients that 
explicitly point at it but I also want to allow transparent access for some 
destinations for only port 80.  So I have wccp2 set up between a cisco 
switch and the squid to direct the traffic to the box (and that seems to be 
happening fine).  I have the below pf.conf (This is on NetBSD using PF) on 
the box to direct the traffic to the intercept port:


ext_if="wm0"
int_if="bnx0"

set skip on lo0

rdr pass on $int_if inet proto tcp from 130.195.0.0/20 to any port 80 -> 
127.0.0.1 port 8081

pass out
pass in



relevant bits of the squid.conf are:

http_port www-cache2:8080
http_port 8081 intercept

wccp2_router 130.195.5.1
wccp2_forwarding_method l2
wccp2_return_method l2
wccp2_assignment_method mask
wccp2_service standard 0


If I try to access a site transparently I get the following in the 
access.log:

1463977560.985      3 130.195.5.88 TCP_MISS/403 3945 GET 
http://www.easychair.org/easychair.cgi - ORIGINAL_DST/127.0.0.1 text/html

and this in cache.log:

2016/05/23 16:26:00 kid1| WARNING: Forwarding loop detected for:
GET /easychair.cgi HTTP/1.1
Accept: */*
User-Agent: tnftp/20151004
Via: 1.1 www-cache2.ecs.vuw.ac.nz (squid/3.5.19)
X-Forwarded-For: 130.195.5.88
Cache-Control: max-age=259200
Connection: keep-alive
Host: www.easychair.org



so presumably squid is sending out the request in such a way that its 
getting fed back into itself (rather than going to www.easychair.org in 
this case) but I can't see why that is happening.  Any suggestions?

cheers
mark



From sagarmalve91 at gmail.com  Mon May 23 06:27:31 2016
From: sagarmalve91 at gmail.com (Sagar Malve)
Date: Mon, 23 May 2016 11:57:31 +0530
Subject: [squid-users] CPU Load 100% after implementing SSL Bump ....
Message-ID: <CAKQSiAU6X5gsx3AOZwLZ3pW8+DjVho7bJV6eiu0wp6KAaKB6mA@mail.gmail.com>

Hi Team,

System Config:

Intel S2400SC2 Motherboard
Intel Xeon ES 2407 V2 CPU
RAM 32 GB


http_port 3127
http_port 3128 intercept
https_port 3129 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_certs/squid.crt
key=/etc/squid/ssl_certs/squid.key options=NO_SSLv3
tls-dh=/etc/squid/dhparam.pem
sslproxy_capath /etc/ssl/certs


# FILTERING HTTPS
acl 1 dstdomain .fbcdn.net .akamaihd.net .fbsbx.com
#acl 2a dstdomain .mahadana.com .mql4.com .metaquotes.net
acl 2 url_regex -i ^https?:\/\/attachment\.fbsbx\.com\/.*\?(id=[0-9]*).*
acl 2 url_regex -i
\.fbsbx\.com\/.*\/(.*\.(unity3d|pak|zip|exe|dll|jpg|png|gif|swf)/)$
acl 2 url_regex -i ^https?:\/\/.*\.ytimg\.com(.*\.(webp|jpg|gif))
acl 2 url_regex -i ^https?:\/\/([^\.]*)\.yimg\.com\/(.*)
acl 2 url_regex -i ^https?:\/\/.*\.gstatic\.com\/images\?q=tbn\:(.*)
acl 2 url_regex -i
^https?:\/\/.*\.reverbnation\.com\/.*\/(ec_stream_song|download_song_direct|stream_song)\/([0-9]*).*
acl 2 url_regex -i
^https?:\/\/([a-z0-9.]*)(\.doubleclick\.net|\.quantserve\.com|.exoclick\.com|interclick.\com|\.googlesyndication\.com|\.auditude\.com|.visiblemeasures\.com|yieldmanager|cpxinteractive)(.*)
acl 2 url_regex -i ^https?:\/\/(.*?)\/(ads)\?(.*?)
acl 2 url_regex -i ^https?:\/\/.*steampowered\.com\/.*\/([0-9]+\/(.*))
acl 3 url_regex -i
^https?:\/\/(.*?)\/speedtest\/.*\.(jpg|txt|png|gif|swf)\?.*
acl 3 url_regex -i speedtest\/.*\.(jpg|txt|png|gif|swf)\?.*
acl 4 url_regex -i reverbnation.*audio_player.*ec_stream_song.*$
acl 5 url_regex -i utm.gif.*
acl 6 url_regex -i c.android.clients.google.com.market.GetBinary.GetBinary.*
acl 7 url_regex -i youtube.*(ptracking|stream_204|player_204|gen_204).*$
acl 7 url_regex -i
\.c\.(youtube|google)\.com\/(get_video|videoplayback|videoplay).*$
acl 7 url_regex -i (youtube|google).*\/videoplayback\?.*
acl 8 http_status 302
acl getmethod method GET


ssl_bump splice localhost
acl 9 at_step SslBump1
acl 10 at_step SslBump2
acl 11 at_step SslBump3
ssl_bump peek 9 all
ssl_bump bump 10 all
ssl_bump bump 11 all


----------------------------------------------------------------------------------------------

Is there any way where it can Cache SSL Certificate for all HTTPS Traffic
....
Because SSL Cert & Squid process were using 99% of CPU Load ....

We have approx 200 users ....

I have set the open file limit to 100000

Could you please let us know if there is any way to Cache the HTTPS Request
in Squid .....
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160523/3e54c9cc/attachment.htm>

From squid3 at treenet.co.nz  Mon May 23 06:48:57 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 23 May 2016 18:48:57 +1200
Subject: [squid-users] squid 3.5.19, wccp2, pf and forwarding loop
In-Reply-To: <1919047.7upNBdQFDu@city-art.ecs.vuw.ac.nz>
References: <1919047.7upNBdQFDu@city-art.ecs.vuw.ac.nz>
Message-ID: <5875225e-2796-ee35-2130-461312f8dee1@treenet.co.nz>

On 23/05/2016 4:41 p.m., Mark Davies wrote:
> I know this comes up repeatedly but I'm now hitting this and can't see why.
> 
> I have a traditional squid setup that works fine for clients that 
> explicitly point at it but I also want to allow transparent access for some 
> destinations for only port 80.  So I have wccp2 set up between a cisco 
> switch and the squid to direct the traffic to the box (and that seems to be 
> happening fine).  I have the below pf.conf (This is on NetBSD using PF) on 
> the box to direct the traffic to the intercept port:
> 
> 
> ext_if="wm0"
> int_if="bnx0"
> 
> set skip on lo0
> 
> rdr pass on $int_if inet proto tcp from 130.195.0.0/20 to any port 80 -> 
> 127.0.0.1 port 8081

What prevents Squids outgoing traffic (to port 80) from being diverted
back into Squid again?

Amos



From mark at ecs.vuw.ac.nz  Mon May 23 07:01:19 2016
From: mark at ecs.vuw.ac.nz (Mark Davies)
Date: Mon, 23 May 2016 19:01:19 +1200
Subject: [squid-users] squid 3.5.19, wccp2, pf and forwarding loop
In-Reply-To: <5875225e-2796-ee35-2130-461312f8dee1@treenet.co.nz>
References: <1919047.7upNBdQFDu@city-art.ecs.vuw.ac.nz>
 <5875225e-2796-ee35-2130-461312f8dee1@treenet.co.nz>
Message-ID: <5742AABF.8030306@ecs.vuw.ac.nz>



On 23/05/16 18:48, Amos Jeffries wrote:
>> ext_if="wm0"
>> int_if="bnx0"
>>
>> set skip on lo0
>>
>> rdr pass on $int_if inet proto tcp from 130.195.0.0/20 to any port 80 ->
>> 127.0.0.1 port 8081
>
> What prevents Squids outgoing traffic (to port 80) from being diverted
> back into Squid again?

I would expect the outgoing traffic to be on the external interface 
(wm0) and the diversion is only on the internal (bnx0)

but I did try to test if something was happening on the internal by 
reducing the address range being matched in the rdr line to something 
that didn't include the internal address of the squid box and it made no 
difference.

cheers
mark



From squid3 at treenet.co.nz  Mon May 23 07:22:35 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 23 May 2016 19:22:35 +1200
Subject: [squid-users] CPU Load 100% after implementing SSL Bump ....
In-Reply-To: <CAKQSiAU6X5gsx3AOZwLZ3pW8+DjVho7bJV6eiu0wp6KAaKB6mA@mail.gmail.com>
References: <CAKQSiAU6X5gsx3AOZwLZ3pW8+DjVho7bJV6eiu0wp6KAaKB6mA@mail.gmail.com>
Message-ID: <b8d315ba-00da-ef5f-7624-23d11bd53b68@treenet.co.nz>

On 23/05/2016 6:27 p.m., Sagar Malve wrote:
> Hi Team,
> 
> System Config:
> 
> Intel S2400SC2 Motherboard
> Intel Xeon ES 2407 V2 CPU
> RAM 32 GB
> 

What Squid version?

> 
> http_port 3127
> http_port 3128 intercept
> https_port 3129 intercept ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_certs/squid.crt
> key=/etc/squid/ssl_certs/squid.key options=NO_SSLv3
> tls-dh=/etc/squid/dhparam.pem
> sslproxy_capath /etc/ssl/certs
> 
> 
> # FILTERING HTTPS
> acl 1 dstdomain .fbcdn.net .akamaihd.net .fbsbx.com
> #acl 2a dstdomain .mahadana.com .mql4.com .metaquotes.net
> acl 2 url_regex -i ^https?:\/\/attachment\.fbsbx\.com\/.*\?(id=[0-9]*).*
> acl 2 url_regex -i
> \.fbsbx\.com\/.*\/(.*\.(unity3d|pak|zip|exe|dll|jpg|png|gif|swf)/)$
> acl 2 url_regex -i ^https?:\/\/.*\.ytimg\.com(.*\.(webp|jpg|gif))
> acl 2 url_regex -i ^https?:\/\/([^\.]*)\.yimg\.com\/(.*)
> acl 2 url_regex -i ^https?:\/\/.*\.gstatic\.com\/images\?q=tbn\:(.*)
> acl 2 url_regex -i
> ^https?:\/\/.*\.reverbnation\.com\/.*\/(ec_stream_song|download_song_direct|stream_song)\/([0-9]*).*
> acl 2 url_regex -i
> ^https?:\/\/([a-z0-9.]*)(\.doubleclick\.net|\.quantserve\.com|.exoclick\.com|interclick.\com|\.googlesyndication\.com|\.auditude\.com|.visiblemeasures\.com|yieldmanager|cpxinteractive)(.*)
> acl 2 url_regex -i ^https?:\/\/(.*?)\/(ads)\?(.*?)
> acl 2 url_regex -i ^https?:\/\/.*steampowered\.com\/.*\/([0-9]+\/(.*))
> acl 3 url_regex -i
> ^https?:\/\/(.*?)\/speedtest\/.*\.(jpg|txt|png|gif|swf)\?.*
> acl 3 url_regex -i speedtest\/.*\.(jpg|txt|png|gif|swf)\?.*
> acl 4 url_regex -i reverbnation.*audio_player.*ec_stream_song.*$
> acl 5 url_regex -i utm.gif.*
> acl 6 url_regex -i c.android.clients.google.com.market.GetBinary.GetBinary.*
> acl 7 url_regex -i youtube.*(ptracking|stream_204|player_204|gen_204).*$
> acl 7 url_regex -i
> \.c\.(youtube|google)\.com\/(get_video|videoplayback|videoplay).*$
> acl 7 url_regex -i (youtube|google).*\/videoplayback\?.*
> acl 8 http_status 302
> acl getmethod method GET
> 

Using .* on the beginning or end of a regex does nothing but cause more
CPU workload for Squid.

If you put it inside (.*), or with an anchor ^.* or .*$ just makes the
CPU usage worse.

What http_access rules are using those?

> 
> ssl_bump splice localhost
> acl 9 at_step SslBump1
> acl 10 at_step SslBump2
> acl 11 at_step SslBump3
> ssl_bump peek 9 all
> ssl_bump bump 10 all
> ssl_bump bump 11 all

Step3 of bumping process will never happen. You told Squid to begin
decryption at step2.

Have you disabled "via"?


> 
> ----------------------------------------------------------------------------------------------
> 
> Is there any way where it can Cache SSL Certificate for all HTTPS Traffic
> ....
> Because SSL Cert & Squid process were using 99% of CPU Load ....

Er, what do you think caching does exactly?

Caching HTTPS will have no effect on your described CPU problem. Might
make it worse even.


Between them?

How much is each process using?

How may concurrent connections are being handled by Squid to get that
loading ?


Check whether Squid is finished loading its cache_dir indexes, or if any
of them are undergoing a "DIRTY" rebuild. That can use a lot of CPU
while its happening and caching cannot be fully operational until its
finished either.


> 
> We have approx 200 users ....
> 
> I have set the open file limit to 100000

FYI: SSL-Bump with your configuration will use 3 FD for each client
inbound HTTPS request. That 100K limit will restrict your users to 150
concurrent connections each.
A browser using Happy eyeballs will open 16 connections to each domain.
Average web page on the most popular sites involve around 100 objects
spread over 10+ domains.
  => ~160 FD needed to load an average page.

I'd double that limit, if you expect this proxy to have much traffic.

> 
> Could you please let us know if there is any way to Cache the HTTPS Request
> in Squid .....
> 

You are already SSL-Bumping traffic. That removes the 'S' from HTTPS.
Leaving Squid with regular HTTP messages, which already are cached if it
can.

Amos



From squid3 at treenet.co.nz  Mon May 23 07:32:07 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 23 May 2016 19:32:07 +1200
Subject: [squid-users] squid 3.5.19, wccp2, pf and forwarding loop
In-Reply-To: <5742AABF.8030306@ecs.vuw.ac.nz>
References: <1919047.7upNBdQFDu@city-art.ecs.vuw.ac.nz>
 <5875225e-2796-ee35-2130-461312f8dee1@treenet.co.nz>
 <5742AABF.8030306@ecs.vuw.ac.nz>
Message-ID: <30208c77-3503-9ceb-599c-86b754d5766b@treenet.co.nz>

On 23/05/2016 7:01 p.m., Mark Davies wrote:
> 
> 
> On 23/05/16 18:48, Amos Jeffries wrote:
>>> ext_if="wm0"
>>> int_if="bnx0"
>>>
>>> set skip on lo0
>>>
>>> rdr pass on $int_if inet proto tcp from 130.195.0.0/20 to any port 80 ->
>>> 127.0.0.1 port 8081
>>
>> What prevents Squids outgoing traffic (to port 80) from being diverted
>> back into Squid again?
> 
> I would expect the outgoing traffic to be on the external interface
> (wm0) and the diversion is only on the internal (bnx0)
> 
> but I did try to test if something was happening on the internal by
> reducing the address range being matched in the rdr line to something
> that didn't include the internal address of the squid box and it made no
> difference.
> 

Okay good.

There are two other things to check then.

Firstly, if the router receiving the wm0 traffic is the one doing WCCP
 divert into Squid. It needs a similar excemption of that outgoing traffic.

Secondly,
 in squid.conf enable "debug_options 28,4" and see what it logs in
cache.log about the bnx0 interface.
 I suspect Squid might be detecting it as a non-Ethernet interface and
so not pulling the IP details correctly from the NAT.

Amos



From sagarmalve91 at gmail.com  Mon May 23 08:18:16 2016
From: sagarmalve91 at gmail.com (Sagar Malve)
Date: Mon, 23 May 2016 13:48:16 +0530
Subject: [squid-users] CPU Load 100% after implementing SSL Bump ....
In-Reply-To: <b8d315ba-00da-ef5f-7624-23d11bd53b68@treenet.co.nz>
References: <CAKQSiAU6X5gsx3AOZwLZ3pW8+DjVho7bJV6eiu0wp6KAaKB6mA@mail.gmail.com>
 <b8d315ba-00da-ef5f-7624-23d11bd53b68@treenet.co.nz>
Message-ID: <CAKQSiAVt2jnrH=mByuLXz-B6F92=nZCZKpGpV7=BkmfWDAntUg@mail.gmail.com>

Hi Team,

Squid - Version 3.5.13


Please find the below Squid Cache Logs
2016/05/23 13:35:55 kid1| Error negotiating SSL connection on FD 138:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
2016/05/23 13:35:55 kid1| Error negotiating SSL connection on FD 457:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
2016/05/23 13:36:00 kid1| Error negotiating SSL connection on FD 33:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
2016/05/23 13:36:01 kid1| Error negotiating SSL connection on FD 438:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
2016/05/23 13:36:05 kid1| Error negotiating SSL connection on FD 555: (104)
Connection reset by peer
2016/05/23 13:36:06 kid1| Error negotiating SSL connection on FD 512:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
2016/05/23 13:36:09 kid1| Error negotiating SSL connection on FD 618: (104)
Connection reset by peer
2016/05/23 13:36:15 kid1| Error negotiating SSL connection on FD 514:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
2016/05/23 13:36:15 kid1| Error negotiating SSL connection on FD 206:
error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
(1/0)
2016/05/23 13:36:18 kid1| Error negotiating SSL connection on FD 627: (104)
Connection reset by peer
2016/05/23 13:36:18 kid1| Error negotiating SSL on FD 147:
error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure
(1/0/0)
2016/05/23 13:36:19 kid1| Error negotiating SSL connection on FD 343:
error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
(1/0)
2016/05/23 13:36:24 kid1| Error negotiating SSL connection on FD 378: (104)
Connection reset by peer
2016/05/23 13:36:25 kid1| Error negotiating SSL connection on FD 491:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
2016/05/23 13:36:28 kid1| ctx: enter level  0: '
http://afs.moatads.com/empty_flash?tracer='
2016/05/23 13:36:28 kid1| keepaliveAccounting: Impossible keep-alive header
from 'http://afs.moatads.com/empty_flash?tracer='
2016/05/23 13:36:34 kid1| ctx: exit level  0
2016/05/23 13:36:34 kid1| Error negotiating SSL connection on FD 257: (104)
Connection reset by peer
2016/05/23 13:36:34 kid1| Error negotiating SSL connection on FD 90:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
2016/05/23 13:36:38 kid1| Error negotiating SSL on FD 125:
error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure
(1/0/0)
2016/05/23 13:36:38 kid1| Error negotiating SSL connection on FD 577: (104)
Connection reset by peer
2016/05/23 13:36:38 kid1| Error negotiating SSL connection on FD 91: (104)
Connection reset by peer
2016/05/23 13:36:39 kid1| Error negotiating SSL connection on FD 220:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
2016/05/23 13:36:43 kid1| Error negotiating SSL connection on FD 50: (104)
Connection reset by peer
2016/05/23 13:36:48 kid1| Error negotiating SSL connection on FD 579: (104)
Connection reset by peer
2016/05/23 13:36:48 kid1| Error negotiating SSL connection on FD 455: (104)
Connection reset by peer
2016/05/23 13:36:49 kid1| Error negotiating SSL connection on FD 414:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
2016/05/23 13:39:28 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, '
http://cdn.sstatic.net/Sites/stackoverflow/all.css?v=fada5080e3ea'
'accept-encoding="gzip,%20deflate"'



----------------------------Cache log End
--------------------------------------

Do we need to update openssl? I got to know these from the forum previous
post ....
If we need to update the openssl then where can we find the updated version
of CA Certs ....





On Mon, May 23, 2016 at 12:52 PM, Amos Jeffries <squid3 at treenet.co.nz>
wrote:

> On 23/05/2016 6:27 p.m., Sagar Malve wrote:
> > Hi Team,
> >
> > System Config:
> >
> > Intel S2400SC2 Motherboard
> > Intel Xeon ES 2407 V2 CPU
> > RAM 32 GB
> >
>
> What Squid version?
>
> >
> > http_port 3127
> > http_port 3128 intercept
> > https_port 3129 intercept ssl-bump generate-host-certificates=on
> > dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_certs/squid.crt
> > key=/etc/squid/ssl_certs/squid.key options=NO_SSLv3
> > tls-dh=/etc/squid/dhparam.pem
> > sslproxy_capath /etc/ssl/certs
> >
> >
> > # FILTERING HTTPS
> > acl 1 dstdomain .fbcdn.net .akamaihd.net .fbsbx.com
> > #acl 2a dstdomain .mahadana.com .mql4.com .metaquotes.net
> > acl 2 url_regex -i ^https?:\/\/attachment\.fbsbx\.com\/.*\?(id=[0-9]*).*
> > acl 2 url_regex -i
> > \.fbsbx\.com\/.*\/(.*\.(unity3d|pak|zip|exe|dll|jpg|png|gif|swf)/)$
> > acl 2 url_regex -i ^https?:\/\/.*\.ytimg\.com(.*\.(webp|jpg|gif))
> > acl 2 url_regex -i ^https?:\/\/([^\.]*)\.yimg\.com\/(.*)
> > acl 2 url_regex -i ^https?:\/\/.*\.gstatic\.com\/images\?q=tbn\:(.*)
> > acl 2 url_regex -i
> >
> ^https?:\/\/.*\.reverbnation\.com\/.*\/(ec_stream_song|download_song_direct|stream_song)\/([0-9]*).*
> > acl 2 url_regex -i
> >
> ^https?:\/\/([a-z0-9.]*)(\.doubleclick\.net|\.quantserve\.com|.exoclick\.com|interclick.\com|\.googlesyndication\.com|\.auditude\.com|.visiblemeasures\.com|yieldmanager|cpxinteractive)(.*)
> > acl 2 url_regex -i ^https?:\/\/(.*?)\/(ads)\?(.*?)
> > acl 2 url_regex -i ^https?:\/\/.*steampowered\.com\/.*\/([0-9]+\/(.*))
> > acl 3 url_regex -i
> > ^https?:\/\/(.*?)\/speedtest\/.*\.(jpg|txt|png|gif|swf)\?.*
> > acl 3 url_regex -i speedtest\/.*\.(jpg|txt|png|gif|swf)\?.*
> > acl 4 url_regex -i reverbnation.*audio_player.*ec_stream_song.*$
> > acl 5 url_regex -i utm.gif.*
> > acl 6 url_regex -i
> c.android.clients.google.com.market.GetBinary.GetBinary.*
> > acl 7 url_regex -i youtube.*(ptracking|stream_204|player_204|gen_204).*$
> > acl 7 url_regex -i
> > \.c\.(youtube|google)\.com\/(get_video|videoplayback|videoplay).*$
> > acl 7 url_regex -i (youtube|google).*\/videoplayback\?.*
> > acl 8 http_status 302
> > acl getmethod method GET
> >
>
> Using .* on the beginning or end of a regex does nothing but cause more
> CPU workload for Squid.
>
> If you put it inside (.*), or with an anchor ^.* or .*$ just makes the
> CPU usage worse.
>
> What http_access rules are using those?
>
> >
> > ssl_bump splice localhost
> > acl 9 at_step SslBump1
> > acl 10 at_step SslBump2
> > acl 11 at_step SslBump3
> > ssl_bump peek 9 all
> > ssl_bump bump 10 all
> > ssl_bump bump 11 all
>
> Step3 of bumping process will never happen. You told Squid to begin
> decryption at step2.
>
> Have you disabled "via"?
>
>
> >
> >
> ----------------------------------------------------------------------------------------------
> >
> > Is there any way where it can Cache SSL Certificate for all HTTPS Traffic
> > ....
> > Because SSL Cert & Squid process were using 99% of CPU Load ....
>
> Er, what do you think caching does exactly?
>
> Caching HTTPS will have no effect on your described CPU problem. Might
> make it worse even.
>
>
> Between them?
>
> How much is each process using?
>
> How may concurrent connections are being handled by Squid to get that
> loading ?
>
>
> Check whether Squid is finished loading its cache_dir indexes, or if any
> of them are undergoing a "DIRTY" rebuild. That can use a lot of CPU
> while its happening and caching cannot be fully operational until its
> finished either.
>
>
> >
> > We have approx 200 users ....
> >
> > I have set the open file limit to 100000
>
> FYI: SSL-Bump with your configuration will use 3 FD for each client
> inbound HTTPS request. That 100K limit will restrict your users to 150
> concurrent connections each.
> A browser using Happy eyeballs will open 16 connections to each domain.
> Average web page on the most popular sites involve around 100 objects
> spread over 10+ domains.
>   => ~160 FD needed to load an average page.
>
> I'd double that limit, if you expect this proxy to have much traffic.
>
> >
> > Could you please let us know if there is any way to Cache the HTTPS
> Request
> > in Squid .....
> >
>
> You are already SSL-Bumping traffic. That removes the 'S' from HTTPS.
> Leaving Squid with regular HTTP messages, which already are cached if it
> can.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160523/692a3b1a/attachment.htm>

From squid3 at treenet.co.nz  Mon May 23 09:11:41 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 23 May 2016 21:11:41 +1200
Subject: [squid-users] CPU Load 100% after implementing SSL Bump ....
In-Reply-To: <CAKQSiAVt2jnrH=mByuLXz-B6F92=nZCZKpGpV7=BkmfWDAntUg@mail.gmail.com>
References: <CAKQSiAU6X5gsx3AOZwLZ3pW8+DjVho7bJV6eiu0wp6KAaKB6mA@mail.gmail.com>
 <b8d315ba-00da-ef5f-7624-23d11bd53b68@treenet.co.nz>
 <CAKQSiAVt2jnrH=mByuLXz-B6F92=nZCZKpGpV7=BkmfWDAntUg@mail.gmail.com>
Message-ID: <8c6d1310-21f4-147c-a04b-e3c101896c1a@treenet.co.nz>

On 23/05/2016 8:18 p.m., Sagar Malve wrote:
> Hi Team,
> 
> Squid - Version 3.5.13
> 
> 
> Please find the below Squid Cache Logs
> 2016/05/23 13:35:55 kid1| Error negotiating SSL connection on FD 138:
> error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
> 2016/05/23 13:35:55 kid1| Error negotiating SSL connection on FD 457:
> error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
> 2016/05/23 13:36:00 kid1| Error negotiating SSL connection on FD 33:
> error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
> 2016/05/23 13:36:01 kid1| Error negotiating SSL connection on FD 438:
> error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
> 2016/05/23 13:36:05 kid1| Error negotiating SSL connection on FD 555: (104)
> Connection reset by peer
<snip>

> 
> ----------------------------Cache log End
> --------------------------------------
> 
> Do we need to update openssl? I got to know these from the forum previous
> post ....
> If we need to update the openssl then where can we find the updated version
> of CA Certs ....
> 

OpenSSL and the global "Trusted CA" certificates are separate things.

Keeping either of those to date would be a good idea even if doing so
does not solve your issue. Whatever provider was used to get your
current versions should have the latest available if you need updates.


You do need to upgrade your Squid though. Current stable is 3.5.19.
If the problems persist with that, you may want to try a 4.x beta
release. There are additional fixes only available there that might be
of use.

Your current 3.5.13 version and all later ones contain the
<http://www.squid-cache.org/Doc/config/sslproxy_foreign_intermediate_certs/>
directive for loading intermediate CA certs that some servers do not
provide. You can find talk about it and an archive maintained by Yuri in
other recent threads on this list. That can resolve some of the "unknown
ca" occurances.

Amos



From mark at ecs.vuw.ac.nz  Mon May 23 10:02:39 2016
From: mark at ecs.vuw.ac.nz (Mark Davies)
Date: Mon, 23 May 2016 22:02:39 +1200
Subject: [squid-users] squid 3.5.19, wccp2, pf and forwarding loop
In-Reply-To: <30208c77-3503-9ceb-599c-86b754d5766b@treenet.co.nz>
References: <1919047.7upNBdQFDu@city-art.ecs.vuw.ac.nz>
 <5875225e-2796-ee35-2130-461312f8dee1@treenet.co.nz>
 <5742AABF.8030306@ecs.vuw.ac.nz>
 <30208c77-3503-9ceb-599c-86b754d5766b@treenet.co.nz>
Message-ID: <5742D53F.3010303@ecs.vuw.ac.nz>

On 23/05/16 19:32, Amos Jeffries wrote:
> There are two other things to check then.
>
> Firstly, if the router receiving the wm0 traffic is the one doing WCCP
>   divert into Squid. It needs a similar excemption of that outgoing traffic.

Its a different router.

> Secondly,
>   in squid.conf enable "debug_options 28,4" and see what it logs in
> cache.log about the bnx0 interface.
>   I suspect Squid might be detecting it as a non-Ethernet interface and
> so not pulling the IP details correctly from the NAT.

Given the amount of ordinary squid traffic going through the box it was
difficult to separate the log entries for the intercepted traffic from 
all the others, but this did point me at "debug_options 89,9" which 
showed me the actual problem.

When building I had "--enable-pf-transparent" but not
"--with-nat-devpf".  Adding the second fixed the problem.

cheers
mark


From eliezer at ngtech.co.il  Mon May 23 11:26:08 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 23 May 2016 14:26:08 +0300
Subject: [squid-users] What are the chunks per request limits in squid? if
	at all? and Is there any client that comply with Retry-After
	response?
Message-ID: <06c501d1b4e5$e6d7d530$b4877f90$@ngtech.co.il>

Is there any limit to the amount of chunks per range request in squid?
I tried to read the RFCs:
https://tools.ietf.org/html/rfc7231#section-7.1.3
https://tools.ietf.org/html/rfc7233#section-3.1

But It was a bit hard for me to understand if there is a limit.
Currently I have seen MS updates trying to fetch about 16 ranges per request
with "if-modified-since X".
>From What I understand squid should be able to fulfill each and every one of
these requests if it has the full file 
but it will fetch each and every chunk or at-least validate against the
origin service.

And I was also wondering about squid compliance to "Retry-After" RFC, is
there any known client which actually implements support for that feature? 

Eliezer

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 63277 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160523/0241a95b/attachment.bin>

From eliezer at ngtech.co.il  Mon May 23 12:03:53 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 23 May 2016 15:03:53 +0300
Subject: [squid-users] What are the chunks per request limits in squid? if
	at all? and Is there any client that comply with Retry-After
	response?
Message-ID: <070501d1b4eb$2cf0fc40$86d2f4c0$@ngtech.co.il>

Is there any limit to the amount of chunks per range request in squid?
I tried to read the RFCs:
https://tools.ietf.org/html/rfc7231#section-7.1.3
https://tools.ietf.org/html/rfc7233#section-3.1

But It was a bit hard for me to understand if there is a limit.
Currently I have seen MS updates trying to fetch about 16 ranges per request
with "if-modified-since X".
>From What I understand squid should be able to fulfill each and every one of
these requests if it has the full file 
but it will fetch each and every chunk or at-least validate against the
origin service.

And I was also wondering about squid compliance to "Retry-After" RFC, is
there any known client which actually implements support for that feature? 

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
 




From dan at getbusi.com  Tue May 24 05:44:06 2016
From: dan at getbusi.com (Dan Charlesworth)
Date: Tue, 24 May 2016 15:44:06 +1000
Subject: [squid-users] How to analyse squid memory usage
In-Reply-To: <E0EA512C-DC76-4D74-B95F-2635BF58C523@getbusi.com>
References: <B60DFE6C-9BA8-42CA-9B57-A2460517A35F@getbusi.com>
 <085044c5-9a62-8b6f-47e6-cee4410dfac9@treenet.co.nz>
 <421A4120-10F7-4694-94AF-B66C3CDF1D3E@getbusi.com>
 <E0EA512C-DC76-4D74-B95F-2635BF58C523@getbusi.com>
Message-ID: <5F7F29D5-F9E2-4FD2-9B9B-25DFE9E02E48@getbusi.com>

Gentle bump ?

-------------- next part --------------
A non-text attachment was scrubbed...
Name: normal-mem.tsv
Type: text/tab-separated-values
Size: 18774 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160524/9c4995c0/attachment.tsv>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: leaky-mem.tsv
Type: text/tab-separated-values
Size: 17652 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160524/9c4995c0/attachment-0001.tsv>
-------------- next part --------------

> On 12 May 2016, at 11:37 AM, Dan Charlesworth <dan at getbusi.com> wrote:
> 
> I?ve now got mgr:mem output from a leaky box for comparison but I?m having a hard time spotting where the problem might be.
> 
> Would anyone more experienced mind taking at these and seeing if anything jumps out as a source of the high memory usage?
> 
>  - The leaky example has 8GB of server memory and 5.7GB was allocated to squid when the snapshot was taken.
> 
>  - The normal example has 12GB of server memory and 2.9GB was allocated to Squid when the snapshot was taken.
> 
> <leaky-mem.tsv><normal-mem.tsv>
> 
> Thanks!
> 
>> On 11 May 2016, at 2:37 PM, Dan Charlesworth <dan at getbusi.com> wrote:
>> 
>> Thanks Amos -
>> 
>> Not sure how self-explanatory the output is, though.
>> 
>> I?ve attached the output from a site with a 12GB server where top was showing 2.9GB allocated to squid (this is normal e.g. ?the control"). But the mem output shows the allocated total as ~1GB, apparently?
>> 
>> Maybe things will become clearer once I have a ?leaky? server?s output to compare with it.
>> 
>> <bdc-mem.tsv>
>> 
>>> On 10 May 2016, at 6:02 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>> 
>>> On 10/05/2016 2:35 p.m., Dan Charlesworth wrote:
>>>> A small percentage of deployments of our squid-based product are using oodles of memory?there doesn?t seem to be a limit to it.
>>>> 
>>>> I?m wondering what the best way might be to analyse what squid is reserving it all for in the latest 3.5 release?
>>>> 
>>>> The output of squidclient mgr:cache_mem is completely incomprehensible to me.
>>> 
>>> Try mgr:mem report. It is TSV (tab-separated values) file format.
>>> 
>>> squidclient mgr:mem > mem.tsv
>>> 
>>> ... and load mem.tsv using your favourite spreadsheet program. The
>>> column titles should then be self-explanatory.
>>> 
>>> Amos
>>> 
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> 
> 


From hydrapolic at gmail.com  Tue May 24 07:52:21 2016
From: hydrapolic at gmail.com (Tomas Mozes)
Date: Tue, 24 May 2016 09:52:21 +0200
Subject: [squid-users] pinger crash - Bad opcode: 112
Message-ID: <CAG6MAzT+JQP0Bd+UDHN3zwigU6W8H6oGYxXdn3iVhuYqU=qZpg@mail.gmail.com>

Hello,
on two different squid servers I've observed a crash of pinger. First it
appeared on version 3.5.15 and later on version 3.5.17.

Cache.log contains these lines:

(pinger): Address.cc:671: void Ip::Address::getAddrInfo(addrinfo*&, int)
const: Assertion `false' failed.
2016/05/14 21:55:25 kid1| Bad opcode: 112 from
[6661:6c73:6522:2061:7420:6c69:6e65:2036]
2016/05/14 21:59:13 kid1| recv: (111) Connection refused
2016/05/14 21:59:13 kid1| Closing Pinger socket on FD 17

On both servers, that IPv6 address was the same -
6661:6c73:6522:2061:7420:6c69:6e65:2036

A quick google search for that showed problems with Squid from the past:
http://www.squid-cache.org/mail-archive/squid-users/201301/0251.html

The strange thing is that I have IPv6 disabled in the system (not even as a
module in the Linux kernel) and Squid was compiled without ipv6 support.

How can I help tracing this issue?

Thanks,
Tomas Mozes
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160524/ad4eca37/attachment.htm>

From buechlerml at hdpnet.de  Tue May 24 08:15:16 2016
From: buechlerml at hdpnet.de (Paul Buechler)
Date: Tue, 24 May 2016 10:15:16 +0200
Subject: [squid-users] google drive up-/download size in squidlog
Message-ID: <57440D94.1080703@hdpnet.de>

Hello there,

i've got the problem that i can't see the size of uploades to google 
drive in the access.log. Also the downloads aren't visible to me.
Is this a problem caused by HTTPS? I tried changing the logformat but 
this didn't helped.

best regards,
Paul


systeminformation:

ubuntu 14.04.4 Server
squid: Version 3.3.8
squid logformat: logformat combined   %>a %[ui %[un [%tl] "%rm %ru 
HTTP/%rv" %>Hs %<st "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
also tested:
logformat squid%ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un %Sh/%<a %mt
logformat common%>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st %Ss:%Sh
logformat referrer%ts.%03tu %>a %{Referer}>h %ru
logformat useragent%>a [%tl] "%{User-Agent}>h"
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160524/147fb802/attachment.htm>

From yvoinov at gmail.com  Tue May 24 16:02:58 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 24 May 2016 22:02:58 +0600
Subject: [squid-users] google drive up-/download size in squidlog
In-Reply-To: <57440D94.1080703@hdpnet.de>
References: <57440D94.1080703@hdpnet.de>
Message-ID: <2f91d6aa-3aa2-d0ac-5377-61486d35f650@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Google Drive application?


24.05.16 14:15, Paul Buechler ?????:
> Hello there,
>
> i've got the problem that i can't see the size of uploades to google
drive in the access.log. Also the downloads aren't visible to me.
> Is this a problem caused by HTTPS? I tried changing the logformat but
this didn't helped.
>
> best regards,
> Paul
>
>
> systeminformation:
>
> ubuntu 14.04.4 Server
> squid: Version 3.3.8
> squid logformat: logformat combined   %>a %[ui %[un [%tl] "%rm %ru
HTTP/%rv" %>Hs %<st "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
> also tested:
> logformat squid      %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un
%Sh/%<a %mt
> logformat common     %>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st
%Ss:%Sh
> logformat referrer   %ts.%03tu %>a %{Referer}>h %ru
> logformat useragent  %>a [%tl] "%{User-Agent}>h"
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXRHsyAAoJENNXIZxhPexG9Q4IALY2DySGmczKje4IoHj8sWzh
vKo7YXbomYfcjP9bwraEPMeQUZAVrMgNEZnYzqZo6LVIQoF712wHt22hcYLUMwF6
O6tgDhKiWqJGjDz5iROsVjK1HCHgLo5h1I32szuZK2Vm/cvCnwZ55+NXvO4Zrs0Q
PCDmWExCB+CTf+ArQnp2uN2y8rKwdsV3EBpPnmFgTxlts+62w6pmH0ehY2r5XWMp
id3SYW91RzmcPDqF1Oz/HWxEJczGENTjWHAz8+ocZPwIzwGhXLub+mGfvyFnTaf8
BAFRGZk7u/TLE1uqS6osiQRXZRLv6XYj/1ekIyn860+vmk0nsZM7a7mwiqYIcuo=
=J87g
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160524/8ec05869/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160524/8ec05869/attachment.key>

From heiler.bemerguy at cinbesa.com.br  Tue May 24 17:46:59 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 24 May 2016 14:46:59 -0300
Subject: [squid-users] ERROR: Collapsed forwarding queue overflow for kid2
	at 1024 items
Message-ID: <460acb1d-cd3e-7a43-c573-90ef975105ea@cinbesa.com.br>


Hi guys

2016/05/24 14:43:41 kid3| ctx: enter level  0: 
'http://www.msn.com/pt-br/?ocid=iehp'
2016/05/24 14:43:41 kid3| ERROR: Collapsed forwarding queue overflow for 
kid2 at 1024 items
2016/05/24 14:43:41 kid3| ctx: exit level  0
2016/05/24 14:43:41 kid3| ERROR: Collapsed forwarding queue overflow for 
kid2 at 1024 items
2016/05/24 14:43:41 kid3| ERROR: Collapsed forwarding queue overflow for 
kid2 at 1024 items

1464111898.361    118 10.11.0.98 TCP_HIT_ABORTED/000 0 GET 
http://www.msn.com/pt-br/? - HIER_NONE/- -
1464111898.385    146 10.11.0.98 TCP_HIT_ABORTED/000 0 GET 
http://www.msn.com/pt-br/? - HIER_NONE/- -
1464111898.385    163 10.11.0.98 TCP_HIT_ABORTED/000 0 GET 
http://www.msn.com/pt-br/? - HIER_NONE/- -
1464111898.385    164 10.11.0.98 TCP_HIT_ABORTED/000 0 GET 
http://www.msn.com/pt-br/? - HIER_NONE/- -
1464111898.385    164 10.11.0.98 TCP_MISS_ABORTED/000 0 GET 
http://www.msn.com/pt-br/? - HIER_DIRECT/131.253.33.203 -
1464111905.666    970 10.102.4.21 TCP_MISS/200 67099 GET 
http://www.msn.com/pt-br/? - HIER_DIRECT/131.253.33.203 text/html
1464111910.484    759 10.102.1.102 TCP_MISS/200 26188 GET 
http://www.msn.com/pt-br/? - HIER_DIRECT/131.253.33.203 text/html


Is this normal?

conf:

client_idle_pconn_timeout 30 seconds
client_persistent_connections on
server_persistent_connections on
collapsed_forwarding on

Best Regards,

-- 
Heiler Bemerguy - (91) 98151-4894
Assessor T?cnico - CINBESA (91) 3184-1751

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160524/510f68e6/attachment.htm>

From denizlist at denizeren.net  Tue May 24 17:50:34 2016
From: denizlist at denizeren.net (Deniz Eren)
Date: Tue, 24 May 2016 20:50:34 +0300
Subject: [squid-users] Excessive TCP memory usage
Message-ID: <CAHQdsZ8ZE=KMC4ytuz7TdAd_=aHnpYPcxYxxst=qB01MPkLj3g@mail.gmail.com>

Hi,

After upgrading to squid 3.5.16 I realized that squid started using
much of kernel's TCP memory.

When squid was running for a long time TCP memory usage is like below:
test at test:~$ cat /proc/net/sockstat
sockets: used *
TCP: inuse * orphan * tw * alloc * mem 200000
UDP: inuse * mem *
UDPLITE: inuse *
RAW: inuse *
FRAG: inuse * memory *

When I restart squid the memory usage drops dramatically:
test at test:~$ cat /proc/net/sockstat
sockets: used *
TCP: inuse * orphan * tw * alloc * mem 10
UDP: inuse * mem *
UDPLITE: inuse *
RAW: inuse *
FRAG: inuse * memory *

I'm using Squid 3.5.16.

When I look with "netstat" and "ss" I see lots of CLOSE_WAIT
connections from squid to ICAP or from squid to upstream server.

Do you have any idea about this problem?

Regards,


From squid3 at treenet.co.nz  Tue May 24 18:32:35 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 25 May 2016 06:32:35 +1200
Subject: [squid-users] google drive up-/download size in squidlog
In-Reply-To: <57440D94.1080703@hdpnet.de>
References: <57440D94.1080703@hdpnet.de>
Message-ID: <009a89d8-79af-45e9-ee97-7baa5e24ceac@treenet.co.nz>

On 24/05/2016 8:15 p.m., Paul Buechler wrote:
> Hello there,
> 
> i've got the problem that i can't see the size of uploades to google
> drive in the access.log. Also the downloads aren't visible to me.
> Is this a problem caused by HTTPS? I tried changing the logformat but
> this didn't helped.

All the normal logs are recording teh data transferred to client. NOt
from client.

You need to create a custom logformat of your own which uses the %st
code instead of the %<st code.
<http://www.squid-cache.org/Doc/config/logformat/>

> 
> best regards,
> Paul
> 
> 
> systeminformation:
> 
> ubuntu 14.04.4 Server
> squid: Version 3.3.8
> squid logformat: logformat combined   %>a %[ui %[un [%tl] "%rm %ru
> HTTP/%rv" %>Hs %<st "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
> also tested:
> logformat squid%ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un %Sh/%<a %mt
> logformat common%>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st %Ss:%Sh
> logformat referrer%ts.%03tu %>a %{Referer}>h %ru
> logformat useragent%>a [%tl] "%{User-Agent}>h"
> 

Please do not re-define the built in format names. Use a name of your
own. Unexpected and probably not good things will happen.

Amos



From squid3 at treenet.co.nz  Tue May 24 18:47:36 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 25 May 2016 06:47:36 +1200
Subject: [squid-users] Excessive TCP memory usage
In-Reply-To: <CAHQdsZ8ZE=KMC4ytuz7TdAd_=aHnpYPcxYxxst=qB01MPkLj3g@mail.gmail.com>
References: <CAHQdsZ8ZE=KMC4ytuz7TdAd_=aHnpYPcxYxxst=qB01MPkLj3g@mail.gmail.com>
Message-ID: <20948875-1d61-94eb-a6ec-f3d93ea716ec@treenet.co.nz>

On 25/05/2016 5:50 a.m., Deniz Eren wrote:
> Hi,
> 
> After upgrading to squid 3.5.16 I realized that squid started using
> much of kernel's TCP memory.

Upgrade from which version?

> 
> When squid was running for a long time TCP memory usage is like below:
> test at test:~$ cat /proc/net/sockstat
> sockets: used *
> TCP: inuse * orphan * tw * alloc * mem 200000
> UDP: inuse * mem *
> UDPLITE: inuse *
> RAW: inuse *
> FRAG: inuse * memory *
> 
> When I restart squid the memory usage drops dramatically:

Of course it does. By restarting you just erased all of the operational
state for an unknown but large number of active network connections.

Whether many of those should have been still active or not is a
different question. the answer to which depends on how you have your
Squid configured, and what the traffic through it has been doing.


> test at test:~$ cat /proc/net/sockstat
> sockets: used *
> TCP: inuse * orphan * tw * alloc * mem 10
> UDP: inuse * mem *
> UDPLITE: inuse *
> RAW: inuse *
> FRAG: inuse * memory *
> 

The numbers you replaced with "*" are rather important for context.


> I'm using Squid 3.5.16.
> 

Please upgrade to 3.5.19. Some important issues have been resolved. Some
of them may be related to your TCP memory problem.


> When I look with "netstat" and "ss" I see lots of CLOSE_WAIT
> connections from squid to ICAP or from squid to upstream server.
> 
> Do you have any idea about this problem?

Memory use by the TCP system of your kernel has very little to do with
Squid. Number of sockets in CLOSE_WAIT does have some relation to Squid
or at least to how the traffic going through it is handled.

If you have disabled persistent connections in squid.conf then lots of
closed sockets and FD are to be expected.

If you have persistent connections enabled, then fewer closures should
happen. But some will so expectations depends on how high the traffic
load is.

Amos



From heiler.bemerguy at cinbesa.com.br  Tue May 24 20:26:57 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 24 May 2016 17:26:57 -0300
Subject: [squid-users] server request timeout not working
Message-ID: <eb50b78f-b7d3-41e7-8a98-cbd914ad8490@cinbesa.com.br>


If you connect to squid and ask it to get a file on a server which 
accepts the tcp connection but won't reply anything, the connection will 
never timeout.

Like this: (client side)

GET http://10.1.4.60:8080/pehasuzyjireohwwlik.txt HTTP/1.1
Accept: */*
Accept-Encoding: identity
Range: bytes=20-80
User-Agent: FakeUser/0.0
Proxy-Connection: Keep-Alive
Host: 10.1.4.60

Gives this on server side:

GET /pehasuzyjireohwwlik.txt HTTP/1.1
Accept: */*
Accept-Encoding: identity
User-Agent: FakeUser/0.0
Host: 10.1.4.60:8080
Via: 1.1 jasperserver (squid)
X-Forwarded-For: 10.1.4.60
Cache-Control: max-age=29030400
Connection: keep-alive

It does connect to 10.1.4.60:8080, this port is open and accepting 
connections.. but it won't reply anything to squid, and squid will 
remain connected to it and waiting forever

client_idle_pconn_timeout 30 seconds

client_persistent_connections on
server_persistent_connections on
connect_timeout 60 seconds
request_timeout 30 seconds
persistent_request_timeout 30 seconds
collapsed_forwarding on


Best Regards,

-- 
Heiler Bemerguy - (91) 98151-4894
Assessor T?cnico - CINBESA (91) 3184-1751

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160524/d427e465/attachment.htm>

From squid3 at treenet.co.nz  Tue May 24 20:32:32 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 25 May 2016 08:32:32 +1200
Subject: [squid-users] ERROR: Collapsed forwarding queue overflow for
 kid2 at 1024 items
In-Reply-To: <460acb1d-cd3e-7a43-c573-90ef975105ea@cinbesa.com.br>
References: <460acb1d-cd3e-7a43-c573-90ef975105ea@cinbesa.com.br>
Message-ID: <5f67f88c-3253-7158-5388-74641f59a00d@treenet.co.nz>

On 25/05/2016 5:46 a.m., Heiler Bemerguy wrote:
> 
> Hi guys
> 
> 2016/05/24 14:43:41 kid3| ctx: enter level  0:
> 'http://www.msn.com/pt-br/?ocid=iehp'
> 2016/05/24 14:43:41 kid3| ERROR: Collapsed forwarding queue overflow for
> kid2 at 1024 items
> 2016/05/24 14:43:41 kid3| ctx: exit level  0
> 2016/05/24 14:43:41 kid3| ERROR: Collapsed forwarding queue overflow for
> kid2 at 1024 items
> 2016/05/24 14:43:41 kid3| ERROR: Collapsed forwarding queue overflow for
> kid2 at 1024 items
> 
> 1464111898.361    118 10.11.0.98 TCP_HIT_ABORTED/000 0 GET
> http://www.msn.com/pt-br/? - HIER_NONE/- -
> 1464111898.385    146 10.11.0.98 TCP_HIT_ABORTED/000 0 GET
> http://www.msn.com/pt-br/? - HIER_NONE/- -
> 1464111898.385    163 10.11.0.98 TCP_HIT_ABORTED/000 0 GET
> http://www.msn.com/pt-br/? - HIER_NONE/- -
> 1464111898.385    164 10.11.0.98 TCP_HIT_ABORTED/000 0 GET
> http://www.msn.com/pt-br/? - HIER_NONE/- -
> 1464111898.385    164 10.11.0.98 TCP_MISS_ABORTED/000 0 GET
> http://www.msn.com/pt-br/? - HIER_DIRECT/131.253.33.203 -
> 1464111905.666    970 10.102.4.21 TCP_MISS/200 67099 GET
> http://www.msn.com/pt-br/? - HIER_DIRECT/131.253.33.203 text/html
> 1464111910.484    759 10.102.1.102 TCP_MISS/200 26188 GET
> http://www.msn.com/pt-br/? - HIER_DIRECT/131.253.33.203 text/html
> 
> 
> Is this normal?

Depends on your normal.

AIUI, that "ERROR:" message means thehre are more than 1024 concurrent
transactions being collapsed by your proxy and the overflowed one is
failing.

So the questions are;
 why are there so many?
and,
 is that number of requests normal for your traffic?


> 
> conf:
> 
> client_idle_pconn_timeout 30 seconds
> client_persistent_connections on
> server_persistent_connections on
> collapsed_forwarding on
> 
> Best Regards,
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From denizlist at denizeren.net  Wed May 25 07:37:47 2016
From: denizlist at denizeren.net (Deniz Eren)
Date: Wed, 25 May 2016 10:37:47 +0300
Subject: [squid-users] Excessive TCP memory usage
In-Reply-To: <20948875-1d61-94eb-a6ec-f3d93ea716ec@treenet.co.nz>
References: <CAHQdsZ8ZE=KMC4ytuz7TdAd_=aHnpYPcxYxxst=qB01MPkLj3g@mail.gmail.com>
 <20948875-1d61-94eb-a6ec-f3d93ea716ec@treenet.co.nz>
Message-ID: <CAHQdsZ9BWF42WjeXuNxDt3XdJq3JcO0XP1zQa8ebb0P8h9CDPg@mail.gmail.com>

2016-05-24 21:47 GMT+03:00 Amos Jeffries <squid3 at treenet.co.nz>:
> On 25/05/2016 5:50 a.m., Deniz Eren wrote:
>> Hi,
>>
>> After upgrading to squid 3.5.16 I realized that squid started using
>> much of kernel's TCP memory.
>
> Upgrade from which version?
>
Upgrading from squid 3.1.14. I started using c-icap and ssl-bump.

>>
>> When squid was running for a long time TCP memory usage is like below:
>> test at test:~$ cat /proc/net/sockstat
>> sockets: used *
>> TCP: inuse * orphan * tw * alloc * mem 200000
>> UDP: inuse * mem *
>> UDPLITE: inuse *
>> RAW: inuse *
>> FRAG: inuse * memory *
>>
>> When I restart squid the memory usage drops dramatically:
>
> Of course it does. By restarting you just erased all of the operational
> state for an unknown but large number of active network connections.
>
That's true but what I mean was squid's CLOSE_WAIT connections are
using too much memory and they are not timing out.

> Whether many of those should have been still active or not is a
> different question. the answer to which depends on how you have your
> Squid configured, and what the traffic through it has been doing.
>
>
>> test at test:~$ cat /proc/net/sockstat
>> sockets: used *
>> TCP: inuse * orphan * tw * alloc * mem 10
>> UDP: inuse * mem *
>> UDPLITE: inuse *
>> RAW: inuse *
>> FRAG: inuse * memory *
>>
>
> The numbers you replaced with "*" are rather important for context.
>
>
Today again I saw the problem:

test at test:~$ cat /proc/net/sockstat
sockets: used 1304
TCP: inuse 876 orphan 81 tw 17 alloc 906 mem 29726
UDP: inuse 17 mem 8
UDPLITE: inuse 0
RAW: inuse 1
FRAG: inuse 0 memory 0

>> I'm using Squid 3.5.16.
>>
>
> Please upgrade to 3.5.19. Some important issues have been resolved. Some
> of them may be related to your TCP memory problem.
>
>
I have upgraded now and problem still exists.

>> When I look with "netstat" and "ss" I see lots of CLOSE_WAIT
>> connections from squid to ICAP or from squid to upstream server.
>>
>> Do you have any idea about this problem?
>
> Memory use by the TCP system of your kernel has very little to do with
> Squid. Number of sockets in CLOSE_WAIT does have some relation to Squid
> or at least to how the traffic going through it is handled.
>
> If you have disabled persistent connections in squid.conf then lots of
> closed sockets and FD are to be expected.
>
> If you have persistent connections enabled, then fewer closures should
> happen. But some will so expectations depends on how high the traffic
> load is.
>
Persistent connection parameters are enabled in my conf, the problem
occurs especially with connections to c-icap service.

My netstat output is like this:
netstat -tulnap|grep squid|grep CLOSE

tcp   211742      0 127.0.0.1:55751             127.0.0.1:1344
     CLOSE_WAIT  17076/(squid-1)
tcp   215700      0 127.0.0.1:55679             127.0.0.1:1344
     CLOSE_WAIT  17076/(squid-1)
tcp   215704      0 127.0.0.1:55683             127.0.0.1:1344
     CLOSE_WAIT  17076/(squid-1)
...(hundreds)
Above ones are connections to c-icap service.

netstat -tulnap|grep squid|grep CLOSE
Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address               Foreign Address
     State       PID/Program name
tcp        1      0 192.168.2.1:8443            192.168.6.180:45182
     CLOSE_WAIT  15245/(squid-1)
tcp        1      0 192.168.2.1:8443            192.168.2.177:50020
     CLOSE_WAIT  15245/(squid-1)
tcp        1      0 192.168.2.1:8443            192.168.2.172:60028
     CLOSE_WAIT  15245/(squid-1)
tcp        1      0 192.168.2.1:8443            192.168.6.180:44049
     CLOSE_WAIT  15245/(squid-1)
tcp        1      0 192.168.2.1:8443            192.168.6.180:55054
     CLOSE_WAIT  15245/(squid-1)
tcp        1      0 192.168.2.1:8443            192.168.2.137:52177
     CLOSE_WAIT  15245/(squid-1)
tcp        1      0 192.168.2.1:8443            192.168.6.180:43542
     CLOSE_WAIT  15245/(squid-1)
tcp        1      0 192.168.2.1:8443            192.168.6.155:39489
     CLOSE_WAIT  15245/(squid-1)
tcp        1      0 192.168.2.1:8443            192.168.0.147:38939
     CLOSE_WAIT  15245/(squid-1)
tcp        1      0 192.168.2.1:8443            192.168.6.180:38754
     CLOSE_WAIT  15245/(squid-1)
tcp        1      0 192.168.2.1:8443            192.168.0.164:39602
     CLOSE_WAIT  15245/(squid-1)
tcp        1      0 192.168.2.1:8443            192.168.0.147:54114
     CLOSE_WAIT  15245/(squid-1)
tcp        1      0 192.168.2.1:8443            192.168.6.180:57857
     CLOSE_WAIT  15245/(squid-1)
tcp        1      0 192.168.2.1:8443            192.168.0.156:43482
     CLOSE_WAIT  15245/(squid-1)
...(about 50)
Above ones are connections from https port to client.

As you can see recv-q for icap connections allocate more memory but
connections from https_port to upstream server connections allocate
only one byte.

 What can be done to close these unused connections?

The problem in this thread seems similar:
http://www.squid-cache.org/mail-archive/squid-users/201301/0092.html

> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From denizlist at denizeren.net  Wed May 25 10:18:27 2016
From: denizlist at denizeren.net (Deniz Eren)
Date: Wed, 25 May 2016 13:18:27 +0300
Subject: [squid-users] Excessive TCP memory usage
In-Reply-To: <CAHQdsZ9BWF42WjeXuNxDt3XdJq3JcO0XP1zQa8ebb0P8h9CDPg@mail.gmail.com>
References: <CAHQdsZ8ZE=KMC4ytuz7TdAd_=aHnpYPcxYxxst=qB01MPkLj3g@mail.gmail.com>
 <20948875-1d61-94eb-a6ec-f3d93ea716ec@treenet.co.nz>
 <CAHQdsZ9BWF42WjeXuNxDt3XdJq3JcO0XP1zQa8ebb0P8h9CDPg@mail.gmail.com>
Message-ID: <CAHQdsZ-enqmicp4RKjLs-NoXUdky1-wU-PnHh5DZ44No65290A@mail.gmail.com>

When I listen to connections between squid and icap using tcpdump I
saw that after a while icap closes the connection but squid does not
close, so connection stays in CLOSE_WAIT state:

[root at test ~]# tcpdump -i any -n port 34693
tcpdump: WARNING: Promiscuous mode not supported on the "any" device
tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
listening on any, link-type LINUX_SLL (Linux cooked), capture size 96 bytes
13:07:31.802238 IP 127.0.0.1.icap > 127.0.0.1.34693: F
2207817997:2207817997(0) ack 710772005 win 395 <nop,nop,timestamp
104616992 104016968>
13:07:31.842186 IP 127.0.0.1.34693 > 127.0.0.1.icap: . ack 1 win 3186
<nop,nop,timestamp 104617032 104616992>

[root at test ~]# netstat -tulnap|grep 34693
tcp   215688      0 127.0.0.1:34693             127.0.0.1:1344
     CLOSE_WAIT  19740/(squid-1)

These CLOSE_WAIT connections do not timeout and stay until squid
process is killed.

2016-05-25 10:37 GMT+03:00 Deniz Eren <denizlist at denizeren.net>:
> 2016-05-24 21:47 GMT+03:00 Amos Jeffries <squid3 at treenet.co.nz>:
>> On 25/05/2016 5:50 a.m., Deniz Eren wrote:
>>> Hi,
>>>
>>> After upgrading to squid 3.5.16 I realized that squid started using
>>> much of kernel's TCP memory.
>>
>> Upgrade from which version?
>>
> Upgrading from squid 3.1.14. I started using c-icap and ssl-bump.
>
>>>
>>> When squid was running for a long time TCP memory usage is like below:
>>> test at test:~$ cat /proc/net/sockstat
>>> sockets: used *
>>> TCP: inuse * orphan * tw * alloc * mem 200000
>>> UDP: inuse * mem *
>>> UDPLITE: inuse *
>>> RAW: inuse *
>>> FRAG: inuse * memory *
>>>
>>> When I restart squid the memory usage drops dramatically:
>>
>> Of course it does. By restarting you just erased all of the operational
>> state for an unknown but large number of active network connections.
>>
> That's true but what I mean was squid's CLOSE_WAIT connections are
> using too much memory and they are not timing out.
>
>> Whether many of those should have been still active or not is a
>> different question. the answer to which depends on how you have your
>> Squid configured, and what the traffic through it has been doing.
>>
>>
>>> test at test:~$ cat /proc/net/sockstat
>>> sockets: used *
>>> TCP: inuse * orphan * tw * alloc * mem 10
>>> UDP: inuse * mem *
>>> UDPLITE: inuse *
>>> RAW: inuse *
>>> FRAG: inuse * memory *
>>>
>>
>> The numbers you replaced with "*" are rather important for context.
>>
>>
> Today again I saw the problem:
>
> test at test:~$ cat /proc/net/sockstat
> sockets: used 1304
> TCP: inuse 876 orphan 81 tw 17 alloc 906 mem 29726
> UDP: inuse 17 mem 8
> UDPLITE: inuse 0
> RAW: inuse 1
> FRAG: inuse 0 memory 0
>
>>> I'm using Squid 3.5.16.
>>>
>>
>> Please upgrade to 3.5.19. Some important issues have been resolved. Some
>> of them may be related to your TCP memory problem.
>>
>>
> I have upgraded now and problem still exists.
>
>>> When I look with "netstat" and "ss" I see lots of CLOSE_WAIT
>>> connections from squid to ICAP or from squid to upstream server.
>>>
>>> Do you have any idea about this problem?
>>
>> Memory use by the TCP system of your kernel has very little to do with
>> Squid. Number of sockets in CLOSE_WAIT does have some relation to Squid
>> or at least to how the traffic going through it is handled.
>>
>> If you have disabled persistent connections in squid.conf then lots of
>> closed sockets and FD are to be expected.
>>
>> If you have persistent connections enabled, then fewer closures should
>> happen. But some will so expectations depends on how high the traffic
>> load is.
>>
> Persistent connection parameters are enabled in my conf, the problem
> occurs especially with connections to c-icap service.
>
> My netstat output is like this:
> netstat -tulnap|grep squid|grep CLOSE
>
> tcp   211742      0 127.0.0.1:55751             127.0.0.1:1344
>      CLOSE_WAIT  17076/(squid-1)
> tcp   215700      0 127.0.0.1:55679             127.0.0.1:1344
>      CLOSE_WAIT  17076/(squid-1)
> tcp   215704      0 127.0.0.1:55683             127.0.0.1:1344
>      CLOSE_WAIT  17076/(squid-1)
> ...(hundreds)
> Above ones are connections to c-icap service.
>
> netstat -tulnap|grep squid|grep CLOSE
> Active Internet connections (servers and established)
> Proto Recv-Q Send-Q Local Address               Foreign Address
>      State       PID/Program name
> tcp        1      0 192.168.2.1:8443            192.168.6.180:45182
>      CLOSE_WAIT  15245/(squid-1)
> tcp        1      0 192.168.2.1:8443            192.168.2.177:50020
>      CLOSE_WAIT  15245/(squid-1)
> tcp        1      0 192.168.2.1:8443            192.168.2.172:60028
>      CLOSE_WAIT  15245/(squid-1)
> tcp        1      0 192.168.2.1:8443            192.168.6.180:44049
>      CLOSE_WAIT  15245/(squid-1)
> tcp        1      0 192.168.2.1:8443            192.168.6.180:55054
>      CLOSE_WAIT  15245/(squid-1)
> tcp        1      0 192.168.2.1:8443            192.168.2.137:52177
>      CLOSE_WAIT  15245/(squid-1)
> tcp        1      0 192.168.2.1:8443            192.168.6.180:43542
>      CLOSE_WAIT  15245/(squid-1)
> tcp        1      0 192.168.2.1:8443            192.168.6.155:39489
>      CLOSE_WAIT  15245/(squid-1)
> tcp        1      0 192.168.2.1:8443            192.168.0.147:38939
>      CLOSE_WAIT  15245/(squid-1)
> tcp        1      0 192.168.2.1:8443            192.168.6.180:38754
>      CLOSE_WAIT  15245/(squid-1)
> tcp        1      0 192.168.2.1:8443            192.168.0.164:39602
>      CLOSE_WAIT  15245/(squid-1)
> tcp        1      0 192.168.2.1:8443            192.168.0.147:54114
>      CLOSE_WAIT  15245/(squid-1)
> tcp        1      0 192.168.2.1:8443            192.168.6.180:57857
>      CLOSE_WAIT  15245/(squid-1)
> tcp        1      0 192.168.2.1:8443            192.168.0.156:43482
>      CLOSE_WAIT  15245/(squid-1)
> ...(about 50)
> Above ones are connections from https port to client.
>
> As you can see recv-q for icap connections allocate more memory but
> connections from https_port to upstream server connections allocate
> only one byte.
>
>  What can be done to close these unused connections?
>
> The problem in this thread seems similar:
> http://www.squid-cache.org/mail-archive/squid-users/201301/0092.html
>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users


From heiler.bemerguy at cinbesa.com.br  Wed May 25 15:35:56 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Wed, 25 May 2016 12:35:56 -0300
Subject: [squid-users] ERROR: Collapsed forwarding queue overflow for
 kid2 at 1024 items
In-Reply-To: <5f67f88c-3253-7158-5388-74641f59a00d@treenet.co.nz>
References: <460acb1d-cd3e-7a43-c573-90ef975105ea@cinbesa.com.br>
 <5f67f88c-3253-7158-5388-74641f59a00d@treenet.co.nz>
Message-ID: <82c60512-9766-ddbe-58a6-b569f28fedf5@cinbesa.com.br>


I don't know if there's something "in loop".. that's why I'm asking...

Start Time:     Fri, 20 May 2016 10:42:20 GMT
Current Time:   Wed, 25 May 2016 15:34:42 GMT
Connection information for squid:
         Number of clients accessing cache:      4745
         Number of HTTP requests received:       4037126
         Number of ICP messages received:        149496
         Number of ICP messages sent:    149496
         Number of queued ICP replies:   0
         Number of HTCP messages received:       0
         Number of HTCP messages sent:   0
         Request failure ratio:   0.00
         Average HTTP requests per minute since start:   15910.5
         Average ICP messages per minute since start:    1318.1
         Select loop called: 317207542 times, 14.168 ms avg

Resource usage for squid:
         UP Time:        449541.774 seconds
         CPU Time:       19248.419 seconds
         CPU Usage:      62.40%
         CPU Usage, 5 minute avg:        68.94%
         CPU Usage, 60 minute avg:       75.08%
         Maximum Resident Size: 80062656 KB
         Page faults with physical i/o: 16560
Memory accounted for:
         Total accounted:       259304 KB
         memPoolAlloc calls: 1145711652
         memPoolFree calls:  1150204906
File descriptor usage for squid:
         Maximum number of file descriptors:   114688
         Largest file desc currently in use:   10865
         Number of file desc currently in use: 13645
         Files queued for open:                   0
         Available number of file descriptors: 101043
         Reserved number of file descriptors:   700
         Store Disk files open:                  22
Internal Data Structures:
           7487 StoreEntries
           1455 StoreEntries with MemObjects
          24407 Hot Object Cache Items
         5181174 on-disk objects


2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items
2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue overflow 
for kid2 at 1024 items

Best Regards,


-- 
Heiler Bemerguy - (91) 98151-4894
Assessor T?cnico - CINBESA (91) 3184-1751


Em 24/05/2016 17:32, Amos Jeffries escreveu:
> On 25/05/2016 5:46 a.m., Heiler Bemerguy wrote:
>> Hi guys
>>
>> 2016/05/24 14:43:41 kid3| ctx: enter level  0:
>> 'http://www.msn.com/pt-br/?ocid=iehp'
>> 2016/05/24 14:43:41 kid3| ERROR: Collapsed forwarding queue overflow for
>> kid2 at 1024 items
>> 2016/05/24 14:43:41 kid3| ctx: exit level  0
>> 2016/05/24 14:43:41 kid3| ERROR: Collapsed forwarding queue overflow for
>> kid2 at 1024 items
>> 2016/05/24 14:43:41 kid3| ERROR: Collapsed forwarding queue overflow for
>> kid2 at 1024 items
>>
>> 1464111898.361    118 10.11.0.98 TCP_HIT_ABORTED/000 0 GET
>> http://www.msn.com/pt-br/? - HIER_NONE/- -
>> 1464111898.385    146 10.11.0.98 TCP_HIT_ABORTED/000 0 GET
>> http://www.msn.com/pt-br/? - HIER_NONE/- -
>> 1464111898.385    163 10.11.0.98 TCP_HIT_ABORTED/000 0 GET
>> http://www.msn.com/pt-br/? - HIER_NONE/- -
>> 1464111898.385    164 10.11.0.98 TCP_HIT_ABORTED/000 0 GET
>> http://www.msn.com/pt-br/? - HIER_NONE/- -
>> 1464111898.385    164 10.11.0.98 TCP_MISS_ABORTED/000 0 GET
>> http://www.msn.com/pt-br/? - HIER_DIRECT/131.253.33.203 -
>> 1464111905.666    970 10.102.4.21 TCP_MISS/200 67099 GET
>> http://www.msn.com/pt-br/? - HIER_DIRECT/131.253.33.203 text/html
>> 1464111910.484    759 10.102.1.102 TCP_MISS/200 26188 GET
>> http://www.msn.com/pt-br/? - HIER_DIRECT/131.253.33.203 text/html
>>
>>
>> Is this normal?
> Depends on your normal.
>
> AIUI, that "ERROR:" message means thehre are more than 1024 concurrent
> transactions being collapsed by your proxy and the overflowed one is
> failing.
>
> So the questions are;
>   why are there so many?
> and,
>   is that number of requests normal for your traffic?
>
>
>> conf:
>>
>> client_idle_pconn_timeout 30 seconds
>> client_persistent_connections on
>> server_persistent_connections on
>> collapsed_forwarding on
>>
>> Best Regards,
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160525/bd2f09f0/attachment.htm>

From yvoinov at gmail.com  Wed May 25 15:53:56 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 25 May 2016 21:53:56 +0600
Subject: [squid-users] ERROR: Collapsed forwarding queue overflow for
 kid2 at 1024 items
In-Reply-To: <82c60512-9766-ddbe-58a6-b569f28fedf5@cinbesa.com.br>
References: <460acb1d-cd3e-7a43-c573-90ef975105ea@cinbesa.com.br>
 <5f67f88c-3253-7158-5388-74641f59a00d@treenet.co.nz>
 <82c60512-9766-ddbe-58a6-b569f28fedf5@cinbesa.com.br>
Message-ID: <831ceba9-bbe4-64a0-aa17-418b0bdf7eb0@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
BTW,

it can be any malware on client machine.


25.05.16 21:35, Heiler Bemerguy ?????:
>
>
> I don't know if there's something "in loop".. that's why I'm asking...
>
> Start Time:     Fri, 20 May 2016 10:42:20 GMT
> Current Time:   Wed, 25 May 2016 15:34:42 GMT
> Connection information for squid:
>         Number of clients accessing cache:      4745
>         Number of HTTP requests received:       4037126
>         Number of ICP messages received:        149496
>         Number of ICP messages sent:    149496
>         Number of queued ICP replies:   0
>         Number of HTCP messages received:       0
>         Number of HTCP messages sent:   0
>         Request failure ratio:   0.00
>         Average HTTP requests per minute since start:   15910.5
>         Average ICP messages per minute since start:    1318.1
>         Select loop called: 317207542 times, 14.168 ms avg
>
> Resource usage for squid:
>         UP Time:        449541.774 seconds
>         CPU Time:       19248.419 seconds
>         CPU Usage:      62.40%
>         CPU Usage, 5 minute avg:        68.94%
>         CPU Usage, 60 minute avg:       75.08%
>         Maximum Resident Size: 80062656 KB
>         Page faults with physical i/o: 16560
> Memory accounted for:
>         Total accounted:       259304 KB
>         memPoolAlloc calls: 1145711652
>         memPoolFree calls:  1150204906
> File descriptor usage for squid:
>         Maximum number of file descriptors:   114688
>         Largest file desc currently in use:   10865
>         Number of file desc currently in use: 13645
>         Files queued for open:                   0
>         Available number of file descriptors: 101043
>         Reserved number of file descriptors:   700
>         Store Disk files open:                  22
> Internal Data Structures:
>           7487 StoreEntries
>           1455 StoreEntries with MemObjects
>          24407 Hot Object Cache Items
>         5181174 on-disk objects
>
>
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
> 2016/05/25 09:58:02.378 kid1| ERROR: Collapsed forwarding queue
overflow for kid2 at 1024 items
>
> Best Regards,
>
>
> --
> Heiler Bemerguy - (91) 98151-4894
> Assessor T?cnico - CINBESA (91) 3184-1751
>
> Em 24/05/2016 17:32, Amos Jeffries escreveu:
>> On 25/05/2016 5:46 a.m., Heiler Bemerguy wrote:
>>> Hi guys
>>>
>>> 2016/05/24 14:43:41 kid3| ctx: enter level  0:
>>> 'http://www.msn.com/pt-br/?ocid=iehp'
>>> 2016/05/24 14:43:41 kid3| ERROR: Collapsed forwarding queue overflow for
>>> kid2 at 1024 items
>>> 2016/05/24 14:43:41 kid3| ctx: exit level  0
>>> 2016/05/24 14:43:41 kid3| ERROR: Collapsed forwarding queue overflow for
>>> kid2 at 1024 items
>>> 2016/05/24 14:43:41 kid3| ERROR: Collapsed forwarding queue overflow for
>>> kid2 at 1024 items
>>>
>>> 1464111898.361    118 10.11.0.98 TCP_HIT_ABORTED/000 0 GET
>>> http://www.msn.com/pt-br/? - HIER_NONE/- -
>>> 1464111898.385    146 10.11.0.98 TCP_HIT_ABORTED/000 0 GET
>>> http://www.msn.com/pt-br/? - HIER_NONE/- -
>>> 1464111898.385    163 10.11.0.98 TCP_HIT_ABORTED/000 0 GET
>>> http://www.msn.com/pt-br/? - HIER_NONE/- -
>>> 1464111898.385    164 10.11.0.98 TCP_HIT_ABORTED/000 0 GET
>>> http://www.msn.com/pt-br/? - HIER_NONE/- -
>>> 1464111898.385    164 10.11.0.98 TCP_MISS_ABORTED/000 0 GET
>>> http://www.msn.com/pt-br/? - HIER_DIRECT/131.253.33.203 -
>>> 1464111905.666    970 10.102.4.21 TCP_MISS/200 67099 GET
>>> http://www.msn.com/pt-br/? - HIER_DIRECT/131.253.33.203 text/html
>>> 1464111910.484    759 10.102.1.102 TCP_MISS/200 26188 GET
>>> http://www.msn.com/pt-br/? - HIER_DIRECT/131.253.33.203 text/html
>>>
>>>
>>> Is this normal?
>> Depends on your normal.
>>
>> AIUI, that "ERROR:" message means thehre are more than 1024 concurrent
>> transactions being collapsed by your proxy and the overflowed one is
>> failing.
>>
>> So the questions are;
>>  why are there so many?
>> and,
>>  is that number of requests normal for your traffic?
>>
>>
>>> conf:
>>>
>>> client_idle_pconn_timeout 30 seconds
>>> client_persistent_connections on
>>> server_persistent_connections on
>>> collapsed_forwarding on
>>>
>>> Best Regards,
>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXRcqUAAoJENNXIZxhPexGd5cH/1EwtOH4RX5lmeXlcTOXpVfg
iXJsegPeWRLrT+V5O1mtiRkJp+c354baRHxHd2KYEQyg2/oYD4uQRZfaMAGelIMu
hUQLMzMygBW2yCdUmF5vFrTpgg4EWGhlVWNXgA4HsVrl1G0lYUkIUMqojRL+JDvg
z1RhQDQFcHkrlhEpz3zwxt2OOgKtx3hPYHzLtsUH76NOWqLj5bnIvjye3fx3Bl9T
0prVSMpPkgAKgS9dU+pZ+riYj2Gv6DhBqXleAR83XDWqlTjcKW1+8mlz2WzS7KxW
IOd2egpbbzDhK9H+Jw/PbKrOM/o/qO4ONpBt3O69UH4eSLScoCavaEiHlmx4hsA=
=OAz3
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160525/d83415c5/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160525/d83415c5/attachment.key>

From rousskov at measurement-factory.com  Wed May 25 16:30:58 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 25 May 2016 10:30:58 -0600
Subject: [squid-users] ERROR: Collapsed forwarding queue overflow for
 kid2 at 1024 items
In-Reply-To: <5f67f88c-3253-7158-5388-74641f59a00d@treenet.co.nz>
References: <460acb1d-cd3e-7a43-c573-90ef975105ea@cinbesa.com.br>
 <5f67f88c-3253-7158-5388-74641f59a00d@treenet.co.nz>
Message-ID: <5745D342.8020101@measurement-factory.com>

On 05/24/2016 02:32 PM, Amos Jeffries wrote:
> On 25/05/2016 5:46 a.m., Heiler Bemerguy wrote:
>> Is this normal?

> Depends on your normal.

> AIUI, that "ERROR:" message means thehre are more than 1024 concurrent
> transactions being collapsed by your proxy and the overflowed one is
> failing.

This is a CF notification queue overflow, not CF table overflow. The
size of the former is hard-coded to 1K. In trunk, the size of the latter
is configurable via collapsed_forwarding_shared_entries_limit and
defaults to 16K.

CF queue overflow is usually a sign of one or more of these problems:

1. UDS messages informing workers about certain important queue events
are being lost. This is likely if you have not configured your OS UDS
memory [correctly]. Unfortunately, Squid does not complain about lost
UDS messages [loudly enough].

2. Squid workers processing queued notifications get blocked on
something. This is likely if Squid is overloaded, running out of RAM,
and/or using blocking cache_dirs.

3. Squid workers processing queued notifications are slower than workers
adding new notifications. This is unlikely, especially if all workers
are configured the same.

4. Squid bugs.

If you can reproduce the problem, enabling UDS logging may help (debug
options ALL,1 54,7), but you will need to sift through a lot of messages
(or find somebody willing to look at your logs).


HTH,

Alex.

>> conf:
>>
>> client_idle_pconn_timeout 30 seconds
>> client_persistent_connections on
>> server_persistent_connections on
>> collapsed_forwarding on






From squid3 at treenet.co.nz  Thu May 26 06:04:36 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 26 May 2016 18:04:36 +1200
Subject: [squid-users] pinger crash - Bad opcode: 112
In-Reply-To: <CAG6MAzT+JQP0Bd+UDHN3zwigU6W8H6oGYxXdn3iVhuYqU=qZpg@mail.gmail.com>
References: <CAG6MAzT+JQP0Bd+UDHN3zwigU6W8H6oGYxXdn3iVhuYqU=qZpg@mail.gmail.com>
Message-ID: <bdb614cb-27fe-ad3a-5780-e6f9245e495d@treenet.co.nz>

On 24/05/2016 7:52 p.m., Tomas Mozes wrote:
> Hello,
> on two different squid servers I've observed a crash of pinger. First it
> appeared on version 3.5.15 and later on version 3.5.17.
> 
> Cache.log contains these lines:
> 
> (pinger): Address.cc:671: void Ip::Address::getAddrInfo(addrinfo*&, int)
> const: Assertion `false' failed.
> 2016/05/14 21:55:25 kid1| Bad opcode: 112 from
> [6661:6c73:6522:2061:7420:6c69:6e65:2036]
> 2016/05/14 21:59:13 kid1| recv: (111) Connection refused
> 2016/05/14 21:59:13 kid1| Closing Pinger socket on FD 17
> 
> On both servers, that IPv6 address was the same -
> 6661:6c73:6522:2061:7420:6c69:6e65:2036
> 

That is the hexadecimal representation of the error:
 false" at line 6

Which means that your kernel is producing garbage when asked to resolve
an IPv6 address or respond to an ICMPv6 packet.


> A quick google search for that showed problems with Squid from the past:
> http://www.squid-cache.org/mail-archive/squid-users/201301/0251.html
> 
> The strange thing is that I have IPv6 disabled in the system (not even as a
> module in the Linux kernel) and Squid was compiled without ipv6 support.
> 

Support for IPv6 has been mandatory for all IP network connected devices
since 2012.

"Disabling" IPv6 in Squid simply means it will not attempt to use IPv6
for HTTP connections. It must still be able to identify IPv6 addresses.
Which requires kernel support for IPv6.

If you don't want IPv6 to take place "the right way" to do it is to
configure your network interfaces not to have IPv6 address assignments
and your machines firewall to block IPv6 traffic.

Amos



From eliezer at ngtech.co.il  Thu May 26 09:11:12 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 26 May 2016 12:11:12 +0300
Subject: [squid-users] DNS as an API -  Squid-Cache version 3.5.19 RPMs
Message-ID: <0b7801d1b72e$8cc8e610$a65ab230$@ngtech.co.il>

Was published at: http://www1.ngtech.co.il/wpe/?p=273
I am happy to "Certify" Squid-Cache version 3.5.19 as
"Works For Me" on
CentOS(6+7), SLES(12SP1), Oracle Linux(6+7), RHEL(7), OpenSUSE(42.1 Leap),
Debian(8.4), Ubuntu(14.04+16.04)
HTTP is commonly used as an API for many purposes in any industry and in
many cases if you analyze an API specs and output you can see that some
thinking was invested in it.
Around the Internet we can find many ideas about API's and while some are
well published others are long forgotten and are considered "old". It is
true that when you look at some of the API's they might look "cryptic" or
"malformed" but these have a purpose. Most of these APIs was meant to be
public and as users we have access to all of them. But also many API's
requires some level of authentication or authorization which was clearly
meant to not be fully public.
Some hackers around the world see the opportunity to "hack" something  when
possible. From my own API's which includes: HTTP, SMTP, DNS, WIFI HotSpot,
Moblie and many others it is clear that some might think that it's funny to
send some malformed packets towards a Router or an AP. But I feel that there
is a need to clear couple things out for any hacker.
Behind any System on the Internet there is some person which deserves
respect. The fact that the API is there means that you are not allowed to
hack it by it's owner unless it was designed for it.
When comparing the real world to the Internet API's not anyone can enter any
door or any place. Not anyone can enter a closed party or a secured area. It
would be a bit different since the minimum requirements to enter one place
would not be the same for another.
For example, in the hackers world it's known that there are ways to prove
your value and earn your "nick" or "name". Some hacking cultures are
restrictive in their approach and respect any API avoiding the flame of war.
While others think it's better to hack some API as a Proof Of Concept or a
Proof Of Knowledge.
White? Black? Green? Red? is there any meaning to all of these?
My answer is that all of these are hats, I do not have one and I do not want
one. I am a simple person who has couple very simple API's under his hands.
But I learned that to give a good example is a profession. Specifically it's
not simple to give an example for a hacking kid. If any hacking kid wants to
hack something, like in the real world, there are playgrounds for this sole
purpose and an example would be canyouhack.it <http://canyouhack.it/> . Also
these days if you want to learn how things work in the micro level we have
Lots of free and open Virtualization platforms. These exist in any part of
the Industry from the electricity level to the application.
All these tools was meant for the sole purpose of allowing the learning
curve to be easy simple and safe, to use a real world power tool in an
environment which will tolerate things which might not be acceptable in the
real world API's.
Not too far from the invention of HTTP the DNS system was invented and it's
an API like HTTP and many others. It is commonly used over UDP and has a
very limited size and format but it has power in the same level as a button
on a car dashboard. Technically it can and is being used in many places as a
trigger to some system. Indeed UDP is not reliable at the same level of TCP
but when the network equipment is trusted then there would be no reason to
not use UDP.
A list of things that can be done using a DNS service messaging:
*	On\Off electrical switch
*	Identity signaling(AKA Port Knocking)
*	Banking transactions
*	Queue status updates
*	Alerts Signalling
And many other uses which can give an example to what an API can look like.
I had the pleasure to read couple books about APIs published by Nordic APIs
<http://nordicapis.com/>  which gave me a fresh perspective on how others
see an API and what might happen on the wild Internet that requires
attention.
One key point which I learned from them is mentioned in the video "Good APIs
aren?t built in a day" <https://www.youtube.com/watch?v=xjIiYTR-YyE> 
 And links to books from Nordic APIs <http://nordicapis.com/>   which I had
the pleasure to read:
http://nordicapis.com/ebook-released-securing-the-api-stronghold/
http://nordicapis.com/api-security-the-4-defenses-of-the-api-stronghold/
*	"Works For Me" means that it was tested on a testing environment
under real world usage in a forward proxy mode with daily usage traffic such
as Browsing News, Video, Learning and Games sites. Special applications that
was tested are SKYPE, IRC and couple other applications inside a fully
trusted network.
*	An Advice: Any system which sits against a non-trusted and a hostile
public or private network should be "Harden" both in the squid configuration
level and other lower levels.
*	This specific version(3.5.19) was tested also on Intercept proxy
mode and ssl-bump but only on forward-proxy and not Intercept mode.


----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 68793 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160526/d596c608/attachment.bin>

From eliezer at ngtech.co.il  Thu May 26 09:52:56 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 26 May 2016 12:52:56 +0300
Subject: [squid-users] Looking for a way to route into cache_peer traffic
	dynamically.
Message-ID: <0bd501d1b734$611f03e0$235d0ba0$@ngtech.co.il>

I have couple ideas on how to route traffic in a cache hierarchy using an
external_acl helper and a "tag" but I was wondering about other options.
Since currently to my understanding an ICAP service cannot add a "tag" to a
request, then I cannot use an ICAP service+tag in order to "delegate" the
routing decision to the ICAP service.
But I am not sure what are the options and also if it is possible to achieve
this goal at all.
The scenario is:
-	Multiple incoming proxy http requests: CONNECT, GET, POST, OTHERS
-	Multiple Upsteam http proxies, some are for caching
-	I want to delegate the LB decision based on the proxy arrays overall
status ie CPU LOAD, Free RAM, OPENED FD and couple others.

I have looked at the headers acls at:
http://www.squid-cache.org/Doc/config/acl/
	acl aclname req_header header-name [-i] any\.regex\.here
	  # regex match against any of the known request headers.  May be
	  # thought of as a superset of "browser", "referer" and "mime-type"
	  # ACL [fast]

And I am not sure(do not remember the runtime checks order) what I can
expect from squid to do when I am adding headers to the request,
will the acls be revalidated after the ICAP service modification\response?
I think that the best way is to use an ICAP meta header instead of altering
the request itself but I am not sure if it is possible and if with what
versions.

Thanks,
Eliezer

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 65309 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160526/72666a69/attachment.bin>

From chip_pop at hotmail.com  Thu May 26 14:30:16 2016
From: chip_pop at hotmail.com (joe)
Date: Thu, 26 May 2016 07:30:16 -0700 (PDT)
Subject: [squid-users] NULL characters
Message-ID: <1464273016183-4677691.post@n4.nabble.com>

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Thu May 26 15:16:52 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 26 May 2016 09:16:52 -0600
Subject: [squid-users] Looking for a way to route into cache_peer
 traffic dynamically.
In-Reply-To: <0bd501d1b734$611f03e0$235d0ba0$@ngtech.co.il>
References: <0bd501d1b734$611f03e0$235d0ba0$@ngtech.co.il>
Message-ID: <57471364.4030007@measurement-factory.com>

On 05/26/2016 03:52 AM, Eliezer Croitoru wrote:

> I think that the best way is to use an ICAP meta header instead of altering
> the request itself 

Agreed.


> but I am not sure if it is possible

It is not possible today: Converting ICAP headers into annotations
understood by Squid ACLs is only supported for eCAP services.

IIRC, somebody posted a patch (on squid-dev) with a similar feature for
ICAP, but that implementation needed to be redone to be officially
accepted (IMO). I do not know whether the author will adjust their code
to follow my recommendations. Perhaps you can do it for them.

Alex.



From deepaganu at gmail.com  Fri May 27 08:55:19 2016
From: deepaganu at gmail.com (deepa ganu)
Date: Fri, 27 May 2016 14:25:19 +0530
Subject: [squid-users] The system returned: (111) Connection refused;
Message-ID: <CA+qV5k+cSUThvZYCS1JLcNuXsFCA8Vnk1Rmc5opK1w15W6asyg@mail.gmail.com>

Hi
I am using squid as a reverse.

#http_port  80 accel defaultsite=202.53.13.19
https_port 443 accel  cert=/var/www/html/webrtc/imp/teleuniv.net.crt
key=/var/www/html/webrtc/imp/teleuniv.net.key
cafile=/var/www/html/webrtc/imp/intermediate.crt defaultsite=202.53.13.19
no-vhost


#this ACL is url path specific which accepts only portal urls and deny
others.
acl portal urlpath_regex ^/portal6may
cache_peer 172.20.36.144 parent 80 0 no-query originserver name=portalserver
cache_peer_access portalserver allow portal
cache_peer_access portalserver deny all
http_access allow portal


cache_peer 172.20.36.150 parent 443 0 no-query originserver ssl
sslflags=DONT_VERIFY_PEER login=PASS connection-auth=off name=teleuniv
acl our_sites dstdomain 202.53.13.19
http_access allow our_sites
cache_peer_access teleuniv allow our_sites
cache_peer_access teleuniv deny all

SO when i try to access the url https://202.53.13.19/ I get the following
error
"The following error was encountered while trying to retrieve the URL: The
system returned: (111) Connection refused; The remote host or network may
be down. Please try the request again."

It only gives for 172.20.36.144 not for the urlpath acl. But this happens
only sometimes. When I physically go to that server (172.20.36.150) and
click on the wired connection (one of the LAN options using linux). It
works again. I am very confused

-- 
Regards
Deepa Ganu
R&D Head(CSE) KMIT
Ph no : 9908036660
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/998e60f3/attachment.htm>

From eliezer at ngtech.co.il  Fri May 27 11:17:17 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 27 May 2016 14:17:17 +0300
Subject: [squid-users] NULL characters
In-Reply-To: <1464273016183-4677691.post@n4.nabble.com>
References: <1464273016183-4677691.post@n4.nabble.com>
Message-ID: <33b501d1b809$541a9620$fc4fc260$@ngtech.co.il>

If it ended with some kind of server issues else then the logs, then it would be considered not nice.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of joe
Sent: Thursday, May 26, 2016 5:30 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From nilesh.gavali at tcs.com  Fri May 27 11:32:15 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Fri, 27 May 2016 12:32:15 +0100
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID: <OF9C6F8F89.5CF2ECB1-ON80257FC0.003EE232-80257FC0.003F5EF7@tcs.com>

Hello ;
 I have installed latest squid 3.5.19 on red hat Linux yesterday. That 
means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but 
facing issues.
followed the steps provided on 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
But unable to find negotiate_kerberos_auth  on my Linux box at any 
location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and 
compile it to make authentication successful.

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.   IT Services
                        Business Solutions
                        Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 
 Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/b812d6ac/attachment.htm>

From belle at bazuin.nl  Fri May 27 11:41:34 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Fri, 27 May 2016 13:41:34 +0200
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
In-Reply-To: <OF9C6F8F89.5CF2ECB1-ON80257FC0.003EE232-80257FC0.003F5EF7@tcs.com>
References: <OF9C6F8F89.5CF2ECB1-ON80257FC0.003EE232-80257FC0.003F5EF7@tcs.com>
Message-ID: <vmime.5748326e.63bf.32264d027089be4e@ms249-lin-003.rotterdam.bazuin.nl>

Should be include imo. 

?

Shoud be in any Squid-3.2 and later.

?

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth 

?

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? 

?

Run squid ?v to check it. 

?

Greetz, 

?

Louis

?

?


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Nilesh Gavali
Verzonden: vrijdag 27 mei 2016 13:32
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] missing negotiate_kerberos_auth on my squid


?

Hello ; 
?I have installed latest squid 3.5.19 on red hat Linux yesterday. That means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but facing issues. 
followed the steps provided on http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
But unable to find negotiate_kerberos_auth ?on my Linux box at any location. 
now I need to know where i can find/download ?negotiate_kerberos_auth ?and compile it to make authentication successful. 

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty. ? ? ? ?IT Services
? ? ? ? ? ? ? ? ? ? ? ?Business Solutions
? ? ? ? ? ? ? ? ? ? ? ?Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated ?with limited liability and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - ?Registered ?in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/bbeb60e2/attachment.htm>

From squid3 at treenet.co.nz  Fri May 27 11:58:32 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 27 May 2016 23:58:32 +1200
Subject: [squid-users] NULL characters
In-Reply-To: <1464273016183-4677691.post@n4.nabble.com>
References: <1464273016183-4677691.post@n4.nabble.com>
Message-ID: <54f63a2f-e27a-ec6c-e68c-4dbb0cd4ab3e@treenet.co.nz>

On 27/05/2016 2:30 a.m., joe wrote:
> 2016/05/26 06:41:28 kid1| ctx: enter level  0:
> 'http://js.advert.mirtesen.ru/data/js/82090.js'
> 2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
> {Server: nginx
> Date: Thu, 26 May 2016 03:46:52 GMT
> Content-Type: application/javascript;charset=utf-8
> Transfer-Encoding: chunked
> Connection: close
> Vary: Accept-Encoding
...
> X-ShmCnt: 3
> Set-Cookie: nid}
> NULL
> {Server: nginx
> Date: Thu, 26 May 2016 03:46:52 GMT
...
> 2016/05/26 06:41:28 kid1| ctx: exit level  0
> 
> is it bad ?????
> 

It is both okay and bad.

The server is producing at least one null / 0x00 character where it
should not. The log shows it to be in the middle of a Set-Cookie header
and strangely have a whole other set of response headers following the
null. That is a sign of very broken server or server scripts. Normally
we see less broken scripts outputting null instead of end-of-line
characters. This one is nasty.


It is okay, because Squid is detecting the problem and is able to
prevent it causing damage.

It is still sort of bad because requests to this server or URL will
result in an error page being delivered to the user and nothing they or
you can do to fix it. Only the admin or webmaster of the server
producing that response can do anything.

Amos



From squid3 at treenet.co.nz  Fri May 27 12:13:33 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 28 May 2016 00:13:33 +1200
Subject: [squid-users] The system returned: (111) Connection refused;
In-Reply-To: <CA+qV5k+cSUThvZYCS1JLcNuXsFCA8Vnk1Rmc5opK1w15W6asyg@mail.gmail.com>
References: <CA+qV5k+cSUThvZYCS1JLcNuXsFCA8Vnk1Rmc5opK1w15W6asyg@mail.gmail.com>
Message-ID: <3afef1dd-8027-32a1-fd5d-ae1184898f64@treenet.co.nz>

On 27/05/2016 8:55 p.m., deepa ganu wrote:
> Hi
> I am using squid as a reverse.
> 
> #http_port  80 accel defaultsite=202.53.13.19
> https_port 443 accel  cert=/var/www/html/webrtc/imp/teleuniv.net.crt
> key=/var/www/html/webrtc/imp/teleuniv.net.key
> cafile=/var/www/html/webrtc/imp/intermediate.crt defaultsite=202.53.13.19
> no-vhost
> 
> 
> #this ACL is url path specific which accepts only portal urls and deny
> others.
> acl portal urlpath_regex ^/portal6may
> cache_peer 172.20.36.144 parent 80 0 no-query originserver name=portalserver
> cache_peer_access portalserver allow portal
> cache_peer_access portalserver deny all
> http_access allow portal
> 
> 
> cache_peer 172.20.36.150 parent 443 0 no-query originserver ssl
> sslflags=DONT_VERIFY_PEER login=PASS connection-auth=off name=teleuniv
> acl our_sites dstdomain 202.53.13.19
> http_access allow our_sites
> cache_peer_access teleuniv allow our_sites
> cache_peer_access teleuniv deny all
> 
> SO when i try to access the url https://202.53.13.19/ I get the following
> error
> "The following error was encountered while trying to retrieve the URL: The
> system returned: (111) Connection refused; The remote host or network may
> be down. Please try the request again."
> 
> It only gives for 172.20.36.144 not for the urlpath acl.

You have configured Squid to:

 1) "no-vhost" - ignore the Host header the client sent indicating what
domain name it was contacting.

 2) defaultsite=202.53.13.19 - use "202.53.13.19" as the domain *name*
for all requests received through that https_port.

Why would you expect to see anything other than https://202.53.13.19 in
the URL when you have configured those?


> But this happens
> only sometimes. When I physically go to that server (172.20.36.150) and
> click on the wired connection (one of the LAN options using linux). It
> works again. I am very confused

Your use of "physically" seems to be incorrect. You walked up to the
machine hardware and did what ?

"Clicking" seems to be that you logged in (not physically) and changed
something which affected how Squid was able to connect to it.


All traffic with the domain name "202.53.13.19" and not the path
"/portal6may" gets sent to the second cache_peer (172.20.36.150).

So what do you expect to happen when the server 172.20.36.150 receives a
request with Host: header domain name set to "202.53.13.19"  ?


It seems like the servers connectivity is a bit flakey and getting
disconnected occasionally. But the wrong Squid configuration could be
hiding some other issue.

Amos



From chip_pop at hotmail.com  Fri May 27 13:05:04 2016
From: chip_pop at hotmail.com (joe)
Date: Fri, 27 May 2016 06:05:04 -0700 (PDT)
Subject: [squid-users] NULL characters
In-Reply-To: <54f63a2f-e27a-ec6c-e68c-4dbb0cd4ab3e@treenet.co.nz>
References: <1464273016183-4677691.post@n4.nabble.com>
 <54f63a2f-e27a-ec6c-e68c-4dbb0cd4ab3e@treenet.co.nz>
Message-ID: <1464354304709-4677699.post@n4.nabble.com>

ok thank you guys :)



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691p4677699.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From nilesh.gavali at tcs.com  Fri May 27 14:07:55 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Fri, 27 May 2016 15:07:55 +0100
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID: <OF6BC559F7.84283A07-ON80257FC0.004CFF22-80257FC0.004D9FAC@tcs.com>

Thanks louise for reply.

but

Should be include imo. -- not sure what is imo

 

Shoud be in any Squid-3.2 and later.

 

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth - check the path but it is not 
there on my linux box.

 

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? 
---- NO didn't gave this option while compilation

 

Run squid ?v to check it. -- we have"--enable-auth-negotiate" only and 
some other configured option.

can you help me how to get hit recomipled with reuqire options.


Thanks & Regards
Nilesh Suresh Gavali

----- Forwarded by Nilesh Gavali/MUM/TCS on 27/05/2016 15:01 -----

From:   squid-users-request at lists.squid-cache.org
To:     squid-users at lists.squid-cache.org
Date:   27/05/2016 12:42
Subject:        squid-users Digest, Vol 21, Issue 101
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org>



Send squid-users mailing list submissions to
                 squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
                 http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
                 squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
                 squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

   1. NULL characters (joe)
   2. Re: Looking for a way to route into cache_peer traffic
      dynamically. (Alex Rousskov)
   3. The system returned: (111) Connection refused; (deepa ganu)
   4. Re: NULL characters (Eliezer Croitoru)
   5. missing negotiate_kerberos_auth on my squid (Nilesh Gavali)
   6. Re: missing negotiate_kerberos_auth on my squid (L.P.H. van Belle)


----------------------------------------------------------------------

Message: 1
Date: Thu, 26 May 2016 07:30:16 -0700 (PDT)
From: joe <chip_pop at hotmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters
Message-ID: <1464273016183-4677691.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: 
http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html

Sent from the Squid - Users mailing list archive at Nabble.com.


------------------------------

Message: 2
Date: Thu, 26 May 2016 09:16:52 -0600
From: Alex Rousskov <rousskov at measurement-factory.com>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Looking for a way to route into cache_peer
                 traffic dynamically.
Message-ID: <57471364.4030007 at measurement-factory.com>
Content-Type: text/plain; charset=utf-8

On 05/26/2016 03:52 AM, Eliezer Croitoru wrote:

> I think that the best way is to use an ICAP meta header instead of 
altering
> the request itself 

Agreed.


> but I am not sure if it is possible

It is not possible today: Converting ICAP headers into annotations
understood by Squid ACLs is only supported for eCAP services.

IIRC, somebody posted a patch (on squid-dev) with a similar feature for
ICAP, but that implementation needed to be redone to be officially
accepted (IMO). I do not know whether the author will adjust their code
to follow my recommendations. Perhaps you can do it for them.

Alex.



------------------------------

Message: 3
Date: Fri, 27 May 2016 14:25:19 +0530
From: deepa ganu <deepaganu at gmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] The system returned: (111) Connection refused;
Message-ID:
 <CA+qV5k+cSUThvZYCS1JLcNuXsFCA8Vnk1Rmc5opK1w15W6asyg at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi
I am using squid as a reverse.

#http_port  80 accel defaultsite=202.53.13.19
https_port 443 accel  cert=/var/www/html/webrtc/imp/teleuniv.net.crt
key=/var/www/html/webrtc/imp/teleuniv.net.key
cafile=/var/www/html/webrtc/imp/intermediate.crt defaultsite=202.53.13.19
no-vhost


#this ACL is url path specific which accepts only portal urls and deny
others.
acl portal urlpath_regex ^/portal6may
cache_peer 172.20.36.144 parent 80 0 no-query originserver 
name=portalserver
cache_peer_access portalserver allow portal
cache_peer_access portalserver deny all
http_access allow portal


cache_peer 172.20.36.150 parent 443 0 no-query originserver ssl
sslflags=DONT_VERIFY_PEER login=PASS connection-auth=off name=teleuniv
acl our_sites dstdomain 202.53.13.19
http_access allow our_sites
cache_peer_access teleuniv allow our_sites
cache_peer_access teleuniv deny all

SO when i try to access the url https://202.53.13.19/ I get the following
error
"The following error was encountered while trying to retrieve the URL: The
system returned: (111) Connection refused; The remote host or network may
be down. Please try the request again."

It only gives for 172.20.36.144 not for the urlpath acl. But this happens
only sometimes. When I physically go to that server (172.20.36.150) and
click on the wired connection (one of the LAN options using linux). It
works again. I am very confused

-- 
Regards
Deepa Ganu
R&D Head(CSE) KMIT
Ph no : 9908036660
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/998e60f3/attachment-0001.html
>

------------------------------

Message: 4
Date: Fri, 27 May 2016 14:17:17 +0300
From: "Eliezer Croitoru" <eliezer at ngtech.co.il>
To: "'joe'" <chip_pop at hotmail.com>,
                 <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] NULL characters
Message-ID: <33b501d1b809$541a9620$fc4fc260$@ngtech.co.il>
Content-Type: text/plain;                charset="utf-8"

If it ended with some kind of server issues else then the logs, then it 
would be considered not nice.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On 
Behalf Of joe
Sent: Thursday, May 26, 2016 5:30 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: 
http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html

Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



------------------------------

Message: 5
Date: Fri, 27 May 2016 12:32:15 +0100
From: Nilesh Gavali <nilesh.gavali at tcs.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
 <OF9C6F8F89.5CF2ECB1-ON80257FC0.003EE232-80257FC0.003F5EF7 at tcs.com>
Content-Type: text/plain; charset="utf-8"

Hello ;
 I have installed latest squid 3.5.19 on red hat Linux yesterday. That 
means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but 
facing issues.
followed the steps provided on 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
But unable to find negotiate_kerberos_auth  on my Linux box at any 
location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and 

compile it to make authentication successful.

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.   IT Services
                        Business Solutions
                        Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 

 Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/b812d6ac/attachment-0001.html
>

------------------------------

Message: 6
Date: Fri, 27 May 2016 13:41:34 +0200
From: L.P.H. van Belle <belle at bazuin.nl>
To: squid-users at squid-cache.org  <squid-users at squid-cache.org>
Subject: Re: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
 <vmime.5748326e.63bf.32264d027089be4e at ms249-lin-003.rotterdam.bazuin.nl>
 
Content-Type: text/plain; charset="windows-1252"

Should be include imo. 

 

Shoud be in any Squid-3.2 and later.

 

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth 

 

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? 

 

Run squid ?v to check it. 

 

Greetz, 

 

Louis

 

 


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens 
Nilesh Gavali
Verzonden: vrijdag 27 mei 2016 13:32
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] missing negotiate_kerberos_auth on my squid


 

Hello ; 
 I have installed latest squid 3.5.19 on red hat Linux yesterday. That 
means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but 
facing issues. 
followed the steps provided on 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
But unable to find negotiate_kerberos_auth  on my Linux box at any 
location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and 
compile it to make authentication successful. 

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.        IT Services
                       Business Solutions
                       Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 
 Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/bbeb60e2/attachment.html
>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 21, Issue 101
********************************************
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/61ac119d/attachment.htm>

From amadaan at ncsu.edu  Fri May 27 14:12:47 2016
From: amadaan at ncsu.edu (Aashima Madaan)
Date: Fri, 27 May 2016 10:12:47 -0400
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
Message-ID: <CAO4ouAZaU5E_bd1TvwVO2gu+cvRMyHDm6_jEPw6RyH=G68EDPA@mail.gmail.com>

Hi,

In my squid configuration file, I am adding a Fully Qualified Domain Name
instead of an IP address for my ICAP server but it is not able to resolve
that name initially and the service goes down saying

essential ICAP service is down after an options fetch failure: icap://
short.domain.name:4321 [down,!opt]

It remains shut down for 3 minutes and then the icap service is up after
that much time. My concern is why there is so much delay in resolving fqdn
of an ip.

Plus, adding that IP with FQDN in my /etc/hosts file resolves the name
immediately on starting the service. But I dont want to do that since that
should not be required thing if know DNS entry for that particular IP works
through ping or nslookup or directly accessing that gateway console admin
from browser with fqdn.

Thanks

Aashima
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/2751463f/attachment.htm>

From Antony.Stone at squid.open.source.it  Fri May 27 14:45:51 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 27 May 2016 16:45:51 +0200
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
In-Reply-To: <CAO4ouAZaU5E_bd1TvwVO2gu+cvRMyHDm6_jEPw6RyH=G68EDPA@mail.gmail.com>
References: <CAO4ouAZaU5E_bd1TvwVO2gu+cvRMyHDm6_jEPw6RyH=G68EDPA@mail.gmail.com>
Message-ID: <201605271645.52105.Antony.Stone@squid.open.source.it>

On Friday 27 May 2016 at 16:12:47, Aashima Madaan wrote:

> Hi,
> 
> In my squid configuration file, I am adding a Fully Qualified Domain Name
> instead of an IP address for my ICAP server but it is not able to resolve
> that name initially

Please define "initially" - do you mean:

 - when the squid server is booted up
 - when the squid service is started on an already-running server
 - something else?

> My concern is why there is so much delay in resolving fqdn of an ip.

What is your DNS setup?  Where is the Squid server pointing for its DNS 
resolver?  Is that DNS server running and answering queries before the Squid 
server/service starts up?


Antony.

-- 
How I want a drink, alcoholic of course, after the heavy chapters involving 
quantum mechanics.

 - mnemonic for 3.14159265358979

                                                   Please reply to the list;
                                                         please *don't* CC me.


From deepaganu at gmail.com  Fri May 27 15:03:11 2016
From: deepaganu at gmail.com (deepa ganu)
Date: Fri, 27 May 2016 20:33:11 +0530
Subject: [squid-users] The system returned: (111) Connection refused;
In-Reply-To: <3afef1dd-8027-32a1-fd5d-ae1184898f64@treenet.co.nz>
References: <CA+qV5k+cSUThvZYCS1JLcNuXsFCA8Vnk1Rmc5opK1w15W6asyg@mail.gmail.com>
 <3afef1dd-8027-32a1-fd5d-ae1184898f64@treenet.co.nz>
Message-ID: <CA+qV5kKsahx91qeejOpQha7+E50T9Xob=HVmOu6G9xMNguez=w@mail.gmail.com>

On May 27, 2016 5:43 PM, "Amos Jeffries" <squid3 at treenet.co.nz> wrote:
>
> On 27/05/2016 8:55 p.m., deepa ganu wrote:
> > Hi
> > I am using squid as a reverse.
> >
> > #http_port  80 accel defaultsite=202.53.13.19
> > https_port 443 accel  cert=/var/www/html/webrtc/imp/teleuniv.net.crt
> > key=/var/www/html/webrtc/imp/teleuniv.net.key
> > cafile=/var/www/html/webrtc/imp/intermediate.crt
defaultsite=202.53.13.19
> > no-vhost
> >
> >
> > #this ACL is url path specific which accepts only portal urls and deny
> > others.
> > acl portal urlpath_regex ^/portal6may
> > cache_peer 172.20.36.144 parent 80 0 no-query originserver
name=portalserver
> > cache_peer_access portalserver allow portal
> > cache_peer_access portalserver deny all
> > http_access allow portal
> >
> >
> > cache_peer 172.20.36.150 parent 443 0 no-query originserver ssl
> > sslflags=DONT_VERIFY_PEER login=PASS connection-auth=off name=teleuniv
> > acl our_sites dstdomain 202.53.13.19
> > http_access allow our_sites
> > cache_peer_access teleuniv allow our_sites
> > cache_peer_access teleuniv deny all
> >
> > SO when i try to access the url https://202.53.13.19/ I get the
following
> > error
> > "The following error was encountered while trying to retrieve the URL:
The
> > system returned: (111) Connection refused; The remote host or network
may
> > be down. Please try the request again."
> >
> > It only gives for 172.20.36.144 not for the urlpath acl.
>
> You have configured Squid to:
>
>  1) "no-vhost" - ignore the Host header the client sent indicating what
> domain name it was contacting.
It usually is vhost and the domain name is teleuniv.com but for testing
purposes we use public IP 202.53.13.19
>
>  2) defaultsite=202.53.13.19 - use "202.53.13.19" as the domain *name*
> for all requests received through that https_port.
>
> Why would you expect to see anything other than https://202.53.13.19 in
> the URL when you have configured those?
Didnt understand the above mentioned point
>
> > But this happens
> > only sometimes. When I physically go to that server (172.20.36.150) and
> > click on the wired connection (one of the LAN options using linux). It
> > works again. I am very confused
>
> Your use of "physically" seems to be incorrect. You walked up to the
> machine hardware and did what ?
> I logged in the machine and click on "wired connection"
> "Clicking" seems to be that you logged in (not physically) and changed
> something which affected how Squid was able to connect to it.
>
>
> All traffic with the domain name "202.53.13.19" and not the path
> "/portal6may" gets sent to the second cache_peer (172.20.36.150).
>
> So what do you expect to happen when the server 172.20.36.150 receives a
> request with Host: header domain name set to "202.53.13.19"  ?
>I didn't understand the host: header part any references to understand
>
> It seems like the servers connectivity is a bit flakey and getting
> disconnected occasionally. But the wrong Squid configuration could be
> hiding some other issue.
> I read somewhere it happens when cache is full. Can u tell me what should
be cache size if my HDD 500 gb and 32 MB RAM
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-user
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/31e62ef1/attachment.htm>

From amadaan at ncsu.edu  Fri May 27 15:10:48 2016
From: amadaan at ncsu.edu (Aashima Madaan)
Date: Fri, 27 May 2016 11:10:48 -0400
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
Message-ID: <CAO4ouAYT6uDjTCZTY-8NMQJjBEWX7QcBzoLVAZO+J2_+eKQajw@mail.gmail.com>

>* Hi,
*> >* In my squid configuration file, I am adding a Fully Qualified Domain Name
*>* instead of an IP address for my ICAP server but it is not able to resolve
*>* that name initially
*
Please define "initially" - do you mean:

 - when the squid server is booted up
 - when the squid service is started on an already-running server
 - something else?

@Aashima - initially here means when I start squid service

>* My concern is why there is so much delay in resolving fqdn of an ip. *
What is your DNS setup?

@Aashima - We got company DNS servers which we have added in our
/etc/resolv.conf of that squid machine.

Where is the Squid server pointing for its DNS
resolver?

@Aashima - I see in cache.log that its adding nameservers from /etc/resolv.conf

Initializing IP Cache...

2016/05/27 10:32:52 kid1| DNS Socket created at [::], FD 6

2016/05/27 10:32:52 kid1| DNS Socket created at 0.0.0.0, FD 8

2016/05/27 10:32:52 kid1| Adding nameserver 10.32.1.1 from /etc/resolv.conf

2016/05/27 10:32:52 kid1| Adding nameserver 10.32.1.1 from /etc/resolv.conf

2016/05/27 10:32:52 kid1| Adding nameserver 8.8.8.8 from /etc/resolv.conf

Is that DNS server running and answering queries before the Squid

server/service starts up?

@Aashima I do curl/ping/nslookup for icap server from squid machine,
it is able to resolve that particular ip.


Thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/03a02f8e/attachment.htm>

From Antony.Stone at squid.open.source.it  Fri May 27 15:28:21 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 27 May 2016 17:28:21 +0200
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
In-Reply-To: <CAO4ouAYT6uDjTCZTY-8NMQJjBEWX7QcBzoLVAZO+J2_+eKQajw@mail.gmail.com>
References: <CAO4ouAYT6uDjTCZTY-8NMQJjBEWX7QcBzoLVAZO+J2_+eKQajw@mail.gmail.com>
Message-ID: <201605271728.22067.Antony.Stone@squid.open.source.it>

On Friday 27 May 2016 at 17:10:48, Aashima Madaan wrote:

> > Please define "initially" - do you mean:
> >
> >  - when the squid server is booted up
> >  - when the squid service is started on an already-running server
> >  - something else?
> >
> initially here means when I start squid service

So, does the problem exist if you:

1. Stop Squid
2. Type "host short.domain.name" to resolve the ICAP server manually
3. Start Squid

(The last two commands in as quick succession as possible - preferably on a 
single line separated by a semi-colon)

> I see in cache.log that its adding nameservers from /etc/resolv.conf
> 
> 2016/05/27 10:32:52 kid1| Adding nameserver 10.32.1.1 from /etc/resolv.conf
> 2016/05/27 10:32:52 kid1| Adding nameserver 10.32.1.1 from /etc/resolv.conf
> 2016/05/27 10:32:52 kid1| Adding nameserver 8.8.8.8 from /etc/resolv.conf

Why have you added 10.32.1.1 twice?

> > Is that DNS server running and answering queries before the Squid
> > server/service starts up?
> 
> I do curl/ping/nslookup for icap server from squid machine, it is able to
> resolve that particular ip.

You do this before starting Squid, and it works, and then when you start 
Squid, it fails for 3 minutes??


Antony.

-- 
I wasn't sure about having a beard at first, but then it grew on me.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From amadaan at ncsu.edu  Fri May 27 15:51:36 2016
From: amadaan at ncsu.edu (Aashima Madaan)
Date: Fri, 27 May 2016 11:51:36 -0400
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
Message-ID: <CAO4ouAYOniDt7z2uJGqtH3ownBPf6b3cNv1+_9FWgDHhPFA2bw@mail.gmail.com>

> So, does the problem exist if you:

> 1. Stop Squid
> 2. Type "host short.domain.name" to resolve the ICAP server manually
> 3. Start Squid

> (The last two commands in as quick succession as possible - preferably on a
> single line separated by a semi-colon)

yes the problem still exists

>>* I see in cache.log that its adding nameservers from /etc/resolv.conf
*>> >>* 2016/05/27 10:32:52 kid1| Adding nameserver 10.32.1.1 from
/etc/resolv.conf
*>>* 2016/05/27 10:32:52 kid1| Adding nameserver 10.32.1.1 from /etc/resolv.conf
*>>* 2016/05/27 10:32:52 kid1| Adding nameserver 8.8.8.8 from /etc/resolv.conf
*
> Why have you added 10.32.1.1 twice?

That was by chance. Its 10.32.1.2.

>* > Is that DNS server running and answering queries before the Squid
*>* > server/service starts up?
*> >* I do curl/ping/nslookup for icap server from squid machine, it is able to
*>* resolve that particular ip.
*
> You do this before starting Squid, and it works, and then when you start
Squid, it fails for 3 minutes??

Yes, after 3 minutes it's able to resolve DNS and brings up the service.

on additional debugging by switching on tcpflow, I see squid sends
OPTIONS request to icap server and that is when it is able to resolve
DNS and which brings the service up in 3 minutes.

###Request

OPTIONS icap://short.domain.name:1344 ICAP/1.0

Host: short.domain.name:1344

Allow: 206

###Response

ICAP/1.0 200 OK

Methods: REQMOD, RESPMOD

Options-TTL: 3600

Encapsulated: null-body=0

Max-Connections: 400

Preview: 30

Service: Gateway 7.5.2

ISTag: "00005042-2.94.230-00008178"

Allow: 204

 --------

Additionally, i increased debug level and saw this in cache logs

 Address.cc(389) lookupHostIP: Given Non-IP 'short.domain.name': Name
or service not known

Thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/2ddc5b19/attachment.htm>

From Antony.Stone at squid.open.source.it  Fri May 27 16:49:02 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 27 May 2016 18:49:02 +0200
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
In-Reply-To: <CAO4ouAYOniDt7z2uJGqtH3ownBPf6b3cNv1+_9FWgDHhPFA2bw@mail.gmail.com>
References: <CAO4ouAYOniDt7z2uJGqtH3ownBPf6b3cNv1+_9FWgDHhPFA2bw@mail.gmail.com>
Message-ID: <201605271849.02631.Antony.Stone@squid.open.source.it>

On Friday 27 May 2016 at 17:51:36, Aashima Madaan wrote:

> > So, does the problem exist if you:
> > 
> > 1. Stop Squid
> > 2. Type "host short.domain.name" to resolve the ICAP server manually
> > 3. Start Squid
> > 
> > (The last two commands in as quick succession as possible - preferably on
> > a single line separated by a semi-colon)
> 
> yes the problem still exists

That tells me that the problem is not DNS, then.

Command 2 verifies that DNS resolution is working.

Command 3 results in the problem.

Therefore whatever is causing the problem is not DNS.

> on additional debugging by switching on tcpflow, I see squid sends
> OPTIONS request to icap server and that is when it is able to resolve
> DNS and which brings the service up in 3 minutes.

Have you tried running some sort of packet tracer (eg: wireshark) to check 
when Squid is sending the DNS request, where it is sending it to, and whether 
it gets a response?

>  Address.cc(389) lookupHostIP: Given Non-IP 'short.domain.name': Name
> or service not known

Can anyone else shed some light on what this particular message means?


Antony.

-- 
Wanted: telepath.   You know where to apply.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From codemarauder at gmail.com  Sat May 28 05:46:12 2016
From: codemarauder at gmail.com (Nishant Sharma)
Date: Sat, 28 May 2016 11:16:12 +0530
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
In-Reply-To: <57492F2B.9050709@gmail.com>
References: <CAO4ouAYOniDt7z2uJGqtH3ownBPf6b3cNv1+_9FWgDHhPFA2bw@mail.gmail.com>
 <57492F2B.9050709@gmail.com>
Message-ID: <CAMptfcdr4D3c-o0ur_UBrawdOyqAK5BGLjx3vRNxBxKVy0OXRQ@mail.gmail.com>

Hi,

On Friday 27 May 2016 09:21 PM, Aashima Madaan wrote:


> (The last two commands in as quick succession as possible - preferably on a
>> single line separated by a semi-colon)
>>
>
> yes the problem still exists
>
>
Could it be because squid is trying to resolve and connect to IPv6 address
first?

Try setting "dns_v4_first on" and try.

Regards,
Nishant
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160528/3f76652c/attachment.htm>

From leloup.christophe at gmail.com  Sat May 28 08:50:57 2016
From: leloup.christophe at gmail.com (Christophe Leloup)
Date: Sat, 28 May 2016 10:50:57 +0200
Subject: [squid-users] ad and squid not working
Message-ID: <CAPXptHn_QAcz9TQdkfUOh0Er3EEyXyDM-=080UrGhiLs2Hn-ug@mail.gmail.com>

Hi

i'm French and geek.

I want to install squid with authentification sso. but it is not working.

I have not log file.  i can' t post my file config ?

thanks.





   Cordialement.

Christophe Leloup
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160528/5ec5c826/attachment.htm>

From squid3 at treenet.co.nz  Sat May 28 11:38:00 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 28 May 2016 23:38:00 +1200
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
In-Reply-To: <201605271849.02631.Antony.Stone@squid.open.source.it>
References: <CAO4ouAYOniDt7z2uJGqtH3ownBPf6b3cNv1+_9FWgDHhPFA2bw@mail.gmail.com>
 <201605271849.02631.Antony.Stone@squid.open.source.it>
Message-ID: <3d45aa71-3275-2d9d-7d6b-d3829cb4728a@treenet.co.nz>

On 28/05/2016 4:49 a.m., Antony Stone wrote:
> On Friday 27 May 2016 at 17:51:36, Aashima Madaan wrote:
> 
>>> So, does the problem exist if you:
>>>
>>> 1. Stop Squid
>>> 2. Type "host short.domain.name" to resolve the ICAP server manually
>>> 3. Start Squid
>>>
>>> (The last two commands in as quick succession as possible - preferably on
>>> a single line separated by a semi-colon)
>>
>> yes the problem still exists
> 
> That tells me that the problem is not DNS, then.
> 
> Command 2 verifies that DNS resolution is working.
> 
> Command 3 results in the problem.
> 
> Therefore whatever is causing the problem is not DNS.

What is causing the problem is that ICAP services need to be working
*immediately* and do not wait for DNS results to come back. If they are
not available immediately then the service is not contactable for that
transaction.

Adding /etc/hosts entries makes Squid load the name+IP details on
startup before ICAP is used. So the problem does not appear.

Also, once Squid has looked it up and got the IP back operations with
the ICAP service will start to succeed.

> 
>> on additional debugging by switching on tcpflow, I see squid sends
>> OPTIONS request to icap server and that is when it is able to resolve
>> DNS and which brings the service up in 3 minutes.
> 
> Have you tried running some sort of packet tracer (eg: wireshark) to check 
> when Squid is sending the DNS request, where it is sending it to, and whether 
> it gets a response?
> 
>>  Address.cc(389) lookupHostIP: Given Non-IP 'short.domain.name': Name
>> or service not known
> 
> Can anyone else shed some light on what this particular message means?
> 

That is Squid checking to see if the ICAP hostname is a raw-IP. It is
not, so that correctly wont succeed.

Amos



From huaraz at moeller.plus.com  Sat May 28 11:38:15 2016
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Sat, 28 May 2016 12:38:15 +0100
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
In-Reply-To: <OF6BC559F7.84283A07-ON80257FC0.004CFF22-80257FC0.004D9FAC@tcs.com>
References: <OF6BC559F7.84283A07-ON80257FC0.004CFF22-80257FC0.004D9FAC@tcs.com>
Message-ID: <nibvvj$op2$1@ger.gmane.org>

What does the configure output say.  You may not have the Kerberos header files. e.g.


checking for LIB_KRB5... yes
configure: Try to find Kerberos headers in given path
checking gssapi.h usability... yes
checking gssapi.h presence... yes
checking for gssapi.h... yes
checking gssapi/gssapi.h usability... yes
checking gssapi/gssapi.h presence... yes
checking for gssapi/gssapi.h... yes
checking gssapi/gssapi_krb5.h usability... yes
checking gssapi/gssapi_krb5.h presence... yes
checking for gssapi/gssapi_krb5.h... yes
checking gssapi/gssapi_generic.h usability... yes
checking gssapi/gssapi_generic.h presence... yes
checking for gssapi/gssapi_generic.h... yes
checking krb5.h usability... yes
checking krb5.h presence... yes
checking for krb5.h... yes
checking com_err.h usability... yes
checking com_err.h presence... yes
checking for com_err.h... yes
checking et/com_err.h usability... yes
checking et/com_err.h presence... yes
checking for et/com_err.h... yes
checking profile.h usability... yes
checking profile.h presence... yes
checking for profile.h... yes
checking for error_message in -lcom_err... yes
checking for krb5_get_err_text in -lkrb5... no
checking for krb5_get_error_message in -lkrb5... yes
checking for krb5_free_error_message in -lkrb5... yes
checking for krb5_free_error_string in -lkrb5... no
checking whether krb5_kt_free_entry is declared... yes
checking for krb5_pac... yes
checking for krb5_kt_free_entry in -lkrb5... yes
checking for krb5_get_init_creds_keytab in -lkrb5... yes
checking for krb5_get_max_time_skew in -lkrb5... no
checking for krb5_get_profile in -lkrb5... yes
checking for profile_get_integer in -lkrb5... yes
checking for profile_release in -lkrb5... yes
checking for krb5_get_renewed_creds in -lkrb5... yes
checking for krb5_principal_get_realm in -lkrb5... no
checking for krb5_get_init_creds_opt_alloc in -lkrb5... yes
checking for krb5_get_init_creds_free requires krb5_context... yes
checking for gss_map_name_to_any... yes
checking for gsskrb5_extract_authz_data_from_sec_context... yes
checking for memory cache... yes
checking for memory keytab... yes
checking for working gssapi... yes
checking for spnego support... yes
checking for working krb5... yes
configure: MIT Kerberos library support: yes  -lgssapi_krb5 -lkrb5 -lk5crypto -lcom_err



Markus


"Nilesh Gavali" <nilesh.gavali at tcs.com> wrote in message news:OF6BC559F7.84283A07-ON80257FC0.004CFF22-80257FC0.004D9FAC at tcs.com...
Thanks louise for reply. 

but 

Should be include imo. -- not sure what is imo

 

Shoud be in any Squid-3.2 and later.

 

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth - check the path but it is not there on my linux box.

 

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ?  ---- NO didn't gave this option while compilation

 

Run squid ?v to check it. -- we have"--enable-auth-negotiate" only and some other configured option. 

can you help me how to get hit recomipled with reuqire options. 


Thanks & Regards
Nilesh Suresh Gavali

----- Forwarded by Nilesh Gavali/MUM/TCS on 27/05/2016 15:01 ----- 

From:        squid-users-request at lists.squid-cache.org 
To:        squid-users at lists.squid-cache.org 
Date:        27/05/2016 12:42 
Subject:        squid-users Digest, Vol 21, Issue 101 
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org> 

--------------------------------------------------------------------------------



Send squid-users mailing list submissions to
                squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
                http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
                squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
                squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

  1. NULL characters (joe)
  2. Re: Looking for a way to route into cache_peer traffic
     dynamically. (Alex Rousskov)
  3. The system returned: (111) Connection refused; (deepa ganu)
  4. Re: NULL characters (Eliezer Croitoru)
  5. missing negotiate_kerberos_auth on my squid (Nilesh Gavali)
  6. Re: missing negotiate_kerberos_auth on my squid (L.P.H. van Belle)


----------------------------------------------------------------------

Message: 1
Date: Thu, 26 May 2016 07:30:16 -0700 (PDT)
From: joe <chip_pop at hotmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters
Message-ID: <1464273016183-4677691.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html
Sent from the Squid - Users mailing list archive at Nabble.com.


------------------------------

Message: 2
Date: Thu, 26 May 2016 09:16:52 -0600
From: Alex Rousskov <rousskov at measurement-factory.com>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Looking for a way to route into cache_peer
                traffic dynamically.
Message-ID: <57471364.4030007 at measurement-factory.com>
Content-Type: text/plain; charset=utf-8

On 05/26/2016 03:52 AM, Eliezer Croitoru wrote:

> I think that the best way is to use an ICAP meta header instead of altering
> the request itself 

Agreed.


> but I am not sure if it is possible

It is not possible today: Converting ICAP headers into annotations
understood by Squid ACLs is only supported for eCAP services.

IIRC, somebody posted a patch (on squid-dev) with a similar feature for
ICAP, but that implementation needed to be redone to be officially
accepted (IMO). I do not know whether the author will adjust their code
to follow my recommendations. Perhaps you can do it for them.

Alex.



------------------------------

Message: 3
Date: Fri, 27 May 2016 14:25:19 +0530
From: deepa ganu <deepaganu at gmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] The system returned: (111) Connection refused;
Message-ID:
                <CA+qV5k+cSUThvZYCS1JLcNuXsFCA8Vnk1Rmc5opK1w15W6asyg at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi
I am using squid as a reverse.

#http_port  80 accel defaultsite=202.53.13.19
https_port 443 accel  cert=/var/www/html/webrtc/imp/teleuniv.net.crt
key=/var/www/html/webrtc/imp/teleuniv.net.key
cafile=/var/www/html/webrtc/imp/intermediate.crt defaultsite=202.53.13.19
no-vhost


#this ACL is url path specific which accepts only portal urls and deny
others.
acl portal urlpath_regex ^/portal6may
cache_peer 172.20.36.144 parent 80 0 no-query originserver name=portalserver
cache_peer_access portalserver allow portal
cache_peer_access portalserver deny all
http_access allow portal


cache_peer 172.20.36.150 parent 443 0 no-query originserver ssl
sslflags=DONT_VERIFY_PEER login=PASS connection-auth=off name=teleuniv
acl our_sites dstdomain 202.53.13.19
http_access allow our_sites
cache_peer_access teleuniv allow our_sites
cache_peer_access teleuniv deny all

SO when i try to access the url https://202.53.13.19/ I get the following
error
"The following error was encountered while trying to retrieve the URL: The
system returned: (111) Connection refused; The remote host or network may
be down. Please try the request again."

It only gives for 172.20.36.144 not for the urlpath acl. But this happens
only sometimes. When I physically go to that server (172.20.36.150) and
click on the wired connection (one of the LAN options using linux). It
works again. I am very confused

-- 
Regards
Deepa Ganu
R&D Head(CSE) KMIT
Ph no : 9908036660
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/998e60f3/attachment-0001.html>

------------------------------

Message: 4
Date: Fri, 27 May 2016 14:17:17 +0300
From: "Eliezer Croitoru" <eliezer at ngtech.co.il>
To: "'joe'" <chip_pop at hotmail.com>,
                <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] NULL characters
Message-ID: <33b501d1b809$541a9620$fc4fc260$@ngtech.co.il>
Content-Type: text/plain;                 charset="utf-8"

If it ended with some kind of server issues else then the logs, then it would be considered not nice.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of joe
Sent: Thursday, May 26, 2016 5:30 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



------------------------------

Message: 5
Date: Fri, 27 May 2016 12:32:15 +0100
From: Nilesh Gavali <nilesh.gavali at tcs.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
                <OF9C6F8F89.5CF2ECB1-ON80257FC0.003EE232-80257FC0.003F5EF7 at tcs.com>
Content-Type: text/plain; charset="utf-8"

Hello ;
I have installed latest squid 3.5.19 on red hat Linux yesterday. That 
means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but 
facing issues.
followed the steps provided on 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
But unable to find negotiate_kerberos_auth  on my Linux box at any 
location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and 
compile it to make authentication successful.

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.   IT Services
                       Business Solutions
                       Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 
Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/b812d6ac/attachment-0001.html>

------------------------------

Message: 6
Date: Fri, 27 May 2016 13:41:34 +0200
From: L.P.H. van Belle <belle at bazuin.nl>
To: squid-users at squid-cache.org  <squid-users at squid-cache.org>
Subject: Re: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
                <vmime.5748326e.63bf.32264d027089be4e at ms249-lin-003.rotterdam.bazuin.nl>
                
Content-Type: text/plain; charset="windows-1252"

Should be include imo. 

 

Shoud be in any Squid-3.2 and later.

 

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth 

 

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? 

 

Run squid ?v to check it. 

 

Greetz, 

 

Louis

 

 


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Nilesh Gavali
Verzonden: vrijdag 27 mei 2016 13:32
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] missing negotiate_kerberos_auth on my squid


 

Hello ; 
I have installed latest squid 3.5.19 on red hat Linux yesterday. That means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but facing issues. 
followed the steps provided on http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
But unable to find negotiate_kerberos_auth  on my Linux box at any location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and compile it to make authentication successful. 

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.        IT Services
                       Business Solutions
                       Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India -  Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/bbeb60e2/attachment.html>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 21, Issue 101
********************************************



--------------------------------------------------------------------------------
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160528/88097d57/attachment.htm>

From squid3 at treenet.co.nz  Sat May 28 11:38:59 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 28 May 2016 23:38:59 +1200
Subject: [squid-users] ad and squid not working
In-Reply-To: <CAPXptHn_QAcz9TQdkfUOh0Er3EEyXyDM-=080UrGhiLs2Hn-ug@mail.gmail.com>
References: <CAPXptHn_QAcz9TQdkfUOh0Er3EEyXyDM-=080UrGhiLs2Hn-ug@mail.gmail.com>
Message-ID: <b6b266d7-0bf5-481f-ee67-867d0747cea4@treenet.co.nz>

On 28/05/2016 8:50 p.m., Christophe Leloup wrote:
> Hi
> 
> i'm French and geek.
> 
> I want to install squid with authentification sso. but it is not working.

What is not working?

> 
> I have not log file.  i can' t post my file config ?
> 

Pardon?

Amos



From leloup.christophe at gmail.com  Sat May 28 15:25:33 2016
From: leloup.christophe at gmail.com (Christophe Leloup)
Date: Sat, 28 May 2016 17:25:33 +0200
Subject: [squid-users] ad and squid not working
In-Reply-To: <b6b266d7-0bf5-481f-ee67-867d0747cea4@treenet.co.nz>
References: <CAPXptHn_QAcz9TQdkfUOh0Er3EEyXyDM-=080UrGhiLs2Hn-ug@mail.gmail.com>
 <b6b266d7-0bf5-481f-ee67-867d0747cea4@treenet.co.nz>
Message-ID: <CAPXptHmVtj0iP3b308V_6UjDz0hjUF6k4+bf1r_PHUJPHX288g@mail.gmail.com>

Hi Amos,

i want to connect with sso but the windows 2008r2 show a windows

my squid.conf : http://paste.debian.net/hidden/4c1d817e/


error : http://paste.debian.net/hidden/4b1e101a/

thank for your help

   Cordialement.

Christophe Leloup

2016-05-28 13:38 GMT+02:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 28/05/2016 8:50 p.m., Christophe Leloup wrote:
> > Hi
> >
> > i'm French and geek.
> >
> > I want to install squid with authentification sso. but it is not working.
>
> What is not working?
>
> >
> > I have not log file.  i can' t post my file config ?
> >
>
> Pardon?
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160528/b2267978/attachment.htm>

From squid3 at treenet.co.nz  Sat May 28 19:58:47 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 29 May 2016 07:58:47 +1200
Subject: [squid-users] ad and squid not working
In-Reply-To: <CAPXptHmVtj0iP3b308V_6UjDz0hjUF6k4+bf1r_PHUJPHX288g@mail.gmail.com>
References: <CAPXptHn_QAcz9TQdkfUOh0Er3EEyXyDM-=080UrGhiLs2Hn-ug@mail.gmail.com>
 <b6b266d7-0bf5-481f-ee67-867d0747cea4@treenet.co.nz>
 <CAPXptHmVtj0iP3b308V_6UjDz0hjUF6k4+bf1r_PHUJPHX288g@mail.gmail.com>
Message-ID: <de7b7785-b442-0703-e312-9824f373418e@treenet.co.nz>

On 29/05/2016 3:25 a.m., Christophe Leloup wrote:
> Hi Amos,
> 
> i want to connect with sso but the windows 2008r2 show a windows
> 
> my squid.conf : http://paste.debian.net/hidden/4c1d817e/
> 
> 
> error : http://paste.debian.net/hidden/4b1e101a/
> 

You should move your http_access auth lines down below the "CONNECT
!SSL_ports" line. Otherwise the Squid portion of your auth config looks
reasonable.

But your ntlm_auth helper is unable to connect to and use your
ActiveDirectory server.

Have you added the Squid proxy account to the winbind group?

<http://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm#winbind_privileged_pipe_permissions>

Amos



From leloup.christophe at gmail.com  Sun May 29 10:41:01 2016
From: leloup.christophe at gmail.com (Christophe Leloup)
Date: Sun, 29 May 2016 12:41:01 +0200
Subject: [squid-users] ad and squid not working
In-Reply-To: <de7b7785-b442-0703-e312-9824f373418e@treenet.co.nz>
References: <CAPXptHn_QAcz9TQdkfUOh0Er3EEyXyDM-=080UrGhiLs2Hn-ug@mail.gmail.com>
 <b6b266d7-0bf5-481f-ee67-867d0747cea4@treenet.co.nz>
 <CAPXptHmVtj0iP3b308V_6UjDz0hjUF6k4+bf1r_PHUJPHX288g@mail.gmail.com>
 <de7b7785-b442-0703-e312-9824f373418e@treenet.co.nz>
Message-ID: <CAPXptHmo9j9n9eE1D6ghJJfs1S7cC4FvrfFyqB28U0XD2-Xf6g@mail.gmail.com>

Hi Amos

it not working :(

my new squid conf : http://pastebin.com/6ebuhB7A
my permission       : http://pastebin.com/t9vE4VsC
my squid debug with lot error http://pastebin.com/RczXhkeA

tank for you help.


*I give you some money*


     :

   Cordialement.

Christophe Leloup

2016-05-28 21:58 GMT+02:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 29/05/2016 3:25 a.m., Christophe Leloup wrote:
> > Hi Amos,
> >
> > i want to connect with sso but the windows 2008r2 show a windows
> >
> > my squid.conf : http://paste.debian.net/hidden/4c1d817e/
> >
> >
> > error : http://paste.debian.net/hidden/4b1e101a/
> >
>
> You should move your http_access auth lines down below the "CONNECT
> !SSL_ports" line. Otherwise the Squid portion of your auth config looks
> reasonable.
>
> But your ntlm_auth helper is unable to connect to and use your
> ActiveDirectory server.
>
> Have you added the Squid proxy account to the winbind group?
>
> <
> http://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm#winbind_privileged_pipe_permissions
> >
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160529/6abb5cfd/attachment.htm>

From yvoinov at gmail.com  Sun May 29 21:16:33 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 30 May 2016 03:16:33 +0600
Subject: [squid-users] Vary object loop returns
Message-ID: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
2016/05/30 03:08:38 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript'
'accept-encoding="gzip,%20deflate,%20sdch,%20br",
cookie="WMF-Last-Access%3D29-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4%3B%20ruwikimwuser-sessionId%3D6129656f6a07d81d",
authorization'
2016/05/30 03:08:38 kid1| clientProcessHit: Vary object loop!
2016/05/30 03:08:38 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript'
'accept-encoding="gzip,%20deflate,%20sdch,%20br",
cookie="WMF-Last-Access%3D29-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4%3B%20ruwikimwuser-sessionId%3D6129656f6a07d81d",
authorization'
2016/05/30 03:08:38 kid1| clientProcessHit: Vary object loop!
2016/05/30 03:08:39 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'https://ru.wikipedia.org/w/api.php?action=opensearch&format=json&formatversion=2&search=%D0%AF&namespace=0&limit=10&suggest=true'
'accept-encoding="gzip,%20deflate,%20sdch,%20br", treat-as-untrusted,
x-forwarded-proto,
cookie="WMF-Last-Access%3D29-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4%3B%20ruwikimwuser-sessionId%3D6129656f6a07d81d",
authorization'
2016/05/30 03:08:39 kid1| clientProcessHit: Vary object loop!

squid-3.5.19-20160524-r14057<http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.19-20160524-r14057-RELEASENOTES.html>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXS1wlAAoJENNXIZxhPexGql8IAJJksf7xGVjRM/KFYrslwJ0W
6YbSEVlvGuE5ztMbxozZiLRpdLdbsYE7eANqSznVfEH/ZL1c+4USjR1K/fe+EYgu
o+/CrVDndy8PjL6fCya3xDiKbbcoHDSMFiGfyDn2ElPEs8MKqrg6zFR4tXi8cNm1
wRgyFik2foyzSmgWPDa7GMJ6ITiBrbm8lsqnE8iniI4kU7UFY6LPgJG9tBqEq0MT
tQjoyfDn7eLi+JeoN676X/YOv3s5BrRVUXGXhvnq2I97atTfYjkdbw+3joDt0TG0
Xri1XgJEacFXMVOviQFBxZccwQKoJf/zfdioAASlWu66YEUPtBee960C2axgMVQ=
=XD8e
-----END PGP SIGNATURE-----



From yvoinov at gmail.com  Sun May 29 21:17:28 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 30 May 2016 03:17:28 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
Message-ID: <39f3fd61-2158-8778-4c4f-5c519b2803f6@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
2016/05/30 03:12:40 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'http://platform.twitter.com.squidinternal/widgets.js'
'accept-encoding="gzip,%20deflate,%20sdch"'


30.05.2016 3:16, Yuri Voinov ?????:
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
> 
> 2016/05/30 03:08:38 kid1| varyEvaluateMatch: Oops. Not a Vary match on
> second attempt,
>
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript'
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>
cookie="WMF-Last-Access%3D29-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4%3B%20ruwikimwuser-sessionId%3D6129656f6a07d81d",
> authorization'
> 2016/05/30 03:08:38 kid1| clientProcessHit: Vary object loop!
> 2016/05/30 03:08:38 kid1| varyEvaluateMatch: Oops. Not a Vary match on
> second attempt,
>
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript'
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>
cookie="WMF-Last-Access%3D29-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4%3B%20ruwikimwuser-sessionId%3D6129656f6a07d81d",
> authorization'
> 2016/05/30 03:08:38 kid1| clientProcessHit: Vary object loop!
> 2016/05/30 03:08:39 kid1| varyEvaluateMatch: Oops. Not a Vary match on
> second attempt,
>
'https://ru.wikipedia.org/w/api.php?action=opensearch&format=json&formatversion=2&search=%D0%AF&namespace=0&limit=10&suggest=true'
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", treat-as-untrusted,
> x-forwarded-proto,
>
cookie="WMF-Last-Access%3D29-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4%3B%20ruwikimwuser-sessionId%3D6129656f6a07d81d",
> authorization'
> 2016/05/30 03:08:39 kid1| clientProcessHit: Vary object loop!
>
>
squid-3.5.19-20160524-r14057<http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.19-20160524-r14057-RELEASENOTES.html>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
> 
> iQEcBAEBCAAGBQJXS1wlAAoJENNXIZxhPexGql8IAJJksf7xGVjRM/KFYrslwJ0W
> 6YbSEVlvGuE5ztMbxozZiLRpdLdbsYE7eANqSznVfEH/ZL1c+4USjR1K/fe+EYgu
> o+/CrVDndy8PjL6fCya3xDiKbbcoHDSMFiGfyDn2ElPEs8MKqrg6zFR4tXi8cNm1
> wRgyFik2foyzSmgWPDa7GMJ6ITiBrbm8lsqnE8iniI4kU7UFY6LPgJG9tBqEq0MT
> tQjoyfDn7eLi+JeoN676X/YOv3s5BrRVUXGXhvnq2I97atTfYjkdbw+3joDt0TG0
> Xri1XgJEacFXMVOviQFBxZccwQKoJf/zfdioAASlWu66YEUPtBee960C2axgMVQ=
> =XD8e
> -----END PGP SIGNATURE-----
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXS1xnAAoJENNXIZxhPexGZ+oH/1whGQp1XMPsa0EjL3bBwg4p
kvamaXaSQ0XJKtSo6p0VjnUvvO2JxQYw0cpNDJLkYszZK5pqjmXz66ZnIrs4qwMx
W087Y1gOfLVCbdYNgjoPHxCJKQ+B6C3y6aaCZQ0+Tod1LU5pRlxC3ugkjMYsMSft
0Ai8Tb7jN7iumM96gyjH+NJoEG+48ndwOuov6niVvFLemfd+9Krgay+ZIyvAUxqA
wFKXRZgXNbpQ0ZzivSYPoaNmBMZrLxyroSa1eKL9RWbVXzGCH4oPg1KVsmQDUvFz
vycFwyaIXGd2aMQIJhsctC6vpVEfx5jthXjAByyLVTyCNJvjofY5dpqCxI0Eoiw=
=3xRM
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160530/20ecfbdd/attachment.key>

From squid3 at treenet.co.nz  Mon May 30 00:54:46 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 30 May 2016 12:54:46 +1200
Subject: [squid-users] ad and squid not working
In-Reply-To: <CAPXptHmo9j9n9eE1D6ghJJfs1S7cC4FvrfFyqB28U0XD2-Xf6g@mail.gmail.com>
References: <CAPXptHn_QAcz9TQdkfUOh0Er3EEyXyDM-=080UrGhiLs2Hn-ug@mail.gmail.com>
 <b6b266d7-0bf5-481f-ee67-867d0747cea4@treenet.co.nz>
 <CAPXptHmVtj0iP3b308V_6UjDz0hjUF6k4+bf1r_PHUJPHX288g@mail.gmail.com>
 <de7b7785-b442-0703-e312-9824f373418e@treenet.co.nz>
 <CAPXptHmo9j9n9eE1D6ghJJfs1S7cC4FvrfFyqB28U0XD2-Xf6g@mail.gmail.com>
Message-ID: <ba242d86-4001-6555-266f-c94347d7e914@treenet.co.nz>

On 29/05/2016 10:41 p.m., Christophe Leloup wrote:
> Hi Amos
> 
> it not working :(
> 
> my new squid conf : http://pastebin.com/6ebuhB7A
> my permission       : http://pastebin.com/t9vE4VsC

That does not tell anything useful. Just says that winbind is owner of
teh winbind sockets.

You (or Squid installation scripts) need to have run the command line
mentioned in teh wiki.

Also, pay attention to the note labeled with a red 'X' "on Debian and
Ubuntu systems there may also be ..."


> my squid debug with lot error http://pastebin.com/RczXhkeA
> 

These two lines:

 2016/05/29 12:31:51 kid1| commBind: Cannot bind socket FD 11 to
[::]:3128: (98) Address already in use
 ...
 FATAL: Unable to open HTTP Socket


Mean some earlier Squid proces is still running. Or some other server
process has taken the Squid port for itself.


These lines:

 WARNING: no_suid: setuid(0): (1) Operation not permitted

Are happening because you have not started Squid by root user. The
"proxy" user acount does not have security permission to set its user level.

You need to start Squid from root user account. Squid will downgrade
itself to "proxy" user account internally when it is done with things
needing root.


> tank for you help.
> 
> 
> *I give you some money*
> 

Thank you.

Amos



From heiler.bemerguy at cinbesa.com.br  Mon May 30 17:08:16 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Mon, 30 May 2016 14:08:16 -0300
Subject: [squid-users] Vary object loop returns
In-Reply-To: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
Message-ID: <0e4ee383-9325-c9a2-5e92-5781b85d36e3@cinbesa.com.br>


Since I enabled collapsed_forwarding, this is a daily warning on my 
cache.log

3.5.19 with squidguard as url_rewriter, no id helper, no aufs, only 
rockstore cache dirs and 3 workers

2016/05/30 14:07:21 kid2| clientProcessHit: Vary object loop!
2016/05/30 14:07:22 kid2| Could not parse headers from on disk object
2016/05/30 14:07:25 kid2| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 'http://cdn.optimizely.com/js/2416500038.js' 
'accept-encoding="gzip,%20deflate"'
2016/05/30 14:07:25 kid2| clientProcessHit: Vary object loop!
2016/05/30 14:07:27 kid2| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 
'http://www.diarioonline.com.br/comentario-seguranca.php' 
'accept-encoding="gzip,%20deflate"'
2016/05/30 14:07:27 kid2| clientProcessHit: Vary object loop!
2016/05/30 14:07:30 kid2| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 'http://www.estrelando.com.br/css/style-1100.css' 
'accept-encoding="gzip,%20deflate"'
2016/05/30 14:07:30 kid3| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 'http://www.estrelando.com.br/css/style.css?2' 
'accept-encoding="gzip,%20deflate"'
2016/05/30 14:07:30 kid3| clientProcessHit: Vary object loop!
2016/05/30 14:07:30 kid2| clientProcessHit: Vary object loop!
2016/05/30 14:07:30 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 
'http://www.estrelando.com.br/js/functions-20150716.js?2131233333' 
'accept-encoding="gzip,%20deflate"'
2016/05/30 14:07:30 kid1| clientProcessHit: Vary object loop!
2016/05/30 14:07:30 kid2| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 'http://s1.blogs.r7.com/responsive/r7.lib.js' 
'accept-encoding="gzip,%20deflate"'
2016/05/30 14:07:30 kid2| clientProcessHit: Vary object loop!
2016/05/30 14:07:31 kid2| Could not parse headers from on disk object


Em 29/05/2016 18:16, Yuri Voinov escreveu:
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>   
> 2016/05/30 03:08:38 kid1| varyEvaluateMatch: Oops. Not a Vary match on
> second attempt,
> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript'
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
> cookie="WMF-Last-Access%3D29-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4%3B%20ruwikimwuser-sessionId%3D6129656f6a07d81d",
> authorization'
> 2016/05/30 03:08:38 kid1| clientProcessHit: Vary object loop!
> 2016/05/30 03:08:38 kid1| varyEvaluateMatch: Oops. Not a Vary match on
> second attempt,
> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript'
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
> cookie="WMF-Last-Access%3D29-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4%3B%20ruwikimwuser-sessionId%3D6129656f6a07d81d",
> authorization'
> 2016/05/30 03:08:38 kid1| clientProcessHit: Vary object loop!
> 2016/05/30 03:08:39 kid1| varyEvaluateMatch: Oops. Not a Vary match on
> second attempt,
> 'https://ru.wikipedia.org/w/api.php?action=opensearch&format=json&formatversion=2&search=%D0%AF&namespace=0&limit=10&suggest=true'
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", treat-as-untrusted,
> x-forwarded-proto,
> cookie="WMF-Last-Access%3D29-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4%3B%20ruwikimwuser-sessionId%3D6129656f6a07d81d",
> authorization'
> 2016/05/30 03:08:39 kid1| clientProcessHit: Vary object loop!
>
> squid-3.5.19-20160524-r14057<http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.19-20160524-r14057-RELEASENOTES.html>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>   
> iQEcBAEBCAAGBQJXS1wlAAoJENNXIZxhPexGql8IAJJksf7xGVjRM/KFYrslwJ0W
> 6YbSEVlvGuE5ztMbxozZiLRpdLdbsYE7eANqSznVfEH/ZL1c+4USjR1K/fe+EYgu
> o+/CrVDndy8PjL6fCya3xDiKbbcoHDSMFiGfyDn2ElPEs8MKqrg6zFR4tXi8cNm1
> wRgyFik2foyzSmgWPDa7GMJ6ITiBrbm8lsqnE8iniI4kU7UFY6LPgJG9tBqEq0MT
> tQjoyfDn7eLi+JeoN676X/YOv3s5BrRVUXGXhvnq2I97atTfYjkdbw+3joDt0TG0
> Xri1XgJEacFXMVOviQFBxZccwQKoJf/zfdioAASlWu66YEUPtBee960C2axgMVQ=
> =XD8e
> -----END PGP SIGNATURE-----
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Heiler Bemerguy - (91) 98151-4894
Assessor T?cnico - CINBESA (91) 3184-1751

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160530/27782dc7/attachment.htm>

From yvoinov at gmail.com  Mon May 30 17:13:01 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 30 May 2016 23:13:01 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <0e4ee383-9325-c9a2-5e92-5781b85d36e3@cinbesa.com.br>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <0e4ee383-9325-c9a2-5e92-5781b85d36e3@cinbesa.com.br>
Message-ID: <a5b50bde-0a6e-a4d1-422f-5a4f43d46c52@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Yep, I have enabled it too.

30.05.2016 23:08, Heiler Bemerguy ?????:
>
>
> Since I enabled collapsed_forwarding, this is a daily warning on my
cache.log
>
> 3.5.19 with squidguard as url_rewriter, no id helper, no aufs, only
rockstore cache dirs and 3 workers
>
> 2016/05/30 14:07:21 kid2| clientProcessHit: Vary object loop!
> 2016/05/30 14:07:22 kid2| Could not parse headers from on disk object
> 2016/05/30 14:07:25 kid2| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'http://cdn.optimizely.com/js/2416500038.js'
'accept-encoding="gzip,%20deflate"'
> 2016/05/30 14:07:25 kid2| clientProcessHit: Vary object loop!
> 2016/05/30 14:07:27 kid2| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'http://www.diarioonline.com.br/comentario-seguranca.php'
'accept-encoding="gzip,%20deflate"'
> 2016/05/30 14:07:27 kid2| clientProcessHit: Vary object loop!
> 2016/05/30 14:07:30 kid2| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'http://www.estrelando.com.br/css/style-1100.css'
'accept-encoding="gzip,%20deflate"'
> 2016/05/30 14:07:30 kid3| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'http://www.estrelando.com.br/css/style.css?2'
'accept-encoding="gzip,%20deflate"'
> 2016/05/30 14:07:30 kid3| clientProcessHit: Vary object loop!
> 2016/05/30 14:07:30 kid2| clientProcessHit: Vary object loop!
> 2016/05/30 14:07:30 kid1| varyEvaluateMatch: Oops. Not a Vary match on
second attempt,
'http://www.estrelando.com.br/js/functions-20150716.js?2131233333'
'accept-encoding="gzip,%20deflate"'
> 2016/05/30 14:07:30 kid1| clientProcessHit: Vary object loop!
> 2016/05/30 14:07:30 kid2| varyEvaluateMatch: Oops. Not a Vary match on
second attempt, 'http://s1.blogs.r7.com/responsive/r7.lib.js'
'accept-encoding="gzip,%20deflate"'
> 2016/05/30 14:07:30 kid2| clientProcessHit: Vary object loop!
> 2016/05/30 14:07:31 kid2| Could not parse headers from on disk object
>
>
> Em 29/05/2016 18:16, Yuri Voinov escreveu:
> 2016/05/30 03:08:38 kid1| varyEvaluateMatch: Oops. Not a Vary match on
> second attempt,
>
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript'
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>
cookie="WMF-Last-Access%3D29-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4%3B%20ruwikimwuser-sessionId%3D6129656f6a07d81d",
> authorization'
> 2016/05/30 03:08:38 kid1| clientProcessHit: Vary object loop!
> 2016/05/30 03:08:38 kid1| varyEvaluateMatch: Oops. Not a Vary match on
> second attempt,
>
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript'
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>
cookie="WMF-Last-Access%3D29-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4%3B%20ruwikimwuser-sessionId%3D6129656f6a07d81d",
> authorization'
> 2016/05/30 03:08:38 kid1| clientProcessHit: Vary object loop!
> 2016/05/30 03:08:39 kid1| varyEvaluateMatch: Oops. Not a Vary match on
> second attempt,
>
'https://ru.wikipedia.org/w/api.php?action=opensearch&format=json&formatversion=2&search=%D0%AF&namespace=0&limit=10&suggest=true'
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", treat-as-untrusted,
> x-forwarded-proto,
>
cookie="WMF-Last-Access%3D29-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4%3B%20ruwikimwuser-sessionId%3D6129656f6a07d81d",
> authorization'
> 2016/05/30 03:08:39 kid1| clientProcessHit: Vary object loop!
>
>
squid-3.5.19-20160524-r14057<http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.19-20160524-r14057-RELEASENOTES.html>
>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> --
> Heiler Bemerguy - (91) 98151-4894
> Assessor T?cnico - CINBESA (91) 3184-1751
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXTHSdAAoJENNXIZxhPexGBM8H/052T9aUmMqf3wpVjgFqwsGF
b2y4VOZgiQ8f5qfa9HFv9HWKsgcB8NtKe2rzNeJhUDDmrlsr3XrVTNwIPdu2bH3z
XuRJ4T2i0TuEjNStn6wbvHr86T/5Ol1nETZ6wekvLDoRMrhyigJx2nR9aBmNMHCr
TevTnQHrSXXge1V0nrvkongKzw9XD8cbVWF/EduwaLoP83xkGivTk24x45+vHMs3
FVtLE0b+1p5O//dzo1+XcaWeMfhh9/VCFOd4iG9SSbzPIp/801GmHNq7DbjnUDNS
xDAyIhTpaW7AB4QHOWFGw62TfiMNBD1BaPVD449pv+LdUzztHwtES2jb+x609tQ=
=+yea
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160530/32b88296/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160530/32b88296/attachment.key>

From chip_pop at hotmail.com  Mon May 30 17:16:34 2016
From: chip_pop at hotmail.com (joe)
Date: Mon, 30 May 2016 10:16:34 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
Message-ID: <1464628594081-4677722.post@n4.nabble.com>

yes only if  vary has different match of the same object you will see that
varyEvaluateMatch
simple test you can do
use that link on firefox 
'http://platform.twitter.com.squidinternal/widgets.js
push  reload and you see no warning after sec  and third or wat ever 

then use chrome the vary dose not match so it will show you
varyEvaluateMatch in log and it replace the object
i have enough post i  did before result in non good answer  
the think is  some vary can be fixt to match on all the browser like gzip or
deflate that will give a good hit 
but  not user-agent  or other vary they need a good understanding on how to
work around them lots a work
but those 2 if they just fix them to match  it will be huge saving 
i have the fix running on my production server for almost 2 month without
any problem



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677722.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon May 30 21:08:20 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 31 May 2016 03:08:20 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1464628594081-4677722.post@n4.nabble.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
Message-ID: <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Is this fix approved by Squid's dev team?


30.05.2016 23:16, joe ?????:
> yes only if  vary has different match of the same object you will see that
> varyEvaluateMatch
> simple test you can do
> use that link on firefox
> 'http://platform.twitter.com.squidinternal/widgets.js
> push  reload and you see no warning after sec  and third or wat ever
>
> then use chrome the vary dose not match so it will show you
> varyEvaluateMatch in log and it replace the object
> i have enough post i  did before result in non good answer 
> the think is  some vary can be fixt to match on all the browser like
gzip or
> deflate that will give a good hit
> but  not user-agent  or other vary they need a good understanding on
how to
> work around them lots a work
> but those 2 if they just fix them to match  it will be huge saving
> i have the fix running on my production server for almost 2 month without
> any problem
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677722.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXTKvDAAoJENNXIZxhPexGJf0IAKg8G0Lxzt4YPHfj3Z0VLO7e
lmN2dTyOTTVe2/lzI3q3xw3pVy3iK60gHAgTICb50gOEP2LmbJFrpvdLjnE2ornf
QgySQF+aUeDg5BSABXccvAxINEwuZYbJ0C5PB4posYCf34VITXCtF7U6axOq+WxW
t35mZdPLGirs2P+wZF9RS0q2+FE77bTazRDhxDC/XUrU03SomFRBs26YE4/8/e4t
Sz+2pmytDiEO4IUvQZkQd5LnhD1nxyp0Fl9E0i4bWv/ncaxpRKr1xofao6eol8Qm
qsu+I9Z1f3RwD8okfCGpjur/RpHWPC6cWkuiS2d5A5R2z1gmW1ljpGSPPBV+syI=
=NG7N
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/addd7576/attachment.key>

From frio_cervesa at hotmail.com  Mon May 30 21:56:53 2016
From: frio_cervesa at hotmail.com (senor)
Date: Mon, 30 May 2016 14:56:53 -0700
Subject: [squid-users] log rotate and debug
Message-ID: <SNT146-W686C4262B248832845267BF7450@phx.gbl>

When I execute 'squid -k rotate' it acts like I also executed 'squid -k debug' and toggles full debugging. Anyone else see this behavior? I've tried numerous combinations of conf options. Not sure at what version this started. 
I've just begun investigation so looking for others with similar config to provide feedback. Hints to resolution would also be appreciated.

on CentOS 6
# squid -v
Squid Cache: Version 3.5.17
Service Name: squid
configure options:  '--enable-ecap' '--disable-arch-native' '--with-openssl' '--enable-ssl' '--enable-ltdl-convenience' '--enable-linux-netfilter' '--enable-auth' '--with-libcap' '--with-default-user=squid' '--sysconfdir=/etc/squid' '--with-logdir=/var/log/squid' '--with-swapdir=/var/spool/squid' '--enable-wccpv2'

relevant conf entries:
cache_log /var/log/squid/cache.log
logfile_rotate 0
debug_options ALL,1

Thanks,
Frio C
 		 	   		  
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160530/a632bda4/attachment.htm>

From chip_pop at hotmail.com  Tue May 31 07:34:53 2016
From: chip_pop at hotmail.com (joe)
Date: Tue, 31 May 2016 00:34:53 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
Message-ID: <1464680093592-4677725.post@n4.nabble.com>

no  until i test it cpl of month and i show it to the dev team they might do
better 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677725.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From hydrapolic at gmail.com  Tue May 31 09:56:19 2016
From: hydrapolic at gmail.com (Tomas Mozes)
Date: Tue, 31 May 2016 11:56:19 +0200
Subject: [squid-users] pinger crash - Bad opcode: 112
In-Reply-To: <bdb614cb-27fe-ad3a-5780-e6f9245e495d@treenet.co.nz>
References: <CAG6MAzT+JQP0Bd+UDHN3zwigU6W8H6oGYxXdn3iVhuYqU=qZpg@mail.gmail.com>
 <bdb614cb-27fe-ad3a-5780-e6f9245e495d@treenet.co.nz>
Message-ID: <CAG6MAzQpEQNA1nv_GfNcWvQTccA7ZejyCoOiscsQS51C5FBcdQ@mail.gmail.com>

On Thu, May 26, 2016 at 8:04 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 24/05/2016 7:52 p.m., Tomas Mozes wrote:
> > Hello,
> > on two different squid servers I've observed a crash of pinger. First it
> > appeared on version 3.5.15 and later on version 3.5.17.
> >
> > Cache.log contains these lines:
> >
> > (pinger): Address.cc:671: void Ip::Address::getAddrInfo(addrinfo*&, int)
> > const: Assertion `false' failed.
> > 2016/05/14 21:55:25 kid1| Bad opcode: 112 from
> > [6661:6c73:6522:2061:7420:6c69:6e65:2036]
> > 2016/05/14 21:59:13 kid1| recv: (111) Connection refused
> > 2016/05/14 21:59:13 kid1| Closing Pinger socket on FD 17
> >
> > On both servers, that IPv6 address was the same -
> > 6661:6c73:6522:2061:7420:6c69:6e65:2036
> >
>
> That is the hexadecimal representation of the error:
>  false" at line 6
>
> Which means that your kernel is producing garbage when asked to resolve
> an IPv6 address or respond to an ICMPv6 packet.
>

Cannot we prevent Squid from crashing in these cases?


>
>
> > A quick google search for that showed problems with Squid from the past:
> > http://www.squid-cache.org/mail-archive/squid-users/201301/0251.html
> >
> > The strange thing is that I have IPv6 disabled in the system (not even
> as a
> > module in the Linux kernel) and Squid was compiled without ipv6 support.
> >
>
> Support for IPv6 has been mandatory for all IP network connected devices
> since 2012.
>
> "Disabling" IPv6 in Squid simply means it will not attempt to use IPv6
> for HTTP connections. It must still be able to identify IPv6 addresses.
> Which requires kernel support for IPv6.
>
> If you don't want IPv6 to take place "the right way" to do it is to
> configure your network interfaces not to have IPv6 address assignments
> and your machines firewall to block IPv6 traffic.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/7ecab3a6/attachment.htm>

From turgut at kalfaoglu.com  Tue May 31 10:00:44 2016
From: turgut at kalfaoglu.com (=?UTF-8?Q?turgut_kalfao=c4=9flu?=)
Date: Tue, 31 May 2016 13:00:44 +0300
Subject: [squid-users] Working SSL configuration for Squid 4.x?
Message-ID: <a8ed145a-9766-694e-8812-19dec7147eb9@kalfaoglu.com>

Hello. Whenever I tried to get squid to transparently cache https 
content (mainly to speed up facebook browsing at my home),  I get all 
kinds of problems.

Is there a cookbook available for the recent squid versions?

Many thanks, -turgut


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/8d2f51fa/attachment.htm>

From yvoinov at gmail.com  Tue May 31 11:00:33 2016
From: yvoinov at gmail.com (Yuri)
Date: Tue, 31 May 2016 17:00:33 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1464680093592-4677725.post@n4.nabble.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
Message-ID: <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>

Heh,

the issue occurs also with disabled collapsed_forwarding:

2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 
'https://ru.wikipedia.org/w/load.php?debug=false&lang=ru&modules=jquery.accessKeyLabel%2Cclient%7Cmediawiki.RegExp%2Cnotify%2Cutil%7Cmediawiki.legacy.wikibits&skin=vector&version=b5e9abd3b463' 
'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
2016/05/31 16:58:12 kid1| Error negotiating SSL on FD 260: 
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate 
verify failed (1/-1/0)
2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Secure.js&action=raw&ctype=text/javascript' 
'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
authorization'
2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Osm.js&action=raw&ctype=text/javascript' 
'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
authorization'
2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Sidebar-related.js&action=raw&ctype=text/javascript' 
'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
authorization'
2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript' 
'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
authorization'
2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript' 
'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
authorization'
2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 
'https://meta.wikimedia.org/w/index.php?title=MediaWiki:Wikiminiatlas.js&action=raw&ctype=text/javascript' 
'accept-encoding="gzip,%20deflate,%20sdch,%20br", cookie, authorization'

3.5.19



31.05.2016 13:34, joe ?????:
> no  until i test it cpl of month and i show it to the dev team they might do
> better
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677725.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From chip_pop at hotmail.com  Tue May 31 11:03:43 2016
From: chip_pop at hotmail.com (joe)
Date: Tue, 31 May 2016 04:03:43 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
Message-ID: <1464692623563-4677729.post@n4.nabble.com>

yup  try accel  the cache.log will have rely lots of those 
my idea of fixing this or having better  hit %
is by erasing anything start with %20 from the vary   
'accept-encoding="gzip,%20deflate,%20sdch,%20br"' 
those ,%20deflate,%20sdch,%20br should be removed and keep only
'accept-encoding="gzip"'

in  'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
authorization' 

should take of anything start with ,%20deflate,%20sdch,%20br"
should be 'accept-encoding="gzip,
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
authorization' 

client_side.cc
in function varyEvaluateMatch

so fare my test code wish i did after i study sbuf function working fine no
complain yet browser or mobile app :) 350 clients
but i know its not the right way of doing it 
i know a bit of c++ c vb all language but not a pro..




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677729.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Tue May 31 11:07:55 2016
From: chip_pop at hotmail.com (joe)
Date: Tue, 31 May 2016 04:07:55 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1464692623563-4677729.post@n4.nabble.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <1464692623563-4677729.post@n4.nabble.com>
Message-ID: <1464692875999-4677730.post@n4.nabble.com>

bluecoat doing same as my idea 
i test my code against bluecoat server



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677730.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Tue May 31 12:18:49 2016
From: yvoinov at gmail.com (Yuri)
Date: Tue, 31 May 2016 18:18:49 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1464692623563-4677729.post@n4.nabble.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <1464692623563-4677729.post@n4.nabble.com>
Message-ID: <b2f86b5b-89b9-8209-ba7e-ede0fb774aeb@gmail.com>

Hmmmmmmm. Seems as dirty hack.

I suggest better to correct strings encoding routines, or simple strip 
symbols starting with% from accept-encoding only.


31.05.2016 17:03, joe ?????:
> yup  try accel  the cache.log will have rely lots of those
> my idea of fixing this or having better  hit %
> is by erasing anything start with %20 from the vary
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
> those ,%20deflate,%20sdch,%20br should be removed and keep only
> 'accept-encoding="gzip"'
>
> in  'accept-encoding="gzip,%20deflate,%20sdch,%20br",
> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
> authorization'
>
> should take of anything start with ,%20deflate,%20sdch,%20br"
> should be 'accept-encoding="gzip,
> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
> authorization'
>
> client_side.cc
> in function varyEvaluateMatch
>
> so fare my test code wish i did after i study sbuf function working fine no
> complain yet browser or mobile app :) 350 clients
> but i know its not the right way of doing it
> i know a bit of c++ c vb all language but not a pro..
>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677729.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Tue May 31 12:19:54 2016
From: yvoinov at gmail.com (Yuri)
Date: Tue, 31 May 2016 18:19:54 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1464692875999-4677730.post@n4.nabble.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <1464692623563-4677729.post@n4.nabble.com>
 <1464692875999-4677730.post@n4.nabble.com>
Message-ID: <57945063-4f6b-5ec7-81f1-8fff9f955c78@gmail.com>

Bluecoat can do what they want :) They rich and fat CIA-tails. :)


31.05.2016 17:07, joe ?????:
> bluecoat doing same as my idea
> i test my code against bluecoat server
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677730.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From chip_pop at hotmail.com  Tue May 31 12:08:02 2016
From: chip_pop at hotmail.com (joe)
Date: Tue, 31 May 2016 05:08:02 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <b2f86b5b-89b9-8209-ba7e-ede0fb774aeb@gmail.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <1464692623563-4677729.post@n4.nabble.com>
 <b2f86b5b-89b9-8209-ba7e-ede0fb774aeb@gmail.com>
Message-ID: <1464696482569-4677733.post@n4.nabble.com>

>I suggest better to correct strings encoding routines, or simple strip 
>symbols starting with% from accept-encoding only. 
yup  exactly 
my problem is how to represent stuff  wen i post :(
that why they ignore or push me out with different answers
 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677733.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From heiler.bemerguy at cinbesa.com.br  Tue May 31 13:32:48 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 31 May 2016 10:32:48 -0300
Subject: [squid-users] Vary object loop returns
In-Reply-To: <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
Message-ID: <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>


I swear this bug was only rarely triggered without collapsed_forwarding 
enabled... but I think you'll have to wipe your cache to really test it...



-- 
Heiler Bemerguy - (91) 98151-4894
Assessor T?cnico - CINBESA (91) 3184-1751


Em 31/05/2016 08:00, Yuri escreveu:
> Heh,
>
> the issue occurs also with disabled collapsed_forwarding:
>
> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
> second attempt, 
> 'https://ru.wikipedia.org/w/load.php?debug=false&lang=ru&modules=jquery.accessKeyLabel%2Cclient%7Cmediawiki.RegExp%2Cnotify%2Cutil%7Cmediawiki.legacy.wikibits&skin=vector&version=b5e9abd3b463' 
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
> 2016/05/31 16:58:12 kid1| Error negotiating SSL on FD 260: 
> error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate 
> verify failed (1/-1/0)
> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
> second attempt, 
> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Secure.js&action=raw&ctype=text/javascript' 
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
> authorization'
> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
> second attempt, 
> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Osm.js&action=raw&ctype=text/javascript' 
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
> authorization'
> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
> second attempt, 
> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Sidebar-related.js&action=raw&ctype=text/javascript' 
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
> authorization'
> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
> second attempt, 
> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript' 
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
> authorization'
> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
> second attempt, 
> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript' 
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
> authorization'
> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match on 
> second attempt, 
> 'https://meta.wikimedia.org/w/index.php?title=MediaWiki:Wikiminiatlas.js&action=raw&ctype=text/javascript' 
> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", cookie, authorization'
>
> 3.5.19
>
>
>
> 31.05.2016 13:34, joe ?????:
>> no  until i test it cpl of month and i show it to the dev team they 
>> might do
>> better
>>
>>
>>
>> -- 
>> View this message in context: 
>> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677725.html
>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/99bea4a4/attachment.htm>

From yvoinov at gmail.com  Tue May 31 13:34:41 2016
From: yvoinov at gmail.com (Yuri)
Date: Tue, 31 May 2016 19:34:41 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
Message-ID: <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>

This is too expensive action. Cold out cache will decrease hit-ratio for 
weeks.


Also, I suggest force reloading objects must overwrite stale cached, no?


31.05.2016 19:32, Heiler Bemerguy ?????:
>
>
> I swear this bug was only rarely triggered without 
> collapsed_forwarding enabled... but I think you'll have to wipe your 
> cache to really test it...
>
>
>
> -- 
> Heiler Bemerguy - (91) 98151-4894
> Assessor T?cnico - CINBESA (91) 3184-1751
>
> Em 31/05/2016 08:00, Yuri escreveu:
>> Heh,
>>
>> the issue occurs also with disabled collapsed_forwarding:
>>
>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>> on second attempt, 
>> 'https://ru.wikipedia.org/w/load.php?debug=false&lang=ru&modules=jquery.accessKeyLabel%2Cclient%7Cmediawiki.RegExp%2Cnotify%2Cutil%7Cmediawiki.legacy.wikibits&skin=vector&version=b5e9abd3b463' 
>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>> 2016/05/31 16:58:12 kid1| Error negotiating SSL on FD 260: 
>> error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate 
>> verify failed (1/-1/0)
>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>> on second attempt, 
>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Secure.js&action=raw&ctype=text/javascript' 
>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>> authorization'
>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>> on second attempt, 
>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Osm.js&action=raw&ctype=text/javascript' 
>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>> authorization'
>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>> on second attempt, 
>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Sidebar-related.js&action=raw&ctype=text/javascript' 
>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>> authorization'
>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>> on second attempt, 
>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript' 
>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>> authorization'
>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>> on second attempt, 
>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript' 
>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>> authorization'
>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>> on second attempt, 
>> 'https://meta.wikimedia.org/w/index.php?title=MediaWiki:Wikiminiatlas.js&action=raw&ctype=text/javascript' 
>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", cookie, authorization'
>>
>> 3.5.19
>>
>>
>>
>> 31.05.2016 13:34, joe ?????:
>>> no  until i test it cpl of month and i show it to the dev team they 
>>> might do
>>> better
>>>
>>>
>>>
>>> -- 
>>> View this message in context: 
>>> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677725.html
>>> Sent from the Squid - Users mailing list archive at Nabble.com.
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/6df22079/attachment.htm>

From heiler.bemerguy at cinbesa.com.br  Tue May 31 13:52:52 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 31 May 2016 10:52:52 -0300
Subject: [squid-users] Vary object loop returns
In-Reply-To: <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
Message-ID: <c9f4b54a-7fd4-3355-a9cd-161b92e1ce15@cinbesa.com.br>


Yeah, I know. This kind of stuff only appeared after enabling 
collapsed_forwarding, I think. Now it's off again.. but I didn't wipe 
the cache too, so I don't know.....

2016/05/31 10:50:24 kid2| varyEvaluateMatch: Oops. Not a Vary match on 
second attempt, 'http://js.statig.com.br/pub/adtags.js' 
'accept-encoding="gzip,%20deflate"'
2016/05/31 10:50:24 kid2| clientProcessHit: Vary object loop!
2016/05/31 10:50:25 kid2| Bug: Missing MemObject::storeId value
2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.start() 0x117e4ce0
2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.finish() 0x117e4ce0
2016/05/31 10:50:25 kid2| MemObject->start_ping: 0.000000
2016/05/31 10:50:25 kid2| MemObject->inmem_hi: 2155
2016/05/31 10:50:25 kid2| MemObject->inmem_lo: 0
2016/05/31 10:50:25 kid2| MemObject->nclients: 0
2016/05/31 10:50:25 kid2| MemObject->reply: 0x7db9ce0
2016/05/31 10:50:25 kid2| MemObject->request: 0
2016/05/31 10:50:25 kid2| MemObject->logUri:
2016/05/31 10:50:25 kid2| MemObject->storeId:


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751


Em 31/05/2016 10:34, Yuri escreveu:
>
> This is too expensive action. Cold out cache will decrease hit-ratio 
> for weeks.
>
>
> Also, I suggest force reloading objects must overwrite stale cached, no?
>
>
> 31.05.2016 19:32, Heiler Bemerguy ?????:
>>
>>
>> I swear this bug was only rarely triggered without 
>> collapsed_forwarding enabled... but I think you'll have to wipe your 
>> cache to really test it...
>>
>>
>>
>> -- 
>> Heiler Bemerguy - (91) 98151-4894
>> Assessor T?cnico - CINBESA (91) 3184-1751
>>
>> Em 31/05/2016 08:00, Yuri escreveu:
>>> Heh,
>>>
>>> the issue occurs also with disabled collapsed_forwarding:
>>>
>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>>> on second attempt, 
>>> 'https://ru.wikipedia.org/w/load.php?debug=false&lang=ru&modules=jquery.accessKeyLabel%2Cclient%7Cmediawiki.RegExp%2Cnotify%2Cutil%7Cmediawiki.legacy.wikibits&skin=vector&version=b5e9abd3b463' 
>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>> 2016/05/31 16:58:12 kid1| Error negotiating SSL on FD 260: 
>>> error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate 
>>> verify failed (1/-1/0)
>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>>> on second attempt, 
>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Secure.js&action=raw&ctype=text/javascript' 
>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>> authorization'
>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>>> on second attempt, 
>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Osm.js&action=raw&ctype=text/javascript' 
>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>> authorization'
>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>>> on second attempt, 
>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Sidebar-related.js&action=raw&ctype=text/javascript' 
>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>> authorization'
>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>>> on second attempt, 
>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript' 
>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>> authorization'
>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>>> on second attempt, 
>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript' 
>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>> authorization'
>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>>> on second attempt, 
>>> 'https://meta.wikimedia.org/w/index.php?title=MediaWiki:Wikiminiatlas.js&action=raw&ctype=text/javascript' 
>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", cookie, 
>>> authorization'
>>>
>>> 3.5.19
>>>
>>>
>>>
>>> 31.05.2016 13:34, joe ?????:
>>>> no  until i test it cpl of month and i show it to the dev team they 
>>>> might do
>>>> better
>>>>
>>>>
>>>>
>>>> -- 
>>>> View this message in context: 
>>>> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677725.html
>>>> Sent from the Squid - Users mailing list archive at Nabble.com.
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/7edca117/attachment.htm>

From chip_pop at hotmail.com  Tue May 31 13:33:56 2016
From: chip_pop at hotmail.com (joe)
Date: Tue, 31 May 2016 06:33:56 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <c9f4b54a-7fd4-3355-a9cd-161b92e1ce15@cinbesa.com.br>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <c9f4b54a-7fd4-3355-a9cd-161b92e1ce15@cinbesa.com.br>
Message-ID: <1464701636671-4677737.post@n4.nabble.com>

load this link on both browser    chrome  and firefox
'http://js.statig.com.br/pub/adtags.js'
keep clicking reload  on both browser  and look at your cache.log
with or without collapsed_forwarding


Heiler Bemerguy wrote
> Yeah, I know. This kind of stuff only appeared after enabling 
> collapsed_forwarding, I think. Now it's off again.. but I didn't wipe 
> the cache too, so I don't know.....
> 
> 2016/05/31 10:50:24 kid2| varyEvaluateMatch: Oops. Not a Vary match on 
> second attempt, 'http://js.statig.com.br/pub/adtags.js' 
> 'accept-encoding="gzip,%20deflate"'
> 2016/05/31 10:50:24 kid2| clientProcessHit: Vary object loop!
> 2016/05/31 10:50:25 kid2| Bug: Missing MemObject::storeId value
> 2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.start() 0x117e4ce0
> 2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.finish() 0x117e4ce0
> 2016/05/31 10:50:25 kid2| MemObject->start_ping: 0.000000
> 2016/05/31 10:50:25 kid2| MemObject->inmem_hi: 2155
> 2016/05/31 10:50:25 kid2| MemObject->inmem_lo: 0
> 2016/05/31 10:50:25 kid2| MemObject->nclients: 0
> 2016/05/31 10:50:25 kid2| MemObject->reply: 0x7db9ce0
> 2016/05/31 10:50:25 kid2| MemObject->request: 0
> 2016/05/31 10:50:25 kid2| MemObject->logUri:
> 2016/05/31 10:50:25 kid2| MemObject->storeId:
> 
> 
> -- 
> Best Regards,
> 
> Heiler Bemerguy
> Network Manager - CINBESA
> 55 91 98151-4894/3184-1751
> 
> 
> Em 31/05/2016 10:34, Yuri escreveu:
>>
>> This is too expensive action. Cold out cache will decrease hit-ratio 
>> for weeks.
>>
>>
>> Also, I suggest force reloading objects must overwrite stale cached, no?
>>
>>
>> 31.05.2016 19:32, Heiler Bemerguy ?????:
>>>
>>>
>>> I swear this bug was only rarely triggered without 
>>> collapsed_forwarding enabled... but I think you'll have to wipe your 
>>> cache to really test it...
>>>
>>>
>>>
>>> -- 
>>> Heiler Bemerguy - (91) 98151-4894
>>> Assessor T?cnico - CINBESA (91) 3184-1751
>>>
>>> Em 31/05/2016 08:00, Yuri escreveu:
>>>> Heh,
>>>>
>>>> the issue occurs also with disabled collapsed_forwarding:
>>>>
>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>>>> on second attempt, 
>>>> 'https://ru.wikipedia.org/w/load.php?debug=false&lang=ru&modules=jquery.accessKeyLabel%2Cclient%7Cmediawiki.RegExp%2Cnotify%2Cutil%7Cmediawiki.legacy.wikibits&skin=vector&version=b5e9abd3b463' 
>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>> 2016/05/31 16:58:12 kid1| Error negotiating SSL on FD 260: 
>>>> error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate 
>>>> verify failed (1/-1/0)
>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>>>> on second attempt, 
>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Secure.js&action=raw&ctype=text/javascript' 
>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>> authorization'
>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>>>> on second attempt, 
>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Osm.js&action=raw&ctype=text/javascript' 
>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>> authorization'
>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>>>> on second attempt, 
>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Sidebar-related.js&action=raw&ctype=text/javascript' 
>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>> authorization'
>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>>>> on second attempt, 
>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript' 
>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>> authorization'
>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>>>> on second attempt, 
>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript' 
>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>> authorization'
>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match 
>>>> on second attempt, 
>>>> 'https://meta.wikimedia.org/w/index.php?title=MediaWiki:Wikiminiatlas.js&action=raw&ctype=text/javascript' 
>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", cookie, 
>>>> authorization'
>>>>
>>>> 3.5.19
>>>>
>>>>
>>>>
>>>> 31.05.2016 13:34, joe ?????:
>>>>> no  until i test it cpl of month and i show it to the dev team they 
>>>>> might do
>>>>> better
>>>>>
>>>>>
>>>>>
>>>>> -- 
>>>>> View this message in context: 
>>>>> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677725.html
>>>>> Sent from the Squid - Users mailing list archive at Nabble.com.
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> 

> squid-users at .squid-cache

>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> 

> squid-users at .squid-cache

>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> 

> squid-users at .squid-cache

>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> 

> squid-users at .squid-cache

>> http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677737.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Tue May 31 14:14:34 2016
From: yvoinov at gmail.com (Yuri)
Date: Tue, 31 May 2016 20:14:34 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <1464701636671-4677737.post@n4.nabble.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <c9f4b54a-7fd4-3355-a9cd-161b92e1ce15@cinbesa.com.br>
 <1464701636671-4677737.post@n4.nabble.com>
Message-ID: <5d9049ba-b688-a22e-07d5-12b7da94dc8c@gmail.com>

Without collapsed_forwarding seems ok:

https://i1.someimage.com/E8pM9tu.png

no warnings/errors in cache.log.

Seems Heiler right.

31.05.2016 19:33, joe ?????:
> load this link on both browser    chrome  and firefox
> 'http://js.statig.com.br/pub/adtags.js'
> keep clicking reload  on both browser  and look at your cache.log
> with or without collapsed_forwarding
>
>
> Heiler Bemerguy wrote
>> Yeah, I know. This kind of stuff only appeared after enabling
>> collapsed_forwarding, I think. Now it's off again.. but I didn't wipe
>> the cache too, so I don't know.....
>>
>> 2016/05/31 10:50:24 kid2| varyEvaluateMatch: Oops. Not a Vary match on
>> second attempt, 'http://js.statig.com.br/pub/adtags.js'
>> 'accept-encoding="gzip,%20deflate"'
>> 2016/05/31 10:50:24 kid2| clientProcessHit: Vary object loop!
>> 2016/05/31 10:50:25 kid2| Bug: Missing MemObject::storeId value
>> 2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.start() 0x117e4ce0
>> 2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.finish() 0x117e4ce0
>> 2016/05/31 10:50:25 kid2| MemObject->start_ping: 0.000000
>> 2016/05/31 10:50:25 kid2| MemObject->inmem_hi: 2155
>> 2016/05/31 10:50:25 kid2| MemObject->inmem_lo: 0
>> 2016/05/31 10:50:25 kid2| MemObject->nclients: 0
>> 2016/05/31 10:50:25 kid2| MemObject->reply: 0x7db9ce0
>> 2016/05/31 10:50:25 kid2| MemObject->request: 0
>> 2016/05/31 10:50:25 kid2| MemObject->logUri:
>> 2016/05/31 10:50:25 kid2| MemObject->storeId:
>>
>>
>> -- 
>> Best Regards,
>>
>> Heiler Bemerguy
>> Network Manager - CINBESA
>> 55 91 98151-4894/3184-1751
>>
>>
>> Em 31/05/2016 10:34, Yuri escreveu:
>>> This is too expensive action. Cold out cache will decrease hit-ratio
>>> for weeks.
>>>
>>>
>>> Also, I suggest force reloading objects must overwrite stale cached, no?
>>>
>>>
>>> 31.05.2016 19:32, Heiler Bemerguy ?????:
>>>>
>>>> I swear this bug was only rarely triggered without
>>>> collapsed_forwarding enabled... but I think you'll have to wipe your
>>>> cache to really test it...
>>>>
>>>>
>>>>
>>>> -- 
>>>> Heiler Bemerguy - (91) 98151-4894
>>>> Assessor T?cnico - CINBESA (91) 3184-1751
>>>>
>>>> Em 31/05/2016 08:00, Yuri escreveu:
>>>>> Heh,
>>>>>
>>>>> the issue occurs also with disabled collapsed_forwarding:
>>>>>
>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>> on second attempt,
>>>>> 'https://ru.wikipedia.org/w/load.php?debug=false&lang=ru&modules=jquery.accessKeyLabel%2Cclient%7Cmediawiki.RegExp%2Cnotify%2Cutil%7Cmediawiki.legacy.wikibits&skin=vector&version=b5e9abd3b463'
>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>> 2016/05/31 16:58:12 kid1| Error negotiating SSL on FD 260:
>>>>> error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate
>>>>> verify failed (1/-1/0)
>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>> on second attempt,
>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Secure.js&action=raw&ctype=text/javascript'
>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
>>>>> authorization'
>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>> on second attempt,
>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Osm.js&action=raw&ctype=text/javascript'
>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
>>>>> authorization'
>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>> on second attempt,
>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Sidebar-related.js&action=raw&ctype=text/javascript'
>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
>>>>> authorization'
>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>> on second attempt,
>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript'
>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
>>>>> authorization'
>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>> on second attempt,
>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript'
>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
>>>>> authorization'
>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>> on second attempt,
>>>>> 'https://meta.wikimedia.org/w/index.php?title=MediaWiki:Wikiminiatlas.js&action=raw&ctype=text/javascript'
>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", cookie,
>>>>> authorization'
>>>>>
>>>>> 3.5.19
>>>>>
>>>>>
>>>>>
>>>>> 31.05.2016 13:34, joe ?????:
>>>>>> no  until i test it cpl of month and i show it to the dev team they
>>>>>> might do
>>>>>> better
>>>>>>
>>>>>>
>>>>>>
>>>>>> -- 
>>>>>> View this message in context:
>>>>>> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677725.html
>>>>>> Sent from the Squid - Users mailing list archive at Nabble.com.
>>>>>> _______________________________________________
>>>>>> squid-users mailing list
>>>>>>
>> squid-users at .squid-cache
>>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>>
>> squid-users at .squid-cache
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>>
>> squid-users at .squid-cache
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>>
>> squid-users at .squid-cache
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at .squid-cache
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677737.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From chip_pop at hotmail.com  Tue May 31 13:52:57 2016
From: chip_pop at hotmail.com (joe)
Date: Tue, 31 May 2016 06:52:57 -0700 (PDT)
Subject: [squid-users] Vary object loop returns
In-Reply-To: <5d9049ba-b688-a22e-07d5-12b7da94dc8c@gmail.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <c9f4b54a-7fd4-3355-a9cd-161b92e1ce15@cinbesa.com.br>
 <1464701636671-4677737.post@n4.nabble.com>
 <5d9049ba-b688-a22e-07d5-12b7da94dc8c@gmail.com>
Message-ID: <1464702777358-4677739.post@n4.nabble.com>

i dont have this issue right now with  collapsed_forwarding on on my test
code 
yes collaps and accel  it trigger that bug more then collaps  and  intercept
without collaps on right no error in log but a miss no hit if u try on both
browsser



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677739.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From heiler.bemerguy at cinbesa.com.br  Tue May 31 14:36:55 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 31 May 2016 11:36:55 -0300
Subject: [squid-users] Vary object loop returns
In-Reply-To: <5d9049ba-b688-a22e-07d5-12b7da94dc8c@gmail.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <c9f4b54a-7fd4-3355-a9cd-161b92e1ce15@cinbesa.com.br>
 <1464701636671-4677737.post@n4.nabble.com>
 <5d9049ba-b688-a22e-07d5-12b7da94dc8c@gmail.com>
Message-ID: <931f91a3-51f4-6ff4-e781-4ed71964f527@cinbesa.com.br>


Just did a test here.

Disabled every cache_dir and fully restarted squid 3.5.19

No more "vary object loop", but these continues:

2016/05/31 11:35:13 kid2| Bug: Missing MemObject::storeId value
2016/05/31 11:35:13 kid2| mem_hdr: 0x3177f40 nodes.start() 0x7370880
2016/05/31 11:35:13 kid2| mem_hdr: 0x3177f40 nodes.finish() 0x7370880
2016/05/31 11:35:13 kid2| MemObject->start_ping: 0.000000
2016/05/31 11:35:13 kid2| MemObject->inmem_hi: 2224
2016/05/31 11:35:13 kid2| MemObject->inmem_lo: 0
2016/05/31 11:35:13 kid2| MemObject->nclients: 0
2016/05/31 11:35:13 kid2| MemObject->reply: 0x29711e0
2016/05/31 11:35:13 kid2| MemObject->request: 0
2016/05/31 11:35:13 kid2| MemObject->logUri:
2016/05/31 11:35:13 kid2| MemObject->storeId:
2016/05/31 11:35:14 kid1| Bug: Missing MemObject::storeId value
2016/05/31 11:35:14 kid1| mem_hdr: 0x3e0d990 nodes.start() 0x1ca70540
2016/05/31 11:35:14 kid1| mem_hdr: 0x3e0d990 nodes.finish() 0x1ca70540
2016/05/31 11:35:14 kid1| MemObject->start_ping: 0.000000
2016/05/31 11:35:14 kid1| MemObject->inmem_hi: 193
2016/05/31 11:35:14 kid1| MemObject->inmem_lo: 0
2016/05/31 11:35:14 kid1| MemObject->nclients: 0
2016/05/31 11:35:14 kid1| MemObject->reply: 0x45656e0
2016/05/31 11:35:14 kid1| MemObject->request: 0
2016/05/31 11:35:14 kid1| MemObject->logUri:
2016/05/31 11:35:14 kid1| MemObject->storeId:
2016/05/31 11:35:14.418 kid1| clientProcessHit: URL mismatch, 
'[unknown_URI]' != 'http://captive.apple.com/hotspot-detect.html'
2016/05/31 11:35:14 kid2| Bug: Missing MemObject::storeId value
2016/05/31 11:35:14 kid2| mem_hdr: 0x336b090 nodes.start() 0x2b136d0
2016/05/31 11:35:14 kid2| mem_hdr: 0x336b090 nodes.finish() 0x82709c0
2016/05/31 11:35:14 kid2| MemObject->start_ping: 0.000000
2016/05/31 11:35:14 kid2| MemObject->inmem_hi: 4573
2016/05/31 11:35:14 kid2| MemObject->inmem_lo: 0
2016/05/31 11:35:14 kid2| MemObject->nclients: 0
2016/05/31 11:35:14 kid2| MemObject->reply: 0x26bdf50
2016/05/31 11:35:14 kid2| MemObject->request: 0
2016/05/31 11:35:14 kid2| MemObject->logUri:
2016/05/31 11:35:14 kid2| MemObject->storeId:


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751


Em 31/05/2016 11:14, Yuri escreveu:
> Without collapsed_forwarding seems ok:
>
> https://i1.someimage.com/E8pM9tu.png
>
> no warnings/errors in cache.log.
>
> Seems Heiler right.
>
> 31.05.2016 19:33, joe ?????:
>> load this link on both browser    chrome and firefox
>> 'http://js.statig.com.br/pub/adtags.js'
>> keep clicking reload  on both browser  and look at your cache.log
>> with or without collapsed_forwarding
>>
>>
>> Heiler Bemerguy wrote
>>> Yeah, I know. This kind of stuff only appeared after enabling
>>> collapsed_forwarding, I think. Now it's off again.. but I didn't wipe
>>> the cache too, so I don't know.....
>>>
>>> 2016/05/31 10:50:24 kid2| varyEvaluateMatch: Oops. Not a Vary match on
>>> second attempt, 'http://js.statig.com.br/pub/adtags.js'
>>> 'accept-encoding="gzip,%20deflate"'
>>> 2016/05/31 10:50:24 kid2| clientProcessHit: Vary object loop!
>>> 2016/05/31 10:50:25 kid2| Bug: Missing MemObject::storeId value
>>> 2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.start() 0x117e4ce0
>>> 2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.finish() 0x117e4ce0
>>> 2016/05/31 10:50:25 kid2| MemObject->start_ping: 0.000000
>>> 2016/05/31 10:50:25 kid2| MemObject->inmem_hi: 2155
>>> 2016/05/31 10:50:25 kid2| MemObject->inmem_lo: 0
>>> 2016/05/31 10:50:25 kid2| MemObject->nclients: 0
>>> 2016/05/31 10:50:25 kid2| MemObject->reply: 0x7db9ce0
>>> 2016/05/31 10:50:25 kid2| MemObject->request: 0
>>> 2016/05/31 10:50:25 kid2| MemObject->logUri:
>>> 2016/05/31 10:50:25 kid2| MemObject->storeId:
>>>
>>>
>>> -- 
>>> Best Regards,
>>>
>>> Heiler Bemerguy
>>> Network Manager - CINBESA
>>> 55 91 98151-4894/3184-1751
>>>
>>>
>>> Em 31/05/2016 10:34, Yuri escreveu:
>>>> This is too expensive action. Cold out cache will decrease hit-ratio
>>>> for weeks.
>>>>
>>>>
>>>> Also, I suggest force reloading objects must overwrite stale 
>>>> cached, no?
>>>>
>>>>
>>>> 31.05.2016 19:32, Heiler Bemerguy ?????:
>>>>>
>>>>> I swear this bug was only rarely triggered without
>>>>> collapsed_forwarding enabled... but I think you'll have to wipe your
>>>>> cache to really test it...
>>>>>
>>>>>
>>>>>
>>>>> -- 
>>>>> Heiler Bemerguy - (91) 98151-4894
>>>>> Assessor T?cnico - CINBESA (91) 3184-1751
>>>>>
>>>>> Em 31/05/2016 08:00, Yuri escreveu:
>>>>>> Heh,
>>>>>>
>>>>>> the issue occurs also with disabled collapsed_forwarding:
>>>>>>
>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>>> on second attempt,
>>>>>> 'https://ru.wikipedia.org/w/load.php?debug=false&lang=ru&modules=jquery.accessKeyLabel%2Cclient%7Cmediawiki.RegExp%2Cnotify%2Cutil%7Cmediawiki.legacy.wikibits&skin=vector&version=b5e9abd3b463' 
>>>>>>
>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>> 2016/05/31 16:58:12 kid1| Error negotiating SSL on FD 260:
>>>>>> error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate
>>>>>> verify failed (1/-1/0)
>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>>> on second attempt,
>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Secure.js&action=raw&ctype=text/javascript' 
>>>>>>
>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>
>>>>>> authorization'
>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>>> on second attempt,
>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Osm.js&action=raw&ctype=text/javascript' 
>>>>>>
>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>
>>>>>> authorization'
>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>>> on second attempt,
>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Sidebar-related.js&action=raw&ctype=text/javascript' 
>>>>>>
>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>
>>>>>> authorization'
>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>>> on second attempt,
>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript' 
>>>>>>
>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>
>>>>>> authorization'
>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>>> on second attempt,
>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript' 
>>>>>>
>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>
>>>>>> authorization'
>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>>> on second attempt,
>>>>>> 'https://meta.wikimedia.org/w/index.php?title=MediaWiki:Wikiminiatlas.js&action=raw&ctype=text/javascript' 
>>>>>>
>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", cookie,
>>>>>> authorization'
>>>>>>
>>>>>> 3.5.19
>>>>>>
>>>>>>
>>>>>>
>>>>>> 31.05.2016 13:34, joe ?????:
>>>>>>> no  until i test it cpl of month and i show it to the dev team they
>>>>>>> might do
>>>>>>> better
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> -- 
>>>>>>> View this message in context:
>>>>>>> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677725.html 
>>>>>>>
>>>>>>> Sent from the Squid - Users mailing list archive at Nabble.com.
>>>>>>> _______________________________________________
>>>>>>> squid-users mailing list
>>>>>>>
>>> squid-users at .squid-cache
>>>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>> _______________________________________________
>>>>>> squid-users mailing list
>>>>>>
>>> squid-users at .squid-cache
>>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>>
>>> squid-users at .squid-cache
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>>
>>> squid-users at .squid-cache
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at .squid-cache
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
>>
>> -- 
>> View this message in context: 
>> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677737.html
>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/0ff2d81a/attachment.htm>

From yvoinov at gmail.com  Tue May 31 14:39:34 2016
From: yvoinov at gmail.com (Yuri)
Date: Tue, 31 May 2016 20:39:34 +0600
Subject: [squid-users] Vary object loop returns
In-Reply-To: <931f91a3-51f4-6ff4-e781-4ed71964f527@cinbesa.com.br>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <c9f4b54a-7fd4-3355-a9cd-161b92e1ce15@cinbesa.com.br>
 <1464701636671-4677737.post@n4.nabble.com>
 <5d9049ba-b688-a22e-07d5-12b7da94dc8c@gmail.com>
 <931f91a3-51f4-6ff4-e781-4ed71964f527@cinbesa.com.br>
Message-ID: <5cb41d75-387c-80af-fac6-e03a2570b0fa@gmail.com>

Bad test. Problem is with swapped onto disk objects exactly. So, when we 
disable cache_dirs, problem is gone.


31.05.2016 20:36, Heiler Bemerguy ?????:
>
>
> Just did a test here.
>
> Disabled every cache_dir and fully restarted squid 3.5.19
>
> No more "vary object loop", but these continues:
>
> 2016/05/31 11:35:13 kid2| Bug: Missing MemObject::storeId value
> 2016/05/31 11:35:13 kid2| mem_hdr: 0x3177f40 nodes.start() 0x7370880
> 2016/05/31 11:35:13 kid2| mem_hdr: 0x3177f40 nodes.finish() 0x7370880
> 2016/05/31 11:35:13 kid2| MemObject->start_ping: 0.000000
> 2016/05/31 11:35:13 kid2| MemObject->inmem_hi: 2224
> 2016/05/31 11:35:13 kid2| MemObject->inmem_lo: 0
> 2016/05/31 11:35:13 kid2| MemObject->nclients: 0
> 2016/05/31 11:35:13 kid2| MemObject->reply: 0x29711e0
> 2016/05/31 11:35:13 kid2| MemObject->request: 0
> 2016/05/31 11:35:13 kid2| MemObject->logUri:
> 2016/05/31 11:35:13 kid2| MemObject->storeId:
> 2016/05/31 11:35:14 kid1| Bug: Missing MemObject::storeId value
> 2016/05/31 11:35:14 kid1| mem_hdr: 0x3e0d990 nodes.start() 0x1ca70540
> 2016/05/31 11:35:14 kid1| mem_hdr: 0x3e0d990 nodes.finish() 0x1ca70540
> 2016/05/31 11:35:14 kid1| MemObject->start_ping: 0.000000
> 2016/05/31 11:35:14 kid1| MemObject->inmem_hi: 193
> 2016/05/31 11:35:14 kid1| MemObject->inmem_lo: 0
> 2016/05/31 11:35:14 kid1| MemObject->nclients: 0
> 2016/05/31 11:35:14 kid1| MemObject->reply: 0x45656e0
> 2016/05/31 11:35:14 kid1| MemObject->request: 0
> 2016/05/31 11:35:14 kid1| MemObject->logUri:
> 2016/05/31 11:35:14 kid1| MemObject->storeId:
> 2016/05/31 11:35:14.418 kid1| clientProcessHit: URL mismatch, 
> '[unknown_URI]' != 'http://captive.apple.com/hotspot-detect.html'
> 2016/05/31 11:35:14 kid2| Bug: Missing MemObject::storeId value
> 2016/05/31 11:35:14 kid2| mem_hdr: 0x336b090 nodes.start() 0x2b136d0
> 2016/05/31 11:35:14 kid2| mem_hdr: 0x336b090 nodes.finish() 0x82709c0
> 2016/05/31 11:35:14 kid2| MemObject->start_ping: 0.000000
> 2016/05/31 11:35:14 kid2| MemObject->inmem_hi: 4573
> 2016/05/31 11:35:14 kid2| MemObject->inmem_lo: 0
> 2016/05/31 11:35:14 kid2| MemObject->nclients: 0
> 2016/05/31 11:35:14 kid2| MemObject->reply: 0x26bdf50
> 2016/05/31 11:35:14 kid2| MemObject->request: 0
> 2016/05/31 11:35:14 kid2| MemObject->logUri:
> 2016/05/31 11:35:14 kid2| MemObject->storeId:
>
>
> -- 
> Best Regards,
>
> Heiler Bemerguy
> Network Manager - CINBESA
> 55 91 98151-4894/3184-1751
>
> Em 31/05/2016 11:14, Yuri escreveu:
>> Without collapsed_forwarding seems ok:
>>
>> https://i1.someimage.com/E8pM9tu.png
>>
>> no warnings/errors in cache.log.
>>
>> Seems Heiler right.
>>
>> 31.05.2016 19:33, joe ?????:
>>> load this link on both browser chrome  and firefox
>>> 'http://js.statig.com.br/pub/adtags.js'
>>> keep clicking reload  on both browser  and look at your cache.log
>>> with or without collapsed_forwarding
>>>
>>>
>>> Heiler Bemerguy wrote
>>>> Yeah, I know. This kind of stuff only appeared after enabling
>>>> collapsed_forwarding, I think. Now it's off again.. but I didn't wipe
>>>> the cache too, so I don't know.....
>>>>
>>>> 2016/05/31 10:50:24 kid2| varyEvaluateMatch: Oops. Not a Vary match on
>>>> second attempt, 'http://js.statig.com.br/pub/adtags.js'
>>>> 'accept-encoding="gzip,%20deflate"'
>>>> 2016/05/31 10:50:24 kid2| clientProcessHit: Vary object loop!
>>>> 2016/05/31 10:50:25 kid2| Bug: Missing MemObject::storeId value
>>>> 2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.start() 0x117e4ce0
>>>> 2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.finish() 
>>>> 0x117e4ce0
>>>> 2016/05/31 10:50:25 kid2| MemObject->start_ping: 0.000000
>>>> 2016/05/31 10:50:25 kid2| MemObject->inmem_hi: 2155
>>>> 2016/05/31 10:50:25 kid2| MemObject->inmem_lo: 0
>>>> 2016/05/31 10:50:25 kid2| MemObject->nclients: 0
>>>> 2016/05/31 10:50:25 kid2| MemObject->reply: 0x7db9ce0
>>>> 2016/05/31 10:50:25 kid2| MemObject->request: 0
>>>> 2016/05/31 10:50:25 kid2| MemObject->logUri:
>>>> 2016/05/31 10:50:25 kid2| MemObject->storeId:
>>>>
>>>>
>>>> -- 
>>>> Best Regards,
>>>>
>>>> Heiler Bemerguy
>>>> Network Manager - CINBESA
>>>> 55 91 98151-4894/3184-1751
>>>>
>>>>
>>>> Em 31/05/2016 10:34, Yuri escreveu:
>>>>> This is too expensive action. Cold out cache will decrease hit-ratio
>>>>> for weeks.
>>>>>
>>>>>
>>>>> Also, I suggest force reloading objects must overwrite stale 
>>>>> cached, no?
>>>>>
>>>>>
>>>>> 31.05.2016 19:32, Heiler Bemerguy ?????:
>>>>>>
>>>>>> I swear this bug was only rarely triggered without
>>>>>> collapsed_forwarding enabled... but I think you'll have to wipe your
>>>>>> cache to really test it...
>>>>>>
>>>>>>
>>>>>>
>>>>>> -- 
>>>>>> Heiler Bemerguy - (91) 98151-4894
>>>>>> Assessor T?cnico - CINBESA (91) 3184-1751
>>>>>>
>>>>>> Em 31/05/2016 08:00, Yuri escreveu:
>>>>>>> Heh,
>>>>>>>
>>>>>>> the issue occurs also with disabled collapsed_forwarding:
>>>>>>>
>>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>>>> on second attempt,
>>>>>>> 'https://ru.wikipedia.org/w/load.php?debug=false&lang=ru&modules=jquery.accessKeyLabel%2Cclient%7Cmediawiki.RegExp%2Cnotify%2Cutil%7Cmediawiki.legacy.wikibits&skin=vector&version=b5e9abd3b463' 
>>>>>>>
>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
>>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>>> 2016/05/31 16:58:12 kid1| Error negotiating SSL on FD 260:
>>>>>>> error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate
>>>>>>> verify failed (1/-1/0)
>>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>>>> on second attempt,
>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Secure.js&action=raw&ctype=text/javascript' 
>>>>>>>
>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>
>>>>>>> authorization'
>>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>>>> on second attempt,
>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Osm.js&action=raw&ctype=text/javascript' 
>>>>>>>
>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>
>>>>>>> authorization'
>>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>>>> on second attempt,
>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Sidebar-related.js&action=raw&ctype=text/javascript' 
>>>>>>>
>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>
>>>>>>> authorization'
>>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>>>> on second attempt,
>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript' 
>>>>>>>
>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>
>>>>>>> authorization'
>>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>>>> on second attempt,
>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript' 
>>>>>>>
>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>
>>>>>>> authorization'
>>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary match
>>>>>>> on second attempt,
>>>>>>> 'https://meta.wikimedia.org/w/index.php?title=MediaWiki:Wikiminiatlas.js&action=raw&ctype=text/javascript' 
>>>>>>>
>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", cookie,
>>>>>>> authorization'
>>>>>>>
>>>>>>> 3.5.19
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> 31.05.2016 13:34, joe ?????:
>>>>>>>> no  until i test it cpl of month and i show it to the dev team 
>>>>>>>> they
>>>>>>>> might do
>>>>>>>> better
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> -- 
>>>>>>>> View this message in context:
>>>>>>>> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677725.html 
>>>>>>>>
>>>>>>>> Sent from the Squid - Users mailing list archive at Nabble.com.
>>>>>>>> _______________________________________________
>>>>>>>> squid-users mailing list
>>>>>>>>
>>>> squid-users at .squid-cache
>>>>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>>> _______________________________________________
>>>>>>> squid-users mailing list
>>>>>>>
>>>> squid-users at .squid-cache
>>>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>>
>>>>>>
>>>>>> _______________________________________________
>>>>>> squid-users mailing list
>>>>>>
>>>> squid-users at .squid-cache
>>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>>
>>>> squid-users at .squid-cache
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at .squid-cache
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>>
>>>
>>> -- 
>>> View this message in context: 
>>> http://squid-web-proxy-cache.1019090.n4.nabble.com/Vary-object-loop-returns-tp4677716p4677737.html
>>> Sent from the Squid - Users mailing list archive at Nabble.com.
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/374bcb7d/attachment.htm>

From heiler.bemerguy at cinbesa.com.br  Tue May 31 14:45:13 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 31 May 2016 11:45:13 -0300
Subject: [squid-users] Bug: Missing MemObject::storeId value
In-Reply-To: <5cb41d75-387c-80af-fac6-e03a2570b0fa@gmail.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <c9f4b54a-7fd4-3355-a9cd-161b92e1ce15@cinbesa.com.br>
 <1464701636671-4677737.post@n4.nabble.com>
 <5d9049ba-b688-a22e-07d5-12b7da94dc8c@gmail.com>
 <931f91a3-51f4-6ff4-e781-4ed71964f527@cinbesa.com.br>
 <5cb41d75-387c-80af-fac6-e03a2570b0fa@gmail.com>
Message-ID: <4fbad1c7-6a7f-b395-4824-08ec7add0a18@cinbesa.com.br>


Yep I know it should/would vanish all those "Vary objects" messages.. 
but what are these other "Bug: Missing MemObject::storeId value" ?? I 
thought it was related...

2016/05/31 11:43:27.594 kid2| clientProcessHit: URL mismatch, 
'[unknown_URI]' != 
'http://www.agenciabelem.com.br/Resize/CreateThumbnail?path=/multimidiaSGN/galeria/69379/69379_213524.jpg&maxHeight=61&maxWidth=91'
2016/05/31 11:43:28.492 kid2| clientProcessHit: URL mismatch, 
'[unknown_URI]' != 
'http://www.agenciabelem.com.br/Resize/CreateThumbnail?path=/MultimidiaSGN/galeria/69395/69395_213686.jpg&maxHeight=225&maxWidth=136'
2016/05/31 11:43:46 kid1| Bug: Missing MemObject::storeId value
2016/05/31 11:43:46 kid1| mem_hdr: 0x3efe990 nodes.start() 0x19b79ef0
2016/05/31 11:43:46 kid1| mem_hdr: 0x3efe990 nodes.finish() 0x19b79ef0
2016/05/31 11:43:46 kid1| MemObject->start_ping: 0.000000
2016/05/31 11:43:46 kid1| MemObject->inmem_hi: 193
2016/05/31 11:43:46 kid1| MemObject->inmem_lo: 0
2016/05/31 11:43:46 kid1| MemObject->nclients: 0
2016/05/31 11:43:46 kid1| MemObject->reply: 0x45656e0
2016/05/31 11:43:46 kid1| MemObject->request: 0
2016/05/31 11:43:46 kid1| MemObject->logUri:
2016/05/31 11:43:46 kid1| MemObject->storeId:
2016/05/31 11:43:46.569 kid2| clientProcessHit: URL mismatch, 
'[unknown_URI]' != 'http://captive.apple.com/hotspot-detect.html'
2016/05/31 11:43:52 kid2| Bug: Missing MemObject::storeId value
2016/05/31 11:43:52 kid2| mem_hdr: 0x24eafe0 nodes.start() 0x7cac320
2016/05/31 11:43:52 kid2| mem_hdr: 0x24eafe0 nodes.finish() 0x5385350
2016/05/31 11:43:52 kid2| MemObject->start_ping: 0.000000
2016/05/31 11:43:52 kid2| MemObject->inmem_hi: 10455
2016/05/31 11:43:52 kid2| MemObject->inmem_lo: 0
2016/05/31 11:43:52 kid2| MemObject->nclients: 0
2016/05/31 11:43:52 kid2| MemObject->reply: 0x2970910
2016/05/31 11:43:52 kid2| MemObject->request: 0
2016/05/31 11:43:52 kid2| MemObject->logUri:
2016/05/31 11:43:52 kid2| MemObject->storeId:
2016/05/31 11:43:52.364 kid2| clientProcessHit: URL mismatch, 
'[unknown_URI]' != 
'http://cdn-00-default.nativex.com/asset/d4c6dac2-76fd-4f91-9254-9708b603f097.css'
2016/05/31 11:43:52.364 kid2| Bug: Missing MemObject::storeId value
2016/05/31 11:43:52.364 kid2| mem_hdr: 0x264c000 nodes.start() 0x311ee90
2016/05/31 11:43:52.364 kid2| mem_hdr: 0x264c000 nodes.finish() 0x6e46250
2016/05/31 11:43:52.364 kid2| MemObject->start_ping: 0.000000
2016/05/31 11:43:52.364 kid2| MemObject->inmem_hi: 12244
2016/05/31 11:43:52.364 kid2| MemObject->inmem_lo: 0
2016/05/31 11:43:52.364 kid2| MemObject->nclients: 0
2016/05/31 11:43:52.364 kid2| MemObject->reply: 0x2233a30
2016/05/31 11:43:52.364 kid2| MemObject->request: 0
2016/05/31 11:43:52.364 kid2| MemObject->logUri:
2016/05/31 11:43:52.364 kid2| MemObject->storeId:
2016/05/31 11:43:52.390 kid2| clientProcessHit: URL mismatch, 
'[unknown_URI]' != 
'http://cdn-00-default.nativex.com/asset/7b4133df-f0c8-4f2d-8532-2dcf6915577b.js'
2016/05/31 11:43:52 kid3| Bug: Missing MemObject::storeId value
2016/05/31 11:43:52 kid3| mem_hdr: 0x2ac67f0 nodes.start() 0x3f5d410
2016/05/31 11:43:52 kid3| mem_hdr: 0x2ac67f0 nodes.finish() 0x1c71fc0
2016/05/31 11:43:52 kid3| MemObject->start_ping: 0.000000
2016/05/31 11:43:52 kid3| MemObject->inmem_hi: 95355
2016/05/31 11:43:52 kid3| MemObject->inmem_lo: 0
2016/05/31 11:43:52 kid3| MemObject->nclients: 0
2016/05/31 11:43:52 kid3| MemObject->reply: 0x2972cc0
2016/05/31 11:43:52 kid3| MemObject->request: 0
2016/05/31 11:43:52 kid3| MemObject->logUri:
2016/05/31 11:43:52 kid3| MemObject->storeId:

-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751


Em 31/05/2016 11:39, Yuri escreveu:
>
> Bad test. Problem is with swapped onto disk objects exactly. So, when 
> we disable cache_dirs, problem is gone.
>
>
> 31.05.2016 20:36, Heiler Bemerguy ?????:
>>
>>
>> Just did a test here.
>>
>> Disabled every cache_dir and fully restarted squid 3.5.19
>>
>> No more "vary object loop", but these continues:
>>
>> 2016/05/31 11:35:13 kid2| Bug: Missing MemObject::storeId value
>> 2016/05/31 11:35:13 kid2| mem_hdr: 0x3177f40 nodes.start() 0x7370880
>> 2016/05/31 11:35:13 kid2| mem_hdr: 0x3177f40 nodes.finish() 0x7370880
>> 2016/05/31 11:35:13 kid2| MemObject->start_ping: 0.000000
>> 2016/05/31 11:35:13 kid2| MemObject->inmem_hi: 2224
>> 2016/05/31 11:35:13 kid2| MemObject->inmem_lo: 0
>> 2016/05/31 11:35:13 kid2| MemObject->nclients: 0
>> 2016/05/31 11:35:13 kid2| MemObject->reply: 0x29711e0
>> 2016/05/31 11:35:13 kid2| MemObject->request: 0
>> 2016/05/31 11:35:13 kid2| MemObject->logUri:
>> 2016/05/31 11:35:13 kid2| MemObject->storeId:
>> 2016/05/31 11:35:14 kid1| Bug: Missing MemObject::storeId value
>> 2016/05/31 11:35:14 kid1| mem_hdr: 0x3e0d990 nodes.start() 0x1ca70540
>> 2016/05/31 11:35:14 kid1| mem_hdr: 0x3e0d990 nodes.finish() 0x1ca70540
>> 2016/05/31 11:35:14 kid1| MemObject->start_ping: 0.000000
>> 2016/05/31 11:35:14 kid1| MemObject->inmem_hi: 193
>> 2016/05/31 11:35:14 kid1| MemObject->inmem_lo: 0
>> 2016/05/31 11:35:14 kid1| MemObject->nclients: 0
>> 2016/05/31 11:35:14 kid1| MemObject->reply: 0x45656e0
>> 2016/05/31 11:35:14 kid1| MemObject->request: 0
>> 2016/05/31 11:35:14 kid1| MemObject->logUri:
>> 2016/05/31 11:35:14 kid1| MemObject->storeId:
>> 2016/05/31 11:35:14.418 kid1| clientProcessHit: URL mismatch, 
>> '[unknown_URI]' != 'http://captive.apple.com/hotspot-detect.html'
>> 2016/05/31 11:35:14 kid2| Bug: Missing MemObject::storeId value
>> 2016/05/31 11:35:14 kid2| mem_hdr: 0x336b090 nodes.start() 0x2b136d0
>> 2016/05/31 11:35:14 kid2| mem_hdr: 0x336b090 nodes.finish() 0x82709c0
>> 2016/05/31 11:35:14 kid2| MemObject->start_ping: 0.000000
>> 2016/05/31 11:35:14 kid2| MemObject->inmem_hi: 4573
>> 2016/05/31 11:35:14 kid2| MemObject->inmem_lo: 0
>> 2016/05/31 11:35:14 kid2| MemObject->nclients: 0
>> 2016/05/31 11:35:14 kid2| MemObject->reply: 0x26bdf50
>> 2016/05/31 11:35:14 kid2| MemObject->request: 0
>> 2016/05/31 11:35:14 kid2| MemObject->logUri:
>> 2016/05/31 11:35:14 kid2| MemObject->storeId:
>>
>>
>> -- 
>> Best Regards,
>>
>> Heiler Bemerguy
>> Network Manager - CINBESA
>> 55 91 98151-4894/3184-1751
>>
>> Em 31/05/2016 11:14, Yuri escreveu:
>>> Without collapsed_forwarding seems ok:
>>>
>>> https://i1.someimage.com/E8pM9tu.png
>>>
>>> no warnings/errors in cache.log.
>>>
>>> Seems Heiler right.
>>>
>>> 31.05.2016 19:33, joe ?????:
>>>> load this link on both browser chrome  and firefox
>>>> 'http://js.statig.com.br/pub/adtags.js'
>>>> keep clicking reload  on both browser  and look at your cache.log
>>>> with or without collapsed_forwarding
>>>>
>>>>
>>>> Heiler Bemerguy wrote
>>>>> Yeah, I know. This kind of stuff only appeared after enabling
>>>>> collapsed_forwarding, I think. Now it's off again.. but I didn't wipe
>>>>> the cache too, so I don't know.....
>>>>>
>>>>> 2016/05/31 10:50:24 kid2| varyEvaluateMatch: Oops. Not a Vary 
>>>>> match on
>>>>> second attempt, 'http://js.statig.com.br/pub/adtags.js'
>>>>> 'accept-encoding="gzip,%20deflate"'
>>>>> 2016/05/31 10:50:24 kid2| clientProcessHit: Vary object loop!
>>>>> 2016/05/31 10:50:25 kid2| Bug: Missing MemObject::storeId value
>>>>> 2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.start() 
>>>>> 0x117e4ce0
>>>>> 2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.finish() 
>>>>> 0x117e4ce0
>>>>> 2016/05/31 10:50:25 kid2| MemObject->start_ping: 0.000000
>>>>> 2016/05/31 10:50:25 kid2| MemObject->inmem_hi: 2155
>>>>> 2016/05/31 10:50:25 kid2| MemObject->inmem_lo: 0
>>>>> 2016/05/31 10:50:25 kid2| MemObject->nclients: 0
>>>>> 2016/05/31 10:50:25 kid2| MemObject->reply: 0x7db9ce0
>>>>> 2016/05/31 10:50:25 kid2| MemObject->request: 0
>>>>> 2016/05/31 10:50:25 kid2| MemObject->logUri:
>>>>> 2016/05/31 10:50:25 kid2| MemObject->storeId:
>>>>>
>>>>>
>>>>> -- 
>>>>> Best Regards,
>>>>>
>>>>> Heiler Bemerguy
>>>>> Network Manager - CINBESA
>>>>> 55 91 98151-4894/3184-1751
>>>>>
>>>>>
>>>>> Em 31/05/2016 10:34, Yuri escreveu:
>>>>>> This is too expensive action. Cold out cache will decrease hit-ratio
>>>>>> for weeks.
>>>>>>
>>>>>>
>>>>>> Also, I suggest force reloading objects must overwrite stale 
>>>>>> cached, no?
>>>>>>
>>>>>>
>>>>>> 31.05.2016 19:32, Heiler Bemerguy ?????:
>>>>>>>
>>>>>>> I swear this bug was only rarely triggered without
>>>>>>> collapsed_forwarding enabled... but I think you'll have to wipe 
>>>>>>> your
>>>>>>> cache to really test it...
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>>> -- 
>>>>>>> Heiler Bemerguy - (91) 98151-4894
>>>>>>> Assessor T?cnico - CINBESA (91) 3184-1751
>>>>>>>
>>>>>>> Em 31/05/2016 08:00, Yuri escreveu:
>>>>>>>> Heh,
>>>>>>>>
>>>>>>>> the issue occurs also with disabled collapsed_forwarding:
>>>>>>>>
>>>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>> match
>>>>>>>> on second attempt,
>>>>>>>> 'https://ru.wikipedia.org/w/load.php?debug=false&lang=ru&modules=jquery.accessKeyLabel%2Cclient%7Cmediawiki.RegExp%2Cnotify%2Cutil%7Cmediawiki.legacy.wikibits&skin=vector&version=b5e9abd3b463' 
>>>>>>>>
>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
>>>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>>>> 2016/05/31 16:58:12 kid1| Error negotiating SSL on FD 260:
>>>>>>>> error:14090086:SSL 
>>>>>>>> routines:SSL3_GET_SERVER_CERTIFICATE:certificate
>>>>>>>> verify failed (1/-1/0)
>>>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>> match
>>>>>>>> on second attempt,
>>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Secure.js&action=raw&ctype=text/javascript' 
>>>>>>>>
>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>>
>>>>>>>> authorization'
>>>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>> match
>>>>>>>> on second attempt,
>>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Osm.js&action=raw&ctype=text/javascript' 
>>>>>>>>
>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>>
>>>>>>>> authorization'
>>>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>> match
>>>>>>>> on second attempt,
>>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Sidebar-related.js&action=raw&ctype=text/javascript' 
>>>>>>>>
>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>>
>>>>>>>> authorization'
>>>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>> match
>>>>>>>> on second attempt,
>>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript' 
>>>>>>>>
>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>>
>>>>>>>> authorization'
>>>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>> match
>>>>>>>> on second attempt,
>>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript' 
>>>>>>>>
>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>>
>>>>>>>> authorization'
>>>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>> match
>>>>>>>> on second attempt,
>>>>>>>> 'https://meta.wikimedia.org/w/index.php?title=MediaWiki:Wikiminiatlas.js&action=raw&ctype=text/javascript' 
>>>>>>>>
>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", cookie,
>>>>>>>> authorization'
>>>>>>>>
>>>>>>>> 3.5.19
>>>>>>>>
>>>>>>>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/fd6fc156/attachment.htm>

From yvoinov at gmail.com  Tue May 31 14:49:05 2016
From: yvoinov at gmail.com (Yuri)
Date: Tue, 31 May 2016 20:49:05 +0600
Subject: [squid-users] Bug: Missing MemObject::storeId value
In-Reply-To: <4fbad1c7-6a7f-b395-4824-08ec7add0a18@cinbesa.com.br>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <c9f4b54a-7fd4-3355-a9cd-161b92e1ce15@cinbesa.com.br>
 <1464701636671-4677737.post@n4.nabble.com>
 <5d9049ba-b688-a22e-07d5-12b7da94dc8c@gmail.com>
 <931f91a3-51f4-6ff4-e781-4ed71964f527@cinbesa.com.br>
 <5cb41d75-387c-80af-fac6-e03a2570b0fa@gmail.com>
 <4fbad1c7-6a7f-b395-4824-08ec7add0a18@cinbesa.com.br>
Message-ID: <6a67dd0e-80ae-ab5e-f353-2ec403ea6e75@gmail.com>

Hm. Seems related. The objects not the same in memory yet.


31.05.2016 20:45, Heiler Bemerguy ?????:
>
>
> Yep I know it should/would vanish all those "Vary objects" messages.. 
> but what are these other "Bug: Missing MemObject::storeId value" ?? I 
> thought it was related...
>
> 2016/05/31 11:43:27.594 kid2| clientProcessHit: URL mismatch, 
> '[unknown_URI]' != 
> 'http://www.agenciabelem.com.br/Resize/CreateThumbnail?path=/multimidiaSGN/galeria/69379/69379_213524.jpg&maxHeight=61&maxWidth=91'
> 2016/05/31 11:43:28.492 kid2| clientProcessHit: URL mismatch, 
> '[unknown_URI]' != 
> 'http://www.agenciabelem.com.br/Resize/CreateThumbnail?path=/MultimidiaSGN/galeria/69395/69395_213686.jpg&maxHeight=225&maxWidth=136'
> 2016/05/31 11:43:46 kid1| Bug: Missing MemObject::storeId value
> 2016/05/31 11:43:46 kid1| mem_hdr: 0x3efe990 nodes.start() 0x19b79ef0
> 2016/05/31 11:43:46 kid1| mem_hdr: 0x3efe990 nodes.finish() 0x19b79ef0
> 2016/05/31 11:43:46 kid1| MemObject->start_ping: 0.000000
> 2016/05/31 11:43:46 kid1| MemObject->inmem_hi: 193
> 2016/05/31 11:43:46 kid1| MemObject->inmem_lo: 0
> 2016/05/31 11:43:46 kid1| MemObject->nclients: 0
> 2016/05/31 11:43:46 kid1| MemObject->reply: 0x45656e0
> 2016/05/31 11:43:46 kid1| MemObject->request: 0
> 2016/05/31 11:43:46 kid1| MemObject->logUri:
> 2016/05/31 11:43:46 kid1| MemObject->storeId:
> 2016/05/31 11:43:46.569 kid2| clientProcessHit: URL mismatch, 
> '[unknown_URI]' != 'http://captive.apple.com/hotspot-detect.html'
> 2016/05/31 11:43:52 kid2| Bug: Missing MemObject::storeId value
> 2016/05/31 11:43:52 kid2| mem_hdr: 0x24eafe0 nodes.start() 0x7cac320
> 2016/05/31 11:43:52 kid2| mem_hdr: 0x24eafe0 nodes.finish() 0x5385350
> 2016/05/31 11:43:52 kid2| MemObject->start_ping: 0.000000
> 2016/05/31 11:43:52 kid2| MemObject->inmem_hi: 10455
> 2016/05/31 11:43:52 kid2| MemObject->inmem_lo: 0
> 2016/05/31 11:43:52 kid2| MemObject->nclients: 0
> 2016/05/31 11:43:52 kid2| MemObject->reply: 0x2970910
> 2016/05/31 11:43:52 kid2| MemObject->request: 0
> 2016/05/31 11:43:52 kid2| MemObject->logUri:
> 2016/05/31 11:43:52 kid2| MemObject->storeId:
> 2016/05/31 11:43:52.364 kid2| clientProcessHit: URL mismatch, 
> '[unknown_URI]' != 
> 'http://cdn-00-default.nativex.com/asset/d4c6dac2-76fd-4f91-9254-9708b603f097.css'
> 2016/05/31 11:43:52.364 kid2| Bug: Missing MemObject::storeId value
> 2016/05/31 11:43:52.364 kid2| mem_hdr: 0x264c000 nodes.start() 0x311ee90
> 2016/05/31 11:43:52.364 kid2| mem_hdr: 0x264c000 nodes.finish() 0x6e46250
> 2016/05/31 11:43:52.364 kid2| MemObject->start_ping: 0.000000
> 2016/05/31 11:43:52.364 kid2| MemObject->inmem_hi: 12244
> 2016/05/31 11:43:52.364 kid2| MemObject->inmem_lo: 0
> 2016/05/31 11:43:52.364 kid2| MemObject->nclients: 0
> 2016/05/31 11:43:52.364 kid2| MemObject->reply: 0x2233a30
> 2016/05/31 11:43:52.364 kid2| MemObject->request: 0
> 2016/05/31 11:43:52.364 kid2| MemObject->logUri:
> 2016/05/31 11:43:52.364 kid2| MemObject->storeId:
> 2016/05/31 11:43:52.390 kid2| clientProcessHit: URL mismatch, 
> '[unknown_URI]' != 
> 'http://cdn-00-default.nativex.com/asset/7b4133df-f0c8-4f2d-8532-2dcf6915577b.js'
> 2016/05/31 11:43:52 kid3| Bug: Missing MemObject::storeId value
> 2016/05/31 11:43:52 kid3| mem_hdr: 0x2ac67f0 nodes.start() 0x3f5d410
> 2016/05/31 11:43:52 kid3| mem_hdr: 0x2ac67f0 nodes.finish() 0x1c71fc0
> 2016/05/31 11:43:52 kid3| MemObject->start_ping: 0.000000
> 2016/05/31 11:43:52 kid3| MemObject->inmem_hi: 95355
> 2016/05/31 11:43:52 kid3| MemObject->inmem_lo: 0
> 2016/05/31 11:43:52 kid3| MemObject->nclients: 0
> 2016/05/31 11:43:52 kid3| MemObject->reply: 0x2972cc0
> 2016/05/31 11:43:52 kid3| MemObject->request: 0
> 2016/05/31 11:43:52 kid3| MemObject->logUri:
> 2016/05/31 11:43:52 kid3| MemObject->storeId:
>
> -- 
> Best Regards,
>
> Heiler Bemerguy
> Network Manager - CINBESA
> 55 91 98151-4894/3184-1751
>
> Em 31/05/2016 11:39, Yuri escreveu:
>>
>> Bad test. Problem is with swapped onto disk objects exactly. So, when 
>> we disable cache_dirs, problem is gone.
>>
>>
>> 31.05.2016 20:36, Heiler Bemerguy ?????:
>>>
>>>
>>> Just did a test here.
>>>
>>> Disabled every cache_dir and fully restarted squid 3.5.19
>>>
>>> No more "vary object loop", but these continues:
>>>
>>> 2016/05/31 11:35:13 kid2| Bug: Missing MemObject::storeId value
>>> 2016/05/31 11:35:13 kid2| mem_hdr: 0x3177f40 nodes.start() 0x7370880
>>> 2016/05/31 11:35:13 kid2| mem_hdr: 0x3177f40 nodes.finish() 0x7370880
>>> 2016/05/31 11:35:13 kid2| MemObject->start_ping: 0.000000
>>> 2016/05/31 11:35:13 kid2| MemObject->inmem_hi: 2224
>>> 2016/05/31 11:35:13 kid2| MemObject->inmem_lo: 0
>>> 2016/05/31 11:35:13 kid2| MemObject->nclients: 0
>>> 2016/05/31 11:35:13 kid2| MemObject->reply: 0x29711e0
>>> 2016/05/31 11:35:13 kid2| MemObject->request: 0
>>> 2016/05/31 11:35:13 kid2| MemObject->logUri:
>>> 2016/05/31 11:35:13 kid2| MemObject->storeId:
>>> 2016/05/31 11:35:14 kid1| Bug: Missing MemObject::storeId value
>>> 2016/05/31 11:35:14 kid1| mem_hdr: 0x3e0d990 nodes.start() 0x1ca70540
>>> 2016/05/31 11:35:14 kid1| mem_hdr: 0x3e0d990 nodes.finish() 0x1ca70540
>>> 2016/05/31 11:35:14 kid1| MemObject->start_ping: 0.000000
>>> 2016/05/31 11:35:14 kid1| MemObject->inmem_hi: 193
>>> 2016/05/31 11:35:14 kid1| MemObject->inmem_lo: 0
>>> 2016/05/31 11:35:14 kid1| MemObject->nclients: 0
>>> 2016/05/31 11:35:14 kid1| MemObject->reply: 0x45656e0
>>> 2016/05/31 11:35:14 kid1| MemObject->request: 0
>>> 2016/05/31 11:35:14 kid1| MemObject->logUri:
>>> 2016/05/31 11:35:14 kid1| MemObject->storeId:
>>> 2016/05/31 11:35:14.418 kid1| clientProcessHit: URL mismatch, 
>>> '[unknown_URI]' != 'http://captive.apple.com/hotspot-detect.html'
>>> 2016/05/31 11:35:14 kid2| Bug: Missing MemObject::storeId value
>>> 2016/05/31 11:35:14 kid2| mem_hdr: 0x336b090 nodes.start() 0x2b136d0
>>> 2016/05/31 11:35:14 kid2| mem_hdr: 0x336b090 nodes.finish() 0x82709c0
>>> 2016/05/31 11:35:14 kid2| MemObject->start_ping: 0.000000
>>> 2016/05/31 11:35:14 kid2| MemObject->inmem_hi: 4573
>>> 2016/05/31 11:35:14 kid2| MemObject->inmem_lo: 0
>>> 2016/05/31 11:35:14 kid2| MemObject->nclients: 0
>>> 2016/05/31 11:35:14 kid2| MemObject->reply: 0x26bdf50
>>> 2016/05/31 11:35:14 kid2| MemObject->request: 0
>>> 2016/05/31 11:35:14 kid2| MemObject->logUri:
>>> 2016/05/31 11:35:14 kid2| MemObject->storeId:
>>>
>>>
>>> -- 
>>> Best Regards,
>>>
>>> Heiler Bemerguy
>>> Network Manager - CINBESA
>>> 55 91 98151-4894/3184-1751
>>>
>>> Em 31/05/2016 11:14, Yuri escreveu:
>>>> Without collapsed_forwarding seems ok:
>>>>
>>>> https://i1.someimage.com/E8pM9tu.png
>>>>
>>>> no warnings/errors in cache.log.
>>>>
>>>> Seems Heiler right.
>>>>
>>>> 31.05.2016 19:33, joe ?????:
>>>>> load this link on both browser chrome  and firefox
>>>>> 'http://js.statig.com.br/pub/adtags.js'
>>>>> keep clicking reload  on both browser  and look at your cache.log
>>>>> with or without collapsed_forwarding
>>>>>
>>>>>
>>>>> Heiler Bemerguy wrote
>>>>>> Yeah, I know. This kind of stuff only appeared after enabling
>>>>>> collapsed_forwarding, I think. Now it's off again.. but I didn't 
>>>>>> wipe
>>>>>> the cache too, so I don't know.....
>>>>>>
>>>>>> 2016/05/31 10:50:24 kid2| varyEvaluateMatch: Oops. Not a Vary 
>>>>>> match on
>>>>>> second attempt, 'http://js.statig.com.br/pub/adtags.js'
>>>>>> 'accept-encoding="gzip,%20deflate"'
>>>>>> 2016/05/31 10:50:24 kid2| clientProcessHit: Vary object loop!
>>>>>> 2016/05/31 10:50:25 kid2| Bug: Missing MemObject::storeId value
>>>>>> 2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.start() 
>>>>>> 0x117e4ce0
>>>>>> 2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.finish() 
>>>>>> 0x117e4ce0
>>>>>> 2016/05/31 10:50:25 kid2| MemObject->start_ping: 0.000000
>>>>>> 2016/05/31 10:50:25 kid2| MemObject->inmem_hi: 2155
>>>>>> 2016/05/31 10:50:25 kid2| MemObject->inmem_lo: 0
>>>>>> 2016/05/31 10:50:25 kid2| MemObject->nclients: 0
>>>>>> 2016/05/31 10:50:25 kid2| MemObject->reply: 0x7db9ce0
>>>>>> 2016/05/31 10:50:25 kid2| MemObject->request: 0
>>>>>> 2016/05/31 10:50:25 kid2| MemObject->logUri:
>>>>>> 2016/05/31 10:50:25 kid2| MemObject->storeId:
>>>>>>
>>>>>>
>>>>>> -- 
>>>>>> Best Regards,
>>>>>>
>>>>>> Heiler Bemerguy
>>>>>> Network Manager - CINBESA
>>>>>> 55 91 98151-4894/3184-1751
>>>>>>
>>>>>>
>>>>>> Em 31/05/2016 10:34, Yuri escreveu:
>>>>>>> This is too expensive action. Cold out cache will decrease 
>>>>>>> hit-ratio
>>>>>>> for weeks.
>>>>>>>
>>>>>>>
>>>>>>> Also, I suggest force reloading objects must overwrite stale 
>>>>>>> cached, no?
>>>>>>>
>>>>>>>
>>>>>>> 31.05.2016 19:32, Heiler Bemerguy ?????:
>>>>>>>>
>>>>>>>> I swear this bug was only rarely triggered without
>>>>>>>> collapsed_forwarding enabled... but I think you'll have to wipe 
>>>>>>>> your
>>>>>>>> cache to really test it...
>>>>>>>>
>>>>>>>>
>>>>>>>>
>>>>>>>> -- 
>>>>>>>> Heiler Bemerguy - (91) 98151-4894
>>>>>>>> Assessor T?cnico - CINBESA (91) 3184-1751
>>>>>>>>
>>>>>>>> Em 31/05/2016 08:00, Yuri escreveu:
>>>>>>>>> Heh,
>>>>>>>>>
>>>>>>>>> the issue occurs also with disabled collapsed_forwarding:
>>>>>>>>>
>>>>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>>> match
>>>>>>>>> on second attempt,
>>>>>>>>> 'https://ru.wikipedia.org/w/load.php?debug=false&lang=ru&modules=jquery.accessKeyLabel%2Cclient%7Cmediawiki.RegExp%2Cnotify%2Cutil%7Cmediawiki.legacy.wikibits&skin=vector&version=b5e9abd3b463' 
>>>>>>>>>
>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
>>>>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>>>>> 2016/05/31 16:58:12 kid1| Error negotiating SSL on FD 260:
>>>>>>>>> error:14090086:SSL 
>>>>>>>>> routines:SSL3_GET_SERVER_CERTIFICATE:certificate
>>>>>>>>> verify failed (1/-1/0)
>>>>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>>> match
>>>>>>>>> on second attempt,
>>>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Secure.js&action=raw&ctype=text/javascript' 
>>>>>>>>>
>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>>>
>>>>>>>>> authorization'
>>>>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>>> match
>>>>>>>>> on second attempt,
>>>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Osm.js&action=raw&ctype=text/javascript' 
>>>>>>>>>
>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>>>
>>>>>>>>> authorization'
>>>>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>>> match
>>>>>>>>> on second attempt,
>>>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Sidebar-related.js&action=raw&ctype=text/javascript' 
>>>>>>>>>
>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>>>
>>>>>>>>> authorization'
>>>>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>>> match
>>>>>>>>> on second attempt,
>>>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript' 
>>>>>>>>>
>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>>>
>>>>>>>>> authorization'
>>>>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>>> match
>>>>>>>>> on second attempt,
>>>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript' 
>>>>>>>>>
>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>>>
>>>>>>>>> authorization'
>>>>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>>> match
>>>>>>>>> on second attempt,
>>>>>>>>> 'https://meta.wikimedia.org/w/index.php?title=MediaWiki:Wikiminiatlas.js&action=raw&ctype=text/javascript' 
>>>>>>>>>
>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", cookie,
>>>>>>>>> authorization'
>>>>>>>>>
>>>>>>>>> 3.5.19
>>>>>>>>>
>>>>>>>>>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/06cdc255/attachment.htm>

From heiler.bemerguy at cinbesa.com.br  Tue May 31 15:09:45 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 31 May 2016 12:09:45 -0300
Subject: [squid-users] Bug: Missing MemObject::storeId value
In-Reply-To: <6a67dd0e-80ae-ab5e-f353-2ec403ea6e75@gmail.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <c9f4b54a-7fd4-3355-a9cd-161b92e1ce15@cinbesa.com.br>
 <1464701636671-4677737.post@n4.nabble.com>
 <5d9049ba-b688-a22e-07d5-12b7da94dc8c@gmail.com>
 <931f91a3-51f4-6ff4-e781-4ed71964f527@cinbesa.com.br>
 <5cb41d75-387c-80af-fac6-e03a2570b0fa@gmail.com>
 <4fbad1c7-6a7f-b395-4824-08ec7add0a18@cinbesa.com.br>
 <6a67dd0e-80ae-ab5e-f353-2ec403ea6e75@gmail.com>
Message-ID: <e21161a5-eef9-7b10-e4a5-0222d0e6756c@cinbesa.com.br>


I disabled ICP requests to it and these "Bug: Missing MemObject::storeId 
value" messages stopped... any thoughts?

Known bug?

-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751



Em 31/05/2016 11:49, Yuri escreveu:
>
> Hm. Seems related. The objects not the same in memory yet.
>
>
> 31.05.2016 20:45, Heiler Bemerguy ?????:
>>
>>
>> Yep I know it should/would vanish all those "Vary objects" messages.. 
>> but what are these other "Bug: Missing MemObject::storeId value" ?? I 
>> thought it was related...
>>
>> 2016/05/31 11:43:27.594 kid2| clientProcessHit: URL mismatch, 
>> '[unknown_URI]' != 
>> 'http://www.agenciabelem.com.br/Resize/CreateThumbnail?path=/multimidiaSGN/galeria/69379/69379_213524.jpg&maxHeight=61&maxWidth=91'
>> 2016/05/31 11:43:28.492 kid2| clientProcessHit: URL mismatch, 
>> '[unknown_URI]' != 
>> 'http://www.agenciabelem.com.br/Resize/CreateThumbnail?path=/MultimidiaSGN/galeria/69395/69395_213686.jpg&maxHeight=225&maxWidth=136'
>> 2016/05/31 11:43:46 kid1| Bug: Missing MemObject::storeId value
>> 2016/05/31 11:43:46 kid1| mem_hdr: 0x3efe990 nodes.start() 0x19b79ef0
>> 2016/05/31 11:43:46 kid1| mem_hdr: 0x3efe990 nodes.finish() 0x19b79ef0
>> 2016/05/31 11:43:46 kid1| MemObject->start_ping: 0.000000
>> 2016/05/31 11:43:46 kid1| MemObject->inmem_hi: 193
>> 2016/05/31 11:43:46 kid1| MemObject->inmem_lo: 0
>> 2016/05/31 11:43:46 kid1| MemObject->nclients: 0
>> 2016/05/31 11:43:46 kid1| MemObject->reply: 0x45656e0
>> 2016/05/31 11:43:46 kid1| MemObject->request: 0
>> 2016/05/31 11:43:46 kid1| MemObject->logUri:
>> 2016/05/31 11:43:46 kid1| MemObject->storeId:
>> 2016/05/31 11:43:46.569 kid2| clientProcessHit: URL mismatch, 
>> '[unknown_URI]' != 'http://captive.apple.com/hotspot-detect.html'
>> 2016/05/31 11:43:52 kid2| Bug: Missing MemObject::storeId value
>> 2016/05/31 11:43:52 kid2| mem_hdr: 0x24eafe0 nodes.start() 0x7cac320
>> 2016/05/31 11:43:52 kid2| mem_hdr: 0x24eafe0 nodes.finish() 0x5385350
>> 2016/05/31 11:43:52 kid2| MemObject->start_ping: 0.000000
>> 2016/05/31 11:43:52 kid2| MemObject->inmem_hi: 10455
>> 2016/05/31 11:43:52 kid2| MemObject->inmem_lo: 0
>> 2016/05/31 11:43:52 kid2| MemObject->nclients: 0
>> 2016/05/31 11:43:52 kid2| MemObject->reply: 0x2970910
>> 2016/05/31 11:43:52 kid2| MemObject->request: 0
>> 2016/05/31 11:43:52 kid2| MemObject->logUri:
>> 2016/05/31 11:43:52 kid2| MemObject->storeId:
>> 2016/05/31 11:43:52.364 kid2| clientProcessHit: URL mismatch, 
>> '[unknown_URI]' != 
>> 'http://cdn-00-default.nativex.com/asset/d4c6dac2-76fd-4f91-9254-9708b603f097.css'
>> 2016/05/31 11:43:52.364 kid2| Bug: Missing MemObject::storeId value
>> 2016/05/31 11:43:52.364 kid2| mem_hdr: 0x264c000 nodes.start() 0x311ee90
>> 2016/05/31 11:43:52.364 kid2| mem_hdr: 0x264c000 nodes.finish() 0x6e46250
>> 2016/05/31 11:43:52.364 kid2| MemObject->start_ping: 0.000000
>> 2016/05/31 11:43:52.364 kid2| MemObject->inmem_hi: 12244
>> 2016/05/31 11:43:52.364 kid2| MemObject->inmem_lo: 0
>> 2016/05/31 11:43:52.364 kid2| MemObject->nclients: 0
>> 2016/05/31 11:43:52.364 kid2| MemObject->reply: 0x2233a30
>> 2016/05/31 11:43:52.364 kid2| MemObject->request: 0
>> 2016/05/31 11:43:52.364 kid2| MemObject->logUri:
>> 2016/05/31 11:43:52.364 kid2| MemObject->storeId:
>> 2016/05/31 11:43:52.390 kid2| clientProcessHit: URL mismatch, 
>> '[unknown_URI]' != 
>> 'http://cdn-00-default.nativex.com/asset/7b4133df-f0c8-4f2d-8532-2dcf6915577b.js'
>> 2016/05/31 11:43:52 kid3| Bug: Missing MemObject::storeId value
>> 2016/05/31 11:43:52 kid3| mem_hdr: 0x2ac67f0 nodes.start() 0x3f5d410
>> 2016/05/31 11:43:52 kid3| mem_hdr: 0x2ac67f0 nodes.finish() 0x1c71fc0
>> 2016/05/31 11:43:52 kid3| MemObject->start_ping: 0.000000
>> 2016/05/31 11:43:52 kid3| MemObject->inmem_hi: 95355
>> 2016/05/31 11:43:52 kid3| MemObject->inmem_lo: 0
>> 2016/05/31 11:43:52 kid3| MemObject->nclients: 0
>> 2016/05/31 11:43:52 kid3| MemObject->reply: 0x2972cc0
>> 2016/05/31 11:43:52 kid3| MemObject->request: 0
>> 2016/05/31 11:43:52 kid3| MemObject->logUri:
>> 2016/05/31 11:43:52 kid3| MemObject->storeId:
>>
>> -- 
>> Best Regards,
>>
>> Heiler Bemerguy
>> Network Manager - CINBESA
>> 55 91 98151-4894/3184-1751
>>
>> Em 31/05/2016 11:39, Yuri escreveu:
>>>
>>> Bad test. Problem is with swapped onto disk objects exactly. So, 
>>> when we disable cache_dirs, problem is gone.
>>>
>>>
>>> 31.05.2016 20:36, Heiler Bemerguy ?????:
>>>>
>>>>
>>>> Just did a test here.
>>>>
>>>> Disabled every cache_dir and fully restarted squid 3.5.19
>>>>
>>>> No more "vary object loop", but these continues:
>>>>
>>>> 2016/05/31 11:35:13 kid2| Bug: Missing MemObject::storeId value
>>>> 2016/05/31 11:35:13 kid2| mem_hdr: 0x3177f40 nodes.start() 0x7370880
>>>> 2016/05/31 11:35:13 kid2| mem_hdr: 0x3177f40 nodes.finish() 0x7370880
>>>> 2016/05/31 11:35:13 kid2| MemObject->start_ping: 0.000000
>>>> 2016/05/31 11:35:13 kid2| MemObject->inmem_hi: 2224
>>>> 2016/05/31 11:35:13 kid2| MemObject->inmem_lo: 0
>>>> 2016/05/31 11:35:13 kid2| MemObject->nclients: 0
>>>> 2016/05/31 11:35:13 kid2| MemObject->reply: 0x29711e0
>>>> 2016/05/31 11:35:13 kid2| MemObject->request: 0
>>>> 2016/05/31 11:35:13 kid2| MemObject->logUri:
>>>> 2016/05/31 11:35:13 kid2| MemObject->storeId:
>>>> 2016/05/31 11:35:14 kid1| Bug: Missing MemObject::storeId value
>>>> 2016/05/31 11:35:14 kid1| mem_hdr: 0x3e0d990 nodes.start() 0x1ca70540
>>>> 2016/05/31 11:35:14 kid1| mem_hdr: 0x3e0d990 nodes.finish() 0x1ca70540
>>>> 2016/05/31 11:35:14 kid1| MemObject->start_ping: 0.000000
>>>> 2016/05/31 11:35:14 kid1| MemObject->inmem_hi: 193
>>>> 2016/05/31 11:35:14 kid1| MemObject->inmem_lo: 0
>>>> 2016/05/31 11:35:14 kid1| MemObject->nclients: 0
>>>> 2016/05/31 11:35:14 kid1| MemObject->reply: 0x45656e0
>>>> 2016/05/31 11:35:14 kid1| MemObject->request: 0
>>>> 2016/05/31 11:35:14 kid1| MemObject->logUri:
>>>> 2016/05/31 11:35:14 kid1| MemObject->storeId:
>>>> 2016/05/31 11:35:14.418 kid1| clientProcessHit: URL mismatch, 
>>>> '[unknown_URI]' != 'http://captive.apple.com/hotspot-detect.html'
>>>> 2016/05/31 11:35:14 kid2| Bug: Missing MemObject::storeId value
>>>> 2016/05/31 11:35:14 kid2| mem_hdr: 0x336b090 nodes.start() 0x2b136d0
>>>> 2016/05/31 11:35:14 kid2| mem_hdr: 0x336b090 nodes.finish() 0x82709c0
>>>> 2016/05/31 11:35:14 kid2| MemObject->start_ping: 0.000000
>>>> 2016/05/31 11:35:14 kid2| MemObject->inmem_hi: 4573
>>>> 2016/05/31 11:35:14 kid2| MemObject->inmem_lo: 0
>>>> 2016/05/31 11:35:14 kid2| MemObject->nclients: 0
>>>> 2016/05/31 11:35:14 kid2| MemObject->reply: 0x26bdf50
>>>> 2016/05/31 11:35:14 kid2| MemObject->request: 0
>>>> 2016/05/31 11:35:14 kid2| MemObject->logUri:
>>>> 2016/05/31 11:35:14 kid2| MemObject->storeId:
>>>>
>>>>
>>>> -- 
>>>> Best Regards,
>>>>
>>>> Heiler Bemerguy
>>>> Network Manager - CINBESA
>>>> 55 91 98151-4894/3184-1751
>>>>
>>>> Em 31/05/2016 11:14, Yuri escreveu:
>>>>> Without collapsed_forwarding seems ok:
>>>>>
>>>>> https://i1.someimage.com/E8pM9tu.png
>>>>>
>>>>> no warnings/errors in cache.log.
>>>>>
>>>>> Seems Heiler right.
>>>>>
>>>>> 31.05.2016 19:33, joe ?????:
>>>>>> load this link on both browser chrome  and firefox
>>>>>> 'http://js.statig.com.br/pub/adtags.js'
>>>>>> keep clicking reload  on both browser  and look at your cache.log
>>>>>> with or without collapsed_forwarding
>>>>>>
>>>>>>
>>>>>> Heiler Bemerguy wrote
>>>>>>> Yeah, I know. This kind of stuff only appeared after enabling
>>>>>>> collapsed_forwarding, I think. Now it's off again.. but I didn't 
>>>>>>> wipe
>>>>>>> the cache too, so I don't know.....
>>>>>>>
>>>>>>> 2016/05/31 10:50:24 kid2| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>> match on
>>>>>>> second attempt, 'http://js.statig.com.br/pub/adtags.js'
>>>>>>> 'accept-encoding="gzip,%20deflate"'
>>>>>>> 2016/05/31 10:50:24 kid2| clientProcessHit: Vary object loop!
>>>>>>> 2016/05/31 10:50:25 kid2| Bug: Missing MemObject::storeId value
>>>>>>> 2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.start() 
>>>>>>> 0x117e4ce0
>>>>>>> 2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.finish() 
>>>>>>> 0x117e4ce0
>>>>>>> 2016/05/31 10:50:25 kid2| MemObject->start_ping: 0.000000
>>>>>>> 2016/05/31 10:50:25 kid2| MemObject->inmem_hi: 2155
>>>>>>> 2016/05/31 10:50:25 kid2| MemObject->inmem_lo: 0
>>>>>>> 2016/05/31 10:50:25 kid2| MemObject->nclients: 0
>>>>>>> 2016/05/31 10:50:25 kid2| MemObject->reply: 0x7db9ce0
>>>>>>> 2016/05/31 10:50:25 kid2| MemObject->request: 0
>>>>>>> 2016/05/31 10:50:25 kid2| MemObject->logUri:
>>>>>>> 2016/05/31 10:50:25 kid2| MemObject->storeId:
>>>>>>>
>>>>>>>
>>>>>>> -- 
>>>>>>> Best Regards,
>>>>>>>
>>>>>>> Heiler Bemerguy
>>>>>>> Network Manager - CINBESA
>>>>>>> 55 91 98151-4894/3184-1751
>>>>>>>
>>>>>>>
>>>>>>> Em 31/05/2016 10:34, Yuri escreveu:
>>>>>>>> This is too expensive action. Cold out cache will decrease 
>>>>>>>> hit-ratio
>>>>>>>> for weeks.
>>>>>>>>
>>>>>>>>
>>>>>>>> Also, I suggest force reloading objects must overwrite stale 
>>>>>>>> cached, no?
>>>>>>>>
>>>>>>>>
>>>>>>>> 31.05.2016 19:32, Heiler Bemerguy ?????:
>>>>>>>>>
>>>>>>>>> I swear this bug was only rarely triggered without
>>>>>>>>> collapsed_forwarding enabled... but I think you'll have to 
>>>>>>>>> wipe your
>>>>>>>>> cache to really test it...
>>>>>>>>>
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> -- 
>>>>>>>>> Heiler Bemerguy - (91) 98151-4894
>>>>>>>>> Assessor T?cnico - CINBESA (91) 3184-1751
>>>>>>>>>
>>>>>>>>> Em 31/05/2016 08:00, Yuri escreveu:
>>>>>>>>>> Heh,
>>>>>>>>>>
>>>>>>>>>> the issue occurs also with disabled collapsed_forwarding:
>>>>>>>>>>
>>>>>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>>>> match
>>>>>>>>>> on second attempt,
>>>>>>>>>> 'https://ru.wikipedia.org/w/load.php?debug=false&lang=ru&modules=jquery.accessKeyLabel%2Cclient%7Cmediawiki.RegExp%2Cnotify%2Cutil%7Cmediawiki.legacy.wikibits&skin=vector&version=b5e9abd3b463' 
>>>>>>>>>>
>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
>>>>>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>>>>>> 2016/05/31 16:58:12 kid1| Error negotiating SSL on FD 260:
>>>>>>>>>> error:14090086:SSL 
>>>>>>>>>> routines:SSL3_GET_SERVER_CERTIFICATE:certificate
>>>>>>>>>> verify failed (1/-1/0)
>>>>>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>>>> match
>>>>>>>>>> on second attempt,
>>>>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Secure.js&action=raw&ctype=text/javascript' 
>>>>>>>>>>
>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>>>>
>>>>>>>>>> authorization'
>>>>>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>>>> match
>>>>>>>>>> on second attempt,
>>>>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Osm.js&action=raw&ctype=text/javascript' 
>>>>>>>>>>
>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>>>>
>>>>>>>>>> authorization'
>>>>>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>>>> match
>>>>>>>>>> on second attempt,
>>>>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Sidebar-related.js&action=raw&ctype=text/javascript' 
>>>>>>>>>>
>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>>>>
>>>>>>>>>> authorization'
>>>>>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>>>> match
>>>>>>>>>> on second attempt,
>>>>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript' 
>>>>>>>>>>
>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>>>>
>>>>>>>>>> authorization'
>>>>>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>>>> match
>>>>>>>>>> on second attempt,
>>>>>>>>>> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript' 
>>>>>>>>>>
>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>>>> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
>>>>>>>>>>
>>>>>>>>>> authorization'
>>>>>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a Vary 
>>>>>>>>>> match
>>>>>>>>>> on second attempt,
>>>>>>>>>> 'https://meta.wikimedia.org/w/index.php?title=MediaWiki:Wikiminiatlas.js&action=raw&ctype=text/javascript' 
>>>>>>>>>>
>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", cookie,
>>>>>>>>>> authorization'
>>>>>>>>>>
>>>>>>>>>> 3.5.19
>>>>>>>>>>
>>>>>>>>>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/637ff3ea/attachment.htm>

From yvoinov at gmail.com  Tue May 31 16:23:52 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 31 May 2016 22:23:52 +0600
Subject: [squid-users] Bug: Missing MemObject::storeId value
In-Reply-To: <e21161a5-eef9-7b10-e4a5-0222d0e6756c@cinbesa.com.br>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <c9f4b54a-7fd4-3355-a9cd-161b92e1ce15@cinbesa.com.br>
 <1464701636671-4677737.post@n4.nabble.com>
 <5d9049ba-b688-a22e-07d5-12b7da94dc8c@gmail.com>
 <931f91a3-51f4-6ff4-e781-4ed71964f527@cinbesa.com.br>
 <5cb41d75-387c-80af-fac6-e03a2570b0fa@gmail.com>
 <4fbad1c7-6a7f-b395-4824-08ec7add0a18@cinbesa.com.br>
 <6a67dd0e-80ae-ab5e-f353-2ec403ea6e75@gmail.com>
 <e21161a5-eef9-7b10-e4a5-0222d0e6756c@cinbesa.com.br>
Message-ID: <4f72c4ab-6262-a62e-956b-a2721b0a59b7@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
This proxy uses as peer for downstreams?


31.05.2016 21:09, Heiler Bemerguy ?????:
>
>
> I disabled ICP requests to it and these "Bug: Missing
MemObject::storeId value" messages stopped... any thoughts?
>
> Known bug?
>
> --
> Best Regards,
>
> Heiler Bemerguy
> Network Manager - CINBESA
> 55 91 98151-4894/3184-1751
>
>
> Em 31/05/2016 11:49, Yuri escreveu:
>>
>> Hm. Seems related. The objects not the same in memory yet.
>>
>>
>> 31.05.2016 20:45, Heiler Bemerguy ?????:
>>>
>>>
>>> Yep I know it should/would vanish all those "Vary objects"
messages.. but what are these other "Bug: Missing MemObject::storeId
value" ?? I thought it was related...
>>>
>>> 2016/05/31 11:43:27.594 kid2| clientProcessHit: URL mismatch,
'[unknown_URI]' !=
'http://www.agenciabelem.com.br/Resize/CreateThumbnail?path=/multimidiaSGN/galeria/69379/69379_213524.jpg&maxHeight=61&maxWidth=91'
>>> 2016/05/31 11:43:28.492 kid2| clientProcessHit: URL mismatch,
'[unknown_URI]' !=
'http://www.agenciabelem.com.br/Resize/CreateThumbnail?path=/MultimidiaSGN/galeria/69395/69395_213686.jpg&maxHeight=225&maxWidth=136'
>>> 2016/05/31 11:43:46 kid1| Bug: Missing MemObject::storeId value
>>> 2016/05/31 11:43:46 kid1| mem_hdr: 0x3efe990 nodes.start() 0x19b79ef0
>>> 2016/05/31 11:43:46 kid1| mem_hdr: 0x3efe990 nodes.finish() 0x19b79ef0
>>> 2016/05/31 11:43:46 kid1| MemObject->start_ping: 0.000000
>>> 2016/05/31 11:43:46 kid1| MemObject->inmem_hi: 193
>>> 2016/05/31 11:43:46 kid1| MemObject->inmem_lo: 0
>>> 2016/05/31 11:43:46 kid1| MemObject->nclients: 0
>>> 2016/05/31 11:43:46 kid1| MemObject->reply: 0x45656e0
>>> 2016/05/31 11:43:46 kid1| MemObject->request: 0
>>> 2016/05/31 11:43:46 kid1| MemObject->logUri:
>>> 2016/05/31 11:43:46 kid1| MemObject->storeId:
>>> 2016/05/31 11:43:46.569 kid2| clientProcessHit: URL mismatch,
'[unknown_URI]' != 'http://captive.apple.com/hotspot-detect.html'
>>> 2016/05/31 11:43:52 kid2| Bug: Missing MemObject::storeId value
>>> 2016/05/31 11:43:52 kid2| mem_hdr: 0x24eafe0 nodes.start() 0x7cac320
>>> 2016/05/31 11:43:52 kid2| mem_hdr: 0x24eafe0 nodes.finish() 0x5385350
>>> 2016/05/31 11:43:52 kid2| MemObject->start_ping: 0.000000
>>> 2016/05/31 11:43:52 kid2| MemObject->inmem_hi: 10455
>>> 2016/05/31 11:43:52 kid2| MemObject->inmem_lo: 0
>>> 2016/05/31 11:43:52 kid2| MemObject->nclients: 0
>>> 2016/05/31 11:43:52 kid2| MemObject->reply: 0x2970910
>>> 2016/05/31 11:43:52 kid2| MemObject->request: 0
>>> 2016/05/31 11:43:52 kid2| MemObject->logUri:
>>> 2016/05/31 11:43:52 kid2| MemObject->storeId:
>>> 2016/05/31 11:43:52.364 kid2| clientProcessHit: URL mismatch,
'[unknown_URI]' !=
'http://cdn-00-default.nativex.com/asset/d4c6dac2-76fd-4f91-9254-9708b603f097.css'
>>> 2016/05/31 11:43:52.364 kid2| Bug: Missing MemObject::storeId value
>>> 2016/05/31 11:43:52.364 kid2| mem_hdr: 0x264c000 nodes.start() 0x311ee90
>>> 2016/05/31 11:43:52.364 kid2| mem_hdr: 0x264c000 nodes.finish()
0x6e46250
>>> 2016/05/31 11:43:52.364 kid2| MemObject->start_ping: 0.000000
>>> 2016/05/31 11:43:52.364 kid2| MemObject->inmem_hi: 12244
>>> 2016/05/31 11:43:52.364 kid2| MemObject->inmem_lo: 0
>>> 2016/05/31 11:43:52.364 kid2| MemObject->nclients: 0
>>> 2016/05/31 11:43:52.364 kid2| MemObject->reply: 0x2233a30
>>> 2016/05/31 11:43:52.364 kid2| MemObject->request: 0
>>> 2016/05/31 11:43:52.364 kid2| MemObject->logUri:
>>> 2016/05/31 11:43:52.364 kid2| MemObject->storeId:
>>> 2016/05/31 11:43:52.390 kid2| clientProcessHit: URL mismatch,
'[unknown_URI]' !=
'http://cdn-00-default.nativex.com/asset/7b4133df-f0c8-4f2d-8532-2dcf6915577b.js'
>>> 2016/05/31 11:43:52 kid3| Bug: Missing MemObject::storeId value
>>> 2016/05/31 11:43:52 kid3| mem_hdr: 0x2ac67f0 nodes.start() 0x3f5d410
>>> 2016/05/31 11:43:52 kid3| mem_hdr: 0x2ac67f0 nodes.finish() 0x1c71fc0
>>> 2016/05/31 11:43:52 kid3| MemObject->start_ping: 0.000000
>>> 2016/05/31 11:43:52 kid3| MemObject->inmem_hi: 95355
>>> 2016/05/31 11:43:52 kid3| MemObject->inmem_lo: 0
>>> 2016/05/31 11:43:52 kid3| MemObject->nclients: 0
>>> 2016/05/31 11:43:52 kid3| MemObject->reply: 0x2972cc0
>>> 2016/05/31 11:43:52 kid3| MemObject->request: 0
>>> 2016/05/31 11:43:52 kid3| MemObject->logUri:
>>> 2016/05/31 11:43:52 kid3| MemObject->storeId:
>>>
>>> --
>>> Best Regards,
>>>
>>> Heiler Bemerguy
>>> Network Manager - CINBESA
>>> 55 91 98151-4894/3184-1751
>>>
>>> Em 31/05/2016 11:39, Yuri escreveu:
>>>>
>>>> Bad test. Problem is with swapped onto disk objects exactly. So,
when we disable cache_dirs, problem is gone.
>>>>
>>>>
>>>> 31.05.2016 20:36, Heiler Bemerguy ?????:
>>>>>
>>>>>
>>>>> Just did a test here.
>>>>>
>>>>> Disabled every cache_dir and fully restarted squid 3.5.19
>>>>>
>>>>> No more "vary object loop", but these continues:
>>>>>
>>>>> 2016/05/31 11:35:13 kid2| Bug: Missing MemObject::storeId value
>>>>> 2016/05/31 11:35:13 kid2| mem_hdr: 0x3177f40 nodes.start() 0x7370880
>>>>> 2016/05/31 11:35:13 kid2| mem_hdr: 0x3177f40 nodes.finish() 0x7370880
>>>>> 2016/05/31 11:35:13 kid2| MemObject->start_ping: 0.000000
>>>>> 2016/05/31 11:35:13 kid2| MemObject->inmem_hi: 2224
>>>>> 2016/05/31 11:35:13 kid2| MemObject->inmem_lo: 0
>>>>> 2016/05/31 11:35:13 kid2| MemObject->nclients: 0
>>>>> 2016/05/31 11:35:13 kid2| MemObject->reply: 0x29711e0
>>>>> 2016/05/31 11:35:13 kid2| MemObject->request: 0
>>>>> 2016/05/31 11:35:13 kid2| MemObject->logUri:
>>>>> 2016/05/31 11:35:13 kid2| MemObject->storeId:
>>>>> 2016/05/31 11:35:14 kid1| Bug: Missing MemObject::storeId value
>>>>> 2016/05/31 11:35:14 kid1| mem_hdr: 0x3e0d990 nodes.start() 0x1ca70540
>>>>> 2016/05/31 11:35:14 kid1| mem_hdr: 0x3e0d990 nodes.finish() 0x1ca70540
>>>>> 2016/05/31 11:35:14 kid1| MemObject->start_ping: 0.000000
>>>>> 2016/05/31 11:35:14 kid1| MemObject->inmem_hi: 193
>>>>> 2016/05/31 11:35:14 kid1| MemObject->inmem_lo: 0
>>>>> 2016/05/31 11:35:14 kid1| MemObject->nclients: 0
>>>>> 2016/05/31 11:35:14 kid1| MemObject->reply: 0x45656e0
>>>>> 2016/05/31 11:35:14 kid1| MemObject->request: 0
>>>>> 2016/05/31 11:35:14 kid1| MemObject->logUri:
>>>>> 2016/05/31 11:35:14 kid1| MemObject->storeId:
>>>>> 2016/05/31 11:35:14.418 kid1| clientProcessHit: URL mismatch,
'[unknown_URI]' != 'http://captive.apple.com/hotspot-detect.html'
>>>>> 2016/05/31 11:35:14 kid2| Bug: Missing MemObject::storeId value
>>>>> 2016/05/31 11:35:14 kid2| mem_hdr: 0x336b090 nodes.start() 0x2b136d0
>>>>> 2016/05/31 11:35:14 kid2| mem_hdr: 0x336b090 nodes.finish() 0x82709c0
>>>>> 2016/05/31 11:35:14 kid2| MemObject->start_ping: 0.000000
>>>>> 2016/05/31 11:35:14 kid2| MemObject->inmem_hi: 4573
>>>>> 2016/05/31 11:35:14 kid2| MemObject->inmem_lo: 0
>>>>> 2016/05/31 11:35:14 kid2| MemObject->nclients: 0
>>>>> 2016/05/31 11:35:14 kid2| MemObject->reply: 0x26bdf50
>>>>> 2016/05/31 11:35:14 kid2| MemObject->request: 0
>>>>> 2016/05/31 11:35:14 kid2| MemObject->logUri:
>>>>> 2016/05/31 11:35:14 kid2| MemObject->storeId:
>>>>>
>>>>>
>>>>> --
>>>>> Best Regards,
>>>>>
>>>>> Heiler Bemerguy
>>>>> Network Manager - CINBESA
>>>>> 55 91 98151-4894/3184-1751
>>>>>
>>>>> Em 31/05/2016 11:14, Yuri escreveu:
>>>>>> Without collapsed_forwarding seems ok:
>>>>>>
>>>>>> https://i1.someimage.com/E8pM9tu.png
>>>>>>
>>>>>> no warnings/errors in cache.log.
>>>>>>
>>>>>> Seems Heiler right.
>>>>>>
>>>>>> 31.05.2016 19:33, joe ?????:
>>>>>>> load this link on both browser    chrome  and firefox
>>>>>>> 'http://js.statig.com.br/pub/adtags.js'
>>>>>>> keep clicking reload  on both browser  and look at your cache.log
>>>>>>> with or without collapsed_forwarding
>>>>>>>
>>>>>>>
>>>>>>> Heiler Bemerguy wrote
>>>>>>>> Yeah, I know. This kind of stuff only appeared after enabling
>>>>>>>> collapsed_forwarding, I think. Now it's off again.. but I
didn't wipe
>>>>>>>> the cache too, so I don't know.....
>>>>>>>>
>>>>>>>> 2016/05/31 10:50:24 kid2| varyEvaluateMatch: Oops. Not a Vary
match on
>>>>>>>> second attempt, 'http://js.statig.com.br/pub/adtags.js'
>>>>>>>> 'accept-encoding="gzip,%20deflate"'
>>>>>>>> 2016/05/31 10:50:24 kid2| clientProcessHit: Vary object loop!
>>>>>>>> 2016/05/31 10:50:25 kid2| Bug: Missing MemObject::storeId value
>>>>>>>> 2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.start()
0x117e4ce0
>>>>>>>> 2016/05/31 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.finish()
0x117e4ce0
>>>>>>>> 2016/05/31 10:50:25 kid2| MemObject->start_ping: 0.000000
>>>>>>>> 2016/05/31 10:50:25 kid2| MemObject->inmem_hi: 2155
>>>>>>>> 2016/05/31 10:50:25 kid2| MemObject->inmem_lo: 0
>>>>>>>> 2016/05/31 10:50:25 kid2| MemObject->nclients: 0
>>>>>>>> 2016/05/31 10:50:25 kid2| MemObject->reply: 0x7db9ce0
>>>>>>>> 2016/05/31 10:50:25 kid2| MemObject->request: 0
>>>>>>>> 2016/05/31 10:50:25 kid2| MemObject->logUri:
>>>>>>>> 2016/05/31 10:50:25 kid2| MemObject->storeId:
>>>>>>>>
>>>>>>>>
>>>>>>>> --
>>>>>>>> Best Regards,
>>>>>>>>
>>>>>>>> Heiler Bemerguy
>>>>>>>> Network Manager - CINBESA
>>>>>>>> 55 91 98151-4894/3184-1751
>>>>>>>>
>>>>>>>>
>>>>>>>> Em 31/05/2016 10:34, Yuri escreveu:
>>>>>>>>> This is too expensive action. Cold out cache will decrease
hit-ratio
>>>>>>>>> for weeks.
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> Also, I suggest force reloading objects must overwrite stale
cached, no?
>>>>>>>>>
>>>>>>>>>
>>>>>>>>> 31.05.2016 19:32, Heiler Bemerguy ?????:
>>>>>>>>>>
>>>>>>>>>> I swear this bug was only rarely triggered without
>>>>>>>>>> collapsed_forwarding enabled... but I think you'll have to
wipe your
>>>>>>>>>> cache to really test it...
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>>
>>>>>>>>>> --
>>>>>>>>>> Heiler Bemerguy - (91) 98151-4894
>>>>>>>>>> Assessor T?cnico - CINBESA (91) 3184-1751
>>>>>>>>>>
>>>>>>>>>> Em 31/05/2016 08:00, Yuri escreveu:
>>>>>>>>>>> Heh,
>>>>>>>>>>>
>>>>>>>>>>> the issue occurs also with disabled collapsed_forwarding:
>>>>>>>>>>>
>>>>>>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a
Vary match
>>>>>>>>>>> on second attempt,
>>>>>>>>>>>
'https://ru.wikipedia.org/w/load.php?debug=false&lang=ru&modules=jquery.accessKeyLabel%2Cclient%7Cmediawiki.RegExp%2Cnotify%2Cutil%7Cmediawiki.legacy.wikibits&skin=vector&version=b5e9abd3b463'
>>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
>>>>>>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>>>>>>> 2016/05/31 16:58:12 kid1| Error negotiating SSL on FD 260:
>>>>>>>>>>> error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate
>>>>>>>>>>> verify failed (1/-1/0)
>>>>>>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a
Vary match
>>>>>>>>>>> on second attempt,
>>>>>>>>>>>
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Secure.js&action=raw&ctype=text/javascript'
>>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>>>>>
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
>>>>>>>>>>> authorization'
>>>>>>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: Oops. Not a
Vary match
>>>>>>>>>>> on second attempt,
>>>>>>>>>>>
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Osm.js&action=raw&ctype=text/javascript'
>>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>>>>>
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
>>>>>>>>>>> authorization'
>>>>>>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object loop!
>>>>>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a
Vary match
>>>>>>>>>>> on second attempt,
>>>>>>>>>>>
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Sidebar-related.js&action=raw&ctype=text/javascript'
>>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>>>>>
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
>>>>>>>>>>> authorization'
>>>>>>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a
Vary match
>>>>>>>>>>> on second attempt,
>>>>>>>>>>>
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript'
>>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>>>>>
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
>>>>>>>>>>> authorization'
>>>>>>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a
Vary match
>>>>>>>>>>> on second attempt,
>>>>>>>>>>>
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript'
>>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>>>>>>>>>>>
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
>>>>>>>>>>> authorization'
>>>>>>>>>>> 2016/05/31 16:58:13 kid1| clientProcessHit: Vary object loop!
>>>>>>>>>>> 2016/05/31 16:58:13 kid1| varyEvaluateMatch: Oops. Not a
Vary match
>>>>>>>>>>> on second attempt,
>>>>>>>>>>>
'https://meta.wikimedia.org/w/index.php?title=MediaWiki:Wikiminiatlas.js&action=raw&ctype=text/javascript'
>>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", cookie,
>>>>>>>>>>> authorization'
>>>>>>>>>>>
>>>>>>>>>>> 3.5.19
>>>>>>>>>>>
>>>>>>>>>>>
>>> 
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXTbqXAAoJENNXIZxhPexGBUkH/28v8MSQP+ud24DsiMnOcOYW
1+/bz42zvnVgGBo092Th7i3ZZObCKmZ3St7wuWQPgFbVP3qoyEZYKumvK+P5+78w
YfuOWge8SG1yVwmPbQ8ge0Oq4/I19HcapFZXnHzEqN8/TbOtm04iTaaPiiKinsnq
KLpb0t9kdrTQgMZudjoDCg5y3kwGkYAMl39pAotFe2GgrBLWrP14/WTbrbmiT88a
bBD2rCjM9H2168q26AzKR/+u85gLvF6YYtN4xLn2/ahwmwu7Ak8hsJko+PeTxIeA
ae3g27/a/cQdch3GtjuDcMl8pmEk8U8rKRcHmQ63i1la3n+08FPjJcYJ2UzWAbM=
=VcAB
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/483dcf49/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/483dcf49/attachment.key>

From heiler.bemerguy at cinbesa.com.br  Tue May 31 16:36:00 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 31 May 2016 13:36:00 -0300
Subject: [squid-users] Bug: Missing MemObject::storeId value
In-Reply-To: <4f72c4ab-6262-a62e-956b-a2721b0a59b7@gmail.com>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <c9f4b54a-7fd4-3355-a9cd-161b92e1ce15@cinbesa.com.br>
 <1464701636671-4677737.post@n4.nabble.com>
 <5d9049ba-b688-a22e-07d5-12b7da94dc8c@gmail.com>
 <931f91a3-51f4-6ff4-e781-4ed71964f527@cinbesa.com.br>
 <5cb41d75-387c-80af-fac6-e03a2570b0fa@gmail.com>
 <4fbad1c7-6a7f-b395-4824-08ec7add0a18@cinbesa.com.br>
 <6a67dd0e-80ae-ab5e-f353-2ec403ea6e75@gmail.com>
 <e21161a5-eef9-7b10-e4a5-0222d0e6756c@cinbesa.com.br>
 <4f72c4ab-6262-a62e-956b-a2721b0a59b7@gmail.com>
Message-ID: <e4d31056-6099-205e-06b4-80dd001fdcd8@cinbesa.com.br>


This is the parent proxy of another one (10.1.10.101).

It was receiveing requests like these:

1464665138.326      0 10.1.10.101 UDP_MISS/000 72 ICP_QUERY 
http://img.olx.com.br/thumbs/51/517630000636766.jpg - HIER_NONE/- -
1464665138.331      0 10.1.10.101 UDP_MISS/000 72 ICP_QUERY 
http://img.olx.com.br/thumbs/51/515630006195751.jpg - HIER_NONE/- -
1464665138.400     68 10.1.10.101 TCP_MISS/200 2439 GET 
http://img.olx.com.br/thumbs/51/515630006195751.jpg - 
HIER_DIRECT/54.192.57.169 image/jpeg
1464665138.404     86 10.1.10.101 TCP_MISS/200 2221 GET 
http://img.olx.com.br/thumbs/51/518630004436306.jpg - 
HIER_DIRECT/54.192.57.169 image/jpeg


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751


Em 31/05/2016 13:23, Yuri Voinov escreveu:
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> This proxy uses as peer for downstreams?
>
>
> 31.05.2016 21:09, Heiler Bemerguy ?????:
> > > > I disabled ICP requests to it and these "Bug: Missing 
> MemObject::storeId value" messages stopped... any thoughts? > > Known 
> bug? > > -- > Best Regards, > > Heiler Bemerguy > Network Manager - 
> CINBESA > 55 91 98151-4894/3184-1751 > > > Em 31/05/2016 11:49, Yuri 
> escreveu: >> >> Hm. Seems related. The objects not the same in memory 
> yet. >> >> >> 31.05.2016 20:45, Heiler Bemerguy ?????: >>> >>> >>> Yep 
> I know it should/would vanish all those "Vary objects" messages.. but 
> what are these other "Bug: Missing MemObject::storeId value" ?? I 
> thought it was related... >>> >>> 2016/05/31 11:43:27.594 kid2| 
> clientProcessHit: URL mismatch, '[unknown_URI]' != 
> 'http://www.agenciabelem.com.br/Resize/CreateThumbnail?path=/multimidiaSGN/galeria/69379/69379_213524.jpg&maxHeight=61&maxWidth=91' 
> >>> 2016/05/31 11:43:28.492 kid2| clientProcessHit: URL mismatch, 
> '[unknown_URI]' != 
> 'http://www.agenciabelem.com.br/Resize/CreateThumbnail?path=/MultimidiaSGN/galeria/69395/69395_213686.jpg&maxHeight=225&maxWidth=136' 
> >>> 2016/05/31 11:43:46 kid1| Bug: Missing MemObject::storeId value 
> >>> 2016/05/31 11:43:46 kid1| mem_hdr: 0x3efe990 nodes.start() 
> 0x19b79ef0 >>> 2016/05/31 11:43:46 kid1| mem_hdr: 0x3efe990 
> nodes.finish() 0x19b79ef0 >>> 2016/05/31 11:43:46 kid1| 
> MemObject->start_ping: 0.000000 >>> 2016/05/31 11:43:46 kid1| 
> MemObject->inmem_hi: 193 >>> 2016/05/31 11:43:46 kid1| 
> MemObject->inmem_lo: 0 >>> 2016/05/31 11:43:46 kid1| 
> MemObject->nclients: 0 >>> 2016/05/31 11:43:46 kid1| MemObject->reply: 
> 0x45656e0 >>> 2016/05/31 11:43:46 kid1| MemObject->request: 0 >>> 
> 2016/05/31 11:43:46 kid1| MemObject->logUri: >>> 2016/05/31 11:43:46 
> kid1| MemObject->storeId: >>> 2016/05/31 11:43:46.569 kid2| 
> clientProcessHit: URL mismatch, '[unknown_URI]' != 
> 'http://captive.apple.com/hotspot-detect.html' >>> 2016/05/31 11:43:52 
> kid2| Bug: Missing MemObject::storeId value >>> 2016/05/31 11:43:52 
> kid2| mem_hdr: 0x24eafe0 nodes.start() 0x7cac320 >>> 2016/05/31 
> 11:43:52 kid2| mem_hdr: 0x24eafe0 nodes.finish() 0x5385350 >>> 
> 2016/05/31 11:43:52 kid2| MemObject->start_ping: 0.000000 >>> 
> 2016/05/31 11:43:52 kid2| MemObject->inmem_hi: 10455 >>> 2016/05/31 
> 11:43:52 kid2| MemObject->inmem_lo: 0 >>> 2016/05/31 11:43:52 kid2| 
> MemObject->nclients: 0 >>> 2016/05/31 11:43:52 kid2| MemObject->reply: 
> 0x2970910 >>> 2016/05/31 11:43:52 kid2| MemObject->request: 0 >>> 
> 2016/05/31 11:43:52 kid2| MemObject->logUri: >>> 2016/05/31 11:43:52 
> kid2| MemObject->storeId: >>> 2016/05/31 11:43:52.364 kid2| 
> clientProcessHit: URL mismatch, '[unknown_URI]' != 
> 'http://cdn-00-default.nativex.com/asset/d4c6dac2-76fd-4f91-9254-9708b603f097.css' 
> >>> 2016/05/31 11:43:52.364 kid2| Bug: Missing MemObject::storeId 
> value >>> 2016/05/31 11:43:52.364 kid2| mem_hdr: 0x264c000 
> nodes.start() 0x311ee90 >>> 2016/05/31 11:43:52.364 kid2| mem_hdr: 
> 0x264c000 nodes.finish() 0x6e46250 >>> 2016/05/31 11:43:52.364 kid2| 
> MemObject->start_ping: 0.000000 >>> 2016/05/31 11:43:52.364 kid2| 
> MemObject->inmem_hi: 12244 >>> 2016/05/31 11:43:52.364 kid2| 
> MemObject->inmem_lo: 0 >>> 2016/05/31 11:43:52.364 kid2| 
> MemObject->nclients: 0 >>> 2016/05/31 11:43:52.364 kid2| 
> MemObject->reply: 0x2233a30 >>> 2016/05/31 11:43:52.364 kid2| 
> MemObject->request: 0 >>> 2016/05/31 11:43:52.364 kid2| 
> MemObject->logUri: >>> 2016/05/31 11:43:52.364 kid2| 
> MemObject->storeId: >>> 2016/05/31 11:43:52.390 kid2| 
> clientProcessHit: URL mismatch, '[unknown_URI]' != 
> 'http://cdn-00-default.nativex.com/asset/7b4133df-f0c8-4f2d-8532-2dcf6915577b.js' 
> >>> 2016/05/31 11:43:52 kid3| Bug: Missing MemObject::storeId value 
> >>> 2016/05/31 11:43:52 kid3| mem_hdr: 0x2ac67f0 nodes.start() 
> 0x3f5d410 >>> 2016/05/31 11:43:52 kid3| mem_hdr: 0x2ac67f0 
> nodes.finish() 0x1c71fc0 >>> 2016/05/31 11:43:52 kid3| 
> MemObject->start_ping: 0.000000 >>> 2016/05/31 11:43:52 kid3| 
> MemObject->inmem_hi: 95355 >>> 2016/05/31 11:43:52 kid3| 
> MemObject->inmem_lo: 0 >>> 2016/05/31 11:43:52 kid3| 
> MemObject->nclients: 0 >>> 2016/05/31 11:43:52 kid3| MemObject->reply: 
> 0x2972cc0 >>> 2016/05/31 11:43:52 kid3| MemObject->request: 0 >>> 
> 2016/05/31 11:43:52 kid3| MemObject->logUri: >>> 2016/05/31 11:43:52 
> kid3| MemObject->storeId: >>> >>> -- >>> Best Regards, >>> >>> Heiler 
> Bemerguy >>> Network Manager - CINBESA >>> 55 91 98151-4894/3184-1751 
> >>> >>> Em 31/05/2016 11:39, Yuri escreveu: >>>> >>>> Bad test. 
> Problem is with swapped onto disk objects exactly. So, when we disable 
> cache_dirs, problem is gone. >>>> >>>> >>>> 31.05.2016 20:36, Heiler 
> Bemerguy ?????: >>>>> >>>>> >>>>> Just did a test here. >>>>> >>>>> 
> Disabled every cache_dir and fully restarted squid 3.5.19 >>>>> >>>>> 
> No more "vary object loop", but these continues: >>>>> >>>>> 
> 2016/05/31 11:35:13 kid2| Bug: Missing MemObject::storeId value >>>>> 
> 2016/05/31 11:35:13 kid2| mem_hdr: 0x3177f40 nodes.start() 0x7370880 
> >>>>> 2016/05/31 11:35:13 kid2| mem_hdr: 0x3177f40 nodes.finish() 
> 0x7370880 >>>>> 2016/05/31 11:35:13 kid2| MemObject->start_ping: 
> 0.000000 >>>>> 2016/05/31 11:35:13 kid2| MemObject->inmem_hi: 2224 
> >>>>> 2016/05/31 11:35:13 kid2| MemObject->inmem_lo: 0 >>>>> 
> 2016/05/31 11:35:13 kid2| MemObject->nclients: 0 >>>>> 2016/05/31 
> 11:35:13 kid2| MemObject->reply: 0x29711e0 >>>>> 2016/05/31 11:35:13 
> kid2| MemObject->request: 0 >>>>> 2016/05/31 11:35:13 kid2| 
> MemObject->logUri: >>>>> 2016/05/31 11:35:13 kid2| MemObject->storeId: 
> >>>>> 2016/05/31 11:35:14 kid1| Bug: Missing MemObject::storeId value 
> >>>>> 2016/05/31 11:35:14 kid1| mem_hdr: 0x3e0d990 nodes.start() 
> 0x1ca70540 >>>>> 2016/05/31 11:35:14 kid1| mem_hdr: 0x3e0d990 
> nodes.finish() 0x1ca70540 >>>>> 2016/05/31 11:35:14 kid1| 
> MemObject->start_ping: 0.000000 >>>>> 2016/05/31 11:35:14 kid1| 
> MemObject->inmem_hi: 193 >>>>> 2016/05/31 11:35:14 kid1| 
> MemObject->inmem_lo: 0 >>>>> 2016/05/31 11:35:14 kid1| 
> MemObject->nclients: 0 >>>>> 2016/05/31 11:35:14 kid1| 
> MemObject->reply: 0x45656e0 >>>>> 2016/05/31 11:35:14 kid1| 
> MemObject->request: 0 >>>>> 2016/05/31 11:35:14 kid1| 
> MemObject->logUri: >>>>> 2016/05/31 11:35:14 kid1| MemObject->storeId: 
> >>>>> 2016/05/31 11:35:14.418 kid1| clientProcessHit: URL mismatch, 
> '[unknown_URI]' != 'http://captive.apple.com/hotspot-detect.html' 
> >>>>> 2016/05/31 11:35:14 kid2| Bug: Missing MemObject::storeId value 
> >>>>> 2016/05/31 11:35:14 kid2| mem_hdr: 0x336b090 nodes.start() 
> 0x2b136d0 >>>>> 2016/05/31 11:35:14 kid2| mem_hdr: 0x336b090 
> nodes.finish() 0x82709c0 >>>>> 2016/05/31 11:35:14 kid2| 
> MemObject->start_ping: 0.000000 >>>>> 2016/05/31 11:35:14 kid2| 
> MemObject->inmem_hi: 4573 >>>>> 2016/05/31 11:35:14 kid2| 
> MemObject->inmem_lo: 0 >>>>> 2016/05/31 11:35:14 kid2| 
> MemObject->nclients: 0 >>>>> 2016/05/31 11:35:14 kid2| 
> MemObject->reply: 0x26bdf50 >>>>> 2016/05/31 11:35:14 kid2| 
> MemObject->request: 0 >>>>> 2016/05/31 11:35:14 kid2| 
> MemObject->logUri: >>>>> 2016/05/31 11:35:14 kid2| MemObject->storeId: 
> >>>>> >>>>> >>>>> -- >>>>> Best Regards, >>>>> >>>>> Heiler Bemerguy 
> >>>>> Network Manager - CINBESA >>>>> 55 91 98151-4894/3184-1751 >>>>> 
> >>>>> Em 31/05/2016 11:14, Yuri escreveu: >>>>>> Without 
> collapsed_forwarding seems ok: >>>>>> >>>>>> 
> https://i1.someimage.com/E8pM9tu.png >>>>>> >>>>>> no warnings/errors 
> in cache.log. >>>>>> >>>>>> Seems Heiler right. >>>>>> >>>>>> 
> 31.05.2016 19:33, joe ?????: >>>>>>> load this link on both browser 
> chrome  and firefox >>>>>>> 'http://js.statig.com.br/pub/adtags.js' 
> >>>>>>> keep clicking reload  on both browser  and look at your 
> cache.log >>>>>>> with or without collapsed_forwarding >>>>>>> >>>>>>> 
> >>>>>>> Heiler Bemerguy wrote >>>>>>>> Yeah, I know. This kind of 
> stuff only appeared after enabling >>>>>>>> collapsed_forwarding, I 
> think. Now it's off again.. but I didn't wipe >>>>>>>> the cache too, 
> so I don't know..... >>>>>>>> >>>>>>>> 2016/05/31 10:50:24 kid2| 
> varyEvaluateMatch: Oops. Not a Vary match on >>>>>>>> second attempt, 
> 'http://js.statig.com.br/pub/adtags.js' >>>>>>>> 
> 'accept-encoding="gzip,%20deflate"' >>>>>>>> 2016/05/31 10:50:24 kid2| 
> clientProcessHit: Vary object loop! >>>>>>>> 2016/05/31 10:50:25 kid2| 
> Bug: Missing MemObject::storeId value >>>>>>>> 2016/05/31 10:50:25 
> kid2| mem_hdr: 0x20573e10 nodes.start() 0x117e4ce0 >>>>>>>> 2016/05/31 
> 10:50:25 kid2| mem_hdr: 0x20573e10 nodes.finish() 0x117e4ce0 >>>>>>>> 
> 2016/05/31 10:50:25 kid2| MemObject->start_ping: 0.000000 >>>>>>>> 
> 2016/05/31 10:50:25 kid2| MemObject->inmem_hi: 2155 >>>>>>>> 
> 2016/05/31 10:50:25 kid2| MemObject->inmem_lo: 0 >>>>>>>> 2016/05/31 
> 10:50:25 kid2| MemObject->nclients: 0 >>>>>>>> 2016/05/31 10:50:25 
> kid2| MemObject->reply: 0x7db9ce0 >>>>>>>> 2016/05/31 10:50:25 kid2| 
> MemObject->request: 0 >>>>>>>> 2016/05/31 10:50:25 kid2| 
> MemObject->logUri: >>>>>>>> 2016/05/31 10:50:25 kid2| 
> MemObject->storeId: >>>>>>>> >>>>>>>> >>>>>>>> -- >>>>>>>> Best 
> Regards, >>>>>>>> >>>>>>>> Heiler Bemerguy >>>>>>>> Network Manager - 
> CINBESA >>>>>>>> 55 91 98151-4894/3184-1751 >>>>>>>> >>>>>>>> >>>>>>>> 
> Em 31/05/2016 10:34, Yuri escreveu: >>>>>>>>> This is too expensive 
> action. Cold out cache will decrease hit-ratio >>>>>>>>> for weeks. 
> >>>>>>>>> >>>>>>>>> >>>>>>>>> Also, I suggest force reloading objects 
> must overwrite stale cached, no? >>>>>>>>> >>>>>>>>> >>>>>>>>> 
> 31.05.2016 19:32, Heiler Bemerguy ?????: >>>>>>>>>> >>>>>>>>>> I swear 
> this bug was only rarely triggered without >>>>>>>>>> 
> collapsed_forwarding enabled... but I think you'll have to wipe your 
> >>>>>>>>>> cache to really test it... >>>>>>>>>> >>>>>>>>>> >>>>>>>>>> 
> >>>>>>>>>> -- >>>>>>>>>> Heiler Bemerguy - (91) 98151-4894 >>>>>>>>>> 
> Assessor T?cnico - CINBESA (91) 3184-1751 >>>>>>>>>> >>>>>>>>>> Em 
> 31/05/2016 08:00, Yuri escreveu: >>>>>>>>>>> Heh, >>>>>>>>>>> 
> >>>>>>>>>>> the issue occurs also with disabled collapsed_forwarding: 
> >>>>>>>>>>> >>>>>>>>>>> 2016/05/31 16:58:12 kid1| varyEvaluateMatch: 
> Oops. Not a Vary match >>>>>>>>>>> on second attempt, >>>>>>>>>>> 
> 'https://ru.wikipedia.org/w/load.php?debug=false&lang=ru&modules=jquery.accessKeyLabel%2Cclient%7Cmediawiki.RegExp%2Cnotify%2Cutil%7Cmediawiki.legacy.wikibits&skin=vector&version=b5e9abd3b463' 
> >>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br"' 
> >>>>>>>>>>> 2016/05/31 16:58:12 kid1| clientProcessHit: Vary object 
> loop! >>>>>>>>>>> 2016/05/31 16:58:12 kid1| Error negotiating SSL on 
> FD 260: >>>>>>>>>>> error:14090086:SSL 
> routines:SSL3_GET_SERVER_CERTIFICATE:certificate >>>>>>>>>>> verify 
> failed (1/-1/0) >>>>>>>>>>> 2016/05/31 16:58:12 kid1| 
> varyEvaluateMatch: Oops. Not a Vary match >>>>>>>>>>> on second 
> attempt, >>>>>>>>>>> 
> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Secure.js&action=raw&ctype=text/javascript' 
> >>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
> >>>>>>>>>>> 
> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
> >>>>>>>>>>> authorization' >>>>>>>>>>> 2016/05/31 16:58:12 kid1| 
> clientProcessHit: Vary object loop! >>>>>>>>>>> 2016/05/31 16:58:12 
> kid1| varyEvaluateMatch: Oops. Not a Vary match >>>>>>>>>>> on second 
> attempt, >>>>>>>>>>> 
> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Osm.js&action=raw&ctype=text/javascript' 
> >>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
> >>>>>>>>>>> 
> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
> >>>>>>>>>>> authorization' >>>>>>>>>>> 2016/05/31 16:58:12 kid1| 
> clientProcessHit: Vary object loop! >>>>>>>>>>> 2016/05/31 16:58:13 
> kid1| varyEvaluateMatch: Oops. Not a Vary match >>>>>>>>>>> on second 
> attempt, >>>>>>>>>>> 
> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Sidebar-related.js&action=raw&ctype=text/javascript' 
> >>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
> >>>>>>>>>>> 
> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
> >>>>>>>>>>> authorization' >>>>>>>>>>> 2016/05/31 16:58:13 kid1| 
> clientProcessHit: Vary object loop! >>>>>>>>>>> 2016/05/31 16:58:13 
> kid1| varyEvaluateMatch: Oops. Not a Vary match >>>>>>>>>>> on second 
> attempt, >>>>>>>>>>> 
> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript' 
> >>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
> >>>>>>>>>>> 
> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
> >>>>>>>>>>> authorization' >>>>>>>>>>> 2016/05/31 16:58:13 kid1| 
> clientProcessHit: Vary object loop! >>>>>>>>>>> 2016/05/31 16:58:13 
> kid1| varyEvaluateMatch: Oops. Not a Vary match >>>>>>>>>>> on second 
> attempt, >>>>>>>>>>> 
> 'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript' 
> >>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", 
> >>>>>>>>>>> 
> cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4", 
> >>>>>>>>>>> authorization' >>>>>>>>>>> 2016/05/31 16:58:13 kid1| 
> clientProcessHit: Vary object loop! >>>>>>>>>>> 2016/05/31 16:58:13 
> kid1| varyEvaluateMatch: Oops. Not a Vary match >>>>>>>>>>> on second 
> attempt, >>>>>>>>>>> 
> 'https://meta.wikimedia.org/w/index.php?title=MediaWiki:Wikiminiatlas.js&action=raw&ctype=text/javascript' 
> >>>>>>>>>>> 'accept-encoding="gzip,%20deflate,%20sdch,%20br", cookie, 
> >>>>>>>>>>> authorization' >>>>>>>>>>> >>>>>>>>>>> 3.5.19 >>>>>>>>>>> 
> >>>>>>>>>>> >>> >>> >>> >>> 
> _______________________________________________ >>> squid-users 
> mailing list >>> squid-users at lists.squid-cache.org >>> 
> http://lists.squid-cache.org/listinfo/squid-users >> >> >> >> 
> _______________________________________________ >> squid-users mailing 
> list >> squid-users at lists.squid-cache.org >> 
> http://lists.squid-cache.org/listinfo/squid-users > > > > 
> _______________________________________________ > squid-users mailing 
> list > squid-users at lists.squid-cache.org > 
> http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJXTbqXAAoJENNXIZxhPexGBUkH/28v8MSQP+ud24DsiMnOcOYW
> 1+/bz42zvnVgGBo092Th7i3ZZObCKmZ3St7wuWQPgFbVP3qoyEZYKumvK+P5+78w
> YfuOWge8SG1yVwmPbQ8ge0Oq4/I19HcapFZXnHzEqN8/TbOtm04iTaaPiiKinsnq
> KLpb0t9kdrTQgMZudjoDCg5y3kwGkYAMl39pAotFe2GgrBLWrP14/WTbrbmiT88a
> bBD2rCjM9H2168q26AzKR/+u85gLvF6YYtN4xLn2/ahwmwu7Ak8hsJko+PeTxIeA
> ae3g27/a/cQdch3GtjuDcMl8pmEk8U8rKRcHmQ63i1la3n+08FPjJcYJ2UzWAbM=
> =VcAB
> -----END PGP SIGNATURE-----
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/bdf61d53/attachment.htm>

From yvoinov at gmail.com  Tue May 31 16:37:27 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 31 May 2016 22:37:27 +0600
Subject: [squid-users] Bug: Missing MemObject::storeId value
In-Reply-To: <e4d31056-6099-205e-06b4-80dd001fdcd8@cinbesa.com.br>
References: <c97dcc8e-6a05-351c-2d0e-17a200e9c99e@gmail.com>
 <1464628594081-4677722.post@n4.nabble.com>
 <6f98c15e-c44b-df4d-fed3-b2d144c3a4fd@gmail.com>
 <1464680093592-4677725.post@n4.nabble.com>
 <e32c9d2d-f04c-a428-e9a6-56ef0ee2ae17@gmail.com>
 <25d7134c-f500-0362-f814-50771964f09e@cinbesa.com.br>
 <70f298ce-d41a-d7f3-8212-bc248234cf07@gmail.com>
 <c9f4b54a-7fd4-3355-a9cd-161b92e1ce15@cinbesa.com.br>
 <1464701636671-4677737.post@n4.nabble.com>
 <5d9049ba-b688-a22e-07d5-12b7da94dc8c@gmail.com>
 <931f91a3-51f4-6ff4-e781-4ed71964f527@cinbesa.com.br>
 <5cb41d75-387c-80af-fac6-e03a2570b0fa@gmail.com>
 <4fbad1c7-6a7f-b395-4824-08ec7add0a18@cinbesa.com.br>
 <6a67dd0e-80ae-ab5e-f353-2ec403ea6e75@gmail.com>
 <e21161a5-eef9-7b10-e4a5-0222d0e6756c@cinbesa.com.br>
 <4f72c4ab-6262-a62e-956b-a2721b0a59b7@gmail.com>
 <e4d31056-6099-205e-06b4-80dd001fdcd8@cinbesa.com.br>
Message-ID: <589ce230-e374-b8f5-ab9a-647239554ec0@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Aha,

for cached objects no matter HTTP or ICP query requested they.

31.05.2016 22:36, Heiler Bemerguy ?????:
>
>
> This is the parent proxy of another one (10.1.10.101).
>
> It was receiveing requests like these:
>
> 1464665138.326      0 10.1.10.101 UDP_MISS/000 72 ICP_QUERY
http://img.olx.com.br/thumbs/51/517630000636766.jpg - HIER_NONE/- -
> 1464665138.331      0 10.1.10.101 UDP_MISS/000 72 ICP_QUERY
http://img.olx.com.br/thumbs/51/515630006195751.jpg - HIER_NONE/- -
> 1464665138.400     68 10.1.10.101 TCP_MISS/200 2439 GET
http://img.olx.com.br/thumbs/51/515630006195751.jpg -
HIER_DIRECT/54.192.57.169 image/jpeg
> 1464665138.404     86 10.1.10.101 TCP_MISS/200 2221 GET
http://img.olx.com.br/thumbs/51/518630004436306.jpg -
HIER_DIRECT/54.192.57.169 image/jpeg
>
>
> --
> Best Regards,
>
> Heiler Bemerguy
> Network Manager - CINBESA
> 55 91 98151-4894/3184-1751
>
> Em 31/05/2016 13:23, Yuri Voinov escreveu:
>>
> This proxy uses as peer for downstreams?
>
>
> 31.05.2016 21:09, Heiler Bemerguy ?????:
>
>
>
>
>       > I disabled ICP requests to it and these "Bug: Missing
>       MemObject::storeId value" messages stopped... any thoughts?
>
>
>
>       > Known bug?
>
>
>
>       > --
>
>       > Best Regards,
>
>
>
>       > Heiler Bemerguy
>
>       > Network Manager - CINBESA
>
>       > 55 91 98151-4894/3184-1751
>
>
>
>
>
>       > Em 31/05/2016 11:49, Yuri escreveu:
>
>       >>
>
>       >> Hm. Seems related. The objects not the same in memory
>       yet.
>
>       >>
>
>       >>
>
>       >> 31.05.2016 20:45, Heiler Bemerguy ?????:
>
>       >>>
>
>       >>>
>
>       >>> Yep I know it should/would vanish all those "Vary
>       objects" messages.. but what are these other "Bug: Missing
>       MemObject::storeId value" ?? I thought it was related...
>
>       >>>
>
>       >>> 2016/05/31 11:43:27.594 kid2| clientProcessHit: URL
>       mismatch, '[unknown_URI]' !=
>
'http://www.agenciabelem.com.br/Resize/CreateThumbnail?path=/multimidiaSGN/galeria/69379/69379_213524.jpg&maxHeight=61&maxWidth=91'
>
>       >>> 2016/05/31 11:43:28.492 kid2| clientProcessHit: URL
>       mismatch, '[unknown_URI]' !=
>
'http://www.agenciabelem.com.br/Resize/CreateThumbnail?path=/MultimidiaSGN/galeria/69395/69395_213686.jpg&maxHeight=225&maxWidth=136'
>
>       >>> 2016/05/31 11:43:46 kid1| Bug: Missing
>       MemObject::storeId value
>
>       >>> 2016/05/31 11:43:46 kid1| mem_hdr: 0x3efe990
>       nodes.start() 0x19b79ef0
>
>       >>> 2016/05/31 11:43:46 kid1| mem_hdr: 0x3efe990
>       nodes.finish() 0x19b79ef0
>
>       >>> 2016/05/31 11:43:46 kid1| MemObject->start_ping:
>       0.000000
>
>       >>> 2016/05/31 11:43:46 kid1| MemObject->inmem_hi: 193
>
>       >>> 2016/05/31 11:43:46 kid1| MemObject->inmem_lo: 0
>
>       >>> 2016/05/31 11:43:46 kid1| MemObject->nclients: 0
>
>       >>> 2016/05/31 11:43:46 kid1| MemObject->reply:
>       0x45656e0
>
>       >>> 2016/05/31 11:43:46 kid1| MemObject->request: 0
>
>       >>> 2016/05/31 11:43:46 kid1| MemObject->logUri:
>
>       >>> 2016/05/31 11:43:46 kid1| MemObject->storeId:
>
>       >>> 2016/05/31 11:43:46.569 kid2| clientProcessHit: URL
>       mismatch, '[unknown_URI]' !=
>       'http://captive.apple.com/hotspot-detect.html'
>
>       >>> 2016/05/31 11:43:52 kid2| Bug: Missing
>       MemObject::storeId value
>
>       >>> 2016/05/31 11:43:52 kid2| mem_hdr: 0x24eafe0
>       nodes.start() 0x7cac320
>
>       >>> 2016/05/31 11:43:52 kid2| mem_hdr: 0x24eafe0
>       nodes.finish() 0x5385350
>
>       >>> 2016/05/31 11:43:52 kid2| MemObject->start_ping:
>       0.000000
>
>       >>> 2016/05/31 11:43:52 kid2| MemObject->inmem_hi:
>       10455
>
>       >>> 2016/05/31 11:43:52 kid2| MemObject->inmem_lo: 0
>
>       >>> 2016/05/31 11:43:52 kid2| MemObject->nclients: 0
>
>       >>> 2016/05/31 11:43:52 kid2| MemObject->reply:
>       0x2970910
>
>       >>> 2016/05/31 11:43:52 kid2| MemObject->request: 0
>
>       >>> 2016/05/31 11:43:52 kid2| MemObject->logUri:
>
>       >>> 2016/05/31 11:43:52 kid2| MemObject->storeId:
>
>       >>> 2016/05/31 11:43:52.364 kid2| clientProcessHit: URL
>       mismatch, '[unknown_URI]' !=
>
'http://cdn-00-default.nativex.com/asset/d4c6dac2-76fd-4f91-9254-9708b603f097.css'
>
>       >>> 2016/05/31 11:43:52.364 kid2| Bug: Missing
>       MemObject::storeId value
>
>       >>> 2016/05/31 11:43:52.364 kid2| mem_hdr: 0x264c000
>       nodes.start() 0x311ee90
>
>       >>> 2016/05/31 11:43:52.364 kid2| mem_hdr: 0x264c000
>       nodes.finish() 0x6e46250
>
>       >>> 2016/05/31 11:43:52.364 kid2|
>       MemObject->start_ping: 0.000000
>
>       >>> 2016/05/31 11:43:52.364 kid2| MemObject->inmem_hi:
>       12244
>
>       >>> 2016/05/31 11:43:52.364 kid2| MemObject->inmem_lo:
>       0
>
>       >>> 2016/05/31 11:43:52.364 kid2| MemObject->nclients:
>       0
>
>       >>> 2016/05/31 11:43:52.364 kid2| MemObject->reply:
>       0x2233a30
>
>       >>> 2016/05/31 11:43:52.364 kid2| MemObject->request:
>       0
>
>       >>> 2016/05/31 11:43:52.364 kid2| MemObject->logUri:
>
>       >>> 2016/05/31 11:43:52.364 kid2| MemObject->storeId:
>
>       >>> 2016/05/31 11:43:52.390 kid2| clientProcessHit: URL
>       mismatch, '[unknown_URI]' !=
>
'http://cdn-00-default.nativex.com/asset/7b4133df-f0c8-4f2d-8532-2dcf6915577b.js'
>
>       >>> 2016/05/31 11:43:52 kid3| Bug: Missing
>       MemObject::storeId value
>
>       >>> 2016/05/31 11:43:52 kid3| mem_hdr: 0x2ac67f0
>       nodes.start() 0x3f5d410
>
>       >>> 2016/05/31 11:43:52 kid3| mem_hdr: 0x2ac67f0
>       nodes.finish() 0x1c71fc0
>
>       >>> 2016/05/31 11:43:52 kid3| MemObject->start_ping:
>       0.000000
>
>       >>> 2016/05/31 11:43:52 kid3| MemObject->inmem_hi:
>       95355
>
>       >>> 2016/05/31 11:43:52 kid3| MemObject->inmem_lo: 0
>
>       >>> 2016/05/31 11:43:52 kid3| MemObject->nclients: 0
>
>       >>> 2016/05/31 11:43:52 kid3| MemObject->reply:
>       0x2972cc0
>
>       >>> 2016/05/31 11:43:52 kid3| MemObject->request: 0
>
>       >>> 2016/05/31 11:43:52 kid3| MemObject->logUri:
>
>       >>> 2016/05/31 11:43:52 kid3| MemObject->storeId:
>
>       >>>
>
>       >>> --
>
>       >>> Best Regards,
>
>       >>>
>
>       >>> Heiler Bemerguy
>
>       >>> Network Manager - CINBESA
>
>       >>> 55 91 98151-4894/3184-1751
>
>       >>>
>
>       >>> Em 31/05/2016 11:39, Yuri escreveu:
>
>       >>>>
>
>       >>>> Bad test. Problem is with swapped onto disk
>       objects exactly. So, when we disable cache_dirs, problem is gone.
>
>       >>>>
>
>       >>>>
>
>       >>>> 31.05.2016 20:36, Heiler Bemerguy ?????:
>
>       >>>>>
>
>       >>>>>
>
>       >>>>> Just did a test here.
>
>       >>>>>
>
>       >>>>> Disabled every cache_dir and fully restarted
>       squid 3.5.19
>
>       >>>>>
>
>       >>>>> No more "vary object loop", but these
>       continues:
>
>       >>>>>
>
>       >>>>> 2016/05/31 11:35:13 kid2| Bug: Missing
>       MemObject::storeId value
>
>       >>>>> 2016/05/31 11:35:13 kid2| mem_hdr: 0x3177f40
>       nodes.start() 0x7370880
>
>       >>>>> 2016/05/31 11:35:13 kid2| mem_hdr: 0x3177f40
>       nodes.finish() 0x7370880
>
>       >>>>> 2016/05/31 11:35:13 kid2|
>       MemObject->start_ping: 0.000000
>
>       >>>>> 2016/05/31 11:35:13 kid2|
>       MemObject->inmem_hi: 2224
>
>       >>>>> 2016/05/31 11:35:13 kid2|
>       MemObject->inmem_lo: 0
>
>       >>>>> 2016/05/31 11:35:13 kid2|
>       MemObject->nclients: 0
>
>       >>>>> 2016/05/31 11:35:13 kid2|
>       MemObject->reply: 0x29711e0
>
>       >>>>> 2016/05/31 11:35:13 kid2|
>       MemObject->request: 0
>
>       >>>>> 2016/05/31 11:35:13 kid2|
>       MemObject->logUri:
>
>       >>>>> 2016/05/31 11:35:13 kid2|
>       MemObject->storeId:
>
>       >>>>> 2016/05/31 11:35:14 kid1| Bug: Missing
>       MemObject::storeId value
>
>       >>>>> 2016/05/31 11:35:14 kid1| mem_hdr: 0x3e0d990
>       nodes.start() 0x1ca70540
>
>       >>>>> 2016/05/31 11:35:14 kid1| mem_hdr: 0x3e0d990
>       nodes.finish() 0x1ca70540
>
>       >>>>> 2016/05/31 11:35:14 kid1|
>       MemObject->start_ping: 0.000000
>
>       >>>>> 2016/05/31 11:35:14 kid1|
>       MemObject->inmem_hi: 193
>
>       >>>>> 2016/05/31 11:35:14 kid1|
>       MemObject->inmem_lo: 0
>
>       >>>>> 2016/05/31 11:35:14 kid1|
>       MemObject->nclients: 0
>
>       >>>>> 2016/05/31 11:35:14 kid1|
>       MemObject->reply: 0x45656e0
>
>       >>>>> 2016/05/31 11:35:14 kid1|
>       MemObject->request: 0
>
>       >>>>> 2016/05/31 11:35:14 kid1|
>       MemObject->logUri:
>
>       >>>>> 2016/05/31 11:35:14 kid1|
>       MemObject->storeId:
>
>       >>>>> 2016/05/31 11:35:14.418 kid1|
>       clientProcessHit: URL mismatch, '[unknown_URI]' !=
>       'http://captive.apple.com/hotspot-detect.html'
>
>       >>>>> 2016/05/31 11:35:14 kid2| Bug: Missing
>       MemObject::storeId value
>
>       >>>>> 2016/05/31 11:35:14 kid2| mem_hdr: 0x336b090
>       nodes.start() 0x2b136d0
>
>       >>>>> 2016/05/31 11:35:14 kid2| mem_hdr: 0x336b090
>       nodes.finish() 0x82709c0
>
>       >>>>> 2016/05/31 11:35:14 kid2|
>       MemObject->start_ping: 0.000000
>
>       >>>>> 2016/05/31 11:35:14 kid2|
>       MemObject->inmem_hi: 4573
>
>       >>>>> 2016/05/31 11:35:14 kid2|
>       MemObject->inmem_lo: 0
>
>       >>>>> 2016/05/31 11:35:14 kid2|
>       MemObject->nclients: 0
>
>       >>>>> 2016/05/31 11:35:14 kid2|
>       MemObject->reply: 0x26bdf50
>
>       >>>>> 2016/05/31 11:35:14 kid2|
>       MemObject->request: 0
>
>       >>>>> 2016/05/31 11:35:14 kid2|
>       MemObject->logUri:
>
>       >>>>> 2016/05/31 11:35:14 kid2|
>       MemObject->storeId:
>
>       >>>>>
>
>       >>>>>
>
>       >>>>> --
>
>       >>>>> Best Regards,
>
>       >>>>>
>
>       >>>>> Heiler Bemerguy
>
>       >>>>> Network Manager - CINBESA
>
>       >>>>> 55 91 98151-4894/3184-1751
>
>       >>>>>
>
>       >>>>> Em 31/05/2016 11:14, Yuri escreveu:
>
>       >>>>>> Without collapsed_forwarding seems ok:
>
>       >>>>>>
>
>       >>>>>> https://i1.someimage.com/E8pM9tu.png
>
>       >>>>>>
>
>       >>>>>> no warnings/errors in cache.log.
>
>       >>>>>>
>
>       >>>>>> Seems Heiler right.
>
>       >>>>>>
>
>       >>>>>> 31.05.2016 19:33, joe ?????:
>
>       >>>>>>> load this link on both browser  
>       chrome  and firefox
>
>       >>>>>>>
>       'http://js.statig.com.br/pub/adtags.js'
>
>       >>>>>>> keep clicking reload  on both
>       browser  and look at your cache.log
>
>       >>>>>>> with or without collapsed_forwarding
>
>       >>>>>>>
>
>       >>>>>>>
>
>       >>>>>>> Heiler Bemerguy wrote
>
>       >>>>>>>> Yeah, I know. This kind of stuff
>       only appeared after enabling
>
>       >>>>>>>> collapsed_forwarding, I think.
>       Now it's off again.. but I didn't wipe
>
>       >>>>>>>> the cache too, so I don't
>       know.....
>
>       >>>>>>>>
>
>       >>>>>>>> 2016/05/31 10:50:24 kid2|
>       varyEvaluateMatch: Oops. Not a Vary match on
>
>       >>>>>>>> second attempt,
>       'http://js.statig.com.br/pub/adtags.js'
>
>       >>>>>>>>
>       'accept-encoding="gzip,%20deflate"'
>
>       >>>>>>>> 2016/05/31 10:50:24 kid2|
>       clientProcessHit: Vary object loop!
>
>       >>>>>>>> 2016/05/31 10:50:25 kid2| Bug:
>       Missing MemObject::storeId value
>
>       >>>>>>>> 2016/05/31 10:50:25 kid2|
>       mem_hdr: 0x20573e10 nodes.start() 0x117e4ce0
>
>       >>>>>>>> 2016/05/31 10:50:25 kid2|
>       mem_hdr: 0x20573e10 nodes.finish() 0x117e4ce0
>
>       >>>>>>>> 2016/05/31 10:50:25 kid2|
>       MemObject->start_ping: 0.000000
>
>       >>>>>>>> 2016/05/31 10:50:25 kid2|
>       MemObject->inmem_hi: 2155
>
>       >>>>>>>> 2016/05/31 10:50:25 kid2|
>       MemObject->inmem_lo: 0
>
>       >>>>>>>> 2016/05/31 10:50:25 kid2|
>       MemObject->nclients: 0
>
>       >>>>>>>> 2016/05/31 10:50:25 kid2|
>       MemObject->reply: 0x7db9ce0
>
>       >>>>>>>> 2016/05/31 10:50:25 kid2|
>       MemObject->request: 0
>
>       >>>>>>>> 2016/05/31 10:50:25 kid2|
>       MemObject->logUri:
>
>       >>>>>>>> 2016/05/31 10:50:25 kid2|
>       MemObject->storeId:
>
>       >>>>>>>>
>
>       >>>>>>>>
>
>       >>>>>>>> --
>
>       >>>>>>>> Best Regards,
>
>       >>>>>>>>
>
>       >>>>>>>> Heiler Bemerguy
>
>       >>>>>>>> Network Manager - CINBESA
>
>       >>>>>>>> 55 91 98151-4894/3184-1751
>
>       >>>>>>>>
>
>       >>>>>>>>
>
>       >>>>>>>> Em 31/05/2016 10:34, Yuri
>       escreveu:
>
>       >>>>>>>>> This is too expensive action.
>       Cold out cache will decrease hit-ratio
>
>       >>>>>>>>> for weeks.
>
>       >>>>>>>>>
>
>       >>>>>>>>>
>
>       >>>>>>>>> Also, I suggest force
>       reloading objects must overwrite stale cached, no?
>
>       >>>>>>>>>
>
>       >>>>>>>>>
>
>       >>>>>>>>> 31.05.2016 19:32, Heiler
>       Bemerguy ?????:
>
>       >>>>>>>>>>
>
>       >>>>>>>>>> I swear this bug was only
>       rarely triggered without
>
>       >>>>>>>>>> collapsed_forwarding
>       enabled... but I think you'll have to wipe your
>
>       >>>>>>>>>> cache to really test
>       it...
>
>       >>>>>>>>>>
>
>       >>>>>>>>>>
>
>       >>>>>>>>>>
>
>       >>>>>>>>>> --
>
>       >>>>>>>>>> Heiler Bemerguy - (91)
>       98151-4894
>
>       >>>>>>>>>> Assessor T?cnico -
>       CINBESA (91) 3184-1751
>
>       >>>>>>>>>>
>
>       >>>>>>>>>> Em 31/05/2016 08:00, Yuri
>       escreveu:
>
>       >>>>>>>>>>> Heh,
>
>       >>>>>>>>>>>
>
>       >>>>>>>>>>> the issue occurs also
>       with disabled collapsed_forwarding:
>
>       >>>>>>>>>>>
>
>       >>>>>>>>>>> 2016/05/31 16:58:12
>       kid1| varyEvaluateMatch: Oops. Not a Vary match
>
>       >>>>>>>>>>> on second attempt,
>
>       >>>>>>>>>>>
>
'https://ru.wikipedia.org/w/load.php?debug=false&lang=ru&modules=jquery.accessKeyLabel%2Cclient%7Cmediawiki.RegExp%2Cnotify%2Cutil%7Cmediawiki.legacy.wikibits&skin=vector&version=b5e9abd3b463'
>
>       >>>>>>>>>>>
>       'accept-encoding="gzip,%20deflate,%20sdch,%20br"'
>
>       >>>>>>>>>>> 2016/05/31 16:58:12
>       kid1| clientProcessHit: Vary object loop!
>
>       >>>>>>>>>>> 2016/05/31 16:58:12
>       kid1| Error negotiating SSL on FD 260:
>
>       >>>>>>>>>>> error:14090086:SSL
>       routines:SSL3_GET_SERVER_CERTIFICATE:certificate
>
>       >>>>>>>>>>> verify failed
>       (1/-1/0)
>
>       >>>>>>>>>>> 2016/05/31 16:58:12
>       kid1| varyEvaluateMatch: Oops. Not a Vary match
>
>       >>>>>>>>>>> on second attempt,
>
>       >>>>>>>>>>>
>
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Secure.js&action=raw&ctype=text/javascript'
>
>       >>>>>>>>>>>
>       'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>
>       >>>>>>>>>>>
>
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
>
>       >>>>>>>>>>> authorization'
>
>       >>>>>>>>>>> 2016/05/31 16:58:12
>       kid1| clientProcessHit: Vary object loop!
>
>       >>>>>>>>>>> 2016/05/31 16:58:12
>       kid1| varyEvaluateMatch: Oops. Not a Vary match
>
>       >>>>>>>>>>> on second attempt,
>
>       >>>>>>>>>>>
>
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Osm.js&action=raw&ctype=text/javascript'
>
>       >>>>>>>>>>>
>       'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>
>       >>>>>>>>>>>
>
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
>
>       >>>>>>>>>>> authorization'
>
>       >>>>>>>>>>> 2016/05/31 16:58:12
>       kid1| clientProcessHit: Vary object loop!
>
>       >>>>>>>>>>> 2016/05/31 16:58:13
>       kid1| varyEvaluateMatch: Oops. Not a Vary match
>
>       >>>>>>>>>>> on second attempt,
>
>       >>>>>>>>>>>
>
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Sidebar-related.js&action=raw&ctype=text/javascript'
>
>       >>>>>>>>>>>
>       'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>
>       >>>>>>>>>>>
>
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
>
>       >>>>>>>>>>> authorization'
>
>       >>>>>>>>>>> 2016/05/31 16:58:13
>       kid1| clientProcessHit: Vary object loop!
>
>       >>>>>>>>>>> 2016/05/31 16:58:13
>       kid1| varyEvaluateMatch: Oops. Not a Vary match
>
>       >>>>>>>>>>> on second attempt,
>
>       >>>>>>>>>>>
>
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Wikibugs.js&action=raw&ctype=text/javascript'
>
>       >>>>>>>>>>>
>       'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>
>       >>>>>>>>>>>
>
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
>
>       >>>>>>>>>>> authorization'
>
>       >>>>>>>>>>> 2016/05/31 16:58:13
>       kid1| clientProcessHit: Vary object loop!
>
>       >>>>>>>>>>> 2016/05/31 16:58:13
>       kid1| varyEvaluateMatch: Oops. Not a Vary match
>
>       >>>>>>>>>>> on second attempt,
>
>       >>>>>>>>>>>
>
'https://ru.wikipedia.org/w/index.php?title=MediaWiki:Interwiki-links.js&action=raw&ctype=text/javascript'
>
>       >>>>>>>>>>>
>       'accept-encoding="gzip,%20deflate,%20sdch,%20br",
>
>       >>>>>>>>>>>
>
cookie="WMF-Last-Access%3D31-May-2016%3B%20GeoIP%3DKZ%3A02%3AAlmaty%3A43.26%3A76.93%3Av4",
>
>       >>>>>>>>>>> authorization'
>
>       >>>>>>>>>>> 2016/05/31 16:58:13
>       kid1| clientProcessHit: Vary object loop!
>
>       >>>>>>>>>>> 2016/05/31 16:58:13
>       kid1| varyEvaluateMatch: Oops. Not a Vary match
>
>       >>>>>>>>>>> on second attempt,
>
>       >>>>>>>>>>>
>
'https://meta.wikimedia.org/w/index.php?title=MediaWiki:Wikiminiatlas.js&action=raw&ctype=text/javascript'
>
>       >>>>>>>>>>>
>       'accept-encoding="gzip,%20deflate,%20sdch,%20br", cookie,
>
>       >>>>>>>>>>> authorization'
>
>       >>>>>>>>>>>
>
>       >>>>>>>>>>> 3.5.19
>
>       >>>>>>>>>>>
>
>       >>>>>>>>>>>
>
>       >>> 
>
>       >>>
>
>       >>>
>
>       >>> _______________________________________________
>
>       >>> squid-users mailing list
>
>       >>> squid-users at lists.squid-cache.org
>
>       >>> http://lists.squid-cache.org/listinfo/squid-users
>
>       >>
>
>       >>
>
>       >>
>
>       >> _______________________________________________
>
>       >> squid-users mailing list
>
>       >> squid-users at lists.squid-cache.org
>
>       >> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXTb3HAAoJENNXIZxhPexGcDwIAJKNR3GmnmkD33KY3cpLf3CT
jAZfrRl1GwNaFD6icOQ8+dVAzlWDNmk8+3JKtUmQ7yJc0g/F3fmiH/F+DMe7Vc6q
iOoSz3RiCYPVceK37fNj8AGr2dT2Kvrek9FM3CqBCaMEdlPi/qoWqBLKLl8myPLI
m4PrMJCjMfPFTfVttyfd3uG7+e6zHLSc+Z7qLk4PyIrNoi+JGAOS/O/D3jiFLbUe
Df43ETplg5bfvS6V8iZOpIa0Taok1cPcmTkBx0YRpolWWsGG74+/MKaenMHpX1hK
YKM72vYa478jn4yqXFs4yvSR0VGihx3a4JKLhZ4K4ZhrZxY6iZu/fpf9GXTRGoU=
=9gjx
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/51acaaf4/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/51acaaf4/attachment.key>

From yvoinov at gmail.com  Tue May 31 16:41:33 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 31 May 2016 22:41:33 +0600
Subject: [squid-users] Working SSL configuration for Squid 4.x?
In-Reply-To: <a8ed145a-9766-694e-8812-19dec7147eb9@kalfaoglu.com>
References: <a8ed145a-9766-694e-8812-19dec7147eb9@kalfaoglu.com>
Message-ID: <960fa2aa-ce67-1841-d33e-1ade5ecbfaa7@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
We have Wiki.

http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit


31.05.2016 16:00, turgut kalfao?lu ?????:
>
> Hello. Whenever I tried to get squid to transparently cache https
content (mainly to speed up facebook browsing at my home),  I get all
kinds of problems.
>
> Is there a cookbook available for the recent squid versions?
>
> Many thanks, -turgut
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXTb69AAoJENNXIZxhPexGNroH/inQRNLJ7wcMx8e8KdTs9PZ/
Ye8me3ny3xkrbckQ2oKKbTT211GTiNFv7JMsv5N1sN350rX5M+uhQ4yNNFQPHjhE
3tfbqb9C8EAXmL78yi/M0+fibfxAUr0ZTHut5GMrwtt6lj0DPds74fYl6U3mnCM9
g/r21/lioKVrJjZKBib3DFBX2i5kJPnMx67fxwzw4VjZ4j3Ig6sdr5WPTfZpa3gs
dSaENw1UOQ/7Vz1Ko0r25aPEa94e73T2oLQfnKvjrZVS4RkdVb2iPhXBFX7DfalI
lumGCorE4/cLQclsDVYtR/AAq6hGAkzQknRyMxdyimkAafCRXU50xbx4qO67yxU=
=zPAy
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/02b487db/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/02b487db/attachment.key>

From nilesh.gavali at tcs.com  Tue May 31 19:19:39 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Tue, 31 May 2016 20:19:39 +0100
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
In-Reply-To: <OF6BC559F7.84283A07-ON80257FC0.004CFF22-80257FC0.004D9F23@LocalDomain>
References: <OF6BC559F7.84283A07-ON80257FC0.004CFF22-80257FC0.004D9F23@LocalDomain>
Message-ID: <OF059DEDF2.DD0EB7D2-ON80257FC4.006A0132-80257FC4.006A2AD0@tcs.com>

Hello All;

Configured the steps require for kerberos authentication as given at 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
but instead of SSO to work when we try to open url; it is prompt for 
username and password, when passing credential it is not authenticating.
attached is our squid config for your reference. 

Kindly let us know what went wrong.

we are using windows 2012 AD.



Thanks & Regards
Nilesh Suresh Gavali




From:   Nilesh Gavali/MUM/TCS
To:     squid-users at lists.squid-cache.org, belle at bazuin.nl
Date:   27/05/2016 15:07
Subject:         missing negotiate_kerberos_auth on my squid


Thanks louise for reply.

but

Should be include imo. -- not sure what is imo

 

Shoud be in any Squid-3.2 and later.

 

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth - check the path but it is not 
there on my linux box.

 

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? 
---- NO didn't gave this option while compilation

 

Run squid ?v to check it. -- we have"--enable-auth-negotiate" only and 
some other configured option.

can you help me how to get hit recomipled with reuqire options.


Thanks & Regards
Nilesh Suresh Gavali

----- Forwarded by Nilesh Gavali/MUM/TCS on 27/05/2016 15:01 -----

From:   squid-users-request at lists.squid-cache.org
To:     squid-users at lists.squid-cache.org
Date:   27/05/2016 12:42
Subject:        squid-users Digest, Vol 21, Issue 101
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org>



Send squid-users mailing list submissions to
                 squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
                 http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
                 squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
                 squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

   1. NULL characters (joe)
   2. Re: Looking for a way to route into cache_peer traffic
      dynamically. (Alex Rousskov)
   3. The system returned: (111) Connection refused; (deepa ganu)
   4. Re: NULL characters (Eliezer Croitoru)
   5. missing negotiate_kerberos_auth on my squid (Nilesh Gavali)
   6. Re: missing negotiate_kerberos_auth on my squid (L.P.H. van Belle)


----------------------------------------------------------------------

Message: 1
Date: Thu, 26 May 2016 07:30:16 -0700 (PDT)
From: joe <chip_pop at hotmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters
Message-ID: <1464273016183-4677691.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: 
http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html

Sent from the Squid - Users mailing list archive at Nabble.com.


------------------------------

Message: 2
Date: Thu, 26 May 2016 09:16:52 -0600
From: Alex Rousskov <rousskov at measurement-factory.com>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Looking for a way to route into cache_peer
                 traffic dynamically.
Message-ID: <57471364.4030007 at measurement-factory.com>
Content-Type: text/plain; charset=utf-8

On 05/26/2016 03:52 AM, Eliezer Croitoru wrote:

> I think that the best way is to use an ICAP meta header instead of 
altering
> the request itself 

Agreed.


> but I am not sure if it is possible

It is not possible today: Converting ICAP headers into annotations
understood by Squid ACLs is only supported for eCAP services.

IIRC, somebody posted a patch (on squid-dev) with a similar feature for
ICAP, but that implementation needed to be redone to be officially
accepted (IMO). I do not know whether the author will adjust their code
to follow my recommendations. Perhaps you can do it for them.

Alex.



------------------------------

Message: 3
Date: Fri, 27 May 2016 14:25:19 +0530
From: deepa ganu <deepaganu at gmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] The system returned: (111) Connection refused;
Message-ID:
 <CA+qV5k+cSUThvZYCS1JLcNuXsFCA8Vnk1Rmc5opK1w15W6asyg at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi
I am using squid as a reverse.

#http_port  80 accel defaultsite=202.53.13.19
https_port 443 accel  cert=/var/www/html/webrtc/imp/teleuniv.net.crt
key=/var/www/html/webrtc/imp/teleuniv.net.key
cafile=/var/www/html/webrtc/imp/intermediate.crt defaultsite=202.53.13.19
no-vhost


#this ACL is url path specific which accepts only portal urls and deny
others.
acl portal urlpath_regex ^/portal6may
cache_peer 172.20.36.144 parent 80 0 no-query originserver 
name=portalserver
cache_peer_access portalserver allow portal
cache_peer_access portalserver deny all
http_access allow portal


cache_peer 172.20.36.150 parent 443 0 no-query originserver ssl
sslflags=DONT_VERIFY_PEER login=PASS connection-auth=off name=teleuniv
acl our_sites dstdomain 202.53.13.19
http_access allow our_sites
cache_peer_access teleuniv allow our_sites
cache_peer_access teleuniv deny all

SO when i try to access the url https://202.53.13.19/ I get the following
error
"The following error was encountered while trying to retrieve the URL: The
system returned: (111) Connection refused; The remote host or network may
be down. Please try the request again."

It only gives for 172.20.36.144 not for the urlpath acl. But this happens
only sometimes. When I physically go to that server (172.20.36.150) and
click on the wired connection (one of the LAN options using linux). It
works again. I am very confused

-- 
Regards
Deepa Ganu
R&D Head(CSE) KMIT
Ph no : 9908036660
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/998e60f3/attachment-0001.html
>

------------------------------

Message: 4
Date: Fri, 27 May 2016 14:17:17 +0300
From: "Eliezer Croitoru" <eliezer at ngtech.co.il>
To: "'joe'" <chip_pop at hotmail.com>,
                 <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] NULL characters
Message-ID: <33b501d1b809$541a9620$fc4fc260$@ngtech.co.il>
Content-Type: text/plain;                charset="utf-8"

If it ended with some kind of server issues else then the logs, then it 
would be considered not nice.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On 
Behalf Of joe
Sent: Thursday, May 26, 2016 5:30 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: 
http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html

Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



------------------------------

Message: 5
Date: Fri, 27 May 2016 12:32:15 +0100
From: Nilesh Gavali <nilesh.gavali at tcs.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
 <OF9C6F8F89.5CF2ECB1-ON80257FC0.003EE232-80257FC0.003F5EF7 at tcs.com>
Content-Type: text/plain; charset="utf-8"

Hello ;
 I have installed latest squid 3.5.19 on red hat Linux yesterday. That 
means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but 
facing issues.
followed the steps provided on 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
But unable to find negotiate_kerberos_auth  on my Linux box at any 
location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and 

compile it to make authentication successful.

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.   IT Services
                        Business Solutions
                        Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 

 Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/b812d6ac/attachment-0001.html
>

------------------------------

Message: 6
Date: Fri, 27 May 2016 13:41:34 +0200
From: L.P.H. van Belle <belle at bazuin.nl>
To: squid-users at squid-cache.org  <squid-users at squid-cache.org>
Subject: Re: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
 <vmime.5748326e.63bf.32264d027089be4e at ms249-lin-003.rotterdam.bazuin.nl>
 
Content-Type: text/plain; charset="windows-1252"

Should be include imo. 

 

Shoud be in any Squid-3.2 and later.

 

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth 

 

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? 

 

Run squid ?v to check it. 

 

Greetz, 

 

Louis

 

 


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens 
Nilesh Gavali
Verzonden: vrijdag 27 mei 2016 13:32
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] missing negotiate_kerberos_auth on my squid


 

Hello ; 
 I have installed latest squid 3.5.19 on red hat Linux yesterday. That 
means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but 
facing issues. 
followed the steps provided on 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
But unable to find negotiate_kerberos_auth  on my Linux box at any 
location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and 
compile it to make authentication successful. 

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.        IT Services
                       Business Solutions
                       Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 
 Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/bbeb60e2/attachment.html
>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 21, Issue 101
********************************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/ea61904b/attachment.htm>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: squid.conf.txt
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/ea61904b/attachment.txt>

From huaraz at moeller.plus.com  Tue May 31 19:31:23 2016
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Tue, 31 May 2016 20:31:23 +0100
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
In-Reply-To: <OF059DEDF2.DD0EB7D2-ON80257FC4.006A0132-80257FC4.006A2AD0@tcs.com>
References: <OF6BC559F7.84283A07-ON80257FC0.004CFF22-80257FC0.004D9F23@LocalDomain>
 <OF059DEDF2.DD0EB7D2-ON80257FC4.006A0132-80257FC4.006A2AD0@tcs.com>
Message-ID: <nikoqr$i2m$1@ger.gmane.org>

What does the log say when you use the ?d option with the helper

Markus


"Nilesh Gavali" <nilesh.gavali at tcs.com> wrote in message news:OF059DEDF2.DD0EB7D2-ON80257FC4.006A0132-80257FC4.006A2AD0 at tcs.com...
Hello All; 

Configured the steps require for kerberos authentication as given at http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
but instead of SSO to work when we try to open url; it is prompt for username and password, when passing credential it is not authenticating. 
attached is our squid config for your reference. 

Kindly let us know what went wrong. 

we are using windows 2012 AD. 



Thanks & Regards
Nilesh Suresh Gavali




From:        Nilesh Gavali/MUM/TCS 
To:        squid-users at lists.squid-cache.org, belle at bazuin.nl 
Date:        27/05/2016 15:07 
Subject:        missing negotiate_kerberos_auth on my squid 

--------------------------------------------------------------------------------


Thanks louise for reply. 

but 

Should be include imo. -- not sure what is imo

 

Shoud be in any Squid-3.2 and later.

 

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth - check the path but it is not there on my linux box.

 

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ?  ---- NO didn't gave this option while compilation

 

Run squid ?v to check it. -- we have"--enable-auth-negotiate" only and some other configured option. 

can you help me how to get hit recomipled with reuqire options. 


Thanks & Regards
Nilesh Suresh Gavali

----- Forwarded by Nilesh Gavali/MUM/TCS on 27/05/2016 15:01 ----- 

From:        squid-users-request at lists.squid-cache.org 
To:        squid-users at lists.squid-cache.org 
Date:        27/05/2016 12:42 
Subject:        squid-users Digest, Vol 21, Issue 101 
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org> 

--------------------------------------------------------------------------------



Send squid-users mailing list submissions to
                squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
                http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
                squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
                squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

  1. NULL characters (joe)
  2. Re: Looking for a way to route into cache_peer traffic
     dynamically. (Alex Rousskov)
  3. The system returned: (111) Connection refused; (deepa ganu)
  4. Re: NULL characters (Eliezer Croitoru)
  5. missing negotiate_kerberos_auth on my squid (Nilesh Gavali)
  6. Re: missing negotiate_kerberos_auth on my squid (L.P.H. van Belle)


----------------------------------------------------------------------

Message: 1
Date: Thu, 26 May 2016 07:30:16 -0700 (PDT)
From: joe <chip_pop at hotmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters
Message-ID: <1464273016183-4677691.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html
Sent from the Squid - Users mailing list archive at Nabble.com.


------------------------------

Message: 2
Date: Thu, 26 May 2016 09:16:52 -0600
From: Alex Rousskov <rousskov at measurement-factory.com>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Looking for a way to route into cache_peer
                traffic dynamically.
Message-ID: <57471364.4030007 at measurement-factory.com>
Content-Type: text/plain; charset=utf-8

On 05/26/2016 03:52 AM, Eliezer Croitoru wrote:

> I think that the best way is to use an ICAP meta header instead of altering
> the request itself 

Agreed.


> but I am not sure if it is possible

It is not possible today: Converting ICAP headers into annotations
understood by Squid ACLs is only supported for eCAP services.

IIRC, somebody posted a patch (on squid-dev) with a similar feature for
ICAP, but that implementation needed to be redone to be officially
accepted (IMO). I do not know whether the author will adjust their code
to follow my recommendations. Perhaps you can do it for them.

Alex.



------------------------------

Message: 3
Date: Fri, 27 May 2016 14:25:19 +0530
From: deepa ganu <deepaganu at gmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] The system returned: (111) Connection refused;
Message-ID:
                <CA+qV5k+cSUThvZYCS1JLcNuXsFCA8Vnk1Rmc5opK1w15W6asyg at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi
I am using squid as a reverse.

#http_port  80 accel defaultsite=202.53.13.19
https_port 443 accel  cert=/var/www/html/webrtc/imp/teleuniv.net.crt
key=/var/www/html/webrtc/imp/teleuniv.net.key
cafile=/var/www/html/webrtc/imp/intermediate.crt defaultsite=202.53.13.19
no-vhost


#this ACL is url path specific which accepts only portal urls and deny
others.
acl portal urlpath_regex ^/portal6may
cache_peer 172.20.36.144 parent 80 0 no-query originserver name=portalserver
cache_peer_access portalserver allow portal
cache_peer_access portalserver deny all
http_access allow portal


cache_peer 172.20.36.150 parent 443 0 no-query originserver ssl
sslflags=DONT_VERIFY_PEER login=PASS connection-auth=off name=teleuniv
acl our_sites dstdomain 202.53.13.19
http_access allow our_sites
cache_peer_access teleuniv allow our_sites
cache_peer_access teleuniv deny all

SO when i try to access the url https://202.53.13.19/ I get the following
error
"The following error was encountered while trying to retrieve the URL: The
system returned: (111) Connection refused; The remote host or network may
be down. Please try the request again."

It only gives for 172.20.36.144 not for the urlpath acl. But this happens
only sometimes. When I physically go to that server (172.20.36.150) and
click on the wired connection (one of the LAN options using linux). It
works again. I am very confused

-- 
Regards
Deepa Ganu
R&D Head(CSE) KMIT
Ph no : 9908036660
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/998e60f3/attachment-0001.html>

------------------------------

Message: 4
Date: Fri, 27 May 2016 14:17:17 +0300
From: "Eliezer Croitoru" <eliezer at ngtech.co.il>
To: "'joe'" <chip_pop at hotmail.com>,
                <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] NULL characters
Message-ID: <33b501d1b809$541a9620$fc4fc260$@ngtech.co.il>
Content-Type: text/plain;                 charset="utf-8"

If it ended with some kind of server issues else then the logs, then it would be considered not nice.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of joe
Sent: Thursday, May 26, 2016 5:30 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



------------------------------

Message: 5
Date: Fri, 27 May 2016 12:32:15 +0100
From: Nilesh Gavali <nilesh.gavali at tcs.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
                <OF9C6F8F89.5CF2ECB1-ON80257FC0.003EE232-80257FC0.003F5EF7 at tcs.com>
Content-Type: text/plain; charset="utf-8"

Hello ;
I have installed latest squid 3.5.19 on red hat Linux yesterday. That 
means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but 
facing issues.
followed the steps provided on 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
But unable to find negotiate_kerberos_auth  on my Linux box at any 
location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and 
compile it to make authentication successful.

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.   IT Services
                       Business Solutions
                       Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 
Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/b812d6ac/attachment-0001.html>

------------------------------

Message: 6
Date: Fri, 27 May 2016 13:41:34 +0200
From: L.P.H. van Belle <belle at bazuin.nl>
To: squid-users at squid-cache.org  <squid-users at squid-cache.org>
Subject: Re: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
                <vmime.5748326e.63bf.32264d027089be4e at ms249-lin-003.rotterdam.bazuin.nl>
                
Content-Type: text/plain; charset="windows-1252"

Should be include imo. 

 

Shoud be in any Squid-3.2 and later.

 

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth 

 

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? 

 

Run squid ?v to check it. 

 

Greetz, 

 

Louis

 

 


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Nilesh Gavali
Verzonden: vrijdag 27 mei 2016 13:32
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] missing negotiate_kerberos_auth on my squid


 

Hello ; 
I have installed latest squid 3.5.19 on red hat Linux yesterday. That means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but facing issues. 
followed the steps provided on http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
But unable to find negotiate_kerberos_auth  on my Linux box at any location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and compile it to make authentication successful. 

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.        IT Services
                       Business Solutions
                       Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India -  Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/bbeb60e2/attachment.html>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 21, Issue 101
********************************************




--------------------------------------------------------------------------------
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/48c269d6/attachment.htm>

From amadaan at ncsu.edu  Tue May 31 20:02:57 2016
From: amadaan at ncsu.edu (Aashima Madaan)
Date: Tue, 31 May 2016 16:02:57 -0400
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
Message-ID: <CAO4ouAazV-mvev9JpPwCLkE8Oj=eUzFUaO4sCLSpDvaxBbY78Q@mail.gmail.com>

Hi Nishant,


>>>* (The last two commands in as quick succession as possible - preferably on a
*>>>* single line separated by a semi-colon)
*>>>>>>* yes the problem still exists
*>>>>

>Could it be because squid is trying to resolve and connect to IPv6 address
>first?

>Try setting "dns_v4_first on" and try.


I tried setting this option but still the behavior is same.


Thanks

Aashima
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/d550af4d/attachment.htm>

From amadaan at ncsu.edu  Tue May 31 21:05:40 2016
From: amadaan at ncsu.edu (Aashima Madaan)
Date: Tue, 31 May 2016 17:05:40 -0400
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
Message-ID: <E3DA71A8-7F4C-493D-B7AF-1C89EFC1C68C@ncsu.edu>

Hey Amos,

>What is causing the problem is that ICAP services need to be working
>*immediately* and do not wait for DNS results to come back. If they are
>not available immediately then the service is not contactable for that
>transaction.

>Adding /etc/hosts entries makes Squid load the name+IP details on
>startup before ICAP is used. So the problem does not appear.
Is there a configuration for squid where we can ask it to perform DNS lookup immediately rather than doing later when it sends an OPTIONS request again.

Thanks
Aashima
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/92a57c07/attachment.htm>

From huaraz at moeller.plus.com  Tue May 31 21:31:20 2016
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Tue, 31 May 2016 22:31:20 +0100
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
In-Reply-To: <nikoqr$i2m$1@ger.gmane.org>
References: <OF6BC559F7.84283A07-ON80257FC0.004CFF22-80257FC0.004D9F23@LocalDomain>
 <OF059DEDF2.DD0EB7D2-ON80257FC4.006A0132-80257FC4.006A2AD0@tcs.com>
 <nikoqr$i2m$1@ger.gmane.org>
Message-ID: <nikvrp$3qr$1@ger.gmane.org>

Hi Nilesh,

Just add a ?d to 


# enable kerberos authentication
auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s HTTP/hostname.domain.org at DOMAIN.ORG

like 

# enable kerberos authentication
auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -s HTTP/hostname.domain.org at DOMAIN.ORG ?d 

Then you get debug output in your cache.log file.

Markus


"Markus Moeller" <huaraz at moeller.plus.com> wrote in message news:nikoqr$i2m$1 at ger.gmane.org...
What does the log say when you use the ?d option with the helper

Markus


"Nilesh Gavali" <nilesh.gavali at tcs.com> wrote in message news:OF059DEDF2.DD0EB7D2-ON80257FC4.006A0132-80257FC4.006A2AD0 at tcs.com...
Hello All; 

Configured the steps require for kerberos authentication as given at http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
but instead of SSO to work when we try to open url; it is prompt for username and password, when passing credential it is not authenticating. 
attached is our squid config for your reference. 

Kindly let us know what went wrong. 

we are using windows 2012 AD. 



Thanks & Regards
Nilesh Suresh Gavali




From:        Nilesh Gavali/MUM/TCS 
To:        squid-users at lists.squid-cache.org, belle at bazuin.nl 
Date:        27/05/2016 15:07 
Subject:        missing negotiate_kerberos_auth on my squid 

--------------------------------------------------------------------------------


Thanks louise for reply. 

but 

Should be include imo. -- not sure what is imo

 

Shoud be in any Squid-3.2 and later.

 

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth - check the path but it is not there on my linux box.

 

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ?  ---- NO didn't gave this option while compilation

 

Run squid ?v to check it. -- we have"--enable-auth-negotiate" only and some other configured option. 

can you help me how to get hit recomipled with reuqire options. 


Thanks & Regards
Nilesh Suresh Gavali

----- Forwarded by Nilesh Gavali/MUM/TCS on 27/05/2016 15:01 ----- 

From:        squid-users-request at lists.squid-cache.org 
To:        squid-users at lists.squid-cache.org 
Date:        27/05/2016 12:42 
Subject:        squid-users Digest, Vol 21, Issue 101 
Sent by:        "squid-users" <squid-users-bounces at lists.squid-cache.org> 

--------------------------------------------------------------------------------



Send squid-users mailing list submissions to
                squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
                http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
                squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
                squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

  1. NULL characters (joe)
  2. Re: Looking for a way to route into cache_peer traffic
     dynamically. (Alex Rousskov)
  3. The system returned: (111) Connection refused; (deepa ganu)
  4. Re: NULL characters (Eliezer Croitoru)
  5. missing negotiate_kerberos_auth on my squid (Nilesh Gavali)
  6. Re: missing negotiate_kerberos_auth on my squid (L.P.H. van Belle)


----------------------------------------------------------------------

Message: 1
Date: Thu, 26 May 2016 07:30:16 -0700 (PDT)
From: joe <chip_pop at hotmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters
Message-ID: <1464273016183-4677691.post at n4.nabble.com>
Content-Type: text/plain; charset=us-ascii

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html
Sent from the Squid - Users mailing list archive at Nabble.com.


------------------------------

Message: 2
Date: Thu, 26 May 2016 09:16:52 -0600
From: Alex Rousskov <rousskov at measurement-factory.com>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Looking for a way to route into cache_peer
                traffic dynamically.
Message-ID: <57471364.4030007 at measurement-factory.com>
Content-Type: text/plain; charset=utf-8

On 05/26/2016 03:52 AM, Eliezer Croitoru wrote:

> I think that the best way is to use an ICAP meta header instead of altering
> the request itself 

Agreed.


> but I am not sure if it is possible

It is not possible today: Converting ICAP headers into annotations
understood by Squid ACLs is only supported for eCAP services.

IIRC, somebody posted a patch (on squid-dev) with a similar feature for
ICAP, but that implementation needed to be redone to be officially
accepted (IMO). I do not know whether the author will adjust their code
to follow my recommendations. Perhaps you can do it for them.

Alex.



------------------------------

Message: 3
Date: Fri, 27 May 2016 14:25:19 +0530
From: deepa ganu <deepaganu at gmail.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] The system returned: (111) Connection refused;
Message-ID:
                <CA+qV5k+cSUThvZYCS1JLcNuXsFCA8Vnk1Rmc5opK1w15W6asyg at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hi
I am using squid as a reverse.

#http_port  80 accel defaultsite=202.53.13.19
https_port 443 accel  cert=/var/www/html/webrtc/imp/teleuniv.net.crt
key=/var/www/html/webrtc/imp/teleuniv.net.key
cafile=/var/www/html/webrtc/imp/intermediate.crt defaultsite=202.53.13.19
no-vhost


#this ACL is url path specific which accepts only portal urls and deny
others.
acl portal urlpath_regex ^/portal6may
cache_peer 172.20.36.144 parent 80 0 no-query originserver name=portalserver
cache_peer_access portalserver allow portal
cache_peer_access portalserver deny all
http_access allow portal


cache_peer 172.20.36.150 parent 443 0 no-query originserver ssl
sslflags=DONT_VERIFY_PEER login=PASS connection-auth=off name=teleuniv
acl our_sites dstdomain 202.53.13.19
http_access allow our_sites
cache_peer_access teleuniv allow our_sites
cache_peer_access teleuniv deny all

SO when i try to access the url https://202.53.13.19/ I get the following
error
"The following error was encountered while trying to retrieve the URL: The
system returned: (111) Connection refused; The remote host or network may
be down. Please try the request again."

It only gives for 172.20.36.144 not for the urlpath acl. But this happens
only sometimes. When I physically go to that server (172.20.36.150) and
click on the wired connection (one of the LAN options using linux). It
works again. I am very confused

-- 
Regards
Deepa Ganu
R&D Head(CSE) KMIT
Ph no : 9908036660
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/998e60f3/attachment-0001.html>

------------------------------

Message: 4
Date: Fri, 27 May 2016 14:17:17 +0300
From: "Eliezer Croitoru" <eliezer at ngtech.co.il>
To: "'joe'" <chip_pop at hotmail.com>,
                <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] NULL characters
Message-ID: <33b501d1b809$541a9620$fc4fc260$@ngtech.co.il>
Content-Type: text/plain;                 charset="utf-8"

If it ended with some kind of server issues else then the logs, then it would be considered not nice.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of joe
Sent: Thursday, May 26, 2016 5:30 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] NULL characters

2016/05/26 06:41:28 kid1| ctx: enter level  0:
'http://js.advert.mirtesen.ru/data/js/82090.js'
2016/05/26 06:41:28 kid1| WARNING: HTTP header contains NULL characters
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid}
NULL
{Server: nginx
Date: Thu, 26 May 2016 03:46:52 GMT
Content-Type: application/javascript;charset=utf-8
Transfer-Encoding: chunked
Connection: close
Vary: Accept-Encoding
X-MaxSize: 5
X-MaxShm: 5
X-ShmTol: 2
X-Loc: 2347
X-MID: 16
X-Node: ssel6
X-ChosenReserve: 2
X-TotalPrimary: 290
X-ExclByGeo: 266
X-TotalPrimaryPayable: 219
X-ChosenPrimary: 3
X-ExclByTime: 18
X-ShmNews: 1989237,2010118,2009700,
X-TotalPrimaryExchange: 0
X-TotalReserve: 332
X-ChosenPayable: 3
X-ShmCnt: 3
Set-Cookie: nid
2016/05/26 06:41:28 kid1| ctx: exit level  0

is it bad ?????



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/NULL-characters-tp4677691.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



------------------------------

Message: 5
Date: Fri, 27 May 2016 12:32:15 +0100
From: Nilesh Gavali <nilesh.gavali at tcs.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
                <OF9C6F8F89.5CF2ECB1-ON80257FC0.003EE232-80257FC0.003F5EF7 at tcs.com>
Content-Type: text/plain; charset="utf-8"

Hello ;
I have installed latest squid 3.5.19 on red hat Linux yesterday. That 
means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but 
facing issues.
followed the steps provided on 
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos
But unable to find negotiate_kerberos_auth  on my Linux box at any 
location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and 
compile it to make authentication successful.

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.   IT Services
                       Business Solutions
                       Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability 
and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India - 
Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/b812d6ac/attachment-0001.html>

------------------------------

Message: 6
Date: Fri, 27 May 2016 13:41:34 +0200
From: L.P.H. van Belle <belle at bazuin.nl>
To: squid-users at squid-cache.org  <squid-users at squid-cache.org>
Subject: Re: [squid-users] missing negotiate_kerberos_auth on my squid
Message-ID:
                <vmime.5748326e.63bf.32264d027089be4e at ms249-lin-003.rotterdam.bazuin.nl>
                
Content-Type: text/plain; charset="windows-1252"

Should be include imo. 

 

Shoud be in any Squid-3.2 and later.

 

And on my debian server its locate here. 

/usr/lib/squid/negotiate_kerberos_auth 

 

Did you enable : --enable-auth-negotiate=kerberos,wrapper on compile ? 

 

Run squid ?v to check it. 

 

Greetz, 

 

Louis

 

 


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens Nilesh Gavali
Verzonden: vrijdag 27 mei 2016 13:32
Aan: squid-users at lists.squid-cache.org
Onderwerp: [squid-users] missing negotiate_kerberos_auth on my squid


 

Hello ; 
I have installed latest squid 3.5.19 on red hat Linux yesterday. That means I am new to squid and linux. 
able to start the squid and its working fine. 
now we are trying to authenticate user via Kerberos with windows AD. but facing issues. 
followed the steps provided on http://wiki.squid-cache.org/ConfigExamples/Authenticate/Kerberos 
But unable to find negotiate_kerberos_auth  on my Linux box at any location. 
now I need to know where i can find/download  negotiate_kerberos_auth  and compile it to make authentication successful. 

Thanks & Regards
Nilesh Suresh Gavali
Tata Consultancy Services
3rd Floor, Tithebarn House
Tithebarn Street
Liverpool - L2 2NZ
United Kingdom
Mailto: nilesh.gavali at tcs.com
Website: http://www.tcs.com
____________________________________________
Experience certainty.        IT Services
                       Business Solutions
                       Consulting
____________________________________________

Tata Consultancy Services Limited , incorporated  with limited liability and registered with Registrar of Companies, Mumbai, India - No: 11-84781
HQ : Nirmal Building , 9th Floor, Nariman Point, Mumbai - 400 021, India -  Registered  in UK : 18 Grosvenor Place, London SW1X 7HS - BR :007627

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160527/bbeb60e2/attachment.html>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 21, Issue 101
********************************************




--------------------------------------------------------------------------------
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



--------------------------------------------------------------------------------
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/737abf12/attachment.htm>

From amadaan at ncsu.edu  Tue May 31 22:22:23 2016
From: amadaan at ncsu.edu (Aashima Madaan)
Date: Tue, 31 May 2016 18:22:23 -0400
Subject: [squid-users] DNS lookup fails initially for FQDN in squid
Message-ID: <CAO4ouAbMRJQUnVEYz7J8YTOnprAtFNjMLxQez1dB=5weErXzAA@mail.gmail.com>

Attaching full log of how it fails initially and then able to resolve dns
lookup in 3 minutes

collected by setting debug_options ALL, 3

>>>>>

2016/05/31 16:55:05.157| 42,2| IcmpPinger.cc(211) SendResult: return result
to squid. len=76

2016/05/31 16:55:05.157 kid1| 51,3| fd.cc(93) fd_close: fd_close FD 12
Pinger Socket

2016/05/31 16:55:05.157| 42,2| IcmpPinger.cc(211) SendResult: return result
to squid. len=7990

2016/05/31 16:55:05.157| 42,2| Icmp.cc(95) Log: pingerLog:
1464728105.157655 127.0.0.1                                     0 Echo
Reply      0ms 1 hops

2016/05/31 16:55:05.635 kid1| 50,3| ModDaemon.cc(172)
logfile_mod_daemon_append: logfile_mod_daemon_append:
daemon:/var/log/squid/access.log: appending 2 bytes

2016/05/31 16:55:05.635 kid1| 50,3| ModDaemon.cc(176)
logfile_mod_daemon_append: logfile_mod_daemon_append: current buffer has 6
of 32768 bytes before append

2016/05/31 16:55:05.635 kid1| 50,3| ModDaemon.cc(108) logfileHandleWrite:
daemon:/var/log/squid/access.log: write returned 8

2016/05/31 16:55:05.635 kid1| storeLateRelease: released 0 objects

2016/05/31 16:55:25.176 kid1| 38,3| net_db.cc(1286) netdbExchangeStart:
netdbExchangeStart: Requesting '
http://127.0.0.1:50005/squid-internal-dynamic/netdb'

2016/05/31 16:55:25.176 kid1| 23,3| url.cc(357) urlParse: urlParse: Split
URL 'http://127.0.0.1:50005/squid-internal-dynamic/netdb' into
proto='http', host='127.0.0.1', port='50005',
path='/squid-internal-dynamic/netdb'

2016/05/31 16:55:25.176 kid1| 23,3| HttpRequest.h(82) SetHost:
HttpRequest::SetHost() given IP: 127.0.0.1

2016/05/31 16:55:25.176 kid1| 20,3| store.cc(774) storeCreatePureEntry:
storeCreateEntry: 'http://127.0.0.1:50005/squid-internal-dynamic/netdb'

2016/05/31 16:55:25.176 kid1| 20,3| MemObject.cc(97) MemObject: new
MemObject 0x7f0f6646d960

2016/05/31 16:55:25.176 kid1| 20,3| store.cc(499) setReleaseFlag:
StoreEntry::setReleaseFlag: '[null_store_key]'

2016/05/31 16:55:25.176 kid1| 20,3| store_key_md5.cc(89) storeKeyPrivate:
storeKeyPrivate: GET http://127.0.0.1:50005/squid-internal-dynamic/netdb

2016/05/31 16:55:25.176 kid1| 20,3| store.cc(447) hashInsert:
StoreEntry::hashInsert: Inserting Entry e:=XI/0x7f0f66898f80*0 key
'8296497AA8EBFF11C70A96598AA18956'

2016/05/31 16:55:25.176 kid1| 20,3| store.cc(483) lock: storeCreateEntry
locked key 8296497AA8EBFF11C70A96598AA18956 e:=XIV/0x7f0f66898f80*1

2016/05/31 16:55:25.176 kid1| 90,3| store_client.cc(200) copy:
store_client::copy: 8296497AA8EBFF11C70A96598AA18956, from 0, for length
4096, cb 1, cbdata 0x7f0f6646c918

2016/05/31 16:55:25.176 kid1| 20,3| store.cc(483) lock: store_client::copy
locked key 8296497AA8EBFF11C70A96598AA18956 e:=XIV/0x7f0f66898f80*2

2016/05/31 16:55:25.176 kid1| 90,3| store_client.cc(297) storeClientCopy2:
storeClientCopy2: 8296497AA8EBFF11C70A96598AA18956

2016/05/31 16:55:25.176 kid1| 90,3| store_client.cc(341) doCopy:
store_client::doCopy: Waiting for more

2016/05/31 16:55:25.176 kid1| 20,3| store.cc(521) unlock:
store_client::copy unlocking key 8296497AA8EBFF11C70A96598AA18956
e:=XIV/0x7f0f66898f80*2

2016/05/31 16:55:25.176 kid1| 17,3| FwdState.cc(332) Start: '
http://127.0.0.1:50005/squid-internal-dynamic/netdb'

2016/05/31 16:55:25.176 kid1| 17,2| FwdState.cc(133) FwdState: Forwarding
client request , url=http://127.0.0.1:50005/squid-internal-dynamic/netdb

2016/05/31 16:55:25.176 kid1| 20,3| store.cc(483) lock: FwdState locked key
8296497AA8EBFF11C70A96598AA18956 e:=XIV/0x7f0f66898f80*2

2016/05/31 16:55:25.176 kid1| 44,3| peer_select.cc(137) peerSelect:
e:=XIWV/0x7f0f66898f80*2 http://127.0.0.1:50005/squid-internal-dynamic/netdb

2016/05/31 16:55:25.177 kid1| 20,3| store.cc(483) lock: peerSelect locked
key 8296497AA8EBFF11C70A96598AA18956 e:=XIWV/0x7f0f66898f80*3

2016/05/31 16:55:25.177 kid1| 44,3| peer_select.cc(441) peerSelectFoo: GET
127.0.0.1

2016/05/31 16:55:25.177 kid1| 44,3| peer_select.cc(468) peerSelectFoo:
peerSelectFoo: direct = DIRECT_YES (forwarding loop detected)

2016/05/31 16:55:25.177 kid1| 44,3| peer_select.cc(477) peerSelectFoo:
peerSelectFoo: direct = DIRECT_YES

2016/05/31 16:55:25.177 kid1| 44,2| peer_select.cc(258) peerSelectDnsPaths:
Find IP destination for: http://127.0.0.1:50005/squid-internal-dynamic/netdb'
via 127.0.0.1

2016/05/31 16:55:25.177 kid1| 44,2| peer_select.cc(280) peerSelectDnsPaths:
Found sources for 'http://127.0.0.1:50005/squid-internal-dynamic/netdb'

2016/05/31 16:55:25.177 kid1| 44,2| peer_select.cc(281) peerSelectDnsPaths:
  always_direct = DENIED

2016/05/31 16:55:25.177 kid1| 44,2| peer_select.cc(282)
peerSelectDnsPaths:    never_direct = DENIED

2016/05/31 16:55:25.177 kid1| 44,2| peer_select.cc(286)
peerSelectDnsPaths:          DIRECT = local=0.0.0.0 remote=127.0.0.1:50005
flags=1

2016/05/31 16:55:25.177 kid1| 44,2| peer_select.cc(295)
peerSelectDnsPaths:        timedout = 0

2016/05/31 16:55:25.177 kid1| 17,3| FwdState.cc(387) startConnectionOrFail:
http://127.0.0.1:50005/squid-internal-dynamic/netdb

2016/05/31 16:55:25.177 kid1| 17,3| FwdState.cc(806) connectStart:
fwdConnectStart: http://127.0.0.1:50005/squid-internal-dynamic/netdb

2016/05/31 16:55:25.177 kid1| 48,3| pconn.cc(439) pop: lookup for key {
127.0.0.1:50005/127.0.0.1} failed.

2016/05/31 16:55:25.177 kid1| 17,3| FwdState.cc(1307) GetMarkingsToServer:
from 0.0.0.0 netfilter mark 0

2016/05/31 16:55:25.177 kid1| 17,3| AsyncCall.cc(26) AsyncCall: The
AsyncCall fwdConnectDoneWrapper constructed, this=0x7f0f6646dfa0 [call52]

2016/05/31 16:55:25.177 kid1| 44,3| peer_select.cc(79) ~ps_state:
http://127.0.0.1:50005/squid-internal-dynamic/netdb

2016/05/31 16:55:25.177 kid1| 20,3| store.cc(521) unlock: peerSelect
unlocking key 8296497AA8EBFF11C70A96598AA18956 e:=p2XIWV/0x7f0f66898f80*3

2016/05/31 16:55:25.177 kid1| 50,3| comm.cc(347) comm_openex: comm_openex:
Attempt open socket for: 0.0.0.0

2016/05/31 16:55:25.177 kid1| 50,3| comm.cc(388) comm_openex: comm_openex:
Opened socket local=0.0.0.0 remote=[::] FD 10 flags=1 : family=2, type=1,
protocol=6

2016/05/31 16:55:25.177 kid1| 51,3| fd.cc(198) fd_open: fd_open() FD 10
127.0.0.1

2016/05/31 16:55:25.177 kid1| 5,3| ConnOpener.cc(289) createFd:
local=0.0.0.0 remote=127.0.0.1:50005 flags=1 will timeout in 60

2016/05/31 16:55:25.177 kid1| 17,3| AsyncCall.cc(93) ScheduleCall:
ConnOpener.cc(137) will call fwdConnectDoneWrapper(local=127.0.0.1:51409
remote=127.0.0.1:50005 FD 10 flags=1, data=0x7f0f6646dee8) [call52]

2016/05/31 16:55:25.177 kid1| 17,3| AsyncCallQueue.cc(55) fireNext:
entering fwdConnectDoneWrapper(local=127.0.0.1:51409 remote=127.0.0.1:50005
FD 10 flags=1, data=0x7f0f6646dee8)

2016/05/31 16:55:25.177 kid1| 17,3| AsyncCall.cc(38) make: make call
fwdConnectDoneWrapper [call52]

2016/05/31 16:55:25.177 kid1| 17,3| FwdState.cc(680) connectDone: local=
127.0.0.1:51409 remote=127.0.0.1:50005 FD 10 flags=1: '
http://127.0.0.1:50005/squid-internal-dynamic/netdb'

2016/05/31 16:55:25.177 kid1| 17,3| FwdState.cc(908) dispatch: : Fetching
GET http://127.0.0.1:50005/squid-internal-dynamic/netdb

2016/05/31 16:55:25.177 kid1| 38,3| net_db.cc(325) netdbSendPing:
netdbSendPing: pinging 127.0.0.1

2016/05/31 16:55:25.178 kid1| 37,2| IcmpSquid.cc(90) SendEcho: to
127.0.0.1, opcode 3, len 9

2016/05/31 16:55:25.178 kid1| 11,3| http.cc(2278) httpStart: GET
http://127.0.0.1:50005/squid-internal-dynamic/netdb

2016/05/31 16:55:25.178 kid1| 20,3| store.cc(483) lock: Client locked key
8296497AA8EBFF11C70A96598AA18956 e:=p2XDIWV/0x7f0f66898f80*3

2016/05/31 16:55:25.178 kid1| 17,3| AsyncCallQueue.cc(57) fireNext: leaving
fwdConnectDoneWrapper(local=127.0.0.1:51409 remote=127.0.0.1:50005 FD 10
flags=1, data=0x7f0f6646dee8)

2016/05/31 16:55:25.178 kid1| 5,3| comm.cc(553) commSetConnTimeout: local=
127.0.0.1:51409 remote=127.0.0.1:50005 FD 10 flags=1 timeout 86400

2016/05/31 16:55:25.178 kid1| 22,3| refresh.cc(656) getMaxAge: getMaxAge: '
http://127.0.0.1:50005/squid-internal-dynamic/netdb'

2016/05/31 16:55:25.178| 42,2| IcmpPinger.cc(198) Recv:  Pass 127.0.0.1 off
to ICMPv4 module.

2016/05/31 16:55:25.178 kid1| 11,2| http.cc(2234) sendRequest: HTTP Server
local=127.0.0.1:51409 remote=127.0.0.1:50005 FD 10 flags=1

2016/05/31 16:55:25.178 kid1| 11,2| http.cc(2235) sendRequest: HTTP Server
REQUEST:

---------

GET /squid-internal-dynamic/netdb HTTP/1.1

Via: 1.1 SLES12-001-0 (squid/3.5.16)

X-Forwarded-For: ::

Host: 127.0.0.1:50005

Authorization: Basic UEFTU1RIUlU=

Cache-Control: max-age=259200

Connection: keep-alive



----------

2016/05/31 16:55:25.178| 42,2| Icmp.cc(95) Log: pingerLog:
1464728125.178329 127.0.0.1                                     32

2016/05/31 16:55:25.178 kid1| 5,3| IoCallback.cc(116) finish: called for
local=127.0.0.1:51409 remote=127.0.0.1:50005 FD 10 flags=1 (0, 0)

2016/05/31 16:55:25.178 kid1| 5,3| comm.cc(553) commSetConnTimeout: local=
127.0.0.1:51409 remote=127.0.0.1:50005 FD 10 flags=1 timeout 900

2016/05/31 16:55:25.178| 42,2| IcmpPinger.cc(211) SendResult: return result
to squid. len=7990

2016/05/31 16:55:25.178| 42,2| Icmp.cc(95) Log: pingerLog:
1464728125.178565 127.0.0.1                                     0 Echo
Reply      0ms 1 hops

2016/05/31 16:55:25.178 kid1| 38,3| net_db.cc(931) netdbHandlePingReply:
netdbHandlePingReply: from 127.0.0.1

2016/05/31 16:55:25.178 kid1| 38,3| net_db.cc(950) netdbHandlePingReply:
netdbHandlePingReply: 127.0.0.0; rtt= 1.00  hops=1.00

2016/05/31 16:55:25.180 kid1| 5,3| Read.cc(144) HandleRead: FD 10, size
16383, retval 99, errno 0

2016/05/31 16:55:25.180 kid1| 5,3| IoCallback.cc(116) finish: called for
local=127.0.0.1:51409 remote=127.0.0.1:50005 FD 10 flags=1 (0, 0)

2016/05/31 16:55:25.180 kid1| ctx: enter level  0: '
http://127.0.0.1:50005/squid-internal-dynamic/netdb'

2016/05/31 16:55:25.180 kid1| 11,3| http.cc(709) processReplyHeader:
processReplyHeader: key '8296497AA8EBFF11C70A96598AA18956'

2016/05/31 16:55:25.180 kid1| 11,2| http.cc(750) processReplyHeader: HTTP
Server local=127.0.0.1:51409 remote=127.0.0.1:50005 FD 10 flags=1

2016/05/31 16:55:25.180 kid1| 11,2| http.cc(751) processReplyHeader: HTTP
Server REPLY:

---------

HTTP/1.1 404 Not Found

Content-Length: 53


<html><body><h1>Resource not found</h1></body></html>

----------

2016/05/31 16:55:25.180 kid1| ctx: exit level  0

2016/05/31 16:55:25.180 kid1| 28,3| Checklist.cc(70) preCheck:
0x7f0f6689a1d8 checking slow rules

2016/05/31 16:55:25.180 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '[::]'
found

2016/05/31 16:55:25.180 kid1| 28,3| Acl.cc(158) matches: checked: all = 1

2016/05/31 16:55:25.180 kid1| 28,3| Acl.cc(158) matches: checked:
adaptation_access#1 = 1

2016/05/31 16:55:25.180 kid1| 28,3| Acl.cc(158) matches: checked:
adaptation_access = 1

2016/05/31 16:55:25.180 kid1| 28,3| Checklist.cc(63) markFinished:
0x7f0f6689a1d8 answer ALLOWED for match

2016/05/31 16:55:25.180 kid1| 28,3| Checklist.cc(163) checkCallback:
ACLChecklist::checkCallback: 0x7f0f6689a1d8 answer=ALLOWED

2016/05/31 16:55:25.180 kid1| 93,3| AccessCheck.cc(196) callBack:
0x7f0f66898b50*2

2016/05/31 16:55:25.180 kid1| 11,3| http.cc(1065) persistentConnStatus:
local=127.0.0.1:51409 remote=127.0.0.1:50005 FD 10 flags=1 eof=0

2016/05/31 16:55:25.180 kid1| 5,3| comm.cc(579) commUnsetConnTimeout:
Remove timeout for local=127.0.0.1:51409 remote=127.0.0.1:50005 FD 10
flags=1

2016/05/31 16:55:25.180 kid1| 5,3| comm.cc(553) commSetConnTimeout: local=
127.0.0.1:51409 remote=127.0.0.1:50005 FD 10 flags=1 timeout -1

2016/05/31 16:55:25.180 kid1| 17,3| FwdState.cc(447) unregister:
http://127.0.0.1:50005/squid-internal-dynamic/netdb

2016/05/31 16:55:25.180 kid1| 48,3| pconn.cc(413) push: new IdleConnList
for {127.0.0.1:50005/127.0.0.1}

2016/05/31 16:55:25.180 kid1| 5,3| comm.cc(553) commSetConnTimeout: local=
127.0.0.1:51409 remote=127.0.0.1:50005 FD 10 flags=1 timeout 60

2016/05/31 16:55:25.180 kid1| 48,3| pconn.cc(425) push: pushed local=
127.0.0.1:51409 remote=127.0.0.1:50005 FD 10 flags=1 for
127.0.0.1:50005/127.0.0.1

2016/05/31 16:55:25.180 kid1| 93,3| Xaction.cc(60) Xaction:
Adaptation::Icap::ModXact constructed, this=0x7f0f6689c5b8 [icapxjob9]

2016/05/31 16:55:25.181 kid1| 93,3| Xaction.cc(60) Xaction:
Adaptation::Icap::OptXact constructed, this=0x7f0f668bde58 [icapxjob11]

2016/05/31 16:55:25.181 kid1| 93,3| ServiceRep.cc(122) getConnection: got
connection:

2016/05/31 16:55:25.181 kid1| 93,3| Xaction.cc(145) openConnection:
Adaptation::Icap::OptXact opens connection to *short.domain.name*
<http://short.domain.name/>:1344

2016/05/31 16:55:25.181 kid1| 14,3| Address.cc(389) lookupHostIP: Given
Non-IP '*short.domain.name* <http://short.domain.name/>': Name or service
not known

2016/05/31 16:55:25.181 kid1| 78,3| dns_internal.cc(1745) idnsALookup:
idnsALookup: buf is 44 bytes for *short.domain.name*
<http://short.domain.name/>, id = 0x5c1f

2016/05/31 16:55:25.181 kid1| 50,3| comm.cc(957) comm_udp_sendto:
comm_udp_sendto: Attempt to send UDP packet to 10.42.70.144:53 using FD 8
using Port 43651

2016/05/31 16:55:25.181 kid1| 78,3| dns_internal.cc(1683)
idnsSendSlaveAAAAQuery: buf is 44 bytes for *short.domain.name*
<http://short.domain.name/>, id = 0xd1ee

2016/05/31 16:55:25.181 kid1| 50,3| comm.cc(957) comm_udp_sendto:
comm_udp_sendto: Attempt to send UDP packet to 10.42.70.144:53 using FD 8
using Port 43651

2016/05/31 16:55:25.181 kid1| 93,3| Xaction.cc(71) ~Xaction:
Adaptation::Icap::OptXact destructed, this=0x7f0f668bde58 [icapxjob11]

2016/05/31 16:55:25.181 kid1| 93,3| Launcher.cc(95) noteXactAbort: cannot
retry or repeat a failed transaction

2016/05/31 16:55:25.181 kid1| 93,3| ServiceRep.cc(534)
noteAdaptationAnswer: failed to fetch options [down,!opt]

2016/05/31 16:55:25.181 kid1| essential ICAP service is down after an
options fetch failure: icap://*short.domain.name*
<http://short.domain.name/>:1344 [down,!opt]

2016/05/31 16:55:25.181 kid1| 93,3| ServiceRep.cc(571) handleNewOptions:
got new options and is now [down,!opt]

2016/05/31 16:55:25.182 kid1| 93,3| ../../../src/base/AsyncJobCalls.h(177)
dial: Adaptation::Icap::ModXact::noteServiceReady threw exception: ICAP
service is unusable

2016/05/31 16:55:25.182 kid1| 93,3| Xaction.cc(71) ~Xaction:
Adaptation::Icap::ModXact destructed, this=0x7f0f6689c5b8 [icapxjob9]

2016/05/31 16:55:25.182 kid1| 93,3| Launcher.cc(95) noteXactAbort: cannot
retry or repeat a failed transaction

2016/05/31 16:55:25.182 kid1| 17,3| FwdState.cc(416) fail: ERR_ICAP_FAILURE
"Internal Server Error"

http://127.0.0.1:50005/squid-internal-dynamic/netdb

2016/05/31 16:55:25.182 kid1| 17,2| FwdState.cc(655)
handleUnregisteredServerEnd: self=0x7f0f6646dee8*2 err=0x7f0f668bda78
http://127.0.0.1:50005/squid-internal-dynamic/netdb

2016/05/31 16:55:25.182 kid1| 20,3| store.cc(521) unlock: Client unlocking
key 8296497AA8EBFF11C70A96598AA18956 e:=p2XDIWV/0x7f0f66898f80*3

2016/05/31 16:55:25.182 kid1| 17,3| FwdState.cc(266) ~FwdState: FwdState
destructor starting

2016/05/31 16:55:25.182 kid1| 4,2| errorpage.cc(1262) BuildContent: No
existing error page language negotiated for ERR_ICAP_FAILURE. Using default
error file.

2016/05/31 16:55:25.182 kid1| 4,3| errorpage.cc(1101) Convert:
errorConvert: %%l --> '/*

 * Copyright (C) 1996-2016 The Squid Software Foundation and contributors

 *

 * Squid software is distributed under GPLv2+ license and includes

 * contributions from numerous individuals and organizations.

 * Please see the COPYING and CONTRIBUTORS files for details.

 */


/*

 Stylesheet for Squid Error pages

 Adapted from design by Free CSS Templates

 http://www.freecsstemplates.org

 Released for free under a Creative Commons Attribution 2.5 License

*/


/* Page basics */

* {

font-family: verdana, sans-serif;

}


html body {

margin: 0;

padding: 0;

background: #efefef;

font-size: 12px;

color: #1e1e1e;

}


/* Page displayed title area */

#titles {

margin-left: 15px;

padding: 10px;

padding-left: 100px;

background: url('/squid-internal-static/icons/SN.png') no-repeat left;

}


/* initial title */

#titles h1 {

color: #000000;

}

#titles h2 {

color: #000000;

}


/* special event: FTP success page titles */

#titles ftpsuccess {

background-color:#00ff00;

width:100%;

}


/* Page displayed body content area */

#content {

padding: 10px;

background: #ffffff;

}


/* General text */

p {

}


/* error brief description */

#error p {

}


/* some data which may have caused the problem */

#data {

}


/* the error message received from the system or other software */

#sysmsg {

}


pre {

    font-family:sans-serif;

}


/* special event: FTP / Gopher directory listing */

#dirmsg {

    font-family: courier;

    color: black;

    font-size: 10pt;

}

#dirlisting {

    margin-left: 2%;

    margin-right: 2%;

}

#dirlisting tr.entry td.icon,td.filename,td.size,td.date {

    border-bottom: groove;

}

#dirlisting td.size {

    width: 50px;

    text-align: right;

    padding-right: 5px;

}


/* horizontal lines */

hr {

margin: 0;

}


/* page displayed footer area */

#footer {

font-size: 9px;

padding-left: 10px;

}

'

2016/05/31 16:55:25.182 kid1| 4,3| errorpage.cc(1101) Convert:
errorConvert: %%; --> '%;'

2016/05/31 16:55:25.182 kid1| 4,3| errorpage.cc(1101) Convert:
errorConvert: %%c --> 'ERR_ICAP_FAILURE'

2016/05/31 16:55:25.182 kid1| 4,3| errorpage.cc(1101) Convert:
errorConvert: %%U --> '
http://PASSTHRU at 127.0.0.1:50005/squid-internal-dynamic/netdb'

2016/05/31 16:55:25.182 kid1| 4,3| errorpage.cc(1101) Convert:
errorConvert: %%U --> '
http://PASSTHRU at 127.0.0.1:50005/squid-internal-dynamic/netdb'

2016/05/31 16:55:25.182 kid1| 4,3| errorpage.cc(1101) Convert:
errorConvert: %%E --> '[No Error]'

2016/05/31 16:55:25.182 kid1| 4,3| errorpage.cc(1101) Convert:
errorConvert: %%T --> 'Tue, 31 May 2016 20:55:25 GMT'

2016/05/31 16:55:25.182 kid1| 4,3| errorpage.cc(1101) Convert:
errorConvert: %%h --> 'SLES12-001-0'

2016/05/31 16:55:25.182 kid1| 4,3| errorpage.cc(1101) Convert:
errorConvert: %%s --> 'squid/3.5.16'

2016/05/31 16:55:25.182 kid1| 4,3| errorpage.cc(1101) Convert:
errorConvert: %%c --> 'ERR_ICAP_FAILURE'

2016/05/31 16:55:25.182 kid1| 20,3| store.cc(483) lock:
StoreEntry::storeErrorResponse locked key 8296497AA8EBFF11C70A96598AA18956
e:=p2XDIWV/0x7f0f66898f80*3

2016/05/31 16:55:25.182 kid1| 20,3| store.cc(1862) replaceHttpReply:
StoreEntry::replaceHttpReply:
http://127.0.0.1:50005/squid-internal-dynamic/netdb

2016/05/31 16:55:25.182 kid1| 20,2| store.cc(949) checkCachable:
StoreEntry::checkCachable: NO: not cachable

2016/05/31 16:55:25.182 kid1| 90,3| store_client.cc(732) invokeHandlers:
InvokeHandlers: 8296497AA8EBFF11C70A96598AA18956

2016/05/31 16:55:25.182 kid1| 90,3| store_client.cc(738) invokeHandlers:
StoreEntry::InvokeHandlers: checking client #0

2016/05/31 16:55:25.182 kid1| 90,3| store_client.cc(297) storeClientCopy2:
storeClientCopy2: 8296497AA8EBFF11C70A96598AA18956

2016/05/31 16:55:25.182 kid1| 90,3| store_client.cc(433) scheduleMemRead:
store_client::doCopy: Copying normal from memory

2016/05/31 16:55:25.182 kid1| 38,3| net_db.cc(689)
netdbExchangeHandleReply: netdbExchangeHandleReply: 3490 read bytes

2016/05/31 16:55:25.182 kid1| 38,3| net_db.cc(697)
netdbExchangeHandleReply: netdbExchangeHandleReply: for '127.0.0.1:50005'

2016/05/31 16:55:25.182 kid1| 38,3| net_db.cc(710)
netdbExchangeHandleReply: netdbExchangeHandleReply: 3490 bytes buf

2016/05/31 16:55:25.182 kid1| 38,3| net_db.cc(724)
netdbExchangeHandleReply: netdbExchangeHandleReply: reply status 500

2016/05/31 16:55:25.182 kid1| 38,3| net_db.cc(865) netdbExchangeDone:
netdbExchangeDone: http://127.0.0.1:50005/squid-internal-dynamic/netdb

2016/05/31 16:55:25.183 kid1| 90,3| store_client.cc(664) storeUnregister:
storeUnregister: called for '8296497AA8EBFF11C70A96598AA18956'

2016/05/31 16:55:25.183 kid1| 20,3| store.cc(483) lock: storeUnregister
locked key 8296497AA8EBFF11C70A96598AA18956 e:=p2XDIV/0x7f0f66898f80*4

2016/05/31 16:55:25.183 kid1| 90,3| store_client.cc(758)
storePendingNClients: storePendingNClients: returning 0

2016/05/31 16:55:25.183 kid1| 90,3| store_client.cc(768)
CheckQuickAbortIsReasonable: entry=0x7f0f66898f80, mem=0x7f0f6646d960

2016/05/31 16:55:25.183 kid1| 90,3| store_client.cc(771)
CheckQuickAbortIsReasonable: quick-abort? YES !mem->request->flags.cachable

2016/05/31 16:55:25.183 kid1| 20,3| store.cc(483) lock: StoreEntry::abort
locked key 8296497AA8EBFF11C70A96598AA18956 e:=p2XDIV/0x7f0f66898f80*5

2016/05/31 16:55:25.183 kid1| 90,3| store_client.cc(732) invokeHandlers:
InvokeHandlers: 8296497AA8EBFF11C70A96598AA18956

2016/05/31 16:55:25.183 kid1| 20,3| store_swapout.cc(273) swapOutFileClose:
storeSwapOutFileClose: 8296497AA8EBFF11C70A96598AA18956 how=1

2016/05/31 16:55:25.183 kid1| 20,3| store_swapout.cc(274) swapOutFileClose:
storeSwapOutFileClose: sio = 0

2016/05/31 16:55:25.183 kid1| 20,3| store.cc(521) unlock: StoreEntry::abort
unlocking key 8296497AA8EBFF11C70A96598AA18956 e:=sp2XDINVA/0x7f0f66898f80*5

2016/05/31 16:55:25.183 kid1| 20,3| store.cc(521) unlock: storeUnregister
unlocking key 8296497AA8EBFF11C70A96598AA18956 e:=sp2XDINVA/0x7f0f66898f80*4

2016/05/31 16:55:25.183 kid1| 20,3| store.cc(521) unlock: netdbExchangeDone
unlocking key 8296497AA8EBFF11C70A96598AA18956 e:=sp2XDINVA/0x7f0f66898f80*3

2016/05/31 16:55:25.183 kid1| 20,3| store.cc(1048) complete: storeComplete:
'8296497AA8EBFF11C70A96598AA18956'

2016/05/31 16:55:25.183 kid1| 20,3| store.cc(521) unlock:
StoreEntry::storeErrorResponse unlocking key
8296497AA8EBFF11C70A96598AA18956 e:=sp2XDINVA/0x7f0f66898f80*2

2016/05/31 16:55:25.183 kid1| 90,3| store_client.cc(758)
storePendingNClients: storePendingNClients: returning 0

2016/05/31 16:55:25.183 kid1| 20,3| store.cc(521) unlock: FwdState
unlocking key 8296497AA8EBFF11C70A96598AA18956 e:=sp2XDINVA/0x7f0f66898f80*1

2016/05/31 16:55:25.183 kid1| 90,3| store_client.cc(758)
storePendingNClients: storePendingNClients: returning 0

2016/05/31 16:55:25.183 kid1| 20,3| store.cc(1239) release: releasing
e:=sp2XDINVA/0x7f0f66898f80*0 8296497AA8EBFF11C70A96598AA18956

2016/05/31 16:55:25.183 kid1| 20,3| store.cc(402) destroyMemObject:
destroyMemObject 0x7f0f6646d960

2016/05/31 16:55:25.183 kid1| 20,3| MemObject.cc(110) ~MemObject: del
MemObject 0x7f0f6646d960

2016/05/31 16:55:25.183 kid1| 20,3| store.cc(420) destroyStoreEntry:
destroyStoreEntry: destroying 0x7f0f66898f88

2016/05/31 16:55:25.183 kid1| 20,3| store.cc(402) destroyMemObject:
destroyMemObject 0

2016/05/31 16:55:25.183 kid1| 17,3| AsyncCall.cc(56) cancel: will not call
fwdConnectDoneWrapper [call52] because FwdState destructed

2016/05/31 16:55:25.183 kid1| 17,3| FwdState.cc(293) ~FwdState: FwdState
destructor done

2016/05/31 16:55:25.183 kid1| 78,3| dns_internal.cc(1277) idnsRead:
idnsRead: starting with FD 8

2016/05/31 16:55:25.183 kid1| 78,3| dns_internal.cc(1323) idnsRead:
idnsRead: FD 8: received 60 bytes from 10.42.70.144:53

2016/05/31 16:55:25.183 kid1| 78,3| dns_internal.cc(1130) idnsGrokReply:
idnsGrokReply: QID 0x5c1f, 1 answers

2016/05/31 16:55:25.183 kid1| 78,3| dns_internal.cc(1323) idnsRead:
idnsRead: FD 8: received 104 bytes from 10.42.70.144:53

2016/05/31 16:55:25.183 kid1| 78,3| dns_internal.cc(1130) idnsGrokReply:
idnsGrokReply: QID 0xd1ee, 0 answers

2016/05/31 16:55:25.183 kid1| 14,3| ipcache.cc(364) ipcacheParse:
ipcacheParse: 1 answers for '*short.domain.name* <http://short.domain.name/>
'

2016/05/31 16:55:25.183 kid1| 14,3| ipcache.cc(422) ipcacheParse:
ipcacheParse: *short.domain.name* <http://short.domain.name/> #0 10.44.3.1

2016/05/31 16:56:25.231 kid1| 48,3| pconn.cc(310) Timeout: local=
127.0.0.1:51409 remote=127.0.0.1:50005 FD 10 flags=1

2016/05/31 16:56:25.231 kid1| 48,3| pconn.cc(70) findIndexOf: found local=
127.0.0.1:51409 remote=127.0.0.1:50005 FD 10 flags=1 at index 0

2016/05/31 16:56:25.231 kid1| 48,3| pconn.cc(156) clearHandlers: removing
close handler for local=127.0.0.1:51409 remote=127.0.0.1:50005 FD 10 flags=1

2016/05/31 16:56:25.231 kid1| 5,3| comm.cc(579) commUnsetConnTimeout:
Remove timeout for local=127.0.0.1:51409 remote=127.0.0.1:50005 FD 10
flags=1

2016/05/31 16:56:25.231 kid1| 5,3| comm.cc(553) commSetConnTimeout: local=
127.0.0.1:51409 remote=127.0.0.1:50005 FD 10 flags=1 timeout -1

2016/05/31 16:56:25.231 kid1| 48,3| pconn.cc(97) removeAt: deleting
127.0.0.1:50005/127.0.0.1

2016/05/31 16:56:25.231 kid1| 5,3| comm.cc(868) _comm_close: comm_close:
start closing FD 10

2016/05/31 16:56:25.232 kid1| 5,3| comm.cc(540) commUnsetFdTimeout: Remove
timeout for FD 10

2016/05/31 16:56:25.232 kid1| 51,3| fd.cc(93) fd_close: fd_close FD 10 Idle
server: 127.0.0.1:50005/127.0.0.1

2016/05/31 16:58:25.182 kid1| 93,3| Xaction.cc(60) Xaction:
Adaptation::Icap::OptXact constructed, this=0x7f0f668bde58 [icapxjob13]

2016/05/31 16:58:25.182 kid1| 93,3| ServiceRep.cc(122) getConnection: got
connection:

2016/05/31 16:58:25.182 kid1| 93,3| Xaction.cc(145) openConnection:
Adaptation::Icap::OptXact opens connection to *short.domain.name*
<http://short.domain.name/>:1344

2016/05/31 16:58:25.182 kid1| 14,3| Address.cc(389) lookupHostIP: Given
Non-IP '*short.domain.name* <http://short.domain.name/>': Name or service
not known

2016/05/31 16:58:25.182 kid1| 93,3| AsyncCall.cc(26) AsyncCall: The
AsyncCall Adaptation::Icap::Xaction::noteCommConnected constructed,
this=0x7f0f6646fa60 [call502]

2016/05/31 16:58:25.182 kid1| 50,3| comm.cc(347) comm_openex: comm_openex:
Attempt open socket for: 0.0.0.0

2016/05/31 16:58:25.182 kid1| 50,3| comm.cc(388) comm_openex: comm_openex:
Opened socket local=0.0.0.0 remote=[::] FD 10 flags=1 : family=2, type=1,
protocol=6

2016/05/31 16:58:25.182 kid1| 51,3| fd.cc(198) fd_open: fd_open() FD 10
*short.domain.name* <http://short.domain.name/>

2016/05/31 16:58:25.182 kid1| 5,3| ConnOpener.cc(289) createFd:
local=0.0.0.0 remote=10.44.3.1:1344 flags=1 will timeout in 60

2016/05/31 16:58:25.184 kid1| 93,3| AsyncCall.cc(93) ScheduleCall:
ConnOpener.cc(137) will call
Adaptation::Icap::Xaction::noteCommConnected(local=10.44.3.21:57084 remote=
10.44.3.1:1344 <http://10.44.73.133:1344/> FD 10 flags=1,
data=0x7f0f668bde58) [call502]

2016/05/31 16:58:25.184 kid1| 93,3| AsyncCallQueue.cc(55) fireNext:
entering Adaptation::Icap::Xaction::noteCommConnected(local=10.44.3.21:57084
remote=10.44.3.1:1344 FD 10 flags=1, data=0x7f0f668bde58)

2016/05/31 16:58:25.184 kid1| 93,3| AsyncCall.cc(38) make: make call
Adaptation::Icap::Xaction::noteCommConnected [call502]

2016/05/31 16:58:25.184 kid1| 93,3| AsyncJob.cc(123) callStart:
Adaptation::Icap::OptXact status in: [FD 10;/ job13]

2016/05/31 16:58:25.184 kid1| 5,3| comm.cc(553) commSetConnTimeout: local=
10.44.3.21:57084 remote=10.44.3.1:1344 FD 10 flags=1 timeout 60

2016/05/31 16:58:25.184 kid1| 93,3| AsyncCall.cc(26) AsyncCall: The
AsyncCall Adaptation::Icap::Xaction::noteCommRead constructed,
this=0x7f0f665bb740 [call509]

2016/05/31 16:58:25.184 kid1| 5,3| comm.cc(553) commSetConnTimeout: local=
10.44.3.21:57084 remote=10.44.3.1:1344 FD 10 flags=1 timeout 900

2016/05/31 16:58:25.184 kid1| 23,3| url.cc(357) urlParse: urlParse: Split
URL 'icap://*short.domain.name* <http://short.domain.name/>:1344 ICAP/1.0

' into proto='icap', host='*short.domain.name* <http://short.domain.name/>',
port='1344', path=' ICAP/1.0'

2016/05/31 16:58:25.184 kid1| 23,2| url.cc(393) urlParse: urlParse: URI has
whitespace: {icap://*short.domain.name* <http://short.domain.name/>:1344
ICAP/1.0

}

2016/05/31 16:58:25.184 kid1| 14,3| Address.cc(389) lookupHostIP: Given
Non-IP '*short.domain.name* <http://short.domain.name/>': Name or service
not known

2016/05/31 16:58:25.185 kid1| 93,3| AsyncCall.cc(26) AsyncCall: The
AsyncCall Adaptation::Icap::Xaction::noteCommWrote constructed,
this=0x7f0f668e54a0 [call511]

2016/05/31 16:58:25.185 kid1| 5,3| comm.cc(553) commSetConnTimeout: local=
10.44.3.21:57084 remote=10.44.3.1:1344 FD 10 flags=1 timeout 900

2016/05/31 16:58:25.185 kid1| 93,3| AsyncJob.cc(152) callEnd:
Adaptation::Icap::OptXact status out: [FD 10wr;/ job13]

2016/05/31 16:58:25.185 kid1| 93,3| AsyncCallQueue.cc(57) fireNext: leaving
Adaptation::Icap::Xaction::noteCommConnected(local=10.44.3.21:57084 remote=
10.44.3.1:1344 FD 10 flags=1, data=0x7f0f668bde58)

2016/05/31 16:58:25.185 kid1| 5,3| IoCallback.cc(116) finish: called for
local=10.44.3.21:57084 remote=10.44.3.1:1344 FD 10 flags=1 (0, 0)

2016/05/31 16:58:25.185 kid1| 93,3| AsyncCall.cc(93) ScheduleCall:
IoCallback.cc(135) will call Adaptation::Icap::Xaction::noteCommWrote(local=
10.44.3.21:57084 <http://10.44.73.219:57084/> remote=10.44.3.1:1344
<http://10.44.73.133:1344/> FD 10 flags=1, data=0x7f0f668bde58) [call511]

2016/05/31 16:58:25.185 kid1| 93,3| AsyncCallQueue.cc(55) fireNext:
entering Adaptation::Icap::Xaction::noteCommWrote(local=10.44.3.21:57084
<http://10.44.73.219:57084/> remote=10.44.3.1:1344
<http://10.44.73.133:1344/> FD 10 flags=1, data=0x7f0f668bde58)

2016/05/31 16:58:25.185 kid1| 93,3| AsyncCall.cc(38) make: make call
Adaptation::Icap::Xaction::noteCommWrote [call511]

2016/05/31 16:58:25.185 kid1| 93,3| AsyncJob.cc(123) callStart:
Adaptation::Icap::OptXact status in: [FD 10wr;/ job13]

2016/05/31 16:58:25.185 kid1| 5,3| comm.cc(553) commSetConnTimeout: local=
10.44.3.21:57084 <http://10.44.73.219:57084/> remote=10.44.3.1:1344
<http://10.44.73.133:1344/> FD 10 flags=1 timeout 900

2016/05/31 16:58:25.185 kid1| 93,3| AsyncJob.cc(152) callEnd:
Adaptation::Icap::OptXact status out: [FD 10r;/ job13]

2016/05/31 16:58:25.185 kid1| 93,3| AsyncCallQueue.cc(57) fireNext: leaving
Adaptation::Icap::Xaction::noteCommWrote(local=10.44.3.21:57084
<http://10.44.73.219:57084/> remote=10.44.3.1:1344
<http://10.44.73.133:1344/> FD 10 flags=1, data=0x7f0f668bde58)

2016/05/31 16:58:25.185 kid1| 5,3| Read.cc(144) HandleRead: FD 10, size
65535, retval 222, errno 0

2016/05/31 16:58:25.185 kid1| 5,3| IoCallback.cc(116) finish: called for
local=10.44.3.21:57084 <http://10.44.73.219:57084/> remote=10.44.3.1:1344
<http://10.44.73.133:1344/> FD 10 flags=1 (0, 0)

2016/05/31 16:58:25.185 kid1| 93,3| AsyncCall.cc(93) ScheduleCall:
IoCallback.cc(135) will call Adaptation::Icap::Xaction::noteCommRead(local=
10.44.3.21:57084 <http://10.44.73.219:57084/> remote=10.44.3.1:1344
<http://10.44.73.133:1344/> FD 10 flags=1, data=0x7f0f668bde58, size=222,
buf=0x7f0f6689d4a0) [call509]

2016/05/31 16:58:25.185 kid1| 93,3| AsyncCallQueue.cc(55) fireNext:
entering Adaptation::Icap::Xaction::noteCommRead(local=10.44.3.21:57084
<http://10.44.73.219:57084/> remote=10.44.3.1:1344
<http://10.44.73.133:1344/> FD 10 flags=1, data=0x7f0f668bde58, size=222,
buf=0x7f0f6689d4a0)

2016/05/31 16:58:25.185 kid1| 93,3| AsyncCall.cc(38) make: make call
Adaptation::Icap::Xaction::noteCommRead [call509]

2016/05/31 16:58:25.185 kid1| 93,3| AsyncJob.cc(123) callStart:
Adaptation::Icap::OptXact status in: [FD 10r;/ job13]

2016/05/31 16:58:25.185 kid1| 5,3| comm.cc(579) commUnsetConnTimeout:
Remove timeout for local=10.44.3.21:57084 <http://10.44.73.219:57084/>
remote=10.44.3.1:1344 <http://10.44.73.133:1344/> FD 10 flags=1

2016/05/31 16:58:25.185 kid1| 5,3| comm.cc(553) commSetConnTimeout: local=
10.44.3.21:57084 <http://10.44.73.219:57084/> remote=10.44.3.1:1344
<http://10.44.73.133:1344/> FD 10 flags=1 timeout -1

2016/05/31 16:58:25.185 kid1| 93,3| Xaction.cc(425) noteCommRead: read 222
bytes

2016/05/31 16:58:25.185 kid1| 93,3| ServiceRep.cc(132) putConnection:
pushing pconn [FD 10;/ job13]

2016/05/31 16:58:25.185 kid1| 5,3| comm.cc(579) commUnsetConnTimeout:
Remove timeout for local=10.44.3.21:57084 <http://10.44.73.219:57084/>
remote=10.44.3.1:1344 <http://10.44.73.133:1344/> FD 10 flags=1

2016/05/31 16:58:25.185 kid1| 5,3| comm.cc(553) commSetConnTimeout: local=
10.44.3.21:57084 <http://10.44.73.219:57084/> remote=10.44.3.1:1344
<http://10.44.73.133:1344/> FD 10 flags=1 timeout -1

2016/05/31 16:58:25.185 kid1| 5,3| comm.cc(553) commSetConnTimeout: local=
10.44.3.21:57084 <http://10.44.73.219:57084/> remote=10.44.3.1:1344
<http://10.44.73.133:1344/> FD 10 flags=1 timeout 60

2016/05/31 16:58:25.185 kid1| 93,3| Xaction.cc(71) ~Xaction:
Adaptation::Icap::OptXact destructed, this=0x7f0f668bde58 [icapxjob13]

2016/05/31 16:58:25.185 kid1| 93,3| AsyncCallQueue.cc(57) fireNext: leaving
Adaptation::Icap::Xaction::noteCommRead(local=10.44.3.21:57084
<http://10.44.73.219:57084/> remote=10.44.3.1:1344
<http://10.44.73.133:1344/> FD 10 flags=1, data=0x7f0f668bde58, size=222,
buf=0x7f0f6689d4a0)

2016/05/31 16:58:25.185 kid1| essential ICAP service is up: icap://
*short.domain.name* <http://short.domain.name/>:1344 [up]

2016/05/31 16:58:25.185 kid1| 93,3| ServiceRep.cc(571) handleNewOptions:
got new options and is now [up]

2016/05/31 16:59:25.401 kid1| 48,3| pconn.cc(310) Timeout: local=
10.44.3.21:57084 <http://10.44.73.219:57084/> remote=10.44.3.1:1344
<http://10.44.73.133:1344/> FD 10 flags=1

2016/05/31 16:59:25.401 kid1| 48,3| pconn.cc(70) findIndexOf: found local=
10.44.3.21:57084 <http://10.44.73.219:57084/> remote=10.44.3.1:1344
<http://10.44.73.133:1344/> FD 10 flags=1 at index 0

2016/05/31 16:59:25.401 kid1| 48,3| pconn.cc(156) clearHandlers: removing
close handler for local=10.44.3.21:57084 <http://10.44.73.219:57084/>
remote=10.44.3.1:1344 <http://10.44.73.133:1344/> FD 10 flags=1

2016/05/31 16:59:25.402 kid1| 5,3| comm.cc(579) commUnsetConnTimeout:
Remove timeout for local=10.44.3.21:57084 <http://10.44.73.219:57084/>
remote=10.44.3.1:1344 <http://10.44.73.133:1344/> FD 10 flags=1

2016/05/31 16:59:25.402 kid1| 5,3| comm.cc(553) commSetConnTimeout: local=
10.44.3.21:57084 <http://10.44.73.219:57084/> remote=10.44.3.1:1344
<http://10.44.73.133:1344/> FD 10 flags=1 timeout -1

2016/05/31 16:59:25.402 kid1| 5,3| comm.cc(868) _comm_close: comm_close:
start closing FD 10

2016/05/31 16:59:25.402 kid1| 5,3| comm.cc(540) commUnsetFdTimeout: Remove
timeout for FD 10

2016/05/31 16:59:25.402 kid1| 51,3| fd.cc(93) fd_close: fd_close FD 10
*short.domain.name* <http://short.domain.name/>

2016/05/31 17:35:05 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state

2016/05/31 17:35:05.157 kid1| 51,3| fd.cc(198) fd_open: fd_open() FD 10
/var/log/squid/netdb.state

2016/05/31 17:35:05.157 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state

2016/05/31 17:35:05.157 kid1| 51,3| fd.cc(93) fd_close: fd_close FD 10
/var/log/squid/netdb.state

2016/05/31 17:35:05.157 kid1| NETDB state saved; 1 entries, 0 msec



Thanks

Aashima
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160531/da498cfe/attachment.htm>

From yvoinov at gmail.com  Tue May 31 22:26:58 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 1 Jun 2016 04:26:58 +0600
Subject: [squid-users] Ciphersuites with SSL bump [squid 3.5.19]
In-Reply-To: <573F22C7.5000909@mathemainzel.info>
References: <573F22C7.5000909@mathemainzel.info>
Message-ID: <6a615373-4852-4610-6037-1bf49678e6eb@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
sslproxy_cipher
!DH-DSS-MISTY1-SHA:!DH-RSA-MISTY1-SHA:!SSLv2:+SSLv3:!AECDH:!ADH:!DES:HIGH:+3DES:!RC4:!MD5:!aNULL:!eNULL:!LOW:!EXP:!DSS:!PSK:!SEED:!SRP


20.05.2016 20:44, Walter H. ?????:
> sslproxy_cipher !SSLv2:+SSLv3:!AECDH:!ADH:!DES:HIGH:+3DES:!RC4:!MD5:!aNULL:!eNULL:!LOW:!EXP:!DSS:!PSK:!SEED:!SRP

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXTg+yAAoJENNXIZxhPexGy08H/j2Rw1ds8trFovsc0hsDe1J0
++D/88+7G9Ess3/VPXxx2cMIzoRGbL8a6PTP4H9x8eLpfpXGN/EmkvWoXnxAxdgy
x60D/+EFfiTEfuNdtUtSzFjObTPnXiTZ4Ykgky7F8323FeLkoyZy2DWuAFGqKSa5
iakhQjfcCKV+CYKY1QjMxI2fojCAMsZezg+wJCwxwL6ahg3+VcP8xEKXPQF+cIVE
pphe866LL5uvv+6d9vaKeOhuq4nG2HEn6eCdEivEfnp7sTR3ZEFYpJzfZbdjoUDI
bVHREa4LUGPSzMN/xQNP0WlEeVh2lhLxnssorQNrR8pEzrikhGeLalGgebl+FRQ=
=H9W7
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160601/c91f4d22/attachment.key>

