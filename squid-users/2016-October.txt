From darren.j.breeze.ml at gmail.com  Sat Oct  1 01:02:15 2016
From: darren.j.breeze.ml at gmail.com (Darren)
Date: Sat, 01 Oct 2016 09:02:15 +0800
Subject: [squid-users] Large text ACL lists
In-Reply-To: <8cee8f0b-bd35-4f76-828b-8fd497c1a4c8@getmailbird.com>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <2c1e0a65-e688-183f-b83e-4fbbfa6d4539@treenet.co.nz>
 <54ee7d9a-96fe-4233-8db7-3b891455f07f@getmailbird.com>
 <35c4e399-1050-06c7-1715-e0c1252955a4@treenet.co.nz>
 <97de62ef-9f55-cb69-2031-4ef56c902d5d@gmail.com>
 <8cee8f0b-bd35-4f76-828b-8fd497c1a4c8@getmailbird.com>
Message-ID: <a7d4ee77-25f0-4bec-aba5-c74336798e70@getmailbird.com>

One further question

If I have to reload the ACL lists do I restart squid or is there a way to update without impacting the users to much?

In some of the scenarios, some acl lists may change frequently

thanks again.



Sent from Mailbird [http://www.getmailbird.com/?utm_source=Mailbird&amp;utm_medium=email&amp;utm_campaign=sent-from-mailbird]
On 1/10/2016 6:05:05 AM, Darren <darren.j.breeze.ml at gmail.com> wrote:
Hi

My main issue with squid guard is that when I try and block say www.facebook.com and the user goes to https://www.facebook.com, squidguard only sees the initial CONNECT as the target IP so doesn't match against the domain entry.

If squidguard did a reverse DNS lookup, I could keep using that more complex filtering solution. That is where the dstdomain acl is a better option but has the ram overhead.

Time for some experimentation

thanks again for the feedback




Sent from Mailbird [http://www.getmailbird.com/?utm_source=Mailbird&amp;utm_medium=email&amp;utm_campaign=sent-from-mailbird]
On 30/09/2016 7:21:53 PM, Yuri Voinov <yvoinov at gmail.com> wrote:

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

Amos, I'm afraid that this is not a solution. Block lists have become so
huge that only their compression and / or placement in an external
database (as Marcus) can save the situation.


30.09.2016 12:59, Amos Jeffries ?????:
> On 30/09/2016 6:58 p.m., Darren wrote:
>> Thank you Amos
>>
>> The resources I save not running multiple Squidguards will make more
>> ram available as you say and having a simpler setup is never a bad
>> thing either.
>>
>> Just to clarify, so when squid fires up, it caches the ACL file into
>> ram in it's entirety and then does some optimizations? If that is
>> the case I would need to budget the ram to allow for this.
>
> Not quite. Squid still reads the files line by line into a memory
> structure for whatever type of ACL is being loaded. That is part of why
> its so much slowe to load than the helpers (which generally do as you
> describe).
>
> The optimizations are type dependent and fairly simplistic. Ignoring
> duplicate entries, catenating regex into bigger " A|B " patterns (faster
> to check against), etc.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBCAAGBQJX7kq8AAoJENNXIZxhPexGH+cH/jmZsQlcZgXpwt62pHDtHp4t
TWDnhr5KOfHv+GFeBUmJYuD2nn8wefb5KUUhea5fdpRAeDihFDQDPQDwAnaC/E5q
FzE68zh+nF13xVwTW9/5mQhK75G17mOGJPGFPn1ZUC3lf/Q2JCOhWB+0MFilXXcQ
/ptCeQII/E8oXaiBOvHPzasOp6eDnu/m51q0DnkfoUceEWap9W0rY/vKxwL32FI9
fjqoZGGBPt3FDczjb8/9X6trqeGBwUl4PKSTE4JSdyU6z52evaCSsVbEgAmw+LjI
ELCBPOuU7buFxNjCSNLVhDNQeZJFJxPV8Oh/OcDQZQDhdUYliEwRke5Sz+Rz37k=
=hFD2
-----END PGP SIGNATURE-----

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161001/b9b63181/attachment.htm>

From webmaster at squidblacklist.org  Sat Oct  1 01:11:55 2016
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Fri, 30 Sep 2016 20:11:55 -0500
Subject: [squid-users] Large text ACL lists
In-Reply-To: <a7d4ee77-25f0-4bec-aba5-c74336798e70@getmailbird.com>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <2c1e0a65-e688-183f-b83e-4fbbfa6d4539@treenet.co.nz>
 <54ee7d9a-96fe-4233-8db7-3b891455f07f@getmailbird.com>
 <35c4e399-1050-06c7-1715-e0c1252955a4@treenet.co.nz>
 <97de62ef-9f55-cb69-2031-4ef56c902d5d@gmail.com>
 <8cee8f0b-bd35-4f76-828b-8fd497c1a4c8@getmailbird.com>
 <a7d4ee77-25f0-4bec-aba5-c74336798e70@getmailbird.com>
Message-ID: <c1ac26e2-e9a1-c556-d0cc-3bdbb057c53a@squidblacklist.org>

I would recommend you stop squid and start it, simply doing a -k 
reconfigure is a bad idea, because sometimes squid will not reload the 
new blacklists, I have no idea why it is unpredictable in this manner or 
if they have fixed this problem, I didnt write the software, but what I 
do know, in my experience, is that the most reliable way to ensure the 
lists actually get reloaded when using large acl domain lists in the 
manner you are, is to stop squid3 and start , which is also kinda lame 
because it takes longer, but its sure to work.

Anyway thats my two cents.


On 9/30/2016 8:02 PM, Darren wrote:
> One further question
>
> If I have to reload the ACL lists do I restart squid or is there a way 
> to update without impacting the users to much?
>
> In some of the scenarios, some acl lists may change frequently
>
> thanks again.
>
>
>
> Sent from Mailbird 
> <http://www.getmailbird.com/?utm_source=Mailbird&utm_medium=email&utm_campaign=sent-from-mailbird>
>>
>> On 1/10/2016 6:05:05 AM, Darren <darren.j.breeze.ml at gmail.com> wrote:
>>
>> Hi
>>
>> My main issue with squid guard is that when I try and block say 
>> www.facebook.com and the user goes to https://www.facebook.com, 
>> squidguard only sees the initial CONNECT as the target IP so doesn't 
>> match against the domain entry.
>>
>> If squidguard did a reverse DNS lookup, I could keep using that more 
>> complex filtering solution. That is where the dstdomain acl is a 
>> better option but has the ram overhead.
>>
>> Time for some experimentation
>>
>> thanks again for the feedback
>>
>>
>>
>>
>> Sent from Mailbird 
>> <http://www.getmailbird.com/?utm_source=Mailbird&utm_medium=email&utm_campaign=sent-from-mailbird>
>>>
>>> On 30/09/2016 7:21:53 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>>>
>>>
>>> -----BEGIN PGP SIGNED MESSAGE-----
>>> Hash: SHA256
>>>
>>> Amos, I'm afraid that this is not a solution. Block lists have 
>>> become so
>>> huge that only their compression and / or placement in an external
>>> database (as Marcus) can save the situation.
>>>
>>>
>>> 30.09.2016 12:59, Amos Jeffries ?????:
>>> > On 30/09/2016 6:58 p.m., Darren wrote:
>>> >> Thank you Amos
>>> >>
>>> >> The resources I save not running multiple Squidguards will make more
>>> >> ram available as you say and having a simpler setup is never a bad
>>> >> thing either.
>>> >>
>>> >> Just to clarify, so when squid fires up, it caches the ACL file into
>>> >> ram in it's entirety and then does some optimizations? If that is
>>> >> the case I would need to budget the ram to allow for this.
>>> >
>>> > Not quite. Squid still reads the files line by line into a memory
>>> > structure for whatever type of ACL is being loaded. That is part 
>>> of why
>>> > its so much slowe to load than the helpers (which generally do as you
>>> > describe).
>>> >
>>> > The optimizations are type dependent and fairly simplistic. Ignoring
>>> > duplicate entries, catenating regex into bigger " A|B " patterns 
>>> (faster
>>> > to check against), etc.
>>> >
>>> > Amos
>>> >
>>> > _______________________________________________
>>> > squid-users mailing list
>>> > squid-users at lists.squid-cache.org
>>> > http://lists.squid-cache.org/listinfo/squid-users
>>>
>>> -----BEGIN PGP SIGNATURE-----
>>> Version: GnuPG v2
>>>
>>> iQEcBAEBCAAGBQJX7kq8AAoJENNXIZxhPexGH+cH/jmZsQlcZgXpwt62pHDtHp4t
>>> TWDnhr5KOfHv+GFeBUmJYuD2nn8wefb5KUUhea5fdpRAeDihFDQDPQDwAnaC/E5q
>>> FzE68zh+nF13xVwTW9/5mQhK75G17mOGJPGFPn1ZUC3lf/Q2JCOhWB+0MFilXXcQ
>>> /ptCeQII/E8oXaiBOvHPzasOp6eDnu/m51q0DnkfoUceEWap9W0rY/vKxwL32FI9
>>> fjqoZGGBPt3FDczjb8/9X6trqeGBwUl4PKSTE4JSdyU6z52evaCSsVbEgAmw+LjI
>>> ELCBPOuU7buFxNjCSNLVhDNQeZJFJxPV8Oh/OcDQZQDhdUYliEwRke5Sz+Rz37k=
>>> =hFD2
>>> -----END PGP SIGNATURE-----
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
--

Signed,

Benjamin E. Nichols
http://www.squidblacklist.org

1-405-397-1360 - Call Anytime.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/4e7a7bcb/attachment.htm>

From webmaster at squidblacklist.org  Sat Oct  1 01:16:30 2016
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Fri, 30 Sep 2016 20:16:30 -0500
Subject: [squid-users] Large text ACL lists
In-Reply-To: <a7d4ee77-25f0-4bec-aba5-c74336798e70@getmailbird.com>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <2c1e0a65-e688-183f-b83e-4fbbfa6d4539@treenet.co.nz>
 <54ee7d9a-96fe-4233-8db7-3b891455f07f@getmailbird.com>
 <35c4e399-1050-06c7-1715-e0c1252955a4@treenet.co.nz>
 <97de62ef-9f55-cb69-2031-4ef56c902d5d@gmail.com>
 <8cee8f0b-bd35-4f76-828b-8fd497c1a4c8@getmailbird.com>
 <a7d4ee77-25f0-4bec-aba5-c74336798e70@getmailbird.com>
Message-ID: <38d1754c-5f13-a26e-3f7b-48f75da2547a@squidblacklist.org>

Also if you are going to use Squid Native ACL blacklists and reload 
while you are updating, its a good idea to have a parent proxy 
configured, so that your traffic/users wont be interrupted, squid will 
default to the next available proxy while its unavailable/reloading the 
blacklists and forward traffic to it, otherwise your proxy will be down 
during the reload process and your users will be without the ability to 
surf.




On 9/30/2016 8:02 PM, Darren wrote:
> One further question
>
> If I have to reload the ACL lists do I restart squid or is there a way 
> to update without impacting the users to much?
>
> In some of the scenarios, some acl lists may change frequently
>
> thanks again.
>
>
>
> Sent from Mailbird 
> <http://www.getmailbird.com/?utm_source=Mailbird&utm_medium=email&utm_campaign=sent-from-mailbird>
>>
>> On 1/10/2016 6:05:05 AM, Darren <darren.j.breeze.ml at gmail.com> wrote:
>>
>> Hi
>>
>> My main issue with squid guard is that when I try and block say 
>> www.facebook.com and the user goes to https://www.facebook.com, 
>> squidguard only sees the initial CONNECT as the target IP so doesn't 
>> match against the domain entry.
>>
>> If squidguard did a reverse DNS lookup, I could keep using that more 
>> complex filtering solution. That is where the dstdomain acl is a 
>> better option but has the ram overhead.
>>
>> Time for some experimentation
>>
>> thanks again for the feedback
>>
>>
>>
>>
>> Sent from Mailbird 
>> <http://www.getmailbird.com/?utm_source=Mailbird&utm_medium=email&utm_campaign=sent-from-mailbird>
>>>
>>> On 30/09/2016 7:21:53 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>>>
>>>
>>> -----BEGIN PGP SIGNED MESSAGE-----
>>> Hash: SHA256
>>>
>>> Amos, I'm afraid that this is not a solution. Block lists have 
>>> become so
>>> huge that only their compression and / or placement in an external
>>> database (as Marcus) can save the situation.
>>>
>>>
>>> 30.09.2016 12:59, Amos Jeffries ?????:
>>> > On 30/09/2016 6:58 p.m., Darren wrote:
>>> >> Thank you Amos
>>> >>
>>> >> The resources I save not running multiple Squidguards will make more
>>> >> ram available as you say and having a simpler setup is never a bad
>>> >> thing either.
>>> >>
>>> >> Just to clarify, so when squid fires up, it caches the ACL file into
>>> >> ram in it's entirety and then does some optimizations? If that is
>>> >> the case I would need to budget the ram to allow for this.
>>> >
>>> > Not quite. Squid still reads the files line by line into a memory
>>> > structure for whatever type of ACL is being loaded. That is part 
>>> of why
>>> > its so much slowe to load than the helpers (which generally do as you
>>> > describe).
>>> >
>>> > The optimizations are type dependent and fairly simplistic. Ignoring
>>> > duplicate entries, catenating regex into bigger " A|B " patterns 
>>> (faster
>>> > to check against), etc.
>>> >
>>> > Amos
>>> >
>>> > _______________________________________________
>>> > squid-users mailing list
>>> > squid-users at lists.squid-cache.org
>>> > http://lists.squid-cache.org/listinfo/squid-users
>>>
>>> -----BEGIN PGP SIGNATURE-----
>>> Version: GnuPG v2
>>>
>>> iQEcBAEBCAAGBQJX7kq8AAoJENNXIZxhPexGH+cH/jmZsQlcZgXpwt62pHDtHp4t
>>> TWDnhr5KOfHv+GFeBUmJYuD2nn8wefb5KUUhea5fdpRAeDihFDQDPQDwAnaC/E5q
>>> FzE68zh+nF13xVwTW9/5mQhK75G17mOGJPGFPn1ZUC3lf/Q2JCOhWB+0MFilXXcQ
>>> /ptCeQII/E8oXaiBOvHPzasOp6eDnu/m51q0DnkfoUceEWap9W0rY/vKxwL32FI9
>>> fjqoZGGBPt3FDczjb8/9X6trqeGBwUl4PKSTE4JSdyU6z52evaCSsVbEgAmw+LjI
>>> ELCBPOuU7buFxNjCSNLVhDNQeZJFJxPV8Oh/OcDQZQDhdUYliEwRke5Sz+Rz37k=
>>> =hFD2
>>> -----END PGP SIGNATURE-----
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
--

Signed,

Benjamin E. Nichols
http://www.squidblacklist.org

1-405-397-1360 - Call Anytime.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/91043397/attachment.htm>

From squidcache at mindchasers.com  Sat Oct  1 01:45:01 2016
From: squidcache at mindchasers.com (Bob Cochran)
Date: Fri, 30 Sep 2016 21:45:01 -0400
Subject: [squid-users] Large text ACL lists
In-Reply-To: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
Message-ID: <5cdc2943-d606-65e9-c224-044b2a2e8408@mindchasers.com>

Darren,

Have you also considered writing your own redirector/rewriter in a 
language like python?  There seems to be a nice starting example in the 
"Squid Book", which I was able to get working along with extending it.

Good luck,

Bob


On 09/29/2016 05:44 AM, Darren wrote:
> Hi All
>
> I have been tinkering with Squidguard for a while, using it to manage 
> ACL lists and time limits etc.
>
> While it works OK, it's not in active development and has it's issues.
>
> What are the limitations with just pumping ACL lists directly into 
> Squid and letting it do all the work internally without running a team 
> of squidguards?
>
> how efficient is squid now at parsing the text files directly, will i 
> Need more ram as the list grows? Is it slower or are their 
> optimizations that I can do?
>
> thanks all
>
> Darren Breeze
>
>
>
>
>
> Sent from Mailbird 
> <http://www.getmailbird.com/?utm_source=Mailbird&utm_medium=email&utm_campaign=sent-from-mailbird>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/1800acf1/attachment.htm>

From gergely at egervary.hu  Sat Oct  1 22:48:27 2016
From: gergely at egervary.hu (=?UTF-8?Q?Egerv=c3=a1ry_Gergely?=)
Date: Sun, 2 Oct 2016 00:48:27 +0200
Subject: [squid-users] intercept + IPv6 + IPFilter 5.1
Message-ID: <76058d09-5599-7426-8ba6-05b7b4550c2d@egervary.hu>

Hi,

Should "intercept" work with IPv6 on NetBSD 7-STABLE and IPFilter 5.1?

I have the patch applied for kern/50198, and it's working fine with
IPv4. I only get a connection reset by peer on IPv6.

Thank You,
--
Gergely EGERVARY


From rousskov at measurement-factory.com  Sun Oct  2 00:38:18 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 1 Oct 2016 18:38:18 -0600
Subject: [squid-users] Large text ACL lists
In-Reply-To: <a7d4ee77-25f0-4bec-aba5-c74336798e70@getmailbird.com>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <2c1e0a65-e688-183f-b83e-4fbbfa6d4539@treenet.co.nz>
 <54ee7d9a-96fe-4233-8db7-3b891455f07f@getmailbird.com>
 <35c4e399-1050-06c7-1715-e0c1252955a4@treenet.co.nz>
 <97de62ef-9f55-cb69-2031-4ef56c902d5d@gmail.com>
 <8cee8f0b-bd35-4f76-828b-8fd497c1a4c8@getmailbird.com>
 <a7d4ee77-25f0-4bec-aba5-c74336798e70@getmailbird.com>
Message-ID: <91674131-8872-0697-594c-17a2a9bcf42d@measurement-factory.com>

On 09/30/2016 07:02 PM, Darren wrote:

> If I have to reload the ACL lists do I restart squid or is there a way
> to update without impacting the users to much?

You can reconfigure Squid instead of restarting it. Reconfiguration is
usually better than a complete restart as far as user impact is
concerned, but reconfiguration is currently still pretty disruptive for
users because Squid closes its listening ports while reconfiguring and
does a lot of useless work which slows reconfiguration down. Also, there
have been many cases where reconfiguration led to memory leaks and other
problems.

Seamless hot reconfiguration has been on many admin wish lists for a
long time, and ACL refreshing is a big part of that demand. We are
moving in that direction but the progress has been slow.

Alex.


From webmaster at squidblacklist.org  Sun Oct  2 01:08:46 2016
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Sat, 1 Oct 2016 20:08:46 -0500
Subject: [squid-users] Large text ACL lists
In-Reply-To: <91674131-8872-0697-594c-17a2a9bcf42d@measurement-factory.com>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <2c1e0a65-e688-183f-b83e-4fbbfa6d4539@treenet.co.nz>
 <54ee7d9a-96fe-4233-8db7-3b891455f07f@getmailbird.com>
 <35c4e399-1050-06c7-1715-e0c1252955a4@treenet.co.nz>
 <97de62ef-9f55-cb69-2031-4ef56c902d5d@gmail.com>
 <8cee8f0b-bd35-4f76-828b-8fd497c1a4c8@getmailbird.com>
 <a7d4ee77-25f0-4bec-aba5-c74336798e70@getmailbird.com>
 <91674131-8872-0697-594c-17a2a9bcf42d@measurement-factory.com>
Message-ID: <d8e4a1ff-4b9d-063c-816a-76c0c1e6d355@squidblacklist.org>

I wouldnt advise reconfigure for when you update your blacklists, sure 
it sounds great, but in reality, as I said, in my experience, only 
sometimes will it actually reload the acl from disk, sometimes it wont.  
Youll do a reconfigure and discover your squid is still running the old 
acls which presumably are memory resident, now this may have been a bug 
thats been since fixed, but Im not messing with it.  In our testig 
environment we dont have time to be dealing with squid deciding to load 
an acl from disk when it feels like it should do so, we need it to load 
from disk every time.

Once you do your own testing youll see what im talking about, go ahead 
and add some urls to your acl and -k reconfigure, do this a few times, 
and I am certain youll eventually find out what Im telling you is true.


On 10/1/2016 7:38 PM, Alex Rousskov wrote:
> On 09/30/2016 07:02 PM, Darren wrote:
>
>> If I have to reload the ACL lists do I restart squid or is there a way
>> to update without impacting the users to much?
> You can reconfigure Squid instead of restarting it. Reconfiguration is
> usually better than a complete restart as far as user impact is
> concerned, but reconfiguration is currently still pretty disruptive for
> users because Squid closes its listening ports while reconfiguring and
> does a lot of useless work which slows reconfiguration down. Also, there
> have been many cases where reconfiguration led to memory leaks and other
> problems.
>
> Seamless hot reconfiguration has been on many admin wish lists for a
> long time, and ACL refreshing is a big part of that demand. We are
> moving in that direction but the progress has been slow.
>
> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
--

Signed,

Benjamin E. Nichols
http://www.squidblacklist.org

1-405-397-1360 - Call Anytime.



From squid3 at treenet.co.nz  Sun Oct  2 04:15:30 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 2 Oct 2016 17:15:30 +1300
Subject: [squid-users] Large text ACL lists
In-Reply-To: <d8e4a1ff-4b9d-063c-816a-76c0c1e6d355@squidblacklist.org>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <2c1e0a65-e688-183f-b83e-4fbbfa6d4539@treenet.co.nz>
 <54ee7d9a-96fe-4233-8db7-3b891455f07f@getmailbird.com>
 <35c4e399-1050-06c7-1715-e0c1252955a4@treenet.co.nz>
 <97de62ef-9f55-cb69-2031-4ef56c902d5d@gmail.com>
 <8cee8f0b-bd35-4f76-828b-8fd497c1a4c8@getmailbird.com>
 <a7d4ee77-25f0-4bec-aba5-c74336798e70@getmailbird.com>
 <91674131-8872-0697-594c-17a2a9bcf42d@measurement-factory.com>
 <d8e4a1ff-4b9d-063c-816a-76c0c1e6d355@squidblacklist.org>
Message-ID: <cfc50320-7d98-41e4-0761-aab51d2ef1b1@treenet.co.nz>

On 2/10/2016 2:08 p.m., Benjamin E. Nichols wrote:
> I wouldnt advise reconfigure for when you update your blacklists, sure
> it sounds great, but in reality, as I said, in my experience, only
> sometimes will it actually reload the acl from disk, sometimes it wont. 
> Youll do a reconfigure and discover your squid is still running the old
> acls which presumably are memory resident, now this may have been a bug
> thats been since fixed, but Im not messing with it.  In our testig
> environment we dont have time to be dealing with squid deciding to load
> an acl from disk when it feels like it should do so, we need it to load
> from disk every time.
> 
> Once you do your own testing youll see what im talking about, go ahead
> and add some urls to your acl and -k reconfigure, do this a few times,

So you are sening Squid a series of reload signals so fast it does not
have time to complete one before the next is arriving?

There are many fixes in Squid-4 and latest 3.5 for those situations. But
still some open bug reports about the behaviour there. Those are not
related to ACLs specifically. Any reconfig task that takes longer than
the time between -k reconfigure signals being sent will trigger issues.

... Ironically using a helper is one of the things which breaks. Squid
looses track of whether any given new helper being started was for the
current or previous -k reconfigure signal.

And of course connections and transactions which are already underway
are not affected by newly loaded config details.

Amos



From darren.j.breeze.ml at gmail.com  Sun Oct  2 04:24:52 2016
From: darren.j.breeze.ml at gmail.com (Darren)
Date: Sun, 02 Oct 2016 12:24:52 +0800
Subject: [squid-users] Large text ACL lists
In-Reply-To: <cfc50320-7d98-41e4-0761-aab51d2ef1b1@treenet.co.nz>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <2c1e0a65-e688-183f-b83e-4fbbfa6d4539@treenet.co.nz>
 <54ee7d9a-96fe-4233-8db7-3b891455f07f@getmailbird.com>
 <35c4e399-1050-06c7-1715-e0c1252955a4@treenet.co.nz>
 <97de62ef-9f55-cb69-2031-4ef56c902d5d@gmail.com>
 <8cee8f0b-bd35-4f76-828b-8fd497c1a4c8@getmailbird.com>
 <a7d4ee77-25f0-4bec-aba5-c74336798e70@getmailbird.com>
 <91674131-8872-0697-594c-17a2a9bcf42d@measurement-factory.com>
 <d8e4a1ff-4b9d-063c-816a-76c0c1e6d355@squidblacklist.org>
 <cfc50320-7d98-41e4-0761-aab51d2ef1b1@treenet.co.nz>
Message-ID: <e211cffe-eab1-41da-8c75-36396444ac16@getmailbird.com>

Hi

I have now opened the Pandora box of writing my own helper as per Bobs suggestion.?

I am playing with the idea of pre-processing my acl lists and using memcached as a KV store. This way I should be able to update ACL members whilst keeping everything as available as possible.

I would update the acl members outside of squid so it should be fast, and if I get my tree model right, fast and scale well too.

I have had great success with Memcache on various large web applications so again, pending a clever tree algorithm, this could provide me with what I need without having to reload / restart squid.

Darren B.






Sent from Mailbird [http://www.getmailbird.com/?utm_source=Mailbird&amp;utm_medium=email&amp;utm_campaign=sent-from-mailbird]
On 2/10/2016 12:15:52 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
On 2/10/2016 2:08 p.m., Benjamin E. Nichols wrote:
> I wouldnt advise reconfigure for when you update your blacklists, sure
> it sounds great, but in reality, as I said, in my experience, only
> sometimes will it actually reload the acl from disk, sometimes it wont.
> Youll do a reconfigure and discover your squid is still running the old
> acls which presumably are memory resident, now this may have been a bug
> thats been since fixed, but Im not messing with it. In our testig
> environment we dont have time to be dealing with squid deciding to load
> an acl from disk when it feels like it should do so, we need it to load
> from disk every time.
>
> Once you do your own testing youll see what im talking about, go ahead
> and add some urls to your acl and -k reconfigure, do this a few times,

So you are sening Squid a series of reload signals so fast it does not
have time to complete one before the next is arriving?

There are many fixes in Squid-4 and latest 3.5 for those situations. But
still some open bug reports about the behaviour there. Those are not
related to ACLs specifically. Any reconfig task that takes longer than
the time between -k reconfigure signals being sent will trigger issues.

... Ironically using a helper is one of the things which breaks. Squid
looses track of whether any given new helper being started was for the
current or previous -k reconfigure signal.

And of course connections and transactions which are already underway
are not affected by newly loaded config details.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161002/5064f49d/attachment.htm>

From codemarauder at gmail.com  Sun Oct  2 06:16:32 2016
From: codemarauder at gmail.com (Nishant Sharma)
Date: Sun, 02 Oct 2016 11:46:32 +0530
Subject: [squid-users] Large text ACL lists
In-Reply-To: <e211cffe-eab1-41da-8c75-36396444ac16@getmailbird.com>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <2c1e0a65-e688-183f-b83e-4fbbfa6d4539@treenet.co.nz>
 <54ee7d9a-96fe-4233-8db7-3b891455f07f@getmailbird.com>
 <35c4e399-1050-06c7-1715-e0c1252955a4@treenet.co.nz>
 <97de62ef-9f55-cb69-2031-4ef56c902d5d@gmail.com>
 <8cee8f0b-bd35-4f76-828b-8fd497c1a4c8@getmailbird.com>
 <a7d4ee77-25f0-4bec-aba5-c74336798e70@getmailbird.com>
 <91674131-8872-0697-594c-17a2a9bcf42d@measurement-factory.com>
 <d8e4a1ff-4b9d-063c-816a-76c0c1e6d355@squidblacklist.org>
 <cfc50320-7d98-41e4-0761-aab51d2ef1b1@treenet.co.nz>
 <e211cffe-eab1-41da-8c75-36396444ac16@getmailbird.com>
Message-ID: <FF3F4012-9EF0-4EB9-A74E-3F2EB874B89E@gmail.com>

Hi,

On 2 October 2016 9:54:52 AM IST, Darren <darren.j.breeze.ml at gmail.com> wrote:
>Hi
>
>I have now opened the Pandora box of writing my own helper as per Bobs
>suggestion.?

We are working on a redirector which we are currently using at around 100 geographically distributed squids. These squid are running on OpenWRT and PfSense embedded boxes like Mikrotik Routerboard, PCEngine Alix & APU.

The helper is written in Perl while server uses Postgresql, memcached and a deamon.

You may check it out at:

https://github.com/codemarauder/charcoal

http://charcoal.io

If you wish to do alpha testing, I would be more than happy to provide access to you on the hosted service.

Regards,
Nishant


-- 
Sent from my Android device with K-9 Mail. Please excuse my brevity.


From squid-user at tlinx.org  Sun Oct  2 07:00:13 2016
From: squid-user at tlinx.org (Linda W)
Date: Sun, 02 Oct 2016 00:00:13 -0700
Subject: [squid-users] --enable-openssl-crtd -- not
	building	openssl-crtd? (3.5.21)
In-Reply-To: <056b01d21aa3$22833020$67899060$@ngtech.co.il>
References: <57E9D3B5.6050405@tlinx.org>
 <598baad3-64d1-b873-b266-55ab5d96fb0c@treenet.co.nz>
 <57E9EFBC.5040407@tlinx.org> <056b01d21aa3$22833020$67899060$@ngtech.co.il>
Message-ID: <57F0B07D.6000500@tlinx.org>

Eliezer Croitoru wrote:
> Hey Linda,
> 
> If you need some help later we are here for any advice.
> Can you say on what OS are you compiling the software?
---
	opensuse 13.2

I have to see what else is needed (if anything).  I already
imported the squid-cert into my browser, but not sure if it
is bumping anything or not.

What I'd like to do is create a list of ssl-"banned" connections
where it can store objects from those sessions into the cache under
plaintext names so for those sites I can regain squid-caching that
is shareable between different sessions.

Right now, due to the ssl-junkies (those who want everything
encrypted because it hides their streams from user eyes), 
it seems that many objects that used to be cached, now, 
can't be cached because they are part of a 
TUNNEL where individual objects are no longer discernible.

I've noticed an overall slowdown of websites due to the 
slowdown from encrypting & decrypting as well as not being
able to cache commonly used items.









From squid-user at tlinx.org  Sun Oct  2 07:29:09 2016
From: squid-user at tlinx.org (Linda A. Walsh)
Date: Sun, 02 Oct 2016 00:29:09 -0700
Subject: [squid-users] Objects in cache that are not found don't seem to be
 removed from the internal index
Message-ID: <57F0B745.8030806@tlinx.org>

I noticed a message like this in my cache.log:
2016/09/30 18:50:27 kid1| DiskThreadsDiskFile::openDone: (2) No such 
file or directory
2016/09/30 18:50:27 kid1|     /var/cache/squid/1D/1C/0001D708

Always wonder why, but barring that, I found multiple statements like that
with the same file number.  I.e. after it has failed and knows it isn't 
in the
cache -- why do I get more failures with it trying to fetch the same bad 
file?





From squid3 at treenet.co.nz  Sun Oct  2 08:00:24 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 2 Oct 2016 21:00:24 +1300
Subject: [squid-users] Objects in cache that are not found don't seem to
 be removed from the internal index
In-Reply-To: <57F0B745.8030806@tlinx.org>
References: <57F0B745.8030806@tlinx.org>
Message-ID: <490972cf-2407-56cb-b901-7f626024ed48@treenet.co.nz>

On 2/10/2016 8:29 p.m., Linda A. Walsh wrote:
> I noticed a message like this in my cache.log:
> 2016/09/30 18:50:27 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or directory
> 2016/09/30 18:50:27 kid1|     /var/cache/squid/1D/1C/0001D708
> 
> Always wonder why, but barring that, I found multiple statements like that
> with the same file number.  I.e. after it has failed and knows it isn't
> in the
> cache -- why do I get more failures with it trying to fetch the same bad
> file?

Unknown without a detailed log trace containing the full Squid
operations between the recorded lines.

Probably multiple objects using the same filename. That might also
explain why it is disappearing too (one got deeted, other entris not
aware of that). Although the filename does not start with 1D1C**** which
I would expect to see there given the path.

Amos



From squid-user at tlinx.org  Sun Oct  2 20:46:29 2016
From: squid-user at tlinx.org (Linda W)
Date: Sun, 02 Oct 2016 13:46:29 -0700
Subject: [squid-users] Objects in cache that are not found don't seem to
 be removed from the internal index
In-Reply-To: <490972cf-2407-56cb-b901-7f626024ed48@treenet.co.nz>
References: <57F0B745.8030806@tlinx.org>
 <490972cf-2407-56cb-b901-7f626024ed48@treenet.co.nz>
Message-ID: <57F17225.2020009@tlinx.org>

Amos Jeffries wrote:
> On 2/10/2016 8:29 p.m., Linda A. Walsh wrote:
>   
>> I noticed a message like this in my cache.log:
>> 2016/09/30 18:50:27 kid1| DiskThreadsDiskFile::openDone: (2) No such
>> file or directory
>> 2016/09/30 18:50:27 kid1|     /var/cache/squid/1D/1C/0001D708
>>
>> Always wonder why, but barring that, I found multiple statements like that
>> with the same file number.  I.e. after it has failed and knows it isn't
>> in the
>> cache -- why do I get more failures with it trying to fetch the same bad
>> file?
>>     
>
> Unknown without a detailed log trace containing the full Squid
> operations between the recorded lines.
>   
---
    I don't know the sequence of actions needed to reliably trigger the 
above,
but the cache logs I have hand show counts of "1" for 99 of the "no such 
file"
errors, with the non-"1" counts being:
      2 /var/cache/squid/11/05/00011167
     12 /var/cache/squid/2C/34/0006CD0A
     33 /var/cache/squid/01/31/00001C56
     51 /var/cache/squid/25/06/000251AD
     71 /var/cache/squid/1D/1C/0001D708
In the oldest log rotated out on Sep 16, There are 6 with count 1, and 2 
with
>  1 counts:
      6 /var/cache/squid/1D/1C/0001D708
      7 /var/cache/squid/25/06/000251AD

    In the large majority of cases, they are 1-time misses, but for 
some, like
"/var/cache/squid/1D/1C/0001D708".  I don't see any that have the two 
cache dirs
as the 1st 2 digits -- I'd be surprised if it worked at all if that were 
the case -- maybe it isn't -- maybe I'm only getting memhits and the 
rest are hits
that would have come from disk if the file was there? 

    Which log would you want a detailed trace of... you talking debug 
level 9?  Erk?...


> Probably multiple objects using the same filename. That might also
> explain why it is disappearing too (one got deeted, other entris not
> aware of that). Although the filename does not start with 1D1C**** which
> I would expect to see there given the path.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>   


From ghoreishi.saeedeh at gmail.com  Mon Oct  3 01:27:13 2016
From: ghoreishi.saeedeh at gmail.com (Saeedeh Ghoreishi)
Date: Sun, 2 Oct 2016 21:27:13 -0400
Subject: [squid-users] Analyzing encrypted traffic
Message-ID: <CAFwjE_1ZN4iPEeieEoL=4SA4DB8CMNkrZ-idjwNvWtEYij413A@mail.gmail.com>

Hello

I'm student in Concordia university in Montreal, Canada. I'm working on a
project which is defining a web proxy server to intercepting the encrypted
traffic of clients. I've used squid 3.5.21 as my transparent proxy server.
My professor told me that the new version of squid (3.5.21) has the option
which I can use it to intercept the encrypted data from client to the
server in the cloud and conversely. I can not find anything special in
squid 3.5.21 about this analyzing. Could you please inform me?

Regards
Saeedeh
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161002/4a265ebd/attachment.htm>

From michael.varun at inmobi.com  Mon Oct  3 03:34:54 2016
From: michael.varun at inmobi.com (Michael Varun)
Date: Mon, 3 Oct 2016 09:04:54 +0530
Subject: [squid-users] Analyzing encrypted traffic
In-Reply-To: <CAFwjE_1ZN4iPEeieEoL=4SA4DB8CMNkrZ-idjwNvWtEYij413A@mail.gmail.com>
References: <CAFwjE_1ZN4iPEeieEoL=4SA4DB8CMNkrZ-idjwNvWtEYij413A@mail.gmail.com>
Message-ID: <CAHhBkD3sj+67KatT8WUjEiUHeAzuPCO1b8TynUnt87FC-NKcvg@mail.gmail.com>

squid will not be able to intercept encrypted traffic it just does a
passover using CONNECT to the origin server . You can explore the feature
SSL_BUMP which will basically help in intercepting encrypted traffic. You
will need to generate certificates and mimick the clients There are some
dependency on HTML HEADERS as well like AUTHORIZATION ,CACHE CONTROL and so
on. I am currently in same situation as you. I was able to perform GET
calls towards origin server ,But i am getting cache miss most of the time
and in process of investigating



On Mon, Oct 3, 2016 at 6:57 AM, Saeedeh Ghoreishi <
ghoreishi.saeedeh at gmail.com> wrote:

> Hello
>
> I'm student in Concordia university in Montreal, Canada. I'm working on a
> project which is defining a web proxy server to intercepting the encrypted
> traffic of clients. I've used squid 3.5.21 as my transparent proxy server.
> My professor told me that the new version of squid (3.5.21) has the option
> which I can use it to intercept the encrypted data from client to the
> server in the cloud and conversely. I can not find anything special in
> squid 3.5.21 about this analyzing. Could you please inform me?
>
> Regards
> Saeedeh
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>

-- 
_____________________________________________________________
The information contained in this communication is intended solely for the 
use of the individual or entity to whom it is addressed and others 
authorized to receive it. It may contain confidential or legally privileged 
information. If you are not the intended recipient you are hereby notified 
that any disclosure, copying, distribution or taking any action in reliance 
on the contents of this information is strictly prohibited and may be 
unlawful. If you have received this communication in error, please notify 
us immediately by responding to this email and then delete it from your 
system. The firm is neither liable for the proper and complete transmission 
of the information contained in this communication nor for any delay in its 
receipt.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161003/7e5a2c2f/attachment.htm>

From squid3 at treenet.co.nz  Mon Oct  3 04:39:31 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 3 Oct 2016 17:39:31 +1300
Subject: [squid-users] Analyzing encrypted traffic
In-Reply-To: <CAHhBkD3sj+67KatT8WUjEiUHeAzuPCO1b8TynUnt87FC-NKcvg@mail.gmail.com>
References: <CAFwjE_1ZN4iPEeieEoL=4SA4DB8CMNkrZ-idjwNvWtEYij413A@mail.gmail.com>
 <CAHhBkD3sj+67KatT8WUjEiUHeAzuPCO1b8TynUnt87FC-NKcvg@mail.gmail.com>
Message-ID: <ba8953db-e76a-4665-fe4e-2fb709982d1e@treenet.co.nz>

On 3/10/2016 4:34 p.m., Michael Varun wrote:
> squid will not be able to intercept encrypted traffic it just does a
> passover using CONNECT to the origin server . You can explore the feature
> SSL_BUMP which will basically help in intercepting encrypted traffic. You
> will need to generate certificates and mimick the clients There are some
> dependency on HTML HEADERS 

I think you mean HTTP headers. HTML has nothing to do with Squid. It is
just opaque payload bytes to any HTTP proxy.


> as well like AUTHORIZATION ,CACHE CONTROL and so
> on. I am currently in same situation as you. I was able to perform GET
> calls towards origin server ,But i am getting cache miss most of the time
> and in process of investigating

The HTTP (or HTTPS) headers are not related to SSL-Bump operations. The
TLS layer and the HTTP layer are separate and handled independently.

For the purposes of caching there is no difference between HTTP and
HTTPS messages. The same rules are applied.

<http://wiki.squid-cache.org/Features/SslPeekAndSplice>

Amos



From michael.varun at inmobi.com  Mon Oct  3 05:25:25 2016
From: michael.varun at inmobi.com (Michael Varun)
Date: Mon, 3 Oct 2016 10:55:25 +0530
Subject: [squid-users] Analyzing encrypted traffic
In-Reply-To: <ba8953db-e76a-4665-fe4e-2fb709982d1e@treenet.co.nz>
References: <CAFwjE_1ZN4iPEeieEoL=4SA4DB8CMNkrZ-idjwNvWtEYij413A@mail.gmail.com>
 <CAHhBkD3sj+67KatT8WUjEiUHeAzuPCO1b8TynUnt87FC-NKcvg@mail.gmail.com>
 <ba8953db-e76a-4665-fe4e-2fb709982d1e@treenet.co.nz>
Message-ID: <CAHhBkD0GNL_hP+4FLe-adngMLnUdb274Wasr+vEKRgY0U23rFg@mail.gmail.com>

Yeah, My bad i meant as HTTP HEADER and not HTML HEADER

Thanks for your input Amos, Just kicking off exploring squid


On Mon, Oct 3, 2016 at 10:09 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 3/10/2016 4:34 p.m., Michael Varun wrote:
> > squid will not be able to intercept encrypted traffic it just does a
> > passover using CONNECT to the origin server . You can explore the feature
> > SSL_BUMP which will basically help in intercepting encrypted traffic. You
> > will need to generate certificates and mimick the clients There are some
> > dependency on HTML HEADERS
>
> I think you mean HTTP headers. HTML has nothing to do with Squid. It is
> just opaque payload bytes to any HTTP proxy.
>
>
> > as well like AUTHORIZATION ,CACHE CONTROL and so
> > on. I am currently in same situation as you. I was able to perform GET
> > calls towards origin server ,But i am getting cache miss most of the time
> > and in process of investigating
>
> The HTTP (or HTTPS) headers are not related to SSL-Bump operations. The
> TLS layer and the HTTP layer are separate and handled independently.
>
> For the purposes of caching there is no difference between HTTP and
> HTTPS messages. The same rules are applied.
>
> <http://wiki.squid-cache.org/Features/SslPeekAndSplice>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

-- 
_____________________________________________________________
The information contained in this communication is intended solely for the 
use of the individual or entity to whom it is addressed and others 
authorized to receive it. It may contain confidential or legally privileged 
information. If you are not the intended recipient you are hereby notified 
that any disclosure, copying, distribution or taking any action in reliance 
on the contents of this information is strictly prohibited and may be 
unlawful. If you have received this communication in error, please notify 
us immediately by responding to this email and then delete it from your 
system. The firm is neither liable for the proper and complete transmission 
of the information contained in this communication nor for any delay in its 
receipt.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161003/27ec91d9/attachment.htm>

From rentorbuy at yahoo.com  Mon Oct  3 07:11:45 2016
From: rentorbuy at yahoo.com (Vieri)
Date: Mon, 3 Oct 2016 07:11:45 +0000 (UTC)
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
 code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <af92d108-b205-decb-13c4-fecb7a554b5e@gmail.com>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
 <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
 <2077594026.2082495.1475235384241@mail.yahoo.com>
 <af92d108-b205-decb-13c4-fecb7a554b5e@gmail.com>
Message-ID: <421701582.3214410.1475478705099@mail.yahoo.com>



Hi,

----- Original Message -----
> From: Yuri Voinov <yvoinov at gmail.com>
>

>> Why is Squid negotiating cipher RC4-MD5 which is reported "insecure"
>> and unsupported by the google web site?> Because your antique client request it. XP desupported years ago.

[...]
> Throw out XP and IE8 and set up W7 as minimum with IE10. I see no other

> way. I am afraid that in this case, the cactus is too large and inedible.

I agree that XP clients shouldn't be used anymore but it's easier said than done in corporate environments.

In any case, on a purely technical level, I don't know the internals of Squid and standard proxying protocols but if a Windows XP+IE8 client has no problem whatsoever connecting directly (no proxy) to https://www.google.com but fails with Squid in the middle (ssl-bump) then that makes me think that it could be either a Squid bug or a missing feature (or maybe the fact that Squid is stricter when implementing protocols than Microsoft products). Whatever the reason, for an end-user like me it seems that the XP client is able to negotiate TLS correctly with Google and presumably using the cipher DES-CBC3-SHA (maybe after failing with RC4-MD5 on a first attempt), whereas Squid immediately fails with RC4-MD5. It doesn't ever seem to try DES-CBC3-SHA even though it's available in openssl. 


So I guess I'll start forcing users to use Firefox on WinXP or any other sane OS. I just wanted to point out though that I'm still confused as to why the client connection is failing.

Vieri


From michael.varun at inmobi.com  Mon Oct  3 08:38:25 2016
From: michael.varun at inmobi.com (Michael Varun)
Date: Mon, 3 Oct 2016 14:08:25 +0530
Subject: [squid-users] Caching application/octet-stream
In-Reply-To: <8895d8b6-ab32-c6c8-4b64-67ce62a33c43@treenet.co.nz>
References: <CAHhBkD0dXw7PztgqGdrZ=6aTxVpuXExx+q+qVA+8rM3a+8Y8NA@mail.gmail.com>
 <a1df4bde-6c40-ff3c-e41e-e5e8aee0a86e@treenet.co.nz>
 <CAHhBkD1E1dFS3wTHXFjE16ES0HEcxA_ePAusrF2q-WwZ-QtfTg@mail.gmail.com>
 <8895d8b6-ab32-c6c8-4b64-67ce62a33c43@treenet.co.nz>
Message-ID: <CAHhBkD0JzUC75jitu74cFF_0upOhdKTVH5nfELcBxCDpO=2Zrg@mail.gmail.com>

There is a bug in the SSL-Bump implementation we have not sorted out
yet, which makes the "ssl-bump" on this port enable reverse-proxy mode
handling. That seems to be leading to Surrogate feature being enabled
and the Authorization:Bearer being removed when it should be relayed to
the server.


Can you refer to the BUD ID if there is one already opened  if not
should i submit one for reference ?


On Fri, Sep 30, 2016 at 1:06 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 30/09/2016 8:10 p.m., Michael Varun wrote:
> > Here is the snippet of debug logs
> > I dont get to see anything missing out there . It does a GET call to the
> > docker registry on behalf of the requesting client The registry listens
> on
> > 443 so squid mimicks  client TLS connections post which does a GET call
> to
> > the docker registry on the requested blobs
>
> Well firstly, going by your earlier config file the client is *not*
> performing TLS connections. Your proxy is configured to receive
> plain-text HTTP at port 443.
>
> You seem to have stumbled onto two bugs in Squid which are combining to
> be problematic.
>
> There is a bug in the SSL-Bump implementation we have not sorted out
> yet, which makes the "ssl-bump" on this port enable reverse-proxy mode
> handling. That seems to be leading to Surrogate feature being enabled
> and the Authorization:Bearer being removed when it should be relayed to
> the server.
>
> The existence of Authorization header on the request combined with lack
> of Cache-Control:public on the response means these reponses are private
> responses associated with that auth credentials token. They cannot be
> cached and given to anyone else.
>
> That brings up what I think may be a second bug. Since the request to
> the server was sent without Auth header then Squid should be considering
> it a non-auth response and treating it as cacheable anyway. But probably
> is just using the client request for that decision.
>
>
> You could try adding the "login=PASSTHRU" option to your cache_peer
> line. If the server sends "Cache-Control:public" that should enable
> caching.
>
> Amos
>
>

-- 
_____________________________________________________________
The information contained in this communication is intended solely for the 
use of the individual or entity to whom it is addressed and others 
authorized to receive it. It may contain confidential or legally privileged 
information. If you are not the intended recipient you are hereby notified 
that any disclosure, copying, distribution or taking any action in reliance 
on the contents of this information is strictly prohibited and may be 
unlawful. If you have received this communication in error, please notify 
us immediately by responding to this email and then delete it from your 
system. The firm is neither liable for the proper and complete transmission 
of the information contained in this communication nor for any delay in its 
receipt.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161003/0d4aecde/attachment.htm>

From jvdwesthuiz at shoprite.co.za  Mon Oct  3 10:50:34 2016
From: jvdwesthuiz at shoprite.co.za (Jasper Van Der Westhuizen)
Date: Mon, 3 Oct 2016 10:50:34 +0000
Subject: [squid-users] Squid crash - 3.5.21
Message-ID: <1475491833.8486.41.camel@shoprite.co.za>

Hi all

This morning I had some problems with some of our proxies. 2 Proxies in cluster A crashed with the below errors. The shortly afterwards 4 in cluster B did the same. Both clusters are configured to run their cache in memory with SMP and 4 workers configured.

2016/10/03 10:28:37 kid3| snmpHandleUdp: FD 258 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:37 kid4| snmpHandleUdp: FD 21 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:37 kid4| snmpHandleUdp: FD 21 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:37 kid3| snmpHandleUdp: FD 258 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:37 kid2| snmpHandleUdp: FD 1892 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:37 kid3| snmpHandleUdp: FD 258 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:37 kid4| snmpHandleUdp: FD 21 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:37 kid3| snmpHandleUdp: FD 258 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:37 kid1| snmpHandleUdp: FD 217 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid1| snmpHandleUdp: FD 217 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid2| snmpHandleUdp: FD 1892 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid3| snmpHandleUdp: FD 258 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid4| snmpHandleUdp: FD 21 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid3| snmpHandleUdp: FD 258 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid1| snmpHandleUdp: FD 217 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid4| snmpHandleUdp: FD 21 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid1| snmpHandleUdp: FD 217 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid3| snmpHandleUdp: FD 258 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid3| snmpHandleUdp: FD 258 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid1| snmpHandleUdp: FD 217 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid1| snmpHandleUdp: FD 217 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid3| snmpHandleUdp: FD 258 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid1| snmpHandleUdp: FD 217 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid1| snmpHandleUdp: FD 217 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid3| snmpHandleUdp: FD 258 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid4| snmpHandleUdp: FD 21 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid1| snmpHandleUdp: FD 217 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid4| snmpHandleUdp: FD 21 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:38 kid2| snmpHandleUdp: FD 1892 recvfrom: (11) Resource temporarily unavailable
2016/10/03 10:28:39 kid3| snmpHandleUdp: FD 258 recvfrom: (11) Resource temporarily unavailable

FATAL: Received Bus Error...dying.
2016/10/03 10:28:49 kid2| Closing HTTP port xxxxxxxxx:8080
2016/10/03 10:28:49 kid2| Closing HTTP port 127.0.0.1:8080
2016/10/03 10:28:49 kid2| storeDirWriteCleanLogs: Starting...
2016/10/03 10:28:49 kid2|   Finished.  Wrote 0 entries.
2016/10/03 10:28:49 kid2|   Took 0.00 seconds (  0.00 entries/sec).
CPU Usage: 29249.604 seconds = 14130.271 user + 15119.333 sys
Maximum Resident Size: 24210640 KB
Page faults with physical i/o: 0
FATAL: Received Bus Error...dying.
2016/10/03 10:28:47 kid4| Closing HTTP port xxxxxxxxxx3:8080
2016/10/03 10:28:47 kid4| Closing HTTP port 127.0.0.1:8080
2016/10/03 10:28:47 kid4| storeDirWriteCleanLogs: Starting...
2016/10/03 10:28:47 kid4|   Finished.  Wrote 0 entries.
2016/10/03 10:28:47 kid4|   Took 0.00 seconds (  0.00 entries/sec).
CPU Usage: 19100.510 seconds = 9502.454 user + 9598.056 sys
Maximum Resident Size: 9194336 KB
Page faults with physical i/o: 0
FATAL: Received Bus Error...dying.
2016/10/03 10:28:47 kid1| Closing HTTP port xxxxxxxxxx:8080
2016/10/03 10:28:47 kid1| Closing HTTP port 127.0.0.1:8080
2016/10/03 10:28:47 kid1| storeDirWriteCleanLogs: Starting...
2016/10/03 10:28:47 kid1|   Finished.  Wrote 0 entries.
2016/10/03 10:28:47 kid1|   Took 0.00 seconds (  0.00 entries/sec).
CPU Usage: 28389.386 seconds = 13891.472 user + 14497.914 sys
Maximum Resident Size: 19754288 KB
Page faults with physical i/o: 0
FATAL: Received Bus Error...dying.
2016/10/03 10:28:47 kid3| Closing HTTP port xxxxxxxxxx:8080
2016/10/03 10:28:47 kid3| Closing HTTP port 127.0.0.1:8080
2016/10/03 10:28:47 kid3| storeDirWriteCleanLogs: Starting...
2016/10/03 10:28:47 kid3|   Finished.  Wrote 0 entries.
2016/10/03 10:28:47 kid3|   Took 0.00 seconds (  0.00 entries/sec).
CPU Usage: 35218.057 seconds = 17518.687 user + 17699.370 sys
Maximum Resident Size: 21131904 KB
Page faults with physical i/o: 0


Squid Cache: Version 3.5.21
Service Name: squid
configure options:  '--prefix=/usr/local/squid3.5.21' '--sysconfdir=/etc/squid3.5.21' '--enable-follow-x-forwarded-for' '--with-logdir=/var/lo
g/squid/' '-with-pidfile=/var/run/squid.pid' '--with-swapdir=/var/cache/squid/' '--with-large-files' '--with-default-user=squid' '--with-inclu
ded-ltdl' '--enable-snmp' '--enable-storeio=ufs,aufs' '--enable-removal-policies=lru,heap' '--enable-ltdl-convenience' '--with-pthreads'

--
Kind Regards
Jasper





Disclaimer:
http://www.shopriteholdings.co.za/Pages/ShopriteE-mailDisclaimer.aspx
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161003/3cc74a08/attachment.htm>

From oagvozd at gmail.com  Mon Oct  3 12:36:29 2016
From: oagvozd at gmail.com (oleg gv)
Date: Mon, 3 Oct 2016 15:36:29 +0300
Subject: [squid-users] Squid 3.5.21: ftp_port intercept doesn't work
Message-ID: <CAFfuDwx5PfZJ32J2WsGDZzPw7PncSLyEdknZ7aiUMf1+UFqfpw@mail.gmail.com>

Hello

I've setup in Squid 3.5.21 on my gateway : ftp_port 10.0.0.1:2121 intercept
and create nat rule to redirect from port 21 to 2121 for client source
address (for example 10.0.0.10)

Then trying to go through browser to ftp://ftp.intel.com from client
10.0.0.10

And in browser got Password prompt window: i set user anonymous and
password a at a

Then got error message 501 Missing Host.

In squid log I see:

2016/10/03 15:34:24.504 kid1| 20,2| store.cc(949) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/10/03 15:34:24.508 kid1| 33,2| client_side.cc(816) swanSong: local=
10.0.0.1:2121 remote=10.0.0.10:37016 flags=1
2016/10/03 15:34:24.508 kid1| 5,2| TcpAcceptor.cc(220) doAccept: New
connection on FD 10
2016/10/03 15:34:24.508 kid1| 5,2| TcpAcceptor.cc(295) acceptNext:
connection on local=0.0.0.0:2121 remote=[::] FD 10 flags=9
2016/10/03 15:34:29.534 kid1| 33,2| FtpServer.cc(699) parseOneRequest:
>>ftp USER anonymous
2016/10/03 15:34:29.534 kid1| 20,2| store.cc(949) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/10/03 15:34:29.534 kid1| 20,2| store.cc(949) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/10/03 15:34:29.534 kid1| 20,2| store.cc(949) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/10/03 15:34:29.534 kid1| 88,2| client_side_reply.cc(2005)
processReplyAccessResult: The reply for NONE error:ftp-missing-host is
ALLOWED, because it matched NO ACL's
2016/10/03 15:34:29.534 kid1| 9,2| FtpServer.cc(1208)
writeForwardedReplyAndCall: FTP Client local=10.0.0.254:2121 remote=
10.0.0.10:37018 FD 13 flags=1
2016/10/03 15:34:29.534 kid1| 9,2| FtpServer.cc(1210)
writeForwardedReplyAndCall: FTP Client REPLY:
---------
501 Missing host

----------
2016/10/03 15:34:29.534 kid1| 20,2| store.cc(949) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/10/03 15:34:29.574 kid1| 33,2| client_side.cc(816) swanSong: local=
10.0.0.1:2121 remote=10.0.0.10:37018 flags=1


Though I can not use native ftp relay to go to ftp servers.

Please, could you help ?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161003/319f49d2/attachment.htm>

From myshark at gmail.com  Mon Oct  3 15:03:13 2016
From: myshark at gmail.com (Shark)
Date: Mon, 3 Oct 2016 18:33:13 +0330
Subject: [squid-users] problem in configuring squid
Message-ID: <CAKCdGgCWF4vUb-K5JZ8L4HCvNEtLRfXaz+VfH8PNfSbACrh6hQ@mail.gmail.com>

Hi and thanks for your good software,

I want to config squid to make "open proxy" for both http & https
I want make anonymous proxy, without decrypting traffic or etc, just change
ip address, like this:

i find lot of ip port in internet for example: 173.161.0.227
when i add some host to /etc/hosts like this:

173.161.0.227 www.iplocation.net

its give me true way without ssl blocking in client and my ip changes to
173.161.0.227,

i want to make same as this server, i search a lot and ask my question here:
http://serverfault.com/questions/805413/squid-with-iptables-bypass-https

my server is centos 7 and i can install any version of squid on it, i try
lot of configuration
but not worked..

Please help me and give me true config.. i have just one valid ip in my
server that connected to internet

thanks alot
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161003/c5e239f1/attachment.htm>

From gergely at egervary.hu  Mon Oct  3 15:12:50 2016
From: gergely at egervary.hu (=?UTF-8?Q?Egerv=c3=a1ry_Gergely?=)
Date: Mon, 3 Oct 2016 17:12:50 +0200
Subject: [squid-users] IPv6 interception crash: Ip::Address::getInAddr :
 Cannot convert non-IPv4 to IPv4.
Message-ID: <57F27572.8000600@egervary.hu>

Hi,

I'm running on NetBSD 7-STABLE, with IPFilter 5.1
(--enable-ipf-transparent)

NAT interception rule:
rdr wm1 from 2001:738:7a00:a::/64 to any port = 80 ->
2001:738:7a00:a::14 port 3128 tcp

cache.log:

2016/10/03 17:08:03.232 kid1| 5,2| TcpAcceptor.cc(220) doAccept: New
connection on FD 18
2016/10/03 17:08:03.232 kid1| 5,2| TcpAcceptor.cc(295) acceptNext:
connection on local=[2001:738:7a00:a::14]:3128 remote=[::] FD 18 flags=41
2016/10/03 17:08:03.232 kid1| 51,3| fd.cc(198) fd_open: fd_open() FD 22
HTTP Request
2016/10/03 17:08:03.233 kid1| 89,5| Intercept.cc(375) Lookup: address
BEGIN: me/client= [2001:738:7a00:a::14]:3128, destination/me=
[2001:738:7a00:a::a:d]:52628
2016/10/03 17:08:03.233 kid1| Ip::Address::getInAddr : Cannot convert
non-IPv4 to IPv4. IPA=[2001:738:7a00:a::14]:3128
2016/10/03 17:08:03.473| 42,8| Icmp6.cc(240) Recv: 24 bytes from
[2001:738:7a00:b::1]

-- squid crash here --

2016/10/03 17:08:06.285 kid1| 21,3| tools.cc(610) enter_suid:
enter_suid: PID 2722 taking root privileges
2016/10/03 17:08:06.285 kid1| 16,3| cache_manager.cc(80)
registerProfile: registering legacy config
2016/10/03 17:08:06.285 kid1| 16,5| cache_manager.cc(114) findAction:
CacheManager::findAction: looking for action config
2016/10/03 17:08:06.285 kid1| 16,6| cache_manager.cc(122) findAction:
Action not found.
2016/10/03 17:08:06.285 kid1| 16,3| cache_manager.cc(65)
registerProfile: registered profile: config
2016/10/03 17:08:06.286 kid1| 13,3| mem.cc(473) Report: Memory pools are
'on'; limit: 5.000 MB
2016/10/03 17:08:06.286 kid1| 1,2| main.cc(1455) SquidMain: Doing
post-config initialization

Any ideas?
Thank You,
--
Gergely EGERVARY


From Antony.Stone at squid.open.source.it  Mon Oct  3 15:22:29 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 3 Oct 2016 17:22:29 +0200
Subject: [squid-users] problem in configuring squid
In-Reply-To: <CAKCdGgCWF4vUb-K5JZ8L4HCvNEtLRfXaz+VfH8PNfSbACrh6hQ@mail.gmail.com>
References: <CAKCdGgCWF4vUb-K5JZ8L4HCvNEtLRfXaz+VfH8PNfSbACrh6hQ@mail.gmail.com>
Message-ID: <201610031722.29450.Antony.Stone@squid.open.source.it>

On Monday 03 October 2016 at 17:03:13, Shark wrote:

> I want to config squid to make "open proxy" for both http & https
> I want make anonymous proxy, without decrypting traffic or etc, just change
> ip address, like this:
> 
> i find lot of ip port in internet for example: 173.161.0.227
> when i add some host to /etc/hosts like this:
> 
> 173.161.0.227 www.iplocation.net
> 
> its give me true way without ssl blocking in client and my ip changes to
> 173.161.0.227,

Squid is the wrong tool for this job.

You probably want something like https://www.torproject.org/
?

Antony.

-- 
There are only 10 types of people in the world:
those who understand binary notation,
and those who don't.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squidcache at mindchasers.com  Mon Oct  3 17:25:51 2016
From: squidcache at mindchasers.com (Bob Cochran)
Date: Mon, 3 Oct 2016 13:25:51 -0400
Subject: [squid-users] Large text ACL lists
In-Reply-To: <FF3F4012-9EF0-4EB9-A74E-3F2EB874B89E@gmail.com>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <2c1e0a65-e688-183f-b83e-4fbbfa6d4539@treenet.co.nz>
 <54ee7d9a-96fe-4233-8db7-3b891455f07f@getmailbird.com>
 <35c4e399-1050-06c7-1715-e0c1252955a4@treenet.co.nz>
 <97de62ef-9f55-cb69-2031-4ef56c902d5d@gmail.com>
 <8cee8f0b-bd35-4f76-828b-8fd497c1a4c8@getmailbird.com>
 <a7d4ee77-25f0-4bec-aba5-c74336798e70@getmailbird.com>
 <91674131-8872-0697-594c-17a2a9bcf42d@measurement-factory.com>
 <d8e4a1ff-4b9d-063c-816a-76c0c1e6d355@squidblacklist.org>
 <cfc50320-7d98-41e4-0761-aab51d2ef1b1@treenet.co.nz>
 <e211cffe-eab1-41da-8c75-36396444ac16@getmailbird.com>
 <FF3F4012-9EF0-4EB9-A74E-3F2EB874B89E@gmail.com>
Message-ID: <1973eeca-021f-cae4-0deb-9f0abf3d7016@mindchasers.com>

On 10/02/2016 02:16 AM, Nishant Sharma wrote:
> Hi,
>
> On 2 October 2016 9:54:52 AM IST, Darren <darren.j.breeze.ml at gmail.com> wrote:
>> Hi
>>
>> I have now opened the Pandora box of writing my own helper as per Bobs
>> suggestion.
> We are working on a redirector which we are currently using at around 100 geographically distributed squids. These squid are running on OpenWRT and PfSense embedded boxes like Mikrotik Routerboard, PCEngine Alix & APU.
>
> The helper is written in Perl while server uses Postgresql, memcached and a deamon.
>
> You may check it out at:
>
> https://github.com/codemarauder/charcoal
>
> http://charcoal.io


It may be helpful at this point to remind everyone that there is a page 
on the squid site that lists redirectors: 
http://www.squid-cache.org/Misc/redirectors.html

Nishant, perhaps you should list Charcoal here.

I searched through the list for python-based redirectors.  Two come up, 
but the links seem to be stale / broken and probably should be removed:  
iredir and pyredir.


>
> If you wish to do alpha testing, I would be more than happy to provide access to you on the hosted service.
>
> Regards,
> Nishant
>
>



From rousskov at measurement-factory.com  Mon Oct  3 17:33:15 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 3 Oct 2016 11:33:15 -0600
Subject: [squid-users] Squid crash - 3.5.21
In-Reply-To: <1475491833.8486.41.camel@shoprite.co.za>
References: <1475491833.8486.41.camel@shoprite.co.za>
Message-ID: <aff9b1ab-5233-5e28-af18-5b867dad89df@measurement-factory.com>

On 10/03/2016 04:50 AM, Jasper Van Der Westhuizen wrote:
> This morning I had some problems with some of our proxies. 2 Proxies in
> cluster A crashed with the below errors. The shortly afterwards 4 in
> cluster B did the same. Both clusters are configured to run their cache
> in memory with SMP and 4 workers configured.
> 
> FATAL: Received Bus Error...dying.


There are at least two possible reasons:

  1. A bug in Squid and
  2. Memory overallocation by the OS kernel.

To fix the former, the developers will need a stack trace (at least). I
recommend filing a bug report after getting that trace and excluding
reason #2. Squid wiki and various system administration guides explain
how to make Squid dump core files.

To check for memory overallocation, you can temporary start Squid v4.0
with "shared_memory_locking on". Unfortunately, that squid.conf
directive is not available in Squid v3. You may be able to emulate it
using some OS-specific sysctl or environment variables, but doing so may
be far from trivial, and I do not have instructions.


HTH,

Alex.



From rousskov at measurement-factory.com  Mon Oct  3 17:38:25 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 3 Oct 2016 11:38:25 -0600
Subject: [squid-users] Squid 3.5.21: ftp_port intercept doesn't work
In-Reply-To: <CAFfuDwx5PfZJ32J2WsGDZzPw7PncSLyEdknZ7aiUMf1+UFqfpw@mail.gmail.com>
References: <CAFfuDwx5PfZJ32J2WsGDZzPw7PncSLyEdknZ7aiUMf1+UFqfpw@mail.gmail.com>
Message-ID: <42227386-810c-9b33-3b7e-a231d61c75a4@measurement-factory.com>

On 10/03/2016 06:36 AM, oleg gv wrote:

> I've setup in Squid 3.5.21 on my gateway : ftp_port 10.0.0.1:2121
> <http://10.0.0.1:2121> intercept and create nat rule to redirect from
> port 21 to 2121 for client source address (for example 10.0.0.10)
> 
> Then trying to go through browser to ftp://ftp.intel.com from client
> 10.0.0.10
> 
> And in browser got Password prompt window: i set user anonymous and
> password a at a
> 
> Then got error message 501 Missing Host.

IIRC, your FTP password is supposed to contain the origin server host
name. There should be to "@" characters in the password. This is how
native FTP proxying works...

It might be easier to get it working with an FTP client (that supports
FTP proxies) rather than a general purpose browser.


HTH,

Alex.



From gaardiolor at gmail.com  Mon Oct  3 17:50:34 2016
From: gaardiolor at gmail.com (Marc)
Date: Mon, 3 Oct 2016 19:50:34 +0200
Subject: [squid-users] handshake problems with stare and bump
Message-ID: <CAPxJK5DSeaA1JzD7CNhAmR2ZQXF87VrEtS9w+Ojvw1q4EhO=Ww@mail.gmail.com>

Hi,

I've got an issue with squid stare and bump, hope someone can help!

I'm staring and bumping everything, using transparent proxy on Fedora
Core 24 using squid-3.5.20-1.fc24.x86_64 (see below for config). Now
the client (iphone app) does TLS v1.0 and has the following ciphers in
the Client Hello (from wireshark):
TLS_RSA_WITH_AES_256_CBC_SHA (0x0035)
TLS_RSA_WITH_AES_128_CBC_SHA (0x002f)
TLS_RSA_WITH_3DES_EDE_CBC_SHA (0x000a)
TLS_RSA_WITH_RC4_128_SHA (0x0005)
TLS_RSA_WITH_RC4_128_MD5 (0x0004)
TLS_RSA_WITH_DES_CBC_SHA (0x0009)

What squid does is replicating all of them in the Client Hello to the
server. This in general goes without problems most of the time, but in
this case not. In the cases where it fails, squid logs an error:
2016/10/01 00:08:13 kid1| Error negotiating SSL on FD 26:
error:1409F07F:SSL routines:ssl3_write_pending:bad write retry
(1/-1/0)
I've also seen:
2016/10/02 20:53:09 kid1| Error negotiating SSL connection on FD 12:
error:1408A0C1:SSL routines:ssl3_get_client_hello:no shared cipher
(1/-1)

Squid then sends the following html to the client (http over https
port 443 - I had to get it out of my pcap):

--
(71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
Handshake with SSL server failed: error:1409F07F:SSL
routines:ssl3_write_pending:bad write retry
This proxy and the remote host failed to negotiate a mutually
acceptable security settings for handling your request. (..)
--
Now it would've been nicer if squid sent out that error over HTTPS,
but my main problem is the error happening in the first place.

I think it has something to do with the cipher. If I look at my pcaps
I can see the webserver is selecting 'TLS_RSA_WITH_3DES_EDE_CBC_SHA
(0x000a)' in the Server Hello. In openssl, this cipher is called
'DES-CBC3-SHA'. So if I try to reproduce on another client (linux),
only using one cipher in the client hello:
1) echo -e "GET / HTTP/1.1\nHost: $host\n\n" | openssl s_client
-cipher DES-CBC3-SHA -quiet -connect $host:443 2>/dev/null
2) echo -e "GET / HTTP/1.1\nHost: $host\n\n" | openssl s_client
-cipher AES256-SHA -quiet -connect $host:443 2>/dev/null

1 breaks like the iphone app. 2 works fine. I've looked on the host
squid is running on, but 1 works there as well. So the host running
squid seems to support the cipher, also according to openssl:
# openssl ciphers -V | grep "0x00,0x0A"
          0x00,0x0A - DES-CBC3-SHA            SSLv3 Kx=RSA      Au=RSA
 Enc=3DES(168) Mac=SHA1

Things that come to mind:
1) Why doesn't DES-CBC3-SHA work with squid ? The host seems to supports it.
2) Squid forwards the Client Hello, including ciphers the host running
squid doesn't support (in my case, the DES and RC4 ones). This could
also potentially lead to problems. Why doesn't squid filter them out
from the Client Hello sent from squid to the webserver ? Or replace
all of them with the ciphers preferred by squid. Perhaps by using the
sslproxy_cipher directive (which is currently ignored in ssl_bump
configurations).
3) Nice to have: Is it possible for squid to report errors to the user
over HTTPS instead of HTTP ?

My squid conf:

#####################################
http_port      3128 transparent
https_port     3129 transparent ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=100MB
cert=/etc/pki/rootca/public+private.pem
http_port      3130 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=100MB
cert=/etc/pki/rootca/public+private.pem

logformat      combined %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %Hs %<st
"%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
access_log     /export/logs/squid/access_log combined
cache_log      /export/logs/squid/cache_log
coredump_dir   /var/spool/squid

acl localhost  src    127.0.0.1/32 ::1

acl localnet   src    10.5.0.0/16
acl localnet   src    fc00::/7
acl localnet   src    fe80::/10

acl SSL_ports  port   443
acl Safe_ports port   80
acl Safe_ports port   443
acl CONNECT    method CONNECT

http_access    allow  manager     localhost
http_access    deny   manager
http_access    deny   !Safe_ports
http_access    deny   CONNECT     !SSL_ports
http_access    allow  localnet
http_access    allow  localhost
http_access    deny   all

forwarded_for  delete
cache deny     all
always_direct  allow  all

ssl_bump       stare  all
ssl_bump       bump   all
#####################################

Thanks,

Marc


From yvoinov at gmail.com  Mon Oct  3 18:09:28 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 4 Oct 2016 00:09:28 +0600
Subject: [squid-users] handshake problems with stare and bump
In-Reply-To: <CAPxJK5DSeaA1JzD7CNhAmR2ZQXF87VrEtS9w+Ojvw1q4EhO=Ww@mail.gmail.com>
References: <CAPxJK5DSeaA1JzD7CNhAmR2ZQXF87VrEtS9w+Ojvw1q4EhO=Ww@mail.gmail.com>
Message-ID: <838791f0-8b15-d3f5-0dc4-4c3d87def405@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit#Hardening


03.10.2016 23:50, Marc ?????:
> Hi,
>
> I've got an issue with squid stare and bump, hope someone can help!
>
> I'm staring and bumping everything, using transparent proxy on Fedora
> Core 24 using squid-3.5.20-1.fc24.x86_64 (see below for config). Now
> the client (iphone app) does TLS v1.0 and has the following ciphers in
> the Client Hello (from wireshark):
> TLS_RSA_WITH_AES_256_CBC_SHA (0x0035)
> TLS_RSA_WITH_AES_128_CBC_SHA (0x002f)
> TLS_RSA_WITH_3DES_EDE_CBC_SHA (0x000a)
> TLS_RSA_WITH_RC4_128_SHA (0x0005)
> TLS_RSA_WITH_RC4_128_MD5 (0x0004)
> TLS_RSA_WITH_DES_CBC_SHA (0x0009)
>
> What squid does is replicating all of them in the Client Hello to the
> server. This in general goes without problems most of the time, but in
> this case not. In the cases where it fails, squid logs an error:
> 2016/10/01 00:08:13 kid1| Error negotiating SSL on FD 26:
> error:1409F07F:SSL routines:ssl3_write_pending:bad write retry
> (1/-1/0)
> I've also seen:
> 2016/10/02 20:53:09 kid1| Error negotiating SSL connection on FD 12:
> error:1408A0C1:SSL routines:ssl3_get_client_hello:no shared cipher
> (1/-1)
>
> Squid then sends the following html to the client (http over https
> port 443 - I had to get it out of my pcap):
>
> --
> (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
> Handshake with SSL server failed: error:1409F07F:SSL
> routines:ssl3_write_pending:bad write retry
> This proxy and the remote host failed to negotiate a mutually
> acceptable security settings for handling your request. (..)
> --
> Now it would've been nicer if squid sent out that error over HTTPS,
> but my main problem is the error happening in the first place.
>
> I think it has something to do with the cipher. If I look at my pcaps
> I can see the webserver is selecting 'TLS_RSA_WITH_3DES_EDE_CBC_SHA
> (0x000a)' in the Server Hello. In openssl, this cipher is called
> 'DES-CBC3-SHA'. So if I try to reproduce on another client (linux),
> only using one cipher in the client hello:
> 1) echo -e "GET / HTTP/1.1\nHost: $host\n\n" | openssl s_client
> -cipher DES-CBC3-SHA -quiet -connect $host:443 2>/dev/null
> 2) echo -e "GET / HTTP/1.1\nHost: $host\n\n" | openssl s_client
> -cipher AES256-SHA -quiet -connect $host:443 2>/dev/null
>
> 1 breaks like the iphone app. 2 works fine. I've looked on the host
> squid is running on, but 1 works there as well. So the host running
> squid seems to support the cipher, also according to openssl:
> # openssl ciphers -V | grep "0x00,0x0A"
>           0x00,0x0A - DES-CBC3-SHA            SSLv3 Kx=RSA      Au=RSA
>  Enc=3DES(168) Mac=SHA1
>
> Things that come to mind:
> 1) Why doesn't DES-CBC3-SHA work with squid ? The host seems to
supports it.
> 2) Squid forwards the Client Hello, including ciphers the host running
> squid doesn't support (in my case, the DES and RC4 ones). This could
> also potentially lead to problems. Why doesn't squid filter them out
> from the Client Hello sent from squid to the webserver ? Or replace
> all of them with the ciphers preferred by squid. Perhaps by using the
> sslproxy_cipher directive (which is currently ignored in ssl_bump
> configurations).
> 3) Nice to have: Is it possible for squid to report errors to the user
> over HTTPS instead of HTTP ?
>
> My squid conf:
>
> #####################################
> http_port      3128 transparent
> https_port     3129 transparent ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=100MB
> cert=/etc/pki/rootca/public+private.pem
> http_port      3130 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=100MB
> cert=/etc/pki/rootca/public+private.pem
>
> logformat      combined %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %Hs %<st
> "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
> access_log     /export/logs/squid/access_log combined
> cache_log      /export/logs/squid/cache_log
> coredump_dir   /var/spool/squid
>
> acl localhost  src    127.0.0.1/32 ::1
>
> acl localnet   src    10.5.0.0/16
> acl localnet   src    fc00::/7
> acl localnet   src    fe80::/10
>
> acl SSL_ports  port   443
> acl Safe_ports port   80
> acl Safe_ports port   443
> acl CONNECT    method CONNECT
>
> http_access    allow  manager     localhost
> http_access    deny   manager
> http_access    deny   !Safe_ports
> http_access    deny   CONNECT     !SSL_ports
> http_access    allow  localnet
> http_access    allow  localhost
> http_access    deny   all
>
> forwarded_for  delete
> cache deny     all
> always_direct  allow  all
>
> ssl_bump       stare  all
> ssl_bump       bump   all
> #####################################
>
> Thanks,
>
> Marc
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX8p7XAAoJENNXIZxhPexG9c0H/0I1b0yyZdHTTsb9q3jj+Tsv
Gggl5zd7xFy6lkV7Z7wtRdMOUrWzrSXGiVZz81uFbfizYf8rMZ4BJMDvGzhUFKN6
YJjLsqtBqaYRWbOqgWeXHngOIQKAeHbugOOcBMgNJ+bOhCSj0ZzkL1KdqZJpTR3b
0zSjwnRcsmmMk0Bdmck/ihRBrbRJ+rpOV3OX5h+viEO83UlIR3/Awz9FYd3oAg5Q
WWXz9ugyFXzkHF9DABeTuckd9z0L0/eIercPdIPCgB/QkfF9nlyY7vm17ijNfare
ehAPdP4+dH7jjZjg5KWICXL9ijMSL/eoR9gzbPuCDWqDYNzHAjVMrIH336nJeT8=
=+epU
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/f03f3c3e/attachment.key>

From killerrabbit2012 at gmail.com  Mon Oct  3 18:55:07 2016
From: killerrabbit2012 at gmail.com (Jason Alexander)
Date: Mon, 3 Oct 2016 14:55:07 -0400
Subject: [squid-users] Problem with Squid3 Caches
Message-ID: <CD14793F-4F48-433E-9A1E-B2030E1D7F14@gmail.com>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161003/f5a6cb42/attachment.htm>

From yvoinov at gmail.com  Mon Oct  3 18:57:31 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 4 Oct 2016 00:57:31 +0600
Subject: [squid-users] Problem with Squid3 Caches
In-Reply-To: <CD14793F-4F48-433E-9A1E-B2030E1D7F14@gmail.com>
References: <CD14793F-4F48-433E-9A1E-B2030E1D7F14@gmail.com>
Message-ID: <4be176f6-84a3-2412-1a20-2e551a7d80c1@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Show config.


04.10.2016 0:55, Jason Alexander ?????:
> Greetings -
>
> I?m trying to install squid on an Ubuntu workstation in a VM.  I
install squid but unable to initialize caches.  I get the following error:
>
> Initializing the Squid cache with the command squid3 -f
/etc/squid/squid.conf -z ..
>
> FATAL: Bungled /etc/squid/squid.conf line 3467: cache_dir rock /ssd3
... max-size=99999
> Squid Cache (Version 3.5.12): Terminated abnormally.
> CPU Usage: 0.004 seconds = 0.004 user + 0.000 sys
> Maximum Resident Size: 115024 KB
> Page faults with physical i/o: 2
>
> Please advise how I may be able to fix this! Thank you.
>
> ~ KR
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX8qobAAoJENNXIZxhPexGhssH/i6ZgpGLflf9B+TQIwoQ7scn
llni2H6gliVz3AsB4usktPmU/slqe6EUjOkdsL/PPwv7i1C4xSyUs9V7D20uElmg
oIEzqTrfnU0tRmgaEEpKqE20XdtgbTDDgmGdiiJ0WAuxUes4KiNOoCpu9ZHjvkjF
rUCjL8itcZCzqZBdMK/QnHlTvcCMjvEfDeZspooLyYfDLLLHW/g77f4W/S/Zip9G
1yutt2v5omF3ExLTA4EXtvQ14pbCzgB9kjqqgdWHLcvQcLrgPpgZ5YVw5MXTOovF
nh6vMZGDcjJGUx3UMdj0VbxYK7yGzmIVZHRRR311EDEZ+I39pTCYi0QwymJgsa0=
=zWsi
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/6705202e/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/6705202e/attachment.key>

From rousskov at measurement-factory.com  Mon Oct  3 19:12:40 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 3 Oct 2016 13:12:40 -0600
Subject: [squid-users] handshake problems with stare and bump
In-Reply-To: <CAPxJK5DSeaA1JzD7CNhAmR2ZQXF87VrEtS9w+Ojvw1q4EhO=Ww@mail.gmail.com>
References: <CAPxJK5DSeaA1JzD7CNhAmR2ZQXF87VrEtS9w+Ojvw1q4EhO=Ww@mail.gmail.com>
Message-ID: <bdf4861d-b620-c837-9a97-a89d35f9a162@measurement-factory.com>

On 10/03/2016 11:50 AM, Marc wrote:

> 2) Squid forwards the Client Hello, including ciphers the host running
> squid doesn't support (in my case, the DES and RC4 ones). This could
> also potentially lead to problems. Why doesn't squid filter them out
> from the Client Hello sent from squid to the webserver?

If this is what happens, then it is a Squid bug. During step2, the
matching "stare" action instructs Squid to start establishing the secure
connection with the origin server with the intent to "bump" it. Unlike
peeking, Squid must not advertise what it does not support in this case
because, as you said, doing so may jeopardize future bumping. If Squid
v4 does the same thing, I recommend filing a bug report.


> 3) Nice to have: Is it possible for squid to report errors to the user
> over HTTPS instead of HTTP ?

Squid is supposed to report bumping errors over HTTPS whenever it can
establish a secure connection with the client. Based on your email, I am
not sure whether Squid could establish a secure connection with the
client, but I suspect that your FD 12 "ssl3_get_client_hello:no shared
cipher" error indicates that Squid tried but failed to do so.

Alex.



From Antony.Stone at squid.open.source.it  Mon Oct  3 21:06:15 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 3 Oct 2016 23:06:15 +0200
Subject: [squid-users] Problem with Squid3 Caches
In-Reply-To: <CD14793F-4F48-433E-9A1E-B2030E1D7F14@gmail.com>
References: <CD14793F-4F48-433E-9A1E-B2030E1D7F14@gmail.com>
Message-ID: <201610032306.15880.Antony.Stone@squid.open.source.it>

On Monday 03 October 2016 at 20:55:07, Jason Alexander wrote:

> Greetings -
> 
> I?m trying to install squid on an Ubuntu workstation in a VM.  I install
> squid but unable to initialize caches.  I get the following error:
> 
> FATAL: Bungled /etc/squid/squid.conf line 3467: cache_dir rock /ssd3 ...

My guess is:

a) you have an email client which isn't correctly adding a plain text body

b) you do not have a directory /ssd3 on your computer

If either of those is incorrect, please follow Yuri's request to post your 
squid.conf (without comments or blank lines, please), but also add the output 
of:

	ls -al /ssd3

from your machine.


Thanks,


Antony.

-- 
Tinned food was developed for the British Navy in 1813.

The tin opener was not invented until 1858.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From darren.j.breeze.ml at gmail.com  Mon Oct  3 21:58:46 2016
From: darren.j.breeze.ml at gmail.com (Darren)
Date: Tue, 04 Oct 2016 05:58:46 +0800
Subject: [squid-users] Large text ACL lists
In-Reply-To: <FF3F4012-9EF0-4EB9-A74E-3F2EB874B89E@gmail.com>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <2c1e0a65-e688-183f-b83e-4fbbfa6d4539@treenet.co.nz>
 <54ee7d9a-96fe-4233-8db7-3b891455f07f@getmailbird.com>
 <35c4e399-1050-06c7-1715-e0c1252955a4@treenet.co.nz>
 <97de62ef-9f55-cb69-2031-4ef56c902d5d@gmail.com>
 <8cee8f0b-bd35-4f76-828b-8fd497c1a4c8@getmailbird.com>
 <a7d4ee77-25f0-4bec-aba5-c74336798e70@getmailbird.com>
 <91674131-8872-0697-594c-17a2a9bcf42d@measurement-factory.com>
 <d8e4a1ff-4b9d-063c-816a-76c0c1e6d355@squidblacklist.org>
 <cfc50320-7d98-41e4-0761-aab51d2ef1b1@treenet.co.nz>
 <e211cffe-eab1-41da-8c75-36396444ac16@getmailbird.com>
 <FF3F4012-9EF0-4EB9-A74E-3F2EB874B89E@gmail.com>
Message-ID: <9fd15c92-4561-4857-bd32-1b5725d3b781@getmailbird.com>

Hi Nishant

Thanks for the lead, I will have a look.

Redis is also interesting in this case due to its ability to scan keys and iterate through keys with a wildcard and cursors. Redis looks like it's just what I need as I need to swap in and out sets of sites on demand.

I have also been using Perl for over 20 years so my rewriter will be a child of Larry Wall.

Darren B.







Sent from Mailbird [http://www.getmailbird.com/?utm_source=Mailbird&amp;utm_medium=email&amp;utm_campaign=sent-from-mailbird]
On 2/10/2016 2:16:51 PM, Nishant Sharma <codemarauder at gmail.com> wrote:
Hi,

On 2 October 2016 9:54:52 AM IST, Darren wrote:
>Hi
>
>I have now opened the Pandora box of writing my own helper as per Bobs
>suggestion.?

We are working on a redirector which we are currently using at around 100 geographically distributed squids. These squid are running on OpenWRT and PfSense embedded boxes like Mikrotik Routerboard, PCEngine Alix & APU.

The helper is written in Perl while server uses Postgresql, memcached and a deamon.

You may check it out at:

https://github.com/codemarauder/charcoal

http://charcoal.io

If you wish to do alpha testing, I would be more than happy to provide access to you on the hosted service.

Regards,
Nishant


--
Sent from my Android device with K-9 Mail. Please excuse my brevity.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/d869b3ec/attachment.htm>

From squid3 at treenet.co.nz  Tue Oct  4 05:00:19 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 4 Oct 2016 18:00:19 +1300
Subject: [squid-users] IPv6 interception crash: Ip::Address::getInAddr :
 Cannot convert non-IPv4 to IPv4.
In-Reply-To: <57F27572.8000600@egervary.hu>
References: <57F27572.8000600@egervary.hu>
Message-ID: <ee0c2401-bccf-ad23-8611-af15f9d55906@treenet.co.nz>

On 4/10/2016 4:12 a.m., Egerv?ry Gergely wrote:
> Hi,
> 
> I'm running on NetBSD 7-STABLE, with IPFilter 5.1
> (--enable-ipf-transparent)
> 
> NAT interception rule:
> rdr wm1 from 2001:738:7a00:a::/64 to any port = 80 ->
> 2001:738:7a00:a::14 port 3128 tcp
> 
> cache.log:
> 
> 2016/10/03 17:08:03.232 kid1| 5,2| TcpAcceptor.cc(220) doAccept: New
> connection on FD 18
> 2016/10/03 17:08:03.232 kid1| 5,2| TcpAcceptor.cc(295) acceptNext:
> connection on local=[2001:738:7a00:a::14]:3128 remote=[::] FD 18 flags=41
> 2016/10/03 17:08:03.232 kid1| 51,3| fd.cc(198) fd_open: fd_open() FD 22
> HTTP Request
> 2016/10/03 17:08:03.233 kid1| 89,5| Intercept.cc(375) Lookup: address
> BEGIN: me/client= [2001:738:7a00:a::14]:3128, destination/me=
> [2001:738:7a00:a::a:d]:52628
> 2016/10/03 17:08:03.233 kid1| Ip::Address::getInAddr : Cannot convert
> non-IPv4 to IPv4. IPA=[2001:738:7a00:a::14]:3128
> 2016/10/03 17:08:03.473| 42,8| Icmp6.cc(240) Recv: 24 bytes from
> [2001:738:7a00:b::1]
> 

And what are your squid.conf http_port line(s) ?

What does squid log about listening HTTP ports on startup?

Amos



From squid3 at treenet.co.nz  Tue Oct  4 05:17:59 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 4 Oct 2016 18:17:59 +1300
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
 code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <421701582.3214410.1475478705099@mail.yahoo.com>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
 <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
 <2077594026.2082495.1475235384241@mail.yahoo.com>
 <af92d108-b205-decb-13c4-fecb7a554b5e@gmail.com>
 <421701582.3214410.1475478705099@mail.yahoo.com>
Message-ID: <f4e0b806-587c-ed2e-4941-b5cccbcda0d1@treenet.co.nz>

On 3/10/2016 8:11 p.m., Vieri wrote:
> 
> 
> Hi,
> 
> ----- Original Message -----
>> From: Yuri Voinov <yvoinov at gmail.com>
>> 
> 
>>> Why is Squid negotiating cipher RC4-MD5 which is reported
>>> "insecure" and unsupported by the google web site?> Because your
>>> antique client request it. XP desupported years ago.
> 
> [...]
>> Throw out XP and IE8 and set up W7 as minimum with IE10. I see no
>> other
> 
>> way. I am afraid that in this case, the cactus is too large and
>> inedible.
> 
> I agree that XP clients shouldn't be used anymore but it's easier
> said than done in corporate environments.
> 
> In any case, on a purely technical level, I don't know the internals
> of Squid and standard proxying protocols but if a Windows XP+IE8
> client has no problem whatsoever connecting directly (no proxy) to
> https://www.google.com but fails with Squid in the middle (ssl-bump)
> then that makes me think that it could be either a Squid bug or a
> missing feature 

TLS/SSL was designed to prevent MITM being done on the encrypted
traffic. When used properly that is exactly what it does.

SSL-Bump is an MITM process.

So the behaviour you see of "working" when no proxy bumping and "not
working" when proxy attempts to bump is exactly the way HTTPS was
designed to behave.

It is unreasonable to believe that working TLS behaviour is a bug in
Squid...

> Whatever the reason,
> for an end-user like me it seems that the XP client is able to
> negotiate TLS correctly with Google and presumably using the cipher
> DES-CBC3-SHA (maybe after failing with RC4-MD5 on a first attempt),
> whereas Squid immediately fails with RC4-MD5. It doesn't ever seem to
> try DES-CBC3-SHA even though it's available in openssl.

... in this case it might be. But not for the reasons stated. The
problem known so far is that RC4-MD5 cipher. Why it is not being used by
your OpenSSL library.

That could bear some further investigation. There may be things you need
to enable in the config passed to OpenSSL, or a different build of the
library needed. Something along those lines - Im just guessing here.

> 
> 
> So I guess I'll start forcing users to use Firefox on WinXP or any
> other sane OS. I just wanted to point out though that I'm still
> confused as to why the client connection is failing.

That sounds like a potentially workable option or at least workaround.

I hope the above explanations can alleviate your confusion a bit despite
not providing any answer to the problem.

Amos



From gergely at egervary.hu  Tue Oct  4 06:25:57 2016
From: gergely at egervary.hu (=?UTF-8?Q?Egerv=c3=a1ry_Gergely?=)
Date: Tue, 4 Oct 2016 08:25:57 +0200
Subject: [squid-users] IPv6 interception crash: Ip::Address::getInAddr :
 Cannot convert non-IPv4 to IPv4.
In-Reply-To: <ee0c2401-bccf-ad23-8611-af15f9d55906@treenet.co.nz>
References: <57F27572.8000600@egervary.hu>
 <ee0c2401-bccf-ad23-8611-af15f9d55906@treenet.co.nz>
Message-ID: <343a7732-6077-49de-ad8f-5ecb2383f715@egervary.hu>

>> 2016/10/03 17:08:03.233 kid1| Ip::Address::getInAddr : Cannot convert
>> non-IPv4 to IPv4. IPA=[2001:738:7a00:a::14]:3128
>
> And what are your squid.conf http_port line(s) ?

http_port 127.0.0.1:8080
http_port [::1]:8080
http_port 172.28.0.20:3128 intercept
http_port 172.28.0.20:8080
http_port [2001:738:7a00:a::14]:3128 intercept
http_port [2001:738:7a00:a::14]:8080

> What does squid log about listening HTTP ports on startup?

2016/10/04 08:25:16 kid1| Accepting HTTP Socket connections at 
local=127.0.0.1:8080 remote=[::] FD 14 flags=9
2016/10/04 08:25:16 kid1| Accepting HTTP Socket connections at 
local=[::1]:8080 remote=[::] FD 15 flags=9
2016/10/04 08:25:16 kid1| Accepting NAT intercepted HTTP Socket 
connections at local=172.28.0.20:3128 remote=[::] FD 16 flags=41
2016/10/04 08:25:16 kid1| Accepting HTTP Socket connections at 
local=172.28.0.20:8080 remote=[::] FD 17 flags=9
2016/10/04 08:25:16 kid1| Accepting NAT intercepted HTTP Socket 
connections at local=[2001:738:7a00:a::14]:3128 remote=[::] FD 18 flags=41
2016/10/04 08:25:16 kid1| Accepting HTTP Socket connections at 
local=[2001:738:7a00:a::14]:8080 remote=[::] FD 19 flags=9

-- 
Gergely EGERVARY



From squid3 at treenet.co.nz  Tue Oct  4 07:37:07 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 4 Oct 2016 20:37:07 +1300
Subject: [squid-users] IPv6 interception crash: Ip::Address::getInAddr :
 Cannot convert non-IPv4 to IPv4.
In-Reply-To: <343a7732-6077-49de-ad8f-5ecb2383f715@egervary.hu>
References: <57F27572.8000600@egervary.hu>
 <ee0c2401-bccf-ad23-8611-af15f9d55906@treenet.co.nz>
 <343a7732-6077-49de-ad8f-5ecb2383f715@egervary.hu>
Message-ID: <627e937e-7572-862c-fdcf-03e5146a1dea@treenet.co.nz>

On 4/10/2016 7:25 p.m., Egerv?ry Gergely wrote:
>>> 2016/10/03 17:08:03.233 kid1| Ip::Address::getInAddr : Cannot convert
>>> non-IPv4 to IPv4. IPA=[2001:738:7a00:a::14]:3128
>>

Okay your setup looks fine.

Apparently the IPFilter 5.1 code defines an 32-bit IPv4-only structure
for 64-bit IPv6 addresses to be placed into. That was supposed to be
fixed in IPFilter 5.0.3.

Can you look through your system for code header files that define
"struct natlookup" and show me what they contain?

Amos



From squid at borrill.org.uk  Tue Oct  4 07:42:35 2016
From: squid at borrill.org.uk (Stephen Borrill)
Date: Tue, 4 Oct 2016 08:42:35 +0100
Subject: [squid-users] intercept + IPv6 + IPFilter 5.1
In-Reply-To: <76058d09-5599-7426-8ba6-05b7b4550c2d@egervary.hu>
References: <76058d09-5599-7426-8ba6-05b7b4550c2d@egervary.hu>
Message-ID: <7298f28a-0d3b-5a43-9aee-81b11862d5bb@borrill.org.uk>

On 01/10/2016 23:48, Egerv?ry Gergely wrote:
> Hi,
> 
> Should "intercept" work with IPv6 on NetBSD 7-STABLE and IPFilter 5.1?
> 
> I have the patch applied for kern/50198, and it's working fine with
> IPv4. I only get a connection reset by peer on IPv6.

I found the IPv4 bug and that PR and patch was done by my work
colleague. Unfortunately we've not done any IPv6 testing.

As well as finding the kernel side of the bug, we found and fixed a
squid-side bug which was related to IPv4 vs IPv6, so this is probably a
good place to start looking:

http://bugs.squid-cache.org/show_bug.cgi?id=4302

-- 
Stephen



From gergely at egervary.hu  Tue Oct  4 07:57:49 2016
From: gergely at egervary.hu (=?UTF-8?Q?Egerv=c3=a1ry_Gergely?=)
Date: Tue, 4 Oct 2016 09:57:49 +0200
Subject: [squid-users] IPv6 interception crash: Ip::Address::getInAddr :
 Cannot convert non-IPv4 to IPv4.
In-Reply-To: <627e937e-7572-862c-fdcf-03e5146a1dea@treenet.co.nz>
References: <57F27572.8000600@egervary.hu>
 <ee0c2401-bccf-ad23-8611-af15f9d55906@treenet.co.nz>
 <343a7732-6077-49de-ad8f-5ecb2383f715@egervary.hu>
 <627e937e-7572-862c-fdcf-03e5146a1dea@treenet.co.nz>
Message-ID: <3f33e001-5c69-ad83-3324-a8cc1565adc4@egervary.hu>

> Apparently the IPFilter 5.1 code defines an 32-bit IPv4-only structure
> for 64-bit IPv6 addresses to be placed into. That was supposed to be
> fixed in IPFilter 5.0.3.
>
> Can you look through your system for code header files that define
> "struct natlookup" and show me what they contain?

in sys/external/bsd/ipf/netinet/ip_nat.h:

typedef struct  natlookup {
         i6addr_t        nl_inipaddr;
         i6addr_t        nl_outipaddr;
         i6addr_t        nl_realipaddr;
         int             nl_v;
         int             nl_flags;
         u_short         nl_inport;
         u_short         nl_outport;
         u_short         nl_realport;
} natlookup_t;


-- 
Gergely EGERVARY



From squid3 at treenet.co.nz  Tue Oct  4 09:27:06 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 4 Oct 2016 22:27:06 +1300
Subject: [squid-users] IPv6 interception crash: Ip::Address::getInAddr :
 Cannot convert non-IPv4 to IPv4.
In-Reply-To: <3f33e001-5c69-ad83-3324-a8cc1565adc4@egervary.hu>
References: <57F27572.8000600@egervary.hu>
 <ee0c2401-bccf-ad23-8611-af15f9d55906@treenet.co.nz>
 <343a7732-6077-49de-ad8f-5ecb2383f715@egervary.hu>
 <627e937e-7572-862c-fdcf-03e5146a1dea@treenet.co.nz>
 <3f33e001-5c69-ad83-3324-a8cc1565adc4@egervary.hu>
Message-ID: <71545a1d-6879-cad8-f56e-4835df7f4043@treenet.co.nz>

On 4/10/2016 8:57 p.m., Egerv?ry Gergely wrote:
>> Apparently the IPFilter 5.1 code defines an 32-bit IPv4-only structure
>> for 64-bit IPv6 addresses to be placed into. That was supposed to be
>> fixed in IPFilter 5.0.3.
>>
>> Can you look through your system for code header files that define
>> "struct natlookup" and show me what they contain?
> 
> in sys/external/bsd/ipf/netinet/ip_nat.h:
> 
> typedef struct  natlookup {
>         i6addr_t        nl_inipaddr;
>         i6addr_t        nl_outipaddr;
>         i6addr_t        nl_realipaddr;
>         int             nl_v;
>         int             nl_flags;
>         u_short         nl_inport;
>         u_short         nl_outport;
>         u_short         nl_realport;
> } natlookup_t;
> 

Is there another defined somewhere else? For some reason your Squid is
managing to build with just "nl_inip" (no 'addr') in the field name.

Amos



From gergely at egervary.hu  Tue Oct  4 09:52:45 2016
From: gergely at egervary.hu (=?UTF-8?Q?Egerv=c3=a1ry_Gergely?=)
Date: Tue, 4 Oct 2016 11:52:45 +0200
Subject: [squid-users] IPv6 interception crash: Ip::Address::getInAddr :
 Cannot convert non-IPv4 to IPv4.
In-Reply-To: <71545a1d-6879-cad8-f56e-4835df7f4043@treenet.co.nz>
References: <57F27572.8000600@egervary.hu>
 <ee0c2401-bccf-ad23-8611-af15f9d55906@treenet.co.nz>
 <343a7732-6077-49de-ad8f-5ecb2383f715@egervary.hu>
 <627e937e-7572-862c-fdcf-03e5146a1dea@treenet.co.nz>
 <3f33e001-5c69-ad83-3324-a8cc1565adc4@egervary.hu>
 <71545a1d-6879-cad8-f56e-4835df7f4043@treenet.co.nz>
Message-ID: <57F37BED.9040502@egervary.hu>

> Is there another defined somewhere else? For some reason your Squid is
> managing to build with just "nl_inip" (no 'addr') in the field name.

There's a copy in /usr/include/netinet, but it's the same:

typedef	struct	natlookup {
	i6addr_t	nl_inipaddr;
	i6addr_t	nl_outipaddr;
	i6addr_t	nl_realipaddr;
	int		nl_v;
	int		nl_flags;
	u_short		nl_inport;
	u_short		nl_outport;
	u_short		nl_realport;
} natlookup_t;

#define	nl_inip		nl_inipaddr.in4
#define	nl_outip	nl_outipaddr.in4
#define	nl_realip	nl_realipaddr.in4
#define	nl_inip6	nl_inipaddr.in6
#define	nl_outip6	nl_outipaddr.in6
#define	nl_realip6	nl_realipaddr.in6

... so "nl_inip" is a simple #define to nl_inipaddr.in4

This is from Squid's Intercept.cc:

    natLookup.nl_inport = htons(newConn->local.port());
    newConn->local.getInAddr(natLookup.nl_inip);
    natLookup.nl_outport = htons(newConn->remote.port());
    newConn->remote.getInAddr(natLookup.nl_outip);

Is this correct?
Should we have this in the "else" section of
  if (newConn->remote.isIPv6()) ... instead?

--
Gergely EGERVARY


From nilesh.gavali at tcs.com  Tue Oct  4 10:08:27 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Tue, 4 Oct 2016 11:08:27 +0100
Subject: [squid-users] Squid - AD kerberos auth and Linux Server proxy
	access not working
Message-ID: <OF227B7BEA.03FD80E0-ON80258042.0036FE6D-80258042.0037B4EB@tcs.com>

All;

we have Squid proxy configured with Windows SSO with Kerberos which work 
fine for WIndows AD users.
we have new requirement where one Linux application server need to access 
Internet via squid proxy, we allowed Linux host access via ACL but getting 
denied access error.
below is the configuration done to allow Linux Server host IWCCP02.

###################################
auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
HTTP/proxy02.cust.in at CUST.IN
auth_param negotiate children 20
auth_param negotiate keep_alive on

acl ad_auth proxy_auth REQUIRED

####  AD Group membership  ####

external_acl_type AD_Group ttl=300 negative_ttl=0 %LOGIN 
/usr/lib64/squid/squid_ldap_group -P -R -b "DC=CUST, DC=IN" -D svcproxy -W 
/etc/squid/pswd/pswd -f 
"(&(objectclass=person)(userPrincipalName=%v)(memberof=cn=%a,ou=InternetAccess,ou=Groups,DC=CUST, 
DC=IN))" -h Cust.in -s sub -v 3
#
#
acl USER external AD_Group lgInternetAccess_Users
acl allowedsite dstdomain "/etc/squid/sitelist/dbs_allowed_site"

acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed

acl IWCCP01 src 10.xx.15.103   # Linux Application server
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines
#
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

# Recommended minimum Access Permission configuration:
#
# Only allow cachemgr access from localhost
http_access allow manager localhost
http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed


http_access allow IWCCP01 allowedsite
http_access allow USER allowedsite
http_access deny all
http_access allow ad_auth

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 8080
never_direct allow all

cache_peer 10.xx.xx.108 parent 8080 0 default
#######################################################################


Thanks & Regards
Nilesh Suresh Gavali
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/92d8b1fa/attachment.htm>

From Antony.Stone at squid.open.source.it  Tue Oct  4 10:13:28 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 4 Oct 2016 12:13:28 +0200
Subject: [squid-users] Squid - AD kerberos auth and Linux Server proxy
	access not working
In-Reply-To: <OF227B7BEA.03FD80E0-ON80258042.0036FE6D-80258042.0037B4EB@tcs.com>
References: <OF227B7BEA.03FD80E0-ON80258042.0036FE6D-80258042.0037B4EB@tcs.com>
Message-ID: <201610041213.28760.Antony.Stone@squid.open.source.it>

On Tuesday 04 October 2016 at 12:08:27, Nilesh Gavali wrote:

> All;
> 
> we have Squid proxy configured with Windows SSO with Kerberos which work
> fine for WIndows AD users.
> we have new requirement where one Linux application server need to access
> Internet via squid proxy, we allowed Linux host access via ACL but getting
> denied access error.

> http_access allow IWCCP01 allowedsite
> http_access allow USER allowedsite
> http_access deny all
> http_access allow ad_auth

That makes no sense.  The last rule can never be triggered.  "deny all" does 
exactly what it says.

However, that doesn't explain your problem, so please show what you get in 
your access log for a request from this Linux machine IWCCP01.

Thanks,

Antony.

-- 
"In fact I wanted to be John Cleese and it took me some time to realise that 
the job was already taken."

 - Douglas Adams

                                                   Please reply to the list;
                                                         please *don't* CC me.


From nilesh.gavali at tcs.com  Tue Oct  4 10:28:44 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Tue, 4 Oct 2016 11:28:44 +0100
Subject: [squid-users] Squid - AD kerberos auth and Linux Server proxy
	access not working
Message-ID: <OF4588894B.96613DF1-ON80258042.00392BFE-80258042.0039900A@tcs.com>

Hello Antony;
I have double checked the current working configuration of my squid.conf 
and it has same settings which I posted earlier. somehow it is working for 
us.

below is the error from access.log file.

1475518342.279      0 10.xx.15.103 TCP_DENIED/407 3589 CONNECT 
vseries-test.bottomline.com:443 - NONE/- text/html


Thanks & Regards
Nilesh Suresh Gavali
------------------------------

Message: 5
Date: Tue, 4 Oct 2016 11:08:27 +0100
From: Nilesh Gavali <nilesh.gavali at tcs.com>
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid - AD kerberos auth and Linux Server proxy
                 access not working
Message-ID:
 <OF227B7BEA.03FD80E0-ON80258042.0036FE6D-80258042.0037B4EB at tcs.com>
Content-Type: text/plain; charset="utf-8"

All;

we have Squid proxy configured with Windows SSO with Kerberos which work 
fine for WIndows AD users.
we have new requirement where one Linux application server need to access 
Internet via squid proxy, we allowed Linux host access via ACL but getting 

denied access error.
below is the configuration done to allow Linux Server host IWCCP02.

###################################
auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
HTTP/proxy02.cust.in at CUST.IN
auth_param negotiate children 20
auth_param negotiate keep_alive on

acl ad_auth proxy_auth REQUIRED

####  AD Group membership  ####

external_acl_type AD_Group ttl=300 negative_ttl=0 %LOGIN 
/usr/lib64/squid/squid_ldap_group -P -R -b "DC=CUST, DC=IN" -D svcproxy -W 

/etc/squid/pswd/pswd -f 
"(&(objectclass=person)(userPrincipalName=%v)(memberof=cn=%a,ou=InternetAccess,ou=Groups,DC=CUST, 

DC=IN))" -h Cust.in -s sub -v 3
#
#
acl USER external AD_Group lgInternetAccess_Users
acl allowedsite dstdomain "/etc/squid/sitelist/dbs_allowed_site"

acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed

acl IWCCP01 src 10.xx.15.103   # Linux Application server
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines
#
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

# Recommended minimum Access Permission configuration:
#
# Only allow cachemgr access from localhost
http_access allow manager localhost
http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed


http_access allow IWCCP01 allowedsite
http_access allow USER allowedsite
http_access deny all
http_access allow ad_auth

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 8080
never_direct allow all

cache_peer 10.xx.xx.108 parent 8080 0 default
#######################################################################


Thanks & Regards
Nilesh Suresh Gavali
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/92d8b1fa/attachment-0001.html
>

------------------------------

Message: 6
Date: Tue, 4 Oct 2016 12:13:28 +0200
From: Antony Stone <Antony.Stone at squid.open.source.it>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid - AD kerberos auth and Linux Server
                 proxy           access not working
Message-ID: <201610041213.28760.Antony.Stone at squid.open.source.it>
Content-Type: Text/Plain;  charset="iso-8859-15"

On Tuesday 04 October 2016 at 12:08:27, Nilesh Gavali wrote:

> All;
> 
> we have Squid proxy configured with Windows SSO with Kerberos which work
> fine for WIndows AD users.
> we have new requirement where one Linux application server need to 
access
> Internet via squid proxy, we allowed Linux host access via ACL but 
getting
> denied access error.

> http_access allow IWCCP01 allowedsite
> http_access allow USER allowedsite
> http_access deny all
> http_access allow ad_auth

That makes no sense.  The last rule can never be triggered.  "deny all" 
does 
exactly what it says.

However, that doesn't explain your problem, so please show what you get in 

your access log for a request from this Linux machine IWCCP01.

Thanks,

Antony.

-- 
"In fact I wanted to be John Cleese and it took me some time to realise 
that 
the job was already taken."

 - Douglas Adams

                                                   Please reply to the 
list;
                                                         please *don't* CC 
me.


------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 26, Issue 10
*******************************************
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/2da79740/attachment.htm>

From Antony.Stone at squid.open.source.it  Tue Oct  4 10:36:25 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 4 Oct 2016 12:36:25 +0200
Subject: [squid-users] Squid - AD kerberos auth and Linux Server proxy
	access not working
In-Reply-To: <OF4588894B.96613DF1-ON80258042.00392BFE-80258042.0039900A@tcs.com>
References: <OF4588894B.96613DF1-ON80258042.00392BFE-80258042.0039900A@tcs.com>
Message-ID: <201610041236.25242.Antony.Stone@squid.open.source.it>

On Tuesday 04 October 2016 at 12:28:44, Nilesh Gavali wrote:

> Hello Antony;
> I have double checked the current working configuration of my squid.conf
> and it has same settings which I posted earlier. somehow it is working for
> us.

I'm not saying the whole thing won't work; I'm saying there is no point in 
having a line "http_access allow ad_auth" following the line "http_access deny 
all".  The ad_auth line can never be invoked.

> below is the error from access.log file.
> 
> 1475518342.279      0 10.xx.15.103 TCP_DENIED/407 3589 CONNECT
> vseries-test.bottomline.com:443 - NONE/- text/html

Error 407 is "proxy auth required", so the proxy is expecting authentication 
for some reason.

Can you confirm that the hostname vseries-test.bottomline.com is contained in 
your site file /etc/squid/sitelist/dbs_allowed_site ?

Can you temporarily change the line "http_access allow IWCCP01 allowedsite" to 
"http_access allow IWCCP01" and see whether the machine then gets access?


Antony.

-- 
+++ Divide By Cucumber Error.  Please Reinstall Universe And Reboot +++

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid-users at filter.luko.org  Tue Oct  4 10:53:39 2016
From: squid-users at filter.luko.org (squid-users at filter.luko.org)
Date: Tue, 4 Oct 2016 21:53:39 +1100
Subject: [squid-users] Introducing delay to HTTP 407 responses
In-Reply-To: <013301d20e8f$12f257f0$38d707d0$@ngtech.co.il>
References: <000301d20e1d$7476f840$5d64e8c0$@filter.luko.org>
 <013301d20e8f$12f257f0$38d707d0$@ngtech.co.il>
Message-ID: <007a01d21e2d$905f1e00$b11d5a00$@filter.luko.org>

Eliezer,

Thankyou for your reply, I tried the following:

> Hey Luke,
> 
> Try to use the next line instead:
> external_acl_type delay ttl=1 negative_ttl=0 cache=0 %SRC %SRCPORT %URI /tmp/delay.pl
> 
> And see what happens.

But it's not introducing a delay into the response.  Running strace across the pid of each child helper doesn't show any activity across those processes either.

I also tried the approach suggested by Amos:

> The outcome of that was a 'ext_delayer_acl helper in Squid-3.5
> 
> <http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_delayer_acl.html>
> 
> It works slightly differently to what was being discussed in the thread.
> see the man page for details on how to configure it.

Using the following config:

external_acl_type delay concurrency=100000 children-max=2 children-startup=1 children-idle=1 cache=10 %URI /tmp/ext_delayer_acl -w 1000 -d
acl http-response-407 http_status 407
acl delay-1sec external delay
http_reply_access deny http-response-407 delay-1sec !all

Debug information from ext_delayer_acl is written to the cache log; I see the processes start up but they are not hit with any requests by Squid.  I also added %SRC %SRCPORT into the configuration, but that didn't seem to help either.

Would the developers be open to adding a configuration-based throttle to authentication responses, avoiding the need for an external helper?  Or alternatively, is there another way to slow down auth responses?  It's comprising about 90% of the log volume (450,000 requests/hr) in badly affected sites at the moment.

Luke




From squid3 at treenet.co.nz  Tue Oct  4 10:56:15 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 4 Oct 2016 23:56:15 +1300
Subject: [squid-users] IPv6 interception crash: Ip::Address::getInAddr :
 Cannot convert non-IPv4 to IPv4.
In-Reply-To: <57F37BED.9040502@egervary.hu>
References: <57F27572.8000600@egervary.hu>
 <ee0c2401-bccf-ad23-8611-af15f9d55906@treenet.co.nz>
 <343a7732-6077-49de-ad8f-5ecb2383f715@egervary.hu>
 <627e937e-7572-862c-fdcf-03e5146a1dea@treenet.co.nz>
 <3f33e001-5c69-ad83-3324-a8cc1565adc4@egervary.hu>
 <71545a1d-6879-cad8-f56e-4835df7f4043@treenet.co.nz>
 <57F37BED.9040502@egervary.hu>
Message-ID: <d741eb47-c65a-e1a5-68b8-3466a5c08853@treenet.co.nz>

On 4/10/2016 10:52 p.m., Egerv?ry Gergely wrote:
>> Is there another defined somewhere else? For some reason your Squid is
>> managing to build with just "nl_inip" (no 'addr') in the field name.
> 
> There's a copy in /usr/include/netinet, but it's the same:
> 
> typedef	struct	natlookup {
> 	i6addr_t	nl_inipaddr;
> 	i6addr_t	nl_outipaddr;
> 	i6addr_t	nl_realipaddr;
> 	int		nl_v;
> 	int		nl_flags;
> 	u_short		nl_inport;
> 	u_short		nl_outport;
> 	u_short		nl_realport;
> } natlookup_t;
> 
> #define	nl_inip		nl_inipaddr.in4
> #define	nl_outip	nl_outipaddr.in4
> #define	nl_realip	nl_realipaddr.in4
> #define	nl_inip6	nl_inipaddr.in6
> #define	nl_outip6	nl_outipaddr.in6
> #define	nl_realip6	nl_realipaddr.in6
> 
> ... so "nl_inip" is a simple #define to nl_inipaddr.in4
> 
> This is from Squid's Intercept.cc:
> 
>     natLookup.nl_inport = htons(newConn->local.port());
>     newConn->local.getInAddr(natLookup.nl_inip);
>     natLookup.nl_outport = htons(newConn->remote.port());
>     newConn->remote.getInAddr(natLookup.nl_outip);
> 
> Is this correct?
> Should we have this in the "else" section of
>   if (newConn->remote.isIPv6()) ... instead?
> 

Aha. Damn macros.

There are a few changes needed, for both v4/v6 inputs and 'realip'
processing. This attached patch should be what you need for Squid-3.5 to
work.

Amos
-------------- next part --------------
=== modified file 'src/ip/Intercept.cc'
--- src/ip/Intercept.cc	2016-04-12 06:52:39 +0000
+++ src/ip/Intercept.cc	2016-10-04 10:35:52 +0000
@@ -207,16 +207,21 @@
         debugs(89, warningLevel, "IPF (IPFilter v4) NAT does not support IPv6. Please upgrade to IPFilter v5.1");
         warningLevel = (warningLevel + 1) % 10;
         return false;
+    }
+    newConn->local.getInAddr(natLookup.nl_inip);
+    newConn->remote.getInAddr(natLookup.nl_outip);
 #else
         natLookup.nl_v = 6;
+        newConn->local.getInAddr(natLookup.nl_inipaddr.in6);
+        newConn->remote.getInAddr(natLookup.nl_outipaddr.in6);
     } else {
         natLookup.nl_v = 4;
+        newConn->local.getInAddr(natLookup.nl_inipaddr.in4);
+        newConn->remote.getInAddr(natLookup.nl_outipaddr.in4);
+    }
 #endif
-    }
     natLookup.nl_inport = htons(newConn->local.port());
-    newConn->local.getInAddr(natLookup.nl_inip);
     natLookup.nl_outport = htons(newConn->remote.port());
-    newConn->remote.getInAddr(natLookup.nl_outip);
     // ... and the TCP flag
     natLookup.nl_flags = IPN_TCP;
 
@@ -281,7 +286,14 @@
         debugs(89, 9, HERE << "address: " << newConn);
         return false;
     } else {
+#if IPFILTER_VERSION < 5000003
         newConn->local = natLookup.nl_realip;
+#else
+        if (newConn->remote.isIPv6())
+            newConn->local = natLookup.nl_realipaddr.in6;
+        else
+            newConn->local = natLookup.nl_realipaddr.in4;
+#endif
         newConn->local.port(ntohs(natLookup.nl_realport));
         debugs(89, 5, HERE << "address NAT: " << newConn);
         return true;


From rentorbuy at yahoo.com  Tue Oct  4 11:07:47 2016
From: rentorbuy at yahoo.com (Vieri)
Date: Tue, 4 Oct 2016 11:07:47 +0000 (UTC)
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
 code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <f4e0b806-587c-ed2e-4941-b5cccbcda0d1@treenet.co.nz>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
 <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
 <2077594026.2082495.1475235384241@mail.yahoo.com>
 <af92d108-b205-decb-13c4-fecb7a554b5e@gmail.com>
 <421701582.3214410.1475478705099@mail.yahoo.com>
 <f4e0b806-587c-ed2e-4941-b5cccbcda0d1@treenet.co.nz>
Message-ID: <1410278953.3964483.1475579267802@mail.yahoo.com>

Hi,

>> Whatever the reason,
>> for an end-user like me it seems that the XP client is able to
>> negotiate TLS correctly with Google and presumably using the cipher
>> DES-CBC3-SHA (maybe after failing with RC4-MD5 on a first attempt),
>> whereas Squid immediately fails with RC4-MD5. It doesn't ever seem to
>> try DES-CBC3-SHA even though it's available in openssl.
>
> ... in this case it might be. But not for the reasons stated. The
> problem known so far is that RC4-MD5 cipher. Why it is not being used by
> your OpenSSL library.
>
> That could bear some further investigation. There may be things you need
> to enable in the config passed to OpenSSL, or a different build of the
> library needed. Something along those lines - Im just guessing here.

Thanks for your reply.

I don't fully understand your point.
I hope you don't mind if I try to make a quick recap here below:

1) www.google.com ONLY allows the following ciphers for TLS V 1.0 (which is the highest TLS version for WinXP IE8):

TLSv1.0:
ciphers:
TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA - strong
TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA - strong
TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong
TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong
TLS_RSA_WITH_3DES_EDE_CBC_SHA - strong
TLS_RSA_WITH_AES_128_CBC_SHA - strong
TLS_RSA_WITH_AES_256_CBC_SHA - strong

Correct?

2) According to https://www.ssllabs.com/ssltest/viewMyClient.html the Windows XP IE8 client supports:
TLS 1.0 and the following cipher list:
TLS_RSA_WITH_RC4_128_MD5 (0x4)   INSECURE 128
TLS_RSA_WITH_RC4_128_SHA (0x5)   INSECURE 128
TLS_RSA_WITH_3DES_EDE_CBC_SHA (0xa)  112
TLS_RSA_WITH_DES_CBC_SHA (0x9)   WEAK 56
TLS_RSA_EXPORT1024_WITH_RC4_56_SHA (0x64)   INSECURE 56
TLS_RSA_EXPORT1024_WITH_DES_CBC_SHA (0x62)   WEAK 56
TLS_RSA_EXPORT_WITH_RC4_40_MD5 (0x3)   INSECURE 40
TLS_RSA_EXPORT_WITH_RC2_CBC_40_MD5 (0x6)   INSECURE 40
TLS_DHE_DSS_WITH_3DES_EDE_CBC_SHA (0x13)   Forward Secrecy2  112
TLS_DHE_DSS_WITH_DES_CBC_SHA (0x12)   WEAK 56
TLS_DHE_DSS_EXPORT1024_WITH_DES_CBC_SHA (0x63)   WEAK 56

of which the least weak are:

TLS_DHE_DSS_WITH_3DES_EDE_CBC_SHA
TLS_RSA_WITH_3DES_EDE_CBC_SHA

Does that sound correct?

3) I'm deducing from the previous two points that the only eligible cipher is TLS_RSA_WITH_3DES_EDE_CBC_SHA because it's the only cipher supported by both google.com and WinXP&IE8.

Right?

4) According to https://testssl.sh/openssl-rfc.mappping.html the openssl cipher name equivalent for TLS_RSA_WITH_3DES_EDE_CBC_SHA is DES-CBC3-SHA.

Correct?

5) So if all the previous points are correct, now I'm assuming that if I run openssl at the command line on the same system where Squid is running then I can "reproduce" what the WinXP client "wants".
I run the following:

# openssl s_client -connect google.com:443 -tls1 -cipher DES-CBC3-SHA
[...]
SSL-Session:
Protocol  : TLSv1
Cipher    : DES-CBC3-SHA
[...]
(that went well)

I also run this other command:

# curl --tlsv1.0 --ciphers DES-CBC3-SHA https://www.google.com --trace trace.log

The trace.log file contains lines such as:
== Info: Cipher selection: DES-CBC3-SHA
Handshake OK and web page is accessed.

Is it correct to assume at this point that the current openssl build on this system is "OK" as far as supporting "Win XP TLS 1.0 ciphers to access at least google.com"?

6) I don't understand why you say that my openssl library does not use RC4-MD5 (did I understand your sentence correctly?). Why should the RC4-MD5 cipher be used in the first place? Who is requesting it? If it's the Windows XP client then it should obviously be discarded since google.com does not support it. So maybe this is what IE8 on XP does: it first tries RC4-MD5 and when that fails, it goes for DES-CBC3-SHA.
In any case, when the WinXP client uses Squid as MITM, Squid *IS* using the RC4-MD5 cipher *AND* my openssl library *does* support this cipher as shown in the following command:

# openssl ciphers
ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:SRP-DSS-AES-256-CBC-SHA:SRP-RSA-AES-256-CBC-SHA:SRP-AES-256-CBC-SHA:DH-DSS-AES256-GCM-SHA384:DHE-DSS-AES256-GCM-SHA384:DH-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA256:DH-RSA-AES256-SHA256:DH-DSS-AES256-SHA256:DHE-RSA-AES256-SHA:DHE-DSS-AES256-SHA:DH-RSA-AES256-SHA:DH-DSS-AES256-SHA:DHE-RSA-CAMELLIA256-SHA:DHE-DSS-CAMELLIA256-SHA:DH-RSA-CAMELLIA256-SHA:DH-DSS-CAMELLIA256-SHA:ECDH-RSA-AES256-GCM-SHA384:ECDH-ECDSA-AES256-GCM-SHA384:ECDH-RSA-AES256-SHA384:ECDH-ECDSA-AES256-SHA384:ECDH-RSA-AES256-SHA:ECDH-ECDSA-AES256-SHA:AES256-GCM-SHA384:AES256-SHA256:AES256-SHA:CAMELLIA256-SHA:PSK-AES256-CBC-SHA:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:SRP-DSS-AES-128-CBC-SHA:SRP-RSA-AES-128-CBC-SHA:SRP-AES-128-CBC-SHA:DH-DSS-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:DH-RSA-AES128-GCM-SHA256:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES128-SHA256:DHE-DSS-AES128-SHA256:DH-RSA-AES128-SHA256:DH-DSS-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA:DH-RSA-AES128-SHA:DH-DSS-AES128-SHA:DHE-RSA-SEED-SHA:DHE-DSS-SEED-SHA:DH-RSA-SEED-SHA:DH-DSS-SEED-SHA:DHE-RSA-CAMELLIA128-SHA:DHE-DSS-CAMELLIA128-SHA:DH-RSA-CAMELLIA128-SHA:DH-DSS-CAMELLIA128-SHA:ECDH-RSA-AES128-GCM-SHA256:ECDH-ECDSA-AES128-GCM-SHA256:ECDH-RSA-AES128-SHA256:ECDH-ECDSA-AES128-SHA256:ECDH-RSA-AES128-SHA:ECDH-ECDSA-AES128-SHA:AES128-GCM-SHA256:AES128-SHA256:AES128-SHA:SEED-SHA:CAMELLIA128-SHA:IDEA-CBC-SHA:PSK-AES128-CBC-SHA:KRB5-IDEA-CBC-SHA:KRB5-IDEA-CBC-MD5:ECDHE-RSA-RC4-SHA:ECDHE-ECDSA-RC4-SHA:ECDH-RSA-RC4-SHA:ECDH-ECDSA-RC4-SHA:RC4-SHA:RC4-MD5:PSK-RC4-SHA:KRB5-RC4-SHA:KRB5-RC4-MD5:ECDHE-RSA-DES-CBC3-SHA:ECDHE-ECDSA-DES-CBC3-SHA:SRP-DSS-3DES-EDE-CBC-SHA:SRP-RSA-3DES-EDE-CBC-SHA:SRP-3DES-EDE-CBC-SHA:EDH-RSA-DES-CBC3-SHA:EDH-DSS-DES-CBC3-SHA:DH-RSA-DES-CBC3-SHA:DH-DSS-DES-CBC3-SHA:ECDH-RSA-DES-CBC3-SHA:ECDH-ECDSA-DES-CBC3-SHA:DES-CBC3-SHA:PSK-3DES-EDE-CBC-SHA:KRB5-DES-CBC3-SHA:KRB5-DES-CBC3-MD5:EDH-RSA-DES-CBC-SHA:EDH-DSS-DES-CBC-SHA:DH-RSA-DES-CBC-SHA:DH-DSS-DES-CBC-SHA:DES-CBC-SHA:KRB5-DES-CBC-SHA:KRB5-DES-CBC-MD5

Am I right?

7) Squid uses openssl, right?

8) If the previous point is true then shouldn't I assume that Squid should have the same features as the ones I can "reproduce" by running the openssl commands as in the above examples?
In other words, shouldn't Squid "support" both RC4-MD5 and DES-CBC3-SHA?

9) If all the previous points are true then:
a) I'm lucky
b) I'd like to know if the issue is simply the fact that Squid is unable to do anything with WinXP&IE8 clients that wrongly ask to use a cipher that's not supoprted by a given web site. Since it's MITM, Squid can't negotiate another cipher I suppose. But then again, like I said before, I don't know how the internals work.

10) I'm not stating that "working TLS behaviour is a bug in Squid". I'm merely assuming that if some modern TLS 1.2 clients can connect seemlessly with Squid in a MITM scenario (intercepted ssl-bump) then the same should happen with older TLS 1.0 clients when connecting to sites that supoprt both the protocol and the ciphers.

Is that an incorrect assumption?

If the WinXP client is faulty because it doesn't abide to the standard protocol then I'll assume it can't be used with Squid as MITM and force users to browse with FF or upgrade their OS.

Thanks,

Vieri


From squid3 at treenet.co.nz  Tue Oct  4 11:11:08 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 5 Oct 2016 00:11:08 +1300
Subject: [squid-users] Squid - AD kerberos auth and Linux Server proxy
 access not working
In-Reply-To: <201610041236.25242.Antony.Stone@squid.open.source.it>
References: <OF4588894B.96613DF1-ON80258042.00392BFE-80258042.0039900A@tcs.com>
 <201610041236.25242.Antony.Stone@squid.open.source.it>
Message-ID: <d35ad0ca-761d-60e3-c594-04697110afdc@treenet.co.nz>

On 4/10/2016 11:36 p.m., Antony Stone wrote:
> On Tuesday 04 October 2016 at 12:28:44, Nilesh Gavali wrote:
> 
>> Hello Antony;
>> I have double checked the current working configuration of my squid.conf
>> and it has same settings which I posted earlier. somehow it is working for
>> us.
> 
> I'm not saying the whole thing won't work; I'm saying there is no point in 
> having a line "http_access allow ad_auth" following the line "http_access deny 
> all".  The ad_auth line can never be invoked.

Not knowing why authentication works is dangerous. You might have been
allowing non-authenticated traffic and invalid user accounts through.

The only reason it does "work" is that the ACL called "USERS" is _not_
actually checking user logins. It is a group checking ACL which requires
authentication to happen before it can be checked.

In this specific case invalid logins cannot be a member of the group. So
they will not get through the proxy.

However, people who accidentally type the user/password wrong, or whose
machines automatically login with an account not a member of the group
will not be allowed any way to try again short of shutting down their
browser or maybe even logging out of the machine and trying from another
one.

That may or may not be a problem for you.

> 
>> below is the error from access.log file.
>>
>> 1475518342.279      0 10.xx.15.103 TCP_DENIED/407 3589 CONNECT
>> vseries-test.bottomline.com:443 - NONE/- text/html
> 
> Error 407 is "proxy auth required", so the proxy is expecting authentication 
> for some reason.
> 
> Can you confirm that the hostname vseries-test.bottomline.com is contained in 
> your site file /etc/squid/sitelist/dbs_allowed_site ?
> 
> Can you temporarily change the line "http_access allow IWCCP01 allowedsite" to 
> "http_access allow IWCCP01" and see whether the machine then gets access?
> 

If that works, please list the output of the command:
  grep "bottomline.com" /etc/squid/sitelist/dbs_allowed_site

Amos



From squid3 at treenet.co.nz  Tue Oct  4 11:18:43 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 5 Oct 2016 00:18:43 +1300
Subject: [squid-users] Introducing delay to HTTP 407 responses
In-Reply-To: <007a01d21e2d$905f1e00$b11d5a00$@filter.luko.org>
References: <000301d20e1d$7476f840$5d64e8c0$@filter.luko.org>
 <013301d20e8f$12f257f0$38d707d0$@ngtech.co.il>
 <007a01d21e2d$905f1e00$b11d5a00$@filter.luko.org>
Message-ID: <c521b757-2596-e122-d468-84ebbc5528c0@treenet.co.nz>

On 4/10/2016 11:53 p.m., squid-users at filter.luko.org wrote:
> Eliezer,
> 
> Thankyou for your reply, I tried the following:
> 
>> Hey Luke,
>>
>> Try to use the next line instead:
>> external_acl_type delay ttl=1 negative_ttl=0 cache=0 %SRC %SRCPORT %URI /tmp/delay.pl
>>
>> And see what happens.
> 
> But it's not introducing a delay into the response.  Running strace across the pid of each child helper doesn't show any activity across those processes either.
> 

The purpose of that helper is to receive all lookups, and actively pause
responding to them. Having any TTL/cache values except "ttl=0
negative_ttl=0 cache=0" in those options bypasses the helper.


> I also tried the approach suggested by Amos:
> 
>> The outcome of that was a 'ext_delayer_acl helper in Squid-3.5
>>
>> <http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_delayer_acl.html>
>>
>> It works slightly differently to what was being discussed in the thread.
>> see the man page for details on how to configure it.
> 
> Using the following config:
> 
> external_acl_type delay concurrency=100000 children-max=2 children-startup=1 children-idle=1 cache=10 %URI /tmp/ext_delayer_acl -w 1000 -d
> acl http-response-407 http_status 407
> acl delay-1sec external delay
> http_reply_access deny http-response-407 delay-1sec !all
> 
> Debug information from ext_delayer_acl is written to the cache log; I see the processes start up but they are not hit with any requests by Squid.  I also added %SRC %SRCPORT into the configuration, but that didn't seem to help either.
> 
> Would the developers be open to adding a configuration-based throttle to authentication responses, avoiding the need for an external helper?  Or alternatively, is there another way to slow down auth responses?  It's comprising about 90% of the log volume (450,000 requests/hr) in badly affected sites at the moment.
> 

This helper is the mechanism that we accepted. Anything else would be
far less useful.

I think the results you are getting show that the http_status ACL is not
working properly.

Can you get a "debug_options 28,5" cache.log trace and see if
"aclMatchHTTPStatus" is matching anything or "http-response-407" even
being tested?

Amos



From gergely at egervary.hu  Tue Oct  4 11:38:56 2016
From: gergely at egervary.hu (=?UTF-8?Q?Egerv=c3=a1ry_Gergely?=)
Date: Tue, 4 Oct 2016 13:38:56 +0200
Subject: [squid-users] IPv6 interception crash: Ip::Address::getInAddr :
 Cannot convert non-IPv4 to IPv4.
In-Reply-To: <d741eb47-c65a-e1a5-68b8-3466a5c08853@treenet.co.nz>
References: <57F27572.8000600@egervary.hu>
 <ee0c2401-bccf-ad23-8611-af15f9d55906@treenet.co.nz>
 <343a7732-6077-49de-ad8f-5ecb2383f715@egervary.hu>
 <627e937e-7572-862c-fdcf-03e5146a1dea@treenet.co.nz>
 <3f33e001-5c69-ad83-3324-a8cc1565adc4@egervary.hu>
 <71545a1d-6879-cad8-f56e-4835df7f4043@treenet.co.nz>
 <57F37BED.9040502@egervary.hu>
 <d741eb47-c65a-e1a5-68b8-3466a5c08853@treenet.co.nz>
Message-ID: <57F394D0.40300@egervary.hu>

> Aha. Damn macros.
> 
> There are a few changes needed, for both v4/v6 inputs and 'realip'
> processing. This attached patch should be what you need for Squid-3.5 to
> work.

Getting closer, but still not there...

The browser client is 2001:738:7a00:a::a:d, the remote destination is
2001:4c48:2:268::2:1c

The ipnat state table entry:
RDR 2001:738:7a00:a::14 3128  <- -> 2001:4c48:2:268::2:1c 80
[2001:738:7a00:a::a:d 56623]

Squid log:

2016/10/04 13:16:33.365 kid1| 51,3| fd.cc(198) fd_open: fd_open() FD 22
HTTP Request
2016/10/04 13:16:33.366 kid1| 89,5| Intercept.cc(391) Lookup: address
BEGIN: me/client= [2001:738:7a00:a::14]:3128, destination/me=
[2001:738:7a00:a::14]:65491
2016/10/04 13:16:33.366 kid1| 89,9| Intercept.cc(290) IpfInterception:
address: local=[2001:738:7a00:a::14]:3128
remote=[2001:738:7a00:a::14]:65491 FD 22 flags=33
2016/10/04 13:16:33.366 kid1| ERROR: NAT/TPROXY lookup failed to locate
original IPs on local=[2001:738:7a00:a::14]:3128
remote=[2001:738:7a00:a::14]:65491 FD 22 flags=33
2016/10/04 13:16:33.366 kid1| 5,5| TcpAcceptor.cc(287) acceptOne:
Listener: local=[2001:738:7a00:a::14]:3128 remote=[::] FD 1
9 flags=41 accepted new connection local=[2001:738:7a00:a::14]:3128
remote=[2001:738:7a00:a::14]:65491 FD 22 flags=33 handler
 Subscription: 0x16acf40*1

--
Gergely EGERVARY



From squid-users at filter.luko.org  Tue Oct  4 11:47:32 2016
From: squid-users at filter.luko.org (squid-users at filter.luko.org)
Date: Tue, 4 Oct 2016 22:47:32 +1100
Subject: [squid-users] Introducing delay to HTTP 407 responses
In-Reply-To: <c521b757-2596-e122-d468-84ebbc5528c0@treenet.co.nz>
References: <000301d20e1d$7476f840$5d64e8c0$@filter.luko.org>
 <013301d20e8f$12f257f0$38d707d0$@ngtech.co.il>
 <007a01d21e2d$905f1e00$b11d5a00$@filter.luko.org>
 <c521b757-2596-e122-d468-84ebbc5528c0@treenet.co.nz>
Message-ID: <009d01d21e35$179582e0$46c088a0$@filter.luko.org>

Amos,

> This helper is the mechanism that we accepted. Anything else would be far
> less useful.

Makes sense.

> I think the results you are getting show that the http_status ACL is not
> working properly.
> 
> Can you get a "debug_options 28,5" cache.log trace and see if
> "aclMatchHTTPStatus" is matching anything or "http-response-407" even
> being tested?

I set this up as you suggested, then triggered a 407 response from the cache.  It seems that way; I couldn't see aclMatchHTTPStatus or http-response-407 in the log:

2016/10/04 22:37:12.656 kid1| 28,3| Checklist.cc(70) preCheck: 0x7ffcaaa6a540 checking fast rules
2016/10/04 22:37:12.656 kid1| 28,5| Checklist.cc(346) fastCheck: aclCheckFast: list: 0x1c3da68
2016/10/04 22:37:12.656 kid1| 28,5| Acl.cc(138) matches: checking snmp_access
2016/10/04 22:37:12.656 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/0is not banned
2016/10/04 22:37:12.656 kid1| 28,5| Acl.cc(138) matches: checking snmp_access#1
2016/10/04 22:37:12.656 kid1| 28,5| Acl.cc(138) matches: checking localhost
2016/10/04 22:37:12.656 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '127.0.0.1:34818' found
2016/10/04 22:37:12.656 kid1| 28,3| Acl.cc(158) matches: checked: localhost = 1
2016/10/04 22:37:12.656 kid1| 28,3| Acl.cc(158) matches: checked: snmp_access#1 = 1
2016/10/04 22:37:12.656 kid1| 28,3| Acl.cc(158) matches: checked: snmp_access = 1
2016/10/04 22:37:12.656 kid1| 28,3| Checklist.cc(63) markFinished: 0x7ffcaaa6a540 answer ALLOWED for match
2016/10/04 22:37:12.656 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffcaaa6a540
2016/10/04 22:37:12.656 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffcaaa6a540
2016/10/04 22:37:12.657 kid1| 28,3| Checklist.cc(70) preCheck: 0x7ffcaaa6a540 checking fast rules
2016/10/04 22:37:12.657 kid1| 28,5| Checklist.cc(346) fastCheck: aclCheckFast: list: 0x1c3da68
2016/10/04 22:37:12.657 kid1| 28,5| Acl.cc(138) matches: checking snmp_access
2016/10/04 22:37:12.657 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/0is not banned
2016/10/04 22:37:12.657 kid1| 28,5| Acl.cc(138) matches: checking snmp_access#1
2016/10/04 22:37:12.657 kid1| 28,5| Acl.cc(138) matches: checking localhost
2016/10/04 22:37:12.657 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '127.0.0.1:34818' found
2016/10/04 22:37:12.657 kid1| 28,3| Acl.cc(158) matches: checked: localhost = 1
2016/10/04 22:37:12.657 kid1| 28,3| Acl.cc(158) matches: checked: snmp_access#1 = 1
2016/10/04 22:37:12.657 kid1| 28,3| Acl.cc(158) matches: checked: snmp_access = 1
2016/10/04 22:37:12.657 kid1| 28,3| Checklist.cc(63) markFinished: 0x7ffcaaa6a540 answer ALLOWED for match
2016/10/04 22:37:12.657 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffcaaa6a540
2016/10/04 22:37:12.657 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffcaaa6a540
2016/10/04 22:37:17.697 kid1| 28,3| Checklist.cc(70) preCheck: 0x7ffcaaa6a540 checking fast rules
2016/10/04 22:37:17.697 kid1| 28,5| Checklist.cc(346) fastCheck: aclCheckFast: list: 0x1c3da68
2016/10/04 22:37:17.697 kid1| 28,5| Acl.cc(138) matches: checking snmp_access
2016/10/04 22:37:17.697 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/0is not banned
2016/10/04 22:37:17.697 kid1| 28,5| Acl.cc(138) matches: checking snmp_access#1
2016/10/04 22:37:17.697 kid1| 28,5| Acl.cc(138) matches: checking localhost
2016/10/04 22:37:17.697 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '127.0.0.1:34912' found
2016/10/04 22:37:17.697 kid1| 28,3| Acl.cc(158) matches: checked: localhost = 1
2016/10/04 22:37:17.697 kid1| 28,3| Acl.cc(158) matches: checked: snmp_access#1 = 1
2016/10/04 22:37:17.697 kid1| 28,3| Acl.cc(158) matches: checked: snmp_access = 1
2016/10/04 22:37:17.697 kid1| 28,3| Checklist.cc(63) markFinished: 0x7ffcaaa6a540 answer ALLOWED for match
2016/10/04 22:37:17.697 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffcaaa6a540
2016/10/04 22:37:17.697 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffcaaa6a540
2016/10/04 22:37:17.698 kid1| 28,3| Checklist.cc(70) preCheck: 0x7ffcaaa6a540 checking fast rules
2016/10/04 22:37:17.698 kid1| 28,5| Checklist.cc(346) fastCheck: aclCheckFast: list: 0x1c3da68
2016/10/04 22:37:17.698 kid1| 28,5| Acl.cc(138) matches: checking snmp_access
2016/10/04 22:37:17.698 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/0is not banned
2016/10/04 22:37:17.698 kid1| 28,5| Acl.cc(138) matches: checking snmp_access#1
2016/10/04 22:37:17.698 kid1| 28,5| Acl.cc(138) matches: checking localhost
2016/10/04 22:37:17.698 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '127.0.0.1:34912' found
2016/10/04 22:37:17.698 kid1| 28,3| Acl.cc(158) matches: checked: localhost = 1
2016/10/04 22:37:17.698 kid1| 28,3| Acl.cc(158) matches: checked: snmp_access#1 = 1
2016/10/04 22:37:17.698 kid1| 28,3| Acl.cc(158) matches: checked: snmp_access = 1
2016/10/04 22:37:17.698 kid1| 28,3| Checklist.cc(63) markFinished: 0x7ffcaaa6a540 answer ALLOWED for match
2016/10/04 22:37:17.698 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffcaaa6a540
2016/10/04 22:37:17.698 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffcaaa6a540
2016/10/04 22:37:18.149 kid1| 28,4| Eui48.cc(178) lookup: id=0x1e34884 query ARP table
2016/10/04 22:37:18.149 kid1| 28,4| Eui48.cc(222) lookup: id=0x1e34884 query ARP on each interface (160 found)
2016/10/04 22:37:18.149 kid1| 28,4| Eui48.cc(228) lookup: id=0x1e34884 found interface lo
2016/10/04 22:37:18.149 kid1| 28,4| Eui48.cc(228) lookup: id=0x1e34884 found interface eth0
2016/10/04 22:37:18.149 kid1| 28,4| Eui48.cc(237) lookup: id=0x1e34884 looking up ARP address for 10.159.192.19 on eth0
2016/10/04 22:37:18.149 kid1| 28,4| Eui48.cc(280) lookup: id=0x1e34884 got address 00:15:5d:c0:11:3f on eth0
2016/10/04 22:37:18.150 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffcaaa6a390
2016/10/04 22:37:18.150 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffcaaa6a390
2016/10/04 22:37:18.150 kid1| 28,3| Checklist.cc(70) preCheck: 0x22e7f98 checking slow rules
2016/10/04 22:37:18.150 kid1| 28,5| Acl.cc(138) matches: checking http_access
2016/10/04 22:37:18.150 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/0is not banned
2016/10/04 22:37:18.150 kid1| 28,5| Acl.cc(138) matches: checking http_access#1
2016/10/04 22:37:18.150 kid1| 28,5| Acl.cc(138) matches: checking to_self
2016/10/04 22:37:18.150 kid1| 28,3| DestinationIp.cc(70) match: aclMatchAcl: Can't yet compare 'to_self' ACL for 'www.theage.com.au'
2016/10/04 22:37:18.150 kid1| 28,3| Acl.cc(158) matches: checked: to_self = -1 async
2016/10/04 22:37:18.150 kid1| 28,3| Acl.cc(158) matches: checked: http_access#1 = -1 async
2016/10/04 22:37:18.150 kid1| 28,3| Acl.cc(158) matches: checked: http_access = -1 async
2016/10/04 22:37:18.160 kid1| 28,5| InnerNode.cc(94) resumeMatchingAt: checking http_access at 0
2016/10/04 22:37:18.160 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/0is not banned
2016/10/04 22:37:18.160 kid1| 28,5| InnerNode.cc(94) resumeMatchingAt: checking http_access#1 at 0
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking to_self
2016/10/04 22:37:18.160 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '150.101.161.17' NOT found
2016/10/04 22:37:18.160 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '150.101.161.26' NOT found
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: to_self = 0
2016/10/04 22:37:18.160 kid1| 28,3| InnerNode.cc(97) resumeMatchingAt: checked: http_access#1 = 0
2016/10/04 22:37:18.160 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/0is not banned
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking http_access#2
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking localhost
2016/10/04 22:37:18.160 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '10.159.192.19:36466' NOT found
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: localhost = 0
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: http_access#2 = 0
2016/10/04 22:37:18.160 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/0is not banned
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking http_access#3
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking localhost
2016/10/04 22:37:18.160 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '10.159.192.19:36466' NOT found
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: localhost = 0
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: http_access#3 = 0
2016/10/04 22:37:18.160 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'DENIED/0is not banned
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking http_access#4
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking manager
2016/10/04 22:37:18.160 kid1| 28,3| RegexData.cc(51) match: aclRegexData::match: checking 'http://www.theage.com.au/'
2016/10/04 22:37:18.160 kid1| 28,3| RegexData.cc(62) match: aclRegexData::match: looking for '(^cache_object://)'
2016/10/04 22:37:18.160 kid1| 28,3| RegexData.cc(62) match: aclRegexData::match: looking for '(^https?://[^/]+/squid-internal-mgr/)'
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: manager = 0
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: http_access#4 = 0
2016/10/04 22:37:18.160 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/0is not banned
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking http_access#5
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking localhost
2016/10/04 22:37:18.160 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '10.159.192.19:36466' NOT found
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: localhost = 0
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: http_access#5 = 0
2016/10/04 22:37:18.160 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'DENIED/0is not banned
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking http_access#6
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking http-connect
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: http-connect = 0
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: http_access#6 = 0
2016/10/04 22:37:18.160 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'DENIED/0is not banned
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking http_access#7
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking !safe-ports
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking safe-ports
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: safe-ports = 1
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: !safe-ports = 0
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: http_access#7 = 0
2016/10/04 22:37:18.160 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'DENIED/0is not banned
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking http_access#8
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking !srcip-local
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking srcip-local
2016/10/04 22:37:18.160 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '10.159.192.19:36466' found
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: srcip-local = 1
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: !srcip-local = 0
2016/10/04 22:37:18.160 kid1| 28,3| Acl.cc(158) matches: checked: http_access#8 = 0
2016/10/04 22:37:18.160 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/0is not banned
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking http_access#9
2016/10/04 22:37:18.160 kid1| 28,5| Acl.cc(138) matches: checking require_auth
2016/10/04 22:37:18.160 kid1| 28,3| AclProxyAuth.cc(119) checkForAsync: checking password via authenticator
2016/10/04 22:37:18.160 kid1| Starting new basicauthenticator helpers...
2016/10/04 22:37:18.161 kid1| 28,4| Acl.cc(70) AuthenticateAcl: returning 2 sending credentials to helper.
2016/10/04 22:37:18.161 kid1| 28,3| Acl.cc(158) matches: checked: require_auth = -1 async
2016/10/04 22:37:18.161 kid1| 28,3| Acl.cc(158) matches: checked: http_access#9 = -1 async
2016/10/04 22:37:18.161 kid1| 28,3| InnerNode.cc(97) resumeMatchingAt: checked: http_access = -1 async
2016/10/04 22:37:18.197 kid1| 28,5| InnerNode.cc(94) resumeMatchingAt: checking http_access at 8
2016/10/04 22:37:18.197 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/0is not banned
2016/10/04 22:37:18.197 kid1| 28,5| InnerNode.cc(94) resumeMatchingAt: checking http_access#9 at 0
2016/10/04 22:37:18.197 kid1| 28,5| Acl.cc(138) matches: checking require_auth
2016/10/04 22:37:18.197 kid1| 28,4| Acl.cc(76) AuthenticateAcl: returning 3 sending authentication challenge.
2016/10/04 22:37:18.197 kid1| 28,3| Checklist.cc(63) markFinished: 0x22e7f98 answer AUTH_REQUIRED for AuthenticateAcl exception
2016/10/04 22:37:18.197 kid1| 28,3| Acl.cc(158) matches: checked: require_auth = -1
2016/10/04 22:37:18.197 kid1| 28,3| InnerNode.cc(97) resumeMatchingAt: checked: http_access#9 = -1
2016/10/04 22:37:18.197 kid1| 28,3| InnerNode.cc(97) resumeMatchingAt: checked: http_access = -1
2016/10/04 22:37:18.197 kid1| 28,3| Checklist.cc(163) checkCallback: ACLChecklist::checkCallback: 0x22e7f98 answer=AUTH_REQUIRED
2016/10/04 22:37:18.197 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffcaaa6a290
2016/10/04 22:37:18.197 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffcaaa6a290
2016/10/04 22:37:18.197 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffcaaa6a0d0
2016/10/04 22:37:18.197 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffcaaa6a0d0
2016/10/04 22:37:18.197 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x22e7f98
2016/10/04 22:37:18.197 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x22e7f98
2016/10/04 22:37:18.197 kid1| 28,3| Checklist.cc(70) preCheck: 0x7ffcaaa6a430 checking fast ACLs
2016/10/04 22:37:18.197 kid1| 28,5| Acl.cc(138) matches: checking access_log /var/log/squid/access.log
2016/10/04 22:37:18.197 kid1| 28,5| Acl.cc(138) matches: checking (access_log /var/log/squid/access.log line)
2016/10/04 22:37:18.197 kid1| 28,3| Acl.cc(158) matches: checked: (access_log /var/log/squid/access.log line) = 1
2016/10/04 22:37:18.197 kid1| 28,3| Acl.cc(158) matches: checked: access_log /var/log/squid/access.log = 1
2016/10/04 22:37:18.197 kid1| 28,3| Checklist.cc(63) markFinished: 0x7ffcaaa6a430 answer ALLOWED for match
2016/10/04 22:37:18.197 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffcaaa6a430
2016/10/04 22:37:18.197 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffcaaa6a430
2016/10/04 22:37:22.738 kid1| 28,3| Checklist.cc(70) preCheck: 0x7ffcaaa6a540 checking fast rules
2016/10/04 22:37:22.738 kid1| 28,5| Checklist.cc(346) fastCheck: aclCheckFast: list: 0x1c3da68
2016/10/04 22:37:22.738 kid1| 28,5| Acl.cc(138) matches: checking snmp_access
2016/10/04 22:37:22.738 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/0is not banned
2016/10/04 22:37:22.738 kid1| 28,5| Acl.cc(138) matches: checking snmp_access#1
2016/10/04 22:37:22.738 kid1| 28,5| Acl.cc(138) matches: checking localhost
2016/10/04 22:37:22.738 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '127.0.0.1:38013' found
2016/10/04 22:37:22.738 kid1| 28,3| Acl.cc(158) matches: checked: localhost = 1
2016/10/04 22:37:22.738 kid1| 28,3| Acl.cc(158) matches: checked: snmp_access#1 = 1
2016/10/04 22:37:22.738 kid1| 28,3| Acl.cc(158) matches: checked: snmp_access = 1
2016/10/04 22:37:22.738 kid1| 28,3| Checklist.cc(63) markFinished: 0x7ffcaaa6a540 answer ALLOWED for match
2016/10/04 22:37:22.738 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffcaaa6a540
2016/10/04 22:37:22.738 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffcaaa6a540
2016/10/04 22:37:22.739 kid1| 28,3| Checklist.cc(70) preCheck: 0x7ffcaaa6a540 checking fast rules
2016/10/04 22:37:22.739 kid1| 28,5| Checklist.cc(346) fastCheck: aclCheckFast: list: 0x1c3da68
2016/10/04 22:37:22.739 kid1| 28,5| Acl.cc(138) matches: checking snmp_access
2016/10/04 22:37:22.739 kid1| 28,5| Checklist.cc(400) bannedAction: Action 'ALLOWED/0is not banned
2016/10/04 22:37:22.739 kid1| 28,5| Acl.cc(138) matches: checking snmp_access#1
2016/10/04 22:37:22.739 kid1| 28,5| Acl.cc(138) matches: checking localhost
2016/10/04 22:37:22.739 kid1| 28,3| Ip.cc(539) match: aclIpMatchIp: '127.0.0.1:38013' found
2016/10/04 22:37:22.739 kid1| 28,3| Acl.cc(158) matches: checked: localhost = 1
2016/10/04 22:37:22.739 kid1| 28,3| Acl.cc(158) matches: checked: snmp_access#1 = 1
2016/10/04 22:37:22.739 kid1| 28,3| Acl.cc(158) matches: checked: snmp_access = 1
2016/10/04 22:37:22.739 kid1| 28,3| Checklist.cc(63) markFinished: 0x7ffcaaa6a540 answer ALLOWED for match
2016/10/04 22:37:22.739 kid1| 28,4| FilledChecklist.cc(66) ~ACLFilledChecklist: ACLFilledChecklist destroyed 0x7ffcaaa6a540
2016/10/04 22:37:22.739 kid1| 28,4| Checklist.cc(197) ~ACLChecklist: ACLChecklist::~ACLChecklist: destroyed 0x7ffcaaa6a540

Luke




From squid3 at treenet.co.nz  Tue Oct  4 12:06:02 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 5 Oct 2016 01:06:02 +1300
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
 code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <1410278953.3964483.1475579267802@mail.yahoo.com>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
 <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
 <2077594026.2082495.1475235384241@mail.yahoo.com>
 <af92d108-b205-decb-13c4-fecb7a554b5e@gmail.com>
 <421701582.3214410.1475478705099@mail.yahoo.com>
 <f4e0b806-587c-ed2e-4941-b5cccbcda0d1@treenet.co.nz>
 <1410278953.3964483.1475579267802@mail.yahoo.com>
Message-ID: <2aeb5cbc-67aa-0742-efb1-ab123c638bc6@treenet.co.nz>

On 5/10/2016 12:07 a.m., Vieri wrote:
> Hi,
> 
>>> Whatever the reason, for an end-user like me it seems that the XP
>>> client is able to negotiate TLS correctly with Google and
>>> presumably using the cipher DES-CBC3-SHA (maybe after failing
>>> with RC4-MD5 on a first attempt), whereas Squid immediately fails
>>> with RC4-MD5. It doesn't ever seem to try DES-CBC3-SHA even
>>> though it's available in openssl.
>> 
>> ... in this case it might be. But not for the reasons stated. The 
>> problem known so far is that RC4-MD5 cipher. Why it is not being
>> used by your OpenSSL library.
>> 
>> That could bear some further investigation. There may be things you
>> need to enable in the config passed to OpenSSL, or a different
>> build of the library needed. Something along those lines - Im just
>> guessing here.
> 
> Thanks for your reply.
> 
> I don't fully understand your point. I hope you don't mind if I try
> to make a quick recap here below:
> 
> 1) www.google.com ONLY allows the following ciphers for TLS V 1.0
> (which is the highest TLS version for WinXP IE8):
> 
> TLSv1.0: ciphers: TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA - strong 
> TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA - strong 
> TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong 
> TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong 
> TLS_RSA_WITH_3DES_EDE_CBC_SHA - strong TLS_RSA_WITH_AES_128_CBC_SHA -
> strong TLS_RSA_WITH_AES_256_CBC_SHA - strong
> 
> Correct?
> 

Insufficient data. Assuming true ...


> 2) According to https://www.ssllabs.com/ssltest/viewMyClient.html the
> Windows XP IE8 client supports: TLS 1.0 and the following cipher
> list: TLS_RSA_WITH_RC4_128_MD5 (0x4)   INSECURE 128 
> TLS_RSA_WITH_RC4_128_SHA (0x5)   INSECURE 128 
> TLS_RSA_WITH_3DES_EDE_CBC_SHA (0xa)  112 TLS_RSA_WITH_DES_CBC_SHA
> (0x9)   WEAK 56 TLS_RSA_EXPORT1024_WITH_RC4_56_SHA (0x64)   INSECURE
> 56 TLS_RSA_EXPORT1024_WITH_DES_CBC_SHA (0x62)   WEAK 56 
> TLS_RSA_EXPORT_WITH_RC4_40_MD5 (0x3)   INSECURE 40 
> TLS_RSA_EXPORT_WITH_RC2_CBC_40_MD5 (0x6)   INSECURE 40 
> TLS_DHE_DSS_WITH_3DES_EDE_CBC_SHA (0x13)   Forward Secrecy2  112 
> TLS_DHE_DSS_WITH_DES_CBC_SHA (0x12)   WEAK 56 
> TLS_DHE_DSS_EXPORT1024_WITH_DES_CBC_SHA (0x63)   WEAK 56
> 
> of which the least weak are:
> 
> TLS_DHE_DSS_WITH_3DES_EDE_CBC_SHA TLS_RSA_WITH_3DES_EDE_CBC_SHA
> 
> Does that sound correct?
> 

Insufficient data. Assuming true ...


> 3) I'm deducing from the previous two points that the only eligible
> cipher is TLS_RSA_WITH_3DES_EDE_CBC_SHA because it's the only cipher
> supported by both google.com and WinXP&IE8.
> 
> Right?
> 

Yes. Qualified by above assumptions.


> 4) According to https://testssl.sh/openssl-rfc.mappping.html the
> openssl cipher name equivalent for TLS_RSA_WITH_3DES_EDE_CBC_SHA is
> DES-CBC3-SHA.
> 
> Correct?

Yes.

> 
> 5) So if all the previous points are correct, now I'm assuming that
> if I run openssl at the command line on the same system where Squid
> is running then I can "reproduce" what the WinXP client "wants". I
> run the following:
> 
> # openssl s_client -connect google.com:443 -tls1 -cipher
> DES-CBC3-SHA [...] SSL-Session: Protocol  : TLSv1 Cipher    :
> DES-CBC3-SHA [...] (that went well)
> 
> I also run this other command:
> 
> # curl --tlsv1.0 --ciphers DES-CBC3-SHA https://www.google.com
> --trace trace.log
> 
> The trace.log file contains lines such as: == Info: Cipher selection:
> DES-CBC3-SHA Handshake OK and web page is accessed.
> 
> Is it correct to assume at this point that the current openssl build
> on this system is "OK" as far as supporting "Win XP TLS 1.0 ciphers
> to access at least google.com"?

Yes. The build is capable of it. That is one of 3 conditions that must
be met for it to work.

The other two being:

* whether it is enabled in the library config.
 - OpenSSL library has its own conf file somewhere.
 - it is possible that curl and other tools whose primary design purpose
is communication (not testing) override the library normal defaults for
their own use, or re-try certain things after failures. That needs to be
eliminated to be sure.

* that the squid.conf settings combine with those library settings to
cause it to be (or stay) enabled.


> 
> 6) I don't understand why you say that my openssl library does not
> use RC4-MD5 (did I understand your sentence correctly?). Why should
> the RC4-MD5 cipher be used in the first place? Who is requesting it?
> If it's the Windows XP client then it should obviously be discarded
> since google.com does not support it. So maybe this is what IE8 on XP
> does: it first tries RC4-MD5 and when that fails, it goes for
> DES-CBC3-SHA. In any case, when the WinXP client uses Squid as MITM,
> Squid *IS* using the RC4-MD5 cipher *AND* my openssl library *does*
> support this cipher as shown in the following command:
> 
> # openssl ciphers 
> ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:SRP-DSS-AES-256-CBC-SHA:SRP-RSA-AES-256-CBC-SHA:SRP-AES-256-CBC-SHA:DH-DSS-AES256-GCM-SHA384:DHE-DSS-AES256-GCM-SHA384:DH-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA256:DH-RSA-AES256-SHA256:DH-DSS-AES256-SHA256:DHE-RSA-AES256-SHA:DHE-DSS-AES256-SHA:DH-RSA-AES256-SHA:DH-DSS-AES256-SHA:DHE-RSA-CAMELLIA256-SHA:DHE-DSS-CAMELLIA256-SHA:DH-RSA-CAMELLIA256-SHA:DH-DSS-CAMELLIA256-SHA:ECDH-RSA-AES256-GCM-SHA384:ECDH-ECDSA-AES256-GCM-SHA384:ECDH-RSA-AES256-SHA384:ECDH-ECDSA-AES256-SHA384:ECDH-RSA-AES256-SHA:ECDH-ECDSA-AES256-SHA:AES256-GCM-SHA384:AES256-SHA256:AES256-SHA:CAMELLIA256-SHA:PSK-AES256-CBC-SHA:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:SRP-DSS-AES-128-CBC-SHA:SRP-RSA-AES-128-CBC-SHA:SRP-AES-128-CBC-SHA:DH-DSS-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:DH-RSA-AES128-GCM-SHA256:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES128-SHA256:DHE-DSS-AES128-SHA256:DH-RSA-AES128-SHA256:DH-DSS-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA:DH-RSA-AES128-SHA:DH-DSS-AES128-SHA:DHE-RSA-SEED-SHA:DHE-DSS-SEED-SHA:DH-RSA-SEED-SHA:DH-DSS-SEED-SHA:DHE-RSA-CAMELLIA128-SHA:DHE-DSS-CAMELLIA128-SHA:DH-RSA-CAMELLIA128-SHA:DH-DSS-CAMELLIA128-SHA:ECDH-RSA-AES128-GCM-SHA256:ECDH-ECDSA-AES128-GCM-SHA256:ECDH-RSA-AES128-SHA256:ECDH-ECDSA-AES128-SHA256:ECDH-RSA-AES128-SHA:ECDH-ECDSA-AES128-SHA:AES128-GCM-SHA256:AES128-SHA256:AES128-SHA:SEED-SHA:CAMELLIA128-SHA:IDEA-CBC-SHA:PSK-AES128-CBC-SHA:KRB5-IDEA-CBC-SHA:KRB5-IDEA-CBC-MD5:ECDHE-RSA-RC4-SHA:ECDHE-ECDSA-RC4-SHA:ECDH-RSA-RC4-SHA:ECDH-ECDSA-RC4-SHA:RC4-SHA:RC4-MD5:PSK-RC4-SHA:KRB5-RC4-SHA:KRB5-RC4-MD5:ECDHE-RSA-DES-CBC3-SHA:ECDHE-ECDSA-DES-CBC3-SHA:SRP-DSS-3DES-EDE-CBC-SHA:SRP-RSA-3DES-EDE-CBC-SHA:SRP-3DES-EDE-CBC-SHA:EDH-RSA-DES-CBC3-SHA:EDH-DSS-DES-CBC3-SHA:DH-RSA-DES-CBC3-SHA:DH-DSS-DES-CBC3-SHA:ECDH-RSA-DES-CBC3-SHA:ECDH-ECDSA-DES-CBC3-SHA:DES-CBC3-SHA:PSK-3DES-EDE-CBC-SHA:KRB5-DES-CBC3-SHA:KRB5-DES-CBC3-MD5:EDH-RSA-DES-CBC-SHA:EDH-DSS-DES-CBC-SHA:DH-RSA-DES-CBC-SHA:DH-DSS-DES-CBC-SHA:DES-CBC-SHA:KRB5-DES-CBC-SHA:KRB5-DES-CBC-MD5
>
>  Am I right?
> 
Yes. Sorry. I should have written DES-CBC3-SHA instead.


> 7) Squid uses openssl, right?
> 

For SSL-Bump in current Squid releases. Yes.

> 8) If the previous point is true then shouldn't I assume that Squid
> should have the same features as the ones I can "reproduce" by
> running the openssl commands as in the above examples? In other
> words, shouldn't Squid "support" both RC4-MD5 and DES-CBC3-SHA?
> 

No. see the answer to (5).


> 9) If all the previous points are true then: a) I'm lucky b) I'd like
> to know if the issue is simply the fact that Squid is unable to do
> anything with WinXP&IE8 clients that wrongly ask to use a cipher
> that's not supoprted by a given web site. Since it's MITM, Squid
> can't negotiate another cipher I suppose. But then again, like I said
> before, I don't know how the internals work.

Squid has to decrypt and re-encrypt the two TCP connections data.
That adds the third set of ciphers (those supported by Squid \w OpenSSL)
to the sets which must overlap.

So far we can assume that it is either a Squid bug relaying the
available cipher list between the two remote endpoints. Or that the set
of ciphers available to Squid does not include the DES-CBC3-SHA one.

To test that last detail you probably need to setup a normal https_port
with SSL and see if you can connect to it with TLSv1.0 and only that
cipher in curl. That will eliminate any possible server details
polluting the test result.


> 
> 10) I'm not stating that "working TLS behaviour is a bug in Squid".
> I'm merely assuming that if some modern TLS 1.2 clients can connect
> seemlessly with Squid in a MITM scenario (intercepted ssl-bump) then
> the same should happen with older TLS 1.0 clients when connecting to
> sites that supoprt both the protocol and the ciphers.
> 
> Is that an incorrect assumption?

"should" is determined by that 3-way cipher set combo (amongst other
protocol feature 3-way combos). The fact that the library can be
configured independent of any application using it throws a rather big
spanner into the expected behaviour logics.

> 
> If the WinXP client is faulty because it doesn't abide to the
> standard protocol then I'll assume it can't be used with Squid as
> MITM and force users to browse with FF or upgrade their OS.

Sorry, what I was trying to get across was that one endpoint not
following the protocol properly is when bumping *does* work.

So throwing blame at anyone when it "fails" without a bug being clearly
in evidence is the wrong thing to do. It is usually a sign that
everybody is actually doing "The Right Thing".

So far your tests are showing that it is about a 50/50 chance of being a
bug in Squid versus a Squid/OpenSSL misconfiguration somewhere.

Amos

From gergely at egervary.hu  Tue Oct  4 12:16:22 2016
From: gergely at egervary.hu (=?UTF-8?Q?Egerv=c3=a1ry_Gergely?=)
Date: Tue, 4 Oct 2016 14:16:22 +0200
Subject: [squid-users] IPv6 interception crash: Ip::Address::getInAddr :
 Cannot convert non-IPv4 to IPv4.
In-Reply-To: <57F394D0.40300@egervary.hu>
References: <57F27572.8000600@egervary.hu>
 <ee0c2401-bccf-ad23-8611-af15f9d55906@treenet.co.nz>
 <343a7732-6077-49de-ad8f-5ecb2383f715@egervary.hu>
 <627e937e-7572-862c-fdcf-03e5146a1dea@treenet.co.nz>
 <3f33e001-5c69-ad83-3324-a8cc1565adc4@egervary.hu>
 <71545a1d-6879-cad8-f56e-4835df7f4043@treenet.co.nz>
 <57F37BED.9040502@egervary.hu>
 <d741eb47-c65a-e1a5-68b8-3466a5c08853@treenet.co.nz>
 <57F394D0.40300@egervary.hu>
Message-ID: <57F39D96.1040407@egervary.hu>

> Getting closer, but still not there...

Hah, we need to apply the kern/50198 patch to ipnat_6.c too.

--- ip_nat6.c.orig      2015-08-08 18:31:21.000000000 +0200
+++ ip_nat6.c   2016-10-04 14:04:21.000000000 +0200
@@ -2470,8 +2469,8 @@
                                }
                        }

-                       np->nl_realip6 = nat->nat_ndst6.in6;
-                       np->nl_realport = nat->nat_ndport;
+                       np->nl_realip6 = nat->nat_odst6.in6;
+                       np->nl_realport = nat->nat_odport;
                }
        }

Thank you very much, Amos, your Squid patch works good with it!

Gergely EGERVARY


From squid3 at treenet.co.nz  Tue Oct  4 12:20:32 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 5 Oct 2016 01:20:32 +1300
Subject: [squid-users] Introducing delay to HTTP 407 responses
In-Reply-To: <009d01d21e35$179582e0$46c088a0$@filter.luko.org>
References: <000301d20e1d$7476f840$5d64e8c0$@filter.luko.org>
 <013301d20e8f$12f257f0$38d707d0$@ngtech.co.il>
 <007a01d21e2d$905f1e00$b11d5a00$@filter.luko.org>
 <c521b757-2596-e122-d468-84ebbc5528c0@treenet.co.nz>
 <009d01d21e35$179582e0$46c088a0$@filter.luko.org>
Message-ID: <7601901b-d28f-5d05-6a17-6ba96e5bd174@treenet.co.nz>

On 5/10/2016 12:47 a.m., squid-users wrote:
> Amos,
> 
>> This helper is the mechanism that we accepted. Anything else would be far
>> less useful.
> 
> Makes sense.
> 
>> I think the results you are getting show that the http_status ACL is not
>> working properly.
>>
>> Can you get a "debug_options 28,5" cache.log trace and see if
>> "aclMatchHTTPStatus" is matching anything or "http-response-407" even
>> being tested?
> 
> I set this up as you suggested, then triggered a 407 response from the cache.  It seems that way; I couldn't see aclMatchHTTPStatus or http-response-407 in the log:
> 

Strange. I was sure Alex did some tests recently and proved that even
internally generated responses get http_reply_access applied to them.
Yet no sign of that in your log.

Is this a very old Squid version?

Or are the "checking http_reply_access" lines just later in the log than
your snippet covered?

Amos



From oagvozd at gmail.com  Tue Oct  4 12:24:58 2016
From: oagvozd at gmail.com (oleg gv)
Date: Tue, 4 Oct 2016 15:24:58 +0300
Subject: [squid-users] Squid-3.5.21: filter FTP content or FTP commands
In-Reply-To: <76e1ef3c-be09-8520-a725-8b9c32a43cdd@measurement-factory.com>
References: <CAFfuDwzpSgAOGwBBEyKtdv_7GF=Lt7muU_wL7ovH=8ED2Fm7zQ@mail.gmail.com>
 <7bb34557-c359-ddb2-a2f1-dd81367cf448@measurement-factory.com>
 <CAFfuDwwfpv6WU-edqeGogk55aXnGv2P-ohpDyRU_N6xNrtBChQ@mail.gmail.com>
 <76e1ef3c-be09-8520-a725-8b9c32a43cdd@measurement-factory.com>
Message-ID: <CAFfuDwxfAqu28S2dvx-VrR9ec1A0z2B9JuubKDyYOTpUyYXhTQ@mail.gmail.com>

Finally I've managed to go on ftp.intel.com using FileZilla through my
squid gateway in standart (proxy) mode.

Squid conf:
ftp_port  x.x.x.x  2122

Then I try to block FTP-Command and nothing happen. Some from my config:

acl rh req_header -i ^FTP-Command
http_access deny rh
http_access permit all

And also add following:

request_header_access  "FTP-Command: LIST" deny all


Connect and browsing of remote ftp.intel.com is  OK - nothing blocked.

In squid log i see (fragment):


2016/10/04 15:23:04.177 kid1| 9,2| FtpServer.cc(495) writeReply: FTP Client
REPLY:
---------
227 Entering Passive Mode (192,168,33,254,230,30).

----------
2016/10/04 15:23:04.177 kid1| 20,2| store.cc(949) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/10/04 15:23:04.177 kid1| 20,2| store.cc(949) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/10/04 15:23:04.178 kid1| 33,2| FtpServer.cc(699) parseOneRequest:
>>ftp LIST
2016/10/04 15:23:04.178 kid1| 9,2| FtpServer.cc(1320) handleRequest: FTP
Client local=192.168.33.254:2122 remote=192.168.33.10:60838 FD 9 flags=1
2016/10/04 15:23:04.178 kid1| 9,2| FtpServer.cc(1322) handleRequest: FTP
Client REQUEST:
---------
GET / HTTP/1.1
FTP-Command: LIST
FTP-Arguments:

----------
2016/10/04 15:23:04.178 kid1| 85,2| client_side_request.cc(744)
clientAccessCheckDone: The request GET ftp://ftp.intel.com/ is ALLOWED;
last ACL checked: net33
2016/10/04 15:23:04.178 kid1| 85,2| client_side_request.cc(720)
clientAccessCheck2: No adapted_http_access configuration. default: ALLOW
2016/10/04 15:23:04.178 kid1| 85,2| client_side_request.cc(744)
clientAccessCheckDone: The request GET ftp://ftp.intel.com/ is ALLOWED;
last ACL checked: net33
2016/10/04 15:23:04.178 kid1| 17,2| FwdState.cc(133) FwdState: Forwarding
client request local=192.168.33.254:2122 remote=192.168.33.10:60838 FD 9
flags=1, url=ftp://ftp.intel.com/
2016/10/04 15:23:04.178 kid1| 44,2| peer_select.cc(258) peerSelectDnsPaths:
Find IP destination for: ftp://ftp.intel.com/' via ftp.intel.com
2016/10/04 15:23:04.178 kid1| 44,2| peer_select.cc(258) peerSelectDnsPaths:
Find IP destination for: ftp://ftp.intel.com/' via ftp.intel.com
2016/10/04 15:23:04.178 kid1| 44,2| peer_select.cc(280) peerSelectDnsPaths:
Found sources for 'ftp://ftp.intel.com/'



But I need to block FTP-Command: LIST (for example)


2016-10-03 20:34 GMT+03:00 Alex Rousskov <rousskov at measurement-factory.com>:

> Please ask these questions on squid-users...
>
> On 10/03/2016 05:51 AM, oleg gv wrote:
> > Thanks, but problems still exist - FTP doesn't work through proxy.
> >
> > 1. I've set in proxy
> >     ftp_port 192.168.0.1:2121 <http://192.168.0.1:2121>
> > 2. set in client browser to use proxy for FTP on 192.168.0.1:2121
> > <http://192.168.0.1:2121>
> >
> > Trying to go ftp://ftp.intel.com  and In log of squid i see:
> >
> > FTP Client REPLY:
> > ---------
> > 530 Must login first
> >
> > ####
> >
> > Another variant: setup inerception ftp_proxy (with nat redirect) - and
> > it also doesn'nt work: last commands in log:
> > 2016/10/03 14:43:09.929 kid1| 9,2| FtpRelay.cc(733)
> > dataChannelConnected: connected FTP server data channel:
> > local=8x.xxx.xxx.xxx:41231 remote=192.198.164.82:36034
> > <http://192.198.164.82:36034> FD 19 flags=1
> > 2016/10/03 14:43:09.929 kid1| 9,2| FtpClient.cc(791) writeCommand: ftp<<
> > LIST
> >
> > 2016/10/03 14:43:10.125 kid1| 9,2| FtpClient.cc(1108) parseControlReply:
> > ftp>> 125 Data connection already open; Transfer starting.
> >
> > And ftp.intel com is hang, trying to open..
> >
> >
> >
> >
> >
> > 2016-10-01 2:12 GMT+03:00 Alex Rousskov
> > <rousskov at measurement-factory.com
> > <mailto:rousskov at measurement-factory.com>>:
> >
> >     On 09/30/2016 10:42 AM, oleg gv wrote:
> >
> >     > Hello, I've found that NativeFtpRelay appeared in squid 3.5 . Is it
> >     > possible to apply http-access acl for FTP proto concerning
> filtering of
> >     > FTP methods(commands)
> >
> >     Yes, it should be possible.
> >
> >
> >     > by analogy of HTTP methods ?
> >
> >     Not quite. IIRC, when the HTTP message representing the FTP
> transaction
> >     is relayed through Squid, the FTP command name is _not_ stored as an
> >     HTTP method. The FTP command name is stored as HTTP "FTP-Command"
> header
> >     value. See http://wiki.squid-cache.org/Features/FtpRelay
> >     <http://wiki.squid-cache.org/Features/FtpRelay>
> >
> >     You should be able to block FTP commands using a req_header ACL.
> >
> >
> >     > what other possibilities in squid exist to do this ?
> >
> >     An ICAP or eCAP service can also filter relayed FTP messages.
> >
> >     Alex.
> >
> >
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/5e875b3d/attachment.htm>

From myeganeh1984 at gmail.com  Tue Oct  4 12:51:13 2016
From: myeganeh1984 at gmail.com (Mehdi Yeganeh)
Date: Tue, 4 Oct 2016 16:21:13 +0330
Subject: [squid-users] problem in configuring squid
In-Reply-To: <201610031722.29450.Antony.Stone@squid.open.source.it>
References: <CAKCdGgCWF4vUb-K5JZ8L4HCvNEtLRfXaz+VfH8PNfSbACrh6hQ@mail.gmail.com>
 <201610031722.29450.Antony.Stone@squid.open.source.it>
Message-ID: <CAKCdGgDDQ2+-vG=fC_6PA4G3af-ObVwpDQi2EnfWzxCM1gtvUw@mail.gmail.com>

Thanks for quick replay,
I need to use my server, i configure my ip address in some software like
antivirus and ...
So, I want all of that working with my server ip address and for this
reason I cannot use torproxy or torproject.
I need a proxy server (squid) on my server ...

More details about 173.161.0.227:
Its sophos web appliance that use squid on debian and using some other
proxy software (Astaro HttpProxy) with squid and
iptables for forwarding ports. but i can`t find the other proxy software
for download. so, i just have squid alone (although iptables is present)

Please tell me that should i use other tools or squid can do it?
Thanks.


On Mon, Oct 3, 2016 at 6:52 PM, Antony Stone <
Antony.Stone at squid.open.source.it> wrote:

> On Monday 03 October 2016 at 17:03:13, Shark wrote:
>
> > I want to config squid to make "open proxy" for both http & https
> > I want make anonymous proxy, without decrypting traffic or etc, just
> change
> > ip address, like this:
> >
> > i find lot of ip port in internet for example: 173.161.0.227
> > when i add some host to /etc/hosts like this:
> >
> > 173.161.0.227 www.iplocation.net
> >
> > its give me true way without ssl blocking in client and my ip changes to
> > 173.161.0.227,
>
> Squid is the wrong tool for this job.
>
> You probably want something like https://www.torproject.org/
> ?
>
> Antony.
>
> --
> There are only 10 types of people in the world:
> those who understand binary notation,
> and those who don't.
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/828d1ab1/attachment.htm>

From hardikdangar+squid at gmail.com  Tue Oct  4 13:05:48 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Tue, 4 Oct 2016 18:35:48 +0530
Subject: [squid-users] Caching http google deb files
Message-ID: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>

Hello,

I am trying to cache following deb files as its most requested file in
network. ( google chrome almost every few days many clients update it ).

http://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
http://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-beta_current_i386.deb

Response headers for both contains Last modified date which is 10 to 15
days old but squid does not seem to cache it somehow. here is sample
response header for one of the file,

HTTP Response Header

Status: HTTP/1.1 200 OK
Accept-Ranges: bytes
Content-Length: 6662208
Content-Type: application/x-debian-package
Etag: "fa383"
Last-Modified: Thu, 15 Sep 2016 19:24:00 GMT
Server: downloads
Vary: *
X-Content-Type-Options: nosniff
X-Frame-Options: SAMEORIGIN
X-Xss-Protection: 1; mode=block
Date: Tue, 04 Oct 2016 12:51:57 GMT
Alt-Svc: quic=":443"; ma=2592000; v="36,35,34,33,32"
Connection: close


I have tried various refresh patterns to cache it but it seems somehow it's
not cached no matter what i try, below are 6 different methods i have
already tried one by one

1) refresh_pattern dl-ssl.google.com  2160 100% 10080 ignore-no-cache
reload-into-ims

2) refresh_pattern
http://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-stable_current_i386.deb
129600 100% 129600 reload-into-ims

3) refresh_pattern dl-ssl.google.com\/dl\/linux\/direct/.*\(.deb|.zip)
43200 80% 129600 reload-into-ims override-lastmod ignore-no-store
refresh-ims store-stale

4) refresh_pattern ^http:\/\/dl-ssl.google.com.*\.(deb|zip)  43200 80%
129600 reload-into-ims

5) refresh_pattern dl.google.com\/.*\.(deb)  129600 100% 129600
reload-into-ims

6) refresh_pattern dl-ssl.google.com\/.*\.(deb)  129600 100% 129600
reload-into-ims


My cache is working fine as at the same time i am able to cache files in
oracle servers via following refresh pattern,
refresh_pattern -i download.oracle.com 5259487 20% 5259487 override-expire
override-lastmod ignore-reload ignore-private ignore-auth


So i am not sure what's the issue with http://dl.google.com/linux servers.
Can anyone give me any clue why it is not working ? anyone out there who
are able to cache those files from google?

Here is the TCP_Miss entry in squid's access.log file for the above file,
04/Oct/2016:16:37:07 +0530.695  78902 192.168.1.76 TCP_MISS/200 6662561 GET
http://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-stable_current_i386.deb
- HIER_DIRECT/74.125.68.91 application/x-debian-package

Here is my squid config file,
http://pastebin.com/raw/jY57XJPp


Thanks.
Hardik
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/b27d8d6f/attachment.htm>

From squid3 at treenet.co.nz  Tue Oct  4 13:10:32 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 5 Oct 2016 02:10:32 +1300
Subject: [squid-users] IPv6 interception crash: Ip::Address::getInAddr :
 Cannot convert non-IPv4 to IPv4.
In-Reply-To: <57F39D96.1040407@egervary.hu>
References: <57F27572.8000600@egervary.hu>
 <ee0c2401-bccf-ad23-8611-af15f9d55906@treenet.co.nz>
 <343a7732-6077-49de-ad8f-5ecb2383f715@egervary.hu>
 <627e937e-7572-862c-fdcf-03e5146a1dea@treenet.co.nz>
 <3f33e001-5c69-ad83-3324-a8cc1565adc4@egervary.hu>
 <71545a1d-6879-cad8-f56e-4835df7f4043@treenet.co.nz>
 <57F37BED.9040502@egervary.hu>
 <d741eb47-c65a-e1a5-68b8-3466a5c08853@treenet.co.nz>
 <57F394D0.40300@egervary.hu> <57F39D96.1040407@egervary.hu>
Message-ID: <07a63de4-356c-81d4-35ed-1842f106b632@treenet.co.nz>

On 5/10/2016 1:16 a.m., Egerv?ry Gergely wrote:
>> Getting closer, but still not there...
> 
> Hah, we need to apply the kern/50198 patch to ipnat_6.c too.
> 
> --- ip_nat6.c.orig      2015-08-08 18:31:21.000000000 +0200
> +++ ip_nat6.c   2016-10-04 14:04:21.000000000 +0200
> @@ -2470,8 +2469,8 @@
>                                 }
>                         }
> 
> -                       np->nl_realip6 = nat->nat_ndst6.in6;
> -                       np->nl_realport = nat->nat_ndport;
> +                       np->nl_realip6 = nat->nat_odst6.in6;
> +                       np->nl_realport = nat->nat_odport;
>                 }
>         }
> 
> Thank you very much, Amos, your Squid patch works good with it!
> 
> Gergely EGERVARY

Thanks for the testing and feedback. I've applied this as part-2 of the
bug 4302 updates. It will be in the next releases of 3.5 and 4.x.

Amos



From Antony.Stone at squid.open.source.it  Tue Oct  4 13:14:47 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 4 Oct 2016 15:14:47 +0200
Subject: [squid-users] problem in configuring squid
In-Reply-To: <CAKCdGgDDQ2+-vG=fC_6PA4G3af-ObVwpDQi2EnfWzxCM1gtvUw@mail.gmail.com>
References: <CAKCdGgCWF4vUb-K5JZ8L4HCvNEtLRfXaz+VfH8PNfSbACrh6hQ@mail.gmail.com>
 <201610031722.29450.Antony.Stone@squid.open.source.it>
 <CAKCdGgDDQ2+-vG=fC_6PA4G3af-ObVwpDQi2EnfWzxCM1gtvUw@mail.gmail.com>
Message-ID: <201610041514.47755.Antony.Stone@squid.open.source.it>

On Tuesday 04 October 2016 at 14:51:13, Mehdi Yeganeh wrote:

> Thanks for quick replay,
> I need to use my server, i configure my ip address in some software like
> antivirus and ...

... and what?

I do not understand what antivirus software has to do with our discussion.  
Please give details, don't just write "...".

> So, I want all of that working

All of what?

> with my server ip address and for this reason I cannot use torproxy or
> torproject. I need a proxy server (squid) on my server

In that case install Squid on your server.  What is the problem?

> More details about 173.161.0.227:
> Its sophos web appliance that use squid on debian and using some other
> proxy software (Astaro HttpProxy) with squid and
> iptables for forwarding ports. but i can`t find the other proxy software
> for download. so, i just have squid alone (although iptables is present)

Okay, so I understand that the machine on that IP address (which appears to be 
serving Pennoyer School in Illinois, with connectivity provided by Comcast) is 
a "Sophos web appliance" - some sort of combined firewall / proxy / port 
forwarder.

What is the relevance of that machine to your question?

> Please tell me that should i use other tools or squid can do it?

Do what?

Please explain exactly what it is you are trying to achieve, and hoping that 
Squid is a solution for.


Regards,


Antony.

-- 
Police have found a cartoonist dead in his house.  They say that details are 
currently sketchy.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid at borrill.org.uk  Tue Oct  4 13:16:15 2016
From: squid at borrill.org.uk (Stephen Borrill)
Date: Tue, 4 Oct 2016 14:16:15 +0100
Subject: [squid-users] IPv6 interception crash: Ip::Address::getInAddr :
 Cannot convert non-IPv4 to IPv4.
In-Reply-To: <07a63de4-356c-81d4-35ed-1842f106b632@treenet.co.nz>
References: <57F27572.8000600@egervary.hu>
 <ee0c2401-bccf-ad23-8611-af15f9d55906@treenet.co.nz>
 <343a7732-6077-49de-ad8f-5ecb2383f715@egervary.hu>
 <627e937e-7572-862c-fdcf-03e5146a1dea@treenet.co.nz>
 <3f33e001-5c69-ad83-3324-a8cc1565adc4@egervary.hu>
 <71545a1d-6879-cad8-f56e-4835df7f4043@treenet.co.nz>
 <57F37BED.9040502@egervary.hu>
 <d741eb47-c65a-e1a5-68b8-3466a5c08853@treenet.co.nz>
 <57F394D0.40300@egervary.hu> <57F39D96.1040407@egervary.hu>
 <07a63de4-356c-81d4-35ed-1842f106b632@treenet.co.nz>
Message-ID: <8501c74d-c30c-0523-dfa1-6222d9c15cbd@borrill.org.uk>

On 04/10/2016 14:10, Amos Jeffries wrote:
> On 5/10/2016 1:16 a.m., Egerv?ry Gergely wrote:
>>> Getting closer, but still not there...
>>
>> Hah, we need to apply the kern/50198 patch to ipnat_6.c too.
>>
>> --- ip_nat6.c.orig      2015-08-08 18:31:21.000000000 +0200
>> +++ ip_nat6.c   2016-10-04 14:04:21.000000000 +0200
>> @@ -2470,8 +2469,8 @@
>>                                 }
>>                         }
>>
>> -                       np->nl_realip6 = nat->nat_ndst6.in6;
>> -                       np->nl_realport = nat->nat_ndport;
>> +                       np->nl_realip6 = nat->nat_odst6.in6;
>> +                       np->nl_realport = nat->nat_odport;
>>                 }
>>         }
>>
>> Thank you very much, Amos, your Squid patch works good with it!
>>
>> Gergely EGERVARY
> 
> Thanks for the testing and feedback. I've applied this as part-2 of the
> bug 4302 updates. It will be in the next releases of 3.5 and 4.x.

Gergely, please update the NetBSD PR with your working kernel patch(es)
and I'll commit them, can't wait for Darren any longer.

-- 
Stephen




From squid3 at treenet.co.nz  Tue Oct  4 13:21:15 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 5 Oct 2016 02:21:15 +1300
Subject: [squid-users] Caching http google deb files
In-Reply-To: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
Message-ID: <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>

On 5/10/2016 2:05 a.m., Hardik Dangar wrote:
> Hello,
> 
> I am trying to cache following deb files as its most requested file in
> network. ( google chrome almost every few days many clients update it ).
> 
> http://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
> http://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-beta_current_i386.deb
> 
> Response headers for both contains Last modified date which is 10 to 15
> days old but squid does not seem to cache it somehow. here is sample
> response header for one of the file,
> 
> HTTP Response Header
> 
> Status: HTTP/1.1 200 OK
> Accept-Ranges: bytes
> Content-Length: 6662208
> Content-Type: application/x-debian-package
> Etag: "fa383"
> Last-Modified: Thu, 15 Sep 2016 19:24:00 GMT
> Server: downloads
> Vary: *

The Vary header says that this response is just one of many that can
happen for this URL.

The "*" in that header says that the way to determine which the clietn
gets is based on something no proxy can ever do. Thus no cache can ever
re-use any content it wanted to store. Making any attempts to store it a
pointless waste of CPU time, disk and memory space that could better be
used by some other more useful object. Squid will not ever cache these
responses.

(Thank you for the well written request for help anyhow.)

Amos



From hardikdangar+squid at gmail.com  Tue Oct  4 13:34:50 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Tue, 4 Oct 2016 19:04:50 +0530
Subject: [squid-users] Caching http google deb files
In-Reply-To: <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
Message-ID: <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>

Hey Amos,

We have about 50 clients which downloads same google chrome update every 2
or 3 days means 2.4 gb. although response says vary but requested file is
same and all is downloaded via apt update.

Is there any option just like ignore-no-store? I know i am asking for too
much but it seems very silly on google's part that they are sending very
header at a place where they shouldn't as no matter how you access those
url's you are only going to get those deb files.

can i hack squid source code to ignore very header ?



On Tue, Oct 4, 2016 at 6:51 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 5/10/2016 2:05 a.m., Hardik Dangar wrote:
> > Hello,
> >
> > I am trying to cache following deb files as its most requested file in
> > network. ( google chrome almost every few days many clients update it ).
> >
> > http://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
> > http://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-
> beta_current_i386.deb
> >
> > Response headers for both contains Last modified date which is 10 to 15
> > days old but squid does not seem to cache it somehow. here is sample
> > response header for one of the file,
> >
> > HTTP Response Header
> >
> > Status: HTTP/1.1 200 OK
> > Accept-Ranges: bytes
> > Content-Length: 6662208
> > Content-Type: application/x-debian-package
> > Etag: "fa383"
> > Last-Modified: Thu, 15 Sep 2016 19:24:00 GMT
> > Server: downloads
> > Vary: *
>
> The Vary header says that this response is just one of many that can
> happen for this URL.
>
> The "*" in that header says that the way to determine which the clietn
> gets is based on something no proxy can ever do. Thus no cache can ever
> re-use any content it wanted to store. Making any attempts to store it a
> pointless waste of CPU time, disk and memory space that could better be
> used by some other more useful object. Squid will not ever cache these
> responses.
>
> (Thank you for the well written request for help anyhow.)
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/7bce88b2/attachment.htm>

From nilesh.gavali at tcs.com  Tue Oct  4 13:49:51 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Tue, 4 Oct 2016 14:49:51 +0100
Subject: [squid-users] Squid - AD kerberos auth and Linux Server proxy
	access not working
In-Reply-To: <mailman.433.1475581675.2924.squid-users@lists.squid-cache.org>
References: <mailman.433.1475581675.2924.squid-users@lists.squid-cache.org>
Message-ID: <OF9164A936.4D1852E8-ON80258042.0049BA9A-80258042.004BF9B4@tcs.com>

Hi Amos;
Ok, we can discussed the issue in Two part  1. For Windows AD 
Authentication & SSO and 2. Linux server unable to access via squid proxy.

For First point-
Requirement to have SSO for accessing internet via squid proxy and based 
on user's AD group membership allow access to specific sites only. I 
believe current configuration of squid is working as expected.

For Second point -
Point I would like to highlight here is, the Linux server IWCCP01 is not 
part of domain at all. Hence the below error as squid configured for 
AD_auth. So how can we allow Linux server or non domain machine to access 
specific sites?

> Error 407 is "proxy auth required", so the proxy is expecting 
authentication 
> for some reason.
====================================
 > Can you confirm that the hostname vseries-test.bottomline.com is 
contained in 
> your site file /etc/squid/sitelist/dbs_allowed_site ?

YES, we have entry as .bottomline.com , which work fine when access via 
windows machine having proxy enabled for that user.
==============================
> Can you temporarily change the line "http_access allow IWCCP01 
allowedsite" to 
> "http_access allow IWCCP01" and see whether the machine then gets 
access?

 I will test this, and update the results.
========================================
If that works, please list the output of the command:
  grep "bottomline.com" /etc/squid/sitelist/dbs_allowed_site

o/p of above command as below -

[root at Proxy02 ~]# grep "bottomline.com" 
/etc/squid/sitelist/dbs_allowed_site
.bottomline.com
[root at Proxy02 ~]#

=======================================

Thanks & Regards
Nilesh Suresh Gavali




 
Message: 2
Date: Wed, 5 Oct 2016 00:11:08 +1300
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid - AD kerberos auth and Linux Server
                 proxy access not working
Message-ID: <d35ad0ca-761d-60e3-c594-04697110afdc at treenet.co.nz>
Content-Type: text/plain; charset=utf-8

On 4/10/2016 11:36 p.m., Antony Stone wrote:
> On Tuesday 04 October 2016 at 12:28:44, Nilesh Gavali wrote:
> 
>> Hello Antony;
>> I have double checked the current working configuration of my 
squid.conf
>> and it has same settings which I posted earlier. somehow it is working 
for
>> us.
> 
> I'm not saying the whole thing won't work; I'm saying there is no point 
in 
> having a line "http_access allow ad_auth" following the line 
"http_access deny 
> all".  The ad_auth line can never be invoked.

Not knowing why authentication works is dangerous. You might have been
allowing non-authenticated traffic and invalid user accounts through.

The only reason it does "work" is that the ACL called "USERS" is _not_
actually checking user logins. It is a group checking ACL which requires
authentication to happen before it can be checked.

In this specific case invalid logins cannot be a member of the group. So
they will not get through the proxy.

However, people who accidentally type the user/password wrong, or whose
machines automatically login with an account not a member of the group
will not be allowed any way to try again short of shutting down their
browser or maybe even logging out of the machine and trying from another
one.

That may or may not be a problem for you.

> 
>> below is the error from access.log file.
>>
>> 1475518342.279      0 10.xx.15.103 TCP_DENIED/407 3589 CONNECT
>> vseries-test.bottomline.com:443 - NONE/- text/html
> 
> Error 407 is "proxy auth required", so the proxy is expecting 
authentication 
> for some reason.
> 
> Can you confirm that the hostname vseries-test.bottomline.com is 
contained in 
> your site file /etc/squid/sitelist/dbs_allowed_site ?
> 
> Can you temporarily change the line "http_access allow IWCCP01 
allowedsite" to 
> "http_access allow IWCCP01" and see whether the machine then gets 
access?
> 

If that works, please list the output of the command:
  grep "bottomline.com" /etc/squid/sitelist/dbs_allowed_site

Amos

*******************************************

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/4f9c6b90/attachment.htm>

From hardikdangar+squid at gmail.com  Tue Oct  4 14:16:47 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Tue, 4 Oct 2016 19:46:47 +0530
Subject: [squid-users] Caching http google deb files
In-Reply-To: <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
Message-ID: <CA+sSnVYVw8Sm0kShuULzn7tiZHfu8rUic_MccaVj6CTqye86Hw@mail.gmail.com>

Hey Amos,

after referring to one of your old posts i found, we can use

reply_header_replace

to replace headers. Is it possible to replace vary * header  with something
appropriate?

or

i need to look at squid's source code to ignore vary header and recompile ?



On Tue, Oct 4, 2016 at 7:04 PM, Hardik Dangar <hardikdangar+squid at gmail.com>
wrote:

> Hey Amos,
>
> We have about 50 clients which downloads same google chrome update every 2
> or 3 days means 2.4 gb. although response says vary but requested file is
> same and all is downloaded via apt update.
>
> Is there any option just like ignore-no-store? I know i am asking for too
> much but it seems very silly on google's part that they are sending very
> header at a place where they shouldn't as no matter how you access those
> url's you are only going to get those deb files.
>
> can i hack squid source code to ignore very header ?
>
>
>
> On Tue, Oct 4, 2016 at 6:51 PM, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
>
>> On 5/10/2016 2:05 a.m., Hardik Dangar wrote:
>> > Hello,
>> >
>> > I am trying to cache following deb files as its most requested file in
>> > network. ( google chrome almost every few days many clients update it ).
>> >
>> > http://dl.google.com/linux/direct/google-chrome-stable_curre
>> nt_amd64.deb
>> > http://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-beta_
>> current_i386.deb
>> >
>> > Response headers for both contains Last modified date which is 10 to 15
>> > days old but squid does not seem to cache it somehow. here is sample
>> > response header for one of the file,
>> >
>> > HTTP Response Header
>> >
>> > Status: HTTP/1.1 200 OK
>> > Accept-Ranges: bytes
>> > Content-Length: 6662208
>> > Content-Type: application/x-debian-package
>> > Etag: "fa383"
>> > Last-Modified: Thu, 15 Sep 2016 19:24:00 GMT
>> > Server: downloads
>> > Vary: *
>>
>> The Vary header says that this response is just one of many that can
>> happen for this URL.
>>
>> The "*" in that header says that the way to determine which the clietn
>> gets is based on something no proxy can ever do. Thus no cache can ever
>> re-use any content it wanted to store. Making any attempts to store it a
>> pointless waste of CPU time, disk and memory space that could better be
>> used by some other more useful object. Squid will not ever cache these
>> responses.
>>
>> (Thank you for the well written request for help anyhow.)
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/515e1323/attachment.htm>

From squid3 at treenet.co.nz  Tue Oct  4 14:17:01 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 5 Oct 2016 03:17:01 +1300
Subject: [squid-users] Caching http google deb files
In-Reply-To: <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
Message-ID: <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>

On 5/10/2016 2:34 a.m., Hardik Dangar wrote:
> Hey Amos,
> 
> We have about 50 clients which downloads same google chrome update every 2
> or 3 days means 2.4 gb. although response says vary but requested file is
> same and all is downloaded via apt update.
> 
> Is there any option just like ignore-no-store? I know i am asking for too
> much but it seems very silly on google's part that they are sending very
> header at a place where they shouldn't as no matter how you access those
> url's you are only going to get those deb files.


Some things G does only make sense whan you ignore all the PR about
wanting to make the web more efficient and consider it's a company whose
income is derived by recording data about peoples habits and activities.
Caching can hide that info from them.

> 
> can i hack squid source code to ignore very header ?
> 

Google are explicitly saying the response changes. I suspect there is
something involving Google account data being embeded in some of the
downloads. For tracking, etc.


If you are wanting to test it I have added a patch to
<http://bugs.squid-cache.org/show_bug.cgi?id=4604> that should implement
archival of responses where the ACLs match. It is completely untested by
me beyond building, so YMMV.

Amos



From gergely at egervary.hu  Tue Oct  4 14:23:46 2016
From: gergely at egervary.hu (=?UTF-8?Q?Egerv=c3=a1ry_Gergely?=)
Date: Tue, 4 Oct 2016 16:23:46 +0200
Subject: [squid-users] IPv6 interception crash: Ip::Address::getInAddr :
 Cannot convert non-IPv4 to IPv4.
In-Reply-To: <07a63de4-356c-81d4-35ed-1842f106b632@treenet.co.nz>
References: <57F27572.8000600@egervary.hu>
 <ee0c2401-bccf-ad23-8611-af15f9d55906@treenet.co.nz>
 <343a7732-6077-49de-ad8f-5ecb2383f715@egervary.hu>
 <627e937e-7572-862c-fdcf-03e5146a1dea@treenet.co.nz>
 <3f33e001-5c69-ad83-3324-a8cc1565adc4@egervary.hu>
 <71545a1d-6879-cad8-f56e-4835df7f4043@treenet.co.nz>
 <57F37BED.9040502@egervary.hu>
 <d741eb47-c65a-e1a5-68b8-3466a5c08853@treenet.co.nz>
 <57F394D0.40300@egervary.hu> <57F39D96.1040407@egervary.hu>
 <07a63de4-356c-81d4-35ed-1842f106b632@treenet.co.nz>
Message-ID: <57F3BB72.3090802@egervary.hu>

> Thanks for the testing and feedback. I've applied this as part-2 of the
> bug 4302 updates. It will be in the next releases of 3.5 and 4.x.

you are the hero of the day, thank you very much!

-- 
Gergely EGERVARY



From hardikdangar+squid at gmail.com  Tue Oct  4 14:30:35 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Tue, 4 Oct 2016 20:00:35 +0530
Subject: [squid-users] Caching http google deb files
In-Reply-To: <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
Message-ID: <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>

Wow, i couldn't think about that. google might need tracking data that
could be the reason they have blindly put vary * header. oh Irony, company
which talks to all of us on how to deliver content is trying to do such
thing.

I have looked at your patch but how do i enable that ? do i need to write
custom ACL ? i know i need to compile and reinstall after applying patch
but what do i need to do exactly in squid.conf file as looking at your
patch i am guessing i need to write archive acl or i am too naive to
understand C code :)

Also

reply_header_replace is any good for this ?


On Tue, Oct 4, 2016 at 7:47 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 5/10/2016 2:34 a.m., Hardik Dangar wrote:
> > Hey Amos,
> >
> > We have about 50 clients which downloads same google chrome update every
> 2
> > or 3 days means 2.4 gb. although response says vary but requested file is
> > same and all is downloaded via apt update.
> >
> > Is there any option just like ignore-no-store? I know i am asking for too
> > much but it seems very silly on google's part that they are sending very
> > header at a place where they shouldn't as no matter how you access those
> > url's you are only going to get those deb files.
>
>
> Some things G does only make sense whan you ignore all the PR about
> wanting to make the web more efficient and consider it's a company whose
> income is derived by recording data about peoples habits and activities.
> Caching can hide that info from them.
>
> >
> > can i hack squid source code to ignore very header ?
> >
>
> Google are explicitly saying the response changes. I suspect there is
> something involving Google account data being embeded in some of the
> downloads. For tracking, etc.
>
>
> If you are wanting to test it I have added a patch to
> <http://bugs.squid-cache.org/show_bug.cgi?id=4604> that should implement
> archival of responses where the ACLs match. It is completely untested by
> me beyond building, so YMMV.
>
> Amos
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/c8f5f081/attachment.htm>

From rousskov at measurement-factory.com  Tue Oct  4 14:38:15 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 4 Oct 2016 08:38:15 -0600
Subject: [squid-users] Introducing delay to HTTP 407 responses
In-Reply-To: <c521b757-2596-e122-d468-84ebbc5528c0@treenet.co.nz>
References: <000301d20e1d$7476f840$5d64e8c0$@filter.luko.org>
 <013301d20e8f$12f257f0$38d707d0$@ngtech.co.il>
 <007a01d21e2d$905f1e00$b11d5a00$@filter.luko.org>
 <c521b757-2596-e122-d468-84ebbc5528c0@treenet.co.nz>
Message-ID: <d90ba0c0-306a-086c-1ff7-4fec13ee7de8@measurement-factory.com>

On 10/04/2016 05:18 AM, Amos Jeffries wrote:
> On 4/10/2016 11:53 p.m., squid-users at filter.luko.org wrote:
>> Would the developers be open to adding a configuration-based throttle to authentication responses

> This helper is the mechanism that we accepted. Anything else would be
> far less useful.

For the record, I agree that the external ACL is the right solution for
now. However, supporting a general built-in "delay" ACL would be a
useful feature worth accepting IMO.

I know this does not help with the problem at hand. I just wanted to
make a note that there is certainly room for an improvement here if
somebody wants to work on it; the "anything else" phrase was too harsh.

Alex.



From rousskov at measurement-factory.com  Tue Oct  4 14:55:28 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 4 Oct 2016 08:55:28 -0600
Subject: [squid-users] Squid-3.5.21: filter FTP content or FTP commands
In-Reply-To: <CAFfuDwxfAqu28S2dvx-VrR9ec1A0z2B9JuubKDyYOTpUyYXhTQ@mail.gmail.com>
References: <CAFfuDwzpSgAOGwBBEyKtdv_7GF=Lt7muU_wL7ovH=8ED2Fm7zQ@mail.gmail.com>
 <7bb34557-c359-ddb2-a2f1-dd81367cf448@measurement-factory.com>
 <CAFfuDwwfpv6WU-edqeGogk55aXnGv2P-ohpDyRU_N6xNrtBChQ@mail.gmail.com>
 <76e1ef3c-be09-8520-a725-8b9c32a43cdd@measurement-factory.com>
 <CAFfuDwxfAqu28S2dvx-VrR9ec1A0z2B9JuubKDyYOTpUyYXhTQ@mail.gmail.com>
Message-ID: <b7409c20-7292-039a-67d5-9543309dfc2f@measurement-factory.com>

On 10/04/2016 06:24 AM, oleg gv wrote:

> Then I try to block FTP-Command and nothing happen. Some from my config:
> 
> acl rh req_header -i ^FTP-Command

Wrong syntax. Please read req_header documentation carefully and try
something like:

  acl rh req_header FTP-Command -i LIST

I also recommend renaming the "rh" ACL to something more meaningful like
"ForbiddenCommand".

Finally, since a regular HTTP request might have an FTP-Command header
field, you should probably limit your rh-based http_access deny rule to
transactions accepted at ftp_port(s).


> http_access permit all

There is no "permit" action AFAIK. Please use documented "allow" and
"deny" actions only and copy-paste exact configuration lines when asking
questions.


> request_header_access  "FTP-Command: LIST" deny all

Wrong syntax and wrong option. You want to deny a transaction, not to
remove a header from that transaction.


HTH,

Alex.



From myshark at gmail.com  Tue Oct  4 15:42:19 2016
From: myshark at gmail.com (Shark)
Date: Tue, 4 Oct 2016 19:12:19 +0330
Subject: [squid-users] problem in configuring squid
In-Reply-To: <201610041514.47755.Antony.Stone@squid.open.source.it>
References: <CAKCdGgCWF4vUb-K5JZ8L4HCvNEtLRfXaz+VfH8PNfSbACrh6hQ@mail.gmail.com>
 <201610031722.29450.Antony.Stone@squid.open.source.it>
 <CAKCdGgDDQ2+-vG=fC_6PA4G3af-ObVwpDQi2EnfWzxCM1gtvUw@mail.gmail.com>
 <201610041514.47755.Antony.Stone@squid.open.source.it>
Message-ID: <CAKCdGgD-F+YUXP55QVUtyQVyi2PWV910CA9PV3UgyLcKfB5a_Q@mail.gmail.com>

Sorry for my bad english,

I want to make a anonymous https & http proxy that pass through any
requests without decrypting or change them,
only change ip address from client ip to my server ip address and define ip
address of my websites that i want to access them from my client in
/etc/hosts,
so i try to install squid on my server and i have good experience when i
set proxy in client with server ip and port 3128 and i can access http &
https behind this proxy,
but when i try to using /etc/hosts i cannot access to https websites. i try
to install squid lot of time with any install instructions that i found
from googling.
I have server with CentOS 7 with one valid internet ip address.

For more explain of what i want to do, i need my squid to work like this ip
173.161.0.227
When i add *173.161.0.227 www.iplocation.net <http://www.iplocation.net>* to
my client /etc/hosts
I can browse https://www.iplocation.net that tell me my client ip address
is 173.161.0.227
I want do my proxy server same as 173.161.0.227

*My problem is now with below config is:*

when i define *216.55.x.x www.iplocation.net <http://www.iplocation.net>* to
/etc/hosts in my client i cannot access to https://www.iplocation.net and
hang on connecting and then give me timeout error,
I`m appreciate for help me to resolve this problem.
I ask it before in
http://serverfault.com/questions/805413/squid-with-iptables-bypass-https
 but i cannot resolve it

*My Iptables config is:*

iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-port 3130

*My squid config is:*

acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src fc00::/7 # RFC 4193 local private network range
acl localnet src fe80::/10 # RFC 4291 link-local (directly plugged) machines
acl localnet src 127.0.0.1

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http

acl CONNECT method CONNECT

http_access allow !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access allow manager
http_access allow localnet
http_access allow localhost
http_access allow all

http_port 3128
http_port 80
http_port 0.0.0.0:3129 ssl-bump  cert=/etc/squid/ssl_cert/myCA.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
https_port 0.0.0.0:3130 ssl-bump intercept
cert=/etc/squid/ssl_cert/myCA.pem generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB

sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER

cache_dir ufs /var/cache/squid 100 16 256

coredump_dir /var/cache/squid

sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/squid/ssl_db -M 4MB
sslcrtd_children 50 startup=1 idle=1

sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER

ssl_bump peek all
ssl_bump splice all
ssl_bump bump all

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0     0% 0
refresh_pattern .               0       20%     4320forwarded_for delete



On Tue, Oct 4, 2016 at 4:44 PM, Antony Stone <
Antony.Stone at squid.open.source.it> wrote:

> On Tuesday 04 October 2016 at 14:51:13, Mehdi Yeganeh wrote:
>
> > Thanks for quick replay,
> > I need to use my server, i configure my ip address in some software like
> > antivirus and ...
>
> ... and what?
>
> I do not understand what antivirus software has to do with our discussion.
> Please give details, don't just write "...".
>
> > So, I want all of that working
>
> All of what?
>
> > with my server ip address and for this reason I cannot use torproxy or
> > torproject. I need a proxy server (squid) on my server
>
> In that case install Squid on your server.  What is the problem?
>
> > More details about 173.161.0.227:
> > Its sophos web appliance that use squid on debian and using some other
> > proxy software (Astaro HttpProxy) with squid and
> > iptables for forwarding ports. but i can`t find the other proxy software
> > for download. so, i just have squid alone (although iptables is present)
>
> Okay, so I understand that the machine on that IP address (which appears
> to be
> serving Pennoyer School in Illinois, with connectivity provided by
> Comcast) is
> a "Sophos web appliance" - some sort of combined firewall / proxy / port
> forwarder.
>
> What is the relevance of that machine to your question?
>
> > Please tell me that should i use other tools or squid can do it?
>
> Do what?
>
> Please explain exactly what it is you are trying to achieve, and hoping
> that
> Squid is a solution for.
>
>
> Regards,
>
>
> Antony.
>
> --
> Police have found a cartoonist dead in his house.  They say that details
> are
> currently sketchy.
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/b529445f/attachment.htm>

From oagvozd at gmail.com  Tue Oct  4 15:44:23 2016
From: oagvozd at gmail.com (oleg gv)
Date: Tue, 4 Oct 2016 18:44:23 +0300
Subject: [squid-users] Squid-3.5.21: filter FTP content or FTP commands
Message-ID: <CAFfuDwxTeZ2dWWempYtNfhWmHxxG-LoY3UCY8MV4PaVb-0t_1w@mail.gmail.com>

Thank you very much. It's my fault - wrote wrong ACL .

That'll do it! Yahooo!  LIST , C.?D blocked ok.

2016-10-04 17:55 GMT+03:00 Alex Rousskov <rousskov at measurement-factory.com>:

> On 10/04/2016 06:24 AM, oleg gv wrote:
>
> > Then I try to block FTP-Command and nothing happen. Some from my config:
> >
> > acl rh req_header -i ^FTP-Command
>
> Wrong syntax. Please read req_header documentation carefully and try
> something like:
>
>   acl rh req_header FTP-Command -i LIST
>
> I also recommend renaming the "rh" ACL to something more meaningful like
> "ForbiddenCommand".
>
> Finally, since a regular HTTP request might have an FTP-Command header
> field, you should probably limit your rh-based http_access deny rule to
> transactions accepted at ftp_port(s).
>
>
> > http_access permit all
>
> There is no "permit" action AFAIK. Please use documented "allow" and
> "deny" actions only and copy-paste exact configuration lines when asking
> questions.
>
>
> > request_header_access  "FTP-Command: LIST" deny all
>
> Wrong syntax and wrong option. You want to deny a transaction, not to
> remove a header from that transaction.
>
>
> HTH,
>
> Alex.
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/2de1db82/attachment.htm>

From Antony.Stone at squid.open.source.it  Tue Oct  4 15:45:20 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 4 Oct 2016 17:45:20 +0200
Subject: [squid-users] Problem with Squid3 Caches
In-Reply-To: <B0508516-890C-4526-8848-78616839ABA5@gmail.com>
References: <CD14793F-4F48-433E-9A1E-B2030E1D7F14@gmail.com>
 <201610032306.15880.Antony.Stone@squid.open.source.it>
 <B0508516-890C-4526-8848-78616839ABA5@gmail.com>
Message-ID: <201610041745.20899.Antony.Stone@squid.open.source.it>

On Tuesday 04 October 2016 at 17:00:24, KR wrote:

> Hello Anthony, Yuri,
> 
> It seems every line is commented out in the config?

Impossible - otherwise it couldn't generate the error message "FATAL: Bungled 
/etc/squid/squid.conf line 3467: cache_dir rock /ssd3 ..."

Thta is telling you that line 3467 of squid.conf starts with the directive 
"cache_dir".

> This is a fresh install.

Standard Ubuntu?  Which version?

> ls -al /ssd3 outputs:
> 
> total 8
> drwxr-xr-x  2 root root 4096 Aug 13 18:20 .
> drwxr-xr-x 30 root root 4096 Oct  3 13:49 ..

Hm, okay, so that really does exist on your machine, then...

> Attached are two screenshots that are suspect.

Er, what are those screenshots of?  It's certainly not the output of Squid, or 
its config file.

> Do I need all of these cache folders on every partition?

You can put your cache directories wherever you like.

> Ubuntu is running inside of a vm,

Er, so /ssd3 is not an actual SSD, then?  What is it?

> default installation method using the setup wizard.

I'm suspicious that you may be used webmin, and we've had someone here on the 
list recently who installed Squid on Ubuntu along with webmin, and we then 
found out that the package maintainer had put the documentation file for 
squid.conf in place of the actual squid.conf.

It can still work (not everything is commented out) but it's *far* bigger than 
it needs to be, and is somewhat confusing to work with.


Regards,


Antony.

-- 
It may not seem obvious, but (6 x 5 + 5) x 5 - 55 equals 5!

                                                   Please reply to the list;
                                                         please *don't* CC me.


From jvdwesthuiz at shoprite.co.za  Tue Oct  4 16:51:52 2016
From: jvdwesthuiz at shoprite.co.za (Jasper Van Der Westhuizen)
Date: Tue, 4 Oct 2016 16:51:52 +0000
Subject: [squid-users] Squid crash - 3.5.21
In-Reply-To: <aff9b1ab-5233-5e28-af18-5b867dad89df@measurement-factory.com>
References: <1475491833.8486.41.camel@shoprite.co.za>
 <aff9b1ab-5233-5e28-af18-5b867dad89df@measurement-factory.com>
Message-ID: <1475599911.7089.20.camel@shoprite.co.za>



On Mon, 2016-10-03 at 11:33 -0600, Alex Rousskov wrote:

On 10/03/2016 04:50 AM, Jasper Van Der Westhuizen wrote:


This morning I had some problems with some of our proxies. 2 Proxies in
cluster A crashed with the below errors. The shortly afterwards 4 in
cluster B did the same. Both clusters are configured to run their cache
in memory with SMP and 4 workers configured.

FATAL: Received Bus Error...dying.




There are at least two possible reasons:

  1. A bug in Squid and
  2. Memory overallocation by the OS kernel.

To fix the former, the developers will need a stack trace (at least). I
recommend filing a bug report after getting that trace and excluding
reason #2. Squid wiki and various system administration guides explain
how to make Squid dump core files.

To check for memory overallocation, you can temporary start Squid v4.0
with "shared_memory_locking on". Unfortunately, that squid.conf
directive is not available in Squid v3. You may be able to emulate it
using some OS-specific sysctl or environment variables, but doing so may
be far from trivial, and I do not have instructions.




Thanks Alex. We have patched the servers to the latest and will monitor. If it happens again I will fill in a bug report and see where it takes us.

Regards
Jasper





Disclaimer:
http://www.shopriteholdings.co.za/Pages/ShopriteE-mailDisclaimer.aspx
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/3265226f/attachment.htm>

From killerrabbit2012 at gmail.com  Tue Oct  4 17:43:21 2016
From: killerrabbit2012 at gmail.com (KR)
Date: Tue, 4 Oct 2016 13:43:21 -0400
Subject: [squid-users] Problem with Squid3 Caches
In-Reply-To: <201610041745.20899.Antony.Stone@squid.open.source.it>
References: <CD14793F-4F48-433E-9A1E-B2030E1D7F14@gmail.com>
 <201610032306.15880.Antony.Stone@squid.open.source.it>
 <B0508516-890C-4526-8848-78616839ABA5@gmail.com>
 <201610041745.20899.Antony.Stone@squid.open.source.it>
Message-ID: <0580E000-F390-4D8A-A658-696BF4DCF67D@gmail.com>


> On Oct 4, 2016, at 11:45 AM, Antony Stone <Antony.Stone at squid.open.source.it> wrote:
> 
> On Tuesday 04 October 2016 at 17:00:24, KR wrote:
> 
>> Hello Anthony, Yuri,
>> 
>> It seems every line is commented out in the config?
> 
> Impossible - otherwise it couldn't generate the error message "FATAL: Bungled 
> /etc/squid/squid.conf line 3467: cache_dir rock /ssd3 ..."
> 
> Thta is telling you that line 3467 of squid.conf starts with the directive 
> "cache_dir?.

I see, is there an easy way to omit all lines that begin with the # sign?

The line in question is 

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /var/spool/squid 100 16 256

> 
>> This is a fresh install.
> 
> Standard Ubuntu?  Which version?

Standard and current.

> 
>> ls -al /ssd3 outputs:
>> 
>> total 8
>> drwxr-xr-x  2 root root 4096 Aug 13 18:20 .
>> drwxr-xr-x 30 root root 4096 Oct  3 13:49 ..
> 
> Hm, okay, so that really does exist on your machine, then...
> 
>> Attached are two screenshots that are suspect.
> 
> Er, what are those screenshots of?  It's certainly not the output of Squid, or 
> its config file.
> 
>> Do I need all of these cache folders on every partition?
> 
> You can put your cache directories wherever you like.
> 
>> Ubuntu is running inside of a vm,
> 
> Er, so /ssd3 is not an actual SSD, then?  What is it?

I suspect it is an SSD drive, but given this is running inside of a VM, it?s a virtual disc on an SSD I would guess.

> 
>> default installation method using the setup wizard.
> 
> I'm suspicious that you may be used webmin, and we've had someone here on the 
> list recently who installed Squid on Ubuntu along with webmin, and we then 
> found out that the package maintainer had put the documentation file for 
> squid.conf in place of the actual squid.conf.

I tried it both its webadmin and terminal to install.  Same result.  Squid seems to want a cache folder one very partition that exists.
> 
> It can still work (not everything is commented out) but it's *far* bigger than 
> it needs to be, and is somewhat confusing to work with.
> 
> 
> Regards,
> 
> 
> Antony.
> 
> -- 
> It may not seem obvious, but (6 x 5 + 5) x 5 - 55 equals 5!
> 
>                                                   Please reply to the list;
>                                                         please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From killerrabbit2012 at gmail.com  Tue Oct  4 17:48:41 2016
From: killerrabbit2012 at gmail.com (KR)
Date: Tue, 4 Oct 2016 13:48:41 -0400
Subject: [squid-users] Problem with Squid3 Caches
In-Reply-To: <201610041745.20899.Antony.Stone@squid.open.source.it>
References: <CD14793F-4F48-433E-9A1E-B2030E1D7F14@gmail.com>
 <201610032306.15880.Antony.Stone@squid.open.source.it>
 <B0508516-890C-4526-8848-78616839ABA5@gmail.com>
 <201610041745.20899.Antony.Stone@squid.open.source.it>
Message-ID: <7DE7A0D4-9C50-48EF-A297-9E65A7E45AC8@gmail.com>

I uncommented that line and now I get

Initializing the Squid cache with the command squid3 -f /etc/squid/squid.conf -z ..

FATAL: Bungled /etc/squid/squid.conf line 3410: cache_dir rock /hdd1 ... min-size=100000
Squid Cache (Version 3.5.12): Terminated abnormally.
CPU Usage: 0.008 seconds = 0.004 user + 0.004 sys
Maximum Resident Size: 114480 KB
Page faults with physical i/o: 6



> On Oct 4, 2016, at 11:45 AM, Antony Stone <Antony.Stone at squid.open.source.it> wrote:
> 
> On Tuesday 04 October 2016 at 17:00:24, KR wrote:
> 
>> Hello Anthony, Yuri,
>> 
>> It seems every line is commented out in the config?
> 
> Impossible - otherwise it couldn't generate the error message "FATAL: Bungled 
> /etc/squid/squid.conf line 3467: cache_dir rock /ssd3 ..."
> 
> Thta is telling you that line 3467 of squid.conf starts with the directive 
> "cache_dir".
> 
>> This is a fresh install.
> 
> Standard Ubuntu?  Which version?
> 
>> ls -al /ssd3 outputs:
>> 
>> total 8
>> drwxr-xr-x  2 root root 4096 Aug 13 18:20 .
>> drwxr-xr-x 30 root root 4096 Oct  3 13:49 ..
> 
> Hm, okay, so that really does exist on your machine, then...
> 
>> Attached are two screenshots that are suspect.
> 
> Er, what are those screenshots of?  It's certainly not the output of Squid, or 
> its config file.
> 
>> Do I need all of these cache folders on every partition?
> 
> You can put your cache directories wherever you like.
> 
>> Ubuntu is running inside of a vm,
> 
> Er, so /ssd3 is not an actual SSD, then?  What is it?
> 
>> default installation method using the setup wizard.
> 
> I'm suspicious that you may be used webmin, and we've had someone here on the 
> list recently who installed Squid on Ubuntu along with webmin, and we then 
> found out that the package maintainer had put the documentation file for 
> squid.conf in place of the actual squid.conf.
> 
> It can still work (not everything is commented out) but it's *far* bigger than 
> it needs to be, and is somewhat confusing to work with.
> 
> 
> Regards,
> 
> 
> Antony.
> 
> -- 
> It may not seem obvious, but (6 x 5 + 5) x 5 - 55 equals 5!
> 
>                                                   Please reply to the list;
>                                                         please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From Antony.Stone at squid.open.source.it  Tue Oct  4 17:59:36 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 4 Oct 2016 19:59:36 +0200
Subject: [squid-users] Problem with Squid3 Caches
In-Reply-To: <0580E000-F390-4D8A-A658-696BF4DCF67D@gmail.com>
References: <CD14793F-4F48-433E-9A1E-B2030E1D7F14@gmail.com>
 <201610041745.20899.Antony.Stone@squid.open.source.it>
 <0580E000-F390-4D8A-A658-696BF4DCF67D@gmail.com>
Message-ID: <201610041959.36451.Antony.Stone@squid.open.source.it>

On Tuesday 04 October 2016 at 19:43:21, KR wrote:

> > On Oct 4, 2016, at 11:45 AM, Antony Stone wrote:
> > 
> > On Tuesday 04 October 2016 at 17:00:24, KR wrote:
> >> Hello Anthony, Yuri,
> >> 
> >> It seems every line is commented out in the config?
> > 
> > Impossible - otherwise it couldn't generate the error message "FATAL:
> > Bungled /etc/squid/squid.conf line 3467: cache_dir rock /ssd3 ..."
> > 
> > That is telling you that line 3467 of squid.conf starts with the
> > directive "cache_dir?.
> 
> I see, is there an easy way to omit all lines that begin with the # sign?

Well, grep?

eg: grep -v "^[^#]" will show all lines which start with something other than 
a # - in other words, it will omit blank lines and comments.

> The line in question is
> 
> # Uncomment and adjust the following to add a disk cache directory.
> #cache_dir ufs /var/spool/squid 100 16 256

Please confirm which file you are showing us the information from.

> > Standard Ubuntu?  Which version?
> 
> Standard and current.

So, 16.04?

> >> Attached are two screenshots that are suspect.
> > 
> > Er, what are those screenshots of?  It's certainly not the output of
> > Squid, or its config file.

An answer to this would be helpful.

> >> Ubuntu is running inside of a vm,
> > 
> > Er, so /ssd3 is not an actual SSD, then?  What is it?
> 
> I suspect it is an SSD drive

"Suspect"?

How have you set up this VM?  Is there an actual device mounted on /ssd3, or 
is it just some directory name in your VM?

> > I'm suspicious that you may be used webmin, and we've had someone here on
> > the list recently who installed Squid on Ubuntu along with webmin, and
> > we then found out that the package maintainer had put the documentation
> > file for squid.conf in place of the actual squid.conf.
> 
> I tried it both its webadmin

Please specify what yu mean by this - what is the "it" which "its" refers to 
above?

> and terminal to install.  Same result.  Squid seems to want a cache folder
> one very partition that exists.

I recommend you stop using any graphical tool to try to manage Squid, remove 
the package, and then simply:

1. Install the Squid (maybe called Squid3?  I can't quite recall for Ubuntu) 
package using apt-get or aptitude.

2. Edit the config file /etc/squid/squid.conf to your needs.

Hope that helps,


Antony.

-- 
"The future is already here.   It's just not evenly distributed yet."

 - William Gibson

                                                   Please reply to the list;
                                                         please *don't* CC me.


From nilesh.gavali at tcs.com  Tue Oct  4 18:00:35 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Tue, 4 Oct 2016 19:00:35 +0100
Subject: [squid-users] Squid - AD kerberos auth and Linux Server proxy
	access not working
Message-ID: <OF8D12BD2C.F821F41E-ON80258042.0062D619-80258042.0062EE60@tcs.com>

Hi Amos;
Ok, we can discussed the issue in Two part  1. For Windows AD 
Authentication & SSO and 2. Linux server unable to access via squid proxy.

For First point-
Requirement to have SSO for accessing internet via squid proxy and based 
on user's AD group membership allow access to specific sites only. I 
believe current configuration of squid is working as expected.

For Second point -
Point I would like to highlight here is, the Linux server IWCCP01 is not 
part of domain at all. Hence the below error as squid configured for 
AD_auth. So how can we allow Linux server or non domain machine to access 
specific sites?

> Error 407 is "proxy auth required", so the proxy is expecting 
authentication 
> for some reason.
====================================
 > Can you confirm that the hostname vseries-test.bottomline.com is 
contained in 
> your site file /etc/squid/sitelist/dbs_allowed_site ?

YES, we have entry as .bottomline.com , which work fine when access via 
windows machine having proxy enabled for that user.
==============================
> Can you temporarily change the line "http_access allow IWCCP01 
allowedsite" to 
> "http_access allow IWCCP01" and see whether the machine then gets 
access?

I made the changes as suggested but still it is giving same Error 407.
========================================
If that works, please list the output of the command:
  grep "bottomline.com" /etc/squid/sitelist/dbs_allowed_site

o/p of above command as below -

[root at Proxy02 ~]# grep "bottomline.com" 
/etc/squid/sitelist/dbs_allowed_site
.bottomline.com
[root at Proxy02 ~]#

=======================================

Thanks & Regards
Nilesh Suresh Gavali




 
Message: 2
Date: Wed, 5 Oct 2016 00:11:08 +1300
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid - AD kerberos auth and Linux Server
                 proxy access not working
Message-ID: <d35ad0ca-761d-60e3-c594-04697110afdc at treenet.co.nz>
Content-Type: text/plain; charset=utf-8

On 4/10/2016 11:36 p.m., Antony Stone wrote:
> On Tuesday 04 October 2016 at 12:28:44, Nilesh Gavali wrote:
> 
>> Hello Antony;
>> I have double checked the current working configuration of my 
squid.conf
>> and it has same settings which I posted earlier. somehow it is working 
for
>> us.
> 
> I'm not saying the whole thing won't work; I'm saying there is no point 
in 
> having a line "http_access allow ad_auth" following the line 
"http_access deny 
> all".  The ad_auth line can never be invoked.

Not knowing why authentication works is dangerous. You might have been
allowing non-authenticated traffic and invalid user accounts through.

The only reason it does "work" is that the ACL called "USERS" is _not_
actually checking user logins. It is a group checking ACL which requires
authentication to happen before it can be checked.

In this specific case invalid logins cannot be a member of the group. So
they will not get through the proxy.

However, people who accidentally type the user/password wrong, or whose
machines automatically login with an account not a member of the group
will not be allowed any way to try again short of shutting down their
browser or maybe even logging out of the machine and trying from another
one.

That may or may not be a problem for you.

> 
>> below is the error from access.log file.
>>
>> 1475518342.279      0 10.xx.15.103 TCP_DENIED/407 3589 CONNECT
>> vseries-test.bottomline.com:443 - NONE/- text/html
> 
> Error 407 is "proxy auth required", so the proxy is expecting 
authentication 
> for some reason.
> 
> Can you confirm that the hostname vseries-test.bottomline.com is 
contained in 
> your site file /etc/squid/sitelist/dbs_allowed_site ?
> 
> Can you temporarily change the line "http_access allow IWCCP01 
allowedsite" to 
> "http_access allow IWCCP01" and see whether the machine then gets 
access?
> 

If that works, please list the output of the command:
  grep "bottomline.com" /etc/squid/sitelist/dbs_allowed_site

Amos

*******************************************

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/74c74d44/attachment.htm>

From erdosain9 at gmail.com  Tue Oct  4 18:45:32 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 4 Oct 2016 11:45:32 -0700 (PDT)
Subject: [squid-users] Kerberos Ne
In-Reply-To: <1475182966034-4679774.post@n4.nabble.com>
References: <1475071362112-4679740.post@n4.nabble.com>
 <b037432c-b371-d721-8f21-eb9c78d8685b@treenet.co.nz>
 <1475182966034-4679774.post@n4.nabble.com>
Message-ID: <1475606732467-4679901.post@n4.nabble.com>

so........... any advice about this??
Thanks!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Kerberos-appropriate-log-file-tp4679740p4679901.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From jetsystemservices at gmail.com  Tue Oct  4 20:41:09 2016
From: jetsystemservices at gmail.com (Jose Torres-Berrocal)
Date: Tue, 4 Oct 2016 16:41:09 -0400
Subject: [squid-users] Whitelist domain ignored?
Message-ID: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>

I  do not know the correct terms to the problem I have.

I have some clients that use a program that tries to connect to:
https://neodecksoftware.com/NeoMedOnline/NeoMedOnlineService.svc

Went to the access.log and found the neodecksoftware.com is being
denied even that I have it in a whitelist file.

The below info is the error lines fund, the whitelist file content,
and the squid conf:

----------------------------------------------------------------------------------------------
1475581614.208      0 192.168.1.20 TCP_DENIED/407 3917 CONNECT
neodecksoftware.com:443 - HIER_NONE/- text/html
1475582327.774      0 192.168.1.20 TCP_DENIED/407 3917 CONNECT
neodecksoftware.com:443 - HIER_NONE/- text/html

/var/squid/acl/whitelist.acl:
.familymedicinepr.com
.anydesk.com
.teamviewer.com
.secureserver.net
.gmail.com
.mail.yahoo.com
.outlook.com
.aol.com
.libertypr.net
.coqui.net
.prtc.net
.assertus.com
.neodecksoftware.com
.office.net
.microsoft.com
.office.com
.live.com

# This file is automatically generated by pfSense
# Do not edit manually !

http_port 192.168.1.1:3128
http_port 127.0.0.1:3128
icp_port 0
dns_v4_first off
pid_filename /var/run/squid/squid.pid
cache_effective_user squid
cache_effective_group proxy
error_default_language en
icon_directory /usr/local/etc/squid/icons
visible_hostname pfsense
cache_mgr jetsystemservices at gmail.com
access_log /var/squid/logs/access.log
cache_log /var/squid/logs/cache.log
cache_store_log none
netdb_filename /var/squid/logs/netdb.state
pinger_enable on
pinger_program /usr/local/libexec/squid/pinger

logfile_rotate 31
debug_options rotate=31
shutdown_lifetime 3 seconds
# Allow local network(s) on interface(s)
acl localnet src  192.168.1.0/24 127.0.0.0/8
forwarded_for on
uri_whitespace strip

acl dynamic urlpath_regex cgi-bin \?
cache deny dynamic

cache_mem 512 MB
maximum_object_size_in_memory 256 KB
memory_replacement_policy heap GDSF
cache_replacement_policy heap LFUDA
minimum_object_size 0 KB
maximum_object_size 4 MB

offline_mode off
cache_swap_low 90
cache_swap_high 95
cache allow all
# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:    1440  20%  10080
refresh_pattern ^gopher:  1440  0%  1440
refresh_pattern -i (/cgi-bin/|\?) 0  0%  0
refresh_pattern .    0  20%  4320


#Remote proxies


# Setup some default acls
# From 3.2 further configuration cleanups have been done to make
things easier and safer. The manager, localhost, and to_localhost ACL
definitions are now built-in.
# acl localhost src 127.0.0.1/32
acl allsrc src all
acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901  3128
3129 1025-65535 444
acl sslports port 443 563  444

# From 3.2 further configuration cleanups have been done to make
things easier and safer. The manager, localhost, and to_localhost ACL
definitions are now built-in.
#acl manager proto cache_object

acl purge method PURGE
acl connect method CONNECT

# Define protocols used for redirects
acl HTTP proto HTTP
acl HTTPS proto HTTPS
acl whitelist dstdom_regex -i "/var/squid/acl/whitelist.acl"
http_access allow manager localhost

http_access deny manager
http_access allow purge localhost
http_access deny purge
http_access deny !safeports
http_access deny CONNECT !sslports

# Always allow localhost connections
# From 3.2 further configuration cleanups have been done to make
things easier and safer.
# The manager, localhost, and to_localhost ACL definitions are now built-in.
# http_access allow localhost

request_body_max_size 0 KB
delay_pools 1
delay_class 1 2
delay_parameters 1 -1/-1 -1/-1
delay_initial_bucket_level 100
delay_access 1 allow allsrc

# Reverse Proxy settings


# Custom options before auth
connect_timeout 2

# Always allow access to whitelist domains
http_access allow whitelist
auth_param basic program /usr/local/libexec/squid/basic_radius_auth -w
Maint4030 -h pfsense -p
auth_param basic children 5
auth_param basic realm Please enter your credentials to access the proxy
auth_param basic credentialsttl 5 minutes
acl password proxy_auth REQUIRED
# Custom options after auth


http_access allow password localnet
# Default block all to be sure
http_access deny allsrc

----------------------------------------------------------------------------------------------

Cordially,
Jose


From jetsystemservices at gmail.com  Tue Oct  4 21:22:15 2016
From: jetsystemservices at gmail.com (Jose Torres-Berrocal)
Date: Tue, 4 Oct 2016 17:22:15 -0400
Subject: [squid-users] Whitelist domain ignored?
In-Reply-To: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>
References: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>
Message-ID: <CABU5kW5Ysi1nAzP83RekKqFvvuxG12Ym6nXwcW_j=qc3Gow5_Q@mail.gmail.com>

Just to confirm that I sent the email

Jose E Torres
939-777-4030
JET System Services


On Tue, Oct 4, 2016 at 4:41 PM, Jose Torres-Berrocal
<jetsystemservices at gmail.com> wrote:
> I  do not know the correct terms to the problem I have.
>
> I have some clients that use a program that tries to connect to:
> https://neodecksoftware.com/NeoMedOnline/NeoMedOnlineService.svc
>
> Went to the access.log and found the neodecksoftware.com is being
> denied even that I have it in a whitelist file.
>
> The below info is the error lines fund, the whitelist file content,
> and the squid conf:
>
> ----------------------------------------------------------------------------------------------
> 1475581614.208      0 192.168.1.20 TCP_DENIED/407 3917 CONNECT
> neodecksoftware.com:443 - HIER_NONE/- text/html
> 1475582327.774      0 192.168.1.20 TCP_DENIED/407 3917 CONNECT
> neodecksoftware.com:443 - HIER_NONE/- text/html
>
> /var/squid/acl/whitelist.acl:
> .familymedicinepr.com
> .anydesk.com
> .teamviewer.com
> .secureserver.net
> .gmail.com
> .mail.yahoo.com
> .outlook.com
> .aol.com
> .libertypr.net
> .coqui.net
> .prtc.net
> .assertus.com
> .neodecksoftware.com
> .office.net
> .microsoft.com
> .office.com
> .live.com
>
> # This file is automatically generated by pfSense
> # Do not edit manually !
>
> http_port 192.168.1.1:3128
> http_port 127.0.0.1:3128
> icp_port 0
> dns_v4_first off
> pid_filename /var/run/squid/squid.pid
> cache_effective_user squid
> cache_effective_group proxy
> error_default_language en
> icon_directory /usr/local/etc/squid/icons
> visible_hostname pfsense
> cache_mgr jetsystemservices at gmail.com
> access_log /var/squid/logs/access.log
> cache_log /var/squid/logs/cache.log
> cache_store_log none
> netdb_filename /var/squid/logs/netdb.state
> pinger_enable on
> pinger_program /usr/local/libexec/squid/pinger
>
> logfile_rotate 31
> debug_options rotate=31
> shutdown_lifetime 3 seconds
> # Allow local network(s) on interface(s)
> acl localnet src  192.168.1.0/24 127.0.0.0/8
> forwarded_for on
> uri_whitespace strip
>
> acl dynamic urlpath_regex cgi-bin \?
> cache deny dynamic
>
> cache_mem 512 MB
> maximum_object_size_in_memory 256 KB
> memory_replacement_policy heap GDSF
> cache_replacement_policy heap LFUDA
> minimum_object_size 0 KB
> maximum_object_size 4 MB
>
> offline_mode off
> cache_swap_low 90
> cache_swap_high 95
> cache allow all
> # Add any of your own refresh_pattern entries above these.
> refresh_pattern ^ftp:    1440  20%  10080
> refresh_pattern ^gopher:  1440  0%  1440
> refresh_pattern -i (/cgi-bin/|\?) 0  0%  0
> refresh_pattern .    0  20%  4320
>
>
> #Remote proxies
>
>
> # Setup some default acls
> # From 3.2 further configuration cleanups have been done to make
> things easier and safer. The manager, localhost, and to_localhost ACL
> definitions are now built-in.
> # acl localhost src 127.0.0.1/32
> acl allsrc src all
> acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901  3128
> 3129 1025-65535 444
> acl sslports port 443 563  444
>
> # From 3.2 further configuration cleanups have been done to make
> things easier and safer. The manager, localhost, and to_localhost ACL
> definitions are now built-in.
> #acl manager proto cache_object
>
> acl purge method PURGE
> acl connect method CONNECT
>
> # Define protocols used for redirects
> acl HTTP proto HTTP
> acl HTTPS proto HTTPS
> acl whitelist dstdom_regex -i "/var/squid/acl/whitelist.acl"
> http_access allow manager localhost
>
> http_access deny manager
> http_access allow purge localhost
> http_access deny purge
> http_access deny !safeports
> http_access deny CONNECT !sslports
>
> # Always allow localhost connections
> # From 3.2 further configuration cleanups have been done to make
> things easier and safer.
> # The manager, localhost, and to_localhost ACL definitions are now built-in.
> # http_access allow localhost
>
> request_body_max_size 0 KB
> delay_pools 1
> delay_class 1 2
> delay_parameters 1 -1/-1 -1/-1
> delay_initial_bucket_level 100
> delay_access 1 allow allsrc
>
> # Reverse Proxy settings
>
>
> # Custom options before auth
> connect_timeout 2
>
> # Always allow access to whitelist domains
> http_access allow whitelist
> auth_param basic program /usr/local/libexec/squid/basic_radius_auth -w
> Maint4030 -h pfsense -p
> auth_param basic children 5
> auth_param basic realm Please enter your credentials to access the proxy
> auth_param basic credentialsttl 5 minutes
> acl password proxy_auth REQUIRED
> # Custom options after auth
>
>
> http_access allow password localnet
> # Default block all to be sure
> http_access deny allsrc
>
> ----------------------------------------------------------------------------------------------
>
> Cordially,
> Jose


From webmaster at squidblacklist.org  Tue Oct  4 21:35:45 2016
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Tue, 4 Oct 2016 16:35:45 -0500
Subject: [squid-users] Whitelist domain ignored?
In-Reply-To: <CABU5kW5Ysi1nAzP83RekKqFvvuxG12Ym6nXwcW_j=qc3Gow5_Q@mail.gmail.com>
References: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>
 <CABU5kW5Ysi1nAzP83RekKqFvvuxG12Ym6nXwcW_j=qc3Gow5_Q@mail.gmail.com>
Message-ID: <80d89697-3d10-a17f-85de-ce5b2fddfd92@squidblacklist.org>

Yes we can see your messages to the group..

While im responding, this doesnt adress you problem, but we have a free 
whitelist that we maintain you may or may not be interested in, but its 
quite  a bit larger. No adult, and no torrent sites.

http://www.squidblacklist.org/downloads/whitelist.txt


<http://www.squidblacklist.org/downloads/whitelist.txt>

Good Luck!


On 10/4/2016 4:22 PM, Jose Torres-Berrocal wrote:
> Just to confirm that I sent the email
>
> Jose E Torres
> 939-777-4030
> JET System Services
>
>
> On Tue, Oct 4, 2016 at 4:41 PM, Jose Torres-Berrocal
> <jetsystemservices at gmail.com> wrote:
>> I  do not know the correct terms to the problem I have.
>>
>> I have some clients that use a program that tries to connect to:
>> https://neodecksoftware.com/NeoMedOnline/NeoMedOnlineService.svc
>>
>> Went to the access.log and found the neodecksoftware.com is being
>> denied even that I have it in a whitelist file.
>>
>> The below info is the error lines fund, the whitelist file content,
>> and the squid conf:
>>
>> ----------------------------------------------------------------------------------------------
>> 1475581614.208      0 192.168.1.20 TCP_DENIED/407 3917 CONNECT
>> neodecksoftware.com:443 - HIER_NONE/- text/html
>> 1475582327.774      0 192.168.1.20 TCP_DENIED/407 3917 CONNECT
>> neodecksoftware.com:443 - HIER_NONE/- text/html
>>
>> /var/squid/acl/whitelist.acl:
>> .familymedicinepr.com
>> .anydesk.com
>> .teamviewer.com
>> .secureserver.net
>> .gmail.com
>> .mail.yahoo.com
>> .outlook.com
>> .aol.com
>> .libertypr.net
>> .coqui.net
>> .prtc.net
>> .assertus.com
>> .neodecksoftware.com
>> .office.net
>> .microsoft.com
>> .office.com
>> .live.com
>>
>> # This file is automatically generated by pfSense
>> # Do not edit manually !
>>
>> http_port 192.168.1.1:3128
>> http_port 127.0.0.1:3128
>> icp_port 0
>> dns_v4_first off
>> pid_filename /var/run/squid/squid.pid
>> cache_effective_user squid
>> cache_effective_group proxy
>> error_default_language en
>> icon_directory /usr/local/etc/squid/icons
>> visible_hostname pfsense
>> cache_mgr jetsystemservices at gmail.com
>> access_log /var/squid/logs/access.log
>> cache_log /var/squid/logs/cache.log
>> cache_store_log none
>> netdb_filename /var/squid/logs/netdb.state
>> pinger_enable on
>> pinger_program /usr/local/libexec/squid/pinger
>>
>> logfile_rotate 31
>> debug_options rotate=31
>> shutdown_lifetime 3 seconds
>> # Allow local network(s) on interface(s)
>> acl localnet src  192.168.1.0/24 127.0.0.0/8
>> forwarded_for on
>> uri_whitespace strip
>>
>> acl dynamic urlpath_regex cgi-bin \?
>> cache deny dynamic
>>
>> cache_mem 512 MB
>> maximum_object_size_in_memory 256 KB
>> memory_replacement_policy heap GDSF
>> cache_replacement_policy heap LFUDA
>> minimum_object_size 0 KB
>> maximum_object_size 4 MB
>>
>> offline_mode off
>> cache_swap_low 90
>> cache_swap_high 95
>> cache allow all
>> # Add any of your own refresh_pattern entries above these.
>> refresh_pattern ^ftp:    1440  20%  10080
>> refresh_pattern ^gopher:  1440  0%  1440
>> refresh_pattern -i (/cgi-bin/|\?) 0  0%  0
>> refresh_pattern .    0  20%  4320
>>
>>
>> #Remote proxies
>>
>>
>> # Setup some default acls
>> # From 3.2 further configuration cleanups have been done to make
>> things easier and safer. The manager, localhost, and to_localhost ACL
>> definitions are now built-in.
>> # acl localhost src 127.0.0.1/32
>> acl allsrc src all
>> acl safeports port 21 70 80 210 280 443 488 563 591 631 777 901  3128
>> 3129 1025-65535 444
>> acl sslports port 443 563  444
>>
>> # From 3.2 further configuration cleanups have been done to make
>> things easier and safer. The manager, localhost, and to_localhost ACL
>> definitions are now built-in.
>> #acl manager proto cache_object
>>
>> acl purge method PURGE
>> acl connect method CONNECT
>>
>> # Define protocols used for redirects
>> acl HTTP proto HTTP
>> acl HTTPS proto HTTPS
>> acl whitelist dstdom_regex -i "/var/squid/acl/whitelist.acl"
>> http_access allow manager localhost
>>
>> http_access deny manager
>> http_access allow purge localhost
>> http_access deny purge
>> http_access deny !safeports
>> http_access deny CONNECT !sslports
>>
>> # Always allow localhost connections
>> # From 3.2 further configuration cleanups have been done to make
>> things easier and safer.
>> # The manager, localhost, and to_localhost ACL definitions are now built-in.
>> # http_access allow localhost
>>
>> request_body_max_size 0 KB
>> delay_pools 1
>> delay_class 1 2
>> delay_parameters 1 -1/-1 -1/-1
>> delay_initial_bucket_level 100
>> delay_access 1 allow allsrc
>>
>> # Reverse Proxy settings
>>
>>
>> # Custom options before auth
>> connect_timeout 2
>>
>> # Always allow access to whitelist domains
>> http_access allow whitelist
>> auth_param basic program /usr/local/libexec/squid/basic_radius_auth -w
>> Maint4030 -h pfsense -p
>> auth_param basic children 5
>> auth_param basic realm Please enter your credentials to access the proxy
>> auth_param basic credentialsttl 5 minutes
>> acl password proxy_auth REQUIRED
>> # Custom options after auth
>>
>>
>> http_access allow password localnet
>> # Default block all to be sure
>> http_access deny allsrc
>>
>> ----------------------------------------------------------------------------------------------
>>
>> Cordially,
>> Jose
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Signed,

Benjamin E. Nichols

http://www.squidblacklist.org

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/5d0ea66c/attachment.htm>

From squid-users at filter.luko.org  Tue Oct  4 23:04:32 2016
From: squid-users at filter.luko.org (squid-users at filter.luko.org)
Date: Wed, 5 Oct 2016 10:04:32 +1100
Subject: [squid-users] Introducing delay to HTTP 407 responses
In-Reply-To: <7601901b-d28f-5d05-6a17-6ba96e5bd174@treenet.co.nz>
References: <000301d20e1d$7476f840$5d64e8c0$@filter.luko.org>
 <013301d20e8f$12f257f0$38d707d0$@ngtech.co.il>
 <007a01d21e2d$905f1e00$b11d5a00$@filter.luko.org>
 <c521b757-2596-e122-d468-84ebbc5528c0@treenet.co.nz>
 <009d01d21e35$179582e0$46c088a0$@filter.luko.org>
 <7601901b-d28f-5d05-6a17-6ba96e5bd174@treenet.co.nz>
Message-ID: <00fb01d21e93$ab3811d0$01a83570$@filter.luko.org>

> > I set this up as you suggested, then triggered a 407 response from the
> cache.  It seems that way; I couldn't see aclMatchHTTPStatus or http-
> response-407 in the log:
> >
> 
> Strange. I was sure Alex did some tests recently and proved that even
> internally generated responses get http_reply_access applied to them.
> Yet no sign of that in your log.
> 
> Is this a very old Squid version?

It's a recent Squid version - 3.5.20 on CentOS 6, built from the SRPM kindly provided by Eliezer.

> Or are the "checking http_reply_access" lines just later in the log than
> your snippet covered?

There was nothing more in the log previously posted at the point the 407 response was returned to the client.

That log did have a lot of other stuff in it though.  Using a much simpler squid.conf (attached), I tested for differences in authenticated vs unauthenticated requests, when "http_reply_access deny all" is in place.  When credentials are supplied, a http/403 (forbidden) response is provided, as you would expect.  But when credentials are not supplied, a http/407 response is provided.  The divergence seems to start around line 31 in cache_noauth.log:

Checklist.cc(63) markFinished: 0x331e4a8 answer AUTH_REQUIRED for AuthenticateAcl exception

Perhaps when answer=AUTH_REQUIRED (line 35), http_reply_access is not checked?  Another difference is that Acl.cc(158) reports async when an authenticated request is in place, but not otherwise.  If someone could give me some pointers where to look in the source, I can start digging to see if I can find out more.

Luke

-------------- next part --------------
A non-text attachment was scrubbed...
Name: cache_auth.log
Type: application/octet-stream
Size: 7534 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161005/90c8d36c/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: cache_noauth.log
Type: application/octet-stream
Size: 4933 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161005/90c8d36c/attachment-0001.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.conf
Type: application/octet-stream
Size: 1039 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161005/90c8d36c/attachment-0002.obj>

From jok at spikes.com  Tue Oct  4 23:16:29 2016
From: jok at spikes.com (Jok Thuau)
Date: Tue, 4 Oct 2016 16:16:29 -0700
Subject: [squid-users] Whitelist domain ignored?
In-Reply-To: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>
References: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>
Message-ID: <CADSSinNYT4GX5+4YhmF62GvGL2remrHm27Av8kr_V-xgBY3rEg@mail.gmail.com>

On Tue, Oct 4, 2016 at 1:41 PM, Jose Torres-Berrocal <
jetsystemservices at gmail.com> wrote:

> I  do not know the correct terms to the problem I have.
>
> I have some clients that use a program that tries to connect to:
> https://neodecksoftware.com/NeoMedOnline/NeoMedOnlineService.svc
>
>
note that there is nothing between "//" and "neodecksoftware.com"...

[snip]

>
> ------------------------------------------------------------
> ----------------------------------
> 1475581614.208      0 192.168.1.20 TCP_DENIED/407 3917 CONNECT
> neodecksoftware.com:443 - HIER_NONE/- text/html
> 1475582327.774      0 192.168.1.20 TCP_DENIED/407 3917 CONNECT
> neodecksoftware.com:443 - HIER_NONE/- text/html
>
>
note that the ACL applies on that connect string. Specifically "
neodecksoftware.com"



> /var/squid/acl/whitelist.acl:
>
[snip]

> .assertus.com
> .neodecksoftware.com


your whitelist for this domain says that it has "something" followed by
that domain name...


>
> .office.net

[snip]


>
> # This file is automatically generated by pfSense
> # Do not edit manually !
>
> http_port 192.168.1.1:3128
> http_port 127.0.0.1:3128
>
[snip]

> acl whitelist dstdom_regex -i "/var/squid/acl/whitelist.acl"
>

and your ACL refers to a regular expression...


> http_access allow manager localhost
>
[snip]

> # Always allow access to whitelist domains
> http_access allow whitelist
>

and you allow that whitelist...

in the end, your regular expression doesn't match.
"." means "any single character". you should replace that line with
something like this:
^neodecksoftware\.com

(this is untested).

Note that all your entries need adjusting as well (they may be working, but
not matching the way you think they do).

HTH,
Jok
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161004/099ab0e5/attachment.htm>

From rousskov at measurement-factory.com  Wed Oct  5 00:12:27 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 4 Oct 2016 18:12:27 -0600
Subject: [squid-users] Introducing delay to HTTP 407 responses
In-Reply-To: <7601901b-d28f-5d05-6a17-6ba96e5bd174@treenet.co.nz>
References: <000301d20e1d$7476f840$5d64e8c0$@filter.luko.org>
 <013301d20e8f$12f257f0$38d707d0$@ngtech.co.il>
 <007a01d21e2d$905f1e00$b11d5a00$@filter.luko.org>
 <c521b757-2596-e122-d468-84ebbc5528c0@treenet.co.nz>
 <009d01d21e35$179582e0$46c088a0$@filter.luko.org>
 <7601901b-d28f-5d05-6a17-6ba96e5bd174@treenet.co.nz>
Message-ID: <82c0c153-a128-74fe-c216-6ea9d285d3be@measurement-factory.com>

On 10/04/2016 06:20 AM, Amos Jeffries wrote:
> On 5/10/2016 12:47 a.m., squid-users wrote:

>> I set this up as you suggested, then triggered a 407 response from
>> the cache.  It seems that way; I couldn't see aclMatchHTTPStatus or
>> http-response-407 in the log


> Strange. I was sure Alex did some tests recently and proved that even
> internally generated responses get http_reply_access applied to them.


Yes, see
http://lists.squid-cache.org/pipermail/squid-users/2016-August/012048.html

However, there is a difference between my August tests and this thread.
My tests were for a request parsing error response. Access denials do
not reach the same http_reply_access checks! See "early return"
statements in clientReplyContext::processReplyAccess(), including:

>     /** Don't block our own responses or HTTP status messages */
>     if (http->logType.oldType == LOG_TCP_DENIED ||
>             http->logType.oldType == LOG_TCP_DENIED_REPLY ||
>             alwaysAllowResponse(reply->sline.status())) {
>         headers_sz = reply->hdr_sz;
>         processReplyAccessResult(ACCESS_ALLOWED);
>         return;
>     }

I am not sure whether avoiding http_reply_access in such cases is a
bug/misfeature or the right behavior. As any exception, it certainly
creates problems for those who want to [ab]use http_reply_access as a
delay hook. FWIW, Squid had this exception since 2007:

> revno: 8474
> committer: hno
> branch nick: HEAD
> timestamp: Thu 2007-08-30 19:03:42 +0000
> message:
>   Bug #2028: FATAL error if using http_reply_access in combination with authentication
>   
>   The attached patch bypasses http_reply_access on access denied messages
>   generated by this Squid, and also optimizes processing slightly in the
>   common case of not using any http_reply_access rules at all.


HTH,

Alex.



From rousskov at measurement-factory.com  Wed Oct  5 00:24:19 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 4 Oct 2016 18:24:19 -0600
Subject: [squid-users] Whitelist domain ignored?
In-Reply-To: <CADSSinNYT4GX5+4YhmF62GvGL2remrHm27Av8kr_V-xgBY3rEg@mail.gmail.com>
References: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>
 <CADSSinNYT4GX5+4YhmF62GvGL2remrHm27Av8kr_V-xgBY3rEg@mail.gmail.com>
Message-ID: <4d4e7006-164a-6b79-c7e1-df5100ceb29f@measurement-factory.com>

On 10/04/2016 05:16 PM, Jok Thuau wrote:
> On Tue, Oct 4, 2016 at 1:41 PM, Jose Torres-Berrocal wrote:

>>     I have some clients that use a program that tries to connect to:
>>     https://neodecksoftware.com/NeoMedOnline/NeoMedOnlineService.svc


>>     /var/squid/acl/whitelist.acl:

>>     .assertus.com
>>     .neodecksoftware.com


> your whitelist for this domain says that it has "something" followed by
> that domain name...

Good catch! Actually, the problem is even worse. The dstdom_regex will
match even notneodecksoftwarexcom.org IIRC.


>>     acl whitelist dstdom_regex -i "/var/squid/acl/whitelist.acl"

Perhaps the configuration author meant to say dstdomain instead of
dstdom_regex? Are there any intentional regular expressions in
/var/squid/acl/whitelist.acl?

Alex.



From squid3 at treenet.co.nz  Wed Oct  5 01:02:59 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 5 Oct 2016 14:02:59 +1300
Subject: [squid-users] problem in configuring squid
In-Reply-To: <CAKCdGgD-F+YUXP55QVUtyQVyi2PWV910CA9PV3UgyLcKfB5a_Q@mail.gmail.com>
References: <CAKCdGgCWF4vUb-K5JZ8L4HCvNEtLRfXaz+VfH8PNfSbACrh6hQ@mail.gmail.com>
 <201610031722.29450.Antony.Stone@squid.open.source.it>
 <CAKCdGgDDQ2+-vG=fC_6PA4G3af-ObVwpDQi2EnfWzxCM1gtvUw@mail.gmail.com>
 <201610041514.47755.Antony.Stone@squid.open.source.it>
 <CAKCdGgD-F+YUXP55QVUtyQVyi2PWV910CA9PV3UgyLcKfB5a_Q@mail.gmail.com>
Message-ID: <4fbed5fe-bd6e-54c9-1fce-ddcb449774cd@treenet.co.nz>

On 5/10/2016 4:42 a.m., Shark wrote:
> Sorry for my bad english,
> 
> I want to make a anonymous https & http proxy that pass through any
> requests without decrypting or change them,
> only change ip address from client ip to my server ip address and define ip
> address of my websites that i want to access them from my client in
> /etc/hosts,
> so i try to install squid on my server and i have good experience when i
> set proxy in client with server ip and port 3128 and i can access http &
> https behind this proxy,

By configuring your client with details about the proxy you have
configured a forward (aka explicit) proxy.

That is the best type to have when you can. Because it lets you use the
full capabilities of proxying in HTTP.

However, it also means that the clients do not use DNS nor /etc/hosts
file. The proxy is what does DNS lookups about where to send the traffic
the client(s) ask it to fetch.


> but when i try to using /etc/hosts i cannot access to https websites.

HTTPS is designed to prevent people playing around with the traffic. The
'S' means *secure(d)* - for a good reason.

> i try
> to install squid lot of time with any install instructions that i found
> from googling.
> I have server with CentOS 7 with one valid internet ip address.
> 
> For more explain of what i want to do, i need my squid to work like this ip
> 173.161.0.227
> When i add *173.161.0.227 www.iplocation.net <http://www.iplocation.net>* to
> my client /etc/hosts
> I can browse https://www.iplocation.net that tell me my client ip address
> is 173.161.0.227
> I want do my proxy server same as 173.161.0.227
> 

>From what you have said so far it is clear the domain names you plan to
use this for are owned by somebody who is not you.


> *My problem is now with below config is:*
> 
> when i define *216.55.x.x www.iplocation.net <http://www.iplocation.net>* to
> /etc/hosts in my client i cannot access to https://www.iplocation.net and
> hang on connecting and then give me timeout error,
> I`m appreciate for help me to resolve this problem.
> I ask it before in
> http://serverfault.com/questions/805413/squid-with-iptables-bypass-https
>  but i cannot resolve it

When you are not the owner of that domain name; ..

That means you do not own the secret encryption key that HTTPS
associates with that domain name.

That means you cannot setup your proxy to perform encryption/decryption
of traffic when acting as a web server for it.

The only options you have for HTTPS are:

1) to use the proxy as a proper forward/explicit proxy the normal way
HTTP does that.

Or

2) to forget the idea of setting your own IP as web server and use MITM
interception of the clients normal port 443 traffic with SSL-Bump
feature enabled in your Squid.


> 
> *My Iptables config is:*
> 
> iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-port 3130
> 

That is okay. It is the (2) option mentioned above.

Be aware that it is incompatible with the idea of setting /etc/hosts IP
address for the domain as a way to get it to the proxy.

This iptables rules is the way to catch client traffic already on its
way to the *real* domain server(s) and send it through the proxy instead.

It is a bit nasty to work with, but still way better than MITM through
/etc/hosts entries.


> *My squid config is:*
> 
<snip>
> 
> http_port 3128

Okay. This port will accept traffic from the above option (1) setups.


> http_port 80

No.

> http_port 0.0.0.0:3129 ssl-bump  cert=/etc/squid/ssl_cert/myCA.pem
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> https_port 0.0.0.0:3130 ssl-bump intercept
> cert=/etc/squid/ssl_cert/myCA.pem generate-host-certificates=on
> dynamic_cert_mem_cache_size=4MB
> 

Okay. These ports will accept traffic for the above option (2) setups.


> sslproxy_cert_error allow all
> sslproxy_flags DONT_VERIFY_PEER
> 

Those are wrong for any installation. Even testing ones. You need to see
the errors to even start to find solutions.

Amos



From hardikdangar+squid at gmail.com  Wed Oct  5 10:27:42 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Wed, 5 Oct 2016 15:57:42 +0530
Subject: [squid-users] Caching http google deb files
In-Reply-To: <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
Message-ID: <CA+sSnVZ2ErFD+LeLVH3KOjJ_0PuqGyWfRHA23zY8yJQs3kP+Rw@mail.gmail.com>

Hey Amos,

I have implemented your patch at

and added following to my squid.conf
archive_mode allow all

and my refresh pattern is,
refresh_pattern dl-ssl.google.com/.*\.(deb|zip|tar|rpm) 129600 100% 129600
ignore-reload ignore-no-store override-expire override-lastmod ignor$

but i am still not able to cache it, can you tell from below output what
would be the problem ? Do i need to configure anything extra ?

here is the debug output for the same,
------------------------------------------------------------------------------------------------

2016/10/05 15:46:25.319 kid1| 5,2| TcpAcceptor.cc(220) doAccept: New
connection on FD 14
2016/10/05 15:46:25.319 kid1| 5,2| TcpAcceptor.cc(295) acceptNext:
connection on local=[::]:3128 remote=[::] FD 14 flags=9
2016/10/05 15:46:25.319 kid1| 11,2| client_side.cc(2346) parseHttpRequest:
HTTP Client local=192.168.1.1:3128 remote=192.168.1.76:51236 FD 12 flags=1
2016/10/05 15:46:25.319 kid1| 11,2| client_side.cc(2347) parseHttpRequest:
HTTP Client REQUEST:
---------
GET
http://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-beta_current_i386.deb
HTTP/1.1
Host: dl-ssl.google.com
User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:49.0) Gecko/20100101
Firefox/49.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate
Cookie:
NID=88=109tS20j8Ec0EQb5HzuNnbwtsl4sK64aakVRn-2qOe91Zv4e3st9lfyik8qQe7d12J4xBDCmdKMwiXY98a2dj4mOitaP4AbJV6fD7o9YKTxE7MziEkNCJ45GiDszPM8wXca5cuYK_gE4QVrU52VqzSa1IzmHbh_7XKsvYuDCSsgIMZaC8d4Fp01vrAU8dHPXGopVpBIxgpHwAjPv8NvLFM3e4y-um5A8umQ-GCFmpaaLd1_1jyafkNLTj-9Ix4hfsw;
SID=1ANPj1-lw03bKfunZfrmk8ZsjEcTl5AiLgwzgtzki8MZ3JuvGyYgiP7LRJ05U1HQWbf76g.;
HSID=AUu5M-p2Rw1uDb2_0; APISID=ss4uEw9eIOgmsZXv/ARs9Vws4Es_o_sfVX
Connection: keep-alive
Upgrade-Insecure-Requests: 1


----------
2016/10/05 15:46:25.320 kid1| 85,2| client_side_request.cc(744)
clientAccessCheckDone: The request GET
http://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-beta_current_i386.deb
is ALLOWED; last ACL checked: CONNECT
2016/10/05 15:46:25.320 kid1| 85,2| client_side_request.cc(720)
clientAccessCheck2: No adapted_http_access configuration. default: ALLOW
2016/10/05 15:46:25.320 kid1| 85,2| client_side_request.cc(744)
clientAccessCheckDone: The request GET
http://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-beta_current_i386.deb
is ALLOWED; last ACL checked: CONNECT
2016/10/05 15:46:25.320 kid1| 17,2| FwdState.cc(133) FwdState: Forwarding
client request local=192.168.1.1:3128 remote=192.168.1.76:51236 FD 12
flags=1, url=
http://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-beta_current_i386.deb
2016/10/05 15:46:25.320 kid1| 44,2| peer_select.cc(258) peerSelectDnsPaths:
Find IP destination for:
http://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-beta_current_i386.deb'
via dl-ssl.google.com
2016/10/05 15:46:25.417 kid1| 44,2| peer_select.cc(280) peerSelectDnsPaths:
Found sources for '
http://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-beta_current_i386.deb
'
2016/10/05 15:46:25.417 kid1| 44,2| peer_select.cc(281) peerSelectDnsPaths:
  always_direct = ALLOWED
2016/10/05 15:46:25.417 kid1| 44,2| peer_select.cc(282) peerSelectDnsPaths:
   never_direct = DENIED
2016/10/05 15:46:25.417 kid1| 44,2| peer_select.cc(286) peerSelectDnsPaths:
         DIRECT = local=[::] remote=[2404:6800:4008:c02::be]:80 flags=1
2016/10/05 15:46:25.417 kid1| 44,2| peer_select.cc(286) peerSelectDnsPaths:
         DIRECT = local=0.0.0.0 remote=74.125.23.136:80 flags=1
2016/10/05 15:46:25.417 kid1| 44,2| peer_select.cc(286) peerSelectDnsPaths:
         DIRECT = local=0.0.0.0 remote=74.125.23.93:80 flags=1
2016/10/05 15:46:25.417 kid1| 44,2| peer_select.cc(286) peerSelectDnsPaths:
         DIRECT = local=0.0.0.0 remote=74.125.23.91:80 flags=1
2016/10/05 15:46:25.418 kid1| 44,2| peer_select.cc(286) peerSelectDnsPaths:
         DIRECT = local=0.0.0.0 remote=74.125.23.190:80 flags=1
2016/10/05 15:46:25.418 kid1| 44,2| peer_select.cc(295) peerSelectDnsPaths:
       timedout = 0
2016/10/05 15:46:25.418 kid1| 14,2| ipcache.cc(924) ipcacheMarkBadAddr:
ipcacheMarkBadAddr: dl-ssl.google.com [2404:6800:4008:c02::be]:80
2016/10/05 15:46:25.567 kid1| 11,2| http.cc(2203) sendRequest: HTTP Server
local=192.168.1.1:36674 remote=74.125.23.136:80 FD 13 flags=1
2016/10/05 15:46:25.567 kid1| 11,2| http.cc(2204) sendRequest: HTTP Server
REQUEST:
---------
GET /dl/linux/direct/mod-pagespeed-beta_current_i386.deb HTTP/1.1
User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:49.0) Gecko/20100101
Firefox/49.0
Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
Accept-Language: en-US,en;q=0.5
Accept-Encoding: gzip, deflate
Cookie:
NID=88=109tS20j8Ec0EQb5HzuNnbwtsl4sK64aakVRn-2qOe91Zv4e3st9lfyik8qQe7d12J4xBDCmdKMwiXY98a2dj4mOitaP4AbJV6fD7o9YKTxE7MziEkNCJ45GiDszPM8wXca5cuYK_gE4QVrU52VqzSa1IzmHbh_7XKsvYuDCSsgIMZaC8d4Fp01vrAU8dHPXGopVpBIxgpHwAjPv8NvLFM3e4y-um5A8umQ-GCFmpaaLd1_1jyafkNLTj-9Ix4hfsw;
SID=1ANPj1-lw03bKfunZfrmk8ZsjEcTl5AiLgwzgtzki8MZ3JuvGyYgiP7LRJ05U1HQWbf76g.;
HSID=AUu5M-p2Rw1uDb2_0; APISID=ss4uEw9eIOgmsZXv/ARs9Vws4Es_o_sfVX
Host: dl-ssl.google.com
Cache-Control: max-age=7776000
Connection: keep-alive


----------
2016/10/05 15:46:25.780 kid1| ctx: enter level  0: '
http://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-beta_current_i386.deb
'
2016/10/05 15:46:25.780 kid1| 11,2| http.cc(717) processReplyHeader: HTTP
Server local=192.168.1.1:36674 remote=74.125.23.136:80 FD 13 flags=1
2016/10/05 15:46:25.780 kid1| 11,2| http.cc(718) processReplyHeader: HTTP
Server REPLY:
---------
HTTP/1.1 200 OK
Accept-Ranges: bytes
Content-Length: 6662208
Content-Type: application/x-debian-package
Etag: "fa383"
Last-Modified: Thu, 15 Sep 2016 19:24:00 GMT
Server: downloads
Vary: *
X-Content-Type-Options: nosniff
X-Frame-Options: SAMEORIGIN
X-Xss-Protection: 1; mode=block
Date: Wed, 05 Oct 2016 10:16:25 GMT

!<arch>
debian-binary   1473872866  0     0     100644  4         `
2.0
control.tar.gz  1473872866  0     0     100644  7806      `
?
----------
2016/10/05 15:46:25.780 kid1| ctx: exit level  0
2016/10/05 15:46:25.780 kid1| 20,2| store.cc(949) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/10/05 15:46:25.780 kid1| 20,2| store.cc(949) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/10/05 15:46:25.781 kid1| 88,2| client_side_reply.cc(2005)
processReplyAccessResult: The reply for GET
http://dl-ssl.google.com/dl/linux/direct/mod-pagespeed-beta_current_i386.deb
is ALLOWED, because it matched all
2016/10/05 15:46:25.781 kid1| 11,2| client_side.cc(1392)
sendStartOfMessage: HTTP Client local=192.168.1.1:3128 remote=
192.168.1.76:51236 FD 12 flags=1
2016/10/05 15:46:25.781 kid1| 11,2| client_side.cc(1393)
sendStartOfMessage: HTTP Client REPLY:
---------
HTTP/1.1 200 OK
Accept-Ranges: bytes
Content-Length: 6662208
Content-Type: application/x-debian-package
ETag: "fa383"
Last-Modified: Thu, 15 Sep 2016 19:24:00 GMT
Server: downloads
Vary: *
X-Content-Type-Options: nosniff
X-Frame-Options: SAMEORIGIN
X-Xss-Protection: 1; mode=block
Date: Wed, 05 Oct 2016 10:16:25 GMT
Connection: keep-alive


----------
2016/10/05 15:46:25.781 kid1| 20,2| store.cc(949) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/10/05 15:46:25.781 kid1| 20,2| store.cc(949) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/10/05 15:46:25.781 kid1| 20,2| store.cc(949) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/10/05 15:46:25.782 kid1| 20,2| store.cc(949) checkCachable:
StoreEntry::checkCachable: NO: not cachable



On Tue, Oct 4, 2016 at 8:00 PM, Hardik Dangar <hardikdangar+squid at gmail.com>
wrote:

> Wow, i couldn't think about that. google might need tracking data that
> could be the reason they have blindly put vary * header. oh Irony, company
> which talks to all of us on how to deliver content is trying to do such
> thing.
>
> I have looked at your patch but how do i enable that ? do i need to write
> custom ACL ? i know i need to compile and reinstall after applying patch
> but what do i need to do exactly in squid.conf file as looking at your
> patch i am guessing i need to write archive acl or i am too naive to
> understand C code :)
>
> Also
>
> reply_header_replace is any good for this ?
>
>
> On Tue, Oct 4, 2016 at 7:47 PM, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
>
>> On 5/10/2016 2:34 a.m., Hardik Dangar wrote:
>> > Hey Amos,
>> >
>> > We have about 50 clients which downloads same google chrome update
>> every 2
>> > or 3 days means 2.4 gb. although response says vary but requested file
>> is
>> > same and all is downloaded via apt update.
>> >
>> > Is there any option just like ignore-no-store? I know i am asking for
>> too
>> > much but it seems very silly on google's part that they are sending very
>> > header at a place where they shouldn't as no matter how you access those
>> > url's you are only going to get those deb files.
>>
>>
>> Some things G does only make sense whan you ignore all the PR about
>> wanting to make the web more efficient and consider it's a company whose
>> income is derived by recording data about peoples habits and activities.
>> Caching can hide that info from them.
>>
>> >
>> > can i hack squid source code to ignore very header ?
>> >
>>
>> Google are explicitly saying the response changes. I suspect there is
>> something involving Google account data being embeded in some of the
>> downloads. For tracking, etc.
>>
>>
>> If you are wanting to test it I have added a patch to
>> <http://bugs.squid-cache.org/show_bug.cgi?id=4604> that should implement
>> archival of responses where the ACLs match. It is completely untested by
>> me beyond building, so YMMV.
>>
>> Amos
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161005/e0262913/attachment.htm>

From john.kj1984 at gmail.com  Wed Oct  5 11:07:04 2016
From: john.kj1984 at gmail.com (john jacob)
Date: Wed, 5 Oct 2016 16:37:04 +0530
Subject: [squid-users] Multiple auth schemes in a single Squid instance
Message-ID: <CAOoFbVc3ubyri8iO3_D+CHHc08wvOpnAG1MzPZasAdMmGwzY+Q@mail.gmail.com>

Hi All,

We have a requirement to use the same Squid instance for Basic and NTLM
authentication to serve various customer groups (may not be on different
network sections). The customer groups which are using Basic authentication
(for legacy reasons) should not receive NTLM scheme and the customer groups
which use NTLM should not receive Basic scheme. I couldn't find a way to
implement this using the existing Squid 4.x config options. So I am
thinking of introducing a new config parameter called "endpoints" like
below.

auth_param basic endpoints ipofBasic portofBasic # Default is "endpoints
all"

auth_param ntlm endpoints ipofNTLM portofNTLM # Default is "endpoints all"

acl ipofBasic  localip 192.168.4.2
acl portofBasic localport 3129 3139

acl ipofNTLM ipofNTLM  192.168.4.2
acl portofNTLMlocalport 3149 3159


The idea is ,if Squid recieves a request on an endpoint on which only basic
authentication is needed (ie 192.168.4.2:3129 and 192.168.4.2:3139), NTLM
will not be presented to the client/browser. Vice versa for NTLM. If no
endpoints is configured , then the existing behavior will be applied.

Do you think this is reasonable and is there are any obvious problems with
this?. If you find this useful, I am happy to contribute back when I finish
implementing this module (I haven't yet started developing).

Please let me know your thoughts.

Regards,
John
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161005/a1a002e2/attachment.htm>

From john.kj1984 at gmail.com  Wed Oct  5 11:09:52 2016
From: john.kj1984 at gmail.com (john jacob)
Date: Wed, 5 Oct 2016 16:39:52 +0530
Subject: [squid-users] Multiple auth schemes in a single Squid instance
Message-ID: <CAOoFbVdcGGvNkS0TEuabqkzwuQRU4=5x0BjhH2Jii2PXZwTREg@mail.gmail.com>

Hi All,

We have a requirement to use the same Squid instance for Basic and NTLM
authentication to serve various customer groups (may not be on different
network sections). The customer groups which are using Basic authentication
(for legacy reasons) should not receive NTLM scheme and the customer groups
which use NTLM should not receive Basic scheme. I couldn't find a way to
implement this using the existing Squid 4.x config options. So I am
thinking of introducing a new config parameter called "endpoints" like
below.

auth_param basic endpoints ipofBasic portofBasic # Default is "endpoints
all"

auth_param ntlm endpoints ipofNTLM portofNTLM # Default is "endpoints all"

acl ipofBasic  localip 192.168.4.2
acl portofBasic localport 3129 3139

acl ipofNTLM ipofNTLM  192.168.4.2
acl portofNTLMlocalport 3149 3159


The idea is ,if Squid recieves a request on an endpoint on which only basic
authentication is needed (ie 192.168.4.2:3129 and192.168.4.2:3139), NTLM
will not be presented to the client/browser. Vice versa for NTLM. If no
endpoints is configured , then the existing behavior will be applied.

Do you think this is reasonable and is there are any obvious problems with
this?. If you find this useful, I am happy to contribute back when I finish
implementing this module (I haven't yet started developing).

Please let me know your thoughts.

Regards,
John
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161005/f08d4da3/attachment.htm>

From amaury at tin.it  Wed Oct  5 12:28:41 2016
From: amaury at tin.it (amaury at tin.it)
Date: Wed, 5 Oct 2016 14:28:41 +0200 (CEST)
Subject: [squid-users] Bug: Missing MemObject::storeId
Message-ID: <15794d136b0.amaury@tin.it>

Hello
I'm using squid-3.5.21-20160908-r14081 and for the first time I 
have configuration squid-smp (4workers and cache_dir rock).
I haven't 
cache_peer.
In cache.log often I found (always on different kid id): 


2016/10/05 14:12:55 kid4| Bug: Missing MemObject::storeId value

2016/10/05 14:12:55 kid4| mem_hdr: 0x54941c0 nodes.start() 0x3b762d0

2016/10/05 14:12:55 kid4| mem_hdr: 0x54941c0 nodes.finish() 0x3b762d0

2016/10/05 14:12:55 kid4| MemObject->start_ping: 0.000000
2016/10/05 14:
12:55 kid4| MemObject->inmem_hi: 970
2016/10/05 14:12:55 kid4| 
MemObject->inmem_lo: 0
2016/10/05 14:12:55 kid4| MemObject->nclients: 0

2016/10/05 14:12:55 kid4| MemObject->reply: 0x3e5e8d0
2016/10/05 14:12:
55 kid4| MemObject->request: 0
2016/10/05 14:12:55 kid4| MemObject-
>logUri:
2016/10/05 14:12:55 kid4| MemObject->storeId:
2016/10/05 14:12:
55 kid4| Bug: Missing MemObject::storeId value
2016/10/05 14:12:55 
kid4| mem_hdr: 0x3199e50 nodes.start() 0x2905ac0
2016/10/05 14:12:55 
kid4| mem_hdr: 0x3199e50 nodes.finish() 0x2a047b0
2016/10/05 14:12:55 
kid4| MemObject->start_ping: 0.000000
2016/10/05 14:12:55 kid4| 
MemObject->inmem_hi: 15888
2016/10/05 14:12:55 kid4| MemObject-
>inmem_lo: 0
2016/10/05 14:12:55 kid4| MemObject->nclients: 0

2016/10/05 14:12:55 kid4| MemObject->reply: 0x6093e60
2016/10/05 14:12:
55 kid4| MemObject->request: 0
2016/10/05 14:12:55 kid4| MemObject-
>logUri:
2016/10/05 14:12:55 kid4| MemObject->storeId:

Is it a 
misconfiguration ?
Thank you



From squid3 at treenet.co.nz  Wed Oct  5 13:07:13 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 6 Oct 2016 02:07:13 +1300
Subject: [squid-users] Problem with Squid3 Caches
In-Reply-To: <7DE7A0D4-9C50-48EF-A297-9E65A7E45AC8@gmail.com>
References: <CD14793F-4F48-433E-9A1E-B2030E1D7F14@gmail.com>
 <201610032306.15880.Antony.Stone@squid.open.source.it>
 <B0508516-890C-4526-8848-78616839ABA5@gmail.com>
 <201610041745.20899.Antony.Stone@squid.open.source.it>
 <7DE7A0D4-9C50-48EF-A297-9E65A7E45AC8@gmail.com>
Message-ID: <9c5a8d4f-40b3-939c-b22a-b57181f8f0ff@treenet.co.nz>

On 5/10/2016 6:48 a.m., KR wrote:
> I uncommented that line and now I get
> 
> Initializing the Squid cache with the command squid3 -f /etc/squid/squid.conf -z ..
> 

Hmm. The 'squid3' package should have config files at /etc/squid3/*

The 'squid' package has config files at /etc/squid/*


> FATAL: Bungled /etc/squid/squid.conf line 3410: cache_dir rock /hdd1 ... min-size=100000

Is that an exact copy-paste of the output?
 Are the "..." characters really in your config file?

If yes, the problem is that somebody has mindlessly cut-n-pasted
incomplete example config line(s) into your squid.conf.

If no, then the problem is that you are hiding the broken piece of
config from us.

Either way you have something to fix.


> Squid Cache (Version 3.5.12): Terminated abnormally.

That is the version number from the Ubuntu 16.10 or later 'squid' package.

It should be started with the command 'squid', not 'squid3' as indicated
by the above lines.

Amos



From squid3 at treenet.co.nz  Wed Oct  5 13:23:23 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 6 Oct 2016 02:23:23 +1300
Subject: [squid-users] Squid - AD kerberos auth and Linux Server proxy
 access not working
In-Reply-To: <OF8D12BD2C.F821F41E-ON80258042.0062D619-80258042.0062EE60@tcs.com>
References: <OF8D12BD2C.F821F41E-ON80258042.0062D619-80258042.0062EE60@tcs.com>
Message-ID: <cc644993-3880-ece2-1369-942daa9b03c6@treenet.co.nz>

On 5/10/2016 7:00 a.m., Nilesh Gavali wrote:
> Hi Amos;
> Ok, we can discussed the issue in Two part  1. For Windows AD 
> Authentication & SSO and 2. Linux server unable to access via squid proxy.
> 
> For First point-
> Requirement to have SSO for accessing internet via squid proxy and based 
> on user's AD group membership allow access to specific sites only. I 
> believe current configuration of squid is working as expected.
> 
> For Second point -
> Point I would like to highlight here is, the Linux server IWCCP01 is not 
> part of domain at all. Hence the below error as squid configured for 
> AD_auth. So how can we allow Linux server or non domain machine to access 
> specific sites?
> 
>> Error 407 is "proxy auth required", so the proxy is expecting 
> authentication 
>> for some reason.
> ====================================
>  > Can you confirm that the hostname vseries-test.bottomline.com is 
> contained in 
>> your site file /etc/squid/sitelist/dbs_allowed_site ?
> 
> YES, we have entry as .bottomline.com , which work fine when access via 
> windows machine having proxy enabled for that user.
> ==============================
>> Can you temporarily change the line "http_access allow IWCCP01 
> allowedsite" to 
>> "http_access allow IWCCP01" and see whether the machine then gets 
> access?
> 
> I made the changes as suggested but still it is giving same Error 407.

Meaning that is the ACL which is broken.


> ========================================
> If that works, please list the output of the command:
>   grep "bottomline.com" /etc/squid/sitelist/dbs_allowed_site
> 
> o/p of above command as below -
> 
> [root at Proxy02 ~]# grep "bottomline.com" 
> /etc/squid/sitelist/dbs_allowed_site
> .bottomline.com
> [root at Proxy02 ~]#

Okay great. Your allowedsite has a correct entry to match the test request.


Since IWCCP01 contains exactly one IP address for the server

> acl IWCCP01 src 10.xx.15.103

it means your server is not using that IP address when it contacts Squid.

BUT that IP is what gots logged as the client/src IP.

> 1475518342.279      0 10.xx.15.103 TCP_DENIED/407 3589 CONNECT
vseries-test.bottomline.com:443 - NONE/- text/html

Strange. Unless:

* those 'xx' are different numbers, or

* the line was logged by another Squid process (with different config), or

* the config file you think is being used actually is not.


I notice that this config tells your Squid to listen on port 8080 and
pass all its traffic through a peer at 10.xx.xx.108 which also listens
on port 8080.
Is that log being produced by that other peer?

Is there anything, any non-# lines at all, in your config besides what
your first post contained? even if you dont think its relevant.

Amos



From squid3 at treenet.co.nz  Wed Oct  5 13:45:49 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 6 Oct 2016 02:45:49 +1300
Subject: [squid-users] Caching http google deb files
In-Reply-To: <CA+sSnVZ2ErFD+LeLVH3KOjJ_0PuqGyWfRHA23zY8yJQs3kP+Rw@mail.gmail.com>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
 <CA+sSnVZ2ErFD+LeLVH3KOjJ_0PuqGyWfRHA23zY8yJQs3kP+Rw@mail.gmail.com>
Message-ID: <89f9840b-7ec7-2f0b-a81c-5376c344878e@treenet.co.nz>

On 5/10/2016 11:27 p.m., Hardik Dangar wrote:
> Hey Amos,
> 
> I have implemented your patch at
> 
> and added following to my squid.conf
> archive_mode allow all
> 
> and my refresh pattern is,
> refresh_pattern dl-ssl.google.com/.*\.(deb|zip|tar|rpm) 129600 100% 129600
> ignore-reload ignore-no-store override-expire override-lastmod ignor$
> 
> but i am still not able to cache it, can you tell from below output what
> would be the problem ? Do i need to configure anything extra ?

Sorry. I was a bit tired when I wrote earlier an steered you wrong.

The archive patch will ony help for things which can be cached in the
first place. Vary:* is not part of that set so this wont help you at all.

That leaves you with the option of using a multi-level cache hierarchy
where the frontend cache removes the header (causing the backend cache /
client to try and store it.

Or removing all of Squids Vary header support. I really dont recommend
either approach.

Amos



From squid3 at treenet.co.nz  Wed Oct  5 14:05:59 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 6 Oct 2016 03:05:59 +1300
Subject: [squid-users] Multiple auth schemes in a single Squid instance
In-Reply-To: <CAOoFbVdcGGvNkS0TEuabqkzwuQRU4=5x0BjhH2Jii2PXZwTREg@mail.gmail.com>
References: <CAOoFbVdcGGvNkS0TEuabqkzwuQRU4=5x0BjhH2Jii2PXZwTREg@mail.gmail.com>
Message-ID: <8fa245d1-ed36-421c-7bb9-f95975d14d44@treenet.co.nz>

On 6/10/2016 12:09 a.m., john jacob wrote:
> Hi All,
> 
> We have a requirement to use the same Squid instance for Basic and NTLM
> authentication to serve various customer groups (may not be on different
> network sections). The customer groups which are using Basic authentication
> (for legacy reasons) should not receive NTLM scheme and the customer groups
> which use NTLM should not receive Basic scheme.

You seem to be implying that Basic auth is somehow worse than NTLM. In
fact NTLM is the least secure of the two by a thin line. Both are almost
equally bad to use anytime in the past decade.

You should really be considering both those to be nasty legacy and
moving on to Negotiate/Kerberos as much as possible.


> I couldn't find a way to
> implement this using the existing Squid 4.x config options. So I am
> thinking of introducing a new config parameter called "endpoints" like
> below.
> 
> auth_param basic endpoints ipofBasic portofBasic # Default is "endpoints
> all"
> 
> auth_param ntlm endpoints ipofNTLM portofNTLM # Default is "endpoints all"
> 
> acl ipofBasic  localip 192.168.4.2
> acl portofBasic localport 3129 3139
> 
> acl ipofNTLM ipofNTLM  192.168.4.2
> acl portofNTLMlocalport 3149 3159
> 
> 
> The idea is ,if Squid recieves a request on an endpoint on which only basic
> authentication is needed (ie 192.168.4.2:3129 and192.168.4.2:3139), NTLM
> will not be presented to the client/browser. Vice versa for NTLM. If no
> endpoints is configured , then the existing behavior will be applied.
> 
> Do you think this is reasonable and is there are any obvious problems with
> this?. If you find this useful, I am happy to contribute back when I finish
> implementing this module (I haven't yet started developing).


The HTTP framework is negotiated thusly:
 the proxy offers what it supports,
 the client tries the most secure credential type it has access to,
 the proxy says whether that is acceptible or to try again.
 .. repeat as necessary until either a success or no more credentials
are known - in which case ask the user with popup(s).

When that framework is used properly the clients with NTLM will try that
and the ones without will try Basic.


Squid-3.5 and later have the "auth_param ... key_extras ..." option that
can take extra parameters for the auth helper to use when it decides if
the credentials are valid.


I suggest you try making your self a script that takes the client IP as
one of those extra parameters; returning ERR if the IP is not allowed to
use the type of auth or relays the lookup on to your real auth helper if
it is allowed.

Amos



From rousskov at measurement-factory.com  Wed Oct  5 14:19:52 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 5 Oct 2016 08:19:52 -0600
Subject: [squid-users] Bug: Missing MemObject::storeId
In-Reply-To: <15794d136b0.amaury@tin.it>
References: <15794d136b0.amaury@tin.it>
Message-ID: <010b9e54-d853-6165-e00f-0266a3f71677@measurement-factory.com>

On 10/05/2016 06:28 AM, amaury at tin.it wrote:

> I'm using squid-3.5.21-20160908-r14081 and for the first time I 
> have configuration squid-smp (4workers and cache_dir rock).

> 2016/10/05 14:12:55 kid4| Bug: Missing MemObject::storeId value


> Is it a misconfiguration ?

It is a known bug: http://bugs.squid-cache.org/show_bug.cgi?id=4527

I recommend updating that bug report with your configuration details,
such as the fact that you are not using ICP (AFAICT). The bug also has
some suggestions for triaging this problem further.

The existence of that bug does not imply that your configuration is
correct, but this bug is not a [known] sign of a misconfiguration.

Alex.



From hardikdangar+squid at gmail.com  Wed Oct  5 14:33:47 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Wed, 5 Oct 2016 20:03:47 +0530
Subject: [squid-users] Caching http google deb files
In-Reply-To: <89f9840b-7ec7-2f0b-a81c-5376c344878e@treenet.co.nz>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
 <CA+sSnVZ2ErFD+LeLVH3KOjJ_0PuqGyWfRHA23zY8yJQs3kP+Rw@mail.gmail.com>
 <89f9840b-7ec7-2f0b-a81c-5376c344878e@treenet.co.nz>
Message-ID: <CA+sSnVYCy5E00jKK5cPZm3q+eBX8Fx=Mjs_iu4Xs0oebxcte9Q@mail.gmail.com>

Hey Amos,

oh, i actually built archive mode squid by getting help at here,
http://bugs.squid-cache.org/show_bug.cgi?id=4604

I was thinking if we have option vary_mode just like archive mode to set it
for particular domain like,

acl dlsslgoogle srcdomain dl-ssl.google.com
vary_mode allow dlsslgoogle
Above could work one of the following way,

1) We replace Vary header for srcdomain to some suitable option so request
can be cached
2) This will remove vary header totally for the above domain.
3) above will use matching squid refresh pattern for srcdomain and only
cache requests for
particular type of file given in refresh_pattern

What do you think would be easiar ? and how do i work on squid source to do
above? any hint is appreciated.


One more thing can you tell me if we are already violating http via options
like nocache, ignore-no-store ignore-private ignore-reload, why can't we do
the same for Vary header ?

It seems servers that are notorious have Vary * header as well as at times
(github) no Last modified header and these are the biggest bandwidth eaters.



Thanks.
Hardik
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161005/df333a18/attachment.htm>

From eliezer at ngtech.co.il  Wed Oct  5 14:42:59 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 5 Oct 2016 17:42:59 +0300
Subject: [squid-users] --enable-openssl-crtd -- not
	building	openssl-crtd? (3.5.21)
In-Reply-To: <57F0B07D.6000500@tlinx.org>
References: <57E9D3B5.6050405@tlinx.org>
 <598baad3-64d1-b873-b266-55ab5d96fb0c@treenet.co.nz>
 <57E9EFBC.5040407@tlinx.org> <056b01d21aa3$22833020$67899060$@ngtech.co.il>
 <57F0B07D.6000500@tlinx.org>
Message-ID: <0a3f01d21f16$c4833380$4d899a80$@ngtech.co.il>

First goes first is to restart the client machine to verify that the certificate is installed.
If you want a list of "banned" ssl sites you will need to do some research on your clients needs...
Nobody can do your work for you without knowing your "thing".
The overall slow down is from both sites that are probably trying to encrypt but it's still not something you cannot do without any system policy.
If you have a regulation policy on encrypted traffic you will be able to force your clients first and allow later.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Linda W [mailto:squid-user at tlinx.org] 
Sent: Sunday, October 2, 2016 10:00 AM
To: Eliezer Croitoru
Cc: squid-users at lists.squid-cache.org
Subject: Re: --enable-openssl-crtd -- not building openssl-crtd? (3.5.21)

Eliezer Croitoru wrote:
> Hey Linda,
> 
> If you need some help later we are here for any advice.
> Can you say on what OS are you compiling the software?
---
	opensuse 13.2

I have to see what else is needed (if anything).  I already
imported the squid-cert into my browser, but not sure if it
is bumping anything or not.

What I'd like to do is create a list of ssl-"banned" connections
where it can store objects from those sessions into the cache under
plaintext names so for those sites I can regain squid-caching that
is shareable between different sessions.

Right now, due to the ssl-junkies (those who want everything
encrypted because it hides their streams from user eyes), 
it seems that many objects that used to be cached, now, 
can't be cached because they are part of a 
TUNNEL where individual objects are no longer discernible.

I've noticed an overall slowdown of websites due to the 
slowdown from encrypting & decrypting as well as not being
able to cache commonly used items.










From rousskov at measurement-factory.com  Wed Oct  5 15:26:10 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 5 Oct 2016 09:26:10 -0600
Subject: [squid-users] Caching http google deb files
In-Reply-To: <CA+sSnVYCy5E00jKK5cPZm3q+eBX8Fx=Mjs_iu4Xs0oebxcte9Q@mail.gmail.com>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
 <CA+sSnVZ2ErFD+LeLVH3KOjJ_0PuqGyWfRHA23zY8yJQs3kP+Rw@mail.gmail.com>
 <89f9840b-7ec7-2f0b-a81c-5376c344878e@treenet.co.nz>
 <CA+sSnVYCy5E00jKK5cPZm3q+eBX8Fx=Mjs_iu4Xs0oebxcte9Q@mail.gmail.com>
Message-ID: <1ba79370-ff21-0e52-a5dc-89919c1171b4@measurement-factory.com>

On 10/05/2016 08:33 AM, Hardik Dangar wrote:

> One more thing can you tell me if we are already violating http via
> options like nocache, ignore-no-store ignore-private ignore-reload, why
> can't we do the same for Vary header ?

We can, but ignoring Vary requires more/different work than adding
another refresh_pattern option. Vary is not a refresh mechanism so
different code areas need to be modified to ignore (but still forward!)
Vary.

Also, a good implementation would not just ignore Vary (because it is
likely to break things on the client side) but support _replacing_ it
with a less restrictive one (as far as Squid internal interpretation is
concerned) while still forwarding the original value. One could argue
that only such reinterpreting implementation should be officially accepted.

If you want to work on that, search Squid sources for httpMakeVaryMark
to find starting points. The reply_header_replace code may also be
useful as far as reinterpret_vary configuration is concerned. Posting a
detailed proposal and securing "acceptance in principle" on squid-dev
before starting this potentially controversial work is a good idea if
you care about official acceptance.

Alex.



From jetsystemservices at gmail.com  Wed Oct  5 15:27:58 2016
From: jetsystemservices at gmail.com (Jose Torres-Berrocal)
Date: Wed, 5 Oct 2016 11:27:58 -0400
Subject: [squid-users] Whitelist domain ignored?
In-Reply-To: <4d4e7006-164a-6b79-c7e1-df5100ceb29f@measurement-factory.com>
References: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>
 <CADSSinNYT4GX5+4YhmF62GvGL2remrHm27Av8kr_V-xgBY3rEg@mail.gmail.com>
 <4d4e7006-164a-6b79-c7e1-df5100ceb29f@measurement-factory.com>
Message-ID: <CABU5kW6gGXogmg1CSWz+8mWmMTjHr4kQho209zmua0=N-Lzu1A@mail.gmail.com>

> /var/squid/acl/whitelist.acl:

[snip]
>
> .assertus.com
> .neodecksoftware.com


your whitelist for this domain says that it has "something" followed
by that domain name...

>
>
> .office.net

1. Each domain is on separate line, why is consider the next line part
of the same pattern?

in the end, your regular expression doesn't match.
"." means "any single character". you should replace that line with
something like this:
^neodecksoftware\.com

2. Then I should change each domain line to resemble your suggested pattern?

^assertus\.com
^neodecksoftware\.com
^office\.net
Jose E Torres
939-777-4030
JET System Services


On Tue, Oct 4, 2016 at 8:24 PM, Alex Rousskov
<rousskov at measurement-factory.com> wrote:
> On 10/04/2016 05:16 PM, Jok Thuau wrote:
>> On Tue, Oct 4, 2016 at 1:41 PM, Jose Torres-Berrocal wrote:
>
>>>     I have some clients that use a program that tries to connect to:
>>>     https://neodecksoftware.com/NeoMedOnline/NeoMedOnlineService.svc
>
>
>>>     /var/squid/acl/whitelist.acl:
>
>>>     .assertus.com
>>>     .neodecksoftware.com
>
>
>> your whitelist for this domain says that it has "something" followed by
>> that domain name...
>
> Good catch! Actually, the problem is even worse. The dstdom_regex will
> match even notneodecksoftwarexcom.org IIRC.
>
>
>>>     acl whitelist dstdom_regex -i "/var/squid/acl/whitelist.acl"
>
> Perhaps the configuration author meant to say dstdomain instead of
> dstdom_regex? Are there any intentional regular expressions in
> /var/squid/acl/whitelist.acl?
>
> Alex.
>


From jok at spikes.com  Wed Oct  5 16:19:22 2016
From: jok at spikes.com (Jok Thuau)
Date: Wed, 5 Oct 2016 09:19:22 -0700
Subject: [squid-users] Caching http google deb files
In-Reply-To: <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
Message-ID: <CADSSinNbzY90jUyYOLPFcqc7a8WQFb4qFdbS7mc0knzcfZDJLw@mail.gmail.com>

This is sort of off-topic, but have you considered using a deb repo
mirroring software?
(it would mean that you need to update your clients to point to that rather
than google, but that's not really difficult).
software like aptly (aptly.info) are really good about this (though a
little hard to get going in the first place). or a deb-caching proxy
(apt-cacher-ng? squid-deb-proxy?)


On Tue, Oct 4, 2016 at 7:30 AM, Hardik Dangar <hardikdangar+squid at gmail.com>
wrote:

> Wow, i couldn't think about that. google might need tracking data that
> could be the reason they have blindly put vary * header. oh Irony, company
> which talks to all of us on how to deliver content is trying to do such
> thing.
>
> I have looked at your patch but how do i enable that ? do i need to write
> custom ACL ? i know i need to compile and reinstall after applying patch
> but what do i need to do exactly in squid.conf file as looking at your
> patch i am guessing i need to write archive acl or i am too naive to
> understand C code :)
>
> Also
>
> reply_header_replace is any good for this ?
>
>
> On Tue, Oct 4, 2016 at 7:47 PM, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
>
>> On 5/10/2016 2:34 a.m., Hardik Dangar wrote:
>> > Hey Amos,
>> >
>> > We have about 50 clients which downloads same google chrome update
>> every 2
>> > or 3 days means 2.4 gb. although response says vary but requested file
>> is
>> > same and all is downloaded via apt update.
>> >
>> > Is there any option just like ignore-no-store? I know i am asking for
>> too
>> > much but it seems very silly on google's part that they are sending very
>> > header at a place where they shouldn't as no matter how you access those
>> > url's you are only going to get those deb files.
>>
>>
>> Some things G does only make sense whan you ignore all the PR about
>> wanting to make the web more efficient and consider it's a company whose
>> income is derived by recording data about peoples habits and activities.
>> Caching can hide that info from them.
>>
>> >
>> > can i hack squid source code to ignore very header ?
>> >
>>
>> Google are explicitly saying the response changes. I suspect there is
>> something involving Google account data being embeded in some of the
>> downloads. For tracking, etc.
>>
>>
>> If you are wanting to test it I have added a patch to
>> <http://bugs.squid-cache.org/show_bug.cgi?id=4604> that should implement
>> archival of responses where the ACLs match. It is completely untested by
>> me beyond building, so YMMV.
>>
>> Amos
>>
>>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161005/7a9f900a/attachment.htm>

From gaardiolor at gmail.com  Wed Oct  5 16:30:31 2016
From: gaardiolor at gmail.com (Marc)
Date: Wed, 5 Oct 2016 18:30:31 +0200
Subject: [squid-users] handshake problems with stare and bump
In-Reply-To: <838791f0-8b15-d3f5-0dc4-4c3d87def405@gmail.com>
References: <CAPxJK5DSeaA1JzD7CNhAmR2ZQXF87VrEtS9w+Ojvw1q4EhO=Ww@mail.gmail.com>
 <838791f0-8b15-d3f5-0dc4-4c3d87def405@gmail.com>
Message-ID: <CAPxJK5Ca9cyqu7dG=TH5tf-dSvj3cK8x1VQu+Q2DX25QOG9hEA@mail.gmail.com>

Hi,

Thanks for the replies. I've figured out more details. First, my
assumption that sslproxy_cipher was ignored in my setup was incorrect.
I confused it with what I've read about sslproxy_options on
http://bazaar.launchpad.net/~yadi/squid/warnings/revision/13928 .
Thanks Yuri for making me come to that conclusion. So I've put in
'sslproxy_cipher ALL' (just for troubleshooting purposes..). After
that, previously mentioned test 1 works on the linux client, however,
the iphone app still does not. So I went on and did more tests.

First, the iphone uses more then one cipher. I'll start with curl,
using TLS1.0 like the app.

3) curl --insecure --tlsv1.0 https://www.google.com
SQUID_ERR_SSL_HANDSHAKE. So with the default ciphers curl using tls
1.0 also breaks.

4) curl --insecure --tlsv1.0 --ciphers rsa_3des_sha https://www.google.com
Works. So using one cipher 'fixes' it.. just like we saw using openssl
s_client. Back to openssl s_client, default ciphers.

5) echo -e "GET / HTTP/1.1\nHost: www.google.com\n\n" | openssl
s_client -quiet -connect www.google.com:443 -tls1
SQUID_ERR_SSL_HANDSHAKE. Also here, using more ciphers generates an error.

6) echo -e "GET / HTTP/1.1\nHost: www.google.com\n\n" | openssl
s_client -quiet -connect www.google.com:443 -tls1_1
SQUID_ERR_SSL_HANDSHAKE. TLS 1.1 does not help.

7) echo -e "GET / HTTP/1.1\nHost: www.google.com\n\n" | openssl
s_client -quiet -connect www.google.com:443 -tls1_2
This works! When using TLS 1.2, we do not have this problem. Note that
compared to the previous 2 tests we have an extra TLS security
extension in the Client Hello, signature_algorithms. Now more tests
with TLS 1.0.

8) Firefox with TLS 1.0 (security.tls.version.max = 1).
Works. But.. Firefox is also using multiple ciphers. Hmm. Firefox also
uses a whole bunch of TLS Extensions with TLS 1.0. Back to openssl and
focus on extensions.

9) echo -e "GET / HTTP/1.1\nHost: www.google.com\n\n" | openssl
s_client -quiet -connect www.google.com:443 -tls1 -servername
www.google.com
SQUID_ERR_SSL_HANDSHAKE. Adding the server_name extension doesn't
help. Now let's try to add other TLS extensions. Since openssl didn't
want to play along I started with a fake one, 33554.

10) echo -e "GET / HTTP/1.1\nHost: www.google.com\n\n" | openssl
s_client -quiet -connect www.google.com:443 -tls1 -servername
www.google.com -serverinfo 33554
This works! Removing SNI, keeping the fake extension:

11) echo -e "GET / HTTP/1.1\nHost: www.google.com\n\n" | openssl
s_client -quiet -connect www.google.com:443 -tls1 -serverinfo 33554
Also works. Adding other extensions instead of the fake one also works.

So yeah.. I'm still confused.
- If TLS v1.0 or TLS v1.1, and more then one cipher, and not some
seemingly random extension then error. TLS v1.2 seems to work, maybe
just because the extra extension signature_algorithms, no idea.
- Squid forwards ciphers in the Client Hello to the webserver, except
for some CHACHA20 ones that are filtered out. Squid should make it's
own decision though when using stare right ? Squid does upgrade the
TLS version.

Should I report 2 bugs and/or attach debug logging ? I'll try test
with squid4 later this week. It doesn't want to compile on FC24 for
some reason.. while my gcc has c11 support. Have to dive into it..
unless someone has tips.

#######
# /usr/bin/g++ -DHAVE_CONFIG_H -I../.. -I../../include -I../../lib
-I../../src -I../../include -I../../libltdl -Wall -Wpointer-arith
-Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -Werror
-Wno-deprecated-register -pipe -D_REENTRANT -g -O2 -march=native -MT
Handshake.lo -MD -MP -MF .deps/Handshake.Tpo -c Handshake.cc -o
Handshake.o
Handshake.cc: In member function ?void
Security::HandshakeParser::parseServerCertificates(const SBuf&)?:
Handshake.cc:560:31: error: ?cert? may be used uninitialized in this
function [-Werror=maybe-uninitialized]
         Security::CertPointer cert;
                               ^~~~
At global scope:
cc1plus: error: unrecognized command line option
?-Wno-deprecated-register? [-Werror]
cc1plus: all warnings being treated as errors

# g++ --version
g++ (GCC) 6.2.1 20160916 (Red Hat 6.2.1-2)
Copyright (C) 2016 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
# gcc -v
Using built-in specs.
COLLECT_GCC=gcc
COLLECT_LTO_WRAPPER=/usr/libexec/gcc/x86_64-redhat-linux/6.2.1/lto-wrapper
Target: x86_64-redhat-linux
Configured with: ../configure --enable-bootstrap
--enable-languages=c,c++,objc,obj-c++,fortran,ada,go,lto --prefix=/usr
--mandir=/usr/share/man --infodir=/usr/share/info
--with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-shared
--enable-threads=posix --enable-checking=release --enable-multilib
--with-system-zlib --enable-__cxa_atexit
--disable-libunwind-exceptions --enable-gnu-unique-object
--enable-linker-build-id --with-linker-hash-style=gnu --enable-plugin
--enable-initfini-array --disable-libgcj --with-isl --enable-libmpx
--enable-gnu-indirect-function --with-tune=generic --with-arch_32=i686
--build=x86_64-redhat-linux
Thread model: posix
gcc version 6.2.1 20160916 (Red Hat 6.2.1-2) (GCC)

#######

Regards,

Marc


From nilesh.gavali at tcs.com  Wed Oct  5 16:31:23 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Wed, 5 Oct 2016 17:31:23 +0100
Subject: [squid-users] Squid - AD kerberos auth and Linux Server proxy
	access not working
Message-ID: <OF7AB42EBD.3C316EA5-ON80258043.0059EE52-80258043.005AC388@tcs.com>

Hi Amos;
To answer your query-

* those 'xx' are different numbers, or

* the line was logged by another Squid process (with different config), or

* the config file you think is being used actually is not.

<<NILESH>> xx is just used to hide the ip subnet over mail. Also ip is 
same it didn't change.

=======================================================

I notice that this config tells your Squid to listen on port 8080 and
pass all its traffic through a peer at 10.xx.xx.108 which also listens
on port 8080.
Is that log being produced by that other peer?

<<NILESH>> we have proxysetup as EndUser PC >> Linux Proxy >> Windows 
Proxy >> Internet gateway.
Log which I captured are from Linux proxy server. 
==============================================
Is there anything, any non-# lines at all, in your config besides what
your first post contained? even if you dont think its relevant.

<<NILESH>> here is the compete squid.conf for your reference-

#
# Recommended minimum configuration:
####  AD SSO Integration  #####
#auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -d -s 
GSS_C_NO_NAME
auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
HTTP/proxy02.CUST.IN at CUST.IN
auth_param negotiate children 20
auth_param negotiate keep_alive on

acl ad_auth proxy_auth REQUIRED

####  AD Group membership  ####


external_acl_type AD_Group ttl=300 negative_ttl=0 children=10 %LOGIN 
/usr/lib64/squid/squid_ldap_group -P -R -b "DC=CUST,DC=IN" -D svcproxy -W 
/etc/squid/pswd/pswd -f 
"(&(objectclass=person)(userPrincipalName=%v)(memberof=cn=%a,ou=InternetAccess,ou=Groups,dc=cust,dc=in))" 
-h CUST.IN -s sub -v 3

acl AVWSUS external AD_Group lgOnlineUpdate
acl windowsupdate dstdomain "/etc/squid/sitelist/infra_update_site"

acl custUSER external AD_Group lgInternetAccess_custUsers
acl custallowedsite dstdomain "/etc/squid/sitelist/cust_allowed_site"

#acl SHAVLIK external AD_Group lgShavlikUpdate
acl shavlikupdate dstdomain "/etc/squid/sitelist/shavlik_update_site"


acl manager proto cache_object
acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl AVSRVR src 10.50.2.107      # Cloud SEPM Servr
acl SHAVLIK_SRVR src 10.50.2.112     # Shavlik Server(NTLM Only Access)
acl IWCCP01 src 10.55.15.103   # Application access to Worldpay/bottomline 
Payment test site.
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
machines
#
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

# Recommended minimum Access Permission configuration:
#
# Only allow cachemgr access from localhost
http_access allow manager localhost
http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed

#http_access allow test shavlikupdate
http_access allow SHAVLIK_SRVR shavlikupdate
http_access allow AVSRVR windowsupdate
http_access allow AVWSUS windowsupdate
http_access allow IWCCP01
#http_access allow IWCCP01 custallowedsite
http_access allow custUSER custallowedsite
http_access allow ad_auth
# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 8080
never_direct allow all

cache_peer 10.50.2.108 parent 8080 0 default
dns_nameservers 10.50.2.108

# We recommend you to use at least the following line.
#hierarchy_stoplist cgi-bin ?

# Uncomment and adjust the following to add a disk cache directory.

cache_dir ufs /var/spool/squid 10240 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

# Log forwarding to SysLog
#access_log syslog:local1.info ####Sachin P.####
#access_log syslog:local1.info squid
access_log /var/log/squid/access.log

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320

=============================================================

Date: Thu, 6 Oct 2016 02:23:23 +1300
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid - AD kerberos auth and Linux Server
                 proxy access not working
Message-ID: <cc644993-3880-ece2-1369-942daa9b03c6 at treenet.co.nz>
Content-Type: text/plain; charset=utf-8

On 5/10/2016 7:00 a.m., Nilesh Gavali wrote:
> Hi Amos;
> Ok, we can discussed the issue in Two part  1. For Windows AD 
> Authentication & SSO and 2. Linux server unable to access via squid 
proxy.
> 
> For First point-
> Requirement to have SSO for accessing internet via squid proxy and based 

> on user's AD group membership allow access to specific sites only. I 
> believe current configuration of squid is working as expected.
> 
> For Second point -
> Point I would like to highlight here is, the Linux server IWCCP01 is not 

> part of domain at all. Hence the below error as squid configured for 
> AD_auth. So how can we allow Linux server or non domain machine to 
access 
> specific sites?
> 
>> Error 407 is "proxy auth required", so the proxy is expecting 
> authentication 
>> for some reason.
> ====================================
>  > Can you confirm that the hostname vseries-test.bottomline.com is 
> contained in 
>> your site file /etc/squid/sitelist/dbs_allowed_site ?
> 
> YES, we have entry as .bottomline.com , which work fine when access via 
> windows machine having proxy enabled for that user.
> ==============================
>> Can you temporarily change the line "http_access allow IWCCP01 
> allowedsite" to 
>> "http_access allow IWCCP01" and see whether the machine then gets 
> access?
> 
> I made the changes as suggested but still it is giving same Error 407.

Meaning that is the ACL which is broken.


> ========================================
> If that works, please list the output of the command:
>   grep "bottomline.com" /etc/squid/sitelist/dbs_allowed_site
> 
> o/p of above command as below -
> 
> [root at Proxy02 ~]# grep "bottomline.com" 
> /etc/squid/sitelist/dbs_allowed_site
> .bottomline.com
> [root at Proxy02 ~]#

Okay great. Your allowedsite has a correct entry to match the test 
request.


Since IWCCP01 contains exactly one IP address for the server

> acl IWCCP01 src 10.xx.15.103

it means your server is not using that IP address when it contacts Squid.

BUT that IP is what gots logged as the client/src IP.

> 1475518342.279      0 10.xx.15.103 TCP_DENIED/407 3589 CONNECT
vseries-test.bottomline.com:443 - NONE/- text/html

Strange. Unless:

* those 'xx' are different numbers, or

* the line was logged by another Squid process (with different config), or

* the config file you think is being used actually is not.


I notice that this config tells your Squid to listen on port 8080 and
pass all its traffic through a peer at 10.xx.xx.108 which also listens
on port 8080.
Is that log being produced by that other peer?

Is there anything, any non-# lines at all, in your config besides what
your first post contained? even if you dont think its relevant.

Amos



------------------------------

Message: 4
Date: Thu, 6 Oct 2016 02:45:49 +1300
From: Amos Jeffries <squid3 at treenet.co.nz>
To: Hardik Dangar <hardikdangar+squid at gmail.com>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Caching http google deb files
Message-ID: <89f9840b-7ec7-2f0b-a81c-5376c344878e at treenet.co.nz>
Content-Type: text/plain; charset=utf-8

On 5/10/2016 11:27 p.m., Hardik Dangar wrote:
> Hey Amos,
> 
> I have implemented your patch at
> 
> and added following to my squid.conf
> archive_mode allow all
> 
> and my refresh pattern is,
> refresh_pattern dl-ssl.google.com/.*\.(deb|zip|tar|rpm) 129600 100% 
129600
> ignore-reload ignore-no-store override-expire override-lastmod ignor$
> 
> but i am still not able to cache it, can you tell from below output what
> would be the problem ? Do i need to configure anything extra ?

Sorry. I was a bit tired when I wrote earlier an steered you wrong.

The archive patch will ony help for things which can be cached in the
first place. Vary:* is not part of that set so this wont help you at all.

That leaves you with the option of using a multi-level cache hierarchy
where the frontend cache removes the header (causing the backend cache /
client to try and store it.

Or removing all of Squids Vary header support. I really dont recommend
either approach.

Amos



------------------------------

Message: 5
Date: Thu, 6 Oct 2016 03:05:59 +1300
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Multiple auth schemes in a single Squid
                 instance
Message-ID: <8fa245d1-ed36-421c-7bb9-f95975d14d44 at treenet.co.nz>
Content-Type: text/plain; charset=utf-8

On 6/10/2016 12:09 a.m., john jacob wrote:
> Hi All,
> 
> We have a requirement to use the same Squid instance for Basic and NTLM
> authentication to serve various customer groups (may not be on different
> network sections). The customer groups which are using Basic 
authentication
> (for legacy reasons) should not receive NTLM scheme and the customer 
groups
> which use NTLM should not receive Basic scheme.

You seem to be implying that Basic auth is somehow worse than NTLM. In
fact NTLM is the least secure of the two by a thin line. Both are almost
equally bad to use anytime in the past decade.

You should really be considering both those to be nasty legacy and
moving on to Negotiate/Kerberos as much as possible.


> I couldn't find a way to
> implement this using the existing Squid 4.x config options. So I am
> thinking of introducing a new config parameter called "endpoints" like
> below.
> 
> auth_param basic endpoints ipofBasic portofBasic # Default is "endpoints
> all"
> 
> auth_param ntlm endpoints ipofNTLM portofNTLM # Default is "endpoints 
all"
> 
> acl ipofBasic  localip 192.168.4.2
> acl portofBasic localport 3129 3139
> 
> acl ipofNTLM ipofNTLM  192.168.4.2
> acl portofNTLMlocalport 3149 3159
> 
> 
> The idea is ,if Squid recieves a request on an endpoint on which only 
basic
> authentication is needed (ie 192.168.4.2:3129 and192.168.4.2:3139), NTLM
> will not be presented to the client/browser. Vice versa for NTLM. If no
> endpoints is configured , then the existing behavior will be applied.
> 
> Do you think this is reasonable and is there are any obvious problems 
with
> this?. If you find this useful, I am happy to contribute back when I 
finish
> implementing this module (I haven't yet started developing).


The HTTP framework is negotiated thusly:
 the proxy offers what it supports,
 the client tries the most secure credential type it has access to,
 the proxy says whether that is acceptible or to try again.
 .. repeat as necessary until either a success or no more credentials
are known - in which case ask the user with popup(s).

When that framework is used properly the clients with NTLM will try that
and the ones without will try Basic.


Squid-3.5 and later have the "auth_param ... key_extras ..." option that
can take extra parameters for the auth helper to use when it decides if
the credentials are valid.


I suggest you try making your self a script that takes the client IP as
one of those extra parameters; returning ERR if the IP is not allowed to
use the type of auth or relays the lookup on to your real auth helper if
it is allowed.

Amos



------------------------------

Message: 6
Date: Wed, 5 Oct 2016 08:19:52 -0600
From: Alex Rousskov <rousskov at measurement-factory.com>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Bug: Missing MemObject::storeId
Message-ID:
 <010b9e54-d853-6165-e00f-0266a3f71677 at measurement-factory.com>
Content-Type: text/plain; charset=utf-8

On 10/05/2016 06:28 AM, amaury at tin.it wrote:

> I'm using squid-3.5.21-20160908-r14081 and for the first time I 
> have configuration squid-smp (4workers and cache_dir rock).

> 2016/10/05 14:12:55 kid4| Bug: Missing MemObject::storeId value


> Is it a misconfiguration ?

It is a known bug: http://bugs.squid-cache.org/show_bug.cgi?id=4527

I recommend updating that bug report with your configuration details,
such as the fact that you are not using ICP (AFAICT). The bug also has
some suggestions for triaging this problem further.

The existence of that bug does not imply that your configuration is
correct, but this bug is not a [known] sign of a misconfiguration.

Alex.



------------------------------

Message: 7
Date: Wed, 5 Oct 2016 20:03:47 +0530
From: Hardik Dangar <hardikdangar+squid at gmail.com>
To: Amos Jeffries <squid3 at treenet.co.nz>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Caching http google deb files
Message-ID:
 <CA+sSnVYCy5E00jKK5cPZm3q+eBX8Fx=Mjs_iu4Xs0oebxcte9Q at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hey Amos,

oh, i actually built archive mode squid by getting help at here,
http://bugs.squid-cache.org/show_bug.cgi?id=4604

I was thinking if we have option vary_mode just like archive mode to set 
it
for particular domain like,

acl dlsslgoogle srcdomain dl-ssl.google.com
vary_mode allow dlsslgoogle
Above could work one of the following way,

1) We replace Vary header for srcdomain to some suitable option so request
can be cached
2) This will remove vary header totally for the above domain.
3) above will use matching squid refresh pattern for srcdomain and only
cache requests for
particular type of file given in refresh_pattern

What do you think would be easiar ? and how do i work on squid source to 
do
above? any hint is appreciated.


One more thing can you tell me if we are already violating http via 
options
like nocache, ignore-no-store ignore-private ignore-reload, why can't we 
do
the same for Vary header ?

It seems servers that are notorious have Vary * header as well as at times
(github) no Last modified header and these are the biggest bandwidth 
eaters.



Thanks.
Hardik
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <
http://lists.squid-cache.org/pipermail/squid-users/attachments/20161005/df333a18/attachment.html
>

------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 26, Issue 22
*******************************************
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161005/86995f48/attachment.htm>

From squid3 at treenet.co.nz  Wed Oct  5 17:03:09 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 6 Oct 2016 06:03:09 +1300
Subject: [squid-users] Squid - AD kerberos auth and Linux Server proxy
 access not working
In-Reply-To: <OF7AB42EBD.3C316EA5-ON80258043.0059EE52-80258043.005AC388@tcs.com>
References: <OF7AB42EBD.3C316EA5-ON80258043.0059EE52-80258043.005AC388@tcs.com>
Message-ID: <4e608076-5ca4-cdac-a5e4-6d0af5106f1d@treenet.co.nz>

On 6/10/2016 5:31 a.m., Nilesh Gavali wrote:
> <<NILESH>> here is the compete squid.conf for your reference-
> 
> #
> # Recommended minimum configuration:
> ####  AD SSO Integration  #####
> #auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -d -s 
> GSS_C_NO_NAME
> auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
> HTTP/proxy02.CUST.IN at CUST.IN
> auth_param negotiate children 20
> auth_param negotiate keep_alive on
> 
> acl ad_auth proxy_auth REQUIRED
> 
> ####  AD Group membership  ####
> 
> 
> external_acl_type AD_Group ttl=300 negative_ttl=0 children=10 %LOGIN 
> /usr/lib64/squid/squid_ldap_group -P -R -b "DC=CUST,DC=IN" -D svcproxy -W 
> /etc/squid/pswd/pswd -f 
> "(&(objectclass=person)(userPrincipalName=%v)(memberof=cn=%a,ou=InternetAccess,ou=Groups,dc=cust,dc=in))" 
> -h CUST.IN -s sub -v 3
> 
> acl AVWSUS external AD_Group lgOnlineUpdate
> acl windowsupdate dstdomain "/etc/squid/sitelist/infra_update_site"
> 
> acl custUSER external AD_Group lgInternetAccess_custUsers
> acl custallowedsite dstdomain "/etc/squid/sitelist/cust_allowed_site"
> 
> #acl SHAVLIK external AD_Group lgShavlikUpdate
> acl shavlikupdate dstdomain "/etc/squid/sitelist/shavlik_update_site"
> 
<snip defaults>

> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl AVSRVR src 10.50.2.107      # Cloud SEPM Servr
> acl SHAVLIK_SRVR src 10.50.2.112     # Shavlik Server(NTLM Only Access)
> acl IWCCP01 src 10.55.15.103   # Application access to Worldpay/bottomline 
> Payment test site.

<snip defaults>
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> 
> #http_access allow test shavlikupdate
> http_access allow SHAVLIK_SRVR shavlikupdate
> http_access allow AVSRVR windowsupdate

The "AVWSUS" ACL below requires authentication in order to check the
group membership. That is what triggers the 407 response to happen.

Move the IWCCP01 line up to here and it should stop.

To make your configuration clearer about which lines need auth and which
lines do not you could place the following line right here:

 http_access deny !ad_auth

All things that do need auth or group names should always go below it.
Things that need to avoid auth should always go above it.


> http_access allow AVWSUS windowsupdate
> http_access allow IWCCP01
> #http_access allow IWCCP01 custallowedsite
> http_access allow custUSER custallowedsite
> http_access allow ad_auth
> # And finally deny all other access to this proxy
> http_access deny all
> 

Amos



From hardikdangar+squid at gmail.com  Wed Oct  5 18:40:46 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Thu, 6 Oct 2016 00:10:46 +0530
Subject: [squid-users] Caching http google deb files
In-Reply-To: <CADSSinNbzY90jUyYOLPFcqc7a8WQFb4qFdbS7mc0knzcfZDJLw@mail.gmail.com>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
 <CADSSinNbzY90jUyYOLPFcqc7a8WQFb4qFdbS7mc0knzcfZDJLw@mail.gmail.com>
Message-ID: <CA+sSnVZ+6csWqt60nwwSM0QDSmx+DutqQeXgL-bGtYbFC6WRuw@mail.gmail.com>

Hey Jok,

Thanks for the suggetion but the big issue with that is i have to download
whole repository about ( 80-120 GB ) first and then each week i need to
download 20 to 25 GB.  We hardly use any of that except few popular repos.
big issue i always have with most of them is third party repo's.
squid-deb-proxy is quite reliable but again its squid with custom config
nothing else and it fails to cache google debs.

Squid is perfect for me because it can cache things which is requested
first time. So next time anybody requests it it's ready. The problem lies
when big companies like google and github does not wants us to cache their
content and puts various tricks so we can't do that. My issue is same
google deb files are downloaded 50 times in same day as apt updates happen
and i waste 100s of gb into same content. Country where i live bandwidth is
very very costly matter and fast connections are very costly. So this is
important for me.

@Amos,

I think it's about time Squid needs update of code which can cache use
cases like difficult to handle google and github. I am interested to create
proposal and will soon share at squid dev and ask for ideas and will try to
get official approval so i can build this according to squid standards.

but before that can you help me with few things.essentially i don't have
much experience with C code. as i have worked most of my life with
php,python and javascript side. I do know how to write C code but i am not
an expert at it. So i want to know if there is any pattern squid follows
except the oop pattern. I also want to know workflow of squid i.e. what
happens when it receives request and how acls are applied programmatically
and how refresh patterns are applied. is there a way i can debug and check
if refresh patterns are applied for given url. as well as
reply_header_replace has replaced header if i can see those lines in debug
it will help me with this. i know debug options can help me but if i turn
it with level 9 it is very difficult to go past so many debug entries.

My idea is to develop a module which will not change any of the squid code
but will be loaded only if its called explicitly within squid config. So i
want to know is there any piece of code available within squid which
behaves similarly just like your archive mode.




On Wed, Oct 5, 2016 at 9:49 PM, Jok Thuau <jok at spikes.com> wrote:

> This is sort of off-topic, but have you considered using a deb repo
> mirroring software?
> (it would mean that you need to update your clients to point to that
> rather than google, but that's not really difficult).
> software like aptly (aptly.info) are really good about this (though a
> little hard to get going in the first place). or a deb-caching proxy
> (apt-cacher-ng? squid-deb-proxy?)
>
>
> On Tue, Oct 4, 2016 at 7:30 AM, Hardik Dangar <
> hardikdangar+squid at gmail.com> wrote:
>
>> Wow, i couldn't think about that. google might need tracking data that
>> could be the reason they have blindly put vary * header. oh Irony, company
>> which talks to all of us on how to deliver content is trying to do such
>> thing.
>>
>> I have looked at your patch but how do i enable that ? do i need to write
>> custom ACL ? i know i need to compile and reinstall after applying patch
>> but what do i need to do exactly in squid.conf file as looking at your
>> patch i am guessing i need to write archive acl or i am too naive to
>> understand C code :)
>>
>> Also
>>
>> reply_header_replace is any good for this ?
>>
>>
>> On Tue, Oct 4, 2016 at 7:47 PM, Amos Jeffries <squid3 at treenet.co.nz>
>> wrote:
>>
>>> On 5/10/2016 2:34 a.m., Hardik Dangar wrote:
>>> > Hey Amos,
>>> >
>>> > We have about 50 clients which downloads same google chrome update
>>> every 2
>>> > or 3 days means 2.4 gb. although response says vary but requested file
>>> is
>>> > same and all is downloaded via apt update.
>>> >
>>> > Is there any option just like ignore-no-store? I know i am asking for
>>> too
>>> > much but it seems very silly on google's part that they are sending
>>> very
>>> > header at a place where they shouldn't as no matter how you access
>>> those
>>> > url's you are only going to get those deb files.
>>>
>>>
>>> Some things G does only make sense whan you ignore all the PR about
>>> wanting to make the web more efficient and consider it's a company whose
>>> income is derived by recording data about peoples habits and activities.
>>> Caching can hide that info from them.
>>>
>>> >
>>> > can i hack squid source code to ignore very header ?
>>> >
>>>
>>> Google are explicitly saying the response changes. I suspect there is
>>> something involving Google account data being embeded in some of the
>>> downloads. For tracking, etc.
>>>
>>>
>>> If you are wanting to test it I have added a patch to
>>> <http://bugs.squid-cache.org/show_bug.cgi?id=4604> that should implement
>>> archival of responses where the ACLs match. It is completely untested by
>>> me beyond building, so YMMV.
>>>
>>> Amos
>>>
>>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161006/98c8f171/attachment.htm>

From gergely at egervary.hu  Wed Oct  5 18:49:54 2016
From: gergely at egervary.hu (=?UTF-8?Q?Egerv=c3=a1ry_Gergely?=)
Date: Wed, 5 Oct 2016 20:49:54 +0200
Subject: [squid-users] intercept + IPv6 + IPFilter 5.1
In-Reply-To: <7298f28a-0d3b-5a43-9aee-81b11862d5bb@borrill.org.uk>
References: <76058d09-5599-7426-8ba6-05b7b4550c2d@egervary.hu>
 <7298f28a-0d3b-5a43-9aee-81b11862d5bb@borrill.org.uk>
Message-ID: <57F54B52.4000803@egervary.hu>

>> Should "intercept" work with IPv6 on NetBSD 7-STABLE and IPFilter 5.1?

Okay, we have "fixed" Squid interception, and IPFilter in the kernel,
and now it's working good. But did we do it in the right way?

While reading ip_nat.c in IPFilter, I found that SIOCGNATL - and its
function called ipf_nat_lookupredir() - is a frontend to two functions:
ipf_nat_inlookup() and ipf_nat_outlookup().

We are now calling SIOCGNATL to use ipf_nat_outlookup(). But should not
we call it to use ipf_nat_inlookup() instead?

In Squid, we are working with 3 different addresses:
- source IP:port of the connection (browser client)
- real destination IP:port (the target web server)
- interception destination IP:port (Squid itself)

In IPFilter, the terminology is different: "real" refers to the
original source, not the original destination.

In my understanding, on redirect (RDR) rules, where we know the
original source address and the rewrited destination address, we should
use ipf_nat_inlookup() to get the original destination address.

ipf_nat_outlookup() should be used on source-NAT (MAP) scenarios,
what we don't need for Squid.

If that's true, IPFilter was correct - we have to revert our IPFilter
patches - and modify Intercept.cc instead.

See IPFilter source code comments below:

========
Function: ipf_nat_inlookup
Returns: nat_t* - NULL == no match, else pointer to matching NAT entry
Parameters:
fin(I) - pointer to packet information
flags(I) - NAT flags for this packet
p(I) - protocol for this packet
src(I) - source IP address
mapdst(I) - destination IP address

Lookup a nat entry based on the mapped destination ip address/port
and real source address/port. We use this lookup when receiving a
packet, we're looking for a table entry, based on the destination
address.

========
Function: ipf_nat_outlookup
Returns: nat_t* - NULL == no match, else pointer to matching NAT entry
Parameters:
fin(I) - pointer to packet information
flags(I) - NAT flags for this packet
p(I) - protocol for this packet
src(I) - source IP address
dst(I) - destination IP address
rw(I) - 1 == write lock on held, 0 == read lock.

Lookup a nat entry based on the source 'real' ip address/port
and destination address/port. We use this lookup when sending a packet
out, we're looking for a table entry, based on the source address.

========

See full ip_nat.c source code here:

http://cvsweb.netbsd.org/bsdweb.cgi/src/sys/external/bsd/ipf/netinet/ip_nat.c?rev=1.16&content-type=text/x-cvsweb-markup

Thank you,
-- 
Gergely EGERVARY



From Antony.Stone at squid.open.source.it  Wed Oct  5 19:13:21 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 5 Oct 2016 21:13:21 +0200
Subject: [squid-users] Caching http google deb files
In-Reply-To: <CA+sSnVZ+6csWqt60nwwSM0QDSmx+DutqQeXgL-bGtYbFC6WRuw@mail.gmail.com>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <CADSSinNbzY90jUyYOLPFcqc7a8WQFb4qFdbS7mc0knzcfZDJLw@mail.gmail.com>
 <CA+sSnVZ+6csWqt60nwwSM0QDSmx+DutqQeXgL-bGtYbFC6WRuw@mail.gmail.com>
Message-ID: <201610052113.21686.Antony.Stone@squid.open.source.it>

On Wednesday 05 October 2016 at 20:40:46, Hardik Dangar wrote:

> Hey Jok,
> 
> Thanks for the suggetion but the big issue with that is i have to download
> whole repository about ( 80-120 GB ) first and then each week i need to
> download 20 to 25 GB.

This is not true for apt-cacher-ng.  You install it and it does nothing.  You 
point your Debian (or Ubuntu, maybe other Debian-derived distros as well, I 
haven't tested) machines at it as their APT proxy, and it then caches content 
as it gets requested and downloaded.  Each machine which requests a new 
package causes that package to get cached.  Each machine which requests a 
cached package gets the local copy (unless it's been updated, in which case 
the cache gets updated).

> We hardly use any of that except few popular repos.
> big issue i always have with most of them is third party repo's.
> squid-deb-proxy is quite reliable but again its squid with custom config
> nothing else and it fails to cache google debs.
> 
> Squid is perfect for me because it can cache things which is requested
> first time. So next time anybody requests it it's ready.

This is exactly how apt-cacher-ng works.  I use it myself and I would 
recommend you investigate it further for this purpose.

> The problem lies when big companies like google and github does not wants us
> to cache their content and puts various tricks so we can't do that.

That's a strange concept for a Debian repository (even third-party).

Are you sure you're talking about repositories and not just isolated .deb 
files?


Antony.

-- 
A user interface is like a joke.
If you have to explain it, it didn't work.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From jetsystemservices at gmail.com  Wed Oct  5 19:15:56 2016
From: jetsystemservices at gmail.com (Jose Torres-Berrocal)
Date: Wed, 5 Oct 2016 15:15:56 -0400
Subject: [squid-users] Whitelist domain ignored?
In-Reply-To: <CADSSinPXUsf5fPUbdzEsV-oafJos0EtaQZhOZK-pZ6ncSS_eYw@mail.gmail.com>
References: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>
 <CADSSinNYT4GX5+4YhmF62GvGL2remrHm27Av8kr_V-xgBY3rEg@mail.gmail.com>
 <CABU5kW7eH3MM99YJuAeei-8gUsC5dg7cgh6higznGASG=gA8sg@mail.gmail.com>
 <CADSSinPXUsf5fPUbdzEsV-oafJos0EtaQZhOZK-pZ6ncSS_eYw@mail.gmail.com>
Message-ID: <CABU5kW5kLn4=2HtueBs0NrkwT+uHkRexyNnpPPQxqV6EqCKndA@mail.gmail.com>

The situation is that I am using squid on the pfsense firewall.  Squid
is available as a package with GUI interface.  The whitelist is part
of the sections provided by the GUI and somehow entering the domains
as a list that I provided it does work for most of the domains but it
fails in others.  The squid.conf is generated by the GUI and uses
dstdom_regex for the whitelist.  It has custom area where I can place
the lines to use dstdomain and it works.  But I would like to know how
I should enter the domains as to make it work correctly using
dstdom_regex behaving like dstdomain

Jose E Torres
939-777-4030
JET System Services


On Wed, Oct 5, 2016 at 12:10 PM, Jok Thuau <jok at spikes.com> wrote:
>
>
> On Tue, Oct 4, 2016 at 6:01 PM, Jose Torres-Berrocal
> <jetsystemservices at gmail.com> wrote:
>>
>> > /var/squid/acl/whitelist.acl:
>>
>> [snip]
>> >
>> > .assertus.com
>> > .neodecksoftware.com
>>
>>
>> your whitelist for this domain says that it has "something" followed
>> by that domain name...
>>
>> >
>> >
>> > .office.net
>>
>> 1. Each domain is on separate line, why is consider the next line part
>> of the same pattern?
>>
>> in the end, your regular expression doesn't match.
>> "." means "any single character". you should replace that line with
>> something like this:
>> ^neodecksoftware\.com
>>
>> 2. Then I should change each domain line to resemble your suggested
>> pattern?
>>
>> ^assertus\.com
>> ^neodecksoftware\.com
>> ^office\.net
>>
>
> Well, not quite that simple. That pattern will block "www.office.net", which
> is probably not what you want. That pattern would only fix that one i
> mentioned (which doesn't use "www" or anything else in front of the domain).
> The "^" is an anchor for the beginning of the string. that would exclude any
> of the sub-domains.
>
> In the end, I believe Alex's suggestion (to change from dstdom_regex to
> dstdomain will be simpler, and will do what you expect (where if you list
> ".something.tld", it will accept both "www.something.tld" and
> "something.tld"). Refer to the documentation and example to understand how
> that is being handled.
>
> I would suggest you research regular expressions. Visit and play with
> regex101.com -- The explanation panel on the side will do wonders to
> demystify the pattern I provided.
>
> see:
> https://regex101.com/r/hVu6vX/3
>
> Thanks,
> Jok
>


From hardikdangar+squid at gmail.com  Wed Oct  5 19:41:01 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Thu, 6 Oct 2016 01:11:01 +0530
Subject: [squid-users] Caching http google deb files
In-Reply-To: <201610052113.21686.Antony.Stone@squid.open.source.it>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <CADSSinNbzY90jUyYOLPFcqc7a8WQFb4qFdbS7mc0knzcfZDJLw@mail.gmail.com>
 <CA+sSnVZ+6csWqt60nwwSM0QDSmx+DutqQeXgL-bGtYbFC6WRuw@mail.gmail.com>
 <201610052113.21686.Antony.Stone@squid.open.source.it>
Message-ID: <CA+sSnVaBBUs-d2cFcwV4M5b+w+=PBogfR1dVAeNXzjnBHb_e2g@mail.gmail.com>

Hey Anthony,

I have used apt-cacher-ng, but it can't save git repos or npm repos. Also i
have used apt-cacher-ng, it used to work great until 12.02 but when we had
started to have mixed setup [ ubuntu 13,14.04 and others ] we got issues
within our setup and one point issues became so daily we decided to scrap
apt-cacher-ng.



On Thu, Oct 6, 2016 at 12:43 AM, Antony Stone <
Antony.Stone at squid.open.source.it> wrote:

> On Wednesday 05 October 2016 at 20:40:46, Hardik Dangar wrote:
>
> > Hey Jok,
> >
> > Thanks for the suggetion but the big issue with that is i have to
> download
> > whole repository about ( 80-120 GB ) first and then each week i need to
> > download 20 to 25 GB.
>
> This is not true for apt-cacher-ng.  You install it and it does nothing.
> You
> point your Debian (or Ubuntu, maybe other Debian-derived distros as well, I
> haven't tested) machines at it as their APT proxy, and it then caches
> content
> as it gets requested and downloaded.  Each machine which requests a new
> package causes that package to get cached.  Each machine which requests a
> cached package gets the local copy (unless it's been updated, in which case
> the cache gets updated).
>
> > We hardly use any of that except few popular repos.
> > big issue i always have with most of them is third party repo's.
> > squid-deb-proxy is quite reliable but again its squid with custom config
> > nothing else and it fails to cache google debs.
> >
> > Squid is perfect for me because it can cache things which is requested
> > first time. So next time anybody requests it it's ready.
>
> This is exactly how apt-cacher-ng works.  I use it myself and I would
> recommend you investigate it further for this purpose.
>
> > The problem lies when big companies like google and github does not
> wants us
> > to cache their content and puts various tricks so we can't do that.
>
> That's a strange concept for a Debian repository (even third-party).
>
> Are you sure you're talking about repositories and not just isolated .deb
> files?
>
>
> Antony.
>
> --
> A user interface is like a joke.
> If you have to explain it, it didn't work.
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161006/85b62f20/attachment.htm>

From rousskov at measurement-factory.com  Wed Oct  5 20:43:04 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 5 Oct 2016 14:43:04 -0600
Subject: [squid-users] Whitelist domain ignored?
In-Reply-To: <CABU5kW5kLn4=2HtueBs0NrkwT+uHkRexyNnpPPQxqV6EqCKndA@mail.gmail.com>
References: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>
 <CADSSinNYT4GX5+4YhmF62GvGL2remrHm27Av8kr_V-xgBY3rEg@mail.gmail.com>
 <CABU5kW7eH3MM99YJuAeei-8gUsC5dg7cgh6higznGASG=gA8sg@mail.gmail.com>
 <CADSSinPXUsf5fPUbdzEsV-oafJos0EtaQZhOZK-pZ6ncSS_eYw@mail.gmail.com>
 <CABU5kW5kLn4=2HtueBs0NrkwT+uHkRexyNnpPPQxqV6EqCKndA@mail.gmail.com>
Message-ID: <c88cca41-ef79-a77d-5e4e-d3ce20f4beb6@measurement-factory.com>

On 10/05/2016 01:15 PM, Jose Torres-Berrocal wrote:
> I would like to know how
> I should enter the domains as to make it work correctly using
> dstdom_regex behaving like dstdomain

To map any leaf FQDN "foo.bar.baz":

  1. start with "^";
  2. add "foo.bar.baz" where every period is escaped with "\";
  3. end with "$".

  In summary, use the following regular expression: ^foo\.bar\.baz$


To map a whole ".bar.baz" domain, including any subdomains, use the
following two regular expressions:

  \.bar\.baz$
  ^bar\.baz$

This untested suggestion is based on how regular expressions work; it
assumes that Squid does not add anything to the specified expressions.


HTH,

Alex.



From jetsystemservices at gmail.com  Wed Oct  5 20:59:03 2016
From: jetsystemservices at gmail.com (Jose Torres-Berrocal)
Date: Wed, 5 Oct 2016 16:59:03 -0400
Subject: [squid-users] Whitelist domain ignored?
In-Reply-To: <c88cca41-ef79-a77d-5e4e-d3ce20f4beb6@measurement-factory.com>
References: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>
 <CADSSinNYT4GX5+4YhmF62GvGL2remrHm27Av8kr_V-xgBY3rEg@mail.gmail.com>
 <CABU5kW7eH3MM99YJuAeei-8gUsC5dg7cgh6higznGASG=gA8sg@mail.gmail.com>
 <CADSSinPXUsf5fPUbdzEsV-oafJos0EtaQZhOZK-pZ6ncSS_eYw@mail.gmail.com>
 <CABU5kW5kLn4=2HtueBs0NrkwT+uHkRexyNnpPPQxqV6EqCKndA@mail.gmail.com>
 <c88cca41-ef79-a77d-5e4e-d3ce20f4beb6@measurement-factory.com>
Message-ID: <CABU5kW7sy9qL3d=8rCR4=ROK4zGLvwp32ZQMPj2Bb8RtmwBniA@mail.gmail.com>

Please confirm equivalence:

1.
acl whitelist1 dstdomain .familymedicinepr.com .mail.yahoo.com
.neodecksoftware.com .office.net
=
acl whitelist2 dstdom_regex ^familymedicinepr\.com$ ^mail\.yahoo\.com$
^neodecksoftware\.com$ ^office\.net$

OR

2.
acl whitelist1 dstdomain .familymedicinepr.com .mail.yahoo.com
.neodecksoftware.com .office.net
=
acl whitelist2 dstdom_regex ^familymedicinepr\.com$ ^mail\.yahoo\.com$
^neodecksoftware\.com$ ^office\.net$ \familymedicinepr\.com$
\mail\.yahoo\.com$ \neodecksoftware\.com$ \office\.net$
Jose E Torres
939-777-4030
JET System Services


On Wed, Oct 5, 2016 at 4:43 PM, Alex Rousskov
<rousskov at measurement-factory.com> wrote:
> On 10/05/2016 01:15 PM, Jose Torres-Berrocal wrote:
>> I would like to know how
>> I should enter the domains as to make it work correctly using
>> dstdom_regex behaving like dstdomain
>
> To map any leaf FQDN "foo.bar.baz":
>
>   1. start with "^";
>   2. add "foo.bar.baz" where every period is escaped with "\";
>   3. end with "$".
>
>   In summary, use the following regular expression: ^foo\.bar\.baz$
>
>
> To map a whole ".bar.baz" domain, including any subdomains, use the
> following two regular expressions:
>
>   \.bar\.baz$
>   ^bar\.baz$
>
> This untested suggestion is based on how regular expressions work; it
> assumes that Squid does not add anything to the specified expressions.
>
>
> HTH,
>
> Alex.
>


From rousskov at measurement-factory.com  Wed Oct  5 21:07:24 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 5 Oct 2016 15:07:24 -0600
Subject: [squid-users] Whitelist domain ignored?
In-Reply-To: <CABU5kW7sy9qL3d=8rCR4=ROK4zGLvwp32ZQMPj2Bb8RtmwBniA@mail.gmail.com>
References: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>
 <CADSSinNYT4GX5+4YhmF62GvGL2remrHm27Av8kr_V-xgBY3rEg@mail.gmail.com>
 <CABU5kW7eH3MM99YJuAeei-8gUsC5dg7cgh6higznGASG=gA8sg@mail.gmail.com>
 <CADSSinPXUsf5fPUbdzEsV-oafJos0EtaQZhOZK-pZ6ncSS_eYw@mail.gmail.com>
 <CABU5kW5kLn4=2HtueBs0NrkwT+uHkRexyNnpPPQxqV6EqCKndA@mail.gmail.com>
 <c88cca41-ef79-a77d-5e4e-d3ce20f4beb6@measurement-factory.com>
 <CABU5kW7sy9qL3d=8rCR4=ROK4zGLvwp32ZQMPj2Bb8RtmwBniA@mail.gmail.com>
Message-ID: <32081c3d-3b75-1f36-08a2-8d0bbadb943e@measurement-factory.com>

On 10/05/2016 02:59 PM, Jose Torres-Berrocal wrote:
> Please confirm equivalence:
> 
> 1.
> acl whitelist1 dstdomain .familymedicinepr.com .mail.yahoo.com
> .neodecksoftware.com .office.net
> =
> acl whitelist2 dstdom_regex ^familymedicinepr\.com$ ^mail\.yahoo\.com$
> ^neodecksoftware\.com$ ^office\.net$
> 
> OR
> 
> 2.
> acl whitelist1 dstdomain .familymedicinepr.com .mail.yahoo.com
> .neodecksoftware.com .office.net
> =
> acl whitelist2 dstdom_regex ^familymedicinepr\.com$ ^mail\.yahoo\.com$
> ^neodecksoftware\.com$ ^office\.net$ \familymedicinepr\.com$
> \mail\.yahoo\.com$ \neodecksoftware\.com$ \office\.net$


Neither pair contains equivalent ACLs. The second attempt was closer to
the correct version but you missed the leading "." in the first of the
two regular expressions for each domain. For example, it is
"\.office\.net$" not "\office\.net$".

I also recommend splitting dstdom_regex ACL into multiple lines, one
regular expression per line, for readability sake.


As others have already recommended, it is best to learn how regular
expressions work before proceeding further. They are a very valuable
tool for a sysadmin!

Alex.


> On Wed, Oct 5, 2016 at 4:43 PM, Alex Rousskov wrote:
>> To map any leaf FQDN "foo.bar.baz":
>>
>>   1. start with "^";
>>   2. add "foo.bar.baz" where every period is escaped with "\";
>>   3. end with "$".
>>
>>   In summary, use the following regular expression: ^foo\.bar\.baz$
>>
>>
>> To map a whole ".bar.baz" domain, including any subdomains, use the
>> following two regular expressions:
>>
>>   \.bar\.baz$
>>   ^bar\.baz$
>>
>> This untested suggestion is based on how regular expressions work; it
>> assumes that Squid does not add anything to the specified expressions.



From gaardiolor at gmail.com  Wed Oct  5 21:17:14 2016
From: gaardiolor at gmail.com (Marc)
Date: Wed, 5 Oct 2016 23:17:14 +0200
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
 code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <2aeb5cbc-67aa-0742-efb1-ab123c638bc6@treenet.co.nz>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
 <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
 <2077594026.2082495.1475235384241@mail.yahoo.com>
 <af92d108-b205-decb-13c4-fecb7a554b5e@gmail.com>
 <421701582.3214410.1475478705099@mail.yahoo.com>
 <f4e0b806-587c-ed2e-4941-b5cccbcda0d1@treenet.co.nz>
 <1410278953.3964483.1475579267802@mail.yahoo.com>
 <2aeb5cbc-67aa-0742-efb1-ab123c638bc6@treenet.co.nz>
Message-ID: <CAPxJK5BD-CnAOWM3Gb+=a+O7UUOBqCuD5_oHvx8WswrGrMtAGQ@mail.gmail.com>

Well.. it looks like the issue I'm having (subject: handshake problems
with stare and bump).

IE8 on XP sends out:

Secure Sockets Layer
    SSL Record Layer: Handshake Protocol: Client Hello
        Content Type: Handshake (22)
        Version: TLS 1.0 (0x0301)
        Length: 104
        Handshake Protocol: Client Hello
            Handshake Type: Client Hello (1)
            Length: 100
            Version: TLS 1.0 (0x0301)
            Random
                GMT Unix Time: Oct  5, 2016 22:53:22.000000000 CEST
                Random Bytes:
f1a9d796abe91c5187a2b3c7d726f02bc64a45992c92599c...
            Session ID Length: 32
            Session ID: 09f457ce0ebaea9adf703ee1c4eaf999b169da6610132dc1...
            Cipher Suites Length: 22
            Cipher Suites (11 suites)
                Cipher Suite: TLS_RSA_WITH_RC4_128_MD5 (0x0004)
                Cipher Suite: TLS_RSA_WITH_RC4_128_SHA (0x0005)
                Cipher Suite: TLS_RSA_WITH_3DES_EDE_CBC_SHA (0x000a)
                Cipher Suite: TLS_RSA_WITH_DES_CBC_SHA (0x0009)
                Cipher Suite: TLS_RSA_EXPORT1024_WITH_RC4_56_SHA (0x0064)
                Cipher Suite: TLS_RSA_EXPORT1024_WITH_DES_CBC_SHA (0x0062)
                Cipher Suite: TLS_RSA_EXPORT_WITH_RC4_40_MD5 (0x0003)
                Cipher Suite: TLS_RSA_EXPORT_WITH_RC2_CBC_40_MD5 (0x0006)
                Cipher Suite: TLS_DHE_DSS_WITH_3DES_EDE_CBC_SHA (0x0013)
                Cipher Suite: TLS_DHE_DSS_WITH_DES_CBC_SHA (0x0012)
                Cipher Suite: TLS_DHE_DSS_EXPORT1024_WITH_DES_CBC_SHA (0x0063)
            Compression Methods Length: 1
            Compression Methods (1 method)
                Compression Method: null (0)
            Extensions Length: 5
            Extension: renegotiation_info
                Type: renegotiation_info (0xff01)
                Length: 1
                Renegotiation Info extension
                    Renegotiation info extension length: 0

Mimicing in openssl (well.. not perfect but it joes the job I guess):
openssl s_client -quiet -connect www.google.com:443 -tls1 -cipher
RC4-MD5:RC4-SHA:DES-CBC3-SHA:DES-CBC-SHA:EXP1024-RC4-SHA:EXP1024-DES-CBC-SHA:EXP-RC4-MD5:EXP-RC2-CBC-MD5:DHE-DSS-DES-CBC3-SHA:DHE-DSS-CBC-SHA:EXP1024-DHE-DSS-DES-CBC-SHA
 < <(echo -e "GET / HTTP/1.1\nHost: https://www.google.com\n\n")
SQUID_ERR_SSL_HANDSHAKE

Like the problem in my post, IE8 on XP doesn't use much TLS
extensions. Adding a random extension, like in my post:
openssl s_client -quiet -connect www.google.com:443 -tls1 -cipher
RC4-MD5:RC4-SHA:DES-CBC3-SHA:DES-CBC-SHA:EXP1024-RC4-SHA:EXP1024-DES-CBC-SHA:EXP-RC4-MD5:EXP-RC2-CBC-MD5:DHE-DSS-DES-CBC3-SHA:DHE-DSS-CBC-SHA:EXP1024-DHE-DSS-DES-CBC-SHA
-serverinfo 12345 < <(echo -e "GET / HTTP/1.1\nHost:
https://www.google.com\n\n")
Succes!

Don't want to pull the bug card too quick, but well..

Marc


From jetsystemservices at gmail.com  Wed Oct  5 22:53:08 2016
From: jetsystemservices at gmail.com (Jose Torres-Berrocal)
Date: Wed, 5 Oct 2016 18:53:08 -0400
Subject: [squid-users] Whitelist domain ignored?
In-Reply-To: <32081c3d-3b75-1f36-08a2-8d0bbadb943e@measurement-factory.com>
References: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>
 <CADSSinNYT4GX5+4YhmF62GvGL2remrHm27Av8kr_V-xgBY3rEg@mail.gmail.com>
 <CABU5kW7eH3MM99YJuAeei-8gUsC5dg7cgh6higznGASG=gA8sg@mail.gmail.com>
 <CADSSinPXUsf5fPUbdzEsV-oafJos0EtaQZhOZK-pZ6ncSS_eYw@mail.gmail.com>
 <CABU5kW5kLn4=2HtueBs0NrkwT+uHkRexyNnpPPQxqV6EqCKndA@mail.gmail.com>
 <c88cca41-ef79-a77d-5e4e-d3ce20f4beb6@measurement-factory.com>
 <CABU5kW7sy9qL3d=8rCR4=ROK4zGLvwp32ZQMPj2Bb8RtmwBniA@mail.gmail.com>
 <32081c3d-3b75-1f36-08a2-8d0bbadb943e@measurement-factory.com>
Message-ID: <CABU5kW7bLMGtYitztHXJX+REuN4_AKNu_Aesf0_urMDmHuVu9w@mail.gmail.com>

Lets try again:

acl whitelist1 dstdomain .familymedicinepr.com .mail.yahoo.com
.neodecksoftware.com .office.net
=
acl whitelist2 dstdom_regex ^familymedicinepr\.com$ ^mail\.yahoo\.com$
^neodecksoftware\.com$ ^office\.net$ \.familymedicinepr\.com$
\.mail\.yahoo\.com$ \.neodecksoftware\.com$ \.office\.net$

And placing it inside a whitelist.acl file:
acl whitelist2 dstdom_regex -i "whitelist.acl"

Where whitelist.acl content:
.^familymedicinepr\.com$
^mail\.yahoo\.com$
^neodecksoftware\.com$
^office\.net$
\.familymedicinepr\.com$
\.mail\.yahoo\.com$
\.neodecksoftware\.com$
\.office\.net$

Jose E Torres
939-777-4030
JET System Services


On Wed, Oct 5, 2016 at 5:07 PM, Alex Rousskov
<rousskov at measurement-factory.com> wrote:
> On 10/05/2016 02:59 PM, Jose Torres-Berrocal wrote:
>> Please confirm equivalence:
>>
>> 1.
>> acl whitelist1 dstdomain .familymedicinepr.com .mail.yahoo.com
>> .neodecksoftware.com .office.net
>> =
>> acl whitelist2 dstdom_regex ^familymedicinepr\.com$ ^mail\.yahoo\.com$
>> ^neodecksoftware\.com$ ^office\.net$
>>
>> OR
>>
>> 2.
>> acl whitelist1 dstdomain .familymedicinepr.com .mail.yahoo.com
>> .neodecksoftware.com .office.net
>> =
>> acl whitelist2 dstdom_regex ^familymedicinepr\.com$ ^mail\.yahoo\.com$
>> ^neodecksoftware\.com$ ^office\.net$ \familymedicinepr\.com$
>> \mail\.yahoo\.com$ \neodecksoftware\.com$ \office\.net$
>
>
> Neither pair contains equivalent ACLs. The second attempt was closer to
> the correct version but you missed the leading "." in the first of the
> two regular expressions for each domain. For example, it is
> "\.office\.net$" not "\office\.net$".
>
> I also recommend splitting dstdom_regex ACL into multiple lines, one
> regular expression per line, for readability sake.
>
>
> As others have already recommended, it is best to learn how regular
> expressions work before proceeding further. They are a very valuable
> tool for a sysadmin!
>
> Alex.
>
>
>> On Wed, Oct 5, 2016 at 4:43 PM, Alex Rousskov wrote:
>>> To map any leaf FQDN "foo.bar.baz":
>>>
>>>   1. start with "^";
>>>   2. add "foo.bar.baz" where every period is escaped with "\";
>>>   3. end with "$".
>>>
>>>   In summary, use the following regular expression: ^foo\.bar\.baz$
>>>
>>>
>>> To map a whole ".bar.baz" domain, including any subdomains, use the
>>> following two regular expressions:
>>>
>>>   \.bar\.baz$
>>>   ^bar\.baz$
>>>
>>> This untested suggestion is based on how regular expressions work; it
>>> assumes that Squid does not add anything to the specified expressions.
>


From jetsystemservices at gmail.com  Wed Oct  5 22:56:14 2016
From: jetsystemservices at gmail.com (Jose Torres-Berrocal)
Date: Wed, 5 Oct 2016 18:56:14 -0400
Subject: [squid-users] Whitelist domain ignored?
In-Reply-To: <CABU5kW7bLMGtYitztHXJX+REuN4_AKNu_Aesf0_urMDmHuVu9w@mail.gmail.com>
References: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>
 <CADSSinNYT4GX5+4YhmF62GvGL2remrHm27Av8kr_V-xgBY3rEg@mail.gmail.com>
 <CABU5kW7eH3MM99YJuAeei-8gUsC5dg7cgh6higznGASG=gA8sg@mail.gmail.com>
 <CADSSinPXUsf5fPUbdzEsV-oafJos0EtaQZhOZK-pZ6ncSS_eYw@mail.gmail.com>
 <CABU5kW5kLn4=2HtueBs0NrkwT+uHkRexyNnpPPQxqV6EqCKndA@mail.gmail.com>
 <c88cca41-ef79-a77d-5e4e-d3ce20f4beb6@measurement-factory.com>
 <CABU5kW7sy9qL3d=8rCR4=ROK4zGLvwp32ZQMPj2Bb8RtmwBniA@mail.gmail.com>
 <32081c3d-3b75-1f36-08a2-8d0bbadb943e@measurement-factory.com>
 <CABU5kW7bLMGtYitztHXJX+REuN4_AKNu_Aesf0_urMDmHuVu9w@mail.gmail.com>
Message-ID: <CABU5kW5=rc8VnxGnagNnhhFONJDCyMctrsW9QtBi_2+hBRmXdA@mail.gmail.com>

Correcting typo:

And placing it inside a whitelist.acl file:
acl whitelist2 dstdom_regex -i "whitelist.acl"

Where whitelist.acl content:
^familymedicinepr\.com$
^mail\.yahoo\.com$
^neodecksoftware\.com$
^office\.net$
\.familymedicinepr\.com$
\.mail\.yahoo\.com$
\.neodecksoftware\.com$
\.office\.net$
Jose E Torres
939-777-4030
JET System Services


On Wed, Oct 5, 2016 at 6:53 PM, Jose Torres-Berrocal
<jetsystemservices at gmail.com> wrote:
> Lets try again:
>
> acl whitelist1 dstdomain .familymedicinepr.com .mail.yahoo.com
> .neodecksoftware.com .office.net
> =
> acl whitelist2 dstdom_regex ^familymedicinepr\.com$ ^mail\.yahoo\.com$
> ^neodecksoftware\.com$ ^office\.net$ \.familymedicinepr\.com$
> \.mail\.yahoo\.com$ \.neodecksoftware\.com$ \.office\.net$
>
> And placing it inside a whitelist.acl file:
> acl whitelist2 dstdom_regex -i "whitelist.acl"
>
> Where whitelist.acl content:
> .^familymedicinepr\.com$
> ^mail\.yahoo\.com$
> ^neodecksoftware\.com$
> ^office\.net$
> \.familymedicinepr\.com$
> \.mail\.yahoo\.com$
> \.neodecksoftware\.com$
> \.office\.net$
>
> Jose E Torres
> 939-777-4030
> JET System Services
>
>
> On Wed, Oct 5, 2016 at 5:07 PM, Alex Rousskov
> <rousskov at measurement-factory.com> wrote:
>> On 10/05/2016 02:59 PM, Jose Torres-Berrocal wrote:
>>> Please confirm equivalence:
>>>
>>> 1.
>>> acl whitelist1 dstdomain .familymedicinepr.com .mail.yahoo.com
>>> .neodecksoftware.com .office.net
>>> =
>>> acl whitelist2 dstdom_regex ^familymedicinepr\.com$ ^mail\.yahoo\.com$
>>> ^neodecksoftware\.com$ ^office\.net$
>>>
>>> OR
>>>
>>> 2.
>>> acl whitelist1 dstdomain .familymedicinepr.com .mail.yahoo.com
>>> .neodecksoftware.com .office.net
>>> =
>>> acl whitelist2 dstdom_regex ^familymedicinepr\.com$ ^mail\.yahoo\.com$
>>> ^neodecksoftware\.com$ ^office\.net$ \familymedicinepr\.com$
>>> \mail\.yahoo\.com$ \neodecksoftware\.com$ \office\.net$
>>
>>
>> Neither pair contains equivalent ACLs. The second attempt was closer to
>> the correct version but you missed the leading "." in the first of the
>> two regular expressions for each domain. For example, it is
>> "\.office\.net$" not "\office\.net$".
>>
>> I also recommend splitting dstdom_regex ACL into multiple lines, one
>> regular expression per line, for readability sake.
>>
>>
>> As others have already recommended, it is best to learn how regular
>> expressions work before proceeding further. They are a very valuable
>> tool for a sysadmin!
>>
>> Alex.
>>
>>
>>> On Wed, Oct 5, 2016 at 4:43 PM, Alex Rousskov wrote:
>>>> To map any leaf FQDN "foo.bar.baz":
>>>>
>>>>   1. start with "^";
>>>>   2. add "foo.bar.baz" where every period is escaped with "\";
>>>>   3. end with "$".
>>>>
>>>>   In summary, use the following regular expression: ^foo\.bar\.baz$
>>>>
>>>>
>>>> To map a whole ".bar.baz" domain, including any subdomains, use the
>>>> following two regular expressions:
>>>>
>>>>   \.bar\.baz$
>>>>   ^bar\.baz$
>>>>
>>>> This untested suggestion is based on how regular expressions work; it
>>>> assumes that Squid does not add anything to the specified expressions.
>>


From squid-users at filter.luko.org  Wed Oct  5 23:49:36 2016
From: squid-users at filter.luko.org (squid-users at filter.luko.org)
Date: Thu, 6 Oct 2016 10:49:36 +1100
Subject: [squid-users] Introducing delay to HTTP 407 responses
In-Reply-To: <82c0c153-a128-74fe-c216-6ea9d285d3be@measurement-factory.com>
References: <000301d20e1d$7476f840$5d64e8c0$@filter.luko.org>
 <013301d20e8f$12f257f0$38d707d0$@ngtech.co.il>
 <007a01d21e2d$905f1e00$b11d5a00$@filter.luko.org>
 <c521b757-2596-e122-d468-84ebbc5528c0@treenet.co.nz>
 <009d01d21e35$179582e0$46c088a0$@filter.luko.org>
 <7601901b-d28f-5d05-6a17-6ba96e5bd174@treenet.co.nz>
 <82c0c153-a128-74fe-c216-6ea9d285d3be@measurement-factory.com>
Message-ID: <007601d21f63$2189ad60$649d0820$@filter.luko.org>

Alex,

> However, there is a difference between my August tests and this thread.
> My tests were for a request parsing error response. Access denials do not
> reach the same http_reply_access checks! See "early return"
> statements in clientReplyContext::processReplyAccess(), including:
> 
> >     /** Don't block our own responses or HTTP status messages */
> >     if (http->logType.oldType == LOG_TCP_DENIED ||
> >             http->logType.oldType == LOG_TCP_DENIED_REPLY ||
> >             alwaysAllowResponse(reply->sline.status())) {
> >         headers_sz = reply->hdr_sz;
> >         processReplyAccessResult(ACCESS_ALLOWED);
> >         return;
> >     }
> 
> I am not sure whether avoiding http_reply_access in such cases is a
> bug/misfeature or the right behavior. As any exception, it certainly
> creates problems for those who want to [ab]use http_reply_access as a
> delay hook. FWIW, Squid had this exception since 2007:

Thanks, makes sense.  It would be great if there was a way to slow down 407 responses; at the moment the only workaround I can think of is to write a log-watching script to maintain a list of offending IP/domain pairs, then write a helper to use that data to introduce delay when the request is first received (via http_access and the !all trick).  If anyone has a better option, I'm all ears.

Luke




From rousskov at measurement-factory.com  Thu Oct  6 00:19:31 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 5 Oct 2016 18:19:31 -0600
Subject: [squid-users] Introducing delay to HTTP 407 responses
In-Reply-To: <007601d21f63$2189ad60$649d0820$@filter.luko.org>
References: <000301d20e1d$7476f840$5d64e8c0$@filter.luko.org>
 <013301d20e8f$12f257f0$38d707d0$@ngtech.co.il>
 <007a01d21e2d$905f1e00$b11d5a00$@filter.luko.org>
 <c521b757-2596-e122-d468-84ebbc5528c0@treenet.co.nz>
 <009d01d21e35$179582e0$46c088a0$@filter.luko.org>
 <7601901b-d28f-5d05-6a17-6ba96e5bd174@treenet.co.nz>
 <82c0c153-a128-74fe-c216-6ea9d285d3be@measurement-factory.com>
 <007601d21f63$2189ad60$649d0820$@filter.luko.org>
Message-ID: <462eb323-28dc-45e0-7b5e-eb37aea5df8c@measurement-factory.com>

On 10/05/2016 05:49 PM, squid-users at filter.luko.org wrote:
>> See "early return"
>> statements in clientReplyContext::processReplyAccess(), including:
>>
>>>     /** Don't block our own responses or HTTP status messages */
>>>     if (http->logType.oldType == LOG_TCP_DENIED ||
>>>             http->logType.oldType == LOG_TCP_DENIED_REPLY ||
>>>             alwaysAllowResponse(reply->sline.status())) {
>>>         headers_sz = reply->hdr_sz;
>>>         processReplyAccessResult(ACCESS_ALLOWED);
>>>         return;
>>>     }

> It would be great if there was a way to slow
> down 407 responses; at the moment the only workaround I can think of
> is to write a log-watching script to maintain a list of offending
> IP/domain pairs, then write a helper to use that data to introduce
> delay when the request is first received (via http_access and the
> !all trick).  If anyone has a better option, I'm all ears.

An alternative idea: Change clientReplyContext::processReplyAccess() and
related code so that the http_reply_access ACL is always checked but,
under the conditions quoted above, the result of that check is forced to
be interpreted as ACCESS_ALLOWED.

This alternative requires a little bit of Squid development and testing,
of course, and I am not sure such a trick can be officially accepted.

Alex.



From squid3 at treenet.co.nz  Thu Oct  6 05:45:00 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 6 Oct 2016 18:45:00 +1300
Subject: [squid-users] Whitelist domain ignored?
In-Reply-To: <CABU5kW5=rc8VnxGnagNnhhFONJDCyMctrsW9QtBi_2+hBRmXdA@mail.gmail.com>
References: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>
 <CADSSinNYT4GX5+4YhmF62GvGL2remrHm27Av8kr_V-xgBY3rEg@mail.gmail.com>
 <CABU5kW7eH3MM99YJuAeei-8gUsC5dg7cgh6higznGASG=gA8sg@mail.gmail.com>
 <CADSSinPXUsf5fPUbdzEsV-oafJos0EtaQZhOZK-pZ6ncSS_eYw@mail.gmail.com>
 <CABU5kW5kLn4=2HtueBs0NrkwT+uHkRexyNnpPPQxqV6EqCKndA@mail.gmail.com>
 <c88cca41-ef79-a77d-5e4e-d3ce20f4beb6@measurement-factory.com>
 <CABU5kW7sy9qL3d=8rCR4=ROK4zGLvwp32ZQMPj2Bb8RtmwBniA@mail.gmail.com>
 <32081c3d-3b75-1f36-08a2-8d0bbadb943e@measurement-factory.com>
 <CABU5kW7bLMGtYitztHXJX+REuN4_AKNu_Aesf0_urMDmHuVu9w@mail.gmail.com>
 <CABU5kW5=rc8VnxGnagNnhhFONJDCyMctrsW9QtBi_2+hBRmXdA@mail.gmail.com>
Message-ID: <571e794e-ce7c-336f-8445-89b1f2b9a975@treenet.co.nz>

On 6/10/2016 11:56 a.m., Jose Torres-Berrocal wrote:
> Correcting typo:
> 
> And placing it inside a whitelist.acl file:
> acl whitelist2 dstdom_regex -i "whitelist.acl"
> 
> Where whitelist.acl content:
> ^familymedicinepr\.com$
> ^mail\.yahoo\.com$
> ^neodecksoftware\.com$
> ^office\.net$
> \.familymedicinepr\.com$
> \.mail\.yahoo\.com$
> \.neodecksoftware\.com$
> \.office\.net$
> 

Yes.

There is a simpler way if you are going to insisit on regex instead of
dstdomain. Starting the pattern with an optional '.' character:  \.?

So whitelist.acl content:

\.?familymedicinepr\.com$
\.?mail\.yahoo\.com$
\.?neodecksoftware\.com$
\.?office\.net$


Using dstdomain in this case is better though since the comparison is
shorter and faster than regex.

Amos



From rentorbuy at yahoo.com  Thu Oct  6 06:10:59 2016
From: rentorbuy at yahoo.com (Vieri)
Date: Thu, 6 Oct 2016 06:10:59 +0000 (UTC)
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
 code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <CAPxJK5BD-CnAOWM3Gb+=a+O7UUOBqCuD5_oHvx8WswrGrMtAGQ@mail.gmail.com>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
 <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
 <2077594026.2082495.1475235384241@mail.yahoo.com>
 <af92d108-b205-decb-13c4-fecb7a554b5e@gmail.com>
 <421701582.3214410.1475478705099@mail.yahoo.com>
 <f4e0b806-587c-ed2e-4941-b5cccbcda0d1@treenet.co.nz>
 <1410278953.3964483.1475579267802@mail.yahoo.com>
 <2aeb5cbc-67aa-0742-efb1-ab123c638bc6@treenet.co.nz>
 <CAPxJK5BD-CnAOWM3Gb+=a+O7UUOBqCuD5_oHvx8WswrGrMtAGQ@mail.gmail.com>
Message-ID: <1780209473.10531511.1475734259504@mail.yahoo.com>



----- Original Message -----
> From: Marc <gaardiolor at gmail.com>
> Mimicing in openssl (well.. not perfect but it joes the job I guess):
> openssl s_client -quiet -connect www.google.com:443 -tls1 -cipher

> RC4-MD5:RC4-SHA:DES-CBC3-SHA:DES-CBC-SHA:EXP1024-RC4-SHA:EXP1024-DES-CBC-SHA:EXP-
> RC4-MD5:EXP-RC2-CBC-MD5:DHE-DSS-DES-CBC3-SHA:DHE-DSS-CBC-SHA:EXP1024-DHE-DSS-
> DES-CBC-SHA

> < <(echo -e "GET / HTTP/1.1\nHost: https://www.google.com\n\n")

> SQUID_ERR_SSL_HANDSHAKE


Hi,

Here's what I get when I run the same commands as you did.

# openssl s_client -quiet -connect www.google.com:443 -tls1 -cipher RC4-MD5:RC4-SHA:DES-CBC3-SHA:DES-CBC-SHA:EXP1024-RC4-SHA:EXP1024-DES-CBC-SHA:EXP-RC4-MD5:EXP-RC2-CBC-MD5:DHE-DSS-DES-CBC3-SHA:DHE-DSS-CBC-SHA:EXP1024-DHE-DSS-DES-CBC-SHA < <(echo -e "GET / HTTP/1.1\nHost: https://www.google.com\n\n")
depth=3 C = US, O = Equifax, OU = Equifax Secure Certificate Authority
verify return:1
depth=2 C = US, O = GeoTrust Inc., CN = GeoTrust Global CA
verify return:1
depth=1 C = US, O = Google Inc, CN = Google Internet Authority G2
verify return:1
depth=0 C = US, ST = California, L = Mountain View, O = Google Inc, CN = www.google.com
verify return:1
HTTP/1.1 400 Bad Request
Content-Length: 54
Content-Type: text/html; charset=UTF-8
Date: Thu, 06 Oct 2016 06:04:47 GMT
Connection: close

<html><title>Error 400 (Bad Request)!!1</title></html>read:errno=0

# openssl s_client -connect www.google.com:443 -tls1 -cipher RC4-MD5:RC4-SHA:DES-CBC3-SHA:DES-CBC-SHA:EXP1024-RC4-SHA:EXP1024-DES-CBC-SHA:EXP-RC4-MD5:EXP-RC2-CBC-MD5:DHE-DSS-DES-CBC3-SHA:DHE-DSS-CBC-SHA:EXP1024-DHE-DSS-DES-CBC-SHA

[...]
SSL-Session:
Protocol  : TLSv1
Cipher    : DES-CBC3-SHA
[...]


As you can see I'm not getting the SSL handshake error.


Using openssl-1.0.2d.

Vieri


From squid3 at treenet.co.nz  Thu Oct  6 06:19:08 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 6 Oct 2016 19:19:08 +1300
Subject: [squid-users] Problem with Squid3 Caches
In-Reply-To: <9BD4DA71-18E9-45E0-8BF8-52149DC38289@gmail.com>
References: <CD14793F-4F48-433E-9A1E-B2030E1D7F14@gmail.com>
 <201610032306.15880.Antony.Stone@squid.open.source.it>
 <B0508516-890C-4526-8848-78616839ABA5@gmail.com>
 <201610041745.20899.Antony.Stone@squid.open.source.it>
 <7DE7A0D4-9C50-48EF-A297-9E65A7E45AC8@gmail.com>
 <9c5a8d4f-40b3-939c-b22a-b57181f8f0ff@treenet.co.nz>
 <9BD4DA71-18E9-45E0-8BF8-52149DC38289@gmail.com>
Message-ID: <2b123df7-bdec-0146-3454-a7e2b71bfffe@treenet.co.nz>

On 6/10/2016 11:27 a.m., KR wrote:
> Hello Amos,
> 
> 
>> On Oct 5, 2016, at 9:07 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>
>> On 5/10/2016 6:48 a.m., KR wrote:
>>> I uncommented that line and now I get
>>>
>>> Initializing the Squid cache with the command squid3 -f /etc/squid/squid.conf -z ..
>>>
>>
>> Hmm. The 'squid3' package should have config files at /etc/squid3/*
>>
>> The 'squid' package has config files at /etc/squid/*
> 
> 
> It seems I have the /etc/squid/* package and NOT squid3.  Not sure why this is referencing squid3.  What?s the difference?
> 

They packaged Squid-2 under the name 'squid' for many years, and
followed the 2.6/2.7 fork with that package name.
 while packaging Squid-3 as 'squid3'. Then when Squid-2 was dropped
Ubuntu migrated everyone to 'squid3' package.

The naming is finally getting back to being 'squid' with only latest
version available.



> 
>>> FATAL: Bungled /etc/squid/squid.conf line 3410: cache_dir rock /hdd1 ... min-size=100000
>>
>> Is that an exact copy-paste of the output?
>> Are the "..." characters really in your config file?
>>
>> If yes, the problem is that somebody has mindlessly cut-n-pasted
>> incomplete example config line(s) into your squid.conf.
>>
>> If no, then the problem is that you are hiding the broken piece of
>> config from us.
>>
>> Either way you have something to fix.
> 
> 
> That is exactly the error message I get.  It?s not in the config file.

That error message existing means the line *does* exist in the
squid.conf file you are loading.

The lack of '#' at the beginning of some lines you quoted below means
that those lines *are* being passed to Squid as active config to use.

> 
> #		store_dir_select_algorithm round-robin
> #		cache_dir rock /hdd1 ... min-size=100000
> #		cache_dir rock /ssd1 ... max-size=99999
> #		cache_dir rock /hdd2 ... min-size=100000
> #		cache_dir rock /ssd2 ... max-size=99999
> #		cache_dir rock /hdd3 ... min-size=100000
> #		cache_dir rock /ssd3 ... max-size=99999
> cache_dir rock /ssd1 ... max-size=99999
> cache_dir rock /hdd2 ... min-size=100000
> cache_dir rock /ssd2 ... max-size=99999
> cache_dir rock /hdd3 ... min-size=100000
> cache_dir rock /ssd3 ... max-size=99999
> 

That is a piece of example documentation being used blindly without
reading the actual documentation it is part of.

It is not even docs about the cache_dir directive!

The reason the "..." exist is that the documentation is explaining how
to use *store_dir_select_algorithm*. The settings other than the shown
ones are irrelevant for that documentation and being skipped.


Amos



From patrick.chemla at performance-managers.com  Thu Oct  6 07:16:41 2016
From: patrick.chemla at performance-managers.com (Patrick Chemla)
Date: Thu, 6 Oct 2016 10:16:41 +0300
Subject: [squid-users] Groups of peers load-balancing
Message-ID: <f9140615-f35a-f0b5-64b9-71a1f11c72ad@performance-managers.com>

Hi,

I am using Squid Cache: Version 3.5.20 on 2 Fedora 24 server.

I have to set a load-balancer for multiple sites, each using different 
peers, on both servers + cloud instances.

Squid is the entry point for all websites. According to the domain, I 
will have 2 to 5 peers to handle the load. But, as I have 2 big domains, 
and a group of other domains, I need dedicated peers for each big 
domains, and another groups of peers for other domains.

So squid must route requests :

- for domain A to peers A1 A2 A3

- for domain B to peers B1 B2 B3 B4 B5

- for all other domains to peers O1 O2

Load balancing method within a group could be different, as some domains 
need user to reach always same peer, when other domain could simply 
handle round-robin balancing.

I can't find how to group peers A1 A2 A3 to group A, peers B1 B2..B5 to 
group B, O1 O2 to group O, then set the cache_peer_access to the needed 
group.

Can you help? Do you have similar examples?

Thanks

Patrick




From rentorbuy at yahoo.com  Thu Oct  6 07:46:37 2016
From: rentorbuy at yahoo.com (Vieri)
Date: Thu, 6 Oct 2016 07:46:37 +0000 (UTC)
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
 code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <2aeb5cbc-67aa-0742-efb1-ab123c638bc6@treenet.co.nz>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
 <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
 <2077594026.2082495.1475235384241@mail.yahoo.com>
 <af92d108-b205-decb-13c4-fecb7a554b5e@gmail.com>
 <421701582.3214410.1475478705099@mail.yahoo.com>
 <f4e0b806-587c-ed2e-4941-b5cccbcda0d1@treenet.co.nz>
 <1410278953.3964483.1475579267802@mail.yahoo.com>
 <2aeb5cbc-67aa-0742-efb1-ab123c638bc6@treenet.co.nz>
Message-ID: <506329095.5248673.1475739997409@mail.yahoo.com>

Hi,



----- Original Message -----
> From: Amos Jeffries <squid3 at treenet.co.nz>
>> Is it correct to assume at this point that the current openssl build
>> on this system is "OK" as far as supporting "Win XP TLS 1.0 ciphers
>> to access at least google.com"?
>
> Yes. The build is capable of it. That is one of 3 conditions that must

> be met for it to work.> 
> The other two being:
>
> * whether it is enabled in the library config.
> - OpenSSL library has its own conf file somewhere.
> - it is possible that curl and other tools whose primary design purpose

> is communication (not testing) override the library normal defaults for> their own use, or re-try certain things after failures. That needs to be

> eliminated to be sure.> 
> * that the squid.conf settings combine with those library settings to

> cause it to be (or stay) enabled.[...]
> So far we can assume that it is either a Squid bug relaying the

> available cipher list between the two remote endpoints. Or that the set
> of ciphers available to Squid does not include the DES-CBC3-SHA one.[...]

> The fact that the library can be

> configured independent of any application using it throws a rather big

> spanner into the expected behaviour logics.
[...]
> So far your tests are showing that it is about a 50/50 chance of being a
> bug in Squid versus a Squid/OpenSSL misconfiguration somewhere.


I don't know what a library configuration file is. OpenSSL has a CONF library/functions to read its own .cnf files. An application such as Squid can use these functions to read a conf file, or not.

I'm assuming that at compile time, both the openssl library and squid were built with most features.
Is there a way to list available openssl ciphers from squid (like a squid command line tool)?
As if Squid were to call an openssl library function to "list available ciphers",or something.


> To test that last detail you probably need to setup a normal https_port
> with SSL and see if you can connect to it with TLSv1.0 and only that
> cipher in curl. That will eliminate any possible server details
> polluting the test result.

What is a "normal https_port with SSL"?
eg. https_port 3132 cert=/etc/ssl/squid/proxyserver.pem
I would appreciate a full conf example so there are no squid misconfigurations that would make the test results even more confusing.

BTW, does sslproxy_cipher default to ALL if undefined in squid.conf?

> So throwing blame at anyone when it "fails" without a bug being clearly

> in evidence is the wrong thing to do. It is usually a sign that
> everybody is actually doing "The Right Thing".

Correct me if I'm wrong but I sense friction here. It was not my intention of "blaming" anyone. That's a harsh word, in my opinion. I love Squid. As with many huge projects, there are bound to be bugs or lacking features. I never said it WAS the case here anyway. I'm just trying to help and pinpoint the root cause of an issue I'm seeing. I guess I'm frustrated because I still have WinXP&IE8 clients lying around and I'm sure that's the sole source of problems. Squid "debug_options" is already very verbose but maybe it would help in this case to add extra information as to how Squid is calling openssl (and maybe seeing if it's possible to get the cipher list). 


Thanks,

Vieri


From george.herbert at gmail.com  Thu Oct  6 07:52:03 2016
From: george.herbert at gmail.com (George William Herbert)
Date: Thu, 6 Oct 2016 00:52:03 -0700
Subject: [squid-users] Groups of peers load-balancing
In-Reply-To: <f9140615-f35a-f0b5-64b9-71a1f11c72ad@performance-managers.com>
References: <f9140615-f35a-f0b5-64b9-71a1f11c72ad@performance-managers.com>
Message-ID: <BEFCD64A-9043-4998-8717-907F87DABF92@gmail.com>

Usually you load balance with another tool...

Sent from my iPhone

> On Oct 6, 2016, at 12:16 AM, Patrick Chemla <patrick.chemla at performance-managers.com> wrote:
> 
> Hi,
> 
> I am using Squid Cache: Version 3.5.20 on 2 Fedora 24 server.
> 
> I have to set a load-balancer for multiple sites, each using different peers, on both servers + cloud instances.
> 
> Squid is the entry point for all websites. According to the domain, I will have 2 to 5 peers to handle the load. But, as I have 2 big domains, and a group of other domains, I need dedicated peers for each big domains, and another groups of peers for other domains.
> 
> So squid must route requests :
> 
> - for domain A to peers A1 A2 A3
> 
> - for domain B to peers B1 B2 B3 B4 B5
> 
> - for all other domains to peers O1 O2
> 
> Load balancing method within a group could be different, as some domains need user to reach always same peer, when other domain could simply handle round-robin balancing.
> 
> I can't find how to group peers A1 A2 A3 to group A, peers B1 B2..B5 to group B, O1 O2 to group O, then set the cache_peer_access to the needed group.
> 
> Can you help? Do you have similar examples?
> 
> Thanks
> 
> Patrick
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From fredbmail at free.fr  Thu Oct  6 08:57:08 2016
From: fredbmail at free.fr (FredB)
Date: Thu, 6 Oct 2016 10:57:08 +0200 (CEST)
Subject: [squid-users] SSO and Squid, SAML 2.0 ?
In-Reply-To: <1840934395.926545982.1474636435138.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <780003625.970981473.1475744228890.JavaMail.root@zimbra4-e1.priv.proxad.net>

Hello,

I found no way to do that, so I changed my mind
I can authenticate a user to squid with a certificate ? I'm thinking about a smart card 

If yes the user name can be saved in squid log file ?

Thanks

Fred


 


From squid3 at treenet.co.nz  Thu Oct  6 10:05:36 2016
From: squid3 at treenet.co.nz (squid-users)
Date: RANDOM_Thu, 6 Oct 2016 13:05:36 +0300
Subject: [squid-users] pleasant surprise
Message-ID: <0000d1b60076$f3aa67d3$28c987f7$@treenet.co.nz>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161006/ce47ae9f/attachment.htm>

From squid3 at treenet.co.nz  Thu Oct  6 10:11:27 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 6 Oct 2016 23:11:27 +1300
Subject: [squid-users] Groups of peers load-balancing
In-Reply-To: <BEFCD64A-9043-4998-8717-907F87DABF92@gmail.com>
References: <f9140615-f35a-f0b5-64b9-71a1f11c72ad@performance-managers.com>
 <BEFCD64A-9043-4998-8717-907F87DABF92@gmail.com>
Message-ID: <d63bd54b-d7b6-245f-4521-993ec35c3765@treenet.co.nz>

On 6/10/2016 8:52 p.m., George William Herbert wrote:
> Usually you load balance with another tool...

HTTP Load Balancer is one of the roles Squid is designed for.

When you need to converge the LB, routing, and caching tasks Squid is
the product for the job.

> 
>> On Oct 6, 2016, at 12:16 AM, Patrick Chemla wrote:
>> 
>> Hi,
>> 
>> I am using Squid Cache: Version 3.5.20 on 2 Fedora 24 server.
>> 
>> I have to set a load-balancer for multiple sites, each using
>> different peers, on both servers + cloud instances.
>> 
>> Squid is the entry point for all websites. According to the domain,
>> I will have 2 to 5 peers to handle the load. But, as I have 2 big
>> domains, and a group of other domains, I need dedicated peers for
>> each big domains, and another groups of peers for other domains.
>> 
>> So squid must route requests :
>> 
>> - for domain A to peers A1 A2 A3
>> 
>> - for domain B to peers B1 B2 B3 B4 B5
>> 
>> - for all other domains to peers O1 O2
>> 
>> Load balancing method within a group could be different, as some
>> domains need user to reach always same peer, when other domain
>> could simply handle round-robin balancing.
>> 
>> I can't find how to group peers A1 A2 A3 to group A, peers B1
>> B2..B5 to group B, O1 O2 to group O, then set the cache_peer_access
>> to the needed group.

Grouping is done by cache_peer_access ACLs.

You need to define one ACL which will only match for one group.
Typically the domain name is used for that. The "group" is simply the
peers which the request is allowed to be sent to.

For example:

 acl groupA dstdomain .example.com
 acl groupB dstdomain .example.net
 acl groupO dstdomain .example.org

 cache_peer_access A1 allow groupA
 cache_peer_access A1 deny all
 cache_peer_access A2 allow groupA
 cache_peer_access A2 deny all
 ...

 cache_peer_access B1 allow groupB
 cache_peer_access B1 deny all
 cache_peer_access B2 allow groupB
 cache_peer_access B2 deny all
 ...


Since your peers are split into distinct groups just add the relevant
algorithm to the cache_peer in that group which is using it.

Things can get complex if you have one peer being part of two groups.
But then you just define two cache_peer lines for it, one in each group
with the relevant LB algorithm. The name= parameter is used distinguish
which cache_peer line is relevant for the cache_peer_access rules.

Amos



From squid3 at treenet.co.nz  Thu Oct  6 10:17:50 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 6 Oct 2016 23:17:50 +1300
Subject: [squid-users] SSO and Squid, SAML 2.0 ?
In-Reply-To: <780003625.970981473.1475744228890.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <780003625.970981473.1475744228890.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <b780d747-ee95-445a-c426-643326dfa36e@treenet.co.nz>

On 6/10/2016 9:57 p.m., FredB wrote:
> Hello,
> 
> I found no way to do that, so I changed my mind
> I can authenticate a user to squid with a certificate ? I'm thinking about a smart card 
> 
> If yes the user name can be saved in squid log file ?
> aking a


Maybe.

There is some very old logic for checking client certificates. The
https_port clientca= parameter enables that. AFAIK you simply configure
it with the CA certificate that was used to issue the client certs and
the rest is automatic.

There are also client cert logformat codes, and the generic %un has code
to pull a 'cert username' from a cert.

I'm not aware of anyone actually using that feature in the a long time
though. So YMMV.

HTH
Amos



From squid3 at treenet.co.nz  Thu Oct  6 10:57:39 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 6 Oct 2016 23:57:39 +1300
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
 code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <506329095.5248673.1475739997409@mail.yahoo.com>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
 <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
 <2077594026.2082495.1475235384241@mail.yahoo.com>
 <af92d108-b205-decb-13c4-fecb7a554b5e@gmail.com>
 <421701582.3214410.1475478705099@mail.yahoo.com>
 <f4e0b806-587c-ed2e-4941-b5cccbcda0d1@treenet.co.nz>
 <1410278953.3964483.1475579267802@mail.yahoo.com>
 <2aeb5cbc-67aa-0742-efb1-ab123c638bc6@treenet.co.nz>
 <506329095.5248673.1475739997409@mail.yahoo.com>
Message-ID: <586bfd7a-ce0b-5654-a63c-da03e20a0bcb@treenet.co.nz>

On 6/10/2016 8:46 p.m., Vieri wrote:
> Hi,
> 
> 
> 
> ----- Original Message -----
>> From: Amos Jeffries <squid3 at treenet.co.nz>
>>> Is it correct to assume at this point that the current openssl
>>> build on this system is "OK" as far as supporting "Win XP TLS 1.0
>>> ciphers to access at least google.com"?
>> 
>> Yes. The build is capable of it. That is one of 3 conditions that
>> must
> 
>> be met for it to work.> The other two being:
>> 
>> * whether it is enabled in the library config. - OpenSSL library
>> has its own conf file somewhere. - it is possible that curl and
>> other tools whose primary design purpose
> 
>> is communication (not testing) override the library normal defaults
>> for> their own use, or re-try certain things after failures. That
>> needs to be
> 
>> eliminated to be sure.> * that the squid.conf settings combine with
>> those library settings to
> 
>> cause it to be (or stay) enabled.[...] So far we can assume that it
>> is either a Squid bug relaying the
> 
>> available cipher list between the two remote endpoints. Or that the
>> set of ciphers available to Squid does not include the DES-CBC3-SHA
>> one.[...]
> 
>> The fact that the library can be
> 
>> configured independent of any application using it throws a rather
>> big
> 
>> spanner into the expected behaviour logics.
> [...]
>> So far your tests are showing that it is about a 50/50 chance of
>> being a bug in Squid versus a Squid/OpenSSL misconfiguration
>> somewhere.
> 
> 
> I don't know what a library configuration file is. OpenSSL has a CONF
> library/functions to read its own .cnf files. An application such as
> Squid can use these functions to read a conf file, or not.

Unless I'm totally confused there is a system-wide conf file that the
library can/does load on its own before all that.

> 
> I'm assuming that at compile time, both the openssl library and squid
> were built with most features. Is there a way to list available
> openssl ciphers from squid (like a squid command line tool)? As if
> Squid were to call an openssl library function to "list available
> ciphers",or something.

Unfortunately not. Squid (mostly) passes the squid.conf strings directly
to the library parser so that list the library produced should be what
Squid is _able_ to use. The detail to be careful of is whether
squid.conf contains any such strings that change the library defaults.

> 
>> To test that last detail you probably need to setup a normal
>> https_port with SSL and see if you can connect to it with TLSv1.0
>> and only that cipher in curl. That will eliminate any possible
>> server details polluting the test result.
> 
> What is a "normal https_port with SSL"? eg. https_port 3132
> cert=/etc/ssl/squid/proxyserver.pem I would appreciate a full conf
> example so there are no squid misconfigurations that would make the
> test results even more confusing.

I mean an https_port that is not doing ssl-bump or intercept.

 https_port 3129 ssl \
   cert=/etc/ssl/squid/cert.pem \
   key=/etc/ssl/squid/key.pam

(unless you have cert + key in the same .pem, then key= is not needed)

> 
> BTW, does sslproxy_cipher default to ALL if undefined in squid.conf?
> 

No.

If undefined in squid.conf the library default ciphers are used. In
recent years that has been a bit volatile and changes with library
version, so I cant be more specific.

"ALL" enables a lot of ciphers and TLS/SSL features that were known to
be unsafe when the library was released. So are not included in the
default available set.


>. Squid
> "debug_options" is already very verbose but maybe it would help in
> this case to add extra information as to how Squid is calling openssl
> (and maybe seeing if it's possible to get the cipher list).
> 

Good idea. Thanks.

Amos


From chip_pop at hotmail.com  Thu Oct  6 10:55:28 2016
From: chip_pop at hotmail.com (joe)
Date: Thu, 6 Oct 2016 03:55:28 -0700 (PDT)
Subject: [squid-users] to all please read
Message-ID: <1475751328916-4679954.post@n4.nabble.com>

im not going to re and re and re lablabla for nothing
all of you should go read and VOTE this squid project we all suport it even
by someone donate or pay 
and most of the rest report bug and even fix code for free
so wat do you want




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/to-all-please-read-tp4679954.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Thu Oct  6 10:57:36 2016
From: chip_pop at hotmail.com (joe)
Date: Thu, 6 Oct 2016 03:57:36 -0700 (PDT)
Subject: [squid-users] to all please read
In-Reply-To: <1475751328916-4679954.post@n4.nabble.com>
References: <1475751328916-4679954.post@n4.nabble.com>
Message-ID: <1475751456801-4679955.post@n4.nabble.com>

sorry  forgot the link
http://bugs.squid-cache.org/show_bug.cgi?id=4604



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/to-all-please-read-tp4679954p4679955.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid-user at tlinx.org  Thu Oct  6 17:14:56 2016
From: squid-user at tlinx.org (Linda A. Walsh)
Date: Thu, 06 Oct 2016 10:14:56 -0700
Subject: [squid-users] Caching http google deb files
In-Reply-To: <1ba79370-ff21-0e52-a5dc-89919c1171b4@measurement-factory.com>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
 <CA+sSnVZ2ErFD+LeLVH3KOjJ_0PuqGyWfRHA23zY8yJQs3kP+Rw@mail.gmail.com>
 <89f9840b-7ec7-2f0b-a81c-5376c344878e@treenet.co.nz>
 <CA+sSnVYCy5E00jKK5cPZm3q+eBX8Fx=Mjs_iu4Xs0oebxcte9Q@mail.gmail.com>
 <1ba79370-ff21-0e52-a5dc-89919c1171b4@measurement-factory.com>
Message-ID: <57F68690.1020109@tlinx.org>

Alex Rousskov wrote:
> We can, but ignoring Vary requires more/different work than adding
> another refresh_pattern option. Vary is not a refresh mechanism so
> different code areas need to be modified to ignore (but still forward!)
> Vary.
>   
----
    I can't say for certain, but I'd give it a 75% shot of it being
used as a forced-refresh pattern because more browser-agents (as well
as caching solutions) are ignoring other refresh options to not have
to download unchanging content. 

    Much of google's "ssl-everywhere", IMO, is all about disabling
the ability to have common caches for multiple users so they can
track the multiple downloads and the users.




From rousskov at measurement-factory.com  Thu Oct  6 17:28:28 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 6 Oct 2016 11:28:28 -0600
Subject: [squid-users] Whitelist domain ignored?
In-Reply-To: <571e794e-ce7c-336f-8445-89b1f2b9a975@treenet.co.nz>
References: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>
 <CADSSinNYT4GX5+4YhmF62GvGL2remrHm27Av8kr_V-xgBY3rEg@mail.gmail.com>
 <CABU5kW7eH3MM99YJuAeei-8gUsC5dg7cgh6higznGASG=gA8sg@mail.gmail.com>
 <CADSSinPXUsf5fPUbdzEsV-oafJos0EtaQZhOZK-pZ6ncSS_eYw@mail.gmail.com>
 <CABU5kW5kLn4=2HtueBs0NrkwT+uHkRexyNnpPPQxqV6EqCKndA@mail.gmail.com>
 <c88cca41-ef79-a77d-5e4e-d3ce20f4beb6@measurement-factory.com>
 <CABU5kW7sy9qL3d=8rCR4=ROK4zGLvwp32ZQMPj2Bb8RtmwBniA@mail.gmail.com>
 <32081c3d-3b75-1f36-08a2-8d0bbadb943e@measurement-factory.com>
 <CABU5kW7bLMGtYitztHXJX+REuN4_AKNu_Aesf0_urMDmHuVu9w@mail.gmail.com>
 <CABU5kW5=rc8VnxGnagNnhhFONJDCyMctrsW9QtBi_2+hBRmXdA@mail.gmail.com>
 <571e794e-ce7c-336f-8445-89b1f2b9a975@treenet.co.nz>
Message-ID: <170d047f-c446-07bc-dbd9-2fbb5e6e1e11@measurement-factory.com>

On 10/05/2016 11:45 PM, Amos Jeffries wrote:
> On 6/10/2016 11:56 a.m., Jose Torres-Berrocal wrote:
>> acl whitelist2 dstdom_regex -i "whitelist.acl"
>>
>> Where whitelist.acl content:
>> ^familymedicinepr\.com$
>> ^mail\.yahoo\.com$
>> ^neodecksoftware\.com$
>> ^office\.net$
>> \.familymedicinepr\.com$
>> \.mail\.yahoo\.com$
>> \.neodecksoftware\.com$
>> \.office\.net$


> There is a simpler way if you are going to insisit on regex instead of
> dstdomain. Starting the pattern with an optional '.' character:  \.?
> 
> So whitelist.acl content:
> 
> \.?familymedicinepr\.com$
> \.?mail\.yahoo\.com$
> \.?neodecksoftware\.com$
> \.?office\.net$

That simpler way is incorrect AFAICT: The top/correct ACL list does not
match "xoffice.net" but yours does.

Alex.



From rousskov at measurement-factory.com  Thu Oct  6 17:44:54 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 6 Oct 2016 11:44:54 -0600
Subject: [squid-users] SSO and Squid, SAML 2.0 ?
In-Reply-To: <b780d747-ee95-445a-c426-643326dfa36e@treenet.co.nz>
References: <780003625.970981473.1475744228890.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <b780d747-ee95-445a-c426-643326dfa36e@treenet.co.nz>
Message-ID: <5d4c6855-5466-01e2-c924-a6fb6756fca9@measurement-factory.com>

On 10/06/2016 04:17 AM, Amos Jeffries wrote:
> On 6/10/2016 9:57 p.m., FredB wrote:
>> I can authenticate a user to squid with a certificate ?
>> If yes the user name can be saved in squid log file ?


> I'm not aware of anyone actually using that feature in the a long time
> though. So YMMV.

I am aware of folks successfully using certificate-based authentication
in production today, but they are still running v3.3-based code (plus
many patches). I am not aware of any regressions in that area, but since
there is no adequate regression testing, Amos is right: YMMV.

Alex.



From jetsystemservices at gmail.com  Thu Oct  6 17:52:22 2016
From: jetsystemservices at gmail.com (Jose Torres-Berrocal)
Date: Thu, 6 Oct 2016 13:52:22 -0400
Subject: [squid-users] Whitelist domain ignored?
In-Reply-To: <170d047f-c446-07bc-dbd9-2fbb5e6e1e11@measurement-factory.com>
References: <CABU5kW7VtfdwLi=bpmq4fy307=z1JaK8kMpGD_zR8sLTV=bnLA@mail.gmail.com>
 <CADSSinNYT4GX5+4YhmF62GvGL2remrHm27Av8kr_V-xgBY3rEg@mail.gmail.com>
 <CABU5kW7eH3MM99YJuAeei-8gUsC5dg7cgh6higznGASG=gA8sg@mail.gmail.com>
 <CADSSinPXUsf5fPUbdzEsV-oafJos0EtaQZhOZK-pZ6ncSS_eYw@mail.gmail.com>
 <CABU5kW5kLn4=2HtueBs0NrkwT+uHkRexyNnpPPQxqV6EqCKndA@mail.gmail.com>
 <c88cca41-ef79-a77d-5e4e-d3ce20f4beb6@measurement-factory.com>
 <CABU5kW7sy9qL3d=8rCR4=ROK4zGLvwp32ZQMPj2Bb8RtmwBniA@mail.gmail.com>
 <32081c3d-3b75-1f36-08a2-8d0bbadb943e@measurement-factory.com>
 <CABU5kW7bLMGtYitztHXJX+REuN4_AKNu_Aesf0_urMDmHuVu9w@mail.gmail.com>
 <CABU5kW5=rc8VnxGnagNnhhFONJDCyMctrsW9QtBi_2+hBRmXdA@mail.gmail.com>
 <571e794e-ce7c-336f-8445-89b1f2b9a975@treenet.co.nz>
 <170d047f-c446-07bc-dbd9-2fbb5e6e1e11@measurement-factory.com>
Message-ID: <CABU5kW7LpD8PPKiTadH5pHvVSDGy_WHLkxLxND5SNGTvpAn4YA@mail.gmail.com>

"dstdomain .office.net" does not match xoffice.net domain.  I do not
want to match xoffice.net with the regex.

So I should use my own last version, right?
Jose E Torres
939-777-4030
JET System Services


On Thu, Oct 6, 2016 at 1:28 PM, Alex Rousskov
<rousskov at measurement-factory.com> wrote:
> On 10/05/2016 11:45 PM, Amos Jeffries wrote:
>> On 6/10/2016 11:56 a.m., Jose Torres-Berrocal wrote:
>>> acl whitelist2 dstdom_regex -i "whitelist.acl"
>>>
>>> Where whitelist.acl content:
>>> ^familymedicinepr\.com$
>>> ^mail\.yahoo\.com$
>>> ^neodecksoftware\.com$
>>> ^office\.net$
>>> \.familymedicinepr\.com$
>>> \.mail\.yahoo\.com$
>>> \.neodecksoftware\.com$
>>> \.office\.net$
>
>
>> There is a simpler way if you are going to insisit on regex instead of
>> dstdomain. Starting the pattern with an optional '.' character:  \.?
>>
>> So whitelist.acl content:
>>
>> \.?familymedicinepr\.com$
>> \.?mail\.yahoo\.com$
>> \.?neodecksoftware\.com$
>> \.?office\.net$
>
> That simpler way is incorrect AFAICT: The top/correct ACL list does not
> match "xoffice.net" but yours does.
>
> Alex.
>


From rousskov at measurement-factory.com  Thu Oct  6 17:55:27 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 6 Oct 2016 11:55:27 -0600
Subject: [squid-users] Caching http google deb files
In-Reply-To: <57F68690.1020109@tlinx.org>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
 <CA+sSnVZ2ErFD+LeLVH3KOjJ_0PuqGyWfRHA23zY8yJQs3kP+Rw@mail.gmail.com>
 <89f9840b-7ec7-2f0b-a81c-5376c344878e@treenet.co.nz>
 <CA+sSnVYCy5E00jKK5cPZm3q+eBX8Fx=Mjs_iu4Xs0oebxcte9Q@mail.gmail.com>
 <1ba79370-ff21-0e52-a5dc-89919c1171b4@measurement-factory.com>
 <57F68690.1020109@tlinx.org>
Message-ID: <2c043b07-b941-9e29-8813-4642070384f6@measurement-factory.com>

On 10/06/2016 11:14 AM, Linda A. Walsh wrote:
> Alex Rousskov wrote:
>> We can, but ignoring Vary requires more/different work than adding
>> another refresh_pattern option. Vary is not a refresh mechanism so
>> different code areas need to be modified to ignore (but still forward!)
>> Vary.


>    I can't say for certain, but I'd give it a 75% shot of it being
> used as a forced-refresh pattern

The [ab]use cases do not matter here -- the _code_ handling Vary is very
different from the code handling refresh logic. That difference is
natural and unavoidable because the two protocol mechanisms are very
different, even if they both can be and are used to create the same effect.

Alex.



From jetsystemservices at gmail.com  Thu Oct  6 18:28:03 2016
From: jetsystemservices at gmail.com (Jose Torres-Berrocal)
Date: Thu, 6 Oct 2016 14:28:03 -0400
Subject: [squid-users] Whitelist domain ignored?
In-Reply-To: <t0l7g9ft2d8q42uudnmscth1.1475776670629@email.lge.com>
References: <t0l7g9ft2d8q42uudnmscth1.1475776670629@email.lge.com>
Message-ID: <CABU5kW4hoRkh6-_gg_DoQTUfCCVP3x8gt1JPSC-SLFo+55EFOw@mail.gmail.com>

Benjamin:

The situation is that I am using squid as a pfsense firewall package.
The squid package is made that a user should enter a whitelist in a
GUI that when saved generates the squid.conf file.  Internally they
use dstdom_regex  instead of dstdomain so the whitelist should be
entered for the regex format not for the dstdomain format.

The squid package maintainer probably made a mistake or do not have a
full understanding of the dstdom_regex, or was lazy explaining how the
whitelist box in his GUI was supposed to be used.

I want to know the correct format to make it work correctly and post
the formula in the pfsense forum as others could benefit from your
support.   I want to provide how to use dstdomain withing the package
GUI capacities and the regex correct use.  Others will decide the
solution they will use.


Jose E Torres
939-777-4030
JET System Services


On Thu, Oct 6, 2016 at 1:57 PM, Benjamin E. Nichols
<webmaster at squidblacklist.org> wrote:
> I think you are creating more work for yourself. What is the practical
> advantage using regex. When you clearly arent doing url blacklisting. But
> rather domain blacklisting. Its uneccesary and pointless.
>
>
>  Benjamin  E. Nichols
>
> http://www.squidblacklist.org
>
>
> 1-405-397-1360
>
>
> ------ Original message------
>
> From: Jose Torres-Berrocal
>
> Date: Thu, Oct 6, 2016 12:52 PM
>
> To: Alex Rousskov;
>
> Cc: Squid Users;
>
> Subject:Re: [squid-users] Whitelist domain ignored?
>
>
> "dstdomain .office.net" does not match xoffice.net domain.  I do notwant to
> match xoffice.net with the regex.So I should use my own last version,
> right?Jose E Torres939-777-4030JET System ServicesOn Thu, Oct 6, 2016 at
> 1:28 PM, Alex Rousskov wrote:> On 10/05/2016 11:45 PM, Amos Jeffries
> wrote:>> On 6/10/2016 11:56 a.m., Jose Torres-Berrocal wrote:>>> acl
> whitelist2 dstdom_regex -i "whitelist.acl">>>>>> Where whitelist.acl
> content:>>> ^familymedicinepr.com$>>> ^mail.yahoo.com$>>>
> ^neodecksoftware.com$>>> ^office.net$>>> .familymedicinepr.com$>>>
> .mail.yahoo.com$>>> .neodecksoftware.com$>>> .office.net$>>>> There is a
> simpler way if you are going to insisit on regex instead of>> dstdomain.
> Starting the pattern with an optional '.' character:  .?>>>> So
> whitelist.acl content:>>>> .?familymedicinepr.com$>> .?mail.yahoo.com$>>
> .?neodecksoftware.com$>> .?office.net$>> That simpler way is incorrect
> AFAICT: The top/correct ACL list does not> match "xoffice.net" but yours
> does.>> Alex.>_______________________________________________squid-users
> mailing
> listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users


From gaardiolor at gmail.com  Thu Oct  6 21:00:21 2016
From: gaardiolor at gmail.com (Marc)
Date: Thu, 6 Oct 2016 23:00:21 +0200
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
 code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <1780209473.10531511.1475734259504@mail.yahoo.com>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
 <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
 <2077594026.2082495.1475235384241@mail.yahoo.com>
 <af92d108-b205-decb-13c4-fecb7a554b5e@gmail.com>
 <421701582.3214410.1475478705099@mail.yahoo.com>
 <f4e0b806-587c-ed2e-4941-b5cccbcda0d1@treenet.co.nz>
 <1410278953.3964483.1475579267802@mail.yahoo.com>
 <2aeb5cbc-67aa-0742-efb1-ab123c638bc6@treenet.co.nz>
 <CAPxJK5BD-CnAOWM3Gb+=a+O7UUOBqCuD5_oHvx8WswrGrMtAGQ@mail.gmail.com>
 <1780209473.10531511.1475734259504@mail.yahoo.com>
Message-ID: <CAPxJK5Bifwae+-h9Yrpvvpjh=zLGJoD2e-49bsPqA9LguMY=kw@mail.gmail.com>

Hi Viery,

Sorry, copy/paste error, my bad. Please try:

openssl s_client -quiet -connect www.google.com:443 -tls1 -cipher
RC4-MD5:RC4-SHA:DES-CBC3-SHA:DES-CBC-SHA:EXP1024-RC4-SHA:EXP1024-DES-CBC-SHA:EXP-RC4-MD5:EXP-RC2-CBC-MD5:DHE-DSS-DES-CBC3-SHA:DHE-DSS-CBC-SHA:EXP1024-DHE-DSS-DES-CBC-SHA
< <(echo -e "GET / HTTP/1.1\nHost: www.google.com\n\n")
That one fails (at least with me). Squid replies with 503 Service
unavailable, SQUID_ERR_SSL_HANDSHAKE .

Now adding a random extension:
openssl s_client -quiet -connect www.google.com:443 -tls1 -cipher
RC4-MD5:RC4-SHA:DES-CBC3-SHA:DES-CBC-SHA:EXP1024-RC4-SHA:EXP1024-DES-CBC-SHA:EXP-RC4-MD5:EXP-RC2-CBC-MD5:DHE-DSS-DES-CBC3-SHA:DHE-DSS-CBC-SHA:EXP1024-DHE-DSS-DES-CBC-SHA
-serverinfo 12345 < <(echo -e "GET / HTTP/1.1\nHost:
www.google.com\n\n")
That one succeeds (302 Found). At least with me. The extension doesn't
have to be 12345, some regular ones do the trick as well. But openssl
doesn't always include the existing ones correctly, so I used the
dummy.

Please let me know. If adding a random extension fixes the error with
you too, well.. It could be a step in the right direction towards
finding the cause of this problem.

Marc


From patrick.chemla at performance-managers.com  Fri Oct  7 06:17:03 2016
From: patrick.chemla at performance-managers.com (Patrick Chemla)
Date: Fri, 7 Oct 2016 09:17:03 +0300
Subject: [squid-users] Groups of peers load-balancing
In-Reply-To: <d63bd54b-d7b6-245f-4521-993ec35c3765@treenet.co.nz>
References: <f9140615-f35a-f0b5-64b9-71a1f11c72ad@performance-managers.com>
 <BEFCD64A-9043-4998-8717-907F87DABF92@gmail.com>
 <d63bd54b-d7b6-245f-4521-993ec35c3765@treenet.co.nz>
Message-ID: <d74e4999-74c0-f098-47d1-7c7c9251d7b1@performance-managers.com>

Many thanks Amos for your help.

I will set up my servers in the next days, and will let you know how it 
works, well I am sure.

Patrick


Le 06/10/2016 ? 13:11, Amos Jeffries a ?crit :
> On 6/10/2016 8:52 p.m., George William Herbert wrote:
>> Usually you load balance with another tool...
> HTTP Load Balancer is one of the roles Squid is designed for.
>
> When you need to converge the LB, routing, and caching tasks Squid is
> the product for the job.
>
>>> On Oct 6, 2016, at 12:16 AM, Patrick Chemla wrote:
>>>
>>> Hi,
>>>
>>> I am using Squid Cache: Version 3.5.20 on 2 Fedora 24 server.
>>>
>>> I have to set a load-balancer for multiple sites, each using
>>> different peers, on both servers + cloud instances.
>>>
>>> Squid is the entry point for all websites. According to the domain,
>>> I will have 2 to 5 peers to handle the load. But, as I have 2 big
>>> domains, and a group of other domains, I need dedicated peers for
>>> each big domains, and another groups of peers for other domains.
>>>
>>> So squid must route requests :
>>>
>>> - for domain A to peers A1 A2 A3
>>>
>>> - for domain B to peers B1 B2 B3 B4 B5
>>>
>>> - for all other domains to peers O1 O2
>>>
>>> Load balancing method within a group could be different, as some
>>> domains need user to reach always same peer, when other domain
>>> could simply handle round-robin balancing.
>>>
>>> I can't find how to group peers A1 A2 A3 to group A, peers B1
>>> B2..B5 to group B, O1 O2 to group O, then set the cache_peer_access
>>> to the needed group.
> Grouping is done by cache_peer_access ACLs.
>
> You need to define one ACL which will only match for one group.
> Typically the domain name is used for that. The "group" is simply the
> peers which the request is allowed to be sent to.
>
> For example:
>
>   acl groupA dstdomain .example.com
>   acl groupB dstdomain .example.net
>   acl groupO dstdomain .example.org
>
>   cache_peer_access A1 allow groupA
>   cache_peer_access A1 deny all
>   cache_peer_access A2 allow groupA
>   cache_peer_access A2 deny all
>   ...
>
>   cache_peer_access B1 allow groupB
>   cache_peer_access B1 deny all
>   cache_peer_access B2 allow groupB
>   cache_peer_access B2 deny all
>   ...
>
>
> Since your peers are split into distinct groups just add the relevant
> algorithm to the cache_peer in that group which is using it.
>
> Things can get complex if you have one peer being part of two groups.
> But then you just define two cache_peer lines for it, one in each group
> with the relevant LB algorithm. The name= parameter is used distinguish
> which cache_peer line is relevant for the cache_peer_access rules.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From fredbmail at free.fr  Fri Oct  7 07:18:34 2016
From: fredbmail at free.fr (FredB)
Date: Fri, 7 Oct 2016 09:18:34 +0200 (CEST)
Subject: [squid-users] ICAP and user ID
In-Reply-To: <2092236600.974363415.1475824487081.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <814047054.974380816.1475824714875.JavaMail.root@zimbra4-e1.priv.proxad.net>

Hello All,

When Squid is connected to an ICAP server, there is a know list of informations transmitted ?
I'm thinking of username with kerberos, or some specific headers 

Regards 

Fred


From fredbmail at free.fr  Fri Oct  7 07:19:23 2016
From: fredbmail at free.fr (FredB)
Date: Fri, 7 Oct 2016 09:19:23 +0200 (CEST)
Subject: [squid-users] SSO and Squid, SAML 2.0 ?
In-Reply-To: <5d4c6855-5466-01e2-c924-a6fb6756fca9@measurement-factory.com>
Message-ID: <286571179.974384283.1475824763705.JavaMail.root@zimbra4-e1.priv.proxad.net>


> I am aware of folks successfully using certificate-based
> authentication
> in production today, but they are still running v3.3-based code (plus
> many patches). I am not aware of any regressions in that area, but
> since
> there is no adequate regression testing, Amos is right: YMMV.
> 
> Alex.
> 
> 

Ok thanks, I will investigate 

Fred


From r.gardner at midata.de  Fri Oct  7 09:17:41 2016
From: r.gardner at midata.de (Gardner Roger)
Date: Fri, 7 Oct 2016 09:17:41 +0000
Subject: [squid-users] Squid Umlauts
Message-ID: <D1B4D1D0E0AC2D418A16E227D23114689C833056@11859s0003.exchange11859.local>

Hello,

I have a server with squid proxy. When I go to a German Web Site with Umlauts, I don't see the Umlauts and can't go to those links. If I go to the same web site without going over the server it works fine. I don't know squid at all and the person who set it is no longer here. I can't figure out where I can set this or how to set it. I found different settings over google, but none of them would be excepted from squid. Any help would be appreciated.


Greetings,

Roger Gardner
Linux Technik
Midata Service GmbH
Schieferstein 5
65439 Fl?rsheim
Telefon : +49 6145 506-842
Fax : +49 6145 506-588
E-Mail : mailto:r.gardner at midata.de
Internet : http://www.mce-bank.eu

---------------------------------------------------------------------------
Diese Nachricht ist vertraulich und nur fuer die bezeichneten Empfaenger bestimmt. Wenn Sie nicht der vorgesehene Adressat dieser E-Mail oder dessen Vertreter sein sollten, so beachten Sie bitte, dass jede Form der Kenntnisnahme, Veroeffentlichung, Vervielfaeltigung oder Weitergabe des Inhalts dieser E-Mail unzulaessig ist. Wir bitten Sie, sich in diesem Fall mit dem Absender der E-Mail in Verbindung zu setzen. Wir weisen ausserdem darauf hin, dass E-Mails verloren gehen, veraendert oder verfaelscht werden koennen. Herkoemmliche E-Mails sind nicht gegen den Zugriff von Dritten geschuetzt und deshalb ist auch die Vertraulichkeit unter Umstaenden nicht gewahrt. Der Inhalt der E-Mail ist nur rechtsverbindlich, wenn er unsererseits durch einen Brief entsprechend bestaetigt wird. Sollte trotz der von uns verwendeten Virenschutz-Programme durch die Zusendung von E-Mails ein Virus in Ihre Systeme gelangen, so haften wir nicht fuer eventuell hieraus entstehende Schaeden.

The information transmitted is confidential and intended only for the person or entity to which it is addressed. If you are not the intended addressee of this e-mail or his representative, please be aware that any kind of review, publication, reproduction or retransmission of the content of this e-mail is prohibited. In this case your are requested to contact the sender of the e-mail. Furthermore, we point out that e-mails may get lost, be changed or falsified. Normal e-mails are not protected against access by third parties and consequently their confidentiality may not be assured in certain circumstances.
The content of this e-mail is only legally binding if it is confirmed by a letter from our side. Should any virus enter your systems in connection with this e-mail despite our use of antivirus software, we cannot be held liable for any possible damages.
---------------------------------------------------------------------------
Die Angaben nach ? 37a HGB finden sich unter dem folgenden Link: http://www.midata.de/37ahgb.htm

Information according to ? 37a HGB can be found under the following link: http://www.midata.de/37ahgb.htm
---------------------------------------------------------------------------
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161007/b654b60a/attachment.htm>

From hardikdangar+squid at gmail.com  Fri Oct  7 09:26:06 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Fri, 7 Oct 2016 14:56:06 +0530
Subject: [squid-users] Caching http google deb files
In-Reply-To: <2c043b07-b941-9e29-8813-4642070384f6@measurement-factory.com>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
 <CA+sSnVZ2ErFD+LeLVH3KOjJ_0PuqGyWfRHA23zY8yJQs3kP+Rw@mail.gmail.com>
 <89f9840b-7ec7-2f0b-a81c-5376c344878e@treenet.co.nz>
 <CA+sSnVYCy5E00jKK5cPZm3q+eBX8Fx=Mjs_iu4Xs0oebxcte9Q@mail.gmail.com>
 <1ba79370-ff21-0e52-a5dc-89919c1171b4@measurement-factory.com>
 <57F68690.1020109@tlinx.org>
 <2c043b07-b941-9e29-8813-4642070384f6@measurement-factory.com>
Message-ID: <CA+sSnVai079zNS6X+Rni9qaRKOAt6PF+nrZQhBR462zL1zWZuA@mail.gmail.com>

Hey Alex,

I totally get that Vary code is different, I have been trying to understand
squid code for last few days although my C, C++ skills are very limited I
am able to understand bits and pieces here and there. I have also read HTTP
1.1 specs for cache ( https://tools.ietf.org/html/rfc2616#section-13 )

After doing fair bit of research I believe we need to two things,

1) start a campaign to convince webmasters to update their server configs,
 for that to happen I am doing my research on apache and Nginx servers on
how to implement ( HTTP 1.1 spec cache guidelines ) and will provide them
copy paste configs for all requests or for the file types like
deb,apk,rpm,exe(binary files),etc...

I am documenting that here,
https://hardikdangar.github.io/thecacheproject/

and once I finish everything I will post everything at the squid-dev list
here so all of you can look at it and if you guys approve it, I will
personally try to contact the big providers and send them above page with
solutions. and will ask community support and will publish it to twitter
and other social sites to get support.

2) I want to build a module which will first handle Vary: * requests and
convert it into Vary: Accept-Encoding or something similar but only for the
ACL's specified by cache administrator.

Next, there are use cases like GitHub which are very difficult to handle
but I feel there is a way we can handle those use cases so I will build ACL
for those.

For this, i am trying to understand squid code, After looking at dev docs,
I understand how the request is handled at clientBeginRequest. But I am
very confused at how squid handles the response.  I know
client_side_reply.cc is the file where the response is handled but I am not
sure how StoreEntry::checkCachable() method in store.cc is called before it
as that is the method i get in squid logs when the cache is denied.

Basically, I need to know how to debug line by line source for squid. Right
now my method of testing involves building squid and adding debug lines and
its very slow process as it takes time every time. Can you help me with
this ? is there a way i could send a request directly to squid source file
i.e debug source code line by line ? If so what are the tools required and
how to set it up ?

Again, I am sorry if i am asking too much but my C experience is very
limited and i feel like i am asking very naive questions but these are very
difficult for me at this stage and i really appreciate all of the squid
dev teams who is been answering all of my questions. Thank you very much
for that.
--------

I just want a better cache support for squid and modern day use cases.

On Thu, Oct 6, 2016 at 11:25 PM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 10/06/2016 11:14 AM, Linda A. Walsh wrote:
> > Alex Rousskov wrote:
> >> We can, but ignoring Vary requires more/different work than adding
> >> another refresh_pattern option. Vary is not a refresh mechanism so
> >> different code areas need to be modified to ignore (but still forward!)
> >> Vary.
>
>
> >    I can't say for certain, but I'd give it a 75% shot of it being
> > used as a forced-refresh pattern
>
> The [ab]use cases do not matter here -- the _code_ handling Vary is very
> different from the code handling refresh logic. That difference is
> natural and unavoidable because the two protocol mechanisms are very
> different, even if they both can be and are used to create the same effect.
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161007/15415130/attachment.htm>

From hardikdangar+squid at gmail.com  Fri Oct  7 09:34:20 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Fri, 7 Oct 2016 15:04:20 +0530
Subject: [squid-users] Squid Umlauts
In-Reply-To: <D1B4D1D0E0AC2D418A16E227D23114689C833056@11859s0003.exchange11859.local>
References: <D1B4D1D0E0AC2D418A16E227D23114689C833056@11859s0003.exchange11859.local>
Message-ID: <CA+sSnVac9+fXmetQ6tfOXCQd3ZdycDNB5_wxi0A-psc5EMmnnw@mail.gmail.com>

Hey Gardner,

depending on your os and squid version squid.conf file could be located at,
/etc/squid/squid.conf

If you could post that file we can look at what could be the issue. What I
understand from your question, I don't think squid is at role here but it
could be squid guard or some other filtering plugin could be playing a role
here. but without looking at squid.conf we cannot tell it for sure what
could be the reason. So please find that file and post it here.



On Fri, Oct 7, 2016 at 2:47 PM, Gardner Roger <r.gardner at midata.de> wrote:

> Hello,
>
>
>
> I have a server with squid proxy. When I go to a German Web Site with
> Umlauts, I don?t see the Umlauts and can?t go to those links. If I go to
> the same web site without going over the server it works fine. I don?t know
> squid at all and the person who set it is no longer here. I can?t figure
> out where I can set this or how to set it. I found different settings over
> google, but none of them would be excepted from squid. Any help would be
> appreciated.
>
>
>
>
>
> Greetings,
>
>
>
> Roger Gardner
>
> Linux Technik
>
> Midata Service GmbH
>
> Schieferstein 5
>
> 65439 Fl?rsheim
>
> Telefon : +49 6145 506-842
>
> Fax : +49 6145 506-588
>
> E-Mail : mailto:r.gardner at midata.de <r.gardner at midata.de>
>
> Internet : http://www.mce-bank.eu
>
>
>
> ------------------------------------------------------------
> ---------------
> Diese Nachricht ist vertraulich und nur fuer die bezeichneten Empfaenger
> bestimmt. Wenn Sie nicht der vorgesehene Adressat dieser E-Mail oder dessen
> Vertreter sein sollten, so beachten Sie bitte, dass jede Form der
> Kenntnisnahme, Veroeffentlichung, Vervielfaeltigung oder Weitergabe des
> Inhalts dieser E-Mail unzulaessig ist. Wir bitten Sie, sich in diesem Fall
> mit dem Absender der E-Mail in Verbindung zu setzen. Wir weisen ausserdem
> darauf hin, dass E-Mails verloren gehen, veraendert oder verfaelscht werden
> koennen. Herkoemmliche E-Mails sind nicht gegen den Zugriff von Dritten
> geschuetzt und deshalb ist auch die Vertraulichkeit unter Umstaenden nicht
> gewahrt. Der Inhalt der E-Mail ist nur rechtsverbindlich, wenn er
> unsererseits durch einen Brief entsprechend bestaetigt wird. Sollte trotz
> der von uns verwendeten Virenschutz-Programme durch die Zusendung von
> E-Mails ein Virus in Ihre Systeme gelangen, so haften wir nicht fuer
> eventuell hieraus entstehende Schaeden.
>
> The information transmitted is confidential and intended only for the
> person or entity to which it is addressed. If you are not the intended
> addressee of this e-mail or his representative, please be aware that any
> kind of review, publication, reproduction or retransmission of the content
> of this e-mail is prohibited. In this case your are requested to contact
> the sender of the e-mail. Furthermore, we point out that e-mails may get
> lost, be changed or falsified. Normal e-mails are not protected against
> access by third parties and consequently their confidentiality may not be
> assured in certain circumstances.
> The content of this e-mail is only legally binding if it is confirmed by a
> letter from our side. Should any virus enter your systems in connection
> with this e-mail despite our use of antivirus software, we cannot be held
> liable for any possible damages.
> ------------------------------------------------------------
> ---------------
> Die Angaben nach ? 37a HGB finden sich unter dem folgenden Link:
> http://www.midata.de/37ahgb.htm
>
> Information according to ? 37a HGB can be found under the following link:
> http://www.midata.de/37ahgb.htm
> ------------------------------------------------------------
> ---------------
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161007/63facf2b/attachment.htm>

From krishna26kulkarni at gmail.com  Fri Oct  7 09:48:58 2016
From: krishna26kulkarni at gmail.com (Krishna Kulkarni)
Date: Fri, 7 Oct 2016 15:18:58 +0530
Subject: [squid-users] Squid Slowness Issues
Message-ID: <CAN-hqtirzmELN5z+nw+NhQ=HxjEkGdbSDEBYYOHA3jy=8-8F9Q@mail.gmail.com>

Dear Team
Thank you very much for accepting my request of mailing list membership..
I am new to squid.. I have installed squid 3.5 on CentOS 6.7. As the
configuration part, I have kept most of the things default. Please advice
on how to allocate cache memory of 20 GB to squid. I got to know that, more
cache memory would increase performance of squid..

Thanks,
Krishna
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161007/fa6084c0/attachment.htm>

From nilesh.gavali at tcs.com  Fri Oct  7 11:24:09 2016
From: nilesh.gavali at tcs.com (Nilesh Gavali)
Date: Fri, 7 Oct 2016 12:24:09 +0100
Subject: [squid-users] Squid - AD kerberos auth and Linux Server proxy
	access not working
Message-ID: <OFF5948154.A0AA974E-ON80258045.003EA2F8-80258045.003EA306@tcs.com>

Hi AMos;
Thanks for clarification, It is working as expected now... Appreciate your support....

Thanks again.

Thanks & Regards
Nilesh Suresh Gavali


-----Forwarded by Nilesh Gavali/MUM/TCS on 10/07/2016 04:52PM -----
To: squid-users at lists.squid-cache.org
From: squid-users-request at lists.squid-cache.org
Sent by: "squid-users" 
Date: 10/06/2016 12:44AM
Subject: squid-users Digest, Vol 26, Issue 25

Send squid-users mailing list submissions to
squid-users at lists.squid-cache.org

To subscribe or unsubscribe via the World Wide Web, visit
http://lists.squid-cache.org/listinfo/squid-users
or, via email, send a message with subject or body 'help' to
squid-users-request at lists.squid-cache.org

You can reach the person managing the list at
squid-users-owner at lists.squid-cache.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of squid-users digest..."


Today's Topics:

?? 1. Re: Squid - AD kerberos auth and Linux Server proxy access
?? ? ?not working (Amos Jeffries)
?? 2. Re: Caching http google deb files (Hardik Dangar)
?? 3. Re: intercept + IPv6 + IPFilter 5.1 (Egerv?ry Gergely)
?? 4. Re: Caching http google deb files (Antony Stone)


----------------------------------------------------------------------

Message: 1
Date: Thu, 6 Oct 2016 06:03:09 +1300
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid - AD kerberos auth and Linux Server
proxy access not working
Message-ID: <4e608076-5ca4-cdac-a5e4-6d0af5106f1d at treenet.co.nz>
Content-Type: text/plain; charset=utf-8

On 6/10/2016 5:31 a.m., Nilesh Gavali wrote:
> <<NILESH>> here is the compete squid.conf for your reference-
> 
> #
> # Recommended minimum configuration:
> #### ?AD SSO Integration ?#####
> #auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -d -s 
> GSS_C_NO_NAME
> auth_param negotiate program /usr/lib64/squid/squid_kerb_auth -s 
> HTTP/proxy02.CUST.IN at CUST.IN
> auth_param negotiate children 20
> auth_param negotiate keep_alive on
> 
> acl ad_auth proxy_auth REQUIRED
> 
> #### ?AD Group membership ?####
> 
> 
> external_acl_type AD_Group ttl=300 negative_ttl=0 children=10 %LOGIN 
> /usr/lib64/squid/squid_ldap_group -P -R -b "DC=CUST,DC=IN" -D svcproxy -W 
> /etc/squid/pswd/pswd -f 
> "(&(objectclass=person)(userPrincipalName=%v)(memberof=cn=%a,ou=InternetAccess,ou=Groups,dc=cust,dc=in))" 
> -h CUST.IN -s sub -v 3
> 
> acl AVWSUS external AD_Group lgOnlineUpdate
> acl windowsupdate dstdomain "/etc/squid/sitelist/infra_update_site"
> 
> acl custUSER external AD_Group lgInternetAccess_custUsers
> acl custallowedsite dstdomain "/etc/squid/sitelist/cust_allowed_site"
> 
> #acl SHAVLIK external AD_Group lgShavlikUpdate
> acl shavlikupdate dstdomain "/etc/squid/sitelist/shavlik_update_site"
> 
<snip defaults>

> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl AVSRVR src 10.50.2.107 ? ? ?# Cloud SEPM Servr
> acl SHAVLIK_SRVR src 10.50.2.112 ? ? # Shavlik Server(NTLM Only Access)
> acl IWCCP01 src 10.55.15.103 ? # Application access to Worldpay/bottomline 
> Payment test site.

<snip defaults>
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> 
> #http_access allow test shavlikupdate
> http_access allow SHAVLIK_SRVR shavlikupdate
> http_access allow AVSRVR windowsupdate

The "AVWSUS" ACL below requires authentication in order to check the
group membership. That is what triggers the 407 response to happen.

Move the IWCCP01 line up to here and it should stop.

To make your configuration clearer about which lines need auth and which
lines do not you could place the following line right here:

?http_access deny !ad_auth

All things that do need auth or group names should always go below it.
Things that need to avoid auth should always go above it.


> http_access allow AVWSUS windowsupdate
> http_access allow IWCCP01
> #http_access allow IWCCP01 custallowedsite
> http_access allow custUSER custallowedsite
> http_access allow ad_auth
> # And finally deny all other access to this proxy
> http_access deny all
> 

Amos



------------------------------

Message: 2
Date: Thu, 6 Oct 2016 00:10:46 +0530
From: Hardik Dangar <hardikdangar+squid at gmail.com>
To: Jok Thuau <jok at spikes.com>
Cc: Squid Users <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Caching http google deb files
Message-ID:
<CA+sSnVZ+6csWqt60nwwSM0QDSmx+DutqQeXgL-bGtYbFC6WRuw at mail.gmail.com>
Content-Type: text/plain; charset="utf-8"

Hey Jok,

Thanks for the suggetion but the big issue with that is i have to download
whole repository about ( 80-120 GB ) first and then each week i need to
download 20 to 25 GB. ?We hardly use any of that except few popular repos.
big issue i always have with most of them is third party repo's.
squid-deb-proxy is quite reliable but again its squid with custom config
nothing else and it fails to cache google debs.

Squid is perfect for me because it can cache things which is requested
first time. So next time anybody requests it it's ready. The problem lies
when big companies like google and github does not wants us to cache their
content and puts various tricks so we can't do that. My issue is same
google deb files are downloaded 50 times in same day as apt updates happen
and i waste 100s of gb into same content. Country where i live bandwidth is
very very costly matter and fast connections are very costly. So this is
important for me.

@Amos,

I think it's about time Squid needs update of code which can cache use
cases like difficult to handle google and github. I am interested to create
proposal and will soon share at squid dev and ask for ideas and will try to
get official approval so i can build this according to squid standards.

but before that can you help me with few things.essentially i don't have
much experience with C code. as i have worked most of my life with
php,python and javascript side. I do know how to write C code but i am not
an expert at it. So i want to know if there is any pattern squid follows
except the oop pattern. I also want to know workflow of squid i.e. what
happens when it receives request and how acls are applied programmatically
and how refresh patterns are applied. is there a way i can debug and check
if refresh patterns are applied for given url. as well as
reply_header_replace has replaced header if i can see those lines in debug
it will help me with this. i know debug options can help me but if i turn
it with level 9 it is very difficult to go past so many debug entries.

My idea is to develop a module which will not change any of the squid code
but will be loaded only if its called explicitly within squid config. So i
want to know is there any piece of code available within squid which
behaves similarly just like your archive mode.




On Wed, Oct 5, 2016 at 9:49 PM, Jok Thuau <jok at spikes.com> wrote:

> This is sort of off-topic, but have you considered using a deb repo
> mirroring software?
> (it would mean that you need to update your clients to point to that
> rather than google, but that's not really difficult).
> software like aptly (aptly.info) are really good about this (though a
> little hard to get going in the first place). or a deb-caching proxy
> (apt-cacher-ng? squid-deb-proxy?)
>
>
> On Tue, Oct 4, 2016 at 7:30 AM, Hardik Dangar <
> hardikdangar+squid at gmail.com> wrote:
>
>> Wow, i couldn't think about that. google might need tracking data that
>> could be the reason they have blindly put vary * header. oh Irony, company
>> which talks to all of us on how to deliver content is trying to do such
>> thing.
>>
>> I have looked at your patch but how do i enable that ? do i need to write
>> custom ACL ? i know i need to compile and reinstall after applying patch
>> but what do i need to do exactly in squid.conf file as looking at your
>> patch i am guessing i need to write archive acl or i am too naive to
>> understand C code :)
>>
>> Also
>>
>> reply_header_replace is any good for this ?
>>
>>
>> On Tue, Oct 4, 2016 at 7:47 PM, Amos Jeffries <squid3 at treenet.co.nz>
>> wrote:
>>
>>> On 5/10/2016 2:34 a.m., Hardik Dangar wrote:
>>> > Hey Amos,
>>> >
>>> > We have about 50 clients which downloads same google chrome update
>>> every 2
>>> > or 3 days means 2.4 gb. although response says vary but requested file
>>> is
>>> > same and all is downloaded via apt update.
>>> >
>>> > Is there any option just like ignore-no-store? I know i am asking for
>>> too
>>> > much but it seems very silly on google's part that they are sending
>>> very
>>> > header at a place where they shouldn't as no matter how you access
>>> those
>>> > url's you are only going to get those deb files.
>>>
>>>
>>> Some things G does only make sense whan you ignore all the PR about
>>> wanting to make the web more efficient and consider it's a company whose
>>> income is derived by recording data about peoples habits and activities.
>>> Caching can hide that info from them.
>>>
>>> >
>>> > can i hack squid source code to ignore very header ?
>>> >
>>>
>>> Google are explicitly saying the response changes. I suspect there is
>>> something involving Google account data being embeded in some of the
>>> downloads. For tracking, etc.
>>>
>>>
>>> If you are wanting to test it I have added a patch to
>>> <http://bugs.squid-cache.org/show_bug.cgi?id=4604> that should implement
>>> archival of responses where the ACLs match. It is completely untested by
>>> me beyond building, so YMMV.
>>>
>>> Amos
>>>
>>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161006/98c8f171/attachment-0001.html>

------------------------------

Message: 3
Date: Wed, 5 Oct 2016 20:49:54 +0200
From: Egerv?ry Gergely <gergely at egervary.hu>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] intercept + IPv6 + IPFilter 5.1
Message-ID: <57F54B52.4000803 at egervary.hu>
Content-Type: text/plain; charset=utf-8

>> Should "intercept" work with IPv6 on NetBSD 7-STABLE and IPFilter 5.1?

Okay, we have "fixed" Squid interception, and IPFilter in the kernel,
and now it's working good. But did we do it in the right way?

While reading ip_nat.c in IPFilter, I found that SIOCGNATL - and its
function called ipf_nat_lookupredir() - is a frontend to two functions:
ipf_nat_inlookup() and ipf_nat_outlookup().

We are now calling SIOCGNATL to use ipf_nat_outlookup(). But should not
we call it to use ipf_nat_inlookup() instead?

In Squid, we are working with 3 different addresses:
- source IP:port of the connection (browser client)
- real destination IP:port (the target web server)
- interception destination IP:port (Squid itself)

In IPFilter, the terminology is different: "real" refers to the
original source, not the original destination.

In my understanding, on redirect (RDR) rules, where we know the
original source address and the rewrited destination address, we should
use ipf_nat_inlookup() to get the original destination address.

ipf_nat_outlookup() should be used on source-NAT (MAP) scenarios,
what we don't need for Squid.

If that's true, IPFilter was correct - we have to revert our IPFilter
patches - and modify Intercept.cc instead.

See IPFilter source code comments below:

========
Function: ipf_nat_inlookup
Returns: nat_t* - NULL == no match, else pointer to matching NAT entry
Parameters:
fin(I) - pointer to packet information
flags(I) - NAT flags for this packet
p(I) - protocol for this packet
src(I) - source IP address
mapdst(I) - destination IP address

Lookup a nat entry based on the mapped destination ip address/port
and real source address/port. We use this lookup when receiving a
packet, we're looking for a table entry, based on the destination
address.

========
Function: ipf_nat_outlookup
Returns: nat_t* - NULL == no match, else pointer to matching NAT entry
Parameters:
fin(I) - pointer to packet information
flags(I) - NAT flags for this packet
p(I) - protocol for this packet
src(I) - source IP address
dst(I) - destination IP address
rw(I) - 1 == write lock on held, 0 == read lock.

Lookup a nat entry based on the source 'real' ip address/port
and destination address/port. We use this lookup when sending a packet
out, we're looking for a table entry, based on the source address.

========

See full ip_nat.c source code here:

http://cvsweb.netbsd.org/bsdweb.cgi/src/sys/external/bsd/ipf/netinet/ip_nat.c?rev=1.16&content-type=text/x-cvsweb-markup

Thank you,
-- 
Gergely EGERVARY



------------------------------

Message: 4
Date: Wed, 5 Oct 2016 21:13:21 +0200
From: Antony Stone <Antony.Stone at squid.open.source.it>
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Caching http google deb files
Message-ID: <201610052113.21686.Antony.Stone at squid.open.source.it>
Content-Type: Text/Plain; ?charset="iso-8859-15"

On Wednesday 05 October 2016 at 20:40:46, Hardik Dangar wrote:

> Hey Jok,
> 
> Thanks for the suggetion but the big issue with that is i have to download
> whole repository about ( 80-120 GB ) first and then each week i need to
> download 20 to 25 GB.

This is not true for apt-cacher-ng. ?You install it and it does nothing. ?You 
point your Debian (or Ubuntu, maybe other Debian-derived distros as well, I 
haven't tested) machines at it as their APT proxy, and it then caches content 
as it gets requested and downloaded. ?Each machine which requests a new 
package causes that package to get cached. ?Each machine which requests a 
cached package gets the local copy (unless it's been updated, in which case 
the cache gets updated).

> We hardly use any of that except few popular repos.
> big issue i always have with most of them is third party repo's.
> squid-deb-proxy is quite reliable but again its squid with custom config
> nothing else and it fails to cache google debs.
> 
> Squid is perfect for me because it can cache things which is requested
> first time. So next time anybody requests it it's ready.

This is exactly how apt-cacher-ng works. ?I use it myself and I would 
recommend you investigate it further for this purpose.

> The problem lies when big companies like google and github does not wants us
> to cache their content and puts various tricks so we can't do that.

That's a strange concept for a Debian repository (even third-party).

Are you sure you're talking about repositories and not just isolated .deb 
files?


Antony.

-- 
A user interface is like a joke.
If you have to explain it, it didn't work.

?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? Please reply to the list;
?? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? please *don't* CC me.


------------------------------

Subject: Digest Footer

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


------------------------------

End of squid-users Digest, Vol 26, Issue 25
*******************************************
=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161007/61b86b91/attachment.htm>

From uhlar at fantomas.sk  Fri Oct  7 11:23:58 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Fri, 7 Oct 2016 13:23:58 +0200
Subject: [squid-users] Whitelist domain ignored?
In-Reply-To: <CABU5kW7LpD8PPKiTadH5pHvVSDGy_WHLkxLxND5SNGTvpAn4YA@mail.gmail.com>
References: <CADSSinPXUsf5fPUbdzEsV-oafJos0EtaQZhOZK-pZ6ncSS_eYw@mail.gmail.com>
 <CABU5kW5kLn4=2HtueBs0NrkwT+uHkRexyNnpPPQxqV6EqCKndA@mail.gmail.com>
 <c88cca41-ef79-a77d-5e4e-d3ce20f4beb6@measurement-factory.com>
 <CABU5kW7sy9qL3d=8rCR4=ROK4zGLvwp32ZQMPj2Bb8RtmwBniA@mail.gmail.com>
 <32081c3d-3b75-1f36-08a2-8d0bbadb943e@measurement-factory.com>
 <CABU5kW7bLMGtYitztHXJX+REuN4_AKNu_Aesf0_urMDmHuVu9w@mail.gmail.com>
 <CABU5kW5=rc8VnxGnagNnhhFONJDCyMctrsW9QtBi_2+hBRmXdA@mail.gmail.com>
 <571e794e-ce7c-336f-8445-89b1f2b9a975@treenet.co.nz>
 <170d047f-c446-07bc-dbd9-2fbb5e6e1e11@measurement-factory.com>
 <CABU5kW7LpD8PPKiTadH5pHvVSDGy_WHLkxLxND5SNGTvpAn4YA@mail.gmail.com>
Message-ID: <20161007112358.GA30277@fantomas.sk>

>>> On 6/10/2016 11:56 a.m., Jose Torres-Berrocal wrote:
>>>> acl whitelist2 dstdom_regex -i "whitelist.acl"
>>>>
>>>> Where whitelist.acl content:
>>>> ^familymedicinepr\.com$
>>>> ^mail\.yahoo\.com$
>>>> ^neodecksoftware\.com$
>>>> ^office\.net$
>>>> \.familymedicinepr\.com$
>>>> \.mail\.yahoo\.com$
>>>> \.neodecksoftware\.com$
>>>> \.office\.net$

>> On 10/05/2016 11:45 PM, Amos Jeffries wrote:
>>> There is a simpler way if you are going to insisit on regex instead of
>>> dstdomain. Starting the pattern with an optional '.' character:  \.?
>>>
>>> So whitelist.acl content:
>>>
>>> \.?familymedicinepr\.com$
>>> \.?mail\.yahoo\.com$
>>> \.?neodecksoftware\.com$
>>> \.?office\.net$

>On Thu, Oct 6, 2016 at 1:28 PM, Alex Rousskov <rousskov at measurement-factory.com> wrote:
>> That simpler way is incorrect AFAICT: The top/correct ACL list does not
>> match "xoffice.net" but yours does.

On 06.10.16 13:52, Jose Torres-Berrocal wrote:
>"dstdomain .office.net" does not match xoffice.net domain.  I do not
>want to match xoffice.net with the regex.

That's precisely why Alex noted that Amos' regex is incorrect.

In fact:

acl whitelist2 dstdomain .neodecksoftware.com

is equivalent to:

acl whitelist2 dstdom_regex ^neodecksoftware\.com$ .*\.neodecksoftware\.com$

or:

acl whitelist2 dstdom_regex ^(.*\.)?neodecksoftware\.com$

because is matches domain itself (neodecksoftware.com) as long as subdomains
(*.neodecksoftware.com).

And this is why Amos said that:
"Using dstdomain in this case is better though since the comparison is
shorter and faster than regex."

whenever you can, use dstdomain insted of dstdom_regex.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
WinError #98652: Operation completed successfully.


From jvdwesthuiz at shoprite.co.za  Fri Oct  7 12:59:41 2016
From: jvdwesthuiz at shoprite.co.za (Jasper Van Der Westhuizen)
Date: Fri, 7 Oct 2016 12:59:41 +0000
Subject: [squid-users] Windows caching
Message-ID: <1475845180.14989.160.camel@shoprite.co.za>

Hi all

I am trying to tweak my configuration to better catch Windows 10
 updates. I download the file manually so at the first log entry I see
the TCP_HIT/206, then after the download is completed I get
TCP_HIT/200. But If I download the file again I get another TCP_HIT/206
and the file is downloaded again.

Any idea why it's doing this?

1475843695.498 241787 10.7.48.42 TCP_HIT/206 1801411025 GET http://au.v
4.download.windowsupdate.com/d/msdownload/update/software/secu/2016/09/
windows10.0-kb3185614-x64_5_c3b5d298472570c878c124
d05a0ef6fb3e088506.psf - HIER_NONE/- application/octet-stream
1475844229.809 238798 10.7.48.42 TCP_HIT/200 1801413860 GET http://au.v
4.download.windowsupdate.com/d/msdownload/update/software/secu/2016/09/
windows10.0-kb3185614-x64_5_c3b5d298472570c878c124
d05a0ef6fb3e088506.psf - HIER_NONE/- application/octet-stream
1475844244.273      0 10.7.48.42 TCP_HIT/206 498 GET http://au.v4.downl
oad.windowsupdate.com/d/msdownload/update/software/secu/2016/09/windows
10.0-kb3185614-x64_5_c3b5d298472570c878c124d05a0ef
6fb3e088506.psf - HIER_NONE/- application/octet-stream
1475844403.706 159429 10.7.48.42 TCP_HIT_ABORTED/206 1165844993 GET htt
p://au.v4.download.windowsupdate.com/d/msdownload/update/software/secu/
2016/09/windows10.0-kb3185614-x64_5_c3b5d298472570
c878c124d05a0ef6fb3e088506.psf - HIER_NONE/- application/octet-stream
1475844648.832 238010 10.7.48.42 TCP_HIT/200 1801413860 GET http://au.v
4.download.windowsupdate.com/d/msdownload/update/software/secu/2016/09/
windows10.0-kb3185614-x64_5_c3b5d298472570c878c124
d05a0ef6fb3e088506.psf - HIER_NONE/- application/octet-stream
1475844658.045      0 10.7.48.42 TCP_HIT/206 498 GET http://au.v4.downl
oad.windowsupdate.com/d/msdownload/update/software/secu/2016/09/windows
10.0-kb3185614-x64_5_c3b5d298472570c878c124d05a0ef
6fb3e088506.psf - HIER_NONE/- application/octet-stream


My config file contains:


--cut--
coredump_dir /var/cache/squid/
cache_dir aufs /var/cache/squid/ 20480 32 256
cache_replacement_policy heap lfuda
memory_replacement_policy lru

################

# CACHE TWEAKING

################
acl Windows_Updates dstdomain .windowsupdate.com
range_offset_limit 5 GB Windows_Updates
range_offset_limit 0
cache_mem 4096 MB
minimum_object_size 0 bytes
maximum_object_size 5 GB
quick_abort_min -1

dns_v4_first on
strip_query_terms off
ipcache_size 8192
fqdncache_size 8192

###################
### DEBUG Options #
###################

debug_options ALL,1 2,4

######################################################################
#                       Custom Refresh patterns
######################################################################

#--------------------------------------
# Added to better cache windows updates
#--------------------------------------

refresh_pattern -i (get_video\?|videoplayback\?|videodownload\?) 10080
80% 43200 override-expire ignore-reload reload-into-ims ignore-private

refresh_pattern -i
\.(mp2|mp3|mid|midi|mp[234]|wav|ram|ra|rm|au|3gp|m4r|m4a)(\?.*|$) 10080
80% 43200 override-expire ignore-reload reload-into-ims ignore-private

refresh_pattern -i
\.(mpg|mpeg|mp4|m4v|mov|avi|asf|wmv|wma|dat|flv|swf)(\?.*|$) 10080 80%
43200 override-expire ignore-reload reload-into-ims ignore-private

refresh_pattern -i
\.(jpeg|jpg|jpe|jp2|gif|tiff?|pcx|png|bmp|pic|ico)(\?.*|$) 10080 80%
43200 override-expire ignore-reload reload-into-ims ignore-private

refresh_pattern -i
\.(chm|dll|doc|docx|xls|xlsx|ppt|pptx|pps|ppsx|mdb|mdbx)(\?.*|$) 10080
80% 43200 override-expire ignore-reload reload-into-ims ignore-private

refresh_pattern -i \.(txt|conf|cfm|psd|wmf|emf|vsd|pdf|rtf|odt)(\?.*|$)
10080 80% 43200 override-expire ignore-reload reload-into-ims ignore
-private

refresh_pattern -i
\.(class|jar|exe|gz|bz|bz2|tar|tgz|zip|gzip|arj|ace|bin|cab|msi|rar|esd
|psf)(\?.*|$) 10080 80% 43200 override-expire ignore-reload reload-into
-ims ignore-private

refresh_pattern -i
.windowsupdate.com/.*\.(class|exe|bin|cab|msi|esd|psf)(\?.*|$) 10080
80% 43200 reload-into-ims

refresh_pattern -i \.(htm|html|mhtml|css|js)(\?.*|$) 1440 90% 86400
override-expire ignore-reload reload-into-ims



--
Kind Regards
Jasper




Disclaimer:
http://www.shopriteholdings.co.za/Pages/ShopriteE-mailDisclaimer.aspx



From rousskov at measurement-factory.com  Fri Oct  7 14:46:37 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 7 Oct 2016 08:46:37 -0600
Subject: [squid-users] Caching http google deb files
In-Reply-To: <CA+sSnVai079zNS6X+Rni9qaRKOAt6PF+nrZQhBR462zL1zWZuA@mail.gmail.com>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
 <CA+sSnVZ2ErFD+LeLVH3KOjJ_0PuqGyWfRHA23zY8yJQs3kP+Rw@mail.gmail.com>
 <89f9840b-7ec7-2f0b-a81c-5376c344878e@treenet.co.nz>
 <CA+sSnVYCy5E00jKK5cPZm3q+eBX8Fx=Mjs_iu4Xs0oebxcte9Q@mail.gmail.com>
 <1ba79370-ff21-0e52-a5dc-89919c1171b4@measurement-factory.com>
 <57F68690.1020109@tlinx.org>
 <2c043b07-b941-9e29-8813-4642070384f6@measurement-factory.com>
 <CA+sSnVai079zNS6X+Rni9qaRKOAt6PF+nrZQhBR462zL1zWZuA@mail.gmail.com>
Message-ID: <b2e37fb3-7454-cc97-c674-c92a5af3d401@measurement-factory.com>

On 10/07/2016 03:26 AM, Hardik Dangar wrote:
> 2) I want to build a module which will first handle Vary: * requests and
> convert it into Vary: Accept-Encoding or something similar but only for
> the ACL's specified by cache administrator.

If you want to convert/change the Vary response header, you can:

* write an ICAP RESPMOD service
* write an eCAP RESPMOD adapter
* add reply_header_replace code similar to request_header_replace code
  or, better, revamp related directives to make header replacing easier.

See http://wiki.squid-cache.org/SquidFaq/ContentAdaptation

As I tried to indicate earlier, a better solution would be not to
replace the Vary header (because that affects everybody receiving it
after Squid) but to make Vary interpretation configurable while still
forwarding the original Vary header. That requires more development.


If you want to minimize [C++] development, you could use c-icap or a
even a temporary ICAP server script and, instead of replacing Vary, add
an X-Squid-Vary header with the right value. After that, you can modify
Squid to honor X-Squid-Vary (instead of Vary) if it is present. Look for
ACCELERATOR_VARY for similar (but different?) code. Such code may not be
officially accepted, but it can work as a proof of concept.


> Basically, I need to know how to debug line by line source for squid.
> Right now my method of testing involves building squid and adding debug
> lines and its very slow process as it takes time every time. Can you
> help me with this ? is there a way i could send a request directly to
> squid source file i.e debug source code line by line ? If so what are
> the tools required and how to set it up ?
> 
> Again, I am sorry if i am asking too much but my C experience is very
> limited and i feel like i am asking very naive questions but these are
> very difficult for me at this stage and i really appreciate all of the
> squid dev teams who is been answering all of my questions.

Sorry, I personally cannot help you with that endeavor right now. This
may sound harsh, but seeing many folks with a lot more C++ skills fail
before you, I have to recommend staying away from non-trivial code
changes given your current skill level. It is possible to learn [C++ and
proxy] development on-the-fly, but Squid is just the wrong product for
doing that IMHO.


Good luck,

Alex.



From rousskov at measurement-factory.com  Fri Oct  7 16:52:50 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 7 Oct 2016 10:52:50 -0600
Subject: [squid-users] ICAP and user ID
In-Reply-To: <814047054.974380816.1475824714875.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <814047054.974380816.1475824714875.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <e1959930-235f-d93a-c361-1b6186bd1005@measurement-factory.com>

On 10/07/2016 01:18 AM, FredB wrote:

> When Squid is connected to an ICAP server, there is a know list of informations transmitted ?
> I'm thinking of username with kerberos, or some specific headers 

Besides the headers required by the ICAP protocol, Squid can be
configured to send ICAP [extension] headers defined by the following
configuration directives:

  * adaptation_meta
  * adaptation_send_client_ip
  * adaptation_send_username
  * adaptation_masterx_shared_names

IIRC, modern Squids support logformat %codes in "quoted" ICAP header
values configured using the adaptation_meta directive, but the
documentation does not mention that fact (a documentation bug).


HTH,

Alex.



From squid3 at treenet.co.nz  Sat Oct  8 01:32:37 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 8 Oct 2016 14:32:37 +1300
Subject: [squid-users] Problem with Squid3 Caches
In-Reply-To: <A6009200-DDD5-4E62-9D8E-02BD979500CA@gmail.com>
References: <CD14793F-4F48-433E-9A1E-B2030E1D7F14@gmail.com>
 <201610032306.15880.Antony.Stone@squid.open.source.it>
 <B0508516-890C-4526-8848-78616839ABA5@gmail.com>
 <201610041745.20899.Antony.Stone@squid.open.source.it>
 <7DE7A0D4-9C50-48EF-A297-9E65A7E45AC8@gmail.com>
 <9c5a8d4f-40b3-939c-b22a-b57181f8f0ff@treenet.co.nz>
 <9BD4DA71-18E9-45E0-8BF8-52149DC38289@gmail.com>
 <2b123df7-bdec-0146-3454-a7e2b71bfffe@treenet.co.nz>
 <2D8085B2-95E3-4E49-9B16-AFD6108970B6@gmail.com>
 <c802221d-5ceb-b57d-2841-cf0427541061@treenet.co.nz>
 <A6009200-DDD5-4E62-9D8E-02BD979500CA@gmail.com>
Message-ID: <a64845da-3722-fb44-8d68-66d2653f4ae8@treenet.co.nz>

On 7/10/2016 9:02 a.m., KR wrote:
> Which script is that?
> 

Depends on which OS you have. For Linux it would be /etc/init.d/squid

Amos

>> On Oct 6, 2016, at 12:59 PM, Amos Jeffries wrote:
>>
>>> On 7/10/2016 3:30 a.m., KR wrote:
>>> Hello Amos,
>>>
>>> Yes, and when I try to specify only one cache dir by commenting out all of the below, squid seems to automatically add them back in. 
>>
>> Hmm. Squid does not edit its own config file. Something else must be
>> doing that.
>>
>> Maybe the init script?
>>
>>
>> Amos
>>



From squid3 at treenet.co.nz  Sat Oct  8 01:36:57 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 8 Oct 2016 14:36:57 +1300
Subject: [squid-users] Squid Slowness Issues
In-Reply-To: <CAN-hqtirzmELN5z+nw+NhQ=HxjEkGdbSDEBYYOHA3jy=8-8F9Q@mail.gmail.com>
References: <CAN-hqtirzmELN5z+nw+NhQ=HxjEkGdbSDEBYYOHA3jy=8-8F9Q@mail.gmail.com>
Message-ID: <219ac62f-cbba-86e7-3bb2-45b5b6b8f5e2@treenet.co.nz>

On 7/10/2016 10:48 p.m., Krishna Kulkarni wrote:
> Dear Team
> Thank you very much for accepting my request of mailing list membership..
> I am new to squid.. I have installed squid 3.5 on CentOS 6.7. As the
> configuration part, I have kept most of the things default. Please advice
> on how to allocate cache memory of 20 GB to squid. I got to know that, more
> cache memory would increase performance of squid..

Maybe, maybe not. "slow" is relative. But to what?

cache_mem is the directive you are asking for
<http://www.squid-cache.org/Doc/config/cache_mem/>

But "slow" is usually not a memory problem. Giving Squid *too much*
cache_mem or configuring othe things that take too much RAM can make the
system swap and slow down.
<http://wiki.squid-cache.org/SquidFaq/SquidMemory>

Amos



From squid3 at treenet.co.nz  Sat Oct  8 01:43:09 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 8 Oct 2016 14:43:09 +1300
Subject: [squid-users] Windows caching
In-Reply-To: <1475845180.14989.160.camel@shoprite.co.za>
References: <1475845180.14989.160.camel@shoprite.co.za>
Message-ID: <9e9eb8b0-b7ca-fe55-0cc5-11490c2a3b11@treenet.co.nz>

On 8/10/2016 1:59 a.m., Jasper Van Der Westhuizen wrote:
> Hi all
> 
> I am trying to tweak my configuration to better catch Windows 10
>  updates. I download the file manually so at the first log entry I see
> the TCP_HIT/206, then after the download is completed I get
> TCP_HIT/200. But If I download the file again I get another TCP_HIT/206
> and the file is downloaded again.
> 
> Any idea why it's doing this?

206 happens because WU client is asking only to be given a range out of
the object. Not the whole thing every time.

TCP_HIT means the response was *not* downloaded from an upstream server.
In all these cases it came completely from the Squid's cache.

So, what do you think is a problem?

Amos



From squid3 at treenet.co.nz  Sat Oct  8 01:48:55 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 8 Oct 2016 14:48:55 +1300
Subject: [squid-users] ICAP and user ID
In-Reply-To: <814047054.974380816.1475824714875.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <814047054.974380816.1475824714875.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <e326d943-04c6-3b50-2a2c-df911cd29526@treenet.co.nz>

On 7/10/2016 8:18 p.m., FredB wrote:
> Hello All,
> 
> When Squid is connected to an ICAP server, there is a know list of informations transmitted ?
> I'm thinking of username with kerberos, or some specific headers 
> 

If you are needing the ICAP REQMOD service to do authentication instead
of Squid you will need Squid-3.5.21 or later.

Other than that see Alex's reply.

Amos



From squid3 at treenet.co.nz  Sat Oct  8 01:50:42 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 8 Oct 2016 14:50:42 +1300
Subject: [squid-users] Problem with Squid3 Caches
In-Reply-To: <764DD7B9-C150-4F68-B8BD-C313CDD51A30@gmail.com>
References: <CD14793F-4F48-433E-9A1E-B2030E1D7F14@gmail.com>
 <201610032306.15880.Antony.Stone@squid.open.source.it>
 <B0508516-890C-4526-8848-78616839ABA5@gmail.com>
 <201610041745.20899.Antony.Stone@squid.open.source.it>
 <7DE7A0D4-9C50-48EF-A297-9E65A7E45AC8@gmail.com>
 <9c5a8d4f-40b3-939c-b22a-b57181f8f0ff@treenet.co.nz>
 <9BD4DA71-18E9-45E0-8BF8-52149DC38289@gmail.com>
 <2b123df7-bdec-0146-3454-a7e2b71bfffe@treenet.co.nz>
 <2D8085B2-95E3-4E49-9B16-AFD6108970B6@gmail.com>
 <c802221d-5ceb-b57d-2841-cf0427541061@treenet.co.nz>
 <764DD7B9-C150-4F68-B8BD-C313CDD51A30@gmail.com>
Message-ID: <2108ba98-5430-8bed-dda9-2a468b48a3d0@treenet.co.nz>

On 7/10/2016 9:33 a.m., KR wrote:
> So I attempted to fix the cache reference in /var/etc/squid.conf but now I?m getting the following:
> 
> FATAL: Bungled /etc/squid/squid.conf line 3410: cache_dir rock /var/cache/squid 307200 16 256

That looks like the configuration for a UFS format directory, but
labeled as being a Rock format directory / database.

See the cache_dir documentation for what each one is supposed to be
configured with:
<http://www.squid-cache.org/Doc/config/cahe_dir>

Amos



From squid3 at treenet.co.nz  Sat Oct  8 01:53:10 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 8 Oct 2016 14:53:10 +1300
Subject: [squid-users] Squid Umlauts
In-Reply-To: <CA+sSnVac9+fXmetQ6tfOXCQd3ZdycDNB5_wxi0A-psc5EMmnnw@mail.gmail.com>
References: <D1B4D1D0E0AC2D418A16E227D23114689C833056@11859s0003.exchange11859.local>
 <CA+sSnVac9+fXmetQ6tfOXCQd3ZdycDNB5_wxi0A-psc5EMmnnw@mail.gmail.com>
Message-ID: <5c9f90b7-9e37-0758-a1ac-09da709d5bbd@treenet.co.nz>

On 7/10/2016 10:34 p.m., Hardik Dangar wrote:
> Hey Gardner,
> 
> depending on your os and squid version squid.conf file could be located at,
> /etc/squid/squid.conf
> 
> If you could post that file we can look at what could be the issue. What I
> understand from your question, I don't think squid is at role here but it
> could be squid guard or some other filtering plugin could be playing a role
> here. but without looking at squid.conf we cannot tell it for sure what
> could be the reason. So please find that file and post it here.
> 

Actually, without knowing where these 'Umlauts' are appearing even the
config file wont help.

> 
> On Fri, Oct 7, 2016 at 2:47 PM, Gardner Roger wrote:
> 
>> Hello,
>>
>> I have a server with squid proxy. When I go to a German Web Site with
>> Umlauts, I don?t see the Umlauts and can?t go to those links. If I go to
>> the same web site without going over the server it works fine. I don?t know
>> squid at all and the person who set it is no longer here. I can?t figure
>> out where I can set this or how to set it. I found different settings over
>> google, but none of them would be excepted from squid. Any help would be
>> appreciated.
>>


Amos




From yvoinov at gmail.com  Sat Oct  8 20:32:49 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 9 Oct 2016 02:32:49 +0600
Subject: [squid-users] Your real byte hit
Message-ID: <5eb45170-15ff-36cd-4899-5171831e5ea2@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Can your achieve this?

https://i1.someimage.com/ce1txmo.png

At the week-end! ;)

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX+VfwAAoJENNXIZxhPexG7/sIALJe0URPi0iCu2ZFycJmFn2V
a6k//Oy3B9oRed6YkNkqHLlcMEqeF4zxQPrDYNSvC9N8TqyqKXVMailZYZRpozME
o/xu/V6fuvG7RzMSVRgohuCEo85uVr69PpKOttEKuWPJmbCMLcr52NMk+6l39epQ
/4wtcLuLRTvHi8kG//EeFfgMcPwZRczIEF87wp7chdlDcPL2+vhkFWh+CqdhoANJ
d5mMEWOBw3auxCkO+h7NhBiWy8KhSlniR2eYSwhKkTib5LdWmrw3r/sDm97mu4eH
xc0K6h7j4dQu/noWEDI1rWDeZAIF1J0YwuZ5DNedSYi68V46kgkWiFrKyRns4aw=
=8imm
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161009/e9109ff4/attachment.key>

From yvoinov at gmail.com  Sat Oct  8 20:54:42 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 9 Oct 2016 02:54:42 +0600
Subject: [squid-users] Your real byte hit
In-Reply-To: <5eb45170-15ff-36cd-4899-5171831e5ea2@gmail.com>
References: <5eb45170-15ff-36cd-4899-5171831e5ea2@gmail.com>
Message-ID: <a1ab0e9e-e19b-eb21-8b67-f758fd667b6b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
 This is simple interception/forwarding proxy :)

09.10.2016 2:32, Yuri Voinov ?????:
>
> Can your achieve this?
>
> https://i1.someimage.com/ce1txmo.png
>
> At the week-end! ;)
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX+V0SAAoJENNXIZxhPexGlVAIAKex8IDxj7JFrKeEDxCQxA8n
PbSWjOdxGbUAN5sILsRKw8FaSHMuqzOeBXRZnscMjIAAtXAJJhC9POwF+V8aurdC
ARF0EikRcxXwj84b1rfiWdL8utSeKBLU2MpfLZxkgJHvRQhVCDiUZoxRDkkOlcyo
QpGXTTUUVc/NgaG7d6IJnRX159b7LGmYiB3FkHWUJacZ8IJOUrPhZK1L4+agEP04
1MbH/wWCbDqoEEcoouJuP5wB9iSHkaG0ui7DLbWRE0/5WC/VNq1cCMg0bPla7nPL
qESN/r+EsdXgRvPPhMUSAbdsnl72TC0daycV3ruevra7/dg94qNbvWyp4JBlGRU=
=yIB/
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161009/5c5d7eb3/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161009/5c5d7eb3/attachment.key>

From augustus_meyer at gmx.net  Sat Oct  8 22:11:22 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Sat, 8 Oct 2016 15:11:22 -0700 (PDT)
Subject: [squid-users] Your real byte hit
In-Reply-To: <5eb45170-15ff-36cd-4899-5171831e5ea2@gmail.com>
References: <5eb45170-15ff-36cd-4899-5171831e5ea2@gmail.com>
Message-ID: <1475964682025-4680016.post@n4.nabble.com>

You mean the 10% ? No problem.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Your-real-byte-hit-tp4680014p4680016.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sat Oct  8 22:37:18 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 9 Oct 2016 04:37:18 +0600
Subject: [squid-users] Your real byte hit
In-Reply-To: <1475964682025-4680016.post@n4.nabble.com>
References: <5eb45170-15ff-36cd-4899-5171831e5ea2@gmail.com>
 <1475964682025-4680016.post@n4.nabble.com>
Message-ID: <70bc7cd2-dce5-154b-617d-61b7241de62b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I mean BYTE HIT :) If you have eyes :)


09.10.2016 4:11, reinerotto ?????:
> You mean the 10% ? No problem.
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Your-real-byte-hit-tp4680014p4680016.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX+XUdAAoJENNXIZxhPexGFh8H/iUsgv1e6wqFz7qYk5WK5Q5d
LOt2ARSVh1LjkmqlamjRP1czC0zlnfCpL2nfwVeMwgaD+kPgdNGQTj3RrHHDpXnD
zatP7Jetq9vazoerF3oZmdNDDQOIxS+LMVw7kkI/oKqoc7iwqi6LLcuMw2Yp/HWW
xp8oWBjzp8kcZsMZcGU0UCRvyBP64V/nxFcAkMD/9b+lJbTNGB46TKqcotjahJXj
w92/TlgxTEfD95+XCaJuCXSMqL1u85KHHYVWFWNwlvld5Ggh4wHDv2CQyxV2I0j+
LOkZ+/w+3X5zFxiGGDGLvvcVTIyWnxpuK1NeGKs0IqYrH0pndwTV0eekIH7QQmc=
=gFIy
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161009/1039ebf5/attachment.key>

From yvoinov at gmail.com  Sat Oct  8 22:39:03 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 9 Oct 2016 04:39:03 +0600
Subject: [squid-users] Your real byte hit
In-Reply-To: <1475964682025-4680016.post@n4.nabble.com>
References: <5eb45170-15ff-36cd-4899-5171831e5ea2@gmail.com>
 <1475964682025-4680016.post@n4.nabble.com>
Message-ID: <99b77356-88b0-8e87-9a03-6a559a4c5e8f@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Blue line :) Colorblind go to the optometrist :)


09.10.2016 4:11, reinerotto ?????:
> You mean the 10% ? No problem.
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Your-real-byte-hit-tp4680014p4680016.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX+XWHAAoJENNXIZxhPexGac0H/R0TZ1k/nRCU8aC/+07fm6lz
23PnPAt1DoL5EtAV2+auK9GkP+9lXvlX01h0GVZ+S5wJD1kBK4ymPYzl4yRAO3h9
7ptr/02r90/3snarxQuKKGVE7r32cW+Pf/Fa11iO99yvXsnOQ+ircbJDoxOpKmsd
ZzHduwJwVG0XaMBJIq5aa1xzywumEd5xv0/zpTYYRoHJ+r2mIEcTZr/Yi+oatm61
SfoKhVtqiDQtkkGlMW5Wk+f96jDptU2J+IrdO1Y4BpqsHlGtGybtzhsueIyi6WOJ
kTcGRwf8VL6BcmjbDULZYC+AbeDl56L92nriwh7tcOQnQqbSW3pl0gigjil2wEY=
=qRgM
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161009/dea3fbfe/attachment.key>

From yvoinov at gmail.com  Sat Oct  8 22:44:37 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 9 Oct 2016 04:44:37 +0600
Subject: [squid-users] Your real byte hit
In-Reply-To: <99b77356-88b0-8e87-9a03-6a559a4c5e8f@gmail.com>
References: <5eb45170-15ff-36cd-4899-5171831e5ea2@gmail.com>
 <1475964682025-4680016.post@n4.nabble.com>
 <99b77356-88b0-8e87-9a03-6a559a4c5e8f@gmail.com>
Message-ID: <488b5743-41b7-bee1-c8dd-a1006cf375a7@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Those who understand - have rushed to they monitor :)

PS. HIT is about nothing. Only BYTE HIT matters.

09.10.2016 4:39, Yuri Voinov ?????:
>
> Blue line :) Colorblind go to the optometrist :)
>
>
> 09.10.2016 4:11, reinerotto ?????:
> > You mean the 10% ? No problem.
>
>
>
> > --
> > View this message in context:
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Your-real-byte-hit-tp4680014p4680016.html
> > Sent from the Squid - Users mailing list archive at Nabble.com.
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX+XbVAAoJENNXIZxhPexGW9gH/2ReJoka1jQQ1nLl/sTNBr4p
Z+UACXg1iR9V6I3JJfGHBE18joeF+kDq1HlvCGFQu6j0ZZcgPPhIwKqFDdBOHbbn
kzwmCUzPedmFQfq1rIFWab0UbV4VP85uNkWTyPqgSiSR65dDB38uwy4NpD8Bn1+Q
uwx2csS+8WIMvlvfMqvO5PVFTUQmM4pO1x2SiPcjWpkFALCjVRceCbMYhm7wVBFh
EOvt8TtyfFm+qvR8yGAGMMpNm2RSJ3I03/cVwa3/YCIy3c9I1hI9590LPMjky2CT
0ef6MHYjkSSKZfaJWKzaEN9b5OqEZRjlKfe26ufvw5++ntAJ0UsNQ8/2bskJ3IM=
=dKyT
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161009/64f225c8/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161009/64f225c8/attachment.key>

From yvoinov at gmail.com  Sat Oct  8 23:08:41 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 9 Oct 2016 05:08:41 +0600
Subject: [squid-users] Your real byte hit
In-Reply-To: <488b5743-41b7-bee1-c8dd-a1006cf375a7@gmail.com>
References: <5eb45170-15ff-36cd-4899-5171831e5ea2@gmail.com>
 <1475964682025-4680016.post@n4.nabble.com>
 <99b77356-88b0-8e87-9a03-6a559a4c5e8f@gmail.com>
 <488b5743-41b7-bee1-c8dd-a1006cf375a7@gmail.com>
Message-ID: <109378ae-31a0-5454-c5d3-83e8ec84a5f2@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
But you can continue to assume that the hit - a measure of the
efficiency of the cache :)


09.10.2016 4:44, Yuri Voinov ?????:
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
> 
> Those who understand - have rushed to they monitor :)
>
> PS. HIT is about nothing. Only BYTE HIT matters.
>
> 09.10.2016 4:39, Yuri Voinov ?????:
> >
>
>       > Blue line :) Colorblind go to the optometrist :)
>
>       >
>
>       >
>
>       > 09.10.2016 4:11, reinerotto ?????:
>
>       > > You mean the 10% ? No problem.
>
>       >
>
>       >
>
>       >
>
>       > > --
>
>       > > View this message in context:
>
>       >
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Your-real-byte-hit-tp4680014p4680016.html
>
>       > > Sent from the Squid - Users mailing list archive at
>       Nabble.com.
>
>       > > _______________________________________________
>
>       > > squid-users mailing list
>
>       > > squid-users at lists.squid-cache.org
>
>       > > http://lists.squid-cache.org/listinfo/squid-users
>
>       >
>
>       >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
> 
> iQEcBAEBCAAGBQJX+XbVAAoJENNXIZxhPexGW9gH/2ReJoka1jQQ1nLl/sTNBr4p
> Z+UACXg1iR9V6I3JJfGHBE18joeF+kDq1HlvCGFQu6j0ZZcgPPhIwKqFDdBOHbbn
> kzwmCUzPedmFQfq1rIFWab0UbV4VP85uNkWTyPqgSiSR65dDB38uwy4NpD8Bn1+Q
> uwx2csS+8WIMvlvfMqvO5PVFTUQmM4pO1x2SiPcjWpkFALCjVRceCbMYhm7wVBFh
> EOvt8TtyfFm+qvR8yGAGMMpNm2RSJ3I03/cVwa3/YCIy3c9I1hI9590LPMjky2CT
> 0ef6MHYjkSSKZfaJWKzaEN9b5OqEZRjlKfe26ufvw5++ntAJ0UsNQ8/2bskJ3IM=
> =dKyT
> -----END PGP SIGNATURE-----
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX+Xx4AAoJENNXIZxhPexGRvoH/2kRQ3LwiU08UtOPcrIxzsTz
W0jT1x979iDwcZTlnCUoULWMdLqK26kNStmQvzJcIE5ZxKXA/1tHU5F3ifJ5zWIi
Bnlb/xbehZRulxSCz6FUBLpZorxWRxaCNYAcLcfWQQw81mw4jidtujxQbbz7esZm
qviFuKnJorXJl5MyazXVnVUrR6jWdGS8G57eZbcDoExE/tBGZVCGO0bZK8b53THS
Q4+wUI8uFnk5neImF0xMuDwnp11JAONsAxWnuNgIY2I1xnwoqjyQ5MT/y2wtdO7Z
Dzl8KP0Db+Xx5hUJa4xMx6Qjj12LkrI32rr4yEMuBB006FFXpw04uiHkuG4Hw7w=
=0Ger
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161009/64c440d6/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161009/64c440d6/attachment.key>

From yvoinov at gmail.com  Sat Oct  8 23:14:18 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 9 Oct 2016 05:14:18 +0600
Subject: [squid-users] Your real byte hit
In-Reply-To: <109378ae-31a0-5454-c5d3-83e8ec84a5f2@gmail.com>
References: <5eb45170-15ff-36cd-4899-5171831e5ea2@gmail.com>
 <1475964682025-4680016.post@n4.nabble.com>
 <99b77356-88b0-8e87-9a03-6a559a4c5e8f@gmail.com>
 <488b5743-41b7-bee1-c8dd-a1006cf375a7@gmail.com>
 <109378ae-31a0-5454-c5d3-83e8ec84a5f2@gmail.com>
Message-ID: <7d5cd8af-02a9-ecbe-9c23-2472179e07b7@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
(When you can just - you come and boast)

09.10.2016 5:08, Yuri Voinov ?????:
>
> But you can continue to assume that the hit - a measure of the
efficiency of the cache :)
>
>
> 09.10.2016 4:44, Yuri Voinov ?????:
>
>
>       > -----BEGIN PGP SIGNED MESSAGE-----
>
>       > Hash: SHA256
>
>
>
>       > Those who understand - have rushed to they monitor :)
>
>
>
>       > PS. HIT is about nothing. Only BYTE HIT matters.
>
>
>
>       > 09.10.2016 4:39, Yuri Voinov ?????:
>
>       > >
>
>
>
>       >       > Blue line :) Colorblind go to the optometrist :)
>
>
>
>       >       >
>
>
>
>       >       >
>
>
>
>       >       > 09.10.2016 4:11, reinerotto ?????:
>
>
>
>       >       > > You mean the 10% ? No problem.
>
>
>
>       >       >
>
>
>
>       >       >
>
>
>
>       >       >
>
>
>
>       >       > > --
>
>
>
>       >       > > View this message in context:
>
>
>
>       >       >
>
>
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Your-real-byte-hit-tp4680014p4680016.html
>
>
>
>       >       > > Sent from the Squid - Users mailing list
>       archive at
>
>       >       Nabble.com.
>
>
>
>       >       > >
>       _______________________________________________
>
>
>
>       >       > > squid-users mailing list
>
>
>
>       >       > > squid-users at lists.squid-cache.org
>
>
>
>       >       > >
>       http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>       >       >
>
>
>
>       >       >
>
>
>
>       >
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX+X3JAAoJENNXIZxhPexGloYH/jH9Ez8XraJxe2JBE3bY+p1F
JPTQvAX2xikl+MxIwcV15CC4NiNRStgXlvprgwwTk7gc+OkU2uan9j2RsvnPlUug
3SbQ7f0Ts7mhohrd9cJeoQGsFIVieaRlhOOqKWWmfZyrEHsp6mVm7U3XyeryhxMb
6PK2ec+eZBCgiPB9Bb08FFE9ouaIN+yAsRxJvjesZ8lx3OLeQ9p7kIfESEacJdFy
V7p39/lUGuti1buLUr3Hx7jFsck/VW+P9znFvZ3AvEp3TR/c+hOn0LKTcPaE4GIT
KFAG7TjmnwZRjG3UUkEzYWSWiaCCIOHIMcGBpIQyRuWRzOCsDrJgPGUABK1CVRI=
=FRMV
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161009/7179fa06/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161009/7179fa06/attachment.key>

From yvoinov at gmail.com  Sat Oct  8 23:19:23 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 9 Oct 2016 05:19:23 +0600
Subject: [squid-users] Your real byte hit
In-Reply-To: <7d5cd8af-02a9-ecbe-9c23-2472179e07b7@gmail.com>
References: <5eb45170-15ff-36cd-4899-5171831e5ea2@gmail.com>
 <1475964682025-4680016.post@n4.nabble.com>
 <99b77356-88b0-8e87-9a03-6a559a4c5e8f@gmail.com>
 <488b5743-41b7-bee1-c8dd-a1006cf375a7@gmail.com>
 <109378ae-31a0-5454-c5d3-83e8ec84a5f2@gmail.com>
 <7d5cd8af-02a9-ecbe-9c23-2472179e07b7@gmail.com>
Message-ID: <15657154-bc13-9cad-5c20-d6618d24031a@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
This is what Squid has to be.

Do not ask me to share configuration - it is not a magic configuration.
This is something else. Custom code, custom config, custom setup.

Train better! Hard luck!

09.10.2016 5:14, Yuri Voinov ?????:
>
> (When you can just - you come and boast)
>
> 09.10.2016 5:08, Yuri Voinov ?????:
>
>
>       > But you can continue to assume that the hit - a measure of
>       the efficiency of the cache :)
>
>
>
>
>
>       > 09.10.2016 4:44, Yuri Voinov ?????:
>
>
>
>
>
>       >       > -----BEGIN PGP SIGNED MESSAGE-----
>
>
>
>       >       > Hash: SHA256
>
>
>
>
>
>
>
>       >       > Those who understand - have rushed to they monitor
>       :)
>
>
>
>
>
>
>
>       >       > PS. HIT is about nothing. Only BYTE HIT matters.
>
>
>
>
>
>
>
>       >       > 09.10.2016 4:39, Yuri Voinov ?????:
>
>
>
>       >       > >
>
>
>
>
>
>
>
>       >       >       > Blue line :) Colorblind go to the
>       optometrist :)
>
>
>
>
>
>
>
>       >       >       >
>
>
>
>
>
>
>
>       >       >       >
>
>
>
>
>
>
>
>       >       >       > 09.10.2016 4:11, reinerotto ?????:
>
>
>
>
>
>
>
>       >       >       > > You mean the 10% ? No problem.
>
>
>
>
>
>
>
>       >       >       >
>
>
>
>
>
>
>
>       >       >       >
>
>
>
>
>
>
>
>       >       >       >
>
>
>
>
>
>
>
>       >       >       > > --
>
>
>
>
>
>
>
>       >       >       > > View this message in context:
>
>
>
>
>
>
>
>       >       >       >
>
>
>
>
>
>
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Your-real-byte-hit-tp4680014p4680016.html
>
>
>
>
>
>
>
>       >       >       > > Sent from the Squid - Users
>       mailing list
>
>       >       archive at
>
>
>
>       >       >       Nabble.com.
>
>
>
>
>
>
>
>       >       >       > >
>
>       >       _______________________________________________
>
>
>
>
>
>
>
>       >       >       > > squid-users mailing list
>
>
>
>
>
>
>
>       >       >       > > squid-users at lists.squid-cache.org
>
>
>
>
>
>
>
>       >       >       > >
>
>       >       http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>       >       >       >
>
>
>
>
>
>
>
>       >       >       >
>
>
>
>
>
>
>
>       >       >
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX+X76AAoJENNXIZxhPexG50oIALVlf8oENcy4CLU2ocMWHLM3
Se//9GKOGqr7VCMfgqcp459MGZjDmkqvfr+0Eh4uHQXB4QylHI6X+LqtQ6GYhU5E
IS85+handElJ9eb+ZrBKvX2eipKjUKd6fGuwsd9mBey7bZB7yDKwWVXsJ9YF3E99
L8dEvHoxNSlJ625NbC07t/WshsqOVJ4enrN4jomjZlljJi1NOrCbnQ6p8xf6Ui4B
yz4yIgplYOpijvhAExzFnlJ5OhMmPSp2TYQtwt3fr5ve76bSN1s+i/EiWuv/d0TI
VafwhlyC2XaL434rG/rMk6/KRvOUavMcpN65Zt8NpfyP7SUJ44d6TTvBIVdI5uA=
=ML2K
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161009/d7bf2826/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161009/d7bf2826/attachment.key>

From augustus_meyer at gmx.net  Sun Oct  9 08:00:43 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Sun, 9 Oct 2016 01:00:43 -0700 (PDT)
Subject: [squid-users] Your real byte hit
In-Reply-To: <70bc7cd2-dce5-154b-617d-61b7241de62b@gmail.com>
References: <5eb45170-15ff-36cd-4899-5171831e5ea2@gmail.com>
 <1475964682025-4680016.post@n4.nabble.com>
 <70bc7cd2-dce5-154b-617d-61b7241de62b@gmail.com>
Message-ID: <1476000043850-4680023.post@n4.nabble.com>

>I mean BYTE HIT :) If you have eyes :) <
Yes, I have. But you might consider to be more specific next time, when
offering a guesswork,
what you are refering to.




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Your-real-byte-hit-tp4680014p4680023.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From augustus_meyer at gmx.net  Sun Oct  9 08:16:48 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Sun, 9 Oct 2016 01:16:48 -0700 (PDT)
Subject: [squid-users] Your real byte hit
In-Reply-To: <109378ae-31a0-5454-c5d3-83e8ec84a5f2@gmail.com>
References: <5eb45170-15ff-36cd-4899-5171831e5ea2@gmail.com>
 <1475964682025-4680016.post@n4.nabble.com>
 <99b77356-88b0-8e87-9a03-6a559a4c5e8f@gmail.com>
 <488b5743-41b7-bee1-c8dd-a1006cf375a7@gmail.com>
 <109378ae-31a0-5454-c5d3-83e8ec84a5f2@gmail.com>
Message-ID: <1476001008864-4680024.post@n4.nabble.com>

>But you can continue to assume that the hit - a measure of the efficiency of
the cache :)<

It depends on, whether you want to optimize towards lowest traffic volume on
the connection to the web, _or_ towards user experience, regarding "browser
speed", for example.

Or, some people are more addicted to quantity, others to quality.





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Your-real-byte-hit-tp4680014p4680024.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From jlay at slave-tothe-box.net  Sun Oct  9 17:02:35 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Sun, 09 Oct 2016 11:02:35 -0600
Subject: [squid-users] ICAP question
Message-ID: <1476032555.2264.5.camel@slave-tothe-box.net>

Trying to just get some content filtering working and I'm running into
the below:

WARNING: Squid is configured to use ICAP method REQMOD for service
icap://localhost:1344/srv_cfg_filter but OPTIONS response declares the
methods are RESPMOD?

Here's the icap snippet from squid.conf:

icap_enable on
icap_send_client_ip on
icap_persistent_connections on
icap_service srv_cfg_filter_req reqmod_precache
icap://localhost:1344/srv_cfg_filter bypass=on
adaptation_access srv_cfg_filter_req allow all
icap_service srv_cfg_filter_resp respmod_precache
icap://localhost:1344/srv_cfg_filter bypass=off
adaptation_access srv_cfg_filter_resp allow all

interesting c-icap.conf bits:

ModulesDir /opt/icap/lib/c_icap
ServicesDir /opt/icap/lib/c_icap
acl localhost src 127.0.0.1/255.255.255.255
acl PERMIT_REQUESTS type REQMOD RESPMOD
icap_access allow localhost PERMIT_REQUESTS
icap_access deny all
Include srv_content_filtering.conf

lastly, srv_content_filtering.conf:

Service srv_cfg_filter srv_content_filtering.so
srv_content_filtering.Match default body /(test)/ig score=5
LogFormat mySrvContentFiltering "%tl, %>a %im %is %huo??[Scores:
%{srv_content_filtering:scores}Sa] [ActionFilter:
%{srv_content_filtering:action_filter}Sa] [Action:
%{srv_content_filtering:action}Sa]"

not sure why I can't seem to get this to fly...any assistance would be
appreciated...thank you.

James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161009/8fd68b51/attachment.htm>

From webmaster at squidblacklist.org  Sun Oct  9 17:09:41 2016
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Sun, 9 Oct 2016 12:09:41 -0500
Subject: [squid-users] ICAP question
In-Reply-To: <1476032555.2264.5.camel@slave-tothe-box.net>
References: <1476032555.2264.5.camel@slave-tothe-box.net>
Message-ID: <99dca644-d1da-6a0b-bfa7-44721e7f481e@squidblacklist.org>

Dearest Mr. James Lay.

After considering your previous slanderous, and inflammatory trolling of 
my earlier correspondence, my initial response is to help alleviate your 
issue but rather, I think not, I believe considering the nature of your 
personal disposition to be a slanderous communist piece of human poop, 
instead rather, I shall instruct you to go walk yourself off of a bridge 
, yes Mr. James Lay.


On 10/9/2016 12:02 PM, James Lay wrote:
> Trying to just get some content filtering working and I'm running into 
> the below:
>
> WARNING: Squid is configured to use ICAP method REQMOD for service 
> icap://localhost:1344/srv_cfg_filter but OPTIONS response declares the 
> methods are RESPMOD
>
> Here's the icap snippet from squid.conf:
>
> icap_enable on
> icap_send_client_ip on
> icap_persistent_connections on
> icap_service srv_cfg_filter_req reqmod_precache 
> icap://localhost:1344/srv_cfg_filter bypass=on
> adaptation_access srv_cfg_filter_req allow all
> icap_service srv_cfg_filter_resp respmod_precache 
> icap://localhost:1344/srv_cfg_filter bypass=off
> adaptation_access srv_cfg_filter_resp allow all
>
> interesting c-icap.conf bits:
>
> ModulesDir /opt/icap/lib/c_icap
> ServicesDir /opt/icap/lib/c_icap
> acl localhost src 127.0.0.1/255.255.255.255
> acl PERMIT_REQUESTS type REQMOD RESPMOD
> icap_access allow localhost PERMIT_REQUESTS
> icap_access deny all
> Include srv_content_filtering.conf
>
> lastly, srv_content_filtering.conf:
>
> Service srv_cfg_filter srv_content_filtering.so
> srv_content_filtering.Match default body /(test)/ig score=5
> LogFormat mySrvContentFiltering "%tl, %>a %im %is %huo  [Scores: 
> %{srv_content_filtering:scores}Sa] [ActionFilter: 
> %{srv_content_filtering:action_filter}Sa] [Action: 
> %{srv_content_filtering:action}Sa]"
>
> not sure why I can't seem to get this to fly...any assistance would be 
> appreciated...thank you.
>
> James
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Signed,

Benjamin E. Nichols

http://www.squidblacklist.org

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161009/3396ab4a/attachment.htm>

From rousskov at measurement-factory.com  Sun Oct  9 18:43:23 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 9 Oct 2016 12:43:23 -0600
Subject: [squid-users] ICAP question
In-Reply-To: <1476032555.2264.5.camel@slave-tothe-box.net>
References: <1476032555.2264.5.camel@slave-tothe-box.net>
Message-ID: <e48029e8-b0aa-32a2-1b65-1ed310597898@measurement-factory.com>

On 10/09/2016 11:02 AM, James Lay wrote:

> WARNING: Squid is configured to use ICAP method REQMOD for service
> icap://localhost:1344/srv_cfg_filter but OPTIONS response declares the
> methods are RESPMOD

If your srv_content_filtering.so service does not need to see HTTP
requests, then you can remove srv_cfg_filter_req from your Squid
configuration.

If your srv_content_filtering.so service needs to see both HTTP requests
and responses, then you have two options, in no particular order:

A) Tell c-icap and/or srv_content_filtering.so to send a "Methods:
REQMOD,RESPMOD" ICAP response header field in OPTIONS response. Sorry, I
do not know how to do that in c-icap and even whether that is actually
possible with that software. Please note that using one service URI for
two modes is not uncommon in the ICAP world, but violates the following
ICAP RFC 3507 MUST:

  Each service should have a distinct URI
  and support only one method in addition to OPTIONS

B) Use different ICAP service URIs for different services (REQMOD and
RESPMOD) and configure each service appropriately on both Squid and
c-icap side. This is what RFC 3507 wants you to do. For example, some
ICAP servers and services would allow you to use these URIs:

  * for REQMOD: icap://localhost:1344/srv_cfg_filter?mode=REQMOD
  * for RESPMOD: icap://localhost:1344/srv_cfg_filter?mode=RESPMOD


IIRC, Squid will try to use your service in both modes despite that
WARNING. However, I do not know whether c-icap and that service itself
will be happy about receiving REQMOD requests.


HTH,

Alex.



> Here's the icap snippet from squid.conf:
> 
> icap_enable on
> icap_send_client_ip on
> icap_persistent_connections on
> icap_service srv_cfg_filter_req reqmod_precache
> icap://localhost:1344/srv_cfg_filter bypass=on
> adaptation_access srv_cfg_filter_req allow all
> icap_service srv_cfg_filter_resp respmod_precache
> icap://localhost:1344/srv_cfg_filter bypass=off
> adaptation_access srv_cfg_filter_resp allow all
> 
> interesting c-icap.conf bits:
> 
> ModulesDir /opt/icap/lib/c_icap
> ServicesDir /opt/icap/lib/c_icap
> acl localhost src 127.0.0.1/255.255.255.255
> acl PERMIT_REQUESTS type REQMOD RESPMOD
> icap_access allow localhost PERMIT_REQUESTS
> icap_access deny all
> Include srv_content_filtering.conf
> 
> lastly, srv_content_filtering.conf:
> 
> Service srv_cfg_filter srv_content_filtering.so
> srv_content_filtering.Match default body /(test)/ig score=5
> LogFormat mySrvContentFiltering "%tl, %>a %im %is %huo  [Scores:
> %{srv_content_filtering:scores}Sa] [ActionFilter:
> %{srv_content_filtering:action_filter}Sa] [Action:
> %{srv_content_filtering:action}Sa]"
> 
> not sure why I can't seem to get this to fly...any assistance would be
> appreciated...thank you.



From jlay at slave-tothe-box.net  Sun Oct  9 19:40:39 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Sun, 09 Oct 2016 13:40:39 -0600
Subject: [squid-users] ICAP question
In-Reply-To: <e48029e8-b0aa-32a2-1b65-1ed310597898@measurement-factory.com>
References: <1476032555.2264.5.camel@slave-tothe-box.net>
 <e48029e8-b0aa-32a2-1b65-1ed310597898@measurement-factory.com>
Message-ID: <1476042039.2264.7.camel@slave-tothe-box.net>

On Sun, 2016-10-09 at 12:43 -0600, Alex Rousskov wrote:
> On 10/09/2016 11:02 AM, James Lay wrote:
> 
> > 
> > WARNING: Squid is configured to use ICAP method REQMOD for service
> > icap://localhost:1344/srv_cfg_filter but OPTIONS response declares
> > the
> > methods are RESPMOD
> If your srv_content_filtering.so service does not need to see HTTP
> requests, then you can remove srv_cfg_filter_req from your Squid
> configuration.
> 
> If your srv_content_filtering.so service needs to see both HTTP
> requests
> and responses, then you have two options, in no particular order:
> 
> A) Tell c-icap and/or srv_content_filtering.so to send a "Methods:
> REQMOD,RESPMOD" ICAP response header field in OPTIONS response.
> Sorry, I
> do not know how to do that in c-icap and even whether that is
> actually
> possible with that software. Please note that using one service URI
> for
> two modes is not uncommon in the ICAP world, but violates the
> following
> ICAP RFC 3507 MUST:
> 
> ? Each service should have a distinct URI
> ? and support only one method in addition to OPTIONS
> 
> B) Use different ICAP service URIs for different services (REQMOD and
> RESPMOD) and configure each service appropriately on both Squid and
> c-icap side. This is what RFC 3507 wants you to do. For example, some
> ICAP servers and services would allow you to use these URIs:
> 
> ? * for REQMOD: icap://localhost:1344/srv_cfg_filter?mode=REQMOD
> ? * for RESPMOD: icap://localhost:1344/srv_cfg_filter?mode=RESPMOD
> 
> 
> IIRC, Squid will try to use your service in both modes despite that
> WARNING. However, I do not know whether c-icap and that service
> itself
> will be happy about receiving REQMOD requests.
> 
> 
> HTH,
> 
> Alex.
> 
> 
> 
> > 
> > Here's the icap snippet from squid.conf:
> > 
> > icap_enable on
> > icap_send_client_ip on
> > icap_persistent_connections on
> > icap_service srv_cfg_filter_req reqmod_precache
> > icap://localhost:1344/srv_cfg_filter bypass=on
> > adaptation_access srv_cfg_filter_req allow all
> > icap_service srv_cfg_filter_resp respmod_precache
> > icap://localhost:1344/srv_cfg_filter bypass=off
> > adaptation_access srv_cfg_filter_resp allow all
> > 
> > interesting c-icap.conf bits:
> > 
> > ModulesDir /opt/icap/lib/c_icap
> > ServicesDir /opt/icap/lib/c_icap
> > acl localhost src 127.0.0.1/255.255.255.255
> > acl PERMIT_REQUESTS type REQMOD RESPMOD
> > icap_access allow localhost PERMIT_REQUESTS
> > icap_access deny all
> > Include srv_content_filtering.conf
> > 
> > lastly, srv_content_filtering.conf:
> > 
> > Service srv_cfg_filter srv_content_filtering.so
> > srv_content_filtering.Match default body /(test)/ig score=5
> > LogFormat mySrvContentFiltering "%tl, %>a %im %is %huo??[Scores:
> > %{srv_content_filtering:scores}Sa] [ActionFilter:
> > %{srv_content_filtering:action_filter}Sa] [Action:
> > %{srv_content_filtering:action}Sa]"
> > 
> > not sure why I can't seem to get this to fly...any assistance would
> > be
> > appreciated...thank you.
Thank you Alex....I followed:
http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
As best I could, but it looks like that adapter needs something
different. ?I'll report my results here once I get it fixed.
James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161009/2a7ddb89/attachment.htm>

From gaardiolor at gmail.com  Sun Oct  9 20:51:23 2016
From: gaardiolor at gmail.com (Marc)
Date: Sun, 9 Oct 2016 22:51:23 +0200
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
 code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <CAPxJK5Bifwae+-h9Yrpvvpjh=zLGJoD2e-49bsPqA9LguMY=kw@mail.gmail.com>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
 <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
 <2077594026.2082495.1475235384241@mail.yahoo.com>
 <af92d108-b205-decb-13c4-fecb7a554b5e@gmail.com>
 <421701582.3214410.1475478705099@mail.yahoo.com>
 <f4e0b806-587c-ed2e-4941-b5cccbcda0d1@treenet.co.nz>
 <1410278953.3964483.1475579267802@mail.yahoo.com>
 <2aeb5cbc-67aa-0742-efb1-ab123c638bc6@treenet.co.nz>
 <CAPxJK5BD-CnAOWM3Gb+=a+O7UUOBqCuD5_oHvx8WswrGrMtAGQ@mail.gmail.com>
 <1780209473.10531511.1475734259504@mail.yahoo.com>
 <CAPxJK5Bifwae+-h9Yrpvvpjh=zLGJoD2e-49bsPqA9LguMY=kw@mail.gmail.com>
Message-ID: <CAPxJK5D8kPHs0Zqfb3tjEHbCpJy71-p7SNvLWRCGBc3nJwKH2w@mail.gmail.com>

Hi Vieri,

Squid 4 fixes it, in my case. Same config, same system.

Regards,

Marc

On Thu, Oct 6, 2016 at 11:00 PM, Marc <gaardiolor at gmail.com> wrote:
> Hi Viery,
>
> Sorry, copy/paste error, my bad. Please try:
>
> openssl s_client -quiet -connect www.google.com:443 -tls1 -cipher
> RC4-MD5:RC4-SHA:DES-CBC3-SHA:DES-CBC-SHA:EXP1024-RC4-SHA:EXP1024-DES-CBC-SHA:EXP-RC4-MD5:EXP-RC2-CBC-MD5:DHE-DSS-DES-CBC3-SHA:DHE-DSS-CBC-SHA:EXP1024-DHE-DSS-DES-CBC-SHA
> < <(echo -e "GET / HTTP/1.1\nHost: www.google.com\n\n")
> That one fails (at least with me). Squid replies with 503 Service
> unavailable, SQUID_ERR_SSL_HANDSHAKE .
>
> Now adding a random extension:
> openssl s_client -quiet -connect www.google.com:443 -tls1 -cipher
> RC4-MD5:RC4-SHA:DES-CBC3-SHA:DES-CBC-SHA:EXP1024-RC4-SHA:EXP1024-DES-CBC-SHA:EXP-RC4-MD5:EXP-RC2-CBC-MD5:DHE-DSS-DES-CBC3-SHA:DHE-DSS-CBC-SHA:EXP1024-DHE-DSS-DES-CBC-SHA
> -serverinfo 12345 < <(echo -e "GET / HTTP/1.1\nHost:
> www.google.com\n\n")
> That one succeeds (302 Found). At least with me. The extension doesn't
> have to be 12345, some regular ones do the trick as well. But openssl
> doesn't always include the existing ones correctly, so I used the
> dummy.
>
> Please let me know. If adding a random extension fixes the error with
> you too, well.. It could be a step in the right direction towards
> finding the cause of this problem.
>
> Marc


From fredbmail at free.fr  Mon Oct 10 07:39:03 2016
From: fredbmail at free.fr (FredB)
Date: Mon, 10 Oct 2016 09:39:03 +0200 (CEST)
Subject: [squid-users] ICAP and user ID
In-Reply-To: <e1959930-235f-d93a-c361-1b6186bd1005@measurement-factory.com>
Message-ID: <1915126790.983046105.1476085143536.JavaMail.root@zimbra4-e1.priv.proxad.net>


Thanks great, if I understand right there is no missing data, all the complete request (HEADER + DATA) can be transmitted to an ICAP server ?

Fred



From eliezer at ngtech.co.il  Mon Oct 10 09:28:38 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 10 Oct 2016 12:28:38 +0300
Subject: [squid-users] ICAP question
In-Reply-To: <1476032555.2264.5.camel@slave-tothe-box.net>
References: <1476032555.2264.5.camel@slave-tothe-box.net>
Message-ID: <024901d222d8$aeb9acd0$0c2d0670$@ngtech.co.il>

I am not sure but it seems to me like I might not understood squid ACLS
right but yet to be 100% about it.
acl PERMIT_REQUESTS type REQMOD RESPMOD
icap_access allow localhost PERMIT_REQUESTS
icap_access deny all

The acl as far as I know doesn?t have any type such as ICAP request mode.
Am I right?

Eliezer

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il
 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of James Lay
Sent: Sunday, October 9, 2016 8:03 PM
To: squid-users
Subject: [squid-users] ICAP question

Trying to just get some content filtering working and I'm running into the
below:

WARNING: Squid is configured to use ICAP method REQMOD for service
icap://localhost:1344/srv_cfg_filter but OPTIONS response declares the
methods are RESPMOD 

Here's the icap snippet from squid.conf:

icap_enable on
icap_send_client_ip on
icap_persistent_connections on
icap_service srv_cfg_filter_req reqmod_precache
icap://localhost:1344/srv_cfg_filter bypass=on
adaptation_access srv_cfg_filter_req allow all
icap_service srv_cfg_filter_resp respmod_precache
icap://localhost:1344/srv_cfg_filter bypass=off
adaptation_access srv_cfg_filter_resp allow all

interesting c-icap.conf bits:

ModulesDir /opt/icap/lib/c_icap
ServicesDir /opt/icap/lib/c_icap
acl localhost src 127.0.0.1/255.255.255.255
acl PERMIT_REQUESTS type REQMOD RESPMOD
icap_access allow localhost PERMIT_REQUESTS
icap_access deny all
Include srv_content_filtering.conf

lastly, srv_content_filtering.conf:

Service srv_cfg_filter srv_content_filtering.so
srv_content_filtering.Match default body /(test)/ig score=5
LogFormat mySrvContentFiltering "%tl, %>a %im %is %huo  [Scores:
%{srv_content_filtering:scores}Sa] [ActionFilter:
%{srv_content_filtering:action_filter}Sa] [Action:
%{srv_content_filtering:action}Sa]"

not sure why I can't seem to get this to fly...any assistance would be
appreciated...thank you.

James
-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 64797 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161010/8e7cb925/attachment.bin>

From eliezer at ngtech.co.il  Mon Oct 10 09:35:50 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 10 Oct 2016 12:35:50 +0300
Subject: [squid-users] Squid Slowness Issues
In-Reply-To: <219ac62f-cbba-86e7-3bb2-45b5b6b8f5e2@treenet.co.nz>
References: <CAN-hqtirzmELN5z+nw+NhQ=HxjEkGdbSDEBYYOHA3jy=8-8F9Q@mail.gmail.com>
 <219ac62f-cbba-86e7-3bb2-45b5b6b8f5e2@treenet.co.nz>
Message-ID: <025201d222d9$b035a900$10a0fb00$@ngtech.co.il>

And If I may add without being rude:
There are cases which squid can slow down traffic compared to a routing only setup.
Due to this it's very important to verify if squid is the right solution for any given scenario.
And I believe in what Alex said in the past "it's not a weekend task".

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Saturday, October 8, 2016 4:37 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid Slowness Issues

On 7/10/2016 10:48 p.m., Krishna Kulkarni wrote:
> Dear Team
> Thank you very much for accepting my request of mailing list membership..
> I am new to squid.. I have installed squid 3.5 on CentOS 6.7. As the
> configuration part, I have kept most of the things default. Please advice
> on how to allocate cache memory of 20 GB to squid. I got to know that, more
> cache memory would increase performance of squid..

Maybe, maybe not. "slow" is relative. But to what?

cache_mem is the directive you are asking for
<http://www.squid-cache.org/Doc/config/cache_mem/>

But "slow" is usually not a memory problem. Giving Squid *too much*
cache_mem or configuring othe things that take too much RAM can make the
system swap and slow down.
<http://wiki.squid-cache.org/SquidFaq/SquidMemory>

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Mon Oct 10 09:41:55 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 10 Oct 2016 12:41:55 +0300
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
	code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <CAPxJK5D8kPHs0Zqfb3tjEHbCpJy71-p7SNvLWRCGBc3nJwKH2w@mail.gmail.com>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
 <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
 <2077594026.2082495.1475235384241@mail.yahoo.com>
 <af92d108-b205-decb-13c4-fecb7a554b5e@gmail.com>
 <421701582.3214410.1475478705099@mail.yahoo.com>
 <f4e0b806-587c-ed2e-4941-b5cccbcda0d1@treenet.co.nz>
 <1410278953.3964483.1475579267802@mail.yahoo.com>
 <2aeb5cbc-67aa-0742-efb1-ab123c638bc6@treenet.co.nz>
 <CAPxJK5BD-CnAOWM3Gb+=a+O7UUOBqCuD5_oHvx8WswrGrMtAGQ@mail.gmail.com>
 <1780209473.10531511.1475734259504@mail.yahoo.com>
 <CAPxJK5Bifwae+-h9Yrpvvpjh=zLGJoD2e-49bsPqA9LguMY=kw@mail.gmail.com>
 <CAPxJK5D8kPHs0Zqfb3tjEHbCpJy71-p7SNvLWRCGBc3nJwKH2w@mail.gmail.com>
Message-ID: <025301d222da$899a4750$9cced5f0$@ngtech.co.il>

Thanks for updating!

May I ask what version of Linux are you using squid ontop?
I have released couple RPMs and am working on releasing a drop-in tar.xz for debian based systems.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Marc
Sent: Sunday, October 9, 2016 11:51 PM
To: Vieri
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)

Hi Vieri,

Squid 4 fixes it, in my case. Same config, same system.

Regards,

Marc

On Thu, Oct 6, 2016 at 11:00 PM, Marc <gaardiolor at gmail.com> wrote:
> Hi Viery,
>
> Sorry, copy/paste error, my bad. Please try:
>
> openssl s_client -quiet -connect www.google.com:443 -tls1 -cipher
> RC4-MD5:RC4-SHA:DES-CBC3-SHA:DES-CBC-SHA:EXP1024-RC4-SHA:EXP1024-DES-CBC-SHA:EXP-RC4-MD5:EXP-RC2-CBC-MD5:DHE-DSS-DES-CBC3-SHA:DHE-DSS-CBC-SHA:EXP1024-DHE-DSS-DES-CBC-SHA
> < <(echo -e "GET / HTTP/1.1\nHost: www.google.com\n\n")
> That one fails (at least with me). Squid replies with 503 Service
> unavailable, SQUID_ERR_SSL_HANDSHAKE .
>
> Now adding a random extension:
> openssl s_client -quiet -connect www.google.com:443 -tls1 -cipher
> RC4-MD5:RC4-SHA:DES-CBC3-SHA:DES-CBC-SHA:EXP1024-RC4-SHA:EXP1024-DES-CBC-SHA:EXP-RC4-MD5:EXP-RC2-CBC-MD5:DHE-DSS-DES-CBC3-SHA:DHE-DSS-CBC-SHA:EXP1024-DHE-DSS-DES-CBC-SHA
> -serverinfo 12345 < <(echo -e "GET / HTTP/1.1\nHost:
> www.google.com\n\n")
> That one succeeds (302 Found). At least with me. The extension doesn't
> have to be 12345, some regular ones do the trick as well. But openssl
> doesn't always include the existing ones correctly, so I used the
> dummy.
>
> Please let me know. If adding a random extension fixes the error with
> you too, well.. It could be a step in the right direction towards
> finding the cause of this problem.
>
> Marc
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Mon Oct 10 10:22:23 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 10 Oct 2016 23:22:23 +1300
Subject: [squid-users] ICAP and user ID
In-Reply-To: <1915126790.983046105.1476085143536.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1915126790.983046105.1476085143536.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <0151ef0f-1853-7996-2a28-02b3b9414b06@treenet.co.nz>

On 10/10/2016 8:39 p.m., FredB wrote:
> 
> Thanks great, if I understand right there is no missing data, all the complete request (HEADER + DATA) can be transmitted to an ICAP server ?
> 

Well, no that exactly. What Squid passes to ICAP is *a* full header and
message. As Squid understands the client request to be. But not the
exact incoming bytes.

There is parsing and initial processing of the message done before ICAP.
Some (invalid) headers and the chunked encoding details do not make it
out of the initial parse or can be altered to valid forms before ICAP
receives them.
 It came to light that hop-by-hop headers in particular were not all
making it through to ICAP. The auth ones should now be fixed in the
latest 3.5, but we have not tested the others.

Amos



From squid3 at treenet.co.nz  Mon Oct 10 10:40:31 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 10 Oct 2016 23:40:31 +1300
Subject: [squid-users] Problem with Squid3 Caches
In-Reply-To: <7238A37A-DC74-4E4E-8A0A-B7CEA0A409B4@gmail.com>
References: <CD14793F-4F48-433E-9A1E-B2030E1D7F14@gmail.com>
 <201610032306.15880.Antony.Stone@squid.open.source.it>
 <B0508516-890C-4526-8848-78616839ABA5@gmail.com>
 <201610041745.20899.Antony.Stone@squid.open.source.it>
 <7DE7A0D4-9C50-48EF-A297-9E65A7E45AC8@gmail.com>
 <9c5a8d4f-40b3-939c-b22a-b57181f8f0ff@treenet.co.nz>
 <9BD4DA71-18E9-45E0-8BF8-52149DC38289@gmail.com>
 <2b123df7-bdec-0146-3454-a7e2b71bfffe@treenet.co.nz>
 <2D8085B2-95E3-4E49-9B16-AFD6108970B6@gmail.com>
 <c802221d-5ceb-b57d-2841-cf0427541061@treenet.co.nz>
 <764DD7B9-C150-4F68-B8BD-C313CDD51A30@gmail.com>
 <2108ba98-5430-8bed-dda9-2a468b48a3d0@treenet.co.nz>
 <7238A37A-DC74-4E4E-8A0A-B7CEA0A409B4@gmail.com>
Message-ID: <c5575218-9f7b-4ec1-cb61-02cab6a26953@treenet.co.nz>

FYI: I am an IT consultant by trade. If you want private help I am happy
to do so after receiving a PayPal donation via the buttons at
<http://treenet.co.nz/projects/squid/>.

Otherwise please keep the replies going to the list so others who know
the answers join in faster than I can reply, and everyone benefits.


On 9/10/2016 3:52 p.m., KR wrote:
> Hi Amos - 
> 
> So I believe I fixed the rock cache by specifying cache_dir /ssd1 5000 but now I?m getting an error regarding writing to a file:
> 
> squid
> 2016/10/08 22:42:49| ALERT: setgid: (1) Operation not permitted
> WARNING: Cannot write log file: /var/log/squid/cache.log
> /var/log/squid/cache.log: Permission denied
>          messages will be sent to 'stderr'.
> 2016/10/08 22:42:49| ALERT: setgid: (1) Operation not permitted
> 
> Permissions are:
> 
> drwxr-xr-x 2 proxy             proxy     4096 Oct  5 07:35 squid
> 
> So not sure why I?m getting this error.

That looks like Squid is not actually running as the user 'proxy', or
you are not starting it from an account that can change itself to be
that effective-user.

Squid-3 should be started by the root user, it will downgrade its
permissions before opening ports and handling traffic.

Amos



From yanghe0921 at 126.com  Mon Oct 10 11:41:54 2016
From: yanghe0921 at 126.com (ysu yang)
Date: Mon, 10 Oct 2016 04:41:54 -0700 (PDT)
Subject: [squid-users] How to configure squid to let ICAP get the port of
	client
Message-ID: <1476099714505-4680036.post@n4.nabble.com>

like "icap_send_client_ip on",ICAP can get the IP of client.but, I don't
found other similar configuration to let ICAP get the port of client.


    THX



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-to-configure-squid-to-let-ICAP-get-the-port-of-client-tp4680036.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yanghe0921 at 126.com  Mon Oct 10 11:50:46 2016
From: yanghe0921 at 126.com (yanghe)
Date: Mon, 10 Oct 2016 19:50:46 +0800
Subject: [squid-users] How to configure squid to let ICAP get the port of
	client
Message-ID: <78bc0e5c.f7b23.157ae6e4e00.Coremail.yanghe0921@126.com>

like "icap_send_client_ip on",ICAP can get the IP of client.but, I don't found other similar configuration to let ICAP get the port of client.


    THX

2016-10-10


  yanghe 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161010/e1f81bd5/attachment.htm>

From jlay at slave-tothe-box.net  Mon Oct 10 12:29:27 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Mon, 10 Oct 2016 06:29:27 -0600
Subject: [squid-users] ICAP question
In-Reply-To: <024901d222d8$aeb9acd0$0c2d0670$@ngtech.co.il>
References: <1476032555.2264.5.camel@slave-tothe-box.net>
 <024901d222d8$aeb9acd0$0c2d0670$@ngtech.co.il>
Message-ID: <1476102567.2264.9.camel@slave-tothe-box.net>

On Mon, 2016-10-10 at 12:28 +0300, Eliezer Croitoru wrote:
> I am not sure but it seems to me like I might not understood squid
> ACLS
> right but yet to be 100% about it.
> acl PERMIT_REQUESTS type REQMOD RESPMOD
> icap_access allow localhost PERMIT_REQUESTS
> icap_access deny all
> The acl as far as I know doesn?t have any type such as ICAP request mode.
> Am I right?
> 
> Eliezer
> 
> ----
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
> > 
> Linux System Administrator
> Mobile+WhatsApp: +972-5-28704261
> Email: eliezer at ngtech.co.il

I am not sure...I am going by the below:
http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/C-ICAP
James
>  
> 
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> ] On
> Behalf Of James Lay
> Sent: Sunday, October 9, 2016 8:03 PM
> To: squid-users
> Subject: [squid-users] ICAP question
> 
> Trying to just get some content filtering working and I'm running into the
> below:
> 
> WARNING: Squid is configured to use ICAP method REQMOD for service
> icap://localhost:1344/srv_cfg_filter but OPTIONS response declares the
> methods are RESPMOD 
> 
> Here's the icap snippet from squid.conf:
> 
> icap_enable on
> icap_send_client_ip on
> icap_persistent_connections on
> icap_service srv_cfg_filter_req reqmod_precache
> icap://localhost:1344/srv_cfg_filter bypass=on
> adaptation_access srv_cfg_filter_req allow all
> icap_service srv_cfg_filter_resp respmod_precache
> icap://localhost:1344/srv_cfg_filter bypass=off
> adaptation_access srv_cfg_filter_resp allow all
> 
> interesting c-icap.conf bits:
> 
> ModulesDir /opt/icap/lib/c_icap
> ServicesDir /opt/icap/lib/c_icap
> acl localhost src 127.0.0.1/255.255.255.255
> acl PERMIT_REQUESTS type REQMOD RESPMOD
> icap_access allow localhost PERMIT_REQUESTS
> icap_access deny all
> Include srv_content_filtering.conf
> 
> lastly, srv_content_filtering.conf:
> 
> Service srv_cfg_filter srv_content_filtering.so
> srv_content_filtering.Match default body /(test)/ig score=5
> LogFormat mySrvContentFiltering "%tl, %>a %im %is %huo  [Scores:
> %{srv_content_filtering:scores}Sa] [ActionFilter:
> %{srv_content_filtering:action_filter}Sa] [Action:
> %{srv_content_filtering:action}Sa]"
> 
> not sure why I can't seem to get this to fly...any assistance would be
> appreciated...thank you.
> 
> James
> 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161010/29dda70a/attachment.htm>

From gaardiolor at gmail.com  Mon Oct 10 13:53:40 2016
From: gaardiolor at gmail.com (Marc)
Date: Mon, 10 Oct 2016 15:53:40 +0200
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
 code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <025301d222da$899a4750$9cced5f0$@ngtech.co.il>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
 <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
 <2077594026.2082495.1475235384241@mail.yahoo.com>
 <af92d108-b205-decb-13c4-fecb7a554b5e@gmail.com>
 <421701582.3214410.1475478705099@mail.yahoo.com>
 <f4e0b806-587c-ed2e-4941-b5cccbcda0d1@treenet.co.nz>
 <1410278953.3964483.1475579267802@mail.yahoo.com>
 <2aeb5cbc-67aa-0742-efb1-ab123c638bc6@treenet.co.nz>
 <CAPxJK5BD-CnAOWM3Gb+=a+O7UUOBqCuD5_oHvx8WswrGrMtAGQ@mail.gmail.com>
 <1780209473.10531511.1475734259504@mail.yahoo.com>
 <CAPxJK5Bifwae+-h9Yrpvvpjh=zLGJoD2e-49bsPqA9LguMY=kw@mail.gmail.com>
 <CAPxJK5D8kPHs0Zqfb3tjEHbCpJy71-p7SNvLWRCGBc3nJwKH2w@mail.gmail.com>
 <025301d222da$899a4750$9cced5f0$@ngtech.co.il>
Message-ID: <CAPxJK5BNq_Y5Frbzb10Se1PPceRAfkG2R1-NUeO-2HJk2cWDCg@mail.gmail.com>

On Mon, Oct 10, 2016 at 11:41 AM, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> Thanks for updating!
>
> May I ask what version of Linux are you using squid ontop?
> I have released couple RPMs and am working on releasing a drop-in tar.xz for debian based systems.

Yeah sure, I'm using Fedora Core 24.
- Installed squid source RPM
- changed the specfile; changed version, removed patches, removed some
configure flags, added --disable-strict-error-checking otherwise it
didn't want to compile.
- built a new rpm .. works on my system, but ymmv
- patch against the Fedora source rpm spec file:

--- rpmbuild-squid-3.5.21/SPECS/squid.spec      2016-10-09
00:33:42.490934810 +0200
+++ rpmbuild-squid-4.0.14/SPECS/squid.spec      2016-10-09
17:33:26.739659533 +0200
@@ -1,7 +1,7 @@
 %define __perl_requires %{SOURCE98}

 Name:     squid
-Version:  3.5.21
+Version:  4.0.14
 Release:  1%{?dist}
 Summary:  The Squid proxy caching server
 Epoch:    7
@@ -9,8 +9,8 @@
 License:  GPLv2+ and (LGPLv2+ and MIT and BSD and Public Domain)
 Group:    System Environment/Daemons
 URL:      http://www.squid-cache.org
-Source0:  http://www.squid-cache.org/Versions/v3/3.5/squid-%{version}.tar.xz
-Source1:  http://www.squid-cache.org/Versions/v3/3.5/squid-%{version}.tar.xz.asc
+Source0:  http://www.squid-cache.org/Versions/v4/squid-%{version}.tar.xz
+Source1:  http://www.squid-cache.org/Versions/v4/squid-%{version}.tar.xz.asc
 Source2:  squid.logrotate
 Source3:  squid.sysconfig
 Source4:  squid.pam
@@ -27,11 +27,6 @@
 # Local patches
 # Applying upstream patches first makes it less likely that local patches
 # will break upstream ones.
-Patch201: squid-3.1.0.9-config.patch
-Patch202: squid-3.1.0.9-location.patch
-Patch203: squid-3.0.STABLE1-perlpath.patch
-Patch204: squid-3.5.9-include-guards.patch
-Patch205: 0001-cppunit-config-no-longer-exists-use-pkg-config.patch

 Buildroot: %{_tmppath}/%{name}-%{version}-%{release}-root-%(%{__id_u} -n)
 Requires: bash >= 2.0
@@ -87,11 +82,6 @@
 # Backported patches

 # Local patches
-%patch201 -p1 -b .config
-%patch202 -p1 -b .location
-%patch203 -p1 -b .perlpath
-%patch204 -p0 -b .include-guards
-%patch205 -p1 -b .cppunit-config

 %build
 # cppunit-config patch changes configure.ac
@@ -114,8 +104,8 @@
    --enable-eui \
    --enable-follow-x-forwarded-for \
    --enable-auth \
-   --enable-auth-basic="DB,LDAP,MSNT-multi-domain,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,getpwnam"
\
-   --enable-auth-ntlm="smb_lm,fake" \
+   --enable-auth-basic="DB,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,getpwnam" \
+   --enable-auth-ntlm="fake" \
    --enable-auth-digest="file,LDAP" \
    --enable-auth-negotiate="kerberos" \
    --enable-external-acl-helpers="LDAP_group,time_quota,session,unix_group,wbinfo_group"
\
@@ -145,7 +135,8 @@
    --with-openssl \
    --with-pthreads \
    --disable-arch-native \
-   --with-pic
+   --with-pic \
+   --disable-strict-error-checking

 make \
        DEFAULT_SWAP_DIR=%{_localstatedir}/spool/squid \
@@ -191,7 +182,7 @@
 install -m 644 %{SOURCE5}
$RPM_BUILD_ROOT%{_sysconfdir}/NetworkManager/dispatcher.d/20-squid
 mkdir -p $RPM_BUILD_ROOT%{_localstatedir}/log/squid
 mkdir -p $RPM_BUILD_ROOT%{_localstatedir}/spool/squid
-chmod 644 contrib/url-normalizer.pl contrib/rredir.* contrib/user-agents.pl
+chmod 644 contrib/url-normalizer.pl contrib/user-agents.pl
 iconv -f ISO88591 -t UTF8 ChangeLog -o ChangeLog.tmp
 mv -f ChangeLog.tmp ChangeLog

@@ -213,7 +204,7 @@
 %defattr(-,root,root,-)
 %license COPYING
 %doc CONTRIBUTORS README ChangeLog QUICKSTART src/squid.conf.documented
-%doc contrib/url-normalizer.pl contrib/rredir.* contrib/user-agents.pl
+%doc contrib/url-normalizer.pl contrib/user-agents.pl

 %{_unitdir}/squid.service
 %attr(755,root,root) %dir %{_libexecdir}/squid
@@ -286,6 +277,9 @@


From rousskov at measurement-factory.com  Mon Oct 10 16:04:44 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 10 Oct 2016 10:04:44 -0600
Subject: [squid-users] ICAP question
In-Reply-To: <024901d222d8$aeb9acd0$0c2d0670$@ngtech.co.il>
References: <1476032555.2264.5.camel@slave-tothe-box.net>
 <024901d222d8$aeb9acd0$0c2d0670$@ngtech.co.il>
Message-ID: <fcef9539-e20b-1c44-a22c-a05c9d8ec4be@measurement-factory.com>

On 10/10/2016 03:28 AM, Eliezer Croitoru wrote:
> I am not sure but it seems to me like I might not understood squid ACLS
> right but yet to be 100% about it.
> acl PERMIT_REQUESTS type REQMOD RESPMOD
> icap_access allow localhost PERMIT_REQUESTS
> icap_access deny all
> 
> The acl as far as I know doesn?t have any type such as ICAP request mode.
> Am I right?

AFAICT, you are looking at c-icap directives/ACLs, not Squid
directives/ACLs. They may look similar but they are not the same.

Alex.


> interesting c-icap.conf bits:
> 
> ModulesDir /opt/icap/lib/c_icap
> ServicesDir /opt/icap/lib/c_icap
> acl localhost src 127.0.0.1/255.255.255.255
> acl PERMIT_REQUESTS type REQMOD RESPMOD
> icap_access allow localhost PERMIT_REQUESTS
> icap_access deny all
> Include srv_content_filtering.conf
> 
> lastly, srv_content_filtering.conf:
> 
> Service srv_cfg_filter srv_content_filtering.so
> srv_content_filtering.Match default body /(test)/ig score=5
> LogFormat mySrvContentFiltering "%tl, %>a %im %is %huo  [Scores:
> %{srv_content_filtering:scores}Sa] [ActionFilter:
> %{srv_content_filtering:action_filter}Sa] [Action:
> %{srv_content_filtering:action}Sa]"



From rousskov at measurement-factory.com  Mon Oct 10 16:16:46 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 10 Oct 2016 10:16:46 -0600
Subject: [squid-users] How to configure squid to let ICAP get the port
 of client
In-Reply-To: <78bc0e5c.f7b23.157ae6e4e00.Coremail.yanghe0921@126.com>
References: <78bc0e5c.f7b23.157ae6e4e00.Coremail.yanghe0921@126.com>
Message-ID: <25f5604a-697e-9fd2-f3c6-7562157b8b1c@measurement-factory.com>

On 10/10/2016 05:50 AM, yanghe wrote:
> like "icap_send_client_ip on",ICAP can get the IP of client.but, I don't
> found other similar configuration to let ICAP get the port of client.

I would try

    adaptation_meta X-Client-Port "%>p"

or

    adaptation_meta X-Client-Address "%>a:%>p"

Quotes are essential in this context.

See also: adaptation_uses_indirect_client and follow_x_forwarded_for. I
am not sure how exactly those two directives will interact with the above.

If everything works, please consider adding the corresponding FAQ to
Squid wiki (or a patch updating adaptation_send_client_ip documentation).

If adaptation_meta does not expand one or both of the above %codes in
Squid v4, consider filing a bug report.


HTH,

Alex.



From notjoe at gmail.com  Mon Oct 10 18:01:07 2016
From: notjoe at gmail.com (Joe O)
Date: Mon, 10 Oct 2016 20:01:07 +0200
Subject: [squid-users] Issues with authentication
Message-ID: <A4A98BD4-15E3-4F70-9A4B-4A66A9222E68@gmail.com>



I have an issue with my browser and squid where they both seem to be stuck in an infinite loop of denied requests.
I have a a helper script that authenticates the user. The script works. Here is an example of the output of authentication 
being successful and not successful.

[root at 1 ~]# /etc/squid/authenticate.php
test1 test1
OK
test1 test2
ERR login failure
So, I am sending the right info back to squid. When I authenticate successfully then squid and my browser play nice and there is no power struggle.
If the authentication fails then I get this:

1476120287.143     24 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com <http://www.google.com/>:443 test HIER_NONE/- text/html
1476120287.143     25 45.63.40.55 TCP_DENIED/407 4253 CONNECT www.facebook.com <http://www.facebook.com/>:443 test HIER_NONE/- text/html
1476120287.143     25 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com <http://www.google.com/>:443 test HIER_NONE/- text/html
1476120287.216     18 45.63.40.55 TCP_DENIED/407 4293 CONNECT www.facebook.com <http://www.facebook.com/>:443 test HIER_NONE/- text/html
1476120287.216      9 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com <http://www.google.com/>:443 test HIER_NONE/- text/html
1476120287.216     15 45.63.40.55 TCP_DENIED/407 4253 CONNECT www.facebook.com <http://www.facebook.com/>:443 test HIER_NONE/- text/html
1476120287.216     15 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com <http://www.google.com/>:443 test HIER_NONE/- text/html
1476120287.216     15 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com <http://www.google.com/>:443 test HIER_NONE/- text/html
1476120287.216     15 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com <http://www.google.com/>:443 test HIER_NONE/- text/html
1476120287.216     15 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com <http://www.google.com/>:443 test HIER_NONE/- text/html

Here is my squid config:

#
# Recommended minimum configuration:
#
 
# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
 
acl SSL_ports port 443
acl Safe_ports port 80    # http
acl Safe_ports port 21    # ftp
acl Safe_ports port 443  # https
acl Safe_ports port 70    # gopher
acl Safe_ports port 210  # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280  # http-mgmt
acl Safe_ports port 488  # gss-http
acl Safe_ports port 591  # filemaker
acl Safe_ports port 777  # multiling http
acl CONNECT method CONNECT
 
http_access deny !Safe_ports
 
http_access deny CONNECT !SSL_ports
 
http_access allow localhost manager
http_access deny manager
 
http_access allow localnet
http_access allow localhost
 
auth_param basic program /usr/bin/php /etc/squid/authenticate.php
auth_param basic children 5
auth_param basic realm Web-Proxy
auth_param basic credentialsttl 1 minute
auth_param basic casesensitive off
 
acl db-auth proxy_auth REQUIRED
http_access allow db-auth
http_access allow localhost
http_access deny all
 
http_port 3128
 
coredump_dir /var/spool/squid
 
refresh_pattern ^ftp:      1440       20%    10080
refresh_pattern ^gopher:        1440    0%  1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%   0
refresh_pattern .              0      20%   4320


Everything I?ve read and tried always left me with the same result which was an infinite loop rather than squid returning an unauthorized result page.

Any help would be greatly appreciated.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161010/bbc825ca/attachment.htm>

From eliezer at ngtech.co.il  Mon Oct 10 18:55:09 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 10 Oct 2016 21:55:09 +0300
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
	code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <CAPxJK5BNq_Y5Frbzb10Se1PPceRAfkG2R1-NUeO-2HJk2cWDCg@mail.gmail.com>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
 <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
 <2077594026.2082495.1475235384241@mail.yahoo.com>
 <af92d108-b205-decb-13c4-fecb7a554b5e@gmail.com>
 <421701582.3214410.1475478705099@mail.yahoo.com>
 <f4e0b806-587c-ed2e-4941-b5cccbcda0d1@treenet.co.nz>
 <1410278953.3964483.1475579267802@mail.yahoo.com>
 <2aeb5cbc-67aa-0742-efb1-ab123c638bc6@treenet.co.nz>
 <CAPxJK5BD-CnAOWM3Gb+=a+O7UUOBqCuD5_oHvx8WswrGrMtAGQ@mail.gmail.com>
 <1780209473.10531511.1475734259504@mail.yahoo.com>
 <CAPxJK5Bifwae+-h9Yrpvvpjh=zLGJoD2e-49bsPqA9LguMY=kw@mail.gmail.com>
 <CAPxJK5D8kPHs0Zqfb3tjEHbCpJy71-p7SNvLWRCGBc3nJwKH2w@mail.gmail.com>
 <025301d222da$899a4750$9cced5f0$@ngtech.co.il>
 <CAPxJK5BNq_Y5Frbzb10Se1PPceRAfkG2R1-NUeO-2HJk2cWDCg@mail.gmail.com>
Message-ID: <000001d22327$d2e07db0$78a17910$@ngtech.co.il>

Thanks for the details!
My SPEC for squid 4.0 seems pretty similar to yours but I haven't published for Fedora 24 yet.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Marc [mailto:gaardiolor at gmail.com] 
Sent: Monday, October 10, 2016 4:54 PM
To: Eliezer Croitoru
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)

On Mon, Oct 10, 2016 at 11:41 AM, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> Thanks for updating!
>
> May I ask what version of Linux are you using squid ontop?
> I have released couple RPMs and am working on releasing a drop-in tar.xz for debian based systems.

Yeah sure, I'm using Fedora Core 24.
- Installed squid source RPM
- changed the specfile; changed version, removed patches, removed some
configure flags, added --disable-strict-error-checking otherwise it
didn't want to compile.
- built a new rpm .. works on my system, but ymmv
- patch against the Fedora source rpm spec file:

--- rpmbuild-squid-3.5.21/SPECS/squid.spec      2016-10-09
00:33:42.490934810 +0200
+++ rpmbuild-squid-4.0.14/SPECS/squid.spec      2016-10-09
17:33:26.739659533 +0200
@@ -1,7 +1,7 @@
 %define __perl_requires %{SOURCE98}

 Name:     squid
-Version:  3.5.21
+Version:  4.0.14
 Release:  1%{?dist}
 Summary:  The Squid proxy caching server
 Epoch:    7
@@ -9,8 +9,8 @@
 License:  GPLv2+ and (LGPLv2+ and MIT and BSD and Public Domain)
 Group:    System Environment/Daemons
 URL:      http://www.squid-cache.org
-Source0:  http://www.squid-cache.org/Versions/v3/3.5/squid-%{version}.tar.xz
-Source1:  http://www.squid-cache.org/Versions/v3/3.5/squid-%{version}.tar.xz.asc
+Source0:  http://www.squid-cache.org/Versions/v4/squid-%{version}.tar.xz
+Source1:  http://www.squid-cache.org/Versions/v4/squid-%{version}.tar.xz.asc
 Source2:  squid.logrotate
 Source3:  squid.sysconfig
 Source4:  squid.pam
@@ -27,11 +27,6 @@
 # Local patches
 # Applying upstream patches first makes it less likely that local patches
 # will break upstream ones.
-Patch201: squid-3.1.0.9-config.patch
-Patch202: squid-3.1.0.9-location.patch
-Patch203: squid-3.0.STABLE1-perlpath.patch
-Patch204: squid-3.5.9-include-guards.patch
-Patch205: 0001-cppunit-config-no-longer-exists-use-pkg-config.patch

 Buildroot: %{_tmppath}/%{name}-%{version}-%{release}-root-%(%{__id_u} -n)
 Requires: bash >= 2.0
@@ -87,11 +82,6 @@
 # Backported patches

 # Local patches
-%patch201 -p1 -b .config
-%patch202 -p1 -b .location
-%patch203 -p1 -b .perlpath
-%patch204 -p0 -b .include-guards
-%patch205 -p1 -b .cppunit-config

 %build
 # cppunit-config patch changes configure.ac
@@ -114,8 +104,8 @@
    --enable-eui \
    --enable-follow-x-forwarded-for \
    --enable-auth \
-   --enable-auth-basic="DB,LDAP,MSNT-multi-domain,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,getpwnam"
\
-   --enable-auth-ntlm="smb_lm,fake" \
+   --enable-auth-basic="DB,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,getpwnam" \
+   --enable-auth-ntlm="fake" \
    --enable-auth-digest="file,LDAP" \
    --enable-auth-negotiate="kerberos" \
    --enable-external-acl-helpers="LDAP_group,time_quota,session,unix_group,wbinfo_group"
\
@@ -145,7 +135,8 @@
    --with-openssl \
    --with-pthreads \
    --disable-arch-native \
-   --with-pic
+   --with-pic \
+   --disable-strict-error-checking

 make \
        DEFAULT_SWAP_DIR=%{_localstatedir}/spool/squid \
@@ -191,7 +182,7 @@
 install -m 644 %{SOURCE5}
$RPM_BUILD_ROOT%{_sysconfdir}/NetworkManager/dispatcher.d/20-squid
 mkdir -p $RPM_BUILD_ROOT%{_localstatedir}/log/squid
 mkdir -p $RPM_BUILD_ROOT%{_localstatedir}/spool/squid
-chmod 644 contrib/url-normalizer.pl contrib/rredir.* contrib/user-agents.pl
+chmod 644 contrib/url-normalizer.pl contrib/user-agents.pl
 iconv -f ISO88591 -t UTF8 ChangeLog -o ChangeLog.tmp
 mv -f ChangeLog.tmp ChangeLog

@@ -213,7 +204,7 @@
 %defattr(-,root,root,-)
 %license COPYING
 %doc CONTRIBUTORS README ChangeLog QUICKSTART src/squid.conf.documented
-%doc contrib/url-normalizer.pl contrib/rredir.* contrib/user-agents.pl
+%doc contrib/url-normalizer.pl contrib/user-agents.pl

 %{_unitdir}/squid.service
 %attr(755,root,root) %dir %{_libexecdir}/squid
@@ -286,6 +277,9 @@



From squid3 at treenet.co.nz  Tue Oct 11 01:02:00 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 11 Oct 2016 14:02:00 +1300
Subject: [squid-users] Issues with authentication
In-Reply-To: <A4A98BD4-15E3-4F70-9A4B-4A66A9222E68@gmail.com>
References: <A4A98BD4-15E3-4F70-9A4B-4A66A9222E68@gmail.com>
Message-ID: <c03b39b0-76bf-afd6-659b-f3b4f9a6e4de@treenet.co.nz>

On 11/10/2016 7:01 a.m., Joe O wrote:
> 
> 
> I have an issue with my browser and squid where they both seem to be stuck in an infinite loop of denied requests.
> I have a a helper script that authenticates the user. The script works. Here is an example of the output of authentication 
> being successful and not successful.
> 
> [root at 1 ~]# /etc/squid/authenticate.php
> test1 test1
> OK
> test1 test2
> ERR login failure
> So, I am sending the right info back to squid. When I authenticate successfully then squid and my browser play nice and there is no power struggle.
> If the authentication fails then I get this:
> 
> 1476120287.143     24 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com:443 test HIER_NONE/- text/html
> 1476120287.143     25 45.63.40.55 TCP_DENIED/407 4253 CONNECT www.facebook.com:443 test HIER_NONE/- text/html
> 1476120287.143     25 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com:443 test HIER_NONE/- text/html
> 1476120287.216     18 45.63.40.55 TCP_DENIED/407 4293 CONNECT www.facebook.com:443 test HIER_NONE/- text/html
> 1476120287.216      9 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com:443 test HIER_NONE/- text/html
> 1476120287.216     15 45.63.40.55 TCP_DENIED/407 4253 CONNECT www.facebook.com:443 test HIER_NONE/- text/html
> 1476120287.216     15 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com:443 test HIER_NONE/- text/html
> 1476120287.216     15 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com:443 test HIER_NONE/- text/html
> 1476120287.216     15 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com:443 test HIER_NONE/- text/html
> 1476120287.216     15 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com:443 test HIER_NONE/- text/html
> 
> Here is my squid config:

<snip defaults>

>  
> http_access allow localnet
> http_access allow localhost
>  

Okay if you want LAN traffic and things going from the Squid machine not
to be authenticated. Otherwise these two lines should go below the auth
checks.


> auth_param basic program /usr/bin/php /etc/squid/authenticate.php
> auth_param basic children 5
> auth_param basic realm Web-Proxy
> auth_param basic credentialsttl 1 minute
> auth_param basic casesensitive off
>  
> acl db-auth proxy_auth REQUIRED
> http_access allow db-auth
> http_access allow localhost

localhost is already permitted on a line above the auth stuff. This one
will just waste CPU cycles checking an impossible requirement.

> http_access deny all
>  

<snip defaults>

> 
> 
> Everything I?ve read and tried always left me with the same result
> which was an infinite loop rather than squid returning an
> unauthorized result page.


Firstly; The 407 you see in access.log *is* the unauthorized being
returned by the proxy. That is accompanied by a error "page" from Squid.

Note that all these are parallel transactions (same ending timestamp,
different durations). Browsers open quite a few connections to proxies.
If it was trying the same bad credentials for all these you can expect
them to fail of course.


Secondly; Browsers refuse to display anything a proxy returns in
response to CONNECT method. That is a browser internal problem we cannot
do anything about. What you should see next is not a page, but a popup
from the browser trying to get working credentials since these ones failed.


Thirdly; If the popup is not appearing you may need to explicitly tell
Squid what to do when credentials are present but invalid.

You do that with a "deny" rule like this:

 http_access deny !db-auth
 http_access allow db-auth

Amos



From yanghe0921 at 126.com  Tue Oct 11 01:13:36 2016
From: yanghe0921 at 126.com (ysu yang)
Date: Mon, 10 Oct 2016 18:13:36 -0700 (PDT)
Subject: [squid-users] How to configure squid to let ICAP get the port
	of client
In-Reply-To: <25f5604a-697e-9fd2-f3c6-7562157b8b1c@measurement-factory.com>
References: <1476099714505-4680036.post@n4.nabble.com>
 <25f5604a-697e-9fd2-f3c6-7562157b8b1c@measurement-factory.com>
Message-ID: <1476148416810-4680045.post@n4.nabble.com>

Thanks very much.
It works well in Squid V3.5,but has error in Squid V3.3.
It displayed "X-Client-Port :41328\r\n" in Squid V3.5,but displayed
"X-Client-Port :%>p\r\n" in Squid V3.3.
And ,how to get other '%code',like "%>a"or "%>p"

Thanks in advance




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/How-to-configure-squid-to-let-ICAP-get-the-port-of-client-tp4680036p4680045.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Tue Oct 11 02:42:16 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 11 Oct 2016 15:42:16 +1300
Subject: [squid-users] How to configure squid to let ICAP get the port
 of client
In-Reply-To: <1476148416810-4680045.post@n4.nabble.com>
References: <1476099714505-4680036.post@n4.nabble.com>
 <25f5604a-697e-9fd2-f3c6-7562157b8b1c@measurement-factory.com>
 <1476148416810-4680045.post@n4.nabble.com>
Message-ID: <deeefbae-7c2c-f09b-255b-07a1bdb09e80@treenet.co.nz>

On 11/10/2016 2:13 p.m., ysu yang wrote:
> Thanks very much.
> It works well in Squid V3.5,but has error in Squid V3.3.
> It displayed "X-Client-Port :41328\r\n" in Squid V3.5,but displayed
> "X-Client-Port :%>p\r\n" in Squid V3.3.
> And ,how to get other '%code',like "%>a"or "%>p"
> 

Squid-3.3 does not contain the features necessary. Please upgrade.

Amos



From makleking at yandex.ru  Tue Oct 11 03:54:59 2016
From: makleking at yandex.ru (=?utf-8?B?0JzQuNGF0LDQuNC7?=)
Date: Tue, 11 Oct 2016 11:54:59 +0800
Subject: [squid-users] ERROR: Cannot connect to 127.0.0.1:3128
Message-ID: <294681476158099@web11o.yandex.ru>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161011/bfbefb34/attachment.htm>

From makleking at yandex.ru  Tue Oct 11 03:59:36 2016
From: makleking at yandex.ru (=?utf-8?B?0JzQuNGF0LDQuNC7?=)
Date: Tue, 11 Oct 2016 11:59:36 +0800
Subject: [squid-users] ERROR: Cannot connect to 127.0.0.1:3128
In-Reply-To: <294681476158099@web11o.yandex.ru>
References: <294681476158099@web11o.yandex.ru>
Message-ID: <302891476158376@web11o.yandex.ru>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161011/1f3d4e92/attachment.htm>

From notjoe at gmail.com  Tue Oct 11 05:18:10 2016
From: notjoe at gmail.com (Joe O)
Date: Tue, 11 Oct 2016 07:18:10 +0200
Subject: [squid-users] Issues with authentication
In-Reply-To: <c03b39b0-76bf-afd6-659b-f3b4f9a6e4de@treenet.co.nz>
References: <A4A98BD4-15E3-4F70-9A4B-4A66A9222E68@gmail.com>
 <c03b39b0-76bf-afd6-659b-f3b4f9a6e4de@treenet.co.nz>
Message-ID: <D7EA2536-CB9E-4644-88E8-D3E03A96DCEB@gmail.com>

Thanks for the reply Amos! I started following another thread in which you were helping some one else with showing pages to / redirecting unauthenticated users
but still haven?t been able to get that to work either. The thread was this one http://squid-web-proxy-cache.1019090.n4.nabble.com/redirecting-unauthenticated-users-td1038146.html <http://squid-web-proxy-cache.1019090.n4.nabble.com/redirecting-unauthenticated-users-td1038146.html>
I think this approach would work well for what I am doing if I could get it working :)


error_directory /usr/share/squid/errors/en
cache deny all
debug_options ALL,1 11,3 20,3
acl whitelist dstdomain .whitelist.com 127.0.0.1

acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1

acl localnet src 127.0.0.1      # RFC1918 possible internal network
acl localnet src 10.0.0.0/8
acl localhost src 127.0.0.1/32 ::1

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

http_access allow manager localhost
http_access deny manager

http_access deny !Safe_ports

http_access deny CONNECT !SSL_ports

http_access allow localnet
http_access allow localhost

http_port 3128

coredump_dir /var/spool/squid

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320

auth_param basic program /usr/bin/php /etc/squid/authenticate.php
auth_param basic children 5
auth_param basic realm Web-Proxy
auth_param basic credentialsttl 1 minute
auth_param basic casesensitive off

acl noAuth src all
acl AuthUsers proxy_auth REQUIRED

http_access allow whitelist
http_access allow AuthUsers
deny_info ERR_ACCESS_DENIED noAuth
http_access deny !AuthUsers noAuth
http_access deny all

> On Oct 11, 2016, at 3:02 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 11/10/2016 7:01 a.m., Joe O wrote:
>> 
>> 
>> I have an issue with my browser and squid where they both seem to be stuck in an infinite loop of denied requests.
>> I have a a helper script that authenticates the user. The script works. Here is an example of the output of authentication 
>> being successful and not successful.
>> 
>> [root at 1 ~]# /etc/squid/authenticate.php
>> test1 test1
>> OK
>> test1 test2
>> ERR login failure
>> So, I am sending the right info back to squid. When I authenticate successfully then squid and my browser play nice and there is no power struggle.
>> If the authentication fails then I get this:
>> 
>> 1476120287.143     24 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com:443 test HIER_NONE/- text/html
>> 1476120287.143     25 45.63.40.55 TCP_DENIED/407 4253 CONNECT www.facebook.com:443 test HIER_NONE/- text/html
>> 1476120287.143     25 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com:443 test HIER_NONE/- text/html
>> 1476120287.216     18 45.63.40.55 TCP_DENIED/407 4293 CONNECT www.facebook.com:443 test HIER_NONE/- text/html
>> 1476120287.216      9 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com:443 test HIER_NONE/- text/html
>> 1476120287.216     15 45.63.40.55 TCP_DENIED/407 4253 CONNECT www.facebook.com:443 test HIER_NONE/- text/html
>> 1476120287.216     15 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com:443 test HIER_NONE/- text/html
>> 1476120287.216     15 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com:443 test HIER_NONE/- text/html
>> 1476120287.216     15 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com:443 test HIER_NONE/- text/html
>> 1476120287.216     15 45.63.40.55 TCP_DENIED/407 4245 CONNECT www.google.com:443 test HIER_NONE/- text/html
>> 
>> Here is my squid config:
> 
> <snip defaults>
> 
>> 
>> http_access allow localnet
>> http_access allow localhost
>> 
> 
> Okay if you want LAN traffic and things going from the Squid machine not
> to be authenticated. Otherwise these two lines should go below the auth
> checks.
> 
> 
>> auth_param basic program /usr/bin/php /etc/squid/authenticate.php
>> auth_param basic children 5
>> auth_param basic realm Web-Proxy
>> auth_param basic credentialsttl 1 minute
>> auth_param basic casesensitive off
>> 
>> acl db-auth proxy_auth REQUIRED
>> http_access allow db-auth
>> http_access allow localhost
> 
> localhost is already permitted on a line above the auth stuff. This one
> will just waste CPU cycles checking an impossible requirement.
> 
>> http_access deny all
>> 
> 
> <snip defaults>
> 
>> 
>> 
>> Everything I?ve read and tried always left me with the same result
>> which was an infinite loop rather than squid returning an
>> unauthorized result page.
> 
> 
> Firstly; The 407 you see in access.log *is* the unauthorized being
> returned by the proxy. That is accompanied by a error "page" from Squid.
> 
> Note that all these are parallel transactions (same ending timestamp,
> different durations). Browsers open quite a few connections to proxies.
> If it was trying the same bad credentials for all these you can expect
> them to fail of course.
> 
> 
> Secondly; Browsers refuse to display anything a proxy returns in
> response to CONNECT method. That is a browser internal problem we cannot
> do anything about. What you should see next is not a page, but a popup
> from the browser trying to get working credentials since these ones failed.
> 
> 
> Thirdly; If the popup is not appearing you may need to explicitly tell
> Squid what to do when credentials are present but invalid.
> 
> You do that with a "deny" rule like this:
> 
> http_access deny !db-auth
> http_access allow db-auth
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
> http://lists.squid-cache.org/listinfo/squid-users <http://lists.squid-cache.org/listinfo/squid-users>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161011/92f5c605/attachment.htm>

From squid3 at treenet.co.nz  Tue Oct 11 06:46:30 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 11 Oct 2016 19:46:30 +1300
Subject: [squid-users] Issues with authentication
In-Reply-To: <D7EA2536-CB9E-4644-88E8-D3E03A96DCEB@gmail.com>
References: <A4A98BD4-15E3-4F70-9A4B-4A66A9222E68@gmail.com>
 <c03b39b0-76bf-afd6-659b-f3b4f9a6e4de@treenet.co.nz>
 <D7EA2536-CB9E-4644-88E8-D3E03A96DCEB@gmail.com>
Message-ID: <41a8d3ec-5010-e524-d124-aff896c71839@treenet.co.nz>

On 11/10/2016 6:18 p.m., Joe O wrote:
> Thanks for the reply Amos! I started following another thread in which you were helping some one else with showing pages to / redirecting unauthenticated users
> but still haven?t been able to get that to work either. The thread was this one http://squid-web-proxy-cache.1019090.n4.nabble.com/redirecting-unauthenticated-users-td1038146.html <http://squid-web-proxy-cache.1019090.n4.nabble.com/redirecting-unauthenticated-users-td1038146.html>
> I think this approach would work well for what I am doing if I could get it working :)

That thread is about having one specific URL being visited cause proxy
authentication to happen. With any unauthenticated visitors redirected
to that URL.

You are dealing with CONNECT requests. Which do not have URL, just
authority-URI and cannot be redirected.

> 
> error_directory /usr/share/squid/errors/en
> cache deny all
> debug_options ALL,1 11,3 20,3
> acl whitelist dstdomain .whitelist.com 127.0.0.1
> 
> acl localhost src 127.0.0.1/32 ::1
> acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1

These ACLs should be defined by default and Squid complain about these
adding duplicate entries on startup or reconfigure. If it does not you
should upgrade to a more recent Squid.


> 
> acl localnet src 127.0.0.1      # RFC1918 possible internal network


127.0.0.1 is not a possible internal network. It is localhost.

> acl localnet src 10.0.0.0/8
> acl localhost src 127.0.0.1/32 ::1

You already defined locahost. Your Squid should be complaining about
this  on startup or reconfigure. If it does not you should upgrade to a
more recent Squid.

> 
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> 
> http_access allow manager localhost
> http_access deny manager
> 

The manager rules are more efficient security when performed after the
"CONNECT !SSL_ports" rule.


> http_access deny !Safe_ports
> 
> http_access deny CONNECT !SSL_ports
> 
> http_access allow localnet
> http_access allow localhost
> 

Amos



From squid3 at treenet.co.nz  Tue Oct 11 06:59:07 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 11 Oct 2016 19:59:07 +1300
Subject: [squid-users] ERROR: Cannot connect to 127.0.0.1:3128
In-Reply-To: <294681476158099@web11o.yandex.ru>
References: <294681476158099@web11o.yandex.ru>
Message-ID: <e663dbd7-b739-ecb9-3598-c649c2b97fcf@treenet.co.nz>

On 11/10/2016 4:54 p.m., ?????? wrote:
> I check version of squid 3.5.21 with my configuration and I faced with a 
> problem. Early I used in version 3.5.12 this line for connect localhost, but now 
> it doesn't work.

Order is important. Where you place the rules in squid.conf matters a
lot with regards to whether they are actually useful and do what you
want, or not.

> # squid.conf
> ...
> http_access allow localhost manager
> http_access deny manager
> ...
> # squidclient -p 3128 -h localhost mgr:info
> HTTP/1.1 403 Forbidden
> Server: squid
> Mime-Version: 1.0
> Date: Tue, 11 Oct 2016 03:42:54 GMT
> ...

> If I set a full access I could connect to localhost.


> # squid.conf
> ...
> http_access allow all
> http_access deny manager
> ...


So what IP address(es) does 'localhost' resolve to?

> # squidclient -p 3128 -h localhost mgr:info
> stub time| WARNING: BCP 177 violation. IPv6 transport forced OFF by build 
> parameters.

I know you said in a followup to ignore this. But it may be important.

It shows that squidclient was built with --disable-ipv6, and yet your
system is IPv6-enabled.

The name "localhost" for IPv6-enabled systems is ::1.

A squid binary that is built with --disable-ipv6 will not permit ::1
since it is non-IP4. But it will be recognized as part of "all" IP space.


> HTTP/1.1 200 OK
> Server: squid
> Mime-Version: 1.0
> Date: Tue, 11 Oct 2016 03:47:36 GMT
> ...
> What is happend? And what is the right way to connect to cache_management from 
> localhost?

squidclient defaults to localhost and port 3128 for management access to
Squid. Just use:

  squidclient mgr:info

Amos



From jorgeley at gmail.com  Tue Oct 11 10:31:03 2016
From: jorgeley at gmail.com (Jorgeley Junior)
Date: Tue, 11 Oct 2016 07:31:03 -0300
Subject: [squid-users] ERROR: Cannot connect to 127.0.0.1:3128
In-Reply-To: <e663dbd7-b739-ecb9-3598-c649c2b97fcf@treenet.co.nz>
References: <294681476158099@web11o.yandex.ru>
 <e663dbd7-b739-ecb9-3598-c649c2b97fcf@treenet.co.nz>
Message-ID: <CAMeoTHmCC3W6zJPsxCGvMpogh-edvc4MVVVbO=DURa+ABs-MXQ@mail.gmail.com>

I think it could be the sequence of the rules, do this command and post the
results:
grep         .       /etc/squid-your-version/squid.conf      |
grep     -v       "#"

2016-10-11 3:59 GMT-03:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 11/10/2016 4:54 p.m., ?????? wrote:
> > I check version of squid 3.5.21 with my configuration and I faced with a
> > problem. Early I used in version 3.5.12 this line for connect localhost,
> but now
> > it doesn't work.
>
> Order is important. Where you place the rules in squid.conf matters a
> lot with regards to whether they are actually useful and do what you
> want, or not.
>
> > # squid.conf
> > ...
> > http_access allow localhost manager
> > http_access deny manager
> > ...
> > # squidclient -p 3128 -h localhost mgr:info
> > HTTP/1.1 403 Forbidden
> > Server: squid
> > Mime-Version: 1.0
> > Date: Tue, 11 Oct 2016 03:42:54 GMT
> > ...
>
> > If I set a full access I could connect to localhost.
>
>
> > # squid.conf
> > ...
> > http_access allow all
> > http_access deny manager
> > ...
>
>
> So what IP address(es) does 'localhost' resolve to?
>
> > # squidclient -p 3128 -h localhost mgr:info
> > stub time| WARNING: BCP 177 violation. IPv6 transport forced OFF by build
> > parameters.
>
> I know you said in a followup to ignore this. But it may be important.
>
> It shows that squidclient was built with --disable-ipv6, and yet your
> system is IPv6-enabled.
>
> The name "localhost" for IPv6-enabled systems is ::1.
>
> A squid binary that is built with --disable-ipv6 will not permit ::1
> since it is non-IP4. But it will be recognized as part of "all" IP space.
>
>
> > HTTP/1.1 200 OK
> > Server: squid
> > Mime-Version: 1.0
> > Date: Tue, 11 Oct 2016 03:47:36 GMT
> > ...
> > What is happend? And what is the right way to connect to
> cache_management from
> > localhost?
>
> squidclient defaults to localhost and port 3128 for management access to
> Squid. Just use:
>
>   squidclient mgr:info
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



--
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161011/b412b42f/attachment.htm>

From Antony.Stone at squid.open.source.it  Tue Oct 11 10:56:23 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 11 Oct 2016 12:56:23 +0200
Subject: [squid-users] ERROR: Cannot connect to 127.0.0.1:3128
In-Reply-To: <CAMeoTHmCC3W6zJPsxCGvMpogh-edvc4MVVVbO=DURa+ABs-MXQ@mail.gmail.com>
References: <294681476158099@web11o.yandex.ru>
 <e663dbd7-b739-ecb9-3598-c649c2b97fcf@treenet.co.nz>
 <CAMeoTHmCC3W6zJPsxCGvMpogh-edvc4MVVVbO=DURa+ABs-MXQ@mail.gmail.com>
Message-ID: <201610111256.24133.Antony.Stone@squid.open.source.it>

On Tuesday 11 October 2016 at 12:31:03, Jorgeley Junior wrote:

> I think it could be the sequence of the rules, do this command and post the
> results:
> grep         .       /etc/squid-your-version/squid.conf      |
> grep     -v       "#"

This can be collapsed down to:

grep "^[^#]" /etc/squid-your-version/squid.conf

That regex matches any character other than # at the start of a line.  Empty 
lines don't count, because there is no character at the start of the line.


Antony.

> 2016-10-11 3:59 GMT-03:00 Amos Jeffries <squid3 at treenet.co.nz>:
> > On 11/10/2016 4:54 p.m., ?????? wrote:
> > > I check version of squid 3.5.21 with my configuration and I faced with
> > > a problem. Early I used in version 3.5.12 this line for connect
> > > localhost,
> > 
> > but now
> > 
> > > it doesn't work.
> > 
> > Order is important. Where you place the rules in squid.conf matters a
> > lot with regards to whether they are actually useful and do what you
> > want, or not.
> > 
> > > # squid.conf
> > > ...
> > > http_access allow localhost manager
> > > http_access deny manager
> > > ...
> > > # squidclient -p 3128 -h localhost mgr:info
> > > HTTP/1.1 403 Forbidden
> > > Server: squid
> > > Mime-Version: 1.0
> > > Date: Tue, 11 Oct 2016 03:42:54 GMT
> > > ...
> > > 
> > > If I set a full access I could connect to localhost.
> > > 
> > > 
> > > # squid.conf
> > > ...
> > > http_access allow all
> > > http_access deny manager
> > > ...
> > 
> > So what IP address(es) does 'localhost' resolve to?
> > 
> > > # squidclient -p 3128 -h localhost mgr:info
> > > stub time| WARNING: BCP 177 violation. IPv6 transport forced OFF by
> > > build parameters.
> > 
> > I know you said in a followup to ignore this. But it may be important.
> > 
> > It shows that squidclient was built with --disable-ipv6, and yet your
> > system is IPv6-enabled.
> > 
> > The name "localhost" for IPv6-enabled systems is ::1.
> > 
> > A squid binary that is built with --disable-ipv6 will not permit ::1
> > since it is non-IP4. But it will be recognized as part of "all" IP space.
> > 
> > > HTTP/1.1 200 OK
> > > Server: squid
> > > Mime-Version: 1.0
> > > Date: Tue, 11 Oct 2016 03:47:36 GMT
> > > ...
> > > What is happend? And what is the right way to connect to
> > 
> > cache_management from
> > 
> > > localhost?
> > 
> > squidclient defaults to localhost and port 3128 for management access to
> > 
> > Squid. Just use:
> >   squidclient mgr:info
> > 
> > Amos
> > 
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> 
> --

-- 
There's no such thing as bad weather - only the wrong clothes.

 - Billy Connolly

                                                   Please reply to the list;
                                                         please *don't* CC me.


From jlay at slave-tothe-box.net  Tue Oct 11 12:54:41 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Tue, 11 Oct 2016 06:54:41 -0600
Subject: [squid-users] Squid 2.5.20 fails to compile with ecap
Message-ID: <1476190481.11475.1.camel@slave-tothe-box.net>

Pretty much topic..sorry for the wall of text here. ?Config'd with:

EXT_LIBECAP_CFLAGS="-I/opt/ecap/include" EXT_LIBECAP_LIBS="-
L/opt/ecap/lib" ./configure --prefix=/opt --with-openssl=/opt/libressl
--enable-ssl --enable-ssl-crtd --enable-linux-netfilter --enable-
follow-x-forwarded-for --with-large-files --sysconfdir=/opt/etc/squid
--enable-xternal-acl-helpers=none --enable-ecap

Thank you.

James

/bin/bash ../libtool??--tag=CXX???--mode=link g++ -Wall -Wpointer-arith 
-Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -Werror -pipe
-D_REENTRANT -m64???-g -O2 -march=native -std=c++11 -export-dynamic
-dlopen force -m64 -g -o squid AclRegs.o AuthReg.o AccessLogEntry.o
AsyncEngine.o YesNoNone.o cache_cf.o CacheDigest.o cache_manager.o
carp.o cbdata.o ChunkedCodingParser.o client_db.o client_side.o
client_side_reply.o client_side_request.o BodyPipe.o clientStream.o
CollapsedForwarding.o CompletionDispatcher.o ConfigOption.o
ConfigParser.o CpuAffinity.o CpuAffinityMap.o CpuAffinitySet.o
debug.o??disk.o DiskIO/DiskIOModule.o DiskIO/ReadRequest.o
DiskIO/WriteRequest.o dlink.o dns_internal.o DnsLookupDetails.o
errorpage.o ETag.o event.o EventLoop.o external_acl.o
ExternalACLEntry.o FadingCounter.o fatal.o fd.o fde.o filemap.o
fqdncache.o FwdState.o gopher.o helper.o htcp.o http.o HttpHdrCc.o
HttpHdrRange.o HttpHdrSc.o HttpHdrScTarget.o HttpHdrContRange.o
HttpHeader.o HttpHeaderTools.o HttpBody.o HttpMsg.o HttpParser.o
HttpReply.o RequestFlags.o HttpRequest.o HttpRequestMethod.o icp_v2.o
icp_v3.o int.o internal.o ipc.o ipcache.o??SquidList.o main.o
MasterXaction.o mem.o mem_node.o MemBuf.o MemObject.o mime.o
mime_header.o multicast.o neighbors.o Notes.o Packer.o
Parsing.o??pconn.o peer_digest.o peer_proxy_negotiate_auth.o
peer_select.o peer_sourcehash.o peer_userhash.o PeerPoolMgr.o
redirect.o refresh.o RemovalPolicy.o send-announce.o MemBlob.o SBuf.o
SBufExceptions.o SBufDetailedStats.o SBufStatsAction.o snmp_core.o
snmp_agent.o SquidMath.o SquidNew.o stat.o StatCounters.o StatHist.o
String.o StrList.o stmem.o store.o StoreFileSystem.o store_io.o
StoreIOState.o store_client.o store_digest.o store_dir.o
store_key_md5.o store_log.o store_rebuild.o store_swapin.o
store_swapmeta.o store_swapout.o StoreMetaUnpacker.o StoreMeta.o
StoreMetaMD5.o StoreMetaSTD.o StoreMetaSTDLFS.o StoreMetaURL.o
StoreMetaVary.o StoreStats.o StoreSwapLogData.o SwapDir.o Transients.o
MemStore.o time.o tools.o tunnel.o unlinkd.o url.o urn.o wccp.o wccp2.o
whois.o wordlist.o???LoadableModule.o LoadableModules.o
DiskIO/DiskIOModules_gen.o err_type.o err_detail_type.o globals.o
hier_code.o icp_opcode.o LogTags.o lookup_t.o repl_modules.o
swap_log_op.o auth/libacls.la ident/libident.la acl/libacls.la
acl/libstate.la auth/libauth.la libAIO.a libBlocking.a libDiskDaemon.a
libDiskThreads.a libIpcIo.a libMmapped.a acl/libapi.la base/libbase.la
libsquid.la ip/libip.la fs/libfs.la ssl/libsslsquid.la
ssl/libsslutil.la ipc/libipc.la mgr/libmgr.la anyp/libanyp.la
comm/libcomm.la eui/libeui.la helper/libhelper.la http/libsquid-http.la 
icmp/libicmp.la icmp/libicmp-core.la log/liblog.la format/libformat.la
clients/libclients.la servers/libservers.la ftp/libftp.la??DiskIO/AIO/A
IODiskIOModule.o DiskIO/Blocking/BlockingDiskIOModule.o
DiskIO/DiskDaemon/DiskDaemonDiskIOModule.o
DiskIO/DiskThreads/DiskThreadsDiskIOModule.o
DiskIO/IpcIo/IpcIoDiskIOModule.o DiskIO/Mmapped/MmappedDiskIOModule.o
repl/liblru.a -lrt -lpthread??-
lcrypt??adaptation/libadaptation.la??snmp/libsnmp.la
../lib/snmplib/libsnmplib.la parser/libsquid-parser.la
../lib/libmisccontainers.la ../lib/libmiscencoding.la
../lib/libmiscutil.la -L/opt/libressl/lib -lssl -lcrypto??????-
lgssapi_krb5 -lkrb5 -lk5crypto -lcom_err????../compat/libcompat-
squid.la??-lm -lnsl -lresolv -lcap -lrt -L.. -lltdl?
libtool: link: rm -f .libs/squid.nm .libs/squid.nmS .libs/squid.nmT
libtool: link: rm -f ".libs/squid.nmI"
libtool: link: (cd .libs && gcc -m64 -Wall -g -O2 -c -fno-builtin
"squidS.c")
libtool: link: rm -f ".libs/squidS.c" ".libs/squid.nm"
".libs/squid.nmS" ".libs/squid.nmT" ".libs/squid.nmI"
libtool: link: g++ -Wall -Wpointer-arith -Wwrite-strings -Wcomments
-Wshadow -Woverloaded-virtual -Werror -pipe -D_REENTRANT -m64 -g -O2
-march=native -std=c++11 .libs/squidS.o -m64 -g -o squid AclRegs.o
AuthReg.o AccessLogEntry.o AsyncEngine.o YesNoNone.o cache_cf.o
CacheDigest.o cache_manager.o carp.o cbdata.o ChunkedCodingParser.o
client_db.o client_side.o client_side_reply.o client_side_request.o
BodyPipe.o clientStream.o CollapsedForwarding.o CompletionDispatcher.o
ConfigOption.o ConfigParser.o CpuAffinity.o CpuAffinityMap.o
CpuAffinitySet.o debug.o disk.o DiskIO/DiskIOModule.o
DiskIO/ReadRequest.o DiskIO/WriteRequest.o dlink.o dns_internal.o
DnsLookupDetails.o errorpage.o ETag.o event.o EventLoop.o
external_acl.o ExternalACLEntry.o FadingCounter.o fatal.o fd.o fde.o
filemap.o fqdncache.o FwdState.o gopher.o helper.o htcp.o http.o
HttpHdrCc.o HttpHdrRange.o HttpHdrSc.o HttpHdrScTarget.o
HttpHdrContRange.o HttpHeader.o HttpHeaderTools.o HttpBody.o HttpMsg.o
HttpParser.o HttpReply.o RequestFlags.o HttpRequest.o
HttpRequestMethod.o icp_v2.o icp_v3.o int.o internal.o ipc.o ipcache.o
SquidList.o main.o MasterXaction.o mem.o mem_node.o MemBuf.o
MemObject.o mime.o mime_header.o multicast.o neighbors.o Notes.o
Packer.o Parsing.o pconn.o peer_digest.o peer_proxy_negotiate_auth.o
peer_select.o peer_sourcehash.o peer_userhash.o PeerPoolMgr.o
redirect.o refresh.o RemovalPolicy.o send-announce.o MemBlob.o SBuf.o
SBufExceptions.o SBufDetailedStats.o SBufStatsAction.o snmp_core.o
snmp_agent.o SquidMath.o SquidNew.o stat.o StatCounters.o StatHist.o
String.o StrList.o stmem.o store.o StoreFileSystem.o store_io.o
StoreIOState.o store_client.o store_digest.o store_dir.o
store_key_md5.o store_log.o store_rebuild.o store_swapin.o
store_swapmeta.o store_swapout.o StoreMetaUnpacker.o StoreMeta.o
StoreMetaMD5.o StoreMetaSTD.o StoreMetaSTDLFS.o StoreMetaURL.o
StoreMetaVary.o StoreStats.o StoreSwapLogData.o SwapDir.o Transients.o
MemStore.o time.o tools.o tunnel.o unlinkd.o url.o urn.o wccp.o wccp2.o
whois.o wordlist.o LoadableModule.o LoadableModules.o
DiskIO/DiskIOModules_gen.o err_type.o err_detail_type.o globals.o
hier_code.o icp_opcode.o LogTags.o lookup_t.o repl_modules.o
swap_log_op.o DiskIO/AIO/AIODiskIOModule.o
DiskIO/Blocking/BlockingDiskIOModule.o
DiskIO/DiskDaemon/DiskDaemonDiskIOModule.o
DiskIO/DiskThreads/DiskThreadsDiskIOModule.o
DiskIO/IpcIo/IpcIoDiskIOModule.o DiskIO/Mmapped/MmappedDiskIOModule.o
-Wl,--export-dynamic??auth/.libs/libacls.a ident/.libs/libident.a
acl/.libs/libacls.a acl/.libs/libstate.a auth/.libs/libauth.a libAIO.a
libBlocking.a libDiskDaemon.a libDiskThreads.a libIpcIo.a libMmapped.a
acl/.libs/libapi.a base/.libs/libbase.a ./.libs/libsquid.a
ip/.libs/libip.a fs/.libs/libfs.a ssl/.libs/libsslsquid.a
ssl/.libs/libsslutil.a ipc/.libs/libipc.a mgr/.libs/libmgr.a
anyp/.libs/libanyp.a comm/.libs/libcomm.a eui/.libs/libeui.a
helper/.libs/libhelper.a http/.libs/libsquid-http.a
icmp/.libs/libicmp.a icmp/.libs/libicmp-core.a log/.libs/liblog.a
format/.libs/libformat.a clients/.libs/libclients.a
servers/.libs/libservers.a ftp/.libs/libftp.a repl/liblru.a -lpthread
-lcrypt adaptation/.libs/libadaptation.a -L/opt/ecap/lib
snmp/.libs/libsnmp.a ../lib/snmplib/.libs/libsnmplib.a
parser/.libs/libsquid-parser.a ../lib/.libs/libmisccontainers.a
../lib/.libs/libmiscencoding.a ../lib/.libs/libmiscutil.a
-L/opt/libressl/lib /opt/libressl/lib/libssl.so
/opt/libressl/lib/libcrypto.so -lgssapi_krb5 -lkrb5 -lk5crypto
-lcom_err ../compat/.libs/libcompat-squid.a -lm -lnsl -lresolv -lcap
-lrt -L.. /usr/lib/x86_64-linux-gnu/libltdl.so -Wl,-rpath
-Wl,/opt/libressl/lib -Wl,-rpath -Wl,/opt/libressl/lib
adaptation/.libs/libadaptation.a(libsquid_ecap_la-Host.o): In function
`Adaptation::Ecap::Host::Host()':
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:41:
undefined reference to `libecap::headerTransferEncoding'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:41:
undefined reference to `libecap::Name::assignHostId(int) const'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:42:
undefined reference to `libecap::headerReferer'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:42:
undefined reference to `libecap::Name::assignHostId(int) const'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:43:
undefined reference to `libecap::headerContentLength'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:43:
undefined reference to `libecap::Name::assignHostId(int) const'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:44:
undefined reference to `libecap::headerVia'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:44:
undefined reference to `libecap::Name::assignHostId(int) const'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:48:
undefined reference to `libecap::protocolHttp'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:48:
undefined reference to `libecap::Name::assignHostId(int) const'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:49:
undefined reference to `libecap::protocolHttps'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:49:
undefined reference to `libecap::Name::assignHostId(int) const'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:50:
undefined reference to `libecap::protocolFtp'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:50:
undefined reference to `libecap::Name::assignHostId(int) const'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:51:
undefined reference to `libecap::protocolGopher'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:51:
undefined reference to `libecap::Name::assignHostId(int) const'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:52:
undefined reference to `libecap::protocolWais'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:52:
undefined reference to `libecap::Name::assignHostId(int) const'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:53:
undefined reference to `libecap::protocolUrn'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:53:
undefined reference to `libecap::Name::assignHostId(int) const'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:54:
undefined reference to `libecap::protocolWhois'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:54:
undefined reference to `libecap::Name::assignHostId(int) const'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:55:
undefined reference to `libecap::Name::assignHostId(int) const'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:56:
undefined reference to `libecap::Name::assignHostId(int) const'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:58:
undefined reference to `libecap::Name::assignHostId(int) const'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:60:
undefined reference to `libecap::Name::assignHostId(int) const'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-
Host.o):/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/Host.cc:61: more undefined references to
`libecap::Name::assignHostId(int) const' follow
adaptation/.libs/libadaptation.a(libsquid_ecap_la-Host.o): In function
`Adaptation::Ecap::Host::Register()':
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:178:
undefined reference to `libecap::VersionString()'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:180:
undefined reference to
`libecap::RegisterHost(std::tr1::shared_ptr<libecap::host::Host>
const&)'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-Host.o): In function
`__static_initialization_and_destruction_0':
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:22:
undefined reference to `libecap::Name::NextId()'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:22:
undefined reference to `libecap::Name::Name(std::string const&, int)'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:23:
undefined reference to `libecap::Name::NextId()'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:23:
undefined reference to `libecap::Name::Name(std::string const&, int)'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:24:
undefined reference to `libecap::Name::NextId()'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:24:
undefined reference to `libecap::Name::Name(std::string const&, int)'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:26:
undefined reference to `libecap::Name::NextId()'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:26:
undefined reference to `libecap::Name::Name(std::string const&, int)'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:28:
undefined reference to `libecap::Name::NextId()'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:28:
undefined reference to `libecap::Name::Name(std::string const&, int)'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:29:
undefined reference to `libecap::Name::NextId()'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:29:
undefined reference to `libecap::Name::Name(std::string const&, int)'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:31:
undefined reference to `libecap::Name::NextId()'
/home//nobackup/build/squid-3.5.20/src/adaptation/ecap/Host.cc:31:
undefined reference to `libecap::Name::Name(std::string const&, int)'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-MessageRep.o): In
function `~Message':
/opt/ecap/include/libecap/common/message.h:16: undefined reference to
`vtable for libecap::Message'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-MessageRep.o): In
function `Adaptation::Ecap::RequestLineRep::method(libecap::Name
const&)':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/MessageRep.cc:231: undefined reference to
`libecap::Name::assignedHostId() const'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-MessageRep.o): In
function `Adaptation::Ecap::RequestLineRep::uri() const':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/MessageRep.cc:225: undefined reference to
`libecap::Area::FromTempBuffer(char const*, unsigned long)'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-MessageRep.o): In
function `Adaptation::Ecap::StatusLineRep::reasonPhrase() const':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/MessageRep.cc:321: undefined reference to
`libecap::Area::FromTempString(std::string const&)'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-MessageRep.o): In
function `Adaptation::Ecap::RequestLineRep::uri(libecap::Area const&)':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/MessageRep.cc:213: undefined reference to
`libecap::Area::toString() const'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-MessageRep.o): In
function `Name':
/opt/ecap/include/libecap/common/name.h:14: undefined reference to
`libecap::methodDelete'
/opt/ecap/include/libecap/common/name.h:14: undefined reference to
`libecap::methodGet'
/opt/ecap/include/libecap/common/name.h:14: undefined reference to
`libecap::methodPost'
/opt/ecap/include/libecap/common/name.h:14: undefined reference to
`libecap::methodPut'
/opt/ecap/include/libecap/common/name.h:14: undefined reference to
`libecap::methodHead'
/opt/ecap/include/libecap/common/name.h:14: undefined reference to
`libecap::methodConnect'
/opt/ecap/include/libecap/common/name.h:14: undefined reference to
`libecap::methodTrace'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-MessageRep.o): In
function `Adaptation::Ecap::RequestLineRep::method() const':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/MessageRep.cc:262: undefined reference to
`libecap::Name::Name(std::string const&)'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-MessageRep.o): In
function `Adaptation::Ecap::HeaderRep::image() const':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/MessageRep.cc:99: undefined reference to
`libecap::Area::FromTempBuffer(char const*, unsigned long)'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-MessageRep.o): In
function `Adaptation::Ecap::HeaderRep::TranslateHeaderId(libecap::Name
const&)':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/MessageRep.cc:116: undefined reference to
`libecap::Name::assignedHostId() const'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-MessageRep.o): In
function `Adaptation::Ecap::HeaderRep::add(libecap::Name const&,
libecap::Area const&)':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/MessageRep.cc:58: undefined reference to
`libecap::Area::toString() const'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-MessageRep.o): In
function `Adaptation::Ecap::HeaderRep::value(libecap::Name const&)
const':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/MessageRep.cc:50: undefined reference to
`libecap::Area::FromTempString(std::string const&)'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-MessageRep.o): In
function `Adaptation::Ecap::FirstLineRep::protocol() const':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/MessageRep.cc:182: undefined reference to
`libecap::Name::Name()'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-MessageRep.o): In
function `Name':
/opt/ecap/include/libecap/common/name.h:14: undefined reference to
`libecap::protocolHttp'
/opt/ecap/include/libecap/common/name.h:14: undefined reference to
`libecap::protocolFtp'
/opt/ecap/include/libecap/common/name.h:14: undefined reference to
`libecap::protocolHttps'
/opt/ecap/include/libecap/common/name.h:14: undefined reference to
`libecap::protocolGopher'
/opt/ecap/include/libecap/common/name.h:14: undefined reference to
`libecap::protocolWais'
/opt/ecap/include/libecap/common/name.h:14: undefined reference to
`libecap::protocolUrn'
/opt/ecap/include/libecap/common/name.h:14: undefined reference to
`libecap::protocolWhois'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-MessageRep.o): In
function
`Adaptation::Ecap::FirstLineRep::TranslateProtocolId(libecap::Name
const&)':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/MessageRep.cc:195: undefined reference to
`libecap::Name::assignedHostId() const'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-MessageRep.o): In
function `~Message':
/opt/ecap/include/libecap/common/message.h:16: undefined reference to
`vtable for libecap::Message'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-MessageRep.o): In
function
`Adaptation::Ecap::HeaderRep::visitEach(libecap::NamedValueVisitor&)
const':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/MessageRep.cc:83: undefined reference to
`libecap::Name::Name(std::string const&)'
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/MessageRep.cc:84: undefined reference to
`libecap::Name::assignHostId(int) const'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-
MessageRep.o):(.data.rel.ro._ZTIN10Adaptation4Ecap10MessageRepE[_ZTIN10
Adaptation4Ecap10MessageRepE]+0x10): undefined reference to `typeinfo
for libecap::Message'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-
MessageRep.o):(.data.rel.ro._ZTVN10Adaptation4Ecap10MessageRepE[_ZTVN10
Adaptation4Ecap10MessageRepE]+0x60): undefined reference to
`libecap::Message::addTrailer()'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-ServiceRep.o): In
function `Adaptation::Ecap::ConfigRep::option(libecap::Name const&)
const':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/ServiceRep.cc:86: undefined reference to
`libecap::Name::Name(std::string const&)'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-ServiceRep.o): In
function
`Adaptation::Ecap::ConfigRep::visitEachOption(libecap::NamedValueVisito
r&) const':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/ServiceRep.cc:102: undefined reference to
`libecap::Area::FromTempString(std::string const&)'
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/ServiceRep.cc:102: undefined reference to
`libecap::Name::Name(std::string const&)'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-XactionRep.o): In
function `Adaptation::Ecap::XactionRep::clientIpValue() const':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:140: undefined reference to
`libecap::Area::FromTempBuffer(char const*, unsigned long)'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-XactionRep.o): In
function `Adaptation::Ecap::XactionRep::usernameValue() const':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:155: undefined reference to
`libecap::Area::FromTempBuffer(char const*, unsigned long)'
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:158: undefined reference to
`libecap::Area::FromTempBuffer(char const*, unsigned long)'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-XactionRep.o): In
function `Adaptation::Ecap::XactionRep::metaValue(libecap::Name const&)
const':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:194: undefined reference to
`libecap::Area::FromTempString(std::string const&)'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-XactionRep.o): In
function `Adaptation::Ecap::XactionRep::answer()':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:328: undefined reference to
`typeinfo for libecap::Message'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-XactionRep.o): In
function `Adaptation::Ecap::XactionRep::status() const':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:718: undefined reference to
`typeinfo for libecap::Message'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-XactionRep.o): In
function `Adaptation::Ecap::XactionRep::moveAbContent()':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:681: undefined reference to
`libecap::nsize'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-XactionRep.o): In
function
`Adaptation::Ecap::XactionRep::visitEachMetaHeader(libecap::NamedValueV
isitor&) const':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:216: undefined reference to
`libecap::Name::Name(std::string const&)'
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:217: undefined reference to
`libecap::Area::FromTempString(std::string const&)'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-XactionRep.o): In
function `Adaptation::Ecap::XactionRep::updateHistory(HttpMsg*)':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:476: undefined reference to
`libecap::Name::Name(std::string const&)'
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:478: undefined reference to
`libecap::Area::toString() const'
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:485: undefined reference to
`libecap::metaNextServices'
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:488: undefined reference to
`libecap::Area::toString() const'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-XactionRep.o): In
function
`Adaptation::Ecap::XactionRep::masterxSharedValue(libecap::Name const&)
const':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:175: undefined reference to
`libecap::Area::FromTempBuffer(char const*, unsigned long)'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-XactionRep.o): In
function
`Adaptation::Ecap::XactionRep::visitEachOption(libecap::NamedValueVisit
or&) const':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:106: undefined reference to
`libecap::metaClientIp'
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:108: undefined reference to
`libecap::metaUserName'
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:111: undefined reference to
`libecap::Name::Name(std::string const&)'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-XactionRep.o): In
function `libecap::Name::operator==(libecap::Name const&) const':
/opt/ecap/include/libecap/common/name.h:27: undefined reference to
`libecap::metaClientIp'
/opt/ecap/include/libecap/common/name.h:27: undefined reference to
`libecap::metaUserName'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-XactionRep.o): In
function `std::string::_M_data() const':
/usr/include/c++/4.8/bits/basic_string.h:293: undefined reference to
`libecap::metaClientIp'
/usr/include/c++/4.8/bits/basic_string.h:293: undefined reference to
`libecap::metaUserName'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-XactionRep.o): In
function `Adaptation::Ecap::XactionRep::vbContent(unsigned long,
unsigned long)':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:562: undefined reference to
`libecap::nsize'
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:567: undefined reference to
`libecap::Area::FromTempBuffer(char const*, unsigned long)'
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:562: undefined reference to
`libecap::nsize'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-XactionRep.o): In
function
`Adaptation::Ecap::XactionRep::useAdapted(std::tr1::shared_ptr<libecap:
:Message> const&)':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:430: undefined reference to
`typeinfo for libecap::Message'
adaptation/.libs/libadaptation.a(libsquid_ecap_la-XactionRep.o): In
function `OptionsExtractor::visit(libecap::Name const&, libecap::Area
const&)':
/home//nobackup/build/squid-
3.5.20/src/adaptation/ecap/XactionRep.cc:41: undefined reference to
`libecap::Area::toString() const'
collect2: error: ld returned 1 exit status
libtool: link: rm -f ".libs/squidS.o"
make[3]: *** [squid] Error 1
make[3]: Leaving directory `/home//nobackup/build/squid-3.5.20/src'
make[2]: *** [all-recursive] Error 1
make[2]: Leaving directory `/home//nobackup/build/squid-3.5.20/src'
make[1]: *** [all] Error 2
make[1]: Leaving directory `/home//nobackup/build/squid-3.5.20/src'
make: *** [all-recursive] Error 1
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161011/0c211849/attachment.htm>

From rousskov at measurement-factory.com  Tue Oct 11 14:42:01 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 11 Oct 2016 08:42:01 -0600
Subject: [squid-users] Squid 2.5.20 fails to compile with ecap
In-Reply-To: <1476190481.11475.1.camel@slave-tothe-box.net>
References: <1476190481.11475.1.camel@slave-tothe-box.net>
Message-ID: <a119a9df-37f9-ad7e-473d-968a764a94ef@measurement-factory.com>

On 10/11/2016 06:54 AM, James Lay wrote:

> EXT_LIBECAP_CFLAGS="-I/opt/ecap/include"
> EXT_LIBECAP_LIBS="-L/opt/ecap/lib" ./configure --prefix=/opt
> --with-openssl=/opt/libressl --enable-ssl --enable-ssl-crtd
> --enable-linux-netfilter --enable-follow-x-forwarded-for
> --with-large-files --sysconfdir=/opt/etc/squid
> --enable-xternal-acl-helpers=none --enable-ecap

Your Squid executable is not linked with libecap, resulting in undefined
references to libecap symbols:

> /bin/bash ../libtool  --tag=CXX   --mode=link g++ -Wall -Wpointer-arith
> -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -Werror -pipe
> -D_REENTRANT -m64   -g -O2 -march=native -std=c++11 -export-dynamic
> -dlopen force -m64 -g -o squid 

<snipped many lines without -lecap, libecap, or equivalent>

> adaptation/.libs/libadaptation.a(libsquid_ecap_la-Host.o):
> undefined reference to `libecap::headerTransferEncoding'

I am not sure why Your Squid executable is not linked with libecap, but
I suspect that manually setting EXT_LIBECAP_CFLAGS and EXT_LIBECAP_LIBS
confuses ./configure. You should not set those variables manually and
let Squid compute them automatically instead. You may need to set
PKG_CONFIG_PATH if Squid cannot find libecap.pc without it.


HTH,

Alex.
P.S. I assume you meant to type "3.5.20" in the Subject


From jlay at slave-tothe-box.net  Tue Oct 11 14:45:19 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Tue, 11 Oct 2016 08:45:19 -0600
Subject: [squid-users] Squid 2.5.20 fails to compile with ecap
In-Reply-To: <a119a9df-37f9-ad7e-473d-968a764a94ef@measurement-factory.com>
References: <1476190481.11475.1.camel@slave-tothe-box.net>
 <a119a9df-37f9-ad7e-473d-968a764a94ef@measurement-factory.com>
Message-ID: <0681e19d0a1a628eea34e7ae021263ea@localhost>

On 2016-10-11 08:42, Alex Rousskov wrote:
> On 10/11/2016 06:54 AM, James Lay wrote:
> 
>> EXT_LIBECAP_CFLAGS="-I/opt/ecap/include"
>> EXT_LIBECAP_LIBS="-L/opt/ecap/lib" ./configure --prefix=/opt
>> --with-openssl=/opt/libressl --enable-ssl --enable-ssl-crtd
>> --enable-linux-netfilter --enable-follow-x-forwarded-for
>> --with-large-files --sysconfdir=/opt/etc/squid
>> --enable-xternal-acl-helpers=none --enable-ecap
> 
> Your Squid executable is not linked with libecap, resulting in 
> undefined
> references to libecap symbols:
> 
>> /bin/bash ../libtool  --tag=CXX   --mode=link g++ -Wall 
>> -Wpointer-arith
>> -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -Werror -pipe
>> -D_REENTRANT -m64   -g -O2 -march=native -std=c++11 -export-dynamic
>> -dlopen force -m64 -g -o squid
> 
> <snipped many lines without -lecap, libecap, or equivalent>
> 
>> adaptation/.libs/libadaptation.a(libsquid_ecap_la-Host.o):
>> undefined reference to `libecap::headerTransferEncoding'
> 
> I am not sure why Your Squid executable is not linked with libecap, but
> I suspect that manually setting EXT_LIBECAP_CFLAGS and EXT_LIBECAP_LIBS
> confuses ./configure. You should not set those variables manually and
> let Squid compute them automatically instead. You may need to set
> PKG_CONFIG_PATH if Squid cannot find libecap.pc without it.
> 
> 
> HTH,
> 
> Alex.
> P.S. I assume you meant to type "3.5.20" in the Subject

Thanks Alex...and yes indeed...meant 3.5.20.  Can you point me in the 
right direction on where to tell squid that libecap lives in /opt/ecap?  
I'll give the pkg-config a go as well.

James


From rousskov at measurement-factory.com  Tue Oct 11 16:52:46 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 11 Oct 2016 10:52:46 -0600
Subject: [squid-users] Squid 2.5.20 fails to compile with ecap
In-Reply-To: <0681e19d0a1a628eea34e7ae021263ea@localhost>
References: <1476190481.11475.1.camel@slave-tothe-box.net>
 <a119a9df-37f9-ad7e-473d-968a764a94ef@measurement-factory.com>
 <0681e19d0a1a628eea34e7ae021263ea@localhost>
Message-ID: <b2d246c9-7cb3-8490-b3f4-3fa135904d19@measurement-factory.com>

On 10/11/2016 08:45 AM, James Lay wrote:
> Can you point me in the right direction on where to tell squid that
> libecap lives in /opt/ecap? 

This is not my area of expertise, but if ./configure --enable-ecap does
not work "as is", then you may need to set PKG_CONFIG_PATH
appropriately. For example:

  export PKG_CONFIG_PATH=...
  ./configure --enable-ecap ...

Alex.



From alex at imaginers.org  Tue Oct 11 17:09:38 2016
From: alex at imaginers.org (- -)
Date: Tue, 11 Oct 2016 19:09:38 +0200 (CEST)
Subject: [squid-users] peek-and-splice on Centos7 and squid4
Message-ID: <1569903703.307394.28a72b84-a091-48c4-83f9-74a8bbde1a18.open-xchange@email.1und1.de>

Dear all,

currently I try to configure peek-and-splice on Centos7 and squid4. I have a
running config for Centos6.6 and squid 3.5.18.

No matter what I try i can't get squid4 to splice certain sites and to
bump/terminate the rest. My config is as follows:

acl sni_exclusions ssl::server_name .google.com
acl sni_exclusions ssl::server_name .google.de

acl tcp_level at_step SslBump1
acl client_hello_peeked at_step SslBump2
ssl_bump peek tcp_level all
ssl_bump splice client_hello_peeked sni_exclusions
ssl_bump bump all

if I replace the ssl_bump bump all with ssl_bump terminate all, all sites are
terminated, if I do a ssl_bump splice all, all https traffic is going through.

the log when a device connects to an allowed site looks is below, if I accept
the self generated certificate access the webpage is allowed. If i do the same
with a site not allowed i'll get redirected to the deny_info page after
accepting the certificate. So everything working as desired besides the
certificate warning for "spliced" websites. I'm using the squid4 build from
http://wiki.squid-cache.org/KnowledgeBase/CentOS#Squid_Beta_release.

Thanks in advance for any hint,
Alex

squid version:
 squid -v
Squid Cache: Version 4.0.12
Service Name: squid
configure options:  '--build=x86_64-redhat-linux-gnu'
'--host=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr'
'--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin'
'--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include'
'--libdir=/usr/lib64' '--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib'
'--mandir=/usr/share/man' '--infodir=/usr/share/info' '--exec_prefix=/usr'
'--libexecdir=/usr/lib64/squid' '--localstatedir=/var'
'--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
'--with-logdir=$(localstatedir)/log/squid'
'--with-pidfile=$(localstatedir)/run/squid.pid' '--disable-dependency-tracking'
'--enable-follow-x-forwarded-for' '--enable-auth'
'--enable-auth-basic=DB,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,getpwnam,fake'
'--enable-auth-ntlm=fake' '--enable-auth-digest=file,LDAP,eDirectory'
'--enable-auth-negotiate=kerberos,wrapper'
'--enable-external-acl-helpers=wbinfo_group,kerberos_ldap_group,LDAP_group,delayer,file_userip,SQL_session,unix_group,session,time_quota'
'--enable-cache-digests' '--enable-cachemgr-hostname=localhost'
'--enable-delay-pools' '--enable-epoll' '--enable-icap-client'
'--enable-ident-lookups' '--enable-linux-netfilter'
'--enable-removal-policies=heap,lru' '--enable-snmp'
'--enable-storeio=aufs,diskd,ufs,rock' '--enable-wccpv2' '--enable-esi'
'--enable-security-cert-generators' '--enable-security-cert-validators'
'--enable-icmp' '--with-aio' '--with-default-user=squid'
'--with-filedescriptors=16384' '--with-dl' '--with-openssl' '--with-pthreads'
'--with-included-ltdl' '--disable-arch-native' '--enable-ecap'
'--without-nettle' 'build_alias=x86_64-redhat-linux-gnu'
'host_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong
--param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic'
'LDFLAGS=-Wl,-z,relro ' 'CXXFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2
-fexceptions -fstack-protector-strong --param=ssp-buffer-size=4
-grecord-gcc-switches   -m64 -mtune=generic -fPIC'
'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig'
--enable-ltdl-convenience


cache.log:
2016/10/11 16:54:57.126 kid1| 33,5| client_side.cc(1367) parseHttpRequest:
Prepare absolute URL from intercept
2016/10/11 16:54:57.126 kid1| 33,5| client_side.cc(2150) clientParseRequests:
local=216.58.211.3:443 remote=10.248.0.8:59837 FD 25 flags=33: done parsing a
request
2016/10/11 16:54:57.126 kid1| 33,3| Pipeline.cc(24) add: Pipeline 0x2b008e0 add
request 1 0x2b06280*3
2016/10/11 16:54:57.126 kid1| 33,5| Http1Server.cc(181) buildHttpRequest:
normalize 1 Host header using 216.58.211.3:443
2016/10/11 16:54:57.126 kid1| 33,3| client_side.cc(643) clientSetKeepaliveFlag:
http_ver = HTTP/1.1
2016/10/11 16:54:57.126 kid1| 33,3| client_side.cc(644) clientSetKeepaliveFlag:
method = CONNECT
2016/10/11 16:54:57.126 kid1| 33,3| http/Stream.h(139) mayUseConnection: This
0x2b06280 marked 1
2016/10/11 16:54:57.127 kid1| 33,3| client_side.cc(2163) clientParseRequests:
Not parsing new requests, as this request may need the connection
2016/10/11 16:54:57.127 kid1| 33,5| client_side.cc(3113) switchToHttps:
converting local=216.58.211.3:443 remote=10.248.0.8:59837 FD 25 flags=33 to SSL
2016/10/11 16:54:57.127 kid1| 33,4| ServerBump.cc(27) ServerBump: will peek at
216.58.211.3:443
2016/10/11 16:54:57.127 kid1| 33,5| AsyncCall.cc(26) AsyncCall: The AsyncCall
ConnStateData::requestTimeout constructed, this=0x2b00b70 [call688]
2016/10/11 16:54:57.127 kid1| 33,4| Server.cc(90) readSomeData:
local=216.58.211.3:443 remote=10.248.0.8:59837 FD 25 flags=33: reading
request...
2016/10/11 16:54:57.127 kid1| 33,5| AsyncCall.cc(26) AsyncCall: The AsyncCall
Server::doClientRead constructed, this=0x2b00c00 [call689]
2016/10/11 16:54:57.131 kid1| 33,5| AsyncCall.cc(93) ScheduleCall:
IoCallback.cc(135) will call Server::doClientRead(local=216.58.211.3:443
remote=10.248.0.8:59837 FD 25 flags=33, data=0x2b00898) [call689]
2016/10/11 16:54:57.131 kid1| 33,5| AsyncCallQueue.cc(55) fireNext: entering
Server::doClientRead(local=216.58.211.3:443 remote=10.248.0.8:59837 FD 25
flags=33, data=0x2b00898)
2016/10/11 16:54:57.131 kid1| 33,5| AsyncCall.cc(38) make: make call
Server::doClientRead [call689]
2016/10/11 16:54:57.131 kid1| 33,5| AsyncJob.cc(123) callStart: Http1::Server
status in: [ job31]
2016/10/11 16:54:57.131 kid1| 33,5| Server.cc(104) doClientRead:
local=216.58.211.3:443 remote=10.248.0.8:59837 FD 25 flags=33
2016/10/11 16:54:57.131 kid1| 33,5| AsyncCall.cc(26) AsyncCall: The AsyncCall
ConnStateData::requestTimeout constructed, this=0x2b04940 [call690]
2016/10/11 16:54:57.131 kid1| 33,3| Pipeline.cc(35) front: Pipeline 0x2b008e0
front 0x2b06280*2
2016/10/11 16:54:57.131 kid1| 33,5| client_side.cc(3232)
httpsSslBumpStep2AccessCheckDone: Answer: ALLOWED kind:5
2016/10/11 16:54:57.131 kid1| 33,3| Pipeline.cc(35) front: Pipeline 0x2b008e0
front 0x2b06280*3
2016/10/11 16:54:57.132 kid1| 33,5| client_side.cc(2577) httpsCreate: will
negotate SSL on local=216.58.211.3:443 remote=10.248.0.8:59837 FD 25 flags=33
2016/10/11 16:54:57.132 kid1| 33,5| AsyncJob.cc(153) callEnd: Http1::Server
status out: [ job31]
2016/10/11 16:54:57.132 kid1| 33,5| AsyncCallQueue.cc(57) fireNext: leaving
Server::doClientRead(local=216.58.211.3:443 remote=10.248.0.8:59837 FD 25
flags=33, data=0x2b00898)
2016/10/11 16:54:57.182 kid1| 33,3| client_side.cc(4000) unpinConnection:
2016/10/11 16:54:57.182 kid1| 33,3| client_side.cc(3833) pinNewConnection:
local=10.4.38.62:26120 remote=216.58.211.3:443 FD 26 flags=1
2016/10/11 16:54:57.182 kid1| 33,5| AsyncCall.cc(26) AsyncCall: The AsyncCall
ConnStateData::clientPinnedConnectionClosed constructed, this=0x2b3e750
[call704]
2016/10/11 16:54:57.182 kid1| 33,3| AsyncCall.cc(26) AsyncCall: The AsyncCall
ConnStateData::clientPinnedConnectionRead constructed, this=0x2b262b0 [call705]
2016/10/11 16:54:57.182 kid1| 33,5| client_side.cc(3361) httpsPeeked: bumped
HTTPS server: 216.58.211.3
2016/10/11 16:54:57.182 kid1| 33,3| Pipeline.cc(44) terminateAll: Pipeline
0x2b008e0 notify(0) 0x2b06280*3
2016/10/11 16:54:57.182 kid1| 33,3| Pipeline.cc(57) popMe: Pipeline 0x2b008e0
drop 0x2b06280*3
2016/10/11 16:54:57.183 kid1| 33,3| client_side_request.cc(270)
~ClientHttpRequest: httpRequestFree: 216.58.211.3:443
2016/10/11 16:54:57.183 kid1| 33,5| client_side.cc(383) logRequest: logging
half-baked transaction: 216.58.211.3:443
2016/10/11 16:54:57.183 kid1| 33,9| client_side.cc(387) logRequest:
clientLogRequest: al.url='216.58.211.3:443'
2016/10/11 16:54:57.183 kid1| 33,9| client_side.cc(397) logRequest:
clientLogRequest: http.code='200'
2016/10/11 16:54:57.183 kid1| 33,5| client_side.cc(3027) getSslContextStart:
Generating SSL certificate for www.google.de
2016/10/11 16:54:57.183 kid1| 33,5| client_side.cc(3346) doPeekAndSpliceStep:
PeekAndSplice mode, proceed with client negotiation. Currrent state:SSLv2/v3
read client hello A
2016/10/11 16:54:57.183 kid1| Error negotiating SSL connection on FD 25:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
2016/10/11 16:54:57.209 kid1| 33,5| AsyncCall.cc(93) ScheduleCall: comm.cc(736)
will call ConnStateData::connStateClosed(FD -1, data=0x2b00898) [call685]
2016/10/11 16:54:57.209 kid1| 33,5| AsyncCallQueue.cc(55) fireNext: entering
ConnStateData::connStateClosed(FD -1, data=0x2b00898)
2016/10/11 16:54:57.209 kid1| 33,5| AsyncCall.cc(38) make: make call
ConnStateData::connStateClosed [call685]
2016/10/11 16:54:57.209 kid1| 33,5| AsyncJob.cc(123) callStart: Http1::Server
status in: [ job31]
2016/10/11 16:54:57.209 kid1| 33,2| client_side.cc(586) swanSong:
local=216.58.211.3:443 remote=10.248.0.8:59837 flags=33
2016/10/11 16:54:57.209 kid1| 33,3| client_side.cc(4000) unpinConnection:
local=10.4.38.62:26120 remote=216.58.211.3:443 FD 26 flags=1
2016/10/11 16:54:57.209 kid1| 33,5| AsyncCall.cc(56) cancel: will not call
ConnStateData::clientPinnedConnectionClosed [call704] because
comm_remove_close_handler
2016/10/11 16:54:57.209 kid1| 33,3| AsyncCall.cc(56) cancel: will not call
ConnStateData::clientPinnedConnectionRead [call705] because comm_read_cancel
2016/10/11 16:54:57.209 kid1| 33,3| AsyncCall.cc(56) cancel: will not call
ConnStateData::clientPinnedConnectionRead [call705] also because
comm_read_cancel
2016/10/11 16:54:57.209 kid1| 33,3| client_side.cc(614) ~ConnStateData:
local=216.58.211.3:443 remote=10.248.0.8:59837 flags=33
2016/10/11 16:54:57.209 kid1| 33,4| ServerBump.cc(46) ~ServerBump: destroying
2016/10/11 16:54:57.209 kid1| 33,4| ServerBump.cc(48) ~ServerBump:
e:=sp2XDIV/0x2b04270*1
2016/10/11 16:54:57.209 kid1| 33,5| AsyncCallQueue.cc(57) fireNext: leaving
ConnStateData::connStateClosed(FD -1, data=0x2b00898)


From rousskov at measurement-factory.com  Tue Oct 11 17:36:09 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 11 Oct 2016 11:36:09 -0600
Subject: [squid-users] peek-and-splice on Centos7 and squid4
In-Reply-To: <1569903703.307394.28a72b84-a091-48c4-83f9-74a8bbde1a18.open-xchange@email.1und1.de>
References: <1569903703.307394.28a72b84-a091-48c4-83f9-74a8bbde1a18.open-xchange@email.1und1.de>
Message-ID: <c47183df-1150-9ccf-9bf5-1a1e597d5ddd@measurement-factory.com>

On 10/11/2016 11:09 AM, - - wrote:

> currently I try to configure peek-and-splice on Centos7 and squid4. I have a
> running config for Centos6.6 and squid 3.5.18.

It might be useful to confirm that v4.0 does not work on Centos6.6
either (so that there is only one variable -- the Squid version).


> No matter what I try i can't get squid4 to splice certain sites and to
> bump/terminate the rest. My config is as follows:
> 
> acl sni_exclusions ssl::server_name .google.com
> acl sni_exclusions ssl::server_name .google.de
> 
> acl tcp_level at_step SslBump1
> acl client_hello_peeked at_step SslBump2
> ssl_bump peek tcp_level all
> ssl_bump splice client_hello_peeked sni_exclusions
> ssl_bump bump all
> 
> if I replace the ssl_bump bump all with ssl_bump terminate all, all sites are
> terminated, if I do a ssl_bump splice all, all https traffic is going through.

Which implies that your splice rule never matches or the match is
ignored for some reason.


> if I accept
> the self generated certificate access the webpage is allowed. If i do the same
> with a site not allowed i'll get redirected to the deny_info page after
> accepting the certificate.

This is consistent with the above theory. The logs you have posted do
not contain ACL evaluation and post-evaluation details so it is
difficult to say why splice does not work. Please post more related
lines from an ALL,9 log. For example, something like the following might
work:

$ egrep -200 -i 'acl|google|-----|bump|sni' cache.log

Compress the results if needed.

Alex.



From jlay at slave-tothe-box.net  Tue Oct 11 20:21:53 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Tue, 11 Oct 2016 14:21:53 -0600
Subject: [squid-users] Squid 2.5.20 fails to compile with ecap
In-Reply-To: <b2d246c9-7cb3-8490-b3f4-3fa135904d19@measurement-factory.com>
References: <1476190481.11475.1.camel@slave-tothe-box.net>
 <a119a9df-37f9-ad7e-473d-968a764a94ef@measurement-factory.com>
 <0681e19d0a1a628eea34e7ae021263ea@localhost>
 <b2d246c9-7cb3-8490-b3f4-3fa135904d19@measurement-factory.com>
Message-ID: <f8fd2ffdfcfcb5e15ca57779eec7525e@localhost>

On 2016-10-11 10:52, Alex Rousskov wrote:
> On 10/11/2016 08:45 AM, James Lay wrote:
>> Can you point me in the right direction on where to tell squid that
>> libecap lives in /opt/ecap?
> 
> This is not my area of expertise, but if ./configure --enable-ecap does
> not work "as is", then you may need to set PKG_CONFIG_PATH
> appropriately. For example:
> 
>   export PKG_CONFIG_PATH=...
>   ./configure --enable-ecap ...
> 
> Alex.

Last word on this...config line:

./configure --prefix=/opt --with-openssl=/opt/libressl --enable-ssl 
--enable-ssl-crtd --enable-linux-netfilter 
--enable-follow-x-forwarded-for --with-large-files 
--sysconfdir=/opt/etc/squid --enable-xternal-acl-helpers=none 
--enable-ecap

Symlinking the libecap.pc, /opt/ecap/lib/pkgconfig/libecap.pc to 
/usr/lib/x86_64-linux-gnu/pkgconfig/ did the trick...thanks so much!

James


From makleking at yandex.ru  Thu Oct 13 02:15:21 2016
From: makleking at yandex.ru (=?utf-8?B?0JzQuNGF0LDQuNC7?=)
Date: Thu, 13 Oct 2016 10:15:21 +0800
Subject: [squid-users] ERROR: Cannot connect to 127.0.0.1:3128
In-Reply-To: <e663dbd7-b739-ecb9-3598-c649c2b97fcf@treenet.co.nz>
References: <294681476158099@web11o.yandex.ru>
 <e663dbd7-b739-ecb9-3598-c649c2b97fcf@treenet.co.nz>
Message-ID: <6306491476324921@web24g.yandex.ru>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161013/49f9c6b5/attachment.htm>

From squid3 at treenet.co.nz  Wed Oct 12 14:42:07 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 13 Oct 2016 03:42:07 +1300
Subject: [squid-users] [squid-announce] Squid 4.0.15 beta is available
Message-ID: <a6ebdec8-ee0a-a862-6b85-d1e497b467c7@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-4.0.15 release!


This release is a bug fix and stability release resolving several issues
found in the prior Squid releases.


The major changes to be aware of:

This release there are no major changes. Despite the size of code
commited most of the change has been small polishing and stability
changes. Some incidental and minor memory leaks have been resolved, and
some crashes introduced by the new Squid-4 features have been resolved.


One change shared with 3.5.22 is noteworthy as it affects cache storage
formats:

* Bug #4471: revalidation doesn't work when expired cached object lacks
  Last-Modified header.

Historically Squid used only Last-Modified header value for evaluating
entry's last modification time while making an internal revalidation
requests. So, without Last-Modified it was not possible to correctly
fill the If-Modified-Since header value. Which would result in many
unnecessary MISS. This release now uses Date header to synthesize a
Last-Modified value if none is provided.

IMPORTANT:
This change affects a binary difference in all cache objects stored by
Squid-4.0.15 or later, and by Squid-3.5.22 or later.
 * When upgrading, older cache content is handled automatically.
 * When downgrading for any reason to an older version the cache will
need to be erased and rebuilt from empty to remove those new objects.


 All users of Squid-4.0.x are encouraged to upgrade to this release as
soon as possible.

 All users of Squid-3 are encouraged to test this release out and plan
for upgrades where possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v4/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Wed Oct 12 14:42:29 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 13 Oct 2016 03:42:29 +1300
Subject: [squid-users] [squid-announce] Squid 3.5.22 is available
Message-ID: <aa6d97d2-2174-12e9-b7e3-e50392bc4d7a@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-3.5.22 release!


This release is a bug fix release resolving several issues found in the
prior Squid releases.


The major changes to be aware of:

* Bug #4471: revalidation doesn't work when expired cached object lacks
  Last-Modified header.

Historically Squid used only Last-Modified header value for evaluating
entry's last modification time while making an internal revalidation
requests. So, without Last-Modified it was not possible to correctly
fill the If-Modified-Since header value. Which would result in many
unnecessary MISS. This release now uses Date header to synthesize a
Last-Modified value if none is provided.

IMPORTANT:
This change affects a binary difference in all cache objects stored.
 * When upgrading, older cache content is handled automatically.
 * When downgrading for any reason to an older version the cache will
need to be erased and rebuilt from empty to remove those new objects.


* Bug #4228: ./configure bug/typo

This bug caused Squid ./configure script to incorrectly fail to detect
missing but required Heimdal and GNU GSS Kerberos libraries. Squid would
build as if it were successful, then not provide the expected Kerberos
support and helpers.


* Bug #3819: "fd >= 0" assertion in file_write() during reconfiguration

This bug shows up as UFS code hitting assertions if it has to log
entries or rebuild swap.state during reconfiguration steps.

Asynchronous UFS cache_dirs such as diskd were the most exposed, but
even blocking UFS caching code could probably hit [rebuild] assertions.
The swap.state rebuilding (always initiated at startup) probably did not
work as intended if reconfiguration happened during the rebuild time
because reconfiguration closed the swap.state file being rebuilt.

Squid now protects that swap.state file and delays rebuilding progress
until reconfiguration is over. There may be other related issues still
present.


* Bug #2833: Collapse internal revalidation requests
  (SMP-unaware caches)

This feature extends Collapsed Forwarding to internal revalidation
requests. This implementation does not support Vary-controlled cache
objects and is limited to SMP-unaware caching environments, where each
Squid worker knows nothing about requests and caches handled by other
workers.

Prior to these changes, multiple concurrent HTTP requests for the same
stale cached object always resulted in multiple internal revalidation
requests sent by Squid to the origin server. Those internal requests
were likely to result in multiple competing Squid cache updates, causing
cache misses and/or more internal revalidation requests, negating
collapsed forwarding savings.


* Bug #4302 pt2: IPFilter v5 transparent interception

This bug showed up as NAT lookup failures or strange IP values being
returned when IPv6 traffic was intercepted using IPFilter.


* Fix logged request size (%http::>st) and other size-related %codes.

Squid was previously logging how many bytes it expected the size of HTTP
responses to be. Not the actual transferred sizes. On large aborted
objects it may be wildly wrong.
Also, the %http:: codes used in ICAP logs are related to the HTTP
message being delivered over ICAP, not the ICAP message.



 All users of Squid-3 are encouraged to upgrade to this release as
soon as possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v3/3.5/RELEASENOTES.html
when you are ready to make the switch to Squid-3.5

Upgrade tip:
  "squid -k parse" is starting to display even more
   useful hints about squid.conf changes.

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v3/3.5/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/3.5/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries

_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From tarotapprentice at yahoo.com  Thu Oct 13 05:20:36 2016
From: tarotapprentice at yahoo.com (Mark James)
Date: Thu, 13 Oct 2016 16:20:36 +1100
Subject: [squid-users] Getting latest 3.5 version into Debian
Message-ID: <EAC18DDF-30CA-4FA9-92F4-84DFF5BA17DB@yahoo.com>

Hi Amos,

Not sure if the Debian maintainers get included in the announcements or not. Do you have any contact with them? I have emailed Luigi previously to see if they could update Sid/Stretch as it's still on 3.5.19. Maybe you would have better luck or another contact.


From denizlist at denizeren.net  Thu Oct 13 07:53:27 2016
From: denizlist at denizeren.net (Deniz Eren)
Date: Thu, 13 Oct 2016 10:53:27 +0300
Subject: [squid-users] Squid SMP workers crash
Message-ID: <CAHQdsZ805myhBd8_s-1dxvp1eZSv_bhykGj9gwm=_6=WMK8Tew@mail.gmail.com>

Hi,

I'm using squid's SMP functionality to distribute requests to many
squid instances and distribute workload to multiple processors.
However while running squid's workers after a while worker processes
crash with the error below and coordinator does not start them again:
...
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-cf__metadata.shm): (2) No such file or directory
Squid Cache (Version 3.5.20): Terminated abnormally.
...

Does a solution exists for this problem? (permissions are OK in /dev/shm)


When everything is OK coordinator listens to http_ports/https_port and
distributes connections to workers(at least that's the conclusion I
got from looking access.logs).
[root at squidbox ~]# netstat -nlp|grep squid
tcp        0      0 0.0.0.0:8080                0.0.0.0:*
     LISTEN      7887/(squid-coord-1
tcp        0      0 0.0.0.0:3127                0.0.0.0:*
     LISTEN      7887/(squid-coord-1
tcp        0      0 0.0.0.0:3128                0.0.0.0:*
     LISTEN      7887/(squid-coord-1
tcp        0      0 0.0.0.0:3130                0.0.0.0:*
     LISTEN      7887/(squid-coord-1
tcp        0      0 0.0.0.0:8443                0.0.0.0:*
     LISTEN      7887/(squid-coord-1
udp        0      0 0.0.0.0:57850               0.0.0.0:*
                 7897/(squid-1)
udp        0      0 0.0.0.0:33643               0.0.0.0:*
                 7894/(squid-4)
udp        0      0 0.0.0.0:50485               0.0.0.0:*
                 7896/(squid-2)
udp        0      0 0.0.0.0:46427               0.0.0.0:*
                 7887/(squid-coord-1
udp        0      0 0.0.0.0:58938               0.0.0.0:*
                 7895/(squid-3)


Also is my way of using SMP functionality correct, since I want to
distribute all connections between workers and to listen only specific
ports?

I have attached the squid.conf.

Regards,
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid.conf
Type: application/octet-stream
Size: 4691 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161013/eec9d4aa/attachment.obj>

From eliezer at ngtech.co.il  Thu Oct 13 11:10:00 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 13 Oct 2016 11:10:00 +0000
Subject: [squid-users] Getting latest 3.5 version into Debian
In-Reply-To: <EAC18DDF-30CA-4FA9-92F4-84DFF5BA17DB@yahoo.com>
References: <EAC18DDF-30CA-4FA9-92F4-84DFF5BA17DB@yahoo.com>
Message-ID: <5cc3e6461f5835f5c47c00bd7ddd30e5@ngtech.co.il>

Hey,

I will try to provide a drop-in-place binaries for Debian and Ubuntu in the next weeks.
This is to overcome some of the complications of contacting the packagers.

Eliezer
----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il
On Thu, Oct 13, 2016 at 08:21 AM, Mark James  wrote:
Hi Amos,

Not sure if the Debian maintainers get included in the announcements or not. Do you have any contact with them? I have emailed Luigi previously to see if they could update Sid/Stretch as it's still on 3.5.19. Maybe you would have better luck or another contact.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org (mailto:squid-users at lists.squid-cache.org)
http://lists.squid-cache.org/listinfo/squid-users (http://lists.squid-cache.org/listinfo/squid-users)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161013/90891406/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 29577 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161013/90891406/attachment.png>

From eliezer at ngtech.co.il  Thu Oct 13 11:15:05 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 13 Oct 2016 11:15:05 +0000
Subject: [squid-users] peek-and-splice on Centos7 and squid4
In-Reply-To: <1569903703.307394.28a72b84-a091-48c4-83f9-74a8bbde1a18.open-xchange@email.1und1.de>
References: <1569903703.307394.28a72b84-a091-48c4-83f9-74a8bbde1a18.open-xchange@email.1und1.de>
Message-ID: <d5e33096c36feee40d68a66207f06fd2@ngtech.co.il>

May I ask if you are Intercepting the connections or in your setup you define/configure in the browserclient the proxy settings?

Eliezer
----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il
On Tue, Oct 11, 2016 at 08:10 PM, - -  wrote:
Dear all,

currently I try to configure peek-and-splice on Centos7 and squid4. I have a
running config for Centos6.6 and squid 3.5.18.

No matter what I try i can't get squid4 to splice certain sites and to
bump/terminate the rest. My config is as follows:

acl sni_exclusions ssl::server_name .google.com
acl sni_exclusions ssl::server_name .google.de

acl tcp_level at_step SslBump1
acl client_hello_peeked at_step SslBump2
ssl_bump peek tcp_level all
ssl_bump splice client_hello_peeked sni_exclusions
ssl_bump bump all

if I replace the ssl_bump bump all with ssl_bump terminate all, all sites are
terminated, if I do a ssl_bump splice all, all https traffic is going through.

the log when a device connects to an allowed site looks is below, if I accept
the self generated certificate access the webpage is allowed. If i do the same
with a site not allowed i'll get redirected to the deny_info page after
accepting the certificate. So everything working as desired besides the
certificate warning for "spliced" websites. I'm using the squid4 build from
http://wiki.squid-cache.org/KnowledgeBase/CentOS#Squid_Beta_release (http://wiki.squid-cache.org/KnowledgeBase/CentOS#Squid_Beta_release).

Thanks in advance for any hint,
Alex

squid version:
squid -v
Squid Cache: Version 4.0.12
Service Name: squid
configure options:  '--build=x86_64-redhat-linux-gnu'
'--host=x86_64-redhat-linux-gnu' '--program-prefix=' '--prefix=/usr'
'--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin'
'--sysconfdir=/etc' '--datadir=/usr/share' '--includedir=/usr/include'
'--libdir=/usr/lib64' '--libexecdir=/usr/libexec' '--sharedstatedir=/var/lib'
'--mandir=/usr/share/man' '--infodir=/usr/share/info' '--exec_prefix=/usr'
'--libexecdir=/usr/lib64/squid' '--localstatedir=/var'
'--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
'--with-logdir=$(localstatedir)/log/squid'
'--with-pidfile=$(localstatedir)/run/squid.pid' '--disable-dependency-tracking'
'--enable-follow-x-forwarded-for' '--enable-auth'
'--enable-auth-basic=DB,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB,getpwnam,fake'
'--enable-auth-ntlm=fake' '--enable-auth-digest=file,LDAP,eDirectory'
'--enable-auth-negotiate=kerberos,wrapper'
'--enable-external-acl-helpers=wbinfo_group,kerberos_ldap_group,LDAP_group,delayer,file_userip,SQL_session,unix_group,session,time_quota'
'--enable-cache-digests' '--enable-cachemgr-hostname=localhost'
'--enable-delay-pools' '--enable-epoll' '--enable-icap-client'
'--enable-ident-lookups' '--enable-linux-netfilter'
'--enable-removal-policies=heap,lru' '--enable-snmp'
'--enable-storeio=aufs,diskd,ufs,rock' '--enable-wccpv2' '--enable-esi'
'--enable-security-cert-generators' '--enable-security-cert-validators'
'--enable-icmp' '--with-aio' '--with-default-user=squid'
'--with-filedescriptors=16384' '--with-dl' '--with-openssl' '--with-pthreads'
'--with-included-ltdl' '--disable-arch-native' '--enable-ecap'
'--without-nettle' 'build_alias=x86_64-redhat-linux-gnu'
'host_alias=x86_64-redhat-linux-gnu' 'CFLAGS=-O2 -g -pipe -Wall
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector-strong
--param=ssp-buffer-size=4 -grecord-gcc-switches   -m64 -mtune=generic'
'LDFLAGS=-Wl,-z,relro ' 'CXXFLAGS=-O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2
-fexceptions -fstack-protector-strong --param=ssp-buffer-size=4
-grecord-gcc-switches   -m64 -mtune=generic -fPIC'
'PKG_CONFIG_PATH=:/usr/lib64/pkgconfig:/usr/share/pkgconfig'
--enable-ltdl-convenience

cache.log:
2016/10/11 16:54:57.126 kid1| 33,5| client_side.cc(1367) parseHttpRequest:
Prepare absolute URL from intercept
2016/10/11 16:54:57.126 kid1| 33,5| client_side.cc(2150) clientParseRequests:
local=216.58.211.3:443 remote=10.248.0.8:59837 FD 25 flags=33: done parsing a
request
2016/10/11 16:54:57.126 kid1| 33,3| Pipeline.cc(24) add: Pipeline 0x2b008e0 add
request 1 0x2b06280*3
2016/10/11 16:54:57.126 kid1| 33,5| Http1Server.cc(181) buildHttpRequest:
normalize 1 Host header using 216.58.211.3:443
2016/10/11 16:54:57.126 kid1| 33,3| client_side.cc(643) clientSetKeepaliveFlag:
http_ver = HTTP/1.1
2016/10/11 16:54:57.126 kid1| 33,3| client_side.cc(644) clientSetKeepaliveFlag:
method = CONNECT
2016/10/11 16:54:57.126 kid1| 33,3| http/Stream.h(139) mayUseConnection: This
0x2b06280 marked 1
2016/10/11 16:54:57.127 kid1| 33,3| client_side.cc(2163) clientParseRequests:
Not parsing new requests, as this request may need the connection
2016/10/11 16:54:57.127 kid1| 33,5| client_side.cc(3113) switchToHttps:
converting local=216.58.211.3:443 remote=10.248.0.8:59837 FD 25 flags=33 to SSL
2016/10/11 16:54:57.127 kid1| 33,4| ServerBump.cc(27) ServerBump: will peek at
216.58.211.3:443
2016/10/11 16:54:57.127 kid1| 33,5| AsyncCall.cc(26) AsyncCall: The AsyncCall
ConnStateData::requestTimeout constructed, this=0x2b00b70 [call688]
2016/10/11 16:54:57.127 kid1| 33,4| Server.cc(90) readSomeData:
local=216.58.211.3:443 remote=10.248.0.8:59837 FD 25 flags=33: reading
request...
2016/10/11 16:54:57.127 kid1| 33,5| AsyncCall.cc(26) AsyncCall: The AsyncCall
Server::doClientRead constructed, this=0x2b00c00 [call689]
2016/10/11 16:54:57.131 kid1| 33,5| AsyncCall.cc(93) ScheduleCall:
IoCallback.cc(135) will call Server::doClientRead(local=216.58.211.3:443
remote=10.248.0.8:59837 FD 25 flags=33, data=0x2b00898) [call689]
2016/10/11 16:54:57.131 kid1| 33,5| AsyncCallQueue.cc(55) fireNext: entering
Server::doClientRead(local=216.58.211.3:443 remote=10.248.0.8:59837 FD 25
flags=33, data=0x2b00898)
2016/10/11 16:54:57.131 kid1| 33,5| AsyncCall.cc(38) make: make call
Server::doClientRead [call689]
2016/10/11 16:54:57.131 kid1| 33,5| AsyncJob.cc(123) callStart: Http1::Server
status in: [ job31]
2016/10/11 16:54:57.131 kid1| 33,5| Server.cc(104) doClientRead:
local=216.58.211.3:443 remote=10.248.0.8:59837 FD 25 flags=33
2016/10/11 16:54:57.131 kid1| 33,5| AsyncCall.cc(26) AsyncCall: The AsyncCall
ConnStateData::requestTimeout constructed, this=0x2b04940 [call690]
2016/10/11 16:54:57.131 kid1| 33,3| Pipeline.cc(35) front: Pipeline 0x2b008e0
front 0x2b06280*2
2016/10/11 16:54:57.131 kid1| 33,5| client_side.cc(3232)
httpsSslBumpStep2AccessCheckDone: Answer: ALLOWED kind:5
2016/10/11 16:54:57.131 kid1| 33,3| Pipeline.cc(35) front: Pipeline 0x2b008e0
front 0x2b06280*3
2016/10/11 16:54:57.132 kid1| 33,5| client_side.cc(2577) httpsCreate: will
negotate SSL on local=216.58.211.3:443 remote=10.248.0.8:59837 FD 25 flags=33
2016/10/11 16:54:57.132 kid1| 33,5| AsyncJob.cc(153) callEnd: Http1::Server
status out: [ job31]
2016/10/11 16:54:57.132 kid1| 33,5| AsyncCallQueue.cc(57) fireNext: leaving
Server::doClientRead(local=216.58.211.3:443 remote=10.248.0.8:59837 FD 25
flags=33, data=0x2b00898)
2016/10/11 16:54:57.182 kid1| 33,3| client_side.cc(4000) unpinConnection:
2016/10/11 16:54:57.182 kid1| 33,3| client_side.cc(3833) pinNewConnection:
local=10.4.38.62:26120 remote=216.58.211.3:443 FD 26 flags=1
2016/10/11 16:54:57.182 kid1| 33,5| AsyncCall.cc(26) AsyncCall: The AsyncCall
ConnStateData::clientPinnedConnectionClosed constructed, this=0x2b3e750
[call704]
2016/10/11 16:54:57.182 kid1| 33,3| AsyncCall.cc(26) AsyncCall: The AsyncCall
ConnStateData::clientPinnedConnectionRead constructed, this=0x2b262b0 [call705]
2016/10/11 16:54:57.182 kid1| 33,5| client_side.cc(3361) httpsPeeked: bumped
HTTPS server: 216.58.211.3
2016/10/11 16:54:57.182 kid1| 33,3| Pipeline.cc(44) terminateAll: Pipeline
0x2b008e0 notify(0) 0x2b06280*3
2016/10/11 16:54:57.182 kid1| 33,3| Pipeline.cc(57) popMe: Pipeline 0x2b008e0
drop 0x2b06280*3
2016/10/11 16:54:57.183 kid1| 33,3| client_side_request.cc(270)
~ClientHttpRequest: httpRequestFree: 216.58.211.3:443
2016/10/11 16:54:57.183 kid1| 33,5| client_side.cc(383) logRequest: logging
half-baked transaction: 216.58.211.3:443
2016/10/11 16:54:57.183 kid1| 33,9| client_side.cc(387) logRequest:
clientLogRequest: al.url='216.58.211.3:443'
2016/10/11 16:54:57.183 kid1| 33,9| client_side.cc(397) logRequest:
clientLogRequest: http.code='200'
2016/10/11 16:54:57.183 kid1| 33,5| client_side.cc(3027) getSslContextStart:
Generating SSL certificate for www.google.de (http://www.google.de)
2016/10/11 16:54:57.183 kid1| 33,5| client_side.cc(3346) doPeekAndSpliceStep:
PeekAndSplice mode, proceed with client negotiation. Currrent state:SSLv2/v3
read client hello A
2016/10/11 16:54:57.183 kid1| Error negotiating SSL connection on FD 25:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
2016/10/11 16:54:57.209 kid1| 33,5| AsyncCall.cc(93) ScheduleCall: comm.cc(736)
will call ConnStateData::connStateClosed(FD -1, data=0x2b00898) [call685]
2016/10/11 16:54:57.209 kid1| 33,5| AsyncCallQueue.cc(55) fireNext: entering
ConnStateData::connStateClosed(FD -1, data=0x2b00898)
2016/10/11 16:54:57.209 kid1| 33,5| AsyncCall.cc(38) make: make call
ConnStateData::connStateClosed [call685]
2016/10/11 16:54:57.209 kid1| 33,5| AsyncJob.cc(123) callStart: Http1::Server
status in: [ job31]
2016/10/11 16:54:57.209 kid1| 33,2| client_side.cc(586) swanSong:
local=216.58.211.3:443 remote=10.248.0.8:59837 flags=33
2016/10/11 16:54:57.209 kid1| 33,3| client_side.cc(4000) unpinConnection:
local=10.4.38.62:26120 remote=216.58.211.3:443 FD 26 flags=1
2016/10/11 16:54:57.209 kid1| 33,5| AsyncCall.cc(56) cancel: will not call
ConnStateData::clientPinnedConnectionClosed [call704] because
comm_remove_close_handler
2016/10/11 16:54:57.209 kid1| 33,3| AsyncCall.cc(56) cancel: will not call
ConnStateData::clientPinnedConnectionRead [call705] because comm_read_cancel
2016/10/11 16:54:57.209 kid1| 33,3| AsyncCall.cc(56) cancel: will not call
ConnStateData::clientPinnedConnectionRead [call705] also because
comm_read_cancel
2016/10/11 16:54:57.209 kid1| 33,3| client_side.cc(614) ~ConnStateData:
local=216.58.211.3:443 remote=10.248.0.8:59837 flags=33
2016/10/11 16:54:57.209 kid1| 33,4| ServerBump.cc(46) ~ServerBump: destroying
2016/10/11 16:54:57.209 kid1| 33,4| ServerBump.cc(48) ~ServerBump:
e:=sp2XDIV/0x2b04270*1
2016/10/11 16:54:57.209 kid1| 33,5| AsyncCallQueue.cc(57) fireNext: leaving
ConnStateData::connStateClosed(FD -1, data=0x2b00898)
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org (mailto:squid-users at lists.squid-cache.org)
http://lists.squid-cache.org/listinfo/squid-users (http://lists.squid-cache.org/listinfo/squid-users)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161013/13caab68/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image.png
Type: image/png
Size: 29577 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161013/13caab68/attachment.png>

From squid3 at treenet.co.nz  Thu Oct 13 12:00:31 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 14 Oct 2016 01:00:31 +1300
Subject: [squid-users] Getting latest 3.5 version into Debian
In-Reply-To: <EAC18DDF-30CA-4FA9-92F4-84DFF5BA17DB@yahoo.com>
References: <EAC18DDF-30CA-4FA9-92F4-84DFF5BA17DB@yahoo.com>
Message-ID: <4bf07cfe-0633-29a2-139e-6e22e9965902@treenet.co.nz>

On 13/10/2016 6:20 p.m., Mark James wrote:
> Hi Amos,
> 
> Not sure if the Debian maintainers get included in the announcements or not. Do you have any contact with them? I have emailed Luigi previously to see if they could update Sid/Stretch as it's still on 3.5.19. Maybe you would have better luck or another contact.

I've done the necessary bits and uploaded .22 to the Debian repository
the other day. It's just waiting for Luigi to sign off on it and upload.

Amos



From yvoinov at gmail.com  Thu Oct 13 12:38:02 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 13 Oct 2016 18:38:02 +0600
Subject: [squid-users] TCP_MISS/304 question
Message-ID: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Hi gents.

I have very stupid question.

Look at this access.log entry:

1476236018.506     85 192.168.100.103 TCP_MISS/304 354 GET
https://www.gazeta.ru/nm2015/gzt/img/logo_footer.png -
HIER_DIRECT/81.19.72.2 -

I'm see this:

http://wiki.squid-cache.org/SquidFaq/SquidLogs#HTTP_status_codes

Code 304 references to RFC 2616. Ok, opens it:

https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html

and read:

"


      10.3.5 304 Not Modified

If the client has performed a conditional GET request and access is
allowed, but the document has not been modified, the server SHOULD
respond with this status code. The 304 response MUST NOT contain a
message-body, and thus is always terminated by the first empty line
after the header fields.

The response MUST include the following header fields:

      - Date, unless its omission is required by section 14.18.1

If a clockless origin server obeys these rules, and proxies and clients
add their own Date to any response received without one (as already
specified by [RFC 2068], section 14.19
<https://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.19>),
caches will operate correctly.

      - ETag and/or Content-Location, if the header would have been sent
        in a 200 response to the same request

      - Expires, Cache-Control, and/or Vary, if the field-value might
        differ from that sent in any previous response for the same
        variant

If the conditional GET used a strong cache validator (see section
13.3.3), the response SHOULD NOT include other entity-headers. Otherwise
(i.e., the conditional GET used a weak validator), the response MUST NOT
include other entity-headers; this prevents inconsistencies between
cached entity-bodies and updated headers.

If a 304 response indicates an entity not currently cached, then the
cache MUST disregard the response and repeat the request without the
conditional.

If a cache uses a received 304 response to update a cache entry, the
cache MUST update the entry to reflect any new field values given in the
response.

"

According to RFC 2616, it comes from client's browser cache, make
revalidation, discover content no changed and return 304 code.

So, it must means (exactly) CLIENT_HIT, right?

My question is:

*Why Squid register this as TCP_MISS/304 in access.log, when logically
expect TCP_CLIENT_HIT/304?*

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX/4ApAAoJENNXIZxhPexGUO8H/iSYKoMpk2nis3mWF/0Vg58y
2/3+lJaf71RspA8WQ23m4JgqhnmfXF8AlMr/wgvaOCMRTpNumKfL3zhnKd3s4tmq
wXvG562PVHhdBO9gnFK+75PYo1xMe5jdbAHMr+XRzv0ylnBE04rNV+tbpSrRTH2Z
BwZrlDi/Y5UmcPF9zrFIy/6umoeDBkKJHpAlmVwD0krWNmgn2ScquPIQZpoqOgtR
yNGMS7WCAhOF7HGQMaHPsW6RzqwKzWGs6L6pg6CbaE780suncHJqQkq+sY8NgB4k
jZmgH579NiH9f+aVwAjIE7IN+aOv/0XWnT3YfFgeFba03JWu8c5e/oHeFFzhKRE=
=uXt1
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161013/199b0bb1/attachment.key>

From squid3 at treenet.co.nz  Thu Oct 13 13:41:29 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 14 Oct 2016 02:41:29 +1300
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
Message-ID: <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>

On 14/10/2016 1:38 a.m., Yuri Voinov wrote:
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>  
> Hi gents.
> 
> I have very stupid question.
> 
> Look at this access.log entry:
> 
> 1476236018.506     85 192.168.100.103 TCP_MISS/304 354 GET
> https://www.gazeta.ru/nm2015/gzt/img/logo_footer.png -
> HIER_DIRECT/81.19.72.2 -
> 
> I'm see this:
> 
> http://wiki.squid-cache.org/SquidFaq/SquidLogs#HTTP_status_codes
> 
> Code 304 references to RFC 2616. Ok, opens it:
> 
> https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html
> 

The reference is outdated. Current requirements are defined in
<https://tools.ietf.org/html/rfc7232#section-4.1>

...
> 
> According to RFC 2616, it comes from client's browser cache, make
> revalidation, discover content no changed and return 304 code.
> 
> So, it must means (exactly) CLIENT_HIT, right?
> 

No. Squid does not receive transactions that would match the meaning of
the tags CLIENT_HIT.


> My question is:
> 
> *Why Squid register this as TCP_MISS/304 in access.log, when logically
> expect TCP_CLIENT_HIT/304?*

This is a MISS on the Squid cache. A 304 from the server delivered to
the client.

It might be a CLIENT_IMS_UNMODIFIED or CLIENT_INM_UNMODIFIED if Squid
had codes for those cases.

Amos



From yvoinov at gmail.com  Thu Oct 13 13:44:32 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 13 Oct 2016 19:44:32 +0600
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
Message-ID: <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


13.10.2016 19:41, Amos Jeffries ?????:
> On 14/10/2016 1:38 a.m., Yuri Voinov wrote:
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>> 
>> Hi gents.
>>
>> I have very stupid question.
>>
>> Look at this access.log entry:
>>
>> 1476236018.506     85 192.168.100.103 TCP_MISS/304 354 GET
>> https://www.gazeta.ru/nm2015/gzt/img/logo_footer.png -
>> HIER_DIRECT/81.19.72.2 -
>>
>> I'm see this:
>>
>> http://wiki.squid-cache.org/SquidFaq/SquidLogs#HTTP_status_codes
>>
>> Code 304 references to RFC 2616. Ok, opens it:
>>
>> https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html
>>
>
> The reference is outdated. Current requirements are defined in
> <https://tools.ietf.org/html/rfc7232#section-4.1>
>
> ...
>>
>> According to RFC 2616, it comes from client's browser cache, make
>> revalidation, discover content no changed and return 304 code.
>>
>> So, it must means (exactly) CLIENT_HIT, right?
>>
>
> No. Squid does not receive transactions that would match the meaning of
> the tags CLIENT_HIT.
Ok.
>
>
>
>> My question is:
>>
>> *Why Squid register this as TCP_MISS/304 in access.log, when logically
>> expect TCP_CLIENT_HIT/304?*
>
> This is a MISS on the Squid cache. A 304 from the server delivered to
> the client.
Ok, 304 delivered. But content - not, right? So, this is HIT - even not
Squid's hit, yes?
>
>
> It might be a CLIENT_IMS_UNMODIFIED or CLIENT_INM_UNMODIFIED if Squid
> had codes for those cases.
Ok, Squid has?
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX/4/AAAoJENNXIZxhPexGfaYIAMnhMWE2doVT7nsviIavXr8w
T2iOEI/2n1IBDyDYk6+IduuwuaRrt4JtAxTkeOap4Li9nEGtcxL2LNMzUs4fC6sc
4tZ489oI0oz7vR88rx/5jH9ylnXtfx91lERrT4X4KThIuFswp3u++d1yEV37ZjTF
3OnrO46PsveKAqO/qWJXRLh/Gp2X7ohFmNfDSwakFOugjbqDa4XLROf/iygHy08w
q0uLRJLzHDDRYJtTKuvWgY1t7uW/KcHLA31aeN8AYjm4hIFHfS055sFFtry1wczl
H0hFhoGR1cjnMK8KOrzb86pkqukOW68DLGgCJt726WaZUZwf+TAhEn7/q9PlFAY=
=zJff
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161013/5bdfc46b/attachment.key>

From yvoinov at gmail.com  Thu Oct 13 13:46:39 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 13 Oct 2016 19:46:39 +0600
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
Message-ID: <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


13.10.2016 19:44, Yuri Voinov ?????:
>
>
>
> 13.10.2016 19:41, Amos Jeffries ?????:
> > On 14/10/2016 1:38 a.m., Yuri Voinov wrote:
> >>
> >> -----BEGIN PGP SIGNED MESSAGE-----
> >> Hash: SHA256
> >>
> >> Hi gents.
> >>
> >> I have very stupid question.
> >>
> >> Look at this access.log entry:
> >>
> >> 1476236018.506     85 192.168.100.103 TCP_MISS/304 354 GET
> >> https://www.gazeta.ru/nm2015/gzt/img/logo_footer.png -
> >> HIER_DIRECT/81.19.72.2 -
> >>
> >> I'm see this:
> >>
> >> http://wiki.squid-cache.org/SquidFaq/SquidLogs#HTTP_status_codes
> >>
> >> Code 304 references to RFC 2616. Ok, opens it:
> >>
> >> https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html
> >>
>
> > The reference is outdated. Current requirements are defined in
> > <https://tools.ietf.org/html/rfc7232#section-4.1>
>
> > ...
> >>
> >> According to RFC 2616, it comes from client's browser cache, make
> >> revalidation, discover content no changed and return 304 code.
> >>
> >> So, it must means (exactly) CLIENT_HIT, right?
> >>
>
> > No. Squid does not receive transactions that would match the meaning of
> > the tags CLIENT_HIT.
> Ok.
>
>
>
> >> My question is:
> >>
> >> *Why Squid register this as TCP_MISS/304 in access.log, when logically
> >> expect TCP_CLIENT_HIT/304?*
>
> > This is a MISS on the Squid cache. A 304 from the server delivered to
> > the client.
> Ok, 304 delivered. But content - not, right? So, this is HIT - even not
> Squid's hit, yes?
In agreement with this (https://tools.ietf.org/html/rfc7232#page-18):

 Since the goal of a 304 response is to minimize information transfer
   when the recipient already has one or more cached representations, a
   sender SHOULD NOT generate representation metadata other than the
   above listed fields unless said metadata exists for the purpose of
   guiding cache updates (e.g., Last-Modified might be useful if the
   response does not have an ETag field).

   Requirements on a cache that receives a 304 response are defined in
   Section 4.3.4 of [RFC7234]
<https://tools.ietf.org/html/rfc7234#section-4.3.4>.  If the conditional
request originated
   with an outbound client, such as a user agent with its own cache
   sending a conditional GET to a shared proxy, then the proxy SHOULD
   forward the 304 response to that client.

   A 304 response cannot contain a message-body; it is always terminated
   by the first empty line after the header fields.


>
>
> > It might be a CLIENT_IMS_UNMODIFIED or CLIENT_INM_UNMODIFIED if Squid
> > had codes for those cases.
> Ok, Squid has?
>
>
> > Amos
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX/5A/AAoJENNXIZxhPexG3NYIAL9pmUn4uAUt2ce9aPu8q/kA
Yeyn5qoCzEhY4Z0bqLFWfyECcQVU1MrcAhhhuRkdPI9zrfVIbF4oa2En4r9jTrUb
nhACmAAq64cYjOIYA9VYzkmiaaPF/ZzSnw+nF9uAwwfUOYP+L0Clg+D4KoywcAqG
0XAOWSasxrc70kFxid17NSMs0/kIIxEek6qhMDbBFKedZoucygIPfgGRX8+cEBQV
8aRdU/M4+HfSNk9sRFcTGUdA44K54z8mOwUDn4axW44M3AOAkDVn1cctaVvYgCLl
NK4Umq0pc0AoF4YoxRRbuXxA6YOvN1CtIhbW8tcYH32Y4dzzcHRdFU9A6kxj8Bw=
=Aulv
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161013/d924efcd/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161013/d924efcd/attachment.key>

From squid3 at treenet.co.nz  Thu Oct 13 14:09:43 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 14 Oct 2016 03:09:43 +1300
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
Message-ID: <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>

On 14/10/2016 2:46 a.m., Yuri Voinov wrote:
> 
> 
> 
> 13.10.2016 19:44, Yuri Voinov ?????:
> 
> 
> 
>> 13.10.2016 19:41, Amos Jeffries ?????:
>>> On 14/10/2016 1:38 a.m., Yuri Voinov wrote:
>>>>
>>>> -----BEGIN PGP SIGNED MESSAGE-----
>>>> Hash: SHA256
>>>>
>>>> Hi gents.
>>>>
>>>> I have very stupid question.
>>>>
>>>> Look at this access.log entry:
>>>>
>>>> 1476236018.506     85 192.168.100.103 TCP_MISS/304 354 GET
>>>> https://www.gazeta.ru/nm2015/gzt/img/logo_footer.png -
>>>> HIER_DIRECT/81.19.72.2 -
>>>>
>>>> I'm see this:
>>>>
>>>> http://wiki.squid-cache.org/SquidFaq/SquidLogs#HTTP_status_codes
>>>>
>>>> Code 304 references to RFC 2616. Ok, opens it:
>>>>
>>>> https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html
>>>>
> 
>>> The reference is outdated. Current requirements are defined in
>>> <https://tools.ietf.org/html/rfc7232#section-4.1>
> 
>>> ...
>>>>
>>>> According to RFC 2616, it comes from client's browser cache, make
>>>> revalidation, discover content no changed and return 304 code.
>>>>
>>>> So, it must means (exactly) CLIENT_HIT, right?
>>>>
> 
>>> No. Squid does not receive transactions that would match the meaning of
>>> the tags CLIENT_HIT.
>> Ok.
> 
> 
> 
>>>> My question is:
>>>>
>>>> *Why Squid register this as TCP_MISS/304 in access.log, when logically
>>>> expect TCP_CLIENT_HIT/304?*
> 
>>> This is a MISS on the Squid cache. A 304 from the server delivered to
>>> the client.
>> Ok, 304 delivered. But content - not, right? So, this is HIT - even not
>> Squid's hit, yes?
> In agreement with this (https://tools.ietf.org/html/rfc7232#page-18):
> 

Unknown without seeing the client request headers.

There might be no content in Squid cache at the start, and due to 304
not providing a payload none at the end either.


> 
>>> It might be a CLIENT_IMS_UNMODIFIED or CLIENT_INM_UNMODIFIED if Squid
>>> had codes for those cases.
>> Ok, Squid has?

Squid has TCP_MISS tag, which is used for unknown situations where a
server was involved.

Amos


From squid3 at treenet.co.nz  Thu Oct 13 14:22:10 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 14 Oct 2016 03:22:10 +1300
Subject: [squid-users] ERROR: Cannot connect to 127.0.0.1:3128
In-Reply-To: <6306491476324921@web24g.yandex.ru>
References: <294681476158099@web11o.yandex.ru>
 <e663dbd7-b739-ecb9-3598-c649c2b97fcf@treenet.co.nz>
 <6306491476324921@web24g.yandex.ru>
Message-ID: <41207f59-32a5-0d29-1b62-95c5061ae21b@treenet.co.nz>

Please run this command:

  squidclient -vv mgr:info | head -n 40


Amos



From gergely at egervary.hu  Thu Oct 13 14:28:59 2016
From: gergely at egervary.hu (=?UTF-8?Q?Egerv=c3=a1ry_Gergely?=)
Date: Thu, 13 Oct 2016 16:28:59 +0200
Subject: [squid-users] IPv6 interception crash: Ip::Address::getInAddr :
 Cannot convert non-IPv4 to IPv4.
In-Reply-To: <07a63de4-356c-81d4-35ed-1842f106b632@treenet.co.nz>
References: <57F27572.8000600@egervary.hu>
 <ee0c2401-bccf-ad23-8611-af15f9d55906@treenet.co.nz>
 <343a7732-6077-49de-ad8f-5ecb2383f715@egervary.hu>
 <627e937e-7572-862c-fdcf-03e5146a1dea@treenet.co.nz>
 <3f33e001-5c69-ad83-3324-a8cc1565adc4@egervary.hu>
 <71545a1d-6879-cad8-f56e-4835df7f4043@treenet.co.nz>
 <57F37BED.9040502@egervary.hu>
 <d741eb47-c65a-e1a5-68b8-3466a5c08853@treenet.co.nz>
 <57F394D0.40300@egervary.hu> <57F39D96.1040407@egervary.hu>
 <07a63de4-356c-81d4-35ed-1842f106b632@treenet.co.nz>
Message-ID: <00f785ea-8b0e-1193-3f7d-a7acda41936b@egervary.hu>

> Thanks for the testing and feedback. I've applied this as part-2 of the
> bug 4302 updates. It will be in the next releases of 3.5 and 4.x.

One more patch for Intercept.cc:

On NetBSD, USE_INET6 is only defined by netinet/ip_compat.h if
__NetBSD_Version__ is defined by sys/param.h:

#if defined(__NetBSD_Version__) && (__NetBSD_Version__ >= 105000000) && \
     !defined(_KERNEL) && !defined(USE_INET6) && !defined(NOINET6)
# define        USE_INET6
#endif

So we have to include sys/param.h:


--- Intercept.cc        2016-10-13 16:24:31.000000000 +0200
+++ Intercept.cc.orig   2016-10-13 16:20:37.000000000 +0200
@@ -25,6 +25,9 @@
  #define IPFILTER_VERSION        5000004
  #endif

+#if HAVE_SYS_PARAM_H
+#include <sys/param.h>
+#endif
  #if HAVE_SYS_IOCCOM_H
  #include <sys/ioccom.h>
  #endif

Thank you!
-- 
Gergely EGERVARY



From r.gardner at midata.de  Thu Oct 13 14:33:14 2016
From: r.gardner at midata.de (Gardner Roger)
Date: Thu, 13 Oct 2016 14:33:14 +0000
Subject: [squid-users] Squid Umlauts
In-Reply-To: <20161007111238.ac52pfympgze2uxj@charite.de>
References: <D1B4D1D0E0AC2D418A16E227D23114689C833056@11859s0003.exchange11859.local>
 <20161007093710.dz5fejrgwkxgxpqm@charite.de>
 <D1B4D1D0E0AC2D418A16E227D23114689C8330A6@11859s0003.exchange11859.local>
 <20161007111238.ac52pfympgze2uxj@charite.de>
Message-ID: <D1B4D1D0E0AC2D418A16E227D23114689C83595E@11859s0003.exchange11859.local>

I keep finding that I should add, Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7
But I am not sure where this should go. I tried going to the site with the proxy it works fine. When I go the from home I get just the login page and it looks ok.
It just when I go over the proxy, squid. Instead of umlauts I get "?1/4" f?r "?". All the umlauts start with "?", then the part varies. I would like to give access, but I am not allowed.

I know the person who set this up, had to change nph-proxy.cgi settings. Maybe it is in there. Would a copy of that help?

Greetings 
Roger Gardner  

-----Urspr?ngliche Nachricht-----
Von: Ralf Hildebrandt [mailto:Ralf.Hildebrandt at charite.de] 
Gesendet: Freitag, 7. Oktober 2016 13:13
An: Gardner Roger <r.gardner at midata.de>
Betreff: Re: [squid-users] Squid Umlauts

* Gardner Roger <r.gardner at midata.de>:

>> In the URL or in the HTML code of the page itself?

>Both

>> Do you have an example? 

> A website I could look at? No, you can not access that site without 
> user and password and I can't give you one.
> 
> One person asked squid.conf, so here is a copy.

This looks really basic, nothing in there that would change contents.

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
http://www.charite.de              Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155
---------------------------------------------------------------------------
Diese Nachricht ist vertraulich und nur fuer die bezeichneten Empfaenger bestimmt. Wenn Sie nicht der vorgesehene Adressat dieser E-Mail oder dessen Vertreter sein sollten, so beachten Sie bitte, dass jede Form der Kenntnisnahme, Veroeffentlichung, Vervielfaeltigung oder Weitergabe des Inhalts dieser E-Mail unzulaessig ist. Wir bitten Sie, sich in diesem Fall mit dem Absender der E-Mail in Verbindung zu setzen. Wir weisen ausserdem darauf hin, dass E-Mails verloren gehen, veraendert oder verfaelscht werden koennen. Herkoemmliche E-Mails sind nicht gegen den Zugriff von Dritten geschuetzt und deshalb ist auch die Vertraulichkeit unter Umstaenden nicht gewahrt. Der Inhalt der E-Mail ist nur rechtsverbindlich, wenn er unsererseits durch einen Brief entsprechend bestaetigt wird. Sollte trotz der von uns verwendeten Virenschutz-Programme durch die Zusendung von E-Mails ein Virus in Ihre Systeme gelangen, so haften wir nicht fuer eventuell hieraus entstehende Schaeden.

The information transmitted is confidential and intended only for the person or entity to which it is addressed. If you are not the intended addressee of this e-mail or his representative, please be aware that any kind of review, publication, reproduction or retransmission of the content of this e-mail is prohibited. In this case your are requested to contact the sender of the e-mail. Furthermore, we point out that e-mails may get lost, be changed or falsified. Normal e-mails are not protected against access by third parties and consequently their confidentiality may not be assured in certain circumstances.
The content of this e-mail is only legally binding if it is confirmed by a letter from our side. Should any virus enter your systems in connection with this e-mail despite our use of antivirus software, we cannot be held liable for any possible damages.
---------------------------------------------------------------------------
Die Angaben nach ? 37a HGB finden sich unter dem folgenden Link: http://www.midata.de/37ahgb.htm

Information according to ? 37a HGB can be found under the following link: http://www.midata.de/37ahgb.htm
---------------------------------------------------------------------------

From yvoinov at gmail.com  Thu Oct 13 15:02:52 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 13 Oct 2016 21:02:52 +0600
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
Message-ID: <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


13.10.2016 20:09, Amos Jeffries ?????:
> On 14/10/2016 2:46 a.m., Yuri Voinov wrote:
>>
>>
>>
>> 13.10.2016 19:44, Yuri Voinov ?????:
>>
>>
>>
>>> 13.10.2016 19:41, Amos Jeffries ?????:
>>>> On 14/10/2016 1:38 a.m., Yuri Voinov wrote:
>>>>>
>>>>> -----BEGIN PGP SIGNED MESSAGE-----
>>>>> Hash: SHA256
>>>>>
>>>>> Hi gents.
>>>>>
>>>>> I have very stupid question.
>>>>>
>>>>> Look at this access.log entry:
>>>>>
>>>>> 1476236018.506     85 192.168.100.103 TCP_MISS/304 354 GET
>>>>> https://www.gazeta.ru/nm2015/gzt/img/logo_footer.png -
>>>>> HIER_DIRECT/81.19.72.2 -
>>>>>
>>>>> I'm see this:
>>>>>
>>>>> http://wiki.squid-cache.org/SquidFaq/SquidLogs#HTTP_status_codes
>>>>>
>>>>> Code 304 references to RFC 2616. Ok, opens it:
>>>>>
>>>>> https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html
>>>>>
>>
>>>> The reference is outdated. Current requirements are defined in
>>>> <https://tools.ietf.org/html/rfc7232#section-4.1>
>>
>>>> ...
>>>>>
>>>>> According to RFC 2616, it comes from client's browser cache, make
>>>>> revalidation, discover content no changed and return 304 code.
>>>>>
>>>>> So, it must means (exactly) CLIENT_HIT, right?
>>>>>
>>
>>>> No. Squid does not receive transactions that would match the meaning of
>>>> the tags CLIENT_HIT.
>>> Ok.
>>
>>
>>
>>>>> My question is:
>>>>>
>>>>> *Why Squid register this as TCP_MISS/304 in access.log, when logically
>>>>> expect TCP_CLIENT_HIT/304?*
>>
>>>> This is a MISS on the Squid cache. A 304 from the server delivered to
>>>> the client.
>>> Ok, 304 delivered. But content - not, right? So, this is HIT - even not
>>> Squid's hit, yes?
>> In agreement with this (https://tools.ietf.org/html/rfc7232#page-18):
>>
>
> Unknown without seeing the client request headers.
>
> There might be no content in Squid cache at the start, and due to 304
> not providing a payload none at the end either.
In given example I know exactly content already in client cache and
Squid's too. This record occurs due to web-page, contains auto-refresh
code/pragma. And does periodically refresh.

Well, is it possible to make this known? We're on proxy between client
and web-server. So, it can be easy - ?ode 304 is immediately after the
reload/refresh query by the same client.

It is not possible to pre-remember that it sent the client in the header
- or a request for an update - and create the correct tag? And not on
the principle of "We broke to determine that it is - so that we log this
as TCP_MISS."

It seems to me, such behavior would be more appropriate, and more than
would be consistent with RFC.

Right?
>
>
>
>>
>>>> It might be a CLIENT_IMS_UNMODIFIED or CLIENT_INM_UNMODIFIED if Squid
>>>> had codes for those cases.
>>> Ok, Squid has?
>
> Squid has TCP_MISS tag, which is used for unknown situations where a
> server was involved.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX/6IcAAoJENNXIZxhPexG+vcH/1nusCNTLM0QR9j8iun6dRnS
h/zD1bNMDJB4EfWr6ZAfUbocoRuYvsv6TRXOu9mTvO0fSTYBd6q3hc97y3en2ivY
Iw0yLuKb9pPxEF1UdjgGKgy9Ibyn4mdhoMZ7uRRDvZx6tvg0JcaF165Yw6osKC6L
0fZXO2fwklwHUC8eGl437yV/HVXv9TWX99VOcKZjtgLe1tpHq2JmJhYp3uv8DUXV
/HMKx0ByxGjZsgdJ9pcP2YMOdZKPA4K3jxJmSf1XuwQH/Mab5Arbx/5DhXUw/7On
+FtdReEc40IN/xwi6zxMERuU8XRlQbnFjCOH+KdVV8mPzS89xj13IL59GUux7+I=
=dEtK
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161013/d0cf5e7b/attachment.key>

From yvoinov at gmail.com  Thu Oct 13 15:09:31 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 13 Oct 2016 21:09:31 +0600
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
Message-ID: <8419e11d-ace0-0476-7194-f92fc1d68d16@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I do not pretend that I have seen everything.

But my personal statistics across multiple servers over they access.log
shows that TCP_MISS/304 in all cases associated with the update 
downloaded content (reload/refresh). Accordingly, the logging of this
event as a TCP_MISS seems incorrect and, consequently, leads to errors
in accounting/billing. That, in turn, can lead to a loss of money.

So, nice to have functionality for correct handling this cases.

13.10.2016 20:09, Amos Jeffries ?????:
> On 14/10/2016 2:46 a.m., Yuri Voinov wrote:
>>
>>
>>
>> 13.10.2016 19:44, Yuri Voinov ?????:
>>
>>
>>
>>> 13.10.2016 19:41, Amos Jeffries ?????:
>>>> On 14/10/2016 1:38 a.m., Yuri Voinov wrote:
>>>>>
>>>>> -----BEGIN PGP SIGNED MESSAGE-----
>>>>> Hash: SHA256
>>>>>
>>>>> Hi gents.
>>>>>
>>>>> I have very stupid question.
>>>>>
>>>>> Look at this access.log entry:
>>>>>
>>>>> 1476236018.506     85 192.168.100.103 TCP_MISS/304 354 GET
>>>>> https://www.gazeta.ru/nm2015/gzt/img/logo_footer.png -
>>>>> HIER_DIRECT/81.19.72.2 -
>>>>>
>>>>> I'm see this:
>>>>>
>>>>> http://wiki.squid-cache.org/SquidFaq/SquidLogs#HTTP_status_codes
>>>>>
>>>>> Code 304 references to RFC 2616. Ok, opens it:
>>>>>
>>>>> https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html
>>>>>
>>
>>>> The reference is outdated. Current requirements are defined in
>>>> <https://tools.ietf.org/html/rfc7232#section-4.1>
>>
>>>> ...
>>>>>
>>>>> According to RFC 2616, it comes from client's browser cache, make
>>>>> revalidation, discover content no changed and return 304 code.
>>>>>
>>>>> So, it must means (exactly) CLIENT_HIT, right?
>>>>>
>>
>>>> No. Squid does not receive transactions that would match the meaning of
>>>> the tags CLIENT_HIT.
>>> Ok.
>>
>>
>>
>>>>> My question is:
>>>>>
>>>>> *Why Squid register this as TCP_MISS/304 in access.log, when logically
>>>>> expect TCP_CLIENT_HIT/304?*
>>
>>>> This is a MISS on the Squid cache. A 304 from the server delivered to
>>>> the client.
>>> Ok, 304 delivered. But content - not, right? So, this is HIT - even not
>>> Squid's hit, yes?
>> In agreement with this (https://tools.ietf.org/html/rfc7232#page-18):
>>
>
> Unknown without seeing the client request headers.
>
> There might be no content in Squid cache at the start, and due to 304
> not providing a payload none at the end either.
>
>
>>
>>>> It might be a CLIENT_IMS_UNMODIFIED or CLIENT_INM_UNMODIFIED if Squid
>>>> had codes for those cases.
>>> Ok, Squid has?
>
> Squid has TCP_MISS tag, which is used for unknown situations where a
> server was involved.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX/6OrAAoJENNXIZxhPexG1BIH/jeTUBXJZJemwUN88SU4NCy9
uRDKWbMP0kLW9WEIZnDA3V6TOrIs1u2yLxHHxN4gBPa3vmVf4qSScTZGLRcwB40E
SrdbJnOh6pHFh1qKO4+MdvpmZnjaLW5xmPXbZg8w3kXc+lwUrF3B/LqdblRSytz0
rvrgpTzjPx+SH3gAZ2MD4h7/08rEahmyxrcf3yaf8CMmlBB2Sf2SwY8BWpVROAkG
aCM/XWLssCzmb0U3Mc3STT14p3X0rjgrSni7ISXSfsxpRCT6EkRPukCQmnhm+Q/6
eiUNAVqviVbs7xNPH1oGo3ANTKoDXVKT2tIvytPZ93hBQwg2BuDdVkEIgTEx3p8=
=5YOE
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161013/4977c39b/attachment.key>

From rousskov at measurement-factory.com  Thu Oct 13 17:13:18 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 13 Oct 2016 11:13:18 -0600
Subject: [squid-users] ssl::server_name never matches during step1
In-Reply-To: <c47183df-1150-9ccf-9bf5-1a1e597d5ddd@measurement-factory.com>
References: <1569903703.307394.28a72b84-a091-48c4-83f9-74a8bbde1a18.open-xchange@email.1und1.de>
 <c47183df-1150-9ccf-9bf5-1a1e597d5ddd@measurement-factory.com>
Message-ID: <dd4f38f5-7e5f-5995-5e6e-20dfbb7dc2a4@measurement-factory.com>

On 10/11/2016 11:36 AM, Alex Rousskov wrote:
> On 10/11/2016 11:09 AM, - - wrote:
>> No matter what I try i can't get squid4 to splice certain sites and to
>> bump/terminate the rest. My config is as follows:
>>
>> acl sni_exclusions ssl::server_name .google.com
>> acl sni_exclusions ssl::server_name .google.de
>>
>> acl tcp_level at_step SslBump1
>> acl client_hello_peeked at_step SslBump2
>> ssl_bump peek tcp_level all
>> ssl_bump splice client_hello_peeked sni_exclusions
>> ssl_bump bump all
>>
>> if I replace the ssl_bump bump all with ssl_bump terminate all, all sites are
>> terminated, if I do a ssl_bump splice all, all https traffic is going through.
> 
> Which implies that your splice rule never matches or the match is
> ignored for some reason.

AFAICT, ssl::server_name and ssl_server_name_regex are completely broken
in v4.0 as far as step1 (and equivalent) matches are concerned. Please
try the above trunk patch. It may need more work (and a v3.5
port/investigation) but it fixes the biggest/obvious problems in my tests.


Thank you,

Alex.



From yvoinov at gmail.com  Thu Oct 13 17:52:02 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 13 Oct 2016 23:52:02 +0600
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
 <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
Message-ID: <f659765b-b467-6d07-121e-7031a010d173@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


13.10.2016 21:02, Yuri Voinov ?????:
>
>
>
> 13.10.2016 20:09, Amos Jeffries ?????:
> > On 14/10/2016 2:46 a.m., Yuri Voinov wrote:
> >>
> >>
> >>
> >> 13.10.2016 19:44, Yuri Voinov ?????:
> >>
> >>
> >>
> >>> 13.10.2016 19:41, Amos Jeffries ?????:
> >>>> On 14/10/2016 1:38 a.m., Yuri Voinov wrote:
> >>>>>
> >>>>> -----BEGIN PGP SIGNED MESSAGE-----
> >>>>> Hash: SHA256
> >>>>>
> >>>>> Hi gents.
> >>>>>
> >>>>> I have very stupid question.
> >>>>>
> >>>>> Look at this access.log entry:
> >>>>>
> >>>>> 1476236018.506     85 192.168.100.103 TCP_MISS/304 354 GET
> >>>>> https://www.gazeta.ru/nm2015/gzt/img/logo_footer.png -
> >>>>> HIER_DIRECT/81.19.72.2 -
> >>>>>
> >>>>> I'm see this:
> >>>>>
> >>>>> http://wiki.squid-cache.org/SquidFaq/SquidLogs#HTTP_status_codes
> >>>>>
> >>>>> Code 304 references to RFC 2616. Ok, opens it:
> >>>>>
> >>>>> https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html
> >>>>>
> >>
> >>>> The reference is outdated. Current requirements are defined in
> >>>> <https://tools.ietf.org/html/rfc7232#section-4.1>
> >>
> >>>> ...
> >>>>>
> >>>>> According to RFC 2616, it comes from client's browser cache, make
> >>>>> revalidation, discover content no changed and return 304 code.
> >>>>>
> >>>>> So, it must means (exactly) CLIENT_HIT, right?
> >>>>>
> >>
> >>>> No. Squid does not receive transactions that would match the
meaning of
> >>>> the tags CLIENT_HIT.
> >>> Ok.
> >>
> >>
> >>
> >>>>> My question is:
> >>>>>
> >>>>> *Why Squid register this as TCP_MISS/304 in access.log, when
logically
> >>>>> expect TCP_CLIENT_HIT/304?*
> >>
> >>>> This is a MISS on the Squid cache. A 304 from the server delivered to
> >>>> the client.
> >>> Ok, 304 delivered. But content - not, right? So, this is HIT -
even not
> >>> Squid's hit, yes?
> >> In agreement with this (https://tools.ietf.org/html/rfc7232#page-18):
> >>
>
> > Unknown without seeing the client request headers.
A bit disagree.

When we seen TCP_MISS/200 with reply size above headers size - we can be
sure content tresspasses proxy first time and this is clean MISS.
When we seen ??????/304 with only headers - most probably content behind
proxy already and this is CLIENT_IMS_HIT observed.

Yes, of course, we don't know is this content really in client cache.
But this is don't care - proxy shared cache contains not modified copy
of content.

Right?
>
> > There might be no content in Squid cache at the start, and due to 304
> > not providing a payload none at the end either.
> In given example I know exactly content already in client cache and
> Squid's too. This record occurs due to web-page, contains auto-refresh
> code/pragma. And does periodically refresh.
>
> Well, is it possible to make this known? We're on proxy between client
> and web-server. So, it can be easy - ?ode 304 is immediately after the
> reload/refresh query by the same client.
>
> It is not possible to pre-remember that it sent the client in the header
> - or a request for an update - and create the correct tag? And not on
> the principle of "We broke to determine that it is - so that we log this
> as TCP_MISS."
>
> It seems to me, such behavior would be more appropriate, and more than
> would be consistent with RFC.
>
> Right?
>
>
>
> >>
> >>>> It might be a CLIENT_IMS_UNMODIFIED or CLIENT_INM_UNMODIFIED if Squid
> >>>> had codes for those cases.
> >>> Ok, Squid has?
>
> > Squid has TCP_MISS tag, which is used for unknown situations where a
> > server was involved.
>
> > Amos
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX/8nBAAoJENNXIZxhPexG6O4H/RSPqYtUJc/c13sENtup86gH
5tg3n1QeU5xLOF0k+osexcvAwf/McuFux4aVN92yJw6F2A3PvQSksdDSo0PVNNZZ
tHQAotiqdxf2NvwU+ZTP91UxYpl8UhNBtWYanWLsrH4taTPznKYmvCQ/TNwTWFqB
R9Wa8KTN1OqX7AK3uRYiCdhzjO/+wwg9p+1RA+YaVNJGBuA/Gp2ANXkeZsgZK4Nn
pDfmGP/Jg2TmaRgnPe8U4bZnkYzLcoOaIy/ytM8ePxJiVlHyEBMohjrfZUN6/Nez
9GwwA3mRl5MH8DsDz8Ro/7D5DHirnVzfWdGBMFzk12kL/SF7uR/XjvRyohAqtps=
=mIPv
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161013/b6604844/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161013/b6604844/attachment.key>

From rousskov at measurement-factory.com  Thu Oct 13 18:28:46 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 13 Oct 2016 12:28:46 -0600
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <f659765b-b467-6d07-121e-7031a010d173@gmail.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
 <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
 <f659765b-b467-6d07-121e-7031a010d173@gmail.com>
Message-ID: <24b8aec3-527d-0e96-2b21-439d9535f3ab@measurement-factory.com>

On 10/13/2016 11:52 AM, Yuri Voinov wrote:
> When we seen ??????/304 with only headers - most probably content behind
> proxy already and this is CLIENT_IMS_HIT observed.
> 
> Yes, of course, we don't know is this content really in client cache.
> But this is don't care - proxy shared cache contains not modified copy
> of content.
> 
> Right?

Wrong.

A 304 code sent by Squid to the client means "Squid told the client that
the client has a fresh copy (or equivalent)". It does not tell us how
Squid came up with that answer, or what Squid has in its cache: We do
not know whether Squid had the corresponding entry cached when the
client request came. If Squid had that entry cached, then Squid may or
may not have tried to validate it. If Squid tried to validate, then
Squid may or may not have gotten an entry from the origin server.
Finally, we do not know whether Squid kept, replaced, or deleted the
cache entry as the result of that validation attempt.

For an extreme example, consider Squid without a cache. Such a
configuration will still have lots of /304 entries in access.log!

A single access.log line (and often even a single Squid result code on
that line!) is telling us what happened when Squid talked to the client
_and_ what happened when Squid talked to the server (if it did talk to
the server). One cannot gain that vital information from a single HTTP
status code alone.


Many folks disagree regarding the best way to structure Squid result
codes. Many also disagree regarding the best definition for "cache hit".
All the different approaches make it very difficult to discuss these
matters and maintain related code. A /304 field alone means the client
got an HTTP 304 response. Whether you call that a "hit" from Squid point
of view depends on your definition of "hit" _and_ (depending on that
definition) on other factors that /304 does not reveal. For example:

* if your definition of a "hit" is "Squid did not talk to the origin
server or peer", then /304 alone does not necessarily mean a hit.

* if your definition of a "hit" is "Squid did not receive a large
response from the origin server or peer", then /304 alone does not
necessarily mean a hit.


HTH,

Alex.



From yvoinov at gmail.com  Thu Oct 13 18:46:30 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 14 Oct 2016 00:46:30 +0600
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <24b8aec3-527d-0e96-2b21-439d9535f3ab@measurement-factory.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
 <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
 <f659765b-b467-6d07-121e-7031a010d173@gmail.com>
 <24b8aec3-527d-0e96-2b21-439d9535f3ab@measurement-factory.com>
Message-ID: <e4276384-8dbb-8cae-3c66-d01b352bd7b8@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 

14.10.2016 0:28, Alex Rousskov ?????:
> On 10/13/2016 11:52 AM, Yuri Voinov wrote:
>> When we seen ??????/304 with only headers - most probably content behind
>> proxy already and this is CLIENT_IMS_HIT observed.
>>
>> Yes, of course, we don't know is this content really in client cache.
>> But this is don't care - proxy shared cache contains not modified copy
>> of content.
>>
>> Right?
>
> Wrong.
>
> A 304 code sent by Squid to the client means "Squid told the client that
> the client has a fresh copy (or equivalent)". It does not tell us how
> Squid came up with that answer, or what Squid has in its cache: We do
> not know whether Squid had the corresponding entry cached when the
> client request came. If Squid had that entry cached, then Squid may or
> may not have tried to validate it. If Squid tried to validate, then
> Squid may or may not have gotten an entry from the origin server.
> Finally, we do not know whether Squid kept, replaced, or deleted the
> cache entry as the result of that validation attempt.
>
> For an extreme example, consider Squid without a cache. Such a
> configuration will still have lots of /304 entries in access.log!
>
> A single access.log line (and often even a single Squid result code on
> that line!) is telling us what happened when Squid talked to the client
> _and_ what happened when Squid talked to the server (if it did talk to
> the server). One cannot gain that vital information from a single HTTP
> status code alone.
>
>
> Many folks disagree regarding the best way to structure Squid result
> codes. Many also disagree regarding the best definition for "cache hit".
> All the different approaches make it very difficult to discuss these
> matters and maintain related code. A /304 field alone means the client
> got an HTTP 304 response. Whether you call that a "hit" from Squid point
> of view depends on your definition of "hit" _and_ (depending on that
> definition) on other factors that /304 does not reveal. For example:
>
> * if your definition of a "hit" is "Squid did not talk to the origin
> server or peer", then /304 alone does not necessarily mean a hit.
But most probably, right?
>
>
> * if your definition of a "hit" is "Squid did not receive a large
> response from the origin server or peer", then /304 alone does not
> necessarily mean a hit.
But still most probably, yes?

Alone - agreed, Alex. But we've can see all transaction, right?

So, if we've already done request to the same URL in the past, got
TCP_MISS, then get again, _and_ has saved copy in cache, _and_ we're got
304 - this is hit. For shared cache itself.

We're not consider cases of HTTP violations - we're respect RFC.  :)

But: If something behaves like a hit, it looks like a hit and quacks
like a hit - it hit. :)
>
>
>
> HTH,
>
> Alex.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX/9aGAAoJENNXIZxhPexGBOMH/iz2NXmTfcVrCMq0Do2sOz2M
ndhc1Pi60HoLYle9zgKfBA4qS5ozHuUyVN96IYcCtu0y/2+IxhnAoliSUTveQTjm
06tXcQtq+6fsEJNmLsF/cMPO3cFGlp8zbjup1P94S8yNyKbsjXGgyWyCIlOtEqT4
uaMRG2dDCx2XzdvLOpW92XSKn6jeF8dYMhLSQy3offbkPoabqQXTyNo+vvZCR4gE
jhtGhLMCFW4/GD1RoDPdI0Gf+4sKdMtOlP5KrS4BCebQ+HQeCKGTnbpbr46wEVWy
PbF1dCnl9REH6Q/sNCXmRwxImFr89Go8VWvzugigGktlRsMM01VFEEIqjzlCQuw=
=47G3
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161014/3a7723d5/attachment.key>

From rousskov at measurement-factory.com  Thu Oct 13 19:28:40 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 13 Oct 2016 13:28:40 -0600
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <e4276384-8dbb-8cae-3c66-d01b352bd7b8@gmail.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
 <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
 <f659765b-b467-6d07-121e-7031a010d173@gmail.com>
 <24b8aec3-527d-0e96-2b21-439d9535f3ab@measurement-factory.com>
 <e4276384-8dbb-8cae-3c66-d01b352bd7b8@gmail.com>
Message-ID: <bad2a73a-cbe4-f616-8928-c4c666a54c86@measurement-factory.com>

On 10/13/2016 12:46 PM, Yuri Voinov wrote:
> 
> 
> 14.10.2016 0:28, Alex Rousskov ?????:
>> On 10/13/2016 11:52 AM, Yuri Voinov wrote:
>>> When we seen ??????/304 with only headers - most probably content behind
>>> proxy already and this is CLIENT_IMS_HIT observed.

>> A 304 code sent by Squid to the client means "Squid told the client that
>> the client has a fresh copy (or equivalent)". It does not tell us how
>> Squid came up with that answer, or what Squid has in its cache: We do
>> not know whether Squid had the corresponding entry cached when the
>> client request came. If Squid had that entry cached, then Squid may or
>> may not have tried to validate it. If Squid tried to validate, then
>> Squid may or may not have gotten an entry from the origin server.
>> Finally, we do not know whether Squid kept, replaced, or deleted the
>> cache entry as the result of that validation attempt.
> 
>> For an extreme example, consider Squid without a cache. Such a
>> configuration will still have lots of /304 entries in access.log!
> 
>> A single access.log line (and often even a single Squid result code on
>> that line!) is telling us what happened when Squid talked to the client
>> _and_ what happened when Squid talked to the server (if it did talk to
>> the server). One cannot gain that vital information from a single HTTP
>> status code alone.
> 
> 
>> Many folks disagree regarding the best way to structure Squid result
>> codes. Many also disagree regarding the best definition for "cache hit".
>> All the different approaches make it very difficult to discuss these
>> matters and maintain related code. A /304 field alone means the client
>> got an HTTP 304 response. Whether you call that a "hit" from Squid point
>> of view depends on your definition of "hit" _and_ (depending on that
>> definition) on other factors that /304 does not reveal. For example:
> 
>> * if your definition of a "hit" is "Squid did not talk to the origin
>> server or peer", then /304 alone does not necessarily mean a hit.
> But most probably, right?

The probability is determined by the environment. I have already given
you a simple example where _all_ /304s mean that Squid talked to the
origin server. In that environment, the probability is 0. There are lots
of environments. I do not know what is "most probable" in yours.



>> * if your definition of a "hit" is "Squid did not receive a large
>> response from the origin server or peer", then /304 alone does not
>> necessarily mean a hit.
> But still most probably, yes?

Same answer. I have seen environments where this probability will be
close to zero for this definition of a "hit".


> Alone - agreed, Alex. But we've can see all transaction, right?

Sure, but your original question was about /304 alone and you have
resisted Amos' attempts to get more transaction information (AFAICT).


> So, if we've already done request to the same URL in the past, got
> TCP_MISS, then get again, _and_ has saved copy in cache, _and_ we're got
> 304 - this is hit. For shared cache itself.

Depends on your definition of a hit. And even if Squid cached Xv2 during
the previous transaction, does not mean Squid did not revalidate Xv2
during the last transaction, did not receive Xv3 from a peer, and the
client does not already have and is revalidating Xv4. Yes, there are
certainly lots of cases where what you think is happening is actually
happening, but there are other cases as well.


> But: If something behaves like a hit, it looks like a hit and quacks
> like a hit - it hit. :)

Unfortunately, there are too many definitions of a "hit".

Alex.


From yvoinov at gmail.com  Thu Oct 13 19:44:30 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 14 Oct 2016 01:44:30 +0600
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <bad2a73a-cbe4-f616-8928-c4c666a54c86@measurement-factory.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
 <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
 <f659765b-b467-6d07-121e-7031a010d173@gmail.com>
 <24b8aec3-527d-0e96-2b21-439d9535f3ab@measurement-factory.com>
 <e4276384-8dbb-8cae-3c66-d01b352bd7b8@gmail.com>
 <bad2a73a-cbe4-f616-8928-c4c666a54c86@measurement-factory.com>
Message-ID: <0a96829a-d9f5-6d41-efda-931814b96b1f@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


14.10.2016 1:28, Alex Rousskov ?????:
> On 10/13/2016 12:46 PM, Yuri Voinov wrote:
>>
>>
>> 14.10.2016 0:28, Alex Rousskov ?????:
>>> On 10/13/2016 11:52 AM, Yuri Voinov wrote:
>>>> When we seen ??????/304 with only headers - most probably content
behind
>>>> proxy already and this is CLIENT_IMS_HIT observed.
>
>>> A 304 code sent by Squid to the client means "Squid told the client that
>>> the client has a fresh copy (or equivalent)". It does not tell us how
>>> Squid came up with that answer, or what Squid has in its cache: We do
>>> not know whether Squid had the corresponding entry cached when the
>>> client request came. If Squid had that entry cached, then Squid may or
>>> may not have tried to validate it. If Squid tried to validate, then
>>> Squid may or may not have gotten an entry from the origin server.
>>> Finally, we do not know whether Squid kept, replaced, or deleted the
>>> cache entry as the result of that validation attempt.
>>
>>> For an extreme example, consider Squid without a cache. Such a
>>> configuration will still have lots of /304 entries in access.log!
>>
>>> A single access.log line (and often even a single Squid result code on
>>> that line!) is telling us what happened when Squid talked to the client
>>> _and_ what happened when Squid talked to the server (if it did talk to
>>> the server). One cannot gain that vital information from a single HTTP
>>> status code alone.
>>
>>
>>> Many folks disagree regarding the best way to structure Squid result
>>> codes. Many also disagree regarding the best definition for "cache hit".
>>> All the different approaches make it very difficult to discuss these
>>> matters and maintain related code. A /304 field alone means the client
>>> got an HTTP 304 response. Whether you call that a "hit" from Squid point
>>> of view depends on your definition of "hit" _and_ (depending on that
>>> definition) on other factors that /304 does not reveal. For example:
>>
>>> * if your definition of a "hit" is "Squid did not talk to the origin
>>> server or peer", then /304 alone does not necessarily mean a hit.
>> But most probably, right?
>
> The probability is determined by the environment. I have already given
> you a simple example where _all_ /304s mean that Squid talked to the
> origin server. In that environment, the probability is 0. There are lots
> of environments. I do not know what is "most probable" in yours.
>
>
>
>>> * if your definition of a "hit" is "Squid did not receive a large
>>> response from the origin server or peer", then /304 alone does not
>>> necessarily mean a hit.
>> But still most probably, yes?
>
> Same answer. I have seen environments where this probability will be
> close to zero for this definition of a "hit".
>
>
>> Alone - agreed, Alex. But we've can see all transaction, right?
>
> Sure, but your original question was about /304 alone and you have
> resisted Amos' attempts to get more transaction information (AFAICT).
Mea culpa. I thought it obvious that, once I show an entry from the log,
I have entire log and, of course, that this is only part of the
transaction, which sees the whole entire proxy.

However, this is nothing more than word games, Alex. The question is -
can we more or less significant differences from known what hit proxy
code level and / or transactions which, obviously, on the proxy level,
we can see in its entirety.
>
>
>
>> So, if we've already done request to the same URL in the past, got
>> TCP_MISS, then get again, _and_ has saved copy in cache, _and_ we're got
>> 304 - this is hit. For shared cache itself.
>
> Depends on your definition of a hit. And even if Squid cached Xv2 during
> the previous transaction, does not mean Squid did not revalidate Xv2
> during the last transaction, did not receive Xv3 from a peer, and the
> client does not already have and is revalidating Xv4. Yes, there are
> certainly lots of cases where what you think is happening is actually
> happening, but there are other cases as well.
>
>
>> But: If something behaves like a hit, it looks like a hit and quacks
>> like a hit - it hit. :)
>
> Unfortunately, there are too many definitions of a "hit".
There is no many definitions of hit. We are talking about the caching
proxy, which is basically no different from all the other caches, and
subject to the same rules.

_If the first access does not find an object in the cache, it requests
from the network, saves in the cache, and re-treatment or gets a hit,
"the object is not changed." Dot. Further. If the time in the cache
object lifetime expires, or a lifetime on the server timed out - the
object is requested again and a miss is recorded._

The fact that we do not know that there is a client with the object? It
is not our business. It is the client's problem. If the client cache get
miss for an object that no longer exists or its lifetime has expired -
he asks his proxy. Proxy, in the future, or fixes hit or miss. Thus, if
the proxy responds to the client "has not changed", it means, in fact,
that the client has a copy of the object and a copy of the proxy object,
the proxy and responds to the client, performing REFRESH that the object
did not change. What is this, if not hit?

>
>
> Alex.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX/+QeAAoJENNXIZxhPexGXaUH/0b+UkESSCj/oFxSSOfyJyJJ
IcqBxSWh8A9H6AQKco2i8P7Gjlr7oAGZsbF3YS+Gzr3F0ixVIBHdTOW5aXrhjWzm
wyLeeZsmLh7vD4sSAA3IbO9xvvG01sIWnRekagdpE/Smg7tJNoGC84GInQKbEsCm
2wMrdhb7sxE56kc9OmpcYZ7RghwWr0rqSZZ0S62xW0jSkffbUBUTiyRPQox+uZ9a
YCwZ9Ant+6+yrNzoMA9Yn2ujRD7OvuIlsC/pNZ4GqyIU5NJ+wjvfdbt6rx5l/dcr
DICdfi/adNegw9vF9DG4lm9i2joGFo7+OPzKoQeyuO3f7bLSdyxGapxIVWjTNr8=
=jHaY
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161014/b519ae93/attachment.key>

From rousskov at measurement-factory.com  Thu Oct 13 20:48:52 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 13 Oct 2016 14:48:52 -0600
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <0a96829a-d9f5-6d41-efda-931814b96b1f@gmail.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
 <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
 <f659765b-b467-6d07-121e-7031a010d173@gmail.com>
 <24b8aec3-527d-0e96-2b21-439d9535f3ab@measurement-factory.com>
 <e4276384-8dbb-8cae-3c66-d01b352bd7b8@gmail.com>
 <bad2a73a-cbe4-f616-8928-c4c666a54c86@measurement-factory.com>
 <0a96829a-d9f5-6d41-efda-931814b96b1f@gmail.com>
Message-ID: <2eb27685-aac2-ee8a-d8e4-14eaf496404f@measurement-factory.com>

On 10/13/2016 01:44 PM, Yuri Voinov wrote:

> However, this is nothing more than word games, Alex. 

... unless the definition of a hit affects your billing or your
interpretation of Squid documentation or the developer interpretation of
the code. Definitions matter! You yourself have seen their importance
when you showed your excellent byte hit ratio results but folks were
looking at the ordinary document hit ratio numbers instead.


> The question is -
> can we more or less significant differences from known what hit proxy
> code level and / or transactions which, obviously, on the proxy level,
> we can see in its entirety.

Sorry, I do not understand the question.


>> Unfortunately, there are too many definitions of a "hit".

> There is no many definitions of hit. We are talking about the caching
> proxy, which is basically no different from all the other caches, and
> subject to the same rules.

You are oversimplifying a complex subject matter. If Squid delivers a
single response comprising 1000 bytes from the cache and 10 bytes from
the origin server, is that a hit or a miss? If Squid delivers the entire
response from the cache but spends 10 minutes talking to the origin
server about that object first, is that a hit or a miss? Different
people will give you different answers to those questions.

We have [poorly defined] byte hits, document hits, revalidation hits,
stale hits, partial hits, etc., etc.


> If the first access does not find an object in the cache, it requests
> from the network,

yes

> saves in the cache,

or does not

> and re-treatment or gets a hit,

or does not

> "the object is not changed." Dot.

or the Squid-cached object did not change but the client-cached object
did. Or vice versa.


> If the time in the cache
> object lifetime expires, or a lifetime on the server timed out - the
> object is requested again and a miss is recorded.

* Yes, if you define a miss as "contact with the origin server".
* No, if contact with the origin server is OK for a hit as long as the
server does not send the response _body_ back to Squid.


> if
> the proxy responds to the client "has not changed", it means, in fact,
> that the client has a copy of the object

Yes.

> and a copy of the proxy object,

The copy in the proxy cache may be different from the copy in the client
cache or may not exist at all.


> the proxy and responds to the client, performing REFRESH that the object
> did not change. What is this, if not hit?

Assuming the proxy asked the origin server whether the object in the
client (or the proxy, depending on the circumstances) cache is fresh,
for many, it is

* a [document] miss (because there was a potentially very slow contact
with the origin server) or
* a [byte] hit (because the response body came from the Squid cache and
not from the origin server).

Resisting the existence of different valid hit definitions is futile
IMO. State what _your_ definition is (be as precise as possible; this
may require several iterations) and then you may ask whether a
particular transaction is a hit.

Alex.


From yvoinov at gmail.com  Thu Oct 13 21:44:12 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 14 Oct 2016 03:44:12 +0600
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <2eb27685-aac2-ee8a-d8e4-14eaf496404f@measurement-factory.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
 <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
 <f659765b-b467-6d07-121e-7031a010d173@gmail.com>
 <24b8aec3-527d-0e96-2b21-439d9535f3ab@measurement-factory.com>
 <e4276384-8dbb-8cae-3c66-d01b352bd7b8@gmail.com>
 <bad2a73a-cbe4-f616-8928-c4c666a54c86@measurement-factory.com>
 <0a96829a-d9f5-6d41-efda-931814b96b1f@gmail.com>
 <2eb27685-aac2-ee8a-d8e4-14eaf496404f@measurement-factory.com>
Message-ID: <b00e459b-784e-73ed-61da-8083591b42a2@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


14.10.2016 2:48, Alex Rousskov ?????:
> On 10/13/2016 01:44 PM, Yuri Voinov wrote:
>
>> However, this is nothing more than word games, Alex.
>
> ... unless the definition of a hit affects your billing or your
> interpretation of Squid documentation or the developer interpretation of
> the code. Definitions matter! You yourself have seen their importance
> when you showed your excellent byte hit ratio results but folks were
> looking at the ordinary document hit ratio numbers instead.
Sure. But difference with TCP_HIT itself and byte hit is obvious.
>
>
>
>> The question is -
>> can we more or less significant differences from known what hit proxy
>> code level and / or transactions which, obviously, on the proxy level,
>> we can see in its entirety.
>
> Sorry, I do not understand the question.
I want to say that on the proxy level, seeing the transaction as a
whole, we are able to differentiate hit or his likeness from all other
transactions. We see the whole session in its entirety. We see repeated
queries of the same client to the same resource. Accordingly, we can
quite clearly be judged by the behavior of the header from the client or
server that is happening. Correctly?

Specifically, in this particular case. Proxy IMS settings is enabled:

refresh_all_ims on
reload_into_ims on

On web-page level we have: periodically reload/refresh directive, which
is forces to check (after initially store in shared cache) freshness of
content.

In this situation (and I've checked this web-page elements stored in
cache) TCP_MISS/304 means TCP_REFRESH_UNMODIFIED.

So, this is HIT exactly.

I'm not saying - literally. And in fact. Correctly?

>
>
>>> Unfortunately, there are too many definitions of a "hit".
>
>> There is no many definitions of hit. We are talking about the caching
>> proxy, which is basically no different from all the other caches, and
>> subject to the same rules.
>
> You are oversimplifying a complex subject matter. If Squid delivers a
> single response comprising 1000 bytes from the cache and 10 bytes from
> the origin server, is that a hit or a miss? If Squid delivers the entire
> response from the cache but spends 10 minutes talking to the origin
> server about that object first, is that a hit or a miss? Different
> people will give you different answers to those questions.
10 minutes a bit above TCP timeout and will be aborted, I think. So,
Squid's write TCP_MISS_ABORTED in access.log. :)
>
>
> We have [poorly defined] byte hits, document hits, revalidation hits,
> stale hits, partial hits, etc., etc.
What yes - yes. The documentation is the problem.
>
>
>
>> If the first access does not find an object in the cache, it requests
>> from the network,
>
> yes
>
>> saves in the cache,
>
> or does not
Yes. May be or may be not. But in this case we are:
1) Know about transaction history and we know the object(s) in cache.
2) Proxy can easy check it, right? Just swap in object from disk in
memory. If this success, object in cache, so we can qualify it as HIT.
Otherwise, exactly MISS.
>
>
>> and re-treatment or gets a hit,
>
> or does not
>
>> "the object is not changed." Dot.
>
> or the Squid-cached object did not change but the client-cached object
> did. Or vice versa.
Client-cached object gives from Squid. They (ideally) must not be the
different. Client cache and squid's cache operates like chain, one is
source for another.
>
>
>
>> If the time in the cache
>> object lifetime expires, or a lifetime on the server timed out - the
>> object is requested again and a miss is recorded.
>
> * Yes, if you define a miss as "contact with the origin server".
I want to add: "contact with the origin server for get content". Not for
revalidation purposes. If revalidation returns "Object not changed" -
this is positive and must be qualified as HIT IMO.
>
> * No, if contact with the origin server is OK for a hit as long as the
> server does not send the response _body_ back to Squid.
.... when revalidation true - i.e. object in shared cache not stale,
this is HIT. We're not interested in client browser's cache state. Only
shared cache matters.
>
>
>
>> if
>> the proxy responds to the client "has not changed", it means, in fact,
>> that the client has a copy of the object
>
> Yes.
>
>> and a copy of the proxy object,
>
> The copy in the proxy cache may be different from the copy in the client
> cache or may not exist at all.
Yes. If object not exists in proxy - this is proxy MISS. If client cache
not contains object - client go to proxy and asks it about object. Found
- excellent, for client this is MISS, for proxy - HIT. If proxy also not
contains object - it will be MISS-MISS and loading object from origin.

>
>
>
>> the proxy and responds to the client, performing REFRESH that the object
>> did not change. What is this, if not hit?
>
> Assuming the proxy asked the origin server whether the object in the
> client (or the proxy, depending on the circumstances) cache is fresh,
> for many, it is
>
> * a [document] miss (because there was a potentially very slow contact
> with the origin server) or
> * a [byte] hit (because the response body came from the Squid cache and
> not from the origin server).
>
> Resisting the existence of different valid hit definitions is futile
> IMO. State what _your_ definition is (be as precise as possible; this
> may require several iterations) and then you may ask whether a
> particular transaction is a hit.
>
> Alex.
I agree that there are a number of boundary cases. However, in most
cases we are dealing with a relatively simple chain, which should be
considered and, in my opinion. How is it to be regarded revalidation
facilities and its results? If revalidation confirms that the object is
not stale and not expired - it's a hit, is not it?

If revalidation fails - object stale/expired - everything is clear and
there is nothing to discuss. Definitely miss.

Well, let's say we do not know and can not know about the object in the
client cache. Assume also that we do not want to check - whether this
object is in the cache proxy. Let us assume that we do not want to spend
resources to figure out what happened to the object in the future, in
client's browser, or on proxy's disk cache. Ok. Is, in this case, would
not be more correct to write in log TCP_NONE/304?

In this case, we're talking directly - "We do not know, hit it or not.
We only know that the object has not changed since the last
request/revalidation. We do not want to know, and you can interpret it
any way you like".

 It would be more correct, it seems to me, than just to say -
"TCP_MISS/304 - This is a cache miss, whatever it was not really."

WBR, Yuri
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYAAAsAAoJENNXIZxhPexGo5EH/15gr4ShSolL0I0RFZOnZbcg
UPZle45kf9ODeLHQ8RKeUwlmOo3jIEeX1WDoYV++scHsqMeBaydwG4ysjED8RhGf
TzfGJyzmTUDzcxe4QpYft3JFvml0uIc74RAPCVq7w6a4FKuPMVHvjqJwJeQtiKSU
V8zkME6SA4K2HrhtiZjvWvFV0YOmH9oQEj7t4S2lt/OJG6w0AsTV3qLHdC6kyeso
rLJkxmJDW7oH7Va+xoP7R6hflsoMv9t3MvuOS1slNyDSZ+nqsRPTJSrhksl7oCIV
I3GI4aPtOecWJOKeenbjWHDyueI6A1+1E5PKgpQW0ysziHi39HyB0Gz1yBhbeWo=
=bTMv
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161014/aab382fe/attachment.key>

From rousskov at measurement-factory.com  Thu Oct 13 22:50:49 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 13 Oct 2016 16:50:49 -0600
Subject: [squid-users] Squid SMP workers crash
In-Reply-To: <CAHQdsZ805myhBd8_s-1dxvp1eZSv_bhykGj9gwm=_6=WMK8Tew@mail.gmail.com>
References: <CAHQdsZ805myhBd8_s-1dxvp1eZSv_bhykGj9gwm=_6=WMK8Tew@mail.gmail.com>
Message-ID: <b9ced597-84e5-c16c-4130-c4050d9089cc@measurement-factory.com>

On 10/13/2016 01:53 AM, Deniz Eren wrote:

> I'm using squid's SMP functionality to distribute requests to many
> squid instances and distribute workload to multiple processors.
> However while running squid's workers after a while worker processes
> crash with the error below and coordinator does not start them again:
> ...
> FATAL: Ipc::Mem::Segment::open failed to
> shm_open(/squid-cf__metadata.shm): (2) No such file or directory
> Squid Cache (Version 3.5.20): Terminated abnormally.
> ...

Are you saying that this fatal shm_open() error happens after all
workers have started serving/logging traffic? I would expect to see it
at startup (first few minutes at the most if you have IPC timeout
problems). Does the error always point to squid-cf__metadata.shm?

Are you sure that there are no other fatal errors, segmentation faults,
or similar deathly problems _before_ this error? Are you sure your
startup script does not accidentally start multiple Squid instances that
compete with each other? Check system error logs.

FWIW, Segment::open errors without Segment::create errors are often a
side-effect of other problems that either prevent Squid from creating
segments or force Squid to remove created segments (both happen in the
master process).


> permissions are OK in /dev/shm

Do you see any Squid segments there (with reasonable timestamps)?


> Also is my way of using SMP functionality correct, since I want to
> distribute all connections between workers and to listen only specific
> ports?

Adding "workers N" and avoiding SMP-incompatible features is the right
way; I do not see any SMP-related problems in your configuration.

Alex.



From jinju.george at gmail.com  Fri Oct 14 04:49:00 2016
From: jinju.george at gmail.com (georgej)
Date: Thu, 13 Oct 2016 21:49:00 -0700 (PDT)
Subject: [squid-users] Squid is not responding when the number of connection
	exceeds
Message-ID: <1476420540608-4680091.post@n4.nabble.com>

Hi Team,

When the number of users exceeds, squid is not responding. The users getting
"System returned: (110) connecion timed out " message.

The following thing are done for troubleshooting.  But getting the same
result.
1) I have upgraded the squid version to 3.5.20.
2) Removed trendmicro antivirus, squidguard, squid_ldap_auth, cache disabled

Server spec:

Red Hat Enterprise Linux Server release 6.7 (Santiago)
2 GB RAM

Filesystem            Size  Used Avail Use% Mounted on
/dev/mapper/VolGroup00-LogVol05
                      7.8G  5.5G  2.0G  74% /
tmpfs                 935M   12K  935M   1% /dev/shm
/dev/sda1             190M  103M   78M  57% /boot
/dev/mapper/VolGroup00-LogVol01
                      976M  1.7M  924M   1% /home
/dev/mapper/VolGroup00-LogVol02
                      3.9G   22M  3.6G   1% /opt
/dev/mapper/VolGroup00-LogVol03
                      976M  332M  594M  36% /tmp
/dev/mapper/VolGroup00-LogVol04
                      3.9G  1.5G  2.2G  41% /var

The issue will not resolve even i restart the squid server. Once reboot the
server i can access the internet. Whe the number of connection exceeds, the
issue will start again



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-is-not-responding-when-the-number-of-connection-exceeds-tp4680091.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Fri Oct 14 09:57:15 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 14 Oct 2016 15:57:15 +0600
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <b00e459b-784e-73ed-61da-8083591b42a2@gmail.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
 <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
 <f659765b-b467-6d07-121e-7031a010d173@gmail.com>
 <24b8aec3-527d-0e96-2b21-439d9535f3ab@measurement-factory.com>
 <e4276384-8dbb-8cae-3c66-d01b352bd7b8@gmail.com>
 <bad2a73a-cbe4-f616-8928-c4c666a54c86@measurement-factory.com>
 <0a96829a-d9f5-6d41-efda-931814b96b1f@gmail.com>
 <2eb27685-aac2-ee8a-d8e4-14eaf496404f@measurement-factory.com>
 <b00e459b-784e-73ed-61da-8083591b42a2@gmail.com>
Message-ID: <889d2834-d20a-3d49-30e7-b278878364af@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
It seems I found the root of problem.

When cached object refreshed and goes via HTTP, it gives
TCP_REFRESH_UNMODIFIED in access.log, which is correct.
When the _same_ _cached_ _object_ refreshes and goes via HTTPS, it gives
TCP_MISS/304 in access.log, and this is wrong.

It seems like bug.

14.10.2016 3:44, Yuri Voinov ?????:
>
>
>
> 14.10.2016 2:48, Alex Rousskov ?????:
> > On 10/13/2016 01:44 PM, Yuri Voinov wrote:
>
> >> However, this is nothing more than word games, Alex.
>
> > ... unless the definition of a hit affects your billing or your
> > interpretation of Squid documentation or the developer interpretation of
> > the code. Definitions matter! You yourself have seen their importance
> > when you showed your excellent byte hit ratio results but folks were
> > looking at the ordinary document hit ratio numbers instead.
> Sure. But difference with TCP_HIT itself and byte hit is obvious.
>
>
>
> >> The question is -
> >> can we more or less significant differences from known what hit proxy
> >> code level and / or transactions which, obviously, on the proxy level,
> >> we can see in its entirety.
>
> > Sorry, I do not understand the question.
> I want to say that on the proxy level, seeing the transaction as a
> whole, we are able to differentiate hit or his likeness from all other
> transactions. We see the whole session in its entirety. We see repeated
> queries of the same client to the same resource. Accordingly, we can
> quite clearly be judged by the behavior of the header from the client or
> server that is happening. Correctly?
>
> Specifically, in this particular case. Proxy IMS settings is enabled:
>
> refresh_all_ims on
> reload_into_ims on
>
> On web-page level we have: periodically reload/refresh directive, which
> is forces to check (after initially store in shared cache) freshness of
> content.
>
> In this situation (and I've checked this web-page elements stored in
> cache) TCP_MISS/304 means TCP_REFRESH_UNMODIFIED.
>
> So, this is HIT exactly.
>
> I'm not saying - literally. And in fact. Correctly?
>
>
>
> >>> Unfortunately, there are too many definitions of a "hit".
>
> >> There is no many definitions of hit. We are talking about the caching
> >> proxy, which is basically no different from all the other caches, and
> >> subject to the same rules.
>
> > You are oversimplifying a complex subject matter. If Squid delivers a
> > single response comprising 1000 bytes from the cache and 10 bytes from
> > the origin server, is that a hit or a miss? If Squid delivers the entire
> > response from the cache but spends 10 minutes talking to the origin
> > server about that object first, is that a hit or a miss? Different
> > people will give you different answers to those questions.
> 10 minutes a bit above TCP timeout and will be aborted, I think. So,
> Squid's write TCP_MISS_ABORTED in access.log. :)
>
>
> > We have [poorly defined] byte hits, document hits, revalidation hits,
> > stale hits, partial hits, etc., etc.
> What yes - yes. The documentation is the problem.
>
>
>
> >> If the first access does not find an object in the cache, it requests
> >> from the network,
>
> > yes
>
> >> saves in the cache,
>
> > or does not
> Yes. May be or may be not. But in this case we are:
> 1) Know about transaction history and we know the object(s) in cache.
> 2) Proxy can easy check it, right? Just swap in object from disk in
> memory. If this success, object in cache, so we can qualify it as HIT.
> Otherwise, exactly MISS.
>
>
> >> and re-treatment or gets a hit,
>
> > or does not
>
> >> "the object is not changed." Dot.
>
> > or the Squid-cached object did not change but the client-cached object
> > did. Or vice versa.
> Client-cached object gives from Squid. They (ideally) must not be the
> different. Client cache and squid's cache operates like chain, one is
> source for another.
>
>
>
> >> If the time in the cache
> >> object lifetime expires, or a lifetime on the server timed out - the
> >> object is requested again and a miss is recorded.
>
> > * Yes, if you define a miss as "contact with the origin server".
> I want to add: "contact with the origin server for get content". Not for
> revalidation purposes. If revalidation returns "Object not changed" -
> this is positive and must be qualified as HIT IMO.
>
> > * No, if contact with the origin server is OK for a hit as long as the
> > server does not send the response _body_ back to Squid.
> .... when revalidation true - i.e. object in shared cache not stale,
> this is HIT. We're not interested in client browser's cache state. Only
> shared cache matters.
>
>
>
> >> if
> >> the proxy responds to the client "has not changed", it means, in fact,
> >> that the client has a copy of the object
>
> > Yes.
>
> >> and a copy of the proxy object,
>
> > The copy in the proxy cache may be different from the copy in the client
> > cache or may not exist at all.
> Yes. If object not exists in proxy - this is proxy MISS. If client cache
> not contains object - client go to proxy and asks it about object. Found
> - excellent, for client this is MISS, for proxy - HIT. If proxy also not
> contains object - it will be MISS-MISS and loading object from origin.
>
>
>
>
> >> the proxy and responds to the client, performing REFRESH that the
object
> >> did not change. What is this, if not hit?
>
> > Assuming the proxy asked the origin server whether the object in the
> > client (or the proxy, depending on the circumstances) cache is fresh,
> > for many, it is
>
> > * a [document] miss (because there was a potentially very slow contact
> > with the origin server) or
> > * a [byte] hit (because the response body came from the Squid cache and
> > not from the origin server).
>
> > Resisting the existence of different valid hit definitions is futile
> > IMO. State what _your_ definition is (be as precise as possible; this
> > may require several iterations) and then you may ask whether a
> > particular transaction is a hit.
>
> > Alex.
> I agree that there are a number of boundary cases. However, in most
> cases we are dealing with a relatively simple chain, which should be
> considered and, in my opinion. How is it to be regarded revalidation
> facilities and its results? If revalidation confirms that the object is
> not stale and not expired - it's a hit, is not it?
>
> If revalidation fails - object stale/expired - everything is clear and
> there is nothing to discuss. Definitely miss.
>
> Well, let's say we do not know and can not know about the object in the
> client cache. Assume also that we do not want to check - whether this
> object is in the cache proxy. Let us assume that we do not want to spend
> resources to figure out what happened to the object in the future, in
> client's browser, or on proxy's disk cache. Ok. Is, in this case, would
> not be more correct to write in log TCP_NONE/304?
>
> In this case, we're talking directly - "We do not know, hit it or not.
> We only know that the object has not changed since the last
> request/revalidation. We do not want to know, and you can interpret it
> any way you like".
>
>  It would be more correct, it seems to me, than just to say -
> "TCP_MISS/304 - This is a cache miss, whatever it was not really."
>
> WBR, Yuri
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYAKv7AAoJENNXIZxhPexGSu4H/RWQb5rwEcT2bnxt50TdadOW
rAHLZ8ASdNDIRoumbXXqmbUTx4vIDTSp+Va77Sw1sKvcJgb/jZ7PdilyQSb60ZsS
IpBVMVbVz0gF7xe2Qqt6lB5Nl48Wmnernb/G47zdXnaJ9d8lZ/P5ed75rbzwXqDY
N7NKa9K2DBnC3PCCYehki2wnQIq7xObN3+D2wnlTSdaqnQFldE/jAmRaDT45A6Ay
awZe47loVM4zo0lTnzqHNlIgfG5ULRjbCHt/a/m4BiS6MPy9mos3yTrZ9xPA0RSX
UmqPTPGQ8gUXGm0YPRDIGT9b4pUZojuRk4ztpeqm6JdYJfF4yePpEnMsYvRWcN4=
=lkj2
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161014/92888787/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161014/92888787/attachment.key>

From makleking at yandex.ru  Fri Oct 14 10:51:25 2016
From: makleking at yandex.ru (=?utf-8?B?0JzQuNGF0LDQuNC7?=)
Date: Fri, 14 Oct 2016 18:51:25 +0800
Subject: [squid-users] ERROR: Cannot connect to 127.0.0.1:3128
In-Reply-To: <41207f59-32a5-0d29-1b62-95c5061ae21b@treenet.co.nz>
References: <294681476158099@web11o.yandex.ru>
 <e663dbd7-b739-ecb9-3598-c649c2b97fcf@treenet.co.nz>
 <6306491476324921@web24g.yandex.ru>
 <41207f59-32a5-0d29-1b62-95c5061ae21b@treenet.co.nz>
Message-ID: <3067671476442285@web6h.yandex.ru>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161014/2143d1fb/attachment.htm>

From yvoinov at gmail.com  Fri Oct 14 11:34:00 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 14 Oct 2016 17:34:00 +0600
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <889d2834-d20a-3d49-30e7-b278878364af@gmail.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
 <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
 <f659765b-b467-6d07-121e-7031a010d173@gmail.com>
 <24b8aec3-527d-0e96-2b21-439d9535f3ab@measurement-factory.com>
 <e4276384-8dbb-8cae-3c66-d01b352bd7b8@gmail.com>
 <bad2a73a-cbe4-f616-8928-c4c666a54c86@measurement-factory.com>
 <0a96829a-d9f5-6d41-efda-931814b96b1f@gmail.com>
 <2eb27685-aac2-ee8a-d8e4-14eaf496404f@measurement-factory.com>
 <b00e459b-784e-73ed-61da-8083591b42a2@gmail.com>
 <889d2834-d20a-3d49-30e7-b278878364af@gmail.com>
Message-ID: <38b1f59b-80bc-9cf7-84b5-dcbe58e93443@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
A bit more details.

This is 4 transactions in chronological order. Two from wget -S and two
from same PC via browser for the same URL:

*root @ khorne /tmp # wget -S
http://www.gazeta.ru/nm2015/js/gazeta.media.query.js*
- --2016-10-14 17:18:05-- 
http://www.gazeta.ru/nm2015/js/gazeta.media.query.js
Connecting to 127.0.0.1:3128... connected.
Proxy request sent, awaiting response...
  HTTP/1.1 301 Moved Permanently
  Server: nginx
  Date: Fri, 14 Oct 2016 11:18:07 GMT
  Content-Type: text/html
  Content-Length: 178
  Location: https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
  X-Cache: MISS from khorne
  X-Cache-Lookup: MISS from khorne:3128
  Connection: keep-alive
Location: https://www.gazeta.ru/nm2015/js/gazeta.media.query.js [following]
- --2016-10-14 17:18:07-- 
https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
Connecting to 127.0.0.1:3128... connected.
Proxy request sent, awaiting response...
  HTTP/1.1 200 OK
  Server: nginx
  Date: Fri, 14 Oct 2016 10:45:57 GMT
  Content-Type: application/javascript; charset=windows-1251
  Last-Modified: Fri, 30 Oct 2015 12:33:38 GMT
  ETag: W/"cdf370-758-52351a306ac80"
  Cache-Control: max-age=3600
  Expires: Fri, 14 Oct 2016 11:45:57 GMT
  Access-Control-Allow-Origin: *
  Age: 1930
  X-Cache: HIT from khorne
  X-Cache-Lookup: HIT from khorne:3128
  Transfer-Encoding: chunked
  Connection: keep-alive
Length: unspecified [application/javascript]
Saving to: 'gazeta.media.query.js'

gazeta.media.query.     [ <=>               ]   1.84K  --.-KB/s    in
0s     

2016-10-14 17:18:07 (138 MB/s) - 'gazeta.media.query.js' saved [1880]

/HTTP object in cache and HIT./
*
**root @ khorne /tmp # wget -S
https://www.gazeta.ru/nm2015/js/gazeta.media.query.js*
- --2016-10-14 17:18:30-- 
https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
Connecting to 127.0.0.1:3128... connected.
Proxy request sent, awaiting response...
  HTTP/1.1 200 OK
  Server: nginx
  Date: Fri, 14 Oct 2016 10:45:57 GMT
  Content-Type: application/javascript; charset=windows-1251
  Last-Modified: Fri, 30 Oct 2015 12:33:38 GMT
  ETag: W/"cdf370-758-52351a306ac80"
  Cache-Control: max-age=3600
  Expires: Fri, 14 Oct 2016 11:45:57 GMT
  Access-Control-Allow-Origin: *
  Age: 1953
  X-Cache: HIT from khorne
  X-Cache-Lookup: HIT from khorne:3128
  Transfer-Encoding: chunked
  Connection: keep-alive
Length: unspecified [application/javascript]
Saving to: 'gazeta.media.query.js.1'

gazeta.media.query.     [ <=>               ]   1.84K  --.-KB/s    in
0s     

2016-10-14 17:18:30 (120 MB/s) - 'gazeta.media.query.js.1' saved [1880]

/HTTPS object in cache and HIT too./

This is ok.

*Ctrl+F5 (force reload) from browser:*

1476443947.419     92 192.168.100.103 TCP_MISS/200 2323 GET
https://www.gazeta.ru/nm2015/js/gazeta.media.query.js -
HIER_DIRECT/81.19.72.0 application/javascript

MISS - it is ok too, client browser sends no-cache.

At this point we sure object in cache, right? Both in proxy cache and in
client cache (client is the same in attempt 3 and 4). Now - refresh from
browser on the same page (same session), which is equivalent of page
auto-refresh.

*F5 (refresh) from the same browser:*

1476443997.252     96 192.168.100.103 TCP_MISS/304 353 GET
https://www.gazeta.ru/nm2015/js/gazeta.media.query.js -
HIER_DIRECT/81.19.72.0 -

Here is it. Object in proxy cache, in client cache, revalidation is ok -
object not changed. It must be TCP_REFRESH_UNMODIFIED, and this tag
we've got with HTTP object via browser.

/But shit! HTTPS goes TCP_MISS/304! We're expected to get
TCP_REFRESH_UNMODIFIED/304! Because this is refresh operation, we're
sure object in both caches - proxy and client, revalidation is ok, but
this marks as MISS./

Why HTTP refresh goes with TCP_REFRESH_UNMODIFIED, and the same object
via HTTPS goes with TCP_MISS? As shown above, object has no headers
preventing caching.

Is it bug or feature? Because of, when site goes under HTTPS, it will
has lower hit with the same content. It seems wrong.

Note: This is news site. There is no private headers or any other
cache-preventing headers.

14.10.2016 15:57, Yuri Voinov ?????:
>
> It seems I found the root of problem.
>
> When cached object refreshed and goes via HTTP, it gives
TCP_REFRESH_UNMODIFIED in access.log, which is correct.
> When the _same_ _cached_ _object_ refreshes and goes via HTTPS, it
gives TCP_MISS/304 in access.log, and this is wrong.
>
> It seems like bug.
>
> 14.10.2016 3:44, Yuri Voinov ?????:
>
>
>
>
>
>
>       > 14.10.2016 2:48, Alex Rousskov ?????:
>
>       > > On 10/13/2016 01:44 PM, Yuri Voinov wrote:
>
>
>
>       > >> However, this is nothing more than word games, Alex.
>
>
>
>       > > ... unless the definition of a hit affects your billing
>       or your
>
>       > > interpretation of Squid documentation or the developer
>       interpretation of
>
>       > > the code. Definitions matter! You yourself have seen
>       their importance
>
>       > > when you showed your excellent byte hit ratio results
>       but folks were
>
>       > > looking at the ordinary document hit ratio numbers
>       instead.
>
>       > Sure. But difference with TCP_HIT itself and byte hit is
>       obvious.
>
>
>
>
>
>
>
>       > >> The question is -
>
>       > >> can we more or less significant differences from
>       known what hit proxy
>
>       > >> code level and / or transactions which, obviously,
>       on the proxy level,
>
>       > >> we can see in its entirety.
>
>
>
>       > > Sorry, I do not understand the question.
>
>       > I want to say that on the proxy level, seeing the transaction
>       as a
>
>       > whole, we are able to differentiate hit or his likeness from
>       all other
>
>       > transactions. We see the whole session in its entirety. We
>       see repeated
>
>       > queries of the same client to the same resource. Accordingly,
>       we can
>
>       > quite clearly be judged by the behavior of the header from
>       the client or
>
>       > server that is happening. Correctly?
>
>
>
>       > Specifically, in this particular case. Proxy IMS settings is
>       enabled:
>
>
>
>       > refresh_all_ims on
>
>       > reload_into_ims on
>
>
>
>       > On web-page level we have: periodically reload/refresh
>       directive, which
>
>       > is forces to check (after initially store in shared cache)
>       freshness of
>
>       > content.
>
>
>
>       > In this situation (and I've checked this web-page elements
>       stored in
>
>       > cache) TCP_MISS/304 means TCP_REFRESH_UNMODIFIED.
>
>
>
>       > So, this is HIT exactly.
>
>
>
>       > I'm not saying - literally. And in fact. Correctly?
>
>
>
>
>
>
>
>       > >>> Unfortunately, there are too many definitions of
>       a "hit".
>
>
>
>       > >> There is no many definitions of hit. We are talking
>       about the caching
>
>       > >> proxy, which is basically no different from all the
>       other caches, and
>
>       > >> subject to the same rules.
>
>
>
>       > > You are oversimplifying a complex subject matter. If
>       Squid delivers a
>
>       > > single response comprising 1000 bytes from the cache and
>       10 bytes from
>
>       > > the origin server, is that a hit or a miss? If Squid
>       delivers the entire
>
>       > > response from the cache but spends 10 minutes talking to
>       the origin
>
>       > > server about that object first, is that a hit or a miss?
>       Different
>
>       > > people will give you different answers to those
>       questions.
>
>       > 10 minutes a bit above TCP timeout and will be aborted, I
>       think. So,
>
>       > Squid's write TCP_MISS_ABORTED in access.log. :)
>
>
>
>
>
>       > > We have [poorly defined] byte hits, document hits,
>       revalidation hits,
>
>       > > stale hits, partial hits, etc., etc.
>
>       > What yes - yes. The documentation is the problem.
>
>
>
>
>
>
>
>       > >> If the first access does not find an object in the
>       cache, it requests
>
>       > >> from the network,
>
>
>
>       > > yes
>
>
>
>       > >> saves in the cache,
>
>
>
>       > > or does not
>
>       > Yes. May be or may be not. But in this case we are:
>
>       > 1) Know about transaction history and we know the object(s)
>       in cache.
>
>       > 2) Proxy can easy check it, right? Just swap in object from
>       disk in
>
>       > memory. If this success, object in cache, so we can qualify
>       it as HIT.
>
>       > Otherwise, exactly MISS.
>
>
>
>
>
>       > >> and re-treatment or gets a hit,
>
>
>
>       > > or does not
>
>
>
>       > >> "the object is not changed." Dot.
>
>
>
>       > > or the Squid-cached object did not change but the
>       client-cached object
>
>       > > did. Or vice versa.
>
>       > Client-cached object gives from Squid. They (ideally) must
>       not be the
>
>       > different. Client cache and squid's cache operates like
>       chain, one is
>
>       > source for another.
>
>
>
>
>
>
>
>       > >> If the time in the cache
>
>       > >> object lifetime expires, or a lifetime on the server
>       timed out - the
>
>       > >> object is requested again and a miss is recorded.
>
>
>
>       > > * Yes, if you define a miss as "contact with the origin
>       server".
>
>       > I want to add: "contact with the origin server for get
>       content". Not for
>
>       > revalidation purposes. If revalidation returns "Object not
>       changed" -
>
>       > this is positive and must be qualified as HIT IMO.
>
>
>
>       > > * No, if contact with the origin server is OK for a hit
>       as long as the
>
>       > > server does not send the response _body_ back to Squid.
>
>       > .... when revalidation true - i.e. object in shared cache not
>       stale,
>
>       > this is HIT. We're not interested in client browser's cache
>       state. Only
>
>       > shared cache matters.
>
>
>
>
>
>
>
>       > >> if
>
>       > >> the proxy responds to the client "has not changed",
>       it means, in fact,
>
>       > >> that the client has a copy of the object
>
>
>
>       > > Yes.
>
>
>
>       > >> and a copy of the proxy object,
>
>
>
>       > > The copy in the proxy cache may be different from the
>       copy in the client
>
>       > > cache or may not exist at all.
>
>       > Yes. If object not exists in proxy - this is proxy MISS. If
>       client cache
>
>       > not contains object - client go to proxy and asks it about
>       object. Found
>
>       > - excellent, for client this is MISS, for proxy - HIT. If
>       proxy also not
>
>       > contains object - it will be MISS-MISS and loading object
>       from origin.
>
>
>
>
>
>
>
>
>
>       > >> the proxy and responds to the client, performing
>       REFRESH that the object
>
>       > >> did not change. What is this, if not hit?
>
>
>
>       > > Assuming the proxy asked the origin server whether the
>       object in the
>
>       > > client (or the proxy, depending on the circumstances)
>       cache is fresh,
>
>       > > for many, it is
>
>
>
>       > > * a [document] miss (because there was a potentially
>       very slow contact
>
>       > > with the origin server) or
>
>       > > * a [byte] hit (because the response body came from the
>       Squid cache and
>
>       > > not from the origin server).
>
>
>
>       > > Resisting the existence of different valid hit
>       definitions is futile
>
>       > > IMO. State what _your_ definition is (be as precise as
>       possible; this
>
>       > > may require several iterations) and then you may ask
>       whether a
>
>       > > particular transaction is a hit.
>
>
>
>       > > Alex.
>
>       > I agree that there are a number of boundary cases. However,
>       in most
>
>       > cases we are dealing with a relatively simple chain, which
>       should be
>
>       > considered and, in my opinion. How is it to be regarded
>       revalidation
>
>       > facilities and its results? If revalidation confirms that the
>       object is
>
>       > not stale and not expired - it's a hit, is not it?
>
>
>
>       > If revalidation fails - object stale/expired - everything is
>       clear and
>
>       > there is nothing to discuss. Definitely miss.
>
>
>
>       > Well, let's say we do not know and can not know about the
>       object in the
>
>       > client cache. Assume also that we do not want to check -
>       whether this
>
>       > object is in the cache proxy. Let us assume that we do not
>       want to spend
>
>       > resources to figure out what happened to the object in the
>       future, in
>
>       > client's browser, or on proxy's disk cache. Ok. Is, in this
>       case, would
>
>       > not be more correct to write in log TCP_NONE/304?
>
>
>
>       > In this case, we're talking directly - "We do not know, hit
>       it or not.
>
>       > We only know that the object has not changed since the last
>
>       > request/revalidation. We do not want to know, and you can
>       interpret it
>
>       > any way you like".
>
>
>
>       >  It would be more correct, it seems to me, than just to say -
>
>       > "TCP_MISS/304 - This is a cache miss, whatever it was not
>       really."
>
>
>
>       > WBR, Yuri
>
>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYAMKnAAoJENNXIZxhPexGLz4H/RjDMSnsVTHDHpBqksSB28jd
SbeNAv34cRd9ECGFb0kM1I7tYe4CdwBEbXWLMdDhYc4vW9AGq70Tc55d+CMl65BV
VW/vkVcDge6g4yJ1YHTZE+sb3djlTIkjurDUTo+VZ6LUXcly58IFR2DoFNTNtU6D
K0n5zfSKkYuw9TKr3tTp9hVyldDRHI3iSvBBsE70AM1iwdTTcLKg8P6i6q51MZEx
SliuJ6gWT3o05guceGspSusBL5fRdU0twUpJhcXohI4oM0JafNmhV29CYhi4t3KU
OaCDraL8ntIHzIcLMHB74Mz0vGrHXojeot+bZ8crtpsumMt9BuUDg5HZTEj3KEU=
=4K9l
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161014/3f3659be/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161014/3f3659be/attachment.key>

From squid3 at treenet.co.nz  Fri Oct 14 12:07:12 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 15 Oct 2016 01:07:12 +1300
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <889d2834-d20a-3d49-30e7-b278878364af@gmail.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
 <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
 <f659765b-b467-6d07-121e-7031a010d173@gmail.com>
 <24b8aec3-527d-0e96-2b21-439d9535f3ab@measurement-factory.com>
 <e4276384-8dbb-8cae-3c66-d01b352bd7b8@gmail.com>
 <bad2a73a-cbe4-f616-8928-c4c666a54c86@measurement-factory.com>
 <0a96829a-d9f5-6d41-efda-931814b96b1f@gmail.com>
 <2eb27685-aac2-ee8a-d8e4-14eaf496404f@measurement-factory.com>
 <b00e459b-784e-73ed-61da-8083591b42a2@gmail.com>
 <889d2834-d20a-3d49-30e7-b278878364af@gmail.com>
Message-ID: <9e6e6e8c-a63a-41e4-1006-7d9485167ba8@treenet.co.nz>

On 14/10/2016 10:57 p.m., Yuri Voinov wrote:
> 
> It seems I found the root of problem.
> 
> When cached object refreshed and goes via HTTP, it gives
> TCP_REFRESH_UNMODIFIED in access.log, which is correct.
> When the _same_ _cached_ _object_ refreshes and goes via HTTPS, it gives
> TCP_MISS/304 in access.log, and this is wrong.
> 
> It seems like bug.
> 

Assuming you did the test right it does seem that way.

The way you have described it makes me think you are probably not
testing it right. Since HTTPS is not exactly like HTTP (the 'S' has
meaning), your test has to treat the HTTPS object as if it had a
completely different URL to the HTTP one.

HTTP objects are not interchangeable with HTTPS objects, even when the
payload bytes are the same. And that also means you must not use
Store-ID to mix them up.

Amos


From squid3 at treenet.co.nz  Fri Oct 14 12:07:21 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 15 Oct 2016 01:07:21 +1300
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <b00e459b-784e-73ed-61da-8083591b42a2@gmail.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
 <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
 <f659765b-b467-6d07-121e-7031a010d173@gmail.com>
 <24b8aec3-527d-0e96-2b21-439d9535f3ab@measurement-factory.com>
 <e4276384-8dbb-8cae-3c66-d01b352bd7b8@gmail.com>
 <bad2a73a-cbe4-f616-8928-c4c666a54c86@measurement-factory.com>
 <0a96829a-d9f5-6d41-efda-931814b96b1f@gmail.com>
 <2eb27685-aac2-ee8a-d8e4-14eaf496404f@measurement-factory.com>
 <b00e459b-784e-73ed-61da-8083591b42a2@gmail.com>
Message-ID: <cd77384e-0216-ab71-f9fb-109dc6b36f4e@treenet.co.nz>

On 14/10/2016 10:44 a.m., Yuri Voinov wrote:
> 
> 
> 
> 14.10.2016 2:48, Alex Rousskov ?????:
>> On 10/13/2016 01:44 PM, Yuri Voinov wrote:
> 
>>> However, this is nothing more than word games, Alex.
> 
>> ... unless the definition of a hit affects your billing or your
>> interpretation of Squid documentation or the developer interpretation of
>> the code. Definitions matter! You yourself have seen their importance
>> when you showed your excellent byte hit ratio results but folks were
>> looking at the ordinary document hit ratio numbers instead.
> Sure. But difference with TCP_HIT itself and byte hit is obvious.
> 

Even that is not so obvious as it appears at first. Since 3.5.22 it is
possible that the proxy finds an item in its cache that needs to be
revalidated. When asked the server responds with a 304 that contains
info far older than the proxy found (maybe from a more up-to-date server
IP).
In this situation Squid discards the outdated server response and
deliveres its content. That should be marked as TCP_HIT under the
current tagging system.

This case and others involving the (thankfully rare) If-Unmodified-Since
header are why I am trying to work out a better tagging scheme that will
be less confusing and more descriptive for the operations.


> 
>>> The question is -
>>> can we more or less significant differences from known what hit proxy
>>> code level and / or transactions which, obviously, on the proxy level,
>>> we can see in its entirety.
> 
>> Sorry, I do not understand the question.
> I want to say that on the proxy level, seeing the transaction as a
> whole, we are able to differentiate hit or his likeness from all other
> transactions. We see the whole session in its entirety. We see repeated
> queries of the same client to the same resource. Accordingly, we can
> quite clearly be judged by the behavior of the header from the client or
> server that is happening. Correctly?
> 

HTTP/1.0 was simple. HIT and MISS were easily known and matched what you
have learnt to expect.

HTTP/1.1 adds 2x time-based If-*Since headers, 2x ETag based If-*Match
headrs, and one extendable If: header - each of which has a 200 or 304
response. With a client cache, proxy cache and upstream cache each
having one of the content-vs-nothing states.

The result is that the log line describes one of the 3*(2^5) = 96
different transaction cases which could occur.

My math there is assuming the that each header adds only a binary
condition (X, or not X). If they add trinary (X, not-X, ignore) then its
2^2*(3^4) = 972 cases, which seems a bit much to me.


> Specifically, in this particular case. Proxy IMS settings is enabled:
> 
> refresh_all_ims on
> reload_into_ims on
> 

These are converting CC:no-cache or CC:max-age=0 client headers into IMS
(If-Modified-Since) revalidations against the server. All they do is
convert the Squid<->server transaction into a revalidation.

The client should still get a /200 object even though the server side
used revalidation. It is a bug for Squid to respond to those client
requests with /304 unless the client *also* sent If-* headers along with
the CC reload/refresh header.


> On web-page level we have: periodically reload/refresh directive, which
> is forces to check (after initially store in shared cache) freshness of
> content.
> 

These reload/refresh coming from the client are supposed to only happen
when a user identifies breakage in the web page and manually forces it
to happen (refresh button in the browser). Bots can use them, but should
not need to.

So when HTTP is working properly they should almost never happen (client
never sees breakage).

If you find them happening a lot it is a sign of breakage.


> In this situation (and I've checked this web-page elements stored in
> cache) TCP_MISS/304 means TCP_REFRESH_UNMODIFIED.
> 
> So, this is HIT exactly.

No "exactly" about it.

If it was *exactly* a HIT that would mean the cached response was a 304
message. Not some object the 304 was about, but the actual 304 status
line + mime headers.

Which also would be logged as as TCP_HIT/304. Identical to the different
case where a normal cache object being HIT on generated a new 304 to the
client.

> 
> I'm not saying - literally. And in fact. Correctly?

With 96 permutations of cases there may be the odd mistake. But where
Squid has a tag code for one case that case is usually tagged correctly.
So the TCP_MISS/304 is definitely *not* a TCP_REFRESH_UNMODIFIED - but
it also may not be strictly a MISS either.

It is entirely possible that a TCP_MISS/304 is a real TCP_MISS/304. MISS
on the proxy cache and 304 from upstream server.

The REFRESH MODIFIED/UNMODIFIED tags are give to the time-based
If-*-Since headers. The ETag based ones are not tagged the same because
'(un)modified' is not applicable. So this TCP_MISS/304 may be one of the
ETag revalidations on proxy content that we dont have a special code for
yet.

> 
>>>> Unfortunately, there are too many definitions of a "hit".
> 
>>> There is no many definitions of hit. We are talking about the caching
>>> proxy, which is basically no different from all the other caches, and
>>> subject to the same rules.
> 
>> You are oversimplifying a complex subject matter. If Squid delivers a
>> single response comprising 1000 bytes from the cache and 10 bytes from
>> the origin server, is that a hit or a miss? If Squid delivers the entire
>> response from the cache but spends 10 minutes talking to the origin
>> server about that object first, is that a hit or a miss? Different
>> people will give you different answers to those questions.
> 10 minutes a bit above TCP timeout and will be aborted, I think. So,
> Squid's write TCP_MISS_ABORTED in access.log. :)
> 

Or TCP_HIT_ABORTED or TCP_REFRESH_ABORTED or TCP_CLIENT_REFRESH_ABORTED :-(

the distiniction is in the headers and your definition of HIT/MISS.


> 
>> We have [poorly defined] byte hits, document hits, revalidation hits,
>> stale hits, partial hits, etc., etc.
> What yes - yes. The documentation is the problem.
> 

Partially. Documentation issue is caused in part by the worse problem of
cases overlapping and currently not being grouped together very well.

I am working on the fix for that. But it is gong very slowly because it
has to touch so much code in areas that I'm not very familiar with yet.
Plus the definitions issue Alex talked about, agreeing on how to define
each tag as it is created leads to long discussions like this one.

> 
>>> If the first access does not find an object in the cache, it requests
>>> from the network,
> 
>> yes
> 
>>> saves in the cache,
> 
>> or does not
> Yes. May be or may be not. But in this case we are:
> 1) Know about transaction history and we know the object(s) in cache.
> 2) Proxy can easy check it, right? Just swap in object from disk in
> memory. If this success, object in cache, so we can qualify it as HIT.
> Otherwise, exactly MISS.
> 
> 
>>> and re-treatment or gets a hit,
> 
>> or does not
> 
>>> "the object is not changed." Dot.
> 
>> or the Squid-cached object did not change but the client-cached object
>> did. Or vice versa.
> Client-cached object gives from Squid. They (ideally) must not be the
> different. Client cache and squid's cache operates like chain, one is
> source for another.

Within HTTP that is true. But clients are not restricted to HTTP as
sources for their cache contents. So we cannot draw such a distinctive
line in the definition of what is happening for a random line selected
out of somebodies access.log.

All we can say is what sub-group of those 96 cases has happened to cause
those tag values to appear. For exact knowledge (or to say what that
means in terms of byte counts) one needs to see the HTTP headers, at
least the client ones and preferrrably the full 11,2 trace data
containing both client and server messages.


> 
>>> If the time in the cache
>>> object lifetime expires, or a lifetime on the server timed out - the
>>> object is requested again and a miss is recorded.
> 
>> * Yes, if you define a miss as "contact with the origin server".
> I want to add: "contact with the origin server for get content". Not for
> revalidation purposes. If revalidation returns "Object not changed" -
> this is positive and must be qualified as HIT IMO.

Even this definition is tricky. For revalidations using the
If-Unmodified-Since header the server (or squid) is instructed to
deliver a 200+object when the "Object not changed" state happens.

That is usually where TCP_REFRESH_UNMODIFIED/200 come from.

> 
>> * No, if contact with the origin server is OK for a hit as long as the
>> server does not send the response _body_ back to Squid.
> .... when revalidation true - i.e. object in shared cache not stale,
> this is HIT. We're not interested in client browser's cache state. Only
> shared cache matters.
> 
> 
> 
>>> if
>>> the proxy responds to the client "has not changed", it means, in fact,
>>> that the client has a copy of the object
> 
>> Yes.
> 
>>> and a copy of the proxy object,
> 
>> The copy in the proxy cache may be different from the copy in the client
>> cache or may not exist at all.
> Yes. If object not exists in proxy - this is proxy MISS. If client cache
> not contains object - client go to proxy and asks it about object. Found
> - excellent, for client this is MISS, for proxy - HIT. If proxy also not
> contains object - it will be MISS-MISS and loading object from origin.
> 

This is where the ETag based If-*Match headers get in the way of a
definition. The proxy could easily have what appears to be a useful
response to the URL, but be told only to send it if *not* matching a set
of ETag values. Or the opposite.

I guess what I (we?) am trying to get across is that defining the entire
Internet in black-and-white terms of HIT vs MISS is wrong for HTTP/1.1
traffic. Within 1.1 traffic REFRESH is the norm, and HIT/MISS on local
proxy cache is only a minor subset of what is going on - even for
transactions logged as TCP_HIT or TCP_MISS.


Squid [read: "the changes we are making to Squid-3/4"] is trying to
minimize bandwidth on both server and client connections. Sometimes only
one connection can be reduced, many times both can be.

What any particular sysadmin sees in regards to client or server
bandwidth used by Squid varies a lot. Usually by how much Squid HTTP/1.1
feature support matches the relevant client or server feature support.


> 
>>> the proxy and responds to the client, performing REFRESH that the object
>>> did not change. What is this, if not hit?
> 
>> Assuming the proxy asked the origin server whether the object in the
>> client (or the proxy, depending on the circumstances) cache is fresh,
>> for many, it is
> 
>> * a [document] miss (because there was a potentially very slow contact
>> with the origin server) or
>> * a [byte] hit (because the response body came from the Squid cache and
>> not from the origin server).
> 
>> Resisting the existence of different valid hit definitions is futile
>> IMO. State what _your_ definition is (be as precise as possible; this
>> may require several iterations) and then you may ask whether a
>> particular transaction is a hit.
> 
>> Alex.
> I agree that there are a number of boundary cases. However, in most
> cases we are dealing with a relatively simple chain, which should be
> considered and, in my opinion. How is it to be regarded revalidation
> facilities and its results? If revalidation confirms that the object is
> not stale and not expired - it's a hit, is not it?
> 
> If revalidation fails - object stale/expired - everything is clear and
> there is nothing to discuss. Definitely miss.

Revalidation does not "fail". It happens or it does not. The result is
always a fresh object when it happens.

In order to cram the 96 revalidation states down into the overly simple
HIT vs MISS terminology you are implicitly using the byte-HIT
definition. Where size of updating headers-only vs updating payload body
is different.
 So your definition only means HIT = low bytes, MISS = many bytes.


> 
> Well, let's say we do not know and can not know about the object in the
> client cache. Assume also that we do not want to check - whether this
> object is in the cache proxy. Let us assume that we do not want to spend
> resources to figure out what happened to the object in the future, in
> client's browser, or on proxy's disk cache. Ok. Is, in this case, would
> not be more correct to write in log TCP_NONE/304?

No. Knowing zero about the client object is one of the 96 cases. (no
revalidation headers present). It looks like this:

 GET /foo HTTP/1.1
 Host: example.com

The response to this has to always involve a "/200". So your /304 is not
possible.
The remainder of the tags are decided by whether Squid has cached
content and needs to revalidate it. That will determine whether
HIT/MISS/REFRESH_* is logged.

Both REFRESH and MISS will involve a server, but different ways and
different amounts of bandwidth used.

Which brings us to your description of the squid cache...

> 
> In this case, we're talking directly - "We do not know, hit it or not.
> We only know that the object has not changed since the last
> request/revalidation. We do not want to know, and you can interpret it
> any way you like".

That would be a TCP_HIT/200. Maximum possible to-client bandwidth
expenditure. Zero server bandwidth expenditure.

However, by using the condition "We only know that the object has not
changed" you have defined this use-case as a situation where
revalidation is not performed. That alone makes it irrelevant to this
discussion about revalidations.


> 
>  It would be more correct, it seems to me, than just to say -
> "TCP_MISS/304 - This is a cache miss, whatever it was not really."
> 

This status code does not describe that.

It describes a cache MISS which when the server response was stored
allowed Squid to optimize away the bandwidth to the client and send only
a 304 response.

OR, it describes a MISS where Squid relayed conditional If-* headers to
the server. So the server responded with a 304 Squid had to relay on to
the client (without adding to its cache).

Amos


From squid3 at treenet.co.nz  Fri Oct 14 12:30:44 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 15 Oct 2016 01:30:44 +1300
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <38b1f59b-80bc-9cf7-84b5-dcbe58e93443@gmail.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
 <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
 <f659765b-b467-6d07-121e-7031a010d173@gmail.com>
 <24b8aec3-527d-0e96-2b21-439d9535f3ab@measurement-factory.com>
 <e4276384-8dbb-8cae-3c66-d01b352bd7b8@gmail.com>
 <bad2a73a-cbe4-f616-8928-c4c666a54c86@measurement-factory.com>
 <0a96829a-d9f5-6d41-efda-931814b96b1f@gmail.com>
 <2eb27685-aac2-ee8a-d8e4-14eaf496404f@measurement-factory.com>
 <b00e459b-784e-73ed-61da-8083591b42a2@gmail.com>
 <889d2834-d20a-3d49-30e7-b278878364af@gmail.com>
 <38b1f59b-80bc-9cf7-84b5-dcbe58e93443@gmail.com>
Message-ID: <bd3d9c1d-f671-20e0-b3a3-2645974b0593@treenet.co.nz>

On 15/10/2016 12:34 a.m., Yuri Voinov wrote:
> 
> A bit more details.
> 
> This is 4 transactions in chronological order. Two from wget -S and two
> from same PC via browser for the same URL:
> 
> *root @ khorne /tmp # wget -S
> http://www.gazeta.ru/nm2015/js/gazeta.media.query.js*
> --2016-10-14 17:18:05-- 
> http://www.gazeta.ru/nm2015/js/gazeta.media.query.js
> Connecting to 127.0.0.1:3128... connected.
> Proxy request sent, awaiting response...
>   HTTP/1.1 301 Moved Permanently
>   Server: nginx
>   Date: Fri, 14 Oct 2016 11:18:07 GMT
>   Content-Type: text/html
>   Content-Length: 178
>   Location: https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
>   X-Cache: MISS from khorne
>   X-Cache-Lookup: MISS from khorne:3128
>   Connection: keep-alive
> Location: https://www.gazeta.ru/nm2015/js/gazeta.media.query.js [following]
> --2016-10-14 17:18:07-- 
> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js

Notice how the Location header made wget fetch send a second fetch to
*actually* load an HTTPS object.

This means your use of HTTP is irrelevant. HTTP just results in an 301
response. That is the end of the HTTP...


> Connecting to 127.0.0.1:3128... connected.
> Proxy request sent, awaiting response...
>   HTTP/1.1 200 OK
>   Server: nginx
>   Date: Fri, 14 Oct 2016 10:45:57 GMT
>   Content-Type: application/javascript; charset=windows-1251
>   Last-Modified: Fri, 30 Oct 2015 12:33:38 GMT
>   ETag: W/"cdf370-758-52351a306ac80"
>   Cache-Control: max-age=3600
>   Expires: Fri, 14 Oct 2016 11:45:57 GMT
>   Access-Control-Allow-Origin: *
>   Age: 1930
>   X-Cache: HIT from khorne
>   X-Cache-Lookup: HIT from khorne:3128
>   Transfer-Encoding: chunked
>   Connection: keep-alive
> Length: unspecified [application/javascript]
> Saving to: 'gazeta.media.query.js'
> 
> gazeta.media.query.     [ <=>               ]   1.84K  --.-KB/s    in
> 0s     
> 
> 2016-10-14 17:18:07 (138 MB/s) - 'gazeta.media.query.js' saved [1880]
> 
> /HTTP object in cache and HIT./

No. *HTTPS* object in cache and HIT.


> *
> **root @ khorne /tmp # wget -S
> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js*
> --2016-10-14 17:18:30-- 
> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
> Connecting to 127.0.0.1:3128... connected.
> Proxy request sent, awaiting response...
>   HTTP/1.1 200 OK
>   Server: nginx
>   Date: Fri, 14 Oct 2016 10:45:57 GMT
>   Content-Type: application/javascript; charset=windows-1251
>   Last-Modified: Fri, 30 Oct 2015 12:33:38 GMT
>   ETag: W/"cdf370-758-52351a306ac80"
>   Cache-Control: max-age=3600
>   Expires: Fri, 14 Oct 2016 11:45:57 GMT
>   Access-Control-Allow-Origin: *
>   Age: 1953
>   X-Cache: HIT from khorne
>   X-Cache-Lookup: HIT from khorne:3128
>   Transfer-Encoding: chunked
>   Connection: keep-alive
> Length: unspecified [application/javascript]
> Saving to: 'gazeta.media.query.js.1'
> 
> gazeta.media.query.     [ <=>               ]   1.84K  --.-KB/s    in
> 0s     
> 
> 2016-10-14 17:18:30 (120 MB/s) - 'gazeta.media.query.js.1' saved [1880]
> 
> /HTTPS object in cache and HIT too./

No. Same HTTPS object from test #1 is still in cache and still being HIT.

> 
> This is ok.

Uh, not if you are going to interpret the first test as being an HTTP
object in cache.

What this tells is that fetching an HTTPS object twice in a row will
produce a HIT.

> 
> *Ctrl+F5 (force reload) from browser:*
> 
> 1476443947.419     92 192.168.100.103 TCP_MISS/200 2323 GET
> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js -
> HIER_DIRECT/81.19.72.0 application/javascript
> 
> MISS - it is ok too, client browser sends no-cache.

Did you check the client request to verify that "no-cache" statement?

> 
> At this point we sure object in cache, right? Both in proxy cache and in
> client cache (client is the same in attempt 3 and 4). Now - refresh from
> browser on the same page (same session), which is equivalent of page
> auto-refresh.

Yes, that is a reasonable state to assume at this point. Though possibly
wrong, since it is an assumption.

> 
> *F5 (refresh) from the same browser:*
> 

NP: be aware that two fetches in a row is different form force-refresh,
which is different from non-forced refresh.

One of the two refresh involved no-cache header, the other involves
max-age=0 header.
The double-fetch does not send either no-cache nor max-age=0.

Also be aware that the MSIE browser name for the button "Refresh" which
got copied by the others is browser GUI terminology, not HTTP terminology.
HTTP terminology uses "force-refresh" or "reload" for the two request
header cases caused by F5 and Ctrl+F5.


> 1476443997.252     96 192.168.100.103 TCP_MISS/304 353 GET
> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js -
> HIER_DIRECT/81.19.72.0 -
> 
> Here is it. Object in proxy cache, in client cache, revalidation is ok -
> object not changed. It must be TCP_REFRESH_UNMODIFIED, and this tag
> we've got with HTTP object via browser.

No. I think you have confused the GUI button name with the Squid log tag
name.
REFRESH tag occurs on revalidation transactions. The F5 (aka
"forced-refresh") can lead to that.
The Ctrl+F5 (aka. "reload") can only lead to MISS (aks reload, re-fetch,
"discard cached contents").

When a browser send no-cache the cached content must not be used, but
can be updated by the reply that comes back.

When the browser sends max-age=0, the cached contents *can* be used
provided they meet the 0sec old criteria (ie revalidate, then use the
resulting cache object).

> 
> /But shit! HTTPS goes TCP_MISS/304! We're expected to get
> TCP_REFRESH_UNMODIFIED/304! Because this is refresh operation, we're
> sure object in both caches - proxy and client, revalidation is ok, but
> this marks as MISS./

Your expectation was fooled by the browser mis-naming of things.

> 
> Why HTTP refresh goes with TCP_REFRESH_UNMODIFIED, and the same object
> via HTTPS goes with TCP_MISS? As shown above, object has no headers
> preventing caching.

HTTP is not relevant for the reason stated above. What your test has
done is fetch the same https:// URL in three different ways and seen
three different log entries result from that.

Whether they were the right responses is unknown. But at least they were
different. I would be more worried if they were the same.

> 
> Is it bug or feature? Because of, when site goes under HTTPS, it will
> has lower hit with the same content. It seems wrong.

I hope the above clarifies the situation. There may or may not be bugs
involved, but this test does not demonstrate any that I can see.

It also does not demonstrate any difference in HIT with HTTP vs HTTPS.
In fact it demonstrates that HTTPS is getting HITs.

Amos


From yvoinov at gmail.com  Fri Oct 14 12:36:49 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 14 Oct 2016 18:36:49 +0600
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <bd3d9c1d-f671-20e0-b3a3-2645974b0593@treenet.co.nz>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
 <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
 <f659765b-b467-6d07-121e-7031a010d173@gmail.com>
 <24b8aec3-527d-0e96-2b21-439d9535f3ab@measurement-factory.com>
 <e4276384-8dbb-8cae-3c66-d01b352bd7b8@gmail.com>
 <bad2a73a-cbe4-f616-8928-c4c666a54c86@measurement-factory.com>
 <0a96829a-d9f5-6d41-efda-931814b96b1f@gmail.com>
 <2eb27685-aac2-ee8a-d8e4-14eaf496404f@measurement-factory.com>
 <b00e459b-784e-73ed-61da-8083591b42a2@gmail.com>
 <889d2834-d20a-3d49-30e7-b278878364af@gmail.com>
 <38b1f59b-80bc-9cf7-84b5-dcbe58e93443@gmail.com>
 <bd3d9c1d-f671-20e0-b3a3-2645974b0593@treenet.co.nz>
Message-ID: <7d86893d-3344-e110-fa5e-912387f98b64@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


14.10.2016 18:30, Amos Jeffries ?????:
> On 15/10/2016 12:34 a.m., Yuri Voinov wrote:
>>
>> A bit more details.
>>
>> This is 4 transactions in chronological order. Two from wget -S and two
>> from same PC via browser for the same URL:
>>
>> *root @ khorne /tmp # wget -S
>> http://www.gazeta.ru/nm2015/js/gazeta.media.query.js*
>> --2016-10-14 17:18:05--
>> http://www.gazeta.ru/nm2015/js/gazeta.media.query.js
>> Connecting to 127.0.0.1:3128... connected.
>> Proxy request sent, awaiting response...
>>   HTTP/1.1 301 Moved Permanently
>>   Server: nginx
>>   Date: Fri, 14 Oct 2016 11:18:07 GMT
>>   Content-Type: text/html
>>   Content-Length: 178
>>   Location: https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
>>   X-Cache: MISS from khorne
>>   X-Cache-Lookup: MISS from khorne:3128
>>   Connection: keep-alive
>> Location: https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
[following]
>> --2016-10-14 17:18:07--
>> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
>
> Notice how the Location header made wget fetch send a second fetch to
> *actually* load an HTTPS object.
>
> This means your use of HTTP is irrelevant. HTTP just results in an 301
> response. That is the end of the HTTP...

Location: https://www.gazeta.ru/nm2015/js/gazeta.media.query.js

This is no matter.
>
>
>
>> Connecting to 127.0.0.1:3128... connected.
>> Proxy request sent, awaiting response...
>>   HTTP/1.1 200 OK
>>   Server: nginx
>>   Date: Fri, 14 Oct 2016 10:45:57 GMT
>>   Content-Type: application/javascript; charset=windows-1251
>>   Last-Modified: Fri, 30 Oct 2015 12:33:38 GMT
>>   ETag: W/"cdf370-758-52351a306ac80"
>>   Cache-Control: max-age=3600
>>   Expires: Fri, 14 Oct 2016 11:45:57 GMT
>>   Access-Control-Allow-Origin: *
>>   Age: 1930
>>   X-Cache: HIT from khorne
>>   X-Cache-Lookup: HIT from khorne:3128
>>   Transfer-Encoding: chunked
>>   Connection: keep-alive
>> Length: unspecified [application/javascript]
>> Saving to: 'gazeta.media.query.js'
>>
>> gazeta.media.query.     [ <=>               ]   1.84K  --.-KB/s    in
>> 0s    
>>
>> 2016-10-14 17:18:07 (138 MB/s) - 'gazeta.media.query.js' saved [1880]
>>
>> /HTTP object in cache and HIT./
>
> No. *HTTPS* object in cache and HIT.
Oh, mistype. Let it be HTTPS and HIT.
>
>
>
>> *
>> **root @ khorne /tmp # wget -S
>> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js*
>> --2016-10-14 17:18:30--
>> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
>> Connecting to 127.0.0.1:3128... connected.
>> Proxy request sent, awaiting response...
>>   HTTP/1.1 200 OK
>>   Server: nginx
>>   Date: Fri, 14 Oct 2016 10:45:57 GMT
>>   Content-Type: application/javascript; charset=windows-1251
>>   Last-Modified: Fri, 30 Oct 2015 12:33:38 GMT
>>   ETag: W/"cdf370-758-52351a306ac80"
>>   Cache-Control: max-age=3600
>>   Expires: Fri, 14 Oct 2016 11:45:57 GMT
>>   Access-Control-Allow-Origin: *
>>   Age: 1953
>>   X-Cache: HIT from khorne
>>   X-Cache-Lookup: HIT from khorne:3128
>>   Transfer-Encoding: chunked
>>   Connection: keep-alive
>> Length: unspecified [application/javascript]
>> Saving to: 'gazeta.media.query.js.1'
>>
>> gazeta.media.query.     [ <=>               ]   1.84K  --.-KB/s    in
>> 0s    
>>
>> 2016-10-14 17:18:30 (120 MB/s) - 'gazeta.media.query.js.1' saved [1880]
>>
>> /HTTPS object in cache and HIT too./
>
> No. Same HTTPS object from test #1 is still in cache and still being HIT.
>
>>
>> This is ok.
>
> Uh, not if you are going to interpret the first test as being an HTTP
> object in cache.
>
> What this tells is that fetching an HTTPS object twice in a row will
> produce a HIT.
Yes. Let it be.
>
>
>>
>> *Ctrl+F5 (force reload) from browser:*
>>
>> 1476443947.419     92 192.168.100.103 TCP_MISS/200 2323 GET
>> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js -
>> HIER_DIRECT/81.19.72.0 application/javascript
>>
>> MISS - it is ok too, client browser sends no-cache.
>
> Did you check the client request to verify that "no-cache" statement?
Yes.
>
>
>>
>> At this point we sure object in cache, right? Both in proxy cache and in
>> client cache (client is the same in attempt 3 and 4). Now - refresh from
>> browser on the same page (same session), which is equivalent of page
>> auto-refresh.
>
> Yes, that is a reasonable state to assume at this point. Though possibly
> wrong, since it is an assumption.
>
>>
>> *F5 (refresh) from the same browser:*
>>
>
> NP: be aware that two fetches in a row is different form force-refresh,
> which is different from non-forced refresh.
>
> One of the two refresh involved no-cache header, the other involves
> max-age=0 header.
> The double-fetch does not send either no-cache nor max-age=0.
>
> Also be aware that the MSIE browser name for the button "Refresh" which
> got copied by the others is browser GUI terminology, not HTTP terminology.
> HTTP terminology uses "force-refresh" or "reload" for the two request
> header cases caused by F5 and Ctrl+F5.
Sure. In case 3 and 4 latest Google Chrome used. No MSIE bullshit, which
is not respect RFC at all.

Anyway. This is word games.

The HTTPS object (HTTP/1.1) is absolutely sure in client and proxy
caches. Right?

So, why not expired object in both caches produces TCP_MISS/304?
>
>
>
>> 1476443997.252     96 192.168.100.103 TCP_MISS/304 353 GET
>> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js -
>> HIER_DIRECT/81.19.72.0 -
>>
>> Here is it. Object in proxy cache, in client cache, revalidation is ok -
>> object not changed. It must be TCP_REFRESH_UNMODIFIED, and this tag
>> we've got with HTTP object via browser.
>
> No. I think you have confused the GUI button name with the Squid log tag
> name.
> REFRESH tag occurs on revalidation transactions. The F5 (aka
> "forced-refresh") can lead to that.
> The Ctrl+F5 (aka. "reload") can only lead to MISS (aks reload, re-fetch,
> "discard cached contents").
>
> When a browser send no-cache the cached content must not be used, but
> can be updated by the reply that comes back.
>
> When the browser sends max-age=0, the cached contents *can* be used
> provided they meet the 0sec old criteria (ie revalidate, then use the
> resulting cache object).
>
>>
>> /But shit! HTTPS goes TCP_MISS/304! We're expected to get
>> TCP_REFRESH_UNMODIFIED/304! Because this is refresh operation, we're
>> sure object in both caches - proxy and client, revalidation is ok, but
>> this marks as MISS./
>
> Your expectation was fooled by the browser mis-naming of things.
>
>>
>> Why HTTP refresh goes with TCP_REFRESH_UNMODIFIED, and the same object
>> via HTTPS goes with TCP_MISS? As shown above, object has no headers
>> preventing caching.
>
> HTTP is not relevant for the reason stated above. What your test has
> done is fetch the same https:// URL in three different ways and seen
> three different log entries result from that.
>
> Whether they were the right responses is unknown. But at least they were
> different. I would be more worried if they were the same.
>
>>
>> Is it bug or feature? Because of, when site goes under HTTPS, it will
>> has lower hit with the same content. It seems wrong.
>
> I hope the above clarifies the situation. There may or may not be bugs
> involved, but this test does not demonstrate any that I can see.
>
> It also does not demonstrate any difference in HIT with HTTP vs HTTPS.
> In fact it demonstrates that HTTPS is getting HITs.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYANFhAAoJENNXIZxhPexGbvIIAMTCtxLxWS7yd6nwTrBvVLqg
mG34AUO6buxKSaqw0ZVx0TZNWY/5t/V4ma4JxRpZKBXDrbE7AtP4LeyKoqShs3U8
AdME7HaSSe7Hdta26IZtisK3a6y9K24IyhiSlu6KeBKJqEdDVjBaoioqj0nrUBJC
hyclRgaV4mFDcJjUZ3ZZToz5ueVXQnBy6VbIz28pY4rjR1t94KrPKOmIKyKlf7Xc
1FlNAtgIZ7tFs4YhI8jx/I5NkHAVxcJN0R9Owp7AzU0afobaSFU/1dMYHs5/UxUG
3GqiHDZB6MdOhT8wAnctchkDlGpeShOxiRJJKfGLXBIOwQiZm3i4A50dsFpmc/I=
=yoS2
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161014/ce3ed501/attachment.key>

From yvoinov at gmail.com  Fri Oct 14 13:01:34 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 14 Oct 2016 19:01:34 +0600
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <7d86893d-3344-e110-fa5e-912387f98b64@gmail.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
 <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
 <f659765b-b467-6d07-121e-7031a010d173@gmail.com>
 <24b8aec3-527d-0e96-2b21-439d9535f3ab@measurement-factory.com>
 <e4276384-8dbb-8cae-3c66-d01b352bd7b8@gmail.com>
 <bad2a73a-cbe4-f616-8928-c4c666a54c86@measurement-factory.com>
 <0a96829a-d9f5-6d41-efda-931814b96b1f@gmail.com>
 <2eb27685-aac2-ee8a-d8e4-14eaf496404f@measurement-factory.com>
 <b00e459b-784e-73ed-61da-8083591b42a2@gmail.com>
 <889d2834-d20a-3d49-30e7-b278878364af@gmail.com>
 <38b1f59b-80bc-9cf7-84b5-dcbe58e93443@gmail.com>
 <bd3d9c1d-f671-20e0-b3a3-2645974b0593@treenet.co.nz>
 <7d86893d-3344-e110-fa5e-912387f98b64@gmail.com>
Message-ID: <89f443bb-6f52-8bba-9fa3-42a0cc3962d2@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Well. Let's made clean, easy to reproduce example.

Let's take one PC behind proxy. Let's clean up any browser's caches.
Let's reboot it for experiment clarity.

Let's take two URLs. One for HTTP and the same for HTTPS. Simple static
image 200 Kb in size.

http://www.opennet.ru/img/carbonsoft1.gif
https://www.opennet.ru/img/carbonsoft1.gif

Let's run Chrome and Firefox on selected PC.

Let's load both object's in browser's cache. Let's verify both in proxy
cache:

1476449165.101    537 192.168.100.103 TCP_HIT/200 210951 GET
http://www.opennet.ru/img/carbonsoft1.gif - HIER_NONE/- image/gif

HTTP and HIT. Exactly.

All the same, but via HTTPS:

1476449299.999    470 192.168.100.103 TCP_MISS/200 210857 GET
https://www.opennet.ru/img/carbonsoft1.gif - HIER_DIRECT/81.95.33.238
image/gif

First load. MISS. It's ok.

Second load. Same PC, Firefox:

1476449352.792    105 192.168.100.103 TCP_HIT/200 210864 GET
https://www.opennet.ru/img/carbonsoft1.gif - HIER_NONE/- image/gif

HTTPS and HIT. It's ok. As expected.

Same Firefox, F5, refresh:

1476449412.235    102 192.168.100.103 TCP_MISS/304 294 GET
https://www.opennet.ru/img/carbonsoft1.gif - HIER_DIRECT/81.95.33.238 -

Same Chrome, F5, refresh (note: object on proxy cache, and in both
browsers caches):

1476449477.621     87 192.168.100.103 TCP_MISS/304 294 GET
https://www.opennet.ru/img/carbonsoft1.gif - HIER_DIRECT/81.95.33.238 -

Let's see on headers:


root @ khorne /tmp # wget -S http://www.opennet.ru/img/carbonsoft1.gif
- --2016-10-14 18:51:56--  http://www.opennet.ru/img/carbonsoft1.gif
Connecting to 127.0.0.1:3128... connected.
Proxy request sent, awaiting response...
  HTTP/1.1 200 OK
  Server: nginx/1.0.9
  Date: Tue, 11 Oct 2016 17:28:11 GMT
  Content-Type: image/gif
  Content-Length: 210501
  Last-Modified: Mon, 05 Sep 2016 12:35:00 GMT
  Expires: Thu, 10 Nov 2016 17:28:11 GMT
  Cache-Control: max-age=2592000
  Accept-Ranges: bytes
  Age: 242631
  Warning: 113 khorne (squid) This cache hit is still fresh and more
than 1 day old
  X-Cache: HIT from khorne
  X-Cache-Lookup: HIT from khorne:3128
  Connection: keep-alive
Length: 210501 (206K) [image/gif]
Saving to: 'carbonsoft1.gif'

carbonsoft1.gif     100%[==================>] 205.57K  --.-KB/s    in 0.001s

2016-10-14 18:51:56 (298 MB/s) - 'carbonsoft1.gif' saved [210501/210501]

root @ khorne /tmp # wget -S https://www.opennet.ru/img/carbonsoft1.gif
- --2016-10-14 18:52:20--  https://www.opennet.ru/img/carbonsoft1.gif
Connecting to 127.0.0.1:3128... connected.
Proxy request sent, awaiting response...
  HTTP/1.1 200 OK
  Server: nginx/1.0.9
  Date: Fri, 14 Oct 2016 12:48:23 GMT
  Content-Type: image/gif
  Content-Length: 210501
  Last-Modified: Mon, 05 Sep 2016 12:35:00 GMT
  Expires: Sun, 13 Nov 2016 12:48:23 GMT
  Cache-Control: max-age=2592000
  Accept-Ranges: bytes
  Age: 241
  X-Cache: HIT from khorne
  X-Cache-Lookup: HIT from khorne:3128
  Connection: keep-alive
Length: 210501 (206K) [image/gif]
Saving to: 'carbonsoft1.gif.1'

carbonsoft1.gif.1   100%[==================>] 205.57K   398KB/s    in
0.5s   

2016-10-14 18:52:21 (398 KB/s) - 'carbonsoft1.gif.1' saved [210501/210501]

Yes, both HTTP and HTTPS in proxy cache, right? Both is HTTP/1.1, right?
All headers the same, no cache preventing.

Let's refresh from Chrome HTTP object:

1476449587.276    111 192.168.100.103 TCP_REFRESH_UNMODIFIED/304 301 GET
http://www.opennet.ru/img/carbonsoft1.gif - HIER_DIRECT/81.95.33.238 -

Request size = 301

TCP_REFRESH_UNMODIFIED. As expected, ok.

Let's refresh HTTPS from same chrome:

1476449697.991    129 192.168.100.103 TCP_MISS/304 294 GET
https://www.opennet.ru/img/carbonsoft1.gif - HIER_DIRECT/81.95.33.238 -

Request size = 294

TCP_MISS/304.

You can easy to reproduce this by youself. Squid 3.5.22.

The question is the same. Latest example must be TCP_REFRESH_UNMODIFIED.
I see no reason why it should be different tnan HTTP object versions.
Squid's begaviour must be the same, as described in RFC. Right? Because
there is absolutely no any reason for this example, why it must be
different.

Agreed?

All the rest is sophistry and does not explain anything.

14.10.2016 18:36, Yuri Voinov ?????:
>
>
>
> 14.10.2016 18:30, Amos Jeffries ?????:
> > On 15/10/2016 12:34 a.m., Yuri Voinov wrote:
> >>
> >> A bit more details.
> >>
> >> This is 4 transactions in chronological order. Two from wget -S and two
> >> from same PC via browser for the same URL:
> >>
> >> *root @ khorne /tmp # wget -S
> >> http://www.gazeta.ru/nm2015/js/gazeta.media.query.js*
> >> --2016-10-14 17:18:05--
> >> http://www.gazeta.ru/nm2015/js/gazeta.media.query.js
> >> Connecting to 127.0.0.1:3128... connected.
> >> Proxy request sent, awaiting response...
> >>   HTTP/1.1 301 Moved Permanently
> >>   Server: nginx
> >>   Date: Fri, 14 Oct 2016 11:18:07 GMT
> >>   Content-Type: text/html
> >>   Content-Length: 178
> >>   Location: https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
> >>   X-Cache: MISS from khorne
> >>   X-Cache-Lookup: MISS from khorne:3128
> >>   Connection: keep-alive
> >> Location: https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
> [following]
> >> --2016-10-14 17:18:07--
> >> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
>
> > Notice how the Location header made wget fetch send a second fetch to
> > *actually* load an HTTPS object.
>
> > This means your use of HTTP is irrelevant. HTTP just results in an 301
> > response. That is the end of the HTTP...
>
> Location: https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
>
> This is no matter.
>
>
>
> >> Connecting to 127.0.0.1:3128... connected.
> >> Proxy request sent, awaiting response...
> >>   HTTP/1.1 200 OK
> >>   Server: nginx
> >>   Date: Fri, 14 Oct 2016 10:45:57 GMT
> >>   Content-Type: application/javascript; charset=windows-1251
> >>   Last-Modified: Fri, 30 Oct 2015 12:33:38 GMT
> >>   ETag: W/"cdf370-758-52351a306ac80"
> >>   Cache-Control: max-age=3600
> >>   Expires: Fri, 14 Oct 2016 11:45:57 GMT
> >>   Access-Control-Allow-Origin: *
> >>   Age: 1930
> >>   X-Cache: HIT from khorne
> >>   X-Cache-Lookup: HIT from khorne:3128
> >>   Transfer-Encoding: chunked
> >>   Connection: keep-alive
> >> Length: unspecified [application/javascript]
> >> Saving to: 'gazeta.media.query.js'
> >>
> >> gazeta.media.query.     [ <=>               ]   1.84K  --.-KB/s    in
> >> 0s   
> >>
> >> 2016-10-14 17:18:07 (138 MB/s) - 'gazeta.media.query.js' saved [1880]
> >>
> >> /HTTP object in cache and HIT./
>
> > No. *HTTPS* object in cache and HIT.
> Oh, mistype. Let it be HTTPS and HIT.
>
>
>
> >> *
> >> **root @ khorne /tmp # wget -S
> >> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js*
> >> --2016-10-14 17:18:30--
> >> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
> >> Connecting to 127.0.0.1:3128... connected.
> >> Proxy request sent, awaiting response...
> >>   HTTP/1.1 200 OK
> >>   Server: nginx
> >>   Date: Fri, 14 Oct 2016 10:45:57 GMT
> >>   Content-Type: application/javascript; charset=windows-1251
> >>   Last-Modified: Fri, 30 Oct 2015 12:33:38 GMT
> >>   ETag: W/"cdf370-758-52351a306ac80"
> >>   Cache-Control: max-age=3600
> >>   Expires: Fri, 14 Oct 2016 11:45:57 GMT
> >>   Access-Control-Allow-Origin: *
> >>   Age: 1953
> >>   X-Cache: HIT from khorne
> >>   X-Cache-Lookup: HIT from khorne:3128
> >>   Transfer-Encoding: chunked
> >>   Connection: keep-alive
> >> Length: unspecified [application/javascript]
> >> Saving to: 'gazeta.media.query.js.1'
> >>
> >> gazeta.media.query.     [ <=>               ]   1.84K  --.-KB/s    in
> >> 0s   
> >>
> >> 2016-10-14 17:18:30 (120 MB/s) - 'gazeta.media.query.js.1' saved [1880]
> >>
> >> /HTTPS object in cache and HIT too./
>
> > No. Same HTTPS object from test #1 is still in cache and still being
HIT.
>
> >>
> >> This is ok.
>
> > Uh, not if you are going to interpret the first test as being an HTTP
> > object in cache.
>
> > What this tells is that fetching an HTTPS object twice in a row will
> > produce a HIT.
> Yes. Let it be.
>
>
> >>
> >> *Ctrl+F5 (force reload) from browser:*
> >>
> >> 1476443947.419     92 192.168.100.103 TCP_MISS/200 2323 GET
> >> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js -
> >> HIER_DIRECT/81.19.72.0 application/javascript
> >>
> >> MISS - it is ok too, client browser sends no-cache.
>
> > Did you check the client request to verify that "no-cache" statement?
> Yes.
>
>
> >>
> >> At this point we sure object in cache, right? Both in proxy cache
and in
> >> client cache (client is the same in attempt 3 and 4). Now - refresh
from
> >> browser on the same page (same session), which is equivalent of page
> >> auto-refresh.
>
> > Yes, that is a reasonable state to assume at this point. Though possibly
> > wrong, since it is an assumption.
>
> >>
> >> *F5 (refresh) from the same browser:*
> >>
>
> > NP: be aware that two fetches in a row is different form force-refresh,
> > which is different from non-forced refresh.
>
> > One of the two refresh involved no-cache header, the other involves
> > max-age=0 header.
> > The double-fetch does not send either no-cache nor max-age=0.
>
> > Also be aware that the MSIE browser name for the button "Refresh" which
> > got copied by the others is browser GUI terminology, not HTTP
terminology.
> > HTTP terminology uses "force-refresh" or "reload" for the two request
> > header cases caused by F5 and Ctrl+F5.
> Sure. In case 3 and 4 latest Google Chrome used. No MSIE bullshit, which
> is not respect RFC at all.
>
> Anyway. This is word games.
>
> The HTTPS object (HTTP/1.1) is absolutely sure in client and proxy
> caches. Right?
>
> So, why not expired object in both caches produces TCP_MISS/304?
>
>
>
> >> 1476443997.252     96 192.168.100.103 TCP_MISS/304 353 GET
> >> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js -
> >> HIER_DIRECT/81.19.72.0 -
> >>
> >> Here is it. Object in proxy cache, in client cache, revalidation is
ok -
> >> object not changed. It must be TCP_REFRESH_UNMODIFIED, and this tag
> >> we've got with HTTP object via browser.
>
> > No. I think you have confused the GUI button name with the Squid log tag
> > name.
> > REFRESH tag occurs on revalidation transactions. The F5 (aka
> > "forced-refresh") can lead to that.
> > The Ctrl+F5 (aka. "reload") can only lead to MISS (aks reload, re-fetch,
> > "discard cached contents").
>
> > When a browser send no-cache the cached content must not be used, but
> > can be updated by the reply that comes back.
>
> > When the browser sends max-age=0, the cached contents *can* be used
> > provided they meet the 0sec old criteria (ie revalidate, then use the
> > resulting cache object).
>
> >>
> >> /But shit! HTTPS goes TCP_MISS/304! We're expected to get
> >> TCP_REFRESH_UNMODIFIED/304! Because this is refresh operation, we're
> >> sure object in both caches - proxy and client, revalidation is ok, but
> >> this marks as MISS./
>
> > Your expectation was fooled by the browser mis-naming of things.
>
> >>
> >> Why HTTP refresh goes with TCP_REFRESH_UNMODIFIED, and the same object
> >> via HTTPS goes with TCP_MISS? As shown above, object has no headers
> >> preventing caching.
>
> > HTTP is not relevant for the reason stated above. What your test has
> > done is fetch the same https:// URL in three different ways and seen
> > three different log entries result from that.
>
> > Whether they were the right responses is unknown. But at least they were
> > different. I would be more worried if they were the same.
>
> >>
> >> Is it bug or feature? Because of, when site goes under HTTPS, it will
> >> has lower hit with the same content. It seems wrong.
>
> > I hope the above clarifies the situation. There may or may not be bugs
> > involved, but this test does not demonstrate any that I can see.
>
> > It also does not demonstrate any difference in HIT with HTTP vs HTTPS.
> > In fact it demonstrates that HTTPS is getting HITs.
>
> > Amos
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYANctAAoJENNXIZxhPexGN4MH/R9W5fIyVU1rAQN8VMutU5an
rZ+GZoiUmKWFGxs5yFEJzpvGrarZjJyJO3RCfEYn/sFLxCAEa4vrUKL2x8KyUycC
m/0TYQmDq+H264mcKrAX0GG/6yNCodh3aZfNT9EFb0tHKRxPeBt8VfD7Qu4dbv3V
SMgysccNNLGbSK4zWEUF78luWsvc0Y+5LRsEbjAkBKpD4V9yG6gj5XC0tFiEqyvy
uNVdCq5r57mXmoeUAlGBEnAHXRusxjppPM2ySVSYGhib+R9AdKZVCEPlgzcmGXbJ
pj7YwIt+UBs5lkmRCRH6jC2Xzie17bFBneEqkF+xsmfKr+h51FMzn2MVCUcppVA=
=p1yH
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161014/1e45a301/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161014/1e45a301/attachment.key>

From squid3 at treenet.co.nz  Fri Oct 14 13:05:55 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 15 Oct 2016 02:05:55 +1300
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <7d86893d-3344-e110-fa5e-912387f98b64@gmail.com>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
 <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
 <f659765b-b467-6d07-121e-7031a010d173@gmail.com>
 <24b8aec3-527d-0e96-2b21-439d9535f3ab@measurement-factory.com>
 <e4276384-8dbb-8cae-3c66-d01b352bd7b8@gmail.com>
 <bad2a73a-cbe4-f616-8928-c4c666a54c86@measurement-factory.com>
 <0a96829a-d9f5-6d41-efda-931814b96b1f@gmail.com>
 <2eb27685-aac2-ee8a-d8e4-14eaf496404f@measurement-factory.com>
 <b00e459b-784e-73ed-61da-8083591b42a2@gmail.com>
 <889d2834-d20a-3d49-30e7-b278878364af@gmail.com>
 <38b1f59b-80bc-9cf7-84b5-dcbe58e93443@gmail.com>
 <bd3d9c1d-f671-20e0-b3a3-2645974b0593@treenet.co.nz>
 <7d86893d-3344-e110-fa5e-912387f98b64@gmail.com>
Message-ID: <4e00c72f-5e54-2693-f725-3e0caf3caf49@treenet.co.nz>

On 15/10/2016 1:36 a.m., Yuri Voinov wrote:
> 
> 
> 
> 14.10.2016 18:30, Amos Jeffries ?????:
>> On 15/10/2016 12:34 a.m., Yuri Voinov wrote:
>>>
>>> A bit more details.
>>>
>>> This is 4 transactions in chronological order. Two from wget -S and two
>>> from same PC via browser for the same URL:
>>>
>>> *root @ khorne /tmp # wget -S
>>> http://www.gazeta.ru/nm2015/js/gazeta.media.query.js*
>>> --2016-10-14 17:18:05--
>>> http://www.gazeta.ru/nm2015/js/gazeta.media.query.js
>>> Connecting to 127.0.0.1:3128... connected.
>>> Proxy request sent, awaiting response...
>>>   HTTP/1.1 301 Moved Permanently
>>>   Server: nginx
>>>   Date: Fri, 14 Oct 2016 11:18:07 GMT
>>>   Content-Type: text/html
>>>   Content-Length: 178
>>>   Location: https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
>>>   X-Cache: MISS from khorne
>>>   X-Cache-Lookup: MISS from khorne:3128
>>>   Connection: keep-alive
>>> Location: https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
> [following]
>>> --2016-10-14 17:18:07--
>>> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
> 
>> Notice how the Location header made wget fetch send a second fetch to
>> *actually* load an HTTPS object.
> 
>> This means your use of HTTP is irrelevant. HTTP just results in an 301
>> response. That is the end of the HTTP...
> 
> Location: https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
> 
> This is no matter.
> 
> 
> 
>>> Connecting to 127.0.0.1:3128... connected.
>>> Proxy request sent, awaiting response...
>>>   HTTP/1.1 200 OK
>>>   Server: nginx
>>>   Date: Fri, 14 Oct 2016 10:45:57 GMT
>>>   Content-Type: application/javascript; charset=windows-1251
>>>   Last-Modified: Fri, 30 Oct 2015 12:33:38 GMT
>>>   ETag: W/"cdf370-758-52351a306ac80"
>>>   Cache-Control: max-age=3600
>>>   Expires: Fri, 14 Oct 2016 11:45:57 GMT
>>>   Access-Control-Allow-Origin: *
>>>   Age: 1930
>>>   X-Cache: HIT from khorne
>>>   X-Cache-Lookup: HIT from khorne:3128
>>>   Transfer-Encoding: chunked
>>>   Connection: keep-alive
>>> Length: unspecified [application/javascript]
>>> Saving to: 'gazeta.media.query.js'
>>>
>>> gazeta.media.query.     [ <=>               ]   1.84K  --.-KB/s    in
>>> 0s    
>>>
>>> 2016-10-14 17:18:07 (138 MB/s) - 'gazeta.media.query.js' saved [1880]
>>>
>>> /HTTP object in cache and HIT./
> 
>> No. *HTTPS* object in cache and HIT.
> Oh, mistype. Let it be HTTPS and HIT.
> 
> 
> 
>>> *
>>> **root @ khorne /tmp # wget -S
>>> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js*
>>> --2016-10-14 17:18:30--
>>> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js
>>> Connecting to 127.0.0.1:3128... connected.
>>> Proxy request sent, awaiting response...
>>>   HTTP/1.1 200 OK
>>>   Server: nginx
>>>   Date: Fri, 14 Oct 2016 10:45:57 GMT
>>>   Content-Type: application/javascript; charset=windows-1251
>>>   Last-Modified: Fri, 30 Oct 2015 12:33:38 GMT
>>>   ETag: W/"cdf370-758-52351a306ac80"
>>>   Cache-Control: max-age=3600
>>>   Expires: Fri, 14 Oct 2016 11:45:57 GMT
>>>   Access-Control-Allow-Origin: *
>>>   Age: 1953
>>>   X-Cache: HIT from khorne
>>>   X-Cache-Lookup: HIT from khorne:3128
>>>   Transfer-Encoding: chunked
>>>   Connection: keep-alive
>>> Length: unspecified [application/javascript]
>>> Saving to: 'gazeta.media.query.js.1'
>>>
>>> gazeta.media.query.     [ <=>               ]   1.84K  --.-KB/s    in
>>> 0s    
>>>
>>> 2016-10-14 17:18:30 (120 MB/s) - 'gazeta.media.query.js.1' saved [1880]
>>>
>>> /HTTPS object in cache and HIT too./
> 
>> No. Same HTTPS object from test #1 is still in cache and still being HIT.
> 
>>>
>>> This is ok.
> 
>> Uh, not if you are going to interpret the first test as being an HTTP
>> object in cache.
> 
>> What this tells is that fetching an HTTPS object twice in a row will
>> produce a HIT.
> Yes. Let it be.
> 
> 
>>>
>>> *Ctrl+F5 (force reload) from browser:*
>>>
>>> 1476443947.419     92 192.168.100.103 TCP_MISS/200 2323 GET
>>> https://www.gazeta.ru/nm2015/js/gazeta.media.query.js -
>>> HIER_DIRECT/81.19.72.0 application/javascript
>>>
>>> MISS - it is ok too, client browser sends no-cache.
> 
>> Did you check the client request to verify that "no-cache" statement?
> Yes.
> 
> 
>>>
>>> At this point we sure object in cache, right? Both in proxy cache and in
>>> client cache (client is the same in attempt 3 and 4). Now - refresh from
>>> browser on the same page (same session), which is equivalent of page
>>> auto-refresh.
> 
>> Yes, that is a reasonable state to assume at this point. Though possibly
>> wrong, since it is an assumption.
> 
>>>
>>> *F5 (refresh) from the same browser:*
>>>
> 
>> NP: be aware that two fetches in a row is different form force-refresh,
>> which is different from non-forced refresh.
> 
>> One of the two refresh involved no-cache header, the other involves
>> max-age=0 header.
>> The double-fetch does not send either no-cache nor max-age=0.
> 
>> Also be aware that the MSIE browser name for the button "Refresh" which
>> got copied by the others is browser GUI terminology, not HTTP terminology.
>> HTTP terminology uses "force-refresh" or "reload" for the two request
>> header cases caused by F5 and Ctrl+F5.
> Sure. In case 3 and 4 latest Google Chrome used. No MSIE bullshit, which
> is not respect RFC at all.

That is why I said "copied by the others". The F5-thing comes from
Visual Studio hotkeys I think, it was a more recent addition.

> 
> Anyway. This is word games.

Games? no. Technical terminology is never a game. Getting it right is a
critical requirement for communication and understanding the technical
concepts/operations.
Like I said the browser button name seems to have confused your
understanding of the HTTP term usage. Which are different.

> 
> The HTTPS object (HTTP/1.1) is absolutely sure in client and proxy
> caches. Right?

It was before, yes. It also is after, yes.

But the two refresh and force-refresh requests placed different
revalidation requirements on what Squid could do. Thus what happened was
different, and that alters the tags that get logged to say what happened.

> 
> So, why not expired object in both caches produces TCP_MISS/304?
> 

I think the situation here is that Squid is still doing the HTTP/1.0
behaviour when the CC:no-cache request header is received. The response
CC:no-cache handling was corrected, but the request handling has not
been updated yet.

Under HTTP/1.1 (RFC 7234 version) it should only force revalidate to
happen. But in HTTP/1.0 it forced the cache to be ignored. That needs
fixing.

In terms of bugs this is a missing feature / enhancement issue. It is an
acceptible response within HTTP/1.1 (so not major bug), but better
bandwidth uses are possible.

Amos


From squid3 at treenet.co.nz  Fri Oct 14 13:12:19 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 15 Oct 2016 02:12:19 +1300
Subject: [squid-users] Squid is not responding when the number of
 connection exceeds
In-Reply-To: <1476420540608-4680091.post@n4.nabble.com>
References: <1476420540608-4680091.post@n4.nabble.com>
Message-ID: <b035c66e-21f5-00e8-6e4e-2a65ef64d275@treenet.co.nz>

On 14/10/2016 5:49 p.m., georgej wrote:
> Hi Team,
> 
> When the number of users exceeds, squid is not responding. The users getting
> "System returned: (110) connecion timed out " message.

Exceeds what?

Amos



From jinju.george at gmail.com  Fri Oct 14 13:42:26 2016
From: jinju.george at gmail.com (georgej)
Date: Fri, 14 Oct 2016 06:42:26 -0700 (PDT)
Subject: [squid-users] Squid is not responding when the number of
	connection exceeds
In-Reply-To: <b035c66e-21f5-00e8-6e4e-2a65ef64d275@treenet.co.nz>
References: <1476420540608-4680091.post@n4.nabble.com>
 <b035c66e-21f5-00e8-6e4e-2a65ef64d275@treenet.co.nz>
Message-ID: <1476452546054-4680102.post@n4.nabble.com>

I can see the number of established connection more than 180 using with below
command.

sudo netstat -nat | grep :8080 | grep ESTABLISHED| wc -l



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-is-not-responding-when-the-number-of-connection-exceeds-tp4680091p4680102.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From jinju.george at gmail.com  Fri Oct 14 13:44:48 2016
From: jinju.george at gmail.com (georgej)
Date: Fri, 14 Oct 2016 06:44:48 -0700 (PDT)
Subject: [squid-users] Squid is not responding when the number of
	connection exceeds
In-Reply-To: <1476452546054-4680102.post@n4.nabble.com>
References: <1476420540608-4680091.post@n4.nabble.com>
 <b035c66e-21f5-00e8-6e4e-2a65ef64d275@treenet.co.nz>
 <1476452546054-4680102.post@n4.nabble.com>
Message-ID: <1476452688219-4680103.post@n4.nabble.com>

The server is hosted in VMware



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-is-not-responding-when-the-number-of-connection-exceeds-tp4680091p4680103.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Fri Oct 14 15:15:35 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 14 Oct 2016 09:15:35 -0600
Subject: [squid-users] TCP_MISS/304 question
In-Reply-To: <cd77384e-0216-ab71-f9fb-109dc6b36f4e@treenet.co.nz>
References: <377cc034-0790-7182-9a52-ae5905153297@gmail.com>
 <9560bd15-cc4c-443d-0c79-3a3b21d959aa@treenet.co.nz>
 <c1d82f3b-47d2-2514-eb9c-623d252cbb9e@gmail.com>
 <e3d60d3a-972d-8763-8eb4-884cd682696c@gmail.com>
 <280300db-5541-d8e4-ca10-294fc32f898c@treenet.co.nz>
 <f2ec0abe-1132-ddc5-9354-d46e7343198d@gmail.com>
 <f659765b-b467-6d07-121e-7031a010d173@gmail.com>
 <24b8aec3-527d-0e96-2b21-439d9535f3ab@measurement-factory.com>
 <e4276384-8dbb-8cae-3c66-d01b352bd7b8@gmail.com>
 <bad2a73a-cbe4-f616-8928-c4c666a54c86@measurement-factory.com>
 <0a96829a-d9f5-6d41-efda-931814b96b1f@gmail.com>
 <2eb27685-aac2-ee8a-d8e4-14eaf496404f@measurement-factory.com>
 <b00e459b-784e-73ed-61da-8083591b42a2@gmail.com>
 <cd77384e-0216-ab71-f9fb-109dc6b36f4e@treenet.co.nz>
Message-ID: <791e79cf-2d31-3500-eb5a-d1ea97171684@measurement-factory.com>

Hello,

    What may help us move forward is a "reverse mapping" table like this
one:

Row (client-Squid) headings:
* response body sent by Squid to client
* 304 response sent by Squid to client
* 412 response sent by Squid to client
...


Column (Squid-server) headings:
* no contact with the server
* response body sent by server to Squid
* 304 response sent by server to Squid
* 412 response sent by server to Squid
...

Each table cell represents a single transaction matching the
intersection of row and column conditions. A cell will contain the
corresponding logged Squid-to-client HTTP status code (where known) and
Squid tag. Some cells may have several lines if several code/tag
combinations are possible.


With some luck, we could then agree which cells should be designated as
"hits", effectively defining what a "hit" is. We may define several
kinds of hits, of course.

I cannot volunteer to fill this table right now, but I think it could be
useful.


HTH,

Alex.
P.S. This 2D table cannot cover all cases, but we can focus on those
successful transactions that affect hit definition(s) under ordinary
conditions (no aborts, no 503s, etc.).



From rafael.akchurin at diladele.com  Fri Oct 14 22:10:22 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Fri, 14 Oct 2016 22:10:22 +0000
Subject: [squid-users] Squid 3.5.22 for Microsoft Windows 64-bit is available
Message-ID: <DB6PR0401MB2680C121F44C4564C18318A78FDF0@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Greetings everyone,



----

Anyone interested in native docker image for Squid 3.5.22 (hopefully soon) on Ubuntu 16 LTS?

Please say so and I will publish the Squid on Windows 10/Windows Server 2016 Docker tutorial here.

----



The CygWin based build of Squid proxy for Microsoft Windows version 3.5.22 is now available (amd64 only!).



* Original release notes are at http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.22-RELEASENOTES.html.

* Ready to use MSI package can be downloaded from http://squid.diladele.com.

* List of open issues for the installer - https://github.com/diladele/squid-windows/issues



Thanks a lot for Squid developers for making this great software!



Please join our humble efforts to provide ready to run MSI installer for Squid on Microsoft Windows with all required dependencies at GitHub -

https://github.com/diladele/squid-windows. Please report all issues/bugs/feature requests at GitHub project. Issues about the *MSI installer only* can also be reported to support at diladele.com<mailto:support at diladele.com>.



Best regards,

Rafael Akchurin

Diladele B.V.

https://www.diladele.com



--

Please take a look at Web Safety - our ICAP based web filter server for Squid proxy.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161014/6fa2662a/attachment.htm>

From jinju.george at gmail.com  Sat Oct 15 09:47:37 2016
From: jinju.george at gmail.com (georgej)
Date: Sat, 15 Oct 2016 02:47:37 -0700 (PDT)
Subject: [squid-users] Squid on VMWare ESX
In-Reply-To: <5544BACB88454C43A7CD5423754A7B637F052B@nwsh1-mail.STADT-NW.DE>
References: <5544BACB88454C43A7CD5423754A7B637F052B@nwsh1-mail.STADT-NW.DE>
Message-ID: <1476524857871-4680106.post@n4.nabble.com>

Hi Jens,

Is this issue resolved. Did you able to run squid on vmware without any
issue?

Thanks
George



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-on-VMWare-ESX-tp1032367p4680106.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From jester at optimera.us  Sat Oct 15 13:36:04 2016
From: jester at optimera.us (Jester Purtteman)
Date: Sat, 15 Oct 2016 06:36:04 -0700
Subject: [squid-users] Identifying the source of Invalid-request (squid 3)
	-> error:transaction-end-before-headers (Squid 4)
Message-ID: <000001d226e9$182689e0$48739da0$@optimera.us>

Greetings!

 

I am running a transparent proxy for plain http traffic, memory caching
only, I have something like 500 devices that are using the proxy at any
given time over a satellite and I am averaging in the range of 2,000
requests per minute across the proxy (again, no SSL bump, I do not control
the devices at all).  I am using 3.5.22 compiled from sources (if it
matters).  I have been seeing lines in my access log like the following:

 

1476535967.570      0 xxx.xxx.xxx.xxx TAG_NONE/400 4538 NONE
error:invalid-request - HIER_NONE/- text/html

 

After some digging on this list I began to suspect websockets or other
non-http traffic coming across port 80.  After additional reading, and as
much as anything to test the hypothesis, I decided to try squid 4.0.15 with
on-unsupported-protocol.  I get what I am guessing to be the same result
with new error text around it:

 

1476536369.742      0 xxx.xxx.xxx.xxx NONE/000 0 NONE
error:transaction-end-before-headers - HIER_NONE/- -

 

An interesting point to interject here is that my "Hits as % bytes sent" in
3.5.x has always been in the 2 to 5% range, but there are periods (sometimes
long ones) where the inbound traffic to squid is much higher than the
outbound.  When I switch to 4.0.x, I am now running about -27% (note,
negative twenty-seven) as bytes, which makes me suspect it is logging the
higher inbound than outbound now.  So, apparently, this unsupported protocol
is triggering some sort of large download, but does not end up going to the
client.  Obviously, this is not good, so I'm digging deeper and I'd
appreciate any pointers that come to mind. 

 

I would like to know a couple things, first: is there some debugging level
other than ALL,9 that might give me some illumination?  ALL,9 generates
about 15 MB of debug log per second at my current load level, and these
errors aren't real frequent, so I end up with ~ 400 MB of text that needs to
be sifted through.  As you can imagine, that can be a bit brutal.  If I
could even identify the other end point, I would at least be able to figure
out if this is Apple, Microsoft, Android, something else, and perhaps get
closer to being able to replicate the error.  Thoughts would be appreciated.
In case its relevant, my compile options were:

 

./configure --prefix=/usr   --localstatedir=/var
--libexecdir=/usr/lib/squid    --srcdir=.   --datadir=/usr/share/squid
--sysconfdir=/etc/squid   --with-default-user=proxy   --with-logdir=/var/log
--with-pidfile=/var/run/squid.pid --enable-linux-netfilter
--enable-cache-digests --enable-storeio=ufs,aufs,diskd,rock
--enable-async-io=30 --enable-http-violations --enable-zph-qos
--with-netfilter-conntrack --with-filedescriptors=65536 --with-large-files

 

Note that, a lot of those are based on a very long and tedious
guess-and-check session last year, and some of them probably are totally
irrelevant to my setup (I'm looking at you --enable-http-violations and
--enable-zph-qos) but hey, what is life without the unnecessary noise from
lazily copy-and-pasting old compile lines.

 

My configuration, edited to eliminate my numerous comments and hashed out
lines of experiments and to hide network identifiers, is pasted below.  

 

///BEGIN /etc/squid/squid.conf

workers 4

 

acl localnet src 10.0.0.0/8     # RFC1918 possible internal network

acl localnet src 172.16.0.0/12  # RFC1918 possible internal network

acl localnet src 192.168.0.0/16 # RFC1918 possible internal network

 

acl localnet src fc00::/7       # RFC 4193 local private network range

acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines

 

acl SSL_ports port 443

acl Safe_ports port 80          # http

acl Safe_ports port 21          # ftp

acl Safe_ports port 443         # https

acl Safe_ports port 70          # gopher

acl Safe_ports port 210         # wais

acl Safe_ports port 1025-65535  # unregistered ports

acl Safe_ports port 280         # http-mgmt

acl Safe_ports port 488         # gss-http

acl Safe_ports port 591         # filemaker

acl Safe_ports port 777         # multiling http

acl CONNECT method CONNECT

 

#Note that I added this line when testing Squid-4, it is commented out when
running Squid-3

on_unsupported_protocol tunnel all

 

http_access allow localnet

http_access allow localhost

 

http_access deny !Safe_ports

http_access deny CONNECT !SSL_Ports

 

# And finally deny all other access to this proxy

http_access deny all

 

http_port 3128

http_port 3129 tproxy

 

visible_hostname squid-proxy.mydomain.tld

 

acl updatesites dstdom_regex "/etc/squid/updatesites.txt"

 

icp_port 3130

htcp_port 4827

icp_access allow localnet

icp_access deny all

 

#Testing QoS Marks

qos_flows tos local-hit=0x30

qos_flows mark local-hit=0x30

qos_flows mark miss=0x0

 

maximum_object_size 800 MB updatesites

maximum_object_size 80 MB !updatesites

range_offset_limit 0

quick_abort_min 0 KB

 

store_id_program /usr/lib/squid/storeid_file_rewrite
/etc/squid/storeid_rewrite.conf

store_id_children 10 startup=3 idle=1 concurrency=0

 

cache_mem 16384 MB

maximum_object_size_in_memory 8 MB

 

cache_swap_low 90

cache_swap_high 95

 

cache_store_log daemon:/var/log/squid/store.log

access_log daemon:/var/log/squid/access.log squid

cache_log /var/log/squid/cache.log

logfile_rotate 40

max_open_disk_fds 64000

 

refresh_pattern ^ftp:           1440    20%     10080

refresh_pattern ^gopher:        1440    0%      1440

refresh_pattern -i (/cgi-bin/|\?) 0     0%      0

refresh_pattern .               0       20%     4320

 

cache_mgr someone at mydomain.td

cache_effective_user proxy

cache_effective_group proxy

///END /etc/squid/squid.conf

 

So, I have a few questions I guess:  

(1)    For one thing, what are the implications of "on_unsupported_protocol
tunnel all"?  I did it as a quick attempt to see if that had any new and
interesting impacts, but is it safe-ish?  Am I letting the bad-guys come
pouring through with that?

(2)    What debug levels should I be thinking about to try and figure out
what is happening.  Seems like we won't get very far without identifying
what is throwing that error.

(3)    Has anyone else seen this?  Right now, for example (after 10 minutes
of typing an email) I'm actually running -61% Hits as Bytes!  (Negative!)
Ouch! 

 

Thanks!

 

--Jester

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161015/d90d60ad/attachment.htm>

From rousskov at measurement-factory.com  Sat Oct 15 17:57:38 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 15 Oct 2016 11:57:38 -0600
Subject: [squid-users] Identifying the source of Invalid-request (squid
 3) -> error:transaction-end-before-headers (Squid 4)
In-Reply-To: <000001d226e9$182689e0$48739da0$@optimera.us>
References: <000001d226e9$182689e0$48739da0$@optimera.us>
Message-ID: <9fe943c5-28d8-1f17-6f36-ccc16169222f@measurement-factory.com>

On 10/15/2016 07:36 AM, Jester Purtteman wrote:
> I have been seeing lines in my access log like the following:  
> 
> 1476535967.570      0 xxx.xxx.xxx.xxx TAG_NONE/400 4538 NONE
> error:invalid-request - HIER_NONE/- text/html
> 
> After some digging on this list I began to suspect websockets or other
> non-http traffic coming across port 80.  I decided to try squid
> 4.0.15 with on-unsupported-protocol.  I get what I am guessing to be the
> same result with new error text around it:
> 
> 1476536369.742      0 xxx.xxx.xxx.xxx NONE/000 0 NONE
> error:transaction-end-before-headers - HIER_NONE/- -
> 
> An interesting point to interject here is that my ?Hits as % bytes sent?
> in 3.5.x has always been in the 2 to 5% range, but there are periods
> (sometimes long ones) where the inbound traffic to squid is much higher
> than the outbound.  When I switch to 4.0.x, I am now running about -27%
> (note, negative twenty-seven) as bytes, which makes me suspect it is
> logging the higher inbound than outbound now.

That difference sounds potentially important to me. I encourage you to
figure out what causes it (which is exactly what you have started doing,
of course).


> So, apparently, this
> unsupported protocol is triggering some sort of large download, but does
> not end up going to the client.

There might be some exceptions, but non-tunneled
error:transaction-end-before-headers are not supposed to trigger a
download. Squid does not know what to download because Squid cannot
parse the request...

When enabled, tunneled error:transaction-end-before-headers do download
data, of course, but you may be able to measure how much they download
then by finding the corresponding transactions in access log.


> I would like to know a couple things, first: is there some debugging
> level other than ALL,9 that might give me some illumination? 

I am sure there is. Once you know what the problem/cause is, it is easy
to come up with the corresponding optimal debug_options settings to show
the cause. Before that? You can try various settings (debugging sections
are semi-documented in doc/debug-sections.txt), but it is often not
worth your time.


> ALL,9
> generates about 15 MB of debug log per second at my current load level,
> and these errors aren?t real frequent, so I end up with ~ 400 MB of text
> that needs to be sifted through.  As you can imagine, that can be a bit
> brutal.  

I do not quite understand the problem of a 400MB ALL,9 cache.log. IMHO,
it is not much more difficult to deal with than a 1MB ALL,9 cache.log:
Either you can navigate ALL,9 noise or you cannot; the total log size
does not really matter much beyond a few MB levels IMO (provided you
have enough disk space to store it and logging itself does not slow
Squid down too much to reproduce the problem).

Please note that I am not saying that you are doing something wrong or
even complaining about a non-problem. I am only saying that I do not see
a [solvable in the context of this email thread] problem with ALL,9 logs
so I cannot help you solve it.


> So, I have a few questions I guess: 
> 
> (1)    For one thing, what are the implications of
> ?on_unsupported_protocol tunnel all??  

In rough terms, everything that is not SSL or HTTP will be tunneled.
AFAIK, non-HTTP inside SSL will not be tunneled yet (there is an
important patch for that going through squid-dev review right now).


> I did it as a quick attempt to
> see if that had any new and interesting impacts, but is it safe-ish?

I do not know what you mean by "safe", but, in a sense, it is more
"safe" than having no proxy at all because your access.log will show you
those tunnels.


> Am I letting the bad-guys come pouring through with that?

I personally do not know -- in general, it depends on the bad guys in
your environment. Others here may have deployment-specific stories that
I lack.


> (2)    What debug levels should I be thinking about to try and figure
> out what is happening.  Seems like we won?t get very far without
> identifying what is throwing that error.

If you do not want to deal with ALL,9, I would recommend this combination:

* a packet capture (you can limit the captured packet size if needed)
* access log format that logs all IPs and all TCP ports so that you can
match an access log line with captured packets/connection.


> (3)    Has anyone else seen this?  Right now, for example (after 10
> minutes of typing an email) I?m actually running -61% Hits as Bytes! 
> (Negative!)  Ouch!

As I said earlier, I am not sure the negative byte hit ratio is actually
related to these errors, but it could be. Squid v4 fixed a few
size-related accounting bugs. It is possible that we screw something up
in the process or that your actual byte hit ratio was always bad (but
you did not know about it because Squid was lying to you).

Can you compare Squid-reported numbers with OS/interfaces-reported
numbers somehow? If OS/interface numbers confirm v3.5 report but not
v4.0 report, then there is a bug we need to fix.


HTH,

Alex.



From eliezer at ngtech.co.il  Sat Oct 15 23:06:54 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 16 Oct 2016 02:06:54 +0300
Subject: [squid-users] Squid on VMWare ESX
In-Reply-To: <1476524857871-4680106.post@n4.nabble.com>
References: <5544BACB88454C43A7CD5423754A7B637F052B@nwsh1-mail.STADT-NW.DE>
 <1476524857871-4680106.post@n4.nabble.com>
Message-ID: <04d001d22738$d24ba3b0$76e2eb10$@ngtech.co.il>

Hey Geroge,

I have been running squid on ESX in small scale and it works fine.
You should consider your use case details like Requests per second and couple other things.
In general these days virtualization gives the software more then I have assumed in the past and in many big use cases Squid Is virtualized.
I do not have the exact link but I posted IBM research that shows the power of virtualized infrastructure which some might not like.
To illustrate, If I can utilize with a specific software 2 of the 4 CPU cycle with virtualization you are "wasting" some cycles but you can utilize in the overall much more cycles.
In any use case you first must run some basic tests.
Also another thing  to consider in the use case is if you need it for caching or ACLs.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of georgej
Sent: Saturday, October 15, 2016 12:48 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid on VMWare ESX

Hi Jens,

Is this issue resolved. Did you able to run squid on vmware without any
issue?

Thanks
George



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-on-VMWare-ESX-tp1032367p4680106.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From jester at optimera.us  Sat Oct 15 23:16:55 2016
From: jester at optimera.us (Jester Purtteman)
Date: Sat, 15 Oct 2016 16:16:55 -0700
Subject: [squid-users] Identifying the source of Invalid-request (squid
 3) -> error:transaction-end-before-headers (Squid 4)
In-Reply-To: <9fe943c5-28d8-1f17-6f36-ccc16169222f@measurement-factory.com>
References: <000001d226e9$182689e0$48739da0$@optimera.us>
 <9fe943c5-28d8-1f17-6f36-ccc16169222f@measurement-factory.com>
Message-ID: <ad69e19a-e59b-ad21-9d9c-7fcc3f0eda9c@optimera.us>

Thanks for the reply Alex, I've embedded some comments below, and I will 
get back to you with additional info after some testing.


On 10/15/2016 10:57 AM, Alex Rousskov wrote:
> On 10/15/2016 07:36 AM, Jester Purtteman wrote:
>> I have been seeing lines in my access log like the following:
>>
>> 1476535967.570      0 xxx.xxx.xxx.xxx TAG_NONE/400 4538 NONE
>> error:invalid-request - HIER_NONE/- text/html
>>
>> After some digging on this list I began to suspect websockets or other
>> non-http traffic coming across port 80.  I decided to try squid
>> 4.0.15 with on-unsupported-protocol.  I get what I am guessing to be the
>> same result with new error text around it:
>>
>> 1476536369.742      0 xxx.xxx.xxx.xxx NONE/000 0 NONE
>> error:transaction-end-before-headers - HIER_NONE/- -
>>
>> An interesting point to interject here is that my ?Hits as % bytes sent?
>> in 3.5.x has always been in the 2 to 5% range, but there are periods
>> (sometimes long ones) where the inbound traffic to squid is much higher
>> than the outbound.  When I switch to 4.0.x, I am now running about -27%
>> (note, negative twenty-seven) as bytes, which makes me suspect it is
>> logging the higher inbound than outbound now.
> That difference sounds potentially important to me. I encourage you to
> figure out what causes it (which is exactly what you have started doing,
> of course).
>
>
>> So, apparently, this
>> unsupported protocol is triggering some sort of large download, but does
>> not end up going to the client.
> There might be some exceptions, but non-tunneled
> error:transaction-end-before-headers are not supposed to trigger a
> download. Squid does not know what to download because Squid cannot
> parse the request...
>
> When enabled, tunneled error:transaction-end-before-headers do download
> data, of course, but you may be able to measure how much they download
> then by finding the corresponding transactions in access log.
>
>
>> I would like to know a couple things, first: is there some debugging
>> level other than ALL,9 that might give me some illumination?
> I am sure there is. Once you know what the problem/cause is, it is easy
> to come up with the corresponding optimal debug_options settings to show
> the cause. Before that? You can try various settings (debugging sections
> are semi-documented in doc/debug-sections.txt), but it is often not
> worth your time.
>
>
>> ALL,9
>> generates about 15 MB of debug log per second at my current load level,
>> and these errors aren?t real frequent, so I end up with ~ 400 MB of text
>> that needs to be sifted through.  As you can imagine, that can be a bit
>> brutal.
> I do not quite understand the problem of a 400MB ALL,9 cache.log. IMHO,
> it is not much more difficult to deal with than a 1MB ALL,9 cache.log:
> Either you can navigate ALL,9 noise or you cannot; the total log size
> does not really matter much beyond a few MB levels IMO (provided you
> have enough disk space to store it and logging itself does not slow
> Squid down too much to reproduce the problem).
>
> Please note that I am not saying that you are doing something wrong or
> even complaining about a non-problem. I am only saying that I do not see
> a [solvable in the context of this email thread] problem with ALL,9 logs
> so I cannot help you solve it.
>
I gotcha, I'll start the digging.  I was curious what it would take to 
get the a dump of what the request looked like, but its some non-HTTP, 
so that probably doesn't make sense anyway

>> So, I have a few questions I guess:
>>
>> (1)    For one thing, what are the implications of
>> ?on_unsupported_protocol tunnel all??
> In rough terms, everything that is not SSL or HTTP will be tunneled.
> AFAIK, non-HTTP inside SSL will not be tunneled yet (there is an
> important patch for that going through squid-dev review right now).
>
Okay, that i think is the desired behavoir in my case, I basically want 
squid to handle the requests that it knows how deal with, and ignore and 
pass along the ones it cannot.  The environment is pretty promiscuous, 
and i don't need to restrict clients from using non-http stuff.
>> I did it as a quick attempt to
>> see if that had any new and interesting impacts, but is it safe-ish?
> I do not know what you mean by "safe", but, in a sense, it is more
> "safe" than having no proxy at all because your access.log will show you
> those tunnels.
Safe as in, not causing security holes.
>
>> Am I letting the bad-guys come pouring through with that?
> I personally do not know -- in general, it depends on the bad guys in
> your environment. Others here may have deployment-specific stories that
> I lack.
>
I was concerned that by permitting connects through the proxy there may 
be security concerns, but i have the thing bolted down so that only our 
clients can get to it, and it doesn't have much access to anywhere else 
on the network, so I am thinking that is probably fine.
>> (2)    What debug levels should I be thinking about to try and figure
>> out what is happening.  Seems like we won?t get very far without
>> identifying what is throwing that error.
> If you do not want to deal with ALL,9, I would recommend this combination:
>
> * a packet capture (you can limit the captured packet size if needed)
> * access log format that logs all IPs and all TCP ports so that you can
> match an access log line with captured packets/connection.
>
I'll just suck it up and do an ALL,9 capture.  It will take me a couple 
tries to get a capture that includes the problem, but it isn't a huge 
problem.  The packet capture idea is a good one too, I'll do that as 
well.  Similar issue (sifting a small amount of info out of an ocean of 
data) but I think valuable.
>> (3)    Has anyone else seen this?  Right now, for example (after 10
>> minutes of typing an email) I?m actually running -61% Hits as Bytes!
>> (Negative!)  Ouch!
> As I said earlier, I am not sure the negative byte hit ratio is actually
> related to these errors, but it could be. Squid v4 fixed a few
> size-related accounting bugs. It is possible that we screw something up
> in the process or that your actual byte hit ratio was always bad (but
> you did not know about it because Squid was lying to you).
>
> Can you compare Squid-reported numbers with OS/interfaces-reported
> numbers somehow? If OS/interface numbers confirm v3.5 report but not
> v4.0 report, then there is a bug we need to fix.
>
I can, i have interface statistics that I should be able to get pretty 
close with.  It won't be perfect (my ssh session will throw it off a 
tad, etc) but it will be able to detect a 30%+ problem without issue.  
I'll do some experiments and share the result.
> HTH,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Sat Oct 15 23:57:54 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 16 Oct 2016 02:57:54 +0300
Subject: [squid-users] Squid SMP workers crash
In-Reply-To: <CAHQdsZ805myhBd8_s-1dxvp1eZSv_bhykGj9gwm=_6=WMK8Tew@mail.gmail.com>
References: <CAHQdsZ805myhBd8_s-1dxvp1eZSv_bhykGj9gwm=_6=WMK8Tew@mail.gmail.com>
Message-ID: <04d101d2273f$f265b3a0$d7311ae0$@ngtech.co.il>

Hey,

I can try to replicate the same configuration removing couple settings just to make it simpler to verify if the issue since it's similar to the next testing lab I have planned.
Can you give more detail about the OS? CentOS, Ubuntu, Other?
If it's a self compiled versions then "squid -v" output.
I have also seen that you are intercepting both http and https traffic, have you tried looking at the logs?

If you don't hear me from me fast enough just bump me with an email.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Deniz Eren
Sent: Thursday, October 13, 2016 10:53 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Squid SMP workers crash

Hi,

I'm using squid's SMP functionality to distribute requests to many
squid instances and distribute workload to multiple processors.
However while running squid's workers after a while worker processes
crash with the error below and coordinator does not start them again:
...
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-cf__metadata.shm): (2) No such file or directory
Squid Cache (Version 3.5.20): Terminated abnormally.
...

Does a solution exists for this problem? (permissions are OK in /dev/shm)


When everything is OK coordinator listens to http_ports/https_port and
distributes connections to workers(at least that's the conclusion I
got from looking access.logs).
[root at squidbox ~]# netstat -nlp|grep squid
tcp        0      0 0.0.0.0:8080                0.0.0.0:*
     LISTEN      7887/(squid-coord-1
tcp        0      0 0.0.0.0:3127                0.0.0.0:*
     LISTEN      7887/(squid-coord-1
tcp        0      0 0.0.0.0:3128                0.0.0.0:*
     LISTEN      7887/(squid-coord-1
tcp        0      0 0.0.0.0:3130                0.0.0.0:*
     LISTEN      7887/(squid-coord-1
tcp        0      0 0.0.0.0:8443                0.0.0.0:*
     LISTEN      7887/(squid-coord-1
udp        0      0 0.0.0.0:57850               0.0.0.0:*
                 7897/(squid-1)
udp        0      0 0.0.0.0:33643               0.0.0.0:*
                 7894/(squid-4)
udp        0      0 0.0.0.0:50485               0.0.0.0:*
                 7896/(squid-2)
udp        0      0 0.0.0.0:46427               0.0.0.0:*
                 7887/(squid-coord-1
udp        0      0 0.0.0.0:58938               0.0.0.0:*
                 7895/(squid-3)


Also is my way of using SMP functionality correct, since I want to
distribute all connections between workers and to listen only specific
ports?

I have attached the squid.conf.

Regards,



From rousskov at measurement-factory.com  Sun Oct 16 00:27:00 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sat, 15 Oct 2016 18:27:00 -0600
Subject: [squid-users] Identifying the source of Invalid-request (squid
 3) -> error:transaction-end-before-headers (Squid 4)
In-Reply-To: <ad69e19a-e59b-ad21-9d9c-7fcc3f0eda9c@optimera.us>
References: <000001d226e9$182689e0$48739da0$@optimera.us>
 <9fe943c5-28d8-1f17-6f36-ccc16169222f@measurement-factory.com>
 <ad69e19a-e59b-ad21-9d9c-7fcc3f0eda9c@optimera.us>
Message-ID: <d65c0e9c-2e6d-c1d3-58f6-1266ae5b9418@measurement-factory.com>

On 10/15/2016 05:16 PM, Jester Purtteman wrote:
> The packet capture idea is a good one too, I'll do that as well. 
> Similar issue (sifting a small amount of info out of an ocean of data)
> but I think valuable.

With a packet capture and a matching access.log, it is easy to find the
offending connections without Squid-specific knowledge because you can
ask Wireshark or a similar tool to locate the packets that match the
logged IPs and ports (the ones on the error:... lines in access.log).
After that, you just follow the TCP stream you found and look at its
packet payload to identify the protocol/intent...

With cache.log, the procedure is similar but there is no nice interface
to "follow the identified transaction". There are some very useful
scripts that can follow descriptors and internal Squid "jobs", but they
do require some low-level Squid-specific knowledge and experience to
operate correctly (unfortunately). Besides, you may not see the payload,
especially if Squid does not try to parse it.

Alex.



From eliezer at ngtech.co.il  Sun Oct 16 00:42:58 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 16 Oct 2016 03:42:58 +0300
Subject: [squid-users] Squid is not responding when the number
	of	connection exceeds
In-Reply-To: <1476452688219-4680103.post@n4.nabble.com>
References: <1476420540608-4680091.post@n4.nabble.com>
 <b035c66e-21f5-00e8-6e4e-2a65ef64d275@treenet.co.nz>
 <1476452546054-4680102.post@n4.nabble.com>
 <1476452688219-4680103.post@n4.nabble.com>
Message-ID: <04e301d22746$3e0e6350$ba2b29f0$@ngtech.co.il>

Hey George,

If the Virtual Hypervisor resources are shared in a balanced way it should not affect your use case.
The first tool you need is "lsof" and not netstat since it has much more details.
And Before diving into anything at all my recommendation is to upper the basic ulimits to 65535 for the hard and 16384 for the soft.
If you need help on how to put it all together let me know and I will try to help you with it.
Specifically on RedHat 6.X to apply a ulimit you need to set it on the first lines of the init.d script like:
ulimit -Hn 65535
ulimit -Sn 16384

The above should allow your system to overcome couple scenarios of the system "overload".
If it works then it should be considered as a good solution.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of georgej
Sent: Friday, October 14, 2016 4:45 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid is not responding when the number of connection exceeds

The server is hosted in VMware



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-is-not-responding-when-the-number-of-connection-exceeds-tp4680091p4680103.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From johnnylam0010 at gmail.com  Sun Oct 16 13:20:39 2016
From: johnnylam0010 at gmail.com (Johnny Lam)
Date: Sun, 16 Oct 2016 21:20:39 +0800
Subject: [squid-users] Squid 2.7 to Squid 3.5
Message-ID: <CAOD59=79vLpfp33x5EWrp=OcWqUvydTH+zQxjZ4dfCLBNwVJmQ@mail.gmail.com>

Dear All,

I've encountered a issue during upgrade from 2.7 to 3.5, please find my
config below. Seems everything changed in version 3.5.

Hope you guys can help, Thanks!

Regards,
Johnny
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161016/99e405e1/attachment.htm>

From Antony.Stone at squid.open.source.it  Sun Oct 16 14:44:42 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sun, 16 Oct 2016 16:44:42 +0200
Subject: [squid-users] Squid 2.7 to Squid 3.5
In-Reply-To: <CAOD59=79vLpfp33x5EWrp=OcWqUvydTH+zQxjZ4dfCLBNwVJmQ@mail.gmail.com>
References: <CAOD59=79vLpfp33x5EWrp=OcWqUvydTH+zQxjZ4dfCLBNwVJmQ@mail.gmail.com>
Message-ID: <201610161644.42685.Antony.Stone@squid.open.source.it>

On Sunday 16 October 2016 at 15:20:39, Johnny Lam wrote:

> Dear All,
> 
> I've encountered a issue during upgrade from 2.7 to 3.5, please find my
> config below. Seems everything changed in version 3.5.

No config to be found :(

Please:

 - post your squid.conf without comments or blank lines

 - tell us which system / distribution / version you are running this on

 - tell us what "issue" means - ie: what problem are you experiencing?

> Hope you guys can help, Thanks!

The more info you give us, the better our chances :)


Antony.

-- 
The Magic Words are Squeamish Ossifrage.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Sun Oct 16 16:42:54 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 16 Oct 2016 22:42:54 +0600
Subject: [squid-users] Squid 2.7 to Squid 3.5
In-Reply-To: <CAOD59=79vLpfp33x5EWrp=OcWqUvydTH+zQxjZ4dfCLBNwVJmQ@mail.gmail.com>
References: <CAOD59=79vLpfp33x5EWrp=OcWqUvydTH+zQxjZ4dfCLBNwVJmQ@mail.gmail.com>
Message-ID: <5924f375-7f30-30c5-6a55-5f5ccbc635ab@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


16.10.2016 19:20, Johnny Lam ?????:
> Dear All,
>
> I've encountered a issue during upgrade from 2.7 to 3.5, please find
my config below. Seems everything changed in version 3.5.
Not a word, man. 10 years in IT - eternity :)

You'd still awake in 22 century. Come out already from the cryochamber!
>
> Hope you guys can help, Thanks!

PS. And - yes, html formatting e-mails out of fashion in the last
century! Now, such a font is selected, only 15-year-old girl :))))))
>
> Regards,
> Johnny
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYA64NAAoJENNXIZxhPexG+C0IAMM1cOoTV/4saDdfbiA7H6b4
LK6ThPQBS//ekHNh/5i5rglrX4YDGP4s7Pd1D+m3UiAuhP39ah1oWpwJLt8Yb8VQ
sRKELaa8nUNSvojf8w7s5llACxONBn66YERT3qvizi4su8AouGtNlOTRvfjJG8pL
eRiZqbwT7TlIJcBm1z8ddlJW2StRCHiA3XeFQ0/j63RAtSwrakO0/K2IlfC0qcgZ
fC+BefIhsghcRnR3OhX17rWiAhnZxtJNtrnnuLhMYHDhUd/5o0PgBX2CbbswGeie
t+Vijqj3Bnbkkn/DJJDnUQshGiPpedtDLY5101Kf3ERWc1blHxzqgzMjE1Kl9Xg=
=2a2J
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161016/f09bf8db/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161016/f09bf8db/attachment.key>

From augustus_meyer at gmx.net  Sun Oct 16 21:02:33 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Sun, 16 Oct 2016 14:02:33 -0700 (PDT)
Subject: [squid-users] Squid 2.7 to Squid 3.5
In-Reply-To: <5924f375-7f30-30c5-6a55-5f5ccbc635ab@gmail.com>
References: <CAOD59=79vLpfp33x5EWrp=OcWqUvydTH+zQxjZ4dfCLBNwVJmQ@mail.gmail.com>
 <5924f375-7f30-30c5-6a55-5f5ccbc635ab@gmail.com>
Message-ID: <1476651753025-4680118.post@n4.nabble.com>

Off topic, but anyway:
>Not a word, man. 10 years in IT - eternity :)<
Not true. 
40yrs ago we already did interrupt driven programming or 20 yrs ago online
apps for mobile touchscreens with radio link.
Only real difference: Better graphics today :-)




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7-to-Squid-3-5-tp4680115p4680118.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sun Oct 16 21:11:14 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 17 Oct 2016 03:11:14 +0600
Subject: [squid-users] Squid 2.7 to Squid 3.5
In-Reply-To: <1476651753025-4680118.post@n4.nabble.com>
References: <CAOD59=79vLpfp33x5EWrp=OcWqUvydTH+zQxjZ4dfCLBNwVJmQ@mail.gmail.com>
 <5924f375-7f30-30c5-6a55-5f5ccbc635ab@gmail.com>
 <1476651753025-4680118.post@n4.nabble.com>
Message-ID: <8b076304-eae7-d619-199d-4c6f844fc688@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Come on! You think so?! :)


17.10.2016 3:02, reinerotto ?????:
> Off topic, but anyway:
>> Not a word, man. 10 years in IT - eternity :)<
> Not true.
> 40yrs ago we already did interrupt driven programming or 20 yrs ago online
> apps for mobile touchscreens with radio link.
> Only real difference: Better graphics today :-)
>
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7-to-Squid-3-5-tp4680115p4680118.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYA+zxAAoJENNXIZxhPexGt5cH/303rJuUGd8GMGzxsgpUdPFO
Xr17gS6K+g6yND7fxlEQnxe98Zp1j4Jqqgbf8k4xDMhXiCDdwYSlrW4nTk1s72bs
X6rJXJHUKdu+sY5LZ6BHIfwX9D53+Y0jlW4iyM96sdakGpI8jpHUGROlF0fYCBjx
qFlJSGgim0rOiwyUk9jqKZUMEy9G6xVCBXQ6dNxbhCNJzxyFpbX9MoaDZrC9yjfG
Y094gzqO5Q3jRY1T9v/gz93OJZMi+uLRQosk/9LUnTqSUvrZ1Y01A9W/Nmj6N0wD
S90EJy++mfaL+KmMy8rIuOv9G0Gc4Yqy7qU0QExQTH9mdFU7woQvxgjv4VxuaUw=
=l/5o
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161017/bfe7e905/attachment.key>

From augustus_meyer at gmx.net  Sun Oct 16 21:07:42 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Sun, 16 Oct 2016 14:07:42 -0700 (PDT)
Subject: [squid-users] Squid 2.7 to Squid 3.5
In-Reply-To: <8b076304-eae7-d619-199d-4c6f844fc688@gmail.com>
References: <CAOD59=79vLpfp33x5EWrp=OcWqUvydTH+zQxjZ4dfCLBNwVJmQ@mail.gmail.com>
 <5924f375-7f30-30c5-6a55-5f5ccbc635ab@gmail.com>
 <1476651753025-4680118.post@n4.nabble.com>
 <8b076304-eae7-d619-199d-4c6f844fc688@gmail.com>
Message-ID: <1476652062820-4680120.post@n4.nabble.com>

Sorry, I forgot: Another difference is, that response times are lower today.
(BTW: I also did a SM-4 ...)



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7-to-Squid-3-5-tp4680115p4680120.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sun Oct 16 22:17:57 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 17 Oct 2016 04:17:57 +0600
Subject: [squid-users] Squid 2.7 to Squid 3.5
In-Reply-To: <1476652062820-4680120.post@n4.nabble.com>
References: <CAOD59=79vLpfp33x5EWrp=OcWqUvydTH+zQxjZ4dfCLBNwVJmQ@mail.gmail.com>
 <5924f375-7f30-30c5-6a55-5f5ccbc635ab@gmail.com>
 <1476651753025-4680118.post@n4.nabble.com>
 <8b076304-eae7-d619-199d-4c6f844fc688@gmail.com>
 <1476652062820-4680120.post@n4.nabble.com>
Message-ID: <84ecc3f1-a253-ddca-969e-7fd5984ac635@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
In _your_ environment :) All world uses DNS caches.... ;)


17.10.2016 3:07, reinerotto ?????:
> Sorry, I forgot: Another difference is, that response times are lower today.
> (BTW: I also did a SM-4 ...)
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7-to-Squid-3-5-tp4680115p4680120.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYA/yVAAoJENNXIZxhPexG2nwH/3F38+kl+E9l5enSFnmiYYx0
J7zBnK8Zxc5FyKS4bGpfvn+jOa7ivz9aBWBovoarZghboVZ3jdGOHs1wsuInFQyW
/Id09VmZi1ttaxKxIBtFsSJcaGOlnhlBEXCzJZXd14GH/NfS8J0sUx2QsrK3Abr1
ohNTRFJ/ebakXm7moYfx4mLf7vjwm7OHncxX78pLZa0z72GtXpXQy9ZPcSJnF4Nm
U+6N3rYC2qPfsKlOl40qF2mXVIA8fUVZWfii1NqLE+Odid4zW4afpzIRRrz/jbFx
Y/XaQ8GTlJp/xzHXm0+wTOFHKNhYClyp6rYNyWFGhYSJeM8GFYh/LZpDSmUIZFc=
=ESWC
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161017/52e006b6/attachment.key>

From yvoinov at gmail.com  Sun Oct 16 23:20:56 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 17 Oct 2016 05:20:56 +0600
Subject: [squid-users] Squid 2.7 to Squid 3.5
In-Reply-To: <84ecc3f1-a253-ddca-969e-7fd5984ac635@gmail.com>
References: <CAOD59=79vLpfp33x5EWrp=OcWqUvydTH+zQxjZ4dfCLBNwVJmQ@mail.gmail.com>
 <5924f375-7f30-30c5-6a55-5f5ccbc635ab@gmail.com>
 <1476651753025-4680118.post@n4.nabble.com>
 <8b076304-eae7-d619-199d-4c6f844fc688@gmail.com>
 <1476652062820-4680120.post@n4.nabble.com>
 <84ecc3f1-a253-ddca-969e-7fd5984ac635@gmail.com>
Message-ID: <09cdb83d-f6b3-4b0e-f75d-209ee779349d@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
You have in the cryochamber, apparently, there was no internet :) :)
It's not been :)


17.10.2016 4:17, Yuri Voinov ?????:
>
> In _your_ environment :) All world uses DNS caches.... ;)
>
>
> 17.10.2016 3:07, reinerotto ?????:
> > Sorry, I forgot: Another difference is, that response times are
lower today.
> > (BTW: I also did a SM-4 ...)
>
>
>
> > --
> > View this message in context:
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7-to-Squid-3-5-tp4680115p4680120.html
> > Sent from the Squid - Users mailing list archive at Nabble.com.
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYBAtYAAoJENNXIZxhPexG7ZkH/2M//fMMpMAvIJUCn1Ld+0JC
WMOqVMaaQ6JHVH6KC2nLRmpqnX/g0baypqy8/z85BRNQJdnv6Re1PGFCKuO45Ne7
ackHSX5Q6BZ4s8iHp9Drn3n3yf0siDjjSois31LCMlFZiIwgANYr1dYoFaJgIghw
V2kDRauZFK15v/G1FsASEmgWz1r8bd14RH6utHijtGCG+EY9sdtFiqA+mjJ7cFsR
l9jukvXyN2jluJZxxh6yeRqSLg1mKA23vbkf4BdQPMZS6YrT44YC4TJjdb7JQzcY
1GGRwiygvOLM/baaSCXTzL3ZSPiBszdwzPJH8UOOYiHc+CY6g2ScjNHTGCK6blQ=
=YH6E
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161017/78369a74/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161017/78369a74/attachment.key>

From johnnylam0010 at gmail.com  Mon Oct 17 01:27:54 2016
From: johnnylam0010 at gmail.com (Johnny Lam)
Date: Mon, 17 Oct 2016 09:27:54 +0800
Subject: [squid-users] Squid 2.7 to Squid 3.5
In-Reply-To: <09cdb83d-f6b3-4b0e-f75d-209ee779349d@gmail.com>
References: <CAOD59=79vLpfp33x5EWrp=OcWqUvydTH+zQxjZ4dfCLBNwVJmQ@mail.gmail.com>
 <5924f375-7f30-30c5-6a55-5f5ccbc635ab@gmail.com>
 <1476651753025-4680118.post@n4.nabble.com>
 <8b076304-eae7-d619-199d-4c6f844fc688@gmail.com>
 <1476652062820-4680120.post@n4.nabble.com>
 <84ecc3f1-a253-ddca-969e-7fd5984ac635@gmail.com>
 <09cdb83d-f6b3-4b0e-f75d-209ee779349d@gmail.com>
Message-ID: <CAOD59=4+itZj_8uZZxf3=FqSj8CmKYrzNveQZP7Jagn3baKuCA@mail.gmail.com>

Dear all,


Sorry for missing the conf in my previous mail.

Below is my conf in squid 2.7

acl dest dst 10.68.8.146/32
http_access deny !dest
auth_param basic program ../libexec/ncsa_auth.exe ../etc/password.txt
acl User_Authorized proxy_auth REQUIRED
http_access allow User_Authorized

I tried to use the same in 3.5 but seems not work, any idea how should I
handle it ?
As I found that the default conf for Squid 3.5 is quite long, Can I just
remove them all and put my 2.7 config in ?

Hope you guys can help. Many Thanks!

Regards,
Johnny


2016-10-17 7:20 GMT+08:00 Yuri Voinov <yvoinov at gmail.com>:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> You have in the cryochamber, apparently, there was no internet :) :) It's
> not been :)
>
>
> 17.10.2016 4:17, Yuri Voinov ?????:
> >
> > In _your_ environment :) All world uses DNS caches.... ;)
> >
> >
> > 17.10.2016 3:07, reinerotto ?????:
> > > Sorry, I forgot: Another difference is, that response times are lower
> today.
> > > (BTW: I also did a SM-4 ...)
> >
> >
> >
> > > --
> > > View this message in context:
> > http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-
> 7-to-Squid-3-5-tp4680115p4680120.html
> > > Sent from the Squid - Users mailing list archive at Nabble.com.
> > > _______________________________________________
> > > squid-users mailing list
> > > squid-users at lists.squid-cache.org
> > > http://lists.squid-cache.org/listinfo/squid-users
> >
> >
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJYBAtYAAoJENNXIZxhPexG7ZkH/2M//fMMpMAvIJUCn1Ld+0JC
> WMOqVMaaQ6JHVH6KC2nLRmpqnX/g0baypqy8/z85BRNQJdnv6Re1PGFCKuO45Ne7
> ackHSX5Q6BZ4s8iHp9Drn3n3yf0siDjjSois31LCMlFZiIwgANYr1dYoFaJgIghw
> V2kDRauZFK15v/G1FsASEmgWz1r8bd14RH6utHijtGCG+EY9sdtFiqA+mjJ7cFsR
> l9jukvXyN2jluJZxxh6yeRqSLg1mKA23vbkf4BdQPMZS6YrT44YC4TJjdb7JQzcY
> 1GGRwiygvOLM/baaSCXTzL3ZSPiBszdwzPJH8UOOYiHc+CY6g2ScjNHTGCK6blQ=
> =YH6E
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161017/33a43461/attachment.htm>

From johnnylam0010 at gmail.com  Mon Oct 17 08:31:02 2016
From: johnnylam0010 at gmail.com (Johnny Lam)
Date: Mon, 17 Oct 2016 16:31:02 +0800
Subject: [squid-users] Squid 2.7 to Squid 3.5
In-Reply-To: <CAOD59=4+itZj_8uZZxf3=FqSj8CmKYrzNveQZP7Jagn3baKuCA@mail.gmail.com>
References: <CAOD59=79vLpfp33x5EWrp=OcWqUvydTH+zQxjZ4dfCLBNwVJmQ@mail.gmail.com>
 <5924f375-7f30-30c5-6a55-5f5ccbc635ab@gmail.com>
 <1476651753025-4680118.post@n4.nabble.com>
 <8b076304-eae7-d619-199d-4c6f844fc688@gmail.com>
 <1476652062820-4680120.post@n4.nabble.com>
 <84ecc3f1-a253-ddca-969e-7fd5984ac635@gmail.com>
 <09cdb83d-f6b3-4b0e-f75d-209ee779349d@gmail.com>
 <CAOD59=4+itZj_8uZZxf3=FqSj8CmKYrzNveQZP7Jagn3baKuCA@mail.gmail.com>
Message-ID: <CAOD59=5X4RWaKPUWg+r17-uAW-=HMK1B-wjAYONyr5x=kXtEbw@mail.gmail.com>

Some more information,

 - tell us which system / distribution / version you are running this on
I am running it on Windows machine.

Regards,
Johnny


2016-10-17 9:27 GMT+08:00 Johnny Lam <johnnylam0010 at gmail.com>:

> Dear all,
>
>
> Sorry for missing the conf in my previous mail.
>
> Below is my conf in squid 2.7
>
> acl dest dst 10.68.8.146/32
> http_access deny !dest
> auth_param basic program ../libexec/ncsa_auth.exe ../etc/password.txt
> acl User_Authorized proxy_auth REQUIRED
> http_access allow User_Authorized
>
> I tried to use the same in 3.5 but seems not work, any idea how should I
> handle it ?
> As I found that the default conf for Squid 3.5 is quite long, Can I just
> remove them all and put my 2.7 config in ?
>
> Hope you guys can help. Many Thanks!
>
> Regards,
> Johnny
>
>
> 2016-10-17 7:20 GMT+08:00 Yuri Voinov <yvoinov at gmail.com>:
>
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>>
>> You have in the cryochamber, apparently, there was no internet :) :) It's
>> not been :)
>>
>>
>> 17.10.2016 4:17, Yuri Voinov ?????:
>> >
>> > In _your_ environment :) All world uses DNS caches.... ;)
>> >
>> >
>> > 17.10.2016 3:07, reinerotto ?????:
>> > > Sorry, I forgot: Another difference is, that response times are lower
>> today.
>> > > (BTW: I also did a SM-4 ...)
>> >
>> >
>> >
>> > > --
>> > > View this message in context:
>> > http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-2-7
>> -to-Squid-3-5-tp4680115p4680120.html
>> > > Sent from the Squid - Users mailing list archive at Nabble.com.
>> > > _______________________________________________
>> > > squid-users mailing list
>> > > squid-users at lists.squid-cache.org
>> > > http://lists.squid-cache.org/listinfo/squid-users
>> >
>> >
>>
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v2
>>
>> iQEcBAEBCAAGBQJYBAtYAAoJENNXIZxhPexG7ZkH/2M//fMMpMAvIJUCn1Ld+0JC
>> WMOqVMaaQ6JHVH6KC2nLRmpqnX/g0baypqy8/z85BRNQJdnv6Re1PGFCKuO45Ne7
>> ackHSX5Q6BZ4s8iHp9Drn3n3yf0siDjjSois31LCMlFZiIwgANYr1dYoFaJgIghw
>> V2kDRauZFK15v/G1FsASEmgWz1r8bd14RH6utHijtGCG+EY9sdtFiqA+mjJ7cFsR
>> l9jukvXyN2jluJZxxh6yeRqSLg1mKA23vbkf4BdQPMZS6YrT44YC4TJjdb7JQzcY
>> 1GGRwiygvOLM/baaSCXTzL3ZSPiBszdwzPJH8UOOYiHc+CY6g2ScjNHTGCK6blQ=
>> =YH6E
>> -----END PGP SIGNATURE-----
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161017/2997a19c/attachment.htm>

From denizlist at denizeren.net  Mon Oct 17 08:38:41 2016
From: denizlist at denizeren.net (Deniz Eren)
Date: Mon, 17 Oct 2016 11:38:41 +0300
Subject: [squid-users] Squid SMP workers crash
In-Reply-To: <b9ced597-84e5-c16c-4130-c4050d9089cc@measurement-factory.com>
References: <CAHQdsZ805myhBd8_s-1dxvp1eZSv_bhykGj9gwm=_6=WMK8Tew@mail.gmail.com>
 <b9ced597-84e5-c16c-4130-c4050d9089cc@measurement-factory.com>
Message-ID: <CAHQdsZ_NV84Tc50OeW+AL+pr4VmOyxAqwLU3nGuVTArJANLK+Q@mail.gmail.com>

On Fri, Oct 14, 2016 at 1:50 AM, Alex Rousskov
<rousskov at measurement-factory.com> wrote:
> On 10/13/2016 01:53 AM, Deniz Eren wrote:
>
>> I'm using squid's SMP functionality to distribute requests to many
>> squid instances and distribute workload to multiple processors.
>> However while running squid's workers after a while worker processes
>> crash with the error below and coordinator does not start them again:
>> ...
>> FATAL: Ipc::Mem::Segment::open failed to
>> shm_open(/squid-cf__metadata.shm): (2) No such file or directory
>> Squid Cache (Version 3.5.20): Terminated abnormally.
>> ...
>
> Are you saying that this fatal shm_open() error happens after all
> workers have started serving/logging traffic?
Yes, they are serving.

> I would expect to see it
> at startup (first few minutes at the most if you have IPC timeout
> problems).
Both happen. Sometimes it crashes after seconds, but most of the time
it takes 5-10 minutes.


> Does the error always point to squid-cf__metadata.shm?
This error is solved but, below error still happens.
2016/10/17 11:22:37 kid1| assertion failed:
../../src/ipc/AtomicWord.h:71: "Enabled()"

>
> Are you sure that there are no other fatal errors, segmentation faults,
> or similar deathly problems _before_ this error?
> Are you sure your
> startup script does not accidentally start multiple Squid instances that
> compete with each other?
You were right there was a problem with startup script. I'm now
starting with "squid -f /conf/file/path/conffile.conf". However there
is a new problem shown below.
2016/10/17 11:22:37 kid1| assertion failed:
../../src/ipc/AtomicWord.h:71: "Enabled()"

Because of this error workers crash couple of times and after that
coordinator gives up creating workers.

> Check system error logs.
>
> FWIW, Segment::open errors without Segment::create errors are often a
> side-effect of other problems that either prevent Squid from creating
> segments or force Squid to remove created segments (both happen in the
> master process).
>
>
>> permissions are OK in /dev/shm
>
> Do you see any Squid segments there (with reasonable timestamps)?
>
>
>> Also is my way of using SMP functionality correct, since I want to
>> distribute all connections between workers and to listen only specific
>> ports?
>
> Adding "workers N" and avoiding SMP-incompatible features is the right
> way; I do not see any SMP-related problems in your configuration.
>
> Alex.
>


From denizlist at denizeren.net  Mon Oct 17 08:45:30 2016
From: denizlist at denizeren.net (Deniz Eren)
Date: Mon, 17 Oct 2016 11:45:30 +0300
Subject: [squid-users] Squid SMP workers crash
In-Reply-To: <04d101d2273f$f265b3a0$d7311ae0$@ngtech.co.il>
References: <CAHQdsZ805myhBd8_s-1dxvp1eZSv_bhykGj9gwm=_6=WMK8Tew@mail.gmail.com>
 <04d101d2273f$f265b3a0$d7311ae0$@ngtech.co.il>
Message-ID: <CAHQdsZ-DQQ_wAJZBVxnd0gRcHKyao-JMdCancuhEsSZ5QXCfTw@mail.gmail.com>

On Sun, Oct 16, 2016 at 2:57 AM, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> Hey,
>
> I can try to replicate the same configuration removing couple settings just to make it simpler to verify if the issue since it's similar to the next testing lab I have planned.
> Can you give more detail about the OS? CentOS, Ubuntu, Other?
CentOS 5

> If it's a self compiled versions then "squid -v" output.
Squid Cache: Version 3.5.20
Service Name: squid
configure options:  '--build=i686-redhat-linux-gnu'
'--host=i686-redhat-linux-gnu' '--target=i386-redhat-linux-gnu'
'--program-prefix=' '--exec-prefix=/opt/squid'
'--datadir=/opt/squid/share' '--libdir=/opt/squid/lib'
'--libexecdir=/opt/squid/libexec' '--localstatedir=/var'
'--sharedstatedir=/opt/squid/com' '--infodir=/usr/share/info'
'--prefix=/opt/squid' '--exec_prefix=/opt/squid'
'--bindir=/opt/squid/bin' '--sbindir=/opt/squid/sbin'
'--sysconfdir=/opt/squid/etc' '--datadir=/opt/squid/share/squid'
'--includedir=/opt/squid/include' '--libdir=/opt/squid/lib/squid'
'--libexecdir=/opt/squid/lib/squid' '--localstatedir=/opt/squid/var'
'--mandir=/opt/squid/share/man' '--infodir=/opt/squid/share/info'
'--enable-epoll' '--disable-dependency-tracking' '--enable-arp-acl'
'--enable-auth' '--enable-auth-negotiate' '--enable-auth-digest'
'--enable-auth-basic' '--enable-auth-ntlm' '--enable-cache-digests'
'--enable-cachemgr-hostname=localhost' '--enable-delay-pools'
'--enable-external-acl-helpers' '--enable-icap-client'
'--with-large-files' '--enable-linux-netfilter' '--enable-referer-log'
'--enable-removal-policies=heap,lru' '--enable-snmp' '--enable-ssl'
'--enable-storeio=aufs,diskd,ufs' '--enable-useragent-log'
'--enable-wccpv2' '--with-aio' '--with-default-user=squid'
'--with-filedescriptors=32768' '--with-dl' '--enable-ssl-crtd'
'--with-openssl=/opt/openssl101' '--with-pthreads'
'--enable-http-violations' '--enable-follow-x-forwarded-for'
'--disable-ipv6' 'build_alias=i686-redhat-linux-gnu'
'host_alias=i686-redhat-linux-gnu'
'target_alias=i386-redhat-linux-gnu' 'CFLAGS=-fPIE -Os -g -pipe
-fsigned-char -I /usr/kerberos/include -I/opt/openssl101/include -O2
-g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
--param=ssp-buffer-size=4 -m32 -march=i386 -mtune=generic
-fasynchronous-unwind-tables' 'LDFLAGS=-pie -L/opt/openssl101/lib'
'CXXFLAGS=-fPIE -I/opt/openssl101/include -O2 -g -pipe -Wall
-Wp,-D_FORTIFY_SOURCE=2 -fexceptions -fstack-protector
--param=ssp-buffer-size=4 -m32 -march=i386 -mtune=generic
-fasynchronous-unwind-tables'
'PKG_CONFIG_PATH=/opt/squid/lib/pkgconfig:/opt/squid/share/pkgconfig'
--enable-ltdl-convenience


> I have also seen that you are intercepting both http and https traffic, have you tried looking at the logs?
You are right I'm intercepting both http and https traffic. Yes I have
looked at logs and only suspicious thing is this line:
2016/10/17 11:22:37 kid1| assertion failed:
../../src/ipc/AtomicWord.h:71: "Enabled()"

>
> If you don't hear me from me fast enough just bump me with an email.
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile+WhatsApp: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Deniz Eren
> Sent: Thursday, October 13, 2016 10:53 AM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Squid SMP workers crash
>
> Hi,
>
> I'm using squid's SMP functionality to distribute requests to many
> squid instances and distribute workload to multiple processors.
> However while running squid's workers after a while worker processes
> crash with the error below and coordinator does not start them again:
> ...
> FATAL: Ipc::Mem::Segment::open failed to
> shm_open(/squid-cf__metadata.shm): (2) No such file or directory
> Squid Cache (Version 3.5.20): Terminated abnormally.
> ...
>
> Does a solution exists for this problem? (permissions are OK in /dev/shm)
>
>
> When everything is OK coordinator listens to http_ports/https_port and
> distributes connections to workers(at least that's the conclusion I
> got from looking access.logs).
> [root at squidbox ~]# netstat -nlp|grep squid
> tcp        0      0 0.0.0.0:8080                0.0.0.0:*
>      LISTEN      7887/(squid-coord-1
> tcp        0      0 0.0.0.0:3127                0.0.0.0:*
>      LISTEN      7887/(squid-coord-1
> tcp        0      0 0.0.0.0:3128                0.0.0.0:*
>      LISTEN      7887/(squid-coord-1
> tcp        0      0 0.0.0.0:3130                0.0.0.0:*
>      LISTEN      7887/(squid-coord-1
> tcp        0      0 0.0.0.0:8443                0.0.0.0:*
>      LISTEN      7887/(squid-coord-1
> udp        0      0 0.0.0.0:57850               0.0.0.0:*
>                  7897/(squid-1)
> udp        0      0 0.0.0.0:33643               0.0.0.0:*
>                  7894/(squid-4)
> udp        0      0 0.0.0.0:50485               0.0.0.0:*
>                  7896/(squid-2)
> udp        0      0 0.0.0.0:46427               0.0.0.0:*
>                  7887/(squid-coord-1
> udp        0      0 0.0.0.0:58938               0.0.0.0:*
>                  7895/(squid-3)
>
>
> Also is my way of using SMP functionality correct, since I want to
> distribute all connections between workers and to listen only specific
> ports?
>
> I have attached the squid.conf.
>
> Regards,
>


From rousskov at measurement-factory.com  Mon Oct 17 16:43:12 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 17 Oct 2016 10:43:12 -0600
Subject: [squid-users] Squid SMP workers crash
In-Reply-To: <CAHQdsZ_NV84Tc50OeW+AL+pr4VmOyxAqwLU3nGuVTArJANLK+Q@mail.gmail.com>
References: <CAHQdsZ805myhBd8_s-1dxvp1eZSv_bhykGj9gwm=_6=WMK8Tew@mail.gmail.com>
 <b9ced597-84e5-c16c-4130-c4050d9089cc@measurement-factory.com>
 <CAHQdsZ_NV84Tc50OeW+AL+pr4VmOyxAqwLU3nGuVTArJANLK+Q@mail.gmail.com>
Message-ID: <e5569764-af99-e286-0458-73cd8068d87f@measurement-factory.com>

On 10/17/2016 02:38 AM, Deniz Eren wrote:
> 2016/10/17 11:22:37 kid1| assertion failed:
> ../../src/ipc/AtomicWord.h:71: "Enabled()"

Either your Squid does not support SMP (a build environment problem) or
Squid is trying to use SMP features when SMP is not enabled (a Squid bug).

What does the following command show?

  fgrep -RI HAVE_ATOMIC_OPS config.status include/autoconf.h

(adjust filename paths as needed).

Alex.



From jlay at slave-tothe-box.net  Mon Oct 17 17:51:52 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Mon, 17 Oct 2016 11:51:52 -0600
Subject: [squid-users] Additional ecap/icap questions
Message-ID: <d573a941f8ab91b781b4d2f7fadc8b3b@localhost>

Well this has been a pretty amazing bit of learning that's for sure.  
Here's what I'm wanting to accomplish and it's been proving a challenge: 
  Detect keywords (think DLP maybe) in http/https flows.  I've got ecap 
and icap compiled in and working.  My challenges:

a)with icap, it appears that the filter content adapters only work with 
responses, not requests....I need both.
b)with icap, if I use the "echo" adapter I can see everything on the lo 
interface, but decoding it has proven fruitless for me
c)with ecap, I configured per 
http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/eCAP, but 
I'm confused on the ecap_service line..examples show 
"ecap://www.vigos.com/ecap_gzip", but what do I put in?  I thought I 
didn't need a service for ecap..do I point this to localhost or 
something?

Anyway thank you.


From rousskov at measurement-factory.com  Mon Oct 17 21:01:08 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 17 Oct 2016 15:01:08 -0600
Subject: [squid-users] Additional ecap/icap questions
In-Reply-To: <d573a941f8ab91b781b4d2f7fadc8b3b@localhost>
References: <d573a941f8ab91b781b4d2f7fadc8b3b@localhost>
Message-ID: <4728c323-1d23-b2f7-f5cb-e1f1cc05ddc5@measurement-factory.com>

On 10/17/2016 11:51 AM, James Lay wrote:

> Here's what I'm wanting to accomplish and it's been proving a challenge:
>  Detect keywords (think DLP maybe) in http/https flows.  I've got ecap
> and icap compiled in and working.  My challenges:
> 
> a)with icap, it appears that the filter content adapters only work with
> responses, not requests....I need both.

It depends on the ICAP service. Some work with requests, some with
responses, some with both kinds of messages.


> b)with icap, if I use the "echo" adapter I can see everything on the lo
> interface, but decoding it has proven fruitless for me

If you are trying to manually decode ICAP traffic on a loopback
interface, please clarify what you are trying to accomplish with that.


> c)with ecap, I configured per
> http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/eCAP, 
> but I'm confused on the ecap_service line..examples show
> "ecap://www.vigos.com/ecap_gzip", but what do I put in?  

Just like with ICAP, you configure an eCAP adapter/service that you want
to use. I do not know whether it exists or needs to be written. For
example, if you want to find viruses, you can use an eCAP ClamAV adapter.


> I thought I
> didn't need a service for ecap..do I point this to localhost or something?

With eCAP, you do not need a server. With both ICAP and eCAP you need a
service or "adapter" that does whatever you want to do. ICAP and eCAP
are just protocols/API -- they cannot do anything useful on their own.

The eCAP service URI is just an identifier. It does not "point" to any
specific location. It is only used to distinguish one loaded eCAP
service from another loaded eCAP service.


Overall, you need some software that will "detect keywords". That
detection is not going to happen magically on its own. ICAP and eCAP are
just two ways to get the HTTP messages to that software. Some call that
_kind_ of software "ICAP service", "ICAP server plugin", "eCAP service",
"eCAP adapter", etc. You need to find or write a specific
service/plugin/adapter/etc. that does keyword detection.

Alex.



From johnnylam0010 at gmail.com  Tue Oct 18 00:01:58 2016
From: johnnylam0010 at gmail.com (Johnny Lam)
Date: Tue, 18 Oct 2016 08:01:58 +0800
Subject: [squid-users] Squid 3.5 conf
Message-ID: <CAOD59=6p2dUQoMw2QM3HGiFcDfWfnUAhPFQLixqY5BW67wXVRQ@mail.gmail.com>

Dear all,


Sorry for missing the conf in my previous mail.

Below is my conf in squid 2.7

acl dest dst 10.68.8.146/32
http_access deny !dest
auth_param basic program ../libexec/ncsa_auth.exe ../etc/password.txt
acl User_Authorized proxy_auth REQUIRED
http_access allow User_Authorized

I tried to use the same in 3.5 but seems not work, any idea how should I
handle it ?
As I found that the default conf for Squid 3.5 is quite long, Can I just
remove them all and put my 2.7 config in ?

Hope you guys can help. Many Thanks!



-- 
Regards,
Johnny
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161018/b3ea6be5/attachment.htm>

From squid-user at tlinx.org  Tue Oct 18 03:41:27 2016
From: squid-user at tlinx.org (L. A. Walsh)
Date: Mon, 17 Oct 2016 20:41:27 -0700
Subject: [squid-users] FYI - primitive hit-rate results w/sslbump vs. not
Message-ID: <580599E7.1080102@tlinx.org>


Just as an FYI, I did a test today of squid's efficacy with
the ssl-bumping feature.  This is a preliminary result with
little or no review of the logs -- just going by access log
entries. 

I was interested because I've been running squid @ home for over
10 years to try to squeeze speed out of a home connection using
a largish-cache (at least for 1-2 users) of around 80G used
on a dedicated, 128G partition.

Over the years, I've gotten a vague feeling for what to expect and
have generally gotten around a 15-30% cache hit ratio. 

This dropped as google pushed https.  I noticed the web slowing
as my local cache hit-rate dropped and encryption overhead increased
request latency.

This was somewhat unscientific, but not so much in that it
does reflect a part of my traffic. 
I opened a bunch of (30+) news articles from news.google.com w/
my new ssl-bumping enabled and decided I wanted to get an idea of
cache-hit differences.  So changed proxy to go through a
non-bumping port and used the browser's saved-session
to quit the browser and restart all the tabs -- twice --
once for the https test, and a 2nd time for a repeat test.

Results:

Intial opening of the sites w/ssl bump got   730/3365   hits/requests.

The reload in solid https-CONNECT streams showed   40/1588 hits/requests.

And the 2nd reload of the same sites got    1268/2263 hits/requests. 

In percentages:

cold-view w/SSL-bump: 22% hit
no SSL-bump:           3% hit
repeat w/SSL-bump:    56% hit


Simply inter/intra-site redundancy resulted in 22% cache-hit
ratio, with a "semi-real" case of bringing up the same content
a second time, gave a 56% hit rate.

I'll have to see if how hard it is to get byte counts out of my
logs to get more detail, but since many of these request are small
there is a large delay caused / request.

FWIW, using a FF-clone (64-bit Palemoon) with no local disk cache
(it does have a memory cache, but that would have been cleared
between runs when I restarted the browser).

Initial results look good for using squid to subvert google's
campaign to keep your webtraffic content hidden, but mostly
from "you".















From denizlist at denizeren.net  Tue Oct 18 04:37:35 2016
From: denizlist at denizeren.net (Deniz Eren)
Date: Tue, 18 Oct 2016 07:37:35 +0300
Subject: [squid-users] Squid SMP workers crash
In-Reply-To: <e5569764-af99-e286-0458-73cd8068d87f@measurement-factory.com>
References: <CAHQdsZ805myhBd8_s-1dxvp1eZSv_bhykGj9gwm=_6=WMK8Tew@mail.gmail.com>
 <b9ced597-84e5-c16c-4130-c4050d9089cc@measurement-factory.com>
 <CAHQdsZ_NV84Tc50OeW+AL+pr4VmOyxAqwLU3nGuVTArJANLK+Q@mail.gmail.com>
 <e5569764-af99-e286-0458-73cd8068d87f@measurement-factory.com>
Message-ID: <CAHQdsZ9dOqXxc9Z=wox8sgMHfasg-qNxpr7Y-ewO=o-_WZ0uEg@mail.gmail.com>

On Mon, Oct 17, 2016 at 7:43 PM, Alex Rousskov
<rousskov at measurement-factory.com> wrote:
> On 10/17/2016 02:38 AM, Deniz Eren wrote:
>> 2016/10/17 11:22:37 kid1| assertion failed:
>> ../../src/ipc/AtomicWord.h:71: "Enabled()"
>
> Either your Squid does not support SMP (a build environment problem) or
> Squid is trying to use SMP features when SMP is not enabled (a Squid bug).
>
> What does the following command show?
>
>   fgrep -RI HAVE_ATOMIC_OPS config.status include/autoconf.h
fgrep -RI HAVE_ATOMIC_OPS config.status include/autoconf.h
config.status:D["HAVE_ATOMIC_OPS"]=" 0"
include/autoconf.h:#define HAVE_ATOMIC_OPS 0

>
> (adjust filename paths as needed).
>
> Alex.
>


From squid3 at treenet.co.nz  Tue Oct 18 05:03:29 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 18 Oct 2016 18:03:29 +1300
Subject: [squid-users] Squid 2.7 to Squid 3.5
In-Reply-To: <CAOD59=4+itZj_8uZZxf3=FqSj8CmKYrzNveQZP7Jagn3baKuCA@mail.gmail.com>
References: <CAOD59=79vLpfp33x5EWrp=OcWqUvydTH+zQxjZ4dfCLBNwVJmQ@mail.gmail.com>
 <5924f375-7f30-30c5-6a55-5f5ccbc635ab@gmail.com>
 <1476651753025-4680118.post@n4.nabble.com>
 <8b076304-eae7-d619-199d-4c6f844fc688@gmail.com>
 <1476652062820-4680120.post@n4.nabble.com>
 <84ecc3f1-a253-ddca-969e-7fd5984ac635@gmail.com>
 <09cdb83d-f6b3-4b0e-f75d-209ee779349d@gmail.com>
 <CAOD59=4+itZj_8uZZxf3=FqSj8CmKYrzNveQZP7Jagn3baKuCA@mail.gmail.com>
Message-ID: <2c85eedb-68c1-1b57-8038-a1bdebf113bc@treenet.co.nz>

On 17/10/2016 2:27 p.m., Johnny Lam wrote:
> Dear all,
> 
> 
> Sorry for missing the conf in my previous mail.
> 
> Below is my conf in squid 2.7
> 
> acl dest dst 10.68.8.146/32
> http_access deny !dest
> auth_param basic program ../libexec/ncsa_auth.exe ../etc/password.txt
> acl User_Authorized proxy_auth REQUIRED
> http_access allow User_Authorized
> 
> I tried to use the same in 3.5 but seems not work, any idea how should I
> handle it ?
> As I found that the default conf for Squid 3.5 is quite long, Can I just
> remove them all and put my 2.7 config in ?

Yes you can do that. Run squid -k parse after doing so and fix the
errors that are logged.

I think it is the auth helper name that is the main error here. The
squid-3.5 equivalent of that helper is called basic_nsca_auth.exe for
your OS.


FYI: the minimal default Squid-3 config can be found at
<http://wiki.squid-cache.org/Squid-3.5>

I recommend you copy those 2.7 settings into the line marked as "INSERT
YOUR OWN RULE(S) HERE" instead of using the above 2.7 conf as-is.

Amos


From rousskov at measurement-factory.com  Tue Oct 18 05:16:27 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 17 Oct 2016 23:16:27 -0600
Subject: [squid-users] Squid SMP workers crash
In-Reply-To: <CAHQdsZ9dOqXxc9Z=wox8sgMHfasg-qNxpr7Y-ewO=o-_WZ0uEg@mail.gmail.com>
References: <CAHQdsZ805myhBd8_s-1dxvp1eZSv_bhykGj9gwm=_6=WMK8Tew@mail.gmail.com>
 <b9ced597-84e5-c16c-4130-c4050d9089cc@measurement-factory.com>
 <CAHQdsZ_NV84Tc50OeW+AL+pr4VmOyxAqwLU3nGuVTArJANLK+Q@mail.gmail.com>
 <e5569764-af99-e286-0458-73cd8068d87f@measurement-factory.com>
 <CAHQdsZ9dOqXxc9Z=wox8sgMHfasg-qNxpr7Y-ewO=o-_WZ0uEg@mail.gmail.com>
Message-ID: <203e89fd-c1b7-3b02-1b30-d66505e24ff0@measurement-factory.com>

On 10/17/2016 10:37 PM, Deniz Eren wrote:
> On Mon, Oct 17, 2016 at 7:43 PM, Alex Rousskov wrote:
>> On 10/17/2016 02:38 AM, Deniz Eren wrote:
>>> 2016/10/17 11:22:37 kid1| assertion failed:
>>> ../../src/ipc/AtomicWord.h:71: "Enabled()"
>>
>> Either your Squid does not support SMP (a build environment problem) or
>> Squid is trying to use SMP features when SMP is not enabled (a Squid bug).
>>
>> What does the following command show?
>>
>>   fgrep -RI HAVE_ATOMIC_OPS config.status include/autoconf.h
> fgrep -RI HAVE_ATOMIC_OPS config.status include/autoconf.h
> config.status:D["HAVE_ATOMIC_OPS"]=" 0"
> include/autoconf.h:#define HAVE_ATOMIC_OPS 0

Your Squid does not support SMP. The ./configure script failed to find
the necessary APIs for SMP support. I wish Squid would tell you that in
a less obscure way than an Enabled() assertion; feel free to file a bug
report about that, but that is a reporting/UI problem; the assertion
itself is correct.

I do not know why your build environment lacks atomics support (or why
Squid cannot detect that support), but I hope that others on the mailing
list would be able to help you with that investigation.


Finally, in the interest of full disclosure, I have to note that, IIRC,
atomics are not actually required for some of the primitive SMP
features, but Squid attempts to create a few shared memory tables even
when those tables are not needed, and those tables do require atomics
(and will hit the Enabled() assertion you have reported).

There have been improvements in this area; eventually no unnecessary
shared memory tables will be created, but it is probably easier for you
to get a build with working atomics (usually does not require any
development) than to get rid of those tables (which probably require
more development).

Alex.



From squid3 at treenet.co.nz  Tue Oct 18 05:49:26 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 18 Oct 2016 18:49:26 +1300
Subject: [squid-users] Squid SMP workers crash
In-Reply-To: <203e89fd-c1b7-3b02-1b30-d66505e24ff0@measurement-factory.com>
References: <CAHQdsZ805myhBd8_s-1dxvp1eZSv_bhykGj9gwm=_6=WMK8Tew@mail.gmail.com>
 <b9ced597-84e5-c16c-4130-c4050d9089cc@measurement-factory.com>
 <CAHQdsZ_NV84Tc50OeW+AL+pr4VmOyxAqwLU3nGuVTArJANLK+Q@mail.gmail.com>
 <e5569764-af99-e286-0458-73cd8068d87f@measurement-factory.com>
 <CAHQdsZ9dOqXxc9Z=wox8sgMHfasg-qNxpr7Y-ewO=o-_WZ0uEg@mail.gmail.com>
 <203e89fd-c1b7-3b02-1b30-d66505e24ff0@measurement-factory.com>
Message-ID: <529c95cd-993b-cf13-8b9f-e269604176e4@treenet.co.nz>

On 18/10/2016 6:16 p.m., Alex Rousskov wrote:
> On 10/17/2016 10:37 PM, Deniz Eren wrote:
>> On Mon, Oct 17, 2016 at 7:43 PM, Alex Rousskov wrote:
>>> On 10/17/2016 02:38 AM, Deniz Eren wrote:
>>>> 2016/10/17 11:22:37 kid1| assertion failed:
>>>> ../../src/ipc/AtomicWord.h:71: "Enabled()"
>>>
>>> Either your Squid does not support SMP (a build environment problem) or
>>> Squid is trying to use SMP features when SMP is not enabled (a Squid bug).
>>>
>>> What does the following command show?
>>>
>>>   fgrep -RI HAVE_ATOMIC_OPS config.status include/autoconf.h
>> fgrep -RI HAVE_ATOMIC_OPS config.status include/autoconf.h
>> config.status:D["HAVE_ATOMIC_OPS"]=" 0"
>> include/autoconf.h:#define HAVE_ATOMIC_OPS 0
> 
> Your Squid does not support SMP. The ./configure script failed to find
> the necessary APIs for SMP support. I wish Squid would tell you that in
> a less obscure way than an Enabled() assertion; feel free to file a bug
> report about that, but that is a reporting/UI problem; the assertion
> itself is correct.
> 
> I do not know why your build environment lacks atomics support (or why
> Squid cannot detect that support), but I hope that others on the mailing
> list would be able to help you with that investigation.

It is based on Linux 2.6.18, which has some big multi-processor support
issues. What M-P support existed was largely still based on the
"Big-Lock" design which made it horribly slow and inefficient.

> 
> Finally, in the interest of full disclosure, I have to note that, IIRC,
> atomics are not actually required for some of the primitive SMP
> features, but Squid attempts to create a few shared memory tables even
> when those tables are not needed, and those tables do require atomics
> (and will hit the Enabled() assertion you have reported).
> 
> There have been improvements in this area; eventually no unnecessary
> shared memory tables will be created, but it is probably easier for you
> to get a build with working atomics (usually does not require any
> development) than to get rid of those tables (which probably require
> more development).
> 

It may be as simple as the compiler version - CentOS 5 came with GCC 3.
Squid-3 requires GCC 4.

Either way the config.log produced during build will be needed to figure
out the reasons.

Amos



From walter.h at mathemainzel.info  Tue Oct 18 11:02:24 2016
From: walter.h at mathemainzel.info (Walter H.)
Date: Tue, 18 Oct 2016 13:02:24 +0200
Subject: [squid-users] CentOS 6.x and SELinux enforcing with Squid 3.5.x
 (thanks to Eliezer Croitoru for the RPM)
Message-ID: <f98aa37f0b856130eeda03d1bcbdbf36.1476788544@squirrel.mail>

Hello,

just in case anybody wants to run Squid 3.5.x on CentOS
with SELinux enforcing,

here is the semodule

<squid_update.tt>
module squid_update 1.0;

require {
        type squid_conf_t;
        type squid_t;
        type var_t;
        class file { append open read write getattr lock execute_no_trans };
}

#============= squid_t ==============
allow squid_t squid_conf_t:file execute_no_trans;
allow squid_t var_t:file { append open read write getattr lock };
</squid_update.tt>

and do the following:

checkmodule -M -m -o squid_update.mod squid_update.tt
semodule_package -o squid_update.pp -m squid_update.mod
semodule -i squid_update.pp

in case someone wants to throw away the cache, whatever reason;

use this script:

<clearcache.sh>
#!/bin/sh

DIR=/var/spool/squid

service squid stop
mv $DIR $DIR.temp
mkdir $DIR
chcon -t squid_cache_t $DIR
chown squid:squid $DIR
chmod 750 $DIR
squid -N -z
service squid start
rm -fr $DIR.temp
date +"%Y/%m/%d %T| Old Swap Directories removed"
</clearcache.sh>



From garryd at comnet.uz  Tue Oct 18 11:31:19 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Tue, 18 Oct 2016 16:31:19 +0500
Subject: [squid-users] CentOS 6.x and SELinux enforcing with Squid 3.5.x
 (thanks to Eliezer Croitoru for the RPM)
In-Reply-To: <f98aa37f0b856130eeda03d1bcbdbf36.1476788544@squirrel.mail>
References: <f98aa37f0b856130eeda03d1bcbdbf36.1476788544@squirrel.mail>
Message-ID: <1476790279.32374.4.camel@comnet.uz>

On Tue, 2016-10-18 at 13:02 +0200, Walter H. wrote:
> Hello,
> 
> just in case anybody wants to run Squid 3.5.x on CentOS
> with SELinux enforcing,
> 
> here is the semodule
> 
> <squid_update.tt>
> module squid_update 1.0;
> 
> require {
> ????????type squid_conf_t;
> ????????type squid_t;
> ????????type var_t;
> ????????class file { append open read write getattr lock
> execute_no_trans };
> }
> 
> #============= squid_t ==============
> allow squid_t squid_conf_t:file execute_no_trans;
> allow squid_t var_t:file { append open read write getattr lock };
> </squid_update.tt>
> 
> and do the following:
> 
> checkmodule -M -m -o squid_update.mod squid_update.tt
> semodule_package -o squid_update.pp -m squid_update.mod
> semodule -i squid_update.pp

Hi,

Have you tried to use default policy and relabel target dirs/files
using types dedicated for squid? For example:

# semanage fcontext -l | grep squid
/etc/squid(/.*)????????????????????????????????????all
files??????????system_u:object_r:squid_conf_t:s0?
/var/run/squid.*???????????????????????????????????all
files??????????system_u:object_r:squid_var_run_t:s0?
/var/log/squid(/.*)????????????????????????????????all
files??????????system_u:object_r:squid_log_t:s0?
/usr/share/squid(/.*)??????????????????????????????all
files??????????system_u:object_r:squid_conf_t:s0?
/var/cache/squid(/.*)??????????????????????????????all
files??????????system_u:object_r:squid_cache_t:s0?
/var/spool/squid(/.*)??????????????????????????????all
files??????????system_u:object_r:squid_cache_t:s0?
/usr/sbin/squid????????????????????????????????????regular
file???????system_u:object_r:squid_exec_t:s0?
/etc/rc\.d/init\.d/squid???????????????????????????regular
file???????system_u:object_r:squid_initrc_exec_t:s0?
/usr/lib/squid/cachemgr\.cgi???????????????????????regular
file???????system_u:object_r:httpd_squid_script_exec_t:s0?
/usr/lib64/squid/cachemgr\.cgi?????????????????????regular
file???????system_u:object_r:httpd_squid_script_exec_t:s0?



From walter.h at mathemainzel.info  Tue Oct 18 12:56:03 2016
From: walter.h at mathemainzel.info (Walter H.)
Date: Tue, 18 Oct 2016 14:56:03 +0200
Subject: [squid-users] CentOS 6.x and SELinux enforcing with Squid 3.5.x
 (thanks to Eliezer Croitoru for the RPM)
In-Reply-To: <1476790279.32374.4.camel@comnet.uz>
References: <f98aa37f0b856130eeda03d1bcbdbf36.1476788544@squirrel.mail>
 <1476790279.32374.4.camel@comnet.uz>
Message-ID: <b30b2d268e76cb10a2826ba1677b8cc2.1476795363@squirrel.mail>

On Tue, October 18, 2016 13:31, Garri Djavadyan wrote:
> On Tue, 2016-10-18 at 13:02 +0200, Walter H. wrote:
>> Hello,
>>
>> just in case anybody wants to run Squid 3.5.x on CentOS
>> with SELinux enforcing,
>>
>> here is the semodule
>>
>> <squid_update.tt>
>> module squid_update 1.0;
>>
>> require {
>> ????????type squid_conf_t;
>> ????????type squid_t;
>> ????????type var_t;
>> ????????class file { append open read write getattr lock
>> execute_no_trans };
>> }
>>
>> #============= squid_t ==============
>> allow squid_t squid_conf_t:file execute_no_trans;
>> allow squid_t var_t:file { append open read write getattr lock };
>> </squid_update.tt>
>>
>> and do the following:
>>
>> checkmodule -M -m -o squid_update.mod squid_update.tt
>> semodule_package -o squid_update.pp -m squid_update.mod
>> semodule -i squid_update.pp
>
> Hi,
>
> Have you tried to use default policy and relabel target dirs/files
> using types dedicated for squid? For example:
>
> # semanage fcontext -l | grep squid
> ...

my output differs a little bit; and yes the target files/dirs are labeled
as dedicated;

don't ask me why, but I have two CentOS 6.x VMs (each latest) one with the
official package (release 3.1.23) and one with this 3.5.20 RPM package;

with the 3.1.x there is no problem with
<squid.conf>
url_rewrite_program /etc/squid/url-rewrite-program.pl
url_rewrite_children 8
url_rewrite_host_header on
url_rewrite_access allow all
</squid.conf>
but with the 3.5.x there is access denied (shown in /var/log/audit/audit.log)
and squid doesn't start;

specific to the 3.5.x release, I added a certificate validator helper,
which has also problems ...

with this semodule package everything works fine ...

so there must be something different, between these two releases;

with SELinux disabled or permissive there is no need of this semodule
package;

Greetings,
Walter




From jinju.george at gmail.com  Tue Oct 18 13:05:18 2016
From: jinju.george at gmail.com (georgej)
Date: Tue, 18 Oct 2016 06:05:18 -0700 (PDT)
Subject: [squid-users] Squid is not responding when the number
	of	connection exceeds
In-Reply-To: <04e301d22746$3e0e6350$ba2b29f0$@ngtech.co.il>
References: <1476420540608-4680091.post@n4.nabble.com>
 <b035c66e-21f5-00e8-6e4e-2a65ef64d275@treenet.co.nz>
 <1476452546054-4680102.post@n4.nabble.com>
 <1476452688219-4680103.post@n4.nabble.com>
 <04e301d22746$3e0e6350$ba2b29f0$@ngtech.co.il>
Message-ID: <1476795918727-4680139.post@n4.nabble.com>

Hi Eliezer,

Thanks for your reply.

I made the changes as per your suggestion. But again i faced the same issue.
Then i used another ISP link to test the load. Now its seems to be working
fine. I will put it on live later and let you know the status.

ulimit -a
core file size          (blocks, -c) 0
data seg size           (kbytes, -d) unlimited
scheduling priority             (-e) 0
file size               (blocks, -f) unlimited
pending signals                 (-i) 7369
max locked memory       (kbytes, -l) 64
max memory size         (kbytes, -m) unlimited
open files                      (-n) 65535
pipe size            (512 bytes, -p) 8
POSIX message queues     (bytes, -q) 819200
real-time priority              (-r) 0
stack size              (kbytes, -s) 10240
cpu time               (seconds, -t) unlimited
max user processes              (-u) 65535
virtual memory          (kbytes, -v) unlimited
file locks                      (-x) unlimited

Thanks,
George



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-is-not-responding-when-the-number-of-connection-exceeds-tp4680091p4680139.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From unixdeaf at gmail.com  Tue Oct 18 13:32:47 2016
From: unixdeaf at gmail.com (John Wright)
Date: Tue, 18 Oct 2016 09:32:47 -0400
Subject: [squid-users] Squid 4.x and Peek and Splice - Host Header Forgery
Message-ID: <CACU80L58pwzAnfo+yf+vVZrfZ=MFtKqJ=WtTWgn7x_1dDuE_7g@mail.gmail.com>

Hi,

I have a constant problem with Host header forgery detection on squid doing
peek and splice.

I see this most commonly with CDN, Amazon and microsoft due to the fact
there TTL is only 5 seconds on certain dns entries im connecting to.  So
when my client connects through my squid i get host header issues due to
the contstant dns changes at these destinations.

I have ready many things online but how do i get around this.  I basically
want to allow certain domains or ip subnets to not hit the host header
error (as things break at this point for me ).

Any ideas ?

One example is

sls.update.microsoft.com

Yes my client and Squid use same DNS server, i have even setup my squid as
a bind server and tried that just for fun same issue.  Fact is the DNS at
these places changes so fast (5 seconds) the dns response keeps changing/


I just need these approved destinations to make it through
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161018/3ae3eac4/attachment.htm>

From garryd at comnet.uz  Tue Oct 18 13:35:12 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Tue, 18 Oct 2016 18:35:12 +0500
Subject: [squid-users] CentOS 6.x and SELinux enforcing with Squid 3.5.x
 (thanks to Eliezer Croitoru for the RPM)
In-Reply-To: <b30b2d268e76cb10a2826ba1677b8cc2.1476795363@squirrel.mail>
References: <f98aa37f0b856130eeda03d1bcbdbf36.1476788544@squirrel.mail>
 <1476790279.32374.4.camel@comnet.uz>
 <b30b2d268e76cb10a2826ba1677b8cc2.1476795363@squirrel.mail>
Message-ID: <1476797712.32374.11.camel@comnet.uz>

On Tue, 2016-10-18 at 14:56 +0200, Walter H. wrote:
> with the 3.1.x there is no problem with
> <squid.conf>
> url_rewrite_program /etc/squid/url-rewrite-program.pl
> url_rewrite_children 8
> url_rewrite_host_header on
> url_rewrite_access allow all
> </squid.conf>
> but with the 3.5.x there is access denied (shown in
> /var/log/audit/audit.log)
> and squid doesn't start;
> 
> specific to the 3.5.x release, I added a certificate validator
> helper,
> which has also problems ...
>?
> 
> Greetings,
> Walter

Hi Walter,

Have you tried to move helpers to '/usr/lib64/squid/' and ensure that
the label for them is 'lib_t'?

Garri


From erdosain9 at gmail.com  Tue Oct 18 13:37:35 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 18 Oct 2016 06:37:35 -0700 (PDT)
Subject: [squid-users] Error DiskThreadsDiskFile::openDone: (2) No such file
	or directory
Message-ID: <1476797855466-4680142.post@n4.nabble.com>

Hi.
squid 3.5.20

Im having a lot of these in cache.log

2016/10/18 10:36:11 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:11 kid1|       /var/spool/squid/00/92/000092E9
2016/10/18 10:36:14 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:14 kid1|       /var/spool/squid/00/AA/0000AA46
2016/10/18 10:36:16 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:16 kid1|       /var/spool/squid/00/AA/0000AA48
2016/10/18 10:36:16 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:16 kid1|       /var/spool/squid/00/AA/0000AA49
2016/10/18 10:36:16 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:16 kid1|       /var/spool/squid/00/AA/0000AA4B
2016/10/18 10:36:16 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:16 kid1|       /var/spool/squid/00/AA/0000AA4C
2016/10/18 10:36:20 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:20 kid1|       /var/spool/squid/00/AA/0000AA60
2016/10/18 10:36:21 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:21 kid1|       /var/spool/squid/00/AA/0000AA67
2016/10/18 10:36:21 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:21 kid1|       /var/spool/squid/00/AA/0000AA66
2016/10/18 10:36:21 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:21 kid1|       /var/spool/squid/00/AA/0000AA65
2016/10/18 10:36:33 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:33 kid1|       /var/spool/squid/00/AA/0000AA10
2016/10/18 10:36:33 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:33 kid1|       /var/spool/squid/00/AA/0000AA8C
2016/10/18 10:36:33 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:33 kid1|       /var/spool/squid/00/AA/0000AA98
2016/10/18 10:36:33 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:33 kid1|       /var/spool/squid/00/AA/0000AA18
2016/10/18 10:36:33 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:33 kid1|       /var/spool/squid/00/AA/0000AA93
2016/10/18 10:36:33 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:33 kid1|       /var/spool/squid/00/AA/0000AA9A
2016/10/18 10:36:34 kid1| DiskThreadsDiskFile::openDone: (2) No such file or
directory
2016/10/18 10:36:34 kid1|       /var/spool/squid/00/70/0000704B

What can i do?? thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Error-DiskThreadsDiskFile-openDone-2-No-such-file-or-directory-tp4680142.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From fredbmail at free.fr  Tue Oct 18 14:04:53 2016
From: fredbmail at free.fr (FredB)
Date: Tue, 18 Oct 2016 16:04:53 +0200 (CEST)
Subject: [squid-users] Error DiskThreadsDiskFile::openDone: (2) No such
 file	or directory
In-Reply-To: <1476797855466-4680142.post@n4.nabble.com>
Message-ID: <2061366482.1008747640.1476799493488.JavaMail.root@zimbra4-e1.priv.proxad.net>

Aufs ?

Fred


From isnard_magali at yahoo.fr  Tue Oct 18 15:42:15 2016
From: isnard_magali at yahoo.fr (magali isnard)
Date: Tue, 18 Oct 2016 15:42:15 +0000 (UTC)
Subject: [squid-users] squid change "method patch" to "method other"
References: <254945056.1248098.1476805335319.ref@mail.yahoo.com>
Message-ID: <254945056.1248098.1476805335319@mail.yahoo.com>

Hello,
I have a squid running under 3.4.12 version. we have a software that tries to send a "method patch" to the ocs, but when squid intercepts the packet it changes it into a "method other". So I have an error message :{"status":405,"type":"about:blank","title":"Method Not Allowed","detail":"No route found for \"METHOD_OTHER \/users\/144\": Method Not Allowed (Allow: GET, HEAD, PUT, PATCH)"}.
I have found no ressources on this problem can you help me to understand.
Thank you

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161018/7665a8fa/attachment.htm>

From garryd at comnet.uz  Tue Oct 18 16:30:16 2016
From: garryd at comnet.uz (garryd at comnet.uz)
Date: Tue, 18 Oct 2016 21:30:16 +0500
Subject: [squid-users] Squid 4.x and Peek and Splice - Host Header
	Forgery
In-Reply-To: <CACU80L58pwzAnfo+yf+vVZrfZ=MFtKqJ=WtTWgn7x_1dDuE_7g@mail.gmail.com>
References: <CACU80L58pwzAnfo+yf+vVZrfZ=MFtKqJ=WtTWgn7x_1dDuE_7g@mail.gmail.com>
Message-ID: <237f4b01b8cde2872ac14e9a9d979fea@comnet.uz>

On 2016-10-18 18:32, John Wright wrote:
> Hi,
> 
> I have a constant problem with Host header forgery detection on squid
> doing peek and splice.
> 
> I see this most commonly with CDN, Amazon and microsoft due to the
> fact there TTL is only 5 seconds on certain dns entries im connecting
> to.  So when my client connects through my squid i get host header
> issues due to the contstant dns changes at these destinations.
> 
> I have ready many things online but how do i get around this.  I
> basically want to allow certain domains or ip subnets to not hit the
> host header error (as things break at this point for me ).
> 
> Any ideas ?
> 
> One example is
> 
> sls.update.microsoft.com [1]
> 
> Yes my client and Squid use same DNS server, i have even setup my
> squid as a bind server and tried that just for fun same issue.  Fact
> is the DNS at these places changes so fast (5 seconds) the dns
> response keeps changing/
> 
> I just need these approved destinations to make it through
> 
> 
> 
> Links:
> ------
> [1] http://sls.update.microsoft.com/

Hi,

Are you sure, that Squid and all your clients use same _caching_ DNS 
server? For example, here results from my server for name 
sls.update.microsoft.com:

$ dig sls.update.microsoft.com
...
sls.update.microsoft.com. 
3345	IN	CNAME	sls.update.microsoft.com.nsatc.net.
sls.update.microsoft.com.nsatc.net. 215	IN A	157.56.77.141
...


Second request after 3 seconds:

$ dig sls.update.microsoft.com
...
sls.update.microsoft.com. 
3342	IN	CNAME	sls.update.microsoft.com.nsatc.net.
sls.update.microsoft.com.nsatc.net. 212	IN A	157.56.77.141
...


Here I see that the TTL for the target A record is 300 seconds (not 5 
seconds), and _caching_ DNS server will serve same A record for all 
clients at least 5 minutes. That behaviour will not introduce false 
positives for host forgery detection.



On other hand, if the DNS server is not _caching_, you would get 
different A records for each request. For example, below are results 
from authoritative DNS server for zone nsatc.net:


$ dig @e.ns.nsatc.net sls.update.microsoft.com.nsatc.net
...
sls.update.microsoft.com.nsatc.net. 300	IN A	157.55.240.220
...


Second request after 5 seconds:

$ dig @e.ns.nsatc.net sls.update.microsoft.com.nsatc.net
...
sls.update.microsoft.com.nsatc.net. 300	IN A	157.56.96.54
...


Here I see, that the DNS server serves exactly one A record in 
round-robin fashion. Same true for Google public DNS services. That 
behavior could cause troubles for host forgery detection.

HTH

Garri


From rousskov at measurement-factory.com  Tue Oct 18 17:25:44 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 18 Oct 2016 11:25:44 -0600
Subject: [squid-users] squid change "method patch" to "method other"
In-Reply-To: <254945056.1248098.1476805335319@mail.yahoo.com>
References: <254945056.1248098.1476805335319.ref@mail.yahoo.com>
 <254945056.1248098.1476805335319@mail.yahoo.com>
Message-ID: <71ec1499-eea7-18c9-ce5e-614ff0a58261@measurement-factory.com>

On 10/18/2016 09:42 AM, magali isnard wrote:

> I have a squid running under 3.4.12 version. we have a software that
> tries to send a "method patch" to the ocs, but when squid intercepts the
> packet it changes it into a "method other". So I have an error message :
> {"status":405,"type":"about:blank","title":"Method Not
> Allowed","detail":"No route found for \"METHOD_OTHER \/users\/144\":
> Method Not Allowed (Allow: GET, HEAD, PUT, PATCH)"}.
> 
> I have found no ressources on this problem can you help me to understand.

I recommend trying Squid v3.5. IIRC, support for custom methods have
improved in v3.5 but I have not checked the change log to confirm.

Alex.




From unixdeaf at gmail.com  Tue Oct 18 17:42:12 2016
From: unixdeaf at gmail.com (John Wright)
Date: Tue, 18 Oct 2016 13:42:12 -0400
Subject: [squid-users] Squid 4.x and Peek and Splice - Host Header
	Forgery
In-Reply-To: <237f4b01b8cde2872ac14e9a9d979fea@comnet.uz>
References: <CACU80L58pwzAnfo+yf+vVZrfZ=MFtKqJ=WtTWgn7x_1dDuE_7g@mail.gmail.com>
 <237f4b01b8cde2872ac14e9a9d979fea@comnet.uz>
Message-ID: <CACU80L4xK-U0x4uvvu+eOazWORp6CJKzVm0u2rynBghjMUDCLw@mail.gmail.com>

Hi

Replying to the list

Yes i get that error on many different sites same exact error about host
headers.
Also if you watch the TTL on the amazonaws url i provided it changes from 3
to 5 to 10 seconds to 60 to 10 back and forth.
If you go online to an dns lookup site like kloth i see via kloth 5 seconds
TTL

i get a different TTL value at different times, it appears they dont have a
set TTL but they change it often and it varies.
Right now it appears to be a ttl of 60 seconds as you found but earlier and
over the weekend it has shown 5 seconds and even AWS support verified it
can vary as low as 5 seconds.
That being said , when it is changing every 3-5 seconds which comes and
goes , squid gives the header forgery errors as shown before.





On Tue, Oct 18, 2016 at 12:30 PM, <garryd at comnet.uz> wrote:

> On 2016-10-18 18:32, John Wright wrote:
>
>> Hi,
>>
>> I have a constant problem with Host header forgery detection on squid
>> doing peek and splice.
>>
>> I see this most commonly with CDN, Amazon and microsoft due to the
>> fact there TTL is only 5 seconds on certain dns entries im connecting
>> to.  So when my client connects through my squid i get host header
>> issues due to the contstant dns changes at these destinations.
>>
>> I have ready many things online but how do i get around this.  I
>> basically want to allow certain domains or ip subnets to not hit the
>> host header error (as things break at this point for me ).
>>
>> Any ideas ?
>>
>> One example is
>>
>> sls.update.microsoft.com [1]
>>
>> Yes my client and Squid use same DNS server, i have even setup my
>> squid as a bind server and tried that just for fun same issue.  Fact
>> is the DNS at these places changes so fast (5 seconds) the dns
>> response keeps changing/
>>
>> I just need these approved destinations to make it through
>>
>>
>>
>> Links:
>> ------
>> [1] http://sls.update.microsoft.com/
>>
>
> Hi,
>
> Are you sure, that Squid and all your clients use same _caching_ DNS
> server? For example, here results from my server for name
> sls.update.microsoft.com:
>
> $ dig sls.update.microsoft.com
> ...
> sls.update.microsoft.com. 3345  IN      CNAME
> sls.update.microsoft.com.nsatc.net.
> sls.update.microsoft.com.nsatc.net. 215 IN A    157.56.77.141
> ...
>
>
> Second request after 3 seconds:
>
> $ dig sls.update.microsoft.com
> ...
> sls.update.microsoft.com. 3342  IN      CNAME
> sls.update.microsoft.com.nsatc.net.
> sls.update.microsoft.com.nsatc.net. 212 IN A    157.56.77.141
> ...
>
>
> Here I see that the TTL for the target A record is 300 seconds (not 5
> seconds), and _caching_ DNS server will serve same A record for all clients
> at least 5 minutes. That behaviour will not introduce false positives for
> host forgery detection.
>
>
>
> On other hand, if the DNS server is not _caching_, you would get different
> A records for each request. For example, below are results from
> authoritative DNS server for zone nsatc.net:
>
>
> $ dig @e.ns.nsatc.net sls.update.microsoft.com.nsatc.net
> ...
> sls.update.microsoft.com.nsatc.net. 300 IN A    157.55.240.220
> ...
>
>
> Second request after 5 seconds:
>
> $ dig @e.ns.nsatc.net sls.update.microsoft.com.nsatc.net
> ...
> sls.update.microsoft.com.nsatc.net. 300 IN A    157.56.96.54
> ...
>
>
> Here I see, that the DNS server serves exactly one A record in round-robin
> fashion. Same true for Google public DNS services. That behavior could
> cause troubles for host forgery detection.
>
> HTH
>
> Garri
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
Thank you for your time,

John Wright
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161018/5ce67176/attachment.htm>

From garryd at comnet.uz  Tue Oct 18 18:01:47 2016
From: garryd at comnet.uz (garryd at comnet.uz)
Date: Tue, 18 Oct 2016 23:01:47 +0500
Subject: [squid-users] Squid 4.x and Peek and Splice - Host Header
	Forgery
In-Reply-To: <CACU80L4xK-U0x4uvvu+eOazWORp6CJKzVm0u2rynBghjMUDCLw@mail.gmail.com>
References: <CACU80L58pwzAnfo+yf+vVZrfZ=MFtKqJ=WtTWgn7x_1dDuE_7g@mail.gmail.com>
 <237f4b01b8cde2872ac14e9a9d979fea@comnet.uz>
 <CACU80L4xK-U0x4uvvu+eOazWORp6CJKzVm0u2rynBghjMUDCLw@mail.gmail.com>
Message-ID: <66df21696fafacad2b97db807f9cffd5@comnet.uz>

On 2016-10-18 22:42, John Wright wrote:
> Hi
> 
> Replying to the list
> 
> Yes i get that error on many different sites same exact error about
> host headers.
> Also if you watch the TTL on the amazonaws url i provided it changes
> from 3 to 5 to 10 seconds to 60 to 10 back and forth.
> If you go online to an dns lookup site like kloth i see via kloth 5
> seconds TTL
> 
> i get a different TTL value at different times, it appears they dont
> have a set TTL but they change it often and it varies.
> Right now it appears to be a ttl of 60 seconds as you found but
> earlier and over the weekend it has shown 5 seconds and even AWS
> support verified it can vary as low as 5 seconds.
> That being said , when it is changing every 3-5 seconds which comes
> and goes , squid gives the header forgery errors as shown before.

The time interval between client's and Squid's name lookup is measured 
in milliseconds. So, in most cases, the would not be false positives in 
environments where same cashing DNS server is used.

That specific issue you encounter except alert messages and Squid's 
inability to cache HTTP responses for "forged" HTTP requests?


From erdosain9 at gmail.com  Tue Oct 18 17:58:30 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 18 Oct 2016 10:58:30 -0700 (PDT)
Subject: [squid-users] Error DiskThreadsDiskFile::openDone: (2) No such
 file	or directory
In-Reply-To: <2061366482.1008747640.1476799493488.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1476797855466-4680142.post@n4.nabble.com>
 <2061366482.1008747640.1476799493488.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1476813510537-4680149.post@n4.nabble.com>

Yes.

cache_dir aufs /var/spool/squid 100000 16 256
cache_mem 256 MB




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Error-DiskThreadsDiskFile-openDone-2-No-such-file-or-directory-tp4680142p4680149.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From unixdeaf at gmail.com  Tue Oct 18 18:10:47 2016
From: unixdeaf at gmail.com (John Wright)
Date: Tue, 18 Oct 2016 14:10:47 -0400
Subject: [squid-users] Squid 4.x and Peek and Splice - Host Header
	Forgery
In-Reply-To: <66df21696fafacad2b97db807f9cffd5@comnet.uz>
References: <CACU80L58pwzAnfo+yf+vVZrfZ=MFtKqJ=WtTWgn7x_1dDuE_7g@mail.gmail.com>
 <237f4b01b8cde2872ac14e9a9d979fea@comnet.uz>
 <CACU80L4xK-U0x4uvvu+eOazWORp6CJKzVm0u2rynBghjMUDCLw@mail.gmail.com>
 <66df21696fafacad2b97db807f9cffd5@comnet.uz>
Message-ID: <CACU80L4YreyqiXtURO3OEwcbsQkqLnGFCO_p=7iPgBSYjMjNWg@mail.gmail.com>

In response to it not being a false positive , maybe its not specifically
the TTL but in this other article on the mailing lists someone else had the
same issue


Here is the response Amos gave, this is a known issue and apparently there
is no way to "ignore host header forgery issues" or bypass them in the
squid config.
My understanding is that , maybe the short TTL is ok, but it is small
enough to where when a cloud based client is connecting to server a server
b to amazon S3 etc it can take a few seconds
Thus that 5 second TTL (which again is often 2-3 seconds) is small enough
to hurt.

Specifically some of these people (aws , google) in some dns situations
they are doing things that squid has been known to identify as host header
forgery just becuse it doesnt understand whats happening.
Also if im doing an S3 call pulling or pushing a big file which is very
common in cloud environments it can take 10-20 seconds for the request to
process , and if TTL expires mid stream , squid is for some reason flagging
as forgery and it hangs until it either returns to the same ip in
DNS by chance or until the connection is dropped.

http://lists.squid-cache.org/pipermail/squid-users/2016-August/012261.html
Here is the note from Amos

>>* The cases where Squid still gets it wrong are where the popular CDN
*>>* service(s) in question are performing DNS actions indistinguishable to
*>>* those malware attacks. If Squid can't tell the difference between an
*>>* attack and normal DNS behaviour the only code change possible is to
*>>* disable the check (see above about the risk level).
*>>


On Tue, Oct 18, 2016 at 2:01 PM, <garryd at comnet.uz> wrote:

> On 2016-10-18 22:42, John Wright wrote:
>
>> Hi
>>
>> Replying to the list
>>
>> Yes i get that error on many different sites same exact error about
>> host headers.
>> Also if you watch the TTL on the amazonaws url i provided it changes
>> from 3 to 5 to 10 seconds to 60 to 10 back and forth.
>> If you go online to an dns lookup site like kloth i see via kloth 5
>> seconds TTL
>>
>> i get a different TTL value at different times, it appears they dont
>> have a set TTL but they change it often and it varies.
>> Right now it appears to be a ttl of 60 seconds as you found but
>> earlier and over the weekend it has shown 5 seconds and even AWS
>> support verified it can vary as low as 5 seconds.
>> That being said , when it is changing every 3-5 seconds which comes
>> and goes , squid gives the header forgery errors as shown before.
>>
>
> The time interval between client's and Squid's name lookup is measured in
> milliseconds. So, in most cases, the would not be false positives in
> environments where same cashing DNS server is used.
>
> That specific issue you encounter except alert messages and Squid's
> inability to cache HTTP responses for "forged" HTTP requests?
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
Thank you for your time,

John Wright
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161018/313870b6/attachment.htm>

From unixdeaf at gmail.com  Tue Oct 18 18:17:12 2016
From: unixdeaf at gmail.com (John Wright)
Date: Tue, 18 Oct 2016 14:17:12 -0400
Subject: [squid-users] Squid 4.x and Peek and Splice - Host Header
	Forgery
In-Reply-To: <CACU80L4YreyqiXtURO3OEwcbsQkqLnGFCO_p=7iPgBSYjMjNWg@mail.gmail.com>
References: <CACU80L58pwzAnfo+yf+vVZrfZ=MFtKqJ=WtTWgn7x_1dDuE_7g@mail.gmail.com>
 <237f4b01b8cde2872ac14e9a9d979fea@comnet.uz>
 <CACU80L4xK-U0x4uvvu+eOazWORp6CJKzVm0u2rynBghjMUDCLw@mail.gmail.com>
 <66df21696fafacad2b97db807f9cffd5@comnet.uz>
 <CACU80L4YreyqiXtURO3OEwcbsQkqLnGFCO_p=7iPgBSYjMjNWg@mail.gmail.com>
Message-ID: <CACU80L6yVWm7haDBMYhZWnWtRdu=9qb2NLeSihULDa5KXyKvSA@mail.gmail.com>

Also here is an example showing the issues when pushing to S3 as well as
the same error with some google url's.

2016/10/17 18:33:32 kid1| SECURITY ALERT: Host header forgery detected on
local=209.85.144.113:443 remote=x.x.x.x:62402 FD 49 flags=33 (local IP does
not match any domain IP)
2016/10/17 18:33:32 kid1| SECURITY ALERT: on URL: tools.google.com:443
2016/10/17 18:34:04 kid1| SECURITY ALERT: Host header forgery detected on
local=209.85.144.113:443 remote=x.x.x.x:62405 FD 110 flags=33 (local IP
does not match any domain IP)
2016/10/17 18:34:04 kid1| SECURITY ALERT: on URL: tools.google.com:443
2016/10/17 18:34:45 kid1| SECURITY ALERT: Host header forgery detected on
local=209.85.144.113:443 remote=x.x.x.x:62409 FD 56 flags=33 (local IP does
not match any domain IP)
2016/10/17 18:34:45 kid1| SECURITY ALERT: on URL: tools.google.com:443
2016/10/17 18:35:16 kid1| SECURITY ALERT: Host header forgery detected on
local=209.85.144.113:443 remote=x.x.x.x:62412 FD 65 flags=33 (local IP does
not match any domain IP)
2016/10/17 18:35:16 kid1| SECURITY ALERT: on URL: tools.google.com:443
2016/10/17 18:57:11 kid1| SECURITY ALERT: Host header forgery detected on
local=172.217.17.78:443 remote=x.x.x.x:52958 FD 66 flags=33 (local IP does
not match any domain IP)
2016/10/17 18:57:11 kid1| SECURITY ALERT: on URL:
alt2-safebrowsing.google.com:443
2016/10/17 18:58:00 kid1| SECURITY ALERT: Host header forgery detected on
local=172.217.17.78:443 remote=x.x.x.x:52965 FD 42 flags=33 (local IP does
not match any domain IP)
2016/10/17 18:58:00 kid1| SECURITY ALERT: on URL:
alt2-safebrowsing.google.com:443



Also please note my dig response time :

;; Query time: 1 msec


And from my DNS server itself :

;; Query time: 2 msec


My bind server is setup as a simple forwarder which always returns
repsonses in about 1-2 msec

So again , things that are big , big files, timely requests to query some
API , they all appear to have host header forgery problems that squid shows
and then drops if the request takes longer to process than the TTL of the
DNS entry associated with the traffic

I have many examples and if i dont use squid everything works fine, with
squid it breaks , thats my simple point is squid is seeing an issue the app
and client themselves dont and thats OK but with no way to "disable " or
"workaround" the errors for lets say S3 on AWS

how do i keep using squid?

On Tue, Oct 18, 2016 at 2:10 PM, John Wright <unixdeaf at gmail.com> wrote:

> In response to it not being a false positive , maybe its not specifically
> the TTL but in this other article on the mailing lists someone else had the
> same issue
>
>
> Here is the response Amos gave, this is a known issue and apparently there
> is no way to "ignore host header forgery issues" or bypass them in the
> squid config.
> My understanding is that , maybe the short TTL is ok, but it is small
> enough to where when a cloud based client is connecting to server a server
> b to amazon S3 etc it can take a few seconds
> Thus that 5 second TTL (which again is often 2-3 seconds) is small enough
> to hurt.
>
> Specifically some of these people (aws , google) in some dns situations
> they are doing things that squid has been known to identify as host header
> forgery just becuse it doesnt understand whats happening.
> Also if im doing an S3 call pulling or pushing a big file which is very
> common in cloud environments it can take 10-20 seconds for the request to
> process , and if TTL expires mid stream , squid is for some reason flagging
> as forgery and it hangs until it either returns to the same ip in
> DNS by chance or until the connection is dropped.
>
> http://lists.squid-cache.org/pipermail/squid-users/2016-August/012261.html
> Here is the note from Amos
>
> >>* The cases where Squid still gets it wrong are where the popular CDN
> *>>* service(s) in question are performing DNS actions indistinguishable to
> *>>* those malware attacks. If Squid can't tell the difference between an
> *>>* attack and normal DNS behaviour the only code change possible is to
> *>>* disable the check (see above about the risk level).
> *>>
>
>
> On Tue, Oct 18, 2016 at 2:01 PM, <garryd at comnet.uz> wrote:
>
>> On 2016-10-18 22:42, John Wright wrote:
>>
>>> Hi
>>>
>>> Replying to the list
>>>
>>> Yes i get that error on many different sites same exact error about
>>> host headers.
>>> Also if you watch the TTL on the amazonaws url i provided it changes
>>> from 3 to 5 to 10 seconds to 60 to 10 back and forth.
>>> If you go online to an dns lookup site like kloth i see via kloth 5
>>> seconds TTL
>>>
>>> i get a different TTL value at different times, it appears they dont
>>> have a set TTL but they change it often and it varies.
>>> Right now it appears to be a ttl of 60 seconds as you found but
>>> earlier and over the weekend it has shown 5 seconds and even AWS
>>> support verified it can vary as low as 5 seconds.
>>> That being said , when it is changing every 3-5 seconds which comes
>>> and goes , squid gives the header forgery errors as shown before.
>>>
>>
>> The time interval between client's and Squid's name lookup is measured in
>> milliseconds. So, in most cases, the would not be false positives in
>> environments where same cashing DNS server is used.
>>
>> That specific issue you encounter except alert messages and Squid's
>> inability to cache HTTP responses for "forged" HTTP requests?
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>
>
> --
> Thank you for your time,
>
> John Wright
>
>


-- 
Thank you for your time,

John Wright
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161018/0f31068a/attachment.htm>

From lean0x2f at gmail.com  Wed Oct 19 06:44:41 2016
From: lean0x2f at gmail.com (Leandro Barragan)
Date: Wed, 19 Oct 2016 03:44:41 -0300
Subject: [squid-users] Peeking on TLS traffic: unknown cipher returned
Message-ID: <CAARTC8k+jHak1CR_B61Y-L5z+7Px6d9jM5X_vD_MJxa=+JqYVA@mail.gmail.com>

Hi!

I'm having trouble with SSL Peek & Splice in Squid 3.5.16 using
intercept mode. I'm trying to configure a transparent proxy (no CA
installed on clients) which denies access to specific sites. I
understand that if I can't Bump (my case), then I can only use SNI
information from TLS "Client Hello" on Step 2.

Everything works OK with most sites, but when I try to connect to some
sites like facebook.com or microsoft.com, clients can't connect and I
get this error on cache.log:

> [...]
> Error negotiating SSL on FD 111: error:140920F8:SSL routines:SSL3_GET_SERVER_HELLO:unknown cipher returned (1/-1/0)
> [...]

Reading emails from this list, I came to the conclusion that this
error is related to new ciphers (like ChaCha20) which are not
supported by OpenSSL 1.0.1... So I tried to compile Squid using
OpenSSL 1.1.0, which is not possible (bug #4599). I also tried to
compile it using LibreSSL unsuccessfully.

I fail to see why is this happening. I only need to peek on the
connection and make a decision based on SNI, I'm not Bumping, so I
don't understand why ciphers matter in my situation.

My squid.conf:

> [...]
> acl face ssl::server_name_regex -i facebook
> acl twitter ssl::server_name_regex -i twitter
>
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
>
> sslproxy_cipher HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE
>
> http_port 3128
> http_port 3129 intercept
> https_port 3130 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/myCA.pem options=NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>
> sslproxy_capath /var/lib/ssl_db
>
> ssl_bump peek all step1
> ssl_bump peek all step2
> ssl_bump terminate face step3
> ssl_bump terminate twitter step3
> ssl_bump splice all step3
>
> sslcrtd_program /lib/squid3/ssl_crtd -s /var/lib/ssl_db -M 4MB
> sslcrtd_children 10
> sslproxy_cert_error deny all
> [...]


Any ideas would be really appreciated.

--

Leandro


From fredbmail at free.fr  Wed Oct 19 07:05:30 2016
From: fredbmail at free.fr (FredB)
Date: Wed, 19 Oct 2016 09:05:30 +0200 (CEST)
Subject: [squid-users] Error DiskThreadsDiskFile::openDone: (2) No such
 file	or directory
In-Reply-To: <1476813510537-4680149.post@n4.nabble.com>
Message-ID: <1556725693.1010586806.1476860730096.JavaMail.root@zimbra4-e1.priv.proxad.net>

I have this problem regularly with aufs (long time ...)
Sorry I know no solution, except purge cache 

I'm using diskd to avoid this 

Fred


From garryd at comnet.uz  Wed Oct 19 08:40:10 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Wed, 19 Oct 2016 13:40:10 +0500
Subject: [squid-users] Error DiskThreadsDiskFile::openDone: (2) No such
 file or directory
In-Reply-To: <1476797855466-4680142.post@n4.nabble.com>
References: <1476797855466-4680142.post@n4.nabble.com>
Message-ID: <1476866410.10027.3.camel@comnet.uz>

On Tue, 2016-10-18 at 06:37 -0700, erdosain9 wrote:
> Hi.
> squid 3.5.20
> 
> Im having a lot of these in cache.log
> 
> 2016/10/18 10:36:11 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:11 kid1|???????/var/spool/squid/00/92/000092E9
> 2016/10/18 10:36:14 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:14 kid1|???????/var/spool/squid/00/AA/0000AA46
> 2016/10/18 10:36:16 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:16 kid1|???????/var/spool/squid/00/AA/0000AA48
> 2016/10/18 10:36:16 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:16 kid1|???????/var/spool/squid/00/AA/0000AA49
> 2016/10/18 10:36:16 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:16 kid1|???????/var/spool/squid/00/AA/0000AA4B
> 2016/10/18 10:36:16 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:16 kid1|???????/var/spool/squid/00/AA/0000AA4C
> 2016/10/18 10:36:20 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:20 kid1|???????/var/spool/squid/00/AA/0000AA60
> 2016/10/18 10:36:21 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:21 kid1|???????/var/spool/squid/00/AA/0000AA67
> 2016/10/18 10:36:21 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:21 kid1|???????/var/spool/squid/00/AA/0000AA66
> 2016/10/18 10:36:21 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:21 kid1|???????/var/spool/squid/00/AA/0000AA65
> 2016/10/18 10:36:33 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:33 kid1|???????/var/spool/squid/00/AA/0000AA10
> 2016/10/18 10:36:33 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:33 kid1|???????/var/spool/squid/00/AA/0000AA8C
> 2016/10/18 10:36:33 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:33 kid1|???????/var/spool/squid/00/AA/0000AA98
> 2016/10/18 10:36:33 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:33 kid1|???????/var/spool/squid/00/AA/0000AA18
> 2016/10/18 10:36:33 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:33 kid1|???????/var/spool/squid/00/AA/0000AA93
> 2016/10/18 10:36:33 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:33 kid1|???????/var/spool/squid/00/AA/0000AA9A
> 2016/10/18 10:36:34 kid1| DiskThreadsDiskFile::openDone: (2) No such
> file or
> directory
> 2016/10/18 10:36:34 kid1|???????/var/spool/squid/00/70/0000704B
> 
> What can i do?? thanks

Hi,

You may find an answer for your case here:

*?http://lists.squid-cache.org/pipermail/squid-users/2014-December/0012
39.html
*?http://lists.squid-cache.org/pipermail/squid-users/2015-September/005
502.html
*?http://bugs.squid-cache.org/show_bug.cgi?id=4367

In my case I get the errors after Squid's crash.

Garri


From sekarit at gmail.com  Wed Oct 19 09:08:26 2016
From: sekarit at gmail.com (Sekar Duraisamy)
Date: Wed, 19 Oct 2016 14:38:26 +0530
Subject: [squid-users] FATAL: Ipc::Mem::Segment::create failed to
 shm_open(/squid-cf__queues.shm): (17) File exists
Message-ID: <CADfQnU20_5nwchzvE=DiU-aGt=nAO8dFrNHE4gOoBqirwUQzLw@mail.gmail.com>

Hello Friends,

I am getting the following message when i start the squid

FATAL: Ipc::Mem::Segment::create failed to shm_open(/squid-cf__queues.shm):
(17) File exists

I am running squid-3.5.20 and even I have tried to remove cache directories
and -z but still giving this error.

So please advice me what is wrong here.

Thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161019/b4093cbd/attachment.htm>

From denizlist at denizeren.net  Wed Oct 19 09:44:41 2016
From: denizlist at denizeren.net (Deniz Eren)
Date: Wed, 19 Oct 2016 12:44:41 +0300
Subject: [squid-users] Squid SMP workers crash
In-Reply-To: <203e89fd-c1b7-3b02-1b30-d66505e24ff0@measurement-factory.com>
References: <CAHQdsZ805myhBd8_s-1dxvp1eZSv_bhykGj9gwm=_6=WMK8Tew@mail.gmail.com>
 <b9ced597-84e5-c16c-4130-c4050d9089cc@measurement-factory.com>
 <CAHQdsZ_NV84Tc50OeW+AL+pr4VmOyxAqwLU3nGuVTArJANLK+Q@mail.gmail.com>
 <e5569764-af99-e286-0458-73cd8068d87f@measurement-factory.com>
 <CAHQdsZ9dOqXxc9Z=wox8sgMHfasg-qNxpr7Y-ewO=o-_WZ0uEg@mail.gmail.com>
 <203e89fd-c1b7-3b02-1b30-d66505e24ff0@measurement-factory.com>
Message-ID: <CAHQdsZ95OG9e58a0AACY7R8U4Ly8U9zW8oBCNucbrXC1hiQyOg@mail.gmail.com>

On 10/18/16, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> On 10/17/2016 10:37 PM, Deniz Eren wrote:
>> On Mon, Oct 17, 2016 at 7:43 PM, Alex Rousskov wrote:
>>> On 10/17/2016 02:38 AM, Deniz Eren wrote:
>>>> 2016/10/17 11:22:37 kid1| assertion failed:
>>>> ../../src/ipc/AtomicWord.h:71: "Enabled()"
>>>
>>> Either your Squid does not support SMP (a build environment problem) or
>>> Squid is trying to use SMP features when SMP is not enabled (a Squid
>>> bug).
>>>
>>> What does the following command show?
>>>
>>>   fgrep -RI HAVE_ATOMIC_OPS config.status include/autoconf.h
>> fgrep -RI HAVE_ATOMIC_OPS config.status include/autoconf.h
>> config.status:D["HAVE_ATOMIC_OPS"]=" 0"
>> include/autoconf.h:#define HAVE_ATOMIC_OPS 0
>
> Your Squid does not support SMP. The ./configure script failed to find
> the necessary APIs for SMP support. I wish Squid would tell you that in
> a less obscure way than an Enabled() assertion; feel free to file a bug
> report about that, but that is a reporting/UI problem; the assertion
> itself is correct.
Yes, you are right. Inspecting more carefully I saw that "Atomic"
support is missing.

>
> I do not know why your build environment lacks atomics support (or why
> Squid cannot detect that support), but I hope that others on the mailing
> list would be able to help you with that investigation.
Fixing system include paths solved the problem. Thanks for pointing me
what the problem is.

>
>
> Finally, in the interest of full disclosure, I have to note that, IIRC,
> atomics are not actually required for some of the primitive SMP
> features, but Squid attempts to create a few shared memory tables even
> when those tables are not needed, and those tables do require atomics
> (and will hit the Enabled() assertion you have reported).
>
> There have been improvements in this area; eventually no unnecessary
> shared memory tables will be created, but it is probably easier for you
> to get a build with working atomics (usually does not require any
> development) than to get rid of those tables (which probably require
> more development).
>
> Alex.
>
>


From sekarit at gmail.com  Wed Oct 19 10:47:01 2016
From: sekarit at gmail.com (Sekar Duraisamy)
Date: Wed, 19 Oct 2016 16:17:01 +0530
Subject: [squid-users] FATAL: Ipc::Mem::Segment::create failed to
 shm_open(/squid-cf__queues.shm): (17) File exists
Message-ID: <CADfQnU2mH0kbxV9HB1wHOZOvYMwqxZ=EEwadB4aPhxFR1UfPbw@mail.gmail.com>

 Hello Friends,

I am getting the following message when i start the squid

FATAL: Ipc::Mem::Segment::create failed to shm_open(/squid-cf__queues.shm):
(17) File exists

I am running squid-3.5.20 and even I have tried to remove cache directories
and -z but still giving this error.

So please advice me what is wrong here.

Thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161019/1757bb0d/attachment.htm>

From garryd at comnet.uz  Wed Oct 19 11:02:04 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Wed, 19 Oct 2016 16:02:04 +0500
Subject: [squid-users] FATAL: Ipc::Mem::Segment::create failed to
 shm_open(/squid-cf__queues.shm): (17) File exists
In-Reply-To: <CADfQnU2mH0kbxV9HB1wHOZOvYMwqxZ=EEwadB4aPhxFR1UfPbw@mail.gmail.com>
References: <CADfQnU2mH0kbxV9HB1wHOZOvYMwqxZ=EEwadB4aPhxFR1UfPbw@mail.gmail.com>
Message-ID: <1476874924.13060.3.camel@comnet.uz>

On Wed, 2016-10-19 at 16:17 +0530, Sekar Duraisamy wrote:
> Hello Friends,
> 
> I am getting the following message when i start the squid
> 
> FATAL: Ipc::Mem::Segment::create failed to shm_open(/squid-
> cf__queues.shm):
> (17) File exists

Hi,

It seems the squid-cf__queues.shm file already exists in /dev/shm/ and
Squid has not permission to overwrite the file.

Garri


From erdosain9 at gmail.com  Wed Oct 19 12:59:42 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 19 Oct 2016 05:59:42 -0700 (PDT)
Subject: [squid-users] Error DiskThreadsDiskFile::openDone: (2) No such
 file	or directory
In-Reply-To: <1556725693.1010586806.1476860730096.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1476797855466-4680142.post@n4.nabble.com>
 <2061366482.1008747640.1476799493488.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <1476813510537-4680149.post@n4.nabble.com>
 <1556725693.1010586806.1476860730096.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1476881982588-4680159.post@n4.nabble.com>

Hi.
I try this
http://www.linuxtopic.com/2016/03/clear-squid-cache-and-re-create-cache.html

but still the same...

This is my conf

####GRUPOS DE IP
acl full src "/etc/squid/ips/full.lst"
acl logistica src "/etc/squid/ips/logistica.lst"
acl sistemas src "/etc/squid/ips/sistemas.lst"
acl adminis  src "/etc/squid/ips/adminis.lst"
acl institucionales src "/etc/squid/ips/institucionales.lst"
acl patriysumi  src     "/etc/squid/ips/patriysumi.lst"
acl rrhh        src     "/etc/squid/ips/rrhh.lst"
acl proyecto    src     "/etc/squid/ips/proyecto.lst"
acl programas_y_activ    src     "/etc/squid/ips/programas_y_activ.lst"

####Bloquea Publicidad ( http://pgl.yoyo.org/adservers/ )
acl ads dstdom_regex "/etc/squid/listas/ad_block.lst"
http_access deny ads
#deny_info TCP_RESET ads

####Streaming
acl stream url_regex -i \.flv$
acl stream url_regex -i \.mp4$
acl stream url_regex -i watch?
acl stream url_regex -i youtube
acl stream url_regex -i facebook
acl stream url_regex -i fbcdn\.net\/v\/(.*\.mp4)\?
acl stream url_regex -i fbcdn\.net\/v\/(.*\.jpg)\? 
acl stream url_regex -i akamaihd\.net\/v\/(.*\.mp4)\?
acl stream url_regex -i akamaihd\.net\/v\/(.*\.jpg)\?

##Dominios denegados
acl dominios_denegados dstdomain "/etc/squid/listas/dominios_denegados.lst"

##Extensiones bloqueadas
acl multimedia urlpath_regex "/etc/squid/listas/multimedia.lst"

##Extensiones peligrosas
acl peligrosos urlpath_regex "/etc/squid/listas/peligrosos.lst"

#Puertos
acl SSL_ports port 443
acl SSL_ports port 8443
acl SSL_ports port 8080

acl Safe_ports port 631         # httpCUPS
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 8443        # httpsalt
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 8080        # edesur y otros
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
http_access allow localhost
http_access allow logistica !dominios_denegados !multimedia !peligrosos
http_access allow full !peligrosos
http_access allow adminis !multimedia !peligrosos
http_access allow institucionales !multimedia !peligrosos
http_access allow patriysumi !multimedia !peligrosos !dominios_denegados
http_access allow proyecto !dominios_denegados
http_access allow rrhh !multimedia !peligrosos
http_access allow sistemas
http_access allow programas_y_activ

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.1.97:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=5MB cert=/etc/squid/ssl_cert/myca.pem
key=/etc/squid/ssl_cert/myca.pem

acl step1 at_step SslBump1

acl excludeSSL ssl::server_name_regex "/etc/squid/listas/excluidosSSL.lst"

ssl_bump peek step1
ssl_bump splice excludeSSL
ssl_bump bump all

# Uncomment and adjust the following to add a disk cache directory.
cache_dir aufs /var/spool/squid 100000 16 256
cache_mem 256 MB

cache_swap_low 90
cache_swap_high 95

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid


#My refresh pattern
#obliga el cache de imagenes .jgp

refresh_pattern -i \.jpg$ 30 0% 30 ignore-no-cache ignore-no-store
ignore-private

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320


###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
via off
forwarded_for delete
###

#Pools para ancho de Banda
delay_pools 10

###VELOCIDAD PARA REDES SOCIALES
#delay_class 1 1
#delay_parameters 1 10000/100000
#delay_access 1 allow limitado redes_sociales   !stream
#delay_access 1 allow full redes_sociales       !stream
#delay_access 1 allow adminis redes_sociales    !stream
#delay_access 1 deny all


#Limitar Video Streaming a 50k
delay_class 1 1
delay_parameters 1 50000/250000
delay_access 1 allow adminis    stream
delay_access 1 allow full       stream
delay_access 1 allow logistica  stream
delay_access 1 allow institucionales stream
delay_access 1 allow patriysumi stream
delay_access 1 allow rrhh stream
delay_access 1 allow proyecto stream
delay_access 1 allow programas_y_activ stream
delay_access 1 deny all

#Limitar Video Streaming a 500k
delay_class 2 1
delay_parameters 2 500000/500000
delay_access 2 allow sistemas   stream
delay_access 2 deny all

#Ancho de Banda Administracion
delay_class 3 2
delay_parameters 3 256000/256000 100000/256000
delay_access 3 allow adminis    !stream
delay_access 3 deny all

#Ancho de Banda Sistemas
delay_class 4 2
delay_parameters 4 512000/512000 64000/256000
delay_access 4 allow sistemas   !stream
delay_access 4 deny all

#Ancho de Banda Logistica
delay_class 5 2
delay_parameters 5 256000/256000 100000/256000
delay_access 5 allow logistica  !stream
delay_access 5 deny all

#Ancho de Banda Institucionales
delay_class 6 2
delay_parameters 6 256000/256000 100000/256000
delay_access 6 allow institucionales !stream
delay_access 6 deny all

#Ancho de Banda Patrimonio y Suministro
delay_class 7 2
delay_parameters 7 256000/256000 100000/256000
delay_access 7 allow patriysumi !stream
delay_access 7 deny all

#Ancho de Banda RRHH
delay_class 8 2
delay_parameters 8 256000/256000 100000/256000
delay_access 8 allow rrhh !stream
delay_access 8 deny all

#Ancho de Banda Proyecto
delay_class 9 2
delay_parameters 9 256000/256000 100000/256000
delay_access 9 allow proyecto !stream
delay_access 9 deny all

#Ancho de Banda programas_y_activ
delay_class 10 2
delay_parameters 10 256000/256000 100000/256000
delay_access 10 allow programas_y_activ !stream
delay_access 10 deny all
                                                                                                              

#dns_nameservers 8.8.8.8 
visible_hostname squid.example.lan

# try connecting to first 25 ips of a domain name
forward_max_tries 25


Is there some problem????
how config diskd???

Thanks!
~                                                                                                                                                    
~                                                                                                                                                    
~                                                             




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Error-DiskThreadsDiskFile-openDone-2-No-such-file-or-directory-tp4680142p4680159.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed Oct 19 13:42:02 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 20 Oct 2016 02:42:02 +1300
Subject: [squid-users] Peeking on TLS traffic: unknown cipher returned
In-Reply-To: <CAARTC8k+jHak1CR_B61Y-L5z+7Px6d9jM5X_vD_MJxa=+JqYVA@mail.gmail.com>
References: <CAARTC8k+jHak1CR_B61Y-L5z+7Px6d9jM5X_vD_MJxa=+JqYVA@mail.gmail.com>
Message-ID: <b7bade4f-2dc9-f5da-dbcf-750165262f16@treenet.co.nz>

On 19/10/2016 7:44 p.m., Leandro Barragan wrote:
> Hi!
> 
> I'm having trouble with SSL Peek & Splice in Squid 3.5.16 using

Please upgrade to 3.5.19 or later. Current is 3.5.22.

> intercept mode. I'm trying to configure a transparent proxy (no CA
> installed on clients) which denies access to specific sites. I
> understand that if I can't Bump (my case), then I can only use SNI
> information from TLS "Client Hello" on Step 2.

Correct.

> 
> Everything works OK with most sites, but when I try to connect to some
> sites like facebook.com or microsoft.com, clients can't connect and I
> get this error on cache.log:
> 
>> [...]
>> Error negotiating SSL on FD 111: error:140920F8:SSL routines:SSL3_GET_SERVER_HELLO:unknown cipher returned (1/-1/0)
>> [...]
> 
> Reading emails from this list, I came to the conclusion that this
> error is related to new ciphers (like ChaCha20) which are not
> supported by OpenSSL 1.0.1... So I tried to compile Squid using
> OpenSSL 1.1.0, which is not possible (bug #4599). I also tried to
> compile it using LibreSSL unsuccessfully.

A more current Squid (3.5.19+) and OpenSSL 1.0.2 latest should work. It
has for others.

> 
> I fail to see why is this happening. I only need to peek on the
> connection and make a decision based on SNI, I'm not Bumping, so I
> don't understand why ciphers matter in my situation.

Note that the sites you get this error on are the ones where "terminate"
action is configured to happen.

Terminate means impersonating the server and responding to the client
with an HTTPS error page.



> 
> My squid.conf:
> 
>> [...]
>> acl face ssl::server_name_regex -i facebook
>> acl twitter ssl::server_name_regex -i twitter
>>
>> acl step1 at_step SslBump1
>> acl step2 at_step SslBump2
>> acl step3 at_step SslBump3
>>
>> sslproxy_cipher HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE
>>
>> http_port 3128
>> http_port 3129 intercept
>> https_port 3130 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/myCA.pem options=NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>>
>> sslproxy_capath /var/lib/ssl_db
>>
>> ssl_bump peek all step1
>> ssl_bump peek all step2

The use of "all" is redundant and useless in the above lines.

Since peek is only valid at step #1 and #2 anyway the "step1 and step2
are pointless.

>> ssl_bump terminate face step3
>> ssl_bump terminate twitter step3
>> ssl_bump splice all step3

The use of "step3" is redundant and useless.

Since ACL "face" and ACL "twitter" are of the same type and used as a
pair with the same action. You would be better off merging their values
under one ACL name.

Oh, and most content from facebook actually comes from the "fbcdn" domain.

You might as well configure:

 acl TF ssl::server_name_regex -i facebook fbcdn twitter
 ssl_bump peek all
 ssl_bump terminate TF
 ssl_bump splice all


Amos



From squid3 at treenet.co.nz  Wed Oct 19 13:56:03 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 20 Oct 2016 02:56:03 +1300
Subject: [squid-users] Error DiskThreadsDiskFile::openDone: (2) No such
 file or directory
In-Reply-To: <1476881982588-4680159.post@n4.nabble.com>
References: <1476797855466-4680142.post@n4.nabble.com>
 <2061366482.1008747640.1476799493488.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <1476813510537-4680149.post@n4.nabble.com>
 <1556725693.1010586806.1476860730096.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <1476881982588-4680159.post@n4.nabble.com>
Message-ID: <c6b34fe3-57b6-b5b5-9a5b-9247e984bf2d@treenet.co.nz>

On 20/10/2016 1:59 a.m., erdosain9 wrote:
> Hi.
> I try this
> http://www.linuxtopic.com/2016/03/clear-squid-cache-and-re-create-cache.html
> 
> but still the same...
> 

Squid auto-corrects the cache data contents. The message you are seeing
is what gets logged during the correction process. You do not have to do
anything to "fix" the cache data, Squid has already done so when it
logged that message.

Clearing the cache does not fix anything - simply quietens the logs,
since you have erased all the broken objects along with the good ones.

The messages *will* occur again whenever the actual problem is
encountered next. Until you find out what that is and fix it the log
entries will just keep coming back.

<snip>
> 
> Is there some problem????

Not in the config file. These errors occur in the following situations:

1) multiple Squid running accessing the same cache_dir path and
overwriting each others data.
 - can also be SMP workers sharing a UFS, AUFS or diskd cache_dir.

2) A Squid crash happening while some files are waiting to be written,
but after the swap.state journal has been updated to mention their
existence.

3) HDD or SSD disk corruption. Squid pushes disks very hard, and they do
die eventually. Usually much faster than manufacturer specs indicate.
Thats not a manufacturer issue, just a symptom of how hard Squid pushes
the disks.

4) some non-Squid script or software playing around with the Squid cache
directory contents. (see #1)


> how config diskd???

Replace "aufs" with "diskd" in your cache_dir line(s).
Then reconfigure Squid.


Amos



From jlay at slave-tothe-box.net  Wed Oct 19 14:13:32 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Wed, 19 Oct 2016 08:13:32 -0600
Subject: [squid-users] Additional ecap/icap questions
In-Reply-To: <4728c323-1d23-b2f7-f5cb-e1f1cc05ddc5@measurement-factory.com>
References: <d573a941f8ab91b781b4d2f7fadc8b3b@localhost>
 <4728c323-1d23-b2f7-f5cb-e1f1cc05ddc5@measurement-factory.com>
Message-ID: <ab6755dddb0c4327dae997c795fbda8c@localhost>

On 2016-10-17 15:01, Alex Rousskov wrote:
> On 10/17/2016 11:51 AM, James Lay wrote:
> 
>> Here's what I'm wanting to accomplish and it's been proving a 
>> challenge:
>>  Detect keywords (think DLP maybe) in http/https flows.  I've got ecap
>> and icap compiled in and working.  My challenges:
>> 
>> a)with icap, it appears that the filter content adapters only work 
>> with
>> responses, not requests....I need both.
> 
> It depends on the ICAP service. Some work with requests, some with
> responses, some with both kinds of messages.
> 

I'm specifically looking at 
http://c-icap.sourceforge.net/c-icap-modules.conf-0.4.x.html#tag_srv_content_filtering_MaxBodyData. 
  This looks like it will do what I need, but as from my previous posts, 
it appears it only works with RESPMOD, not requests.

>> b)with icap, if I use the "echo" adapter I can see everything on the 
>> lo
>> interface, but decoding it has proven fruitless for me
> 
> If you are trying to manually decode ICAP traffic on a loopback
> interface, please clarify what you are trying to accomplish with that.

I'm trying to match text in a stream, somehow.  Either with the above 
icap method, which would appear to be designed for this purpose, but 
only responses not request, or by decoding the stream and sending the 
decoded traffic to an interface where an IDS can match content.  In 
short, if someone drops an f-bomb in a chat let's say, I want it known.

> 
>> c)with ecap, I configured per
>> http://wiki.squid-cache.org/ConfigExamples/ContentAdaptation/eCAP,
>> but I'm confused on the ecap_service line..examples show
>> "ecap://www.vigos.com/ecap_gzip", but what do I put in?
> 
> Just like with ICAP, you configure an eCAP adapter/service that you 
> want
> to use. I do not know whether it exists or needs to be written. For
> example, if you want to find viruses, you can use an eCAP ClamAV 
> adapter.
> 
> 
>> I thought I
>> didn't need a service for ecap..do I point this to localhost or 
>> something?
> 
> With eCAP, you do not need a server. With both ICAP and eCAP you need a
> service or "adapter" that does whatever you want to do. ICAP and eCAP
> are just protocols/API -- they cannot do anything useful on their own.
> 
> The eCAP service URI is just an identifier. It does not "point" to any
> specific location. It is only used to distinguish one loaded eCAP
> service from another loaded eCAP service.
> 
> 
> Overall, you need some software that will "detect keywords". That
> detection is not going to happen magically on its own. ICAP and eCAP 
> are
> just two ways to get the HTTP messages to that software. Some call that
> _kind_ of software "ICAP service", "ICAP server plugin", "eCAP 
> service",
> "eCAP adapter", etc. You need to find or write a specific
> service/plugin/adapter/etc. that does keyword detection.
> 
> Alex.

Thanks Alex....I can't imagine that I'm the only one wanting to do this 
purely with open source software, but it appears that way.

James


From lean0x2f at gmail.com  Thu Oct 20 02:51:32 2016
From: lean0x2f at gmail.com (Leandro Barragan)
Date: Wed, 19 Oct 2016 23:51:32 -0300
Subject: [squid-users] Peeking on TLS traffic: unknown cipher returned
In-Reply-To: <b7bade4f-2dc9-f5da-dbcf-750165262f16@treenet.co.nz>
References: <CAARTC8k+jHak1CR_B61Y-L5z+7Px6d9jM5X_vD_MJxa=+JqYVA@mail.gmail.com>
 <b7bade4f-2dc9-f5da-dbcf-750165262f16@treenet.co.nz>
Message-ID: <CAARTC8n7dGRbD3hW0PwhfG5EX2horcwM4vAuqu=8MCkWuiwD=Q@mail.gmail.com>

Amos,

I really appreciate your answer and the time you took trying to
explain me the rules. I'm already compiling Squid 3.5.22 with OpenSSL
1.0.2j to see if that solves my issue.

Leaving aside the software version, it seems weird to me that I see
this behaviour not only on blocked (terminated) sites like facebook,
but in other sites too, like microsoft.com, which should only be
peeked (taking into account that I applied the config you recommended
me: peek all, terminate facebook&twitter, and splice all).
When I access microsoft.com, I get the unknown cipher error on Squid
but on the client I see a certificate error. When I look at the
certificate info, it is signed by Squid. It makes no sense at all.
Microsoft.com should be peeked and then spliced, not bumped. That
makes me think that I'm missing something else. I don't want to bump
at all, I just want to block sites by looking at SNI info.

Thanks

Leandro

On 19 October 2016 at 10:42, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 19/10/2016 7:44 p.m., Leandro Barragan wrote:
>> Hi!
>>
>> I'm having trouble with SSL Peek & Splice in Squid 3.5.16 using
>
> Please upgrade to 3.5.19 or later. Current is 3.5.22.
>
>> intercept mode. I'm trying to configure a transparent proxy (no CA
>> installed on clients) which denies access to specific sites. I
>> understand that if I can't Bump (my case), then I can only use SNI
>> information from TLS "Client Hello" on Step 2.
>
> Correct.
>
>>
>> Everything works OK with most sites, but when I try to connect to some
>> sites like facebook.com or microsoft.com, clients can't connect and I
>> get this error on cache.log:
>>
>>> [...]
>>> Error negotiating SSL on FD 111: error:140920F8:SSL routines:SSL3_GET_SERVER_HELLO:unknown cipher returned (1/-1/0)
>>> [...]
>>
>> Reading emails from this list, I came to the conclusion that this
>> error is related to new ciphers (like ChaCha20) which are not
>> supported by OpenSSL 1.0.1... So I tried to compile Squid using
>> OpenSSL 1.1.0, which is not possible (bug #4599). I also tried to
>> compile it using LibreSSL unsuccessfully.
>
> A more current Squid (3.5.19+) and OpenSSL 1.0.2 latest should work. It
> has for others.
>
>>
>> I fail to see why is this happening. I only need to peek on the
>> connection and make a decision based on SNI, I'm not Bumping, so I
>> don't understand why ciphers matter in my situation.
>
> Note that the sites you get this error on are the ones where "terminate"
> action is configured to happen.
>
> Terminate means impersonating the server and responding to the client
> with an HTTPS error page.
>
>
>
>>
>> My squid.conf:
>>
>>> [...]
>>> acl face ssl::server_name_regex -i facebook
>>> acl twitter ssl::server_name_regex -i twitter
>>>
>>> acl step1 at_step SslBump1
>>> acl step2 at_step SslBump2
>>> acl step3 at_step SslBump3
>>>
>>> sslproxy_cipher HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>>> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE
>>>
>>> http_port 3128
>>> http_port 3129 intercept
>>> https_port 3130 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/myCA.pem options=NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE cipher=HIGH:MEDIUM:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>>>
>>> sslproxy_capath /var/lib/ssl_db
>>>
>>> ssl_bump peek all step1
>>> ssl_bump peek all step2
>
> The use of "all" is redundant and useless in the above lines.
>
> Since peek is only valid at step #1 and #2 anyway the "step1 and step2
> are pointless.
>
>>> ssl_bump terminate face step3
>>> ssl_bump terminate twitter step3
>>> ssl_bump splice all step3
>
> The use of "step3" is redundant and useless.
>
> Since ACL "face" and ACL "twitter" are of the same type and used as a
> pair with the same action. You would be better off merging their values
> under one ACL name.
>
> Oh, and most content from facebook actually comes from the "fbcdn" domain.
>
> You might as well configure:
>
>  acl TF ssl::server_name_regex -i facebook fbcdn twitter
>  ssl_bump peek all
>  ssl_bump terminate TF
>  ssl_bump splice all
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Thu Oct 20 04:01:33 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 19 Oct 2016 22:01:33 -0600
Subject: [squid-users] Peeking on TLS traffic: unknown cipher returned
In-Reply-To: <CAARTC8k+jHak1CR_B61Y-L5z+7Px6d9jM5X_vD_MJxa=+JqYVA@mail.gmail.com>
References: <CAARTC8k+jHak1CR_B61Y-L5z+7Px6d9jM5X_vD_MJxa=+JqYVA@mail.gmail.com>
Message-ID: <2d98d293-f2ff-8f87-1d6c-c425d803115f@measurement-factory.com>

On 10/19/2016 12:44 AM, Leandro Barragan wrote:

>> error:140920F8:SSL routines:SSL3_GET_SERVER_HELLO:unknown cipher returned (1/-1/0)

> I fail to see why is this happening. I only need to peek on the
> connection and make a decision based on SNI, 

Please note that "peek and make a decision based on SNI" is not what
your configuration tells Squid to do. Your configuration tells Squid to
peek during step2, which means making a decision based on server
certificates (and SNI).


> I'm not Bumping, so I
> don't understand why ciphers matter in my situation.

The ciphers matter because Squid v3 uses OpenSSL parsers during step1,
step2, and step3. FWIW, Squid v4 uses OpenSSL parsers during step2 (a
little) and step3. It is possible to completely remove OpenSSL from
step2 but there is currently no project to do that AFAIK.


>> ssl_bump peek all step1
>> ssl_bump peek all step2
>> ssl_bump terminate face step3
>> ssl_bump terminate twitter step3
>> ssl_bump splice all step3

BTW, "step1", "step2", and "step3" ACLs do nothing useful in the above
config. You can safely remove them to arrive at the equivalent ssl_bump
configuration.


On 10/19/2016 07:42 AM, Amos Jeffries wrote:
> Terminate means impersonating the server and responding to the client
> with an HTTPS error page.

Terminate means "close client and server connections immediately". The
problem is not with the terminate action but with peeking (which relies
on OpenSSL, especially during step2, especially in Squid v3).


HTH,

Alex.



From rousskov at measurement-factory.com  Thu Oct 20 04:10:30 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 19 Oct 2016 22:10:30 -0600
Subject: [squid-users] Peeking on TLS traffic: unknown cipher returned
In-Reply-To: <CAARTC8n7dGRbD3hW0PwhfG5EX2horcwM4vAuqu=8MCkWuiwD=Q@mail.gmail.com>
References: <CAARTC8k+jHak1CR_B61Y-L5z+7Px6d9jM5X_vD_MJxa=+JqYVA@mail.gmail.com>
 <b7bade4f-2dc9-f5da-dbcf-750165262f16@treenet.co.nz>
 <CAARTC8n7dGRbD3hW0PwhfG5EX2horcwM4vAuqu=8MCkWuiwD=Q@mail.gmail.com>
Message-ID: <dfa7b43a-bd5d-c570-8a4d-757f674c339d@measurement-factory.com>

On 10/19/2016 08:51 PM, Leandro Barragan wrote:
> I get the unknown cipher error on Squid
> but on the client I see a certificate error. When I look at the
> certificate info, it is signed by Squid. It makes no sense at all.

When Squid v3 encounters an OpenSSL error (such as an unsupported
cipher), it tries to serve the corresponding error page to the user.
This happens before your "terminate" rules are reached and requires
impersonating the server, which explains why you see a Squid-signed
error page.

Squid v4 works better in this situation because:

* v4 does not rely on OpenSSL during step1. This will help if you are
willing to make decisions based on SNI/host alone (requires changing
your config).

* v4 can be configured to tunnel unexpected non-SSL traffic (via
on_unsupported_protocol). I am not sure whether this helps with the
ciphers issue during step2 (if you leave your configuration unchanged)
-- I do not remember whether Squid treats that kind of failure as an
unsupported protocol issue (but I doubt it does).


HTH,

Alex.



From jason_haar at trimble.com  Thu Oct 20 04:12:08 2016
From: jason_haar at trimble.com (Jason Haar)
Date: Thu, 20 Oct 2016 17:12:08 +1300
Subject: [squid-users] Peeking on TLS traffic: unknown cipher returned
In-Reply-To: <2d98d293-f2ff-8f87-1d6c-c425d803115f@measurement-factory.com>
References: <CAARTC8k+jHak1CR_B61Y-L5z+7Px6d9jM5X_vD_MJxa=+JqYVA@mail.gmail.com>
 <2d98d293-f2ff-8f87-1d6c-c425d803115f@measurement-factory.com>
Message-ID: <CAFChrgJKfZp0BUpW+4S_wJ7CsV+cMQEPWkrxnjGEX5wNp2Ptwg@mail.gmail.com>

On Thu, Oct 20, 2016 at 5:01 PM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> Please note that "peek and make a decision based on SNI" is not what
> your configuration tells Squid to do.
>

This is a complex situation for most people (myself included), can you tell
us how to "peek and make a decision based on SNI"?

I'm probably like the original poster in that I simply want to be able to
do transparent proxy of TCP/443 so as to better log HTTPS transactions. I
wouldn't even bother with the "terminate" bit - if I wanted to blacklist
some HTTPS sites, I'd rather rely on the normal non-bumping ACLs, the
SNI-learnt domain names -  and "deny" - I don't care if a cleartext blob is
sent through to a client who thinks it's TLS - it will break and that's all
that matters. Anything better *requires* full MiTM which I want to avoid as
I believe it has no future due to pinning.

Off to upgrade to 3.5.22 :-)

-- 
Cheers

Jason Haar
Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161020/50f9dd22/attachment.htm>

From rousskov at measurement-factory.com  Thu Oct 20 06:17:21 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 20 Oct 2016 00:17:21 -0600
Subject: [squid-users] Peeking on TLS traffic: unknown cipher returned
In-Reply-To: <CAFChrgJKfZp0BUpW+4S_wJ7CsV+cMQEPWkrxnjGEX5wNp2Ptwg@mail.gmail.com>
References: <CAARTC8k+jHak1CR_B61Y-L5z+7Px6d9jM5X_vD_MJxa=+JqYVA@mail.gmail.com>
 <2d98d293-f2ff-8f87-1d6c-c425d803115f@measurement-factory.com>
 <CAFChrgJKfZp0BUpW+4S_wJ7CsV+cMQEPWkrxnjGEX5wNp2Ptwg@mail.gmail.com>
Message-ID: <8b73df74-68ce-6443-ab01-9a61e6a1d481@measurement-factory.com>

On 10/19/2016 10:12 PM, Jason Haar wrote:

> This is a complex situation for most people (myself included), can you
> tell us how to "peek and make a decision based on SNI"?

I have (long time ago) in the "Peek at SNI and Bump" and other examples
at http://wiki.squid-cache.org/Features/SslPeekAndSplice

Since then, that page have been significantly improved, mostly by others
(thanks, Marcus!) so you may find better examples there.

In short, if you want to do everything based on SNI, then do not let
Squid to get to SslBump step3. Make all final (splice, bump, or
terminate) decisions during step2 (or earlier). That implies that your
ssl_bump rules have to be shaped without step2 and step3 ACLs.


> I'm probably like the original poster in that I simply want to be able
> to do transparent proxy of TCP/443 so as to better log HTTPS
> transactions. I wouldn't even bother with the "terminate" bit - if I
> wanted to blacklist some HTTPS sites, I'd rather rely on the normal
> non-bumping ACLs, the SNI-learnt domain names -  and "deny" - I don't
> care if a cleartext blob is sent through to a client who thinks it's TLS
> - it will break and that's all that matters.

Squid does not work that way. If you tell Squid to "deny" something,
Squid will most likely try to bump the client connection to serve the
corresponding error page. The early developers, reviewers, and users all
thought that serving a plain text error response to an SSL client is
pointless. If you want to avoid bumping at all costs, then "ssl_bump
terminate" is your best option.

Virtually all errors, including certificate validation and OpenSSL
failures are treated similar to access denials and result in bumping.
This is often the right default, but it would be good to add a knob for
fine-tuning that behavior, similar to how the recently added
on_unsupported_protocol fine-tunes treatment of parsing errors.


HTH,

Alex.



From Anton.Kornexl at Uni-Passau.De  Thu Oct 20 11:07:58 2016
From: Anton.Kornexl at Uni-Passau.De (Anton Kornexl)
Date: Thu, 20 Oct 2016 13:07:58 +0200
Subject: [squid-users] Lots of "Vary object loop!"
Message-ID: <5808C1AE020000940008A662@smtp1.gw.uni-passau.de>

Hello,
 
i also had many of these messages in cache.log
 
we do filtering with squidguard (redirect http://www.xxxx.xx ....)
 
It is possible that the same url is redirected for one user but not for another (different filter rules per user)
 
Are the redirected objects saved in cache:dir ?
Can i control which variables are used for vary checking?
 
Now i have disabled caching and the messages are gone but i would like to reactivate caching.


Anton Kornexl
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161020/0255eca2/attachment.htm>

From garryd at comnet.uz  Thu Oct 20 11:25:08 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Thu, 20 Oct 2016 16:25:08 +0500
Subject: [squid-users] Lots of "Vary object loop!"
In-Reply-To: <5808C1AE020000940008A662@smtp1.gw.uni-passau.de>
References: <5808C1AE020000940008A662@smtp1.gw.uni-passau.de>
Message-ID: <1476962708.9392.25.camel@comnet.uz>

On Thu, 2016-10-20 at 13:07 +0200, Anton Kornexl wrote:
> Hello,
> ?
> i also had many of these messages in cache.log
> ?
> we do filtering with squidguard (redirect http://www.xxxx.xx ....)
> ?
> It is possible that the same url is redirected for one user but not
> for?another (different filter rules per user)
> ?
> Are the redirected objects saved in cache:dir ?
> Can i control which variables are used for vary checking?
> ?
> Now i have disabled caching and the?messages are gone?but i would
> like to reactivate caching.
> 
> Anton Kornexl

Hi,

There are many reasons have been discussed on the list. For example:

http://lists.squid-cache.org/pipermail/squid-users/2015-August/005132.h
tml

Also, If you use collapsed_forwarding you may be affected by the false
positives described here:

http://bugs.squid-cache.org/show_bug.cgi?id=4619

Garri?


From squid3 at treenet.co.nz  Thu Oct 20 11:25:52 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 21 Oct 2016 00:25:52 +1300
Subject: [squid-users] Lots of "Vary object loop!"
In-Reply-To: <5808C1AE020000940008A662@smtp1.gw.uni-passau.de>
References: <5808C1AE020000940008A662@smtp1.gw.uni-passau.de>
Message-ID: <25d9f04f-4d34-69ee-3fa7-41e8db90d756@treenet.co.nz>

On 21/10/2016 12:07 a.m., Anton Kornexl wrote:
> Hello,
>  
> i also had many of these messages in cache.log
>  
> we do filtering with squidguard (redirect http://www.xxxx.xx ....)
>  
> It is possible that the same url is redirected for one user but not for another (different filter rules per user)
>  
> Are the redirected objects saved in cache:dir ?

Yes.

* If it is a true HTTP 30x redirect the followup client request will be
handled normally with regards to everything, including caching.

* If you are re-writing URLs the fetched object will be stored under the
mangled URL location.


> Can i control which variables are used for vary checking?

No. Variant values are determined by the server and provided by the client.

>  
> Now i have disabled caching and the messages are gone but i would like to reactivate caching.
> 

The bug data being presented recently hints that the message is being
logged when some new variant is needed and simply not-yet-cached. In
other words, a normal MISS is happening and nothing to worry about.

Amos



From gaela at ace-service.fr  Thu Oct 20 14:07:17 2016
From: gaela at ace-service.fr (Gael Ancelin)
Date: Thu, 20 Oct 2016 14:07:17 +0000
Subject: [squid-users] FTP : Squid sending private IP in PASV response
Message-ID: <bd96ae7bac3b4b54ade9ebd5aae16462@HERMES.ace.lan>

Hello,

I have searched in maillist archives but have not seen so far someone with the
same problem.

My Squid's objective is to foward FTP & HTTP requests to a distant server.

Squid is running on CentOS 7.2.
uname -r : 3.10.0-327.28.3.el7.x86_64
squid -v : Version 3.5.20


I don't have the choice to use anything but Squid, and I can't use firewalling
rules for forwarding directly ports.


WAN_1stPublic_IP ----------------------------[FIREWALL_1] -----[FTP_SERVER]

WAN_2ndPublic_IP ---[FIREWALL_2]--[SQUID]-----[VPN]-----[FTP_SERVER]


Here's my problem :
When I'm connecting in FTP on the 2nd Public IP, everything is ok, but when I
want to switch to passive mode, Squid is sending his own private ip instead of
the 2nd public IP. So the connexion timed out.


ftp> open <WAN 2ndPublic IP>
Connected to <WAN 2ndPublic IP> (<WAN 2ndPublic IP>).
220 Service ready
Name (<WAN 2ndPublic IP>:<user>): <login>
---> USER <login>
331 Please specify the password.
Password:
---> PASS XXXX
230 Login successful.
---> SYST
215 UNIX Type: L8
Remote system type is UNIX.
Using binary mode to transfer files.
ftp> pwd
---> PWD
257 "/"
ftp> ls
---> PASV
227 Entering Passive Mode (<SQUID Private IP>,<port>).
ftp: connect: Connexion termin?e par expiration du d?lai d'attente


Is there a way to "force" Squid to resend his public IP ?
I'm thinking of something like "pasv_address" option in vsftpd, but for squid.

Ga?l Ancelin
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161020/cee2f67f/attachment.htm>

From lean0x2f at gmail.com  Fri Oct 21 02:15:56 2016
From: lean0x2f at gmail.com (Leandro Barragan)
Date: Thu, 20 Oct 2016 23:15:56 -0300
Subject: [squid-users] Peeking on TLS traffic: unknown cipher returned
In-Reply-To: <2d98d293-f2ff-8f87-1d6c-c425d803115f@measurement-factory.com>
References: <CAARTC8k+jHak1CR_B61Y-L5z+7Px6d9jM5X_vD_MJxa=+JqYVA@mail.gmail.com>
 <2d98d293-f2ff-8f87-1d6c-c425d803115f@measurement-factory.com>
Message-ID: <CAARTC8kyKsnKQv+SXci0C02q_Nt7w0piYCKmxS_WaNFUb=NLqw@mail.gmail.com>

Thanks for your time Alex! I modified my original config based on Amos
recommendations, so I think now I have a more consistent peek & splice
config:

 acl TF ssl::server_name_regex -i facebook fbcdn twitter reddit
 ssl_bump peek all
 ssl_bump terminate TF
 ssl_bump splice all

As you mentioned, terminate closes the connection, it doesn't serve an
error page (when it works, i.e. with reddit and twitter).

I've compiled Squid 3.5.22 using OpenSSL 1.0.2j and I'm having the
same exact issue, even with this new config. Based on what you
explained, I think it's a OpenSSL problem and Squid can't do anything
about it. I have two reasons to believe that:

1) The "unknown cipher returned" error get's triggered on terminated
and non terminated (e.g. microsoft.com) sites, which makes me think it
has nothing to do with Squid ACLs.
2) All problematic sites use a new cipher called "ChaCha20" (E.g.
TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256....according to Qualys
online analyzer and TestSSLServer tool)

A lot of sites are using this new cipher. I'm back at the beginning, I
will continue trying to compile Squid with patched versions of OpenSSL
or LibreSSL.

Thanks!

On 20 October 2016 at 01:01, Alex Rousskov
<rousskov at measurement-factory.com> wrote:
> On 10/19/2016 12:44 AM, Leandro Barragan wrote:
>
>>> error:140920F8:SSL routines:SSL3_GET_SERVER_HELLO:unknown cipher returned (1/-1/0)
>
>> I fail to see why is this happening. I only need to peek on the
>> connection and make a decision based on SNI,
>
> Please note that "peek and make a decision based on SNI" is not what
> your configuration tells Squid to do. Your configuration tells Squid to
> peek during step2, which means making a decision based on server
> certificates (and SNI).
>
>
>> I'm not Bumping, so I
>> don't understand why ciphers matter in my situation.
>
> The ciphers matter because Squid v3 uses OpenSSL parsers during step1,
> step2, and step3. FWIW, Squid v4 uses OpenSSL parsers during step2 (a
> little) and step3. It is possible to completely remove OpenSSL from
> step2 but there is currently no project to do that AFAIK.
>
>
>>> ssl_bump peek all step1
>>> ssl_bump peek all step2
>>> ssl_bump terminate face step3
>>> ssl_bump terminate twitter step3
>>> ssl_bump splice all step3
>
> BTW, "step1", "step2", and "step3" ACLs do nothing useful in the above
> config. You can safely remove them to arrive at the equivalent ssl_bump
> configuration.
>
>
> On 10/19/2016 07:42 AM, Amos Jeffries wrote:
>> Terminate means impersonating the server and responding to the client
>> with an HTTPS error page.
>
> Terminate means "close client and server connections immediately". The
> problem is not with the terminate action but with peeking (which relies
> on OpenSSL, especially during step2, especially in Squid v3).
>
>
> HTH,
>
> Alex.
>


From garryd at comnet.uz  Fri Oct 21 05:15:28 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Fri, 21 Oct 2016 10:15:28 +0500
Subject: [squid-users] FTP : Squid sending private IP in PASV response
In-Reply-To: <bd96ae7bac3b4b54ade9ebd5aae16462@HERMES.ace.lan>
References: <bd96ae7bac3b4b54ade9ebd5aae16462@HERMES.ace.lan>
Message-ID: <1477026928.18948.6.camel@comnet.uz>

On Thu, 2016-10-20 at 14:07 +0000, Gael Ancelin wrote:
> Hello,
> ?
> I have searched in maillist archives but have not seen so far someone
> with the
> same problem.
> ?
> My Squid's objective is to foward FTP & HTTP requests to a distant
> server.
> ?
> Squid is running on CentOS 7.2.
> uname -r : 3.10.0-327.28.3.el7.x86_64
> squid -v : Version 3.5.20
> ?
> ?
> I don't have the choice to use anything but Squid, and I can't use
> firewalling
> rules for forwarding directly ports.
> ?
> ?
> WAN_1stPublic_IP ----------------------------[FIREWALL_1] ---
> --[FTP_SERVER]
> ?
> WAN_2ndPublic_IP ---[FIREWALL_2]--[SQUID]-----[VPN]-----[FTP_SERVER]
> ?
> ?
> Here's my problem :
> When I'm connecting in FTP on the 2nd Public IP, everything is ok,
> but when I
> want to switch to passive mode, Squid is sending his own private ip
> instead of
> the 2nd public IP. So the connexion timed out.
> ?
> ?
> ftp> open <WAN 2ndPublic IP>
> Connected to <WAN 2ndPublic IP> (<WAN 2ndPublic IP>).
> 220 Service ready
> Name (<WAN 2ndPublic IP>:<user>): <login>
> ---> USER <login>
> 331 Please specify the password.
> Password:
> ---> PASS XXXX
> 230 Login successful.
> ---> SYST
> 215 UNIX Type: L8
> Remote system type is UNIX.
> Using binary mode to transfer files.
> ftp> pwd
> ---> PWD
> 257 "/"
> ftp> ls
> ---> PASV
> 227 Entering Passive Mode (<SQUID Private IP>,<port>).
> ftp: connect: Connexion termin?e par expiration du d?lai d'attente
> ?
> ?
> Is there a way to "force" Squid to resend his public IP ?
> I'm thinking of something like "pasv_address" option in vsftpd, but
> for squid.
> ?
> Ga?l Ancelin

Hi,

Can you provide the configuration options related to FTP?
I can't reproduce the problem using following method:

# diff etc/squid.conf.default etc/squid.conf
73a74,75
>?
> ftp_port 21

---

$ ftp 127.0.0.1
Connected to 127.0.0.1.
220 Service ready
Name (127.0.0.1:user): anonymous at mirror.yandex.ru
530 Must login first
530 Must login first
SSL not available
331 Please specify the password.
Password:
230 Login successful.
Remote system type is UNIX.
Using binary mode to transfer files.
ftp> passive
Passive mode on.
ftp> ls
227 Entering Passive Mode (127,0,0,1,229,181).
150 Here comes the directory listing.
drwxr-xr-x???19 ftp??????ftp??????????4096 Oct 21 05:00 altlinux
...
drwxr-xr-x???11 ftp??????ftp??????????4096 Oct 21 03:16 ubuntu-releases
226 Transfer complete

---

The example showed that Squid returned the IP address of the interface
facing the client, not the IP address of my interface facing the
origin.

Garri


From gaela at ace-service.fr  Fri Oct 21 08:27:21 2016
From: gaela at ace-service.fr (Gael Ancelin)
Date: Fri, 21 Oct 2016 08:27:21 +0000
Subject: [squid-users] FTP : Squid sending private IP in PASV response
In-Reply-To: <1477026928.18948.6.camel@comnet.uz>
References: <bd96ae7bac3b4b54ade9ebd5aae16462@HERMES.ace.lan>
 <1477026928.18948.6.camel@comnet.uz>
Message-ID: <280e11faf0ab42349b20e0f6c1747298@HERMES.ace.lan>

Hello,

Thanks for your interest. 


As resquested, here is my FTP related configuration :

acl FTP proto FTP
http_access allow FTP
always_direct allow FTP
ftp_port 21 accel defaultsite=<real_server_ftp> protocol=FTP


------- On Squid itself ------
ftp> open 127.0.0.1
Connected to 127.0.0.1 (127.0.0.1).
220 Service ready
Name (127.0.0.1:<local_user>): <ftp_user>
---> USER <ftp_user>
331 Please specify the password.
Password:
---> PASS XXXX
230 Login successful.
---> SYST
215 UNIX Type: L8
Remote system type is UNIX.
Using binary mode to transfer files.
ftp> pwd
---> PWD
257 "/"
ftp> ls
---> PASV
227 Entering Passive Mode (127,0,0,1,158,0).
---> LIST
150 Here comes the directory listing.
[...]
226 Transfer complete


------- From anywhere (including Squid itself ------
ftp> open <dns name of the squid machine>
Connected to <dns name of the squid machine> (54.xx.xx.xx).
220 Service ready
Name (<dns name of the squid machine>:<local_user>): <ftp_user>
---> USER <ftp_user>
331 Please specify the password.
Password:
---> PASS XXXX
230 Login successful.
---> SYST
215 UNIX Type: L8
Remote system type is UNIX.
Using binary mode to transfer files.
ftp> pwd
---> PWD
257 "/"
ftp> cd scripts
---> CWD scripts
250 Directory successfully changed.
ftp> ls
---> PASV
227 Entering Passive Mode (172,31,xx,xx,213,249).



WAN_IP---[FW]-------localIP1-[SQUID]-localIP2------------localIP3-[FTP_Server]

I was expecting something like "227 Entering Passive Mode (54,xx,xx,xx,213,249)." 
with public ip.
What I want is a response like (WAN_IP,port), but what I obtain is 
(localIP1,port) instead.

Squid does not respond with the FTP server address, so I presume that Squid is
understanding enough FTP protocol to modify response and put his own ip address
instead of the real FTP server's.
So I'm wondering if it exists a way to force squid to respond with a fixed IP 
address instead of his own local address.




-----Message d'origine-----
De?: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Garri Djavadyan
Envoy??: vendredi 21 octobre 2016 07:15
??: squid-users at lists.squid-cache.org
Objet?: Re: [squid-users] FTP : Squid sending private IP in PASV response

On Thu, 2016-10-20 at 14:07 +0000, Gael Ancelin wrote:
> Hello,
> ?
> I have searched in maillist archives but have not seen so far someone 
> with the same problem.
> ?
> My Squid's objective is to foward FTP & HTTP requests to a distant 
> server.
> ?
> Squid is running on CentOS 7.2.
> uname -r : 3.10.0-327.28.3.el7.x86_64
> squid -v : Version 3.5.20
> ?
> ?
> I don't have the choice to use anything but Squid, and I can't use 
> firewalling rules for forwarding directly ports.
> ?
> ?
> WAN_1stPublic_IP ----------------------------[FIREWALL_1] --- 
> --[FTP_SERVER]
> ?
> WAN_2ndPublic_IP ---[FIREWALL_2]--[SQUID]-----[VPN]-----[FTP_SERVER]
> ?
> ?
> Here's my problem :
> When I'm connecting in FTP on the 2nd Public IP, everything is ok, but 
> when I want to switch to passive mode, Squid is sending his own 
> private ip instead of the 2nd public IP. So the connexion timed out.
> ?
> ?
> ftp> open <WAN 2ndPublic IP>
> Connected to <WAN 2ndPublic IP> (<WAN 2ndPublic IP>).
> 220 Service ready
> Name (<WAN 2ndPublic IP>:<user>): <login>
> ---> USER <login>
> 331 Please specify the password.
> Password:
> ---> PASS XXXX
> 230 Login successful.
> ---> SYST
> 215 UNIX Type: L8
> Remote system type is UNIX.
> Using binary mode to transfer files.
> ftp> pwd
> ---> PWD
> 257 "/"
> ftp> ls
> ---> PASV
> 227 Entering Passive Mode (<SQUID Private IP>,<port>).
> ftp: connect: Connexion termin?e par expiration du d?lai d'attente
> ?
> ?
> Is there a way to "force" Squid to resend his public IP ?
> I'm thinking of something like "pasv_address" option in vsftpd, but 
> for squid.
> ?
> Ga?l Ancelin

Hi,

Can you provide the configuration options related to FTP?
I can't reproduce the problem using following method:

# diff etc/squid.conf.default etc/squid.conf
73a74,75
>?
> ftp_port 21

---

$ ftp 127.0.0.1
Connected to 127.0.0.1.
220 Service ready
Name (127.0.0.1:user): anonymous at mirror.yandex.ru
530 Must login first
530 Must login first
SSL not available
331 Please specify the password.
Password:
230 Login successful.
Remote system type is UNIX.
Using binary mode to transfer files.
ftp> passive
Passive mode on.
ftp> ls
227 Entering Passive Mode (127,0,0,1,229,181).
150 Here comes the directory listing.
drwxr-xr-x???19 ftp??????ftp??????????4096 Oct 21 05:00 altlinux ...
drwxr-xr-x???11 ftp??????ftp??????????4096 Oct 21 03:16 ubuntu-releases
226 Transfer complete

---

The example showed that Squid returned the IP address of the interface facing the client, not the IP address of my interface facing the origin.

Garri
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From garryd at comnet.uz  Fri Oct 21 09:02:04 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Fri, 21 Oct 2016 14:02:04 +0500
Subject: [squid-users] FTP : Squid sending private IP in PASV response
In-Reply-To: <280e11faf0ab42349b20e0f6c1747298@HERMES.ace.lan>
References: <bd96ae7bac3b4b54ade9ebd5aae16462@HERMES.ace.lan>
 <1477026928.18948.6.camel@comnet.uz>
 <280e11faf0ab42349b20e0f6c1747298@HERMES.ace.lan>
Message-ID: <1477040524.18948.30.camel@comnet.uz>

On Fri, 2016-10-21 at 08:27 +0000, Gael Ancelin wrote:
> WAN_IP---[FW]-------localIP1-[SQUID]-localIP2------------localIP3-
> [FTP_Server]
> 
> I was expecting something like "227 Entering Passive Mode
> (54,xx,xx,xx,213,249)."?
> with public ip.
> What I want is a response like (WAN_IP,port), but what I obtain is?
> (localIP1,port) instead.
> 
> Squid does not respond with the FTP server address, so I presume that
> Squid is
> understanding enough FTP protocol to modify response and put his own
> ip address
> instead of the real FTP server's.

According to your scheme, FW is DNAT device and it forwards packets
destined to FTP control channel port (21) on public IP of FW to private
localIP1 of SQUID. In that scenario Squid don't even know that the
client used WAN_IP to access FTP service and therefore it can't use the
public IP even if it wish.


> So I'm wondering if it exists a way to force squid to respond with a
>?fixed IP?>?address instead of his own local address.

Here?http://www.squid-cache.org/Doc/config/?you can find all available
options.


From andre61 at brazcubas.br  Fri Oct 21 11:21:33 2016
From: andre61 at brazcubas.br (=?UTF-8?Q?Andr=c3=a9_Janna?=)
Date: Fri, 21 Oct 2016 09:21:33 -0200
Subject: [squid-users] sourcehash load balance
Message-ID: <d4af11ba-018f-0d88-c953-c9932a4f0891@brazcubas.br>

I set up a Squid proxy that forwards all requests to 2 parent caches. 
I'm using Squid version 3.5.19.
My goal is that multiple connection from a client to a server should be 
forwarded to the same parent, so that the server see all requests coming 
from the same IP address.

I'm using the following configuration:
cache_peer squid1 parent 3128 0 no-query sourcehash
cache_peer squid2 parent 3128 0 no-query sourcehash
never_direct allow all

Looking at access.log some requests are tagged as CLOSEST_PARENT instead 
of SOURCEHASH_PARENT, so it seams that Squid is not always using source 
hash rule to forward requests to parent caches.
For instance:
1477046954.047   3882 10.11.2.4 TCP_TUNNEL/200 21935 CONNECT 
sso.cisco.com:443 - SOURCEHASH_PARENT/10.0.33.12 -
1477046968.056     21 10.11.2.4 TCP_MISS/200 1012 POST 
http://ocsp.digicert.com/ - CLOSEST_PARENT/10.0.33.13 
application/ocsp-response
1477047782.038     22 10.11.2.4 TCP_MISS/204 307 GET 
http://clients1.google.com/generate_204 - SOURCEHASH_PARENT/10.0.33.12 -
1477047782.045    181 10.11.2.4 TCP_MISS/200 745 GET 
http://tags.bluekai.com/site/2964? - CLOSEST_PARENT/10.0.33.13 image/gif

So requests from the same client are not sent to the same parent cache.
How can I force Squid to always use source hash parent selection method?


Regards,
Andr? Janna


From jlay at slave-tothe-box.net  Fri Oct 21 13:55:41 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Fri, 21 Oct 2016 07:55:41 -0600
Subject: [squid-users] Peeking on TLS traffic: unknown cipher returned
In-Reply-To: <CAARTC8kyKsnKQv+SXci0C02q_Nt7w0piYCKmxS_WaNFUb=NLqw@mail.gmail.com>
References: <CAARTC8k+jHak1CR_B61Y-L5z+7Px6d9jM5X_vD_MJxa=+JqYVA@mail.gmail.com>
 <2d98d293-f2ff-8f87-1d6c-c425d803115f@measurement-factory.com>
 <CAARTC8kyKsnKQv+SXci0C02q_Nt7w0piYCKmxS_WaNFUb=NLqw@mail.gmail.com>
Message-ID: <6b1a87c4f76aa544d5316e03f3769085@localhost>

On 2016-10-20 20:15, Leandro Barragan wrote:
> Thanks for your time Alex! I modified my original config based on Amos
> recommendations, so I think now I have a more consistent peek & splice
> config:
> 
>  acl TF ssl::server_name_regex -i facebook fbcdn twitter reddit
>  ssl_bump peek all
>  ssl_bump terminate TF
>  ssl_bump splice all
> 
> As you mentioned, terminate closes the connection, it doesn't serve an
> error page (when it works, i.e. with reddit and twitter).
> 
> I've compiled Squid 3.5.22 using OpenSSL 1.0.2j and I'm having the
> same exact issue, even with this new config. Based on what you
> explained, I think it's a OpenSSL problem and Squid can't do anything
> about it. I have two reasons to believe that:
> 
> 1) The "unknown cipher returned" error get's triggered on terminated
> and non terminated (e.g. microsoft.com) sites, which makes me think it
> has nothing to do with Squid ACLs.
> 2) All problematic sites use a new cipher called "ChaCha20" (E.g.
> TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256....according to Qualys
> online analyzer and TestSSLServer tool)
> 
> A lot of sites are using this new cipher. I'm back at the beginning, I
> will continue trying to compile Squid with patched versions of OpenSSL
> or LibreSSL.
> 
> Thanks!
> 
> On 20 October 2016 at 01:01, Alex Rousskov
> <rousskov at measurement-factory.com> wrote:
>> On 10/19/2016 12:44 AM, Leandro Barragan wrote:
>> 
>>>> error:140920F8:SSL routines:SSL3_GET_SERVER_HELLO:unknown cipher 
>>>> returned (1/-1/0)
>> 
>>> I fail to see why is this happening. I only need to peek on the
>>> connection and make a decision based on SNI,
>> 
>> Please note that "peek and make a decision based on SNI" is not what
>> your configuration tells Squid to do. Your configuration tells Squid 
>> to
>> peek during step2, which means making a decision based on server
>> certificates (and SNI).
>> 
>> 
>>> I'm not Bumping, so I
>>> don't understand why ciphers matter in my situation.
>> 
>> The ciphers matter because Squid v3 uses OpenSSL parsers during step1,
>> step2, and step3. FWIW, Squid v4 uses OpenSSL parsers during step2 (a
>> little) and step3. It is possible to completely remove OpenSSL from
>> step2 but there is currently no project to do that AFAIK.
>> 
>> 
>>>> ssl_bump peek all step1
>>>> ssl_bump peek all step2
>>>> ssl_bump terminate face step3
>>>> ssl_bump terminate twitter step3
>>>> ssl_bump splice all step3
>> 
>> BTW, "step1", "step2", and "step3" ACLs do nothing useful in the above
>> config. You can safely remove them to arrive at the equivalent 
>> ssl_bump
>> configuration.
>> 
>> 
>> On 10/19/2016 07:42 AM, Amos Jeffries wrote:
>>> Terminate means impersonating the server and responding to the client
>>> with an HTTPS error page.
>> 
>> Terminate means "close client and server connections immediately". The
>> problem is not with the terminate action but with peeking (which 
>> relies
>> on OpenSSL, especially during step2, especially in Squid v3).
>> 
>> 
>> HTH,
>> 
>> Alex.

FWIW I've had great success with the git version of libressl and using 
the below:

./configure --prefix=/opt/libressl

and for squid:

./configure --prefix=/opt --with-openssl=/opt/libressl --enable-ssl 
--enable-ssl-crtd

James


From heiler.bemerguy at cinbesa.com.br  Fri Oct 21 15:21:10 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Fri, 21 Oct 2016 12:21:10 -0300
Subject: [squid-users] Caching http google deb files
In-Reply-To: <CA+sSnVai079zNS6X+Rni9qaRKOAt6PF+nrZQhBR462zL1zWZuA@mail.gmail.com>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
 <CA+sSnVZ2ErFD+LeLVH3KOjJ_0PuqGyWfRHA23zY8yJQs3kP+Rw@mail.gmail.com>
 <89f9840b-7ec7-2f0b-a81c-5376c344878e@treenet.co.nz>
 <CA+sSnVYCy5E00jKK5cPZm3q+eBX8Fx=Mjs_iu4Xs0oebxcte9Q@mail.gmail.com>
 <1ba79370-ff21-0e52-a5dc-89919c1171b4@measurement-factory.com>
 <57F68690.1020109@tlinx.org>
 <2c043b07-b941-9e29-8813-4642070384f6@measurement-factory.com>
 <CA+sSnVai079zNS6X+Rni9qaRKOAt6PF+nrZQhBR462zL1zWZuA@mail.gmail.com>
Message-ID: <14791d65-c8ce-7bb1-47b2-55ebefa507da@cinbesa.com.br>


Hello,

I've limited the "vary" usage and gained some hits by making these 
modifications (in blue) to the http.cc code:

     while (strListGetItem(&vary, ',', &item, &ilen, &pos)) {
         SBuf name(item, ilen);
         if (name == asterisk) {
*/** vstr.clear();
             break; **/ *
*            continue;*
         }
         name.toLower();

*       if (name.cmp("accept", 6) != 0 &&**
**          name.cmp("user-agent", 10) != 0)**
**               continue;*

         if (!vstr.isEmpty())
             vstr.append(", ", 2);



-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751



Em 07/10/2016 06:26, Hardik Dangar escreveu:
> Hey Alex,
>
> I totally get that Vary code is different, I have been trying to 
> understand squid code for last few days although my C, C++ skills are 
> very limited I am able to understand bits and pieces here and there. I 
> have also read HTTP 1.1 specs for cache ( 
> https://tools.ietf.org/html/rfc2616#section-13 )
>
> After doing fair bit of research I believe we need to two things,
>
> 1) start a campaign to convince webmasters to update their server 
> configs,  for that to happen I am doing my research on apache and 
> Nginx servers on how to implement ( HTTP 1.1 spec cache guidelines ) 
> and will provide them copy paste configs for all requests or for the 
> file types like deb,apk,rpm,exe(binary files),etc...
>
> I am documenting that here,
> https://hardikdangar.github.io/thecacheproject/
>
> and once I finish everything I will post everything at the 
> squid-dev list here so all of you can look at it and if you guys 
> approve it, I will personally try to contact the big providers and 
> send them above page with solutions. and will ask community support 
> and will publish it to twitter and other social sites to get support.
>
> 2) I want to build a module which will first handle Vary: * requests 
> and convert it into Vary: Accept-Encoding or something similar but 
> only for the ACL's specified by cache administrator.
>
> Next, there are use cases like GitHub which are very difficult to 
> handle but I feel there is a way we can handle those use cases so I 
> will build ACL for those.
>
> For this, i am trying to understand squid code, After looking at dev 
> docs, I understand how the request is handled at clientBeginRequest. 
> But I am very confused at how squid handles the response.  I know 
> client_side_reply.cc is the file where the response is handled but I 
> am not sure how StoreEntry::checkCachable() method in store.cc is 
> called before it as that is the method i get in squid logs when the 
> cache is denied.
>
> Basically, I need to know how to debug line by line source for squid. 
> Right now my method of testing involves building squid and adding 
> debug lines and its very slow process as it takes time every time. Can 
> you help me with this ? is there a way i could send a request directly 
> to squid source file i.e debug source code line by line ? If so what 
> are the tools required and how to set it up ?
>
> Again, I am sorry if i am asking too much but my C experience is very 
> limited and i feel like i am asking very naive questions but these are 
> very difficult for me at this stage and i really appreciate all of the 
> squid dev teams who is been answering all of my questions. Thank you 
> very much for that.
> --------
>
> I just want a better cache support for squid and modern day use cases.
>
> On Thu, Oct 6, 2016 at 11:25 PM, Alex Rousskov 
> <rousskov at measurement-factory.com 
> <mailto:rousskov at measurement-factory.com>> wrote:
>
>     On 10/06/2016 11:14 AM, Linda A. Walsh wrote:
>     > Alex Rousskov wrote:
>     >> We can, but ignoring Vary requires more/different work than adding
>     >> another refresh_pattern option. Vary is not a refresh mechanism so
>     >> different code areas need to be modified to ignore (but still
>     forward!)
>     >> Vary.
>
>
>     >    I can't say for certain, but I'd give it a 75% shot of it being
>     > used as a forced-refresh pattern
>
>     The [ab]use cases do not matter here -- the _code_ handling Vary
>     is very
>     different from the code handling refresh logic. That difference is
>     natural and unavoidable because the two protocol mechanisms are very
>     different, even if they both can be and are used to create the
>     same effect.
>
>     Alex.
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161021/0868eeb3/attachment.htm>

From lean0x2f at gmail.com  Fri Oct 21 15:58:52 2016
From: lean0x2f at gmail.com (Leandro Barragan)
Date: Fri, 21 Oct 2016 12:58:52 -0300
Subject: [squid-users] Peeking on TLS traffic: unknown cipher returned
In-Reply-To: <6b1a87c4f76aa544d5316e03f3769085@localhost>
References: <CAARTC8k+jHak1CR_B61Y-L5z+7Px6d9jM5X_vD_MJxa=+JqYVA@mail.gmail.com>
 <2d98d293-f2ff-8f87-1d6c-c425d803115f@measurement-factory.com>
 <CAARTC8kyKsnKQv+SXci0C02q_Nt7w0piYCKmxS_WaNFUb=NLqw@mail.gmail.com>
 <6b1a87c4f76aa544d5316e03f3769085@localhost>
Message-ID: <CAARTC8m7oYOoxnzs63=n2dxuuRCy4zpMuocoA_kDjwQte7SN3Q@mail.gmail.com>

James, thanks for your advice! I've read your email on this list about
LibreSSL. I tried to compile Squid with LibreSSL in the first place
because of what you wrote about ChaCha20. But unfortunately, I
couldn't, compilation stopped because of some obscure error.

Do you remember what version of squid and libressl you used? BTW I
tried with OpenSSL 1.0.2g applying the CloudFare ChaCha20 patch, but
it doesn't work either, same error (unknown cipher)

Thanks!

On 21 October 2016 at 10:55, James Lay <jlay at slave-tothe-box.net> wrote:
> On 2016-10-20 20:15, Leandro Barragan wrote:
>>
>> Thanks for your time Alex! I modified my original config based on Amos
>> recommendations, so I think now I have a more consistent peek & splice
>> config:
>>
>>  acl TF ssl::server_name_regex -i facebook fbcdn twitter reddit
>>  ssl_bump peek all
>>  ssl_bump terminate TF
>>  ssl_bump splice all
>>
>> As you mentioned, terminate closes the connection, it doesn't serve an
>> error page (when it works, i.e. with reddit and twitter).
>>
>> I've compiled Squid 3.5.22 using OpenSSL 1.0.2j and I'm having the
>> same exact issue, even with this new config. Based on what you
>> explained, I think it's a OpenSSL problem and Squid can't do anything
>> about it. I have two reasons to believe that:
>>
>> 1) The "unknown cipher returned" error get's triggered on terminated
>> and non terminated (e.g. microsoft.com) sites, which makes me think it
>> has nothing to do with Squid ACLs.
>> 2) All problematic sites use a new cipher called "ChaCha20" (E.g.
>> TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256....according to Qualys
>> online analyzer and TestSSLServer tool)
>>
>> A lot of sites are using this new cipher. I'm back at the beginning, I
>> will continue trying to compile Squid with patched versions of OpenSSL
>> or LibreSSL.
>>
>> Thanks!
>>
>> On 20 October 2016 at 01:01, Alex Rousskov
>> <rousskov at measurement-factory.com> wrote:
>>>
>>> On 10/19/2016 12:44 AM, Leandro Barragan wrote:
>>>
>>>>> error:140920F8:SSL routines:SSL3_GET_SERVER_HELLO:unknown cipher
>>>>> returned (1/-1/0)
>>>
>>>
>>>> I fail to see why is this happening. I only need to peek on the
>>>> connection and make a decision based on SNI,
>>>
>>>
>>> Please note that "peek and make a decision based on SNI" is not what
>>> your configuration tells Squid to do. Your configuration tells Squid to
>>> peek during step2, which means making a decision based on server
>>> certificates (and SNI).
>>>
>>>
>>>> I'm not Bumping, so I
>>>> don't understand why ciphers matter in my situation.
>>>
>>>
>>> The ciphers matter because Squid v3 uses OpenSSL parsers during step1,
>>> step2, and step3. FWIW, Squid v4 uses OpenSSL parsers during step2 (a
>>> little) and step3. It is possible to completely remove OpenSSL from
>>> step2 but there is currently no project to do that AFAIK.
>>>
>>>
>>>>> ssl_bump peek all step1
>>>>> ssl_bump peek all step2
>>>>> ssl_bump terminate face step3
>>>>> ssl_bump terminate twitter step3
>>>>> ssl_bump splice all step3
>>>
>>>
>>> BTW, "step1", "step2", and "step3" ACLs do nothing useful in the above
>>> config. You can safely remove them to arrive at the equivalent ssl_bump
>>> configuration.
>>>
>>>
>>> On 10/19/2016 07:42 AM, Amos Jeffries wrote:
>>>>
>>>> Terminate means impersonating the server and responding to the client
>>>> with an HTTPS error page.
>>>
>>>
>>> Terminate means "close client and server connections immediately". The
>>> problem is not with the terminate action but with peeking (which relies
>>> on OpenSSL, especially during step2, especially in Squid v3).
>>>
>>>
>>> HTH,
>>>
>>> Alex.
>
>
> FWIW I've had great success with the git version of libressl and using the
> below:
>
> ./configure --prefix=/opt/libressl
>
> and for squid:
>
> ./configure --prefix=/opt --with-openssl=/opt/libressl --enable-ssl
> --enable-ssl-crtd
>
> James
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From jlay at slave-tothe-box.net  Fri Oct 21 16:01:52 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Fri, 21 Oct 2016 10:01:52 -0600
Subject: [squid-users] Peeking on TLS traffic: unknown cipher returned
In-Reply-To: <CAARTC8m7oYOoxnzs63=n2dxuuRCy4zpMuocoA_kDjwQte7SN3Q@mail.gmail.com>
References: <CAARTC8k+jHak1CR_B61Y-L5z+7Px6d9jM5X_vD_MJxa=+JqYVA@mail.gmail.com>
 <2d98d293-f2ff-8f87-1d6c-c425d803115f@measurement-factory.com>
 <CAARTC8kyKsnKQv+SXci0C02q_Nt7w0piYCKmxS_WaNFUb=NLqw@mail.gmail.com>
 <6b1a87c4f76aa544d5316e03f3769085@localhost>
 <CAARTC8m7oYOoxnzs63=n2dxuuRCy4zpMuocoA_kDjwQte7SN3Q@mail.gmail.com>
Message-ID: <9a1bdcd7ccbbdfe6d901dfd674003617@localhost>

On 2016-10-21 09:58, Leandro Barragan wrote:
> James, thanks for your advice! I've read your email on this list about
> LibreSSL. I tried to compile Squid with LibreSSL in the first place
> because of what you wrote about ChaCha20. But unfortunately, I
> couldn't, compilation stopped because of some obscure error.
> 
> Do you remember what version of squid and libressl you used? BTW I
> tried with OpenSSL 1.0.2g applying the CloudFare ChaCha20 patch, but
> it doesn't work either, same error (unknown cipher)
> 
> Thanks!
> 
> On 21 October 2016 at 10:55, James Lay <jlay at slave-tothe-box.net> 
> wrote:
>> On 2016-10-20 20:15, Leandro Barragan wrote:
>>> 
>>> Thanks for your time Alex! I modified my original config based on 
>>> Amos
>>> recommendations, so I think now I have a more consistent peek & 
>>> splice
>>> config:
>>> 
>>>  acl TF ssl::server_name_regex -i facebook fbcdn twitter reddit
>>>  ssl_bump peek all
>>>  ssl_bump terminate TF
>>>  ssl_bump splice all
>>> 
>>> As you mentioned, terminate closes the connection, it doesn't serve 
>>> an
>>> error page (when it works, i.e. with reddit and twitter).
>>> 
>>> I've compiled Squid 3.5.22 using OpenSSL 1.0.2j and I'm having the
>>> same exact issue, even with this new config. Based on what you
>>> explained, I think it's a OpenSSL problem and Squid can't do anything
>>> about it. I have two reasons to believe that:
>>> 
>>> 1) The "unknown cipher returned" error get's triggered on terminated
>>> and non terminated (e.g. microsoft.com) sites, which makes me think 
>>> it
>>> has nothing to do with Squid ACLs.
>>> 2) All problematic sites use a new cipher called "ChaCha20" (E.g.
>>> TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256....according to Qualys
>>> online analyzer and TestSSLServer tool)
>>> 
>>> A lot of sites are using this new cipher. I'm back at the beginning, 
>>> I
>>> will continue trying to compile Squid with patched versions of 
>>> OpenSSL
>>> or LibreSSL.
>>> 
>>> Thanks!
>>> 
>>> On 20 October 2016 at 01:01, Alex Rousskov
>>> <rousskov at measurement-factory.com> wrote:
>>>> 
>>>> On 10/19/2016 12:44 AM, Leandro Barragan wrote:
>>>> 
>>>>>> error:140920F8:SSL routines:SSL3_GET_SERVER_HELLO:unknown cipher
>>>>>> returned (1/-1/0)
>>>> 
>>>> 
>>>>> I fail to see why is this happening. I only need to peek on the
>>>>> connection and make a decision based on SNI,
>>>> 
>>>> 
>>>> Please note that "peek and make a decision based on SNI" is not what
>>>> your configuration tells Squid to do. Your configuration tells Squid 
>>>> to
>>>> peek during step2, which means making a decision based on server
>>>> certificates (and SNI).
>>>> 
>>>> 
>>>>> I'm not Bumping, so I
>>>>> don't understand why ciphers matter in my situation.
>>>> 
>>>> 
>>>> The ciphers matter because Squid v3 uses OpenSSL parsers during 
>>>> step1,
>>>> step2, and step3. FWIW, Squid v4 uses OpenSSL parsers during step2 
>>>> (a
>>>> little) and step3. It is possible to completely remove OpenSSL from
>>>> step2 but there is currently no project to do that AFAIK.
>>>> 
>>>> 
>>>>>> ssl_bump peek all step1
>>>>>> ssl_bump peek all step2
>>>>>> ssl_bump terminate face step3
>>>>>> ssl_bump terminate twitter step3
>>>>>> ssl_bump splice all step3
>>>> 
>>>> 
>>>> BTW, "step1", "step2", and "step3" ACLs do nothing useful in the 
>>>> above
>>>> config. You can safely remove them to arrive at the equivalent 
>>>> ssl_bump
>>>> configuration.
>>>> 
>>>> 
>>>> On 10/19/2016 07:42 AM, Amos Jeffries wrote:
>>>>> 
>>>>> Terminate means impersonating the server and responding to the 
>>>>> client
>>>>> with an HTTPS error page.
>>>> 
>>>> 
>>>> Terminate means "close client and server connections immediately". 
>>>> The
>>>> problem is not with the terminate action but with peeking (which 
>>>> relies
>>>> on OpenSSL, especially during step2, especially in Squid v3).
>>>> 
>>>> 
>>>> HTH,
>>>> 
>>>> Alex.
>> 
>> 
>> FWIW I've had great success with the git version of libressl and using 
>> the
>> below:
>> 
>> ./configure --prefix=/opt/libressl
>> 
>> and for squid:
>> 
>> ./configure --prefix=/opt --with-openssl=/opt/libressl --enable-ssl
>> --enable-ssl-crtd
>> 
>> James

I'm currently using squid-3.5.22 and using the below git for libressl:

commit b7ba692f72f232602efb3e720ab0510406bae69c
Author: Brent Cook <bcook at openbsd.org>
Date:   Wed Sep 14 23:40:10 2016 -0500

What's the error you're getting when you try and compile?

James


From eliezer at ngtech.co.il  Fri Oct 21 19:07:45 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 21 Oct 2016 22:07:45 +0300
Subject: [squid-users] Caching http google deb files
In-Reply-To: <14791d65-c8ce-7bb1-47b2-55ebefa507da@cinbesa.com.br>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
 <CA+sSnVZ2ErFD+LeLVH3KOjJ_0PuqGyWfRHA23zY8yJQs3kP+Rw@mail.gmail.com>
 <89f9840b-7ec7-2f0b-a81c-5376c344878e@treenet.co.nz>
 <CA+sSnVYCy5E00jKK5cPZm3q+eBX8Fx=Mjs_iu4Xs0oebxcte9Q@mail.gmail.com>
 <1ba79370-ff21-0e52-a5dc-89919c1171b4@measurement-factory.com>
 <57F68690.1020109@tlinx.org>
 <2c043b07-b941-9e29-8813-4642070384f6@measurement-factory.com>
 <CA+sSnVai079zNS6X+Rni9qaRKOAt6PF+nrZQhBR462zL1zWZuA@mail.gmail.com>
 <14791d65-c8ce-7bb1-47b2-55ebefa507da@cinbesa.com.br>
Message-ID: <053a01d22bce$67f6f1a0$37e4d4e0$@ngtech.co.il>

Instead of modifying the code, would you consider to use an ICAP service
that will mangle this?
I am unsure about the risks about doing so but why patch the sources if you
can resolve it with the current mainstream capabilities and API?

Eliezer

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Heiler Bemerguy
Sent: Friday, October 21, 2016 18:21
To: squid-users at squid-cache.org
Subject: Re: [squid-users] Caching http google deb files


Hello,
I've limited the "vary" usage and gained some hits by making these
modifications (in blue) to the http.cc code:
    while (strListGetItem(&vary, ',', &item, &ilen, &pos)) {
        SBuf name(item, ilen);
        if (name == asterisk) {
        /*  vstr.clear();            
            break; */ 
            continue;
        }
        name.toLower();

       if (name.cmp("accept", 6) != 0 &&
          name.cmp("user-agent", 10) != 0)
               continue;

        if (!vstr.isEmpty())
            vstr.append(", ", 2);



-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751

Em 07/10/2016 06:26, Hardik Dangar escreveu:
Hey Alex, 

I totally get that Vary code is different, I have been trying to understand
squid code for last few days although my C, C++ skills are very limited I am
able to understand bits and pieces here and there. I have also read HTTP 1.1
specs for cache ( https://tools.ietf.org/html/rfc2616#section-13
<https://tools.ietf.org/html/rfc2616>  )

After doing fair bit of research I believe we need to two things, 

1) start a campaign to convince webmasters to update their server configs,
for that to happen I am doing my research on apache and Nginx servers on how
to implement ( HTTP 1.1 spec cache guidelines ) and will provide them copy
paste configs for all requests or for the file types like
deb,apk,rpm,exe(binary files),etc...

I am documenting that here,
https://hardikdangar.github.io/thecacheproject/

and once I finish everything I will post everything at the squid-dev list
here so all of you can look at it and if you guys approve it, I will
personally try to contact the big providers and send them above page with
solutions. and will ask community support and will publish it to twitter and
other social sites to get support.

2) I want to build a module which will first handle Vary: * requests and
convert it into Vary: Accept-Encoding or something similar but only for the
ACL's specified by cache administrator.

Next, there are use cases like GitHub which are very difficult to handle
but I feel there is a way we can handle those use cases so I will build ACL
for those.

For this, i am trying to understand squid code, After looking at dev docs,
I understand how the request is handled at clientBeginRequest. But I am very
confused at how squid handles the response.  I know client_side_reply.cc is
the file where the response is handled but I am not sure how
StoreEntry::checkCachable() method in store.cc is called before it as that
is the method i get in squid logs when the cache is denied.

Basically, I need to know how to debug line by line source for squid. Right
now my method of testing involves building squid and adding debug lines and
its very slow process as it takes time every time. Can you help me with this
? is there a way i could send a request directly to squid source file i.e
debug source code line by line ? If so what are the tools required and how
to set it up ?

Again, I am sorry if i am asking too much but my C experience is very
limited and i feel like i am asking very naive questions but these are very
difficult for me at this stage and i really appreciate all of the squid dev
teams who is been answering all of my questions. Thank you very much for
that.
--------

I just want a better cache support for squid and modern day use cases.

On Thu, Oct 6, 2016 at 11:25 PM, Alex Rousskov
<rousskov at measurement-factory.com <mailto:rousskov at measurement-factory.com>
> wrote:
On 10/06/2016 11:14 AM, Linda A. Walsh wrote:
> Alex Rousskov wrote:
>> We can, but ignoring Vary requires more/different work than adding
>> another refresh_pattern option. Vary is not a refresh mechanism so
>> different code areas need to be modified to ignore (but still forward!)
>> Vary.


>    I can't say for certain, but I'd give it a 75% shot of it being
> used as a forced-refresh pattern

The [ab]use cases do not matter here -- the _code_ handling Vary is very
different from the code handling refresh logic. That difference is
natural and unavoidable because the two protocol mechanisms are very
different, even if they both can be and are used to create the same effect.

Alex.

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users




_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 69189 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161021/a97400aa/attachment.bin>

From yvoinov at gmail.com  Fri Oct 21 19:28:21 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 22 Oct 2016 01:28:21 +0600
Subject: [squid-users] Caching http google deb files
In-Reply-To: <053a01d22bce$67f6f1a0$37e4d4e0$@ngtech.co.il>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
 <CA+sSnVZ2ErFD+LeLVH3KOjJ_0PuqGyWfRHA23zY8yJQs3kP+Rw@mail.gmail.com>
 <89f9840b-7ec7-2f0b-a81c-5376c344878e@treenet.co.nz>
 <CA+sSnVYCy5E00jKK5cPZm3q+eBX8Fx=Mjs_iu4Xs0oebxcte9Q@mail.gmail.com>
 <1ba79370-ff21-0e52-a5dc-89919c1171b4@measurement-factory.com>
 <57F68690.1020109@tlinx.org>
 <2c043b07-b941-9e29-8813-4642070384f6@measurement-factory.com>
 <CA+sSnVai079zNS6X+Rni9qaRKOAt6PF+nrZQhBR462zL1zWZuA@mail.gmail.com>
 <14791d65-c8ce-7bb1-47b2-55ebefa507da@cinbesa.com.br>
 <053a01d22bce$67f6f1a0$37e4d4e0$@ngtech.co.il>
Message-ID: <dad5c927-56ae-8887-5dfd-7fd1eabac2d0@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
This is inappropriate. Just all we are need that to make the option
"F*ck the RFC and f*ck anyone who opposes caching" in the SQUID.


22.10.2016 1:07, Eliezer Croitoru ?????:
> Instead of modifying the code, would you consider to use an ICAP service
> that will mangle this?
> I am unsure about the risks about doing so but why patch the sources
if you
> can resolve it with the current mainstream capabilities and API?
>
> Eliezer
>
> ----
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
>
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Heiler Bemerguy
> Sent: Friday, October 21, 2016 18:21
> To: squid-users at squid-cache.org
> Subject: Re: [squid-users] Caching http google deb files
>
>
> Hello,
> I've limited the "vary" usage and gained some hits by making these
> modifications (in blue) to the http.cc code:
>     while (strListGetItem(&vary, ',', &item, &ilen, &pos)) {
>         SBuf name(item, ilen);
>         if (name == asterisk) {
>         /*  vstr.clear();           
>             break; */
>             continue;
>         }
>         name.toLower();
>
>        if (name.cmp("accept", 6) != 0 &&
>           name.cmp("user-agent", 10) != 0)
>                continue;
>
>         if (!vstr.isEmpty())
>             vstr.append(", ", 2);
>
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYCmxVAAoJENNXIZxhPexGj5AH/1GVTNwdJisRXBWSsD190zn5
GoEaYfpYnGczsUh3h3acbzIbeiAZ048NsKxJx/1wfutGeWSt8sLzLNVX+ej02kN1
oLnFh0WSQ4uwzZSrvFIe+j1lxumvugpeoA27wZaVaz4uRP8kDiOvnTnFRjevXSH5
jVHiZkP3BUSElB7Y9p+2GGDyE5AXFIRvF1kJ3GTDqIb90fvpw2K/ES3pKcj7LL8j
xJRgoyFg7b5tn5xnAPFiiJwwT+4fqIAqDgOL0AZpeLuBPqqXP/UGs5d1KnLWESvT
luxn4jxJYCcIqfvYC39PVSoXySBHPq58paQtz9wWLM1faDdHX6I78JVROp/Werk=
=b1xs
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161022/c2830710/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161022/c2830710/attachment.key>

From yvoinov at gmail.com  Fri Oct 21 19:45:03 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 22 Oct 2016 01:45:03 +0600
Subject: [squid-users] Caching http google deb files
In-Reply-To: <dad5c927-56ae-8887-5dfd-7fd1eabac2d0@gmail.com>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
 <CA+sSnVZ2ErFD+LeLVH3KOjJ_0PuqGyWfRHA23zY8yJQs3kP+Rw@mail.gmail.com>
 <89f9840b-7ec7-2f0b-a81c-5376c344878e@treenet.co.nz>
 <CA+sSnVYCy5E00jKK5cPZm3q+eBX8Fx=Mjs_iu4Xs0oebxcte9Q@mail.gmail.com>
 <1ba79370-ff21-0e52-a5dc-89919c1171b4@measurement-factory.com>
 <57F68690.1020109@tlinx.org>
 <2c043b07-b941-9e29-8813-4642070384f6@measurement-factory.com>
 <CA+sSnVai079zNS6X+Rni9qaRKOAt6PF+nrZQhBR462zL1zWZuA@mail.gmail.com>
 <14791d65-c8ce-7bb1-47b2-55ebefa507da@cinbesa.com.br>
 <053a01d22bce$67f6f1a0$37e4d4e0$@ngtech.co.il>
 <dad5c927-56ae-8887-5dfd-7fd1eabac2d0@gmail.com>
Message-ID: <86acfe5f-53cd-5293-d8e5-00a46aad1de8@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
But I think it will be quite sufficient to bring back one of the options
HTTP violations, namely - "Ignore cache-control".

That's all. The rest we do ourselves.

22.10.2016 1:28, Yuri Voinov ?????:
>
> This is inappropriate. Just all we are need that to make the option
"F*ck the RFC and f*ck anyone who opposes caching" in the SQUID.
>
>
> 22.10.2016 1:07, Eliezer Croitoru ?????:
> > Instead of modifying the code,
>       would you consider to use an ICAP service
>
>       > that will mangle this?
>
>       > I am unsure about the risks about doing so but why patch the
>       sources if you
>
>       > can resolve it with the current mainstream capabilities and
>       API?
>
>
>
>       > Eliezer
>
>
>
>       > ----
>
>       > Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
>
>       > Linux System Administrator
>
>       > Mobile: +972-5-28704261
>
>       > Email: eliezer at ngtech.co.il
>
>
>
>
>
>       > From: squid-users
>       [mailto:squid-users-bounces at lists.squid-cache.org] On
>
>       > Behalf Of Heiler Bemerguy
>
>       > Sent: Friday, October 21, 2016 18:21
>
>       > To: squid-users at squid-cache.org
>
>       > Subject: Re: [squid-users] Caching http google deb files
>
>
>
>
>
>       > Hello,
>
>       > I've limited the "vary" usage and gained some hits by making
>       these
>
>       > modifications (in blue) to the http.cc code:
>
>       >     while (strListGetItem(&vary, ',', &item,
>       &ilen, &pos)) {
>
>       >         SBuf name(item, ilen);
>
>       >         if (name == asterisk) {
>
>       >         /*  vstr.clear();           
>
>       >             break; */
>
>       >             continue;
>
>       >         }
>
>       >         name.toLower();
>
>
>
>       >        if (name.cmp("accept", 6) != 0 &&
>
>       >           name.cmp("user-agent", 10) != 0)
>
>       >                continue;
>
>
>
>       >         if (!vstr.isEmpty())
>
>       >             vstr.append(", ", 2);
>
>
>
>
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYCnA/AAoJENNXIZxhPexGguEIAMKABEEHBNSO1+9ySQJJuEF1
spOET1zeDEEWvkVPAAfiFZK/13hG3xDoAA1hX8gtyChFTgDszBJvlvNAI/4UKKKY
uHZLm2HFxng1xTlyx0SD0CR00sXgk8mLQFl+JDeaZs8y7tQV+MNlZ+vJa9ox+xOO
ZbCudWthgC6Jl4scYI82fmfPEk3GdTaMyqfzF23iNglQ+CxHWnhoKspsau6b244j
yqSCjEsR7czZn7HEEeUkX0/7pYruz0+m8qleFgz1HW/Zcs5/i5M/szrow9BhUKqo
GF9IViquTfJJSthYC0XF5oC3NTOY0rsRaQDoCA0KNgcG7fn8ddt74bIcA4j7mLk=
=p36C
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161022/516158a4/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161022/516158a4/attachment.key>

From rui.godinho.lopes at gmail.com  Sat Oct 22 08:53:41 2016
From: rui.godinho.lopes at gmail.com (Rui Lopes)
Date: Sat, 22 Oct 2016 09:53:41 +0100
Subject: [squid-users] Caching Google Chrome
	googlechromestandaloneenterprise64.msi
Message-ID: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>

Hello,

I'm trying to receive a cached version
of googlechromestandaloneenterprise64.msi with:

refresh_pattern googlechromestandaloneenterprise64\.msi 4320 100% 4320
override-expire override-lastmod reload-into-ims ignore-reload
ignore-no-store ignore-private

and trying it with the following httpie command:

https_proxy=http://10.10.10.222:3128 http --verify=no -o chrome.msi '
https://dl.google.com/tag/s/appguid=%7B00000000-0000-0000-0000-000000000000%7D&iid=%7B00000000-0000-0000-0000-000000000000%7D&lang=en&browser=4&usagestats=0&appname=Google%20Chrome&needsadmin=true/dl/chrome/install/googlechromestandaloneenterprise64.msi
'

but squid never caches the response. it always shows:

1477125665.643   4040 10.10.10.1 TCP_MISS/200 50323942 GET
https://dl.google.com/tag/s/appguid=%7B00000000-0000-0000-0000-000000000000%7D&iid=%7B00000000-0000-0000-0000-000000000000%7D&lang=en&browser=4&usagestats=0&appname=Google%20Chrome&needsadmin=true/dl/chrome/install/googlechromestandaloneenterprise64.msi
- HIER_DIRECT/216.58.210.174 application/octet-stream

how can I make it cache?

-- RGL

PS I'm using squid 3.5.12-1ubuntu7.2 and my full squid.conf is:

acl localnet src 10.0.0.0/8
acl SSL_ports port 443
acl Safe_ports port 80
acl Safe_ports port 443
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localnet
http_access allow localhost
http_access deny allhttp_port \    3128 \
    ssl-bump \
    generate-host-certificates=on \
    dynamic_cert_mem_cache_size=16MB \
    key=/etc/squid/ssl_cert/ca.key \
    cert=/etc/squid/ssl_cert/ca.pemssl_bump bump allsslcrtd_program \
  /usr/lib/squid/ssl_crtd \
    -s /var/lib/ssl_db \
    -M 16MB \
    -b 4096 \
    sslcrtd_children 5# a ~15 GiB cache (only caches files that have a
length of 2 GiB or less).
maximum_object_size 2 GB
cache_dir ufs /var/spool/squid 15000 16 256cache_store_log
daemon:/var/log/squid/store.logshutdown_lifetime 2 secondscoredump_dir
/var/spool/squidrefresh_pattern
googlechromestandaloneenterprise64\.msi 4320 100% 4320 override-expire
override-lastmod reload-into-ims ignore-reload ignore-no-store
ignore-private
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161022/d80408bc/attachment.htm>

From yvoinov at gmail.com  Sat Oct 22 10:53:15 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 22 Oct 2016 16:53:15 +0600
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
Message-ID: <b9f4b8ce-88ef-531d-6906-9029a025ff50@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Try to use store-ID. Your URL seems dynamic. So, Squid never can cache it.

Don't forget - Google, like many other web companies, actively
counteracts caching. It is likely that you even Store ID will not help.


22.10.2016 14:53, Rui Lopes ?????:
> Hello,
>
> I'm trying to receive a cached version of
googlechromestandaloneenterprise64.msi with:
>
> refresh_pattern googlechromestandaloneenterprise64\.msi 4320 100% 4320
override-expire override-lastmod reload-into-ims ignore-reload
ignore-no-store ignore-private
>
> and trying it with the following httpie command:
>
> https_proxy=http://10.10.10.222:3128 http --verify=no -o chrome.msi
'https://dl.google.com/tag/s/appguid=%7B00000000-0000-0000-0000-000000000000%7D&iid=%7B00000000-0000-0000-0000-000000000000%7D&lang=en&browser=4&usagestats=0&appname=Google%20Chrome&needsadmin=true/dl/chrome/install/googlechromestandaloneenterprise64.msi'
>
> but squid never caches the response. it always shows:
>
> 1477125665.643   4040 10.10.10.1 TCP_MISS/200 50323942 GET
https://dl.google.com/tag/s/appguid=%7B00000000-0000-0000-0000-000000000000%7D&iid=%7B00000000-0000-0000-0000-000000000000%7D&lang=en&browser=4&usagestats=0&appname=Google%20Chrome&needsadmin=true/dl/chrome/install/googlechromestandaloneenterprise64.msi
- HIER_DIRECT/216.58.210.174 <http://216.58.210.174>
application/octet-stream
>
> how can I make it cache?
>
> -- RGL
>
> PS I'm using squid 3.5.12-1ubuntu7.2 and my full squid.conf is:
> acl localnet src 10.0.0.0/8 <http://10.0.0.0/8>
> acl SSL_ports port 443
> acl Safe_ports port 80
> acl Safe_ports port 443
> acl CONNECT method CONNECT
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access allow localnet
> http_access allow localhost
> http_access deny all
>
> http_port \
>     3128 \
>     ssl-bump \
>     generate-host-certificates=on \
>     dynamic_cert_mem_cache_size=16MB \
>     key=/etc/squid/ssl_cert/ca.key \
>     cert=/etc/squid/ssl_cert/ca.pem
>
> ssl_bump bump all
>
> sslcrtd_program \
>     /usr/lib/squid/ssl_crtd \
>     -s /var/lib/ssl_db \
>     -M 16MB \
>     -b 4096 \
>     sslcrtd_children 5
>
> # a ~15 GiB cache (only caches files that have a length of 2 GiB or less).
> maximum_object_size 2 GB
> cache_dir ufs /var/spool/squid 15000 16 256
>
> cache_store_log daemon:/var/log/squid/store.log
>
> shutdown_lifetime 2 seconds
>
> coredump_dir /var/spool/squid
>
> refresh_pattern googlechromestandaloneenterprise64\.msi 4320 100% 4320
override-expire override-lastmod reload-into-ims ignore-reload
ignore-no-store ignore-private
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYC0UaAAoJENNXIZxhPexGYM0H/RcmQBWc2A2b5FyRtlFBz3it
rKWailKYibbTj//SLjj4C0lh1SlFvB5v64liLNEUAMg0KdXJbfm8isnvpatR6/Lx
Hd44JIf87Xqy66IoQL9/LD/frrPf4XipDgBqHqKuijJVZqyXNSUBdlOZG23qF5th
U1rJfCcjBw0eWBd5Qp46XVTYPtLIg1iYuUBQDqWM3EDLwAiUoI6LMnS1zas0LJyk
hkKtMlVHLOAgSo/YHipvPuUzoWGUgmzGvInVo+dhyxN2c83jlm9HiJKWlQoUELo3
mGFb0UgfsBz/8+bfZR6J9sC7YVJL4aErbeT1xvlnmVDNXYowoQCY82OAzqz0Yb4=
=de5W
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161022/24d246ba/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161022/24d246ba/attachment.key>

From garryd at comnet.uz  Sat Oct 22 10:55:31 2016
From: garryd at comnet.uz (garryd at comnet.uz)
Date: Sat, 22 Oct 2016 15:55:31 +0500
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
Message-ID: <df9eb004318dae81e49c08c518acd39c@comnet.uz>

On 2016-10-22 13:53, Rui Lopes wrote:
> Hello,
> 
> I'm trying to receive a cached version of
> googlechromestandaloneenterprise64.msi with:
> 
> refresh_pattern googlechromestandaloneenterprise64\.msi 4320 100% 4320
> override-expire override-lastmod reload-into-ims ignore-reload
> ignore-no-store ignore-private
> 
> and trying it with the following httpie command:
> 
> https_proxy=http://10.10.10.222:3128 http --verify=no -o chrome.msi
> 'https://dl.google.com/tag/s/appguid=%7B00000000-0000-0000-0000-000000000000%7D&iid=%7B00000000-0000-0000-0000-000000000000%7D&lang=en&browser=4&usagestats=0&appname=Google%20Chrome&needsadmin=true/dl/chrome/install/googlechromestandaloneenterprise64.msi'
> 
> but squid never caches the response. it always shows:
> 
> 1477125665.643   4040 10.10.10.1 TCP_MISS/200 50323942 GET
> https://dl.google.com/tag/s/appguid=%7B00000000-0000-0000-0000-000000000000%7D&iid=%7B00000000-0000-0000-0000-000000000000%7D&lang=en&browser=4&usagestats=0&appname=Google%20Chrome&needsadmin=true/dl/chrome/install/googlechromestandaloneenterprise64.msi
> - HIER_DIRECT/216.58.210.174 [2] application/octet-stream
> 
> how can I make it cache?
> 
> -- RGL
> 
> PS I'm using squid 3.5.12-1ubuntu7.2 and my full squid.conf is:
> 
> acl localnet src 10.0.0.0/8 [1]
> acl SSL_ports port 443
> acl Safe_ports port 80
> acl Safe_ports port 443
> acl CONNECT method CONNECT
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> http_access allow localnet
> http_access allow localhost
> http_access deny all
> 
> http_port \
>     3128 \
>     ssl-bump \
>     generate-host-certificates=on \
>     dynamic_cert_mem_cache_size=16MB \
>     key=/etc/squid/ssl_cert/ca.key \
>     cert=/etc/squid/ssl_cert/ca.pem
> 
> ssl_bump bump all
> 
> sslcrtd_program \
>     /usr/lib/squid/ssl_crtd \
>     -s /var/lib/ssl_db \
>     -M 16MB \
>     -b 4096 \
>     sslcrtd_children 5
> 
> # a ~15 GiB cache (only caches files that have a length of 2 GiB or
> less).
> maximum_object_size 2 GB
> cache_dir ufs /var/spool/squid 15000 16 256
> 
> cache_store_log daemon:/var/log/squid/store.log
> 
> shutdown_lifetime 2 seconds
> 
> coredump_dir /var/spool/squid
> 
> refresh_pattern googlechromestandaloneenterprise64\.msi 4320 100% 4320
> override-expire override-lastmod reload-into-ims ignore-reload
> ignore-no-store ignore-private
> 
> 
> 
> Links:
> ------
> [1] http://10.0.0.0/8
> [2] http://216.58.210.174

Hi,

It have already been well explained by Amos this month:

http://lists.squid-cache.org/pipermail/squid-users/2016-October/012869.html


From yvoinov at gmail.com  Sat Oct 22 11:05:30 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 22 Oct 2016 17:05:30 +0600
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <df9eb004318dae81e49c08c518acd39c@comnet.uz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <df9eb004318dae81e49c08c518acd39c@comnet.uz>
Message-ID: <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


22.10.2016 16:55, garryd at comnet.uz ?????:
> On 2016-10-22 13:53, Rui Lopes wrote:
>> Hello,
>>
>> I'm trying to receive a cached version of
>> googlechromestandaloneenterprise64.msi with:
>>
>> refresh_pattern googlechromestandaloneenterprise64\.msi 4320 100% 4320
>> override-expire override-lastmod reload-into-ims ignore-reload
>> ignore-no-store ignore-private
>>
>> and trying it with the following httpie command:
>>
>> https_proxy=http://10.10.10.222:3128 http --verify=no -o chrome.msi
>>
'https://dl.google.com/tag/s/appguid=%7B00000000-0000-0000-0000-000000000000%7D&iid=%7B00000000-0000-0000-0000-000000000000%7D&lang=en&browser=4&usagestats=0&appname=Google%20Chrome&needsadmin=true/dl/chrome/install/googlechromestandaloneenterprise64.msi'
>>
>> but squid never caches the response. it always shows:
>>
>> 1477125665.643   4040 10.10.10.1 TCP_MISS/200 50323942 GET
>>
https://dl.google.com/tag/s/appguid=%7B00000000-0000-0000-0000-000000000000%7D&iid=%7B00000000-0000-0000-0000-000000000000%7D&lang=en&browser=4&usagestats=0&appname=Google%20Chrome&needsadmin=true/dl/chrome/install/googlechromestandaloneenterprise64.msi
>> - HIER_DIRECT/216.58.210.174 [2] application/octet-stream
>>
>> how can I make it cache?
>>
>> -- RGL
>>
>> PS I'm using squid 3.5.12-1ubuntu7.2 and my full squid.conf is:
>>
>> acl localnet src 10.0.0.0/8 [1]
>> acl SSL_ports port 443
>> acl Safe_ports port 80
>> acl Safe_ports port 443
>> acl CONNECT method CONNECT
>> http_access deny !Safe_ports
>> http_access deny CONNECT !SSL_ports
>> http_access allow localhost manager
>> http_access deny manager
>> http_access allow localnet
>> http_access allow localhost
>> http_access deny all
>>
>> http_port \
>>     3128 \
>>     ssl-bump \
>>     generate-host-certificates=on \
>>     dynamic_cert_mem_cache_size=16MB \
>>     key=/etc/squid/ssl_cert/ca.key \
>>     cert=/etc/squid/ssl_cert/ca.pem
>>
>> ssl_bump bump all
>>
>> sslcrtd_program \
>>     /usr/lib/squid/ssl_crtd \
>>     -s /var/lib/ssl_db \
>>     -M 16MB \
>>     -b 4096 \
>>     sslcrtd_children 5
>>
>> # a ~15 GiB cache (only caches files that have a length of 2 GiB or
>> less).
>> maximum_object_size 2 GB
>> cache_dir ufs /var/spool/squid 15000 16 256
>>
>> cache_store_log daemon:/var/log/squid/store.log
>>
>> shutdown_lifetime 2 seconds
>>
>> coredump_dir /var/spool/squid
>>
>> refresh_pattern googlechromestandaloneenterprise64\.msi 4320 100% 4320
>> override-expire override-lastmod reload-into-ims ignore-reload
>> ignore-no-store ignore-private
>>
>>
>>
>> Links:
>> ------
>> [1] http://10.0.0.0/8
>> [2] http://216.58.210.174
>
> Hi,
>
> It have already been well explained by Amos this month:
>
>
http://lists.squid-cache.org/pipermail/squid-users/2016-October/012869.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Good explanations do not always help to get a good solution. A person
needs no explanation and solution.

So far I've seen a lot of excellent reasons why Squid can not do
so-and-so in the normal configuration. However, this explanation does
not help in solving problems.

Nothing personal, just observation.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYC0f6AAoJENNXIZxhPexGpygH/A0mzDuTYq4g1LCZjHJA0Cuu
vZKf0+t/Z8dJtf6gKyhYDHH7IlByNJslPCOxWjx9b0ZnPuLAcMVp1rH9omzim93H
IEUnBj+4iSxOD5NEzmdwauYy4McyUedZsJLpEIc0MS9RF2X/18xIljjrYW+Rl4I5
9t88NiQjlwqTGKqgm5hIzjgMQDQbxmLhITmeXuC4sebGl0o8y+rl1NdJ/cy+0s5B
iCMb8PhqN8N/bmrHix6dIKhdktGVzyKyWiplPFymX21u0OLAwkbk2ZHYUzTCEX8G
eT7Ot+hRmk7GxdjEm5rlurUTkhynViYuc/BnMsmSNGqJk5p/zJx7jv/wPdTJ6r8=
=okUk
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161022/9e9642a2/attachment.key>

From garryd at comnet.uz  Sat Oct 22 12:43:55 2016
From: garryd at comnet.uz (garryd at comnet.uz)
Date: Sat, 22 Oct 2016 17:43:55 +0500
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <df9eb004318dae81e49c08c518acd39c@comnet.uz>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
Message-ID: <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>

On 2016-10-22 16:05, Yuri Voinov wrote:
> Good explanations do not always help to get a good solution. A person
> needs no explanation and solution.
> 
> So far I've seen a lot of excellent reasons why Squid can not do
> so-and-so in the normal configuration. However, this explanation does
> not help in solving problems.
> 
> Nothing personal, just observation.

IMO:

The only reason I believe explains why core developers of Squid tend to 
move HTTP violating settings from average users is to prevent possible 
abuse/misuse. Options like 'refresh_pattern ... ignore-vary' can severe 
affect browsing experience if used by people without enough knowledge of 
HTTP protocol(s). The abuse can easily compromise reputation of Squid 
software.

Fortunately, the license of Squid permits modification of the software. 
There are many ways to get desired and not yet implemented features of 
Squid:

* Group of enthusiasts can easily make a fork project, name it 
"Humboldt", for example and implement options like 'refresh_pattern ... 
ignore-vary', 'host_forgery_verification off'. For example, some time 
ago there was the project Lusca, which implemented address spoofing 
(like TProxy) for BSD systems (among other features). The feature was 
highly demanded and Squid project also implemented it later for BSD 
systems. Now Lusca is not so popular.

* Commercial organizations like ISP or any other enterprise can hire a 
developer to implement the options.

* Many system administrators with programming skills can successfully 
modify the Squid sources to reach the goal. The squid-users list and 
bugzilla remembers those success stories.


Nevertheless, I believe that core developers should publish an 
_official_ explanations regarding the tendency, as it often becomes a 
"center of gravity" of many topics.

Garri


From yvoinov at gmail.com  Sat Oct 22 12:52:32 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 22 Oct 2016 18:52:32 +0600
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <df9eb004318dae81e49c08c518acd39c@comnet.uz>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
Message-ID: <28ba22a7-ac40-0af7-e802-bd1ae02b1744@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


22.10.2016 18:43, garryd at comnet.uz ?????:
> On 2016-10-22 16:05, Yuri Voinov wrote:
>> Good explanations do not always help to get a good solution. A person
>> needs no explanation and solution.
>>
>> So far I've seen a lot of excellent reasons why Squid can not do
>> so-and-so in the normal configuration. However, this explanation does
>> not help in solving problems.
>>
>> Nothing personal, just observation.
>
> IMO:
>
> The only reason I believe explains why core developers of Squid tend
to move HTTP violating settings from average users is to prevent
possible abuse/misuse. Options like 'refresh_pattern ... ignore-vary'
can severe affect browsing experience if used by people without enough
knowledge of HTTP protocol(s). The abuse can easily compromise
reputation of Squid software.
>
> Fortunately, the license of Squid permits modification of the
software. There are many ways to get desired and not yet implemented
features of Squid:
>
> * Group of enthusiasts can easily make a fork project, name it
"Humboldt", for example and implement options like 'refresh_pattern ...
ignore-vary', 'host_forgery_verification off'. For example, some time
ago there was the project Lusca, which implemented address spoofing
(like TProxy) for BSD systems (among other features). The feature was
highly demanded and Squid project also implemented it later for BSD
systems. Now Lusca is not so popular.
>
> * Commercial organizations like ISP or any other enterprise can hire a
developer to implement the options.
>
> * Many system administrators with programming skills can successfully
modify the Squid sources to reach the goal. The squid-users list and
bugzilla remembers those success stories.
>
>
> Nevertheless, I believe that core developers should publish an
_official_ explanations regarding the tendency, as it often becomes a
"center of gravity" of many topics.
I do not think that someone is authorized to make official statements by
the developers. On behalf of any of its own community.
>
>
> Garri
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
But who would argue. You can always make a fork. Just got another indoor
bike. Received another 2049-Linux distribution. I do not think that this
is something to aspire to any open society.

And the trend is obvious. Large Internet companies pay a lot of money
for advertising, and they absolutely do not care about users and their
traffic. Arises only one rhetorical question. Key developers think about
the users or large companies with their income?

Actually, it's completely pointless debate. Developer position for a
long time, we all know. "You can modify the code and go to the devil."

I do not see the point in any further discussion, Harry. Your position
is quite clear.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYC2EQAAoJENNXIZxhPexGg9YH+gNpJVa5cDTbw96qZXlbRCmq
/Znw9tkSirx8ZKMeY/wHaKvlPxIXTO1f46180UqtNWf8VTBjXq0U1Y6C+uEg2yhj
/RjT+pxjmaV0CystefIUmHeyvB+iKltmkPVLWCkD4jGCoBGljmGSdUTlfQtMu4lW
eogyWZju/LDVNmJ516YreVX0TY47q4qz1zxh9yQ+dP7+6jKROqp/kLTPND8MXTbV
RXyM+pLWbFC3uK1KnGhMLdaq+RK8FW3KKo0gWqQf6/iNRry1Oin8VauhpmejTmbz
AeakNFFGbbQiYVuNNp1EadFRDE1O025BeQn72Un+SYADkZtDrAdSMsZ4VNFQzJM=
=CyoF
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161022/9ffe65a0/attachment.key>

From Antony.Stone at squid.open.source.it  Sat Oct 22 12:56:11 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sat, 22 Oct 2016 14:56:11 +0200
Subject: [squid-users] Caching Google Chrome
	googlechromestandaloneenterprise64.msi
In-Reply-To: <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
Message-ID: <201610221456.11879.Antony.Stone@squid.open.source.it>

Disclaimer: I am not a Squid developer.

On Saturday 22 October 2016 at 14:43:55, garryd at comnet.uz wrote:

> IMO:
> 
> The only reason I believe [explains] why core developers of Squid tend to
> move HTTP violating settings from average users is to prevent possible
> abuse/misuse.

I believe the reason is that one of Squid's goals is to be RFC compliant, 
therefore it does not contain features which violate HTTP.

> Nevertheless, I believe that core developers should publish an
> _official_ explanations regarding the tendency, as it often becomes a
> "center of gravity" of many topics.

Which "tendency"?

What are you asking for an official explanation of?


Antony.

-- 
"640 kilobytes (of RAM) should be enough for anybody."

 - Bill Gates

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Sat Oct 22 13:13:27 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 22 Oct 2016 19:13:27 +0600
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <201610221456.11879.Antony.Stone@squid.open.source.it>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
Message-ID: <d6b30490-6dad-f4d1-a4c2-1e228e726b91@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
I will explain why I am extremely outraged by this position. Every
single major players - both from the Web companies and from suppliers
caching solutions (BlueCoat, ThunderCache etc.) - to one degree or
another violate RFC. And developers of position - is to be paladins in
white robes, who strictly follow these _recommendations_ (not standard,
please note!) And to be holier than the Pope, even at the expense of its
users!

And, what is the strangest thing, while being the most support among the
users.

At the same time, for a moment, everybody forgets one simple thing.
Traffic - is money. A lot of money. Almost nowhere is there any truly
unlimited Internet, and we - the users - are paying money for it. And
because of the position of developers, we lose money. Anybody are told -
"Relax, you can always make a fork Or you can always make some crutches
as you like. This OpenSource, baby!". We can - and do. But this is - not
the solution. This is problem disregard.

Yes, we can make a fork. Yes, we can buy a commercial solution. But then
the question arises - why, in fact, if at all there is Squid? For
pathos? Or, as a source of commercial forks?

The trend is that the one who can with impunity violate RFC - he got a
lot of money. Remaining calm myself that this is the standard, it is
required to follow all. Go on! Most people believe that Squid is worth
nothing as a caching proxy! And - they right. Vanilla Squid makes not
above 10% byte hit. With increasing latency. Yes, I know that he is not
currently marketed as a caching proxy. Just in case, I'll take another
proxy, without the useless features that are not possible without the
need to break the RFC recommendations. Just - not needed.

22.10.2016 18:56, Antony Stone ?????:
> Disclaimer: I am not a Squid developer.
>
> On Saturday 22 October 2016 at 14:43:55, garryd at comnet.uz wrote:
>
>> IMO:
>>
>> The only reason I believe [explains] why core developers of Squid tend to
>> move HTTP violating settings from average users is to prevent possible
>> abuse/misuse.
>
> I believe the reason is that one of Squid's goals is to be RFC compliant,
> therefore it does not contain features which violate HTTP.
>
>> Nevertheless, I believe that core developers should publish an
>> _official_ explanations regarding the tendency, as it often becomes a
>> "center of gravity" of many topics.
>
> Which "tendency"?
>
> What are you asking for an official explanation of?
>
>
> Antony.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYC2X3AAoJENNXIZxhPexGgZYH/1/YbvICadk7nrFD/6znHC8y
JD74iAsB9XEKm9VSKKF+dEmKpBKs0iP4kJe75NZqJ8dBh6hM5H5FDAix7kvqkSj1
rJqxaqzZs2FfOO2+ylNYAVyjSVDWrsstpvX2fBMK8I4+WDXzAHzvYrFyo/KpP8uO
brdlrWrubMH0mfAJGIiVT/R3rNuRh7ZXkihakv2iLTg4ayZsQoDEgcbFfDW9ZN0M
mPWiPe2gofluXj2lYoAH/albY0NVypyvCSs0c9CBjvFwaMyj1pzbpHz0udsM1ix8
uZ7WTQPnuM4qh1lFNPHJ1bMUW3Fz9AiHXdrs2Ct0llppoj+pdGoAG4aQuefZhDw=
=pGxs
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161022/81922b68/attachment.key>

From garryd at comnet.uz  Sat Oct 22 13:32:09 2016
From: garryd at comnet.uz (garryd at comnet.uz)
Date: Sat, 22 Oct 2016 18:32:09 +0500
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <201610221456.11879.Antony.Stone@squid.open.source.it>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
Message-ID: <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>

On 2016-10-22 17:56, Antony Stone wrote:
> Disclaimer: I am not a Squid developer.
> 
> On Saturday 22 October 2016 at 14:43:55, garryd at comnet.uz wrote:
> 
>> IMO:
>> 
>> The only reason I believe [explains] why core developers of Squid tend 
>> to
>> move HTTP violating settings from average users is to prevent possible
>> abuse/misuse.
> 
> I believe the reason is that one of Squid's goals is to be RFC 
> compliant,
> therefore it does not contain features which violate HTTP.
> 
>> Nevertheless, I believe that core developers should publish an
>> _official_ explanations regarding the tendency, as it often becomes a
>> "center of gravity" of many topics.
> 
> Which "tendency"?
> 
> What are you asking for an official explanation of?
> 
> 
> Antony.

Since I started use Squid, it's configuration always RFC compliant by 
default, _but_ there were always knobs for users to make it HTTP 
violent. It was in hands of users to decide how to handle a web 
resource. Now it is not always possible, and the topic is an evidence. 
For example, in terms of this topic, users can't violate this RFC 
statement [1]:

    A Vary field value of "*" signals that anything about the request
    might play a role in selecting the response representation, possibly
    including elements outside the message syntax (e.g., the client's
    network address).  A recipient will not be able to determine whether
    this response is appropriate for a later request without forwarding
    the request to the origin server.  A proxy MUST NOT generate a Vary
    field with a "*" value.

[1] https://tools.ietf.org/html/rfc7231#section-7.1.4


From lean0x2f at gmail.com  Sat Oct 22 13:35:58 2016
From: lean0x2f at gmail.com (Leandro Barragan)
Date: Sat, 22 Oct 2016 10:35:58 -0300
Subject: [squid-users] Peeking on TLS traffic: unknown cipher returned
In-Reply-To: <9a1bdcd7ccbbdfe6d901dfd674003617@localhost>
References: <CAARTC8k+jHak1CR_B61Y-L5z+7Px6d9jM5X_vD_MJxa=+JqYVA@mail.gmail.com>
 <2d98d293-f2ff-8f87-1d6c-c425d803115f@measurement-factory.com>
 <CAARTC8kyKsnKQv+SXci0C02q_Nt7w0piYCKmxS_WaNFUb=NLqw@mail.gmail.com>
 <6b1a87c4f76aa544d5316e03f3769085@localhost>
 <CAARTC8m7oYOoxnzs63=n2dxuuRCy4zpMuocoA_kDjwQte7SN3Q@mail.gmail.com>
 <9a1bdcd7ccbbdfe6d901dfd674003617@localhost>
Message-ID: <CAARTC8=amUOvEcOOAUB7pDJ-9pkVLfDwS3dWVtpWhVuLjLpU0Q@mail.gmail.com>

Thanks a lot James, compiling Squid 3.5.22 using that specific commit
of LibreSSL worked as a charm! I no longer have that "unknown cipher
returned" errors. I do have some errors with a tiny amount of sites,
but I suppose its because of server-side misconfigurations that
LibreSSL simply don't like.


On 21 October 2016 at 13:01, James Lay <jlay at slave-tothe-box.net> wrote:
> On 2016-10-21 09:58, Leandro Barragan wrote:
>>
>> James, thanks for your advice! I've read your email on this list about
>> LibreSSL. I tried to compile Squid with LibreSSL in the first place
>> because of what you wrote about ChaCha20. But unfortunately, I
>> couldn't, compilation stopped because of some obscure error.
>>
>> Do you remember what version of squid and libressl you used? BTW I
>> tried with OpenSSL 1.0.2g applying the CloudFare ChaCha20 patch, but
>> it doesn't work either, same error (unknown cipher)
>>
>> Thanks!
>>
>> On 21 October 2016 at 10:55, James Lay <jlay at slave-tothe-box.net> wrote:
>>>
>>> On 2016-10-20 20:15, Leandro Barragan wrote:
>>>>
>>>>
>>>> Thanks for your time Alex! I modified my original config based on Amos
>>>> recommendations, so I think now I have a more consistent peek & splice
>>>> config:
>>>>
>>>>  acl TF ssl::server_name_regex -i facebook fbcdn twitter reddit
>>>>  ssl_bump peek all
>>>>  ssl_bump terminate TF
>>>>  ssl_bump splice all
>>>>
>>>> As you mentioned, terminate closes the connection, it doesn't serve an
>>>> error page (when it works, i.e. with reddit and twitter).
>>>>
>>>> I've compiled Squid 3.5.22 using OpenSSL 1.0.2j and I'm having the
>>>> same exact issue, even with this new config. Based on what you
>>>> explained, I think it's a OpenSSL problem and Squid can't do anything
>>>> about it. I have two reasons to believe that:
>>>>
>>>> 1) The "unknown cipher returned" error get's triggered on terminated
>>>> and non terminated (e.g. microsoft.com) sites, which makes me think it
>>>> has nothing to do with Squid ACLs.
>>>> 2) All problematic sites use a new cipher called "ChaCha20" (E.g.
>>>> TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256....according to Qualys
>>>> online analyzer and TestSSLServer tool)
>>>>
>>>> A lot of sites are using this new cipher. I'm back at the beginning, I
>>>> will continue trying to compile Squid with patched versions of OpenSSL
>>>> or LibreSSL.
>>>>
>>>> Thanks!
>>>>
>>>> On 20 October 2016 at 01:01, Alex Rousskov
>>>> <rousskov at measurement-factory.com> wrote:
>>>>>
>>>>>
>>>>> On 10/19/2016 12:44 AM, Leandro Barragan wrote:
>>>>>
>>>>>>> error:140920F8:SSL routines:SSL3_GET_SERVER_HELLO:unknown cipher
>>>>>>> returned (1/-1/0)
>>>>>
>>>>>
>>>>>
>>>>>> I fail to see why is this happening. I only need to peek on the
>>>>>> connection and make a decision based on SNI,
>>>>>
>>>>>
>>>>>
>>>>> Please note that "peek and make a decision based on SNI" is not what
>>>>> your configuration tells Squid to do. Your configuration tells Squid to
>>>>> peek during step2, which means making a decision based on server
>>>>> certificates (and SNI).
>>>>>
>>>>>
>>>>>> I'm not Bumping, so I
>>>>>> don't understand why ciphers matter in my situation.
>>>>>
>>>>>
>>>>>
>>>>> The ciphers matter because Squid v3 uses OpenSSL parsers during step1,
>>>>> step2, and step3. FWIW, Squid v4 uses OpenSSL parsers during step2 (a
>>>>> little) and step3. It is possible to completely remove OpenSSL from
>>>>> step2 but there is currently no project to do that AFAIK.
>>>>>
>>>>>
>>>>>>> ssl_bump peek all step1
>>>>>>> ssl_bump peek all step2
>>>>>>> ssl_bump terminate face step3
>>>>>>> ssl_bump terminate twitter step3
>>>>>>> ssl_bump splice all step3
>>>>>
>>>>>
>>>>>
>>>>> BTW, "step1", "step2", and "step3" ACLs do nothing useful in the above
>>>>> config. You can safely remove them to arrive at the equivalent ssl_bump
>>>>> configuration.
>>>>>
>>>>>
>>>>> On 10/19/2016 07:42 AM, Amos Jeffries wrote:
>>>>>>
>>>>>>
>>>>>> Terminate means impersonating the server and responding to the client
>>>>>> with an HTTPS error page.
>>>>>
>>>>>
>>>>>
>>>>> Terminate means "close client and server connections immediately". The
>>>>> problem is not with the terminate action but with peeking (which relies
>>>>> on OpenSSL, especially during step2, especially in Squid v3).
>>>>>
>>>>>
>>>>> HTH,
>>>>>
>>>>> Alex.
>>>
>>>
>>>
>>> FWIW I've had great success with the git version of libressl and using
>>> the
>>> below:
>>>
>>> ./configure --prefix=/opt/libressl
>>>
>>> and for squid:
>>>
>>> ./configure --prefix=/opt --with-openssl=/opt/libressl --enable-ssl
>>> --enable-ssl-crtd
>>>
>>> James
>
>
> I'm currently using squid-3.5.22 and using the below git for libressl:
>
> commit b7ba692f72f232602efb3e720ab0510406bae69c
> Author: Brent Cook <bcook at openbsd.org>
> Date:   Wed Sep 14 23:40:10 2016 -0500
>
> What's the error you're getting when you try and compile?
>
>
> James
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From ahmed.zaeem at netstream.ps  Sat Oct 22 13:42:23 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Sat, 22 Oct 2016 15:42:23 +0200
Subject: [squid-users] possible to intercept https traffic in TCP_TUNNEL
	CONNECT method ?
Message-ID: <AE0816ED-3231-4F5A-A4ED-4B41DE6F1F37@netstream.ps>

Hi guys 
say that i have squid proxy sever 
and i was running  capturing traffic on that server .

say that all users were using ip:port ?> ((tcp_connect  tunnel))) mode of squid 

the question is being asked here ? will i be able to see https traffic like Facebook  as normal traffic ?
or encrypted ?


the question in other way  ?. is it possible to hack https traffic and see it as not encrypted ?


cheers



From yvoinov at gmail.com  Sat Oct 22 13:45:45 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 22 Oct 2016 19:45:45 +0600
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
Message-ID: <be2fa378-d949-8582-bb30-eac13020352f@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


22.10.2016 19:32, garryd at comnet.uz ?????:
> On 2016-10-22 17:56, Antony Stone wrote:
>> Disclaimer: I am not a Squid developer.
>>
>> On Saturday 22 October 2016 at 14:43:55, garryd at comnet.uz wrote:
>>
>>> IMO:
>>>
>>> The only reason I believe [explains] why core developers of Squid
tend to
>>> move HTTP violating settings from average users is to prevent possible
>>> abuse/misuse.
>>
>> I believe the reason is that one of Squid's goals is to be RFC compliant,
>> therefore it does not contain features which violate HTTP.
>>
>>> Nevertheless, I believe that core developers should publish an
>>> _official_ explanations regarding the tendency, as it often becomes a
>>> "center of gravity" of many topics.
>>
>> Which "tendency"?
>>
>> What are you asking for an official explanation of?
>>
>>
>> Antony.
>
> Since I started use Squid, it's configuration always RFC compliant by
default, _but_ there were always knobs for users to make it HTTP
violent. It was in hands of users to decide how to handle a web
resource. Now it is not always possible, and the topic is an evidence.
For example, in terms of this topic, users can't violate this RFC
statement [1]:
>
>    A Vary field value of "*" signals that anything about the request
>    might play a role in selecting the response representation, possibly
>    including elements outside the message syntax (e.g., the client's
>    network address).  A recipient will not be able to determine whether
>    this response is appropriate for a later request without forwarding
>    the request to the origin server.  A proxy MUST NOT generate a Vary
>    field with a "*" value.
>
> [1] https://tools.ietf.org/html/rfc7231#section-7.1.4
Well, what of it? What developers RFC got good money from Google for
ignoring caching level standards. Because that Google is profitable.
"Hey - they say - these dumb bastards all unlimited internet! Let it pay!"

And Google is not the only example in this case. I have seen, for
example, http://www.example.com/big_fucking_favicon.ico?null=0 design.
Where the size of the icons was hundreds of kilobytes! How about this?
Do not tell me that this is required for the functioning of the site - a
code may be in the picture?

What's the bottom line? Let's continue to sit on horseback, dressed in
white, and pray to the RFC!

> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYC22IAAoJENNXIZxhPexGELAH/02opOgF+Jh4fff/6T15ECMB
kqobxY+RYdLgkzGV23Fx88dLD4AHDQIapw7tlbpgzGpjc8N4z78AY/TSBRT/l3AP
l7wfQ+Egq9DRC2Z+XXN5oQT0naIgHmGbJl73btpG9t59u84N9jqMrA4i3fnVy0aO
fY1dq5+aG6jo4aGB17QzL9JGJxFsBkVbAvI6ZVJ445RMmoeh4+MHOUoewv7h/xY6
GSRN9kwdAfhqkGtiRAH4y8mpexRAztpTB6EOpGXupJzRuTuAujB2LGKlbnHYvXL4
a+PzlcvG8n2ZHy4YtjxRg0mymbM59F7SZvMTTRaQ7knD/2/cnXTx5U22roT57Io=
=kpXt
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161022/5a19aed5/attachment.key>

From jlay at slave-tothe-box.net  Sat Oct 22 13:52:57 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Sat, 22 Oct 2016 07:52:57 -0600
Subject: [squid-users] Peeking on TLS traffic: unknown cipher returned
In-Reply-To: <CAARTC8=amUOvEcOOAUB7pDJ-9pkVLfDwS3dWVtpWhVuLjLpU0Q@mail.gmail.com>
References: <CAARTC8k+jHak1CR_B61Y-L5z+7Px6d9jM5X_vD_MJxa=+JqYVA@mail.gmail.com>
 <2d98d293-f2ff-8f87-1d6c-c425d803115f@measurement-factory.com>
 <CAARTC8kyKsnKQv+SXci0C02q_Nt7w0piYCKmxS_WaNFUb=NLqw@mail.gmail.com>
 <6b1a87c4f76aa544d5316e03f3769085@localhost>
 <CAARTC8m7oYOoxnzs63=n2dxuuRCy4zpMuocoA_kDjwQte7SN3Q@mail.gmail.com>
 <9a1bdcd7ccbbdfe6d901dfd674003617@localhost>
 <CAARTC8=amUOvEcOOAUB7pDJ-9pkVLfDwS3dWVtpWhVuLjLpU0Q@mail.gmail.com>
Message-ID: <1477144377.3720.0.camel@slave-tothe-box.net>

Excellent...glad it worked.
James
On Sat, 2016-10-22 at 10:35 -0300, Leandro Barragan wrote:
> Thanks a lot James, compiling Squid 3.5.22 using that specific commit
> of LibreSSL worked as a charm! I no longer have that "unknown cipher
> returned" errors. I do have some errors with a tiny amount of sites,
> but I suppose its because of server-side misconfigurations that
> LibreSSL simply don't like.
> 
> 
> On 21 October 2016 at 13:01, James Lay <jlay at slave-tothe-box.net>
> wrote:
> > 
> > On 2016-10-21 09:58, Leandro Barragan wrote:
> > > 
> > > 
> > > James, thanks for your advice! I've read your email on this list
> > > about
> > > LibreSSL. I tried to compile Squid with LibreSSL in the first
> > > place
> > > because of what you wrote about ChaCha20. But unfortunately, I
> > > couldn't, compilation stopped because of some obscure error.
> > > 
> > > Do you remember what version of squid and libressl you used? BTW
> > > I
> > > tried with OpenSSL 1.0.2g applying the CloudFare ChaCha20 patch,
> > > but
> > > it doesn't work either, same error (unknown cipher)
> > > 
> > > Thanks!
> > > 
> > > On 21 October 2016 at 10:55, James Lay <jlay at slave-tothe-box.net>
> > > wrote:
> > > > 
> > > > 
> > > > On 2016-10-20 20:15, Leandro Barragan wrote:
> > > > > 
> > > > > 
> > > > > 
> > > > > Thanks for your time Alex! I modified my original config
> > > > > based on Amos
> > > > > recommendations, so I think now I have a more consistent peek
> > > > > & splice
> > > > > config:
> > > > > 
> > > > > ?acl TF ssl::server_name_regex -i facebook fbcdn twitter
> > > > > reddit
> > > > > ?ssl_bump peek all
> > > > > ?ssl_bump terminate TF
> > > > > ?ssl_bump splice all
> > > > > 
> > > > > As you mentioned, terminate closes the connection, it doesn't
> > > > > serve an
> > > > > error page (when it works, i.e. with reddit and twitter).
> > > > > 
> > > > > I've compiled Squid 3.5.22 using OpenSSL 1.0.2j and I'm
> > > > > having the
> > > > > same exact issue, even with this new config. Based on what
> > > > > you
> > > > > explained, I think it's a OpenSSL problem and Squid can't do
> > > > > anything
> > > > > about it. I have two reasons to believe that:
> > > > > 
> > > > > 1) The "unknown cipher returned" error get's triggered on
> > > > > terminated
> > > > > and non terminated (e.g. microsoft.com) sites, which makes me
> > > > > think it
> > > > > has nothing to do with Squid ACLs.
> > > > > 2) All problematic sites use a new cipher called "ChaCha20"
> > > > > (E.g.
> > > > > TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256....according to
> > > > > Qualys
> > > > > online analyzer and TestSSLServer tool)
> > > > > 
> > > > > A lot of sites are using this new cipher. I'm back at the
> > > > > beginning, I
> > > > > will continue trying to compile Squid with patched versions
> > > > > of OpenSSL
> > > > > or LibreSSL.
> > > > > 
> > > > > Thanks!
> > > > > 
> > > > > On 20 October 2016 at 01:01, Alex Rousskov
> > > > > <rousskov at measurement-factory.com> wrote:
> > > > > > 
> > > > > > 
> > > > > > 
> > > > > > On 10/19/2016 12:44 AM, Leandro Barragan wrote:
> > > > > > 
> > > > > > > 
> > > > > > > > 
> > > > > > > > error:140920F8:SSL
> > > > > > > > routines:SSL3_GET_SERVER_HELLO:unknown cipher
> > > > > > > > returned (1/-1/0)
> > > > > > 
> > > > > > 
> > > > > > > 
> > > > > > > I fail to see why is this happening. I only need to peek
> > > > > > > on the
> > > > > > > connection and make a decision based on SNI,
> > > > > > 
> > > > > > 
> > > > > > Please note that "peek and make a decision based on SNI" is
> > > > > > not what
> > > > > > your configuration tells Squid to do. Your configuration
> > > > > > tells Squid to
> > > > > > peek during step2, which means making a decision based on
> > > > > > server
> > > > > > certificates (and SNI).
> > > > > > 
> > > > > > 
> > > > > > > 
> > > > > > > I'm not Bumping, so I
> > > > > > > don't understand why ciphers matter in my situation.
> > > > > > 
> > > > > > 
> > > > > > The ciphers matter because Squid v3 uses OpenSSL parsers
> > > > > > during step1,
> > > > > > step2, and step3. FWIW, Squid v4 uses OpenSSL parsers
> > > > > > during step2 (a
> > > > > > little) and step3. It is possible to completely remove
> > > > > > OpenSSL from
> > > > > > step2 but there is currently no project to do that AFAIK.
> > > > > > 
> > > > > > 
> > > > > > > 
> > > > > > > > 
> > > > > > > > ssl_bump peek all step1
> > > > > > > > ssl_bump peek all step2
> > > > > > > > ssl_bump terminate face step3
> > > > > > > > ssl_bump terminate twitter step3
> > > > > > > > ssl_bump splice all step3
> > > > > > 
> > > > > > 
> > > > > > BTW, "step1", "step2", and "step3" ACLs do nothing useful
> > > > > > in the above
> > > > > > config. You can safely remove them to arrive at the
> > > > > > equivalent ssl_bump
> > > > > > configuration.
> > > > > > 
> > > > > > 
> > > > > > On 10/19/2016 07:42 AM, Amos Jeffries wrote:
> > > > > > > 
> > > > > > > 
> > > > > > > 
> > > > > > > Terminate means impersonating the server and responding
> > > > > > > to the client
> > > > > > > with an HTTPS error page.
> > > > > > 
> > > > > > 
> > > > > > Terminate means "close client and server connections
> > > > > > immediately". The
> > > > > > problem is not with the terminate action but with peeking
> > > > > > (which relies
> > > > > > on OpenSSL, especially during step2, especially in Squid
> > > > > > v3).
> > > > > > 
> > > > > > 
> > > > > > HTH,
> > > > > > 
> > > > > > Alex.
> > > > 
> > > > 
> > > > FWIW I've had great success with the git version of libressl
> > > > and using
> > > > the
> > > > below:
> > > > 
> > > > ./configure --prefix=/opt/libressl
> > > > 
> > > > and for squid:
> > > > 
> > > > ./configure --prefix=/opt --with-openssl=/opt/libressl --
> > > > enable-ssl
> > > > --enable-ssl-crtd
> > > > 
> > > > James
> > 
> > I'm currently using squid-3.5.22 and using the below git for
> > libressl:
> > 
> > commit b7ba692f72f232602efb3e720ab0510406bae69c
> > Author: Brent Cook <bcook at openbsd.org>
> > Date:???Wed Sep 14 23:40:10 2016 -0500
> > 
> > What's the error you're getting when you try and compile?
> > 
> > 
> > James
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161022/184e3e27/attachment.htm>

From Antony.Stone at squid.open.source.it  Sat Oct 22 13:54:27 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sat, 22 Oct 2016 15:54:27 +0200
Subject: [squid-users] possible to intercept https traffic in TCP_TUNNEL
	CONNECT method ?
In-Reply-To: <AE0816ED-3231-4F5A-A4ED-4B41DE6F1F37@netstream.ps>
References: <AE0816ED-3231-4F5A-A4ED-4B41DE6F1F37@netstream.ps>
Message-ID: <201610221554.27436.Antony.Stone@squid.open.source.it>

On Saturday 22 October 2016 at 15:42:23, --Ahmad-- wrote:

> Hi guys
> say that i have squid proxy sever
> and i was running  capturing traffic on that server .

You mean using ICAP or ECAP service?

> say that all users were using ip:port ?> ((tcp_connect  tunnel))) mode of
> squid

I'm not sure what you mean here - are you saying the clients are configured to 
use the proxy, or that the proxy is operating in intercept mode, and the 
clients don't know?

> the question is being asked here ? will i be able to see https traffic like
> Facebook  as normal traffic ? or encrypted ?

You can always see the encrypted traffic - you don't need Squid for that - just 
run tcpdump, wireshark or similar on a router between your clients and the 
Internet.  Encrypted traffic isn't going to tell you much, though.

> the question in other way  ?. is it possible to hack https traffic and see
> it as not encrypted ?

Yes - you perform a Man-in-the-Middle attack, which requires configuring the 
clients to accept fake certificates from Squid by trusting its built-in 
Certificate Authority.  In other words, you cannot do it without clients 
knowing that the certificate presented by Squid does not belong to the site 
they're visiting.

Also, all technical possibilities aside, it may well be illegal for you to do 
this, depending on where you are and who your users are.

See http://wiki.squid-cache.org/Features/SslPeekAndSplice and 
http://wiki.squid-cache.org/SquidFaq/ContentAdaptation for more details.


Antony.

-- 
"Life is just a lot better if you feel you're having 10 [small] wins a day 
rather than a [big] win every 10 years or so."

 - Chris Hadfield, former skiing (and ski racing) instructor

                                                   Please reply to the list;
                                                         please *don't* CC me.


From heiler.bemerguy at cinbesa.com.br  Sat Oct 22 18:18:22 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Sat, 22 Oct 2016 15:18:22 -0300
Subject: [squid-users] Caching http google deb files
In-Reply-To: <053a01d22bce$67f6f1a0$37e4d4e0$@ngtech.co.il>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
 <CA+sSnVZ2ErFD+LeLVH3KOjJ_0PuqGyWfRHA23zY8yJQs3kP+Rw@mail.gmail.com>
 <89f9840b-7ec7-2f0b-a81c-5376c344878e@treenet.co.nz>
 <CA+sSnVYCy5E00jKK5cPZm3q+eBX8Fx=Mjs_iu4Xs0oebxcte9Q@mail.gmail.com>
 <1ba79370-ff21-0e52-a5dc-89919c1171b4@measurement-factory.com>
 <57F68690.1020109@tlinx.org>
 <2c043b07-b941-9e29-8813-4642070384f6@measurement-factory.com>
 <CA+sSnVai079zNS6X+Rni9qaRKOAt6PF+nrZQhBR462zL1zWZuA@mail.gmail.com>
 <14791d65-c8ce-7bb1-47b2-55ebefa507da@cinbesa.com.br>
 <053a01d22bce$67f6f1a0$37e4d4e0$@ngtech.co.il>
Message-ID: <fa1fecc7-6e0b-0af4-7e86-44f1ccdf9697@cinbesa.com.br>


Hi Eliezer

I've never used ICAP, and I think hacking the code is way faster than 
creating/using a separate service for that. And I'm not sure, but I 
don't think I can manage to get this done with current squid's options.

This patch will make squid NOT ignore the objects with "*Vary: **" 
replies. It will consider them a valid and cacheable object.
And it will only consider as a valid Vary option those who *begins 
*with"accept" or the "user-agent" one.


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751

Em 21/10/2016 16:07, Eliezer Croitoru escreveu:
> Instead of modifying the code, would you consider to use an ICAP service
> that will mangle this?
> I am unsure about the risks about doing so but why patch the sources if you
> can resolve it with the current mainstream capabilities and API?
>
> Eliezer
>
> ----
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>   
>
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Heiler Bemerguy
> Sent: Friday, October 21, 2016 18:21
> To: squid-users at squid-cache.org
> Subject: Re: [squid-users] Caching http google deb files
>
>
> Hello,
> I've limited the "vary" usage and gained some hits by making these
> modifications (in blue) to the http.cc code:
>      while (strListGetItem(&vary, ',', &item, &ilen, &pos)) {
>          SBuf name(item, ilen);
>          if (name == asterisk) {
>          /*  vstr.clear();
>              break; */
>              continue;
>          }
>          name.toLower();
>
>         if (name.cmp("accept", 6) != 0 &&
>            name.cmp("user-agent", 10) != 0)
>                 continue;
>
>          if (!vstr.isEmpty())
>              vstr.append(", ", 2);
>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161022/eaad47ed/attachment.htm>

From eliezer at ngtech.co.il  Sat Oct 22 21:55:01 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 23 Oct 2016 00:55:01 +0300
Subject: [squid-users] Caching http google deb files
In-Reply-To: <fa1fecc7-6e0b-0af4-7e86-44f1ccdf9697@cinbesa.com.br>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
 <CA+sSnVZ2ErFD+LeLVH3KOjJ_0PuqGyWfRHA23zY8yJQs3kP+Rw@mail.gmail.com>
 <89f9840b-7ec7-2f0b-a81c-5376c344878e@treenet.co.nz>
 <CA+sSnVYCy5E00jKK5cPZm3q+eBX8Fx=Mjs_iu4Xs0oebxcte9Q@mail.gmail.com>
 <1ba79370-ff21-0e52-a5dc-89919c1171b4@measurement-factory.com>
 <57F68690.1020109@tlinx.org>
 <2c043b07-b941-9e29-8813-4642070384f6@measurement-factory.com>
 <CA+sSnVai079zNS6X+Rni9qaRKOAt6PF+nrZQhBR462zL1zWZuA@mail.gmail.com>
 <14791d65-c8ce-7bb1-47b2-55ebefa507da@cinbesa.com.br>
 <053a01d22bce$67f6f1a0$37e4d4e0$@ngtech.co.il>
 <fa1fecc7-6e0b-0af4-7e86-44f1ccdf9697@cinbesa.com.br>
Message-ID: <ddf7001d22cae$f0216de0$d06449a0$@ngtech.co.il>

Well you are right about that but for me it?s simpler to Write and ICAP
service to do that then hack squid code.

Eliezer

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
 

From: Heiler Bemerguy [mailto:heiler.bemerguy at cinbesa.com.br] 
Sent: Saturday, October 22, 2016 21:18
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at squid-cache.org
Subject: Re: [squid-users] Caching http google deb files


Hi Eliezer
I've never used ICAP, and I think hacking the code is way faster than
creating/using a separate service for that. And I'm not sure, but I don't
think I can manage to get this done with current squid's options.
This patch will make squid NOT ignore the objects with "Vary: *" replies.
It will consider them a valid and cacheable object. 
And it will only consider as a valid Vary option those who begins
with"accept" or the "user-agent" one.

-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751
Em 21/10/2016 16:07, Eliezer Croitoru escreveu:
Instead of modifying the code, would you consider to use an ICAP service
that will mangle this?
I am unsure about the risks about doing so but why patch the sources if you
can resolve it with the current mainstream capabilities and API?

Eliezer

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
<http://ngtech.co.il/lmgtfy/>  
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il> 
 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Heiler Bemerguy
Sent: Friday, October 21, 2016 18:21
To: squid-users at squid-cache.org <mailto:squid-users at squid-cache.org> 
Subject: Re: [squid-users] Caching http google deb files


Hello,
I've limited the "vary" usage and gained some hits by making these
modifications (in blue) to the http.cc code:
    while (strListGetItem(&vary, ',', &item, &ilen, &pos)) {
        SBuf name(item, ilen);
        if (name == asterisk) {
        /*  vstr.clear();            
            break; */ 
            continue;
        }
        name.toLower();

       if (name.cmp("accept", 6) != 0 &&
          name.cmp("user-agent", 10) != 0)
               continue;

        if (!vstr.isEmpty())
            vstr.append(", ", 2);




-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 65809 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/8607aab5/attachment.bin>

From krishna26kulkarni at gmail.com  Sun Oct 23 03:36:22 2016
From: krishna26kulkarni at gmail.com (Krishna Kulkarni)
Date: Sun, 23 Oct 2016 09:06:22 +0530
Subject: [squid-users] Slowness in Squid
Message-ID: <CAN-hqth-kdQDYXTR=jDnbVoiNmEMpi71+Sx7waO=61s0keucDQ@mail.gmail.com>

Dear Team
I am new to squid.. I have installed squid 3.5 on CentOS 6.7. As a
configuration part, I have kept most of the things default. Please advice
on how to allocate cache memory of 20 GB to squid. I got to know that, more
cache memory would increase performance of squid..

Thanks,
Krishna
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/9ddd4442/attachment.htm>

From Antony.Stone at squid.open.source.it  Sun Oct 23 08:16:28 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sun, 23 Oct 2016 10:16:28 +0200
Subject: [squid-users] Slowness in Squid
In-Reply-To: <CAN-hqth-kdQDYXTR=jDnbVoiNmEMpi71+Sx7waO=61s0keucDQ@mail.gmail.com>
References: <CAN-hqth-kdQDYXTR=jDnbVoiNmEMpi71+Sx7waO=61s0keucDQ@mail.gmail.com>
Message-ID: <201610231016.28867.Antony.Stone@squid.open.source.it>

On Sunday 23 October 2016 at 05:36:22, Krishna Kulkarni wrote:

> I am new to squid.. I have installed squid 3.5 on CentOS 6.7. As a
> configuration part, I have kept most of the things default. Please advice
> on how to allocate cache memory of 20 GB to squid.

Do you mean cache memory, or disk cache?


If you mean memory (RAM) and you have enough of this in your system (eg: 32 
Gbytes or more), then find the section in squid.conf which starts with:

# MEMORY CACHE OPTIONS

And read about the tag "cache_mem".

To set this value (normally 256 Mbytes) to 20 Gbytes, set:

cache_mem 20 GB


If, on the other hand, you do not mean memory, but you mean disk cache, then 
find the section in squid.conf with starts with:

#  TAG: cache_dir

and read that section.

Pay particular attention to the line which says:

#       cache_dir ufs Directory-Name Mbytes L1 L2 [options]

And then later there is an example:

# cache_dir ufs /var/spool/squid3 100 16 256

Uncomment that line and change the 100 (Megabytes) in that line to 20000 (for 
20 Gigabytes) and perhaps also adjust the 16 to something like 64 or even 256 
- for a large cache you don't want a few directories with lots of entries 
each, so it's worthwhile creating lots of directories to keep the number of 
files in each down.

> I got to know that, more cache memory would increase performance of squid..

What do you mean by "performance"?


Antony.

-- 
Just when you think you're done, a cat floats by with buttered toast strapped 
to its back.

 - Steve Krug, "Don't make me think"

                                                   Please reply to the list;
                                                         please *don't* CC me.


From augustus_meyer at gmx.net  Sun Oct 23 10:39:31 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Sun, 23 Oct 2016 03:39:31 -0700 (PDT)
Subject: [squid-users] external_acl_type problem
Message-ID: <1477219171447-4680203.post@n4.nabble.com>

1)
According to
http://www.squid-cache.org/Doc/config/external_acl_type/

in squid.conf, this 

external_acl_type check_delay ttl=0 cache=0 %SRC /etc/squid/check_delay.sh

should start 0 helpers immediately after squid (3.5.22) start-up.
However, I always see 5.

2)
I often see this:
Sat Oct 22 23:51:18 2016 user.alert syslog: The check_delay helpers are
crashing too rapidly, need help!
Sat Oct 22 23:51:18 2016 local4.notice squid[21677]: Squid Parent: (squid-1)
process 27685 exited with status 1
 
Still trying to trace down the problem, I notice, that in this case some
helpers still kept alive, although
I expect them to be killed, too, in case squid-1 exits.


I need to add, that I am running squid on an embedded system, cross-compiled
for MIPS.
So there _might_ be some assumptions made for "standard LINUX" squid, which
are not true in my case.




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/external-acl-type-problem-tp4680203.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sun Oct 23 11:15:53 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 23 Oct 2016 17:15:53 +0600
Subject: [squid-users] Slowness in Squid
In-Reply-To: <CAN-hqth-kdQDYXTR=jDnbVoiNmEMpi71+Sx7waO=61s0keucDQ@mail.gmail.com>
References: <CAN-hqth-kdQDYXTR=jDnbVoiNmEMpi71+Sx7waO=61s0keucDQ@mail.gmail.com>
Message-ID: <ebf2c080-b508-9547-a9df-d7971df609a4@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Keep in mind - a huge in-memory cache does not always give the
acceleration. Moreover, in most cases you can get the opposite effect
expected. It is a common misconception - that the giant memory cache
will give a giant performance gain.


23.10.2016 9:36, Krishna Kulkarni ?????:
>
> Dear Team
> I am new to squid.. I have installed squid 3.5 on CentOS 6.7. As a
configuration part, I have kept most of the things default. Please
advice on how to allocate cache memory of 20 GB to squid. I got to know
that, more cache memory would increase performance of squid..
>
> Thanks,
> Krishna
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDJvoAAoJENNXIZxhPexGyFsH/3or29Reesz9IzZVim7aNk7h
8MYCw8n7l4oaWtZFXdnj6f7sCMKTBVYoxNXqI4O172/XPgkg6y3onFqgU3a5eNIT
r1f09FLi7MAdBAl0YtuwbRXpcKe9SyjhA/hzOhC1UiN3nUcxSR/hyc0oKpjw3Oy1
LwrBQGq7ZjZlNnKZh/uatxyKZolizof9uvKufVJqJdGtJRwkfjc6ELBpC/Lp7chz
yVe2JA7Qi0NHzMoQwS7HblZ/o60E7rdoGTPhBdozxoOMiteW3ZVbm97Mol+t1BM2
s0IsYw9IJSoWPUJ8V+AUryjrzComGnXR4wl20pFrZ+eO/v+tZff6OZVb5A5PDCE=
=6ozO
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/607405d9/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/607405d9/attachment.key>

From uhlar at fantomas.sk  Sun Oct 23 11:37:04 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sun, 23 Oct 2016 13:37:04 +0200
Subject: [squid-users] Slowness in Squid
In-Reply-To: <ebf2c080-b508-9547-a9df-d7971df609a4@gmail.com>
References: <CAN-hqth-kdQDYXTR=jDnbVoiNmEMpi71+Sx7waO=61s0keucDQ@mail.gmail.com>
 <ebf2c080-b508-9547-a9df-d7971df609a4@gmail.com>
Message-ID: <20161023113704.GA12924@fantomas.sk>

On 23.10.16 17:15, Yuri Voinov wrote:
>Keep in mind - a huge in-memory cache does not always give the
>acceleration. Moreover, in most cases you can get the opposite effect
>expected. It is a common misconception - that the giant memory cache
>will give a giant performance gain.

doesn't that imply kind of effectiveness?

>23.10.2016 9:36, Krishna Kulkarni ?????:
>> I am new to squid.. I have installed squid 3.5 on CentOS 6.7. As a
>configuration part, I have kept most of the things default. Please
>advice on how to allocate cache memory of 20 GB to squid. I got to know
>that, more cache memory would increase performance of squid..

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
The only substitute for good manners is fast reflexes. 


From yvoinov at gmail.com  Sun Oct 23 11:40:46 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 23 Oct 2016 17:40:46 +0600
Subject: [squid-users] Slowness in Squid
In-Reply-To: <20161023113704.GA12924@fantomas.sk>
References: <CAN-hqth-kdQDYXTR=jDnbVoiNmEMpi71+Sx7waO=61s0keucDQ@mail.gmail.com>
 <ebf2c080-b508-9547-a9df-d7971df609a4@gmail.com>
 <20161023113704.GA12924@fantomas.sk>
Message-ID: <790ee9e7-f646-d14a-1213-a3729e30d90f@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
This effect is good known to all who have worked with relational
databases. In fact, it is typical in general for all caches except
purpose-built highly scalable systems.


23.10.2016 17:37, Matus UHLAR - fantomas ?????:
> doesn't that imply kind of effectiveness?

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDKG+AAoJENNXIZxhPexGv9IH/A+T/eimJHaIkzY4oyDjbM9Z
fiDZyJPKoQz3uEDCS1qu+xxm33aol+IXFfE6L9ksuTUDwhzVnfw+m1aeEKv0NbBR
ODUL6dUhHnSmKWQ4TjDG/nXaQHK7QQDy+uqeIdZe1P9WHdGJ0qNDKwtCV2mD9hHH
QHg9Ukx7ycYDNAxxBvFfieOIhRfemuh8L+Z7Ne7nrmE6yGW+UCZze1/HfipYdFHH
IAiMO87icjbdd//EcLvhupMAQIBvSBMdehHsri+eHS/hwId2aWGtE/eqRovi8ITe
pPS2xKRC4H1IpzuMMNy0xCGsZ4UZ/vVN8fL0OhMX+VSX48RRN0C2GA1giFcNUAM=
=wnN6
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/327fc190/attachment.key>

From yvoinov at gmail.com  Sun Oct 23 11:53:30 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 23 Oct 2016 17:53:30 +0600
Subject: [squid-users] Slowness in Squid
In-Reply-To: <790ee9e7-f646-d14a-1213-a3729e30d90f@gmail.com>
References: <CAN-hqth-kdQDYXTR=jDnbVoiNmEMpi71+Sx7waO=61s0keucDQ@mail.gmail.com>
 <ebf2c080-b508-9547-a9df-d7971df609a4@gmail.com>
 <20161023113704.GA12924@fantomas.sk>
 <790ee9e7-f646-d14a-1213-a3729e30d90f@gmail.com>
Message-ID: <aaf19f9a-ce43-3038-6350-b68742a54064@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
In fact, the explanation is very simple. At some point soon will get the
content from the disc using an index of any kind than consequentially
and fully scan the giant structure in RAM.

Performance indicator is expressed in the data access time. But this is
from the category of personal experience. Everyone can choose their own
road to hell. :)


23.10.2016 17:40, Yuri Voinov ?????:
>
> This effect is good known to all who have worked with relational
> databases. In fact, it is typical in general for all caches except
> purpose-built highly scalable systems.
>
>
> 23.10.2016 17:37, Matus UHLAR - fantomas ?????:
> > doesn't that imply kind of effectiveness?
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDKS6AAoJENNXIZxhPexGZPgH/0zb2g9Q35y7FOs5twsdtaYV
D/4KC5XarOmK6Ki9Nok3J6LVo4fa6gtIJwoZiItIy+Gh3ByvbZePhjfwNcmJmQn/
p3mt/AelOjaCcI/0ZDxg28PxdNE2Scso6TXE+ZtlHRwpbhZQ5WsXF/bYS+VaZjsM
cAW9BAR0/pOTPbOaRC7iFO2Jp7POLHhOEIP/al75aMhedAMz1UIymGa/Wxj4ZMpA
UpG76xAe78UkBg7mPJAXJmAddnnynlC1VazmlZwSs9YJqFVSnSQ3SvfPxXUW4cN4
3E2iCq3EnO0rDn6TqLmG6w7ZqrZLNsl/JJTwecJ+Ai19xfvODYciAPjz2jB/Kuw=
=8j7T
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/6712cf63/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/6712cf63/attachment.key>

From uhlar at fantomas.sk  Sun Oct 23 12:09:41 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sun, 23 Oct 2016 14:09:41 +0200
Subject: [squid-users] Slowness in Squid
In-Reply-To: <aaf19f9a-ce43-3038-6350-b68742a54064@gmail.com>
References: <CAN-hqth-kdQDYXTR=jDnbVoiNmEMpi71+Sx7waO=61s0keucDQ@mail.gmail.com>
 <ebf2c080-b508-9547-a9df-d7971df609a4@gmail.com>
 <20161023113704.GA12924@fantomas.sk>
 <790ee9e7-f646-d14a-1213-a3729e30d90f@gmail.com>
 <aaf19f9a-ce43-3038-6350-b68742a54064@gmail.com>
Message-ID: <20161023120941.GB12924@fantomas.sk>

>23.10.2016 17:40, Yuri Voinov ?????:
>> This effect is good known to all who have worked with relational
>> databases. In fact, it is typical in general for all caches except
>> purpose-built highly scalable systems.

>> 23.10.2016 17:37, Matus UHLAR - fantomas ?????:
>> > doesn't that imply kind of effectiveness?

On 23.10.16 17:53, Yuri Voinov wrote:
>In fact, the explanation is very simple. At some point soon will get the
>content from the disc using an index of any kind than consequentially
>and fully scan the giant structure in RAM.
>
>Performance indicator is expressed in the data access time. But this is
>from the category of personal experience. Everyone can choose their own
>road to hell. :)

saying this you could say that huge in-memory cache for OSes is useless....

iirc in some squid versions itwas caused by linear searching for memory
objects.

using indexes should speed up saerching and bigger probability to find and
higher probability to find object in memory could outweight searching time.

databases are much faster when using indexes properly, aren't they?

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Support bacteria - they're the only culture some people have. 


From yvoinov at gmail.com  Sun Oct 23 12:15:49 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 23 Oct 2016 18:15:49 +0600
Subject: [squid-users] Slowness in Squid
In-Reply-To: <20161023120941.GB12924@fantomas.sk>
References: <CAN-hqth-kdQDYXTR=jDnbVoiNmEMpi71+Sx7waO=61s0keucDQ@mail.gmail.com>
 <ebf2c080-b508-9547-a9df-d7971df609a4@gmail.com>
 <20161023113704.GA12924@fantomas.sk>
 <790ee9e7-f646-d14a-1213-a3729e30d90f@gmail.com>
 <aaf19f9a-ce43-3038-6350-b68742a54064@gmail.com>
 <20161023120941.GB12924@fantomas.sk>
Message-ID: <c9deee8c-a4b9-db12-53e3-1b1963889b5c@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


23.10.2016 18:09, Matus UHLAR - fantomas ?????:
>> 23.10.2016 17:40, Yuri Voinov ?????:
>>> This effect is good known to all who have worked with relational
>>> databases. In fact, it is typical in general for all caches except
>>> purpose-built highly scalable systems.
>
>>> 23.10.2016 17:37, Matus UHLAR - fantomas ?????:
>>> > doesn't that imply kind of effectiveness?
>
> On 23.10.16 17:53, Yuri Voinov wrote:
>> In fact, the explanation is very simple. At some point soon will get the
>> content from the disc using an index of any kind than consequentially
>> and fully scan the giant structure in RAM.
>>
>> Performance indicator is expressed in the data access time. But this is
>> from the category of personal experience. Everyone can choose their own
>> road to hell. :)
>
> saying this you could say that huge in-memory cache for OSes is
useless....
This is not me talking, and tuning specialists.
>
> iirc in some squid versions itwas caused by linear searching for memory
> objects.
Only up to a point and is highly dependent on the server hardware
architecture and software process architecture.
>
> using indexes should speed up saerching and bigger probability to find and
> higher probability to find object in memory could outweight searching
time.
Certainly. As I said above, it depends on the software architecture
access to a cache memory. If there is an effective index structure (like
a balanced B-tree), the effect disappears.
>
> databases are much faster when using indexes properly, aren't they?
Absolutely yes. But: Most database index structures exist for disk
objects and do not exist for the memory structures. There's a completely
different mechanism. Indices disk objects (which are the metadata) are
loaded into memory and used to access the on-disk data. But access to
the memory is carried out mostly through a simple list structures.

Which leads to performance degradation in case of huge caches. Again we
come back to the importance of software architecture of the memory accesses.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDKn1AAoJENNXIZxhPexGoloH/2LRFaUccVw1lJHdPW0AhB4b
al73ryEEuXo7y0H42T661Xs2rIReOdyIz68qvOUUq8dJBuY48SIAktd5DDfVEU8z
FyGTzxub4LPzU6xKO+LCPd8Mp2SXLayE7Gb3MuMKq++XzubARKfxHwzft+cvAMAN
GTCa+2WIgtQ3WowN7gaOZmKqW7GVSb0rz2yXSOw1sJMQ+VKvAv+vbWgiRi9osiAR
VDgCYWMPX6aQLQGFweLhDVU84xkvxMnCcUisK+DnNXO9DoLwRBbwDbvXuTutRnik
Wk+k1LB4A2OWdHsvAbNsPORqSaeUzjBLHkWROu4H3A0b5Kd+yDRXYThFSA85AsA=
=Khvr
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/007fd9e3/attachment.key>

From yvoinov at gmail.com  Sun Oct 23 12:19:50 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 23 Oct 2016 18:19:50 +0600
Subject: [squid-users] Slowness in Squid
In-Reply-To: <c9deee8c-a4b9-db12-53e3-1b1963889b5c@gmail.com>
References: <CAN-hqth-kdQDYXTR=jDnbVoiNmEMpi71+Sx7waO=61s0keucDQ@mail.gmail.com>
 <ebf2c080-b508-9547-a9df-d7971df609a4@gmail.com>
 <20161023113704.GA12924@fantomas.sk>
 <790ee9e7-f646-d14a-1213-a3729e30d90f@gmail.com>
 <aaf19f9a-ce43-3038-6350-b68742a54064@gmail.com>
 <20161023120941.GB12924@fantomas.sk>
 <c9deee8c-a4b9-db12-53e3-1b1963889b5c@gmail.com>
Message-ID: <abe5da55-0f20-1de6-bfc8-d2c1294347f7@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
In the final, I do not think Squid architecture is designed for fast
access to huge amounts of memory. It came from a time when computers
were young, memory cost like Boeing and hardly Squid itself seriously
reworked in this part since then.

23.10.2016 18:15, Yuri Voinov ?????:
>
>
>
> 23.10.2016 18:09, Matus UHLAR - fantomas ?????:
> >> 23.10.2016 17:40, Yuri Voinov ?????:
> >>> This effect is good known to all who have worked with relational
> >>> databases. In fact, it is typical in general for all caches except
> >>> purpose-built highly scalable systems.
>
> >>> 23.10.2016 17:37, Matus UHLAR - fantomas ?????:
> >>>> doesn't that imply kind of effectiveness?
>
> > On 23.10.16 17:53, Yuri Voinov wrote:
> >> In fact, the explanation is very simple. At some point soon will
get the
> >> content from the disc using an index of any kind than consequentially
> >> and fully scan the giant structure in RAM.
> >>
> >> Performance indicator is expressed in the data access time. But this is
> >> from the category of personal experience. Everyone can choose their own
> >> road to hell. :)
>
> > saying this you could say that huge in-memory cache for OSes is
> useless....
> This is not me talking, and tuning specialists.
>
> > iirc in some squid versions itwas caused by linear searching for memory
> > objects.
> Only up to a point and is highly dependent on the server hardware
> architecture and software process architecture.
>
> > using indexes should speed up saerching and bigger probability to
find and
> > higher probability to find object in memory could outweight searching
> time.
> Certainly. As I said above, it depends on the software architecture
> access to a cache memory. If there is an effective index structure (like
> a balanced B-tree), the effect disappears.
>
> > databases are much faster when using indexes properly, aren't they?
> Absolutely yes. But: Most database index structures exist for disk
> objects and do not exist for the memory structures. There's a completely
> different mechanism. Indices disk objects (which are the metadata) are
> loaded into memory and used to access the on-disk data. But access to
> the memory is carried out mostly through a simple list structures.
>
> Which leads to performance degradation in case of huge caches. Again we
> come back to the importance of software architecture of the memory
accesses.
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDKrmAAoJENNXIZxhPexGMPEIALfRoGL7EDTi4lS1rmItes6k
VJATrwChT8uZR+nexYTusVRaiYc2OnbQthTLYSOTYWqXl43l+Haj0+YAAc4edS1J
8ajAY0FzmGZsLynTsRLq526QsIXBUcuTAnbXbZb16g8sHbWZ/cnZzeR2SBP86qyC
b7EqAsQV1preTlqXo4WpfaZFDZldjwTaemjb91Rl9HsdBaKxcru35wzZbdvefbng
y4I9QPAv6xVFvEjw/IsUdpSe9vRPHFaLXF7WyYF2rM9+1mmCWd9YhFK0NASJ8Jxs
REhMi/WMZHFCh3SK1Dj5H+bH4xONN0AHuf0YogpbgvmjxrJkQhRB88RkH2xNiRE=
=/YWN
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/54138799/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/54138799/attachment.key>

From squid3 at treenet.co.nz  Sun Oct 23 12:32:26 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 24 Oct 2016 01:32:26 +1300
Subject: [squid-users] FTP : Squid sending private IP in PASV response
In-Reply-To: <1477040524.18948.30.camel@comnet.uz>
References: <bd96ae7bac3b4b54ade9ebd5aae16462@HERMES.ace.lan>
 <1477026928.18948.6.camel@comnet.uz>
 <280e11faf0ab42349b20e0f6c1747298@HERMES.ace.lan>
 <1477040524.18948.30.camel@comnet.uz>
Message-ID: <4f14e849-c48b-596e-798f-148b26841ced@treenet.co.nz>

On 21/10/2016 10:02 p.m., Garri Djavadyan wrote:
> On Fri, 2016-10-21 at 08:27 +0000, Gael Ancelin wrote:
>> WAN_IP---[FW]-------localIP1-[SQUID]-localIP2------------localIP3-
>> [FTP_Server]
>>
>> I was expecting something like "227 Entering Passive Mode
>> (54,xx,xx,xx,213,249)." 
>> with public ip.
>> What I want is a response like (WAN_IP,port), but what I obtain is 
>> (localIP1,port) instead.
>>
>> Squid does not respond with the FTP server address, so I presume that
>> Squid is
>> understanding enough FTP protocol to modify response and put his own
>> ip address
>> instead of the real FTP server's.
> 
> According to your scheme, FW is DNAT device and it forwards packets
> destined to FTP control channel port (21) on public IP of FW to private
> localIP1 of SQUID. In that scenario Squid don't even know that the
> client used WAN_IP to access FTP service and therefore it can't use the
> public IP even if it wish.
> 
> 
>> So I'm wondering if it exists a way to force squid to respond with a
>>  fixed IP > address instead of his own local address.
> 
> Here http://www.squid-cache.org/Doc/config/ you can find all available
> options.

'accel' mode is a thing very specific to HTTP port 80 and 443.

The closest thing Squid has for FTP is 'intercept'. I am assuming that
mode works

That brings us to the often repeated advice about NAT intercepted traffic:

 Destination NAT *MUST NOT* be performed on traffic from the client
before it reaches the Squid machine.

When you correct the DNAT to be happening on the Squid machine instead
of the FW, use the 'intercept' option on the ftp_port instead of 'accel'.
(I have not tried it myself, but AFAIK that should work for this scenario)

Amos



From squid3 at treenet.co.nz  Sun Oct 23 12:35:55 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 24 Oct 2016 01:35:55 +1300
Subject: [squid-users] sourcehash load balance
In-Reply-To: <d4af11ba-018f-0d88-c953-c9932a4f0891@brazcubas.br>
References: <d4af11ba-018f-0d88-c953-c9932a4f0891@brazcubas.br>
Message-ID: <d6bbe519-3408-e8f7-9631-a14b89cac603@treenet.co.nz>

On 22/10/2016 12:21 a.m., Andr? Janna wrote:
> I set up a Squid proxy that forwards all requests to 2 parent caches.
> I'm using Squid version 3.5.19.
> My goal is that multiple connection from a client to a server should be
> forwarded to the same parent, so that the server see all requests coming
> from the same IP address.
> 
> I'm using the following configuration:
> cache_peer squid1 parent 3128 0 no-query sourcehash
> cache_peer squid2 parent 3128 0 no-query sourcehash
> never_direct allow all
> 
> Looking at access.log some requests are tagged as CLOSEST_PARENT instead
> of SOURCEHASH_PARENT, so it seams that Squid is not always using source
> hash rule to forward requests to parent caches.
> For instance:
> 1477046954.047   3882 10.11.2.4 TCP_TUNNEL/200 21935 CONNECT
> sso.cisco.com:443 - SOURCEHASH_PARENT/10.0.33.12 -
> 1477046968.056     21 10.11.2.4 TCP_MISS/200 1012 POST
> http://ocsp.digicert.com/ - CLOSEST_PARENT/10.0.33.13
> application/ocsp-response
> 1477047782.038     22 10.11.2.4 TCP_MISS/204 307 GET
> http://clients1.google.com/generate_204 - SOURCEHASH_PARENT/10.0.33.12 -
> 1477047782.045    181 10.11.2.4 TCP_MISS/200 745 GET
> http://tags.bluekai.com/site/2964? - CLOSEST_PARENT/10.0.33.13 image/gif
> 
> So requests from the same client are not sent to the same parent cache.
> How can I force Squid to always use source hash parent selection method?

Check you setting for nonhierarchical_direct. It should be 'off'. The
default is 'on'.

Amos



From krishna26kulkarni at gmail.com  Sun Oct 23 12:42:02 2016
From: krishna26kulkarni at gmail.com (Krishna Kulkarni)
Date: Sun, 23 Oct 2016 18:12:02 +0530
Subject: [squid-users] squid-users Digest, Vol 26, Issue 82
In-Reply-To: <mailman.2194.1477222851.2924.squid-users@lists.squid-cache.org>
References: <mailman.2194.1477222851.2924.squid-users@lists.squid-cache.org>
Message-ID: <CAN-hqtj+OGarvKUo+A4E2-eZvQ20zTwGK26u7rqZ9831Oh-OJQ@mail.gmail.com>

Hi Antony,
Thanks for the reply. I have made changes in squid.conf as per your
suggestion and have allocated 20 GB of Hard disk space.
Squid server at my location handles http/https requests for more than 500
hosts. But at peak hours squid usually performs very slow and browser takes
1-2 minutes just to serve google home page and more time than that for
heavy web page.
I have verified network link utilization & found it consumes not more than
15 mb whereas link bandwidth is of 45mb but still squid serves web pages
very slow to client hosts.
Any suggestions in squid configuration to overcome this issue would be
highly appreciated.

Thanks,
Krishna.
On Oct 23, 2016 5:11 PM, <squid-users-request at lists.squid-cache.org> wrote:

> Send squid-users mailing list submissions to
>         squid-users at lists.squid-cache.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         http://lists.squid-cache.org/listinfo/squid-users
> or, via email, send a message with subject or body 'help' to
>         squid-users-request at lists.squid-cache.org
>
> You can reach the person managing the list at
>         squid-users-owner at lists.squid-cache.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of squid-users digest..."
>
>
> Today's Topics:
>
>    1. Slowness in Squid (Krishna Kulkarni)
>    2. Re: Slowness in Squid (Antony Stone)
>    3. external_acl_type problem (reinerotto)
>    4. Re: Slowness in Squid (Yuri Voinov)
>    5. Re: Slowness in Squid (Matus UHLAR - fantomas)
>    6. Re: Slowness in Squid (Yuri Voinov)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sun, 23 Oct 2016 09:06:22 +0530
> From: Krishna Kulkarni <krishna26kulkarni at gmail.com>
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Slowness in Squid
> Message-ID:
>         <CAN-hqth-kdQDYXTR=jDnbVoiNmEMpi71+Sx7waO=61s0keu
> cDQ at mail.gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Dear Team
> I am new to squid.. I have installed squid 3.5 on CentOS 6.7. As a
> configuration part, I have kept most of the things default. Please advice
> on how to allocate cache memory of 20 GB to squid. I got to know that, more
> cache memory would increase performance of squid..
>
> Thanks,
> Krishna
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <http://lists.squid-cache.org/pipermail/squid-users/
> attachments/20161023/9ddd4442/attachment-0001.html>
>
> ------------------------------
>
> Message: 2
> Date: Sun, 23 Oct 2016 10:16:28 +0200
> From: Antony Stone <Antony.Stone at squid.open.source.it>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Slowness in Squid
> Message-ID: <201610231016.28867.Antony.Stone at squid.open.source.it>
> Content-Type: Text/Plain;  charset="iso-8859-15"
>
> On Sunday 23 October 2016 at 05:36:22, Krishna Kulkarni wrote:
>
> > I am new to squid.. I have installed squid 3.5 on CentOS 6.7. As a
> > configuration part, I have kept most of the things default. Please advice
> > on how to allocate cache memory of 20 GB to squid.
>
> Do you mean cache memory, or disk cache?
>
>
> If you mean memory (RAM) and you have enough of this in your system (eg: 32
> Gbytes or more), then find the section in squid.conf which starts with:
>
> # MEMORY CACHE OPTIONS
>
> And read about the tag "cache_mem".
>
> To set this value (normally 256 Mbytes) to 20 Gbytes, set:
>
> cache_mem 20 GB
>
>
> If, on the other hand, you do not mean memory, but you mean disk cache,
> then
> find the section in squid.conf with starts with:
>
> #  TAG: cache_dir
>
> and read that section.
>
> Pay particular attention to the line which says:
>
> #       cache_dir ufs Directory-Name Mbytes L1 L2 [options]
>
> And then later there is an example:
>
> # cache_dir ufs /var/spool/squid3 100 16 256
>
> Uncomment that line and change the 100 (Megabytes) in that line to 20000
> (for
> 20 Gigabytes) and perhaps also adjust the 16 to something like 64 or even
> 256
> - for a large cache you don't want a few directories with lots of entries
> each, so it's worthwhile creating lots of directories to keep the number of
> files in each down.
>
> > I got to know that, more cache memory would increase performance of
> squid..
>
> What do you mean by "performance"?
>
>
> Antony.
>
> --
> Just when you think you're done, a cat floats by with buttered toast
> strapped
> to its back.
>
>  - Steve Krug, "Don't make me think"
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
>
>
> ------------------------------
>
> Message: 3
> Date: Sun, 23 Oct 2016 03:39:31 -0700 (PDT)
> From: reinerotto <augustus_meyer at gmx.net>
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] external_acl_type problem
> Message-ID: <1477219171447-4680203.post at n4.nabble.com>
> Content-Type: text/plain; charset=us-ascii
>
> 1)
> According to
> http://www.squid-cache.org/Doc/config/external_acl_type/
>
> in squid.conf, this
>
> external_acl_type check_delay ttl=0 cache=0 %SRC /etc/squid/check_delay.sh
>
> should start 0 helpers immediately after squid (3.5.22) start-up.
> However, I always see 5.
>
> 2)
> I often see this:
> Sat Oct 22 23:51:18 2016 user.alert syslog: The check_delay helpers are
> crashing too rapidly, need help!
> Sat Oct 22 23:51:18 2016 local4.notice squid[21677]: Squid Parent:
> (squid-1)
> process 27685 exited with status 1
>
> Still trying to trace down the problem, I notice, that in this case some
> helpers still kept alive, although
> I expect them to be killed, too, in case squid-1 exits.
>
>
> I need to add, that I am running squid on an embedded system,
> cross-compiled
> for MIPS.
> So there _might_ be some assumptions made for "standard LINUX" squid, which
> are not true in my case.
>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.
> 1019090.n4.nabble.com/external-acl-type-problem-tp4680203.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
>
>
> ------------------------------
>
> Message: 4
> Date: Sun, 23 Oct 2016 17:15:53 +0600
> From: Yuri Voinov <yvoinov at gmail.com>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Slowness in Squid
> Message-ID: <ebf2c080-b508-9547-a9df-d7971df609a4 at gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> Keep in mind - a huge in-memory cache does not always give the
> acceleration. Moreover, in most cases you can get the opposite effect
> expected. It is a common misconception - that the giant memory cache
> will give a giant performance gain.
>
>
> 23.10.2016 9:36, Krishna Kulkarni ?????:
> >
> > Dear Team
> > I am new to squid.. I have installed squid 3.5 on CentOS 6.7. As a
> configuration part, I have kept most of the things default. Please
> advice on how to allocate cache memory of 20 GB to squid. I got to know
> that, more cache memory would increase performance of squid..
> >
> > Thanks,
> > Krishna
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJYDJvoAAoJENNXIZxhPexGyFsH/3or29Reesz9IzZVim7aNk7h
> 8MYCw8n7l4oaWtZFXdnj6f7sCMKTBVYoxNXqI4O172/XPgkg6y3onFqgU3a5eNIT
> r1f09FLi7MAdBAl0YtuwbRXpcKe9SyjhA/hzOhC1UiN3nUcxSR/hyc0oKpjw3Oy1
> LwrBQGq7ZjZlNnKZh/uatxyKZolizof9uvKufVJqJdGtJRwkfjc6ELBpC/Lp7chz
> yVe2JA7Qi0NHzMoQwS7HblZ/o60E7rdoGTPhBdozxoOMiteW3ZVbm97Mol+t1BM2
> s0IsYw9IJSoWPUJ8V+AUryjrzComGnXR4wl20pFrZ+eO/v+tZff6OZVb5A5PDCE=
> =6ozO
> -----END PGP SIGNATURE-----
>
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <http://lists.squid-cache.org/pipermail/squid-users/
> attachments/20161023/607405d9/attachment-0001.html>
> -------------- next part --------------
> A non-text attachment was scrubbed...
> Name: 0x613DEC46.asc
> Type: application/pgp-keys
> Size: 2437 bytes
> Desc: not available
> URL: <http://lists.squid-cache.org/pipermail/squid-users/
> attachments/20161023/607405d9/attachment-0001.key>
>
> ------------------------------
>
> Message: 5
> Date: Sun, 23 Oct 2016 13:37:04 +0200
> From: Matus UHLAR - fantomas <uhlar at fantomas.sk>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Slowness in Squid
> Message-ID: <20161023113704.GA12924 at fantomas.sk>
> Content-Type: text/plain; charset=utf-8; format=flowed
>
> On 23.10.16 17:15, Yuri Voinov wrote:
> >Keep in mind - a huge in-memory cache does not always give the
> >acceleration. Moreover, in most cases you can get the opposite effect
> >expected. It is a common misconception - that the giant memory cache
> >will give a giant performance gain.
>
> doesn't that imply kind of effectiveness?
>
> >23.10.2016 9:36, Krishna Kulkarni ?????:
> >> I am new to squid.. I have installed squid 3.5 on CentOS 6.7. As a
> >configuration part, I have kept most of the things default. Please
> >advice on how to allocate cache memory of 20 GB to squid. I got to know
> >that, more cache memory would increase performance of squid..
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> The only substitute for good manners is fast reflexes.
>
>
> ------------------------------
>
> Message: 6
> Date: Sun, 23 Oct 2016 17:40:46 +0600
> From: Yuri Voinov <yvoinov at gmail.com>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Slowness in Squid
> Message-ID: <790ee9e7-f646-d14a-1213-a3729e30d90f at gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> This effect is good known to all who have worked with relational
> databases. In fact, it is typical in general for all caches except
> purpose-built highly scalable systems.
>
>
> 23.10.2016 17:37, Matus UHLAR - fantomas ?????:
> > doesn't that imply kind of effectiveness?
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJYDKG+AAoJENNXIZxhPexGv9IH/A+T/eimJHaIkzY4oyDjbM9Z
> fiDZyJPKoQz3uEDCS1qu+xxm33aol+IXFfE6L9ksuTUDwhzVnfw+m1aeEKv0NbBR
> ODUL6dUhHnSmKWQ4TjDG/nXaQHK7QQDy+uqeIdZe1P9WHdGJ0qNDKwtCV2mD9hHH
> QHg9Ukx7ycYDNAxxBvFfieOIhRfemuh8L+Z7Ne7nrmE6yGW+UCZze1/HfipYdFHH
> IAiMO87icjbdd//EcLvhupMAQIBvSBMdehHsri+eHS/hwId2aWGtE/eqRovi8ITe
> pPS2xKRC4H1IpzuMMNy0xCGsZ4UZ/vVN8fL0OhMX+VSX48RRN0C2GA1giFcNUAM=
> =wnN6
> -----END PGP SIGNATURE-----
>
> -------------- next part --------------
> A non-text attachment was scrubbed...
> Name: 0x613DEC46.asc
> Type: application/pgp-keys
> Size: 2437 bytes
> Desc: not available
> URL: <http://lists.squid-cache.org/pipermail/squid-users/
> attachments/20161023/327fc190/attachment.key>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> ------------------------------
>
> End of squid-users Digest, Vol 26, Issue 82
> *******************************************
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/c777098f/attachment.htm>

From Antony.Stone at squid.open.source.it  Sun Oct 23 12:55:39 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sun, 23 Oct 2016 14:55:39 +0200
Subject: [squid-users] Slowness in Squid [squid-users Digest, Vol 26,
	Issue 82]
In-Reply-To: <CAN-hqtj+OGarvKUo+A4E2-eZvQ20zTwGK26u7rqZ9831Oh-OJQ@mail.gmail.com>
References: <mailman.2194.1477222851.2924.squid-users@lists.squid-cache.org>
 <CAN-hqtj+OGarvKUo+A4E2-eZvQ20zTwGK26u7rqZ9831Oh-OJQ@mail.gmail.com>
Message-ID: <201610231455.39491.Antony.Stone@squid.open.source.it>

On Sunday 23 October 2016 at 14:42:02, Krishna Kulkarni wrote:

> Hi Antony,
> Thanks for the reply. I have made changes in squid.conf as per your
> suggestion and have allocated 20 GB of Hard disk space.

Have you made any measurements at all (either before making the disk cache 
bigger, or since) of what percentage of content Squid is actually caching for 
you?

In other words, how much bandwidth is Squid saving you, compared to simply not 
using Squid at all and getting the content directly?

Also, what made you believe that your disk cache was too small and needed to 
be 20Gbytes instead?

> Squid server at my location handles http/https requests for more than 500
> hosts.

What's more important is the number of requests per second going through Squid 
- it doesn't matter how many hosts are generating them.

> But at peak hours squid usually performs very slow and browser takes
> 1-2 minutes just to serve google home page and more time than that for
> heavy web page.

Have you compared this side-by-side with a browser configured to use Squid and 
a browser configured to go direct?

> I have verified network link utilization & found it consumes not more than
> 15 mb whereas link bandwidth is of 45mb

So, why are you using Squid?

> but still squid serves web pages very slow to client hosts.

What hardware are you running Squid on?

Which operating system / version are you running it under?

What load is Squid generating on the machine?

> Any suggestions in squid configuration to overcome this issue would be
> highly appreciated.

Have you made any measurements of the type of traffic your users are generating 
(for eaxmple, HTTP vs. HTTPS) and how much of this is cacheable at all?

Squid won't help you if the content they're fetching can't be cached (either 
encrypted, or dynamically-generated etc.).


Regards,


Antony.


From squid3 at treenet.co.nz  Sun Oct 23 13:06:02 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 24 Oct 2016 02:06:02 +1300
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <df9eb004318dae81e49c08c518acd39c@comnet.uz>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
Message-ID: <bcae10b2-dfe9-0689-73c6-af58e23c7683@treenet.co.nz>

On 23/10/2016 1:43 a.m., garryd at comnet.uz wrote:
> 
> Nevertheless, I believe that core developers should publish an
> _official_ explanations regarding the tendency, as it often becomes a
> "center of gravity" of many topics.
> 

I did so. Back when these removals started:

<https://squidproxy.wordpress.com/2012/10/16/squid-3-2-pragma-cache-control-no-cache-versus-storage/>

The later options have all been documented (but less in-depth) in the
release announcements for the version which changed, in release notes,
and in squid.conf docs for the series (eg.
<http://www.squid-cache.org/Doc/config/refresh_pattern/>). With a
statement of what they have been replaced with.

They all have been *replaced* with updated behaviour, not simply dropped
as some noisy complainers keep stating.


Also the notion that we have suddenly dropped any control over Vary is
simply false. Squid has never had any way to violate Vary
specifications. The old "broken_vary" feature *prevented* caching of
some Vary. The recent proposal is the opposite of that, about ignoring
Vary for purely the purpose of polluting client users traffic with false
data.

 - there is zero benefit to anyone else in the HTTP ecosystem (and
Internet) beyond the individual sysadmin who proposes doing it.

 - there is serious negative effects to everyone. Including the sysadmin
proposing doing it.

 - there is a very high risk of copy-and-paste sysadmin spreading the
problems without realising what they are doing. Particularly since those
proposing it are so vocal about how great it *seems* for them.

 - there is zero wiggle room in HTTP specifications to work with. These
are absolute "MUST NOT" criterion with no similar mechanism to pretend
was received that would leave HTTP even partially working. (at least not
until Key header exists).

Amos



From yvoinov at gmail.com  Sun Oct 23 13:26:54 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 23 Oct 2016 19:26:54 +0600
Subject: [squid-users] squid-users Digest, Vol 26, Issue 82
In-Reply-To: <CAN-hqtj+OGarvKUo+A4E2-eZvQ20zTwGK26u7rqZ9831Oh-OJQ@mail.gmail.com>
References: <mailman.2194.1477222851.2924.squid-users@lists.squid-cache.org>
 <CAN-hqtj+OGarvKUo+A4E2-eZvQ20zTwGK26u7rqZ9831Oh-OJQ@mail.gmail.com>
Message-ID: <fe490a79-5d6c-af50-c0bd-5236770058b3@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
You can have slow DNS. Consider to use local caching DNS recursor as
source for proxy & users.

23.10.2016 18:42, Krishna Kulkarni ?????:
>
> Hi Antony,
> Thanks for the reply. I have made changes in squid.conf as per your
suggestion and have allocated 20 GB of Hard disk space.
> Squid server at my location handles http/https requests for more than
500 hosts. But at peak hours squid usually performs very slow and
browser takes 1-2 minutes just to serve google home page and more time
than that for heavy web page.
> I have verified network link utilization & found it consumes not more
than 15 mb whereas link bandwidth is of 45mb but still squid serves web
pages very slow to client hosts.
> Any suggestions in squid configuration to overcome this issue would be
highly appreciated.
>
> Thanks,
> Krishna.
>
> On Oct 23, 2016 5:11 PM, <squid-users-request at lists.squid-cache.org
<mailto:squid-users-request at lists.squid-cache.org>> wrote:
>
>     Send squid-users mailing list submissions to
>             squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>     To subscribe or unsubscribe via the World Wide Web, visit
>             http://lists.squid-cache.org/listinfo/squid-users
<http://lists.squid-cache.org/listinfo/squid-users>
>     or, via email, send a message with subject or body 'help' to
>             squid-users-request at lists.squid-cache.org
<mailto:squid-users-request at lists.squid-cache.org>
>
>     You can reach the person managing the list at
>             squid-users-owner at lists.squid-cache.org
<mailto:squid-users-owner at lists.squid-cache.org>
>
>     When replying, please edit your Subject line so it is more specific
>     than "Re: Contents of squid-users digest..."
>
>
>     Today's Topics:
>
>        1. Slowness in Squid (Krishna Kulkarni)
>        2. Re: Slowness in Squid (Antony Stone)
>        3. external_acl_type problem (reinerotto)
>        4. Re: Slowness in Squid (Yuri Voinov)
>        5. Re: Slowness in Squid (Matus UHLAR - fantomas)
>        6. Re: Slowness in Squid (Yuri Voinov)
>
>
>     ----------------------------------------------------------------------
>
>     Message: 1
>     Date: Sun, 23 Oct 2016 09:06:22 +0530
>     From: Krishna Kulkarni <krishna26kulkarni at gmail.com
<mailto:krishna26kulkarni at gmail.com>>
>     To: squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     Subject: [squid-users] Slowness in Squid
>     Message-ID:
>            
<CAN-hqth-kdQDYXTR=jDnbVoiNmEMpi71+Sx7waO=61s0keucDQ at mail.gmail.com
<mailto:61s0keucDQ at mail.gmail.com>>
>     Content-Type: text/plain; charset="utf-8"
>
>     Dear Team
>     I am new to squid.. I have installed squid 3.5 on CentOS 6.7. As a
>     configuration part, I have kept most of the things default. Please
advice
>     on how to allocate cache memory of 20 GB to squid. I got to know
that, more
>     cache memory would increase performance of squid..
>
>     Thanks,
>     Krishna
>     -------------- next part --------------
>     An HTML attachment was scrubbed...
>     URL:
<http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/9ddd4442/attachment-0001.html
<http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/9ddd4442/attachment-0001.html>>
>
>     ------------------------------
>
>     Message: 2
>     Date: Sun, 23 Oct 2016 10:16:28 +0200
>     From: Antony Stone <Antony.Stone at squid.open.source.it
<mailto:Antony.Stone at squid.open.source.it>>
>     To: squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     Subject: Re: [squid-users] Slowness in Squid
>     Message-ID: <201610231016.28867.Antony.Stone at squid.open.source.it
<mailto:201610231016.28867.Antony.Stone at squid.open.source.it>>
>     Content-Type: Text/Plain;  charset="iso-8859-15"
>
>     On Sunday 23 October 2016 at 05:36:22, Krishna Kulkarni wrote:
>
>     > I am new to squid.. I have installed squid 3.5 on CentOS 6.7. As a
>     > configuration part, I have kept most of the things default.
Please advice
>     > on how to allocate cache memory of 20 GB to squid.
>
>     Do you mean cache memory, or disk cache?
>
>
>     If you mean memory (RAM) and you have enough of this in your
system (eg: 32
>     Gbytes or more), then find the section in squid.conf which starts
with:
>
>     # MEMORY CACHE OPTIONS
>
>     And read about the tag "cache_mem".
>
>     To set this value (normally 256 Mbytes) to 20 Gbytes, set:
>
>     cache_mem 20 GB
>
>
>     If, on the other hand, you do not mean memory, but you mean disk
cache, then
>     find the section in squid.conf with starts with:
>
>     #  TAG: cache_dir
>
>     and read that section.
>
>     Pay particular attention to the line which says:
>
>     #       cache_dir ufs Directory-Name Mbytes L1 L2 [options]
>
>     And then later there is an example:
>
>     # cache_dir ufs /var/spool/squid3 100 16 256
>
>     Uncomment that line and change the 100 (Megabytes) in that line to
20000 (for
>     20 Gigabytes) and perhaps also adjust the 16 to something like 64
or even 256
>     - for a large cache you don't want a few directories with lots of
entries
>     each, so it's worthwhile creating lots of directories to keep the
number of
>     files in each down.
>
>     > I got to know that, more cache memory would increase performance
of squid..
>
>     What do you mean by "performance"?
>
>
>     Antony.
>
>     --
>     Just when you think you're done, a cat floats by with buttered
toast strapped
>     to its back.
>
>      - Steve Krug, "Don't make me think"
>
>                                                        Please reply to
the list;
>                                                              please
*don't* CC me.
>
>
>     ------------------------------
>
>     Message: 3
>     Date: Sun, 23 Oct 2016 03:39:31 -0700 (PDT)
>     From: reinerotto <augustus_meyer at gmx.net
<mailto:augustus_meyer at gmx.net>>
>     To: squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     Subject: [squid-users] external_acl_type problem
>     Message-ID: <1477219171447-4680203.post at n4.nabble.com
<mailto:1477219171447-4680203.post at n4.nabble.com>>
>     Content-Type: text/plain; charset=us-ascii
>
>     1)
>     According to
>     http://www.squid-cache.org/Doc/config/external_acl_type/
<http://www.squid-cache.org/Doc/config/external_acl_type/>
>
>     in squid.conf, this
>
>     external_acl_type check_delay ttl=0 cache=0 %SRC
/etc/squid/check_delay.sh
>
>     should start 0 helpers immediately after squid (3.5.22) start-up.
>     However, I always see 5.
>
>     2)
>     I often see this:
>     Sat Oct 22 23:51:18 2016 user.alert syslog: The check_delay
helpers are
>     crashing too rapidly, need help!
>     Sat Oct 22 23:51:18 2016 local4.notice squid[21677]: Squid Parent:
(squid-1)
>     process 27685 exited with status 1
>
>     Still trying to trace down the problem, I notice, that in this
case some
>     helpers still kept alive, although
>     I expect them to be killed, too, in case squid-1 exits.
>
>
>     I need to add, that I am running squid on an embedded system,
cross-compiled
>     for MIPS.
>     So there _might_ be some assumptions made for "standard LINUX"
squid, which
>     are not true in my case.
>
>
>
>
>     --
>     View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/external-acl-type-problem-tp4680203.html
<http://squid-web-proxy-cache.1019090.n4.nabble.com/external-acl-type-problem-tp4680203.html>
>     Sent from the Squid - Users mailing list archive at Nabble.com.
>
>
>     ------------------------------
>
>     Message: 4
>     Date: Sun, 23 Oct 2016 17:15:53 +0600
>     From: Yuri Voinov <yvoinov at gmail.com <mailto:yvoinov at gmail.com>>
>     To: squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     Subject: Re: [squid-users] Slowness in Squid
>     Message-ID: <ebf2c080-b508-9547-a9df-d7971df609a4 at gmail.com
<mailto:ebf2c080-b508-9547-a9df-d7971df609a4 at gmail.com>>
>     Content-Type: text/plain; charset="utf-8"
>
>
> Keep in mind - a huge in-memory cache does not always give the
> acceleration. Moreover, in most cases you can get the opposite effect
> expected. It is a common misconception - that the giant memory cache
> will give a giant performance gain.
>
>
> 23.10.2016 9:36, Krishna Kulkarni ?????:
>
> > Dear Team
> > I am new to squid.. I have installed squid 3.5 on CentOS 6.7. As a
> configuration part, I have kept most of the things default. Please
> advice on how to allocate cache memory of 20 GB to squid. I got to know
> that, more cache memory would increase performance of squid..
>
> > Thanks,
> > Krishna
>
>
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
> > http://lists.squid-cache.org/listinfo/squid-users
<http://lists.squid-cache.org/listinfo/squid-users>
>
>
>     -------------- next part --------------
>     An HTML attachment was scrubbed...
>     URL:
<http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/607405d9/attachment-0001.html
<http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/607405d9/attachment-0001.html>>
>     -------------- next part --------------
>     A non-text attachment was scrubbed...
>     Name: 0x613DEC46.asc
>     Type: application/pgp-keys
>     Size: 2437 bytes
>     Desc: not available
>     URL:
<http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/607405d9/attachment-0001.key
<http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/607405d9/attachment-0001.key>>
>
>     ------------------------------
>
>     Message: 5
>     Date: Sun, 23 Oct 2016 13:37:04 +0200
>     From: Matus UHLAR - fantomas <uhlar at fantomas.sk
<mailto:uhlar at fantomas.sk>>
>     To: squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     Subject: Re: [squid-users] Slowness in Squid
>     Message-ID: <20161023113704.GA12924 at fantomas.sk
<mailto:20161023113704.GA12924 at fantomas.sk>>
>     Content-Type: text/plain; charset=utf-8; format=flowed
>
>     On 23.10.16 17:15, Yuri Voinov wrote:
>     >Keep in mind - a huge in-memory cache does not always give the
>     >acceleration. Moreover, in most cases you can get the opposite effect
>     >expected. It is a common misconception - that the giant memory cache
>     >will give a giant performance gain.
>
>     doesn't that imply kind of effectiveness?
>
>     >23.10.2016 9:36, Krishna Kulkarni ?????:
>     >> I am new to squid.. I have installed squid 3.5 on CentOS 6.7. As a
>     >configuration part, I have kept most of the things default. Please
>     >advice on how to allocate cache memory of 20 GB to squid. I got
to know
>     >that, more cache memory would increase performance of squid..
>
>     --
>     Matus UHLAR - fantomas, uhlar at fantomas.sk
<mailto:uhlar at fantomas.sk> ; http://www.fantomas.sk/
>     Warning: I wish NOT to receive e-mail advertising to this address.
>     Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
>     The only substitute for good manners is fast reflexes.
>
>
>     ------------------------------
>
>     Message: 6
>     Date: Sun, 23 Oct 2016 17:40:46 +0600
>     From: Yuri Voinov <yvoinov at gmail.com <mailto:yvoinov at gmail.com>>
>     To: squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     Subject: Re: [squid-users] Slowness in Squid
>     Message-ID: <790ee9e7-f646-d14a-1213-a3729e30d90f at gmail.com
<mailto:790ee9e7-f646-d14a-1213-a3729e30d90f at gmail.com>>
>     Content-Type: text/plain; charset="utf-8"
>
>
>     -----BEGIN PGP SIGNED MESSAGE-----
>     Hash: SHA256
>
>     This effect is good known to all who have worked with relational
>     databases. In fact, it is typical in general for all caches except
>     purpose-built highly scalable systems.
>
>
>     23.10.2016 17:37, Matus UHLAR - fantomas ?????:
>     > doesn't that imply kind of effectiveness?
>
>     -----BEGIN PGP SIGNATURE-----
>     Version: GnuPG v2
>
>     iQEcBAEBCAAGBQJYDKG+AAoJENNXIZxhPexGv9IH/A+T/eimJHaIkzY4oyDjbM9Z
>     fiDZyJPKoQz3uEDCS1qu+xxm33aol+IXFfE6L9ksuTUDwhzVnfw+m1aeEKv0NbBR
>     ODUL6dUhHnSmKWQ4TjDG/nXaQHK7QQDy+uqeIdZe1P9WHdGJ0qNDKwtCV2mD9hHH
>     QHg9Ukx7ycYDNAxxBvFfieOIhRfemuh8L+Z7Ne7nrmE6yGW+UCZze1/HfipYdFHH
>     IAiMO87icjbdd//EcLvhupMAQIBvSBMdehHsri+eHS/hwId2aWGtE/eqRovi8ITe
>     pPS2xKRC4H1IpzuMMNy0xCGsZ4UZ/vVN8fL0OhMX+VSX48RRN0C2GA1giFcNUAM=
>     =wnN6
>     -----END PGP SIGNATURE-----
>
>     -------------- next part --------------
>     A non-text attachment was scrubbed...
>     Name: 0x613DEC46.asc
>     Type: application/pgp-keys
>     Size: 2437 bytes
>     Desc: not available
>     URL:
<http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/327fc190/attachment.key
<http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/327fc190/attachment.key>>
>
>     ------------------------------
>
>     Subject: Digest Footer
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
<http://lists.squid-cache.org/listinfo/squid-users>
>
>
>     ------------------------------
>
>     End of squid-users Digest, Vol 26, Issue 82
>     *******************************************
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDLqcAAoJENNXIZxhPexGfR8IAISoTylwJrRlHtJtMzV8JDBe
PTs0xLIUd6wtpmVmIfKy/rU1MhKzeShRuoWZ3YHVG7NurSZvYm0B9EMBweh8Xrly
f4YUgwABCXzzy78UgJsmGLVPhRLlORDV7PQys+PAT2MHHL32l4geDUOfVWZ5gv6/
2GEQhH5rYHWeHcVqUpsVyoYfHB3y13t9hdYWEg7k32ZDik8IIVbfV2q+uW0WQjVj
FC4j6599louhwfVCqePJM3hQwycuEqRO8fD/oQwv1jr6x2+4Y71bjm4lbM0HiuKu
byFlnHrhdtD6m5UkQgSzC+PhG2jho02G56IeP20E8HONhwJJLH5/pCrkIAhjmW8=
=J44M
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/c8bcf5d3/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/c8bcf5d3/attachment.key>

From squid3 at treenet.co.nz  Sun Oct 23 13:31:32 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 24 Oct 2016 02:31:32 +1300
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
Message-ID: <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>

On 23/10/2016 2:32 a.m., garryd wrote:
> On 2016-10-22 17:56, Antony Stone wrote:
>> Disclaimer: I am not a Squid developer.
>>
>> On Saturday 22 October 2016 at 14:43:55, garryd wrote:
>>
>>> IMO:
>>>
>>> The only reason I believe [explains] why core developers of Squid
>>> tend to
>>> move HTTP violating settings from average users is to prevent possible
>>> abuse/misuse.
>>
>> I believe the reason is that one of Squid's goals is to be RFC compliant,
>> therefore it does not contain features which violate HTTP.
>>
>>> Nevertheless, I believe that core developers should publish an
>>> _official_ explanations regarding the tendency, as it often becomes a
>>> "center of gravity" of many topics.
>>
>> Which "tendency"?
>>
>> What are you asking for an official explanation of?
>>
>>
>> Antony.
> 
> Since I started use Squid, it's configuration always RFC compliant by
> default, _but_ there were always knobs for users to make it HTTP
> violent. It was in hands of users to decide how to handle a web
> resource. Now it is not always possible, and the topic is an evidence.
> For example, in terms of this topic, users can't violate this RFC
> statement [1]:
> 
>    A Vary field value of "*" signals that anything about the request
>    might play a role in selecting the response representation, possibly
>    including elements outside the message syntax (e.g., the client's
>    network address).  A recipient will not be able to determine whether
>    this response is appropriate for a later request without forwarding
>    the request to the origin server.  A proxy MUST NOT generate a Vary
>    field with a "*" value.
> 
> [1] https://tools.ietf.org/html/rfc7231#section-7.1.4


Please name the option in any version of Squid which allowed Squid to
cache those "Vary: *" responses.

No such option ever existed. For the 20+ years Vary has existed Squid
has behaved in the same way it does today. For all that time you did not
notice these responses.

The one thing that has changed is that we have slowly added support for
the RFC bits that allowed more and more objects to be cached. So this
has become more and more noticable as an outstanding non-cacheable response.


Amos



From squid3 at treenet.co.nz  Sun Oct 23 13:38:08 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 24 Oct 2016 02:38:08 +1300
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <201610221456.11879.Antony.Stone@squid.open.source.it>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
Message-ID: <1a643e9a-77bf-c9d4-7524-a8fb6978481c@treenet.co.nz>

On 23/10/2016 1:56 a.m., Antony Stone wrote:
> Disclaimer: I am not a Squid developer.
> 
> On Saturday 22 October 2016 at 14:43:55, garry wrote:
> 
>> IMO:
>>
>> The only reason I believe [explains] why core developers of Squid tend to
>> move HTTP violating settings from average users is to prevent possible
>> abuse/misuse.
> 
> I believe the reason is that one of Squid's goals is to be RFC compliant, 

It is.

> therefore it does not contain features which violate HTTP.
> 

None of the Squid dev agree with that conclusion. It would be nice, but
is not realistic. Squid has two relevant builds;

--disable-http-violations which adheres to the RFCs. Tollerant
processing is written into the RFCs, so we do not have to violate them
to interoperate with badly behaving other softwares.

--enable-http-violations which either just does or allows the sysadmin
to configure options that:
 * directly override SHOULD (NOT) requirements in the RFCs, and
 * directly overrides some MUST (NOT) requirements where we think they
can be safely avoided, and
 * extend the RFC described behaviours in custom ways that may not work
well but seem to have benefits.



Amos



From Antony.Stone at squid.open.source.it  Sun Oct 23 14:02:07 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sun, 23 Oct 2016 16:02:07 +0200
Subject: [squid-users] squid-users Digest, Vol 26, Issue 82
In-Reply-To: <fe490a79-5d6c-af50-c0bd-5236770058b3@gmail.com>
References: <mailman.2194.1477222851.2924.squid-users@lists.squid-cache.org>
 <CAN-hqtj+OGarvKUo+A4E2-eZvQ20zTwGK26u7rqZ9831Oh-OJQ@mail.gmail.com>
 <fe490a79-5d6c-af50-c0bd-5236770058b3@gmail.com>
Message-ID: <201610231602.08041.Antony.Stone@squid.open.source.it>

On Sunday 23 October 2016 at 15:26:54, Yuri Voinov wrote:

> You can have slow DNS. Consider to use local caching DNS recursor as
> source for proxy & users.

Why would that result in requests via Squid being slower than direct?

@Krishna: You *have* confirmed that Squid requests are slower than direct 
requests, for the same URL, at the same time, haven't you?

Antony.

> 23.10.2016 18:42, Krishna Kulkarni ?????:
> > Hi Antony,
> > Thanks for the reply. I have made changes in squid.conf as per your
> > suggestion and have allocated 20 GB of Hard disk space.
> > Squid server at my location handles http/https requests for more than
> > 500 hosts. But at peak hours squid usually performs very slow and
> > browser takes 1-2 minutes just to serve google home page and more time
> > than that for heavy web page.
> >
> > I have verified network link utilization & found it consumes not more
> > than 15 mb whereas link bandwidth is of 45mb but still squid serves web
> > pages very slow to client hosts.
> >
> > Any suggestions in squid configuration to overcome this issue would be
> > highly appreciated.
> >
> > Thanks,
> > Krishna.

-- 
"If I've told you once, I've told you a million times - stop exaggerating!"

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Sun Oct 23 14:11:21 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 23 Oct 2016 20:11:21 +0600
Subject: [squid-users] squid-users Digest, Vol 26, Issue 82
In-Reply-To: <201610231602.08041.Antony.Stone@squid.open.source.it>
References: <mailman.2194.1477222851.2924.squid-users@lists.squid-cache.org>
 <CAN-hqtj+OGarvKUo+A4E2-eZvQ20zTwGK26u7rqZ9831Oh-OJQ@mail.gmail.com>
 <fe490a79-5d6c-af50-c0bd-5236770058b3@gmail.com>
 <201610231602.08041.Antony.Stone@squid.open.source.it>
Message-ID: <22879676-5cf2-359e-6650-97d9bb6f28ce@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
We're don't know, whhat DNS uses Squid itself, it's clients, which DNS
provided by ISP.....

Tis is one of possibilities.

Anyway require to investigate - what exactly is slow.


23.10.2016 20:02, Antony Stone ?????:
> On Sunday 23 October 2016 at 15:26:54, Yuri Voinov wrote:
>
>> You can have slow DNS. Consider to use local caching DNS recursor as
>> source for proxy & users.
>
> Why would that result in requests via Squid being slower than direct?
>
> @Krishna: You *have* confirmed that Squid requests are slower than direct
> requests, for the same URL, at the same time, haven't you?
>
> Antony.
>
>> 23.10.2016 18:42, Krishna Kulkarni ?????:
>>> Hi Antony,
>>> Thanks for the reply. I have made changes in squid.conf as per your
>>> suggestion and have allocated 20 GB of Hard disk space.
>>> Squid server at my location handles http/https requests for more than
>>> 500 hosts. But at peak hours squid usually performs very slow and
>>> browser takes 1-2 minutes just to serve google home page and more time
>>> than that for heavy web page.
>>>
>>> I have verified network link utilization & found it consumes not more
>>> than 15 mb whereas link bandwidth is of 45mb but still squid serves web
>>> pages very slow to client hosts.
>>>
>>> Any suggestions in squid configuration to overcome this issue would be
>>> highly appreciated.
>>>
>>> Thanks,
>>> Krishna.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDMUJAAoJENNXIZxhPexG1MoH/Roe5k3brwKQvA9ppj4ZppJS
7mQsKBbSQeYuu/Jxg0KkbJ9F6CTaswv2ktJFZ9WTqDKrRx7Ysl0T07uiGcVkuh3B
SBUw3pf3AzR1C7FZvNZMQxAlyoUBn4eQ/tfT6RJtaijng4ICAvjs9MTgspNP4ORQ
GrtOclugaeNuncXZ9etEFj5zoG7z1lSvkErsAioHr1VlZWA+QpLzho5mcD6qE5Uy
QqdAwWwnQ1k1GdwwOgMZD4n9P4HbAGGlaXP7owpHx0U20bSYtZ2G5sSx4tm+wKyI
OJHdW6pVs7Tc5vql80jOc3XuPDbXYpFacrt8pJX4gtfUrV2WjLlCeCBW9YkWHZQ=
=p/E9
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/93f48bb6/attachment.key>

From garryd at comnet.uz  Sun Oct 23 16:47:10 2016
From: garryd at comnet.uz (garryd at comnet.uz)
Date: Sun, 23 Oct 2016 21:47:10 +0500
Subject: [squid-users] Caching http google deb files
In-Reply-To: <fa1fecc7-6e0b-0af4-7e86-44f1ccdf9697@cinbesa.com.br>
References: <CA+sSnVYVSAwBrswBumpn0C2yKGwdxhRgT_TRgBBPOU-AoUjc3Q@mail.gmail.com>
 <791856a3-c922-6aea-79e3-369cb7afb2e6@treenet.co.nz>
 <CA+sSnVa-2o2AyKVk85fvQ9L0qsxoGBOLR=q0e8cx39GGVUoFJw@mail.gmail.com>
 <1761f848-efe6-6007-6bfb-0deca32b6774@treenet.co.nz>
 <CA+sSnVbT1D8XxGEyYGLZuOaaF=P=Bj1aQzRzLnv3JcBXRi0nMg@mail.gmail.com>
 <CA+sSnVZ2ErFD+LeLVH3KOjJ_0PuqGyWfRHA23zY8yJQs3kP+Rw@mail.gmail.com>
 <89f9840b-7ec7-2f0b-a81c-5376c344878e@treenet.co.nz>
 <CA+sSnVYCy5E00jKK5cPZm3q+eBX8Fx=Mjs_iu4Xs0oebxcte9Q@mail.gmail.com>
 <1ba79370-ff21-0e52-a5dc-89919c1171b4@measurement-factory.com>
 <57F68690.1020109@tlinx.org>
 <2c043b07-b941-9e29-8813-4642070384f6@measurement-factory.com>
 <CA+sSnVai079zNS6X+Rni9qaRKOAt6PF+nrZQhBR462zL1zWZuA@mail.gmail.com>
 <14791d65-c8ce-7bb1-47b2-55ebefa507da@cinbesa.com.br>
 <053a01d22bce$67f6f1a0$37e4d4e0$@ngtech.co.il>
 <fa1fecc7-6e0b-0af4-7e86-44f1ccdf9697@cinbesa.com.br>
Message-ID: <0c7fa674009a22a71a70efea4bc7ff07@comnet.uz>

On 2016-10-22 23:18, Heiler Bemerguy wrote:
> I've never used ICAP, and I think hacking the code is way faster than
> creating/using a separate service for that. And I'm not sure, but I
> don't think I can manage to get this done with current squid's
> options.

Hi,

For this case I also suggest to use content adaptation, especially eCAP, 
for the following reasons:

* ACL can be used to steer only abusing replies to eCAP to mangle Vary 
field
* There is no need to apply local patch to new Squid versions
* There is no need to build Squid from sources
* There is no need to use daemons for content adaptation
* There is a sample adapter 'ecap_adapter_modifying' [1], prepared by 
The Measurement Factory (Many thanks!), which successfully modifies HTTP 
message's body. It can be to modified to mangle HTTP headers.

[1] http://e-cap.org/Documentation

Garri


From garth at bitco.co.za  Sun Oct 23 17:16:13 2016
From: garth at bitco.co.za (Garth van Sittert | BitCo)
Date: Sun, 23 Oct 2016 17:16:13 +0000
Subject: [squid-users] Squid with ASR9001
Message-ID: <HE1PR01MB12108D2D44BA6ACBC6E75EF5F6D60@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>

Good day all

Has anyone had any experience setting up Squid with any IOS XR Cisco routers?  The Cisco ASR9000 range doesn't support WCCP and I cannot find any examples online.

I have also found quotes regarding PBR on the ASR9000... "With IOS XR traditional policy-based routing (PBR) is history"

I plan to use this on our 10Gbps ISP traffic to improve customer experience...

Garth


[BitCo Email Footer]<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=!3m1!4b1!4m5!3m4!1s0x142989bce6c63b3:0xc0b44878907297f4!8m2!3d-26.04982!4d28.0218801>
The information contained in this message is intended solely for the individual to whom it is specifically and originally addressed. This message and its contents may contain confidential or privileged information from BitCo. If you are not the intended recipient, you are hereby notified that any disclosure or distribution, is strictly prohibited. If you receive this email in error, please notify BitCo immediately and delete it. BitCo does not accept any liability or responsibility if action is taken in reliance on the contents of this information.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/3b8a36c2/attachment.htm>

From garryd at comnet.uz  Sun Oct 23 17:28:57 2016
From: garryd at comnet.uz (garryd at comnet.uz)
Date: Sun, 23 Oct 2016 22:28:57 +0500
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
 <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
Message-ID: <578241c68e8e1238519585b8b1fc0151@comnet.uz>

On 2016-10-23 18:31, Amos Jeffries wrote:
> On 23/10/2016 2:32 a.m., garryd wrote:
>> Since I started use Squid, it's configuration always RFC compliant by
>> default, _but_ there were always knobs for users to make it HTTP
>> violent. It was in hands of users to decide how to handle a web
>> resource. Now it is not always possible, and the topic is an evidence.
>> For example, in terms of this topic, users can't violate this RFC
>> statement [1]:
>> 
>>    A Vary field value of "*" signals that anything about the request
>>    might play a role in selecting the response representation, 
>> possibly
>>    including elements outside the message syntax (e.g., the client's
>>    network address).  A recipient will not be able to determine 
>> whether
>>    this response is appropriate for a later request without forwarding
>>    the request to the origin server.  A proxy MUST NOT generate a Vary
>>    field with a "*" value.
>> 
>> [1] https://tools.ietf.org/html/rfc7231#section-7.1.4
> 
> 
> Please name the option in any version of Squid which allowed Squid to
> cache those "Vary: *" responses.
> 
> No such option ever existed. For the 20+ years Vary has existed Squid
> has behaved in the same way it does today. For all that time you did 
> not
> notice these responses.

You are absolutely right, but there were not such abuse vector in the 
past (at least in my practice). There were tools provided by devs to 
admins to protect against trending abuse cases. So, the question arised, 
what changed in Squid development policy? Why there is no configuration 
option like 'ignore_vary [acl]', so highly demanded by many users in the 
list? Personally, I'm no affected by the Vary abuse, but I suppose there 
will be increasing number of abuse cases in the future. One of your 
answers confirmed my assumption regarding the question:

>  - there is a very high risk of copy-and-paste sysadmin spreading the
> problems without realising what they are doing. Particularly since 
> those
> proposing it are so vocal about how great it *seems* for them.

Garri


From ulysse31 at gmail.com  Sun Oct 23 17:33:41 2016
From: ulysse31 at gmail.com (Ulysse 31)
Date: Sun, 23 Oct 2016 19:33:41 +0200
Subject: [squid-users] icap (squidclamav) and squid 3.5 ssl peek splice
Message-ID: <CAFSDvD0ospBA0g8J5xpyscdoE5hTvoLqF=LNWzvMjPdZJhoJow@mail.gmail.com>

Hello,

I'm actually trying to scan https web pages for viruses.
I have a working squid 3.5.21 configured for https intercept with ssl bump
peek splice (basic) like following :

[...]
ssl_bump peek all
ssl_bump splice all
[...]
icap_enable on
adaptation_send_client_ip on
adaptation_send_username on
icap_client_username_header X-Authenticated-User
icap_preview_enable on
icap_preview_size 1024
icap_service service_req reqmod_precache bypass=1 icap://
127.0.0.1:1344/squidclamav
adaptation_access service_req allow all
icap_service service_resp respmod_precache bypass=1 icap://
127.0.0.1:1344/squidclamav
adaptation_access service_resp allow all
[...]

I have c-icap, clamd, installed and running correctly.
My problem is the following:
I've an external web server, accessible in both HTTP or HTTPS, in one of
its websites, I've put a eicar.com file. When I access it via HTTP, the
eicar.com file is correctly blocked, but when I do it over HTTPS, the file
is not blocked ... And I don't see why ...
Does peek / splice don't allow icap scanning/filtering ?

Thanks for the help.

Cheers,


-- 
do Vale Victor
Ing?nieur Syst?mes, R?seaux et S?curit?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/3210862a/attachment.htm>

From yvoinov at gmail.com  Sun Oct 23 19:23:02 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 24 Oct 2016 01:23:02 +0600
Subject: [squid-users] Squid with ASR9001
In-Reply-To: <HE1PR01MB12108D2D44BA6ACBC6E75EF5F6D60@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
References: <HE1PR01MB12108D2D44BA6ACBC6E75EF5F6D60@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
Message-ID: <48da4dc7-7b05-1409-1de4-3ae5cdfe5f7b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
https://supportforums.cisco.com/discussion/12227051/ios-xr-and-wccp

https://supportforums.cisco.com/discussion/11561126/wccp-not-working-after-asr-migration-done


23.10.2016 23:16, Garth van Sittert | BitCo ?????:
> Cisco ASR9000

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDQ4WAAoJENNXIZxhPexG3LQH/jDPPc9Z3NqBXgk10oyEk4Ca
4Qt1teZtmqR5Vg0F8FcDcaHhph05pLmzwgCaHXFaXEyatd9HnXq8Zeh1lVCA5ECy
IQh3T5EPMJZC1V/WyJL+eDNErpUHhV2dFxtYjHHB10yQ+f7uzHFyXcwZtRwrXnXw
kKw/F0g3hPMtmtKU+eZ8N4OUpuzOSFOEi7RV40O8JKXpTAF63FATUdvO3+SiCkUI
l8wy0bY4EXZOb7NqKh3mPAlag+Oci+kj3xMio9wGZqAX/mzM8EHpfgeTAfGp9dBR
txfWfgGHvxi/+5y/yIJM+RjjitoWY5MhECWDdwWuXWgbB9WoHko6NyOVyd5Wnmw=
=9qRS
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/66ca74de/attachment.key>

From rousskov at measurement-factory.com  Sun Oct 23 19:34:23 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 23 Oct 2016 13:34:23 -0600
Subject: [squid-users] icap (squidclamav) and squid 3.5 ssl peek splice
In-Reply-To: <CAFSDvD0ospBA0g8J5xpyscdoE5hTvoLqF=LNWzvMjPdZJhoJow@mail.gmail.com>
References: <CAFSDvD0ospBA0g8J5xpyscdoE5hTvoLqF=LNWzvMjPdZJhoJow@mail.gmail.com>
Message-ID: <ccedaee8-1fa4-5986-dff8-18dea7b5a273@measurement-factory.com>

On 10/23/2016 11:33 AM, Ulysse 31 wrote:

> ssl_bump peek all
> ssl_bump splice all

> Does peek / splice don't allow icap scanning/filtering ?

The splice action does not allow for scanning/filtering message bodies.
The bump action does. The bump action is not compatible with the peek
action during step 2. So, your configuration will evolve among these lines:

  ssl_bump bump all

or

  ssl_bump stare step1
  ssl_bump bump all

or

  ssl_bump stare all
  ssl_bump bump all

All production configurations are more complex/nuanced. The wiki has
more examples.

Make sure your get SslBump fully working _before_ you throw adaptation
into the mix. You should see all the bumped requests in access.log.


HTH,

Alex.



From yvoinov at gmail.com  Sun Oct 23 19:34:42 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 24 Oct 2016 01:34:42 +0600
Subject: [squid-users] Squid with ASR9001
In-Reply-To: <HE1PR01MB12108D2D44BA6ACBC6E75EF5F6D60@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
References: <HE1PR01MB12108D2D44BA6ACBC6E75EF5F6D60@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
Message-ID: <62d2a63b-b5db-40f9-445f-1087a4fc5850@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


23.10.2016 23:16, Garth van Sittert | BitCo ?????:
>
> Good day all
>
> 
>
> Has anyone had any experience setting up Squid with any IOS XR Cisco
routers?  The Cisco ASR9000 range doesn?t support WCCP and I cannot find
any examples online.
>
Seriously, the entire range?

Who said that it does not support WCCP? It is obligation to support, if
only because it is not a home dish soap. That's when Cisco write the
documentation that does not support - and then we cry.
>
> 
>
> I have also found quotes regarding PBR on the ASR9000? ?With IOS XR
traditional policy-based routing (PBR) is history?
>
It's crazy city a forum talking about? PBR - is a fundamental
functionality for the router. Especially for the router at this level. I
somehow difficult to imagine a company that completely cuts down the
business by releasing incompatible with what device. This is only
possible in the OpenSource. But not in huge IT-business company. AFAIK.
>
> 
>
> I plan to use this on our 10Gbps ISP traffic to improve customer
experience?
>
There is no examples because the solutions of such a level rarely use
Squid. Personally, I do not have a machine to play and write an example
to Squid's wiki. As you know, Christmas is not the wife of a router is
present as trinkets.
>
> 
>
> Garth
>
> 
>
> 
>
> BitCo Email Footer
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=!3m1!4b1!4m5!3m4!1s0x142989bce6c63b3:0xc0b44878907297f4!8m2!3d-26.04982!4d28.0218801>
> The information contained in this message is intended solely for the
individual to whom it is specifically and originally addressed. This
message and its contents may contain confidential or privileged
information from BitCo. If you are not the intended recipient, you are
hereby notified that any disclosure or distribution, is strictly
prohibited. If you receive this email in error, please notify BitCo
immediately and delete it. BitCo does not accept any liability or
responsibility if action is taken in reliance on the contents of this
information.
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEbBAEBCAAGBQJYDRDSAAoJENNXIZxhPexG7roH90gh9VtKKk4g7WKscldhl5ki
tjs5d46Wl6uIWOI0XyK7+94wKGV2oE4cAnoTqmDesxe058r8H67djDJvehIW9s1Q
zjd3DI4Th8QXEzMn5LnxqVSYz3WmANV5Jf/UsUQsUzPzgW2VHOpA8YfLPfEgbvhZ
zeJRG0gMg5fgyFlt90pK1p0v6sAOEB2leigxiWBXI27BEDajBnnSfbqeMvqanDgI
9Cwh1itpkukDNeU7e/e9y1sHLAJrJ8Z0V7ag2iqYb4KJv/SqkcCAsjX1aSv3VpDE
M4OvE+2tRT3v8ud4gIQroQmWrbNKCaBFgKI1tM82ojErj6FgTmv/5FjxHGq1Cw==
=YLEX
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/4e0f3b7f/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/4e0f3b7f/attachment.key>

From nvalera at gmail.com  Sun Oct 23 22:11:01 2016
From: nvalera at gmail.com (N V)
Date: Sun, 23 Oct 2016 19:11:01 -0300
Subject: [squid-users] skype connection problem
Message-ID: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>

hi there,
i've had problems with windows skype clients with the only internet
connection is through squid. the clients can login successful but when they
make a call, it hangs after 12 secconds.

I checked the client connections and see that attempts to connect directly even
if the proxy is properly configured.

my squid version is 3.5.12
the skype clients have the last version available.
does anyone have the same issues?
any idea?

thanks in advance!
Nicol?s.

pd. sorry about my english
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161023/19e6e1ae/attachment.htm>

From yvoinov at gmail.com  Sun Oct 23 22:28:47 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 24 Oct 2016 04:28:47 +0600
Subject: [squid-users] skype connection problem
In-Reply-To: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
Message-ID: <0dc219d6-e5b2-8473-822d-df6ec51d57ed@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


24.10.2016 4:11, N V ?????:
> hi there,
> i've had problems with windows skype clients with the only internet
connection is through squid. the clients can login successful but when
they make a call, it hangs after 12 secconds.
>
> I checked the client connections and see that attempts to connect
directly even if the proxy is properly configured.
Exactly, Skype does not use HTTP to calls. So, why you expect it calls
should goes via proxy?
>
> my squid version is 3.5.12
> the skype clients have the last version available.
> does anyone have the same issues?
> any idea?
With properly configured ssl bump and transparent proxy we have not any
problems with skype. I don't know your details.
>
> thanks in advance!
> Nicol?s.
>
> pd. sorry about my english
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDTmeAAoJENNXIZxhPexG15oH/Alq2pQYRr80H/gMJUj4RJSi
z3X/lD+QN7I7N7XkxV4/vL5Lzznxc/bGKznuAqiusha/t4mDdgpIp0issR9LtcV4
8pLnrnovxTrEWZR7yFfYX+u8V1KGnudQNxlfaJXLL8C8K0mg3cp3GpsW+1a8s2c5
3gvsrj6Ft871gKfNmXXVmT7BVQdrBwnQvBLmP4eKEOIiT9mKQSIZwMJB4HgKUgVW
dmNQQb4q4975FD6c2t8/0Uu6l/A5lbMcxxuRIv3O9xrLqQud05IjYcSDDakzgtTy
qv+w7gFHbKe1YWDUkl2wJEi/TPbIdiXvV73cmh+HiogItDrw++v2rftxMfbJa4U=
=s3Ih
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/40932de1/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/40932de1/attachment.key>

From squid3 at treenet.co.nz  Mon Oct 24 06:03:27 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 24 Oct 2016 19:03:27 +1300
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <578241c68e8e1238519585b8b1fc0151@comnet.uz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
 <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
 <578241c68e8e1238519585b8b1fc0151@comnet.uz>
Message-ID: <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>

On 24/10/2016 6:28 a.m., garryd at comnet.uz wrote:
> On 2016-10-23 18:31, Amos Jeffries wrote:
>> On 23/10/2016 2:32 a.m., garryd wrote:
>>> Since I started use Squid, it's configuration always RFC compliant by
>>> default, _but_ there were always knobs for users to make it HTTP
>>> violent. It was in hands of users to decide how to handle a web
>>> resource. Now it is not always possible, and the topic is an evidence.
>>> For example, in terms of this topic, users can't violate this RFC
>>> statement [1]:
>>>
>>>    A Vary field value of "*" signals that anything about the request
>>>    might play a role in selecting the response representation, possibly
>>>    including elements outside the message syntax (e.g., the client's
>>>    network address).  A recipient will not be able to determine whether
>>>    this response is appropriate for a later request without forwarding
>>>    the request to the origin server.  A proxy MUST NOT generate a Vary
>>>    field with a "*" value.
>>>
>>> [1] https://tools.ietf.org/html/rfc7231#section-7.1.4
>>
>>
>> Please name the option in any version of Squid which allowed Squid to
>> cache those "Vary: *" responses.
>>
>> No such option ever existed. For the 20+ years Vary has existed Squid
>> has behaved in the same way it does today. For all that time you did not
>> notice these responses.
> 
> You are absolutely right, but there were not such abuse vector in the
> past (at least in my practice). There were tools provided by devs to
> admins to protect against trending abuse cases.

What trend? There is exactly one mentioned URL that I'm aware of, the
Chrome browser download URL. I've posted two reasons why Chrome uses the
Vary:* header. Just opinions of mine, but formed after actual
discussions with the Chrome developers some years back.


[I very much dislike writing this. But you seem to have been sucked in
and deserve to know the history.]

All the fuss that is going on AFAICS was started by Yuri. His comment
history here and in bugzilla, and in private responses range from
non-compromising "cache everything no matter what - do what I say, now!"
(repeatedy in unrelated bugzilla reports), "f*ck the RFCs and anyone
following them, just store everything I dont care about what happens"
(this mornings post), to personal attacks against anyone who mentions
the previous stance might have problems (all the "Squid developers
believe/say/..." comments - none of which match what the team we have
actually said to him or believe).

There is one other email address which changes its name occasionally and
posts almost exactly the same words as Yuri's. So it looks to me as Yuri
and some sock puppets performing a campaign to spread lies and FUD about
Squid and hurt the people doing work on it.

Not exactly a good way to get people to do things for free. But it seems
to have worked on getting you and a few others now doing the coding part
for him at no cost, and I have now wasted time responding to you and
thinking of a solution for it that might get accepted for merge.


This particular topic is not the first to have such behaviour by Yuri.
There have been other things where someone made a mistake (overlooked
something) and all hell full of insults broke loose at them. And several
other cases where missing features in Squid did not get instant
obedience to quite blunt and insulting demands. Followed by weeks of
insults until the bug was fixed by other people - then suddenly polite
Yuri comes back overnight.


As a developer, I personally decided not to write the requested code.
Not in the way demanded. This seems to have upset Yuri who has taken to
insulting me and the rest of the dev team as a whole. I'm not sure if he
is trolling to intentionally cause the above mentioned effects, or
really in need of medical assistance to deal with work related stress.

[/history]


> So, the question arised,
> what changed in Squid development policy?

In policy: Nothing I'm aware of in the past 10 years.

What changed on the Internet? a new bunch of RFCs came out, the server
and clients Squid talks to all got updated to follow those documents
more closely.

What changed in Squid? the dev team have been slowly adding the new
abilities to Squid. One by one, its only ~90% (maybe less) compliant
withe the MUST conditions, not even close to that on the SHOULDs, MAYs,
and implied processing abilities.


What do you think should happen to Squid when all the software it talks
to speaks and expects what the RFCs say they should expect from
recipients/Squid ?

Consider the extreme this leads towards: You could easily write a piece
of software that took HTTP requests and sent back random data that
looked vaguely like HTTP responses. But how useless that is when used as
a proxy. So much for ignoring the HTTP specs.


> Why there is no configuration
> option like 'ignore_vary [acl]', so highly demanded by many users in the
> list?

AFAIK nobody has ever even proposed adding one until these past few weeks.

A proposals to ignore "Vary: *" has come up every few years, but when
the proposer was made aware of the server expectations as stated in the
RFC 2616 they went away, no attempt to go any further. So I assume that
means it wasn't really a problem for them, not a serious one.

In RFC 2616 (or older) compliant web there is no benefit to caching
these objects. The revalidate clause did not exist so the server can be
expected to always produce a new one.
So what is gained by caching it? a waste of space other HIT's could have
used better. Negative benefits really, not even zero gain.

The middle sentence of that part of RFC 7231 has only existed for the
past few years. Even I had overlooked it until today. Sorry, but I have
been concentrating on getting Cache-Control going properly (no-cache and
side effects are still a hot topic 4 years after it went in). Vary is
much broken in other serious ways, '*' storage seems a minor issue to me.

Also be aware that Squid is still in the process of moving from HTTP/1.0
behaviour to HTTP/1.1 revalidation. We (Eduard, Alex and myself) have
not magically made everything work perfectly in one release. This is one
of probably many cases where revalidation is potentially usable - just
that nobody has coded it yet. Or cases which were previously forbidden
and HTTPbis discussions (recent 7-ish years) shown that other vendors
are widely okay with it so its been allowed now by the 723x RFC series.


As maintainer its my responsibility to point out the issues to anyone
even proposing a violation gets added. To make sure they are aware of
the expectations the servers and clients may have of Squid.

All violation proposals get the same treatment (heck all patches get
this same treatment too, I'm just a little more lenient on compliance
increasing patches):
 - make the proposer aware of the problems they will cause,
 ** my posts in reply to this and other threads.

 - mention any alternatives (where available),
 ** others have mentioned eCAP/ICAP as better suited to such violations.
That is exactly what those interfaces are designed for.
 ** re-reading the section you quoted above, the middle sentence adds a
possibility I overlooked earlier. You now have a potential direction to
go without even doing any violation. The audit process shows its worth
right there :-).

 - and let them decide if it is worth the trouble to go forward.
 ** so far mostly whats happened is a lot of complaints that "Squid dev
team" are not providing things for free, on demand, to service a very
abusive and extremist person. Or just outright abuse. Seems like the
individual who started the discussions does not care about getting it to
happen. You care more, and as you say below ...


> Personally, I'm no affected by the Vary abuse, but I suppose there
> will be increasing number of abuse cases in the future.

Me neither (for seeing the problem in my sysadmin roles), so for both of
us and many others it seems (to me) not to be a major problem. Or at
least not worth facing the consequences the proposed change risks causing.

We can guess at what the future holds. But until we get there we really
dont know.

My view of things includes years of app developer queries sent to the
IETF HTTPbis WG. There is an increasing number of applications that
*need* proxies to follow the spec requirements. I am not seeing them
much in the wild yet, but those applications are definitely around and
breaking them could lead people to a lot of trouble.


FWIW:  The current spec for HTTP/1.1 is extremely tollerant. There are a
very few places where it comes to an absolute inviolate rule. Those are
cases which have very clear use-case mentioned in the spec and problems
being avoided mentioned as well.

For example the quoted section above about Vary. I overlooked that
middle sentance that has been added since 2616. That creates the leeway
we need to cache the object within compliance. We are thusly allowed to
treat "Vary:*" as another of the must-revalidate caching cases, just
like Cc:private or Authenticated responses.
(From the use-cases that have been mentioned in IETF WG about this
header, and cases people have been advised to use it I very much doubt
any server will respond with 304 to such revalidation. But we might get
lucky, or future servers might do so.)

NP: all previous discussions and proposals of Vary:* handling came up
when 2616 was the spec to follow, and Squid did not do 1.1 much anyway -
so using revalidation was not even on the horizon so to speak.


Anyhow, back to me rant ;-P

The current specs were written by representatives standing for *all* the
major browsers, *all* the major web servers, *all* the major
language/library frameworks, almost all the major command-line tools,
and many application developers as well.

So it is not written in isolation by some few "ivory tower types" Yuri
would have you believe (yes some specs are - HTTP is not, or at least
those types are outnumbered for HTTP). The RFC 723x set is explicitly a
collection of details about how the current HTTP applications actually
found around the world *do* talk to each other today and how best to
exchange messages so the processing operations are understood at both
ends of the network connection.

The HTTP RFC's are effectively a description of current best practice.
Violating is only useful if you are fixing some broken application your
particular proxy has to deal with. All other cases are just causing
inefficiency and varying amounts of nasty depending on the violation.

This latter point is part of why we require a clear use-case before
accepting violation patches - the need for it should be well thought
out. People who choose to violate that type of spec without a good
reason are just being stupid.


The three persons (well, 2 use aliased email addresses - I suspect are
actually one or two persons from the same region of the world) providing
the most noise about Vary keep demanding it be provided for free.


> One of your
> answers confirmed my assumption regarding the question:
> 
>>  - there is a very high risk of copy-and-paste sysadmin spreading the
>> problems without realising what they are doing. Particularly since those
>> proposing it are so vocal about how great it *seems* for them.
> 

When someone else does the coding I act as both auditor and maintainer.
The policies checked during audit do not go into good/bad judgements -
just: code style, quality (no identifiable bugs) and a clear statement
of the need behind the addition (for the merge repo comment to guide
future maintenance of that code).

As maintainer I merge patches myself only if I'm happy to take on code
maintenance for them, or supplier explicitly takes it on themselves (ie
helper authors). Sometimes I get patches up to scratch in audit then let
others merge, or advise they just be used as custom patches. In the
latter case we at least know that patch is not full of obvious bug
behaviours.

But note so far *nobody* has submitted patches to audit about this. It
has all just been a rather heated discussion in various unrelated bug
reports and some threads in this users list.

Amos



From squid3 at treenet.co.nz  Mon Oct 24 06:51:09 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 24 Oct 2016 19:51:09 +1300
Subject: [squid-users] external_acl_type problem
In-Reply-To: <1477219171447-4680203.post@n4.nabble.com>
References: <1477219171447-4680203.post@n4.nabble.com>
Message-ID: <c49ff38c-4ad5-f71e-8389-f4810e2258c5@treenet.co.nz>

On 23/10/2016 11:39 p.m., reinerotto wrote:
> 1)
> According to
> http://www.squid-cache.org/Doc/config/external_acl_type/
> 
> in squid.conf, this 
> 
> external_acl_type check_delay ttl=0 cache=0 %SRC /etc/squid/check_delay.sh
> 
> should start 0 helpers immediately after squid (3.5.22) start-up.
> However, I always see 5.

Odd. The docs are slightly incorrect the max= value should be 5 not 20.

But the startup should be 0 in all Squid-3.2+ like you say. Are you
applying any patches to external_acl.cc or helper/ChildConfig.cc ?


> 
> 2)
> I often see this:
> Sat Oct 22 23:51:18 2016 user.alert syslog: The check_delay helpers are
> crashing too rapidly, need help!
> Sat Oct 22 23:51:18 2016 local4.notice squid[21677]: Squid Parent: (squid-1)
> process 27685 exited with status 1
>  
> Still trying to trace down the problem, I notice, that in this case some
> helpers still kept alive, although
> I expect them to be killed, too, in case squid-1 exits.

That is only logged when helpers exit by themselves. Properly
functioning helpers are required to always remain active and listening
for more lookups from Squid. Only when Squid terminates the stdin
channel should the helper exit.

> 
> I need to add, that I am running squid on an embedded system, cross-compiled
> for MIPS.
> So there _might_ be some assumptions made for "standard LINUX" squid, which
> are not true in my case.
> 

I hope there is no difference. Perl scripts are supposed to work the
same on any OSthat supports Perl.

Amos



From garth at bitco.co.za  Mon Oct 24 07:16:42 2016
From: garth at bitco.co.za (Garth van Sittert | BitCo)
Date: Mon, 24 Oct 2016 07:16:42 +0000
Subject: [squid-users] Squid with ASR9001
In-Reply-To: <62d2a63b-b5db-40f9-445f-1087a4fc5850@gmail.com>
References: <HE1PR01MB12108D2D44BA6ACBC6E75EF5F6D60@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <62d2a63b-b5db-40f9-445f-1087a4fc5850@gmail.com>
Message-ID: <HE1PR01MB1210B9F41867169E17A0A2DAF6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>

Yes, it looks like all of the ASR9000 range which makes use of IOS XR no longer supports WCCP.

Policy Based Routing has been replaced by ACL Based Forwarding or ABF.




From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
Sent: Sunday, 23 October 2016 9:35 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid with ASR9001


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256



23.10.2016 23:16, Garth van Sittert | BitCo ?????:
>

      > Good day all

      >

      >

      >

      > Has anyone had any experience setting up Squid with any IOS
      XR Cisco routers?  The Cisco ASR9000 range doesn?t support WCCP
      and I cannot find any examples online.

      >
Seriously, the entire range?

Who said that it does not support WCCP? It is obligation to support, if only because it is not a home dish soap. That's when Cisco write the documentation that does not support - and then we cry.
>

      >

      >

      > I have also found quotes regarding PBR on the ASR9000? ?With
      IOS XR traditional policy-based routing (PBR) is history?

      >
It's crazy city a forum talking about? PBR - is a fundamental functionality for the router. Especially for the router at this level. I somehow difficult to imagine a company that completely cuts down the business by releasing incompatible with what device. This is only possible in the OpenSource. But not in huge IT-business company. AFAIK.
>

      >

      >

      > I plan to use this on our 10Gbps ISP traffic to improve
      customer experience?

      >
There is no examples because the solutions of such a level rarely use Squid. Personally, I do not have a machine to play and write an example to Squid's wiki. As you know, Christmas is not the wife of a router is present as trinkets.
>

      >

      >

      > Garth

      >

      >

      >

      >

      >

      > BitCo Email Footer
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=!3m1!4b1!4m5!3m4!1s0x142989bce6c63b3:0xc0b44878907297f4!8m2!3d-26.04982!4d28.0218801><https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=!3m1!4b1!4m5!3m4!1s0x142989bce6c63b3:0xc0b44878907297f4!8m2!3d-26.04982!4d28.0218801>

      > The information contained in this message is intended solely
      for the individual to whom it is specifically and originally
      addressed. This message and its contents may contain confidential
      or privileged information from BitCo. If you are not the intended
      recipient, you are hereby notified that any disclosure or
      distribution, is strictly prohibited. If you receive this email in
      error, please notify BitCo immediately and delete it. BitCo does
      not accept any liability or responsibility if action is taken in
      reliance on the contents of this information.

      >

      >

      > _______________________________________________

      > squid-users mailing list

      > squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

      > http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEbBAEBCAAGBQJYDRDSAAoJENNXIZxhPexG7roH90gh9VtKKk4g7WKscldhl5ki
tjs5d46Wl6uIWOI0XyK7+94wKGV2oE4cAnoTqmDesxe058r8H67djDJvehIW9s1Q
zjd3DI4Th8QXEzMn5LnxqVSYz3WmANV5Jf/UsUQsUzPzgW2VHOpA8YfLPfEgbvhZ
zeJRG0gMg5fgyFlt90pK1p0v6sAOEB2leigxiWBXI27BEDajBnnSfbqeMvqanDgI
9Cwh1itpkukDNeU7e/e9y1sHLAJrJ8Z0V7ag2iqYb4KJv/SqkcCAsjX1aSv3VpDE
M4OvE+2tRT3v8ud4gIQroQmWrbNKCaBFgKI1tM82ojErj6FgTmv/5FjxHGq1Cw==
=YLEX
-----END PGP SIGNATURE-----
[BitCo Email Footer]<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=!3m1!4b1!4m5!3m4!1s0x142989bce6c63b3:0xc0b44878907297f4!8m2!3d-26.04982!4d28.0218801>
The information contained in this message is intended solely for the individual to whom it is specifically and originally addressed. This message and its contents may contain confidential or privileged information from BitCo. If you are not the intended recipient, you are hereby notified that any disclosure or distribution, is strictly prohibited. If you receive this email in error, please notify BitCo immediately and delete it. BitCo does not accept any liability or responsibility if action is taken in reliance on the contents of this information.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/0f665508/attachment.htm>

From makleking at yandex.ru  Mon Oct 24 08:34:54 2016
From: makleking at yandex.ru (=?utf-8?B?0JzQuNGF0LDQuNC7?=)
Date: Mon, 24 Oct 2016 16:34:54 +0800
Subject: [squid-users] ERROR: Cannot connect to 127.0.0.1:3128
In-Reply-To: <3067671476442285@web6h.yandex.ru>
References: <294681476158099@web11o.yandex.ru>
 <e663dbd7-b739-ecb9-3598-c649c2b97fcf@treenet.co.nz>
 <6306491476324921@web24g.yandex.ru>
 <41207f59-32a5-0d29-1b62-95c5061ae21b@treenet.co.nz>
 <3067671476442285@web6h.yandex.ru>
Message-ID: <9377811477298094@web29g.yandex.ru>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/2548260e/attachment.htm>

From garryd at comnet.uz  Mon Oct 24 08:59:10 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Mon, 24 Oct 2016 13:59:10 +0500
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
 <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
 <578241c68e8e1238519585b8b1fc0151@comnet.uz>
 <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>
Message-ID: <1477299550.5002.35.camel@comnet.uz>

On Mon, 2016-10-24 at 19:03 +1300, Amos Jeffries wrote:
> On 24/10/2016 6:28 a.m., garryd at comnet.uz wrote:
> > 
> > On 2016-10-23 18:31, Amos Jeffries wrote:
> > > 
> > > On 23/10/2016 2:32 a.m., garryd wrote:
> > > > 
> > > > Since I started use Squid, it's configuration always RFC
> > > > compliant by
> > > > default, _but_ there were always knobs for users to make it
> > > > HTTP
> > > > violent. It was in hands of users to decide how to handle a web
> > > > resource. Now it is not always possible, and the topic is an
> > > > evidence.
> > > > For example, in terms of this topic, users can't violate this
> > > > RFC
> > > > statement [1]:
> > > > 
> > > > ???A Vary field value of "*" signals that anything about the
> > > > request
> > > > ???might play a role in selecting the response representation,
> > > > possibly
> > > > ???including elements outside the message syntax (e.g., the
> > > > client's
> > > > ???network address).??A recipient will not be able to determine
> > > > whether
> > > > ???this response is appropriate for a later request without
> > > > forwarding
> > > > ???the request to the origin server.??A proxy MUST NOT generate
> > > > a Vary
> > > > ???field with a "*" value.
> > > > 
> > > > [1] https://tools.ietf.org/html/rfc7231#section-7.1.4
> > > 
> > > 
> > > Please name the option in any version of Squid which allowed
> > > Squid to
> > > cache those "Vary: *" responses.
> > > 
> > > No such option ever existed. For the 20+ years Vary has existed
> > > Squid
> > > has behaved in the same way it does today. For all that time you
> > > did not
> > > notice these responses.
> > 
> > You are absolutely right, but there were not such abuse vector in
> > the
> > past (at least in my practice). There were tools provided by devs
> > to
> > admins to protect against trending abuse cases.
> 
> What trend? There is exactly one mentioned URL that I'm aware of, the
> Chrome browser download URL. I've posted two reasons why Chrome uses
> the
> Vary:* header. Just opinions of mine, but formed after actual
> discussions with the Chrome developers some years back.
> 
> 
> [I very much dislike writing this. But you seem to have been sucked
> in
> and deserve to know the history.]
> 
> All the fuss that is going on AFAICS was started by Yuri. His comment
> history here and in bugzilla, and in private responses range from
> non-compromising "cache everything no matter what - do what I say,
> now!"
> (repeatedy in unrelated bugzilla reports), "f*ck the RFCs and anyone
> following them, just store everything I dont care about what happens"
> (this mornings post), to personal attacks against anyone who mentions
> the previous stance might have problems (all the "Squid developers
> believe/say/..." comments - none of which match what the team we have
> actually said to him or believe).
> 
> There is one other email address which changes its name occasionally
> and
> posts almost exactly the same words as Yuri's. So it looks to me as
> Yuri
> and some sock puppets performing a campaign to spread lies and FUD
> about
> Squid and hurt the people doing work on it.
> 
> Not exactly a good way to get people to do things for free. But it
> seems
> to have worked on getting you and a few others now doing the coding
> part
> for him at no cost, and I have now wasted time responding to you and
> thinking of a solution for it that might get accepted for merge.
> 
> 
> This particular topic is not the first to have such behaviour by
> Yuri.
> There have been other things where someone made a mistake (overlooked
> something) and all hell full of insults broke loose at them. And
> several
> other cases where missing features in Squid did not get instant
> obedience to quite blunt and insulting demands. Followed by weeks of
> insults until the bug was fixed by other people - then suddenly
> polite
> Yuri comes back overnight.
> 
> 
> As a developer, I personally decided not to write the requested code.
> Not in the way demanded. This seems to have upset Yuri who has taken
> to
> insulting me and the rest of the dev team as a whole. I'm not sure if
> he
> is trolling to intentionally cause the above mentioned effects, or
> really in need of medical assistance to deal with work related
> stress.
> 
> [/history]
> 
> 
> > 
> > So, the question arised,
> > what changed in Squid development policy?
> 
> In policy: Nothing I'm aware of in the past 10 years.
> 
> What changed on the Internet? a new bunch of RFCs came out, the
> server
> and clients Squid talks to all got updated to follow those documents
> more closely.
> 
> What changed in Squid? the dev team have been slowly adding the new
> abilities to Squid. One by one, its only ~90% (maybe less) compliant
> withe the MUST conditions, not even close to that on the SHOULDs,
> MAYs,
> and implied processing abilities.
> 
> 
> What do you think should happen to Squid when all the software it
> talks
> to speaks and expects what the RFCs say they should expect from
> recipients/Squid ?
> 
> Consider the extreme this leads towards: You could easily write a
> piece
> of software that took HTTP requests and sent back random data that
> looked vaguely like HTTP responses. But how useless that is when used
> as
> a proxy. So much for ignoring the HTTP specs.
> 
> 
> > 
> > Why there is no configuration
> > option like 'ignore_vary [acl]', so highly demanded by many users
> > in the
> > list?
> 
> AFAIK nobody has ever even proposed adding one until these past few
> weeks.
> 
> A proposals to ignore "Vary: *" has come up every few years, but when
> the proposer was made aware of the server expectations as stated in
> the
> RFC 2616 they went away, no attempt to go any further. So I assume
> that
> means it wasn't really a problem for them, not a serious one.
> 
> In RFC 2616 (or older) compliant web there is no benefit to caching
> these objects. The revalidate clause did not exist so the server can
> be
> expected to always produce a new one.
> So what is gained by caching it? a waste of space other HIT's could
> have
> used better. Negative benefits really, not even zero gain.
> 
> The middle sentence of that part of RFC 7231 has only existed for the
> past few years. Even I had overlooked it until today. Sorry, but I
> have
> been concentrating on getting Cache-Control going properly (no-cache
> and
> side effects are still a hot topic 4 years after it went in). Vary is
> much broken in other serious ways, '*' storage seems a minor issue to
> me.
> 
> Also be aware that Squid is still in the process of moving from
> HTTP/1.0
> behaviour to HTTP/1.1 revalidation. We (Eduard, Alex and myself) have
> not magically made everything work perfectly in one release. This is
> one
> of probably many cases where revalidation is potentially usable -
> just
> that nobody has coded it yet. Or cases which were previously
> forbidden
> and HTTPbis discussions (recent 7-ish years) shown that other vendors
> are widely okay with it so its been allowed now by the 723x RFC
> series.
> 
> 
> As maintainer its my responsibility to point out the issues to anyone
> even proposing a violation gets added. To make sure they are aware of
> the expectations the servers and clients may have of Squid.
> 
> All violation proposals get the same treatment (heck all patches get
> this same treatment too, I'm just a little more lenient on compliance
> increasing patches):
> ?- make the proposer aware of the problems they will cause,
> ?** my posts in reply to this and other threads.
> 
> ?- mention any alternatives (where available),
> ?** others have mentioned eCAP/ICAP as better suited to such
> violations.
> That is exactly what those interfaces are designed for.
> ?** re-reading the section you quoted above, the middle sentence adds
> a
> possibility I overlooked earlier. You now have a potential direction
> to
> go without even doing any violation. The audit process shows its
> worth
> right there :-).
> 
> ?- and let them decide if it is worth the trouble to go forward.
> ?** so far mostly whats happened is a lot of complaints that "Squid
> dev
> team" are not providing things for free, on demand, to service a very
> abusive and extremist person. Or just outright abuse. Seems like the
> individual who started the discussions does not care about getting it
> to
> happen. You care more, and as you say below ...
> 
> 
> > 
> > Personally, I'm no affected by the Vary abuse, but I suppose there
> > will be increasing number of abuse cases in the future.
> 
> Me neither (for seeing the problem in my sysadmin roles), so for both
> of
> us and many others it seems (to me) not to be a major problem. Or at
> least not worth facing the consequences the proposed change risks
> causing.
> 
> We can guess at what the future holds. But until we get there we
> really
> dont know.
> 
> My view of things includes years of app developer queries sent to the
> IETF HTTPbis WG. There is an increasing number of applications that
> *need* proxies to follow the spec requirements. I am not seeing them
> much in the wild yet, but those applications are definitely around
> and
> breaking them could lead people to a lot of trouble.
> 
> 
> FWIW:??The current spec for HTTP/1.1 is extremely tollerant. There
> are a
> very few places where it comes to an absolute inviolate rule. Those
> are
> cases which have very clear use-case mentioned in the spec and
> problems
> being avoided mentioned as well.
> 
> For example the quoted section above about Vary. I overlooked that
> middle sentance that has been added since 2616. That creates the
> leeway
> we need to cache the object within compliance. We are thusly allowed
> to
> treat "Vary:*" as another of the must-revalidate caching cases, just
> like Cc:private or Authenticated responses.
> (From the use-cases that have been mentioned in IETF WG about this
> header, and cases people have been advised to use it I very much
> doubt
> any server will respond with 304 to such revalidation. But we might
> get
> lucky, or future servers might do so.)
> 
> NP: all previous discussions and proposals of Vary:* handling came up
> when 2616 was the spec to follow, and Squid did not do 1.1 much
> anyway -
> so using revalidation was not even on the horizon so to speak.
> 
> 
> Anyhow, back to me rant ;-P
> 
> The current specs were written by representatives standing for *all*
> the
> major browsers, *all* the major web servers, *all* the major
> language/library frameworks, almost all the major command-line tools,
> and many application developers as well.
> 
> So it is not written in isolation by some few "ivory tower types"
> Yuri
> would have you believe (yes some specs are - HTTP is not, or at least
> those types are outnumbered for HTTP). The RFC 723x set is explicitly
> a
> collection of details about how the current HTTP applications
> actually
> found around the world *do* talk to each other today and how best to
> exchange messages so the processing operations are understood at both
> ends of the network connection.
> 
> The HTTP RFC's are effectively a description of current best
> practice.
> Violating is only useful if you are fixing some broken application
> your
> particular proxy has to deal with. All other cases are just causing
> inefficiency and varying amounts of nasty depending on the violation.
> 
> This latter point is part of why we require a clear use-case before
> accepting violation patches - the need for it should be well thought
> out. People who choose to violate that type of spec without a good
> reason are just being stupid.
> 
> 
> The three persons (well, 2 use aliased email addresses - I suspect
> are
> actually one or two persons from the same region of the world)
> providing
> the most noise about Vary keep demanding it be provided for free.
> 
> 
> > 
> > One of your
> > answers confirmed my assumption regarding the question:
> > 
> > > 
> > > ?- there is a very high risk of copy-and-paste sysadmin spreading
> > > the
> > > problems without realising what they are doing. Particularly
> > > since those
> > > proposing it are so vocal about how great it *seems* for them.
> > 
> 
> When someone else does the coding I act as both auditor and
> maintainer.
> The policies checked during audit do not go into good/bad judgements
> -
> just: code style, quality (no identifiable bugs) and a clear
> statement
> of the need behind the addition (for the merge repo comment to guide
> future maintenance of that code).
> 
> As maintainer I merge patches myself only if I'm happy to take on
> code
> maintenance for them, or supplier explicitly takes it on themselves
> (ie
> helper authors). Sometimes I get patches up to scratch in audit then
> let
> others merge, or advise they just be used as custom patches. In the
> latter case we at least know that patch is not full of obvious bug
> behaviours.
> 
> But note so far *nobody* has submitted patches to audit about this.
> It
> has all just been a rather heated discussion in various unrelated bug
> reports and some threads in this users list.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Hi Amos,

Thank you very much for so detailed explanation. I've made conclusions
from presented information. I deeply regret, that the topic took so
many time from you. I believe, information presented here will be
helpful for the community.

Nevertheless, the topic surfaced new details regarding the Vary and I
tried conditional requests on same URL (Google Chrome) from different
machines/IPs. Here results:

$ curl --head --header "If-Modified-Since: Thu, 22 Oct 2016 08:29:09
GMT" https://dl.google.com/linux/direct/google-chrome-stable_current_am
d64.deb
HTTP/1.1 304 Not Modified
Etag: "101395"
Server: downloads
Vary: *
X-Content-Type-Options: nosniff
X-Frame-Options: SAMEORIGIN
X-Xss-Protection: 1; mode=block
Date: Mon, 24 Oct 2016 08:53:44 GMT
Alt-Svc: quic=":443"; ma=2592000; v="36,35,34"

----

$ curl --head --header 'If-None-Match: "101395"' https://dl.google.com/
linux/direct/google-chrome-stable_current_amd64.deb?
HTTP/1.1 304 Not Modified
Etag: "101395"
Last-Modified: Thu, 20 Oct 2016 08:29:09 GMT
Server: downloads
Vary: *
X-Content-Type-Options: nosniff
X-Frame-Options: SAMEORIGIN
X-Xss-Protection: 1; mode=block
Date: Mon, 24 Oct 2016 08:54:18 GMT
Alt-Svc: quic=":443"; ma=2592000; v="36,35,34"

Garri


From abarqawi at elm.sa  Mon Oct 24 09:27:17 2016
From: abarqawi at elm.sa (Alaa Hassan Barqawi)
Date: Mon, 24 Oct 2016 09:27:17 +0000
Subject: [squid-users] Issue when connecting to apple APN
Message-ID: <94610c000ba1423487833263ae5b8b64@PE1-ELM-WV-EM02.elm.com.sa>

Dears,
I am facing issue in connecting with apple APN gateway.push.apple.com : 2195
The name cannot be resolved although I am using google DNS servers and it throws an error
Unable to determine IP address from host name gateway.push.apple.com
The DNS server returned:
No DNS records

Thanks for support
confirm ca611d6d71a1f7df902469d92f5ea5977079243b


This e-mail message and all attachments transmitted with it are intended solely for the use of the addressee and may contain legally privileged and confidential information. If the reader of this message is not the intended recipient, or an employee or agent responsible for delivering this message to the intended recipient, you are hereby notified that any dissemination, distribution, copying, or other use of this message or its attachments is strictly prohibited. If you have received this message in error, please notify the sender immediately by replying to this message and please delete it from your computer.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/4bbf9a5a/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Oct 24 09:36:34 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 24 Oct 2016 11:36:34 +0200
Subject: [squid-users] Issue when connecting to apple APN
In-Reply-To: <94610c000ba1423487833263ae5b8b64@PE1-ELM-WV-EM02.elm.com.sa>
References: <94610c000ba1423487833263ae5b8b64@PE1-ELM-WV-EM02.elm.com.sa>
Message-ID: <201610241136.35176.Antony.Stone@squid.open.source.it>

On Monday 24 October 2016 at 11:27:17, Alaa Hassan Barqawi wrote:

> Dears,
> I am facing issue in connecting with apple APN gateway.push.apple.com :
> 2195 The name cannot be resolved although I am using google DNS servers
> and it throws an error Unable to determine IP address from host name
> gateway.push.apple.com The DNS server returned:
> No DNS records

There is no A (or AAAA) record, but it is a CNAME:

$ dig gateway.push.apple.com

; <<>> DiG 9.8.4-rpz2+rl005.12-P1 <<>> gateway.push.apple.com
;; global options: +cmd
;; Got answer:
;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 4722
;; flags: qr rd ra; QUERY: 1, ANSWER: 9, AUTHORITY: 0, ADDITIONAL: 0

;; QUESTION SECTION:
;gateway.push.apple.com.                IN      A

;; ANSWER SECTION:
gateway.push.apple.com. 193     IN      CNAME   gateway.push-
apple.com.akadns.net.
gateway.push-apple.com.akadns.net. 60 IN A      17.188.129.25
gateway.push-apple.com.akadns.net. 60 IN A      17.188.134.21
gateway.push-apple.com.akadns.net. 60 IN A      17.188.135.152
gateway.push-apple.com.akadns.net. 60 IN A      17.188.135.149
gateway.push-apple.com.akadns.net. 60 IN A      17.188.134.150
gateway.push-apple.com.akadns.net. 60 IN A      17.188.136.184
gateway.push-apple.com.akadns.net. 60 IN A      17.188.137.150
gateway.push-apple.com.akadns.net. 60 IN A      17.188.142.26

;; Query time: 19 msec
;; SERVER: 80.68.80.24#53(80.68.80.24)
;; WHEN: Mon Oct 24 10:35:09 2016
;; MSG SIZE  rcvd: 215

Are you using your own DNS server, or someone else's?


Antony.

-- 
"There is no reason for any individual to have a computer in their home."

 - Ken Olsen, President of Digital Equipment Corporation (DEC, later consumed 
by Compaq, later merged with HP)

                                                   Please reply to the list;
                                                         please *don't* CC me.


From Antony.Stone at squid.open.source.it  Mon Oct 24 09:42:05 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 24 Oct 2016 11:42:05 +0200
Subject: [squid-users] Issue when connecting to apple APN
In-Reply-To: <201610241136.35176.Antony.Stone@squid.open.source.it>
References: <94610c000ba1423487833263ae5b8b64@PE1-ELM-WV-EM02.elm.com.sa>
 <201610241136.35176.Antony.Stone@squid.open.source.it>
Message-ID: <201610241142.06290.Antony.Stone@squid.open.source.it>

On Monday 24 October 2016 at 11:36:34, Antony Stone wrote:

> On Monday 24 October 2016 at 11:27:17, Alaa Hassan Barqawi wrote:
> > Dears,
> > I am facing issue in connecting with apple APN gateway.push.apple.com :
> > 2195 The name cannot be resolved although I am using google DNS servers
> > and it throws an error Unable to determine IP address from host name
> > gateway.push.apple.com The DNS server returned:
> > No DNS records
> 
> There is no A (or AAAA) record, but it is a CNAME:
> 
> $ dig gateway.push.apple.com
> 
> ; <<>> DiG 9.8.4-rpz2+rl005.12-P1 <<>> gateway.push.apple.com
> ;; global options: +cmd
> ;; Got answer:
> ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 4722
> ;; flags: qr rd ra; QUERY: 1, ANSWER: 9, AUTHORITY: 0, ADDITIONAL: 0
> 
> ;; QUESTION SECTION:
> ;gateway.push.apple.com.                IN      A
> 
> ;; ANSWER SECTION:
> gateway.push.apple.com. 193     IN      CNAME   gateway.push-
> apple.com.akadns.net.
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.129.25
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.134.21
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.135.152
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.135.149
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.134.150
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.136.184
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.137.150
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.142.26
> 
> ;; Query time: 19 msec
> ;; SERVER: 80.68.80.24#53(80.68.80.24)
> ;; WHEN: Mon Oct 24 10:35:09 2016
> ;; MSG SIZE  rcvd: 215
> 
> Are you using your own DNS server, or someone else's?

I apologise for not noticing "I am using Google DNS servers".

However, sending the above query to 8.8.8.8 gives me precisely the same 
result.


Antony.

-- 
The Magic Words are Squeamish Ossifrage.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Mon Oct 24 10:12:10 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 24 Oct 2016 16:12:10 +0600
Subject: [squid-users] Squid with ASR9001
In-Reply-To: <HE1PR01MB1210B9F41867169E17A0A2DAF6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
References: <HE1PR01MB12108D2D44BA6ACBC6E75EF5F6D60@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <62d2a63b-b5db-40f9-445f-1087a4fc5850@gmail.com>
 <HE1PR01MB1210B9F41867169E17A0A2DAF6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
Message-ID: <613eff0c-4cb9-75ea-e7f2-b4bccd95ce74@gmail.com>



24.10.2016 13:16, Garth van Sittert | BitCo ?????:
>
> Yes, it looks like all of the ASR9000 range which makes use of IOS XR 
> no longer supports WCCP.
>
Please, provide prooflink from Cisco.
>
> Policy Based Routing has been replaced by ACL Based Forwarding or ABF.
>
So? This is therminology difference, if any.
>
> *From:*squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
> *On Behalf Of *Yuri Voinov
> *Sent:* Sunday, 23 October 2016 9:35 PM
> *To:* squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Squid with ASR9001
>
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
>
>
> 23.10.2016 23:16, Garth van Sittert | BitCo ?????:
> >
>
>       > Good day all
>
>       >
>
>       >
>
>       >
>
>       > Has anyone had any experience setting up Squid with any IOS
>
>       XR Cisco routers?  The Cisco ASR9000 range doesn?t support WCCP
>
>       and I cannot find any examples online.
>
>       >
> Seriously, the entire range?
>
> Who said that it does not support WCCP? It is obligation to support, 
> if only because it is not a home dish soap. That's when Cisco write 
> the documentation that does not support - and then we cry.
> >
>
>       >
>
>       >
>
>       > I have also found quotes regarding PBR on the ASR9000? ?With
>
>       IOS XR traditional policy-based routing (PBR) is history?
>
>       >
> It's crazy city a forum talking about? PBR - is a fundamental 
> functionality for the router. Especially for the router at this level. 
> I somehow difficult to imagine a company that completely cuts down the 
> business by releasing incompatible with what device. This is only 
> possible in the OpenSource. But not in huge IT-business company. AFAIK.
> >
>
>       >
>
>       >
>
>       > I plan to use this on our 10Gbps ISP traffic to improve
>
>       customer experience?
>
>       >
> There is no examples because the solutions of such a level rarely use 
> Squid. Personally, I do not have a machine to play and write an 
> example to Squid's wiki. As you know, Christmas is not the wife of a 
> router is present as trinkets.
> >
>
>       >
>
>       >
>
>       > Garth
>
>       >
>
>       >
>
>       >
>
>       >
>
>       >
>
>       > BitCo Email Footer
>
> <https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=!3m1!4b1!4m5!3m4!1s0x142989bce6c63b3:0xc0b44878907297f4!8m2!3d-26.04982!4d28.0218801> 
> <https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b44878907297f4%218m2%213d-26.04982%214d28.0218801>
>
>       > The information contained in this message is intended solely
>
>       for the individual to whom it is specifically and originally
>
>       addressed. This message and its contents may contain confidential
>
>       or privileged information from BitCo. If you are not the intended
>
>       recipient, you are hereby notified that any disclosure or
>
>       distribution, is strictly prohibited. If you receive this email in
>
>       error, please notify BitCo immediately and delete it. BitCo does
>
>       not accept any liability or responsibility if action is taken in
>
>       reliance on the contents of this information.
>
>       >
>
>       >
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>
>
>       > http://lists.squid-cache.org/listinfo/squid-users 
> <http://lists.squid-cache.org/listinfo/squid-users>
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEbBAEBCAAGBQJYDRDSAAoJENNXIZxhPexG7roH90gh9VtKKk4g7WKscldhl5ki
> tjs5d46Wl6uIWOI0XyK7+94wKGV2oE4cAnoTqmDesxe058r8H67djDJvehIW9s1Q
> zjd3DI4Th8QXEzMn5LnxqVSYz3WmANV5Jf/UsUQsUzPzgW2VHOpA8YfLPfEgbvhZ
> zeJRG0gMg5fgyFlt90pK1p0v6sAOEB2leigxiWBXI27BEDajBnnSfbqeMvqanDgI
> 9Cwh1itpkukDNeU7e/e9y1sHLAJrJ8Z0V7ag2iqYb4KJv/SqkcCAsjX1aSv3VpDE
> M4OvE+2tRT3v8ud4gIQroQmWrbNKCaBFgKI1tM82ojErj6FgTmv/5FjxHGq1Cw==
> =YLEX
> -----END PGP SIGNATURE-----
>
> BitCo Email Footer 
> <https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b44878907297f4%218m2%213d-26.04982%214d28.0218801>
> The information contained in this message is intended solely for the 
> individual to whom it is specifically and originally addressed. This 
> message and its contents may contain confidential or privileged 
> information from BitCo. If you are not the intended recipient, you are 
> hereby notified that any disclosure or distribution, is strictly 
> prohibited. If you receive this email in error, please notify BitCo 
> immediately and delete it. BitCo does not accept any liability or 
> responsibility if action is taken in reliance on the contents of this 
> information.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/28e99667/attachment.htm>

From yvoinov at gmail.com  Mon Oct 24 10:26:15 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 24 Oct 2016 16:26:15 +0600
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
 <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
 <578241c68e8e1238519585b8b1fc0151@comnet.uz>
 <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>
Message-ID: <4284d81f-5edd-203e-5927-cfa0a0ec4b0d@gmail.com>

No, Amos, I'm not trolling your or another developers.

I just really do not understand why there is a caching proxy, which is 
almost nothing can cache in the modern world. And that in vanilla 
version gives a maximum of 10-30% byte hit. From me personally, it needs 
no justification and no explanation. And the results.

I can not explain to management why no result, referring to your 
explanations or descriptions of standards. I think it's understandable.

At the present time to obtain any acceptable result it is necessary to 
make a hell of a lot of effort. To maintenance such installation is not 
easy.

And as with every new version of the caching level it falls - and it is 
very easy to check - it is very difficult to explain to management, is 
not it?

It's not my imagination - this is confirmed by dozens of Squid 
administrators, including me personally familiar. Therefore, I would 
heed to claim that I lie or deliberately introduce someone else astray.


24.10.2016 12:03, Amos Jeffries ?????:
> On 24/10/2016 6:28 a.m., garryd at comnet.uz wrote:
>> On 2016-10-23 18:31, Amos Jeffries wrote:
>>> On 23/10/2016 2:32 a.m., garryd wrote:
>>>> Since I started use Squid, it's configuration always RFC compliant by
>>>> default, _but_ there were always knobs for users to make it HTTP
>>>> violent. It was in hands of users to decide how to handle a web
>>>> resource. Now it is not always possible, and the topic is an evidence.
>>>> For example, in terms of this topic, users can't violate this RFC
>>>> statement [1]:
>>>>
>>>>     A Vary field value of "*" signals that anything about the request
>>>>     might play a role in selecting the response representation, possibly
>>>>     including elements outside the message syntax (e.g., the client's
>>>>     network address).  A recipient will not be able to determine whether
>>>>     this response is appropriate for a later request without forwarding
>>>>     the request to the origin server.  A proxy MUST NOT generate a Vary
>>>>     field with a "*" value.
>>>>
>>>> [1] https://tools.ietf.org/html/rfc7231#section-7.1.4
>>>
>>> Please name the option in any version of Squid which allowed Squid to
>>> cache those "Vary: *" responses.
>>>
>>> No such option ever existed. For the 20+ years Vary has existed Squid
>>> has behaved in the same way it does today. For all that time you did not
>>> notice these responses.
>> You are absolutely right, but there were not such abuse vector in the
>> past (at least in my practice). There were tools provided by devs to
>> admins to protect against trending abuse cases.
> What trend? There is exactly one mentioned URL that I'm aware of, the
> Chrome browser download URL. I've posted two reasons why Chrome uses the
> Vary:* header. Just opinions of mine, but formed after actual
> discussions with the Chrome developers some years back.
>
>
> [I very much dislike writing this. But you seem to have been sucked in
> and deserve to know the history.]
>
> All the fuss that is going on AFAICS was started by Yuri. His comment
> history here and in bugzilla, and in private responses range from
> non-compromising "cache everything no matter what - do what I say, now!"
> (repeatedy in unrelated bugzilla reports), "f*ck the RFCs and anyone
> following them, just store everything I dont care about what happens"
> (this mornings post), to personal attacks against anyone who mentions
> the previous stance might have problems (all the "Squid developers
> believe/say/..." comments - none of which match what the team we have
> actually said to him or believe).
>
> There is one other email address which changes its name occasionally and
> posts almost exactly the same words as Yuri's. So it looks to me as Yuri
> and some sock puppets performing a campaign to spread lies and FUD about
> Squid and hurt the people doing work on it.
>
> Not exactly a good way to get people to do things for free. But it seems
> to have worked on getting you and a few others now doing the coding part
> for him at no cost, and I have now wasted time responding to you and
> thinking of a solution for it that might get accepted for merge.
>
>
> This particular topic is not the first to have such behaviour by Yuri.
> There have been other things where someone made a mistake (overlooked
> something) and all hell full of insults broke loose at them. And several
> other cases where missing features in Squid did not get instant
> obedience to quite blunt and insulting demands. Followed by weeks of
> insults until the bug was fixed by other people - then suddenly polite
> Yuri comes back overnight.
>
>
> As a developer, I personally decided not to write the requested code.
> Not in the way demanded. This seems to have upset Yuri who has taken to
> insulting me and the rest of the dev team as a whole. I'm not sure if he
> is trolling to intentionally cause the above mentioned effects, or
> really in need of medical assistance to deal with work related stress.
>
> [/history]
>
>
>> So, the question arised,
>> what changed in Squid development policy?
> In policy: Nothing I'm aware of in the past 10 years.
>
> What changed on the Internet? a new bunch of RFCs came out, the server
> and clients Squid talks to all got updated to follow those documents
> more closely.
>
> What changed in Squid? the dev team have been slowly adding the new
> abilities to Squid. One by one, its only ~90% (maybe less) compliant
> withe the MUST conditions, not even close to that on the SHOULDs, MAYs,
> and implied processing abilities.
>
>
> What do you think should happen to Squid when all the software it talks
> to speaks and expects what the RFCs say they should expect from
> recipients/Squid ?
>
> Consider the extreme this leads towards: You could easily write a piece
> of software that took HTTP requests and sent back random data that
> looked vaguely like HTTP responses. But how useless that is when used as
> a proxy. So much for ignoring the HTTP specs.
>
>
>> Why there is no configuration
>> option like 'ignore_vary [acl]', so highly demanded by many users in the
>> list?
> AFAIK nobody has ever even proposed adding one until these past few weeks.
>
> A proposals to ignore "Vary: *" has come up every few years, but when
> the proposer was made aware of the server expectations as stated in the
> RFC 2616 they went away, no attempt to go any further. So I assume that
> means it wasn't really a problem for them, not a serious one.
>
> In RFC 2616 (or older) compliant web there is no benefit to caching
> these objects. The revalidate clause did not exist so the server can be
> expected to always produce a new one.
> So what is gained by caching it? a waste of space other HIT's could have
> used better. Negative benefits really, not even zero gain.
>
> The middle sentence of that part of RFC 7231 has only existed for the
> past few years. Even I had overlooked it until today. Sorry, but I have
> been concentrating on getting Cache-Control going properly (no-cache and
> side effects are still a hot topic 4 years after it went in). Vary is
> much broken in other serious ways, '*' storage seems a minor issue to me.
>
> Also be aware that Squid is still in the process of moving from HTTP/1.0
> behaviour to HTTP/1.1 revalidation. We (Eduard, Alex and myself) have
> not magically made everything work perfectly in one release. This is one
> of probably many cases where revalidation is potentially usable - just
> that nobody has coded it yet. Or cases which were previously forbidden
> and HTTPbis discussions (recent 7-ish years) shown that other vendors
> are widely okay with it so its been allowed now by the 723x RFC series.
>
>
> As maintainer its my responsibility to point out the issues to anyone
> even proposing a violation gets added. To make sure they are aware of
> the expectations the servers and clients may have of Squid.
>
> All violation proposals get the same treatment (heck all patches get
> this same treatment too, I'm just a little more lenient on compliance
> increasing patches):
>   - make the proposer aware of the problems they will cause,
>   ** my posts in reply to this and other threads.
>
>   - mention any alternatives (where available),
>   ** others have mentioned eCAP/ICAP as better suited to such violations.
> That is exactly what those interfaces are designed for.
>   ** re-reading the section you quoted above, the middle sentence adds a
> possibility I overlooked earlier. You now have a potential direction to
> go without even doing any violation. The audit process shows its worth
> right there :-).
>
>   - and let them decide if it is worth the trouble to go forward.
>   ** so far mostly whats happened is a lot of complaints that "Squid dev
> team" are not providing things for free, on demand, to service a very
> abusive and extremist person. Or just outright abuse. Seems like the
> individual who started the discussions does not care about getting it to
> happen. You care more, and as you say below ...
>
>
>> Personally, I'm no affected by the Vary abuse, but I suppose there
>> will be increasing number of abuse cases in the future.
> Me neither (for seeing the problem in my sysadmin roles), so for both of
> us and many others it seems (to me) not to be a major problem. Or at
> least not worth facing the consequences the proposed change risks causing.
>
> We can guess at what the future holds. But until we get there we really
> dont know.
>
> My view of things includes years of app developer queries sent to the
> IETF HTTPbis WG. There is an increasing number of applications that
> *need* proxies to follow the spec requirements. I am not seeing them
> much in the wild yet, but those applications are definitely around and
> breaking them could lead people to a lot of trouble.
>
>
> FWIW:  The current spec for HTTP/1.1 is extremely tollerant. There are a
> very few places where it comes to an absolute inviolate rule. Those are
> cases which have very clear use-case mentioned in the spec and problems
> being avoided mentioned as well.
>
> For example the quoted section above about Vary. I overlooked that
> middle sentance that has been added since 2616. That creates the leeway
> we need to cache the object within compliance. We are thusly allowed to
> treat "Vary:*" as another of the must-revalidate caching cases, just
> like Cc:private or Authenticated responses.
> (From the use-cases that have been mentioned in IETF WG about this
> header, and cases people have been advised to use it I very much doubt
> any server will respond with 304 to such revalidation. But we might get
> lucky, or future servers might do so.)
>
> NP: all previous discussions and proposals of Vary:* handling came up
> when 2616 was the spec to follow, and Squid did not do 1.1 much anyway -
> so using revalidation was not even on the horizon so to speak.
>
>
> Anyhow, back to me rant ;-P
>
> The current specs were written by representatives standing for *all* the
> major browsers, *all* the major web servers, *all* the major
> language/library frameworks, almost all the major command-line tools,
> and many application developers as well.
>
> So it is not written in isolation by some few "ivory tower types" Yuri
> would have you believe (yes some specs are - HTTP is not, or at least
> those types are outnumbered for HTTP). The RFC 723x set is explicitly a
> collection of details about how the current HTTP applications actually
> found around the world *do* talk to each other today and how best to
> exchange messages so the processing operations are understood at both
> ends of the network connection.
>
> The HTTP RFC's are effectively a description of current best practice.
> Violating is only useful if you are fixing some broken application your
> particular proxy has to deal with. All other cases are just causing
> inefficiency and varying amounts of nasty depending on the violation.
>
> This latter point is part of why we require a clear use-case before
> accepting violation patches - the need for it should be well thought
> out. People who choose to violate that type of spec without a good
> reason are just being stupid.
>
>
> The three persons (well, 2 use aliased email addresses - I suspect are
> actually one or two persons from the same region of the world) providing
> the most noise about Vary keep demanding it be provided for free.
>
>
>> One of your
>> answers confirmed my assumption regarding the question:
>>
>>>   - there is a very high risk of copy-and-paste sysadmin spreading the
>>> problems without realising what they are doing. Particularly since those
>>> proposing it are so vocal about how great it *seems* for them.
> When someone else does the coding I act as both auditor and maintainer.
> The policies checked during audit do not go into good/bad judgements -
> just: code style, quality (no identifiable bugs) and a clear statement
> of the need behind the addition (for the merge repo comment to guide
> future maintenance of that code).
>
> As maintainer I merge patches myself only if I'm happy to take on code
> maintenance for them, or supplier explicitly takes it on themselves (ie
> helper authors). Sometimes I get patches up to scratch in audit then let
> others merge, or advise they just be used as custom patches. In the
> latter case we at least know that patch is not full of obvious bug
> behaviours.
>
> But note so far *nobody* has submitted patches to audit about this. It
> has all just been a rather heated discussion in various unrelated bug
> reports and some threads in this users list.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From abarqawi at elm.sa  Mon Oct 24 10:27:42 2016
From: abarqawi at elm.sa (Alaa Hassan Barqawi)
Date: Mon, 24 Oct 2016 10:27:42 +0000
Subject: [squid-users] [External] Re: Issue when connecting to apple APN
In-Reply-To: <201610241142.06290.Antony.Stone@squid.open.source.it>
References: <94610c000ba1423487833263ae5b8b64@PE1-ELM-WV-EM02.elm.com.sa>
 <201610241136.35176.Antony.Stone@squid.open.source.it>
 <201610241142.06290.Antony.Stone@squid.open.source.it>
Message-ID: <178d540d7e7b43a3a9ee4568b97f8607@PE1-ELM-WV-EM02.elm.com.sa>

I used the same configuration as this URL https://panaharjuna.wordpress.com/2009/12/17/speed-your-squid-server-using-google-public-dns/
But unfortunately when it comes to resolve the apple APN gateway it failed and return 503 service unavailable
Any hope to solve it please?
Access.log

1477295971.100      0 192.168.186.37 TCP_MISS/503 0 CONNECT gateway.push.apple.com:2195 - HIER_NONE/- -




-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Antony Stone
Sent: Monday, October 24, 2016 12:42 PM
To: squid-users at lists.squid-cache.org
Subject: [External] Re: [squid-users] Issue when connecting to apple APN

On Monday 24 October 2016 at 11:36:34, Antony Stone wrote:

> On Monday 24 October 2016 at 11:27:17, Alaa Hassan Barqawi wrote:
> > Dears,
> > I am facing issue in connecting with apple APN gateway.push.apple.com :
> > 2195 The name cannot be resolved although I am using google DNS 
> > servers and it throws an error Unable to determine IP address from 
> > host name gateway.push.apple.com The DNS server returned:
> > No DNS records
> 
> There is no A (or AAAA) record, but it is a CNAME:
> 
> $ dig gateway.push.apple.com
> 
> ; <<>> DiG 9.8.4-rpz2+rl005.12-P1 <<>> gateway.push.apple.com ;; 
> global options: +cmd ;; Got answer:
> ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 4722 ;; flags: qr 
> rd ra; QUERY: 1, ANSWER: 9, AUTHORITY: 0, ADDITIONAL: 0
> 
> ;; QUESTION SECTION:
> ;gateway.push.apple.com.                IN      A
> 
> ;; ANSWER SECTION:
> gateway.push.apple.com. 193     IN      CNAME   gateway.push-
> apple.com.akadns.net.
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.129.25
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.134.21
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.135.152
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.135.149
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.134.150
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.136.184
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.137.150
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.142.26
> 
> ;; Query time: 19 msec
> ;; SERVER: 80.68.80.24#53(80.68.80.24) ;; WHEN: Mon Oct 24 10:35:09 
> 2016 ;; MSG SIZE  rcvd: 215
> 
> Are you using your own DNS server, or someone else's?

I apologise for not noticing "I am using Google DNS servers".

However, sending the above query to 8.8.8.8 gives me precisely the same result.


Antony.

-- 
The Magic Words are Squeamish Ossifrage.

                                                   Please reply to the list;
                                                         please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

This e-mail message and all attachments transmitted with it are intended solely for the use of the addressee and may contain legally privileged and confidential information. If the reader of this message is not the intended recipient, or an employee or agent responsible for delivering this message to the intended recipient, you are hereby notified that any dissemination, distribution, copying, or other use of this message or its attachments is strictly prohibited. If you have received this message in error, please notify the sender immediately by replying to this message and please delete it from your computer.

From garth at bitco.co.za  Mon Oct 24 10:30:45 2016
From: garth at bitco.co.za (Garth van Sittert | BitCo)
Date: Mon, 24 Oct 2016 10:30:45 +0000
Subject: [squid-users] Squid with ASR9001
In-Reply-To: <613eff0c-4cb9-75ea-e7f2-b4bccd95ce74@gmail.com>
References: <HE1PR01MB12108D2D44BA6ACBC6E75EF5F6D60@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <62d2a63b-b5db-40f9-445f-1087a4fc5850@gmail.com>
 <HE1PR01MB1210B9F41867169E17A0A2DAF6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <613eff0c-4cb9-75ea-e7f2-b4bccd95ce74@gmail.com>
Message-ID: <HE1PR01MB12104763BDD60B87220FB257F6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>


By Cisco employee - ?Correct, there is no WCCP and no plans for it either... :(?
https://supportforums.cisco.com/discussion/12227051/ios-xr-and-wccp

WCCP supported platforms ?
                https://supportforums.cisco.com/document/133201/wccp-platform-support-overview

Our ASR9001 has no commands that support wccp anywhere?




[http://www.loveburd.com/bitco/bitco-email-logo.jpg]

Garth van Sittert | Chief Executive Officer
(BSC Physics & Computer Science)
Tel: 087 135 0000 Ext: 201
garth at bitco.co.za<mailto:garth at bitco.co.za>
bitco.co.za<http://www.bitco.co.za/>



From: Yuri [mailto:yvoinov at gmail.com]
Sent: Monday, 24 October 2016 12:12 PM
To: Garth van Sittert | BitCo <garth at bitco.co.za>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid with ASR9001




24.10.2016 13:16, Garth van Sittert | BitCo ?????:
Yes, it looks like all of the ASR9000 range which makes use of IOS XR no longer supports WCCP.
Please, provide prooflink from Cisco.


Policy Based Routing has been replaced by ACL Based Forwarding or ABF.
So? This is therminology difference, if any.





From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
Sent: Sunday, 23 October 2016 9:35 PM
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Squid with ASR9001


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256



23.10.2016 23:16, Garth van Sittert | BitCo ?????:
>


      > Good day all


      >


      >


      >


      > Has anyone had any experience setting up Squid with any IOS
      XR Cisco routers?  The Cisco ASR9000 range doesn?t support WCCP
      and I cannot find any examples online.


      >
Seriously, the entire range?

Who said that it does not support WCCP? It is obligation to support, if only because it is not a home dish soap. That's when Cisco write the documentation that does not support - and then we cry.
>


      >


      >


      > I have also found quotes regarding PBR on the ASR9000? ?With
      IOS XR traditional policy-based routing (PBR) is history?


      >
It's crazy city a forum talking about? PBR - is a fundamental functionality for the router. Especially for the router at this level. I somehow difficult to imagine a company that completely cuts down the business by releasing incompatible with what device. This is only possible in the OpenSource. But not in huge IT-business company. AFAIK.
>


      >


      >


      > I plan to use this on our 10Gbps ISP traffic to improve
      customer experience?


      >
There is no examples because the solutions of such a level rarely use Squid. Personally, I do not have a machine to play and write an example to Squid's wiki. As you know, Christmas is not the wife of a router is present as trinkets.
>


      >


      >


      > Garth


      >


      >


      >


      >


      >


      > BitCo Email Footer
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=!3m1!4b1!4m5!3m4!1s0x142989bce6c63b3:0xc0b44878907297f4!8m2!3d-26.04982!4d28.0218801><https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b44878907297f4%218m2%213d-26.04982%214d28.0218801>


      > The information contained in this message is intended solely
      for the individual to whom it is specifically and originally
      addressed. This message and its contents may contain confidential
      or privileged information from BitCo. If you are not the intended
      recipient, you are hereby notified that any disclosure or
      distribution, is strictly prohibited. If you receive this email in
      error, please notify BitCo immediately and delete it. BitCo does
      not accept any liability or responsibility if action is taken in
      reliance on the contents of this information.


      >


      >


      > _______________________________________________


      > squid-users mailing list


      > squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>


      > http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEbBAEBCAAGBQJYDRDSAAoJENNXIZxhPexG7roH90gh9VtKKk4g7WKscldhl5ki
tjs5d46Wl6uIWOI0XyK7+94wKGV2oE4cAnoTqmDesxe058r8H67djDJvehIW9s1Q
zjd3DI4Th8QXEzMn5LnxqVSYz3WmANV5Jf/UsUQsUzPzgW2VHOpA8YfLPfEgbvhZ
zeJRG0gMg5fgyFlt90pK1p0v6sAOEB2leigxiWBXI27BEDajBnnSfbqeMvqanDgI
9Cwh1itpkukDNeU7e/e9y1sHLAJrJ8Z0V7ag2iqYb4KJv/SqkcCAsjX1aSv3VpDE
M4OvE+2tRT3v8ud4gIQroQmWrbNKCaBFgKI1tM82ojErj6FgTmv/5FjxHGq1Cw==
=YLEX
-----END PGP SIGNATURE-----
[BitCo Email Footer]<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b44878907297f4%218m2%213d-26.04982%214d28.0218801>
The information contained in this message is intended solely for the individual to whom it is specifically and originally addressed. This message and its contents may contain confidential or privileged information from BitCo. If you are not the intended recipient, you are hereby notified that any disclosure or distribution, is strictly prohibited. If you receive this email in error, please notify BitCo immediately and delete it. BitCo does not accept any liability or responsibility if action is taken in reliance on the contents of this information.

[BitCo Email Footer]<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=!3m1!4b1!4m5!3m4!1s0x142989bce6c63b3:0xc0b44878907297f4!8m2!3d-26.04982!4d28.0218801>
The information contained in this message is intended solely for the individual to whom it is specifically and originally addressed. This message and its contents may contain confidential or privileged information from BitCo. If you are not the intended recipient, you are hereby notified that any disclosure or distribution, is strictly prohibited. If you receive this email in error, please notify BitCo immediately and delete it. BitCo does not accept any liability or responsibility if action is taken in reliance on the contents of this information.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/df55bc66/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.jpg
Type: image/jpeg
Size: 6213 bytes
Desc: image001.jpg
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/df55bc66/attachment.jpg>

From acrow at integrafin.co.uk  Mon Oct 24 10:42:09 2016
From: acrow at integrafin.co.uk (Alex Crow)
Date: Mon, 24 Oct 2016 11:42:09 +0100
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <4284d81f-5edd-203e-5927-cfa0a0ec4b0d@gmail.com>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
 <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
 <578241c68e8e1238519585b8b1fc0151@comnet.uz>
 <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>
 <4284d81f-5edd-203e-5927-cfa0a0ec4b0d@gmail.com>
Message-ID: <d9527fe0-f14d-e1b4-3891-f87af5ed088b@integrafin.co.uk>

On 24/10/16 11:26, Yuri wrote:

> No, Amos, I'm not trolling your or another developers.
>
> I just really do not understand why there is a caching proxy, which is 
> almost nothing can cache in the modern world. And that in vanilla 
> version gives a maximum of 10-30% byte hit. From me personally, it 
> needs no justification and no explanation. And the results.
>
> I can not explain to management why no result, referring to your 
> explanations or descriptions of standards. I think it's understandable.
>
> At the present time to obtain any acceptable result it is necessary to 
> make a hell of a lot of effort. To maintenance such installation is 
> not easy.
>
> And as with every new version of the caching level it falls - and it 
> is very easy to check - it is very difficult to explain to management, 
> is not it?
>
> It's not my imagination - this is confirmed by dozens of Squid 
> administrators, including me personally familiar. Therefore, I would 
> heed to claim that I lie or deliberately introduce someone else astray.
>

I'd rather have to explain to management about a low hitrate than have 
to explain why they weren't seeing the content they expected to see, or 
that some vital transaction did not go through, but, hey look here, 
we're saving 80% of web traffic bill!


--
This message is intended only for the addressee and may contain
confidential information. Unless you are that person, you may not
disclose its contents or use it in any way and are requested to delete
the message along with any attachments and notify us immediately.
This email is not intended to, nor should it be taken to, constitute advice.
The information provided is correct to our knowledge & belief and must not
be used as a substitute for obtaining tax, regulatory, investment, legal or
any other appropriate advice.

"Transact" is operated by Integrated Financial Arrangements Ltd.
29 Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900 Fax: (020) 7608 5300.
(Registered office: as above; Registered in England and Wales under
number: 3727592). Authorised and regulated by the Financial Conduct
Authority (entered on the Financial Services Register; no. 190856).


From yvoinov at gmail.com  Mon Oct 24 10:49:43 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 24 Oct 2016 16:49:43 +0600
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <d9527fe0-f14d-e1b4-3891-f87af5ed088b@integrafin.co.uk>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
 <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
 <578241c68e8e1238519585b8b1fc0151@comnet.uz>
 <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>
 <4284d81f-5edd-203e-5927-cfa0a0ec4b0d@gmail.com>
 <d9527fe0-f14d-e1b4-3891-f87af5ed088b@integrafin.co.uk>
Message-ID: <8aa13ca6-4ff0-d548-3be6-447b90c16043@gmail.com>



24.10.2016 16:42, Alex Crow ?????:
> On 24/10/16 11:26, Yuri wrote:
>
>> No, Amos, I'm not trolling your or another developers.
>>
>> I just really do not understand why there is a caching proxy, which 
>> is almost nothing can cache in the modern world. And that in vanilla 
>> version gives a maximum of 10-30% byte hit. From me personally, it 
>> needs no justification and no explanation. And the results.
>>
>> I can not explain to management why no result, referring to your 
>> explanations or descriptions of standards. I think it's understandable.
>>
>> At the present time to obtain any acceptable result it is necessary 
>> to make a hell of a lot of effort. To maintenance such installation 
>> is not easy.
>>
>> And as with every new version of the caching level it falls - and it 
>> is very easy to check - it is very difficult to explain to 
>> management, is not it?
>>
>> It's not my imagination - this is confirmed by dozens of Squid 
>> administrators, including me personally familiar. Therefore, I would 
>> heed to claim that I lie or deliberately introduce someone else astray.
>>
>
> I'd rather have to explain to management about a low hitrate than have 
> to explain why they weren't seeing the content they expected to see, 
> or that some vital transaction did not go through, but, hey look here, 
> we're saving 80% of web traffic bill!
So, what are you talking about - the smallest of the problems that can 
be easily testing and solving by existing functionality - such as no_cache.

In any case - it is the choice of each and I only wish to have all 
possible tools. And not to have my hands tied.

Especially when there are competing products that provide the desired 
results. Yes, they cost money. But management is not often ask - just 
buy what they need, by they opinion, and you - with Squid - went to look 
for a job. So simple.

>
>
> -- 
> This message is intended only for the addressee and may contain
> confidential information. Unless you are that person, you may not
> disclose its contents or use it in any way and are requested to delete
> the message along with any attachments and notify us immediately.
> This email is not intended to, nor should it be taken to, constitute 
> advice.
> The information provided is correct to our knowledge & belief and must 
> not
> be used as a substitute for obtaining tax, regulatory, investment, 
> legal or
> any other appropriate advice.
>
> "Transact" is operated by Integrated Financial Arrangements Ltd.
> 29 Clement's Lane, London EC4N 7AE. Tel: (020) 7608 4900 Fax: (020) 
> 7608 5300.
> (Registered office: as above; Registered in England and Wales under
> number: 3727592). Authorised and regulated by the Financial Conduct
> Authority (entered on the Financial Services Register; no. 190856).
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Mon Oct 24 10:51:16 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 24 Oct 2016 23:51:16 +1300
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <1477299550.5002.35.camel@comnet.uz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
 <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
 <578241c68e8e1238519585b8b1fc0151@comnet.uz>
 <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>
 <1477299550.5002.35.camel@comnet.uz>
Message-ID: <bccae1dd-596c-7797-79d0-fb5fdee7297f@treenet.co.nz>

On 24/10/2016 9:59 p.m., Garri Djavadyan wrote:
> Hi Amos,
> 
> Thank you very much for so detailed explanation. I've made conclusions
> from presented information. I deeply regret, that the topic took so
> many time from you. I believe, information presented here will be
> helpful for the community.
> 
> Nevertheless, the topic surfaced new details regarding the Vary and I
> tried conditional requests on same URL (Google Chrome) from different
> machines/IPs. Here results:
> 
> $ curl --head --header "If-Modified-Since: Thu, 22 Oct 2016 08:29:09
> GMT" https://dl.google.com/linux/direct/google-chrome-stable_current_am
> d64.deb
> HTTP/1.1 304 Not Modified
> Etag: "101395"
> Server: downloads
> Vary: *
> X-Content-Type-Options: nosniff
> X-Frame-Options: SAMEORIGIN
> X-Xss-Protection: 1; mode=block
> Date: Mon, 24 Oct 2016 08:53:44 GMT
> Alt-Svc: quic=":443"; ma=2592000; v="36,35,34"
> 
> ----
> 
> $ curl --head --header 'If-None-Match: "101395"' https://dl.google.com/
> linux/direct/google-chrome-stable_current_amd64.deb 
> HTTP/1.1 304 Not Modified
> Etag: "101395"
> Last-Modified: Thu, 20 Oct 2016 08:29:09 GMT
> Server: downloads
> Vary: *
> X-Content-Type-Options: nosniff
> X-Frame-Options: SAMEORIGIN
> X-Xss-Protection: 1; mode=block
> Date: Mon, 24 Oct 2016 08:54:18 GMT
> Alt-Svc: quic=":443"; ma=2592000; v="36,35,34"
> 

Sweet! Far better than I was expecting. That means this patch should work:

=== modified file 'src/http.cc'
--- src/http.cc 2016-10-08 22:19:44 +0000
+++ src/http.cc 2016-10-24 10:50:16 +0000
@@ -593,7 +593,7 @@
     while (strListGetItem(&vary, ',', &item, &ilen, &pos)) {
         SBuf name(item, ilen);
         if (name == asterisk) {
-            vstr.clear();
+            vstr = asterisk;
             break;
         }
         name.toLower();
@@ -947,6 +947,12 @@
             varyFailure = true;
         } else {
             entry->mem_obj->vary_headers = vary;
+
+            // RFC 7231 section 7.1.4
+            // Vary:* can be cached, but has mandatory revalidation
+            static const SBuf asterisk("*");
+            if (vary == asterisk)
+                EBIT_SET(entry->flags, ENTRY_REVALIDATE_ALWAYS);
         }
     }


Amos



From abarqawi at elm.sa  Mon Oct 24 10:53:16 2016
From: abarqawi at elm.sa (Alaa Hassan Barqawi)
Date: Mon, 24 Oct 2016 10:53:16 +0000
Subject: [squid-users] [External] Re: Issue when connecting to apple APN
References: <94610c000ba1423487833263ae5b8b64@PE1-ELM-WV-EM02.elm.com.sa>
 <201610241136.35176.Antony.Stone@squid.open.source.it>
 <201610241142.06290.Antony.Stone@squid.open.source.it> 
Message-ID: <d1d517df23a44b3c8ce9561775c929d0@PE1-ELM-WV-EM02.elm.com.sa>

Dears,
Finally we found the issue as we are running squid on RHEL 7 
Service dnsmasq was stopped 
We just start it and everything worked fine !


???? ??? ???? ??????
Ala'a Hasan Jamil Barqawi
System Integrator

8191 Takhassusi Road, Olaya
Riyadh 12333 - 3038, KSA
Tel +(9661) 2887513
Mobile +(966) 565050590
abarqawi at elm.sa 
www.elm.sa

-----Original Message-----
From: Alaa Hassan Barqawi 
Sent: Monday, October 24, 2016 1:28 PM
To: 'Antony Stone'; squid-users at lists.squid-cache.org
Subject: RE: [External] Re: [squid-users] Issue when connecting to apple APN

I used the same configuration as this URL https://panaharjuna.wordpress.com/2009/12/17/speed-your-squid-server-using-google-public-dns/
But unfortunately when it comes to resolve the apple APN gateway it failed and return 503 service unavailable Any hope to solve it please?
Access.log

1477295971.100      0 192.168.186.37 TCP_MISS/503 0 CONNECT gateway.push.apple.com:2195 - HIER_NONE/- -




-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Antony Stone
Sent: Monday, October 24, 2016 12:42 PM
To: squid-users at lists.squid-cache.org
Subject: [External] Re: [squid-users] Issue when connecting to apple APN

On Monday 24 October 2016 at 11:36:34, Antony Stone wrote:

> On Monday 24 October 2016 at 11:27:17, Alaa Hassan Barqawi wrote:
> > Dears,
> > I am facing issue in connecting with apple APN gateway.push.apple.com :
> > 2195 The name cannot be resolved although I am using google DNS 
> > servers and it throws an error Unable to determine IP address from 
> > host name gateway.push.apple.com The DNS server returned:
> > No DNS records
> 
> There is no A (or AAAA) record, but it is a CNAME:
> 
> $ dig gateway.push.apple.com
> 
> ; <<>> DiG 9.8.4-rpz2+rl005.12-P1 <<>> gateway.push.apple.com ;; 
> global options: +cmd ;; Got answer:
> ;; ->>HEADER<<- opcode: QUERY, status: NOERROR, id: 4722 ;; flags: qr 
> rd ra; QUERY: 1, ANSWER: 9, AUTHORITY: 0, ADDITIONAL: 0
> 
> ;; QUESTION SECTION:
> ;gateway.push.apple.com.                IN      A
> 
> ;; ANSWER SECTION:
> gateway.push.apple.com. 193     IN      CNAME   gateway.push-
> apple.com.akadns.net.
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.129.25
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.134.21
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.135.152
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.135.149
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.134.150
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.136.184
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.137.150
> gateway.push-apple.com.akadns.net. 60 IN A      17.188.142.26
> 
> ;; Query time: 19 msec
> ;; SERVER: 80.68.80.24#53(80.68.80.24) ;; WHEN: Mon Oct 24 10:35:09
> 2016 ;; MSG SIZE  rcvd: 215
> 
> Are you using your own DNS server, or someone else's?

I apologise for not noticing "I am using Google DNS servers".

However, sending the above query to 8.8.8.8 gives me precisely the same result.


Antony.

--
The Magic Words are Squeamish Ossifrage.

                                                   Please reply to the list;
                                                         please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

This e-mail message and all attachments transmitted with it are intended solely for the use of the addressee and may contain legally privileged and confidential information. If the reader of this message is not the intended recipient, or an employee or agent responsible for delivering this message to the intended recipient, you are hereby notified that any dissemination, distribution, copying, or other use of this message or its attachments is strictly prohibited. If you have received this message in error, please notify the sender immediately by replying to this message and please delete it from your computer.

From yvoinov at gmail.com  Mon Oct 24 11:05:32 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 24 Oct 2016 17:05:32 +0600
Subject: [squid-users] Squid with ASR9001
In-Reply-To: <HE1PR01MB12104763BDD60B87220FB257F6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
References: <HE1PR01MB12108D2D44BA6ACBC6E75EF5F6D60@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <62d2a63b-b5db-40f9-445f-1087a4fc5850@gmail.com>
 <HE1PR01MB1210B9F41867169E17A0A2DAF6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <613eff0c-4cb9-75ea-e7f2-b4bccd95ce74@gmail.com>
 <HE1PR01MB12104763BDD60B87220FB257F6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
Message-ID: <c4f64d19-91a1-91f3-bc39-fc72d5501b18@gmail.com>

Ha, it seems ASR9000 really does not support WCCP exactly. You right.

WCCP supported on Nexus, on ASR1000... So, your router only can use PBR 
or analoquie.

The only idea is to buy 3750 as aggregation switch, config WCCP on it 
and connect to your ASR by fiber trunk.

24.10.2016 16:30, Garth van Sittert | BitCo ?????:
>
> By Cisco employee - ?Correct, there is no WCCP and no plans for it 
> either... :(?
>
> https://supportforums.cisco.com/discussion/12227051/ios-xr-and-wccp
>
> WCCP supported platforms ?
>
> https://supportforums.cisco.com/document/133201/wccp-platform-support-overview
>
> Our ASR9001 has no commands that support wccp anywhere?
>
> http://www.loveburd.com/bitco/bitco-email-logo.jpg
>
> Garth van Sittert | Chief Executive Officer
> /(BSC Physics & Computer Science)/
> Tel: 087 135 0000 Ext: 201
> garth at bitco.co.za <mailto:garth at bitco.co.za>
> bitco.co.za <http://www.bitco.co.za/>
>
> *From:*Yuri [mailto:yvoinov at gmail.com]
> *Sent:* Monday, 24 October 2016 12:12 PM
> *To:* Garth van Sittert | BitCo <garth at bitco.co.za>; 
> squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Squid with ASR9001
>
> 24.10.2016 13:16, Garth van Sittert | BitCo ?????:
>
>     Yes, it looks like all of the ASR9000 range which makes use of IOS
>     XR no longer supports WCCP.
>
> Please, provide prooflink from Cisco.
>
>     Policy Based Routing has been replaced by ACL Based Forwarding or ABF.
>
> So? This is therminology difference, if any.
>
>     *From:*squid-users
>     [mailto:squid-users-bounces at lists.squid-cache.org] *On Behalf Of
>     *Yuri Voinov
>     *Sent:* Sunday, 23 October 2016 9:35 PM
>     *To:* squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     *Subject:* Re: [squid-users] Squid with ASR9001
>
>
>     -----BEGIN PGP SIGNED MESSAGE-----
>     Hash: SHA256
>
>
>
>     23.10.2016 23:16, Garth van Sittert | BitCo ?????:
>     >
>
>
>           > Good day all
>
>
>           >
>
>
>           >
>
>
>           >
>
>
>           > Has anyone had any experience setting up Squid with any IOS
>
>           XR Cisco routers?  The Cisco ASR9000 range doesn?t support WCCP
>
>           and I cannot find any examples online.
>
>
>           >
>     Seriously, the entire range?
>
>     Who said that it does not support WCCP? It is obligation to
>     support, if only because it is not a home dish soap. That's when
>     Cisco write the documentation that does not support - and then we cry.
>     >
>
>
>           >
>
>
>           >
>
>
>           > I have also found quotes regarding PBR on the ASR9000? ?With
>
>           IOS XR traditional policy-based routing (PBR) is history?
>
>
>           >
>     It's crazy city a forum talking about? PBR - is a fundamental
>     functionality for the router. Especially for the router at this
>     level. I somehow difficult to imagine a company that completely
>     cuts down the business by releasing incompatible with what device.
>     This is only possible in the OpenSource. But not in huge
>     IT-business company. AFAIK.
>     >
>
>
>           >
>
>
>           >
>
>
>           > I plan to use this on our 10Gbps ISP traffic to improve
>
>           customer experience?
>
>
>           >
>     There is no examples because the solutions of such a level rarely
>     use Squid. Personally, I do not have a machine to play and write
>     an example to Squid's wiki. As you know, Christmas is not the wife
>     of a router is present as trinkets.
>     >
>
>
>           >
>
>
>           >
>
>
>           > Garth
>
>
>           >
>
>
>           >
>
>
>           >
>
>
>           >
>
>
>           >
>
>
>           > BitCo Email Footer
>
>     <https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=!3m1!4b1!4m5!3m4!1s0x142989bce6c63b3:0xc0b44878907297f4!8m2!3d-26.04982!4d28.0218801>
>     <https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b44878907297f4%218m2%213d-26.04982%214d28.0218801>
>
>
>           > The information contained in this message is intended solely
>
>           for the individual to whom it is specifically and originally
>
>           addressed. This message and its contents may contain
>     confidential
>
>           or privileged information from BitCo. If you are not the
>     intended
>
>           recipient, you are hereby notified that any disclosure or
>
>           distribution, is strictly prohibited. If you receive this
>     email in
>
>           error, please notify BitCo immediately and delete it. BitCo does
>
>           not accept any liability or responsibility if action is taken in
>
>           reliance on the contents of this information.
>
>
>           >
>
>
>           >
>
>
>           > _______________________________________________
>
>
>           > squid-users mailing list
>
>
>           > squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>
>
>           > http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>
>
>     -----BEGIN PGP SIGNATURE-----
>     Version: GnuPG v2
>
>     iQEbBAEBCAAGBQJYDRDSAAoJENNXIZxhPexG7roH90gh9VtKKk4g7WKscldhl5ki
>     tjs5d46Wl6uIWOI0XyK7+94wKGV2oE4cAnoTqmDesxe058r8H67djDJvehIW9s1Q
>     zjd3DI4Th8QXEzMn5LnxqVSYz3WmANV5Jf/UsUQsUzPzgW2VHOpA8YfLPfEgbvhZ
>     zeJRG0gMg5fgyFlt90pK1p0v6sAOEB2leigxiWBXI27BEDajBnnSfbqeMvqanDgI
>     9Cwh1itpkukDNeU7e/e9y1sHLAJrJ8Z0V7ag2iqYb4KJv/SqkcCAsjX1aSv3VpDE
>     M4OvE+2tRT3v8ud4gIQroQmWrbNKCaBFgKI1tM82ojErj6FgTmv/5FjxHGq1Cw==
>     =YLEX
>     -----END PGP SIGNATURE-----
>
>     BitCo Email Footer
>     <https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b44878907297f4%218m2%213d-26.04982%214d28.0218801>
>
>     The information contained in this message is intended solely for
>     the individual to whom it is specifically and originally
>     addressed. This message and its contents may contain confidential
>     or privileged information from BitCo. If you are not the intended
>     recipient, you are hereby notified that any disclosure or
>     distribution, is strictly prohibited. If you receive this email in
>     error, please notify BitCo immediately and delete it. BitCo does
>     not accept any liability or responsibility if action is taken in
>     reliance on the contents of this information.
>
> BitCo Email Footer 
> <https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b44878907297f4%218m2%213d-26.04982%214d28.0218801>
> The information contained in this message is intended solely for the 
> individual to whom it is specifically and originally addressed. This 
> message and its contents may contain confidential or privileged 
> information from BitCo. If you are not the intended recipient, you are 
> hereby notified that any disclosure or distribution, is strictly 
> prohibited. If you receive this email in error, please notify BitCo 
> immediately and delete it. BitCo does not accept any liability or 
> responsibility if action is taken in reliance on the contents of this 
> information.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/2e24cfc6/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: image/jpeg
Size: 6213 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/2e24cfc6/attachment.jpe>

From augustus_meyer at gmx.net  Mon Oct 24 11:01:29 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Mon, 24 Oct 2016 04:01:29 -0700 (PDT)
Subject: [squid-users] external_acl_type problem
In-Reply-To: <c49ff38c-4ad5-f71e-8389-f4810e2258c5@treenet.co.nz>
References: <1477219171447-4680203.post@n4.nabble.com>
 <c49ff38c-4ad5-f71e-8389-f4810e2258c5@treenet.co.nz>
Message-ID: <1477306889688-4680247.post@n4.nabble.com>

>But the startup should be 0 in all Squid-3.2+ like you say. Are you
applying any patches to external_acl.cc or helper/ChildConfig.cc ? <

No patches. 
Now I rebuilt squid on a 32-bit debian, with default ./configure opts.
Same effect:
2016/10/24 09:54:09 kid1| helperOpenServers: Starting 5/5 'check_delay.sh'
processes

having this in squid.conf:

external_acl_type check_delay ttl=0 cache=0 %SRC /etc/squid/check_delay.sh



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/external-acl-type-problem-tp4680203p4680247.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From garryd at comnet.uz  Mon Oct 24 11:32:06 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Mon, 24 Oct 2016 16:32:06 +0500
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <bccae1dd-596c-7797-79d0-fb5fdee7297f@treenet.co.nz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
 <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
 <578241c68e8e1238519585b8b1fc0151@comnet.uz>
 <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>
 <1477299550.5002.35.camel@comnet.uz>
 <bccae1dd-596c-7797-79d0-fb5fdee7297f@treenet.co.nz>
Message-ID: <1477308726.5002.47.camel@comnet.uz>

On Mon, 2016-10-24 at 23:51 +1300, Amos Jeffries wrote:
> On 24/10/2016 9:59 p.m., Garri Djavadyan wrote:
> > Nevertheless, the topic surfaced new details regarding the Vary and
> > I
> > tried conditional requests on same URL (Google Chrome) from
> > different
> > machines/IPs. Here results:
> > 
> > $ curl --head --header "If-Modified-Since: Thu, 22 Oct 2016
> > 08:29:09
> > GMT" https://dl.google.com/linux/direct/google-chrome-stable_curren
> > t_am
> > d64.deb
> > HTTP/1.1 304 Not Modified
> > Etag: "101395"
> > Server: downloads
> > Vary: *
> > X-Content-Type-Options: nosniff
> > X-Frame-Options: SAMEORIGIN
> > X-Xss-Protection: 1; mode=block
> > Date: Mon, 24 Oct 2016 08:53:44 GMT
> > Alt-Svc: quic=":443"; ma=2592000; v="36,35,34"
> > 
> > ----
> > 
> > $ curl --head --header 'If-None-Match: "101395"' https://dl.google.
> > com/
> > linux/direct/google-chrome-stable_current_amd64.deb?
> > HTTP/1.1 304 Not Modified
> > Etag: "101395"
> > Last-Modified: Thu, 20 Oct 2016 08:29:09 GMT
> > Server: downloads
> > Vary: *
> > X-Content-Type-Options: nosniff
> > X-Frame-Options: SAMEORIGIN
> > X-Xss-Protection: 1; mode=block
> > Date: Mon, 24 Oct 2016 08:54:18 GMT
> > Alt-Svc: quic=":443"; ma=2592000; v="36,35,34"
> > 
> 
> Sweet! Far better than I was expecting. That means this patch should
> work:
> 
> === modified file 'src/http.cc'
> --- src/http.cc 2016-10-08 22:19:44 +0000
> +++ src/http.cc 2016-10-24 10:50:16 +0000
> @@ -593,7 +593,7 @@
> ?????while (strListGetItem(&vary, ',', &item, &ilen, &pos)) {
> ?????????SBuf name(item, ilen);
> ?????????if (name == asterisk) {
> -????????????vstr.clear();
> +????????????vstr = asterisk;
> ?????????????break;
> ?????????}
> ?????????name.toLower();
> @@ -947,6 +947,12 @@
> ?????????????varyFailure = true;
> ?????????} else {
> ?????????????entry->mem_obj->vary_headers = vary;
> +
> +????????????// RFC 7231 section 7.1.4
> +????????????// Vary:* can be cached, but has mandatory revalidation
> +????????????static const SBuf asterisk("*");
> +????????????if (vary == asterisk)
> +????????????????EBIT_SET(entry->flags, ENTRY_REVALIDATE_ALWAYS);
> ?????????}
> ?????}
> 
> 
> Amos

I have applied the patch. Below my results.

In access.log I see:

1477307991.672??49890 127.0.0.1 TCP_REFRESH_MODIFIED/200 45532786 GET h
ttp://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
 - HIER_DIRECT/173.194.222.136 application/x-debian-package

In packet capture, I see that Squid doesn't use conditional request:

GET /linux/direct/google-chrome-stable_current_amd64.deb HTTP/1.1
User-Agent: curl/7.50.3
Accept: */*
Host: dl.google.com
Via: 1.1 gentoo.comnet.uz (squid/3.5.22)
X-Forwarded-For: 127.0.0.1
Cache-Control: max-age=259200
Connection: keep-alive

Garri


From squid3 at treenet.co.nz  Mon Oct 24 12:14:29 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 25 Oct 2016 01:14:29 +1300
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <8aa13ca6-4ff0-d548-3be6-447b90c16043@gmail.com>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
 <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
 <578241c68e8e1238519585b8b1fc0151@comnet.uz>
 <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>
 <4284d81f-5edd-203e-5927-cfa0a0ec4b0d@gmail.com>
 <d9527fe0-f14d-e1b4-3891-f87af5ed088b@integrafin.co.uk>
 <8aa13ca6-4ff0-d548-3be6-447b90c16043@gmail.com>
Message-ID: <b5fe80bc-078f-2049-40c3-4724a79d34e5@treenet.co.nz>

On 24/10/2016 11:49 p.m., Yuri wrote:
> 
> 
> 24.10.2016 16:42, Alex Crow ?????:
>> On 24/10/16 11:26, Yuri wrote:
>>
>>> No, Amos, I'm not trolling your or another developers.
>>>
>>> I just really do not understand why there is a caching proxy, which
>>> is almost nothing can cache in the modern world. And that in vanilla
>>> version gives a maximum of 10-30% byte hit. From me personally, it
>>> needs no justification and no explanation. And the results.
>>>
>>> I can not explain to management why no result, referring to your
>>> explanations or descriptions of standards. I think it's understandable.
>>>
>>> At the present time to obtain any acceptable result it is necessary
>>> to make a hell of a lot of effort. To maintenance such installation
>>> is not easy.
>>>
>>> And as with every new version of the caching level it falls - and it
>>> is very easy to check - it is very difficult to explain to
>>> management, is not it?
>>>
>>> It's not my imagination - this is confirmed by dozens of Squid
>>> administrators, including me personally familiar. Therefore, I would
>>> heed to claim that I lie or deliberately introduce someone else astray.
>>>
>>
>> I'd rather have to explain to management about a low hitrate than have
>> to explain why they weren't seeing the content they expected to see,
>> or that some vital transaction did not go through, but, hey look here,
>> we're saving 80% of web traffic bill!
> So, what are you talking about - the smallest of the problems that can
> be easily testing and solving by existing functionality - such as no_cache.
> 
> In any case - it is the choice of each and I only wish to have all
> possible tools. And not to have my hands tied.

Squid is moving to HTTP/1.1 specifications. It no longer does some
things the HTTP/1.0-ish way.

I keep mentioning over and over again:  the controls you keep asking for
are only needed by the HTTP/1.0 behaviours ... to make the HTTP/1.0
proxy operate more like HTTP/1.1 !! But not quite identical to a 1.1
proxy/cache because it adds traffic problems that the true 1.1
proxy/cache does not allow to happen.

Squid is being converted to HTTP/1.1 native behaviour. The controls no
longer are needed in the bits that have been converted, the current
releases do *better* than what you are asking for when faced with
Cache-Control:no-cache, private etc. which have been converted already.

Having controls to force the old 1990's behaviour on todays Internet
traffic only leads to old bugs and problems being forced on clients. The
gains you got from those controls on HTTP/1.0 traffic are now just
happening naturally with HTTP/1.1 - no knobs need turning on/off for it
to happen.

So the old settings are going away (replaced). If the new behaviour
needs new settings that is something to discover as Squid improves.
Evidence so far is that there are few needed, but that could change.


So lets put it this way:
 You started with a proxy that could do X and be forced to also do a Y
and a Z thing.
 You then upgraded to a proxy that did X and Y, and be forced to do a Z
thing.
 So you complain that you can no longer force the new proxy to do Y thing.

Makes no sense to me unless I assume you are confused by the way the
forced-Y looks different to the real Y - though both are almost the same
thing. The difference being how real-Y fixed some nasty bugs caused by
forced-Y.


> 
> Especially when there are competing products that provide the desired
> results. Yes, they cost money. But management is not often ask - just
> buy what they need, by they opinion, and you - with Squid - went to look
> for a job. So simple.
> 

There will always be other products that do part of what Squid does
along with other things Squid does not. Just like Squid does part of
what they do and other things they do not.

Causing a product installation to produce corrupted traffic responses
does not help with that products reputation compared to 'the
competition' - no matter whether its Squid or something else. Whereas
reliable and accurate data transfer integrity is a cornerstone for good
reputation in any caching or networking product.

Amos



From squid3 at treenet.co.nz  Mon Oct 24 12:22:30 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 25 Oct 2016 01:22:30 +1300
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <1477308726.5002.47.camel@comnet.uz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
 <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
 <578241c68e8e1238519585b8b1fc0151@comnet.uz>
 <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>
 <1477299550.5002.35.camel@comnet.uz>
 <bccae1dd-596c-7797-79d0-fb5fdee7297f@treenet.co.nz>
 <1477308726.5002.47.camel@comnet.uz>
Message-ID: <86f78bf4-28ee-4f6a-b855-90a87d86a673@treenet.co.nz>

On 25/10/2016 12:32 a.m., Garri Djavadyan wrote:
> On Mon, 2016-10-24 at 23:51 +1300, Amos Jeffries wrote:
>> On 24/10/2016 9:59 p.m., Garri Djavadyan wrote:
>>> Nevertheless, the topic surfaced new details regarding the Vary and
>>> I
>>> tried conditional requests on same URL (Google Chrome) from
>>> different
>>> machines/IPs. Here results:
>>>
>>> $ curl --head --header "If-Modified-Since: Thu, 22 Oct 2016
>>> 08:29:09
>>> GMT" https://dl.google.com/linux/direct/google-chrome-stable_curren
>>> t_am
>>> d64.deb
>>> HTTP/1.1 304 Not Modified
>>> Etag: "101395"
>>> Server: downloads
>>> Vary: *
>>> X-Content-Type-Options: nosniff
>>> X-Frame-Options: SAMEORIGIN
>>> X-Xss-Protection: 1; mode=block
>>> Date: Mon, 24 Oct 2016 08:53:44 GMT
>>> Alt-Svc: quic=":443"; ma=2592000; v="36,35,34"
>>>
>>> ----
>>>
>>> $ curl --head --header 'If-None-Match: "101395"' https://dl.google.
>>> com/
>>> linux/direct/google-chrome-stable_current_amd64.deb 
>>> HTTP/1.1 304 Not Modified
>>> Etag: "101395"
>>> Last-Modified: Thu, 20 Oct 2016 08:29:09 GMT
>>> Server: downloads
>>> Vary: *
>>> X-Content-Type-Options: nosniff
>>> X-Frame-Options: SAMEORIGIN
>>> X-Xss-Protection: 1; mode=block
>>> Date: Mon, 24 Oct 2016 08:54:18 GMT
>>> Alt-Svc: quic=":443"; ma=2592000; v="36,35,34"
>>>
>>
>> Sweet! Far better than I was expecting. That means this patch should
>> work:
>>
>> === modified file 'src/http.cc'
>> --- src/http.cc 2016-10-08 22:19:44 +0000
>> +++ src/http.cc 2016-10-24 10:50:16 +0000
>> @@ -593,7 +593,7 @@
>>      while (strListGetItem(&vary, ',', &item, &ilen, &pos)) {
>>          SBuf name(item, ilen);
>>          if (name == asterisk) {
>> -            vstr.clear();
>> +            vstr = asterisk;
>>              break;
>>          }
>>          name.toLower();
>> @@ -947,6 +947,12 @@
>>              varyFailure = true;
>>          } else {
>>              entry->mem_obj->vary_headers = vary;
>> +
>> +            // RFC 7231 section 7.1.4
>> +            // Vary:* can be cached, but has mandatory revalidation
>> +            static const SBuf asterisk("*");
>> +            if (vary == asterisk)
>> +                EBIT_SET(entry->flags, ENTRY_REVALIDATE_ALWAYS);
>>          }
>>      }
>>
>>
>> Amos
> 
> I have applied the patch. Below my results.
> 
> In access.log I see:
> 
> 1477307991.672  49890 127.0.0.1 TCP_REFRESH_MODIFIED/200 45532786 GET h
> ttp://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
>  - HIER_DIRECT/173.194.222.136 application/x-debian-package
> 
> In packet capture, I see that Squid doesn't use conditional request:
> 
> GET /linux/direct/google-chrome-stable_current_amd64.deb HTTP/1.1
> User-Agent: curl/7.50.3
> Accept: */*
> Host: dl.google.com
> Via: 1.1 gentoo.comnet.uz (squid/3.5.22)
> X-Forwarded-For: 127.0.0.1
> Cache-Control: max-age=259200
> Connection: keep-alive

Hmmm. That looks to me like the new patch is working (log says REFRESH
being done) but there is some bug in the revalidate logic not adding the
required headers.
 If thats right, then that bug might be causing other revalidate traffic
to have major /200 issues.

I'm in need of sleep right now. If you can grab a ALL,9 cache.log trace
and mail it to me I will take a look in the morning. Otherwise I will
try to replicate the case myself and track it down in the next few days.

Amos


From squid3 at treenet.co.nz  Mon Oct 24 12:32:43 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 25 Oct 2016 01:32:43 +1300
Subject: [squid-users] ERROR: Cannot connect to 127.0.0.1:3128
In-Reply-To: <9377811477298094@web29g.yandex.ru>
References: <294681476158099@web11o.yandex.ru>
 <e663dbd7-b739-ecb9-3598-c649c2b97fcf@treenet.co.nz>
 <6306491476324921@web24g.yandex.ru>
 <41207f59-32a5-0d29-1b62-95c5061ae21b@treenet.co.nz>
 <3067671476442285@web6h.yandex.ru> <9377811477298094@web29g.yandex.ru>
Message-ID: <50a63c13-f313-b7b2-e664-3bdb6f2cc26a@treenet.co.nz>

On 24/10/2016 9:34 p.m., ?????? wrote:
> Hi!
> Could you write me if you had managed to emulate the problem that I have?
> Best regards, Misha.

I have not been able to replicate it here. I think I remember seeing it
a few years back, but not recently and trying last week my Squid worked
okay.

I was suspicious that the ::1 was being resolved. But your -vv output
shows it is finding 127.0.0.1 just fine. Something in the proxy is
denying the transaction, but your config looks like it should be allowed
through without any problem.


As a wild guess; try commenting out the ::1 entry in your /etc/hosts
file. Squid loads that file into its internal DNS cache and maybe the
entry is causing an issue on the Squid side of things.

Amos



From garryd at comnet.uz  Mon Oct 24 14:40:07 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Mon, 24 Oct 2016 19:40:07 +0500
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <86f78bf4-28ee-4f6a-b855-90a87d86a673@treenet.co.nz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
 <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
 <578241c68e8e1238519585b8b1fc0151@comnet.uz>
 <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>
 <1477299550.5002.35.camel@comnet.uz>
 <bccae1dd-596c-7797-79d0-fb5fdee7297f@treenet.co.nz>
 <1477308726.5002.47.camel@comnet.uz>
 <86f78bf4-28ee-4f6a-b855-90a87d86a673@treenet.co.nz>
Message-ID: <1477320007.5002.67.camel@comnet.uz>

On Tue, 2016-10-25 at 01:22 +1300, Amos Jeffries wrote:
> On 25/10/2016 12:32 a.m., Garri Djavadyan wrote:
> > 
> > On Mon, 2016-10-24 at 23:51 +1300, Amos Jeffries wrote:
> > > 
> > > On 24/10/2016 9:59 p.m., Garri Djavadyan wrote:
> > > > 
> > > > Nevertheless, the topic surfaced new details regarding the Vary
> > > > and
> > > > I
> > > > tried conditional requests on same URL (Google Chrome) from
> > > > different
> > > > machines/IPs. Here results:
> > > > 
> > > > $ curl --head --header "If-Modified-Since: Thu, 22 Oct 2016
> > > > 08:29:09
> > > > GMT" https://dl.google.com/linux/direct/google-chrome-stable_cu
> > > > rren
> > > > t_am
> > > > d64.deb
> > > > HTTP/1.1 304 Not Modified
> > > > Etag: "101395"
> > > > Server: downloads
> > > > Vary: *
> > > > X-Content-Type-Options: nosniff
> > > > X-Frame-Options: SAMEORIGIN
> > > > X-Xss-Protection: 1; mode=block
> > > > Date: Mon, 24 Oct 2016 08:53:44 GMT
> > > > Alt-Svc: quic=":443"; ma=2592000; v="36,35,34"
> > > > 
> > > > ----
> > > > 
> > > > $ curl --head --header 'If-None-Match: "101395"' https://dl.goo
> > > > gle.
> > > > com/
> > > > linux/direct/google-chrome-stable_current_amd64.deb?
> > > > HTTP/1.1 304 Not Modified
> > > > Etag: "101395"
> > > > Last-Modified: Thu, 20 Oct 2016 08:29:09 GMT
> > > > Server: downloads
> > > > Vary: *
> > > > X-Content-Type-Options: nosniff
> > > > X-Frame-Options: SAMEORIGIN
> > > > X-Xss-Protection: 1; mode=block
> > > > Date: Mon, 24 Oct 2016 08:54:18 GMT
> > > > Alt-Svc: quic=":443"; ma=2592000; v="36,35,34"
> > > > 
> > > 
> > > Sweet! Far better than I was expecting. That means this patch
> > > should
> > > work:
> > > 
> > > === modified file 'src/http.cc'
> > > --- src/http.cc 2016-10-08 22:19:44 +0000
> > > +++ src/http.cc 2016-10-24 10:50:16 +0000
> > > @@ -593,7 +593,7 @@
> > > ?????while (strListGetItem(&vary, ',', &item, &ilen, &pos)) {
> > > ?????????SBuf name(item, ilen);
> > > ?????????if (name == asterisk) {
> > > -????????????vstr.clear();
> > > +????????????vstr = asterisk;
> > > ?????????????break;
> > > ?????????}
> > > ?????????name.toLower();
> > > @@ -947,6 +947,12 @@
> > > ?????????????varyFailure = true;
> > > ?????????} else {
> > > ?????????????entry->mem_obj->vary_headers = vary;
> > > +
> > > +????????????// RFC 7231 section 7.1.4
> > > +????????????// Vary:* can be cached, but has mandatory
> > > revalidation
> > > +????????????static const SBuf asterisk("*");
> > > +????????????if (vary == asterisk)
> > > +????????????????EBIT_SET(entry->flags, ENTRY_REVALIDATE_ALWAYS);
> > > ?????????}
> > > ?????}
> > > 
> > > 
> > > Amos
> > 
> > I have applied the patch. Below my results.
> > 
> > In access.log I see:
> > 
> > 1477307991.672??49890 127.0.0.1 TCP_REFRESH_MODIFIED/200 45532786
> > GET h
> > ttp://dl.google.com/linux/direct/google-chrome-
> > stable_current_amd64.deb
> > ?- HIER_DIRECT/173.194.222.136 application/x-debian-package
> > 
> > In packet capture, I see that Squid doesn't use conditional
> > request:
> > 
> > GET /linux/direct/google-chrome-stable_current_amd64.deb HTTP/1.1
> > User-Agent: curl/7.50.3
> > Accept: */*
> > Host: dl.google.com
> > Via: 1.1 gentoo.comnet.uz (squid/3.5.22)
> > X-Forwarded-For: 127.0.0.1
> > Cache-Control: max-age=259200
> > Connection: keep-alive
> 
> Hmmm. That looks to me like the new patch is working (log says
> REFRESH
> being done) but there is some bug in the revalidate logic not adding
> the
> required headers.
> ?If thats right, then that bug might be causing other revalidate
> traffic
> to have major /200 issues.
> 
> I'm in need of sleep right now. If you can grab a ALL,9 cache.log
> trace
> and mail it to me I will take a look in the morning. Otherwise I will
> try to replicate the case myself and track it down in the next few
> days.
> 
> Amos

Sorry, I probably analysed the header of first request. I tried again,
and found that Squid sends the header correctly:

GET /linux/direct/google-chrome-stable_current_amd64.deb HTTP/1.1
If-Modified-Since: Thu, 20 Oct 2016 08:29:09 GMT
If-None-Match: "101395"
User-Agent: curl/7.50.3
Accept: */*
Host: dl.google.com
Via: 1.1 gentoo.comnet.uz (squid/3.5.22)
X-Forwarded-For: 127.0.0.1
Cache-Control: max-age=259200
Connection: keep-alive


Sad enough, the reply is:

HTTP/1.1 200 OK
Accept-Ranges: bytes
Content-Type: application/x-debian-package
ETag: "101395"
Last-Modified: Thu, 20 Oct 2016 08:29:09 GMT
Server: downloads
Vary: *
X-Content-Type-Options: nosniff
X-Frame-Options: SAMEORIGIN
X-Xss-Protection: 1; mode=block
Date: Mon, 24 Oct 2016 13:41:13 GMT
Content-Length: 45532350
Connection: keep-alive


So, the big G sends 304 only to HEAD requests, although it is a
violation [1], AIUI:

curl --head -H 'If-Modified-Since: Thu, 20 Oct 2016 08:29:09 GMT' -H
'If-None-Match: "101395"' http://dl.google.com/linux/direct/google-chro
me-stable_current_amd64.deb
HTTP/1.1 304 Not Modified
ETag: "101395"
Server: downloads
Vary: *
X-Content-Type-Options: nosniff
X-Frame-Options: SAMEORIGIN
X-Xss-Protection: 1; mode=block
Date: Mon, 24 Oct 2016 14:36:32 GMT
Connection: keep-alive

---

$ curl --verbose -H 'If-Modified-Since: Thu, 20 Oct 2016 08:29:09 GMT'
-H 'If-None-Match: "101395"' http://dl.google.com/linux/direct/google-c
hrome-stable_current_amd64.deb > /dev/null
> GET /linux/direct/google-chrome-stable_current_amd64.deb HTTP/1.1
> Host: dl.google.com
> User-Agent: curl/7.50.3
> Accept: */*
> If-Modified-Since: Thu, 20 Oct 2016 08:29:09 GMT
> If-None-Match: "101395"
>?
< HTTP/1.1 200 OK
< Accept-Ranges: bytes
< Content-Type: application/x-debian-package
< ETag: "101395"
< Last-Modified: Thu, 20 Oct 2016 08:29:09 GMT
< Server: downloads
< Vary: *
< X-Content-Type-Options: nosniff
< X-Frame-Options: SAMEORIGIN
< X-Xss-Protection: 1; mode=block
< Date: Mon, 24 Oct 2016 14:38:19 GMT
< Content-Length: 45532350
< Connection: keep-alive

[1]?https://tools.ietf.org/html/rfc7234#section-4.3.5

Garri


From yvoinov at gmail.com  Mon Oct 24 15:19:56 2016
From: yvoinov at gmail.com (Yuri)
Date: Mon, 24 Oct 2016 21:19:56 +0600
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <1477320007.5002.67.camel@comnet.uz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
 <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
 <578241c68e8e1238519585b8b1fc0151@comnet.uz>
 <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>
 <1477299550.5002.35.camel@comnet.uz>
 <bccae1dd-596c-7797-79d0-fb5fdee7297f@treenet.co.nz>
 <1477308726.5002.47.camel@comnet.uz>
 <86f78bf4-28ee-4f6a-b855-90a87d86a673@treenet.co.nz>
 <1477320007.5002.67.camel@comnet.uz>
Message-ID: <4a56b8a8-8931-60ff-8fdd-6c5c35ed6595@gmail.com>

I'm sorry to interrupt - I remember someone saying that you need to 
always abide by RFC? Well, as you say it to Google?


24.10.2016 20:40, Garri Djavadyan ?????:
> On Tue, 2016-10-25 at 01:22 +1300, Amos Jeffries wrote:
>> On 25/10/2016 12:32 a.m., Garri Djavadyan wrote:
>>> On Mon, 2016-10-24 at 23:51 +1300, Amos Jeffries wrote:
>>>> On 24/10/2016 9:59 p.m., Garri Djavadyan wrote:
>>>>> Nevertheless, the topic surfaced new details regarding the Vary
>>>>> and
>>>>> I
>>>>> tried conditional requests on same URL (Google Chrome) from
>>>>> different
>>>>> machines/IPs. Here results:
>>>>>
>>>>> $ curl --head --header "If-Modified-Since: Thu, 22 Oct 2016
>>>>> 08:29:09
>>>>> GMT" https://dl.google.com/linux/direct/google-chrome-stable_cu
>>>>> rren
>>>>> t_am
>>>>> d64.deb
>>>>> HTTP/1.1 304 Not Modified
>>>>> Etag: "101395"
>>>>> Server: downloads
>>>>> Vary: *
>>>>> X-Content-Type-Options: nosniff
>>>>> X-Frame-Options: SAMEORIGIN
>>>>> X-Xss-Protection: 1; mode=block
>>>>> Date: Mon, 24 Oct 2016 08:53:44 GMT
>>>>> Alt-Svc: quic=":443"; ma=2592000; v="36,35,34"
>>>>>
>>>>> ----
>>>>>
>>>>> $ curl --head --header 'If-None-Match: "101395"' https://dl.goo
>>>>> gle.
>>>>> com/
>>>>> linux/direct/google-chrome-stable_current_amd64.deb
>>>>> HTTP/1.1 304 Not Modified
>>>>> Etag: "101395"
>>>>> Last-Modified: Thu, 20 Oct 2016 08:29:09 GMT
>>>>> Server: downloads
>>>>> Vary: *
>>>>> X-Content-Type-Options: nosniff
>>>>> X-Frame-Options: SAMEORIGIN
>>>>> X-Xss-Protection: 1; mode=block
>>>>> Date: Mon, 24 Oct 2016 08:54:18 GMT
>>>>> Alt-Svc: quic=":443"; ma=2592000; v="36,35,34"
>>>>>
>>>> Sweet! Far better than I was expecting. That means this patch
>>>> should
>>>> work:
>>>>
>>>> === modified file 'src/http.cc'
>>>> --- src/http.cc 2016-10-08 22:19:44 +0000
>>>> +++ src/http.cc 2016-10-24 10:50:16 +0000
>>>> @@ -593,7 +593,7 @@
>>>>       while (strListGetItem(&vary, ',', &item, &ilen, &pos)) {
>>>>           SBuf name(item, ilen);
>>>>           if (name == asterisk) {
>>>> -            vstr.clear();
>>>> +            vstr = asterisk;
>>>>               break;
>>>>           }
>>>>           name.toLower();
>>>> @@ -947,6 +947,12 @@
>>>>               varyFailure = true;
>>>>           } else {
>>>>               entry->mem_obj->vary_headers = vary;
>>>> +
>>>> +            // RFC 7231 section 7.1.4
>>>> +            // Vary:* can be cached, but has mandatory
>>>> revalidation
>>>> +            static const SBuf asterisk("*");
>>>> +            if (vary == asterisk)
>>>> +                EBIT_SET(entry->flags, ENTRY_REVALIDATE_ALWAYS);
>>>>           }
>>>>       }
>>>>
>>>>
>>>> Amos
>>> I have applied the patch. Below my results.
>>>
>>> In access.log I see:
>>>
>>> 1477307991.672  49890 127.0.0.1 TCP_REFRESH_MODIFIED/200 45532786
>>> GET h
>>> ttp://dl.google.com/linux/direct/google-chrome-
>>> stable_current_amd64.deb
>>>   - HIER_DIRECT/173.194.222.136 application/x-debian-package
>>>
>>> In packet capture, I see that Squid doesn't use conditional
>>> request:
>>>
>>> GET /linux/direct/google-chrome-stable_current_amd64.deb HTTP/1.1
>>> User-Agent: curl/7.50.3
>>> Accept: */*
>>> Host: dl.google.com
>>> Via: 1.1 gentoo.comnet.uz (squid/3.5.22)
>>> X-Forwarded-For: 127.0.0.1
>>> Cache-Control: max-age=259200
>>> Connection: keep-alive
>> Hmmm. That looks to me like the new patch is working (log says
>> REFRESH
>> being done) but there is some bug in the revalidate logic not adding
>> the
>> required headers.
>>   If thats right, then that bug might be causing other revalidate
>> traffic
>> to have major /200 issues.
>>
>> I'm in need of sleep right now. If you can grab a ALL,9 cache.log
>> trace
>> and mail it to me I will take a look in the morning. Otherwise I will
>> try to replicate the case myself and track it down in the next few
>> days.
>>
>> Amos
> Sorry, I probably analysed the header of first request. I tried again,
> and found that Squid sends the header correctly:
>
> GET /linux/direct/google-chrome-stable_current_amd64.deb HTTP/1.1
> If-Modified-Since: Thu, 20 Oct 2016 08:29:09 GMT
> If-None-Match: "101395"
> User-Agent: curl/7.50.3
> Accept: */*
> Host: dl.google.com
> Via: 1.1 gentoo.comnet.uz (squid/3.5.22)
> X-Forwarded-For: 127.0.0.1
> Cache-Control: max-age=259200
> Connection: keep-alive
>
>
> Sad enough, the reply is:
>
> HTTP/1.1 200 OK
> Accept-Ranges: bytes
> Content-Type: application/x-debian-package
> ETag: "101395"
> Last-Modified: Thu, 20 Oct 2016 08:29:09 GMT
> Server: downloads
> Vary: *
> X-Content-Type-Options: nosniff
> X-Frame-Options: SAMEORIGIN
> X-Xss-Protection: 1; mode=block
> Date: Mon, 24 Oct 2016 13:41:13 GMT
> Content-Length: 45532350
> Connection: keep-alive
>
>
> So, the big G sends 304 only to HEAD requests, although it is a
> violation [1], AIUI:
>
> curl --head -H 'If-Modified-Since: Thu, 20 Oct 2016 08:29:09 GMT' -H
> 'If-None-Match: "101395"' http://dl.google.com/linux/direct/google-chro
> me-stable_current_amd64.deb
> HTTP/1.1 304 Not Modified
> ETag: "101395"
> Server: downloads
> Vary: *
> X-Content-Type-Options: nosniff
> X-Frame-Options: SAMEORIGIN
> X-Xss-Protection: 1; mode=block
> Date: Mon, 24 Oct 2016 14:36:32 GMT
> Connection: keep-alive
>
> ---
>
> $ curl --verbose -H 'If-Modified-Since: Thu, 20 Oct 2016 08:29:09 GMT'
> -H 'If-None-Match: "101395"' http://dl.google.com/linux/direct/google-c
> hrome-stable_current_amd64.deb > /dev/null
>> GET /linux/direct/google-chrome-stable_current_amd64.deb HTTP/1.1
>> Host: dl.google.com
>> User-Agent: curl/7.50.3
>> Accept: */*
>> If-Modified-Since: Thu, 20 Oct 2016 08:29:09 GMT
>> If-None-Match: "101395"
>>   
> < HTTP/1.1 200 OK
> < Accept-Ranges: bytes
> < Content-Type: application/x-debian-package
> < ETag: "101395"
> < Last-Modified: Thu, 20 Oct 2016 08:29:09 GMT
> < Server: downloads
> < Vary: *
> < X-Content-Type-Options: nosniff
> < X-Frame-Options: SAMEORIGIN
> < X-Xss-Protection: 1; mode=block
> < Date: Mon, 24 Oct 2016 14:38:19 GMT
> < Content-Length: 45532350
> < Connection: keep-alive
>
> [1] https://tools.ietf.org/html/rfc7234#section-4.3.5
>
> Garri
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From erdosain9 at gmail.com  Mon Oct 24 15:24:11 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 24 Oct 2016 08:24:11 -0700 (PDT)
Subject: [squid-users] Error "ipcacheParse: No Address records in response
	to"
Message-ID: <1477322651492-4680254.post@n4.nabble.com>

Hi.
The squid was working perfect... but, i need to change the router (for some
problems). So im using a Juniper Firewall like router... 
So, now i have this error

2016/10/24 12:13:27 kid1| WARNING: All 32/32 ssl_crtd processes are busy.
2016/10/24 12:13:27 kid1| WARNING: 32 pending requests queued
2016/10/24 12:13:27 kid1| WARNING: Consider increasing the number of
ssl_crtd processes in your config file.
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:27 kid1| Queue overload, rejecting
2016/10/24 12:13:36 kid1| ipcacheParse: No Address records in response to
'client.wns.windows.com'
2016/10/24 12:13:36 kid1| ipcacheParse: No Address records in response to
'client.wns.windows.com'
2016/10/24 12:13:36 kid1| ipcacheParse: No Address records in response to
'client.wns.windows.com'
2016/10/24 12:13:36 kid1| ipcacheParse: No Address records in response to
'skp03.epimg.net'
2016/10/24 12:13:36 kid1| ipcacheParse: No Address records in response to
'www.msftncsi.com'
2016/10/24 12:13:41 kid1| ipcacheParse: No Address records in response to
'client-s.gateway.messenger.live.com'
2016/10/24 12:13:41 kid1| ipcacheParse: No Address records in response to
'client-s.gateway.messenger.live.com'
2016/10/24 12:13:41 kid1| ipcacheParse: No Address records in response to
'client-s.gateway.messenger.live.com'
2016/10/24 12:13:54 kid1| Error negotiating SSL connection on FD 76: (104)
Connection reset by peer
2016/10/24 12:14:06 kid1| ipcacheParse: No Address records in response to
'www.posadadonantonio.com'
2016/10/24 12:14:06 kid1| ipcacheParse: No Address records in response to
'www.posadadonantonio.com'
2016/10/24 12:14:16 kid1| ipcacheParse: No Address records in response to
'www.msftncsi.com'
2016/10/24 12:14:31 kid1| ipcacheParse: No Address records in response to
'c.live.com'
2016/10/24 12:14:33 kid1| Error negotiating SSL connection on FD 35:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
2016/10/24 12:14:56 kid1| ipcacheParse: No Address records in response to
'outlook.live.com'
2016/10/24 12:14:56 kid1| ipcacheParse: No Address records in response to
'outlook.live.com'
2016/10/24 12:14:56 kid1| ipcacheParse: No Address records in response to
'outlook.live.com'
2016/10/24 12:14:56 kid1| ipcacheParse: No Address records in response to
'outlook.live.com'
2016/10/24 12:15:16 kid1| ipcacheParse: No Address records in response to
'ipv6.msftncsi.com'
2016/10/24 12:15:16 kid1| ipcacheParse: No Address records in response to
'ocsp.digicert.com'
2016/10/24 12:15:31 kid1| ipcacheParse: No Address records in response to
'outlook.live.com'
2016/10/24 12:15:31 kid1| ipcacheParse: No Address records in response to
'outlook.live.com'
2016/10/24 12:15:31 kid1| ipcacheParse: No Address records in response to
'outlook.live.com'
2016/10/24 12:15:31 kid1| ipcacheParse: No Address records in response to
'outlook.live.com'
2016/10/24 12:15:31 kid1| ipcacheParse: No Address records in response to
'outlook.live.com'
2016/10/24 12:15:31 kid1| ipcacheParse: No Address records in response to
'fravega.vteximg.com.br'
2016/10/24 12:15:36 kid1| ipcacheParse: No Address records in response to
'www.clarin.com'
2016/10/24 12:15:36 kid1| ipcacheParse: No Address records in response to
'www.clarin.com'


What can i do??? by the way sometimes google.com answer with a
ipv6........... and squid, do not know what to do with that.....

Thanks!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Error-ipcacheParse-No-Address-records-in-response-to-tp4680254.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Mon Oct 24 15:48:28 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 24 Oct 2016 08:48:28 -0700 (PDT)
Subject: [squid-users] Error "ipcacheParse: No Address records in
	response to"
In-Reply-To: <1477322651492-4680254.post@n4.nabble.com>
References: <1477322651492-4680254.post@n4.nabble.com>
Message-ID: <1477324108761-4680255.post@n4.nabble.com>

By the way...

When i get this error

2016/10/24 12:13:36 kid1| ipcacheParse: No Address records in response to
'client.wns.windows.com' 
2016/10/24 12:13:36 kid1| ipcacheParse: No Address records in response to
'client.wns.windows.com' 
2016/10/24 12:13:36 kid1| ipcacheParse: No Address records in response to
'client.wns.windows.com' 
2016/10/24 12:13:36 kid1| ipcacheParse: No Address records in response to
'skp03.epimg.net' 
2016/10/24 12:13:36 kid1| ipcacheParse: No Address records in response to
'www.msftncsi.com' 
2016/10/24 12:13:41 kid1| ipcacheParse: No Address records in response to
'client-s.gateway.messenger.live.com' 
2016/10/24 12:13:41 kid1| ipcacheParse: No Address records in response to
'client-s.gateway.messenger.live.com' 
2016/10/24 12:13:41 kid1| ipcacheParse: No Address records in response to
'client-s.gateway.messenger.live.com' 
2016/10/24 12:13:54 kid1| Error negotiating SSL connection on FD 76: (104)
Connection reset by peer 
2016/10/24 12:14:06 kid1| ipcacheParse: No Address records in response to
'www.posadadonantonio.com' 
2016/10/24 12:14:06 kid1| ipcacheParse: No Address records in response to
'www.posadadonantonio.com' 
2016/10/24 12:14:16 kid1| ipcacheParse: No Address records in response to
'www.msftncsi.com' 
2016/10/24 12:14:31 kid1| ipcacheParse: No Address records in response to
'c.live.com' 



I put

set envar ipv6=yes

in juniper

and this error not happen again , but google sometimes give a ipv6, and
squid dosent work then.....

(sorry for my english)



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Error-ipcacheParse-No-Address-records-in-response-to-tp4680254p4680255.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From garryd at comnet.uz  Mon Oct 24 16:05:28 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Mon, 24 Oct 2016 21:05:28 +0500
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <1477320007.5002.67.camel@comnet.uz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
 <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
 <578241c68e8e1238519585b8b1fc0151@comnet.uz>
 <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>
 <1477299550.5002.35.camel@comnet.uz>
 <bccae1dd-596c-7797-79d0-fb5fdee7297f@treenet.co.nz>
 <1477308726.5002.47.camel@comnet.uz>
 <86f78bf4-28ee-4f6a-b855-90a87d86a673@treenet.co.nz>
 <1477320007.5002.67.camel@comnet.uz>
Message-ID: <34080265b0f71525c3f304d3d5e3db66@comnet.uz>

On 2016-10-24 19:40, Garri Djavadyan wrote:
> So, the big G sends 304 only to HEAD requests, although it is a
> violation [1], AIUI:
> 
> curl --head -H 'If-Modified-Since: Thu, 20 Oct 2016 08:29:09 GMT' -H
> 'If-None-Match: "101395"' http://dl.google.com/linux/direct/google-chro
> me-stable_current_amd64.deb
> HTTP/1.1 304 Not Modified
> ETag: "101395"
> Server: downloads
> Vary: *
> X-Content-Type-Options: nosniff
> X-Frame-Options: SAMEORIGIN
> X-Xss-Protection: 1; mode=block
> Date: Mon, 24 Oct 2016 14:36:32 GMT
> Connection: keep-alive
> 
> ---
> 
> $ curl --verbose -H 'If-Modified-Since: Thu, 20 Oct 2016 08:29:09 GMT'
> -H 'If-None-Match: "101395"' http://dl.google.com/linux/direct/google-c
> hrome-stable_current_amd64.deb > /dev/null
>> GET /linux/direct/google-chrome-stable_current_amd64.deb HTTP/1.1
>> Host: dl.google.com
>> User-Agent: curl/7.50.3
>> Accept: */*
>> If-Modified-Since: Thu, 20 Oct 2016 08:29:09 GMT
>> If-None-Match: "101395"
>> 
> < HTTP/1.1 200 OK
> < Accept-Ranges: bytes
> < Content-Type: application/x-debian-package
> < ETag: "101395"
> < Last-Modified: Thu, 20 Oct 2016 08:29:09 GMT
> < Server: downloads
> < Vary: *
> < X-Content-Type-Options: nosniff
> < X-Frame-Options: SAMEORIGIN
> < X-Xss-Protection: 1; mode=block
> < Date: Mon, 24 Oct 2016 14:38:19 GMT
> < Content-Length: 45532350
> < Connection: keep-alive
> 
> [1] https://tools.ietf.org/html/rfc7234#section-4.3.5

Actually I mixed SHOULD agains MUST. The RFC 7231, section 4.3.2 states 
[1]:
...
The server SHOULD send the same header fields in response to a HEAD 
request as it would have sent if
the request had been a GET, except that the payload header fields 
(Section 3.3) MAY be omitted.
...

So, big G does not follow the recommendation, but does not violate the 
standard.

[1] https://tools.ietf.org/html/rfc7231#section-4.3.2

Garri


From nvalera at gmail.com  Mon Oct 24 16:19:55 2016
From: nvalera at gmail.com (Nicolas Valera)
Date: Mon, 24 Oct 2016 13:19:55 -0300
Subject: [squid-users] skype connection problem
In-Reply-To: <0dc219d6-e5b2-8473-822d-df6ec51d57ed@gmail.com>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <0dc219d6-e5b2-8473-822d-df6ec51d57ed@gmail.com>
Message-ID: <53fbc061-28e6-9445-89a1-053632d94c24@gmail.com>

Hi Yuri, thanks for the answer!

we don't have the squid in transparent mode in this network.
the squid configuration is very basic. here is the conf:

-------------------------------------------------------------------------
http_port 1280 connection-auth=off
forwarded_for delete
httpd_suppress_version_string on
client_persistent_connections off

cache_mem 16 GB
maximum_object_size_in_memory 8 MB

url_rewrite_program /usr/bin/squidGuard
url_rewrite_children 10
url_rewrite_access allow all

acl numeric_IPs dstdom_regex 
^(([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)|(\[([0-9a-f]+)?:([0-9a-f:]+)?:([0-9a-f]+|0-9\.]+)?\])):443
acl Skype_UA browser ^skype

acl SSL_ports port 443 563 873 1445 2083 8000 8088 10017 8443 5443 7443 
50001
acl Safe_ports port 80 82 88 182 210 554 591 777 873 1001 21 443 70 280 488
acl Safe_ports port 1025-65535  # unregistered ports

acl CONNECT method CONNECT
acl safe_method method GET
acl safe_method method PUT
acl safe_method method POST
acl safe_method method HEAD
acl safe_method method CONNECT
acl safe_method method OPTIONS
acl safe_method method PROPFIND
acl safe_method method REPORT
acl safe_method method MERGE
acl safe_method method MKACTIVITY
acl safe_method method CHECKOUT

http_access deny !Safe_ports
http_access allow CONNECT localnet numeric_IPS Skype_UA
http_access deny CONNECT !SSL_ports
http_access deny !safe_method
http_access allow localnet
http_access allow localhost
http_access deny all

refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern Packages\.tar$ 0       20%    4320 refresh-ims 
ignore-no-cache
refresh_pattern Packages\.bz2$ 0       20%    4320 refresh-ims 
ignore-no-cache
refresh_pattern Sources\.bz2$  0       20%    4320 refresh-ims 
ignore-no-cache
refresh_pattern Release\.gpg$  0       20%    4320 refresh-ims
refresh_pattern Release$       0       20%    4320 refresh-ims
refresh_pattern -i 
microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 
43200 reload-into-ims ignore-no-cache
refresh_pattern -i 
windowsupdate.com/.*\.(esd|cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 
4320 80% 43200 reload-into-ims ignore-no-cache
refresh_pattern -i 
windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 
43200 reload-into-ims ignore-no-cache
refresh_pattern -i 
live.net/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 
reload-into-ims ignore-no-cache
refresh_pattern .		0	20%	4320

-------------------------------------------------------------------------

please, can you send me your settings for ssl bump?

thanks again!
nicol?s.

On 10/23/2016 07:28 PM, Yuri Voinov wrote:
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
>
>
> 24.10.2016 4:11, N V ?????:
>> hi there,
>> i've had problems with windows skype clients with the only internet
> connection is through squid. the clients can login successful but when
> they make a call, it hangs after 12 secconds.
>>
>> I checked the client connections and see that attempts to connect
> directly even if the proxy is properly configured.
> Exactly, Skype does not use HTTP to calls. So, why you expect it calls
> should goes via proxy?
>>
>> my squid version is 3.5.12
>> the skype clients have the last version available.
>> does anyone have the same issues?
>> any idea?
> With properly configured ssl bump and transparent proxy we have not any
> problems with skype. I don't know your details.
>>
>> thanks in advance!
>> Nicol?s.
>>
>> pd. sorry about my english
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJYDTmeAAoJENNXIZxhPexG15oH/Alq2pQYRr80H/gMJUj4RJSi
> z3X/lD+QN7I7N7XkxV4/vL5Lzznxc/bGKznuAqiusha/t4mDdgpIp0issR9LtcV4
> 8pLnrnovxTrEWZR7yFfYX+u8V1KGnudQNxlfaJXLL8C8K0mg3cp3GpsW+1a8s2c5
> 3gvsrj6Ft871gKfNmXXVmT7BVQdrBwnQvBLmP4eKEOIiT9mKQSIZwMJB4HgKUgVW
> dmNQQb4q4975FD6c2t8/0Uu6l/A5lbMcxxuRIv3O9xrLqQud05IjYcSDDakzgtTy
> qv+w7gFHbKe1YWDUkl2wJEi/TPbIdiXvV73cmh+HiogItDrw++v2rftxMfbJa4U=
> =s3Ih
> -----END PGP SIGNATURE-----
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From yvoinov at gmail.com  Mon Oct 24 16:19:42 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 24 Oct 2016 22:19:42 +0600
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <34080265b0f71525c3f304d3d5e3db66@comnet.uz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
 <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
 <578241c68e8e1238519585b8b1fc0151@comnet.uz>
 <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>
 <1477299550.5002.35.camel@comnet.uz>
 <bccae1dd-596c-7797-79d0-fb5fdee7297f@treenet.co.nz>
 <1477308726.5002.47.camel@comnet.uz>
 <86f78bf4-28ee-4f6a-b855-90a87d86a673@treenet.co.nz>
 <1477320007.5002.67.camel@comnet.uz>
 <34080265b0f71525c3f304d3d5e3db66@comnet.uz>
Message-ID: <78a6c0d9-f1fe-3c1a-1bae-7bf3a24022c6@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


24.10.2016 22:05, Garri Djavadyan ?????:
> On 2016-10-24 19:40, Garri Djavadyan wrote:
>> So, the big G sends 304 only to HEAD requests, although it is a
>> violation [1], AIUI:
>>
>> curl --head -H 'If-Modified-Since: Thu, 20 Oct 2016 08:29:09 GMT' -H
>> 'If-None-Match: "101395"' http://dl.google.com/linux/direct/google-chro
>> me-stable_current_amd64.deb
>> HTTP/1.1 304 Not Modified
>> ETag: "101395"
>> Server: downloads
>> Vary: *
>> X-Content-Type-Options: nosniff
>> X-Frame-Options: SAMEORIGIN
>> X-Xss-Protection: 1; mode=block
>> Date: Mon, 24 Oct 2016 14:36:32 GMT
>> Connection: keep-alive
>>
>> ---
>>
>> $ curl --verbose -H 'If-Modified-Since: Thu, 20 Oct 2016 08:29:09 GMT'
>> -H 'If-None-Match: "101395"' http://dl.google.com/linux/direct/google-c
>> hrome-stable_current_amd64.deb > /dev/null
>>> GET /linux/direct/google-chrome-stable_current_amd64.deb HTTP/1.1
>>> Host: dl.google.com
>>> User-Agent: curl/7.50.3
>>> Accept: */*
>>> If-Modified-Since: Thu, 20 Oct 2016 08:29:09 GMT
>>> If-None-Match: "101395"
>>>
>> < HTTP/1.1 200 OK
>> < Accept-Ranges: bytes
>> < Content-Type: application/x-debian-package
>> < ETag: "101395"
>> < Last-Modified: Thu, 20 Oct 2016 08:29:09 GMT
>> < Server: downloads
>> < Vary: *
>> < X-Content-Type-Options: nosniff
>> < X-Frame-Options: SAMEORIGIN
>> < X-Xss-Protection: 1; mode=block
>> < Date: Mon, 24 Oct 2016 14:38:19 GMT
>> < Content-Length: 45532350
>> < Connection: keep-alive
>>
>> [1] https://tools.ietf.org/html/rfc7234#section-4.3.5
>
> Actually I mixed SHOULD agains MUST. The RFC 7231, section 4.3.2
states [1]:
> ...
> The server SHOULD send the same header fields in response to a HEAD
request as it would have sent if
> the request had been a GET, except that the payload header fields
(Section 3.3) MAY be omitted.
> ...
>
> So, big G does not follow the recommendation, but does not violate the
standard.
Of course, one does not violate the standards. Just a little do not
follow the recommendations. It also does not interfere with critical
transactions, right? Just prevent caching. But this is no problem here -
you can download file? That's enough. Isn't it?

Corporation of Good allows itself not to follow the recommendations.
What is permitted to Jupiter - the bull is not allowed, is not it? They
do all by rule - "Because we can". We are, instead, must follows
"Because we can't".

Nothing personal, no trolling. Just a note.

>
> [1] https://tools.ietf.org/html/rfc7231#section-4.3.2
>
> Garri
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDjSeAAoJENNXIZxhPexGAHAIAIDM3QyTLdMbK+HTz8o8zBnH
eKbnCBdkiDUalojgVlkWwW6llp78lFdJWf8ilzKpq9WE83g8fiesUMz5qQzShtqg
OFD9NT25w793L0F7Ne7b4haPqSh05RgIsPvri0PWSy1WRLBV1l+nHAKHzsTLoZ6w
MmtoQycP86p8z+FuuOg1mkmjlgUAlfeG0jWWQkwxfYcn0vxi2vM1nLc00xCxJi4U
iX3dbzWPuPDlljO+wm6ZKaOiQCdjTb8pk5AmFaFH/hhOIflffhPZdMBVikWAhaCp
1p8YTlUJvKj2nmP9SVkrFSFP5/AmAy0AZn+Cbg79+4lWRG2+KwepCAoO7EMbS4Q=
=hPcm
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/553079da/attachment.key>

From yvoinov at gmail.com  Mon Oct 24 16:21:38 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 24 Oct 2016 22:21:38 +0600
Subject: [squid-users] skype connection problem
In-Reply-To: <53fbc061-28e6-9445-89a1-053632d94c24@gmail.com>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <0dc219d6-e5b2-8473-822d-df6ec51d57ed@gmail.com>
 <53fbc061-28e6-9445-89a1-053632d94c24@gmail.com>
Message-ID: <637a63e0-d32d-61d6-3709-5f77b31979a7@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 

24.10.2016 22:19, Nicolas Valera ?????:
> Hi Yuri, thanks for the answer!
>
> we don't have the squid in transparent mode in this network.
So, you route all traffic to proxy box?

> the squid configuration is very basic. here is the conf:
>
> -------------------------------------------------------------------------
> http_port 1280 connection-auth=off
> forwarded_for delete
> httpd_suppress_version_string on
> client_persistent_connections off
>
> cache_mem 16 GB
> maximum_object_size_in_memory 8 MB
>
> url_rewrite_program /usr/bin/squidGuard
> url_rewrite_children 10
> url_rewrite_access allow all
>
> acl numeric_IPs dstdom_regex
^(([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)|(\[([0-9a-f]+)?:([0-9a-f:]+)?:([0-9a-f]+|0-9\.]+)?\])):443
> acl Skype_UA browser ^skype
>
> acl SSL_ports port 443 563 873 1445 2083 8000 8088 10017 8443 5443
7443 50001
> acl Safe_ports port 80 82 88 182 210 554 591 777 873 1001 21 443 70
280 488
> acl Safe_ports port 1025-65535  # unregistered ports
>
> acl CONNECT method CONNECT
> acl safe_method method GET
> acl safe_method method PUT
> acl safe_method method POST
> acl safe_method method HEAD
> acl safe_method method CONNECT
> acl safe_method method OPTIONS
> acl safe_method method PROPFIND
> acl safe_method method REPORT
> acl safe_method method MERGE
> acl safe_method method MKACTIVITY
> acl safe_method method CHECKOUT
>
> http_access deny !Safe_ports
> http_access allow CONNECT localnet numeric_IPS Skype_UA
> http_access deny CONNECT !SSL_ports
> http_access deny !safe_method
> http_access allow localnet
> http_access allow localhost
> http_access deny all
>
> refresh_pattern ^ftp:        1440    20%    10080
> refresh_pattern ^gopher:    1440    0%    1440
> refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
> refresh_pattern Packages\.tar$ 0       20%    4320 refresh-ims
ignore-no-cache
> refresh_pattern Packages\.bz2$ 0       20%    4320 refresh-ims
ignore-no-cache
> refresh_pattern Sources\.bz2$  0       20%    4320 refresh-ims
ignore-no-cache
> refresh_pattern Release\.gpg$  0       20%    4320 refresh-ims
> refresh_pattern Release$       0       20%    4320 refresh-ims
> refresh_pattern -i
microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
43200 reload-into-ims ignore-no-cache
> refresh_pattern -i
windowsupdate.com/.*\.(esd|cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
4320 80% 43200 reload-into-ims ignore-no-cache
> refresh_pattern -i
windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
43200 reload-into-ims ignore-no-cache
> refresh_pattern -i
live.net/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
reload-into-ims ignore-no-cache
> refresh_pattern .        0    20%    4320
>
> -------------------------------------------------------------------------
>
> please, can you send me your settings for ssl bump?
Copy-n-paste unknown configs is very bad idea, Nicolas.

>
> thanks again!
> nicol?s.
>
> On 10/23/2016 07:28 PM, Yuri Voinov wrote:
>>
>
>
> 24.10.2016 4:11, N V ?????:
> >>> hi there,
> >>> i've had problems with windows skype clients with the only internet
> connection is through squid. the clients can login successful but when
> they make a call, it hangs after 12 secconds.
> >>>
> >>> I checked the client connections and see that attempts to connect
> directly even if the proxy is properly configured.
> Exactly, Skype does not use HTTP to calls. So, why you expect it calls
> should goes via proxy?
> >>>
> >>> my squid version is 3.5.12
> >>> the skype clients have the last version available.
> >>> does anyone have the same issues?
> >>> any idea?
> With properly configured ssl bump and transparent proxy we have not any
> problems with skype. I don't know your details.
> >>>
> >>> thanks in advance!
> >>> Nicol?s.
> >>>
> >>> pd. sorry about my english
> >>>
> >>>
> >>>
> >>> _______________________________________________
> >>> squid-users mailing list
> >>> squid-users at lists.squid-cache.org
> >>> http://lists.squid-cache.org/listinfo/squid-users
>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDjURAAoJENNXIZxhPexGJAYH/jWHDNBJz43d17Lx1iUZSn1N
88PER8+AcS9aVlAzBWnu7uSu2yCWdcmMMNz1g5O2PYOnzuzMpyBHd2fKZFgksoP8
azdw5AXeHT9FOvXnY1qjGGWmn/vcBXC06NDpA8OEeuW9qNpEoRYR/0LQUrAOokW3
vLFft2FWT127ZK5c2DlD/p7yPrW7FmlovSkMlAAoe+sXkMMmPomSu75PhDBv3dKs
HCsTpama4Cwv+huJg/HDMyOLCsy4uiYZoFmilNiOF92Hg6RNq18LymVqe2FX0IlY
guY1U/DrkugmeGF1n8M+6Z5VWhR1Nhq2+lna9wlozRF1EqfuwsYT/a6EUSkx/LU=
=fHtH
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/dff57a60/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/dff57a60/attachment.key>

From nvalera at gmail.com  Mon Oct 24 16:28:54 2016
From: nvalera at gmail.com (Nicolas Valera)
Date: Mon, 24 Oct 2016 13:28:54 -0300
Subject: [squid-users] skype connection problem
In-Reply-To: <637a63e0-d32d-61d6-3709-5f77b31979a7@gmail.com>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <0dc219d6-e5b2-8473-822d-df6ec51d57ed@gmail.com>
 <53fbc061-28e6-9445-89a1-053632d94c24@gmail.com>
 <637a63e0-d32d-61d6-3709-5f77b31979a7@gmail.com>
Message-ID: <055a85fc-4981-64f4-f05a-f5dc45a0fa80@gmail.com>



On 10/24/2016 01:21 PM, Yuri Voinov wrote:
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
>
> 24.10.2016 22:19, Nicolas Valera ?????:
>> Hi Yuri, thanks for the answer!
>>
>> we don't have the squid in transparent mode in this network.
> So, you route all traffic to proxy box?
Yes, clients do not have direct Internet access
>
>> the squid configuration is very basic. here is the conf:
>>
>> -------------------------------------------------------------------------
>> http_port 1280 connection-auth=off
>> forwarded_for delete
>> httpd_suppress_version_string on
>> client_persistent_connections off
>>
>> cache_mem 16 GB
>> maximum_object_size_in_memory 8 MB
>>
>> url_rewrite_program /usr/bin/squidGuard
>> url_rewrite_children 10
>> url_rewrite_access allow all
>>
>> acl numeric_IPs dstdom_regex
> ^(([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)|(\[([0-9a-f]+)?:([0-9a-f:]+)?:([0-9a-f]+|0-9\.]+)?\])):443
>> acl Skype_UA browser ^skype
>>
>> acl SSL_ports port 443 563 873 1445 2083 8000 8088 10017 8443 5443
> 7443 50001
>> acl Safe_ports port 80 82 88 182 210 554 591 777 873 1001 21 443 70
> 280 488
>> acl Safe_ports port 1025-65535  # unregistered ports
>>
>> acl CONNECT method CONNECT
>> acl safe_method method GET
>> acl safe_method method PUT
>> acl safe_method method POST
>> acl safe_method method HEAD
>> acl safe_method method CONNECT
>> acl safe_method method OPTIONS
>> acl safe_method method PROPFIND
>> acl safe_method method REPORT
>> acl safe_method method MERGE
>> acl safe_method method MKACTIVITY
>> acl safe_method method CHECKOUT
>>
>> http_access deny !Safe_ports
>> http_access allow CONNECT localnet numeric_IPS Skype_UA
>> http_access deny CONNECT !SSL_ports
>> http_access deny !safe_method
>> http_access allow localnet
>> http_access allow localhost
>> http_access deny all
>>
>> refresh_pattern ^ftp:        1440    20%    10080
>> refresh_pattern ^gopher:    1440    0%    1440
>> refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
>> refresh_pattern Packages\.tar$ 0       20%    4320 refresh-ims
> ignore-no-cache
>> refresh_pattern Packages\.bz2$ 0       20%    4320 refresh-ims
> ignore-no-cache
>> refresh_pattern Sources\.bz2$  0       20%    4320 refresh-ims
> ignore-no-cache
>> refresh_pattern Release\.gpg$  0       20%    4320 refresh-ims
>> refresh_pattern Release$       0       20%    4320 refresh-ims
>> refresh_pattern -i
> microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
> 43200 reload-into-ims ignore-no-cache
>> refresh_pattern -i
> windowsupdate.com/.*\.(esd|cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
> 4320 80% 43200 reload-into-ims ignore-no-cache
>> refresh_pattern -i
> windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
> 43200 reload-into-ims ignore-no-cache
>> refresh_pattern -i
> live.net/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
> reload-into-ims ignore-no-cache
>> refresh_pattern .        0    20%    4320
>>
>> -------------------------------------------------------------------------
>>
>> please, can you send me your settings for ssl bump?
> Copy-n-paste unknown configs is very bad idea, Nicolas.

sorry about that!
the only way to make skype works through squid is with ssl bump?

>>
>> thanks again!
>> nicol?s.
>>
>> On 10/23/2016 07:28 PM, Yuri Voinov wrote:
>>>
>>
>>
>> 24.10.2016 4:11, N V ?????:
>> >>> hi there,
>> >>> i've had problems with windows skype clients with the only internet
>> connection is through squid. the clients can login successful but when
>> they make a call, it hangs after 12 secconds.
>> >>>
>> >>> I checked the client connections and see that attempts to connect
>> directly even if the proxy is properly configured.
>> Exactly, Skype does not use HTTP to calls. So, why you expect it calls
>> should goes via proxy?
>> >>>
>> >>> my squid version is 3.5.12
>> >>> the skype clients have the last version available.
>> >>> does anyone have the same issues?
>> >>> any idea?
>> With properly configured ssl bump and transparent proxy we have not any
>> problems with skype. I don't know your details.
>> >>>
>> >>> thanks in advance!
>> >>> Nicol?s.
>> >>>
>> >>> pd. sorry about my english
>> >>>
>> >>>
>> >>>
>> >>> _______________________________________________
>> >>> squid-users mailing list
>> >>> squid-users at lists.squid-cache.org
>> >>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> - --
> Cats - delicious. You just do not know how to cook them.
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJYDjURAAoJENNXIZxhPexGJAYH/jWHDNBJz43d17Lx1iUZSn1N
> 88PER8+AcS9aVlAzBWnu7uSu2yCWdcmMMNz1g5O2PYOnzuzMpyBHd2fKZFgksoP8
> azdw5AXeHT9FOvXnY1qjGGWmn/vcBXC06NDpA8OEeuW9qNpEoRYR/0LQUrAOokW3
> vLFft2FWT127ZK5c2DlD/p7yPrW7FmlovSkMlAAoe+sXkMMmPomSu75PhDBv3dKs
> HCsTpama4Cwv+huJg/HDMyOLCsy4uiYZoFmilNiOF92Hg6RNq18LymVqe2FX0IlY
> guY1U/DrkugmeGF1n8M+6Z5VWhR1Nhq2+lna9wlozRF1EqfuwsYT/a6EUSkx/LU=
> =fHtH
> -----END PGP SIGNATURE-----
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From yvoinov at gmail.com  Mon Oct 24 16:51:32 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 24 Oct 2016 22:51:32 +0600
Subject: [squid-users] skype connection problem
In-Reply-To: <055a85fc-4981-64f4-f05a-f5dc45a0fa80@gmail.com>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <0dc219d6-e5b2-8473-822d-df6ec51d57ed@gmail.com>
 <53fbc061-28e6-9445-89a1-053632d94c24@gmail.com>
 <637a63e0-d32d-61d6-3709-5f77b31979a7@gmail.com>
 <055a85fc-4981-64f4-f05a-f5dc45a0fa80@gmail.com>
Message-ID: <ee0a018b-e36c-3655-110e-babb2ef480be@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


24.10.2016 22:28, Nicolas Valera ?????:
>
>
> On 10/24/2016 01:21 PM, Yuri Voinov wrote:
>>
>
> 24.10.2016 22:19, Nicolas Valera ?????:
> >>> Hi Yuri, thanks for the answer!
> >>>
> >>> we don't have the squid in transparent mode in this network.
> So, you route all traffic to proxy box?
> > Yes, clients do not have direct Internet access
Here is root of problem. Skype does not always uses HTTP/HTTPS as
transport. Just pass Skype connections with proxy bypass and it will work.

In transparent environment non-HTTP/HTTPS connections not route to proxy.
>
> >>> the squid configuration is very basic. here is the conf:
> >>>
> >>>
-------------------------------------------------------------------------
> >>> http_port 1280 connection-auth=off
> >>> forwarded_for delete
> >>> httpd_suppress_version_string on
> >>> client_persistent_connections off
> >>>
> >>> cache_mem 16 GB
> >>> maximum_object_size_in_memory 8 MB
> >>>
> >>> url_rewrite_program /usr/bin/squidGuard
> >>> url_rewrite_children 10
> >>> url_rewrite_access allow all
> >>>
> >>> acl numeric_IPs dstdom_regex
>
^(([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)|(\[([0-9a-f]+)?:([0-9a-f:]+)?:([0-9a-f]+|0-9\.]+)?\])):443
> >>> acl Skype_UA browser ^skype
> >>>
> >>> acl SSL_ports port 443 563 873 1445 2083 8000 8088 10017 8443 5443
> 7443 50001
> >>> acl Safe_ports port 80 82 88 182 210 554 591 777 873 1001 21 443 70
> 280 488
> >>> acl Safe_ports port 1025-65535  # unregistered ports
> >>>
> >>> acl CONNECT method CONNECT
> >>> acl safe_method method GET
> >>> acl safe_method method PUT
> >>> acl safe_method method POST
> >>> acl safe_method method HEAD
> >>> acl safe_method method CONNECT
> >>> acl safe_method method OPTIONS
> >>> acl safe_method method PROPFIND
> >>> acl safe_method method REPORT
> >>> acl safe_method method MERGE
> >>> acl safe_method method MKACTIVITY
> >>> acl safe_method method CHECKOUT
> >>>
> >>> http_access deny !Safe_ports
> >>> http_access allow CONNECT localnet numeric_IPS Skype_UA
> >>> http_access deny CONNECT !SSL_ports
> >>> http_access deny !safe_method
> >>> http_access allow localnet
> >>> http_access allow localhost
> >>> http_access deny all
> >>>
> >>> refresh_pattern ^ftp:        1440    20%    10080
> >>> refresh_pattern ^gopher:    1440    0%    1440
> >>> refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
> >>> refresh_pattern Packages\.tar$ 0       20%    4320 refresh-ims
> ignore-no-cache
> >>> refresh_pattern Packages\.bz2$ 0       20%    4320 refresh-ims
> ignore-no-cache
> >>> refresh_pattern Sources\.bz2$  0       20%    4320 refresh-ims
> ignore-no-cache
> >>> refresh_pattern Release\.gpg$  0       20%    4320 refresh-ims
> >>> refresh_pattern Release$       0       20%    4320 refresh-ims
> >>> refresh_pattern -i
> microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
> 43200 reload-into-ims ignore-no-cache
> >>> refresh_pattern -i
> windowsupdate.com/.*\.(esd|cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
> 4320 80% 43200 reload-into-ims ignore-no-cache
> >>> refresh_pattern -i
> windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
> 43200 reload-into-ims ignore-no-cache
> >>> refresh_pattern -i
> live.net/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
> reload-into-ims ignore-no-cache
> >>> refresh_pattern .        0    20%    4320
> >>>
> >>>
-------------------------------------------------------------------------
> >>>
> >>> please, can you send me your settings for ssl bump?
> Copy-n-paste unknown configs is very bad idea, Nicolas.
>
> > sorry about that!
> > the only way to make skype works through squid is with ssl bump?
No. Just permit skype TCP traffic bypass proxy.
>
> >>>
> >>> thanks again!
> >>> nicol?s.
> >>>
> >>> On 10/23/2016 07:28 PM, Yuri Voinov wrote:
> >>>>
> >>>
> >>>
> >>> 24.10.2016 4:11, N V ?????:
> >>> >>> hi there,
> >>> >>> i've had problems with windows skype clients with the only
internet
> >>> connection is through squid. the clients can login successful but when
> >>> they make a call, it hangs after 12 secconds.
> >>> >>>
> >>> >>> I checked the client connections and see that attempts to connect
> >>> directly even if the proxy is properly configured.
> >>> Exactly, Skype does not use HTTP to calls. So, why you expect it calls
> >>> should goes via proxy?
> >>> >>>
> >>> >>> my squid version is 3.5.12
> >>> >>> the skype clients have the last version available.
> >>> >>> does anyone have the same issues?
> >>> >>> any idea?
> >>> With properly configured ssl bump and transparent proxy we have
not any
> >>> problems with skype. I don't know your details.
> >>> >>>
> >>> >>> thanks in advance!
> >>> >>> Nicol?s.
> >>> >>>
> >>> >>> pd. sorry about my english
> >>> >>>
> >>> >>>
> >>> >>>
> >>> >>> _______________________________________________
> >>> >>> squid-users mailing list
> >>> >>> squid-users at lists.squid-cache.org
> >>> >>> http://lists.squid-cache.org/listinfo/squid-users
> >>>
> >>>>
> >>>>
> >>>>
> >>>> _______________________________________________
> >>>> squid-users mailing list
> >>>> squid-users at lists.squid-cache.org
> >>>> http://lists.squid-cache.org/listinfo/squid-users
> >>>>
> >>> _______________________________________________
> >>> squid-users mailing list
> >>> squid-users at lists.squid-cache.org
> >>> http://lists.squid-cache.org/listinfo/squid-users
>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDjwUAAoJENNXIZxhPexGN9EH/3ttH+4Xydg4EnSSfn+2SStI
MsQeyOY4VNLNfwg7Gul/JZ8/9dl03Bzpn5U3/vSFL1RHu3syRVsH9CkROsO1u9ui
MaEtdOYnY53AYAnW5xbppV+TaBgBGlRH6pYFPJ55uKPmTBYPnDO2TIrZnaGT1bZF
TAWbSinZ7R0I0dRVm+Bm2CYFkyDJxkeTxf0dgYNtLAeI9wyH0lwN7YO6lpOAMhzA
JAX7mz2prV8NPxVp21UkzA0Nj6My4iVeyOK87AMX9Z+mkZMwhqnSPXp4bsCNCL9l
WZl7If88PgZVqh/CxPV9T09S7zAtsqMNPzabRi0XGC2DoEuof+azqx+uAuX5aSA=
=g0h2
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/140f0a72/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/140f0a72/attachment.key>

From eliezer at ngtech.co.il  Mon Oct 24 17:03:42 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 24 Oct 2016 20:03:42 +0300
Subject: [squid-users] skype connection problem
In-Reply-To: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
Message-ID: <031501d22e18$93029b00$b907d100$@ngtech.co.il>

Just to understand the scenario:
You have let say 1 client on network 192.168.0.0/24
You have a proxy at 192.168.0.200
The client doesn?t have a gateway in the network IE cannot run dns queries
or pings to the internet.
The client must define the proxy in order to access any Internet resources.
Right?
The proxy have access to dns and the ip stack natted or not.

I believe it would be pretty simple to reproduced in order to verify the
issue by another party.

Let me know if I got the situation right.

Eliezer

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of N V
Sent: Monday, October 24, 2016 01:11
To: squid-users at squid-cache.org
Subject: [squid-users] skype connection problem

hi there,
i've had problems with windows skype clients with the only internet
connection is through squid. the clients can login successful but when they
make a call, it hangs after 12 secconds.

I checked the client connections and see that attempts to connect directly
even if the proxy is properly configured.

my squid version is 3.5.12
the skype clients have the last version available.
does anyone have the same issues?
any idea?

thanks in advance!
Nicol?s.

pd. sorry about my english
-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 63705 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161024/839bcb11/attachment.bin>

From yvoinov at gmail.com  Mon Oct 24 18:07:23 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 25 Oct 2016 00:07:23 +0600
Subject: [squid-users] Squid with ASR9001
In-Reply-To: <032e01d22e1d$b802db90$280892b0$@ngtech.co.il>
References: <HE1PR01MB12108D2D44BA6ACBC6E75EF5F6D60@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <62d2a63b-b5db-40f9-445f-1087a4fc5850@gmail.com>
 <HE1PR01MB1210B9F41867169E17A0A2DAF6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <613eff0c-4cb9-75ea-e7f2-b4bccd95ce74@gmail.com>
 <HE1PR01MB12104763BDD60B87220FB257F6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <c4f64d19-91a1-91f3-bc39-fc72d5501b18@gmail.com>
 <032e01d22e1d$b802db90$280892b0$@ngtech.co.il>
Message-ID: <bed8a892-c90a-8106-230a-11f494b3273d@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
No.

24.10.2016 23:40, Eliezer Croitoru ?????:
> And why would you want this exactly?
> The most simple thing is to use routing policy and to monitor the proxy in
> a much higher level then WCCP.
Based on my personal experience with WCCP (over 6 years). PBR is VERY
router's CPU consumpted.
WCCP - is not (L2, not GRE. GRE performs on CPU, L2 on control-plane and
hardware-accelerated).

However, using edge router for WCCP is not so good idea by another
reason. It breaks good network architecture in most cases. I'm not CCA,
but ever for me it's obvious.

So, underlying aggregations switches is more appropriate target for
WCCP, because of they can be uses L2 WCCP - which is extremely fast.

> For example fetch a web page or a statistics page every 10 seconds.
> It?s considered pretty right in the industry.
> For routers it?s a whole another story but for a rock solid system I
do not
> believe WCCP is a must.
Depending of router. Branch router must have. Just take a look on whole
Cisco's router's range. Just for interest.

> Any juniper and Cisco + others these days do not rely on WCCP since it?s
> considered a hassle to maintain.
Cats delicious. You just do not know how to cook them :)

WCCP is a very simple protocol. While there may be poorly documented.
There is another problem - very few people well versed in networking
technologies, few details delves into what makes. The vast majority
simply copy-paste configs without a single thought in his head, not
bothering to understand.

What is there to maintain? Just configure it once and sit on the ass
straight.
>
> Eliezer
>
> ----
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
>
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Yuri
> Sent: Monday, October 24, 2016 14:06
> To: Garth van Sittert | BitCo <garth at bitco.co.za>;
> squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid with ASR9001
>
> Ha, it seems ASR9000 really does not support WCCP exactly. You right.
>
> WCCP supported on Nexus, on ASR1000... So, your router only can use PBR or
> analoquie.
>
> The only idea is to buy 3750 as aggregation switch, config WCCP on it and
> connect to your ASR by fiber trunk.
> 24.10.2016 16:30, Garth van Sittert | BitCo ?????:
> 
> By Cisco employee - ?Correct, there is no WCCP and no plans for it
> either... :(?
> https://supportforums.cisco.com/discussion/12227051/ios-xr-and-wccp
> 
> WCCP supported platforms ?
>
>
https://supportforums.cisco.com/document/133201/wccp-platform-support-overvi
> ew
> 
> Our ASR9001 has no commands that support wccp anywhere?
> 
> 
> 
> 
>     
> Garth van Sittert | Chief Executive Officer     
> (BSC Physics & Computer Science)
> Tel: 087 135 0000 Ext: 201
> garth at bitco.co.za <mailto:garth at bitco.co.za> 
> bitco.co.za <http://www.bitco.co.za/>    
> 
> 
> From: Yuri [mailto:yvoinov at gmail.com]
> Sent: Monday, 24 October 2016 12:12 PM
> To: Garth van Sittert | BitCo <garth at bitco.co.za>
> <mailto:garth at bitco.co.za> ; squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> Subject: Re: [squid-users] Squid with ASR9001
> 
> 
> 
> 24.10.2016 13:16, Garth van Sittert | BitCo ?????:
> Yes, it looks like all of the ASR9000 range which makes use of IOS XR no
> longer supports WCCP.
> Please, provide prooflink from Cisco.
>
>
> 
> Policy Based Routing has been replaced by ACL Based Forwarding or ABF.
> So? This is therminology difference, if any.
>
>
> 
> 
> 
> 
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Yuri Voinov
> Sent: Sunday, 23 October 2016 9:35 PM
> To: squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
> Subject: Re: [squid-users] Squid with ASR9001
> 
>
>
>
> 23.10.2016 23:16, Garth van Sittert | BitCo ?????:
>
>
>
>
>       > Good day all
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       > Has anyone had any experience setting up Squid with any IOS
>       XR Cisco routers?  The Cisco ASR9000 range doesn?t support WCCP
>       and I cannot find any examples online.
>
>
>
>
> Seriously, the entire range?
>
> Who said that it does not support WCCP? It is obligation to support, if
> only because it is not a home dish soap. That's when Cisco write the
> documentation that does not support - and then we cry.
>
>
>
>
>
>
>
>
>
>
>
>
>       > I have also found quotes regarding PBR on the ASR9000? ?With
>       IOS XR traditional policy-based routing (PBR) is history?
>
>
>
>
> It's crazy city a forum talking about? PBR - is a fundamental
functionality
> for the router. Especially for the router at this level. I somehow
difficult
> to imagine a company that completely cuts down the business by releasing
> incompatible with what device. This is only possible in the
OpenSource. But
> not in huge IT-business company. AFAIK.
>
>
>
>
>
>
>
>
>
>
>
>
>       > I plan to use this on our 10Gbps ISP traffic to improve
>       customer experience?
>
>
>
>
> There is no examples because the solutions of such a level rarely use
> Squid. Personally, I do not have a machine to play and write an example to
> Squid's wiki. As you know, Christmas is not the wife of a router is
present
> as trinkets.
>
>
>
>
>
>
>
>
>
>
>
>
>       > Garth
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       > BitCo Email Footer
>
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.01
>
96914,17z/data=!3m1!4b1!4m5!3m4!1s0x142989bce6c63b3:0xc0b44878907297f4!8m2!3
> d-26.04982!4d28.0218801>
>
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.019
>
6914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b4487890729
> 7f4%218m2%213d-26.04982%214d28.0218801>
>
>
>
>       > The information contained in this message is intended solely
>       for the individual to whom it is specifically and originally
>       addressed. This message and its contents may contain confidential
>       or privileged information from BitCo. If you are not the intended
>       recipient, you are hereby notified that any disclosure or
>       distribution, is strictly prohibited. If you receive this email in
>       error, please notify BitCo immediately and delete it. BitCo does
>       not accept any liability or responsibility if action is taken in
>       reliance on the contents of this information.
>
>
>
>
>
>
>
>
>
>
>
>       > _______________________________________________
>
>
>
>       > squid-users mailing list
>
>
>
>       > squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
>
>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.019
>
6914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b4487890729
> 7f4%218m2%213d-26.04982%214d28.0218801>
> The information contained in this message is intended solely for the
> individual to whom it is specifically and originally addressed. This
message
> and its contents may contain confidential or privileged information from
> BitCo. If you are not the intended recipient, you are hereby notified that
> any disclosure or distribution, is strictly prohibited. If you receive
this
> email in error, please notify BitCo immediately and delete it. BitCo does
> not accept any liability or responsibility if action is taken in
reliance on
> the contents of this information.
> 
>
>
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.019
>
6914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b4487890729
> 7f4%218m2%213d-26.04982%214d28.0218801>
> The information contained in this message is intended solely for the
> individual to whom it is specifically and originally addressed. This
message
> and its contents may contain confidential or privileged information from
> BitCo. If you are not the intended recipient, you are hereby notified that
> any disclosure or distribution, is strictly prohibited. If you receive
this
> email in error, please notify BitCo immediately and delete it. BitCo does
> not accept any liability or responsibility if action is taken in
reliance on
> the contents of this information.
>

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDk3bAAoJENNXIZxhPexGpukH/jYRZWMfyWdNjSVkkA9CyWf+
tsH9sktpAswwoBvSPXJfQ8cjDivuRozlOBSB13R4aWcKVb8/d9JJGvjcAJ4NBE5R
NHM9GDLvL8tf5QgQS109f/MWst+hnxcGFq0aKKRc2p3Bo/Jdbf2pk2msBunWSwwq
QViPshouqz9fOteRpCAccv6kJKndmFu+ManM/oGDNL0RDwQE20paSUnTLC2iig2I
PHPd8uup3Qa6xy/enlMscDx9ySw74lM9rJz+bpe5irH93LWaSzkmPDMFyNJJ6Rxs
lWJ6L+doOhV2O74HYuq6hocMg5ekq9/p6rnv0c6ZqPljuxoc0TG0TOFCWpWrGsU=
=S8RU
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/2ec4cd95/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/2ec4cd95/attachment.key>

From andre61 at brazcubas.br  Mon Oct 24 18:14:31 2016
From: andre61 at brazcubas.br (=?UTF-8?Q?Andr=c3=a9_Janna?=)
Date: Mon, 24 Oct 2016 16:14:31 -0200
Subject: [squid-users] sourcehash load balance
In-Reply-To: <d6bbe519-3408-e8f7-9631-a14b89cac603@treenet.co.nz>
References: <d4af11ba-018f-0d88-c953-c9932a4f0891@brazcubas.br>
 <d6bbe519-3408-e8f7-9631-a14b89cac603@treenet.co.nz>
Message-ID: <d9ec3e34-dead-74a2-f28d-b3178b6cdd50@brazcubas.br>

On 23/10/2016 10:35 a.m., Amos Jeffries wrote:

> On 22/10/2016 12:21 a.m., Andr?? Janna wrote:
>> I set up a Squid proxy that forwards all requests to 2 parent caches.
>> I'm using Squid version 3.5.19.
>> My goal is that multiple connection from a client to a server should be
>> forwarded to the same parent, so that the server see all requests coming
>> from the same IP address.
>>
>> I'm using the following configuration:
>> cache_peer squid1 parent 3128 0 no-query sourcehash
>> cache_peer squid2 parent 3128 0 no-query sourcehash
>> never_direct allow all
>>
>> Looking at access.log some requests are tagged as CLOSEST_PARENT instead
>> of SOURCEHASH_PARENT, so it seams that Squid is not always using source
>> hash rule to forward requests to parent caches.
>> For instance:
>> 1477046954.047   3882 10.11.2.4 TCP_TUNNEL/200 21935 CONNECT
>> sso.cisco.com:443 - SOURCEHASH_PARENT/10.0.33.12 -
>> 1477046968.056     21 10.11.2.4 TCP_MISS/200 1012 POST
>> http://ocsp.digicert.com/ - CLOSEST_PARENT/10.0.33.13
>> application/ocsp-response
>> 1477047782.038     22 10.11.2.4 TCP_MISS/204 307 GET
>> http://clients1.google.com/generate_204 - SOURCEHASH_PARENT/10.0.33.12 -
>> 1477047782.045    181 10.11.2.4 TCP_MISS/200 745 GET
>> http://tags.bluekai.com/site/2964? - CLOSEST_PARENT/10.0.33.13 image/gif
>>
>> So requests from the same client are not sent to the same parent cache.
>> How can I force Squid to always use source hash parent selection method?
> Check you setting for nonhierarchical_direct. It should be 'off'. The
> default is 'on'.
>
> Amos
>
>

Hi Amos,
I've just added "nonhierarchical_direct off" to my setting but there are 
still requests that are forwarded using a parent selection method 
different from "sourcehash".
For instance:
1477331305.998     13 10.11.0.12 TCP_MISS/200 4267 GET 
http://www.cisco.com/etc/designs/cdc/dmr/icons/arrows-grey.png - 
SOURCEHASH_PARENT/10.0.33.12 image/png
1477331306.948     10 10.11.0.12 TCP_MISS/304 609 GET 
http://platform.twitter.com/widgets.js - CLOSEST_PARENT/10.0.33.13 -

Regards,
Andre



From yvoinov at gmail.com  Mon Oct 24 19:01:25 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 25 Oct 2016 01:01:25 +0600
Subject: [squid-users] Squid with ASR9001
In-Reply-To: <036301d22e26$b4594570$1d0bd050$@ngtech.co.il>
References: <HE1PR01MB12108D2D44BA6ACBC6E75EF5F6D60@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <62d2a63b-b5db-40f9-445f-1087a4fc5850@gmail.com>
 <HE1PR01MB1210B9F41867169E17A0A2DAF6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <613eff0c-4cb9-75ea-e7f2-b4bccd95ce74@gmail.com>
 <HE1PR01MB12104763BDD60B87220FB257F6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <c4f64d19-91a1-91f3-bc39-fc72d5501b18@gmail.com>
 <032e01d22e1d$b802db90$280892b0$@ngtech.co.il>
 <bed8a892-c90a-8106-230a-11f494b3273d@gmail.com>
 <036301d22e26$b4594570$1d0bd050$@ngtech.co.il>
Message-ID: <eebc0bc5-3166-ef19-731a-80ef00ee0671@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Well, if we're talking about squid-based appliances.....

http://wiki.squid-cache.org/ConfigExamples/Intercept/CiscoIOSv15Wccp2

In this article descrived approx. half-year experimental experience with
various LAN topologies, and Cisco devices.

More common:

http://www.cisco.com/c/en/us/td/docs/ios/12_2/configfun/configuration/guide/ffun_c/fcf018.html
https://supportforums.cisco.com/document/143961/understanding-wccp-redirection-and-assignment-methods-waas

Cisco has not best-in-the-world documentation, yes, but everything
depends on an understanding of network protocols and basic architecture.

25.10.2016 0:44, Eliezer Croitoru ?????:
> Well I do agree on most of the things but it seems that CPU is missing in
> some devices and there for a simpler protocol is better but?. CPU?
Yessssss. Router has CPU. :) Not only ASIC. :) PBR is problem, because
of EVERY policy/ACL match handles on CPU.

This brings us to the other side - the rules / policies must be
carefully optimized - that too few people do, until the router does not
choke on CPU overload.

> Admins in many cases do not use their own to understand the complexity but
> from what I do see in the jobs market employers expect the unexpected.
Admins, in most cases, understand nothing and do not bother trying to
grasp and understand more deeply than in the first three-five seconds. ;)

About the present, of course, do not tell. :)

> Or if to be more accurate: They expect a mage which knows and understand
> every single protocol language and piece of hardware.
>
> Can you gather me what ever documentation on the WCCP protocol?
> I want to see how simple it would be to implement the same concepts
with an
> HTTP\tcp interface.
There's really just all. The main thing to understand how the network
works on L2 and L3 in OSI. And a bit network hardware knowledge.

>
> Eliezer
>
> ----
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
>
> From: Yuri Voinov [mailto:yvoinov at gmail.com]
> Sent: Monday, October 24, 2016 21:07
> To: Eliezer Croitoru <eliezer at ngtech.co.il>; 'Garth van Sittert | BitCo'
> <garth at bitco.co.za>; squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid with ASR9001
>
>
> No.
>
> 24.10.2016 23:40, Eliezer Croitoru ?????:
> > And why would you want this
>       exactly?
>
>       > The most simple thing is to use routing policy and to monitor
>       the proxy in
>
>       > a much higher level then WCCP.
> Based on my personal experience with WCCP (over 6 years). PBR is VERY
> router's CPU consumpted.
> WCCP - is not (L2, not GRE. GRE performs on CPU, L2 on control-plane and
> hardware-accelerated).
>
> However, using edge router for WCCP is not so good idea by another reason.
> It breaks good network architecture in most cases. I'm not CCA, but
ever for
> me it's obvious.
>
> So, underlying aggregations switches is more appropriate target for WCCP,
> because of they can be uses L2 WCCP - which is extremely fast.
>
> > For example fetch a web page or
>       a statistics page every 10 seconds.
>
>       > It?s considered pretty right in the industry.
>
>       > For routers it?s a whole another story but for a rock solid
>       system I do not
>
>       > believe WCCP is a must.
> Depending of router. Branch router must have. Just take a look on whole
> Cisco's router's range. Just for interest.
>
> > Any juniper and Cisco + others
>       these days do not rely on WCCP since it?s
>
>       > considered a hassle to maintain.
> Cats delicious. You just do not know how to cook them :)
>
> WCCP is a very simple protocol. While there may be poorly documented.
There
> is another problem - very few people well versed in networking
technologies,
> few details delves into what makes. The vast majority simply copy-paste
> configs without a single thought in his head, not bothering to understand.
>
> What is there to maintain? Just configure it once and sit on the ass
> straight.
>
>
>       > Eliezer
>
>
>
>       > ----
>
>       > Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> <http://ngtech.co.il/lmgtfy/> 
>
>       > Linux System Administrator
>
>       > Mobile: +972-5-28704261
>
>       > Email: eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>
>
>
>
>
>
>       > From: squid-users
>       [mailto:squid-users-bounces at lists.squid-cache.org] On
>
>       > Behalf Of Yuri
>
>       > Sent: Monday, October 24, 2016 14:06
>
>       > To: Garth van Sittert | BitCo <garth at bitco.co.za>
> <mailto:garth at bitco.co.za> ;
>
>       > squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
>
>       > Subject: Re: [squid-users] Squid with ASR9001
>
>
>
>       > Ha, it seems ASR9000 really does not support WCCP exactly.
>       You right.
>
>
>
>       > WCCP supported on Nexus, on ASR1000... So, your router only
>       can use PBR or
>
>       > analoquie.
>
>
>
>       > The only idea is to buy 3750 as aggregation switch, config
>       WCCP on it and
>
>       > connect to your ASR by fiber trunk.
>
>       > 24.10.2016 16:30, Garth van Sittert | BitCo ?????:
>
>
>
>       > By Cisco employee - ?Correct, there is no WCCP and no plans
>       for it
>
>       > either... :(?
>
>
>       https://supportforums.cisco.com/discussion/12227051/ios-xr-and-wccp
>
>
>
>       > WCCP supported platforms ?
>
>
>
>
>
https://supportforums.cisco.com/document/133201/wccp-platform-support-overv
> i
>
>       > ew
>
>
>
>       > Our ASR9001 has no commands that support wccp anywhere?
>
>
>
>
>
>
>
>
>
>
>
>       > Garth van Sittert | Chief Executive Officer     
>
>       > (BSC Physics & Computer Science)
>
>       > Tel: 087 135 0000 Ext: 201
>
>       > garth at bitco.co.za <mailto:garth at bitco.co.za>
> <mailto:garth at bitco.co.za> <mailto:garth at bitco.co.za>  
>
>       > bitco.co.za <http://www.bitco.co.za/> <http://www.bitco.co.za/>
>
>
>
>
>       > From: Yuri [mailto:yvoinov at gmail.com]
>
>       > Sent: Monday, 24 October 2016 12:12 PM
>
>       > To: Garth van Sittert | BitCo <garth at bitco.co.za>
> <mailto:garth at bitco.co.za>
>
>       > <mailto:garth at bitco.co.za> <mailto:garth at bitco.co.za>  ;
>       squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
>
>       > <mailto:squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org> 
>
>       > Subject: Re: [squid-users] Squid with ASR9001
>
>
>
>
>
>
>
>       > 24.10.2016 13:16, Garth van Sittert | BitCo ?????:
>
>       > Yes, it looks like all of the ASR9000 range which makes use
>       of IOS XR no
>
>       > longer supports WCCP.
>
>       > Please, provide prooflink from Cisco.
>
>
>
>
>
>
>
>       > Policy Based Routing has been replaced by ACL Based
>       Forwarding or ABF.
>
>       > So? This is therminology difference, if any.
>
>
>
>
>
>
>
>
>
>
>
>
>
>       > From: squid-users
>       [mailto:squid-users-bounces at lists.squid-cache.org] On
>
>       > Behalf Of Yuri Voinov
>
>       > Sent: Sunday, 23 October 2016 9:35 PM
>
>       > To: squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
>
>       > <mailto:squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org> 
>
>       > Subject: Re: [squid-users] Squid with ASR9001
>
>
>
>
>
>
>
>
>
>       > 23.10.2016 23:16, Garth van Sittert | BitCo ?????:
>
>
>
>
>
>
>
>
>
>       >       > Good day all
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > Has anyone had any experience setting up Squid
>       with any IOS
>
>       >       XR Cisco routers?  The Cisco ASR9000 range doesn?t
>       support WCCP
>
>       >       and I cannot find any examples online.
>
>
>
>
>
>
>
>
>
>       > Seriously, the entire range?
>
>
>
>       > Who said that it does not support WCCP? It is obligation to
>       support, if
>
>       > only because it is not a home dish soap. That's when Cisco
>       write the
>
>       > documentation that does not support - and then we cry.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > I have also found quotes regarding PBR on the
>       ASR9000? ?With
>
>       >       IOS XR traditional policy-based routing (PBR) is
>       history?
>
>
>
>
>
>
>
>
>
>       > It's crazy city a forum talking about? PBR - is a fundamental
>       functionality
>
>       > for the router. Especially for the router at this level. I
>       somehow difficult
>
>       > to imagine a company that completely cuts down the business
>       by releasing
>
>       > incompatible with what device. This is only possible in the
>       OpenSource. But
>
>       > not in huge IT-business company. AFAIK.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > I plan to use this on our 10Gbps ISP traffic to
>       improve
>
>       >       customer experience?
>
>
>
>
>
>
>
>
>
>       > There is no examples because the solutions of such a level
>       rarely use
>
>       > Squid. Personally, I do not have a machine to play and write
>       an example to
>
>       > Squid's wiki. As you know, Christmas is not the wife of a
>       router is present
>
>       > as trinkets.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > Garth
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > BitCo Email Footer
>
>
>
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.01
>
>
>
96914,17z/data=!3m1!4b1!4m5!3m4!1s0x142989bce6c63b3:0xc0b44878907297f4!8m2!
> 3
>
>       > d-26.04982!4d28.0218801>
>
>
>
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.01
> 9
>
>
>
6914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b448789072
> 9
>
>       > 7f4%218m2%213d-26.04982%214d28.0218801>
>
>
>
>
>
>
>
>       >       > The information contained in this message is
>       intended solely
>
>       >       for the individual to whom it is specifically and
>       originally
>
>       >       addressed. This message and its contents may contain
>       confidential
>
>       >       or privileged information from BitCo. If you are not
>       the intended
>
>       >       recipient, you are hereby notified that any disclosure
>       or
>
>       >       distribution, is strictly prohibited. If you receive
>       this email in
>
>       >       error, please notify BitCo immediately and delete it.
>       BitCo does
>
>       >       not accept any liability or responsibility if action is
>       taken in
>
>       >       reliance on the contents of this information.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > _______________________________________________
>
>
>
>
>
>
>
>       >       > squid-users mailing list
>
>
>
>
>
>
>
>       >       > squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
>
>       > <mailto:squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>
>
>
>
>
>
>
>
>       >       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.01
> 9
>
>
>
6914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b448789072
> 9
>
>       > 7f4%218m2%213d-26.04982%214d28.0218801>
>
>       > The information contained in this message is intended solely
>       for the
>
>       > individual to whom it is specifically and originally
>       addressed. This message
>
>       > and its contents may contain confidential or privileged
>       information from
>
>       > BitCo. If you are not the intended recipient, you are hereby
>       notified that
>
>       > any disclosure or distribution, is strictly prohibited. If
>       you receive this
>
>       > email in error, please notify BitCo immediately and delete
>       it. BitCo does
>
>       > not accept any liability or responsibility if action is taken
>       in reliance on
>
>       > the contents of this information.
>
>
>
>
>
>
>
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.01
> 9
>
>
>
6914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b448789072
> 9
>
>       > 7f4%218m2%213d-26.04982%214d28.0218801>
>
>       > The information contained in this message is intended solely
>       for the
>
>       > individual to whom it is specifically and originally
>       addressed. This message
>
>       > and its contents may contain confidential or privileged
>       information from
>
>       > BitCo. If you are not the intended recipient, you are hereby
>       notified that
>
>       > any disclosure or distribution, is strictly prohibited. If
>       you receive this
>
>       > email in error, please notify BitCo immediately and delete
>       it. BitCo does
>
>       > not accept any liability or responsibility if action is taken
>       in reliance on
>
>       > the contents of this information.
>
>
>

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDlqFAAoJENNXIZxhPexGTskIAIhaOEvGtlNhdCZCuU9zcbvI
HZmPXZ+s2Wqnh8ui2ptkMrhilLaS8S+1paFOpMqxk5CcweSnJKXiaBNAGyaD6fAg
IB6DuaMwp5bCUZvUcSkXoHtiGaiQifbo5E/ueSpZ6xe2zhfkAFH4OkFeZ23nY3kV
QHd1I557zB0MlVr7f5Oqm9csN7TQKFn5oqDmLxtTKyrNUusGBNjRLxSSMY5VEmQ4
+z8D5fbMfm7M5vY0oDQqa8rEUjYuMFDFAVDOZoSgIPTk79eTi+3hD/BCuJrrLNUX
FlHcshMno22xceddOlBigfMQO/V2v1Zrj2ZPCKKpC1I4XwKvyFkG3qkqzXeOiPQ=
=gCZT
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/ee3034da/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/ee3034da/attachment.key>

From yvoinov at gmail.com  Mon Oct 24 19:05:21 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 25 Oct 2016 01:05:21 +0600
Subject: [squid-users] Squid with ASR9001
In-Reply-To: <036301d22e26$b4594570$1d0bd050$@ngtech.co.il>
References: <HE1PR01MB12108D2D44BA6ACBC6E75EF5F6D60@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <62d2a63b-b5db-40f9-445f-1087a4fc5850@gmail.com>
 <HE1PR01MB1210B9F41867169E17A0A2DAF6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <613eff0c-4cb9-75ea-e7f2-b4bccd95ce74@gmail.com>
 <HE1PR01MB12104763BDD60B87220FB257F6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <c4f64d19-91a1-91f3-bc39-fc72d5501b18@gmail.com>
 <032e01d22e1d$b802db90$280892b0$@ngtech.co.il>
 <bed8a892-c90a-8106-230a-11f494b3273d@gmail.com>
 <036301d22e26$b4594570$1d0bd050$@ngtech.co.il>
Message-ID: <9f2c1980-47f6-76ca-8268-886387f5e02b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Ah - in Squid's wiki don't pay attention on Variant III.

This is minimalistic topology, main goal was as minimum hardware units
as possible (for cost minimization).

Also VRF-variant still in progress. We can't solve DNS proxying task as
required yet.

25.10.2016 0:44, Eliezer Croitoru ?????:
> Well I do agree on most of the things but it seems that CPU is missing in
> some devices and there for a simpler protocol is better but?. CPU?
> Admins in many cases do not use their own to understand the complexity but
> from what I do see in the jobs market employers expect the unexpected.
> Or if to be more accurate: They expect a mage which knows and understand
> every single protocol language and piece of hardware.
>
> Can you gather me what ever documentation on the WCCP protocol?
> I want to see how simple it would be to implement the same concepts
with an
> HTTP\tcp interface.
>
> Eliezer
>
> ----
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
>
> From: Yuri Voinov [mailto:yvoinov at gmail.com]
> Sent: Monday, October 24, 2016 21:07
> To: Eliezer Croitoru <eliezer at ngtech.co.il>; 'Garth van Sittert | BitCo'
> <garth at bitco.co.za>; squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid with ASR9001
>
>
> No.
>
> 24.10.2016 23:40, Eliezer Croitoru ?????:
> > And why would you want this
>       exactly?
>
>       > The most simple thing is to use routing policy and to monitor
>       the proxy in
>
>       > a much higher level then WCCP.
> Based on my personal experience with WCCP (over 6 years). PBR is VERY
> router's CPU consumpted.
> WCCP - is not (L2, not GRE. GRE performs on CPU, L2 on control-plane and
> hardware-accelerated).
>
> However, using edge router for WCCP is not so good idea by another reason.
> It breaks good network architecture in most cases. I'm not CCA, but
ever for
> me it's obvious.
>
> So, underlying aggregations switches is more appropriate target for WCCP,
> because of they can be uses L2 WCCP - which is extremely fast.
>
> > For example fetch a web page or
>       a statistics page every 10 seconds.
>
>       > It?s considered pretty right in the industry.
>
>       > For routers it?s a whole another story but for a rock solid
>       system I do not
>
>       > believe WCCP is a must.
> Depending of router. Branch router must have. Just take a look on whole
> Cisco's router's range. Just for interest.
>
> > Any juniper and Cisco + others
>       these days do not rely on WCCP since it?s
>
>       > considered a hassle to maintain.
> Cats delicious. You just do not know how to cook them :)
>
> WCCP is a very simple protocol. While there may be poorly documented.
There
> is another problem - very few people well versed in networking
technologies,
> few details delves into what makes. The vast majority simply copy-paste
> configs without a single thought in his head, not bothering to understand.
>
> What is there to maintain? Just configure it once and sit on the ass
> straight.
>
>
>       > Eliezer
>
>
>
>       > ----
>
>       > Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> <http://ngtech.co.il/lmgtfy/> 
>
>       > Linux System Administrator
>
>       > Mobile: +972-5-28704261
>
>       > Email: eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>
>
>
>
>
>
>       > From: squid-users
>       [mailto:squid-users-bounces at lists.squid-cache.org] On
>
>       > Behalf Of Yuri
>
>       > Sent: Monday, October 24, 2016 14:06
>
>       > To: Garth van Sittert | BitCo <garth at bitco.co.za>
> <mailto:garth at bitco.co.za> ;
>
>       > squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
>
>       > Subject: Re: [squid-users] Squid with ASR9001
>
>
>
>       > Ha, it seems ASR9000 really does not support WCCP exactly.
>       You right.
>
>
>
>       > WCCP supported on Nexus, on ASR1000... So, your router only
>       can use PBR or
>
>       > analoquie.
>
>
>
>       > The only idea is to buy 3750 as aggregation switch, config
>       WCCP on it and
>
>       > connect to your ASR by fiber trunk.
>
>       > 24.10.2016 16:30, Garth van Sittert | BitCo ?????:
>
>
>
>       > By Cisco employee - ?Correct, there is no WCCP and no plans
>       for it
>
>       > either... :(?
>
>
>       https://supportforums.cisco.com/discussion/12227051/ios-xr-and-wccp
>
>
>
>       > WCCP supported platforms ?
>
>
>
>
>
https://supportforums.cisco.com/document/133201/wccp-platform-support-overv
> i
>
>       > ew
>
>
>
>       > Our ASR9001 has no commands that support wccp anywhere?
>
>
>
>
>
>
>
>
>
>
>
>       > Garth van Sittert | Chief Executive Officer     
>
>       > (BSC Physics & Computer Science)
>
>       > Tel: 087 135 0000 Ext: 201
>
>       > garth at bitco.co.za <mailto:garth at bitco.co.za>
> <mailto:garth at bitco.co.za> <mailto:garth at bitco.co.za>  
>
>       > bitco.co.za <http://www.bitco.co.za/> <http://www.bitco.co.za/>
>
>
>
>
>       > From: Yuri [mailto:yvoinov at gmail.com]
>
>       > Sent: Monday, 24 October 2016 12:12 PM
>
>       > To: Garth van Sittert | BitCo <garth at bitco.co.za>
> <mailto:garth at bitco.co.za>
>
>       > <mailto:garth at bitco.co.za> <mailto:garth at bitco.co.za>  ;
>       squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
>
>       > <mailto:squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org> 
>
>       > Subject: Re: [squid-users] Squid with ASR9001
>
>
>
>
>
>
>
>       > 24.10.2016 13:16, Garth van Sittert | BitCo ?????:
>
>       > Yes, it looks like all of the ASR9000 range which makes use
>       of IOS XR no
>
>       > longer supports WCCP.
>
>       > Please, provide prooflink from Cisco.
>
>
>
>
>
>
>
>       > Policy Based Routing has been replaced by ACL Based
>       Forwarding or ABF.
>
>       > So? This is therminology difference, if any.
>
>
>
>
>
>
>
>
>
>
>
>
>
>       > From: squid-users
>       [mailto:squid-users-bounces at lists.squid-cache.org] On
>
>       > Behalf Of Yuri Voinov
>
>       > Sent: Sunday, 23 October 2016 9:35 PM
>
>       > To: squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
>
>       > <mailto:squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org> 
>
>       > Subject: Re: [squid-users] Squid with ASR9001
>
>
>
>
>
>
>
>
>
>       > 23.10.2016 23:16, Garth van Sittert | BitCo ?????:
>
>
>
>
>
>
>
>
>
>       >       > Good day all
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > Has anyone had any experience setting up Squid
>       with any IOS
>
>       >       XR Cisco routers?  The Cisco ASR9000 range doesn?t
>       support WCCP
>
>       >       and I cannot find any examples online.
>
>
>
>
>
>
>
>
>
>       > Seriously, the entire range?
>
>
>
>       > Who said that it does not support WCCP? It is obligation to
>       support, if
>
>       > only because it is not a home dish soap. That's when Cisco
>       write the
>
>       > documentation that does not support - and then we cry.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > I have also found quotes regarding PBR on the
>       ASR9000? ?With
>
>       >       IOS XR traditional policy-based routing (PBR) is
>       history?
>
>
>
>
>
>
>
>
>
>       > It's crazy city a forum talking about? PBR - is a fundamental
>       functionality
>
>       > for the router. Especially for the router at this level. I
>       somehow difficult
>
>       > to imagine a company that completely cuts down the business
>       by releasing
>
>       > incompatible with what device. This is only possible in the
>       OpenSource. But
>
>       > not in huge IT-business company. AFAIK.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > I plan to use this on our 10Gbps ISP traffic to
>       improve
>
>       >       customer experience?
>
>
>
>
>
>
>
>
>
>       > There is no examples because the solutions of such a level
>       rarely use
>
>       > Squid. Personally, I do not have a machine to play and write
>       an example to
>
>       > Squid's wiki. As you know, Christmas is not the wife of a
>       router is present
>
>       > as trinkets.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > Garth
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > BitCo Email Footer
>
>
>
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.01
>
>
>
96914,17z/data=!3m1!4b1!4m5!3m4!1s0x142989bce6c63b3:0xc0b44878907297f4!8m2!
> 3
>
>       > d-26.04982!4d28.0218801>
>
>
>
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.01
> 9
>
>
>
6914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b448789072
> 9
>
>       > 7f4%218m2%213d-26.04982%214d28.0218801>
>
>
>
>
>
>
>
>       >       > The information contained in this message is
>       intended solely
>
>       >       for the individual to whom it is specifically and
>       originally
>
>       >       addressed. This message and its contents may contain
>       confidential
>
>       >       or privileged information from BitCo. If you are not
>       the intended
>
>       >       recipient, you are hereby notified that any disclosure
>       or
>
>       >       distribution, is strictly prohibited. If you receive
>       this email in
>
>       >       error, please notify BitCo immediately and delete it.
>       BitCo does
>
>       >       not accept any liability or responsibility if action is
>       taken in
>
>       >       reliance on the contents of this information.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > _______________________________________________
>
>
>
>
>
>
>
>       >       > squid-users mailing list
>
>
>
>
>
>
>
>       >       > squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
>
>       > <mailto:squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>
>
>
>
>
>
>
>
>       >       > http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.01
> 9
>
>
>
6914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b448789072
> 9
>
>       > 7f4%218m2%213d-26.04982%214d28.0218801>
>
>       > The information contained in this message is intended solely
>       for the
>
>       > individual to whom it is specifically and originally
>       addressed. This message
>
>       > and its contents may contain confidential or privileged
>       information from
>
>       > BitCo. If you are not the intended recipient, you are hereby
>       notified that
>
>       > any disclosure or distribution, is strictly prohibited. If
>       you receive this
>
>       > email in error, please notify BitCo immediately and delete
>       it. BitCo does
>
>       > not accept any liability or responsibility if action is taken
>       in reliance on
>
>       > the contents of this information.
>
>
>
>
>
>
>
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.01
> 9
>
>
>
6914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b448789072
> 9
>
>       > 7f4%218m2%213d-26.04982%214d28.0218801>
>
>       > The information contained in this message is intended solely
>       for the
>
>       > individual to whom it is specifically and originally
>       addressed. This message
>
>       > and its contents may contain confidential or privileged
>       information from
>
>       > BitCo. If you are not the intended recipient, you are hereby
>       notified that
>
>       > any disclosure or distribution, is strictly prohibited. If
>       you receive this
>
>       > email in error, please notify BitCo immediately and delete
>       it. BitCo does
>
>       > not accept any liability or responsibility if action is taken
>       in reliance on
>
>       > the contents of this information.
>
>
>

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDltxAAoJENNXIZxhPexGx6MH/2zfsWdKgF5tjEp7CBs8sxPk
Zb7kq6KS8OKyPlvwEMwaJoLCw5OZkGsvZWUpshSisgaeh3gyIZluWcXoXyXj2BkE
zrHa2E4hi5/HC5Bv+O17SpsdTmGs5+EcohTlhugFSJKaIGRlx5sFbhOjQTXFuW9w
T+V8zUxRjeGDwQYXseieke8+++XhouJsmdr/HaHzwd0q/kI01cyMQtw7AlR/3Ww7
1qAo+sF4bOLPevK3QB+GXcXgosGYWKYw5/mC+x/xJuRgqJlV8XEI9azWTNVDFZRa
PdFvB5N3G840/uUanUJhYeUefg56JHGA3VAmuf0OQpNOOZ3l0r2lf5mH1E4Ac5Y=
=QWrl
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/e107e353/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/e107e353/attachment.key>

From yvoinov at gmail.com  Mon Oct 24 22:07:21 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 25 Oct 2016 04:07:21 +0600
Subject: [squid-users] Squid with ASR9001
In-Reply-To: <03fa01d22e41$f1a94540$d4fbcfc0$@ngtech.co.il>
References: <HE1PR01MB12108D2D44BA6ACBC6E75EF5F6D60@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <62d2a63b-b5db-40f9-445f-1087a4fc5850@gmail.com>
 <HE1PR01MB1210B9F41867169E17A0A2DAF6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <613eff0c-4cb9-75ea-e7f2-b4bccd95ce74@gmail.com>
 <HE1PR01MB12104763BDD60B87220FB257F6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <c4f64d19-91a1-91f3-bc39-fc72d5501b18@gmail.com>
 <032e01d22e1d$b802db90$280892b0$@ngtech.co.il>
 <bed8a892-c90a-8106-230a-11f494b3273d@gmail.com>
 <036301d22e26$b4594570$1d0bd050$@ngtech.co.il>
 <eebc0bc5-3166-ef19-731a-80ef00ee0671@gmail.com>
 <03fa01d22e41$f1a94540$d4fbcfc0$@ngtech.co.il>
Message-ID: <bf758bde-6615-6556-d02b-e1e20178fafd@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Compared with PBR - definitely.

IF OS TCP stack supports bridging - exactly.

25.10.2016 3:59, Eliezer Croitoru ?????:
> So what you are illustrating is that if we will handle the connection
> interception using bridge tables it would be much more efficient then
Policy
> Based routing.
> I believe it?s very simple to implement in linux.
>
> Eliezer
>
> ----
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
>
> From: Yuri Voinov [mailto:yvoinov at gmail.com]
> Sent: Monday, October 24, 2016 22:01
> To: Eliezer Croitoru <eliezer at ngtech.co.il>
> Cc: 'Garth van Sittert | BitCo' <garth at bitco.co.za>;
> squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid with ASR9001
>
>
> Well, if we're talking about squid-based appliances.....
>
> http://wiki.squid-cache.org/ConfigExamples/Intercept/CiscoIOSv15Wccp2
>
> In this article descrived approx. half-year experimental experience with
> various LAN topologies, and Cisco devices.
>
> More common:
>
>
http://www.cisco.com/c/en/us/td/docs/ios/12_2/configfun/configuration/guide
> /ffun_c/fcf018.html
>
https://supportforums.cisco.com/document/143961/understanding-wccp-redirect
> ion-and-assignment-methods-waas
>
> Cisco has not best-in-the-world documentation, yes, but everything depends
> on an understanding of network protocols and basic architecture.
>
> 25.10.2016 0:44, Eliezer Croitoru ?????:
> > Well I do agree on most of the
>       things but it seems that CPU is missing in
>
>       > some devices and there for a simpler protocol is better but?.
>       CPU?
> Yessssss. Router has CPU. :) Not only ASIC. :) PBR is problem, because of
> EVERY policy/ACL match handles on CPU.
>
> This brings us to the other side - the rules / policies must be carefully
> optimized - that too few people do, until the router does not choke on CPU
> overload.
>
> > Admins in many cases do not use
>       their own to understand the complexity but
>
>       > from what I do see in the jobs market employers expect the
>       unexpected.
> Admins, in most cases, understand nothing and do not bother trying to
grasp
> and understand more deeply than in the first three-five seconds. ;)
>
> About the present, of course, do not tell. :)
>
> > Or if to be more accurate: They
>       expect a mage which knows and understand
>
>       > every single protocol language and piece of hardware.
>
>
>
>       > Can you gather me what ever documentation on the WCCP
>       protocol?
>
>       > I want to see how simple it would be to implement the same
>       concepts with an
>
>       > HTTP\tcp interface.
> There's really just all. The main thing to understand how the network
works
> on L2 and L3 in OSI. And a bit network hardware knowledge.
>
>
>
>       > Eliezer
>
>
>
>       > ----
>
>       > Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> <http://ngtech.co.il/lmgtfy/> 
>
>       > Linux System Administrator
>
>       > Mobile: +972-5-28704261
>
>       > Email: eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>
>
>
>
>
>
>       > From: Yuri Voinov [mailto:yvoinov at gmail.com]
>
>       > Sent: Monday, October 24, 2016 21:07
>
>       > To: Eliezer Croitoru <eliezer at ngtech.co.il>
> <mailto:eliezer at ngtech.co.il> ; 'Garth van
>       Sittert | BitCo'
>
>       > <garth at bitco.co.za> <mailto:garth at bitco.co.za> ;
> squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
> > Subject: Re: [squid-users] Squid with ASR9001
>
>
>
>
>
>       > No.
>
>
>
>       > 24.10.2016 23:40, Eliezer Croitoru ?????:
>
>       > > And why would you want this
>
>       >       exactly?
>
>
>
>       >       > The most simple thing is to use routing policy and
>       to monitor
>
>       >       the proxy in
>
>
>
>       >       > a much higher level then WCCP.
>
>       > Based on my personal experience with WCCP (over 6 years). PBR
>       is VERY
>
>       > router's CPU consumpted.
>
>       > WCCP - is not (L2, not GRE. GRE performs on CPU, L2 on
>       control-plane and
>
>       > hardware-accelerated).
>
>
>
>       > However, using edge router for WCCP is not so good idea by
>       another reason.
>
>       > It breaks good network architecture in most cases. I'm not
>       CCA, but ever for
>
>       > me it's obvious.
>
>
>
>       > So, underlying aggregations switches is more appropriate
>       target for WCCP,
>
>       > because of they can be uses L2 WCCP - which is extremely
>       fast.
>
>
>
>       > > For example fetch a web page or
>
>       >       a statistics page every 10 seconds.
>
>
>
>       >       > It?s considered pretty right in the industry.
>
>
>
>       >       > For routers it?s a whole another story but for a
>       rock solid
>
>       >       system I do not
>
>
>
>       >       > believe WCCP is a must.
>
>       > Depending of router. Branch router must have. Just take a
>       look on whole
>
>       > Cisco's router's range. Just for interest.
>
>
>
>       > > Any juniper and Cisco + others
>
>       >       these days do not rely on WCCP since it?s
>
>
>
>       >       > considered a hassle to maintain.
>
>       > Cats delicious. You just do not know how to cook them :)
>
>
>
>       > WCCP is a very simple protocol. While there may be poorly
>       documented. There
>
>       > is another problem - very few people well versed in
>       networking technologies,
>
>       > few details delves into what makes. The vast majority simply
>       copy-paste
>
>       > configs without a single thought in his head, not bothering
>       to understand.
>
>
>
>       > What is there to maintain? Just configure it once and sit on
>       the ass
>
>       > straight.
>
>
>
>
>
>       >       > Eliezer
>
>
>
>
>
>
>
>       >       > ----
>
>
>
>       >       > Eliezer Croitoru
>       <http://ngtech.co.il/lmgtfy/> <http://ngtech.co.il/lmgtfy/>
>
>       > <http://ngtech.co.il/lmgtfy/> <http://ngtech.co.il/lmgtfy/>  
>
>
>
>       >       > Linux System Administrator
>
>
>
>       >       > Mobile: +972-5-28704261
>
>
>
>       >       > Email: eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>
>       <mailto:eliezer at ngtech.co.il> <mailto:eliezer at ngtech.co.il>
>
>
>
>
>
>
>
>
>
>
>
>       >       > From: squid-users
>
>       >       [mailto:squid-users-bounces at lists.squid-cache.org] On
>
>
>
>       >       > Behalf Of Yuri
>
>
>
>       >       > Sent: Monday, October 24, 2016 14:06
>
>
>
>       >       > To: Garth van Sittert | BitCo
>       <garth at bitco.co.za> <mailto:garth at bitco.co.za>
>
>       > <mailto:garth at bitco.co.za> <mailto:garth at bitco.co.za>  ;
>
>
>
>       >       > squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
>
>       > <mailto:squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>
>
>
>
>       >       > Subject: Re: [squid-users] Squid with ASR9001
>
>
>
>
>
>
>
>       >       > Ha, it seems ASR9000 really does not support WCCP
>       exactly.
>
>       >       You right.
>
>
>
>
>
>
>
>       >       > WCCP supported on Nexus, on ASR1000... So, your
>       router only
>
>       >       can use PBR or
>
>
>
>       >       > analoquie.
>
>
>
>
>
>
>
>       >       > The only idea is to buy 3750 as aggregation
>       switch, config
>
>       >       WCCP on it and
>
>
>
>       >       > connect to your ASR by fiber trunk.
>
>
>
>       >       > 24.10.2016 16:30, Garth van Sittert | BitCo ?????:
>
>
>
>
>
>
>
>       >       > By Cisco employee - ?Correct, there is no WCCP and
>       no plans
>
>       >       for it
>
>
>
>       >       > either... :(?
>
>
>
>
>
>
>       https://supportforums.cisco.com/discussion/12227051/ios-xr-and-wccp
>
>
>
>
>
>
>
>       >       > WCCP supported platforms ?
>
>
>
>
>
>
>
>
>
>
>
https://supportforums.cisco.com/document/133201/wccp-platform-support-overv
>
>       > i
>
>
>
>       >       > ew
>
>
>
>
>
>
>
>       >       > Our ASR9001 has no commands that support wccp
>       anywhere?
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > Garth van Sittert | Chief Executive Officer     
>
>
>
>       >       > (BSC Physics & Computer Science)
>
>
>
>       >       > Tel: 087 135 0000 Ext: 201
>
>
>
>       >       > garth at bitco.co.za <mailto:garth at bitco.co.za>
> <mailto:garth at bitco.co.za> <mailto:garth at bitco.co.za>
>
>       > <mailto:garth at bitco.co.za> <mailto:garth at bitco.co.za>
>       <mailto:garth at bitco.co.za> <mailto:garth at bitco.co.za>   
>
>
>
>       >       > bitco.co.za <http://www.bitco.co.za/>
> <http://www.bitco.co.za/>
>       <http://www.bitco.co.za/> <http://www.bitco.co.za/>
>
>
>
>
>
>
>
>
>
>       >       > From: Yuri [mailto:yvoinov at gmail.com]
>
>
>
>       >       > Sent: Monday, 24 October 2016 12:12 PM
>
>
>
>       >       > To: Garth van Sittert | BitCo
>       <garth at bitco.co.za> <mailto:garth at bitco.co.za>
>
>       > <mailto:garth at bitco.co.za> <mailto:garth at bitco.co.za>
>
>
>
>       >       > <mailto:garth at bitco.co.za> <mailto:garth at bitco.co.za>
>       <mailto:garth at bitco.co.za> <mailto:garth at bitco.co.za>   ;
>
>       >       squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
>
>       > <mailto:squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>
>
>
>
>       >       > <mailto:squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>
>
>       > <mailto:squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>  
>
>
>
>       >       > Subject: Re: [squid-users] Squid with ASR9001
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > 24.10.2016 13:16, Garth van Sittert | BitCo ?????:
>
>
>
>       >       > Yes, it looks like all of the ASR9000 range which
>       makes use
>
>       >       of IOS XR no
>
>
>
>       >       > longer supports WCCP.
>
>
>
>       >       > Please, provide prooflink from Cisco.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > Policy Based Routing has been replaced by ACL
>       Based
>
>       >       Forwarding or ABF.
>
>
>
>       >       > So? This is therminology difference, if any.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > From: squid-users
>
>       >       [mailto:squid-users-bounces at lists.squid-cache.org] On
>
>
>
>       >       > Behalf Of Yuri Voinov
>
>
>
>       >       > Sent: Sunday, 23 October 2016 9:35 PM
>
>
>
>       >       > To: squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
>
>       > <mailto:squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>
>
>
>
>       >       > <mailto:squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>
>
>       > <mailto:squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>  
>
>
>
>       >       > Subject: Re: [squid-users] Squid with ASR9001
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > 23.10.2016 23:16, Garth van Sittert | BitCo ?????:
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > Good day all
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > Has anyone had any experience setting
>       up Squid
>
>       >       with any IOS
>
>
>
>       >       >       XR Cisco routers?  The Cisco ASR9000 range
>       doesn?t
>
>       >       support WCCP
>
>
>
>       >       >       and I cannot find any examples online.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > Seriously, the entire range?
>
>
>
>
>
>
>
>       >       > Who said that it does not support WCCP? It is
>       obligation to
>
>       >       support, if
>
>
>
>       >       > only because it is not a home dish soap. That's
>       when Cisco
>
>       >       write the
>
>
>
>       >       > documentation that does not support - and then we
>       cry.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > I have also found quotes regarding PBR
>       on the
>
>       >       ASR9000? ?With
>
>
>
>       >       >       IOS XR traditional policy-based routing
>       (PBR) is
>
>       >       history?
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > It's crazy city a forum talking about? PBR - is a
>       fundamental
>
>       >       functionality
>
>
>
>       >       > for the router. Especially for the router at this
>       level. I
>
>       >       somehow difficult
>
>
>
>       >       > to imagine a company that completely cuts down the
>       business
>
>       >       by releasing
>
>
>
>       >       > incompatible with what device. This is only
>       possible in the
>
>       >       OpenSource. But
>
>
>
>       >       > not in huge IT-business company. AFAIK.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > I plan to use this on our 10Gbps ISP
>       traffic to
>
>       >       improve
>
>
>
>       >       >       customer experience?
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       > There is no examples because the solutions of such
>       a level
>
>       >       rarely use
>
>
>
>       >       > Squid. Personally, I do not have a machine to play
>       and write
>
>       >       an example to
>
>
>
>       >       > Squid's wiki. As you know, Christmas is not the
>       wife of a
>
>       >       router is present
>
>
>
>       >       > as trinkets.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > Garth
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > BitCo Email Footer
>
>
>
>
>
>
>
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.01
>
>
>
>
>
>
>
96914,17z/data=!3m1!4b1!4m5!3m4!1s0x142989bce6c63b3:0xc0b44878907297f4!8m2!
>
>       > 3
>
>
>
>       >       > d-26.04982!4d28.0218801>
>
>
>
>
>
>
>
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.01
>
>       > 9
>
>
>
>
>
>
>
6914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b448789072
>
>       > 9
>
>
>
>       >       > 7f4%218m2%213d-26.04982%214d28.0218801>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > The information contained in this
>       message is
>
>       >       intended solely
>
>
>
>       >       >       for the individual to whom it is
>       specifically and
>
>       >       originally
>
>
>
>       >       >       addressed. This message and its contents may
>       contain
>
>       >       confidential
>
>
>
>       >       >       or privileged information from BitCo. If you
>       are not
>
>       >       the intended
>
>
>
>       >       >       recipient, you are hereby notified that any
>       disclosure
>
>       >       or
>
>
>
>       >       >       distribution, is strictly prohibited. If you
>       receive
>
>       >       this email in
>
>
>
>       >       >       error, please notify BitCo immediately and
>       delete it.
>
>       >       BitCo does
>
>
>
>       >       >       not accept any liability or responsibility
>       if action is
>
>       >       taken in
>
>
>
>       >       >       reliance on the contents of this
>       information.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >
>       _______________________________________________
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > squid-users mailing list
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       > squid-users at lists.squid-cache.org
> <mailto:squid-users at lists.squid-cache.org>
>
>       > <mailto:squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>
>
>
>
>       >       > <mailto:squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>
>
>       > <mailto:squid-users at lists.squid-cache.org>
> <mailto:squid-users at lists.squid-cache.org>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>       >       >       >
>       http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.01
>
>       > 9
>
>
>
>
>
>
>
6914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b448789072
>
>       > 9
>
>
>
>       >       > 7f4%218m2%213d-26.04982%214d28.0218801>
>
>
>
>       >       > The information contained in this message is
>       intended solely
>
>       >       for the
>
>
>
>       >       > individual to whom it is specifically and
>       originally
>
>       >       addressed. This message
>
>
>
>       >       > and its contents may contain confidential or
>       privileged
>
>       >       information from
>
>
>
>       >       > BitCo. If you are not the intended recipient, you
>       are hereby
>
>       >       notified that
>
>
>
>       >       > any disclosure or distribution, is strictly
>       prohibited. If
>
>       >       you receive this
>
>
>
>       >       > email in error, please notify BitCo immediately
>       and delete
>
>       >       it. BitCo does
>
>
>
>       >       > not accept any liability or responsibility if
>       action is taken
>
>       >       in reliance on
>
>
>
>       >       > the contents of this information.
>
>
>
>
>
>
>
>
>
>
>
>
>
>
>
<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.01
>
>       > 9
>
>
>
>
>
>
>
6914,17z/data=%213m1%214b1%214m5%213m4%211s0x142989bce6c63b3:0xc0b448789072
>
>       > 9
>
>
>
>       >       > 7f4%218m2%213d-26.04982%214d28.0218801>
>
>
>
>       >       > The information contained in this message is
>       intended solely
>
>       >       for the
>
>
>
>       >       > individual to whom it is specifically and
>       originally
>
>       >       addressed. This message
>
>
>
>       >       > and its contents may contain confidential or
>       privileged
>
>       >       information from
>
>
>
>       >       > BitCo. If you are not the intended recipient, you
>       are hereby
>
>       >       notified that
>
>
>
>       >       > any disclosure or distribution, is strictly
>       prohibited. If
>
>       >       you receive this
>
>
>
>       >       > email in error, please notify BitCo immediately
>       and delete
>
>       >       it. BitCo does
>
>
>
>       >       > not accept any liability or responsibility if
>       action is taken
>
>       >       in reliance on
>
>
>
>       >       > the contents of this information.
>
>
>
>
>
>
>

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDoYZAAoJENNXIZxhPexGNHcIAJUWBGZF+aEfA8V0FMWVJgJn
LfxfyTdtTqBQYeY+/mJzpoGZRul7SHiaJ98cFc6b30oDXQoPu6L5Url5ueBicqPK
QhTJxnAtWdl3UNy4sxTcYg646Zy9FLXbwloblE9ATn3Q2/Kkj6s4vy+kVy88pgmY
0txDr+K7UdUowhIJzPMSsCLHcNquXHvpIJeZA13TLTzxwAtUWbIioyG+S1Z3aqWy
uHpKBRSx/Ei8Keg1XaDF82QzOnG2uSMU7fcYc6wDYCfN+6MwZoNOqbCoD/69krpV
is4z7bJrlma8hr4Z0KzhNgNYZDowFoGdtG5UY484nTghsyGoot3TgR3aedxMguI=
=5MI8
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/a58a04d7/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/a58a04d7/attachment.key>

From yvoinov at gmail.com  Mon Oct 24 23:04:36 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 25 Oct 2016 05:04:36 +0600
Subject: [squid-users] Squid with ASR9001
In-Reply-To: <50260e55-a014-8612-4418-d3eed32593b7@gmail.com>
References: <HE1PR01MB12108D2D44BA6ACBC6E75EF5F6D60@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <62d2a63b-b5db-40f9-445f-1087a4fc5850@gmail.com>
 <HE1PR01MB1210B9F41867169E17A0A2DAF6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <613eff0c-4cb9-75ea-e7f2-b4bccd95ce74@gmail.com>
 <HE1PR01MB12104763BDD60B87220FB257F6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <c4f64d19-91a1-91f3-bc39-fc72d5501b18@gmail.com>
 <032e01d22e1d$b802db90$280892b0$@ngtech.co.il>
 <bed8a892-c90a-8106-230a-11f494b3273d@gmail.com>
 <036301d22e26$b4594570$1d0bd050$@ngtech.co.il>
 <eebc0bc5-3166-ef19-731a-80ef00ee0671@gmail.com>
 <03fa01d22e41$f1a94540$d4fbcfc0$@ngtech.co.il>
 <bf758bde-6615-6556-d02b-e1e20178fafd@gmail.com>
 <041201d22e48$b9667bb0$2c337310$@ngtech.co.il>
 <50260e55-a014-8612-4418-d3eed32593b7@gmail.com>
Message-ID: <aca8b6d5-42dc-839b-5089-e9df5f28fd49@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
No, Juniper is not my area ;)

It is impossible to know everything :)
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYDpOEAAoJENNXIZxhPexGUWEH/jdttWLpJNQm49z0XlTMwwIM
HfPo3gUEufPGtYSNqvx+XWq448BMr+VxvcMi5ojDhE43FhHpLgCaJK40mw8U2M/i
EUV2DFOJ9f6D6KgIAYYPtAngD/hhYCxl8YBlRG3G+OfTbip8n4pSqShVwTHRs8F8
pzPtQ/5qrzIdocXQy+VKO+O6+vYYfZYA71LiS2YObu+M6lY8pNPYLeG6RB9c3Ou7
lFXyuoTwIdfhbj3fY78IrB8kDXHft5283rxtgqe5vzXCouI8swcAZ00I7Z6xEr6n
RkYShP3xu+vhn2uzx/aqcDo+t3DswsZw0f0EgWkSZTYu3s09kuuYaeIb5fr4KmU=
=4AXt
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/566a5308/attachment.key>

From eliezer at ngtech.co.il  Tue Oct 25 00:25:51 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 25 Oct 2016 03:25:51 +0300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <0cf0c543-f2f0-e880-6ef7-cec6312127ad@treenet.co.nz>
References: <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
 <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>
 <6e65eafe-37aa-e6f2-9c04-e4e14b9ff3e9@gmail.com>
 <CAEpx-0WMruHcZBP=kpZO1+C4YnELpeYGy2=WYtKMY5zmTWuaBg@mail.gmail.com>
 <3c02e953-d2cb-7905-f52a-e036ed3e06ab@treenet.co.nz>
 <1473879398350-4679512.post@n4.nabble.com>
 <e730f7da-c6ce-808f-f454-2d7a0369a92b@measurement-factory.com>
 <1473894106709-4679515.post@n4.nabble.com>
 <11a31fcd-901a-351a-4f60-8b2fe054b224@measurement-factory.com>
 <1473903753861-4679519.post@n4.nabble.com>
 <1474306760218-4679596.post@n4.nabble.com>
 <010701d219d7$8f2efcd0$ad8cf670$@ngtech.co.il>
 <0cf0c543-f2f0-e880-6ef7-cec6312127ad@treenet.co.nz>
Message-ID: <044001d22e56$572c9390$0585bab0$@ngtech.co.il>

It took me a while and I hope that I will be able to get the dumps this week.
I started working on an example of ebtables level traffic redirection towards the squid machine.
The scenario should be a good example for embedded devices which operates mostly food in the bridge level rather then the CPU and iptables level.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Thursday, September 29, 2016 07:16
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Web Whatsapp, Dropbox... problem

On 29/09/2016 11:27 a.m., Eliezer Croitoru wrote:
> I am also testing this issue and I have the next settings:
> acl DiscoverSNIHost at_step SslBump1
> acl NoSSLIntercept ssl::server_name_regex -i "/etc/squid/url.nobump"
> ssl_bump splice NoSSLIntercept
> ssl_bump peek DiscoverSNIHost
> ssl_bump bump all
> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/squid/ssl -M 4MB 
> sslcrtd_children 10 read_ahead_gap 64 MB sslproxy_cert_error allow all 
> tls_outgoing_options flags=DONT_VERIFY_PEER acl foreignProtocol 
> squid_error ERR_PROTOCOL_UNKNOWN ERR_TOO_BIG on_unsupported_protocol 
> tunnel foreignProtocol
> 
> (Which is not recommended for production as is!!!)
> 
> Now the "/etc/squid/url.nobump" file contains:
> # WU (Squid 3.5.x and above with SSL Bump) # Only this sites must be 
> spliced.
> update\.microsoft\.com$
> update\.microsoft\.com\.akadns\.net$
> v10\.vortex\-win\.data\.microsoft.com$
> settings\-win\.data\.microsoft\.com$
> # The next are trusted SKYPE addresses a\.config\.skype\.com$ 
> pipe\.skype\.com$ mail\.rimon\.net\.il$ w[0-9]+\.web\.whatsapp\.com$ 
> \.web\.whatsapp\.com$ web\.whatsapp\.com$ ##END OF NO BUMP DOMAINS.
> 
> And squid 4.0.14 doesn't tunnel the requests.
> The above is with:
> http_port 3128
> http_port 13128 intercept
> https_port 13129 intercept ssl-bump \
>    cert=/etc/squid/ssl_cert/myCA.pem \
>      generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> 
> On the 443 intercept port.
> Access log output:
> 1475100891.636 000445 192.168.10.112 NONE/200 0 CONNECT 
> 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
> 1475100908.469 000223 192.168.10.112 TCP_MISS/200 508 GET 
> https://web.whatsapp.com/status.json - ORIGINAL_DST/31.13.90.51 
> text/json 52:54:00:bc:9f:73
> 1475100952.107 000445 192.168.10.112 NONE/200 0 CONNECT 
> 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
> 1475100968.832 000191 192.168.10.112 NONE/200 0 CONNECT 
> 216.58.214.110:443 - ORIGINAL_DST/216.58.214.110 - 52:54:00:bc:9f:73
> 1475100968.984 000199 192.168.10.112 NONE/200 0 CONNECT 
> 172.217.22.14:443 - ORIGINAL_DST/172.217.22.14 - 52:54:00:bc:9f:73
> 1475101012.572 000447 192.168.10.112 NONE/200 0 CONNECT 
> 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
> 1475101033.232 000621 192.168.10.112 NONE/200 0 CONNECT 
> 31.13.66.49:443 - ORIGINAL_DST/31.13.66.49 - 52:54:00:bc:9f:73
> 1475101034.470 001224 192.168.10.112 TCP_MISS/200 512 GET 
> https://web.whatsapp.com/status.json - ORIGINAL_DST/31.13.66.49 
> text/json 52:54:00:bc:9f:73
> 1475101073.039 000446 192.168.10.112 NONE/200 0 CONNECT 
> 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
> 1475101133.502 000448 192.168.10.112 NONE/200 0 CONNECT 
> 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
> 
> Now the issue is more then just this since I cannot see any logs about the websocket connections ie to the domains:
> w3.web.whatsapp.com
> 

They might be in the ones with raw-IP in NONE/200 lines. Since server_name_regex matches against the TLS-cert details which do not necessarily get logged as a URL domain name when splice is done.

The SNI _should_ be made the CONNECT URI domain. But when it matches the server cert altSubjectName that is definitely not a client requested value.


> and couple other similar.
> 
> What I did until now is to bypass specific domains IP addresses using ipset+iptables.
> I believe that squid can do much better then it's doing now.

Can you get a packet dump to see what its TLS handshake details actually are? both client and server sides of Squid.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Tue Oct 25 01:16:39 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 25 Oct 2016 04:16:39 +0300
Subject: [squid-users] External nat'ed transparent proxy
In-Reply-To: <262ddf06-6781-a49b-335a-11a807a0ce73@treenet.co.nz>
References: <9cb02f45-ad81-7d77-0d7a-cf313c34f4fd@nitronetworks.nl>
 <20160930103642.GB29597@fantomas.sk>
 <57a01083-d569-cd4b-9d42-b6dc619cfd7c@nitronetworks.nl>
 <262ddf06-6781-a49b-335a-11a807a0ce73@treenet.co.nz>
Message-ID: <045401d22e5d$700d4600$5027d200$@ngtech.co.il>

+1 for Amos direction.
I am still trying to understand what is the difference between a router and a switch since they seems to have the same CPU but missing one or two embedded instructions.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Friday, September 30, 2016 20:36
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] External nat'ed transparent proxy

On 1/10/2016 12:27 a.m., Henry Paulissen wrote:
> Hi Matus,
> 
> 
> On 30-09-16 12:36, Matus UHLAR - fantomas wrote:
>> On 29.09.16 16:39, Henry Paulissen wrote:
>>> In the company I work for we are currently using squid v2 proxies in 
>>> transparent mode to intercept traffic from servers to the outside 
>>> (access control).
>>>
>>> The technical solution for this is roughly as follows:
>>> [server] -> [gateway] -> [firewall]
>>>                              |
>>>    ----------- DNAT ---------
>>>   v
>>> [squid]  -> [gateway] -> [firewall] -> [internet router]
>>
>> this is a bad configuration. The firewall in the path should NOT use 
>> DNAT, since it makes the important part of connection (destination 
>> IP) invisible to squid.
>>
> 
> That is where the HTTP Host header can be used for... For squid to 
> figure out the destination of the request. (aren?t they?)

That is what it was intended for 20 or so years ago. But times change and nowdays we have to deal with browsers that can be sent a scimple script and instructed to do all sorts of nasty things in the traffic. If you want the gory details you can find my prvious answers to people asking this same question repeatedly over the last 5 years.

The TL;DR is: no, that is no longer safe to do and Squid will not do it any more. Simply dont use DNAT on the port 80 (or 443) packets before they hit the machine running Squid. Routing is a more powerful feature than most realize, make use of it.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From garryd at comnet.uz  Tue Oct 25 05:35:09 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Tue, 25 Oct 2016 10:35:09 +0500
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <34080265b0f71525c3f304d3d5e3db66@comnet.uz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
 <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
 <578241c68e8e1238519585b8b1fc0151@comnet.uz>
 <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>
 <1477299550.5002.35.camel@comnet.uz>
 <bccae1dd-596c-7797-79d0-fb5fdee7297f@treenet.co.nz>
 <1477308726.5002.47.camel@comnet.uz>
 <86f78bf4-28ee-4f6a-b855-90a87d86a673@treenet.co.nz>
 <1477320007.5002.67.camel@comnet.uz>
 <34080265b0f71525c3f304d3d5e3db66@comnet.uz>
Message-ID: <1477373709.16301.25.camel@comnet.uz>

On Mon, 2016-10-24 at 21:05 +0500, Garri Djavadyan wrote:
> On 2016-10-24 19:40, Garri Djavadyan wrote:
> > 
> > So, the big G sends 304 only to HEAD requests, although it is a
> > violation [1], AIUI:
> > 
> > curl --head -H 'If-Modified-Since: Thu, 20 Oct 2016 08:29:09 GMT'
> > -H
> > 'If-None-Match: "101395"' http://dl.google.com/linux/direct/google-
> > chro
> > me-stable_current_amd64.deb
> > HTTP/1.1 304 Not Modified
> > ETag: "101395"
> > Server: downloads
> > Vary: *
> > X-Content-Type-Options: nosniff
> > X-Frame-Options: SAMEORIGIN
> > X-Xss-Protection: 1; mode=block
> > Date: Mon, 24 Oct 2016 14:36:32 GMT
> > Connection: keep-alive
> > 
> > ---
> > 
> > $ curl --verbose -H 'If-Modified-Since: Thu, 20 Oct 2016 08:29:09
> > GMT'
> > -H 'If-None-Match: "101395"' http://dl.google.com/linux/direct/goog
> > le-c
> > hrome-stable_current_amd64.deb > /dev/null
> > > 
> > > GET /linux/direct/google-chrome-stable_current_amd64.deb HTTP/1.1
> > > Host: dl.google.com
> > > User-Agent: curl/7.50.3
> > > Accept: */*
> > > If-Modified-Since: Thu, 20 Oct 2016 08:29:09 GMT
> > > If-None-Match: "101395"
> > > 
> > < HTTP/1.1 200 OK
> > < Accept-Ranges: bytes
> > < Content-Type: application/x-debian-package
> > < ETag: "101395"
> > < Last-Modified: Thu, 20 Oct 2016 08:29:09 GMT
> > < Server: downloads
> > < Vary: *
> > < X-Content-Type-Options: nosniff
> > < X-Frame-Options: SAMEORIGIN
> > < X-Xss-Protection: 1; mode=block
> > < Date: Mon, 24 Oct 2016 14:38:19 GMT
> > < Content-Length: 45532350
> > < Connection: keep-alive
> > 
> > [1] https://tools.ietf.org/html/rfc7234#section-4.3.5
> 
> Actually I mixed SHOULD agains MUST. The RFC 7231, section 4.3.2
> states?
> [1]:
> ...
> The server SHOULD send the same header fields in response to a HEAD?
> request as it would have sent if
> the request had been a GET, except that the payload header fields?
> (Section 3.3) MAY be omitted.
> ...
> 
> So, big G does not follow the recommendation, but does not violate
> the?
> standard.
> 
> [1] https://tools.ietf.org/html/rfc7231#section-4.3.2
> 
> Garri

I've overlooked that the statement applies to header _fields_, not to
reply code. The full paragraph states:

? ?The HEAD method is identical to GET except that the server MUST NOT
???send a message body in the response (i.e., the response terminates
? ?at the end of the header section).??The server SHOULD send the same
???header fields in response to a HEAD request as it would have sent if
???the request had been a GET, except that the payload header fields
???(Section 3.3) MAY be omitted.??This method can be used for obtaining
???metadata about the selected representation without transferring the
???representation data and is often used for testing hypertext links ?
? ?for validity, accessibility, and recent modification.

Nevertheless, the last sentence in the above excerpt use word 'can',
same for the following excerpt from section 4.3.5 [1]:

? ?A response to the HEAD method is identical to what an equivalent
???request made with a GET would have been, except it lacks a body.
? ?This property of HEAD responses can be used to invalidate or update
? ?a cached GET response if the more efficient conditional GET request
???mechanism is not available (due to no validators being present in ?
? ?the stored response) or if transmission of the representation body ?
? ?is not desired even if it has changed.

So, HEAD request _can_ be used as a reliable source for object
revalidation. How the 'can' should it be interpreted? RFC2119 [2] does
not specifies that.


AIUI, that exact case leaves two choices:

* Implement something like 'revalidate_using_head [[!]acl]
* Contact Google and inform about the behavior

The former is RFC-compliant way to solve that particular case, but
requires costly development efforts and may be useless after some time.
The latter may break HEAD revalidation also, but gives hopes that the
GET conditionals may be fixed.

[1]?https://tools.ietf.org/html/rfc7234#section-4.3.5
[2]?https://tools.ietf.org/html/rfc2119


From squid3 at treenet.co.nz  Tue Oct 25 07:50:27 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 25 Oct 2016 20:50:27 +1300
Subject: [squid-users] Caching Google Chrome
 googlechromestandaloneenterprise64.msi
In-Reply-To: <1477373709.16301.25.camel@comnet.uz>
References: <CA+kzyBKz3AfVd5doY8Cd9y-dkOeaM-vgegx4u1qc4m+DhCDZvQ@mail.gmail.com>
 <a4b5d054-a50e-227a-b3c5-3f351d73a258@gmail.com>
 <a12feaeb0e695a380f0db4eb6ad01f47@comnet.uz>
 <201610221456.11879.Antony.Stone@squid.open.source.it>
 <8a9105164e96b80eb06bfdb516ad2ab0@comnet.uz>
 <7323b009-8b12-6c65-9c01-e9e8b986629c@treenet.co.nz>
 <578241c68e8e1238519585b8b1fc0151@comnet.uz>
 <69977f75-8fb2-c43b-775f-80e64c549031@treenet.co.nz>
 <1477299550.5002.35.camel@comnet.uz>
 <bccae1dd-596c-7797-79d0-fb5fdee7297f@treenet.co.nz>
 <1477308726.5002.47.camel@comnet.uz>
 <86f78bf4-28ee-4f6a-b855-90a87d86a673@treenet.co.nz>
 <1477320007.5002.67.camel@comnet.uz>
 <34080265b0f71525c3f304d3d5e3db66@comnet.uz>
 <1477373709.16301.25.camel@comnet.uz>
Message-ID: <af4e889a-0a6e-1b15-81c6-91468d406fa4@treenet.co.nz>

On 25/10/2016 6:35 p.m., Garri Djavadyan wrote:
> 
> So, HEAD request _can_ be used as a reliable source for object
> revalidation. How the 'can' should it be interpreted? RFC2119 [2] does
> not specifies that.
> 
> 
> AIUI, that exact case leaves two choices:
> 
> * Implement something like 'revalidate_using_head [[!]acl]
> * Contact Google and inform about the behavior
> 

* or both would be better.

For now I'm applying the tested patch. HEAD revalidation is a much
larger project.


> The former is RFC-compliant way to solve that particular case, but
> requires costly development efforts and may be useless after some time.
> The latter may break HEAD revalidation also, but gives hopes that the
> GET conditionals may be fixed.
> 
> [1] https://tools.ietf.org/html/rfc7234#section-4.3.5
> [2] https://tools.ietf.org/html/rfc2119

Amos




From garth at bitco.co.za  Tue Oct 25 10:12:06 2016
From: garth at bitco.co.za (Garth van Sittert | BitCo)
Date: Tue, 25 Oct 2016 10:12:06 +0000
Subject: [squid-users] Squid with ASR9001
In-Reply-To: <043401d22e4b$86f62970$94e27c50$@ngtech.co.il>
References: <HE1PR01MB12108D2D44BA6ACBC6E75EF5F6D60@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <62d2a63b-b5db-40f9-445f-1087a4fc5850@gmail.com>
 <HE1PR01MB1210B9F41867169E17A0A2DAF6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <613eff0c-4cb9-75ea-e7f2-b4bccd95ce74@gmail.com>
 <HE1PR01MB12104763BDD60B87220FB257F6A90@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>
 <c4f64d19-91a1-91f3-bc39-fc72d5501b18@gmail.com>
 <032e01d22e1d$b802db90$280892b0$@ngtech.co.il>
 <bed8a892-c90a-8106-230a-11f494b3273d@gmail.com>
 <036301d22e26$b4594570$1d0bd050$@ngtech.co.il>
 <eebc0bc5-3166-ef19-731a-80ef00ee0671@gmail.com>
 <03fa01d22e41$f1a94540$d4fbcfc0$@ngtech.co.il>
 <bf758bde-6615-6556-d02b-e1e20178fafd@gmail.com>
 <041201d22e48$b9667bb0$2c337310$@ngtech.co.il>
 <50260e55-a014-8612-4418-d3eed32593b7@gmail.com>
 <043401d22e4b$86f62970$94e27c50$@ngtech.co.il>
Message-ID: <HE1PR01MB12104F835A686D4346C8C167F6A80@HE1PR01MB1210.eurprd01.prod.exchangelabs.com>

Would any of you Cisco experts know how to use ABF to route only http to a Squid server? ?

        https://supportforums.cisco.com/document/145271/abf-acl-based-forwarding-asr9k

We?ve tested intercept on a Mikrotik successfully by marking http traffic and sending it through to a different routing table.  This works well on Mikrotik but we cannot find anything other than WCCP examples on Cisco.

This would be a good addition to the examples on http://wiki.squid-cache.org/ConfigExamples/Intercept/

Kind Regards
Garth



_____________________________________________
From: Eliezer Croitoru [mailto:eliezer at ngtech.co.il]
Sent: Tuesday, 25 October 2016 1:08 AM
To: 'Yuri Voinov' <yvoinov at gmail.com>
Cc: Garth van Sittert | BitCo <garth at bitco.co.za>; squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Squid with ASR9001


I do not need them that much but I know they use a special Packet Forwarding IE routing engine to  overcome most of the issues that may arise by many routing policies.
It would work the same fine for a Linux based OS and  I am pretty sure that many of these do use these engines.

Eliezer


From: Yuri Voinov [mailto:yvoinov at gmail.com]
Sent: Tuesday, October 25, 2016 02:03
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: 'Garth van Sittert | BitCo' <garth at bitco.co.za>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid with ASR9001


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

No, Juniper is not my area. :)

It is impossible to know everything :)

25.10.2016 4:48, Eliezer Croitoru ?????:
> By any chance do you have any
      experience\example with juniper interception?

      > They seems to do everything in the IP level policy and not
      Bridge level.

      >

      > Eliezer

      >

      > ----

      > Eliezer Croitoru <http://ngtech.co.il/lmgtfy/><http://ngtech.co.il/lmgtfy/>

      > Linux System Administrator

      > Mobile: +972-5-28704261

      > Email: eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>

      >

      >

      > From: Yuri Voinov [mailto:yvoinov at gmail.com]

      > Sent: Tuesday, October 25, 2016 01:07

      > To: Eliezer Croitoru <eliezer at ngtech.co.il><mailto:eliezer at ngtech.co.il>

      > Cc: 'Garth van Sittert | BitCo' <garth at bitco.co.za><mailto:garth at bitco.co.za>;

      > squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

      > Subject: Re: [squid-users] Squid with ASR9001

      >

      >

      > Compared with PBR - definitely.

      >

      > IF OS TCP stack supports bridging - exactly.

      >

      > 25.10.2016 3:59, Eliezer Croitoru ?????:

      > > So what you are illustrating is

      >       that if we will handle the connection

      >

      >       > interception using bridge tables it would be much
      more

      >       efficient then Policy

      >

      >       > Based routing.

      >

      >       > I believe it?s very simple to implement in linux.

      >

      >

      >

      >       > Eliezer

      >

      >

      >

      >       > ----

      >

      >       > Eliezer Croitoru
      <http://ngtech.co.il/lmgtfy/><http://ngtech.co.il/lmgtfy/>

      > <http://ngtech.co.il/lmgtfy/><http://ngtech.co.il/lmgtfy/>

      >

      >       > Linux System Administrator

      >

      >       > Mobile: +972-5-28704261

      >

      >       > Email: eliezer at ngtech.co.il<mailto:eliezer at ngtech.co.il>
      <mailto:eliezer at ngtech.co.il><mailto:eliezer at ngtech.co.il>

      >

      >

      >

      >

      >

      >       > From: Yuri Voinov [mailto:yvoinov at gmail.com]

      >

      >       > Sent: Monday, October 24, 2016 22:01

      >

      >       > To: Eliezer Croitoru <eliezer at ngtech.co.il><mailto:eliezer at ngtech.co.il>

      > <mailto:eliezer at ngtech.co.il><mailto:eliezer at ngtech.co.il>

      >

      >       > Cc: 'Garth van Sittert | BitCo'
      <garth at bitco.co.za><mailto:garth at bitco.co.za>

      > <mailto:garth at bitco.co.za><mailto:garth at bitco.co.za> ;

      >

      >       > squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

      > <mailto:squid-users at lists.squid-cache.org><mailto:squid-users at lists.squid-cache.org>

      >

      >       > Subject: Re: [squid-users] Squid with ASR9001

      >

[BitCo Email Footer]<https://www.google.co.za/maps/place/Wedgewood+Office+Park/@-26.04982,28.0196914,17z/data=!3m1!4b1!4m5!3m4!1s0x142989bce6c63b3:0xc0b44878907297f4!8m2!3d-26.04982!4d28.0218801>

The information contained in this message is intended solely for the individual to whom it is specifically and originally addressed. This message and its contents may contain confidential or privileged information from BitCo. If you are not the intended recipient, you are hereby notified that any disclosure or distribution, is strictly prohibited. If you receive this email in error, please notify BitCo immediately and delete it. BitCo does not accept any liability or responsibility if action is taken in reliance on the contents of this information.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/8585d723/attachment.htm>

From squid3 at treenet.co.nz  Tue Oct 25 11:13:50 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 26 Oct 2016 00:13:50 +1300
Subject: [squid-users] skype connection problem
In-Reply-To: <53fbc061-28e6-9445-89a1-053632d94c24@gmail.com>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <0dc219d6-e5b2-8473-822d-df6ec51d57ed@gmail.com>
 <53fbc061-28e6-9445-89a1-053632d94c24@gmail.com>
Message-ID: <b3a04049-9deb-0943-0f07-2bdd37acec74@treenet.co.nz>

On 25/10/2016 5:19 a.m., Nicolas Valera wrote:
> Hi Yuri, thanks for the answer!
> 
> we don't have the squid in transparent mode in this network.
> the squid configuration is very basic. here is the conf:
> 
> -------------------------------------------------------------------------
> http_port 1280 connection-auth=off
> forwarded_for delete
> httpd_suppress_version_string on
> client_persistent_connections off
> 
> cache_mem 16 GB
> maximum_object_size_in_memory 8 MB
> 
> url_rewrite_program /usr/bin/squidGuard

These...

> url_rewrite_children 10
> url_rewrite_access allow all

... are redundant. That is the default values for those directives.

> 
> acl numeric_IPs dstdom_regex
> ^(([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)|(\[([0-9a-f]+)?:([0-9a-f:]+)?:([0-9a-f]+|0-9\.]+)?\])):443
> 
> acl Skype_UA browser ^skype
> 
> acl SSL_ports port 443 563 873 1445 2083 8000 8088 10017 8443 5443 7443
> 50001
> acl Safe_ports port 80 82 88 182 210 554 591 777 873 1001 21 443 70 280 488
> acl Safe_ports port 1025-65535  # unregistered ports
> 
> acl CONNECT method CONNECT
> acl safe_method method GET
> acl safe_method method PUT
> acl safe_method method POST
> acl safe_method method HEAD
> acl safe_method method CONNECT
> acl safe_method method OPTIONS
> acl safe_method method PROPFIND
> acl safe_method method REPORT
> acl safe_method method MERGE
> acl safe_method method MKACTIVITY
> acl safe_method method CHECKOUT

Whats the point of this ACL ?


> 
> http_access deny !Safe_ports
> http_access allow CONNECT localnet numeric_IPS Skype_UA
> http_access deny CONNECT !SSL_ports
> http_access deny !safe_method
> http_access allow localnet
> http_access allow localhost
> http_access deny all
> 
> refresh_pattern ^ftp:        1440    20%    10080
> refresh_pattern ^gopher:    1440    0%    1440
> refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
> refresh_pattern Packages\.tar$ 0       20%    4320 refresh-ims
> ignore-no-cache
> refresh_pattern Packages\.bz2$ 0       20%    4320 refresh-ims
> ignore-no-cache
> refresh_pattern Sources\.bz2$  0       20%    4320 refresh-ims
> ignore-no-cache
> refresh_pattern Release\.gpg$  0       20%    4320 refresh-ims
> refresh_pattern Release$       0       20%    4320 refresh-ims
> refresh_pattern -i
> microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
> 43200 reload-into-ims ignore-no-cache
> refresh_pattern -i
> windowsupdate.com/.*\.(esd|cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
> 4320 80% 43200 reload-into-ims ignore-no-cache
> refresh_pattern -i
> windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
> 43200 reload-into-ims ignore-no-cache
> refresh_pattern -i
> live.net/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
> reload-into-ims ignore-no-cache
> refresh_pattern .        0    20%    4320
> 

All those "ignore-no-cache" are not useful. Run "squid -k parse" and it
should mention they are no longer supported.

Amos


From squid3 at treenet.co.nz  Tue Oct 25 11:25:30 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 26 Oct 2016 00:25:30 +1300
Subject: [squid-users] Error "ipcacheParse: No Address records in
 response to"
In-Reply-To: <1477324108761-4680255.post@n4.nabble.com>
References: <1477322651492-4680254.post@n4.nabble.com>
 <1477324108761-4680255.post@n4.nabble.com>
Message-ID: <b2cf556f-392c-6f56-354a-0288127c0d04@treenet.co.nz>

On 25/10/2016 4:48 a.m., erdosain9 wrote:
> By the way...
> 
> When i get this error
> 
> 2016/10/24 12:13:36 kid1| ipcacheParse: No Address records in response to
> 'client.wns.windows.com' 
> 2016/10/24 12:13:36 kid1| ipcacheParse: No Address records in response to
> 'client.wns.windows.com' 
> 2016/10/24 12:13:36 kid1| ipcacheParse: No Address records in response to
> 'client.wns.windows.com' 
> 2016/10/24 12:13:36 kid1| ipcacheParse: No Address records in response to
> 'skp03.epimg.net' 
> 2016/10/24 12:13:36 kid1| ipcacheParse: No Address records in response to
> 'www.msftncsi.com' 
> 2016/10/24 12:13:41 kid1| ipcacheParse: No Address records in response to
> 'client-s.gateway.messenger.live.com' 
> 2016/10/24 12:13:41 kid1| ipcacheParse: No Address records in response to
> 'client-s.gateway.messenger.live.com' 
> 2016/10/24 12:13:41 kid1| ipcacheParse: No Address records in response to
> 'client-s.gateway.messenger.live.com' 
> 2016/10/24 12:13:54 kid1| Error negotiating SSL connection on FD 76: (104)
> Connection reset by peer 
> 2016/10/24 12:14:06 kid1| ipcacheParse: No Address records in response to
> 'www.posadadonantonio.com' 
> 2016/10/24 12:14:06 kid1| ipcacheParse: No Address records in response to
> 'www.posadadonantonio.com' 
> 2016/10/24 12:14:16 kid1| ipcacheParse: No Address records in response to
> 'www.msftncsi.com' 
> 2016/10/24 12:14:31 kid1| ipcacheParse: No Address records in response to
> 'c.live.com' 
> 

Those names are aliases that refer via CNAME records to another name
which is an alias using CNAME record to point at an alias which is a
CNAME record ...

What you are calling an error is just a message that your DNS server is
not providing any IP address when those names are looked up by Squid.

Squid cannot do anything about that.


> 
> 
> I put
> 
> set envar ipv6=yes
> 
> in juniper
> 
> and this error not happen again , but google sometimes give a ipv6, and
> squid dosent work then.....
> 

What is the output of "squid -v" ?
 If it contains "--disable-ipv6" then you need a build of Squid without
that option.

If squid -v does not mention that option, what do you mean by "squid
dosent work" ?

Amos



From heiler.bemerguy at cinbesa.com.br  Tue Oct 25 13:26:06 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 25 Oct 2016 10:26:06 -0300
Subject: [squid-users] RANGED requests still a pain for me..
Message-ID: <1fa457f8-34b9-5c68-5a21-0f907898142f@cinbesa.com.br>

These firefox updates takes weeks to be really cached.. it won't cache 
if more than 1 person is trying to download at the same time.. but WHY 
does this happen?
I've filled a bug report about this *TCP_SWAPFAIL_MISS*, but it seems no 
one is interested.. lol RockStore BTW

*acl fullDLext urlpath_regex -i 
\.(exe|ms[iup]|cab|bin|zip|mar|pdf|appx(bundle)?|esd|lzma2)\??**
**range_offset_limit -1 fullDLext*


1477401191.608   5151 10.61.0.67 TCP_MISS/206 300542 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.209 application/octet-stream
1477401192.592 206375 10.20.1.2 TCP_MISS/206 300544 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.203 application/octet-stream
1477401223.080 189489 10.22.0.170 TCP_MISS/206 300544 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.203 application/octet-stream
1477401249.934 115769 10.42.0.35 TCP_SWAPFAIL_MISS/206 300544 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.209 application/octet-stream
1477401254.789   9990 10.88.75.39 TCP_MISS/206 300542 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.209 application/octet-stream
1477401257.163   4259 10.61.0.67 TCP_MISS/206 300542 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.209 application/octet-stream
1477401258.363  40266 10.82.3.75 TCP_MISS/206 300542 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.209 application/octet-stream
1477401289.774  67097 10.42.0.16 TCP_MISS/206 300544 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.209 application/octet-stream
1477401292.236  86726 10.42.0.39 TCP_SWAPFAIL_MISS/206 300544 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.209 application/octet-stream
1477401322.618   7778 10.88.75.39 TCP_MISS/206 300542 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.203 application/octet-stream
1477401322.825  91270 10.42.0.27 TCP_MISS/206 300544 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.209 application/octet-stream
1477401329.305  11130 10.61.0.67 TCP_MISS/206 300542 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.203 application/octet-stream
1477401331.331  21370 10.42.0.35 TCP_MISS/206 300544 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.203 application/octet-stream
1477401333.559 149961 10.112.0.180 TCP_SWAPFAIL_MISS/206 300544 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.209 application/octet-stream
1477401337.498 354278 10.92.0.236 TCP_MISS/206 300544 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/201.30.251.11 application/octet-stream
1477401345.123  92307 10.20.1.2 TCP_MISS/206 300544 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.209 application/octet-stream
1477401355.231 486327 10.32.0.247 TCP_MISS/206 300544 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.203 application/octet-stream
1477401358.732 389591 10.88.10.1 TCP_MISS/206 300544 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/201.30.251.11 application/octet-stream
1477401382.833 395352 10.22.0.118 TCP_MISS/206 300544 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/201.30.251.9 application/octet-stream
1477401390.293   7422 10.88.75.39 TCP_MISS/206 300542 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.203 application/octet-stream
1477401408.065   2621 10.20.1.2 TCP_MISS_ABORTED/206 544 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.203 application/octet-stream
1477401416.541  33712 10.42.0.27 TCP_MISS/206 300544 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.203 application/octet-stream
1477401419.167 100779 10.82.3.75 TCP_MISS/206 300542 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.203 application/octet-stream
1477401448.025  57668 10.61.0.67 TCP_MISS/206 300542 GET 
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar 
- HIER_DIRECT/200.149.150.203 application/octet-stream


-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/e9d8ce7e/attachment.htm>

From nvalera at gmail.com  Tue Oct 25 14:19:12 2016
From: nvalera at gmail.com (Nicolas Valera)
Date: Tue, 25 Oct 2016 11:19:12 -0300
Subject: [squid-users] skype connection problem
In-Reply-To: <031501d22e18$93029b00$b907d100$@ngtech.co.il>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <031501d22e18$93029b00$b907d100$@ngtech.co.il>
Message-ID: <2d005fe0-4b41-e96a-d4ee-f8e8b1a10cb6@gmail.com>

Hi Eliezer, thanks for the answer!

On 10/24/2016 02:03 PM, Eliezer Croitoru wrote:
> Just to understand the scenario:
> You have let say 1 client on network 192.168.0.0/24
> You have a proxy at 192.168.0.200
> The client doesn?t have a gateway in the network IE cannot run dns queries
> or pings to the internet.
> The client must define the proxy in order to access any Internet resources.
> Right?

Yes, you're right!
So, in this scenario, the skype will never work?

> The proxy have access to dns and the ip stack natted or not.
>
> I believe it would be pretty simple to reproduced in order to verify the
> issue by another party.
>
> Let me know if I got the situation right.
>
> Eliezer
>
> ----
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of N V
> Sent: Monday, October 24, 2016 01:11
> To: squid-users at squid-cache.org
> Subject: [squid-users] skype connection problem
>
> hi there,
> i've had problems with windows skype clients with the only internet
> connection is through squid. the clients can login successful but when they
> make a call, it hangs after 12 secconds.
>
> I checked the client connections and see that attempts to connect directly
> even if the proxy is properly configured.
>
> my squid version is 3.5.12
> the skype clients have the last version available.
> does anyone have the same issues?
> any idea?
>
> thanks in advance!
> Nicol?s.
>
> pd. sorry about my english
>


From nvalera at gmail.com  Tue Oct 25 14:25:35 2016
From: nvalera at gmail.com (Nicolas Valera)
Date: Tue, 25 Oct 2016 11:25:35 -0300
Subject: [squid-users] skype connection problem
In-Reply-To: <b3a04049-9deb-0943-0f07-2bdd37acec74@treenet.co.nz>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <0dc219d6-e5b2-8473-822d-df6ec51d57ed@gmail.com>
 <53fbc061-28e6-9445-89a1-053632d94c24@gmail.com>
 <b3a04049-9deb-0943-0f07-2bdd37acec74@treenet.co.nz>
Message-ID: <6e48d0b8-8922-9c3a-4ec3-1dfdec96be8c@gmail.com>

Amos, thanks for the tips!
any idea about my skype problem?

regards

On 10/25/2016 08:13 AM, Amos Jeffries wrote:
> On 25/10/2016 5:19 a.m., Nicolas Valera wrote:
>> Hi Yuri, thanks for the answer!
>>
>> we don't have the squid in transparent mode in this network.
>> the squid configuration is very basic. here is the conf:
>>
>> -------------------------------------------------------------------------
>> http_port 1280 connection-auth=off
>> forwarded_for delete
>> httpd_suppress_version_string on
>> client_persistent_connections off
>>
>> cache_mem 16 GB
>> maximum_object_size_in_memory 8 MB
>>
>> url_rewrite_program /usr/bin/squidGuard
>
> These...
>
>> url_rewrite_children 10
>> url_rewrite_access allow all
>
> ... are redundant. That is the default values for those directives.
>
>>
>> acl numeric_IPs dstdom_regex
>> ^(([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)|(\[([0-9a-f]+)?:([0-9a-f:]+)?:([0-9a-f]+|0-9\.]+)?\])):443
>>
>> acl Skype_UA browser ^skype
>>
>> acl SSL_ports port 443 563 873 1445 2083 8000 8088 10017 8443 5443 7443
>> 50001
>> acl Safe_ports port 80 82 88 182 210 554 591 777 873 1001 21 443 70 280 488
>> acl Safe_ports port 1025-65535  # unregistered ports
>>
>> acl CONNECT method CONNECT
>> acl safe_method method GET
>> acl safe_method method PUT
>> acl safe_method method POST
>> acl safe_method method HEAD
>> acl safe_method method CONNECT
>> acl safe_method method OPTIONS
>> acl safe_method method PROPFIND
>> acl safe_method method REPORT
>> acl safe_method method MERGE
>> acl safe_method method MKACTIVITY
>> acl safe_method method CHECKOUT
>
> Whats the point of this ACL ?
>
>
>>
>> http_access deny !Safe_ports
>> http_access allow CONNECT localnet numeric_IPS Skype_UA
>> http_access deny CONNECT !SSL_ports
>> http_access deny !safe_method
>> http_access allow localnet
>> http_access allow localhost
>> http_access deny all
>>
>> refresh_pattern ^ftp:        1440    20%    10080
>> refresh_pattern ^gopher:    1440    0%    1440
>> refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
>> refresh_pattern Packages\.tar$ 0       20%    4320 refresh-ims
>> ignore-no-cache
>> refresh_pattern Packages\.bz2$ 0       20%    4320 refresh-ims
>> ignore-no-cache
>> refresh_pattern Sources\.bz2$  0       20%    4320 refresh-ims
>> ignore-no-cache
>> refresh_pattern Release\.gpg$  0       20%    4320 refresh-ims
>> refresh_pattern Release$       0       20%    4320 refresh-ims
>> refresh_pattern -i
>> microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
>> 43200 reload-into-ims ignore-no-cache
>> refresh_pattern -i
>> windowsupdate.com/.*\.(esd|cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
>> 4320 80% 43200 reload-into-ims ignore-no-cache
>> refresh_pattern -i
>> windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
>> 43200 reload-into-ims ignore-no-cache
>> refresh_pattern -i
>> live.net/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
>> reload-into-ims ignore-no-cache
>> refresh_pattern .        0    20%    4320
>>
>
> All those "ignore-no-cache" are not useful. Run "squid -k parse" and it
> should mention they are no longer supported.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From yvoinov at gmail.com  Tue Oct 25 14:26:48 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 25 Oct 2016 20:26:48 +0600
Subject: [squid-users] skype connection problem
In-Reply-To: <6e48d0b8-8922-9c3a-4ec3-1dfdec96be8c@gmail.com>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <0dc219d6-e5b2-8473-822d-df6ec51d57ed@gmail.com>
 <53fbc061-28e6-9445-89a1-053632d94c24@gmail.com>
 <b3a04049-9deb-0943-0f07-2bdd37acec74@treenet.co.nz>
 <6e48d0b8-8922-9c3a-4ec3-1dfdec96be8c@gmail.com>
Message-ID: <ebb3917e-4698-3c4b-8979-b879eed93a14@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
You LAN settings is too restrictive. AFAIK you require to permit traffic
to skype servers directly from your clients. Without proxy.

Because of Skype voice traffic is non-HTTP(S). And proxy can't know how
to handle it.


25.10.2016 20:25, Nicolas Valera ?????:
> Amos, thanks for the tips!
> any idea about my skype problem?
>
> regards
>
> On 10/25/2016 08:13 AM, Amos Jeffries wrote:
>> On 25/10/2016 5:19 a.m., Nicolas Valera wrote:
>>> Hi Yuri, thanks for the answer!
>>>
>>> we don't have the squid in transparent mode in this network.
>>> the squid configuration is very basic. here is the conf:
>>>
>>>
-------------------------------------------------------------------------
>>> http_port 1280 connection-auth=off
>>> forwarded_for delete
>>> httpd_suppress_version_string on
>>> client_persistent_connections off
>>>
>>> cache_mem 16 GB
>>> maximum_object_size_in_memory 8 MB
>>>
>>> url_rewrite_program /usr/bin/squidGuard
>>
>> These...
>>
>>> url_rewrite_children 10
>>> url_rewrite_access allow all
>>
>> ... are redundant. That is the default values for those directives.
>>
>>>
>>> acl numeric_IPs dstdom_regex
>>>
^(([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)|(\[([0-9a-f]+)?:([0-9a-f:]+)?:([0-9a-f]+|0-9\.]+)?\])):443
>>>
>>> acl Skype_UA browser ^skype
>>>
>>> acl SSL_ports port 443 563 873 1445 2083 8000 8088 10017 8443 5443 7443
>>> 50001
>>> acl Safe_ports port 80 82 88 182 210 554 591 777 873 1001 21 443 70
280 488
>>> acl Safe_ports port 1025-65535  # unregistered ports
>>>
>>> acl CONNECT method CONNECT
>>> acl safe_method method GET
>>> acl safe_method method PUT
>>> acl safe_method method POST
>>> acl safe_method method HEAD
>>> acl safe_method method CONNECT
>>> acl safe_method method OPTIONS
>>> acl safe_method method PROPFIND
>>> acl safe_method method REPORT
>>> acl safe_method method MERGE
>>> acl safe_method method MKACTIVITY
>>> acl safe_method method CHECKOUT
>>
>> Whats the point of this ACL ?
>>
>>
>>>
>>> http_access deny !Safe_ports
>>> http_access allow CONNECT localnet numeric_IPS Skype_UA
>>> http_access deny CONNECT !SSL_ports
>>> http_access deny !safe_method
>>> http_access allow localnet
>>> http_access allow localhost
>>> http_access deny all
>>>
>>> refresh_pattern ^ftp:        1440    20%    10080
>>> refresh_pattern ^gopher:    1440    0%    1440
>>> refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
>>> refresh_pattern Packages\.tar$ 0       20%    4320 refresh-ims
>>> ignore-no-cache
>>> refresh_pattern Packages\.bz2$ 0       20%    4320 refresh-ims
>>> ignore-no-cache
>>> refresh_pattern Sources\.bz2$  0       20%    4320 refresh-ims
>>> ignore-no-cache
>>> refresh_pattern Release\.gpg$  0       20%    4320 refresh-ims
>>> refresh_pattern Release$       0       20%    4320 refresh-ims
>>> refresh_pattern -i
>>> microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
>>> 43200 reload-into-ims ignore-no-cache
>>> refresh_pattern -i
>>> windowsupdate.com/.*\.(esd|cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip)
>>> 4320 80% 43200 reload-into-ims ignore-no-cache
>>> refresh_pattern -i
>>> windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
>>> 43200 reload-into-ims ignore-no-cache
>>> refresh_pattern -i
>>> live.net/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200
>>> reload-into-ims ignore-no-cache
>>> refresh_pattern .        0    20%    4320
>>>
>>
>> All those "ignore-no-cache" are not useful. Run "squid -k parse" and it
>> should mention they are no longer supported.
>>
>> Amos
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYD2uoAAoJENNXIZxhPexGX1IIAI+JWytszKKX9ArRjDioUmeU
6tyWfumjWiiASMDV83MOtS54cuhy1UMGzXoHuJBb+aqo76suXQVI/w+fO987go6g
fU6lm0xsSnXDbcwoIahSmfoevDsP6dQzGAXDWv1Q3Tqky+mPc/xtNlISO/5BhHL0
JzAkl/XFIzDZFraTJOOuJXiQ7FoMhwsICWL8hO7+OiRR6vpuPlxruuzYNbqLBxD2
3LPMbgv67XsitcdM21jsiR+CrO/7VeIcoOcbwpE8yE8dM03ldRq8+PoUmUtUut77
cQZl+7j2Fyh7H08vqAp46fFcWoAyiebPW+SnNh5zCLhw4XBHBp4vK3bqQCQOp3o=
=17cK
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/46270587/attachment.key>

From eliezer at ngtech.co.il  Tue Oct 25 14:35:19 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 25 Oct 2016 17:35:19 +0300
Subject: [squid-users] skype connection problem
In-Reply-To: <2d005fe0-4b41-e96a-d4ee-f8e8b1a10cb6@gmail.com>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <031501d22e18$93029b00$b907d100$@ngtech.co.il>
 <2d005fe0-4b41-e96a-d4ee-f8e8b1a10cb6@gmail.com>
Message-ID: <062601d22ecd$02d56ac0$08804040$@ngtech.co.il>

Hey Nicolas,

I know that it should work but it will request all sort of weird CONNECT requests to other parties.
Skype is designed to work as a p2p network and there for might not work as expected in your environment.
I will try myself to test it and see how if and how it works in a very specific scenario.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Nicolas Valera [mailto:nvalera at gmail.com] 
Sent: Tuesday, October 25, 2016 17:19
To: Eliezer Croitoru <eliezer at ngtech.co.il>; squid-users at squid-cache.org
Subject: Re: [squid-users] skype connection problem

Hi Eliezer, thanks for the answer!

On 10/24/2016 02:03 PM, Eliezer Croitoru wrote:
> Just to understand the scenario:
> You have let say 1 client on network 192.168.0.0/24 You have a proxy 
> at 192.168.0.200 The client doesn?t have a gateway in the network IE 
> cannot run dns queries or pings to the internet.
> The client must define the proxy in order to access any Internet resources.
> Right?

Yes, you're right!
So, in this scenario, the skype will never work?

> The proxy have access to dns and the ip stack natted or not.
>
> I believe it would be pretty simple to reproduced in order to verify 
> the issue by another party.
>
> Let me know if I got the situation right.
>
> Eliezer
>
> ----
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> Linux System 
> Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
> On Behalf Of N V
> Sent: Monday, October 24, 2016 01:11
> To: squid-users at squid-cache.org
> Subject: [squid-users] skype connection problem
>
> hi there,
> i've had problems with windows skype clients with the only internet 
> connection is through squid. the clients can login successful but when 
> they make a call, it hangs after 12 secconds.
>
> I checked the client connections and see that attempts to connect 
> directly even if the proxy is properly configured.
>
> my squid version is 3.5.12
> the skype clients have the last version available.
> does anyone have the same issues?
> any idea?
>
> thanks in advance!
> Nicol?s.
>
> pd. sorry about my english
>



From yvoinov at gmail.com  Tue Oct 25 14:37:00 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 25 Oct 2016 20:37:00 +0600
Subject: [squid-users] skype connection problem
In-Reply-To: <062601d22ecd$02d56ac0$08804040$@ngtech.co.il>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <031501d22e18$93029b00$b907d100$@ngtech.co.il>
 <2d005fe0-4b41-e96a-d4ee-f8e8b1a10cb6@gmail.com>
 <062601d22ecd$02d56ac0$08804040$@ngtech.co.il>
Message-ID: <55117246-90c3-db39-98c2-8cf02e63e84f@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


25.10.2016 20:35, Eliezer Croitoru ?????:
> Hey Nicolas,
>
> I know that it should work but it will request all sort of weird
CONNECT requests to other parties.
> Skype is designed to work as a p2p network and there for might not
work as expected in your environment.
Not p2p already. Via central MS servers.
>
> I will try myself to test it and see how if and how it works in a very
specific scenario.
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: Nicolas Valera [mailto:nvalera at gmail.com]
> Sent: Tuesday, October 25, 2016 17:19
> To: Eliezer Croitoru <eliezer at ngtech.co.il>; squid-users at squid-cache.org
> Subject: Re: [squid-users] skype connection problem
>
> Hi Eliezer, thanks for the answer!
>
> On 10/24/2016 02:03 PM, Eliezer Croitoru wrote:
>> Just to understand the scenario:
>> You have let say 1 client on network 192.168.0.0/24 You have a proxy
>> at 192.168.0.200 The client doesn?t have a gateway in the network IE
>> cannot run dns queries or pings to the internet.
>> The client must define the proxy in order to access any Internet
resources.
>> Right?
>
> Yes, you're right!
> So, in this scenario, the skype will never work?
>
>> The proxy have access to dns and the ip stack natted or not.
>>
>> I believe it would be pretty simple to reproduced in order to verify
>> the issue by another party.
>>
>> Let me know if I got the situation right.
>>
>> Eliezer
>>
>> ----
>> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> Linux System
>> Administrator
>> Mobile: +972-5-28704261
>> Email: eliezer at ngtech.co.il
>>
>>
>> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
>> On Behalf Of N V
>> Sent: Monday, October 24, 2016 01:11
>> To: squid-users at squid-cache.org
>> Subject: [squid-users] skype connection problem
>>
>> hi there,
>> i've had problems with windows skype clients with the only internet
>> connection is through squid. the clients can login successful but when
>> they make a call, it hangs after 12 secconds.
>>
>> I checked the client connections and see that attempts to connect
>> directly even if the proxy is properly configured.
>>
>> my squid version is 3.5.12
>> the skype clients have the last version available.
>> does anyone have the same issues?
>> any idea?
>>
>> thanks in advance!
>> Nicol?s.
>>
>> pd. sorry about my english
>>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYD24MAAoJENNXIZxhPexG304H+gP1bJInqvHfXc7cc3REamTq
nGg5dLPlCYxiaxw6lBxbexsZ6QXJCc28yokJhXjMzce9F1bDzc0MBuGnz1tsDJBk
kkPp6PoArMHNQGSofVBiLFEGNKTeWSu2/PxB1Xc0zwwwoscaXuz/9XSWwuR9KoEH
r84uTOHDMDzYCFs/JQ7KlI+i1RkJFMHWqViQ+jknITd6DhtVEUO80eLjjlK7zLUA
824mgT0DCx9rI18i9x+RETE1rFcIwYL99qhNdPK0drdVx1X/WrifDNUwNaekXoTA
7LPg94gFRP/O632ensHAMoi2j77IbPckwi5KOsTjiBbVCBUm1uVyILMnQrbf06Q=
=WbGB
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/f8e29b4d/attachment.key>

From eliezer at ngtech.co.il  Tue Oct 25 14:38:41 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 25 Oct 2016 17:38:41 +0300
Subject: [squid-users] External nat'ed transparent proxy
In-Reply-To: <789f52cc-6929-0719-9e3b-7378bdf37343@nitronetworks.nl>
References: <9cb02f45-ad81-7d77-0d7a-cf313c34f4fd@nitronetworks.nl>
 <!&!AAAAAAAAAAAuAAAAAAAAAP1vRcAAnWlNoU7f4f0YNhgBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADQt4cUeAlsQ6ihb0bN4K2wAQAAAAA=@ngtech.co.il>
 <789f52cc-6929-0719-9e3b-7378bdf37343@nitronetworks.nl>
Message-ID: <063101d22ecd$7b0c6930$71253b90$@ngtech.co.il>

Hey,

As Amos suggested you should use Policy based routing and not DNAT.
The main reason for that is since it's breaking the Interception layer which squid relies on for fallback scenarios.

I can write the logic for this pretty fast but you should first understand that your setup is wrong in a way.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Henry Paulissen [mailto:henry at nitronetworks.nl] 
Sent: Friday, September 30, 2016 12:48
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] External nat'ed transparent proxy

Good morning Eliezer,


It took some time for me to construct a drawing who would be understandable enough how our setup is, as the diagrams you provided didn't fully fit the case. But, I think I managed to make a understandable drawing of it :-)

[ Link to PNG image ]
https://drive.google.com/file/d/0BysciyDBahUtWU55RjNPUlFjMTQ/view


Some additional info with the drwaing:
  - Each linux firewall server handles top ~5G traffic. After that we
    build a new firewall cluster and new servers are connected to
    that one.

  - The linux firewall is gateway for the vlan.

  - As you might know: LVS is internally also a DNAT, so bassicly we do
    a double DNAT.

  - The green and blue line indicates how the traffic is routed

  - Linux firewalls is physical hardware, but all the servers
    (including the squid hosts) are linux vservers (like LXC containers
    or docker containers).


Hopes this clears up our setup and where I run into problems with squid3.

Regards,

--
Henry Paulissen - PD0OM
henry at nitronetworks.nl - Phone: +31-(0)6-115.305.64 Linux/Unix System Engineer

On 30-09-16 00:35, Eliezer Croitoru wrote:
> Hey Henry,
> 
> I want to emulate the setup to understand the complication with a FULL linux based setup here on my local testing grounds.
> Can you give more details on the networks in the form of subnets and VLAN numbers?
> What is not clear to me is: Who is doing the DNAT?
> Also, if you have not used tproxy and intercept on the PROXY machine you should re-think the whole logic of the system first before deciding on the next step.
> There are systems which needs redesign when moving from Squid 2 to 3 or 4.
> When I and you will have the right understanding of the scenario I believe we can find the right path if this is not already there.
> 
> Let me know if these( the diagrams..):
> http://wiki.squid-cache.org/EliezerCroitoru/Drafts/MwanLB#Intoduction_
> to_MultiWAN_LoadBalancing
> http://wiki.squid-cache.org/ConfigExamples/UbuntuTproxy4Wccp2
> 
> Make any sense to you so we can find the right words to fill the gaps in the situation.
> Once I will have the right picture I would probably have enough information to draw some picture in VISIO and move forward to the Systems table.
> 
> Eliezer
> 
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile+WhatsApp: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
> 
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
> On Behalf Of Henry Paulissen
> Sent: Thursday, September 29, 2016 5:40 PM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] External nat'ed transparent proxy
> 
> Hi all,
> 
> In the company I work for we are currently using squid v2 proxies in transparent mode to intercept traffic from servers to the outside (access control).
> 
> The technical solution for this is roughly as follows:
> [server] -> [gateway] -> [firewall]
>                               |
>     ----------- DNAT ---------
>    v
> [squid]  -> [gateway] -> [firewall] -> [internet router]
> 
> Our firewalls (who live between the vlan gateway and internet router), DNAT the traffic towards separate squid proxies (who are in a lvs cluster). These squid proxies are in their own vlan with special permissions to allow unrestricted port 80 outbound, etc, etc...
> 
> Because squid v2 is becoming more and more obsolete we are looking at upgrading it towards squid v3.
> 
> From what I read in the manuals, transparent mode is replaced by intercept (and tproxy) mode. But both dont seem to be fully backward complaint with the v2 transparent mode.
> 
> The old trasparent mode allowed us to just dnat traffic towards the squid host without the need for the client to be aware of this. For example, the old style accepted 'GET / HTTP/1.1' (without full URL in the GET request and looking at the Host header for the destination).
> 
> The new intercept mode comes close to this behavior, but instead of 
> remotly dnat, it wants us to next-hop it towards the squid proxy and 
> redirect it locally. This is problematic for us as firewall and squid 
> proxy dont live in the same vlan, so next-hop should be the router to 
> that vlan (and forgetting about the path back to the server). 
> Secondly, and not less blocking, we use vservers (predecessor to linux 
> containers
> lxc) as such, we dont have any promiscuous interfaces rights within the container.
> 
> 
> Is there still a option to emulate normal 'regular? style squid (as without any listen options) but instead accepting the URI path in the GET request and looking at the Host header for the destination? (lets call it passthrough mode?).
> 
> Or, is there in squid3 a new and better way to facilitate larger setups, with the knowledge the server, firewall and squids are all in different vlans (and no, we dont have Cisco firewalls in between them ;-)).
> 
> 
> Thanks in advance,
> 
> --
> Henry Paulissen - PD0OM
> henry at nitronetworks.nl - Phone: +31-(0)6-115.305.64 Linux/Unix System 
> Engineer
> 
> 





From ml at netfence.it  Tue Oct 25 14:41:56 2016
From: ml at netfence.it (Andrea Venturoli)
Date: Tue, 25 Oct 2016 16:41:56 +0200
Subject: [squid-users] skype connection problem
In-Reply-To: <ebb3917e-4698-3c4b-8979-b879eed93a14@gmail.com>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <0dc219d6-e5b2-8473-822d-df6ec51d57ed@gmail.com>
 <53fbc061-28e6-9445-89a1-053632d94c24@gmail.com>
 <b3a04049-9deb-0943-0f07-2bdd37acec74@treenet.co.nz>
 <6e48d0b8-8922-9c3a-4ec3-1dfdec96be8c@gmail.com>
 <ebb3917e-4698-3c4b-8979-b879eed93a14@gmail.com>
Message-ID: <fbc0ea15-8387-7520-1d31-769185e2309c@netfence.it>

On 10/25/16 16:26, Yuri Voinov wrote:

> You LAN settings is too restrictive. AFAIK you require to permit traffic
> to skype servers directly from your clients. Without proxy.

Any hint on how to identify those server?
Any IP list?

  bye & Thanks
	av.


From eliezer at ngtech.co.il  Tue Oct 25 14:42:27 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 25 Oct 2016 17:42:27 +0300
Subject: [squid-users] skype connection problem
In-Reply-To: <55117246-90c3-db39-98c2-8cf02e63e84f@gmail.com>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <031501d22e18$93029b00$b907d100$@ngtech.co.il>
 <2d005fe0-4b41-e96a-d4ee-f8e8b1a10cb6@gmail.com>
 <062601d22ecd$02d56ac0$08804040$@ngtech.co.il>
 <55117246-90c3-db39-98c2-8cf02e63e84f@gmail.com>
Message-ID: <063301d22ece$01cd5420$0567fc60$@ngtech.co.il>

>From what I have seen it relies on p2p network to coordinate the FW port piercing,
This haven't changed for a very long time to my knowledge.
However it relies heavily on the Skype Infrastructure.
For example if  you would want to block skype you will just need to block their coordination infrastructure and all domains which contains the words "skype".

If someone is will to help me testing I will be here later tonight.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
Sent: Tuesday, October 25, 2016 17:37
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] skype connection problem


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


25.10.2016 20:35, Eliezer Croitoru ?????:
> Hey Nicolas,
>
> I know that it should work but it will request all sort of weird
CONNECT requests to other parties.
> Skype is designed to work as a p2p network and there for might not
work as expected in your environment.
Not p2p already. Via central MS servers.
>
> I will try myself to test it and see how if and how it works in a very
specific scenario.
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: Nicolas Valera [mailto:nvalera at gmail.com]
> Sent: Tuesday, October 25, 2016 17:19
> To: Eliezer Croitoru <eliezer at ngtech.co.il>; 
> squid-users at squid-cache.org
> Subject: Re: [squid-users] skype connection problem
>
> Hi Eliezer, thanks for the answer!
>
> On 10/24/2016 02:03 PM, Eliezer Croitoru wrote:
>> Just to understand the scenario:
>> You have let say 1 client on network 192.168.0.0/24 You have a proxy 
>> at 192.168.0.200 The client doesn?t have a gateway in the network IE 
>> cannot run dns queries or pings to the internet.
>> The client must define the proxy in order to access any Internet
resources.
>> Right?
>
> Yes, you're right!
> So, in this scenario, the skype will never work?
>
>> The proxy have access to dns and the ip stack natted or not.
>>
>> I believe it would be pretty simple to reproduced in order to verify 
>> the issue by another party.
>>
>> Let me know if I got the situation right.
>>
>> Eliezer
>>
>> ----
>> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> Linux System 
>> Administrator
>> Mobile: +972-5-28704261
>> Email: eliezer at ngtech.co.il
>>
>>
>> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
>> On Behalf Of N V
>> Sent: Monday, October 24, 2016 01:11
>> To: squid-users at squid-cache.org
>> Subject: [squid-users] skype connection problem
>>
>> hi there,
>> i've had problems with windows skype clients with the only internet 
>> connection is through squid. the clients can login successful but 
>> when they make a call, it hangs after 12 secconds.
>>
>> I checked the client connections and see that attempts to connect 
>> directly even if the proxy is properly configured.
>>
>> my squid version is 3.5.12
>> the skype clients have the last version available.
>> does anyone have the same issues?
>> any idea?
>>
>> thanks in advance!
>> Nicol?s.
>>
>> pd. sorry about my english
>>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

- --
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYD24MAAoJENNXIZxhPexG304H+gP1bJInqvHfXc7cc3REamTq
nGg5dLPlCYxiaxw6lBxbexsZ6QXJCc28yokJhXjMzce9F1bDzc0MBuGnz1tsDJBk
kkPp6PoArMHNQGSofVBiLFEGNKTeWSu2/PxB1Xc0zwwwoscaXuz/9XSWwuR9KoEH
r84uTOHDMDzYCFs/JQ7KlI+i1RkJFMHWqViQ+jknITd6DhtVEUO80eLjjlK7zLUA
824mgT0DCx9rI18i9x+RETE1rFcIwYL99qhNdPK0drdVx1X/WrifDNUwNaekXoTA
7LPg94gFRP/O632ensHAMoi2j77IbPckwi5KOsTjiBbVCBUm1uVyILMnQrbf06Q=
=WbGB
-----END PGP SIGNATURE-----




From yvoinov at gmail.com  Tue Oct 25 14:43:26 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 25 Oct 2016 20:43:26 +0600
Subject: [squid-users] skype connection problem
In-Reply-To: <fbc0ea15-8387-7520-1d31-769185e2309c@netfence.it>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <0dc219d6-e5b2-8473-822d-df6ec51d57ed@gmail.com>
 <53fbc061-28e6-9445-89a1-053632d94c24@gmail.com>
 <b3a04049-9deb-0943-0f07-2bdd37acec74@treenet.co.nz>
 <6e48d0b8-8922-9c3a-4ec3-1dfdec96be8c@gmail.com>
 <ebb3917e-4698-3c4b-8979-b879eed93a14@gmail.com>
 <fbc0ea15-8387-7520-1d31-769185e2309c@netfence.it>
Message-ID: <71658383-8a90-08c2-5853-1b97f4a93c97@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Wireshark? :)

No, I have no IP list. In my environment this not required.


25.10.2016 20:41, Andrea Venturoli ?????:
> On 10/25/16 16:26, Yuri Voinov wrote:
>
>> You LAN settings is too restrictive. AFAIK you require to permit traffic
>> to skype servers directly from your clients. Without proxy.
>
> Any hint on how to identify those server?
> Any IP list?
>
>  bye & Thanks
>     av.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYD2+OAAoJENNXIZxhPexGz20H/1Db4jVt7fvkqCbxgpdy/PvL
jsc3SojZ3N00DJ9pWfvqp+gdguNHL8N8cighQoiqy6B2pcCdPY5YZOhn76Gg4YmE
lAeUbEKOAQb1KLkpxXegJ0ZMu5kDN5X+IArCX21N3IxG38u2Q8kUhBt9eXfKab2b
jcAVEV9JUWpXbdf1upOS3ZZEyO49+H2y4qjB0bm9PVLddSeB6oQ71EG7Dm7UK8PF
3W7bjUzwaTGfYcgr0chf3gbsVQ3wITfCL4xb+X+w3y5ndfSVKN8N2Lu/LzRUli5M
8HYPGpMR20uiMTKtqmdyds/eUiUbtn/02qqWjhOQ/VnoZuuBK7PdHl6TUsiiqyU=
=FXkv
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/8e70c145/attachment.key>

From eliezer at ngtech.co.il  Tue Oct 25 14:44:28 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 25 Oct 2016 17:44:28 +0300
Subject: [squid-users] skype connection problem
In-Reply-To: <fbc0ea15-8387-7520-1d31-769185e2309c@netfence.it>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <0dc219d6-e5b2-8473-822d-df6ec51d57ed@gmail.com>
 <53fbc061-28e6-9445-89a1-053632d94c24@gmail.com>
 <b3a04049-9deb-0943-0f07-2bdd37acec74@treenet.co.nz>
 <6e48d0b8-8922-9c3a-4ec3-1dfdec96be8c@gmail.com>
 <ebb3917e-4698-3c4b-8979-b879eed93a14@gmail.com>
 <fbc0ea15-8387-7520-1d31-769185e2309c@netfence.it>
Message-ID: <063b01d22ece$4a3a2170$deae6450$@ngtech.co.il>

I am working on these but it involves a huge CDN and it might not work for everyone.

Later tonight I will try to see how it goes.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Andrea Venturoli
Sent: Tuesday, October 25, 2016 17:42
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] skype connection problem

On 10/25/16 16:26, Yuri Voinov wrote:

> You LAN settings is too restrictive. AFAIK you require to permit 
> traffic to skype servers directly from your clients. Without proxy.

Any hint on how to identify those server?
Any IP list?

  bye & Thanks
	av.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Tue Oct 25 14:53:24 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 25 Oct 2016 17:53:24 +0300
Subject: [squid-users] GoLang Based delayer
Message-ID: <064901d22ecf$898071d0$9c815570$@ngtech.co.il>

Inspired by Francesco Chemolli delayer at:
http://bazaar.launchpad.net/~squid/squid/trunk/view/head:/src/acl/external/d
elayer/ext_delayer_acl.pl.in

I wrote a delayer in golang:
http://wiki.squid-cache.org/EliezerCroitoru/GoLangDelayer

The binaries for the helper are at:
http://ngtech.co.il/squid/helpers/delayer/squid-externalacl_delayer.tar.xz

For windows, linux, BSD, Darwin, arm

Eliezer

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
 


-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 63497 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/4d7e23bd/attachment.bin>

From gkinkie at gmail.com  Tue Oct 25 14:57:39 2016
From: gkinkie at gmail.com (Kinkie)
Date: Tue, 25 Oct 2016 15:57:39 +0100
Subject: [squid-users] GoLang Based delayer
In-Reply-To: <064901d22ecf$898071d0$9c815570$@ngtech.co.il>
References: <064901d22ecf$898071d0$9c815570$@ngtech.co.il>
Message-ID: <CA+Y8hcOmOBCFbXKLsY==63JQ3MXXjfzvm-24y87tvFKdOhgjUQ@mail.gmail.com>

Hi Eliezer,
   Please list it as "realted software" on the wiki.

On Tue, Oct 25, 2016 at 3:53 PM, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> Inspired by Francesco Chemolli delayer at:
> http://bazaar.launchpad.net/~squid/squid/trunk/view/head:/src/acl/external/d
> elayer/ext_delayer_acl.pl.in
>
> I wrote a delayer in golang:
> http://wiki.squid-cache.org/EliezerCroitoru/GoLangDelayer
>
> The binaries for the helper are at:
> http://ngtech.co.il/squid/helpers/delayer/squid-externalacl_delayer.tar.xz
>
> For windows, linux, BSD, Darwin, arm
>
> Eliezer
>
> ----
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
    Francesco


From ml at netfence.it  Tue Oct 25 15:45:01 2016
From: ml at netfence.it (Andrea Venturoli)
Date: Tue, 25 Oct 2016 17:45:01 +0200
Subject: [squid-users] skype connection problem
In-Reply-To: <71658383-8a90-08c2-5853-1b97f4a93c97@gmail.com>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <0dc219d6-e5b2-8473-822d-df6ec51d57ed@gmail.com>
 <53fbc061-28e6-9445-89a1-053632d94c24@gmail.com>
 <b3a04049-9deb-0943-0f07-2bdd37acec74@treenet.co.nz>
 <6e48d0b8-8922-9c3a-4ec3-1dfdec96be8c@gmail.com>
 <ebb3917e-4698-3c4b-8979-b879eed93a14@gmail.com>
 <fbc0ea15-8387-7520-1d31-769185e2309c@netfence.it>
 <71658383-8a90-08c2-5853-1b97f4a93c97@gmail.com>
Message-ID: <0fde461a-caf1-deb9-65d6-c5204fcbfc7d@netfence.it>

On 10/25/16 16:43, Yuri Voinov wrote:
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> Wireshark? :)

No good: I don't trust MS not to change them the next day.



> In my environment this not required.

Neither in mine, but some customer insists on using this Skype crap and 
while the Windows version will work through Squid, the Mac one won't (at 
least not with a "new" account).

  bye & Thanks


From yvoinov at gmail.com  Tue Oct 25 15:54:36 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 25 Oct 2016 21:54:36 +0600
Subject: [squid-users] skype connection problem
In-Reply-To: <0fde461a-caf1-deb9-65d6-c5204fcbfc7d@netfence.it>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <0dc219d6-e5b2-8473-822d-df6ec51d57ed@gmail.com>
 <53fbc061-28e6-9445-89a1-053632d94c24@gmail.com>
 <b3a04049-9deb-0943-0f07-2bdd37acec74@treenet.co.nz>
 <6e48d0b8-8922-9c3a-4ec3-1dfdec96be8c@gmail.com>
 <ebb3917e-4698-3c4b-8979-b879eed93a14@gmail.com>
 <fbc0ea15-8387-7520-1d31-769185e2309c@netfence.it>
 <71658383-8a90-08c2-5853-1b97f4a93c97@gmail.com>
 <0fde461a-caf1-deb9-65d6-c5204fcbfc7d@netfence.it>
Message-ID: <094cab6f-9c6d-c1c1-c3aa-9c96a95c7d6b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


25.10.2016 21:45, Andrea Venturoli ?????:
> On 10/25/16 16:43, Yuri Voinov wrote:
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>>
>> Wireshark? :)
>
> No good: I don't trust MS not to change them the next day.
You. But you is not the same as your users & management. Tell this idea
to your manager. :) Whatch what he/she answered.
>
>
>
>> In my environment this not required.
>
> Neither in mine, but some customer insists on using this Skype crap
and while the Windows version will work through Squid, the Mac one won't
(at least not with a "new" account).
>
>  bye & Thanks
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYD4A7AAoJENNXIZxhPexGxcAH/1uhmbJd3HK8VqPloHtdSYc9
HCqZ3iLxMWEW3v73H70y/dTw04iEXgBjT49Vaqqm7zccm41jomOATIgTTUcS8dKN
ggI1X8BJy3e0pxfFTQzSTDq+wFZMbo/jyR6Prn+RMxUVA1qkoC3rlpywfYMfxtbE
RhVs5DIpw2EeTBg7kDlb4hPuNQPjyY2squCTivIQUo07KOiSse/Aqp+FBCoJ+q9g
YiYlP6ko3MxZCWY3mOxYuoYVZUMZFbqNCGMSsVQ18qWHt0D47NedKvmakzUEQdEi
s3hFG3uS4EAWvIVF03KxaKaCPI8zHD/e2d+UEbIhg878B3yjtNwC0yVHePcQgnM=
=HlzN
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/39383f2f/attachment.key>

From eliezer at ngtech.co.il  Tue Oct 25 16:26:54 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 25 Oct 2016 19:26:54 +0300
Subject: [squid-users] External nat'ed transparent proxy
In-Reply-To: <bc65b95c-6f9e-033c-b47f-0e475fa32a94@nitronetworks.nl>
References: <9cb02f45-ad81-7d77-0d7a-cf313c34f4fd@nitronetworks.nl>
 <!&!AAAAAAAAAAAuAAAAAAAAAP1vRcAAnWlNoU7f4f0YNhgBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADQt4cUeAlsQ6ihb0bN4K2wAQAAAAA=@ngtech.co.il>
 <789f52cc-6929-0719-9e3b-7378bdf37343@nitronetworks.nl>
 <063101d22ecd$7b0c6930$71253b90$@ngtech.co.il>
 <bc65b95c-6f9e-033c-b47f-0e475fa32a94@nitronetworks.nl>
Message-ID: <06af01d22edc$99080c50$cb1824f0$@ngtech.co.il>

Hey Henry,

It's not about RFC at all from my point of view.
It's very simple to setup the system in a way that will work as you want but with Let say Ubuntu 16.04 or Debian 8(latest).
These are very stable in my environment and if you need some help with the design I would be able to assist you with it.
I cannot find right now the whole setup specs but it's very simple to mark connections by the VLAN or the source network:
You will just need to change the next rules to be static and to not rely on NFQUEUE:
http://wiki.squid-cache.org/EliezerCroitoru/Drafts/MwanLB#iptables_rules_example

Then write a special routing table per vlan.
The reason to do so is since this is how it is suppose to be and not because of the RFC.
Your setup breaks good connections but maybe you are just not aware of it.
I believe that migrating from 2.X to a 3.5 can be completed smoothly enough in a way that nobody will fill it.

Elezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Henry Paulissen [mailto:henry at nitronetworks.nl] 
Sent: Tuesday, October 25, 2016 18:45
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] External nat'ed transparent proxy

Hi Eliezer,

Thank you for looking into it.

I fully understand the setup is far from ideal and breaks RFC's (I was already aware of this).

The reason we would like to keep this in place is to keep support on the older applications who aren't proxy aware. While still being able to keep some control of standard outbound connections. We know, that a sufficient knowledgeable hacker would very easily bypass the proxy but it is not in place to stop them. The proxy is there to stop the automatic bots / script kiddies / etc. A first line of defense.

That being said,
As a fast solution I now installed a debian weezy machine (who comes standard with squid 2.7.x). That proxy will act as transparent one and have the acls pushed to it from the new squid 3.x ones (so we can have a mixed env). That way we can keep supporting the older stuff (and have logging on it, who still uses it to encourage them to swap to the "real"
proxy).

Regards,

--
Henry Paulissen - PD0OM
mailto:henry at nitronetworks.nl - Phone: +31-(0)6-115.305.64 Linux/Unix System Engineer

On 25-10-16 16:38, Eliezer Croitoru wrote:
> Hey,
> 
> As Amos suggested you should use Policy based routing and not DNAT.
> The main reason for that is since it's breaking the Interception layer which squid relies on for fallback scenarios.
> 
> I can write the logic for this pretty fast but you should first understand that your setup is wrong in a way.
> 
> Eliezer
> 
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: mailto:eliezer at ngtech.co.il
> 
> 
> -----Original Message-----
> From: Henry Paulissen [mailto:henry at nitronetworks.nl]
> Sent: Friday, September 30, 2016 12:48
> To: Eliezer Croitoru <mailto:eliezer at ngtech.co.il>
> Cc: mailto:squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] External nat'ed transparent proxy
> 
> Good morning Eliezer,
> 
> 
> It took some time for me to construct a drawing who would be 
> understandable enough how our setup is, as the diagrams you provided 
> didn't fully fit the case. But, I think I managed to make a 
> understandable drawing of it :-)
> 
> [ Link to PNG image ]
> https://drive.google.com/file/d/0BysciyDBahUtWU55RjNPUlFjMTQ/view
> 
> 
> Some additional info with the drwaing:
>   - Each linux firewall server handles top ~5G traffic. After that we
>     build a new firewall cluster and new servers are connected to
>     that one.
> 
>   - The linux firewall is gateway for the vlan.
> 
>   - As you might know: LVS is internally also a DNAT, so bassicly we do
>     a double DNAT.
> 
>   - The green and blue line indicates how the traffic is routed
> 
>   - Linux firewalls is physical hardware, but all the servers
>     (including the squid hosts) are linux vservers (like LXC containers
>     or docker containers).
> 
> 
> Hopes this clears up our setup and where I run into problems with squid3.
> 
> Regards,
> 
> --
> Henry Paulissen - PD0OM
> mailto:henry at nitronetworks.nl - Phone: +31-(0)6-115.305.64 Linux/Unix System 
> Engineer
> 
> On 30-09-16 00:35, Eliezer Croitoru wrote:
>> Hey Henry,
>>
>> I want to emulate the setup to understand the complication with a FULL linux based setup here on my local testing grounds.
>> Can you give more details on the networks in the form of subnets and VLAN numbers?
>> What is not clear to me is: Who is doing the DNAT?
>> Also, if you have not used tproxy and intercept on the PROXY machine you should re-think the whole logic of the system first before deciding on the next step.
>> There are systems which needs redesign when moving from Squid 2 to 3 or 4.
>> When I and you will have the right understanding of the scenario I believe we can find the right path if this is not already there.
>>
>> Let me know if these( the diagrams..):
>> http://wiki.squid-cache.org/EliezerCroitoru/Drafts/MwanLB#Intoduction
>> _
>> to_MultiWAN_LoadBalancing
>> http://wiki.squid-cache.org/ConfigExamples/UbuntuTproxy4Wccp2
>>
>> Make any sense to you so we can find the right words to fill the gaps in the situation.
>> Once I will have the right picture I would probably have enough information to draw some picture in VISIO and move forward to the Systems table.
>>
>> Eliezer
>>
>> ----
>> Eliezer Croitoru
>> Linux System Administrator
>> Mobile+WhatsApp: +972-5-28704261
>> Email: mailto:eliezer at ngtech.co.il
>>
>>
>> -----Original Message-----
>> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
>> On Behalf Of Henry Paulissen
>> Sent: Thursday, September 29, 2016 5:40 PM
>> To: mailto:squid-users at lists.squid-cache.org
>> Subject: [squid-users] External nat'ed transparent proxy
>>
>> Hi all,
>>
>> In the company I work for we are currently using squid v2 proxies in transparent mode to intercept traffic from servers to the outside (access control).
>>
>> The technical solution for this is roughly as follows:
>> [server] -> [gateway] -> [firewall]
>>                               |
>>     ----------- DNAT ---------
>>    v
>> [squid]  -> [gateway] -> [firewall] -> [internet router]
>>
>> Our firewalls (who live between the vlan gateway and internet router), DNAT the traffic towards separate squid proxies (who are in a lvs cluster). These squid proxies are in their own vlan with special permissions to allow unrestricted port 80 outbound, etc, etc...
>>
>> Because squid v2 is becoming more and more obsolete we are looking at upgrading it towards squid v3.
>>
>> From what I read in the manuals, transparent mode is replaced by intercept (and tproxy) mode. But both dont seem to be fully backward complaint with the v2 transparent mode.
>>
>> The old trasparent mode allowed us to just dnat traffic towards the squid host without the need for the client to be aware of this. For example, the old style accepted 'GET / HTTP/1.1' (without full URL in the GET request and looking at the Host header for the destination).
>>
>> The new intercept mode comes close to this behavior, but instead of 
>> remotly dnat, it wants us to next-hop it towards the squid proxy and 
>> redirect it locally. This is problematic for us as firewall and squid 
>> proxy dont live in the same vlan, so next-hop should be the router to 
>> that vlan (and forgetting about the path back to the server).
>> Secondly, and not less blocking, we use vservers (predecessor to 
>> linux containers
>> lxc) as such, we dont have any promiscuous interfaces rights within the container.
>>
>>
>> Is there still a option to emulate normal 'regular? style squid (as without any listen options) but instead accepting the URI path in the GET request and looking at the Host header for the destination? (lets call it passthrough mode?).
>>
>> Or, is there in squid3 a new and better way to facilitate larger setups, with the knowledge the server, firewall and squids are all in different vlans (and no, we dont have Cisco firewalls in between them ;-)).
>>
>>
>> Thanks in advance,
>>
>> --
>> Henry Paulissen - PD0OM
>> mailto:henry at nitronetworks.nl - Phone: +31-(0)6-115.305.64 Linux/Unix System 
>> Engineer
>>
>>
> 
> 
> 




From yuriang at ltu.sld.cu  Tue Oct 25 22:17:12 2016
From: yuriang at ltu.sld.cu (Yurian Gonzalez)
Date: Tue, 25 Oct 2016 15:17:12 -0700
Subject: [squid-users] =?utf-8?q?Problema_de_conexi=C3=B3n_al_hacer_reload?=
 =?utf-8?q?_en_squid3=2E4?=
Message-ID: <580FD9E8.6000701@ltu.sld.cu>

Tengo un problema con squid3.4:
La situaci?n es:

Tengo una aplicaci?n web que escribe en varios archivos por ejemplo:

ip_lan.txt -> ip de las PC subred LAN
mac_lan.txt -> mac de las PC subred LAN

estos archivos son usados por squid3 para permitir el acceso, de tal 
manera que cada vez que la aplicaci?n modifica estos archivos tengo que 
realizar un reload al squid3 para que reconozca las nuevas modificaciones.

adem?s, utilizo cahe_peer, proveedor del servicio de internet.

Puedo navegar normalmente, pero cuando hago reload, hay como un corte de 
conexi?n, pues lo que recibo del cache_peer es el siguiente mensaje:



*ERROR
El URL solicitado no se ha podido conseguir

Se encontr? el siguiente error al intentar recuperar la direcci?n URL: 
/deportes*

*   URL Inv?lida
*
Alg?n aspecto del URL solicitado es incorrecto.

Algunos posibles problemas son:

     Falta o es incorrecto el protocolo de acceso (debe ser "http://" o 
similar)

     Falta el nombre de la m?quina

     Hay un doble-escape ilegal en la ruta de la URL

     Hay caracteres ilegales en el nombre de m?quina; el car?cter 
subrayado (_) no est? permitido.

Su administrador del cach? es admin at algo.com.

en el access.log sale:
*1477068035.768    183 192.168.1.20 TCP_MISS/400 3678 GET 
http://www.algunsitio.com/deportes usuario FIRSTUP_PARENT/10.0.0.2 
text/html*


Luego hago un F5, actualizo la p?gina y entonces funciona, es decir 
puedo navegar normalmente.
todo parece indicar que al hacer reload al squid3 se pierde algo entre 
el cache hijo y el padre, o no llega la solicitud de forma correcta al 
padre.
Anteriormente lo ten?a funcionando en una versi?n anterior de squid la 
3.1 y no pasa esto, incluso puedo hacer varios reload que no sucede 
nada, pero en este s?.

Por favor, agradecer?a si alguien pudiera ayudarme.
este es mi correo: yuriang at ltu.sld.cu.


--
Este mensaje le ha llegado mediante el servicio de correo electronico que ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema Nacional de Salud. La persona que envia este correo asume el compromiso de usar el servicio a tales fines y cumplir con las regulaciones establecidas

Infomed: http://www.sld.cu/
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161025/05cf8b8f/attachment.htm>

From killerrabbit2012 at gmail.com  Tue Oct 25 19:28:53 2016
From: killerrabbit2012 at gmail.com (KR)
Date: Tue, 25 Oct 2016 15:28:53 -0400
Subject: [squid-users] Rock cache partition
Message-ID: <629AAA99-662C-47AF-99E9-84419699BF66@gmail.com>

Greetings,

I'm running Ubuntu inside a VM.

How do I reference a virtual hdd partition /dev/sdb1" in squid.conf to be used for the rock cache? /hdd1 or /ssd2 do not seem to work.  

Thanks,
KR

From rousskov at measurement-factory.com  Tue Oct 25 21:13:19 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 25 Oct 2016 15:13:19 -0600
Subject: [squid-users] Rock cache partition
In-Reply-To: <629AAA99-662C-47AF-99E9-84419699BF66@gmail.com>
References: <629AAA99-662C-47AF-99E9-84419699BF66@gmail.com>
Message-ID: <a26e9c36-4284-151e-70b2-616f8aba9c42@measurement-factory.com>

On 10/25/2016 01:28 PM, KR wrote:

> How do I reference a virtual hdd partition /dev/sdb1" in squid.conf
> to be used for the rock cache?

You do not reference a partition. You reference a regular file system
directory [on that partition], just like with any other cache_dir type.

Eventually, rock will support raw disk partitions, but nobody has added
that support yet. FWIW, the amount of additional work required for that
support is relatively small -- the primary rock code already treats the
storage a single monolithic disk space.


HTH,

Alex.



From augustus_meyer at gmx.net  Tue Oct 25 22:11:07 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Tue, 25 Oct 2016 15:11:07 -0700 (PDT)
Subject: [squid-users] external_acl_type problem
In-Reply-To: <1477306889688-4680247.post@n4.nabble.com>
References: <1477219171447-4680203.post@n4.nabble.com>
 <c49ff38c-4ad5-f71e-8389-f4810e2258c5@treenet.co.nz>
 <1477306889688-4680247.post@n4.nabble.com>
Message-ID: <1477433467322-4680295.post@n4.nabble.com>

Some addition:
I activated some squid-debugging, and noticed:

2016/10/25 10:06:36.340 kid1| 84,5| helper.cc(1167) GetFirstAvailable:
GetFirstAvailable: Running servers 1
2016/10/25 10:06:36.340 kid1| helperOpenServers: Starting 10/20
'delay_generate_204.sh' processes
2016/10/25 10:06:36.462 kid1| 84,5| helper.cc(1167) GetFirstAvailable:
GetFirstAvailable: Running servers 10
Hlpr1 is never used later on


It looks like, in case a second helper is  requested, before the previous
one could respond (I see 2 requests within 100ms), the second request is
"lost". 
15min later (timeout ?) this helper is considered "exited", and new helpers
created.
However, when killing squid later on, some of the first helpers stay alive.
So the parent-child relation
was lost somehow.




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/external-acl-type-problem-tp4680203p4680295.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Tue Oct 25 23:37:37 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 26 Oct 2016 02:37:37 +0300
Subject: [squid-users] external_acl_type problem
In-Reply-To: <1477219171447-4680203.post@n4.nabble.com>
References: <1477219171447-4680203.post@n4.nabble.com>
Message-ID: <07e501d22f18$c4e66600$4eb33200$@ngtech.co.il>

You referred to some assumptions that we might have on a linux system but the question from my side is:
What for example?
Disk Space?
Libraries?
Etc..

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of reinerotto
Sent: Sunday, October 23, 2016 13:40
To: squid-users at lists.squid-cache.org
Subject: [squid-users] external_acl_type problem

1)
According to
http://www.squid-cache.org/Doc/config/external_acl_type/

in squid.conf, this 

external_acl_type check_delay ttl=0 cache=0 %SRC /etc/squid/check_delay.sh

should start 0 helpers immediately after squid (3.5.22) start-up.
However, I always see 5.

2)
I often see this:
Sat Oct 22 23:51:18 2016 user.alert syslog: The check_delay helpers are crashing too rapidly, need help!
Sat Oct 22 23:51:18 2016 local4.notice squid[21677]: Squid Parent: (squid-1) process 27685 exited with status 1
 
Still trying to trace down the problem, I notice, that in this case some helpers still kept alive, although I expect them to be killed, too, in case squid-1 exits.


I need to add, that I am running squid on an embedded system, cross-compiled for MIPS.
So there _might_ be some assumptions made for "standard LINUX" squid, which are not true in my case.




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/external-acl-type-problem-tp4680203.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Wed Oct 26 05:26:44 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 26 Oct 2016 18:26:44 +1300
Subject: [squid-users] External nat'ed transparent proxy
In-Reply-To: <06af01d22edc$99080c50$cb1824f0$@ngtech.co.il>
References: <9cb02f45-ad81-7d77-0d7a-cf313c34f4fd@nitronetworks.nl>
 <!&!AAAAAAAAAAAuAAAAAAAAAP1vRcAAnWlNoU7f4f0YNhgBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADQt4cUeAlsQ6ihb0bN4K2wAQAAAAA=@ngtech.co.il>
 <789f52cc-6929-0719-9e3b-7378bdf37343@nitronetworks.nl>
 <063101d22ecd$7b0c6930$71253b90$@ngtech.co.il>
 <bc65b95c-6f9e-033c-b47f-0e475fa32a94@nitronetworks.nl>
 <06af01d22edc$99080c50$cb1824f0$@ngtech.co.il>
Message-ID: <663e50ef-6859-3f3a-a37e-9e4d7c2186d4@treenet.co.nz>

On 26/10/2016 5:26 a.m., Eliezer Croitoru wrote:
> Hey Henry,
> 
> It's not about RFC at all from my point of view.
> It's very simple to setup the system in a way that will work as you want but with Let say Ubuntu 16.04 or Debian 8(latest).
> These are very stable in my environment and if you need some help with the design I would be able to assist you with it.
> I cannot find right now the whole setup specs but it's very simple to mark connections by the VLAN or the source network:
> You will just need to change the next rules to be static and to not rely on NFQUEUE:
> http://wiki.squid-cache.org/EliezerCroitoru/Drafts/MwanLB#iptables_rules_example
> 
> Then write a special routing table per vlan.
> The reason to do so is since this is how it is suppose to be and not because of the RFC.

Well, the RFC describe what "how it is suppose to be" is exactly. But
that is as relevant as they get.

It's a simple situation of; if you replace part of any protocol on-wire
binary bytes with random or wrong data, dont expect it to continue working.

> Your setup breaks good connections but maybe you are just not aware of it.

No 'maybe' about it. It *is* breaking connections, guaranteed.

Otherwise you (Henry) would not have noticed any issue when Squid
stopped the breakage from happening. The TCP/IP level breakage is/was
just happening in a way that hides itself from the admin sight and logs
until Squid-3 started pointing it out.

Amos



From squid3 at treenet.co.nz  Wed Oct 26 05:37:19 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 26 Oct 2016 18:37:19 +1300
Subject: [squid-users] RANGED requests still a pain for me..
In-Reply-To: <1fa457f8-34b9-5c68-5a21-0f907898142f@cinbesa.com.br>
References: <1fa457f8-34b9-5c68-5a21-0f907898142f@cinbesa.com.br>
Message-ID: <dc9c4d33-fe75-e234-ee83-a654c3abca08@treenet.co.nz>

On 26/10/2016 2:26 a.m., Heiler Bemerguy wrote:
> These firefox updates takes weeks to be really cached.. it won't cache
> if more than 1 person is trying to download at the same time.. but WHY
> does this happen?
> I've filled a bug report about this *TCP_SWAPFAIL_MISS*, but it seems no
> one is interested.. lol RockStore BTW
> 
> *acl fullDLext urlpath_regex -i
> \.(exe|ms[iup]|cab|bin|zip|mar|pdf|appx(bundle)?|esd|lzma2)\??**
> **range_offset_limit -1 fullDLext*
> 
> 1477401191.608   5151 10.61.0.67 TCP_MISS/206 300542 GET
> http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar
> - HIER_DIRECT/200.149.150.209 application/octet-stream
> 1477401192.592 206375 10.20.1.2 TCP_MISS/206 300544 GET
> http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/pt-BR/firefox-48.0.2.complete.mar
> - HIER_DIRECT/200.149.150.203 application/octet-stream

The log does not tell us much except that it was a cache MISS and that a
206 was delivered to the client.

Also, note that the duration column matters a lot. It indicates that the
second of those entries was started and still ntot yet completed when
the first happened.


A "debug_options 11,2" cache.log trace with the full HTTP message
headers to/from client and to/from server for these is neeed to see what
exactly is going on at the traffic level.

A deeper (ALL,5) cache.log trace might be needed to see what is causing
that traffic level messaging to happen if its not obvious from the 11,2
details.

Amos



From squid3 at treenet.co.nz  Wed Oct 26 05:48:57 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 26 Oct 2016 18:48:57 +1300
Subject: [squid-users]
 =?utf-8?q?Problema_de_conexi=C3=B3n_al_hacer_reload?=
 =?utf-8?q?_en_squid3=2E4?=
In-Reply-To: <580FD9E8.6000701@ltu.sld.cu>
References: <580FD9E8.6000701@ltu.sld.cu>
Message-ID: <de33d8e4-d2a3-584c-2237-466dfad31a0a@treenet.co.nz>

NOTE: please post in English. translate.google.com can be used if you need.

On 26/10/2016 11:17 a.m., Yurian Gonzalez wrote:

[Google translaton of the original]

> I have a problem with squid3.4: The situation is:
> 
> I have a web application that writes into several files for example:
> 
> ip_lan.txt -> IP subnet of PC LAN mac_lan.txt -> Mac PC LAN subnet
> 
> these files are used by squid3 to allow access, so that whenever the
> application modifies these files have to do a reload to squid3 to
> recognize the new modifications.
> 
> also I use cahe_peer, internet service provider.
> 
> I can navigate normally, but when I reload, there as a connection
> outage, because what I receive from cache_peer is the following
> message:
> 
> 
> 
> *ERROR The requested URL could not get /deportes

> 
> in the access.log sale:
> *1477068035.768    183 192.168.1.20 TCP_MISS/400 3678 GET http://www.algunsitio.com/deportes usuario FIRSTUP_PARENT/10.0.0.2 text/html* 
> 

The 400 page is being produced by the proxy at 10.0.0.2.

> 
> Then I do a F5, update the page and then functions, ie can browse
> normally. it seems that when you reload the squid3 lost something
> between child and parent cache, or does not reach the correct
> application of the parent form.

HTTP is stateless, meaning everything necessary to perform the
transaction is in the message headers themselves, not in any stored
state. There is nothing to be lost on a simple reconfigure.

> Previously it was operating in an
> earlier version of squid 3.1 and does not pass this, I can even make
> multiple reload that nothing happens, but this one did.
> 
> Please appreciate if someone could help me.

Please do you have any other info to work with?
for example your squid.conf or a cache.log trace when this happens?

Amos



From garryd at comnet.uz  Wed Oct 26 06:21:57 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Wed, 26 Oct 2016 11:21:57 +0500
Subject: [squid-users] Objects with values below 60 second for
 Cache-Control max-age are not cached
In-Reply-To: <1472047793.650.5.camel@comnet.uz>
References: <1471866407.18669.13.camel@comnet.uz>
 <1472047793.650.5.camel@comnet.uz>
Message-ID: <1477462917.6983.10.camel@comnet.uz>

On Wed, 2016-08-24 at 19:09 +0500, Garri Djavadyan wrote:
> On Mon, 2016-08-22 at 16:46 +0500, Garri Djavadyan wrote:
> > 
> > Hello Squid users,
> > 
> > Can anyone explain, why Squid doesn't cache the objects with max-
> > age
> > values below 60 seconds? For example:
> > 
> > $ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comnet.lo
> > ca
> > l/
> > cgi-bin/hello.cgi" && date
> > HTTP/1.1 200 OK
> > Date: Mon, 22 Aug 2016 11:31:16 GMT
> > Server: Apache
> > Cache-Control: max-age=60
> > Content-Type: text/plain
> > X-Cache: MISS from gentoo.comnet.uz
> > Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
> > Connection: keep-alive
> > 
> > Mon Aug 22 16:31:19 UZT 2016
> > 
> > ---
> > 
> > $ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comnet.lo
> > ca
> > l/
> > cgi-bin/hello.cgi" && date
> > HTTP/1.1 200 OK
> > Date: Mon, 22 Aug 2016 11:31:23 GMT
> > Server: Apache
> > Cache-Control: max-age=60
> > Content-Type: text/plain
> > X-Cache: MISS from gentoo.comnet.uz
> > Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
> > Connection: keep-alive
> > 
> > Mon Aug 22 16:31:26 UZT 2016
> > 
> > 
> > No problems with values above 60 seconds. For example:
> > 
> > $ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comnet.lo
> > ca
> > l/
> > cgi-bin/hello.cgi" && date
> > HTTP/1.1 200 OK
> > Date: Mon, 22 Aug 2016 11:36:06 GMT
> > Server: Apache
> > Cache-Control: max-age=70
> > Content-Type: text/plain
> > X-Cache: MISS from gentoo.comnet.uz
> > Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
> > Connection: keep-alive
> > 
> > Mon Aug 22 16:36:09 UZT 2016
> > 
> > ---
> > 
> > $ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comnet.lo
> > ca
> > l/
> > cgi-bin/hello.cgi" && date
> > HTTP/1.1 200 OK
> > Date: Mon, 22 Aug 2016 11:36:06 GMT
> > Server: Apache
> > Cache-Control: max-age=70
> > Content-Type: text/plain
> > Age: 5
> > X-Cache: HIT from gentoo.comnet.uz
> > Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
> > Connection: keep-alive
> > 
> > Mon Aug 22 16:36:11 UZT 2016
> > 
> > 
> > As you can see, time difference between origin server and localhost
> > is
> > 3 seconds (UZT is +5 offset).
> > 
> > Configuration is minimal:
> > 
> > # diff -u etc/squid.conf.default etc/squid.conf
> > --- etc/squid.conf.default	2016-08-12 17:21:48.877474780
> > +0500
> > +++ etc/squid.conf	2016-08-22 16:41:47.759766991 +0500
> > @@ -71,3 +71,5 @@
> > ?refresh_pattern ^gopher:	1440	0%	1440
> > ?refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
> > ?refresh_pattern .		0	20%	4320
> > +
> > +cache_mem 64 MB
> > 
> > 
> > Thanks in advance!
> > Garri
> 
> Dear Squid developers,
> 
> Is the situation described above intended behaviour, or a bug which
> should be reported? Thanks.
> 
> Garri

Squid debugging led me to:
http://www.squid-cache.org/Doc/config/minimum_expiry_time/

Garri


From wolle5050 at gmx.de  Wed Oct 26 06:42:00 2016
From: wolle5050 at gmx.de (Jens Offenbach)
Date: Wed, 26 Oct 2016 08:42:00 +0200
Subject: [squid-users] TProxy not working (Squid 3.5.12,
	Ubuntu Server 16.04.1)
Message-ID: <trinity-d9cfc3d9-2ca2-4a26-93cc-c36acaa8070e-1477464120242@3capp-gmx-bs30>

Hi,
I am trying to setup a transparent proxy with Squid 3.5.12 on Ubuntu Server 16.04.1, but I cannot get it working. When a client tries to connect to the web, the connection always times out.

Hopefully, someone has an idea what's going.

uname-r:
4.4.0-45-generic

sysct:
net.ipv4.ip_forward=1
net.ipv4.conf.default.rp_filter=0
net.ipv4.conf.all.rp_filter=0

squid.conf:
# ACCESS CONTROLS
# -----------------------------------------------------------------------------
  acl localnet    src 139.2.0.0/16
  acl localnet    src 193.96.112.0/21
  acl localnet    src 192.109.216.0/24
  acl localnet    src 100.1.4.0/22
  acl localnet    src 10.0.0.0/8
  acl localnet    src 172.16.0.0/12
  acl localnet    src 192.168.0.0/16
  acl to_localnet dst 139.2.0.0/16
  acl to_localnet dst 193.96.112.0/21
  acl to_localnet dst 192.109.216.0/24
  acl to_localnet dst 100.1.4.0/22
  acl to_localnet dst 10.0.0.0/8
  acl to_localnet dst 172.16.0.0/12
  acl to_localnet dst 192.168.0.0/16

  http_access allow manager localhost
  http_access deny  manager
  http_access allow localnet
  http_access allow localhost
  http_access allow to_localnet
  http_access deny all

# NETWORK OPTIONS
# -----------------------------------------------------------------------------
  http_port 10.30.200.99:3128
  http_port 10.30.216.254:3128
  http_port 10.30.216.254:3129 tproxy

# OPTIONS WHICH AFFECT THE NEIGHBOR SELECTION ALGORITHM
# -----------------------------------------------------------------------------
  cache_peer proxy.mycompany.com parent 8080 0 no-query no-digest default
  cache_peer  roxy.mycompany.com parent 8080 0 no-query no-digest

# MEMORY CACHE OPTIONS
# -----------------------------------------------------------------------------
  maximum_object_size_in_memory 8 MB
  memory_replacement_policy heap LFUDA
  cache_mem 256 MB

# DISK CACHE OPTIONS
# -----------------------------------------------------------------------------
  maximum_object_size 10 GB
  cache_replacement_policy heap GDSF
  cache_dir ufs /var/cache/squid 88894 16 256 max-size=10737418240

# LOGFILE OPTIONS
# -----------------------------------------------------------------------------
  access_log daemon:/var/log/squid/access.log squid
  cache_store_log daemon:/var/log/squid/store.log

# OPTIONS FOR TROUBLESHOOTING
# -----------------------------------------------------------------------------
  cache_log /var/log/squid/cache.log
  coredump_dir /var/log/squid
  
# OPTIONS FOR TUNING THE CACHE
# -----------------------------------------------------------------------------
  cache allow all
  
# ADMINISTRATIVE PARAMETERS
# -----------------------------------------------------------------------------
  visible_hostname my-proxy.mycompany.com

# ICP OPTIONS
# -----------------------------------------------------------------------------
  icp_port 0

# OPTIONS INFLUENCING REQUEST FORWARDING 
# -----------------------------------------------------------------------------
  always_direct allow to_localnet
  always_direct allow to_localhost
  never_direct  allow all

# DNS OPTIONS
# -----------------------------------------------------------------------------
  dns_nameservers 192.168.0.1
  dns_nameservers 192.168.0.2

# MISCELLANEOUS
# -----------------------------------------------------------------------------
  memory_pools off

iptables-rules:
iptables -t mangle -N DIVERT
iptables -t mangle -A DIVERT -j MARK --set-mark 0x1
iptables -t mangle -A DIVERT -j ACCEPT
iptables -t mangle -A PREROUTING -p tcp -m socket -j DIVERT
iptables -t mangle -A PREROUTING -p tcp --dport 80 -j TPROXY --tproxy-mark 0x1/0x1 --on-port 3129 --on-ip 10.30.216.254

I can see that packets are traversing the chain DIVERT and TPROXY (packet counter):
Chain DIVERT (1 references)
 pkts bytes target     prot opt in     out     source               destination
1134K  416M MARK       all  --  *      *       0.0.0.0/0            0.0.0.0/0            MARK set 0x1
1134K  416M ACCEPT     all  --  *      *       0.0.0.0/0            0.0.0.0/0

Chain PREROUTING (policy ACCEPT 2380 packets, 261K bytes)
 pkts bytes target     prot opt in     out     source               destination
1253K  455M neutron-openvswi-PREROUTING  all  --  *      *       0.0.0.0/0            0.0.0.0/0
1134K  416M DIVERT     tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            socket
 2125  119K LOG        tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:80 LOG flags 0 level 4 prefix "TPROXY : "
   63  3780 TPROXY     tcp  --  *      *       0.0.0.0/0            0.0.0.0/0            tcp dpt:80 TPROXY redirect 10.30.216.254:3129 mark 0x1/0x1

The client request is present in my syslog:
Oct 26 08:38:49 os-controller01 kernel: [ 4590.987956] TPROXY : IN=eth2 OUT= MAC=00:50:56:8d:2f:d4:02:05:69:02:be:68:08:00 SRC=10.30.216.132 DST=74.125.24.94 LEN=60 TOS=0x00 PREC=0x00 TTL=62 ID=21615 DF PROTO=TCP SPT=47706 DPT=80 WINDOW=27200 RES=0x00 SYN URGP=0

There is nothing in squid logs.

I have no idea. Has someone any hints what is wrong with my setup.

Regards,
Jens


From augustus_meyer at gmx.net  Wed Oct 26 08:56:56 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Wed, 26 Oct 2016 01:56:56 -0700 (PDT)
Subject: [squid-users] external_acl_type problem
In-Reply-To: <07e501d22f18$c4e66600$4eb33200$@ngtech.co.il>
References: <1477219171447-4680203.post@n4.nabble.com>
 <07e501d22f18$c4e66600$4eb33200$@ngtech.co.il>
Message-ID: <1477472216790-4680302.post@n4.nabble.com>

>You referred to some assumptions that we might have on a linux system but
the question from my side is:
What for example?
Disk Space?
Libraries?
Etc..<

Sorry, I do not really know. I had one similar, very strange effect on my
embedded LINUX, regarding bash:
It was necessary for redirect function in bash to work, to have this one:
ln -s /proc/self/fd /dev/fd
So just my idea about this special squid function having a similar reason.
Because as I have seen, squid uses socket connections to communicate with
the helper. 
So just a long shot.

It very looks like squids accouting of helpers is disturbed: I see much more
than max helpers active after a few hours.  And lot of helpers stay alive,
when I kill parent process squid. 
This problem only shows up, in case of having 2 (or more) active requests to
2 helpers (same key: %SRC).
Like squid assumes some internal queuing of the 2 requests, but second
request is not.
So it also could be some type of resource issue: Only one socket conn
allowed for squid, second one is silently ignored. This would cause exactly
my effect.
It must be something very special, as I have a lot of other software running
on this embedded LINUX, incl. nginx, rsync. And without the helper, squid
ran fine for long time, incl. cache to SSD.

configure options:
Squid Cache: Version 3.5.22
Service Name: squid
configure options:  '--target=mipsel-openwrt-linux'
'--host=mipsel-openwrt-linux' '--build=x86_64-linux-gnu' '--program-prefix='
'--program-suffix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin'
'--sbindir=/usr/sbin' '--libexecdir=/usr/lib' '--sysconfdir=/etc'
'--datadir=/usr/share' '--localstatedir=/var' '--mandir=/usr/man'
'--infodir=/usr/info' '--disable-nls' '--config-cache'
'--datadir=/usr/share/squid' '--libexecdir=/usr/lib/squid'
'--sysconfdir=/etc/squid' '--enable-shared' '--disable-static'
'--disable-icmp' '--enable-delay-pools' '--disable-icap-client'
'--enable-kill-parent-hack' '--disable-snmp' '--disable-ecap'
'--disable-wccp' '--disable-wccpv2' '--disable-eui' '--disable-htcp'
'--disable-ident-lookups' '--enable-auth'
'--disable-storeid-rewrite-helpers' '--disable-ipv6' '--enable-ssl'
'--enable-ssl-crtd' '--disable-cache-digests' '--enable-linux-netfilter'
'--disable-unlinkd' '--disable-x-accelerator-vary' '--disable-translation'
'--disable-auto-locale' '--with-dl' '--with-pthreads' '--without-expat'
'--without-libxml2' '--without-gnutls' '--without-nettle'
'--with-openssl=/etc/openwrt/mw-m96/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr'
'--enable-epoll' '--with-maxfd=4096' '--enable-external-acl-helpers'
'--disable-auth-negotiate' '--disable-auth-ntlm' '--disable-auth-digest'
'--enable-auth-basic' '--disable-arch-native' '--with-krb5-config=no'
'--without-mit-krb5' '--without-libcap' '--without-netfilter-conntrack'
'build_alias=x86_64-linux-gnu' 'host_alias=mipsel-openwrt-linux'
'target_alias=mipsel-openwrt-linux' 'CC=mipsel-openwrt-linux-uclibc-gcc'
'CFLAGS=-Os -pipe -mno-branch-likely -mips32r2 -mtune=24kec -mdsp
-fno-caller-saves -fhonour-copts -Wno-error=unused-but-set-variable
-Wno-error=unused-result -msoft-float '
'LDFLAGS=-L/etc/openwrt/mw-m96/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/lib
-L/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/lib
-L/etc/openwrt/router/staging_dir/toolchain-mipsel_24kec+dsp_gcc-4.8-linaro_uClibc-0.9.33.2/usr/lib
-L/etc/openwrt/router/staging_dir/toolchain-mipsel_24kec+dsp_gcc-4.8-linaro_uClibc-0.9.33.2/lib
'
'CPPFLAGS=-I/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/include
-I/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/include
-I/etc/openwrt/router/staging_dir/toolchain-mipsel_24kec+dsp_gcc-4.8-linaro_uClibc-0.9.33.2/usr/include
-I/etc/openwrt/router/staging_dir/toolchain-mipsel_24kec+dsp_gcc-4.8-linaro_uClibc-0.9.33.2/include
' 'CXX=mipsel-openwrt-linux-uclibc-g++' 'CXXFLAGS=-Os -pipe
-mno-branch-likely -mips32r2 -mtune=24kec -mdsp -fno-caller-saves
-fhonour-copts -Wno-error=unused-but-set-variable -Wno-error=unused-result
-msoft-float '
'PKG_CONFIG=/etc/openwrt/router/staging_dir/host/bin/pkg-config'
'PKG_CONFIG_PATH=/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/lib/pkgconfig:/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/share/pkgconfig'
'PKG_CONFIG_LIBDIR=/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/lib/pkgconfig:/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/share/pkgconfig'






--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/external-acl-type-problem-tp4680203p4680302.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Wed Oct 26 10:58:01 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 26 Oct 2016 13:58:01 +0300
Subject: [squid-users] external_acl_type problem
In-Reply-To: <1477472216790-4680302.post@n4.nabble.com>
References: <1477219171447-4680203.post@n4.nabble.com>
 <07e501d22f18$c4e66600$4eb33200$@ngtech.co.il>
 <1477472216790-4680302.post@n4.nabble.com>
Message-ID: <081101d22f77$d20e1e40$762a5ac0$@ngtech.co.il>

Thanks for the details! It gave me another perspective on things.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of reinerotto
Sent: Wednesday, October 26, 2016 11:57
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] external_acl_type problem

>You referred to some assumptions that we might have on a linux system 
>but
the question from my side is:
What for example?
Disk Space?
Libraries?
Etc..<

Sorry, I do not really know. I had one similar, very strange effect on my embedded LINUX, regarding bash:
It was necessary for redirect function in bash to work, to have this one:
ln -s /proc/self/fd /dev/fd
So just my idea about this special squid function having a similar reason.
Because as I have seen, squid uses socket connections to communicate with the helper. 
So just a long shot.

It very looks like squids accouting of helpers is disturbed: I see much more than max helpers active after a few hours.  And lot of helpers stay alive, when I kill parent process squid. 
This problem only shows up, in case of having 2 (or more) active requests to
2 helpers (same key: %SRC).
Like squid assumes some internal queuing of the 2 requests, but second request is not.
So it also could be some type of resource issue: Only one socket conn allowed for squid, second one is silently ignored. This would cause exactly my effect.
It must be something very special, as I have a lot of other software running on this embedded LINUX, incl. nginx, rsync. And without the helper, squid ran fine for long time, incl. cache to SSD.

configure options:
Squid Cache: Version 3.5.22
Service Name: squid
configure options:  '--target=mipsel-openwrt-linux'
'--host=mipsel-openwrt-linux' '--build=x86_64-linux-gnu' '--program-prefix='
'--program-suffix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin'
'--sbindir=/usr/sbin' '--libexecdir=/usr/lib' '--sysconfdir=/etc'
'--datadir=/usr/share' '--localstatedir=/var' '--mandir=/usr/man'
'--infodir=/usr/info' '--disable-nls' '--config-cache'
'--datadir=/usr/share/squid' '--libexecdir=/usr/lib/squid'
'--sysconfdir=/etc/squid' '--enable-shared' '--disable-static'
'--disable-icmp' '--enable-delay-pools' '--disable-icap-client'
'--enable-kill-parent-hack' '--disable-snmp' '--disable-ecap'
'--disable-wccp' '--disable-wccpv2' '--disable-eui' '--disable-htcp'
'--disable-ident-lookups' '--enable-auth'
'--disable-storeid-rewrite-helpers' '--disable-ipv6' '--enable-ssl'
'--enable-ssl-crtd' '--disable-cache-digests' '--enable-linux-netfilter'
'--disable-unlinkd' '--disable-x-accelerator-vary' '--disable-translation'
'--disable-auto-locale' '--with-dl' '--with-pthreads' '--without-expat'
'--without-libxml2' '--without-gnutls' '--without-nettle'
'--with-openssl=/etc/openwrt/mw-m96/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr'
'--enable-epoll' '--with-maxfd=4096' '--enable-external-acl-helpers'
'--disable-auth-negotiate' '--disable-auth-ntlm' '--disable-auth-digest'
'--enable-auth-basic' '--disable-arch-native' '--with-krb5-config=no'
'--without-mit-krb5' '--without-libcap' '--without-netfilter-conntrack'
'build_alias=x86_64-linux-gnu' 'host_alias=mipsel-openwrt-linux'
'target_alias=mipsel-openwrt-linux' 'CC=mipsel-openwrt-linux-uclibc-gcc'
'CFLAGS=-Os -pipe -mno-branch-likely -mips32r2 -mtune=24kec -mdsp -fno-caller-saves -fhonour-copts -Wno-error=unused-but-set-variable
-Wno-error=unused-result -msoft-float '
'LDFLAGS=-L/etc/openwrt/mw-m96/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/lib
-L/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/lib
-L/etc/openwrt/router/staging_dir/toolchain-mipsel_24kec+dsp_gcc-4.8-linaro_uClibc-0.9.33.2/usr/lib
-L/etc/openwrt/router/staging_dir/toolchain-mipsel_24kec+dsp_gcc-4.8-linaro_uClibc-0.9.33.2/lib
'
'CPPFLAGS=-I/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/include
-I/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/include
-I/etc/openwrt/router/staging_dir/toolchain-mipsel_24kec+dsp_gcc-4.8-linaro_uClibc-0.9.33.2/usr/include
-I/etc/openwrt/router/staging_dir/toolchain-mipsel_24kec+dsp_gcc-4.8-linaro_uClibc-0.9.33.2/include
' 'CXX=mipsel-openwrt-linux-uclibc-g++' 'CXXFLAGS=-Os -pipe -mno-branch-likely -mips32r2 -mtune=24kec -mdsp -fno-caller-saves -fhonour-copts -Wno-error=unused-but-set-variable -Wno-error=unused-result -msoft-float '
'PKG_CONFIG=/etc/openwrt/router/staging_dir/host/bin/pkg-config'
'PKG_CONFIG_PATH=/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/lib/pkgconfig:/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/share/pkgconfig'
'PKG_CONFIG_LIBDIR=/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/lib/pkgconfig:/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/share/pkgconfig'






--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/external-acl-type-problem-tp4680203p4680302.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Wed Oct 26 10:58:39 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 26 Oct 2016 23:58:39 +1300
Subject: [squid-users] Objects with values below 60 second for
 Cache-Control max-age are not cached
In-Reply-To: <1477462917.6983.10.camel@comnet.uz>
References: <1471866407.18669.13.camel@comnet.uz>
 <1472047793.650.5.camel@comnet.uz> <1477462917.6983.10.camel@comnet.uz>
Message-ID: <ea5d1b64-334a-45f9-deb4-832019630155@treenet.co.nz>

On 26/10/2016 7:21 p.m., Garri Djavadyan wrote:
> On Wed, 2016-08-24 at 19:09 +0500, Garri Djavadyan wrote:
>> On Mon, 2016-08-22 at 16:46 +0500, Garri Djavadyan wrote:
>>>
>>> Hello Squid users,
>>>
>>> Can anyone explain, why Squid doesn't cache the objects with max-
>>> age
>>> values below 60 seconds?

Several possible reasons...

> For example:
>>>
>>> $ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comnet.lo
>>> ca
>>> l/
>>> cgi-bin/hello.cgi" && date
>>> HTTP/1.1 200 OK
>>> Date: Mon, 22 Aug 2016 11:31:16 GMT
>>> Server: Apache
>>> Cache-Control: max-age=60
>>> Content-Type: text/plain
>>> X-Cache: MISS from gentoo.comnet.uz
>>> Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
>>> Connection: keep-alive
>>>
>>> Mon Aug 22 16:31:19 UZT 2016
>>>

1) This is not a GET request.

There is no object data returned on a HEAD request. So Squid does not
have anything to cache.

If you did a GET before this request, then the caching time is relative
to that request, not this one.


2) There is no Last-Modified header.

Squid older than 3.5.22 do not revalidate properly with only a Date
header. Meaning new content is required fetching if the cached object
was stale.

3) The response to a HEAD request is supposed to be the headers that
would be sent in an equivalent GET. So the servers upstream response
headers are the right output here in light of (2) and/or (1).

>>> ---
>>>
>>> $ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comnet.lo
>>> ca
>>> l/
>>> cgi-bin/hello.cgi" && date
>>> HTTP/1.1 200 OK
>>> Date: Mon, 22 Aug 2016 11:31:23 GMT
>>> Server: Apache
>>> Cache-Control: max-age=60
>>> Content-Type: text/plain
>>> X-Cache: MISS from gentoo.comnet.uz
>>> Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
>>> Connection: keep-alive
>>>
>>> Mon Aug 22 16:31:26 UZT 2016
>>>
>>>
>>> No problems with values above 60 seconds. For example:
>>>
>>> $ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comnet.lo
>>> ca
>>> l/
>>> cgi-bin/hello.cgi" && date
>>> HTTP/1.1 200 OK
>>> Date: Mon, 22 Aug 2016 11:36:06 GMT
>>> Server: Apache
>>> Cache-Control: max-age=70
>>> Content-Type: text/plain
>>> X-Cache: MISS from gentoo.comnet.uz
>>> Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
>>> Connection: keep-alive
>>>
>>> Mon Aug 22 16:36:09 UZT 2016
>>>
>>> ---
>>>
>>> $ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comnet.lo
>>> ca
>>> l/
>>> cgi-bin/hello.cgi" && date
>>> HTTP/1.1 200 OK
>>> Date: Mon, 22 Aug 2016 11:36:06 GMT
>>> Server: Apache
>>> Cache-Control: max-age=70
>>> Content-Type: text/plain
>>> Age: 5
>>> X-Cache: HIT from gentoo.comnet.uz
>>> Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
>>> Connection: keep-alive
>>>
>>> Mon Aug 22 16:36:11 UZT 2016
>>>
>>>
>>> As you can see, time difference between origin server and localhost
>>> is
>>> 3 seconds (UZT is +5 offset).

Your interpretation of the timestamps is flawed.

The message header contains teh timestamp the servre generated teh message.
The 'date' tool produces the timestamp at teh time the transaction
delivering it was completed.

All that is evident is that the transaction took ~5 seconds from message
generation to completion of delivery. That may contain any amount of +N
or -N difference in the three machines clocks (server, proxy, and client).

...


>>>
>>> Configuration is minimal:
>>>
>>> # diff -u etc/squid.conf.default etc/squid.conf
>>> --- etc/squid.conf.default	2016-08-12 17:21:48.877474780
>>> +0500
>>> +++ etc/squid.conf	2016-08-22 16:41:47.759766991 +0500
>>> @@ -71,3 +71,5 @@
>>>  refresh_pattern ^gopher:	1440	0%	1440
>>>  refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
>>>  refresh_pattern .		0	20%	4320
>>> +
>>> +cache_mem 64 MB
>>>
>>>
>>> Thanks in advance!
>>> Garri
>>
>> Dear Squid developers,
>>
>> Is the situation described above intended behaviour, or a bug which
>> should be reported? Thanks.
>>
>> Garri
> 
> Squid debugging led me to:
> http://www.squid-cache.org/Doc/config/minimum_expiry_time/
> 

HTTP requires a full second resolution of time, no shorter due to clock
skew across the length and breadth of the Internet. And for the same
reason 60sec resolution on caching is recommended for best response
accuracy if any type of long-distance exists between servers and proxy.

Amos



From squid3 at treenet.co.nz  Wed Oct 26 11:12:50 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 27 Oct 2016 00:12:50 +1300
Subject: [squid-users] TProxy not working (Squid 3.5.12,
 Ubuntu Server 16.04.1)
In-Reply-To: <trinity-d9cfc3d9-2ca2-4a26-93cc-c36acaa8070e-1477464120242@3capp-gmx-bs30>
References: <trinity-d9cfc3d9-2ca2-4a26-93cc-c36acaa8070e-1477464120242@3capp-gmx-bs30>
Message-ID: <1a01fc55-1673-ff7a-2503-4749a0d5796a@treenet.co.nz>

On 26/10/2016 7:42 p.m., Jens Offenbach wrote:
> Hi,
> I am trying to setup a transparent proxy with Squid 3.5.12 on Ubuntu Server 16.04.1, but I cannot get it working. When a client tries to connect to the web, the connection always times out.
> 
> Hopefully, someone has an idea what's going.
> 
> uname-r:
> 4.4.0-45-generic
> 
> sysct:
> net.ipv4.ip_forward=1
> net.ipv4.conf.default.rp_filter=0
> net.ipv4.conf.all.rp_filter=0
> 
> squid.conf:
> # ACCESS CONTROLS
> # -----------------------------------------------------------------------------
>   acl localnet    src 139.2.0.0/16
>   acl localnet    src 193.96.112.0/21
>   acl localnet    src 192.109.216.0/24
>   acl localnet    src 100.1.4.0/22
>   acl localnet    src 10.0.0.0/8
>   acl localnet    src 172.16.0.0/12
>   acl localnet    src 192.168.0.0/16
>   acl to_localnet dst 139.2.0.0/16
>   acl to_localnet dst 193.96.112.0/21
>   acl to_localnet dst 192.109.216.0/24
>   acl to_localnet dst 100.1.4.0/22
>   acl to_localnet dst 10.0.0.0/8
>   acl to_localnet dst 172.16.0.0/12
>   acl to_localnet dst 192.168.0.0/16
> 

Missing basic security controlsto prevent this being an abused open proxy.
 http_access deny !Safe_Ports
 http_access deny CONNECT !SSL_Ports


>   http_access allow manager localhost
>   http_access deny  manager
>   http_access allow localnet
>   http_access allow localhost
>   http_access allow to_localnet

Permits external visitors uncontrolled access to your LAN IP spaces.
Particularly when combined with the "always_direct allow to_localnet" below.
  Really want that?

>   http_access deny all
> 
> # NETWORK OPTIONS
> # -----------------------------------------------------------------------------
>   http_port 10.30.200.99:3128
>   http_port 10.30.216.254:3128
>   http_port 10.30.216.254:3129 tproxy
> 
> # OPTIONS WHICH AFFECT THE NEIGHBOR SELECTION ALGORITHM
> # -----------------------------------------------------------------------------
>   cache_peer proxy.mycompany.com parent 8080 0 no-query no-digest default
>   cache_peer  roxy.mycompany.com parent 8080 0 no-query no-digest

I suspect the peers are sending TCP SYN+ACK responses directly back to
the client IP which Squid is spoofing.

Add the option "no-tproxy" to these peer lines to avoid that.

> 
> # MEMORY CACHE OPTIONS
> # -----------------------------------------------------------------------------
>   maximum_object_size_in_memory 8 MB
>   memory_replacement_policy heap LFUDA
>   cache_mem 256 MB
> 
> # DISK CACHE OPTIONS
> # -----------------------------------------------------------------------------
>   maximum_object_size 10 GB
>   cache_replacement_policy heap GDSF
>   cache_dir ufs /var/cache/squid 88894 16 256 max-size=10737418240
> 
> # LOGFILE OPTIONS
> # -----------------------------------------------------------------------------
>   access_log daemon:/var/log/squid/access.log squid
>   cache_store_log daemon:/var/log/squid/store.log
> 

store.log is very rarely needed. You might consider removing it for some
extra speed out of the proxy.


> # OPTIONS FOR TROUBLESHOOTING
> # -----------------------------------------------------------------------------
>   cache_log /var/log/squid/cache.log
>   coredump_dir /var/log/squid
>   
> # OPTIONS FOR TUNING THE CACHE
> # -----------------------------------------------------------------------------
>   cache allow all

Unnecessary default value configured.

>   
> # ADMINISTRATIVE PARAMETERS
> # -----------------------------------------------------------------------------
>   visible_hostname my-proxy.mycompany.com
> 
> # ICP OPTIONS
> # -----------------------------------------------------------------------------
>   icp_port 0
> 

Unnecessary default value configured.

> # OPTIONS INFLUENCING REQUEST FORWARDING 
> # -----------------------------------------------------------------------------
>   always_direct allow to_localnet
>   always_direct allow to_localhost
>   never_direct  allow all
> 

Amos



From augustus_meyer at gmx.net  Wed Oct 26 11:12:27 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Wed, 26 Oct 2016 04:12:27 -0700 (PDT)
Subject: [squid-users] external_acl_type problem
In-Reply-To: <081101d22f77$d20e1e40$762a5ac0$@ngtech.co.il>
References: <1477219171447-4680203.post@n4.nabble.com>
 <07e501d22f18$c4e66600$4eb33200$@ngtech.co.il>
 <1477472216790-4680302.post@n4.nabble.com>
 <081101d22f77$d20e1e40$762a5ac0$@ngtech.co.il>
Message-ID: <1477480347296-4680306.post@n4.nabble.com>

Looks like I found a workaround: To use %SRC %SRCPORT. Which avoids (at least
up to now) identical key. 
So it looks like a bug in squid.
This _might_ be part of the problem:
 2016/10/26 06:11:28.417 kid1| 82,4| external_acl.cc(816) aclMatchExternal:
entry = { date=1477480288, result=DENIED tag= log= }

As  "date=1477480288" , not taking into account multiple requests during
same second, _and_ identical key (%SRC) this might trigger a problem.




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/external-acl-type-problem-tp4680203p4680306.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed Oct 26 11:50:31 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 27 Oct 2016 00:50:31 +1300
Subject: [squid-users] external_acl_type problem
In-Reply-To: <1477472216790-4680302.post@n4.nabble.com>
References: <1477219171447-4680203.post@n4.nabble.com>
 <07e501d22f18$c4e66600$4eb33200$@ngtech.co.il>
 <1477472216790-4680302.post@n4.nabble.com>
Message-ID: <868d4c4c-629b-2245-b86e-544090eb3b7e@treenet.co.nz>

On 26/10/2016 9:56 p.m., reinerotto wrote:
>> You referred to some assumptions that we might have on a linux system but
> the question from my side is:
> What for example?
> Disk Space?
> Libraries?
> Etc..<
> 
> Sorry, I do not really know. I had one similar, very strange effect on my
> embedded LINUX, regarding bash:
> It was necessary for redirect function in bash to work, to have this one:
> ln -s /proc/self/fd /dev/fd
> So just my idea about this special squid function having a similar reason.
> Because as I have seen, squid uses socket connections to communicate with
> the helper. 
> So just a long shot.
> 
> It very looks like squids accouting of helpers is disturbed: I see much more
> than max helpers active after a few hours.  And lot of helpers stay alive,
> when I kill parent process squid. 

By 'kill' do you mean something like "kill -9" ?

Or do you mean the proper "kill -SIGHUP" or "squid -k shutdown" sequence ?



> This problem only shows up, in case of having 2 (or more) active requests to
> 2 helpers (same key: %SRC).
> Like squid assumes some internal queuing of the 2 requests, but second
> request is not.

There *is* queueing for what it sends to the helper. The queue length
defaults to being equal to the number of running helpers.

Squid writes multiple lookups and waits for the responses. When
concurrency is disabled the helper must reply to them in order. When
concurrency is enabled it can reply in any order, but must deliver the
relevant channel-ID back to Squid with each reply.

If two requests have already been written to the helper, but it crashes
or exists after replying to the first one, the second should be handled
as if the helper replied with a BH (broken helper) response.


NP: if the helper does not real each "line" of input and response with
exactly 1 line of output for each. Then it is the helper which is broken.
Also, any helper which exitst or closes after only one line of input is
broken. Squid requires that they stay running.

> So it also could be some type of resource issue: Only one socket conn
> allowed for squid, second one is silently ignored. This would cause exactly
> my effect.

There better not be any socket limits like that. A *single* client web
browser opening a web page can cause around a hundred connections to be
opened. And these helpers require 3 FD/sockets (stdin->FD, stdout->FD,
and stderr->cache.log)


I see that you are using the obsolete RHEL custom built option
"--with-maxfd=4096". That will mean the --with-filedescriptors option
defaults to being 4096 unless the system building the Squid binary had a
smaller value enforced.


> It must be something very special, as I have a lot of other software running
> on this embedded LINUX, incl. nginx, rsync. And without the helper, squid
> ran fine for long time, incl. cache to SSD.


Squid uses fork() + execv() to start helpers. That results in the helper
process using as much virtual memory space a the main Squid was using at
the time the helper started. On an embeded system that could blow either
Squid or the helper out of the allowed memory limits.


> 
> configure options:
> Squid Cache: Version 3.5.22
> Service Name: squid
> configure options:  '--target=mipsel-openwrt-linux'
> '--host=mipsel-openwrt-linux' '--build=x86_64-linux-gnu' '--program-prefix='
> '--program-suffix=' '--prefix=/usr' '--exec-prefix=/usr' '--bindir=/usr/bin'
> '--sbindir=/usr/sbin' '--libexecdir=/usr/lib' '--sysconfdir=/etc'
> '--datadir=/usr/share' '--localstatedir=/var' '--mandir=/usr/man'
> '--infodir=/usr/info' '--disable-nls' '--config-cache'
> '--datadir=/usr/share/squid' '--libexecdir=/usr/lib/squid'
> '--sysconfdir=/etc/squid' '--enable-shared' '--disable-static'
> '--disable-icmp' '--enable-delay-pools' '--disable-icap-client'
> '--enable-kill-parent-hack' '--disable-snmp' '--disable-ecap'
> '--disable-wccp' '--disable-wccpv2' '--disable-eui' '--disable-htcp'
> '--disable-ident-lookups' '--enable-auth'
> '--disable-storeid-rewrite-helpers' '--disable-ipv6' '--enable-ssl'

"--enable-ssl" is obsolete. Remove.

> '--enable-ssl-crtd' '--disable-cache-digests' '--enable-linux-netfilter'
> '--disable-unlinkd' '--disable-x-accelerator-vary' '--disable-translation'
> '--disable-auto-locale' '--with-dl' '--with-pthreads' '--without-expat'
> '--without-libxml2' '--without-gnutls' '--without-nettle'
> '--with-openssl=/etc/openwrt/mw-m96/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr'
> '--enable-epoll' '--with-maxfd=4096' '--enable-external-acl-helpers'
> '--disable-auth-negotiate' '--disable-auth-ntlm' '--disable-auth-digest'
> '--enable-auth-basic' '--disable-arch-native' '--with-krb5-config=no'
> '--without-mit-krb5' '--without-libcap' '--without-netfilter-conntrack'
> 'build_alias=x86_64-linux-gnu' 'host_alias=mipsel-openwrt-linux'
> 'target_alias=mipsel-openwrt-linux' 'CC=mipsel-openwrt-linux-uclibc-gcc'
> 'CFLAGS=-Os -pipe -mno-branch-likely -mips32r2 -mtune=24kec -mdsp
> -fno-caller-saves -fhonour-copts -Wno-error=unused-but-set-variable
> -Wno-error=unused-result -msoft-float '
> 'LDFLAGS=-L/etc/openwrt/mw-m96/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/lib
> -L/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/lib
> -L/etc/openwrt/router/staging_dir/toolchain-mipsel_24kec+dsp_gcc-4.8-linaro_uClibc-0.9.33.2/usr/lib
> -L/etc/openwrt/router/staging_dir/toolchain-mipsel_24kec+dsp_gcc-4.8-linaro_uClibc-0.9.33.2/lib
> '
> 'CPPFLAGS=-I/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/include
> -I/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/include
> -I/etc/openwrt/router/staging_dir/toolchain-mipsel_24kec+dsp_gcc-4.8-linaro_uClibc-0.9.33.2/usr/include
> -I/etc/openwrt/router/staging_dir/toolchain-mipsel_24kec+dsp_gcc-4.8-linaro_uClibc-0.9.33.2/include
> ' 'CXX=mipsel-openwrt-linux-uclibc-g++' 'CXXFLAGS=-Os -pipe
> -mno-branch-likely -mips32r2 -mtune=24kec -mdsp -fno-caller-saves
> -fhonour-copts -Wno-error=unused-but-set-variable -Wno-error=unused-result
> -msoft-float '
> 'PKG_CONFIG=/etc/openwrt/router/staging_dir/host/bin/pkg-config'
> 'PKG_CONFIG_PATH=/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/lib/pkgconfig:/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/share/pkgconfig'
> 'PKG_CONFIG_LIBDIR=/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/lib/pkgconfig:/etc/openwrt/router/staging_dir/target-mipsel_24kec+dsp_uClibc-0.9.33.2/usr/share/pkgconfig'
> 
> 

Amos



From squid3 at treenet.co.nz  Wed Oct 26 11:52:26 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 27 Oct 2016 00:52:26 +1300
Subject: [squid-users] external_acl_type problem
In-Reply-To: <1477480347296-4680306.post@n4.nabble.com>
References: <1477219171447-4680203.post@n4.nabble.com>
 <07e501d22f18$c4e66600$4eb33200$@ngtech.co.il>
 <1477472216790-4680302.post@n4.nabble.com>
 <081101d22f77$d20e1e40$762a5ac0$@ngtech.co.il>
 <1477480347296-4680306.post@n4.nabble.com>
Message-ID: <c5a29ab0-922a-53e0-27f5-adbe60208e7a@treenet.co.nz>

On 27/10/2016 12:12 a.m., reinerotto wrote:
> Looks like I found a workaround: To use %SRC %SRCPORT. Which avoids (at least
> up to now) identical key. 
> So it looks like a bug in squid.
> This _might_ be part of the problem:
>  2016/10/26 06:11:28.417 kid1| 82,4| external_acl.cc(816) aclMatchExternal:
> entry = { date=1477480288, result=DENIED tag= log= }
> 
> As  "date=1477480288" , not taking into account multiple requests during
> same second, _and_ identical key (%SRC) this might trigger a problem.
> 

Yes. That would do it.

Amos



From erdosain9 at gmail.com  Wed Oct 26 13:14:12 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 26 Oct 2016 06:14:12 -0700 (PDT)
Subject: [squid-users] Transparent and non Transparent at the same time
Message-ID: <1477487652545-4680309.post@n4.nabble.com>

Hi.
Well, i just want to know if is possible config at the same time Transparent
and No Transparent for  different subnets...
Like 
192.168.1.0/24 ---------------- No transparent
192.168.100.0/24-------------- Transparent

i want this, because i have a net (1.0) that i can manager and other (100.0)
that dont......

(sorry for my english)

Thanks!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Transparent-and-non-Transparent-at-the-same-time-tp4680309.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yuriang at ltu.sld.cu  Wed Oct 26 17:36:16 2016
From: yuriang at ltu.sld.cu (Yurian Gonzalez)
Date: Wed, 26 Oct 2016 10:36:16 -0700
Subject: [squid-users] Connection problem when you reload in squid3.4
In-Reply-To: <mailman.2561.1477462925.2924.squid-users@lists.squid-cache.org>
References: <mailman.2561.1477462925.2924.squid-users@lists.squid-cache.org>
Message-ID: <5810E990.6020602@ltu.sld.cu>

I have a problem with squid3.4:
The situation is:
I have a web application that writes into several files for example:
ip_lan.txt -> IP subnet of PC LAN
     mac_lan.txt -> Mac PC LAN subnet

These files are used by squid3 to allow access, so that whenever the 
application modifies these files have to do a reload to squid3 to 
recognize the new modifications.

also I use cahe_peer, internet service provider.

I can navigate normally, but when I reload, there as a connection 
outage, because what I receive from cache_peer is the following message:
--- ERROR IN THE BROWSER ------------------------------------------- 
--------------
ERROR
The requested URL could not get
the following error when trying to retrieve the URL is found: / Sports
Invalid URL
Some aspect of the requested URL is incorrect.
Some possible problems are:
Missing or incorrect access protocol (should be "http: //" or similar)
Missing hostname
There is an illegal double-escape on the path of the URL
There are illegal characters in the hostname; the underscore character 
(_) is not allowed.
Your cache administrator is admin at algo.com.
-------------------------------------------------- 
-------------------------------------------------- ----------
Then I do a F5, update the page and then functions, ie can browse normally.
Previously worked in the vercion 3.1 squid3 and not pass this, I could 
even make multiple reload, and this situation did not happen.

##### cache.log #####
2016/10/26 06:17:30 kid1| Reconfiguring Squid Cache (version 3.4.8)...
2016/10/26 06:17:30 kid1| Closing HTTP port [::]:3128
2016/10/26 06:17:30 kid1| Closing Pinger socket on FD 30
2016/10/26 06:17:30 kid1| Logfile: closing log 
daemon:/var/log/squid3/access.log
2016/10/26 06:17:30 kid1| Logfile Daemon: closing log 
daemon:/var/log/squid3/access.log
2016/10/26 06:17:30 kid1| Startup: Initializing Authentication Schemes ...
2016/10/26 06:17:30 kid1| Startup: Initialized Authentication Scheme 'basic'
2016/10/26 06:17:30 kid1| Startup: Initialized Authentication Scheme 
'digest'
2016/10/26 06:17:30 kid1| Startup: Initialized Authentication Scheme 
'negotiate'
2016/10/26 06:17:30 kid1| Startup: Initialized Authentication Scheme 'ntlm'
2016/10/26 06:17:30 kid1| Startup: Initialized Authentication.
2016/10/26 06:17:30 kid1| Processing Configuration File: 
/etc/squid3/squid.conf (depth 0)
2016/10/26 06:17:30 kid1| Logfile: opening log 
daemon:/var/log/squid3/access.log
2016/10/26 06:17:30 kid1| Logfile Daemon: opening log 
/var/log/squid3/access.log
2016/10/26 06:17:30 kid1| Squid plugin modules loaded: 0
2016/10/26 06:17:30 kid1| Adaptation support is off.
2016/10/26 06:17:30 kid1| Store logging disabled
2016/10/26 06:17:30 kid1| DNS Socket created at [::], FD 13
2016/10/26 06:17:30 kid1| DNS Socket created at 0.0.0.0, FD 14
2016/10/26 06:17:30 kid1| Adding nameserver 201.220.222.131 from squid.conf
2016/10/26 06:17:30 kid1| HTCP Disabled.
2016/10/26 06:17:30 kid1| Pinger socket opened on FD 19
2016/10/26 06:17:30 kid1| Configuring Parent proxy.sld.cu/3128/0
2016/10/26 06:17:30| pinger: Initialising ICMP pinger ...
2016/10/26 06:17:30| pinger: ICMP socket opened.
2016/10/26 06:17:30| pinger: ICMPv6 socket opened
2016/10/26 06:17:30 kid1| Finished loading MIME types and icons.
2016/10/26 06:17:30 kid1| Accepting HTTP Socket connections at 
local=[::]:3128 remote=[::] FD 15 flags=9
2016/10/26 06:17:40| Pinger exiting.

##### squid.conf (minimum configuration) ######
acl ucm_net src 192.168.1.0/24    # LOCALNET
acl SSL_ports port 443
acl Safe_ports port 80        # http
acl Safe_ports port 21        # ftp
acl Safe_ports port 443        # https
acl Safe_ports port 70        # gopher
acl Safe_ports port 210        # wais
acl Safe_ports port 1025-65535    # unregistered ports
acl Safe_ports port 280        # http-mgmt
acl Safe_ports port 488        # gss-http
acl Safe_ports port 591        # filemaker
acl Safe_ports port 777        # multiling http
acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localhost
http_access allow ucm_net
http_access deny all
http_port 3128
cache_peer proxy.enet.com parent 3128 0 no-query no-digest default
cache_peer_domain proxy.enet.com !.enet.com
hierarchy_stoplist cgi-bin ?
never_direct allow all
prefer_direct off
cache_log /var/log/squid3/cache.log
debug_options ALL,1
coredump_dir /var/spool/squid3
refresh_pattern ^ftp:        1440    20%    10080
refresh_pattern ^gopher:    1440    0%    1440
refresh_pattern -i (/cgi-bin/|\?) 0    0%    0
refresh_pattern .        0    20%    4320
dns_nameservers 201.200.200.201
#############################################
This configuration is practically the default brings the squid3.4.8, to 
Nonstop an ACL, the cache_peer and dns_nameservers.
I've tried reinstalling the server, only install squid and no other 
pakete, besides setting is minimal.
---------------------------------------------------------------
Please appreciate if someone could help me.
this is my email: yuriang at ltu.sld.cu.


--
Este mensaje le ha llegado mediante el servicio de correo electronico que ofrece Infomed para respaldar el cumplimiento de las misiones del Sistema Nacional de Salud. La persona que envia este correo asume el compromiso de usar el servicio a tales fines y cumplir con las regulaciones establecidas

Infomed: http://www.sld.cu/



From nvalera at gmail.com  Wed Oct 26 14:50:39 2016
From: nvalera at gmail.com (Nicolas Valera)
Date: Wed, 26 Oct 2016 11:50:39 -0300
Subject: [squid-users] skype connection problem
In-Reply-To: <063b01d22ece$4a3a2170$deae6450$@ngtech.co.il>
References: <CA+ieveGnsBFvQzYOHdUByNNeoVc6H0UThz8RmD0mYjsrj601xw@mail.gmail.com>
 <0dc219d6-e5b2-8473-822d-df6ec51d57ed@gmail.com>
 <53fbc061-28e6-9445-89a1-053632d94c24@gmail.com>
 <b3a04049-9deb-0943-0f07-2bdd37acec74@treenet.co.nz>
 <6e48d0b8-8922-9c3a-4ec3-1dfdec96be8c@gmail.com>
 <ebb3917e-4698-3c4b-8979-b879eed93a14@gmail.com>
 <fbc0ea15-8387-7520-1d31-769185e2309c@netfence.it>
 <063b01d22ece$4a3a2170$deae6450$@ngtech.co.il>
Message-ID: <3f432502-b9b8-8c12-8e1c-62b82fee2cf7@gmail.com>

Well, this is really frustrating!
I'm trying with socks5 and it doesn't work...
the behavior is the same as https proxy, it tries to connect to the peer 
through udp, not through the proxy.

i can't believe it!


On 10/25/2016 11:44 AM, Eliezer Croitoru wrote:
> I am working on these but it involves a huge CDN and it might not work for everyone.
>
> Later tonight I will try to see how it goes.
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Andrea Venturoli
> Sent: Tuesday, October 25, 2016 17:42
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] skype connection problem
>
> On 10/25/16 16:26, Yuri Voinov wrote:
>
>> You LAN settings is too restrictive. AFAIK you require to permit
>> traffic to skype servers directly from your clients. Without proxy.
>
> Any hint on how to identify those server?
> Any IP list?
>
>   bye & Thanks
> 	av.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From garryd at comnet.uz  Wed Oct 26 14:53:02 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Wed, 26 Oct 2016 19:53:02 +0500
Subject: [squid-users] Objects with values below 60 second for
 Cache-Control max-age are not cached
In-Reply-To: <ea5d1b64-334a-45f9-deb4-832019630155@treenet.co.nz>
References: <1471866407.18669.13.camel@comnet.uz>
 <1472047793.650.5.camel@comnet.uz> <1477462917.6983.10.camel@comnet.uz>
 <ea5d1b64-334a-45f9-deb4-832019630155@treenet.co.nz>
Message-ID: <1477493582.6983.40.camel@comnet.uz>

Sorry, Amos, it seems my latest reply was ambiguous. I tried to inform,
that while debugging the issue I have found the cause. It was default
value for 'minimum_expire_time'.


On Wed, 2016-10-26 at 23:58 +1300, Amos Jeffries wrote:
> On 26/10/2016 7:21 p.m., Garri Djavadyan wrote:
> > 
> > On Wed, 2016-08-24 at 19:09 +0500, Garri Djavadyan wrote:
> > > 
> > > On Mon, 2016-08-22 at 16:46 +0500, Garri Djavadyan wrote:
> > > > 
> > > > 
> > > > Hello Squid users,
> > > > 
> > > > Can anyone explain, why Squid doesn't cache the objects with
> > > > max-
> > > > age
> > > > values below 60 seconds?
> 
> Several possible reasons...
> 
> > 
> > For example:
> > > 
> > > > 
> > > > 
> > > > $ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comne
> > > > t.lo
> > > > ca
> > > > l/
> > > > cgi-bin/hello.cgi" && date
> > > > HTTP/1.1 200 OK
> > > > Date: Mon, 22 Aug 2016 11:31:16 GMT
> > > > Server: Apache
> > > > Cache-Control: max-age=60
> > > > Content-Type: text/plain
> > > > X-Cache: MISS from gentoo.comnet.uz
> > > > Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
> > > > Connection: keep-alive
> > > > 
> > > > Mon Aug 22 16:31:19 UZT 2016
> > > > 
> 
> 1) This is not a GET request.
> 
> There is no object data returned on a HEAD request. So Squid does not
> have anything to cache.
> 
> If you did a GET before this request, then the caching time is
> relative
> to that request, not this one.

It is not true. Squid successfully caches HEAD requests.

$ for i in 1 2 ; do http_proxy="127.0.0.1:3128" \
curl --head http://sandbox.comnet.local/cgi-bin/5mb.cgi \
2>/dev/null | grep X-Cache; done

X-Cache: MISS from gentoo.comnet.uz
X-Cache: HIT from gentoo.comnet.uz


> 2) There is no Last-Modified header.
> 
> Squid older than 3.5.22 do not revalidate properly with only a Date
> header. Meaning new content is required fetching if the cached object
> was stale.

'Date' + 'Cache-Control: max-age=70' worked as expected.
'Date' + 'Cache-Control: max-age=60' does not worked.


> 3) The response to a HEAD request is supposed to be the headers that
> would be sent in an equivalent GET. So the servers upstream response
> headers are the right output here in light of (2) and/or (1).
> 
> > 
> > > 
> > > > 
> > > > ---
> > > > 
> > > > $ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comne
> > > > t.lo
> > > > ca
> > > > l/
> > > > cgi-bin/hello.cgi" && date
> > > > HTTP/1.1 200 OK
> > > > Date: Mon, 22 Aug 2016 11:31:23 GMT
> > > > Server: Apache
> > > > Cache-Control: max-age=60
> > > > Content-Type: text/plain
> > > > X-Cache: MISS from gentoo.comnet.uz
> > > > Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
> > > > Connection: keep-alive
> > > > 
> > > > Mon Aug 22 16:31:26 UZT 2016
> > > > 
> > > > 
> > > > No problems with values above 60 seconds. For example:
> > > > 
> > > > $ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comne
> > > > t.lo
> > > > ca
> > > > l/
> > > > cgi-bin/hello.cgi" && date
> > > > HTTP/1.1 200 OK
> > > > Date: Mon, 22 Aug 2016 11:36:06 GMT
> > > > Server: Apache
> > > > Cache-Control: max-age=70
> > > > Content-Type: text/plain
> > > > X-Cache: MISS from gentoo.comnet.uz
> > > > Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
> > > > Connection: keep-alive
> > > > 
> > > > Mon Aug 22 16:36:09 UZT 2016
> > > > 
> > > > ---
> > > > 
> > > > $ http_proxy="127.0.0.1:3128" curl --head "http://sandbox.comne
> > > > t.lo
> > > > ca
> > > > l/
> > > > cgi-bin/hello.cgi" && date
> > > > HTTP/1.1 200 OK
> > > > Date: Mon, 22 Aug 2016 11:36:06 GMT
> > > > Server: Apache
> > > > Cache-Control: max-age=70
> > > > Content-Type: text/plain
> > > > Age: 5
> > > > X-Cache: HIT from gentoo.comnet.uz
> > > > Via: 1.1 gentoo.comnet.uz (squid/3.5.20)
> > > > Connection: keep-alive
> > > > 
> > > > Mon Aug 22 16:36:11 UZT 2016
> > > > 
> > > > 
> > > > As you can see, time difference between origin server and
> > > > localhost
> > > > is
> > > > 3 seconds (UZT is +5 offset).
> 
> Your interpretation of the timestamps is flawed.
> 
> The message header contains teh timestamp the servre generated teh
> message.
> The 'date' tool produces the timestamp at teh time the transaction
> delivering it was completed.
> 
> All that is evident is that the transaction took ~5 seconds from
> message
> generation to completion of delivery. That may contain any amount of
> +N
> or -N difference in the three machines clocks (server, proxy, and
> client).

I showed the output of 'date' tool to confirm that Squid received fresh
object. The client and Squid ran on the same machine.

Garri


From sebelk at gmail.com  Wed Oct 26 14:57:52 2016
From: sebelk at gmail.com (Sergio Belkin)
Date: Wed, 26 Oct 2016 11:57:52 -0300
Subject: [squid-users] Problems with acltype "dst"
Message-ID: <CABZC=5wrRCaUnRrvKEBuAqTJUxKwBo65kJWXBvQoQa42KnNYGA@mail.gmail.com>

Hi,

I've found that sometimes acl dst is ignored.

I've found a workaround, that is adding the domain name corresponding to a
given Ip address to a separated dstdomain acltype.

It's ugly because sometimes users access to a websites by IP address...


But I wonder why... is it has to do with that?:

"Some check-points will *not* suspend the request: they allow (or deny)
immediately. If a SLOW acl has to be checked, and the results of the check
are not cached, the corresponding ACL result will be as if it didn't match"

(Source: http://wiki.squid-cache.org/SquidFaq/SquidAcl)

Thanks in advance!
-- 
--
Sergio Belkin
LPIC-2 Certified - http://www.lpi.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161026/72353f0d/attachment.htm>

From augustus_meyer at gmx.net  Wed Oct 26 15:20:41 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Wed, 26 Oct 2016 08:20:41 -0700 (PDT)
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <1477487652545-4680309.post@n4.nabble.com>
References: <1477487652545-4680309.post@n4.nabble.com>
Message-ID: <1477495241988-4680314.post@n4.nabble.com>

Just configure 2 different ports for squid to listen, one is transparent, the
other is not.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Transparent-and-non-Transparent-at-the-same-time-tp4680309p4680314.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From sebelk at gmail.com  Wed Oct 26 16:16:45 2016
From: sebelk at gmail.com (Sergio Belkin)
Date: Wed, 26 Oct 2016 13:16:45 -0300
Subject: [squid-users] Problems with acltype "dst"
In-Reply-To: <CABZC=5wrRCaUnRrvKEBuAqTJUxKwBo65kJWXBvQoQa42KnNYGA@mail.gmail.com>
References: <CABZC=5wrRCaUnRrvKEBuAqTJUxKwBo65kJWXBvQoQa42KnNYGA@mail.gmail.com>
Message-ID: <CABZC=5yqVQFaZQs8zsMhE4LAgq9G2vH2ReAa6t_iUaVo=XTVtA@mail.gmail.com>

Nevermind, shame of me :)

I had a typo

2016-10-26 11:57 GMT-03:00 Sergio Belkin <sebelk at gmail.com>:

> Hi,
>
> I've found that sometimes acl dst is ignored.
>
> I've found a workaround, that is adding the domain name corresponding to a
> given Ip address to a separated dstdomain acltype.
>
> It's ugly because sometimes users access to a websites by IP address...
>
>
> But I wonder why... is it has to do with that?:
>
> "Some check-points will *not* suspend the request: they allow (or deny)
> immediately. If a SLOW acl has to be checked, and the results of the check
> are not cached, the corresponding ACL result will be as if it didn't match"
>
> (Source: http://wiki.squid-cache.org/SquidFaq/SquidAcl)
>
> Thanks in advance!
> --
> --
> Sergio Belkin
> LPIC-2 Certified - http://www.lpi.org
>



-- 
--
Sergio Belkin
LPIC-2 Certified - http://www.lpi.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161026/76279daf/attachment.htm>

From jok at spikes.com  Wed Oct 26 18:01:43 2016
From: jok at spikes.com (Jok Thuau)
Date: Wed, 26 Oct 2016 11:01:43 -0700
Subject: [squid-users] filtering http(s) sites, transparently
In-Reply-To: <5704F3C3.2050709@treenet.co.nz>
References: <CADSSinP_yEvv_m=d=-KLgp77FPdGwWRYAn7SaLO-DK0ptq7qAA@mail.gmail.com>
 <5701F4B0.8060001@treenet.co.nz>
 <CADSSinOuefuE+auum5UcFiOkt6mxTxs1sD_2MMMmpU6WT67jFg@mail.gmail.com>
 <57031390.8020604@treenet.co.nz>
 <CADSSinPNCRfr8kitW4RXXAYSTk8tw6ibgSYdW+7q6O2j=P0JpQ@mail.gmail.com>
 <5704F3C3.2050709@treenet.co.nz>
Message-ID: <CADSSinNPiGzFFe+jeEJgtYaocfYM7jynYLsGJaQqxG1Cd+Gimg@mail.gmail.com>

After being side-tracked with a few different project, I ended up with the
config below. It appears to do the right things, though the ACL
organization could use some cleanup...
(Browsing to authorized sites works, browsing to something else, i get a
denied page from squid)

However, even though msdn.microsoft.com is on my whitelist, it appears to
"timeout". Looking at the logs, I see entries like this:

2016/09/20 15:10:19.640 kid1| SECURITY ALERT: Host header forgery detected
on local=65.54.226.150:443 remote=10.11.12.13:51984
<http://10.0.32.177:51984> FD 18 flags=33 (local IP does not match any
domain IP)
2016/09/20 15:10:19.640 kid1| SECURITY ALERT: By user agent:
2016/09/20 15:10:19.640 kid1| SECURITY ALERT: on URL: msdn.microsoft.com:443
2016/09/20 15:10:19.640 kid1| 4,2| errorpage.cc(1262) BuildContent: No
existing error page language negotiated for ERR_CONFLICT_HOST. Using
default error file.
2016/09/20 15:10:19.641 kid1| 20,2| store.cc(954) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/09/20 15:10:19.641 kid1| 20,2| store.cc(954) checkCachable:
StoreEntry::checkCachable: NO: not cachable
2016/09/20 15:10:19.641 kid1| 88,2| client_side_reply.cc(2001)
processReplyAccessResult: The reply for CONNECT msdn.microsoft.com:443 is
ALLOWED, because it matched SniBypass
2016/09/20 15:10:19.641 kid1| 33,2| client_side.cc(925)
deferRecipientForLater: clientSocketRecipient: Deferring request
msdn.microsoft.com:443

What is interesting is that we changed from using 8.8.8.8 as our DNS server
to a locally installed bind instance, and we no longer see any issues.
that is NOT what I expected... I can't explain why the client browser was
hanging. Any suggestions?

It's all happy now, with the following config, with a firewall doing policy
based routing, a local iptables rule to redirect from port 443 to 8443, and
from 80 to 3129, as well as the certificate deployed as trusted on each
endpoint:

squid.conf:
# setup standard ports
acl SSL_ports port 443
acl Safe_ports port 80
acl Safe_ports port 21
acl Safe_ports port 443
acl Safe_ports port 70
acl Safe_ports port 210
acl Safe_ports port 1025-65535
acl Safe_ports port 280
acl Safe_ports port 488
acl Safe_ports port 591
acl Safe_ports port 777
acl CONNECT method CONNECT
# for security
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports

# not actually used and blocked by local firewall on host, but squid
complains if it's not there...
http_port 3128

# http intercept, and ACL that matches that inbound port
http_port 3129 intercept
acl http_proxy myportname 3129

# same for https
https_port 8443 intercept ssl-bump \
    generate-host-certificates=on \
    dynamic_cert_mem_cache_size=64MB \
    cert=/etc/squid/ssl/proxy.pem \
    key=/etc/squid/ssl/proxy.key \
    cafile=/etc/squid/ssl/proxy.pem
acl https_proxy myportname 8443

always_direct allow all

# define the steps needed for bumping...
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3

# and the list of domains that are allowed
acl SniBypass ssl::server_name_regex -i "/etc/squid/snibypass.acl"
acl http_bypass dstdom_regex -n -i "/etc/squid/snibypass.acl"

# ensure we have target SSL port when checking data
acl https_ok all-of SniBypass SSL_ports
# and the destination domain when not SSL...
acl http_ok all-of http_bypass Safe_ports

# splice when we know the target matches
ssl_bump splice SniBypass
# peek and bump otherwise
ssl_bump peek step1
ssl_bump stare step2
ssl_bump bump all

# some options for the certificate generation..
sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE
sslproxy_cert_sign_hash sha256
sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 64MB
sslcrtd_children 8 startup=1 idle=1

# for http, let's block if we're not on the whitelist
http_access         deny !http_ok        http_proxy
# for https, let's wait until step3 of the bumping, so we can replace the
SSL content post-bumping)
http_access         deny !https_ok step3 https_proxy

# never cache anything
cache deny all

#for windows updates
quick_abort_min -1
range_offset_limit 0 all

shutdown_lifetime 2 seconds
connect_timeout 20 seconds
#debug_options ALL,2
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161026/1f0e85bd/attachment.htm>

From yvoinov at gmail.com  Wed Oct 26 18:45:19 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 27 Oct 2016 00:45:19 +0600
Subject: [squid-users] filtering http(s) sites, transparently
In-Reply-To: <CADSSinNPiGzFFe+jeEJgtYaocfYM7jynYLsGJaQqxG1Cd+Gimg@mail.gmail.com>
References: <CADSSinP_yEvv_m=d=-KLgp77FPdGwWRYAn7SaLO-DK0ptq7qAA@mail.gmail.com>
 <5701F4B0.8060001@treenet.co.nz>
 <CADSSinOuefuE+auum5UcFiOkt6mxTxs1sD_2MMMmpU6WT67jFg@mail.gmail.com>
 <57031390.8020604@treenet.co.nz>
 <CADSSinPNCRfr8kitW4RXXAYSTk8tw6ibgSYdW+7q6O2j=P0JpQ@mail.gmail.com>
 <5704F3C3.2050709@treenet.co.nz>
 <CADSSinNPiGzFFe+jeEJgtYaocfYM7jynYLsGJaQqxG1Cd+Gimg@mail.gmail.com>
Message-ID: <3ebec194-d16b-15a3-7ea8-e83a4f47abb0@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Jok,

it can be DNS leak. Does you tested it? 8.8.8.8 can be poisoned
(probably) or intercepted by ISP.


27.10.2016 0:01, Jok Thuau ?????:
> After being side-tracked with a few different project, I ended up with the config below. It appears to
do the right things, though the ACL organization could use some cleanup...
> (Browsing to authorized sites works, browsing to something else, i get
a denied page from squid)
>
> However, even though msdn.microsoft.com <http://msdn.microsoft.com> is
on my whitelist, it appears to "timeout". Looking at the logs, I see
entries like this:
>
> 2016/09/20 15:10:19.640 kid1| SECURITY ALERT: Host header forgery
detected on local=65.54.226.150:443 <http://65.54.226.150:443>
remote=10.11.12.13:51984 <http://10.0.32.177:51984> FD 18 flags=33
(local IP does not match any domain IP)
> 2016/09/20 15:10:19.640 kid1| SECURITY ALERT: By user agent:
> 2016/09/20 15:10:19.640 kid1| SECURITY ALERT: on URL:
msdn.microsoft.com:443 <http://msdn.microsoft.com:443>
> 2016/09/20 15:10:19.640 kid1| 4,2| errorpage.cc(1262) BuildContent: No
existing error page language negotiated for ERR_CONFLICT_HOST. Using
default error file.
> 2016/09/20 15:10:19.641 kid1| 20,2| store.cc(954) checkCachable:
StoreEntry::checkCachable: NO: not cachable
> 2016/09/20 15:10:19.641 kid1| 20,2| store.cc(954) checkCachable:
StoreEntry::checkCachable: NO: not cachable
> 2016/09/20 15:10:19.641 kid1| 88,2| client_side_reply.cc(2001)
processReplyAccessResult: The reply for CONNECT msdn.microsoft.com:443
<http://msdn.microsoft.com:443> is ALLOWED, because it matched SniBypass
> 2016/09/20 15:10:19.641 kid1| 33,2| client_side.cc(925)
deferRecipientForLater: clientSocketRecipient: Deferring request
msdn.microsoft.com:443 <http://msdn.microsoft.com:443>
>
> What is interesting is that we changed from using 8.8.8.8 as our DNS
server to a locally installed bind instance, and we no longer see any
issues.
> that is NOT what I expected... I can't explain why the client browser
was hanging. Any suggestions?
>
> It's all happy now, with the following config, with a firewall doing
policy based routing, a local iptables rule to redirect from port 443 to
8443, and from 80 to 3129, as well as the certificate deployed as
trusted on each endpoint:
>
> squid.conf:
> # setup standard ports
> acl SSL_ports port 443
> acl Safe_ports port 80
> acl Safe_ports port 21
> acl Safe_ports port 443
> acl Safe_ports port 70
> acl Safe_ports port 210
> acl Safe_ports port 1025-65535
> acl Safe_ports port 280
> acl Safe_ports port 488
> acl Safe_ports port 591
> acl Safe_ports port 777
> acl CONNECT method CONNECT
> # for security
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
>
> # not actually used and blocked by local firewall on host, but squid
complains if it's not there...
> http_port 3128
>
> # http intercept, and ACL that matches that inbound port
> http_port 3129 intercept
> acl http_proxy myportname 3129
>
> # same for https
> https_port 8443 intercept ssl-bump \
>     generate-host-certificates=on \
>     dynamic_cert_mem_cache_size=64MB \
>     cert=/etc/squid/ssl/proxy.pem \
>     key=/etc/squid/ssl/proxy.key \
>     cafile=/etc/squid/ssl/proxy.pe <http://proxy.pe>m
> acl https_proxy myportname 8443
>
> always_direct allow all
>
> # define the steps needed for bumping...
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
>
> # and the list of domains that are allowed
> acl SniBypass ssl::server_name_regex -i "/etc/squid/snibypass.acl"
> acl http_bypass dstdom_regex -n -i "/etc/squid/snibypass.acl"
>
> # ensure we have target SSL port when checking data
> acl https_ok all-of SniBypass SSL_ports
> # and the destination domain when not SSL...
> acl http_ok all-of http_bypass Safe_ports
>
> # splice when we know the target matches
> ssl_bump splice SniBypass
> # peek and bump otherwise
> ssl_bump peek step1
> ssl_bump stare step2
> ssl_bump bump all
>
> # some options for the certificate generation..
> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE
> sslproxy_cert_sign_hash sha256
> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 64MB
> sslcrtd_children 8 startup=1 idle=1
>
> # for http, let's block if we're not on the whitelist
> http_access         deny !http_ok        http_proxy
> # for https, let's wait until step3 of the bumping, so we can replace
the SSL content post-bumping)
> http_access         deny !https_ok step3 https_proxy
>
> # never cache anything
> cache deny all
>
> #for windows updates
> quick_abort_min -1
> range_offset_limit 0 all
>
> shutdown_lifetime 2 seconds
> connect_timeout 20 seconds
> #debug_options ALL,2
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYEPm+AAoJENNXIZxhPexGnewH/0e2rK5ZU87NSgskaJsZ5orA
3E7kwxXa9pt8M1LJLlcSD73HM3ASfO3xKqY+ajhKp0hvcApH+SwJFUVyuQktAoVS
P96WCIwobasSH7rGuBvvsuny0pwDrJfjvdkJjD7e2l/qFkHE9Fv1HBwMD1Kidp51
mJ8hqhh/xghUDOQgcGN1+Ae519+jOBwE/R8/fgtQ/i5TJeljEVgEaLFcw7eZ2/E1
qk/H1kV3YCrVeslUWIxqxAPPhcS6WQLSaqKxlxYgVk1n0Ya2SC7u75MtK2n/68z2
ejQwEguAn+uMx/IuX1nxVx47jK7DGsAyMeASLqIjofMst1ct0WuhQxyeAh7O4MA=
=H5/c
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161027/7973af63/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161027/7973af63/attachment.key>

From jok at spikes.com  Wed Oct 26 18:54:32 2016
From: jok at spikes.com (Jok Thuau)
Date: Wed, 26 Oct 2016 11:54:32 -0700
Subject: [squid-users] filtering http(s) sites, transparently
In-Reply-To: <3ebec194-d16b-15a3-7ea8-e83a4f47abb0@gmail.com>
References: <CADSSinP_yEvv_m=d=-KLgp77FPdGwWRYAn7SaLO-DK0ptq7qAA@mail.gmail.com>
 <5701F4B0.8060001@treenet.co.nz>
 <CADSSinOuefuE+auum5UcFiOkt6mxTxs1sD_2MMMmpU6WT67jFg@mail.gmail.com>
 <57031390.8020604@treenet.co.nz>
 <CADSSinPNCRfr8kitW4RXXAYSTk8tw6ibgSYdW+7q6O2j=P0JpQ@mail.gmail.com>
 <5704F3C3.2050709@treenet.co.nz>
 <CADSSinNPiGzFFe+jeEJgtYaocfYM7jynYLsGJaQqxG1Cd+Gimg@mail.gmail.com>
 <3ebec194-d16b-15a3-7ea8-e83a4f47abb0@gmail.com>
Message-ID: <CADSSinP31vp7Vdp7j-VZhkkTeRqSza1Mqigq1Ajqk38SCgeJ0A@mail.gmail.com>

On Wed, Oct 26, 2016 at 11:45 AM, Yuri Voinov <yvoinov at gmail.com> wrote:

>
>
> Jok,
>
> it can be DNS leak. Does you tested it? 8.8.8.8 can be poisoned (probably)
> or intercepted by ISP.
>
>
DNS is working fine and is not being poisoned/intercepted/messed with. The
records that come back from the google servers appear to not be consistent
(likely due to some anycast system, and not talking each time to the same
"host"). So when i request the same records back to back, each results in
one record, and that record changes really fast (non-coherent set of data,
so the results are correct, but random). Setting up the client and the
proxy to use a common infrastructure for DNS (dnsmasq on the network)
helped a lot.

Thanks,
Jok
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161026/811a7e5e/attachment.htm>

From yvoinov at gmail.com  Wed Oct 26 18:55:50 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 27 Oct 2016 00:55:50 +0600
Subject: [squid-users] filtering http(s) sites, transparently
In-Reply-To: <CADSSinP31vp7Vdp7j-VZhkkTeRqSza1Mqigq1Ajqk38SCgeJ0A@mail.gmail.com>
References: <CADSSinP_yEvv_m=d=-KLgp77FPdGwWRYAn7SaLO-DK0ptq7qAA@mail.gmail.com>
 <5701F4B0.8060001@treenet.co.nz>
 <CADSSinOuefuE+auum5UcFiOkt6mxTxs1sD_2MMMmpU6WT67jFg@mail.gmail.com>
 <57031390.8020604@treenet.co.nz>
 <CADSSinPNCRfr8kitW4RXXAYSTk8tw6ibgSYdW+7q6O2j=P0JpQ@mail.gmail.com>
 <5704F3C3.2050709@treenet.co.nz>
 <CADSSinNPiGzFFe+jeEJgtYaocfYM7jynYLsGJaQqxG1Cd+Gimg@mail.gmail.com>
 <3ebec194-d16b-15a3-7ea8-e83a4f47abb0@gmail.com>
 <CADSSinP31vp7Vdp7j-VZhkkTeRqSza1Mqigq1Ajqk38SCgeJ0A@mail.gmail.com>
Message-ID: <9bc1f729-4a67-4f2f-35eb-273d4aaa12ba@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


27.10.2016 0:54, Jok Thuau ?????:
>
> On Wed, Oct 26, 2016 at 11:45 AM, Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> wrote:
>
>
>
>     Jok,
>
>     it can be DNS leak. Does you tested it? 8.8.8.8 can be poisoned
(probably) or intercepted by ISP.
>
>
> DNS is working fine and is not being poisoned/intercepted/messed with.
The records that come back from the google servers appear to not be
consistent (likely due to some anycast system, and not talking each time
to the same "host"). So when i request the same records back to back,
each results in one record, and that record changes really fast
(non-coherent set of data, so the results are correct, but random).
Setting up the client and the proxy to use a common infrastructure for
DNS (dnsmasq on the network) helped a lot.
Yes, this is common and best practice already. I think, time to write
article on Wiki ;)
>
> Thanks,
> Jok

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYEPw1AAoJENNXIZxhPexGIW0H/Rk82EjHy/UfQm44SvsHgBeq
Pw5b1yavLtFNXSpRsLyw8wekepJvLLk1XEtGWbLC33Z3O7REBYXL2nzXD9iNzFbp
RhdF4aaIgCfp+WqHtVxRgnqoHNAmDs2U7uhJqYmXIubvbFyddRwwh/vS2Ns89/t7
BK9GuqkkeG4PrGG3ogAX8YpRaE57LaTcDXrOlco5JU/wGkxbMJzUxOvmFyl+0SLI
4xbUBgEaFFAAmJ46PWm3c8e+zo5O6k2E86asfDJUCMtnKvRPnhce8MxTH8MwkLxl
GR5UNyVAIpYWlJAqjDRRwYlEcTGfxofyZD3SKKDUP4SduwicdZArBGGirtKUdJA=
=uXwb
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161027/b485bc05/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161027/b485bc05/attachment.key>

From squid3 at treenet.co.nz  Wed Oct 26 22:37:17 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 27 Oct 2016 11:37:17 +1300
Subject: [squid-users] filtering http(s) sites, transparently
In-Reply-To: <9bc1f729-4a67-4f2f-35eb-273d4aaa12ba@gmail.com>
References: <CADSSinP_yEvv_m=d=-KLgp77FPdGwWRYAn7SaLO-DK0ptq7qAA@mail.gmail.com>
 <5701F4B0.8060001@treenet.co.nz>
 <CADSSinOuefuE+auum5UcFiOkt6mxTxs1sD_2MMMmpU6WT67jFg@mail.gmail.com>
 <57031390.8020604@treenet.co.nz>
 <CADSSinPNCRfr8kitW4RXXAYSTk8tw6ibgSYdW+7q6O2j=P0JpQ@mail.gmail.com>
 <5704F3C3.2050709@treenet.co.nz>
 <CADSSinNPiGzFFe+jeEJgtYaocfYM7jynYLsGJaQqxG1Cd+Gimg@mail.gmail.com>
 <3ebec194-d16b-15a3-7ea8-e83a4f47abb0@gmail.com>
 <CADSSinP31vp7Vdp7j-VZhkkTeRqSza1Mqigq1Ajqk38SCgeJ0A@mail.gmail.com>
 <9bc1f729-4a67-4f2f-35eb-273d4aaa12ba@gmail.com>
Message-ID: <7d04c758-e520-c6aa-2734-b7d1cafc789a@treenet.co.nz>

On 27/10/2016 7:55 a.m., Yuri Voinov wrote:
> 
> 27.10.2016 0:54, Jok Thuau ?????:
> 
>> Setting up the client and the proxy to use a common infrastructure for
>> DNS (dnsmasq on the network) helped a lot.
> 
> Yes, this is common and best practice already. I think, time to write
> article on Wiki ;)
> 

Thanks for the reminder. This and the SSL-Bump issue are now mentioned
in <http://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery>

Amos


From yvoinov at gmail.com  Wed Oct 26 22:53:39 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 27 Oct 2016 04:53:39 +0600
Subject: [squid-users] filtering http(s) sites, transparently
In-Reply-To: <7d04c758-e520-c6aa-2734-b7d1cafc789a@treenet.co.nz>
References: <CADSSinP_yEvv_m=d=-KLgp77FPdGwWRYAn7SaLO-DK0ptq7qAA@mail.gmail.com>
 <5701F4B0.8060001@treenet.co.nz>
 <CADSSinOuefuE+auum5UcFiOkt6mxTxs1sD_2MMMmpU6WT67jFg@mail.gmail.com>
 <57031390.8020604@treenet.co.nz>
 <CADSSinPNCRfr8kitW4RXXAYSTk8tw6ibgSYdW+7q6O2j=P0JpQ@mail.gmail.com>
 <5704F3C3.2050709@treenet.co.nz>
 <CADSSinNPiGzFFe+jeEJgtYaocfYM7jynYLsGJaQqxG1Cd+Gimg@mail.gmail.com>
 <3ebec194-d16b-15a3-7ea8-e83a4f47abb0@gmail.com>
 <CADSSinP31vp7Vdp7j-VZhkkTeRqSza1Mqigq1Ajqk38SCgeJ0A@mail.gmail.com>
 <9bc1f729-4a67-4f2f-35eb-273d4aaa12ba@gmail.com>
 <7d04c758-e520-c6aa-2734-b7d1cafc789a@treenet.co.nz>
Message-ID: <f26654e3-ddb4-41ed-36da-9d1b47fa2b74@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


27.10.2016 4:37, Amos Jeffries ?????:
> On 27/10/2016 7:55 a.m., Yuri Voinov wrote:
>>
>> 27.10.2016 0:54, Jok Thuau ?????:
>>
>>> Setting up the client and the proxy to use a common infrastructure for
>>> DNS (dnsmasq on the network) helped a lot.
>>
>> Yes, this is common and best practice already. I think, time to write
>> article on Wiki ;)
>>
>
> Thanks for the reminder. This and the SSL-Bump issue are now mentioned
> in <http://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery>
Wow, good to know. Much time ago last checked this page....
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYETPzAAoJENNXIZxhPexGUBcIAJ4C+/V+V0mMqQpyFYgR2u/J
BMpUnKuwGXCX3Cq+j+rH4J9/IQgk1vKtxkV5JrgJaE+4R80KLQUDlYmHgzAAlo1Y
UwuR2bljRd07JgLn+Oz5oirBCFF8aP2vTXnMaZG3EmAyXQeclyb69xVfIKXdungE
3XxFKkOjARdIcGa/md2gZswCVKlF4mZCi38p4i0Smps1zyVMEhpPBN6J/3rHT2ur
rX6sBDPNbGwn34a7XEm7AP0/91qj8CW3ddz4AH23iQsP67pGPJg/IWKnhZIgMbwz
u9XTq4xmZddEIKUT1awghXMgamyIqo3oKD+OzidwCJvIV1HI4YSfWYIaN3DfiM8=
=4j39
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161027/e62574bc/attachment.key>

From john.e.huggins at gmail.com  Wed Oct 26 23:30:36 2016
From: john.e.huggins at gmail.com (john huggins)
Date: Wed, 26 Oct 2016 18:30:36 -0500
Subject: [squid-users] Using Squid to Create Multiple Proxy IP's
Message-ID: <CAF7W3WFbPHbZL7RMKi3hA5d3cDZPfreDZR42yKhtSiiS0saZOA@mail.gmail.com>

I've looked up and down everywhere but I can't seem how to use squid to
mass create multiple proxy IP's. Any help would be appreciated it.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161026/e9f5a396/attachment.htm>

From squid3 at treenet.co.nz  Wed Oct 26 23:52:41 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 27 Oct 2016 12:52:41 +1300
Subject: [squid-users] Using Squid to Create Multiple Proxy IP's
In-Reply-To: <CAF7W3WFbPHbZL7RMKi3hA5d3cDZPfreDZR42yKhtSiiS0saZOA@mail.gmail.com>
References: <CAF7W3WFbPHbZL7RMKi3hA5d3cDZPfreDZR42yKhtSiiS0saZOA@mail.gmail.com>
Message-ID: <5d158bbb-103a-cc85-fadf-6403c83249d7@treenet.co.nz>

On 27/10/2016 12:30 p.m., john huggins wrote:
> I've looked up and down everywhere but I can't seem how to use squid to
> mass create multiple proxy IP's. Any help would be appreciated it.
> 

What do you mean by "create multiple proxy IP's" ??

IP and HTTP are different protocols. Neither one "creates" addresses.

Amos



From squid3 at treenet.co.nz  Thu Oct 27 02:31:06 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 27 Oct 2016 15:31:06 +1300
Subject: [squid-users] Using Squid to Create Multiple Proxy IP's
In-Reply-To: <CAF7W3WHfh9bH6xF4z0+igWPWzQHkJeqotWvNXnHPoZUeKnM6wQ@mail.gmail.com>
References: <CAF7W3WFbPHbZL7RMKi3hA5d3cDZPfreDZR42yKhtSiiS0saZOA@mail.gmail.com>
 <5d158bbb-103a-cc85-fadf-6403c83249d7@treenet.co.nz>
 <CAF7W3WG=iL500Cqn=W=aDds6hJfHTLzdBzWLbQgCSxEcFSQbEg@mail.gmail.com>
 <CAF7W3WHfh9bH6xF4z0+igWPWzQHkJeqotWvNXnHPoZUeKnM6wQ@mail.gmail.com>
Message-ID: <4e8297c8-a63e-c8f0-808b-1cf38301882b@treenet.co.nz>

On 27/10/2016 3:18 p.m., john huggins wrote:
> Okay maybe this makes more sense.. Can I assign multiple private IP's to it
> all at once
> 

Um ...

The basic/default configuration of Squid does not involve IP assignments
at all. Just a listening port (3128) receiving all traffic sent to that
port on any IP that machine has been configured to use (including
localhost, local-scope, link-local, etc).

Listening on just one IP:port is an optional extra you have to configure
explicitly. That can be manually repeated for multiple IPs.

You can also configure Squid to listen on a hostname:port and setup DNS
to have a few IPs for that hostname. For when you want multiple IPs but
not everything assigned to the machine.

Amos



From john.e.huggins at gmail.com  Thu Oct 27 02:37:10 2016
From: john.e.huggins at gmail.com (john huggins)
Date: Wed, 26 Oct 2016 21:37:10 -0500
Subject: [squid-users] Using Squid to Create Multiple Proxy IP's
In-Reply-To: <4e8297c8-a63e-c8f0-808b-1cf38301882b@treenet.co.nz>
References: <CAF7W3WFbPHbZL7RMKi3hA5d3cDZPfreDZR42yKhtSiiS0saZOA@mail.gmail.com>
 <5d158bbb-103a-cc85-fadf-6403c83249d7@treenet.co.nz>
 <CAF7W3WG=iL500Cqn=W=aDds6hJfHTLzdBzWLbQgCSxEcFSQbEg@mail.gmail.com>
 <CAF7W3WHfh9bH6xF4z0+igWPWzQHkJeqotWvNXnHPoZUeKnM6wQ@mail.gmail.com>
 <4e8297c8-a63e-c8f0-808b-1cf38301882b@treenet.co.nz>
Message-ID: <CAF7W3WFBNZWo-9HpUx0q2T7+DSWmTEGia2b2i2LOD96udTO3qQ@mail.gmail.com>

Okay so if I create multiple private IP addresses on my virtual service
provider, how would I go about using them with squid.

My goal: to use these IP's to spoof my public IP. If one gets banned or
goes dead, I just go to my network setting on my local machine and change
the proxy to an active "spoofed ip"

*im trying to use the correct terminology to the best of my ability, in
order to explain. So if I use the wrong wording I apologize, since using
proxy servers are new to me.

On Wednesday, October 26, 2016, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 27/10/2016 3:18 p.m., john huggins wrote:
> > Okay maybe this makes more sense.. Can I assign multiple private IP's to
> it
> > all at once
> >
>
> Um ...
>
> The basic/default configuration of Squid does not involve IP assignments
> at all. Just a listening port (3128) receiving all traffic sent to that
> port on any IP that machine has been configured to use (including
> localhost, local-scope, link-local, etc).
>
> Listening on just one IP:port is an optional extra you have to configure
> explicitly. That can be manually repeated for multiple IPs.
>
> You can also configure Squid to listen on a hostname:port and setup DNS
> to have a few IPs for that hostname. For when you want multiple IPs but
> not everything assigned to the machine.
>
> Amos
>
>

-- 

[image: Campus Protein] <https://htmlsig.com/t/000001BK8QRR>

Eric Huggins / Sale Representative
john.e.huggins at gmail.com / (918) 606-1636

Campus Protein
http://EricCP.com

[image: Twitter]  <https://twitter.com/ericcpfit> [image: Facebook]
<https://www.facebook.com/johneric.huggins> [image: Instagram]
<https://instagram.com/ericcpfit>

<https://www.campusprotein.com/collections/vendors?q=BPI#_l_30c>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161026/e0766589/attachment.htm>

From squid3 at treenet.co.nz  Thu Oct 27 02:51:58 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 27 Oct 2016 15:51:58 +1300
Subject: [squid-users] Using Squid to Create Multiple Proxy IP's
In-Reply-To: <CAF7W3WFBNZWo-9HpUx0q2T7+DSWmTEGia2b2i2LOD96udTO3qQ@mail.gmail.com>
References: <CAF7W3WFbPHbZL7RMKi3hA5d3cDZPfreDZR42yKhtSiiS0saZOA@mail.gmail.com>
 <5d158bbb-103a-cc85-fadf-6403c83249d7@treenet.co.nz>
 <CAF7W3WG=iL500Cqn=W=aDds6hJfHTLzdBzWLbQgCSxEcFSQbEg@mail.gmail.com>
 <CAF7W3WHfh9bH6xF4z0+igWPWzQHkJeqotWvNXnHPoZUeKnM6wQ@mail.gmail.com>
 <4e8297c8-a63e-c8f0-808b-1cf38301882b@treenet.co.nz>
 <CAF7W3WFBNZWo-9HpUx0q2T7+DSWmTEGia2b2i2LOD96udTO3qQ@mail.gmail.com>
Message-ID: <596c65d3-f525-2bad-3093-b47eb05f5211@treenet.co.nz>

On 27/10/2016 3:37 p.m., john huggins wrote:
> Okay so if I create multiple private IP addresses on my virtual service
> provider, how would I go about using them with squid.
> 
> My goal: to use these IP's to spoof my public IP. If one gets banned or
> goes dead, I just go to my network setting on my local machine and change
> the proxy to an active "spoofed ip"

Ah. That is outgoing from Squid. Not incoming from clients. My earlier
reply details do not apply.


IP addressing on the outgoing connections is an operating system choice.
Squid does not have any direct control over outgoing connections besides
their destination IP:port.

You can try tcp_outgoing_address directive and ACLs to select which IP
Squid asks the OS for as source-IP on any particular HTTP request.
 <http://www.squid-cache.org/Doc/config/tcp_outgoing_address/>

But this is only a hint to the OS. It will make the final choise of
outgoing IP address.

ALso, if you have (like most networks do these days) a NAT translating
between the LAN and the WAN space all the effort in Squid may be erased
by the NAT.


> 
> *im trying to use the correct terminology to the best of my ability, in
> order to explain. So if I use the wrong wording I apologize, since using
> proxy servers are new to me.
> 

No worries. It just slows things down a bit. We have managed to muddle
through that now I hope. :-)

NP: for anonymity with Squid you will want to configure:

 forwarded_for transparent
 via off


Amos



From wolle5050 at gmx.de  Thu Oct 27 05:40:59 2016
From: wolle5050 at gmx.de (Jens Offenbach)
Date: Thu, 27 Oct 2016 07:40:59 +0200
Subject: [squid-users] TProxy not working (Squid 3.5.12,
 Ubuntu Server 16.04.1)
In-Reply-To: <1a01fc55-1673-ff7a-2503-4749a0d5796a@treenet.co.nz>
References: <trinity-d9cfc3d9-2ca2-4a26-93cc-c36acaa8070e-1477464120242@3capp-gmx-bs30>, 
 <1a01fc55-1673-ff7a-2503-4749a0d5796a@treenet.co.nz>
Message-ID: <trinity-573af4cb-8350-4a93-9435-b91c25f8d5c4-1477546859914@3capp-gmx-bs58>

@Amos
Thank you very much for improving the Squid configuration. I am currently in the setup phase and "opened" everything, in order not to run into permission problems. I have added and removed your suggestions, respectively. The configuration looks much better now.

I was able to solve my Tproxy problem. The routing table was missing. The following commands fixed it:
ip rule add fwmark 0x1 lookup 100
ip route add local 0.0.0.0/0 dev lo table 100

Regards,
Jens
?

Gesendet:?Mittwoch, 26. Oktober 2016 um 13:12 Uhr
Von:?"Amos Jeffries" <squid3 at treenet.co.nz>
An:?squid-users at lists.squid-cache.org
Betreff:?Re: [squid-users] TProxy not working (Squid 3.5.12, Ubuntu Server 16.04.1)
On 26/10/2016 7:42 p.m., Jens Offenbach wrote:
> Hi,
> I am trying to setup a transparent proxy with Squid 3.5.12 on Ubuntu Server 16.04.1, but I cannot get it working. When a client tries to connect to the web, the connection always times out.
>
> Hopefully, someone has an idea what's going.
>
> uname-r:
> 4.4.0-45-generic
>
> sysct:
> net.ipv4.ip_forward=1
> net.ipv4.conf.default.rp_filter=0
> net.ipv4.conf.all.rp_filter=0
>
> squid.conf:
> # ACCESS CONTROLS
> # -----------------------------------------------------------------------------
> acl localnet src 139.2.0.0/16
> acl localnet src 193.96.112.0/21
> acl localnet src 192.109.216.0/24
> acl localnet src 100.1.4.0/22
> acl localnet src 10.0.0.0/8
> acl localnet src 172.16.0.0/12
> acl localnet src 192.168.0.0/16
> acl to_localnet dst 139.2.0.0/16
> acl to_localnet dst 193.96.112.0/21
> acl to_localnet dst 192.109.216.0/24
> acl to_localnet dst 100.1.4.0/22
> acl to_localnet dst 10.0.0.0/8
> acl to_localnet dst 172.16.0.0/12
> acl to_localnet dst 192.168.0.0/16
>

Missing basic security controlsto prevent this being an abused open proxy.
http_access deny !Safe_Ports
http_access deny CONNECT !SSL_Ports


> http_access allow manager localhost
> http_access deny manager
> http_access allow localnet
> http_access allow localhost
> http_access allow to_localnet

Permits external visitors uncontrolled access to your LAN IP spaces.
Particularly when combined with the "always_direct allow to_localnet" below.
Really want that?

> http_access deny all
>
> # NETWORK OPTIONS
> # -----------------------------------------------------------------------------
> http_port 10.30.200.99:3128
> http_port 10.30.216.254:3128
> http_port 10.30.216.254:3129 tproxy
>
> # OPTIONS WHICH AFFECT THE NEIGHBOR SELECTION ALGORITHM
> # -----------------------------------------------------------------------------
> cache_peer proxy.mycompany.com parent 8080 0 no-query no-digest default
> cache_peer roxy.mycompany.com parent 8080 0 no-query no-digest

I suspect the peers are sending TCP SYN+ACK responses directly back to
the client IP which Squid is spoofing.

Add the option "no-tproxy" to these peer lines to avoid that.

>
> # MEMORY CACHE OPTIONS
> # -----------------------------------------------------------------------------
> maximum_object_size_in_memory 8 MB
> memory_replacement_policy heap LFUDA
> cache_mem 256 MB
>
> # DISK CACHE OPTIONS
> # -----------------------------------------------------------------------------
> maximum_object_size 10 GB
> cache_replacement_policy heap GDSF
> cache_dir ufs /var/cache/squid 88894 16 256 max-size=10737418240
>
> # LOGFILE OPTIONS
> # -----------------------------------------------------------------------------
> access_log daemon:/var/log/squid/access.log squid
> cache_store_log daemon:/var/log/squid/store.log
>

store.log is very rarely needed. You might consider removing it for some
extra speed out of the proxy.


> # OPTIONS FOR TROUBLESHOOTING
> # -----------------------------------------------------------------------------
> cache_log /var/log/squid/cache.log
> coredump_dir /var/log/squid
>
> # OPTIONS FOR TUNING THE CACHE
> # -----------------------------------------------------------------------------
> cache allow all

Unnecessary default value configured.

>
> # ADMINISTRATIVE PARAMETERS
> # -----------------------------------------------------------------------------
> visible_hostname my-proxy.mycompany.com
>
> # ICP OPTIONS
> # -----------------------------------------------------------------------------
> icp_port 0
>

Unnecessary default value configured.

> # OPTIONS INFLUENCING REQUEST FORWARDING
> # -----------------------------------------------------------------------------
> always_direct allow to_localnet
> always_direct allow to_localhost
> never_direct allow all
>

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From augustus_meyer at gmx.net  Thu Oct 27 11:54:09 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Thu, 27 Oct 2016 04:54:09 -0700 (PDT)
Subject: [squid-users] external_acl_type problem
In-Reply-To: <c5a29ab0-922a-53e0-27f5-adbe60208e7a@treenet.co.nz>
References: <1477219171447-4680203.post@n4.nabble.com>
 <07e501d22f18$c4e66600$4eb33200$@ngtech.co.il>
 <1477472216790-4680302.post@n4.nabble.com>
 <081101d22f77$d20e1e40$762a5ac0$@ngtech.co.il>
 <1477480347296-4680306.post@n4.nabble.com>
 <c5a29ab0-922a-53e0-27f5-adbe60208e7a@treenet.co.nz>
Message-ID: <1477569249833-4680328.post@n4.nabble.com>

>> It very looks like squids accouting of helpers is disturbed: I see much
more
>> than max helpers active after a few hours.  And lot of helpers stay
>> alive,
>> when I kill parent process squid.

>By 'kill' do you mean something like "kill -9" ?

>Or do you mean the proper "kill -SIGHUP" or "squid -k shutdown" sequence ?

Few helpers stay alive (also) for "squid -k shutdown".

I was too optimistic; %SRC %SRCPORT does not help. 

I have seen the recent patch in this area, but it seems not to change any
functionality within squid.
Will use it, anyway




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/external-acl-type-problem-tp4680203p4680328.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From uhlar at fantomas.sk  Thu Oct 27 13:02:55 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 27 Oct 2016 15:02:55 +0200
Subject: [squid-users] Using Squid to Create Multiple Proxy IP's
In-Reply-To: <CAF7W3WFBNZWo-9HpUx0q2T7+DSWmTEGia2b2i2LOD96udTO3qQ@mail.gmail.com>
References: <CAF7W3WFbPHbZL7RMKi3hA5d3cDZPfreDZR42yKhtSiiS0saZOA@mail.gmail.com>
 <5d158bbb-103a-cc85-fadf-6403c83249d7@treenet.co.nz>
 <CAF7W3WG=iL500Cqn=W=aDds6hJfHTLzdBzWLbQgCSxEcFSQbEg@mail.gmail.com>
 <CAF7W3WHfh9bH6xF4z0+igWPWzQHkJeqotWvNXnHPoZUeKnM6wQ@mail.gmail.com>
 <4e8297c8-a63e-c8f0-808b-1cf38301882b@treenet.co.nz>
 <CAF7W3WFBNZWo-9HpUx0q2T7+DSWmTEGia2b2i2LOD96udTO3qQ@mail.gmail.com>
Message-ID: <20161027130254.GA27502@fantomas.sk>

On 26.10.16 21:37, john huggins wrote:
>My goal: to use these IP's to spoof my public IP. If one gets banned or
>goes dead, I just go to my network setting on my local machine and change
>the proxy to an active "spoofed ip"

only your public IP will get to world.
When you get multiple IPs assigned by your ISP, you can select one of them,
buy you can not use private IPs to hide your real one.

note that all your IPs can get blocked by remote servers and even by your
ISP...

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
How does cat play with mouse? cat /dev/mouse


From erdosain9 at gmail.com  Thu Oct 27 16:08:20 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 27 Oct 2016 09:08:20 -0700 (PDT)
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <1477495241988-4680314.post@n4.nabble.com>
References: <1477487652545-4680309.post@n4.nabble.com>
 <1477495241988-4680314.post@n4.nabble.com>
Message-ID: <1477584500484-4680330.post@n4.nabble.com>

Ok... but i have this problem

 ERROR: NAT/TPROXY lookup failed to locate original IPs on
local=192.168.1.15:3130 remote=192.168.1.1:52090 FD 14 flags=33

...
I put some dstnat in Mikrotik (192.168.1.1)


ip firewall nat add chain=dstnat src-add=192.168.1.121 protocol=tcp
dst-port=80  action=dst-nat 
to-addresses=192.168.1.20 to-ports=3129

ERROR: NAT/TPROXY lookup failed to locate original IPs on
local=192.168.1.20:3129 remote=192.168.1.1:52153 FD 14 flags=33
2016/10/27 14:01:43 kid1| ERROR: NF getsockopt(ORIGINAL_DST) failed on
local=192.168.1.215:3129 remote=192.168.1.1:52154 FD 14 flags=33: (92)
Protocol not available

I dont have iptables or firewalld... im using Centos... is necessary enable
firewalld or iptables??? 


im using the PC (192.168.1.121 for test)
Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Transparent-and-non-Transparent-at-the-same-time-tp4680309p4680330.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Thu Oct 27 17:46:53 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 27 Oct 2016 20:46:53 +0300
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <1477584500484-4680330.post@n4.nabble.com>
References: <1477487652545-4680309.post@n4.nabble.com>
 <1477495241988-4680314.post@n4.nabble.com>
 <1477584500484-4680330.post@n4.nabble.com>
Message-ID: <05b601d2307a$1a6dc2f0$4f4948d0$@ngtech.co.il>

You need routing policy not DNAT.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Thursday, October 27, 2016 19:08
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Transparent and non Transparent at the same time

Ok... but i have this problem

 ERROR: NAT/TPROXY lookup failed to locate original IPs on
local=192.168.1.15:3130 remote=192.168.1.1:52090 FD 14 flags=33

...
I put some dstnat in Mikrotik (192.168.1.1)


ip firewall nat add chain=dstnat src-add=192.168.1.121 protocol=tcp
dst-port=80  action=dst-nat
to-addresses=192.168.1.20 to-ports=3129

ERROR: NAT/TPROXY lookup failed to locate original IPs on
local=192.168.1.20:3129 remote=192.168.1.1:52153 FD 14 flags=33
2016/10/27 14:01:43 kid1| ERROR: NF getsockopt(ORIGINAL_DST) failed on
local=192.168.1.215:3129 remote=192.168.1.1:52154 FD 14 flags=33: (92) Protocol not available

I dont have iptables or firewalld... im using Centos... is necessary enable firewalld or iptables??? 


im using the PC (192.168.1.121 for test) Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Transparent-and-non-Transparent-at-the-same-time-tp4680309p4680330.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From jarrett+squid-users at jarrettgraham.com  Thu Oct 27 17:48:38 2016
From: jarrett+squid-users at jarrettgraham.com (jarrett+squid-users at jarrettgraham.com)
Date: Thu, 27 Oct 2016 13:48:38 -0400
Subject: [squid-users] Custom User Agent Per ACL
Message-ID: <2efca5d4-a5a1-e720-6c5c-584b49926178@jarrettgraham.com>

Is it possible to have a custom "request_header_replace User-Agent" assigned to mapped acl/listening port/tcp_outgoing_address?

Examples:
acl ipv4-1 myportname 3128 src xxx.xxx.xxx.xxx/24http_access allow ipv4-1 -> request_header_replace User Agent "Firefox xxxxx" ipv4-1 -> tcp_outgoing_address xxx.xxx.xxx.xxx ipv4-1
acl ipv4-2 myportname 3129 src xxx.xxx.xxx.xxx/24 -> http_access allow ipv4-2 -> request_header_replace User Agent "Internet Explorer xxxxx" ipv4-2 -> tcp_outgoing_address xxx.xxx.xxx.xxx ipv4-2

Thanks!



From yvoinov at gmail.com  Thu Oct 27 17:51:22 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 27 Oct 2016 23:51:22 +0600
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <05b601d2307a$1a6dc2f0$4f4948d0$@ngtech.co.il>
References: <1477487652545-4680309.post@n4.nabble.com>
 <1477495241988-4680314.post@n4.nabble.com>
 <1477584500484-4680330.post@n4.nabble.com>
 <05b601d2307a$1a6dc2f0$4f4948d0$@ngtech.co.il>
Message-ID: <96df8157-c896-dc68-0547-ca84cffec168@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
You absolutely sure, Eliezier? :)


27.10.2016 23:46, Eliezer Croitoru ?????:
> You need routing policy not DNAT.
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
On Behalf Of erdosain9
> Sent: Thursday, October 27, 2016 19:08
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Transparent and non Transparent at the same
time
>
> Ok... but i have this problem
>
>  ERROR: NAT/TPROXY lookup failed to locate original IPs on
> local=192.168.1.15:3130 remote=192.168.1.1:52090 FD 14 flags=33
>
> ...
> I put some dstnat in Mikrotik (192.168.1.1)
>
>
> ip firewall nat add chain=dstnat src-add=192.168.1.121 protocol=tcp
> dst-port=80  action=dst-nat
> to-addresses=192.168.1.20 to-ports=3129
>
> ERROR: NAT/TPROXY lookup failed to locate original IPs on
> local=192.168.1.20:3129 remote=192.168.1.1:52153 FD 14 flags=33
> 2016/10/27 14:01:43 kid1| ERROR: NF getsockopt(ORIGINAL_DST) failed on
> local=192.168.1.215:3129 remote=192.168.1.1:52154 FD 14 flags=33: (92)
Protocol not available
>
> I dont have iptables or firewalld... im using Centos... is necessary
enable firewalld or iptables???
>
>
> im using the PC (192.168.1.121 for test) Thanks
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Transparent-and-non-Transparent-at-the-same-time-tp4680309p4680330.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYEj6aAAoJENNXIZxhPexGKMwH/1bJbs+gQQAg5rdk/pyskSYB
hPxlzR2MCa2glOhDMKqcnBBscv94ITVJW4eCzxZZZaNhAe1xbBISUhFfS3SBpCbn
C6RfOMG0N2D1uXRDRtskuoELMbfxOsRPGLcUC1a7acUts299k+oTz1kpLlzWWWTB
kfNvDZTLTvatvgGTI6lD9EUjk7zR0DbzXDX6AuF8UZ2z2izv/RqPMFKu9se+zkGe
gjGgDNYwD1gBDXhPvTzLRjRnWgZPv0Cb4L63JPerZvl+nPt6gcfPf32DR8imkKeg
YnDp3YDZQcZqMZRWANBb7UZefQ/PNisoHhLybhoQ7SuyKEVq2tKmq1DPwcSy18A=
=iuPQ
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161027/c470245f/attachment.key>

From eliezer at ngtech.co.il  Thu Oct 27 17:55:25 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 27 Oct 2016 20:55:25 +0300
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <96df8157-c896-dc68-0547-ca84cffec168@gmail.com>
References: <1477487652545-4680309.post@n4.nabble.com>
 <1477495241988-4680314.post@n4.nabble.com>
 <1477584500484-4680330.post@n4.nabble.com>
 <05b601d2307a$1a6dc2f0$4f4948d0$@ngtech.co.il>
 <96df8157-c896-dc68-0547-ca84cffec168@gmail.com>
Message-ID: <05be01d2307b$4bff2a10$e3fd7e30$@ngtech.co.il>

Well this is the most efficient and less risker way.
I do not know MikroTik enough to the hardware but it has a routing engine so... routing policy.
In the past I wrote about it somewhere with details instructions on how to do it in a mikrotik.

Eliezer 

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
Sent: Thursday, October 27, 2016 20:51
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Transparent and non Transparent at the same time


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
You absolutely sure, Eliezier? :)


27.10.2016 23:46, Eliezer Croitoru ?????:
> You need routing policy not DNAT.
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
On Behalf Of erdosain9
> Sent: Thursday, October 27, 2016 19:08
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Transparent and non Transparent at the same
time
>
> Ok... but i have this problem
>
>  ERROR: NAT/TPROXY lookup failed to locate original IPs on
> local=192.168.1.15:3130 remote=192.168.1.1:52090 FD 14 flags=33
>
> ...
> I put some dstnat in Mikrotik (192.168.1.1)
>
>
> ip firewall nat add chain=dstnat src-add=192.168.1.121 protocol=tcp
> dst-port=80  action=dst-nat
> to-addresses=192.168.1.20 to-ports=3129
>
> ERROR: NAT/TPROXY lookup failed to locate original IPs on
> local=192.168.1.20:3129 remote=192.168.1.1:52153 FD 14 flags=33
> 2016/10/27 14:01:43 kid1| ERROR: NF getsockopt(ORIGINAL_DST) failed on
> local=192.168.1.215:3129 remote=192.168.1.1:52154 FD 14 flags=33: (92)
Protocol not available
>
> I dont have iptables or firewalld... im using Centos... is necessary
enable firewalld or iptables???
>
>
> im using the PC (192.168.1.121 for test) Thanks
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Transparent-and-non-Transparent-at-the-same-time-tp4680309p4680330.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYEj6aAAoJENNXIZxhPexGKMwH/1bJbs+gQQAg5rdk/pyskSYB
hPxlzR2MCa2glOhDMKqcnBBscv94ITVJW4eCzxZZZaNhAe1xbBISUhFfS3SBpCbn
C6RfOMG0N2D1uXRDRtskuoELMbfxOsRPGLcUC1a7acUts299k+oTz1kpLlzWWWTB
kfNvDZTLTvatvgGTI6lD9EUjk7zR0DbzXDX6AuF8UZ2z2izv/RqPMFKu9se+zkGe
gjGgDNYwD1gBDXhPvTzLRjRnWgZPv0Cb4L63JPerZvl+nPt6gcfPf32DR8imkKeg
YnDp3YDZQcZqMZRWANBb7UZefQ/PNisoHhLybhoQ7SuyKEVq2tKmq1DPwcSy18A=
=iuPQ
-----END PGP SIGNATURE-----




From yvoinov at gmail.com  Thu Oct 27 17:58:21 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 27 Oct 2016 23:58:21 +0600
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <05be01d2307b$4bff2a10$e3fd7e30$@ngtech.co.il>
References: <1477487652545-4680309.post@n4.nabble.com>
 <1477495241988-4680314.post@n4.nabble.com>
 <1477584500484-4680330.post@n4.nabble.com>
 <05b601d2307a$1a6dc2f0$4f4948d0$@ngtech.co.il>
 <96df8157-c896-dc68-0547-ca84cffec168@gmail.com>
 <05be01d2307b$4bff2a10$e3fd7e30$@ngtech.co.il>
Message-ID: <a67b8933-7fbb-ade0-7103-fb181d194cc8@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Once more: You are really absolutely sure you talking about Squid's
transparent interception proxy?

Well, let's open Squid's wiki:

http://wiki.squid-cache.org/ConfigExamples/Intercept

Please, read to us latest statement on this screenshot:

https://i1.someimage.com/uKbfdot.png

27.10.2016 23:55, Eliezer Croitoru ?????:
> Well this is the most efficient and less risker way.
> I do not know MikroTik enough to the hardware but it has a routing
engine so... routing policy.
> In the past I wrote about it somewhere with details instructions on
how to do it in a mikrotik.
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
On Behalf Of Yuri Voinov
> Sent: Thursday, October 27, 2016 20:51
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Transparent and non Transparent at the same
time
>
>
> You absolutely sure, Eliezier? :)
>
>
> 27.10.2016 23:46, Eliezer Croitoru ?????:
> > You need routing policy not DNAT.
>
> > Eliezer
>
> > ----
> > Eliezer Croitoru
> > Linux System Administrator
> > Mobile: +972-5-28704261
> > Email: eliezer at ngtech.co.il
>
>
> > -----Original Message-----
> > From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
> On Behalf Of erdosain9
> > Sent: Thursday, October 27, 2016 19:08
> > To: squid-users at lists.squid-cache.org
> > Subject: Re: [squid-users] Transparent and non Transparent at the same
> time
>
> > Ok... but i have this problem
>
> >  ERROR: NAT/TPROXY lookup failed to locate original IPs on
> > local=192.168.1.15:3130 remote=192.168.1.1:52090 FD 14 flags=33
>
> > ...
> > I put some dstnat in Mikrotik (192.168.1.1)
>
>
> > ip firewall nat add chain=dstnat src-add=192.168.1.121 protocol=tcp
> > dst-port=80  action=dst-nat
> > to-addresses=192.168.1.20 to-ports=3129
>
> > ERROR: NAT/TPROXY lookup failed to locate original IPs on
> > local=192.168.1.20:3129 remote=192.168.1.1:52153 FD 14 flags=33
> > 2016/10/27 14:01:43 kid1| ERROR: NF getsockopt(ORIGINAL_DST) failed on
> > local=192.168.1.215:3129 remote=192.168.1.1:52154 FD 14 flags=33: (92)
> Protocol not available
>
> > I dont have iptables or firewalld... im using Centos... is necessary
> enable firewalld or iptables???
>
>
> > im using the PC (192.168.1.121 for test) Thanks
>
>
>
> > --
> > View this message in context:
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Transparent-and-non-Transparent-at-the-same-time-tp4680309p4680330.html
> > Sent from the Squid - Users mailing list archive at Nabble.com.
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
>

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYEkA9AAoJENNXIZxhPexG6SQH/3KfdIijTUfo9P+gIAr/RRq4
ph8xJbzoLsxTBT+3TXdO4dTm0g9WJev7ZzJfKe0GcZsKWah6XSIzgYivm7HVFJ1Q
z2r1FC5ofyfIgLB66a1wXtAe+RDwbsIH5/LIEcQPEcdYbCdU5ELE/Z/iJ2v89YjZ
73TWJYCZOCgCehUfMvkR+cfnqZP8jl+BxvnPPdfAwYjWEyIJRVwgHYWsfYXt3EuM
2+I6m5IXOwjFPzxIM4OEOmGl3e8jrCUCfk6ao11zxGLux5wmsPYb/NJXh9wQyr0n
fld7PAS8ijeqIReZf7MYy2M8kgoSkWRr31o2TMnKRtL10p6EZB59tho5EByD5m0=
=YqFK
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161027/ffa49c40/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161027/ffa49c40/attachment.key>

From yvoinov at gmail.com  Thu Oct 27 18:08:17 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 28 Oct 2016 00:08:17 +0600
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <1477584500484-4680330.post@n4.nabble.com>
References: <1477487652545-4680309.post@n4.nabble.com>
 <1477495241988-4680314.post@n4.nabble.com>
 <1477584500484-4680330.post@n4.nabble.com>
Message-ID: <d7ef0c6a-c2df-1da9-1e2f-cbace787c694@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
erdosain9,

here is documentation your required.

http://wiki.squid-cache.org/ConfigExamples/Intercept

Sadly, but interception proxy with modern Squid, in addition to router
with PBR/WCCP redirection, also always required NAT, configured on proxy
box - iptables/IPF/IPFilter etc. and requires to build squid with
appropriate NAT support.

This is a bit more complex technical task, which is required more
computer skills.

So, start from good Squid's documentation. ;-)

Hard luck! :-)


27.10.2016 22:08, erdosain9 ?????:
> Ok... but i have this problem
>
>  ERROR: NAT/TPROXY lookup failed to locate original IPs on
> local=192.168.1.15:3130 remote=192.168.1.1:52090 FD 14 flags=33
>
> ...
> I put some dstnat in Mikrotik (192.168.1.1)
>
>
> ip firewall nat add chain=dstnat src-add=192.168.1.121 protocol=tcp
> dst-port=80  action=dst-nat
> to-addresses=192.168.1.20 to-ports=3129
>
> ERROR: NAT/TPROXY lookup failed to locate original IPs on
> local=192.168.1.20:3129 remote=192.168.1.1:52153 FD 14 flags=33
> 2016/10/27 14:01:43 kid1| ERROR: NF getsockopt(ORIGINAL_DST) failed on
> local=192.168.1.215:3129 remote=192.168.1.1:52154 FD 14 flags=33: (92)
> Protocol not available
>
> I dont have iptables or firewalld... im using Centos... is necessary
enable
> firewalld or iptables???
>
>
> im using the PC (192.168.1.121 for test)
> Thanks
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Transparent-and-non-Transparent-at-the-same-time-tp4680309p4680330.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYEkKQAAoJENNXIZxhPexGtP0H/0kB5mJMQmJWZgVCD7ZLQ5/A
lqYYEp0mwj2WiLMOeRa9uz+RW8qlzPX2Kw1DmrhjfMGTsCsjOcyRnd4w87hY0S1/
Q9DYJ4dfbtQMz/WKB6gf0D2/lv2Wc4eCuqS5QXGRgF5/wenfJuMKB42BN5dMshBN
hB5Kfw7p9ywvrB+GR9zHvADIcOlgu4tobR5bUAraQKhUk82PMRojbutnRBXcTUL3
gKjLFXg4VFi3LDJospVr4lMMif0vkacEpI8XHbscqClngTNEKQvQN1MLD+5JQL3y
oWGgmUzmvEGTJGRCntlKSriFS+DJn1GUcUVplALehXjSRAyJp7aIC0Q+Vc/GCfU=
=zxIL
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161028/5863dcdf/attachment.key>

From Antony.Stone at squid.open.source.it  Thu Oct 27 18:54:32 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 27 Oct 2016 20:54:32 +0200
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <96df8157-c896-dc68-0547-ca84cffec168@gmail.com>
References: <1477487652545-4680309.post@n4.nabble.com>
 <05b601d2307a$1a6dc2f0$4f4948d0$@ngtech.co.il>
 <96df8157-c896-dc68-0547-ca84cffec168@gmail.com>
Message-ID: <201610272054.32686.Antony.Stone@squid.open.source.it>

On Thursday 27 October 2016 at 19:51:22, Yuri Voinov wrote:

> You absolutely sure, Eliezier? :)

Yes - you do not use DNAT.

You do use REDIRECT on the machine Squid is running on.


Antony.

> 27.10.2016 23:46, Eliezer Croitoru ?????:
> > You need routing policy not DNAT.
> > 
> > Eliezer
> > 
> > ----
> > Eliezer Croitoru
> > Linux System Administrator
> > Mobile: +972-5-28704261
> > Email: eliezer at ngtech.co.il
> > 
> > 
> > -----Original Message-----
> > From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
> 
> On Behalf Of erdosain9
> 
> > Sent: Thursday, October 27, 2016 19:08
> > To: squid-users at lists.squid-cache.org
> > Subject: Re: [squid-users] Transparent and non Transparent at the same
> 
> time
> 
> > Ok... but i have this problem
> > 
> >  ERROR: NAT/TPROXY lookup failed to locate original IPs on
> > 
> > local=192.168.1.15:3130 remote=192.168.1.1:52090 FD 14 flags=33
> > 
> > ...
> > I put some dstnat in Mikrotik (192.168.1.1)
> > 
> > 
> > ip firewall nat add chain=dstnat src-add=192.168.1.121 protocol=tcp
> > dst-port=80  action=dst-nat
> > to-addresses=192.168.1.20 to-ports=3129
> > 
> > ERROR: NAT/TPROXY lookup failed to locate original IPs on
> > local=192.168.1.20:3129 remote=192.168.1.1:52153 FD 14 flags=33
> > 2016/10/27 14:01:43 kid1| ERROR: NF getsockopt(ORIGINAL_DST) failed on
> > local=192.168.1.215:3129 remote=192.168.1.1:52154 FD 14 flags=33: (92)
> 
> Protocol not available
> 
> > I dont have iptables or firewalld... im using Centos... is necessary
> 
> enable firewalld or iptables???
> 
> > im using the PC (192.168.1.121 for test) Thanks
> 
> http://squid-web-proxy-cache.1019090.n4.nabble.com/Transparent-and-non-Tran
> sparent-at-the-same-time-tp4680309p4680330.html
> 
> > Sent from the Squid - Users mailing list archive at Nabble.com.
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
> > 
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users

-- 
#define SIX 1+5
#define NINE 8+1

int main() {
    printf("%d\n", SIX * NINE);
}
	- thanks to ECB for bringing this to my attention

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Thu Oct 27 18:57:04 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 28 Oct 2016 00:57:04 +0600
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <201610272054.32686.Antony.Stone@squid.open.source.it>
References: <1477487652545-4680309.post@n4.nabble.com>
 <05b601d2307a$1a6dc2f0$4f4948d0$@ngtech.co.il>
 <96df8157-c896-dc68-0547-ca84cffec168@gmail.com>
 <201610272054.32686.Antony.Stone@squid.open.source.it>
Message-ID: <cd6828f4-41fc-0803-bb32-b59ff66ce9d1@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
You know method to do this without NAT? ;)


28.10.2016 0:54, Antony Stone ?????:
> On Thursday 27 October 2016 at 19:51:22, Yuri Voinov wrote:
>
>> You absolutely sure, Eliezier? :)
>
> Yes - you do not use DNAT.
>
> You do use REDIRECT on the machine Squid is running on.
>
>
> Antony.
>
>> 27.10.2016 23:46, Eliezer Croitoru ?????:
>>> You need routing policy not DNAT.
>>>
>>> Eliezer
>>>
>>> ----
>>> Eliezer Croitoru
>>> Linux System Administrator
>>> Mobile: +972-5-28704261
>>> Email: eliezer at ngtech.co.il
>>>
>>>
>>> -----Original Message-----
>>> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
>>
>> On Behalf Of erdosain9
>>
>>> Sent: Thursday, October 27, 2016 19:08
>>> To: squid-users at lists.squid-cache.org
>>> Subject: Re: [squid-users] Transparent and non Transparent at the same
>>
>> time
>>
>>> Ok... but i have this problem
>>>
>>>  ERROR: NAT/TPROXY lookup failed to locate original IPs on
>>>
>>> local=192.168.1.15:3130 remote=192.168.1.1:52090 FD 14 flags=33
>>>
>>> ...
>>> I put some dstnat in Mikrotik (192.168.1.1)
>>>
>>>
>>> ip firewall nat add chain=dstnat src-add=192.168.1.121 protocol=tcp
>>> dst-port=80  action=dst-nat
>>> to-addresses=192.168.1.20 to-ports=3129
>>>
>>> ERROR: NAT/TPROXY lookup failed to locate original IPs on
>>> local=192.168.1.20:3129 remote=192.168.1.1:52153 FD 14 flags=33
>>> 2016/10/27 14:01:43 kid1| ERROR: NF getsockopt(ORIGINAL_DST) failed on
>>> local=192.168.1.215:3129 remote=192.168.1.1:52154 FD 14 flags=33: (92)
>>
>> Protocol not available
>>
>>> I dont have iptables or firewalld... im using Centos... is necessary
>>
>> enable firewalld or iptables???
>>
>>> im using the PC (192.168.1.121 for test) Thanks
>>
>>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Transparent-and-non-Tran
>> sparent-at-the-same-time-tp4680309p4680330.html
>>
>>> Sent from the Squid - Users mailing list archive at Nabble.com.
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYEk4AAAoJENNXIZxhPexGGakIAMLVs9E4pOELHc2ER9TSQ2pD
VLPffzjRkSndZvv8Qck0rmoANfZHJoKFzCSx9EMifdiPQjQGRgFm19Hy6wjMNt0v
E7J6Qp5rC2BIIf/zg+rPj4Wz5dcSndV+3m+zk18oEOB47i4MCFkJCwPAYwSkHvXZ
8m4/5pMDSuS7rp+O2Pd217EvesSkMqUXOSKT1/iuvR5yqplTBgEQ8OOpEGYuui9c
dUMm73veIXF22gbcj4NgyFAWnnjJl4oOS7mAuJ2Vs+ZhQeY/uPlurJoCjGm2zXFB
QuhJj05bZkDUqwzWp3VsuXhhSk9skJSRVjqBzMS30q1ocBDN4+adcHrP1n1ISyU=
=jDMd
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161028/2eff3420/attachment.key>

From Antony.Stone at squid.open.source.it  Thu Oct 27 18:59:55 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 27 Oct 2016 20:59:55 +0200
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <cd6828f4-41fc-0803-bb32-b59ff66ce9d1@gmail.com>
References: <1477487652545-4680309.post@n4.nabble.com>
 <201610272054.32686.Antony.Stone@squid.open.source.it>
 <cd6828f4-41fc-0803-bb32-b59ff66ce9d1@gmail.com>
Message-ID: <201610272059.55586.Antony.Stone@squid.open.source.it>

On Thursday 27 October 2016 at 20:57:04, Yuri Voinov wrote:

> You know method to do this without NAT? ;)

I know how to do it without DNAT, which is what Eliezer recommended and you 
challenged.

Antony.

-- 
"The tofu battle I saw last weekend was quite brutal."

 - Marija Danute Brigita Kuncaitis

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Thu Oct 27 19:04:18 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 28 Oct 2016 01:04:18 +0600
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <201610272059.55586.Antony.Stone@squid.open.source.it>
References: <1477487652545-4680309.post@n4.nabble.com>
 <201610272054.32686.Antony.Stone@squid.open.source.it>
 <cd6828f4-41fc-0803-bb32-b59ff66ce9d1@gmail.com>
 <201610272059.55586.Antony.Stone@squid.open.source.it>
Message-ID: <e047814d-fc00-3ea5-4ec2-c08145ebe711@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
(facepalm)

rdr(REDIRECT) is NAT functionality? Yes or no?


28.10.2016 0:59, Antony Stone ?????:
> On Thursday 27 October 2016 at 20:57:04, Yuri Voinov wrote:
>
>> You know method to do this without NAT? ;)
>
> I know how to do it without DNAT, which is what Eliezer recommended
and you
> challenged.
>
> Antony.
>

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYEk+yAAoJENNXIZxhPexGC+QH/RuR8zwmZkv4MI+3hDa+V2VV
xRSDQgAuc3LVc/vQkqVaJXCsZ1KG07Pm/M0kH2+bZNpgGa+5NWc0/XYlXUphsDDi
S5sIFd4uMEUXJxtMOg1J+xqmOy2fqtGs4XZn6rTGVnVF3dSwW+gPpOLH5BKiqHhR
Jdtdc3q2Tvce6Z0+RUSDviFSR1N+p0z4Hx4xrNLaa8UB5Lky9pZAZq/VGPwY5zRI
YqsBnmFSu7jH/0Of0MsY6lOMDuqea497EReLOgspIUIKNoCpFseWijxXt87HW/2w
BrxyBWePdU6/RS5QBktMzFlJBjjFtn5Z2lVVjdHP0rkV6CqtMmgrdfVCVtRaU90=
=rFPk
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161028/5068b5eb/attachment.key>

From Antony.Stone at squid.open.source.it  Thu Oct 27 19:07:25 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 27 Oct 2016 21:07:25 +0200
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <e047814d-fc00-3ea5-4ec2-c08145ebe711@gmail.com>
References: <1477487652545-4680309.post@n4.nabble.com>
 <201610272059.55586.Antony.Stone@squid.open.source.it>
 <e047814d-fc00-3ea5-4ec2-c08145ebe711@gmail.com>
Message-ID: <201610272107.25522.Antony.Stone@squid.open.source.it>

On Thursday 27 October 2016 at 21:04:18, Yuri Voinov wrote:

> (facepalm)
> 
> rdr(REDIRECT) is NAT functionality? Yes or no?

Yes, DNAT is one NAT functionality.  There are several others.

On Thursday 27 October 2016 at 19:46:53, Eliezer Croitoru wrote:

> You need routing policy not DNAT.

DNAT is definitively not required for this - it needs a different form of NAT.


Antony.

-- 
f u cn rd ths, u cn gt a gd jb n nx prgrmmng

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Thu Oct 27 19:09:44 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 28 Oct 2016 01:09:44 +0600
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <e047814d-fc00-3ea5-4ec2-c08145ebe711@gmail.com>
References: <1477487652545-4680309.post@n4.nabble.com>
 <201610272054.32686.Antony.Stone@squid.open.source.it>
 <cd6828f4-41fc-0803-bb32-b59ff66ce9d1@gmail.com>
 <201610272059.55586.Antony.Stone@squid.open.source.it>
 <e047814d-fc00-3ea5-4ec2-c08145ebe711@gmail.com>
Message-ID: <bbd1856d-050e-9362-529b-d62b4ac4148a@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Well,

http://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect
http://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxDnat

If I'm not stupid completely, this examples both uses NAT functionality.

Yes or no?

The question - what do we argue? Op originally wrote - "I have no
iptables and so on." He needs specific guidance, not word games. So, no?

28.10.2016 1:04, Yuri Voinov ?????:
>
> (facepalm)
>
> rdr(REDIRECT) is NAT functionality? Yes or no?
>
>
> 28.10.2016 0:59, Antony Stone ?????:
> > On Thursday 27 October 2016 at 20:57:04, Yuri Voinov wrote:
>
> >> You know method to do this without NAT? ;)
>
> > I know how to do it without DNAT, which is what Eliezer recommended
> and you
> > challenged.
>
> > Antony.
>
>
>

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYElD4AAoJENNXIZxhPexG3d4H+wTllZGRI6URada+ifxa8mPe
EnLO7Bviwe26VqvJZbmhIy9a9zX2tunykADk1cII45nIhBaoYVqMJe65p8NDox+z
4V0RJn0oU02nPpHM5RTwNxisfUFKqz+TvypL91c3AOApUqsWOftApt9AuWru3dV+
vwO+p4C7i0JQRPd1pSiK0JpAolg+QM4dJaxrJ/+Sqsr5PIKMtCngWy2VzDTPuhoe
6Gl1u3nqiWzfJRMoqfRyHowx7tNe06i/FlT5qR1NTJ1Iu3sGIlLZyShswwxk6SSs
/w0W0jhcnArAJ4ITSP5X3CTRKw2GsgzPSIBlzchrt7SNfiVMxJ3GCpUw5F7qbk4=
=Q1cn
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161028/3b606a21/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161028/3b606a21/attachment.key>

From Antony.Stone at squid.open.source.it  Thu Oct 27 19:10:35 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 27 Oct 2016 21:10:35 +0200
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <e047814d-fc00-3ea5-4ec2-c08145ebe711@gmail.com>
References: <1477487652545-4680309.post@n4.nabble.com>
 <201610272059.55586.Antony.Stone@squid.open.source.it>
 <e047814d-fc00-3ea5-4ec2-c08145ebe711@gmail.com>
Message-ID: <201610272110.35901.Antony.Stone@squid.open.source.it>

On Thursday 27 October 2016 at 21:04:18, Yuri Voinov wrote:

> (facepalm)
> 
> rdr(REDIRECT) is NAT functionality? Yes or no?

Apologies - I could have answered this better:

Yes, REDIRECT is one NAT functionality.  There are several others.

On Thursday 27 October 2016 at 19:46:53, Eliezer Croitoru wrote:

> You need routing policy not DNAT.

This remains a correct statement.


Antony.

-- 
f u cn rd ths, u cn gt a gd jb n nx prgrmmng

                                                   Please reply to the list;
                                                         please *don't* CC me.


From Antony.Stone at squid.open.source.it  Thu Oct 27 19:14:08 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 27 Oct 2016 21:14:08 +0200
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <bbd1856d-050e-9362-529b-d62b4ac4148a@gmail.com>
References: <1477487652545-4680309.post@n4.nabble.com>
 <e047814d-fc00-3ea5-4ec2-c08145ebe711@gmail.com>
 <bbd1856d-050e-9362-529b-d62b4ac4148a@gmail.com>
Message-ID: <201610272114.09142.Antony.Stone@squid.open.source.it>

On Thursday 27 October 2016 at 21:09:44, Yuri Voinov wrote:

> OP originally wrote - "I have no IPtables and so on."
> He needs specific guidance, not word games.

Agreed.


Antony.

-- 
There's no such thing as bad weather - only the wrong clothes.

 - Billy Connolly

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Thu Oct 27 19:15:42 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 28 Oct 2016 01:15:42 +0600
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <201610272114.09142.Antony.Stone@squid.open.source.it>
References: <1477487652545-4680309.post@n4.nabble.com>
 <e047814d-fc00-3ea5-4ec2-c08145ebe711@gmail.com>
 <bbd1856d-050e-9362-529b-d62b4ac4148a@gmail.com>
 <201610272114.09142.Antony.Stone@squid.open.source.it>
Message-ID: <a67dcec6-6eed-401b-8090-8d8483bccec3@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Good. We are came to an agreement :)

Peace :)

Let's support to op :)


28.10.2016 1:14, Antony Stone ?????:
> On Thursday 27 October 2016 at 21:09:44, Yuri Voinov wrote:
>
>> OP originally wrote - "I have no IPtables and so on."
>> He needs specific guidance, not word games.
>
> Agreed.
>
>
> Antony.
>

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYElJeAAoJENNXIZxhPexGQMMH/jBpHN5EkIYnNtUk3eeHWY1R
axGwKENC8mTc+YYEJKMkTh+l+fuhGYUsHY59QeS5TYW3YSlAWVusUgX0jFRBdNpx
dSWIaJHBF3HCQdDjB36SaoCKsJ4HmiRJbclSN7mW6yQ7AmV6xclTgdedrJZJz1wF
Y8Jge4XKalhbf8QfC74RR+j6gSanjMCs60Jl/8iYjSulEhwfEuuirF77A/ldWgmv
oahQIpu1UDt+o2zvELmbHGeuADT8b6kQuC9GhsFOxzGe8iEhK4+Ad61GNSBJKY+6
BB1JzMVmBMridYW2WVpJaMgRm9anCPe+u7OHALxewT/isGYhNSRcq77IKmWXCuk=
=g8yy
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161028/b276bee6/attachment.key>

From jetsystemservices at gmail.com  Thu Oct 27 19:35:11 2016
From: jetsystemservices at gmail.com (Jose Torres-Berrocal)
Date: Thu, 27 Oct 2016 15:35:11 -0400
Subject: [squid-users] Squid Logs local and remote
Message-ID: <CABU5kW5+AVQG8NX9ZEkOra03gOi5fBVsEg57NOMWL+HcetBCtA@mail.gmail.com>

Is there a way that I can have the squid logs locally and remotely?

I need them locally for lightsquid and remotelly for sarg in other server.

Lightsquid does not show the tcp_denied sites only the successful
connections (at least I did not see how), Sarg does show both type of
connections.

I can not install Sarg on the local server (pfsense 2.3.2 is not compatible)

Please advice.

Jose E Torres
939-777-4030
JET System Services


From ambrose.li at gmail.com  Thu Oct 27 19:40:36 2016
From: ambrose.li at gmail.com (Ambrose LI)
Date: Thu, 27 Oct 2016 15:40:36 -0400
Subject: [squid-users] Squid Logs local and remote
In-Reply-To: <CABU5kW5+AVQG8NX9ZEkOra03gOi5fBVsEg57NOMWL+HcetBCtA@mail.gmail.com>
References: <CABU5kW5+AVQG8NX9ZEkOra03gOi5fBVsEg57NOMWL+HcetBCtA@mail.gmail.com>
Message-ID: <CADJvFOW4k3MMzDLnWvE1U47zZOwfkRuqov3fKe2uSV5fZFRJqA@mail.gmail.com>

2016-10-27 15:35 GMT-04:00 Jose Torres-Berrocal <jetsystemservices at gmail.com>:
> Is there a way that I can have the squid logs locally and remotely?
>
> I need them locally for lightsquid and remotelly for sarg in other server.
>
> Lightsquid does not show the tcp_denied sites only the successful
> connections (at least I did not see how), Sarg does show both type of
> connections.
>
> I can not install Sarg on the local server (pfsense 2.3.2 is not compatible)

What kind of logs, and does your system use rsyslog? If it's just the
access log you can configure squid to log to syslog, then configure
rsyslog to both save a local copy and forward to a remote server. But
the formatting of the logs is going to change somewhat.



-- 
Ambrose Li // http://o.gniw.ca / http://gniw.ca
If you saw this on CE-L: You do not need my permission to quote
me, only proper attribution. Always cite your sources, even if
you have to anonymize and/or cite it as "personal communication".


From yvoinov at gmail.com  Thu Oct 27 19:42:58 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 28 Oct 2016 01:42:58 +0600
Subject: [squid-users] Squid Logs local and remote
In-Reply-To: <CADJvFOW4k3MMzDLnWvE1U47zZOwfkRuqov3fKe2uSV5fZFRJqA@mail.gmail.com>
References: <CABU5kW5+AVQG8NX9ZEkOra03gOi5fBVsEg57NOMWL+HcetBCtA@mail.gmail.com>
 <CADJvFOW4k3MMzDLnWvE1U47zZOwfkRuqov3fKe2uSV5fZFRJqA@mail.gmail.com>
Message-ID: <7ecd61e6-80c5-e432-d4a8-ccc33f1242cf@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
.... or on writable NFS-mount from remote server..... :)


28.10.2016 1:40, Ambrose LI ?????:
> 2016-10-27 15:35 GMT-04:00 Jose Torres-Berrocal <jetsystemservices at gmail.com>:
>> Is there a way that I can have the squid logs locally and remotely?
>>
>> I need them locally for lightsquid and remotelly for sarg in other
server.
>>
>> Lightsquid does not show the tcp_denied sites only the successful
>> connections (at least I did not see how), Sarg does show both type of
>> connections.
>>
>> I can not install Sarg on the local server (pfsense 2.3.2 is not
compatible)
>
> What kind of logs, and does your system use rsyslog? If it's just the
> access log you can configure squid to log to syslog, then configure
> rsyslog to both save a local copy and forward to a remote server. But
> the formatting of the logs is going to change somewhat.
>
>
>

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYEljBAAoJENNXIZxhPexGOIUH/ip230AyziNvGPeiQnWIMgSc
mFNAGmhcvMBox8cPkXyAQz5beDx6PfEyS2kR0jLgHynLBA3dv5Baa/BNpcspiVHP
ciXoPgx/8TDpItbHqpd2Zql7VppoXH+vKg5k8zYoPmBuefKPYR9qP7EXkidujuVD
oeOH2j0qm5eBj+XImKcoPqCGFeSoI19AUkVZ3fEdoQ8aTK7N2Gp7IVFHt6vvxR7t
eeKZ/8Vv+QeDfpxRQ4R9CYR/1bIa1jkdgolwMGUyn5QfO91JIsvHY7H/PCqwtYyQ
fQNXSQSwGclZdr1MZC8q9RbYCgOQjVRL0L2x4rb+RWR8n3UW9+ZCNhIx+R6RekM=
=ZxWP
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161028/151f6a42/attachment.key>

From jetsystemservices at gmail.com  Thu Oct 27 20:55:23 2016
From: jetsystemservices at gmail.com (Jose Torres-Berrocal)
Date: Thu, 27 Oct 2016 16:55:23 -0400
Subject: [squid-users] Squid Logs local and remote
In-Reply-To: <CADJvFOW4k3MMzDLnWvE1U47zZOwfkRuqov3fKe2uSV5fZFRJqA@mail.gmail.com>
References: <CABU5kW5+AVQG8NX9ZEkOra03gOi5fBVsEg57NOMWL+HcetBCtA@mail.gmail.com>
 <CADJvFOW4k3MMzDLnWvE1U47zZOwfkRuqov3fKe2uSV5fZFRJqA@mail.gmail.com>
Message-ID: <CABU5kW420rKj2xX0o3-qt2HFa0hsn__PzuxJ3Kt=g+7LPiwZPw@mail.gmail.com>

My system is a pfsense. It does not hace rsyslog. Pfsense is based on
Freebsd.

Lets say it can be installed. Will the logs be compatible with lightsquid
and sarg?

On Oct 27, 2016 3:41 PM, "Ambrose LI" <ambrose.li at gmail.com> wrote:

> 2016-10-27 15:35 GMT-04:00 Jose Torres-Berrocal <
> jetsystemservices at gmail.com>:
> > Is there a way that I can have the squid logs locally and remotely?
> >
> > I need them locally for lightsquid and remotelly for sarg in other
> server.
> >
> > Lightsquid does not show the tcp_denied sites only the successful
> > connections (at least I did not see how), Sarg does show both type of
> > connections.
> >
> > I can not install Sarg on the local server (pfsense 2.3.2 is not
> compatible)
>
> What kind of logs, and does your system use rsyslog? If it's just the
> access log you can configure squid to log to syslog, then configure
> rsyslog to both save a local copy and forward to a remote server. But
> the formatting of the logs is going to change somewhat.
>
>
>
> --
> Ambrose Li // http://o.gniw.ca / http://gniw.ca
> If you saw this on CE-L: You do not need my permission to quote
> me, only proper attribution. Always cite your sources, even if
> you have to anonymize and/or cite it as "personal communication".
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161027/aa591343/attachment.htm>

From squid3 at treenet.co.nz  Thu Oct 27 22:43:04 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 28 Oct 2016 11:43:04 +1300
Subject: [squid-users] Custom User Agent Per ACL
In-Reply-To: <2efca5d4-a5a1-e720-6c5c-584b49926178@jarrettgraham.com>
References: <2efca5d4-a5a1-e720-6c5c-584b49926178@jarrettgraham.com>
Message-ID: <8d39a9e7-1c5b-1070-1a91-ba455cf89f34@treenet.co.nz>

On 28/10/2016 6:48 a.m., jarrett+squid-users wrote:
> Is it possible to have a custom "request_header_replace User-Agent" assigned to mapped acl/listening port/tcp_outgoing_address?
> 
> Examples:
> acl ipv4-1 myportname 3128 src xxx.xxx.xxx.xxx/24http_access allow ipv4-1 -> request_header_replace User Agent "Firefox xxxxx" ipv4-1 -> tcp_outgoing_address xxx.xxx.xxx.xxx ipv4-1
> acl ipv4-2 myportname 3129 src xxx.xxx.xxx.xxx/24 -> http_access allow ipv4-2 -> request_header_replace User Agent "Internet Explorer xxxxx" ipv4-2 -> tcp_outgoing_address xxx.xxx.xxx.xxx ipv4-2
> 

That depends on your Squid version.

Replacement is a simple replacement of all headers with a (single) new
value.

What you are looking for is request_header_add. Though don't forget to
use "request_header_access deny" to remove the old versions of headers
(if any).

Amos



From eliezer at ngtech.co.il  Fri Oct 28 00:43:51 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 28 Oct 2016 03:43:51 +0300
Subject: [squid-users] Squid Logs local and remote
In-Reply-To: <CABU5kW420rKj2xX0o3-qt2HFa0hsn__PzuxJ3Kt=g+7LPiwZPw@mail.gmail.com>
References: <CABU5kW5+AVQG8NX9ZEkOra03gOi5fBVsEg57NOMWL+HcetBCtA@mail.gmail.com>
 <CADJvFOW4k3MMzDLnWvE1U47zZOwfkRuqov3fKe2uSV5fZFRJqA@mail.gmail.com>
 <CABU5kW420rKj2xX0o3-qt2HFa0hsn__PzuxJ3Kt=g+7LPiwZPw@mail.gmail.com>
Message-ID: <077501d230b4$5a48e960$0edabc20$@ngtech.co.il>

Depends on the squid version you can send it to a custom tcp daemon.

 

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Jose Torres-Berrocal
Sent: Thursday, October 27, 2016 23:55
To: Ambrose LI <ambrose.li at gmail.com>
Cc: Squid Users <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Squid Logs local and remote

 

My system is a pfsense. It does not hace rsyslog. Pfsense is based on Freebsd.

Lets say it can be installed. Will the logs be compatible with lightsquid and sarg?

 

On Oct 27, 2016 3:41 PM, "Ambrose LI" <ambrose.li at gmail.com <mailto:ambrose.li at gmail.com> > wrote:

2016-10-27 15:35 GMT-04:00 Jose Torres-Berrocal <jetsystemservices at gmail.com <mailto:jetsystemservices at gmail.com> >:
> Is there a way that I can have the squid logs locally and remotely?
>
> I need them locally for lightsquid and remotelly for sarg in other server.
>
> Lightsquid does not show the tcp_denied sites only the successful
> connections (at least I did not see how), Sarg does show both type of
> connections.
>
> I can not install Sarg on the local server (pfsense 2.3.2 is not compatible)

What kind of logs, and does your system use rsyslog? If it's just the
access log you can configure squid to log to syslog, then configure
rsyslog to both save a local copy and forward to a remote server. But
the formatting of the logs is going to change somewhat.



--
Ambrose Li // http://o.gniw.ca / http://gniw.ca
If you saw this on CE-L: You do not need my permission to quote
me, only proper attribution. Always cite your sources, even if
you have to anonymize and/or cite it as "personal communication".

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161028/e31d88e1/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image002.png
Type: image/png
Size: 11295 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161028/e31d88e1/attachment.png>

From eliezer at ngtech.co.il  Fri Oct 28 03:21:01 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 28 Oct 2016 06:21:01 +0300
Subject: [squid-users] Transparent and non Transparent at the same time
In-Reply-To: <a67dcec6-6eed-401b-8090-8d8483bccec3@gmail.com>
References: <1477487652545-4680309.post@n4.nabble.com>
 <e047814d-fc00-3ea5-4ec2-c08145ebe711@gmail.com>
 <bbd1856d-050e-9362-529b-d62b4ac4148a@gmail.com>
 <201610272114.09142.Antony.Stone@squid.open.source.it>
 <a67dcec6-6eed-401b-8090-8d8483bccec3@gmail.com>
Message-ID: <07ed01d230ca$4ef91740$eceb45c0$@ngtech.co.il>

This would be a starter point:
http://wiki.mikrotik.com/wiki/Policy_Routing_in_RouterOS_2.9.x

Logically it should be similar to this:
http://blog.butchevans.com/2008/09/mikrotik-policy-routing-implementation-example/

but the proxy should have two interfaces, in and out.
It can be done on one interface but then you will need to add some exceptions to traffic by the MAC address of the proxy.
I wrote this once in the past.
And this should summarize how it should be done:
https://aacable.wordpress.com/2011/07/21/mikrotik-howto-redirect-http-traffic-to-squid-with-original-source-client-ip/

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
Sent: Thursday, October 27, 2016 22:16
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Transparent and non Transparent at the same time


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Good. We are came to an agreement :)

Peace :)

Let's support to op :)


28.10.2016 1:14, Antony Stone ?????:
> On Thursday 27 October 2016 at 21:09:44, Yuri Voinov wrote:
>
>> OP originally wrote - "I have no IPtables and so on."
>> He needs specific guidance, not word games.
>
> Agreed.
>
>
> Antony.
>

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYElJeAAoJENNXIZxhPexGQMMH/jBpHN5EkIYnNtUk3eeHWY1R
axGwKENC8mTc+YYEJKMkTh+l+fuhGYUsHY59QeS5TYW3YSlAWVusUgX0jFRBdNpx
dSWIaJHBF3HCQdDjB36SaoCKsJ4HmiRJbclSN7mW6yQ7AmV6xclTgdedrJZJz1wF
Y8Jge4XKalhbf8QfC74RR+j6gSanjMCs60Jl/8iYjSulEhwfEuuirF77A/ldWgmv
oahQIpu1UDt+o2zvELmbHGeuADT8b6kQuC9GhsFOxzGe8iEhK4+Ad61GNSBJKY+6
BB1JzMVmBMridYW2WVpJaMgRm9anCPe+u7OHALxewT/isGYhNSRcq77IKmWXCuk=
=g8yy
-----END PGP SIGNATURE-----




From indunil75 at gmail.com  Fri Oct 28 06:35:28 2016
From: indunil75 at gmail.com (Indunil Jayasooriya)
Date: Fri, 28 Oct 2016 12:05:28 +0530
Subject: [squid-users] Can I block facebook videos globally?
Message-ID: <CAJF2yJT3L08Z=UBWmL0bQnYUYHfYDK1jfOztQtXAPbPS3pqNZg@mail.gmail.com>

Hi list,


Can I block facebook videos globally?

I wrote below acls

acl deny_rep_mime_flashvideo rep_mime_type video/x-flv
http_reply_access deny deny_rep_mime_flashvideo

acl facebook_videos dstdomain fbcdn-video-*.akamaihd.net video-*.fbcdn.net
fbcdn-creative-*.akamaihd.net
http_access deny facebook_videos


It seems like it blocks only a few.


any idea?

is it possible with squid ?






-- 
cat /etc/motd

Thank you
Indunil Jayasooriya
http://www.theravadanet.net/
http://www.siyabas.lk/sinhala_how_to_install.html   -  Download Sinhala
Fonts
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161028/fba20f7b/attachment.htm>

From squid3 at treenet.co.nz  Fri Oct 28 07:34:37 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 28 Oct 2016 20:34:37 +1300
Subject: [squid-users] Can I block facebook videos globally?
In-Reply-To: <CAJF2yJT3L08Z=UBWmL0bQnYUYHfYDK1jfOztQtXAPbPS3pqNZg@mail.gmail.com>
References: <CAJF2yJT3L08Z=UBWmL0bQnYUYHfYDK1jfOztQtXAPbPS3pqNZg@mail.gmail.com>
Message-ID: <ea62ac4a-c555-835a-706b-a130d769e1e0@treenet.co.nz>

On 28/10/2016 7:35 p.m., Indunil Jayasooriya wrote:
> Hi list,
> 
> 
> Can I block facebook videos globally?
> 

"globally" is relative. If you can define an ACL or set of ACL tests
that match the transactions, you can block them.

> I wrote below acls
> 
> acl deny_rep_mime_flashvideo rep_mime_type video/x-flv
> http_reply_access deny deny_rep_mime_flashvideo

That prevents Squid delivering "x-flv" responses to the clients. Nothing
more. see below ...

> 
> acl facebook_videos dstdomain fbcdn-video-*.akamaihd.net video-*.fbcdn.net
> fbcdn-creative-*.akamaihd.net

Those "*" make the domain names regex (dstdom_regex type) not suitable
for dstdomain lists.

> http_access deny facebook_videos
> 
> 
> It seems like it blocks only a few.
> 
> 
> any idea?
> 
> is it possible with squid ?
> 

That depends on your definition of "globally". You can only control in
Squid that which goes through Squid.

If you block on the request (http_access) the transaction is blocked.

If you block on reply details (http_reply_access) the transactions goes
through anyway, only the response is stopped from reaching the client.
It still happens on the server side and Squid still consumes all or a
lot of the video bandwidth.

Of the browser uses a non-HTTP protocol and/or other WebSocket ports
then Squid has no relevance.

Amos



From squid3 at treenet.co.nz  Fri Oct 28 10:40:17 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 28 Oct 2016 23:40:17 +1300
Subject: [squid-users] [squid-announce] Squid Signing key rollover
Message-ID: <4098dd8a-8d48-ca1f-e32b-3761998047f3@treenet.co.nz>

The PGP key I use to sign Squid binaries and associated files is being
refreshed.

Squid-4.0.16 and later releases will be signed with the key;

 Email: Amos Jeffries (Squid Signing Key) <squid3 at treenet.co.nz>
 Fingerprint: B068 84ED B779 C89B 044E  64E3 CD6D BF8E F3B1 7D3E

 This new Squid-4 key has been signed by the Squid-3 key, and is
contained in the Squid Project keyring which can be downloaded from
<http://www.squid-cache.org/pgp.asc>

 It should also be found in the pool.sks-keyservers.net public servers.


Squid-3 releases will continue to be signed with the existing key to the
end of that versions support.


As always the .asc file published for any signed item contains the key
IDs and other details relevant for verifying that item.

If any issues are encountered please do not hesitate to contact me.

Amos Jeffries
The Squid Software Foundation
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From garryd at comnet.uz  Fri Oct 28 12:56:44 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Fri, 28 Oct 2016 17:56:44 +0500
Subject: [squid-users] Default state for the option
	generate-host-certificates
Message-ID: <1477659404.3336.11.camel@comnet.uz>

Hello list,

The last sentence for?generate-host-certificates[=<on|off>] option
paragraph states:

? This option is enabled by default when ssl-bump is used. See the
? ssl-bump option above for more information.

But a client can't negotiate secure connection and times out when the
option is not specified explicitly. For example, with following config
I get negotiation timeout:

# diff etc/squid.conf.default etc/squid.conf
59c59
< http_port 3128
---
> http_port 3128 ssl-bump cert=/usr/local/squid35/etc/ssl_cert/myCA.pem
73a74,76
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump bump all

-----
$ https_proxy="127.0.0.1:3128" curl -v -k https://ya.ru/ > /dev/null
*???Trying 127.0.0.1...
* TCP_NODELAY set
? % Total????% Received % Xferd??Average
Speed???Time????Time?????Time??Current
?????????????????????????????????Dload??Upload???Total???Spent????Left?
?Speed
? 0?????0????0?????0????0?????0??????0??????0 --:--:-- --:--:-- --:--:-
-?????0* Connected to 127.0.0.1 (127.0.0.1) port 3128 (#0)
* Establish HTTP proxy tunnel to ya.ru:443
> CONNECT ya.ru:443 HTTP/1.1
> Host: ya.ru:443
> User-Agent: curl/7.50.3
> Proxy-Connection: Keep-Alive
>?
< HTTP/1.1 200 Connection established
<?
* Proxy replied OK to CONNECT request
* Initializing NSS with certpath: none
? 0?????0????0?????0????0?????0??????0??????0 --:--:--??0:00:59 --:--:-
-?????0* NSS error -5938 (PR_END_OF_FILE_ERROR)
* Encountered end of file
* Curl_http_done: called premature == 1
? 0?????0????0?????0????0?????0??????0??????0 --:--:--??0:01:00 --:--:-
-?????0
* Closing connection 0
curl: (35) Encountered end of file



No problems, if the option specified explicitly:

# diff etc/squid.conf.default etc/squid.conf
59c59,61
< http_port 3128
---
> http_port 3128 ssl-bump \
>?????cert=/usr/local/squid35/etc/ssl_cert/myCA.pem \
>?????generate-host-certificates
73a76,78
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump bump all


Is it a bug, documentation error or I simply missed something?

Thanks.

Garri


From yvoinov at gmail.com  Fri Oct 28 13:39:37 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 28 Oct 2016 19:39:37 +0600
Subject: [squid-users] Default state for the option
 generate-host-certificates
In-Reply-To: <1477659404.3336.11.camel@comnet.uz>
References: <1477659404.3336.11.camel@comnet.uz>
Message-ID: <b22a786a-446d-fc11-73e7-90f873eba61d@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
It seems bug.

Just always specify option explicity.


28.10.2016 18:56, Garri Djavadyan ?????:
> Hello list,
>
> The last sentence for generate-host-certificates[=<on|off>] option
> paragraph states:
>
>   This option is enabled by default when ssl-bump is used. See the
>   ssl-bump option above for more information.
>
> But a client can't negotiate secure connection and times out when the
> option is not specified explicitly. For example, with following config
> I get negotiation timeout:
>
> # diff etc/squid.conf.default etc/squid.conf
> 59c59
> < http_port 3128
> ---
>> http_port 3128 ssl-bump cert=/usr/local/squid35/etc/ssl_cert/myCA.pem
> 73a74,76
>> acl step1 at_step SslBump1
>> ssl_bump peek step1
>> ssl_bump bump all
>
> -----
> $ https_proxy="127.0.0.1:3128" curl -v -k https://ya.ru/ > /dev/null
> *   Trying 127.0.0.1...
> * TCP_NODELAY set
>   % Total    % Received % Xferd  Average
> Speed   Time    Time     Time  Current
>                                  Dload  Upload   Total   Spent    Left
>  Speed
>   0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:-
> -     0* Connected to 127.0.0.1 (127.0.0.1) port 3128 (#0)
> * Establish HTTP proxy tunnel to ya.ru:443
>> CONNECT ya.ru:443 HTTP/1.1
>> Host: ya.ru:443
>> User-Agent: curl/7.50.3
>> Proxy-Connection: Keep-Alive
>> 
> < HTTP/1.1 200 Connection established
> <
> * Proxy replied OK to CONNECT request
> * Initializing NSS with certpath: none
>   0     0    0     0    0     0      0      0 --:--:--  0:00:59 --:--:-
> -     0* NSS error -5938 (PR_END_OF_FILE_ERROR)
> * Encountered end of file
> * Curl_http_done: called premature == 1
>   0     0    0     0    0     0      0      0 --:--:--  0:01:00 --:--:-
> -     0
> * Closing connection 0
> curl: (35) Encountered end of file
>
>
>
> No problems, if the option specified explicitly:
>
> # diff etc/squid.conf.default etc/squid.conf
> 59c59,61
> < http_port 3128
> ---
>> http_port 3128 ssl-bump \
>>      cert=/usr/local/squid35/etc/ssl_cert/myCA.pem \
>>      generate-host-certificates
> 73a76,78
>> acl step1 at_step SslBump1
>> ssl_bump peek step1
>> ssl_bump bump all
>
>
> Is it a bug, documentation error or I simply missed something?
>
> Thanks.
>
> Garri
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYE1UYAAoJENNXIZxhPexG6dkIAMEk7PLEQkBdOH9L4ZELMnjm
GalwtMVwpulVMtiiPWShL6GY9mUTZE33hVAjEq3Hw0xj82ZZjI6QsWxqsyq9RvBN
sXWsydx9C0OAULU8oFWW8sv4b8iUGCvW01U8ZxgjhKxVb0n+7BKmcnSk0nR8iXxO
2I6JKPP9nd20Bh5e0zKucmdVyNhkOGq00KJk4a8M7oxunbo0BkTKsOusd90hmjdD
5JRNbT5cJbyA2ZmEGdyi4fM9pNRuIk4WQe+/m3ycpbY8S6ySFEwe0tcW1+hQ5eoS
r16xhbMUtpseejUjRNWIzDO9H7ix57bugyW72oNPhrnEn96+d3vWUyUB+eNaR0E=
=hInQ
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161028/7271c452/attachment.key>

From eliezer at ngtech.co.il  Fri Oct 28 14:30:35 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 28 Oct 2016 17:30:35 +0300
Subject: [squid-users] Squid 4.0.15 sni exceptions works for whatsapp
Message-ID: <09ab01d23127$d8c37760$8a4a6620$@ngtech.co.il>

In 4.0.14 there was a regression in ssl bump.
I have tested with the next snippet:
acl DiscoverSNIHost at_step SslBump1
acl NoSSLIntercept ssl::server_name_regex -i "/etc/squid/url.nobump"

ssl_bump splice NoSSLIntercept

ssl_bump peek DiscoverSNIHost
ssl_bump bump all

##url.nobump
w[0-9]+\.web\.whatsapp\.com$
\.web\.whatsapp\.com$
web\.whatsapp\.com$
w3.web.whatsapp.com$

And it seems that in a regular forward proxy mode squid respects the
ssl::server_name_regex and http://web.whatsapp.com/ seems to works as
expected.

Anyone else can help me to verify it?
I have not tested in intercept mode yet but I ASSUME  that since the issue
was present in both intercept and forward mode now it should be resolved to
both.

Eliezer

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
 


-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 63241 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161028/3ef4fbfa/attachment.bin>

From rousskov at measurement-factory.com  Fri Oct 28 14:53:17 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 28 Oct 2016 08:53:17 -0600
Subject: [squid-users] Default state for the option
 generate-host-certificates
In-Reply-To: <1477659404.3336.11.camel@comnet.uz>
References: <1477659404.3336.11.camel@comnet.uz>
Message-ID: <a341a28b-3bea-7303-4b9c-5b1e31471f52@measurement-factory.com>

On 10/28/2016 06:56 AM, Garri Djavadyan wrote:

> The last sentence for generate-host-certificates[=<on|off>] option
> paragraph states:
> 
>   This option is enabled by default when ssl-bump is used.

I see no [trunk] code to match that statement.


> Is it a bug, documentation error or I simply missed something?

It is a bug IMO. The documented intent sounds worth supporting to me.

Alex.



From rousskov at measurement-factory.com  Fri Oct 28 15:31:10 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 28 Oct 2016 09:31:10 -0600
Subject: [squid-users] Squid 4.0.15 sni exceptions works for whatsapp
In-Reply-To: <09ab01d23127$d8c37760$8a4a6620$@ngtech.co.il>
References: <09ab01d23127$d8c37760$8a4a6620$@ngtech.co.il>
Message-ID: <d959ff84-2381-30f3-e5dc-7d49622880b3@measurement-factory.com>

On 10/28/2016 08:30 AM, Eliezer Croitoru wrote:
> In 4.0.14 there was a regression in ssl bump.

If you are thinking about the server_name bug fixed by trunk r14898,
then it was not a v4.0.14 regression but an original bug. Any
server_name testing without that fix is nearly useless (unfortunately)
because the bug affected core server_name functionality.


HTH,

Alex.



From garryd at comnet.uz  Fri Oct 28 19:18:47 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Sat, 29 Oct 2016 00:18:47 +0500
Subject: [squid-users] Default state for the option
 generate-host-certificates
In-Reply-To: <a341a28b-3bea-7303-4b9c-5b1e31471f52@measurement-factory.com>
References: <1477659404.3336.11.camel@comnet.uz>
 <a341a28b-3bea-7303-4b9c-5b1e31471f52@measurement-factory.com>
Message-ID: <1d4da1c04ef0cce85cc471a0260bcd60@comnet.uz>

On 2016-10-28 18:39, Yuri Voinov wrote:
> It seems bug.


On 2016-10-28 19:53, Alex Rousskov wrote:
>> Is it a bug, documentation error or I simply missed something?
> 
> It is a bug IMO. The documented intent sounds worth supporting to me.


Thanks. I've opened the report [1].

[1] http://bugs.squid-cache.org/show_bug.cgi?id=4627

Garri


From eliezer at ngtech.co.il  Fri Oct 28 21:58:16 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sat, 29 Oct 2016 00:58:16 +0300
Subject: [squid-users] Squid 4.0.15 sni exceptions works for whatsapp
In-Reply-To: <d959ff84-2381-30f3-e5dc-7d49622880b3@measurement-factory.com>
References: <09ab01d23127$d8c37760$8a4a6620$@ngtech.co.il>
 <d959ff84-2381-30f3-e5dc-7d49622880b3@measurement-factory.com>
Message-ID: <0add01d23166$62cd69a0$28683ce0$@ngtech.co.il>

OK then I will wait for 4.0.16 to see how it will work there.
In 3.5.22 I see that there is still an issue.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Alex Rousskov [mailto:rousskov at measurement-factory.com] 
Sent: Friday, October 28, 2016 18:31
To: squid-users at lists.squid-cache.org
Cc: Eliezer Croitoru <eliezer at ngtech.co.il>
Subject: Re: [squid-users] Squid 4.0.15 sni exceptions works for whatsapp

On 10/28/2016 08:30 AM, Eliezer Croitoru wrote:
> In 4.0.14 there was a regression in ssl bump.

If you are thinking about the server_name bug fixed by trunk r14898, then it was not a v4.0.14 regression but an original bug. Any server_name testing without that fix is nearly useless (unfortunately) because the bug affected core server_name functionality.


HTH,

Alex.




From rousskov at measurement-factory.com  Sat Oct 29 02:34:43 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 28 Oct 2016 20:34:43 -0600
Subject: [squid-users] Squid 4.0.15 sni exceptions works for whatsapp
In-Reply-To: <0add01d23166$62cd69a0$28683ce0$@ngtech.co.il>
References: <09ab01d23127$d8c37760$8a4a6620$@ngtech.co.il>
 <d959ff84-2381-30f3-e5dc-7d49622880b3@measurement-factory.com>
 <0add01d23166$62cd69a0$28683ce0$@ngtech.co.il>
Message-ID: <aba696ef-3996-72b3-518f-7a1e217392f6@measurement-factory.com>

On 10/28/2016 03:58 PM, Eliezer Croitoru wrote:
> OK then I will wait for 4.0.16 to see how it will work there.
> In 3.5.22 I see that there is still an issue.

Yes, but we did provide a v3.5 fix as well, and I encourage you to test
it:
http://lists.squid-cache.org/pipermail/squid-dev/2016-October/007137.html

Alex.


> -----Original Message-----
> From: Alex Rousskov [mailto:rousskov at measurement-factory.com] 
> Sent: Friday, October 28, 2016 18:31
> To: squid-users at lists.squid-cache.org
> Cc: Eliezer Croitoru <eliezer at ngtech.co.il>
> Subject: Re: [squid-users] Squid 4.0.15 sni exceptions works for whatsapp
> 
> On 10/28/2016 08:30 AM, Eliezer Croitoru wrote:
>> In 4.0.14 there was a regression in ssl bump.
> 
> If you are thinking about the server_name bug fixed by trunk r14898, then it was not a v4.0.14 regression but an original bug. Any server_name testing without that fix is nearly useless (unfortunately) because the bug affected core server_name functionality.
> 
> 
> HTH,
> 
> Alex.
> 



From paul.greene.va at verizon.net  Sat Oct 29 15:40:23 2016
From: paul.greene.va at verizon.net (paul.greene.va at verizon.net)
Date: Sat, 29 Oct 2016 10:40:23 -0500 (CDT)
Subject: [squid-users] Squid communications proxy dilemma
Message-ID: <18967036.1516462.1477755623057.JavaMail.root@vznit170064.mailsrvcs.net>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161029/761f2323/attachment.htm>

From squid3 at treenet.co.nz  Sat Oct 29 22:38:27 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 30 Oct 2016 11:38:27 +1300
Subject: [squid-users] Squid communications proxy dilemma
In-Reply-To: <18967036.1516462.1477755623057.JavaMail.root@vznit170064.mailsrvcs.net>
References: <18967036.1516462.1477755623057.JavaMail.root@vznit170064.mailsrvcs.net>
Message-ID: <4b16b704-ce08-723b-3952-c97e19a54548@treenet.co.nz>

On 30/10/2016 4:40 a.m., paul.greene.va wrote:
> 
> Our firewall guy says what he's seeing in his logs is that traffic destined for 
> port 443, after it goes through the proxy, is trying to go straight to the 
> vendor over the internet, rather than go through the upstream McAfee gateway as 
> required, and thus, the traffic is getting dropped by the Cisco firewall. I did 
> a packet capture test with the McAfee gateway guy, and he confirmed that no 
> traffic coming from either either the WSUS or the SEPM is reaching his gateway.
> 
> I thought this line in the squid.conf file should send traffic from our proxy to 
> the upstream McAfee gateway, but maybe I'm misunderstanding the intent of the 
> cache_peer parent parameter.
> 
> cache_peer <McAfee Gateway IP address>      parent    8080  3130  proxy-only 
> no-query no-netdb-exchange default login=username:password
> 

cache_peer configures the *how* of traffic sent to that gateway. Which
traffic uses it is configured by other directives (cache_peer_access,
always_direct, never_direct, peer_direct, nonhierarchical_direct) and
depends on the type of traffic.

NP: the above also indicates the connection(s) are plain-text HTTP. If
you are using interception then HTTPS traffic cannot go through that
link. Since HTTPS requires end-to-end security, the cache_peer
connection needs to use 'ssl' options for intercepted port 443 to use it
safely.


> (if placement of this cache_peer parameter matters, its currently near the end 
> of the squid.conf file)
> 
> As a test, I configured internet explorer on the WSUS server to use the proxy 
> for internet access, Without configuring for the proxy, IE can't go anywhere 
> except the local network. IE can hit http websites (i.e. www.cnn.com) when it's 
> configured to use the proxy, but not https websites.
> 
> The Safe_ports and SSL_ports list is the same as the squid.conf defaults.
> 
> This is squid 3.3 running on Redhat 7.
> 
> Any suggestions or pointers?

Assuming you are using explicit/forward proxy, add this to your squid.conf:

 never_direct allow all

if that dont work by itself you may need these as well:

 prefer_direct off
 nonhierarchical_direct off

You should not have any existing lines with those directives or with
always_direct. If you do the placement might matter.

Amos



From paul.greene.va at verizon.net  Sat Oct 29 23:38:37 2016
From: paul.greene.va at verizon.net (paul.greene.va at verizon.net)
Date: Sat, 29 Oct 2016 18:38:37 -0500 (CDT)
Subject: [squid-users] Squid communications proxy dilemma
Message-ID: <9914394.1526867.1477784317599.JavaMail.root@vznit170064.mailsrvcs.net>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161029/8a6fa365/attachment.htm>

From squid3 at treenet.co.nz  Sun Oct 30 00:38:45 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 30 Oct 2016 13:38:45 +1300
Subject: [squid-users] Squid communications proxy dilemma
In-Reply-To: <9914394.1526867.1477784317599.JavaMail.root@vznit170064.mailsrvcs.net>
References: <9914394.1526867.1477784317599.JavaMail.root@vznit170064.mailsrvcs.net>
Message-ID: <17d2d218-7550-9f67-a28d-a7f256c03462@treenet.co.nz>

On 30/10/2016 12:38 p.m., paul.greene.va wrote:
> This fixed the WSUS server, it wasn't the cache_peer parameter after all.
> 
> acl inside dstdomain .mydomain.com
> always_direct allow inside
> never_direct allow all
> The SEPM might have an additional known issue (known by Symantec that is)
> 
> If a proxy or a firewall is stripping, compressing, or encrypting content length 
> packet headers, that'll break SEPM too. (SEPM uses port 80 by default, so 
> theoretically it should have been getting out)
> 
> Is there a parameter in squid that would do that? (so I can see if it is 
> configured or not) The squid.conf is 90% of the default file, with just a few 
> tweaks needed for our environment.

Squid is HTTP software, it does not do anything with the TCP packet
level of things.

If by "packets" you actually meant "HTTP messages", then ... HTTP is
designed with middleware alterations of the message along the way. Any
software which cannot handle that is broken.

Likewise any software using port 80 which cannot handle HTTP on the port
is broken.

Amos



From paul.greene.va at verizon.net  Sun Oct 30 01:41:37 2016
From: paul.greene.va at verizon.net (paul.greene.va at verizon.net)
Date: Sat, 29 Oct 2016 20:41:37 -0500 (CDT)
Subject: [squid-users] Squid communications proxy dilemma
Message-ID: <14750058.1528817.1477791697436.JavaMail.root@vznit170064.mailsrvcs.net>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161029/c9d8a2dc/attachment.htm>

From squid3 at treenet.co.nz  Sun Oct 30 02:21:55 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 30 Oct 2016 15:21:55 +1300
Subject: [squid-users] Squid communications proxy dilemma
In-Reply-To: <14750058.1528817.1477791697436.JavaMail.root@vznit170064.mailsrvcs.net>
References: <14750058.1528817.1477791697436.JavaMail.root@vznit170064.mailsrvcs.net>
Message-ID: <dd796843-819b-2297-51e3-f255faae9126@treenet.co.nz>

On 30/10/2016 2:41 p.m., paul.greene.va wrote:
> It is supposed to be some headers in the http protocol; a description from the 
> vendor:
> 
> "Ensure that any proxy, firewall or content filtering applications or devices 
> are not stripping header information from FTP or HTTP traffic, especially file 
> size header information."
> 
>   In the SEPM error log, it is stating that it failed to get file size header 
> information - but I don't know exactly where that would be getting removed. If 
> its not squid, it could be anywhere upstream from me
> I've got a "Squid Proxy Server 3.1 - Beginners Guide" but this doesn't go into 
> that much about modifying packet headers, excepts for headers to obfuscate 
> client information for security reasons. I'm pretty sure squid isn't doing 
> anything about the packet headers since this config file is so basic, so maybe 
> this has gotten outside the scope of a squid mailing list.

Nod. Squid only modifies the headers it is required to modify by HTTP,
or if you configure specific modifications to happen (any
*_header_access, *_header_replace, *_header_add directives in squid.conf).

There is no such thing as "file" in HTTP - so no "file size" exists as
such. If they mean some custom header, then Squid is definitely not
altering it without config making that happen.

There is a Content-Length header but that applies to the payload size of
the message being sent. If that is what they mean , Squid does not alter
it in valid HTTP traffic. They may be using it in invalid ways though
which Squid is required to correct on sight.

You can add "debug_options 11,2" to squid.conf to get a trace of the
HTTP messages going through when SEPM does its update thing. I suggest
only trying that in a period of low traffic.

Amos



From squid3 at treenet.co.nz  Sun Oct 30 02:32:57 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 30 Oct 2016 15:32:57 +1300
Subject: [squid-users] Default state for the option
 generate-host-certificates
In-Reply-To: <1d4da1c04ef0cce85cc471a0260bcd60@comnet.uz>
References: <1477659404.3336.11.camel@comnet.uz>
 <a341a28b-3bea-7303-4b9c-5b1e31471f52@measurement-factory.com>
 <1d4da1c04ef0cce85cc471a0260bcd60@comnet.uz>
Message-ID: <dc0d8804-dbae-7dc4-daa1-b6005ea25e67@treenet.co.nz>

On 29/10/2016 8:18 a.m., Garri Djavadyan wrote:
> On 2016-10-28 18:39, Yuri Voinov wrote:
>> It seems bug.
> 
> 
> On 2016-10-28 19:53, Alex Rousskov wrote:
>>> Is it a bug, documentation error or I simply missed something?
>>
>> It is a bug IMO. The documented intent sounds worth supporting to me.
> 
> 
> Thanks. I've opened the report [1].
> 
> [1] http://bugs.squid-cache.org/show_bug.cgi?id=4627
> 

Thanks. I've fixed the docs in Squid-3, will sho up whenever teh next
3.5 reease happens.

For Squid-4 I am making Squid actually have those defaults. That will go
in soon after the change passes pre-commit build testing.

Amos



From garryd at comnet.uz  Sun Oct 30 04:13:34 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Sun, 30 Oct 2016 09:13:34 +0500
Subject: [squid-users] Squid communications proxy dilemma
In-Reply-To: <18967036.1516462.1477755623057.JavaMail.root@vznit170064.mailsrvcs.net>
References: <18967036.1516462.1477755623057.JavaMail.root@vznit170064.mailsrvcs.net>
Message-ID: <0fd72a5caec661e3c0f80a9f17d984f0@comnet.uz>

On 2016-10-29 20:40, paul.greene.va at verizon.net wrote:
> I've inherited a squid proxy at work; I'm new to squid, so this is
> still on the learning curve. Unfortunately no one else in the office
> is very good with squid either, so I'm attempting to  be the resident
> guru.
> 
> Our network is all in private IP address space. A MS WSUS server and a
> Symantec Endpoint Protection Manager server need to get through the
> squid proxy to get out to MS and Symantec respectively for their
> updates. Some other servers are coming online in the near future that
> will also need to get out to their respective vendors to get updates,
> including a Redhat Satellite server.
> 
> For these WSUS and SEPM servers, they have to go through the proxy I'm
> working with, through a Cisco firewall, upstream to a McAfee web
> gateway, and through another gateway after that. After traffic gets
> past that Cisco firewall, a different networking group is responsible
> for any upstream configuration
> 
> None of our other servers, except these specialty servers that need to
> get out to their respective vendors for updates, have direct access to
> the internet.
> 
> Our firewall guy says what he's seeing in his logs is that traffic
> destined for port 443, after it goes through the proxy, is trying to
> go straight to the vendor over the internet, rather than go through
> the upstream McAfee gateway as required, and thus, the traffic is
> getting dropped by the Cisco firewall. I did a packet capture test
> with the McAfee gateway guy, and he confirmed that no traffic coming
> from either either the WSUS or the SEPM is reaching his gateway.
> 
> I thought this line in the squid.conf file should send traffic from
> our proxy to the upstream McAfee gateway, but maybe I'm
> misunderstanding the intent of the cache_peer parent parameter.
> 
> cache_peer <McAfee Gateway IP address>      parent    8080  3130
> proxy-only no-query no-netdb-exchange default login=username:password
> 
> (if placement of this cache_peer parameter matters, its currently near
> the end of the squid.conf file)
> 
> As a test, I configured internet explorer on the WSUS server to use
> the proxy for internet access, Without configuring for the proxy, IE
> can't go anywhere except the local network. IE can hit http websites
> (i.e. www.cnn.com) when it's configured to use the proxy, but not
> https websites.
> 
> The Safe_ports and SSL_ports list is the same as the squid.conf
> defaults.
> 
> This is squid 3.3 running on Redhat 7.
> 
> Any suggestions or pointers?
> 
> PG
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Please, use plain text (not HTML) for messages next time, as it hurts 
people reading messages on web archive [1]. Also, IMO, it increases the 
chances a message would be answered. Thanks.

[1] 
http://lists.squid-cache.org/pipermail/squid-users/2016-October/013308.html

Garri


From garryd at comnet.uz  Sun Oct 30 06:32:38 2016
From: garryd at comnet.uz (Garri Djavadyan)
Date: Sun, 30 Oct 2016 11:32:38 +0500
Subject: [squid-users]  flickr.com redirect error
In-Reply-To: <064801d1d12c$0a651d20$1f2f5760$@ngtech.co.il>
Message-ID: <1477809158.7270.7.camel@comnet.uz>

>Can you test if the details at bug 4253:
>
>http://bugs.squid-cache.org/show_bug.cgi?id=4253#c13
>
>Helps you to resolve the issue?
>
>Eliezer

The above bug is not related to the issue.

The issue is actually on origin servers side. Details can be found
here:

http://bugs.squid-cache.org/show_bug.cgi?id=4537#c3

Garri


From squid3 at treenet.co.nz  Mon Oct 31 03:07:05 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 31 Oct 2016 16:07:05 +1300
Subject: [squid-users] [squid-announce] Squid 4.0.16 beta is available
Message-ID: <8aae6d8f-f805-b92a-5306-81728b95e95b@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-4.0.16 release!


This release is a bug fix and stability release resolving several issues
found in the prior Squid releases.


The major changes to be aware of:


* Regex ACL performance improvement

The code loading regex ACL data has been refactored. The result has been
a surprisingly large improvement in speed when loading configuration
files containing regex ACLs with many values.


* HTTP: initial support for Cache-Control:immutable

The 'immutable' Cache-Control value is a new experimental caching
control which allows servers to indicate certain responses are not going
to change during their freshness lifetime. It is an improved version the
refresh_pattern 'ignore-reload' option.

NP: the 'ignore-reload' option remains until this control is fully
standardised. It is expected to become increasingly useless as wider use
of 'immutable' grows amongst servers.


Some changes shared with the future 3.5.23 release are noteworthy:

* Bug #4627: fix generate-host-certificates default

The squid.conf documentation has for some time said that this feature
was enabled by default. That was incorrect for Squid-3 and previous
Squid-4 releases.

This release actually enables the certificate generator by default in
Squid-4.


* HTTP: support Vary:* caching

Under RFC 2616 responses containing "Vary: *" header were not cachable.
That requirement has been loosened by RFC 7231 and Squid is now able to
cache these responses.


* ssl::server_name ACL badly broken since inception

The original server_name code mishandled all SNI checks and some rare
host checks. This was most visible with the reports that the
ssl::server_name ACL tests would fail where the equivalent regex ACL
test would behave differently, usually by matching. Or in situations
where neither would match despite the value appearing to be available.


 All users of Squid-4.0.x with ACL type ssl::server_name or
ssl::server_name_regex should upgrade to this release and re-test for
desired SSL-Bump feature behaviour.

 All users of Squid-4.0.x are encouraged to upgrade to this release as
soon as possible.

 All users of Squid-3 are encouraged to test this release out and plan
for upgrades where possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v4/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From eduardoocarneiro at gmail.com  Mon Oct 31 17:31:27 2016
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Mon, 31 Oct 2016 10:31:27 -0700 (PDT)
Subject: [squid-users] Authentication problem
Message-ID: <1477935087451-4680378.post@n4.nabble.com>

Hi all.

I have a strange authentication issue in my squid 3.5.19. My workstations
only can authenticate if they are entered into the domain. When they doesn't
entered into the domain, I access any URL on browser (Firefox and Chrome
tested) and I'm not able authenticate on the boxes that are shown to me.

Squid logs show me "TCP_DENIED/407".

Bellow is my squid.conf authentication configuration:

---
auth_param ntlm program /usr/bin/ntlm_auth
--helper-protocol=squid-2.5-ntlmssp
auth_param ntlm children 140
auth_param ntlm keep_alive on
auth_param basic program /usr/bin/ntlm_auth
--helper-protocol=squid-2.5-basic
auth_param basic children 60
auth_param basic credentialsttl 10 hours
auth_param basic realm enter your password

acl authenticated proxy_auth REQUIRED
http_access deny !authenticated
---

I noticed that in Firefox's private tabs works perfectly.

Am I doing something wrong? Has anyone experienced this?

Thanks,
Eduardo Carneiro



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Authentication-problem-tp4680378.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid-user at tlinx.org  Mon Oct 31 22:13:49 2016
From: squid-user at tlinx.org (L. A. Walsh)
Date: Mon, 31 Oct 2016 15:13:49 -0700
Subject: [squid-users] Certificate transparency: problem for ssl-bumping,
	no effect, or?
Message-ID: <5817C21D.5050003@tlinx.org>

Google is pushing this for all websites by October 2017

One issue to be "caught" are subordinated CA certs that can
allow one vector for generating certs accepted by browsers w/o
importing any new certs.

Some of the info on the cert page:

    https://www.certificate-transparency.org/what-is-ct

Seems to indicate that site-local generated and imported
certs may also be detected as invalid and be disallowed for
SSL connection approvals.  That would be a major pain given
google's actions that seem to be hostile to end-user (or
end-site) web-caching.
(saw this on 
http://www.theregister.co.uk/2016/10/31/google_certificate_transparency/
).



From yvoinov at gmail.com  Mon Oct 31 22:41:35 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 1 Nov 2016 04:41:35 +0600
Subject: [squid-users] Certificate transparency: problem for ssl-bumping,
 no effect, or?
In-Reply-To: <5817C21D.5050003@tlinx.org>
References: <5817C21D.5050003@tlinx.org>
Message-ID: <abae187b-2eae-d9fe-1b55-ffc13f21baea@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
When the future comes - then we will worry. What wonder, then?

October 2017 is not tomorrow.


01.11.2016 4:13, L. A. Walsh ?????:
> Google is pushing this for all websites by October 2017
>
> One issue to be "caught" are subordinated CA certs that can
> allow one vector for generating certs accepted by browsers w/o
> importing any new certs.
>
> Some of the info on the cert page:
>
>    https://www.certificate-transparency.org/what-is-ct
>
> Seems to indicate that site-local generated and imported
> certs may also be detected as invalid and be disallowed for
> SSL connection approvals.  That would be a major pain given
> google's actions that seem to be hostile to end-user (or
> end-site) web-caching.
> (saw this on
http://www.theregister.co.uk/2016/10/31/google_certificate_transparency/
> ).
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYF8ieAAoJENNXIZxhPexGVrMIAIXr9n92Ven5E7vmtgtxsRtq
Knf2sv/qz1jyl6P836FjSSd+GJuKe0hNxUsuina/MiBlRcbH2hUTuEAJzdbLxebH
2qvN/RxulejKOQFLFaZvrOSBh3b809m+dBlEtIQ8IeWfWpCF02fddU+X7cT9o+8p
hHZW2mgZLq2mJH8u2iIpPzv1uQx4uJdxg22by9YE2bYo2TOpN4b/6vnDEfF8Ggnt
1S2Z4nvak1d+GfX+b9Temlf7LSOuzeWW8gtgj4WPjNUMOnToRo+RGm0Z0by61x3z
frDreEtHuTXVh5ppVIpQdP9VZDsIbTnYt9JmU6c0CigW11sQCU7Z3rQZPG1xp7o=
=2BL1
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161101/7c20f4d2/attachment.key>

From yvoinov at gmail.com  Mon Oct 31 22:48:08 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 1 Nov 2016 04:48:08 +0600
Subject: [squid-users] Certificate transparency: problem for ssl-bumping,
 no effect, or?
In-Reply-To: <abae187b-2eae-d9fe-1b55-ffc13f21baea@gmail.com>
References: <5817C21D.5050003@tlinx.org>
 <abae187b-2eae-d9fe-1b55-ffc13f21baea@gmail.com>
Message-ID: <f6d8a611-7d4f-aef0-e257-0129672b7e6c@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Google and so is not too conducive to caching the end user. One problem
anymore - one less, what's the difference? When we begin to beat - start
to cry. In general, the year in IT - eternity. During this time,
everything can happen. So relax, cousin. Nothing else happened. ;)

PS. A magic bullets - does not exist. You have forgotten that some
governments are willing to carry out globally SSL Bump over its
citizens. This is a separate issue for everyone, not just for these
citizens. So quietly celebrate Halloween and do not ride the wave :)

01.11.2016 4:41, Yuri Voinov ?????:
>
> When the future comes - then we will worry. What wonder, then?
>
> October 2017 is not tomorrow.
>
>
> 01.11.2016 4:13, L. A. Walsh ?????:
> > Google is pushing this for all websites by October 2017
>
> > One issue to be "caught" are subordinated CA certs that can
> > allow one vector for generating certs accepted by browsers w/o
> > importing any new certs.
>
> > Some of the info on the cert page:
>
> >    https://www.certificate-transparency.org/what-is-ct
>
> > Seems to indicate that site-local generated and imported
> > certs may also be detected as invalid and be disallowed for
> > SSL connection approvals.  That would be a major pain given
> > google's actions that seem to be hostile to end-user (or
> > end-site) web-caching.
> > (saw this on
> http://www.theregister.co.uk/2016/10/31/google_certificate_transparency/
> > ).
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

- -- 
Cats - delicious. You just do not know how to cook them.
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJYF8ooAAoJENNXIZxhPexG+VAH/15vFPprneESrl94A2iOrHo4
2JoAy0Fqi7mJjuSjSNOhW3O2AutJkrPMDMTg8FEso999wI/HsuRCWqaMLpQU/7dv
hzA3BwegOrELBXb5x5YPXP8FgMkN6Wytcy9nOkU6Hn/s3u3QP8zUqLWFbLGqnMoF
PSJuCbNA3m8IOf7WP2nF3824KLM3AMkByQ2XszS7TnP4LxYIIYh+0mcJ7oSqaLxo
oMCDCknfu0FcISl1MVxQQVIpVqxfNnzBxFrBVK2ZJ5mDgeyB0+dQjULpRO0IDGDL
PRQeUAgyREEejfuJLpoE+ufwT9SkTyxm6WZUZiJgOEnueNdxc5wox0jJpOX+5bY=
=zXZ1
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161101/9944b196/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161101/9944b196/attachment.key>

