From fredbmail at free.fr  Thu Sep  1 07:08:07 2016
From: fredbmail at free.fr (FredB)
Date: Thu, 1 Sep 2016 09:08:07 +0200 (CEST)
Subject: [squid-users] Squid 3.5.20 rock store and enable-disk-io
In-Reply-To: <8d554ef6-6c7a-4b1b-16a5-d5abc52ed19a@measurement-factory.com>
Message-ID: <1989140072.789143140.1472713687911.JavaMail.root@zimbra4-e1.priv.proxad.net>

Hi Alex


> Normally, you do not need any ./configure options to enable Rock
> support, including support for a stand-alone disker process. If you
> want
> to enable IpcIo explicitly, you may, but I would first check whether
> it
> was enabled without any --enable-disk-io options:
> 
> > $ fgrep IpcIo config.log
> > configure:21195: Enabling IpcIo DiskIO module
> > configure:21227: IO Modules built:  AIO Blocking DiskDaemon
> > DiskThreads IpcIo Mmapped
> 
> IpcIo requires shared memory support bust most modern build
> environments
> provide that.

Ok 

configure:21150: result:  Blocking DiskThreads IpcIo Mmapped AIO DiskDaemon
configure:21665: Enabling IpcIo DiskIO module
configure:21695: IO Modules built:  Blocking DiskThreads IpcIo Mmapped AIO DiskDaemon


> 
> > Perhaps this process is only created in smp mode ?
> 
> As the documentation tries to imply, the disker process is used when
> all
> of the statements below are true:
> 
> * there are rock cache_dir(s) in squid.conf


cache_dir rock /cache1 130000 
cache_dir rock /cache2 130000 

> * IpcIo disk I/O module is enabled (it usually is by default)

Yes

configure:21150: result:  Blocking DiskThreads IpcIo Mmapped AIO DiskDaemon
configure:21665: Enabling IpcIo DiskIO module
configure:21695: IO Modules built:  Blocking DiskThreads IpcIo Mmapped AIO DiskDaemon

> * Squid was started without the -N command line option.

This is the point ! 
By default, after the compilation the systemd is generated like this 

more ./tools/systemd/squid.service
## Copyright (C) 1996-2016 The Squid Software Foundation and contributors
##
## Squid software is distributed under GPLv2+ license and includes
## contributions from numerous individuals and organizations.
## Please see the COPYING and CONTRIBUTORS files for details.
##

[Unit]
Description=Squid Web Proxy Server
After=network.target

[Service]
Type=simple
ExecStart=/usr/sbin/squid -sYC -N
ExecReload=/bin/kill -HUP $MAINPID
KillMode=process

[Install]
WantedBy=multi-user.target

But I have a new problem, not present without IpcIo or with squid -N 

FATAL: Rock cache_dir at /cache1/rock failed to open db file: (2) No such file or directory
Squid Cache (Version 3.5.20): Terminated abnormally.
CPU Usage: 0.056 seconds = 0.008 user + 0.048 sys
Maximum Resident Size: 104144 KB
Page faults with physical i/o: 0
2016/09/01 09:01:01 kid2| Store rebuilding is 61.69% complete
2016/09/01 09:01:01 kid3| Store rebuilding is 62.03% complete
2016/09/01 09:01:01 kid1| Set Current Directory to /home/squid
2016/09/01 09:01:01 kid1| Starting Squid Cache version 3.5.20 for x86_64-pc-linux-gnu...
2016/09/01 09:01:01 kid1| Service Name: squid
2016/09/01 09:01:01 kid1| Process ID 7454
2016/09/01 09:01:01 kid1| Process Roles: worker
2016/09/01 09:01:01 kid1| With 65535 file descriptors available
2016/09/01 09:01:01 kid1| Initializing IP Cache...
2016/09/01 09:01:01 kid1| DNS Socket created at 0.0.0.0, FD 12
2016/09/01 09:01:01 kid1| Adding nameserver 192.168.115.1 from /etc/resolv.conf
2016/09/01 09:01:01 kid1| Adding nameserver 192.168.115.2 from /etc/resolv.conf
2016/09/01 09:01:01 kid1| helperOpenServers: Starting 50/150 'digest_ldap_auth' processes
2016/09/01 09:01:01 kid1| helperOpenServers: Starting 40/150 'basic_ldap_auth' processes
2016/09/01 09:01:01 kid1| Logfile: opening log stdio:/var/log/squid/access.log
2016/09/01 09:01:01 kid1| Local cache digest enabled; rebuild/rewrite every 3600/3600 sec
2016/09/01 09:01:01 kid1| Store logging disabled
2016/09/01 09:01:01 kid1| WARNING: disk-cache maximum object size is too large for mem-cache: 5242880.00 KB > 5120.00 KB
2016/09/01 09:01:01 kid1| Swap maxSize 0 + 16777216 KB, estimated 1290555 objects
2016/09/01 09:01:01 kid1| Target number of buckets: 64527
2016/09/01 09:01:01 kid1| Using 65536 Store buckets
2016/09/01 09:01:01 kid1| Max Mem  size: 16777216 KB [shared]
2016/09/01 09:01:01 kid1| Max Swap size: 0 KB
2016/09/01 09:01:01 kid1| Using Least Load store dir selection
2016/09/01 09:01:01 kid1| Set Current Directory to /home/squid
2016/09/01 09:01:01 kid1| Finished loading MIME types and icons.
2016/09/01 09:01:01 kid1| HTCP Disabled.
2016/09/01 09:01:01 kid1| Squid plugin modules loaded: 0
2016/09/01 09:01:01 kid1| Adaptation support is on
2016/09/01 09:01:01 kid1| commBind: Cannot bind socket FD 20 to [::]: (2) No such file or directory
2016/09/01 09:01:08 kid1| ERROR: /cache1/rock communication channel establishment timeout
2016/09/01 09:01:08 kid1| Closing HTTP port 0.0.0.0:8080
FATAL: Rock cache_dir at /cache1/rock failed to open db file: (2) No such file or directory
Squid Cache (Version 3.5.20): Terminated abnormally.
CPU Usage: 0.056 seconds = 0.012 user + 0.044 sys
Maximum Resident Size: 103632 KB
Page faults with physical i/o: 0
2016/09/01 09:01:11 kid1| Set Current Directory to /home/squid
2016/09/01 09:01:11 kid1| Starting Squid Cache version 3.5.20 for x86_64-pc-linux-gnu...
2016/09/01 09:01:11 kid1| Service Name: squid
2016/09/01 09:01:11 kid1| Process ID 7550
2016/09/01 09:01:11 kid1| Process Roles: worker
2016/09/01 09:01:11 kid1| With 65535 file descriptors available
2016/09/01 09:01:11 kid1| Initializing IP Cache...
2016/09/01 09:01:11 kid1| DNS Socket created at 0.0.0.0, FD 12
2016/09/01 09:01:11 kid1| Adding nameserver 192.168.115.1 from /etc/resolv.conf
2016/09/01 09:01:11 kid1| Adding nameserver 192.168.115.2 from /etc/resolv.conf
2016/09/01 09:01:11 kid1| helperOpenServers: Starting 50/150 'digest_ldap_auth' processes
2016/09/01 09:01:11 kid1| helperOpenServers: Starting 40/150 'basic_ldap_auth' processes
2016/09/01 09:01:11 kid1| Logfile: opening log stdio:/var/log/squid/access.log
2016/09/01 09:01:11 kid1| Local cache digest enabled; rebuild/rewrite every 3600/3600 sec
2016/09/01 09:01:11 kid1| Store logging disabled
2016/09/01 09:01:11 kid1| WARNING: disk-cache maximum object size is too large for mem-cache: 5242880.00 KB > 5120.00 KB
2016/09/01 09:01:11 kid1| Swap maxSize 0 + 16777216 KB, estimated 1290555 objects
2016/09/01 09:01:11 kid1| Target number of buckets: 64527
2016/09/01 09:01:11 kid1| Using 65536 Store buckets
2016/09/01 09:01:11 kid1| Max Mem  size: 16777216 KB [shared]
2016/09/01 09:01:11 kid1| Max Swap size: 0 KB
2016/09/01 09:01:11 kid1| Using Least Load store dir selection
2016/09/01 09:01:11 kid1| Set Current Directory to /home/squid
2016/09/01 09:01:11 kid1| Finished loading MIME types and icons.
2016/09/01 09:01:11 kid1| HTCP Disabled.
2016/09/01 09:01:11 kid1| Squid plugin modules loaded: 0
2016/09/01 09:01:11 kid1| Adaptation support is on
2016/09/01 09:01:11 kid1| commBind: Cannot bind socket FD 20 to [::]: (2) No such file or directory
2016/09/01 09:01:16 kid3| Store rebuilding is 94.96% complete
2016/09/01 09:01:16 kid2| Store rebuilding is 94.63% complete
2016/09/01 09:01:18 kid3| Finished rebuilding storage from disk.
2016/09/01 09:01:18 kid3|   8319999 Entries scanned
2016/09/01 09:01:18 kid3|         0 Invalid entries.
2016/09/01 09:01:18 kid3|         0 With invalid flags.
2016/09/01 09:01:18 kid3|         0 Objects loaded.
2016/09/01 09:01:18 kid3|         0 Objects expired.
2016/09/01 09:01:18 kid3|         0 Objects cancelled.
2016/09/01 09:01:18 kid3|         0 Duplicate URLs purged.
2016/09/01 09:01:18 kid3|         0 Swapfile clashes avoided.
2016/09/01 09:01:18 kid3|   Took 47.02 seconds (  0.00 objects/sec).
2016/09/01 09:01:18 kid3| Beginning Validation Procedure
2016/09/01 09:01:18 kid3|   Completed Validation Procedure
2016/09/01 09:01:18 kid3|   Validated 0 Entries
2016/09/01 09:01:18 kid3|   store_swap_size = 16.00 KB
2016/09/01 09:01:18 kid2| Finished rebuilding storage from disk.
2016/09/01 09:01:18 kid2|   8319999 Entries scanned
2016/09/01 09:01:18 kid2|         0 Invalid entries.
2016/09/01 09:01:18 kid2|         0 With invalid flags.
2016/09/01 09:01:18 kid2|         0 Objects loaded.
2016/09/01 09:01:18 kid2|         0 Objects expired.
2016/09/01 09:01:18 kid2|         0 Objects cancelled.
2016/09/01 09:01:18 kid2|         0 Duplicate URLs purged.
2016/09/01 09:01:18 kid2|         0 Swapfile clashes avoided.
2016/09/01 09:01:18 kid2|   Took 47.22 seconds (  0.00 objects/sec).
2016/09/01 09:01:18 kid2| Beginning Validation Procedure
2016/09/01 09:01:18 kid2|   Completed Validation Procedure
2016/09/01 09:01:18 kid2|   Validated 0 Entries
2016/09/01 09:01:18 kid2|   store_swap_size = 16.00 KB
2016/09/01 09:01:18 kid1| ERROR: /cache1/rock communication channel establishment timeout
2016/09/01 09:01:18 kid1| Closing HTTP port 0.0.0.0:8080
FATAL: Rock cache_dir at /cache1/rock failed to open db file: (2) No such file or directory
Squid Cache (Version 3.5.20): Terminated abnormally.
CPU Usage: 0.064 seconds = 0.020 user + 0.044 sys
Maximum Resident Size: 103952 KB
Page faults with physical i/o: 0
2016/09/01 09:01:19 kid2| storeLateRelease: released 0 objects
2016/09/01 09:01:19 kid3| storeLateRelease: released 0 objects

If I add -N the problem and restart is gone 

Fred

> 
> 
> HTH,
> 
> Alex.
> 
> 


From fredbmail at free.fr  Thu Sep  1 07:16:22 2016
From: fredbmail at free.fr (FredB)
Date: Thu, 1 Sep 2016 09:16:22 +0200 (CEST)
Subject: [squid-users] Squid 3.5.20 rock store and enable-disk-io
In-Reply-To: <1989140072.789143140.1472713687911.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1205093198.789203025.1472714182616.JavaMail.root@zimbra4-e1.priv.proxad.net>

I forgot


/cache1:
total 212380
drwxrwxrwx  3 squid root          4096 sept.  1 09:00 .
drwxr-xr-x 26 root  root          4096 nov.  17  2015 ..
drwxrwxrwx  2 squid root         16384 ao?t  31 09:12 lost+found
-rwxrwxrwx  1 squid squid 136314880000 sept.  1 09:14 rock

/cache2:
total 204584
drwxrwxrwx  3 squid root          4096 sept.  1 09:00 .
drwxr-xr-x 26 root  root          4096 nov.  17  2015 ..
drwxrwxrwx  2 squid root         16384 ao?t  31 09:12 lost+found
-rwxrwxrwx  1 squid squid 136314880000 sept.  1 09:14 rock


From fredbmail at free.fr  Thu Sep  1 07:48:28 2016
From: fredbmail at free.fr (FredB)
Date: Thu, 1 Sep 2016 09:48:28 +0200 (CEST)
Subject: [squid-users] Squid 3.5.20 rock store and enable-disk-io
In-Reply-To: <1989140072.789143140.1472713687911.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1948576894.789630177.1472716108769.JavaMail.root@zimbra4-e1.priv.proxad.net>


> 
> [Unit]
> Description=Squid Web Proxy Server
> After=network.target
> 
> [Service]
> Type=simple
> ExecStart=/usr/sbin/squid -sYC -N


Yes this is the default value 

http://bazaar.launchpad.net/~squid/squid/3.5/view/head:/tools/systemd/squid.service

I guess this is wrong no ?

Fred





From splash at gmail.com  Thu Sep  1 09:37:09 2016
From: splash at gmail.com (Diogenes S. Jesus)
Date: Thu, 1 Sep 2016 11:37:09 +0200
Subject: [squid-users] HTTPS chrome - SHA1 this page is insecure
In-Reply-To: <a8e64dad-e101-430f-5c90-b895c01e8714@measurement-factory.com>
References: <1472653571328-4679281.post@n4.nabble.com>
 <132fa841-bddd-630a-85c1-a0475e9480a8@treenet.co.nz>
 <a8e64dad-e101-430f-5c90-b895c01e8714@measurement-factory.com>
Message-ID: <CAD8MJvD964OD5YRc6vpMk+rRHWRDPvx76XhJpqDPGWXEWgsZWg@mail.gmail.com>

The answer why you only see it on Chrome is because since Chrome >= 41:

"Sites with end-entity certificates that expire on or after 1 January 2017,
and which include a SHA-1-based signature as part of the certificate chain,
will be treated as ?affirmatively insecure?. Subresources from such domain
will be treated as ?active mixed content?."
Source:
https://security.googleblog.com/2014/09/gradually-sunsetting-sha-1.html

Best regards

On Wed, Aug 31, 2016 at 5:24 PM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 08/31/2016 09:15 AM, Amos Jeffries wrote:
> > On 1/09/2016 2:26 a.m., erdosain9 wrote:
> >> Hi.
> >> Im using ssl-bump.. all ir working fine, but i want to know if it is
> >> possible that which is not seen crossed out and red "https".
> >> This happen just in Chrome
> >> This page is insecure (broken HTTPS)
> >> SHA-1 Certificate
> >> The certificate for this site expires in 2017 or later, and the
> certificate
> >> chain contains a certificate signed using SHA-1.
>
> Sounds like you are running an old Squid version.
>
>
> > This requires changes to the certificate generator used by SSL-Bump.
> > IIRC there were some patches, but I can't find them right now in the
> > changesets. If the issue exists in current releases then please ask on
> > squid-dev.
>
> See http://www.squid-cache.org/Doc/config/sslproxy_cert_sign_hash/
>
>
> > Of course, its possible the site realy does have a SHA1 certificate and
> > Squid is just passing on the real details. The mimic feature is designed
> > to ensure TLS is actually transparent as best we can manage.
>
> I have not checked, but I doubt we mimic the signing algorithm (because
> it would make client-Squid communication less secure?). If we do, we
> should update the wiki page that lists what is being mimicked.
>
>
> HTH,
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 

--------

Diogenes S. de Jesus
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160901/9bf829f8/attachment.htm>

From rafael.akchurin at diladele.com  Thu Sep  1 09:54:43 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 1 Sep 2016 09:54:43 +0000
Subject: [squid-users] HTTPS chrome - SHA1 this page is insecure
In-Reply-To: <CAD8MJvD964OD5YRc6vpMk+rRHWRDPvx76XhJpqDPGWXEWgsZWg@mail.gmail.com>
References: <1472653571328-4679281.post@n4.nabble.com>
 <132fa841-bddd-630a-85c1-a0475e9480a8@treenet.co.nz>
 <a8e64dad-e101-430f-5c90-b895c01e8714@measurement-factory.com>
 <CAD8MJvD964OD5YRc6vpMk+rRHWRDPvx76XhJpqDPGWXEWgsZWg@mail.gmail.com>
Message-ID: <DB6PR0401MB26800E07801A286AF0410BC38FE20@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Hello everyone,

It also may be you are using old Squid that does not support signing faked certificate with algorithm other than SHA-1 (because it was hardcoded at that time). This is the case of Squid 3.3.8 usually present in stable Ubuntu 14 LTS and CentOS 7.

In order to fix it you either need to go to most recent Squid (preferred) or recompile your Squid after applying a small patch like the following:

--- gadgets.cc  2013-07-13 15:25:14.000000000 +0200
+++ gadgets.cc.new      2015-11-09 23:00:47.591124352 +0100
@@ -389,9 +389,9 @@

     /*Now sign the request */
     if (properties.signAlgorithm != Ssl::algSignSelf && properties.signWithPkey.get())
-        ret = X509_sign(cert.get(), properties.signWithPkey.get(), EVP_sha1());
+        ret = X509_sign(cert.get(), properties.signWithPkey.get(), EVP_sha256());
     else //else sign with self key (self signed request)
-        ret = X509_sign(cert.get(), pkey.get(), EVP_sha1());
+        ret = X509_sign(cert.get(), pkey.get(), EVP_sha256());

     if (!ret)
         return false;

There is doc article and repo that has it all explained:
http://docs.diladele.com/administrator_guide_4_4/install/ubuntu14/squid.html
https://github.com/ra-at-diladele-com/qlproxy_external/tree/master/src/va/scripts.ubuntu14

But please take it with a huge grain of salt if you can.

Best regards,
Rafael Akchurin
Diladele B.V.
http://www.quintolabs.com
http://www.diladele.com

--
Please take a look at Web Safety - our ICAP based web filter server for Squid proxy.




From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Diogenes S. Jesus
Sent: Thursday, September 1, 2016 11:37 AM
To: Alex Rousskov <rousskov at measurement-factory.com>
Cc: squid-users at lists.squid-cache.org; erdosain9 <erdosain9 at gmail.com>
Subject: Re: [squid-users] HTTPS chrome - SHA1 this page is insecure

The answer why you only see it on Chrome is because since Chrome >= 41:

"Sites with end-entity certificates that expire on or after 1 January 2017, and which include a SHA-1-based signature as part of the certificate chain, will be treated as ?affirmatively insecure?. Subresources from such domain will be treated as ?active mixed content?."
Source: https://security.googleblog.com/2014/09/gradually-sunsetting-sha-1.html

Best regards

On Wed, Aug 31, 2016 at 5:24 PM, Alex Rousskov <rousskov at measurement-factory.com<mailto:rousskov at measurement-factory.com>> wrote:
On 08/31/2016 09:15 AM, Amos Jeffries wrote:
> On 1/09/2016 2:26 a.m., erdosain9 wrote:
>> Hi.
>> Im using ssl-bump.. all ir working fine, but i want to know if it is
>> possible that which is not seen crossed out and red "https".
>> This happen just in Chrome
>> This page is insecure (broken HTTPS)
>> SHA-1 Certificate
>> The certificate for this site expires in 2017 or later, and the certificate
>> chain contains a certificate signed using SHA-1.

Sounds like you are running an old Squid version.


> This requires changes to the certificate generator used by SSL-Bump.
> IIRC there were some patches, but I can't find them right now in the
> changesets. If the issue exists in current releases then please ask on
> squid-dev.

See http://www.squid-cache.org/Doc/config/sslproxy_cert_sign_hash/


> Of course, its possible the site realy does have a SHA1 certificate and
> Squid is just passing on the real details. The mimic feature is designed
> to ensure TLS is actually transparent as best we can manage.

I have not checked, but I doubt we mimic the signing algorithm (because
it would make client-Squid communication less secure?). If we do, we
should update the wiki page that lists what is being mimicked.


HTH,

Alex.

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users



--

--------

Diogenes S. de Jesus
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160901/b609f2cf/attachment.htm>

From erdosain9 at gmail.com  Thu Sep  1 13:12:13 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 1 Sep 2016 06:12:13 -0700 (PDT)
Subject: [squid-users] Web Whatsapp, Dropbox... problem
Message-ID: <1472735533311-4679299.post@n4.nabble.com>

Hi to all.
Im having problem with the 

web.whatssap.com

and with Dropbox client... 

There is a way to exclude this things from the proxy???

Thanks!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Thu Sep  1 13:23:50 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 1 Sep 2016 19:23:50 +0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1472735533311-4679299.post@n4.nabble.com>
References: <1472735533311-4679299.post@n4.nabble.com>
Message-ID: <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
http://wiki.squid-cache.org/Features/SslPeekAndSplice

Here is answer to your question. Read carefully.


01.09.2016 19:12, erdosain9 ?????:
> Hi to all.
> Im having problem with the
>
> web.whatssap.com
>
> and with Dropbox client...
>
> There is a way to exclude this things from the proxy???
>
> Thanks!
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXyCvmAAoJENNXIZxhPexGy38H/i60uON6MvoqycUAAiP4WezA
zPxux5/AHfa60teRnbgOZp9WNL/sPI71+r00yKeu+9hAbtaFclovaTISwehDm13H
B+P3czWFKrkkSf2Qz2jcdT+OS/0m06+3fTaeA0KSdtIFmBukx9To430BBB7o3ltK
5owj9ahn38fQHE8T/X3shmYnz54BBXWQGzKhxe/cehUABm0QfLx4EuVKpHeT63by
I20IcXdqT92quwaTystVxCDNnktySj+YhlHOGOaFa5pmU6WjJxIbZG8yDaU7PkYY
e0s1KlkYyElAcDp5wyDItGxBpR3G1nwYUUr4s3h/3YLJIrbV4qX5WifYfsPU9Yk=
=DYaf
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160901/97943f74/attachment.key>

From erdosain9 at gmail.com  Thu Sep  1 13:43:23 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 1 Sep 2016 06:43:23 -0700 (PDT)
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <144fe7c6-b110-4cce-365e-e885564e3d99@treenet.co.nz>
References: <1472150349506-4679182.post@n4.nabble.com>
 <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
 <1472157312575-4679194.post@n4.nabble.com>
 <144fe7c6-b110-4cce-365e-e885564e3d99@treenet.co.nz>
Message-ID: <1472737403741-4679301.post@n4.nabble.com>

PLEASE HELP!
I probe this 
" You can use debug_options 11,2 to see the HTTP message headers and 
figure it out"

and now i cant stop the debug??? i have a big big access.log... i cannot
stop the debug. 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679301.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Thu Sep  1 13:54:14 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 1 Sep 2016 19:54:14 +0600
Subject: [squid-users] Limit Bandwith for youtube....
In-Reply-To: <1472737403741-4679301.post@n4.nabble.com>
References: <1472150349506-4679182.post@n4.nabble.com>
 <1b9902dd-b1d6-5852-2695-25301d7c5ab4@gmail.com>
 <1472157312575-4679194.post@n4.nabble.com>
 <144fe7c6-b110-4cce-365e-e885564e3d99@treenet.co.nz>
 <1472737403741-4679301.post@n4.nabble.com>
Message-ID: <6094961e-87dd-88ba-fd23-724d7e4a1f4f@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Man, don't panic.

just comment out debud_options and reconfigure your squid.

Always yours, Captain Obvious.

01.09.2016 19:43, erdosain9 ?????:
> PLEASE HELP!
> I probe this
> " You can use debug_options 11,2 to see the HTTP message headers and
> figure it out"
>
> and now i cant stop the debug??? i have a big big access.log... i cannot
> stop the debug.
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Limit-Bandwith-for-youtube-tp4679182p4679301.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXyDMGAAoJENNXIZxhPexGIJ8H/j7h5DkqO0afDor8kc0t+Ton
53Sz1FcdAmluvhefFyxbaFKVRYuOAeUUGTTPfyavFhIzeCaZSPGFDTjjtRFp9uch
F3IjSIaVIFyKMAmzVGED04MsdqNz6YGuY9rdEztt14TFfGNS7kK4PpXX0jWFkNoR
J62Tl3WD8NuqPC3NqCAdF4kJd4ybj1IkWQRefLAlXkmzQZrrz4cUUPfI5BIqBV31
Dku+NuIbEFSph0vEjesVUmVRfn5mNtyhHBPo45qG/QvNJComb0MoSvxgEuZ9KCWF
U1BAPwsp18FACRONYgvCVbfdcs2N5zvZElCSRZUl9A6YuSRt7f106KksuYsPMwM=
=UWuB
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160901/bb3be6a5/attachment.key>

From chicocvenancio at gmail.com  Thu Sep  1 14:18:33 2016
From: chicocvenancio at gmail.com (Chico Venancio)
Date: Thu, 1 Sep 2016 11:18:33 -0300
Subject: [squid-users] Fwd:  Limit Bandwith for youtube....
In-Reply-To: <CAEpx-0XfURCP+rH23Zrq8BQR2_esCT1uogUm8Tasjy_uog06BQ@mail.gmail.com>
References: <20160826175435.GB32085@fantomas.sk>
 <e51536e9-c91d-4053-2a41-d9387f5f6be6@gmail.com>
 <20160828113431.GA8946@fantomas.sk>
 <c158c4c4-c5f0-9ab4-c22e-97e3a8756e0b@gmail.com>
 <b2dbda87-c1e1-807a-9f0f-c48b82f8043c@gmail.com>
 <da17cab1-3681-85e4-7c7a-3621ff37867c@gmail.com>
 <1472483298687-4679242.post@n4.nabble.com>
 <9e3d4c8d-1f6e-78c2-64fc-7c89b879c17d@gmail.com>
 <1472501589650-4679253.post@n4.nabble.com>
 <32111747-1177-6735-ca32-b289378c3ec1@treenet.co.nz>
 <1472587980055-4679268.post@n4.nabble.com>
 <defe52fd-6193-9fed-8a05-2bb76afaa744@treenet.co.nz>
 <CAEpx-0XfURCP+rH23Zrq8BQR2_esCT1uogUm8Tasjy_uog06BQ@mail.gmail.com>
Message-ID: <CAEpx-0U9Hps-53rBvZF6RahTdxF1J2fc9cCP9hvy1pJ0YOnnuQ@mail.gmail.com>

Sent in private to Amos in error.


There are known bugs in delay pools but they
> cause very specific low number of multiples or fractions of the
> configured pool size - not hundreds of KB faster rates.


That's true for the latest version. A few many versions ago there were lots
of bugs with https and delay pools. Since he refuses to state the running
version I wouldn't discount the possibility.

Chico Venancio

2016-08-31 12:23 GMT-03:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 31/08/2016 8:13 a.m., erdosain9 wrote:
> > Thanks.
> > But...
> > I'm misunderstanding ?
> > Tx , is not the download?
>
> TX is sent bytes. It depends on what your interfaces mean, but it looks
> to me like it is uploads. There are known bugs in delay pools but they
> cause very specific low number of multiples or fractions of the
> configured pool size - not hundreds of KB faster rates.
>
> >
> > I think it works this way in the mikrotik . That is, the transmission
> would
> > be the " download "
>
> So the report you are looking at is measuring the Squid<->client interface?
>
> Squid delay pools are operating on the Squid<->Server interface traffic.
> So they can rate limit your (probably costly) *upstream* bandwidth, not
> your internal LAN bandwidth between Squid and clients.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160901/fd807493/attachment.htm>

From erdosain9 at gmail.com  Thu Sep  1 14:21:09 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 1 Sep 2016 07:21:09 -0700 (PDT)
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
Message-ID: <1472739669810-4679304.post@n4.nabble.com>

hi.
Thanks
but, now im using ssl-bump with squid 3.3.8 is there a possibility that work
web.whatsapp and drobpox with this version, or at least exclude them from
the "proxy"???

Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679304.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Thu Sep  1 14:27:04 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 1 Sep 2016 08:27:04 -0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1472739669810-4679304.post@n4.nabble.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
Message-ID: <b93fc0a9-56a6-4e53-1ebd-ae1dba2c4ca5@measurement-factory.com>

On 09/01/2016 08:21 AM, erdosain9 wrote:
> but, now im using ssl-bump with squid 3.3.8 

You really should not: Using that Squid version with SslBump creates
more problems than you can solve. Upgrading to the latest v3.5 (at
least) is the right solution.

Alex.



From yvoinov at gmail.com  Thu Sep  1 14:29:07 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 1 Sep 2016 20:29:07 +0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1472739669810-4679304.post@n4.nabble.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
Message-ID: <84ee6abb-63ec-f833-ef7d-39121481803f@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
In versions older than 3.5 squid's uses obsolete SSL bump
implementation, which requires IP's against server_name to splice/no_bump.

Your Squid is antique. Upgrade it first.


01.09.2016 20:21, erdosain9 ?????:
> hi.
> Thanks
> but, now im using ssl-bump with squid 3.3.8 is there a possibility
that work
> web.whatsapp and drobpox with this version, or at least exclude them from
> the "proxy"???
>
> Thanks
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679304.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXyDsyAAoJENNXIZxhPexG3XsH/jX8twPzWDTCE3/NYDKdFstm
dgQOM7vvXg5lQWx/ufc8FNns6TvM3+pGJmPSJmEchZ8Ai+YA++xGpf050zIedd/W
Txf/unD8yb2WWuUKNtu45Px4jagaO3A65Y6WwUMSe79zdvdT/n7tu8AxD2E5t9Yn
NxkQs/EOv66Au3rbQDjcEPxWbL0tm5t46g8pnFdYYlzriW+SpRtN9WkzRPhyR3qw
rK3GJ33teSvee2E2sjoJWPtbX+dMSeXxNYrT9ZTTXttdpjQYkU6tKYZvpoHKXvjE
ET4ppSuEfnORGMTrKOOoe1GmfFOPBHl7wy4hM96TM+rXIOeWdN0z8kvGHKu7zpg=
=NlaO
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160901/b815acc1/attachment.key>

From yvoinov at gmail.com  Thu Sep  1 14:30:33 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 1 Sep 2016 20:30:33 +0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1472739669810-4679304.post@n4.nabble.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
Message-ID: <c8bdf166-9504-763b-fc31-4317aeda418a@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Or, you can buy router to bypass proxy for selected IP's. eBay is great.


01.09.2016 20:21, erdosain9 ?????:
> hi.
> Thanks
> but, now im using ssl-bump with squid 3.3.8 is there a possibility
that work
> web.whatsapp and drobpox with this version, or at least exclude them from
> the "proxy"???
>
> Thanks
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679304.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXyDuJAAoJENNXIZxhPexGfXYH/1669rVJf9ByEEd5tVioLFcY
EV+QB01EfmT2pq5zKsuLGofVaFtg6v+ir8IQ6Zq6Qmdp4GHX9urTd69QZ2xouN58
8zmvO//upApC4GiGj2FlVlNL5d6qmFyLLWY51q869yTQM509nYyhitJlMVEMCgeM
YhUrknjWF73TOwYSCVaRVJ3KkXYRJn9VgAYy/dJsrkuOlykZvgg4ZJG+4wvISYPX
X1GPCOZVgIaHSkCmwmtvBMLoz5C+kk5fGMjG71S96dJ6qsX9lq96yZF7fcIHG2kM
SLqfSv7QoIVZOiOdIIgLJ8wFo85SA//j5aKxRgMQylrXQ88sW/vpRkb1GIfw4oU=
=dKIq
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160901/fa33bab6/attachment.key>

From Tommy.Craddock at bicgraphic.com  Thu Sep  1 14:30:43 2016
From: Tommy.Craddock at bicgraphic.com (Craddock, Tommy)
Date: Thu, 1 Sep 2016 14:30:43 +0000
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1472739669810-4679304.post@n4.nabble.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
Message-ID: <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>

Hello, 

Create an ACL that will be a list of domains, either in the ACL or in a txt file that the ACL refers to, and place any URLs you want bypassed by the proxy into the ACL.  Something like this:


ACL Section of your squid.conf:

acl bypass_dst_dom  dstdomain "/etc/squid/bypass_dst_domain.txt"


Then in the http_access section:

http_access allow bypass_dst_dom



Thanks!

?
Tommy E CRADDOCK JR

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Thursday, September 01, 2016 10:21 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Web Whatsapp, Dropbox... problem

hi.
Thanks
but, now im using ssl-bump with squid 3.3.8 is there a possibility that work web.whatsapp and drobpox with this version, or at least exclude them from the "proxy"???

Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679304.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com ______________________________________________________________________

______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________

From yvoinov at gmail.com  Thu Sep  1 14:34:18 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 1 Sep 2016 20:34:18 +0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
Message-ID: <98c00258-1c8d-32fa-ddb8-eb24251f165a@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
This will not work in Squid<3.5.

3.4 and below requires dst (IP-based) acl type for no-bump because they
does not contains SNI functionality.


01.09.2016 20:30, Craddock, Tommy ?????:
> Hello, 
>
> Create an ACL that will be a list of domains, either in the ACL or in
a txt file that the ACL refers to, and place any URLs you want bypassed
by the proxy into the ACL.  Something like this:
>
>
> ACL Section of your squid.conf:
>
> acl bypass_dst_dom  dstdomain "/etc/squid/bypass_dst_domain.txt"
>
>
> Then in the http_access section:
>
> http_access allow bypass_dst_dom
>
>
>
> Thanks!
>
> 
> Tommy E CRADDOCK JR
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
On Behalf Of erdosain9
> Sent: Thursday, September 01, 2016 10:21 AM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Web Whatsapp, Dropbox... problem
>
> hi.
> Thanks
> but, now im using ssl-bump with squid 3.3.8 is there a possibility
that work web.whatsapp and drobpox with this version, or at least
exclude them from the "proxy"???
>
> Thanks
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679304.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> ______________________________________________________________________
> This email has been scanned by the Symantec Email Security.cloud service.
> For more information please visit http://www.symanteccloud.com
______________________________________________________________________
>
> ______________________________________________________________________
> This email has been scanned by the Symantec Email Security.cloud service.
> For more information please visit http://www.symanteccloud.com
> ______________________________________________________________________
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXyDxpAAoJENNXIZxhPexG/g4H/jDIqRy/UUjM2QROIsp1hKJb
0GikntJ+9Qb+swzcYxRoSKVJeDfwByLExIw249ntsoGpsl98G7UTs6ShO9TeZS8Z
cCKylcnpeHUIm8PpxLYZZdcxT8pPtDCnBD6g+fXs7B4nwlzMBaZE004xV4eeKVMJ
x3Yu76CE57700rDRX6MYU6lfkyKYoDEJfhsk48BL/aJHAEvjYeDTg22WuYvj4Idp
0bfGQPyGvv8QfF8+aJPlseWmgJV9Edmvsk1uQtPFc9jcNDaqdLuaarqiA66wTexx
8dSyuV2ecPbLegUWn0/kEO32crEJDk8sCPCevBYrgFSNUTwu+maqgK2IDswe4nQ=
=/2Hs
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160901/43dbb7cf/attachment.key>

From rousskov at measurement-factory.com  Thu Sep  1 14:42:25 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 1 Sep 2016 08:42:25 -0600
Subject: [squid-users] Squid 3.5.20 rock store and enable-disk-io
In-Reply-To: <1948576894.789630177.1472716108769.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1948576894.789630177.1472716108769.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <8937277b-6efc-2c0c-e94d-fda7c8c1fed3@measurement-factory.com>

On 09/01/2016 01:48 AM, FredB wrote:
> 
>>
>> [Unit]
>> Description=Squid Web Proxy Server
>> After=network.target
>>
>> [Service]
>> Type=simple
>> ExecStart=/usr/sbin/squid -sYC -N


> Yes this is the default value 
> 
> http://bazaar.launchpad.net/~squid/squid/3.5/view/head:/tools/systemd/squid.service
> 
> I guess this is wrong no ?

First of all, startup scripts is not my area of expertise. AFAICT, the
correct short answer is "Using -N to start production Squid is usually
wrong", but that is misleading because the _default_ systemd script may
have to use -N until Squid itself provides a better alternative that is
easy to use from the default systemd script.

A better answer is probably something like "Do not use the default
systemd script in production" and "Make sure you understand the command
line options you pass to Squid".

Squid startup and daemon mode configuration is a complicated area that
affects SMP, -z, and other features. There may be consensus among
developers on what needs to be done there to improve/fix things, but
nobody is working on that at the moment AFAICT.

Alex.



From squid3 at treenet.co.nz  Thu Sep  1 14:49:50 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 2 Sep 2016 02:49:50 +1200
Subject: [squid-users] TCP_MISS_ABORTED only for one site
In-Reply-To: <57C741A2.9030106@bhz.jamef.com.br>
References: <57C741A2.9030106@bhz.jamef.com.br>
Message-ID: <bd11f8db-b697-6c3d-3a1f-5cdd6af75d9a@treenet.co.nz>

On 1/09/2016 8:44 a.m., Rejaine Monteiro wrote:
> 
> hi,
> 
> we are having trouble accessing (only) that site below.  all other sites
> are accessing normally.
> 
> TCP_MISS_ABORTED/000 0 GET http://www.ipiranga.com.br/ - H
> (the site in question works with direct access to internet - without proxy)
> 
>  discarded problems with cpu, firewall rules, memory, acls, link, etc.
> 
> I set up another squid (in another machine and direct internet access)
> with basic settings and the same problem. Any idea?
> 

The particular details "ABORTED/000 0 " indicate that the client
disconnected 0 milliseconds after the transaction started (ie. the
request message was parsed) and before any response from the server (or
a local HIT) could be determined.


> squid version 3.3.13. my basic squid.conf bellow:
> 

As Yuri said 3.3 is quite old now. It may be a bug in that version that
the site is triggering, or something else. You could try an upgrade to
current version and see if it disappears. If not the more current
version would be better to work with replicating the issue.


> http_access allow localnet
> http_access allow localhost
> http_access deny all
...

> http_access allow localnet
> http_access deny all

These last two lines are redundant (identical lines above).

Other than that your config looks normal and the site works for at least
two of us through Squid. It also passes my usual 'bad proxy' tests for
crashing servers just fine.

Amos



From squid3 at treenet.co.nz  Thu Sep  1 15:05:24 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 2 Sep 2016 03:05:24 +1200
Subject: [squid-users] Transparent Proxy on OSX Yosemite
In-Reply-To: <F25802A5228F1345B9BD8093E210C3B90257C35106@EXWCMS01.fanniemae.com>
References: <F25802A5228F1345B9BD8093E210C3B90257C35106@EXWCMS01.fanniemae.com>
Message-ID: <586bef11-35a9-feec-4741-e541eda38a4f@treenet.co.nz>

On 1/09/2016 5:59 a.m., Shively, Gregory wrote:
>> On 31/08/2016 11:19 a.m., Shively, Gregory wrote:
> 
>>> I'm attempting to get a squid working as a transparent proxy on
>>> OSX
> 
>>> Yosemite. Every attempt ended with a "Forward loop detected". I
> 
>>> initially started with the version from homebrew and moved to
>>> just
> 
>>> compiling myself to see if I could figure out what was going on.
> 
>>> Being new to both pf network and squid, it might be something
>>> that I
> 
>>> have configured wrong. I configured pf similar to:
> 
>>> 
> 
>>> nat on $ext_if proto {udp, tcp} from $int_if:network to any port
>>> domain -> ($ext_if)
> 
>>> rdr pass on $int_if proto tcp from $int_if:network to any port
> 
>>> {http, https} -> 127.0.0.1 port 3129
> 
>>> 
> 
>>> And my squid.conf for my testing is basically:
> 
>>> 
> 
>>> http_port 3128
> 
>>> http_port 3129 intercept
> 
>>> http_access allow all
> 
>>> 
> 
> 
> 
>>> I'm not sure if this is more appropriate on this mailing list or
>>> the
> 
>>> developer mailing list (hoping it is just something I'm doing
>>> wrong).
> 
>>> The squid that I'm using doesn't have -with-nat-devpf enabled;
>>> it
> 
>>> fails to compile with that option. I'm wondering if the
>>> getsockname()
> 
>>> as per comment for PFIntercept (of the !_USE_NAT_DEVPF) in
> 
>>> src/ip/Intercept.cc, on OSX is not returning the pre-rdr address
>>> and
> 
>>> causing the forward loop.
> 
> 
> 
>> Your access.log can show that. It shows up as the server the
>> transaction is being sent to being port 3128/3129 on 127.0.0.1 or
>> another IP assigned to the Squid machine.
> 
> 
> 
> It looks like I get 2 associated TCP_MISS entries in the access.log,

saying what? *exact details* are important for debugging these types of
issue.

> followed by entries that looks like they are associated with the
> access denied error screen. All generate the forwarding loop warning
> when running squid in debug.  I also had the pf logging and see the
> rdr getting redirected, plus had started netcat listening on 3129
> prior to starting squid and saw the HTTP request come in.
> 

The netcat test tells nothing you dont already know. A forwarding loop
by definition is the request arriving into Squid, then going out and
coming right back a second time (thus 2+ access.log entries).

netcat test only shows the first arrival, which is of course normal. It
also does not perform the NAT lookup and de-mangling Squid does - so
wont show if that is part of the problem or not.


>> * check the PF version in your MacOS. If it derives from OpenBSD
>> 4.8 or later then the .dev.pf is not relevant - rdr/divert-to
>> failure is then a bug somewhere AFAIK.
> 
> 
> 
> I tried using both the internal and external interface IP addresses
> on the rdr rule. Both ended in the same forward loop. And it doesn't
> look like, at least Yosemite, has the option to use the divert-to in
> the firewall rules. I can't seem to find the reference, but I think
> that the pf in OSX is based around OpenBSD 4.4 or 4.5, but don't hold
> me to it. I'm guessing that is the reason that the divert-to is not
> available. I can look at an El Capt machine, but don't currently have
> access.
> 
> 
> 
> Thanks for the help on getting this setup. I had put some code in the
> PfInterception method to replace the "local" address that I pulled
> from running the pfctl -s state command and it did change the
> results. But I'm thinking that I might have gotten the host or port
> in the "address" object incorrectly - it didn't seem to work and
> further connections just errored out. When I get a change will take a
> more detailed look and verify I'm getting the addresses in the
> correct form.

Okay. I'm thinking its not misconfiguration then and since it seems to
be a Mac-specific PF based on the old /vdev/pf logic you are going down
the right path.

If you can get it working I will take the patch. Wrap the Mac-specific
new bits in " #if _SQUID_APPLE_ " and the missing header include line
with " #if !_SQUID_APPLE_ ".

Amos


From squid3 at treenet.co.nz  Thu Sep  1 15:26:29 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 2 Sep 2016 03:26:29 +1200
Subject: [squid-users] Squid 3.5.20 rock store and enable-disk-io
In-Reply-To: <8937277b-6efc-2c0c-e94d-fda7c8c1fed3@measurement-factory.com>
References: <1948576894.789630177.1472716108769.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <8937277b-6efc-2c0c-e94d-fda7c8c1fed3@measurement-factory.com>
Message-ID: <65be8023-a5fe-617b-002b-8d12b23a436f@treenet.co.nz>

On 2/09/2016 2:42 a.m., Alex Rousskov wrote:
> On 09/01/2016 01:48 AM, FredB wrote:
>>
>>>
>>> [Unit]
>>> Description=Squid Web Proxy Server
>>> After=network.target
>>>
>>> [Service]
>>> Type=simple
>>> ExecStart=/usr/sbin/squid -sYC -N
> 
> 
>> Yes this is the default value 
>>
>> http://bazaar.launchpad.net/~squid/squid/3.5/view/head:/tools/systemd/squid.service
>>
>> I guess this is wrong no ?
> 
> First of all, startup scripts is not my area of expertise. AFAICT, the
> correct short answer is "Using -N to start production Squid is usually
> wrong", but that is misleading because the _default_ systemd script may
> have to use -N until Squid itself provides a better alternative that is
> easy to use from the default systemd script.

Squid-3 and systemd do not play nicely together, especially in SMP mode.

Why?
 Both systemd and the initial 'squid' Squid-3 process are daemon manager
processes. Running a daemon manager to manage a daemon manager of a
different type results in some very weird 'broken' behaviours. (which
are logicaly consistent and should be expected when you look closely at
what the layers of managers are doing).

Also, systemd makes some (arguably brain-dead) assumptions about
processes it starts. Which are; that its only being used to start a
single-process binary (multi-thread is okay, multi-process like Squid
gets weird even when you take the manager part away), that the PID it
started is a daemon or can be run as one, that the .pid file can be
ignored. For kernel services that probably okay, for Squid-3 (and any
other daemon manager process like it) those assumptions are critically
wrong.

The result is that -N (forcing Squid to be a single daemon/worker
process) is the least problematic way to run Squid-3 under systemd,
Upstart, or OpenRC. It is still a bad way to run Squid, but the
most-working way with those daemon managers.

If you want Squid to run well with systemd you need Squid-4 with its
updated .service file (_dont_ use that .service file with Squid-3 it
will do more damage than good).


> 
> A better answer is probably something like "Do not use the default
> systemd script in production" and "Make sure you understand the command
> line options you pass to Squid".
> 
> Squid startup and daemon mode configuration is a complicated area that
> affects SMP, -z, and other features. There may be consensus among
> developers on what needs to be done there to improve/fix things, but
> nobody is working on that at the moment AFAICT.

AFAIK, most of what is needed has been done for Squid-4 and is too big a
change for Squid-3. The remaining bit is removing need for -z. Which is
optional anyhow and systemd can ignore.

Amos



From gregory_shively at fanniemae.com  Thu Sep  1 17:14:23 2016
From: gregory_shively at fanniemae.com (Shively, Gregory)
Date: Thu, 1 Sep 2016 13:14:23 -0400
Subject: [squid-users] Transparent Proxy on OSX Yosemite
In-Reply-To: <586bef11-35a9-feec-4741-e541eda38a4f@treenet.co.nz>
References: <F25802A5228F1345B9BD8093E210C3B90257C35106@EXWCMS01.fanniemae.com>
 <586bef11-35a9-feec-4741-e541eda38a4f@treenet.co.nz>
Message-ID: <F25802A5228F1345B9BD8093E210C3B90257C35689@EXWCMS01.fanniemae.com>



> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf
> Of Amos Jeffries
> Sent: Thursday, September 1, 2016 11:05 AM
> To: squid-users at lists.squid-cache.org
> Subject: [EXTERNAL] Re: [squid-users] Transparent Proxy on OSX Yosemite
> 
> On 1/09/2016 5:59 a.m., Shively, Gregory wrote:
> >> On 31/08/2016 11:19 a.m., Shively, Gregory wrote:
> >
> >>> I'm attempting to get a squid working as a transparent proxy on OSX
> >
> >>> Yosemite. Every attempt ended with a "Forward loop detected". I
> >
> >>> initially started with the version from homebrew and moved to just
> >
> >>> compiling myself to see if I could figure out what was going on.
> >
> >>> Being new to both pf network and squid, it might be something that I
> >
> >>> have configured wrong. I configured pf similar to:
> >
> >>>
> >
> >>> nat on $ext_if proto {udp, tcp} from $int_if:network to any port
> >>> domain -> ($ext_if)
> >
> >>> rdr pass on $int_if proto tcp from $int_if:network to any port
> >
> >>> {http, https} -> 127.0.0.1 port 3129
> >
> >>>
> >
> >>> And my squid.conf for my testing is basically:
> >
> >>>
> >
> >>> http_port 3128
> >
> >>> http_port 3129 intercept
> >
> >>> http_access allow all
> >
> >>>
> >
> >
> >
> >>> I'm not sure if this is more appropriate on this mailing list or the
> >
> >>> developer mailing list (hoping it is just something I'm doing
> >>> wrong).
> >
> >>> The squid that I'm using doesn't have -with-nat-devpf enabled; it
> >
> >>> fails to compile with that option. I'm wondering if the
> >>> getsockname()
> >
> >>> as per comment for PFIntercept (of the !_USE_NAT_DEVPF) in
> >
> >>> src/ip/Intercept.cc, on OSX is not returning the pre-rdr address and
> >
> >>> causing the forward loop.
> >
> >
> >
> >> Your access.log can show that. It shows up as the server the
> >> transaction is being sent to being port 3128/3129 on 127.0.0.1 or
> >> another IP assigned to the Squid machine.
> >
> >
> >
> > It looks like I get 2 associated TCP_MISS entries in the access.log,
> 
> saying what? *exact details* are important for debugging these types of issue.
> 

I apologize - my Mac where I'm testing was on a different network where I wasn't able to send email and couldn't get access to copy and paste. I now have access to the log entries:

	1472664782.393      0 127.0.0.1 TCP_MISS/403 4417 GET http://google.com/ - HIER_NONE/- text/html
	1472664782.394      6 192.168.100.2 TCP_MISS/403 4487 GET http://google.com/ - ORIGINAL_DST/127.0.0.1 text/html
	1472664782.468      0 192.168.100.2 TCP_MEM_HIT/200 13035 GET http://osx-mdslfd56-u:3128/squid-internal-static/icons/SN.png - HIER_NONE/- image/png
	1472664784.921      0 192.168.100.2 TAG_NONE/400 4401 NONE error:invalid-request - HIER_NONE/- text/html


> > followed by entries that looks like they are associated with the
> > access denied error screen. All generate the forwarding loop warning
> > when running squid in debug.  I also had the pf logging and see the
> > rdr getting redirected, plus had started netcat listening on 3129
> > prior to starting squid and saw the HTTP request come in.
> >
> 
> The netcat test tells nothing you dont already know. A forwarding loop by
> definition is the request arriving into Squid, then going out and coming right back
> a second time (thus 2+ access.log entries).
> 
> netcat test only shows the first arrival, which is of course normal. It also does
> not perform the NAT lookup and de-mangling Squid does - so wont show if that
> is part of the problem or not.
> 
> 

Thanks for the explanation - from observation, that is what I was guessing on how it was working. But hearing it helps.

> >> * check the PF version in your MacOS. If it derives from OpenBSD
> >> 4.8 or later then the .dev.pf is not relevant - rdr/divert-to failure
> >> is then a bug somewhere AFAIK.
> >
> >
> >
> > I tried using both the internal and external interface IP addresses on
> > the rdr rule. Both ended in the same forward loop. And it doesn't look
> > like, at least Yosemite, has the option to use the divert-to in the
> > firewall rules. I can't seem to find the reference, but I think that
> > the pf in OSX is based around OpenBSD 4.4 or 4.5, but don't hold me to
> > it. I'm guessing that is the reason that the divert-to is not
> > available. I can look at an El Capt machine, but don't currently have
> > access.
> >
> >
> >
> > Thanks for the help on getting this setup. I had put some code in the
> > PfInterception method to replace the "local" address that I pulled
> > from running the pfctl -s state command and it did change the results.
> > But I'm thinking that I might have gotten the host or port in the
> > "address" object incorrectly - it didn't seem to work and further
> > connections just errored out. When I get a change will take a more
> > detailed look and verify I'm getting the addresses in the correct
> > form.
> 
> Okay. I'm thinking its not misconfiguration then and since it seems to be a Mac-
> specific PF based on the old /vdev/pf logic you are going down the right path.
> 
> If you can get it working I will take the patch. Wrap the Mac-specific new bits in
> " #if _SQUID_APPLE_ " and the missing header include line with " #if
> !_SQUID_APPLE_ ".
> 

Will do. Thanks again Amos.


> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

From rejaine at bhz.jamef.com.br  Thu Sep  1 18:33:02 2016
From: rejaine at bhz.jamef.com.br (Rejaine Monteiro)
Date: Thu, 01 Sep 2016 15:33:02 -0300
Subject: [squid-users] TCP_MISS_ABORTED only for one site
In-Reply-To: <bd11f8db-b697-6c3d-3a1f-5cdd6af75d9a@treenet.co.nz>
References: <57C741A2.9030106@bhz.jamef.com.br>
 <bd11f8db-b697-6c3d-3a1f-5cdd6af75d9a@treenet.co.nz>
Message-ID: <57C8745E.6060200@bhz.jamef.com.br>

works now...

solved with :

acl postoipiranga dstdomain .ipiranga.com.br
request_header_access Via deny postoipiranga

not the right thing to do, but it was the only solution for now. update 
also was not resolved.


On 01-09-2016 11:49, Amos Jeffries wrote:
> On 1/09/2016 8:44 a.m., Rejaine Monteiro wrote:
>> hi,
>>
>> we are having trouble accessing (only) that site below.  all other sites
>> are accessing normally.
>>
>> TCP_MISS_ABORTED/000 0 GET http://www.ipiranga.com.br/ - H
>> (the site in question works with direct access to internet - without proxy)
>>
>>   discarded problems with cpu, firewall rules, memory, acls, link, etc.
>>
>> I set up another squid (in another machine and direct internet access)
>> with basic settings and the same problem. Any idea?
>>
> The particular details "ABORTED/000 0 " indicate that the client
> disconnected 0 milliseconds after the transaction started (ie. the
> request message was parsed) and before any response from the server (or
> a local HIT) could be determined.
>
>
>> squid version 3.3.13. my basic squid.conf bellow:
>>
> As Yuri said 3.3 is quite old now. It may be a bug in that version that
> the site is triggering, or something else. You could try an upgrade to
> current version and see if it disappears. If not the more current
> version would be better to work with replicating the issue.
>
>
>> http_access allow localnet
>> http_access allow localhost
>> http_access deny all
> ...
>
>> http_access allow localnet
>> http_access deny all
> These last two lines are redundant (identical lines above).
>
> Other than that your config looks normal and the site works for at least
> two of us through Squid. It also passes my usual 'bad proxy' tests for
> crashing servers just fine.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Thu Sep  1 18:36:00 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 1 Sep 2016 21:36:00 +0300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1472735533311-4679299.post@n4.nabble.com>
References: <1472735533311-4679299.post@n4.nabble.com>
Message-ID: <011101d2047f$b01353a0$1039fae0$@ngtech.co.il>

Hey Erdosian,

I have a question regarding the need for squid bypass.
What have you tried until now to resolve the issue?
If you do not care about caching at this stage then you can try to use the next idea and scripts that I wrote:
https://github.com/elico/squid-yt-log-analyzer

If you will add iptables rules in either the nat or the mangle tables like at:
https://github.com/elico/squid-yt-log-analyzer/blob/master/qos-start.sh#L35

but changing the CLASSIFY to ACCEPT and put it in the right table you would be able to bypass squid for the right destinations.
If you need help to tweak the script let me know and I will publish another more suitable version for squid bypassing.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Thursday, September 1, 2016 4:12 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Web Whatsapp, Dropbox... problem

Hi to all.
Im having problem with the 

web.whatssap.com

and with Dropbox client... 

There is a way to exclude this things from the proxy???

Thanks!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Thu Sep  1 18:51:21 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 2 Sep 2016 00:51:21 +0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <011101d2047f$b01353a0$1039fae0$@ngtech.co.il>
References: <1472735533311-4679299.post@n4.nabble.com>
 <011101d2047f$b01353a0$1039fae0$@ngtech.co.il>
Message-ID: <ad36355d-3c60-7488-01d6-b67ad59984d4@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Thank you, Eliezer, I forgot about the solution with IP tables.

When the hand router, everything seems to network :)


02.09.2016 0:36, Eliezer Croitoru ?????:
> Hey Erdosian,
>
> I have a question regarding the need for squid bypass.
> What have you tried until now to resolve the issue?
> If you do not care about caching at this stage then you can try to use
the next idea and scripts that I wrote:
> https://github.com/elico/squid-yt-log-analyzer
>
> If you will add iptables rules in either the nat or the mangle tables
like at:
>
https://github.com/elico/squid-yt-log-analyzer/blob/master/qos-start.sh#L35
>
> but changing the CLASSIFY to ACCEPT and put it in the right table you
would be able to bypass squid for the right destinations.
> If you need help to tweak the script let me know and I will publish
another more suitable version for squid bypassing.
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
On Behalf Of erdosain9
> Sent: Thursday, September 1, 2016 4:12 PM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Web Whatsapp, Dropbox... problem
>
> Hi to all.
> Im having problem with the
>
> web.whatssap.com
>
> and with Dropbox client...
>
> There is a way to exclude this things from the proxy???
>
> Thanks!
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXyHipAAoJENNXIZxhPexGq3wH/1NJHMwqiCGB+U7Iplz0EUUe
ZMN480fVUCTjT4kwKMuLQvkNK6mOV7WCJO1VhY+ehwrPgF5BO0yoZT4LrnlYk+Xy
AfrrmV46sRrsQm9ERx5dJF+TzAG0HtgIqgARhvECRbNi6fQ6UAiduVOXixyOweAn
qhJ9awv5Ii6sJRmWvCkacrU4WR1YTgeKyPN4cIK+sAAoDPeanRp1RVWSwji0h8Sw
VTQl3J35Kc5dZnHZgTuC/5Zr6knLSNG2fl+RudGQiYSwV+nvnntopJXJdUcVJDBu
QoWSI27eKGCav9r3xODG/u74wpvXFA032LNVl15y7W6r19Cr55XldV9c7AyTf3A=
=Az8T
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160902/5f13c806/attachment.key>

From heiler.bemerguy at cinbesa.com.br  Thu Sep  1 19:27:48 2016
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Thu, 1 Sep 2016 16:27:48 -0300
Subject: [squid-users] WARNING: fullDLmime ACL is used in context without an
 HTTP response. Assuming mismatch.
Message-ID: <36503dba-1d30-2e85-1a16-3f6f8909b035@cinbesa.com.br>


Objective: make squid download the whole file when it's an application. 
I'm trying to base the acl on the replied mime type, which I think it's 
more obvious than regexping URLs...

acl limit maxconn 1
acl fullDLmime rep_mime_type application/x-tar application/octet-stream
range_offset_limit -1 fullDLmime !limit

But these warnings keep flooding my cache.log

-- 
Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751



From marcus.kool at urlfilterdb.com  Thu Sep  1 19:53:21 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Thu, 1 Sep 2016 16:53:21 -0300
Subject: [squid-users] Skype+intercept+ssl_bump
In-Reply-To: <972e69a0-2d21-f73a-df32-d547f3c531f3@urlfilterdb.com>
References: <1468579083.987752759@f362.i.mail.ru>
 <8db650ae-f784-2fd4-365f-ac4ae7b59323@treenet.co.nz>
 <578D603C.4050009@measurement-factory.com>
 <579CFE32.4040400@measurement-factory.com>
 <972e69a0-2d21-f73a-df32-d547f3c531f3@urlfilterdb.com>
Message-ID: <fec236ba-b16e-3c79-0956-9bd18f0c465d@urlfilterdb.com>



On 08/27/2016 02:20 PM, Marcus Kool wrote:
>
>
> On 07/30/2016 04:21 PM, Alex Rousskov wrote:
> *snip*
>
>> Update: The question still stands, but we now know more about what
>> happens if the on_unsupported_protocol bug (in code and/or
>> documentation, depending on how you look at it) discussed above is
>> fixed: Squid then starts tunneling traffic as it is told by the
>> on_unsupported_protocol directive, but forgets to use the existing
>> encrypted connection to the server and opens/uses a new Squid-to-server
>> unencrypted connection instead.
>>
>> Thus, the patch I posted previously does not solve the known Skype
>> groups/MSNP problem -- it only exposes the next (and bigger!) obstacle
>> on the way to that solution.
>>
>> We are working on supporting/fixing tunneling of bumped connections, but
>> feedback regarding request counting check question above is still welcomed.

Is there an expected date for a fix?
I volunteer for testing patches.

Marcus

>>
>> Thank you,
>>
>> Alex.
>
> I am using squid-4.0.13-20160819-r14813 and have observed the following
> with transparent intercept:
> 1) skype (on windows10) login fails, access.log contains
>    "CNT error:invalid-request HTTP/1.1" 400 3705 NONE:HIER_NONE -
> 2) whatsapp (on Android) fails, access.log contains
>    "NONE error:transaction-end-before-headers HTTP/0.0" 0 0 NONE:HIER_NONE -
>    "' error:invalid-request HTTP/1.1" 400 3705 NONE:HIER_NONE -
> 3) Samsung (monitoring?) app on my Samsung smartphone:
>    "CONNECT 54.76.6.24:80 HTTP/1.1" 403 3775 TCP_DENIED:HIER_NONE Host:%2054.76.6.24:80%0D%0A
>    "NONE error:invalid-request HTTP/1.1" 400 3705 NONE:HIER_NONE -
>
> TCP_DENIED in 3) is OK since the app connects on port 80 and this port is
> not in SSL_ports, but the error message "invalid-request" on the next line
> is misleading.
>
> If you need a cache.log with debug ALL,9 I can provide one.
>
> The ssl-bump rules on my server are:
> acl tls_s1_connect at_step SslBump1
> acl tls_to_splice complex-acl-but-does-not-matter-what-it-has
> ssl_bump peek   tls_s1_connect
> ssl_bump splice tls_to_splice
> ssl_bump stare  all
> ssl_bump bump   all
>
> With best regards,
>
> Marcus


From rousskov at measurement-factory.com  Thu Sep  1 19:59:51 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 1 Sep 2016 13:59:51 -0600
Subject: [squid-users] Skype+intercept+ssl_bump
In-Reply-To: <fec236ba-b16e-3c79-0956-9bd18f0c465d@urlfilterdb.com>
References: <1468579083.987752759@f362.i.mail.ru>
 <8db650ae-f784-2fd4-365f-ac4ae7b59323@treenet.co.nz>
 <578D603C.4050009@measurement-factory.com>
 <579CFE32.4040400@measurement-factory.com>
 <972e69a0-2d21-f73a-df32-d547f3c531f3@urlfilterdb.com>
 <fec236ba-b16e-3c79-0956-9bd18f0c465d@urlfilterdb.com>
Message-ID: <e5efdc51-328b-cfd3-72ac-5d4f39327d8a@measurement-factory.com>

On 09/01/2016 01:53 PM, Marcus Kool wrote:
>> On 07/30/2016 04:21 PM, Alex Rousskov wrote:
>>> We are working on supporting/fixing tunneling of bumped connections

> Is there an expected date for a fix?

I hesitate publishing private ETAs because priorities often change but
"in a few weeks" does not sound too outrageous to me right now.


> I volunteer for testing patches.

Thank you,

Alex.



From eliezer at ngtech.co.il  Thu Sep  1 20:16:43 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 1 Sep 2016 23:16:43 +0300
Subject: [squid-users] Can Someone with some C experience help me to make
	sure my eyes are seeing right?
Message-ID: <016001d2048d$c1b3eda0$451bc8e0$@ngtech.co.il>

I am trying to figure out how others identify Skype Connections but not sure
about it.
I started looking at the functions at:
https://github.com/ntop/nDPI/blob/d9264e415c1325946c9b638e6455b0126ee9c8ad/s
rc/lib/protocols/skype.c

Since these are pretty like "plaintext" for someone with more experience
then me I am asking for couple spare eyes on the tiny code.

Thanks,
Eliezer

----
Eliezer Croitoru <http://ngtech.co.il/lmgtfy/> 
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il
 


-------------- next part --------------
A non-text attachment was scrubbed...
Name: winmail.dat
Type: application/ms-tnef
Size: 62941 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160901/0d072857/attachment.bin>

From vze2k3sa at verizon.net  Thu Sep  1 23:37:00 2016
From: vze2k3sa at verizon.net (vze2k3sa at verizon.net)
Date: Thu, 01 Sep 2016 19:37:00 -0400
Subject: [squid-users] HTTP 503 Meaning
Message-ID: <002e01d204a9$bcd7f760$3687e620$@verizon.net>

Hi,

 

I'm looking for a little help. The Squid access log line below show an http
503 error. Does this mean that Squid received a 503 from the server it
connecting to or does it mean Squid itself is too busy at the moment to
service the request?

 

01/Sep/2016:17:20:24 -0400  21044 192.168.59.196 TAG_NONE/503 0 CONNECT
www.website.com:443 <http://www.website.com:443>  - HIER_NONE/- -

 

Also, does anyone know of a better more preferred log pattern than the one
shown above? Maybe one that might supply even more details for any/all cases
not just the one above?

 

Thanks so much!

Patrick

 

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160901/7b3f2652/attachment.htm>

From bryan.mabra at gmail.com  Fri Sep  2 01:44:41 2016
From: bryan.mabra at gmail.com (mabraFoo)
Date: Thu, 1 Sep 2016 21:44:41 -0400
Subject: [squid-users] how to redirect certain domains to a specific url?
Message-ID: <CAPSJP+LFe=S+dLYsvbcJ3c4PSbDzw=Ty02mDcokVTP9Xacn-GQ@mail.gmail.com>

I need to redirect 3 https domains to a specific url

redirect all requests for these 3 domains:
https://first.com
https://second.com
https://third.com

To here:
https://specific.com/xyz/index.html

I am using squid 3.5.19.  Standard squid.conf

http://wiki.squid-cache.org/SquidFaq/ConfiguringSquid#Squid-3.5_default_config

http_port 3128

acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines

acl SSL_ports port 443

acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 1025-65535  # unregistered ports

acl CONNECT method CONNECT

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

http_access allow localnet
http_access allow localhost
http_access deny all

coredump_dir /squid/var/cache/squid

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320

thanks for your help!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160901/4a36f7db/attachment.htm>

From marciobacci at gmail.com  Fri Sep  2 03:21:27 2016
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Fri, 2 Sep 2016 00:21:27 -0300
Subject: [squid-users] Problems with Linux Worstations
Message-ID: <CA+0TdyrGBxitJDCOgcULKsdiq5uqzs4UJEm6Ht=_RMRfatZadg@mail.gmail.com>

In my Windows workstations the authentication works correctly, however in
Ubuntu 14.04 the user and password are asked twice.

I am using the basic_ncsa_auth with Squid 3.4.8

Is there any setting that I do in Squid?

Bellow is my squid.conf

### Configuracoes Basicas
http_port 3128

#debug_options ALL,111,2 29,9 84,6

cache_mem 512 MB
cache_swap_low 80
cache_swap_high 90

maximum_object_size 512 MB
minimum_object_size 0 KB

maximum_object_size_in_memory 4096 KB

cache_replacement_policy heap LFUDA
memory_replacement_policy heap LFUDA

#Para n?o bloquear downloads
quick_abort_min -1 KB


#Resolve um problema com conexoes persistentes
detect_broken_pconn on

fqdncache_size 1024

### Parametros de atualizacao da memoria cache
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320

### Localizacao dos logs
access_log /var/log/squid3/access.log
cache_log /var/log/squid3/cache.log

### define a localizacao do cache de disco, tamanho, qtd de diretorios pai
e subdiretorios
cache_dir aufs /var/spool/squid3 600 16 256

auth_param basic program /usr/lib/squid3/basic_ncsa_auth /etc/squid3/passwd
auth_param basic children 5
auth_param basic realm AUTENTICACAO
auth_param basic credentialsttl 2 hours
auth_param basic casesensitive off

visible_hostname proxy.home.com

### acls
#acl manager proto cache_object
acl localhost src 192.168.200.7/32
acl to_localhost dst 192.168.200.7/32
acl SSL_ports port 22 443 563 7071 10000 # ssh, https, snews, zimbra, webmin
acl Safe_ports port 21 # ftp
acl Safe_ports port 70 # gopher
acl Safe_ports port 80 # http
acl Safe_ports port 88 # kerberos
acl Safe_ports port 210 # wais
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 389 # ldap
acl Safe_ports port 443 # https
acl Safe_ports port 488 # gss-http
acl Safe_ports port 563 # snews
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl Safe_ports port 3001            # imprenssa nacional
acl Safe_ports port 8080 # http
acl Safe_ports port 1025-65535 # unregistered ports

acl purge method PURGE
acl CONNECT method CONNECT


### Regras iniciais do Squid
http_access allow localhost
http_access allow purge localhost
http_access deny purge
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports

### Exige autenticacao
acl autenticados proxy_auth REQUIRED
http_access allow autenticados

### Bloqueia extensoes de arquivos
acl extensoes_bloqueadas url_regex -i "/etc/squid3/acls/extensoes-proibidas"

### Liberar alguns sites
acl sites_liberados url_regex -i "/etc/squid3/acls/sites-permitidos"

### Bloqueia sites por URL
acl sites_bloqueados url_regex -i "/etc/squid3/acls/sites-proibidos"

#bloqueios basicos
http_access allow sites_liberados
http_access deny extensoes_bloqueadas
http_access deny sites_bloqueados

### LAN #####
acl rede_lan src 192.168.200.0/22

### Nega acesso de quem nao esta na rede local do CMB
http_access allow rede_lan

#negando o acesso para todos que nao estiverem nas regras anteriores
http_access deny all

### Erros em portugues
error_directory /usr/share/squid3/errors/pt-br

#cache_effective_user proxy
coredump_dir /var/spool/squid3

Regards,

M?rcio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160902/d5f174e7/attachment.htm>

From fredbmail at free.fr  Fri Sep  2 10:13:31 2016
From: fredbmail at free.fr (FredB)
Date: Fri, 2 Sep 2016 12:13:31 +0200 (CEST)
Subject: [squid-users] Squid 3.5.20 rock store and enable-disk-io
In-Reply-To: <1989140072.789143140.1472713687911.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <2009623931.797186191.1472811211157.JavaMail.root@zimbra4-e1.priv.proxad.net>


About this, I should open a bug ? Or you think I missed something ?
Maybe I'm wrong but it seems there is something bad with diskers/rock store

squid without -N + Squid compiled with IpcIo + rock =

> 
> FATAL: Rock cache_dir at /cache1/rock failed to open db file: (2) No
> such file or directory
> Squid Cache (Version 3.5.20): Terminated abnormally.
> CPU Usage: 0.056 seconds = 0.008 user + 0.048 sys
> Maximum Resident Size: 104144 KB
> Page faults with physical i/o: 0
> 2016/09/01 09:01:01 kid2| Store rebuilding is 61.69% complete
> 2016/09/01 09:01:01 kid3| Store rebuilding is 62.03% complete
> 2016/09/01 09:01:01 kid1| Set Current Directory to /home/squid
> 2016/09/01 09:01:01 kid1| Starting Squid Cache version 3.5.20 for
> x86_64-pc-linux-gnu...
> 2016/09/01 09:01:01 kid1| Service Name: squid
> 2016/09/01 09:01:01 kid1| Process ID 7454
> 2016/09/01 09:01:01 kid1| Process Roles: worker
> 2016/09/01 09:01:01 kid1| With 65535 file descriptors available
> 2016/09/01 09:01:01 kid1| Initializing IP Cache...
> 2016/09/01 09:01:01 kid1| DNS Socket created at 0.0.0.0, FD 12
> 2016/09/01 09:01:01 kid1| Adding nameserver 192.168.115.1 from
> /etc/resolv.conf
> 2016/09/01 09:01:01 kid1| Adding nameserver 192.168.115.2 from
> /etc/resolv.conf
> 2016/09/01 09:01:01 kid1| helperOpenServers: Starting 50/150
> 'digest_ldap_auth' processes
> 2016/09/01 09:01:01 kid1| helperOpenServers: Starting 40/150
> 'basic_ldap_auth' processes
> 2016/09/01 09:01:01 kid1| Logfile: opening log
> stdio:/var/log/squid/access.log
> 2016/09/01 09:01:01 kid1| Local cache digest enabled; rebuild/rewrite
> every 3600/3600 sec
> 2016/09/01 09:01:01 kid1| Store logging disabled
> 2016/09/01 09:01:01 kid1| WARNING: disk-cache maximum object size is
> too large for mem-cache: 5242880.00 KB > 5120.00 KB
> 2016/09/01 09:01:01 kid1| Swap maxSize 0 + 16777216 KB, estimated
> 1290555 objects
> 2016/09/01 09:01:01 kid1| Target number of buckets: 64527
> 2016/09/01 09:01:01 kid1| Using 65536 Store buckets
> 2016/09/01 09:01:01 kid1| Max Mem  size: 16777216 KB [shared]
> 2016/09/01 09:01:01 kid1| Max Swap size: 0 KB
> 2016/09/01 09:01:01 kid1| Using Least Load store dir selection
> 2016/09/01 09:01:01 kid1| Set Current Directory to /home/squid
> 2016/09/01 09:01:01 kid1| Finished loading MIME types and icons.
> 2016/09/01 09:01:01 kid1| HTCP Disabled.
> 2016/09/01 09:01:01 kid1| Squid plugin modules loaded: 0
> 2016/09/01 09:01:01 kid1| Adaptation support is on
> 2016/09/01 09:01:01 kid1| commBind: Cannot bind socket FD 20 to [::]:
> (2) No such file or directory
> 2016/09/01 09:01:08 kid1| ERROR: /cache1/rock communication channel
> establishment timeout
> 2016/09/01 09:01:08 kid1| Closing HTTP port 0.0.0.0:8080
> FATAL: Rock cache_dir at /cache1/rock failed to open db file: (2) No
> such file or directory
> Squid Cache (Version 3.5.20): Terminated abnormally.
> CPU Usage: 0.056 seconds = 0.012 user + 0.044 sys
> Maximum Resident Size: 103632 KB
> Page faults with physical i/o: 0
> 2016/09/01 09:01:11 kid1| Set Current Directory to /home/squid
> 2016/09/01 09:01:11 kid1| Starting Squid Cache version 3.5.20 for
> x86_64-pc-linux-gnu...
> 2016/09/01 09:01:11 kid1| Service Name: squid
> 2016/09/01 09:01:11 kid1| Process ID 7550
> 2016/09/01 09:01:11 kid1| Process Roles: worker
> 2016/09/01 09:01:11 kid1| With 65535 file descriptors available
> 2016/09/01 09:01:11 kid1| Initializing IP Cache...
> 2016/09/01 09:01:11 kid1| DNS Socket created at 0.0.0.0, FD 12
> 2016/09/01 09:01:11 kid1| Adding nameserver 192.168.115.1 from
> /etc/resolv.conf
> 2016/09/01 09:01:11 kid1| Adding nameserver 192.168.115.2 from
> /etc/resolv.conf
> 2016/09/01 09:01:11 kid1| helperOpenServers: Starting 50/150
> 'digest_ldap_auth' processes
> 2016/09/01 09:01:11 kid1| helperOpenServers: Starting 40/150
> 'basic_ldap_auth' processes
> 2016/09/01 09:01:11 kid1| Logfile: opening log
> stdio:/var/log/squid/access.log
> 2016/09/01 09:01:11 kid1| Local cache digest enabled; rebuild/rewrite
> every 3600/3600 sec
> 2016/09/01 09:01:11 kid1| Store logging disabled
> 2016/09/01 09:01:11 kid1| WARNING: disk-cache maximum object size is
> too large for mem-cache: 5242880.00 KB > 5120.00 KB
> 2016/09/01 09:01:11 kid1| Swap maxSize 0 + 16777216 KB, estimated
> 1290555 objects
> 2016/09/01 09:01:11 kid1| Target number of buckets: 64527
> 2016/09/01 09:01:11 kid1| Using 65536 Store buckets
> 2016/09/01 09:01:11 kid1| Max Mem  size: 16777216 KB [shared]
> 2016/09/01 09:01:11 kid1| Max Swap size: 0 KB
> 2016/09/01 09:01:11 kid1| Using Least Load store dir selection
> 2016/09/01 09:01:11 kid1| Set Current Directory to /home/squid
> 2016/09/01 09:01:11 kid1| Finished loading MIME types and icons.
> 2016/09/01 09:01:11 kid1| HTCP Disabled.
> 2016/09/01 09:01:11 kid1| Squid plugin modules loaded: 0
> 2016/09/01 09:01:11 kid1| Adaptation support is on
> 2016/09/01 09:01:11 kid1| commBind: Cannot bind socket FD 20 to [::]:
> (2) No such file or directory
> 2016/09/01 09:01:16 kid3| Store rebuilding is 94.96% complete
> 2016/09/01 09:01:16 kid2| Store rebuilding is 94.63% complete
> 2016/09/01 09:01:18 kid3| Finished rebuilding storage from disk.
> 2016/09/01 09:01:18 kid3|   8319999 Entries scanned
> 2016/09/01 09:01:18 kid3|         0 Invalid entries.
> 2016/09/01 09:01:18 kid3|         0 With invalid flags.
> 2016/09/01 09:01:18 kid3|         0 Objects loaded.
> 2016/09/01 09:01:18 kid3|         0 Objects expired.
> 2016/09/01 09:01:18 kid3|         0 Objects cancelled.
> 2016/09/01 09:01:18 kid3|         0 Duplicate URLs purged.
> 2016/09/01 09:01:18 kid3|         0 Swapfile clashes avoided.
> 2016/09/01 09:01:18 kid3|   Took 47.02 seconds (  0.00 objects/sec).
> 2016/09/01 09:01:18 kid3| Beginning Validation Procedure
> 2016/09/01 09:01:18 kid3|   Completed Validation Procedure
> 2016/09/01 09:01:18 kid3|   Validated 0 Entries
> 2016/09/01 09:01:18 kid3|   store_swap_size = 16.00 KB
> 2016/09/01 09:01:18 kid2| Finished rebuilding storage from disk.
> 2016/09/01 09:01:18 kid2|   8319999 Entries scanned
> 2016/09/01 09:01:18 kid2|         0 Invalid entries.
> 2016/09/01 09:01:18 kid2|         0 With invalid flags.
> 2016/09/01 09:01:18 kid2|         0 Objects loaded.
> 2016/09/01 09:01:18 kid2|         0 Objects expired.
> 2016/09/01 09:01:18 kid2|         0 Objects cancelled.
> 2016/09/01 09:01:18 kid2|         0 Duplicate URLs purged.
> 2016/09/01 09:01:18 kid2|         0 Swapfile clashes avoided.
> 2016/09/01 09:01:18 kid2|   Took 47.22 seconds (  0.00 objects/sec).
> 2016/09/01 09:01:18 kid2| Beginning Validation Procedure
> 2016/09/01 09:01:18 kid2|   Completed Validation Procedure
> 2016/09/01 09:01:18 kid2|   Validated 0 Entries
> 2016/09/01 09:01:18 kid2|   store_swap_size = 16.00 KB
> 2016/09/01 09:01:18 kid1| ERROR: /cache1/rock communication channel
> establishment timeout
> 2016/09/01 09:01:18 kid1| Closing HTTP port 0.0.0.0:8080
> FATAL: Rock cache_dir at /cache1/rock failed to open db file: (2) No
> such file or directory
> Squid Cache (Version 3.5.20): Terminated abnormally.
> CPU Usage: 0.064 seconds = 0.020 user + 0.044 sys
> Maximum Resident Size: 103952 KB
> Page faults with physical i/o: 0
> 2016/09/01 09:01:19 kid2| storeLateRelease: released 0 objects
> 2016/09/01 09:01:19 kid3| storeLateRelease: released 0 objects
> 
> If I add -N the problem and restart is gone
> 
> Fred
> 
> > 
> > 
> > HTH,
> > 
> > Alex.
> > 
> > 
> 


From yvoinov at gmail.com  Fri Sep  2 11:53:50 2016
From: yvoinov at gmail.com (Yuri)
Date: Fri, 2 Sep 2016 17:53:50 +0600
Subject: [squid-users] BUG: Unexpected state while connecting to a
 cache_peer or origin server
Message-ID: <a446efbf-ffe9-d016-4aab-042e6f1614f2@gmail.com>

Hi gents,

What does this message means?

3.5.20. WIthout any peers. DIrectly connected to Internet.

What bug? WTF?




From squid3 at treenet.co.nz  Fri Sep  2 13:50:54 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 3 Sep 2016 01:50:54 +1200
Subject: [squid-users] WARNING: fullDLmime ACL is used in context
 without an HTTP response. Assuming mismatch.
In-Reply-To: <36503dba-1d30-2e85-1a16-3f6f8909b035@cinbesa.com.br>
References: <36503dba-1d30-2e85-1a16-3f6f8909b035@cinbesa.com.br>
Message-ID: <7bb744b9-12e3-3383-ca58-4becccf64a4f@treenet.co.nz>

On 2/09/2016 7:27 a.m., Heiler Bemerguy wrote:
> 
> Objective: make squid download the whole file when it's an application.
> I'm trying to base the acl on the replied mime type, which I think it's
> more obvious than regexping URLs...
> 
> acl limit maxconn 1
> acl fullDLmime rep_mime_type application/x-tar application/octet-stream
> range_offset_limit -1 fullDLmime !limit
> 
> But these warnings keep flooding my cache.log
> 

To download the full file Squid has to modify the *request* headers that
gets sent to the server to not ask for a partial download.

When sending a request the future response is unknown. So the ACL cannot
possibly determine what Content-Type header value will be returned in
that future time.

Amos



From squid3 at treenet.co.nz  Fri Sep  2 13:57:36 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 3 Sep 2016 01:57:36 +1200
Subject: [squid-users] HTTP 503 Meaning
In-Reply-To: <002e01d204a9$bcd7f760$3687e620$@verizon.net>
References: <002e01d204a9$bcd7f760$3687e620$@verizon.net>
Message-ID: <f90fabce-6c36-563b-5d0d-03d9fdc14ac9@treenet.co.nz>

On 2/09/2016 11:37 a.m., vze2k3sa wrote:
> Hi,
> 
>  
> 
> I'm looking for a little help. The Squid access log line below show an http
> 503 error. Does this mean that Squid received a 503 from the server it
> connecting to or does it mean Squid itself is too busy at the moment to
> service the request?
> 
>  
> 
> 01/Sep/2016:17:20:24 -0400  21044 192.168.59.196 TAG_NONE/503 0 CONNECT
> www.website.com:443 <http://www.website.com:443>  - HIER_NONE/- -
> 

The HIER_NONE means that no server was involved with that transaction.

So therefore the 503 was generated by the Squid logging that entry.

Given that it waited for 21.044 seconds before generating the failure
response. I interpret that as either DNS lookups taking too long, or TCP
timeouts when sending the initial TCP SYN packets.


> 
> Also, does anyone know of a better more preferred log pattern than the one
> shown above? Maybe one that might supply even more details for any/all cases
> not just the one above?

The Squid native format is better. It gives you millisecond time
resolution for tracking transactions.

Otherwise you need to decide what details you want to record and build a
custom log format. The available options are fairly comprehensive
(though there are some holes depending on your Squid version).

Amos



From squid3 at treenet.co.nz  Fri Sep  2 14:10:17 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 3 Sep 2016 02:10:17 +1200
Subject: [squid-users] Problems with Linux Worstations
In-Reply-To: <CA+0TdyrGBxitJDCOgcULKsdiq5uqzs4UJEm6Ht=_RMRfatZadg@mail.gmail.com>
References: <CA+0TdyrGBxitJDCOgcULKsdiq5uqzs4UJEm6Ht=_RMRfatZadg@mail.gmail.com>
Message-ID: <524b90be-8363-f906-1b18-d9481d8c63b3@treenet.co.nz>

On 2/09/2016 3:21 p.m., Marcio Demetrio Bacci wrote:
> In my Windows workstations the authentication works correctly, however in
> Ubuntu 14.04 the user and password are asked twice.
> 
> I am using the basic_ncsa_auth with Squid 3.4.8
> 
> Is there any setting that I do in Squid?
> 
> Bellow is my squid.conf
> 
...
> 
> auth_param basic program /usr/lib/squid3/basic_ncsa_auth /etc/squid3/passwd
> auth_param basic children 5
> auth_param basic realm AUTENTICACAO
> auth_param basic credentialsttl 2 hours
> auth_param basic casesensitive off
> 
...
> 
> ### Regras iniciais do Squid
> http_access allow localhost
> http_access allow purge localhost
> http_access deny purge
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports

Please re-order the above security rules to be:

  http_access deny !Safe_ports
  http_access deny CONNECT !SSL_ports
  http_access allow localhost
  http_access deny purge

> 
> ### Exige autenticacao
> acl autenticados proxy_auth REQUIRED
> http_access allow autenticados
> 
> ### Bloqueia extensoes de arquivos
> acl extensoes_bloqueadas url_regex -i "/etc/squid3/acls/extensoes-proibidas"
> 
> ### Liberar alguns sites
> acl sites_liberados url_regex -i "/etc/squid3/acls/sites-permitidos"
> 
> ### Bloqueia sites por URL
> acl sites_bloqueados url_regex -i "/etc/squid3/acls/sites-proibidos"
> 
> #bloqueios basicos
> http_access allow sites_liberados
> http_access deny extensoes_bloqueadas
> http_access deny sites_bloqueados
> 
> ### LAN #####
> acl rede_lan src 192.168.200.0/22
> 
> ### Nega acesso de quem nao esta na rede local do CMB
> http_access allow rede_lan
> 
> #negando o acesso para todos que nao estiverem nas regras anteriores
> http_access deny all
>
...


With your config Squid will only challenge the browser to send some if
they are completely missing. It will not deny access when invalid
credentials are sent.

That means the browser probably does not have access to any Basic auth
credentials it can send.

The two popups are probably from two TCP connections being made with no
credentials (maybe the result of the "Happy Eyeballs" algorithm doing
its thing). You can check for that with "debug_options 11,2" and seeing
what HTTP messages are happening with what IP:port details.

Amos



From rousskov at measurement-factory.com  Fri Sep  2 14:15:32 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 2 Sep 2016 08:15:32 -0600
Subject: [squid-users] BUG: Unexpected state while connecting to a
 cache_peer or origin server
In-Reply-To: <a446efbf-ffe9-d016-4aab-042e6f1614f2@gmail.com>
References: <a446efbf-ffe9-d016-4aab-042e6f1614f2@gmail.com>
Message-ID: <3c27984f-b5f5-6eb9-dbac-27958e769a92@measurement-factory.com>

On 09/02/2016 05:53 AM, Yuri wrote:

> What does this message means?

It means there is a bug in your Squid. Squid code discovered an
internally-inconsistent or unexpected state. The developer was not sure
that this state is impossible to reach and, instead of asserting and
crashing Squid worker, he decided that warning the admin about the bug
and trying to salvage the situation would be better. Whether that
salvaging actually worked, I do not know.

If you want this bug fixed and can reproduce it, then I recommend filing
a bug report with an ALL,9 cache.log leading to the BUG message:

http://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction


> 3.5.20. WIthout any peers. DIrectly connected to Internet.

Yes, this bug does not require a cache_peer.


HTH,

Alex.



From drcimino at mail.com  Fri Sep  2 15:06:18 2016
From: drcimino at mail.com (akn ab)
Date: Fri, 2 Sep 2016 17:06:18 +0200
Subject: [squid-users] Debugging NTLM problem
Message-ID: <trinity-93183f7b-d152-4318-a594-dbd52b624208-1472828777733@3capp-mailcom-lxa03>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160902/4e68beed/attachment.htm>

From rousskov at measurement-factory.com  Fri Sep  2 16:50:50 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 2 Sep 2016 10:50:50 -0600
Subject: [squid-users] Squid 3.5.20 rock store and enable-disk-io
In-Reply-To: <2009623931.797186191.1472811211157.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <2009623931.797186191.1472811211157.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <c999f493-11a5-0e1d-3dbb-a28713e4f9de@measurement-factory.com>

On 09/02/2016 04:13 AM, FredB wrote:

> About this, I should open a bug ? Or you think I missed something ?

Not sure what you mean by "this". I assume you mean the errors that you
quoted later in your email.


>> 2016/09/01 09:01:01 kid1| commBind: Cannot bind socket FD 20 to [::]:
>> (2) No such file or directory

This is probably the same environment problem as the one described at

http://wiki.squid-cache.org/Features/SmpScale#Cannot_bind_socket_FD_NN_to_.5B::.5D:_.2813.29_Permission_denied

You error is "No such file or directory" but that may not matter much.
If I am right, then you need to fix this problem before you can use SMP
features, including rock caches.


>> 2016/09/01 09:01:08 kid1| ERROR: /cache1/rock communication channel establishment timeout

This is probably a side effect of the socket failure reported above.


>> 2016/09/01 09:01:08 kid1| Closing HTTP port 0.0.0.0:8080
>> FATAL: Rock cache_dir at /cache1/rock failed to open db file: (2) No such file or directory

And this is probably a side effect of the timeout reported above.


Alex.



From fredbmail at free.fr  Fri Sep  2 20:00:59 2016
From: fredbmail at free.fr (FredB)
Date: Fri, 2 Sep 2016 22:00:59 +0200 (CEST)
Subject: [squid-users] Squid 3.5.20 rock store and enable-disk-io
In-Reply-To: <c999f493-11a5-0e1d-3dbb-a28713e4f9de@measurement-factory.com>
Message-ID: <2056323530.799357071.1472846459621.JavaMail.root@zimbra4-e1.priv.proxad.net>



I will take a look,thanks
But there is no smp configuration, just rock and squid with two caches


From rousskov at measurement-factory.com  Fri Sep  2 20:18:51 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 2 Sep 2016 14:18:51 -0600
Subject: [squid-users] Squid 3.5.20 rock store and enable-disk-io
In-Reply-To: <2056323530.799357071.1472846459621.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <2056323530.799357071.1472846459621.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <269cc967-bd15-8ae7-c68e-87897159e3c5@measurement-factory.com>

On 09/02/2016 02:00 PM, FredB wrote:
> But there is no smp configuration, just rock and squid with two caches

That's SMP mode. See the last bullet at
http://wiki.squid-cache.org/Features/SmpScale#Terminology

Alex.



From squid3 at treenet.co.nz  Sat Sep  3 02:43:36 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 3 Sep 2016 14:43:36 +1200
Subject: [squid-users] Debugging NTLM problem
In-Reply-To: <trinity-93183f7b-d152-4318-a594-dbd52b624208-1472828777733@3capp-mailcom-lxa03>
References: <trinity-93183f7b-d152-4318-a594-dbd52b624208-1472828777733@3capp-mailcom-lxa03>
Message-ID: <ae9856e6-9945-0285-250f-cd81e0f4cbf6@treenet.co.nz>

On 3/09/2016 3:06 a.m., akn ab wrote:
> Hello Amos,
> auth_param ntlm keep_alive off
> unfortunately does not solve the problem.
> I did more investigation about the problem and i found informations.
> Every time a user get the browser popup requesting credentials, i found on squid 
> log this event:
> Login for user [DOMAIN]\[user]@[PC_XXXX] failed due to [Access denied]
> NTLMSSP BH: NT_STATUS_ACCESS_DENIED
> 2016/09/02 16:56:13 kid1| ERROR: NTLM Authentication validating user. Result: 
> {result=BH, notes={message: NT_STATUS_ACCESS_DENIED; }}

That is ntlm_auth (on behalf of AD) telling Squid the user credentials
are not correct. There is no NTLM protocol problem.

Consider this NT_STATUS_ACCESS_DENIED as if a user entered the wrong
password. Why do you want to allow them access in that case?


> It's not easy to do more debug because i have 9000 concurrent connections, but 
> if you think that can help me, i try to set debug_option to something like 29,5
> Sometimes users left the office letting the browser open.
> After 1 hour (more or less), they return to the pc and popup show as soos as 
> mouse point to a new link on the open browser.
> It's probably because something cached expire, but i cannot demostrate it so 
> easily beceuse, as you said, ntlm never cache.
> On my samba/winbind logs i see many
> rpccli_netlogon_sam_network_logon: credentials chain check failed
> So it's very strange to understand if some problem occur beetween squid and 
> browser or samba and Active Directory.
> What do you think about?
> Thanks.
> Giulius.
> 
> On 1/09/2016 12:37 a.m., akn ab wrote:
>  > Dear all,
>  > i'm facing a strange problem using squid 3.5.20 with ntlm transparent
>  > authentication.
>  > I cannot use kerberos auth because i need to pass DOMAIN\user to my parent proxy
>  > with x-authenticated-user header, and the form USERNAME at DOMAIN is not supported.

I suggest you use an external_acl_type helper that takes the %LOGIN
format parameter and sends 'OK upstream_user_="..." ' back to Squid. Use
the %note{upstream_user_} in your request_header_add directive to send
the right header value upstream.

That will allow you to at least keep your part of the proxy chain using
secure Negotiate authentication even though the parent proxy allows
anyone to inject traffic spoofing your user accounts.

Amos



From squid3 at treenet.co.nz  Sat Sep  3 02:57:53 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 3 Sep 2016 14:57:53 +1200
Subject: [squid-users] how to redirect certain domains to a specific url?
In-Reply-To: <CAPSJP+LFe=S+dLYsvbcJ3c4PSbDzw=Ty02mDcokVTP9Xacn-GQ@mail.gmail.com>
References: <CAPSJP+LFe=S+dLYsvbcJ3c4PSbDzw=Ty02mDcokVTP9Xacn-GQ@mail.gmail.com>
Message-ID: <18965197-39d8-133d-c861-9ceab848abc7@treenet.co.nz>

On 2/09/2016 1:44 p.m., mabraFoo wrote:
> I need to redirect 3 https domains to a specific url
> 
> redirect all requests for these 3 domains:
> https://first.com

Registrant Organization: Sitestar Internet Services

> https://second.com

Registrant Organization: REFLEX PUBLISHING, INC.

> https://third.com

Registrant Organization: Third Dimension

> 
> To here:
> https://specific.com/xyz/index.html
> 

Registrant Organization: Specific Media, Inc.


The 'S' in HTTPS means secure and exists for a reason. It means there
are TLS requirements that have to be obeyed which HTTP does not require.

Unless the origin server you are redirecting the CONNECT tunnel to is
able to produce a valid TLS/SSL certificate for those domain names that
can be authenticated successfully you won't be able to do it.

If it does produce the right TLS details then:

 acl 3d dstdomain first.com second.com third.com
 cache_peer specific.com parent 443 0 originserver
 cache_peer_access specific.com allow CONNECT 3d
 cache_peer_access specific.com deny all
 never_direct allow CONNECT 3d

Amos



From ahmed.zaeem at netstream.ps  Sat Sep  3 09:18:58 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Sat, 3 Sep 2016 12:18:58 +0300
Subject: [squid-users] proxy authorization header remover from 3.5.x squid
Message-ID: <965C1E8E-0F8A-4EBE-86CD-B5F6D2539409@netstream.ps>

hi squid users ,
 I?m looking for the directive that will remove 
proxy authorization header 

when i analyze my proxy which has usr/pwd using basic_ncsa auth 

it still show that header 

not sure  the directive to remove that header .

?


thanks

From omidkosari at yahoo.com  Sat Sep  3 09:58:43 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Sat, 3 Sep 2016 02:58:43 -0700 (PDT)
Subject: [squid-users] reply_header_access Server deny (IF Server==squid)
Message-ID: <1472896723526-4679338.post@n4.nabble.com>

Hello,

I want to hide squid's OWN reply header . I have tested following config

acl squid_server rep_header Server squid
reply_header_access Server deny squid_server
reply_header_replace Server Foo/1.0

But got the error "ACL is used in context without an HTTP response. Assuming
mismatch."

The only thing that works is following but it hide all Server headers . I
just want to remove if it is from squid's own .

reply_header_access Server deny all


HTTP/1.1 400 Bad Request
===========
Server: squid
===========
Mime-Version: 1.0
Date: Sun, 28 Aug 2016 09:00:12 GMT
Content-Type: text/html;charset=utf-8
Content-Length: 0
X-Cache: MISS from cache1
X-Cache-Lookup: NONE from cache1:3128
Connection: close



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/reply-header-access-Server-deny-IF-Server-squid-tp4679338.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Sat Sep  3 13:53:28 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 4 Sep 2016 01:53:28 +1200
Subject: [squid-users] proxy authorization header remover from 3.5.x
	squid
In-Reply-To: <965C1E8E-0F8A-4EBE-86CD-B5F6D2539409@netstream.ps>
References: <965C1E8E-0F8A-4EBE-86CD-B5F6D2539409@netstream.ps>
Message-ID: <f86a9e56-a63e-c4be-6644-da7efedc8486@treenet.co.nz>

On 3/09/2016 9:18 p.m., --Ahmad-- wrote:
> hi squid users ,
>  I?m looking for the directive that will remove 
> proxy authorization header 
> 
> when i analyze my proxy which has usr/pwd using basic_ncsa auth 
> 
> it still show that header 
> 
> not sure  the directive to remove that header .
> 
> ?

I don't understand why authentication happening would be a problem after
you configured it to happen.

Can you describe the problem in a bit more detail please?

Amos



From squid3 at treenet.co.nz  Sat Sep  3 13:57:17 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 4 Sep 2016 01:57:17 +1200
Subject: [squid-users] reply_header_access Server deny (IF Server==squid)
In-Reply-To: <1472896723526-4679338.post@n4.nabble.com>
References: <1472896723526-4679338.post@n4.nabble.com>
Message-ID: <15d66d9d-22a7-7560-c45f-42173bcf84c9@treenet.co.nz>

On 3/09/2016 9:58 p.m., Omid Kosari wrote:
> Hello,
> 
> I want to hide squid's OWN reply header .

Why?

Amos



From omidkosari at yahoo.com  Sun Sep  4 07:40:35 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Sun, 4 Sep 2016 00:40:35 -0700 (PDT)
Subject: [squid-users] reply_header_access Server deny (IF Server==squid)
In-Reply-To: <15d66d9d-22a7-7560-c45f-42173bcf84c9@treenet.co.nz>
References: <1472896723526-4679338.post@n4.nabble.com>
 <15d66d9d-22a7-7560-c45f-42173bcf84c9@treenet.co.nz>
Message-ID: <1472974835645-4679341.post@n4.nabble.com>

Because squid should be really transparent tproxy . I want to remove its
footprints.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/reply-header-access-Server-deny-IF-Server-squid-tp4679338p4679341.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From wes_whitt at yahoo.com  Sun Sep  4 14:40:09 2016
From: wes_whitt at yahoo.com (Wesley Whitteker)
Date: Sun, 4 Sep 2016 14:40:09 +0000 (UTC)
Subject: [squid-users] Copy and send decrypted HTTPS traffic to specific
	location
References: <620103417.1303756.1473000009143.ref@mail.yahoo.com>
Message-ID: <620103417.1303756.1473000009143@mail.yahoo.com>

Hello Folks,
I've been doing some testing with Squid and am currently using it to decrypt HTTPS flows (i.e. MITM Proxy).? I also have the C-ICAP feature working. 

Now, I'm trying to determine if Squid has the capabilities to send a copy of decrypted HTTPS traffic out a particular port on the HW platform I'm running squid on -- any ideas if this has/can be done?
Thanks!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160904/6ef57e74/attachment.htm>

From squid3 at treenet.co.nz  Sun Sep  4 15:08:53 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 5 Sep 2016 03:08:53 +1200
Subject: [squid-users] reply_header_access Server deny (IF Server==squid)
In-Reply-To: <1472974835645-4679341.post@n4.nabble.com>
References: <1472896723526-4679338.post@n4.nabble.com>
 <15d66d9d-22a7-7560-c45f-42173bcf84c9@treenet.co.nz>
 <1472974835645-4679341.post@n4.nabble.com>
Message-ID: <aa1588f2-fe84-afed-aa30-7d390e3e5e05@treenet.co.nz>

On 4/09/2016 7:40 p.m., Omid Kosari wrote:
> Because squid should be really transparent tproxy . I want to remove its
> footprints.
> 

"transparent" != "invisible".

"Transparent" in HTTP terms means the proxy *is* visible, and relaying
messages, but without transforming them. Making the source agent of each
message clear is part of that type of transparency.

Wen it comes to proxy/Squid generated messages the entire request and
response is footprint. To "hide the footprints" you need to prevent the
entire message being delivered. That is done with "deny_info TCP_RESET ..."

Amos



From squid3 at treenet.co.nz  Sun Sep  4 15:10:49 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 5 Sep 2016 03:10:49 +1200
Subject: [squid-users] Copy and send decrypted HTTPS traffic to specific
 location
In-Reply-To: <620103417.1303756.1473000009143@mail.yahoo.com>
References: <620103417.1303756.1473000009143.ref@mail.yahoo.com>
 <620103417.1303756.1473000009143@mail.yahoo.com>
Message-ID: <4acbf7b1-8a23-c530-651b-cbe12ba9dd7c@treenet.co.nz>

On 5/09/2016 2:40 a.m., Wesley Whitteker wrote:
> Hello Folks, I've been doing some testing with Squid and am currently
> using it to decrypt HTTPS flows (i.e. MITM Proxy).  I also have the
> C-ICAP feature working.
> 
> Now, I'm trying to determine if Squid has the capabilities to send a
> copy of decrypted HTTPS traffic out a particular port on the HW
> platform I'm running squid on -- any ideas if this has/can be done? 

No it does not. To do that you should use an ICAP service designed to do
unnatural things to the messages it gets delivered.

Amos


From squid3 at treenet.co.nz  Sun Sep  4 15:41:32 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 5 Sep 2016 03:41:32 +1200
Subject: [squid-users] proxy authorization header remover from 3.5.x
	squid
In-Reply-To: <C3C31A3A-AF91-4069-893D-F7931179B776@gmail.com>
References: <965C1E8E-0F8A-4EBE-86CD-B5F6D2539409@netstream.ps>
 <f86a9e56-a63e-c4be-6644-da7efedc8486@treenet.co.nz>
 <C3C31A3A-AF91-4069-893D-F7931179B776@gmail.com>
Message-ID: <c15f7d2f-1a21-d09e-7fae-599ad77d5742@treenet.co.nz>

On 5/09/2016 3:31 a.m., Ahmed Alzaeem wrote:
> hi amos I?m curious to have my proxies not being detected from others .
> 

Then you choose to make your clients and network internal structore
entirely visible to the upstream servers.

You can hide your network structure and clients, or you can hide the
proxy. Not both.


> thats all .
> 
> i already tried the header access directive 
> request_header_access Proxy-Connection deny  all
> request_header_access Proxy-Authorization deny all
> request_header_access Proxy-Authenticate deny  all
> 
> 
> but i still see the header 
> 

Er. Those are hop-by-hop headers.

* Proxy-Connection is an experimental header that has not had any
meaningful use since Netscape Navigator 4.x died out.

* Squid removes the Auth related headers on upstream connections unless
you configure Squid to authenticate against the upstream server or proxy
the message is going to. see RFC 7235 for details on that.

* requests on the client->Squid connection are not under your control.
They are generated by the client.


Also, you said "my proxy which has usr/pwd using basic_ncsa auth".
That means you have proxy authentication configured to happen. A forward
proxy can only do HTTP authentication with the use of Proxy-Auth* headers.

Amos


> 
> thank you 
> 
>> On Sep 3, 2016, at 4:53 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>
>> On 3/09/2016 9:18 p.m., --Ahmad-- wrote:
>>> hi squid users ,
>>> I?m looking for the directive that will remove 
>>> proxy authorization header 
>>>
>>> when i analyze my proxy which has usr/pwd using basic_ncsa auth 
>>>
>>> it still show that header 
>>>
>>> not sure  the directive to remove that header .
>>>
>>> ?
>>
>> I don't understand why authentication happening would be a problem after
>> you configured it to happen.
>>
>> Can you describe the problem in a bit more detail please?
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 



From squid3 at treenet.co.nz  Sun Sep  4 15:54:21 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 5 Sep 2016 03:54:21 +1200
Subject: [squid-users] Acl to deny all sites, and allow some sites
In-Reply-To: <1472608547291-4679275.post@n4.nabble.com>
References: <1472608547291-4679275.post@n4.nabble.com>
Message-ID: <14487fb5-d9b9-302d-7e44-54fdb1ff3797@treenet.co.nz>

On 31/08/2016 1:55 p.m., hibandx wrote:
> So, i have an squid configured and ok with ad 2012, but the acl
> Proxy_restrito is not working...
> 
> This acl is for 
> 
> any solution?

What version of Squid are you using?
 the "squid -v" command will show that detail.

> 
> This is my conf is for deny all sites, and allow just some sites on file
> proxy_restrito_whitelist...
> 

Your http_access rules allow a lot of things to go through the proxy
before proxy_restrito_whitelist is every considered as a limitation.

After those allows there is no rule allowing access to clients that do
get past the rule involving proxy_restrito_whitelistd.


> follow:
> 
> #Porta padr?o do proxy
> http_port 3128
>  
> #Endereco de E-mail do administrador do proxy
> cache_mgr suporte at dominio.local
>  

>From here ...

> #Nao faz cache de dados de formularios html,em de resultados de programas
> cgi                      
> #hierarchy_stoplist cgi-bin ?
>  
> #Cria uma access control list, baseando-se na url e utilizando exp.
> regulares nesta situacao   
> #foi criado uma exp. regular para cgi e ?.        
> acl QUERY urlpath_regex cgi-bin \?
>  
> #Nao faz cache da acl QUERY                        
> cache deny QUERY

.. to here can be removed completely.

Your config contains the refresh_pattern necessary to handle dynamic
content properly.

<snip a lot of directives mostly set to default values>
If you have a Squid-3.1 or later you can remove any config options which
are set to the default values. That will help clarify the non-normal
things your Squid is doing.



> #Maquinas que nao precisaram de autenticacao   
> acl liberados dstdomain "/etc/squid/regras/liberados"
> http_access allow liberados
>  
> #liberar o acesso ao site da caixa que est? com problemas 
> #acl caixa dstdomain caixa.gov.br
> #always_direct allow caixa
> #cache deny caixa
>  
> #MACS que est?o liberados.
> acl macliberado   arp "/etc/squid/regras/mac_liberado"
> http_access allow macliberado
>  

Please place custom http_access rules down ....

>  
> ### ACL Padroes
> acl SSL_ports port 443 # https
> acl SSL_ports port 563 # snews
> acl SSL_ports port 873 # rsync
> acl Safe_ports port 80 # http
> acl Safe_ports port 21 # ftp
> acl Safe_ports port 443 563 # https, snews
> acl Safe_ports port 70 # gopher
> acl Safe_ports port 210 # wais
> acl Safe_ports port 1025-65535 # unregistered ports
> acl Safe_ports port 280 # http-mgmt
> acl Safe_ports port 488 # gss-http
> acl Safe_ports port 591 # filemaker
> acl Safe_ports port 777 # multiling http
> acl Safe_ports port 631 # cups
> acl Safe_ports port 873 # rsync
> acl Safe_ports port 901 # SWAT
> acl Safe_ports port 1080
> acl Safe_ports port 1863
> acl Safe_ports port 8443 # https
> acl Safe_ports port 5222 # gTalk
> acl Safe_ports port 5223 # gTalk
> acl Safe_ports port 47057 # torrent
> 
> acl purge method PURGE
> acl CONNECT method CONNECT
> 
> http_access allow manager localhost
> http_access deny manager
> http_access allow purge localhost
> http_access deny purge
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> 

... here after the security default http_access rules.

> #Limita conexeos HTTP
> #acl connect_abertas maxconn 8
> 
> #sites que n?o ser?o feito cache geralmente bancos
> acl NOCACHE dstdomain "/etc/squid/regras/direto" \?
> no_cache deny NOCACHE

Remove the "no_" part from the above line.


>  
> #### Autenticao no Windows 2008/2012/Samba 4 via WINBIND
> auth_param ntlm program /usr/bin/ntlm_auth
> --helper-protocol=squid-2.5-ntlmssp
> auth_param ntlm children 30
> auth_param basic program /usr/bin/ntlm_auth
> --helper-protocol=squid-2.5-basic
> auth_param basic children 5
> auth_param basic realm Squid proxy server
> auth_param basic credentialsttl 2 hours
> #Note que abaixo o meu sistema ? 64 ent?o as minhas libs est?o em /usr/lib64
> caso esteja utilizando sistema 32 troque para /usr/lib
> external_acl_type ad_group ttl=1800 children=200 %LOGIN
> /usr/lib64/squid/ext_wbinfo_group_acl
> 
> #-----------------------------------------------------------------------------------#
> #       Nome ACL                TIPO                    Nome Grupo AD              
> #
> #-----------------------------------------------------------------------------------#
> 
> acl    proxy_livre        external ad_group          proxy_livre
> acl    proxy_geral           external ad_group          proxy_geral
> acl    proxy_restrito      external ad_group         proxy_restrito
> 
> 
> # Whitelists / Blacklists
> acl downloads         urlpath_regex -i "/etc/squid/regras/downloads"
> acl proxy_restrito_whitelist url_regex -i
> "/etc/squid/regras/proxy_restrito_whitelist"
> acl proxy_geral_bracklist   url_regex  -i
> "/etc/squid/regras/proxy_geral_blacklist"
> acl proxy_livre_proibidos	url_regex	 -i
> "/etc/squid/regras/proxy_livre_proibidos"
> 
> #Bloquear determinados usu?rios autenticados
> acl usuarios_bloqueados proxy_auth "/etc/squid/regras/usuarios_bloqueados"
>  
> #Controle de acesso por hor?rio aqui, vamos liberar o acesso no hor?rio do
> almo?o
> #aqui os usu?rio v?o poder acessar alguns sites diferenciados entre as 12:00
> at? as 13:00
> #acl almoco time MTWHFAS 12:30-13:30
> 
> #Agora vamos criar uma regra para garantir que os usu?rios que v?o acessar
> no almo?o est?o autenticados
> acl autenticados proxy_auth REQUIRED
> 
> #Agora vamos criar uma lista de sites que eles v?o poder acessar no hor?rio
> do almo?o
> acl sites-almoco   url_regex     -i "/etc/squid/regras/sites_almoco"
> 
> # Permissoes de Acesso
> http_access allow proxy_livre !proxy_livre_proibidos
> http_access deny  downloads
> http_access deny  usu_bloqueados
> http_access allow proxy_geral !proxy_geral_bracklist
> http_access deny proxy_restrito 	!proxy_restrito_whitelist

Any "http_access deny" rule folowed by "http_access deny all" is almost
guaraneed to be useless waste of CPU and config file text.

> ############################################################
> http_access deny all
> http_reply_access allow all
> icp_access allow all
> miss_access allow all
> visible_hostname proxy
> error_directory /usr/share/squid/errors/pt-br
> #cache_effective_group squid
> cache_effective_user squid
> coredump_dir /var/spool/squid
> 

Amos



From squid3 at treenet.co.nz  Sun Sep  4 16:12:21 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 5 Sep 2016 04:12:21 +1200
Subject: [squid-users] More host header forgery pain with peek/splice
In-Reply-To: <0aebb8f5-e2fe-71ea-5477-d299acd9ccf9@urlfilterdb.com>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <1472150075016-4679181.post@n4.nabble.com>
 <477b5e2b-6eb4-54bc-240f-af416f53612c@treenet.co.nz>
 <0aebb8f5-e2fe-71ea-5477-d299acd9ccf9@urlfilterdb.com>
Message-ID: <b1fde5e0-7725-7264-4039-17f34cf7e6fb@treenet.co.nz>

On 31/08/2016 5:25 a.m., Marcus Kool wrote:
> Do I understand it correctly that Squid in normal proxy mode
> allows malware to do a CONNECT to any destination, while in
> transparent proxy mode does extra security checks which causes
> some regular (non-malware) clients to fail?


Intercepted traffic has different processing applied, different
assumptions made about the traffic, and different security model
relevant to its messages.

The short answer is "yes", but reality is not that simple black/white.


> 
> And philosophical questions: is Squid the right tool
> to stop malware?  If yes, is it acceptable that connections
> of regular (non-malware) clients are wrongly dropped?

No more or less than any software.

Squid manages the HTTP that flows through it. If the malware uses HTTP
messages to communicate then it very much part of Squid's job to prevent
that. Other protocols Squid is not responsible for, except to prevent
itself being a vector of attack.

> 
> IMO Squid should do all it can to be a secure proxy.

Which is the case for Host forgery atacks. If Squid did not MITM the
network traffic, there would not be a vulnerability to Host forgery
issues. Therefore an intercept/tproxy Squid is very much responsible for
preventing this particular type of attack which it causes to exist.

A forward-proxy or reverse-proxy does not have that vulnerability,
therefore does not need to check the same things.


> Doing security checks on connections in an attempt
> to stop malware sounds like a job for an antivirus / IDS tool.
> 

Additional to what Squid does. Indeed many of those tools use a proxy
service which performs the same or similar checks to what Squid does,
with far more intrusive behaviour, or are themselves also vulnerable to
becoming vectors of the Host attack(s). The Host attack(s) are
vulnerability built into the concept of MITM'ing HTTP(S) traffic. It is
not something specific to Squid.

Amos



From marciobacci at gmail.com  Sun Sep  4 22:41:59 2016
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Sun, 4 Sep 2016 19:41:59 -0300
Subject: [squid-users] Problems with Linux Worstations
In-Reply-To: <524b90be-8363-f906-1b18-d9481d8c63b3@treenet.co.nz>
References: <CA+0TdyrGBxitJDCOgcULKsdiq5uqzs4UJEm6Ht=_RMRfatZadg@mail.gmail.com>
 <524b90be-8363-f906-1b18-d9481d8c63b3@treenet.co.nz>
Message-ID: <CA+0Tdyoer7WW0Sfvy_5z5T3JQ3j_hw1Yf=mDLFtF2gJZmyMfew@mail.gmail.com>

I have used debug_options 11,2 in squid.conf file. After I have following
results in logs files:

/var/log/squid3/access.log
1473026084.048    253 192.168.200.85 TCP_MISS_ABORTED/000 0 POST
http://m.addthis.com/live/red_lojson/100eng.json? marcio HIER_NONE/- -
1473026086.275      0 192.168.200.85 TCP_DENIED/407 3792 CONNECT
tiles.services.mozilla.com:443 - HIER_NONE/- text/html
1473026086.778      0 192.168.200.85 TCP_DENIED/407 3995 GET
http://start.ubuntu.com/14.04/Google/? - HIER_NONE/- text/html
1473026088.908      0 192.168.200.85 TCP_DENIED/407 3796 CONNECT
shavar.services.mozilla.com:443 - HIER_NONE/- text/html
1473026091.932      0 192.168.200.85 TCP_DENIED/407 3780 CONNECT
self-repair.mozilla.org:443 - HIER_NONE/- text/html
1473026096.418    180 192.168.200.85 TCP_MISS/200 960 POST
http://ocsp.digicert.com/ marcio HIER_DIRECT/192.16.58.8
application/ocsp-response
1473026096.467     85 192.168.200.85 TCP_MISS/200 960 POST
http://ocsp.digicert.com/ marcio HIER_DIRECT/192.16.58.8
application/ocsp-response
1473026102.051    525 192.168.200.85 TCP_REFRESH_UNMODIFIED/200 2907 GET
http://start.ubuntu.com/14.04/Google/? marcio HIER_DIRECT/91.189.90.41
text/html
1473026102.091      0 192.168.200.85 TCP_HIT/200 22099 GET
http://start.ubuntu.com/12.04/sprite.png marcio HIER_NONE/- image/png
1473026104.855      0 10.133.85.3 TCP_DENIED/407 3929 GET
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab?
- HIER_NONE/- text/html
1473026146.453     83 192.168.200.85 TCP_MISS/200 960 POST
http://ocsp.digicert.com/ marcio HIER_DIRECT/192.16.58.8
application/ocsp-response
1473026147.447     83 192.168.200.85 TCP_MISS/200 960 POST
http://ocsp.digicert.com/ marcio HIER_DIRECT/192.16.58.8
application/ocsp-response
1473026148.923      0 192.168.200.85 TCP_DENIED/407 3796 CONNECT
shavar.services.mozilla.com:443 - HIER_NONE/- text/html
1473026157.117  61506 192.168.200.85 TCP_MISS/200 3525 CONNECT
tiles.services.mozilla.com:443 marcio HIER_DIRECT/52.24.123.95 -
1473026157.195  61584 192.168.200.85 TCP_MISS/200 4521 CONNECT
self-repair.mozilla.org:443 marcio HIER_DIRECT/54.69.9.44 -
1473026160.190  63085 192.168.200.85 TCP_MISS/200 5449 CONNECT
self-repair.mozilla.org:443 marcio HIER_DIRECT/54.69.9.44 -
1473026204.518      0 192.168.200.85 TCP_DENIED/407 3780 CONNECT
safebrowsing.google.com:443 - HIER_NONE/- text/html
1473026207.807  62056 192.168.200.85 TCP_MISS/200 3686 CONNECT
incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
1473026207.808  61159 192.168.200.85 TCP_MISS/200 390 CONNECT
incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
1473026207.808  61159 192.168.200.85 TCP_MISS/200 390 CONNECT
incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
1473026207.808  61160 192.168.200.85 TCP_MISS/200 390 CONNECT
incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
1473026207.809  61160 192.168.200.85 TCP_MISS/200 390 CONNECT
incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
1473026207.814  61165 192.168.200.85 TCP_MISS/200 390 CONNECT
incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
1473026207.866  61052 192.168.200.85 TCP_MISS/200 3821 CONNECT
aus5.mozilla.org:443 marcio HIER_DIRECT/52.34.235.152 -
1473026212.687 116018 192.168.200.85 TCP_MISS/200 61971 CONNECT
normandy.cdn.mozilla.net:443 marcio HIER_DIRECT/52.84.177.125 -
1473026264.532      0 192.168.200.85 TCP_DENIED/407 3780 CONNECT
safebrowsing.google.com:443 - HIER_NONE/- text/html
1473026299.647      0 10.133.85.3 TCP_DENIED/407 3813 CONNECT
iecvlist.microsoft.com:443 - HIER_NONE/- text/html
1473026335.221      0 10.133.85.3 TCP_DENIED/407 3813 CONNECT
ieonline.microsoft.com:443 - HIER_NONE/- text/html
1473026592.061   6624 10.133.85.3 TCP_MISS/200 3582 CONNECT
forum.zentyal.org:443 marcio HIER_DIRECT/162.13.13.134 -
1473026793.073      0 192.168.200.96 TCP_DENIED/407 3780 CONNECT
safebrowsing.google.com:443 - HIER_NONE/- text/html

/var/log/squid3/cache.log

----------
2016/09/04 19:06:33.073 kid1| client_side.cc(2407) parseHttpRequest: HTTP
Client local=192.168.200.7:3128 remote=192.168.200.96:56302 FD 12 flags=1
2016/09/04 19:06:33.073 kid1| client_side.cc(2408) parseHttpRequest: HTTP
Client REQUEST:
---------
CONNECT safebrowsing.google.com:443 HTTP/1.1
User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:35.0) Gecko/20100101
Firefox/35.0
Proxy-Connection: keep-alive
Connection: keep-alive
Host: safebrowsing.google.com:443


----------
2016/09/04 19:06:33.073 kid1| client_side.cc(1459) sendStartOfMessage: HTTP
Client local=192.168.200.7:3128 remote=192.168.200.96:56302 FD 12 flags=1
2016/09/04 19:06:33.073 kid1| client_side.cc(1460) sendStartOfMessage: HTTP
Client REPLY:
---------
HTTP/1.1 407 Proxy Authentication Required
Server: squid/3.4.8
Mime-Version: 1.0
Date: Sun, 04 Sep 2016 22:06:33 GMT
Content-Type: text/html
Content-Length: 3357
X-Squid-Error: *ERR_CACHE_ACCESS_DENIED 0*
Proxy-Authenticate: Basic realm="CMS"
X-Cache: MISS from proxy.cms.ensino.br
X-Cache-Lookup: NONE from proxy.cms.ensino.br:3128
Via: 1.1 proxy.cms.ensino.br (squid/3.4.8)
Connection: keep-alive

----------

Sorry, but I didn't discover the problem!

Anybody have an idea?

Regards,

M?rcio

2016-09-02 11:10 GMT-03:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 2/09/2016 3:21 p.m., Marcio Demetrio Bacci wrote:
> > In my Windows workstations the authentication works correctly, however in
> > Ubuntu 14.04 the user and password are asked twice.
> >
> > I am using the basic_ncsa_auth with Squid 3.4.8
> >
> > Is there any setting that I do in Squid?
> >
> > Bellow is my squid.conf
> >
> ...
> >
> > auth_param basic program /usr/lib/squid3/basic_ncsa_auth
> /etc/squid3/passwd
> > auth_param basic children 5
> > auth_param basic realm AUTENTICACAO
> > auth_param basic credentialsttl 2 hours
> > auth_param basic casesensitive off
> >
> ...
> >
> > ### Regras iniciais do Squid
> > http_access allow localhost
> > http_access allow purge localhost
> > http_access deny purge
> > http_access deny !Safe_ports
> > http_access deny CONNECT !SSL_ports
>
> Please re-order the above security rules to be:
>
>   http_access deny !Safe_ports
>   http_access deny CONNECT !SSL_ports
>   http_access allow localhost
>   http_access deny purge
>
> >
> > ### Exige autenticacao
> > acl autenticados proxy_auth REQUIRED
> > http_access allow autenticados
> >
> > ### Bloqueia extensoes de arquivos
> > acl extensoes_bloqueadas url_regex -i "/etc/squid3/acls/extensoes-
> proibidas"
> >
> > ### Liberar alguns sites
> > acl sites_liberados url_regex -i "/etc/squid3/acls/sites-permitidos"
> >
> > ### Bloqueia sites por URL
> > acl sites_bloqueados url_regex -i "/etc/squid3/acls/sites-proibidos"
> >
> > #bloqueios basicos
> > http_access allow sites_liberados
> > http_access deny extensoes_bloqueadas
> > http_access deny sites_bloqueados
> >
> > ### LAN #####
> > acl rede_lan src 192.168.200.0/22
> >
> > ### Nega acesso de quem nao esta na rede local do CMB
> > http_access allow rede_lan
> >
> > #negando o acesso para todos que nao estiverem nas regras anteriores
> > http_access deny all
> >
> ...
>
>
> With your config Squid will only challenge the browser to send some if
> they are completely missing. It will not deny access when invalid
> credentials are sent.
>
> That means the browser probably does not have access to any Basic auth
> credentials it can send.
>
> The two popups are probably from two TCP connections being made with no
> credentials (maybe the result of the "Happy Eyeballs" algorithm doing
> its thing). You can check for that with "debug_options 11,2" and seeing
> what HTTP messages are happening with what IP:port details.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160904/39fdd078/attachment.htm>

From marcus.kool at urlfilterdb.com  Sun Sep  4 23:35:59 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Sun, 4 Sep 2016 20:35:59 -0300
Subject: [squid-users] More host header forgery pain with peek/splice
In-Reply-To: <b1fde5e0-7725-7264-4039-17f34cf7e6fb@treenet.co.nz>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <1472150075016-4679181.post@n4.nabble.com>
 <477b5e2b-6eb4-54bc-240f-af416f53612c@treenet.co.nz>
 <0aebb8f5-e2fe-71ea-5477-d299acd9ccf9@urlfilterdb.com>
 <b1fde5e0-7725-7264-4039-17f34cf7e6fb@treenet.co.nz>
Message-ID: <ac05d49c-fe7f-f0f3-af19-7a065d2fe228@urlfilterdb.com>

Thanks for your reply.

The 13-year old child in me says "I want it fixed yesterday"
since false positives are very painful and cannot always
be prevented since the environment where Squid works is
not always that easy to control.

You mentioned earlier that a fix will probably go in squid 5
which is long due and there is no workaround.  A second
thought is to have an acl that determines for which domains
the check must be skipped, but this is not optimal since
the admin gains an extra job.

My vote goes to re-prioritizing the fix and put it in Squid 4.
Of course I have no idea about the implications.

Thanks
Marcus


On 09/04/2016 01:12 PM, Amos Jeffries wrote:
> On 31/08/2016 5:25 a.m., Marcus Kool wrote:
>> Do I understand it correctly that Squid in normal proxy mode
>> allows malware to do a CONNECT to any destination, while in
>> transparent proxy mode does extra security checks which causes
>> some regular (non-malware) clients to fail?
>
>
> Intercepted traffic has different processing applied, different
> assumptions made about the traffic, and different security model
> relevant to its messages.
>
> The short answer is "yes", but reality is not that simple black/white.
>
>
>>
>> And philosophical questions: is Squid the right tool
>> to stop malware?  If yes, is it acceptable that connections
>> of regular (non-malware) clients are wrongly dropped?
>
> No more or less than any software.
>
> Squid manages the HTTP that flows through it. If the malware uses HTTP
> messages to communicate then it very much part of Squid's job to prevent
> that. Other protocols Squid is not responsible for, except to prevent
> itself being a vector of attack.
>
>>
>> IMO Squid should do all it can to be a secure proxy.
>
> Which is the case for Host forgery atacks. If Squid did not MITM the
> network traffic, there would not be a vulnerability to Host forgery
> issues. Therefore an intercept/tproxy Squid is very much responsible for
> preventing this particular type of attack which it causes to exist.
>
> A forward-proxy or reverse-proxy does not have that vulnerability,
> therefore does not need to check the same things.
>
>
>> Doing security checks on connections in an attempt
>> to stop malware sounds like a job for an antivirus / IDS tool.
>>
>
> Additional to what Squid does. Indeed many of those tools use a proxy
> service which performs the same or similar checks to what Squid does,
> with far more intrusive behaviour, or are themselves also vulnerable to
> becoming vectors of the Host attack(s). The Host attack(s) are
> vulnerability built into the concept of MITM'ing HTTP(S) traffic. It is
> not something specific to Squid.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From squid3 at treenet.co.nz  Mon Sep  5 04:17:44 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 5 Sep 2016 16:17:44 +1200
Subject: [squid-users] Problems with Linux Worstations
In-Reply-To: <CA+0Tdyoer7WW0Sfvy_5z5T3JQ3j_hw1Yf=mDLFtF2gJZmyMfew@mail.gmail.com>
References: <CA+0TdyrGBxitJDCOgcULKsdiq5uqzs4UJEm6Ht=_RMRfatZadg@mail.gmail.com>
 <524b90be-8363-f906-1b18-d9481d8c63b3@treenet.co.nz>
 <CA+0Tdyoer7WW0Sfvy_5z5T3JQ3j_hw1Yf=mDLFtF2gJZmyMfew@mail.gmail.com>
Message-ID: <5de64bba-dcc9-d809-c5b6-3f9e50da9f09@treenet.co.nz>

On 5/09/2016 10:41 a.m., Marcio Demetrio Bacci wrote:
> I have used debug_options 11,2 in squid.conf file. After I have following
> results in logs files:
> 
> /var/log/squid3/access.log
> 1473026084.048    253 192.168.200.85 TCP_MISS_ABORTED/000 0 POST
> http://m.addthis.com/live/red_lojson/100eng.json? marcio HIER_NONE/- -
> 1473026086.275      0 192.168.200.85 TCP_DENIED/407 3792 CONNECT
> tiles.services.mozilla.com:443 - HIER_NONE/- text/html
> 1473026086.778      0 192.168.200.85 TCP_DENIED/407 3995 GET
> http://start.ubuntu.com/14.04/Google/? - HIER_NONE/- text/html
> 1473026088.908      0 192.168.200.85 TCP_DENIED/407 3796 CONNECT
> shavar.services.mozilla.com:443 - HIER_NONE/- text/html
> 1473026091.932      0 192.168.200.85 TCP_DENIED/407 3780 CONNECT
> self-repair.mozilla.org:443 - HIER_NONE/- text/html
> 1473026096.418    180 192.168.200.85 TCP_MISS/200 960 POST
> http://ocsp.digicert.com/ marcio HIER_DIRECT/192.16.58.8
> application/ocsp-response
> 1473026096.467     85 192.168.200.85 TCP_MISS/200 960 POST
> http://ocsp.digicert.com/ marcio HIER_DIRECT/192.16.58.8
> application/ocsp-response
> 1473026102.051    525 192.168.200.85 TCP_REFRESH_UNMODIFIED/200 2907 GET
> http://start.ubuntu.com/14.04/Google/? marcio HIER_DIRECT/91.189.90.41
> text/html
> 1473026102.091      0 192.168.200.85 TCP_HIT/200 22099 GET
> http://start.ubuntu.com/12.04/sprite.png marcio HIER_NONE/- image/png
> 1473026104.855      0 10.133.85.3 TCP_DENIED/407 3929 GET
> http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab?
> - HIER_NONE/- text/html
> 1473026146.453     83 192.168.200.85 TCP_MISS/200 960 POST
> http://ocsp.digicert.com/ marcio HIER_DIRECT/192.16.58.8
> application/ocsp-response
> 1473026147.447     83 192.168.200.85 TCP_MISS/200 960 POST
> http://ocsp.digicert.com/ marcio HIER_DIRECT/192.16.58.8
> application/ocsp-response
> 1473026148.923      0 192.168.200.85 TCP_DENIED/407 3796 CONNECT
> shavar.services.mozilla.com:443 - HIER_NONE/- text/html
> 1473026157.117  61506 192.168.200.85 TCP_MISS/200 3525 CONNECT
> tiles.services.mozilla.com:443 marcio HIER_DIRECT/52.24.123.95 -
> 1473026157.195  61584 192.168.200.85 TCP_MISS/200 4521 CONNECT
> self-repair.mozilla.org:443 marcio HIER_DIRECT/54.69.9.44 -
> 1473026160.190  63085 192.168.200.85 TCP_MISS/200 5449 CONNECT
> self-repair.mozilla.org:443 marcio HIER_DIRECT/54.69.9.44 -
> 1473026204.518      0 192.168.200.85 TCP_DENIED/407 3780 CONNECT
> safebrowsing.google.com:443 - HIER_NONE/- text/html
> 1473026207.807  62056 192.168.200.85 TCP_MISS/200 3686 CONNECT
> incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
> 1473026207.808  61159 192.168.200.85 TCP_MISS/200 390 CONNECT
> incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
> 1473026207.808  61159 192.168.200.85 TCP_MISS/200 390 CONNECT
> incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
> 1473026207.808  61160 192.168.200.85 TCP_MISS/200 390 CONNECT
> incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
> 1473026207.809  61160 192.168.200.85 TCP_MISS/200 390 CONNECT
> incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
> 1473026207.814  61165 192.168.200.85 TCP_MISS/200 390 CONNECT
> incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
> 1473026207.866  61052 192.168.200.85 TCP_MISS/200 3821 CONNECT
> aus5.mozilla.org:443 marcio HIER_DIRECT/52.34.235.152 -
> 1473026212.687 116018 192.168.200.85 TCP_MISS/200 61971 CONNECT
> normandy.cdn.mozilla.net:443 marcio HIER_DIRECT/52.84.177.125 -
> 1473026264.532      0 192.168.200.85 TCP_DENIED/407 3780 CONNECT
> safebrowsing.google.com:443 - HIER_NONE/- text/html
> 1473026299.647      0 10.133.85.3 TCP_DENIED/407 3813 CONNECT
> iecvlist.microsoft.com:443 - HIER_NONE/- text/html
> 1473026335.221      0 10.133.85.3 TCP_DENIED/407 3813 CONNECT
> ieonline.microsoft.com:443 - HIER_NONE/- text/html
> 1473026592.061   6624 10.133.85.3 TCP_MISS/200 3582 CONNECT
> forum.zentyal.org:443 marcio HIER_DIRECT/162.13.13.134 -

Notice how the 407 occur in bunches. 2-3 getting a 407 reject, then many
requests going through with user credentials. Then again some without
any getting a 407.
Those bunches of 407 will be matching some type of credentials timeout
in the browser, or opening of new tabs.


This request below is the only one from 192.168.200.96 so appears to be
the one you provide cache.log trace for...


> 1473026793.073      0 192.168.200.96 TCP_DENIED/407 3780 CONNECT
> safebrowsing.google.com:443 - HIER_NONE/- text/html
> 
> /var/log/squid3/cache.log
> 
> ----------
> 2016/09/04 19:06:33.073 kid1| client_side.cc(2407) parseHttpRequest: HTTP
> Client local=192.168.200.7:3128 remote=192.168.200.96:56302 FD 12 flags=1
> 2016/09/04 19:06:33.073 kid1| client_side.cc(2408) parseHttpRequest: HTTP
> Client REQUEST:
> ---------
> CONNECT safebrowsing.google.com:443 HTTP/1.1
> User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:35.0) Gecko/20100101
> Firefox/35.0
> Proxy-Connection: keep-alive
> Connection: keep-alive
> Host: safebrowsing.google.com:443

Notice the abence of any Proxy-Authorization header containing credentials.

> 
> 
> ----------
> 2016/09/04 19:06:33.073 kid1| client_side.cc(1459) sendStartOfMessage: HTTP
> Client local=192.168.200.7:3128 remote=192.168.200.96:56302 FD 12 flags=1
> 2016/09/04 19:06:33.073 kid1| client_side.cc(1460) sendStartOfMessage: HTTP
> Client REPLY:
> ---------
> HTTP/1.1 407 Proxy Authentication Required
> Server: squid/3.4.8
> Mime-Version: 1.0
> Date: Sun, 04 Sep 2016 22:06:33 GMT
> Content-Type: text/html
> Content-Length: 3357
> X-Squid-Error: *ERR_CACHE_ACCESS_DENIED 0*
> Proxy-Authenticate: Basic realm="CMS"

That realm="CMS" does not match the realm value of "AUTENTICACAO" which
your earlier config contained.

Unless you changed your auth_param settings that is a sign that some
other proxy is generating that response message. BUT, your access.log
entry shows no server being contacted.



> X-Cache: MISS from proxy.cms.ensino.br
> X-Cache-Lookup: NONE from proxy.cms.ensino.br:3128
> Via: 1.1 proxy.cms.ensino.br (squid/3.4.8)
> Connection: keep-alive
> 
> ----------
> 
> Sorry, but I didn't discover the problem!
> 
> Anybody have an idea?

If you altered your squid.conf settings as above in the auth details,
did you also remove 192.168.200.7 from the "localhost" ACL ?

Your rule "http_access allow localhost" occurs before anything that
requires authentication. That means these requests coming from
192.168.200.7 to your proxy would not use authentication for the above
CONNECT request. So no reason for your proxy to generate any 407 response.


Amos



From marciobacci at gmail.com  Mon Sep  5 04:32:47 2016
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Mon, 5 Sep 2016 01:32:47 -0300
Subject: [squid-users] Squid Authentication - Problems
Message-ID: <CA+0Tdyo0fWPAk-10Mt28BudAPc3AZzb3mFRPzr8JUok3hK9BMg@mail.gmail.com>

Hi

I have tried to use only Kerberos authentication, but didn't work! I have
already used the 3 way below:

1) auth_param negotiate program /usr/lib/squid3/negotiate_kerberos_auth
2) auth_param negotiate program /usr/lib/squid3/negotiate_kerberos_auth -s
GSS_C_NO_NAME -i
3) auth_param negotiate program /usr/lib/squid3/negotiate_kerberos_auth -s
HTTP/proxy.cms.ensino.br at CMS.ENSINO.BR

Now, kerberos and NTLM together is OK with Windows worstations, but with
Linux appear the message in my Browser: "cache denied access".
Thus, I have used the basic_ldap_auth to Linux machines.

Following is authentication block the my squid.conf:

### Kerberos and NTLM ###
auth_param negotiate program /usr/lib/squid3/negotiate_wrapper_auth -d
--ntlm /usr/bin/ntlm_auth --diagnostics
--helper-protocol=squid-2.5-ntlmssp --domain=CMS --kerberos
/usr/lib/squid3/negotiate_kerberos_auth -d -s GSS_C_NO_NAME
auth_param negotiate children 10
auth_param negotiate keep_alive off

### LDAP ###
auth_param basic program /usr/lib/squid3/basic_ldap_auth -R -b
DC=cms,DC=ensino,DC=br -D CN=proxy,CN=Users,DC=cms,DC=ensino,DC=br -w
passwd -h 192.168.200.25 -p 389 -s sub -v 3 -f "sAMAccountName=%s"
auth_param basic children 50
auth_param basic realm "Acesso Monitorado - CMS"
auth_param basic credentialsttl 8 hours
auth_param basic casesensitive off

Now I would like to identify groups of the users (admins, managers and
domain users) to create access profiles. How can I do this?
ext_ldap_group_acl or ext_kerberos_ldap_group_acl ?

Regards,
M?rcio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160905/2edf2c89/attachment.htm>

From squid3 at treenet.co.nz  Mon Sep  5 11:02:06 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 5 Sep 2016 23:02:06 +1200
Subject: [squid-users] More host header forgery pain with peek/splice
In-Reply-To: <ac05d49c-fe7f-f0f3-af19-7a065d2fe228@urlfilterdb.com>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <1472150075016-4679181.post@n4.nabble.com>
 <477b5e2b-6eb4-54bc-240f-af416f53612c@treenet.co.nz>
 <0aebb8f5-e2fe-71ea-5477-d299acd9ccf9@urlfilterdb.com>
 <b1fde5e0-7725-7264-4039-17f34cf7e6fb@treenet.co.nz>
 <ac05d49c-fe7f-f0f3-af19-7a065d2fe228@urlfilterdb.com>
Message-ID: <87b0feed-bfc8-bde5-3e3f-007275eb5ca6@treenet.co.nz>

On 5/09/2016 11:35 a.m., Marcus Kool wrote:
> Thanks for your reply.
> 
> The 13-year old child in me says "I want it fixed yesterday"
> since false positives are very painful and cannot always
> be prevented since the environment where Squid works is
> not always that easy to control.
> 
> You mentioned earlier that a fix will probably go in squid 5
> which is long due and there is no workaround.  A second
> thought is to have an acl that determines for which domains
> the check must be skipped, but this is not optimal since
> the admin gains an extra job.
> 
> My vote goes to re-prioritizing the fix and put it in Squid 4.
> Of course I have no idea about the implications.

Resources to work on it would be very welcome. I still think it will
take too long to go into Squid-4 though, since 4.1 is already overdue
for release.

Amos



From omidkosari at yahoo.com  Mon Sep  5 13:39:54 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Mon, 5 Sep 2016 06:39:54 -0700 (PDT)
Subject: [squid-users] reply_header_access Server deny (IF Server==squid)
In-Reply-To: <aa1588f2-fe84-afed-aa30-7d390e3e5e05@treenet.co.nz>
References: <1472896723526-4679338.post@n4.nabble.com>
 <15d66d9d-22a7-7560-c45f-42173bcf84c9@treenet.co.nz>
 <1472974835645-4679341.post@n4.nabble.com>
 <aa1588f2-fe84-afed-aa30-7d390e3e5e05@treenet.co.nz>
Message-ID: <1473082794517-4679354.post@n4.nabble.com>

Thanks but according to my other thread
http://squid-web-proxy-cache.1019090.n4.nabble.com/TCP-RESET-non-http-requests-on-port-80-td4679102.html
deny_info generates some other headers/footprints.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/reply-header-access-Server-deny-IF-Server-squid-tp4679338p4679354.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From omidkosari at yahoo.com  Mon Sep  5 13:46:09 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Mon, 5 Sep 2016 06:46:09 -0700 (PDT)
Subject: [squid-users] range_offset_limit not working as expected
Message-ID: <1473083169343-4679355.post@n4.nabble.com>

Hello,

My config:
acl download_until_end dstdomain .cdn.mozilla.net
range_offset_limit none download_until_end


Squid 3.5.19




1473082997.229    697 x.29.186.47 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.72 application/octet-stream
1473082999.365   1122 x.10.189.81 TCP_MISS/206 300512 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083001.570    573 x.29.184.205 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.81 application/octet-stream
1473083004.941   2196 x.10.184.141 TCP_MISS/206 300514 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083005.383    631 x.10.184.65 TCP_MISS/206 300514 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win64/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083006.711    970 x.10.191.220 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/49.0b6/update/win32/en-US/firefox-49.0b6.complete.mar
- ORIGINAL_DST/2.21.246.11 application/octet-stream
1473083008.124  74151 x.10.182.124 TCP_MISS/206 300627 GET
http://download.cdn.mozilla.net/pub/firefox/releases/12.0/update/win32/en-US/firefox-12.0.complete.mar
- ORIGINAL_DST/54.192.128.59 application/octet-stream
1473083012.317    646 x.10.185.248 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.81 application/octet-stream
1473083015.680    793 x.29.187.142 TCP_MISS/206 300474 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/2.21.246.11 application/octet-stream
1473083017.918    515 x.10.184.114 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.81 application/octet-stream
1473083023.480    514 x.29.185.194 TCP_MISS/206 300474 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win64/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.59 application/octet-stream
1473083027.521   1208 x.6.25.227 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/en-US/firefox-47.0.1.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083028.096   1017 x.6.24.5 TCP_MISS/206 300474 GET
http://download.cdn.mozilla.net/pub/firefox/releases/43.0.1/update/win32/en-US/firefox-43.0.1.complete.mar
- ORIGINAL_DST/188.43.76.81 application/octet-stream
1473083032.366   1288 x.10.183.80 TCP_MISS/206 300474 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.59 application/octet-stream
1473083038.171    548 x.29.185.69 TCP_MISS/206 300514 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083038.579   1298 x.10.182.90 TCP_HIT/206 300623 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win64/en-US/firefox-48.0.1-48.0.2.partial.mar
- HIER_NONE/- application/octet-stream
1473083038.706    277 x.10.185.96 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.59 application/octet-stream
1473083039.127   7808 x.29.189.2 TCP_MISS/206 300487 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- STANDBY_POOL/1.1.1.12 application/octet-stream
1473083044.820   1296 x.6.25.74 TCP_MISS/206 300473 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.1-48.0.2.partial.mar
- ORIGINAL_DST/188.43.76.81 application/octet-stream
1473083047.174    577 x.29.188.118 TCP_HIT/206 300622 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/fa/firefox-47.0.1.complete.mar
- HIER_NONE/- application/octet-stream
1473083050.059    623 x.10.188.231 TCP_MISS/206 300474 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/en-US/firefox-47.0.1.complete.mar
- ORIGINAL_DST/188.43.76.72 application/octet-stream
1473083050.332    436 x.6.25.60 TCP_MISS/206 300624 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/en-US/firefox-47.0.1.complete.mar
- STANDBY_POOL/1.1.1.12 application/octet-stream
1473083053.730    824 x.10.183.153 TCP_MISS/206 300621 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/en-US/firefox-47.0.1.complete.mar
- ORIGINAL_DST/54.192.44.217 application/octet-stream
1473083058.374    759 x.29.186.47 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.72 application/octet-stream
1473083059.571   3537 x.6.24.123 TCP_MISS/206 300474 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.59 application/octet-stream
1473083061.041   1068 x.10.189.81 TCP_MISS/206 300512 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083062.504    562 x.29.184.205 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.81 application/octet-stream
1473083066.482    768 x.10.184.65 TCP_MISS/206 300514 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win64/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083067.842   2611 x.10.186.8 TCP_MISS/206 300485 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- STANDBY_POOL/1.1.1.12 application/octet-stream
1473083068.328    947 x.10.191.220 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/49.0b6/update/win32/en-US/firefox-49.0b6.complete.mar
- ORIGINAL_DST/2.21.246.11 application/octet-stream
1473083069.011   2324 x.10.184.141 TCP_MISS/206 300514 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083073.250    722 x.10.185.248 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.81 application/octet-stream
1473083076.617    760 x.29.187.142 TCP_MISS/206 300474 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/2.21.246.11 application/octet-stream
1473083078.889    531 x.10.184.114 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.81 application/octet-stream
1473083079.248    756 x.6.25.60 TCP_MISS/206 300625 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/en-US/firefox-47.0.1.complete.mar
- STANDBY_POOL/1.1.1.12 application/octet-stream
1473083084.462    638 x.29.185.194 TCP_MISS/206 300474 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win64/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.59 application/octet-stream
1473083089.045   1374 x.6.25.227 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/en-US/firefox-47.0.1.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083098.255   1191 x.10.182.131 TCP_HIT/206 300488 GET
http://download.cdn.mozilla.net/pub/firefox/releases/12.0/update/win32/en-US/firefox-12.0.complete.mar
- HIER_NONE/- application/octet-stream
1473083099.285    524 x.29.185.69 TCP_MISS/206 300514 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083099.408    652 x.10.185.96 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.59 application/octet-stream
1473083100.063   1088 x.10.182.90 TCP_HIT/206 300624 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win64/en-US/firefox-48.0.1-48.0.2.partial.mar
- HIER_NONE/- application/octet-stream
1473083106.221   1214 x.6.25.74 TCP_MISS/206 300473 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.1-48.0.2.partial.mar
- ORIGINAL_DST/188.43.76.81 application/octet-stream
1473083107.936    560 x.29.188.118 TCP_HIT/206 300623 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/fa/firefox-47.0.1.complete.mar
- HIER_NONE/- application/octet-stream
1473083109.106   3703 x.29.189.2 TCP_MISS/206 300487 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- STANDBY_POOL/1.1.1.12 application/octet-stream
1473083110.606    461 x.10.188.231 TCP_MISS/206 300474 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/en-US/firefox-47.0.1.complete.mar
- ORIGINAL_DST/188.43.76.72 application/octet-stream
1473083117.117   1428 x.10.183.153 TCP_MISS/206 300622 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/en-US/firefox-47.0.1.complete.mar
- ORIGINAL_DST/54.192.44.217 application/octet-stream
1473083119.444    697 x.29.186.47 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.72 application/octet-stream
1473083122.682    977 x.10.189.81 TCP_MISS/206 300512 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083123.436    562 x.29.184.205 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.81 application/octet-stream
1473083125.641   3494 x.6.24.123 TCP_MISS/206 300474 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.59 application/octet-stream
1473083127.791   1110 x.10.184.65 TCP_MISS/206 300514 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win64/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083129.991    975 x.10.191.220 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/49.0b6/update/win32/en-US/firefox-49.0b6.complete.mar
- ORIGINAL_DST/2.21.246.11 application/octet-stream
1473083132.907   2201 x.10.184.141 TCP_MISS/206 300514 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083133.160   2028 x.29.188.16 TCP_MISS/206 300626 GET
http://download.cdn.mozilla.net/pub/firefox/releases/43.0.1/update/win32/en-US/firefox-43.0.1.complete.mar
- STANDBY_POOL/1.1.1.12 application/octet-stream
1473083134.093    629 x.10.185.248 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.81 application/octet-stream
1473083137.540    758 x.29.187.142 TCP_MISS/206 300474 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/2.21.246.11 application/octet-stream
1473083139.841    508 x.10.184.114 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.81 application/octet-stream
1473083140.132    580 x.6.25.60 TCP_MISS/206 300625 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/en-US/firefox-47.0.1.complete.mar
- STANDBY_POOL/1.1.1.12 application/octet-stream
1473083144.676    523 x.10.183.169 TCP_MISS/206 300623 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/en-US/firefox-47.0.1.complete.mar
- STANDBY_POOL/1.1.1.12 application/octet-stream
1473083145.432    623 x.29.185.194 TCP_MISS/206 300475 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win64/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.59 application/octet-stream
1473083150.678   1401 x.6.25.227 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/en-US/firefox-47.0.1.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083159.669    402 x.10.181.243 TCP_MISS/206 300483 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- STANDBY_POOL/1.1.1.12 application/octet-stream
1473083159.984    540 x.10.185.96 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.59 application/octet-stream
1473083161.515   1088 x.10.182.90 TCP_HIT/206 300625 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win64/en-US/firefox-48.0.1-48.0.2.partial.mar
- HIER_NONE/- application/octet-stream
1473083167.504   1069 x.6.25.74 TCP_MISS/206 280483 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.1-48.0.2.partial.mar
- ORIGINAL_DST/188.43.76.81 application/octet-stream
1473083168.699    553 x.29.188.118 TCP_HIT/206 300623 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/fa/firefox-47.0.1.complete.mar
- HIER_NONE/- application/octet-stream
1473083171.595    873 x.10.188.231 TCP_MISS/206 300474 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/en-US/firefox-47.0.1.complete.mar
- ORIGINAL_DST/188.43.76.72 application/octet-stream
1473083175.433   3624 x.29.189.2 TCP_MISS/206 300487 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- STANDBY_POOL/1.1.1.12 application/octet-stream
1473083177.088  17269 x.29.185.69 TCP_MISS/206 300514 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083178.399    773 x.10.183.153 TCP_MISS/206 300623 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/en-US/firefox-47.0.1.complete.mar
- ORIGINAL_DST/54.192.44.217 application/octet-stream
1473083180.400    583 x.29.186.47 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.72 application/octet-stream
1473083184.321    967 x.10.189.81 TCP_MISS/206 300512 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083184.375    561 x.29.184.205 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.81 application/octet-stream
1473083188.727    578 x.10.184.65 TCP_MISS/206 300514 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win64/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083191.677   1011 x.10.191.220 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/49.0b6/update/win32/en-US/firefox-49.0b6.complete.mar
- ORIGINAL_DST/2.21.246.11 application/octet-stream
1473083191.892   3636 x.6.24.123 TCP_MISS/206 300474 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.59 application/octet-stream
1473083193.504   7646 x.10.191.76 TCP_MISS/206 300622 GET
http://download.cdn.mozilla.net/pub/firefox/releases/43.0.1/update/win32/en-US/firefox-43.0.1.complete.mar
- STANDBY_POOL/1.1.1.12 application/octet-stream
1473083195.044    736 x.10.185.248 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.81 application/octet-stream
1473083195.752   2153 x.29.188.16 TCP_MISS/206 300626 GET
http://download.cdn.mozilla.net/pub/firefox/releases/43.0.1/update/win32/en-US/firefox-43.0.1.complete.mar
- STANDBY_POOL/1.1.1.12 application/octet-stream
1473083200.501    842 x.29.187.142 TCP_MISS/206 300623 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/54.192.44.217 application/octet-stream
1473083200.805    520 x.10.184.114 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.81 application/octet-stream
1473083201.198   6592 x.10.184.141 TCP_MISS/206 300514 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083206.310    573 x.29.185.194 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win64/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.59 application/octet-stream
1473083212.437   1563 x.6.25.227 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/en-US/firefox-47.0.1.complete.mar
- ORIGINAL_DST/188.43.76.80 application/octet-stream
1473083220.760    740 x.10.185.96 TCP_MISS/206 300476 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
- ORIGINAL_DST/188.43.76.59 application/octet-stream
1473083222.952   1084 x.10.182.90 TCP_HIT/206 300625 GET
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win64/en-US/firefox-48.0.1-48.0.2.partial.mar
- HIER_NONE/- application/octet-stream
1473083224.446    201 x.10.188.231 TCP_MISS/206 300623 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/en-US/firefox-47.0.1.complete.mar
- STANDBY_POOL/1.1.1.12 application/octet-stream
1473083229.466    549 x.29.188.118 TCP_HIT/206 300623 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/fa/firefox-47.0.1.complete.mar
- HIER_NONE/- application/octet-stream
1473083239.495    848 x.10.183.153 TCP_MISS/206 300623 GET
http://download.cdn.mozilla.net/pub/firefox/releases/47.0.1/update/win32/en-US/firefox-47.0.1.complete.mar
- ORIGINAL_DST/54.192.44.217 application/octet-stream




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/range-offset-limit-not-working-as-expected-tp4679355.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Mon Sep  5 14:09:55 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 6 Sep 2016 02:09:55 +1200
Subject: [squid-users] range_offset_limit not working as expected
In-Reply-To: <1473083169343-4679355.post@n4.nabble.com>
References: <1473083169343-4679355.post@n4.nabble.com>
Message-ID: <d6e5127b-8c07-3218-a722-78eb53b12ab4@treenet.co.nz>

What are you expecting?

The Squid native format access.log shows what was delivered to the
client, and what server was involved. It does not show how the
range_offset_limit directive affected the server connection messages.

The ORIGINAL_DST indicates that this is intercepted traffic.

Notice how the TCP_MISS transactions are rotating through different IP
addresses and using ORIGINAL_DST. That is usualy a sign that Host header
verification is unable to match the destination domain name with the
client contacted IP address on many transactions.

There is a mix of TCP_HIT/206 when that verification succeeds in its
matching.

Amos



From squid3 at treenet.co.nz  Mon Sep  5 14:39:08 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 6 Sep 2016 02:39:08 +1200
Subject: [squid-users] reply_header_access Server deny (IF Server==squid)
In-Reply-To: <1473082794517-4679354.post@n4.nabble.com>
References: <1472896723526-4679338.post@n4.nabble.com>
 <15d66d9d-22a7-7560-c45f-42173bcf84c9@treenet.co.nz>
 <1472974835645-4679341.post@n4.nabble.com>
 <aa1588f2-fe84-afed-aa30-7d390e3e5e05@treenet.co.nz>
 <1473082794517-4679354.post@n4.nabble.com>
Message-ID: <7fd6c203-f2e9-4d33-c447-e21e704c87e2@treenet.co.nz>

On 6/09/2016 1:39 a.m., Omid Kosari wrote:
> Thanks but according to my other thread
> http://squid-web-proxy-cache.1019090.n4.nabble.com/TCP-RESET-non-http-requests-on-port-80-td4679102.html
> deny_info generates some other headers/footprints.
> 

See Alex's last message in that thread. In particular the link to a FAQ
about what your options are for fixing the broken behaviour.

Using a differently non-working approach is not one of the options.

Amos



From marciobacci at gmail.com  Mon Sep  5 16:25:19 2016
From: marciobacci at gmail.com (Marcio Demetrio Bacci)
Date: Mon, 5 Sep 2016 13:25:19 -0300
Subject: [squid-users] Problems with Linux Worstations
In-Reply-To: <5de64bba-dcc9-d809-c5b6-3f9e50da9f09@treenet.co.nz>
References: <CA+0TdyrGBxitJDCOgcULKsdiq5uqzs4UJEm6Ht=_RMRfatZadg@mail.gmail.com>
 <524b90be-8363-f906-1b18-d9481d8c63b3@treenet.co.nz>
 <CA+0Tdyoer7WW0Sfvy_5z5T3JQ3j_hw1Yf=mDLFtF2gJZmyMfew@mail.gmail.com>
 <5de64bba-dcc9-d809-c5b6-3f9e50da9f09@treenet.co.nz>
Message-ID: <CA+0Tdyp938vvpvgSk2_L2=bhuo6MCE7FsWt=S83WT+kA7XYNwg@mail.gmail.com>

Hi Amos

Now, my squid.conf is as follow (very simple):

############ START #################
http_port 3128

debug_options 11,2

cache_mem 512 MB
cache_swap_low 80
cache_swap_high 90

maximum_object_size 512 MB
minimum_object_size 0 KB

maximum_object_size_in_memory 4096 KB

cache_replacement_policy heap LFUDA
memory_replacement_policy heap LFUDA

fqdncache_size 1024

### Parametros de atualizacao da memoria cache
refresh_pattern ^ftp:    1440      20%    10080
refresh_pattern ^gopher:    1440    0%    1440
refresh_pattern -i (/cgi-bin/|\?) 0 0%     0
refresh_pattern .        0    20%    4320

### Localizacao dos logs
access_log /var/log/squid3/access.log
cache_log /var/log/squid3/cache.log

cache_dir aufs /var/spool/squid3 600 16 256

visible_hostname proxy

### acls
acl localhost src 192.168.200.7/32
acl to_localhost dst 192.168.200.7/32
acl SSL_ports port 22 443 563 7071 10000
acl Safe_ports port 21 70 80 88 210 280 389 443 488 563 591 777
1025-65535

acl purge method PURGE
acl CONNECT method CONNECT

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access deny purge

auth_param basic program /usr/lib/squid3/basic_ncsa_auth /etc/squid3/passwd
auth_param basic children 5
auth_param basic realm CMS
auth_param basic credentialsttl 2 hours
auth_param basic casesensitive off

### Exige autenticacao
acl autenticados proxy_auth REQUIRED
http_access deny !autenticados

### Rede do CMS #####
acl lannet src 192.168.200.0/22

### Nega acesso de quem nao esta na rede local do CMS
http_access allow lannet
http_access allow localhost

#negando o acesso para todos que nao estiverem nas regras anteriores
http_access deny all

### Erros em portugues
error_directory /usr/share/squid3/errors/pt-br

#cache_effective_user proxy
coredump_dir /var/spool/squid3

########## END ###########################

I have some doubts:

1) I open my browser to test the authentication. It seems OK, but  when I
open new tab in browser the Squid3 ask the user and password again. Is this
normal behavior  ?

2) Is necessary to declare LOCALHOST acl as "acl localhost src
192.168.200.7/32" ?

3) Isn't necessary MANAGER acl as "acl manager proto cache_object" ?

4) Is correct order of the ACL in my squid.conf ? How do I improve it?

5) In my access.log, I have saw many "TCP_MISS/200". Does mean only the
website is not in cache or is a strange behavior?


Sorry, but I'm still learning about Squid!


Regards,

M?rcio




2016-09-05 1:17 GMT-03:00 Amos Jeffries <squid3 at treenet.co.nz>:

> On 5/09/2016 10:41 a.m., Marcio Demetrio Bacci wrote:
> > I have used debug_options 11,2 in squid.conf file. After I have following
> > results in logs files:
> >
> > /var/log/squid3/access.log
> > 1473026084.048    253 192.168.200.85 TCP_MISS_ABORTED/000 0 POST
> > http://m.addthis.com/live/red_lojson/100eng.json? marcio HIER_NONE/- -
> > 1473026086.275      0 192.168.200.85 TCP_DENIED/407 3792 CONNECT
> > tiles.services.mozilla.com:443 - HIER_NONE/- text/html
> > 1473026086.778      0 192.168.200.85 TCP_DENIED/407 3995 GET
> > http://start.ubuntu.com/14.04/Google/? - HIER_NONE/- text/html
> > 1473026088.908      0 192.168.200.85 TCP_DENIED/407 3796 CONNECT
> > shavar.services.mozilla.com:443 - HIER_NONE/- text/html
> > 1473026091.932      0 192.168.200.85 TCP_DENIED/407 3780 CONNECT
> > self-repair.mozilla.org:443 - HIER_NONE/- text/html
> > 1473026096.418    180 192.168.200.85 TCP_MISS/200 960 POST
> > http://ocsp.digicert.com/ marcio HIER_DIRECT/192.16.58.8
> > application/ocsp-response
> > 1473026096.467     85 192.168.200.85 TCP_MISS/200 960 POST
> > http://ocsp.digicert.com/ marcio HIER_DIRECT/192.16.58.8
> > application/ocsp-response
> > 1473026102.051    525 192.168.200.85 TCP_REFRESH_UNMODIFIED/200 2907 GET
> > http://start.ubuntu.com/14.04/Google/? marcio HIER_DIRECT/91.189.90.41
> > text/html
> > 1473026102.091      0 192.168.200.85 TCP_HIT/200 22099 GET
> > http://start.ubuntu.com/12.04/sprite.png marcio HIER_NONE/- image/png
> > 1473026104.855      0 10.133.85.3 TCP_DENIED/407 3929 GET
> > http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/
> authrootstl.cab?
> > - HIER_NONE/- text/html
> > 1473026146.453     83 192.168.200.85 TCP_MISS/200 960 POST
> > http://ocsp.digicert.com/ marcio HIER_DIRECT/192.16.58.8
> > application/ocsp-response
> > 1473026147.447     83 192.168.200.85 TCP_MISS/200 960 POST
> > http://ocsp.digicert.com/ marcio HIER_DIRECT/192.16.58.8
> > application/ocsp-response
> > 1473026148.923      0 192.168.200.85 TCP_DENIED/407 3796 CONNECT
> > shavar.services.mozilla.com:443 - HIER_NONE/- text/html
> > 1473026157.117  61506 192.168.200.85 TCP_MISS/200 3525 CONNECT
> > tiles.services.mozilla.com:443 marcio HIER_DIRECT/52.24.123.95 -
> > 1473026157.195  61584 192.168.200.85 TCP_MISS/200 4521 CONNECT
> > self-repair.mozilla.org:443 marcio HIER_DIRECT/54.69.9.44 -
> > 1473026160.190 63085 192.168.200.85 TCP_MISS/200 5449 CONNECT
> > self-repair.mozilla.org:443 marcio HIER_DIRECT/54.69.9.44 -
> > 1473026204.518      0 192.168.200.85 TCP_DENIED/407 3780 CONNECT
> > safebrowsing.google.com:443 - HIER_NONE/- text/html
> > 1473026207.807  62056 192.168.200.85 TCP_MISS/200 3686 CONNECT
> > incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
> > 1473026207.808  61159 192.168.200.85 TCP_MISS/200 390 CONNECT
> > incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
> > 1473026207.808  61159 192.168.200.85 TCP_MISS/200 390 CONNECT
> > incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
> > 1473026207.808  61160 192.168.200.85 TCP_MISS/200 390 CONNECT
> > incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
> > 1473026207.809  61160 192.168.200.85 TCP_MISS/200 390 CONNECT
> > incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
> > 1473026207.814  61165 192.168.200.85 TCP_MISS/200 390 CONNECT
> > incoming.telemetry.mozilla.org:443 marcio HIER_DIRECT/52.89.83.186 -
> > 1473026207.866  61052 192.168.200.85 TCP_MISS/200 3821 CONNECT
> > aus5.mozilla.org:443 marcio HIER_DIRECT/52.34.235.152 -
> > 1473026212.687 116018 192.168.200.85 TCP_MISS/200 61971 CONNECT
> > normandy.cdn.mozilla.net:443 marcio HIER_DIRECT/52.84.177.125 -
> > 1473026264.532      0 192.168.200.85 TCP_DENIED/407 3780 CONNECT
> > safebrowsing.google.com:443 - HIER_NONE/- text/html
> > 1473026299.647      0 10.133.85.3 TCP_DENIED/407 3813 CONNECT
> > iecvlist.microsoft.com:443 - HIER_NONE/- text/html
> > 1473026335.221      0 10.133.85.3 TCP_DENIED/407 3813 CONNECT
> > ieonline.microsoft.com:443 - HIER_NONE/- text/html
> > 1473026592.061   6624 10.133.85.3 TCP_MISS/200 3582 CONNECT
> > forum.zentyal.org:443 marcio HIER_DIRECT/162.13.13.134 -
>
> Notice how the 407 occur in bunches. 2-3 getting a 407 reject, then many
> requests going through with user credentials. Then again some without
> any getting a 407.
> Those bunches of 407 will be matching some type of credentials timeout
> in the browser, or opening of new tabs.
>
>
> This request below is the only one from 192.168.200.96 so appears to be
> the one you provide cache.log trace for...
>
>
> > 1473026793.073      0 192.168.200.96 TCP_DENIED/407 3780 CONNECT
> > safebrowsing.google.com:443 - HIER_NONE/- text/html
> >
> > /var/log/squid3/cache.log
> >
> > ----------
> > 2016/09/04 19:06:33.073 kid1| client_side.cc(2407) parseHttpRequest: HTTP
> > Client local=192.168.200.7:3128 remote=192.168.200.96:56302 FD 12
> flags=1
> > 2016/09/04 19:06:33.073 kid1| client_side.cc(2408) parseHttpRequest: HTTP
> > Client REQUEST:
> > ---------
> > CONNECT safebrowsing.google.com:443 HTTP/1.1
> > User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:35.0)
> Gecko/20100101
> > Firefox/35.0
> > Proxy-Connection: keep-alive
> > Connection: keep-alive
> > Host: safebrowsing.google.com:443
>
> Notice the abence of any Proxy-Authorization header containing credentials.
>
> >
> >
> > ----------
> > 2016/09/04 19:06:33.073 kid1| client_side.cc(1459) sendStartOfMessage:
> HTTP
> > Client local=192.168.200.7:3128 remote=192.168.200.96:56302 FD 12
> flags=1
> > 2016/09/04 19:06:33.073 kid1| client_side.cc(1460) sendStartOfMessage:
> HTTP
> > Client REPLY:
> > ---------
> > HTTP/1.1 407 Proxy Authentication Required
> > Server: squid/3.4.8
> > Mime-Version: 1.0
> > Date: Sun, 04 Sep 2016 22:06:33 GMT
> > Content-Type: text/html
> > Content-Length: 3357
> > X-Squid-Error: *ERR_CACHE_ACCESS_DENIED 0*
> > Proxy-Authenticate: Basic realm="CMS"
>
> That realm="CMS" does not match the realm value of "AUTENTICACAO" which
> your earlier config contained.
>
> Unless you changed your auth_param settings that is a sign that some
> other proxy is generating that response message. BUT, your access.log
> entry shows no server being contacted.
>
>
>
> > X-Cache: MISS from proxy.cms.ensino.br
> > X-Cache-Lookup: NONE from proxy.cms.ensino.br:3128
> > Via: 1.1 proxy.cms.ensino.br (squid/3.4.8)
> > Connection: keep-alive
> >
> > ----------
> >
> > Sorry, but I didn't discover the problem!
> >
> > Anybody have an idea?
>
> If you altered your squid.conf settings as above in the auth details,
> did you also remove 192.168.200.7 from the "localhost" ACL ?
>
> Your rule "http_access allow localhost" occurs before anything that
> requires authentication. That means these requests coming from
> 192.168.200.7 to your proxy would not use authentication for the above
> CONNECT request. So no reason for your proxy to generate any 407 response.
>
>
> Amos
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160905/285d83ad/attachment.htm>

From yvoinov at gmail.com  Mon Sep  5 17:14:14 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 5 Sep 2016 23:14:14 +0600
Subject: [squid-users] Problems with Linux Worstations
In-Reply-To: <CA+0Tdyp938vvpvgSk2_L2=bhuo6MCE7FsWt=S83WT+kA7XYNwg@mail.gmail.com>
References: <CA+0TdyrGBxitJDCOgcULKsdiq5uqzs4UJEm6Ht=_RMRfatZadg@mail.gmail.com>
 <524b90be-8363-f906-1b18-d9481d8c63b3@treenet.co.nz>
 <CA+0Tdyoer7WW0Sfvy_5z5T3JQ3j_hw1Yf=mDLFtF2gJZmyMfew@mail.gmail.com>
 <5de64bba-dcc9-d809-c5b6-3f9e50da9f09@treenet.co.nz>
 <CA+0Tdyp938vvpvgSk2_L2=bhuo6MCE7FsWt=S83WT+kA7XYNwg@mail.gmail.com>
Message-ID: <6230529e-5d4a-5ae7-a78f-14ed55bee279@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


05.09.2016 22:25, Marcio Demetrio Bacci ?????:
> Hi Amos
>
> Now, my squid.conf is as follow (very simple):
>
> ############ START #################
> http_port 3128
>
> debug_options 11,2
>
> cache_mem 512 MB
> cache_swap_low 80
> cache_swap_high 90
>
> maximum_object_size 512 MB
> minimum_object_size 0 KB
>
> maximum_object_size_in_memory 4096 KB
>
> cache_replacement_policy heap LFUDA
> memory_replacement_policy heap LFUDA
>
> fqdncache_size 1024
>
> ### Parametros de atualizacao da memoria cache
> refresh_pattern ^ftp:    1440      20%    10080
> refresh_pattern ^gopher:    1440    0%    1440
> refresh_pattern -i (/cgi-bin/|\?) 0 0%     0
> refresh_pattern .        0    20%    4320
>
> ### Localizacao dos logs
> access_log /var/log/squid3/access.log
> cache_log /var/log/squid3/cache.log
>
> cache_dir aufs /var/spool/squid3 600 16 256
>
> visible_hostname proxy
>
> ### acls
> acl localhost src 192.168.200.7/32 <http://192.168.200.7/32>
> acl to_localhost dst 192.168.200.7/32 <http://192.168.200.7/32>
> acl SSL_ports port 22 443 563 7071 10000
> acl Safe_ports port 21 70 80 88 210 280 389 443 488 563 591 777
1025-65535        
>
> acl purge method PURGE
> acl CONNECT method CONNECT
>
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access deny purge
>
> auth_param basic program /usr/lib/squid3/basic_ncsa_auth
/etc/squid3/passwd
> auth_param basic children 5
> auth_param basic realm CMS
> auth_param basic credentialsttl 2 hours
> auth_param basic casesensitive off
>
> ### Exige autenticacao
> acl autenticados proxy_auth REQUIRED
> http_access deny !autenticados
>
> ### Rede do CMS #####
> acl lannet src 192.168.200.0/22 <http://192.168.200.0/22>
>
> ### Nega acesso de quem nao esta na rede local do CMS
> http_access allow lannet
> http_access allow localhost
>
> #negando o acesso para todos que nao estiverem nas regras anteriores
> http_access deny all
>
> ### Erros em portugues
> error_directory /usr/share/squid3/errors/pt-br
>
> #cache_effective_user proxy
> coredump_dir /var/spool/squid3
>
> ########## END ###########################
>
> I have some doubts:
>
> 1) I open my browser to test the authentication. It seems OK, but 
when I open new tab in browser the Squid3 ask the user and password
again. Is this normal behavior  ?
>
> 2) Is necessary to declare LOCALHOST acl as "acl localhost src
192.168.200.7/32 <http://192.168.200.7/32>" ?
#Default:
# ACLs all, manager, localhost, and to_localhost are predefined.

PS. localhost is always 127.0.0.1. You specified localnet, not localhost.

>
> 3) Isn't necessary MANAGER acl as "acl manager proto cache_object" ?
No.
>
> 4) Is correct order of the ACL in my squid.conf ? How do I improve it?
Read squid.conf.documented carefully.
>
> 5) In my access.log, I have saw many "TCP_MISS/200". Does mean only
the website is not in cache or is a strange behavior?
website is not in cache
>
>
> Sorry, but I'm still learning about Squid!
Welcome. Do not forget to do RTFM first.

A good habit is to first try to find the answers yourself. Especially
the obvious questions.
>
>
> Regards,
>
> M?rcio
>
>
>
>
> 2016-09-05 1:17 GMT-03:00 Amos Jeffries <squid3 at treenet.co.nz
<mailto:squid3 at treenet.co.nz>>:
>
>     On 5/09/2016 10:41 a.m., Marcio Demetrio Bacci wrote:
>     > I have used debug_options 11,2 in squid.conf file. After I have
following
>     > results in logs files:
>     >
>     > /var/log/squid3/access.log
>     > 1473026084.048    253 192.168.200.85 TCP_MISS_ABORTED/000 0 POST
>     > http://m.addthis.com/live/red_lojson/100eng.json
<http://m.addthis.com/live/red_lojson/100eng.json>? marcio HIER_NONE/- -
>     > 1473026086.275      0 192.168.200.85 TCP_DENIED/407 3792 CONNECT
>     > tiles.services.mozilla.com:443
<http://tiles.services.mozilla.com:443> - HIER_NONE/- text/html
>     > 1473026086.778      0 192.168.200.85 TCP_DENIED/407 3995 GET
>     > http://start.ubuntu.com/14.04/Google/
<http://start.ubuntu.com/14.04/Google/>? - HIER_NONE/- text/html
>     > 1473026088.908      0 192.168.200.85 TCP_DENIED/407 3796 CONNECT
>     > shavar.services.mozilla.com:443
<http://shavar.services.mozilla.com:443> - HIER_NONE/- text/html
>     > 1473026091.932      0 192.168.200.85 TCP_DENIED/407 3780 CONNECT
>     > self-repair.mozilla.org:443 <http://self-repair.mozilla.org:443>
- HIER_NONE/- text/html
>     > 1473026096.418    180 192.168.200.85 TCP_MISS/200 960 POST
>     > http://ocsp.digicert.com/ marcio HIER_DIRECT/192.16.58.8
<http://192.16.58.8>
>     > application/ocsp-response
>     > 1473026096.467     85 192.168.200.85 TCP_MISS/200 960 POST
>     > http://ocsp.digicert.com/ marcio HIER_DIRECT/192.16.58.8
<http://192.16.58.8>
>     > application/ocsp-response
>     > 1473026102.051    525 192.168.200.85 TCP_REFRESH_UNMODIFIED/200
2907 GET
>     > http://start.ubuntu.com/14.04/Google/
<http://start.ubuntu.com/14.04/Google/>? marcio HIER_DIRECT/91.189.90.41
<http://91.189.90.41>
>     > text/html
>     > 1473026102.091      0 192.168.200.85 TCP_HIT/200 22099 GET
>     > http://start.ubuntu.com/12.04/sprite.png
<http://start.ubuntu.com/12.04/sprite.png> marcio HIER_NONE/- image/png
>     > 1473026104.855      0 10.133.85.3 TCP_DENIED/407 3929 GET
>     >
http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab
<http://ctldl.windowsupdate.com/msdownload/update/v3/static/trustedr/en/authrootstl.cab>?
>     > - HIER_NONE/- text/html
>     > 1473026146.453     83 192.168.200.85 TCP_MISS/200 960 POST
>     > http://ocsp.digicert.com/ marcio HIER_DIRECT/192.16.58.8
<http://192.16.58.8>
>     > application/ocsp-response
>     > 1473026147.447     83 192.168.200.85 TCP_MISS/200 960 POST
>     > http://ocsp.digicert.com/ marcio HIER_DIRECT/192.16.58.8
<http://192.16.58.8>
>     > application/ocsp-response
>     > 1473026148.923      0 192.168.200.85 TCP_DENIED/407 3796 CONNECT
>     > shavar.services.mozilla.com:443
<http://shavar.services.mozilla.com:443> - HIER_NONE/- text/html
>     > 1473026157.117  61506 192.168.200.85 TCP_MISS/200 3525 CONNECT
>     > tiles.services.mozilla.com:443
<http://tiles.services.mozilla.com:443> marcio HIER_DIRECT/52.24.123.95
<http://52.24.123.95> -
>     > 1473026157.195  61584 192.168.200.85 TCP_MISS/200 4521 CONNECT
>     > self-repair.mozilla.org:443 <http://self-repair.mozilla.org:443>
marcio HIER_DIRECT/54.69.9.44 <http://54.69.9.44> -
>     > 1473026160.190 63085 192 <tel:190%20%2063085%20192>.168.200.85
TCP_MISS/200 5449 CONNECT
>     > self-repair.mozilla.org:443 <http://self-repair.mozilla.org:443>
marcio HIER_DIRECT/54.69.9.44 <http://54.69.9.44> -
>     > 1473026204.518      0 192.168.200.85 TCP_DENIED/407 3780 CONNECT
>     > safebrowsing.google.com:443 <http://safebrowsing.google.com:443>
- HIER_NONE/- text/html
>     > 1473026207.807  62056 192.168.200.85 TCP_MISS/200 3686 CONNECT
>     > incoming.telemetry.mozilla.org:443
<http://incoming.telemetry.mozilla.org:443> marcio
HIER_DIRECT/52.89.83.186 <http://52.89.83.186> -
>     > 1473026207.808  61159 192.168.200.85 TCP_MISS/200 390 CONNECT
>     > incoming.telemetry.mozilla.org:443
<http://incoming.telemetry.mozilla.org:443> marcio
HIER_DIRECT/52.89.83.186 <http://52.89.83.186> -
>     > 1473026207.808  61159 192.168.200.85 TCP_MISS/200 390 CONNECT
>     > incoming.telemetry.mozilla.org:443
<http://incoming.telemetry.mozilla.org:443> marcio
HIER_DIRECT/52.89.83.186 <http://52.89.83.186> -
>     > 1473026207.808  61160 192.168.200.85 TCP_MISS/200 390 CONNECT
>     > incoming.telemetry.mozilla.org:443
<http://incoming.telemetry.mozilla.org:443> marcio
HIER_DIRECT/52.89.83.186 <http://52.89.83.186> -
>     > 1473026207.809  61160 192.168.200.85 TCP_MISS/200 390 CONNECT
>     > incoming.telemetry.mozilla.org:443
<http://incoming.telemetry.mozilla.org:443> marcio
HIER_DIRECT/52.89.83.186 <http://52.89.83.186> -
>     > 1473026207.814  61165 192.168.200.85 TCP_MISS/200 390 CONNECT
>     > incoming.telemetry.mozilla.org:443
<http://incoming.telemetry.mozilla.org:443> marcio
HIER_DIRECT/52.89.83.186 <http://52.89.83.186> -
>     > 1473026207.866  61052 192.168.200.85 TCP_MISS/200 3821 CONNECT
>     > aus5.mozilla.org:443 <http://aus5.mozilla.org:443> marcio
HIER_DIRECT/52.34.235.152 <http://52.34.235.152> -
>     > 1473026212.687 116018 192.168.200.85 TCP_MISS/200 61971 CONNECT
>     > normandy.cdn.mozilla.net:443
<http://normandy.cdn.mozilla.net:443> marcio HIER_DIRECT/52.84.177.125
<http://52.84.177.125> -
>     > 1473026264.532      0 192.168.200.85 TCP_DENIED/407 3780 CONNECT
>     > safebrowsing.google.com:443 <http://safebrowsing.google.com:443>
- HIER_NONE/- text/html
>     > 1473026299.647      0 10.133.85.3 TCP_DENIED/407 3813 CONNECT
>     > iecvlist.microsoft.com:443 <http://iecvlist.microsoft.com:443> -
HIER_NONE/- text/html
>     > 1473026335.221      0 10.133.85.3 TCP_DENIED/407 3813 CONNECT
>     > ieonline.microsoft.com:443 <http://ieonline.microsoft.com:443> -
HIER_NONE/- text/html
>     > 1473026592.061   6624 10.133.85.3 TCP_MISS/200 3582 CONNECT
>     > forum.zentyal.org:443 <http://forum.zentyal.org:443> marcio
HIER_DIRECT/162.13.13.134 <http://162.13.13.134> -
>
>     Notice how the 407 occur in bunches. 2-3 getting a 407 reject,
then many
>     requests going through with user credentials. Then again some without
>     any getting a 407.
>     Those bunches of 407 will be matching some type of credentials timeout
>     in the browser, or opening of new tabs.
>
>
>     This request below is the only one from 192.168.200.96 so appears
to be
>     the one you provide cache.log trace for...
>
>
>     > 1473026793.073      0 192.168.200.96 TCP_DENIED/407 3780 CONNECT
>     > safebrowsing.google.com:443 <http://safebrowsing.google.com:443>
- HIER_NONE/- text/html
>     >
>     > /var/log/squid3/cache.log
>     >
>     > ----------
>     > 2016/09/04 19:06:33.073 kid1| client_side.cc(2407)
parseHttpRequest: HTTP
>     > Client local=192.168.200.7:3128 <http://192.168.200.7:3128>
remote=192.168.200.96:56302 <http://192.168.200.96:56302> FD 12 flags=1
>     > 2016/09/04 19:06:33.073 kid1| client_side.cc(2408)
parseHttpRequest: HTTP
>     > Client REQUEST:
>     > ---------
>     > CONNECT safebrowsing.google.com:443
<http://safebrowsing.google.com:443> HTTP/1.1
>     > User-Agent: Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:35.0)
Gecko/20100101
>     > Firefox/35.0
>     > Proxy-Connection: keep-alive
>     > Connection: keep-alive
>     > Host: safebrowsing.google.com:443
<http://safebrowsing.google.com:443>
>
>     Notice the abence of any Proxy-Authorization header containing
credentials.
>
>     >
>     >
>     > ----------
>     > 2016/09/04 19:06:33.073 kid1| client_side.cc(1459)
sendStartOfMessage: HTTP
>     > Client local=192.168.200.7:3128 <http://192.168.200.7:3128>
remote=192.168.200.96:56302 <http://192.168.200.96:56302> FD 12 flags=1
>     > 2016/09/04 19:06:33.073 kid1| client_side.cc(1460)
sendStartOfMessage: HTTP
>     > Client REPLY:
>     > ---------
>     > HTTP/1.1 407 Proxy Authentication Required
>     > Server: squid/3.4.8
>     > Mime-Version: 1.0
>     > Date: Sun, 04 Sep 2016 22:06:33 GMT
>     > Content-Type: text/html
>     > Content-Length: 3357
>     > X-Squid-Error: *ERR_CACHE_ACCESS_DENIED 0*
>     > Proxy-Authenticate: Basic realm="CMS"
>
>     That realm="CMS" does not match the realm value of "AUTENTICACAO"
which
>     your earlier config contained.
>
>     Unless you changed your auth_param settings that is a sign that some
>     other proxy is generating that response message. BUT, your access.log
>     entry shows no server being contacted.
>
>
>
>     > X-Cache: MISS from proxy.cms.ensino.br <http://proxy.cms.ensino.br>
>     > X-Cache-Lookup: NONE from proxy.cms.ensino.br:3128
<http://proxy.cms.ensino.br:3128>
>     > Via: 1.1 proxy.cms.ensino.br <http://proxy.cms.ensino.br>
(squid/3.4.8)
>     > Connection: keep-alive
>     >
>     > ----------
>     >
>     > Sorry, but I didn't discover the problem!
>     >
>     > Anybody have an idea?
>
>     If you altered your squid.conf settings as above in the auth details,
>     did you also remove 192.168.200.7 from the "localhost" ACL ?
>
>     Your rule "http_access allow localhost" occurs before anything that
>     requires authentication. That means these requests coming from
>     192.168.200.7 to your proxy would not use authentication for the above
>     CONNECT request. So no reason for your proxy to generate any 407
response.
>
>
>     Amos
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXzaflAAoJENNXIZxhPexG6eUH/jWH/V1FJmKWyDLDt8cTj4+Q
0cBW7KhaBvJnN0QX1t9J/AVaPP5ZY5wlsSFo6ESWd7tYo2h6UDbCLnUHADpI4DPC
nH3f8yBGL9sELL+RnUZjCV+mwwGLJPDbGquxRiJ2VVGijNj1CGrHEGQWMnZESG5D
Sz1e+9zBM62vM+40T/llgMopH7Z0NgsansWDgsFJlC9iuDzXQ3kDJ6lPG7w2HB2c
dL/jssrZg7tjDuMPJi5ZrI963GMxrbmqx8w2kTOvoLKiIYHmK6E1fSGvKtpSzXjz
PtuLqdleFGklny2n9iLBYwtPmjGCr1DBr4L7/k6Yt6GdPWaTfRQJolK5hBYm7/g=
=ObEq
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160905/012fa7cb/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160905/012fa7cb/attachment.key>

From harisrind284 at gmail.com  Mon Sep  5 18:23:23 2016
From: harisrind284 at gmail.com (sallo baloch)
Date: Mon, 5 Sep 2016 23:23:23 +0500
Subject: [squid-users] range_offset_limit not working as expected
In-Reply-To: <d6e5127b-8c07-3218-a722-78eb53b12ab4@treenet.co.nz>
References: <1473083169343-4679355.post@n4.nabble.com>
 <d6e5127b-8c07-3218-a722-78eb53b12ab4@treenet.co.nz>
Message-ID: <CAKikXHrBxf7ngix6C_pJNgB3MP5T4ZtYdSA-si9vNjb1RgJOUA@mail.gmail.com>

plz send me a squid.config file from https and http cahe

On Mon, Sep 5, 2016 at 7:09 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> What are you expecting?
>
> The Squid native format access.log shows what was delivered to the
> client, and what server was involved. It does not show how the
> range_offset_limit directive affected the server connection messages.
>
> The ORIGINAL_DST indicates that this is intercepted traffic.
>
> Notice how the TCP_MISS transactions are rotating through different IP
> addresses and using ORIGINAL_DST. That is usualy a sign that Host header
> verification is unable to match the destination domain name with the
> client contacted IP address on many transactions.
>
> There is a mix of TCP_HIT/206 when that verification succeeds in its
> matching.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160905/9e1ba94f/attachment.htm>

From omidkosari at yahoo.com  Tue Sep  6 06:32:08 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Mon, 5 Sep 2016 23:32:08 -0700 (PDT)
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <14b920b2-67b5-31c8-b85e-96eea33768f0@measurement-factory.com>
References: <1472063048224-4679147.post@n4.nabble.com>
 <3baf0e15-0dbb-8a7c-ceee-06d7d08a3b3e@measurement-factory.com>
 <1472222534649-4679207.post@n4.nabble.com>
 <1fc69717-57d1-d600-ee26-8c39a70a3665@measurement-factory.com>
 <1472298288404-4679212.post@n4.nabble.com>
 <079edebc-9f88-3cbb-d4c2-c79629b1da0a@measurement-factory.com>
 <1472375429698-4679222.post@n4.nabble.com>
 <e4ab7076-5343-9c4c-d83a-24c508bd01ad@measurement-factory.com>
 <1472478056062-4679239.post@n4.nabble.com>
 <14b920b2-67b5-31c8-b85e-96eea33768f0@measurement-factory.com>
Message-ID: <1473143528034-4679361.post@n4.nabble.com>

Filed a bug report http://bugs.squid-cache.org/show_bug.cgi?id=4585



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TCP-RESET-non-http-requests-on-port-80-tp4679102p4679361.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From omidkosari at yahoo.com  Tue Sep  6 09:14:50 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Tue, 6 Sep 2016 02:14:50 -0700 (PDT)
Subject: [squid-users] range_offset_limit not working as expected
In-Reply-To: <d6e5127b-8c07-3218-a722-78eb53b12ab4@treenet.co.nz>
References: <1473083169343-4679355.post@n4.nabble.com>
 <d6e5127b-8c07-3218-a722-78eb53b12ab4@treenet.co.nz>
Message-ID: <1473153290520-4679362.post@n4.nabble.com>

It is tproxy cache . Is there a way to force caching them .
current configs:
host_verify_strict off
client_dst_passthru on

dns_nameservers x.y.160.172
dns_nameservers 217.218.155.155
dns_nameservers 217.218.127.127
dns_nameservers 8.8.8.8
dns_nameservers 8.8.4.4
dns_nameservers 208.67.222.222
dns_nameservers 208.67.220.220
dns_nameservers 208.67.222.220
dns_nameservers 208.67.220.222

The first dns server is our caching dns server and its parents dns servers
are the others which appears in this config . Users dns traffic intercepted
to x.y.160.172 .

So the problem seems the cdn dns round-robin . Is there a way to solve that
?




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/range-offset-limit-not-working-as-expected-tp4679355p4679362.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From mailfaheem86 at gmail.com  Tue Sep  6 10:01:10 2016
From: mailfaheem86 at gmail.com (Faheem)
Date: Tue, 6 Sep 2016 15:31:10 +0530
Subject: [squid-users] Squid CPU usage in cachemgr.cgi
Message-ID: <CAF1uRGayDcQ3wMyjVP-=W6AypZLtbbRHc3_BWNt0h7z5ADShJg@mail.gmail.com>

Hello,

I am trying to setup proper monitoring for our squid farm so that we will
be alerted when there is a performance issue. I was looking at several
statistics of squid available in cachemgr.cgi and see the below. I am a bit
confused about the CPU usage stats shown in the cachemanager. If I go to 5
Minute Average of Counters in cachemanager it says "cpu_usage = 24.008036%"

What does this actually mean? Is this inclusive of all 4 cores in my
server? We have CPU affinity set for squid process and it uses all 4
available cores. So does 100% mean that all 4 cores are fully being
utilized? Which parameter would be the best one to look at to understand
the real CPU usage.


Thanks,
meeh.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160906/9ae8a108/attachment.htm>

From yvoinov at gmail.com  Tue Sep  6 10:35:44 2016
From: yvoinov at gmail.com (Yuri)
Date: Tue, 6 Sep 2016 16:35:44 +0600
Subject: [squid-users] Squid CPU usage in cachemgr.cgi
In-Reply-To: <CAF1uRGayDcQ3wMyjVP-=W6AypZLtbbRHc3_BWNt0h7z5ADShJg@mail.gmail.com>
References: <CAF1uRGayDcQ3wMyjVP-=W6AypZLtbbRHc3_BWNt0h7z5ADShJg@mail.gmail.com>
Message-ID: <5bb8bf78-4a16-b35d-52ed-61916b053e32@gmail.com>

http://wiki.squid-cache.org/KnowledgeBase/PerformanceAnalysis

http://wiki.squid-cache.org/SquidFaq/SquidProfiling


06.09.2016 16:01, Faheem ?????:
> Hello,
>
> I am trying to setup proper monitoring for our squid farm so that we 
> will be alerted when there is a performance issue. I was looking at 
> several statistics of squid available in cachemgr.cgi and see the 
> below. I am a bit confused about the CPU usage stats shown in the 
> cachemanager. If I go to 5 Minute Average of Counters in cachemanager 
> it says "cpu_usage = 24.008036%"
>
> What does this actually mean? Is this inclusive of all 4 cores in my 
> server? We have CPU affinity set for squid process and it uses all 4 
> available cores. So does 100% mean that all 4 cores are fully being 
> utilized? Which parameter would be the best one to look at to 
> understand the real CPU usage.
>
>
> Thanks,
> meeh.
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160906/74ad97cb/attachment.htm>

From squid3 at treenet.co.nz  Tue Sep  6 11:25:02 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 6 Sep 2016 23:25:02 +1200
Subject: [squid-users] range_offset_limit not working as expected
In-Reply-To: <1473153290520-4679362.post@n4.nabble.com>
References: <1473083169343-4679355.post@n4.nabble.com>
 <d6e5127b-8c07-3218-a722-78eb53b12ab4@treenet.co.nz>
 <1473153290520-4679362.post@n4.nabble.com>
Message-ID: <1444ed08-fc1b-d7b9-f54d-39a94d727346@treenet.co.nz>

On 6/09/2016 9:14 p.m., Omid Kosari wrote:
> It is tproxy cache . Is there a way to force caching them .

No, and trying to do so is a VERY bad idea. I cannot stress enough how
bad it is.  Allowing remote attackers to completely (and invisibly)
bypass almost all other security measures you might have in your
network, just for starters.

I fully realise that not being able to cache a fairly large chunk of CDN
hosted traffic is extremely annoying and also can be costly. But the
risks of this particular vulnerability outweight that price tag.


> current configs:
> host_verify_strict off
> client_dst_passthru on
> 
> dns_nameservers x.y.160.172
> dns_nameservers 217.218.155.155
> dns_nameservers 217.218.127.127
> dns_nameservers 8.8.8.8
> dns_nameservers 8.8.4.4
> dns_nameservers 208.67.222.222
> dns_nameservers 208.67.220.220
> dns_nameservers 208.67.222.220
> dns_nameservers 208.67.220.222
> 
> The first dns server is our caching dns server and its parents dns servers
> are the others which appears in this config . Users dns traffic intercepted
> to x.y.160.172 .
> 
> So the problem seems the cdn dns round-robin . Is there a way to solve that
> ?

Use only that first DNS server in your squid.conf. Using it as an
aggregation point reduces the impact, but only if it is also the sole
point of resolving for Squid.
 NP: this is not a fix, just a workaround to reduce impact until Squid
DNS system can be updated to do things better.

Amos



From ahmed.zaeem at netstream.ps  Tue Sep  6 12:04:23 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 6 Sep 2016 15:04:23 +0300
Subject: [squid-users] regarding to "cache videos" plugin now as open source
Message-ID: <4A92237B-E2C4-4026-AEE7-AEB0DA555956@netstream.ps>

hi squid users 

just a question

since the plugin that is called ?cache videos ? became now free and open source 

why i don?t see many users dealing with it ??

isn?t it  open source  now ??


i don?t see here  guys who ask about it 

just curious to know why 


cheers



From mailfaheem86 at gmail.com  Tue Sep  6 12:04:11 2016
From: mailfaheem86 at gmail.com (Faheem)
Date: Tue, 6 Sep 2016 17:34:11 +0530
Subject: [squid-users] Squid CPU usage in cachemgr.cgi
In-Reply-To: <5bb8bf78-4a16-b35d-52ed-61916b053e32@gmail.com>
References: <CAF1uRGayDcQ3wMyjVP-=W6AypZLtbbRHc3_BWNt0h7z5ADShJg@mail.gmail.com>
 <5bb8bf78-4a16-b35d-52ed-61916b053e32@gmail.com>
Message-ID: <CAF1uRGZ=6w-58YJqASiyiNm7WphWTGhd_tHv7t0D7asiSNC4Kw@mail.gmail.com>

Thanks for that. But do you know the CPU usage shown in the cache manager
is 24% of the total 4 CPU cores? If it says 100% does that mean that all 4
cores are fully utilized?


On Tue, Sep 6, 2016 at 4:05 PM, Yuri <yvoinov at gmail.com> wrote:

> http://wiki.squid-cache.org/KnowledgeBase/PerformanceAnalysis
>
> http://wiki.squid-cache.org/SquidFaq/SquidProfiling
>
> 06.09.2016 16:01, Faheem ?????:
>
> Hello,
>
> I am trying to setup proper monitoring for our squid farm so that we will
> be alerted when there is a performance issue. I was looking at several
> statistics of squid available in cachemgr.cgi and see the below. I am a bit
> confused about the CPU usage stats shown in the cachemanager. If I go to 5
> Minute Average of Counters in cachemanager it says "cpu_usage = 24.008036%"
>
> What does this actually mean? Is this inclusive of all 4 cores in my
> server? We have CPU affinity set for squid process and it uses all 4
> available cores. So does 100% mean that all 4 cores are fully being
> utilized? Which parameter would be the best one to look at to understand
> the real CPU usage.
>
>
> Thanks,
> meeh.
>
>
> _______________________________________________
> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160906/77dd9891/attachment.htm>

From yvoinov at gmail.com  Tue Sep  6 12:06:41 2016
From: yvoinov at gmail.com (Yuri)
Date: Tue, 6 Sep 2016 18:06:41 +0600
Subject: [squid-users] regarding to "cache videos" plugin now as open
 source
In-Reply-To: <4A92237B-E2C4-4026-AEE7-AEB0DA555956@netstream.ps>
References: <4A92237B-E2C4-4026-AEE7-AEB0DA555956@netstream.ps>
Message-ID: <591347b3-2572-0c66-791c-53cee3a4e150@gmail.com>

In world of the huge number of all kinds of software. We do not have 
even heard of it, not what to use.


06.09.2016 18:04, --Ahmad-- ?????:
> hi squid users
>
> just a question
>
> since the plugin that is called ?cache videos ? became now free and open source
>
> why i don?t see many users dealing with it ??
>
> isn?t it  open source  now ??
>
>
> i don?t see here  guys who ask about it
>
> just curious to know why
>
>
> cheers
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Tue Sep  6 12:08:52 2016
From: yvoinov at gmail.com (Yuri)
Date: Tue, 6 Sep 2016 18:08:52 +0600
Subject: [squid-users] Squid CPU usage in cachemgr.cgi
In-Reply-To: <CAF1uRGZ=6w-58YJqASiyiNm7WphWTGhd_tHv7t0D7asiSNC4Kw@mail.gmail.com>
References: <CAF1uRGayDcQ3wMyjVP-=W6AypZLtbbRHc3_BWNt0h7z5ADShJg@mail.gmail.com>
 <5bb8bf78-4a16-b35d-52ed-61916b053e32@gmail.com>
 <CAF1uRGZ=6w-58YJqASiyiNm7WphWTGhd_tHv7t0D7asiSNC4Kw@mail.gmail.com>
Message-ID: <656683d7-0036-564e-ed44-cd142cb7983c@gmail.com>

How I know something. In the light of dozens of different operating 
systems. Check the source code, they are also open. Even the top is not 
too reliably shows the load across multiple cores. By the way, SQUID, 
except in very specific configurations, running on a single core.


06.09.2016 18:04, Faheem ?????:
> Thanks for that. But do you know the CPU usage shown in the cache 
> manager is 24% of the total 4 CPU cores? If it says 100% does that 
> mean that all 4 cores are fully utilized?
>
>
> On Tue, Sep 6, 2016 at 4:05 PM, Yuri <yvoinov at gmail.com 
> <mailto:yvoinov at gmail.com>> wrote:
>
>     http://wiki.squid-cache.org/KnowledgeBase/PerformanceAnalysis
>     <http://wiki.squid-cache.org/KnowledgeBase/PerformanceAnalysis>
>
>     http://wiki.squid-cache.org/SquidFaq/SquidProfiling
>     <http://wiki.squid-cache.org/SquidFaq/SquidProfiling>
>
>
>     06.09.2016 16:01, Faheem ?????:
>>     Hello,
>>
>>     I am trying to setup proper monitoring for our squid farm so that
>>     we will be alerted when there is a performance issue. I was
>>     looking at several statistics of squid available in cachemgr.cgi
>>     and see the below. I am a bit confused about the CPU usage stats
>>     shown in the cachemanager. If I go to 5 Minute Average of
>>     Counters in cachemanager it says "cpu_usage = 24.008036%"
>>
>>     What does this actually mean? Is this inclusive of all 4 cores in
>>     my server? We have CPU affinity set for squid process and it uses
>>     all 4 available cores. So does 100% mean that all 4 cores are
>>     fully being utilized? Which parameter would be the best one to
>>     look at to understand the real CPU usage.
>>
>>
>>     Thanks,
>>     meeh.
>>
>>
>>     _______________________________________________
>>     squid-users mailing list
>>     squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org>
>>     http://lists.squid-cache.org/listinfo/squid-users
>>     <http://lists.squid-cache.org/listinfo/squid-users>
>     _______________________________________________ squid-users
>     mailing list squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users> 
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160906/57aa46e3/attachment.htm>

From marco.calegari2000 at gmail.com  Tue Sep  6 12:58:40 2016
From: marco.calegari2000 at gmail.com (Marco Calegari)
Date: Tue, 6 Sep 2016 14:58:40 +0200
Subject: [squid-users] squid and files cache between multiple pc
Message-ID: <CAORw=UUURY4ZxKsw8p4NDvoHd4z4vZn4Hn=kTiJWk0NbxUhdhQ@mail.gmail.com>

hi all
I've a strange problem with squid v3.1.20

Using squid also to cache "big" files (for big I mean >20Mb), happens that
if a pc download a file, first time file has downloaded from internet.
Second time from squid cache. Everything ok But: if I try to download same
file from another pc, same file come downloaded from internet and not via
squid.

Why?

thanks!

maximum_object_size 5 Gb
cache_dir ufs /data/vmware/squid-cache 30720 16 256
cache_mem 4096 MB

minimum_object_size 0
maximum_object_size_in_memory 512 Kb
cache_replacement_policy heap GDSF

cache_swap_low 85
cache_swap_high 90

half_closed_clients off

hosts_file /etc/hosts
memory_pools off
client_db off
dns_nameservers 127.0.0.1

via off
forwarded_for off
httpd_suppress_version_string off
follow_x_forwarded_for deny all
#visible_hostname sign.bunker.org

refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i \.(gif|png|jpg|jpeg|ico)$ 10080 90% 43200
override-expire ignore-no-cache ignore-no-store ignore-private
refresh_pattern -i \.(iso|avi|wav|mp3|mp4|mpeg|swf|flv|x-flv)$ 43200 90%
432000 override-expire ignore-no-cache ignore-no-store ignore-private
refresh_pattern -i \.(deb|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff)$
10080 90% 43200 override-expire ignore-no-cache ignore-no-store
ignore-private
refresh_pattern -i \.index.(html|htm)$ 0 40% 10080
refresh_pattern -i \.(html|htm|css|js)$ 1440 40% 40320
refresh_pattern . 0 40% 40320

refresh_pattern -i movies.com/.* 10080 90% 43200
refresh_pattern (*/cgi-bin/*|\?) 0 0% 0
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160906/5dd0d6d6/attachment.htm>

From Antony.Stone at squid.open.source.it  Tue Sep  6 13:22:27 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 6 Sep 2016 15:22:27 +0200
Subject: [squid-users] squid and files cache between multiple pc
In-Reply-To: <CAORw=UUURY4ZxKsw8p4NDvoHd4z4vZn4Hn=kTiJWk0NbxUhdhQ@mail.gmail.com>
References: <CAORw=UUURY4ZxKsw8p4NDvoHd4z4vZn4Hn=kTiJWk0NbxUhdhQ@mail.gmail.com>
Message-ID: <201609061522.27466.Antony.Stone@squid.open.source.it>

On Tuesday 06 September 2016 at 14:58:40, Marco Calegari wrote:

> hi all
> I've a strange problem with squid v3.1.20

That is over four years old.  You should upgrade.

> Using squid also to cache "big" files (for big I mean >20Mb), happens that
> if a pc download a file, first time file has downloaded from internet.
> Second time from squid cache. Everything ok But: if I try to download same
> file from another pc, same file come downloaded from internet and not via
> squid.
> 
> Why?

Thanks for including your squid.conf - that is useful.

However, we also need to see the access.log lines which are generated by the 
three requests:

1. Original request (which downloads from the Internet) from PC1

2. Second request (which gets cached content) from PC1

3. First request (which download from the Internet again) from PC2

By the way, can you confirm that small files do not have the same problem, and 
the cached copy gets sent to PC2 in request number 3 above?


Thanks,


Antony.

-- 
I bought a book about anti-gravity.  The reviews say you can't put it down.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From uhlar at fantomas.sk  Tue Sep  6 14:36:20 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 6 Sep 2016 16:36:20 +0200
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <1473143528034-4679361.post@n4.nabble.com>
References: <3baf0e15-0dbb-8a7c-ceee-06d7d08a3b3e@measurement-factory.com>
 <1472222534649-4679207.post@n4.nabble.com>
 <1fc69717-57d1-d600-ee26-8c39a70a3665@measurement-factory.com>
 <1472298288404-4679212.post@n4.nabble.com>
 <079edebc-9f88-3cbb-d4c2-c79629b1da0a@measurement-factory.com>
 <1472375429698-4679222.post@n4.nabble.com>
 <e4ab7076-5343-9c4c-d83a-24c508bd01ad@measurement-factory.com>
 <1472478056062-4679239.post@n4.nabble.com>
 <14b920b2-67b5-31c8-b85e-96eea33768f0@measurement-factory.com>
 <1473143528034-4679361.post@n4.nabble.com>
Message-ID: <20160906143620.GA15684@fantomas.sk>

On 05.09.16 23:32, Omid Kosari wrote:
>Filed a bug report http://bugs.squid-cache.org/show_bug.cgi?id=4585

I wonder if this is doable at all.

when squid accepts a connnection, it only can close it without noticing.

Does any tcp stack allow sending reset AFTER the connection has been
opened?

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
LSD will make your ECS screen display 16.7 million colors


From omidkosari at yahoo.com  Tue Sep  6 14:48:18 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Tue, 6 Sep 2016 07:48:18 -0700 (PDT)
Subject: [squid-users] Windows Updates a Caching Stub zone,
	A windows updates store.
In-Reply-To: <004a01d1daf3$e6c4a490$b44dedb0$@ngtech.co.il>
References: <004a01d1daf3$e6c4a490$b44dedb0$@ngtech.co.il>
Message-ID: <1473173298160-4679373.post@n4.nabble.com>

Hey Eliezer,

According to these threads
http://squid-web-proxy-cache.1019090.n4.nabble.com/range-offset-limit-not-working-as-expected-td4679355.html

http://squid-web-proxy-cache.1019090.n4.nabble.com/TProxy-and-client-dst-passthru-td4670189.html

Is there any chance that you implement something that may be used for other
(206 partial) popular sites like download.cdn.mozilla.net . I think it has
also same problem as windows update and has lots of uncachable requests .

Thanks in advance .



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Windows-Updates-a-Caching-Stub-zone-A-windows-updates-store-tp4678454p4679373.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From ahmed.zaeem at netstream.ps  Tue Sep  6 14:59:36 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 6 Sep 2016 17:59:36 +0300
Subject: [squid-users] windows update not working squid 3.5.2
Message-ID: <763AFEA6-52DE-4DCB-805D-DA1136933178@netstream.ps>

hi squid users .

I?m trying to catch windows updates as cached object 
im testing with  windows 10 pc

i see all request as tcp_miss and the caching store is not getting increase .

=========
1473173748.014   3603 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173748.022  12146 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173748.057   5321 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173748.155   3684 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173748.355   4832 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173748.612  12645 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173748.650   7276 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173748.720  12654 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173748.816   5064 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173749.022   4159 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173749.048   5618 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173749.177   7817 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173749.208   3383 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173749.318   5096 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173749.395   3986 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173749.850  13837 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173750.015    914 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173750.029   1365 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473173750.420   7126 192.168.0.10 TCP_MISS/206 1049229 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream

=======================

root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# 

==============
here is squid config :

root at raspberrypi:~# cat /etc/squid/squid.conf
#########
acl windowsupdate dstdomain windowsupdate.microsoft.com
acl windowsupdate dstdomain .update.microsoft.com
acl windowsupdate dstdomain download.windowsupdate.com
acl windowsupdate dstdomain redir.metaservices.microsoft.com
acl windowsupdate dstdomain images.metaservices.microsoft.com
acl windowsupdate dstdomain c.microsoft.com
acl windowsupdate dstdomain www.download.windowsupdate.com
acl windowsupdate dstdomain wustat.windows.com
acl windowsupdate dstdomain crl.microsoft.com
acl windowsupdate dstdomain sls.microsoft.com
acl windowsupdate dstdomain productactivation.one.microsoft.com
acl windowsupdate dstdomain ntservicepack.microsoft.com

acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com

#######################
refresh_pattern -i microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
refresh_pattern -i windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
refresh_pattern -i windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
# DONT MODIFY THESE LINES
refresh_pattern \^ftp:           1440    20%     10080
refresh_pattern \^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
#################################################################
###########################
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT


http_access allow CONNECT wuCONNECT localnet
http_access allow windowsupdate localnet
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager


http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.0.1:3128

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/cache/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid


#############
range_offset_limit 200 MB windowsupdate
maximum_object_size 200 MB
quick_abort_min -1
#########
http_port 3129 intercept
maximum_object_size 200000 KB




thank you 



From yvoinov at gmail.com  Tue Sep  6 15:01:21 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 6 Sep 2016 21:01:21 +0600
Subject: [squid-users] windows update not working squid 3.5.2
In-Reply-To: <763AFEA6-52DE-4DCB-805D-DA1136933178@netstream.ps>
References: <763AFEA6-52DE-4DCB-805D-DA1136933178@netstream.ps>
Message-ID: <20f02386-6272-0489-4f31-4f41051a1fa0@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
http://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates

Did you read this?


06.09.2016 20:59, --Ahmad-- ?????:
> hi squid users .
>
> I?m trying to catch windows updates as cached object
> im testing with  windows 10 pc
>
> i see all request as tcp_miss and the caching store is not getting
increase .
>
> =========
> 1473173748.014   3603 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173748.022  12146 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173748.057   5321 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173748.155   3684 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173748.355   4832 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173748.612  12645 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173748.650   7276 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173748.720  12654 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173748.816   5064 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173749.022   4159 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173749.048   5618 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173749.177   7817 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173749.208   3383 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173749.318   5096 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173749.395   3986 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173749.850  13837 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173750.015    914 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173750.029   1365 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473173750.420   7126 192.168.0.10 TCP_MISS/206 1049229 GET
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream
>
> =======================
>
> root at raspberrypi:~# du -sh /var/cache/squid/
> 17M     /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 17M     /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 17M     /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 17M     /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 17M     /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 17M     /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 17M     /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 17M     /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 17M     /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 17M     /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 17M     /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 17M     /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 17M     /var/cache/squid/
> root at raspberrypi:~#
>
> ==============
> here is squid config :
>
> root at raspberrypi:~# cat /etc/squid/squid.conf
> #########
> acl windowsupdate dstdomain windowsupdate.microsoft.com
> acl windowsupdate dstdomain .update.microsoft.com
> acl windowsupdate dstdomain download.windowsupdate.com
> acl windowsupdate dstdomain redir.metaservices.microsoft.com
> acl windowsupdate dstdomain images.metaservices.microsoft.com
> acl windowsupdate dstdomain c.microsoft.com
> acl windowsupdate dstdomain www.download.windowsupdate.com
> acl windowsupdate dstdomain wustat.windows.com
> acl windowsupdate dstdomain crl.microsoft.com
> acl windowsupdate dstdomain sls.microsoft.com
> acl windowsupdate dstdomain productactivation.one.microsoft.com
> acl windowsupdate dstdomain ntservicepack.microsoft.com
>
> acl CONNECT method CONNECT
> acl wuCONNECT dstdomain www.update.microsoft.com
> acl wuCONNECT dstdomain sls.microsoft.com
>
> #######################
> refresh_pattern -i
microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
43200 reload-into-ims
> refresh_pattern -i
windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320
80% 43200 reload-into-ims
> refresh_pattern -i
windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
43200 reload-into-ims
> # DONT MODIFY THESE LINES
> refresh_pattern \^ftp:           1440    20%     10080
> refresh_pattern \^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> #################################################################
> ###########################
> #
> # Recommended minimum configuration:
> #
>
> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly
plugged) machines
>
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
>
>
> http_access allow CONNECT wuCONNECT localnet
> http_access allow windowsupdate localnet
> http_access deny !Safe_ports
>
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
>
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
>
>
> http_access allow localnet
> http_access allow localhost
>
> # And finally deny all other access to this proxy
> http_access deny all
>
> # Squid normally listens to port 3128
> http_port 192.168.0.1:3128
>
> # Uncomment and adjust the following to add a disk cache directory.
> cache_dir ufs /var/cache/squid 100 16 256
>
> # Leave coredumps in the first cache dir
> coredump_dir /var/cache/squid
>
>
> #############
> range_offset_limit 200 MB windowsupdate
> maximum_object_size 200 MB
> quick_abort_min -1
> #########
> http_port 3129 intercept
> maximum_object_size 200000 KB
>
>
>
>
> thank you
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXztpBAAoJENNXIZxhPexGSx4H/0bK8485yWhpNbGUIGtwvx9h
PTuRhfJP+f8xoTbTh/zH1TgXs21M953uf5DoYlynMBSeVXCfQQiUhDOs+0bqAjfD
JsLCXVpZdSYYWyX2aErjfZqKQO67aVkX+zJbAY/zlTJKG6Gxg1+ssQSEJaFWu6cK
J8KBudfWaKmPc9xdiZRfYFE6LKBSeQr93BqBF6s1SwdAPKEkspQmDTuqPZEwMwW5
zQfuI/HnIvynSE+SxCFYOAwka2zVAdewXfVyWqYyFCHaHnDkXkPmK/5zZJDOmqGi
erifbGQHRHAFWNnT4mMsHGjM3Wfz1bbhr+j+tZJkY4x116eVUMrVbbXRApY5nn0=
=ZaFG
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160906/1812792d/attachment.key>

From ahmed.zaeem at netstream.ps  Tue Sep  6 15:13:40 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 6 Sep 2016 18:13:40 +0300
Subject: [squid-users] windows update not working squid 3.5.2
In-Reply-To: <20f02386-6272-0489-4f31-4f41051a1fa0@gmail.com>
References: <763AFEA6-52DE-4DCB-805D-DA1136933178@netstream.ps>
 <20f02386-6272-0489-4f31-4f41051a1fa0@gmail.com>
Message-ID: <493238DC-C305-42CB-A373-68644FA8A243@netstream.ps>

yes i did .

here is conf file  again :
#########
acl windowsupdate dstdomain windowsupdate.microsoft.com <http://windowsupdate.microsoft.com/>
acl windowsupdate dstdomain .update.microsoft.com <http://update.microsoft.com/>
acl windowsupdate dstdomain download.windowsupdate.com <http://download.windowsupdate.com/>
acl windowsupdate dstdomain redir.metaservices.microsoft.com <http://redir.metaservices.microsoft.com/>
acl windowsupdate dstdomain images.metaservices.microsoft.com <http://images.metaservices.microsoft.com/>
acl windowsupdate dstdomain c.microsoft.com <http://c.microsoft.com/>
acl windowsupdate dstdomain www.download.windowsupdate.com <http://www.download.windowsupdate.com/>
acl windowsupdate dstdomain wustat.windows.com <http://wustat.windows.com/>
acl windowsupdate dstdomain crl.microsoft.com <http://crl.microsoft.com/>
acl windowsupdate dstdomain sls.microsoft.com <http://sls.microsoft.com/>
acl windowsupdate dstdomain productactivation.one.microsoft.com <http://productactivation.one.microsoft.com/>
acl windowsupdate dstdomain ntservicepack.microsoft.com <http://ntservicepack.microsoft.com/>

acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com <http://www.update.microsoft.com/>
acl wuCONNECT dstdomain sls.microsoft.com <http://sls.microsoft.com/>

#http_access allow CONNECT wuCONNECT localnet
#http_access allow windowsupdate localnet
#######################
# Updates: Windows
refresh_pattern -i windowsupdate.com/.* <http://windowsupdate.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i microsoft.com/.* <http://microsoft.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i windows.com/.* <http://windows.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i microsoft.com.akadns.net/.* <http://microsoft.com.akadns.net/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i deploy.akamaitechnologies.com/.* <http://deploy.akamaitechnologies.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
###########
refresh_pattern -i microsoft.com/.* <http://microsoft.com/.*>\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
refresh_pattern -i windowsupdate.com/.* <http://windowsupdate.com/.*>\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
refresh_pattern -i windows.com/.* <http://windows.com/.*>\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
# DONT MODIFY THESE LINES
refresh_pattern \^ftp:           1440    20%     10080
refresh_pattern \^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
#################################################################
###########################
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access allow CONNECT wuCONNECT localnet
http_access allow windowsupdate localnet
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.0.1:3128

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/cache/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
#refresh_pattern ^ftp:          1440    20%     10080
#refresh_pattern ^gopher:       1440    0%      1440
#refresh_pattern -i (/cgi-bin/|\?) 0    0%      0
#refresh_pattern .              0       20%     4320
#############
range_offset_limit 5 Gb windowsupdate
maximum_object_size 5 Gb
quick_abort_min -1
#########
http_port 3129 intercept
#####################



cheers
>> 
>> =======================
>> 
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~#
>> 
>> ==============
>> here is squid config :
>> 
>> root at raspberrypi:~# cat /etc/squid/squid.conf
>> #########
>> acl windowsupdate dstdomain windowsupdate.microsoft.com
>> acl windowsupdate dstdomain .update.microsoft.com
>> acl windowsupdate dstdomain download.windowsupdate.com
>> acl windowsupdate dstdomain redir.metaservices.microsoft.com
>> acl windowsupdate dstdomain images.metaservices.microsoft.com
>> acl windowsupdate dstdomain c.microsoft.com
>> acl windowsupdate dstdomain www.download.windowsupdate.com
>> acl windowsupdate dstdomain wustat.windows.com
>> acl windowsupdate dstdomain crl.microsoft.com
>> acl windowsupdate dstdomain sls.microsoft.com
>> acl windowsupdate dstdomain productactivation.one.microsoft.com
>> acl windowsupdate dstdomain ntservicepack.microsoft.com
>> 
>> acl CONNECT method CONNECT
>> acl wuCONNECT dstdomain www.update.microsoft.com
>> acl wuCONNECT dstdomain sls.microsoft.com
>> 
>> #######################
>> refresh_pattern -i
> microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
> 43200 reload-into-ims
>> refresh_pattern -i
> windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320
> 80% 43200 reload-into-ims
>> refresh_pattern -i
> windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
> 43200 reload-into-ims
>> # DONT MODIFY THESE LINES
>> refresh_pattern \^ftp:           1440    20%     10080
>> refresh_pattern \^gopher:        1440    0%      1440
>> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
>> refresh_pattern .               0       20%     4320
>> #################################################################
>> ###########################
>> #
>> # Recommended minimum configuration:
>> #
>> 
>> # Example rule allowing access from your local networks.
>> # Adapt to list your (internal) IP networks from where browsing
>> # should be allowed
>> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
>> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
>> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
>> acl localnet src fc00::/7       # RFC 4193 local private network range
>> acl localnet src fe80::/10      # RFC 4291 link-local (directly
> plugged) machines
>> 
>> acl SSL_ports port 443
>> acl Safe_ports port 80          # http
>> acl Safe_ports port 21          # ftp
>> acl Safe_ports port 443         # https
>> acl Safe_ports port 70          # gopher
>> acl Safe_ports port 210         # wais
>> acl Safe_ports port 1025-65535  # unregistered ports
>> acl Safe_ports port 280         # http-mgmt
>> acl Safe_ports port 488         # gss-http
>> acl Safe_ports port 591         # filemaker
>> acl Safe_ports port 777         # multiling http
>> acl CONNECT method CONNECT
>> 
>> 
>> http_access allow CONNECT wuCONNECT localnet
>> http_access allow windowsupdate localnet
>> http_access deny !Safe_ports
>> 
>> # Deny CONNECT to other than secure SSL ports
>> http_access deny CONNECT !SSL_ports
>> 
>> # Only allow cachemgr access from localhost
>> http_access allow localhost manager
>> http_access deny manager
>> 
>> 
>> http_access allow localnet
>> http_access allow localhost
>> 
>> # And finally deny all other access to this proxy
>> http_access deny all
>> 
>> # Squid normally listens to port 3128
>> http_port 192.168.0.1:3128
>> 
>> # Uncomment and adjust the following to add a disk cache directory.
>> cache_dir ufs /var/cache/squid 100 16 256
>> 
>> # Leave coredumps in the first cache dir
>> coredump_dir /var/cache/squid
>> 
>> 
>> #############
>> range_offset_limit 200 MB windowsupdate
>> maximum_object_size 200 MB
>> quick_abort_min -1
>> #########
>> http_port 3129 intercept
>> maximum_object_size 200000 KB
>> 
>> 
>> 
>> 
>> thank you
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
> 
> iQEcBAEBCAAGBQJXztpBAAoJENNXIZxhPexGSx4H/0bK8485yWhpNbGUIGtwvx9h
> PTuRhfJP+f8xoTbTh/zH1TgXs21M953uf5DoYlynMBSeVXCfQQiUhDOs+0bqAjfD
> JsLCXVpZdSYYWyX2aErjfZqKQO67aVkX+zJbAY/zlTJKG6Gxg1+ssQSEJaFWu6cK
> J8KBudfWaKmPc9xdiZRfYFE6LKBSeQr93BqBF6s1SwdAPKEkspQmDTuqPZEwMwW5
> zQfuI/HnIvynSE+SxCFYOAwka2zVAdewXfVyWqYyFCHaHnDkXkPmK/5zZJDOmqGi
> erifbGQHRHAFWNnT4mMsHGjM3Wfz1bbhr+j+tZJkY4x116eVUMrVbbXRApY5nn0=
> =ZaFG
> -----END PGP SIGNATURE-----
> 
> <0x613DEC46.asc>_______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160906/7961e78a/attachment.htm>

From yvoinov at gmail.com  Tue Sep  6 15:15:59 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 6 Sep 2016 21:15:59 +0600
Subject: [squid-users] windows update not working squid 3.5.2
In-Reply-To: <A2272412-2369-4C9A-928A-A43D19E331D7@gmail.com>
References: <763AFEA6-52DE-4DCB-805D-DA1136933178@netstream.ps>
 <20f02386-6272-0489-4f31-4f41051a1fa0@gmail.com>
 <A2272412-2369-4C9A-928A-A43D19E331D7@gmail.com>
Message-ID: <34c3f7ad-4f9e-cc77-fb07-2ef442b9c0be@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Well, let's see.

06.09.2016 21:12, Ahmed Alzaeem ?????:
> yes i did .
>
> here is conf file  again :
> #########
> acl windowsupdate dstdomain windowsupdate.microsoft.com
> acl windowsupdate dstdomain .update.microsoft.com
> acl windowsupdate dstdomain download.windowsupdate.com
> acl windowsupdate dstdomain redir.metaservices.microsoft.com
> acl windowsupdate dstdomain images.metaservices.microsoft.com
> acl windowsupdate dstdomain c.microsoft.com
> acl windowsupdate dstdomain www.download.windowsupdate.com
> acl windowsupdate dstdomain wustat.windows.com
> acl windowsupdate dstdomain crl.microsoft.com
> acl windowsupdate dstdomain sls.microsoft.com
> acl windowsupdate dstdomain productactivation.one.microsoft.com
> acl windowsupdate dstdomain ntservicepack.microsoft.com
>
> acl CONNECT method CONNECT
> acl wuCONNECT dstdomain www.update.microsoft.com
> acl wuCONNECT dstdomain sls.microsoft.com
>
> #http_access allow CONNECT wuCONNECT localnet
> #http_access allow windowsupdate localnet
> #######################
> # Updates: Windows
> refresh_pattern -i
windowsupdate.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf)
43200 80% 129600 reload-into-ims
> refresh_pattern -i
microsoft.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200
80% 129600 reload-into-ims
> refresh_pattern -i
windows.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200
80% 129600 reload-into-ims
> refresh_pattern -i
microsoft.com.akadns.net/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf)
43200 80% 129600 reload-into-ims
> refresh_pattern -i
deploy.akamaitechnologies.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf)
43200 80% 129600 reload-into-ims
> ###########

> refresh_pattern -i
microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
43200 reload-into-ims
> refresh_pattern -i
windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320
80% 43200 reload-into-ims
> refresh_pattern -i
windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
43200 reload-into-ims
Twice refresh pattern. Remove three lines above.

> # DONT MODIFY THESE LINES
> refresh_pattern \^ftp:           1440    20%     10080
> refresh_pattern \^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> #################################################################
> ###########################
> #
> # Recommended minimum configuration:
> #
>
> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly
plugged) machines
>
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
>
> #
> # Recommended minimum Access Permission configuration:
> #
> # Deny requests to certain unsafe ports
> http_access allow CONNECT wuCONNECT localnet
> http_access allow windowsupdate localnet
> http_access deny !Safe_ports
>
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
>
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
>
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> #http_access deny to_localhost
>
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
>
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
>
> # And finally deny all other access to this proxy
> http_access deny all
>
> # Squid normally listens to port 3128
> http_port 192.168.0.1:3128
>
> # Uncomment and adjust the following to add a disk cache directory.
> cache_dir ufs /var/cache/squid 100 16 256
You specify only 100 megabytes sized cache_dir. Where do you think
should be cached updates? For them, just not enough space.
>
> # Leave coredumps in the first cache dir
> coredump_dir /var/cache/squid
>
> #
> # Add any of your own refresh_pattern entries above these.
> #
> #refresh_pattern ^ftp:          1440    20%     10080
> #refresh_pattern ^gopher:       1440    0%      1440
> #refresh_pattern -i (/cgi-bin/|\?) 0    0%      0
> #refresh_pattern .              0       20%     4320
> #############
> range_offset_limit 5 Gb windowsupdate
> maximum_object_size 5 Gb
> quick_abort_min -1
> #########
> http_port 3129 intercept
> #####################
>
>
>
> cheers
>> On Sep 6, 2016, at 6:01 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>>
>>
> http://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates
>
> Did you read this?
>
>
> 06.09.2016 20:59, --Ahmad-- ?????:
> >>> hi squid users .
> >>>
> >>> I?m trying to catch windows updates as cached object
> >>> im testing with  windows 10 pc
> >>>
> >>> i see all request as tcp_miss and the caching store is not getting
> increase .
> >>>
> >>> =========
> >>> 1473173748.014   3603 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173748.022  12146 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173748.057   5321 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173748.155   3684 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173748.355   4832 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173748.612  12645 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173748.650   7276 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173748.720  12654 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173748.816   5064 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173749.022   4159 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173749.048   5618 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173749.177   7817 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173749.208   3383 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173749.318   5096 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173749.395   3986 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173749.850  13837 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173750.015    914 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173750.029   1365 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>> 1473173750.420   7126 192.168.0.10 TCP_MISS/206 1049229 GET
>
http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> >>>
> >>> =======================
> >>>
> >>> root at raspberrypi:~# du -sh /var/cache/squid/
> >>> 17M     /var/cache/squid/
> >>> root at raspberrypi:~# du -sh /var/cache/squid/
> >>> 17M     /var/cache/squid/
> >>> root at raspberrypi:~# du -sh /var/cache/squid/
> >>> 17M     /var/cache/squid/
> >>> root at raspberrypi:~# du -sh /var/cache/squid/
> >>> 17M     /var/cache/squid/
> >>> root at raspberrypi:~# du -sh /var/cache/squid/
> >>> 17M     /var/cache/squid/
> >>> root at raspberrypi:~# du -sh /var/cache/squid/
> >>> 17M     /var/cache/squid/
> >>> root at raspberrypi:~# du -sh /var/cache/squid/
> >>> 17M     /var/cache/squid/
> >>> root at raspberrypi:~# du -sh /var/cache/squid/
> >>> 17M     /var/cache/squid/
> >>> root at raspberrypi:~# du -sh /var/cache/squid/
> >>> 17M     /var/cache/squid/
> >>> root at raspberrypi:~# du -sh /var/cache/squid/
> >>> 17M     /var/cache/squid/
> >>> root at raspberrypi:~# du -sh /var/cache/squid/
> >>> 17M     /var/cache/squid/
> >>> root at raspberrypi:~# du -sh /var/cache/squid/
> >>> 17M     /var/cache/squid/
> >>> root at raspberrypi:~# du -sh /var/cache/squid/
> >>> 17M     /var/cache/squid/
> >>> root at raspberrypi:~#
> >>>
> >>> ==============
> >>> here is squid config :
> >>>
> >>> root at raspberrypi:~# cat /etc/squid/squid.conf
> >>> #########
> >>> acl windowsupdate dstdomain windowsupdate.microsoft.com
> >>> acl windowsupdate dstdomain .update.microsoft.com
> >>> acl windowsupdate dstdomain download.windowsupdate.com
> >>> acl windowsupdate dstdomain redir.metaservices.microsoft.com
> >>> acl windowsupdate dstdomain images.metaservices.microsoft.com
> >>> acl windowsupdate dstdomain c.microsoft.com
> >>> acl windowsupdate dstdomain www.download.windowsupdate.com
> >>> acl windowsupdate dstdomain wustat.windows.com
> >>> acl windowsupdate dstdomain crl.microsoft.com
> >>> acl windowsupdate dstdomain sls.microsoft.com
> >>> acl windowsupdate dstdomain productactivation.one.microsoft.com
> >>> acl windowsupdate dstdomain ntservicepack.microsoft.com
> >>>
> >>> acl CONNECT method CONNECT
> >>> acl wuCONNECT dstdomain www.update.microsoft.com
> >>> acl wuCONNECT dstdomain sls.microsoft.com
> >>>
> >>> #######################
> >>> refresh_pattern -i
> microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
> 43200 reload-into-ims
> >>> refresh_pattern -i
> windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320
> 80% 43200 reload-into-ims
> >>> refresh_pattern -i
> windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
> 43200 reload-into-ims
> >>> # DONT MODIFY THESE LINES
> >>> refresh_pattern \^ftp:           1440    20%     10080
> >>> refresh_pattern \^gopher:        1440    0%      1440
> >>> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> >>> refresh_pattern .               0       20%     4320
> >>> #################################################################
> >>> ###########################
> >>> #
> >>> # Recommended minimum configuration:
> >>> #
> >>>
> >>> # Example rule allowing access from your local networks.
> >>> # Adapt to list your (internal) IP networks from where browsing
> >>> # should be allowed
> >>> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
> >>> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
> >>> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> >>> acl localnet src fc00::/7       # RFC 4193 local private network range
> >>> acl localnet src fe80::/10      # RFC 4291 link-local (directly
> plugged) machines
> >>>
> >>> acl SSL_ports port 443
> >>> acl Safe_ports port 80          # http
> >>> acl Safe_ports port 21          # ftp
> >>> acl Safe_ports port 443         # https
> >>> acl Safe_ports port 70          # gopher
> >>> acl Safe_ports port 210         # wais
> >>> acl Safe_ports port 1025-65535  # unregistered ports
> >>> acl Safe_ports port 280         # http-mgmt
> >>> acl Safe_ports port 488         # gss-http
> >>> acl Safe_ports port 591         # filemaker
> >>> acl Safe_ports port 777         # multiling http
> >>> acl CONNECT method CONNECT
> >>>
> >>>
> >>> http_access allow CONNECT wuCONNECT localnet
> >>> http_access allow windowsupdate localnet
> >>> http_access deny !Safe_ports
> >>>
> >>> # Deny CONNECT to other than secure SSL ports
> >>> http_access deny CONNECT !SSL_ports
> >>>
> >>> # Only allow cachemgr access from localhost
> >>> http_access allow localhost manager
> >>> http_access deny manager
> >>>
> >>>
> >>> http_access allow localnet
> >>> http_access allow localhost
> >>>
> >>> # And finally deny all other access to this proxy
> >>> http_access deny all
> >>>
> >>> # Squid normally listens to port 3128
> >>> http_port 192.168.0.1:3128
> >>>
> >>> # Uncomment and adjust the following to add a disk cache directory.
> >>> cache_dir ufs /var/cache/squid 100 16 256
> >>>
> >>> # Leave coredumps in the first cache dir
> >>> coredump_dir /var/cache/squid
> >>>
> >>>
> >>> #############
> >>> range_offset_limit 200 MB windowsupdate
> >>> maximum_object_size 200 MB
> >>> quick_abort_min -1
> >>> #########
> >>> http_port 3129 intercept
> >>> maximum_object_size 200000 KB
> >>>
> >>>
> >>>
> >>>
> >>> thank you
> >>>
> >>> _______________________________________________
> >>> squid-users mailing list
> >>> squid-users at lists.squid-cache.org
> >>> http://lists.squid-cache.org/listinfo/squid-users
>
>>
>> <0x613DEC46.asc>_______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXzt2vAAoJENNXIZxhPexGs4cH/2Yjuzr54vMfdx4XdO9nUMri
rCXzkOPFJmRCHIWcr31cxPvgMHCpmlhp5EtnmGdG5ZdEXxeWBcHLdwfMiqSYLfsI
8iNA3Lh0cAEWOf2kVPXzTI8MTSEjsxXnHmYPZrCP3A9xloBiBmhuRQbhENc3fXz4
IqvCHJHdsIHwlDyWaOyeQXydNX/keysZVRgaOjGztpboMrYMIJR/84qBYkdEaEsa
e/Zzs2vO0UFTxwEOzZz1zOFNMYeul3UO5fZa59UY2XsAkzRacRC6SKgITMuMzp4B
WtEAuTtVY7aXKoSjlJkb9Ts/iXYzB+hUz8hpU9iAZzBVpw2NeoNh1URjTh6LLUk=
=ckYb
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160906/5f7fef8d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160906/5f7fef8d/attachment.key>

From augustus_meyer at gmx.net  Tue Sep  6 15:26:16 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Tue, 6 Sep 2016 08:26:16 -0700 (PDT)
Subject: [squid-users] regarding to "cache videos" plugin now as open
	source
In-Reply-To: <4A92237B-E2C4-4026-AEE7-AEB0DA555956@netstream.ps>
References: <4A92237B-E2C4-4026-AEE7-AEB0DA555956@netstream.ps>
Message-ID: <1473175576893-4679378.post@n4.nabble.com>

>since the plugin that is called ?cache videos ? became now free and open
source <
Link, pls.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/regarding-to-cache-videos-plugin-now-as-open-source-tp4679366p4679378.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Tue Sep  6 15:30:25 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 6 Sep 2016 21:30:25 +0600
Subject: [squid-users] regarding to "cache videos" plugin now as open
 source
In-Reply-To: <1473175576893-4679378.post@n4.nabble.com>
References: <4A92237B-E2C4-4026-AEE7-AEB0DA555956@netstream.ps>
 <1473175576893-4679378.post@n4.nabble.com>
Message-ID: <cf07f23e-6e95-1da1-91ac-f598a84e5d5c@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
https://www.google.com

:)


06.09.2016 21:26, reinerotto ?????:
>> since the plugin that is called ?cache videos ? became now free and open
> source <
> Link, pls.
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/regarding-to-cache-videos-plugin-now-as-open-source-tp4679366p4679378.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJXzuERAAoJENNXIZxhPexGcJsH/24oHssew54knp4S7AMoqIiw
IIsexy4/gJibM27rTG/NlQFRfWF5hd06tUAk6Zv/TJiTURULgCkqoCC8gKA4kh1v
6HUFQJ+mkm2ZlG7u1d9qRRpieDz/qr58C9pRfkZuzYAaiP8jJIwE7LBqUvOygFih
XDi3F+tg1qZj1fFzfrw7pE1WXyo0+SUhgH2MfocUCc0RPu50wnmMlFvBfoxTSeJh
h4O8PAoGcd8LwfonNIxi+rKAj/VxYOc57Y+q2scM0tfIWKgQc7U+CKH8ul2cUQsl
/qlnh9nxm31/jW36hcq/QDos6Qm1ayqsT9mfzm80l+ssqCG4aRYTNxwvzkaJseA=
=Xux5
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160906/3fa9083f/attachment.key>

From chip_pop at hotmail.com  Tue Sep  6 15:56:42 2016
From: chip_pop at hotmail.com (joe)
Date: Tue, 6 Sep 2016 08:56:42 -0700 (PDT)
Subject: [squid-users] regarding to "cache videos" plugin now as open
	source
In-Reply-To: <cf07f23e-6e95-1da1-91ac-f598a84e5d5c@gmail.com>
References: <4A92237B-E2C4-4026-AEE7-AEB0DA555956@netstream.ps>
 <1473175576893-4679378.post@n4.nabble.com>
 <cf07f23e-6e95-1da1-91ac-f598a84e5d5c@gmail.com>
Message-ID: <1473177402732-4679381.post@n4.nabble.com>

http://www.yahoo.com



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/regarding-to-cache-videos-plugin-now-as-open-source-tp4679366p4679381.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From ahmed.zaeem at netstream.ps  Tue Sep  6 17:07:36 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 6 Sep 2016 20:07:36 +0300
Subject: [squid-users] windows update not working squid 3.5.2
In-Reply-To: <20f02386-6272-0489-4f31-4f41051a1fa0@gmail.com>
References: <763AFEA6-52DE-4DCB-805D-DA1136933178@netstream.ps>
 <20f02386-6272-0489-4f31-4f41051a1fa0@gmail.com>
Message-ID: <A2612C06-B8D6-4BDA-BAE1-03E566565C67@netstream.ps>

/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.13.30 application/octet-stream
1473181228.768   1202 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.70.206 application/octet-stream
1473181229.117   1159 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.253.70.206 application/octet-stream
1473181229.265    984 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181229.525   1207 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181230.066   1314 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.253.70.206 application/octet-stream
1473181230.147    913 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181230.166   1659 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.253.13.30 application/octet-stream
1473181230.438   1233 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.13.30 application/octet-stream
1473181230.461   1569 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181230.621   1023 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181231.143   1219 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181231.166   1212 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181231.528   1131 192.168.0.10 TCP_MISS/206 1049142 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181231.601   1416 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.253.13.30 application/octet-stream
1473181231.784    938 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181232.102   1565 192.168.0.10 TCP_MISS/206 1049142 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.70.206 application/octet-stream
1473181232.330   1453 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.253.70.206 application/octet-stream


with squid.conf :
#########
acl windowsupdate dstdomain windowsupdate.microsoft.com <http://windowsupdate.microsoft.com/>
acl windowsupdate dstdomain .update.microsoft.com <http://update.microsoft.com/>
acl windowsupdate dstdomain download.windowsupdate.com <http://download.windowsupdate.com/>
acl windowsupdate dstdomain redir.metaservices.microsoft.com <http://redir.metaservices.microsoft.com/>
acl windowsupdate dstdomain images.metaservices.microsoft.com <http://images.metaservices.microsoft.com/>
acl windowsupdate dstdomain c.microsoft.com <http://c.microsoft.com/>
acl windowsupdate dstdomain www.download.windowsupdate.com <http://www.download.windowsupdate.com/>
acl windowsupdate dstdomain wustat.windows.com <http://wustat.windows.com/>
acl windowsupdate dstdomain crl.microsoft.com <http://crl.microsoft.com/>
acl windowsupdate dstdomain sls.microsoft.com <http://sls.microsoft.com/>
acl windowsupdate dstdomain productactivation.one.microsoft.com <http://productactivation.one.microsoft.com/>
acl windowsupdate dstdomain ntservicepack.microsoft.com <http://ntservicepack.microsoft.com/>

acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com <http://www.update.microsoft.com/>
acl wuCONNECT dstdomain sls.microsoft.com <http://sls.microsoft.com/>

#http_access allow CONNECT wuCONNECT localnet
#http_access allow windowsupdate localnet
#######################
# Updates: Windows
refresh_pattern -i windowsupdate.com/.* <http://windowsupdate.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i microsoft.com/.* <http://microsoft.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i windows.com/.* <http://windows.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i microsoft.com.akadns.net/.* <http://microsoft.com.akadns.net/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i deploy.akamaitechnologies.com/.* <http://deploy.akamaitechnologies.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
###########
#refresh_pattern -i microsoft.com/.* <http://microsoft.com/.*>\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
#refresh_pattern -i windowsupdate.com/.* <http://windowsupdate.com/.*>\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
#refresh_pattern -i windows.com/.* <http://windows.com/.*>\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
# DONT MODIFY THESE LINES
refresh_pattern \^ftp:           1440    20%     10080
refresh_pattern \^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
#################################################################
###########################
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access allow CONNECT wuCONNECT localnet
http_access allow windowsupdate localnet
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.0.1:3128

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/cache/squid 20000 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
#refresh_pattern ^ftp:          1440    20%     10080
#refresh_pattern ^gopher:       1440    0%      1440
#refresh_pattern -i (/cgi-bin/|\?) 0    0%      0
#refresh_pattern .              0       20%     4320
#############
range_offset_limit 5 Gb windowsupdate
maximum_object_size 5 Gb
quick_abort_min -1
#########
http_port 3129 intercept
#####################
> On Sep 6, 2016, at 6:01 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
> 
> 
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
> 
> http://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates
> 
> Did you read this?
> 
> 
> 06.09.2016 20:59, --Ahmad-- ?????:
>> hi squid users .
>> 
>> I?m trying to catch windows updates as cached object
>> im testing with  windows 10 pc
>> 
>> i see all request as tcp_miss and the caching store is not getting
> increase .
>> 
>> =========
>> 1473173748.014   3603 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173748.022  12146 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173748.057   5321 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173748.155   3684 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173748.355   4832 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173748.612  12645 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173748.650   7276 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173748.720  12654 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173748.816   5064 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173749.022   4159 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173749.048   5618 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173749.177   7817 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173749.208   3383 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173749.318   5096 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173749.395   3986 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173749.850  13837 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173750.015    914 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173750.029   1365 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473173750.420   7126 192.168.0.10 TCP_MISS/206 1049229 GET
> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>> =======================
>> 
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 17M     /var/cache/squid/
>> root at raspberrypi:~#
>> 
>> ==============
>> here is squid config :
>> 
>> root at raspberrypi:~# cat /etc/squid/squid.conf
>> #########
>> acl windowsupdate dstdomain windowsupdate.microsoft.com
>> acl windowsupdate dstdomain .update.microsoft.com
>> acl windowsupdate dstdomain download.windowsupdate.com
>> acl windowsupdate dstdomain redir.metaservices.microsoft.com
>> acl windowsupdate dstdomain images.metaservices.microsoft.com
>> acl windowsupdate dstdomain c.microsoft.com
>> acl windowsupdate dstdomain www.download.windowsupdate.com
>> acl windowsupdate dstdomain wustat.windows.com
>> acl windowsupdate dstdomain crl.microsoft.com
>> acl windowsupdate dstdomain sls.microsoft.com
>> acl windowsupdate dstdomain productactivation.one.microsoft.com
>> acl windowsupdate dstdomain ntservicepack.microsoft.com
>> 
>> acl CONNECT method CONNECT
>> acl wuCONNECT dstdomain www.update.microsoft.com
>> acl wuCONNECT dstdomain sls.microsoft.com
>> 
>> #######################
>> refresh_pattern -i
> microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
> 43200 reload-into-ims
>> refresh_pattern -i
> windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320
> 80% 43200 reload-into-ims
>> refresh_pattern -i
> windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
> 43200 reload-into-ims
>> # DONT MODIFY THESE LINES
>> refresh_pattern \^ftp:           1440    20%     10080
>> refresh_pattern \^gopher:        1440    0%      1440
>> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
>> refresh_pattern .               0       20%     4320
>> #################################################################
>> ###########################
>> #
>> # Recommended minimum configuration:
>> #
>> 
>> # Example rule allowing access from your local networks.
>> # Adapt to list your (internal) IP networks from where browsing
>> # should be allowed
>> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
>> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
>> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
>> acl localnet src fc00::/7       # RFC 4193 local private network range
>> acl localnet src fe80::/10      # RFC 4291 link-local (directly
> plugged) machines
>> 
>> acl SSL_ports port 443
>> acl Safe_ports port 80          # http
>> acl Safe_ports port 21          # ftp
>> acl Safe_ports port 443         # https
>> acl Safe_ports port 70          # gopher
>> acl Safe_ports port 210         # wais
>> acl Safe_ports port 1025-65535  # unregistered ports
>> acl Safe_ports port 280         # http-mgmt
>> acl Safe_ports port 488         # gss-http
>> acl Safe_ports port 591         # filemaker
>> acl Safe_ports port 777         # multiling http
>> acl CONNECT method CONNECT
>> 
>> 
>> http_access allow CONNECT wuCONNECT localnet
>> http_access allow windowsupdate localnet
>> http_access deny !Safe_ports
>> 
>> # Deny CONNECT to other than secure SSL ports
>> http_access deny CONNECT !SSL_ports
>> 
>> # Only allow cachemgr access from localhost
>> http_access allow localhost manager
>> http_access deny manager
>> 
>> 
>> http_access allow localnet
>> http_access allow localhost
>> 
>> # And finally deny all other access to this proxy
>> http_access deny all
>> 
>> # Squid normally listens to port 3128
>> http_port 192.168.0.1:3128
>> 
>> # Uncomment and adjust the following to add a disk cache directory.
>> cache_dir ufs /var/cache/squid 100 16 256
>> 
>> # Leave coredumps in the first cache dir
>> coredump_dir /var/cache/squid
>> 
>> 
>> #############
>> range_offset_limit 200 MB windowsupdate
>> maximum_object_size 200 MB
>> quick_abort_min -1
>> #########
>> http_port 3129 intercept
>> maximum_object_size 200000 KB
>> 
>> 
>> 
>> 
>> thank you
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
> 
> iQEcBAEBCAAGBQJXztpBAAoJENNXIZxhPexGSx4H/0bK8485yWhpNbGUIGtwvx9h
> PTuRhfJP+f8xoTbTh/zH1TgXs21M953uf5DoYlynMBSeVXCfQQiUhDOs+0bqAjfD
> JsLCXVpZdSYYWyX2aErjfZqKQO67aVkX+zJbAY/zlTJKG6Gxg1+ssQSEJaFWu6cK
> J8KBudfWaKmPc9xdiZRfYFE6LKBSeQr93BqBF6s1SwdAPKEkspQmDTuqPZEwMwW5
> zQfuI/HnIvynSE+SxCFYOAwka2zVAdewXfVyWqYyFCHaHnDkXkPmK/5zZJDOmqGi
> erifbGQHRHAFWNnT4mMsHGjM3Wfz1bbhr+j+tZJkY4x116eVUMrVbbXRApY5nn0=
> =ZaFG
> -----END PGP SIGNATURE-----
> 
> <0x613DEC46.asc>_______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160906/921ce38c/attachment.htm>

From rousskov at measurement-factory.com  Tue Sep  6 17:50:32 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 6 Sep 2016 11:50:32 -0600
Subject: [squid-users] Copy and send decrypted HTTPS traffic to specific
 location
In-Reply-To: <620103417.1303756.1473000009143@mail.yahoo.com>
References: <620103417.1303756.1473000009143.ref@mail.yahoo.com>
 <620103417.1303756.1473000009143@mail.yahoo.com>
Message-ID: <fec4b1bd-fa35-7356-d8c8-9147ee4accde@measurement-factory.com>

On 09/04/2016 08:40 AM, Wesley Whitteker wrote:

> I've been doing some testing with Squid and am currently using it to
> decrypt HTTPS flows (i.e. MITM Proxy).  I also have the C-ICAP feature
> working.
> 
> Now, I'm trying to determine if Squid has the capabilities to send a
> copy of decrypted HTTPS traffic out a particular port on the HW platform
> I'm running squid on -- any ideas if this has/can be done?

This is possible using ICAP or eCAP interfaces: Folks write ICAP or eCAP
adapters that reassemble TCP/IP traffic based on the adaptation messages
those adapters receive from Squid and inject that TCP/IP traffic into
the network. Needless to say, the injected traffic is not exactly the
same as the original would have been, but the differences are usually
not important for the logging and analysis tools that receive the
injected TCP/IP packets. It works pretty well, actually.


HTH,

Alex.



From rousskov at measurement-factory.com  Tue Sep  6 18:02:57 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 6 Sep 2016 12:02:57 -0600
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <20160906143620.GA15684@fantomas.sk>
References: <3baf0e15-0dbb-8a7c-ceee-06d7d08a3b3e@measurement-factory.com>
 <1472222534649-4679207.post@n4.nabble.com>
 <1fc69717-57d1-d600-ee26-8c39a70a3665@measurement-factory.com>
 <1472298288404-4679212.post@n4.nabble.com>
 <079edebc-9f88-3cbb-d4c2-c79629b1da0a@measurement-factory.com>
 <1472375429698-4679222.post@n4.nabble.com>
 <e4ab7076-5343-9c4c-d83a-24c508bd01ad@measurement-factory.com>
 <1472478056062-4679239.post@n4.nabble.com>
 <14b920b2-67b5-31c8-b85e-96eea33768f0@measurement-factory.com>
 <1473143528034-4679361.post@n4.nabble.com>
 <20160906143620.GA15684@fantomas.sk>
Message-ID: <f3a72736-d714-e661-56c2-a135a81e9cd3@measurement-factory.com>

On 09/06/2016 08:36 AM, Matus UHLAR - fantomas wrote:
> On 05.09.16 23:32, Omid Kosari wrote:
>> Filed a bug report http://bugs.squid-cache.org/show_bug.cgi?id=4585
> 
> I wonder if this is doable at all.

Yes, and Squid supports it in other contexts.


> Does any tcp stack allow sending reset AFTER the connection has been
> opened?

A TCP RESET packet can be sent at any time. This is not something the
protocol can (or needs to!) prohibit.

Alex.



From ahmed.zaeem at netstream.ps  Tue Sep  6 20:06:49 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 6 Sep 2016 23:06:49 +0300
Subject: [squid-users] regarding to "cache videos" plugin now as open
	source
In-Reply-To: <4A92237B-E2C4-4026-AEE7-AEB0DA555956@netstream.ps>
References: <4A92237B-E2C4-4026-AEE7-AEB0DA555956@netstream.ps>
Message-ID: <7AC21AF8-13F6-41A7-9CC2-585274DB17E7@netstream.ps>

i see it as open source now 



https://github.com/kulbirsaini/videocache <https://github.com/kulbirsaini/videocache>


no ??
> On Sep 6, 2016, at 3:04 PM, --Ahmad-- <ahmed.zaeem at netstream.ps> wrote:
> 
> hi squid users 
> 
> just a question
> 
> since the plugin that is called ?cache videos ? became now free and open source 
> 
> why i don?t see many users dealing with it ??
> 
> isn?t it  open source  now ??
> 
> 
> i don?t see here  guys who ask about it 
> 
> just curious to know why 
> 
> 
> cheers
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160906/1134eedf/attachment.htm>

From belle at bazuin.nl  Wed Sep  7 07:32:31 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 7 Sep 2016 09:32:31 +0200
Subject: [squid-users] windows update not working squid 3.5.2
In-Reply-To: <A2612C06-B8D6-4BDA-BAE1-03E566565C67@netstream.ps>
References: <20f02386-6272-0489-4f31-4f41051a1fa0@gmail.com>
Message-ID: <vmime.57cfc28f.5555.55a2b7e92dd821ff@ms249-lin-003.rotterdam.bazuin.nl>

I also have these for windows updates. 

?

acl windowsupdate dstdomain au.download.windowsupdate.com

acl windowsupdate dstdomain ds.download.windowsupdate.com

acl windowsupdate dstdomain ctldl.windowsupdate.com

acl windowsupdate dstdomain .data.microsoft.com

acl windowsupdate dstdomain .l.windowsupdate.com

acl windowsupdate dstdomain .microsoft.com.akadns.net

acl windowsupdate dstdomain .deploy.akamaitechnologies.com

?

and add this one to your refresh.

refresh_pattern -i deploy.akamaitechnologies.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims

?

?

Greetz, 

?

Louis

?

?


Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens --Ahmad--
Verzonden: dinsdag 6 september 2016 19:08
Aan: Yuri Voinov
CC: squid-users at lists.squid-cache.org
Onderwerp: Re: [squid-users] windows update not working squid 3.5.2


?

/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.13.30 application/octet-stream
1473181228.768 ??1202 192.168.0.10 TCP_MISS/206 1049144 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe?- ORIGINAL_DST/8.253.70.206 application/octet-stream
1473181229.117 ??1159 192.168.0.10 TCP_MISS/206 1049146 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab?- ORIGINAL_DST/8.253.70.206 application/octet-stream
1473181229.265 ???984 192.168.0.10 TCP_MISS/206 1049144 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe?- ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181229.525 ??1207 192.168.0.10 TCP_MISS/206 1049144 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe?- ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181230.066 ??1314 192.168.0.10 TCP_MISS/206 1049146 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab?- ORIGINAL_DST/8.253.70.206 application/octet-stream
1473181230.147 ???913 192.168.0.10 TCP_MISS/206 1049146 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab?- ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181230.166 ??1659 192.168.0.10 TCP_MISS/206 1049144 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab?- ORIGINAL_DST/8.253.13.30 application/octet-stream
1473181230.438 ??1233 192.168.0.10 TCP_MISS/206 1049144 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe?- ORIGINAL_DST/8.253.13.30 application/octet-stream
1473181230.461 ??1569 192.168.0.10 TCP_MISS/206 1049146 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe?- ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181230.621 ??1023 192.168.0.10 TCP_MISS/206 1049144 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab?- ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181231.143 ??1219 192.168.0.10 TCP_MISS/206 1049144 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe?- ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181231.166 ??1212 192.168.0.10 TCP_MISS/206 1049144 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe?- ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181231.528 ??1131 192.168.0.10 TCP_MISS/206 1049142 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab?- ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181231.601 ??1416 192.168.0.10 TCP_MISS/206 1049146 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab?- ORIGINAL_DST/8.253.13.30 application/octet-stream
1473181231.784 ???938 192.168.0.10 TCP_MISS/206 1049144 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe?- ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181232.102 ??1565 192.168.0.10 TCP_MISS/206 1049142 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe?- ORIGINAL_DST/8.253.70.206 application/octet-stream
1473181232.330 ??1453 192.168.0.10 TCP_MISS/206 1049146 GET?http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab?- ORIGINAL_DST/8.253.70.206 application/octet-stream


with squid.conf :
#########
acl windowsupdate dstdomain?windowsupdate.microsoft.com
acl windowsupdate dstdomain .update.microsoft.com
acl windowsupdate dstdomain?download.windowsupdate.com
acl windowsupdate dstdomain?redir.metaservices.microsoft.com
acl windowsupdate dstdomain?images.metaservices.microsoft.com
acl windowsupdate dstdomain?c.microsoft.com
acl windowsupdate dstdomain?www.download.windowsupdate.com
acl windowsupdate dstdomain?wustat.windows.com
acl windowsupdate dstdomain?crl.microsoft.com
acl windowsupdate dstdomain?sls.microsoft.com
acl windowsupdate dstdomain?productactivation.one.microsoft.com
acl windowsupdate dstdomain?ntservicepack.microsoft.com

acl CONNECT method CONNECT
acl wuCONNECT dstdomain?www.update.microsoft.com
acl wuCONNECT dstdomain?sls.microsoft.com

#http_access allow CONNECT wuCONNECT localnet
#http_access allow windowsupdate localnet
#######################
# Updates: Windows
refresh_pattern -i?windowsupdate.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i?microsoft.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i?windows.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i?microsoft.com.akadns.net/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i?deploy.akamaitechnologies.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
###########
#refresh_pattern -i?microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
#refresh_pattern -i?windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
#refresh_pattern -i?windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
# DONT MODIFY THESE LINES
refresh_pattern \^ftp: ??????????1440 ???20% ????10080
refresh_pattern \^gopher: ???????1440 ???0% ?????1440
refresh_pattern -i (/cgi-bin/|\?) 0 ????0% ?????0
refresh_pattern . ??????????????0 ??????20% ????4320
#################################################################
###########################
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8 ????# RFC1918 possible internal network
acl localnet src 172.16.0.0/12 ?# RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7 ??????# RFC 4193 local private network range
acl localnet src fe80::/10 ?????# RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80 ?????????# http
acl Safe_ports port 21 ?????????# ftp
acl Safe_ports port 443 ????????# https
acl Safe_ports port 70 ?????????# gopher
acl Safe_ports port 210 ????????# wais
acl Safe_ports port 1025-65535 ?# unregistered ports
acl Safe_ports port 280 ????????# http-mgmt
acl Safe_ports port 488 ????????# gss-http
acl Safe_ports port 591 ????????# filemaker
acl Safe_ports port 777 ????????# multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access allow CONNECT wuCONNECT localnet
http_access allow windowsupdate localnet
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.0.1:3128

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/cache/squid 20000 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
#refresh_pattern ^ftp: ?????????1440 ???20% ????10080
#refresh_pattern ^gopher: ??????1440 ???0% ?????1440
#refresh_pattern -i (/cgi-bin/|\?) 0 ???0% ?????0
#refresh_pattern . ?????????????0 ??????20% ????4320
#############
range_offset_limit 5 Gb windowsupdate
maximum_object_size 5 Gb
quick_abort_min -1
#########
http_port 3129 intercept
#####################

On Sep 6, 2016, at 6:01 PM, Yuri Voinov <yvoinov at gmail.com> wrote:


?


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

http://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates

Did you read this?


06.09.2016 20:59, --Ahmad-- ?????:



hi squid users .

I?m trying to catch windows updates as cached object
im testing with ?windows 10 pc

i see all request as tcp_miss and the caching store is not getting

increase .




=========
1473173748.014 ??3603 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.022 ?12146 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.057 ??5321 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.155 ??3684 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.355 ??4832 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.612 ?12645 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.650 ??7276 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.720 ?12654 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.816 ??5064 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.022 ??4159 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.048 ??5618 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.177 ??7817 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.208 ??3383 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.318 ??5096 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.395 ??3986 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.850 ?13837 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173750.015 ???914 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173750.029 ??1365 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173750.420 ??7126 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream




=======================

root at raspberrypi:~# du -sh /var/cache/squid/
17M ????/var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M ????/var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M ????/var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M ????/var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M ????/var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M ????/var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M ????/var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M ????/var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M ????/var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M ????/var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M ????/var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M ????/var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M ????/var/cache/squid/
root at raspberrypi:~#

==============
here is squid config :

root at raspberrypi:~# cat /etc/squid/squid.conf
#########
acl windowsupdate dstdomain windowsupdate.microsoft.com
acl windowsupdate dstdomain .update.microsoft.com
acl windowsupdate dstdomain download.windowsupdate.com
acl windowsupdate dstdomain redir.metaservices.microsoft.com
acl windowsupdate dstdomain images.metaservices.microsoft.com
acl windowsupdate dstdomain c.microsoft.com
acl windowsupdate dstdomain www.download.windowsupdate.com
acl windowsupdate dstdomain wustat.windows.com
acl windowsupdate dstdomain crl.microsoft.com
acl windowsupdate dstdomain sls.microsoft.com
acl windowsupdate dstdomain productactivation.one.microsoft.com
acl windowsupdate dstdomain ntservicepack.microsoft.com

acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com

#######################
refresh_pattern -i

microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
43200 reload-into-ims



refresh_pattern -i

windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320
80% 43200 reload-into-ims



refresh_pattern -i

windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
43200 reload-into-ims



# DONT MODIFY THESE LINES
refresh_pattern \^ftp: ??????????1440 ???20% ????10080
refresh_pattern \^gopher: ???????1440 ???0% ?????1440
refresh_pattern -i (/cgi-bin/|\?) 0 ????0% ?????0
refresh_pattern . ??????????????0 ??????20% ????4320
#################################################################
###########################
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8 ????# RFC1918 possible internal network
acl localnet src 172.16.0.0/12 ?# RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7 ??????# RFC 4193 local private network range
acl localnet src fe80::/10 ?????# RFC 4291 link-local (directly

plugged) machines




acl SSL_ports port 443
acl Safe_ports port 80 ?????????# http
acl Safe_ports port 21 ?????????# ftp
acl Safe_ports port 443 ????????# https
acl Safe_ports port 70 ?????????# gopher
acl Safe_ports port 210 ????????# wais
acl Safe_ports port 1025-65535 ?# unregistered ports
acl Safe_ports port 280 ????????# http-mgmt
acl Safe_ports port 488 ????????# gss-http
acl Safe_ports port 591 ????????# filemaker
acl Safe_ports port 777 ????????# multiling http
acl CONNECT method CONNECT


http_access allow CONNECT wuCONNECT localnet
http_access allow windowsupdate localnet
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager


http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.0.1:3128

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/cache/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid


#############
range_offset_limit 200 MB windowsupdate
maximum_object_size 200 MB
quick_abort_min -1
#########
http_port 3129 intercept
maximum_object_size 200000 KB




thank you

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBCAAGBQJXztpBAAoJENNXIZxhPexGSx4H/0bK8485yWhpNbGUIGtwvx9h
PTuRhfJP+f8xoTbTh/zH1TgXs21M953uf5DoYlynMBSeVXCfQQiUhDOs+0bqAjfD
JsLCXVpZdSYYWyX2aErjfZqKQO67aVkX+zJbAY/zlTJKG6Gxg1+ssQSEJaFWu6cK
J8KBudfWaKmPc9xdiZRfYFE6LKBSeQr93BqBF6s1SwdAPKEkspQmDTuqPZEwMwW5
zQfuI/HnIvynSE+SxCFYOAwka2zVAdewXfVyWqYyFCHaHnDkXkPmK/5zZJDOmqGi
erifbGQHRHAFWNnT4mMsHGjM3Wfz1bbhr+j+tZJkY4x116eVUMrVbbXRApY5nn0=
=ZaFG
-----END PGP SIGNATURE-----

<0x613DEC46.asc>_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users




?


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160907/bd2521f9/attachment.htm>

From ahmed.zaeem at netstream.ps  Wed Sep  7 07:39:49 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Wed, 7 Sep 2016 10:39:49 +0300
Subject: [squid-users] windows update not working squid 3.5.2
In-Reply-To: <vmime.57cfc28f.5555.55a2b7e92dd821ff@ms249-lin-003.rotterdam.bazuin.nl>
References: <20f02386-6272-0489-4f31-4f41051a1fa0@gmail.com>
 <vmime.57cfc28f.5555.55a2b7e92dd821ff@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <5AF2C012-C041-46DB-95BD-956EBF11E1D9@netstream.ps>

thanks for reply 

but i still  don?t see even the hdd drive getting increasing when windows updates go on !!!!

i tested it on windows 7 

i never seen TCP_HIT and  the hdd size still the same !!!


here is again my  squid.conf in final form on my server :

root at raspberrypi:~# cat /etc/squid/squid.conf
#########
acl windowsupdate dstdomain windowsupdate.microsoft.com
acl windowsupdate dstdomain .update.microsoft.com
acl windowsupdate dstdomain download.windowsupdate.com
acl windowsupdate dstdomain redir.metaservices.microsoft.com
acl windowsupdate dstdomain images.metaservices.microsoft.com
acl windowsupdate dstdomain c.microsoft.com
acl windowsupdate dstdomain www.download.windowsupdate.com
acl windowsupdate dstdomain wustat.windows.com
acl windowsupdate dstdomain crl.microsoft.com
acl windowsupdate dstdomain sls.microsoft.com
acl windowsupdate dstdomain productactivation.one.microsoft.com
acl windowsupdate dstdomain ntservicepack.microsoft.com
acl windowsupdate dstdomain au.download.windowsupdate.com
acl windowsupdate dstdomain ds.download.windowsupdate.com
acl windowsupdate dstdomain ctldl.windowsupdate.com
acl windowsupdate dstdomain .data.microsoft.com
acl windowsupdate dstdomain .l.windowsupdate.com
acl windowsupdate dstdomain .microsoft.com.akadns.net
acl windowsupdate dstdomain .deploy.akamaitechnologies.com
################################################### 
acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com
####################################
refresh_pattern -i windowsupdate.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i microsoft.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i windows.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i microsoft.com.akadns.net/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i deploy.akamaitechnologies.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
########################################################
refresh_pattern \^ftp:           1440    20%     10080
refresh_pattern \^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
########################################################
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access allow CONNECT wuCONNECT localnet
http_access allow windowsupdate localnet
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.0.1:3128

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/cache/squid 20000 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
#refresh_pattern ^ftp:          1440    20%     10080
#refresh_pattern ^gopher:       1440    0%      1440
#refresh_pattern -i (/cgi-bin/|\?) 0    0%      0
#refresh_pattern .              0       20%     4320
#############
range_offset_limit 5 Gb windowsupdate
maximum_object_size 5 Gb
quick_abort_min -1
#########
http_port 3129 intercept
#####################





any other suggestions ???



kind regards
> On Sep 7, 2016, at 10:32 AM, L.P.H. van Belle <belle at bazuin.nl> wrote:
> 
> acl windowsupdate dstdomain au.download.windowsupdate.com <http://au.download.windowsupdate.com/>
> acl windowsupdate dstdomain ds.download.windowsupdate.com <http://ds.download.windowsupdate.com/>
> acl windowsupdate dstdomain ctldl.windowsupdate.com <http://ctldl.windowsupdate.com/>
> acl windowsupdate dstdomain .data.microsoft.com <http://data.microsoft.com/>
> acl windowsupdate dstdomain .l.windowsupdate.com <http://l.windowsupdate.com/>
> acl windowsupdate dstdomain .microsoft.com.akadns.net <http://microsoft.com.akadns.net/>
> acl windowsupdate dstdomain .deploy.akamaitechnologies.com <http://deploy.akamaitechnologies.com/>
>  
> and add this one to your refresh.
> refresh_pattern -i deploy.akamaitechnologies.com/.* <http://deploy.akamaitechnologies.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
>  

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160907/874856ad/attachment.htm>

From drcimino at mail.com  Wed Sep  7 07:44:38 2016
From: drcimino at mail.com (akn ab)
Date: Wed, 7 Sep 2016 09:44:38 +0200
Subject: [squid-users] Debugging NTLM problem
In-Reply-To: <ae9856e6-9945-0285-250f-cd81e0f4cbf6@treenet.co.nz>
References: <trinity-93183f7b-d152-4318-a594-dbd52b624208-1472828777733@3capp-mailcom-lxa03>,
 <ae9856e6-9945-0285-250f-cd81e0f4cbf6@treenet.co.nz>
Message-ID: <trinity-53646a45-7d77-4cc6-9d15-c8fae4bdcc2f-1473234278587@3capp-mailcom-lxa03>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160907/ce40b854/attachment.htm>

From uhlar at fantomas.sk  Wed Sep  7 07:56:11 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 7 Sep 2016 09:56:11 +0200
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <f3a72736-d714-e661-56c2-a135a81e9cd3@measurement-factory.com>
References: <1fc69717-57d1-d600-ee26-8c39a70a3665@measurement-factory.com>
 <1472298288404-4679212.post@n4.nabble.com>
 <079edebc-9f88-3cbb-d4c2-c79629b1da0a@measurement-factory.com>
 <1472375429698-4679222.post@n4.nabble.com>
 <e4ab7076-5343-9c4c-d83a-24c508bd01ad@measurement-factory.com>
 <1472478056062-4679239.post@n4.nabble.com>
 <14b920b2-67b5-31c8-b85e-96eea33768f0@measurement-factory.com>
 <1473143528034-4679361.post@n4.nabble.com>
 <20160906143620.GA15684@fantomas.sk>
 <f3a72736-d714-e661-56c2-a135a81e9cd3@measurement-factory.com>
Message-ID: <20160907075611.GA9976@fantomas.sk>

>> On 05.09.16 23:32, Omid Kosari wrote:
>>> Filed a bug report http://bugs.squid-cache.org/show_bug.cgi?id=4585

>On 09/06/2016 08:36 AM, Matus UHLAR - fantomas wrote:
>> I wonder if this is doable at all.

On 06.09.16 12:02, Alex Rousskov wrote:
>Yes, and Squid supports it in other contexts.

and how is this done? Which system or library call does drop connection to
send a RST immediately?

>> Does any tcp stack allow sending reset AFTER the connection has been
>> opened?
>
>A TCP RESET packet can be sent at any time. This is not something the
>protocol can (or needs to!) prohibit.

I'm not saying that it should not be done, I was just unaware of how this is
implemented. closing connection sends FIN, not RST, correct?

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
2B|!2B, that's a question!


From jsayce at asdlighting.com  Wed Sep  7 08:23:02 2016
From: jsayce at asdlighting.com (John Sayce)
Date: Wed, 7 Sep 2016 08:23:02 +0000
Subject: [squid-users] Transparent Proxy
In-Reply-To: <ac05d49c-fe7f-f0f3-af19-7a065d2fe228@urlfilterdb.com>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <1472150075016-4679181.post@n4.nabble.com>
 <477b5e2b-6eb4-54bc-240f-af416f53612c@treenet.co.nz>
 <0aebb8f5-e2fe-71ea-5477-d299acd9ccf9@urlfilterdb.com>
 <b1fde5e0-7725-7264-4039-17f34cf7e6fb@treenet.co.nz>
 <ac05d49c-fe7f-f0f3-af19-7a065d2fe228@urlfilterdb.com>
Message-ID: <ba42abf98b0746c0ac080a7484b444ec@IT-S-MAIL1.asd.local>

I'm trying to set up a transparent proxy but I'm fairly sure I'm missing something.

I've followed the instructions on the juniper website along with a couple of other blogs as per:
https://damn.technology/using-squid-juniper-pbr-transparent-proxy
http://davehope.co.uk/Blog/implementing-pbr-and-squid3-as-a-transparent-proxy/
https://kb.juniper.net/InfoCenter/index?id=KB24139&page=content&actp=search


I have a juniper SSG320 firewall setup with policy based routing.  For my chosen subnet this is configured to forward traffic on port 80 to the squid server.

The traffic from my firewall is forwarded to squid.  This appears to be happening.  

The client starts with a syn packet which is forwarded from the firewall to the squid server. The packet is forwarded to the squid server with the source IP address remaining that of the client.  The problem is that the squid server then responds to the client as itself rather than spoofing the address that the client originally requested. So the ACK packet the client receives is from the squid server rather than the remote webserver the client made a request to, which isn't going to work.

So should my firewall be doing something more, or is it my squid server that's not performing as expected?

In addition to forwarding the packet to squid I can enable source translation on the firewall (which isn't in the guides I mentioned) so the source address of the packet sent to squid comes from the firewall, squid then responds to the firewall, which in turn translates the packet back to the client.  This configuration works, however the access log stores the address of the firewall rather than the address of the client.  Is this how it's meant to work, or am I missing something?

Thanks


From Antony.Stone at squid.open.source.it  Wed Sep  7 08:28:00 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 7 Sep 2016 10:28:00 +0200
Subject: [squid-users] Transparent Proxy
In-Reply-To: <ba42abf98b0746c0ac080a7484b444ec@IT-S-MAIL1.asd.local>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <ac05d49c-fe7f-f0f3-af19-7a065d2fe228@urlfilterdb.com>
 <ba42abf98b0746c0ac080a7484b444ec@IT-S-MAIL1.asd.local>
Message-ID: <201609071028.00629.Antony.Stone@squid.open.source.it>

On Wednesday 07 September 2016 at 10:23:02, John Sayce wrote:

> I'm trying to set up a transparent proxy but I'm fairly sure I'm missing
> something.
> 
> I've followed the instructions on the juniper website along with a couple
> of other blogs as per:
> https://damn.technology/using-squid-juniper-pbr-transparent-proxy

You *have* applied the iptables rule on the machine running squid as described 
on that page, yes?

iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j REDIRECT --to-port 
3128


Antony.

-- 
This email was created using 100% recycled electrons.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From jsayce at asdlighting.com  Wed Sep  7 08:51:49 2016
From: jsayce at asdlighting.com (John Sayce)
Date: Wed, 7 Sep 2016 08:51:49 +0000
Subject: [squid-users] Transparent Proxy
In-Reply-To: <201609071028.00629.Antony.Stone@squid.open.source.it>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <ac05d49c-fe7f-f0f3-af19-7a065d2fe228@urlfilterdb.com>
 <ba42abf98b0746c0ac080a7484b444ec@IT-S-MAIL1.asd.local>
 <201609071028.00629.Antony.Stone@squid.open.source.it>
Message-ID: <48eea6e3dbdb46f6b7281bb5be42855d@IT-S-MAIL1.asd.local>

I believe so.  The specific command I used was:

iptables -t nat -A PREROUTING -i ens33 -p tcp --dport 80 -j REDIRECT --to-port 3128

(For some reason my adapter is ens33, I have no idea why it's not eth0.  Squid is set to run on 3128.)

And after running this command port 80 now shows as being open with nmap.

And the output from iptables -t nat -L

Chain PREROUTING (policy ACCEPT)
target     prot opt source               destination
REDIRECT   tcp  --  anywhere             anywhere             tcp dpt:http redir ports 3128

Chain INPUT (policy ACCEPT)
target     prot opt source               destination

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination

Chain POSTROUTING (policy ACCEPT)
target     prot opt source               destination


It's fair to say I have almost no experience with iptables.  Is it iptables that should be doing the address translation? when the packet is sent back to the client? 



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Antony Stone
Sent: 07 September 2016 09:28
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Transparent Proxy

On Wednesday 07 September 2016 at 10:23:02, John Sayce wrote:

> I'm trying to set up a transparent proxy but I'm fairly sure I'm 
> missing something.
> 
> I've followed the instructions on the juniper website along with a 
> couple of other blogs as per:
> https://damn.technology/using-squid-juniper-pbr-transparent-proxy

You *have* applied the iptables rule on the machine running squid as described on that page, yes?

iptables -t nat -A PREROUTING -i eth0 -p tcp --dport 80 -j REDIRECT --to-port
3128


Antony.

-- 
This email was created using 100% recycled electrons.

                                                   Please reply to the list;
                                                         please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From belle at bazuin.nl  Wed Sep  7 09:03:22 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 7 Sep 2016 11:03:22 +0200
Subject: [squid-users] windows update not working squid 3.5.2
In-Reply-To: <5AF2C012-C041-46DB-95BD-956EBF11E1D9@netstream.ps>
References: <vmime.57cfc28f.5555.55a2b7e92dd821ff@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <vmime.57cfd7da.1000.3ad64af64ad35c7a@ms249-lin-003.rotterdam.bazuin.nl>

Hai, 

?

Change this part : 

#############

range_offset_limit 5 Gb windowsupdate

maximum_object_size 5 Gb

quick_abort_min -1

#########

?

To 

?

range_offset_limit 0

quick_abort_min 0 KB

quick_abort_max 0 KB

quick_abort_pct 90

?

and see what happens. 

?

?

Greetz, 

?

Louis

?

?

?

?

?


Van: --Ahmad-- [mailto:ahmed.zaeem at netstream.ps] 
Verzonden: woensdag 7 september 2016 9:40
Aan: L.P.H. van Belle
CC: squid-users at squid-cache.org
Onderwerp: Re: [squid-users] windows update not working squid 3.5.2


?

thanks for reply?

?


but i still ?don?t see even the hdd drive getting increasing when windows updates go on !!!!


?


i tested it on windows 7?


?


i never seen TCP_HIT and ?the hdd size still the same !!!


?


?


here is again my ?squid.conf in final form on my server :


?


root at raspberrypi:~# cat /etc/squid/squid.conf


#########


acl windowsupdate dstdomain windowsupdate.microsoft.com


acl windowsupdate dstdomain .update.microsoft.com


acl windowsupdate dstdomain download.windowsupdate.com


acl windowsupdate dstdomain redir.metaservices.microsoft.com


acl windowsupdate dstdomain images.metaservices.microsoft.com


acl windowsupdate dstdomain c.microsoft.com


acl windowsupdate dstdomain www.download.windowsupdate.com


acl windowsupdate dstdomain wustat.windows.com


acl windowsupdate dstdomain crl.microsoft.com


acl windowsupdate dstdomain sls.microsoft.com


acl windowsupdate dstdomain productactivation.one.microsoft.com


acl windowsupdate dstdomain ntservicepack.microsoft.com


acl windowsupdate dstdomain au.download.windowsupdate.com


acl windowsupdate dstdomain ds.download.windowsupdate.com


acl windowsupdate dstdomain ctldl.windowsupdate.com


acl windowsupdate dstdomain .data.microsoft.com


acl windowsupdate dstdomain .l.windowsupdate.com


acl windowsupdate dstdomain .microsoft.com.akadns.net


acl windowsupdate dstdomain .deploy.akamaitechnologies.com


###################################################?


acl CONNECT method CONNECT


acl wuCONNECT dstdomain www.update.microsoft.com


acl wuCONNECT dstdomain sls.microsoft.com


####################################


refresh_pattern -i windowsupdate.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims


refresh_pattern -i microsoft.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims


refresh_pattern -i windows.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims


refresh_pattern -i microsoft.com.akadns.net/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims


refresh_pattern -i deploy.akamaitechnologies.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims


########################################################


refresh_pattern \^ftp: ? ? ? ? ? 1440 ? ?20% ? ? 10080


refresh_pattern \^gopher: ? ? ? ?1440 ? ?0% ? ? ?1440


refresh_pattern -i (/cgi-bin/|\?) 0 ? ? 0% ? ? ?0


refresh_pattern . ? ? ? ? ? ? ? 0 ? ? ? 20% ? ? 4320


########################################################


acl localnet src 10.0.0.0/8 ? ? # RFC1918 possible internal network


acl localnet src 172.16.0.0/12 ?# RFC1918 possible internal network


acl localnet src 192.168.0.0/16 # RFC1918 possible internal network


acl localnet src fc00::/7 ? ? ? # RFC 4193 local private network range


acl localnet src fe80::/10 ? ? ?# RFC 4291 link-local (directly plugged) machines


?


acl SSL_ports port 443


acl Safe_ports port 80 ? ? ? ? ?# http


acl Safe_ports port 21 ? ? ? ? ?# ftp


acl Safe_ports port 443 ? ? ? ? # https


acl Safe_ports port 70 ? ? ? ? ?# gopher


acl Safe_ports port 210 ? ? ? ? # wais


acl Safe_ports port 1025-65535 ?# unregistered ports


acl Safe_ports port 280 ? ? ? ? # http-mgmt


acl Safe_ports port 488 ? ? ? ? # gss-http


acl Safe_ports port 591 ? ? ? ? # filemaker


acl Safe_ports port 777 ? ? ? ? # multiling http


acl CONNECT method CONNECT


?


#


# Recommended minimum Access Permission configuration:


#


# Deny requests to certain unsafe ports


http_access allow CONNECT wuCONNECT localnet


http_access allow windowsupdate localnet


http_access deny !Safe_ports


?


# Deny CONNECT to other than secure SSL ports


http_access deny CONNECT !SSL_ports


?


# Only allow cachemgr access from localhost


http_access allow localhost manager


http_access deny manager


?


# We strongly recommend the following be uncommented to protect innocent


# web applications running on the proxy server who think the only


# one who can access services on "localhost" is a local user


#http_access deny to_localhost


?


#


# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS


#


?


# Example rule allowing access from your local networks.


# Adapt localnet in the ACL section to list your (internal) IP networks


# from where browsing should be allowed


http_access allow localnet


http_access allow localhost


?


# And finally deny all other access to this proxy


http_access deny all


?


# Squid normally listens to port 3128


http_port 192.168.0.1:3128


?


# Uncomment and adjust the following to add a disk cache directory.


cache_dir ufs /var/cache/squid 20000 16 256


?


# Leave coredumps in the first cache dir


coredump_dir /var/cache/squid


?


#


# Add any of your own refresh_pattern entries above these.


#


#refresh_pattern ^ftp: ? ? ? ? ?1440 ? ?20% ? ? 10080


#refresh_pattern ^gopher: ? ? ? 1440 ? ?0% ? ? ?1440


#refresh_pattern -i (/cgi-bin/|\?) 0 ? ?0% ? ? ?0


#refresh_pattern . ? ? ? ? ? ? ?0 ? ? ? 20% ? ? 4320


#############


range_offset_limit 5 Gb windowsupdate


maximum_object_size 5 Gb


quick_abort_min -1


#########


http_port 3129 intercept


#####################


?


?


?


?


?


any other suggestions ???


?


?


?


kind regards


On Sep 7, 2016, at 10:32 AM, L.P.H. van Belle <belle at bazuin.nl> wrote:


?

acl windowsupdate dstdomain?au.download.windowsupdate.com


acl windowsupdate dstdomain?ds.download.windowsupdate.com


acl windowsupdate dstdomain?ctldl.windowsupdate.com


acl windowsupdate dstdomain .data.microsoft.com


acl windowsupdate dstdomain .l.windowsupdate.com


acl windowsupdate dstdomain .microsoft.com.akadns.net


acl windowsupdate dstdomain .deploy.akamaitechnologies.com


?


and add this one to your refresh.


refresh_pattern -i?deploy.akamaitechnologies.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims


?




?



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160907/c4c07ec0/attachment.htm>

From augustus_meyer at gmx.net  Wed Sep  7 09:02:09 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Wed, 7 Sep 2016 02:02:09 -0700 (PDT)
Subject: [squid-users] regarding to "cache videos" plugin now as open
	source
In-Reply-To: <7AC21AF8-13F6-41A7-9CC2-585274DB17E7@netstream.ps>
References: <4A92237B-E2C4-4026-AEE7-AEB0DA555956@netstream.ps>
 <7AC21AF8-13F6-41A7-9CC2-585274DB17E7@netstream.ps>
Message-ID: <1473238929356-4679394.post@n4.nabble.com>

Might be usable. Question is, how effective it will be on overall traffic, as
most famous/accessed videos to be found on youtube. Which uses https, in my
area, at least.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/regarding-to-cache-videos-plugin-now-as-open-source-tp4679366p4679394.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From ahmed.zaeem at netstream.ps  Wed Sep  7 09:08:57 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Wed, 7 Sep 2016 12:08:57 +0300
Subject: [squid-users] windows update not working squid 3.5.2
In-Reply-To: <vmime.57cfd7da.1000.3ad64af64ad35c7a@ms249-lin-003.rotterdam.bazuin.nl>
References: <vmime.57cfc28f.5555.55a2b7e92dd821ff@ms249-lin-003.rotterdam.bazuin.nl>
 <vmime.57cfd7da.1000.3ad64af64ad35c7a@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <07169996-2333-44E2-A824-4CFF19E4DC4A@netstream.ps>

its same not caching at all 
1473239296.459    990 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239296.576   1032 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239296.624   1183 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239297.332   1540 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239297.502   1145 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239297.509   1247 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239297.676   1376 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239297.836    666 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239297.911   1277 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239298.593   1146 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239298.601   1475 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239298.623   1550 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239299.174   1238 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239299.213   1327 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239299.576   1594 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239299.794   1527 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239300.070   1373 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239300.167   1356 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239300.321   1558 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
1473239300.443   1347 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream



here is config file :
#########
acl windowsupdate dstdomain windowsupdate.microsoft.com
acl windowsupdate dstdomain .update.microsoft.com
acl windowsupdate dstdomain download.windowsupdate.com
acl windowsupdate dstdomain redir.metaservices.microsoft.com
acl windowsupdate dstdomain images.metaservices.microsoft.com
acl windowsupdate dstdomain c.microsoft.com
acl windowsupdate dstdomain www.download.windowsupdate.com
acl windowsupdate dstdomain wustat.windows.com
acl windowsupdate dstdomain crl.microsoft.com
acl windowsupdate dstdomain sls.microsoft.com
acl windowsupdate dstdomain productactivation.one.microsoft.com
acl windowsupdate dstdomain ntservicepack.microsoft.com
acl windowsupdate dstdomain au.download.windowsupdate.com
acl windowsupdate dstdomain ds.download.windowsupdate.com
acl windowsupdate dstdomain ctldl.windowsupdate.com
acl windowsupdate dstdomain .data.microsoft.com
acl windowsupdate dstdomain .l.windowsupdate.com
acl windowsupdate dstdomain .microsoft.com.akadns.net
acl windowsupdate dstdomain .deploy.akamaitechnologies.com
################################################### 
acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com
####################################
refresh_pattern -i windowsupdate.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i microsoft.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i windows.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i microsoft.com.akadns.net/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i deploy.akamaitechnologies.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
########################################################
refresh_pattern \^ftp:           1440    20%     10080
refresh_pattern \^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
########################################################
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access allow CONNECT wuCONNECT localnet
http_access allow windowsupdate localnet
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.0.1:3128

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/cache/squid 20000 16 256

# Leave coredumps in the first cache dir
#coredump_dir /var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
#refresh_pattern ^ftp:          1440    20%     10080
#refresh_pattern ^gopher:       1440    0%      1440
#refresh_pattern -i (/cgi-bin/|\?) 0    0%      0
#refresh_pattern .              0       20%     4320
#############
#range_offset_limit 5 Gb windowsupdate
#maximum_object_size 5 Gb
#quick_abort_min -1
range_offset_limit 0
quick_abort_min 0 KB
quick_abort_max 0 KB
quick_abort_pct 90
#########
http_port 3129 intercept
#####################




cheers
> On Sep 7, 2016, at 12:03 PM, L.P.H. van Belle <belle at bazuin.nl> wrote:
> 
> range_offset_limit 0
> quick_abort_min 0 KB
> quick_abort_max 0 KB
> quick_abort_pct 90

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160907/4c3cc437/attachment.htm>

From ahmed.zaeem at netstream.ps  Wed Sep  7 09:12:41 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Wed, 7 Sep 2016 12:12:41 +0300
Subject: [squid-users] windows update not working squid 3.5.2
In-Reply-To: <07169996-2333-44E2-A824-4CFF19E4DC4A@netstream.ps>
References: <vmime.57cfc28f.5555.55a2b7e92dd821ff@ms249-lin-003.rotterdam.bazuin.nl>
 <vmime.57cfd7da.1000.3ad64af64ad35c7a@ms249-lin-003.rotterdam.bazuin.nl>
 <07169996-2333-44E2-A824-4CFF19E4DC4A@netstream.ps>
Message-ID: <696FBD2C-E61B-41FC-8B6E-7BBF3B2F947D@netstream.ps>

also  here is squid -k parse not sure if it helps :
root at raspberrypi:~# squid -k parse
2016/09/07 09:10:44| Startup: Initializing Authentication Schemes ...
2016/09/07 09:10:44| Startup: Initialized Authentication Scheme 'basic'
2016/09/07 09:10:44| Startup: Initialized Authentication Scheme 'digest'
2016/09/07 09:10:44| Startup: Initialized Authentication Scheme 'negotiate'
2016/09/07 09:10:44| Startup: Initialized Authentication Scheme 'ntlm'
2016/09/07 09:10:44| Startup: Initialized Authentication.
2016/09/07 09:10:44| Processing Configuration File: /etc/squid/squid.conf (depth 0)
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain windowsupdate.microsoft.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain .update.microsoft.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain download.windowsupdate.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain redir.metaservices.microsoft.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain images.metaservices.microsoft.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain c.microsoft.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain www.download.windowsupdate.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain wustat.windows.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain crl.microsoft.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain sls.microsoft.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain productactivation.one.microsoft.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain ntservicepack.microsoft.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain au.download.windowsupdate.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain ds.download.windowsupdate.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain ctldl.windowsupdate.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain .data.microsoft.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain .l.windowsupdate.com
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain .microsoft.com.akadns.net
2016/09/07 09:10:44| Processing: acl windowsupdate dstdomain .deploy.akamaitechnologies.com
2016/09/07 09:10:44| Processing: acl CONNECT method CONNECT
2016/09/07 09:10:44| Processing: acl wuCONNECT dstdomain www.update.microsoft.com
2016/09/07 09:10:44| Processing: acl wuCONNECT dstdomain sls.microsoft.com
2016/09/07 09:10:44| Processing: refresh_pattern -i windowsupdate.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
2016/09/07 09:10:44| Processing: refresh_pattern -i microsoft.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
2016/09/07 09:10:44| Processing: refresh_pattern -i windows.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
2016/09/07 09:10:44| Processing: refresh_pattern -i microsoft.com.akadns.net/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
2016/09/07 09:10:44| Processing: refresh_pattern -i deploy.akamaitechnologies.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
2016/09/07 09:10:44| Processing: refresh_pattern \^ftp:           1440    20%     10080
2016/09/07 09:10:44| Processing: refresh_pattern \^gopher:        1440    0%      1440
2016/09/07 09:10:44| Processing: refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
2016/09/07 09:10:44| Processing: refresh_pattern .               0       20%     4320
2016/09/07 09:10:44| Processing: acl localnet src 10.0.0.0/8    # RFC1918 possible internal network
2016/09/07 09:10:44| Processing: acl localnet src 172.16.0.0/12 # RFC1918 possible internal network
2016/09/07 09:10:44| Processing: acl localnet src 192.168.0.0/16        # RFC1918 possible internal network
2016/09/07 09:10:44| Processing: acl localnet src fc00::/7       # RFC 4193 local private network range
2016/09/07 09:10:44| Processing: acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
2016/09/07 09:10:44| Processing: acl SSL_ports port 443
2016/09/07 09:10:44| Processing: acl Safe_ports port 80         # http
2016/09/07 09:10:44| Processing: acl Safe_ports port 21         # ftp
2016/09/07 09:10:44| Processing: acl Safe_ports port 443                # https
2016/09/07 09:10:44| Processing: acl Safe_ports port 70         # gopher
2016/09/07 09:10:44| Processing: acl Safe_ports port 210                # wais
2016/09/07 09:10:44| Processing: acl Safe_ports port 1025-65535 # unregistered ports
2016/09/07 09:10:44| Processing: acl Safe_ports port 280                # http-mgmt
2016/09/07 09:10:44| Processing: acl Safe_ports port 488                # gss-http
2016/09/07 09:10:44| Processing: acl Safe_ports port 591                # filemaker
2016/09/07 09:10:44| Processing: acl Safe_ports port 777                # multiling http
2016/09/07 09:10:44| Processing: acl CONNECT method CONNECT
2016/09/07 09:10:44| Processing: http_access allow CONNECT wuCONNECT localnet
2016/09/07 09:10:44| Processing: http_access allow windowsupdate localnet
2016/09/07 09:10:44| Processing: http_access deny !Safe_ports
2016/09/07 09:10:44| Processing: http_access deny CONNECT !SSL_ports
2016/09/07 09:10:44| Processing: http_access allow localhost manager
2016/09/07 09:10:44| Processing: http_access deny manager
2016/09/07 09:10:44| Processing: http_access allow localnet
2016/09/07 09:10:44| Processing: http_access allow localhost
2016/09/07 09:10:44| Processing: http_access deny all
2016/09/07 09:10:44| Processing: http_port 192.168.0.1:3128
2016/09/07 09:10:44| Processing: cache_dir ufs /var/cache/squid 20000 16 256
2016/09/07 09:10:44| Processing: range_offset_limit 0
2016/09/07 09:10:44| Processing: quick_abort_min 0 KB
2016/09/07 09:10:44| Processing: quick_abort_max 0 KB
2016/09/07 09:10:44| Processing: quick_abort_pct 90
2016/09/07 09:10:44| Processing: http_port 3129 intercept
2016/09/07 09:10:44| Starting Authentication on port [::]:3129
2016/09/07 09:10:44| Disabling Authentication on port [::]:3129 (interception enabled)
2016/09/07 09:10:44| WARNING: use of 'reload-into-ims' in 'refresh_pattern' violates HTTP
2016/09/07 09:10:44| Initializing https proxy context



cheers

> On Sep 7, 2016, at 12:08 PM, --Ahmad-- <ahmed.zaeem at netstream.ps> wrote:
> 
> its same not caching at all 
> 1473239296.459    990 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239296.576   1032 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239296.624   1183 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239297.332   1540 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239297.502   1145 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239297.509   1247 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239297.676   1376 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239297.836    666 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239297.911   1277 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239298.593   1146 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239298.601   1475 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239298.623   1550 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239299.174   1238 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239299.213   1327 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239299.576   1594 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239299.794   1527 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239300.070   1373 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239300.167   1356 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239300.321   1558 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239300.443   1347 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 
> 
> 
> here is config file :
> #########
> acl windowsupdate dstdomain windowsupdate.microsoft.com <http://windowsupdate.microsoft.com/>
> acl windowsupdate dstdomain .update.microsoft.com <http://update.microsoft.com/>
> acl windowsupdate dstdomain download.windowsupdate.com <http://download.windowsupdate.com/>
> acl windowsupdate dstdomain redir.metaservices.microsoft.com <http://redir.metaservices.microsoft.com/>
> acl windowsupdate dstdomain images.metaservices.microsoft.com <http://images.metaservices.microsoft.com/>
> acl windowsupdate dstdomain c.microsoft.com <http://c.microsoft.com/>
> acl windowsupdate dstdomain www.download.windowsupdate.com <http://www.download.windowsupdate.com/>
> acl windowsupdate dstdomain wustat.windows.com <http://wustat.windows.com/>
> acl windowsupdate dstdomain crl.microsoft.com <http://crl.microsoft.com/>
> acl windowsupdate dstdomain sls.microsoft.com <http://sls.microsoft.com/>
> acl windowsupdate dstdomain productactivation.one.microsoft.com <http://productactivation.one.microsoft.com/>
> acl windowsupdate dstdomain ntservicepack.microsoft.com <http://ntservicepack.microsoft.com/>
> acl windowsupdate dstdomain au.download.windowsupdate.com <http://au.download.windowsupdate.com/>
> acl windowsupdate dstdomain ds.download.windowsupdate.com <http://ds.download.windowsupdate.com/>
> acl windowsupdate dstdomain ctldl.windowsupdate.com <http://ctldl.windowsupdate.com/>
> acl windowsupdate dstdomain .data.microsoft.com <http://data.microsoft.com/>
> acl windowsupdate dstdomain .l.windowsupdate.com <http://l.windowsupdate.com/>
> acl windowsupdate dstdomain .microsoft.com.akadns.net <http://microsoft.com.akadns.net/>
> acl windowsupdate dstdomain .deploy.akamaitechnologies.com <http://deploy.akamaitechnologies.com/>
> ################################################### 
> acl CONNECT method CONNECT
> acl wuCONNECT dstdomain www.update.microsoft.com <http://www.update.microsoft.com/>
> acl wuCONNECT dstdomain sls.microsoft.com <http://sls.microsoft.com/>
> ####################################
> refresh_pattern -i windowsupdate.com/.* <http://windowsupdate.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
> refresh_pattern -i microsoft.com/.* <http://microsoft.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
> refresh_pattern -i windows.com/.* <http://windows.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
> refresh_pattern -i microsoft.com.akadns.net/.* <http://microsoft.com.akadns.net/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
> refresh_pattern -i deploy.akamaitechnologies.com/.* <http://deploy.akamaitechnologies.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
> ########################################################
> refresh_pattern \^ftp:           1440    20%     10080
> refresh_pattern \^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> ########################################################
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
> 
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> 
> #
> # Recommended minimum Access Permission configuration:
> #
> # Deny requests to certain unsafe ports
> http_access allow CONNECT wuCONNECT localnet
> http_access allow windowsupdate localnet
> http_access deny !Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
> 
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
> 
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> #http_access deny to_localhost
> 
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> 
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
> 
> # And finally deny all other access to this proxy
> http_access deny all
> 
> # Squid normally listens to port 3128
> http_port 192.168.0.1:3128
> 
> # Uncomment and adjust the following to add a disk cache directory.
> cache_dir ufs /var/cache/squid 20000 16 256
> 
> # Leave coredumps in the first cache dir
> #coredump_dir /var/cache/squid
> 
> #
> # Add any of your own refresh_pattern entries above these.
> #
> #refresh_pattern ^ftp:          1440    20%     10080
> #refresh_pattern ^gopher:       1440    0%      1440
> #refresh_pattern -i (/cgi-bin/|\?) 0    0%      0
> #refresh_pattern .              0       20%     4320
> #############
> #range_offset_limit 5 Gb windowsupdate
> #maximum_object_size 5 Gb
> #quick_abort_min -1
> range_offset_limit 0
> quick_abort_min 0 KB
> quick_abort_max 0 KB
> quick_abort_pct 90
> #########
> http_port 3129 intercept
> #####################
> 
> 
> 
> 
> cheers
>> On Sep 7, 2016, at 12:03 PM, L.P.H. van Belle <belle at bazuin.nl <mailto:belle at bazuin.nl>> wrote:
>> 
>> range_offset_limit 0
>> quick_abort_min 0 KB
>> quick_abort_max 0 KB
>> quick_abort_pct 90
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160907/1e0fee45/attachment.htm>

From Antony.Stone at squid.open.source.it  Wed Sep  7 09:27:06 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 7 Sep 2016 11:27:06 +0200
Subject: [squid-users] Transparent Proxy
In-Reply-To: <48eea6e3dbdb46f6b7281bb5be42855d@IT-S-MAIL1.asd.local>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <201609071028.00629.Antony.Stone@squid.open.source.it>
 <48eea6e3dbdb46f6b7281bb5be42855d@IT-S-MAIL1.asd.local>
Message-ID: <201609071127.06411.Antony.Stone@squid.open.source.it>

On Wednesday 07 September 2016 at 10:51:49, John Sayce wrote:

> I believe so.  The specific command I used was:
> 
> iptables -t nat -A PREROUTING -i ens33 -p tcp --dport 80 -j REDIRECT
> --to-port 3128
> 
> (For some reason my adapter is ens33, I have no idea why it's not eth0. 
> Squid is set to run on 3128.)

That looks okay, then.

> It's fair to say I have almost no experience with iptables.  Is it iptables
> that should be doing the address translation?

Yes - the rule above tells the machine to take any packet addressed to port 80 
on any address and send it instead to the local machine (REDIRECT changes the 
destination address to 127.0.0.1, even though that's not obvious) and port 
3128.

> when the packet is sent back to the client?

Correct.  IPtables' address translation rules are automatically symmetrical - 
when a packet gets translated in one direction, a record is kept that it was 
done, and then the reply packet is automatically reverse-translated when it 
comes back in the other direction.

This is true no matter whether packets are going *through* the IPtables 
machine (ie: it's acting as a router), or whether they're being processed *on* 
the IPtables machine (as in this case).

I think we need to know more about your squid setup.

Please tell us which version of squid you are using, and post here your 
squid.conf file without comments or blank lines.


Antony.

-- 
Software development can be quick, high quality, or low cost.

The customer gets to pick any two out of three.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid1 at fuckaround.org  Wed Sep  7 13:05:25 2016
From: squid1 at fuckaround.org (Pol Hallen)
Date: Wed, 7 Sep 2016 15:05:25 +0200
Subject: [squid-users] subnet forward
Message-ID: <76433e3b-5126-eee0-ba44-d85c1bc207b4@fuckaround.org>

Hello all :-) I'm sorry if this couldn't squid problem.. honestly I 
don't know..

I've a small lan:

dsl<-WAN_NIC0_192.168.5.0/30->lan1_192.168.10.0/24 (NIC1)<-->switch+AP
                               lan2_192.168.1.0/24 (NIC2)<--->switch+AP

I've squid server v.3.1.20 on 192.168.1.20

from 192.168.1.0/24 network squid works perfectly :-))) from 
192.168.10.0/24 network squid works but: is very very very slow...

I've check firewall and routing, dns and ping and seem ok

anyone has an advice for this scenario? is it a forward/routing problem? 
any idea?

many thanks!


maximum_object_size 5 Gb
cache_dir ufs /data/vmware/squid-cache 30720 16 256
cache_mem 4096 MB

minimum_object_size 0
maximum_object_size_in_memory 512 Kb
cache_replacement_policy heap GDSF

cache_swap_low 85
cache_swap_high 90

half_closed_clients off

hosts_file /etc/hosts
memory_pools off
client_db off
dns_nameservers 127.0.0.1

via off
forwarded_for off
httpd_suppress_version_string off
follow_x_forwarded_for deny all
#visible_hostname sign.bunker.org

refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i \.(gif|png|jpg|jpeg|ico)$ 10080 90% 43200 
override-expire ignore-no-cache ignore-no-store ignore-private
refresh_pattern -i \.(iso|avi|wav|mp3|mp4|mpeg|swf|flv|x-flv)$ 43200 90% 
432000 override-expire ignore-no-cache ignore-no-store ignore-private
refresh_pattern -i \.(deb|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff)$ 
10080 90% 43200 override-expire ignore-no-cache ignore-no-store 
ignore-private
refresh_pattern -i \.index.(html|htm)$ 0 40% 10080
refresh_pattern -i \.(html|htm|css|js)$ 1440 40% 40320
refresh_pattern . 0 40% 40320

refresh_pattern -i movies.com/.* 10080 90% 43200
refresh_pattern (/cgi-bin/|\?) 0 0% 0




From Antony.Stone at squid.open.source.it  Wed Sep  7 13:20:11 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 7 Sep 2016 15:20:11 +0200
Subject: [squid-users] subnet forward
In-Reply-To: <76433e3b-5126-eee0-ba44-d85c1bc207b4@fuckaround.org>
References: <76433e3b-5126-eee0-ba44-d85c1bc207b4@fuckaround.org>
Message-ID: <201609071520.11698.Antony.Stone@squid.open.source.it>

On Wednesday 07 September 2016 at 15:05:25, Pol Hallen wrote:

> I've a small lan:
> 
> dsl<-WAN_NIC0_192.168.5.0/30->lan1_192.168.10.0/24 (NIC1)<-->switch+AP
>                                lan2_192.168.1.0/24 (NIC2)<--->switch+AP
> 
> I've squid server v.3.1.20 on 192.168.1.20
> 
> from 192.168.1.0/24 network squid works perfectly :-))) from
> 192.168.10.0/24 network squid works but: is very very very slow...
> 
> I've check firewall and routing, dns and ping and seem ok

Where's the firewall?

Show us the routing table on 192.168.1.20, and show us the routing table on 
the machine above with three network cards.  Also please tell us the IP 
addresses on its three interfaces.

Show us any NAT rules you have on that machine.

> maximum_object_size 5 Gb
> cache_dir ufs /data/vmware/squid-cache 30720 16 256
> cache_mem 4096 MB
> 
> minimum_object_size 0
> maximum_object_size_in_memory 512 Kb
> cache_replacement_policy heap GDSF
> 
> cache_swap_low 85
> cache_swap_high 90
> 
> half_closed_clients off
> 
> hosts_file /etc/hosts
> memory_pools off
> client_db off
> dns_nameservers 127.0.0.1
> 
> via off
> forwarded_for off
> httpd_suppress_version_string off
> follow_x_forwarded_for deny all
> #visible_hostname sign.bunker.org
> 
> refresh_pattern ^ftp: 1440 20% 10080
> refresh_pattern ^gopher: 1440 0% 1440
> refresh_pattern -i \.(gif|png|jpg|jpeg|ico)$ 10080 90% 43200
> override-expire ignore-no-cache ignore-no-store ignore-private
> refresh_pattern -i \.(iso|avi|wav|mp3|mp4|mpeg|swf|flv|x-flv)$ 43200 90%
> 432000 override-expire ignore-no-cache ignore-no-store ignore-private
> refresh_pattern -i \.(deb|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff)$
> 10080 90% 43200 override-expire ignore-no-cache ignore-no-store
> ignore-private
> refresh_pattern -i \.index.(html|htm)$ 0 40% 10080
> refresh_pattern -i \.(html|htm|css|js)$ 1440 40% 40320
> refresh_pattern . 0 40% 40320
> 
> refresh_pattern -i movies.com/.* 10080 90% 43200
> refresh_pattern (/cgi-bin/|\?) 0 0% 0

What?  No http_access rules or ACLs?


Antony.

-- 
Wanted: telepath.   You know where to apply.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From marcus.kool at urlfilterdb.com  Wed Sep  7 13:36:09 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 7 Sep 2016 10:36:09 -0300
Subject: [squid-users] subnet forward
In-Reply-To: <76433e3b-5126-eee0-ba44-d85c1bc207b4@fuckaround.org>
References: <76433e3b-5126-eee0-ba44-d85c1bc207b4@fuckaround.org>
Message-ID: <362f6d34-80a1-67fa-d2fe-6f71b1b18124@urlfilterdb.com>



On 09/07/2016 10:05 AM, Pol Hallen wrote:
> Hello all :-) I'm sorry if this couldn't squid problem.. honestly I don't know..
>
> I've a small lan:
>
> dsl<-WAN_NIC0_192.168.5.0/30->lan1_192.168.10.0/24 (NIC1)<-->switch+AP
>                               lan2_192.168.1.0/24 (NIC2)<--->switch+AP
>
> I've squid server v.3.1.20 on 192.168.1.20
>
> from 192.168.1.0/24 network squid works perfectly :-))) from 192.168.10.0/24 network squid works but: is very very very slow...
>
> I've check firewall and routing, dns and ping and seem ok
>
> anyone has an advice for this scenario? is it a forward/routing problem? any idea?

Since you have an ancient version of Squid I am assuming that you also have ancient hardware.
Old NICs can do speed-negotiation and duplex setting wrong and if the switch and NIC have different duplex settings, throughput is ~75K/sec where you expect 10 MB/sec.
I suggest to doublecheck speed and duplex setting on NIC and switch.

Marcus

> many thanks!
>


From squid3 at treenet.co.nz  Wed Sep  7 13:44:21 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 8 Sep 2016 01:44:21 +1200
Subject: [squid-users] Transparent Proxy
In-Reply-To: <201609071127.06411.Antony.Stone@squid.open.source.it>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <201609071028.00629.Antony.Stone@squid.open.source.it>
 <48eea6e3dbdb46f6b7281bb5be42855d@IT-S-MAIL1.asd.local>
 <201609071127.06411.Antony.Stone@squid.open.source.it>
Message-ID: <33c42e19-87f1-a463-f7eb-bc0423217444@treenet.co.nz>

On 7/09/2016 9:27 p.m., Antony Stone wrote:
> On Wednesday 07 September 2016 at 10:51:49, John Sayce wrote:
> 

FYI: Jon. Please be careful about yoru use of teh word "forward" and
"forwarding". Both NAT and routing  are methods of forwarding, but which
one is used at each particular step of the packets path through your
network from client to Squid matters A LOT.

Some routers offer "forwarding" options / settings, which actually NAT.
That will break MITM Squid installations which require routing only
outside the Squid machine.


>> I believe so.  The specific command I used was:
>>
>> iptables -t nat -A PREROUTING -i ens33 -p tcp --dport 80 -j REDIRECT
>> --to-port 3128
>>
>> (For some reason my adapter is ens33, I have no idea why it's not eth0. 
>> Squid is set to run on 3128.)
> 
> That looks okay, then.
> 
>> It's fair to say I have almost no experience with iptables.  Is it iptables
>> that should be doing the address translation?
> 
> Yes - the rule above tells the machine to take any packet addressed to port 80 
> on any address and send it instead to the local machine (REDIRECT changes the 
> destination address to 127.0.0.1, even though that's not obvious) and port 
> 3128.

No it does not change the IP to localhost. It changes the address to the
machines primary IP. If that is localhost IP then something is wrong in
the machines network interface configuration - which may lead to trouble.


> 
>> when the packet is sent back to the client?
> 
> Correct.  IPtables' address translation rules are automatically symmetrical - 
> when a packet gets translated in one direction, a record is kept that it was 
> done, and then the reply packet is automatically reverse-translated when it 
> comes back in the other direction.
> 
> This is true no matter whether packets are going *through* the IPtables 
> machine (ie: it's acting as a router), or whether they're being processed *on* 
> the IPtables machine (as in this case).
> 
> I think we need to know more about your squid setup.
> 
> Please tell us which version of squid you are using, and post here your 
> squid.conf file without comments or blank lines.
> 


Amos



From rousskov at measurement-factory.com  Wed Sep  7 13:47:17 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 7 Sep 2016 07:47:17 -0600
Subject: [squid-users] TCP_RESET non http requests on port 80
In-Reply-To: <20160907075611.GA9976@fantomas.sk>
References: <1fc69717-57d1-d600-ee26-8c39a70a3665@measurement-factory.com>
 <1472298288404-4679212.post@n4.nabble.com>
 <079edebc-9f88-3cbb-d4c2-c79629b1da0a@measurement-factory.com>
 <1472375429698-4679222.post@n4.nabble.com>
 <e4ab7076-5343-9c4c-d83a-24c508bd01ad@measurement-factory.com>
 <1472478056062-4679239.post@n4.nabble.com>
 <14b920b2-67b5-31c8-b85e-96eea33768f0@measurement-factory.com>
 <1473143528034-4679361.post@n4.nabble.com>
 <20160906143620.GA15684@fantomas.sk>
 <f3a72736-d714-e661-56c2-a135a81e9cd3@measurement-factory.com>
 <20160907075611.GA9976@fantomas.sk>
Message-ID: <7e9d08ca-d36e-e3c1-4430-b0e0ebd8224f@measurement-factory.com>

On 09/07/2016 01:56 AM, Matus UHLAR - fantomas wrote:

> and how is this done? Which system or library call does drop connection to
> send a RST immediately?

This is not a squid-users question, but Squid calls comm_reset_close()
(quoted below) to reset the connection. That function uses zero
SO_LINGER option value to trigger a TCP reset when the connection is
closed. AFAICT, this is a "standard" approach.

I do not know whether that approach results in an actual TCP reset
packet immediately sent (as opposed to responding to any incoming
packets on the same connection with TCP reset packets).


HTH,

Alex.

> /**
>  * enable linger with time of 0 so that when the socket is
>  * closed, TCP generates a RESET
>  */
> void
> comm_reset_close(const Comm::ConnectionPointer &conn)
> {
>     struct linger L;
>     L.l_onoff = 1;
>     L.l_linger = 0;
> 
>     if (setsockopt(conn->fd, SOL_SOCKET, SO_LINGER, (char *) &L, sizeof(L)) < 0) {
>         int xerrno = errno;
>         debugs(50, DBG_CRITICAL, "ERROR: Closing " << conn << " with TCP RST: " << xstrerr(xerrno));
>     }
>     conn->close();
> }



From squid3 at treenet.co.nz  Wed Sep  7 14:10:08 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 8 Sep 2016 02:10:08 +1200
Subject: [squid-users] windows update not working squid 3.5.2
In-Reply-To: <07169996-2333-44E2-A824-4CFF19E4DC4A@netstream.ps>
References: <vmime.57cfc28f.5555.55a2b7e92dd821ff@ms249-lin-003.rotterdam.bazuin.nl>
 <vmime.57cfd7da.1000.3ad64af64ad35c7a@ms249-lin-003.rotterdam.bazuin.nl>
 <07169996-2333-44E2-A824-4CFF19E4DC4A@netstream.ps>
Message-ID: <088ea327-4393-b385-230a-7fddcc6086eb@treenet.co.nz>

On 7/09/2016 9:08 p.m., --Ahmad-- wrote:
> its same not caching at all 
> 1473239296.459    990 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239296.576   1032 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239296.624   1183 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239297.332   1540 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239297.502   1145 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239297.509   1247 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239297.676   1376 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239297.836    666 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239297.911   1277 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239298.593   1146 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239298.601   1475 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239298.623   1550 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239299.174   1238 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239299.213   1327 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239299.576   1594 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239299.794   1527 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239300.070   1373 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239300.167   1356 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239300.321   1558 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 1473239300.443   1347 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.254.191.254 application/octet-stream
> 

That is expected, with maximum_object_size at the default value of 4MB
the object in those URLs is too large to be stored. It is ~231 MB big.

You need to place this line *before* the cache_dir line:
  	maximum_object_size 1 GB

NP: you used to have it *after* the cache_dir, which means the HDD used
4MB default and your new config limit was not used for any cache_dir.


> here is config file :
> #########
> acl windowsupdate dstdomain windowsupdate.microsoft.com
> acl windowsupdate dstdomain .update.microsoft.com
> acl windowsupdate dstdomain download.windowsupdate.com
> acl windowsupdate dstdomain redir.metaservices.microsoft.com
> acl windowsupdate dstdomain images.metaservices.microsoft.com
> acl windowsupdate dstdomain c.microsoft.com
> acl windowsupdate dstdomain www.download.windowsupdate.com
> acl windowsupdate dstdomain wustat.windows.com
> acl windowsupdate dstdomain crl.microsoft.com
> acl windowsupdate dstdomain sls.microsoft.com
> acl windowsupdate dstdomain productactivation.one.microsoft.com
> acl windowsupdate dstdomain ntservicepack.microsoft.com
> acl windowsupdate dstdomain au.download.windowsupdate.com
> acl windowsupdate dstdomain ds.download.windowsupdate.com
> acl windowsupdate dstdomain ctldl.windowsupdate.com
> acl windowsupdate dstdomain .data.microsoft.com
> acl windowsupdate dstdomain .l.windowsupdate.com
> acl windowsupdate dstdomain .microsoft.com.akadns.net
> acl windowsupdate dstdomain .deploy.akamaitechnologies.com
> ################################################### 
> acl CONNECT method CONNECT
> acl wuCONNECT dstdomain www.update.microsoft.com
> acl wuCONNECT dstdomain sls.microsoft.com
> ####################################
> refresh_pattern -i windowsupdate.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
> refresh_pattern -i microsoft.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
> refresh_pattern -i windows.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
> refresh_pattern -i microsoft.com.akadns.net/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
> refresh_pattern -i deploy.akamaitechnologies.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
> ########################################################
> refresh_pattern \^ftp:           1440    20%     10080
> refresh_pattern \^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> ########################################################
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
> 
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> 
> #
> # Recommended minimum Access Permission configuration:
> #
> # Deny requests to certain unsafe ports
> http_access allow CONNECT wuCONNECT localnet
> http_access allow windowsupdate localnet

Given that your config simply has "allow localnet" after the security
rules. With nothing complicated like auth or domain restrictions. You do
not need the above rules at all. WU uses regular port 443.


> http_access deny !Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
> 
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
> 
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> #http_access deny to_localhost
> 
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> 
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
> 
> # And finally deny all other access to this proxy
> http_access deny all
> 
> # Squid normally listens to port 3128
> http_port 192.168.0.1:3128
> 
> # Uncomment and adjust the following to add a disk cache directory.
> cache_dir ufs /var/cache/squid 20000 16 256
> 
> # Leave coredumps in the first cache dir
> #coredump_dir /var/cache/squid
> 
> #
> # Add any of your own refresh_pattern entries above these.
> #
> #refresh_pattern ^ftp:          1440    20%     10080
> #refresh_pattern ^gopher:       1440    0%      1440
> #refresh_pattern -i (/cgi-bin/|\?) 0    0%      0
> #refresh_pattern .              0       20%     4320

You already have refresh_pattern above. Remove the above lines entirely,
its just a waste of text in your config file that maybe confusing.

> #############
> #range_offset_limit 5 Gb windowsupdate
> #maximum_object_size 5 Gb
> #quick_abort_min -1
> range_offset_limit 0

In current Squid the above line means any Range: requested which is more
than 0 bytes into the file will be sent upstream as a Range request (the
reply to which is not cacheable).

Now use the word "none" in place of the 0 and see what changes.


> quick_abort_min 0 KB
> quick_abort_max 0 KB
> quick_abort_pct 90
> #########
> http_port 3129 intercept
> #####################
> 

Amos



From squid1 at fuckaround.org  Wed Sep  7 16:01:13 2016
From: squid1 at fuckaround.org (Pol Hallen)
Date: Wed, 7 Sep 2016 18:01:13 +0200
Subject: [squid-users] subnet forward
In-Reply-To: <362f6d34-80a1-67fa-d2fe-6f71b1b18124@urlfilterdb.com>
References: <76433e3b-5126-eee0-ba44-d85c1bc207b4@fuckaround.org>
 <362f6d34-80a1-67fa-d2fe-6f71b1b18124@urlfilterdb.com>
Message-ID: <1b7376ba-baa0-a2e0-1a6b-acf18ec01746@fuckaround.org>

> Since you have an ancient version of Squid I am assuming that you also
> have ancient hardware.

:-)

NIC are not so ancient :-) hw also..

Settings for eth0:
	Supported ports: [ TP MII ]
	Supported link modes:   10baseT/Half 10baseT/Full
	                        100baseT/Half 100baseT/Full
	                        1000baseT/Half 1000baseT/Full
	Supported pause frame use: No
	Supports auto-negotiation: Yes
	Advertised link modes:  10baseT/Half 10baseT/Full
	                        100baseT/Half 100baseT/Full
	                        1000baseT/Half 1000baseT/Full
	Advertised pause frame use: Symmetric Receive-only
	Advertised auto-negotiation: Yes
	Link partner advertised link modes:  10baseT/Half 10baseT/Full
	                                     100baseT/Half 100baseT/Full
	                                     1000baseT/Full
	Link partner advertised pause frame use: Symmetric
	Link partner advertised auto-negotiation: Yes
	Speed: 1000Mb/s
	Duplex: Full
	Port: MII
	PHYAD: 0
	Transceiver: internal
	Auto-negotiation: on
	Supports Wake-on: pumbg
	Wake-on: g
	Current message level: 0x00000033 (51)
			       drv probe ifdown ifup
	Link detected: yes

Pol


From mzgmedia at gmail.com  Wed Sep  7 16:02:41 2016
From: mzgmedia at gmail.com (mzgmedia)
Date: Wed, 7 Sep 2016 09:02:41 -0700 (PDT)
Subject: [squid-users] compliled squid size
Message-ID: <1473264161043-4679405.post@n4.nabble.com>

hello

I've tried to compile squid with the same params as on
www1.ngtech.co.il/repo/ but the binnary size of the squid is 50M but the one
from the repo is only 6M, any idea why?




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/compliled-squid-size-tp4679405.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From uhlar at fantomas.sk  Wed Sep  7 16:17:49 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 7 Sep 2016 18:17:49 +0200
Subject: [squid-users] compliled squid size
In-Reply-To: <1473264161043-4679405.post@n4.nabble.com>
References: <1473264161043-4679405.post@n4.nabble.com>
Message-ID: <20160907161749.GA18997@fantomas.sk>

On 07.09.16 09:02, mzgmedia wrote:
>I've tried to compile squid with the same params as on
>www1.ngtech.co.il/repo/ but the binnary size of the squid is 50M but the one
>from the repo is only 6M, any idea why?

apparently unstriped binary (compiled/linked without the "-s" flag)

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Your mouse has moved. Windows NT will now restart for changes to take
to take effect. [OK]


From eliezer at ngtech.co.il  Wed Sep  7 16:56:47 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 7 Sep 2016 19:56:47 +0300
Subject: [squid-users] Windows Updates a Caching Stub zone,
	A windows updates store.
In-Reply-To: <1473173298160-4679373.post@n4.nabble.com>
References: <004a01d1daf3$e6c4a490$b44dedb0$@ngtech.co.il>
 <1473173298160-4679373.post@n4.nabble.com>
Message-ID: <01ed01d20928$d2606440$77212cc0$@ngtech.co.il>

Hey Omid,

For now the software is restricted only to windows updates which is protected and secured enough to sustain caching.
About Mozilla, I need to verify it before I am doing anything about it.
>From my point of view it is hosted on Akamai and HSTS is restricting couple things on their service.
I will try to look at it later without any promises.

Do you have any starting points else then the domain itself?
Have you tried to analyze some logs?

Eliezer 

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Omid Kosari
Sent: Tuesday, September 6, 2016 5:48 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Windows Updates a Caching Stub zone, A windows updates store.

Hey Eliezer,

According to these threads
http://squid-web-proxy-cache.1019090.n4.nabble.com/range-offset-limit-not-working-as-expected-td4679355.html

http://squid-web-proxy-cache.1019090.n4.nabble.com/TProxy-and-client-dst-passthru-td4670189.html

Is there any chance that you implement something that may be used for other
(206 partial) popular sites like download.cdn.mozilla.net . I think it has also same problem as windows update and has lots of uncachable requests .

Thanks in advance .



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Windows-Updates-a-Caching-Stub-zone-A-windows-updates-store-tp4678454p4679373.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From marcus.kool at urlfilterdb.com  Wed Sep  7 18:17:09 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 7 Sep 2016 15:17:09 -0300
Subject: [squid-users] subnet forward
In-Reply-To: <1b7376ba-baa0-a2e0-1a6b-acf18ec01746@fuckaround.org>
References: <76433e3b-5126-eee0-ba44-d85c1bc207b4@fuckaround.org>
 <362f6d34-80a1-67fa-d2fe-6f71b1b18124@urlfilterdb.com>
 <1b7376ba-baa0-a2e0-1a6b-acf18ec01746@fuckaround.org>
Message-ID: <a1068530-2b56-cecf-6fd6-be882595d485@urlfilterdb.com>

to be sure that the link speed and duplex is OK, you need to look at both sides.

Marcus

On 09/07/2016 01:01 PM, Pol Hallen wrote:
>> Since you have an ancient version of Squid I am assuming that you also
>> have ancient hardware.
>
> :-)
>
> NIC are not so ancient :-) hw also..
>
> Settings for eth0:
>     Supported ports: [ TP MII ]
>     Supported link modes:   10baseT/Half 10baseT/Full
>                             100baseT/Half 100baseT/Full
>                             1000baseT/Half 1000baseT/Full
>     Supported pause frame use: No
>     Supports auto-negotiation: Yes
>     Advertised link modes:  10baseT/Half 10baseT/Full
>                             100baseT/Half 100baseT/Full
>                             1000baseT/Half 1000baseT/Full
>     Advertised pause frame use: Symmetric Receive-only
>     Advertised auto-negotiation: Yes
>     Link partner advertised link modes:  10baseT/Half 10baseT/Full
>                                          100baseT/Half 100baseT/Full
>                                          1000baseT/Full
>     Link partner advertised pause frame use: Symmetric
>     Link partner advertised auto-negotiation: Yes
>     Speed: 1000Mb/s
>     Duplex: Full
>     Port: MII
>     PHYAD: 0
>     Transceiver: internal
>     Auto-negotiation: on
>     Supports Wake-on: pumbg
>     Wake-on: g
>     Current message level: 0x00000033 (51)
>                    drv probe ifdown ifup
>     Link detected: yes
>
> Pol
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From erdosain9 at gmail.com  Wed Sep  7 20:25:47 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 7 Sep 2016 13:25:47 -0700 (PDT)
Subject: [squid-users] ssl bump certificate question
Message-ID: <1473279947243-4679409.post@n4.nabble.com>


Hi.
A query. Sslbump is possible without installing the certificate, machine by
machine ???
Is there any way that this certificate Squid SUBMIT ??

sorry for my english.....

Thanks!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/ssl-bump-certificate-question-tp4679409.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Wed Sep  7 20:55:06 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 8 Sep 2016 02:55:06 +0600
Subject: [squid-users] ssl bump certificate question
In-Reply-To: <1473279947243-4679409.post@n4.nabble.com>
References: <1473279947243-4679409.post@n4.nabble.com>
Message-ID: <0e2cfcd1-ab3e-5b2f-5593-f0c3396377cd@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


08.09.2016 2:25, erdosain9 ?????:
>
> Hi.
> A query. Sslbump is possible without installing the certificate,
machine by
> machine ???
Bump impossible. Splice - possible.
>
> Is there any way that this certificate Squid SUBMIT ??
Cant understand question. What do you mean?
>
>
> sorry for my english.....
>
> Thanks!
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/ssl-bump-certificate-question-tp4679409.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX0H6pAAoJENNXIZxhPexG4bgIALO4Gudeot2aSVp9ckCaRdDO
mMv9R9P1W2rT2b2tZt9b39mFrU7qFnF/m1m3p1++vqBr7StSZKyeWxJFYhwXA86p
cvKiyk6Nd/1u29eXfr4+dJRFD2jf3aax84cjgAIlJLzZrO3QAYzEZs/f36GkmFVs
WDz/1oOjpH7hXqoohVL4X+DFUb9Iq5DHwMLP6pDhu9d4sFxX0DOQfoilp9P7gBd5
yxXevN/kfjaf8Rm53xLYjPO81dY9iLkMJEwt4aEQpBHvNd2hWKgIk9sjS6d58++L
MiKUDiCzW6BZMhQB6tZ6LaDYULH2eThjJ1a8Ahc36N3uglHdG4CQrEh64aDcMj0=
=avbu
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160908/d3301a28/attachment.key>

From Antony.Stone at squid.open.source.it  Wed Sep  7 20:58:07 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 7 Sep 2016 22:58:07 +0200
Subject: [squid-users] ssl bump certificate question
In-Reply-To: <0e2cfcd1-ab3e-5b2f-5593-f0c3396377cd@gmail.com>
References: <1473279947243-4679409.post@n4.nabble.com>
 <0e2cfcd1-ab3e-5b2f-5593-f0c3396377cd@gmail.com>
Message-ID: <201609072258.07445.Antony.Stone@squid.open.source.it>

On Wednesday 07 September 2016 at 22:55:06, Yuri Voinov wrote:

> 08.09.2016 2:25, erdosain9 ?????:
> > Hi.
> > A query. Sslbump is possible without installing the certificate,
> > machine by machine ???
> 
> Bump impossible. Splice - possible.
> 
> > Is there any way that this certificate Squid SUBMIT ??
> 
> Cant understand question. What do you mean?

I believe he wants a mechanism for squid to be able to provide the fake CA 
certificate to the browser, so that the browser then trusts the fake site 
certificate which is signed with it.

Of course, this is impossible, since any mechanism which allowed this would 
allow the browser to be fooled into trusting any certificate anyone cared to 
wave at it.


Antony.

-- 
#define SIX 1+5
#define NINE 8+1

int main() {
    printf("%d\n", SIX * NINE);
}
	- thanks to ECB for bringing this to my attention

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Wed Sep  7 20:59:40 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 8 Sep 2016 02:59:40 +0600
Subject: [squid-users] ssl bump certificate question
In-Reply-To: <201609072258.07445.Antony.Stone@squid.open.source.it>
References: <1473279947243-4679409.post@n4.nabble.com>
 <0e2cfcd1-ab3e-5b2f-5593-f0c3396377cd@gmail.com>
 <201609072258.07445.Antony.Stone@squid.open.source.it>
Message-ID: <99827859-d8c6-0bb5-71e7-eb8fb5105b77@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


08.09.2016 2:58, Antony Stone ?????:
> On Wednesday 07 September 2016 at 22:55:06, Yuri Voinov wrote:
>
>> 08.09.2016 2:25, erdosain9 ?????:
>>> Hi.
>>> A query. Sslbump is possible without installing the certificate,
>>> machine by machine ???
>>
>> Bump impossible. Splice - possible.
>>
>>> Is there any way that this certificate Squid SUBMIT ??
>>
>> Cant understand question. What do you mean?
>
> I believe he wants a mechanism for squid to be able to provide the
fake CA
> certificate to the browser, so that the browser then trusts the fake site
> certificate which is signed with it.
>
> Of course, this is impossible, since any mechanism which allowed this
would
> allow the browser to be fooled into trusting any certificate anyone
cared to
> wave at it.
(facepalm)
>
>
>
> Antony.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX0H+7AAoJENNXIZxhPexG8+YH/jq85O+ieQ5+Bf5CK2arYyb2
F7p7sa3+bgFY4zuw9e592fCWlMaUEQdCVGSwnSJv6Zaxsylst/GnBk8d1yq1PyAR
R6CKr9itvwvyfqKXpqbasB41NogbesHn21ht5ttxusv+c0i1onp6BHDkWRVDEBTA
RLrdBZmw/yuHCOKXi3L3Ef/0k7OVHfbvTXUAcI70cweaGMr8Nbofm6Zn/T6LN2ow
FJKSFrWpluMFhidaMhEuLiJ/FmbgCJSl2E14Bz57YBusiMVmjNvJjIpo5dnPbxnF
HyQrkRq/UJxHw2YIeVIrQ4+Yubw4xxerw7R2ecO3fCoH7Y6dyL/D4R2e96t33dw=
=SvH8
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160908/74e0e321/attachment.key>

From erdosain9 at gmail.com  Wed Sep  7 21:14:24 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 7 Sep 2016 14:14:24 -0700 (PDT)
Subject: [squid-users] ssl bump certificate question
In-Reply-To: <99827859-d8c6-0bb5-71e7-eb8fb5105b77@gmail.com>
References: <1473279947243-4679409.post@n4.nabble.com>
 <0e2cfcd1-ab3e-5b2f-5593-f0c3396377cd@gmail.com>
 <201609072258.07445.Antony.Stone@squid.open.source.it>
 <99827859-d8c6-0bb5-71e7-eb8fb5105b77@gmail.com>
Message-ID: <1473282864750-4679413.post@n4.nabble.com>


"I believe he wants a mechanism for squid to be able to provide the fake CA 
certificate to the browser"
Exactly......... ok, no possible then.
Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/ssl-bump-certificate-question-tp4679409p4679413.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From marcus.kool at urlfilterdb.com  Wed Sep  7 22:05:49 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 7 Sep 2016 19:05:49 -0300
Subject: [squid-users] ssl bump certificate question
In-Reply-To: <201609072258.07445.Antony.Stone@squid.open.source.it>
References: <1473279947243-4679409.post@n4.nabble.com>
 <0e2cfcd1-ab3e-5b2f-5593-f0c3396377cd@gmail.com>
 <201609072258.07445.Antony.Stone@squid.open.source.it>
Message-ID: <a32c6810-ef58-8e70-8fa7-16193fb07683@urlfilterdb.com>



On 09/07/2016 05:58 PM, Antony Stone wrote:
> On Wednesday 07 September 2016 at 22:55:06, Yuri Voinov wrote:
>
>> 08.09.2016 2:25, erdosain9 ?????:
>>> Hi.
>>> A query. Sslbump is possible without installing the certificate,
>>> machine by machine ???
>>
>> Bump impossible. Splice - possible.
>>
>>> Is there any way that this certificate Squid SUBMIT ??
>>
>> Cant understand question. What do you mean?
>
> I believe he wants a mechanism for squid to be able to provide the fake CA
> certificate to the browser, so that the browser then trusts the fake site
> certificate which is signed with it.
>
> Of course, this is impossible, since any mechanism which allowed this would
> allow the browser to be fooled into trusting any certificate anyone cared to
> wave at it.
>
>
> Antony.

Yes, I also interpret his question like that.

slightly off topic: what is the easiest way to install a cert on a smartphone?
I looked for an app but did not find one.

Marcus

--
int main()
{
    printf("42\n");
}


From marcus.kool at urlfilterdb.com  Wed Sep  7 22:06:02 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Wed, 7 Sep 2016 19:06:02 -0300
Subject: [squid-users] ssl bump certificate question
In-Reply-To: <201609072258.07445.Antony.Stone@squid.open.source.it>
References: <1473279947243-4679409.post@n4.nabble.com>
 <0e2cfcd1-ab3e-5b2f-5593-f0c3396377cd@gmail.com>
 <201609072258.07445.Antony.Stone@squid.open.source.it>
Message-ID: <694b415e-434d-18f0-4b7e-54252ada9569@urlfilterdb.com>



On 09/07/2016 05:58 PM, Antony Stone wrote:
> On Wednesday 07 September 2016 at 22:55:06, Yuri Voinov wrote:
>
>> 08.09.2016 2:25, erdosain9 ?????:
>>> Hi.
>>> A query. Sslbump is possible without installing the certificate,
>>> machine by machine ???
>>
>> Bump impossible. Splice - possible.
>>
>>> Is there any way that this certificate Squid SUBMIT ??
>>
>> Cant understand question. What do you mean?
>
> I believe he wants a mechanism for squid to be able to provide the fake CA
> certificate to the browser, so that the browser then trusts the fake site
> certificate which is signed with it.
>
> Of course, this is impossible, since any mechanism which allowed this would
> allow the browser to be fooled into trusting any certificate anyone cared to
> wave at it.
>
>
> Antony.

Yes, I also interpret his question like that.

slightly off topic: what is the easiest way to install a cert on a smartphone?
I looked for an app but did not find one.

Marcus

--
int main()
{
    printf("42\n");
}


From Antony.Stone at squid.open.source.it  Wed Sep  7 22:23:56 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 8 Sep 2016 00:23:56 +0200
Subject: [squid-users] ssl bump certificate question
In-Reply-To: <694b415e-434d-18f0-4b7e-54252ada9569@urlfilterdb.com>
References: <1473279947243-4679409.post@n4.nabble.com>
 <201609072258.07445.Antony.Stone@squid.open.source.it>
 <694b415e-434d-18f0-4b7e-54252ada9569@urlfilterdb.com>
Message-ID: <201609080023.56462.Antony.Stone@squid.open.source.it>

On Thursday 08 September 2016 at 00:06:02, Marcus Kool wrote:

> slightly off topic: what is the easiest way to install a cert on a
> smartphone? I looked for an app but did not find one.

On my Android 4.2.2 device:

Settings -> Security -> Trusted credentials: "Display trusted CA certificates"

Settings -> Security -> Install from SD card: "Install certificates from SD 
card"


Antony.

-- 
You can tell that the day just isn't going right when you find yourself using 
the telephone before the toilet.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From jok at spikes.com  Wed Sep  7 22:56:28 2016
From: jok at spikes.com (Jok Thuau)
Date: Wed, 7 Sep 2016 15:56:28 -0700
Subject: [squid-users] ssl bump certificate question
In-Reply-To: <a32c6810-ef58-8e70-8fa7-16193fb07683@urlfilterdb.com>
References: <1473279947243-4679409.post@n4.nabble.com>
 <0e2cfcd1-ab3e-5b2f-5593-f0c3396377cd@gmail.com>
 <201609072258.07445.Antony.Stone@squid.open.source.it>
 <a32c6810-ef58-8e70-8fa7-16193fb07683@urlfilterdb.com>
Message-ID: <CADSSinP7YCMyhDwYtkaQpnvSEKxT05oww=2pFyBogyFGZHZa6A@mail.gmail.com>

On Wed, Sep 7, 2016 at 3:05 PM, Marcus Kool <marcus.kool at urlfilterdb.com>
wrote:

>
> slightly off topic: what is the easiest way to install a cert on a
> smartphone?
> I looked for an app but did not find one.
>
>
Look for some MDM solutions. That's not really an option for one (personal)
phone, but for a company, that allows you to manage a fleet of phone
long-term, including profiles, policies, etc (including certs, both client
certs and root certs).
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160907/74cd914c/attachment.htm>

From jsayce at asdlighting.com  Thu Sep  8 08:12:48 2016
From: jsayce at asdlighting.com (John Sayce)
Date: Thu, 8 Sep 2016 08:12:48 +0000
Subject: [squid-users] Transparent Proxy
In-Reply-To: <201609071127.06411.Antony.Stone@squid.open.source.it>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <201609071028.00629.Antony.Stone@squid.open.source.it>
 <48eea6e3dbdb46f6b7281bb5be42855d@IT-S-MAIL1.asd.local>
 <201609071127.06411.Antony.Stone@squid.open.source.it>
Message-ID: <34e818ab3ba94c8ba86664959eef0ef7@IT-S-MAIL1.asd.local>

For testing purposes I've reduced it to the following:

http_port 3128 intercept
#dns_v4_first on
dns_nameservers 10.8.2.3 194.168.4.100 10.8.2.2 8.8.8.8
acl wifi src 10.8.14.0/24
acl all src all
http_access allow all
maximum_object_size 1 GB
minimum_object_size 0 KB
maximum_object_size_in_memory 4 MB
cache_mem 1700 MB
cache_dir aufs /var/cache/squid 40000 32 512
coredump_dir /var/cache/squid
access_log /var/log/squid/access.log squid
cache_log /var/log/squid/cache.log
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
cache_effective_user asd
cache_effective_group asd
cache_mgr jsayce at asdlighting.com
forwarded_for off

The version is 3.5.12

Okay.  Sorry, to clarify with a specific example.  Lets say I'm contacting http://1.1.1.1/ then the ack packet starts off with the client with ip address 10.8.14.9 in subnet 10.8.14.9/24 with default gateway 10.8.14.1.  It's routed through my core switch to my my firewall with ip 10.8.1.1.  My firewall recognises that the packet has a destination port 80 and is in subnet 10.8.14.0/24 and changes the destination address to be that of my proxy server 10.8.2.11.  So now the ack packet has source 10.8.14.9 and destination 10.8.2.11.  How does iptables know to reply to my client 10.8.14.9 with source address 1.1.1.1?  Does iptables know to read the header?

Thanks


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Antony Stone
Sent: 07 September 2016 10:27
To: 'squid-users at lists.squid-cache.org'
Subject: Re: [squid-users] Transparent Proxy

On Wednesday 07 September 2016 at 10:51:49, John Sayce wrote:

> I believe so.  The specific command I used was:
> 
> iptables -t nat -A PREROUTING -i ens33 -p tcp --dport 80 -j REDIRECT 
> --to-port 3128
> 
> (For some reason my adapter is ens33, I have no idea why it's not eth0. 
> Squid is set to run on 3128.)

That looks okay, then.

> It's fair to say I have almost no experience with iptables.  Is it 
> iptables that should be doing the address translation?

Yes - the rule above tells the machine to take any packet addressed to port 80 on any address and send it instead to the local machine (REDIRECT changes the destination address to 127.0.0.1, even though that's not obvious) and port 3128.

> when the packet is sent back to the client?

Correct.  IPtables' address translation rules are automatically symmetrical - when a packet gets translated in one direction, a record is kept that it was done, and then the reply packet is automatically reverse-translated when it comes back in the other direction.

This is true no matter whether packets are going *through* the IPtables machine (ie: it's acting as a router), or whether they're being processed *on* the IPtables machine (as in this case).

I think we need to know more about your squid setup.

Please tell us which version of squid you are using, and post here your squid.conf file without comments or blank lines.


Antony.

-- 
Software development can be quick, high quality, or low cost.

The customer gets to pick any two out of three.

                                                   Please reply to the list;
                                                         please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From Antony.Stone at squid.open.source.it  Thu Sep  8 08:36:07 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 8 Sep 2016 10:36:07 +0200
Subject: [squid-users] Transparent Proxy
In-Reply-To: <34e818ab3ba94c8ba86664959eef0ef7@IT-S-MAIL1.asd.local>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <201609071127.06411.Antony.Stone@squid.open.source.it>
 <34e818ab3ba94c8ba86664959eef0ef7@IT-S-MAIL1.asd.local>
Message-ID: <201609081036.07978.Antony.Stone@squid.open.source.it>

On Thursday 08 September 2016 at 10:12:48, John Sayce wrote:

> For testing purposes I've reduced it to the following:
> 
> http_port 3128 intercept
> #dns_v4_first on
> dns_nameservers 10.8.2.3 194.168.4.100 10.8.2.2 8.8.8.8
> acl wifi src 10.8.14.0/24
> acl all src all
> http_access allow all
> maximum_object_size 1 GB
> minimum_object_size 0 KB
> maximum_object_size_in_memory 4 MB
> cache_mem 1700 MB
> cache_dir aufs /var/cache/squid 40000 32 512
> coredump_dir /var/cache/squid
> access_log /var/log/squid/access.log squid
> cache_log /var/log/squid/cache.log
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> cache_effective_user asd
> cache_effective_group asd
> cache_mgr jsayce at asdlighting.com
> forwarded_for off
> 
> The version is 3.5.12
> 
> Okay.  Sorry, to clarify with a specific example.

Don't apologise - specific examples are good, because it makes sure we're both 
talking about the same thing (and sometimes, as below, reveals little details 
about the network arrangement which weren't previously clear).

> Lets say I'm contacting http://1.1.1.1/ then the ack packet starts off with
> the client with ip address 10.8.14.9

So, source IP = 10.8.14.9 : destination IP = 1.1.11

> in subnet 10.8.14.9/24 with default gateway 10.8.14.1. 
> It's routed through my core switch to my my firewall with ip 10.8.1.1.

So that's a router, not just a switch?  It has one interface 10.8.14.1 on 
subnet 10.8.14.0/24 and another interface on (presumably) 10.8.1.0/24 pointing 
at 10.8.1.1 as the next-hop route towards 1.1.1.1

> My firewall recognises that the packet has a destination port 80 and is in
> subnet 10.8.14.0/24

The source address is in that subnet, yes.

> and changes the destination address to be that of my proxy server 10.8.2.11.

No - see below.

> So now the ack packet has source 10.8.14.9 and destination 10.8.2.11.

No, it doesn't.  When a packet goes via a router, its destination IP address 
is not changed to the address of the next-hop router (otherwise things would 
never work across the Internet).

It's only the destination MAC address in the encapsulating ethernet frame 
which gets changed to that of the next-hop router.  The source and destination 
IP addresses inside are not touched.

> How does iptables know to reply to my client 10.8.14.9 with source address
> 1.1.1.1?  Does iptables know to read the header?

TCP header, yes.

HTTP header, no.

Just think about the very first link between the client and its default 
gateway:

Packet with source address = 10.8.14.9, destinatoin address = 1.1.1.1

How does that packet get to the default router 10.8.14.1?  Its destination IP 
is 1.1.1.1, so that doesn't help.

It's because the destination MAC address in the ethernet frame containing that 
IP packet is the MAC address of 10.8.14.1.

A few minutes playing around with wireshark on your network could be quite 
enlightening :)



Regards,


Antony.

-- 
I think broken pencils are pointless.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From jsayce at asdlighting.com  Thu Sep  8 08:44:12 2016
From: jsayce at asdlighting.com (John Sayce)
Date: Thu, 8 Sep 2016 08:44:12 +0000
Subject: [squid-users] Transparent Proxy
In-Reply-To: <201609081036.07978.Antony.Stone@squid.open.source.it>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <201609071127.06411.Antony.Stone@squid.open.source.it>
 <34e818ab3ba94c8ba86664959eef0ef7@IT-S-MAIL1.asd.local>
 <201609081036.07978.Antony.Stone@squid.open.source.it>
Message-ID: <c1871bc8b9fe4e51b02fba9f36e274e6@IT-S-MAIL1.asd.local>

After I wrote this I realised it should be changing the mac not the ip, which is not what?s happeneing.  I think it's my firewall configuration that's wrong.

Thanks



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Antony Stone
Sent: 08 September 2016 09:36
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Transparent Proxy

On Thursday 08 September 2016 at 10:12:48, John Sayce wrote:

> For testing purposes I've reduced it to the following:
> 
> http_port 3128 intercept
> #dns_v4_first on
> dns_nameservers 10.8.2.3 194.168.4.100 10.8.2.2 8.8.8.8 acl wifi src 
> 10.8.14.0/24 acl all src all http_access allow all maximum_object_size 
> 1 GB minimum_object_size 0 KB maximum_object_size_in_memory 4 MB 
> cache_mem 1700 MB cache_dir aufs /var/cache/squid 40000 32 512 
> coredump_dir /var/cache/squid access_log /var/log/squid/access.log 
> squid cache_log /var/log/squid/cache.log
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> cache_effective_user asd
> cache_effective_group asd
> cache_mgr jsayce at asdlighting.com
> forwarded_for off
> 
> The version is 3.5.12
> 
> Okay.  Sorry, to clarify with a specific example.

Don't apologise - specific examples are good, because it makes sure we're both talking about the same thing (and sometimes, as below, reveals little details about the network arrangement which weren't previously clear).

> Lets say I'm contacting http://1.1.1.1/ then the ack packet starts off 
> with the client with ip address 10.8.14.9

So, source IP = 10.8.14.9 : destination IP = 1.1.11

> in subnet 10.8.14.9/24 with default gateway 10.8.14.1. 
> It's routed through my core switch to my my firewall with ip 10.8.1.1.

So that's a router, not just a switch?  It has one interface 10.8.14.1 on subnet 10.8.14.0/24 and another interface on (presumably) 10.8.1.0/24 pointing at 10.8.1.1 as the next-hop route towards 1.1.1.1

> My firewall recognises that the packet has a destination port 80 and 
> is in subnet 10.8.14.0/24

The source address is in that subnet, yes.

> and changes the destination address to be that of my proxy server 10.8.2.11.

No - see below.

> So now the ack packet has source 10.8.14.9 and destination 10.8.2.11.

No, it doesn't.  When a packet goes via a router, its destination IP address is not changed to the address of the next-hop router (otherwise things would never work across the Internet).

It's only the destination MAC address in the encapsulating ethernet frame which gets changed to that of the next-hop router.  The source and destination IP addresses inside are not touched.

> How does iptables know to reply to my client 10.8.14.9 with source 
> address 1.1.1.1?  Does iptables know to read the header?

TCP header, yes.

HTTP header, no.

Just think about the very first link between the client and its default
gateway:

Packet with source address = 10.8.14.9, destinatoin address = 1.1.1.1

How does that packet get to the default router 10.8.14.1?  Its destination IP is 1.1.1.1, so that doesn't help.

It's because the destination MAC address in the ethernet frame containing that IP packet is the MAC address of 10.8.14.1.

A few minutes playing around with wireshark on your network could be quite enlightening :)



Regards,


Antony.

-- 
I think broken pencils are pointless.

                                                   Please reply to the list;
                                                         please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From Antony.Stone at squid.open.source.it  Thu Sep  8 09:00:30 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 8 Sep 2016 11:00:30 +0200
Subject: [squid-users] Transparent Proxy
In-Reply-To: <c1871bc8b9fe4e51b02fba9f36e274e6@IT-S-MAIL1.asd.local>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <201609081036.07978.Antony.Stone@squid.open.source.it>
 <c1871bc8b9fe4e51b02fba9f36e274e6@IT-S-MAIL1.asd.local>
Message-ID: <201609081100.31096.Antony.Stone@squid.open.source.it>

On Thursday 08 September 2016 at 10:44:12, John Sayce wrote:

> After I wrote this I realised it should be changing the mac not the ip,
> which is not what?s happeneing.  I think it's my firewall configuration
> that's wrong.

In that case your firewall is doing NAT instead of policy routing.

Regards,


Antony.

> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Antony Stone Sent: 08 September 2016 09:36
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Transparent Proxy
> 
> On Thursday 08 September 2016 at 10:12:48, John Sayce wrote:
> > For testing purposes I've reduced it to the following:
> > 
> > http_port 3128 intercept
> > #dns_v4_first on
> > dns_nameservers 10.8.2.3 194.168.4.100 10.8.2.2 8.8.8.8 acl wifi src
> > 10.8.14.0/24 acl all src all http_access allow all maximum_object_size
> > 1 GB minimum_object_size 0 KB maximum_object_size_in_memory 4 MB
> > cache_mem 1700 MB cache_dir aufs /var/cache/squid 40000 32 512
> > coredump_dir /var/cache/squid access_log /var/log/squid/access.log
> > squid cache_log /var/log/squid/cache.log
> > refresh_pattern ^ftp:           1440    20%     10080
> > refresh_pattern ^gopher:        1440    0%      1440
> > refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> > refresh_pattern .               0       20%     4320
> > cache_effective_user asd
> > cache_effective_group asd
> > cache_mgr jsayce at asdlighting.com
> > forwarded_for off
> > 
> > The version is 3.5.12
> > 
> > Okay.  Sorry, to clarify with a specific example.
> 
> Don't apologise - specific examples are good, because it makes sure we're
> both talking about the same thing (and sometimes, as below, reveals little
> details about the network arrangement which weren't previously clear).
> 
> > Lets say I'm contacting http://1.1.1.1/ then the ack packet starts off
> > with the client with ip address 10.8.14.9
> 
> So, source IP = 10.8.14.9 : destination IP = 1.1.11
> 
> > in subnet 10.8.14.9/24 with default gateway 10.8.14.1.
> > It's routed through my core switch to my my firewall with ip 10.8.1.1.
> 
> So that's a router, not just a switch?  It has one interface 10.8.14.1 on
> subnet 10.8.14.0/24 and another interface on (presumably) 10.8.1.0/24
> pointing at 10.8.1.1 as the next-hop route towards 1.1.1.1
> 
> > My firewall recognises that the packet has a destination port 80 and
> > is in subnet 10.8.14.0/24
> 
> The source address is in that subnet, yes.
> 
> > and changes the destination address to be that of my proxy server
> > 10.8.2.11.
> 
> No - see below.
> 
> > So now the ack packet has source 10.8.14.9 and destination 10.8.2.11.
> 
> No, it doesn't.  When a packet goes via a router, its destination IP
> address is not changed to the address of the next-hop router (otherwise
> things would never work across the Internet).
> 
> It's only the destination MAC address in the encapsulating ethernet frame
> which gets changed to that of the next-hop router.  The source and
> destination IP addresses inside are not touched.
> 
> > How does iptables know to reply to my client 10.8.14.9 with source
> > address 1.1.1.1?  Does iptables know to read the header?
> 
> TCP header, yes.
> 
> HTTP header, no.
> 
> Just think about the very first link between the client and its default
> gateway:
> 
> Packet with source address = 10.8.14.9, destinatoin address = 1.1.1.1
> 
> How does that packet get to the default router 10.8.14.1?  Its destination
> IP is 1.1.1.1, so that doesn't help.
> 
> It's because the destination MAC address in the ethernet frame containing
> that IP packet is the MAC address of 10.8.14.1.
> 
> A few minutes playing around with wireshark on your network could be quite
> enlightening :)
> 
> 
> 
> Regards,
> 
> 
> Antony.

-- 
"Reports that say that something hasn't happened are always interesting to me, 
because as we know, there are known knowns; there are things we know we know. 
We also know there are known unknowns; that is to say we know there are some 
things we do not know. But there are also unknown unknowns - the ones we don't 
know we don't know."

 - Donald Rumsfeld, US Secretary of Defence

                                                   Please reply to the list;
                                                         please *don't* CC me.


From omidkosari at yahoo.com  Thu Sep  8 10:27:42 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Thu, 8 Sep 2016 03:27:42 -0700 (PDT)
Subject: [squid-users] TProxy and client_dst_passthru
In-Reply-To: <1435996974697-4672054.post@n4.nabble.com>
References: <1435835131864-4672020.post@n4.nabble.com>
 <559528CD.5020600@treenet.co.nz> <1435840988272-4672022.post@n4.nabble.com>
 <1435925126078-4672041.post@n4.nabble.com> <5596872A.7050508@treenet.co.nz>
 <1435929702099-4672044.post@n4.nabble.com> <5596A975.2060903@treenet.co.nz>
 <1435936908218-4672048.post@n4.nabble.com> <5596BA9A.9070401@treenet.co.nz>
 <1435996974697-4672054.post@n4.nabble.com>
Message-ID: <1473330462286-4679422.post@n4.nabble.com>

Hi Fred,

Same problem here . Do you found any solution or workaround ?

Regards



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TProxy-and-client-dst-passthru-tp4670189p4679422.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Thu Sep  8 11:15:20 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 8 Sep 2016 13:15:20 +0200
Subject: [squid-users] TProxy and client_dst_passthru
In-Reply-To: <1473330462286-4679422.post@n4.nabble.com>
References: <1435835131864-4672020.post@n4.nabble.com>
 <1435996974697-4672054.post@n4.nabble.com>
 <1473330462286-4679422.post@n4.nabble.com>
Message-ID: <201609081315.20967.Antony.Stone@squid.open.source.it>

On Thursday 08 September 2016 at 12:27:42, Omid Kosari wrote:

> Hi Fred,
> 
> Same problem here . Do you found any solution or workaround ?

Please clarify which message you are reply / referring to.

Thanks,


Antony.

-- 
Archaeologists have found a previously-unknown dinosaur which seems to have 
had a very large vocabulary.  They've named it Thesaurus.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From jsayce at asdlighting.com  Thu Sep  8 11:54:14 2016
From: jsayce at asdlighting.com (John Sayce)
Date: Thu, 8 Sep 2016 11:54:14 +0000
Subject: [squid-users] Transparent Proxy
In-Reply-To: <201609081100.31096.Antony.Stone@squid.open.source.it>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <201609081036.07978.Antony.Stone@squid.open.source.it>
 <c1871bc8b9fe4e51b02fba9f36e274e6@IT-S-MAIL1.asd.local>
 <201609081100.31096.Antony.Stone@squid.open.source.it>
Message-ID: <8d9db604c8eb4c318517a382c0d3e27a@IT-S-MAIL1.asd.local>

Yeah, that was the key.  I was expecting my firewall to be doing NAT but destination NAT rather than source NAT.  I hadn't realised this was completely wrong.  

Got it working now.

Thanks


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Antony Stone
Sent: 08 September 2016 10:00
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Transparent Proxy

On Thursday 08 September 2016 at 10:44:12, John Sayce wrote:

> After I wrote this I realised it should be changing the mac not the 
> ip, which is not what?s happeneing.  I think it's my firewall 
> configuration that's wrong.

In that case your firewall is doing NAT instead of policy routing.

Regards,


Antony.

> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
> On Behalf Of Antony Stone Sent: 08 September 2016 09:36
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Transparent Proxy
> 
> On Thursday 08 September 2016 at 10:12:48, John Sayce wrote:
> > For testing purposes I've reduced it to the following:
> > 
> > http_port 3128 intercept
> > #dns_v4_first on
> > dns_nameservers 10.8.2.3 194.168.4.100 10.8.2.2 8.8.8.8 acl wifi src
> > 10.8.14.0/24 acl all src all http_access allow all 
> > maximum_object_size
> > 1 GB minimum_object_size 0 KB maximum_object_size_in_memory 4 MB 
> > cache_mem 1700 MB cache_dir aufs /var/cache/squid 40000 32 512 
> > coredump_dir /var/cache/squid access_log /var/log/squid/access.log 
> > squid cache_log /var/log/squid/cache.log
> > refresh_pattern ^ftp:           1440    20%     10080
> > refresh_pattern ^gopher:        1440    0%      1440
> > refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> > refresh_pattern .               0       20%     4320
> > cache_effective_user asd
> > cache_effective_group asd
> > cache_mgr jsayce at asdlighting.com
> > forwarded_for off
> > 
> > The version is 3.5.12
> > 
> > Okay.  Sorry, to clarify with a specific example.
> 
> Don't apologise - specific examples are good, because it makes sure 
> we're both talking about the same thing (and sometimes, as below, 
> reveals little details about the network arrangement which weren't previously clear).
> 
> > Lets say I'm contacting http://1.1.1.1/ then the ack packet starts 
> > off with the client with ip address 10.8.14.9
> 
> So, source IP = 10.8.14.9 : destination IP = 1.1.11
> 
> > in subnet 10.8.14.9/24 with default gateway 10.8.14.1.
> > It's routed through my core switch to my my firewall with ip 10.8.1.1.
> 
> So that's a router, not just a switch?  It has one interface 10.8.14.1 
> on subnet 10.8.14.0/24 and another interface on (presumably) 
> 10.8.1.0/24 pointing at 10.8.1.1 as the next-hop route towards 1.1.1.1
> 
> > My firewall recognises that the packet has a destination port 80 and 
> > is in subnet 10.8.14.0/24
> 
> The source address is in that subnet, yes.
> 
> > and changes the destination address to be that of my proxy server 
> > 10.8.2.11.
> 
> No - see below.
> 
> > So now the ack packet has source 10.8.14.9 and destination 10.8.2.11.
> 
> No, it doesn't.  When a packet goes via a router, its destination IP 
> address is not changed to the address of the next-hop router 
> (otherwise things would never work across the Internet).
> 
> It's only the destination MAC address in the encapsulating ethernet 
> frame which gets changed to that of the next-hop router.  The source 
> and destination IP addresses inside are not touched.
> 
> > How does iptables know to reply to my client 10.8.14.9 with source 
> > address 1.1.1.1?  Does iptables know to read the header?
> 
> TCP header, yes.
> 
> HTTP header, no.
> 
> Just think about the very first link between the client and its 
> default
> gateway:
> 
> Packet with source address = 10.8.14.9, destinatoin address = 1.1.1.1
> 
> How does that packet get to the default router 10.8.14.1?  Its 
> destination IP is 1.1.1.1, so that doesn't help.
> 
> It's because the destination MAC address in the ethernet frame 
> containing that IP packet is the MAC address of 10.8.14.1.
> 
> A few minutes playing around with wireshark on your network could be 
> quite enlightening :)
> 
> 
> 
> Regards,
> 
> 
> Antony.

--
"Reports that say that something hasn't happened are always interesting to me, because as we know, there are known knowns; there are things we know we know. 
We also know there are known unknowns; that is to say we know there are some things we do not know. But there are also unknown unknowns - the ones we don't know we don't know."

 - Donald Rumsfeld, US Secretary of Defence

                                                   Please reply to the list;
                                                         please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From squid3 at treenet.co.nz  Thu Sep  8 11:59:29 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 8 Sep 2016 23:59:29 +1200
Subject: [squid-users] Transparent Proxy
In-Reply-To: <8d9db604c8eb4c318517a382c0d3e27a@IT-S-MAIL1.asd.local>
References: <fd37526a-d77a-66e5-93f0-29f2c62fec34@opendium.com>
 <201609081036.07978.Antony.Stone@squid.open.source.it>
 <c1871bc8b9fe4e51b02fba9f36e274e6@IT-S-MAIL1.asd.local>
 <201609081100.31096.Antony.Stone@squid.open.source.it>
 <8d9db604c8eb4c318517a382c0d3e27a@IT-S-MAIL1.asd.local>
Message-ID: <d964ae50-f85e-8d83-95f5-3bc0d7a78833@treenet.co.nz>

On 8/09/2016 11:54 p.m., John Sayce wrote:
> Yeah, that was the key.  I was expecting my firewall to be doing NAT but destination NAT rather than source NAT.  I hadn't realised this was completely wrong.  
> 
> Got it working now.

Source-NAT is fine and sometimes needed to translate between subnets.
But Destination-NAT before the TCP packets reach the Squid machine kills
the MITM being done by proxy machine.

Amos



From erdosain9 at gmail.com  Thu Sep  8 12:38:04 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 8 Sep 2016 05:38:04 -0700 (PDT)
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
Message-ID: <1473338284062-4679426.post@n4.nabble.com>

Finally i update to squid 3.5 and try the acl with dstdomain


Craddock, Tommy wrote
> Hello, 
> Create an ACL that will be a list of domains, either in the ACL or in a
> txt file that the ACL refers to, and place any URLs you want bypassed by
> the proxy into the ACL.  Something like this:
> ACL Section of your squid.conf:
> acl bypass_dst_dom  dstdomain "/etc/squid/bypass_dst_domain.txt"
> Then in the http_access section:
> http_access allow bypass_dst_dom

But dosent work....  the web keep loading
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4679426/Captura_de_pantalla_de_2016-09-08_09-40-14.png> 




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679426.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Thu Sep  8 14:28:20 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 8 Sep 2016 20:28:20 +0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1473338284062-4679426.post@n4.nabble.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
Message-ID: <c51c23c1-a4f9-2edd-fa93-336b5f075b6b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Show access.log, not screenshot.


08.09.2016 18:38, erdosain9 ?????:
> Finally i update to squid 3.5 and try the acl with dstdomain
>
>
> Craddock, Tommy wrote
>> Hello,
>> Create an ACL that will be a list of domains, either in the ACL or in a
>> txt file that the ACL refers to, and place any URLs you want bypassed by
>> the proxy into the ACL.  Something like this:
>> ACL Section of your squid.conf:
>> acl bypass_dst_dom  dstdomain "/etc/squid/bypass_dst_domain.txt"
>> Then in the http_access section:
>> http_access allow bypass_dst_dom
>
> But dosent work....  the web keep loading
>
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4679426/Captura_de_pantalla_de_2016-09-08_09-40-14.png>

>
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679426.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX0XWEAAoJENNXIZxhPexG81sH/1AH9gE9bNLF3szIA1J26tUt
v+BCEZawxIWG7lcAhYnXZ6Ylk4U9afJhvWn2KRdFZvuPUMvJRMfPDn2jDKF3Djto
iEBjXthbzcEW0zNLFyfjw0l41mwb+Vpw/l0cLm06+wB+eqmJJ1DAAbuhNceraC4i
lYEAw0Cs6W+iI9QkD503EyHh5yE3R50B5L+n7PthM41hI/6KhH4xVqVApvGHpd9d
myQnSRl8IlQAuqtXQQnT+1THmtuDQcr83Fpu/ziV/g4JBpAEy1+T1m9o9WV+KP2u
8YS9R2M1fGGuNSS0ioLd/6QVvbp846565He3Ih6DCEh25C13VTMdjAO+LBL+j74=
=9594
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160908/de602ace/attachment.key>

From erdosain9 at gmail.com  Thu Sep  8 16:35:12 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 8 Sep 2016 09:35:12 -0700 (PDT)
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <c51c23c1-a4f9-2edd-fa93-336b5f075b6b@gmail.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <c51c23c1-a4f9-2edd-fa93-336b5f075b6b@gmail.com>
Message-ID: <1473352512538-4679428.post@n4.nabble.com>

Ok.
Access.log

1473352640.832    514 192.168.1.172 TCP_MISS/200 527 GET
https://web.whatsapp.com/status.json - HIER_DIRECT/31.13.85.51 text/json
1473352642.737    290 192.168.1.172 TCP_MISS/404 464 GET
https://web.whatsapp.com/404.appcache - HIER_DIRECT/31.13.85.51 text/html
1473352643.237    143 192.168.1.172 TAG_NONE/200 0 CONNECT
fonts.gstatic.com:443 - HIER_DIRECT/64.233.190.94 -
1473352644.668    288 192.168.1.172 TCP_MISS/304 535 GET
https://web.whatsapp.com/serviceworker.js - HIER_DIRECT/31.13.85.51
application/javascript
1473352649.604    296 192.168.1.172 TCP_MISS/200 527 GET
https://web.whatsapp.com/status.json - HIER_DIRECT/31.13.85.51 text/json
1473352654.317    291 192.168.1.172 TCP_MISS/200 527 GET
https://web.whatsapp.com/status.json - HIER_DIRECT/31.13.85.51 text/json




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679428.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Tommy.Craddock at bicgraphic.com  Thu Sep  8 18:09:32 2016
From: Tommy.Craddock at bicgraphic.com (Craddock, Tommy)
Date: Thu, 8 Sep 2016 18:09:32 +0000
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1473352512538-4679428.post@n4.nabble.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <c51c23c1-a4f9-2edd-fa93-336b5f075b6b@gmail.com>
 <1473352512538-4679428.post@n4.nabble.com>
Message-ID: <CA86A9283AA07E478F6B0629521FFEE73E486B@CLWSEXCMBX02.na.bicworld.com>

Hello, 

Show your squid.conf to see how you setup the http_access section.   

?
Tommy E CRADDOCK JR

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Thursday, September 08, 2016 12:35 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Web Whatsapp, Dropbox... problem

Ok.
Access.log

1473352640.832    514 192.168.1.172 TCP_MISS/200 527 GET
https://web.whatsapp.com/status.json - HIER_DIRECT/31.13.85.51 text/json
1473352642.737    290 192.168.1.172 TCP_MISS/404 464 GET
https://web.whatsapp.com/404.appcache - HIER_DIRECT/31.13.85.51 text/html
1473352643.237    143 192.168.1.172 TAG_NONE/200 0 CONNECT
fonts.gstatic.com:443 - HIER_DIRECT/64.233.190.94 -
1473352644.668    288 192.168.1.172 TCP_MISS/304 535 GET
https://web.whatsapp.com/serviceworker.js - HIER_DIRECT/31.13.85.51 application/javascript
1473352649.604    296 192.168.1.172 TCP_MISS/200 527 GET
https://web.whatsapp.com/status.json - HIER_DIRECT/31.13.85.51 text/json
1473352654.317    291 192.168.1.172 TCP_MISS/200 527 GET
https://web.whatsapp.com/status.json - HIER_DIRECT/31.13.85.51 text/json




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679428.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________

From erdosain9 at gmail.com  Thu Sep  8 19:05:01 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 8 Sep 2016 12:05:01 -0700 (PDT)
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <CA86A9283AA07E478F6B0629521FFEE73E486B@CLWSEXCMBX02.na.bicworld.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <c51c23c1-a4f9-2edd-fa93-336b5f075b6b@gmail.com>
 <1473352512538-4679428.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E486B@CLWSEXCMBX02.na.bicworld.com>
Message-ID: <1473361501592-4679430.post@n4.nabble.com>

Thanks.
There you have 

# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
#acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
#acl localnet src 172.16.0.0/12	# RFC1918 possible internal network
#acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
#IPV6 Deshabilitado
#acl localnet src fc00::/7       # RFC 4193 local private network range
#acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines
#acl lan1_network src 192.168.1.0/24 ###Red 1 completa (no esta allowed)
#acl adminsquid src 192.168.1.172 #Administrar squid

#allways_direct allow lan1_network

####GRUPOS DE IP
acl full src "/etc/squid/ips/full.lst"
acl limitado src "/etc/squid/ips/limitado.lst"
acl sistemas src "/etc/squid/ips/sistemas.lst"
acl adminis  src "/etc/squid/ips/adminis.lst"

####Bloquea Publicidad ( http://pgl.yoyo.org/adservers/ )
acl ads dstdom_regex "/etc/squid/listas/ad_block.lst"
http_access deny ads
#deny_info TCP_RESET ads

####Streaming
#acl youtube dstdomain .googlevideo.com
#acl youtube dstdomain .fbcdn.net
#acl youtube dstdomain .akamaihd.net
acl stream url_regex -i \.flv$
acl stream url_regex -i \.mp4$
acl stream url_regex -i watch?
acl stream url_regex -i youtube
acl stream url_regex -i facebook
acl stream url_regex -i fbcdn\.net\/v\/(.*\.mp4)\?
acl stream url_regex -i fbcdn\.net\/v\/(.*\.jpg)\? 
acl stream url_regex -i akamaihd\.net\/v\/(.*\.mp4)\?
acl stream url_regex -i akamaihd\.net\/v\/(.*\.jpg)\?

##Dominios denegados
acl dominios_denegados dstdomain "/etc/squid/listas/dominios_denegados.lst"

##Extensiones bloqueadas
acl multimedia urlpath_regex "/etc/squid/listas/multimedia.lst"

##Extensiones peligrosas
acl peligrosos urlpath_regex "/etc/squid/listas/peligrosos.lst"

#Bypass squid
acl bypass_dst_dom  dstdomain "/etc/squid/listas/bypass_dst_domain.lst"

##Redes sociales
acl redes_sociales url_regex -i ?/etc/squid/listas/redes_sociales.lst?


#Puertos
acl SSL_ports port 443
acl SSL_ports port 8443

acl Safe_ports port 631		# httpCUPS
acl Safe_ports port 80		# http
acl Safe_ports port 21		# ftp
acl Safe_ports port 443		# https
acl Safe_ports port 70		# gopher
acl Safe_ports port 210		# wais
acl Safe_ports port 8443        # httpsalt
acl Safe_ports port 1025-65535	# unregistered ports
acl Safe_ports port 280		# http-mgmt
acl Safe_ports port 488		# gss-http
acl Safe_ports port 591		# filemaker
acl Safe_ports port 777		# multiling http
acl CONNECT method CONNECT


#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
#http_access allow adminsquid manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
http_access allow localhost
#http_access allow bypass_dst_dom
http_access allow limitado !dominios_denegados !multimedia !peligrosos
http_access allow full !peligrosos
http_access allow adminis !multimedia
http_access allow sistemas

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.1.9:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem
key=/etc/squid/ssl_cert/myca.pem 

acl excluidosSSL dstdomain "/etc/squid/listas/excluidosSSL.lst"
ssl_bump none excluidosSSL

# SSL Bump Config
ssl_bump stare all  
ssl_bump bump all 

#
sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
sslcrtd_children 8 startup=1 idle=1


# Uncomment and adjust the following to add a disk cache directory.
cache_dir aufs /var/spool/squid 1000 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320

dns_nameservers 192.168.1.14 192.168.1.5 192.168.1.7
visible_hostname squid


#obliga el cache de imagenes .jgp

refresh_pattern -i \.jpg$ 30 0% 30 ignore-no-cache ignore-no-store
ignore-private

######POOL DE VELOCIDAD
#delay_pools 2
#delay_class 1 1
#delay_class 2 1
#delay_access 1 allow full
#delay_access 1 deny all
#delay_access 2 allow sistemas
#delay_access 2 deny all
#delay_parameters 1 64000/64000
#delay_parameters 2 32000/32000

###VELOCIDAD PARA REDES SOCIALES
#delay_class 1 1
#delay_parameters 1 15000/2000
#acl redes_sociales url_regex -i ?/etc/squid/listas/redes_sociales?
#delay_access 1 allow limitado redes_sociales


###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
#via off
#forwarded_for delete
###

#Pools para ancho de Banda
delay_pools 6

###VELOCIDAD PARA REDES SOCIALES
delay_class 1 1
delay_parameters 1 10000/100000
delay_access 1 allow redes_sociales limitado
delay_access 1 allow redes_sociales full
delay_access 1 allow redes_sociales adminis
delay_access 1 deny all


#Limitar Video Streaming a 20k
delay_class 2 1
delay_parameters 2 10000/100000
delay_access 2 allow stream adminis
delay_access 2 allow stream full
delay_access 2 allow stream limitado
delay_access 2 deny all

#Limitar Video Streaming a 500k
delay_class 3 1
delay_parameters 3 500000/500000
delay_access 3 allow stream sistemas
delay_access 3 deny all

#Ancho de Banda Administracion
delay_class 4 1
delay_parameters 4 256000/256000
delay_access 4 allow adminis
delay_access 4 deny all


#Ancho de Banda Sistemas
delay_class 5 2
delay_parameters 5 512000/512000 64000/256000
delay_access 5 allow sistemas
delay_access 5 deny all

#Ancho de Banda Logistica
delay_class 6 2
delay_parameters 6 256000/256000 30000/125000
delay_access 6 allow limitado
delay_access 6 deny all

###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
#via off
#forwarded_for delete
###


by the way if someone wanna tell me about this config other things (errors,
stupid syntax, or whatever.... thanks! )



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679430.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Thu Sep  8 19:08:14 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 8 Sep 2016 22:08:14 +0300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1473338284062-4679426.post@n4.nabble.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
Message-ID: <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>

Hey,

Can I reproduce this by just entering the url in chrome\chromium\firefox\Internet Exploere\Edge\other?
I am testing Squid 4 but it's moving slow compared to what I could in the past.
I have a squid 4 up and running and I will try to see if I can reproduce it.
Can you provide more details about the squid.conf?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Thursday, September 8, 2016 3:38 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Web Whatsapp, Dropbox... problem

Finally i update to squid 3.5 and try the acl with dstdomain


Craddock, Tommy wrote
> Hello,
> Create an ACL that will be a list of domains, either in the ACL or in 
> a txt file that the ACL refers to, and place any URLs you want 
> bypassed by the proxy into the ACL.  Something like this:
> ACL Section of your squid.conf:
> acl bypass_dst_dom  dstdomain "/etc/squid/bypass_dst_domain.txt"
> Then in the http_access section:
> http_access allow bypass_dst_dom

But dosent work....  the web keep loading <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4679426/Captura_de_pantalla_de_2016-09-08_09-40-14.png> 




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679426.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From chicocvenancio at gmail.com  Thu Sep  8 20:04:55 2016
From: chicocvenancio at gmail.com (Chico Venancio)
Date: Thu, 8 Sep 2016 17:04:55 -0300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
Message-ID: <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>

We had that trouble with whatsapp web. We simply put it in the splice rule.
It seems whatsapp checks the client certificate.

Chico Venancio

Em 08/09/2016 16:09, "Eliezer Croitoru" <eliezer at ngtech.co.il> escreveu:

> Hey,
>
> Can I reproduce this by just entering the url in chrome\chromium\firefox\Internet
> Exploere\Edge\other?
> I am testing Squid 4 but it's moving slow compared to what I could in the
> past.
> I have a squid 4 up and running and I will try to see if I can reproduce
> it.
> Can you provide more details about the squid.conf?
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of erdosain9
> Sent: Thursday, September 8, 2016 3:38 PM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Web Whatsapp, Dropbox... problem
>
> Finally i update to squid 3.5 and try the acl with dstdomain
>
>
> Craddock, Tommy wrote
> > Hello,
> > Create an ACL that will be a list of domains, either in the ACL or in
> > a txt file that the ACL refers to, and place any URLs you want
> > bypassed by the proxy into the ACL.  Something like this:
> > ACL Section of your squid.conf:
> > acl bypass_dst_dom  dstdomain "/etc/squid/bypass_dst_domain.txt"
> > Then in the http_access section:
> > http_access allow bypass_dst_dom
>
> But dosent work....  the web keep loading <http://squid-web-proxy-cache.
> 1019090.n4.nabble.com/file/n4679426/Captura_de_pantalla_
> de_2016-09-08_09-40-14.png>
>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.
> 1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679426.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160908/82d31e35/attachment.htm>

From yvoinov at gmail.com  Thu Sep  8 20:10:39 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 9 Sep 2016 02:10:39 +0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
Message-ID: <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Absolutely right. It is requires to put Whatsapp web to splice rule to
make it work.


09.09.2016 2:04, Chico Venancio ?????:
>
> We had that trouble with whatsapp web. We simply put it in the splice
rule. It seems whatsapp checks the client certificate.
>
> Chico Venancio
>
>
> Em 08/09/2016 16:09, "Eliezer Croitoru" <eliezer at ngtech.co.il
<mailto:eliezer at ngtech.co.il>> escreveu:
>
>     Hey,
>
>     Can I reproduce this by just entering the url in
chrome\chromium\firefox\Internet Exploere\Edge\other?
>     I am testing Squid 4 but it's moving slow compared to what I could
in the past.
>     I have a squid 4 up and running and I will try to see if I can
reproduce it.
>     Can you provide more details about the squid.conf?
>
>     Eliezer
>
>     ----
>     Eliezer Croitoru
>     Linux System Administrator
>     Mobile: +972-5-28704261 <tel:%2B972-5-28704261>
>     Email: eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>
>
>
>     -----Original Message-----
>     From: squid-users
[mailto:squid-users-bounces at lists.squid-cache.org
<mailto:squid-users-bounces at lists.squid-cache.org>] On Behalf Of erdosain9
>     Sent: Thursday, September 8, 2016 3:38 PM
>     To: squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     Subject: Re: [squid-users] Web Whatsapp, Dropbox... problem
>
>     Finally i update to squid 3.5 and try the acl with dstdomain
>
>
>     Craddock, Tommy wrote
>     > Hello,
>     > Create an ACL that will be a list of domains, either in the ACL
or in
>     > a txt file that the ACL refers to, and place any URLs you want
>     > bypassed by the proxy into the ACL.  Something like this:
>     > ACL Section of your squid.conf:
>     > acl bypass_dst_dom  dstdomain "/etc/squid/bypass_dst_domain.txt"
>     > Then in the http_access section:
>     > http_access allow bypass_dst_dom
>
>     But dosent work....  the web keep loading
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4679426/Captura_de_pantalla_de_2016-09-08_09-40-14.png
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4679426/Captura_de_pantalla_de_2016-09-08_09-40-14.png>>
>
>
>
>
>     --
>     View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679426.html
<http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679426.html>
>     Sent from the Squid - Users mailing list archive at Nabble.com.
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
<http://lists.squid-cache.org/listinfo/squid-users>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
<http://lists.squid-cache.org/listinfo/squid-users>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX0cW+AAoJENNXIZxhPexGotYIAKgrCVW/KdWiljFC+Um7QJrr
SUMYmbky6eMzKDnFGpWG7hSExIlb2g3GXeMZCUT5uhLuNdTSbQal++bTRcua/I19
qNd8aAvWre+b3c2iVbBQAhcYNUqoBhj3FLhm6MzCwxzB/+256b+MLA7lxWP9yvB1
bPGq1G7arx1kbGo/3XMXZ5KtjgLCDj2w3Mt+dZLtlaN6CFNqZ7yE3x5ZebhOIbXQ
4N/ppGkk/8iAyAYnbhUHUeDwP241xvkdTPKOmpD3cay5BuDKcn6tHYnhZQQw4c2B
QETiV4qKOsTeHRAaLWPQ2aUuEfGuUAB/QuM7VmVfrXyVhYsa877KngLqPFvfcKw=
=NUFs
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160909/62a139c8/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160909/62a139c8/attachment.key>

From eliezer at ngtech.co.il  Thu Sep  8 20:19:13 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 8 Sep 2016 23:19:13 +0300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
Message-ID: <005d01d20a0e$43dea3d0$cb9beb70$@ngtech.co.il>

Can it be verified using some kind of dumps?

The issues is that if I will try to access https://web.whatsapp.com/ it will probably won't work despite to the fact that I have or do not have a certificate.

>From my eyes it's not a certificate issue but rather a websocket one.

The simplest way to see it would be using this firefox dump:

curl "https://w1.web.whatsapp.com/ws" -H "Host: w1.web.whatsapp.com" -H "User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64; rv:48.0) Gecko/20100101 Firefox/48.0" -H "Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8" -H "Accept-Language: en-US,he;q=0.7,en;q=0.3" --compressed -H "Sec-WebSocket-Version: 13" -H "Origin: https://web.whatsapp.com" -H "Sec-WebSocket-Extensions: permessage-deflate" -H "Sec-WebSocket-Key: 323TCNi3BxG0LJ+nTi2V1g==" -H "Connection: keep-alive, Upgrade" -H "Pragma: no-cache" -H "Cache-Control: no-cache" -H "Upgrade: websocket"

 

I believe that we can somehow make sure how it will be secure "enough" to mangle the response headers and change any Connection into a "close" one and then splice the client and the server.

It's not safe for many systems but when the sysadmins are using whatsapp to send internal messages it would be ridicules to restrict the network users for these apps.

But in the other hand maybe the sysadmins are smart and the other users are not enough so I am not sure what would be the best option.

For this case a configuration would be appropriate.

 

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: Chico Venancio [mailto:chicocvenancio at gmail.com] 
Sent: Thursday, September 8, 2016 11:05 PM
To: Eliezer Croitoru
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Web Whatsapp, Dropbox... problem

 

We had that trouble with whatsapp web. We simply put it in the splice rule. It seems whatsapp checks the client certificate. 

Chico Venancio 

 

Em 08/09/2016 16:09, "Eliezer Croitoru" <eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il> > escreveu:

Hey,

Can I reproduce this by just entering the url in chrome\chromium\firefox\Internet Exploere\Edge\other?
I am testing Squid 4 but it's moving slow compared to what I could in the past.
I have a squid 4 up and running and I will try to see if I can reproduce it.
Can you provide more details about the squid.conf?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261 <tel:%2B972-5-28704261> 
Email: eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il> 


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org <mailto:squid-users-bounces at lists.squid-cache.org> ] On Behalf Of erdosain9
Sent: Thursday, September 8, 2016 3:38 PM
To: squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
Subject: Re: [squid-users] Web Whatsapp, Dropbox... problem

Finally i update to squid 3.5 and try the acl with dstdomain


Craddock, Tommy wrote
> Hello,
> Create an ACL that will be a list of domains, either in the ACL or in
> a txt file that the ACL refers to, and place any URLs you want
> bypassed by the proxy into the ACL.  Something like this:
> ACL Section of your squid.conf:
> acl bypass_dst_dom  dstdomain "/etc/squid/bypass_dst_domain.txt"
> Then in the http_access section:
> http_access allow bypass_dst_dom

But dosent work....  the web keep loading <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4679426/Captura_de_pantalla_de_2016-09-08_09-40-14.png>




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679426.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160908/8d05c243/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160908/8d05c243/attachment.png>

From erdosain9 at gmail.com  Fri Sep  9 13:55:29 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Fri, 9 Sep 2016 06:55:29 -0700 (PDT)
Subject: [squid-users] squid TCP_DENIED/403
Message-ID: <1473429329556-4679435.post@n4.nabble.com>

Hi, 
If i go to http://affiliates.digitalriver.com/z/36067/CD109988 squid tell me
ACCESS DENIED. I look the access.log and yes... is 

1473428538.203      0 192.168.1.17 TCP_DENIED/403 4032 GET
http://affiliates.digitalriver.com/z/36067/CD109988 - HIER_NONE/- text/html

But, i dont have any denied rule. As far as i know this is the only web that
give me this problem...  (probably not )
What can be? What can do?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/squid-TCP-DENIED-403-tp4679435.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From mzgmedia at gmail.com  Fri Sep  9 13:58:57 2016
From: mzgmedia at gmail.com (mzgmedia)
Date: Fri, 9 Sep 2016 06:58:57 -0700 (PDT)
Subject: [squid-users] compliled squid size
In-Reply-To: <20160907161749.GA18997@fantomas.sk>
References: <1473264161043-4679405.post@n4.nabble.com>
 <20160907161749.GA18997@fantomas.sk>
Message-ID: <1473429537536-4679436.post@n4.nabble.com>

I think that the 
the param is -g and is there already there on the CFLAGS and CXXFLAGS



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/compliled-squid-size-tp4679405p4679436.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From belle at bazuin.nl  Fri Sep  9 14:04:07 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Fri, 9 Sep 2016 16:04:07 +0200
Subject: [squid-users] squid TCP_DENIED/403
In-Reply-To: <1473429329556-4679435.post@n4.nabble.com>
References: <1473429329556-4679435.post@n4.nabble.com>
Message-ID: <vmime.57d2c157.37a2.4470ff61568e3947@ms249-lin-003.rotterdam.bazuin.nl>

Its in here :

( from your squid.conf )
"/etc/squid/listas/ad_block.lst"
http_access deny ads
#deny_info TCP_RESET ads 


affiliates.digitalriver.com
it is in the ads list. 


Greetz, 

Louis

> -----Oorspronkelijk bericht-----
> Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens
> erdosain9
> Verzonden: vrijdag 9 september 2016 15:55
> Aan: squid-users at lists.squid-cache.org
> Onderwerp: [squid-users] squid TCP_DENIED/403
> 
> Hi,
> If i go to http://affiliates.digitalriver.com/z/36067/CD109988 squid tell
> me
> ACCESS DENIED. I look the access.log and yes... is
> 
> 1473428538.203      0 192.168.1.17 TCP_DENIED/403 4032 GET
> http://affiliates.digitalriver.com/z/36067/CD109988 - HIER_NONE/-
> text/html
> 
> But, i dont have any denied rule. As far as i know this is the only web
> that
> give me this problem...  (probably not )
> What can be? What can do?
> 
> 
> 
> --
> View this message in context: http://squid-web-proxy-
> cache.1019090.n4.nabble.com/squid-TCP-DENIED-403-tp4679435.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Fri Sep  9 14:04:47 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 9 Sep 2016 20:04:47 +0600
Subject: [squid-users] squid TCP_DENIED/403
In-Reply-To: <1473429329556-4679435.post@n4.nabble.com>
References: <1473429329556-4679435.post@n4.nabble.com>
Message-ID: <b8925a7e-73c5-b19d-7312-5519173c4d9c@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
My Squid tells me this is adware URL. And my setup blocks this URL with
TCP_DENIED/403.


09.09.2016 19:55, erdosain9 ?????:
> Hi, 
> If i go to http://affiliates.digitalriver.com/z/36067/CD109988 squid
tell me
> ACCESS DENIED. I look the access.log and yes... is
>
> 1473428538.203      0 192.168.1.17 TCP_DENIED/403 4032 GET
> http://affiliates.digitalriver.com/z/36067/CD109988 - HIER_NONE/-
text/html
>
> But, i dont have any denied rule. As far as i know this is the only
web that
> give me this problem...  (probably not )
> What can be? What can do?
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/squid-TCP-DENIED-403-tp4679435.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX0sF/AAoJENNXIZxhPexGMQ8IAKnryIEeoyKL5VZJAF4Xw8yR
n8rRlAQBMlBNDbn7GCLSHY1ck/ZXMrOTXuWmaxo7kmXjOBlV9MOvUWIxQXfYcsqu
06pc05AzH7OWzVEWg5AHQlKf6XzKRbaBlIgUPbAarxNvfAhIyNv54q6QkFn0mi8z
wNeIPvqos/0PgW7DSRix0eJNgUWRII+M8iq+Snoe6MW7HZONlRIyNT8YmRPuOrRo
lD356mY8U+AHMppnrXl8qa7oIkX8E0Hs1WCkS4iP1bbb2+7TXRp+sSA67WFlXCYa
qRZc5ZbPqjgpmXRtMDU+0iHeWKA1SnuABQIzFRxPsz4U2yRBgqlkb0E+FCbgago=
=0wv4
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160909/147bc607/attachment.key>

From erdosain9 at gmail.com  Fri Sep  9 14:06:03 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Fri, 9 Sep 2016 07:06:03 -0700 (PDT)
Subject: [squid-users] squid TCP_DENIED/403
In-Reply-To: <b8925a7e-73c5-b19d-7312-5519173c4d9c@gmail.com>
References: <1473429329556-4679435.post@n4.nabble.com>
 <b8925a7e-73c5-b19d-7312-5519173c4d9c@gmail.com>
Message-ID: <1473429963203-4679439.post@n4.nabble.com>

I cant believe how good is your help! (that you look my config in the other
post)
Thanks! 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/squid-TCP-DENIED-403-tp4679435p4679439.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Fri Sep  9 15:03:53 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Fri, 9 Sep 2016 08:03:53 -0700 (PDT)
Subject: [squid-users] squid TCP_DENIED/403
In-Reply-To: <1473429963203-4679439.post@n4.nabble.com>
References: <1473429329556-4679435.post@n4.nabble.com>
 <b8925a7e-73c5-b19d-7312-5519173c4d9c@gmail.com>
 <1473429963203-4679439.post@n4.nabble.com>
Message-ID: <1473433433921-4679440.post@n4.nabble.com>

But... now that i think... there is a way to prevent this?? because, i see
now that this is the "real" link... i mean, i wrote 

http://www.vladan.fr/recommends/essentials

then i get "ACCES DENIED" with that web
(http://affiliates.digitalriver.com/z/36067/CD109988)

but, should go too

http://store.vmware.com/store/vmware/en_US/pd/productID.282883900?cvosrc=affiliate.ond.CD109988&ClickID=cp47iavevep7ep4klz77sxxl4esawllqknea

Thanks!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/squid-TCP-DENIED-403-tp4679435p4679440.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Fri Sep  9 17:18:22 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 9 Sep 2016 23:18:22 +0600
Subject: [squid-users] squid TCP_DENIED/403
In-Reply-To: <1473433433921-4679440.post@n4.nabble.com>
References: <1473429329556-4679435.post@n4.nabble.com>
 <b8925a7e-73c5-b19d-7312-5519173c4d9c@gmail.com>
 <1473429963203-4679439.post@n4.nabble.com>
 <1473433433921-4679440.post@n4.nabble.com>
Message-ID: <1306f04e-55a8-9bc3-fb3b-a0da30993ea3@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Just not go to sites via marketing references.

Just type

http://store.vmware.com/store/vmware/en_US/pd/productID.282883900

in address bar then press Enter. Viola! Here is it!

09.09.2016 21:03, erdosain9 ?????:
> But... now that i think... there is a way to prevent this?? because, i see
> now that this is the "real" link... i mean, i wrote
>
> http://www.vladan.fr/recommends/essentials
>
> then i get "ACCES DENIED" with that web
> (http://affiliates.digitalriver.com/z/36067/CD109988)
>
> but, should go too
>
>
http://store.vmware.com/store/vmware/en_US/pd/productID.282883900?cvosrc=affiliate.ond.CD109988&ClickID=cp47iavevep7ep4klz77sxxl4esawllqknea
>
> Thanks!
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/squid-TCP-DENIED-403-tp4679435p4679440.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX0u7eAAoJENNXIZxhPexGUbYIAIttrWYuf1YWq7gNWzFrVQMS
OWOl/GTvS1Ixqbsf13xxEY6tK5R0yG+RY5gqLlWwyoF+1NrikWWJZ5J/+7TK7Xq8
y5llYMpE/MJFdEghVRUajeUMY5NdsGS3KUiyaBaywbuguSEkbvrAeCi3vRj9GFEW
L8o4h+QB55ure0x9L+b+vy7L8ScOHPzWNi57vE5LCXNCXhtLp4sT9J5DxgzI1foS
Syw0tY7tuQ0/gKOE50TWKRwGGgnH+yS8Z/2bAd9F3venRK4uET+4nDWDEmyTGawS
gIvKxtzlt6NI9cPhZRpWHqLJoDwQyD5JdO4FaUIqQmjcKDPB8S4mHkk7lsnJcjQ=
=EmVd
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160909/4b580804/attachment.key>

From cassiano at polaco.pro.br  Fri Sep  9 18:07:18 2016
From: cassiano at polaco.pro.br (Cassiano Martin)
Date: Fri, 9 Sep 2016 15:07:18 -0300
Subject: [squid-users] compliled squid size
In-Reply-To: <1473429537536-4679436.post@n4.nabble.com>
References: <1473264161043-4679405.post@n4.nabble.com>
 <20160907161749.GA18997@fantomas.sk>
 <1473429537536-4679436.post@n4.nabble.com>
Message-ID: <B85199B8-A39E-47F7-91C6-61186E89124C@polaco.pro.br>


Strip binary: strip -s squid

Enviado do meu iPhone

> Em 9 de set de 2016, ?s 10:58, mzgmedia <mzgmedia at gmail.com> escreveu:
> 
> I think that the 
> the param is -g and is there already there on the CFLAGS and CXXFLAGS
> 
> 
> 
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/compliled-squid-size-tp4679405p4679436.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From mzgmedia at gmail.com  Fri Sep  9 18:06:22 2016
From: mzgmedia at gmail.com (mzgmedia)
Date: Fri, 9 Sep 2016 11:06:22 -0700 (PDT)
Subject: [squid-users] compliled squid size
In-Reply-To: <1473429537536-4679436.post@n4.nabble.com>
References: <1473264161043-4679405.post@n4.nabble.com>
 <20160907161749.GA18997@fantomas.sk>
 <1473429537536-4679436.post@n4.nabble.com>
Message-ID: <1473444382232-4679443.post@n4.nabble.com>

thank you genius

that was



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/compliled-squid-size-tp4679405p4679443.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Fri Sep  9 19:14:24 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 10 Sep 2016 01:14:24 +0600
Subject: [squid-users] compliled squid size
In-Reply-To: <B85199B8-A39E-47F7-91C6-61186E89124C@polaco.pro.br>
References: <1473264161043-4679405.post@n4.nabble.com>
 <20160907161749.GA18997@fantomas.sk>
 <1473429537536-4679436.post@n4.nabble.com>
 <B85199B8-A39E-47F7-91C6-61186E89124C@polaco.pro.br>
Message-ID: <3148d452-9b01-f38c-dfa9-52382624f55c@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
..... or just gmake install-strip ;)


10.09.2016 0:07, Cassiano Martin ?????:
>
> Strip binary: strip -s squid
>
> Enviado do meu iPhone
>
>> Em 9 de set de 2016, ?s 10:58, mzgmedia <mzgmedia at gmail.com> escreveu:
>>
>> I think that the
>> the param is -g and is there already there on the CFLAGS and CXXFLAGS
>>
>>
>>
>> --
>> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/compliled-squid-size-tp4679405p4679436.html
>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX0woPAAoJENNXIZxhPexGGX8H/3QQXk8McqbmqBo/BphHTlZx
iEXbWPdC70luoGSAoW1/lP/5vn7pW3npiA36CxttpiXfxs3nmNDAdMjHRh9PgrEA
MsO0SJr9Yg3woOyDPbcCLx8M1nlODOZSnLlPrEqM0KYJKBBE5YML1UXdn9FrC/cQ
OoIOltMySHG23kH6/wie4lvAdziEWZa7WN+qgv81d5fhCvqLcQ7nQ5X8Wq+Az5EI
UYU1rMEtDwzmJPBG+yEiJERZjQBejKeF0+3OkaMI5z7jTvZMpPWGh+0YhtYA0V/P
GRKfqgg0sQEc0kP/CZMNjoiVSJPQx1Ic5++5UZBQR/vsf0/gL+mR63/CAOIzfWQ=
=MqEO
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160910/445fddde/attachment.key>

From omidkosari at yahoo.com  Sun Sep 11 15:04:07 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Sun, 11 Sep 2016 08:04:07 -0700 (PDT)
Subject: [squid-users] TProxy and client_dst_passthru
In-Reply-To: <201609081315.20967.Antony.Stone@squid.open.source.it>
References: <1435840988272-4672022.post@n4.nabble.com>
 <1435925126078-4672041.post@n4.nabble.com> <5596872A.7050508@treenet.co.nz>
 <1435929702099-4672044.post@n4.nabble.com> <5596A975.2060903@treenet.co.nz>
 <1435936908218-4672048.post@n4.nabble.com> <5596BA9A.9070401@treenet.co.nz>
 <1435996974697-4672054.post@n4.nabble.com>
 <1473330462286-4679422.post@n4.nabble.com>
 <201609081315.20967.Antony.Stone@squid.open.source.it>
Message-ID: <1473606247560-4679450.post@n4.nabble.com>

Antony Stone wrote
> On Thursday 08 September 2016 at 12:27:42, Omid Kosari wrote:
> 
>> Hi Fred,
>> 
>> Same problem here . Do you found any solution or workaround ?
> 
> Please clarify which message you are reply / referring to.
> 
> Thanks,
> 
> 
> Antony.
> 
> -- 
> Archaeologists have found a previously-unknown dinosaur which seems to
> have 
> had a very large vocabulary.  They've named it Thesaurus.
> 
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users

I refer to following messages .i have same problem


FredT wrote
> Hi Amos,
> 
> We have done additional tests in production with ISPs and the ORIGINAL_DST
> in tproxy cannot be cached.
> In normal mode (not tproxy), ORIGINAL_DST can be cached, no problem.
> But once in tproxy (http_port 3128 tproxy), no way, it's impossible to get
> TCP_HIT.
> 
> We have played with the client_dst_passthru and the host_verify_strict,
> many combinaisons on/off.
> By settings client_dst_passthru ON and host_verify_strict OFF, we can
> reduce the number of ORIGINAL_DST (generating DNS "alerts" in the
> cache.log) but it makes issues with HTTPS websites (facebook, hotmail,
> gmail, etc...).
> We have also tried many DNS servers (internals and/or externals), same
> issue.
> 
> I read what you explain in your previous email but it seems there is
> something weird.
> The problem is that the ORIGINAL_DST could be up to 25% of the traffic
> with some installations meaning this part is "out-of-control" in term of
> cache potential.
> 
> All help is welcome here
> Thanks in advance.
> 
> Bye Fred 


FredT wrote
> Hi Eliezer,
> 
> Well, we have done many tests with Squid (3.1 to 3.5.x), disabling
> "client_dst_passthru" (off) will stop the DNS entry as explained in the
> wiki, the option directly acts on the flag "ORIGINAL_DST".
> As you know, ORIGINAL_DST switches the optimization off (ex: StoreID) then
> it's not possible to cache the URL (ex:
> http://cdn2.example.com/mypic.png).
> 
> In no tproxy/NAT mode, the client_dst_passthru works perfectly by
> disabling the DNS entry control, so optimization is done correctly.
> But in tproxy/NAT, the client_dst_passthru has no effect, we see
> ORIGINAL_DST in logs.
> 
> So, maybe I'm totaly wrong here the client_dst_passthru is not related to
> the ORIGINAL_DST, or there is an explaination why the client_dst_passthru
> does not act in tproxy/NAT...
> 
> Bye Fred

please look at following results 
As you know the following command shows statistics of line which only have
ORIGINAL_DST

tail -n 1000000 /var/log/squid/access.log | grep -a ORIGINAL_DST | calamaris 
--config-file /etc/calamaris/calamaris.conf --all-useful-reports | more


----------------------------------------------------- --------------
----------
Proxy statistics
----------------------------------------------------- --------------
----------
Total amount:                                               requests    
378310
unique hosts/users:                                            hosts      
1859
Total Bandwidth:                                                Byte    
16453M
Proxy efficiency (HIT [kB/sec] / DIRECT [kB/sec]):            factor      
1.22
Average speed increase:                                            %      
0.39
TCP response time of 100% requests:                             msec        
0M
----------------------------------------------------- --------------
----------
Cache statistics
----------------------------------------------------- --------------
----------
Total amount cached:                                        requests     
11945
Request hit rate:                                                  %      
3.16
Bandwidth savings:                                              Byte      
355M
Bandwidth savings in Percent (Byte hit rate):                      %      
2.16
Average cached object size:                                     Byte        
0M
Average direct object size:                                     Byte        
0M
Average object size:                                            Byte        
0M
----------------------------------------------------- --------------
----------

# Incoming TCP-requests by status
status                          request      %  sec/req   Byte       % 
kB/sec
------------------------------ --------- ------ ------- -------- ------
-------
HIT                                11945   3.16    1.94     355M   2.16  
15.66
 TCP_REFRESH_UNMODIFIED_ABORTED
                                     104   0.03   44.89     158M   0.96  
34.55
 TCP_REFRESH_UNMODIFIED            11795   3.12    0.77     119M   0.72  
13.47
 TCP_REFRESH_UNMODIFIED_TIMEDOUT
                                       8   0.00 1108.82      79M   0.48   
9.09
 TCP_HIT_ABORTED                      38   0.01   16.89       0M   0.00   
0.00
MISS                              366365  96.84    3.49   16098M  97.84  
12.87
 TCP_MISS                         342321  90.49    2.11   12723M  77.33  
18.02
 TCP_MISS_ABORTED                  20588   5.44   24.61    2902M  17.64   
5.86
 TCP_REFRESH_MODIFIED_ABORTED         55   0.01   99.34     193M   1.17  
36.14
 TCP_REFRESH_MODIFIED                941   0.25    1.41     118M   0.72  
91.05
 TCP_MISS_TIMEDOUT                    45   0.01  949.92      80M   0.49   
1.92
 TCP_SWAPFAIL_MISS                  2107   0.56    0.34      49M   0.30  
71.08
 TCP_REFRESH_FAIL_OLD_ABORTED         12   0.00   31.61      29M   0.18  
78.96
 TCP_CLIENT_REFRESH_MISS             284   0.08    0.31       3M   0.02  
35.74
 TCP_SWAPFAIL_MISS_ABORTED            11   0.00    0.49       0M   0.00   
1.47
 TCP_REFRESH_FAIL_OLD                  1   0.00   59.05       0M   0.00   
0.06
ERROR                                  0   0.00    0.00        0   0.00   
0.00
------------------------------ --------- ------ ------- -------- ------
-------
Sum                               378310 100.00    3.45   16453M 100.00  
12.92


# Outgoing requests by status
status                          request      %  sec/req   Byte       % 
kB/sec
------------------------------ --------- ------ ------- -------- ------
-------
DIRECT Fetch from Source          378310 100.00    3.45   16453M 100.00  
12.92
 ORIGINAL_DST                     377424  99.77    3.45   16424M  99.82  
12.92
 TIMEOUT_ORIGINAL_DST                886   0.23    2.51      29M   0.18  
13.31
SIBLING                                0   0.00    0.00        0   0.00   
0.00
PARENT                                 0   0.00    0.00        0   0.00   
0.00
------------------------------ --------- ------ ------- -------- ------
-------
Sum                               378310 100.00    3.45   16453M 100.00  
12.92


# Outgoing requests by destination
neighbor type                   request      %  sec/req   Byte       % 
kB/sec
------------------------------ --------- ------ ------- -------- ------
-------
DIRECT                            378310 100.00    3.45   16453M 100.00  
12.92
------------------------------ --------- ------ ------- -------- ------
-------
Sum                               378310 100.00    3.45   16453M 100.00  
12.92



As you know the following command shows statistics of line which DOES NOT
have ORIGINAL_DST

tail -n 1000000 /var/log/squid/access.log | grep -a -v ORIGINAL_DST |
calamaris  --config-file /etc/calamaris/calamaris.conf --all-useful-reports
| more

----------------------------------------------------- --------------
----------
Proxy statistics
----------------------------------------------------- --------------
----------
Total amount:                                               requests    
624866
unique hosts/users:                                            hosts      
1427
Total Bandwidth:                                                Byte     
6864M
Proxy efficiency (HIT [kB/sec] / DIRECT [kB/sec]):            factor      
1.62
Average speed increase:                                            %     
29.24
TCP response time of 100% requests:                             msec        
0M
----------------------------------------------------- --------------
----------
Cache statistics
----------------------------------------------------- --------------
----------
Total amount cached:                                        requests    
134472
Request hit rate:                                                  %     
21.52
Bandwidth savings:                                              Byte     
4067M
Bandwidth savings in Percent (Byte hit rate):                      %     
59.26
Average cached object size:                                     Byte        
0M
Average direct object size:                                     Byte        
0M
Average object size:                                            Byte        
0M
----------------------------------------------------- --------------
----------

# Incoming TCP-requests by status
status                          request      %  sec/req   Byte       % 
kB/sec
------------------------------ --------- ------ ------- -------- ------
-------
HIT                               134472  21.52    0.42    4067M  59.26  
74.04
 TCP_HIT                           72883  11.66    0.23    3092M  45.04 
191.49
 TCP_MEM_HIT                       33078   5.29    0.08     507M   7.38 
193.01
 TCP_HIT_ABORTED                     556   0.09   16.68     344M   5.01  
37.97
 TCP_REFRESH_UNMODIFIED             3432   0.55    1.25     111M   1.62  
26.39
 TCP_IMS_HIT                       24390   3.90    0.00       6M   0.08  
67.65
 TCP_HIT_TIMEDOUT                     23   0.00  907.61       5M   0.07   
0.23
 TCP_MEM_HIT_ABORTED                  82   0.01    7.15       3M   0.04   
5.20
 TCP_REFRESH_UNMODIFIED_ABORTED
                                      27   0.00   70.41       0M   0.00   
0.18
 TCP_IMS_HIT_ABORTED                   1   0.00    0.00       0M   0.00
1689.45
MISS                               62944  10.07    0.88    2713M  39.52  
50.42
 TCP_MISS                          59824   9.57    0.41    2425M  35.32 
100.93
 TCP_MISS_ABORTED                    451   0.07   11.23     157M   2.29  
31.82
 TCP_SWAPFAIL_MISS                  2069   0.33    0.38      51M   0.75  
66.22
 TCP_MISS_TIMEDOUT                    21   0.00  913.96      43M   0.63   
2.29
 TCP_REFRESH_MODIFIED_ABORTED          6   0.00  138.09      32M   0.46  
38.99
 TCP_REFRESH_MODIFIED                366   0.06    0.18       3M   0.04  
45.45
 TCP_CLIENT_REFRESH_MISS             160   0.03    0.13       2M   0.02  
83.19
 TCP_REFRESH_FAIL_OLD                 33   0.01  135.57       0M   0.01   
0.09
 TCP_REFRESH_FAIL_OLD_ABORTED          1   0.00   59.66       0M   0.00   
1.94
 TCP_SWAPFAIL_MISS_ABORTED            13   0.00    0.07       0M   0.00   
0.00
ERROR                             427450  68.41    0.02      84M   1.22  
11.52
 TCP_MISS                            761   0.12    0.61      42M   0.61  
93.13
 TCP_MISS_ABORTED                    284   0.05   16.29      36M   0.53   
8.02
 TCP_DENIED                        19564   3.13    0.00       4M   0.07  
71.49
 TAG_NONE                           8096   1.30    0.00       1M   0.02
1484.81
 TCP_DENIED_ABORTED                    7   0.00    0.00       0M   0.00
2327.01
 TAG_NONE_ABORTED                    732   0.12    3.11       0M   0.00   
0.00
 UDP_MISS                         334769  53.57    0.00       0M   0.00   
0.00
 UDP_HIT                           63237  10.12    0.00       0M   0.00   
0.00
------------------------------ --------- ------ ------- -------- ------
-------
Sum                               624866 100.00    0.19    6864M 100.00  
59.16



60% vs 2% hit ratio(bytes) . The problem is ORIGINAL_DST










--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TProxy-and-client-dst-passthru-tp4670189p4679450.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Sun Sep 11 14:36:19 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 12 Sep 2016 02:36:19 +1200
Subject: [squid-users] [squid-announce] Squid 3.5.21 is available
Message-ID: <63609595-62f8-b6c8-b349-f5129657edc3@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-3.5.21 release!


This release is a bug fix release resolving several issues found in the
prior Squid releases.


The major changes to be aware of:


* Bug #4534: assertion failure in xcalloc when using many cache_dir

Squid is documented as supporting up to 64 cache directories, but would
crash with a memory allocation error if more than a few were actually
configured.


* Bug #4542: authentication credentials IP TTL updated incorrectly

This bug caused error in max_user_ip ACL accounting to allow clients to
shift IP address more times than configured. This bug fix may have an
effect on IPv6 clients using "proviacy adressing" to rotate IPs.


* Bug #4428: mal-formed Cache-Control:stale-if-error header

This bug shows up as incorrect stale-if-error values being relayed by
Squid breaking the use of this feature in the recipients. Squid now
relays the header values correctly.


* Bug #3025: Proxy-Authenticate problem using ICAP server

With this change Squid now treats the ICAP REQMOD adaptation point as a
part of itself with regards to proxy authentication. The
Proxy-Authentication header received from the client is delivered as
part of the HTTP request headers in expectation that the ICAP service
may authenticate and/or produce 407 response itself.

Note that use of stateful or connection-oriented authentication schemes
is not possible. HTTP is designed to operate in a stateless way and any
deviation from that design requires Squid to perform special message
processing.


* HTTP: MUST always revalidate Cache-Control:no-cache responses.

This bug shows up as Squid not revalidating some responses until they
became stale according to refresh_pattern heuristic rules (specifically
the minimum caching age). Squid now revalidates these objects on every
request.


* HTTP: do not allow Proxy-Connection to override Connection header

The Proxy-Connection: header is a long-deprecated experimental header.
For the past decade Squid has been actively stripping it out of relayed
traffic. This release continues the removal process by also preventing
it from having any effect on Squid client connection persistence when a
Connection: header is present.


* SSL CN wildcard must only match a single domain component [fragment].

This bug shows up as incorrect matching (or non-matching) of the
ss::server_name ACL against TLS certificate values. Squid now treats the
certificate CN fields according to X.509 domain matching requirements
instead of HTTP domain matching requirements.



 All users of Squid-3 are encouraged to upgrade to this release as
soon as possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v3/3.5/RELEASENOTES.html
when you are ready to make the switch to Squid-3.5

Upgrade tip:
  "squid -k parse" is starting to display even more
   useful hints about squid.conf changes.

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v3/3.5/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/3.5/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries

_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Sun Sep 11 14:53:39 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 12 Sep 2016 02:53:39 +1200
Subject: [squid-users] [squid-announce] Squid 4.0.14 beta is available
Message-ID: <c5916bd8-ea74-300d-c6e0-24c18e277f97@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-4.0.14 release!


This release is a bug fix release resolving several issues found in the
prior Squid releases.


The major changes to be aware of:


* Bugs #4404 and #4503: access.log responses marked _ABORTED

The past few Squid-4 releases have incorrectly logged several
transaction types as ABORTED. This hopefully resolves the
remaininginstances of that behaviour.


* Make Squid death due to overloaded helpers optional

Previous Squid versions would halt the entire Squid process if a helper
became too non-responsive and its lookup queue became overloaded. This
release allows the Squid handling behaviour to be configured to simulate
an ERR helper response instead of always halting.


* Crashes on shutdown

The Squid shutdown process when set to a short timeout was crashing
while cleaning up idle ICAP connections. This resolves the ICAP issues,
however some other sources of shutdown crash still remain to be fixed.



* Various HTTP/1.1 compliance updates

Previous Squid releases have a number of compliance issues with RFC 7230
updated HTTP specifications. This release fixes several issues involved
with detecting invalid message framing and required error reponse
generation.


* General portability and stability changes

This release also includes a large number of code cleanup fixes too
small to mention individually, but which resolve a lot of portability
and build issues.

The release size appears to be very large, however the majority of
alterations are in documentation and translation updates for Squid-4.



 All users of Squid-4.0.x are encouraged to upgrade to this release as
soon as possible.

 All users of Squid-3 are encouraged to test this release out and plan
for upgrades where possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v4/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Sun Sep 11 16:23:39 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 12 Sep 2016 04:23:39 +1200
Subject: [squid-users] TProxy and client_dst_passthru
In-Reply-To: <1473606247560-4679450.post@n4.nabble.com>
References: <1435840988272-4672022.post@n4.nabble.com>
 <1435925126078-4672041.post@n4.nabble.com> <5596872A.7050508@treenet.co.nz>
 <1435929702099-4672044.post@n4.nabble.com> <5596A975.2060903@treenet.co.nz>
 <1435936908218-4672048.post@n4.nabble.com> <5596BA9A.9070401@treenet.co.nz>
 <1435996974697-4672054.post@n4.nabble.com>
 <1473330462286-4679422.post@n4.nabble.com>
 <201609081315.20967.Antony.Stone@squid.open.source.it>
 <1473606247560-4679450.post@n4.nabble.com>
Message-ID: <f6cbebb8-3ca6-8d7f-8524-0649a020703c@treenet.co.nz>

On 12/09/2016 3:04 a.m., Omid Kosari wrote:
> 
> I refer to following messages .i have same problem
> 

The "problem" is misunderstanding of the log entry meaning.

> 
> FredT wrote
>> Hi Amos,
>>
>> We have done additional tests in production with ISPs and the ORIGINAL_DST
>> in tproxy cannot be cached.
>> In normal mode (not tproxy), ORIGINAL_DST can be cached, no problem.
>> But once in tproxy (http_port 3128 tproxy), no way, it's impossible to get
>> TCP_HIT.
>>
>> We have played with the client_dst_passthru and the host_verify_strict,
>> many combinaisons on/off.
>> By settings client_dst_passthru ON and host_verify_strict OFF, we can
>> reduce the number of ORIGINAL_DST (generating DNS "alerts" in the
>> cache.log) but it makes issues with HTTPS websites (facebook, hotmail,
>> gmail, etc...).

Nod. That is the purpose of those controls. So they are working.

>> We have also tried many DNS servers (internals and/or externals), same
>> issue.
>>
>> I read what you explain in your previous email but it seems there is
>> something weird.
>> The problem is that the ORIGINAL_DST could be up to 25% of the traffic
>> with some installations meaning this part is "out-of-control" in term of
>> cache potential.

Any server type could be up to 100%. The type of server used implies
nothing about caching potential.

The reverse is true: caching potential implies server type, with
adjustments for traffic mode type and squid.conf settings.

For example:
 HIT implies HEIR_NONE.

 MISS with intercept/tproxy implies ORIGINAL_DST or a peer.
 REFRESH with intercept/tproxy implies ORIGINAL_DST or a peer.

 MISS in forward-proxy implies DIRECT or a peer.
 REFRESH in forward-proxy implies DIRECT or a peer.

> 
> FredT wrote
>> Hi Eliezer,
>>
>> Well, we have done many tests with Squid (3.1 to 3.5.x), disabling
>> "client_dst_passthru" (off) will stop the DNS entry as explained in the
>> wiki, the option directly acts on the flag "ORIGINAL_DST".
>> As you know, ORIGINAL_DST switches the optimization off (ex: StoreID) then
>> it's not possible to cache the URL (ex:
>> http://cdn2.example.com/mypic.png).

ORIGINAL_DST does nothing. It is simply a label indicating which type of
server supplied the HTTP response message for the transaction.

>>
>> In no tproxy/NAT mode, the client_dst_passthru works perfectly by
>> disabling the DNS entry control, so optimization is done correctly.
>> But in tproxy/NAT, the client_dst_passthru has no effect, we see
>> ORIGINAL_DST in logs.
>>
>> So, maybe I'm totaly wrong here the client_dst_passthru is not related to
>> the ORIGINAL_DST,

"client_dst_passthru on" makes Squid use ORIGINAL_DST (client provided)
server instead of DIRECT (DNS lookup) server(s) for *all* intercepted
traffic. Even requests where DIRECT is possible.


> or there is an explaination why the client_dst_passthru
>> does not act in tproxy/NAT...
>>

There is. The "transparent" part of "transparent interception proxy"
means that MISS should use the same server the client was originally
sending its request to (the ORIGINAL_DST server).


>> Bye Fred
> 
> please look at following results 
...
> 
> 60% vs 2% hit ratio(bytes) . The problem is ORIGINAL_DST
> 

The only visible problem is why that 2% exists.

==> ORIGINAL_DST is should *only* ever be used on MISS or
REFRESH/revalidate traffic. Never on a HIT. Thus zero (0%) hit-ratio is
the expected behaviour.

For the same reason that a report of the log traffic using "grep -v HIT"
will show zero cache ratio.

Amos



From rousskov at measurement-factory.com  Sun Sep 11 18:18:00 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 11 Sep 2016 12:18:00 -0600
Subject: [squid-users] TProxy and client_dst_passthru
In-Reply-To: <f6cbebb8-3ca6-8d7f-8524-0649a020703c@treenet.co.nz>
References: <1435840988272-4672022.post@n4.nabble.com>
 <1435925126078-4672041.post@n4.nabble.com> <5596872A.7050508@treenet.co.nz>
 <1435929702099-4672044.post@n4.nabble.com> <5596A975.2060903@treenet.co.nz>
 <1435936908218-4672048.post@n4.nabble.com> <5596BA9A.9070401@treenet.co.nz>
 <1435996974697-4672054.post@n4.nabble.com>
 <1473330462286-4679422.post@n4.nabble.com>
 <201609081315.20967.Antony.Stone@squid.open.source.it>
 <1473606247560-4679450.post@n4.nabble.com>
 <f6cbebb8-3ca6-8d7f-8524-0649a020703c@treenet.co.nz>
Message-ID: <0906265c-186d-f6f4-a51c-3a5f56a6ef96@measurement-factory.com>

On 09/11/2016 10:23 AM, Amos Jeffries wrote:
> The only visible problem is why that 2% exists.
> 
> ==> ORIGINAL_DST is should *only* ever be used on MISS or
> REFRESH/revalidate traffic. Never on a HIT. Thus zero (0%) hit-ratio is
> the expected behaviour.


It is possible that a terminology clash affects Squid code and Squid
output interpretation. There are two popular approaches:

A. "Hit" means "served from the cache" or, more precisely, "the response
is based on the cache entry present in the cache at the time of request
interpretation". "Pure hits" (or similar) are served without an attempt
to contact the origin server. "Revalidation hits" (or similar) are
served after an attempt to check the cached entry freshness with the
origin server (that did not result in replacing or removing the
previously cached entry).

B. "Hit" means served without an attempt to contact the origin server.
Revalidation transactions are not hits (by definition).

The above definitions are not precise and do not cover all use cases,
but that is not important for highlighting the key difference between them.


Many people, including Amos in his email quoted above AFAICT, are using
approach "B". Many people, including myself, are using approach "A".
Squid code, output, and documentation mix the two approaches,
unfortunately. Be careful when you interpret what you see.


HTH,

Alex.



From fredbmail at free.fr  Mon Sep 12 08:23:59 2016
From: fredbmail at free.fr (FredB)
Date: Mon, 12 Sep 2016 10:23:59 +0200 (CEST)
Subject: [squid-users] Rock store status
In-Reply-To: <5d227f1b-e1e9-b8cb-c70a-9aeed3b90691@opendium.com>
Message-ID: <1099544740.855884885.1473668639818.JavaMail.root@zimbra4-e1.priv.proxad.net>

Just for for information, no problem after two weeks. 
Unfortunately I can't test now with IpcIo (a problem with systemd) but rock store is very stable 


From ahmed.zaeem at netstream.ps  Mon Sep 12 09:47:28 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Mon, 12 Sep 2016 12:47:28 +0300
Subject: [squid-users] caching store increase then decrease during caching
	windows updates and all request are TCP_MISS ??!!!
Message-ID: <A7F66C74-5126-441D-BB33-F83A2D91892D@netstream.ps>

hi 

i have caching store increase then decrease  during caching windows updates and all request are TCP_MISS ??!!!

root at raspberrypi:~# du -sh /var/cache/squid/
558M    /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
561M    /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
564M    /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
647M    /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
650M    /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
652M    /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
604M    /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
605M    /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
605M    /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
606M    /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
606M    /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
595M    /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/


here is sample of logs :

1473672787.641    444 192.168.0.10 TCP_CLIENT_REFRESH_MISS/200 872 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672799.084  11876 192.168.0.10 TCP_MISS/206 615396 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672808.553   8396 192.168.0.10 TCP_MISS/206 615396 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672811.054  24905 192.168.0.10 TCP_MISS/206 1017331 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/1fc27b6e-d563-415b-b11a-9e7e6f1ad33c? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672812.922   2687 192.168.0.10 TCP_CLIENT_REFRESH_MISS/206 1049501 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672817.014 325638 192.168.0.10 TCP_MISS/206 1049207 GET http://au.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672830.229   7673 192.168.0.10 TCP_CLIENT_REFRESH_MISS/206 615395 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672830.577  14270 192.168.0.10 TCP_CLIENT_REFRESH_MISS/206 1049513 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/1fc27b6e-d563-415b-b11a-9e7e6f1ad33c? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672834.348 332467 192.168.0.10 TCP_MISS/206 1049207 GET http://au.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672834.693  12139 192.168.0.10 TCP_CLIENT_REFRESH_MISS/206 1049501 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672839.837     19 192.168.0.10 TCP_MISS/200 875 HEAD http://dl.delivery.mp.microsoft.com/filestreamingservice/files/74c45c94-e8f2-43c6-9c1a-0ef798b56116 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672839.874     21 192.168.0.10 TCP_CLIENT_REFRESH_MISS/200 874 HEAD http://dl.delivery.mp.microsoft.com/filestreamingservice/files/74c45c94-e8f2-43c6-9c1a-0ef798b56116 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672839.876     22 192.168.0.10 TCP_CLIENT_REFRESH_MISS/200 874 HEAD http://dl.delivery.mp.microsoft.com/filestreamingservice/files/74c45c94-e8f2-43c6-9c1a-0ef798b56116 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672839.879     23 192.168.0.10 TCP_CLIENT_REFRESH_MISS/200 874 HEAD http://dl.delivery.mp.microsoft.com/filestreamingservice/files/74c45c94-e8f2-43c6-9c1a-0ef798b56116 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672839.884     25 192.168.0.10 TCP_CLIENT_REFRESH_MISS/200 874 HEAD http://dl.delivery.mp.microsoft.com/filestreamingservice/files/74c45c94-e8f2-43c6-9c1a-0ef798b56116 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672839.970     90 192.168.0.10 TCP_MISS/206 81857 GET http://dl.delivery.mp.microsoft.com/filestreamingservice/files/74c45c94-e8f2-43c6-9c1a-0ef798b56116 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672840.373    489 192.168.0.10 TCP_MISS/206 81857 GET http://dl.delivery.mp.microsoft.com/filestreamingservice/files/74c45c94-e8f2-43c6-9c1a-0ef798b56116 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672840.374    471 192.168.0.10 TCP_MISS/206 81857 GET http://dl.delivery.mp.microsoft.com/filestreamingservice/files/74c45c94-e8f2-43c6-9c1a-0ef798b56116 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672840.714    825 192.168.0.10 TCP_MISS/206 81857 GET http://dl.delivery.mp.microsoft.com/filestreamingservice/files/74c45c94-e8f2-43c6-9c1a-0ef798b56116 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672840.768  24456 192.168.0.10 TCP_CLIENT_REFRESH_MISS/206 1049513 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/1fc27b6e-d563-415b-b11a-9e7e6f1ad33c? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672841.687     25 192.168.0.10 TCP_MISS/200 3818 GET http://dl.delivery.mp.microsoft.com/filestreamingservice//files/6bd00537-0160-46ff-b7c8-a58327e6722c/pieceshash - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672841.769     21 192.168.0.10 TCP_MISS/200 840 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/6bd00537-0160-46ff-b7c8-a58327e6722c? - ORIGINAL_DST/13.107.4.50 -
1473672841.791     37 192.168.0.10 TCP_MISS/200 840 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/6bd00537-0160-46ff-b7c8-a58327e6722c? - ORIGINAL_DST/13.107.4.50 -
1473672841.794     39 192.168.0.10 TCP_MISS/200 880 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/6bd00537-0160-46ff-b7c8-a58327e6722c? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672842.075    326 192.168.0.10 TCP_MISS/200 880 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/6bd00537-0160-46ff-b7c8-a58327e6722c? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672855.052  69572 192.168.0.10 TCP_MISS/206 311289 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ca1aed45-880f-4294-81ef-368554dcb282? - ORIGINAL_DST/13.107.4.50 -
1473672870.475  23892 192.168.0.10 TCP_CLIENT_REFRESH_MISS/206 1049513 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/1fc27b6e-d563-415b-b11a-9e7e6f1ad33c? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672877.996     53 192.168.0.10 TCP_MISS/200 299 POST http://webres1.bullguard.ctmail.com/SpamResolverNG/SpamResolverNG.dll? - ORIGINAL_DST/84.39.153.33 text/html
1473672881.817  35092 192.168.0.10 TCP_CLIENT_REFRESH_MISS/206 1049513 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/1fc27b6e-d563-415b-b11a-9e7e6f1ad33c? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672888.028     40 192.168.0.10 TCP_MISS/200 868 HEAD http://dl.delivery.mp.microsoft.com/filestreamingservice/files/83501d77-70b0-4d63-8891-949938435c79 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672888.061     20 192.168.0.10 TCP_CLIENT_REFRESH_MISS/200 867 HEAD http://dl.delivery.mp.microsoft.com/filestreamingservice/files/83501d77-70b0-4d63-8891-949938435c79 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672888.067     24 192.168.0.10 TCP_CLIENT_REFRESH_MISS/200 867 HEAD http://dl.delivery.mp.microsoft.com/filestreamingservice/files/83501d77-70b0-4d63-8891-949938435c79 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672888.076     31 192.168.0.10 TCP_CLIENT_REFRESH_MISS/200 867 HEAD http://dl.delivery.mp.microsoft.com/filestreamingservice/files/83501d77-70b0-4d63-8891-949938435c79 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672888.076     29 192.168.0.10 TCP_CLIENT_REFRESH_MISS/200 867 HEAD http://dl.delivery.mp.microsoft.com/filestreamingservice/files/83501d77-70b0-4d63-8891-949938435c79 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672888.113     32 192.168.0.10 TCP_MISS/206 15400 GET http://dl.delivery.mp.microsoft.com/filestreamingservice/files/83501d77-70b0-4d63-8891-949938435c79 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672888.169     28 192.168.0.10 TCP_CLIENT_REFRESH_MISS/206 15399 GET http://dl.delivery.mp.microsoft.com/filestreamingservice/files/83501d77-70b0-4d63-8891-949938435c79 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672888.507    362 192.168.0.10 TCP_CLIENT_REFRESH_MISS/206 15399 GET http://dl.delivery.mp.microsoft.com/filestreamingservice/files/83501d77-70b0-4d63-8891-949938435c79 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672888.521    374 192.168.0.10 TCP_CLIENT_REFRESH_MISS/206 15399 GET http://dl.delivery.mp.microsoft.com/filestreamingservice/files/83501d77-70b0-4d63-8891-949938435c79 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672889.692     20 192.168.0.10 TCP_MISS/200 833 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/b9956be9-38bc-41cd-8668-3691c7e0c235? - ORIGINAL_DST/13.107.4.50 -
1473672889.729     20 192.168.0.10 TCP_CLIENT_REFRESH_MISS/200 832 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/b9956be9-38bc-41cd-8668-3691c7e0c235? - ORIGINAL_DST/13.107.4.50 -
1473672889.732     21 192.168.0.10 TCP_CLIENT_REFRESH_MISS/200 832 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/b9956be9-38bc-41cd-8668-3691c7e0c235? - ORIGINAL_DST/13.107.4.50 -
1473672889.756     42 192.168.0.10 TCP_CLIENT_REFRESH_MISS/200 832 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/b9956be9-38bc-41cd-8668-3691c7e0c235? - ORIGINAL_DST/13.107.4.50 -
1473672890.050    335 192.168.0.10 TCP_CLIENT_REFRESH_MISS/200 832 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/b9956be9-38bc-41cd-8668-3691c7e0c235? - ORIGINAL_DST/13.107.4.50 -
1473672901.577 398176 192.168.0.10 TCP_MISS/206 1049207 GET http://au.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672913.571 408766 192.168.0.10 TCP_MISS/206 1049207 GET http://au.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473672919.550  29816 192.168.0.10 TCP_MISS/206 437400 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/b9956be9-38bc-41cd-8668-3691c7e0c235? - ORIGINAL_DST/13.107.4.50 -
^C



here is config file :

#refresh_pattern ([^.]+.|)(download|(windows|)update|).(microsoft.|)com/.*.(cab|exe|msi|msp) 4320 100% 43200 reload-into-ims
refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200 reload-into-ims
refresh_pattern ([^.]+.|)(download|adcdownload).(apple.|)com/.*.(pkg|dmg) 4320 100% 43200 reload-into-ims
range_offset_limit -1


quick_abort_min -1

http_port 3129 intercept

visible_hostname hey 
cache_swap_low 90
cache_swap_high 95
fqdncache_size 65535
ipcache_size 65535
ipcache_low 98
ipcache_high 99
memory_replacement_policy heap GDSF
cache_replacement_policy heap LFUDA
############
#cache_mem 512 MB
maximum_object_size 1 GB
################################################
maximum_object_size_in_memory 10 MB
#########
acl windowsupdate dstdomain fg.v4.download.windowsupdate.com
acl windowsupdate dstdomain windowsupdate.microsoft.com
acl windowsupdate dstdomain .update.microsoft.com
acl windowsupdate dstdomain download.windowsupdate.com
acl windowsupdate dstdomain redir.metaservices.microsoft.com
acl windowsupdate dstdomain images.metaservices.microsoft.com
acl windowsupdate dstdomain c.microsoft.com
acl windowsupdate dstdomain www.download.windowsupdate.com
acl windowsupdate dstdomain wustat.windows.com
acl windowsupdate dstdomain crl.microsoft.com
acl windowsupdate dstdomain sls.microsoft.com
acl windowsupdate dstdomain productactivation.one.microsoft.com
acl windowsupdate dstdomain ntservicepack.microsoft.com
acl windowsupdate dstdomain au.download.windowsupdate.com
acl windowsupdate dstdomain ds.download.windowsupdate.com
acl windowsupdate dstdomain ctldl.windowsupdate.com
acl windowsupdate dstdomain .data.microsoft.com
acl windowsupdate dstdomain .l.windowsupdate.com
acl windowsupdate dstdomain .microsoft.com.akadns.net
acl windowsupdate dstdomain .deploy.akamaitechnologies.com
################################################### 
acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com
acl wuCONNECT dstdomain sls.microsoft.com
####################################
refresh_pattern -i windowsupdate.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i microsoft.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i windows.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i microsoft.com.akadns.net/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i deploy.akamaitechnologies.com/.*\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
########################################################
#refresh_pattern \^ftp:           1440    20%     10080
#refresh_pattern \^gopher:        1440    0%      1440
#refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
#refresh_pattern .               0       20%     4320
########################################################
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access allow CONNECT wuCONNECT localnet
http_access allow windowsupdate localnet
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.0.1:3128

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /var/cache/squid 20000 16 256
cache_dir aufs /var/cache/squid 10000 32 256

# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid
##############



hope to help


cheers


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160912/21e692e9/attachment.htm>

From erdosain9 at gmail.com  Mon Sep 12 13:45:27 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 12 Sep 2016 06:45:27 -0700 (PDT)
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
Message-ID: <1473687927215-4679455.post@n4.nabble.com>

Hi
I keep having problem...

i put this on squid.conf

acl excludeSSL ssl::server_name .whatsapp.com

ssl_bump splice excludeSSL
ssl_bump peek all
ssl_bump bump all

but, nothing same behavior...




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679455.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chicocvenancio at gmail.com  Mon Sep 12 13:52:16 2016
From: chicocvenancio at gmail.com (Chico Venancio)
Date: Mon, 12 Sep 2016 10:52:16 -0300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1473687927215-4679455.post@n4.nabble.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
Message-ID: <CAEpx-0XC2J-aG4OAqwSe+LP1g9OKu8H+zm0ZoDrm55rK-y78cA@mail.gmail.com>

The logs remained the same?
What is the CA of the certificate on the page now?

Chico Venancio

Em 12/09/2016 10:49, "erdosain9" <erdosain9 at gmail.com> escreveu:

> Hi
> I keep having problem...
>
> i put this on squid.conf
>
> acl excludeSSL ssl::server_name .whatsapp.com
>
> ssl_bump splice excludeSSL
> ssl_bump peek all
> ssl_bump bump all
>
> but, nothing same behavior...
>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.
> 1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679455.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160912/ed35907b/attachment.htm>

From squid3 at treenet.co.nz  Mon Sep 12 14:13:05 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 13 Sep 2016 02:13:05 +1200
Subject: [squid-users] caching store increase then decrease during
 caching windows updates and all request are TCP_MISS ??!!!
In-Reply-To: <A7F66C74-5126-441D-BB33-F83A2D91892D@netstream.ps>
References: <A7F66C74-5126-441D-BB33-F83A2D91892D@netstream.ps>
Message-ID: <3aea9e0f-f149-f20e-57c6-0a466445e011@treenet.co.nz>

On 12/09/2016 9:47 p.m., --Ahmad-- wrote:
> hi 
> 
> i have caching store increase then decrease  during caching windows updates and all request are TCP_MISS ??!!!
> 
> root at raspberrypi:~# du -sh /var/cache/squid/
> 558M    /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 561M    /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 564M    /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 647M    /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 650M    /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 652M    /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 604M    /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 605M    /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 605M    /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 606M    /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 606M    /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 595M    /var/cache/squid/
> root at raspberrypi:~# du -sh /var/cache/squid/
> 

What relevance is this?


> 
> here is sample of logs :
> 
> 1473672787.641    444 192.168.0.10 TCP_CLIENT_REFRESH_MISS/200 872 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56? - ORIGINAL_DST/13.107.4.50 application/octet-stream

HEAD request. None of the object got downloaded.

> 1473672799.084  11876 192.168.0.10 TCP_MISS/206 615396 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56? - ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473672808.553   8396 192.168.0.10 TCP_MISS/206 615396 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56? - ORIGINAL_DST/13.107.4.50 application/octet-stream
> 1473672811.054  24905 192.168.0.10 TCP_MISS/206 1017331 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/1fc27b6e-d563-415b-b11a-9e7e6f1ad33c? - ORIGINAL_DST/13.107.4.50 application/octet-stream

Some Range requests for URI with ?query parameters. You need to add
"strip_query_terms no" to your squid.conf. Then you will be able to see
if these are identical URI or not.

Right now all that can be said is the script on the server which is
producing objects is the same one for many of the requests. There is no
way to know if they are requesting the same object or different ones.


> 1473672812.922   2687 192.168.0.10 TCP_CLIENT_REFRESH_MISS/206 1049501 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56? - ORIGINAL_DST/13.107.4.50 application/octet-stream

A request where the client required new content to be fetched.

The rest of your log shows a lot of repeats of the above things happening.


> 
> #refresh_pattern ([^.]+.|)(download|(windows|)update|).(microsoft.|)com/.*.(cab|exe|msi|msp) 4320 100% 43200 reload-into-ims
> refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200 reload-into-ims
> refresh_pattern ([^.]+.|)(download|adcdownload).(apple.|)com/.*.(pkg|dmg) 4320 100% 43200 reload-into-ims

These refresh_pattern contain broken regex patterns.


1) Unless you explicitly use start/end anchors regex have implicit .*
sequences before and after the provided pattern.

 That means "([^.]+.|)" and "([^.]+.)?" are just a very complex (and
slow to compare) ways to write .*


2) '.' is a reserved character. If you want it to match a '.' in the
domain name you need to write it as \.


Hint both above regex will match the non-Microsoft, non-Apple URI:
  http://download.com/?pkg=caddy


Amos



From yvoinov at gmail.com  Mon Sep 12 14:13:14 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 12 Sep 2016 20:13:14 +0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1473687927215-4679455.post@n4.nabble.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
Message-ID: <6c298b3b-640b-0f62-638d-9a15999c2ef8@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Rewrite as follows:

acl step1 at_step SslBump1
acl excludeSSL ssl::server_name_regex web.whatsapp.com

ssl_bump peek step1
ssl_bump splice excludeSSL
ssl_bump bump all

Then try again.

12.09.2016 19:45, erdosain9 ?????:
> Hi
> I keep having problem...
>
> i put this on squid.conf
>
> acl excludeSSL ssl::server_name .whatsapp.com
>
> ssl_bump splice excludeSSL
> ssl_bump peek all
> ssl_bump bump all
>
> but, nothing same behavior...
>
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679455.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX1rf6AAoJENNXIZxhPexGhOAH/i9y2z/z5n7EJha66YQOlLNQ
QYrGaHPC2Bg0od3TdIKvpi5xpUfECNYgD9lNLaoXJ6c8lSNaJ+GgOs0W4azfIKBK
0ThMnTVO7d3RIAFeZL68XyAtccfYY6pKR5R0N4iIIubvCNQJLurJdME9l/7V9YW0
M8651z8phD5qzMUr2o3Hot06ICNOWnQpWiXMjhcCJ+ihpAyVq39ipIiiCQiTdviZ
/dgTCBgc1K91MwbHISFBIVN3iWYYSXdvrpeG8rzyvOFmnmzKlA0UAnFBj6YTawPN
7c5C4aChQ0q6iTWC2NG2U1feDRXja/BOXHjdvxg/hEIpAePl5f8UUdkZtl1FIm4=
=Muas
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160912/d7b6c0ba/attachment.key>

From yvoinov at gmail.com  Mon Sep 12 14:14:13 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 12 Sep 2016 20:14:13 +0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <6c298b3b-640b-0f62-638d-9a15999c2ef8@gmail.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
 <6c298b3b-640b-0f62-638d-9a15999c2ef8@gmail.com>
Message-ID: <364f404f-a22a-2791-b367-51e3f5fa9484@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Oooops,

acl must be:

acl excludeSSL ssl::server_name_regex web\.whatsapp\.com

12.09.2016 20:13, Yuri Voinov ?????:
>
> Rewrite as follows:
>
> acl step1 at_step SslBump1
> acl excludeSSL ssl::server_name_regex web.whatsapp.com
>
> ssl_bump peek step1
> ssl_bump splice excludeSSL
> ssl_bump bump all
>
> Then try again.
>
> 12.09.2016 19:45, erdosain9 ?????:
> > Hi
> > I keep having problem...
>
> > i put this on squid.conf
>
> > acl excludeSSL ssl::server_name .whatsapp.com
>
> > ssl_bump splice excludeSSL
> > ssl_bump peek all
> > ssl_bump bump all
>
> > but, nothing same behavior...
>
>
>
>
> > --
> > View this message in context:
>
http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679455.html
> > Sent from the Squid - Users mailing list archive at Nabble.com.
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX1rg1AAoJENNXIZxhPexGV+MH/2lpeHvCwtqa51f5TMsf1nXP
kAdlhDf6RhCd4jcuZ9chhfGqvXD6MwDMSO0jl62HWcrRog+rCmzuPu2aDP8+uKk8
gLh/5m9qCfRI5CEEtXw2yvcgCHQD1d4MkZEMeo+V6wiMJ/q8lBBiV5agSIGIi5xJ
Gq3Nk0hjuwGeovfHB4ThAWmAH/AOfVDBfzvNUknGlMeejARq43+s0+VrFpw9JYhv
30stI32SMKPld5mBkzEfIsZxu2F73r2BgfV6LpFds+r13LLcKf7cubZnlcBC98vD
uCeVEC/3ftAFBGFc6TWYwrEBoJApWhzHLAoaWCMZK6INF/T3LIlxfbME5a5YRgU=
=Xq79
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160912/af4df9b1/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160912/af4df9b1/attachment.key>

From marcus.kool at urlfilterdb.com  Mon Sep 12 14:38:05 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Mon, 12 Sep 2016 11:38:05 -0300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <364f404f-a22a-2791-b367-51e3f5fa9484@gmail.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
 <6c298b3b-640b-0f62-638d-9a15999c2ef8@gmail.com>
 <364f404f-a22a-2791-b367-51e3f5fa9484@gmail.com>
Message-ID: <284da6c2-3a23-0151-add2-5b87b2f7b57d@urlfilterdb.com>



On 09/12/2016 11:14 AM, Yuri Voinov wrote:
>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> Oooops,
>
> acl must be:
>
> acl excludeSSL ssl::server_name_regex web\.whatsapp\.com

why a regex?
why not the following ?
    acl excludeSSL ssl::server_name web.whatsapp.com

Marcus


From yvoinov at gmail.com  Mon Sep 12 14:42:43 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 12 Sep 2016 20:42:43 +0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <284da6c2-3a23-0151-add2-5b87b2f7b57d@urlfilterdb.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
 <6c298b3b-640b-0f62-638d-9a15999c2ef8@gmail.com>
 <364f404f-a22a-2791-b367-51e3f5fa9484@gmail.com>
 <284da6c2-3a23-0151-add2-5b87b2f7b57d@urlfilterdb.com>
Message-ID: <7773c161-efb3-b572-19e9-d3af5affa6e5@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Because ssl :: server_name_regex works reliably. As shown by my personal
practice. But in general it is by op's choice.


12.09.2016 20:38, Marcus Kool ?????:
>
>
> On 09/12/2016 11:14 AM, Yuri Voinov wrote:
>>
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>>
>> Oooops,
>>
>> acl must be:
>>
>> acl excludeSSL ssl::server_name_regex web\.whatsapp\.com
>
> why a regex?
> why not the following ?
>    acl excludeSSL ssl::server_name web.whatsapp.com
>
> Marcus
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX1r7jAAoJENNXIZxhPexGiDgH/18a12inWiaf8mRJtB/eGOhV
s1Qb+TMtWEQUUKJocxnSLKWTND6I+ZrVnDHGI2b64x0bZUOHYtH1dx0NgC0/xC8L
JppQbDHAQfQGjLuJFfu+VLzp5SNDGXYxZ/4aliiF8JMibtcOSt4viMbxN20ic5Bo
eAIuZiJXuVhmUhND9eSGUTyOdATgjCzBOZRwBBAWbi4/CfK7FML2kfzqZnbGsc8i
6qy01w0Hz06g2bY0Gz3qD/VtnYIjGACR+LZlugnpw1LXVpsQfW8D3m7l50zSBflM
Sp4Ku5BqjJ/pIXbODR4TZ70KdzqYUZ1V6u+LBukTvrjiLSoX2hnkYlhzviZGS0A=
=YrH2
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160912/dff1d2f8/attachment.key>

From chicocvenancio at gmail.com  Mon Sep 12 15:15:22 2016
From: chicocvenancio at gmail.com (Chico Venancio)
Date: Mon, 12 Sep 2016 12:15:22 -0300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <7773c161-efb3-b572-19e9-d3af5affa6e5@gmail.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
 <6c298b3b-640b-0f62-638d-9a15999c2ef8@gmail.com>
 <364f404f-a22a-2791-b367-51e3f5fa9484@gmail.com>
 <284da6c2-3a23-0151-add2-5b87b2f7b57d@urlfilterdb.com>
 <7773c161-efb3-b572-19e9-d3af5affa6e5@gmail.com>
Message-ID: <CAEpx-0WsVF5K_K-ROKCotGMPDL1tQjDRvMjOc3+b1zjceU8Wxw@mail.gmail.com>

I'd think a regex consumes a lot more resources than server name, but don't
know if it is significant.
Anyway, without more details we can't be sure the server name not matching
is the problem.

We need access logs and client(browser) details.

By the way, acl excludeSSL ssl::server_name web.whatsapp.com
Would not work, whatsapp uses some subdomains that also should not be
bumped.

Chico Venancio

Em 12/09/2016 11:42, "Yuri Voinov" <yvoinov at gmail.com> escreveu:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> Because ssl :: server_name_regex works reliably. As shown by my personal
> practice. But in general it is by op's choice.
>
>
> 12.09.2016 20:38, Marcus Kool ?????:
> >
> >
> > On 09/12/2016 11:14 AM, Yuri Voinov wrote:
> >>
> >> -----BEGIN PGP SIGNED MESSAGE-----
> >> Hash: SHA256
> >>
> >> Oooops,
> >>
> >> acl must be:
> >>
> >> acl excludeSSL ssl::server_name_regex web\.whatsapp\.com
> >
> > why a regex?
> > why not the following ?
> >    acl excludeSSL ssl::server_name web.whatsapp.com
> >
> > Marcus
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJX1r7jAAoJENNXIZxhPexGiDgH/18a12inWiaf8mRJtB/eGOhV
> s1Qb+TMtWEQUUKJocxnSLKWTND6I+ZrVnDHGI2b64x0bZUOHYtH1dx0NgC0/xC8L
> JppQbDHAQfQGjLuJFfu+VLzp5SNDGXYxZ/4aliiF8JMibtcOSt4viMbxN20ic5Bo
> eAIuZiJXuVhmUhND9eSGUTyOdATgjCzBOZRwBBAWbi4/CfK7FML2kfzqZnbGsc8i
> 6qy01w0Hz06g2bY0Gz3qD/VtnYIjGACR+LZlugnpw1LXVpsQfW8D3m7l50zSBflM
> Sp4Ku5BqjJ/pIXbODR4TZ70KdzqYUZ1V6u+LBukTvrjiLSoX2hnkYlhzviZGS0A=
> =YrH2
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160912/21cee03a/attachment.htm>

From marcus.kool at urlfilterdb.com  Mon Sep 12 15:40:36 2016
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Mon, 12 Sep 2016 12:40:36 -0300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <CAEpx-0WsVF5K_K-ROKCotGMPDL1tQjDRvMjOc3+b1zjceU8Wxw@mail.gmail.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
 <6c298b3b-640b-0f62-638d-9a15999c2ef8@gmail.com>
 <364f404f-a22a-2791-b367-51e3f5fa9484@gmail.com>
 <284da6c2-3a23-0151-add2-5b87b2f7b57d@urlfilterdb.com>
 <7773c161-efb3-b572-19e9-d3af5affa6e5@gmail.com>
 <CAEpx-0WsVF5K_K-ROKCotGMPDL1tQjDRvMjOc3+b1zjceU8Wxw@mail.gmail.com>
Message-ID: <62c95d49-3d71-1941-9f8e-0675df41fd68@urlfilterdb.com>



On 09/12/2016 12:15 PM, Chico Venancio wrote:
> I'd think a regex consumes a lot more resources than server name, but don't know if it is significant.
> Anyway, without more details we can't be sure the server name not matching is the problem.
>
> We need access logs and client(browser) details.
>
> By the way, acl excludeSSL ssl::server_name web.whatsapp.com <http://web.whatsapp.com>
> Would not work, whatsapp uses some subdomains that also should not be bumped.

squid.conf.documented seems to imply that you can add a dot to match the subdomains also, just like with dstdomain :
    acl excludeSSL ssl::server_name .web.whatsapp.com

Be careful with the regex, it matches also web.whatsapp.com-24.site: it needs a $

Marcus

> Chico Venancio
>
>
> Em 12/09/2016 11:42, "Yuri Voinov" <yvoinov at gmail.com <mailto:yvoinov at gmail.com>> escreveu:
>
>
>     -----BEGIN PGP SIGNED MESSAGE-----
>     Hash: SHA256
>
>     Because ssl :: server_name_regex works reliably. As shown by my personal
>     practice. But in general it is by op's choice.
>
>
>     12.09.2016 20:38, Marcus Kool ?????:
>     >
>     >
>     > On 09/12/2016 11:14 AM, Yuri Voinov wrote:
>     >>
>     >> -----BEGIN PGP SIGNED MESSAGE-----
>     >> Hash: SHA256
>     >>
>     >> Oooops,
>     >>
>     >> acl must be:
>     >>
>     >> acl excludeSSL ssl::server_name_regex web\.whatsapp\.com
>     >
>     > why a regex?
>     > why not the following ?
>     >    acl excludeSSL ssl::server_name web.whatsapp.com <http://web.whatsapp.com>
>     >
>     > Marcus
>     > _______________________________________________
>     > squid-users mailing list
>     > squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
>     > http://lists.squid-cache.org/listinfo/squid-users <http://lists.squid-cache.org/listinfo/squid-users>
>
>     -----BEGIN PGP SIGNATURE-----
>     Version: GnuPG v2
>
>     iQEcBAEBCAAGBQJX1r7jAAoJENNXIZxhPexGiDgH/18a12inWiaf8mRJtB/eGOhV
>     s1Qb+TMtWEQUUKJocxnSLKWTND6I+ZrVnDHGI2b64x0bZUOHYtH1dx0NgC0/xC8L
>     JppQbDHAQfQGjLuJFfu+VLzp5SNDGXYxZ/4aliiF8JMibtcOSt4viMbxN20ic5Bo
>     eAIuZiJXuVhmUhND9eSGUTyOdATgjCzBOZRwBBAWbi4/CfK7FML2kfzqZnbGsc8i
>     6qy01w0Hz06g2bY0Gz3qD/VtnYIjGACR+LZlugnpw1LXVpsQfW8D3m7l50zSBflM
>     Sp4Ku5BqjJ/pIXbODR4TZ70KdzqYUZ1V6u+LBukTvrjiLSoX2hnkYlhzviZGS0A=
>     =YrH2
>     -----END PGP SIGNATURE-----
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users <http://lists.squid-cache.org/listinfo/squid-users>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>


From yvoinov at gmail.com  Mon Sep 12 15:45:35 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 12 Sep 2016 21:45:35 +0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <62c95d49-3d71-1941-9f8e-0675df41fd68@urlfilterdb.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
 <6c298b3b-640b-0f62-638d-9a15999c2ef8@gmail.com>
 <364f404f-a22a-2791-b367-51e3f5fa9484@gmail.com>
 <284da6c2-3a23-0151-add2-5b87b2f7b57d@urlfilterdb.com>
 <7773c161-efb3-b572-19e9-d3af5affa6e5@gmail.com>
 <CAEpx-0WsVF5K_K-ROKCotGMPDL1tQjDRvMjOc3+b1zjceU8Wxw@mail.gmail.com>
 <62c95d49-3d71-1941-9f8e-0675df41fd68@urlfilterdb.com>
Message-ID: <93b46cb9-a128-4adf-cef7-60da0e25265c@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Both of you are caught in the access control list, completely lost sight
of that op basically wrote the wrong general rules for bump, skipped
step1 - SslBump1.

Which can be splice by server name without peek performing? Yes?

That is why he did not work. All the rest is not fundamental cosmetics
and can be written and debugged later.

12.09.2016 21:40, Marcus Kool ?????:
>
>
> On 09/12/2016 12:15 PM, Chico Venancio wrote:
>> I'd think a regex consumes a lot more resources than server name, but
don't know if it is significant.
>> Anyway, without more details we can't be sure the server name not
matching is the problem.
>>
>> We need access logs and client(browser) details.
>>
>> By the way, acl excludeSSL ssl::server_name web.whatsapp.com
<http://web.whatsapp.com>
>> Would not work, whatsapp uses some subdomains that also should not be
bumped.
>
> squid.conf.documented seems to imply that you can add a dot to match
the subdomains also, just like with dstdomain :
>    acl excludeSSL ssl::server_name .web.whatsapp.com
>
> Be careful with the regex, it matches also web.whatsapp.com-24.site:
it needs a $
>
> Marcus
>
>> Chico Venancio
>>
>>
>> Em 12/09/2016 11:42, "Yuri Voinov" <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>> escreveu:
>>
>>
> Because ssl :: server_name_regex works reliably. As shown by my personal
> practice. But in general it is by op's choice.
>
>
> 12.09.2016 20:38, Marcus Kool ?????:
>
>
> > On 09/12/2016 11:14 AM, Yuri Voinov wrote:
>
> >> -----BEGIN PGP SIGNED MESSAGE-----
> >> Hash: SHA256
>
> >> Oooops,
>
> >> acl must be:
>
> >> acl excludeSSL ssl::server_name_regex web\.whatsapp\.com
>
> > why a regex?
> > why not the following ?
> >    acl excludeSSL ssl::server_name web.whatsapp.com
<http://web.whatsapp.com>
>
> > Marcus
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
> > http://lists.squid-cache.org/listinfo/squid-users
<http://lists.squid-cache.org/listinfo/squid-users>
>
>>
>>
>>     _______________________________________________
>>     squid-users mailing list
>>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>>     http://lists.squid-cache.org/listinfo/squid-users
<http://lists.squid-cache.org/listinfo/squid-users>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX1s2fAAoJENNXIZxhPexGRXoH/2TnA1g+DuwwXsg5qugSngC/
3mcMtqtSZ8szaESp0ofCuGvB7f3pYU3pOpm6OAumyDDIO9bVmHX7QLDK4hkNWaUo
f8BICxg/zqDbIxLOJyMRo9kCyT3CT1hUd7F/EtvAAcAUk68blAKupksYZ5gDSeN6
gY13RLeWoNgsaIZL+LgztRf8bKGepIK9vGFyIPvKXxYP0dey4/zndyjQbRf1ggtV
E8K/0xU6zaflcggKFPjBHWpekATRoza09/+BT8T/THndf1CBybmAo7wOGi1oG6nu
1qw3H2X32DyDjIOQ+YV6NVjSDb0jPaj/taanT3W5F1/VNhFshyw/IjIPLeoYw9k=
=TMa5
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160912/eb11414c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160912/eb11414c/attachment.key>

From chicocvenancio at gmail.com  Mon Sep 12 16:38:59 2016
From: chicocvenancio at gmail.com (Chico Venancio)
Date: Mon, 12 Sep 2016 13:38:59 -0300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <93b46cb9-a128-4adf-cef7-60da0e25265c@gmail.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
 <6c298b3b-640b-0f62-638d-9a15999c2ef8@gmail.com>
 <364f404f-a22a-2791-b367-51e3f5fa9484@gmail.com>
 <284da6c2-3a23-0151-add2-5b87b2f7b57d@urlfilterdb.com>
 <7773c161-efb3-b572-19e9-d3af5affa6e5@gmail.com>
 <CAEpx-0WsVF5K_K-ROKCotGMPDL1tQjDRvMjOc3+b1zjceU8Wxw@mail.gmail.com>
 <62c95d49-3d71-1941-9f8e-0675df41fd68@urlfilterdb.com>
 <93b46cb9-a128-4adf-cef7-60da0e25265c@gmail.com>
Message-ID: <CAEpx-0W6X0dh3uLjfWatkEBUJOEWq_S3XnGDAMej2U3LJCnEXw@mail.gmail.com>

According to the logs bump was being performed before the change, so I
don't follow.

If the lack of an acl step1 SslBump1 was the problem he would have no bumps
or bumps with incorrect host names in the certificates. Right now it seems
he either is bumping some connect request whatsapp doesn't want to be MITM
or he is outright denying something, maybe something else entirely, without
logs we cannot be sure.
Chico Venancio

Em 12/09/2016 12:46, "Yuri Voinov" <yvoinov at gmail.com> escreveu:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> Both of you are caught in the access control list, completely lost sight
> of that op basically wrote the wrong general rules for bump, skipped step1
> - SslBump1.
>
> Which can be splice by server name without peek performing? Yes?
>
> That is why he did not work. All the rest is not fundamental cosmetics and
> can be written and debugged later.
>
> 12.09.2016 21:40, Marcus Kool ?????:
> >
> >
> > On 09/12/2016 12:15 PM, Chico Venancio wrote:
> >> I'd think a regex consumes a lot more resources than server name, but
> don't know if it is significant.
> >> Anyway, without more details we can't be sure the server name not
> matching is the problem.
> >>
> >> We need access logs and client(browser) details.
> >>
> >> By the way, acl excludeSSL ssl::server_name web.whatsapp.com
> <http://web.whatsapp.com> <http://web.whatsapp.com>
> >> Would not work, whatsapp uses some subdomains that also should not be
> bumped.
> >
> > squid.conf.documented seems to imply that you can add a dot to match the
> subdomains also, just like with dstdomain :
> >    acl excludeSSL ssl::server_name .web.whatsapp.com
> >
> > Be careful with the regex, it matches also web.whatsapp.com-24.site: it
> needs a $
> >
> > Marcus
> >
> >> Chico Venancio
> >>
> >>
> >> Em 12/09/2016 11:42, "Yuri Voinov" <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com> <yvoinov at gmail.com>> escreveu:
> >>
> >>
> > Because ssl :: server_name_regex works reliably. As shown by my personal
> > practice. But in general it is by op's choice.
> >
> >
> > 12.09.2016 20:38, Marcus Kool ?????:
> >
> >
> > > On 09/12/2016 11:14 AM, Yuri Voinov wrote:
> >
> > >> -----BEGIN PGP SIGNED MESSAGE-----
> > >> Hash: SHA256
> >
> > >> Oooops,
> >
> > >> acl must be:
> >
> > >> acl excludeSSL ssl::server_name_regex web\.whatsapp\.com
> >
> > > why a regex?
> > > why not the following ?
> > >    acl excludeSSL ssl::server_name web.whatsapp.com
> <http://web.whatsapp.com> <http://web.whatsapp.com>
> >
> > > Marcus
> > > _______________________________________________
> > > squid-users mailing list
> > > squid-users at lists.squid-cache.org <mailto:squid-users at lists.
> squid-cache.org> <squid-users at lists.squid-cache.org>
> > > http://lists.squid-cache.org/listinfo/squid-users
> <http://lists.squid-cache.org/listinfo/squid-users>
> <http://lists.squid-cache.org/listinfo/squid-users>
> >
> >>
> >>
> >>     _______________________________________________
> >>     squid-users mailing list
> >>     squid-users at lists.squid-cache.org <mailto:squid-users at lists.
> squid-cache.org> <squid-users at lists.squid-cache.org>
> >>     http://lists.squid-cache.org/listinfo/squid-users
> <http://lists.squid-cache.org/listinfo/squid-users>
> <http://lists.squid-cache.org/listinfo/squid-users>
> >>
> >>
> >>
> >> _______________________________________________
> >> squid-users mailing list
> >> squid-users at lists.squid-cache.org
> >> http://lists.squid-cache.org/listinfo/squid-users
> >>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJX1s2fAAoJENNXIZxhPexGRXoH/2TnA1g+DuwwXsg5qugSngC/
> 3mcMtqtSZ8szaESp0ofCuGvB7f3pYU3pOpm6OAumyDDIO9bVmHX7QLDK4hkNWaUo
> f8BICxg/zqDbIxLOJyMRo9kCyT3CT1hUd7F/EtvAAcAUk68blAKupksYZ5gDSeN6
> gY13RLeWoNgsaIZL+LgztRf8bKGepIK9vGFyIPvKXxYP0dey4/zndyjQbRf1ggtV
> E8K/0xU6zaflcggKFPjBHWpekATRoza09/+BT8T/THndf1CBybmAo7wOGi1oG6nu
> 1qw3H2X32DyDjIOQ+YV6NVjSDb0jPaj/taanT3W5F1/VNhFshyw/IjIPLeoYw9k=
> =TMa5
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160912/bcef6b98/attachment.htm>

From eduardoocarneiro at gmail.com  Mon Sep 12 16:54:20 2016
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Mon, 12 Sep 2016 09:54:20 -0700 (PDT)
Subject: [squid-users] Lost of all squid cache
Message-ID: <1473699260953-4679466.post@n4.nabble.com>

Hi everyone!

I've got a strange issue on my Squid 3.5.19. 

About 30 minutes ago, my squid stopped and I noticed that the message
"Rebuilding storage in /squid/cache/directory (dirty log)" was in my
cache.log. Other message was also detected in my cache.log (Store rebuilding
is 5.14% complete). When reached 100%, I lost all my 350GB cache data. 

The data are still in the Hard disk, but squid doesn't understand it.

Using squidclient, I can see now only 0.1% of my cache used. For the
operating system, all the data are still available. For the squid, not.

Someone can help me that?

Best regards,
Eduardo Carneiro



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Lost-of-all-squid-cache-tp4679466.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon Sep 12 16:59:21 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 12 Sep 2016 22:59:21 +0600
Subject: [squid-users] Lost of all squid cache
In-Reply-To: <1473699260953-4679466.post@n4.nabble.com>
References: <1473699260953-4679466.post@n4.nabble.com>
Message-ID: <93895347-1e9f-0a0b-5409-34e40acd4ef9@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
What cache_dir mode? aufs?


12.09.2016 22:54, Eduardo Carneiro ?????:
> Hi everyone!
>
> I've got a strange issue on my Squid 3.5.19.
>
> About 30 minutes ago, my squid stopped and I noticed that the message
> "Rebuilding storage in /squid/cache/directory (dirty log)" was in my
> cache.log. Other message was also detected in my cache.log (Store
rebuilding
> is 5.14% complete). When reached 100%, I lost all my 350GB cache data.
>
> The data are still in the Hard disk, but squid doesn't understand it.
>
> Using squidclient, I can see now only 0.1% of my cache used. For the
> operating system, all the data are still available. For the squid, not.
>
> Someone can help me that?
>
> Best regards,
> Eduardo Carneiro
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Lost-of-all-squid-cache-tp4679466.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX1t7oAAoJENNXIZxhPexGLOwH/0hIn4qN90b/y4yCMxC3bAes
2DHO+vCJQ0RPGfagtF3tt3Jhzasd83uRs7ru6P9qSeabGmTGFgsQwLWIjBqjoJVI
2sCF8XBCXGAEh0EvSI2H5KnipV8uVtJQtdbCusF8DMLC5IaeZNO4VjrdY+/Iq8dC
Kt2H/jcMasongmYRf9n+XSdDi240oR0WhS4gVGJ4S09QHv1u9a7SFSZfOSjMB632
vpoT9aHJi1/GKnz3Zyvc5Zq6qf+BcQkJLEA96bmbocYkH5B4iFM65GNUK1Y+r6yY
99Z0YM7DOhnrk4+cvv+3nyceSHG3qIAWXpwnuyVnt6sJEiyzIANqjSgD3C9s+AU=
=o08b
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160912/8609572f/attachment.key>

From eduardoocarneiro at gmail.com  Mon Sep 12 16:57:15 2016
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Mon, 12 Sep 2016 09:57:15 -0700 (PDT)
Subject: [squid-users] Lost of all squid cache
In-Reply-To: <93895347-1e9f-0a0b-5409-34e40acd4ef9@gmail.com>
References: <1473699260953-4679466.post@n4.nabble.com>
 <93895347-1e9f-0a0b-5409-34e40acd4ef9@gmail.com>
Message-ID: <1473699435450-4679468.post@n4.nabble.com>

No Yuri, is "ufs".



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Lost-of-all-squid-cache-tp4679466p4679468.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon Sep 12 17:12:39 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 12 Sep 2016 23:12:39 +0600
Subject: [squid-users] Lost of all squid cache
In-Reply-To: <1473699260953-4679466.post@n4.nabble.com>
References: <1473699260953-4679466.post@n4.nabble.com>
Message-ID: <a49cefe7-3a37-63fc-ad40-d69006e7e5a9@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Hm.

As a recovery you can try to rename/remove swap.state from cache_dir's
and start squid again. AFAIK in this case it re-indexing all exists disk
cache contents and build new one swap.state file. Also, does all
permissions to cache_dir and subdirectories recursively is correct and
intact?


12.09.2016 22:54, Eduardo Carneiro ?????:
> Hi everyone!
>
> I've got a strange issue on my Squid 3.5.19.
>
> About 30 minutes ago, my squid stopped and I noticed that the message
> "Rebuilding storage in /squid/cache/directory (dirty log)" was in my
> cache.log. Other message was also detected in my cache.log (Store
rebuilding
> is 5.14% complete). When reached 100%, I lost all my 350GB cache data.
>
> The data are still in the Hard disk, but squid doesn't understand it.
>
> Using squidclient, I can see now only 0.1% of my cache used. For the
> operating system, all the data are still available. For the squid, not.
>
> Someone can help me that?
>
> Best regards,
> Eduardo Carneiro
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Lost-of-all-squid-cache-tp4679466.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX1uIGAAoJENNXIZxhPexGLy0IAJNYvHpDMR7PL/y/KFpnJBaE
Q2HSvivzlYqLRpl42A9rtlsYb+KY7ZzOlsUtgFtwV2Cl1Unb2em8K3nPcS7zPiMU
kqF+ee969Ajgr7iwU3Cu+3t4dGe1eLOnkXz4RPSY0KXx/9qDlyPKi2iKTuJ1h5O+
jsnBT6TAds5vETeLmhmvFdseYUkj1etou5nWjgjmDVCRDrQ+s/MJEZ2gdckdJO5w
VYcqGARpLEe2JT2XuVTorWtBQaj5n53OJ7mzkhe1Eqxv+f66T7WPAIUdipeYpUcD
+5C8tsem+lcnlsGkiMrnxp7UfvaKGOuiLLe00Z1EsAypjxzv1tPfddyaLPrwy+0=
=Cml6
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160912/ae94351d/attachment.key>

From erdosain9 at gmail.com  Mon Sep 12 17:40:58 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 12 Sep 2016 10:40:58 -0700 (PDT)
Subject: [squid-users] SSO (ldap kerberos)
Message-ID: <1473702058647-4679470.post@n4.nabble.com>

HI.
I want Single Sing on... i want can take groups to assing acl and control
bandwith, etc.  
I need ldap??? i know i need kerberos to sso... but is necessary ldap for
take groups??? or with kerberos i can "take" groups??

by the way, 
i probe this

basic_ldap_auth -R -b "cn=Users,dc=example,dc=lan" -D
squid-probe at example.lan -w 123456  -f sAMAccountName=%s -v 3 -s sub -h
192.168.1.102

basic_ldap_auth: WARNING, could not bind to binddn 'Strong(er)
authentication required'

Why this???
but anyway, i need ldap for take groups???

my version of squid is 3.5.20 (on Centos 7)
AD (samba 4.3.9 on Ubuntu)

Thanks!




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SSO-ldap-kerberos-tp4679470.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Mon Sep 12 19:36:35 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 12 Sep 2016 13:36:35 -0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1473687927215-4679455.post@n4.nabble.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
Message-ID: <a0fbb21c-8617-5acc-a2ab-4b695e25296c@measurement-factory.com>

On 09/12/2016 07:45 AM, erdosain9 wrote:

> ssl_bump splice excludeSSL
> ssl_bump peek all
> ssl_bump bump all

As Yuri has implied and then tried to explain, the above configuration
is wrong. Please do not use SslBump until you understand why it is
wrong. This understanding may not solve all your existing problems, but
you will probably keep running into new problems if you do not
understand how Squid is supposed to interpret your configuration.

Alex.



From ahmed.zaeem at netstream.ps  Mon Sep 12 20:26:17 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Mon, 12 Sep 2016 23:26:17 +0300
Subject: [squid-users] caching store increase then decrease during
	caching windows updates and all request are TCP_MISS ??!!!
In-Reply-To: <3aea9e0f-f149-f20e-57c6-0a466445e011@treenet.co.nz>
References: <A7F66C74-5126-441D-BB33-F83A2D91892D@netstream.ps>
 <3aea9e0f-f149-f20e-57c6-0a466445e011@treenet.co.nz>
Message-ID: <4D44E232-EFAD-4AC4-9AB8-6C3AC14B2DB1@netstream.ps>

amos thank you so much for reply 


how can i correct the patterns below ?


im not sure if the other patterns are doing the game 

but so far i don?t have disk increasing at all

only  the disk start increase when only i add :
>> refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200 reload-into-ims
>> refresh_pattern ([^.]+.|)(download|adcdownload).(apple.|)com/.*.(pkg|dmg) 4320 100% 43200 reload-into-ins

but  i still don?t have HITs 

im not sure where should i tune ?

i also added stip query terms to off


not sure  what should i do next ??. all i need is windows updates go ok , I?m not interested with other caching 



hope to assist 


cheers 



> On Sep 12, 2016, at 5:13 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 12/09/2016 9:47 p.m., --Ahmad-- wrote:
>> hi 
>> 
>> i have caching store increase then decrease  during caching windows updates and all request are TCP_MISS ??!!!
>> 
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 558M    /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 561M    /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 564M    /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 647M    /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 650M    /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 652M    /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 604M    /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 605M    /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 605M    /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 606M    /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 606M    /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 595M    /var/cache/squid/
>> root at raspberrypi:~# du -sh /var/cache/squid/
>> 
> 
> What relevance is this?
> 
> 
>> 
>> here is sample of logs :
>> 
>> 1473672787.641    444 192.168.0.10 TCP_CLIENT_REFRESH_MISS/200 872 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56? <http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56?> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> 
> HEAD request. None of the object got downloaded.
> 
>> 1473672799.084  11876 192.168.0.10 TCP_MISS/206 615396 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56? <http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56?> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473672808.553   8396 192.168.0.10 TCP_MISS/206 615396 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56? <http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56?> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 1473672811.054  24905 192.168.0.10 TCP_MISS/206 1017331 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/1fc27b6e-d563-415b-b11a-9e7e6f1ad33c? <http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/1fc27b6e-d563-415b-b11a-9e7e6f1ad33c?> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> 
> Some Range requests for URI with ?query parameters. You need to add
> "strip_query_terms no" to your squid.conf. Then you will be able to see
> if these are identical URI or not.
> 
> Right now all that can be said is the script on the server which is
> producing objects is the same one for many of the requests. There is no
> way to know if they are requesting the same object or different ones.
> 
> 
>> 1473672812.922   2687 192.168.0.10 TCP_CLIENT_REFRESH_MISS/206 1049501 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56? <http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/ee82a2cb-f2cf-4cb3-907a-4f5496d2dc56?> - ORIGINAL_DST/13.107.4.50 application/octet-stream
> 
> A request where the client required new content to be fetched.
> 
> The rest of your log shows a lot of repeats of the above things happening.
> 
> 
>> 
>> #refresh_pattern ([^.]+.|)(download|(windows|)update|).(microsoft.|)com/.*.(cab|exe|msi|msp) 4320 100% 43200 reload-into-ims
>> refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200 reload-into-ims
>> refresh_pattern ([^.]+.|)(download|adcdownload).(apple.|)com/.*.(pkg|dmg) 4320 100% 43200 reload-into-ims
> 
> These refresh_pattern contain broken regex patterns.
> 
> 
> 1) Unless you explicitly use start/end anchors regex have implicit .*
> sequences before and after the provided pattern.
> 
> That means "([^.]+.|)" and "([^.]+.)?" are just a very complex (and
> slow to compare) ways to write .*
> 
> 
> 2) '.' is a reserved character. If you want it to match a '.' in the
> domain name you need to write it as \.
> 
> 
> Hint both above regex will match the non-Microsoft, non-Apple URI:
>  http://download.com/?pkg=caddy <http://download.com/?pkg=caddy>
> 
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
> http://lists.squid-cache.org/listinfo/squid-users <http://lists.squid-cache.org/listinfo/squid-users>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160912/85e2c393/attachment.htm>

From squid3 at treenet.co.nz  Tue Sep 13 03:04:42 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 13 Sep 2016 15:04:42 +1200
Subject: [squid-users] caching store increase then decrease during
 caching windows updates and all request are TCP_MISS ??!!!
In-Reply-To: <4D44E232-EFAD-4AC4-9AB8-6C3AC14B2DB1@netstream.ps>
References: <A7F66C74-5126-441D-BB33-F83A2D91892D@netstream.ps>
 <3aea9e0f-f149-f20e-57c6-0a466445e011@treenet.co.nz>
 <4D44E232-EFAD-4AC4-9AB8-6C3AC14B2DB1@netstream.ps>
Message-ID: <5ba94d28-710f-39eb-83a4-d265fa6df96e@treenet.co.nz>

On 13/09/2016 8:26 a.m., --Ahmad-- wrote:
> amos thank you so much for reply 
> 
> 
> how can i correct the patterns below ?
> 

Remove the ([^.]+.)? and ([^.]+.|) parts.

Replace the . where you want to match a '.' with \.


> 
> im not sure if the other patterns are doing the game 
> 
> but so far i don?t have disk increasing at all
> 
> only  the disk start increase when only i add :
>>> refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200 reload-into-ims
>>> refresh_pattern ([^.]+.|)(download|adcdownload).(apple.|)com/.*.(pkg|dmg) 4320 100% 43200 reload-into-ins
> 
> but  i still don?t have HITs 
> 

You have many CLIENT_REFRESH/20x. Which means cached content was found,
but the client required it to be refreshed. When revalidated the server
returned an entire new object.

With the above refresh_rattern, the client may have required the cached
data to be reloaded (Cache-Control:max-age=0) and the reload-into-ims
converted it to a CLIENT_REFRESH from a MISS.


> im not sure where should i tune ?

There is not much you can do when the server returns whole objects in
response to revalidation requests.

The client is requiring that only the latest copy be used, and the
server is insisting that the object has changed.

Since this is an OS update process it is exremely unsafe to make
assumptions yourself about anything being differently cacheable than
what the server is insisting. It is entirely possible that each response
is encrypted and hashed independently - so actually is different.


> 
> i also added stip query terms to off
> 
> 
> not sure  what should i do next ??. all i need is windows updates go ok , I?m not interested with other caching 
> 

With query-terms in the access.log you can better see what requests
should be MISS and which ones have a chance of being HITs (or near-HITs).

Once you can tell which requests actually should be HIT-able you can
then look at the messages going through (in cache.log with debug_options
11,2) for those requests to see what else might be done.

Amos



From squid3 at treenet.co.nz  Tue Sep 13 03:08:11 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 13 Sep 2016 15:08:11 +1200
Subject: [squid-users] Lost of all squid cache
In-Reply-To: <a49cefe7-3a37-63fc-ad40-d69006e7e5a9@gmail.com>
References: <1473699260953-4679466.post@n4.nabble.com>
 <a49cefe7-3a37-63fc-ad40-d69006e7e5a9@gmail.com>
Message-ID: <0f4191e8-9e7e-6b28-16d1-d880bb583d2e@treenet.co.nz>

On 13/09/2016 5:12 a.m., Yuri Voinov wrote:
> 
> Hm.
> 
> As a recovery you can try to rename/remove swap.state from cache_dir's
> and start squid again. AFAIK in this case it re-indexing all exists disk
> cache contents and build new one swap.state file. Also, does all
> permissions to cache_dir and subdirectories recursively is correct and
> intact?

Also, check that the config file cache_dir L1 and L2 parameters are
identical to those which the disk directories were initially created
with. If those are different the file hashes will no longer map to the
directory layout they are sitting in.

Amos


From squid3 at treenet.co.nz  Tue Sep 13 03:54:52 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 13 Sep 2016 15:54:52 +1200
Subject: [squid-users] SSO (ldap kerberos)
In-Reply-To: <1473702058647-4679470.post@n4.nabble.com>
References: <1473702058647-4679470.post@n4.nabble.com>
Message-ID: <6bbebad5-7712-9b39-2510-8fcb7ece641b@treenet.co.nz>

On 13/09/2016 5:40 a.m., erdosain9 wrote:
> HI.
> I want Single Sing on...

"Single Sign-On" is the emergent behaviour of multiple pieces of
software all sharing a single password manager - either to locate user
credentials or to perform the authentication on the software behalf.

The type(s) of authentication that can be peformed is limited only by
your chosen password managers abilities:

* ActiveDirectory only does SSO with NTLM or Negotiate/Kerberos credentials.

* Browser password managers allow any HTTP authentication type (and some
others) to be used.

* operating system "wallets" differ by system. Usually restricting to
TLS certificate authentication, though some allow Kerberos or Basic
credentials to be stored as well.


> i want can take groups to assing acl and control
> bandwith, etc.

What clients can do with your proxy is unrelated to whether they perform
SSO or not.

> I need ldap???

"need" no. Squid provides helpers for LDAP or WinBind group lookup.
Worst case you could write your own (or have someone write it for you)
for other types of lookup.


> i know i need kerberos to sso...

No you don't. see above.

> but is necessary ldap for
> take groups??? or with kerberos i can "take" groups??
> 

What do you mean by "take" ?

In english 'take' is a word meaning movement of something from A to B -
where the things existence in A ceases to exist during the process. (B
takes from A).

Looking at what group an user belongs to does not change that group or
their user name. So it cannot be "taken".


> by the way, 
> i probe this
> 
> basic_ldap_auth -R -b "cn=Users,dc=example,dc=lan" -D
> squid-probe at example.lan -w 123456  -f sAMAccountName=%s -v 3 -s sub -h
> 192.168.1.102
> 
> basic_ldap_auth: WARNING, could not bind to binddn 'Strong(er)
> authentication required'
> 
> Why this???

There are two logins:

1) the user login to the proxy. Used to send an HTTP message through the
proxy.

2) the helper login to AD. Used to verify if the login (1) credentials
are valid.

Your AD requires a different (stronger / more secure) login of type (2)
be used by the helper.

Check the AD settings you have for user "squid-probe at example.lan" with
password "123456". That is the account this Squid helper is using to
access AD.


FWIW, the helper can use TLS connections to AD when the -Z option is
configured. Your AD may be wanting that.


> but anyway, i need ldap for take groups???
> 

Many types of group lookup exist;

For Squid running on Windows natively:
<http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_ad_group_acl>

For Squid receiving Kerberos or NTLM credentials and checking via LDAP:
<http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_kerberos_ldap_group_acl.html>

For Squid receiving Basic credentials and checking via LDAP:
<http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_ldap_group_acl.html>

For Squid receiving LanManager credentials to check against a Windows
NT/2000 domain controller:
<http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_lm_group_acl.html>

For Squid receiving credentials to check against Unix group membership:
<http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_unix_group_acl.html>

For Squid receiving NTLM credentials to check against Samba, AD, or
eDirectory via WinBind service:
<http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_wbinfo_group_acl.html>


> my version of squid is 3.5.20 (on Centos 7)
> AD (samba 4.3.9 on Ubuntu)

Then you want one of ext_ldap_group_acl, ext_kerberos_ldap_group_acl, or
ext_wbinfo_group_acl.

The first of those is most generic, so usually the one to use. But your
specific situation may or may not require one of the others.

Amos




From eliezer at ngtech.co.il  Tue Sep 13 06:02:55 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 13 Sep 2016 09:02:55 +0300
Subject: [squid-users] caching store increase then decrease during
	caching windows updates and all request are TCP_MISS ??!!!
In-Reply-To: <5ba94d28-710f-39eb-83a4-d265fa6df96e@treenet.co.nz>
References: <A7F66C74-5126-441D-BB33-F83A2D91892D@netstream.ps>
 <3aea9e0f-f149-f20e-57c6-0a466445e011@treenet.co.nz>
 <4D44E232-EFAD-4AC4-9AB8-6C3AC14B2DB1@netstream.ps>
 <5ba94d28-710f-39eb-83a4-d265fa6df96e@treenet.co.nz>
Message-ID: <01f701d20d84$78c7cd50$6a5767f0$@ngtech.co.il>

Just as a side note to the server insisting on the full object:
Since we believe and estimate that SHA digests are considered collision safe on the 100+ MB files sizes for the next couple years it is safe to assume(from my point of view on things) that if the whole file was digested with a SHA1 and forward and the full object was found to match this same SHA1 (or other digest) it is safe to be cached.
However I must admit that if these is some communication channel over this url such as in the headers, it would be possible to assume that you cannot cache this content.
With all the above in mind I think that Caching Windows Updates in most cases might not be the right path.
Only if you can provide much  beefier compute and storage resources then the original source it would be smart to cache these.

When an admin will try to cache with a much slower and less performing system then the original one it would be pretty simple to estimate that it will "slow down" things for the clients in many cases.
The practical example I can give is using a 5400RPM spinning disk for a cache which utilizes more then 100 IOPs from disk.

I believe that this should only be used when there are cases which you took anything you can into consideration and consulted any engineer which you should.

All The Bests,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Tuesday, September 13, 2016 6:05 AM
To: --Ahmad--
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] caching store increase then decrease during caching windows updates and all request are TCP_MISS ??!!!

On 13/09/2016 8:26 a.m., --Ahmad-- wrote:
> amos thank you so much for reply 
> 
> 
> how can i correct the patterns below ?
> 

Remove the ([^.]+.)? and ([^.]+.|) parts.

Replace the . where you want to match a '.' with \.


> 
> im not sure if the other patterns are doing the game 
> 
> but so far i don?t have disk increasing at all
> 
> only  the disk start increase when only i add :
>>> refresh_pattern ([^.]+.)?(download|(windows)?update).(microsoft.)?com/.*.(cab|exe|msi|msp|psf) 4320 100% 43200 reload-into-ims
>>> refresh_pattern ([^.]+.|)(download|adcdownload).(apple.|)com/.*.(pkg|dmg) 4320 100% 43200 reload-into-ins
> 
> but  i still don?t have HITs 
> 

You have many CLIENT_REFRESH/20x. Which means cached content was found,
but the client required it to be refreshed. When revalidated the server
returned an entire new object.

With the above refresh_rattern, the client may have required the cached
data to be reloaded (Cache-Control:max-age=0) and the reload-into-ims
converted it to a CLIENT_REFRESH from a MISS.


> im not sure where should i tune ?

There is not much you can do when the server returns whole objects in
response to revalidation requests.

The client is requiring that only the latest copy be used, and the
server is insisting that the object has changed.

Since this is an OS update process it is exremely unsafe to make
assumptions yourself about anything being differently cacheable than
what the server is insisting. It is entirely possible that each response
is encrypted and hashed independently - so actually is different.


> 
> i also added stip query terms to off
> 
> 
> not sure  what should i do next ??. all i need is windows updates go ok , I?m not interested with other caching 
> 

With query-terms in the access.log you can better see what requests
should be MISS and which ones have a chance of being HITs (or near-HITs).

Once you can tell which requests actually should be HIT-able you can
then look at the messages going through (in cache.log with debug_options
11,2) for those requests to see what else might be done.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From omidkosari at yahoo.com  Tue Sep 13 08:32:17 2016
From: omidkosari at yahoo.com (Omid Kosari)
Date: Tue, 13 Sep 2016 01:32:17 -0700 (PDT)
Subject: [squid-users] TProxy and client_dst_passthru
In-Reply-To: <f6cbebb8-3ca6-8d7f-8524-0649a020703c@treenet.co.nz>
References: <5596872A.7050508@treenet.co.nz>
 <1435929702099-4672044.post@n4.nabble.com> <5596A975.2060903@treenet.co.nz>
 <1435936908218-4672048.post@n4.nabble.com> <5596BA9A.9070401@treenet.co.nz>
 <1435996974697-4672054.post@n4.nabble.com>
 <1473330462286-4679422.post@n4.nabble.com>
 <201609081315.20967.Antony.Stone@squid.open.source.it>
 <1473606247560-4679450.post@n4.nabble.com>
 <f6cbebb8-3ca6-8d7f-8524-0649a020703c@treenet.co.nz>
Message-ID: <1473755537175-4679477.post@n4.nabble.com>

Amos Jeffries wrote
> ==> ORIGINAL_DST is should *only* ever be used on MISS or
> REFRESH/revalidate traffic. Never on a HIT. Thus zero (0%) hit-ratio is
> the expected behaviour.
> 
> For the same reason that a report of the log traffic using "grep -v HIT"
> will show zero cache ratio.

I have describe my problem in another thread
http://squid-web-proxy-cache.1019090.n4.nabble.com/range-offset-limit-not-working-as-expected-td4679355.html
. Based on your suggestion , now squid only has one dns server which is same
as users .

I am sure that this url
http://download.cdn.mozilla.net/pub/firefox/releases/48.0.2/update/win32/en-US/firefox-48.0.2.complete.mar
existed and cached . So why there are lots of log lines with ORIGINAL_DST ?





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/TProxy-and-client-dst-passthru-tp4670189p4679477.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From fredbmail at free.fr  Tue Sep 13 11:01:35 2016
From: fredbmail at free.fr (FredB)
Date: Tue, 13 Sep 2016 13:01:35 +0200 (CEST)
Subject: [squid-users] Rock store status
In-Reply-To: <1099544740.855884885.1473668639818.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <2100750397.862159570.1473764495110.JavaMail.root@zimbra4-e1.priv.proxad.net>

One thing, squid restart is very slow because of time required to rebuild the cache

2016/09/13 00:25:34|   Took 1498.42 seconds (3972.24 objects/sec). -> Rock
2016/09/13 00:00:51|   Took 5.71 seconds (533481.90 objects/sec). -> Diskd



From eduardoocarneiro at gmail.com  Tue Sep 13 11:23:11 2016
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Tue, 13 Sep 2016 04:23:11 -0700 (PDT)
Subject: [squid-users] Lost of all squid cache
In-Reply-To: <0f4191e8-9e7e-6b28-16d1-d880bb583d2e@treenet.co.nz>
References: <1473699260953-4679466.post@n4.nabble.com>
 <a49cefe7-3a37-63fc-ad40-d69006e7e5a9@gmail.com>
 <0f4191e8-9e7e-6b28-16d1-d880bb583d2e@treenet.co.nz>
Message-ID: <1473765791681-4679479.post@n4.nabble.com>

Amos Jeffries wrote
> On 13/09/2016 5:12 a.m., Yuri Voinov wrote:
>> 
>> Hm.
>> 
>> As a recovery you can try to rename/remove swap.state from cache_dir's
>> and start squid again. AFAIK in this case it re-indexing all exists disk
>> cache contents and build new one swap.state file. Also, does all
>> permissions to cache_dir and subdirectories recursively is correct and
>> intact?
> 
> Also, check that the config file cache_dir L1 and L2 parameters are
> identical to those which the disk directories were initially created
> with. If those are different the file hashes will no longer map to the
> directory layout they are sitting in.
> 
> Amos
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users

The L1 and L2 parameters are identical Amos. I did not change anything or
the configuration or in the directory.

I tried the solution Yuri mentioned, but it still fails. It took a long time
to rebuild the swap.state, but cache still only 1GB.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Lost-of-all-squid-cache-tp4679466p4679479.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From jorgeley at gmail.com  Tue Sep 13 11:30:51 2016
From: jorgeley at gmail.com (Jorgeley Junior)
Date: Tue, 13 Sep 2016 08:30:51 -0300
Subject: [squid-users] Lost of all squid cache
In-Reply-To: <1473765791681-4679479.post@n4.nabble.com>
References: <1473699260953-4679466.post@n4.nabble.com>
 <a49cefe7-3a37-63fc-ad40-d69006e7e5a9@gmail.com>
 <0f4191e8-9e7e-6b28-16d1-d880bb583d2e@treenet.co.nz>
 <1473765791681-4679479.post@n4.nabble.com>
Message-ID: <CAMeoTHmia5vLfGOPwROGApRskLR=MvJPQwa3t+EkF8VTvt9a+g@mail.gmail.com>

what about cache_swap_low and cache_swap_high???

2016-09-13 8:23 GMT-03:00 Eduardo Carneiro <eduardoocarneiro at gmail.com>:

> Amos Jeffries wrote
> > On 13/09/2016 5:12 a.m., Yuri Voinov wrote:
> >>
> >> Hm.
> >>
> >> As a recovery you can try to rename/remove swap.state from cache_dir's
> >> and start squid again. AFAIK in this case it re-indexing all exists disk
> >> cache contents and build new one swap.state file. Also, does all
> >> permissions to cache_dir and subdirectories recursively is correct and
> >> intact?
> >
> > Also, check that the config file cache_dir L1 and L2 parameters are
> > identical to those which the disk directories were initially created
> > with. If those are different the file hashes will no longer map to the
> > directory layout they are sitting in.
> >
> > Amos
> > _______________________________________________
> > squid-users mailing list
>
> > squid-users at .squid-cache
>
> > http://lists.squid-cache.org/listinfo/squid-users
>
> The L1 and L2 parameters are identical Amos. I did not change anything or
> the configuration or in the directory.
>
> I tried the solution Yuri mentioned, but it still fails. It took a long
> time
> to rebuild the swap.state, but cache still only 1GB.
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.
> 1019090.n4.nabble.com/Lost-of-all-squid-cache-tp4679466p4679479.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



--
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160913/831a9dfe/attachment.htm>

From eduardoocarneiro at gmail.com  Tue Sep 13 11:37:48 2016
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Tue, 13 Sep 2016 04:37:48 -0700 (PDT)
Subject: [squid-users] Lost of all squid cache
In-Reply-To: <CAMeoTHmia5vLfGOPwROGApRskLR=MvJPQwa3t+EkF8VTvt9a+g@mail.gmail.com>
References: <1473699260953-4679466.post@n4.nabble.com>
 <a49cefe7-3a37-63fc-ad40-d69006e7e5a9@gmail.com>
 <0f4191e8-9e7e-6b28-16d1-d880bb583d2e@treenet.co.nz>
 <1473765791681-4679479.post@n4.nabble.com>
 <CAMeoTHmia5vLfGOPwROGApRskLR=MvJPQwa3t+EkF8VTvt9a+g@mail.gmail.com>
Message-ID: <1473766668966-4679481.post@n4.nabble.com>

Jorgeley wrote
> what about cache_swap_low and cache_swap_high???
> 
> 2016-09-13 8:23 GMT-03:00 Eduardo Carneiro &lt;

> eduardoocarneiro@

> &gt;:
> 
>> Amos Jeffries wrote
>> > On 13/09/2016 5:12 a.m., Yuri Voinov wrote:
>> >>
>> >> Hm.
>> >>
>> >> As a recovery you can try to rename/remove swap.state from cache_dir's
>> >> and start squid again. AFAIK in this case it re-indexing all exists
>> disk
>> >> cache contents and build new one swap.state file. Also, does all
>> >> permissions to cache_dir and subdirectories recursively is correct and
>> >> intact?
>> >
>> > Also, check that the config file cache_dir L1 and L2 parameters are
>> > identical to those which the disk directories were initially created
>> > with. If those are different the file hashes will no longer map to the
>> > directory layout they are sitting in.
>> >
>> > Amos
>> > _______________________________________________
>> > squid-users mailing list
>>
>> > squid-users at .squid-cache
>>
>> > http://lists.squid-cache.org/listinfo/squid-users
>>
>> The L1 and L2 parameters are identical Amos. I did not change anything or
>> the configuration or in the directory.
>>
>> I tried the solution Yuri mentioned, but it still fails. It took a long
>> time
>> to rebuild the swap.state, but cache still only 1GB.
>>
>>
>>
>> --
>> View this message in context: http://squid-web-proxy-cache.
>> 1019090.n4.nabble.com/Lost-of-all-squid-cache-tp4679466p4679479.html
>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> _______________________________________________
>> squid-users mailing list
>> 

> squid-users at .squid-cache

>> http://lists.squid-cache.org/listinfo/squid-users
>>
> 
> 
> 
> --
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users

cache_swap_low 90
cache_swap_high 95

When the problem was detected, the cache was only 77% of used disk space.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Lost-of-all-squid-cache-tp4679466p4679481.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Tue Sep 13 14:15:39 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 13 Sep 2016 07:15:39 -0700 (PDT)
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <a0fbb21c-8617-5acc-a2ab-4b695e25296c@measurement-factory.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
 <a0fbb21c-8617-5acc-a2ab-4b695e25296c@measurement-factory.com>
Message-ID: <1473776139024-4679482.post@n4.nabble.com>

Hi.
Sorry but... dont work...

In the chrome i get this

Creating Application Cache with manifest
https://web.whatsapp.com/404.appcache
web.whatsapp.com/:1 Application Cache Checking event
web.whatsapp.com/:1 Application Cache Error event: Manifest fetch failed
(404) https://web.whatsapp.com/404.appcache
app_5163437?.js:6 WebSocket connection to 'wss://w5.web.whatsapp.com/ws'
failed: Error in connection establishment: net::ERR_TIMED_OUT
app_5163437?.js:6 WebSocket connection to 'wss://w6.web.whatsapp.com/ws'
failed: Error in connection establishment: net::ERR_TIMED_OUT
app_5163437?.js:6 WebSocket connection to 'wss://w7.web.whatsapp.com/ws'
failed: Error in connection establishment: net::ERR_TIMED_OUT
app_5163437?.js:6 WebSocket connection to 'wss://w8.web.whatsapp.com/ws'
failed: Error in connection establishment: net::ERR_TIMED_OUT
app_5163437?.js:6 WebSocket connection to 'wss://w1.web.whatsapp.com/ws'
failed: Error in connection establishment: net::ERR_TIMED_OUT

In access.log i get

1473776268.226    198 192.168.1.172 TAG_NONE/200 0 CONNECT
fonts.googleapis.com:443 - HIER_DIRECT/64.233.190.95 -
1473776268.731    132 192.168.1.172 TAG_NONE/200 0 CONNECT
fonts.gstatic.com:443 - HIER_DIRECT/64.233.190.94 -


just that... ??????????
Thanks!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679482.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Tue Sep 13 15:15:53 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 13 Sep 2016 18:15:53 +0300
Subject: [squid-users] Lost of all squid cache
In-Reply-To: <1473699260953-4679466.post@n4.nabble.com>
References: <1473699260953-4679466.post@n4.nabble.com>
Message-ID: <00a601d20dd1$b7e94610$27bbd230$@ngtech.co.il>

Hey Eduardo,

The first thing I would do is to first disable the disk cache in order to try to recover\rebuild the disk cache manually using another squid instance.
It's not always possible but if this cache is important enough then a loss of couple tiny bits for recovery time plus some network load might worth it.
If you are up to manually trying to recover the cache I will try to be here(publically) to see if I can help you.
In the past I wrote a tiny tool that can inspect cache files but I am not sure if I have it here or on another disk remotely.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Eduardo Carneiro
Sent: Monday, September 12, 2016 7:54 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Lost of all squid cache

Hi everyone!

I've got a strange issue on my Squid 3.5.19. 

About 30 minutes ago, my squid stopped and I noticed that the message "Rebuilding storage in /squid/cache/directory (dirty log)" was in my cache.log. Other message was also detected in my cache.log (Store rebuilding is 5.14% complete). When reached 100%, I lost all my 350GB cache data. 

The data are still in the Hard disk, but squid doesn't understand it.

Using squidclient, I can see now only 0.1% of my cache used. For the operating system, all the data are still available. For the squid, not.

Someone can help me that?

Best regards,
Eduardo Carneiro



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Lost-of-all-squid-cache-tp4679466.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From erdosain9 at gmail.com  Tue Sep 13 15:34:36 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 13 Sep 2016 08:34:36 -0700 (PDT)
Subject: [squid-users] SSO (ldap kerberos)
In-Reply-To: <6bbebad5-7712-9b39-2510-8fcb7ece641b@treenet.co.nz>
References: <1473702058647-4679470.post@n4.nabble.com>
 <6bbebad5-7712-9b39-2510-8fcb7ece641b@treenet.co.nz>
Message-ID: <1473780876101-4679484.post@n4.nabble.com>

Hi.
Thanks.
With "take" a mean... to control which group a user belongs. So I can apply
acl, etc to that groups.

Like this in ldap

# Active Directory
auth_param basic program /usr/lib64/squid/basic_ldap_auth -R -b
"cn=Users,dc=example,dc=lan" -D squid at example.lan -w 123456  -f
sAMAccountName=%s -v 3 -s sub -h 192.168.1.109
auth_param basic children 10
auth_param basic realm SQUID
auth_param basic credentialsttl 2 hour

external_acl_type grupos ttl=360 %LOGIN /usr/lib64/squid/ext_ldap_group_acl
-d -R -b "dc=example,dc=lan" -D squid at example.lan -w 123456 -f
"(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%a,ou=grupos,dc=example,dc=lan))"
-h 192.168.1.109


acl ifull  external grupos ifull
acl icontrol external grupos icontrol

But, in this way the web browser ask for user... and i want automatically
take the user that is logging on PC. 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SSO-ldap-kerberos-tp4679470p4679484.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Tue Sep 13 15:54:48 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 14 Sep 2016 03:54:48 +1200
Subject: [squid-users] SSO (ldap kerberos)
In-Reply-To: <1473780876101-4679484.post@n4.nabble.com>
References: <1473702058647-4679470.post@n4.nabble.com>
 <6bbebad5-7712-9b39-2510-8fcb7ece641b@treenet.co.nz>
 <1473780876101-4679484.post@n4.nabble.com>
Message-ID: <ddc7ffa7-9858-710a-b8e0-6848106168bb@treenet.co.nz>

On 14/09/2016 3:34 a.m., erdosain9 wrote:
> Hi.
> Thanks.
> With "take" a mean... to control which group a user belongs. So I can apply
> acl, etc to that groups.
> 
> Like this in ldap
> 
> # Active Directory
> auth_param basic program /usr/lib64/squid/basic_ldap_auth -R -b
> "cn=Users,dc=example,dc=lan" -D squid at example.lan -w 123456  -f
> sAMAccountName=%s -v 3 -s sub -h 192.168.1.109
> auth_param basic children 10
> auth_param basic realm SQUID
> auth_param basic credentialsttl 2 hour
> 
> external_acl_type grupos ttl=360 %LOGIN /usr/lib64/squid/ext_ldap_group_acl
> -d -R -b "dc=example,dc=lan" -D squid at example.lan -w 123456 -f
> "(&(objectclass=person)(sAMAccountName=%v)(memberof=cn=%a,ou=grupos,dc=example,dc=lan))"
> -h 192.168.1.109
> 
> 
> acl ifull  external grupos ifull
> acl icontrol external grupos icontrol
> 
> But, in this way the web browser ask for user... and i want automatically
> take the user that is logging on PC. 

That is a problem between the browser and the OS. Squid and its helpers
only verify what the browser sends them.

There is nothing Squid can do except offering various authentication
schemes in the hope that the browser can get one of those schemes
credentials from the OS.

Amos



From squid3 at treenet.co.nz  Tue Sep 13 15:57:10 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 14 Sep 2016 03:57:10 +1200
Subject: [squid-users] Lost of all squid cache
In-Reply-To: <00a601d20dd1$b7e94610$27bbd230$@ngtech.co.il>
References: <1473699260953-4679466.post@n4.nabble.com>
 <00a601d20dd1$b7e94610$27bbd230$@ngtech.co.il>
Message-ID: <1678d5b9-10d0-dfb7-58d1-f039ab1c1c3d@treenet.co.nz>

On 14/09/2016 3:15 a.m., Eliezer Croitoru wrote:
> Hey Eduardo,
> 
> The first thing I would do is to first disable the disk cache in order to try to recover\rebuild the disk cache manually using another squid instance.
> It's not always possible but if this cache is important enough then a loss of couple tiny bits for recovery time plus some network load might worth it.
> If you are up to manually trying to recover the cache I will try to be here(publically) to see if I can help you.
> In the past I wrote a tiny tool that can inspect cache files but I am not sure if I have it here or on another disk remotely.
> 

Since it is a UFS format cache the squid-purge tool may be of use
inspecting the disk files. Though it may not be up to date with the
latest file format.

Amos



From rousskov at measurement-factory.com  Tue Sep 13 17:24:30 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 13 Sep 2016 11:24:30 -0600
Subject: [squid-users] Rock store status
In-Reply-To: <2100750397.862159570.1473764495110.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <2100750397.862159570.1473764495110.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <ab9de679-f835-5ba9-59fe-87b064304c18@measurement-factory.com>

On 09/13/2016 05:01 AM, FredB wrote:
> One thing, squid restart is very slow because of time required to rebuild the cache
> 
> 2016/09/13 00:25:34|   Took 1498.42 seconds (3972.24 objects/sec). -> Rock
> 2016/09/13 00:00:51|   Took 5.71 seconds (533481.90 objects/sec). -> Diskd

This is a known problem, with several important wrinkles, including:

* Squid start itself is not slow. Cache index build is slow.

* Squid can serve requests, including cache hits while it builds rock
index, but indexing does affect overall Squid performance and hit ratios.

* Avoid comparing loading a "few" ufs entries (from the clean swap
state) with scanning all available cache slots for rock. The biggest
difference is observed for a virtually empty ufs cache that was in use
for a short time (small swap.state). Rock focus is on Squid running for
a long time with a full cache (the common and intended use case).

* We are essentially comparing a from-scratch index build for rock with
a clean index loading for ufs. If you remove all swap state files, ufs
indexing time will probably be worse than that of rock. If you leave
dirty swap state files, then ufs indexing may slow down significantly;
this happens after Squid crashes, for example. Rock indexing does not
depend on the previous Squid state.

* Rock indexing can be optimized in various ways, of course. Many trade
offs are involved, and some optimizations may hurt runtime performance.
For example, there is a trade-off between
    - maintaining a disk index (i.e., swap state files) at runtime
     (and then saving a clean index at shutdown) like UFS stores do and
    - building an index from scratch by scanning the entire cache at
      start like rock stores do.


This is now documented at

http://wiki.squid-cache.org/Features/LargeRockStore#Slow_cache_index_build


HTH,

Alex.



From eliezer at ngtech.co.il  Tue Sep 13 17:34:46 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 13 Sep 2016 20:34:46 +0300
Subject: [squid-users] Lost of all squid cache
In-Reply-To: <1678d5b9-10d0-dfb7-58d1-f039ab1c1c3d@treenet.co.nz>
References: <1473699260953-4679466.post@n4.nabble.com>
 <00a601d20dd1$b7e94610$27bbd230$@ngtech.co.il>
 <1678d5b9-10d0-dfb7-58d1-f039ab1c1c3d@treenet.co.nz>
Message-ID: <014501d20de5$1efc2a80$5cf47f80$@ngtech.co.il>

Amos,

I found my old code at:
http://ngtech.co.il/paste/1012/

I will try to verify this week if it's compatible with 3.5 and 4.0 ufs\aufs cache_dir.

Eliezer 

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Tuesday, September 13, 2016 6:57 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Lost of all squid cache

On 14/09/2016 3:15 a.m., Eliezer Croitoru wrote:
> Hey Eduardo,
> 
> The first thing I would do is to first disable the disk cache in order to try to recover\rebuild the disk cache manually using another squid instance.
> It's not always possible but if this cache is important enough then a loss of couple tiny bits for recovery time plus some network load might worth it.
> If you are up to manually trying to recover the cache I will try to be here(publically) to see if I can help you.
> In the past I wrote a tiny tool that can inspect cache files but I am not sure if I have it here or on another disk remotely.
> 

Since it is a UFS format cache the squid-purge tool may be of use inspecting the disk files. Though it may not be up to date with the latest file format.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From chicocvenancio at gmail.com  Tue Sep 13 18:34:16 2016
From: chicocvenancio at gmail.com (Chico Venancio)
Date: Tue, 13 Sep 2016 15:34:16 -0300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1473776139024-4679482.post@n4.nabble.com>
References: <1472735533311-4679299.post@n4.nabble.com>
 <ce3d6fe5-ef94-fb16-dcd9-bcba7cbfda71@gmail.com>
 <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
 <a0fbb21c-8617-5acc-a2ab-4b695e25296c@measurement-factory.com>
 <1473776139024-4679482.post@n4.nabble.com>
Message-ID: <CAEpx-0X=HJWO2BVhR-NZMu-oc5R631+FxAgDov6EAhs45qaNaQ@mail.gmail.com>

Is this intercept proxy?

Chico Venancio

2016-09-13 11:15 GMT-03:00 erdosain9 <erdosain9 at gmail.com>:

> Hi.
> Sorry but... dont work...
>
> In the chrome i get this
>
> Creating Application Cache with manifest
> https://web.whatsapp.com/404.appcache
> web.whatsapp.com/:1 Application Cache Checking event
> web.whatsapp.com/:1 Application Cache Error event: Manifest fetch failed
> (404) https://web.whatsapp.com/404.appcache
> app_5163437?.js:6 WebSocket connection to 'wss://w5.web.whatsapp.com/ws'
> failed: Error in connection establishment: net::ERR_TIMED_OUT
> app_5163437?.js:6 WebSocket connection to 'wss://w6.web.whatsapp.com/ws'
> failed: Error in connection establishment: net::ERR_TIMED_OUT
> app_5163437?.js:6 WebSocket connection to 'wss://w7.web.whatsapp.com/ws'
> failed: Error in connection establishment: net::ERR_TIMED_OUT
> app_5163437?.js:6 WebSocket connection to 'wss://w8.web.whatsapp.com/ws'
> failed: Error in connection establishment: net::ERR_TIMED_OUT
> app_5163437?.js:6 WebSocket connection to 'wss://w1.web.whatsapp.com/ws'
> failed: Error in connection establishment: net::ERR_TIMED_OUT
>
> In access.log i get
>
> 1473776268.226    198 192.168.1.172 TAG_NONE/200 0 CONNECT
> fonts.googleapis.com:443 - HIER_DIRECT/64.233.190.95 -
> 1473776268.731    132 192.168.1.172 TAG_NONE/200 0 CONNECT
> fonts.gstatic.com:443 - HIER_DIRECT/64.233.190.94 -
>
>
> just that... ??????????
> Thanks!
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.
> 1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679482.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160913/adec036a/attachment.htm>

From erdosain9 at gmail.com  Tue Sep 13 18:33:19 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 13 Sep 2016 11:33:19 -0700 (PDT)
Subject: [squid-users] SSO (ldap kerberos)
In-Reply-To: <ddc7ffa7-9858-710a-b8e0-6848106168bb@treenet.co.nz>
References: <1473702058647-4679470.post@n4.nabble.com>
 <6bbebad5-7712-9b39-2510-8fcb7ece641b@treenet.co.nz>
 <1473780876101-4679484.post@n4.nabble.com>
 <ddc7ffa7-9858-710a-b8e0-6848106168bb@treenet.co.nz>
Message-ID: <1473791599383-4679490.post@n4.nabble.com>

Hi again.


I get this

msktutil --auto-update --verbose --computer-name squid-k -k PROXY.keytab 
 -- init_password: Wiping the computer password structure
 -- generate_new_password: Generating a new, random password for the
computer account
 -- generate_new_password:  Characters read from /dev/udandom = 95
 -- get_dc_host: Attempting to find a Domain Controller to use (DNS SRV RR
TCP)
 -- get_dc_host: Found DC: ads-01.example.lan
 -- get_dc_host: Canonicalizing DC through forward/reverse lookup...
 -- get_dc_host: Found Domain Controller: ads-01.example.lan
 -- create_fake_krb5_conf: Created a fake krb5.conf file:
/tmp/.msktkrb5.conf-L8DxV8
 -- reload: Reloading Kerberos Context
 -- finalize_exec: SAM Account Name is: squid-k$
 -- try_machine_keytab_princ: Trying to authenticate for squid-k$ from local
keytab...
 -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed
(Preauthentication failed)
 -- try_machine_keytab_princ: Authentication with keytab failed
 -- try_machine_keytab_princ: Trying to authenticate for
host/squid.example.lan from local keytab...
 -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed
(Client not found in Kerberos database)
 -- try_machine_keytab_princ: Authentication with keytab failed
 -- try_machine_password: Trying to authenticate for squid-k$ with password.
 -- create_default_machine_password: Default machine password for squid-k$
is squid-k
 -- try_machine_password: Error: krb5_get_init_creds_keytab failed
(Preauthentication failed)
 -- try_machine_password: Authentication with password failed
 -- try_user_creds: Checking if default ticket cache has tickets...
 -- finalize_exec: Authenticated using method 4

 -- ldap_connect: Connecting to LDAP server: ads-01.example.lan try_tls=YES
 -- ldap_connect: Connecting to LDAP server: ads-01.example.lan try_tls=NO
SASL/GSSAPI authentication started
SASL username: administrator at example.LAN
SASL SSF: 56
SASL data security layer installed.
 -- ldap_connect: LDAP_OPT_X_SASL_SSF=56

 -- ldap_get_base_dn: Determining default LDAP base: dc=example,dc=LAN
 -- get_default_ou: Determining default OU: CN=Computers,DC=example,DC=lan
 -- ldap_check_account: Checking that a computer account for squid-k$ exists
 -- ldap_check_account: Checking computer account - found
 -- ldap_check_account: Found userAccountControl = 0x1000

 -- ldap_check_account: Found supportedEncryptionTypes = 28

 -- ldap_check_account: Found dNSHostName = squid.example.lan

 -- ldap_check_account:   Found Principal: HTTP/squid.example.lan
 -- ldap_check_account:   Found Principal: host/squid.example.lan
 -- ldap_check_account:   Found User Principal: HTTP/squid.example.lan
 -- ldap_check_account_strings: Inspecting (and updating) computer account
attributes
 -- ldap_set_supportedEncryptionTypes: No need to change
msDs-supportedEncryptionTypes they are 28

 -- ldap_set_userAccountControl_flag: Setting userAccountControl bit at
0x200000 to 0x0
 -- ldap_set_userAccountControl_flag:  userAccountControl not changed 0x1000

 -- set_password: Attempting to reset computer's password
 -- set_password: Try change password using user's ticket cache

 -- ldap_get_pwdLastSet: pwdLastSet is 131182651460000000
 -- set_password: Successfully set password, waiting for it to be reflected
in LDAP.
 -- ldap_get_pwdLastSet: pwdLastSet is 131182651580000000
 -- set_password: Successfully reset computer's password
 -- execute: Updating all entries for squid.example.lan in the keytab
WRFILE:PROXY.keytab

 -- update_keytab: Updating all entires for squid-k$
 -- ldap_get_kvno: KVNO is 4
 -- add_principal_keytab: Adding principal to keytab: squid-k$
 -- add_principal_keytab: Removing entries with kvno < 0
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x17
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x11
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x12
 -- add_principal_keytab: Adding principal to keytab: HTTP/squid.example.lan
 -- add_principal_keytab: Removing entries with kvno < 0
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x17
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x11
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x12
 -- add_principal_keytab: Adding principal to keytab: host/squid.example.lan
 -- add_principal_keytab: Removing entries with kvno < 0
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x17
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x11
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x12
 -- ~msktutil_exec: Destroying msktutil_exec
 -- ldap_cleanup: Disconnecting from LDAP server
 -- init_password: Wiping the computer password structure
 -- ~KRB5Context: Destroying Kerberos Context


Why?? 
I am following this
http://wiki.squid-cache.org/ConfigExamples/Authenticate/WindowsActiveDirectory
............




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SSO-ldap-kerberos-tp4679470p4679490.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Tommy.Craddock at bicgraphic.com  Tue Sep 13 18:55:46 2016
From: Tommy.Craddock at bicgraphic.com (Craddock, Tommy)
Date: Tue, 13 Sep 2016 18:55:46 +0000
Subject: [squid-users] SSO (ldap kerberos)
In-Reply-To: <1473791599383-4679490.post@n4.nabble.com>
References: <1473702058647-4679470.post@n4.nabble.com>
 <6bbebad5-7712-9b39-2510-8fcb7ece641b@treenet.co.nz>
 <1473780876101-4679484.post@n4.nabble.com>
 <ddc7ffa7-9858-710a-b8e0-6848106168bb@treenet.co.nz>
 <1473791599383-4679490.post@n4.nabble.com>
Message-ID: <CA86A9283AA07E478F6B0629521FFEE73FC133@CLWSEXCMBX02.na.bicworld.com>


Hello, 

You get that because that is what happens when you update a keytab using the msktutil program. 
?
Tommy E CRADDOCK JR

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Tuesday, September 13, 2016 2:33 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] SSO (ldap kerberos)

Hi again.


I get this

msktutil --auto-update --verbose --computer-name squid-k -k PROXY.keytab
 -- init_password: Wiping the computer password structure
 -- generate_new_password: Generating a new, random password for the computer account
 -- generate_new_password:  Characters read from /dev/udandom = 95
 -- get_dc_host: Attempting to find a Domain Controller to use (DNS SRV RR
TCP)
 -- get_dc_host: Found DC: ads-01.example.lan
 -- get_dc_host: Canonicalizing DC through forward/reverse lookup...
 -- get_dc_host: Found Domain Controller: ads-01.example.lan
 -- create_fake_krb5_conf: Created a fake krb5.conf file:
/tmp/.msktkrb5.conf-L8DxV8
 -- reload: Reloading Kerberos Context
 -- finalize_exec: SAM Account Name is: squid-k$
 -- try_machine_keytab_princ: Trying to authenticate for squid-k$ from local keytab...
 -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed (Preauthentication failed)
 -- try_machine_keytab_princ: Authentication with keytab failed
 -- try_machine_keytab_princ: Trying to authenticate for host/squid.example.lan from local keytab...
 -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed (Client not found in Kerberos database)
 -- try_machine_keytab_princ: Authentication with keytab failed
 -- try_machine_password: Trying to authenticate for squid-k$ with password.
 -- create_default_machine_password: Default machine password for squid-k$ is squid-k
 -- try_machine_password: Error: krb5_get_init_creds_keytab failed (Preauthentication failed)
 -- try_machine_password: Authentication with password failed
 -- try_user_creds: Checking if default ticket cache has tickets...
 -- finalize_exec: Authenticated using method 4

 -- ldap_connect: Connecting to LDAP server: ads-01.example.lan try_tls=YES
 -- ldap_connect: Connecting to LDAP server: ads-01.example.lan try_tls=NO SASL/GSSAPI authentication started SASL username: administrator at example.LAN SASL SSF: 56 SASL data security layer installed.
 -- ldap_connect: LDAP_OPT_X_SASL_SSF=56

 -- ldap_get_base_dn: Determining default LDAP base: dc=example,dc=LAN
 -- get_default_ou: Determining default OU: CN=Computers,DC=example,DC=lan
 -- ldap_check_account: Checking that a computer account for squid-k$ exists
 -- ldap_check_account: Checking computer account - found
 -- ldap_check_account: Found userAccountControl = 0x1000

 -- ldap_check_account: Found supportedEncryptionTypes = 28

 -- ldap_check_account: Found dNSHostName = squid.example.lan

 -- ldap_check_account:   Found Principal: HTTP/squid.example.lan
 -- ldap_check_account:   Found Principal: host/squid.example.lan
 -- ldap_check_account:   Found User Principal: HTTP/squid.example.lan
 -- ldap_check_account_strings: Inspecting (and updating) computer account attributes
 -- ldap_set_supportedEncryptionTypes: No need to change msDs-supportedEncryptionTypes they are 28

 -- ldap_set_userAccountControl_flag: Setting userAccountControl bit at
0x200000 to 0x0
 -- ldap_set_userAccountControl_flag:  userAccountControl not changed 0x1000

 -- set_password: Attempting to reset computer's password
 -- set_password: Try change password using user's ticket cache

 -- ldap_get_pwdLastSet: pwdLastSet is 131182651460000000
 -- set_password: Successfully set password, waiting for it to be reflected in LDAP.
 -- ldap_get_pwdLastSet: pwdLastSet is 131182651580000000
 -- set_password: Successfully reset computer's password
 -- execute: Updating all entries for squid.example.lan in the keytab WRFILE:PROXY.keytab

 -- update_keytab: Updating all entires for squid-k$
 -- ldap_get_kvno: KVNO is 4
 -- add_principal_keytab: Adding principal to keytab: squid-k$
 -- add_principal_keytab: Removing entries with kvno < 0
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x17
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x11
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x12
 -- add_principal_keytab: Adding principal to keytab: HTTP/squid.example.lan
 -- add_principal_keytab: Removing entries with kvno < 0
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x17
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x11
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x12
 -- add_principal_keytab: Adding principal to keytab: host/squid.example.lan
 -- add_principal_keytab: Removing entries with kvno < 0
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x17
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x11
 -- add_principal_keytab:     Using salt of
example.LANhostsquid-k.example.lan
 -- add_principal_keytab:   Adding entry of enctype 0x12
 -- ~msktutil_exec: Destroying msktutil_exec
 -- ldap_cleanup: Disconnecting from LDAP server
 -- init_password: Wiping the computer password structure
 -- ~KRB5Context: Destroying Kerberos Context


Why?? 
I am following this
http://wiki.squid-cache.org/ConfigExamples/Authenticate/WindowsActiveDirectory
............




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SSO-ldap-kerberos-tp4679470p4679490.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________

From eliezer at ngtech.co.il  Tue Sep 13 19:44:38 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 13 Sep 2016 22:44:38 +0300
Subject: [squid-users] Lost of all squid cache
In-Reply-To: <1473766668966-4679481.post@n4.nabble.com>
References: <1473699260953-4679466.post@n4.nabble.com>
 <a49cefe7-3a37-63fc-ad40-d69006e7e5a9@gmail.com>
 <0f4191e8-9e7e-6b28-16d1-d880bb583d2e@treenet.co.nz>
 <1473765791681-4679479.post@n4.nabble.com>
 <CAMeoTHmia5vLfGOPwROGApRskLR=MvJPQwa3t+EkF8VTvt9a+g@mail.gmail.com>
 <1473766668966-4679481.post@n4.nabble.com>
Message-ID: <020701d20df7$437dd950$ca798bf0$@ngtech.co.il>

Hey Eduardo,

I replayed the script on my testing lab and it seems to fir 3.5 and 4.0.
The next script will receive a filename and will try to read it.
As long as the file is in a good shape it will print the URL of the original request.
The ruby script at: http://paste.ngtech.co.il/pul2zg62a
This script is written in ruby and uses the "bindata" gem(library) depends on your OS it will be pretty simple to install.
Once you will be able to run the above script on a single file we can move on to verify each and every one of the files in the cache_dir.

But first comment the "cache_dir" line from squid so your squid will not touch anything while you will be trying to verify the status of the files.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Eduardo Carneiro
Sent: Tuesday, September 13, 2016 2:38 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Lost of all squid cache

Jorgeley wrote
> what about cache_swap_low and cache_swap_high???
> 
> 2016-09-13 8:23 GMT-03:00 Eduardo Carneiro &lt;

> eduardoocarneiro@

> &gt;:
> 
>> Amos Jeffries wrote
>> > On 13/09/2016 5:12 a.m., Yuri Voinov wrote:
>> >>
>> >> Hm.
>> >>
>> >> As a recovery you can try to rename/remove swap.state from cache_dir's
>> >> and start squid again. AFAIK in this case it re-indexing all exists
>> disk
>> >> cache contents and build new one swap.state file. Also, does all
>> >> permissions to cache_dir and subdirectories recursively is correct and
>> >> intact?
>> >
>> > Also, check that the config file cache_dir L1 and L2 parameters are
>> > identical to those which the disk directories were initially created
>> > with. If those are different the file hashes will no longer map to the
>> > directory layout they are sitting in.
>> >
>> > Amos
>> > _______________________________________________
>> > squid-users mailing list
>>
>> > squid-users at .squid-cache
>>
>> > http://lists.squid-cache.org/listinfo/squid-users
>>
>> The L1 and L2 parameters are identical Amos. I did not change anything or
>> the configuration or in the directory.
>>
>> I tried the solution Yuri mentioned, but it still fails. It took a long
>> time
>> to rebuild the swap.state, but cache still only 1GB.
>>
>>
>>
>> --
>> View this message in context: http://squid-web-proxy-cache.
>> 1019090.n4.nabble.com/Lost-of-all-squid-cache-tp4679466p4679479.html
>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> _______________________________________________
>> squid-users mailing list
>> 

> squid-users at .squid-cache

>> http://lists.squid-cache.org/listinfo/squid-users
>>
> 
> 
> 
> --
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users

cache_swap_low 90
cache_swap_high 95

When the problem was detected, the cache was only 77% of used disk space.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Lost-of-all-squid-cache-tp4679466p4679481.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From erdosain9 at gmail.com  Tue Sep 13 19:59:13 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 13 Sep 2016 12:59:13 -0700 (PDT)
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <CAEpx-0X=HJWO2BVhR-NZMu-oc5R631+FxAgDov6EAhs45qaNaQ@mail.gmail.com>
References: <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
 <a0fbb21c-8617-5acc-a2ab-4b695e25296c@measurement-factory.com>
 <1473776139024-4679482.post@n4.nabble.com>
 <CAEpx-0X=HJWO2BVhR-NZMu-oc5R631+FxAgDov6EAhs45qaNaQ@mail.gmail.com>
Message-ID: <1473796753468-4679493.post@n4.nabble.com>

Hi,
No. is explicit.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679493.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chicocvenancio at gmail.com  Tue Sep 13 20:38:31 2016
From: chicocvenancio at gmail.com (Chico Venancio)
Date: Tue, 13 Sep 2016 17:38:31 -0300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1473796753468-4679493.post@n4.nabble.com>
References: <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
 <a0fbb21c-8617-5acc-a2ab-4b695e25296c@measurement-factory.com>
 <1473776139024-4679482.post@n4.nabble.com>
 <CAEpx-0X=HJWO2BVhR-NZMu-oc5R631+FxAgDov6EAhs45qaNaQ@mail.gmail.com>
 <1473796753468-4679493.post@n4.nabble.com>
Message-ID: <CAEpx-0X8QP6WELguYtkaQ_TJwQKo5qrXS_y60J9VUPi0ygB1cw@mail.gmail.com>

We need more of access log.
There is at least connect attempts at w1.web.whatsapp.com not shown.

Chico Venancio

Em 13/09/2016 17:03, "erdosain9" <erdosain9 at gmail.com> escreveu:
>
> Hi,
> No. is explicit.
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679493.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Chico Venancio
CEO e Diretor de Cria??o
VM TECH - (98)8800-2743
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160913/72800933/attachment.htm>

From yvoinov at gmail.com  Tue Sep 13 20:40:06 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 14 Sep 2016 02:40:06 +0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <CAEpx-0X8QP6WELguYtkaQ_TJwQKo5qrXS_y60J9VUPi0ygB1cw@mail.gmail.com>
References: <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
 <a0fbb21c-8617-5acc-a2ab-4b695e25296c@measurement-factory.com>
 <1473776139024-4679482.post@n4.nabble.com>
 <CAEpx-0X=HJWO2BVhR-NZMu-oc5R631+FxAgDov6EAhs45qaNaQ@mail.gmail.com>
 <1473796753468-4679493.post@n4.nabble.com>
 <CAEpx-0X8QP6WELguYtkaQ_TJwQKo5qrXS_y60J9VUPi0ygB1cw@mail.gmail.com>
Message-ID: <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Wait.

Does anybody see WebSockets connections to web.whatsapp.com?


14.09.2016 2:38, Chico Venancio ?????:
>
> We need more of access log.
> There is at least connect attempts at w1.web.whatsapp.com
<http://w1.web.whatsapp.com> not shown.
>
> Chico Venancio
>
> Em 13/09/2016 17:03, "erdosain9" <erdosain9 at gmail.com
<mailto:erdosain9 at gmail.com>> escreveu:
> >
> > Hi,
> > No. is explicit.
> >
> >
> >
> > --
> > View this message in
context:http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679493.html
<http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679493.html>
> > Sent from the Squid - Users mailing list archive at Nabble.com.
> > _______________________________________________
> > squid-users mailing list
> >squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
> >http://lists.squid-cache.org/listinfo/squid-users
<http://lists.squid-cache.org/listinfo/squid-users>
>
> Chico Venancio
> CEO e Diretor de Cria??o
> VM TECH - (98)8800-2743
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX2GQmAAoJENNXIZxhPexG9CMH/368uq1R7qpnXtP6rKB80sFs
WBvPHwfSX1U4EAUpHuZK3bPNQXki/9xzX0D/kvbUiDGf3lu9NqYjNEFpv3lqGC2B
61euZ5XjYbUXpOa3tysIrchl0tC2J5dLNTkK5cAaEABG328YxY2Yil9UqQyf2GEj
Cwr3vpJlOMQpDlnDNjHlMvsv+scrSEiZ5CVmoj41qoYGw1S+2mym9+pxwlhRxNrd
9i+8Dnjj1DmMsq2IKNc/DdRciNaYIuXQAEdn8bdcoTkLWffj7KHqCCyjMFxys9F3
RJ6vS9v1kdqLEiK2LAdVyMMylaiRWZh6Nt7ZBkYSjPCJix+hPREUPIDiF9qPM10=
=tg++
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160914/ad875587/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160914/ad875587/attachment.key>

From chicocvenancio at gmail.com  Tue Sep 13 21:03:10 2016
From: chicocvenancio at gmail.com (Chico Venancio)
Date: Tue, 13 Sep 2016 18:03:10 -0300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
References: <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
 <a0fbb21c-8617-5acc-a2ab-4b695e25296c@measurement-factory.com>
 <1473776139024-4679482.post@n4.nabble.com>
 <CAEpx-0X=HJWO2BVhR-NZMu-oc5R631+FxAgDov6EAhs45qaNaQ@mail.gmail.com>
 <1473796753468-4679493.post@n4.nabble.com>
 <CAEpx-0X8QP6WELguYtkaQ_TJwQKo5qrXS_y60J9VUPi0ygB1cw@mail.gmail.com>
 <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
Message-ID: <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>

You mean the connect requests to the websockets on w[0-9].web.whatsapp.com
?

1473800440.053  16932 192.168.10.128 TCP_TUNNEL/200 3639 CONNECT
w7.web.whatsapp.com:443 - HIER_DIRECT/169.55.69.156 -


Chico Venancio

2016-09-13 17:40 GMT-03:00 Yuri Voinov <yvoinov at gmail.com>:

>
> -----BEGIN PGP SIGNED MESSAGE-----
> Hash: SHA256
>
> Wait.
>
> Does anybody see WebSockets connections to web.whatsapp.com?
>
>
> 14.09.2016 2:38, Chico Venancio ?????:
> >
> > We need more of access log.
> > There is at least connect attempts at w1.web.whatsapp.com
> <http://w1.web.whatsapp.com> <http://w1.web.whatsapp.com> not shown.
> >
> > Chico Venancio
> >
> > Em 13/09/2016 17:03, "erdosain9" <erdosain9 at gmail.com
> <mailto:erdosain9 at gmail.com> <erdosain9 at gmail.com>> escreveu:
> > >
> > > Hi,
> > > No. is explicit.
> > >
> > >
> > >
> > > --
> > > View this message in context:http://squid-web-
> proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-
> problem-tp4679299p4679493.html <http://squid-web-proxy-cache.
> 1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679493.html>
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679493.html>
> > > Sent from the Squid - Users mailing list archive at Nabble.com.
> > > _______________________________________________
> > > squid-users mailing list
> > >squid-users at lists.squid-cache.org <mailto:squid-users at lists.
> squid-cache.org> <squid-users at lists.squid-cache.org>
> > >http://lists.squid-cache.org/listinfo/squid-users
> <http://lists.squid-cache.org/listinfo/squid-users>
> <http://lists.squid-cache.org/listinfo/squid-users>
> >
> > Chico Venancio
> > CEO e Diretor de Cria??o
> > VM TECH - (98)8800-2743
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
> -----BEGIN PGP SIGNATURE-----
> Version: GnuPG v2
>
> iQEcBAEBCAAGBQJX2GQmAAoJENNXIZxhPexG9CMH/368uq1R7qpnXtP6rKB80sFs
> WBvPHwfSX1U4EAUpHuZK3bPNQXki/9xzX0D/kvbUiDGf3lu9NqYjNEFpv3lqGC2B
> 61euZ5XjYbUXpOa3tysIrchl0tC2J5dLNTkK5cAaEABG328YxY2Yil9UqQyf2GEj
> Cwr3vpJlOMQpDlnDNjHlMvsv+scrSEiZ5CVmoj41qoYGw1S+2mym9+pxwlhRxNrd
> 9i+8Dnjj1DmMsq2IKNc/DdRciNaYIuXQAEdn8bdcoTkLWffj7KHqCCyjMFxys9F3
> RJ6vS9v1kdqLEiK2LAdVyMMylaiRWZh6Nt7ZBkYSjPCJix+hPREUPIDiF9qPM10=
> =tg++
> -----END PGP SIGNATURE-----
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160913/47033913/attachment.htm>

From yvoinov at gmail.com  Tue Sep 13 21:12:23 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 14 Sep 2016 03:12:23 +0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>
References: <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
 <a0fbb21c-8617-5acc-a2ab-4b695e25296c@measurement-factory.com>
 <1473776139024-4679482.post@n4.nabble.com>
 <CAEpx-0X=HJWO2BVhR-NZMu-oc5R631+FxAgDov6EAhs45qaNaQ@mail.gmail.com>
 <1473796753468-4679493.post@n4.nabble.com>
 <CAEpx-0X8QP6WELguYtkaQ_TJwQKo5qrXS_y60J9VUPi0ygB1cw@mail.gmail.com>
 <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
 <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>
Message-ID: <6e65eafe-37aa-e6f2-9c04-e4e14b9ff3e9@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Ah,

my mistake. This is simple tunnel.

14.09.2016 3:03, Chico Venancio ?????:
> You mean the connect requests to the websockets on w[0-9].web.whatsapp.com <http://web.whatsapp.com> ?
>
> 1473800440.053  16932 192.168.10.128 TCP_TUNNEL/200 3639 CONNECT
w7.web.whatsapp.com:443 <http://w7.web.whatsapp.com:443> -
HIER_DIRECT/169.55.69.156 <http://169.55.69.156> -
>
>
> Chico Venancio
>
> 2016-09-13 17:40 GMT-03:00 Yuri Voinov <yvoinov at gmail.com
<mailto:yvoinov at gmail.com>>:
>
>
> Wait.
>
> Does anybody see WebSockets connections to web.whatsapp.com
<http://web.whatsapp.com>?
>
>
> 14.09.2016 2:38, Chico Venancio ?????:
>
>
>       > We need more of access log.
>
>       > There is at least connect attempts at w1.web.whatsapp.com
<http://w1.web.whatsapp.com>
>       <http://w1.web.whatsapp.com> <http://w1.web.whatsapp.com> not shown.
>
>
>
>       > Chico Venancio
>
>
>
>       > Em 13/09/2016 17:03, "erdosain9" <erdosain9 at gmail.com
<mailto:erdosain9 at gmail.com>
>       <mailto:erdosain9 at gmail.com> <mailto:erdosain9 at gmail.com>> escreveu:
>
>       > >
>
>       > > Hi,
>
>       > > No. is explicit.
>
>       > >
>
>       > >
>
>       > >
>
>       > > --
>
>       > > View this message in
>
context:http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679493.html
<http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679493.html>
>
<http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679493.html>
<http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679493.html>
>
>       > > Sent from the Squid - Users mailing list archive at
>       Nabble.com.
>
>       > > _______________________________________________
>
>       > > squid-users mailing list
>
>       > >squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>       <mailto:squid-users at lists.squid-cache.org>
<mailto:squid-users at lists.squid-cache.org>
>
>       > >http://lists.squid-cache.org/listinfo/squid-users
<http://lists.squid-cache.org/listinfo/squid-users>
>       <http://lists.squid-cache.org/listinfo/squid-users>
<http://lists.squid-cache.org/listinfo/squid-users>
>
>
>
>       > Chico Venancio
>
>       > CEO e Diretor de Cria??o
>
>       > VM TECH - (98)8800-2743 <tel:%2898%298800-2743>
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
<http://lists.squid-cache.org/listinfo/squid-users>
>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
<http://lists.squid-cache.org/listinfo/squid-users>
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX2Gu3AAoJENNXIZxhPexGJnMIAJXwR3ni9uos/PJo/8/YfKZ5
/90dhZ/W5Fm2bImnbn32NR1gZXl4E7TXWE+B2SRwyc4DdFqzuyNdMCGYe1jAKKrs
8DKEA1Z1wOof+gTWB0/LRl2OpmHPbTFuxzbQEj5noFYCblQZq86a1Ucc3mh5LQUR
bBSBe5VZi35XOIFW0ZSdeX5eJtR23lSnS9Sq/rV129pY18M/BtZ4FvRUm2Pc9FN2
4l2PZW1/xxYK02L7ucd2rT0d50wyRAiPOlGP2Ot7rzdjrCaeyaFBLDaJopEaXTwn
5CyVDS0Nu+cuZW8Wx3gSO3mEFGqpXu4NiQ6HXPQBRT5pJgNg2zezT9lk/diyhqA=
=GvIy
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160914/1a536287/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160914/1a536287/attachment.key>

From chicocvenancio at gmail.com  Tue Sep 13 21:14:57 2016
From: chicocvenancio at gmail.com (Chico Venancio)
Date: Tue, 13 Sep 2016 18:14:57 -0300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <6e65eafe-37aa-e6f2-9c04-e4e14b9ff3e9@gmail.com>
References: <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
 <a0fbb21c-8617-5acc-a2ab-4b695e25296c@measurement-factory.com>
 <1473776139024-4679482.post@n4.nabble.com>
 <CAEpx-0X=HJWO2BVhR-NZMu-oc5R631+FxAgDov6EAhs45qaNaQ@mail.gmail.com>
 <1473796753468-4679493.post@n4.nabble.com>
 <CAEpx-0X8QP6WELguYtkaQ_TJwQKo5qrXS_y60J9VUPi0ygB1cw@mail.gmail.com>
 <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
 <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>
 <6e65eafe-37aa-e6f2-9c04-e4e14b9ff3e9@gmail.com>
Message-ID: <CAEpx-0WMruHcZBP=kpZO1+C4YnELpeYGy2=WYtKMY5zmTWuaBg@mail.gmail.com>

Not really,
As I understand it it is a websocket, that when proxied starts its
handshake with a connect request so it can be "understood" by proxies such
as squid.


Chico Venancio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160913/2e71bba3/attachment.htm>

From squid-users at filter.luko.org  Wed Sep 14 00:18:01 2016
From: squid-users at filter.luko.org (squid-users at filter.luko.org)
Date: Wed, 14 Sep 2016 10:18:01 +1000
Subject: [squid-users] Introducing delay to HTTP 407 responses
Message-ID: <000301d20e1d$7476f840$5d64e8c0$@filter.luko.org>

Hi Squid users,

Seeking advice on how to slow down 407 responses to broken Apple & MS
clients, which seem to retry at very short intervals and quickly fill the
access.log with garbage.  The problem is very similar to this:

http://www.squid-cache.org/mail-archive/squid-users/201404/0326.html

However the config below doesn't seem to slow down the response:

acl delaydomains dstdomain .live.net .apple.com
acl authresponse http_status 407
external_acl_type delay ttl=0 negative_ttl=0 cache=0 %SRC /tmp/delay.pl
acl delay external delay
http_reply_access deny delaydomains authresponse delay
http_reply_access allow all

The helper is never asked by Squid to process the request.  Just wondering
if http_status ACLs can be used in http_reply_access?

My other thinking, if this isn't possible, was to mark 407 responses with
clientside_tos so they could be delayed/throttled with tc or iptables.  Ie,

acl authresponse http_status 407
clientside_tos 0x20 authresponse

However, auth response packets don't get the desired tos markings.  Instead
the following message appears in cache.log:

2016/09/13 11:35:43 kid1| WARNING: authresponse ACL is used in context
without an HTTP response. Assuming mismatch.

After reviewing
http://lists.squid-cache.org/pipermail/squid-users/2016-May/010630.html it
seems like this has cropped up before.  The suggestion in that thread was to
exclude 407 responses from the access log.  Fortunately this works.  But I'm
wondering if there is a way to introduce delay into the 407 response itself?
Partly to minimise load associated with serving broken clients, and also to
maintain logging of actual intrusion attempts.  Any suggestions?

Luke




From yanghe0921 at 126.com  Wed Sep 14 01:02:28 2016
From: yanghe0921 at 126.com (yanghe)
Date: Wed, 14 Sep 2016 09:02:28 +0800
Subject: [squid-users] c-icap load balancing
Message-ID: <146a7ed6.396.15726376e43.Coremail.yanghe0921@126.com>

Hi 
Unlickily,I meet a  problem.I want to implement the c-icap cluster.the traffic averagely distribute to each c-icap.but I just found the adaptation_srvices_set and adaptation_services_chain.
adaptation_service_set is useful when hot standby or backup adaptation servers are available.The second applicable service is tried if and only if the transacion with the first service fails and the message waiting to be adapted is still intact.
adaptation_service_chain is useful when Squid must perform different adaptations on the same message.configures a list of complementary services that will be applied one-by-one.
These does not reach my requirement. I hope to confirm whether the c-icap can achieve cluster and load balancing.
Look forward to your advice 
Thanks in advance

2016-09-14


yanghe 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160914/80a3dc4b/attachment.htm>

From dan at getbusi.com  Wed Sep 14 02:05:35 2016
From: dan at getbusi.com (Dan Charlesworth)
Date: Wed, 14 Sep 2016 12:05:35 +1000
Subject: [squid-users] Introducing delay to HTTP 407 responses
In-Reply-To: <000301d20e1d$7476f840$5d64e8c0$@filter.luko.org>
References: <000301d20e1d$7476f840$5d64e8c0$@filter.luko.org>
Message-ID: <2C1F2621-B945-4A6A-B3AD-DACD2D71A94E@getbusi.com>

I just want to throw my support behind seeking a solution to this problem. Luke?s clearly considered it in way more detail than anyone so far, myself included.

The affects the squids under my purview every day.

Best,
Dan

> On 14 Sep. 2016, at 10:18 am, squid-users at filter.luko.org wrote:
> 
> Hi Squid users,
> 
> Seeking advice on how to slow down 407 responses to broken Apple & MS
> clients, which seem to retry at very short intervals and quickly fill the
> access.log with garbage.  The problem is very similar to this:
> 
> http://www.squid-cache.org/mail-archive/squid-users/201404/0326.html
> 
> However the config below doesn't seem to slow down the response:
> 
> acl delaydomains dstdomain .live.net .apple.com
> acl authresponse http_status 407
> external_acl_type delay ttl=0 negative_ttl=0 cache=0 %SRC /tmp/delay.pl
> acl delay external delay
> http_reply_access deny delaydomains authresponse delay
> http_reply_access allow all
> 
> The helper is never asked by Squid to process the request.  Just wondering
> if http_status ACLs can be used in http_reply_access?
> 
> My other thinking, if this isn't possible, was to mark 407 responses with
> clientside_tos so they could be delayed/throttled with tc or iptables.  Ie,
> 
> acl authresponse http_status 407
> clientside_tos 0x20 authresponse
> 
> However, auth response packets don't get the desired tos markings.  Instead
> the following message appears in cache.log:
> 
> 2016/09/13 11:35:43 kid1| WARNING: authresponse ACL is used in context
> without an HTTP response. Assuming mismatch.
> 
> After reviewing
> http://lists.squid-cache.org/pipermail/squid-users/2016-May/010630.html it
> seems like this has cropped up before.  The suggestion in that thread was to
> exclude 407 responses from the access log.  Fortunately this works.  But I'm
> wondering if there is a way to introduce delay into the 407 response itself?
> Partly to minimise load associated with serving broken clients, and also to
> maintain logging of actual intrusion attempts.  Any suggestions?
> 
> Luke
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From alphabet at shaw.ca  Wed Sep 14 05:43:44 2016
From: alphabet at shaw.ca (Jason Leshchyshyn)
Date: Tue, 13 Sep 2016 23:43:44 -0600 (MDT)
Subject: [squid-users] Cannot get ACL to work
In-Reply-To: <2004212518.88458758.1473831178813.JavaMail.root@shaw.ca>
Message-ID: <845626423.88462565.1473831824978.JavaMail.root@shaw.ca>

Ugh, I am trying to get Squid to deny access to a particular AD group, but when I enable the rule, then it denys everyone. 


This is what I have in squid.conf 






# NTLM 

auth_param ntlm program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp 

auth_param ntlm children 15 

auth_param ntlm keep_alive on 



# Limit access for Factory users 

external_acl_type nt_group %LOGIN /usr/lib64/squid/ext_wbinfo_group_acl 

acl FactoryDeny external nt_group sec_deny_internet 

http_access deny FactoryDeny 




acl auth proxy_auth REQUIRED 

http_access deny !auth 

http_access allow auth 





-=- 
I have verified the ext_wbinfo_group_acl works: 


<blockquote>


[root at fac-proxy squid]# ./ext_wbinfo_group_acl -d 

Debugging mode ON. 

user sec_vpn_users 

Got user sec_vpn_users from squid 

User: -user- 

Group: -sec_vpn_users- 

SID: -S-1-5-21-1978138449-291607360-3720246513-19354- 

GID: -1677721- 

Sending OK to squid 

OK 

user sec_deny_internet 

Got user sec_deny_internet from squid 

User: -user- 

Group: -sec_deny_internet- 

SID: -S-1-5-21-1978138449-291607360-3720246513-18148- 

GID: -1677721- 

Sending ERR to squid 

ERR 
</blockquote>




Because this is a production server there's a bunch of traffic on it so I can't catch too much of the log, but this is what I can see with debugging turned on: 


<blockquote>



2016/09/13 23:22:32.552 kid1| Acl.cc(336) matches: ACLList::matches: checking FactoryDeny 


2016/09/13 23:22:32.552 kid1| Acl.cc(319) checklistMatches: ACL::checklistMatches: checking 'FactoryDeny' 


2016/09/13 23:22:32.552 kid1| Acl.cc(321) checklistMatches: ACL::ChecklistMatches: result for 'FactoryDeny' is -1 


2016/09/13 23:22:32.552 kid1| Acl.cc(343) matches: FactoryDeny failed. 


2016/09/13 23:22:32.552 kid1| Acl.cc(354) matches: FactoryDeny result is false 
</blockquote>




If the result is false then the deny should be false and it should continue to the next rule, right? 


Please help, I don't get it... 



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160913/d08bf45f/attachment.htm>

From eduardoocarneiro at gmail.com  Wed Sep 14 11:08:52 2016
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Wed, 14 Sep 2016 04:08:52 -0700 (PDT)
Subject: [squid-users] Lost of all squid cache
In-Reply-To: <020701d20df7$437dd950$ca798bf0$@ngtech.co.il>
References: <1473699260953-4679466.post@n4.nabble.com>
 <a49cefe7-3a37-63fc-ad40-d69006e7e5a9@gmail.com>
 <0f4191e8-9e7e-6b28-16d1-d880bb583d2e@treenet.co.nz>
 <1473765791681-4679479.post@n4.nabble.com>
 <CAMeoTHmia5vLfGOPwROGApRskLR=MvJPQwa3t+EkF8VTvt9a+g@mail.gmail.com>
 <1473766668966-4679481.post@n4.nabble.com>
 <020701d20df7$437dd950$ca798bf0$@ngtech.co.il>
Message-ID: <1473851332317-4679503.post@n4.nabble.com>

SOLVED!

I've isolated the cache and created another instance for users to use.
Deleted swap.state (made a backup before) and restarted the squid service.
It took a long time to rebuild the cache, but it worked.

Thank you all for your help.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Lost-of-all-squid-cache-tp4679466p4679503.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From fredbmail at free.fr  Wed Sep 14 11:22:35 2016
From: fredbmail at free.fr (FredB)
Date: Wed, 14 Sep 2016 13:22:35 +0200 (CEST)
Subject: [squid-users] Rock store status
In-Reply-To: <ab9de679-f835-5ba9-59fe-87b064304c18@measurement-factory.com>
Message-ID: <222120125.867089644.1473852155231.JavaMail.root@zimbra4-e1.priv.proxad.net>

Hello Alex and thank you for the explanations, I forgot but of course the test is running on same hardware and same full caches (2 sata drives 15k rpm 123 Gb of caches each)

I will return to diskd now, because the point 2 is annoying for me, but rock seems very promising for me


From squid3 at treenet.co.nz  Wed Sep 14 13:35:13 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Sep 2016 01:35:13 +1200
Subject: [squid-users] Cannot get ACL to work
In-Reply-To: <845626423.88462565.1473831824978.JavaMail.root@shaw.ca>
References: <845626423.88462565.1473831824978.JavaMail.root@shaw.ca>
Message-ID: <2ecd5868-4e68-cd94-75d5-c921eaf72e10@treenet.co.nz>

On 14/09/2016 5:43 p.m., Jason Leshchyshyn wrote:
> Ugh, I am trying to get Squid to deny access to a particular AD group, but when I enable the rule, then it denys everyone. 
> 
> 
> This is what I have in squid.conf 
> 
> 
> 
> 
> 
> 
> # NTLM 
> 
> auth_param ntlm program /usr/bin/ntlm_auth --helper-protocol=squid-2.5-ntlmssp 
> 
> auth_param ntlm children 15 
> 
> auth_param ntlm keep_alive on 
> 
> 
> 
> # Limit access for Factory users 
> 
> external_acl_type nt_group %LOGIN /usr/lib64/squid/ext_wbinfo_group_acl 
> 
> acl FactoryDeny external nt_group sec_deny_internet 
> 
> http_access deny FactoryDeny 
> 

Move all that below the "deny !auth" line. One would expect clients to
login before group checking. Order is important.


> 
> acl auth proxy_auth REQUIRED 
> 
> http_access deny !auth 
> 
> http_access allow auth 
> 
> 
> 
> 
> 
> -=- 
> I have verified the ext_wbinfo_group_acl works: 
> 
> 
> <blockquote>
> 
> 
> [root at fac-proxy squid]# ./ext_wbinfo_group_acl -d 
> 
> Debugging mode ON. 
> 
> user sec_vpn_users 
> 
> Got user sec_vpn_users from squid 

This is irrelevant sec_vpn_users is not a group in the config above.

> 
> user sec_deny_internet 
> 
> Got user sec_deny_internet from squid 
> 
> User: -user- 
> 
> Group: -sec_deny_internet- 
> 
> SID: -S-1-5-21-1978138449-291607360-3720246513-18148- 
> 
> GID: -1677721- 
> 
> Sending ERR to squid 
> 

Meaning the "deny FactoryDeny" is false (no deny action) when the
username is "user".


> 
> Because this is a production server there's a bunch of traffic on it so I can't catch too much of the log, but this is what I can see with debugging turned on: 
> 
> 
> <blockquote>
> 
> 
> 
> 2016/09/13 23:22:32.552 kid1| Acl.cc(336) matches: ACLList::matches: checking FactoryDeny 
> 
> 
> 2016/09/13 23:22:32.552 kid1| Acl.cc(319) checklistMatches: ACL::checklistMatches: checking 'FactoryDeny' 
> 
> 
> 2016/09/13 23:22:32.552 kid1| Acl.cc(321) checklistMatches: ACL::ChecklistMatches: result for 'FactoryDeny' is -1 
> 

Login credentials are unknown (-1). Authentication needs to be performed
and the ACLs checked again.


> 
> 2016/09/13 23:22:32.552 kid1| Acl.cc(343) matches: FactoryDeny failed. 
> 
> 
> 2016/09/13 23:22:32.552 kid1| Acl.cc(354) matches: FactoryDeny result is false 
> </blockquote>
> 
> 
> If the result is false then the deny should be false and it should continue to the next rule, right? 
> 

Normally yes, but authentication is involved here and that makes it a
bit more complex.

Since the external_acl_type uses %LOGIN and responds with -1, that is a
signal that the false actually means Squid is to generate the 407/401
response to make authentication happen. The http_access action is not
known yet, and wont be until the client presents some credentials.


The suggestion above to place the authentication above the group lookup
simplifies things again by ensuring that auth has already happened and
this special-case situation with %LOGIN does not happen very often.

Amos



From squid3 at treenet.co.nz  Wed Sep 14 13:43:58 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Sep 2016 01:43:58 +1200
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <CAEpx-0WMruHcZBP=kpZO1+C4YnELpeYGy2=WYtKMY5zmTWuaBg@mail.gmail.com>
References: <1472739669810-4679304.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73E24F3@CLWSEXCMBX02.na.bicworld.com>
 <1473338284062-4679426.post@n4.nabble.com>
 <003001d20a04$59782a40$0c687ec0$@ngtech.co.il>
 <CAEpx-0UM6w+okGfbMaWOFduhOhQbJnOA6nt4CeLmqfsEqzdw=A@mail.gmail.com>
 <db1154f0-f39f-e69f-fe65-367cb50fd619@gmail.com>
 <1473687927215-4679455.post@n4.nabble.com>
 <a0fbb21c-8617-5acc-a2ab-4b695e25296c@measurement-factory.com>
 <1473776139024-4679482.post@n4.nabble.com>
 <CAEpx-0X=HJWO2BVhR-NZMu-oc5R631+FxAgDov6EAhs45qaNaQ@mail.gmail.com>
 <1473796753468-4679493.post@n4.nabble.com>
 <CAEpx-0X8QP6WELguYtkaQ_TJwQKo5qrXS_y60J9VUPi0ygB1cw@mail.gmail.com>
 <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
 <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>
 <6e65eafe-37aa-e6f2-9c04-e4e14b9ff3e9@gmail.com>
 <CAEpx-0WMruHcZBP=kpZO1+C4YnELpeYGy2=WYtKMY5zmTWuaBg@mail.gmail.com>
Message-ID: <3c02e953-d2cb-7905-f52a-e036ed3e06ab@treenet.co.nz>

On 14/09/2016 9:14 a.m., Chico Venancio wrote:
> Not really,
> As I understand it it is a websocket, that when proxied starts its
> handshake with a connect request so it can be "understood" by proxies such
> as squid.

Correct. Squid will open the TCP tunnel and (if succesful) send an HTTP
200 OK response to the client to let it know it can send opaque data
through it. For this client it would be WebSocket connection frames.


erdosain9's original post quoted Chrome output and some unrelated lines
from access.log (Google != WhatsApp). So we don't know anything from
that excapt WhatsApp connections have a problem, ... like the thread
subject says.

Amos



From squid3 at treenet.co.nz  Wed Sep 14 13:48:29 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Sep 2016 01:48:29 +1200
Subject: [squid-users] c-icap load balancing
In-Reply-To: <146a7ed6.396.15726376e43.Coremail.yanghe0921@126.com>
References: <146a7ed6.396.15726376e43.Coremail.yanghe0921@126.com>
Message-ID: <441ce8b7-662f-1d37-89c9-9e843f5fab75@treenet.co.nz>

On 14/09/2016 1:02 p.m., yanghe wrote:
> I hope to confirm whether the c-icap can achieve cluster and load balancing.

That is not anything to do with Squid.

Squid is simply a client application that connects to a URI presented by
whatever C-ICAP service you setup. How that service works is its own
business.


FWIW: if you can't contact the C-ICAP author through the C-ICAP
softwares contact point you could try asking on squid-dev mailing list
where he is more likely to see your request.

Amos



From rousskov at measurement-factory.com  Wed Sep 14 13:50:59 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 14 Sep 2016 07:50:59 -0600
Subject: [squid-users] c-icap load balancing
In-Reply-To: <146a7ed6.396.15726376e43.Coremail.yanghe0921@126.com>
References: <146a7ed6.396.15726376e43.Coremail.yanghe0921@126.com>
Message-ID: <25eb8491-49bf-1166-adba-f94d6c00065f@measurement-factory.com>

On 09/13/2016 07:02 PM, yanghe wrote:
> I want to implement the c-icap cluster.the
> traffic averagely distribute to each c-icap.

Unfortunately, Squid does not support true load balancing of ICAP and
eCAP services directly. It would be a welcomed feature[1].

However, there is a workaround: Use "random" ACLs in your
adaptation_access rules to select each service at random, with the same
probability. There are production deployments using that workaround to
approximate load balancing effects. When implementing this, be careful
not to fall into a common trap of mistaking an individual
adaptation_access rule match probability with the service selection
probability[2].

[1]
http://wiki.squid-cache.org/SquidFaq/AboutSquid#How_to_add_a_new_Squid_feature.2C_enhance.2C_of_fix_something.3F

[2]
http://lists.squid-cache.org/pipermail/squid-users/2016-August/012217.html


HTH,

Alex.



From eliezer at ngtech.co.il  Wed Sep 14 13:51:20 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 14 Sep 2016 16:51:20 +0300
Subject: [squid-users] Introducing delay to HTTP 407 responses
In-Reply-To: <000301d20e1d$7476f840$5d64e8c0$@filter.luko.org>
References: <000301d20e1d$7476f840$5d64e8c0$@filter.luko.org>
Message-ID: <013301d20e8f$12f257f0$38d707d0$@ngtech.co.il>

Hey Luke,

Try to use the next line instead:
external_acl_type delay ttl=1 negative_ttl=0 cache=0 %SRC %SRCPORT %URI /tmp/delay.pl

And see what happens.
I do not know why the helper is not delaying but if you have a specific logic I can convert one of my scripts to support concurrency and do this delay.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of squid-users at filter.luko.org
Sent: Wednesday, September 14, 2016 3:18 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Introducing delay to HTTP 407 responses

Hi Squid users,

Seeking advice on how to slow down 407 responses to broken Apple & MS
clients, which seem to retry at very short intervals and quickly fill the
access.log with garbage.  The problem is very similar to this:

http://www.squid-cache.org/mail-archive/squid-users/201404/0326.html

However the config below doesn't seem to slow down the response:

acl delaydomains dstdomain .live.net .apple.com
acl authresponse http_status 407
external_acl_type delay ttl=0 negative_ttl=0 cache=0 %SRC /tmp/delay.pl
acl delay external delay
http_reply_access deny delaydomains authresponse delay
http_reply_access allow all

The helper is never asked by Squid to process the request.  Just wondering
if http_status ACLs can be used in http_reply_access?

My other thinking, if this isn't possible, was to mark 407 responses with
clientside_tos so they could be delayed/throttled with tc or iptables.  Ie,

acl authresponse http_status 407
clientside_tos 0x20 authresponse

However, auth response packets don't get the desired tos markings.  Instead
the following message appears in cache.log:

2016/09/13 11:35:43 kid1| WARNING: authresponse ACL is used in context
without an HTTP response. Assuming mismatch.

After reviewing
http://lists.squid-cache.org/pipermail/squid-users/2016-May/010630.html it
seems like this has cropped up before.  The suggestion in that thread was to
exclude 407 responses from the access log.  Fortunately this works.  But I'm
wondering if there is a way to introduce delay into the 407 response itself?
Partly to minimise load associated with serving broken clients, and also to
maintain logging of actual intrusion attempts.  Any suggestions?

Luke


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Wed Sep 14 13:57:23 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 14 Sep 2016 16:57:23 +0300
Subject: [squid-users] windows update not working squid 3.5.2
In-Reply-To: <A2612C06-B8D6-4BDA-BAE1-03E566565C67@netstream.ps>
References: <763AFEA6-52DE-4DCB-805D-DA1136933178@netstream.ps>
 <20f02386-6272-0489-4f31-4f41051a1fa0@gmail.com>
 <A2612C06-B8D6-4BDA-BAE1-03E566565C67@netstream.ps>
Message-ID: <013501d20e8f$eb411970$c1c34c50$@ngtech.co.il>

Hey Ahmad,

 

First use some paste like pastebin to share you configuration file since it's not well formatted in the email.

Once I will have this I can take a look at the file and try to understand what you might try to do.

Also I have seen you are not using StoreID at all and you are intercepting traffic and not using the proxy as a forward proxy.

Have you tried to test squid caching using curl or wget compared to the original windows update client?

 

I can try to guide you with this but your config file doesn't make any sense at all to me.


Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of --Ahmad--
Sent: Tuesday, September 6, 2016 8:08 PM
To: Yuri Voinov
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] windows update not working squid 3.5.2

 

/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.13.30 application/octet-stream
1473181228.768   1202 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.70.206 application/octet-stream
1473181229.117   1159 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.70.206 application/octet-stream
1473181229.265    984 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181229.525   1207 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181230.066   1314 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.70.206 application/octet-stream
1473181230.147    913 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181230.166   1659 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.13.30 application/octet-stream
1473181230.438   1233 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.13.30 application/octet-stream
1473181230.461   1569 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181230.621   1023 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181231.143   1219 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181231.166   1212 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181231.528   1131 192.168.0.10 TCP_MISS/206 1049142 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181231.601   1416 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.13.30 application/octet-stream
1473181231.784    938 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181232.102   1565 192.168.0.10 TCP_MISS/206 1049142 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.70.206 application/octet-stream
1473181232.330   1453 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.70.206 application/octet-stream


with squid.conf :
#########
acl windowsupdate dstdomain windowsupdate.microsoft.com <http://windowsupdate.microsoft.com> 
acl windowsupdate dstdomain .update.microsoft.com <http://update.microsoft.com> 
acl windowsupdate dstdomain download.windowsupdate.com <http://download.windowsupdate.com> 
acl windowsupdate dstdomain redir.metaservices.microsoft.com <http://redir.metaservices.microsoft.com> 
acl windowsupdate dstdomain images.metaservices.microsoft.com <http://images.metaservices.microsoft.com> 
acl windowsupdate dstdomain c.microsoft.com <http://c.microsoft.com> 
acl windowsupdate dstdomain www.download.windowsupdate.com <http://www.download.windowsupdate.com> 
acl windowsupdate dstdomain wustat.windows.com <http://wustat.windows.com> 
acl windowsupdate dstdomain crl.microsoft.com <http://crl.microsoft.com> 
acl windowsupdate dstdomain sls.microsoft.com <http://sls.microsoft.com> 
acl windowsupdate dstdomain productactivation.one.microsoft.com <http://productactivation.one.microsoft.com> 
acl windowsupdate dstdomain ntservicepack.microsoft.com <http://ntservicepack.microsoft.com> 

acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com <http://www.update.microsoft.com> 
acl wuCONNECT dstdomain sls.microsoft.com <http://sls.microsoft.com> 

#http_access allow CONNECT wuCONNECT localnet
#http_access allow windowsupdate localnet
#######################
# Updates: Windows
refresh_pattern -i windowsupdate.com/.* <http://windowsupdate.com/.*> \.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i microsoft.com/.* <http://microsoft.com/.*> \.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i windows.com/.* <http://windows.com/.*> \.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i microsoft.com.akadns.net/.* <http://microsoft.com.akadns.net/.*> \.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i deploy.akamaitechnologies.com/.* <http://deploy.akamaitechnologies.com/.*> \.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
###########
#refresh_pattern -i microsoft.com/.* <http://microsoft.com/.*> \.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
#refresh_pattern -i windowsupdate.com/.* <http://windowsupdate.com/.*> \.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
#refresh_pattern -i windows.com/.* <http://windows.com/.*> \.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
# DONT MODIFY THESE LINES
refresh_pattern \^ftp:           1440    20%     10080
refresh_pattern \^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
#################################################################
###########################
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access allow CONNECT wuCONNECT localnet
http_access allow windowsupdate localnet
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.0.1:3128

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/cache/squid 20000 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
#refresh_pattern ^ftp:          1440    20%     10080
#refresh_pattern ^gopher:       1440    0%      1440
#refresh_pattern -i (/cgi-bin/|\?) 0    0%      0
#refresh_pattern .              0       20%     4320
#############
range_offset_limit 5 Gb windowsupdate
maximum_object_size 5 Gb
quick_abort_min -1
#########
http_port 3129 intercept
#####################

On Sep 6, 2016, at 6:01 PM, Yuri Voinov <yvoinov at gmail.com <mailto:yvoinov at gmail.com> > wrote:

 


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

http://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates

Did you read this?


06.09.2016 20:59, --Ahmad-- ?????:



hi squid users .

I?m trying to catch windows updates as cached object
im testing with  windows 10 pc

i see all request as tcp_miss and the caching store is not getting

increase .




=========
1473173748.014   3603 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.022  12146 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.057   5321 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.155   3684 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.355   4832 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.612  12645 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.650   7276 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.720  12654 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.816   5064 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.022   4159 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.048   5618 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.177   7817 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.208   3383 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.318   5096 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.395   3986 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.850  13837 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173750.015    914 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173750.029   1365 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173750.420   7126 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream




=======================

root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~#

==============
here is squid config :

root at raspberrypi:~# cat /etc/squid/squid.conf
#########
acl windowsupdate dstdomain windowsupdate.microsoft.com
acl windowsupdate dstdomain .update.microsoft.com
acl windowsupdate dstdomain download.windowsupdate.com
acl windowsupdate dstdomain redir.metaservices.microsoft.com
acl windowsupdate dstdomain images.metaservices.microsoft.com
acl windowsupdate dstdomain c.microsoft.com
acl windowsupdate dstdomain www.download.windowsupdate.com <http://www.download.windowsupdate.com> 
acl windowsupdate dstdomain wustat.windows.com
acl windowsupdate dstdomain crl.microsoft.com
acl windowsupdate dstdomain sls.microsoft.com
acl windowsupdate dstdomain productactivation.one.microsoft.com
acl windowsupdate dstdomain ntservicepack.microsoft.com

acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com <http://www.update.microsoft.com> 
acl wuCONNECT dstdomain sls.microsoft.com

#######################
refresh_pattern -i

microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
43200 reload-into-ims



refresh_pattern -i

windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320
80% 43200 reload-into-ims



refresh_pattern -i

windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
43200 reload-into-ims



# DONT MODIFY THESE LINES
refresh_pattern \^ftp:           1440    20%     10080
refresh_pattern \^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
#################################################################
###########################
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly

plugged) machines




acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT


http_access allow CONNECT wuCONNECT localnet
http_access allow windowsupdate localnet
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager


http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.0.1:3128

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/cache/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid


#############
range_offset_limit 200 MB windowsupdate
maximum_object_size 200 MB
quick_abort_min -1
#########
http_port 3129 intercept
maximum_object_size 200000 KB




thank you

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBCAAGBQJXztpBAAoJENNXIZxhPexGSx4H/0bK8485yWhpNbGUIGtwvx9h
PTuRhfJP+f8xoTbTh/zH1TgXs21M953uf5DoYlynMBSeVXCfQQiUhDOs+0bqAjfD
JsLCXVpZdSYYWyX2aErjfZqKQO67aVkX+zJbAY/zlTJKG6Gxg1+ssQSEJaFWu6cK
J8KBudfWaKmPc9xdiZRfYFE6LKBSeQr93BqBF6s1SwdAPKEkspQmDTuqPZEwMwW5
zQfuI/HnIvynSE+SxCFYOAwka2zVAdewXfVyWqYyFCHaHnDkXkPmK/5zZJDOmqGi
erifbGQHRHAFWNnT4mMsHGjM3Wfz1bbhr+j+tZJkY4x116eVUMrVbbXRApY5nn0=
=ZaFG
-----END PGP SIGNATURE-----

<0x613DEC46.asc>_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160914/e545ddfb/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image001.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160914/e545ddfb/attachment.png>

From squid3 at treenet.co.nz  Wed Sep 14 14:05:03 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Sep 2016 02:05:03 +1200
Subject: [squid-users] Introducing delay to HTTP 407 responses
In-Reply-To: <000301d20e1d$7476f840$5d64e8c0$@filter.luko.org>
References: <000301d20e1d$7476f840$5d64e8c0$@filter.luko.org>
Message-ID: <4ed7a4c1-9be8-a766-1ec6-cc34246e1eca@treenet.co.nz>

On 14/09/2016 12:18 p.m., squid-users at filter.luko.org wrote:
> Hi Squid users,
> 
> Seeking advice on how to slow down 407 responses to broken Apple & MS
> clients, which seem to retry at very short intervals and quickly fill the
> access.log with garbage.  The problem is very similar to this:
> 
> http://www.squid-cache.org/mail-archive/squid-users/201404/0326.html
> 

The outcome of that was a 'ext_delayer_acl helper in Squid-3.5

<http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_delayer_acl.html>

It works slightly differently to what was being discussed in the thread.
see the man page for details on how to configure it.

Amos



From erdosain9 at gmail.com  Wed Sep 14 18:56:38 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 14 Sep 2016 11:56:38 -0700 (PDT)
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <3c02e953-d2cb-7905-f52a-e036ed3e06ab@treenet.co.nz>
References: <a0fbb21c-8617-5acc-a2ab-4b695e25296c@measurement-factory.com>
 <1473776139024-4679482.post@n4.nabble.com>
 <CAEpx-0X=HJWO2BVhR-NZMu-oc5R631+FxAgDov6EAhs45qaNaQ@mail.gmail.com>
 <1473796753468-4679493.post@n4.nabble.com>
 <CAEpx-0X8QP6WELguYtkaQ_TJwQKo5qrXS_y60J9VUPi0ygB1cw@mail.gmail.com>
 <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
 <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>
 <6e65eafe-37aa-e6f2-9c04-e4e14b9ff3e9@gmail.com>
 <CAEpx-0WMruHcZBP=kpZO1+C4YnELpeYGy2=WYtKMY5zmTWuaBg@mail.gmail.com>
 <3c02e953-d2cb-7905-f52a-e036ed3e06ab@treenet.co.nz>
Message-ID: <1473879398350-4679512.post@n4.nabble.com>

Hi.
If i put 

acl step1 at_step SslBump1 
acl excludeSSL ssl::server_name_regex web/.whatsapp/.com 

ssl_bump peek step1 
ssl_bump splice excludeSSL 
ssl_bump bump all 

I dont get nothing about web.whatsapp.com in access.log

But if i change config to

ssl_bump stare all
ssl_bump bump all

I get this Access.log.


1473879403.629   1030 192.168.1.172 TAG_NONE/200 0 CONNECT
web.whatsapp.com:443 - HIER_DIRECT/31.13.85.51 -
1473879403.878    164 192.168.1.172 TAG_NONE/200 0 CONNECT
fonts.gstatic.com:443 - HIER_DIRECT/64.233.186.94 -
1473879403.950    295 192.168.1.172 TCP_MISS/404 525 GET
https://web.whatsapp.com/404.appcache - HIER_DIRECT/31.13.85.51 text/html
1473879404.110     58 192.168.1.172 TCP_MISS/200 647 GET
https://www.google.com/searchdomaincheck? - HIER_DIRECT/172.217.28.228
text/plain
1473879405.340    423 192.168.1.172 TCP_MISS/304 592 GET
https://web.whatsapp.com/serviceworker.js - HIER_DIRECT/31.13.85.51
application/javascript
1473879407.051    184 192.168.1.172 TCP_MISS/503 427 HEAD http://tsxvhgadd/
- HIER_NONE/- text/html
1473879407.111    243 192.168.1.172 TCP_MISS/503 427 HEAD
http://twngvdpnqgywgf/ - HIER_NONE/- text/html
1473879407.113    245 192.168.1.172 TCP_MISS/503 427 HEAD
http://jvmxcnnzacik/ - HIER_NONE/- text/html
1473879409.275    188 192.168.1.172 TAG_NONE/200 0 CONNECT
ssl.gstatic.com:443 - HIER_DIRECT/64.233.190.120 -
1473879409.335     19 192.168.1.172 TCP_HIT/200 70267 GET
https://ssl.gstatic.com/safebrowsing/csd/client_model_v5_variation_0.pb -
HIER_NONE/- application/octet-stream
1473879409.355      4 192.168.1.172 TCP_HIT/200 70267 GET
https://ssl.gstatic.com/safebrowsing/csd/client_model_v5_ext_variation_0.pb
- HIER_NONE/- application/octet-stream
1473879409.568    481 192.168.1.172 TAG_NONE/200 0 CONNECT
ssl.gstatic.com:443 - HIER_DIRECT/64.233.190.120 -
1473879409.977    305 192.168.1.172 TCP_MISS/200 584 GET
https://web.whatsapp.com/status.json - HIER_DIRECT/31.13.85.51 text/json
1473879411.771     85 192.168.1.172 TCP_MISS/200 1807 GET
https://www.google.com.ar/_/chrome/newtab-serviceworker.js -
HIER_DIRECT/172.217.28.35 text/javascript
1473879414.612    321 192.168.1.172 TCP_MISS/200 584 GET
https://web.whatsapp.com/status.json - HIER_DIRECT/31.13.85.51 text/json
1473879428.127    301 192.168.1.172 TCP_MISS/200 584 GET
https://web.whatsapp.com/status.json - HIER_DIRECT/31.13.85.51 text/json
1473879446.136    333 192.168.1.172 TCP_MISS/200 584 GET
https://web.whatsapp.com/status.json - HIER_DIRECT/31.13.85.51 text/json



Thanks!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679512.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Wed Sep 14 20:13:52 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 14 Sep 2016 23:13:52 +0300
Subject: [squid-users] windows update not working squid 3.5.2
In-Reply-To: <A2612C06-B8D6-4BDA-BAE1-03E566565C67@netstream.ps>
References: <763AFEA6-52DE-4DCB-805D-DA1136933178@netstream.ps>
 <20f02386-6272-0489-4f31-4f41051a1fa0@gmail.com>
 <A2612C06-B8D6-4BDA-BAE1-03E566565C67@netstream.ps>
Message-ID: <02d501d20ec4$834bd690$89e383b0$@ngtech.co.il>

Hey Ahmad,

 

Try the new version of ms-updates from:

http://ngtech.co.il/ms-updates-store/

http://www1.ngtech.co.il/wpe/?page_id=301

 

Since you are using an armX based system.

>From my point of view on things I do not see the difference between other traffic to MS updates.

Windows Updates are HTTP requests and responses which are identical to other objects.

When a proxy or a service starts to see these things with "new" perspective my assumption is that something with either RAM or CPU or DISK is wrong and couple simple objects will clear out things about the proxy state.


What I need is a testing use case from the squid world jargon.

Are you using an Intercept proxy?

If so what type of Interception? Tproxy or Intercept?

What objects did you tried until now? Only Windows Updates?

Do you have a dump of these requests?(you can use http://wiki.squid-cache.org/KnowledgeBase/DebugSections)

The dumps should be using section 11 ie: debug_options ALL,1 11,6

With these dumps we need the corresponding access.log.

These should be enough to think about things and maybe re-test them.

Also What OS are you using?

 

Eliezer

 

----

 <http://ngtech.co.il/lmgtfy/> Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



 

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of --Ahmad--
Sent: Tuesday, September 6, 2016 8:08 PM
To: Yuri Voinov
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] windows update not working squid 3.5.2

 

/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.13.30 application/octet-stream
1473181228.768   1202 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.70.206 application/octet-stream
1473181229.117   1159 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.70.206 application/octet-stream
1473181229.265    984 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181229.525   1207 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181230.066   1314 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.70.206 application/octet-stream
1473181230.147    913 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181230.166   1659 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.13.30 application/octet-stream
1473181230.438   1233 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.13.30 application/octet-stream
1473181230.461   1569 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181230.621   1023 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181231.143   1219 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181231.166   1212 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181231.528   1131 192.168.0.10 TCP_MISS/206 1049142 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181231.601   1416 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.13.30 application/octet-stream
1473181231.784    938 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.13.46 application/octet-stream
1473181232.102   1565 192.168.0.10 TCP_MISS/206 1049142 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe - ORIGINAL_DST/8.253.70.206 application/octet-stream
1473181232.330   1453 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.70.206 application/octet-stream


with squid.conf :
#########
acl windowsupdate dstdomain windowsupdate.microsoft.com <http://windowsupdate.microsoft.com> 
acl windowsupdate dstdomain .update.microsoft.com <http://update.microsoft.com> 
acl windowsupdate dstdomain download.windowsupdate.com <http://download.windowsupdate.com> 
acl windowsupdate dstdomain redir.metaservices.microsoft.com <http://redir.metaservices.microsoft.com> 
acl windowsupdate dstdomain images.metaservices.microsoft.com <http://images.metaservices.microsoft.com> 
acl windowsupdate dstdomain c.microsoft.com <http://c.microsoft.com> 
acl windowsupdate dstdomain www.download.windowsupdate.com <http://www.download.windowsupdate.com> 
acl windowsupdate dstdomain wustat.windows.com <http://wustat.windows.com> 
acl windowsupdate dstdomain crl.microsoft.com <http://crl.microsoft.com> 
acl windowsupdate dstdomain sls.microsoft.com <http://sls.microsoft.com> 
acl windowsupdate dstdomain productactivation.one.microsoft.com <http://productactivation.one.microsoft.com> 
acl windowsupdate dstdomain ntservicepack.microsoft.com <http://ntservicepack.microsoft.com> 

acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com <http://www.update.microsoft.com> 
acl wuCONNECT dstdomain sls.microsoft.com <http://sls.microsoft.com> 

#http_access allow CONNECT wuCONNECT localnet
#http_access allow windowsupdate localnet
#######################
# Updates: Windows
refresh_pattern -i windowsupdate.com/.* <http://windowsupdate.com/.*> \.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i microsoft.com/.* <http://microsoft.com/.*> \.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i windows.com/.* <http://windows.com/.*> \.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i microsoft.com.akadns.net/.* <http://microsoft.com.akadns.net/.*> \.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
refresh_pattern -i deploy.akamaitechnologies.com/.* <http://deploy.akamaitechnologies.com/.*> \.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
###########
#refresh_pattern -i microsoft.com/.* <http://microsoft.com/.*> \.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
#refresh_pattern -i windowsupdate.com/.* <http://windowsupdate.com/.*> \.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
#refresh_pattern -i windows.com/.* <http://windows.com/.*> \.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
# DONT MODIFY THESE LINES
refresh_pattern \^ftp:           1440    20%     10080
refresh_pattern \^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
#################################################################
###########################
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access allow CONNECT wuCONNECT localnet
http_access allow windowsupdate localnet
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.0.1:3128

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/cache/squid 20000 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid

#
# Add any of your own refresh_pattern entries above these.
#
#refresh_pattern ^ftp:          1440    20%     10080
#refresh_pattern ^gopher:       1440    0%      1440
#refresh_pattern -i (/cgi-bin/|\?) 0    0%      0
#refresh_pattern .              0       20%     4320
#############
range_offset_limit 5 Gb windowsupdate
maximum_object_size 5 Gb
quick_abort_min -1
#########
http_port 3129 intercept
#####################

On Sep 6, 2016, at 6:01 PM, Yuri Voinov <yvoinov at gmail.com <mailto:yvoinov at gmail.com> > wrote:

 


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

http://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates

Did you read this?


06.09.2016 20:59, --Ahmad-- ?????:



hi squid users .

I?m trying to catch windows updates as cached object
im testing with  windows 10 pc

i see all request as tcp_miss and the caching store is not getting

increase .




=========
1473173748.014   3603 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.022  12146 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.057   5321 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.155   3684 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.355   4832 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.612  12645 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.650   7276 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.720  12654 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173748.816   5064 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.022   4159 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.048   5618 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.177   7817 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.208   3383 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.318   5096 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.395   3986 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173749.850  13837 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173750.015    914 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173750.029   1365 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream



1473173750.420   7126 192.168.0.10 TCP_MISS/206 1049229 GET

http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf
- ORIGINAL_DST/13.107.4.50 application/octet-stream




=======================

root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~# du -sh /var/cache/squid/
17M     /var/cache/squid/
root at raspberrypi:~#

==============
here is squid config :

root at raspberrypi:~# cat /etc/squid/squid.conf
#########
acl windowsupdate dstdomain windowsupdate.microsoft.com
acl windowsupdate dstdomain .update.microsoft.com
acl windowsupdate dstdomain download.windowsupdate.com
acl windowsupdate dstdomain redir.metaservices.microsoft.com
acl windowsupdate dstdomain images.metaservices.microsoft.com
acl windowsupdate dstdomain c.microsoft.com
acl windowsupdate dstdomain www.download.windowsupdate.com <http://www.download.windowsupdate.com> 
acl windowsupdate dstdomain wustat.windows.com
acl windowsupdate dstdomain crl.microsoft.com
acl windowsupdate dstdomain sls.microsoft.com
acl windowsupdate dstdomain productactivation.one.microsoft.com
acl windowsupdate dstdomain ntservicepack.microsoft.com

acl CONNECT method CONNECT
acl wuCONNECT dstdomain www.update.microsoft.com <http://www.update.microsoft.com> 
acl wuCONNECT dstdomain sls.microsoft.com

#######################
refresh_pattern -i

microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
43200 reload-into-ims



refresh_pattern -i

windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320
80% 43200 reload-into-ims



refresh_pattern -i

windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
43200 reload-into-ims



# DONT MODIFY THESE LINES
refresh_pattern \^ftp:           1440    20%     10080
refresh_pattern \^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320
#################################################################
###########################
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly

plugged) machines




acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT


http_access allow CONNECT wuCONNECT localnet
http_access allow windowsupdate localnet
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager


http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.0.1:3128

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/cache/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/cache/squid


#############
range_offset_limit 200 MB windowsupdate
maximum_object_size 200 MB
quick_abort_min -1
#########
http_port 3129 intercept
maximum_object_size 200000 KB




thank you

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBCAAGBQJXztpBAAoJENNXIZxhPexGSx4H/0bK8485yWhpNbGUIGtwvx9h
PTuRhfJP+f8xoTbTh/zH1TgXs21M953uf5DoYlynMBSeVXCfQQiUhDOs+0bqAjfD
JsLCXVpZdSYYWyX2aErjfZqKQO67aVkX+zJbAY/zlTJKG6Gxg1+ssQSEJaFWu6cK
J8KBudfWaKmPc9xdiZRfYFE6LKBSeQr93BqBF6s1SwdAPKEkspQmDTuqPZEwMwW5
zQfuI/HnIvynSE+SxCFYOAwka2zVAdewXfVyWqYyFCHaHnDkXkPmK/5zZJDOmqGi
erifbGQHRHAFWNnT4mMsHGjM3Wfz1bbhr+j+tZJkY4x116eVUMrVbbXRApY5nn0=
=ZaFG
-----END PGP SIGNATURE-----

<0x613DEC46.asc>_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org> 
http://lists.squid-cache.org/listinfo/squid-users

 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160914/5037ce31/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: image002.png
Type: image/png
Size: 11308 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160914/5037ce31/attachment.png>

From rousskov at measurement-factory.com  Wed Sep 14 21:54:40 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 14 Sep 2016 15:54:40 -0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1473879398350-4679512.post@n4.nabble.com>
References: <a0fbb21c-8617-5acc-a2ab-4b695e25296c@measurement-factory.com>
 <1473776139024-4679482.post@n4.nabble.com>
 <CAEpx-0X=HJWO2BVhR-NZMu-oc5R631+FxAgDov6EAhs45qaNaQ@mail.gmail.com>
 <1473796753468-4679493.post@n4.nabble.com>
 <CAEpx-0X8QP6WELguYtkaQ_TJwQKo5qrXS_y60J9VUPi0ygB1cw@mail.gmail.com>
 <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
 <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>
 <6e65eafe-37aa-e6f2-9c04-e4e14b9ff3e9@gmail.com>
 <CAEpx-0WMruHcZBP=kpZO1+C4YnELpeYGy2=WYtKMY5zmTWuaBg@mail.gmail.com>
 <3c02e953-d2cb-7905-f52a-e036ed3e06ab@treenet.co.nz>
 <1473879398350-4679512.post@n4.nabble.com>
Message-ID: <e730f7da-c6ce-808f-f454-2d7a0369a92b@measurement-factory.com>

On 09/14/2016 12:56 PM, erdosain9 wrote:
> If i put 
> 
> acl step1 at_step SslBump1 
> acl excludeSSL ssl::server_name_regex web/.whatsapp/.com 
> 
> ssl_bump peek step1 
> ssl_bump splice excludeSSL 
> ssl_bump bump all 
> 
> I dont get nothing about web.whatsapp.com in access.log

What kind of CONNECT requests do you get logged in this case?


> But if i change config to
> 
> ssl_bump stare all
> ssl_bump bump all
> 
> I get this Access.log.
> 
> 
> 1473879403.629   1030 192.168.1.172 TAG_NONE/200 0 CONNECT
> web.whatsapp.com:443 - HIER_DIRECT/31.13.85.51 -

I would expect a logged CONNECT for the splicing case as well (assuming
splicing works). If Squid knows the server name (and a matching
excludeSSL implies that it does), then Squid should log it when logging
CONNECT after the spliced connections terminate.

Alex.



From erdosain9 at gmail.com  Wed Sep 14 23:01:46 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 14 Sep 2016 16:01:46 -0700 (PDT)
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <e730f7da-c6ce-808f-f454-2d7a0369a92b@measurement-factory.com>
References: <CAEpx-0X=HJWO2BVhR-NZMu-oc5R631+FxAgDov6EAhs45qaNaQ@mail.gmail.com>
 <1473796753468-4679493.post@n4.nabble.com>
 <CAEpx-0X8QP6WELguYtkaQ_TJwQKo5qrXS_y60J9VUPi0ygB1cw@mail.gmail.com>
 <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
 <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>
 <6e65eafe-37aa-e6f2-9c04-e4e14b9ff3e9@gmail.com>
 <CAEpx-0WMruHcZBP=kpZO1+C4YnELpeYGy2=WYtKMY5zmTWuaBg@mail.gmail.com>
 <3c02e953-d2cb-7905-f52a-e036ed3e06ab@treenet.co.nz>
 <1473879398350-4679512.post@n4.nabble.com>
 <e730f7da-c6ce-808f-f454-2d7a0369a92b@measurement-factory.com>
Message-ID: <1473894106709-4679515.post@n4.nabble.com>

Hi, thanks


With

acl step1 at_step SslBump1 
acl excludeSSL ssl::server_name_regex web/.whatsapp/.com 

ssl_bump peek step1 
ssl_bump splice excludeSSL 
ssl_bump bump all 

I dont get nothing about web.whatsapp.com in access.log 
except this, a lot of time after i close the tab window of web browser...:
1473879972.435  37929 192.168.1.172 TCP_TUNNEL/200 1069 CONNECT
web.whatsapp.com:443 - HIER_DIRECT/31.13.85.51 - 

Just that


But if i change config to 

ssl_bump stare all 
ssl_bump bump all 

I get this Access.log. 

1473879403.950    295 192.168.1.172 TCP_MISS/404 525 GET
https://web.whatsapp.com/404.appcache - HIER_DIRECT/31.13.85.51 text/html 
1473879404.110     58 192.168.1.172 TCP_MISS/200 647 GET
https://www.google.com/searchdomaincheck? - HIER_DIRECT/172.217.28.228
text/plain 
1473879405.340    423 192.168.1.172 TCP_MISS/304 592 GET
https://web.whatsapp.com/serviceworker.js - HIER_DIRECT/31.13.85.51
application/javascript 
1473879407.051    184 192.168.1.172 TCP_MISS/503 427 HEAD http://tsxvhgadd/
- HIER_NONE/- text/html 
1473879407.111    243 192.168.1.172 TCP_MISS/503 427 HEAD
http://twngvdpnqgywgf/ - HIER_NONE/- text/html 
1473879407.113    245 192.168.1.172 TCP_MISS/503 427 HEAD
http://jvmxcnnzacik/ - HIER_NONE/- text/html 
1473879409.275    188 192.168.1.172 TAG_NONE/200 0 CONNECT
ssl.gstatic.com:443 - HIER_DIRECT/64.233.190.120 - 
1473879409.335     19 192.168.1.172 TCP_HIT/200 70267 GET
https://ssl.gstatic.com/safebrowsing/csd/client_model_v5_variation_0.pb -
HIER_NONE/- application/octet-stream 
1473879409.355      4 192.168.1.172 TCP_HIT/200 70267 GET
https://ssl.gstatic.com/safebrowsing/csd/client_model_v5_ext_variation_0.pb
- HIER_NONE/- application/octet-stream 
1473879409.568    481 192.168.1.172 TAG_NONE/200 0 CONNECT
ssl.gstatic.com:443 - HIER_DIRECT/64.233.190.120 - 
1473879409.977    305 192.168.1.172 TCP_MISS/200 584 GET
https://web.whatsapp.com/status.json - HIER_DIRECT/31.13.85.51 text/json 
1473879411.771     85 192.168.1.172 TCP_MISS/200 1807 GET
https://www.google.com.ar/_/chrome/newtab-serviceworker.js -
HIER_DIRECT/172.217.28.35 text/javascript 
1473879414.612    321 192.168.1.172 TCP_MISS/200 584 GET
https://web.whatsapp.com/status.json - HIER_DIRECT/31.13.85.51 text/json 
1473879428.127    301 192.168.1.172 TCP_MISS/200 584 GET
https://web.whatsapp.com/status.json - HIER_DIRECT/31.13.85.51 text/json 
1473879446.136    333 192.168.1.172 TCP_MISS/200 584 GET
https://web.whatsapp.com/status.json - HIER_DIRECT/31.13.85.51 text/json 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679515.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Wed Sep 14 23:31:13 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 14 Sep 2016 17:31:13 -0600
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1473894106709-4679515.post@n4.nabble.com>
References: <CAEpx-0X=HJWO2BVhR-NZMu-oc5R631+FxAgDov6EAhs45qaNaQ@mail.gmail.com>
 <1473796753468-4679493.post@n4.nabble.com>
 <CAEpx-0X8QP6WELguYtkaQ_TJwQKo5qrXS_y60J9VUPi0ygB1cw@mail.gmail.com>
 <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
 <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>
 <6e65eafe-37aa-e6f2-9c04-e4e14b9ff3e9@gmail.com>
 <CAEpx-0WMruHcZBP=kpZO1+C4YnELpeYGy2=WYtKMY5zmTWuaBg@mail.gmail.com>
 <3c02e953-d2cb-7905-f52a-e036ed3e06ab@treenet.co.nz>
 <1473879398350-4679512.post@n4.nabble.com>
 <e730f7da-c6ce-808f-f454-2d7a0369a92b@measurement-factory.com>
 <1473894106709-4679515.post@n4.nabble.com>
Message-ID: <11a31fcd-901a-351a-4f60-8b2fe054b224@measurement-factory.com>

On 09/14/2016 05:01 PM, erdosain9 wrote:

> acl step1 at_step SslBump1 
> acl excludeSSL ssl::server_name_regex web/.whatsapp/.com 
> 
> ssl_bump peek step1 
> ssl_bump splice excludeSSL 
> ssl_bump bump all 
> 
> I dont get nothing about web.whatsapp.com in access.log 

I suspect you just do not know how to find relevant access.log records.
The first logged CONNECT (that I would expect to see) will not have
web.whatsapp.com domain name, but will have one of its IP addresses.


> except this, a lot of time after i close the tab window of web browser...:
> 1473879972.435  37929 192.168.1.172 TCP_TUNNEL/200 1069 CONNECT
> web.whatsapp.com:443 - HIER_DIRECT/31.13.85.51 - 
> 
> Just that

That is not nothing! That is exactly what I would expect -- an
indication of a successfully established tunnel, splicing client and
server connections. Keep in mind that Squid logs transactions when they
are over, not when they start. A tunnel may last for hours or more...

I trust that you do not expect to see HTTP transactions (besides opening
CONNECT) that happen inside the tunnel. After splicing SSL connections,
Squid does not (and cannot) inspect what happens inside the resulting
tunnel.

Alex.



From hardikdangar+squid at gmail.com  Wed Sep 14 23:54:27 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Thu, 15 Sep 2016 05:24:27 +0530
Subject: [squid-users] cache github zip repositories
Message-ID: <CA+sSnVYRRMPz6ZSBbZnMvAeLzL3=4sAG=Bkvr5U-B=OxpKMnhQ@mail.gmail.com>

Hello,

I am trying to cache Github zip URL's so it can be effectively cached as a
composer(php dependency management tool) uses them and in our local setup (
we are about 40 developers on a Lan and it will really help us managing
cache.). My squid version is 3.5.12 and our squid cache server is ubuntu
16.04. Here is squid.conf file we use,
https://gist.github.com/hardikdangar/df31d5bce725eff66e06f3abd6e77600

Here is the part which I want to cache,
say for example you want to download repo from GitHub then URL looks like
https://github.com/hardikdangar/test/archive/master.zip
but it redirects to the following,
https://codeload.github.com/hardikdangar/test/zip/master

You can see the response parameters via redbot.org
https://redbot.org/?uri=https%3A%2F%2Fcodeload.github.com%
2Fhardikdangar%2Ftest%2Fzip%2Fmaster

  HTTP/1.1 200 OK
    Content-Length: 929
    Access-Control-Allow-Origin: https://render.githubusercontent.com
    Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'
    Strict-Transport-Security: max-age=31536000
    Vary: Authorization,Accept-Encoding
    X-Content-Type-Options: nosniff
    X-Frame-Options: deny
    X-XSS-Protection: 1; mode=block
    ETag: "9ea9838812d6f7bc53763eb1577da04e2fa473d5"
    Content-Type: application/zip
    Content-Disposition: attachment; filename=test-master.zip
    X-Geo-Block-List:
    Date: Wed, 14 Sep 2016 23:24:44 GMT
    X-GitHub-Request-Id: 77092BF1:7F40:346461:57D9DC3C

Now if i do any change to above repository github does change ETAG and if i
don't change anything then ETAG remains the same so i believe we should be
able to cache those .zip files.

By default, squid does not cache codeload.github.com, to put it into cache,
I added,
refresh_pattern codeload.github.com 900 20% 4320 reload-into-ims

Now as per my understanding this should check etag as Last-Modified is not
provided by github for each new request. This does cache the zip file but
what happens is in next request even if i change the content and etag
changes squid sends the cached file from its cache instead of downloading
new file.

I have no clue why this happens. Can anyone help me figure out what's wrong
here? why squid does not detect new etag when repository is updated? why it
sends cache file even though there is new file available.

Thank you very much in advance for reading upto this point and have a good
day.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160915/3acc26a2/attachment.htm>

From squid3 at treenet.co.nz  Thu Sep 15 00:35:03 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Sep 2016 12:35:03 +1200
Subject: [squid-users] cache github zip repositories
In-Reply-To: <CA+sSnVYRRMPz6ZSBbZnMvAeLzL3=4sAG=Bkvr5U-B=OxpKMnhQ@mail.gmail.com>
References: <CA+sSnVYRRMPz6ZSBbZnMvAeLzL3=4sAG=Bkvr5U-B=OxpKMnhQ@mail.gmail.com>
Message-ID: <555fbe87-18f2-2998-3d26-3837a9fb8337@treenet.co.nz>

On 15/09/2016 11:54 a.m., Hardik Dangar wrote:
> Hello,
> 
> I am trying to cache Github zip URL's so it can be effectively cached as a
> composer(php dependency management tool) uses them and in our local setup (
> we are about 40 developers on a Lan and it will really help us managing
> cache.). My squid version is 3.5.12 and our squid cache server is ubuntu
> 16.04. Here is squid.conf file we use,
> https://gist.github.com/hardikdangar/df31d5bce725eff66e06f3abd6e77600
> 
> Here is the part which I want to cache,
> say for example you want to download repo from GitHub then URL looks like
> https://github.com/hardikdangar/test/archive/master.zip
> but it redirects to the following,
> https://codeload.github.com/hardikdangar/test/zip/master
> 
> You can see the response parameters via redbot.org
> https://redbot.org/?uri=https%3A%2F%2Fcodeload.github.com%
> 2Fhardikdangar%2Ftest%2Fzip%2Fmaster
> 
>   HTTP/1.1 200 OK
>     Content-Length: 929
>     Access-Control-Allow-Origin: https://render.githubusercontent.com
>     Content-Security-Policy: default-src 'none'; style-src 'unsafe-inline'
>     Strict-Transport-Security: max-age=31536000
>     Vary: Authorization,Accept-Encoding
>     X-Content-Type-Options: nosniff
>     X-Frame-Options: deny
>     X-XSS-Protection: 1; mode=block
>     ETag: "9ea9838812d6f7bc53763eb1577da04e2fa473d5"
>     Content-Type: application/zip
>     Content-Disposition: attachment; filename=test-master.zip
>     X-Geo-Block-List:
>     Date: Wed, 14 Sep 2016 23:24:44 GMT
>     X-GitHub-Request-Id: 77092BF1:7F40:346461:57D9DC3C
> 
> Now if i do any change to above repository github does change ETAG and if i
> don't change anything then ETAG remains the same so i believe we should be
> able to cache those .zip files.
> 
> By default, squid does not cache codeload.github.com, to put it into cache,
> I added,
> refresh_pattern codeload.github.com 900 20% 4320 reload-into-ims
> 
> Now as per my understanding this should check etag as Last-Modified is not
> provided by github for each new request. This does cache the zip file but
> what happens is in next request even if i change the content and etag
> changes squid sends the cached file from its cache instead of downloading
> new file.
> 
> I have no clue why this happens. Can anyone help me figure out what's wrong
> here? why squid does not detect new etag when repository is updated? why it
> sends cache file even though there is new file available.
> 

Consider: how does Squid know the ETag has changed on the server?

What you know about things happening in RL is not what Squid knows.

I fact how do *you* know someone else did not commit a change during
that ~1 second it takes to look at the page and click the download button?
 Simply, you don't, and cannot until the new object has been fetched.

Likewise, Squid cannot know if the object is the same until it has
fetched a MISS from the server. Except that Squid does not look at the
previous page content, so it cannot even 'see' if there is a commit
listed there that might be different since whenever it got the previous
object.

There is no Cache-Control or Expires header indicating a specific
storage timeout or revalidation procedure. So refresh_pattern defaults
will be used. These responses will be cached for the refresh_pattern
'Min' duration (900 minutes) before being considered for revalidated.


NP 1: Synthesizing Last-Modified from the Date header is only just being
fixed in Squid the past few weeks, and some parts of it still to be
committed. So I would not expect that response to be revalidated, just
re-fetched fully in older Squid.


NP 2: The Vary header indicates that every person logged in gets a
differently cached response based on how their credentials are hashed on
each request (in Authorization tokens). So caching these objects will
not help much with many developers involved. It will be of most help for
the anonymous visitors where username is always a generic NIL value.

HTH
Amos



From erdosain9 at gmail.com  Thu Sep 15 01:42:33 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 14 Sep 2016 18:42:33 -0700 (PDT)
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <11a31fcd-901a-351a-4f60-8b2fe054b224@measurement-factory.com>
References: <CAEpx-0X8QP6WELguYtkaQ_TJwQKo5qrXS_y60J9VUPi0ygB1cw@mail.gmail.com>
 <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
 <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>
 <6e65eafe-37aa-e6f2-9c04-e4e14b9ff3e9@gmail.com>
 <CAEpx-0WMruHcZBP=kpZO1+C4YnELpeYGy2=WYtKMY5zmTWuaBg@mail.gmail.com>
 <3c02e953-d2cb-7905-f52a-e036ed3e06ab@treenet.co.nz>
 <1473879398350-4679512.post@n4.nabble.com>
 <e730f7da-c6ce-808f-f454-2d7a0369a92b@measurement-factory.com>
 <1473894106709-4679515.post@n4.nabble.com>
 <11a31fcd-901a-351a-4f60-8b2fe054b224@measurement-factory.com>
Message-ID: <1473903753861-4679519.post@n4.nabble.com>

It is only my pc in the proxy. So , see the access.log is simple ... really ,
no more information than copied.

.....................either way, the website never finish loading 




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679519.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Thu Sep 15 02:01:16 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 14 Sep 2016 19:01:16 -0700 (PDT)
Subject: [squid-users] Cannot get ACL to work
In-Reply-To: <845626423.88462565.1473831824978.JavaMail.root@shaw.ca>
References: <845626423.88462565.1473831824978.JavaMail.root@shaw.ca>
Message-ID: <1473904876640-4679520.post@n4.nabble.com>

Hi.
What's your squid version??



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Cannot-get-ACL-to-work-tp4679502p4679520.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From fredbmail at free.fr  Thu Sep 15 08:53:27 2016
From: fredbmail at free.fr (FredB)
Date: Thu, 15 Sep 2016 10:53:27 +0200 (CEST)
Subject: [squid-users] Squid 3.5.21 ssl bump and x-forward
In-Reply-To: <1829656031.875795801.1473925899528.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <1137045505.876317557.1473929607708.JavaMail.root@zimbra4-e1.priv.proxad.net>

Hello,

I'm testing SSlBump and it works good, however I'm seeing something strange with two proxies and x-forwarded enabled to the first, some requests are wrote with the first proxy address. 

user -> squid (fowarded_for on) -> squid (follow_x_forwarded_for allow all) -> Net 

Here log from the second squids, on same server, (same result when there are separate 127.0.0.1 = IP FIRST SQUID) 

10.x.x.x.x - myaccount [15/Sep/2016:09:40:07 +0200] "CONNECT www.google.fr:443 HTTP/1.0" 200 0 440 TAG_NONE:HIER_NONE "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
10.x.x.x.x - myaccount [15/Sep/2016:09:40:07 +0200] "GET http://www.google.fr/ HTTP/1.0" 302 643 1575 TCP_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
10.x.x.x.x - myaccount [15/Sep/2016:09:40:07 +0200] "CONNECT www.google.fr:443 HTTP/1.0" 200 0 440 TAG_NONE:HIER_NONE "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
127.0.0.1 - myaccount [15/Sep/2016:09:40:07 +0200] "POST https://www.google.fr/gen_204?atyp=i&ct=slh&cad=&ei=EVDaV-rAOcS7adLmucAF&s=3&v=2&pv=0.19272099408438004&me=4:1473925301533,e,U&zx=1473925301536 HTTP/1.1" 204 401 1571 TCP_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
127.0.0.1 - myaccount [15/Sep/2016:09:40:08 +0200] "GET https://www.google.fr/?gws_rd=ssl HTTP/1.1" 200 61953 1387 TCP_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
127.0.0.1 - myaccount [15/Sep/2016:09:40:08 +0200] "POST https://www.google.fr/gen_204?atyp=i&ct=slh&cad=&ei=EVDaV-rAOcS7adLmucAF&s=4&v=2&pv=0.19272099408438004&me=5:1473925302218,e,H&zx=1473925302220 HTTP/1.1" 204 401 1571 TCP_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
127.0.0.1 - myaccount [15/Sep/2016:09:40:08 +0200] "GET https://www.google.fr/complete/search?sclient=psy-ab&site=&source=hp&q=&oq=&gs_l=&pbx=1&bav=on.2,or.r_cp.&fp=1&biw=995&bih=554&dpr=1.25&pf=p&gs_rn=64&gs_ri=psy-ab&tok=yZHeL-_L5Be_JazeSm0Mtg&cp=0&gs_id=0&xhr=t&tch=1&ech=1&psi=tVDaV7_DMsXqauCygeAF.1473925302436.1 HTTP/1.1" 200 913 1618 TCP_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
127.0.0.1 - myaccount [15/Sep/2016:09:40:08 +0200] "GET https://www.google.fr/gen_204?v=3&s=webhp&atyp=csi&ei=tVDaV7_DMsXqauCygeAF&imc=2&imn=2&imp=0&adh=&xjs=init.26.20.sb.18.p.3.jsa.1.abd.1.foot.1&ima=0&rt=xjsls.21,prt.41,iml.41,dcl.82,xjses.124,jraids.149,jraide.153,xjsee.185,xjs.185,ol.217,aft.41,wsrt.748,cst.1,dnst.0,rqst.522,rspt.533,rqstt.161,unt.143,cstt.144,dit.816 HTTP/1.1" 204 401 1616 TCP_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
10.x.x.x.x - myaccount [15/Sep/2016:09:40:08 +0200] "CONNECT plus.google.com:443 HTTP/1.0" 200 0 446 TAG_NONE:HIER_NONE "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
127.0.0.1 - myaccount [15/Sep/2016:09:40:08 +0200] "POST https://plus.google.com/u/0/_/n/gcosuc HTTP/1.1" 200 862 1388 TCP_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
10.x.x.x.x - myaccount [15/Sep/2016:09:40:18 +0200] "CONNECT p5-d67enuz43bu7a-hck6hyjacaic2rnf-280807-i1-v6exp3-v4.metric.gstatic.com:443 HTTP/1.0" 200 0 617 TAG_NONE:HIER_NONE "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
10.x.x.x.x - myaccount [15/Sep/2016:09:40:18 +0200] "CONNECT p5-d67enuz43bu7a-hck6hyjacaic2rnf-280807-i2-v6exp3-ds.metric.gstatic.com:443 HTTP/1.0" 200 0 617 TAG_NONE:HIER_NONE "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
127.0.0.1 - myaccount [15/Sep/2016:09:40:18 +0200] "GET https://p5-d67enuz43bu7a-hck6hyjacaic2rnf-280807-i2-v6exp3-ds.metric.gstatic.com/v6exp3/6.gif HTTP/1.1" 200 1214 702 TCP_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
127.0.0.1 - myaccount [15/Sep/2016:09:40:18 +0200] "GET https://p5-d67enuz43bu7a-hck6hyjacaic2rnf-280807-i1-v6exp3-v4.metric.gstatic.com/v6exp3/6.gif HTTP/1.1" 200 1214 702 TCP_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
10.x.x.x.x - myaccount [15/Sep/2016:09:40:48 +0200] "CONNECT p5-d67enuz43bu7a-hck6hyjacaic2rnf-280807-s1-v6exp3-v4.metric.gstatic.com:443 HTTP/1.0" 200 0 617 TAG_NONE:HIER_NONE "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
127.0.0.1 - myaccount [15/Sep/2016:09:40:48 +0200] "GET https://p5-d67enuz43bu7a-hck6hyjacaic2rnf-280807-s1-v6exp3-v4.metric.gstatic.com/gen_204?ipv6exp=3&sentinel=1&v4_img_dt=270&ds_img_dt=253 HTTP/1.1" 204 1393 601 TCP_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 

Fred



From squid3 at treenet.co.nz  Thu Sep 15 10:18:45 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 15 Sep 2016 22:18:45 +1200
Subject: [squid-users] Squid 3.5.21 ssl bump and x-forward
In-Reply-To: <1137045505.876317557.1473929607708.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1137045505.876317557.1473929607708.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <801c5135-4270-4c86-6c3a-49ba4cf6296f@treenet.co.nz>

On 15/09/2016 8:53 p.m., FredB wrote:
> Hello,
> 
> I'm testing SSlBump and it works good, however I'm seeing something strange with two proxies and x-forwarded enabled to the first, some requests are wrote with the first proxy address. 
> 
> user -> squid (fowarded_for on) -> squid (follow_x_forwarded_for allow all) -> Net 
> 
> Here log from the second squids, on same server, (same result when there are separate 127.0.0.1 = IP FIRST SQUID) 
> 
> 10.x.x.x.x - myaccount [15/Sep/2016:09:40:07 +0200] "CONNECT www.google.fr:443 HTTP/1.0" 200 0 440 TAG_NONE:HIER_NONE "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
> 10.x.x.x.x - myaccount [15/Sep/2016:09:40:07 +0200] "GET http://www.google.fr/ HTTP/1.0" 302 643 1575 TCP_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
> 10.x.x.x.x - myaccount [15/Sep/2016:09:40:07 +0200] "CONNECT www.google.fr:443 HTTP/1.0" 200 0 440 TAG_NONE:HIER_NONE "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 

Above are HTTP requests sent from proxy #1 to proxy #2.

> 127.0.0.1 - myaccount [15/Sep/2016:09:40:07 +0200] "POST https://www.google.fr/gen_204?atyp=i&ct=slh&cad=&ei=EVDaV-rAOcS7adLmucAF&s=3&v=2&pv=0.19272099408438004&me=4:1473925301533,e,U&zx=1473925301536 HTTP/1.1" 204 401 1571 TCP_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
> 127.0.0.1 - myaccount [15/Sep/2016:09:40:08 +0200] "GET https://www.google.fr/?gws_rd=ssl HTTP/1.1" 200 61953 1387 TCP_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
> 127.0.0.1 - myaccount [15/Sep/2016:09:40:08 +0200] "POST https://www.google.fr/gen_204?atyp=i&ct=slh&cad=&ei=EVDaV-rAOcS7adLmucAF&s=4&v=2&pv=0.19272099408438004&me=5:1473925302218,e,H&zx=1473925302220 HTTP/1.1" 204 401 1571 TCP_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
> 127.0.0.1 - myaccount [15/Sep/2016:09:40:08 +0200] "GET https://www.google.fr/complete/search?sclient=psy-ab&site=&source=hp&q=&oq=&gs_l=&pbx=1&bav=on.2,or.r_cp.&fp=1&biw=995&bih=554&dpr=1.25&pf=p&gs_rn=64&gs_ri=psy-ab&tok=yZHeL-_L5Be_JazeSm0Mtg&cp=0&gs_id=0&xhr=t&tch=1&ech=1&psi=tVDaV7_DMsXqauCygeAF.1473925302436.1 HTTP/1.1" 200 913 1618 TCP_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 
> 127.0.0.1 - myaccount [15/Sep/2016:09:40:08 +0200] "GET https://www.google.fr/gen_204?v=3&s=webhp&atyp=csi&ei=tVDaV7_DMsXqauCygeAF&imc=2&imn=2&imp=0&adh=&xjs=init.26.20.sb.18.p.3.jsa.1.abd.1.foot.1&ima=0&rt=xjsls.21,prt.41,iml.41,dcl.82,xjses.124,jraids.149,jraide.153,xjsee.185,xjs.185,ol.217,aft.41,wsrt.748,cst.1,dnst.0,rqst.522,rspt.533,rqstt.161,unt.143,cstt.144,dit.816 HTTP/1.1" 204 401 1616 TCP_MISS:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; rv:48.0) Gecko/20100101 Firefox/48.0" 

Above are bumped requests sent inside the tunnel. Proxy #1 did not
interact with them, so it has no way to add XFF headers.

The SSL-Bump logic does not yet store some things like indirect client
IP and associate them with the bumped requests.

Amos



From fredbmail at free.fr  Thu Sep 15 10:54:10 2016
From: fredbmail at free.fr (FredB)
Date: Thu, 15 Sep 2016 12:54:10 +0200 (CEST)
Subject: [squid-users] Squid 3.5.21 ssl bump and x-forward
In-Reply-To: <801c5135-4270-4c86-6c3a-49ba4cf6296f@treenet.co.nz>
Message-ID: <2063513699.877590939.1473936850830.JavaMail.root@zimbra4-e1.priv.proxad.net>


> 
> Above are bumped requests sent inside the tunnel. Proxy #1 did not
> interact with them, so it has no way to add XFF headers.
> 
> The SSL-Bump logic does not yet store some things like indirect
> client
> IP and associate them with the bumped requests.
> 
> Amos
> 


Ok thank you, there is a plan to add this ? Without identification we are in the fog all bumped requests are only recorded with 127.0.0.1

Fred


From squid3 at treenet.co.nz  Thu Sep 15 12:44:24 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 16 Sep 2016 00:44:24 +1200
Subject: [squid-users] Squid 3.5.21 ssl bump and x-forward
In-Reply-To: <2063513699.877590939.1473936850830.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <2063513699.877590939.1473936850830.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <7405158d-40a3-53de-b933-09482cb9ac5a@treenet.co.nz>

On 15/09/2016 10:54 p.m., FredB wrote:
> 
>>
>> Above are bumped requests sent inside the tunnel. Proxy #1 did not
>> interact with them, so it has no way to add XFF headers.
>>
>> The SSL-Bump logic does not yet store some things like indirect
>> client
>> IP and associate them with the bumped requests.
>>
>> Amos
>>
> 
> 
> Ok thank you, there is a plan to add this ? Without identification we are in the fog all bumped requests are only recorded with 127.0.0.1
> 

Eventually, yes. I'm not aware of anyone actually working on it at
present though.

Amos



From ahmed.zaeem at netstream.ps  Thu Sep 15 12:48:50 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Thu, 15 Sep 2016 15:48:50 +0300
Subject: [squid-users] windows update not working squid 3.5.2
In-Reply-To: <02d501d20ec4$834bd690$89e383b0$@ngtech.co.il>
References: <763AFEA6-52DE-4DCB-805D-DA1136933178@netstream.ps>
 <20f02386-6272-0489-4f31-4f41051a1fa0@gmail.com>
 <A2612C06-B8D6-4BDA-BAE1-03E566565C67@netstream.ps>
 <02d501d20ec4$834bd690$89e383b0$@ngtech.co.il>
Message-ID: <B864901A-A0D1-4DC2-9630-2C5C82E7C95F@netstream.ps>

he eliezer 
right now i moved from arm to intel 
I?m using real pc
 i will  test the arm solution tomorrow .

for now i hope u can assist .

i got with ur advice and used now the store id solution .

but so far i have the hdd increase then suddenly decrease and so on
Thu 15 Sep 13:29:25 BST 2016
357M /cache/
Thu 15 Sep 13:29:40 BST 2016
335M /cache/
Thu 15 Sep 13:29:55 BST 2016
360M /cache/
Thu 15 Sep 13:30:10 BST 2016
472M /cache/
Thu 15 Sep 13:30:25 BST 2016
580M /cache/
Thu 15 Sep 13:30:40 BST 2016
656M /cache/
Thu 15 Sep 13:30:55 BST 2016
690M /cache/
Thu 15 Sep 13:31:11 BST 2016
543M /cache/
Thu 15 Sep 13:31:26 BST 2016
607M /cache/
Thu 15 Sep 13:31:41 BST 2016
438M /cache/

================

I?m sure there is wrong settings 

here is squid.conf as u asked the format 
http://pastebin.com/ySt7e9iu


here is store.log file 
http://pastebin.com/FtxWZirc

i didn?t see any TCP_HIT in access.log 

http://pastebin.com/LunBmLgf



again I?m sure the config above is not fine with windows 10 updates and so far I?m stuck and not able to have it working and caching correctly .



> On Sep 14, 2016, at 11:13 PM, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> 
> Hey Ahmad,
>  




a
> Try the new version of ms-updates from:
> http://ngtech.co.il/ms-updates-store/ <http://ngtech.co.il/ms-updates-store/>
> http://www1.ngtech.co.il/wpe/?page_id=301 <http://www1.ngtech.co.il/wpe/?page_id=301>
>  
> Since you are using an armX based system.
> From my point of view on things I do not see the difference between other traffic to MS updates.
> Windows Updates are HTTP requests and responses which are identical to other objects.
> When a proxy or a service starts to see these things with "new" perspective my assumption is that something with either RAM or CPU or DISK is wrong and couple simple objects will clear out things about the proxy state.
> 
> What I need is a testing use case from the squid world jargon.
> Are you using an Intercept proxy?
> If so what type of Interception? Tproxy or Intercept?
> What objects did you tried until now? Only Windows Updates?
> Do you have a dump of these requests?(you can use http://wiki.squid-cache.org/KnowledgeBase/DebugSections <http://wiki.squid-cache.org/KnowledgeBase/DebugSections>)
> The dumps should be using section 11 ie: debug_options ALL,1 11,6
> With these dumps we need the corresponding access.log.
> These should be enough to think about things and maybe re-test them.
> Also What OS are you using?
>  
> Eliezer
>  
> ----
> Eliezer Croitoru <http://ngtech.co.il/lmgtfy/>
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il <mailto:eliezer at ngtech.co.il>
> <image002.png>
>  
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of --Ahmad--
> Sent: Tuesday, September 6, 2016 8:08 PM
> To: Yuri Voinov
> Cc: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] windows update not working squid 3.5.2
>  
> /driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab - ORIGINAL_DST/8.253.13.30 application/octet-stream
> 1473181228.768   1202 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.70.206 application/octet-stream
> 1473181229.117   1159 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.253.70.206 application/octet-stream
> 1473181229.265    984 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.13.46 application/octet-stream
> 1473181229.525   1207 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.13.46 application/octet-stream
> 1473181230.066   1314 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.253.70.206 application/octet-stream
> 1473181230.147    913 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.253.13.46 application/octet-stream
> 1473181230.166   1659 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.253.13.30 application/octet-stream
> 1473181230.438   1233 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.13.30 application/octet-stream
> 1473181230.461   1569 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.13.46 application/octet-stream
> 1473181230.621   1023 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.253.13.46 application/octet-stream
> 1473181231.143   1219 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.13.46 application/octet-stream
> 1473181231.166   1212 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.13.46 application/octet-stream
> 1473181231.528   1131 192.168.0.10 TCP_MISS/206 1049142 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.253.13.46 application/octet-stream
> 1473181231.601   1416 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.253.13.30 application/octet-stream
> 1473181231.784    938 192.168.0.10 TCP_MISS/206 1049144 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.13.46 application/octet-stream
> 1473181232.102   1565 192.168.0.10 TCP_MISS/206 1049142 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/defu/2016/08/am_base_9668287df050e32ce73537e6505b5101ec5dc7f0.exe> - ORIGINAL_DST/8.253.70.206 application/octet-stream
> 1473181232.330   1453 192.168.0.10 TCP_MISS/206 1049146 GET http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab <http://fg.v4.download.windowsupdate.com/d/msdownload/update/driver/drvs/2015/10/200006767_cec6101480492a8c7be6e668ff3284626a787359.cab> - ORIGINAL_DST/8.253.70.206 application/octet-stream
> 
> 
> with squid.conf :
> #########
> acl windowsupdate dstdomain windowsupdate.microsoft.com <http://windowsupdate.microsoft.com/>
> acl windowsupdate dstdomain .update.microsoft.com <http://update.microsoft.com/>
> acl windowsupdate dstdomain download.windowsupdate.com <http://download.windowsupdate.com/>
> acl windowsupdate dstdomain redir.metaservices.microsoft.com <http://redir.metaservices.microsoft.com/>
> acl windowsupdate dstdomain images.metaservices.microsoft.com <http://images.metaservices.microsoft.com/>
> acl windowsupdate dstdomain c.microsoft.com <http://c.microsoft.com/>
> acl windowsupdate dstdomain www.download.windowsupdate.com <http://www.download.windowsupdate.com/>
> acl windowsupdate dstdomain wustat.windows.com <http://wustat.windows.com/>
> acl windowsupdate dstdomain crl.microsoft.com <http://crl.microsoft.com/>
> acl windowsupdate dstdomain sls.microsoft.com <http://sls.microsoft.com/>
> acl windowsupdate dstdomain productactivation.one.microsoft.com <http://productactivation.one.microsoft.com/>
> acl windowsupdate dstdomain ntservicepack.microsoft.com <http://ntservicepack.microsoft.com/>
> 
> acl CONNECT method CONNECT
> acl wuCONNECT dstdomain www.update.microsoft.com <http://www.update.microsoft.com/>
> acl wuCONNECT dstdomain sls.microsoft.com <http://sls.microsoft.com/>
> 
> #http_access allow CONNECT wuCONNECT localnet
> #http_access allow windowsupdate localnet
> #######################
> # Updates: Windows
> refresh_pattern -i windowsupdate.com/.* <http://windowsupdate.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
> refresh_pattern -i microsoft.com/.* <http://microsoft.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
> refresh_pattern -i windows.com/.* <http://windows.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
> refresh_pattern -i microsoft.com.akadns.net/.* <http://microsoft.com.akadns.net/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
> refresh_pattern -i deploy.akamaitechnologies.com/.* <http://deploy.akamaitechnologies.com/.*>\.(cab|exe|ms[i|u|f|p]|[ap]sf|wm[v|a]|dat|zip|psf) 43200 80% 129600 reload-into-ims
> ###########
> #refresh_pattern -i microsoft.com/.* <http://microsoft.com/.*>\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
> #refresh_pattern -i windowsupdate.com/.* <http://windowsupdate.com/.*>\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
> #refresh_pattern -i windows.com/.* <http://windows.com/.*>\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80% 43200 reload-into-ims
> # DONT MODIFY THESE LINES
> refresh_pattern \^ftp:           1440    20%     10080
> refresh_pattern \^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> #################################################################
> ###########################
> #
> # Recommended minimum configuration:
> #
> 
> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
> 
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> 
> #
> # Recommended minimum Access Permission configuration:
> #
> # Deny requests to certain unsafe ports
> http_access allow CONNECT wuCONNECT localnet
> http_access allow windowsupdate localnet
> http_access deny !Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
> 
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
> 
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> #http_access deny to_localhost
> 
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> 
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
> 
> # And finally deny all other access to this proxy
> http_access deny all
> 
> # Squid normally listens to port 3128
> http_port 192.168.0.1:3128
> 
> # Uncomment and adjust the following to add a disk cache directory.
> cache_dir ufs /var/cache/squid 20000 16 256
> 
> # Leave coredumps in the first cache dir
> coredump_dir /var/cache/squid
> 
> #
> # Add any of your own refresh_pattern entries above these.
> #
> #refresh_pattern ^ftp:          1440    20%     10080
> #refresh_pattern ^gopher:       1440    0%      1440
> #refresh_pattern -i (/cgi-bin/|\?) 0    0%      0
> #refresh_pattern .              0       20%     4320
> #############
> range_offset_limit 5 Gb windowsupdate
> maximum_object_size 5 Gb
> quick_abort_min -1
> #########
> http_port 3129 intercept
> #####################
>> On Sep 6, 2016, at 6:01 PM, Yuri Voinov <yvoinov at gmail.com <mailto:yvoinov at gmail.com>> wrote:
>>  
>> 
>> -----BEGIN PGP SIGNED MESSAGE-----
>> Hash: SHA256
>> 
>> http://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates <http://wiki.squid-cache.org/ConfigExamples/Caching/WindowsUpdates>
>> 
>> Did you read this?
>> 
>> 
>> 06.09.2016 20:59, --Ahmad-- ?????:
>> 
>>> hi squid users .
>>> 
>>> I?m trying to catch windows updates as cached object
>>> im testing with  windows 10 pc
>>> 
>>> i see all request as tcp_miss and the caching store is not getting
>> increase .
>> 
>>> 
>>> =========
>>> 1473173748.014   3603 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173748.022  12146 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173748.057   5321 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173748.155   3684 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173748.355   4832 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173748.612  12645 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173748.650   7276 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173748.720  12654 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173748.816   5064 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173749.022   4159 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173749.048   5618 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173749.177   7817 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173749.208   3383 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173749.318   5096 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173749.395   3986 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173749.850  13837 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173750.015    914 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173750.029   1365 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 1473173750.420   7126 192.168.0.10 TCP_MISS/206 1049229 GET
>> http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf <http://fg.v4.download.windowsupdate.com/d/msdownload/update/software/crup/2016/08/windows10.0-kb3176938-x64_6e080b0ebebeb8a463a297f5b14fcd03690eb1b8.psf>
>> - ORIGINAL_DST/13.107.4.50 application/octet-stream
>> 
>>> 
>>> =======================
>>> 
>>> root at raspberrypi:~# du -sh /var/cache/squid/
>>> 17M     /var/cache/squid/
>>> root at raspberrypi:~# du -sh /var/cache/squid/
>>> 17M     /var/cache/squid/
>>> root at raspberrypi:~# du -sh /var/cache/squid/
>>> 17M     /var/cache/squid/
>>> root at raspberrypi:~# du -sh /var/cache/squid/
>>> 17M     /var/cache/squid/
>>> root at raspberrypi:~# du -sh /var/cache/squid/
>>> 17M     /var/cache/squid/
>>> root at raspberrypi:~# du -sh /var/cache/squid/
>>> 17M     /var/cache/squid/
>>> root at raspberrypi:~# du -sh /var/cache/squid/
>>> 17M     /var/cache/squid/
>>> root at raspberrypi:~# du -sh /var/cache/squid/
>>> 17M     /var/cache/squid/
>>> root at raspberrypi:~# du -sh /var/cache/squid/
>>> 17M     /var/cache/squid/
>>> root at raspberrypi:~# du -sh /var/cache/squid/
>>> 17M     /var/cache/squid/
>>> root at raspberrypi:~# du -sh /var/cache/squid/
>>> 17M     /var/cache/squid/
>>> root at raspberrypi:~# du -sh /var/cache/squid/
>>> 17M     /var/cache/squid/
>>> root at raspberrypi:~# du -sh /var/cache/squid/
>>> 17M     /var/cache/squid/
>>> root at raspberrypi:~#
>>> 
>>> ==============
>>> here is squid config :
>>> 
>>> root at raspberrypi:~# cat /etc/squid/squid.conf
>>> #########
>>> acl windowsupdate dstdomain windowsupdate.microsoft.com
>>> acl windowsupdate dstdomain .update.microsoft.com
>>> acl windowsupdate dstdomain download.windowsupdate.com
>>> acl windowsupdate dstdomain redir.metaservices.microsoft.com
>>> acl windowsupdate dstdomain images.metaservices.microsoft.com
>>> acl windowsupdate dstdomain c.microsoft.com
>>> acl windowsupdate dstdomain www.download.windowsupdate.com <http://www.download.windowsupdate.com/>
>>> acl windowsupdate dstdomain wustat.windows.com
>>> acl windowsupdate dstdomain crl.microsoft.com
>>> acl windowsupdate dstdomain sls.microsoft.com
>>> acl windowsupdate dstdomain productactivation.one.microsoft.com
>>> acl windowsupdate dstdomain ntservicepack.microsoft.com
>>> 
>>> acl CONNECT method CONNECT
>>> acl wuCONNECT dstdomain www.update.microsoft.com <http://www.update.microsoft.com/>
>>> acl wuCONNECT dstdomain sls.microsoft.com
>>> 
>>> #######################
>>> refresh_pattern -i
>> microsoft.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
>> 43200 reload-into-ims
>> 
>>> refresh_pattern -i
>> windowsupdate.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320
>> 80% 43200 reload-into-ims
>> 
>>> refresh_pattern -i
>> windows.com/.*\.(cab|exe|ms[i|u|f]|[ap]sf|wm[v|a]|dat|zip) 4320 80%
>> 43200 reload-into-ims
>> 
>>> # DONT MODIFY THESE LINES
>>> refresh_pattern \^ftp:           1440    20%     10080
>>> refresh_pattern \^gopher:        1440    0%      1440
>>> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
>>> refresh_pattern .               0       20%     4320
>>> #################################################################
>>> ###########################
>>> #
>>> # Recommended minimum configuration:
>>> #
>>> 
>>> # Example rule allowing access from your local networks.
>>> # Adapt to list your (internal) IP networks from where browsing
>>> # should be allowed
>>> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
>>> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
>>> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
>>> acl localnet src fc00::/7       # RFC 4193 local private network range
>>> acl localnet src fe80::/10      # RFC 4291 link-local (directly
>> plugged) machines
>> 
>>> 
>>> acl SSL_ports port 443
>>> acl Safe_ports port 80          # http
>>> acl Safe_ports port 21          # ftp
>>> acl Safe_ports port 443         # https
>>> acl Safe_ports port 70          # gopher
>>> acl Safe_ports port 210         # wais
>>> acl Safe_ports port 1025-65535  # unregistered ports
>>> acl Safe_ports port 280         # http-mgmt
>>> acl Safe_ports port 488         # gss-http
>>> acl Safe_ports port 591         # filemaker
>>> acl Safe_ports port 777         # multiling http
>>> acl CONNECT method CONNECT
>>> 
>>> 
>>> http_access allow CONNECT wuCONNECT localnet
>>> http_access allow windowsupdate localnet
>>> http_access deny !Safe_ports
>>> 
>>> # Deny CONNECT to other than secure SSL ports
>>> http_access deny CONNECT !SSL_ports
>>> 
>>> # Only allow cachemgr access from localhost
>>> http_access allow localhost manager
>>> http_access deny manager
>>> 
>>> 
>>> http_access allow localnet
>>> http_access allow localhost
>>> 
>>> # And finally deny all other access to this proxy
>>> http_access deny all
>>> 
>>> # Squid normally listens to port 3128
>>> http_port 192.168.0.1:3128
>>> 
>>> # Uncomment and adjust the following to add a disk cache directory.
>>> cache_dir ufs /var/cache/squid 100 16 256
>>> 
>>> # Leave coredumps in the first cache dir
>>> coredump_dir /var/cache/squid
>>> 
>>> 
>>> #############
>>> range_offset_limit 200 MB windowsupdate
>>> maximum_object_size 200 MB
>>> quick_abort_min -1
>>> #########
>>> http_port 3129 intercept
>>> maximum_object_size 200000 KB
>>> 
>>> 
>>> 
>>> 
>>> thank you
>>> 
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
>>> http://lists.squid-cache.org/listinfo/squid-users <http://lists.squid-cache.org/listinfo/squid-users>
>> -----BEGIN PGP SIGNATURE-----
>> Version: GnuPG v2
>> 
>> iQEcBAEBCAAGBQJXztpBAAoJENNXIZxhPexGSx4H/0bK8485yWhpNbGUIGtwvx9h
>> PTuRhfJP+f8xoTbTh/zH1TgXs21M953uf5DoYlynMBSeVXCfQQiUhDOs+0bqAjfD
>> JsLCXVpZdSYYWyX2aErjfZqKQO67aVkX+zJbAY/zlTJKG6Gxg1+ssQSEJaFWu6cK
>> J8KBudfWaKmPc9xdiZRfYFE6LKBSeQr93BqBF6s1SwdAPKEkspQmDTuqPZEwMwW5
>> zQfuI/HnIvynSE+SxCFYOAwka2zVAdewXfVyWqYyFCHaHnDkXkPmK/5zZJDOmqGi
>> erifbGQHRHAFWNnT4mMsHGjM3Wfz1bbhr+j+tZJkY4x116eVUMrVbbXRApY5nn0=
>> =ZaFG
>> -----END PGP SIGNATURE-----
>> 
>> <0x613DEC46.asc>_______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
>> http://lists.squid-cache.org/listinfo/squid-users <http://lists.squid-cache.org/listinfo/squid-users>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160915/cbb097e2/attachment.htm>

From vze2k3sa at verizon.net  Thu Sep 15 13:31:05 2016
From: vze2k3sa at verizon.net (Patrick Flaherty)
Date: Thu, 15 Sep 2016 09:31:05 -0400
Subject: [squid-users] Preserving Squid.conf when upgrading
Message-ID: <006301d20f55$698e0e80$3caa2b80$@verizon.net>

Hi,

 

For the Windows version of Squid from the good folks at Diladele, will it
ever preserve the squid.conf file when uninstalling and reinstalling
(upgrading)?

 

Thank you,

Patrick

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160915/8ba9fb2e/attachment.htm>

From ahmed.zaeem at netstream.ps  Thu Sep 15 14:17:30 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Thu, 15 Sep 2016 17:17:30 +0300
Subject: [squid-users] NgTech Caching solution problem
Message-ID: <6AB2AA6C-E12C-4718-9508-B8E6A1DDDCAD@netstream.ps>


Hi all  , 
dear eliezer 


i tried the  NgTech solution  on AMD cpu but the caching still 0 !!.

==================

i have debian 64 bits 
already had the bin file and moved to /usr/bin

################
root at debian:~# cat fetch-task.sh 
#!/usr/bin/env bash

lockfile -r 0 /tmp/store-fetcher.lock || exit 1

/usr/bin/ms-updates-fetcher-helper_linux_amd64 -dir=/cache

echo ""
echo ""
echo "removing lock file: /tmp/store-fetcher.lock"
rm -f /tmp/store-fetcher.lock

root at debian:~# 
##################


i run the script now fetch-task.sh
###############################################
root at debian:~# bash fetch-task.sh 
2016/09/15 14:35:43 storing cached resources in /cache


removing lock file: /tmp/store-fetcher.lock
root at debian:~# 


then i  run squid

squid


below are logs >>>>>>>>


###################################

root at debian:~# squid -k parse
2016/09/15 14:30:13| Startup: Initializing Authentication Schemes ...
2016/09/15 14:30:13| Startup: Initialized Authentication Scheme 'basic'
2016/09/15 14:30:13| Startup: Initialized Authentication Scheme 'digest'
2016/09/15 14:30:13| Startup: Initialized Authentication Scheme 'negotiate'
2016/09/15 14:30:13| Startup: Initialized Authentication Scheme 'ntlm'
2016/09/15 14:30:13| Startup: Initialized Authentication.
2016/09/15 14:30:13| Processing Configuration File: /etc/squid/squid.conf (depth 0)
2016/09/15 14:30:13| Processing: acl wu dstdom_regex \.download\.windowsupdate\.com$
2016/09/15 14:30:13| Processing: acl wu-rejects dstdom_regex stats
2016/09/15 14:30:13| Processing: acl GET method GET
2016/09/15 14:30:13| Processing: cache_peer 127.0.0.1 parent 8080 0 proxy-only no-tproxy no-digest no-query no-netdb-exchange name=ms1
2016/09/15 14:30:13| Processing: cache_peer_access ms1 allow GET wu !wu-rejects
2016/09/15 14:30:13| Processing: cache_peer_access ms1 deny all
2016/09/15 14:30:13| Processing: never_direct allow GET wu !wu-rejects
2016/09/15 14:30:13| Processing: never_direct deny all
2016/09/15 14:30:13| Processing: acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
2016/09/15 14:30:13| Processing: acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
2016/09/15 14:30:13| Processing: acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
2016/09/15 14:30:13| Processing: acl localnet src fc00::/7       # RFC 4193 local private network range
2016/09/15 14:30:13| Processing: acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
2016/09/15 14:30:13| Processing: acl SSL_ports port 443
2016/09/15 14:30:13| Processing: acl Safe_ports port 80          # http
2016/09/15 14:30:13| Processing: acl Safe_ports port 21          # ftp
2016/09/15 14:30:13| Processing: acl Safe_ports port 443         # https
2016/09/15 14:30:13| Processing: acl Safe_ports port 70          # gopher
2016/09/15 14:30:13| Processing: acl Safe_ports port 210         # wais
2016/09/15 14:30:13| Processing: acl Safe_ports port 1025-65535  # unregistered ports
2016/09/15 14:30:13| Processing: acl Safe_ports port 280         # http-mgmt
2016/09/15 14:30:13| Processing: acl Safe_ports port 488         # gss-http
2016/09/15 14:30:13| Processing: acl Safe_ports port 591         # filemaker
2016/09/15 14:30:13| Processing: acl Safe_ports port 777         # multiling http
2016/09/15 14:30:13| Processing: acl CONNECT method CONNECT
2016/09/15 14:30:13| Processing: http_access allow localnet
2016/09/15 14:30:13| Processing: http_access allow localhost
2016/09/15 14:30:13| Processing: http_access  deny all
2016/09/15 14:30:13| Processing: http_port 3128
2016/09/15 14:30:13| Processing: http_port 3129 intercept
2016/09/15 14:30:13| Starting Authentication on port [::]:3129
2016/09/15 14:30:13| Disabling Authentication on port [::]:3129 (interception enabled)
2016/09/15 14:30:13| Processing: maximum_object_size 5000 MB
2016/09/15 14:30:13| Processing: cache_store_log /var/log/squid/store.log
2016/09/15 14:30:13| Processing: access_log daemon:/var/log/squid/access.log squid
2016/09/15 14:30:13| Processing: cache_log /var/log/squid/cache.log
2016/09/15 14:30:13| Initializing https proxy context
root at debian:~# tailf /var/log/squid/cache.log 
2016/09/15 14:28:14 kid1| Using Least Load store dir selection
2016/09/15 14:28:14 kid1| Current Directory is /root
2016/09/15 14:28:14 kid1| Finished loading MIME types and icons.
2016/09/15 14:28:14 kid1| HTCP Disabled.
2016/09/15 14:28:14 kid1| Configuring Parent 127.0.0.1/8080/0
2016/09/15 14:28:14 kid1| Squid plugin modules loaded: 0
2016/09/15 14:28:14 kid1| Adaptation support is off.
2016/09/15 14:28:14 kid1| Accepting HTTP Socket connections at local=[::]:3128 remote=[::] FD 12 flags=9
2016/09/15 14:28:14 kid1| Accepting NAT intercepted HTTP Socket connections at local=[::]:3129 remote=[::] FD 13 flags=41
2016/09/15 14:28:15 kid1| storeLateRelease: released 0 objects
###############################################
root at debian:~# cat /etc/squid/squid.conf
acl wu dstdom_regex \.download\.windowsupdate\.com$
acl wu-rejects dstdom_regex stats
acl GET method GET
cache_peer 127.0.0.1 parent 8080 0 proxy-only no-tproxy no-digest no-query no-netdb-exchange name=ms1
cache_peer_access ms1 allow GET wu !wu-rejects
cache_peer_access ms1 deny all
never_direct allow GET wu !wu-rejects
never_direct deny all
###############
#strip_query_terms off
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
 
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT
 
http_access allow localnet
http_access allow localhost
 
# And finally deny all other access to this proxy
http_access  deny all
 
 
http_port 3128
http_port 3129 intercept
 
#cache_dir ufs /cache 45000 16 256
 
maximum_object_size 5000 MB
 
cache_store_log /var/log/squid/store.log
access_log daemon:/var/log/squid/access.log squid
cache_log /var/log/squid/cache.log
 
#coredump_dir /cache
 

###############################



for the access_logs

e/files/46f445a5-4b69-4636-8d45-5154fadf0011? - ORIGINAL_DST/13.107.4.50 -
1473946597.093    898 10.10.10.118 TCP_MISS/206 1049474 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/46f445a5-4b69-4636-8d45-5154fadf0011? - ORIGINAL_DST/13.107.4.50 -
1473946597.119    593 10.10.10.118 TCP_MISS/206 1049474 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/46f445a5-4b69-4636-8d45-5154fadf0011? - ORIGINAL_DST/13.107.4.50 -
1473946597.151    847 10.10.10.118 TCP_MISS/206 1049474 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/46f445a5-4b69-4636-8d45-5154fadf0011? - ORIGINAL_DST/13.107.4.50 -
1473946597.294    781 10.10.10.118 TCP_MISS/206 1049474 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/46f445a5-4b69-4636-8d45-5154fadf0011? - ORIGINAL_DST/13.107.4.50 -
1473946597.404   1199 10.10.10.118 TCP_MISS/206 1049474 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/46f445a5-4b69-4636-8d45-5154fadf0011? - ORIGINAL_DST/13.107.4.50 -
1473946598.900     13 10.10.10.118 TCP_MISS/200 880 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/f016d99d-9dd6-4ea8-87b6-b8d001939b19? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946598.922     12 10.10.10.118 TCP_MISS/200 880 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/f016d99d-9dd6-4ea8-87b6-b8d001939b19? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946598.924     13 10.10.10.118 TCP_MISS/200 880 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/f016d99d-9dd6-4ea8-87b6-b8d001939b19? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946598.926     13 10.10.10.118 TCP_MISS/200 880 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/f016d99d-9dd6-4ea8-87b6-b8d001939b19? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946598.927     13 10.10.10.118 TCP_MISS/200 880 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/f016d99d-9dd6-4ea8-87b6-b8d001939b19? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946599.139    208 10.10.10.118 TCP_MISS/206 947564 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/f016d99d-9dd6-4ea8-87b6-b8d001939b19? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946603.805     13 10.10.10.118 TCP_MISS/200 871 HEAD http://dl.delivery.mp.microsoft.com/filestreamingservice/files/0a6da74d-d64d-4586-91c5-d81904b94a22 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946603.827     13 10.10.10.118 TCP_CLIENT_REFRESH_MISS/200 870 HEAD http://dl.delivery.mp.microsoft.com/filestreamingservice/files/0a6da74d-d64d-4586-91c5-d81904b94a22 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946603.828     13 10.10.10.118 TCP_CLIENT_REFRESH_MISS/200 870 HEAD http://dl.delivery.mp.microsoft.com/filestreamingservice/files/0a6da74d-d64d-4586-91c5-d81904b94a22 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946603.830     13 10.10.10.118 TCP_CLIENT_REFRESH_MISS/200 870 HEAD http://dl.delivery.mp.microsoft.com/filestreamingservice/files/0a6da74d-d64d-4586-91c5-d81904b94a22 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946603.838     19 10.10.10.118 TCP_CLIENT_REFRESH_MISS/200 870 HEAD http://dl.delivery.mp.microsoft.com/filestreamingservice/files/0a6da74d-d64d-4586-91c5-d81904b94a22 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946603.858     28 10.10.10.118 TCP_MISS/206 69093 GET http://dl.delivery.mp.microsoft.com/filestreamingservice/files/0a6da74d-d64d-4586-91c5-d81904b94a22 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946603.865     33 10.10.10.118 TCP_MISS/206 69093 GET http://dl.delivery.mp.microsoft.com/filestreamingservice/files/0a6da74d-d64d-4586-91c5-d81904b94a22 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946603.873     39 10.10.10.118 TCP_MISS/206 69093 GET http://dl.delivery.mp.microsoft.com/filestreamingservice/files/0a6da74d-d64d-4586-91c5-d81904b94a22 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946603.880     39 10.10.10.118 TCP_MISS/206 69093 GET http://dl.delivery.mp.microsoft.com/filestreamingservice/files/0a6da74d-d64d-4586-91c5-d81904b94a22 - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946605.237     20 10.10.10.118 TCP_MISS/200 3357 GET http://dl.delivery.mp.microsoft.com/filestreamingservice//files/b6f13875-0aa9-49bc-8e64-c8f8ec7a7349/pieceshash - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946605.284     12 10.10.10.118 TCP_MISS/200 876 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/b6f13875-0aa9-49bc-8e64-c8f8ec7a7349? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946605.285     12 10.10.10.118 TCP_MISS/200 876 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/b6f13875-0aa9-49bc-8e64-c8f8ec7a7349? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946605.287     13 10.10.10.118 TCP_MISS/200 876 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/b6f13875-0aa9-49bc-8e64-c8f8ec7a7349? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946605.295     16 10.10.10.118 TCP_MISS/200 876 HEAD http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/b6f13875-0aa9-49bc-8e64-c8f8ec7a7349? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946605.501    215 10.10.10.118 TCP_MISS/206 976116 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/b6f13875-0aa9-49bc-8e64-c8f8ec7a7349? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946609.120    178 10.10.10.118 TCP_MISS/206 1049515 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/f016d99d-9dd6-4ea8-87b6-b8d001939b19? - ORIGINAL_DST/13.107.4.50 application/octet-stream
1473946615.452    147 10.10.10.118 TCP_MISS/206 1049513 GET http://tlu.dl.delivery.mp.microsoft.com/filestreamingservice/files/b6f13875-0aa9-49bc-8e64-c8f8ec7a7349? - ORIGINAL_DST/13.107.4.50 application/octet-stream

#############################################


again the cache_dir is empty !!!
root at debian:~# du -sh /cache/
4.0K    /cache/
root at debian:~# 


###################################

hope to help 

thank you 



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160915/23ac8221/attachment.htm>

From rafael.akchurin at diladele.com  Thu Sep 15 14:28:02 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 15 Sep 2016 14:28:02 +0000
Subject: [squid-users] Preserving Squid.conf when upgrading
In-Reply-To: <006301d20f55$698e0e80$3caa2b80$@verizon.net>
References: <006301d20f55$698e0e80$3caa2b80$@verizon.net>
Message-ID: <DB6PR0401MB2680B6E1AD4D712B4DB49D3A8FF00@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Hello Patrick,

Sorry I do not know. I guess MSI will just remove it.
So back it up somewhere before uninstall/install.

Best regards,
Rafael Akchurin
Diladele B.V.

BTW - new Docker build makes the native Windows Squid obsolete :)

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Patrick Flaherty
Sent: Thursday, September 15, 2016 3:31 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Preserving Squid.conf when upgrading

Hi,

For the Windows version of Squid from the good folks at Diladele, will it ever preserve the squid.conf file when uninstalling and reinstalling (upgrading)?

Thank you,
Patrick
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160915/0e70a4e0/attachment.htm>

From yvoinov at gmail.com  Thu Sep 15 14:39:45 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 15 Sep 2016 20:39:45 +0600
Subject: [squid-users] Preserving Squid.conf when upgrading
In-Reply-To: <DB6PR0401MB2680B6E1AD4D712B4DB49D3A8FF00@DB6PR0401MB2680.eurprd04.prod.outlook.com>
References: <006301d20f55$698e0e80$3caa2b80$@verizon.net>
 <DB6PR0401MB2680B6E1AD4D712B4DB49D3A8FF00@DB6PR0401MB2680.eurprd04.prod.outlook.com>
Message-ID: <e17d8bcf-9603-7724-31fa-17559d179e38@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


15.09.2016 20:28, Rafael Akchurin ?????:
>
> Hello Patrick,
>
> 
>
> Sorry I do not know. I guess MSI will just remove it.
>
> So back it up somewhere before uninstall/install.
>
This is easy and obvious procedure ;)
>
> 
>
> Best regards,
>
> Rafael Akchurin
>
> Diladele B.V.
>
> 
>
> BTW ? new Docker build makes the native Windows Squid obsolete :)
>
(irony) On windows notebook too? ;)

PS. It's not native - this is only a very rough resemblance native
Squid. :) BTW, Raf - where is 3.5.21 win64 port ? ;)
>
> 
>
> *From:* squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
*On Behalf Of *Patrick Flaherty
> *Sent:* Thursday, September 15, 2016 3:31 PM
> *To:* squid-users at lists.squid-cache.org
> *Subject:* [squid-users] Preserving Squid.conf when upgrading
>
> 
>
> Hi,
>
> 
>
> For the Windows version of Squid from the good folks at Diladele, will
it ever preserve the squid.conf file when uninstalling and reinstalling
(upgrading)?
>
> 
>
> Thank you,
>
> Patrick
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX2rKxAAoJENNXIZxhPexGTBEH/29HWJeJ3HMoNL0m6m6GyCIi
Z8gsOHBOQH1iu5wiJSD2107QN3ge5NVwe5Y9mVDBD3NvLY2xHh2AgNYOIAoMQJr3
ZS2RvgxZ29KoiOAn6gmYk9rW1imzuIzyDSY4qwKWP8MJhsOW8wIasidw4+ptYVKY
NVYk7sGXqexginVjFeaWKaMFh3g+B1K5ghDITRlEC4TcodHp//3KnBe2g71y0UQx
ARMfz/vETujZgLn2DbVgnIrLPey55GRs6IgPHRXDxvjk0YBl9DYHyx2A+Sbqfm6c
RsuM/jvu26X11pEzrsDW0JqfrCzDuULvfV7911ynyyzZjUHdsled7Uwq5keuPsg=
=ik7p
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160915/6d66f07d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160915/6d66f07d/attachment.key>

From alphabet at shaw.ca  Thu Sep 15 14:59:50 2016
From: alphabet at shaw.ca (Jason Leshchyshyn)
Date: Thu, 15 Sep 2016 08:59:50 -0600 (MDT)
Subject: [squid-users] Cannot get ACL to work
Message-ID: <phvw3e1mfwn656uefedhinrx.1473951588066@email.android.com>

It's version 3.3.8


Sent from my Bell Samsung device over Canada's largest network.<div>
</div><div>
</div><!-- originalMessage --><div>-------- Original message --------</div><div>From: erdosain9 <erdosain9 at gmail.com> </div><div>Date: 2016-09-14  8:05 PM  (GMT-07:00) </div><div>To: squid-users at lists.squid-cache.org </div><div>Subject: Re: [squid-users] Cannot get ACL to work </div><div>
</div>Hi.
What's your squid version??



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Cannot-get-ACL-to-work-tp4679502p4679520.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160915/d4dde0c8/attachment.htm>

From tmblue at gmail.com  Thu Sep 15 15:13:59 2016
From: tmblue at gmail.com (Tory M Blue)
Date: Thu, 15 Sep 2016 08:13:59 -0700
Subject: [squid-users] add header for https requests that are served to an
	upstream http server
Message-ID: <CAEaSS0a5G23ys1Rr8keOvXwQbC7R8D51Kn-LMJ+yo6EVfmSiLQ@mail.gmail.com>

So we are moving from an F5 LB to an AWS ELB. In the F5 we have a irule
that inserts a header that our origin servers looks for so they can return
https urls.

The ELB and Squid combination ends up rewritting the x_forward_proto header

from

HTTP_X_FORWARDED_PROTO: https

to

HTTP_X_FORWARDED_PROTO: http


So my origin, or back end server does not know that the request came
into Squid as https and that breaks the application.

I need to figure out how to keep the x_forwarded_proto header in tact,
or I need to know how to add a custom header if the original r

x_forwarded_proto header is https

There appears to be a "request_header_add" but I'm unclear how to use it.
Any assistance would be appreciated.

I'm running 3.5.x

Thanks
Tory
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160915/bdad953b/attachment.htm>

From robertocarna36 at gmail.com  Thu Sep 15 15:39:54 2016
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Thu, 15 Sep 2016 12:39:54 -0300
Subject: [squid-users] Logrotate with postrotate script
Message-ID: <CAG2Qp6unt8TDEaYuq+jixyH8JmuFpe5AmPRUEwpZC=-Uzyzrnw@mail.gmail.com>

Dear, I've installed Squid3 with log rotation by default.

I've analyzed the /etc/logrotate.d/squid3 file, and I can see this lines:

postrotate
                test ! -e /var/run/squid3.pid || /usr/sbin/squid3 -k rotate
endscript

Why is the reason of the "test ! -e /var/run/squid3.pid ||
/usr/sbin/squid3 -k rotate" command ??? Can yuo explain to me in
detail please ??? Because I think if I delete this line, the logrotae
config file is correct.

Thanks in advance.

Roberto


From rafael.akchurin at diladele.com  Thu Sep 15 16:04:36 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Thu, 15 Sep 2016 16:04:36 +0000
Subject: [squid-users] Preserving Squid.conf when upgrading
In-Reply-To: <e17d8bcf-9603-7724-31fa-17559d179e38@gmail.com>
References: <006301d20f55$698e0e80$3caa2b80$@verizon.net>
 <DB6PR0401MB2680B6E1AD4D712B4DB49D3A8FF00@DB6PR0401MB2680.eurprd04.prod.outlook.com>
 <e17d8bcf-9603-7724-31fa-17559d179e38@gmail.com>
Message-ID: <DB6PR0401MB268028A38917FD36052A22038FF00@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Hello Yuri,

Yes latest Docker runs natively on Windows ? you do not need to install anything and so will happily run Squid in Docker container (inside hyper-v I guess). See https://docs.docker.com/docker-for-windows/.

As for Squid 3.5.21 for Windows ? will make installer for it in a couple of days. Currently we are very busy with releasing version 4.6 of our ICAP web filter for Squid.

BTW does anyone object if I post here the announcement about its availability later?

Best regards,
Rafael Akchurin
Diladele B.V.

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
Sent: Thursday, September 15, 2016 4:40 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Preserving Squid.conf when upgrading


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256



15.09.2016 20:28, Rafael Akchurin ?????:
>

      > Hello Patrick,

      >

      >

      >

      > Sorry I do not know. I guess MSI will just remove it.

      >

      > So back it up somewhere before uninstall/install.

      >
This is easy and obvious procedure ;)
>

      >

      >

      > Best regards,

      >

      > Rafael Akchurin

      >

      > Diladele B.V.

      >

      >

      >

      > BTW ? new Docker build makes the native Windows Squid
      obsolete :)

      >
(irony) On windows notebook too? ;)

PS. It's not native - this is only a very rough resemblance native Squid. :) BTW, Raf - where is 3.5.21 win64 port ? ;)
>

      >

      >

      > *From:* squid-users
      [mailto:squid-users-bounces at lists.squid-cache.org] *On Behalf Of
      *Patrick Flaherty

      > *Sent:* Thursday, September 15, 2016 3:31 PM

      > *To:* squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

      > *Subject:* [squid-users] Preserving Squid.conf when upgrading

      >

      >

      >

      > Hi,

      >

      >

      >

      > For the Windows version of Squid from the good folks at
      Diladele, will it ever preserve the squid.conf file when
      uninstalling and reinstalling (upgrading)?

      >

      >

      >

      > Thank you,

      >

      > Patrick

      >

      >

      >

      > _______________________________________________

      > squid-users mailing list

      > squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

      > http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBCAAGBQJX2rKxAAoJENNXIZxhPexGTBEH/29HWJeJ3HMoNL0m6m6GyCIi
Z8gsOHBOQH1iu5wiJSD2107QN3ge5NVwe5Y9mVDBD3NvLY2xHh2AgNYOIAoMQJr3
ZS2RvgxZ29KoiOAn6gmYk9rW1imzuIzyDSY4qwKWP8MJhsOW8wIasidw4+ptYVKY
NVYk7sGXqexginVjFeaWKaMFh3g+B1K5ghDITRlEC4TcodHp//3KnBe2g71y0UQx
ARMfz/vETujZgLn2DbVgnIrLPey55GRs6IgPHRXDxvjk0YBl9DYHyx2A+Sbqfm6c
RsuM/jvu26X11pEzrsDW0JqfrCzDuULvfV7911ynyyzZjUHdsled7Uwq5keuPsg=
=ik7p
-----END PGP SIGNATURE-----
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160915/18726618/attachment.htm>

From tmblue at gmail.com  Thu Sep 15 16:21:30 2016
From: tmblue at gmail.com (Tory M Blue)
Date: Thu, 15 Sep 2016 09:21:30 -0700
Subject: [squid-users] FATAL: Invalid ACL type 'reg_header' 3.3.
Message-ID: <CAEaSS0ZO5pcvk3zosJx0e54JjndrHWbyRpEGna3t6YyouaiFkQ@mail.gmail.com>

*squid*-3.3.8

http://www.squid-cache.org/Versions/v3/3.3/cfgman/acl.html

This is suppose to be valid in squid-3.3.8

2016/09/15 09:18:02| FATAL: Invalid ACL type 'reg_header'

FATAL: Bungled /etc/squid/squid.conf line 21: acl CDKSSL reg_header
header-name ^HTTP_X_FORWARDED_PROTO: https


Thanks

Tory
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160915/0949421b/attachment.htm>

From rousskov at measurement-factory.com  Thu Sep 15 16:40:57 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 15 Sep 2016 10:40:57 -0600
Subject: [squid-users] FATAL: Invalid ACL type 'reg_header' 3.3.
In-Reply-To: <CAEaSS0ZO5pcvk3zosJx0e54JjndrHWbyRpEGna3t6YyouaiFkQ@mail.gmail.com>
References: <CAEaSS0ZO5pcvk3zosJx0e54JjndrHWbyRpEGna3t6YyouaiFkQ@mail.gmail.com>
Message-ID: <962345e6-205d-8dd8-ff59-0028c895c9a2@measurement-factory.com>

On 09/15/2016 10:21 AM, Tory M Blue wrote:
> This is suppose to be valid in squid-3.3.8
> 
> 2016/09/15 09:18:02| FATAL: Invalid ACL type 'reg_header'

You meant to type "req_header" instead of "reg_header".


> acl CDKSSL reg_header header-name ^HTTP_X_FORWARDED_PROTO: https

You are also misinterpreting the ACL declaration syntax. You probably
want something like:

    acl CDKSSL req_header X-Forwarded-Proto ^https$

but I do not actually know what you are trying to do so the above sketch
may need more adjustments.


Finally, you should not be using Squid v3.3. Too many serious bugs have
been fixed since that release.


HTH,

Alex.



From yvoinov at gmail.com  Thu Sep 15 17:56:47 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 15 Sep 2016 23:56:47 +0600
Subject: [squid-users] Preserving Squid.conf when upgrading
In-Reply-To: <DB6PR0401MB268028A38917FD36052A22038FF00@DB6PR0401MB2680.eurprd04.prod.outlook.com>
References: <006301d20f55$698e0e80$3caa2b80$@verizon.net>
 <DB6PR0401MB2680B6E1AD4D712B4DB49D3A8FF00@DB6PR0401MB2680.eurprd04.prod.outlook.com>
 <e17d8bcf-9603-7724-31fa-17559d179e38@gmail.com>
 <DB6PR0401MB268028A38917FD36052A22038FF00@DB6PR0401MB2680.eurprd04.prod.outlook.com>
Message-ID: <02caa2b3-672f-3f2b-0004-7227db0400d1@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


15.09.2016 22:04, Rafael Akchurin ?????:
>
> Hello Yuri,
>
> 
>
> Yes latest Docker runs natively on Windows ? you do not need to
install anything and so will happily run Squid in Docker container
(inside hyper-v I guess). See https://docs.docker.com/docker-for-windows/.
Waaaaa, hyperv..... Virtualization is evil.
>
> 
>
> As for Squid 3.5.21 for Windows ? will make installer for it in a
couple of days. Currently we are very busy with releasing version 4.6 of
our ICAP web filter for Squid.
Waiting for ;)
>
> 
>
> BTW does anyone object if I post here the announcement about its
availability later?
>
> 
>
> Best regards,
>
> Rafael Akchurin
>
> Diladele B.V.
>
> 
>
> *From:*squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
*On Behalf Of *Yuri Voinov
> *Sent:* Thursday, September 15, 2016 4:40 PM
> *To:* squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Preserving Squid.conf when upgrading
>
> 
>
>
>
>
> 15.09.2016 20:28, Rafael Akchurin ?????:
>
>
>       > Hello Patrick,
>
>
>
>
>
>
>
>       > Sorry I do not know. I guess MSI will just remove it.
>
>
>
>       > So back it up somewhere before uninstall/install.
>
>
> This is easy and obvious procedure ;)
>
>
>
>
>
>
>       > Best regards,
>
>
>
>       > Rafael Akchurin
>
>
>
>       > Diladele B.V.
>
>
>
>
>
>
>
>       > BTW ? new Docker build makes the native Windows Squid
>
>       obsolete :)
>
>
> (irony) On windows notebook too? ;)
>
> PS. It's not native - this is only a very rough resemblance native
Squid. :) BTW, Raf - where is 3.5.21 win64 port ? ;)
>
>
>
>
>
>
>       > *From:* squid-users
>
>       [mailto:squid-users-bounces at lists.squid-cache.org] *On Behalf Of
>
>       *Patrick Flaherty
>
>       > *Sent:* Thursday, September 15, 2016 3:31 PM
>
>       > *To:* squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       > *Subject:* [squid-users] Preserving Squid.conf when upgrading
>
>
>
>
>
>
>
>       > Hi,
>
>
>
>
>
>
>
>       > For the Windows version of Squid from the good folks at
>
>       Diladele, will it ever preserve the squid.conf file when
>
>       uninstalling and reinstalling (upgrading)?
>
>
>
>
>
>
>
>       > Thank you,
>
>
>
>       > Patrick
>
>
>
>
>
>
>
>       > _______________________________________________
>
>       > squid-users mailing list
>
>       > squid-users at lists.squid-cache.org
<mailto:squid-users at lists.squid-cache.org>
>
>       > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX2uDeAAoJENNXIZxhPexGw24H/AnXbxIR3RF6B5aLHsnOoKV3
e1kL0o8hSElJBH5LvO43LN7KyfkuC/7T+QcGWL06zkWpQU+Q1cqKDP1hD8O+UbXx
cN06w4pPgBDhudu7gzu0QzpIC2UD1SZkjuNv35JT4f7MR6cWCwPdmO0SlLZA7nxs
R1w2zcOwPgdLNzu5k9ZoimAcQwloNfGQu8TzW6WL7Z8weZw9WWmMqwzwKGuu0ut6
ryh/VJX3/7P46zMAhiY4c0ugCsYDwEnUlM02kyNN9mywTDgs7gwDyjQSPy/UmehH
WpWi77EijQMOfTl7bByHW1vbqr6gGDEYhT5CjEG6+gQSs11eIIl+61yH5GmqNZs=
=exNQ
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160915/c39cada8/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160915/c39cada8/attachment.key>

From squid3 at treenet.co.nz  Thu Sep 15 17:59:09 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 16 Sep 2016 05:59:09 +1200
Subject: [squid-users] Logrotate with postrotate script
In-Reply-To: <CAG2Qp6unt8TDEaYuq+jixyH8JmuFpe5AmPRUEwpZC=-Uzyzrnw@mail.gmail.com>
References: <CAG2Qp6unt8TDEaYuq+jixyH8JmuFpe5AmPRUEwpZC=-Uzyzrnw@mail.gmail.com>
Message-ID: <9a35471a-f34d-ba5b-54c2-52b978bb4030@treenet.co.nz>

On 16/09/2016 3:39 a.m., Roberto Carna wrote:
> Dear, I've installed Squid3 with log rotation by default.
> 
> I've analyzed the /etc/logrotate.d/squid3 file, and I can see this lines:
> 
> postrotate
>                 test ! -e /var/run/squid3.pid || /usr/sbin/squid3 -k rotate
> endscript
> 
> Why is the reason of the "test ! -e /var/run/squid3.pid ||
> /usr/sbin/squid3 -k rotate" command ??? Can yuo explain to me in
> detail please ??? Because I think if I delete this line, the logrotae
> config file is correct.
> 

It checks that Squid is running before sending it the signal to rotate logs.

Amos



From squid3 at treenet.co.nz  Thu Sep 15 18:06:14 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 16 Sep 2016 06:06:14 +1200
Subject: [squid-users] add header for https requests that are served to
 an upstream http server
In-Reply-To: <CAEaSS0a5G23ys1Rr8keOvXwQbC7R8D51Kn-LMJ+yo6EVfmSiLQ@mail.gmail.com>
References: <CAEaSS0a5G23ys1Rr8keOvXwQbC7R8D51Kn-LMJ+yo6EVfmSiLQ@mail.gmail.com>
Message-ID: <30ed1c89-4e7e-a0db-8d98-7a4945546fdc@treenet.co.nz>

On 16/09/2016 3:13 a.m., Tory M Blue wrote:
> So we are moving from an F5 LB to an AWS ELB. In the F5 we have a irule
> that inserts a header that our origin servers looks for so they can return
> https urls.
> 
> The ELB and Squid combination ends up rewritting the x_forward_proto header


Squid does not have any special handling for that obsolete experimental
header.

Any changes done to it are done by the ELB before it reaches Squid, or
due to the ELB Connection header explicitly instructing Squid that
headers using that name are to be erased before relaying the request.

Amos



From erdosain9 at gmail.com  Thu Sep 15 18:44:19 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 15 Sep 2016 11:44:19 -0700 (PDT)
Subject: [squid-users] (71) Protocol error (TLS code:
	X509_V_ERR_CERT_HAS_EXPIRED)
Message-ID: <1473965059992-4679539.post@n4.nabble.com>

Hi.
I have this problem with some webs....

example:
https://www.dalemacartney.com/2012/07/06/squid-proxy-integration-with-active-directory-the-quick-and-simple-way/

The following error was encountered while trying to retrieve the URL:
https://www.dalemacartney.com/*

Failed to establish a secure connection to 88.202.227.60

The system returned:

(71) Protocol error (TLS code: X509_V_ERR_CERT_HAS_EXPIRED)
SSL Certificate expired on: Aug 3 17:35:16 2014 GMT

This proxy and the remote host failed to negotiate a mutually acceptable
security settings for handling your request. It is possible that the remote
host does not support secure connections, or the proxy is not satisfied with
the host security credentials.

Your cache administrator is webmaster.


This is access.log

214      0 192.168.1.172 TAG_NONE/503 4576 GET
https://www.dalemacartney.com/2012/07/06/squid-proxy-integration-with-active-directory-the-quick-and-simple-way/
- HIER_NONE/- text/html




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/71-Protocol-error-TLS-code-X509-V-ERR-CERT-HAS-EXPIRED-tp4679539.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Thu Sep 15 18:55:36 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 15 Sep 2016 11:55:36 -0700 (PDT)
Subject: [squid-users] SSO (ldap kerberos)
In-Reply-To: <CA86A9283AA07E478F6B0629521FFEE73FC133@CLWSEXCMBX02.na.bicworld.com>
References: <1473702058647-4679470.post@n4.nabble.com>
 <6bbebad5-7712-9b39-2510-8fcb7ece641b@treenet.co.nz>
 <1473780876101-4679484.post@n4.nabble.com>
 <ddc7ffa7-9858-710a-b8e0-6848106168bb@treenet.co.nz>
 <1473791599383-4679490.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73FC133@CLWSEXCMBX02.na.bicworld.com>
Message-ID: <1473965736706-4679540.post@n4.nabble.com>

This is no error???


try_machine_keytab_princ: Trying to authenticate for squid-k$ from local
keytab... 
 -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed
(Preauthentication failed) 
 -- try_machine_keytab_princ: Authentication with keytab failed 
 -- try_machine_keytab_princ: Trying to authenticate for
host/squid.example.lan from local keytab... 
 -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed
(Client not found in Kerberos database) 
 -- try_machine_keytab_princ: Authentication with keytab failed 


.........................
Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SSO-ldap-kerberos-tp4679470p4679540.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Tommy.Craddock at bicgraphic.com  Thu Sep 15 19:10:43 2016
From: Tommy.Craddock at bicgraphic.com (Craddock, Tommy)
Date: Thu, 15 Sep 2016 19:10:43 +0000
Subject: [squid-users] SSO (ldap kerberos)
In-Reply-To: <1473965736706-4679540.post@n4.nabble.com>
References: <1473702058647-4679470.post@n4.nabble.com>
 <6bbebad5-7712-9b39-2510-8fcb7ece641b@treenet.co.nz>
 <1473780876101-4679484.post@n4.nabble.com>
 <ddc7ffa7-9858-710a-b8e0-6848106168bb@treenet.co.nz>
 <1473791599383-4679490.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73FC133@CLWSEXCMBX02.na.bicworld.com>
 <1473965736706-4679540.post@n4.nabble.com>
Message-ID: <CA86A9283AA07E478F6B0629521FFEE73FCF2C@CLWSEXCMBX02.na.bicworld.com>

Read the whole section you referred to:

/tmp/.msktkrb5.conf-L8DxV8
 -- reload: Reloading Kerberos Context
 -- finalize_exec: SAM Account Name is: squid-k$
 -- try_machine_keytab_princ: Trying to authenticate for squid-k$ from local keytab...
 -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed (Preauthentication failed)
 -- try_machine_keytab_princ: Authentication with keytab failed
 -- try_machine_keytab_princ: Trying to authenticate for host/squid.example.lan from local keytab...
 -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed (Client not found in Kerberos database)
 -- try_machine_keytab_princ: Authentication with keytab failed
 -- try_machine_password: Trying to authenticate for squid-k$ with password.
 -- create_default_machine_password: Default machine password for squid-k$ is squid-k
 -- try_machine_password: Error: krb5_get_init_creds_keytab failed (Preauthentication failed)
 -- try_machine_password: Authentication with password failed
 -- try_user_creds: Checking if default ticket cache has tickets...
 -- finalize_exec: Authenticated using method 4

It authed and was able to update the machine password:

-- ldap_get_pwdLastSet: pwdLastSet is 131182651460000000
 -- set_password: Successfully set password, waiting for it to be reflected in LDAP.
 -- ldap_get_pwdLastSet: pwdLastSet is 131182651580000000
 -- set_password: Successfully reset computer's password
 -- execute: Updating all entries for squid.example.lan in the keytab WRFILE:PROXY.keytab

?
Tommy E CRADDOCK JR


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Thursday, September 15, 2016 2:56 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] SSO (ldap kerberos)

This is no error???


try_machine_keytab_princ: Trying to authenticate for squid-k$ from local keytab... 
 -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed (Preauthentication failed)
 -- try_machine_keytab_princ: Authentication with keytab failed
 -- try_machine_keytab_princ: Trying to authenticate for host/squid.example.lan from local keytab... 
 -- try_machine_keytab_princ: Error: krb5_get_init_creds_keytab failed (Client not found in Kerberos database)
 -- try_machine_keytab_princ: Authentication with keytab failed 


.........................
Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SSO-ldap-kerberos-tp4679470p4679540.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________

From erdosain9 at gmail.com  Thu Sep 15 20:04:39 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 15 Sep 2016 13:04:39 -0700 (PDT)
Subject: [squid-users] SSO (ldap kerberos)
In-Reply-To: <CA86A9283AA07E478F6B0629521FFEE73FCF2C@CLWSEXCMBX02.na.bicworld.com>
References: <1473702058647-4679470.post@n4.nabble.com>
 <6bbebad5-7712-9b39-2510-8fcb7ece641b@treenet.co.nz>
 <1473780876101-4679484.post@n4.nabble.com>
 <ddc7ffa7-9858-710a-b8e0-6848106168bb@treenet.co.nz>
 <1473791599383-4679490.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73FC133@CLWSEXCMBX02.na.bicworld.com>
 <1473965736706-4679540.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73FCF2C@CLWSEXCMBX02.na.bicworld.com>
Message-ID: <1473969879489-4679542.post@n4.nabble.com>


Thank you very much. Sorry but ... also he authenticated with Kerberos ?? or
only Ldap ?? Because the important thing for me is Kerberos.

APOLOGY ignorance about it. 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SSO-ldap-kerberos-tp4679470p4679542.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Thu Sep 15 22:00:51 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 15 Sep 2016 23:00:51 +0100
Subject: [squid-users] (71) Protocol error (TLS code:
	X509_V_ERR_CERT_HAS_EXPIRED)
In-Reply-To: <1473965059992-4679539.post@n4.nabble.com>
References: <1473965059992-4679539.post@n4.nabble.com>
Message-ID: <201609152300.52056.Antony.Stone@squid.open.source.it>

On Thursday 15 Sep 2016 at 19:44, erdosain9 wrote:

> Hi.
> I have this problem with some webs....
> 
> example:
> https://www.dalemacartney.com/2012/07/06/squid-proxy-integration-with-activ
> e-directory-the-quick-and-simple-way/

> (71) Protocol error (TLS code: X509_V_ERR_CERT_HAS_EXPIRED)
> SSL Certificate expired on: Aug 3 17:35:16 2014 GMT
> 
> This proxy and the remote host failed to negotiate a mutually acceptable
> security settings for handling your request. It is possible that the remote
> host does not support secure connections, or the proxy is not satisfied
> with the host security credentials.

And what is your surprise about this?

That certificate is valid from 01/08/2013 03:48 to 03/08/2014 17:35

There's nothing Squid can magically do to resurrect an expired certificate.


Antony.

-- 
"In fact I wanted to be John Cleese and it took me some time to realise that 
the job was already taken."

 - Douglas Adams


From yvoinov at gmail.com  Thu Sep 15 22:33:14 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 16 Sep 2016 04:33:14 +0600
Subject: [squid-users] (71) Protocol error (TLS code:
 X509_V_ERR_CERT_HAS_EXPIRED)
In-Reply-To: <201609152300.52056.Antony.Stone@squid.open.source.it>
References: <1473965059992-4679539.post@n4.nabble.com>
 <201609152300.52056.Antony.Stone@squid.open.source.it>
Message-ID: <75f38330-b5b9-81d9-71aa-6b94872a93ba@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


16.09.2016 4:00, Antony Stone ?????:
> On Thursday 15 Sep 2016 at 19:44, erdosain9 wrote:
>
>> Hi.
>> I have this problem with some webs....
>>
>> example:
>>
https://www.dalemacartney.com/2012/07/06/squid-proxy-integration-with-activ
>> e-directory-the-quick-and-simple-way/
>
>> (71) Protocol error (TLS code: X509_V_ERR_CERT_HAS_EXPIRED)
>> SSL Certificate expired on: Aug 3 17:35:16 2014 GMT
>>
>> This proxy and the remote host failed to negotiate a mutually acceptable
>> security settings for handling your request. It is possible that the
remote
>> host does not support secure connections, or the proxy is not satisfied
>> with the host security credentials.
>
> And what is your surprise about this?
>
> That certificate is valid from 01/08/2013 03:48 to 03/08/2014 17:35
>
> There's nothing Squid can magically do to resurrect an expired
certificate.
A terrible grief, Antonio :)
>
>
>
> Antony.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX2yGqAAoJENNXIZxhPexGD4oH/1PNVQl4QNIF636MLXIqRt7/
Et4vCks8udApUmSJCr/X2WLPEX3AdCSj1IzytLESMtI+30dH2tvlwLKOpRwlO6vJ
ylecDhofhMhetckGHQ7UKA4CPYCk8lKPGeMNUtElV5JXkDhlpZkONdwQDFOrPzD1
9lxEb1n8FaflQB2wNkbkJ8sDmGuwppPQSWxqIK0XcDeJ8G/22X6Oayimy6YT0e5k
0sy8BP0KSOdWh9vBqbN9+IsCdva0UgwAMw/pwvMQMrO7P+lCHMQu3RDOI8PbjrpX
DDq/nRS7rxhovZB6L2Z/fdAUQIXwVqlnH6+ZQHqm10/XI8XggNtyMgDRdMWk+tU=
=XOa9
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160916/7c7504e1/attachment.key>

From yvoinov at gmail.com  Thu Sep 15 22:33:50 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 16 Sep 2016 04:33:50 +0600
Subject: [squid-users] (71) Protocol error (TLS code:
 X509_V_ERR_CERT_HAS_EXPIRED)
In-Reply-To: <201609152300.52056.Antony.Stone@squid.open.source.it>
References: <1473965059992-4679539.post@n4.nabble.com>
 <201609152300.52056.Antony.Stone@squid.open.source.it>
Message-ID: <aee59b58-a746-1ac7-23a7-54ecf2f0e61d@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Rotten year ago certificate - a terrible grief :)


16.09.2016 4:00, Antony Stone ?????:
> On Thursday 15 Sep 2016 at 19:44, erdosain9 wrote:
>
>> Hi.
>> I have this problem with some webs....
>>
>> example:
>>
https://www.dalemacartney.com/2012/07/06/squid-proxy-integration-with-activ
>> e-directory-the-quick-and-simple-way/
>
>> (71) Protocol error (TLS code: X509_V_ERR_CERT_HAS_EXPIRED)
>> SSL Certificate expired on: Aug 3 17:35:16 2014 GMT
>>
>> This proxy and the remote host failed to negotiate a mutually acceptable
>> security settings for handling your request. It is possible that the
remote
>> host does not support secure connections, or the proxy is not satisfied
>> with the host security credentials.
>
> And what is your surprise about this?
>
> That certificate is valid from 01/08/2013 03:48 to 03/08/2014 17:35
>
> There's nothing Squid can magically do to resurrect an expired
certificate.
>
>
> Antony.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX2yHNAAoJENNXIZxhPexGnSAH/ApT2CEP7gHsOuxej4deT2pc
b0AIuEkYF8phAkCWhXtejk2reFv0kzRJMCUFnD5quDk/nZTEo4/S3Y8jIcfPSPR2
QW/11HToQbrAR4Cpx5TI1cZ2Hd1pzX1LylJKsPE2NSrgcu8DVvhqfWXgo5PE0T/1
07r8YKooh9+BbEtz3jNNPp/tO/+6lVDBoRDtGyqhJ+7qoxmvMuOoaEF/tLRPB2au
eE/mMwOI1NfITWPr8cxjXGg/XTE0CewMUeNKUTqIgqioznInNLZR1LE+C2rU1CpH
qSuZ1uZ74A1OY+gqdv2AnfQUob1mVP9Em8mT9awjiXdHQTliqpwQQkess85Z29Y=
=QYq4
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160916/fcb19ff3/attachment.key>

From hardikdangar+squid at gmail.com  Fri Sep 16 07:09:03 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Fri, 16 Sep 2016 12:39:03 +0530
Subject: [squid-users] cache github zip repositories
Message-ID: <CA+sSnVYomLi=n+dqNmAkP5uA6j9z=GKaEw9_7AM1qH+mNZXw_w@mail.gmail.com>

*Amos,*

Thanks for the reply but it seems i am not able to tell you what i
want to do. i don't want to cache repo files. i want to cache .zip
files only. i don't want .git file to cache but only .zip files which
are fetch from github.com,

Also you have said things about commits but i am talking about zip
file which is given by github via download button or composer fetches
those files via command line directly. as soon as someone commits zip
file's ETag is changed when you fetch it.

So there is no way to achieve this ? Do you think there is a way to
achieve this ?


*Consider: how does Squid know the ETag has changed on the
server?**What you know about things happening in RL is not what Squid
knows.*
> *I fact how do *you* know someone else did not commit a change during*
> *that ~1 second it takes to look at the page and click the download button?** Simply, you don't, and cannot until the new object has been fetched.*
> *Likewise, Squid cannot know if the object is the same until it has*
> *fetched a MISS from the server. Except that Squid does not look at the*
> *previous page content, so it cannot even 'see' if there is a commit*
> *listed there that might be different since whenever it got the previous**object.*
> *There is no Cache-Control or Expires header indicating a specific*
> *storage timeout or revalidation procedure. So refresh_pattern defaults*
> *will be used. These responses will be cached for the refresh_pattern**'Min' duration (900 minutes) before being considered for revalidated.*
> *NP 1: Synthesizing Last-Modified from the Date header is only just being*
> *fixed in Squid the past few weeks, and some parts of it still to be*
> *committed. So I would not expect that response to be revalidated, just**re-fetched fully in older Squid.*
> *NP 2: The Vary header indicates that every person logged in gets a*
> *differently cached response based on how their credentials are hashed on*
> *each request (in Authorization tokens). So caching these objects will*
> *not help much with many developers involved. It will be of most help for**the anonymous visitors where username is always a generic NIL value.*
> *HTH**Amos*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160916/cbbd875a/attachment.htm>

From silamael at coronamundi.de  Fri Sep 16 08:14:45 2016
From: silamael at coronamundi.de (Silamael Darkomen)
Date: Fri, 16 Sep 2016 10:14:45 +0200
Subject: [squid-users] Problem with Kerberos and ext_kerberos_ldap_group_acl
 not being able to reach realm's KDC
Message-ID: <955b9071-4d07-f0a2-2925-8f63fa3324af@coronamundi.de>

Hello,

I'm currently working on setting up our proxy to authenticate the users
via Kerberos against a Windows AD.
The simple user authentication through negotiate_kerberos_auth is
already working.
But the second step for checking the group of an authenticated users
gives me some headache. Even with Kerberos configured not to search the
KDC via DNS, the ext_kerberos_ldap_group_acl tool complains about not
being able to find the realms KDC:

squid-3.5.20/helpers/external_acl/kerberos_ldap_group/kerberos_ldap_group.cc(376):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: INFO: Got User:
user Domain: EXAMPLE.COM
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_member.cc(63):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: User domain
loop: group at domain linux@
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_member.cc(91):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Default
domain loop: group at domain linux@
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_member.cc(93):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Found
group at domain linux@
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_ldap.cc(898):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Setup
Kerberos credential cache
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_krb5.cc(127):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Set
credential cache to MEMORY:squid_ldap_23191
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_krb5.cc(138):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Get default
keytab file name
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_krb5.cc(144):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Got default
keytab file name /etc/HTTP.keytab
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_krb5.cc(158):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Get
principal name from keytab /etc/HTTP.keytab
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_krb5.cc(167):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Keytab entry
has realm name: EXAMPLE.COM
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_krb5.cc(181):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Found
principal name: host/proxy.example.com at EXAMPLE.COM
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_krb5.cc(196):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Got
principal name host/proxy.example.com at EXAMPLE.COM
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_krb5.cc(64):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: ERROR: Error while
initialising credentials from keytab : unable to reach any KDC in realm
EXAMPLE.COM
...

The last lines of the error messages repeat for every entry in the keytab.
All other Kerberos related tools work fine with the given krb5.conf.

Some more information about the setup:
We're running under OpenBSD with Heimdal version 1.5.3.
The AD is reachable from the proxy machine but DNS is not done by the AD
but on the proxy machine itself.

Below you find the krb5.conf used and the settings from the squid.conf.
The limitation to 1 child is just for testing purposes.

Would be really great if anyone could shed some light on this issue!

Thanks in advance,
Matthias

---------------------------------------------------------------------

krb5.conf:
[logging]
default = FILE:/var/log/krb5libs.log
kdc = FILE:/var/log/krb5kdc.log
admin_server = FILE:/var/log/kadmind.log
default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5
default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5
permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5

[libdefaults]
ticket_lifetime = 24000
default_realm = EXAMPLE.COM
default_keytab_name = /etc/HTTP.keytab
dns_lookup_kdc = no
dns_lookup_realm = no

[realms]
EXAMPLE.COM = {
        kdc = 1.2.3.4
        admin_server = 1.2.3.4
        default_domain = example.com
}

squid.conf:
auth_param negotiate program
/usr/local/libexec/squid/negotiate_kerberos_auth -di -s
HTTP/proxy.example.com
auth_param negotiate children 1
auth_param negotiate keep_alive on

external_acl_type squid_kerb_ldap children-max=1 ttl=3600
negative_ttl=3600 %LOGIN
/usr/local/libexec/squid/ext_kerberos_ldap_group_acl -di -S 1.2.3.4@ -g
linux@
acl ldap_group_check external squid_kerb_ldap
http_access deny !ldap_group_check


From yanghe0921 at 126.com  Fri Sep 16 08:19:17 2016
From: yanghe0921 at 126.com (yanghe)
Date: Fri, 16 Sep 2016 16:19:17 +0800
Subject: [squid-users] c-icap load balancing
In-Reply-To: 25eb8491-49bf-1166-adba-f94d6c00065f@measurement-factory.com
References: <146a7ed6.396.15726376e43.Coremail.yanghe0921@126.com><25eb8491-49bf-1166-adba-f94d6c00065f@measurement-factory.com>
Message-ID: <7afcd3a9.a1f2b.15732140f03.Coremail.yanghe0921@126.com>

On 09/14/2016 09:51 PM,  wrote: "Alex Rousskov"<rousskov at measurement-factory.com>
> Unfortunately, Squid does not support true load
> However, there is a workaround: Use 

Thanks for your adivice. 
IF I do not use adaptation_service_set or adaptation_service_chain to list N c-icap services.the traffic will only go to the first.
Get your advice.I tried configure the "random" ACLs,But,It is not successful
Here is my squid.conf
balance_on_multiple_ip on
acl halfpercent random 0.5
tcp_outgoing_address 192.168.1.4 halfpercent
tcp_outgoing_address 192.168.1.2

icap_service service_req reqmod_precache bypass=0 icap://192.168.1.4:1344/echo
adaptation_access service_req allow all

icap_service service_req_two reqmod_precache bypass=0 icap://192.168.1.2:1344/echo
adaptation_access service_req_two allow all
This is mistake in cache.log
"commBind: Cannot bind socket FD 18 to 192.168.1.2: (99) Cannot assign requested address"
"commBind: Cannot bind socket FD 18 to 192.168.1.4: (99) Cannot assign requested address"

That's why 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160916/6dfe582b/attachment.htm>

From rafael.akchurin at diladele.com  Fri Sep 16 08:28:03 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Fri, 16 Sep 2016 08:28:03 +0000
Subject: [squid-users] c-icap load balancing
In-Reply-To: <7afcd3a9.a1f2b.15732140f03.Coremail.yanghe0921@126.com>
References: <146a7ed6.396.15726376e43.Coremail.yanghe0921@126.com><25eb8491-49bf-1166-adba-f94d6c00065f@measurement-factory.com>
 <7afcd3a9.a1f2b.15732140f03.Coremail.yanghe0921@126.com>
Message-ID: <DB6PR0401MB2680ABCEE19ECE7D19A66F5F8FF30@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Hello Yanghe,
Why not to setup HAproxy in front of your ICAP instances?
ICAP is relatively easily can be load balanced by HAProxy.
We have it in place up and running.

Best regards,

Rafael Akchurin

Diladele B.V.

http://www.quintolabs.com

http://www.diladele.com



--

Please take a look at Web Safety - our ICAP based web filter server for Squid proxy.



From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of yanghe
Sent: Friday, September 16, 2016 10:19 AM
To: squid-users <squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] c-icap load balancing

On 09/14/2016 09:51 PM,  wrote: "Alex Rousskov"<rousskov at measurement-factory.com<mailto:rousskov at measurement-factory.com>>
> Unfortunately, Squid does not support true load
> However, there is a workaround: Use

Thanks for your adivice.
IF I do not use adaptation_service_set or adaptation_service_chain to list N c-icap services.the traffic will only go to the first.
Get your advice.I tried configure the "random" ACLs,But,It is not successful
Here is my squid.conf
balance_on_multiple_ip on
acl halfpercent random 0.5
tcp_outgoing_address 192.168.1.4 halfpercent
tcp_outgoing_address 192.168.1.2

icap_service service_req reqmod_precache bypass=0 icap://192.168.1.4:1344/echo
adaptation_access service_req allow all
icap_service service_req_two reqmod_precache bypass=0 icap://192.168.1.2:1344/echo
adaptation_access service_req_two allow all
This is mistake in cache.log
"commBind: Cannot bind socket FD 18 to 192.168.1.2: (99) Cannot assign requested address"
"commBind: Cannot bind socket FD 18 to 192.168.1.4: (99) Cannot assign requested address"

That's why
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160916/4f5d8156/attachment.htm>

From belle at bazuin.nl  Fri Sep 16 08:52:59 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Fri, 16 Sep 2016 10:52:59 +0200
Subject: [squid-users] Problem with Kerberos and
 ext_kerberos_ldap_group_acl not being able to reach realm's KDC
In-Reply-To: <955b9071-4d07-f0a2-2925-8f63fa3324af@coronamundi.de>
References: <955b9071-4d07-f0a2-2925-8f63fa3324af@coronamundi.de>
Message-ID: <vmime.57dbb2eb.3061.61eb226d1421221b@ms249-lin-003.rotterdam.bazuin.nl>

I think you forgot in your test, that you may need to modify the default kerberos ticket used. 

?

?

I suggest you change you config a bit to something like 

?

external_acl_type internet-win-allowed %LOGIN /usr/local/libexec/squid/ext_kerberos_ldap_group_acl \

-D YOUR.REALM.TLD \

-g allowed-internet at YOUR.REALM.TLD \

-N NTDOMAIN at YOUR.REALM.TLD \

-S dc1.your.dnsdomain.tld at YOUR.REALM.TLD:dc2.your.dnsdomain.tld at YOUR.REALM.TLD \

?

Now test it. ?start like this :? ?

/usr/local/libexec/squid/negotiate_kerberos_auth \

-D YOUR.REALM.TLD \

-g allowed-internet at YOUR.REALM.TLD \

-N NTDOMAIN at YOUR.REALM.TLD \

-S dc1.your.dnsdomain.tld at YOUR.REALM.TLD:dc2.your.dnsdomain.tld at YOUR.REALM.TLD \

-d 

(-d = debug ) 

Test with ?S and point to your server, does it work? 

Test again with ?S , does it works, no? Change the default keytab for te test.

KRB5_KTNAME=/etc/squid/keytab.SQUID-HTTP

export KRB5_KTNAME

?

Type a username belonging to you group your testing with, hit enter. 

?

And in the end you should see : 

support_member.cc(69): pid=10396 :2016/09/16 10:39:07| kerberos_ldap_group: INFO: User testuser is member of group at domain allowed-internet at YOUR.REALM.TLD

OK

kerberos_ldap_group.cc(408): pid=10396 :2016/09/16 10:39:07| kerberos_ldap_group: DEBUG: OK

?

with search for the kdc in krb5.conf 

?

[libdefaults]

??? default_realm = YOUR.REALM.TLD

??? dns_lookup_kdc = true

??? dns_lookup_realm = false

?

and now when it works adjust you parameters to your needs. ?

( like the : children-max=1 ttl=3600 negative_ttl=3600 ) 

?

?

?

Greetz, 

?

Louis

?

?

> 

> squid.conf:

> auth_param negotiate program

> /usr/local/libexec/squid/negotiate_kerberos_auth -di -s

> HTTP/proxy.example.com

> auth_param negotiate children 1

> auth_param negotiate keep_alive on

> 

> external_acl_type squid_kerb_ldap children-max=1 ttl=3600 negative_ttl=3600 %LOGIN

> /usr/local/libexec/squid/ext_kerberos_ldap_group_acl -di -S 1.2.3.4@ -g

> linux@

> acl ldap_group_check external squid_kerb_ldap

> http_access deny !ldap_group_check

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160916/63d1259e/attachment.htm>

From squid3 at treenet.co.nz  Fri Sep 16 08:58:07 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 16 Sep 2016 20:58:07 +1200
Subject: [squid-users] c-icap load balancing
In-Reply-To: <7afcd3a9.a1f2b.15732140f03.Coremail.yanghe0921@126.com>
References: <146a7ed6.396.15726376e43.Coremail.yanghe0921@126.com>
 <25eb8491-49bf-1166-adba-f94d6c00065f@measurement-factory.com>
 <7afcd3a9.a1f2b.15732140f03.Coremail.yanghe0921@126.com>
Message-ID: <0a716896-9aa2-741f-ecf3-957c7ea45984@treenet.co.nz>

On 16/09/2016 8:19 p.m., yanghe wrote:
> On 09/14/2016 09:51 PM,  wrote: "Alex Rousskov"
>> Unfortunately, Squid does not support true load
>> However, there is a workaround: Use 
> 
> Thanks for your adivice. 
> IF I do not use adaptation_service_set or adaptation_service_chain to list N c-icap services.the traffic will only go to the first.
> Get your advice.I tried configure the "random" ACLs,But,It is not successful
> Here is my squid.conf
> balance_on_multiple_ip on
> acl halfpercent random 0.5
> tcp_outgoing_address 192.168.1.4 halfpercent
> tcp_outgoing_address 192.168.1.2
> 
> icap_service service_req reqmod_precache bypass=0 icap://192.168.1.4:1344/echo
> adaptation_access service_req allow all
> 
> icap_service service_req_two reqmod_precache bypass=0 icap://192.168.1.2:1344/echo
> adaptation_access service_req_two allow all

This is *not* what Alex advised.

tcp_outgoing_address is the IP Squid will use to contact upstream web
servers. Dont do that.


What Alex suggested was to use the random ACL in your
*adaptation_access* rules to select ICAP service for use.

Getting the right random value to check against is tricky though. I'm
not sure what the calculation should be here. Maybe this:

 acl half random 0.5

 icap_service service_req reqmod_precache \
    bypass=0 icap://192.168.1.4:1344/echo
 adaptation_access service_req allow half

 icap_service service_req_two reqmod_precache \
    bypass=0 icap://192.168.1.2:1344/echo
 adaptation_access service_req_two allow all


Amos



From squid3 at treenet.co.nz  Fri Sep 16 09:34:30 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 16 Sep 2016 21:34:30 +1200
Subject: [squid-users] cache github zip repositories
In-Reply-To: <CA+sSnVYomLi=n+dqNmAkP5uA6j9z=GKaEw9_7AM1qH+mNZXw_w@mail.gmail.com>
References: <CA+sSnVYomLi=n+dqNmAkP5uA6j9z=GKaEw9_7AM1qH+mNZXw_w@mail.gmail.com>
Message-ID: <a0e13f12-0443-237a-bd0b-3c5c89cb246b@treenet.co.nz>

On 16/09/2016 7:09 p.m., Hardik Dangar wrote:
> *Amos,*
> 
> Thanks for the reply but it seems i am not able to tell you what i
> want to do. i don't want to cache repo files. i want to cache .zip
> files only. i don't want .git file to cache but only .zip files which
> are fetch from github.com,

I undersand that. Maybe my reply was not clear about the problem being
faced.


> 
> Also you have said things about commits but i am talking about zip
> file which is given by github via download button or composer fetches
> those files via command line directly. as soon as someone commits zip
> file's ETag is changed when you fetch it.

That is because the .zip file is generated by github on-demand.

When someone commmits something to the repository the contents of the
next .zip to be downloaded change. The ETag is, or represents, a hash of
the .zip current contents.


> 
> So there is no way to achieve this ? Do you think there is a way to
> achieve this ?
> 

Since the .zip file (and ETag) is able to change at any time Squid
cannot know whether the file it has from a previous request is still
usable. Current versions of Squid must fetch a new .zip to find out - at
that point they might as well just deliver the new copy.

Future Squid releases** will allow these .zip object to be cached and
reused for a short period defined by a matching refresh_pattern line.

But really, unless github change how they create those .zip files
caching of them will not work very well.


** If you really need this behaviour right now you can build the latest
Squid-4 snapshot and apply Eduards patch from
<http://lists.squid-cache.org/pipermail/squid-dev/2016-September/006750.html>.

Amos



From vero.ovando at live.com  Fri Sep 16 11:45:04 2016
From: vero.ovando at live.com (=?iso-8859-1?Q?Ver=F3nica_Ovando?=)
Date: Fri, 16 Sep 2016 11:45:04 +0000
Subject: [squid-users] Delay pools for authentcated users
Message-ID: <BN3PR0801MB229113B4E815233F8CF4759C9EF30@BN3PR0801MB2291.namprd08.prod.outlook.com>

Hi!

I am trying to set up delay pools for AD authenticated users.

I run Squid 3.4.8 in a Debian 8 server.


I configured come delay pools, but they really don't have effect. What I want to do is to provide full bandwidth for some pages and create a delay for ALL the others. This is because I can't restrict internet surfing and I need a solution and control bandwidth usage.


(Squid is working without problems with AD, so I will omit some directives about authentication )


For example:


#****************************ACLs**************************#

acl AD_Standard external Grupos_AD Standard

acl redLocal src 90.0.0.0/22



#****************************Delay Pools**************************#

delay_pools 3


delay_class 1 4

delay_access 1 allow AD_Standard socialNets
delay_access 1 deny all
delay_parameters 1 32000/32000 8000/8000 600/64000 1000/10000

delay_class 2 1
delay_parameters 2 -1/-1
delay_access 2 allow redLocal redLocal
delay_access 2 allow redLocal oficiales
delay_access 2 allow redLocal diarios
delay_access 2 allow redLocal bancos
delay_access 2 allow redLocal tarjCred
delay_access 2 allow redLocal inmueble
delay_access 2 allow redLocal mails
delay_access 2 allow redLocal externos
delay_access 2 allow redLocal varias
delay_access 2 allow redLocal servicios
delay_access 2 deny all

delay_class 3 4
delay_parameters 3 32000/32000 8000/8000 10000/64000 15000/50000
delay_access 3 allow AD_Standard all
delay_access 3 deny all

#*******************************************************************************************#

So, I am creating three delay_pools, the first one provides 10KB for each user (for the AD group Standard), no matters hoy many hosts are logged in; the second one provides full usage of the bandwidth for my local network to access those pages; the third delay provides up to 50KB for the ALL the websites, with exception of those defined in the delay 2. Is this correct?

Thanks in advance.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160916/a5a16f1f/attachment.htm>

From yanghe0921 at 126.com  Fri Sep 16 11:49:13 2016
From: yanghe0921 at 126.com (yanghe)
Date: Fri, 16 Sep 2016 19:49:13 +0800
Subject: [squid-users] c-icap load balancing
In-Reply-To: <57DBAB05.6090706@126.com>
References: <146a7ed6.396.15726376e43.Coremail.yanghe0921@126.com><25eb8491-49bf-1166-adba-f94d6c00065f@measurement-factory.com><57DBAB05.6090706@126.com>
Message-ID: <1c259aa2.762.15732d4413d.Coremail.yanghe0921@126.com>

on 09/16/2016 08:58 AM,  wrote: "Amos Jeffries"squid3 at treenet.co.nz
> This is *not* what Alex advised
> tcp_outgoing_address is the IP Squid will use to contact
Thank you and Alex?
It's OK.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160916/bbe59f38/attachment.htm>

From temporalev at gmail.com  Fri Sep 16 11:50:52 2016
From: temporalev at gmail.com (VB)
Date: Fri, 16 Sep 2016 04:50:52 -0700 (PDT)
Subject: [squid-users] SQUID 3.4.8 on RPi 3
Message-ID: <1474026652857-4679556.post@n4.nabble.com>

Hi guys

I'd like to ask you for a suggestion..

I'm running SQUID 3.4.8 under Rasberry PI3 (Rasbian Jesse) - proxy server
"intercept" mode (with iptables forwarding rule to 3128).

I've created ACL for devices (ipad, mobiles...) - time based, because I
need to allow Internet connection restricted at some hours only to some
children devices.

The proxy works quite well.. it stops correctly HTTP...but... I'm facing an
issue with HTTPS:
Infact.. all http:\\addresses are stopped.. but for example
https:\\www.google.com not..

Questions:
1. How can I stop both http and https?
2. In case I'd like to compile a new squid version.. like the 3.5.21 on
Rasbian Jesse.. how can I do?

thx a lot for your feedback
Vincenzo




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SQUID-3-4-8-on-RPi-3-tp4679556.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yanghe0921 at 126.com  Fri Sep 16 12:01:57 2016
From: yanghe0921 at 126.com (yanghe)
Date: Fri, 16 Sep 2016 20:01:57 +0800
Subject: [squid-users] c-icap load balancing
In-Reply-To: <57DBDC39.50506@126.com>
References: <146a7ed6.396.15726376e43.Coremail.yanghe0921@126.com><25eb8491-49bf-1166-adba-f94d6c00065f@measurement-factory.com><57DBAB05.6090706@126.com><57DBDC39.50506@126.com>
Message-ID: <3c44fea1.777.15732dfe907.Coremail.yanghe0921@126.com>

on 09/16/2016 08:28 AM,  wrote: "Rafael Akchurin"rafael.akchurin at diladele.com
> Why not to setup HAproxy in front of your ICAP instances?
> Best regards
The haproxy was actually occurred to me before,but I am confused how to configure
1?How can I configure squid that the next traffic will go to haproxy.
2?Shouldn't the IP of the c-icap list by icap_service. if listed in haproxy,how to configure icap_service
yanghe 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160916/a3b8630a/attachment.htm>

From yvoinov at gmail.com  Fri Sep 16 12:04:50 2016
From: yvoinov at gmail.com (Yuri)
Date: Fri, 16 Sep 2016 18:04:50 +0600
Subject: [squid-users] SQUID 3.4.8 on RPi 3
In-Reply-To: <1474026652857-4679556.post@n4.nabble.com>
References: <1474026652857-4679556.post@n4.nabble.com>
Message-ID: <9cd977fb-1fa2-803d-d06d-7bf181cd33ca@gmail.com>



16.09.2016 17:50, VB ?????:
> Hi guys
>
> I'd like to ask you for a suggestion..
>
> I'm running SQUID 3.4.8 under Rasberry PI3 (Rasbian Jesse) - proxy server
> "intercept" mode (with iptables forwarding rule to 3128).
>
> I've created ACL for devices (ipad, mobiles...) - time based, because I
> need to allow Internet connection restricted at some hours only to some
> children devices.
>
> The proxy works quite well.. it stops correctly HTTP...but... I'm facing an
> issue with HTTPS:
> Infact.. all http:\\addresses are stopped.. but for example
> https:\\www.google.com not..
>
> Questions:
> 1. How can I stop both http and https?
http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
> 2. In case I'd like to compile a new squid version.. like the 3.5.21 on
> Rasbian Jesse.. how can I do?
http://wiki.squid-cache.org/CategoryKnowledgeBase
>
> thx a lot for your feedback
> Vincenzo
>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SQUID-3-4-8-on-RPi-3-tp4679556.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Fri Sep 16 14:34:33 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 17 Sep 2016 02:34:33 +1200
Subject: [squid-users] Delay pools for authentcated users
In-Reply-To: <BN3PR0801MB229113B4E815233F8CF4759C9EF30@BN3PR0801MB2291.namprd08.prod.outlook.com>
References: <BN3PR0801MB229113B4E815233F8CF4759C9EF30@BN3PR0801MB2291.namprd08.prod.outlook.com>
Message-ID: <4bfe0297-ce91-9aa0-43fb-bfc5337b8c8f@treenet.co.nz>

On 16/09/2016 11:45 p.m., Ver?nica Ovando wrote:
> Hi!
> 
> I am trying to set up delay pools for AD authenticated users.
> 
> I run Squid 3.4.8 in a Debian 8 server.
> 
> 
> I configured come delay pools, but they really don't have effect. What I want to do is to provide full bandwidth for some pages and create a delay for ALL the others. This is because I can't restrict internet surfing and I need a solution and control bandwidth usage.
> 
> 
> (Squid is working without problems with AD, so I will omit some directives about authentication )
> 

delay_access is a 'fast' category access control. It cannot do auth or
group lookups itself. In order to work with those type of ACL it
requires a previous access control (usually http_access) to have checked
them first and recorded the results as part of the transacion state.


> 
> For example:
> 
> 
> #****************************ACLs**************************#
> 
> acl AD_Standard external Grupos_AD Standard
> 
> acl redLocal src 90.0.0.0/22
> 
> 
> 
> #****************************Delay Pools**************************#
> 
> delay_pools 3
> 
> 
> delay_class 1 4
> 
> delay_access 1 allow AD_Standard socialNets
> delay_access 1 deny all
> delay_parameters 1 32000/32000 8000/8000 600/64000 1000/10000
> 
> delay_class 2 1
> delay_parameters 2 -1/-1

This is a useless pool. It wastes time calculating bandwidth caps
delays, only to not do any limiting.

Instead of having an "unlimited" pool, simply deny these transactions
from having one of the other pools applied to them. By definition
anything which does not have a pool assigned is unlimited.


Especially since when a transaction meets the criteria for multiple
pools they will *all* have some effect on that transactions bandwidth.
Which can lead to some weird behaviours and (negative!) available
bandwidth values in the byte accounting.


> delay_access 2 allow redLocal redLocal
> delay_access 2 allow redLocal oficiales
> delay_access 2 allow redLocal diarios
> delay_access 2 allow redLocal bancos
> delay_access 2 allow redLocal tarjCred
> delay_access 2 allow redLocal inmueble
> delay_access 2 allow redLocal mails
> delay_access 2 allow redLocal externos
> delay_access 2 allow redLocal varias
> delay_access 2 allow redLocal servicios
> delay_access 2 deny all
> 
> delay_class 3 4
> delay_parameters 3 32000/32000 8000/8000 10000/64000 15000/50000
> delay_access 3 allow AD_Standard all
> delay_access 3 deny all
> 
> #*******************************************************************************************#
> 
> 
> So, I am creating three delay_pools, the first one provides 10KB for
> each user (for the AD group Standard), no matters hoy many hosts are
> logged in; the second one provides full usage of the bandwidth for my
> local network to access those pages; the third delay provides up to 50KB
> for the ALL the websites, with exception of those defined in the delay
> 2. Is this correct?

No. The 'restore' is the averaged N/sec byte amount. The smallest of the
parameters for each pool will be the limiting factor.


A transaction that gets assigned to pool #3 will be able to download at
most (ever) 8000 bytes in one second (due to the 8000/8000 bucket). The
other buckets are all larger, so they will refill faster than they are
allowed to drain.
 ** Also the 8000 bucket is the per-network bucket. So you have 8000
bytes/sec being shared by each /24 subnet of clients.


A transaction that gets assigned to pool #1 will be able to download at
most (ever) 8000 bytes in one second (due to the 8000/8000 bucket).
However, the other pools refill at slower rates so it gets more complex...

Assuming that pool #1 is completely full to begin with, and only 1
transaction happens:
 For the 1st second of transfer that maximum 8000 B/sec will happen.
 For the 2nd second of transfer the bandwidth will drop to 3000 B/sec
(there will now only be 3000 bytes in the per-user bucket).
 For the 3rd second of transfer the bandwidth will drop to 1000 B/sec
(the refill rate of the per-user bucket).
 Then 135 seconds later if the transaction is still going the 64000
bucket will be drained and start limiting the transfer to 600 B/sec (the
refill rate of the per-network bucket).

If anything else is going on these buckets may drain faster than
mentioned above as they may (or not) get shared by parallel transaction
and clients.
 If the proxy gets loaded you will increasingly not see the initial
'high' speeds, just the 1000 B/sec or 600 B/sec rates being applied most
of the time.

Amos



From huaraz at moeller.plus.com  Fri Sep 16 20:11:52 2016
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Fri, 16 Sep 2016 21:11:52 +0100
Subject: [squid-users] Problem with Kerberos and
	ext_kerberos_ldap_group_acl not being able to reach realm's KDC
In-Reply-To: <955b9071-4d07-f0a2-2925-8f63fa3324af@coronamundi.de>
References: <955b9071-4d07-f0a2-2925-8f63fa3324af@coronamundi.de>
Message-ID: <nrhjm8$mu5$1@blaine.gmane.org>

Hi Silamael,

     Can you perform a kinit user at EXAMPLE.COM ?   Does the squid user have 
read access to  krb5.conf ?

Markus

"Silamael Darkomen"  wrote in message 
news:955b9071-4d07-f0a2-2925-8f63fa3324af at coronamundi.de...

Hello,

I'm currently working on setting up our proxy to authenticate the users
via Kerberos against a Windows AD.
The simple user authentication through negotiate_kerberos_auth is
already working.
But the second step for checking the group of an authenticated users
gives me some headache. Even with Kerberos configured not to search the
KDC via DNS, the ext_kerberos_ldap_group_acl tool complains about not
being able to find the realms KDC:

squid-3.5.20/helpers/external_acl/kerberos_ldap_group/kerberos_ldap_group.cc(376):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: INFO: Got User:
user Domain: EXAMPLE.COM
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_member.cc(63):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: User domain
loop: group at domain linux@
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_member.cc(91):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Default
domain loop: group at domain linux@
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_member.cc(93):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Found
group at domain linux@
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_ldap.cc(898):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Setup
Kerberos credential cache
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_krb5.cc(127):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Set
credential cache to MEMORY:squid_ldap_23191
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_krb5.cc(138):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Get default
keytab file name
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_krb5.cc(144):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Got default
keytab file name /etc/HTTP.keytab
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_krb5.cc(158):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Get
principal name from keytab /etc/HTTP.keytab
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_krb5.cc(167):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Keytab entry
has realm name: EXAMPLE.COM
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_krb5.cc(181):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Found
principal name: host/proxy.example.com at EXAMPLE.COM
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_krb5.cc(196):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: DEBUG: Got
principal name host/proxy.example.com at EXAMPLE.COM
squid-3.5.20/helpers/external_acl/kerberos_ldap_group/support_krb5.cc(64):
pid=23191 :2016/09/16 09:53:10| kerberos_ldap_group: ERROR: Error while
initialising credentials from keytab : unable to reach any KDC in realm
EXAMPLE.COM
...

The last lines of the error messages repeat for every entry in the keytab.
All other Kerberos related tools work fine with the given krb5.conf.

Some more information about the setup:
We're running under OpenBSD with Heimdal version 1.5.3.
The AD is reachable from the proxy machine but DNS is not done by the AD
but on the proxy machine itself.

Below you find the krb5.conf used and the settings from the squid.conf.
The limitation to 1 child is just for testing purposes.

Would be really great if anyone could shed some light on this issue!

Thanks in advance,
Matthias

---------------------------------------------------------------------

krb5.conf:
[logging]
default = FILE:/var/log/krb5libs.log
kdc = FILE:/var/log/krb5kdc.log
admin_server = FILE:/var/log/kadmind.log
default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5
default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5
permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5

[libdefaults]
ticket_lifetime = 24000
default_realm = EXAMPLE.COM
default_keytab_name = /etc/HTTP.keytab
dns_lookup_kdc = no
dns_lookup_realm = no

[realms]
EXAMPLE.COM = {
        kdc = 1.2.3.4
        admin_server = 1.2.3.4
        default_domain = example.com
}

squid.conf:
auth_param negotiate program
/usr/local/libexec/squid/negotiate_kerberos_auth -di -s
HTTP/proxy.example.com
auth_param negotiate children 1
auth_param negotiate keep_alive on

external_acl_type squid_kerb_ldap children-max=1 ttl=3600
negative_ttl=3600 %LOGIN
/usr/local/libexec/squid/ext_kerberos_ldap_group_acl -di -S 1.2.3.4@ -g
linux@
acl ldap_group_check external squid_kerb_ldap
http_access deny !ldap_group_check
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 




From hardikdangar+squid at gmail.com  Fri Sep 16 21:53:11 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Sat, 17 Sep 2016 03:23:11 +0530
Subject: [squid-users] cache github zip repositories
In-Reply-To: <CA+sSnVYomLi=n+dqNmAkP5uA6j9z=GKaEw9_7AM1qH+mNZXw_w@mail.gmail.com>
References: <CA+sSnVYomLi=n+dqNmAkP5uA6j9z=GKaEw9_7AM1qH+mNZXw_w@mail.gmail.com>
Message-ID: <CA+sSnVYuiUo9qZ9egGBV5jJ5P=bvP93kjMWD9FDFJPsaQbQu6w@mail.gmail.com>

Amos,

Thank you very much for you reply,

But I would just like to confirm this,

I thought ETAG is something which we can verify like,

- when the server is sending response it sends ETAG.
- squid then decides to cache it with ETAG
- now if somebody tries to fetch the same URL given they are on same squid
network, squid will send previously saved copy of the ETag along with the
request in a "If-None-Match" field.
- On this subsequent request, the server may now compare the client's ETag
with the ETag for the current version of the resource. If the ETag values
match, meaning that the resource has not changed, then the server may send
back a very short response with a HTTP 304 Not Modified status. The 304
status tells the client that its cached version is still good and that it
should use that.

Now comparing this to our GitHub example.
- when we request https://codeload.github.com/hardikdangar/test/zip/master
it has
 ETag: "9ea9838812d6f7bc53763eb1577da04e2fa473d5"
- even if you request it after a day ETAG remains the same as long as
repository is not changed.
- So when i request that file again squid would not send request with ETAG
to server ?

( just to clarify, github does not change ETAG unless you change files in
repo). My concern is if ETAG is not changed then we want to use the cache
but if its change then we want to download copy of new version.

now based on your answer you have said it will not request the file again
until min time defined in referesh_pattern. what if i set the request min
time to be like 1 minute in referesh_pattern ? will it cause squid to check
ETAG with server and it will serve cached file as ETAG is not changed. or
will it just drop the cached file after a minute and download new file ?

Sorry for all of my noob questions but i am just trying to understand squid
and its options. it's really fascinating software and really appreciate
your answers here.

Thank you very much.
Have a good day.




On Fri, Sep 16, 2016 at 12:39 PM, Hardik Dangar <
hardikdangar+squid at gmail.com> wrote:

> *Amos,*
>
> Thanks for the reply but it seems i am not able to tell you what i want to do. i don't want to cache repo files. i want to cache .zip files only. i don't want .git file to cache but only .zip files which are fetch from github.com,
>
> Also you have said things about commits but i am talking about zip file which is given by github via download button or composer fetches those files via command line directly. as soon as someone commits zip file's ETag is changed when you fetch it.
>
> So there is no way to achieve this ? Do you think there is a way to achieve this ?
>
>
> *Consider: how does Squid know the ETag has changed on the server?**What you know about things happening in RL is not what Squid knows.*
>> *I fact how do *you* know someone else did not commit a change during*
>> *that ~1 second it takes to look at the page and click the download button?** Simply, you don't, and cannot until the new object has been fetched.*
>> *Likewise, Squid cannot know if the object is the same until it has*
>> *fetched a MISS from the server. Except that Squid does not look at the*
>> *previous page content, so it cannot even 'see' if there is a commit*
>> *listed there that might be different since whenever it got the previous**object.*
>> *There is no Cache-Control or Expires header indicating a specific*
>> *storage timeout or revalidation procedure. So refresh_pattern defaults*
>> *will be used. These responses will be cached for the refresh_pattern**'Min' duration (900 minutes) before being considered for revalidated.*
>> *NP 1: Synthesizing Last-Modified from the Date header is only just being*
>> *fixed in Squid the past few weeks, and some parts of it still to be*
>> *committed. So I would not expect that response to be revalidated, just**re-fetched fully in older Squid.*
>> *NP 2: The Vary header indicates that every person logged in gets a*
>> *differently cached response based on how their credentials are hashed on*
>> *each request (in Authorization tokens). So caching these objects will*
>> *not help much with many developers involved. It will be of most help for**the anonymous visitors where username is always a generic NIL value.*
>> *HTH**Amos*
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160917/cb6cc96d/attachment.htm>

From temporalev at gmail.com  Sat Sep 17 06:38:37 2016
From: temporalev at gmail.com (VB)
Date: Fri, 16 Sep 2016 23:38:37 -0700 (PDT)
Subject: [squid-users] SQUID 3.4.8 on RPi 3
In-Reply-To: <9cd977fb-1fa2-803d-d06d-7bf181cd33ca@gmail.com>
References: <1474026652857-4679556.post@n4.nabble.com>
 <9cd977fb-1fa2-803d-d06d-7bf181cd33ca@gmail.com>
Message-ID: <1474094317965-4679562.post@n4.nabble.com>

Hi Yuri

thx a lot for your links.. following the first one, what I did:

1. Create and sign the .pem certificate

2. Update my squid.conf with:
https_port 3130 ssl-bump \
cert=/etc/squid/ssl/myCA.pem \
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

acl step1 at_step SslBump1

ssl_bump peek step1
ssl_bump bump all

but when I check the configuration (squid3 -k  parse), I get:

Processing: https_port 3130 ssl-bump cert=/etc/squid/ssl/myCA.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
ERROR: 'https_port' requires --enable-ssl
Processing: acl step1 at_step SslBump1
FATAL: Invalid ACL type 'at_step'
FATAL: Bungled /etc/squid3/squid.conf line 130: acl step1 at_step SslBump1

how can I overcome these errors on squid 3.4.8?
Is my version of squid ssl-enabled? and if not.. how can I re-configure it?

thx
Vincenzo



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SQUID-3-4-8-on-RPi-3-tp4679556p4679562.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rafael.akchurin at diladele.com  Sat Sep 17 07:26:12 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Sat, 17 Sep 2016 07:26:12 +0000
Subject: [squid-users] SQUID 3.4.8 on RPi 3
In-Reply-To: <1474094317965-4679562.post@n4.nabble.com>
References: <1474026652857-4679556.post@n4.nabble.com>
 <9cd977fb-1fa2-803d-d06d-7bf181cd33ca@gmail.com>
 <1474094317965-4679562.post@n4.nabble.com>
Message-ID: <DB6PR0401MB26809A082AA78DC300DCC4688FF20@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Hello VB,

Hopefully this will be helpful to recompile Squid on Raspberry PI - http://docs.diladele.com/administrator_guide_4_6/install/rpi/squid.html

Scripts to do that are https://github.com/ra-at-diladele-com/qlproxy_external/tree/master/src/va/scripts.debian8

Best regards,
Rafael Akchurin
Diladele B.V. 
http://www.quintolabs.com
http://www.diladele.com

--
Please take a look at Web Safety - our ICAP based web filter server for Squid proxy.




-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of VB
Sent: Saturday, September 17, 2016 8:39 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] SQUID 3.4.8 on RPi 3

Hi Yuri

thx a lot for your links.. following the first one, what I did:

1. Create and sign the .pem certificate

2. Update my squid.conf with:
https_port 3130 ssl-bump \
cert=/etc/squid/ssl/myCA.pem \
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

acl step1 at_step SslBump1

ssl_bump peek step1
ssl_bump bump all

but when I check the configuration (squid3 -k  parse), I get:

Processing: https_port 3130 ssl-bump cert=/etc/squid/ssl/myCA.pem generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
ERROR: 'https_port' requires --enable-ssl
Processing: acl step1 at_step SslBump1
FATAL: Invalid ACL type 'at_step'
FATAL: Bungled /etc/squid3/squid.conf line 130: acl step1 at_step SslBump1

how can I overcome these errors on squid 3.4.8?
Is my version of squid ssl-enabled? and if not.. how can I re-configure it?

thx
Vincenzo



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SQUID-3-4-8-on-RPi-3-tp4679556p4679562.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From ahmed.zaeem at netstream.ps  Sat Sep 17 09:05:18 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Sat, 17 Sep 2016 12:05:18 +0300
Subject: [squid-users] proxy authorization header remover from 3.5.x
	squid
In-Reply-To: <c15f7d2f-1a21-d09e-7fae-599ad77d5742@treenet.co.nz>
References: <965C1E8E-0F8A-4EBE-86CD-B5F6D2539409@netstream.ps>
 <f86a9e56-a63e-c4be-6644-da7efedc8486@treenet.co.nz>
 <C3C31A3A-AF91-4069-893D-F7931179B776@gmail.com>
 <c15f7d2f-1a21-d09e-7fae-599ad77d5742@treenet.co.nz>
Message-ID: <55162AC7-6EB6-417F-9318-322C7F22BF7D@netstream.ps>

Hi Amos again 

all what i need is the proxy authorization header get removed since some websites will ban may proxy incase there were any headers that comes with the proxy .

thats all

i could see that header myself in firefox as :
proxy-authorization "Basic ZHJ2aXJ1czpkcnZpcnVz?

regarding to the upstream proxy , 
do you mean i setup cache peer directive to other proxy and the that header is gone ??

thanks 
> On Sep 4, 2016, at 6:41 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 5/09/2016 3:31 a.m., Ahmed Alzaeem wrote:
>> hi amos I?m curious to have my proxies not being detected from others .
>> 
> 
> Then you choose to make your clients and network internal structore
> entirely visible to the upstream servers.
> 
> You can hide your network structure and clients, or you can hide the
> proxy. Not both.
> 
> 
>> thats all .
>> 
>> i already tried the header access directive 
>> request_header_access Proxy-Connection deny  all
>> request_header_access Proxy-Authorization deny all
>> request_header_access Proxy-Authenticate deny  all
>> 
>> 
>> but i still see the header 
>> 
> 
> Er. Those are hop-by-hop headers.
> 
> * Proxy-Connection is an experimental header that has not had any
> meaningful use since Netscape Navigator 4.x died out.
> 
> * Squid removes the Auth related headers on upstream connections unless
> you configure Squid to authenticate against the upstream server or proxy
> the message is going to. see RFC 7235 for details on that.
> 
> * requests on the client->Squid connection are not under your control.
> They are generated by the client.
> 
> 
> Also, you said "my proxy which has usr/pwd using basic_ncsa auth".
> That means you have proxy authentication configured to happen. A forward
> proxy can only do HTTP authentication with the use of Proxy-Auth* headers.
> 
> Amos
> 
> 
>> 
>> thank you 
>> 
>>> On Sep 3, 2016, at 4:53 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>> 
>>> On 3/09/2016 9:18 p.m., --Ahmad-- wrote:
>>>> hi squid users ,
>>>> I?m looking for the directive that will remove 
>>>> proxy authorization header 
>>>> 
>>>> when i analyze my proxy which has usr/pwd using basic_ncsa auth 
>>>> 
>>>> it still show that header 
>>>> 
>>>> not sure  the directive to remove that header .
>>>> 
>>>> ?
>>> 
>>> I don't understand why authentication happening would be a problem after
>>> you configured it to happen.
>>> 
>>> Can you describe the problem in a bit more detail please?
>>> 
>>> Amos
>>> 
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
> http://lists.squid-cache.org/listinfo/squid-users <http://lists.squid-cache.org/listinfo/squid-users>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160917/03508a74/attachment.htm>

From squid3 at treenet.co.nz  Sat Sep 17 09:35:28 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 17 Sep 2016 21:35:28 +1200
Subject: [squid-users] proxy authorization header remover from 3.5.x
	squid
In-Reply-To: <55162AC7-6EB6-417F-9318-322C7F22BF7D@netstream.ps>
References: <965C1E8E-0F8A-4EBE-86CD-B5F6D2539409@netstream.ps>
 <f86a9e56-a63e-c4be-6644-da7efedc8486@treenet.co.nz>
 <C3C31A3A-AF91-4069-893D-F7931179B776@gmail.com>
 <c15f7d2f-1a21-d09e-7fae-599ad77d5742@treenet.co.nz>
 <55162AC7-6EB6-417F-9318-322C7F22BF7D@netstream.ps>
Message-ID: <c44a438b-f29d-7217-c5e0-4af7a77e7703@treenet.co.nz>

On 17/09/2016 9:05 p.m., --Ahmad-- wrote:
> Hi Amos again 
> 
> all what i need is the proxy authorization header get removed since some websites will ban may proxy incase there were any headers that comes with the proxy .
> 
> thats all
> 
> i could see that header myself in firefox as :
> proxy-authorization "Basic ZHJ2aXJ1czpkcnZpcnVz?
> 

HTTP is a stateless and multiplexed protocol.

Firefox only sees the connection between it and the proxy. It cannot see
what happens on any of the connection(s) outgoing from the proxy.

Note: the proxy may not even be using HTTP to fetch the data it sends
back as an HTTP response.

If you want to see what Squid is sending upstream the way to do that is
to enable "debug_options 11,2" and look for the "Server HTTP" messages
in cache.log. They might surprise you.


> regarding to the upstream proxy , 
> do you mean i setup cache peer directive to other proxy and the that header is gone ??
> 

Certain headers in HTTP are only relevant to a single TCP connection.
These are called "hop-by-hop" headers.

They get erased on the receiving agent. Different ones containing same
or similar content MAY be generated outgoing from that agent, but only
if required by that different proxy->upstream TCP connection.

The request_header_access rules you configured earlier *only* affect
these outgoing proxy requests. Note that they are the ones Firefox
*cannot* see.

However;
* All the Proxy-Auth* headers are hop-by-hop headers.

* Proxy-Connection is a long ago obsolete experimental header. So Squid
receives it but never sends.

You only need those request_header_access rules to remove Proxy-*
headers *IF* they are actually being sent out by _Squid_ in that 11,2
debugs trace. Having them sent by Firfox is irrelevant.

Amos



From ahmed.zaeem at netstream.ps  Sat Sep 17 09:41:03 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Sat, 17 Sep 2016 12:41:03 +0300
Subject: [squid-users] proxy authorization header remover from 3.5.x
	squid
In-Reply-To: <c44a438b-f29d-7217-c5e0-4af7a77e7703@treenet.co.nz>
References: <965C1E8E-0F8A-4EBE-86CD-B5F6D2539409@netstream.ps>
 <f86a9e56-a63e-c4be-6644-da7efedc8486@treenet.co.nz>
 <C3C31A3A-AF91-4069-893D-F7931179B776@gmail.com>
 <c15f7d2f-1a21-d09e-7fae-599ad77d5742@treenet.co.nz>
 <55162AC7-6EB6-417F-9318-322C7F22BF7D@netstream.ps>
 <c44a438b-f29d-7217-c5e0-4af7a77e7703@treenet.co.nz>
Message-ID: <A5FB4274-43DE-4E73-93D1-676D836E508A@netstream.ps>

Hi Amos thanks for the reply 

so indeed I?m only interested with connection between the proxy and the website that I?m visiting .

all what I?m care is the website i visit don?t see any headers that indicate that I?m coming from a proxy 

i also tried with x-cache-header but i still see it in my firefox .

i have final question 

can i have squid proxy that the website that i visit see it exactly as I?m using socks5 ???

i believe socks5 is not seen at all and don?t leak any headers

i hope so


cheers 
> On Sep 17, 2016, at 12:35 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 17/09/2016 9:05 p.m., --Ahmad-- wrote:
>> Hi Amos again 
>> 
>> all what i need is the proxy authorization header get removed since some websites will ban may proxy incase there were any headers that comes with the proxy .
>> 
>> thats all
>> 
>> i could see that header myself in firefox as :
>> proxy-authorization "Basic ZHJ2aXJ1czpkcnZpcnVz?
>> 
> 
> HTTP is a stateless and multiplexed protocol.
> 
> Firefox only sees the connection between it and the proxy. It cannot see
> what happens on any of the connection(s) outgoing from the proxy.
> 
> Note: the proxy may not even be using HTTP to fetch the data it sends
> back as an HTTP response.
> 
> If you want to see what Squid is sending upstream the way to do that is
> to enable "debug_options 11,2" and look for the "Server HTTP" messages
> in cache.log. They might surprise you.
> 
> 
>> regarding to the upstream proxy , 
>> do you mean i setup cache peer directive to other proxy and the that header is gone ??
>> 
> 
> Certain headers in HTTP are only relevant to a single TCP connection.
> These are called "hop-by-hop" headers.
> 
> They get erased on the receiving agent. Different ones containing same
> or similar content MAY be generated outgoing from that agent, but only
> if required by that different proxy->upstream TCP connection.
> 
> The request_header_access rules you configured earlier *only* affect
> these outgoing proxy requests. Note that they are the ones Firefox
> *cannot* see.
> 
> However;
> * All the Proxy-Auth* headers are hop-by-hop headers.
> 
> * Proxy-Connection is a long ago obsolete experimental header. So Squid
> receives it but never sends.
> 
> You only need those request_header_access rules to remove Proxy-*
> headers *IF* they are actually being sent out by _Squid_ in that 11,2
> debugs trace. Having them sent by Firfox is irrelevant.
> 
> Amos
> 



From squid3 at treenet.co.nz  Sat Sep 17 10:02:34 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 17 Sep 2016 22:02:34 +1200
Subject: [squid-users] proxy authorization header remover from 3.5.x
	squid
In-Reply-To: <A5FB4274-43DE-4E73-93D1-676D836E508A@netstream.ps>
References: <965C1E8E-0F8A-4EBE-86CD-B5F6D2539409@netstream.ps>
 <f86a9e56-a63e-c4be-6644-da7efedc8486@treenet.co.nz>
 <C3C31A3A-AF91-4069-893D-F7931179B776@gmail.com>
 <c15f7d2f-1a21-d09e-7fae-599ad77d5742@treenet.co.nz>
 <55162AC7-6EB6-417F-9318-322C7F22BF7D@netstream.ps>
 <c44a438b-f29d-7217-c5e0-4af7a77e7703@treenet.co.nz>
 <A5FB4274-43DE-4E73-93D1-676D836E508A@netstream.ps>
Message-ID: <fd7f7b18-2374-a480-4971-90bb43ff3204@treenet.co.nz>

On 17/09/2016 9:41 p.m., --Ahmad-- wrote:
> Hi Amos thanks for the reply 
> 
> so indeed I?m only interested with connection between the proxy and the website that I?m visiting .
> 
> all what I?m care is the website i visit don?t see any headers that indicate that I?m coming from a proxy 
> 
> i also tried with x-cache-header but i still see it in my firefox .

As I said. Your firefox details are irrelevant. That is about a
completely different TCP connection to what goes to the website server.


> 
> i have final question 
> 
> can i have squid proxy that the website that i visit see it exactly as I?m using socks5 ???

SOCKS is not HTTP. Squid is an HTTP proxy.

If you want a cup of wine, you dont pour yourself a cup of orange juice.

SOCKS is about proxying TCP packets. If you want that level of
transparency, then use it. Don't use Squid.

Amos



From yvoinov at gmail.com  Sat Sep 17 10:03:27 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 17 Sep 2016 16:03:27 +0600
Subject: [squid-users] SQUID 3.4.8 on RPi 3
In-Reply-To: <1474094317965-4679562.post@n4.nabble.com>
References: <1474026652857-4679556.post@n4.nabble.com>
 <9cd977fb-1fa2-803d-d06d-7bf181cd33ca@gmail.com>
 <1474094317965-4679562.post@n4.nabble.com>
Message-ID: <a08f8c87-5287-89e2-8abd-dfb15b16d2e9@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


17.09.2016 12:38, VB ?????:
> Hi Yuri
>
> thx a lot for your links.. following the first one, what I did:
>
> 1. Create and sign the .pem certificate
>
> 2. Update my squid.conf with:
> https_port 3130 ssl-bump \
> cert=/etc/squid/ssl/myCA.pem \
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>
> acl step1 at_step SslBump1
>
> ssl_bump peek step1
> ssl_bump bump all
>
> but when I check the configuration (squid3 -k  parse), I get:
>
> Processing: https_port 3130 ssl-bump cert=/etc/squid/ssl/myCA.pem
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> ERROR: 'https_port' requires --enable-ssl
> Processing: acl step1 at_step SslBump1
> FATAL: Invalid ACL type 'at_step'
> FATAL: Bungled /etc/squid3/squid.conf line 130: acl step1 at_step SslBump1
>
> how can I overcome these errors on squid 3.4.8?
Drop it out. This is antique version which not yet supported modern SSL
Bump ACL's/directives.

As Wiki, by the way, is written about the implementation of different
versions of the SSL bump in different SQUID. You need to carefully read.
>
> Is my version of squid ssl-enabled? and if not.. how can I
re-configure it?
Yes, but SSL bump has different implementation in antique 3.4.x.
>
>
> thx
> Vincenzo
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/SQUID-3-4-8-on-RPi-3-tp4679556p4679562.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX3RTvAAoJENNXIZxhPexGJX8IAJ+73xZ4W9R8fxZibyJ8y2lQ
GbxfMmoN9DW49RSqjMXNpLSi+Pqs/dcR0dySS7QwtL3cI/EnMP99ZsNFjxT8RUgi
KsEiz0khi9lqkCeoYAJuQCUSD767T6jVTIGBEyMEQNMXynLzJV8QdfHafFBOETOP
pIEzF8dkEPshohyjTrMcHojRiXA2EjXYwfNDSJb5k31F18adJ2ojcb7T6FikaVr2
w9nOiltEVxjCAere95AuhsMp1iW5ploKYHMP/0u3Pqwm5TPqlLhsUL1V4xAsCD/m
+iItqH+wQO3eLabmGcsPRctDAMOZsGdmXdZU1zpnQI6qgPagCtj7vi7JOZvZm9Y=
=whNB
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160917/335153c5/attachment.key>

From yvoinov at gmail.com  Sat Sep 17 09:59:04 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 17 Sep 2016 15:59:04 +0600
Subject: [squid-users] SQUID 3.4.8 on RPi 3
In-Reply-To: <1474094317965-4679562.post@n4.nabble.com>
References: <1474026652857-4679556.post@n4.nabble.com>
 <9cd977fb-1fa2-803d-d06d-7bf181cd33ca@gmail.com>
 <1474094317965-4679562.post@n4.nabble.com>
Message-ID: <7e8962f9-df0c-db69-205b-6fd256f0008f@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


17.09.2016 12:38, VB ?????:
> Hi Yuri
>
> thx a lot for your links.. following the first one, what I did:
>
> 1. Create and sign the .pem certificate
>
> 2. Update my squid.conf with:
> https_port 3130 ssl-bump \
> cert=/etc/squid/ssl/myCA.pem \
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>
> acl step1 at_step SslBump1
>
> ssl_bump peek step1
> ssl_bump bump all
>
> but when I check the configuration (squid3 -k  parse), I get:
>
> Processing: https_port 3130 ssl-bump cert=/etc/squid/ssl/myCA.pem
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> ERROR: 'https_port' requires --enable-ssl
> Processing: acl step1 at_step SslBump1
> FATAL: Invalid ACL type 'at_step'
> FATAL: Bungled /etc/squid3/squid.conf line 130: acl step1 at_step SslBump1
>
> how can I overcome these errors on squid 3.4.8?
Drop it out. This is antique version which not yet supported modern SSL
Bump ACL's/directives.
>
> Is my version of squid ssl-enabled? and if not.. how can I
re-configure it?
Yes, but SSL bump has different implementation in antique 3.4.x.
>
>
> thx
> Vincenzo
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/SQUID-3-4-8-on-RPi-3-tp4679556p4679562.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX3RPoAAoJENNXIZxhPexGPXAIAI0dBkbBSZCYksa74JxVqNVY
mXySn5w8BSQ9lXE1SDvNrekjTEN69Zgt3hJ6B5hlaXLVOPqa9QoRtrQY0LrfCuA+
Amh9Oqp+KfRJi10EAXXq1r6iIfuSFQ+4Wup/bg0PzPbPlvPl3qTqXuVxcH9kBuHe
0RKGuVDty5EE4BaLmzW8PCBF9hcY5RNWe3XhiphlPJAbtDSJk0a6VZe4tirxRGwB
RLqponHgZ8enFCpjJocMBgCPfvYTFQvDYZ0mShN3HULYn6pB+Yc3FFulRX+NSvd/
u9YGXk0mY27Qv2IlguFGARufRnEqaCXav08+11XW/PJIdUkgcIGK5BHDLe+zFv0=
=hHYX
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160917/f06de81e/attachment.key>

From ahmed.zaeem at netstream.ps  Sat Sep 17 10:41:54 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Sat, 17 Sep 2016 13:41:54 +0300
Subject: [squid-users] proxy authorization header remover from 3.5.x
	squid
In-Reply-To: <fd7f7b18-2374-a480-4971-90bb43ff3204@treenet.co.nz>
References: <965C1E8E-0F8A-4EBE-86CD-B5F6D2539409@netstream.ps>
 <f86a9e56-a63e-c4be-6644-da7efedc8486@treenet.co.nz>
 <C3C31A3A-AF91-4069-893D-F7931179B776@gmail.com>
 <c15f7d2f-1a21-d09e-7fae-599ad77d5742@treenet.co.nz>
 <55162AC7-6EB6-417F-9318-322C7F22BF7D@netstream.ps>
 <c44a438b-f29d-7217-c5e0-4af7a77e7703@treenet.co.nz>
 <A5FB4274-43DE-4E73-93D1-676D836E508A@netstream.ps>
 <fd7f7b18-2374-a480-4971-90bb43ff3204@treenet.co.nz>
Message-ID: <CBD63540-BEBF-48CA-ABB7-328BCEE98D19@netstream.ps>

thanks Amos

BTW is there a method that i check the headers on the website level ?

like ti setup remote apache server and then analyze the headers ?


cheers 
> On Sep 17, 2016, at 1:02 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 17/09/2016 9:41 p.m., --Ahmad-- wrote:
>> Hi Amos thanks for the reply 
>> 
>> so indeed I?m only interested with connection between the proxy and the website that I?m visiting .
>> 
>> all what I?m care is the website i visit don?t see any headers that indicate that I?m coming from a proxy 
>> 
>> i also tried with x-cache-header but i still see it in my firefox .
> 
> As I said. Your firefox details are irrelevant. That is about a
> completely different TCP connection to what goes to the website server.
> 
> 
>> 
>> i have final question 
>> 
>> can i have squid proxy that the website that i visit see it exactly as I?m using socks5 ???
> 
> SOCKS is not HTTP. Squid is an HTTP proxy.
> 
> If you want a cup of wine, you dont pour yourself a cup of orange juice.
> 
> SOCKS is about proxying TCP packets. If you want that level of
> transparency, then use it. Don't use Squid.
> 
> Amos
> 



From temporalev at gmail.com  Sat Sep 17 13:02:07 2016
From: temporalev at gmail.com (VB)
Date: Sat, 17 Sep 2016 06:02:07 -0700 (PDT)
Subject: [squid-users] SQUID 3.4.8 on RPi 3
In-Reply-To: <7e8962f9-df0c-db69-205b-6fd256f0008f@gmail.com>
References: <1474026652857-4679556.post@n4.nabble.com>
 <9cd977fb-1fa2-803d-d06d-7bf181cd33ca@gmail.com>
 <1474094317965-4679562.post@n4.nabble.com>
 <7e8962f9-df0c-db69-205b-6fd256f0008f@gmail.com>
Message-ID: <1474117327060-4679571.post@n4.nabble.com>

Hi Yuri

which version do you suggest for Raspian Jesse?
Is it OK the 3.5.21?
thx
Vincenzo 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SQUID-3-4-8-on-RPi-3-tp4679556p4679571.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From temporalev at gmail.com  Sat Sep 17 13:04:32 2016
From: temporalev at gmail.com (VB)
Date: Sat, 17 Sep 2016 06:04:32 -0700 (PDT)
Subject: [squid-users] SQUID 3.4.8 on RPi 3
In-Reply-To: <DB6PR0401MB26809A082AA78DC300DCC4688FF20@DB6PR0401MB2680.eurprd04.prod.outlook.com>
References: <1474026652857-4679556.post@n4.nabble.com>
 <9cd977fb-1fa2-803d-d06d-7bf181cd33ca@gmail.com>
 <1474094317965-4679562.post@n4.nabble.com>
 <DB6PR0401MB26809A082AA78DC300DCC4688FF20@DB6PR0401MB2680.eurprd04.prod.outlook.com>
Message-ID: <1474117472190-4679572.post@n4.nabble.com>

Hi Rafael

thx a lot.. I'm trying also your suggestion.. but this is the errors I'm
facing:

1. I've download the squid-3.4.8 source.. but this does not contain
/debian/rules dir. Anyhow I've manually created it..

2. Running 04_squid.sh..these are the errors:
File squid-3.4.8/debian/rules is not a regular file -- refusing to patch
File squid-3.4.8/debian/rules is read-only; trying to patch anyway
patch: **** Can't create temporary file squid-3.4.8/debian/rules.oRDX0tF :
Permission denied

thx
vincenzo



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SQUID-3-4-8-on-RPi-3-tp4679556p4679572.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sat Sep 17 13:22:31 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sat, 17 Sep 2016 19:22:31 +0600
Subject: [squid-users] SQUID 3.4.8 on RPi 3
In-Reply-To: <1474117327060-4679571.post@n4.nabble.com>
References: <1474026652857-4679556.post@n4.nabble.com>
 <9cd977fb-1fa2-803d-d06d-7bf181cd33ca@gmail.com>
 <1474094317965-4679562.post@n4.nabble.com>
 <7e8962f9-df0c-db69-205b-6fd256f0008f@gmail.com>
 <1474117327060-4679571.post@n4.nabble.com>
Message-ID: <f544baf3-37ac-5dc3-ef33-53bc988ab895@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
IDK. I'm not Linux fanboy.


17.09.2016 19:02, VB ?????:
> Hi Yuri
>
> which version do you suggest for Raspian Jesse?
> Is it OK the 3.5.21?
Probably. At least 3.5.20.
>
> thx
> Vincenzo
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/SQUID-3-4-8-on-RPi-3-tp4679556p4679571.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX3UOXAAoJENNXIZxhPexGWA8IAMXqd9UwK7qyDWWC9AnHw6ir
+JkI4DXQwpObsbeOQi+xPnk7nexu3eWHm7B0ayVY6bdCiZCndZzNzqrquCohbgoS
SEqd5NIoksdpVNq/36fQt9/FegmO3keUTxpDdc0FsthGZBcnramaGdw2Xz5X1ThE
V+BLTL7WOLf3Hx4bO99xK+CISZE4YhMvuUJX4YY9NeC3wnNKZqT/O2yTOZfi9hgX
BzsBHGOGAOgZwyWTru6o3bt3cJvfbTwKfK9XVIZqVThl2uiDBvFzOUvAreSAlP99
MgTcBYEQ5TAS42vvbs79p7xnWHTR6y9jruEptDvNBybO7Z6j8j6/GnCSEylzKgg=
=UuSr
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160917/975687eb/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160917/975687eb/attachment.key>

From ahmed.zaeem at netstream.ps  Sat Sep 17 14:48:49 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Sat, 17 Sep 2016 17:48:49 +0300
Subject: [squid-users] squid kid/SMP limitation like 1024 ips/opened
	sessions ?????
Message-ID: <3D27A7CD-648E-41E4-92D4-C8BE585C7C11@netstream.ps>

Hi squid Guys!

i noticed something .

If i run SMP with 800 ips/listening ports ?..squid work 
if i run like 900 ports with SMP it work 

i think if i was close to the # 1000 or 1024

the SMP don?t work and i began to have ?kid registration timeout ?

is there a squid version that i can run squid with SMP like 10 workers with like 3000 ips /opened sessions without having the issue ?registration kid timeout ?? ???

i sure its squid limitation 

i  tested it on 3.5.2



i hope the newer versions fix it 


waiting Amos reply :::)


cheers 

From rafael.akchurin at diladele.com  Sat Sep 17 16:22:19 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Sat, 17 Sep 2016 16:22:19 +0000
Subject: [squid-users] SQUID 3.4.8 on RPi 3
In-Reply-To: <1474117472190-4679572.post@n4.nabble.com>
References: <1474026652857-4679556.post@n4.nabble.com>
 <9cd977fb-1fa2-803d-d06d-7bf181cd33ca@gmail.com>
 <1474094317965-4679562.post@n4.nabble.com>
 <DB6PR0401MB26809A082AA78DC300DCC4688FF20@DB6PR0401MB2680.eurprd04.prod.outlook.com>
 <1474117472190-4679572.post@n4.nabble.com>
Message-ID: <DB6PR0401MB2680AC2578FA18E6CCE5051A8FF20@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Hello VB,

You do not need to download yourself anything. The scripts I mentioned automatically download source-deb file that contains squid 3.4.8 sources. 

I would suggest rebuilding the squid 3.4.8 default in rpi first using our scripts and when you are comfortable with this - try to build latest squid yourself as Yuri suggested.

Best regards,
Rafael Akchurin
Diladele B.V.

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of VB
Sent: Saturday, September 17, 2016 3:05 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] SQUID 3.4.8 on RPi 3

Hi Rafael

thx a lot.. I'm trying also your suggestion.. but this is the errors I'm
facing:

1. I've download the squid-3.4.8 source.. but this does not contain /debian/rules dir. Anyhow I've manually created it..

2. Running 04_squid.sh..these are the errors:
File squid-3.4.8/debian/rules is not a regular file -- refusing to patch File squid-3.4.8/debian/rules is read-only; trying to patch anyway
patch: **** Can't create temporary file squid-3.4.8/debian/rules.oRDX0tF :
Permission denied

thx
vincenzo



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SQUID-3-4-8-on-RPi-3-tp4679556p4679572.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From ahmed.zaeem at netstream.ps  Sat Sep 17 16:57:43 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Sat, 17 Sep 2016 19:57:43 +0300
Subject: [squid-users] squid AUTH basic-nasa always 1st time get denied !!!
Message-ID: <8A4398A3-637C-416D-B798-2673FA235EFE@netstream.ps>

Hi Guys ,
i want to ask why always 1st time of basic-nasa auth get denied and the 2d time get work ??

I?m sure i set the right pwd , but the 1st time must give me wrong then it works

here is logs :
NE/- text/html
1474163690.278    229 68.68.102.158 TCP_MISS/200 37701 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html ilybwy HIER_DIRECT/23.213.106.42 text/html
1474163695.290      0 68.68.102.158 TCP_DENIED/407 4187 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html - HIER_NONE/- text/html
1474163695.520    230 68.68.102.158 TCP_MISS/200 34951 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html hzrcfj HIER_DIRECT/23.213.106.42 text/html
1474163700.532      0 68.68.102.158 TCP_DENIED/407 4187 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html - HIER_NONE/- text/html
1474163700.764    231 68.68.102.158 TCP_MISS/200 34951 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html dbftyv HIER_DIRECT/23.213.106.42 text/html
1474163705.777      0 68.68.102.158 TCP_DENIED/407 4187 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html - HIER_NONE/- text/html
1474163706.007    230 68.68.102.158 TCP_MISS/200 34951 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html ynsxui HIER_DIRECT/23.213.106.42 text/html
1474163711.022      0 68.68.102.158 TCP_DENIED/407 4187 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html - HIER_NONE/- text/html
1474163711.261    238 68.68.102.158 TCP_MISS/200 37700 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html mjdvka HIER_DIRECT/23.213.106.42 text/html
1474163716.279      0 68.68.102.158 TCP_DENIED/407 4187 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html - HIER_NONE/- text/html
1474163716.790    510 68.68.102.158 TCP_MISS/200 37700 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html xbrdkw HIER_DIRECT/23.213.106.42 text/html
1474163722.004      0 68.68.102.158 TCP_DENIED/407 4187 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html - HIER_NONE/- text/html
1474163722.233    227 68.68.102.158 TCP_MISS/200 34951 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html xgmbwc HIER_DIRECT/23.213.106.42 text/html



here is my auth settings :

# Lockdown Procedures
auth_param basic program /lib/squid/basic_ncsa_auth /etc/squid/squid_user
acl ncsa_users proxy_auth REQUIRED
http_access allow ncsa_users


any other optimization settings ?

also can i have other settings to let the operation faster ?


cheers 




From squid3 at treenet.co.nz  Sat Sep 17 17:52:16 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 18 Sep 2016 05:52:16 +1200
Subject: [squid-users] squid AUTH basic-nasa always 1st time get denied
 !!!
In-Reply-To: <8A4398A3-637C-416D-B798-2673FA235EFE@netstream.ps>
References: <8A4398A3-637C-416D-B798-2673FA235EFE@netstream.ps>
Message-ID: <252e5440-cd5d-f858-44be-5ba8e5bb2f39@treenet.co.nz>

On 18/09/2016 4:57 a.m., --Ahmad-- wrote:
> Hi Guys ,
> i want to ask why always 1st time of basic-nasa auth get denied and the 2d time get work ??
> 

Would you prefer your browser to broadcast your username and password
un-encrypted to anything it happens to connect to? Dangerous.

On each new TCP connection your browser sends one request with *no*
credentials. The proxy tells it that credentials are needed and what
type. Browser then repeats its request with the credentials attached.

You can reduce the number of 407 occuring by ensuring that client
persistent connections is enabled. That is on by default in current
Squid, make sure you are not disabling it in squid.conf.


> I?m sure i set the right pwd , but the 1st time must give me wrong then it works
> 
> here is logs :
> NE/- text/html
> 1474163690.278    229 68.68.102.158 TCP_MISS/200 37701 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html ilybwy HIER_DIRECT/23.213.106.42 text/html
> 1474163695.290      0 68.68.102.158 TCP_DENIED/407 4187 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html - HIER_NONE/- text/html
> 1474163695.520    230 68.68.102.158 TCP_MISS/200 34951 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html hzrcfj HIER_DIRECT/23.213.106.42 text/html
> 1474163700.532      0 68.68.102.158 TCP_DENIED/407 4187 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html - HIER_NONE/- text/html
> 1474163700.764    231 68.68.102.158 TCP_MISS/200 34951 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html dbftyv HIER_DIRECT/23.213.106.42 text/html
> 1474163705.777      0 68.68.102.158 TCP_DENIED/407 4187 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html - HIER_NONE/- text/html
> 1474163706.007    230 68.68.102.158 TCP_MISS/200 34951 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html ynsxui HIER_DIRECT/23.213.106.42 text/html
> 1474163711.022      0 68.68.102.158 TCP_DENIED/407 4187 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html - HIER_NONE/- text/html
> 1474163711.261    238 68.68.102.158 TCP_MISS/200 37700 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html mjdvka HIER_DIRECT/23.213.106.42 text/html
> 1474163716.279      0 68.68.102.158 TCP_DENIED/407 4187 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html - HIER_NONE/- text/html
> 1474163716.790    510 68.68.102.158 TCP_MISS/200 37700 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html xbrdkw HIER_DIRECT/23.213.106.42 text/html
> 1474163722.004      0 68.68.102.158 TCP_DENIED/407 4187 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html - HIER_NONE/- text/html
> 1474163722.233    227 68.68.102.158 TCP_MISS/200 34951 GET http://www.adidas.com/us/nmd_r1-shoes/S31507.html xgmbwc HIER_DIRECT/23.213.106.42 text/html
> 
> 
> 
> here is my auth settings :
> 
> # Lockdown Procedures
> auth_param basic program /lib/squid/basic_ncsa_auth /etc/squid/squid_user
> acl ncsa_users proxy_auth REQUIRED
> http_access allow ncsa_users
> 
> 
> any other optimization settings ?

With only those three config lines to go on. You can optimize by
changing the allow rule to a deny.

 http_access deny !ncsa_users
 http_access allow localnet

> 
> also can i have other settings to let the operation faster ?
> 

You will need to let us know your current squid.conf for any answers to
be meaningful.

Amos



From squid3 at treenet.co.nz  Sat Sep 17 18:33:28 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 18 Sep 2016 06:33:28 +1200
Subject: [squid-users] squid kid/SMP limitation like 1024 ips/opened
 sessions ?????
In-Reply-To: <3D27A7CD-648E-41E4-92D4-C8BE585C7C11@netstream.ps>
References: <3D27A7CD-648E-41E4-92D4-C8BE585C7C11@netstream.ps>
Message-ID: <5aa9d2bd-b611-fa75-b781-40c81ee8c2de@treenet.co.nz>

On 18/09/2016 2:48 a.m., --Ahmad-- wrote:
> Hi squid Guys!
> 
> i noticed something .
> 
> If i run SMP with 800 ips/listening ports ?..squid work if i run like
> 900 ports with SMP it work
> 
> i think if i was close to the # 1000 or 1024
> 

You are pushing Squid far outside its normal operating conditions.
Expect weird things to happen ...

> the SMP don?t work and i began to have ?kid registration timeout ?
> 
> is there a squid version that i can run squid with SMP like 10
> workers with like 3000 ips /opened sessions without having the issue
> ?registration kid timeout ?? ???

What is this "opened sessions" thing you speak of?

Listening sockets are not "sessions" by any definition of session I've
ever heard of.

> 
> i sure its squid limitation
> 

"kid registration timeout" from many listening port registrations is
more likely a UDS kernel level limitation. There are limits to how many
UDS packets can be sent through the kernel UDS bus.

> i  tested it on 3.5.2
> 
> 
> 
> i hope the newer versions fix it
> 

Maybe, maybe not. There have been optimizations done on other things
that more commonly lead to the registration timeout message. Too many
listening sockets has not been mentioned before.

Amos




From ahmed.zaeem at netstream.ps  Sat Sep 17 18:39:20 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Sat, 17 Sep 2016 21:39:20 +0300
Subject: [squid-users] squid kid/SMP limitation like 1024 ips/opened
	sessions ?????
In-Reply-To: <5aa9d2bd-b611-fa75-b781-40c81ee8c2de@treenet.co.nz>
References: <3D27A7CD-648E-41E4-92D4-C8BE585C7C11@netstream.ps>
 <5aa9d2bd-b611-fa75-b781-40c81ee8c2de@treenet.co.nz>
Message-ID: <4DF424F5-2A9F-4E92-BBB2-BFAB279AACD4@netstream.ps>

thanks amos for clarification 

i expanded the kernel to  handle high traffic 
but still the issue in squid  i believe ??.

is there anything can i do to let squid expand the 1024 sessions form kernel ?

you can imagine that I?m talking about the # of sockets seems limited to 1024 .

can i expand it form squid ?

any squid building compilation settings needed ?


kind regards


> On Sep 17, 2016, at 9:33 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 18/09/2016 2:48 a.m., --Ahmad-- wrote:
>> Hi squid Guys!
>> 
>> i noticed something .
>> 
>> If i run SMP with 800 ips/listening ports ?..squid work if i run like
>> 900 ports with SMP it work
>> 
>> i think if i was close to the # 1000 or 1024
>> 
> 
> You are pushing Squid far outside its normal operating conditions.
> Expect weird things to happen ...
> 
>> the SMP don?t work and i began to have ?kid registration timeout ?
>> 
>> is there a squid version that i can run squid with SMP like 10
>> workers with like 3000 ips /opened sessions without having the issue
>> ?registration kid timeout ?? ???
> 
> What is this "opened sessions" thing you speak of?
> 
> Listening sockets are not "sessions" by any definition of session I've
> ever heard of.
> 
>> 
>> i sure its squid limitation
>> 
> 
> "kid registration timeout" from many listening port registrations is
> more likely a UDS kernel level limitation. There are limits to how many
> UDS packets can be sent through the kernel UDS bus.
> 
>> i  tested it on 3.5.2
>> 
>> 
>> 
>> i hope the newer versions fix it
>> 
> 
> Maybe, maybe not. There have been optimizations done on other things
> that more commonly lead to the registration timeout message. Too many
> listening sockets has not been mentioned before.
> 
> Amos
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From yanghe0921 at 126.com  Sun Sep 18 07:25:06 2016
From: yanghe0921 at 126.com (yanghe)
Date: Sun, 18 Sep 2016 15:25:06 +0800
Subject: [squid-users] What's the algorithm to achieve AclRandom
Message-ID: <16ebfd1f.a6850.1573c2f2f35.Coremail.yanghe0921@126.com>

Hi
Although he said it was random,certainly based on an algorithm.
I would like to know what's the algorithm or principle  to achieve AclRandom.
Can I make certain the next traffic will go to which Web server?

Thanks in advance


2016-09-18

  yanghe 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160918/3895544b/attachment.htm>

From squid3 at treenet.co.nz  Sun Sep 18 07:49:52 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 18 Sep 2016 19:49:52 +1200
Subject: [squid-users] What's the algorithm to achieve AclRandom
In-Reply-To: <16ebfd1f.a6850.1573c2f2f35.Coremail.yanghe0921@126.com>
References: <16ebfd1f.a6850.1573c2f2f35.Coremail.yanghe0921@126.com>
Message-ID: <910d3013-41fd-6b9a-48a9-b081cf03ae15@treenet.co.nz>

On 18/09/2016 7:25 p.m., yanghe wrote:
> Hi
> Although he said it was random,certainly based on an algorithm.
> I would like to know what's the algorithm or principle  to achieve AclRandom.


ACL random uses the operating system random() number generator.

A new random number is selected each time the ACL is checked. The ACL
will declare match vs. no-match depending on whether that number is
below or above a defined squid.conf threshold value.

> Can I make certain the next traffic will go to which Web server?

Not using ACL random.

For certainty you need one of the many load balancing cache_peer
selection algorithms. Which naturally require the server(s) to be
cache_peer.

Amos



From squid3 at treenet.co.nz  Sun Sep 18 08:49:53 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 18 Sep 2016 20:49:53 +1200
Subject: [squid-users] squid kid/SMP limitation like 1024 ips/opened
 sessions ?????
In-Reply-To: <4123611E-CA6A-4EAA-9ACF-7201D24533DD@gmail.com>
References: <3D27A7CD-648E-41E4-92D4-C8BE585C7C11@netstream.ps>
 <5aa9d2bd-b611-fa75-b781-40c81ee8c2de@treenet.co.nz>
 <4123611E-CA6A-4EAA-9ACF-7201D24533DD@gmail.com>
Message-ID: <e2f330d8-8232-65f2-4bef-06abbe8de773@treenet.co.nz>

On 18/09/2016 6:38 a.m., Ahmed Alzaeem wrote:
> thanks amos for clarification 
> 
> i expanded the kernel to  handle high traffic 
> but still the issue in squid  i believe ??.
> 
> is there anything can i do to let squid expand the 1024 sessions form kernel ?

It is not a limit on number of "sessions". It is queues inside both the
kernel and Squid getting so full of actions that need to happen that
small ~50 byte packets travelling between worker processes (running
inside the same machine!) take over 6 whole seconds to arrive.

For processes on the same machine 'whole seconds' is thousands if not
millions of times slower than it should be.


> 
> you can imagine that I?m talking about the # of sockets seems limited to 1024 .
> 

The key word is "seems". To you it seems that way. Reality is that
number you are looking at is just a side effect of how fast your CPU is.
Faster or slower CPU will have different number show up as the limit -
because they will be able to process more or less actions before delays
get longer than the timeout.

Around about 1024 (or was it 1022? or 1028? or ...) the coordinator
process and kernel are doing so much work the worker processes start
thinking they have been orphaned and self-terminate.



> can i expand it form squid ?
> 
> any squid building compilation settings needed ?
> 

You can edit src/ipc/Strand.cc and change the number parameter of the line:
  setTimeout(6, "Ipc::Strand::timeoutHandler");

I would advise against making it too much different from the existing
value though.

Amos



From ahmed.zaeem at netstream.ps  Sun Sep 18 10:14:02 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Sun, 18 Sep 2016 13:14:02 +0300
Subject: [squid-users] squid kid/SMP limitation like 1024 ips/opened
	sessions ?????
In-Reply-To: <e2f330d8-8232-65f2-4bef-06abbe8de773@treenet.co.nz>
References: <3D27A7CD-648E-41E4-92D4-C8BE585C7C11@netstream.ps>
 <5aa9d2bd-b611-fa75-b781-40c81ee8c2de@treenet.co.nz>
 <4123611E-CA6A-4EAA-9ACF-7201D24533DD@gmail.com>
 <e2f330d8-8232-65f2-4bef-06abbe8de773@treenet.co.nz>
Message-ID: <BCD490B1-EB12-410B-AE36-2F3BD918786B@netstream.ps>

hi Amos 
you rock 
that solved it  !!


thank you so much 


> On Sep 18, 2016, at 11:49 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 18/09/2016 6:38 a.m., Ahmed Alzaeem wrote:
>> thanks amos for clarification 
>> 
>> i expanded the kernel to  handle high traffic 
>> but still the issue in squid  i believe ??.
>> 
>> is there anything can i do to let squid expand the 1024 sessions form kernel ?
> 
> It is not a limit on number of "sessions". It is queues inside both the
> kernel and Squid getting so full of actions that need to happen that
> small ~50 byte packets travelling between worker processes (running
> inside the same machine!) take over 6 whole seconds to arrive.
> 
> For processes on the same machine 'whole seconds' is thousands if not
> millions of times slower than it should be.
> 
> 
>> 
>> you can imagine that I?m talking about the # of sockets seems limited to 1024 .
>> 
> 
> The key word is "seems". To you it seems that way. Reality is that
> number you are looking at is just a side effect of how fast your CPU is.
> Faster or slower CPU will have different number show up as the limit -
> because they will be able to process more or less actions before delays
> get longer than the timeout.
> 
> Around about 1024 (or was it 1022? or 1028? or ...) the coordinator
> process and kernel are doing so much work the worker processes start
> thinking they have been orphaned and self-terminate.
> 
> 
> 
>> can i expand it form squid ?
>> 
>> any squid building compilation settings needed ?
>> 
> 
> You can edit src/ipc/Strand.cc and change the number parameter of the line:
>  setTimeout(6, "Ipc::Strand::timeoutHandler");
> 
> I would advise against making it too much different from the existing
> value though.
> 
> Amos
> 



From yanghe0921 at 126.com  Sun Sep 18 11:41:10 2016
From: yanghe0921 at 126.com (yanghe)
Date: Sun, 18 Sep 2016 19:41:10 +0800
Subject: [squid-users] What's the algorithm to achieve AclRandom
In-Reply-To: <57DBDC39.50506@126.com>
References: <146a7ed6.396.15726376e43.Coremail.yanghe0921@126.com><25eb8491-49bf-1166-adba-f94d6c00065f@measurement-factory.com><57DBAB05.6090706@126.com><57DBDC39.50506@126.com>
Message-ID: <4ea65ca7.22ca.1573d199f28.Coremail.yanghe0921@126.com>

on 09/18/2016 03:46 PM,  wrote: "Amos Jeffries"squid3 at treenet.co.nz
    Now,I have two ICAP servers and want load balancing.If I use AclRandom,the traffic will be averagely distributed to the two ICAP servers,but it can't guarantee the integrity of the session.For example,I sent a message with 5 attachments,which were randomly assigned to two ICAP servers.
    If I want the 5 attachments to go to only one ICAP to maintain the integrity of the session and load banlacing as far as possible,which parameters can be used.
 
Thanks for
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160918/57c02174/attachment.htm>

From yanghe0921 at 126.com  Sun Sep 18 12:00:44 2016
From: yanghe0921 at 126.com (ysu yang)
Date: Sun, 18 Sep 2016 05:00:44 -0700 (PDT)
Subject: [squid-users] c-icap load balancing
In-Reply-To: <DB6PR0401MB2680ABCEE19ECE7D19A66F5F8FF30@DB6PR0401MB2680.eurprd04.prod.outlook.com>
References: <146a7ed6.396.15726376e43.Coremail.yanghe0921@126.com>
 <25eb8491-49bf-1166-adba-f94d6c00065f@measurement-factory.com>
 <7afcd3a9.a1f2b.15732140f03.Coremail.yanghe0921@126.com>
 <DB6PR0401MB2680ABCEE19ECE7D19A66F5F8FF30@DB6PR0401MB2680.eurprd04.prod.outlook.com>
Message-ID: <1474200044288-4679585.post@n4.nabble.com>


The haproxy was actually occurred to me before,but I am confused how to
configure
1?How can I configure squid that the next traffic will go to haproxy.
2?Shouldn't the IP of the c-icap list by icap_service. if listed in
haproxy,how to configure icap_service

Hope to give some advice
yanghe



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/c-icap-load-balancing-tp4679500p4679585.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yanghe0921 at 126.com  Sun Sep 18 12:04:02 2016
From: yanghe0921 at 126.com (ysu yang)
Date: Sun, 18 Sep 2016 05:04:02 -0700 (PDT)
Subject: [squid-users] What's the algorithm to achieve AclRandom
In-Reply-To: <910d3013-41fd-6b9a-48a9-b081cf03ae15@treenet.co.nz>
References: <16ebfd1f.a6850.1573c2f2f35.Coremail.yanghe0921@126.com>
 <910d3013-41fd-6b9a-48a9-b081cf03ae15@treenet.co.nz>
Message-ID: <1474200242438-4679586.post@n4.nabble.com>

    Now,I have two ICAP servers and want load balancing.If I use
AclRandom,the traffic will be averagely distributed to the two ICAP
servers,but it can't guarantee the integrity of the session.For example,I
sent a message with 5 attachments,which were randomly assigned to two ICAP
servers.
    If I want the 5 attachments to go to only one ICAP to maintain the
integrity of the session and load banlacing as far as possible,which
parameters can be used.
 
Thanks for



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/What-s-the-algorithm-to-achieve-AclRandom-tp4679580p4679586.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Sun Sep 18 14:59:10 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 18 Sep 2016 08:59:10 -0600
Subject: [squid-users] What's the algorithm to achieve AclRandom
In-Reply-To: <4ea65ca7.22ca.1573d199f28.Coremail.yanghe0921@126.com>
References: <146a7ed6.396.15726376e43.Coremail.yanghe0921@126.com>
 <25eb8491-49bf-1166-adba-f94d6c00065f@measurement-factory.com>
 <57DBAB05.6090706@126.com> <57DBDC39.50506@126.com>
 <4ea65ca7.22ca.1573d199f28.Coremail.yanghe0921@126.com>
Message-ID: <a85c96e4-b422-ee70-539a-ef6f9279330a@measurement-factory.com>

On 09/18/2016 05:41 AM, yanghe wrote:

> I have two ICAP servers and want load balancing.If I
> use AclRandom,the traffic will be averagely distributed to
> the two ICAP servers,but it can't guarantee the integrity of
> the session.For example,I sent a message with 5
> attachments,which were randomly assigned to two ICAP servers.

>From Squid point of view, the "session" you are talking about does not
exist and, hence, there is no "integrity of the session" issue.


>                 If I want the 5 attachments to go to only one ICAP to
>             maintain the integrity of the session and load banlacing as
>             far as possible,which parameters can be used.

HTTP itself does not tie an "attachment" transaction to the "parent"
transaction to form what you call a "session". Each HTTP
request/response pair are independent from other pairs. You are thinking
in application terms that Squid/HTTP does not understand/support.

Going forward, you have two basic options:

A. Define "session" in HTTP or Squid terms that Squid understands. Write
ACLs (likely including an external ACL or an eCAP adapter) that will
define a "session" for any given transaction and annotate same-session
transactions accordingly. Load balance based on sessions instead of
random events. The same external ACL or eCAP adapter can define load
balancing by annotating the transaction according to the ICAP service it
should be directed to.

B. Adjust the ICAP service to store information about "sessions" in such
a way that different service instances can share it. For example, if all
ICAP services run on the same machine, they can use shared memory
segments to exchange information among each other.


HTH,

Alex.



From silamael at coronamundi.de  Mon Sep 19 11:35:10 2016
From: silamael at coronamundi.de (Silamael Darkomen)
Date: Mon, 19 Sep 2016 13:35:10 +0200
Subject: [squid-users] Problem with Kerberos and
 ext_kerberos_ldap_group_acl not being able to reach realm's KDC
In-Reply-To: <vmime.57dbb2eb.3061.61eb226d1421221b@ms249-lin-003.rotterdam.bazuin.nl>
References: <955b9071-4d07-f0a2-2925-8f63fa3324af@coronamundi.de>
 <vmime.57dbb2eb.3061.61eb226d1421221b@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <9071f8bb-7e55-cd53-03ea-7d27eff8b6ec@coronamundi.de>

On 16.09.2016 10:52, L.P.H. van Belle wrote:
> I think you forgot in your test, that you may need to modify the default
> kerberos ticket used.
> 
>  
> 
>  
> 
> I suggest you change you config a bit to something like
> 
>  
> 
> external_acl_type internet-win-allowed %LOGIN
> /usr/local/libexec/squid/ext_kerberos_ldap_group_acl \
> 
> -D YOUR.REALM.TLD \
> 
> -g allowed-internet at YOUR.REALM.TLD \
> 
> -N NTDOMAIN at YOUR.REALM.TLD \
> 
> -S
> dc1.your.dnsdomain.tld at YOUR.REALM.TLD:dc2.your.dnsdomain.tld at YOUR.REALM.TLD

Hello,

Tried your suggestions but that doesn't change anything.
Furthermore the ext_kerberos_ldap_group_acl creates a core dump after
iterating over all the entries for the keytab...
Any further ideas?

-- Matthias


From silamael at coronamundi.de  Mon Sep 19 11:39:42 2016
From: silamael at coronamundi.de (Silamael Darkomen)
Date: Mon, 19 Sep 2016 13:39:42 +0200
Subject: [squid-users] Problem with Kerberos and
 ext_kerberos_ldap_group_acl not being able to reach realm's KDC
In-Reply-To: <nrhjm8$mu5$1@blaine.gmane.org>
References: <955b9071-4d07-f0a2-2925-8f63fa3324af@coronamundi.de>
 <nrhjm8$mu5$1@blaine.gmane.org>
Message-ID: <35fd4285-c508-cacd-f166-a3f8b8bac09d@coronamundi.de>



On 16.09.2016 22:11, Markus Moeller wrote:
> Hi Silamael,
> 
>     Can you perform a kinit user at EXAMPLE.COM ?   Does the squid user
> have read access to  krb5.conf ?
> 
> Markus

Hello Markus,

Yes, the permissions are correctly set up so that Squid and it's
processes can read every file needed.
For it seems that the Heimdal library ignores the dns_lookup_kdc and
dns_lookup_realm options in the krb5.conf...
As written in my other response, the helper also crashes at the end.
I'll take a look on the stack trace...

-- Matthias


From belle at bazuin.nl  Mon Sep 19 12:08:52 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Mon, 19 Sep 2016 14:08:52 +0200
Subject: [squid-users] Problem with Kerberos and
 ext_kerberos_ldap_group_acl not being able to reach realm's KDC
In-Reply-To: <9071f8bb-7e55-cd53-03ea-7d27eff8b6ec@coronamundi.de>
References: <vmime.57dbb2eb.3061.61eb226d1421221b@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <vmime.57dfd554.661a.26d3a34510840703@ms249-lin-003.rotterdam.bazuin.nl>

Well thats strange. 
No i cant speak about openBSD, but below is pretty general. 

When you test, did you set this before the test. 
KRB5_KTNAME=/etc/squid/proxy.keytab
And does that keytab contain the HTTP/SPN
And test/check if you see http/SPN in the UPN, if not try that also. 
After that change the 
I just tested again to make my groups more flexible. 

/usr/lib/squid3/ext_kerberos_ldap_group_acl -m 4  \
    -D YOUR.REALM.TLD \
    -N NTDOMAIN at YOUR.REALM.TLD \
    - S dc1.your.dnsdomain.tld at YOUR.REALM.TLD \
    -i -d 
This one is without the -g so we can use more group names, 
but test with -g first.

from this example like. But i change the ldap group to kerberos group here.
http://wiki.bitbinary.com/index.php/Active_Directory_Integrated_Squid_Proxy 


When i now put in "username groupname" after staring with the line above to testout im getting. 

support_member.cc(69): pid=23472 :2016/09/19 13:55:39| kerberos_ldap_group: INFO: User username is member of group at domain groupname at YOUR.REALM.TLD
OK
kerberos_ldap_group.cc(408): pid=23472 :2016/09/19 13:55:39| kerberos_ldap_group: DEBUG: OK

this is all i have in krb5.conf
[libdefaults]
    default_keytab_name = /etc/krb5.keytab
    default_realm = YOUR.REALM.TLD
    dns_lookup_kdc = true
    dns_lookup_realm = false
    ticket_lifetime = 24h
    ccache_type = 4
    forwardable = true

and the ad dc lookup works, if you set the SPN in the UPN, at least works for me. 
I have my systems keytab as default keytab and  KRB5_KTNAME=/etc/squid/proxy.keytab
export KRB5_KTNAME

TLS_CACERTFILE=/etc/ssl/certs/ca-certificates.crt
export TLS_CACERTFILE

Is set in the /etc/default/squid3 

So im thinking review the keytab setup and the variable. 

And:
>The AD is reachable from the proxy machine but DNS is not done by the AD
>but on the proxy machine itself.

Same here, but i do have a forward zone in the dns for my ad domain.


Hope this helps a bit. 

Greetz, 

Louis


> -----Oorspronkelijk bericht-----
> Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens
> Silamael Darkomen
> Verzonden: maandag 19 september 2016 13:35
> Aan: squid-users at lists.squid-cache.org
> Onderwerp: Re: [squid-users] Problem with Kerberos and
> ext_kerberos_ldap_group_acl not being able to reach realm's KDC
> 
> On 16.09.2016 10:52, L.P.H. van Belle wrote:
> > I think you forgot in your test, that you may need to modify the default
> > kerberos ticket used.
> >
> >
> >
> >
> >
> > I suggest you change you config a bit to something like
> >
> >
> >
> > external_acl_type internet-win-allowed %LOGIN
> > /usr/local/libexec/squid/ext_kerberos_ldap_group_acl \
> >
> > -D YOUR.REALM.TLD \
> >
> > -g allowed-internet at YOUR.REALM.TLD \
> >
> > -N NTDOMAIN at YOUR.REALM.TLD \
> >
> > -S
> >
> dc1.your.dnsdomain.tld at YOUR.REALM.TLD:dc2.your.dnsdomain.tld at YOUR.REALM.TL
> D
> 
> Hello,
> 
> Tried your suggestions but that doesn't change anything.
> Furthermore the ext_kerberos_ldap_group_acl creates a core dump after
> iterating over all the entries for the keytab...
> Any further ideas?
> 
> -- Matthias
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From silamael at coronamundi.de  Mon Sep 19 12:20:29 2016
From: silamael at coronamundi.de (Silamael Darkomen)
Date: Mon, 19 Sep 2016 14:20:29 +0200
Subject: [squid-users] Problem with Kerberos and
 ext_kerberos_ldap_group_acl not being able to reach realm's KDC
In-Reply-To: <vmime.57dfd554.661a.26d3a34510840703@ms249-lin-003.rotterdam.bazuin.nl>
References: <vmime.57dbb2eb.3061.61eb226d1421221b@ms249-lin-003.rotterdam.bazuin.nl>
 <vmime.57dfd554.661a.26d3a34510840703@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <66655aac-c8f9-db4d-0234-c455063d592e@coronamundi.de>


On 19.09.2016 14:08, L.P.H. van Belle wrote:
> Well thats strange. 
> No i cant speak about openBSD, but below is pretty general. 
> 
> When you test, did you set this before the test. 
> KRB5_KTNAME=/etc/squid/proxy.keytab
> And does that keytab contain the HTTP/SPN
> And test/check if you see http/SPN in the UPN, if not try that also. 
> After that change the 
> I just tested again to make my groups more flexible. 
> 
> /usr/lib/squid3/ext_kerberos_ldap_group_acl -m 4  \
>     -D YOUR.REALM.TLD \
>     -N NTDOMAIN at YOUR.REALM.TLD \
>     - S dc1.your.dnsdomain.tld at YOUR.REALM.TLD \
>     -i -d 
> This one is without the -g so we can use more group names, 
> but test with -g first.
> 
> from this example like. But i change the ldap group to kerberos group here.
> http://wiki.bitbinary.com/index.php/Active_Directory_Integrated_Squid_Proxy 

That's all there, environment is correctly set up. Keytab looks good.
As said before, the negotiate_kerberos_auth part works like a charm.
All I get is a bunch of messages complaining about not being able to
reach any KDC in realm while initializing the credentials of the keytab...
Thought that it might be a DNS issue but even configuring DNS so that
the AD server does all the DNS stuff did not change a bit :(

-- Matthias


From yanghe0921 at 126.com  Mon Sep 19 12:23:40 2016
From: yanghe0921 at 126.com (ysu yang)
Date: Mon, 19 Sep 2016 05:23:40 -0700 (PDT)
Subject: [squid-users] What's the algorithm to achieve AclRandom
In-Reply-To: <a85c96e4-b422-ee70-539a-ef6f9279330a@measurement-factory.com>
References: <146a7ed6.396.15726376e43.Coremail.yanghe0921@126.com>
 <25eb8491-49bf-1166-adba-f94d6c00065f@measurement-factory.com>
 <a85c96e4-b422-ee70-539a-ef6f9279330a@measurement-factory.com>
Message-ID: <1474287820853-4679592.post@n4.nabble.com>

Firstly of all.Thanks for your advice.

>     B. Adjust the ICAP service to store information about "sessions" in
> such 
>     a way that different service instances can share it. For example, if
> all 
>     ICAP services run on the same machine, they can use shared memory 
>     segments to exchange information among each other. 

I have no ability to achieve that different ICAP servers share same memory.

>     A. Define "session" in HTTP or Squid terms that Squid understands.
> Write
>     ACLs (likely including an external ACL or an eCAP adapter) that will 
>     define a "session" for any given transaction and annotate same-session 
>     transactions accordingly. Load balance based on sessions instead of 
>     random events. The same external ACL or eCAP adapter can define load 
>     balancing by annotating the transaction according to the ICAP service
> it 
>     should be directed to. 

I see your point,but I didn't find what I wanted in ACLs.  i would like to
achieve load balancing based on IP?maybe implement by Source IP hash
algorithm?.Do you have a idea.

And,If one ICAP sever go down, can squid check  it is down and will not send
message to it

Thanks in advance




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/c-icap-load-balancing-tp4679500p4679592.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From belle at bazuin.nl  Mon Sep 19 12:32:20 2016
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Mon, 19 Sep 2016 14:32:20 +0200
Subject: [squid-users] Problem with Kerberos and
 ext_kerberos_ldap_group_acl not being able to reach realm's KDC
In-Reply-To: <66655aac-c8f9-db4d-0234-c455063d592e@coronamundi.de>
References: <vmime.57dfd554.661a.26d3a34510840703@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <vmime.57dfdad4.7356.1d3303cc3e4614@ms249-lin-003.rotterdam.bazuin.nl>

Yes, 

You can fix that by setting the SPN : HTTP/host.you.domain.tld in UPN 
I had that too, changed it and it is working perfect now. 

See subject : Re: [squid-users] ext_kerberos_ldap_group_acl problem ( 2 minorbugsmaybe ) 

Greetz, 

Louis




> -----Oorspronkelijk bericht-----
> Van: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Namens
> Silamael Darkomen
> Verzonden: maandag 19 september 2016 14:20
> Aan: squid-users at lists.squid-cache.org
> Onderwerp: Re: [squid-users] Problem with Kerberos and
> ext_kerberos_ldap_group_acl not being able to reach realm's KDC
> 
> 
> On 19.09.2016 14:08, L.P.H. van Belle wrote:
> > Well thats strange.
> > No i cant speak about openBSD, but below is pretty general.
> >
> > When you test, did you set this before the test.
> > KRB5_KTNAME=/etc/squid/proxy.keytab
> > And does that keytab contain the HTTP/SPN
> > And test/check if you see http/SPN in the UPN, if not try that also.
> > After that change the
> > I just tested again to make my groups more flexible.
> >
> > /usr/lib/squid3/ext_kerberos_ldap_group_acl -m 4  \
> >     -D YOUR.REALM.TLD \
> >     -N NTDOMAIN at YOUR.REALM.TLD \
> >     - S dc1.your.dnsdomain.tld at YOUR.REALM.TLD \
> >     -i -d
> > This one is without the -g so we can use more group names,
> > but test with -g first.
> >
> > from this example like. But i change the ldap group to kerberos group
> here.
> >
> http://wiki.bitbinary.com/index.php/Active_Directory_Integrated_Squid_Prox
> y
> 
> That's all there, environment is correctly set up. Keytab looks good.
> As said before, the negotiate_kerberos_auth part works like a charm.
> All I get is a bunch of messages complaining about not being able to
> reach any KDC in realm while initializing the credentials of the keytab...
> Thought that it might be a DNS issue but even configuring DNS so that
> the AD server does all the DNS stuff did not change a bit :(
> 
> -- Matthias
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From yanghe0921 at 126.com  Mon Sep 19 12:29:56 2016
From: yanghe0921 at 126.com (ysu yang)
Date: Mon, 19 Sep 2016 05:29:56 -0700 (PDT)
Subject: [squid-users] What's the algorithm to achieve AclRandom
In-Reply-To: <a85c96e4-b422-ee70-539a-ef6f9279330a@measurement-factory.com>
References: <146a7ed6.396.15726376e43.Coremail.yanghe0921@126.com>
 <25eb8491-49bf-1166-adba-f94d6c00065f@measurement-factory.com>
 <a85c96e4-b422-ee70-539a-ef6f9279330a@measurement-factory.com>
Message-ID: <1474288196230-4679594.post@n4.nabble.com>

First of all.thanks for your advice.

>     B. Adjust the ICAP service to store information about "sessions" in
> such 
>     a way that different service instances can share it. For example, if
> all 
>     ICAP services run on the same machine, they can use shared memory 
>     segments to exchange information among each other. 

I have no ability to achieve that different ICAP servers share same memory.

>     A. Define "session" in HTTP or Squid terms that Squid understands.
> Write
>     ACLs (likely including an external ACL or an eCAP adapter) that will 
>     define a "session" for any given transaction and annotate same-session 
>     transactions accordingly. Load balance based on sessions instead of 
>     random events. The same external ACL or eCAP adapter can define load 
>     balancing by annotating the transaction according to the ICAP service
> it 
>     should be directed to. 

I see your point,but I didn't find what I wanted in ACLs.  i would like to
achieve load balancing based on IP?maybe implement by Source IP hash
algorithm?.Do you have a idea.

And,If one ICAP sever go down, can squid check  it is down and will not send
message to it

Thanks in advance



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/c-icap-load-balancing-tp4679500p4679594.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From hardikdangar+squid at gmail.com  Mon Sep 19 16:42:09 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Mon, 19 Sep 2016 22:12:09 +0530
Subject: [squid-users] squid https intercept mode and ubuntu third party
	repositories issue
Message-ID: <CA+sSnVYQ6CQEWdZf2CVLjzdEcWTtEJWsGFRtFtb+6n950sNRkA@mail.gmail.com>

Hello,

I am using squid 3.5.12(detailed version info is below) on Ubuntu 16.04.1
LTS server. My squid config is at, http://pastebin.com/raw/b8RZ67u9

I have configured squid as intercept proxy bumping all SSL https
connections. Setup is working fine for many things like browsing,
even on command line like wget i can download via https as i have installed
root certificate within my client os.

My issue is whenever i try to add extra repository via command, i.e.
sudo add-apt-repository ppa:ondrej/php
command fails with output "Cannot add PPA: 'ppa:~ondrej/ubuntu/php'.ERROR:
'~ondrej' user or team does not exist." and in squid's cache and access.log
following entries can be located for this request,

==> /var/log/squid/access.log <==
1474302162.378    439 192.168.1.66 TAG_NONE/200 0 CONNECT 91.189.89.223:443
- ORIGINAL_DST/91.189.89.223 -

==> /var/log/squid/cache.log <==
2016/09/19 21:52:42 kid1| Error negotiating SSL connection on FD 21:
error:14094418:SSL routines:ssl3_read_bytes:tlsv1 alert unknown ca (1/0)
2016/09/19 21:52:42 kid1| hold write on SSL connection on FD 22

==> /var/log/squid/access.log <==
1474302162.885    403 192.168.1.66 TAG_NONE/200 0 CONNECT 91.189.89.223:443
- ORIGINAL_DST/91.189.89.223 -

==> /var/log/squid/cache.log <==
2016/09/19 21:52:42 kid1| Error negotiating SSL connection on FD 21:
error:14094418:SSL routines:ssl3_read_bytes:tlsv1 alert unknown ca (1/0)

in the above output 192.168.1.66 is my client requesting that request and
as you can see in cache.log there is certificate negotiation error. I have
tried to fiddle with all options provided at http://wiki.squid-cache.org/
ConfigExamples/Intercept/SslBumpExplicit but it seems i am out of luck
after almost half of my day battling this issue.

Can someone tell me they are successful with this issue? if so can you
share your squid.conf relevant section?

$ squid -v
Squid Cache: Version 3.5.12
Service Name: squid
Ubuntu linux
configure options:  '--build=x86_64-linux-gnu' '--prefix=/usr'
'--includedir=${prefix}/include' '--mandir=${prefix}/share/man'
'--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var'
'--libexecdir=${prefix}/lib/squid3' '--srcdir=.'
'--disable-maintainer-mode' '--disable-dependency-tracking'
'--disable-silent-rules' 'BUILDCXXFLAGS=-g -O2 -fPIE
-fstack-protector-strong -Wformat -Werror=format-security
-Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro -Wl,-z,now'
'--datadir=/usr/share/squid' '--sysconfdir=/etc/squid'
'--libexecdir=/usr/lib/squid' '--mandir=/usr/share/man' '--with-openssl'
'--enable-ssl-crtd' '--enable-inline' '--disable-arch-native'
'--enable-async-io=8' '--enable-storeio=ufs,aufs,diskd,rock'
'--enable-removal-policies=lru,heap' '--enable-delay-pools'
'--enable-cache-digests' '--enable-icap-client'
'--enable-follow-x-forwarded-for' '--enable-auth-basic=DB,fake,
getpwnam,LDAP,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB'
'--enable-auth-digest=file,LDAP'
'--enable-auth-negotiate=kerberos,wrapper' '--enable-auth-ntlm=fake,smb_lm'
'--enable-external-acl-helpers=file_userip,kerberos_
ldap_group,LDAP_group,session,SQL_session,unix_group,wbinfo_group'
'--enable-url-rewrite-helpers=fake' '--enable-eui' '--enable-esi'
'--enable-icmp' '--enable-zph-qos' '--enable-ecap' '--disable-translation'
'--with-swapdir=/var/spool/squid' '--with-logdir=/var/log/squid'
'--with-pidfile=/var/run/squid.pid' '--with-filedescriptors=65536'
'--with-large-files' '--with-default-user=proxy'
'--enable-build-info=Ubuntu linux' '--enable-linux-netfilter'
'build_alias=x86_64-linux-gnu' 'CFLAGS=-g -O2 -fPIE
-fstack-protector-strong -Wformat -Werror=format-security -Wall'
'LDFLAGS=-Wl,-Bsymbolic-functions -fPIE -pie -Wl,-z,relro -Wl,-z,now'
'CPPFLAGS=-Wdate-time -D_FORTIFY_SOURCE=2' 'CXXFLAGS=-g -O2 -fPIE
-fstack-protector-strong -Wformat -Werror=format-security'
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160919/0c41762e/attachment.htm>

From erdosain9 at gmail.com  Mon Sep 19 17:39:20 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 19 Sep 2016 10:39:20 -0700 (PDT)
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1473903753861-4679519.post@n4.nabble.com>
References: <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
 <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>
 <6e65eafe-37aa-e6f2-9c04-e4e14b9ff3e9@gmail.com>
 <CAEpx-0WMruHcZBP=kpZO1+C4YnELpeYGy2=WYtKMY5zmTWuaBg@mail.gmail.com>
 <3c02e953-d2cb-7905-f52a-e036ed3e06ab@treenet.co.nz>
 <1473879398350-4679512.post@n4.nabble.com>
 <e730f7da-c6ce-808f-f454-2d7a0369a92b@measurement-factory.com>
 <1473894106709-4679515.post@n4.nabble.com>
 <11a31fcd-901a-351a-4f60-8b2fe054b224@measurement-factory.com>
 <1473903753861-4679519.post@n4.nabble.com>
Message-ID: <1474306760218-4679596.post@n4.nabble.com>

mmmmmmmmmm....
so...
i think this is working for non take the certificate

acl step1 at_step SslBump1 
acl excludeSSL ssl::server_name_regex web/.whatsapp/.com 

ssl_bump peek step1 
ssl_bump splice excludeSSL 
ssl_bump bump all 

but, anyway something more is happening because well... dosent work.
another point of view??



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679596.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From jok at spikes.com  Mon Sep 19 18:12:11 2016
From: jok at spikes.com (Jok Thuau)
Date: Mon, 19 Sep 2016 11:12:11 -0700
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1474306760218-4679596.post@n4.nabble.com>
References: <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
 <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>
 <6e65eafe-37aa-e6f2-9c04-e4e14b9ff3e9@gmail.com>
 <CAEpx-0WMruHcZBP=kpZO1+C4YnELpeYGy2=WYtKMY5zmTWuaBg@mail.gmail.com>
 <3c02e953-d2cb-7905-f52a-e036ed3e06ab@treenet.co.nz>
 <1473879398350-4679512.post@n4.nabble.com>
 <e730f7da-c6ce-808f-f454-2d7a0369a92b@measurement-factory.com>
 <1473894106709-4679515.post@n4.nabble.com>
 <11a31fcd-901a-351a-4f60-8b2fe054b224@measurement-factory.com>
 <1473903753861-4679519.post@n4.nabble.com>
 <1474306760218-4679596.post@n4.nabble.com>
Message-ID: <CADSSinMq2GoE0gwYWXMX7foiVqExoc5HnQbEdX0qm-q4CM13tA@mail.gmail.com>

On Mon, Sep 19, 2016 at 10:39 AM, erdosain9 <erdosain9 at gmail.com> wrote:

> mmmmmmmmmm....
> so...
> i think this is working for non take the certificate
>
> acl step1 at_step SslBump1
> acl excludeSSL ssl::server_name_regex web/.whatsapp/.com
>

wrong slashes... you want "\"


>
> ssl_bump peek step1
> ssl_bump splice excludeSSL
> ssl_bump bump all
>
> but, anyway something more is happening because well... dosent work.
> another point of view??
>

Yes, you still had something wrong. Also, i'm not sure if you need to
anchor the RE to prevent it matching something like
"web.whatsapp.com.malware.tld" in the server name. Maybe someone closer to
the code can answer that question...

Jok
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160919/ac8cd23e/attachment.htm>

From rousskov at measurement-factory.com  Mon Sep 19 18:45:55 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 19 Sep 2016 12:45:55 -0600
Subject: [squid-users] What's the algorithm to achieve AclRandom
In-Reply-To: <1474288196230-4679594.post@n4.nabble.com>
References: <146a7ed6.396.15726376e43.Coremail.yanghe0921@126.com>
 <25eb8491-49bf-1166-adba-f94d6c00065f@measurement-factory.com>
 <a85c96e4-b422-ee70-539a-ef6f9279330a@measurement-factory.com>
 <1474288196230-4679594.post@n4.nabble.com>
Message-ID: <54900b85-9f04-40dc-b010-0874766bd89b@measurement-factory.com>

On 09/19/2016 06:29 AM, ysu yang wrote:
>>     A. Define "session" in HTTP or Squid terms that Squid understands. Write
>>     ACLs (likely including an external ACL or an eCAP adapter) that will 
>>     define a "session" for any given transaction and annotate same-session 
>>     transactions accordingly. Load balance based on sessions instead of 
>>     random events. The same external ACL or eCAP adapter can define load 
>>     balancing by annotating the transaction according to the ICAP service it 
>>     should be directed to. 

> I see your point,but I didn't find what I wanted in ACLs.  i would like to
> achieve load balancing based on IP?maybe implement by Source IP hash
> algorithm?.Do you have a idea.

Consider using an external ACL (i.e., Squid calling your custom script
when deciding whether the ACL matched). Your script gets the client IP
from Squid and, as a side effect, returns a transaction annotation to
Squid. Squid uses that annotation (via the "note" ACL) in the
adaptation_access rules to route the traffic to the right ICAP service
(or service set).


> And,If one ICAP sever go down, can squid check  it is down and will not send
> message to it

See http://www.squid-cache.org/Doc/config/adaptation_service_set/

Alex.



From jlay at slave-tothe-box.net  Mon Sep 19 22:01:26 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Mon, 19 Sep 2016 16:01:26 -0600
Subject: [squid-users] Squid 3.5.20 fails to compile with openssl
Message-ID: <9d0215029d45f27347f4f697de5c3b55@localhost>

So I know I posted this a while ago...thought I'd give it a shot today, 
but still no luck:

make[3]: Entering directory `/home/nobackup/build/squid-3.5.20/src/anyp'
depbase=`echo PortCfg.lo | sed 's|[^/]*$|.deps/&|;s|\.lo$||'`;\
         /bin/bash ../../libtool  --tag=CXX   --mode=compile g++ 
-DHAVE_CONFIG_H   -I../.. -I../../include -I../../lib -I../../src 
-I../../include    -I/opt/openssl/include  -Wall -Wpointer-arith 
-Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -Werror -pipe 
-D_REENTRANT -m64   -g -O2 -march=native -std=c++11 -MT PortCfg.lo -MD 
-MP -MF $depbase.Tpo -c -o PortCfg.lo PortCfg.cc &&\
         mv -f $depbase.Tpo $depbase.Plo
libtool: compile:  g++ -DHAVE_CONFIG_H -I../.. -I../../include 
-I../../lib -I../../src -I../../include -I/opt/openssl/include -Wall 
-Wpointer-arith -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual 
-Werror -pipe -D_REENTRANT -m64 -g -O2 -march=native -std=c++11 -MT 
PortCfg.lo -MD -MP -MF .deps/PortCfg.Tpo -c PortCfg.cc  -fPIC -DPIC -o 
.libs/PortCfg.o
In file included from ../../src/anyp/PortCfg.h:18:0,
                  from PortCfg.cc:10:
../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not 
declared in this scope
  typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> 
X509_Pointer;
                                              ^
../../src/ssl/gadgets.h:83:61: error: template argument 3 is invalid
  typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> 
X509_Pointer;
                                                              ^
../../src/ssl/gadgets.h:83:75: error: invalid type in declaration before 
?;? token
  typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> 
X509_Pointer;
                                                                          
   ^
../../src/ssl/gadgets.h:89:53: error: ?CRYPTO_LOCK_EVP_PKEY? was not 
declared in this scope
  typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, 
CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;
                                                      ^
../../src/ssl/gadgets.h:89:73: error: template argument 3 is invalid
  typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, 
CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;
                                                                          
^
../../src/ssl/gadgets.h:89:91: error: invalid type in declaration before 
?;? token
  typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, 
CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;
                                                                          
                   ^
../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not 
declared in this scope
  typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;
                                            ^
../../src/ssl/gadgets.h:116:58: error: template argument 3 is invalid
  typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;
                                                           ^
../../src/ssl/gadgets.h:116:71: error: invalid type in declaration 
before ?;? token
  typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;
                                                                        ^
make[3]: *** [PortCfg.lo] Error 1
make[3]: Leaving directory `/home/nobackup/build/squid-3.5.20/src/anyp'
make[2]: *** [all-recursive] Error 1
make[2]: Leaving directory `/home/nobackup/build/squid-3.5.20/src'
make[1]: *** [all] Error 2
make[1]: Leaving directory `/home/nobackup/build/squid-3.5.20/src'
make: *** [all-recursive] Error 1

Openssl git latest commit version commit 
e2562bbbe1e1c68ec5a3e02c1f151fd6149ee2ae.  thank you.

James


From rousskov at measurement-factory.com  Mon Sep 19 22:05:15 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 19 Sep 2016 16:05:15 -0600
Subject: [squid-users] Squid 3.5.20 fails to compile with openssl
In-Reply-To: <9d0215029d45f27347f4f697de5c3b55@localhost>
References: <9d0215029d45f27347f4f697de5c3b55@localhost>
Message-ID: <6e43eb43-d529-7c2d-2778-74997a5516ba@measurement-factory.com>

On 09/19/2016 04:01 PM, James Lay wrote:

> Openssl git latest commit version commit
> e2562bbbe1e1c68ec5a3e02c1f151fd6149ee2ae.

Please see http://bugs.squid-cache.org/show_bug.cgi?id=4599


Thank you,

Alex.



From jlay at slave-tothe-box.net  Mon Sep 19 22:51:48 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Mon, 19 Sep 2016 16:51:48 -0600
Subject: [squid-users] Squid 3.5.20 fails to compile with openssl
In-Reply-To: <6e43eb43-d529-7c2d-2778-74997a5516ba@measurement-factory.com>
References: <9d0215029d45f27347f4f697de5c3b55@localhost>
 <6e43eb43-d529-7c2d-2778-74997a5516ba@measurement-factory.com>
Message-ID: <5821160775cf9483b92875f2c463fef1@localhost>

On 2016-09-19 16:05, Alex Rousskov wrote:
> On 09/19/2016 04:01 PM, James Lay wrote:
> 
>> Openssl git latest commit version commit
>> e2562bbbe1e1c68ec5a3e02c1f151fd6149ee2ae.
> 
> Please see http://bugs.squid-cache.org/show_bug.cgi?id=4599
> 
> 
> Thank you,
> 
> Alex.

And there you go...thanks Alex.

James


From jlay at slave-tothe-box.net  Tue Sep 20 00:22:03 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Mon, 19 Sep 2016 18:22:03 -0600
Subject: [squid-users] Squid 3.5.20 compile issue
Message-ID: <1474330923.2521.8.camel@slave-tothe-box.net>

Ok so this is with the 1.0.2 branch of openssl:

make[3]: Entering directory `/home//nobackup/build/squid-
3.5.20/src/ssl'
/bin/bash ../../libtool??--tag=CXX???--mode=link g++ -Wall -Wpointer-
arith -Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -Werror
-pipe -D_REENTRANT -m64???-g -O2 -march=native -std=c++11??-m64 -g -o
ssl_crtd ssl_crtd.o certificate_db.o libsslutil.la -L/opt/openssl/lib
-lssl -lcrypto????../../compat/libcompat-squid.la??
libtool: link: g++ -Wall -Wpointer-arith -Wwrite-strings -Wcomments
-Wshadow -Woverloaded-virtual -Werror -pipe -D_REENTRANT -m64 -g -O2
-march=native -std=c++11 -m64 -g -o ssl_crtd ssl_crtd.o
certificate_db.o??./.libs/libsslutil.a -L/opt/openssl/lib -lssl
-lcrypto ../../compat/.libs/libcompat-squid.a
/opt/openssl/lib/libcrypto.a(dso_dlfcn.o): In function
`dlfcn_globallookup':
dso_dlfcn.c:(.text+0x11): undefined reference to `dlopen'
dso_dlfcn.c:(.text+0x24): undefined reference to `dlsym'
dso_dlfcn.c:(.text+0x2f): undefined reference to `dlclose'
/opt/openssl/lib/libcrypto.a(dso_dlfcn.o): In function
`dlfcn_bind_func':
dso_dlfcn.c:(.text+0x334): undefined reference to `dlsym'
dso_dlfcn.c:(.text+0x3db): undefined reference to `dlerror'
/opt/openssl/lib/libcrypto.a(dso_dlfcn.o): In function
`dlfcn_bind_var':
dso_dlfcn.c:(.text+0x454): undefined reference to `dlsym'
dso_dlfcn.c:(.text+0x4fb): undefined reference to `dlerror'
/opt/openssl/lib/libcrypto.a(dso_dlfcn.o): In function `dlfcn_load':
dso_dlfcn.c:(.text+0x569): undefined reference to `dlopen'
dso_dlfcn.c:(.text+0x5cb): undefined reference to `dlclose'
dso_dlfcn.c:(.text+0x603): undefined reference to `dlerror'
/opt/openssl/lib/libcrypto.a(dso_dlfcn.o): In function
`dlfcn_pathbyaddr':
dso_dlfcn.c:(.text+0x68f): undefined reference to `dladdr'
dso_dlfcn.c:(.text+0x6f1): undefined reference to `dlerror'
/opt/openssl/lib/libcrypto.a(dso_dlfcn.o): In function `dlfcn_unload':
dso_dlfcn.c:(.text+0x742): undefined reference to `dlclose'
collect2: error: ld returned 1 exit status
make[3]: *** [ssl_crtd] Error 1
make[3]: Leaving directory `/home/nobackup/build/squid-3.5.20/src/ssl'
make[2]: *** [all-recursive] Error 1
make[2]: Leaving directory `/home/nobackup/build/squid-3.5.20/src'
make[1]: *** [all] Error 2
make[1]: Leaving directory `/home/nobackup/build/squid-3.5.20/src'
make: *** [all-recursive] Error 1

Should I just try something different? ?1.0.1? ?1.0? ?Thank you.

James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160919/c8b9c3b9/attachment.htm>

From rousskov at measurement-factory.com  Tue Sep 20 00:37:44 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 19 Sep 2016 18:37:44 -0600
Subject: [squid-users] Squid 3.5.20 compile issue
In-Reply-To: <1474330923.2521.8.camel@slave-tothe-box.net>
References: <1474330923.2521.8.camel@slave-tothe-box.net>
Message-ID: <78153f47-8855-8c61-c775-8c209b653a48@measurement-factory.com>

On 09/19/2016 06:22 PM, James Lay wrote:
> Ok so this is with the 1.0.2 branch of openssl:
> 
> dso_dlfcn.c:(.text+0x11): undefined reference to `dlopen'
> dso_dlfcn.c:(.text+0x24): undefined reference to `dlsym'
> dso_dlfcn.c:(.text+0x2f): undefined reference to `dlclose'

You can probably force you way through this by linking with more system
libraries, but I do not know exactly which ones you need. This smells
like an environment or build configuration problem to me -- the linker
does not know that your OpenSSL library depends on another system
library that provides those [dynamic linking] functions.


> Should I just try something different?  1.0.1?  1.0?

I know that both v1.0 and v1.0.1 work in many environments. YMMV.

Alex.



From jlay at slave-tothe-box.net  Tue Sep 20 00:39:23 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Mon, 19 Sep 2016 18:39:23 -0600
Subject: [squid-users] Squid 3.5.20 compile issue
In-Reply-To: <78153f47-8855-8c61-c775-8c209b653a48@measurement-factory.com>
References: <1474330923.2521.8.camel@slave-tothe-box.net>
 <78153f47-8855-8c61-c775-8c209b653a48@measurement-factory.com>
Message-ID: <1474331963.2521.14.camel@slave-tothe-box.net>

Thanks...off to git cloning the 1.0.1 branch...all this work for chacha
and poly...yugh 8-|
James
On Mon, 2016-09-19 at 18:37 -0600, Alex Rousskov wrote:
> On 09/19/2016 06:22 PM, James Lay wrote:
> > 
> > Ok so this is with the 1.0.2 branch of openssl:
> > 
> > dso_dlfcn.c:(.text+0x11): undefined reference to `dlopen'
> > dso_dlfcn.c:(.text+0x24): undefined reference to `dlsym'
> > dso_dlfcn.c:(.text+0x2f): undefined reference to `dlclose'
> You can probably force you way through this by linking with more
> system
> libraries, but I do not know exactly which ones you need. This smells
> like an environment or build configuration problem to me -- the
> linker
> does not know that your OpenSSL library depends on another system
> library that provides those [dynamic linking] functions.
> 
> 
> > 
> > Should I just try something different???1.0.1???1.0?
> I know that both v1.0 and v1.0.1 work in many environments. YMMV.
> 
> Alex.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160919/24c0ff84/attachment.htm>

From brett.lymn at baesystems.com  Tue Sep 20 00:42:11 2016
From: brett.lymn at baesystems.com (LYMN)
Date: Tue, 20 Sep 2016 10:12:11 +0930
Subject: [squid-users] Squid 3.5.20 compile issue
In-Reply-To: <78153f47-8855-8c61-c775-8c209b653a48@measurement-factory.com>
References: <1474330923.2521.8.camel@slave-tothe-box.net>
 <78153f47-8855-8c61-c775-8c209b653a48@measurement-factory.com>
Message-ID: <20160920004211.GA13295@baea.com.au>

On Mon, Sep 19, 2016 at 06:37:44PM -0600, Alex Rousskov wrote:
> On 09/19/2016 06:22 PM, James Lay wrote:
> > Ok so this is with the 1.0.2 branch of openssl:
> > 
> > dso_dlfcn.c:(.text+0x11): undefined reference to `dlopen'
> > dso_dlfcn.c:(.text+0x24): undefined reference to `dlsym'
> > dso_dlfcn.c:(.text+0x2f): undefined reference to `dlclose'
> 
> You can probably force you way through this by linking with more system
> libraries, but I do not know exactly which ones you need. This smells
> like an environment or build configuration problem to me -- the linker
> does not know that your OpenSSL library depends on another system
> library that provides those [dynamic linking] functions.
> 

At a guess add this to the libraries list after openssl: -ldl

-- 
Brett Lymn
This email has been sent on behalf of one of the following companies within the BAE Systems Australia group of companies:

    BAE Systems Australia Limited - Australian Company Number 008 423 005
    BAE Systems Australia Defence Pty Limited - Australian Company Number 006 870 846
    BAE Systems Australia Logistics Pty Limited - Australian Company Number 086 228 864

Our registered office is Evans Building, Taranaki Road, Edinburgh Parks,
Edinburgh, South Australia, 5111. If the identity of the sending company is
not clear from the content of this email please contact the sender.

This email and any attachments may contain confidential and legally
privileged information.  If you are not the intended recipient, do not copy or
disclose its content, but please reply to this email immediately and highlight
the error to the sender and then immediately delete the message.



From jlay at slave-tothe-box.net  Tue Sep 20 00:44:38 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Mon, 19 Sep 2016 18:44:38 -0600
Subject: [squid-users] Squid 3.5.20 compile issue
In-Reply-To: <20160920004211.GA13295@baea.com.au>
References: <1474330923.2521.8.camel@slave-tothe-box.net>
 <78153f47-8855-8c61-c775-8c209b653a48@measurement-factory.com>
 <20160920004211.GA13295@baea.com.au>
Message-ID: <1474332278.2521.15.camel@slave-tothe-box.net>

On Tue, 2016-09-20 at 10:12 +0930, LYMN wrote:
> On Mon, Sep 19, 2016 at 06:37:44PM -0600, Alex Rousskov wrote:
> > 
> > On 09/19/2016 06:22 PM, James Lay wrote:
> > > 
> > > Ok so this is with the 1.0.2 branch of openssl:
> > > 
> > > dso_dlfcn.c:(.text+0x11): undefined reference to `dlopen'
> > > dso_dlfcn.c:(.text+0x24): undefined reference to `dlsym'
> > > dso_dlfcn.c:(.text+0x2f): undefined reference to `dlclose'
> > You can probably force you way through this by linking with more
> > system
> > libraries, but I do not know exactly which ones you need. This
> > smells
> > like an environment or build configuration problem to me -- the
> > linker
> > does not know that your OpenSSL library depends on another system
> > library that provides those [dynamic linking] functions.
> > 
> At a guess add this to the libraries list after openssl: -ldl
> 
Thank you...where would I add that to? ?My config line? ?Here it is:
./configure --prefix=/opt --with-openssl=/opt/openssl --enable-ssl --
enable-ssl-crtd --enable-linux-netfilter --enable-follow-x-forwarded-
for --with-large-files --sysconfdir=/opt/etc/squid --enable-external-
acl-helpers=none
James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160919/bf0508f8/attachment.htm>

From jlay at slave-tothe-box.net  Tue Sep 20 01:13:53 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Mon, 19 Sep 2016 19:13:53 -0600
Subject: [squid-users] Squid 3.5.20 compile issue
In-Reply-To: <20160920005652.GB13295@baea.com.au>
References: <1474330923.2521.8.camel@slave-tothe-box.net>
 <78153f47-8855-8c61-c775-8c209b653a48@measurement-factory.com>
 <20160920004211.GA13295@baea.com.au>
 <1474332278.2521.15.camel@slave-tothe-box.net>
 <20160920005652.GB13295@baea.com.au>
Message-ID: <1474334033.2521.18.camel@slave-tothe-box.net>

On Tue, 2016-09-20 at 10:26 +0930, LYMN wrote:
> On Mon, Sep 19, 2016 at 06:44:38PM -0600, James Lay wrote:
> > 
> > > 
> > > > 
> > > > 
> > > At a guess add this to the libraries list after openssl: -ldl
> > > 
> > Thank you...where would I add that to? ?My config line? ?Here it
> > is:
> > ./configure --prefix=/opt --with-openssl=/opt/openssl --enable-ssl
> > --
> > enable-ssl-crtd --enable-linux-netfilter --enable-follow-x-
> > forwarded-
> > for --with-large-files --sysconfdir=/opt/etc/squid --enable-
> > external-
> > acl-helpers=none
> > 
> try setting LIBS="-ldl" in the environment before you do the
> configure.
> 
> 
Thanks again Brett. ?Turns out you have to add the "shared" option:
./Configure enable-chacha enable-poly1305 --prefix=/opt/openssl shared
linux-x86_64
which you know....kind of makes sense because it's like...a SHARED
library 8-| ?Yugh..I hate being dumb.
James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160919/95554546/attachment.htm>

From jlay at slave-tothe-box.net  Tue Sep 20 01:20:14 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Mon, 19 Sep 2016 19:20:14 -0600
Subject: [squid-users] Squid 3.5.20 compile issue
In-Reply-To: <1474332278.2521.15.camel@slave-tothe-box.net>
References: <1474330923.2521.8.camel@slave-tothe-box.net>
 <78153f47-8855-8c61-c775-8c209b653a48@measurement-factory.com>
 <20160920004211.GA13295@baea.com.au>
 <1474332278.2521.15.camel@slave-tothe-box.net>
Message-ID: <1474334414.2521.19.camel@slave-tothe-box.net>

On Mon, 2016-09-19 at 18:44 -0600, James Lay wrote:
> On Tue, 2016-09-20 at 10:12 +0930, LYMN wrote:
> > On Mon, Sep 19, 2016 at 06:37:44PM -0600, Alex Rousskov wrote:
> > > 
> > > On 09/19/2016 06:22 PM, James Lay wrote:
> > > > 
> > > > Ok so this is with the 1.0.2 branch of openssl:
> > > > 
> > > > dso_dlfcn.c:(.text+0x11): undefined reference to `dlopen'
> > > > dso_dlfcn.c:(.text+0x24): undefined reference to `dlsym'
> > > > dso_dlfcn.c:(.text+0x2f): undefined reference to `dlclose'
> > > You can probably force you way through this by linking with more
> > > system
> > > libraries, but I do not know exactly which ones you need. This
> > > smells
> > > like an environment or build configuration problem to me -- the
> > > linker
> > > does not know that your OpenSSL library depends on another system
> > > library that provides those [dynamic linking] functions.
> > > 
> > At a guess add this to the libraries list after openssl: -ldl
> > 
> Thank you...where would I add that to? ?My config line? ?Here it is:
> 
> ./configure --prefix=/opt --with-openssl=/opt/openssl --enable-ssl --
> enable-ssl-crtd --enable-linux-netfilter --enable-follow-x-forwarded-
> for --with-large-files --sysconfdir=/opt/etc/squid --enable-external-
> acl-helpers=none
> 
> James
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
Well last word on this...squid starts but dies with:
/squid: symbol lookup error: ./squid: undefined symbol:
SSL_set_alpn_protos
So at this point I'll just go back to linking to libressl. ?Thanks all.
James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160919/eedfeaa9/attachment.htm>

From brett.lymn at baesystems.com  Tue Sep 20 01:35:22 2016
From: brett.lymn at baesystems.com (LYMN)
Date: Tue, 20 Sep 2016 11:05:22 +0930
Subject: [squid-users] Squid 3.5.20 compile issue
In-Reply-To: <1474334414.2521.19.camel@slave-tothe-box.net>
References: <1474330923.2521.8.camel@slave-tothe-box.net>
 <78153f47-8855-8c61-c775-8c209b653a48@measurement-factory.com>
 <20160920004211.GA13295@baea.com.au>
 <1474332278.2521.15.camel@slave-tothe-box.net>
 <1474334414.2521.19.camel@slave-tothe-box.net>
Message-ID: <20160920013521.GD13295@baea.com.au>

On Mon, Sep 19, 2016 at 07:20:14PM -0600, James Lay wrote:
>
> Well last word on this...squid starts but dies with:
> /squid: symbol lookup error: ./squid: undefined symbol:
> SSL_set_alpn_protos
> So at this point I'll just go back to linking to libressl. ?Thanks all.
>


What does a "ldd squid" output?  You have built your openssl libraries
to a non-standard place so perhaps squid cannot find them at run time?
If this was the case then you either need to use LD_LIBRARY_PATH at run
time or set LDFLAGS="-L/opt/openssl/lib -Wl,-R/opt/openssl/lib" at squid
configure time.


-- 
Brett Lymn
This email has been sent on behalf of one of the following companies within the BAE Systems Australia group of companies:

    BAE Systems Australia Limited - Australian Company Number 008 423 005
    BAE Systems Australia Defence Pty Limited - Australian Company Number 006 870 846
    BAE Systems Australia Logistics Pty Limited - Australian Company Number 086 228 864

Our registered office is Evans Building, Taranaki Road, Edinburgh Parks,
Edinburgh, South Australia, 5111. If the identity of the sending company is
not clear from the content of this email please contact the sender.

This email and any attachments may contain confidential and legally
privileged information.  If you are not the intended recipient, do not copy or
disclose its content, but please reply to this email immediately and highlight
the error to the sender and then immediately delete the message.



From jlay at slave-tothe-box.net  Tue Sep 20 01:50:21 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Mon, 19 Sep 2016 19:50:21 -0600
Subject: [squid-users] Squid 3.5.20 compile issue
In-Reply-To: <20160920013521.GD13295@baea.com.au>
References: <1474330923.2521.8.camel@slave-tothe-box.net>
 <78153f47-8855-8c61-c775-8c209b653a48@measurement-factory.com>
 <20160920004211.GA13295@baea.com.au>
 <1474332278.2521.15.camel@slave-tothe-box.net>
 <1474334414.2521.19.camel@slave-tothe-box.net>
 <20160920013521.GD13295@baea.com.au>
Message-ID: <1474336221.2521.20.camel@slave-tothe-box.net>

On Tue, 2016-09-20 at 11:05 +0930, LYMN wrote:
> On Mon, Sep 19, 2016 at 07:20:14PM -0600, James Lay wrote:
> > 
> > 
> > Well last word on this...squid starts but dies with:
> > /squid: symbol lookup error: ./squid: undefined symbol:
> > SSL_set_alpn_protos
> > So at this point I'll just go back to linking to libressl. ?Thanks
> > all.
> > 
> 
> What does a "ldd squid" output???You have built your openssl
> libraries
> to a non-standard place so perhaps squid cannot find them at run
> time?
> If this was the case then you either need to use LD_LIBRARY_PATH at
> run
> time or set LDFLAGS="-L/opt/openssl/lib -Wl,-R/opt/openssl/lib" at
> squid
> configure time.
> 
> 
Woo hoo! ?Success! ?Looks like this works with openssl-1.0.1. ?Thanks
much all!
James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160919/426d67eb/attachment.htm>

From fredbmail at free.fr  Tue Sep 20 08:39:57 2016
From: fredbmail at free.fr (FredB)
Date: Tue, 20 Sep 2016 10:39:57 +0200 (CEST)
Subject: [squid-users] SSO and Squid, SAML 2.0 ?
In-Reply-To: <1035998297.909219926.1474359122436.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <852764541.909339728.1474360797455.JavaMail.root@zimbra4-e1.priv.proxad.net>

Hello All,

I'm searching a way to use a secure SSO with Squid, how did you implement the authenticate method with an implicit proxy ? 
I'm reading many documentations about SAML, but I found nothing about Squid 

I guess we can only do something with cookies ? 

Anyone know if it's possible?

Thanks

Regards 

Fred




From fredbmail at free.fr  Tue Sep 20 08:58:52 2016
From: fredbmail at free.fr (FredB)
Date: Tue, 20 Sep 2016 10:58:52 +0200 (CEST)
Subject: [squid-users] SSO and Squid, SAML 2.0 ?
In-Reply-To: <852764541.909339728.1474360797455.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <626627072.909423261.1474361932159.JavaMail.root@zimbra4-e1.priv.proxad.net>

I forgot, if possible a method without active directory 


From squid3 at treenet.co.nz  Tue Sep 20 10:12:32 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 20 Sep 2016 22:12:32 +1200
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <CADSSinMq2GoE0gwYWXMX7foiVqExoc5HnQbEdX0qm-q4CM13tA@mail.gmail.com>
References: <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
 <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>
 <6e65eafe-37aa-e6f2-9c04-e4e14b9ff3e9@gmail.com>
 <CAEpx-0WMruHcZBP=kpZO1+C4YnELpeYGy2=WYtKMY5zmTWuaBg@mail.gmail.com>
 <3c02e953-d2cb-7905-f52a-e036ed3e06ab@treenet.co.nz>
 <1473879398350-4679512.post@n4.nabble.com>
 <e730f7da-c6ce-808f-f454-2d7a0369a92b@measurement-factory.com>
 <1473894106709-4679515.post@n4.nabble.com>
 <11a31fcd-901a-351a-4f60-8b2fe054b224@measurement-factory.com>
 <1473903753861-4679519.post@n4.nabble.com>
 <1474306760218-4679596.post@n4.nabble.com>
 <CADSSinMq2GoE0gwYWXMX7foiVqExoc5HnQbEdX0qm-q4CM13tA@mail.gmail.com>
Message-ID: <d63c5455-6a07-1da6-e089-240a10fce37c@treenet.co.nz>

On 20/09/2016 6:12 a.m., Jok Thuau wrote:
> On Mon, Sep 19, 2016 at 10:39 AM, erdosain9 <erdosain9 at gmail.com> wrote:
> 
>> mmmmmmmmmm....
>> so...
>> i think this is working for non take the certificate
>>
>> acl step1 at_step SslBump1
>> acl excludeSSL ssl::server_name_regex web/.whatsapp/.com
>>
> 
> wrong slashes... you want "\"
> 
> 
>>
>> ssl_bump peek step1
>> ssl_bump splice excludeSSL
>> ssl_bump bump all
>>
>> but, anyway something more is happening because well... dosent work.
>> another point of view??
>>
> 
> Yes, you still had something wrong. Also, i'm not sure if you need to
> anchor the RE to prevent it matching something like
> "web.whatsapp.com.malware.tld" in the server name. Maybe someone closer to
> the code can answer that question...

You are correct. regex contains implicit .* before and after the pattern
unless anchors are used.

Amos



From squid3 at treenet.co.nz  Tue Sep 20 10:18:22 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 20 Sep 2016 22:18:22 +1200
Subject: [squid-users] Squid 3.5.20 compile issue
In-Reply-To: <20160920013521.GD13295@baea.com.au>
References: <1474330923.2521.8.camel@slave-tothe-box.net>
 <78153f47-8855-8c61-c775-8c209b653a48@measurement-factory.com>
 <20160920004211.GA13295@baea.com.au>
 <1474332278.2521.15.camel@slave-tothe-box.net>
 <1474334414.2521.19.camel@slave-tothe-box.net>
 <20160920013521.GD13295@baea.com.au>
Message-ID: <be83bdca-7339-b4de-9012-ed6b4cbac847@treenet.co.nz>

On 20/09/2016 1:35 p.m., LYMN wrote:
> On Mon, Sep 19, 2016 at 07:20:14PM -0600, James Lay wrote:
>>
>> Well last word on this...squid starts but dies with:
>> /squid: symbol lookup error: ./squid: undefined symbol:
>> SSL_set_alpn_protos
>> So at this point I'll just go back to linking to libressl.  Thanks all.
>>
> 
> 
> What does a "ldd squid" output?  You have built your openssl libraries
> to a non-standard place so perhaps squid cannot find them at run time?
> If this was the case then you either need to use LD_LIBRARY_PATH at run
> time or set LDFLAGS="-L/opt/openssl/lib -Wl,-R/opt/openssl/lib" at squid
> configure time.
> 

Or just pass the Squid ./configure --with-openssl=/opt/openssl option.
Which will point Squid compiler at all the locations it needs for
correct symbols, dependecncies, include headers, etc. for the OpenSSL
version.

Amos



From squid3 at treenet.co.nz  Tue Sep 20 10:28:15 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 20 Sep 2016 22:28:15 +1200
Subject: [squid-users] squid https intercept mode and ubuntu third party
 repositories issue
In-Reply-To: <CA+sSnVYQ6CQEWdZf2CVLjzdEcWTtEJWsGFRtFtb+6n950sNRkA@mail.gmail.com>
References: <CA+sSnVYQ6CQEWdZf2CVLjzdEcWTtEJWsGFRtFtb+6n950sNRkA@mail.gmail.com>
Message-ID: <db9016e0-b147-812d-8fb6-c43215ca8123@treenet.co.nz>

On 20/09/2016 4:42 a.m., Hardik Dangar wrote:
> Hello,
> 
> I am using squid 3.5.12(detailed version info is below) on Ubuntu 16.04.1
> LTS server. My squid config is at, http://pastebin.com/raw/b8RZ67u9
> 
> I have configured squid as intercept proxy bumping all SSL https
> connections. Setup is working fine for many things like browsing,
> even on command line like wget i can download via https as i have installed
> root certificate within my client os.
> 
> My issue is whenever i try to add extra repository via command, i.e.
> sudo add-apt-repository ppa:ondrej/php
> command fails with output "Cannot add PPA: 'ppa:~ondrej/ubuntu/php'.ERROR:
> '~ondrej' user or team does not exist." and in squid's cache and access.log
> following entries can be located for this request,
> 
> ==> /var/log/squid/access.log <==
> 1474302162.378    439 192.168.1.66 TAG_NONE/200 0 CONNECT 91.189.89.223:443
> - ORIGINAL_DST/91.189.89.223 -
> 
> ==> /var/log/squid/cache.log <==
> 2016/09/19 21:52:42 kid1| Error negotiating SSL connection on FD 21:
> error:14094418:SSL routines:ssl3_read_bytes:tlsv1 alert unknown ca (1/0)
> 2016/09/19 21:52:42 kid1| hold write on SSL connection on FD 22
> 
> ==> /var/log/squid/access.log <==
> 1474302162.885    403 192.168.1.66 TAG_NONE/200 0 CONNECT 91.189.89.223:443
> - ORIGINAL_DST/91.189.89.223 -
> 
> ==> /var/log/squid/cache.log <==
> 2016/09/19 21:52:42 kid1| Error negotiating SSL connection on FD 21:
> error:14094418:SSL routines:ssl3_read_bytes:tlsv1 alert unknown ca (1/0)
> 
> in the above output 192.168.1.66 is my client requesting that request and
> as you can see in cache.log there is certificate negotiation error. I have
> tried to fiddle with all options provided at http://wiki.squid-cache.org/
> ConfigExamples/Intercept/SslBumpExplicit but it seems i am out of luck
> after almost half of my day battling this issue.
> 
> Can someone tell me they are successful with this issue? if so can you
> share your squid.conf relevant section?
> 
> $ squid -v
> Squid Cache: Version 3.5.12

Ubuntu Squid package does not build with SSL functionality.

When re-building your Squid with SSL-Bump features it is important to
always use teh very latest Squid release. SSL/TLS and bumping are part
of an ongoing arms race situation. Things are constantly changing and
software from as little as a year ago is unlikly to work 100% well with
intercepting ('bumping') encryption from today.

First thing to try is to rebuild with squid 3.5.20 or .21 and see if the
problem remains.

Amos



From hardikdangar+squid at gmail.com  Tue Sep 20 11:59:11 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Tue, 20 Sep 2016 17:29:11 +0530
Subject: [squid-users] squid https intercept mode and ubuntu third party
 repositories issue
In-Reply-To: <db9016e0-b147-812d-8fb6-c43215ca8123@treenet.co.nz>
References: <CA+sSnVYQ6CQEWdZf2CVLjzdEcWTtEJWsGFRtFtb+6n950sNRkA@mail.gmail.com>
 <db9016e0-b147-812d-8fb6-c43215ca8123@treenet.co.nz>
Message-ID: <CA+sSnVbTA92Ocfpedv7yAY9KO1FDZcfaKCbivK7q+JXB5of=-Q@mail.gmail.com>

Amos,
Thank you for your reply.
I have version 3.5.12 compiled with Debian rules example provided here,
http://docs.diladele.com/administrator_guide_4_5/install/ubuntu14/tools.html

Do you think I could patch squid from 3.5.12 to 3.5.21 via patches
available at http://www.squid-cache.org/Versions/v3/3.5/
Or I could download tar.gz file and replace files from that folder to
Debian source folder ?

do i need any extra tools to build squid 3.5.21?


On Tue, Sep 20, 2016 at 3:58 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 20/09/2016 4:42 a.m., Hardik Dangar wrote:
> > Hello,
> >
> > I am using squid 3.5.12(detailed version info is below) on Ubuntu 16.04.1
> > LTS server. My squid config is at, http://pastebin.com/raw/b8RZ67u9
> >
> > I have configured squid as intercept proxy bumping all SSL https
> > connections. Setup is working fine for many things like browsing,
> > even on command line like wget i can download via https as i have
> installed
> > root certificate within my client os.
> >
> > My issue is whenever i try to add extra repository via command, i.e.
> > sudo add-apt-repository ppa:ondrej/php
> > command fails with output "Cannot add PPA: 'ppa:~ondrej/ubuntu/php'.
> ERROR:
> > '~ondrej' user or team does not exist." and in squid's cache and
> access.log
> > following entries can be located for this request,
> >
> > ==> /var/log/squid/access.log <==
> > 1474302162.378    439 192.168.1.66 TAG_NONE/200 0 CONNECT
> 91.189.89.223:443
> > - ORIGINAL_DST/91.189.89.223 -
> >
> > ==> /var/log/squid/cache.log <==
> > 2016/09/19 21:52:42 kid1| Error negotiating SSL connection on FD 21:
> > error:14094418:SSL routines:ssl3_read_bytes:tlsv1 alert unknown ca (1/0)
> > 2016/09/19 21:52:42 kid1| hold write on SSL connection on FD 22
> >
> > ==> /var/log/squid/access.log <==
> > 1474302162.885    403 192.168.1.66 TAG_NONE/200 0 CONNECT
> 91.189.89.223:443
> > - ORIGINAL_DST/91.189.89.223 -
> >
> > ==> /var/log/squid/cache.log <==
> > 2016/09/19 21:52:42 kid1| Error negotiating SSL connection on FD 21:
> > error:14094418:SSL routines:ssl3_read_bytes:tlsv1 alert unknown ca (1/0)
> >
> > in the above output 192.168.1.66 is my client requesting that request and
> > as you can see in cache.log there is certificate negotiation error. I
> have
> > tried to fiddle with all options provided at
> http://wiki.squid-cache.org/
> > ConfigExamples/Intercept/SslBumpExplicit but it seems i am out of luck
> > after almost half of my day battling this issue.
> >
> > Can someone tell me they are successful with this issue? if so can you
> > share your squid.conf relevant section?
> >
> > $ squid -v
> > Squid Cache: Version 3.5.12
>
> Ubuntu Squid package does not build with SSL functionality.
>
> When re-building your Squid with SSL-Bump features it is important to
> always use teh very latest Squid release. SSL/TLS and bumping are part
> of an ongoing arms race situation. Things are constantly changing and
> software from as little as a year ago is unlikly to work 100% well with
> intercepting ('bumping') encryption from today.
>
> First thing to try is to rebuild with squid 3.5.20 or .21 and see if the
> problem remains.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160920/86fae107/attachment.htm>

From Silamael at coronamundi.de  Tue Sep 20 13:20:06 2016
From: Silamael at coronamundi.de (Silamael)
Date: Tue, 20 Sep 2016 15:20:06 +0200
Subject: [squid-users] Problem with Kerberos and
 ext_kerberos_ldap_group_acl not being able to reach realm's KDC
In-Reply-To: <35fd4285-c508-cacd-f166-a3f8b8bac09d@coronamundi.de>
References: <955b9071-4d07-f0a2-2925-8f63fa3324af@coronamundi.de>
 <nrhjm8$mu5$1@blaine.gmane.org>
 <35fd4285-c508-cacd-f166-a3f8b8bac09d@coronamundi.de>
Message-ID: <3655aec8-d4cc-83c0-fb75-b778b6fd4785@coronamundi.de>

On 19.09.2016 13:39, Silamael Darkomen wrote:
> 
> 
> On 16.09.2016 22:11, Markus Moeller wrote:
>> Hi Silamael,
>>
>>     Can you perform a kinit user at EXAMPLE.COM ?   Does the squid user
>> have read access to  krb5.conf ?
>>
>> Markus
> 
> Hello Markus,
> 
> Yes, the permissions are correctly set up so that Squid and it's
> processes can read every file needed.
> For it seems that the Heimdal library ignores the dns_lookup_kdc and
> dns_lookup_realm options in the krb5.conf...
> As written in my other response, the helper also crashes at the end.
> I'll take a look on the stack trace...

Ok, found one problem. Under OpenBSD I had some hack that the external
helper was linked against libbind (the bind resolver library) instead of
libc (as the helper uses some defines which have different names in the
OpenBSD libc). This caused that the Heimdal libs used also the Bind
resolver library instead of the libc resolver. And this lead to an error
in the getaddrinfo() call due to invalid ai_flags.
After patching the helper to compile with the libc now a new problem
comes up:
When binding to the LDAP server the helper uses SASL/GSSAPI. And then
ldap_sasl_interactive_bind_s failes with "Unknown authentication method".
Is there anything special that must be given on the Windows side? Or
what's wrong now?

-- Matthias


From erdosain9 at gmail.com  Tue Sep 20 16:50:56 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 20 Sep 2016 09:50:56 -0700 (PDT)
Subject: [squid-users] SSO (kerberos)
In-Reply-To: <1473969879489-4679542.post@n4.nabble.com>
References: <1473702058647-4679470.post@n4.nabble.com>
 <6bbebad5-7712-9b39-2510-8fcb7ece641b@treenet.co.nz>
 <1473780876101-4679484.post@n4.nabble.com>
 <ddc7ffa7-9858-710a-b8e0-6848106168bb@treenet.co.nz>
 <1473791599383-4679490.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73FC133@CLWSEXCMBX02.na.bicworld.com>
 <1473965736706-4679540.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73FCF2C@CLWSEXCMBX02.na.bicworld.com>
 <1473969879489-4679542.post@n4.nabble.com>
Message-ID: <1474390256210-4679618.post@n4.nabble.com>

Ok,
Well i have this settings

-----------------------------------------------------------------------------------------------------------------------------
*cat /etc/sysconfig/squid
*# Kerberos autenticacion
KRB5_KTNAME=/etc/squid/PROXY.keytab
export KRB5_KTNAME
# # default squid options
SQUID_OPTS=""
#
# # Time to wait for Squid to shut down when asked. Should not be necessary
# # most of the time.
SQUID_SHUTDOWN_TIMEOUT=100
#
# # default squid conf file
SQUID_CONF="/etc/squid/squid.conf"
# ~                                       "

-----------------------------------------------------------------------------------------------------------------------------
*/etc/krb5.conf 
*
[logging]
 default = FILE:/var/log/krb5libs.log
 kdc = FILE:/var/log/krb5kdc.log
 admin_server = FILE:/var/log/kadmind.log

[libdefaults]
    default_realm = EXAMPLE.LAN
    dns_lookup_kdc = no 
    dns_lookup_realm = no
    ticket_lifetime = 24h
    default_keytab_name = /etc/squid/PROXY.keytab

; for Windows 2003
;    default_tgs_enctypes = rc4-hmac des-cbc-crc des-cbc-md5
;    default_tkt_enctypes = rc4-hmac des-cbc-crc des-cbc-md5
;    permitted_enctypes = rc4-hmac des-cbc-crc des-cbc-md5

; for Windows 2008 with AES
    default_tgs_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5
    default_tkt_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5
    permitted_enctypes = aes256-cts-hmac-sha1-96 rc4-hmac des-cbc-crc
des-cbc-md5


[realms]
    EXAMPLE.LAN = {
        kdc = ads-1.example.lan
	kdc = ads-2.example.lan
        admin_server = ads-1.example.lan
	default_domain = example.lan
    }

[domain_realm]
    .example.lan = EXAMPLE.LAN
    example.lan = EXAMPLE.LAN

---------------------------------------------------------------------------------------------------------------------------------

*/etc/samba/smb.conf 
*[global]
 
local master = no
workgroup = EXAMPLE
security = ads
realm = EXAMPLE.LAN

winbind uid = 10000-20000
winbind gid = 10000-20000
winbind use default domain = yes
winbind enum users = yes
winbind enum groups = yes

load printers = no
printing = bsd
printcap name = /dev/null
disable spoolss = yes
     
---------------------------------------------------------------------------------

*SQUID.CONF
*
auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -d -s
HTTP/squid.example.lan at EXAMPLE.LANauth_param negotiate children 10
auth_param negotiate keep_alive on

acl auth proxy_auth REQUIRED
http_access allow all auth


--------------------------------------------------------------------------------------

*cat /var/log/squid/cache.log
*2016/09/20 13:50:00| Set Current Directory to /var/spool/squid
2016/09/20 13:50:00| Set Current Directory to /var/spool/squid
2016/09/20 13:50:32 kid1| Set Current Directory to /var/spool/squid
2016/09/20 13:50:32 kid1| Starting Squid Cache version 3.5.20 for
x86_64-redhat-linux-gnu...
2016/09/20 13:50:32 kid1| Service Name: squid
2016/09/20 13:50:32 kid1| Process ID 2014
2016/09/20 13:50:32 kid1| Process Roles: worker
2016/09/20 13:50:32 kid1| With 16384 file descriptors available
2016/09/20 13:50:32 kid1| Initializing IP Cache...
2016/09/20 13:50:32 kid1| DNS Socket created at [::], FD 9
2016/09/20 13:50:32 kid1| DNS Socket created at 0.0.0.0, FD 10
2016/09/20 13:50:32 kid1| Adding nameserver 192.168.1.1 from squid.conf
2016/09/20 13:50:32 kid1| helperOpenServers: Starting 1/8 'ssl_crtd'
processes
2016/09/20 13:50:32 kid1| helperOpenServers: Starting 0/20
'negotiate_kerberos_auth' processes
2016/09/20 13:50:32 kid1| helperStatefulOpenServers: No
'negotiate_kerberos_auth' processes needed.
2016/09/20 13:50:32 kid1| Logfile: opening log
daemon:/var/log/squid/access.log
2016/09/20 13:50:32 kid1| Logfile Daemon: opening log
/var/log/squid/access.log
2016/09/20 13:50:32 kid1| Local cache digest enabled; rebuild/rewrite every
3600/3600 sec
2016/09/20 13:50:32 kid1| Store logging disabled
2016/09/20 13:50:32 kid1| Swap maxSize 1024000 + 262144 KB, estimated 98934
objects
2016/09/20 13:50:32 kid1| Target number of buckets: 4946
2016/09/20 13:50:32 kid1| Using 8192 Store buckets
2016/09/20 13:50:32 kid1| Max Mem  size: 262144 KB
2016/09/20 13:50:32 kid1| Max Swap size: 1024000 KB
2016/09/20 13:50:32 kid1| Rebuilding storage in /var/spool/squid (clean log)
2016/09/20 13:50:32 kid1| Using Least Load store dir selection
2016/09/20 13:50:32 kid1| Set Current Directory to /var/spool/squid
2016/09/20 13:50:32 kid1| Finished loading MIME types and icons.
2016/09/20 13:50:32 kid1| HTCP Disabled.
2016/09/20 13:50:32 kid1| Squid plugin modules loaded: 0
2016/09/20 13:50:32 kid1| Adaptation support is off.
2016/09/20 13:50:32 kid1| Accepting SSL bumped HTTP Socket connections at
local=192.168.1.109:3128 remote=[::] FD 18 flags=9
2016/09/20 13:50:32 kid1| Store rebuilding is 9.41% complete
2016/09/20 13:50:32 kid1| Done reading /var/spool/squid swaplog (42515
entries)
2016/09/20 13:50:32 kid1| Finished rebuilding storage from disk.
2016/09/20 13:50:32 kid1|     42515 Entries scanned
2016/09/20 13:50:32 kid1|         0 Invalid entries.
2016/09/20 13:50:32 kid1|         0 With invalid flags.
2016/09/20 13:50:32 kid1|     42515 Objects loaded.
2016/09/20 13:50:32 kid1|         0 Objects expired.
2016/09/20 13:50:32 kid1|         0 Objects cancelled.
2016/09/20 13:50:32 kid1|         0 Duplicate URLs purged.
2016/09/20 13:50:32 kid1|         0 Swapfile clashes avoided.
2016/09/20 13:50:32 kid1|   Took 0.08 seconds (529577.36 objects/sec).
2016/09/20 13:50:32 kid1| Beginning Validation Procedure
2016/09/20 13:50:32 kid1|   Completed Validation Procedure
2016/09/20 13:50:32 kid1|   Validated 42514 Entries
2016/09/20 13:50:32 kid1|   store_swap_size = 921596.00 KB
2016/09/20 13:50:33 kid1| storeLateRelease: released 0 objects
2016/09/20 13:50:47 kid1| Starting new negotiateauthenticator helpers...
2016/09/20 13:50:47 kid1| helperOpenServers: Starting 1/20
'negotiate_kerberos_auth' processes
negotiate_kerberos_auth.cc(487): pid=2018 :2016/09/20 13:50:47|
negotiate_kerberos_auth: INFO: Starting version 3.0.4sq
negotiate_kerberos_auth.cc(546): pid=2018 :2016/09/20 13:50:47|
negotiate_kerberos_auth: INFO: Setting keytab to /etc/squid/PROXY.keytab
negotiate_kerberos_auth.cc(570): pid=2018 :2016/09/20 13:50:47|
negotiate_kerberos_auth: INFO: Changed keytab to
MEMORY:negotiate_kerberos_auth_2018
negotiate_kerberos_auth.cc(610): pid=2018 :2016/09/20 13:50:47|
negotiate_kerberos_auth: DEBUG: Got 'YR
TlRMTVNTUAABAAAAl4II4gAAAAAAAAAAAAAAAAAAAAAGAbEdAAAADw==' from squid
(length: 59).
negotiate_kerberos_auth.cc(663): pid=2018 :2016/09/20 13:50:47|
negotiate_kerberos_auth: DEBUG: Decode
'TlRMTVNTUAABAAAAl4II4gAAAAAAAAAAAAAAAAAAAAAGAbEdAAAADw==' (decoded length:
40).
negotiate_kerberos_auth.cc(673): pid=2018 :2016/09/20 13:50:47|
negotiate_kerberos_auth: WARNING: received type 1 NTLM token
2016/09/20 13:50:47 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}

-----------------------------------------------------------------------------------------------------------------------------------------

*access.log*
1474390313.371      0 192.168.1.121 TCP_DENIED/407 4334 CONNECT
incoming.telemetry.mozilla.org:443 - HIER_NONE/- text/html
1474390313.374      0 192.168.1.121 TCP_DENIED/407 4334 CONNECT
incoming.telemetry.mozilla.org:443 - HIER_NONE/- text/html
1474390449.644      0 192.168.1.121 TCP_DENIED/407 4167 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1474390449.651      0 192.168.1.121 TCP_DENIED/407 4270 CONNECT
www.google.com:443 - HIER_NONE/- text/html
1474390464.320      0 192.168.1.121 TCP_DENIED/407 4175 CONNECT
www.facebook.com:443 - HIER_NONE/- text/html
1474390464.326      0 192.168.1.121 TCP_DENIED/407 4278 CONNECT
www.facebook.com:443 - HIER_NONE/- text/html


So...... what can i do??




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SSO-kerberos-tp4679470p4679618.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Tue Sep 20 18:42:20 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 20 Sep 2016 11:42:20 -0700 (PDT)
Subject: [squid-users] Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
Message-ID: <1474396940500-4679619.post@n4.nabble.com>

Hi,
Im having this error randomly.....

This is traying access google.com

The following error was encountered while trying to retrieve the URL:
https://www.google.com.ar/*

Failed to establish a secure connection to 172.217.28.227

The system returned:

(71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
Handshake with SSL server failed: [No Error]

This proxy and the remote host failed to negotiate a mutually acceptable
security settings for handling your request. It is possible that the remote
host does not support secure connections, or the proxy is not satisfied with
the host security credentials.

Your cache administrator is webmaster.

---------------------------

Access.log

1474396984.699     69 192.168.1.172 TCP_MISS/200 716 GET
https://www.google.com.ar/complete/search? - HIER_DIRECT/172.217.28.227
application/json
1474396985.558    673 192.168.1.172 TCP_MISS/200 730 GET
https://www.google.com.ar/complete/search? - HIER_DIRECT/172.217.28.227
application/json
1474396985.782    104 192.168.1.172 TCP_MISS/200 710 GET
https://www.google.com.ar/complete/search? - HIER_DIRECT/172.217.28.227
application/json
1474396986.066     83 192.168.1.172 TCP_MISS_ABORTED/000 0 GET
https://www.google.com.ar/complete/search? - HIER_DIRECT/172.217.28.227 -
1474396986.157     87 192.168.1.172 TCP_MISS/200 757 GET
https://www.google.com.ar/complete/search? - HIER_DIRECT/172.217.28.227
application/json
1474396986.541      0 192.168.1.172 TAG_NONE/503 4423 GET
https://www.google.com.ar/search? - HIER_NONE/- text/html
1474396986.569      1 192.168.1.172 TAG_NONE/503 4423 GET
http://squid:3128/squid-internal-static/icons/SN.png - HIER_NONE/- text/html
1474396986.612     77 192.168.1.172 TCP_MISS/204 340 POST
https://www.google.com.ar/gen_204? - HIER_DIRECT/172.217.28.227 text/html


Thanks to all.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Protocol-error-TLS-code-SQUID-ERR-SSL-HANDSHAKE-tp4679619.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From hardikdangar+squid at gmail.com  Tue Sep 20 18:59:48 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Wed, 21 Sep 2016 00:29:48 +0530
Subject: [squid-users] Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <1474396940500-4679619.post@n4.nabble.com>
References: <1474396940500-4679619.post@n4.nabble.com>
Message-ID: <CA+sSnVZyD6O51ukYthm4V0h2xEuC0sKxZvtTVKgZqtDGTSGBMA@mail.gmail.com>

It looks like server failure,
this could be due to isp snooping connection at upper level or google.com.ar
servers are broken temporarily.
see similar issue
http://lists.squid-cache.org/pipermail/squid-users/2014-October/000562.html



On Wed, Sep 21, 2016 at 12:12 AM, erdosain9 <erdosain9 at gmail.com> wrote:

> Hi,
> Im having this error randomly.....
>
> This is traying access google.com
>
> The following error was encountered while trying to retrieve the URL:
> https://www.google.com.ar/*
>
> Failed to establish a secure connection to 172.217.28.227
>
> The system returned:
>
> (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
> Handshake with SSL server failed: [No Error]
>
> This proxy and the remote host failed to negotiate a mutually acceptable
> security settings for handling your request. It is possible that the remote
> host does not support secure connections, or the proxy is not satisfied
> with
> the host security credentials.
>
> Your cache administrator is webmaster.
>
> ---------------------------
>
> Access.log
>
> 1474396984.699     69 192.168.1.172 TCP_MISS/200 716 GET
> https://www.google.com.ar/complete/search? - HIER_DIRECT/172.217.28.227
> application/json
> 1474396985.558    673 192.168.1.172 TCP_MISS/200 730 GET
> https://www.google.com.ar/complete/search? - HIER_DIRECT/172.217.28.227
> application/json
> 1474396985.782    104 192.168.1.172 TCP_MISS/200 710 GET
> https://www.google.com.ar/complete/search? - HIER_DIRECT/172.217.28.227
> application/json
> 1474396986.066     83 192.168.1.172 TCP_MISS_ABORTED/000 0 GET
> https://www.google.com.ar/complete/search? - HIER_DIRECT/172.217.28.227 -
> 1474396986.157     87 192.168.1.172 TCP_MISS/200 757 GET
> https://www.google.com.ar/complete/search? - HIER_DIRECT/172.217.28.227
> application/json
> 1474396986.541      0 192.168.1.172 TAG_NONE/503 4423 GET
> https://www.google.com.ar/search? - HIER_NONE/- text/html
> 1474396986.569      1 192.168.1.172 TAG_NONE/503 4423 GET
> http://squid:3128/squid-internal-static/icons/SN.png - HIER_NONE/-
> text/html
> 1474396986.612     77 192.168.1.172 TCP_MISS/204 340 POST
> https://www.google.com.ar/gen_204? - HIER_DIRECT/172.217.28.227 text/html
>
>
> Thanks to all.
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.
> 1019090.n4.nabble.com/Protocol-error-TLS-code-SQUID-
> ERR-SSL-HANDSHAKE-tp4679619.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160921/50cb9350/attachment.htm>

From erdosain9 at gmail.com  Tue Sep 20 19:28:00 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 20 Sep 2016 12:28:00 -0700 (PDT)
Subject: [squid-users] Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <CA+sSnVZyD6O51ukYthm4V0h2xEuC0sKxZvtTVKgZqtDGTSGBMA@mail.gmail.com>
References: <1474396940500-4679619.post@n4.nabble.com>
 <CA+sSnVZyD6O51ukYthm4V0h2xEuC0sKxZvtTVKgZqtDGTSGBMA@mail.gmail.com>
Message-ID: <1474399680244-4679621.post@n4.nabble.com>

Hi.
I have this in cache.log

Starting new ssl_crtd helpers...
2016/09/20 16:30:15 kid1| helperOpenServers: Starting 1/8 'ssl_crtd'
processes
2016/09/20 16:30:15 kid1| Error negotiating SSL on FD 28: error:1409F07F:SSL
routines:SSL3_WRITE_PENDING:bad write retry (1/-1/0)
2016/09/20 16:30:16 kid1| Error negotiating SSL on FD 28: error:1409F07F:SSL
routines:SSL3_WRITE_PENDING:bad write retry (1/-1/0)
2016/09/20 16:30:16 kid1| Error negotiating SSL on FD 28: error:1409F07F:SSL
routines:SSL3_WRITE_PENDING:bad write retry (1/-1/0)
2016/09/20 16:30:16 kid1| Error negotiating SSL on FD 22: error:1409F07F:SSL
routines:SSL3_WRITE_PENDING:bad write retry (1/-1/0)






--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Protocol-error-TLS-code-SQUID-ERR-SSL-HANDSHAKE-tp4679619p4679621.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From gkinkie at gmail.com  Tue Sep 20 19:41:24 2016
From: gkinkie at gmail.com (Kinkie)
Date: Tue, 20 Sep 2016 20:41:24 +0100
Subject: [squid-users] SSO and Squid, SAML 2.0 ?
In-Reply-To: <626627072.909423261.1474361932159.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <852764541.909339728.1474360797455.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <626627072.909423261.1474361932159.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <CA+Y8hcO3xc9TaNP_YkjRL6xEtg8Y7axC8e2_YTf+w74p-PJ2uw@mail.gmail.com>

Hi Fred,
  I assume that by "implicit" you mean "transparent" or
"interception". Short answer, not possible: there is nothing to anchor
cookies to. It could be possible to fake it by having an auxiliary
website doing standard SAML and feeding a database of associations
userid-ip. It will fail to account for cases where multiple users
share the same IP, but that doesn't stop many vendors from caliming
they do "transparent authentication".

On Tue, Sep 20, 2016 at 9:58 AM, FredB <fredbmail at free.fr> wrote:
> I forgot, if possible a method without active directory
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



-- 
    Francesco


From hchuongyh90 at gmail.com  Wed Sep 21 04:09:11 2016
From: hchuongyh90 at gmail.com (Chuong Hoang)
Date: Wed, 21 Sep 2016 11:09:11 +0700
Subject: [squid-users] Squid for proxy server on Google Compute Engine?
Message-ID: <3C50F975-A0CF-4A3F-80C4-90DA6CD5DF72@gmail.com>

Hi guys, thanks for reading this! I?m new so sorry if this is a dumb question! But I've been finding the answer for 3 days but still no sign of light.

I?ve already posted the problem on GCE discussion group- this link: https://groups.google.com/forum/#!topic/gce-discussion/xwlHYhFTUtU

To make it clear, I also restate the problem here:
Been working on this for 2 days and still cannot find the way out :(

Below is my setup for testing, which basically supports all http_access through port 8888

-squid.conf file:

http_port 8888
http_access allow all
-Open port 8888 for incoming HTTP data by gcloud command (which returned "allowed")

gcloud compute firewall-rules create allow-tcp --description "Incoming-http-allowed." --allow tcp:8888 --format json
With the setup above, I can telnet to the IP with port 8888. However, when querying to some http links with browser (Safari/Chrome), I always get this message

The following error was encountered while trying to retrieve the URL: http://google.com/ <http://google.com/>

Access Denied.

Access control configuration prevents your request from being allowed at this time. Please contact your service provider if you feel this is incorrect.

Your cache administrator is webmaster.
I also tried other ports (3128, 8000, 80) but no help
I also tried to force the port to listen IPv4 addresses with something like http_port 0.0.0.0:8888 <http://0.0.0.0:8888/> and still not working
Someone please help me out of this mess :( Much appreciated!

P/S: I connect to the squid proxy though my Macbook (OS Sierra) with Web Proxy (HTTP) enabled in Network Preferences.

This is some logs from cache.log, which probably indicates that my conf file is fraud. client_side.cc(777) swanSong: local=10.xxx.0.2:8888 remote=113.xxx.xxx.113:54856 flags=1 - 10.xxx.0.2 is GCE's internal IP - 113.xxx.xxx.113 is my computer's external IP 


Much appreciated if anyone can help me out!

Thank you!
Chuong
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160921/40188717/attachment.htm>

From Silamael at coronamundi.de  Wed Sep 21 06:54:07 2016
From: Silamael at coronamundi.de (Silamael)
Date: Wed, 21 Sep 2016 08:54:07 +0200
Subject: [squid-users] Problem with Kerberos and
 ext_kerberos_ldap_group_acl not being able to reach realm's KDC
In-Reply-To: <3655aec8-d4cc-83c0-fb75-b778b6fd4785@coronamundi.de>
References: <955b9071-4d07-f0a2-2925-8f63fa3324af@coronamundi.de>
 <nrhjm8$mu5$1@blaine.gmane.org>
 <35fd4285-c508-cacd-f166-a3f8b8bac09d@coronamundi.de>
 <3655aec8-d4cc-83c0-fb75-b778b6fd4785@coronamundi.de>
Message-ID: <5525e662-5e6a-da5c-84e1-f3f4a42aa398@coronamundi.de>

On 20.09.2016 15:20, Silamael wrote:
> Ok, found one problem. Under OpenBSD I had some hack that the external
> helper was linked against libbind (the bind resolver library) instead of
> libc (as the helper uses some defines which have different names in the
> OpenBSD libc). This caused that the Heimdal libs used also the Bind
> resolver library instead of the libc resolver. And this lead to an error
> in the getaddrinfo() call due to invalid ai_flags.
> After patching the helper to compile with the libc now a new problem
> comes up:
> When binding to the LDAP server the helper uses SASL/GSSAPI. And then
> ldap_sasl_interactive_bind_s failes with "Unknown authentication method".
> Is there anything special that must be given on the Windows side? Or
> what's wrong now?

Just for completness, the problems got solved. Cause for the last issue
was that the cyrus-sasl2 package wasn't built with GSSAPI support and
after that that the needed .so files were missing in the chroot
environment. After fixing this, the external_kerberos_ldap_group_acl
helper works like a charm.

Many thanks for any hints given!

-- Matthias


From fredbmail at free.fr  Wed Sep 21 07:10:43 2016
From: fredbmail at free.fr (FredB)
Date: Wed, 21 Sep 2016 09:10:43 +0200 (CEST)
Subject: [squid-users] SSO and Squid, SAML 2.0 ?
In-Reply-To: <CA+Y8hcO3xc9TaNP_YkjRL6xEtg8Y7axC8e2_YTf+w74p-PJ2uw@mail.gmail.com>
Message-ID: <1412277241.913080986.1474441843283.JavaMail.root@zimbra4-e1.priv.proxad.net>


> Hi Fred,
>   I assume that by "implicit" you mean "transparent" or
> "interception". Short answer, not possible: there is nothing to
> anchor
> cookies to. It could be possible to fake it by having an auxiliary
> website doing standard SAML and feeding a database of associations
> userid-ip. It will fail to account for cases where multiple users
> share the same IP, but that doesn't stop many vendors from caliming
> they do "transparent authentication".
> 


Hi Kinkie,

No, sorry, I mean explicit (not transparent) 
And yes, I have some multiple users with the same IP 

Regards 

Fred


From Ralf.Hildebrandt at charite.de  Wed Sep 21 09:13:14 2016
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Wed, 21 Sep 2016 11:13:14 +0200
Subject: [squid-users] Ignoring DNS Lookup errors in ACLs?
Message-ID: <20160921091314.adu7iyzmszuzvj3d@charite.de>

Is there any way of making DNS Lookup errors in ACLs a warning only?

2016/09/19 13:00:14| aclIpParseIpData: Bad host/IP: 'cfmww-v-it-17.charite.de' in 'cfmww-v-it-17.charite.de', flags=0 : (-2) Name or service not known
2016/09/19 13:00:14| Not currently OK to rewrite swap log.
2016/09/19 13:00:14| storeDirWriteCleanLogs: Operation aborted. FATAL: Bungled /etc/squid3/squid.conf line 1694: acl teamviewer-allow src "/etc/squid3/teamviewer.acl"


-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
http://www.charite.de              Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From inspirit1986 at gmail.com  Wed Sep 21 13:41:00 2016
From: inspirit1986 at gmail.com (=?UTF-8?B?0KHQtdGA0LPQuNC9INCQ0LvQtdC60YHQsNC90LTRgA==?=)
Date: Wed, 21 Sep 2016 16:41:00 +0300
Subject: [squid-users] Fwd: Squid ssl bumping. Ssl bumping not working on
 sites with ssl GOST cypher certificate
In-Reply-To: <CAKodO4Uy2xNnGSkgdP+Aqz1rOrO4f9LjqfUE9bjX7Hm6DQvj2Q@mail.gmail.com>
References: <CAKodO4Uy2xNnGSkgdP+Aqz1rOrO4f9LjqfUE9bjX7Hm6DQvj2Q@mail.gmail.com>
Message-ID: <CAKodO4VLa8oqbND6Xbkjqg23U9cyrtVVv32hxVieoAcb77N_Og@mail.gmail.com>

Hi, can you please explain me, does squid support ssl bumping with site
signed with GOST certificate?

I have OpenSSL 1.0.2d 9 Jul 2015

openssl engine
(dynamic) Dynamic engine loading support
*(gost) Reference implementation of GOST engine*


*openssl ciphers | grep GOST*

*GOST2001-GOST89-GOST89:GOST94-GOST89-GOST89*

/opt/squid/sbin/squid -v
Squid Cache: Version 3.5.19
Service Name: squid
configure options:  'CFLAGS=-march=i686 -g -O2' 'CXXFLAGS=-march=i686 -g
-O2' '--prefix=/opt/squid-3.5.19-4' '--enable-async-io=32'
'--enable-storeio=ufs,aufs,rock,diskd' '--enable-disk-io'
'--enable-removal-policies=heap,lru' '--enable-useragent-log'
'--enable-referer-log' '--enable-arp-acl' '--with-openssl'
'--enable-forw-via-db' '--enable-cache-digests' '--enable-linux-netfilter'
'--enable-basic-auth=all' '--enable-ntlm-auth=all'
'--enable-ntlm-fail-open' '--enable-negotiate-auth=all'
'--enable-external-acl-helpers' '--with-filedescriptors=32768'
'--with-large-files' '--enable-delay-pools' '--enable-ssl-crtd'
'--disable-static' '--with-logdir=/var/log/squid'
'--with-pidfile=/var/run/squid.pid'
'--with-swapdir=/var/data/squid/cache' '--disable-arch-native'

SSL bumping with dynamic certificates working well but when I try to go to
site with GOST certificate,
I see error -

The system returned:

(71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)

Handshake with SSL server failed: error:0609E09C:digital envelope
routines:PKEY_SET_TYPE:unsupported algorithm


Please explain me this Error please
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160921/c0080a8b/attachment.htm>

From inspirit1986 at gmail.com  Wed Sep 21 13:42:56 2016
From: inspirit1986 at gmail.com (=?UTF-8?B?0KHQtdGA0LPQuNC9INCQ0LvQtdC60YHQsNC90LTRgA==?=)
Date: Wed, 21 Sep 2016 16:42:56 +0300
Subject: [squid-users] Squid SSL Bumping and GOST ciper error.
Message-ID: <CAKodO4XgoMcuCJ5KcUZcXVyJ3L_B5BNm8_LQa=ZtL8=GRer_tg@mail.gmail.com>

Best Regards,
Hi, can you please explain me, does squid support ssl bumping with site
signed with GOST certificate?

I have OpenSSL 1.0.2d 9 Jul 2015

openssl engine
(dynamic) Dynamic engine loading support
*(gost) Reference implementation of GOST engine*


*openssl ciphers | grep GOST*

*GOST2001-GOST89-GOST89:GOST94-GOST89-GOST89*

/opt/squid/sbin/squid -v
Squid Cache: Version 3.5.19
Service Name: squid
configure options:  'CFLAGS=-march=i686 -g -O2' 'CXXFLAGS=-march=i686 -g
-O2' '--prefix=/opt/squid-3.5.19-4' '--enable-async-io=32'
'--enable-storeio=ufs,aufs,rock,diskd' '--enable-disk-io'
'--enable-removal-policies=heap,lru' '--enable-useragent-log'
'--enable-referer-log' '--enable-arp-acl' '--with-openssl'
'--enable-forw-via-db' '--enable-cache-digests' '--enable-linux-netfilter'
'--enable-basic-auth=all' '--enable-ntlm-auth=all'
'--enable-ntlm-fail-open' '--enable-negotiate-auth=all'
'--enable-external-acl-helpers' '--with-filedescriptors=32768'
'--with-large-files' '--enable-delay-pools' '--enable-ssl-crtd'
'--disable-static' '--with-logdir=/var/log/squid'
'--with-pidfile=/var/run/squid.pid'
'--with-swapdir=/var/data/squid/cache' '--disable-arch-native'

SSL bumping with dynamic certificates working well but when I try to go to
site with GOST certificate,
I see error -

The system returned:

(71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)

Handshake with SSL server failed: error:0609E09C:digital envelope
routines:PKEY_SET_TYPE:unsupported algorithm


Please explain me this Error please
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160921/dc28fd3b/attachment.htm>

From jvdwesthuiz at shoprite.co.za  Wed Sep 21 13:53:36 2016
From: jvdwesthuiz at shoprite.co.za (Jasper Van Der Westhuizen)
Date: Wed, 21 Sep 2016 13:53:36 +0000
Subject: [squid-users] Squid 3.5.21 - High CPU (100%)
Message-ID: <1474466015.14617.153.camel@shoprite.co.za>

Hi all


In my environment I have two Squid clusters that comprise of 4 VM's each, load balanced over a F5 LB. I will refer to them as cluster A (client facing) and cluster B(edge proxies). Depending on the destination, the traffic is routed from cluster A via ISP 1 or to cluster B via ISP 2. I have been having some problems with Squid using 100% CPU at times which impacts my users browsing experience. This would happen on both clusters, even after upgrading to the latest 3.5.21 build.


I also recently saw the following errors in the cache logs:

2016/09/20 14:37:02 kid1| DiskThreadsDiskFile::openDone: (2) No such file or directory


After some reading up it looks like files were removed without Squid knowing about it. My cache director was on a EXT3 FS with journaling enabled. To try and address a possible disk access/speed issue I disabled journaling on the LV.

I have also done some optimizing from a OS point of view.


In order to get the CPU utilization down, a simple squid -k reconfigure will be enough. Not a full restart.


During the last time I had a proxy servers CPU reach 100% I ran a cachemgr export and below is an extract.


________________________________

________________________________



sample_start_time = 1474463096.261275 (Wed, 21 Sep 2016 13:04:56 GMT)
sample_end_time = 1474463396.382713 (Wed, 21 Sep 2016 13:09:56 GMT)
client_http.requests = 101.722157/sec
client_http.hits = 6.623985/sec
client_http.errors = 18.505842/sec
client_http.kbytes_in = 4718.936473/sec
client_http.kbytes_out = 4148.813921/sec
client_http.all_median_svc_time = 0.898576 seconds
client_http.miss_median_svc_time = 0.321543 seconds
client_http.nm_median_svc_time = 0.008653 seconds
client_http.nh_median_svc_time = 0.220042 seconds
client_http.hit_median_svc_time = 0.013867 seconds
server.all.requests = 78.671488/sec
server.all.errors = 0.000000/sec
server.all.kbytes_in = 7963.083264/sec
server.all.kbytes_out = 4704.282405/sec
server.http.requests = 31.533902/sec
server.http.errors = 0.000000/sec
server.http.kbytes_in = 4451.098225/sec
server.http.kbytes_out = 45.414950/sec
server.ftp.requests = 0.000000/sec
server.ftp.errors = 0.000000/sec
server.ftp.kbytes_in = 0.000000/sec
server.ftp.kbytes_out = 0.000000/sec
server.other.requests = 47.137586/sec
server.other.errors = 0.000000/sec
server.other.kbytes_in = 3511.981707/sec
server.other.kbytes_out = 4658.870787/sec
icp.pkts_sent = 0.000000/sec
icp.pkts_recv = 0.000000/sec
icp.queries_sent = 0.000000/sec
icp.replies_sent = 0.000000/sec
icp.queries_recv = 0.000000/sec
icp.replies_recv = 0.000000/sec
icp.replies_queued = 0.000000/sec
icp.query_timeouts = 0.000000/sec
icp.kbytes_sent = 0.000000/sec
icp.kbytes_recv = 0.000000/sec
icp.q_kbytes_sent = 0.000000/sec
icp.r_kbytes_sent = 0.000000/sec
icp.q_kbytes_recv = 0.000000/sec
icp.r_kbytes_recv = 0.000000/sec
icp.query_median_svc_time = 0.000000 seconds
icp.reply_median_svc_time = 0.000000 seconds
dns.median_svc_time = 0.002783 seconds
unlink.requests = 0.000000/sec
page_faults = 0.029988/sec
select_loops = 260.427914/sec
select_fds = 4391.065859/sec
average_select_fd_period = 0.000000/fd
median_select_fds = 1.000000
swap.outs = 6.204155/sec
swap.ins = 2.312397/sec
swap.files_cleaned = 0.000000/sec
aborted_requests = 2.962134/sec
syscalls.disk.opens = 8.253326/sec
syscalls.disk.closes = 16.216769/sec
syscalls.disk.reads = 24.953232/sec
syscalls.disk.writes = 998.445836/sec
syscalls.disk.seeks = 0.000000/sec
syscalls.disk.unlinks = 1.426089/sec
syscalls.sock.accepts = 74.449863/sec
syscalls.sock.sockets = 59.052763/sec
syscalls.sock.connects = 59.052763/sec
syscalls.sock.binds = 0.000000/sec
syscalls.sock.closes = 137.934165/sec
syscalls.sock.reads = 2467.637783/sec
syscalls.sock.writes = 1735.070988/sec
syscalls.sock.recvfroms = 24.050265/sec
syscalls.sock.sendtos = 14.464145/sec
cpu_time = 295.754484 seconds
wall_time = 300.121438 seconds
cpu_usage = 98.544938%


________________________________


Here is one some time later after running a suid -k reconfigure.


Cache Manager menu<http://critproxy4.shoprite.co.za/cgi-bin/cachemgr.cgi?host=localhost&port=8080&user_name=servicedesk at shoprite.co.za&operation=menu&auth=bG9jYWxob3N0fDE0NzQ0NjU5NDh8c2VydmljZWRlc2tAc2hvcHJpdGUuY28uemF8MTIzcXdlQVNE>

________________________________

________________________________



sample_start_time = 1474465618.601004 (Wed, 21 Sep 2016 13:46:58 GMT)
sample_end_time = 1474465918.604173 (Wed, 21 Sep 2016 13:51:58 GMT)
client_http.requests = 72.862564/sec
client_http.hits = 1.216654/sec
client_http.errors = 3.693294/sec
client_http.kbytes_in = 904.270448/sec
client_http.kbytes_out = 3676.207834/sec
client_http.all_median_svc_time = 0.649683 seconds
client_http.miss_median_svc_time = 0.177113 seconds
client_http.nm_median_svc_time = 0.000000 seconds
client_http.nh_median_svc_time = 0.034266 seconds
client_http.hit_median_svc_time = 0.009754 seconds
server.all.requests = 72.545900/sec
server.all.errors = 0.000000/sec
server.all.kbytes_in = 3668.624580/sec
server.all.kbytes_out = 892.610571/sec
server.http.requests = 32.159660/sec
server.http.errors = 0.000000/sec
server.http.kbytes_in = 503.211351/sec
server.http.kbytes_out = 43.506207/sec
server.ftp.requests = 0.000000/sec
server.ftp.errors = 0.000000/sec
server.ftp.kbytes_in = 0.000000/sec
server.ftp.kbytes_out = 0.000000/sec
server.other.requests = 40.386240/sec
server.other.errors = 0.000000/sec
server.other.kbytes_in = 3165.409896/sec
server.other.kbytes_out = 849.101031/sec
icp.pkts_sent = 0.000000/sec
icp.pkts_recv = 0.000000/sec
icp.queries_sent = 0.000000/sec
icp.replies_sent = 0.000000/sec
icp.queries_recv = 0.000000/sec
icp.replies_recv = 0.000000/sec
icp.replies_queued = 0.000000/sec
icp.query_timeouts = 0.000000/sec
icp.kbytes_sent = 0.000000/sec
icp.kbytes_recv = 0.000000/sec
icp.q_kbytes_sent = 0.000000/sec
icp.r_kbytes_sent = 0.000000/sec
icp.q_kbytes_recv = 0.000000/sec
icp.r_kbytes_recv = 0.000000/sec
icp.query_median_svc_time = 0.000000 seconds
icp.reply_median_svc_time = 0.000000 seconds
dns.median_svc_time = 0.000000 seconds
unlink.requests = 0.000000/sec
page_faults = 0.000000/sec
select_loops = 4294.267972/sec
select_fds = 3765.856887/sec
average_select_fd_period = 0.000000/fd
median_select_fds = 0.000000
swap.outs = 9.133237/sec
swap.ins = 2.816637/sec
swap.files_cleaned = 0.000000/sec
aborted_requests = 0.623327/sec
syscalls.disk.opens = 10.643221/sec
syscalls.disk.closes = 21.233109/sec
syscalls.disk.reads = 3.226633/sec
syscalls.disk.writes = 201.931200/sec
syscalls.disk.seeks = 0.000000/sec
syscalls.disk.unlinks = 0.433329/sec
syscalls.sock.accepts = 44.596196/sec
syscalls.sock.sockets = 49.176147/sec
syscalls.sock.connects = 49.176147/sec
syscalls.sock.binds = 49.176147/sec
syscalls.sock.closes = 93.635678/sec
syscalls.sock.reads = 1762.804712/sec
syscalls.sock.writes = 1817.204138/sec
syscalls.sock.recvfroms = 38.502927/sec
syscalls.sock.sendtos = 21.323108/sec
cpu_time = 59.151697 seconds
wall_time = 300.003169 seconds
cpu_usage = 19.717024%


________________________________


Compile options:
Squid Cache: Version 3.5.21
Service Name: squid
configure options:  '--prefix=/usr/local/squid3.5.21' '--sysconfdir=/etc/squid3.5.21' '--enable-follow-x-forwarded-for' '--with-logdir=/var/log/squid/' '-with-pidfile=/var/run/squid.pid' '--w
ith-swapdir=/var/cache/squid/' '--with-large-files' '--with-default-user=squid' '--with-included-ltdl' '--enable-snmp' '--enable-storeio=ufs,aufs' '--enable-removal-policies=lru,heap' '--enab
le-ltdl-convenience'



Any help or suggestions would be greatly appreciated.


--
Kind Regards
Jasper





Disclaimer:
http://www.shopriteholdings.co.za/Pages/ShopriteE-mailDisclaimer.aspx
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160921/87dc21b6/attachment.htm>

From rousskov at measurement-factory.com  Wed Sep 21 14:09:33 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 21 Sep 2016 08:09:33 -0600
Subject: [squid-users] Ignoring DNS Lookup errors in ACLs?
In-Reply-To: <20160921091314.adu7iyzmszuzvj3d@charite.de>
References: <20160921091314.adu7iyzmszuzvj3d@charite.de>
Message-ID: <e330fb4e-50bd-2629-5456-f16c596341a8@measurement-factory.com>

On 09/21/2016 03:13 AM, Ralf Hildebrandt wrote:
> Is there any way of making DNS Lookup errors in ACLs a warning only?

Only by modifying the code I am afraid. And we probably cannot do that
by default because it can be a security risk in some environments.

Alex.



From rousskov at measurement-factory.com  Wed Sep 21 14:34:33 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 21 Sep 2016 08:34:33 -0600
Subject: [squid-users] Squid 3.5.21 - High CPU (100%)
In-Reply-To: <1474466015.14617.153.camel@shoprite.co.za>
References: <1474466015.14617.153.camel@shoprite.co.za>
Message-ID: <d72ccfb0-8e9d-261b-d52f-3be082566d35@measurement-factory.com>

On 09/21/2016 07:53 AM, Jasper Van Der Westhuizen wrote:
> I have been having some problems with Squid using
> 100% CPU at times which impacts my users browsing experience. 

Sustained 100% CPU load at ~100/s rates with regular traffic on
reasonable hardware is a sign (albeit not a proof!) of a Squid bug
(including long searches and similar optimization problems).


> During the last time I had a proxy servers CPU reach 100% I ran a
> cachemgr export and below is an extract.

Next time this happens, consider getting a stack trace or two from the
process showing sustained 100% CPU utilization. It is possible to do
that without killing the processes (at least on Linux). I do not have
step-by-step instructions, but you can find them. Make sure you run (or
at least use for getting the stack trace?) an unstripped Squid binary,
preferably built with --disable-optimizations.

If the place where Squid gets stuck is known, somebody may volunteer to
fix the corresponding code.


Good luck,

Alex.



From robertocarna36 at gmail.com  Wed Sep 21 16:03:10 2016
From: robertocarna36 at gmail.com (Roberto Carna)
Date: Wed, 21 Sep 2016 13:03:10 -0300
Subject: [squid-users] Parameter to define quantity of clients in Proxy
	Reverse
Message-ID: <CAG2Qp6tMHJGQVNB5mBWtZD4w7MDEUJMus0WYBVWCLqTUygCq8Q@mail.gmail.com>

Dear, just a brief question:

I have Squid 3.4.8 on Debian running in reverse proxy mode, and I need
to know if there is any parameter in squid.conf that I have to adjust
in order to define the quantity of clients I will accept.

Or is the same if the squid receives 10 or 1.000.000 petitions at the
same time??? (My hardware is big enough, this is not my problem).

Special thanks,

Roberto


From Antony.Stone at squid.open.source.it  Wed Sep 21 17:34:10 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 21 Sep 2016 18:34:10 +0100
Subject: [squid-users] Parameter to define quantity of clients in Proxy
	Reverse
In-Reply-To: <CAG2Qp6tMHJGQVNB5mBWtZD4w7MDEUJMus0WYBVWCLqTUygCq8Q@mail.gmail.com>
References: <CAG2Qp6tMHJGQVNB5mBWtZD4w7MDEUJMus0WYBVWCLqTUygCq8Q@mail.gmail.com>
Message-ID: <201609211834.10944.Antony.Stone@squid.open.source.it>

On Wednesday 21 Sep 2016 at 17:03, Roberto Carna wrote:

> Dear, just a brief question:
> 
> I have Squid 3.4.8 on Debian running in reverse proxy mode, and I need
> to know if there is any parameter in squid.conf that I have to adjust
> in order to define the quantity of clients I will accept.

No.

> Or is the same if the squid receives 10 or 1.000.000 petitions at the
> same time??? (My hardware is big enough, this is not my problem).

Squid will handle as many simulataneous connections as your hardware, 
operating system, and network connection can support.

It's just the same as your web server - it'll handle as many connection 
requests as it can; there's nothing to configure to specify how many to 
accept.


Antony.

-- 
There are two possible outcomes:

 If the result confirms the hypothesis, then you've made a measurement.
 If the result is contrary to the hypothesis, then you've made a discovery.

 - Enrico Fermi

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Wed Sep 21 17:44:57 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 22 Sep 2016 05:44:57 +1200
Subject: [squid-users] Parameter to define quantity of clients in Proxy
 Reverse
In-Reply-To: <201609211834.10944.Antony.Stone@squid.open.source.it>
References: <CAG2Qp6tMHJGQVNB5mBWtZD4w7MDEUJMus0WYBVWCLqTUygCq8Q@mail.gmail.com>
 <201609211834.10944.Antony.Stone@squid.open.source.it>
Message-ID: <da2d561f-8477-4a84-8deb-2b00c513398f@treenet.co.nz>

On 22/09/2016 5:34 a.m., Antony Stone wrote:
> On Wednesday 21 Sep 2016 at 17:03, Roberto Carna wrote:
> 
>> Dear, just a brief question:
>>
>> I have Squid 3.4.8 on Debian running in reverse proxy mode, and I need
>> to know if there is any parameter in squid.conf that I have to adjust
>> in order to define the quantity of clients I will accept.
> 
> No.
> 
>> Or is the same if the squid receives 10 or 1.000.000 petitions at the
>> same time??? (My hardware is big enough, this is not my problem).
> 
> Squid will handle as many simulataneous connections as your hardware, 
> operating system, and network connection can support.
> 
> It's just the same as your web server - it'll handle as many connection 
> requests as it can; there's nothing to configure to specify how many to 
> accept.
> 

True. Though sometimes the operating system FD limits need to be
increased. This is usually the case for reverse-proxy setups that are
expecting large volumes of traffic.
<http://wiki.squid-cache.org/SquidFaq/TroubleShooting#Running_out_of_filedescriptors>

Amos



From squid3 at treenet.co.nz  Wed Sep 21 17:55:34 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 22 Sep 2016 05:55:34 +1200
Subject: [squid-users] Fwd: Squid ssl bumping. Ssl bumping not working
 on sites with ssl GOST cypher certificate
In-Reply-To: <CAKodO4VLa8oqbND6Xbkjqg23U9cyrtVVv32hxVieoAcb77N_Og@mail.gmail.com>
References: <CAKodO4Uy2xNnGSkgdP+Aqz1rOrO4f9LjqfUE9bjX7Hm6DQvj2Q@mail.gmail.com>
 <CAKodO4VLa8oqbND6Xbkjqg23U9cyrtVVv32hxVieoAcb77N_Og@mail.gmail.com>
Message-ID: <111a0384-2287-170b-79fd-5abe93cc48da@treenet.co.nz>

On 22/09/2016 1:41 a.m., ?????? ????????? wrote:
> Hi, can you please explain me, does squid support ssl bumping with site
> signed with GOST certificate?
> 

The crypto details in squid.conf are almost always passed directly to
the crypto library. So Squid supports what the library does. I don't
know enough about the GOST ciphers to know if there is anything unusual
needed from Squid.


> I have OpenSSL 1.0.2d 9 Jul 2015
> 
> openssl engine
> (dynamic) Dynamic engine loading support
> *(gost) Reference implementation of GOST engine*
> 

That would indicate the answer is yes, unless something unusual is needed.

> 
> *openssl ciphers | grep GOST*
> 
> *GOST2001-GOST89-GOST89:GOST94-GOST89-GOST89*
> 
> /opt/squid/sbin/squid -v
> Squid Cache: Version 3.5.19
> Service Name: squid
> configure options:  'CFLAGS=-march=i686 -g -O2' 'CXXFLAGS=-march=i686 -g
> -O2' '--prefix=/opt/squid-3.5.19-4' '--enable-async-io=32'
> '--enable-storeio=ufs,aufs,rock,diskd' '--enable-disk-io'
> '--enable-removal-policies=heap,lru' '--enable-useragent-log'
> '--enable-referer-log' '--enable-arp-acl' '--with-openssl'
> '--enable-forw-via-db' '--enable-cache-digests' '--enable-linux-netfilter'
> '--enable-basic-auth=all' '--enable-ntlm-auth=all'
> '--enable-ntlm-fail-open' '--enable-negotiate-auth=all'
> '--enable-external-acl-helpers' '--with-filedescriptors=32768'
> '--with-large-files' '--enable-delay-pools' '--enable-ssl-crtd'
> '--disable-static' '--with-logdir=/var/log/squid'
> '--with-pidfile=/var/run/squid.pid'
> '--with-swapdir=/var/data/squid/cache' '--disable-arch-native'
> 
> SSL bumping with dynamic certificates working well but when I try to go to
> site with GOST certificate,
> I see error -
> 
> The system returned:
> 
> (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
> 
> Handshake with SSL server failed: error:0609E09C:digital envelope
> routines:PKEY_SET_TYPE:unsupported algorithm
> 
> 
> Please explain me this Error please
> 

The error is produced by OpenSSL. It means one endpoint of the
Squid<->server connection has a crypto library that does not support one
of the cipher algorithms the other endpoint is requiring.

This is different from simply not being able to agree on a matching set
of ciphers to use. One of the ciphers is actively non-supported for the
use to which it is being attempted.

It could be the cipher (server not supporting GOST?), a checksum hash
(RC4, DES, SHA1 are frequently forbidden these days), or something else.

NP: That is the limit of what I know about this error sorry. Good luck
finding a fix.

Amos



From squid3 at treenet.co.nz  Wed Sep 21 18:44:00 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 22 Sep 2016 06:44:00 +1200
Subject: [squid-users] Squid for proxy server on Google Compute Engine?
In-Reply-To: <3C50F975-A0CF-4A3F-80C4-90DA6CD5DF72@gmail.com>
References: <3C50F975-A0CF-4A3F-80C4-90DA6CD5DF72@gmail.com>
Message-ID: <fdf91d22-e461-4138-9b97-6efee488531d@treenet.co.nz>

On 21/09/2016 4:09 p.m., Chuong Hoang wrote:
> Hi guys, thanks for reading this! I?m new so sorry if this is a dumb
> question! But I've been finding the answer for 3 days but still no
> sign of light.
> 
> I?ve already posted the problem on GCE discussion group- this link:
> https://groups.google.com/forum/#!topic/gce-discussion/xwlHYhFTUtU
> 
> To make it clear, I also restate the problem here: Been working on
> this for 2 days and still cannot find the way out :(
> 
> Below is my setup for testing, which basically supports all
> http_access through port 8888
> 
> -squid.conf file:
> 
> http_port 8888 http_access allow all -Open port 8888 for incoming
> HTTP data by gcloud command (which returned "allowed")

What other rules do you have in your squid.conf file?

How are these two lines placed in relation to all the others that should
be there? Order is important.

> 
> gcloud compute firewall-rules create allow-tcp --description
> "Incoming-http-allowed." --allow tcp:8888 --format json With the
> setup above, I can telnet to the IP with port 8888. However, when
> querying to some http links with browser (Safari/Chrome), I always
> get this message
> 
> The following error was encountered while trying to retrieve the URL:
> http://google.com/ <http://google.com/>
> 
> Access Denied.
> 
> Access control configuration prevents your request from being allowed
> at this time. Please contact your service provider if you feel this
> is incorrect.
> 
> Your cache administrator is webmaster. I also tried other ports
> (3128, 8000, 80) but no help I also tried to force the port to listen
> IPv4 addresses with something like http_port 0.0.0.0:8888
> <http://0.0.0.0:8888/> and still not working Someone please help me
> out of this mess :( Much appreciated!
> 
> P/S: I connect to the squid proxy though my Macbook (OS Sierra) with
> Web Proxy (HTTP) enabled in Network Preferences.
> 
> This is some logs from cache.log, which probably indicates that my
> conf file is fraud. client_side.cc(777) swanSong:
> local=10.xxx.0.2:8888 remote=113.xxx.xxx.113:54856 flags=1 -
> 10.xxx.0.2 is GCE's internal IP - 113.xxx.xxx.113 is my computer's
> external IP

The log line shows correct IPs for the client connection - remote being
the client IP and local the Squid machines IP.


Amos


From chip_pop at hotmail.com  Wed Sep 21 20:46:49 2016
From: chip_pop at hotmail.com (joe)
Date: Wed, 21 Sep 2016 13:46:49 -0700 (PDT)
Subject: [squid-users] libevent
Message-ID: <1474490809121-4679637.post@n4.nabble.com>

is there a support for libevent in squid ???



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/libevent-tp4679637.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Wed Sep 21 21:01:49 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 22 Sep 2016 03:01:49 +0600
Subject: [squid-users] libevent
In-Reply-To: <1474490809121-4679637.post@n4.nabble.com>
References: <1474490809121-4679637.post@n4.nabble.com>
Message-ID: <9fd498da-19d6-9552-bfb3-b0b569e1d96e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Joined.


22.09.2016 2:46, joe ?????:
> is there a support for libevent in squid ???
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/libevent-tp4679637.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX4vU9AAoJENNXIZxhPexGhWoH/jg9C8MvbZn6Kxb6NJA6pCeX
eDTDpwxXsfUDip1NA+XWnMMG46dQFTyd2NBiBjx/XEyUimnThG2Csg91bgTi0QXJ
UFlQ/8SeYGB+iSh95UpwPL05peifqYh3kMPSnihCpmdWtIirabiG4E1o9gQt+qL0
A9xnkzgiTQrps3pq/u9/8HRGFd7axcAjgJcHoAeizdrB8G4hL48ds09qMbkWpwLh
9PpSp7vWgbQwBDeJy2Kz3sgKPPWOz1OAZKkLar8PjekT+dz1lJ2swdgUn7kk9Zhs
GKiXRIoqVJq9tK9HJTYrNr3gqSO1brb6gCF8727O3seB3S9rGRWFA7pR8CsKKMQ=
=PiRT
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160922/1c9776aa/attachment.key>

From chip_pop at hotmail.com  Wed Sep 21 21:01:35 2016
From: chip_pop at hotmail.com (joe)
Date: Wed, 21 Sep 2016 14:01:35 -0700 (PDT)
Subject: [squid-users] libevent
In-Reply-To: <9fd498da-19d6-9552-bfb3-b0b569e1d96e@gmail.com>
References: <1474490809121-4679637.post@n4.nabble.com>
 <9fd498da-19d6-9552-bfb3-b0b569e1d96e@gmail.com>
Message-ID: <1474491695435-4679639.post@n4.nabble.com>

almost most of  internet app like dns and other  cache using it  its the
futur so why not squid  it perform beter stability and speed



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/libevent-tp4679637p4679639.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Wed Sep 21 21:23:14 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 21 Sep 2016 14:23:14 -0700 (PDT)
Subject: [squid-users] SSO (kerberos)
In-Reply-To: <1474390256210-4679618.post@n4.nabble.com>
References: <1473702058647-4679470.post@n4.nabble.com>
 <6bbebad5-7712-9b39-2510-8fcb7ece641b@treenet.co.nz>
 <1473780876101-4679484.post@n4.nabble.com>
 <ddc7ffa7-9858-710a-b8e0-6848106168bb@treenet.co.nz>
 <1473791599383-4679490.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73FC133@CLWSEXCMBX02.na.bicworld.com>
 <1473965736706-4679540.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73FCF2C@CLWSEXCMBX02.na.bicworld.com>
 <1473969879489-4679542.post@n4.nabble.com>
 <1474390256210-4679618.post@n4.nabble.com>
Message-ID: <1474492994109-4679640.post@n4.nabble.com>

Hi.
Kerberos authentication is working now .

This is my config

###Kerberos Auth with ActiveDirectory###############
auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -d -s
HTTP/squid.example.lan at EXAMPLE.LAN
auth_param negotiate children 10
auth_param negotiate keep_alive on

acl auth proxy_auth REQUIRED
http_access allow all auth

But, i want check the group of an authenticated users so i can apply acl to
them, etc.

What would be the syntax I could use ??

Thanks!!!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SSO-kerberos-tp4679470p4679640.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Wed Sep 21 21:52:28 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 21 Sep 2016 15:52:28 -0600
Subject: [squid-users] libevent
In-Reply-To: <1474491695435-4679639.post@n4.nabble.com>
References: <1474490809121-4679637.post@n4.nabble.com>
 <9fd498da-19d6-9552-bfb3-b0b569e1d96e@gmail.com>
 <1474491695435-4679639.post@n4.nabble.com>
Message-ID: <674a291e-da47-20ab-2a30-f01274fa6bfb@measurement-factory.com>

On 09/21/2016 03:01 PM, joe wrote:
> almost most of  internet app like dns and other  cache using it  its the
> futur so why not squid

because nobody added libevent support to Squid.


> it perform beter stability and speed

Better than what? And what makes you think that?

Most Squid performance and stability problems are not related to the
code that libevent can replace...

Alex.



From yvoinov at gmail.com  Wed Sep 21 21:54:33 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 22 Sep 2016 03:54:33 +0600
Subject: [squid-users] libevent
In-Reply-To: <674a291e-da47-20ab-2a30-f01274fa6bfb@measurement-factory.com>
References: <1474490809121-4679637.post@n4.nabble.com>
 <9fd498da-19d6-9552-bfb3-b0b569e1d96e@gmail.com>
 <1474491695435-4679639.post@n4.nabble.com>
 <674a291e-da47-20ab-2a30-f01274fa6bfb@measurement-factory.com>
Message-ID: <8222e54d-b4d1-af9e-f46d-13d5ff3eca46@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


22.09.2016 3:52, Alex Rousskov ?????:
> On 09/21/2016 03:01 PM, joe wrote:
>> almost most of  internet app like dns and other  cache using it  its the
>> futur so why not squid
>
> because nobody added libevent support to Squid.
.... including devs.......
>
>
>
>> it perform beter stability and speed
>
> Better than what? And what makes you think that?
>
> Most Squid performance and stability problems are not related to the
> code that libevent can replace...
Yes, the problems stem from the hands. Certainly. Not from libraries.
>
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX4wGZAAoJENNXIZxhPexGH7QH/1eDWC8GaX2j0A20eTRRVFiU
dGn7yeM/bc5zKQOLKXNDlIEgN8D9uy/YGSyHUt7fBe9nPZCj+antYUi09sPyvrEz
yDoRaDI6NJoObjzAbmlcxI3eF4TrAIp6NffpFJheLsTtL7sNIv2yUygOmKTkV/ka
afcN+DyfHnCmeuzasfXG+lPakA73Npq9fdJb2gxoz+hONhsdAODnnCkLuEW06Dqr
Ej6eWWFKIaRrf2cOOGSy0mdbN5mksU6u8z80dg5BCVMmB6rSdolzjYoMRjRlXMNr
5RdEwkM9P8tJCIQ5KTBvzKLkXyuM6tHe81y4F3yNpOd5dDu8AQqDBQTOuzzS4Bo=
=urzw
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160922/354e964d/attachment.key>

From yvoinov at gmail.com  Wed Sep 21 22:00:22 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 22 Sep 2016 04:00:22 +0600
Subject: [squid-users] libevent
In-Reply-To: <8222e54d-b4d1-af9e-f46d-13d5ff3eca46@gmail.com>
References: <1474490809121-4679637.post@n4.nabble.com>
 <9fd498da-19d6-9552-bfb3-b0b569e1d96e@gmail.com>
 <1474491695435-4679639.post@n4.nabble.com>
 <674a291e-da47-20ab-2a30-f01274fa6bfb@measurement-factory.com>
 <8222e54d-b4d1-af9e-f46d-13d5ff3eca46@gmail.com>
Message-ID: <e44c6ba4-d453-f636-3b19-e7c9265a713e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
You are too few in number to provide something decent enough, and not
from the last century.

So, business as usual.

22.09.2016 3:54, Yuri Voinov ?????:
>
>
>
> 22.09.2016 3:52, Alex Rousskov ?????:
> > On 09/21/2016 03:01 PM, joe wrote:
> >> almost most of  internet app like dns and other  cache using it 
its the
> >> futur so why not squid
>
> > because nobody added libevent support to Squid.
> .... including devs.......
>
>
>
> >> it perform beter stability and speed
>
> > Better than what? And what makes you think that?
>
> > Most Squid performance and stability problems are not related to the
> > code that libevent can replace...
> Yes, the problems stem from the hands. Certainly. Not from libraries.
>
>
> > Alex.
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org
> > http://lists.squid-cache.org/listinfo/squid-users
>
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX4wL1AAoJENNXIZxhPexGeMsH/2/4pC1J3Pmopw8gb5KJ8Fqb
r+1k6NyPYwxhgnqIYUK/bHlmfUsg4POS0r28pr+9BLX70ahuL4qAiJubCP2YxQM5
Gzl4O3h/N1eb6PgQsrWezV4yTQcluELY62WLhHUiBSQ6+patCGFygXgUDsmXlIWZ
mdHzknxFS3Ox2QoBYgCPT9U9xzKwZawP+Olo/TraiwqcKRbTa8RA79KQnO7dPkNR
8eXw6QJFV2ohG+cT2dPDTLgtJoNPqNqdTmsct9P0lFUGe8FYtzSm4kNakzVEsT5j
uOw405FWjULfHVZcocuEnWsSUz6mqBHhpXxKknSSoloSKKeV1lxhIIH506B3ZXY=
=w+47
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160922/3d31af77/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160922/3d31af77/attachment.key>

From bycn82 at gmail.com  Thu Sep 22 04:29:47 2016
From: bycn82 at gmail.com (Bill Yuan)
Date: Thu, 22 Sep 2016 12:29:47 +0800
Subject: [squid-users] Question about the url rewrite before proxy out
Message-ID: <CAC+JH2w=9Bk2jh-MM-WG-UWbOcyXKSL8rrKNiKPGtgHw7u9tcw@mail.gmail.com>

?Hello,

i am looking for a proxy which can "bounce" the request, which is not a
classic proxy.

I want it works in this way.
e.g. a proxy is running a 192.168.1.1
and when i want to open www.yahoo.com, i just need call
http://192.168.1.1/www.yahoo.com
the proxy can pickup the the host "www.yahoo.com" from the URI, and
retrieve the info for me?,

so it need to get the new $host from $location, and remove the $host from
the $location before proxy pass it.

it is doable via squid?

Regards
Bill
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160922/751fa78f/attachment.htm>

From squid-users at filter.luko.org  Thu Sep 22 05:04:58 2016
From: squid-users at filter.luko.org (squid-users at filter.luko.org)
Date: Thu, 22 Sep 2016 15:04:58 +1000
Subject: [squid-users] Question about the url rewrite before proxy out
In-Reply-To: <CAC+JH2w=9Bk2jh-MM-WG-UWbOcyXKSL8rrKNiKPGtgHw7u9tcw@mail.gmail.com>
References: <CAC+JH2w=9Bk2jh-MM-WG-UWbOcyXKSL8rrKNiKPGtgHw7u9tcw@mail.gmail.com>
Message-ID: <003401d2148e$ddabc8a0$990359e0$@filter.luko.org>

> i am looking for a proxy which can "bounce" the request, which is not a classic proxy.
>
> I want it works in this way.
> 
> e.g. a proxy is running a 192.168.1.1 
> and when i want to open http://www.yahoo.com, i just need call http://192.168.1.1/www.yahoo.com
> the proxy can pickup the the host "http://www.yahoo.com" from the URI, and retrieve the info for me?, 
> so it need to get the new $host from $location, and remove the $host from the $location before proxy pass it.
> it is doable via squid?

Yes it is doable (but unusual).  First you need to tell Squid which requests should be rewritten, then send them to a rewrite program to be transformed.  Identify the domains like this:

acl rewrite-domains dstdomain .yahoo.com .google.com etc)

Then set up a URL rewriting program, and only allow it to process requests matching the rewrite-domains ACL, like this:

url_rewrite_program /tmp/rewrite-program.pl
url_rewrite_extras "%>ru"
url_rewrite_access allow rewrite-domains
url_rewrite_access deny all

The program itself can be anything.  A very simple example in Perl might look like this:

#!/usr/bin/perl
use strict;
$| = 1;

# Enter loop
while (my $thisline = <>) {
	my @parts = split(/\s+/, $thisline);
	my $url = $parts[0];
	$url =~ s/http:\/\/(.*)/http:\/\/192.168.1.1\/$1/g;
	print "OK rewrite-url=\"$url\"\n";
}

If you input http://www.yahoo.com/page.html, this will be transformed to http://192.168.1.1/www.google.com/page.html.  The helper just needs to print that out prepended by "OK rewrite-url=xxx".  More info at http://www.squid-cache.org/Doc/config/url_rewrite_program/

Of course, you will need something listening on 192.168.1.1 (Apache, nginx, whatever) that can deal with those rewritten requests.  That is an unusual way of getting requests to 192.168.1.1 though, because you are effectively putting the hostname component into the URL then sending it to a web service and expecting it to deal with that.

Another note.  If you have a cache_peer defined, you might need some config to force rewritten requests to be sent to 192.168.1.1 and not your cache peer.  In that case this should do the trick:

acl rewrite-host dst 192.168.1.1
always_direct allow rewrite-host

HtH.

Luke




From drikus at geocastsp.co.za  Thu Sep 22 05:47:45 2016
From: drikus at geocastsp.co.za (Drikus Brits)
Date: Thu, 22 Sep 2016 07:47:45 +0200
Subject: [squid-users] multiple instances with different outgoing addresses
 and 2x external nics
Message-ID: <1e6798ede0caaf479338bbd2667e37f1@geocastsp.co.za>

 

HI Experts, 

I'm struggling to get squid to work the way i need it to. 

My setup : 

1x Server : Ubuntu 14
3x Interfaces : 1x Inside ( 192.168.100.10 ) 2x Outside connected to DSL
(1st = 10.0.0.2, 2nd 10.0.1.2)
2x default routes : 1x for each DSL link 

Management uses proxy address : 192.168.100.10 3128
All else uses address : 192.168.100.10 3129 

Both instances have their own configuration file and squid starts both
instances without issues. the mngt instance is configured to use
tcp_outgoing_address : 10.0.0.2 and all_else instance configured to use
tcp_outgoing_address : 10.0.1.2, but when i test a website that reveals
your outside IP, it always seems to only go out via the 1 DSL network
and not the other. 

If i remove the default route to DSL1, then both instances works via
DSL2. My thoughts was that if the outgoing_address is 10.0.0.2 it should
go out via DSL1 and if outgoing_address is 10.0.1.2 it should go via
DSL2. 

If it try to use an outgoing address that is not the IP of the
configured eth interface, then it complains about binding issues. 

I'm not using any firewalls of sorts to manipulate routing at this
stage. I really would prefer to use 1x VM (squid) instead of 2 seperate
VMs running squid... 

Any suggestions? 

Thanks 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160922/964bc1cb/attachment.htm>

From Antony.Stone at squid.open.source.it  Thu Sep 22 08:51:37 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 22 Sep 2016 09:51:37 +0100
Subject: [squid-users] multiple instances with different outgoing
	addresses and 2x external nics
In-Reply-To: <1e6798ede0caaf479338bbd2667e37f1@geocastsp.co.za>
References: <1e6798ede0caaf479338bbd2667e37f1@geocastsp.co.za>
Message-ID: <201609220951.38025.Antony.Stone@squid.open.source.it>

On Thursday 22 Sep 2016 at 06:47, Drikus Brits wrote:

> HI Experts,
> 
> I'm struggling to get squid to work the way i need it to.
> 
> My setup :
> 
> 1x Server : Ubuntu 14
> 3x Interfaces : 1x Inside ( 192.168.100.10 ) 2x Outside connected to DSL
> (1st = 10.0.0.2, 2nd 10.0.1.2)
> 2x default routes : 1x for each DSL link

Have you configured IProute2 or similar to use both "default" routes?

If not, and you have simply told the Linux kernel that there are two default 
routes, it will only use the first one.

> Management uses proxy address : 192.168.100.10 3128
> All else uses address : 192.168.100.10 3129
> 
> Both instances have their own configuration file and squid starts both
> instances without issues. the mngt instance is configured to use
> tcp_outgoing_address : 10.0.0.2 and all_else instance configured to use
> tcp_outgoing_address : 10.0.1.2, but when i test a website that reveals
> your outside IP, it always seems to only go out via the 1 DSL network
> and not the other.

If you have simply told the Linux kernel that there are two default routes, it 
will only use the first one.

> If i remove the default route to DSL1, then both instances works via
> DSL2. My thoughts was that if the outgoing_address is 10.0.0.2 it should
> go out via DSL1 and if outgoing_address is 10.0.1.2 it should go via
> DSL2.

Sounds very much like you need to configure IProute2 to use both paths.  Look 
up LARTC for documentation.

> If it try to use an outgoing address that is not the IP of the
> configured eth interface, then it complains about binding issues.

Well, yes.

> I'm not using any firewalls of sorts to manipulate routing at this
> stage. I really would prefer to use 1x VM (squid) instead of 2 seperate
> VMs running squid...
> 
> Any suggestions?

See above :)


Antony.

-- 
"The future is already here.   It's just not evenly distributed yet."

 - William Gibson

                                                   Please reply to the list;
                                                         please *don't* CC me.


From Antony.Stone at squid.open.source.it  Thu Sep 22 08:56:29 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 22 Sep 2016 09:56:29 +0100
Subject: [squid-users] Question about the url rewrite before proxy out
In-Reply-To: <003401d2148e$ddabc8a0$990359e0$@filter.luko.org>
References: <CAC+JH2w=9Bk2jh-MM-WG-UWbOcyXKSL8rrKNiKPGtgHw7u9tcw@mail.gmail.com>
 <003401d2148e$ddabc8a0$990359e0$@filter.luko.org>
Message-ID: <201609220956.29355.Antony.Stone@squid.open.source.it>

On Thursday 22 Sep 2016 at 06:04, squid-users at filter.luko.org wrote:

> > i am looking for a proxy which can "bounce" the request, which is not a
> > classic proxy.
> > 
> > I want it works in this way.
> > 
> > e.g. a proxy is running a 192.168.1.1
> > and when i want to open http://www.yahoo.com, i just need call
> > http://192.168.1.1/www.yahoo.com the proxy can pickup the the host
> > "http://www.yahoo.com" from the URI, and retrieve the info for me?, so
> > it need to get the new $host from $location, and remove the $host from
> > the $location before proxy pass it. it is doable via squid?
> 
> Yes it is doable (but unusual).  First you need to tell Squid which requests
> should be rewritten, then send them to a rewrite program to be transformed. 
> Identify the domains like this:

<detail snipped>

> If you input http://www.yahoo.com/page.html, this will be transformed to
> http://192.168.1.1/www.google.com/page.html.

I got the impression that the OP wanted the rewrite to work the other way 
around.

Squid sees http://192.168.1.1/www.google.com and  re-writes it to 
http://www.google.com

> The helper just needs to print that out prepended by "OK rewrite-url=xxx". 
> More info at http://www.squid-cache.org/Doc/config/url_rewrite_program/
> 
> Of course, you will need something listening on 192.168.1.1 (Apache, nginx,
> whatever) that can deal with those rewritten requests.

I got the impression that the OP wanted Squid to be listening on this address, 
doing the rewrites, and then fetching from standard origin servers.

> That is an unusual way of getting requests to 192.168.1.1 though, because
> you are effectively putting the hostname component into the URL then sending
> it to a web service and expecting it to deal with that.

Yes, that's what the OP wants Squid to handle, I think.


Antony.

-- 
"640 kilobytes (of RAM) should be enough for anybody."

 - Bill Gates

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid-users at filter.luko.org  Thu Sep 22 10:20:01 2016
From: squid-users at filter.luko.org (squid-users at filter.luko.org)
Date: Thu, 22 Sep 2016 20:20:01 +1000
Subject: [squid-users] Question about the url rewrite before proxy out
In-Reply-To: <201609220956.29355.Antony.Stone@squid.open.source.it>
References: <CAC+JH2w=9Bk2jh-MM-WG-UWbOcyXKSL8rrKNiKPGtgHw7u9tcw@mail.gmail.com>
 <003401d2148e$ddabc8a0$990359e0$@filter.luko.org>
 <201609220956.29355.Antony.Stone@squid.open.source.it>
Message-ID: <008901d214ba$e0adba00$a2092e00$@filter.luko.org>

> <detail snipped>
> 
> > If you input http://www.yahoo.com/page.html, this will be transformed
> > to http://192.168.1.1/www.google.com/page.html.
> 
> I got the impression that the OP wanted the rewrite to work the other way
> around.

My apologies, that does seem to be the case.

> Squid sees http://192.168.1.1/www.google.com and  re-writes it to
> http://www.google.com
> 
> > The helper just needs to print that out prepended by "OK rewrite-
> url=xxx".
> > More info at
> > http://www.squid-cache.org/Doc/config/url_rewrite_program/
> >
> > Of course, you will need something listening on 192.168.1.1 (Apache,
> > nginx,
> > whatever) that can deal with those rewritten requests.
> 
> I got the impression that the OP wanted Squid to be listening on this
> address, doing the rewrites, and then fetching from standard origin
> servers.

Then not only the request needs to be rewritten, but probably the page content too.  Eg, assets in the page will all be pointing at http://www.yahoo.com/image.png and also need transforming to http://192.168.1.1/www.yahoo.com/image.png.

If that is the case, then Squid doesn't seem like the right tool for the job.  I think CGIproxy can do this (https://www.jmarshall.com/tools/cgiproxy/) or perhaps Apache's mod_proxy (https://httpd.apache.org/docs/current/mod/mod_proxy.html) would work.

Luke




From rousskov at measurement-factory.com  Thu Sep 22 14:56:29 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 22 Sep 2016 08:56:29 -0600
Subject: [squid-users] Question about the url rewrite before proxy out
In-Reply-To: <008901d214ba$e0adba00$a2092e00$@filter.luko.org>
References: <CAC+JH2w=9Bk2jh-MM-WG-UWbOcyXKSL8rrKNiKPGtgHw7u9tcw@mail.gmail.com>
 <003401d2148e$ddabc8a0$990359e0$@filter.luko.org>
 <201609220956.29355.Antony.Stone@squid.open.source.it>
 <008901d214ba$e0adba00$a2092e00$@filter.luko.org>
Message-ID: <eab797dc-9221-c7d3-5b61-4a1b98c40850@measurement-factory.com>

On 09/22/2016 04:20 AM, squid-users at filter.luko.org wrote:

> Then not only the request needs to be rewritten, but probably the 
> page content too. [...] If that is the case,
> then Squid doesn't seem like the right tool for the job.

Why not? If rewriting is needed, an ICAP or eCAP service can rewrite the
response body before Squid serves it.

However, in practice, this kind of page rewriting does not work very
well (regardless of which software is doing the rewrite) because many
page URLs are formed dynamically on the client side (by Javascript code).

Alex.



From erdosain9 at gmail.com  Thu Sep 22 18:11:02 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 22 Sep 2016 11:11:02 -0700 (PDT)
Subject: [squid-users] Errors in cache.log
Message-ID: <1474567862731-4679651.post@n4.nabble.com>

Hi.
Im having this message in cache.log

 Error negotiating SSL on FD 121: error:00000000:lib(0):func(0):reason(0)
(5/0/0)
2016/09/22 14:20:36 kid1| BUG: Unexpected state while connecting to a
cache_peer or origin server
2016/09/22 14:29:23 kid1| Error negotiating SSL connection on FD 33:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
2016/09/22 14:29:24 kid1| Error negotiating SSL connection on FD 33:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
2016/09/22 14:32:02 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://r3---sn-q4f7sn7l.googlevideo.com/videoplayback?pl=21&itag=242&dur=3973.160&source=youtube&keepalive=yes&expire=1474585097&mime=video%2Fwebm&signature=14F5607A717C8A9DD579A55C69F6CDF4C2308FC5.47CE0A2B9F54F2C8C4042FF7797A08708951C276&clen=12532131&gir=yes&key=cms1&ip=190.113.224.106&ipbits=0&id=o-ABdgV3GldzFU1c8jBp6s_27abh9g_9c3hA0dbUgDkgjM&upn=4Xlvne-1RrE&lmt=1449585312748326&sparams=clen,dur,ei,expire,gir,id,initcwndbps,ip,ipbits,itag,keepalive,lmt,mime,mm,mn,ms,mv,nh,pl,requiressl,source,upn&ei=qQ3kV7rtJNT0wQTR0I_oDg&requiressl=yes&cpn=jdZ-1Vthefy2q9Og&alr=yes&ratebypass=yes&c=WEB&cver=1.20160921&redirect_counter=1&req_id=ad722d06312b3cfc&cms_redirect=yes&mm=34&mn=sn-q4f7sn7l&ms=ltu&mt=1474563648&mv=m&nh=IgpwcjAyLmV6ZTAxKgkxMjcuMC4wLjE&range=8224151-8353222&rn=840&rbuf=585667
AKA
r3---sn-q4f7sn7l.googlevideo.com/videoplayback?pl=21&itag=242&dur=3973.160&source=youtube&keepalive=yes&expire=1474585097&mime=video%2Fwebm&signature=14F5607A717C8A9DD579A55C69F6CDF4C2308FC5.47CE0A2B9F54F2C8C4042FF7797A08708951C276&clen=12532131&gir=yes&key=cms1&ip=190.113.224.106&ipbits=0&id=o-ABdgV3GldzFU1c8jBp6s_27abh9g_9c3hA0dbUgDkgjM&upn=4Xlvne-1RrE&lmt=1449585312748326&sparams=clen,dur,ei,expire,gir,id,initcwndbps,ip,ipbits,itag,keepalive,lmt,mime,mm,mn,ms,mv,nh,pl,requiressl,source,upn&ei=qQ3kV7rtJNT0wQTR0I_oDg&requiressl=yes&cpn=jdZ-1Vthefy2q9Og&alr=yes&ratebypass=yes&c=WEB&cver=1.20160921&redirect_counter=1&req_id=ad722d06312b3cfc&cms_redirect=yes&mm=34&mn=sn-q4f7sn7l&ms=ltu&mt=1474563648&mv=m&nh=IgpwcjAyLmV6ZTAxKgkxMjcuMC4wLjE&range=8224151-8353222&rn=840&rbuf=585667
Error negotiating SSL on FD 91: error:00000000:lib(0):func(0):reason(0)
(5/-1/104)



Sometimes in webbrowser give something like bad CA

or this (IPV6??)

The following error was encountered while trying to retrieve the URL:
https://www.facebook.com/*

Connection to 2a03:2880:f105:83:face:b00c:0:25de failed.

The system returned: (101) Network is unreachable

The remote host or network may be down. Please try the request again.

Your cache administrator is webmaster.

This is my config

#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
#acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
#acl localnet src 172.16.0.0/12	# RFC1918 possible internal network
#acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
#IPV6 Deshabilitado
#acl localnet src fc00::/7       # RFC 4193 local private network range
#acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines
#acl lan1_network src 192.168.1.0/24 ###Red 1 completa (no esta allowed)
#acl adminsquid src 192.168.1.172 #Administrar squid

#allways_direct allow lan1_network

####GRUPOS DE IP
acl full src "/etc/squid/ips/full.lst"
acl limitado src "/etc/squid/ips/limitado.lst"
acl sistemas src "/etc/squid/ips/sistemas.lst"
acl adminis  src "/etc/squid/ips/adminis.lst"


#Sitios monitorizados
#acl monitoredSites ssl::server_name "/etc/squid/listas/monitorizados.lst"
 

####Bloquea Publicidad ( http://pgl.yoyo.org/adservers/ )
acl ads dstdom_regex "/etc/squid/listas/ad_block.lst"
http_access deny ads
#deny_info TCP_RESET ads

####Streaming
#acl youtube dstdomain .googlevideo.com
#acl youtube dstdomain .fbcdn.net
#acl youtube dstdomain .akamaihd.net
acl stream url_regex -i \.flv$
acl stream url_regex -i \.mp4$
acl stream url_regex -i watch?
acl stream url_regex -i youtube
acl stream url_regex -i facebook
acl stream url_regex -i fbcdn\.net\/v\/(.*\.mp4)\?
acl stream url_regex -i fbcdn\.net\/v\/(.*\.jpg)\? 
acl stream url_regex -i akamaihd\.net\/v\/(.*\.mp4)\?
acl stream url_regex -i akamaihd\.net\/v\/(.*\.jpg)\?

##Dominios denegados
acl dominios_denegados dstdomain "/etc/squid/listas/dominios_denegados.lst"

##Extensiones bloqueadas
acl multimedia urlpath_regex "/etc/squid/listas/multimedia.lst"

##Extensiones peligrosas
acl peligrosos urlpath_regex "/etc/squid/listas/peligrosos.lst"

#Bypass squid
#acl bypass_dst_dom  dstdomain "/etc/squid/listas/bypass_dst_domain.lst"

##Redes sociales
acl redes_sociales url_regex -i ?/etc/squid/listas/redes_sociales.lst?


#Puertos
acl SSL_ports port 443
acl SSL_ports port 8443
acl SSL_ports port 8080

acl Safe_ports port 631		# httpCUPS
acl Safe_ports port 80		# http
acl Safe_ports port 21		# ftp
acl Safe_ports port 443		# https
acl Safe_ports port 70		# gopher
acl Safe_ports port 210		# wais
acl Safe_ports port 8443        # httpsalt
acl Safe_ports port 1025-65535	# unregistered ports
acl Safe_ports port 280		# http-mgmt
acl Safe_ports port 488		# gss-http
acl Safe_ports port 591		# filemaker
acl Safe_ports port 777		# multiling http
acl Safe_ports port 8080	# edesur y otros
acl CONNECT method CONNECT


#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
#http_access allow adminsquid manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
http_access allow localhost
#http_access allow bypass_dst_dom
http_access allow limitado !dominios_denegados !multimedia !peligrosos
http_access allow full !peligrosos
http_access allow adminis !multimedia
http_access allow sistemas

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.1.97:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=5MB cert=/etc/squid/ssl_cert/myca.pem
key=/etc/squid/ssl_cert/myca.pem 

sslproxy_cafile /etc/pki/tls/certs/ca-bundle.crt

#sslproxy_options  NO_SSLv3,

#acl step1 at_step SslBump1 
#acl excludeSSL ssl::server_name_regex web\.whatsapp\.com 
#acl excludeSSL ssl::server_name_regex arba\.gov\.ar
#acl excludeSSL ssl::server_name_regex argentinacompra\.gov\.ar

#ssl_bump peek step1 
#ssl_bump splice excludeSSL 
#ssl_bump bump all 

############################################################
acl excluidosSSL dstdomain "/etc/squid/listas/excluidosSSL.lst"
ssl_bump none excluidosSSL

# SSL Bump Config
ssl_bump stare all  
ssl_bump bump all 

sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER

#
sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 5MB
sslcrtd_children 8 startup=1 idle=1

#OJO ESTO!
always_direct allow all

# Uncomment and adjust the following to add a disk cache directory.
cache_dir aufs /var/spool/squid 1000 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320

#obliga el cache de imagenes .jgp

refresh_pattern -i \.jpg$ 30 0% 30 ignore-no-cache ignore-no-store
ignore-private

######POOL DE VELOCIDAD
#delay_pools 2
#delay_class 1 1
#delay_class 2 1
#delay_access 1 allow full
#delay_access 1 deny all
#delay_access 2 allow sistemas
#delay_access 2 deny all
#delay_parameters 1 64000/64000
#delay_parameters 2 32000/32000

###VELOCIDAD PARA REDES SOCIALES
#delay_class 1 1
#delay_parameters 1 15000/2000
#acl redes_sociales url_regex -i ?/etc/squid/listas/redes_sociales?
#delay_access 1 allow limitado redes_sociales


###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
via off
forwarded_for delete
###

#Pools para ancho de Banda
delay_pools 6

###VELOCIDAD PARA REDES SOCIALES
delay_class 1 1
delay_parameters 1 10000/100000
delay_access 1 allow redes_sociales limitado
delay_access 1 allow redes_sociales full
delay_access 1 allow redes_sociales adminis
delay_access 1 deny all


#Limitar Video Streaming a 20k
delay_class 2 1
delay_parameters 2 40000/100000
delay_access 2 allow stream adminis
delay_access 2 allow stream full
delay_access 2 allow stream limitado
delay_access 2 deny all

#Limitar Video Streaming a 500k
delay_class 3 1
delay_parameters 3 500000/500000
delay_access 3 allow stream sistemas
delay_access 3 deny all

#Ancho de Banda Administracion
delay_class 4 1
delay_parameters 4 256000/256000
delay_access 4 allow adminis
delay_access 4 deny all


#Ancho de Banda Sistemas
delay_class 5 2
delay_parameters 5 512000/512000 64000/256000
delay_access 5 allow sistemas
delay_access 5 deny all

#Ancho de Banda Logistica
delay_class 6 2
delay_parameters 6 256000/256000 30000/125000
delay_access 6 allow limitado
delay_access 6 deny all

###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
via off
forwarded_for delete
###

#dns_nameservers 8.8.8.8 
visible_hostname squid

# try connecting to first 25 ips of a domain name
forward_max_tries 25

# fix some ipv6 errors (recommended to comment out)
dns_v4_first on





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Errors-in-cache-log-tp4679651.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Thu Sep 22 18:59:27 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 22 Sep 2016 11:59:27 -0700 (PDT)
Subject: [squid-users] SSO (kerberos)
In-Reply-To: <1474492994109-4679640.post@n4.nabble.com>
References: <6bbebad5-7712-9b39-2510-8fcb7ece641b@treenet.co.nz>
 <1473780876101-4679484.post@n4.nabble.com>
 <ddc7ffa7-9858-710a-b8e0-6848106168bb@treenet.co.nz>
 <1473791599383-4679490.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73FC133@CLWSEXCMBX02.na.bicworld.com>
 <1473965736706-4679540.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73FCF2C@CLWSEXCMBX02.na.bicworld.com>
 <1473969879489-4679542.post@n4.nabble.com>
 <1474390256210-4679618.post@n4.nabble.com>
 <1474492994109-4679640.post@n4.nabble.com>
Message-ID: <1474570767416-4679652.post@n4.nabble.com>

So, i have a little more of info

this is config

###Kerberos Auth with ActiveDirectory###############
auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -d -s
HTTP/squid.example.lan at EXAMPLE.LAN
auth_param negotiate children 10
auth_param negotiate keep_alive on

#acl auth proxy_auth REQUIRED

external_acl_type i-limitado-krb children=10 cache=10 grace=15 %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -a -g i-limitado at EXAMPLE.LAN

acl i-limitado external i-limitado-krb
http_access allow i-limitado



AND HAVE THIS ERROR....
The grupos helpers are crashing too rapidly, need help!

"grupos" is for "group" in AD (samba)



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/SSO-kerberos-tp4679470p4679652.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From huaraz at moeller.plus.com  Thu Sep 22 19:36:39 2016
From: huaraz at moeller.plus.com (Markus Moeller)
Date: Thu, 22 Sep 2016 20:36:39 +0100
Subject: [squid-users] SSO (kerberos)
In-Reply-To: <1474570767416-4679652.post@n4.nabble.com>
References: <6bbebad5-7712-9b39-2510-8fcb7ece641b@treenet.co.nz>
 <1473780876101-4679484.post@n4.nabble.com>
 <ddc7ffa7-9858-710a-b8e0-6848106168bb@treenet.co.nz>
 <1473791599383-4679490.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73FC133@CLWSEXCMBX02.na.bicworld.com>
 <1473965736706-4679540.post@n4.nabble.com>
 <CA86A9283AA07E478F6B0629521FFEE73FCF2C@CLWSEXCMBX02.na.bicworld.com>
 <1473969879489-4679542.post@n4.nabble.com>
 <1474390256210-4679618.post@n4.nabble.com>
 <1474492994109-4679640.post@n4.nabble.com>
 <1474570767416-4679652.post@n4.nabble.com>
Message-ID: <ns1bs6$sva$1@blaine.gmane.org>

Hi

  Did you try the debug option -d for ext_kerberos_ldap_group_acl  to get 
some debug ? Maybe it gives some indication of the problem ?

Markus

"erdosain9"  wrote in message 
news:1474570767416-4679652.post at n4.nabble.com...

So, i have a little more of info

this is config

###Kerberos Auth with ActiveDirectory###############
auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -d -s
HTTP/squid.example.lan at EXAMPLE.LAN
auth_param negotiate children 10
auth_param negotiate keep_alive on

#acl auth proxy_auth REQUIRED

external_acl_type i-limitado-krb children=10 cache=10 grace=15 %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -a -g i-limitado at EXAMPLE.LAN

acl i-limitado external i-limitado-krb
http_access allow i-limitado



AND HAVE THIS ERROR....
The grupos helpers are crashing too rapidly, need help!

"grupos" is for "group" in AD (samba)



--
View this message in context: 
http://squid-web-proxy-cache.1019090.n4.nabble.com/SSO-kerberos-tp4679470p4679652.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users 




From augustus_meyer at gmx.net  Thu Sep 22 21:33:56 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Thu, 22 Sep 2016 14:33:56 -0700 (PDT)
Subject: [squid-users] libevent
In-Reply-To: <e44c6ba4-d453-f636-3b19-e7c9265a713e@gmail.com>
References: <1474490809121-4679637.post@n4.nabble.com>
 <9fd498da-19d6-9552-bfb3-b0b569e1d96e@gmail.com>
 <1474491695435-4679639.post@n4.nabble.com>
 <674a291e-da47-20ab-2a30-f01274fa6bfb@measurement-factory.com>
 <8222e54d-b4d1-af9e-f46d-13d5ff3eca46@gmail.com>
 <e44c6ba4-d453-f636-3b19-e7c9265a713e@gmail.com>
Message-ID: <1474580036371-4679654.post@n4.nabble.com>

>You are too few in number to provide something decent enough, and not from
the last century.<
The smaller the development team, the more efficient it is. Highly qualified
staff assumed.
And LINUX is as suitable to event-driven programming as MVS.
Therefore, (bad) compromise has to be made.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/libevent-tp4679637p4679654.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Thu Sep 22 21:42:15 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 23 Sep 2016 03:42:15 +0600
Subject: [squid-users] libevent
In-Reply-To: <1474580036371-4679654.post@n4.nabble.com>
References: <1474490809121-4679637.post@n4.nabble.com>
 <9fd498da-19d6-9552-bfb3-b0b569e1d96e@gmail.com>
 <1474491695435-4679639.post@n4.nabble.com>
 <674a291e-da47-20ab-2a30-f01274fa6bfb@measurement-factory.com>
 <8222e54d-b4d1-af9e-f46d-13d5ff3eca46@gmail.com>
 <e44c6ba4-d453-f636-3b19-e7c9265a713e@gmail.com>
 <1474580036371-4679654.post@n4.nabble.com>
Message-ID: <c52c4d1b-7e44-2e27-956c-db670144881e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


23.09.2016 3:33, reinerotto ?????:
>> You are too few in number to provide something decent enough, and not from
> the last century.<
> The smaller the development team, the more efficient it is. Highly
qualified
> staff assumed.
Oh, yes, we've seen. Bugs can not be closed for years. If the bug is not
obvious or can not be replayed in one action - it is ignored.
>
> And LINUX is as suitable to event-driven programming as MVS.
> Therefore, (bad) compromise has to be made.
I will not argue. We are not here maxims throws.
>
>
>
>
> --
> View this message in context:
http://squid-web-proxy-cache.1019090.n4.nabble.com/libevent-tp4679637p4679654.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX5FA3AAoJENNXIZxhPexGNeIIAI4pVwbIdKw++Q/yh+kDtfK1
RzvQ4uw1RfilLAOSm5X+qHHapemiFxeXowxTKmWA2PTLjK+XEkU4SMFlmjMX3yn1
wEBeVF4He+j7LQrz8zaB2eXP519GZkjsZVjY3tOGIFwAOSbFajca42wuJHxWQiCn
gyFfVr1lk4DzXa6gtF+WrZfhHtk1+PeypGK/GM/0sXIKO2CF07kgm2yHAOpGJnIc
InC4CKIahkBDJGy5ldKpqd9BetWNyV6ScPZS5ynXupL2/6uKJCRp3+xTrVu2anJz
/8ORWVcuTYAQbVUQC5wLeih9BJ2idpWNi/ennxJCxmNdX/Yu/3neXv3Vq3GsSfQ=
=yFcg
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160923/5c34f212/attachment.key>

From augustus_meyer at gmx.net  Thu Sep 22 23:43:16 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Thu, 22 Sep 2016 16:43:16 -0700 (PDT)
Subject: [squid-users] libevent
In-Reply-To: <c52c4d1b-7e44-2e27-956c-db670144881e@gmail.com>
References: <1474490809121-4679637.post@n4.nabble.com>
 <9fd498da-19d6-9552-bfb3-b0b569e1d96e@gmail.com>
 <1474491695435-4679639.post@n4.nabble.com>
 <674a291e-da47-20ab-2a30-f01274fa6bfb@measurement-factory.com>
 <8222e54d-b4d1-af9e-f46d-13d5ff3eca46@gmail.com>
 <e44c6ba4-d453-f636-3b19-e7c9265a713e@gmail.com>
 <1474580036371-4679654.post@n4.nabble.com>
 <c52c4d1b-7e44-2e27-956c-db670144881e@gmail.com>
Message-ID: <1474587796526-4679656.post@n4.nabble.com>

Although off topic, 
>Oh, yes, we've seen. Bugs can not be closed for years. If the bug is not
obvious or can not be replayed in one action - it is ignored. <

there is no software (besides mine :-) which is free of bugs. So the amount
of bugs still present simply should be "managable". More or less one-time
effects might even be caused by compiler glitches or "language pecularities"
(the decision to switch from C was a big mistake in my opinion, increasing
the chances of such effects) _or_ very seldom timing issues. Last not least,
you still have the option to sponsor fixing a bug, which for any reason
especially harms you. We are talking about opensource, better to say,
(mostly) free-of-charge software.





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/libevent-tp4679637p4679656.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From bycn82 at gmail.com  Thu Sep 22 23:57:02 2016
From: bycn82 at gmail.com (Bill Yuan)
Date: Fri, 23 Sep 2016 07:57:02 +0800
Subject: [squid-users] Question about the url rewrite before proxy out
In-Reply-To: <eab797dc-9221-c7d3-5b61-4a1b98c40850@measurement-factory.com>
References: <CAC+JH2w=9Bk2jh-MM-WG-UWbOcyXKSL8rrKNiKPGtgHw7u9tcw@mail.gmail.com>
 <003401d2148e$ddabc8a0$990359e0$@filter.luko.org>
 <201609220956.29355.Antony.Stone@squid.open.source.it>
 <008901d214ba$e0adba00$a2092e00$@filter.luko.org>
 <eab797dc-9221-c7d3-5b61-4a1b98c40850@measurement-factory.com>
Message-ID: <CAC+JH2zbr3v2DPFG=xy_mZv83o+hF5CBvsD_qWZ4PF40eheKQw@mail.gmail.com>

Thanks for replying

I see, it is a url rewrite  and i am trying to find an sample to have a test


the content are not required to be updated if it is a image


On Thursday, September 22, 2016, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 09/22/2016 04:20 AM, squid-users at filter.luko.org <javascript:;> wrote:
>
> > Then not only the request needs to be rewritten, but probably the
> > page content too. [...] If that is the case,
> > then Squid doesn't seem like the right tool for the job.
>
> Why not? If rewriting is needed, an ICAP or eCAP service can rewrite the
> response body before Squid serves it.
>
> However, in practice, this kind of page rewriting does not work very
> well (regardless of which software is doing the rewrite) because many
> page URLs are formed dynamically on the client side (by Javascript code).
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org <javascript:;>
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160923/06afded1/attachment.htm>

From creditu at eml.cc  Fri Sep 23 00:45:20 2016
From: creditu at eml.cc (creditu at eml.cc)
Date: Thu, 22 Sep 2016 18:45:20 -0600
Subject: [squid-users] Accelerator Mode  - HSTS and Redirect
Message-ID: <1474591520.68413.734388465.08421690@webmail.messagingengine.com>

We have been using squid in accelerator mode for a number of years. In
the current setup we have the squid frontends that send all the http
requests to the backend apache webservers using a simple redirect
script.  We need to switch to https for the public presence.

So, our initial thought would be to use https_port for public HTTPS
presence and send the requests using cache_peer to the backend apache
servers using plain http.  Basically terminating HTTPS from clients and
relaying it to backend servers using HTTP.  

We will need to implement HSTS at some point (i.e.
Strict-Transport-Security: max-age=8888; includeSubDomains; preload),
will we be able to do this in the above scenario?

Also, we will initially be providing both http and https, but will need
to stop http at some point.  Is there a way to redirect the clients that
try to connect via http to use https with squid?  Something like the
rewrite engine in apache?

We use RH 6.x which comes with squid 3.1.  Thanks for any feedback. 


From squid3 at treenet.co.nz  Fri Sep 23 03:03:56 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 23 Sep 2016 15:03:56 +1200
Subject: [squid-users] Accelerator Mode - HSTS and Redirect
In-Reply-To: <1474591520.68413.734388465.08421690@webmail.messagingengine.com>
References: <1474591520.68413.734388465.08421690@webmail.messagingengine.com>
Message-ID: <dc4e839f-dceb-5850-2c71-20a85c459b53@treenet.co.nz>

On 23/09/2016 12:45 p.m., creditu wrote:
> We have been using squid in accelerator mode for a number of years. In
> the current setup we have the squid frontends that send all the http
> requests to the backend apache webservers using a simple redirect
> script.  We need to switch to https for the public presence.

redirect/rewrite script is very rarely a suitable way to do this for
reverse-proxy.

Use cache_peer to configure what backend servers exist and
cache_peer_access rules to determine which one(s) any given request can
be sent to.

The backends should be capable of accepting the traffic as if the proxy
were not there. If for some reason it has to have a different domain
name (actual need for this is rare), then the cache_peer forcedomain=
option can be used.

> 
> So, our initial thought would be to use https_port for public HTTPS
> presence and send the requests using cache_peer to the backend apache
> servers using plain http.  Basically terminating HTTPS from clients and
> relaying it to backend servers using HTTP.  
> 
> We will need to implement HSTS at some point (i.e.
> Strict-Transport-Security: max-age=8888; includeSubDomains; preload),
> will we be able to do this in the above scenario?
> 

Yes. Provided you can get rid of that redirect/rewrite script. The
background things cache_peer logic does to the traffic will be needed
for the HTTPS transition.


> Also, we will initially be providing both http and https, but will need
> to stop http at some point.  Is there a way to redirect the clients that
> try to connect via http to use https with squid?  Something like the
> rewrite engine in apache?

cache_peer can be configured to contact the peer over TLS. This can be
done individually, and before the HSTS gets added for public viewing.

> 
> We use RH 6.x which comes with squid 3.1.  Thanks for any feedback. 

For your particular use a build of that with OpenSSL support should be
okay. But if you can, an upgrade to more recent version would be better
as there have been some important OpenSSL and TLS protocol changes since
3.1 was designed.

Amos



From jason_haar at trimble.com  Fri Sep 23 04:17:49 2016
From: jason_haar at trimble.com (Jason Haar)
Date: Fri, 23 Sep 2016 16:17:49 +1200
Subject: [squid-users] SSO and Squid, SAML 2.0 ?
In-Reply-To: <852764541.909339728.1474360797455.JavaMail.root@zimbra4-e1.priv.proxad.net>
References: <1035998297.909219926.1474359122436.JavaMail.root@zimbra4-e1.priv.proxad.net>
 <852764541.909339728.1474360797455.JavaMail.root@zimbra4-e1.priv.proxad.net>
Message-ID: <CAFChrgL5W=JBqWGqVPV7g-HxnjgEs4Y0xqUq=RYHqiVGccvbZw@mail.gmail.com>

On Tue, Sep 20, 2016 at 8:39 PM, FredB <fredbmail at free.fr> wrote:

> I'm searching a way to use a secure SSO with Squid, how did you implement
> the authenticate method with an implicit proxy ?
> I'm reading many documentations about SAML, but I found nothing about Squid
>
> I guess we can only do something with cookies ?
>

Hi Fred

Proxies only support "HTTP authentication" methods: Basic, Digest, NTLM
,etc. So you either have to use one of those, or perhaps "fake" the
creation of one of those...?

eg you mentioned SAML, but gave no context beyond saying you didn't want
AD. So let's say SAML is a requirement. Well that's directly impossible as
it isn't an "HTTP authentication" method, but you could hit it from the
sides...

How about putting a SAML SP on your squid server, and it generates fresh
random Digest authentication creds for any authenticated user (ie same
username, but 30char random password), and tells them to cut-n-paste them
into their web browser proxy prompt and "save" them. That way the proxy is
using Digest and it involved a one-off SAML interaction. I say Digest
instead of Basic because Digest is more secure over cleartext - but it's
also noticeably slower than Basic over latency links, so you can choose
your poison there

If you're really keen, you can actually do proxy-over-TLS via WPAD with
Firefox/Chrome - at which point I'd definitely recommend Basic for the
performance reasons ;-)



-- 
Cheers

Jason Haar
Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160923/789fee58/attachment.htm>

From squid3 at treenet.co.nz  Fri Sep 23 05:26:57 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 23 Sep 2016 17:26:57 +1200
Subject: [squid-users] Errors in cache.log
In-Reply-To: <1474567862731-4679651.post@n4.nabble.com>
References: <1474567862731-4679651.post@n4.nabble.com>
Message-ID: <5756dcf2-f88b-1f15-9b43-dff112f17894@treenet.co.nz>

On 23/09/2016 6:11 a.m., erdosain9 wrote:
> Hi.
> Im having this message in cache.log
> 
>  Error negotiating SSL on FD 121: error:00000000:lib(0):func(0):reason(0)
> (5/0/0)
> 2016/09/22 14:20:36 kid1| BUG: Unexpected state while connecting to a
> cache_peer or origin server
> 2016/09/22 14:29:23 kid1| Error negotiating SSL connection on FD 33:
> error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
> 2016/09/22 14:29:24 kid1| Error negotiating SSL connection on FD 33:
> error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca (1/0)
> 2016/09/22 14:32:02 kid1| WARNING: HTTP: Invalid Response: No object data
> received for
> https://r3---sn-q4f7sn7l.googlevideo.com/videoplayback?pl=21&itag=242&dur=3973.160&source=youtube&keepalive=yes&expire=1474585097&mime=video%2Fwebm&signature=14F5607A717C8A9DD579A55C69F6CDF4C2308FC5.47CE0A2B9F54F2C8C4042FF7797A08708951C276&clen=12532131&gir=yes&key=cms1&ip=190.113.224.106&ipbits=0&id=o-ABdgV3GldzFU1c8jBp6s_27abh9g_9c3hA0dbUgDkgjM&upn=4Xlvne-1RrE&lmt=1449585312748326&sparams=clen,dur,ei,expire,gir,id,initcwndbps,ip,ipbits,itag,keepalive,lmt,mime,mm,mn,ms,mv,nh,pl,requiressl,source,upn&ei=qQ3kV7rtJNT0wQTR0I_oDg&requiressl=yes&cpn=jdZ-1Vthefy2q9Og&alr=yes&ratebypass=yes&c=WEB&cver=1.20160921&redirect_counter=1&req_id=ad722d06312b3cfc&cms_redirect=yes&mm=34&mn=sn-q4f7sn7l&ms=ltu&mt=1474563648&mv=m&nh=IgpwcjAyLmV6ZTAxKgkxMjcuMC4wLjE&range=8224151-8353222&rn=840&rbuf=585667
> AKA
> r3---sn-q4f7sn7l.googlevideo.com/videoplayback?pl=21&itag=242&dur=3973.160&source=youtube&keepalive=yes&expire=1474585097&mime=video%2Fwebm&signature=14F5607A717C8A9DD579A55C69F6CDF4C2308FC5.47CE0A2B9F54F2C8C4042FF7797A08708951C276&clen=12532131&gir=yes&key=cms1&ip=190.113.224.106&ipbits=0&id=o-ABdgV3GldzFU1c8jBp6s_27abh9g_9c3hA0dbUgDkgjM&upn=4Xlvne-1RrE&lmt=1449585312748326&sparams=clen,dur,ei,expire,gir,id,initcwndbps,ip,ipbits,itag,keepalive,lmt,mime,mm,mn,ms,mv,nh,pl,requiressl,source,upn&ei=qQ3kV7rtJNT0wQTR0I_oDg&requiressl=yes&cpn=jdZ-1Vthefy2q9Og&alr=yes&ratebypass=yes&c=WEB&cver=1.20160921&redirect_counter=1&req_id=ad722d06312b3cfc&cms_redirect=yes&mm=34&mn=sn-q4f7sn7l&ms=ltu&mt=1474563648&mv=m&nh=IgpwcjAyLmV6ZTAxKgkxMjcuMC4wLjE&range=8224151-8353222&rn=840&rbuf=585667
> Error negotiating SSL on FD 91: error:00000000:lib(0):func(0):reason(0)
> (5/-1/104)
> 

Firstly, it is not one message. It is 4 and one partial message.

They may be related log entries, or maybe not. It is hard to say when
they are occuring across ~12 minutes. A single TLS handshake should be
much faster than that, so I suspect they are a mix of at least three
different transactions worth of info.


> 
> 
> Sometimes in webbrowser give something like bad CA
> 
> or this (IPV6??)
> 

The below error is not necessarily IPv6 related. It shows an IPv6
address because you configured "dns_v4_first on", so the _last_ thing to
be tried was that IPv6 address.

What it means is that *all* the IPv4 and IPv6 ways to contact the server
are not working.


> The following error was encountered while trying to retrieve the URL:
> https://www.facebook.com/*
> 
> Connection to 2a03:2880:f105:83:face:b00c:0:25de failed.
> 
> The system returned: (101) Network is unreachable
> 
> The remote host or network may be down. Please try the request again.
> 
> Your cache administrator is webmaster.
> 
> This is my config
> 
> #
> # Recommended minimum configuration:
> #
> 

<snip commented out ACL definitions>

> 
> ####GRUPOS DE IP
> acl full src "/etc/squid/ips/full.lst"
> acl limitado src "/etc/squid/ips/limitado.lst"
> acl sistemas src "/etc/squid/ips/sistemas.lst"
> acl adminis  src "/etc/squid/ips/adminis.lst"

<snip commented out lines>

> 
> ####Bloquea Publicidad ( http://pgl.yoyo.org/adservers/ )
> acl ads dstdom_regex "/etc/squid/listas/ad_block.lst"
> http_access deny ads

<snip commented out lines>

> acl stream url_regex -i \.flv$
> acl stream url_regex -i \.mp4$
> acl stream url_regex -i watch?
> acl stream url_regex -i youtube
> acl stream url_regex -i facebook
> acl stream url_regex -i fbcdn\.net\/v\/(.*\.mp4)\?
> acl stream url_regex -i fbcdn\.net\/v\/(.*\.jpg)\? 
> acl stream url_regex -i akamaihd\.net\/v\/(.*\.mp4)\?
> acl stream url_regex -i akamaihd\.net\/v\/(.*\.jpg)\?
> 
> ##Dominios denegados
> acl dominios_denegados dstdomain "/etc/squid/listas/dominios_denegados.lst"
> 
> ##Extensiones bloqueadas
> acl multimedia urlpath_regex "/etc/squid/listas/multimedia.lst"
> 
> ##Extensiones peligrosas
> acl peligrosos urlpath_regex "/etc/squid/listas/peligrosos.lst"
> 
> #Bypass squid
> #acl bypass_dst_dom  dstdomain "/etc/squid/listas/bypass_dst_domain.lst"
> 
> ##Redes sociales
> acl redes_sociales url_regex -i ?/etc/squid/listas/redes_sociales.lst?
> 
> 
> #Puertos
> acl SSL_ports port 443
> acl SSL_ports port 8443
> acl SSL_ports port 8080
> 
> acl Safe_ports port 631		# httpCUPS
> acl Safe_ports port 80		# http
> acl Safe_ports port 21		# ftp
> acl Safe_ports port 443		# https
> acl Safe_ports port 70		# gopher
> acl Safe_ports port 210		# wais
> acl Safe_ports port 8443        # httpsalt
> acl Safe_ports port 1025-65535	# unregistered ports
> acl Safe_ports port 280		# http-mgmt
> acl Safe_ports port 488		# gss-http
> acl Safe_ports port 591		# filemaker
> acl Safe_ports port 777		# multiling http
> acl Safe_ports port 8080	# edesur y otros
> acl CONNECT method CONNECT
> 
> 
> #
> # Recommended minimum Access Permission configuration:
> #
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
> 
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> #http_access allow adminsquid manager
> http_access deny manager
> 
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> #http_access deny to_localhost
> 
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> 

<snip commented out lines in the below rules>

> http_access allow localhost
> http_access allow limitado !dominios_denegados !multimedia !peligrosos
> http_access allow full !peligrosos
> http_access allow adminis !multimedia
> http_access allow sistemas
> http_access deny all
> 

> http_port 192.168.1.97:3128 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=5MB cert=/etc/squid/ssl_cert/myca.pem
> key=/etc/squid/ssl_cert/myca.pem 
> 
> sslproxy_cafile /etc/pki/tls/certs/ca-bundle.crt
> 

<snip commented out lines>

> 
> ############################################################
> acl excluidosSSL dstdomain "/etc/squid/listas/excluidosSSL.lst"
> ssl_bump none excluidosSSL
> 
> # SSL Bump Config
> ssl_bump stare all  
> ssl_bump bump all 

The "none" action from Squid-3.1 bumping design is not compatible with
"stare" and "bump" actions from Squid-3.4+ bumping design.

I believe this incorrect mix of bumping actions is probably the cause of
some of the TLS errors you are encountering.

Use "splice excluidosSSL" instead. To get the splice to work you may
need to peek at bumping step #1 instead of stare'ing.

> 
> sslproxy_cert_error allow all
> sslproxy_flags DONT_VERIFY_PEER
> 

Very bad options. When combined they destroy all security bnefits TLS is
supposed to provide.

Remove those lines, then fix any specific issues that occur afterwards
via a more correct fix.


> #
> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 5MB
> sslcrtd_children 8 startup=1 idle=1
> 
> #OJO ESTO!
> always_direct allow all

Above rule has no effect. You do not have any cache_peer configured.


> 
> # Uncomment and adjust the following to add a disk cache directory.
> cache_dir aufs /var/spool/squid 1000 16 256
> 
> # Leave coredumps in the first cache dir
> coredump_dir /var/spool/squid
> 
> #
> # Add any of your own refresh_pattern entries above these.

Notice what the above line says. It is important ...

> #
> refresh_pattern ^ftp:		1440	20%	10080
> refresh_pattern ^gopher:	1440	0%	1440
> refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
> refresh_pattern .		0	20%	4320
> 
> #obliga el cache de imagenes .jgp
> 
> refresh_pattern -i \.jpg$ 30 0% 30 ignore-no-cache ignore-no-store
> ignore-private

... this refresh_pattern is never reached nor used, because it does not
go above the default patterns.


<snip comments>
> 
> ###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
> via off
> forwarded_for delete
> ###
> 
> #Pools para ancho de Banda
> delay_pools 6
> 
> ###VELOCIDAD PARA REDES SOCIALES
> delay_class 1 1
> delay_parameters 1 10000/100000
> delay_access 1 allow redes_sociales limitado
> delay_access 1 allow redes_sociales full
> delay_access 1 allow redes_sociales adminis
> delay_access 1 deny all
> 
> 
> #Limitar Video Streaming a 20k
> delay_class 2 1
> delay_parameters 2 40000/100000
> delay_access 2 allow stream adminis
> delay_access 2 allow stream full
> delay_access 2 allow stream limitado
> delay_access 2 deny all
> 
> #Limitar Video Streaming a 500k
> delay_class 3 1
> delay_parameters 3 500000/500000
> delay_access 3 allow stream sistemas
> delay_access 3 deny all
> 
> #Ancho de Banda Administracion
> delay_class 4 1
> delay_parameters 4 256000/256000
> delay_access 4 allow adminis
> delay_access 4 deny all
> 

Note: requests which match the "redes_sociales adminis" ACLs have BOTH
pool #1 and pool #4 restrictions applied to them.

Note: requests which match the "stream adminis" ACLs have BOTH pool #2
and pool #4 restrictions applied to them.

> 
> #Ancho de Banda Sistemas
> delay_class 5 2
> delay_parameters 5 512000/512000 64000/256000
> delay_access 5 allow sistemas
> delay_access 5 deny all
> 

Note: requests which match the "redes_sociales sistemas" ACLs have BOTH
pool #1 and pool #5 restrictions applied to them.

Note: requests which match the "stream sistemas" ACLs have BOTH pool #3
and pool #5 restrictions applied to them.

> #Ancho de Banda Logistica
> delay_class 6 2
> delay_parameters 6 256000/256000 30000/125000
> delay_access 6 allow limitado
> delay_access 6 deny all
> 

Note: requests which match the "redes_sociales limitado" ACLs have BOTH
pool #1 and pool #6 restrictions applied to them.

Note: requests which match the "stream limitado" ACLs have BOTH pool #2
and pool #6 restrictions applied to them.


> ###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
> via off
> forwarded_for delete

These details are duplicated above the deal pool stuff. Remove the
duplication.


> visible_hostname squid

This needs to be a FQDN. That will reduce the number of problems you
have with the Via header being sent out.


> 
> # try connecting to first 25 ips of a domain name
> forward_max_tries 25
> 
> # fix some ipv6 errors (recommended to comment out)
> dns_v4_first on
> 

FYI: This does not fix any IPv6 errors. It hides IPv6 problems by making
Squid first try IPv4 when contacting servers unless their IPv4 is broken
or unavailable.

One should never consider it a "fix". At best it is a temporary
workaround that will cease working as the Internet migrates to IPv6-only
(which has already begun in some parts of the world).

Amos



From fredbmail at free.fr  Fri Sep 23 13:13:55 2016
From: fredbmail at free.fr (FredB)
Date: Fri, 23 Sep 2016 15:13:55 +0200 (CEST)
Subject: [squid-users] SSO and Squid, SAML 2.0 ?
In-Reply-To: <CAFChrgL5W=JBqWGqVPV7g-HxnjgEs4Y0xqUq=RYHqiVGccvbZw@mail.gmail.com>
Message-ID: <1840934395.926545982.1474636435138.JavaMail.root@zimbra4-e1.priv.proxad.net>


> 
> 
> Proxies only support "HTTP authentication" methods: Basic, Digest,
> NTLM ,etc. So you either have to use one of those, or perhaps "fake"
> the creation of one of those...?
> 
> 
> eg you mentioned SAML, but gave no context beyond saying you didn't
> want AD. So let's say SAML is a requirement. Well that's directly
> impossible as it isn't an "HTTP authentication" method, but you
> could hit it from the sides...
> 
> 
> How about putting a SAML SP on your squid server, and it generates
> fresh random Digest authentication creds for any authenticated user
> (ie same username, but 30char random password), and tells them to
> cut-n-paste them into their web browser proxy prompt and "save"
> them. That way the proxy is using Digest and it involved a one-off
> SAML interaction. I say Digest instead of Basic because Digest is
> more secure over cleartext - but it's also noticeably slower than
> Basic over latency links, so you can choose your poison there
> 
> 
> If you're really keen, you can actually do proxy-over-TLS via WPAD
> with Firefox/Chrome - at which point I'd definitely recommend Basic
> for the performance reasons ;-)
> 

Hi,

I'm using Digest now, with a large network for me it's fast enough (more than 100 0000 users), we remove BASIC identification for security reasons and the web browsers aren't all in AD.

The point about SSO is to remove the popup with a web portal (Identification for all internal websites + Internet proxy) 

I mentioned SAML, and yes there is no real context :) because I'm just searching informations, in my company a team thinks about SAML for the portal (SSO Intranet) so I thought why not ?

I guess some companies are using identifications with a web portal ? No ?

Fred


From ahmed.zaeem at netstream.ps  Fri Sep 23 13:32:19 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Fri, 23 Sep 2016 16:32:19 +0300
Subject: [squid-users] squid with apple updates caching problem !
Message-ID: <78A7B9B4-B331-4F2F-A6EB-69E70E029C02@netstream.ps>

hi foks .

i need to know what wrong i have in apple caching updates .

1st of all the access.log files as below :
1474636714.291     89 192.168.0.11 TCP_MISS/206 9501 GET http://swcdn.apple.com/content/downloads/49/62/031-1878/hfuvnhh956akbythuxg2im9pdnm3c263sf/BookKitDelta.pkg - ORIGINAL_DST/17.253.37.202 application/octet-stream
1474636777.755     95 192.168.0.11 TCP_MISS/206 9501 GET http://swcdn.apple.com/content/downloads/49/62/031-1878/hfuvnhh956akbythuxg2im9pdnm3c263sf/BookKitDelta.pkg - ORIGINAL_DST/17.253.37.202 application/octet-stream
1474636841.194     99 192.168.0.11 TCP_MISS/206 9501 GET http://swcdn.apple.com/content/downloads/49/62/031-1878/hfuvnhh956akbythuxg2im9pdnm3c263sf/BookKitDelta.pkg - ORIGINAL_DST/17.253.37.202 application/octet-stream
1474636934.576     81 192.168.0.11 TCP_MISS/200 2062 GET http://sr.symcd.com/MFYwVKADAgEAME0wSzBJMAkGBSsOAwIaBQAEFHQkFGcGn/XgmD9ePhproGUqVBV1BBQBWavn3ToLWaZkY9bPIAdX1ZHnagIQEyA4ubHXyrHK2FbDJD3q1A== - ORIGINAL_DST/2.22.139.27 application/ocsp-response

==========
not sure exactly what i need to modify in the ACLS .

===========
squid.conf :

acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
 
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT
 
http_access allow localnet
http_access allow localhost
 
# And finally deny all other access to this proxy
http_access  deny all
 
 
http_port 3128
http_port 3129 intercept
 
cache_dir ufs /var/cache/squid1 10000 16 256
 
 
maximum_object_size 6000 MB
range_offset_limit -1
quick_abort_min -1 KB
##################
acl updatesites dstdom_regex "/etc/squid/updatesites.txt"
cache allow updatesites
cache deny all 
############################
cache_store_log /var/log/squid/store.log
access_log daemon:/var/log/squid/access.log squid
cache_log /var/log/squid/cache.log
 
coredump_dir /var/cache/squid
 
store_id_program /lib/squid/storeid_file_rewrite /etc/squid/storeid_rewrite.conf
store_id_children 10 startup=3 idle=1 concurrency=0
############################################
refresh_pattern -i appldnld\.apple\.com 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern -i \.apple\.com 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod
refresh_pattern -i .apple\.com 43200 100% 43200 ignore-reload ignore-no-store override-expire override-lastmod


###################################################
cat /etc/squid/updatesites.txt

([^.]+.|)apple.com
([^.]+\.)?(download|(windows)?update)\.(microsoft\.)?com
([^.]+\.)?adobe.com
([^.]+\.)?java.com
([^.]+\.)?sun.com
([^.]+\.)?oracle.com
([^.]+\.)?apple.com
([^.]+\.)?apple.com
([^.]+\.)?ubuntu.com
([^.]+\.)?steampowered.com
([^.]+\.)?google.com <http://google.com/>
#########################################

 cat /etc/squid/storeid_rewrite.conf
^http:\/\/[^\.]+\.phobos\.apple\.com\/(.*)		http://appupdates.apple.squid.internal/$1
^http:\/\/[^\.]+\.cs\.steampowered\.com\/(.*)		 http: //steamupdates.squid.internal/$1


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160923/c2f74ac3/attachment.htm>

From erdosain9 at gmail.com  Fri Sep 23 13:50:03 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Fri, 23 Sep 2016 06:50:03 -0700 (PDT)
Subject: [squid-users] Errors in cache.log
In-Reply-To: <5756dcf2-f88b-1f15-9b43-dff112f17894@treenet.co.nz>
References: <1474567862731-4679651.post@n4.nabble.com>
 <5756dcf2-f88b-1f15-9b43-dff112f17894@treenet.co.nz>
Message-ID: <1474638603998-4679664.post@n4.nabble.com>

Hi,
Thanks a lot.
But, i really dont get something...
about delay pools

you tell me that



Amos Jeffries wrote
> Note: requests which match the "redes_sociales adminis" ACLs have BOTH
> pool #1 and pool #4 restrictions applied to them.
> 
> Note: requests which match the "stream adminis" ACLs have BOTH pool #2
> and pool #4 restrictions applied to them.
> Amos

And the same for the others delay pools...
But, what i think that im doing is apply for example

the web pages of "redes_sociales"(social network) to "adminis"... i mean,
that bandwith for those webs... and then the other delay pools for bandwith
for youtube, and other delay pool for all the other webs........

it is not right??

Thansk!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Errors-in-cache-log-tp4679651p4679664.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From tornadoofsouls87 at gmail.com  Fri Sep 23 14:28:31 2016
From: tornadoofsouls87 at gmail.com (lravelo)
Date: Fri, 23 Sep 2016 07:28:31 -0700 (PDT)
Subject: [squid-users] issues with amazonaws & cloudfront
Message-ID: <1474640911785-4679665.post@n4.nabble.com>

Good morning!

I have four squid 3.3.8 proxies load balanced behind two VIPs (in groups of
two) using least connections load balancing.  I've been having issues with
the .amazonaws.com and .cloudfront.com domains.  We use TCP load balancing
and not HTTP load balancing.  Basically what happens is that these web pages
request a keep-alive and on the browser console I'm seeing messages saying
that proxy authentication failed and some "ERR_CACHE_ACCESS_DENIED 0" errors
as well.  We do have kerberos authentication for SSO.  Not sure if anyone
else has had this issue and what's been done to resolve it.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/issues-with-amazonaws-cloudfront-tp4679665.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From hardikdangar+squid at gmail.com  Fri Sep 23 14:37:28 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Fri, 23 Sep 2016 20:07:28 +0530
Subject: [squid-users] squid with apple updates caching problem !
In-Reply-To: <78A7B9B4-B331-4F2F-A6EB-69E70E029C02@netstream.ps>
References: <78A7B9B4-B331-4F2F-A6EB-69E70E029C02@netstream.ps>
Message-ID: <CA+sSnVbfBGhQ8dQMixJOZCHJeSE=OyVW5arE_5nxz4jHSvj8mw@mail.gmail.com>

Hey Ahmed,

You can use reload-into-ms, most other squid refresh patterns you have used
do more harm than benefits,
something like,

refresh_pattern -i appldnld\.apple\.com 43200 100% 43200  reload-into-ims

would work. I am not sure about the regex you have used, i thought i had
different.

On Fri, Sep 23, 2016 at 7:02 PM, --Ahmad-- <ahmed.zaeem at netstream.ps> wrote:

> hi foks .
>
> i need to know what wrong i have in apple caching updates .
>
> 1st of all the access.log files as below :
> 1474636714.291     89 192.168.0.11 TCP_MISS/206 9501 GET
> http://swcdn.apple.com/content/downloads/49/62/031-1878/
> hfuvnhh956akbythuxg2im9pdnm3c263sf/BookKitDelta.pkg - ORIGINAL_DST/
> 17.253.37.202 application/octet-stream
> 1474636777.755     95 192.168.0.11 TCP_MISS/206 9501 GET
> http://swcdn.apple.com/content/downloads/49/62/031-1878/
> hfuvnhh956akbythuxg2im9pdnm3c263sf/BookKitDelta.pkg - ORIGINAL_DST/
> 17.253.37.202 application/octet-stream
> 1474636841.194     99 192.168.0.11 TCP_MISS/206 9501 GET
> http://swcdn.apple.com/content/downloads/49/62/031-1878/
> hfuvnhh956akbythuxg2im9pdnm3c263sf/BookKitDelta.pkg - ORIGINAL_DST/
> 17.253.37.202 application/octet-stream
> 1474636934.576     81 192.168.0.11 TCP_MISS/200 2062 GET
> http://sr.symcd.com/MFYwVKADAgEAME0wSzBJMAkGBSsOAwIaBQAEFHQkFGcGn/
> XgmD9ePhproGUqVBV1BBQBWavn3ToLWaZkY9bPIAdX1ZHnagIQEyA4ubHXyrHK2FbDJD3q1A==
> - ORIGINAL_DST/2.22.139.27 application/ocsp-response
>
> ==========
> not sure exactly what i need to modify in the ACLS .
>
> ===========
> squid.conf :
>
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
> machines
>
>
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
>
>
> http_access allow localnet
> http_access allow localhost
>
>
> # And finally deny all other access to this proxy
> http_access  deny all
>
>
>
>
> http_port 3128
> http_port 3129 intercept
>
>
> cache_dir ufs /var/cache/squid1 10000 16 256
>
>
>
>
> maximum_object_size 6000 MB
> range_offset_limit -1
> quick_abort_min -1 KB
> ##################
> acl updatesites dstdom_regex "/etc/squid/updatesites.txt"
> cache allow updatesites
> cache deny all
> ############################
> cache_store_log /var/log/squid/store.log
> access_log daemon:/var/log/squid/access.log squid
> cache_log /var/log/squid/cache.log
>
>
> coredump_dir /var/cache/squid
>
>
> store_id_program /lib/squid/storeid_file_rewrite
> /etc/squid/storeid_rewrite.conf
> store_id_children 10 startup=3 idle=1 concurrency=0
> ############################################
> refresh_pattern -i appldnld\.apple\.com 43200 100% 43200 ignore-reload
> ignore-no-store override-expire override-lastmod
> refresh_pattern -i \.apple\.com 43200 100% 43200 ignore-reload
> ignore-no-store override-expire override-lastmod
> refresh_pattern -i .apple\.com 43200 100% 43200 ignore-reload
> ignore-no-store override-expire override-lastmod
>
>
> ###################################################
> cat /etc/squid/updatesites.txt
>
> ([^.]+.|)apple.com
> ([^.]+\.)?(download|(windows)?update)\.(microsoft\.)?com
> ([^.]+\.)?adobe.com
> ([^.]+\.)?java.com
> ([^.]+\.)?sun.com
> ([^.]+\.)?oracle.com
> ([^.]+\.)?apple.com
> ([^.]+\.)?apple.com
> ([^.]+\.)?ubuntu.com
> ([^.]+\.)?steampowered.com
> ([^.]+\.)?google.com
> #########################################
>
>  cat /etc/squid/storeid_rewrite.conf
> ^http:\/\/[^\.]+\.phobos\.apple\.com\/(.*) http://appupdates.apple.squid.
> internal/$1
> ^http:\/\/[^\.]+\.cs\.steampowered\.com\/(.*) http:
> //steamupdates.squid.internal/$1
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160923/c719fff0/attachment.htm>

From nilesh.gavali at tcs.com  Fri Sep 23 17:17:20 2016
From: nilesh.gavali at tcs.com (nilesh.gavali at tcs.com)
Date: Fri, 23 Sep 2016 22:47:20 +0530
Subject: [squid-users] Squid stop working
Message-ID: <OF0F139F4F.83BD7AEF-ON80258037.005EF14D-80258037.005EF8C6@tcs.com>

All;
Recently facing issue of squid stop working. it was working fine when 
there was little load on it. 
Our system administrator configure group policy to enabled proxy on all 
desktops with exception in proxy settings to local network.
Reason to increase load on proxy is; Google chrome browser - when opened, 
it try to open chrome sign-in page which redirect to client1.google.com 
and so on.
all these request get denied on proxy. Same with IE's bing home page try 
to connect MS site.

So I carry out following changes to squid config file
Cache_dir value from 1024 to 10240.
Since we have Kerberos auth cofnigured for SSO, I also increase auth_param 
negotiate children from 10 to 20.

after this it start working as of now.

I need to know what all caution I need to take more to avoid further 
issue.
attached is squidclient o/p and squid.conf for analysis.






Thanks & Regards
Nilesh Suresh Gavali

=====-----=====-----=====
Notice: The information contained in this e-mail
message and/or attachments to it may contain 
confidential or privileged information. If you are 
not the intended recipient, any dissemination, use, 
review, distribution, printing or copying of the 
information contained in this e-mail message 
and/or attachments to it are strictly prohibited. If 
you have received this communication in error, 
please notify us by reply e-mail or telephone and 
immediately and permanently delete the message 
and any attachments. Thank you


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160923/d5d93f40/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Squid_23092016.conf
Type: application/octet-stream
Size: 4520 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160923/d5d93f40/attachment.obj>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Squid Info.txt
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160923/d5d93f40/attachment.txt>

From bycn82 at gmail.com  Fri Sep 23 17:31:08 2016
From: bycn82 at gmail.com (Bill Yuan)
Date: Sat, 24 Sep 2016 01:31:08 +0800
Subject: [squid-users] Question about the url rewrite before proxy out
In-Reply-To: <CAC+JH2zbr3v2DPFG=xy_mZv83o+hF5CBvsD_qWZ4PF40eheKQw@mail.gmail.com>
References: <CAC+JH2w=9Bk2jh-MM-WG-UWbOcyXKSL8rrKNiKPGtgHw7u9tcw@mail.gmail.com>
 <003401d2148e$ddabc8a0$990359e0$@filter.luko.org>
 <201609220956.29355.Antony.Stone@squid.open.source.it>
 <008901d214ba$e0adba00$a2092e00$@filter.luko.org>
 <eab797dc-9221-c7d3-5b61-4a1b98c40850@measurement-factory.com>
 <CAC+JH2zbr3v2DPFG=xy_mZv83o+hF5CBvsD_qWZ4PF40eheKQw@mail.gmail.com>
Message-ID: <CAC+JH2w_WxFXanik_7w1ts1fwn+ojJ+exnCvYrKZrEt5Z+y-Fw@mail.gmail.com>

Did not resolve yet. anyone can help to provide an example plase



On 23 September 2016 at 07:57, Bill Yuan <bycn82 at gmail.com> wrote:

> Thanks for replying
>
> I see, it is a url rewrite  and i am trying to find an sample to have a
> test
>
>
> the content are not required to be updated if it is a image
>
>
> On Thursday, September 22, 2016, Alex Rousskov <
> rousskov at measurement-factory.com> wrote:
>
>> On 09/22/2016 04:20 AM, squid-users at filter.luko.org wrote:
>>
>> > Then not only the request needs to be rewritten, but probably the
>> > page content too. [...] If that is the case,
>> > then Squid doesn't seem like the right tool for the job.
>>
>> Why not? If rewriting is needed, an ICAP or eCAP service can rewrite the
>> response body before Squid serves it.
>>
>> However, in practice, this kind of page rewriting does not work very
>> well (regardless of which software is doing the rewrite) because many
>> page URLs are formed dynamically on the client side (by Javascript code).
>>
>> Alex.
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160924/f50fae56/attachment.htm>

From ahmed.zaeem at netstream.ps  Fri Sep 23 17:44:22 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Fri, 23 Sep 2016 20:44:22 +0300
Subject: [squid-users] squid with apple updates caching problem !
In-Reply-To: <CA+sSnVbfBGhQ8dQMixJOZCHJeSE=OyVW5arE_5nxz4jHSvj8mw@mail.gmail.com>
References: <78A7B9B4-B331-4F2F-A6EB-69E70E029C02@netstream.ps>
 <CA+sSnVbfBGhQ8dQMixJOZCHJeSE=OyVW5arE_5nxz4jHSvj8mw@mail.gmail.com>
Message-ID: <204FAA62-3C53-4C04-A0E6-7CC4A1D2AFF6@netstream.ps>

hi mate 

could you provide me sample working config that you have ?

I?m appreciating it much 


cheers 

> On Sep 23, 2016, at 5:37 PM, Hardik Dangar <hardikdangar+squid at gmail.com> wrote:
> 
> refresh_pattern -i appldnld\.apple\.com 43200 100% 43200  reload-into-ims
> 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160923/45f0aec2/attachment.htm>

From bycn82 at gmail.com  Fri Sep 23 17:45:37 2016
From: bycn82 at gmail.com (Bill Yuan)
Date: Sat, 24 Sep 2016 01:45:37 +0800
Subject: [squid-users] help to configure squid in below requirement
Message-ID: <CAC+JH2zPLWidaE=XpScZiMcE2e+gJVg=miTXtkO2vZ6Y8j_sEw@mail.gmail.com>

I want to configure squid as a "traffic bouncing" server as below

I am running squid on 192.168.1.1:3128
when I request URL "http://192.168.1.1:3128/www.yahoo.com/abc.png"
I hope I can get the png from "http://www.yahoo.com/abc.png"

Regards,
Bill
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160924/4b5d6a5b/attachment.htm>

From hardikdangar+squid at gmail.com  Fri Sep 23 18:12:03 2016
From: hardikdangar+squid at gmail.com (Hardik Dangar)
Date: Fri, 23 Sep 2016 23:42:03 +0530
Subject: [squid-users] help to configure squid in below requirement
In-Reply-To: <CAC+JH2zPLWidaE=XpScZiMcE2e+gJVg=miTXtkO2vZ6Y8j_sEw@mail.gmail.com>
References: <CAC+JH2zPLWidaE=XpScZiMcE2e+gJVg=miTXtkO2vZ6Y8j_sEw@mail.gmail.com>
Message-ID: <CA+sSnVbGpRy4vta5y6hS_6T48WewXRwDYD74za7+cuvnwOWiww@mail.gmail.com>

Hey Bill,

Look at,
http://www.ex-parrot.com/pete/upside-down-ternet.html
also this may help,
https://blog.g0tmi1k.com/2011/04/playing-with-traffic-squid/



On Fri, Sep 23, 2016 at 11:15 PM, Bill Yuan <bycn82 at gmail.com> wrote:

> I want to configure squid as a "traffic bouncing" server as below
>
> I am running squid on 192.168.1.1:3128
> when I request URL "http://192.168.1.1:3128/www.yahoo.com/abc.png"
> I hope I can get the png from "http://www.yahoo.com/abc.png"
>
> Regards,
> Bill
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160923/83acc082/attachment.htm>

From squid at buglecreek.com  Fri Sep 23 22:25:20 2016
From: squid at buglecreek.com (squid at buglecreek.com)
Date: Fri, 23 Sep 2016 16:25:20 -0600
Subject: [squid-users] Accelerator Mode - HSTS and Redirect
In-Reply-To: <dc4e839f-dceb-5850-2c71-20a85c459b53@treenet.co.nz>
References: <1474591520.68413.734388465.08421690@webmail.messagingengine.com>
 <dc4e839f-dceb-5850-2c71-20a85c459b53@treenet.co.nz>
Message-ID: <1474669520.1854307.735286985.7B479AE8@webmail.messagingengine.com>

Thank you.  Just want to make sure I understand before we dive in.

On Thu, Sep 22, 2016, at 09:03 PM, Amos Jeffries wrote:
> On 23/09/2016 12:45 p.m., creditu wrote:
> > We have been using squid in accelerator mode for a number of years. In
> > the current setup we have the squid frontends that send all the http
> > requests to the backend apache webservers using a simple redirect
> > script.  We need to switch to https for the public presence.
> 
> redirect/rewrite script is very rarely a suitable way to do this for
> reverse-proxy.
> 
> Use cache_peer to configure what backend servers exist and
> cache_peer_access rules to determine which one(s) any given request can
> be sent to.
> 
> The backends should be capable of accepting the traffic as if the proxy
> were not there. If for some reason it has to have a different domain
> name (actual need for this is rare), then the cache_peer forcedomain=
> option can be used.
> > 
> > So, our initial thought would be to use https_port for public HTTPS
> > presence and send the requests using cache_peer to the backend apache
> > servers using plain http.  Basically terminating HTTPS from clients and
> > relaying it to backend servers using HTTP.  
> > 
> > We will need to implement HSTS at some point (i.e.
> > Strict-Transport-Security: max-age=8888; includeSubDomains; preload),
> > will we be able to do this in the above scenario.
> 
> Yes. Provided you can get rid of that redirect/rewrite script. The
> background things cache_peer logic does to the traffic will be needed
> for the HTTPS transition.

We will get rid of the script, but, not sure I understand the rest of
the statement.  Can you elaborate?  Since  HSTS is only set when there
is a secure connection it seems that I would have send to the backend
via https and set the Strict-Transport . . . header on the backend
Apache servers (ssl.conf) so the reply would be sent back to the
Internet user via Squid?    
> 
> > Also, we will initially be providing both http and https, but will need
> > to stop http at some point.  Is there a way to redirect the clients that
> > try to connect via http to use https with squid?  Something like the
> > rewrite engine in apache?
> 
> cache_peer can be configured to contact the peer over TLS. This can be
> done individually, and before the HSTS gets added for public viewing.

I'm sure I'm missing something here.  What I will need to do is force
Internet users who come to us over via http to use https instead. 
Something like what happens when someone types http://www.google.com
they get sent to https://www.google.com. This is pretty simple going
straight to an Apache server, but I haven't seen a way to do it directly
with Squid.  In a very quick test on some non-production systems I sent
a http request through the squid and did the redirect on the backend
Apache server.  I assume in the Apache config I would do something like
this:

VirtualHost *:80>
   ServerName www.example.com
   Redirect permanent / https://SquidPublicIP/
</VirtualHost>

 Just trying to understand how this would work.  Thanks Again. 
> > 
> > We use RH 6.x which comes with squid 3.1.  Thanks for any feedback. 
> 
> For your particular use a build of that with OpenSSL support should be
> okay. But if you can, an upgrade to more recent version would be better
> as there have been some important OpenSSL and TLS protocol changes since
> 3.1 was designed.
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From bpk678 at gmail.com  Fri Sep 23 22:53:18 2016
From: bpk678 at gmail.com (Brendan Kearney)
Date: Fri, 23 Sep 2016 18:53:18 -0400
Subject: [squid-users] issues with amazonaws & cloudfront
In-Reply-To: <1474640911785-4679665.post@n4.nabble.com>
References: <1474640911785-4679665.post@n4.nabble.com>
Message-ID: <57E5B25E.2020509@gmail.com>

On 09/23/2016 10:28 AM, lravelo wrote:
> Good morning!
>
> I have four squid 3.3.8 proxies load balanced behind two VIPs (in groups of
> two) using least connections load balancing.  I've been having issues with
> the .amazonaws.com and .cloudfront.com domains.  We use TCP load balancing
> and not HTTP load balancing.  Basically what happens is that these web pages
> request a keep-alive and on the browser console I'm seeing messages saying
> that proxy authentication failed and some "ERR_CACHE_ACCESS_DENIED 0" errors
> as well.  We do have kerberos authentication for SSO.  Not sure if anyone
> else has had this issue and what's been done to resolve it.
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/issues-with-amazonaws-cloudfront-tp4679665.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
what is the DNS name of the VIP you load balance behind?  does the DNS 
name match the HTTP principal you created in kerberos?  for example:

dns name: proxy.domain.tld
kerberos principal: HTTP/proxy.domain.tld at REALM

the keytabs that you created, they have to be identical for each load 
balanced pool member.  you should have made one keytab, and securely 
copied it to each pool member.  if they are not exactly identical, one 
proxy will work (the one with the latest keytab created, because the 
KVNO will be ordinally greater[use "klist -Kket /path/to/file.keytab]) 
and the other wont work.


From ahmed.zaeem at netstream.ps  Sat Sep 24 06:13:20 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Sat, 24 Sep 2016 09:13:20 +0300
Subject: [squid-users] squid binding outgoing ip with a username auth
Message-ID: <5C0C7846-D9E8-4235-A5C6-FF925A4B987E@netstream.ps>

hi folks .

i have many ips on same server .
also i  have  basic_ncsa auth type on squid .

say i have 3 ips  and i created 3 users .

the issue i have now is any user can use any outgoing address .

let me explain below :


auth_param basic program /lib/squid/basic_ncsa_auth /etc/squid/squid_user
acl ncsa_users proxy_auth REQUIRED
auth_param basic children 100
http_access allow ncsa_users

###############
http_port 100.160.238.0:17648
http_port 100.160.238.1:48049
http_port 100.160.238.2:26394

#############
acl  ip1myip 100.160.238.0
acl  ip2 myip 100.160.238.1
acl  ip3 myip 100.160.238.2
#############

tcp_outgoing_address 100.160.238.0 ip1
tcp_outgoing_address 100.160.238.1 ip2
tcp_outgoing_address 100.160.238.2 ip3

########################

i created 3 users :

htpasswd -cdb   /etc/squid/squid_user user1 user1
htpasswd -cdb   /etc/squid/squid_user user2 user2
htpasswd -cdb   /etc/squid/squid_user user3 user3

#################



now if user1 connected to 100.160.238.0:17648 it will be able to use it 
also if connected to   100.160.238.1:48049 also will be able .

 and so for 100.160.238.2:26394.


the question is
 how can i let user1 only use  100.160.238.0:17648  and user2 only use  100.160.238.1:48049  and user3 only use  100.160.238.2:26394 ???


i don?t want as an example user1  if he tried   100.160.238.1:48049 to get it working 

thank you 




From squid3 at treenet.co.nz  Sat Sep 24 21:58:05 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 25 Sep 2016 10:58:05 +1300
Subject: [squid-users] squid binding outgoing ip with a username auth
In-Reply-To: <5C0C7846-D9E8-4235-A5C6-FF925A4B987E@netstream.ps>
References: <5C0C7846-D9E8-4235-A5C6-FF925A4B987E@netstream.ps>
Message-ID: <edd4ef36-b783-3afc-6c29-7781479ac796@treenet.co.nz>

On 24/09/2016 6:13 p.m., --Ahmad-- wrote:
> hi folks .
> 
> i have many ips on same server .
> also i  have  basic_ncsa auth type on squid .
> 
> say i have 3 ips  and i created 3 users .
> 
> the issue i have now is any user can use any outgoing address .
> 
> let me explain below :
> 
> 
> auth_param basic program /lib/squid/basic_ncsa_auth /etc/squid/squid_user
> acl ncsa_users proxy_auth REQUIRED
> auth_param basic children 100
> http_access allow ncsa_users
> 
> ###############
> http_port 100.160.238.0:17648
> http_port 100.160.238.1:48049
> http_port 100.160.238.2:26394
> 
> #############
> acl  ip1myip 100.160.238.0
> acl  ip2 myip 100.160.238.1
> acl  ip3 myip 100.160.238.2
> #############
> 
> tcp_outgoing_address 100.160.238.0 ip1
> tcp_outgoing_address 100.160.238.1 ip2
> tcp_outgoing_address 100.160.238.2 ip3
> 

'myip' matches the Squid IP address.
tcp_outgoing_address is what sets the Squid IP address.
See any problem with using the Squid IP address current value to set the
Squid IP address?

Use the myportname ACL instead. In your above config it will match the
IP:port string on the htp_port line. For example:

  acl ip0 myportname 100.160.238.0:17648
  tcp_outgoing_address 100.160.238.0 ip0

Or you can add a name= parameter to each port to set a custom name for
it that the myportname ACL looks for.


> ########################
> 
> i created 3 users :
> 
> htpasswd -cdb   /etc/squid/squid_user user1 user1
> htpasswd -cdb   /etc/squid/squid_user user2 user2
> htpasswd -cdb   /etc/squid/squid_user user3 user3
> 
> #################
> 
> 
> 
> now if user1 connected to 100.160.238.0:17648 it will be able to use it 
> also if connected to   100.160.238.1:48049 also will be able .
> 
>  and so for 100.160.238.2:26394.
> 
> 
> the question is
>  how can i let user1 only use  100.160.238.0:17648  and user2 only use  100.160.238.1:48049  and user3 only use  100.160.238.2:26394 ???
> 

Use the ext_file_userip_acl helper. The format for entries in the helper
config file is listed in the man page:
<http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_file_userip_acl.html>

Replace the line "http_access allow ncsa_users" with the following:

 external_acl_type userIp %SRC /usr/bin/ext_file_userip_acl -f
/etc/squid/userIP.conf
 acl userIp external userIp

 http_access deny !ncsa_users
 http_access allow userIp

NP: that is all. Do not add userIp check to tcp_outgoing_address lines.


After all the above changes your squid.conf should look something like this:

 ## ... the default http_access rules at the top ...
 ##
 ## Your local custom rules go here:

 auth_param basic program /lib/squid/basic_ncsa_auth \
    /etc/squid/squid_user
 auth_param basic children 100

 external_acl_type userIp %SRC %LOGIN /lib/squid/ext_file_userip_acl \
    -f /etc/squid/userIP.conf

 acl ncsa_users proxy_auth REQUIRED
 acl userIp external userIp

 http_access deny !ncsa_users
 http_access allow userIp
 http_access deny all

 ##
 http_port 100.160.238.0:17648 name=0
 acl ip0 myportname 0
 tcp_outgoing_address 100.160.238.0 ip0

 http_port 100.160.238.1:48049 name=1
 acl ip1 myportname 1
 tcp_outgoing_address 100.160.238.1 ip1

 http_port 100.160.238.2:26394 name=2
 acl ip2 myportname 2
 tcp_outgoing_address 100.160.238.2 ip2


Amos



From squid3 at treenet.co.nz  Sat Sep 24 22:06:32 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 25 Sep 2016 11:06:32 +1300
Subject: [squid-users] Errors in cache.log
In-Reply-To: <1474638603998-4679664.post@n4.nabble.com>
References: <1474567862731-4679651.post@n4.nabble.com>
 <5756dcf2-f88b-1f15-9b43-dff112f17894@treenet.co.nz>
 <1474638603998-4679664.post@n4.nabble.com>
Message-ID: <ec63ead9-72cc-71da-9e00-e607d02c5559@treenet.co.nz>

On 24/09/2016 1:50 a.m., erdosain9 wrote:
> Hi,
> Thanks a lot.
> But, i really dont get something...
> about delay pools
> 
> you tell me that
> 
> 
> 
> Amos Jeffries wrote
>> Note: requests which match the "redes_sociales adminis" ACLs have BOTH
>> pool #1 and pool #4 restrictions applied to them.
>>
>> Note: requests which match the "stream adminis" ACLs have BOTH pool #2
>> and pool #4 restrictions applied to them.
>> Amos
> 
> And the same for the others delay pools...
> But, what i think that im doing is apply for example
> 
> the web pages of "redes_sociales"(social network) to "adminis"... i mean,
> that bandwith for those webs... and then the other delay pools for bandwith
> for youtube, and other delay pool for all the other webs........
> 
> it is not right??

You have one pool which says "allow adminis" and another that says
"allow redes_sociales adminis".

That means a request that matches redes_sociales AND adminis will match
both those pools.

If a request matches the ACLs to have two different pools assigned to
it. Then both those pools will be assigned. The traffic accounting then
interacts in some weird ways due to bugs and which order the pools have
in your squid.conf. The request may be over- or under- counted and the
traffic amount used subtracted from one or both pools.

So for now it is best to make sure only one pool can match at a time,
and then you can be sure what any given request will have happen to it.

Amos



From squid3 at treenet.co.nz  Sat Sep 24 22:30:42 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 25 Sep 2016 11:30:42 +1300
Subject: [squid-users] Squid stop working
In-Reply-To: <OF0F139F4F.83BD7AEF-ON80258037.005EF14D-80258037.005EF8C6@tcs.com>
References: <OF0F139F4F.83BD7AEF-ON80258037.005EF14D-80258037.005EF8C6@tcs.com>
Message-ID: <93286fb7-c964-1673-1f4e-c7123d974ba6@treenet.co.nz>

On 24/09/2016 5:17 a.m., nilesh.gavali at tcs.com wrote:
> All;
> Recently facing issue of squid stop working. it was working fine when 
> there was little load on it. 
> Our system administrator configure group policy to enabled proxy on all 
> desktops with exception in proxy settings to local network.
> Reason to increase load on proxy is; Google chrome browser - when opened, 
> it try to open chrome sign-in page which redirect to client1.google.com 
> and so on.
> all these request get denied on proxy. Same with IE's bing home page try 
> to connect MS site.
> 
> So I carry out following changes to squid config file
> Cache_dir value from 1024 to 10240.

cache_dir has nothing to do with access permissions. That is simply a
storage space for HTTP response objects.

> Since we have Kerberos auth cofnigured for SSO, I also increase auth_param 
> negotiate children from 10 to 20.
> 
> after this it start working as of now.


So lets get this straight.

When you increased the number of concurrent logins the proxy could
process to be 20. The proxy started to work more happily handling ~20
concurrent users, at ~20 requests per second.


Hint: Does the number 20 occuring a lot in those values give you any
ideas about the problem?


> 
> I need to know what all caution I need to take more to avoid further 
> issue.

Several things you can do (in this order of preference):

* upgrade to a supported Squid proxy version.
 3.1 is more than 5 years out of date. Current stable is 3.5.21. If your
operating system does not provide a more recent version it also needs to
be upgraded.

* ensure that persistent connections to clients is enabled.
 This will reduce the amount of authentications needed (thus alter the
helper load).

* increase the auth helper children value a bit more.
 Check the report (squidclient mgr:negotiateauthenticator) to see how
much each child is processing, the first should have a lot of uses, the
last none or nearly none. If the last child is handling many requests
then you could benefit from some more being started.


Amos



From squid3 at treenet.co.nz  Sat Sep 24 23:40:19 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 25 Sep 2016 12:40:19 +1300
Subject: [squid-users] Accelerator Mode - HSTS and Redirect
In-Reply-To: <1474669520.1854307.735286985.7B479AE8@webmail.messagingengine.com>
References: <1474591520.68413.734388465.08421690@webmail.messagingengine.com>
 <dc4e839f-dceb-5850-2c71-20a85c459b53@treenet.co.nz>
 <1474669520.1854307.735286985.7B479AE8@webmail.messagingengine.com>
Message-ID: <64f6b9e8-4b55-8e85-63b9-231e3c45fcf5@treenet.co.nz>

On 24/09/2016 10:25 a.m., squid wrote:
> Thank you.  Just want to make sure I understand before we dive in.
> 
> On Thu, Sep 22, 2016, at 09:03 PM, Amos Jeffries wrote:
>> On 23/09/2016 12:45 p.m., creditu wrote:
>>> We have been using squid in accelerator mode for a number of years. In
>>> the current setup we have the squid frontends that send all the http
>>> requests to the backend apache webservers using a simple redirect
>>> script.  We need to switch to https for the public presence.
>>
>> redirect/rewrite script is very rarely a suitable way to do this for
>> reverse-proxy.
>>
>> Use cache_peer to configure what backend servers exist and
>> cache_peer_access rules to determine which one(s) any given request can
>> be sent to.
>>
>> The backends should be capable of accepting the traffic as if the proxy
>> were not there. If for some reason it has to have a different domain
>> name (actual need for this is rare), then the cache_peer forcedomain=
>> option can be used.
>>>
>>> So, our initial thought would be to use https_port for public HTTPS
>>> presence and send the requests using cache_peer to the backend apache
>>> servers using plain http.  Basically terminating HTTPS from clients and
>>> relaying it to backend servers using HTTP.  
>>>
>>> We will need to implement HSTS at some point (i.e.
>>> Strict-Transport-Security: max-age=8888; includeSubDomains; preload),
>>> will we be able to do this in the above scenario.
>>
>> Yes. Provided you can get rid of that redirect/rewrite script. The
>> background things cache_peer logic does to the traffic will be needed
>> for the HTTPS transition.
> 
> We will get rid of the script, but, not sure I understand the rest of
> the statement.  Can you elaborate?

By "background things" I mean the code inside Squid. reverse-proxy logic
does things to the request and reply when sending to a peer that are not
done on DIRECT requests to servers.

> Since  HSTS is only set when there
> is a secure connection it seems that I would have send to the backend
> via https and set the Strict-Transport . . . header on the backend
> Apache servers (ssl.conf) so the reply would be sent back to the
> Internet user via Squid?

No. The reply is sent back along the same TCP connection the request was
received over. Always.

For a reverse-proxy it does not matter if that connection happens to be
TLS encrypted or not.

If the cache_peer line in squid.conf says to use port 80 that will be
the server port used. Likewise it could say port 443 and use TLS to get
there. The server connection is completely independent from the client
connections.

HSTS simply tells clients to not bother using http:// to contact the
domain. Always to try https:// first. A properly setup reverse-proxy
does not care about HSTS. It will simply listen on the port it is
configured to listen on and send to the server it is configured to send to.



>>
>>> Also, we will initially be providing both http and https, but will need
>>> to stop http at some point.  Is there a way to redirect the clients that
>>> try to connect via http to use https with squid?  Something like the
>>> rewrite engine in apache?
>>
>> cache_peer can be configured to contact the peer over TLS. This can be
>> done individually, and before the HSTS gets added for public viewing.
> 
> I'm sure I'm missing something here.  What I will need to do is force
> Internet users who come to us over via http to use https instead. 
> Something like what happens when someone types http://www.google.com
> they get sent to https://www.google.com. This is pretty simple going
> straight to an Apache server, but I haven't seen a way to do it directly
> with Squid.  In a very quick test on some non-production systems I sent
> a http request through the squid and did the redirect on the backend
> Apache server.  I assume in the Apache config I would do something like
> this:
> 
> VirtualHost *:80>
>    ServerName www.example.com
>    Redirect permanent / https://SquidPublicIP/
> </VirtualHost>
> 
>  Just trying to understand how this would work.  Thanks Again. 

Squid would listen on port 80 and 'deny' any traffic arriving in that
port with a 30x redirect pointing at the relevant https:// URL.

 http_port 80 accel
 acl HTTP proto HTTP
 deny_info 301:https://%H%R HTTP
 http_access deny HTTP

Zero involvement from the server.

The current releases of Squid should be able to also add a static STS
header to the denial reply if you want to use HSTS.

But that is all for later. First get the proxy connected to the server
working with the traffic (HTTP-only?) that your site receives _right now_.

Amos



From erdosain9 at gmail.com  Sun Sep 25 02:50:38 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Sat, 24 Sep 2016 19:50:38 -0700 (PDT)
Subject: [squid-users] Errors in cache.log
In-Reply-To: <ec63ead9-72cc-71da-9e00-e607d02c5559@treenet.co.nz>
References: <1474567862731-4679651.post@n4.nabble.com>
 <5756dcf2-f88b-1f15-9b43-dff112f17894@treenet.co.nz>
 <1474638603998-4679664.post@n4.nabble.com>
 <ec63ead9-72cc-71da-9e00-e607d02c5559@treenet.co.nz>
Message-ID: <1474771838380-4679679.post@n4.nabble.com>

Hi. Thank you.
I fail to understand.
In other words, the delay pools are poorly structured? (or you're telling me
to deactivated the delay pools, if they are causing a problem)

i think that you're telling me that are poorly made.

So, for example.

if i want to apply this acl

acl stream url_regex -i \.flv$ 
acl stream url_regex -i \.mp4$ 
acl stream url_regex -i watch? 
acl stream url_regex -i youtube 
acl stream url_regex -i facebook 
acl stream url_regex -i fbcdn\.net\/v\/(.*\.mp4)\? 
acl stream url_regex -i fbcdn\.net\/v\/(.*\.jpg)\? 
acl stream url_regex -i akamaihd\.net\/v\/(.*\.mp4)\? 
acl stream url_regex -i akamaihd\.net\/v\/(.*\.jpg)\? 

to "adminis" but, i want that "adminis" have one bandwith for those webs
(acl "stream") and other bandwith for the others webs??? how would it be?

I think I have seen tutorials where the delay pools were made in this way.
or I screwed up.....

Thanks again.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Errors-in-cache-log-tp4679651p4679679.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Sun Sep 25 03:46:45 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 25 Sep 2016 16:46:45 +1300
Subject: [squid-users] Errors in cache.log
In-Reply-To: <1474771838380-4679679.post@n4.nabble.com>
References: <1474567862731-4679651.post@n4.nabble.com>
 <5756dcf2-f88b-1f15-9b43-dff112f17894@treenet.co.nz>
 <1474638603998-4679664.post@n4.nabble.com>
 <ec63ead9-72cc-71da-9e00-e607d02c5559@treenet.co.nz>
 <1474771838380-4679679.post@n4.nabble.com>
Message-ID: <7d0acc3e-502d-000c-f227-4e5902e47ff1@treenet.co.nz>

On 25/09/2016 3:50 p.m., erdosain9 wrote:
> Hi. Thank you.
> I fail to understand.
> In other words, the delay pools are poorly structured? (or you're telling me
> to deactivated the delay pools, if they are causing a problem)
> 
> i think that you're telling me that are poorly made.
> 
> So, for example.
> 
> if i want to apply this acl
> 
> acl stream url_regex -i \.flv$ 
> acl stream url_regex -i \.mp4$ 
> acl stream url_regex -i watch? 
> acl stream url_regex -i youtube 
> acl stream url_regex -i facebook 
> acl stream url_regex -i fbcdn\.net\/v\/(.*\.mp4)\? 
> acl stream url_regex -i fbcdn\.net\/v\/(.*\.jpg)\? 
> acl stream url_regex -i akamaihd\.net\/v\/(.*\.mp4)\? 
> acl stream url_regex -i akamaihd\.net\/v\/(.*\.jpg)\? 
> 
> to "adminis" but, i want that "adminis" have one bandwith for those webs
> (acl "stream") and other bandwith for the others webs??? how would it be?
> 
> I think I have seen tutorials where the delay pools were made in this way.
> or I screwed up.....

You need to do this:

 delay_access X allow adminis stream
 ...
 delay_access Y allow adminis !stream


instead of this:

 delay_access X allow adminis stream
 ...
 delay_access Y allow adminis


Amos


From michael.pelletier at palmbeachschools.org  Sun Sep 25 04:29:14 2016
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Sun, 25 Sep 2016 00:29:14 -0400
Subject: [squid-users] How to log url_rewrite results
Message-ID: <CAEnCSG5zZiM05WsnvB6jtDNB1yRyDNf6sEB=gFKjU75R=4Nhpg@mail.gmail.com>

Hello,

I can not get %et to log anything. What am I missing?

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160925/a60eb834/attachment.htm>

From squid3 at treenet.co.nz  Sun Sep 25 10:40:20 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 25 Sep 2016 23:40:20 +1300
Subject: [squid-users] How to log url_rewrite results
In-Reply-To: <CAEnCSG5zZiM05WsnvB6jtDNB1yRyDNf6sEB=gFKjU75R=4Nhpg@mail.gmail.com>
References: <CAEnCSG5zZiM05WsnvB6jtDNB1yRyDNf6sEB=gFKjU75R=4Nhpg@mail.gmail.com>
Message-ID: <7e704888-f4e3-4cc7-0e4f-420cda3fb272@treenet.co.nz>

On 25/09/2016 5:29 p.m., Michael Pelletier wrote:
> Hello,
> 
> I can not get %et to log anything. What am I missing?
> 

%et is the tag produced by an external_acl_type helper, nothing to do
with url_rewrite_program.

If you are using a Squid-3.4+ AND if your helper is updated to use the
key=value pair protocol for those Squid versions. Then you could log
%note{status}:%note{url} for redirections, or %note{url-rewrite} for
re-written URLs.

Amos



From erdosain9 at gmail.com  Sun Sep 25 18:36:40 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Sun, 25 Sep 2016 11:36:40 -0700 (PDT)
Subject: [squid-users] Errors in cache.log
In-Reply-To: <7d0acc3e-502d-000c-f227-4e5902e47ff1@treenet.co.nz>
References: <1474567862731-4679651.post@n4.nabble.com>
 <5756dcf2-f88b-1f15-9b43-dff112f17894@treenet.co.nz>
 <1474638603998-4679664.post@n4.nabble.com>
 <ec63ead9-72cc-71da-9e00-e607d02c5559@treenet.co.nz>
 <1474771838380-4679679.post@n4.nabble.com>
 <7d0acc3e-502d-000c-f227-4e5902e47ff1@treenet.co.nz>
Message-ID: <1474828600378-4679683.post@n4.nabble.com>

#Pools para ancho de Banda 
delay_pools 3 

###VELOCIDAD PARA REDES SOCIALES 
delay_class 1 1 
delay_parameters 1 10000/100000 
delay_access 1 allow adminis redes_sociales !stream 
delay_access 1 deny all 


#Limitar Video Streaming a 20k 
delay_class 2 1 
delay_parameters 2 20000/100000 
delay_access 2 allow adminis stream !redes_sociales
delay_access 2 deny all 


#Ancho de Banda Administracion 
delay_class 3 1 
delay_parameters 3 256000/256000 
delay_access 3 allow adminis !stream !redes_sociales 
delay_access 3 deny all 


So, here i have 3 different banwith for same people (adminis) in differents
webs... like 10kb if they go to "facebook", 20kb, if they go to "youtube",
and 256kb for all the rest......... 

this would be fine?

Thanks!





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Errors-in-cache-log-tp4679651p4679683.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Sun Sep 25 20:09:57 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 26 Sep 2016 09:09:57 +1300
Subject: [squid-users] Errors in cache.log
In-Reply-To: <1474828600378-4679683.post@n4.nabble.com>
References: <1474567862731-4679651.post@n4.nabble.com>
 <5756dcf2-f88b-1f15-9b43-dff112f17894@treenet.co.nz>
 <1474638603998-4679664.post@n4.nabble.com>
 <ec63ead9-72cc-71da-9e00-e607d02c5559@treenet.co.nz>
 <1474771838380-4679679.post@n4.nabble.com>
 <7d0acc3e-502d-000c-f227-4e5902e47ff1@treenet.co.nz>
 <1474828600378-4679683.post@n4.nabble.com>
Message-ID: <e0b2c96c-03cc-717a-0c26-2d6d6e854153@treenet.co.nz>

On 26/09/2016 7:36 a.m., erdosain9 wrote:
> #Pools para ancho de Banda 
> delay_pools 3 
> 
> ###VELOCIDAD PARA REDES SOCIALES 
> delay_class 1 1 
> delay_parameters 1 10000/100000 
> delay_access 1 allow adminis redes_sociales !stream 
> delay_access 1 deny all 
> 
> 
> #Limitar Video Streaming a 20k 
> delay_class 2 1 
> delay_parameters 2 20000/100000 
> delay_access 2 allow adminis stream !redes_sociales
> delay_access 2 deny all 
> 
> 
> #Ancho de Banda Administracion 
> delay_class 3 1 
> delay_parameters 3 256000/256000 
> delay_access 3 allow adminis !stream !redes_sociales 
> delay_access 3 deny all 
> 
> 
> So, here i have 3 different banwith for same people (adminis) in differents
> webs... like 10kb if they go to "facebook", 20kb, if they go to "youtube",
> and 256kb for all the rest......... 
> 
> this would be fine?

Yes.

Amos



From ahmed.zaeem at netstream.ps  Sun Sep 25 21:28:59 2016
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Mon, 26 Sep 2016 00:28:59 +0300
Subject: [squid-users] squid binding outgoing ip with a username auth
In-Reply-To: <edd4ef36-b783-3afc-6c29-7781479ac796@treenet.co.nz>
References: <5C0C7846-D9E8-4235-A5C6-FF925A4B987E@netstream.ps>
 <edd4ef36-b783-3afc-6c29-7781479ac796@treenet.co.nz>
Message-ID: <96B41342-C71A-4453-9961-474BAD911EF7@netstream.ps>

hi amos , thanks  for reply .

but let me ask you other question  for clarification .


in  the section :
external_acl_type type-name %SRC %LOGIN /path/to/ext_file_userip_acl -f /path/to/config.file

now i see it has the form :
ip_addr[/netmask] username|@group|ALL|NONE


say i  have 3 users

user1
user2
and user3

======================
user1 ??> 100.160.238.0:17648
user2?>100.160.238.1:48049
user3??>100.160.238.2:26394
=================



will the  file /path/to/config.file  be like below ????


100.160.238.0 user1
100.160.238.1 user2
100.160.238.2 user3



kind regards 
> On Sep 25, 2016, at 12:58 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 24/09/2016 6:13 p.m., --Ahmad-- wrote:
>> hi folks .
>> 
>> i have many ips on same server .
>> also i  have  basic_ncsa auth type on squid .
>> 
>> say i have 3 ips  and i created 3 users .
>> 
>> the issue i have now is any user can use any outgoing address .
>> 
>> let me explain below :
>> 
>> 
>> auth_param basic program /lib/squid/basic_ncsa_auth /etc/squid/squid_user
>> acl ncsa_users proxy_auth REQUIRED
>> auth_param basic children 100
>> http_access allow ncsa_users
>> 
>> ###############
>> http_port 100.160.238.0:17648
>> http_port 100.160.238.1:48049
>> http_port 100.160.238.2:26394
>> 
>> #############
>> acl  ip1myip 100.160.238.0
>> acl  ip2 myip 100.160.238.1
>> acl  ip3 myip 100.160.238.2
>> #############
>> 
>> tcp_outgoing_address 100.160.238.0 ip1
>> tcp_outgoing_address 100.160.238.1 ip2
>> tcp_outgoing_address 100.160.238.2 ip3
>> 
> 
> 'myip' matches the Squid IP address.
> tcp_outgoing_address is what sets the Squid IP address.
> See any problem with using the Squid IP address current value to set the
> Squid IP address?
> 
> Use the myportname ACL instead. In your above config it will match the
> IP:port string on the htp_port line. For example:
> 
>  acl ip0 myportname 100.160.238.0:17648
>  tcp_outgoing_address 100.160.238.0 ip0
> 
> Or you can add a name= parameter to each port to set a custom name for
> it that the myportname ACL looks for.
> 
> 
>> ########################
>> 
>> i created 3 users :
>> 
>> htpasswd -cdb   /etc/squid/squid_user user1 user1
>> htpasswd -cdb   /etc/squid/squid_user user2 user2
>> htpasswd -cdb   /etc/squid/squid_user user3 user3
>> 
>> #################
>> 
>> 
>> 
>> now if user1 connected to 100.160.238.0:17648 it will be able to use it 
>> also if connected to   100.160.238.1:48049 also will be able .
>> 
>> and so for 100.160.238.2:26394.
>> 
>> 
>> the question is
>> how can i let user1 only use  100.160.238.0:17648  and user2 only use  100.160.238.1:48049  and user3 only use 100.160.238.2:26394 ???
>> 
> 
> Use the ext_file_userip_acl helper. The format for entries in the helper
> config file is listed in the man page:
> <http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_file_userip_acl.html <http://www.squid-cache.org/Versions/v3/3.5/manuals/ext_file_userip_acl.html>>
> 
> Replace the line "http_access allow ncsa_users" with the following:
> 
> external_acl_type userIp %SRC /usr/bin/ext_file_userip_acl -f
> /etc/squid/userIP.conf
> acl userIp external userIp
> 
> http_access deny !ncsa_users
> http_access allow userIp
> 
> NP: that is all. Do not add userIp check to tcp_outgoing_address lines.
> 
> 
> After all the above changes your squid.conf should look something like this:
> 
> ## ... the default http_access rules at the top ...
> ##
> ## Your local custom rules go here:
> 
> auth_param basic program /lib/squid/basic_ncsa_auth \
>    /etc/squid/squid_user
> auth_param basic children 100
> 
> external_acl_type userIp %SRC %LOGIN /lib/squid/ext_file_userip_acl \
>    -f /etc/squid/userIP.conf
> 
> acl ncsa_users proxy_auth REQUIRED
> acl userIp external userIp
> 
> http_access deny !ncsa_users
> http_access allow userIp
> http_access deny all
> 
> ##
> http_port 100.160.238.0:17648 name=0
> acl ip0 myportname 0
> tcp_outgoing_address 100.160.238.0 ip0
> 
> http_port 100.160.238.1:48049 name=1
> acl ip1 myportname 1
> tcp_outgoing_address 100.160.238.1 ip1
> 
> http_port 100.160.238.2:26394 name=2
> acl ip2 myportname 2
> tcp_outgoing_address 100.160.238.2 ip2
> 
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org <mailto:squid-users at lists.squid-cache.org>
> http://lists.squid-cache.org/listinfo/squid-users <http://lists.squid-cache.org/listinfo/squid-users>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160926/cdb4933c/attachment.htm>

From squid3 at treenet.co.nz  Sun Sep 25 21:30:52 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 26 Sep 2016 10:30:52 +1300
Subject: [squid-users] squid binding outgoing ip with a username auth
In-Reply-To: <3B0A5DF2-C13B-4B83-B997-E8E084A68AD5@gmail.com>
References: <5C0C7846-D9E8-4235-A5C6-FF925A4B987E@netstream.ps>
 <edd4ef36-b783-3afc-6c29-7781479ac796@treenet.co.nz>
 <3B0A5DF2-C13B-4B83-B997-E8E084A68AD5@gmail.com>
Message-ID: <f5f1c4f8-9f52-b390-4629-a8c2f44ee8b2@treenet.co.nz>

On 26/09/2016 10:28 a.m., Ahmed Alzaeem wrote:
> hi amos , thanks  for reply .
> 
> but let me ask you other question  for clarification .
> 
> 
> in  the section :
> external_acl_type type-name %SRC %LOGIN /path/to/ext_file_userip_acl -f /path/to/config.file
> 
> now i see it has the form :
> ip_addr[/netmask] username|@group|ALL|NONE
> 
> 
> say i  have 3 users
> 
> user1
> user2
> and user3
> 
> ======================
> user1 ??> 100.160.238.0:17648
> user2?>100.160.238.1:48049
> user3??>100.160.238.2:26394
> =================
> will the  file /path/to/config.file  be like below ????
> 
> 
> 100.160.238.0 user1
> 100.160.238.1 user2
> 100.160.238.2 user3
> 

Yes. Exactly so.

Amos



From sebelk at gmail.com  Mon Sep 26 00:28:09 2016
From: sebelk at gmail.com (Sergio Belkin)
Date: Sun, 25 Sep 2016 21:28:09 -0300
Subject: [squid-users] How does squid know the url of https?
Message-ID: <CABZC=5wX-foQdpcmerMoWvfqqcKfX4uyAevgj6=83qAsLG+Rjw@mail.gmail.com>

I've read http://wiki.squid-cache.org/Features/SslBump

But I don't understand exactly how does squid to know the url.

Does squid a decryption is the client request?

Thanks in advance!

-- 
--
Sergio Belkin
LPIC-2 Certified - http://www.lpi.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160925/05fad8d8/attachment.htm>

From squid3 at treenet.co.nz  Mon Sep 26 04:38:02 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 26 Sep 2016 17:38:02 +1300
Subject: [squid-users] How does squid know the url of https?
In-Reply-To: <CABZC=5wX-foQdpcmerMoWvfqqcKfX4uyAevgj6=83qAsLG+Rjw@mail.gmail.com>
References: <CABZC=5wX-foQdpcmerMoWvfqqcKfX4uyAevgj6=83qAsLG+Rjw@mail.gmail.com>
Message-ID: <3fd61017-a7fb-f52d-149d-ae4ad36fc0ea@treenet.co.nz>

On 26/09/2016 1:28 p.m., Sergio Belkin wrote:
> I've read http://wiki.squid-cache.org/Features/SslBump
> 
> But I don't understand exactly how does squid to know the url.
> 
> Does squid a decryption is the client request?

Yes.

SSL-Bump is about performing an MITM interception attack on TLS traffic.
Decrypting it to get at the HTTP messages inside.

Since the original SslBump functionality is very much obsolete it is
perhapse best to read
<http://wiki.squid-cache.org/Features/SslPeekAndSplice> which explains
how the current releases do it.

Amos



From jvdwesthuiz at shoprite.co.za  Mon Sep 26 06:59:45 2016
From: jvdwesthuiz at shoprite.co.za (Jasper Van Der Westhuizen)
Date: Mon, 26 Sep 2016 06:59:45 +0000
Subject: [squid-users] Squid 3.5.21 - High CPU (100%)
In-Reply-To: <d72ccfb0-8e9d-261b-d52f-3be082566d35@measurement-factory.com>
References: <1474466015.14617.153.camel@shoprite.co.za>
 <d72ccfb0-8e9d-261b-d52f-3be082566d35@measurement-factory.com>
Message-ID: <1474873185.9155.24.camel@shoprite.co.za>



On Wed, 2016-09-21 at 08:34 -0600, Alex Rousskov wrote:

On 09/21/2016 07:53 AM, Jasper Van Der Westhuizen wrote:


I have been having some problems with Squid using
100% CPU at times which impacts my users browsing experience.



Sustained 100% CPU load at ~100/s rates with regular traffic on
reasonable hardware is a sign (albeit not a proof!) of a Squid bug
(including long searches and similar optimization problems).


I seem to have gotten better results/performance by doing some config changed. I removed a whole bunch of pattern_refresh lines and replaced them with better formulated lines.








During the last time I had a proxy servers CPU reach 100% I ran a
cachemgr export and below is an extract.



Next time this happens, consider getting a stack trace or two from the
process showing sustained 100% CPU utilization. It is possible to do
that without killing the processes (at least on Linux). I do not have
step-by-step instructions, but you can find them. Make sure you run (or
at least use for getting the stack trace?) an unstripped Squid binary,
preferably built with --disable-optimizations.

If the place where Squid gets stuck is known, somebody may volunteer to
fix the corresponding code.



I do not have much experience with strace. What I found now after making changes to my squid.conf file, my cache drive gets *hammered* at times of high usage. Especially in the morning when all the users come online. I have huge amounts of writes happening and this creates CPU wait and the user experience goes out of the window. My proxies are VM's with separate drives for the cache, running on reiserfs(previously EXT3). My L1 and L2 directory structure is 32 and 256 respectively with the aufs store type. In my VMWare cluster I see high write latency to the cache disks.

Is there anything that you guys can suggest I do around the cache? Should I try a different store type? A different filesystem type perhaps?

Kind Regards
Jasper




Disclaimer:
http://www.shopriteholdings.co.za/Pages/ShopriteE-mailDisclaimer.aspx
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160926/b27b64ee/attachment.htm>

From jlay at slave-tothe-box.net  Mon Sep 26 11:41:12 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Mon, 26 Sep 2016 05:41:12 -0600
Subject: [squid-users] Clarification on icap
Message-ID: <1474890072.2709.6.camel@slave-tothe-box.net>

Hey all,

So I'm going to try and get some visibility into tls traffic. ?Not
concerned with the sslbumping of the traffic, but what I DON'T know
what to do is what to do with the traffic once it's decrypted. ?This
squid machine runs IDS software as well, so my hope was to have the IDS
software listen to traffic that'd decrypted, but for the life of me I'm
not sure where to start. ?Does squid pipe out a stream? ?Or does the
IDS listen to a different "interface"? ?Is this where ICAP comes in??

Thanks for any assistance...just starting out so thought this would be
the best place to start.

James
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160926/a8098a1c/attachment.htm>

From squid3 at treenet.co.nz  Mon Sep 26 12:50:06 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 27 Sep 2016 01:50:06 +1300
Subject: [squid-users] Clarification on icap
In-Reply-To: <1474890072.2709.6.camel@slave-tothe-box.net>
References: <1474890072.2709.6.camel@slave-tothe-box.net>
Message-ID: <9dfb226f-5e99-cfb3-33bb-651dd0cace83@treenet.co.nz>

On 27/09/2016 12:41 a.m., James Lay wrote:
> Hey all,
> 
> So I'm going to try and get some visibility into tls traffic.  Not
> concerned with the sslbumping of the traffic, but what I DON'T know
> what to do is what to do with the traffic once it's decrypted.  This
> squid machine runs IDS software as well, so my hope was to have the IDS
> software listen to traffic that'd decrypted, but for the life of me I'm
> not sure where to start.  Does squid pipe out a stream?  Or does the
> IDS listen to a different "interface"?  Is this where ICAP comes in? 

Keeping it secure is of high importance. So ensuring that any
connections it goes over are securely encrypted somehow is important.

The best way to ensure data security is not to transmit it. What data
does the IDS actually need? and can you 'log' only those details to a
private pipe/socket the IDS is reading?

Amos



From michael.pelletier at palmbeachschools.org  Mon Sep 26 13:50:23 2016
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Mon, 26 Sep 2016 09:50:23 -0400
Subject: [squid-users] How to log url_rewrite_program results
Message-ID: <CAEnCSG4uP9NXNxDS5R_ddNfjZSDq3Hc=Sek=dU4hLS88kBzLmg@mail.gmail.com>

Hello,

I have a custom logformat and I would like to log the results of my url
rewriter (urlfilterdb). I can't seem to get this to work. Can someone tell
me the basics?


Michael

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160926/e087881d/attachment.htm>

From amaury at tin.it  Mon Sep 26 14:02:44 2016
From: amaury at tin.it (amaury at tin.it)
Date: Mon, 26 Sep 2016 16:02:44 +0200 (CEST)
Subject: [squid-users] problem reload configuration with workers
Message-ID: <15766ce14dc.amaury@tin.it>

Hello
I'm using squid 3.5.21-20160908-r14081 and for the first time I'm 
using workers configuration. I have a problem:
when I reload 
configuration (via init script)
suid -k reconfigure -f /et/squid/squid.
conf
the system kill squid-coord and squid-disk
So I have to remove pd 
file and lock files and restart squid.
Please, do it exist a solution 
to reload with restart squid?
I tried also using something like:

pid_filename /var/run/squid/squid-{proccess_number}.
Thank you



From rousskov at measurement-factory.com  Mon Sep 26 14:03:14 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 26 Sep 2016 08:03:14 -0600
Subject: [squid-users] Squid 3.5.21 - High CPU (100%)
In-Reply-To: <1474873185.9155.24.camel@shoprite.co.za>
References: <1474466015.14617.153.camel@shoprite.co.za>
 <d72ccfb0-8e9d-261b-d52f-3be082566d35@measurement-factory.com>
 <1474873185.9155.24.camel@shoprite.co.za>
Message-ID: <eda6e7a2-c172-d9be-905c-825b48365261@measurement-factory.com>

On 09/26/2016 12:59 AM, Jasper Van Der Westhuizen wrote:
> On Wed, 2016-09-21 at 08:34 -0600, Alex Rousskov wrote:
>> On 09/21/2016 07:53 AM, Jasper Van Der Westhuizen wrote:
>>> I have been having some problems with Squid using 100% CPU at times
>>> which impacts my users browsing experience.

>> Sustained 100% CPU load at ~100/s rates with regular traffic on
>> reasonable hardware is a sign (albeit not a proof!) of a Squid bug
>> (including long searches and similar optimization problems).

> What I found now after making
> changes to my squid.conf file, my cache drive gets *hammered* at times
> of high usage.

That is a different problem that requires different approaches.


>> Next time this happens, consider getting a stack trace or two from the
>> process showing sustained 100% CPU utilization.

> I do not have much experience with strace.

I was not talking about strace but a stack trace produced by gdb and
such. However, I was trying to help you solve a different problem so you
should ignore those instructions.


> I have huge amounts of writes happening and this creates CPU wait and
> the user experience goes out of the window.

Yes, disk write queue overflow/flushing is a common performance problem.
IIRC, it does not manifest as 100% CPU usage but perhaps that is what
you see with aufs which I am not intimately familiar with.


> Is there anything that you guys can suggest I do around the cache?
> Should I try a different store type? A different filesystem type perhaps?

If your store has a configuration knob that effectively limits disk
writing rate, then use it to limit that rate to avoid overflowing the queue.

You can also consider using rock store that has an explicit write rate
limiting option (but comes with other problems that may or may not
affect your setup).

Adding more physical disk spindles helps, of course.

Alex.



From rousskov at measurement-factory.com  Mon Sep 26 14:12:47 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 26 Sep 2016 08:12:47 -0600
Subject: [squid-users] problem reload configuration with workers
In-Reply-To: <15766ce14dc.amaury@tin.it>
References: <15766ce14dc.amaury@tin.it>
Message-ID: <f1c3880b-cde2-c68d-4e81-7148b2183393@measurement-factory.com>

On 09/26/2016 08:02 AM, amaury at tin.it wrote:

> I'm using squid 3.5.21-20160908-r14081 and for the first time I'm 
> using workers configuration. I have a problem:
> when I reload configuration (via init script)
> suid -k reconfigure -f /et/squid/squid.conf

I assume that by "suid" you meant "squid". If yes, then the above
command is a correct way to reconfigure Squid, including SMP Squid.


> the system kill squid-coord and squid-disk

Does "the system" do more than run "squid -k reconfigure ..."?

* If not, then "the system" does not kill squid-coord and squid-disk
(something else does).

* If yes, then you should fix your system script. Perhaps it thinks that
Squid died and tries to kill/restart it?


> So I have to remove pd 
> file and lock files and restart squid.
> Please, do it exist a solution 
> to reload with restart squid?

Reconfiguration should work "as is". If it does not work, file a bug
report with details such as your system command(s) and resulting
cache.log and syslog output.


> I tried also using something like:
> 
> pid_filename /var/run/squid/squid-{proccess_number}.

Please do not do that. SMP Squid is designed to work with a single
configuration file without SMP macros.


Thank you,

Alex.



From jlay at slave-tothe-box.net  Mon Sep 26 14:16:45 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Mon, 26 Sep 2016 08:16:45 -0600
Subject: [squid-users] Clarification on icap
In-Reply-To: <9dfb226f-5e99-cfb3-33bb-651dd0cace83@treenet.co.nz>
References: <1474890072.2709.6.camel@slave-tothe-box.net>
 <9dfb226f-5e99-cfb3-33bb-651dd0cace83@treenet.co.nz>
Message-ID: <75d0e03c035456310fceef1173e44f6e@localhost>

On 2016-09-26 06:50, Amos Jeffries wrote:
> On 27/09/2016 12:41 a.m., James Lay wrote:
>> Hey all,
>> 
>> So I'm going to try and get some visibility into tls traffic.  Not
>> concerned with the sslbumping of the traffic, but what I DON'T know
>> what to do is what to do with the traffic once it's decrypted.  This
>> squid machine runs IDS software as well, so my hope was to have the 
>> IDS
>> software listen to traffic that'd decrypted, but for the life of me 
>> I'm
>> not sure where to start.  Does squid pipe out a stream?  Or does the
>> IDS listen to a different "interface"?  Is this where ICAP comes in?
> 
> Keeping it secure is of high importance. So ensuring that any
> connections it goes over are securely encrypted somehow is important.
> 
> The best way to ensure data security is not to transmit it. What data
> does the IDS actually need? and can you 'log' only those details to a
> private pipe/socket the IDS is reading?
> 
> Amos
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


Ah Amos...always vigilant...thank you.  Yea those are the questions I'm 
asking really...how can squid "present" the unencrypted data?  Pipe to a 
socket?  Log to a file?  Dump to a pcap?  As soon as I know the options 
of how squid can manipulate a session during bumping/decrypting, I'll be 
able to see if snort/suricata can "listen" to the data.  Does that make 
sense?  Thanks as always Amos.

James


From jvdwesthuiz at shoprite.co.za  Mon Sep 26 14:22:06 2016
From: jvdwesthuiz at shoprite.co.za (Jasper Van Der Westhuizen)
Date: Mon, 26 Sep 2016 14:22:06 +0000
Subject: [squid-users] Squid 3.5.21 - High CPU (100%)
In-Reply-To: <eda6e7a2-c172-d9be-905c-825b48365261@measurement-factory.com>
References: <1474466015.14617.153.camel@shoprite.co.za>
 <d72ccfb0-8e9d-261b-d52f-3be082566d35@measurement-factory.com>
 <1474873185.9155.24.camel@shoprite.co.za>
 <eda6e7a2-c172-d9be-905c-825b48365261@measurement-factory.com>
Message-ID: <1474899725.9155.131.camel@shoprite.co.za>


Is there anything that you guys can suggest I do around the cache?
Should I try a different store type? A different filesystem type perhaps?



If your store has a configuration knob that effectively limits disk
writing rate, then use it to limit that rate to avoid overflowing the queue.

You can also consider using rock store that has an explicit write rate
limiting option (but comes with other problems that may or may not
affect your setup).

Adding more physical disk spindles helps, of course.




Thanks Alex. My next approach is to add more spindles. In fact I am currently testing with 4 cache dirs. All aufs currently. After adding these cache dirs, Squid started crashing every 20mins or so..

--cut-- (Cache.log)
FATAL: Received Segment Violation...dying.
2016/09/26 15:54:54 kid1| Closing HTTP port 0.0.0.0:8080
2016/09/26 15:54:54 kid1| storeDirWriteCleanLogs: Starting...
2016/09/26 15:54:54 kid1|     65536 entries written so far.
2016/09/26 15:54:54 kid1|   Finished.  Wrote 98159 entries.
2016/09/26 15:54:54 kid1|   Took 0.05 seconds (2044425.47 entries/sec).
CPU Usage: 1230.157 seconds = 166.490 user + 1063.666 sys
Maximum Resident Size: 3535840 KB
Page faults with physical i/o: 0
2016/09/26 15:54:57 kid1| Set Current Directory to /var/cache/squid/
2016/09/26 15:54:57 kid1| Starting Squid Cache version 3.5.21 for x86_64-pc-linux-gnu...
2016/09/26 15:54:57 kid1| Service Name: squid
2016/09/26 15:54:57 kid1| Process ID 16054
2016/09/26 15:54:57 kid1| Process Roles: worker
2016/09/26 15:54:57 kid1| With 65536 file descriptors available
2016/09/26 15:54:57 kid1| Initializing IP Cache...
2016/09/26 15:54:57 kid1| DNS Socket created at 0.0.0.0, FD 7
2016/09/26 15:54:57 kid1| Adding domain xxxxxx from /etc/resolv.conf
2016/09/26 15:54:57 kid1| Adding domain xxxxxx from /etc/resolv.conf
2016/09/26 15:54:57 kid1| Adding domain xxxxxx from /etc/resolv.conf
2016/09/26 15:54:57 kid1| Adding domain xxxxxx from /etc/resolv.conf
2016/09/26 15:54:57 kid1| Adding domain xxxxxx from /etc/resolv.conf
2016/09/26 15:54:57 kid1| Adding domain xxxxxx from /etc/resolv.conf
2016/09/26 15:54:57 kid1| Adding domain xxxxxx from /etc/resolv.conf
2016/09/26 15:54:57 kid1| Adding domain xxxxxx from /etc/resolv.conf
2016/09/26 15:54:57 kid1| Adding nameserver xxxxxx from /etc/resolv.conf
2016/09/26 15:54:57 kid1| Adding nameserver xxxxxx from /etc/resolv.conf
2016/09/26 15:54:57 kid1| Adding nameserver xxxxxx from /etc/resolv.conf
2016/09/26 15:54:57 kid1| Logfile: opening log daemon:/var/log/squid//access.log
2016/09/26 15:54:57 kid1| Logfile Daemon: opening log /var/log/squid//access.log
2016/09/26 15:54:57 kid1| Store logging disabled
2016/09/26 15:54:57 kid1| Swap maxSize 41943040 + 4194304 KB, estimated 3549026 objects
2016/09/26 15:54:57 kid1| Target number of buckets: 177451
2016/09/26 15:54:57 kid1| Using 262144 Store buckets
2016/09/26 15:54:57 kid1| Max Mem  size: 4194304 KB
2016/09/26 15:54:57 kid1| Max Swap size: 41943040 KB
2016/09/26 15:54:57 kid1| Rebuilding storage in /var/cache/squid-c1/ (clean log)
2016/09/26 15:54:57 kid1| Rebuilding storage in /var/cache/squid-c2/ (clean log)
2016/09/26 15:54:57 kid1| Rebuilding storage in /var/cache/squid-c3/ (clean log)
2016/09/26 15:54:57 kid1| Rebuilding storage in /var/cache/squid-c4/ (clean log)
2016/09/26 15:54:57 kid1| Using Least Load store dir selection
2016/09/26 15:54:57 kid1| Set Current Directory to /var/cache/squid/
2016/09/26 15:54:57 kid1| Finished loading MIME types and icons.
2016/09/26 15:54:57 kid1| HTCP Disabled.
2016/09/26 15:54:57 kid1| Sending SNMP messages from 0.0.0.0:3401
2016/09/26 15:54:57 kid1| Configuring Parent xxxxxx8/80/0
2016/09/26 15:54:57 kid1| Configuring Parent xxxxxx/80/0
2016/09/26 15:54:57 kid1| Configuring Sibling xxxxxx/8080/3131
2016/09/26 15:54:57 kid1| Squid plugin modules loaded: 0
2016/09/26 15:54:57 kid1| Adaptation support is off.
2016/09/26 15:54:57 kid1| Accepting HTTP Socket connections at local=0.0.0.0:8080 remote=[::] FD 18 flags=9
2016/09/26 15:54:57 kid1| Accepting SNMP messages on 0.0.0.0:3401
2016/09/26 15:54:57 kid1| Store rebuilding is 33.00% complete
2016/09/26 15:54:57 kid1| Done reading /var/cache/squid-c3/ swaplog (8660 entries)
2016/09/26 15:54:57 kid1| Done reading /var/cache/squid-c1/ swaplog (12119 entries)
2016/09/26 15:54:58 kid1| Done reading /var/cache/squid-c2/ swaplog (30684 entries)
2016/09/26 15:54:58 kid1| Done reading /var/cache/squid-c4/ swaplog (46696 entries)
2016/09/26 15:54:58 kid1| Finished rebuilding storage from disk.
2016/09/26 15:54:58 kid1|     98159 Entries scanned
2016/09/26 15:54:58 kid1|         0 Invalid entries.
2016/09/26 15:54:58 kid1|         0 With invalid flags.
2016/09/26 15:54:58 kid1|     98159 Objects loaded.
2016/09/26 15:54:58 kid1|         0 Objects expired.
2016/09/26 15:54:58 kid1|         0 Objects cancelled.
2016/09/26 15:54:58 kid1|         0 Duplicate URLs purged.
2016/09/26 15:54:58 kid1|         0 Swapfile clashes avoided.
2016/09/26 15:54:58 kid1|   Took 0.61 seconds (162197.49 objects/sec).
2016/09/26 15:54:58 kid1| Beginning Validation Procedure
2016/09/26 15:54:58 kid1|   Completed Validation Procedure
2016/09/26 15:54:58 kid1|   Validated 98159 Entries
2016/09/26 15:54:58 kid1|   store_swap_size = 11495920.00 KB
2016/09/26 15:54:58 kid1| storeLateRelease: released 0 objects

--cut--


 I tried rock but was stuck with this error for a while and decided to go back to aufs until I can do some more reading up.

FATAL: Rock cache_dir at /var/cache/squid-c3//rock failed to open db file: (2) No such file or directory

I am currently testing again after recompiling squid..  The rest of my proxy cluster has the "cache deny all" configuration directive.. So nothing is cached.





Disclaimer:
http://www.shopriteholdings.co.za/Pages/ShopriteE-mailDisclaimer.aspx
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160926/2bdb086b/attachment.htm>

From rousskov at measurement-factory.com  Mon Sep 26 14:30:09 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 26 Sep 2016 08:30:09 -0600
Subject: [squid-users] Clarification on icap
In-Reply-To: <1474890072.2709.6.camel@slave-tothe-box.net>
References: <1474890072.2709.6.camel@slave-tothe-box.net>
Message-ID: <10bbdad1-1892-ff29-1c0a-7db095cf2119@measurement-factory.com>

On 09/26/2016 05:41 AM, James Lay wrote:
> So I'm going to try and get some visibility into tls traffic.  Not
> concerned with the sslbumping of the traffic, but what I DON'T know what
> to do is what to do with the traffic once it's decrypted.  This squid
> machine runs IDS software as well, so my hope was to have the IDS
> software listen to traffic that'd decrypted, but for the life of me I'm
> not sure where to start.  Does squid pipe out a stream?  Or does the IDS
> listen to a different "interface"?  Is this where ICAP comes in? 

Squid-IDS integration is mostly independent from SslBump issues -- you
integrate traffic analysis of plain and secure traffic similarly. Your
options depend on IDS interfaces:

1. If IDS is content with passively looking at something Squid can log
(after the transaction is completed), then give IDS the logs (see
access_log and logformat directives). This is what Amos recommended in
his response. It is the best option if your IDS can use it.

2. If IDS is content with reacting to something Squid can log while
processing a message, then write or purchase a custom external ACL
script. External ACL input can be customized just like the access log.

3. If IDS needs access to message bodies, then use an ICAP or eCAP
service to give IDS whole messages. You may have to write or purchase
that service. How that service is going to give messages to IDS depends
on IDS interfaces. Some IDSes have APIs while others listen to raw
traffic (that a service can emulate and emit).


HTH,

Alex.



From rousskov at measurement-factory.com  Mon Sep 26 14:38:29 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 26 Sep 2016 08:38:29 -0600
Subject: [squid-users] Squid 3.5.21 - High CPU (100%)
In-Reply-To: <1474899725.9155.131.camel@shoprite.co.za>
References: <1474466015.14617.153.camel@shoprite.co.za>
 <d72ccfb0-8e9d-261b-d52f-3be082566d35@measurement-factory.com>
 <1474873185.9155.24.camel@shoprite.co.za>
 <eda6e7a2-c172-d9be-905c-825b48365261@measurement-factory.com>
 <1474899725.9155.131.camel@shoprite.co.za>
Message-ID: <abc1ddf5-10bb-4d8b-47f5-8e83c3c1eeeb@measurement-factory.com>

On 09/26/2016 08:22 AM, Jasper Van Der Westhuizen wrote:
> I am
> currently testing with 4 cache dirs. All aufs currently. After adding
> these cache dirs, Squid started crashing every 20mins or so..

> FATAL: Received Segment Violation...dying.

This is probably a Squid bug. Get a stack trace and post to bugzilla.
However, nobody I know works on aufs code; if the bug is specific to
aufs, it may take a while for this bug to be fixed.


> I tried rock but was stuck with this error for a while and decided to
> go back to aufs until I can do some more reading up. 
> 
> FATAL: Rock cache_dir at /var/cache/squid-c3//rock failed to open db
> file: (2) No such file or directory

Probably a misconfiguration combined with a misleading/wrong error
message. The Squid wiki has some suggestions on what system settings to
check and configure to make sure that all SMP workers can communicate
with each other over UDS. And do not forget to check permissions (even
"squid -N" will fail if they are wrong).


Cheers,

Alex.



From jlay at slave-tothe-box.net  Mon Sep 26 14:43:13 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Mon, 26 Sep 2016 08:43:13 -0600
Subject: [squid-users] Clarification on icap
In-Reply-To: <10bbdad1-1892-ff29-1c0a-7db095cf2119@measurement-factory.com>
References: <1474890072.2709.6.camel@slave-tothe-box.net>
 <10bbdad1-1892-ff29-1c0a-7db095cf2119@measurement-factory.com>
Message-ID: <81153b82678a1d8430523326df800bc2@localhost>

On 2016-09-26 08:30, Alex Rousskov wrote:
> On 09/26/2016 05:41 AM, James Lay wrote:
>> So I'm going to try and get some visibility into tls traffic.  Not
>> concerned with the sslbumping of the traffic, but what I DON'T know 
>> what
>> to do is what to do with the traffic once it's decrypted.  This squid
>> machine runs IDS software as well, so my hope was to have the IDS
>> software listen to traffic that'd decrypted, but for the life of me 
>> I'm
>> not sure where to start.  Does squid pipe out a stream?  Or does the 
>> IDS
>> listen to a different "interface"?  Is this where ICAP comes in?
> 
> Squid-IDS integration is mostly independent from SslBump issues -- you
> integrate traffic analysis of plain and secure traffic similarly. Your
> options depend on IDS interfaces:
> 
> 1. If IDS is content with passively looking at something Squid can log
> (after the transaction is completed), then give IDS the logs (see
> access_log and logformat directives). This is what Amos recommended in
> his response. It is the best option if your IDS can use it.
> 
> 2. If IDS is content with reacting to something Squid can log while
> processing a message, then write or purchase a custom external ACL
> script. External ACL input can be customized just like the access log.
> 
> 3. If IDS needs access to message bodies, then use an ICAP or eCAP
> service to give IDS whole messages. You may have to write or purchase
> that service. How that service is going to give messages to IDS depends
> on IDS interfaces. Some IDSes have APIs while others listen to raw
> traffic (that a service can emulate and emit).
> 
> 
> HTH,
> 
> Alex.

Ah..there's the rub Alex thanks.  I already have rock solid access 
controls with squids acl's and great logging.  Now I find that I need to 
inspect the actual content, i.e. message bodies.  So cool..I'm on the 
right track for ICAP or eCAP.  So, from what I've read, it appears that 
squid sends the data to a listening ICAP/eCAP service, which in turn the 
IDS can access, depending on the IDS...is that about right?

James


From rousskov at measurement-factory.com  Mon Sep 26 14:52:26 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 26 Sep 2016 08:52:26 -0600
Subject: [squid-users] Clarification on icap
In-Reply-To: <81153b82678a1d8430523326df800bc2@localhost>
References: <1474890072.2709.6.camel@slave-tothe-box.net>
 <10bbdad1-1892-ff29-1c0a-7db095cf2119@measurement-factory.com>
 <81153b82678a1d8430523326df800bc2@localhost>
Message-ID: <377d2ec5-6d05-9c10-4b3e-6aa2732aeae1@measurement-factory.com>

On 09/26/2016 08:43 AM, James Lay wrote:
> So, from what I've read, it appears that
> squid sends the data to a listening ICAP/eCAP service, which in turn the
> IDS can access, depending on the IDS...is that about right?

Not exactly.

Yes, Squid sends the message to the adaptation service ("listening" is
not a good verb for eCAP because, unlike ICAP, eCAP services are not
network services but "plugins" or libraries).

No, the IDS does not normally come to the adaptation service for
messages. Normally, the adaptation service itself needs to give IDS the
data. How that is done depends on the IDS interfaces, of course.

On a logical level, the message is transmitted using the following chain:

  Squid -> adaptation service -> IDS

And the allow/block decision (if any) is transmitted in the opposite
direction:

  Squid <- adaptation service <- IDS

Alex.



From jlay at slave-tothe-box.net  Mon Sep 26 14:55:03 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Mon, 26 Sep 2016 08:55:03 -0600
Subject: [squid-users] Clarification on icap
In-Reply-To: <377d2ec5-6d05-9c10-4b3e-6aa2732aeae1@measurement-factory.com>
References: <1474890072.2709.6.camel@slave-tothe-box.net>
 <10bbdad1-1892-ff29-1c0a-7db095cf2119@measurement-factory.com>
 <81153b82678a1d8430523326df800bc2@localhost>
 <377d2ec5-6d05-9c10-4b3e-6aa2732aeae1@measurement-factory.com>
Message-ID: <f002ad762ea7f45e1200e1165246bee3@localhost>

On 2016-09-26 08:52, Alex Rousskov wrote:
> On 09/26/2016 08:43 AM, James Lay wrote:
>> So, from what I've read, it appears that
>> squid sends the data to a listening ICAP/eCAP service, which in turn 
>> the
>> IDS can access, depending on the IDS...is that about right?
> 
> Not exactly.
> 
> Yes, Squid sends the message to the adaptation service ("listening" is
> not a good verb for eCAP because, unlike ICAP, eCAP services are not
> network services but "plugins" or libraries).
> 
> No, the IDS does not normally come to the adaptation service for
> messages. Normally, the adaptation service itself needs to give IDS the
> data. How that is done depends on the IDS interfaces, of course.
> 
> On a logical level, the message is transmitted using the following 
> chain:
> 
>   Squid -> adaptation service -> IDS
> 
> And the allow/block decision (if any) is transmitted in the opposite
> direction:
> 
>   Squid <- adaptation service <- IDS
> 
> Alex.

Beautiful...just what I needed.  Last question...any recommended open 
source ICAP/eCAP services that squid works well with?  Thanks again.

James


From augustus_meyer at gmx.net  Mon Sep 26 15:23:52 2016
From: augustus_meyer at gmx.net (reinerotto)
Date: Mon, 26 Sep 2016 08:23:52 -0700 (PDT)
Subject: [squid-users] Squid 3.5.21 - High CPU (100%)
In-Reply-To: <1474899725.9155.131.camel@shoprite.co.za>
References: <1474466015.14617.153.camel@shoprite.co.za>
 <d72ccfb0-8e9d-261b-d52f-3be082566d35@measurement-factory.com>
 <1474873185.9155.24.camel@shoprite.co.za>
 <eda6e7a2-c172-d9be-905c-825b48365261@measurement-factory.com>
 <1474899725.9155.131.camel@shoprite.co.za>
Message-ID: <1474903432467-4679705.post@n4.nabble.com>

>FATAL: Received Segment Violation...dying.
2016/09/26 15:54:54 kid1| Closing HTTP port 0.0.0.0:8080
2016/09/26 15:54:54 kid1| storeDirWriteCleanLogs: Starting...
2016/09/26 15:54:54 kid1|     65536 entries written so far.    <<<-----
short Int ?????????

Makes me a bit suspicious regarding possible overflow ...



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-3-5-21-High-CPU-100-tp4679629p4679705.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Mon Sep 26 15:44:15 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 26 Sep 2016 21:44:15 +0600
Subject: [squid-users] Question: Is it possible adaptation_service_chain
 from services with different access lists?
Message-ID: <66ab3541-531a-4c8d-d26b-fa1ddd88a43b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Hi gents.

I appeal to the experts in the adaptation.

For example, I have to adaptation service A, which has the access list
"All".

And B adaptation service that has access list, for example, "only text
types".

I want to chain both services in  adaptation_service_chain with next logic:

All_content -> service A -> service B -> adapted content.

In this scheme, service A must adapt all content and pass positive
(adapted) results to service B, which must filter and adapt only text
types from incoming transaction, and pass another unchanged.

Question: Does this scheme of adaptation possible?

If yes - how it can be done, given the fact that the service A can block
access to content and has an inside access control from a subset of
"All", and the service B has an outside access control list (squid's
driven)?

Any advices are welcome.


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX6UJPAAoJENNXIZxhPexGGLcH/i5Jr890U0XraRIB0ivRKjTY
7ZniL1hRDXgpsBsUiNUyJjxr6fpRdm9YduIn49d2e3nsxPBST+tB/9HVNtijNIRs
Mr6HgXpbU4mtAvnhoNZAX028/54JEIuuFZukAT/s9QyRWsoZY7+izJVSsB5jAuDV
JFf0DRnJhT6dWzqYTG9YGeQxG/nCrU1r73tEP+HamVfHo+YDDBxUjcFACs7ousX0
yxLUaCxaXBywtj16hgQec7eNuDr+TZTsW2euHktBtwy8ElmM632sHgpv7orHp01y
dcWOzjP+a47k5h/9aiQuvo/vMUvUwNkeQB2kbXxm1u7VY70YdbP1Tee+jvc/fWc=
=4FY9
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160926/bbfb866a/attachment.key>

From jvdwesthuiz at shoprite.co.za  Mon Sep 26 15:53:20 2016
From: jvdwesthuiz at shoprite.co.za (Jasper Van Der Westhuizen)
Date: Mon, 26 Sep 2016 15:53:20 +0000
Subject: [squid-users] Squid 3.5.21 - High CPU (100%)
In-Reply-To: <abc1ddf5-10bb-4d8b-47f5-8e83c3c1eeeb@measurement-factory.com>
References: <1474466015.14617.153.camel@shoprite.co.za>
 <d72ccfb0-8e9d-261b-d52f-3be082566d35@measurement-factory.com>
 <1474873185.9155.24.camel@shoprite.co.za>
 <eda6e7a2-c172-d9be-905c-825b48365261@measurement-factory.com>
 <1474899725.9155.131.camel@shoprite.co.za>
 <abc1ddf5-10bb-4d8b-47f5-8e83c3c1eeeb@measurement-factory.com>
Message-ID: <1474905199.9155.142.camel@shoprite.co.za>


--
Kind Regards
Jasper



On 09/26/2016 08:22 AM, Jasper Van Der Westhuizen wrote:


I am
currently testing with 4 cache dirs. All aufs currently. After adding
these cache dirs, Squid started crashing every 20mins or so..





FATAL: Received Segment Violation...dying.



This is probably a Squid bug. Get a stack trace and post to bugzilla.
However, nobody I know works on aufs code; if the bug is specific to
aufs, it may take a while for this bug to be fixed.




Thanks Alex. How many aufs cache directories would you recommend? I currently have 4 configured and even though I don't see SQUID crashing and restarting I see a significant increase in CPU with very little traffic(End of business day).






Disclaimer:
http://www.shopriteholdings.co.za/Pages/ShopriteE-mailDisclaimer.aspx
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160926/5a1fbcdc/attachment.htm>

From rousskov at measurement-factory.com  Mon Sep 26 16:25:07 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 26 Sep 2016 10:25:07 -0600
Subject: [squid-users] Question: Is it possible adaptation_service_chain
 from services with different access lists?
In-Reply-To: <66ab3541-531a-4c8d-d26b-fa1ddd88a43b@gmail.com>
References: <66ab3541-531a-4c8d-d26b-fa1ddd88a43b@gmail.com>
Message-ID: <2ea6f023-e6c6-45cd-0e6a-60b83d843809@measurement-factory.com>

On 09/26/2016 09:44 AM, Yuri Voinov wrote:

> I have to adaptation service A, which has the access list "All".
> 
> And B adaptation service that has access list "only text types".

> I want to chain both services in  adaptation_service_chain with next logic:

> In this scheme, service A must adapt all content and pass positive
> (adapted) results to service B, which must filter and adapt only text
> types from incoming transaction, and pass another unchanged.

The last part does not make sense to me: Why send non-text messages to
service B that does not want them? I assume you meant that Squid should
not send service B non-text messages at all.


> Question: Does this scheme of adaptation possible?

Yes, there are several ways to accomplish this.

1. Static decision using ACLs:

  adaptation_service_chain vegetarianChain serviceA serviceB

  acl messageIsText ...
  adaptation_access vegetarianChain messageIsText
  adaptation_access serviceA all


2. Dynamic decision inside ServiceA:

   Modify ServiceA to emit an appropriate ICAP X-Next-Services header
[for text messages]. Do not forget to configure ServiceA with
routing=on! Search for X-Next-Services in squid.conf.documented.


> If yes - how it can be done, given the fact that the service A can block
> access to content and has an inside access control from a subset of
> "All", and the service B has an outside access control list (squid's
> driven)?

You can generalize the above solutions to virtually any combination of
access lists. Just do not think in terms of access control lists for
individual services. Think of access control lists for chains (a
single-service chain is just a corner case which you can optimize by
replacing the chain with the service as shown in #1 above).


HTH,

Alex.


From rousskov at measurement-factory.com  Mon Sep 26 16:40:17 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 26 Sep 2016 10:40:17 -0600
Subject: [squid-users] Clarification on icap
In-Reply-To: <f002ad762ea7f45e1200e1165246bee3@localhost>
References: <1474890072.2709.6.camel@slave-tothe-box.net>
 <10bbdad1-1892-ff29-1c0a-7db095cf2119@measurement-factory.com>
 <81153b82678a1d8430523326df800bc2@localhost>
 <377d2ec5-6d05-9c10-4b3e-6aa2732aeae1@measurement-factory.com>
 <f002ad762ea7f45e1200e1165246bee3@localhost>
Message-ID: <0ebb7801-8d45-2097-2756-0cfb7c3fc970@measurement-factory.com>

On 09/26/2016 08:55 AM, James Lay wrote:
> any recommended open source ICAP/eCAP services that squid works well with?

You do not need an ICAP/eCAP service that Squid works well with. You
need an ICAP/eCAP service that integrates with your IDS. All production
ICAP/eCAP services are doing some specific adaptation (e.g., downgrade
image quality) or integrate with some specific adaptation library (e.g.,
ClamAV). They are useless to you unless they integrate with your IDS.

If there is no existing service that integrates with your IDS, you would
have to write and support one. If you go the ICAP route, many plug their
custom ICAP services into the free c-icap ICAP server. If you decide
going the eCAP route, then you do not need a server (eCAP is a
library/API, not a communication protocol, so your custom code plugs
directly into the host application such as Squid).

  http://wiki.squid-cache.org/SquidFaq/ContentAdaptation

Alex.



From yvoinov at gmail.com  Mon Sep 26 16:42:07 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 26 Sep 2016 22:42:07 +0600
Subject: [squid-users] Question: Is it possible adaptation_service_chain
 from services with different access lists?
In-Reply-To: <2ea6f023-e6c6-45cd-0e6a-60b83d843809@measurement-factory.com>
References: <66ab3541-531a-4c8d-d26b-fa1ddd88a43b@gmail.com>
 <2ea6f023-e6c6-45cd-0e6a-60b83d843809@measurement-factory.com>
Message-ID: <4c37cb2d-8fd1-8ea5-b82b-e879c46b816e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


26.09.2016 22:25, Alex Rousskov ?????:
> On 09/26/2016 09:44 AM, Yuri Voinov wrote:
>
>> I have to adaptation service A, which has the access list "All".
>>
>> And B adaptation service that has access list "only text types".
>
>> I want to chain both services in  adaptation_service_chain with next
logic:
>
>> In this scheme, service A must adapt all content and pass positive
>> (adapted) results to service B, which must filter and adapt only text
>> types from incoming transaction, and pass another unchanged.
>
> The last part does not make sense to me: Why send non-text messages to
> service B that does not want them? I assume you meant that Squid should
> not send service B non-text messages at all.
And how to do it? To adapt the chain is only one access control list.
Suppose I, for whatever reason, can not modify the services at the level
of source code. It's not uncommon that the adaptation services are
proprietary code, is not it? How can I make a chain of adaptation with
different acl's for different chained services?
>
>
>
>> Question: Does this scheme of adaptation possible?
>
> Yes, there are several ways to accomplish this.
>
> 1. Static decision using ACLs:
>
>   adaptation_service_chain vegetarianChain serviceA serviceB
>
>   acl messageIsText ...
>   adaptation_access vegetarianChain messageIsText
>   adaptation_access serviceA all
Here from this place can be a bit more detail. And if versa? A service
receives all of the transactions, and the service B is limited to text
answers?

How will it look like in practice and how to really work?
>
>
>
> 2. Dynamic decision inside ServiceA:
>
>    Modify ServiceA to emit an appropriate ICAP X-Next-Services header
> [for text messages]. Do not forget to configure ServiceA with
> routing=on! Search for X-Next-Services in squid.conf.documented.
As I understand it, there is required a modification service code, right?

And is it possible specific example here:

#    routing=on|off|1|0
#        If set to 'on' or '1', the ICAP service is allowed to
#        dynamically change the current message adaptation plan by
#        returning a chain of services to be used next. The services
#        are specified using the X-Next-Services ICAP response header
#        value, formatted as a comma-separated list of service names.
#        Each named service should be configured in squid.conf. Other
#        services are ignored. An empty X-Next-Services value results
#        in an empty plan which ends the current adaptation.
#
#        Dynamic adaptation plan may cross or cover multiple supported
#        vectoring points in their natural processing order.
#
#        Routing is not allowed by default: the ICAP X-Next-Services
#        response header is ignored.

For me personally, this paragraph does not explain anything.

>
>
>
>> If yes - how it can be done, given the fact that the service A can block
>> access to content and has an inside access control from a subset of
>> "All", and the service B has an outside access control list (squid's
>> driven)?
>
> You can generalize the above solutions to virtually any combination of
> access lists. Just do not think in terms of access control lists for
> individual services. Think of access control lists for chains (a
> single-service chain is just a corner case which you can optimize by
> replacing the chain with the service as shown in #1 above).
Should we understand this statement as something that we can not set
different access to services in the chain and the chain can have only
one level of access is the same for all the services within it?

Because then this assertion is contrary to the above.
>
>
>
> HTH,
>
> Alex.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX6U/fAAoJENNXIZxhPexGw+8H/07twJ6EEhw8FPypWFVyg3OY
dcQ42xuQTyXEqeCl2JwAOcgDEN90uacVEFRfA3HUcZhLIyaWwqarHeYOMwVtiCK9
IhLA9K+WzlhqGSR4VQNN6cNv/2OyMRwepBz9xo6KOF4TIxPkYpy6YhZ4mbCBd3xY
Jxhr1RfQxRn6YBfhCLTDJpMP+Lam3VApdkvfCmvKHmGNtKXTDSJXLi2fWM6/Pc62
dzf8CMgeEMP7FQ/8RUH3qS3wR3gxW2al5xmbHP/JR76qoEf2KntAtuIKK+pp7I0c
UOhXa//JiVodGgF63bg89a0n5gxSOwtcvhUVzy1TVX3z2znTLhQTpalX1QyNuWI=
=mvCb
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160926/71125c2e/attachment.key>

From rousskov at measurement-factory.com  Mon Sep 26 17:16:52 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 26 Sep 2016 11:16:52 -0600
Subject: [squid-users] Question: Is it possible adaptation_service_chain
 from services with different access lists?
In-Reply-To: <4c37cb2d-8fd1-8ea5-b82b-e879c46b816e@gmail.com>
References: <66ab3541-531a-4c8d-d26b-fa1ddd88a43b@gmail.com>
 <2ea6f023-e6c6-45cd-0e6a-60b83d843809@measurement-factory.com>
 <4c37cb2d-8fd1-8ea5-b82b-e879c46b816e@gmail.com>
Message-ID: <9b1317c1-99ac-4ff1-b5ca-47e97760f504@measurement-factory.com>

On 09/26/2016 10:42 AM, Yuri Voinov wrote:
> 26.09.2016 22:25, Alex Rousskov ?????:
>> I assume you meant that Squid should
>> not send service B non-text messages at all.

> And how to do it?

I gave a specific example.


> To adapt the chain is only one access control list.

You are approaching this problem from the wrong angle: adaptation_access
rules are not attached to a specific adaptation service, set, or chain.
Those rules are like routing tables -- they send each message to one of
the existing services, sets, or chains (the first matching rule wins).
This is the same as cache_peer_access rules sending each message to a
specific cache peer. More on that below.


> How can I make a chain of adaptation with
> different acl's for different chained services?

By configuring several chains and then writing adaptation_access rules
to select the right chain for a given message.


>>   adaptation_service_chain vegetarianChain serviceA serviceB
>>
>>   acl messageIsText ...
>>   adaptation_access vegetarianChain messageIsText
>>   adaptation_access serviceA all

> Here from this place can be a bit more detail. 

The above contains everything except for the messageIsText ACL
definition (which I do not know). Please let me know what other details
are missing...


> A service
> receives all of the transactions, and the service B is limited to text
> answers?

That is exactly what the above configuration accomplishes. Service A
receives all messages because this service is present no matter which
adaptation_access rule matches. Service B only receives messageIsText
messages (after they are processed by Service A).


>> 2. Dynamic decision inside ServiceA:
> 
>>    Modify ServiceA to emit an appropriate ICAP X-Next-Services header
>> [for text messages]. Do not forget to configure ServiceA with
>> routing=on! Search for X-Next-Services in squid.conf.documented.

> As I understand it, there is required a modification service code, right?

Yes, unless ServiceA already has some configuration options to
accomplish this.


> And is it possible specific example here:

A specific example for dynamic routing would be service A returning an
ICAP header like this:

  X-Next-Services: serviceB

(when and only when service A wants service B to be applied next). In
this case, Squid configuration becomes trivial:

  adaptation_access serviceA all


> #    routing=on|off|1|0
> #        If set to 'on' or '1', the ICAP service is allowed to
> #        dynamically change the current message adaptation plan by
> #        returning a chain of services to be used next. The services
> #        are specified using the X-Next-Services ICAP response header
> #        value, formatted as a comma-separated list of service names.
> #        Each named service should be configured in squid.conf. Other
> #        services are ignored. An empty X-Next-Services value results
> #        in an empty plan which ends the current adaptation.
> #
> #        Dynamic adaptation plan may cross or cover multiple supported
> #        vectoring points in their natural processing order.
> #
> #        Routing is not allowed by default: the ICAP X-Next-Services
> #        response header is ignored.
> 
> For me personally, this paragraph does not explain anything.

I am sorry to hear that, but I cannot explain it better. Perhaps you can
ask specific questions and/or others can pitch in.



> we can not set
> different access to services in the chain and the chain can have only
> one level of access is the same for all the services within it?

Yes, dynamic routing aside, Squid builds a message adaptation plan and
then follows it. That plan is built at adaptation_access evaluation
time. That evaluation happens once per virgin message at each vectoring
point (REQMOD and RESPMOD). During that evaluation, the first
adaptation_access rule wins and the winning set/chain/service becomes
that adaptation plan.

There are some minor caveats like "down" services and adaptation plans
that span vectoring points, but I do not think they are important in
this context.



> Because then this assertion is contrary to the above.

I do not see a contradiction. What contradicts what, exactly?

Alex.


From yvoinov at gmail.com  Mon Sep 26 17:32:07 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Mon, 26 Sep 2016 23:32:07 +0600
Subject: [squid-users] Question: Is it possible adaptation_service_chain
 from services with different access lists?
In-Reply-To: <9b1317c1-99ac-4ff1-b5ca-47e97760f504@measurement-factory.com>
References: <66ab3541-531a-4c8d-d26b-fa1ddd88a43b@gmail.com>
 <2ea6f023-e6c6-45cd-0e6a-60b83d843809@measurement-factory.com>
 <4c37cb2d-8fd1-8ea5-b82b-e879c46b816e@gmail.com>
 <9b1317c1-99ac-4ff1-b5ca-47e97760f504@measurement-factory.com>
Message-ID: <ac367c8d-144b-d05a-3893-2842306d60c1@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


26.09.2016 23:16, Alex Rousskov ?????:
> On 09/26/2016 10:42 AM, Yuri Voinov wrote:
>> 26.09.2016 22:25, Alex Rousskov ?????:
>>> I assume you meant that Squid should
>>> not send service B non-text messages at all.
>
>> And how to do it?
>
> I gave a specific example.
>
>
>> To adapt the chain is only one access control list.
>
> You are approaching this problem from the wrong angle: adaptation_access
> rules are not attached to a specific adaptation service, set, or chain.
> Those rules are like routing tables -- they send each message to one of
> the existing services, sets, or chains (the first matching rule wins).
> This is the same as cache_peer_access rules sending each message to a
> specific cache peer. More on that below.
>
>
>> How can I make a chain of adaptation with
>> different acl's for different chained services?
>
> By configuring several chains and then writing adaptation_access rules
> to select the right chain for a given message.
Ahaaaaaaaaa. I.e., I can specify chain_A with own access rules and one
service_A in chain, and then chain_B, also with own access rules and one
service_B, and, finally, specify chain_C with chain_A+chain_B and with
access "all". Right?
>
>
>
>>>   adaptation_service_chain vegetarianChain serviceA serviceB
>>>
>>>   acl messageIsText ...
>>>   adaptation_access vegetarianChain messageIsText
>>>   adaptation_access serviceA all
>
>> Here from this place can be a bit more detail.
>
> The above contains everything except for the messageIsText ACL
> definition (which I do not know). Please let me know what other details
> are missing...
>
>
>> A service
>> receives all of the transactions, and the service B is limited to text
>> answers?
>
> That is exactly what the above configuration accomplishes. Service A
> receives all messages because this service is present no matter which
> adaptation_access rule matches. Service B only receives messageIsText
> messages (after they are processed by Service A).
>
>
>>> 2. Dynamic decision inside ServiceA:
>>
>>>    Modify ServiceA to emit an appropriate ICAP X-Next-Services header
>>> [for text messages]. Do not forget to configure ServiceA with
>>> routing=on! Search for X-Next-Services in squid.conf.documented.
>
>> As I understand it, there is required a modification service code, right?
>
> Yes, unless ServiceA already has some configuration options to
> accomplish this.
>
>
>> And is it possible specific example here:
>
> A specific example for dynamic routing would be service A returning an
> ICAP header like this:
>
>   X-Next-Services: serviceB
>
> (when and only when service A wants service B to be applied next). In
> this case, Squid configuration becomes trivial:
>
>   adaptation_access serviceA all
>
>
>> #    routing=on|off|1|0
>> #        If set to 'on' or '1', the ICAP service is allowed to
>> #        dynamically change the current message adaptation plan by
>> #        returning a chain of services to be used next. The services
>> #        are specified using the X-Next-Services ICAP response header
>> #        value, formatted as a comma-separated list of service names.
>> #        Each named service should be configured in squid.conf. Other
>> #        services are ignored. An empty X-Next-Services value results
>> #        in an empty plan which ends the current adaptation.
>> #
>> #        Dynamic adaptation plan may cross or cover multiple supported
>> #        vectoring points in their natural processing order.
>> #
>> #        Routing is not allowed by default: the ICAP X-Next-Services
>> #        response header is ignored.
>>
>> For me personally, this paragraph does not explain anything.
>
> I am sorry to hear that, but I cannot explain it better. Perhaps you can
> ask specific questions and/or others can pitch in.
There would not be an extra circuit or illustration. Not quite clear
exactly what is meant.
>
>
>
>
>> we can not set
>> different access to services in the chain and the chain can have only
>> one level of access is the same for all the services within it?
>
> Yes, dynamic routing aside, Squid builds a message adaptation plan and
> then follows it. That plan is built at adaptation_access evaluation
> time. That evaluation happens once per virgin message at each vectoring
> point (REQMOD and RESPMOD). During that evaluation, the first
> adaptation_access rule wins and the winning set/chain/service becomes
> that adaptation plan.
>
> There are some minor caveats like "down" services and adaptation plans
> that span vectoring points, but I do not think they are important in
> this context.
Yes, right.
>
>
>
>
>> Because then this assertion is contrary to the above.
>
> I do not see a contradiction. What contradicts what, exactly?
Ah, this statement is removed. :) Picture clearer :)
>
>
> Alex.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX6VuXAAoJENNXIZxhPexG9lYIAKXdIFgCgxk8/dYa+SW5wHZt
dQQZwaff4IRFzXsIZpxSIL9JxL9r4ISoExf7bsVtA4aFEi/XvNqJgCNMiAsvr+Mh
XeXkIeI1OILY17Ol0YD7rZLfmpcTDumUWpumgOnCfh9Bi20lRwGh41oi/KyH3yY3
CS4oh3pGTUWCB3WpwTqiX2GL5HBrasQT21qh4ehLhM8IP0Hkql/AUAWImWZxxvLl
j9MJPqJew5lzMAhNRchCh2erzk1jZMFVof+7JEvywIlj1AEUIgvc3oVchdbcuuq2
eS+7amOxkZ1J+Bi9unIZV5Ni+iersDzVCqaDaTEDc2Eiy2rKKiUgnujJXTCyAX0=
=FjfB
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160926/de9524db/attachment.key>

From David.J.Berkes at pjc.com  Mon Sep 26 18:01:56 2016
From: David.J.Berkes at pjc.com (Berkes, David)
Date: Mon, 26 Sep 2016 18:01:56 +0000
Subject: [squid-users] New error on version 3.5.19
Message-ID: <916606669CFF224AB6997E9DB783F6EACCCDADC4@ESCML200.corp.pjc.com>

Hi squid community,
I'm seeing a new error in my squid logs.  These are iphones configured for a squid proxy.  They are running IOS 10.0.2 and siri is now failing.  You can see the request is allowed through, but is preceded with the error lines then siri fails.  Any idea of what these errors indicate.  They seem to be the root cause for the siri requests failing.


squid -v
Squid Cache: Version 3.5.19


tail -f access.log
- 333.444.5.66 - - [26/Sep/2016:12:49:33 -0500] "NONE error:invalid-request  HTTP/1.1" 400 4418 "-" "-" TAG_NONE:HIER_NONE

- 333.444.5.66 - - [26/Sep/2016:12:49:36 -0500] "NONE error:invalid-request  HTTP/1.1" 400 4418 "-" "-" TAG_NONE:HIER_NONE

- 333.444.5.66 - - [26/Sep/2016:12:49:36 -0500] "NONE error:invalid-request  HTTP/1.1" 400 4418 "-" "-" TAG_NONE:HIER_NONE
www.apple.com 333.444.5.66 - - [26/Sep/2016:12:49:36 -0500] "HEAD http://www.apple.com/  HTTP/1.1" 200 502 "-" "com.apple.siri.analyzer/1 CFNetwork/808.0.2 Darwin/16.0.0" TCP_MEM_HIT:HIER_NONE
guzzoni.apple.com:443 333.444.5.66 - - [26/Sep/2016:12:49:36 -0500] "CONNECT guzzoni.apple.com:443  HTTP/1.1" 200 3475 "-" "com.apple.siri.analyzer/1 CFNetwork/808.0.2 Darwin/16.0.0" TCP_TUNNEL:HIER_DIRECT
guzzoni.apple.com:443 333.444.5.66 - - [26/Sep/2016:12:49:37 -0500] "CONNECT guzzoni.apple.com:443  HTTP/1.1" 200 299 "-" "com.apple.siri.analyzer/1 CFNetwork/808.0.2 Darwin/16.0.0" TCP_TUNNEL:HIER_DIRECT




--
David J. Berkes
Piper Jaffray & Co.
800 Nicollet Mall, Suite 1000
Minneapolis, MN 55402
Office:  612.303.6412
Mobile:  612.845.5483
Email:    david.j.berkes at pjc.com<mailto:david.j.berkes at pjc.com>

________________________________

Piper Jaffray & Co. Since 1895. Member SIPC and NYSE. Learn more at www.piperjaffray.com. Piper Jaffray corporate headquarters is located at 800 Nicollet Mall, Minneapolis, MN 55402.

Piper Jaffray outgoing and incoming e-mail is electronically archived and recorded and is subject to review, monitoring and/or disclosure to someone other than the recipient. This e-mail may be considered an advertisement or solicitation for purposes of regulation of commercial electronic mail messages. If you do not wish to receive commercial e-mail communications from Piper Jaffray, go to: www.piperjaffray.com/do_not_email to review the details and submit your request to be added to the Piper Jaffray "Do Not E-mail Registry." For additional disclosure information see www.piperjaffray.com/disclosures
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160926/5592879a/attachment.htm>

From rousskov at measurement-factory.com  Mon Sep 26 18:08:44 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 26 Sep 2016 12:08:44 -0600
Subject: [squid-users] Question: Is it possible adaptation_service_chain
 from services with different access lists?
In-Reply-To: <ac367c8d-144b-d05a-3893-2842306d60c1@gmail.com>
References: <66ab3541-531a-4c8d-d26b-fa1ddd88a43b@gmail.com>
 <2ea6f023-e6c6-45cd-0e6a-60b83d843809@measurement-factory.com>
 <4c37cb2d-8fd1-8ea5-b82b-e879c46b816e@gmail.com>
 <9b1317c1-99ac-4ff1-b5ca-47e97760f504@measurement-factory.com>
 <ac367c8d-144b-d05a-3893-2842306d60c1@gmail.com>
Message-ID: <27835cdb-e964-ea2d-19d9-c95657e3fcd1@measurement-factory.com>

On 09/26/2016 11:32 AM, Yuri Voinov wrote:
> 26.09.2016 23:16, Alex Rousskov ?????:
>> On 09/26/2016 10:42 AM, Yuri Voinov wrote:
>>> How can I make a chain of adaptation with
>>> different acl's for different chained services?

>> By configuring several chains and then writing adaptation_access rules
>> to select the right chain for a given message.


> Ahaaaaaaaaa. I.e., I can specify chain_A with own access rules and one
> service_A in chain, and then chain_B, also with own access rules and one
> service_B, and, finally, specify chain_C with chain_A+chain_B and with
> access "all". Right?

Whether that is right or wrong depends on the specific ACLs. Also, there
is no need to create single-service chains. If your rulesA are mutually
exclusive with rulesB, then you can use them like this:

  adaptation_access serviceA rulesA
  adaptation_access serviceB rulesB
  adaptation_access chainAB all

However, again, I discourage you from saying "chain_A with own access
rulesA" because access rules do not belong to a chain. Squid evaluates
adaptation_access lines in the squid.conf order. Thus, if rulesA are NOT
mutually exclusive with rulesB, then the following configuration will
have a different effect from the above three lines:

  adaptation_access serviceB rulesB
  adaptation_access serviceA rulesA
  adaptation_access chainAB all

and this configuration does not make any sense at all:

  adaptation_access chainAB all
  adaptation_access serviceA rulesA
  adaptation_access serviceB rulesB


It is better to think like this:

  adaptation_access serviceA rules1
  adaptation_access serviceB rules2
  adaptation_access chainC rules3

serviceA is used when and only when "rules1" matches
serviceB is used when and only when "!rules1 rules2" matches
chainC is used when and only when "!rules1 !rules2 rules3" matches

Each message will be sent to either just serviceA, or just serviceB, or
just ChainC, or no services/chains/sets at all.


HTH,

Alex.


From yvoinov at gmail.com  Mon Sep 26 18:20:53 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 27 Sep 2016 00:20:53 +0600
Subject: [squid-users] Question: Is it possible adaptation_service_chain
 from services with different access lists?
In-Reply-To: <27835cdb-e964-ea2d-19d9-c95657e3fcd1@measurement-factory.com>
References: <66ab3541-531a-4c8d-d26b-fa1ddd88a43b@gmail.com>
 <2ea6f023-e6c6-45cd-0e6a-60b83d843809@measurement-factory.com>
 <4c37cb2d-8fd1-8ea5-b82b-e879c46b816e@gmail.com>
 <9b1317c1-99ac-4ff1-b5ca-47e97760f504@measurement-factory.com>
 <ac367c8d-144b-d05a-3893-2842306d60c1@gmail.com>
 <27835cdb-e964-ea2d-19d9-c95657e3fcd1@measurement-factory.com>
Message-ID: <782af7b9-5cc8-a090-26f1-3b76ae6c4862@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 

27.09.2016 0:08, Alex Rousskov ?????:
> On 09/26/2016 11:32 AM, Yuri Voinov wrote:
>> 26.09.2016 23:16, Alex Rousskov ?????:
>>> On 09/26/2016 10:42 AM, Yuri Voinov wrote:
>>>> How can I make a chain of adaptation with
>>>> different acl's for different chained services?
>
>>> By configuring several chains and then writing adaptation_access rules
>>> to select the right chain for a given message.
>
>
>> Ahaaaaaaaaa. I.e., I can specify chain_A with own access rules and one
>> service_A in chain, and then chain_B, also with own access rules and one
>> service_B, and, finally, specify chain_C with chain_A+chain_B and with
>> access "all". Right?
>
> Whether that is right or wrong depends on the specific ACLs. Also, there
> is no need to create single-service chains. If your rulesA are mutually
> exclusive with rulesB, then you can use them like this:
>
>   adaptation_access serviceA rulesA
>   adaptation_access serviceB rulesB
>   adaptation_access chainAB all
>
> However, again, I discourage you from saying "chain_A with own access
> rulesA" because access rules do not belong to a chain. Squid evaluates
> adaptation_access lines in the squid.conf order. Thus, if rulesA are NOT
> mutually exclusive with rulesB, then the following configuration will
> have a different effect from the above three lines:
>
>   adaptation_access serviceB rulesB
>   adaptation_access serviceA rulesA
>   adaptation_access chainAB all
>
> and this configuration does not make any sense at all:
>
>   adaptation_access chainAB all
>   adaptation_access serviceA rulesA
>   adaptation_access serviceB rulesB
>
>
> It is better to think like this:
>
>   adaptation_access serviceA rules1
>   adaptation_access serviceB rules2
>   adaptation_access chainC rules3
>
> serviceA is used when and only when "rules1" matches
> serviceB is used when and only when "!rules1 rules2" matches
> chainC is used when and only when "!rules1 !rules2 rules3" matches
>
> Each message will be sent to either just serviceA, or just serviceB, or
> just ChainC, or no services/chains/sets at all.
Ahaaaaaaaa, yes. Understand.

It is now clear. I rewrote the access rules and now adaptation works in
the chain at the right logic. Thank you for your explanations and your time!
>
>
>
> HTH,
>
> Alex.

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX6WcFAAoJENNXIZxhPexGWfEIAL8e3Al3C2lAxoKC8qCByzch
iKqBwOUbQBBoiQDsrKG0qgF4B+VMpalnO7OvtNOw/P9zcVAU27kzh643H3ynJCHY
gxEtrc2wjJjM1OlIEg0qR8cs4chC+bQ9eaySJtArAFnWktS6hm7VjebgivZq5IMT
eCz9EFizwVLld04QLKbOAX5cL2z8+ScumKPYH9ygEhllnNAdtg+9r3GwFJoOGPyM
JebsZjUTX56SrGZyEro89T2acGWC4rwJ1+oBwcMtp+rD5RUjAUStG/4teAdPopIA
R6v2hBHQSSsyttpaP9QL55JmhQmeV21FCAvyuU58pVv05UDVh4iROcWY43XY4IE=
=++B5
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160927/68df9247/attachment.key>

From jlay at slave-tothe-box.net  Mon Sep 26 18:28:10 2016
From: jlay at slave-tothe-box.net (James Lay)
Date: Mon, 26 Sep 2016 12:28:10 -0600
Subject: [squid-users] Clarification on icap
In-Reply-To: <0ebb7801-8d45-2097-2756-0cfb7c3fc970@measurement-factory.com>
References: <1474890072.2709.6.camel@slave-tothe-box.net>
 <10bbdad1-1892-ff29-1c0a-7db095cf2119@measurement-factory.com>
 <81153b82678a1d8430523326df800bc2@localhost>
 <377d2ec5-6d05-9c10-4b3e-6aa2732aeae1@measurement-factory.com>
 <f002ad762ea7f45e1200e1165246bee3@localhost>
 <0ebb7801-8d45-2097-2756-0cfb7c3fc970@measurement-factory.com>
Message-ID: <9a800e58baa751df1839f0825296ab83@localhost>

On 2016-09-26 10:40, Alex Rousskov wrote:
> On 09/26/2016 08:55 AM, James Lay wrote:
>> any recommended open source ICAP/eCAP services that squid works well 
>> with?
> 
> You do not need an ICAP/eCAP service that Squid works well with. You
> need an ICAP/eCAP service that integrates with your IDS. All production
> ICAP/eCAP services are doing some specific adaptation (e.g., downgrade
> image quality) or integrate with some specific adaptation library 
> (e.g.,
> ClamAV). They are useless to you unless they integrate with your IDS.
> 
> If there is no existing service that integrates with your IDS, you 
> would
> have to write and support one. If you go the ICAP route, many plug 
> their
> custom ICAP services into the free c-icap ICAP server. If you decide
> going the eCAP route, then you do not need a server (eCAP is a
> library/API, not a communication protocol, so your custom code plugs
> directly into the host application such as Squid).
> 
>   http://wiki.squid-cache.org/SquidFaq/ContentAdaptation
> 
> Alex.

Excellent...thanks so much Alex!

James


From squid3 at treenet.co.nz  Mon Sep 26 21:04:04 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 27 Sep 2016 10:04:04 +1300
Subject: [squid-users] How to log url_rewrite_program results
In-Reply-To: <CAEnCSG4uP9NXNxDS5R_ddNfjZSDq3Hc=Sek=dU4hLS88kBzLmg@mail.gmail.com>
References: <CAEnCSG4uP9NXNxDS5R_ddNfjZSDq3Hc=Sek=dU4hLS88kBzLmg@mail.gmail.com>
Message-ID: <17424c8a-df5d-e651-b210-e1bf1299cd96@treenet.co.nz>

On 27/09/2016 2:50 a.m., Michael Pelletier wrote:
> Hello,
> 
> I have a custom logformat and I would like to log the results of my url
> rewriter (urlfilterdb). I can't seem to get this to work. Can someone tell
> me the basics?

The helper potocol is outlined at
<http://wiki.squid-cache.org/Features/AddonHelpers#URL_manipulation>.

Each 'key=' in the helper output gets appended to the HTTP transaction
as an annotation 'note'. The logging can display these via the
%note{key-name} format code.

For older helpers that use the pre-3.4 protocol without kv-pairs their
responses get mapped into the kv-pair format. So you should see the same
%note{url} or %note{rewrite-url} annotations at logging time even with
older helpers.

Amos



From squid3 at treenet.co.nz  Mon Sep 26 21:10:36 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 27 Sep 2016 10:10:36 +1300
Subject: [squid-users] New error on version 3.5.19
In-Reply-To: <916606669CFF224AB6997E9DB783F6EACCCDADC4@ESCML200.corp.pjc.com>
References: <916606669CFF224AB6997E9DB783F6EACCCDADC4@ESCML200.corp.pjc.com>
Message-ID: <c570fee0-c3cd-154f-d22e-9a0cf0d377c3@treenet.co.nz>

On 27/09/2016 7:01 a.m., Berkes, David wrote:
> Hi squid community, I'm seeing a new error in my squid logs.  These
> are iphones configured for a squid proxy.  They are running IOS
> 10.0.2 and siri is now failing.  You can see the request is allowed
> through, but is preceded with the error lines then siri fails.  Any
> idea of what these errors indicate.  They seem to be the root cause
> for the siri requests failing.
> 

"error:invalid-request" indicates that the traffic arriving to Squid is
not using HTTP message format.

You are going to need a "debug_options ALL,9" cache.log trace or
perhapse a TCP packet trace (with full packet payloads recorded) in
order to find out what is actually being set to Squid.

At a guess I suspect it might be WebSockets if you are intercepting port 80.

Amos



From squid3 at treenet.co.nz  Mon Sep 26 21:19:37 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 27 Sep 2016 10:19:37 +1300
Subject: [squid-users] Squid 3.5.21 - High CPU (100%)
In-Reply-To: <1474903432467-4679705.post@n4.nabble.com>
References: <1474466015.14617.153.camel@shoprite.co.za>
 <d72ccfb0-8e9d-261b-d52f-3be082566d35@measurement-factory.com>
 <1474873185.9155.24.camel@shoprite.co.za>
 <eda6e7a2-c172-d9be-905c-825b48365261@measurement-factory.com>
 <1474899725.9155.131.camel@shoprite.co.za>
 <1474903432467-4679705.post@n4.nabble.com>
Message-ID: <40cdc687-ea3f-b398-c44a-c5232dcdf984@treenet.co.nz>

On 27/09/2016 4:23 a.m., reinerotto wrote:
>> FATAL: Received Segment Violation...dying.
> 2016/09/26 15:54:54 kid1| Closing HTTP port 0.0.0.0:8080
> 2016/09/26 15:54:54 kid1| storeDirWriteCleanLogs: Starting...
> 2016/09/26 15:54:54 kid1|     65536 entries written so far.    <<<-----
> short Int ?????????
> 
> Makes me a bit suspicious regarding possible overflow ...
> 

Maybe. Maybe not. The loading is broken down into smaller batches so as
not to block other traffic handling on possibly slow cache_dir rebuilds.
Depends on whether there is a followup with a larger number in the log.

Amos



From squid3 at treenet.co.nz  Mon Sep 26 21:27:40 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 27 Sep 2016 10:27:40 +1300
Subject: [squid-users] Squid 3.5.21 - High CPU (100%)
In-Reply-To: <1474899725.9155.131.camel@shoprite.co.za>
References: <1474466015.14617.153.camel@shoprite.co.za>
 <d72ccfb0-8e9d-261b-d52f-3be082566d35@measurement-factory.com>
 <1474873185.9155.24.camel@shoprite.co.za>
 <eda6e7a2-c172-d9be-905c-825b48365261@measurement-factory.com>
 <1474899725.9155.131.camel@shoprite.co.za>
Message-ID: <ce54f56a-ea1d-407d-8b9f-093e005a693c@treenet.co.nz>

On 27/09/2016 3:22 a.m., Jasper Van Der Westhuizen wrote:
> 
> Is there anything that you guys can suggest I do around the cache? 
> Should I try a different store type? A different filesystem type
> perhaps?
> 
> 
> 
> If your store has a configuration knob that effectively limits disk 
> writing rate, then use it to limit that rate to avoid overflowing the
> queue.
> 
> You can also consider using rock store that has an explicit write
> rate limiting option (but comes with other problems that may or may
> not affect your setup).
> 
> Adding more physical disk spindles helps, of course.
> 

Just to be clear since you mentioned working with virtual services. By
"spindle" Alex refers to individual physical HDD devices underneath the
whole VM storage setup. 'Disk' a the VM level, even at the RAID level
might refer to multiple or overlapping (shared) 'spindles'.

Unless your AUFS/UFS/diskd cache_dir are limited to being on one
"spindle" HDD, they can cause a shared HDD controller to fill up /
overload and adding more cache_dir just makes that particular problem worse.

Amos



From squid-user at tlinx.org  Tue Sep 27 02:04:37 2016
From: squid-user at tlinx.org (Linda A. Walsh)
Date: Mon, 26 Sep 2016 19:04:37 -0700
Subject: [squid-users] --enable-openssl-crtd -- not building openssl-crtd?
	(3.5.21)
Message-ID: <57E9D3B5.6050405@tlinx.org>

In squid 3.5.21, I'm setting the --enable-openssl-crtd option, but it is
not building ./src/sll/ssl_crtd.cc into an executable (and none is
installed in /usr/lib64/squid, where everything else seems to get installed.

I also note, though that the --enable-openssl-crtd option is not
listed in 'configure --help' -- is that intentional?  Maybe the
fact that it isn't listed means the option is _silently_ ignored (don't
see any reference to "crtd" except in where my configure options are
listed.

In the build log, I see 1 "line" that appears to reference the line:
sed \
-e "s%[@]DEFAULT_HTTP_PORT[@]%3128%g" \
-e "s%[@]DEFAULT_ICP_PORT[@]%3130%g" \
-e "s%[@]DEFAULT_CACHE_EFFECTIVE_USER[@]%squid%g" \
-e "s%[@]DEFAULT_MIME_TABLE[@]%/etc/squid/mime.conf%g" \
-e "s%[@]DEFAULT_SSL_CRTD[@]%/usr/lib64/squid/`echo ssl_crtd  | sed 
's,x,x,;s/$//'`%g" \
....

but nothing showing any error or actual file reference.

Is it no longer used or why isn't the option generating the 'helper'?




From michael.pelletier at palmbeachschools.org  Tue Sep 27 02:59:13 2016
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Mon, 26 Sep 2016 22:59:13 -0400
Subject: [squid-users] How to log url_rewrite_program results
In-Reply-To: <17424c8a-df5d-e651-b210-e1bf1299cd96@treenet.co.nz>
References: <CAEnCSG4uP9NXNxDS5R_ddNfjZSDq3Hc=Sek=dU4hLS88kBzLmg@mail.gmail.com>
 <17424c8a-df5d-e651-b210-e1bf1299cd96@treenet.co.nz>
Message-ID: <CAEnCSG4oimyDYpM6asO=P+HausrH73eSU9p0S=0USpTt9+qNhg@mail.gmail.com>

OK. I will try this. Really, All I am trying to log is the ACL that was
matched and the result. Is the default in
*url_rewrite_extras good enough?*

On Mon, Sep 26, 2016 at 5:04 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 27/09/2016 2:50 a.m., Michael Pelletier wrote:
> > Hello,
> >
> > I have a custom logformat and I would like to log the results of my url
> > rewriter (urlfilterdb). I can't seem to get this to work. Can someone
> tell
> > me the basics?
>
> The helper potocol is outlined at
> <http://wiki.squid-cache.org/Features/AddonHelpers#URL_manipulation>.
>
> Each 'key=' in the helper output gets appended to the HTTP transaction
> as an annotation 'note'. The logging can display these via the
> %note{key-name} format code.
>
> For older helpers that use the pre-3.4 protocol without kv-pairs their
> responses get mapped into the kv-pair format. So you should see the same
> %note{url} or %note{rewrite-url} annotations at logging time even with
> older helpers.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160926/38896432/attachment.htm>

From squid3 at treenet.co.nz  Tue Sep 27 03:09:39 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 27 Sep 2016 16:09:39 +1300
Subject: [squid-users] --enable-openssl-crtd -- not building
 openssl-crtd? (3.5.21)
In-Reply-To: <57E9D3B5.6050405@tlinx.org>
References: <57E9D3B5.6050405@tlinx.org>
Message-ID: <598baad3-64d1-b873-b266-55ab5d96fb0c@treenet.co.nz>

On 27/09/2016 3:04 p.m., Linda A. Walsh wrote:
> In squid 3.5.21, I'm setting the --enable-openssl-crtd option, but it is
> not building ./src/sll/ssl_crtd.cc into an executable (and none is
> installed in /usr/lib64/squid, where everything else seems to get
> installed.
> 
> I also note, though that the --enable-openssl-crtd option is not
> listed in 'configure --help' -- is that intentional?  Maybe the
> fact that it isn't listed means the option is _silently_ ignored (don't
> see any reference to "crtd" except in where my configure options are
> listed.

There is no such option. Never has been.

## ./configure --help | grep ssl

  --enable-ssl-crtd       ...

  --with-openssl=PATH     Compile with the OpenSSL libraries. ...


Amos



From michael.pelletier at palmbeachschools.org  Tue Sep 27 03:25:22 2016
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Mon, 26 Sep 2016 23:25:22 -0400
Subject: [squid-users] How to log url_rewrite_program results
In-Reply-To: <CAEnCSG4oimyDYpM6asO=P+HausrH73eSU9p0S=0USpTt9+qNhg@mail.gmail.com>
References: <CAEnCSG4uP9NXNxDS5R_ddNfjZSDq3Hc=Sek=dU4hLS88kBzLmg@mail.gmail.com>
 <17424c8a-df5d-e651-b210-e1bf1299cd96@treenet.co.nz>
 <CAEnCSG4oimyDYpM6asO=P+HausrH73eSU9p0S=0USpTt9+qNhg@mail.gmail.com>
Message-ID: <CAEnCSG5PoN+EUowmE+XLAtwS8y_h4+w2ji0m+=R2Kou7UKShSw@mail.gmail.com>

I tried
%{message}note %{status}note
-- and --
%note{message}note %note{status}

But I do not get results...

On Mon, Sep 26, 2016 at 10:59 PM, Michael Pelletier <
michael.pelletier at palmbeachschools.org> wrote:

> OK. I will try this. Really, All I am trying to log is the ACL that was
> matched and the result. Is the default in
> *url_rewrite_extras good enough?*
>
> On Mon, Sep 26, 2016 at 5:04 PM, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
>
>> On 27/09/2016 2:50 a.m., Michael Pelletier wrote:
>> > Hello,
>> >
>> > I have a custom logformat and I would like to log the results of my url
>> > rewriter (urlfilterdb). I can't seem to get this to work. Can someone
>> tell
>> > me the basics?
>>
>> The helper potocol is outlined at
>> <http://wiki.squid-cache.org/Features/AddonHelpers#URL_manipulation>.
>>
>> Each 'key=' in the helper output gets appended to the HTTP transaction
>> as an annotation 'note'. The logging can display these via the
>> %note{key-name} format code.
>>
>> For older helpers that use the pre-3.4 protocol without kv-pairs their
>> responses get mapped into the kv-pair format. So you should see the same
>> %note{url} or %note{rewrite-url} annotations at logging time even with
>> older helpers.
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>
>

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160926/e0ce1bb9/attachment.htm>

From squid-user at tlinx.org  Tue Sep 27 04:04:12 2016
From: squid-user at tlinx.org (Linda W)
Date: Mon, 26 Sep 2016 21:04:12 -0700
Subject: [squid-users] --enable-openssl-crtd -- not building
	openssl-crtd? (3.5.21)
In-Reply-To: <598baad3-64d1-b873-b266-55ab5d96fb0c@treenet.co.nz>
References: <57E9D3B5.6050405@tlinx.org>
 <598baad3-64d1-b873-b266-55ab5d96fb0c@treenet.co.nz>
Message-ID: <57E9EFBC.5040407@tlinx.org>

Amos Jeffries wrote:
> There is no such option. Never has been.
>
> ## ./configure --help | grep ssl
>
>   --enable-ssl-crtd       ...
>
>   --with-openssl=PATH     Compile with the OpenSSL libraries. ...
>   
----
Oops... Conflated the two... back to configuring...
tnx,
-l

>   


From jvdwesthuiz at shoprite.co.za  Tue Sep 27 04:06:23 2016
From: jvdwesthuiz at shoprite.co.za (Jasper Van Der Westhuizen)
Date: Tue, 27 Sep 2016 04:06:23 +0000
Subject: [squid-users] Squid 3.5.21 - High CPU (100%)
In-Reply-To: <ce54f56a-ea1d-407d-8b9f-093e005a693c@treenet.co.nz>
References: <1474466015.14617.153.camel@shoprite.co.za>
 <d72ccfb0-8e9d-261b-d52f-3be082566d35@measurement-factory.com>
 <1474873185.9155.24.camel@shoprite.co.za>
 <eda6e7a2-c172-d9be-905c-825b48365261@measurement-factory.com>
 <1474899725.9155.131.camel@shoprite.co.za>
 <ce54f56a-ea1d-407d-8b9f-093e005a693c@treenet.co.nz>
Message-ID: <1474949181.9155.153.camel@shoprite.co.za>




> Is there anything that you guys can suggest I do around the cache?
> Should I try a different store type? A different filesystem type
> perhaps?
>
>
>
> If your store has a configuration knob that effectively limits disk
> writing rate, then use it to limit that rate to avoid overflowing the
> queue.
>
> You can also consider using rock store that has an explicit write
> rate limiting option (but comes with other problems that may or may
> not affect your setup).
>
> Adding more physical disk spindles helps, of course.
>

Just to be clear since you mentioned working with virtual services. By
"spindle" Alex refers to individual physical HDD devices underneath the
whole VM storage setup. 'Disk' a the VM level, even at the RAID level
might refer to multiple or overlapping (shared) 'spindles'.

Unless your AUFS/UFS/diskd cache_dir are limited to being on one
"spindle" HDD, they can cause a shared HDD controller to fill up /
overload and adding more cache_dir just makes that particular problem worse.

Amos


Hi Amos

At the time of my email my cache_dir was a 100GB disk assigned from the same datastore as where the VM is. I have to say that I never had problems with this setup. The storage is provided from a IBM XIV storage unit so it's not the slowest of storage devices. After some discussions with a couple of people we thought that perhaps the cache is too big, so I now made it 4 x 15GB aufs cach_dirs. 2 Disks are from the same datastore as the VM, and 2 are from a datastore assigned to the cluster from a SVC (XIV behind it) with the following in my squid.conf.

maximum_object_size_in_memory 256 KB
maximum_object_size 4096 MB
store_dir_select_algorithm least-load

cache_dir aufs /var/cache/squid-c1/ 10240 32 256
cache_dir aufs /var/cache/squid-c2/ 10240 32 256
cache_dir aufs /var/cache/squid-c3/ 10240 32 256
cache_dir aufs /var/cache/squid-c4/ 10240 32 256
cache_replacement_policy heap lfuda
memory_replacement_policy lru


Do you think this is optimal?














Disclaimer:
http://www.shopriteholdings.co.za/Pages/ShopriteE-mailDisclaimer.aspx
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160927/17087f22/attachment.htm>

From amaury at tin.it  Tue Sep 27 09:15:09 2016
From: amaury at tin.it (amaury at tin.it)
Date: Tue, 27 Sep 2016 11:15:09 +0200 (CEST)
Subject: [squid-users] R: Re:  problem reload configuration with workers
Message-ID: <1576aed2708.amaury@tin.it>

Hi Alex
thank you for your answer.
Obviously, I intended to write 
squid.
I have resolve my problem changing the workers configuration 
from:

workers 4
http_access allow localhost
http_port localhost:
400${process_number}
cache_dir aufs /var/spool/squid 16384 32 512

cache_dir rock /var/spool/squid/rock 16384 max-size=32768
cache_dir 
aufs /var/spool/squid/squid-cache0${process_number} 16384 16 512 min-
size=32769

to

workers 4
http_access allow localhost
http_port 
localhost:400${process_number}
cache_dir rock /var/spool/squid/rock 
16384 max-size=32768

if ${process_number} = 1
        cache_dir aufs 
/var/spool/squid/squid-cache01 16384 16 512 min-size=32769
endif
if 
${process_number} = 2
        cache_dir aufs /var/spool/squid/squid-
cache02 16384 16 512 min-size=32769
endif
if ${process_number} = 3

        cache_dir aufs /var/spool/squid/squid-cache03 16384 16 512 min-
size=32769
endif
if ${process_number} = 4
        cache_dir aufs 
/var/spool/squid/squid-cache04 16384 16 512 min-size=32769
endif

 
Thank you

----Messaggio originale----
Da: rousskov at measurement-factory.
com
Data: 26-set-2016 16.12
A: <squid-users at lists.squid-cache.org>
Cc: 
"amaury at tin.it"<amaury at tin.it>
Ogg: Re: [squid-users] problem reload 
configuration with workers

On 09/26/2016 08:02 AM, amaury at tin.it 
wrote:

> I'm using squid 3.5.21-20160908-r14081 and for the first time 
I'm 
> using workers configuration. I have a problem:
> when I reload 
configuration (via init script)
> suid -k reconfigure -f 
/et/squid/squid.conf

I assume that by "suid" you meant "squid". If 
yes, then the above
command is a correct way to reconfigure Squid, 
including SMP Squid.


> the system kill squid-coord and squid-disk


Does "the system" do more than run "squid -k reconfigure ..."?

* If 
not, then "the system" does not kill squid-coord and squid-disk

(something else does).

* If yes, then you should fix your system 
script. Perhaps it thinks that
Squid died and tries to kill/restart it?



> So I have to remove pd 
> file and lock files and restart squid.
> 
Please, do it exist a solution 
> to reload with restart squid?


Reconfiguration should work "as is". If it does not work, file a bug

report with details such as your system command(s) and resulting
cache.
log and syslog output.


> I tried also using something like:
> 
> 
pid_filename /var/run/squid/squid-{proccess_number}.

Please do not do 
that. SMP Squid is designed to work with a single
configuration file 
without SMP macros.


Thank you,

Alex.






From rousskov at measurement-factory.com  Tue Sep 27 15:38:09 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 27 Sep 2016 09:38:09 -0600
Subject: [squid-users] R: Re: problem reload configuration with workers
In-Reply-To: <1576aed2708.amaury@tin.it>
References: <1576aed2708.amaury@tin.it>
Message-ID: <9bafba5c-1771-32d2-0c66-f936524dc596@measurement-factory.com>

On 09/27/2016 03:15 AM, amaury at tin.it wrote:
> I have resolve my problem changing the workers configuration from:
> 
> workers 4
> http_access allow localhost
> http_port localhost:
> 400${process_number}
> cache_dir aufs /var/spool/squid 16384 32 512
> 
> cache_dir rock /var/spool/squid/rock 16384 max-size=32768
> cache_dir aufs /var/spool/squid/squid-cache0${process_number} 16384 16 512 min-size=32769

The above combination of SMP-aware and SMP-unaware caches is unsupported
and probably will not work.


> to
> 
> workers 4
> http_access allow localhost
> http_port 
> localhost:400${process_number}
> cache_dir rock /var/spool/squid/rock 16384 max-size=32768
> 
> if ${process_number} = 1
>         cache_dir aufs /var/spool/squid/squid-cache01 16384 16 512 min-size=32769
> endif
> if 
> ${process_number} = 2
>         cache_dir aufs /var/spool/squid/squid-cache02 16384 16 512 min-size=32769
> endif
> if ${process_number} = 3 
>         cache_dir aufs /var/spool/squid/squid-cache03 16384 16 512 min-size=32769
> endif
> if ${process_number} = 4
>         cache_dir aufs /var/spool/squid/squid-cache04 16384 16 512 min-size=32769
> endif

The above is equivalent to

  workers 4
  http_access allow localhost
  http_port
  localhost:400${process_number}
  cache_dir rock /var/spool/squid/rock 16384 max-size=32768
  cache_dir aufs /var/spool/squid/squid-cache${process_number} 16384 ...

which is still an unsupported combination of SMP-aware and SMP-unaware
caches that probably will not work.

BTW, why do you give each worker a dedicated listening port (i.e.,
"400${process_number}")?

Alex.


> ----Messaggio originale----
> Da: rousskov at measurement-factory.
> com
> Data: 26-set-2016 16.12
> A: <squid-users at lists.squid-cache.org>
> Cc: 
> "amaury at tin.it"<amaury at tin.it>
> Ogg: Re: [squid-users] problem reload 
> configuration with workers
> 
> On 09/26/2016 08:02 AM, amaury at tin.it 
> wrote:
> 
>> I'm using squid 3.5.21-20160908-r14081 and for the first time 
> I'm 
>> using workers configuration. I have a problem:
>> when I reload 
> configuration (via init script)
>> suid -k reconfigure -f 
> /et/squid/squid.conf
> 
> I assume that by "suid" you meant "squid". If 
> yes, then the above
> command is a correct way to reconfigure Squid, 
> including SMP Squid.
> 
> 
>> the system kill squid-coord and squid-disk
> 
> 
> Does "the system" do more than run "squid -k reconfigure ..."?
> 
> * If 
> not, then "the system" does not kill squid-coord and squid-disk
> 
> (something else does).
> 
> * If yes, then you should fix your system 
> script. Perhaps it thinks that
> Squid died and tries to kill/restart it?
> 
> 
> 
>> So I have to remove pd 
>> file and lock files and restart squid.
>>
> Please, do it exist a solution 
>> to reload with restart squid?
> 
> 
> Reconfiguration should work "as is". If it does not work, file a bug
> 
> report with details such as your system command(s) and resulting
> cache.
> log and syslog output.
> 
> 
>> I tried also using something like:
>>
>>
> pid_filename /var/run/squid/squid-{proccess_number}.
> 
> Please do not do 
> that. SMP Squid is designed to work with a single
> configuration file 
> without SMP macros.
> 
> 
> Thank you,
> 
> Alex.
> 
> 
> 



From rousskov at measurement-factory.com  Tue Sep 27 15:55:54 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 27 Sep 2016 09:55:54 -0600
Subject: [squid-users] How to log url_rewrite_program results
In-Reply-To: <CAEnCSG5PoN+EUowmE+XLAtwS8y_h4+w2ji0m+=R2Kou7UKShSw@mail.gmail.com>
References: <CAEnCSG4uP9NXNxDS5R_ddNfjZSDq3Hc=Sek=dU4hLS88kBzLmg@mail.gmail.com>
 <17424c8a-df5d-e651-b210-e1bf1299cd96@treenet.co.nz>
 <CAEnCSG4oimyDYpM6asO=P+HausrH73eSU9p0S=0USpTt9+qNhg@mail.gmail.com>
 <CAEnCSG5PoN+EUowmE+XLAtwS8y_h4+w2ji0m+=R2Kou7UKShSw@mail.gmail.com>
Message-ID: <06c7b4dd-65d9-eb71-a1c3-e38edb87311a@measurement-factory.com>

On 09/26/2016 09:25 PM, Michael Pelletier wrote:
> I tried
> %{message}note %{status}note
> But I do not get results...

Did your helper return message=... and status=... annotations to Squid?
The %note logformat code expands into transaction annotations.
Annotations come from helpers (and other sources irrelevant for this
discussion).


> All I am trying to log is the ACL that was matched and the result. Is
> the default in url_rewrite_extras good enough?

You seem to be asking a question that only you can answer: You know what
your helper can do and how it is used. url_rewrite_extras is about
information passed from Squid to your helper. You know what information
the default url_rewrite_extras passes to your helper. Is that
information enough for your helper to responds with annotations
containing "the ACL that was matched and the result" info?


Alex.



> On Mon, Sep 26, 2016 at 10:59 PM, Michael Pelletier wrote:
> 
>     OK. I will try this. Really, All I am trying to log is the ACL that
>     was matched and the result. Is the default in *url_rewrite_extras
>     good enough?
>     *
> 
>     On Mon, Sep 26, 2016 at 5:04 PM, Amos Jeffries <squid3 at treenet.co.nz
>     <mailto:squid3 at treenet.co.nz>> wrote:
> 
>         On 27/09/2016 2:50 a.m., Michael Pelletier wrote:
>         > Hello,
>         >
>         > I have a custom logformat and I would like to log the results of my url
>         > rewriter (urlfilterdb). I can't seem to get this to work. Can someone tell
>         > me the basics?
> 
>         The helper potocol is outlined at
>         <http://wiki.squid-cache.org/Features/AddonHelpers#URL_manipulation
>         <http://wiki.squid-cache.org/Features/AddonHelpers#URL_manipulation>>.
> 
>         Each 'key=' in the helper output gets appended to the HTTP
>         transaction
>         as an annotation 'note'. The logging can display these via the
>         %note{key-name} format code.
> 
>         For older helpers that use the pre-3.4 protocol without kv-pairs
>         their
>         responses get mapped into the kv-pair format. So you should see
>         the same
>         %note{url} or %note{rewrite-url} annotations at logging time
>         even with
>         older helpers.
> 
>         Amos
> 
>         _______________________________________________
>         squid-users mailing list
>         squid-users at lists.squid-cache.org
>         <mailto:squid-users at lists.squid-cache.org>
>         http://lists.squid-cache.org/listinfo/squid-users
>         <http://lists.squid-cache.org/listinfo/squid-users>
> 
> 
> 
> 
> *Disclaimer: *Under Florida law, e-mail addresses are public records. If
> you do not want your e-mail address released in response to a public
> records request, do not send electronic mail to this entity. Instead,
> contact this office by phone or in writing.
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From emz at norma.perm.ru  Tue Sep 27 17:13:17 2016
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Tue, 27 Sep 2016 22:13:17 +0500
Subject: [squid-users] connections from particular users sometimes get stuck
Message-ID: <42b972b9-77a7-f43d-1630-fe31a71ab508@norma.perm.ru>

Hi.

I have a weird problem. I run a squid cache 3.5.19 on FreeBSD/amd64, 
with about 300 active users, lots of authentication, external helpers 
(yeah, it's usually the place when one starts to post configs, but let 
me get to the point), and everything basically works just fine, but 
sometimes one particular user (don't know, may be it's one particular 
machine or some other entity) starts to have troubles. Usual trouble 
looks like the following:

- around 299 users are working and authenticatiing just fine

- one particular user starts experiencing connection stucking: his 
browser requests a web page, it starts to load and then some random 
object on it blocks indefinitely.

- this happens every time on one machine, for the time given. This 
machine is permanent for a given issue, until it's gone. Then it's some 
another machine, and I cannot figure out the pattern.

- this machine may be locked in this malfuctioning state for days. This 
state is usually cleared by the squid restart, or it may clear itself.

- after a month or so the issue appears on another machine. and it 
persists on a new machine for quite some time.

On a l3 level this looks simple: browser requests an object, gets 407 
answer, replies with proper credentials set and then this connection 
goes indefinitely into a keepalived state: the squid and the browser 
send keepalives to each other, but nothing happens other than 
keepalives. User sees the spinning loader on a browser tab, and some 
content inside the tab, depending on how many objects the browses has 
received. In the same time new connections to squid are opening from 
this machine just fine, and the basic connectivity is normal for both 
the squid and the troubled machine. Furthermore, I'm sure that this 
problem isn't caused by bottlenecks on the squid machine: because it 
this way all the users would have eventually this problem, not only one. 
In the same time these aren't bottlenecks on the user machine: while the 
browser is stuck, other applications are working fine. If I switch the 
proxy to a backup squid (on another server) this machine is able to 
browse the internet.

I really need to solve this, but I have no idea where to start. The 
error log show nothing suspicious.

The wireshark screen where the issue is isolated for one particular 
connection can be found here - 
https://gyazo.com/fdec1d9d7c31a75afc7d4676abb83d15 (it's really a simple 
picture: TCP connection establishing, then GET -> 407 -> GET and bunch 
of keepalives, not a rocket science).

Any ideas ?

Thanks.

Eugene.



From rousskov at measurement-factory.com  Tue Sep 27 19:29:03 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 27 Sep 2016 13:29:03 -0600
Subject: [squid-users] connections from particular users sometimes get
 stuck
In-Reply-To: <42b972b9-77a7-f43d-1630-fe31a71ab508@norma.perm.ru>
References: <42b972b9-77a7-f43d-1630-fe31a71ab508@norma.perm.ru>
Message-ID: <91801fea-4baa-375b-7a91-91a0d1040e46@measurement-factory.com>

On 09/27/2016 11:13 AM, Eugene M. Zheganin wrote:

> The wireshark screen where the issue is isolated for one particular
> connection can be found here -
> https://gyazo.com/fdec1d9d7c31a75afc7d4676abb83d15 (it's really a simple
> picture: TCP connection establishing, then GET -> 407 -> GET and bunch
> of keepalives, not a rocket science).
> 
> Any ideas ?

Since you can reproduce this, I suggest collecting ALL,9 log for the
stuck master transaction:

http://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction

If collecting a debugging trace is impossible for some reason, then
collect the corresponding TCP packets on the Squid to origin server link
and post actual packets (not screenshots of packet summaries) from both
connections. The debugging trace will most likely have the answer. The
packet trace might have the answer.

You may need to change user credentials for this test or after posting
the details requested above.


Cheers,

Alex.



From emz at norma.perm.ru  Tue Sep 27 20:02:20 2016
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Wed, 28 Sep 2016 01:02:20 +0500
Subject: [squid-users] connections from particular users sometimes get
 stuck
In-Reply-To: <91801fea-4baa-375b-7a91-91a0d1040e46@measurement-factory.com>
References: <42b972b9-77a7-f43d-1630-fe31a71ab508@norma.perm.ru>
 <91801fea-4baa-375b-7a91-91a0d1040e46@measurement-factory.com>
Message-ID: <31e7fe32-399b-ffb7-75a9-87a731cca154@norma.perm.ru>

Hi.

On 28.09.2016 0:29, Alex Rousskov wrote:
> Since you can reproduce this, I suggest collecting ALL,9 log for the
> stuck master transaction:
>
> http://wiki.squid-cache.org/SquidFaq/BugReporting#Debugging_a_single_transaction
>
> If collecting a debugging trace is impossible for some reason, then
> collect the corresponding TCP packets on the Squid to origin server link
> and post actual packets (not screenshots of packet summaries) from both
> connections. The debugging trace will most likely have the answer. The
> packet trace might have the answer.
>
> You may need to change user credentials for this test or after posting
> the details requested above.
>
Well... I cannot reproduce it on purpose, I'm just saying it is 
self-reproducible for almost a year, in certain moments of time. 
Collecting a debug trace isn't hard by itself, but I'm pretty sure the 
restart will clear this state for a current machine (I guess squid 
didn't get a way to increase debug level on the fly ? at least I'm not 
aware of it; so I will need to restart it to set ALL,9), and I'll have 
to run with ALL,9 for quite some time, which is, obviously, not good for 
production, because it will create enormous amounts of logging in cache 
log. So I will post the tcpdump containing both exchanges, and if it 
will be still unclear I'll think about running in a debug mode.

Thanks.
Eugene.


From rousskov at measurement-factory.com  Tue Sep 27 20:36:59 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 27 Sep 2016 14:36:59 -0600
Subject: [squid-users] connections from particular users sometimes get
 stuck
In-Reply-To: <31e7fe32-399b-ffb7-75a9-87a731cca154@norma.perm.ru>
References: <42b972b9-77a7-f43d-1630-fe31a71ab508@norma.perm.ru>
 <91801fea-4baa-375b-7a91-91a0d1040e46@measurement-factory.com>
 <31e7fe32-399b-ffb7-75a9-87a731cca154@norma.perm.ru>
Message-ID: <715805cc-4a0f-0430-a142-1ef03cf0d547@measurement-factory.com>

On 09/27/2016 02:02 PM, Eugene M. Zheganin wrote:

> I guess squid
> didn't get a way to increase debug level on the fly ? 

"squid -k debug" (or sending an equivalent signal) does that:
http://wiki.squid-cache.org/SquidFaq/BugReporting#Detailed_Debug_Output

You will not get ALL,9 this way, unfortunately, but ALL,7 might be enough.

Alex.



From emz at norma.perm.ru  Wed Sep 28 08:22:04 2016
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Wed, 28 Sep 2016 13:22:04 +0500
Subject: [squid-users] connections from particular users sometimes get
 stuck
In-Reply-To: <715805cc-4a0f-0430-a142-1ef03cf0d547@measurement-factory.com>
References: <42b972b9-77a7-f43d-1630-fe31a71ab508@norma.perm.ru>
 <91801fea-4baa-375b-7a91-91a0d1040e46@measurement-factory.com>
 <31e7fe32-399b-ffb7-75a9-87a731cca154@norma.perm.ru>
 <715805cc-4a0f-0430-a142-1ef03cf0d547@measurement-factory.com>
Message-ID: <57EB7DAC.9000408@norma.perm.ru>

Hi.

On 28.09.2016 01:36, Alex Rousskov wrote:
> On 09/27/2016 02:02 PM, Eugene M. Zheganin wrote:
>
>> I guess squid
>> didn't get a way to increase debug level on the fly ? 
> "squid -k debug" (or sending an equivalent signal) does that:
> http://wiki.squid-cache.org/SquidFaq/BugReporting#Detailed_Debug_Output
>
> You will not get ALL,9 this way, unfortunately, but ALL,7 might be enough.
>
>
I took the debug trace and both the tcpdump client-side and server-side
(towards the internet) capturea.
Since the debug log is way heavy, I decided to put all of the three
files on the web-server. Here they are:

Squid debug log (ALL,7):

http://zhegan.in/files/squid/cache.log.debug

tcpdump client-side capture (windump -s 0 -w
squid-stuck-reference-client.pcap -ni 1):

http://zhegan.in/files/squid/squid-stuck-reference-client.pcap

tcpdump server-side capture, towards the outer world, empty - obviously,
server didn't send anything outside (tcpdump -s 0 -w
squid-stuck-reference-server.pcap -ni vlan23 host 217.112.35.75):

http://zhegan.in/files/squid/squid-stuck-reference-server.pcap

Test sequence:

client - 192.168.3.215
squid - 192.168.3.1:3128
URL - http://www.ru/index.html

I requested a http://www.ru/index.html from a client machine Chrome. No
other applications were requesting this URL at this time there (however,
capture does contain a lot of traffic, including HTTP sessions). Then I
waited about a minute (loader in Chrome was spinning), and aborted both
captures, then aborted the request. The aborted request probably made it
to the squid log.

Eugene.



From amaury at tin.it  Wed Sep 28 09:44:19 2016
From: amaury at tin.it (amaury at tin.it)
Date: Wed, 28 Sep 2016 11:44:19 +0200 (CEST)
Subject: [squid-users] R: Re: R: Re: problem reload configuration with
 workers
Message-ID: <157702e371c.amaury@tin.it>

Hi Alex

I have used like reference the example backend.conf in 
/ConfigExamples/SmpCarpCluster

Every swap.state is updated so I 
suppose that it's working.

Mau
----Messaggio originale----
Da: 
rousskov at measurement-factory.com
Data: 27-set-2016 17.38
A: <squid-
users at lists.squid-cache.org>
Cc: "amaury at tin.it"<amaury at tin.it>
Ogg: 
Re: R: Re: [squid-users] problem reload configuration with workers

On 
09/27/2016 03:15 AM, amaury at tin.it wrote:
> I have resolve my problem 
changing the workers configuration from:
> 
> workers 4
> http_access 
allow localhost
> http_port localhost:
> 400${process_number}
> 
cache_dir aufs /var/spool/squid 16384 32 512
> 
> cache_dir rock 
/var/spool/squid/rock 16384 max-size=32768
> cache_dir aufs 
/var/spool/squid/squid-cache0${process_number} 16384 16 512 min-
size=32769

The above combination of SMP-aware and SMP-unaware caches 
is unsupported
and probably will not work.


> to
> 
> workers 4
> 
http_access allow localhost
> http_port 
> localhost:
400${process_number}
> cache_dir rock /var/spool/squid/rock 16384 max-
size=32768
> 
> if ${process_number} = 1
>         cache_dir aufs 
/var/spool/squid/squid-cache01 16384 16 512 min-size=32769
> endif
> 
if 
> ${process_number} = 2
>         cache_dir aufs 
/var/spool/squid/squid-cache02 16384 16 512 min-size=32769
> endif
> if 
${process_number} = 3 
>         cache_dir aufs /var/spool/squid/squid-
cache03 16384 16 512 min-size=32769
> endif
> if ${process_number} = 4

>         cache_dir aufs /var/spool/squid/squid-cache04 16384 16 512 
min-size=32769
> endif

The above is equivalent to

  workers 4
  
http_access allow localhost
  http_port
  localhost:
400${process_number}
  cache_dir rock /var/spool/squid/rock 16384 max-
size=32768
  cache_dir aufs /var/spool/squid/squid-
cache${process_number} 16384 ...

which is still an unsupported 
combination of SMP-aware and SMP-unaware
caches that probably will not 
work.

BTW, why do you give each worker a dedicated listening port (i.
e.,
"400${process_number}")?

Alex.


> ----Messaggio originale----
> 
Da: rousskov at measurement-factory.
> com
> Data: 26-set-2016 16.12
> A: 
<squid-users at lists.squid-cache.org>
> Cc: 
> "amaury at tin.it"<amaury at tin.
it>
> Ogg: Re: [squid-users] problem reload 
> configuration with 
workers
> 
> On 09/26/2016 08:02 AM, amaury at tin.it 
> wrote:
> 
>> I'm 
using squid 3.5.21-20160908-r14081 and for the first time 
> I'm 
>> 
using workers configuration. I have a problem:
>> when I reload 
> 
configuration (via init script)
>> suid -k reconfigure -f 
> 
/et/squid/squid.conf
> 
> I assume that by "suid" you meant "squid". 
If 
> yes, then the above
> command is a correct way to reconfigure 
Squid, 
> including SMP Squid.
> 
> 
>> the system kill squid-coord and 
squid-disk
> 
> 
> Does "the system" do more than run "squid -k 
reconfigure ..."?
> 
> * If 
> not, then "the system" does not kill 
squid-coord and squid-disk
> 
> (something else does).
> 
> * If yes, 
then you should fix your system 
> script. Perhaps it thinks that
> 
Squid died and tries to kill/restart it?
> 
> 
> 
>> So I have to 
remove pd 
>> file and lock files and restart squid.
>>
> Please, do it 
exist a solution 
>> to reload with restart squid?
> 
> 
> 
Reconfiguration should work "as is". If it does not work, file a bug
> 

> report with details such as your system command(s) and resulting
> 
cache.
> log and syslog output.
> 
> 
>> I tried also using something 
like:
>>
>>
> pid_filename /var/run/squid/squid-{proccess_number}.
> 
> 
Please do not do 
> that. SMP Squid is designed to work with a single
> 
configuration file 
> without SMP macros.
> 
> 
> Thank you,
> 
> Alex.

> 
> 
> 






From michael.varun at inmobi.com  Wed Sep 28 10:17:55 2016
From: michael.varun at inmobi.com (Michael Varun)
Date: Wed, 28 Sep 2016 15:47:55 +0530
Subject: [squid-users] Caching application/octet-stream
Message-ID: <CAHhBkD0dXw7PztgqGdrZ=6aTxVpuXExx+q+qVA+8rM3a+8Y8NA@mail.gmail.com>

Team -

Would like to know is there any specific config that we need to enable to
cache MIME attachement of application/octet-stream type

We are trying to caching docker image blobs which is of
application/octet-stream  and everytime we hit the docker registry via)GET
call squid throws up TCP_MISS/200  I had never got a CACHE HIT or MEM HIT
for these contents. Can someone show pointers to how to succeed in cache
hit


Logs
====
1475056789.667      0 10.0.0.160 TAG_NONE/200 0 CONNECT <docker
registry>:443 - HIER_NONE/- -
1475056789.706   1633 10.0.0.160 TCP_MISS/200 1114 GET https://docker
registry/v2/blobs/sha256:36e0da2b6e166c5e7b1f243e9257590d4fbd1be729773df7f3d6a779941b22d9
- FIRSTUP_PARENT/IP.xx.xx.xxapplication/octet-stream
1475056789.708      0 10.0.0.160 TAG_NONE/200 0 CONNECT <docker
registry>443 - HIER_NONE/- -
1475056791.259   1545 10.0.0.160 TCP_MISS/200 1698 GET https://docker
registry/v2/blobs/sha256:2a00f8fcea92b16de0de328c557da476e930aa038ccee482daf91a62de5afa33
- FIRSTUP_PARENT/IP.xx.xx.xx application/octet-stream


Configuration
=============
http_port docker registry:443 ssl-bump cert=/etc/ssl/private/docker
registry.certkey=/etc/ssl/private/docker registry.key
maximum_object_size 8 GB
maximum_object_size_in_memory 102400 KB
quick_abort_min -1
cache_dir ufs /data/squid/cache/squid 204800 16 256
cache_mem 51200 MB
cache allow all
cache_peer docker registry parent 443 0 no-query originserver no-digest
name=upstream ssl sslflags=DONT_VERIFY_PEER
never_direct allow all
#
acl site dstdomain /etc/mirror-dstdomain.acl
acl site1 dstdomain docker-registry.xx.xx
http_access allow site
http_access allow site1
cache_peer_access upstream allow site1
cache_peer_access upstream deny all
ssl_bump bump site1
ssl_bump splice all
sslproxy_flags DONT_VERIFY_PEER

-- 
_____________________________________________________________
The information contained in this communication is intended solely for the 
use of the individual or entity to whom it is addressed and others 
authorized to receive it. It may contain confidential or legally privileged 
information. If you are not the intended recipient you are hereby notified 
that any disclosure, copying, distribution or taking any action in reliance 
on the contents of this information is strictly prohibited and may be 
unlawful. If you have received this communication in error, please notify 
us immediately by responding to this email and then delete it from your 
system. The firm is neither liable for the proper and complete transmission 
of the information contained in this communication nor for any delay in its 
receipt.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160928/df9eb268/attachment.htm>

From eliezer at ngtech.co.il  Wed Sep 28 11:39:04 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 28 Sep 2016 14:39:04 +0300
Subject: [squid-users] =?utf-8?b?VGhlIFNxdWlkIOKAnFBlcnNvbmHigJ0tIFNxdWlk?=
	=?utf-8?q?_3=2E5=2E21+4=2E0=2E14_Release?=
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAP1vRcAAnWlNoU7f4f0YNhgBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABsZAtsSLJaRLAoEGsoGj3pAQAAAAA=@ngtech.co.il>

Take a look at the page source to get the full article: http://www1.ngtech.co.il/wpe/?p=345

Who Is The Squid Girl Persona?
[Squid Persona|http://www1.ngtech.co.il/wpe/wp-content/uploads/2016/09/squid_girl__shinryaku__ika_musume__minimalism_by_greenmapple17-d8u9mum-768x432.png]

As a Squidder I know a girl or two but others are in the lookup for their Squid Girl Persona. Its?s not a simple task!!
To illustrate the idea: We as males used to the web with all sort of GET, POST, OPTIONS, PROFIND and all sort of normal methods.
But the Squid Girls is something else. She has brains!
	
[Artist of the Persona|http://www.deviantart.com/tag/squid_girl?offset=3]


Eliezer Croitoru
----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-announce [mailto:squid-announce-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Sunday, September 11, 2016 5:36 PM
To: squid-announce at lists.squid-cache.org
Subject: [squid-announce] Squid 3.5.21 is available

The Squid HTTP Proxy team is very pleased to announce the availability of the Squid-3.5.21 release!


This release is a bug fix release resolving several issues found in the prior Squid releases.


The major changes to be aware of:


* Bug #4534: assertion failure in xcalloc when using many cache_dir

Squid is documented as supporting up to 64 cache directories, but would crash with a memory allocation error if more than a few were actually configured.


* Bug #4542: authentication credentials IP TTL updated incorrectly

This bug caused error in max_user_ip ACL accounting to allow clients to shift IP address more times than configured. This bug fix may have an effect on IPv6 clients using "proviacy adressing" to rotate IPs.


* Bug #4428: mal-formed Cache-Control:stale-if-error header

This bug shows up as incorrect stale-if-error values being relayed by Squid breaking the use of this feature in the recipients. Squid now relays the header values correctly.


* Bug #3025: Proxy-Authenticate problem using ICAP server

With this change Squid now treats the ICAP REQMOD adaptation point as a part of itself with regards to proxy authentication. The Proxy-Authentication header received from the client is delivered as part of the HTTP request headers in expectation that the ICAP service may authenticate and/or produce 407 response itself.

Note that use of stateful or connection-oriented authentication schemes is not possible. HTTP is designed to operate in a stateless way and any deviation from that design requires Squid to perform special message processing.


* HTTP: MUST always revalidate Cache-Control:no-cache responses.

This bug shows up as Squid not revalidating some responses until they became stale according to refresh_pattern heuristic rules (specifically the minimum caching age). Squid now revalidates these objects on every request.


* HTTP: do not allow Proxy-Connection to override Connection header

The Proxy-Connection: header is a long-deprecated experimental header.
For the past decade Squid has been actively stripping it out of relayed traffic. This release continues the removal process by also preventing it from having any effect on Squid client connection persistence when a
Connection: header is present.


* SSL CN wildcard must only match a single domain component [fragment].

This bug shows up as incorrect matching (or non-matching) of the ss::server_name ACL against TLS certificate values. Squid now treats the certificate CN fields according to X.509 domain matching requirements instead of HTTP domain matching requirements.



 All users of Squid-3 are encouraged to upgrade to this release as soon as possible.


 See the ChangeLog for the full list of changes in this and earlier  releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v3/3.5/RELEASENOTES.html
when you are ready to make the switch to Squid-3.5

Upgrade tip:
  "squid -k parse" is starting to display even more
   useful hints about squid.conf changes.

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v3/3.5/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/3.5/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries

_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce



From Antony.Stone at squid.open.source.it  Wed Sep 28 11:43:08 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 28 Sep 2016 13:43:08 +0200
Subject: [squid-users]
 =?utf-8?b?VGhlIFNxdWlkIOKAnFBlcnNvbmHigJ0tIFNxdWlk?=
 =?utf-8?q?_3=2E5=2E21+4=2E0=2E14_Release?=
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAP1vRcAAnWlNoU7f4f0YNhgBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABsZAtsSLJaRLAoEGsoGj3pAQAAAAA=@ngtech.co.il>
References: <!&!AAAAAAAAAAAuAAAAAAAAAP1vRcAAnWlNoU7f4f0YNhgBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABsZAtsSLJaRLAoEGsoGj3pAQAAAAA=@ngtech.co.il>
Message-ID: <201609281343.08693.Antony.Stone@squid.open.source.it>

On Wednesday 28 September 2016 at 13:39:04, Eliezer Croitoru wrote:

> Take a look at the page source to get the full article:
> http://www1.ngtech.co.il/wpe/?p=345

If this is to be used as publicity material or a news item associated with the 
Squid project, I humbly recommend that a native English speaker is engaged to 
proofread and edit it.

Regards,

Antony.

-- 
3 logicians walk into a bar. The bartender asks "Do you all want a drink?"
The first logician says "I don't know."
The second logician says "I don't know."
The third logician says "Yes!"

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Wed Sep 28 12:50:11 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 28 Sep 2016 18:50:11 +0600
Subject: [squid-users]
 =?utf-8?b?VGhlIFNxdWlkIOKAnFBlcnNvbmHigJ0tIFNxdWlk?=
 =?utf-8?q?_3=2E5=2E21+4=2E0=2E14_Release?=
In-Reply-To: <201609281343.08693.Antony.Stone@squid.open.source.it>
References: <!&!AAAAAAAAAAAuAAAAAAAAAP1vRcAAnWlNoU7f4f0YNhgBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABsZAtsSLJaRLAoEGsoGj3pAQAAAAA=@ngtech.co.il>
 <201609281343.08693.Antony.Stone@squid.open.source.it>
Message-ID: <bafc8a59-10de-03eb-8a9a-94e1b19667e7@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
It seems to me more important than the quality of the product debugging
instead invention mascot for it.


28.09.2016 17:43, Antony Stone ?????:
> On Wednesday 28 September 2016 at 13:39:04, Eliezer Croitoru wrote:
>
>> Take a look at the page source to get the full article:
>> http://www1.ngtech.co.il/wpe/?p=345
>
> If this is to be used as publicity material or a news item associated
with the
> Squid project, I humbly recommend that a native English speaker is
engaged to
> proofread and edit it.
>
> Regards,
>
> Antony.
>

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX67yCAAoJENNXIZxhPexGbD4H/Apve4VU3ksfk8hYymmmi9bq
VVmVNjYIgWb5Q76H4nlU5hmDTAd2bUX7UgbtsCIpib/hlbk/0UQ8zglnt23z+pyT
WEdT7hIMRJMxz43biMzhAxMZdS/CsL+ipeqn+4jMPrPUL2LuYb3KScwE6+LsrMf5
jGML1rbrqBOZIkYJQLEbYQ0gSprmG9iiFJ41STc1a+cmPxk6RKViKB1gGchX7FKF
+PIKvqpVqy8V19lYvY5dR37gETpmXm/hID/CbrLRwu6DHovL20DoJyyA8c39vgjt
eqeKXgb1P0ahwy04P6VUPeZv+YWXT3GR5zPTgYHnnRnIeierOJHWnIP/4RRPKI8=
=xAA4
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160928/21c1ee9c/attachment.key>

From bruno.larini at riosoft.com.br  Wed Sep 28 13:26:58 2016
From: bruno.larini at riosoft.com.br (Bruno de Paula Larini)
Date: Wed, 28 Sep 2016 10:26:58 -0300
Subject: [squid-users]
 =?utf-8?b?VGhlIFNxdWlkIOKAnFBlcnNvbmHigJ0tIFNxdWlk?=
 =?utf-8?q?_3=2E5=2E21+4=2E0=2E14_Release?=
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAP1vRcAAnWlNoU7f4f0YNhgBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABsZAtsSLJaRLAoEGsoGj3pAQAAAAA=@ngtech.co.il>
References: <!&!AAAAAAAAAAAuAAAAAAAAAP1vRcAAnWlNoU7f4f0YNhgBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABsZAtsSLJaRLAoEGsoGj3pAQAAAAA=@ngtech.co.il>
Message-ID: <cfd3f260-64c3-a618-e3c7-05d0be4c7899@riosoft.com.br>

Em 28/09/2016 08:39, Eliezer Croitoru escreveu:
> Take a look at the page source to get the full article: http://www1.ngtech.co.il/wpe/?p=345
>
> Who Is The Squid Girl Persona?
> [Squid Persona|http://www1.ngtech.co.il/wpe/wp-content/uploads/2016/09/squid_girl__shinryaku__ika_musume__minimalism_by_greenmapple17-d8u9mum-768x432.png]
>
> As a Squidder I know a girl or two but others are in the lookup for their Squid Girl Persona. Its?s not a simple task!!
> To illustrate the idea: We as males used to the web with all sort of GET, POST, OPTIONS, PROFIND and all sort of normal methods.
> But the Squid Girls is something else. She has brains!
> 	
> [Artist of the Persona|http://www.deviantart.com/tag/squid_girl?offset=3]
>
Is she a kid or a squid?


From erdosain9 at gmail.com  Wed Sep 28 14:02:42 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 28 Sep 2016 07:02:42 -0700 (PDT)
Subject: [squid-users] Kerberos Ne
Message-ID: <1475071362112-4679740.post@n4.nabble.com>

Hi.
Sorry for my ignorance, but, i have squid authentication with kerberos...

all is working fine...

but i have some behavior in cache.log that... i dont know if this is the
expected, or there is some problem....

because the file is going to be huge as put the squid in production ... this
is appropriate behavior, or is warning of a problem?

this is just a little of "cache.log" and with just one user... so i think is
a lot of info... this is ok?? 

2016/09/28 10:58:08 kid1| helperOpenServers: Starting 1/10
'negotiate_kerberos_auth' processes
negotiate_kerberos_auth.cc(487): pid=9723 :2016/09/28 10:58:08|
negotiate_kerberos_auth: INFO: Starting version 3.0.4sq
negotiate_kerberos_auth.cc(546): pid=9723 :2016/09/28 10:58:08|
negotiate_kerberos_auth: INFO: Setting keytab to /etc/squid/PROXY.keytab
negotiate_kerberos_auth.cc(570): pid=9723 :2016/09/28 10:58:08|
negotiate_kerberos_auth: INFO: Changed keytab to
MEMORY:negotiate_kerberos_auth_9723
negotiate_kerberos_auth.cc(610): pid=9723 :2016/09/28 10:58:08|
negotiate_kerberos_auth: DEBUG: Got 'YR
YIIGcQYGKwYBBQUCoIIGZTCCBmGgMDAuBgkqhkiC9xIBA
gIGCSqGSIb3EgECAgYKKwYBBAGCNwICHgYKKwYBBAGCNwICCqKCBisEggYnYIIGIwYJKoZIhvcSAQICAQBuggYSMIIGDqADAgEFoQMCAQ6iBwMFACAAAACjggSaYYIEljCCBJKgAwIBBaEUGxJFU1
BBQ0lPTUVNT1JJQS5MQU6iKzApoAMCAQKhIjAgGwRIVFRQGxhzcXVpZC5lc3BhY2lvbWVtb3JpYS5sYW6jggRGMIIEQqADAgESoQMCAQGiggQ0BIIEMKZf4kp8jYe6rqDiqZVclO1QD0fVSDYKdMt
teiw3I/nw0dvJwaQzgLbbs1hnhVfbKD77eKbQfJNBFcwcRr6bQRE/AySa+qOGZj3flRwxJgzcf6/wAMgfUNqU0qubkpH8BYhzd7q1KFI2t0vxAIZyj+O8Ot0HdKb3QH2ZC8EW5yCvGeYmLzkNBR4c
JLm6vLOAdwdqyHnBLuwjQyXrLEcEOS9CmBCF9AJMAr3Kmegicax2fzhzz2MgYE80O+aJ983ffVU2wFW1W1r766cEDYtxNT7CWVf1zRnAeOLpj7dSp3a5o3gMke0Y526zidlgkrEX2XCnMot2PnD9t
NNbcUwS1Hgp+Dkq7mJ6hsPTB0rDh/GGhS/yTTB0s/aT6++dq3CXl3glCy3bfax9UMnrHYSOrI8SVuPrva4SLgbTAcHPrmfWPbowf/ZOqGJ+94mOMdKzkhJIJcPz5KE5PiaOX/6N+hTGWc1mTzIzP3
V7/Wy8jWIPY+vBbE2hgykpgPCYEkVSz6KbuSiOx0TUEYG0d4hIvlwpx1VhSJoHU3/yStiodVpuSYiDr9UTrPe36c/hAd0G4IyTq/HC6JIicIf5joMsp6TKwp7q5+MQWLBNuQnXDl6bBrAw2sqvT96
mGkf4ZfowzWVgV8GeObZopIbMRYtG1C/NmgzK1ro9JiPDwsCS+bMs4rpNfiw7i+0LBGI5DTkWZwAhaZTZsbCXGSyeYnUkbKtuSLlczHCiAOyN4hQgXtXbL26rN4AqmF7rLlCgMlQPvxrVAjQ1cOqq
t9ZBxej/JzSrq5Xhifu0KqurZ5oZ8baNZJ/nBv2N5ntXpUli/9S5Qs4T5hR0khUdt2Vb9Hzx/pLRbF6Wo4iTCw1I7qH+QYVqDH2ZzlWC18ZVN1mPXLIsdii6edbNl/PY5o8htGfZnOOf8nlij3ZFl
CquzYKQNusQgN7RK/DcqJlxfE9CIoZyOPic5rC7nJ3Q55Bzx2+UTdS6JvNRVy+QmFMyUYpbDVF7VIZan6J2hf+2ND8+D5X3VhVhLYqQFPfmgJGeWUkcb/FGJoNPWTl5t3JSh6ASS2JzHwfChTwOwy
NXs2ej8s2IVYh8H6TLKdDiWmuhJZAyE5r8wnAgpIwgq+Jt1Cpj1wAToCJrXc6XZ77yA9NlD5iyz4Us2JsUBmXO1RpSXWBCev3il/TiL/+Ifu3ShrIeusUNDEMzsFjlhRuXuSKhzH9dolnKl8fSwKu
P4HyObuySUKP+4tCdOMZ/4VN1Rp8UCnrmbDcAvhPxpkoDx34KuXD4OYNtjwoJnyPMb1LUe0Z5K4ll0Ray66Ake/YjFuaWY/P7cTpwEe7TmfUNGghmB3iHxY1EQT9ySgBS0A+X5PBY/IkAgwG3teXUGIOx08g60Yme1Kq7nJcu1IQqUtCCNYN9s7Etcgbw9ecYbtz79rzT32KkggFZMIIBVaADAgESooIBTASCAUirSsLoI1x0RGwC84lXB4HADhLTlMA2gy7nx3J8DJmAoRLj9akJVJvoPhRqmxJdIs7vNZ1XbhZBcJ/84cz8yqiXOFMq9C3vvIAw57diqp6uDUd2yyQAMoB2WyAu/VIIvXkJ2v5iUu77VxTUNtV/VGmYM+SonXMWEFXi81VRPoVTIXySAFXRO7NF8rugf7TiAtB5SYHtC8EG0+jBV3ZBPeIAaDEWHWnHdDi4kQnWA5biuRf5FEP0elnxzEwh6Fzp/cTdrAMBLucbtjr1kInT5dwN0UePEGxtTzo7ajVCK/8uaHz1X2vPSKSSp/z5W3leoEtq3JMYQCn6RaERrQ1cjZ0+zVtWaWDu6KgIOcCo1jcY+SZ4ZFwox2BqdGkJJxi3AfW+1/MJBV9eA1YDV0cwZu77F+ymkB32z8d+jGvBFewGkDaKQX8GrQL6'
from squid (length: 2207).
negotiate_kerberos_auth.cc(663): pid=9723 :2016/09/28 10:58:08|
negotiate_kerberos_auth: DEBUG: Decode
'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'
(decoded length: 1653).
negotiate_kerberos_pac.cc(376): pid=9723 :2016/09/28 10:58:08|
negotiate_kerberos_auth: INFO: Got PAC data of lengh 480
negotiate_kerberos_pac.cc(180): pid=9723 :2016/09/28 10:58:08|
negotiate_kerberos_auth: INFO: Found 4 rids
negotiate_kerberos_pac.cc(188): pid=9723 :2016/09/28 10:58:08|
negotiate_kerberos_auth: Info: Got rid: 512
negotiate_kerberos_pac.cc(188): pid=9723 :2016/09/28 10:58:08|
negotiate_kerberos_auth: Info: Got rid: 572
negotiate_kerberos_pac.cc(188): pid=9723 :2016/09/28 10:58:08|
negotiate_kerberos_auth: Info: Got rid: 1104
negotiate_kerberos_pac.cc(188): pid=9723 :2016/09/28 10:58:08|
negotiate_kerberos_auth: Info: Got rid: 1603
negotiate_kerberos_pac.cc(256): pid=9723 :2016/09/28 10:58:08|
negotiate_kerberos_auth: INFO: Got DomainLogonId
S-1-5-21-1629365404-3444910380-4267131508
negotiate_kerberos_pac.cc(456): pid=9723 :2016/09/28 10:58:08|
negotiate_kerberos_auth: INFO: Read 480 of 480 bytes 
negotiate_kerberos_auth.cc(778): pid=9723 :2016/09/28 10:58:08|
negotiate_kerberos_auth: DEBUG: Groups
group=AQUAAAAAAAUVAAAAnCQeYSwpVc10Qlf+AAIAAA==
group=AQUAAAAAAAUVAAAAnCQeYSwpVc10Qlf+PAIAAA==
group=AQUAAAAAAAUVAAAAnCQeYSwpVc10Qlf+UAQAAA==
group=AQUAAAAAAAUVAAAAnCQeYSwpVc10Qlf+QwYAAA==
negotiate_kerberos_auth.cc(783): pid=9723 :2016/09/28 10:58:08|
negotiate_kerberos_auth: DEBUG: AF
oYG2MIGzoAMKAQChCwYJKoZIgvcSAQICooGeBIGbYIGYBgkqhkiG9xIBAgICAG+BiDCBhaADAgEFoQMCAQ+ieTB3oAMCARKicARuMyqk3lTexjmqjNAFgDgnpyzNpWxfB1vWjtWiVW0rfQ0fsjMGthWoG494SxlMZn4GGzA9f6LP8queDpTEMUkZ1toZSb91MvSZwqFARbfpm8qjsaEoz1NhyP7ACjIoaA+1QnfBrurMNI+8KfIIC/k=
user at example.LAN
negotiate_kerberos_auth.cc(610): pid=9723 :2016/09/28 10:58:09|
negotiate_kerberos_auth: DEBUG: Got 'YR
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'
from squid (length: 2207).
negotiate_kerberos_auth.cc(663): pid=9723 :2016/09/28 10:58:09|
negotiate_kerberos_auth: DEBUG: Decode
'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'
(decoded length: 1653).
negotiate_kerberos_pac.cc(376): pid=9723 :2016/09/28 10:58:09|
negotiate_kerberos_auth: INFO: Got PAC data of lengh 480
negotiate_kerberos_pac.cc(180): pid=9723 :2016/09/28 10:58:09|
negotiate_kerberos_auth: INFO: Found 4 rids
negotiate_kerberos_pac.cc(188): pid=9723 :2016/09/28 10:58:09|
negotiate_kerberos_auth: Info: Got rid: 512
negotiate_kerberos_pac.cc(188): pid=9723 :2016/09/28 10:58:09|
negotiate_kerberos_auth: Info: Got rid: 572
negotiate_kerberos_pac.cc(188): pid=9723 :2016/09/28 10:58:09|
negotiate_kerberos_auth: Info: Got rid: 1104
negotiate_kerberos_pac.cc(188): pid=9723 :2016/09/28 10:58:09|
negotiate_kerberos_auth: Info: Got rid: 1603
negotiate_kerberos_pac.cc(256): pid=9723 :2016/09/28 10:58:09|
negotiate_kerberos_auth: INFO: Got DomainLogonId
S-1-5-21-1629365404-3444910380-4267131508
negotiate_kerberos_pac.cc(456): pid=9723 :2016/09/28 10:58:09|
negotiate_kerberos_auth: INFO: Read 480 of 480 bytes 
negotiate_kerberos_auth.cc(778): pid=9723 :2016/09/28 10:58:09|
negotiate_kerberos_auth: DEBUG: Groups
group=AQUAAAAAAAUVAAAAnCQeYSwpVc10Qlf+AAIAAA==
group=AQUAAAAAAAUVAAAAnCQeYSwpVc10Qlf+PAIAAA==
group=AQUAAAAAAAUVAAAAnCQeYSwpVc10Qlf+UAQAAA==
group=AQUAAAAAAAUVAAAAnCQeYSwpVc10Qlf+QwYAAA==
negotiate_kerberos_auth.cc(783): pid=9723 :2016/09/28 10:58:09|
negotiate_kerberos_auth: DEBUG: AF
oYG2MIGzoAMKAQChCwYJKoZIgvcSAQICooGeBIGbYIGYBgkqhkiG9xIBAgICAG+BiDCBhaADAgEFoQMCAQ+ieTB3oAMCARKicARuK20b/yPUlQMARj9bjHVQvmhxEvw9booaB682C2v9bnJT3FH3JIow+9fSFUQR0SvlUmlaI3IIq17n+Up5WtC9wEA9/olV8til/8QylmG+44rrxsSrYuRXJWcIAAadBLxBYP7tBkszh7wKG2uHxss=
user at example.LAN
negotiate_kerberos_auth.cc(610): pid=9723 :2016/09/28 10:58:14|
negotiate_kerberos_auth: DEBUG: Got 'YR
YIIGcQYGKwYBBQUCoIIGZTCCBmGgMDAuBgkqhkiC9xIBA
gIGCSqGSIb3EgECAgYKKwYBBAGCNwICHgYKKwYBBAGCNwICCqKCBisEggYnYIIGIwYJKoZIhvcSAQICAQBuggYSMIIGDqADAgEFoQMCAQ6iBwMFACAAAACjggSaYYIEljCCBJKgAwIBBaEUGxJFU1
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'
from squid (length: 2207).
negotiate_kerberos_auth.cc(663): pid=9723 :2016/09/28 10:58:14|
negotiate_kerberos_auth: DEBUG: Decode
'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'
(decoded length: 1653).
2016/09/28 10:58:14 kid1| Starting new negotiateauthenticator helpers...
2016/09/28 10:58:14 kid1| helperOpenServers: Starting 1/10
'negotiate_kerberos_auth' processes





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Kerberos-Ne-tp4679740.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Wed Sep 28 14:10:56 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 28 Sep 2016 16:10:56 +0200
Subject: [squid-users] Kerberos Ne
In-Reply-To: <1475071362112-4679740.post@n4.nabble.com>
References: <1475071362112-4679740.post@n4.nabble.com>
Message-ID: <201609281610.56374.Antony.Stone@squid.open.source.it>

On Wednesday 28 September 2016 at 16:02:42, erdosain9 wrote:

> Hi.
> Sorry for my ignorance, but, i have squid authentication with kerberos...
> 
> all is working fine...
> 
> but i have some behavior in cache.log that... i dont know if this is the
> expected, or there is some problem....
> 
> because the file is going to be huge as put the squid in production ...
> this is appropriate behavior, or is warning of a problem?

Please post here your current squid.conf without comments or blank lines.

Antony.

-- 
All matter in the Universe can be placed into one of two categories:

1. Things which need to be fixed.
2. Things which need to be fixed once you've had a few minutes to play with 
them.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Wed Sep 28 14:24:21 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 29 Sep 2016 03:24:21 +1300
Subject: [squid-users] Caching application/octet-stream
In-Reply-To: <CAHhBkD0dXw7PztgqGdrZ=6aTxVpuXExx+q+qVA+8rM3a+8Y8NA@mail.gmail.com>
References: <CAHhBkD0dXw7PztgqGdrZ=6aTxVpuXExx+q+qVA+8rM3a+8Y8NA@mail.gmail.com>
Message-ID: <a1df4bde-6c40-ff3c-e41e-e5e8aee0a86e@treenet.co.nz>

On 28/09/2016 11:17 p.m., Michael Varun wrote:
> Team -
> 
> Would like to know is there any specific config that we need to enable to
> cache MIME attachement of application/octet-stream type
> 
> We are trying to caching docker image blobs which is of
> application/octet-stream  and everytime we hit the docker registry via)GET
> call squid throws up TCP_MISS/200  I had never got a CACHE HIT or MEM HIT
> for these contents. Can someone show pointers to how to succeed in cache
> hit

The object mime type does not matter for caching. What does matter are
the URL and identifier headers, plus headers about the objects age,
Vary, Expires and Cache-Control.

You can configure "debug_options 11,2" to get a cache.log trace of the
messages going through the proxy. Taking a closer look at those message
headers to find out why caching is not happening.

You could also use the tool at redbot.org. It takes a public URL and
displays the cacheability situation for it.

Amos



From rousskov at measurement-factory.com  Wed Sep 28 14:26:10 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 28 Sep 2016 08:26:10 -0600
Subject: [squid-users] R: Re: R: Re: problem reload configuration with
 workers
In-Reply-To: <157702e371c.amaury@tin.it>
References: <157702e371c.amaury@tin.it>
Message-ID: <0a0d62ac-0fb3-6a65-77ed-56bf4757135b@measurement-factory.com>

On 09/28/2016 03:44 AM, amaury at tin.it wrote:

> I have used like reference the example backend.conf in 
> /ConfigExamples/SmpCarpCluster

That example configuration contains a combination of SMP-aware and
SMP-unaware caches. In SMP mode, that combination is unsupported and
probably will not work correctly.


> Every swap.state is updated so I suppose that it's working.

Good luck,

Alex.


> ----Messaggio originale----
> Da: 
> rousskov at measurement-factory.com
> Data: 27-set-2016 17.38
> A: <squid-
> users at lists.squid-cache.org>
> Cc: "amaury at tin.it"<amaury at tin.it>
> Ogg: 
> Re: R: Re: [squid-users] problem reload configuration with workers
> 
> On 
> 09/27/2016 03:15 AM, amaury at tin.it wrote:
>> I have resolve my problem 
> changing the workers configuration from:
>>
>> workers 4
>> http_access 
> allow localhost
>> http_port localhost:
>> 400${process_number}
>>
> cache_dir aufs /var/spool/squid 16384 32 512
>>
>> cache_dir rock 
> /var/spool/squid/rock 16384 max-size=32768
>> cache_dir aufs 
> /var/spool/squid/squid-cache0${process_number} 16384 16 512 min-
> size=32769
> 
> The above combination of SMP-aware and SMP-unaware caches 
> is unsupported
> and probably will not work.
> 
> 
>> to
>>
>> workers 4
>>
> http_access allow localhost
>> http_port 
>> localhost:
> 400${process_number}
>> cache_dir rock /var/spool/squid/rock 16384 max-
> size=32768
>>
>> if ${process_number} = 1
>>         cache_dir aufs 
> /var/spool/squid/squid-cache01 16384 16 512 min-size=32769
>> endif
>>
> if 
>> ${process_number} = 2
>>         cache_dir aufs 
> /var/spool/squid/squid-cache02 16384 16 512 min-size=32769
>> endif
>> if 
> ${process_number} = 3 
>>         cache_dir aufs /var/spool/squid/squid-
> cache03 16384 16 512 min-size=32769
>> endif
>> if ${process_number} = 4
> 
>>         cache_dir aufs /var/spool/squid/squid-cache04 16384 16 512 
> min-size=32769
>> endif
> 
> The above is equivalent to
> 
>   workers 4
>   
> http_access allow localhost
>   http_port
>   localhost:
> 400${process_number}
>   cache_dir rock /var/spool/squid/rock 16384 max-
> size=32768
>   cache_dir aufs /var/spool/squid/squid-
> cache${process_number} 16384 ...
> 
> which is still an unsupported 
> combination of SMP-aware and SMP-unaware
> caches that probably will not 
> work.
> 
> BTW, why do you give each worker a dedicated listening port (i.
> e.,
> "400${process_number}")?
> 
> Alex.
> 
> 
>> ----Messaggio originale----
>>
> Da: rousskov at measurement-factory.
>> com
>> Data: 26-set-2016 16.12
>> A: 
> <squid-users at lists.squid-cache.org>
>> Cc: 
>> "amaury at tin.it"<amaury at tin.
> it>
>> Ogg: Re: [squid-users] problem reload 
>> configuration with 
> workers
>>
>> On 09/26/2016 08:02 AM, amaury at tin.it 
>> wrote:
>>
>>> I'm 
> using squid 3.5.21-20160908-r14081 and for the first time 
>> I'm 
>>>
> using workers configuration. I have a problem:
>>> when I reload 
>>
> configuration (via init script)
>>> suid -k reconfigure -f 
>>
> /et/squid/squid.conf
>>
>> I assume that by "suid" you meant "squid". 
> If 
>> yes, then the above
>> command is a correct way to reconfigure 
> Squid, 
>> including SMP Squid.
>>
>>
>>> the system kill squid-coord and 
> squid-disk
>>
>>
>> Does "the system" do more than run "squid -k 
> reconfigure ..."?
>>
>> * If 
>> not, then "the system" does not kill 
> squid-coord and squid-disk
>>
>> (something else does).
>>
>> * If yes, 
> then you should fix your system 
>> script. Perhaps it thinks that
>>
> Squid died and tries to kill/restart it?
>>
>>
>>
>>> So I have to 
> remove pd 
>>> file and lock files and restart squid.
>>>
>> Please, do it 
> exist a solution 
>>> to reload with restart squid?
>>
>>
>>
> Reconfiguration should work "as is". If it does not work, file a bug
>>
> 
>> report with details such as your system command(s) and resulting
>>
> cache.
>> log and syslog output.
>>
>>
>>> I tried also using something 
> like:
>>>
>>>
>> pid_filename /var/run/squid/squid-{proccess_number}.
>>
>>
> Please do not do 
>> that. SMP Squid is designed to work with a single
>>
> configuration file 
>> without SMP macros.
>>
>>
>> Thank you,
>>
>> Alex.
> 
>>
>>
>>
> 
> 
> 



From squid3 at treenet.co.nz  Wed Sep 28 14:43:08 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 29 Sep 2016 03:43:08 +1300
Subject: [squid-users] Kerberos Ne
In-Reply-To: <1475071362112-4679740.post@n4.nabble.com>
References: <1475071362112-4679740.post@n4.nabble.com>
Message-ID: <b037432c-b371-d721-8f21-eb9c78d8685b@treenet.co.nz>

On 29/09/2016 3:02 a.m., erdosain9 wrote:
> Hi.
> Sorry for my ignorance, but, i have squid authentication with kerberos...
> 
> all is working fine...
> 
> but i have some behavior in cache.log that... i dont know if this is the
> expected, or there is some problem....
> 
> because the file is going to be huge as put the squid in production ... this
> is appropriate behavior, or is warning of a problem?
> 
> this is just a little of "cache.log" and with just one user... so i think is
> a lot of info... this is ok?? 
> 

It's not clear what you are asking about exactly.

The amount of info the helper is dumping into cache.log is because you
have the helpers debug (-d) enabled in its auth_param program line. Once
you have the auth working you should turn that off of course (remove the
-d option).

Amos



From rousskov at measurement-factory.com  Wed Sep 28 15:37:58 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 28 Sep 2016 09:37:58 -0600
Subject: [squid-users] connections from particular users sometimes get
 stuck
In-Reply-To: <57EB7DAC.9000408@norma.perm.ru>
References: <42b972b9-77a7-f43d-1630-fe31a71ab508@norma.perm.ru>
 <91801fea-4baa-375b-7a91-91a0d1040e46@measurement-factory.com>
 <31e7fe32-399b-ffb7-75a9-87a731cca154@norma.perm.ru>
 <715805cc-4a0f-0430-a142-1ef03cf0d547@measurement-factory.com>
 <57EB7DAC.9000408@norma.perm.ru>
Message-ID: <f81aae25-958a-b8f4-2b28-5a0daecc1f71@measurement-factory.com>

On 09/28/2016 02:22 AM, Eugene M. Zheganin wrote:
> I took the debug trace and both the tcpdump client-side and server-side
> (towards the internet) capturea.
...
> I requested a http://www.ru/index.html from a client machine Chrome. 


AFAICT, Squid did not receive a request for www.ru:

> $ egrep -c 'wwww.ru|217.112.35.75' cache.log.debug 
> 0

> $ tshark -V -r squid-stuck-reference-client.pcap | egrep -c 'wwww.ru|217.112.35.75'
> 0


If you find that request in your client-to-Squid packet captures, please
point me to it. Otherwise, please fix your captures and redo the test
from scratch.

Also, please include access.log and/or some other indication of which
transactions got stuck. You may want to stop captures _after_ you cancel
the stuck request -- it is more difficult to find "what has not
happened" (no answer for X seconds) than "what has happened" (e.g., a
TCP connection was reset). Keep in mind that, in general, the request
for the URL you type in the browser may succeed, but the browser may get
stuck getting some resource on that page.

You may limit captures to TCP and DNS traffic to and from Squid.

Finally, for the future, [if you cannot isolate the problem to one HTTP
transaction(*),] it is best to capture everything that Squid receives or
sends rather than trying to guess what the browser and Squid will
receive or send -- according to cache.log, there were lots of
Squid-server packets that your tcpdump configuration did not capture.


Thank you,

Alex.
P.S. (*) Entering a regular page URL in the browser usually results in
more than one HTTP transaction between the browser and Squid.



From Antony.Stone at squid.open.source.it  Wed Sep 28 15:41:54 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 28 Sep 2016 17:41:54 +0200
Subject: [squid-users] connections from particular users sometimes get
	stuck
In-Reply-To: <f81aae25-958a-b8f4-2b28-5a0daecc1f71@measurement-factory.com>
References: <42b972b9-77a7-f43d-1630-fe31a71ab508@norma.perm.ru>
 <57EB7DAC.9000408@norma.perm.ru>
 <f81aae25-958a-b8f4-2b28-5a0daecc1f71@measurement-factory.com>
Message-ID: <201609281741.54358.Antony.Stone@squid.open.source.it>

On Wednesday 28 September 2016 at 17:37:58, Alex Rousskov wrote:

> AFAICT, Squid did not receive a request for www.ru:
> > $ egrep -c 'wwww.ru|217.112.35.75' cache.log.debug
> > 0
> > 
> > $ tshark -V -r squid-stuck-reference-client.pcap | egrep -c
> > 'wwww.ru|217.112.35.75' 0

Is that a direct copy'n'paste from your terminal?

If so, you tried one too many w's :(


Antony.

-- 
"There has always been an underlying argument that we should open up our 
source code more broadly. The fact is that we are learning from open source 
and we are opening our code more broadly through Shared Source.

Is there value to providing source code? The answer is unequivocally yes."

 - Jason Matusow, head of Microsoft's Shared Source Program, in response to 
leaks of Windows source code on the Internet.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From rousskov at measurement-factory.com  Wed Sep 28 16:21:46 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 28 Sep 2016 10:21:46 -0600
Subject: [squid-users] connections from particular users sometimes get
 stuck
In-Reply-To: <201609281741.54358.Antony.Stone@squid.open.source.it>
References: <42b972b9-77a7-f43d-1630-fe31a71ab508@norma.perm.ru>
 <57EB7DAC.9000408@norma.perm.ru>
 <f81aae25-958a-b8f4-2b28-5a0daecc1f71@measurement-factory.com>
 <201609281741.54358.Antony.Stone@squid.open.source.it>
Message-ID: <7280391c-a10c-8eb9-c41a-4f924600dda8@measurement-factory.com>

On 09/28/2016 09:41 AM, Antony Stone wrote:
> On Wednesday 28 September 2016 at 17:37:58, Alex Rousskov wrote:
> 
>> AFAICT, Squid did not receive a request for www.ru:
>>> $ egrep -c 'wwww.ru|217.112.35.75' cache.log.debug
>>> 0
>>>
>>> $ tshark -V -r squid-stuck-reference-client.pcap | egrep -c
>>> 'wwww.ru|217.112.35.75' 0
> 
> Is that a direct copy'n'paste from your terminal?
> 
> If so, you tried one too many w's :(

Indeed! Fixing that exposes one HTTP request in the capture file.
Unfortunately,

1. Squid responded to that request (with a 407 message).
   Follow (tcp.stream eq 32) in Wireshark.

2. Squid did not receive this request when debugging was on:
   $ egrep -c 'www.ru|217.112.35.75' cache.log.debug
   0

It may be important to know that the captured request was received at
minute 53 while Squid debugging starts at minute 58 (I assume the
difference in hours is due to time zone effects and such).

Another potentially important fact that it took almost two minutes for
the 407 response to show up in the capture. It is not clear (to me)
whether the delay was due to network problems (in one or both
directions) or due to Squid. Again, follow (tcp.stream eq 32) in
Wireshark to see the details.


The "I do not know which transaction got stuck and whether that
transaction go cache-logged" conclusion and suggestions in my original
response still apply AFAICT.


Thank you,

Alex.



From erdosain9 at gmail.com  Wed Sep 28 16:43:51 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 28 Sep 2016 09:43:51 -0700 (PDT)
Subject: [squid-users] Errors in cache.log
In-Reply-To: <e0b2c96c-03cc-717a-0c26-2d6d6e854153@treenet.co.nz>
References: <1474567862731-4679651.post@n4.nabble.com>
 <5756dcf2-f88b-1f15-9b43-dff112f17894@treenet.co.nz>
 <1474638603998-4679664.post@n4.nabble.com>
 <ec63ead9-72cc-71da-9e00-e607d02c5559@treenet.co.nz>
 <1474771838380-4679679.post@n4.nabble.com>
 <7d0acc3e-502d-000c-f227-4e5902e47ff1@treenet.co.nz>
 <1474828600378-4679683.post@n4.nabble.com>
 <e0b2c96c-03cc-717a-0c26-2d6d6e854153@treenet.co.nz>
Message-ID: <1475081031054-4679741.post@n4.nabble.com>

Hi.
Another question  in reference to this topic off delay pools.........
if i have "internet-limitation" (a group with 100kb for all webs) and i want
that users of that group have different youtube bandwith... is this
posible??

I need to do another group with the user of that group that i want they have
different bandwith for youtube? if i do that i will split
"internet-limitation" in "youtubegroup512kb", youtubegroup256kb... but... in
this way.. i have to give http_access for other groups to?? (youtube512/256)
or just because that users are in "internet-limitation"... It is not
necessary?

i think im completely wrong about this.......... but i really dont know how
to do what i want.

Thanks.




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Errors-in-cache-log-tp4679651p4679741.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From dans at chairfour.com  Wed Sep 28 17:48:12 2016
From: dans at chairfour.com (Daniel Sutcliffe)
Date: Wed, 28 Sep 2016 13:48:12 -0400
Subject: [squid-users] cache_peer name gone from logs after upgrade to 3.5
Message-ID: <CA+ZjQ1K9Xz6DJa_fEB_0w4PCRifVL0Sj4Fj0wMB4ySmPB7Dx8A@mail.gmail.com>

I have been using squid 3.1 on EL6 for a long time and recently made
the upgrade to 3.5 - all seems to be working as expected functionality
wise, but I'm noticing a difference in the log file content which is
not helping me doing a bit of peer debugging...

In 3.1 the access.log used to contain a:
  *_PARENT/<peername>
What I'm now seeing is:
  *_PARENT/<peer-ip>

Which wouldn't be so bad if all my <peer-ip> are the same, 127.0.0.1
as they are all SSH tunnels.

Otherwise the cache_peer name= directive seems to be doing its job as
far as ACLs are concerned.

Maybe this is now the expected behavior but I can't seem to find it
documented anywhere - it would be nice if the old log behavior could
be turned back on or I could have it confirmed that what I am seeing
is just the way it is now.

Cheers
/dan
-- 
Daniel Sutcliffe <dans at chairfour.com>
Chair Four Development Group LLC


From yvoinov at gmail.com  Wed Sep 28 17:56:29 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 28 Sep 2016 23:56:29 +0600
Subject: [squid-users] cache_peer name gone from logs after upgrade to
	3.5
In-Reply-To: <CA+ZjQ1K9Xz6DJa_fEB_0w4PCRifVL0Sj4Fj0wMB4ySmPB7Dx8A@mail.gmail.com>
References: <CA+ZjQ1K9Xz6DJa_fEB_0w4PCRifVL0Sj4Fj0wMB4ySmPB7Dx8A@mail.gmail.com>
Message-ID: <48ec5724-ccaf-4eab-33e8-771bb3c1470b@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
It's tragedy, man.

But 3.1 is too antique against 3.5 to remain unchanged.

Also, do not expect good documentation from open source - you can always
read sources yourself and know what's changed.

Too sad. But this it.

WBR, Yuri


28.09.2016 23:48, Daniel Sutcliffe ?????:
> I have been using squid 3.1 on EL6 for a long time and recently made
> the upgrade to 3.5 - all seems to be working as expected functionality
> wise, but I'm noticing a difference in the log file content which is
> not helping me doing a bit of peer debugging...
>
> In 3.1 the access.log used to contain a:
>   *_PARENT/<peername>
> What I'm now seeing is:
>   *_PARENT/<peer-ip>
>
> Which wouldn't be so bad if all my <peer-ip> are the same, 127.0.0.1
> as they are all SSH tunnels.
>
> Otherwise the cache_peer name= directive seems to be doing its job as
> far as ACLs are concerned.
>
> Maybe this is now the expected behavior but I can't seem to find it
> documented anywhere - it would be nice if the old log behavior could
> be turned back on or I could have it confirmed that what I am seeing
> is just the way it is now.
>
> Cheers
> /dan

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX7ARNAAoJENNXIZxhPexG2isIALrnOT/TVMd5Nhchf18HFs6b
zGoI3KjFD3hpIDrUAFhzFss5WhLc0f/rFwdkEQBpwTjJm8t3jHawoMxo3yDeHqzm
4O9qknEtq1sObI4nCuI9SxK0gXkIqynUKW1fOEWVHGD990H0aw7KiZ5p9T2Ro61q
upXOYP0aYiiaTT9bJTxl5l/gzNrU5yGi/NClpV1UbFt/O4MTTrRemZd8NmeP8J2u
6uqRarDaLEv62SDOdbc8xXEw5n+GLkUEVX12I9/oXvwrwrFGfQhPaSCqgsdvK/rW
cycS672NlRu/yTkqdsnPQ/nWtG744lM/OnMwy2I36i/qBAv7q9HBPc0nRpLoZMw=
=lKgO
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160928/b74fe27d/attachment.key>

From dans at chairfour.com  Wed Sep 28 18:02:17 2016
From: dans at chairfour.com (Daniel Sutcliffe)
Date: Wed, 28 Sep 2016 14:02:17 -0400
Subject: [squid-users] cache_peer name gone from logs after upgrade to
	3.5
In-Reply-To: <48ec5724-ccaf-4eab-33e8-771bb3c1470b@gmail.com>
References: <CA+ZjQ1K9Xz6DJa_fEB_0w4PCRifVL0Sj4Fj0wMB4ySmPB7Dx8A@mail.gmail.com>
 <48ec5724-ccaf-4eab-33e8-771bb3c1470b@gmail.com>
Message-ID: <CA+ZjQ1KATj1Yaxr0ciLbYk-wWyA275C_Y_SEu5gWB+nFzd0Z+g@mail.gmail.com>

On Wed, Sep 28, 2016 at 1:56 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
> It's tragedy, man.
>
> But 3.1 is too antique against 3.5 to remain unchanged.

:) Thankfully, almost all of the changes are improvements

> Also, do not expect good documentation from open source - you can always
> read sources yourself and know what's changed.

Very true - I just thought this mailing list might provide a quick
answer - and it did!

> Too sad. But this it.

Unless it bugs me enough to find the change and work out how I patch
back  the old behavior ;)

Cheers
/dan
-- 
Daniel Sutcliffe <dans at chairfour.com>
Chair Four Development Group LLC


From dans at chairfour.com  Wed Sep 28 18:38:48 2016
From: dans at chairfour.com (Daniel Sutcliffe)
Date: Wed, 28 Sep 2016 14:38:48 -0400
Subject: [squid-users] cache_peer name gone from logs after upgrade to
	3.5
In-Reply-To: <CA+ZjQ1KATj1Yaxr0ciLbYk-wWyA275C_Y_SEu5gWB+nFzd0Z+g@mail.gmail.com>
References: <CA+ZjQ1K9Xz6DJa_fEB_0w4PCRifVL0Sj4Fj0wMB4ySmPB7Dx8A@mail.gmail.com>
 <48ec5724-ccaf-4eab-33e8-771bb3c1470b@gmail.com>
 <CA+ZjQ1KATj1Yaxr0ciLbYk-wWyA275C_Y_SEu5gWB+nFzd0Z+g@mail.gmail.com>
Message-ID: <CA+ZjQ1Jb=DD_0V7SqLFebGDxifPNeU3RYP5kbzUf1vM7mq=S8w@mail.gmail.com>

On Wed, Sep 28, 2016 at 1:56 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>> It's tragedy, man.
>>
>> But 3.1 is too antique against 3.5 to remain unchanged.

On Wed, Sep 28, 2016 at 2:02 PM, Daniel Sutcliffe <dans at chairfour.com> wrote:
> :) Thankfully, almost all of the changes are improvements
>
>> Also, do not expect good documentation from open source

Also, perhaps do not expect 100% reliable answers on open source
mailing lists ;)

In the 3.1 logformat docs -
http://www.squid-cache.org/Versions/v3/3.1/cfgman/logformat.html
we have a default of:
  logformat squid %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt
Whereas in the 3.5 we have:
  logformat squid %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un %Sh/%<a %mt

This is new for 3.5
  <a Server IP address of the last server or peer connection
And this changed from this:
  <A Server IP address or peer name
to this:
  <A Server FQDN or peer name

I just needed to read a bit more - problem solved :)
Cheers
/dan
-- 
Daniel Sutcliffe <dans at chairfour.com>
Chair Four Development Group LLC


From yvoinov at gmail.com  Wed Sep 28 19:02:09 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 29 Sep 2016 01:02:09 +0600
Subject: [squid-users] cache_peer name gone from logs after upgrade to
	3.5
In-Reply-To: <CA+ZjQ1Jb=DD_0V7SqLFebGDxifPNeU3RYP5kbzUf1vM7mq=S8w@mail.gmail.com>
References: <CA+ZjQ1K9Xz6DJa_fEB_0w4PCRifVL0Sj4Fj0wMB4ySmPB7Dx8A@mail.gmail.com>
 <48ec5724-ccaf-4eab-33e8-771bb3c1470b@gmail.com>
 <CA+ZjQ1KATj1Yaxr0ciLbYk-wWyA275C_Y_SEu5gWB+nFzd0Z+g@mail.gmail.com>
 <CA+ZjQ1Jb=DD_0V7SqLFebGDxifPNeU3RYP5kbzUf1vM7mq=S8w@mail.gmail.com>
Message-ID: <53ce43ee-4d07-1b5a-d1a1-47b739a788c3@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


29.09.2016 0:38, Daniel Sutcliffe ?????:
> On Wed, Sep 28, 2016 at 1:56 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>>> It's tragedy, man.
>>>
>>> But 3.1 is too antique against 3.5 to remain unchanged.
>
> On Wed, Sep 28, 2016 at 2:02 PM, Daniel Sutcliffe <dans at chairfour.com>
wrote:
>> :) Thankfully, almost all of the changes are improvements
>>
>>> Also, do not expect good documentation from open source
>
> Also, perhaps do not expect 100% reliable answers on open source
> mailing lists ;)
>
> In the 3.1 logformat docs -
> http://www.squid-cache.org/Versions/v3/3.1/cfgman/logformat.html
> we have a default of:
>   logformat squid %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %un
%Sh/%<A %mt
> Whereas in the 3.5 we have:
>   logformat squid %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un
%Sh/%<a %mt
>
> This is new for 3.5
>   <a Server IP address of the last server or peer connection
> And this changed from this:
>   <A Server IP address or peer name
> to this:
>   <A Server FQDN or peer name
>
> I just needed to read a bit more - problem solved :)
So simple, is it? :-D Just RTFM - and viola, solved! ;-)
>
> Cheers
> /dan

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX7BOwAAoJENNXIZxhPexG478H/1PzSRptW9rmlqdJVgdf6nBn
SMgaOijnZSi2VDFbyEdVB+o7CIQ+h3uQhxSvTHrtty/XbfSIUk+7bsn+erRH69ex
w610kPyNrfjNsbVvV4eiltu0RIWSVE0MnwZp5+OOWtt1d3dFJ0BCr/csnNDVJXMT
Okpn55a+CWfybf5WUjrQcGImbKSjBLre4FrjRbQhlMSoXjltxNxiWFRUxUH7kjn7
hsrGxMKoioMWQeVxTreVpAmWpDODWNd8HxdttpLM77D2O5kbjgqdptyPdHJ0MDdj
ofa0Vadi4PCK138228hCZzmdIMmmRdvFDnkXrjRvrBCfqSeMZvlnPLLNBEEUviQ=
=ywxd
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160929/06aea2ea/attachment.key>

From eliezer at ngtech.co.il  Wed Sep 28 22:15:58 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 29 Sep 2016 01:15:58 +0300
Subject: [squid-users]
	=?utf-8?b?VGhlIFNxdWlkIOKAnFBlcnNvbmHigJ0tIFNxdWlk?=
	=?utf-8?q?_3=2E5=2E21+4=2E0=2E14_Release?=
In-Reply-To: <cfd3f260-64c3-a618-e3c7-05d0be4c7899@riosoft.com.br>
References: <!&!AAAAAAAAAAAuAAAAAAAAAP1vRcAAnWlNoU7f4f0YNhgBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAABsZAtsSLJaRLAoEGsoGj3pAQAAAAA=@ngtech.co.il>
 <cfd3f260-64c3-a618-e3c7-05d0be4c7899@riosoft.com.br>
Message-ID: <00fa01d219d5$e3918920$aab49b60$@ngtech.co.il>

It looks like a kid but missing a persona in some "things"..
Squid is a great product that helps many but sometimes someone can miss the point of the product.
There are limits to what the product can be when some QA is missing.
We need a more assistance with debugging and testing as much as possible.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Bruno de Paula Larini
Sent: Wednesday, September 28, 2016 4:27 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] The Squid ?Persona?- Squid 3.5.21+4.0.14 Release

Em 28/09/2016 08:39, Eliezer Croitoru escreveu:
> Take a look at the page source to get the full article: http://www1.ngtech.co.il/wpe/?p=345
>
> Who Is The Squid Girl Persona?
> [Squid Persona|http://www1.ngtech.co.il/wpe/wp-content/uploads/2016/09/squid_girl__shinryaku__ika_musume__minimalism_by_greenmapple17-d8u9mum-768x432.png]
>
> As a Squidder I know a girl or two but others are in the lookup for their Squid Girl Persona. Its?s not a simple task!!
> To illustrate the idea: We as males used to the web with all sort of GET, POST, OPTIONS, PROFIND and all sort of normal methods.
> But the Squid Girls is something else. She has brains!
> 	
> [Artist of the Persona|http://www.deviantart.com/tag/squid_girl?offset=3]
>
Is she a kid or a squid?
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Wed Sep 28 22:27:55 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 29 Sep 2016 01:27:55 +0300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <1474306760218-4679596.post@n4.nabble.com>
References: <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
 <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>
 <6e65eafe-37aa-e6f2-9c04-e4e14b9ff3e9@gmail.com>
 <CAEpx-0WMruHcZBP=kpZO1+C4YnELpeYGy2=WYtKMY5zmTWuaBg@mail.gmail.com>
 <3c02e953-d2cb-7905-f52a-e036ed3e06ab@treenet.co.nz>
 <1473879398350-4679512.post@n4.nabble.com>
 <e730f7da-c6ce-808f-f454-2d7a0369a92b@measurement-factory.com>
 <1473894106709-4679515.post@n4.nabble.com>
 <11a31fcd-901a-351a-4f60-8b2fe054b224@measurement-factory.com>
 <1473903753861-4679519.post@n4.nabble.com>
 <1474306760218-4679596.post@n4.nabble.com>
Message-ID: <010701d219d7$8f2efcd0$ad8cf670$@ngtech.co.il>

I am also testing this issue and I have the next settings:
acl DiscoverSNIHost at_step SslBump1
acl NoSSLIntercept ssl::server_name_regex -i "/etc/squid/url.nobump"
ssl_bump splice NoSSLIntercept
ssl_bump peek DiscoverSNIHost
ssl_bump bump all
sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/squid/ssl -M 4MB
sslcrtd_children 10
read_ahead_gap 64 MB
sslproxy_cert_error allow all
tls_outgoing_options flags=DONT_VERIFY_PEER
acl foreignProtocol squid_error ERR_PROTOCOL_UNKNOWN ERR_TOO_BIG
on_unsupported_protocol tunnel foreignProtocol

(Which is not recommended for production as is!!!)

Now the "/etc/squid/url.nobump" file contains:
# WU (Squid 3.5.x and above with SSL Bump)
# Only this sites must be spliced.
update\.microsoft\.com$
update\.microsoft\.com\.akadns\.net$
v10\.vortex\-win\.data\.microsoft.com$
settings\-win\.data\.microsoft\.com$
# The next are trusted SKYPE addresses
a\.config\.skype\.com$
pipe\.skype\.com$
mail\.rimon\.net\.il$
w[0-9]+\.web\.whatsapp\.com$
\.web\.whatsapp\.com$
web\.whatsapp\.com$
##END OF NO BUMP DOMAINS.

And squid 4.0.14 doesn't tunnel the requests.
The above is with:
http_port 3128
http_port 13128 intercept
https_port 13129 intercept ssl-bump \
   cert=/etc/squid/ssl_cert/myCA.pem \
     generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

On the 443 intercept port.
Access log output:
1475100891.636 000445 192.168.10.112 NONE/200 0 CONNECT 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
1475100908.469 000223 192.168.10.112 TCP_MISS/200 508 GET https://web.whatsapp.com/status.json - ORIGINAL_DST/31.13.90.51 text/json 52:54:00:bc:9f:73
1475100952.107 000445 192.168.10.112 NONE/200 0 CONNECT 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
1475100968.832 000191 192.168.10.112 NONE/200 0 CONNECT 216.58.214.110:443 - ORIGINAL_DST/216.58.214.110 - 52:54:00:bc:9f:73
1475100968.984 000199 192.168.10.112 NONE/200 0 CONNECT 172.217.22.14:443 - ORIGINAL_DST/172.217.22.14 - 52:54:00:bc:9f:73
1475101012.572 000447 192.168.10.112 NONE/200 0 CONNECT 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
1475101033.232 000621 192.168.10.112 NONE/200 0 CONNECT 31.13.66.49:443 - ORIGINAL_DST/31.13.66.49 - 52:54:00:bc:9f:73
1475101034.470 001224 192.168.10.112 TCP_MISS/200 512 GET https://web.whatsapp.com/status.json - ORIGINAL_DST/31.13.66.49 text/json 52:54:00:bc:9f:73
1475101073.039 000446 192.168.10.112 NONE/200 0 CONNECT 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
1475101133.502 000448 192.168.10.112 NONE/200 0 CONNECT 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73

Now the issue is more then just this since I cannot see any logs about the websocket connections ie to the domains:
w3.web.whatsapp.com

and couple other similar.

What I did until now is to bypass specific domains IP addresses using ipset+iptables.
I believe that squid can do much better then it's doing now.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Monday, September 19, 2016 8:39 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Web Whatsapp, Dropbox... problem

mmmmmmmmmm....
so...
i think this is working for non take the certificate

acl step1 at_step SslBump1 
acl excludeSSL ssl::server_name_regex web/.whatsapp/.com 

ssl_bump peek step1 
ssl_bump splice excludeSSL 
ssl_bump bump all 

but, anyway something more is happening because well... dosent work.
another point of view??



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Web-Whatsapp-Dropbox-problem-tp4679299p4679596.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From emz at norma.perm.ru  Thu Sep 29 03:38:40 2016
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Thu, 29 Sep 2016 08:38:40 +0500
Subject: [squid-users] connections from particular users sometimes get
 stuck
In-Reply-To: <7280391c-a10c-8eb9-c41a-4f924600dda8@measurement-factory.com>
References: <42b972b9-77a7-f43d-1630-fe31a71ab508@norma.perm.ru>
 <57EB7DAC.9000408@norma.perm.ru>
 <f81aae25-958a-b8f4-2b28-5a0daecc1f71@measurement-factory.com>
 <201609281741.54358.Antony.Stone@squid.open.source.it>
 <7280391c-a10c-8eb9-c41a-4f924600dda8@measurement-factory.com>
Message-ID: <c14e1d4d-bff7-6ea2-dd8c-82a9663b1c19@norma.perm.ru>

Hi.

On 28.09.2016 21:21, Alex Rousskov wrote:
>
> Indeed! Fixing that exposes one HTTP request in the capture file.
> Unfortunately,
>
> 1. Squid responded to that request (with a 407 message).
>     Follow (tcp.stream eq 32) in Wireshark.
>
> 2. Squid did not receive this request when debugging was on:
>     $ egrep -c 'www.ru|217.112.35.75' cache.log.debug
>     0
Yup, I noticed this too.
> It may be important to know that the captured request was received at
> minute 53 while Squid debugging starts at minute 58 (I assume the
> difference in hours is due to time zone effects and such).
>
The thing is, the client machine is in the AD domain and it's time is NTP-synced, so is the time on the squid machine. I think I was accurate, but mey be I still wasn't. I will redo the captures, this time with squid-towards-the-LAN capture, and I will try to validate them myself. Luckily, I didn't restart squid yet and this machine still demonstrates the symptoms.

Thanks.
Eugene.



From squid3 at treenet.co.nz  Thu Sep 29 03:47:33 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 29 Sep 2016 16:47:33 +1300
Subject: [squid-users] Errors in cache.log
In-Reply-To: <1475081031054-4679741.post@n4.nabble.com>
References: <1474567862731-4679651.post@n4.nabble.com>
 <5756dcf2-f88b-1f15-9b43-dff112f17894@treenet.co.nz>
 <1474638603998-4679664.post@n4.nabble.com>
 <ec63ead9-72cc-71da-9e00-e607d02c5559@treenet.co.nz>
 <1474771838380-4679679.post@n4.nabble.com>
 <7d0acc3e-502d-000c-f227-4e5902e47ff1@treenet.co.nz>
 <1474828600378-4679683.post@n4.nabble.com>
 <e0b2c96c-03cc-717a-0c26-2d6d6e854153@treenet.co.nz>
 <1475081031054-4679741.post@n4.nabble.com>
Message-ID: <6898f100-7bd9-d0ba-673a-de68b7a92b9e@treenet.co.nz>

On 29/09/2016 5:43 a.m., erdosain9 wrote:
> Hi.
> Another question  in reference to this topic off delay pools.........
> if i have "internet-limitation" (a group with 100kb for all webs) and i want
> that users of that group have different youtube bandwith... is this
> posible??

Of course you can. You just have to configure it.

This is why I tried to make you think about the adminis pools
configuration, and the other one with same problem. If you understood it
you would not be asking us and waiting for responses to every little
change to your config file.

The config for this questions answer is exactly the same logic as it is
for the adminis group using streams (or not). Just different ACL names
and (maybe) pool numbers.


> 
> I need to do another group with the user of that group that i want they have
> different bandwith for youtube? if i do that i will split
> "internet-limitation" in "youtubegroup512kb", youtubegroup256kb... but... in
> this way.. i have to give http_access for other groups to?? (youtube512/256)
> or just because that users are in "internet-limitation"... It is not
> necessary?
> 

http_access determines who is allowed (or not) to use the proxy.

It is also being used as a workaround place to lookup specific
user+group connections that will be used in the delay_pool_access rules
(which cant do that lookup themselves).

You should know the answer to your question by now.


> i think im completely wrong about this.......... but i really dont know how
> to do what i want.

Perhapse it would help you to write to us what you are thinking is
happening. We can correct bits where you are going wrong (if any).

Amos



From squid3 at treenet.co.nz  Thu Sep 29 03:53:01 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 29 Sep 2016 16:53:01 +1300
Subject: [squid-users] cache_peer name gone from logs after upgrade to
	3.5
In-Reply-To: <CA+ZjQ1Jb=DD_0V7SqLFebGDxifPNeU3RYP5kbzUf1vM7mq=S8w@mail.gmail.com>
References: <CA+ZjQ1K9Xz6DJa_fEB_0w4PCRifVL0Sj4Fj0wMB4ySmPB7Dx8A@mail.gmail.com>
 <48ec5724-ccaf-4eab-33e8-771bb3c1470b@gmail.com>
 <CA+ZjQ1KATj1Yaxr0ciLbYk-wWyA275C_Y_SEu5gWB+nFzd0Z+g@mail.gmail.com>
 <CA+ZjQ1Jb=DD_0V7SqLFebGDxifPNeU3RYP5kbzUf1vM7mq=S8w@mail.gmail.com>
Message-ID: <270f124c-2368-f881-a07c-af962b35d5b5@treenet.co.nz>

On 29/09/2016 7:38 a.m., Daniel Sutcliffe wrote:
> On Wed, Sep 28, 2016 at 1:56 PM, Yuri Voinov <yvoinov at gmail.com> wrote:
>>> It's tragedy, man.
>>>
>>> But 3.1 is too antique against 3.5 to remain unchanged.
> 
> On Wed, Sep 28, 2016 at 2:02 PM, Daniel Sutcliffe <dans at chairfour.com> wrote:
>> :) Thankfully, almost all of the changes are improvements
>>
>>> Also, do not expect good documentation from open source
> 
> Also, perhaps do not expect 100% reliable answers on open source
> mailing lists ;)
> 
> In the 3.1 logformat docs -
> http://www.squid-cache.org/Versions/v3/3.1/cfgman/logformat.html
> we have a default of:
>   logformat squid %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt
> Whereas in the 3.5 we have:
>   logformat squid %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un %Sh/%<a %mt
> 
> This is new for 3.5
>   <a Server IP address of the last server or peer connection
> And this changed from this:
>   <A Server IP address or peer name
> to this:
>   <A Server FQDN or peer name
> 
> I just needed to read a bit more - problem solved :)

As for the why:
 With many sites going IPv6-enabled we were getting a lot of complaints
and queries about why some requests would work and others not work, but
the log only have one name displayed for any access to the site(s). It
often turned out to be broken connections to just one IP of several.
With the new format one can see the broken IPs more clearly and identify
the issue without guessing.

Amos



From squid3 at treenet.co.nz  Thu Sep 29 04:15:51 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 29 Sep 2016 17:15:51 +1300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <010701d219d7$8f2efcd0$ad8cf670$@ngtech.co.il>
References: <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
 <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>
 <6e65eafe-37aa-e6f2-9c04-e4e14b9ff3e9@gmail.com>
 <CAEpx-0WMruHcZBP=kpZO1+C4YnELpeYGy2=WYtKMY5zmTWuaBg@mail.gmail.com>
 <3c02e953-d2cb-7905-f52a-e036ed3e06ab@treenet.co.nz>
 <1473879398350-4679512.post@n4.nabble.com>
 <e730f7da-c6ce-808f-f454-2d7a0369a92b@measurement-factory.com>
 <1473894106709-4679515.post@n4.nabble.com>
 <11a31fcd-901a-351a-4f60-8b2fe054b224@measurement-factory.com>
 <1473903753861-4679519.post@n4.nabble.com>
 <1474306760218-4679596.post@n4.nabble.com>
 <010701d219d7$8f2efcd0$ad8cf670$@ngtech.co.il>
Message-ID: <0cf0c543-f2f0-e880-6ef7-cec6312127ad@treenet.co.nz>

On 29/09/2016 11:27 a.m., Eliezer Croitoru wrote:
> I am also testing this issue and I have the next settings:
> acl DiscoverSNIHost at_step SslBump1
> acl NoSSLIntercept ssl::server_name_regex -i "/etc/squid/url.nobump"
> ssl_bump splice NoSSLIntercept
> ssl_bump peek DiscoverSNIHost
> ssl_bump bump all
> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/squid/ssl -M 4MB
> sslcrtd_children 10
> read_ahead_gap 64 MB
> sslproxy_cert_error allow all
> tls_outgoing_options flags=DONT_VERIFY_PEER
> acl foreignProtocol squid_error ERR_PROTOCOL_UNKNOWN ERR_TOO_BIG
> on_unsupported_protocol tunnel foreignProtocol
> 
> (Which is not recommended for production as is!!!)
> 
> Now the "/etc/squid/url.nobump" file contains:
> # WU (Squid 3.5.x and above with SSL Bump)
> # Only this sites must be spliced.
> update\.microsoft\.com$
> update\.microsoft\.com\.akadns\.net$
> v10\.vortex\-win\.data\.microsoft.com$
> settings\-win\.data\.microsoft\.com$
> # The next are trusted SKYPE addresses
> a\.config\.skype\.com$
> pipe\.skype\.com$
> mail\.rimon\.net\.il$
> w[0-9]+\.web\.whatsapp\.com$
> \.web\.whatsapp\.com$
> web\.whatsapp\.com$
> ##END OF NO BUMP DOMAINS.
> 
> And squid 4.0.14 doesn't tunnel the requests.
> The above is with:
> http_port 3128
> http_port 13128 intercept
> https_port 13129 intercept ssl-bump \
>    cert=/etc/squid/ssl_cert/myCA.pem \
>      generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> 
> On the 443 intercept port.
> Access log output:
> 1475100891.636 000445 192.168.10.112 NONE/200 0 CONNECT 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
> 1475100908.469 000223 192.168.10.112 TCP_MISS/200 508 GET https://web.whatsapp.com/status.json - ORIGINAL_DST/31.13.90.51 text/json 52:54:00:bc:9f:73
> 1475100952.107 000445 192.168.10.112 NONE/200 0 CONNECT 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
> 1475100968.832 000191 192.168.10.112 NONE/200 0 CONNECT 216.58.214.110:443 - ORIGINAL_DST/216.58.214.110 - 52:54:00:bc:9f:73
> 1475100968.984 000199 192.168.10.112 NONE/200 0 CONNECT 172.217.22.14:443 - ORIGINAL_DST/172.217.22.14 - 52:54:00:bc:9f:73
> 1475101012.572 000447 192.168.10.112 NONE/200 0 CONNECT 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
> 1475101033.232 000621 192.168.10.112 NONE/200 0 CONNECT 31.13.66.49:443 - ORIGINAL_DST/31.13.66.49 - 52:54:00:bc:9f:73
> 1475101034.470 001224 192.168.10.112 TCP_MISS/200 512 GET https://web.whatsapp.com/status.json - ORIGINAL_DST/31.13.66.49 text/json 52:54:00:bc:9f:73
> 1475101073.039 000446 192.168.10.112 NONE/200 0 CONNECT 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
> 1475101133.502 000448 192.168.10.112 NONE/200 0 CONNECT 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
> 
> Now the issue is more then just this since I cannot see any logs about the websocket connections ie to the domains:
> w3.web.whatsapp.com
> 

They might be in the ones with raw-IP in NONE/200 lines. Since
server_name_regex matches against the TLS-cert details which do not
necessarily get logged as a URL domain name when splice is done.

The SNI _should_ be made the CONNECT URI domain. But when it matches the
server cert altSubjectName that is definitely not a client requested value.


> and couple other similar.
> 
> What I did until now is to bypass specific domains IP addresses using ipset+iptables.
> I believe that squid can do much better then it's doing now.

Can you get a packet dump to see what its TLS handshake details actually
are? both client and server sides of Squid.

Amos



From emz at norma.perm.ru  Thu Sep 29 08:58:17 2016
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Thu, 29 Sep 2016 13:58:17 +0500
Subject: [squid-users] connections from particular users sometimes get
 stuck
In-Reply-To: <c14e1d4d-bff7-6ea2-dd8c-82a9663b1c19@norma.perm.ru>
References: <42b972b9-77a7-f43d-1630-fe31a71ab508@norma.perm.ru>
 <57EB7DAC.9000408@norma.perm.ru>
 <f81aae25-958a-b8f4-2b28-5a0daecc1f71@measurement-factory.com>
 <201609281741.54358.Antony.Stone@squid.open.source.it>
 <7280391c-a10c-8eb9-c41a-4f924600dda8@measurement-factory.com>
 <c14e1d4d-bff7-6ea2-dd8c-82a9663b1c19@norma.perm.ru>
Message-ID: <57ECD7A9.60607@norma.perm.ru>

Hi.

On 29.09.2016 08:38, Eugene M. Zheganin wrote:
> Hi.
>
> On 28.09.2016 21:21, Alex Rousskov wrote:
>>
>> Indeed! Fixing that exposes one HTTP request in the capture file.
>> Unfortunately,
>>
>> 1. Squid responded to that request (with a 407 message).
>>     Follow (tcp.stream eq 32) in Wireshark.
>>
>> 2. Squid did not receive this request when debugging was on:
>>     $ egrep -c 'www.ru|217.112.35.75' cache.log.debug
>>     0
> Yup, I noticed this too.
>> It may be important to know that the captured request was received at
>> minute 53 while Squid debugging starts at minute 58 (I assume the
>> difference in hours is due to time zone effects and such).
>>
> The thing is, the client machine is in the AD domain and it's time is
> NTP-synced, so is the time on the squid machine. I think I was
> accurate, but mey be I still wasn't. I will redo the captures, this
> time with squid-towards-the-LAN capture, and I will try to validate
> them myself. Luckily, I didn't restart squid yet and this machine
> still demonstrates the symptoms.
Okay, second try. Same IPs, same browser; this time user opens
http://turbodom.ru/index.html (www.ru/index.html got unstuck).
Time is NTP-synced on both machines.

This time turbodom.ru entries are present in the debug log (actually,
there's no /index.html at the turbodom.ru, so anyone requesting
http://turbodom.ru/index.html is me).

debug log:
http://zhegan.in/files/squid/cache.log.debug

tcpdump capture taken from a client machine:
http://zhegan.in/files/squid/squid-stuck-client.pcap

tcpdump capture taken from squid machine, on the interface the client
machine is connected via:
http://zhegan.in/files/squid/squid-stuck-server-to-client.pcap

Thanks.
Eugene.



From darren.j.breeze.ml at gmail.com  Thu Sep 29 09:44:28 2016
From: darren.j.breeze.ml at gmail.com (Darren)
Date: Thu, 29 Sep 2016 17:44:28 +0800
Subject: [squid-users] Large text ACL lists
Message-ID: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>

Hi All

I have been tinkering with Squidguard for a while, using it to manage ACL lists and time limits etc.

While it works OK, it's not in active development and has it's issues.

What are the limitations with just pumping ACL lists directly into Squid and letting it do all the work internally without running a team of squidguards?

how efficient is squid now at parsing the text files directly, will i Need more ram as the list grows? Is it slower or are their optimizations that I can do?

thanks all

Darren Breeze





Sent from Mailbird [http://www.getmailbird.com/?utm_source=Mailbird&amp;utm_medium=email&amp;utm_campaign=sent-from-mailbird]
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160929/ba831ea1/attachment.htm>

From Antony.Stone at squid.open.source.it  Thu Sep 29 10:08:09 2016
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 29 Sep 2016 12:08:09 +0200
Subject: [squid-users] Large text ACL lists
In-Reply-To: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
Message-ID: <201609291208.09456.Antony.Stone@squid.open.source.it>

On Thursday 29 September 2016 at 11:44:28, Darren wrote:

> Hi All
> 
> I have been tinkering with Squidguard for a while, using it to manage ACL
> lists and time limits etc.
> 
> While it works OK, it's not in active development and has its issues.

Have you considered https://www.urlfilterdb.com/products/ufdbguard.html ?

Their database is not free, but the filtering plugin is.

> What are the limitations with just pumping ACL lists directly into Squid
> and letting it do all the work internally without running a team of
> squidguards?
> 
> how efficient is squid now at parsing the text files directly, will i Need
> more ram as the list grows? Is it slower or are their optimizations that I
> can do?

Maybe someone else can answer this part of your question; I have no data on 
this.


Antony.

-- 
This email was created using 100% recycled electrons.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From rentorbuy at yahoo.com  Thu Sep 29 12:02:36 2016
From: rentorbuy at yahoo.com (Vieri)
Date: Thu, 29 Sep 2016 12:02:36 +0000 (UTC)
Subject: [squid-users] squid tproxy ssl-bump and Protocol error (TLS code:
 SQUID_ERR_SSL_HANDSHAKE)
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
Message-ID: <414102480.6739156.1475150556309@mail.yahoo.com>

Hi,

I'm running a Squid proxy like so:

http_port 3129 tproxy
https_port 3130 tproxy ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=16MB cert=/etc/ssl/squid/proxyserver.pem

The squid server certificate was self-generated:
openssl req -new -newkey rsa:2048 -sha256 -days 7300 -nodes -x509 -keyout /etc/ssl/squid/proxyserver.pem -out /etc/ssl/squid/proxyserver.pem

I configured my firewall rules approriately and everything seems to work fine on systems such as Windows 7 32bits/64bits with IE11, IE8 or latest Firefox.
However, I'm having trouble with Windows XP Pro SP3 and IE8.
On this client OS, Firefox 45.0.1 works fine with HTTP and HTTPS sites. However, IE8 on this same client OS works fine accessing HTTP sites but not HTTPS.

When I try to access google.com I first get a certificate warning (untrusted cert). That's the first flaw because I shouldn't get this page since the proxy server's certificate is in the IE Trust Store (under root certificates).
Then if I try to connect to google.com despite the "untrusted certificate" warning, I get the exception:

71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
Handshake with SSL server failed: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry

I noticed that this browser/OS only has TLS up to 1.0 (no 1.2 or 1.1).

I can reproduce the same Squid exception on a Windows 7 IE8 system if I disable TLS 1.2 and only use TLS 1.1 and/or lower.

Any ideas?

Regards,

Vieri


From dans at chairfour.com  Thu Sep 29 13:03:55 2016
From: dans at chairfour.com (Daniel Sutcliffe)
Date: Thu, 29 Sep 2016 09:03:55 -0400
Subject: [squid-users] cache_peer name gone from logs after upgrade to
	3.5
In-Reply-To: <270f124c-2368-f881-a07c-af962b35d5b5@treenet.co.nz>
References: <CA+ZjQ1K9Xz6DJa_fEB_0w4PCRifVL0Sj4Fj0wMB4ySmPB7Dx8A@mail.gmail.com>
 <48ec5724-ccaf-4eab-33e8-771bb3c1470b@gmail.com>
 <CA+ZjQ1KATj1Yaxr0ciLbYk-wWyA275C_Y_SEu5gWB+nFzd0Z+g@mail.gmail.com>
 <CA+ZjQ1Jb=DD_0V7SqLFebGDxifPNeU3RYP5kbzUf1vM7mq=S8w@mail.gmail.com>
 <270f124c-2368-f881-a07c-af962b35d5b5@treenet.co.nz>
Message-ID: <CA+ZjQ1J8M2tOr588t6gSvtsW15T5akx=vNHz+HrmVbbduAM4_w@mail.gmail.com>

> On 29/09/2016 7:38 a.m., Daniel Sutcliffe wrote:
>> In the 3.1 logformat docs -
>> http://www.squid-cache.org/Versions/v3/3.1/cfgman/logformat.html
>> we have a default of:
>>   logformat squid %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt
>> Whereas in the 3.5 we have:
>>   logformat squid %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un %Sh/%<a %mt
>>
>> This is new for 3.5
>>   <a Server IP address of the last server or peer connection
>> And this changed from this:
>>   <A Server IP address or peer name
>> to this:
>>   <A Server FQDN or peer name
>>
>> I just needed to read a bit more - problem solved :)

On Wed, Sep 28, 2016 at 11:53 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> As for the why:
>  With many sites going IPv6-enabled we were getting a lot of complaints
> and queries about why some requests would work and others not work, but
> the log only have one name displayed for any access to the site(s). It
> often turned out to be broken connections to just one IP of several.
> With the new format one can see the broken IPs more clearly and identify
> the issue without guessing.

Thanks for the background explanation.
Makes perfect sense to me - almost the opposite to the problem I had.

Cheers
/dan
-- 
Daniel Sutcliffe <dans at chairfour.com>
Chair Four Development Group LLC


From henry at nitronetworks.nl  Thu Sep 29 14:39:53 2016
From: henry at nitronetworks.nl (Henry Paulissen)
Date: Thu, 29 Sep 2016 16:39:53 +0200
Subject: [squid-users] External nat'ed transparent proxy
Message-ID: <9cb02f45-ad81-7d77-0d7a-cf313c34f4fd@nitronetworks.nl>

Hi all,

In the company I work for we are currently using squid v2 proxies in
transparent mode to intercept traffic from servers to the outside
(access control).

The technical solution for this is roughly as follows:
[server] -> [gateway] -> [firewall]
                              |
    ----------- DNAT ---------
   v
[squid]  -> [gateway] -> [firewall] -> [internet router]

Our firewalls (who live between the vlan gateway and internet router),
DNAT the traffic towards separate squid proxies (who are in a lvs
cluster). These squid proxies are in their own vlan with special
permissions to allow unrestricted port 80 outbound, etc, etc...

Because squid v2 is becoming more and more obsolete we are looking at
upgrading it towards squid v3.

From what I read in the manuals, transparent mode is replaced by
intercept (and tproxy) mode. But both dont seem to be fully backward
complaint with the v2 transparent mode.

The old trasparent mode allowed us to just dnat traffic towards the
squid host without the need for the client to be aware of this. For
example, the old style accepted 'GET / HTTP/1.1' (without full URL in
the GET request and looking at the Host header for the destination).

The new intercept mode comes close to this behavior, but instead of
remotly dnat, it wants us to next-hop it towards the squid proxy and
redirect it locally. This is problematic for us as firewall and squid
proxy dont live in the same vlan, so next-hop should be the router to
that vlan (and forgetting about the path back to the server). Secondly,
and not less blocking, we use vservers (predecessor to linux containers
lxc) as such, we dont have any promiscuous interfaces rights within the
container.


Is there still a option to emulate normal 'regular? style squid (as
without any listen options) but instead accepting the URI path in the
GET request and looking at the Host header for the destination? (lets
call it passthrough mode?).

Or, is there in squid3 a new and better way to facilitate larger setups,
with the knowledge the server, firewall and squids are all in different
vlans (and no, we dont have Cisco firewalls in between them ;-)).


Thanks in advance,

-- 
Henry Paulissen - PD0OM
henry at nitronetworks.nl - Phone: +31-(0)6-115.305.64
Linux/Unix System Engineer

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160929/5bc9c277/attachment.sig>

From webmaster at squidblacklist.org  Thu Sep 29 17:42:49 2016
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Thu, 29 Sep 2016 12:42:49 -0500
Subject: [squid-users] Large text ACL lists
In-Reply-To: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
Message-ID: <895f4c0a-643a-924d-ede9-af457c8c3e32@squidblacklist.org>

The other issue is that shalla and urlblacklist produce garbage 
blacklists, and neither of them are actively developing or improving the 
backend technology required to product high quality blacklists.

We are the leading publisher of blacklists tailored for Web Filtering 
Purposes.

We are also the only commercial source for Squid Native ACL. Yes, we 
have it.


On 9/29/2016 4:44 AM, Darren wrote:
> Hi All
>
> I have been tinkering with Squidguard for a while, using it to manage 
> ACL lists and time limits etc.
>
> While it works OK, it's not in active development and has it's issues.
>
> What are the limitations with just pumping ACL lists directly into 
> Squid and letting it do all the work internally without running a team 
> of squidguards?
>
> how efficient is squid now at parsing the text files directly, will i 
> Need more ram as the list grows? Is it slower or are their 
> optimizations that I can do?
>
> thanks all
>
> Darren Breeze
>
>
>
>
>
> Sent from Mailbird 
> <http://www.getmailbird.com/?utm_source=Mailbird&utm_medium=email&utm_campaign=sent-from-mailbird>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
--

Signed,

Benjamin E. Nichols
http://www.squidblacklist.org

1-405-397-1360 - Call Anytime.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160929/6787e095/attachment.htm>

From rousskov at measurement-factory.com  Thu Sep 29 18:17:12 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 29 Sep 2016 12:17:12 -0600
Subject: [squid-users] connections from particular users sometimes get
 stuck
In-Reply-To: <57ECD7A9.60607@norma.perm.ru>
References: <42b972b9-77a7-f43d-1630-fe31a71ab508@norma.perm.ru>
 <57EB7DAC.9000408@norma.perm.ru>
 <f81aae25-958a-b8f4-2b28-5a0daecc1f71@measurement-factory.com>
 <201609281741.54358.Antony.Stone@squid.open.source.it>
 <7280391c-a10c-8eb9-c41a-4f924600dda8@measurement-factory.com>
 <c14e1d4d-bff7-6ea2-dd8c-82a9663b1c19@norma.perm.ru>
 <57ECD7A9.60607@norma.perm.ru>
Message-ID: <5ec198bf-ae59-1972-698b-591a575285bc@measurement-factory.com>

On 09/29/2016 02:58 AM, Eugene M. Zheganin wrote:
> This time turbodom.ru entries are present in the debug log

Yes, there are two complete HTTP transactions with that domain. One is a
407 Authentication Required and one is a 301 redirect:

> HTTP/1.1 301 Moved Permanently
...
> Location: http://turbodom.ru/index.html/

I see no relevant problems with those two transactions.


> tcpdump capture taken from a client machine:
> http://zhegan.in/files/squid/squid-stuck-client.pcap

This capture one is missing most of the second transaction packets
(tcp.stream eq 186). I do not know why tcpdump was unable to collect them.


> tcpdump capture taken from squid machine, on the interface the client
> machine is connected via:
> http://zhegan.in/files/squid/squid-stuck-server-to-client.pcap

This one has both HTTP transactions described above (tcp.stream eq 206).

It also contains a related and incomplete transaction that follows the
above redirect (tcp.stream eq 346). According to tcpdump, that
transaction starts around 13:31:26.

Squid cache log does not mention that third transaction (or that TCP
connection), probably because Squid could not accept it. There were a
few accept failures (ECONNABORTED) right around the time of that
third/missing transaction:

> 13:31:25.060 kid1| accept failure: (53) Software caused connection abort
> 13:31:25.865 kid1| accept failure: (53) Software caused connection abort
> 13:31:25.904 kid2| accept failure: (53) Software caused connection abort

The timestamps are a ~second off, but AFAICT, they are a ~second off for
successful accepts as well, so it is probably just a tcpdump logging
artifact.

In summary, your browser is probably stuck because Squid could not
accept a connection. Why did that accept call fail with ECONNABORTED? I
cannot say for sure -- the packet trace is rather dirty/misleading
(e.g., it shows the redirect packet being sent to the client _after_ the
client follows that redirect which does not make sense).

Any relevant errors in you system logs?

If you cancel browser wait and repeat the request, will it work? If this
was just a random accept failure, then it should work on the second try.
If it does not work again, then there is something more serious going on
(but you would need to collect more logs to study that).

The connection accepting code in Squid is in poor shape, but I do not
think those minor code problems affect this particular use case.

Alex.



From eliezer at ngtech.co.il  Thu Sep 29 20:34:57 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 29 Sep 2016 23:34:57 +0300
Subject: [squid-users] Web Whatsapp, Dropbox... problem
In-Reply-To: <0cf0c543-f2f0-e880-6ef7-cec6312127ad@treenet.co.nz>
References: <2bac3033-f451-4db6-017a-f694774c6ed4@gmail.com>
 <CAEpx-0UWfZqwQStgmdrh9D3-ktYLx8D_LpV0MghV_2vG10i2LA@mail.gmail.com>
 <6e65eafe-37aa-e6f2-9c04-e4e14b9ff3e9@gmail.com>
 <CAEpx-0WMruHcZBP=kpZO1+C4YnELpeYGy2=WYtKMY5zmTWuaBg@mail.gmail.com>
 <3c02e953-d2cb-7905-f52a-e036ed3e06ab@treenet.co.nz>
 <1473879398350-4679512.post@n4.nabble.com>
 <e730f7da-c6ce-808f-f454-2d7a0369a92b@measurement-factory.com>
 <1473894106709-4679515.post@n4.nabble.com>
 <11a31fcd-901a-351a-4f60-8b2fe054b224@measurement-factory.com>
 <1473903753861-4679519.post@n4.nabble.com>
 <1474306760218-4679596.post@n4.nabble.com>
 <010701d219d7$8f2efcd0$ad8cf670$@ngtech.co.il>
 <0cf0c543-f2f0-e880-6ef7-cec6312127ad@treenet.co.nz>
Message-ID: <053301d21a90$f16a1600$d43e4200$@ngtech.co.il>

As a partial solution until I will be able to sit on the dumps and get the required data I wrote this script:
https://gist.github.com/elico/e0faadf0cc63942c5aaade808a87deef

Which bypasses squid for specific domains.
It is a very simple script and it works OK for whatsapp and it's on the iptables level so your will maybe loss some caching.
But for most of the public critical systems it is much better to have a bypass in standby compared to make your workers work harder then they can.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Thursday, September 29, 2016 7:16 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Web Whatsapp, Dropbox... problem

On 29/09/2016 11:27 a.m., Eliezer Croitoru wrote:
> I am also testing this issue and I have the next settings:
> acl DiscoverSNIHost at_step SslBump1
> acl NoSSLIntercept ssl::server_name_regex -i "/etc/squid/url.nobump"
> ssl_bump splice NoSSLIntercept
> ssl_bump peek DiscoverSNIHost
> ssl_bump bump all
> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/squid/ssl -M 4MB
> sslcrtd_children 10
> read_ahead_gap 64 MB
> sslproxy_cert_error allow all
> tls_outgoing_options flags=DONT_VERIFY_PEER
> acl foreignProtocol squid_error ERR_PROTOCOL_UNKNOWN ERR_TOO_BIG
> on_unsupported_protocol tunnel foreignProtocol
> 
> (Which is not recommended for production as is!!!)
> 
> Now the "/etc/squid/url.nobump" file contains:
> # WU (Squid 3.5.x and above with SSL Bump)
> # Only this sites must be spliced.
> update\.microsoft\.com$
> update\.microsoft\.com\.akadns\.net$
> v10\.vortex\-win\.data\.microsoft.com$
> settings\-win\.data\.microsoft\.com$
> # The next are trusted SKYPE addresses
> a\.config\.skype\.com$
> pipe\.skype\.com$
> mail\.rimon\.net\.il$
> w[0-9]+\.web\.whatsapp\.com$
> \.web\.whatsapp\.com$
> web\.whatsapp\.com$
> ##END OF NO BUMP DOMAINS.
> 
> And squid 4.0.14 doesn't tunnel the requests.
> The above is with:
> http_port 3128
> http_port 13128 intercept
> https_port 13129 intercept ssl-bump \
>    cert=/etc/squid/ssl_cert/myCA.pem \
>      generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> 
> On the 443 intercept port.
> Access log output:
> 1475100891.636 000445 192.168.10.112 NONE/200 0 CONNECT 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
> 1475100908.469 000223 192.168.10.112 TCP_MISS/200 508 GET https://web.whatsapp.com/status.json - ORIGINAL_DST/31.13.90.51 text/json 52:54:00:bc:9f:73
> 1475100952.107 000445 192.168.10.112 NONE/200 0 CONNECT 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
> 1475100968.832 000191 192.168.10.112 NONE/200 0 CONNECT 216.58.214.110:443 - ORIGINAL_DST/216.58.214.110 - 52:54:00:bc:9f:73
> 1475100968.984 000199 192.168.10.112 NONE/200 0 CONNECT 172.217.22.14:443 - ORIGINAL_DST/172.217.22.14 - 52:54:00:bc:9f:73
> 1475101012.572 000447 192.168.10.112 NONE/200 0 CONNECT 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
> 1475101033.232 000621 192.168.10.112 NONE/200 0 CONNECT 31.13.66.49:443 - ORIGINAL_DST/31.13.66.49 - 52:54:00:bc:9f:73
> 1475101034.470 001224 192.168.10.112 TCP_MISS/200 512 GET https://web.whatsapp.com/status.json - ORIGINAL_DST/31.13.66.49 text/json 52:54:00:bc:9f:73
> 1475101073.039 000446 192.168.10.112 NONE/200 0 CONNECT 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
> 1475101133.502 000448 192.168.10.112 NONE/200 0 CONNECT 158.85.224.178:443 - ORIGINAL_DST/158.85.224.178 - 52:54:00:bc:9f:73
> 
> Now the issue is more then just this since I cannot see any logs about the websocket connections ie to the domains:
> w3.web.whatsapp.com
> 

They might be in the ones with raw-IP in NONE/200 lines. Since
server_name_regex matches against the TLS-cert details which do not
necessarily get logged as a URL domain name when splice is done.

The SNI _should_ be made the CONNECT URI domain. But when it matches the
server cert altSubjectName that is definitely not a client requested value.


> and couple other similar.
> 
> What I did until now is to bypass specific domains IP addresses using ipset+iptables.
> I believe that squid can do much better then it's doing now.

Can you get a packet dump to see what its TLS handshake details actually
are? both client and server sides of Squid.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From erdosain9 at gmail.com  Thu Sep 29 21:02:46 2016
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 29 Sep 2016 14:02:46 -0700 (PDT)
Subject: [squid-users] Kerberos Ne
In-Reply-To: <b037432c-b371-d721-8f21-eb9c78d8685b@treenet.co.nz>
References: <1475071362112-4679740.post@n4.nabble.com>
 <b037432c-b371-d721-8f21-eb9c78d8685b@treenet.co.nz>
Message-ID: <1475182966034-4679774.post@n4.nabble.com>

Hi.
yes, i see this now.

it's strange... authentication is working fine... i can surf the web... but
im having some error in cache.log...

tail -f /var/log/squid/cache.log
2016/09/29 15:43:37 kid1| Adding nameserver 192.168.1.10 from squid.conf
2016/09/29 15:43:37 kid1| Adding nameserver 192.168.1.6 from squid.conf
2016/09/29 15:43:37 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
processes
2016/09/29 15:43:37 kid1| helperOpenServers: Starting 0/10
'negotiate_kerberos_auth' processes
2016/09/29 15:43:37 kid1| helperStatefulOpenServers: No
'negotiate_kerberos_auth' processes needed.
2016/09/29 15:43:37 kid1| helperOpenServers: Starting 5/5
'ext_kerberos_ldap_group_acl' processes
2016/09/29 15:43:38 kid1| helperOpenServers: Starting 5/5
'ext_kerberos_ldap_group_acl' processes
2016/09/29 15:43:38 kid1| HTCP Disabled.
2016/09/29 15:43:38 kid1| Finished loading MIME types and icons.
2016/09/29 15:43:38 kid1| Accepting SSL bumped HTTP Socket connections at
local=192.168.1.12:3128 remote=[::] FD 49 flags=9
2016/09/29 15:44:15 kid1| Starting new negotiateauthenticator helpers...
2016/09/29 15:44:15 kid1| helperOpenServers: Starting 1/10
'negotiate_kerberos_auth' processes
support_krb5.cc(64): pid=11755 :2016/09/29 15:44:15| kerberos_ldap_group:
ERROR: Error while initialising credentials from keytab : Preauthentication
failed
support_krb5.cc(64): pid=11755 :2016/09/29 15:44:15| kerberos_ldap_group:
ERROR: Error while initialising credentials from keytab : Preauthentication
failed
support_krb5.cc(64): pid=11755 :2016/09/29 15:44:15| kerberos_ldap_group:
ERROR: Error while initialising credentials from keytab : Preauthentication
failed
2016/09/29 15:44:27 kid1| Starting new negotiateauthenticator helpers...
2016/09/29 15:44:27 kid1| helperOpenServers: Starting 1/10
'negotiate_kerberos_auth' processes
2016/09/29 15:44:27 kid1| Starting new negotiateauthenticator helpers...
2016/09/29 15:44:27 kid1| helperOpenServers: Starting 1/10
'negotiate_kerberos_auth' processes
2016/09/29 15:44:27 kid1| Starting new negotiateauthenticator helpers...
2016/09/29 15:44:27 kid1| helperOpenServers: Starting 1/10
'negotiate_kerberos_auth' processes
2016/09/29 15:44:27 kid1| Starting new negotiateauthenticator helpers...
2016/09/29 15:44:27 kid1| helperOpenServers: Starting 1/10
'negotiate_kerberos_auth' processes
2016/09/29 15:44:27 kid1| Starting new negotiateauthenticator helpers...
2016/09/29 15:44:27 kid1| helperOpenServers: Starting 1/10
'negotiate_kerberos_auth' processes
2016/09/29 15:44:27 kid1| Starting new negotiateauthenticator helpers...
2016/09/29 15:44:27 kid1| helperOpenServers: Starting 1/10
'negotiate_kerberos_auth' processes
support_krb5.cc(64): pid=11760 :2016/09/29 15:45:03| kerberos_ldap_group:
ERROR: Error while initialising credentials from keytab : Preauthentication
failed
support_krb5.cc(64): pid=11760 :2016/09/29 15:45:03| kerberos_ldap_group:
ERROR: Error while initialising credentials from keytab : Preauthentication
failed
support_krb5.cc(64): pid=11760 :2016/09/29 15:45:03| kerberos_ldap_group:
ERROR: Error while initialising credentials from keytab : Preauthentication
failed


This is access.log

1475174886.981     23 192.168.1.121 TCP_MEM_HIT/200 3993 GET
http://images.clarin.com/deportes/Boca-Lanus_CLAVID20160928_0082_32.jpg
user1 at EXAMPLE.LAN HIER_NONE/- image/jpeg
1475174886.994     41 192.168.1.121 TCP_MEM_HIT/200 4601 GET
http://images.clarin.com/deportes/penales-dieron-triunfo-Boca_CLAVID20160928_0085_32.jpg
user1 at EXAMPLE.LAN HIER_NONE/- image/jpeg
1475174887.124    148 192.168.1.121 TCP_MISS/200 19321 GET
http://images.clarin.com/politica/Bonafini-Cesar-Milani-Asociacon-Madres_CLAIMA20160622_0266_47.jpg
user1 at EXAMPLE.LAN HIER_DIRECT/200.42.136.212 image/jpeg
1475174887.139    182 192.168.1.121 TCP_MISS/200 4389 GET
http://images.clarin.com/extrashow/Cristian-Castro-winner_CLAVID20160929_0011_32.jpg
user1 at EXAMPLE.LAN HIER_DIRECT/200.42.136.212 image/jpeg
1475174887.280    288 192.168.1.121 TCP_MISS/200 20143 GET
http://images.clarin.com/politica/Macri-Tecnopolis-presentar-proyectos-emprendedores_CLAIMA20160821_0007_44.jpg
user1 at EXAMPLE.LAN HIER_DIRECT/200.42.136.212 image/jpeg
1475174887.340    163 192.168.1.121 TCP_MISS/200 5715 GET
http://images.clarin.com/mundo/herida-choque-Nueva-Jersey-AFP_CLAIMA20160929_0106_44.jpg
user1 at EXAMPLE.LAN HIER_DIRECT/200.42.136.212 image/jpeg
1475174887.369    411 192.168.1.121 TCP_MISS/200 29566 GET
http://images.clarin.com/policiales/jefatura-departamental-frente-edificios-publicos_CLAIMA20160408_0426_50.jpg
user1 at EXAMPLE.LAN HIER_DIRECT/200.42.136.212 image/jpeg
1475174887.388     95 192.168.1.121 TCP_MISS/200 5185 GET
http://images.clarin.com/mundo/Hoboken-edificios-Nueva-York-AP_CLAIMA20160929_0127_45.jpg
user1 at EXAMPLE.LAN HIER_DIRECT/200.42.136.212 image/jpeg
1475174888.099   1141 192.168.1.121 TCP_MISS/200 20771 GET
http://images.clarin.com/politica/Reunion-CGT-Gobierno-Foto-DyN_CLAIMA20160929_0102_43.jpg
user1 at EXAMPLE.LAN HIER_DIRECT/200.42.136.212 image/jpeg
1475174888.099    963 192.168.1.121 TCP_MISS/200 4238 GET
http://images.clarin.com/politica/Sanfelice-Cristobal-Kirchner-Gallegos-OPI_CLAIMA20160211_0039_49.jpg
user1 at EXAMPLE.LAN HIER_DIRECT/200.42.136.212 image/jpeg
1475174888.099    682 192.168.1.121 TCP_MISS/200 5958 GET
http://images.clarin.com/politica/Camano-Diputados-Guillermo-Rodriguez-Adami_CLAIMA20160929_0033_44.jpg
user1 at EXAMPLE.LAN HIER_DIRECT/200.42.136.212 image/jpeg
1475174888.099    722 192.168.1.121 TCP_MISS/200 16558 GET
http://images.clarin.com/politica/Amado-Boudou-clase-magistral-Plata_CLAIMA20160929_0153_43.jpg
user1 at EXAMPLE.LAN HIER_DIRECT/200.42.136.212 image/jpeg
1475174888.099   1141 192.168.1.121 TCP_MISS/200 16419 GET
http://www.googletagmanager.com/gtm.js? user1 at EXAMPLE.LAN
HIER_DIRECT/216.58.222.136 application/javascript
1475174888.099    740 192.168.1.121 TCP_MISS/200 25190 GET
http://images.clarin.com/mundo/Nueva-Jersey-Tren-estacion-AFP_CLAIMA20160929_0074_46.jpg
user1 at EXAMPLE.LAN HIER_DIRECT/200.42.136.212 image/jpeg
1475174888.247      0 192.168.1.121 TCP_DENIED/407 4159 CONNECT
connect.facebook.net:443 - HIER_NONE/- text/html
1475174888.247      0 192.168.1.121 TCP_DENIED/403 4347 GET
http://www.googleadservices.com/pagead/conversion_async.js - HIER_NONE/-
text/html
1475174888.333   2428 192.168.1.121 TCP_MISS/200 46659 GET
https://cdns.gigya.com/JS/socialize.js? user1 at EXAMPLE.LAN
HIER_DIRECT/23.7.114.199 text/javascript
1475174888.461      0 192.168.1.121 TCP_DENIED/407 4135 CONNECT
api.cxense.com:443 - HIER_NONE/- text/html
1475174888.462      0 192.168.1.121 TCP_DENIED/407 4798 GET
http://fonts.gstatic.com/s/roboto/v15/d-6IYplOFocCacKzxwXSOFtXRa8TVwTICgirnJhmVJw.woff2
- HIER_NONE/- text/html
1475174888.462      1 192.168.1.121 TCP_MEM_HIT/200 20022 GET
http://www.clarin.com/static/CLAClarinV3/images/spriteHeaderFooter.png
user1 at EXAMPLE.LAN HIER_NONE/- image/png
1475174888.475      6 192.168.1.121 TCP_HIT/200 15166 GET
http://fonts.gstatic.com/s/roboto/v15/d-6IYplOFocCacKzxwXSOFtXRa8TVwTICgirnJhmVJw.woff2
user1 at EXAMPLE.LAN HIER_NONE/- font/woff2
1475174888.514      0 192.168.1.121 TCP_DENIED/407 4135 CONNECT
cdns.gigya.com:443 - HIER_NONE/- text/html
1475174888.551      0 192.168.1.121 TCP_MEM_HIT/200 1555 GET
http://www.clarin.com/static/CLAClarinV3/images/nav-buscador.png
user1 at EXAMPLE.LAN HIER_NONE/- image/png
1475174888.554      0 192.168.1.121 TCP_MEM_HIT/200 1623 GET
http://www.clarin.com/static/CLAClarinV3/images/nav-str.png
user1 at EXAMPLE.LAN HIER_NONE/- image/png
1475174888.604      0 192.168.1.121 TCP_DENIED/407 4810 GET
http://fonts.gstatic.com/s/droidserif/v6/QQt14e8dY39u-eYBZmppwYlIZu-HDpmDIZMigmsroc4.woff2
- HIER_NONE/- text/html
1475174888.611      0 192.168.1.121 TCP_MEM_HIT/200 764 GET
http://www.clarin.com/static/CLAClarinV3/images/flash-list.png
user1 at EXAMPLE.LAN HIER_NONE/- image/png
1475174888.613      7 192.168.1.121 TCP_HIT/200 26762 GET
http://fonts.gstatic.com/s/droidserif/v6/QQt14e8dY39u-eYBZmppwYlIZu-HDpmDIZMigmsroc4.woff2
user1 at EXAMPLE.LAN HIER_NONE/- font/woff2
1475174888.615      0 192.168.1.121 TCP_MEM_HIT/200 20344 GET
http://www.clarin.com/static/CLAClarinV3/images/spriteNoticias.png
user1 at EXAMPLE.LAN HIER_NONE/- image/png
1475174888.686      0 192.168.1.121 TCP_HIT/200 706 GET
http://www.clarin.com/static/CLAClarinV3/images/colR.gif user1 at EXAMPLE.LAN
HIER_NONE/- image/gif
1475174888.687      0 192.168.1.121 TCP_HIT/200 23254 GET
http://fonts.gstatic.com/s/droidserif/v6/0AKsP294HTD-nvJgucYTaI4P5ICox8Kq3LLUNMylGO4.woff2
user1 at EXAMPLE.LAN HIER_NONE/- font/woff2
1475174888.696      0 192.168.1.121 TCP_HIT/200 15153 GET
http://fonts.gstatic.com/s/roboto/v15/mnpfi9pxYH-Go5UiibESIltXRa8TVwTICgirnJhmVJw.woff2
user1 at EXAMPLE.LAN HIER_NONE/- font/woff2


Myconfig
------------------------

###Kerberos Auth with ActiveDirectory###
auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -s
HTTP/squid.example.lan at EXAMPLE.LAN
auth_param negotiate children 10
auth_param negotiate keep_alive on


external_acl_type i-limitado ttl=300 negative_ttl=60 %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -g i-limitado at EXAMPLE.LAN
external_acl_type i-full ttl=300 negative_ttl=60 %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -g i-full at EXAMPLE.LAN


#GRUPOS
acl i-limitado external i-limitado
acl i-full external i-full

i dont understand... why "kerberos_ldap_group: ERROR: Error while
initialising credentials from keytab : Preauthentication failed", if i can
surf the web, SSO is working, and in access.log i can see the user, etc.
then, in practice, no error is perceived.
but I have this log ...




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Kerberos-appropriate-log-file-tp4679740p4679774.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From darren.j.breeze.ml at gmail.com  Thu Sep 29 21:29:12 2016
From: darren.j.breeze.ml at gmail.com (Darren)
Date: Fri, 30 Sep 2016 05:29:12 +0800
Subject: [squid-users] Large text ACL lists
In-Reply-To: <895f4c0a-643a-924d-ede9-af457c8c3e32@squidblacklist.org>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <895f4c0a-643a-924d-ede9-af457c8c3e32@squidblacklist.org>
Message-ID: <975b517e-9748-4396-b3bb-e7c3aed48429@getmailbird.com>

Hi

What I am trying to do is to simplify everything and remove the external re-writers from the workflow due to the fact that they are either old with sporadic development or wrap their own lists into the solution.

I am also producing my own ACL lists for this project so third party blacklists will not work for me.?

Squid has a lot more smarts and is very active in development so I think it would be a more complete robust solution if I can get a handle on how it behaves when parsing large ACL files.

My ACL's will be stored on a Ram based drive so speed there should not be an issue.

Looking at the config samples at squidblackist.org, you seem to pump massive ACL lists through the dstdomain acl so maybe that is anecdotal evidence that this will work OK.

Darren B.


Sent from Mailbird [http://www.getmailbird.com/?utm_source=Mailbird&amp;utm_medium=email&amp;utm_campaign=sent-from-mailbird]
On 30/09/2016 1:43:33 AM, Benjamin E. Nichols <webmaster at squidblacklist.org> wrote:
The other issue is that shalla and urlblacklist produce garbage blacklists, and neither of them are actively developing or improving the backend technology required to product high quality blacklists.
We are the leading publisher of blacklists tailored for Web Filtering Purposes.

We are also the only commercial source for Squid Native ACL. Yes, we have it.


On 9/29/2016 4:44 AM, Darren wrote:

Hi All

I have been tinkering with Squidguard for a while, using it to manage ACL lists and time limits etc.

While it works OK, it's not in active development and has it's issues.

What are the limitations with just pumping ACL lists directly into Squid and letting it do all the work internally without running a team of squidguards?

how efficient is squid now at parsing the text files directly, will i Need more ram as the list grows? Is it slower or are their optimizations that I can do?

thanks all

Darren Breeze





Sent from Mailbird [http://www.getmailbird.com/?utm_source=Mailbird&amp;utm_medium=email&amp;utm_campaign=sent-from-mailbird]


_______________________________________________ squid-users mailing list squid-users at lists.squid-cache.org [mailto:squid-users at lists.squid-cache.org] http://lists.squid-cache.org/listinfo/squid-users [http://lists.squid-cache.org/listinfo/squid-users]

-- -- Signed, Benjamin E. Nichols http://www.squidblacklist.org [http://www.squidblacklist.org] 1-405-397-1360 - Call Anytime.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/cd008061/attachment.htm>

From webmaster at squidblacklist.org  Thu Sep 29 21:42:04 2016
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Thu, 29 Sep 2016 16:42:04 -0500
Subject: [squid-users] Large text ACL lists
In-Reply-To: <975b517e-9748-4396-b3bb-e7c3aed48429@getmailbird.com>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <895f4c0a-643a-924d-ede9-af457c8c3e32@squidblacklist.org>
 <975b517e-9748-4396-b3bb-e7c3aed48429@getmailbird.com>
Message-ID: <0ba579ee-73e5-9434-25f3-04b13001bc91@squidblacklist.org>

Well, forgive me for bad mouthing the developers here, but I think this 
is a good reason.

You see, you are going to have to eliminate all the redundant subdomains 
in your blacklists, because they are going to crash modern versions of 
squid. And to do this I would recommend using an older version of Squid 
for your blacklist validation purposes, because, a few years ago, The 
developers decided it was a good idea to stop throwing errors in the 
logs when there is a duplicate entry in the blacklists, you know, the 
way squid used to be, I have no idea who is smoking hashish over there 
and making these idiotic decisions, because clearly, it would be better 
to actually have something in your error log indicating where the 
problem is, rather than just having squid shit on itself and have zero 
indication of how or why it happened, but again, the hashish must be 
cheap because the latest versions of squid will do just that, shit on 
themselves and give you zero indication of why or where the problems in 
your acl lists are.

And yes Squid Native ACL Blacklisting does work, but we are also, unlike 
the competitors, actually removing dead domains daily, to minimize 
wasteful bulk, in other words, we are actually doing our job rather than 
just boasting about line counts with 50% dead domains that really should 
be removed to make the list size the most efficient.

We also offer the lists in other various formats to ensure maximum 
compatibility.
I would love to share thoughts with you regarding the matter.


On 9/29/2016 4:29 PM, Darren wrote:
> Hi
>
> What I am trying to do is to simplify everything and remove the 
> external re-writers from the workflow due to the fact that they are 
> either old with sporadic development or wrap their own lists into the 
> solution.
>
> I am also producing my own ACL lists for this project so third party 
> blacklists will not work for me.
>
> Squid has a lot more smarts and is very active in development so I 
> think it would be a more complete robust solution if I can get a 
> handle on how it behaves when parsing large ACL files.
>
> My ACL's will be stored on a Ram based drive so speed there should not 
> be an issue.
>
> Looking at the config samples at squidblackist.org, you seem to pump 
> massive ACL lists through the dstdomain acl so maybe that is anecdotal 
> evidence that this will work OK.
>
> Darren B.
>
> Sent from Mailbird 
> <http://www.getmailbird.com/?utm_source=Mailbird&utm_medium=email&utm_campaign=sent-from-mailbird>
>>
>> On 30/09/2016 1:43:33 AM, Benjamin E. Nichols 
>> <webmaster at squidblacklist.org> wrote:
>>
>> The other issue is that shalla and urlblacklist produce garbage 
>> blacklists, and neither of them are actively developing or improving 
>> the backend technology required to product high quality blacklists.
>>
>> We are the leading publisher of blacklists tailored for Web Filtering 
>> Purposes.
>>
>> We are also the only commercial source for Squid Native ACL. Yes, we 
>> have it.
>>
>>
>> On 9/29/2016 4:44 AM, Darren wrote:
>>> Hi All
>>>
>>> I have been tinkering with Squidguard for a while, using it to 
>>> manage ACL lists and time limits etc.
>>>
>>> While it works OK, it's not in active development and has it's issues.
>>>
>>> What are the limitations with just pumping ACL lists directly into 
>>> Squid and letting it do all the work internally without running a 
>>> team of squidguards?
>>>
>>> how efficient is squid now at parsing the text files directly, will 
>>> i Need more ram as the list grows? Is it slower or are their 
>>> optimizations that I can do?
>>>
>>> thanks all
>>>
>>> Darren Breeze
>>>
>>>
>>>
>>>
>>>
>>> Sent from Mailbird 
>>> <http://www.getmailbird.com/?utm_source=Mailbird&utm_medium=email&utm_campaign=sent-from-mailbird>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> -- 
>> --
>>
>> Signed,
>>
>> Benjamin E. Nichols
>> http://www.squidblacklist.org
>>
>> 1-405-397-1360 - Call Anytime.

-- 
--

Signed,

Benjamin E. Nichols
http://www.squidblacklist.org

1-405-397-1360 - Call Anytime.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160929/c7a3ad2e/attachment.htm>

From eliezer at ngtech.co.il  Thu Sep 29 22:23:22 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 30 Sep 2016 01:23:22 +0300
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
	code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <414102480.6739156.1475150556309@mail.yahoo.com>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
Message-ID: <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>

Hey Vieri,

Just as a tiny reply I must admit that it's expected.
What you see is the result of squid and it's ssl stack support the goal of a minimum specific version of ssl encrypted connections.
I am not sure but there might be  a way to make it all work for these clients.
Have you tried search the squid-cache lists using google\yahoo\bing\other?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Vieri
Sent: Thursday, September 29, 2016 3:03 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] squid tproxy ssl-bump and Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)

Hi,

I'm running a Squid proxy like so:

http_port 3129 tproxy
https_port 3130 tproxy ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=16MB cert=/etc/ssl/squid/proxyserver.pem

The squid server certificate was self-generated:
openssl req -new -newkey rsa:2048 -sha256 -days 7300 -nodes -x509 -keyout /etc/ssl/squid/proxyserver.pem -out /etc/ssl/squid/proxyserver.pem

I configured my firewall rules approriately and everything seems to work fine on systems such as Windows 7 32bits/64bits with IE11, IE8 or latest Firefox.
However, I'm having trouble with Windows XP Pro SP3 and IE8.
On this client OS, Firefox 45.0.1 works fine with HTTP and HTTPS sites. However, IE8 on this same client OS works fine accessing HTTP sites but not HTTPS.

When I try to access google.com I first get a certificate warning (untrusted cert). That's the first flaw because I shouldn't get this page since the proxy server's certificate is in the IE Trust Store (under root certificates).
Then if I try to connect to google.com despite the "untrusted certificate" warning, I get the exception:

71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE) Handshake with SSL server failed: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry

I noticed that this browser/OS only has TLS up to 1.0 (no 1.2 or 1.1).

I can reproduce the same Squid exception on a Windows 7 IE8 system if I disable TLS 1.2 and only use TLS 1.1 and/or lower.

Any ideas?

Regards,

Vieri
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Thu Sep 29 22:35:20 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 30 Sep 2016 01:35:20 +0300
Subject: [squid-users] External nat'ed transparent proxy
In-Reply-To: <9cb02f45-ad81-7d77-0d7a-cf313c34f4fd@nitronetworks.nl>
References: <9cb02f45-ad81-7d77-0d7a-cf313c34f4fd@nitronetworks.nl>
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAP1vRcAAnWlNoU7f4f0YNhgBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADQt4cUeAlsQ6ihb0bN4K2wAQAAAAA=@ngtech.co.il>

Hey Henry,

I want to emulate the setup to understand the complication with a FULL linux based setup here on my local testing grounds.
Can you give more details on the networks in the form of subnets and VLAN numbers?
What is not clear to me is: Who is doing the DNAT?
Also, if you have not used tproxy and intercept on the PROXY machine you should re-think the whole logic of the system first before deciding on the next step.
There are systems which needs redesign when moving from Squid 2 to 3 or 4.
When I and you will have the right understanding of the scenario I believe we can find the right path if this is not already there.

Let me know if these( the diagrams..):
http://wiki.squid-cache.org/EliezerCroitoru/Drafts/MwanLB#Intoduction_to_MultiWAN_LoadBalancing
http://wiki.squid-cache.org/ConfigExamples/UbuntuTproxy4Wccp2

Make any sense to you so we can find the right words to fill the gaps in the situation.
Once I will have the right picture I would probably have enough information to draw some picture in VISIO and move forward to the Systems table.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Henry Paulissen
Sent: Thursday, September 29, 2016 5:40 PM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] External nat'ed transparent proxy

Hi all,

In the company I work for we are currently using squid v2 proxies in transparent mode to intercept traffic from servers to the outside (access control).

The technical solution for this is roughly as follows:
[server] -> [gateway] -> [firewall]
                              |
    ----------- DNAT ---------
   v
[squid]  -> [gateway] -> [firewall] -> [internet router]

Our firewalls (who live between the vlan gateway and internet router), DNAT the traffic towards separate squid proxies (who are in a lvs cluster). These squid proxies are in their own vlan with special permissions to allow unrestricted port 80 outbound, etc, etc...

Because squid v2 is becoming more and more obsolete we are looking at upgrading it towards squid v3.

>From what I read in the manuals, transparent mode is replaced by intercept (and tproxy) mode. But both dont seem to be fully backward complaint with the v2 transparent mode.

The old trasparent mode allowed us to just dnat traffic towards the squid host without the need for the client to be aware of this. For example, the old style accepted 'GET / HTTP/1.1' (without full URL in the GET request and looking at the Host header for the destination).

The new intercept mode comes close to this behavior, but instead of remotly dnat, it wants us to next-hop it towards the squid proxy and redirect it locally. This is problematic for us as firewall and squid proxy dont live in the same vlan, so next-hop should be the router to that vlan (and forgetting about the path back to the server). Secondly, and not less blocking, we use vservers (predecessor to linux containers
lxc) as such, we dont have any promiscuous interfaces rights within the container.


Is there still a option to emulate normal 'regular? style squid (as without any listen options) but instead accepting the URI path in the GET request and looking at the Host header for the destination? (lets call it passthrough mode?).

Or, is there in squid3 a new and better way to facilitate larger setups, with the knowledge the server, firewall and squids are all in different vlans (and no, we dont have Cisco firewalls in between them ;-)).


Thanks in advance,

--
Henry Paulissen - PD0OM
henry at nitronetworks.nl - Phone: +31-(0)6-115.305.64 Linux/Unix System Engineer




From eliezer at ngtech.co.il  Thu Sep 29 22:45:10 2016
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 30 Sep 2016 01:45:10 +0300
Subject: [squid-users] --enable-openssl-crtd -- not
	building	openssl-crtd? (3.5.21)
In-Reply-To: <57E9EFBC.5040407@tlinx.org>
References: <57E9D3B5.6050405@tlinx.org>
 <598baad3-64d1-b873-b266-55ab5d96fb0c@treenet.co.nz>
 <57E9EFBC.5040407@tlinx.org>
Message-ID: <056b01d21aa3$22833020$67899060$@ngtech.co.il>

Hey Linda,

If you need some help later we are here for any advice.
Can you say on what OS are you compiling the software?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile+WhatsApp: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Linda W
Sent: Tuesday, September 27, 2016 7:04 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] --enable-openssl-crtd -- not building openssl-crtd? (3.5.21)

Amos Jeffries wrote:
> There is no such option. Never has been.
>
> ## ./configure --help | grep ssl
>
>   --enable-ssl-crtd       ...
>
>   --with-openssl=PATH     Compile with the OpenSSL libraries. ...
>   
----
Oops... Conflated the two... back to configuring...
tnx,
-l

>   
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Thu Sep 29 22:48:37 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 29 Sep 2016 16:48:37 -0600
Subject: [squid-users] Large text ACL lists
In-Reply-To: <0ba579ee-73e5-9434-25f3-04b13001bc91@squidblacklist.org>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <895f4c0a-643a-924d-ede9-af457c8c3e32@squidblacklist.org>
 <975b517e-9748-4396-b3bb-e7c3aed48429@getmailbird.com>
 <0ba579ee-73e5-9434-25f3-04b13001bc91@squidblacklist.org>
Message-ID: <5708ee9c-d0f2-03ba-ee2c-3077549e74b3@measurement-factory.com>

On 09/29/2016 03:42 PM, Benjamin E. Nichols wrote:
> Well, forgive me for bad mouthing the developers here, but I think this
> is a good reason.

It is not. Badmouthing, for any reason, has no positive side effects and
may have many negative ones.


> it would be better
> to actually have something in your error log indicating where the
> problem is, rather than just having squid shit on itself and have zero
> indication of how or why it happened

Please file a bug report with specifics if you have not already.


> but we are also, unlike the competitors, ...
> we are actually doing our job rather than ...

Please do your best to avoid disparaging competitors on this mailing
list, regardless of whether you think your comments are 100% accurate.
Many of the "blacklisting" posts (not just yours) are already in the
"advertisement" red zone, and with the attacks added, the Project would
have to police the mailing list. That would not be a good use of
volunteers time!


Thank you,

Alex.


> On 9/29/2016 4:29 PM, Darren wrote:
>> Hi
>>
>> What I am trying to do is to simplify everything and remove the
>> external re-writers from the workflow due to the fact that they are
>> either old with sporadic development or wrap their own lists into the
>> solution.
>>
>> I am also producing my own ACL lists for this project so third party
>> blacklists will not work for me. 
>>
>> Squid has a lot more smarts and is very active in development so I
>> think it would be a more complete robust solution if I can get a
>> handle on how it behaves when parsing large ACL files.
>>
>> My ACL's will be stored on a Ram based drive so speed there should not
>> be an issue.
>>
>> Looking at the config samples at squidblackist.org, you seem to pump
>> massive ACL lists through the dstdomain acl so maybe that is anecdotal
>> evidence that this will work OK.
>>
>> Darren B.
>>
>> Sent from Mailbird
>> <http://www.getmailbird.com/?utm_source=Mailbird&utm_medium=email&utm_campaign=sent-from-mailbird>
>>>
>>> On 30/09/2016 1:43:33 AM, Benjamin E. Nichols
>>> <webmaster at squidblacklist.org> wrote:
>>>
>>> The other issue is that shalla and urlblacklist produce garbage
>>> blacklists, and neither of them are actively developing or improving
>>> the backend technology required to product high quality blacklists.
>>>
>>> We are the leading publisher of blacklists tailored for Web Filtering
>>> Purposes.
>>>
>>> We are also the only commercial source for Squid Native ACL. Yes, we
>>> have it.
>>>
>>>
>>> On 9/29/2016 4:44 AM, Darren wrote:
>>>> Hi All
>>>>
>>>> I have been tinkering with Squidguard for a while, using it to
>>>> manage ACL lists and time limits etc.
>>>>
>>>> While it works OK, it's not in active development and has it's issues.
>>>>
>>>> What are the limitations with just pumping ACL lists directly into
>>>> Squid and letting it do all the work internally without running a
>>>> team of squidguards?
>>>>
>>>> how efficient is squid now at parsing the text files directly, will
>>>> i Need more ram as the list grows? Is it slower or are their
>>>> optimizations that I can do?
>>>>
>>>> thanks all
>>>>
>>>> Darren Breeze
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> Sent from Mailbird
>>>> <http://www.getmailbird.com/?utm_source=Mailbird&utm_medium=email&utm_campaign=sent-from-mailbird>
>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>> -- 
>>> --
>>>
>>> Signed,
>>>
>>> Benjamin E. Nichols
>>> http://www.squidblacklist.org
>>>
>>> 1-405-397-1360 - Call Anytime.
> 
> -- 
> --
> 
> Signed,
> 
> Benjamin E. Nichols
> http://www.squidblacklist.org
> 
> 1-405-397-1360 - Call Anytime.
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From michael.pelletier at palmbeachschools.org  Thu Sep 29 22:50:15 2016
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Thu, 29 Sep 2016 18:50:15 -0400
Subject: [squid-users] No matter what I do I can not get %ssl:>sni (or other
	%ssl) to log
Message-ID: <CAEnCSG5pRx93x45-RN98by-OR1D5TmimRhRrcj99+VTV5oUpzQ@mail.gmail.com>

Hello,

I am trying to log some data during the ssl flow. I have this for my
logformat
logformat custom %>a %>p %>lp %la %<la %<lp %<p %<a %tr %dt %st %>st %<st
%mt %[un %rm %>rd %>ru %>Hs %{Referer}>h [%{User-Agent}>h] [%{Host}>h]
%ssl::>sni %ssl::>cert_subject %ssl::>cert_issuer
sq_err:[%{X-Squid-Error}<h] c_hdr:[%>h] s_hdr:[%<h] %{Cat-Result}note
%{Cat}note %{Cat-Sub}note

Yet I get nothing from any of the %ssl:: entries....

Can someone help?

Michael

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160929/9338530f/attachment.htm>

From rousskov at measurement-factory.com  Thu Sep 29 23:01:27 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 29 Sep 2016 17:01:27 -0600
Subject: [squid-users] No matter what I do I can not get %ssl:>sni (or
 other %ssl) to log
In-Reply-To: <CAEnCSG5pRx93x45-RN98by-OR1D5TmimRhRrcj99+VTV5oUpzQ@mail.gmail.com>
References: <CAEnCSG5pRx93x45-RN98by-OR1D5TmimRhRrcj99+VTV5oUpzQ@mail.gmail.com>
Message-ID: <9d59d390-9c53-8b2a-9f14-11d89c545450@measurement-factory.com>

On 09/29/2016 04:50 PM, Michael Pelletier wrote:

> I am trying to log some data during the ssl flow.

> logformat custom ... %ssl::>sni %ssl::>cert_subject %ssl::>cert_issuer
> 
> Yet I get nothing from any of the %ssl:: entries....

Do your users send certificates to Squid? If not, %ssl::>cert_subject
%ssl::>cert_issuer should be "-". These %codes are _not_ about the
origin server certificate.

ssl::>sni is only available during certain SslBump steps. Do you use
SslBump? If yes, do you get the corresponding CONNECT entries in your
access log (there should be more than one CONNECT per SSL connection
IIRC)? What are your ssl_bump rules?

Alex.



From webmaster at squidblacklist.org  Thu Sep 29 23:04:22 2016
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Thu, 29 Sep 2016 18:04:22 -0500
Subject: [squid-users] Large text ACL lists
In-Reply-To: <5708ee9c-d0f2-03ba-ee2c-3077549e74b3@measurement-factory.com>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <895f4c0a-643a-924d-ede9-af457c8c3e32@squidblacklist.org>
 <975b517e-9748-4396-b3bb-e7c3aed48429@getmailbird.com>
 <0ba579ee-73e5-9434-25f3-04b13001bc91@squidblacklist.org>
 <5708ee9c-d0f2-03ba-ee2c-3077549e74b3@measurement-factory.com>
Message-ID: <032100b1-bd16-2fd7-337a-6aa726688be6@squidblacklist.org>

Dear Mr Alex Rousskov.

   Please kindly take your opinions, take them and shove them directly 
up your bloated arrogant ass. I have little need to cater to you, or to 
dignify your mindless criticism of my opinions, which only serve to 
demonstrate that your ego is larger than you are sir.


Signed,

Benjamin E. Nichols

http://www.squidblacklist.org



From michael.pelletier at palmbeachschools.org  Thu Sep 29 23:09:59 2016
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Thu, 29 Sep 2016 19:09:59 -0400
Subject: [squid-users] No matter what I do I can not get %ssl:>sni (or
 other %ssl) to log
In-Reply-To: <9d59d390-9c53-8b2a-9f14-11d89c545450@measurement-factory.com>
References: <CAEnCSG5pRx93x45-RN98by-OR1D5TmimRhRrcj99+VTV5oUpzQ@mail.gmail.com>
 <9d59d390-9c53-8b2a-9f14-11d89c545450@measurement-factory.com>
Message-ID: <CAEnCSG4MMezEOrNA0uXqZhi4EeEc9V+pU-rnu2aTp4HvfpAvZQ@mail.gmail.com>

I misspoke. I am getting %ssl::>sni but not %ssl::<cert_subject or
%ssl::<cert_issuer but then clients may not be sending certs out....

The doc says is supports server certs but using %ssl::>cert_subject and
%ssl::>cert_issuer. gives me a parse error....

Note the "<" instead of the ">"

On Thu, Sep 29, 2016 at 7:01 PM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 09/29/2016 04:50 PM, Michael Pelletier wrote:
>
> > I am trying to log some data during the ssl flow.
>
> > logformat custom ... %ssl::>sni %ssl::>cert_subject %ssl::>cert_issuer
> >
> > Yet I get nothing from any of the %ssl:: entries....
>
> Do your users send certificates to Squid? If not, %ssl::>cert_subject
> %ssl::>cert_issuer should be "-". These %codes are _not_ about the
> origin server certificate.
>
> ssl::>sni is only available during certain SslBump steps. Do you use
> SslBump? If yes, do you get the corresponding CONNECT entries in your
> access log (there should be more than one CONNECT per SSL connection
> IIRC)? What are your ssl_bump rules?
>
> Alex.
>
>

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160929/5b3df839/attachment.htm>

From michael.pelletier at palmbeachschools.org  Thu Sep 29 23:44:21 2016
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Thu, 29 Sep 2016 19:44:21 -0400
Subject: [squid-users] No matter what I do I can not get %ssl:>sni (or
 other %ssl) to log
In-Reply-To: <CAEnCSG4MMezEOrNA0uXqZhi4EeEc9V+pU-rnu2aTp4HvfpAvZQ@mail.gmail.com>
References: <CAEnCSG5pRx93x45-RN98by-OR1D5TmimRhRrcj99+VTV5oUpzQ@mail.gmail.com>
 <9d59d390-9c53-8b2a-9f14-11d89c545450@measurement-factory.com>
 <CAEnCSG4MMezEOrNA0uXqZhi4EeEc9V+pU-rnu2aTp4HvfpAvZQ@mail.gmail.com>
Message-ID: <CAEnCSG5_448kytKSzOGJ7zbWO_ptEinBV1-SN+FmMSn+ai37Jg@mail.gmail.com>

In the squid.conf.documented, it looks like I can log the server
certificate as well as the client certificate....

#         %ssl::>sni    SSL client SNI sent to
Squid

#         %ssl::<cert_subject SSL server certificate
DN

#         %ssl::<cert_issuer SSL server certificate issuer
DN

#

#         %>{Header}    HTTP request header "Header"

On Thu, Sep 29, 2016 at 7:09 PM, Michael Pelletier <
michael.pelletier at palmbeachschools.org> wrote:

> I misspoke. I am getting %ssl::>sni but not %ssl::<cert_subject or
> %ssl::<cert_issuer but then clients may not be sending certs out....
>
> The doc says is supports server certs but using %ssl::>cert_subject and
> %ssl::>cert_issuer. gives me a parse error....
>
> Note the "<" instead of the ">"
>
> On Thu, Sep 29, 2016 at 7:01 PM, Alex Rousskov <
> rousskov at measurement-factory.com> wrote:
>
>> On 09/29/2016 04:50 PM, Michael Pelletier wrote:
>>
>> > I am trying to log some data during the ssl flow.
>>
>> > logformat custom ... %ssl::>sni %ssl::>cert_subject %ssl::>cert_issuer
>> >
>> > Yet I get nothing from any of the %ssl:: entries....
>>
>> Do your users send certificates to Squid? If not, %ssl::>cert_subject
>> %ssl::>cert_issuer should be "-". These %codes are _not_ about the
>> origin server certificate.
>>
>> ssl::>sni is only available during certain SslBump steps. Do you use
>> SslBump? If yes, do you get the corresponding CONNECT entries in your
>> access log (there should be more than one CONNECT per SSL connection
>> IIRC)? What are your ssl_bump rules?
>>
>> Alex.
>>
>>
>

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160929/29394936/attachment.htm>

From rousskov at measurement-factory.com  Thu Sep 29 23:48:01 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 29 Sep 2016 17:48:01 -0600
Subject: [squid-users] No matter what I do I can not get %ssl:>sni (or
 other %ssl) to log
In-Reply-To: <CAEnCSG4MMezEOrNA0uXqZhi4EeEc9V+pU-rnu2aTp4HvfpAvZQ@mail.gmail.com>
References: <CAEnCSG5pRx93x45-RN98by-OR1D5TmimRhRrcj99+VTV5oUpzQ@mail.gmail.com>
 <9d59d390-9c53-8b2a-9f14-11d89c545450@measurement-factory.com>
 <CAEnCSG4MMezEOrNA0uXqZhi4EeEc9V+pU-rnu2aTp4HvfpAvZQ@mail.gmail.com>
Message-ID: <4ab6e5bd-d05a-3da8-2f64-188b6401df6e@measurement-factory.com>

On 09/29/2016 05:09 PM, Michael Pelletier wrote:

> The doc says is supports server certs

Which doc? I am reading squid.conf.documented in trunk/v4:

> ssl::>cert_subject
>                 The Subject field of the received client
>                 SSL certificate or a dash ('-')...
> 
> ssl::>cert_issuer
>                 The Issuer field of the received client
>                 SSL certificate or a dash ('-')...

which seems to refer to client certificates, as it should.

Alex.


> 
> On Thu, Sep 29, 2016 at 7:01 PM, Alex Rousskov
> <rousskov at measurement-factory.com
> <mailto:rousskov at measurement-factory.com>> wrote:
> 
>     On 09/29/2016 04:50 PM, Michael Pelletier wrote:
> 
>     > I am trying to log some data during the ssl flow.
> 
>     > logformat custom ... %ssl::>sni %ssl::>cert_subject %ssl::>cert_issuer
>     >
>     > Yet I get nothing from any of the %ssl:: entries....
> 
>     Do your users send certificates to Squid? If not, %ssl::>cert_subject
>     %ssl::>cert_issuer should be "-". These %codes are _not_ about the
>     origin server certificate.
> 
>     ssl::>sni is only available during certain SslBump steps. Do you use
>     SslBump? If yes, do you get the corresponding CONNECT entries in your
>     access log (there should be more than one CONNECT per SSL connection
>     IIRC)? What are your ssl_bump rules?
> 
>     Alex.
> 
> 
> 
> *Disclaimer: *Under Florida law, e-mail addresses are public records. If
> you do not want your e-mail address released in response to a public
> records request, do not send electronic mail to this entity. Instead,
> contact this office by phone or in writing.
> 



From rousskov at measurement-factory.com  Thu Sep 29 23:55:48 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 29 Sep 2016 17:55:48 -0600
Subject: [squid-users] No matter what I do I can not get %ssl:>sni (or
 other %ssl) to log
In-Reply-To: <CAEnCSG5_448kytKSzOGJ7zbWO_ptEinBV1-SN+FmMSn+ai37Jg@mail.gmail.com>
References: <CAEnCSG5pRx93x45-RN98by-OR1D5TmimRhRrcj99+VTV5oUpzQ@mail.gmail.com>
 <9d59d390-9c53-8b2a-9f14-11d89c545450@measurement-factory.com>
 <CAEnCSG4MMezEOrNA0uXqZhi4EeEc9V+pU-rnu2aTp4HvfpAvZQ@mail.gmail.com>
 <CAEnCSG5_448kytKSzOGJ7zbWO_ptEinBV1-SN+FmMSn+ai37Jg@mail.gmail.com>
Message-ID: <7d4fdc9a-a665-284d-40d6-dc7b2ca20725@measurement-factory.com>

On 09/29/2016 05:44 PM, Michael Pelletier wrote:
> In the squid.conf.documented, it looks like I can log the server
> certificate as well as the client certificate....
> 
> #         %ssl::<cert_subject SSL server certificate DN
> #         %ssl::<cert_issuer SSL server certificate issuer DN                                                                              

Wrong directive? The above %codes were for the external_acl_type
context, not logformat IIRC.

I do not know whether they are still supported in v4 but no longer
documented (which would be a [documentation] bug) or not supported at
all (which would be a [regression] bug).

Alex.


> On Thu, Sep 29, 2016 at 7:09 PM, Michael Pelletier wrote:
> 
>     I misspoke. I am getting %ssl::>sni but not %ssl::<cert_subject or
>     %ssl::<cert_issuer but then clients may not be sending certs out....
> 
>     The doc says is supports server certs but using %ssl::>cert_subject
>     and %ssl::>cert_issuer. gives me a parse error....
> 
>     Note the "<" instead of the ">"
> 
>     On Thu, Sep 29, 2016 at 7:01 PM, Alex Rousskov
>     <rousskov at measurement-factory.com
>     <mailto:rousskov at measurement-factory.com>> wrote:
> 
>         On 09/29/2016 04:50 PM, Michael Pelletier wrote:
> 
>         > I am trying to log some data during the ssl flow.
> 
>         > logformat custom ... %ssl::>sni %ssl::>cert_subject
>         %ssl::>cert_issuer
>         >
>         > Yet I get nothing from any of the %ssl:: entries....
> 
>         Do your users send certificates to Squid? If not,
>         %ssl::>cert_subject
>         %ssl::>cert_issuer should be "-". These %codes are _not_ about the
>         origin server certificate.
> 
>         ssl::>sni is only available during certain SslBump steps. Do you use
>         SslBump? If yes, do you get the corresponding CONNECT entries in
>         your
>         access log (there should be more than one CONNECT per SSL connection
>         IIRC)? What are your ssl_bump rules?
> 
>         Alex.
> 
> 
> 
> 
> *Disclaimer: *Under Florida law, e-mail addresses are public records. If
> you do not want your e-mail address released in response to a public
> records request, do not send electronic mail to this entity. Instead,
> contact this office by phone or in writing.
> 



From squid3 at treenet.co.nz  Fri Sep 30 02:04:04 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Sep 2016 15:04:04 +1300
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
 code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
Message-ID: <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>

On 30/09/2016 11:23 a.m., Eliezer Croitoru wrote:
> Hey Vieri,
> 
> Just as a tiny reply I must admit that it's expected.
> What you see is the result of squid and it's ssl stack support the goal of a minimum specific version of ssl encrypted connections.
> I am not sure but there might be  a way to make it all work for these clients.
> Have you tried search the squid-cache lists using google\yahoo\bing\other?

Small correction. It is the "Handshake with SSL server failed" (note
"server"). After several years of ciphers and SSLv2/v3 protocol things
being found to be badly insecure and removed from browser and servers
all over the place. It is indeed expected.

Firefox works because Mozilla have their own SSL/TLS library built into
the browser with modern capabilities. IE uses the WinXP one which is no
longer compatible with most of the Internet servers.

Squid mimics the client details when contacting the server. So you would
get the same problem (though maybe different description) if going
directly without the proxy.

To get around this you require the latest Squid version (with
peek-and-splice feature) doing the "bump" action on these clients
traffic so that it can upgrade the TLS/SSL handshake and use some
ciphers etc the server will accept on their connections.

Amos



From squid3 at treenet.co.nz  Fri Sep 30 02:29:36 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Sep 2016 15:29:36 +1300
Subject: [squid-users] External nat'ed transparent proxy
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAP1vRcAAnWlNoU7f4f0YNhgBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADQt4cUeAlsQ6ihb0bN4K2wAQAAAAA=@ngtech.co.il>
References: <9cb02f45-ad81-7d77-0d7a-cf313c34f4fd@nitronetworks.nl>
 <!&!AAAAAAAAAAAuAAAAAAAAAP1vRcAAnWlNoU7f4f0YNhgBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADQt4cUeAlsQ6ihb0bN4K2wAQAAAAA=@ngtech.co.il>
Message-ID: <deafc1e1-ab42-2921-ce89-3fdeb2bdf772@treenet.co.nz>

On 30/09/2016 11:35 a.m., Eliezer Croitoru wrote:
> Hey Henry,
> 
> I want to emulate the setup to understand the complication with a FULL linux based setup here on my local testing grounds.

No need Eliezer. This is the basic NAT re-writing problem.

> Can you give more details on the networks in the form of subnets and VLAN numbers?
> What is not clear to me is: Who is doing the DNAT?

The firewall *outside* the Squid machine.

> 
> -----Original Message-----
> From: Henry Paulissen
> 
> Hi all,
> 
> In the company I work for we are currently using squid v2 proxies in
> transparent mode to intercept traffic from servers to the outside
> (access control).
>
> The technical solution for this is roughly as follows:
> [server] -> [gateway] -> [firewall]
>                               |
>     ----------- DNAT ---------
>    v
> [squid]  -> [gateway] -> [firewall] -> [internet router]
> 
> Our firewalls (who live between the vlan gateway and internet
> router), DNAT the traffic towards separate squid proxies (who are in
> a lvs cluster). These squid proxies are in their own vlan with
> special permissions to allow unrestricted port 80 outbound, etc,
> etc...
> 
> Because squid v2 is becoming more and more obsolete we are looking
> at upgrading it towards squid v3.
> 
> From what I read in the manuals, transparent mode is replaced by 
> intercept (and tproxy) mode. But both dont seem to be fully backward 
> complaint with the v2 transparent mode.
> 
> The old trasparent mode allowed us to just dnat traffic towards the 
> squid host without the need for the client to be aware of this. For 
> example, the old style accepted 'GET / HTTP/1.1' (without full URL
> in the GET request and looking at the Host header for the
> destination).

Sadly. That is incorrect.

Squid-2 used to simply lie to you, silently hiding any attacks that were
happening through the proxy. Whenever NAT on the Squid machine failed to
identify the packet destination it gave Squid false information for the
logs based on the client-supplied Host header DNS results.

> 
> The new intercept mode comes close to this behavior, but instead of 
> remotly dnat, it wants us to next-hop it towards the squid proxy and 
> redirect it locally. This is problematic for us as firewall and
> squid proxy dont live in the same vlan, so next-hop should be the
> router to that vlan (and forgetting about the path back to the
> server). Secondly, and not less blocking, we use vservers
> (predecessor to linux containers lxc) as such, we dont have any
> promiscuous interfaces rights within the container.

Sorry. That is a requirement nowdays. Browser offer a full XHR or Flash
networking stack for use by remotely supplied (ie attacker supplied)
code that can forge requests so we cannot trust the client delivered
Host headers anymore.
NP: This actually makes Squid behave more "transparent" than ever
before, since it now preserves the destination IP.

You have a couple of options;

1) tunneling the packets from the machine which used to do NAT through
to the Squid machine. WCCP, IP-over-IP, GRE, etc.

 The NAT you used to have was just a way to tunnel the packets through
the DMZ subnet to Squid anyway. So this is conceptually no different to
what you have now. The issues which you might associate with tunnels
were already happening, just hidden by the NAT.


2) route the packets from the internal gateway to the squid machine as
if it were another gateway. Conceptually Squid *is* being a gateway for
port 80 traffic.

There are a couple of routing designs detailed at
<http://wiki.squid-cache.org/ConfigExamples/Intercept/IptablesPolicyRoute>
for setting that up if your gateway machine uses iptables. You might be
able to find equivalent documentation for other OS if you need.

Or you might design your own routing methods. The key thing is that the
destination IP:port numbers cannot be changed on the TCP packets between
the client and Squid.

Amos



From squid3 at treenet.co.nz  Fri Sep 30 02:41:57 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Sep 2016 15:41:57 +1300
Subject: [squid-users] Large text ACL lists
In-Reply-To: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
Message-ID: <2c1e0a65-e688-183f-b83e-4fbbfa6d4539@treenet.co.nz>

On 29/09/2016 10:44 p.m., Darren wrote:
> Hi All
> 
> I have been tinkering with Squidguard for a while, using it to manage
> ACL lists and time limits etc.
> 
> While it works OK, it's not in active development and has it's
> issues.
> 
> What are the limitations with just pumping ACL lists directly into
> Squid and letting it do all the work internally without running a
> team of squidguards?

CPU mostly. The helpers will use Nx the RAM for N helpers, so Squid
technically uses less that way. But since Squid workers are internally
single-threaded the CPU time takes from the processing of things through
the lists does slow down the workers handling other transactions. There
is also the time on startup for loading the data into memory. With big
data lists both of those differences can be noticable.

There are some RAM differences purely due to the storage formats. We
have not particularly optimized Squid ACLs recently for large data sets.

> 
> how efficient is squid now at parsing the text files directly, will i
> Need more ram as the list grows? Is it slower or are their
> optimizations that I can do?
> 

You will. Regardless of whether you use a helper or Squid.

Optimizations center around reducing the list sizes, removing
duplication, overlaps and dead entries.

For regex ACLs compacting the patterns down helps a lot. Squid will do
that itself now but is not very smart about it, so manual optimizations
still can have big impact.


Amos



From squid3 at treenet.co.nz  Fri Sep 30 03:04:36 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Sep 2016 16:04:36 +1300
Subject: [squid-users] Large text ACL lists
In-Reply-To: <032100b1-bd16-2fd7-337a-6aa726688be6@squidblacklist.org>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <895f4c0a-643a-924d-ede9-af457c8c3e32@squidblacklist.org>
 <975b517e-9748-4396-b3bb-e7c3aed48429@getmailbird.com>
 <0ba579ee-73e5-9434-25f3-04b13001bc91@squidblacklist.org>
 <5708ee9c-d0f2-03ba-ee2c-3077549e74b3@measurement-factory.com>
 <032100b1-bd16-2fd7-337a-6aa726688be6@squidblacklist.org>
Message-ID: <dd2ab572-7ca1-a65a-b036-acdc3a620cda@treenet.co.nz>

<snip>

That is more than enough please.

Some people on this list are competitors. There will necessarily be
private issues between people and/or organisations.

And that is exactly where those issues should stay. Private. It benefits
us all to interact politely on the list(s) no matter what is going on in
the background.

What gets written here is on permanent public record and might come back
to bite later in life.


If you have problems with how Squid code decisions are going, please
join in over at squid-dev. Or if you just want to join in. We could do
with more interested people.


Amos Jeffries
The Squid Software Foundation



From squid3 at treenet.co.nz  Fri Sep 30 03:12:03 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Sep 2016 16:12:03 +1300
Subject: [squid-users] No matter what I do I can not get %ssl:>sni (or
 other %ssl) to log
In-Reply-To: <7d4fdc9a-a665-284d-40d6-dc7b2ca20725@measurement-factory.com>
References: <CAEnCSG5pRx93x45-RN98by-OR1D5TmimRhRrcj99+VTV5oUpzQ@mail.gmail.com>
 <9d59d390-9c53-8b2a-9f14-11d89c545450@measurement-factory.com>
 <CAEnCSG4MMezEOrNA0uXqZhi4EeEc9V+pU-rnu2aTp4HvfpAvZQ@mail.gmail.com>
 <CAEnCSG5_448kytKSzOGJ7zbWO_ptEinBV1-SN+FmMSn+ai37Jg@mail.gmail.com>
 <7d4fdc9a-a665-284d-40d6-dc7b2ca20725@measurement-factory.com>
Message-ID: <e89aee4f-51c4-b689-9185-bbebcc9ccc05@treenet.co.nz>

On 30/09/2016 12:55 p.m., Alex Rousskov wrote:
> On 09/29/2016 05:44 PM, Michael Pelletier wrote:
>> In the squid.conf.documented, it looks like I can log the server
>> certificate as well as the client certificate....
>>
>> #         %ssl::<cert_subject SSL server certificate DN
>> #         %ssl::<cert_issuer SSL server certificate issuer DN                                                                              
> 
> Wrong directive? The above %codes were for the external_acl_type
> context, not logformat IIRC.
> 
> I do not know whether they are still supported in v4 but no longer
> documented (which would be a [documentation] bug) or not supported at
> all (which would be a [regression] bug).
> 

With Squid-4 the ACl and log format codes should be the same now.
Perhapse more info at logging time than helper API, but thats all.

* Things available to the ACL but not at logging is a bug, probably a
regression.
* Things that used to log but no longer do are regressions.
* Otherwise things that should be available but are not at the helper
ACL time are missing feature bugs.

Amos



From darren.j.breeze.ml at gmail.com  Fri Sep 30 05:58:32 2016
From: darren.j.breeze.ml at gmail.com (Darren)
Date: Fri, 30 Sep 2016 13:58:32 +0800
Subject: [squid-users] Large text ACL lists
In-Reply-To: <2c1e0a65-e688-183f-b83e-4fbbfa6d4539@treenet.co.nz>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <2c1e0a65-e688-183f-b83e-4fbbfa6d4539@treenet.co.nz>
Message-ID: <54ee7d9a-96fe-4233-8db7-3b891455f07f@getmailbird.com>

Thank you Amos

The resources I save not running multiple Squidguards will ?make more ram available as you say and having a simpler setup is never a bad thing either.

Just to clarify, so when squid fires up, it caches the ACL file into ram ?in it's entirety and then does some optimizations? If that is the case I would need to budget the ram to allow for this.

This sounds great and I get the bonus reverse DNS on dstdomain acls too, something Squidgard didn't do.

happy days

thanks

Darren B.





Sent from Mailbird [http://www.getmailbird.com/?utm_source=Mailbird&amp;utm_medium=email&amp;utm_campaign=sent-from-mailbird]
On 30/09/2016 10:42:15 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
On 29/09/2016 10:44 p.m., Darren wrote:
> Hi All
>
> I have been tinkering with Squidguard for a while, using it to manage
> ACL lists and time limits etc.
>
> While it works OK, it's not in active development and has it's
> issues.
>
> What are the limitations with just pumping ACL lists directly into
> Squid and letting it do all the work internally without running a
> team of squidguards?

CPU mostly. The helpers will use Nx the RAM for N helpers, so Squid
technically uses less that way. But since Squid workers are internally
single-threaded the CPU time takes from the processing of things through
the lists does slow down the workers handling other transactions. There
is also the time on startup for loading the data into memory. With big
data lists both of those differences can be noticable.

There are some RAM differences purely due to the storage formats. We
have not particularly optimized Squid ACLs recently for large data sets.

>
> how efficient is squid now at parsing the text files directly, will i
> Need more ram as the list grows? Is it slower or are their
> optimizations that I can do?
>

You will. Regardless of whether you use a helper or Squid.

Optimizations center around reducing the list sizes, removing
duplication, overlaps and dead entries.

For regex ACLs compacting the patterns down helps a lot. Squid will do
that itself now but is not very smart about it, so manual optimizations
still can have big impact.


Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/61ac4163/attachment.htm>

From hydrapolic at gmail.com  Fri Sep 30 06:18:17 2016
From: hydrapolic at gmail.com (Tomas Mozes)
Date: Fri, 30 Sep 2016 08:18:17 +0200
Subject: [squid-users] pinger crash - Bad opcode: 112
In-Reply-To: <aa120a29-edb0-52b8-375e-09cb1f0453ac@treenet.co.nz>
References: <CAG6MAzT+JQP0Bd+UDHN3zwigU6W8H6oGYxXdn3iVhuYqU=qZpg@mail.gmail.com>
 <bdb614cb-27fe-ad3a-5780-e6f9245e495d@treenet.co.nz>
 <CAG6MAzQpEQNA1nv_GfNcWvQTccA7ZejyCoOiscsQS51C5FBcdQ@mail.gmail.com>
 <a176619d-3ca6-132b-f72e-40723be158ed@treenet.co.nz>
 <CAG6MAzRSmL_9wxCYoVjhQggC-BXSGeeScpPtaMBgBN6M8uQ9yw@mail.gmail.com>
 <aa120a29-edb0-52b8-375e-09cb1f0453ac@treenet.co.nz>
Message-ID: <CAG6MAzQ5bmoSSi-YXfVR5=RDtYJxvU89XD48FBfDFqen8BwMaA@mail.gmail.com>

After enabling IPv6 in the kernel, building squid with IPv6 and firewalling
IPv6 no crash was observed any more.

Thanks for the tip Amos.

On Sat, Jun 11, 2016 at 7:14 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 3/06/2016 3:47 a.m., Tomas Mozes wrote:
> > On Wed, Jun 1, 2016 at 1:53 PM, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
> >
> >> On 31/05/2016 9:56 p.m., Tomas Mozes wrote:
> >>> On Thu, May 26, 2016 at 8:04 AM, Amos Jeffries wrote:
> >>>
> >>>> On 24/05/2016 7:52 p.m., Tomas Mozes wrote:
> >>>>> Hello,
> >>>>> on two different squid servers I've observed a crash of pinger. First
> >> it
> >>>>> appeared on version 3.5.15 and later on version 3.5.17.
> >>>>>
> >>>>> Cache.log contains these lines:
> >>>>>
> >>>>> (pinger): Address.cc:671: void Ip::Address::getAddrInfo(addrinfo*&,
> >> int)
> >>>>> const: Assertion `false' failed.
> >>>>> 2016/05/14 21:55:25 kid1| Bad opcode: 112 from
> >>>>> [6661:6c73:6522:2061:7420:6c69:6e65:2036]
> >>>>> 2016/05/14 21:59:13 kid1| recv: (111) Connection refused
> >>>>> 2016/05/14 21:59:13 kid1| Closing Pinger socket on FD 17
> >>>>>
> >>>>> On both servers, that IPv6 address was the same -
> >>>>> 6661:6c73:6522:2061:7420:6c69:6e65:2036
> >>>>>
> >>>>
> >>>> That is the hexadecimal representation of the error:
> >>>>  false" at line 6
> >>>>
> >>>> Which means that your kernel is producing garbage when asked to
> resolve
> >>>> an IPv6 address or respond to an ICMPv6 packet.
> >>>>
> >>>
> >>> Cannot we prevent Squid from crashing in these cases?
> >>>
> >>
> >> Squid is not crashing. The pinger is. Squid continues with degraded
> >> service latency.
> >>
> >
> > Yes, sorry, I wasn't specific. I meant like some part of Squid, not the
> > Squid caching process itself.
> >
> >
> >> What kind of continued operations would you expect a program to do when
> >> it discovers at least some portion of its RAM has been filled with
> >> garbage by the system kernel?
> >>
> >
> >
> > In the worst case - wouldn't it be possible for the master process to
> > restart it?
> >
>
> For most helpers that is exacty what happens, but with frequent enough
> failures killing Squid. That latter bit has been part of the problem
> preventing this one being the same so far.
>
> This paticular helper needs root permission to use ICMP sockets. It has
> a long history of being installed with wrong ownership and access
> permissions, which cause it to exit early. So the most common form of it
> dying is not a situation in which Squid can reasonably restart it - or
> risks almost certainly dying itself.
>
> Thesituation has been improving in recent years though. So I'm hopeful
> we will get there eventually. If you wish to sponsor some work to speed
> that up it could be made a configurable action.
>
>
> >
> >>
> >> Now cross your fingers and pray that no other programs on your whole
> >> system (network, if you did the same "disable" on other machines) are
> >> behaving badly in secret when given the garbage by the kernel like
> >> Squid's pinger was.
> >>
> >
> > You know, the strange thing is I only found those strings on google
> > attached with Squid. No other place. If it's a general issue in the Linux
> > kernel, then it's been there for years, unnoticed. And as I mentioned
> > before, it happened on two machines, separate from each other, in
> > completely different data-centers with the same error message.
> >
> > What would you suggest?
> >
>
> I suggest enabling IPv6 within your network. :-) It can be firewalled if
> you want it not to be used, same as any other digital service.
>
> That will also give you a way to measure whether you have reached
> tipping point of it being useful. The global traffic passed 12% last
> weekend and growth rate is somewhere between exponential and hyperbolic
> despite a lot of networks still clinging to IPv4.
>
> Amos
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/50fcca44/attachment.htm>

From emz at norma.perm.ru  Fri Sep 30 06:38:07 2016
From: emz at norma.perm.ru (Eugene M. Zheganin)
Date: Fri, 30 Sep 2016 11:38:07 +0500
Subject: [squid-users] connections from particular users sometimes get
 stuck
In-Reply-To: <5ec198bf-ae59-1972-698b-591a575285bc@measurement-factory.com>
References: <42b972b9-77a7-f43d-1630-fe31a71ab508@norma.perm.ru>
 <57EB7DAC.9000408@norma.perm.ru>
 <f81aae25-958a-b8f4-2b28-5a0daecc1f71@measurement-factory.com>
 <201609281741.54358.Antony.Stone@squid.open.source.it>
 <7280391c-a10c-8eb9-c41a-4f924600dda8@measurement-factory.com>
 <c14e1d4d-bff7-6ea2-dd8c-82a9663b1c19@norma.perm.ru>
 <57ECD7A9.60607@norma.perm.ru>
 <5ec198bf-ae59-1972-698b-591a575285bc@measurement-factory.com>
Message-ID: <57EE084F.6020505@norma.perm.ru>

Hi.

On 29.09.2016 23:17, Alex Rousskov wrote:
> On 09/29/2016 02:58 AM, Eugene M. Zheganin wrote:
>> This time turbodom.ru entries are present in the debug log
> Yes, there are two complete HTTP transactions with that domain. One is a
> 407 Authentication Required and one is a 301 redirect:
>
>> HTTP/1.1 301 Moved Permanently
> ...
>> Location: http://turbodom.ru/index.html/
> I see no relevant problems with those two transactions.
Me neither, but the original transaction start wasn't 'GET
http://turbodom.ru/index.html/', it was 'GET
http://turbodom.ru/index.html', without trailing slash. Trailing slash
was added by the web-server, due to it's specific configuration. And the
main sign indicating there's something wrong with this initial
transaction was the fact that 407 answer took 42 seconds to appear in
both tcpdump captures.
>
>
>> tcpdump capture taken from a client machine:
>> http://zhegan.in/files/squid/squid-stuck-client.pcap
> This capture one is missing most of the second transaction packets
> (tcp.stream eq 186). I do not know why tcpdump was unable to collect them.
This is because of the gap between Ctrl^C issued in the client machine
cmd console and squid server ssh console (in this exact order) - I had
to switch between windows on my desktop, and because about a minute has
passed since the beginning of the transaction (42 seconds plus quite
some time), and I was worried that the debug log will grow more and
more, making it difficult to navigate then.
>> tcpdump capture taken from squid machine, on the interface the client
>> machine is connected via:
>> http://zhegan.in/files/squid/squid-stuck-server-to-client.pcap
> This one has both HTTP transactions described above (tcp.stream eq 206).
>
> It also contains a related and incomplete transaction that follows the
> above redirect (tcp.stream eq 346). According to tcpdump, that
> transaction starts around 13:31:26.
>
> Squid cache log does not mention that third transaction (or that TCP
> connection), probably because Squid could not accept it. There were a
> few accept failures (ECONNABORTED) right around the time of that
> third/missing transaction:
>
>> 13:31:25.060 kid1| accept failure: (53) Software caused connection abort
>> 13:31:25.865 kid1| accept failure: (53) Software caused connection abort
>> 13:31:25.904 kid2| accept failure: (53) Software caused connection abort
> The timestamps are a ~second off, but AFAICT, they are a ~second off for
> successful accepts as well, so it is probably just a tcpdump logging
> artifact.
>
> In summary, your browser is probably stuck because Squid could not
> accept a connection. Why did that accept call fail with ECONNABORTED? I
> cannot say for sure -- the packet trace is rather dirty/misleading
> (e.g., it shows the redirect packet being sent to the client _after_ the
> client follows that redirect which does not make sense).
>
> Any relevant errors in you system logs?
Nothing except

Limiting closed port RST response from 294 to 200 packets/sec

repeated by many times, which doesn't look related to this, because they
keep popping even when nobody's complaining. I've already did the
initial investigation and found no signs of resource starvation -
meaning no connection/files/mbufs/memory/pf states starvation happens.
At least I didn't find it. Plus, it would affect all of the clients
randomly, right ? Not this particular one.
>
> If you cancel browser wait and repeat the request, will it work?
Sometimes, but this means like 3-5% percents. Most of the time
rerequests lead to the same timeout, Chrome shows the request is
"pending" in the developer's tools/network tab for dozens of seconds,
and so on.
>  If this
> was just a random accept failure, then it should work on the second try.
> If it does not work again, then there is something more serious going on
> (but you would need to collect more logs to study that).
>
> The connection accepting code in Squid is in poor shape, but I do not
> think those minor code problems affect this particular use case.
>
I still have this machine in stuck state (I think), what should I focus on ?

Thanks.
Eugene.



From squid3 at treenet.co.nz  Fri Sep 30 06:59:07 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Sep 2016 19:59:07 +1300
Subject: [squid-users] Large text ACL lists
In-Reply-To: <54ee7d9a-96fe-4233-8db7-3b891455f07f@getmailbird.com>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <2c1e0a65-e688-183f-b83e-4fbbfa6d4539@treenet.co.nz>
 <54ee7d9a-96fe-4233-8db7-3b891455f07f@getmailbird.com>
Message-ID: <35c4e399-1050-06c7-1715-e0c1252955a4@treenet.co.nz>

On 30/09/2016 6:58 p.m., Darren wrote:
> Thank you Amos
> 
> The resources I save not running multiple Squidguards will  make more
> ram available as you say and having a simpler setup is never a bad
> thing either.
> 
> Just to clarify, so when squid fires up, it caches the ACL file into
> ram  in it's entirety and then does some optimizations? If that is
> the case I would need to budget the ram to allow for this.

Not quite. Squid still reads the files line by line into a memory
structure for whatever type of ACL is being loaded. That is part of why
its so much slowe to load than the helpers (which generally do as you
describe).

The optimizations are type dependent and fairly simplistic. Ignoring
duplicate entries, catenating regex into bigger " A|B " patterns (faster
to check against), etc.

Amos



From michael.varun at inmobi.com  Fri Sep 30 07:10:54 2016
From: michael.varun at inmobi.com (Michael Varun)
Date: Fri, 30 Sep 2016 12:40:54 +0530
Subject: [squid-users] Caching application/octet-stream
In-Reply-To: <a1df4bde-6c40-ff3c-e41e-e5e8aee0a86e@treenet.co.nz>
References: <CAHhBkD0dXw7PztgqGdrZ=6aTxVpuXExx+q+qVA+8rM3a+8Y8NA@mail.gmail.com>
 <a1df4bde-6c40-ff3c-e41e-e5e8aee0a86e@treenet.co.nz>
Message-ID: <CAHhBkD1E1dFS3wTHXFjE16ES0HEcxA_ePAusrF2q-WwZ-QtfTg@mail.gmail.com>

Here is the snippet of debug logs
I dont get to see anything missing out there . It does a GET call to the
docker registry on behalf of the requesting client The registry listens on
443 so squid mimicks  client TLS connections post which does a GET call to
the docker registry on the requested blobs


Logs
=====


---------
GET
/v2/idp/mtd-log-viewer/blobs/sha256:7f24efe711014be87fc45d3ccdc15bb419f45f26ab1f7dd4652b83890ba16294
HTTP/1.1
Host: dockerregistry.com
User-Agent: docker/1.12.1 go/go1.6.3 git-commit/23cf638
kernel/3.16.0-71-generic os/linux arch/amd64
UpstreamClient(Docker-Client/1.12.1 \(linux\))
Authorization: Bearer
AKCp2V5yYCcLhiuTrm6gvr2h6At9FfzhpxEB61CncxQsQxoRNT4tmcSLbWjecmnSFT4gtvF1q
Accept-Encoding: gzip
Connection: close


----------
2016/09/30 07:05:26.100| 11,2| http.cc(2201) sendRequest: HTTP Server local=
10.88.92.129:56249 remote=xx.xx.xx.xx:443 FD 16 flags=1
2016/09/30 07:05:26.100| 11,2| http.cc(2202) sendRequest: HTTP Server
REQUEST:
---------
GET
/v2/idp/mtd-log-viewer/blobs/sha256:7f24efe711014be87fc45d3ccdc15bb419f45f26ab1f7dd4652b83890ba16294
HTTP/1.1
User-Agent: docker/1.12.1 go/go1.6.3 git-commit/23cf638
kernel/3.16.0-71-generic os/linux arch/amd64
UpstreamClient(Docker-Client/1.12.1 \(linux\))
Host: dockerregistry.com
Via: 1.1 proxyserver (squid/3.5.20-20160817-r14075)
Surrogate-Capability: proxyserver="Surrogate/1.0"
X-Forwarded-For: 10.88.84.102
Cache-Control: max-age=600
Connection: keep-alive


----------
2016/09/30 07:05:27.046| ctx: enter level  0: '
https://dockerregistry.com/v2/blobs/sha256:3071a8ec2f6e96d06697a8069a385f889fa318ef479a0c2557baddb0e06a9b2c
'
2016/09/30 07:05:27.046| 11,2| http.cc(717) processReplyHeader: HTTP Server
local=10.88.92.129:56250 remote=xx.xx.xx.xx:443 FD 21 flags=1
2016/09/30 07:05:27.046| 11,2| http.cc(718) processReplyHeader: HTTP Server
REPLY:
---------
HTTP/1.1 200 OK
Server: nginx
Date: Fri, 30 Sep 2016 07:06:12 GMT
Content-Type: application/octet-stream
Content-Length: 1256
Connection: keep-alive
X-Artifactory-Id: fb4bb806eccd564b:-7d2d7c9a:156cf92100e:-8000
Last-Modified: Tue, 13 Sep 2016 06:03:06 GMT
ETag: ca5755fd72e65e6cc42e608eb7524d4956c9a358
X-Checksum-Sha1: ca5755fd72e65e6cc42e608eb7524d4956c9a358
Accept-Ranges: bytes
X-Checksum-Md5: a15d3dcf76f3334177fa44e6ad0af578
X-Artifactory-Filename:
sha256__3071a8ec2f6e96d06697a8069a385f889fa318ef479a0c2557baddb0e06a9b2c
Docker-Distribution-Api-Version: registry/2.0
Docker-Content-Digest:
sha256:3071a8ec2f6e96d06697a8069a385f889fa318ef479a0c2557baddb0e06a9b2c

?
----------
2016/09/30 07:05:27.046| ctx: exit level  0
2016/09/30 07:05:27.046| 11,2| client_side.cc(1392) sendStartOfMessage:
HTTP Client local=10.88.92.129:443 remote=10.88.84.102:41429 FD 18 flags=1
2016/09/30 07:05:27.046| 11,2| client_side.cc(1393) sendStartOfMessage:
HTTP Client REPLY:
---------
HTTP/1.1 200 OK
Server: nginx
Date: Fri, 30 Sep 2016 07:06:12 GMT
Content-Type: application/octet-stream
Content-Length: 1256
X-Artifactory-Id: fb4bb806eccd564b:-7d2d7c9a:156cf92100e:-8000
Last-Modified: Tue, 13 Sep 2016 06:03:06 GMT
ETag: ca5755fd72e65e6cc42e608eb7524d4956c9a358
X-Checksum-Sha1: ca5755fd72e65e6cc42e608eb7524d4956c9a358
Accept-Ranges: bytes
X-Checksum-Md5: a15d3dcf76f3334177fa44e6ad0af578
X-Artifactory-Filename:
sha256__3071a8ec2f6e96d06697a8069a385f889fa318ef479a0c2557baddb0e06a9b2c
Docker-Distribution-Api-Version: registry/2.0
Docker-Content-Digest:
sha256:3071a8ec2f6e96d06697a8069a385f889fa318ef479a0c2557baddb0e06a9b2c
X-Cache: MISS from proxyserver
<=======================================================================================
MISS
X-Cache-Lookup: MISS from
proxyserver:443<=============================================================================
LOOKUP MISS
Via: 1.1 proxyserver (squid/3.5.20-20160817-r14075)
Connection: close

On Wed, Sep 28, 2016 at 7:54 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 28/09/2016 11:17 p.m., Michael Varun wrote:
> > Team -
> >
> > Would like to know is there any specific config that we need to enable to
> > cache MIME attachement of application/octet-stream type
> >
> > We are trying to caching docker image blobs which is of
> > application/octet-stream  and everytime we hit the docker registry
> via)GET
> > call squid throws up TCP_MISS/200  I had never got a CACHE HIT or MEM HIT
> > for these contents. Can someone show pointers to how to succeed in cache
> > hit
>
> The object mime type does not matter for caching. What does matter are
> the URL and identifier headers, plus headers about the objects age,
> Vary, Expires and Cache-Control.
>
> You can configure "debug_options 11,2" to get a cache.log trace of the
> messages going through the proxy. Taking a closer look at those message
> headers to find out why caching is not happening.
>
> You could also use the tool at redbot.org. It takes a public URL and
> displays the cacheability situation for it.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

-- 
_____________________________________________________________
The information contained in this communication is intended solely for the 
use of the individual or entity to whom it is addressed and others 
authorized to receive it. It may contain confidential or legally privileged 
information. If you are not the intended recipient you are hereby notified 
that any disclosure, copying, distribution or taking any action in reliance 
on the contents of this information is strictly prohibited and may be 
unlawful. If you have received this communication in error, please notify 
us immediately by responding to this email and then delete it from your 
system. The firm is neither liable for the proper and complete transmission 
of the information contained in this communication nor for any delay in its 
receipt.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/3ef8ac31/attachment.htm>

From squid3 at treenet.co.nz  Fri Sep 30 07:10:52 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Sep 2016 20:10:52 +1300
Subject: [squid-users] connections from particular users sometimes get
 stuck
In-Reply-To: <57EE084F.6020505@norma.perm.ru>
References: <42b972b9-77a7-f43d-1630-fe31a71ab508@norma.perm.ru>
 <57EB7DAC.9000408@norma.perm.ru>
 <f81aae25-958a-b8f4-2b28-5a0daecc1f71@measurement-factory.com>
 <201609281741.54358.Antony.Stone@squid.open.source.it>
 <7280391c-a10c-8eb9-c41a-4f924600dda8@measurement-factory.com>
 <c14e1d4d-bff7-6ea2-dd8c-82a9663b1c19@norma.perm.ru>
 <57ECD7A9.60607@norma.perm.ru>
 <5ec198bf-ae59-1972-698b-591a575285bc@measurement-factory.com>
 <57EE084F.6020505@norma.perm.ru>
Message-ID: <6bb1cbbd-226a-23fe-5922-78dbb14459b7@treenet.co.nz>

On 30/09/2016 7:38 p.m., Eugene M. Zheganin wrote:
> On 29.09.2016 23:17, Alex Rousskov wrote:
>>
>> In summary, your browser is probably stuck because Squid could not
>> accept a connection. Why did that accept call fail with ECONNABORTED? I
>> cannot say for sure -- the packet trace is rather dirty/misleading
>> (e.g., it shows the redirect packet being sent to the client _after_ the
>> client follows that redirect which does not make sense).
>>
>> Any relevant errors in you system logs?
> Nothing except
> 
> Limiting closed port RST response from 294 to 200 packets/sec
> 
> repeated by many times, which doesn't look related to this, because they
> keep popping even when nobody's complaining. I've already did the
> initial investigation and found no signs of resource starvation -
> meaning no connection/files/mbufs/memory/pf states starvation happens.
> At least I didn't find it. Plus, it would affect all of the clients
> randomly, right ? Not this particular one.
>>
>> If you cancel browser wait and repeat the request, will it work?
> Sometimes, but this means like 3-5% percents. Most of the time
> rerequests lead to the same timeout, Chrome shows the request is
> "pending" in the developer's tools/network tab for dozens of seconds,
> and so on.
>>  If this
>> was just a random accept failure, then it should work on the second try.
>> If it does not work again, then there is something more serious going on
>> (but you would need to collect more logs to study that).
>>
>> The connection accepting code in Squid is in poor shape, but I do not
>> think those minor code problems affect this particular use case.
>>
> I still have this machine in stuck state (I think), what should I focus on ?

I think the TCP packets, particularly the SYN and first few after that
between the client and Squid.
There may be some clues in the TCP features which they are trying to
negotiate for use. Or the timings relative to when Squid calls accept()
to receive the connection (TCP queues too big etc).

Amos



From squid3 at treenet.co.nz  Fri Sep 30 07:36:43 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 30 Sep 2016 20:36:43 +1300
Subject: [squid-users] Caching application/octet-stream
In-Reply-To: <CAHhBkD1E1dFS3wTHXFjE16ES0HEcxA_ePAusrF2q-WwZ-QtfTg@mail.gmail.com>
References: <CAHhBkD0dXw7PztgqGdrZ=6aTxVpuXExx+q+qVA+8rM3a+8Y8NA@mail.gmail.com>
 <a1df4bde-6c40-ff3c-e41e-e5e8aee0a86e@treenet.co.nz>
 <CAHhBkD1E1dFS3wTHXFjE16ES0HEcxA_ePAusrF2q-WwZ-QtfTg@mail.gmail.com>
Message-ID: <8895d8b6-ab32-c6c8-4b64-67ce62a33c43@treenet.co.nz>

On 30/09/2016 8:10 p.m., Michael Varun wrote:
> Here is the snippet of debug logs
> I dont get to see anything missing out there . It does a GET call to the
> docker registry on behalf of the requesting client The registry listens on
> 443 so squid mimicks  client TLS connections post which does a GET call to
> the docker registry on the requested blobs

Well firstly, going by your earlier config file the client is *not*
performing TLS connections. Your proxy is configured to receive
plain-text HTTP at port 443.

You seem to have stumbled onto two bugs in Squid which are combining to
be problematic.

There is a bug in the SSL-Bump implementation we have not sorted out
yet, which makes the "ssl-bump" on this port enable reverse-proxy mode
handling. That seems to be leading to Surrogate feature being enabled
and the Authorization:Bearer being removed when it should be relayed to
the server.

The existence of Authorization header on the request combined with lack
of Cache-Control:public on the response means these reponses are private
responses associated with that auth credentials token. They cannot be
cached and given to anyone else.

That brings up what I think may be a second bug. Since the request to
the server was sent without Auth header then Squid should be considering
it a non-auth response and treating it as cacheable anyway. But probably
is just using the client request for that decision.


You could try adding the "login=PASSTHRU" option to your cache_peer
line. If the server sends "Cache-Control:public" that should enable caching.

Amos



From rafael.akchurin at diladele.com  Fri Sep 30 07:37:10 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Fri, 30 Sep 2016 07:37:10 +0000
Subject: [squid-users] Squid 3.5.21 for Microsoft Windows 64-bit is available
Message-ID: <DB6PR0401MB2680B214A6F1B0D482C80CF58FC10@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Greetings everyone,



@yuri Sorry for being so late, we had some issues compiling this version :(



----

For those wishing to have Squid 3.5.19 recompiled with HTTPS filtering support see https://github.com/diladele/squid-ubuntu#how-to-use-the-repository-at-ubuntu16diladelecom-for-ubuntu-16.

Note, we still have 3.5.19 in the repository because we actually rebuild the package from Debian 8 testing and it still is not updated.

----



The CygWin based build of Squid proxy for Microsoft Windows version 3.5.21 is now available (amd64 only!).



* Original release notes are at http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.21-RELEASENOTES.html.

* Ready to use MSI package can be downloaded from http://squid.diladele.com.

* List of open issues for the installer - https://github.com/diladele/squid3-windows/issues



Thanks a lot for Squid developers for making this great software!



Please join our humble efforts to provide ready to run MSI installer for Squid on Microsoft Windows with all required dependencies at GitHub -

https://github.com/diladele/squid3-windows. Please report all issues/bugs/feature requests at GitHub project. Issues about the *MSI installer only* can also be reported to support at diladele.com<mailto:support at diladele.com>.



Best regards,

Rafael Akchurin

Diladele B.V.

https://www.diladele.com



--

Please take a look at Web Safety - our ICAP based web filter server for Squid proxy.







-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/3e954d7a/attachment.htm>

From henry at nitronetworks.nl  Fri Sep 30 09:48:05 2016
From: henry at nitronetworks.nl (Henry Paulissen)
Date: Fri, 30 Sep 2016 11:48:05 +0200
Subject: [squid-users] External nat'ed transparent proxy
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAP1vRcAAnWlNoU7f4f0YNhgBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADQt4cUeAlsQ6ihb0bN4K2wAQAAAAA=@ngtech.co.il>
References: <9cb02f45-ad81-7d77-0d7a-cf313c34f4fd@nitronetworks.nl>
 <!&!AAAAAAAAAAAuAAAAAAAAAP1vRcAAnWlNoU7f4f0YNhgBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAADQt4cUeAlsQ6ihb0bN4K2wAQAAAAA=@ngtech.co.il>
Message-ID: <789f52cc-6929-0719-9e3b-7378bdf37343@nitronetworks.nl>

Good morning Eliezer,


It took some time for me to construct a drawing who would be
understandable enough how our setup is, as the diagrams you provided
didn't fully fit the case. But, I think I managed to make a
understandable drawing of it :-)

[ Link to PNG image ]
https://drive.google.com/file/d/0BysciyDBahUtWU55RjNPUlFjMTQ/view


Some additional info with the drwaing:
  - Each linux firewall server handles top ~5G traffic. After that we
    build a new firewall cluster and new servers are connected to
    that one.

  - The linux firewall is gateway for the vlan.

  - As you might know: LVS is internally also a DNAT, so bassicly we do
    a double DNAT.

  - The green and blue line indicates how the traffic is routed

  - Linux firewalls is physical hardware, but all the servers
    (including the squid hosts) are linux vservers (like LXC containers
    or docker containers).


Hopes this clears up our setup and where I run into problems with squid3.

Regards,

-- 
Henry Paulissen - PD0OM
henry at nitronetworks.nl - Phone: +31-(0)6-115.305.64
Linux/Unix System Engineer

On 30-09-16 00:35, Eliezer Croitoru wrote:
> Hey Henry,
> 
> I want to emulate the setup to understand the complication with a FULL linux based setup here on my local testing grounds.
> Can you give more details on the networks in the form of subnets and VLAN numbers?
> What is not clear to me is: Who is doing the DNAT?
> Also, if you have not used tproxy and intercept on the PROXY machine you should re-think the whole logic of the system first before deciding on the next step.
> There are systems which needs redesign when moving from Squid 2 to 3 or 4.
> When I and you will have the right understanding of the scenario I believe we can find the right path if this is not already there.
> 
> Let me know if these( the diagrams..):
> http://wiki.squid-cache.org/EliezerCroitoru/Drafts/MwanLB#Intoduction_to_MultiWAN_LoadBalancing
> http://wiki.squid-cache.org/ConfigExamples/UbuntuTproxy4Wccp2
> 
> Make any sense to you so we can find the right words to fill the gaps in the situation.
> Once I will have the right picture I would probably have enough information to draw some picture in VISIO and move forward to the Systems table.
> 
> Eliezer
> 
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile+WhatsApp: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
> 
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Henry Paulissen
> Sent: Thursday, September 29, 2016 5:40 PM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] External nat'ed transparent proxy
> 
> Hi all,
> 
> In the company I work for we are currently using squid v2 proxies in transparent mode to intercept traffic from servers to the outside (access control).
> 
> The technical solution for this is roughly as follows:
> [server] -> [gateway] -> [firewall]
>                               |
>     ----------- DNAT ---------
>    v
> [squid]  -> [gateway] -> [firewall] -> [internet router]
> 
> Our firewalls (who live between the vlan gateway and internet router), DNAT the traffic towards separate squid proxies (who are in a lvs cluster). These squid proxies are in their own vlan with special permissions to allow unrestricted port 80 outbound, etc, etc...
> 
> Because squid v2 is becoming more and more obsolete we are looking at upgrading it towards squid v3.
> 
> From what I read in the manuals, transparent mode is replaced by intercept (and tproxy) mode. But both dont seem to be fully backward complaint with the v2 transparent mode.
> 
> The old trasparent mode allowed us to just dnat traffic towards the squid host without the need for the client to be aware of this. For example, the old style accepted 'GET / HTTP/1.1' (without full URL in the GET request and looking at the Host header for the destination).
> 
> The new intercept mode comes close to this behavior, but instead of remotly dnat, it wants us to next-hop it towards the squid proxy and redirect it locally. This is problematic for us as firewall and squid proxy dont live in the same vlan, so next-hop should be the router to that vlan (and forgetting about the path back to the server). Secondly, and not less blocking, we use vservers (predecessor to linux containers
> lxc) as such, we dont have any promiscuous interfaces rights within the container.
> 
> 
> Is there still a option to emulate normal 'regular? style squid (as without any listen options) but instead accepting the URI path in the GET request and looking at the Host header for the destination? (lets call it passthrough mode?).
> 
> Or, is there in squid3 a new and better way to facilitate larger setups, with the knowledge the server, firewall and squids are all in different vlans (and no, we dont have Cisco firewalls in between them ;-)).
> 
> 
> Thanks in advance,
> 
> --
> Henry Paulissen - PD0OM
> henry at nitronetworks.nl - Phone: +31-(0)6-115.305.64 Linux/Unix System Engineer
> 
> 


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/1f7e5f0c/attachment.sig>

From uhlar at fantomas.sk  Fri Sep 30 10:36:42 2016
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Fri, 30 Sep 2016 12:36:42 +0200
Subject: [squid-users] External nat'ed transparent proxy
In-Reply-To: <9cb02f45-ad81-7d77-0d7a-cf313c34f4fd@nitronetworks.nl>
References: <9cb02f45-ad81-7d77-0d7a-cf313c34f4fd@nitronetworks.nl>
Message-ID: <20160930103642.GB29597@fantomas.sk>

On 29.09.16 16:39, Henry Paulissen wrote:
>In the company I work for we are currently using squid v2 proxies in
>transparent mode to intercept traffic from servers to the outside
>(access control).
>
>The technical solution for this is roughly as follows:
>[server] -> [gateway] -> [firewall]
>                              |
>    ----------- DNAT ---------
>   v
>[squid]  -> [gateway] -> [firewall] -> [internet router]

this is a bad configuration. The firewall in the path should NOT use DNAT,
since it makes the important part of connection (destination IP) invisible
to squid.

>Because squid v2 is becoming more and more obsolete we are looking at
>upgrading it towards squid v3.
>
>From what I read in the manuals, transparent mode is replaced by
>intercept (and tproxy) mode. But both dont seem to be fully backward
>complaint with the v2 transparent mode.

not replaced, but renamed.

A "transparent proxy" is a proxy that does not modify the request or
response beyond what is required for proxy authentication and
identification.

An intercepting proxy is a proxy that intercepts request sent to other
server and handles it by itself.

otherwise the functionality is the same (just better) with intercept.
tproxy is intercepting in special mode, so the connection comes from the
client's instead of proxy server's IP address.

>The old trasparent mode allowed us to just dnat traffic towards the
>squid host without the need for the client to be aware of this. For
>example, the old style accepted 'GET / HTTP/1.1' (without full URL in
>the GET request and looking at the Host header for the destination).
>
>The new intercept mode comes close to this behavior, but instead of
>remotly dnat, it wants us to next-hop it towards the squid proxy and
>redirect it locally. This is problematic for us as firewall and squid
>proxy dont live in the same vlan, so next-hop should be the router to
>that vlan (and forgetting about the path back to the server). Secondly,
>and not less blocking, we use vservers (predecessor to linux containers
>lxc) as such, we dont have any promiscuous interfaces rights within the
>container.

if you really need to intercept users' requests, your network architecture
should be able to do it.

>Is there still a option to emulate normal 'regular? style squid (as
>without any listen options) but instead accepting the URI path in the
>GET request and looking at the Host header for the destination? (lets
>call it passthrough mode?).

Have you tried configuring WPAD?

>Or, is there in squid3 a new and better way to facilitate larger setups,
>with the knowledge the server, firewall and squids are all in different
>vlans (and no, we dont have Cisco firewalls in between them ;-)).

I am not sure whether it's a good design to intercept requests on one router
and direct them through multiple routers/firewalls.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Enter any 12-digit prime number to continue.


From yvoinov at gmail.com  Fri Sep 30 11:21:32 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 30 Sep 2016 17:21:32 +0600
Subject: [squid-users] Large text ACL lists
In-Reply-To: <35c4e399-1050-06c7-1715-e0c1252955a4@treenet.co.nz>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <2c1e0a65-e688-183f-b83e-4fbbfa6d4539@treenet.co.nz>
 <54ee7d9a-96fe-4233-8db7-3b891455f07f@getmailbird.com>
 <35c4e399-1050-06c7-1715-e0c1252955a4@treenet.co.nz>
Message-ID: <97de62ef-9f55-cb69-2031-4ef56c902d5d@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Amos, I'm afraid that this is not a solution. Block lists have become so
huge that only their compression and / or placement in an external
database (as Marcus) can save the situation.


30.09.2016 12:59, Amos Jeffries ?????:
> On 30/09/2016 6:58 p.m., Darren wrote:
>> Thank you Amos
>>
>> The resources I save not running multiple Squidguards will  make more
>> ram available as you say and having a simpler setup is never a bad
>> thing either.
>>
>> Just to clarify, so when squid fires up, it caches the ACL file into
>> ram  in it's entirety and then does some optimizations? If that is
>> the case I would need to budget the ram to allow for this.
>
> Not quite. Squid still reads the files line by line into a memory
> structure for whatever type of ACL is being loaded. That is part of why
> its so much slowe to load than the helpers (which generally do as you
> describe).
>
> The optimizations are type dependent and fairly simplistic. Ignoring
> duplicate entries, catenating regex into bigger " A|B " patterns (faster
> to check against), etc.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX7kq8AAoJENNXIZxhPexGH+cH/jmZsQlcZgXpwt62pHDtHp4t
TWDnhr5KOfHv+GFeBUmJYuD2nn8wefb5KUUhea5fdpRAeDihFDQDPQDwAnaC/E5q
FzE68zh+nF13xVwTW9/5mQhK75G17mOGJPGFPn1ZUC3lf/Q2JCOhWB+0MFilXXcQ
/ptCeQII/E8oXaiBOvHPzasOp6eDnu/m51q0DnkfoUceEWap9W0rY/vKxwL32FI9
fjqoZGGBPt3FDczjb8/9X6trqeGBwUl4PKSTE4JSdyU6z52evaCSsVbEgAmw+LjI
ELCBPOuU7buFxNjCSNLVhDNQeZJFJxPV8Oh/OcDQZQDhdUYliEwRke5Sz+Rz37k=
=hFD2
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/40c36bdb/attachment.key>

From henry at nitronetworks.nl  Fri Sep 30 11:27:00 2016
From: henry at nitronetworks.nl (Henry Paulissen)
Date: Fri, 30 Sep 2016 13:27:00 +0200
Subject: [squid-users] External nat'ed transparent proxy
In-Reply-To: <20160930103642.GB29597@fantomas.sk>
References: <9cb02f45-ad81-7d77-0d7a-cf313c34f4fd@nitronetworks.nl>
 <20160930103642.GB29597@fantomas.sk>
Message-ID: <57a01083-d569-cd4b-9d42-b6dc619cfd7c@nitronetworks.nl>

Hi Matus,


On 30-09-16 12:36, Matus UHLAR - fantomas wrote:
> On 29.09.16 16:39, Henry Paulissen wrote:
>> In the company I work for we are currently using squid v2 proxies in
>> transparent mode to intercept traffic from servers to the outside
>> (access control).
>>
>> The technical solution for this is roughly as follows:
>> [server] -> [gateway] -> [firewall]
>>                              |
>>    ----------- DNAT ---------
>>   v
>> [squid]  -> [gateway] -> [firewall] -> [internet router]
> 
> this is a bad configuration. The firewall in the path should NOT use DNAT,
> since it makes the important part of connection (destination IP) invisible
> to squid.
> 

That is where the HTTP Host header can be used for... For squid to
figure out the destination of the request. (aren?t they?)

>> Because squid v2 is becoming more and more obsolete we are looking at
>> upgrading it towards squid v3.
>>
>> From what I read in the manuals, transparent mode is replaced by
>> intercept (and tproxy) mode. But both dont seem to be fully backward
>> complaint with the v2 transparent mode.
> 
> not replaced, but renamed.
> 
> A "transparent proxy" is a proxy that does not modify the request or
> response beyond what is required for proxy authentication and
> identification.
> 
> An intercepting proxy is a proxy that intercepts request sent to other
> server and handles it by itself.
> 
> otherwise the functionality is the same (just better) with intercept.
> tproxy is intercepting in special mode, so the connection comes from the
> client's instead of proxy server's IP address.
> 

Sorry, this is a discussion about the definition about what a
transparent proxy is and what is not. I dont feel the need for this to
discuss at the moment (no hard feelings, but it doesn't aid to the
problem i`m facing).


>> The old trasparent mode allowed us to just dnat traffic towards the
>> squid host without the need for the client to be aware of this. For
>> example, the old style accepted 'GET / HTTP/1.1' (without full URL in
>> the GET request and looking at the Host header for the destination).
>>
>> The new intercept mode comes close to this behavior, but instead of
>> remotly dnat, it wants us to next-hop it towards the squid proxy and
>> redirect it locally. This is problematic for us as firewall and squid
>> proxy dont live in the same vlan, so next-hop should be the router to
>> that vlan (and forgetting about the path back to the server). Secondly,
>> and not less blocking, we use vservers (predecessor to linux containers
>> lxc) as such, we dont have any promiscuous interfaces rights within the
>> container.
> 
> if you really need to intercept users' requests, your network architecture
> should be able to do it.
> 

Our network architecture is able to do it, otherwise it wouldn't
currently work.

>> Is there still a option to emulate normal 'regular? style squid (as
>> without any listen options) but instead accepting the URI path in the
>> GET request and looking at the Host header for the destination? (lets
>> call it passthrough mode?).
> 
> Have you tried configuring WPAD?
> 

Linux (shell) servers dont do WPAD ;-)


>> Or, is there in squid3 a new and better way to facilitate larger setups,
>> with the knowledge the server, firewall and squids are all in different
>> vlans (and no, we dont have Cisco firewalls in between them ;-)).
> 
> I am not sure whether it's a good design to intercept requests on one
> router
> and direct them through multiple routers/firewalls.
> 

The whole idea about intercepting is that we delivered environments in
the past (10+ years) who didn't had to be configured to use a proxy.
Whatever this was a good thing to do or not is not within my power to
change anymore.
Back then, SSL wasn't a thing yet. So nobody thought about it.

In my reply to Eliezer Croitoru is a network diagram included.
Maybe this can shed a light onto our network topology.


-- 
Henry Paulissen - PD0OM
henry at nitronetworks.nl - Phone: +31-(0)6-115.305.64
Linux/Unix System Engineer

-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/860803e3/attachment.sig>

From rentorbuy at yahoo.com  Fri Sep 30 11:36:24 2016
From: rentorbuy at yahoo.com (Vieri)
Date: Fri, 30 Sep 2016 11:36:24 +0000 (UTC)
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
 code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
 <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
Message-ID: <2077594026.2082495.1475235384241@mail.yahoo.com>

Hi,

----- Original Message -----
> From: Amos Jeffries <squid3 at treenet.co.nz>
>
> Squid mimics the client details when contacting the server. So you would

> get the same problem (though maybe different description) if going

> directly without the proxy.


If I try connecting to https://www.google.com with this client and going directly without proxy then I have no problem whatsoever. I'm sure any Windows XP user still out there with IE8 can confirm that a direct connection to https://www.google.com still works fine. I hit the issue only when using Squid.


So from the squid server I ran:

# nmap --script ssl-enum-ciphers google.com
[...]
| ssl-enum-ciphers:
|   TLSv1.0:
|     ciphers:
|       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA - strong
|       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA - strong
|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong
|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong
|       TLS_RSA_WITH_3DES_EDE_CBC_SHA - strong
|       TLS_RSA_WITH_AES_128_CBC_SHA - strong
|       TLS_RSA_WITH_AES_256_CBC_SHA - strong
|     compressors:
|
|   TLSv1.1:
|     ciphers:
|       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA - strong
|       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA - strong
|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong
|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong
|       TLS_RSA_WITH_3DES_EDE_CBC_SHA - strong
|       TLS_RSA_WITH_AES_128_CBC_SHA - strong
|       TLS_RSA_WITH_AES_256_CBC_SHA - strong
|     compressors:
|
|   TLSv1.2:
|     ciphers:
|       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA - strong
|       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 - strong
|       TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 - strong
|       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA - strong
|       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384 - strong
|       TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 - strong
|       TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 - strong
|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong
|       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 - strong
|       TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 - strong
|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong
|       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 - strong
|       TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 - strong
|       TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256 - strong
|       TLS_RSA_WITH_3DES_EDE_CBC_SHA - strong
|       TLS_RSA_WITH_AES_128_CBC_SHA - strong
|       TLS_RSA_WITH_AES_128_CBC_SHA256 - strong
|       TLS_RSA_WITH_AES_128_GCM_SHA256 - strong
|       TLS_RSA_WITH_AES_256_CBC_SHA - strong
|       TLS_RSA_WITH_AES_256_CBC_SHA256 - strong
|       TLS_RSA_WITH_AES_256_GCM_SHA384 - strong
|     compressors:
|
|_  least strength: strong


So if TLS 1.0 is supported by Google then the Windows XP clients should be able to connect.


Can a cipher issue trigger the error message "Handshake with SSL server failed: error:1409F07F:SSL routines:ssl3_write_pending:bad write retry"?

I ran:

# openssl ciphers
ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:SRP-DSS-AES-256-CBC-SHA:SRP-RSA-AES-256-CBC-SHA:SRP-AES-256-CBC-SHA:DH-DSS-AES256-GCM-SHA384:DHE-DSS-AES256-GCM-SHA384:DH-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA256:DH-RSA-AES256-SHA256:DH-DSS-AES256-SHA256:DHE-RSA-AES256-SHA:DHE-DSS-AES256-SHA:DH-RSA-AES256-SHA:DH-DSS-AES256-SHA:DHE-RSA-CAMELLIA256-SHA:DHE-DSS-CAMELLIA256-SHA:DH-RSA-CAMELLIA256-SHA:DH-DSS-CAMELLIA256-SHA:ECDH-RSA-AES256-GCM-SHA384:ECDH-ECDSA-AES256-GCM-SHA384:ECDH-RSA-AES256-SHA384:ECDH-ECDSA-AES256-SHA384:ECDH-RSA-AES256-SHA:ECDH-ECDSA-AES256-SHA:AES256-GCM-SHA384:AES256-SHA256:AES256-SHA:CAMELLIA256-SHA:PSK-AES256-CBC-SHA:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:SRP-DSS-AES-128-CBC-SHA:SRP-RSA-AES-128-CBC-SHA:SRP-AES-128-CBC-SHA:DH-DSS-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:DH-RSA-AES128-GCM-SHA256:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES128-SHA256:DHE-DSS-AES128-SHA256:DH-RSA-AES128-SHA256:DH-DSS-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA:DH-RSA-AES128-SHA:DH-DSS-AES128-SHA:DHE-RSA-SEED-SHA:DHE-DSS-SEED-SHA:DH-RSA-SEED-SHA:DH-DSS-SEED-SHA:DHE-RSA-CAMELLIA128-SHA:DHE-DSS-CAMELLIA128-SHA:DH-RSA-CAMELLIA128-SHA:DH-DSS-CAMELLIA128-SHA:ECDH-RSA-AES128-GCM-SHA256:ECDH-ECDSA-AES128-GCM-SHA256:ECDH-RSA-AES128-SHA256:ECDH-ECDSA-AES128-SHA256:ECDH-RSA-AES128-SHA:ECDH-ECDSA-AES128-SHA:AES128-GCM-SHA256:AES128-SHA256:AES128-SHA:SEED-SHA:CAMELLIA128-SHA:IDEA-CBC-SHA:PSK-AES128-CBC-SHA:KRB5-IDEA-CBC-SHA:KRB5-IDEA-CBC-MD5:ECDHE-RSA-RC4-SHA:ECDHE-ECDSA-RC4-SHA:ECDH-RSA-RC4-SHA:ECDH-ECDSA-RC4-SHA:RC4-SHA:RC4-MD5:PSK-RC4-SHA:KRB5-RC4-SHA:KRB5-RC4-MD5:ECDHE-RSA-DES-CBC3-SHA:ECDHE-ECDSA-DES-CBC3-SHA:SRP-DSS-3DES-EDE-CBC-SHA:SRP-RSA-3DES-EDE-CBC-SHA:SRP-3DES-EDE-CBC-SHA:EDH-RSA-DES-CBC3-SHA:EDH-DSS-DES-CBC3-SHA:DH-RSA-DES-CBC3-SHA:DH-DSS-DES-CBC3-SHA:ECDH-RSA-DES-CBC3-SHA:ECDH-ECDSA-DES-CBC3-SHA:DES-CBC3-SHA:PSK-3DES-EDE-CBC-SHA:KRB5-DES-CBC3-SHA:KRB5-DES-CBC3-MD5:EDH-RSA-DES-CBC-SHA:EDH-DSS-DES-CBC-SHA:DH-RSA-DES-CBC-SHA:DH-DSS-DES-CBC-SHA:DES-CBC-SHA:KRB5-DES-CBC-SHA:KRB5-DES-CBC-MD5


# openssl s_client -connect google.com:443 -tls1
[...]
SSL-Session:
Protocol  : TLSv1
Cipher    : ECDHE-RSA-AES128-SHA

[...]

I also tried the following on the Squid server:

# curl --tlsv1.0 --trace trace.log https://www.google.com && grep "SSL connection using" trace.log[...]
== Info: SSL connection using TLSv1.0 / ECDHE-RSA-AES128-SHA
[...]

>From the Windows XP IE8 client I connected to this web site to quickly see all the supported protocols and ciphers:
https://www.ssllabs.com/ssltest/viewMyClient.html
I can see TLS 1.0 support and the following cipher list:

TLS_RSA_WITH_RC4_128_MD5 (0x4)   INSECURE 128 
TLS_RSA_WITH_RC4_128_SHA (0x5)   INSECURE 128 
TLS_RSA_WITH_3DES_EDE_CBC_SHA (0xa)  112 
TLS_RSA_WITH_DES_CBC_SHA (0x9)   WEAK 56 
TLS_RSA_EXPORT1024_WITH_RC4_56_SHA (0x64)   INSECURE 56 
TLS_RSA_EXPORT1024_WITH_DES_CBC_SHA (0x62)   WEAK 56 
TLS_RSA_EXPORT_WITH_RC4_40_MD5 (0x3)   INSECURE 40 
TLS_RSA_EXPORT_WITH_RC2_CBC_40_MD5 (0x6)   INSECURE 40 
TLS_DHE_DSS_WITH_3DES_EDE_CBC_SHA (0x13)   Forward Secrecy2  112 
TLS_DHE_DSS_WITH_DES_CBC_SHA (0x12)   WEAK 56 
TLS_DHE_DSS_EXPORT1024_WITH_DES_CBC_SHA (0x63)   WEAK 56 


On a Windows 7 IE8 client with no Squid proxy issues I can see the following list of ciphers:

TLS_RSA_WITH_AES_128_CBC_SHA256 (0x3c)  128 
TLS_RSA_WITH_AES_128_CBC_SHA (0x2f)  128 
TLS_RSA_WITH_AES_256_CBC_SHA256 (0x3d)  256 
TLS_RSA_WITH_AES_256_CBC_SHA (0x35)  256 
TLS_RSA_WITH_RC4_128_SHA (0x5)   INSECURE 128 
TLS_RSA_WITH_3DES_EDE_CBC_SHA (0xa)  112 
TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 (0xc027)   Forward Secrecy  128 
TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (0xc013)   Forward Secrecy  128 
TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (0xc014)   Forward Secrecy  256 
TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 (0xc02b)   Forward Secrecy  128 
TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 (0xc023)   Forward Secrecy  128 
TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 (0xc02c)   Forward Secrecy  256 
TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384 (0xc024)   Forward Secrecy  256 
TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA (0xc009)   Forward Secrecy  128 
TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA (0xc00a)   Forward Secrecy  256 
TLS_DHE_DSS_WITH_AES_128_CBC_SHA256 (0x40)   Forward Secrecy2  128 
TLS_DHE_DSS_WITH_AES_128_CBC_SHA (0x32)   Forward Secrecy2  128 
TLS_DHE_DSS_WITH_AES_256_CBC_SHA256 (0x6a)   Forward Secrecy2  256 
TLS_DHE_DSS_WITH_AES_256_CBC_SHA (0x38)   Forward Secrecy2  256 
TLS_DHE_DSS_WITH_3DES_EDE_CBC_SHA (0x13)   Forward Secrecy2  112 
TLS_RSA_WITH_RC4_128_MD5 (0x4)   INSECURE 128 


I suppose that the Windows XP client successfully connects to https://www.google.com because it uses TLS_RSA_WITH_3DES_EDE_CBC_SHA (when NOT using Squid). Am I right? Is there a way I can confirm that?


So, back on the squid server I checked the openssl ciphers for one that is supported by the Windows XP system. I searched for the oepnssl cipher name from the RFC cipher name at https://testssl.sh/openssl-rfc.mappping.html.

I found the following:
TLS_RSA_WITH_3DES_EDE_CBC_SHA = DES-CBC3-SHA
The other "strong" cipher supported by Windows XP seems to be:
TLS_DHE_DSS_WITH_3DES_EDE_CBC_SHA = EDH-DSS-DES-CBC3-SHA


# curl --tlsv1.0 --ciphers SRP-RSA-3DES-EDE-CBC-SHA --trace trace.log https://www.google.com
curl: (35) error:140740B5:SSL routines:SSL23_CLIENT_HELLO:no ciphers available


So I tried these commands on the Squid server:

# openssl s_client -connect google.com:443 -tls1 -cipher DES-CBC3-SHA
[...]
SSL-Session:
Protocol  : TLSv1
Cipher    : DES-CBC3-SHA

[...]
(that went well)


# openssl s_client -connect google.com:443 -tls1 -cipher EDH-DSS-DES-CBC3-SHA

CONNECTED(00000003)
3072018108:error:14094410:SSL routines:ssl3_read_bytes:sslv3 alert handshake failure:s3_pkt.c:1472:SSL alert number 40
3072018108:error:1409E0E5:SSL routines:ssl3_write_bytes:ssl handshake failure:s3_pkt.c:656:


So this failed. Why?
Is google wrongly advertising the supported cipher (I doubt it)?

I have OpenSSL 1.0.2d 9 Jul 2015 and Squid 3.5.14.

How do I know if Squid is also trying to use the same cipher EDH-DSS-DES-CBC3-SHA instead of DES-CBC3-SHA?

I tried setting debug_options rotate=1 ALL,5 but found nothing related to the cipher in the log:

# tail -n 1000000 /var/log/squid/cache.log | grep "10.215.144.47" | grep -i cipher

> To get around this you require the latest Squid version (with> peek-and-splice feature) doing the "bump" action on these clients

> traffic so that it can upgrade the TLS/SSL handshake and use some
> ciphers etc the server will accept on their connections.

I'm already using sslbump with squid 3.5. As posted in my first message I have:
https_port 3130 tproxy ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=16MB cert=/etc/ssl/squid/proxyserver.pem

How can I tell which TLS/cipher versions Squid is using? What exactly should I search for in the log?

I tried this while connecting from the Windows XP client:
# watch -n 1 "tail -n 10000 /var/log/squid/cache.log | grep clientNegotiateSSL"
2016/09/30 13:19:06.633 kid1| 83,2| client_side.cc(3796) clientNegotiateSSL: clientNegotiateSSL: New session 0x870088d8 on FD 151 (10.215.144.47:1649)
2016/09/30 13:19:06.633 kid1| 83,3| client_side.cc(3800) clientNegotiateSSL: clientNegotiateSSL: FD 151 negotiated cipher RC4-MD5
2016/09/30 13:19:06.633 kid1| 83,5| client_side.cc(3816) clientNegotiateSSL: clientNegotiateSSL: FD 151 has no certificate.


Why is Squid negotiating cipher RC4-MD5 which is reported "insecure" and unsupported by the google web site?


I finally tried this on the Squid server:

# openssl s_client -connect google.com:443 -tls1 -cipher RC4-MD5
CONNECTED(00000003)
3071960764:error:14094410:SSL routines:ssl3_read_bytes:sslv3 alert handshake failure:s3_pkt.c:1472:SSL alert number 40
3071960764:error:1409E0E5:SSL routines:ssl3_write_bytes:ssl handshake failure:s3_pkt.c:656:


If I watch the Squid log when performing a connection to google from a Windows 7 IE8 with no issues, I get this:
2016/09/30 13:30:55.266 kid1| 83,2| client_side.cc(3764) clientNegotiateSSL: clientNegotiateSSL: Session 0x8331ee98 reused on FD 40 (10.215.144.48:21962)
2016/09/30 13:30:55.266 kid1| 83,3| client_side.cc(3800) clientNegotiateSSL: clientNegotiateSSL: FD 40 negotiated cipher AES256-GCM-SHA384
2016/09/30 13:30:55.267 kid1| 83,5| client_side.cc(3816) clientNegotiateSSL: clientNegotiateSSL: FD 40 has no certificate.


Any more ideas?

Vieri


From rentorbuy at yahoo.com  Fri Sep 30 11:49:49 2016
From: rentorbuy at yahoo.com (Vieri)
Date: Fri, 30 Sep 2016 11:49:49 +0000 (UTC)
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
 code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
 <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
Message-ID: <2107546723.2074207.1475236189870@mail.yahoo.com>

Maybe my previous post was too long. Simply put, why doesn't Squid negotiate the DES-CBC3-SHA cipher instead of RC4-MD5?


Vieri


From yvoinov at gmail.com  Fri Sep 30 11:56:43 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 30 Sep 2016 17:56:43 +0600
Subject: [squid-users] FW: squid tproxy ssl-bump and Protocol error (TLS
 code: SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <2077594026.2082495.1475235384241@mail.yahoo.com>
References: <414102480.6739156.1475150556309.ref@mail.yahoo.com>
 <414102480.6739156.1475150556309@mail.yahoo.com>
 <056101d21aa0$16b13f10$4413bd30$@ngtech.co.il>
 <a901bd9b-6643-0088-7ee8-a4336094be90@treenet.co.nz>
 <2077594026.2082495.1475235384241@mail.yahoo.com>
Message-ID: <af92d108-b205-decb-13c4-fecb7a554b5e@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 


30.09.2016 17:36, Vieri ?????:
> Hi,
>
> ----- Original Message -----
>> From: Amos Jeffries <squid3 at treenet.co.nz>
>>
>> Squid mimics the client details when contacting the server. So you would
>
>> get the same problem (though maybe different description) if going
>
>> directly without the proxy.
>
>
> If I try connecting to https://www.google.com with this client and
going directly without proxy then I have no problem whatsoever. I'm sure
any Windows XP user still out there with IE8 can confirm that a direct
connection to https://www.google.com still works fine. I hit the issue
only when using Squid.
>
>
> So from the squid server I ran:
>
> # nmap --script ssl-enum-ciphers google.com
> [...]
> | ssl-enum-ciphers:
> |   TLSv1.0:
> |     ciphers:
> |       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA - strong
> |       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA - strong
> |       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong
> |       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong
> |       TLS_RSA_WITH_3DES_EDE_CBC_SHA - strong
> |       TLS_RSA_WITH_AES_128_CBC_SHA - strong
> |       TLS_RSA_WITH_AES_256_CBC_SHA - strong
> |     compressors:
> |
> |   TLSv1.1:
> |     ciphers:
> |       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA - strong
> |       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA - strong
> |       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong
> |       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong
> |       TLS_RSA_WITH_3DES_EDE_CBC_SHA - strong
> |       TLS_RSA_WITH_AES_128_CBC_SHA - strong
> |       TLS_RSA_WITH_AES_256_CBC_SHA - strong
> |     compressors:
> |
> |   TLSv1.2:
> |     ciphers:
> |       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA - strong
> |       TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 - strong
> |       TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 - strong
> |       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA - strong
> |       TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384 - strong
> |       TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 - strong
> |       TLS_ECDHE_ECDSA_WITH_CHACHA20_POLY1305_SHA256 - strong
> |       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA - strong
> |       TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 - strong
> |       TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 - strong
> |       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA - strong
> |       TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 - strong
> |       TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 - strong
> |       TLS_ECDHE_RSA_WITH_CHACHA20_POLY1305_SHA256 - strong
> |       TLS_RSA_WITH_3DES_EDE_CBC_SHA - strong
> |       TLS_RSA_WITH_AES_128_CBC_SHA - strong
> |       TLS_RSA_WITH_AES_128_CBC_SHA256 - strong
> |       TLS_RSA_WITH_AES_128_GCM_SHA256 - strong
> |       TLS_RSA_WITH_AES_256_CBC_SHA - strong
> |       TLS_RSA_WITH_AES_256_CBC_SHA256 - strong
> |       TLS_RSA_WITH_AES_256_GCM_SHA384 - strong
> |     compressors:
> |
> |_  least strength: strong
>
>
> So if TLS 1.0 is supported by Google then the Windows XP clients
should be able to connect.
>
>
> Can a cipher issue trigger the error message "Handshake with SSL
server failed: error:1409F07F:SSL routines:ssl3_write_pending:bad write
retry"?
>
> I ran:
>
> # openssl ciphers
>
ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:SRP-DSS-AES-256-CBC-SHA:SRP-RSA-AES-256-CBC-SHA:SRP-AES-256-CBC-SHA:DH-DSS-AES256-GCM-SHA384:DHE-DSS-AES256-GCM-SHA384:DH-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA256:DH-RSA-AES256-SHA256:DH-DSS-AES256-SHA256:DHE-RSA-AES256-SHA:DHE-DSS-AES256-SHA:DH-RSA-AES256-SHA:DH-DSS-AES256-SHA:DHE-RSA-CAMELLIA256-SHA:DHE-DSS-CAMELLIA256-SHA:DH-RSA-CAMELLIA256-SHA:DH-DSS-CAMELLIA256-SHA:ECDH-RSA-AES256-GCM-SHA384:ECDH-ECDSA-AES256-GCM-SHA384:ECDH-RSA-AES256-SHA384:ECDH-ECDSA-AES256-SHA384:ECDH-RSA-AES256-SHA:ECDH-ECDSA-AES256-SHA:AES256-GCM-SHA384:AES256-SHA256:AES256-SHA:CAMELLIA256-SHA:PSK-AES256-CBC-SHA:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:SRP-DSS-AES-128-CBC-SHA:SRP-RSA-AES-128-CBC-SHA:SRP-AES-128-CBC-SHA:DH-DSS-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:DH-RSA-AES128-GCM-SHA256:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES128-SHA256:DHE-DSS-AES128-SHA256:DH-RSA-AES128-SHA256:DH-DSS-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA:DH-RSA-AES128-SHA:DH-DSS-AES128-SHA:DHE-RSA-SEED-SHA:DHE-DSS-SEED-SHA:DH-RSA-SEED-SHA:DH-DSS-SEED-SHA:DHE-RSA-CAMELLIA128-SHA:DHE-DSS-CAMELLIA128-SHA:DH-RSA-CAMELLIA128-SHA:DH-DSS-CAMELLIA128-SHA:ECDH-RSA-AES128-GCM-SHA256:ECDH-ECDSA-AES128-GCM-SHA256:ECDH-RSA-AES128-SHA256:ECDH-ECDSA-AES128-SHA256:ECDH-RSA-AES128-SHA:ECDH-ECDSA-AES128-SHA:AES128-GCM-SHA256:AES128-SHA256:AES128-SHA:SEED-SHA:CAMELLIA128-SHA:IDEA-CBC-SHA:PSK-AES128-CBC-SHA:KRB5-IDEA-CBC-SHA:KRB5-IDEA-CBC-MD5:ECDHE-RSA-RC4-SHA:ECDHE-ECDSA-RC4-SHA:ECDH-RSA-RC4-SHA:ECDH-ECDSA-RC4-SHA:RC4-SHA:RC4-MD5:PSK-RC4-SHA:KRB5-RC4-SHA:KRB5-RC4-MD5:ECDHE-RSA-DES-CBC3-SHA:ECDHE-ECDSA-DES-CBC3-SHA:SRP-DSS-3DES-EDE-CBC-SHA:SRP-RSA-3DES-EDE-CBC-SHA:SRP-3DES-EDE-CBC-SHA:EDH-RSA-DES-CBC3-SHA:EDH-DSS-DES-CBC3-SHA:DH-RSA-DES-CBC3-SHA:DH-DSS-DES-CBC3-SHA:ECDH-RSA-DES-CBC3-SHA:ECDH-ECDSA-DES-CBC3-SHA:DES-CBC3-SHA:PSK-3DES-EDE-CBC-SHA:KRB5-DES-CBC3-SHA:KRB5-DES-CBC3-MD5:EDH-RSA-DES-CBC-SHA:EDH-DSS-DES-CBC-SHA:DH-RSA-DES-CBC-SHA:DH-DSS-DES-CBC-SHA:DES-CBC-SHA:KRB5-DES-CBC-SHA:KRB5-DES-CBC-MD5
>
>
> # openssl s_client -connect google.com:443 -tls1
> [...]
> SSL-Session:
> Protocol  : TLSv1
> Cipher    : ECDHE-RSA-AES128-SHA
>
> [...]
>
> I also tried the following on the Squid server:
>
> # curl --tlsv1.0 --trace trace.log https://www.google.com && grep "SSL
connection using" trace.log[...]
> == Info: SSL connection using TLSv1.0 / ECDHE-RSA-AES128-SHA
> [...]
>
> From the Windows XP IE8 client I connected to this web site to quickly
see all the supported protocols and ciphers:
> https://www.ssllabs.com/ssltest/viewMyClient.html
> I can see TLS 1.0 support and the following cipher list:
>
> TLS_RSA_WITH_RC4_128_MD5 (0x4)   INSECURE 128
> TLS_RSA_WITH_RC4_128_SHA (0x5)   INSECURE 128
> TLS_RSA_WITH_3DES_EDE_CBC_SHA (0xa)  112
> TLS_RSA_WITH_DES_CBC_SHA (0x9)   WEAK 56
> TLS_RSA_EXPORT1024_WITH_RC4_56_SHA (0x64)   INSECURE 56
> TLS_RSA_EXPORT1024_WITH_DES_CBC_SHA (0x62)   WEAK 56
> TLS_RSA_EXPORT_WITH_RC4_40_MD5 (0x3)   INSECURE 40
> TLS_RSA_EXPORT_WITH_RC2_CBC_40_MD5 (0x6)   INSECURE 40
> TLS_DHE_DSS_WITH_3DES_EDE_CBC_SHA (0x13)   Forward Secrecy2  112
> TLS_DHE_DSS_WITH_DES_CBC_SHA (0x12)   WEAK 56
> TLS_DHE_DSS_EXPORT1024_WITH_DES_CBC_SHA (0x63)   WEAK 56
>
>
> On a Windows 7 IE8 client with no Squid proxy issues I can see the
following list of ciphers:
>
> TLS_RSA_WITH_AES_128_CBC_SHA256 (0x3c)  128
> TLS_RSA_WITH_AES_128_CBC_SHA (0x2f)  128
> TLS_RSA_WITH_AES_256_CBC_SHA256 (0x3d)  256
> TLS_RSA_WITH_AES_256_CBC_SHA (0x35)  256
> TLS_RSA_WITH_RC4_128_SHA (0x5)   INSECURE 128
> TLS_RSA_WITH_3DES_EDE_CBC_SHA (0xa)  112
> TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 (0xc027)   Forward Secrecy  128
> TLS_ECDHE_RSA_WITH_AES_128_CBC_SHA (0xc013)   Forward Secrecy  128
> TLS_ECDHE_RSA_WITH_AES_256_CBC_SHA (0xc014)   Forward Secrecy  256
> TLS_ECDHE_ECDSA_WITH_AES_128_GCM_SHA256 (0xc02b)   Forward Secrecy  128
> TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA256 (0xc023)   Forward Secrecy  128
> TLS_ECDHE_ECDSA_WITH_AES_256_GCM_SHA384 (0xc02c)   Forward Secrecy  256
> TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA384 (0xc024)   Forward Secrecy  256
> TLS_ECDHE_ECDSA_WITH_AES_128_CBC_SHA (0xc009)   Forward Secrecy  128
> TLS_ECDHE_ECDSA_WITH_AES_256_CBC_SHA (0xc00a)   Forward Secrecy  256
> TLS_DHE_DSS_WITH_AES_128_CBC_SHA256 (0x40)   Forward Secrecy2  128
> TLS_DHE_DSS_WITH_AES_128_CBC_SHA (0x32)   Forward Secrecy2  128
> TLS_DHE_DSS_WITH_AES_256_CBC_SHA256 (0x6a)   Forward Secrecy2  256
> TLS_DHE_DSS_WITH_AES_256_CBC_SHA (0x38)   Forward Secrecy2  256
> TLS_DHE_DSS_WITH_3DES_EDE_CBC_SHA (0x13)   Forward Secrecy2  112
> TLS_RSA_WITH_RC4_128_MD5 (0x4)   INSECURE 128
>
>
> I suppose that the Windows XP client successfully connects to
https://www.google.com because it uses TLS_RSA_WITH_3DES_EDE_CBC_SHA
(when NOT using Squid). Am I right? Is there a way I can confirm that?
>
>
> So, back on the squid server I checked the openssl ciphers for one
that is supported by the Windows XP system. I searched for the oepnssl
cipher name from the RFC cipher name at
https://testssl.sh/openssl-rfc.mappping.html.
>
> I found the following:
> TLS_RSA_WITH_3DES_EDE_CBC_SHA = DES-CBC3-SHA
> The other "strong" cipher supported by Windows XP seems to be:
> TLS_DHE_DSS_WITH_3DES_EDE_CBC_SHA = EDH-DSS-DES-CBC3-SHA
>
>
> # curl --tlsv1.0 --ciphers SRP-RSA-3DES-EDE-CBC-SHA --trace trace.log
https://www.google.com
> curl: (35) error:140740B5:SSL routines:SSL23_CLIENT_HELLO:no ciphers
available
>
>
> So I tried these commands on the Squid server:
>
> # openssl s_client -connect google.com:443 -tls1 -cipher DES-CBC3-SHA
> [...]
> SSL-Session:
> Protocol  : TLSv1
> Cipher    : DES-CBC3-SHA
>
> [...]
> (that went well)
>
>
> # openssl s_client -connect google.com:443 -tls1 -cipher
EDH-DSS-DES-CBC3-SHA
>
> CONNECTED(00000003)
> 3072018108:error:14094410:SSL routines:ssl3_read_bytes:sslv3 alert
handshake failure:s3_pkt.c:1472:SSL alert number 40
> 3072018108:error:1409E0E5:SSL routines:ssl3_write_bytes:ssl handshake
failure:s3_pkt.c:656:
>
>
> So this failed. Why?
> Is google wrongly advertising the supported cipher (I doubt it)?
>
> I have OpenSSL 1.0.2d 9 Jul 2015 and Squid 3.5.14.
>
> How do I know if Squid is also trying to use the same cipher
EDH-DSS-DES-CBC3-SHA instead of DES-CBC3-SHA?
>
> I tried setting debug_options rotate=1 ALL,5 but found nothing related
to the cipher in the log:
>
> # tail -n 1000000 /var/log/squid/cache.log | grep "10.215.144.47" |
grep -i cipher
>
>> To get around this you require the latest Squid version (with>
peek-and-splice feature) doing the "bump" action on these clients
>
>> traffic so that it can upgrade the TLS/SSL handshake and use some
>> ciphers etc the server will accept on their connections.
>
> I'm already using sslbump with squid 3.5. As posted in my first
message I have:
> https_port 3130 tproxy ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=16MB cert=/etc/ssl/squid/proxyserver.pem
>
> How can I tell which TLS/cipher versions Squid is using? What exactly
should I search for in the log?
>
> I tried this while connecting from the Windows XP client:
> # watch -n 1 "tail -n 10000 /var/log/squid/cache.log | grep
clientNegotiateSSL"
> 2016/09/30 13:19:06.633 kid1| 83,2| client_side.cc(3796)
clientNegotiateSSL: clientNegotiateSSL: New session 0x870088d8 on FD 151
(10.215.144.47:1649)
> 2016/09/30 13:19:06.633 kid1| 83,3| client_side.cc(3800)
clientNegotiateSSL: clientNegotiateSSL: FD 151 negotiated cipher RC4-MD5
> 2016/09/30 13:19:06.633 kid1| 83,5| client_side.cc(3816)
clientNegotiateSSL: clientNegotiateSSL: FD 151 has no certificate.
>
>
> Why is Squid negotiating cipher RC4-MD5 which is reported "insecure"
and unsupported by the google web site?
Because your antique client request it. XP desupported years ago.
>
>
>
> I finally tried this on the Squid server:
>
> # openssl s_client -connect google.com:443 -tls1 -cipher RC4-MD5
> CONNECTED(00000003)
> 3071960764:error:14094410:SSL routines:ssl3_read_bytes:sslv3 alert
handshake failure:s3_pkt.c:1472:SSL alert number 40
> 3071960764:error:1409E0E5:SSL routines:ssl3_write_bytes:ssl handshake
failure:s3_pkt.c:656:
>
>
> If I watch the Squid log when performing a connection to google from a
Windows 7 IE8 with no issues, I get this:
> 2016/09/30 13:30:55.266 kid1| 83,2| client_side.cc(3764)
clientNegotiateSSL: clientNegotiateSSL: Session 0x8331ee98 reused on FD
40 (10.215.144.48:21962)
> 2016/09/30 13:30:55.266 kid1| 83,3| client_side.cc(3800)
clientNegotiateSSL: clientNegotiateSSL: FD 40 negotiated cipher
AES256-GCM-SHA384
> 2016/09/30 13:30:55.267 kid1| 83,5| client_side.cc(3816)
clientNegotiateSSL: clientNegotiateSSL: FD 40 has no certificate.
>
>
> Any more ideas?
Throw out XP and IE8 and set up W7 as minimum with IE10. I see no other
way. I am afraid that in this case, the cactus is too large and inedible.
>
>
> Vieri
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX7lL7AAoJENNXIZxhPexGw5oIALIpfdV1EESJFy3h92PkKgSH
10/swwaKKzDT3mOcPVSAW6V4y6M8H9MGvR8oUHws1RnHrSsOcdwAoFrlKgRdHmvP
B51iuyrIas/QdOmjuCm5UFYE/ZxAqcMfcyyqC7Y9+ctyRClG16Kn8mdyxwDioqfq
Qv+NNP8X216t/7enO99oUam/Q3sBowfo/r2ZR2zbsTWiM9o7TQLl9rPOrhSsVu8M
K8/dmzGvk2J8KPJQBp5nZNvzt9+pyoulQwMywg7vlsoCUC7MCal/CzgcdW9jLGy8
pjLFV385VoS2CJCIx3ORDJE0NlUfaEzfu+/Ihwic2jZGQOSZVNcD2N+rjvSyarA=
=nXdM
-----END PGP SIGNATURE-----

-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/0671979f/attachment.key>

From yvoinov at gmail.com  Fri Sep 30 12:19:03 2016
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 30 Sep 2016 18:19:03 +0600
Subject: [squid-users] Squid 3.5.21 for Microsoft Windows 64-bit is
 available
In-Reply-To: <DB6PR0401MB2680B214A6F1B0D482C80CF58FC10@DB6PR0401MB2680.eurprd04.prod.outlook.com>
References: <DB6PR0401MB2680B214A6F1B0D482C80CF58FC10@DB6PR0401MB2680.eurprd04.prod.outlook.com>
Message-ID: <58d2ae8a-a660-3702-7905-47097576f1ab@gmail.com>


-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256
 
Yup, Raf, sure. Thank you!


30.09.2016 13:37, Rafael Akchurin ?????:
>
> Greetings everyone,
>
> 
>
> @yuri Sorry for being so late, we had some issues compiling this
version :(
>
> 
>
> ----
>
> For those wishing to have Squid 3.5.19 recompiled with HTTPS filtering
support see
https://github.com/diladele/squid-ubuntu#how-to-use-the-repository-at-ubuntu16diladelecom-for-ubuntu-16.
>
> Note, we still have 3.5.19 in the repository because we actually
rebuild the package from Debian 8 testing and it still is not updated.
>
> ----
>
> 
>
> The CygWin based build of Squid proxy for Microsoft Windows version
3.5.21 is now available (amd64 only!).
>
> 
>
> * Original release notes are at
http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.21-RELEASENOTES.html.
>
> * Ready to use MSI package can be downloaded from
http://squid.diladele.com.
>
> * List of open issues for the installer -
https://github.com/diladele/squid3-windows/issues
>
> 
>
> Thanks a lot for Squid developers for making this great software!
>
> 
>
> Please join our humble efforts to provide ready to run MSI installer
for Squid on Microsoft Windows with all required dependencies at GitHub -
>
> https://github.com/diladele/squid3-windows. Please report all
issues/bugs/feature requests at GitHub project. Issues about the *MSI
installer only* can also be reported to support at diladele.com
<mailto:support at diladele.com>.
>
> 
>
> Best regards,
>
> Rafael Akchurin
>
> Diladele B.V.
>
> https://www.diladele.com
>
> 
>
> --
>
> Please take a look at Web Safety - our ICAP based web filter server
for Squid proxy.
>
> 
>
> 
>
> 
>
> 
>
> 
>
> 
>
> 
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2
 
iQEcBAEBCAAGBQJX7lg3AAoJENNXIZxhPexGT68IAI1YEBu0qrmZI0b0aJcOyvma
MyzTmHKwUOF8x8XjNzoVwyCaAAUQ26q2SbTC7ubyHYAyc5JnZMlt/UwjQ6WvzD+6
Blfcafw07lI43IAiLQoWeaDKwbmwN7uAb+VpcDXdSuLo/oXAHxI3kFGGRXjc0sp9
pLid8O55bdzf3Dk8ehQq8XzfIV8VMbURwGT6uQuZ9j2oe7CAggL3L15AmFJFpi6P
CO3dIRCbUyx8Cd6ycy5IHrC12ay4b9pGtfWBOPeVCtgodJim7S/FDG9qYE/JGWQp
FHjd3sHNZtMrHVN8Ng0leT9ut1NHNbG1kRZPyH+ue9X9+k0zjrQPPp64yxa4utY=
=8FhK
-----END PGP SIGNATURE-----

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/ef032e76/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/ef032e76/attachment.key>

From vero.ovando at live.com  Fri Sep 30 12:43:41 2016
From: vero.ovando at live.com (=?iso-8859-1?Q?Ver=F3nica_Ovando?=)
Date: Fri, 30 Sep 2016 12:43:41 +0000
Subject: [squid-users] What to do with Squid after upgrading domain
	controller?
Message-ID: <BN3PR0801MB22912BB7483C3353149485A89EC10@BN3PR0801MB2291.namprd08.prod.outlook.com>

I have Squid 3.4.8 using AD authentication, but now I need to upgrade my domain controller from Win Server 2008 to Win Server 2012.

Is there something to do with Squid to prevent broken auths? Do I need to rejoin my Squid box?

For testing purposes, I tried to use my Squid (working with AD auths) with a backup of my current DC (Server 2008) and did not work. Only the hosts accessing to internet by IP number worked well, but not windows users.

Because of this situation, I want to prevent some issues before upgrading.


Thanks in advance.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/98c8579a/attachment.htm>

From alex at delgado-lucas.com  Fri Sep 30 12:48:02 2016
From: alex at delgado-lucas.com (Alex Delgado)
Date: Fri, 30 Sep 2016 12:48:02 +0000
Subject: [squid-users] What to do with Squid after upgrading
	domain	controller?
In-Reply-To: <BN3PR0801MB22912BB7483C3353149485A89EC10@BN3PR0801MB2291.namprd08.prod.outlook.com>
References: <BN3PR0801MB22912BB7483C3353149485A89EC10@BN3PR0801MB2291.namprd08.prod.outlook.com>
Message-ID: <DB6PR1001MB1159C12A1C4650F52F51E8C980C10@DB6PR1001MB1159.EURPRD10.PROD.OUTLOOK.COM>

Hi Ver?nica,


Wich manual do you used to do authenticacion?


I'm trying to do so, but can't find it to do right.


Regards,


________________________________
De: squid-users <squid-users-bounces at lists.squid-cache.org> en nombre de Ver?nica Ovando <vero.ovando at live.com>
Enviado: viernes, 30 de septiembre de 2016 12:43
Para: squid-users at lists.squid-cache.org
Asunto: [squid-users] What to do with Squid after upgrading domain controller?


I have Squid 3.4.8 using AD authentication, but now I need to upgrade my domain controller from Win Server 2008 to Win Server 2012.

Is there something to do with Squid to prevent broken auths? Do I need to rejoin my Squid box?

For testing purposes, I tried to use my Squid (working with AD auths) with a backup of my current DC (Server 2008) and did not work. Only the hosts accessing to internet by IP number worked well, but not windows users.

Because of this situation, I want to prevent some issues before upgrading.


Thanks in advance.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/27c08d50/attachment.htm>

From guy.helmer at gmail.com  Fri Sep 30 13:08:39 2016
From: guy.helmer at gmail.com (Guy Helmer)
Date: Fri, 30 Sep 2016 08:08:39 -0500
Subject: [squid-users] connections from particular users sometimes get
	stuck
In-Reply-To: <57EE084F.6020505@norma.perm.ru>
References: <42b972b9-77a7-f43d-1630-fe31a71ab508@norma.perm.ru>
 <57EB7DAC.9000408@norma.perm.ru>
 <f81aae25-958a-b8f4-2b28-5a0daecc1f71@measurement-factory.com>
 <201609281741.54358.Antony.Stone@squid.open.source.it>
 <7280391c-a10c-8eb9-c41a-4f924600dda8@measurement-factory.com>
 <c14e1d4d-bff7-6ea2-dd8c-82a9663b1c19@norma.perm.ru>
 <57ECD7A9.60607@norma.perm.ru>
 <5ec198bf-ae59-1972-698b-591a575285bc@measurement-factory.com>
 <57EE084F.6020505@norma.perm.ru>
Message-ID: <6476A19E-E24A-400C-95D5-585D80F1FE25@gmail.com>

On Sep 30, 2016, at 1:38 AM, Eugene M. Zheganin <emz at norma.perm.ru> wrote:
> 
> Hi.
> 
>>> 13:31:25.060 kid1| accept failure: (53) Software caused connection abort
>>> 13:31:25.865 kid1| accept failure: (53) Software caused connection abort
>>> 13:31:25.904 kid2| accept failure: (53) Software caused connection abort
>> The timestamps are a ~second off, but AFAICT, they are a ~second off for
>> successful accepts as well, so it is probably just a tcpdump logging
>> artifact.
>> 
>> In summary, your browser is probably stuck because Squid could not
>> accept a connection. Why did that accept call fail with ECONNABORTED? I
>> cannot say for sure -- the packet trace is rather dirty/misleading
>> (e.g., it shows the redirect packet being sent to the client _after_ the
>> client follows that redirect which does not make sense).
>> 
>> Any relevant errors in you system logs?
> Nothing except
> 
> Limiting closed port RST response from 294 to 200 packets/sec

Sometimes I have noticed odd problems when this appears ? I?m thinking that on occasion there may be a necessary RST that is being ignored and causing a client connection to ?hang?. The ?net.inet.icmp.icmplim? sysctl limits the ICMP response rate to RST packets received for ports that are not open ? perhaps increase that from the default of 200 to 400 and see if it helps.

Otherwise, are you using dynamic IPFW rules that involve the ports used by squid? I?ve had some issues with those in the past (timeouts or maximum numbers of rules exceeded), so I?ve switched to using static IPFW rules for connections in and out of squid to avoid issues.

Guy



From rafael.akchurin at diladele.com  Fri Sep 30 14:05:26 2016
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Fri, 30 Sep 2016 14:05:26 +0000
Subject: [squid-users] What to do with Squid after
	upgrading	domain	controller?
In-Reply-To: <DB6PR1001MB1159C12A1C4650F52F51E8C980C10@DB6PR1001MB1159.EURPRD10.PROD.OUTLOOK.COM>
References: <BN3PR0801MB22912BB7483C3353149485A89EC10@BN3PR0801MB2291.namprd08.prod.outlook.com>
 <DB6PR1001MB1159C12A1C4650F52F51E8C980C10@DB6PR1001MB1159.EURPRD10.PROD.OUTLOOK.COM>
Message-ID: <DB6PR0401MB26804873ACCA6999692D76138FC10@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Hello Alex,

I would humbly propose our manual - https://docs.diladele.com/administrator_guide_4_6/active_directory/index.html
But please take a look at Squid wiki too - http://wiki.squid-cache.org/ConfigExamples/Authenticate/WindowsActiveDirectory

Best regards,
Rafael Akchurin
Diladele B.V.

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Alex Delgado
Sent: Friday, September 30, 2016 2:48 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] What to do with Squid after upgrading domain controller?


Hi Ver?nica,



Wich manual do you used to do authenticacion?



I'm trying to do so, but can't find it to do right.



Regards,

________________________________
De: squid-users <squid-users-bounces at lists.squid-cache.org<mailto:squid-users-bounces at lists.squid-cache.org>> en nombre de Ver?nica Ovando <vero.ovando at live.com<mailto:vero.ovando at live.com>>
Enviado: viernes, 30 de septiembre de 2016 12:43
Para: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Asunto: [squid-users] What to do with Squid after upgrading domain controller?


I have Squid 3.4.8 using AD authentication, but now I need to upgrade my domain controller from Win Server 2008 to Win Server 2012.

Is there something to do with Squid to prevent broken auths? Do I need to rejoin my Squid box?

For testing purposes, I tried to use my Squid (working with AD auths) with a backup of my current DC (Server 2008) and did not work. Only the hosts accessing to internet by IP number worked well, but not windows users.

Because of this situation, I want to prevent some issues before upgrading.



Thanks in advance.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/e26450fc/attachment.htm>

From rousskov at measurement-factory.com  Fri Sep 30 15:12:46 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 30 Sep 2016 09:12:46 -0600
Subject: [squid-users] connections from particular users sometimes get
 stuck
In-Reply-To: <57EE084F.6020505@norma.perm.ru>
References: <42b972b9-77a7-f43d-1630-fe31a71ab508@norma.perm.ru>
 <57EB7DAC.9000408@norma.perm.ru>
 <f81aae25-958a-b8f4-2b28-5a0daecc1f71@measurement-factory.com>
 <201609281741.54358.Antony.Stone@squid.open.source.it>
 <7280391c-a10c-8eb9-c41a-4f924600dda8@measurement-factory.com>
 <c14e1d4d-bff7-6ea2-dd8c-82a9663b1c19@norma.perm.ru>
 <57ECD7A9.60607@norma.perm.ru>
 <5ec198bf-ae59-1972-698b-591a575285bc@measurement-factory.com>
 <57EE084F.6020505@norma.perm.ru>
Message-ID: <35294bd8-93cf-0ff6-b155-d973cd8e99c1@measurement-factory.com>

On 09/30/2016 12:38 AM, Eugene M. Zheganin wrote:
> And the
> main sign indicating there's something wrong with this initial
> transaction was the fact that 407 answer took 42 seconds to appear in
> both tcpdump captures.

To avoid misunderstanding: There are many red flags in your logs,
including excessive processing delays. I am ignoring the ones that do
not appear to be related to the "stuck browser" problem.


>>> tcpdump capture taken from a client machine:
>>> http://zhegan.in/files/squid/squid-stuck-client.pcap

>> This capture one is missing most of the second transaction packets
>> (tcp.stream eq 186). I do not know why tcpdump was unable to collect them.

> This is because of the gap between Ctrl^C issued in the client machine
> cmd console and squid server ssh console (in this exact order) - I had
> to switch between windows on my desktop, and because about a minute has
> passed since the beginning of the transaction (42 seconds plus quite
> some time), and I was worried that the debug log will grow more and
> more, making it difficult to navigate then.

Please do not worry about log navigation -- you are already posting logs
with 95+% of irrelevant transactions; adding 2% more would make no
difference. Focus on collecting complete logs. However, please
_compress_ your logs before posting them.


>> In summary, your browser is probably stuck because Squid could not
>> accept a connection. Why did that accept call fail with ECONNABORTED?

>> If you cancel browser wait and repeat the request, will it work?

> Sometimes, but this means like 3-5% percents. 

This may be your pathway to the answer! A _random_ ECONNABORTED
accept(2) error would have a ~100% probability of disappearing on the
second attempt. Your observations seem to confirm that this error
(assuming Squid gets ECONNABORTED for all stuck transactions) is caused
by something on that client or something between that specific client
and Squid.

We obviously do not know what is wrong yet, but just for the sake of an
example, consider a mismatching negotiated Ethernet settings that lead
to packet loss and similar low-level problems that lead to TCP accept(2)
errors from Squid point of view. Again, I am not claiming that this is
what is going on.


> Most of the time
> rerequests lead to the same timeout, Chrome shows the request is
> "pending" in the developer's tools/network tab for dozens of seconds,
> and so on.

Very good. This is something we can use to investigate.



> I still have this machine in stuck state (I think), what should I focus on ?

I recommend the following:

0. Start capturing to/from-Squid packets on the client machine.
   Make sure tcpdump does not do DNS resolution (if applicable).
1. Start capturing to/from-clientS packets on the Squid machine.
   Make sure tcpdump does not do DNS resolution (if applicable).
2. Start Squid debugging.

3. On both machines (if possible):
   Collect "netstat -s" or equivalent TCP stack stats.
   Collect "ifconfig ..." or equivalent high-level interface stats.
   Collect "ethtool -s ..." or equivalent low-level interface stats.

4. Reproduce the problem. Wait until Chrome times out.

5. On both machines (if possible):
   Collect "netstat -s" or equivalent TCP stack stats.
   Collect "ifconfig ..." or equivalent high-level interface stats.
   Collect "ethtool -s ..." or equivalent low-level interface stats.

6. Rereproduce the problem. Wait until Chrome times out.
   If possible, use a slightly different URL for this test.
   For example, append "?test2" to the URL in #4, assuming
   that will not screw things up.

7. On both machines (if possible):
   Collect "netstat -s" or equivalent TCP stack stats.
   Collect "ifconfig ..." or equivalent high-level interface stats.
   Collect "ethtool -s ..." or equivalent low-level interface stats.

8. Wait 60 seconds.

9. Stop all captures and Squid debugging.
10. Archive, compress, and share all the logs and the test URL(s).
    When archiving, please preserve file modification times for
    logs from steps 3,5,7.

Adjust the procedure as needed, of course.

Alex.



From oagvozd at gmail.com  Fri Sep 30 16:42:24 2016
From: oagvozd at gmail.com (oleg gv)
Date: Fri, 30 Sep 2016 19:42:24 +0300
Subject: [squid-users] Squid-3.5.21: filter FTP content or FTP commands
Message-ID: <CAFfuDwzpSgAOGwBBEyKtdv_7GF=Lt7muU_wL7ovH=8ED2Fm7zQ@mail.gmail.com>

Hello, I've found that NativeFtpRelay appeared in squid 3.5 . Is it
possible to apply http-access acl for FTP proto concerning filtering of FTP
methods(commands) by analogy of HTTP methods ?

For example, I need to deny FTP CD command:

acl m method CD
acl p proto FTP
http-access deny m p
http-access permit all

If it is not possible - what other possibilities in squid exist to do this ?

May be in future ?

Thanks!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/4f4b5031/attachment.htm>

From michael.pelletier at palmbeachschools.org  Fri Sep 30 16:51:39 2016
From: michael.pelletier at palmbeachschools.org (Michael Pelletier)
Date: Fri, 30 Sep 2016 12:51:39 -0400
Subject: [squid-users] No matter what I do I can not get %ssl:>sni (or
 other %ssl) to log
In-Reply-To: <e89aee4f-51c4-b689-9185-bbebcc9ccc05@treenet.co.nz>
References: <CAEnCSG5pRx93x45-RN98by-OR1D5TmimRhRrcj99+VTV5oUpzQ@mail.gmail.com>
 <9d59d390-9c53-8b2a-9f14-11d89c545450@measurement-factory.com>
 <CAEnCSG4MMezEOrNA0uXqZhi4EeEc9V+pU-rnu2aTp4HvfpAvZQ@mail.gmail.com>
 <CAEnCSG5_448kytKSzOGJ7zbWO_ptEinBV1-SN+FmMSn+ai37Jg@mail.gmail.com>
 <7d4fdc9a-a665-284d-40d6-dc7b2ca20725@measurement-factory.com>
 <e89aee4f-51c4-b689-9185-bbebcc9ccc05@treenet.co.nz>
Message-ID: <CAEnCSG7tGb=Xa2LHX5RAYrryRAR-GrUoDfUWfnxwZqMMwWwhBg@mail.gmail.com>

Thanks!

On Thu, Sep 29, 2016 at 11:12 PM, Amos Jeffries <squid3 at treenet.co.nz>
wrote:

> On 30/09/2016 12:55 p.m., Alex Rousskov wrote:
> > On 09/29/2016 05:44 PM, Michael Pelletier wrote:
> >> In the squid.conf.documented, it looks like I can log the server
> >> certificate as well as the client certificate....
> >>
> >> #         %ssl::<cert_subject SSL server certificate DN
> >> #         %ssl::<cert_issuer SSL server certificate issuer DN
> >
> > Wrong directive? The above %codes were for the external_acl_type
> > context, not logformat IIRC.
> >
> > I do not know whether they are still supported in v4 but no longer
> > documented (which would be a [documentation] bug) or not supported at
> > all (which would be a [regression] bug).
> >
>
> With Squid-4 the ACl and log format codes should be the same now.
> Perhapse more info at logging time than helper API, but thats all.
>
> * Things available to the ACL but not at logging is a bug, probably a
> regression.
> * Things that used to log but no longer do are regressions.
> * Otherwise things that should be available but are not at the helper
> ACL time are missing feature bugs.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>

-- 


*Disclaimer: *Under Florida law, e-mail addresses are public records. If 
you do not want your e-mail address released in response to a public 
records request, do not send electronic mail to this entity. Instead, 
contact this office by phone or in writing.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/4d0cc7dc/attachment.htm>

From squid3 at treenet.co.nz  Fri Sep 30 17:35:42 2016
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 1 Oct 2016 06:35:42 +1300
Subject: [squid-users] External nat'ed transparent proxy
In-Reply-To: <57a01083-d569-cd4b-9d42-b6dc619cfd7c@nitronetworks.nl>
References: <9cb02f45-ad81-7d77-0d7a-cf313c34f4fd@nitronetworks.nl>
 <20160930103642.GB29597@fantomas.sk>
 <57a01083-d569-cd4b-9d42-b6dc619cfd7c@nitronetworks.nl>
Message-ID: <262ddf06-6781-a49b-335a-11a807a0ce73@treenet.co.nz>

On 1/10/2016 12:27 a.m., Henry Paulissen wrote:
> Hi Matus,
> 
> 
> On 30-09-16 12:36, Matus UHLAR - fantomas wrote:
>> On 29.09.16 16:39, Henry Paulissen wrote:
>>> In the company I work for we are currently using squid v2 proxies in
>>> transparent mode to intercept traffic from servers to the outside
>>> (access control).
>>>
>>> The technical solution for this is roughly as follows:
>>> [server] -> [gateway] -> [firewall]
>>>                              |
>>>    ----------- DNAT ---------
>>>   v
>>> [squid]  -> [gateway] -> [firewall] -> [internet router]
>>
>> this is a bad configuration. The firewall in the path should NOT use DNAT,
>> since it makes the important part of connection (destination IP) invisible
>> to squid.
>>
> 
> That is where the HTTP Host header can be used for... For squid to
> figure out the destination of the request. (aren?t they?)

That is what it was intended for 20 or so years ago. But times change
and nowdays we have to deal with browsers that can be sent a scimple
script and instructed to do all sorts of nasty things in the traffic. If
you want the gory details you can find my prvious answers to people
asking this same question repeatedly over the last 5 years.

The TL;DR is: no, that is no longer safe to do and Squid will not do it
any more. Simply dont use DNAT on the port 80 (or 443) packets before
they hit the machine running Squid. Routing is a more powerful feature
than most realize, make use of it.

Amos



From evan.blackstone at oecu.org  Fri Sep 30 21:12:28 2016
From: evan.blackstone at oecu.org (Evan Blackstone)
Date: Fri, 30 Sep 2016 21:12:28 +0000
Subject: [squid-users] SSL Inspection Question
Message-ID: <844AD9F6A8DF3A4FB789270813B18FE3FF0A49D4@OECU-EXCHANGE2.oecu.org>

I currently use a web filter product that does not feature ICAP server capability. (It can act as an ICAP client and send requests to other ICAP servers, but it cannot function as an ICAP server itself). Therefore, I'm unable to use Squid's ICAP functionality to query my web filter product.

Is there any safe way of using SSL-Bump on Squid to decrypt client traffic, redirect (via standard HTTP or some other means) to another network location, then receive and re-encrypt it before sending it out to its ultimate destination? Is this idea insane? I have several devices that would benefit from seeing an unencrypted view of our traffic in and out.


Experience local rewards with a new Experience Oklahoma Rewards credit card. Click here<https://www.oecu.org/credit-cards/researching-cards/rewards-credit-card/> for details.

________________________________

NOTICE:
This e-mail is intended solely for the use of the individual to whom it is addressed and may contain information that is privileged, confidential or otherwise exempt from disclosure. If the reader of this e-mail is not the intended recipient or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any dissemination, distribution, or copying of this communication is strictly prohibited. If you have received this communication in error, please immediately notify us by replying to the original message at the listed email address.

Thank you
Oklahoma Employees Credit Union
http://www.oecu.org
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20160930/f60aa272/attachment.htm>

From rousskov at measurement-factory.com  Fri Sep 30 21:34:28 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 30 Sep 2016 15:34:28 -0600
Subject: [squid-users] SSL Inspection Question
In-Reply-To: <844AD9F6A8DF3A4FB789270813B18FE3FF0A49D4@OECU-EXCHANGE2.oecu.org>
References: <844AD9F6A8DF3A4FB789270813B18FE3FF0A49D4@OECU-EXCHANGE2.oecu.org>
Message-ID: <3caabfe1-830b-3d48-049b-de3d871f91c1@measurement-factory.com>

On 09/30/2016 03:12 PM, Evan Blackstone wrote:

> Is there any safe way of using SSL-Bump on Squid to decrypt client
> traffic, redirect (via standard HTTP or some other means) to another
> network location, then receive and re-encrypt it before sending it out
> to its ultimate destination? 

You have two options:

1. Write or purchase an eCAP adapter (or an ICAP service) that does what
you want. eCAP and ICAP are the only Squid interfaces to get
[unencrypted] bumped messages out of Squid without modifying Squid.

2. Modify Squid to do what you want. I doubt such modifications would be
officially accepted, but I might be wrong.

The biggest problem with what you want to do is the "then receive" part.
Sending unencrypted traffic to a DPI system is straightforward and there
is at least one eCAP adapter doing that already, but that is a "one way"
"inform only" solution. If you want the traffic to come back to the
adapter (and then to Squid), then you would have to do a lot more work.


> Is this idea insane?

Many would consider SslBump itself "insane"...

IMHO, the security implications of your scheme depend on how that
unencrypted traffic will reach your web filter product. If the security
of the transmission channel is comparable to the security of the web
filter product itself, then you are not really making [the already
insane] thing _much_ worse.


HTH,

Alex.



From darren.j.breeze.ml at gmail.com  Fri Sep 30 22:05:04 2016
From: darren.j.breeze.ml at gmail.com (Darren)
Date: Sat, 01 Oct 2016 06:05:04 +0800
Subject: [squid-users] Large text ACL lists
In-Reply-To: <97de62ef-9f55-cb69-2031-4ef56c902d5d@gmail.com>
References: <6dfcd8c2-dd84-4942-8be0-865b62778a89@getmailbird.com>
 <2c1e0a65-e688-183f-b83e-4fbbfa6d4539@treenet.co.nz>
 <54ee7d9a-96fe-4233-8db7-3b891455f07f@getmailbird.com>
 <35c4e399-1050-06c7-1715-e0c1252955a4@treenet.co.nz>
 <97de62ef-9f55-cb69-2031-4ef56c902d5d@gmail.com>
Message-ID: <8cee8f0b-bd35-4f76-828b-8fd497c1a4c8@getmailbird.com>

Hi

My main issue with squid guard is that when I try and block say www.facebook.com and the user goes to https://www.facebook.com, squidguard only sees the initial CONNECT as the target IP so doesn't match against the domain entry.

If squidguard did a reverse DNS lookup, I could keep using that more complex filtering solution. That is where the dstdomain acl is a better option but has the ram overhead.

Time for some experimentation

thanks again for the feedback




Sent from Mailbird [http://www.getmailbird.com/?utm_source=Mailbird&amp;utm_medium=email&amp;utm_campaign=sent-from-mailbird]
On 30/09/2016 7:21:53 PM, Yuri Voinov <yvoinov at gmail.com> wrote:

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

Amos, I'm afraid that this is not a solution. Block lists have become so
huge that only their compression and / or placement in an external
database (as Marcus) can save the situation.


30.09.2016 12:59, Amos Jeffries ?????:
> On 30/09/2016 6:58 p.m., Darren wrote:
>> Thank you Amos
>>
>> The resources I save not running multiple Squidguards will make more
>> ram available as you say and having a simpler setup is never a bad
>> thing either.
>>
>> Just to clarify, so when squid fires up, it caches the ACL file into
>> ram in it's entirety and then does some optimizations? If that is
>> the case I would need to budget the ram to allow for this.
>
> Not quite. Squid still reads the files line by line into a memory
> structure for whatever type of ACL is being loaded. That is part of why
> its so much slowe to load than the helpers (which generally do as you
> describe).
>
> The optimizations are type dependent and fairly simplistic. Ignoring
> duplicate entries, catenating regex into bigger " A|B " patterns (faster
> to check against), etc.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v2

iQEcBAEBCAAGBQJX7kq8AAoJENNXIZxhPexGH+cH/jmZsQlcZgXpwt62pHDtHp4t
TWDnhr5KOfHv+GFeBUmJYuD2nn8wefb5KUUhea5fdpRAeDihFDQDPQDwAnaC/E5q
FzE68zh+nF13xVwTW9/5mQhK75G17mOGJPGFPn1ZUC3lf/Q2JCOhWB+0MFilXXcQ
/ptCeQII/E8oXaiBOvHPzasOp6eDnu/m51q0DnkfoUceEWap9W0rY/vKxwL32FI9
fjqoZGGBPt3FDczjb8/9X6trqeGBwUl4PKSTE4JSdyU6z52evaCSsVbEgAmw+LjI
ELCBPOuU7buFxNjCSNLVhDNQeZJFJxPV8Oh/OcDQZQDhdUYliEwRke5Sz+Rz37k=
=hFD2
-----END PGP SIGNATURE-----

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20161001/3473b5dd/attachment.htm>

From rousskov at measurement-factory.com  Fri Sep 30 23:12:48 2016
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 30 Sep 2016 17:12:48 -0600
Subject: [squid-users] Squid-3.5.21: filter FTP content or FTP commands
In-Reply-To: <CAFfuDwzpSgAOGwBBEyKtdv_7GF=Lt7muU_wL7ovH=8ED2Fm7zQ@mail.gmail.com>
References: <CAFfuDwzpSgAOGwBBEyKtdv_7GF=Lt7muU_wL7ovH=8ED2Fm7zQ@mail.gmail.com>
Message-ID: <7bb34557-c359-ddb2-a2f1-dd81367cf448@measurement-factory.com>

On 09/30/2016 10:42 AM, oleg gv wrote:

> Hello, I've found that NativeFtpRelay appeared in squid 3.5 . Is it
> possible to apply http-access acl for FTP proto concerning filtering of
> FTP methods(commands) 

Yes, it should be possible.


> by analogy of HTTP methods ?

Not quite. IIRC, when the HTTP message representing the FTP transaction
is relayed through Squid, the FTP command name is _not_ stored as an
HTTP method. The FTP command name is stored as HTTP "FTP-Command" header
value. See http://wiki.squid-cache.org/Features/FtpRelay

You should be able to block FTP commands using a req_header ACL.


> what other possibilities in squid exist to do this ?

An ICAP or eCAP service can also filter relayed FTP messages.

Alex.



