From squid3 at treenet.co.nz  Sun Apr  2 07:47:49 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 2 Apr 2017 19:47:49 +1200
Subject: [squid-users] Using client certificate for all connection
In-Reply-To: <0b0901d2a9c1$d179fa20$746dee60$@ngtech.co.il>
References: <1490892909667-4681942.post@n4.nabble.com>
 <0b0901d2a9c1$d179fa20$746dee60$@ngtech.co.il>
Message-ID: <72ca44aa-bfaa-6355-71db-d47009fc96e9@treenet.co.nz>

On 31/03/2017 2:55 p.m., Eliezer  Croitoru wrote:
> As far my understanding goes squid doesn't have this function yet.
> Maybe if you will put haproxy(not sure) infront of squid you might be able to achieve your goal.
> 

It depends on exactly what is wanted as to how they are configured. But
Squid does have support for client certificates on all TLS connections.

Amos



From squid3 at treenet.co.nz  Sun Apr  2 07:51:02 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 2 Apr 2017 19:51:02 +1200
Subject: [squid-users] Using client certificate for all connection
In-Reply-To: <1490949541069-4681951.post@n4.nabble.com>
References: <1490892909667-4681942.post@n4.nabble.com>
 <201703302252.25018.Antony.Stone@squid.open.source.it>
 <1490949541069-4681951.post@n4.nabble.com>
Message-ID: <ef5a44f1-860f-e691-edbc-826e9f206ce3@treenet.co.nz>

On 31/03/2017 9:39 p.m., Juande wrote:
> Half and half. I need a way to client certificate authorize the requests from
> my analyzer software that does not support certificate authentication, but
> does support using a proxy. 
> 
> So I need that squid provides the certificate for all requests to all
> servers. We have testing certificates that work in many servers, so I can
> use the same certificate to authenticate in all of them.

For Squid-3 releases use:
 <http://www.squid-cache.org/Doc/config/sslproxy_client_certificate/>
 <http://www.squid-cache.org/Doc/config/sslproxy_client_key/>

For Squid-4 and later those have become the cert= and key= options for:
 <http://www.squid-cache.org/Doc/config/tls_outgoing_options/>


Amos



From squid3 at treenet.co.nz  Sun Apr  2 08:27:04 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 2 Apr 2017 20:27:04 +1200
Subject: [squid-users] HTTPS reverse proxy: SSL Certficate verification
 failed
In-Reply-To: <CAJmUcmarAkwGX7f7Gw4iBPBTA-Yc-b-OAeiLMXgpg9cQZGPmYA@mail.gmail.com>
References: <CAJmUcmbfVqJGWpetdEqtFxfMpfbgVi7niRU+cr1_Fk9wNVAwaQ@mail.gmail.com>
 <a9bc23dc-5638-7512-0d2f-738c954caef3@treenet.co.nz>
 <CAJmUcmarAkwGX7f7Gw4iBPBTA-Yc-b-OAeiLMXgpg9cQZGPmYA@mail.gmail.com>
Message-ID: <7e8eeb8e-0b3d-fdd0-472c-76cb1b06743b@treenet.co.nz>

On 1/04/2017 4:42 a.m., Eric Veiras Galisson wrote:
> On Fri, Mar 31, 2017 at 4:44 AM, Amos Jeffries wrote:
> 
>> On 31/03/2017 4:01 a.m., Eric Veiras Galisson wrote:
>>> Hello,
>>>
>>> I want to setup Squid as a HTTPS reverse proxy for several of our
>> websites,
>>> but I have a certificate verification problem on Squid access.log.
>>> Our upstream webservers are behind a VPN tunnel and only the Squid server
>>> can access it. (*We actually use Nginx for the same purpose but want to
>>> switch to Squid)*
>>>
>>>                               HTTPS                           HTTPS
>>> [client browser] -----------------------> [Squid]
>>> --------------------------> [upstream server]
>>>
>>>
>>> I run squid 3.4.8-6+deb8u4 recompiled with --enable-ssl
>>> --with-open-ssl="/etc/ssl/openssl.cnf" on Debian Jessie.
>>>
>>> The certificate presented to the client is the same as on the upstream
>>> server, a wildcard one signed by GeoTrust (with intermediate CA). It
>>> appears correctly in the browser.
>>> The problem comes from squid verification of upstream certificate.
>>>
>> ...
>>>
>>> What am I doing wrong? and what should I do to make squid work in this
>>> setup?
>>
>> The server (and Squid) should be supplying the intermediate cert along
>> with its own cert for best validation behaviour.
>>
> 
> Both the server and squid (https_port cert= option) are actually using the
> same certificate: a single file with priv key, server certificate and
> intermediary cert CA.
> 

That does not matter. TLS is point-to-point.

What matters is that *any* software operating as the server endpoint of
a TLS connection sends the right details along with its cert.

Your setup is special in that it has multiple pieces of software using
the same cert (Squid and the peer web service). That is not great for
security (reduces the effective trust lifetime of the cert), but is doable.


> 
>> If it cannot, use the cache_peer sslcafile= option to provide Squid with
>> a PEM file containing the public certs of the whole chain (excluding the
>> server cert itself). Order of those certs in the file is important. I've
>> forgotten which end of the chain to start with sorry, but it is one or
>> the other and definitely sequential.
>>
>>
> I changed cache_peer directive to add sslcafile option to a PEM file
> containing root and intermediary CA certificate, in one order or the other.
> 
> And when verifying with openssl s_client -showcerts -connect
> upstream1.domain.tld directly (no squid) or via squid, it's OK [1]
> 
> $ openssl s_client -showcerts -connect upstream.domain.tld:443
> CONNECTED(00000003)
> depth=2 C = US, O = GeoTrust Inc., CN = GeoTrust Global CA
> verify return:1
> depth=1 C = US, O = GeoTrust Inc., CN = RapidSSL SHA256 CA
> verify return:1
> depth=0 CN = *.domain.tld
> verify return:1
> ---
>     Verify return code: 0 (ok)
> 
> 
> But I still have the same error when connecting to the website with a
> browser.
> 

Exact same error? Since Squid is juggling multiple TLS connections for
the transaction I am looking at "fwdNegotiateSSL" in the log message
which is the only detail indicating what connection is having the issue.

That Squid->server connection has zero difference between the browser
and the command line tool connecting to a reverse-proxy, or when both
are using opaque (non-Bumped) CONNECT tunnels. So one working and the
other not is impossible.

Amos



From eliezer at ngtech.co.il  Sun Apr  2 08:59:07 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Sun, 2 Apr 2017 11:59:07 +0300
Subject: [squid-users] Using client certificate for all connection
In-Reply-To: <72ca44aa-bfaa-6355-71db-d47009fc96e9@treenet.co.nz>
References: <1490892909667-4681942.post@n4.nabble.com>
 <0b0901d2a9c1$d179fa20$746dee60$@ngtech.co.il>
 <72ca44aa-bfaa-6355-71db-d47009fc96e9@treenet.co.nz>
Message-ID: <00b101d2ab8f$62f23840$28d6a8c0$@ngtech.co.il>

For Incoming and outgoing  connections?
IE I want the only the users which their certificates are in a file will be able to use the proxy?
The other side is that squid as a client will posses and use a client side certificate.
Which of the above is possible on latest stable(3.5)?

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Sunday, April 2, 2017 10:48 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Using client certificate for all connection

On 31/03/2017 2:55 p.m., Eliezer  Croitoru wrote:
> As far my understanding goes squid doesn't have this function yet.
> Maybe if you will put haproxy(not sure) infront of squid you might be able to achieve your goal.
> 

It depends on exactly what is wanted as to how they are configured. But
Squid does have support for client certificates on all TLS connections.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Sun Apr  2 09:01:51 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Sun, 2 Apr 2017 12:01:51 +0300
Subject: [squid-users] MAXHTTPORTS CentOS 6
In-Reply-To: <1490925320544-4681947.post@n4.nabble.com>
References: <1490923445770-4681944.post@n4.nabble.com>
 <0b0b01d2a9c1$e4b64b20$ae22e160$@ngtech.co.il>
 <1490925320544-4681947.post@n4.nabble.com>
Message-ID: <00b301d2ab8f$c4dee260$4e9ca720$@ngtech.co.il>

Well I can patch the RPM I am publishing with such a things but I will need Amos Or Alex describe to me the possible effects such a patch and in what limits we are talking about.

Amos, Alex:
What do you think about including a patch to squid stable release?
What is the right limit? Would it be wise to embed in an enterprise distribution?

Elieze

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of dakotamartinez
Sent: Friday, March 31, 2017 4:55 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] MAXHTTPORTS CentOS 6

Is there a way I could go about doing this? I've read some stuff in similar forums but haven't seen a direct answer.

Dakota



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/MAXHTTPORTS-CentOS-6-tp4681944p4681947.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Sun Apr  2 09:08:58 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Sun, 2 Apr 2017 12:08:58 +0300
Subject: [squid-users] Load balance on two internet connections
In-Reply-To: <3f92707c-d468-37f8-d3ca-0b4f77eb95a4@gmail.com>
References: <65A19584-E99E-46BC-894B-80AA08152CB6@yahoo.com>
 <3f92707c-d468-37f8-d3ca-0b4f77eb95a4@gmail.com>
Message-ID: <00b501d2ab90$c33a1690$49ae43b0$@ngtech.co.il>

+1 fro the OS iptables level method and an addition:
http://wiki.squid-cache.org/EliezerCroitoru/Drafts/MwanLB
And consider to make the load balancing a bit "static" per something or your users will have troubles accessing services which tends to notice if requests are coming from the same src ip(such as google and many others).

Mikrotik has a nice picture to demonstrate the idea and is pretty close to iptables so the concept would be something like that:
https://wiki.mikrotik.com/wiki/Policy_Base_Routing

But you will might need to find the right way for consistency.

Let me know if you need more help.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Mimiko
Sent: Tuesday, March 21, 2017 4:57 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Load balance on two internet connections

On 21.03.2017 15:46, TarotApprentice wrote:
> If I have two internet connections is it possible to spread the traffic between them? I have a single squid 3.5 instance as an explicit proxy under Linux.

Hello.

I use output load balancing network traffic between 3 ISP using linux load-balancing ip rule. And squid automatically is balanced.
http://serverfault.com/questions/93678/load-balancing-nat-ing-multiple-isp-connections-on-linux



-- 
Mimiko desu.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From uhlar at fantomas.sk  Sun Apr  2 11:22:26 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Sun, 2 Apr 2017 13:22:26 +0200
Subject: [squid-users] MAXHTTPORTS CentOS 6
In-Reply-To: <00b301d2ab8f$c4dee260$4e9ca720$@ngtech.co.il>
References: <1490923445770-4681944.post@n4.nabble.com>
 <0b0b01d2a9c1$e4b64b20$ae22e160$@ngtech.co.il>
 <1490925320544-4681947.post@n4.nabble.com>
 <00b301d2ab8f$c4dee260$4e9ca720$@ngtech.co.il>
Message-ID: <20170402112226.GA29338@fantomas.sk>

On 02.04.17 12:01, Eliezer  Croitoru wrote:
>Well I can patch the RPM I am publishing with such a things but I will need Amos Or Alex describe to me the possible effects such a patch and in what limits we are talking about.
>
>Amos, Alex:
>What do you think about including a patch to squid stable release?
>What is the right limit? Would it be wise to embed in an enterprise distribution?

I'm not sure whether enterprise solutions should use this kind of hacks...


>-----Original Message-----
>From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of dakotamartinez
>Sent: Friday, March 31, 2017 4:55 AM
>To: squid-users at lists.squid-cache.org
>Subject: Re: [squid-users] MAXHTTPORTS CentOS 6
>
>Is there a way I could go about doing this? I've read some stuff in similar forums but haven't seen a direct answer.

maybe multiple squid servers running on multiple ports, see
http://wiki.squid-cache.org/MultipleInstances
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
10 GOTO 10 : REM (C) Bill Gates 1998, All Rights Reserved!


From rousskov at measurement-factory.com  Sun Apr  2 16:58:52 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 2 Apr 2017 10:58:52 -0600
Subject: [squid-users] MAXHTTPORTS CentOS 6
In-Reply-To: <00b301d2ab8f$c4dee260$4e9ca720$@ngtech.co.il>
References: <1490923445770-4681944.post@n4.nabble.com>
 <0b0b01d2a9c1$e4b64b20$ae22e160$@ngtech.co.il>
 <1490925320544-4681947.post@n4.nabble.com>
 <00b301d2ab8f$c4dee260$4e9ca720$@ngtech.co.il>
Message-ID: <94344999-9ad1-a465-f895-ad97bcf4bef3@measurement-factory.com>

On 04/02/2017 03:01 AM, Eliezer Croitoru wrote:

> What do you think about including a patch to squid stable release?

A high-quality patch removing the limit should be welcomed IMO. However,
implementing this change correctly is difficult, and there are much
bigger problems to solve if somebody has the time and the skills...


> I'm not sure whether enterprise solutions should use this kind of hacks... 

True, but a non-enterprise use case alone is not a valid justification
for having a limit. Besides, I have seen "enterprise" deployments that
had to raise the limit.

Alex.



From eliezer at ngtech.co.il  Mon Apr  3 07:32:59 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Mon, 3 Apr 2017 10:32:59 +0300
Subject: [squid-users] MAXHTTPORTS CentOS 6
In-Reply-To: <1490923445770-4681944.post@n4.nabble.com>
References: <1490923445770-4681944.post@n4.nabble.com>
Message-ID: <002901d2ac4c$8535c030$8fa14090$@ngtech.co.il>

How many ports do you need?
Depends on the number I will decide if to patch Squid RPM's.

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of dakotamartinez
Sent: Friday, March 31, 2017 4:24 AM
To: squid-users at lists.squid-cache.org
Subject: [squid-users] MAXHTTPORTS CentOS 6

Hi,

I'm new the forum. But i'm a sneaker website proxy seller and I use /24 subnets with squid in order to connect to these websites. I configure these servers with different ports as well as outgoing IP's. After applying all my ports and everything I get this in my cache log:

"WARNING: You have too many 'http_port' lines.
         The limit is 128"

I can't seem to figure it out. Is there a way to change the max ports value in the CentOS operating system? I'm sort of a beginner user with squid. I don't know too much. If there is, could somebody guide me through it.

Thanks,

Dakota





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/MAXHTTPORTS-CentOS-6-tp4681944.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eric.veirasgalisson at gmail.com  Mon Apr  3 08:38:49 2017
From: eric.veirasgalisson at gmail.com (Eric Veiras Galisson)
Date: Mon, 3 Apr 2017 10:38:49 +0200
Subject: [squid-users] HTTPS reverse proxy: SSL Certficate verification
	failed
In-Reply-To: <7e8eeb8e-0b3d-fdd0-472c-76cb1b06743b@treenet.co.nz>
References: <CAJmUcmbfVqJGWpetdEqtFxfMpfbgVi7niRU+cr1_Fk9wNVAwaQ@mail.gmail.com>
 <a9bc23dc-5638-7512-0d2f-738c954caef3@treenet.co.nz>
 <CAJmUcmarAkwGX7f7Gw4iBPBTA-Yc-b-OAeiLMXgpg9cQZGPmYA@mail.gmail.com>
 <7e8eeb8e-0b3d-fdd0-472c-76cb1b06743b@treenet.co.nz>
Message-ID: <CAJmUcmbvetHjMpdwxUHQ67=e3VHTFvCRkG4rw9f7obamBMN=iA@mail.gmail.com>

On Sun, Apr 2, 2017 at 10:27 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 1/04/2017 4:42 a.m., Eric Veiras Galisson wrote:
> > On Fri, Mar 31, 2017 at 4:44 AM, Amos Jeffries wrote:
> >
> >> On 31/03/2017 4:01 a.m., Eric Veiras Galisson wrote:
> >>> Hello,
> >>>
> >>> I want to setup Squid as a HTTPS reverse proxy for several of our
> >> websites,
> >>> but I have a certificate verification problem on Squid access.log.
> >>> Our upstream webservers are behind a VPN tunnel and only the Squid
> server
> >>> can access it. (*We actually use Nginx for the same purpose but want to
> >>> switch to Squid)*
> >>>
> >>>                               HTTPS                           HTTPS
> >>> [client browser] -----------------------> [Squid]
> >>> --------------------------> [upstream server]
> >>>
> >>>
> >>> I run squid 3.4.8-6+deb8u4 recompiled with --enable-ssl
> >>> --with-open-ssl="/etc/ssl/openssl.cnf" on Debian Jessie.
> >>>
> >>> The certificate presented to the client is the same as on the upstream
> >>> server, a wildcard one signed by GeoTrust (with intermediate CA). It
> >>> appears correctly in the browser.
> >>> The problem comes from squid verification of upstream certificate.
> >>>
> >> ...
> >>>
> >>> What am I doing wrong? and what should I do to make squid work in this
> >>> setup?
> >>
> >> The server (and Squid) should be supplying the intermediate cert along
> >> with its own cert for best validation behaviour.
> >>
> >
> > Both the server and squid (https_port cert= option) are actually using
> the
> > same certificate: a single file with priv key, server certificate and
> > intermediary cert CA.
> >
>
> That does not matter. TLS is point-to-point.
>
> What matters is that *any* software operating as the server endpoint of
> a TLS connection sends the right details along with its cert.
>

I think that is what I'm doing: priv key, server cert + intermediate CA
cert.

And openssl s_client is OK with TLS chain.



> Your setup is special in that it has multiple pieces of software using
> the same cert (Squid and the peer web service). That is not great for
> security (reduces the effective trust lifetime of the cert), but is doable.
>

I understand that.


> >
> >> If it cannot, use the cache_peer sslcafile= option to provide Squid with
> >> a PEM file containing the public certs of the whole chain (excluding the
> >> server cert itself). Order of those certs in the file is important. I've
> >> forgotten which end of the chain to start with sorry, but it is one or
> >> the other and definitely sequential.
> >>
> >>
> > I changed cache_peer directive to add sslcafile option to a PEM file
> > containing root and intermediary CA certificate, in one order or the
> other.
> >
> > And when verifying with openssl s_client -showcerts -connect
> > upstream1.domain.tld directly (no squid) or via squid, it's OK [1]
> >
> > $ openssl s_client -showcerts -connect upstream.domain.tld:443
> > CONNECTED(00000003)
> > depth=2 C = US, O = GeoTrust Inc., CN = GeoTrust Global CA
> > verify return:1
> > depth=1 C = US, O = GeoTrust Inc., CN = RapidSSL SHA256 CA
> > verify return:1
> > depth=0 CN = *.domain.tld
> > verify return:1
> > ---
> >     Verify return code: 0 (ok)
> >
> >
> > But I still have the same error when connecting to the website with a
> > browser.
> >
>
> Exact same error? Since Squid is juggling multiple TLS connections for
> the transaction I am looking at "fwdNegotiateSSL" in the log message
> which is the only detail indicating what connection is having the issue.
>
>
Yes, same error. If I try to access upstream1.domain.tld via a browser via
squid, I got this in squid/cache.log

2017/04/03 09:29:57 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 14: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/04/03 09:29:57 kid1| TCP connection to <upstream IP>/443 failed
2017/04/03 09:29:57 kid1| fwdNegotiateSSL: Error negotiating SSL connection
on FD 14: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/04/03 09:29:57 kid1| TCP connection to <upstream IP>/443 failed

No request is visible in upstream Apache logs.



> That Squid->server connection has zero difference between the browser
> and the command line tool connecting to a reverse-proxy, or when both
> are using opaque (non-Bumped) CONNECT tunnels. So one working and the
> other not is impossible.
>

Yes, I understand this. My problem now is finding what is failing in my
setup.

Eric.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170403/59598c71/attachment.htm>

From squid3 at treenet.co.nz  Mon Apr  3 12:11:27 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 4 Apr 2017 00:11:27 +1200
Subject: [squid-users] MAXHTTPORTS CentOS 6
In-Reply-To: <00b301d2ab8f$c4dee260$4e9ca720$@ngtech.co.il>
References: <1490923445770-4681944.post@n4.nabble.com>
 <0b0b01d2a9c1$e4b64b20$ae22e160$@ngtech.co.il>
 <1490925320544-4681947.post@n4.nabble.com>
 <00b301d2ab8f$c4dee260$4e9ca720$@ngtech.co.il>
Message-ID: <a4e5a793-33f6-3d48-cfc6-5ba57caaaefe@treenet.co.nz>

On 2/04/2017 9:01 p.m., Eliezer  Croitoru wrote:
> Well I can patch the RPM I am publishing with such a things but I will need Amos Or Alex describe to me the possible effects such a patch and in what limits we are talking about.
> 
> Amos, Alex:
> What do you think about including a patch to squid stable release?
> What is the right limit? Would it be wise to embed in an enterprise distribution?
> 

The limit is currently 128.

You build Squid-3.5 with -DMAXTCPLISTENPORTS=blah to change it.

Amos



From squid3 at treenet.co.nz  Mon Apr  3 15:03:25 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 4 Apr 2017 03:03:25 +1200
Subject: [squid-users] Using client certificate for all connection
In-Reply-To: <00b101d2ab8f$62f23840$28d6a8c0$@ngtech.co.il>
References: <1490892909667-4681942.post@n4.nabble.com>
 <0b0901d2a9c1$d179fa20$746dee60$@ngtech.co.il>
 <72ca44aa-bfaa-6355-71db-d47009fc96e9@treenet.co.nz>
 <00b101d2ab8f$62f23840$28d6a8c0$@ngtech.co.il>
Message-ID: <2dae6c86-4608-b379-6083-ac937c70b72d@treenet.co.nz>

On 2/04/2017 8:59 p.m., Eliezer Croitoru wrote:
> For Incoming and outgoing  connections?

Yes.

> IE I want the only the users which their certificates are in a file will be able to use the proxy?
> The other side is that squid as a client will posses and use a client side certificate.
> Which of the above is possible on latest stable(3.5)?

Same things that have been possible since about Squid-2.1 or whenever
SSL support was added.

Amos



From uhlar at fantomas.sk  Mon Apr  3 15:06:33 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Mon, 3 Apr 2017 17:06:33 +0200
Subject: [squid-users] Using client certificate for all connection
In-Reply-To: <2dae6c86-4608-b379-6083-ac937c70b72d@treenet.co.nz>
References: <1490892909667-4681942.post@n4.nabble.com>
 <0b0901d2a9c1$d179fa20$746dee60$@ngtech.co.il>
 <72ca44aa-bfaa-6355-71db-d47009fc96e9@treenet.co.nz>
 <00b101d2ab8f$62f23840$28d6a8c0$@ngtech.co.il>
 <2dae6c86-4608-b379-6083-ac937c70b72d@treenet.co.nz>
Message-ID: <20170403150633.GA31527@fantomas.sk>

>> IE I want the only the users which their certificates are in a file will be able to use the proxy?
>> The other side is that squid as a client will posses and use a client side certificate.
>> Which of the above is possible on latest stable(3.5)?

On 04.04.17 03:03, Amos Jeffries wrote:
>Same things that have been possible since about Squid-2.1 or whenever
>SSL support was added.

iirs this was not supported by browsers, does any support ssl-proxy
connections?
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Boost your system's speed by 500% - DEL C:\WINDOWS\*.*


From rousskov at measurement-factory.com  Mon Apr  3 18:35:59 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 3 Apr 2017 12:35:59 -0600
Subject: [squid-users] Using client certificate for all connection
In-Reply-To: <20170403150633.GA31527@fantomas.sk>
References: <1490892909667-4681942.post@n4.nabble.com>
 <0b0901d2a9c1$d179fa20$746dee60$@ngtech.co.il>
 <72ca44aa-bfaa-6355-71db-d47009fc96e9@treenet.co.nz>
 <00b101d2ab8f$62f23840$28d6a8c0$@ngtech.co.il>
 <2dae6c86-4608-b379-6083-ac937c70b72d@treenet.co.nz>
 <20170403150633.GA31527@fantomas.sk>
Message-ID: <b76055e0-9087-d121-3bda-bade63dedb76@measurement-factory.com>

On 04/03/2017 09:06 AM, Matus UHLAR - fantomas wrote:
> iirs this was not supported by browsers, does any support ssl-proxy
> connections?

Yes, IIRC, FireFox and Chrome (at least) support SSL connections to
proxies, but configuration of that feature is "hidden". You should be
able to find several emails discussing details on this and IETF HTTP WG
mailing lists.

There are other, specialized browser-like clients/kiosks/etc. that
support SSL connections to proxies. FWIW, the latest Curl also supports
it (<plug>Factory implemented that Curl feature</plug>) so you can test
the functionality from the command line.


HTH,

Alex.



From eliezer at ngtech.co.il  Mon Apr  3 19:39:25 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Mon, 3 Apr 2017 22:39:25 +0300
Subject: [squid-users] MAXHTTPORTS CentOS 6
In-Reply-To: <a4e5a793-33f6-3d48-cfc6-5ba57caaaefe@treenet.co.nz>
References: <1490923445770-4681944.post@n4.nabble.com>
 <0b0b01d2a9c1$e4b64b20$ae22e160$@ngtech.co.il>
 <1490925320544-4681947.post@n4.nabble.com>
 <00b301d2ab8f$c4dee260$4e9ca720$@ngtech.co.il>
 <a4e5a793-33f6-3d48-cfc6-5ba57caaaefe@treenet.co.nz>
Message-ID: <01c701d2acb2$008380a0$018a81e0$@ngtech.co.il>

Amos still the question in hands is very simple:
Would it matter if I will upper the limit to 16384?
For example would it result in some memory overhead?

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Monday, April 3, 2017 3:11 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] MAXHTTPORTS CentOS 6

On 2/04/2017 9:01 p.m., Eliezer  Croitoru wrote:
> Well I can patch the RPM I am publishing with such a things but I will need Amos Or Alex describe to me the possible effects such a patch and in what limits we are talking about.
> 
> Amos, Alex:
> What do you think about including a patch to squid stable release?
> What is the right limit? Would it be wise to embed in an enterprise distribution?
> 

The limit is currently 128.

You build Squid-3.5 with -DMAXTCPLISTENPORTS=blah to change it.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Mon Apr  3 19:45:22 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Mon, 3 Apr 2017 22:45:22 +0300
Subject: [squid-users] Google Captcha,
	can something be done to help it with squid?
Message-ID: <01c901d2acb2$d5401ab0$7fc05010$@ngtech.co.il>

Hey List,

I got couple complains from couple sysadmins about google forcing their
clients to verify that they are indeed humans in some very horrible ways.
But when they are logged in as a user it's "all good" and the search is
working properly.
These networks are using Squid and BlueCoat for 1k users plus and I am not
sure what to do to ease the clients.
I can verify the clients using a username and password using basic and
digest auth but I am not sure what I can do to make google services
understand that I have no bot in my networks.

Does anyone noticed such an issue? Did anyone found a specific solution for
this?
Maybe some header?

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il






From yvoinov at gmail.com  Mon Apr  3 19:50:48 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 4 Apr 2017 01:50:48 +0600
Subject: [squid-users] Google Captcha,
 can something be done to help it with squid?
In-Reply-To: <01c901d2acb2$d5401ab0$7fc05010$@ngtech.co.il>
References: <01c901d2acb2$d5401ab0$7fc05010$@ngtech.co.il>
Message-ID: <b5fda738-86b4-65e2-00cf-1b57244c43d4@gmail.com>

I guess an issue relevant to BlueCoat, not to Squid.

AFAIK BlueCoat ignores RFC. Squid - not.


04.04.2017 1:45, Eliezer Croitoru ?????:
> Hey List,
>
> I got couple complains from couple sysadmins about google forcing their
> clients to verify that they are indeed humans in some very horrible ways.
> But when they are logged in as a user it's "all good" and the search is
> working properly.
> These networks are using Squid and BlueCoat for 1k users plus and I am not
> sure what to do to ease the clients.
> I can verify the clients using a username and password using basic and
> digest auth but I am not sure what I can do to make google services
> understand that I have no bot in my networks.
>
> Does anyone noticed such an issue? Did anyone found a specific solution for
> this?
With squid there is no issue. Only when Squid is torified, but this as
expected and no issue.
> Maybe some header?
Don't think so. It still seems as BlueCoat-relevant, not Squid.
>
> Thanks,
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170404/cccb9d20/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170404/cccb9d20/attachment.sig>

From eliezer at ngtech.co.il  Mon Apr  3 21:10:16 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Tue, 4 Apr 2017 00:10:16 +0300
Subject: [squid-users] Google Captcha,
	can something be done to help it with squid?
In-Reply-To: <b5fda738-86b4-65e2-00cf-1b57244c43d4@gmail.com>
References: <01c901d2acb2$d5401ab0$7fc05010$@ngtech.co.il>
 <b5fda738-86b4-65e2-00cf-1b57244c43d4@gmail.com>
Message-ID: <076201d2acbe$b128cad0$137a6070$@ngtech.co.il>

Why relevant to BlueCoat and not squid?
It happens for the users for both systems and google clearly states that it's related to this specific ip activity.
(while bing and others works just fine)

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
Sent: Monday, April 3, 2017 10:51 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Google Captcha, can something be done to help it with squid?

I guess an issue relevant to BlueCoat, not to Squid.

AFAIK BlueCoat ignores RFC. Squid - not.


04.04.2017 1:45, Eliezer Croitoru ?????:
> Hey List,
>
> I got couple complains from couple sysadmins about google forcing 
> their clients to verify that they are indeed humans in some very horrible ways.
> But when they are logged in as a user it's "all good" and the search 
> is working properly.
> These networks are using Squid and BlueCoat for 1k users plus and I am 
> not sure what to do to ease the clients.
> I can verify the clients using a username and password using basic and 
> digest auth but I am not sure what I can do to make google services 
> understand that I have no bot in my networks.
>
> Does anyone noticed such an issue? Did anyone found a specific 
> solution for this?
With squid there is no issue. Only when Squid is torified, but this as expected and no issue.
> Maybe some header?
Don't think so. It still seems as BlueCoat-relevant, not Squid.
>
> Thanks,
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

--
Bugs to the Future



From yvoinov at gmail.com  Mon Apr  3 21:51:35 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 4 Apr 2017 03:51:35 +0600
Subject: [squid-users] Google Captcha,
 can something be done to help it with squid?
In-Reply-To: <076201d2acbe$b128cad0$137a6070$@ngtech.co.il>
References: <01c901d2acb2$d5401ab0$7fc05010$@ngtech.co.il>
 <b5fda738-86b4-65e2-00cf-1b57244c43d4@gmail.com>
 <076201d2acbe$b128cad0$137a6070$@ngtech.co.il>
Message-ID: <126fa8b6-d8e5-4d3d-372b-a3c1e59b6912@gmail.com>



04.04.2017 3:10, Eliezer Croitoru ?????:
> Why relevant to BlueCoat and not squid?
> It happens for the users for both systems and google clearly states that it's related to this specific ip activity.
Ah. You don't said it first. So, may be bot behind proxy. Or...... skew
routing to tor-like external IP.
> (while bing and others works just fine)
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri Voinov
> Sent: Monday, April 3, 2017 10:51 PM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Google Captcha, can something be done to help it with squid?
>
> I guess an issue relevant to BlueCoat, not to Squid.
>
> AFAIK BlueCoat ignores RFC. Squid - not.
>
>
> 04.04.2017 1:45, Eliezer Croitoru ?????:
>> Hey List,
>>
>> I got couple complains from couple sysadmins about google forcing 
>> their clients to verify that they are indeed humans in some very horrible ways.
>> But when they are logged in as a user it's "all good" and the search 
>> is working properly.
>> These networks are using Squid and BlueCoat for 1k users plus and I am 
>> not sure what to do to ease the clients.
>> I can verify the clients using a username and password using basic and 
>> digest auth but I am not sure what I can do to make google services 
>> understand that I have no bot in my networks.
>>
>> Does anyone noticed such an issue? Did anyone found a specific 
>> solution for this?
> With squid there is no issue. Only when Squid is torified, but this as expected and no issue.
>> Maybe some header?
> Don't think so. It still seems as BlueCoat-relevant, not Squid.
>> Thanks,
>> Eliezer
>>
>> ----
>> Eliezer Croitoru
>> Linux System Administrator
>> Mobile: +972-5-28704261
>> Email: eliezer at ngtech.co.il
>>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> --
> Bugs to the Future
>

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170404/4d7ef2fb/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170404/4d7ef2fb/attachment.sig>

From squid3 at treenet.co.nz  Mon Apr  3 23:53:04 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 4 Apr 2017 11:53:04 +1200
Subject: [squid-users] Using client certificate for all connection
In-Reply-To: <20170403150633.GA31527@fantomas.sk>
References: <1490892909667-4681942.post@n4.nabble.com>
 <0b0901d2a9c1$d179fa20$746dee60$@ngtech.co.il>
 <72ca44aa-bfaa-6355-71db-d47009fc96e9@treenet.co.nz>
 <00b101d2ab8f$62f23840$28d6a8c0$@ngtech.co.il>
 <2dae6c86-4608-b379-6083-ac937c70b72d@treenet.co.nz>
 <20170403150633.GA31527@fantomas.sk>
Message-ID: <9d59bb81-b743-e818-5f7b-ea80062cf230@treenet.co.nz>

On 4/04/2017 3:06 a.m., Matus UHLAR - fantomas wrote:
>>> IE I want the only the users which their certificates are in a file
>>> will be able to use the proxy?
>>> The other side is that squid as a client will posses and use a client
>>> side certificate.
>>> Which of the above is possible on latest stable(3.5)?
> 
> On 04.04.17 03:03, Amos Jeffries wrote:
>> Same things that have been possible since about Squid-2.1 or whenever
>> SSL support was added.
> 
> iirs this was not supported by browsers, does any support ssl-proxy
> connections?

You recall correct - for explicit/forward proxy Chrome and Firefox have
limited support when PAC is used, or some advanced hacks like command
line options. But generally browsers are refusing to talk to proxies
securely. Squid supports it already though.

Reverse-proxy, non-browser traffic, cache_peer and Squid->server
connections are where it really comes in handy.

Amos



From squid3 at treenet.co.nz  Tue Apr  4 00:01:10 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 4 Apr 2017 12:01:10 +1200
Subject: [squid-users] MAXHTTPORTS CentOS 6
In-Reply-To: <01c701d2acb2$008380a0$018a81e0$@ngtech.co.il>
References: <1490923445770-4681944.post@n4.nabble.com>
 <0b0b01d2a9c1$e4b64b20$ae22e160$@ngtech.co.il>
 <1490925320544-4681947.post@n4.nabble.com>
 <00b301d2ab8f$c4dee260$4e9ca720$@ngtech.co.il>
 <a4e5a793-33f6-3d48-cfc6-5ba57caaaefe@treenet.co.nz>
 <01c701d2acb2$008380a0$018a81e0$@ngtech.co.il>
Message-ID: <7f2324a7-e58f-baaa-f484-207acb38ce90@treenet.co.nz>

On 4/04/2017 7:39 a.m., Eliezer  Croitoru wrote:
> Amos still the question in hands is very simple:
> Would it matter if I will upper the limit to 16384?
> For example would it result in some memory overhead?

The usual answer applies - "it depends".

Some of the I/O modules (eg select and poll) require each special port
to be explicitly polled once every 10ms. The epoll/kqueue etc, only poll
them when other things do I/O and no less than every 10ms. So you need a
very fast server or it will kill performance for anything else.

And yes, having configuration state for each port means a lot more
memory used. These daya the use of TLS on ports means OpenSSL loads the
full set of trusted CAs into that state. So it can get VERY huge for no
obvious reason.

I dont think it is wise to embed larger limits. The one we have is an
order of magnitude larger than necessary for most installs. So it is not
generally useful.

All of the above is why there is no ./configure option. But there have
been a handful of queries wanting more, so the build option is conditional.

HTH
Amos



From squid3 at treenet.co.nz  Tue Apr  4 00:11:40 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 4 Apr 2017 12:11:40 +1200
Subject: [squid-users] Google Captcha,
 can something be done to help it with squid?
In-Reply-To: <126fa8b6-d8e5-4d3d-372b-a3c1e59b6912@gmail.com>
References: <01c901d2acb2$d5401ab0$7fc05010$@ngtech.co.il>
 <b5fda738-86b4-65e2-00cf-1b57244c43d4@gmail.com>
 <076201d2acbe$b128cad0$137a6070$@ngtech.co.il>
 <126fa8b6-d8e5-4d3d-372b-a3c1e59b6912@gmail.com>
Message-ID: <102cfcf8-931f-172e-af0f-c794971f74bc@treenet.co.nz>

On 4/04/2017 9:51 a.m., Yuri Voinov wrote:
> 
> 04.04.2017 3:10, Eliezer Croitoru ?????:
>> Why relevant to BlueCoat and not squid?
>> It happens for the users for both systems and google clearly states that it's related to this specific ip activity.
> Ah. You don't said it first. So, may be bot behind proxy. Or...... skew
> routing to tor-like external IP.
>> (while bing and others works just fine)
>>

I think it is the TOR involvement, I have heard a number of issues
between TOR and Google. But so far very few of simply being behind
Squid. It would have come up a lot more often if simply using Squid with
many clients was an issue.


TOR is a product based around anonymity. Google is a company whose
business model hinges on tracking users. "... and never the twain shall
meet" etc.

The necessary info is embeded into Via and XFF headers a required for
the HTTP part of the journey. There is nothng more Squid can do without
severaly compromising users safety. Further anonymising (ie removing Via
and XFF) makes things a bit worse as the non-TOR users of the proxy get
dragged into the issue.

HTH
Amos



From squid3 at treenet.co.nz  Tue Apr  4 00:14:23 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 4 Apr 2017 12:14:23 +1200
Subject: [squid-users] HTTPS reverse proxy: SSL Certficate verification
 failed
In-Reply-To: <CAJmUcmbvetHjMpdwxUHQ67=e3VHTFvCRkG4rw9f7obamBMN=iA@mail.gmail.com>
References: <CAJmUcmbfVqJGWpetdEqtFxfMpfbgVi7niRU+cr1_Fk9wNVAwaQ@mail.gmail.com>
 <a9bc23dc-5638-7512-0d2f-738c954caef3@treenet.co.nz>
 <CAJmUcmarAkwGX7f7Gw4iBPBTA-Yc-b-OAeiLMXgpg9cQZGPmYA@mail.gmail.com>
 <7e8eeb8e-0b3d-fdd0-472c-76cb1b06743b@treenet.co.nz>
 <CAJmUcmbvetHjMpdwxUHQ67=e3VHTFvCRkG4rw9f7obamBMN=iA@mail.gmail.com>
Message-ID: <0c4a898b-2854-3f00-8745-f3724ca416fa@treenet.co.nz>

On 3/04/2017 8:38 p.m., Eric Veiras Galisson wrote:
> On Sun, Apr 2, 2017 at 10:27 AM, Amos Jeffries wrote:
> 
>> That Squid->server connection has zero difference between the browser
>> and the command line tool connecting to a reverse-proxy, or when both
>> are using opaque (non-Bumped) CONNECT tunnels. So one working and the
>> other not is impossible.
>>
> 
> Yes, I understand this. My problem now is finding what is failing in my
> setup.
> 
> Eric.
> 

I think you are going to have to resort to packet tracing with wireshark
on the Squid->server connection. :-( good luck.

Amos



From heiler.bemerguy at cinbesa.com.br  Tue Apr  4 04:24:23 2017
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 4 Apr 2017 01:24:23 -0300
Subject: [squid-users] regexp on refresh_pattern
Message-ID: <b9ac3977-f617-e174-47ee-065fe29eef31@cinbesa.com.br>

Dudes, are these escaped characters right, for refresh_pattern syntax?

*refresh_pattern -i personal\.avira\-update.com.*\.(gz|idx|lz)$ 40320 
80% 120960 override-expire ignore-private ignore-no-store store-stale 
ignore-reload ignore-must-revalidate*


-- 
Atenciosamente / Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170404/baac433d/attachment.htm>

From squid3 at treenet.co.nz  Tue Apr  4 05:48:58 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 4 Apr 2017 17:48:58 +1200
Subject: [squid-users] regexp on refresh_pattern
In-Reply-To: <b9ac3977-f617-e174-47ee-065fe29eef31@cinbesa.com.br>
References: <b9ac3977-f617-e174-47ee-065fe29eef31@cinbesa.com.br>
Message-ID: <2966a192-6ac3-7cee-86cd-26b929acf88d@treenet.co.nz>

On 4/04/2017 4:24 p.m., Heiler Bemerguy wrote:
> Dudes, are these escaped characters right, for refresh_pattern syntax?
> 
> *refresh_pattern -i personal\.avira\-update.com.*\.(gz|idx|lz)$ 40320
> 80% 120960 override-expire ignore-private ignore-no-store store-stale
> ignore-reload ignore-must-revalidate*
> 

To which the only possible answer is:
  Are you referring to the escaped characters or the non-escaped characters?

Amos



From squid3 at treenet.co.nz  Tue Apr  4 06:18:08 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 4 Apr 2017 18:18:08 +1200
Subject: [squid-users] Squid Authentication if URL is on a Blacklist
 from SquidGuard
In-Reply-To: <1490948531197-4681950.post@n4.nabble.com>
References: <1490948531197-4681950.post@n4.nabble.com>
Message-ID: <640ad9a7-15c3-34a0-73a5-2676d4216b8e@treenet.co.nz>

On 31/03/2017 9:22 p.m., CrossfireAUT wrote:
> Hello Squid-Community!
> 
> I need your help with a rather non-standard config.
> My aim is as following:
> -> Users that use my proxy (will deploy it via group policy in AD) should be
> able to use my proxy without authentication

If you have such a thing as AD and the ability to push Group Policy to
the users there is no need to avoid authentication.

Perhapse the client is actually asking to get away from lots of annoying
popups the browsers are forcing on them? if that is happening it is a
strong sign that the authentication system needs fixing. When it works
there should be zero popups.


> -> if a user invokes SquidGuard (he wants to call up a URL on my
> blacklists), he should get prompted for his username and password
> -> only users of the AD-group webusers should be able to continue and go to
> this site on the blacklist
> I know, it isn't the best way to use SquidGuard, but a customer wants it
> that way.

Ewww. Okay. See below....


> 
> My current config is as following:
> auth_param basic program /usr/lib/squid/basic_ldap_auth -R -b
> "dc=xxxx,dc=local" -D testuser at xxxx.local -W /etc/squid/squid.secrets -f
> sAMAccountName=%s -h 172.30.0.36
> auth_param basic children 10
> auth_param basic realm xxxx
> auth_param basic credentialsttl 2 hours
> 
> external_acl_type webusers %LOGIN /usr/lib/squid/ext_ldap_group_acl -b
> "dc=xxxx,dc=local" -D testuser at xxxx.local -W /etc/squid/squid.secrets -f
> "(&(sAMAccountName=%v)(memberOf=cn=%a,cn=Users,dc=xxxx,dc=local))" -h
> 172.30.0.36
> 
> authenticate_ip_ttl 1 second
> 

Er, credentials are valid for 2 hours, but the "users" are jumping
around between IPs every second?

NP: the authenticate_ip_* stuff is irrelevant unless a maxuserip type
ACL is being used.

> 
> acl auth proxy_auth REQUIRED
> acl no_webusers dstdomain .xxxx.at
> acl ldapgroup_webusers external webusers webusers
> 
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> 
> 
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> 
> http_access deny !auth
> http_access allow no_webusers
> 
> http_access allow ldapgroup_webuser
> 
> http_access deny all
> 
> http_port 3128
> 
> 
> url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
> url_rewrite_children 4
> 
> 
> 
> 
> So my users get prompted for their username/passwords everytime they restart
> their browser.

Funky.
 Have you check that is not simple the browser "Password Manager"
feature requesting access to their machine or AD "Domain login" details?

I have seen a few computer-illiterate people confuse their browser
"master password" as some form of password associated with their default
homepage website. This can be particularly bad when that is set the
homepage to some popular social media site or search engine.


> If they call up a domain on my blacklists, they get ACCESS DENIED.
> 
> Does anyone know how you can achieve this?
> Until know, I tried really hard, thought it would be a good idea to ask the
> user-list!

So ignoring SG for now the problem is a matter of access control. That
means the right way to do it is with ACLs in http_access.


To use SG as requested you need to make an external_acl_type helper that
receives the same things SG needs and passes them on to it, mapping the
result back to an OK/ERR result for Squid ACL use.
 [ IIRC Eliezer has posted a helper that does that to the list . ]

Then you can do something like:
  external_acl_type sgMapper ...
  acl testWithSg external sgMapper

  http_access allow testWithSG
  http_access deny !auth
  ...

Note that this does not involve the url_rewrite_* API. You can drop that
entirely. Unless you want some traffic to still be redirected/rewritten
by SG. In which case you need url_rewrite_access to define which traffic
SG applies to.

Amos



From squid3 at treenet.co.nz  Tue Apr  4 06:21:47 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 4 Apr 2017 18:21:47 +1200
Subject: [squid-users] https_port and capath
In-Reply-To: <BN6PR17MB114004712BDD997506282D99F7320@BN6PR17MB1140.namprd17.prod.outlook.com>
References: <BN6PR17MB114004712BDD997506282D99F7320@BN6PR17MB1140.namprd17.prod.outlook.com>
Message-ID: <d2359e68-0f42-c63e-5b1d-be2014f0fa44@treenet.co.nz>

On 29/03/2017 11:07 a.m., senor wrote:
> Previous questions on this list referred to using the capath= option
> to https_port directive to fill in certificates missing in the chain
> to the Root CA trusted by the clients. I can not seem to get that to
> work.
> 
> I see no error in parsing even with debug on (debug section 3,9). The
> directive is read and no error produced but also no hint that the
> file pointed to by capath is used for anything. The SSL negotiation
> is not changed. The same 2 certs are passed. Just the signing cert
> and the signed cert.
>
> directive:
> https_port 192.168.12.10:8443 intercept ssl-bump \
>  cert=/etc/squid/mitm.crt key=/etc/squid/mitm.key \
>  cafile=/etc/squid/mitm_chain.crt generate-host-certificates=on \
>  dynamic_cert_mem_cache_size=32MB name=mitm
> 
> The RootCA.crt is trusted by clients.
> The Root CA signed intermediate1
> Intermediate1 signed intermediate2
> cert=intermediate2
> cafile=intermediate1
> 
> This command succeeds:
> openssl verify -CAfile RootCA.crt -untrusted intermediate1.crt intermediateL2.crt
> If the untrusted intermediate1 is added to client the MITM works.
> 
> I realize this wouldn't be used very often and I'd prefer not using it myself but it is necessary in this case. 
> Any hints?

The cert= and key= parameters are used by the cert generator.

The cafile= parameter and the generator output are used by the
verification and maybe sent to the client.

So your PEM file in *both* cert= and cafile= need to contain the whole
chain of intermediates.

Amos


From eliezer at ngtech.co.il  Tue Apr  4 06:28:45 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Tue, 4 Apr 2017 09:28:45 +0300
Subject: [squid-users] MAXHTTPORTS CentOS 6
In-Reply-To: <7f2324a7-e58f-baaa-f484-207acb38ce90@treenet.co.nz>
References: <1490923445770-4681944.post@n4.nabble.com>
 <0b0b01d2a9c1$e4b64b20$ae22e160$@ngtech.co.il>
 <1490925320544-4681947.post@n4.nabble.com>
 <00b301d2ab8f$c4dee260$4e9ca720$@ngtech.co.il>
 <a4e5a793-33f6-3d48-cfc6-5ba57caaaefe@treenet.co.nz>
 <01c701d2acb2$008380a0$018a81e0$@ngtech.co.il>
 <7f2324a7-e58f-baaa-f484-207acb38ce90@treenet.co.nz>
Message-ID: <005101d2ad0c$b63dec50$22b9c4f0$@ngtech.co.il>

OK so I will stick with the default since it makes more sense that it fit's most of the regular use cases.
If someone needs a special build he should be able to handle a self compiled squid.

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: Amos Jeffries [mailto:squid3 at treenet.co.nz] 
Sent: Tuesday, April 4, 2017 3:01 AM
To: Eliezer Croitoru <eliezer at ngtech.co.il>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] MAXHTTPORTS CentOS 6

On 4/04/2017 7:39 a.m., Eliezer  Croitoru wrote:
> Amos still the question in hands is very simple:
> Would it matter if I will upper the limit to 16384?
> For example would it result in some memory overhead?

The usual answer applies - "it depends".

Some of the I/O modules (eg select and poll) require each special port to be explicitly polled once every 10ms. The epoll/kqueue etc, only poll them when other things do I/O and no less than every 10ms. So you need a very fast server or it will kill performance for anything else.

And yes, having configuration state for each port means a lot more memory used. These daya the use of TLS on ports means OpenSSL loads the full set of trusted CAs into that state. So it can get VERY huge for no obvious reason.

I dont think it is wise to embed larger limits. The one we have is an order of magnitude larger than necessary for most installs. So it is not generally useful.

All of the above is why there is no ./configure option. But there have been a handful of queries wanting more, so the build option is conditional.

HTH
Amos




From heiler.bemerguy at cinbesa.com.br  Tue Apr  4 13:45:14 2017
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 4 Apr 2017 10:45:14 -0300
Subject: [squid-users] regexp on refresh_pattern
In-Reply-To: <2966a192-6ac3-7cee-86cd-26b929acf88d@treenet.co.nz>
References: <b9ac3977-f617-e174-47ee-065fe29eef31@cinbesa.com.br>
 <2966a192-6ac3-7cee-86cd-26b929acf88d@treenet.co.nz>
Message-ID: <fedb59ce-2e46-7992-13de-4d547784ed73@cinbesa.com.br>


>> Dudes, are these escaped characters right, for refresh_pattern syntax?
>>
>> *refresh_pattern -i personal\.avira\-update.com.*\.(gz|idx|lz)$ 40320
>> 80% 120960 override-expire ignore-private ignore-no-store store-stale
>> ignore-reload ignore-must-revalidate*
>>
> To which the only possible answer is:
>    Are you referring to the escaped characters or the non-escaped characters?
>

Escaped. Is it really necessary to escape dots and hyphens? And, will 
the $ really makes it verify from the right to the left ?

-- 
Atenciosamente / Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751



From timor at iinet.net.au  Wed Apr  5 06:00:53 2017
From: timor at iinet.net.au (daveh)
Date: Tue, 4 Apr 2017 23:00:53 -0700 (PDT)
Subject: [squid-users] https log message formatting help
Message-ID: <1491372053249-4681994.post@n4.nabble.com>

Hi squid users

Is there any way to change the request url log format for HTTPS messages?

I am using %ru to pull out the URL. When we get https connections, we see
the url logged as www.microsoft.com:443 

is there any way to reformat the log message to remove the appended port? or
to go further and rewrite to use https://<url>?



Thanks in advance



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/https-log-message-formatting-help-tp4681994.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From kevinmuehlparzer at hotmail.de  Wed Apr  5 07:48:12 2017
From: kevinmuehlparzer at hotmail.de (CrossfireAUT)
Date: Wed, 5 Apr 2017 00:48:12 -0700 (PDT)
Subject: [squid-users] Squid Authentication if URL is on a Blacklist
	from SquidGuard
In-Reply-To: <640ad9a7-15c3-34a0-73a5-2676d4216b8e@treenet.co.nz>
References: <1490948531197-4681950.post@n4.nabble.com>
 <640ad9a7-15c3-34a0-73a5-2676d4216b8e@treenet.co.nz>
Message-ID: <1491378492676-4681995.post@n4.nabble.com>

/If you have such a thing as AD and the ability to push Group Policy to
the users there is no need to avoid authentication./

I have a running AD on Ubuntu 16.04 with samba4.


/Perhapse the client is actually asking to get away from lots of annoying
popups the browsers are forcing on them? if that is happening it is a
strong sign that the authentication system needs fixing. When it works
there should be zero popups./

The client gets asked for his username/password everytime he closes & opens
the browser, while surfing, there are no PopUps so the client can surf
undisturbed.
At first, my client wanted to authenticate everytime someone opens & closes
the browser, now he wants to authenticate ONLY if someone calls up "a bad
Website".



/Er, credentials are valid for 2 hours, but the "users" are jumping
around between IPs every second?
NP: the authenticate_ip_* stuff is irrelevant unless a maxuserip type
ACL is being used.
/

Thanks, the thing with "authenticate_ip_ttl 1 second" was my fallacy.



/Funky.
Have you check that is not simple the browser "Password Manager"
feature requesting access to their machine or AD "Domain login" details?/

Browsers with "Password-Manager"-Features can save the password, but only
fill in the saved username and password.
So you would have to press Enter in order to continue. If you don't use this
Feature, you will get asked everytime you close & open the browser and have
to enter it yourself.


/
To use SG as requested you need to make an external_acl_type helper that
receives the same things SG needs and passes them on to it, mapping the
result back to an OK/ERR result for Squid ACL use.
 [ IIRC Eliezer has posted a helper that does that to the list . ]

Then you can do something like:
  external_acl_type sgMapper ...
  acl testWithSg external sgMapper

  http_access allow testWithSG
  http_access deny !auth
  ...

Note that this does not involve the url_rewrite_* API. You can drop that
entirely. Unless you want some traffic to still be redirected/rewritten
by SG. In which case you need url_rewrite_access to define which traffic
SG applies to./

I have to excuse myself, I'm still a beginner in the world of Squid.
Thanks for understanding.
You are right, I don't need to redirect to Blockpages anymore.
If the user authenticates because he called up a bad url, he should be
allowed to pass.

I don't understand that solution, why do I need to make that
external_acl_type helper?
Isn't it the same as my external_acl_type?

/external_acl_type webusers %LOGIN /usr/lib/squid/ext_ldap_group_acl -b
"dc=xxxx,dc=local" -D testuser at xxxx.local -W /etc/squid/squid.secrets -f
"(&(sAMAccountName=%v)(memberOf=cn=%a,cn=Users,dc=xxxx,dc=local))" -h
172.30.0.36

acl ldapgroup_webusers external webusers webusers

http_access allow ldapgroup_webusers
/

My helper are working well:
xxxx at xxxx-testproxy01:~# /usr/lib/squid/basic_ldap_auth -R -b
"dc=xxxx,dc=local" -D testuser at xxxx.local -W /etc/squid/squid.secrets -f
sAMAccountName=%s -h 172.30.0.36
testuser xxxx
OK

xxxx at xxxx-testproxy01:~# /usr/lib/squid/ext_ldap_group_acl -b
"dc=xxxx,dc=local" -D testuser at xxxx.local -W /etc/squid/squid.secrets -f
"(&(sAMAccountName=%v)(memberOf=cn=%a,cn=Users,dc=xxxx,dc=local))" -h
172.30.0.36
testuser webusers
OK

How can I match the requested URL against the Blacklists without SquidGuard?
I still need to match it against the Blacklist, and then it has to get
decided if he needs to authenticate or not.

Thanks for answering!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Authentication-if-URL-is-on-a-Blacklist-from-SquidGuard-tp4681950p4681995.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Wed Apr  5 09:00:54 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Wed, 5 Apr 2017 12:00:54 +0300
Subject: [squid-users] What squid should do with RFC non-compliant response
	header?
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAJAi8qAYKFtBkRXMK4znJhMBANlTnCJhprtFudq2LHCBs8EBACQA//8AABAAAAC8VZQ2Fuc5RoNjBks5ZDAMAQAAAAA=@ngtech.co.il>

Hi List,

I noticed that there are broken services out-there which uses non RFC
compliance response header such as the case of space, for  example:
"Content Type:  hola amigos"

Compared to: 
"Content-Type: Hola amigos"

Leaving aside if the content type is valid and is indeed  mime one and
looking only at the header name.
Should squid pass such a header or deny it?
What is expected from squid?
Should squid continue to handle the request or report an error?


Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il






From squid-user at tlinx.org  Wed Apr  5 19:18:54 2017
From: squid-user at tlinx.org (L A Walsh)
Date: Wed, 05 Apr 2017 12:18:54 -0700
Subject: [squid-users] What squid should do with RFC non-compliant
	response	header?
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAJAi8qAYKFtBkRXMK4znJhMBANlTnCJhprtFudq2LHCBs8EBACQA//8AABAAAAC8VZQ2Fuc5RoNjBks5ZDAMAQAAAAA=@ngtech.co.il>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJAi8qAYKFtBkRXMK4znJhMBANlTnCJhprtFudq2LHCBs8EBACQA//8AABAAAAC8VZQ2Fuc5RoNjBks5ZDAMAQAAAAA=@ngtech.co.il>
Message-ID: <58E5431E.2000609@tlinx.org>

Eliezer Croitoru wrote:
> Hi List,
>
> I noticed that there are broken services out-there which uses non RFC
> compliance response header such as the case of space, for  example:
> "Content Type:  hola amigos"
>   
Hmmm....April 1?...

Seriously -- what would a user's browser do?  Probably depends on
browser, but browsers are notoriously accepting and most would
likely ignore a problem like that and try to use defaults to
decide on content and rendering.

So if you want your proxy to not look like a stick-in-the-mud
for standards, I'd just pass it on.  If a proxy rejected every
non-compliant web-page, some significant percentage of the web
would be unviewable.





From eliezer at ngtech.co.il  Wed Apr  5 19:32:02 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Wed, 5 Apr 2017 22:32:02 +0300
Subject: [squid-users] What squid should do with RFC non-compliant
	response	header?
In-Reply-To: <58E5431E.2000609@tlinx.org>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJAi8qAYKFtBkRXMK4znJhMBANlTnCJhprtFudq2LHCBs8EBACQA//8AABAAAAC8VZQ2Fuc5RoNjBks5ZDAMAQAAAAA=@ngtech.co.il>
 <58E5431E.2000609@tlinx.org>
Message-ID: <024f01d2ae43$4ce4f180$e6aed480$@ngtech.co.il>

Thanks for the reponse.
Actually browsers ignore the header as a response header and do not show it at all.
(at least firefox)
Technically I would expect squid to pass it but it's might have the potential for a CVE in some casese.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: L A Walsh [mailto:squid-user at tlinx.org] 
Sent: Wednesday, April 5, 2017 10:19 PM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: What squid should do with RFC non-compliant response header?

Eliezer Croitoru wrote:
> Hi List,
>
> I noticed that there are broken services out-there which uses non RFC 
> compliance response header such as the case of space, for  example:
> "Content Type:  hola amigos"
>   
Hmmm....April 1?...

Seriously -- what would a user's browser do?  Probably depends on browser, but browsers are notoriously accepting and most would likely ignore a problem like that and try to use defaults to decide on content and rendering.

So if you want your proxy to not look like a stick-in-the-mud for standards, I'd just pass it on.  If a proxy rejected every non-compliant web-page, some significant percentage of the web would be unviewable.






From psa at cdot.in  Thu Apr  6 10:27:54 2017
From: psa at cdot.in (Punyasloka Arya)
Date: Thu, 6 Apr 2017 15:57:54 +0530
Subject: [squid-users] squid cache analysis
Message-ID: <20170406101855.M97492@cdot.in>


squid version:3.3
OS:centos

###############################################
The squid cache is not functioning properly
###############################################
Please suggest something to analyze or capture the log 
so that the cache service will improve.
Do we need to put some tool which will do it automatic?

from



Punyasloka Arya
Staffno:3880
Senior Research Engineer
Netops,TS(B)
C-DOT(B)
PHASE-1,ELECTRONICS CITY
BANGALORE-560100
INDIA


From Antony.Stone at squid.open.source.it  Thu Apr  6 10:43:01 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 6 Apr 2017 12:43:01 +0200
Subject: [squid-users] squid cache analysis
In-Reply-To: <20170406101855.M97492@cdot.in>
References: <20170406101855.M97492@cdot.in>
Message-ID: <201704061243.01363.Antony.Stone@squid.open.source.it>

On Thursday 06 April 2017 at 12:27:54, Punyasloka Arya wrote:

> squid version:3.3
> OS:centos

Which version of CentOS?

How was Squid installed?

Precisely which version of 3.3 are you using?

> The squid cache is not functioning properly

You'll have to be more specific than that - what *is* working, what is *not* 
working, what is the problem?

> Please suggest something to analyze or capture the log
> so that the cache service will improve.

Well, start with what you see in access.log

http://wiki.squid-cache.org/SquidFaq/SquidLogs

> Do we need to put some tool which will do it automatic?

Please tell us what "it" is - once we know what you want to do, we might be 
able to suggest ways of achieving it.


Antony.

-- 
Atheism is a non-prophet-making organisation.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Thu Apr  6 14:22:03 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 7 Apr 2017 02:22:03 +1200
Subject: [squid-users] regexp on refresh_pattern
In-Reply-To: <fedb59ce-2e46-7992-13de-4d547784ed73@cinbesa.com.br>
References: <b9ac3977-f617-e174-47ee-065fe29eef31@cinbesa.com.br>
 <2966a192-6ac3-7cee-86cd-26b929acf88d@treenet.co.nz>
 <fedb59ce-2e46-7992-13de-4d547784ed73@cinbesa.com.br>
Message-ID: <44525099-6a03-d59f-9689-59456bd2ac67@treenet.co.nz>

On 5/04/2017 1:45 a.m., Heiler Bemerguy wrote:
> 
>>> Dudes, are these escaped characters right, for refresh_pattern syntax?
>>>
>>> *refresh_pattern -i personal\.avira\-update.com.*\.(gz|idx|lz)$ 40320
>>> 80% 120960 override-expire ignore-private ignore-no-store store-stale
>>> ignore-reload ignore-must-revalidate*
>>>
>> To which the only possible answer is:
>>    Are you referring to the escaped characters or the non-escaped
>> characters?
>>
> 
> Escaped. Is it really necessary to escape dots and hyphens?


That depends on what you want it to match. Dot (.) and hyphen (-) have
special meanings in regex, so if you want to match those exact
characters in the input, then yes you need to \-escape them.

> And, will
> the $ really makes it verify from the right to the left ?
> 

Huh? never heard "verify" in regards to regex. If you mean scan, that is
something your OS regex library implementation may or may not do.

Dollar ($) is the end-anchor, the pattern is only a match if the ending
of the URL is at that position in relation to the rest of the pattern
pieces.


FYI: none of this has anything particular to do with Squid. It is basic
regular expressions. You should lookup a beginners guide to regular
expressions for these answers and many other useful things about regex.

Amos



From omidkosari at yahoo.com  Thu Apr  6 14:39:26 2017
From: omidkosari at yahoo.com (Omid Kosari)
Date: Thu, 6 Apr 2017 07:39:26 -0700 (PDT)
Subject: [squid-users] Windows Updates a Caching Stub zone,
	A windows updates store.
In-Reply-To: <004a01d1daf3$e6c4a490$b44dedb0$@ngtech.co.il>
References: <004a01d1daf3$e6c4a490$b44dedb0$@ngtech.co.il>
Message-ID: <1491489566256-4682002.post@n4.nabble.com>

Hey Eliezer,

Recently i have found that the fetcher script is very busy and it is always
downloading . It seems that microsoft changed something . I am not sure and
it is just a guess . 

Whats up at your servers ?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Windows-Updates-a-Caching-Stub-zone-A-windows-updates-store-tp4678454p4682002.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Thu Apr  6 14:52:19 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 7 Apr 2017 02:52:19 +1200
Subject: [squid-users] https log message formatting help
In-Reply-To: <1491372053249-4681994.post@n4.nabble.com>
References: <1491372053249-4681994.post@n4.nabble.com>
Message-ID: <79584cf7-57f4-7deb-8558-d41d600c2bc1@treenet.co.nz>

On 5/04/2017 6:00 p.m., daveh wrote:
> Hi squid users
> 
> Is there any way to change the request url log format for HTTPS messages?
> 
> I am using %ru to pull out the URL. When we get https connections, we see
> the url logged as www.microsoft.com:443 

You are assumping that URI means HTTPS. It may seem reasonable, but is
wrong.

The CONNECT request is a _tunnel_ request. It is an opaque *TCP* tunnel.

There is no guarantee that any given port-443 tunnel request is actually
HTTPS these days. There is WebSockets, SPDY, HTTP/2, and a number of
custom protocols inside TLS, and non-TLS protocols as well all using the
port.

When HTTPS does go through a port-443 tunnel, there is often more than
one HTTPS request. So writing https://blah/ to the log would be a lie,
and a deceptive one at that.


> 
> is there any way to reformat the log message to remove the appended port?


Well, the log %ru code is intended to record the *actual* details being
received. What you are seeing is what actually exists in the traffic.

It is a URI type called "authority-form".
<https://tools.ietf.org/html/rfc7230#section-5.3.3>

There is no protocol scheme, no path, no query and no fragment portions
for Squid to work with.



> to go further and rewrite to use https://<url>?

You can always define a log format that prints out the pieces of the URI
as separate format components "%>rs://%>rd:%>rP%>rp"
<http://www.squid-cache.org/Doc/config/logformat/>

However, you will need to do that for a separate log to other traffic
and as mentioned above keep in mind that port-443 does not necessarily
mean HTTPS.

To actually log https:// URL requires either passing Squid https:// URLs
instead of CONNECT request, or decrypting the traffic (with SSL-Bump
feature) and see what is inside the TLS (if it is TLS, it may not be).
Squid will then log the appropriate https:// URL for each received or
decrypted HTTPS request, no changes necessary.

PS: If you are asking this because of some tool that is doing broken
things when passed real URIs (not URL ... *URI*) that tool needs to be
fixed.

Amos



From squid3 at treenet.co.nz  Thu Apr  6 15:38:22 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 7 Apr 2017 03:38:22 +1200
Subject: [squid-users] Squid Authentication if URL is on a Blacklist
 from SquidGuard
In-Reply-To: <1491378492676-4681995.post@n4.nabble.com>
References: <1490948531197-4681950.post@n4.nabble.com>
 <640ad9a7-15c3-34a0-73a5-2676d4216b8e@treenet.co.nz>
 <1491378492676-4681995.post@n4.nabble.com>
Message-ID: <9decae7d-d2d3-3650-6fc9-aa6b29510489@treenet.co.nz>

On 5/04/2017 7:48 p.m., CrossfireAUT wrote:
> /If you have such a thing as AD and the ability to push Group Policy to
> the users there is no need to avoid authentication./
> 
> I have a running AD on Ubuntu 16.04 with samba4.
> 
> 
> /Perhapse the client is actually asking to get away from lots of annoying
> popups the browsers are forcing on them? if that is happening it is a
> strong sign that the authentication system needs fixing. When it works
> there should be zero popups./
> 
> The client gets asked for his username/password everytime he closes & opens
> the browser, while surfing, there are no PopUps so the client can surf
> undisturbed.
> At first, my client wanted to authenticate everytime someone opens & closes
> the browser, now he wants to authenticate ONLY if someone calls up "a bad
> Website".
> 
> 
> 
> /Er, credentials are valid for 2 hours, but the "users" are jumping
> around between IPs every second?
> NP: the authenticate_ip_* stuff is irrelevant unless a maxuserip type
> ACL is being used.
> /
> 
> Thanks, the thing with "authenticate_ip_ttl 1 second" was my fallacy.
> 
> 
> 
> /Funky.
> Have you check that is not simple the browser "Password Manager"
> feature requesting access to their machine or AD "Domain login" details?/
> 
> Browsers with "Password-Manager"-Features can save the password, but only
> fill in the saved username and password.
> So you would have to press Enter in order to continue. If you don't use this
> Feature, you will get asked everytime you close & open the browser and have
> to enter it yourself.
> 
> 
> /
> To use SG as requested you need to make an external_acl_type helper that
> receives the same things SG needs and passes them on to it, mapping the
> result back to an OK/ERR result for Squid ACL use.
>  [ IIRC Eliezer has posted a helper that does that to the list . ]
> 
> Then you can do something like:
>   external_acl_type sgMapper ...
>   acl testWithSg external sgMapper
> 
>   http_access allow testWithSG
>   http_access deny !auth
>   ...
> 
> Note that this does not involve the url_rewrite_* API. You can drop that
> entirely. Unless you want some traffic to still be redirected/rewritten
> by SG. In which case you need url_rewrite_access to define which traffic
> SG applies to./
> 
> I have to excuse myself, I'm still a beginner in the world of Squid.
> Thanks for understanding.
> You are right, I don't need to redirect to Blockpages anymore.
> If the user authenticates because he called up a bad url, he should be
> allowed to pass.
> 
> I don't understand that solution, why do I need to make that
> external_acl_type helper?

You need external_acl_type is because of that requirement that SG be
used. It is too late to authenticate by the time url_rewrite_helper API
gets consulted. So a complex ACL is needed that does a lookup with SG.
 The external_acl_type helper interface exists for that type of purpose.

You need the special mapping helper only because SG is very outdated
software and no longer maintained. It does not understand the generic
helper syntax Squid uses these days, and only responds with the old
redirect_helper syntax.

The wrapper helper is needed to map that old SG syntax to new OK/ERR
responses that the ACL interface expects.

My answer went that way because you said using SG was a client
requirement. I assumed you could not change that.

FWIW: Any helper which responds using the generic helper syntax
(produces OK/ERR codes) can be used directly in an external_acl_type
directive without the special wrapper SG needs. ufdbGuard is one I
expect could be used like that as a replacement for SG.


> Isn't it the same as my external_acl_type?
> 
> /external_acl_type webusers %LOGIN /usr/lib/squid/ext_ldap_group_acl -b
> "dc=xxxx,dc=local" -D testuser at xxxx.local -W /etc/squid/squid.secrets -f
> "(&(sAMAccountName=%v)(memberOf=cn=%a,cn=Users,dc=xxxx,dc=local))" -h
> 172.30.0.36

This external_acl_type is a lookup to check the already logged-in users
group membership.

It does not check what SG thinks about the URL (good or bad), or
anything else. Just the group check.


You can have multiple external_acl_type lines. Having one for SG does
not affect the above group one in any way. They are named in that first
parameter so your "acl ... external" lines can reference which helper is
to be sent the lookup by that ACL.


> 
> acl ldapgroup_webusers external webusers webusers
> 
> http_access allow ldapgroup_webusers
> /
> 
> My helper are working well:
> xxxx at xxxx-testproxy01:~# /usr/lib/squid/basic_ldap_auth -R -b
> "dc=xxxx,dc=local" -D testuser at xxxx.local -W /etc/squid/squid.secrets -f
> sAMAccountName=%s -h 172.30.0.36
> testuser xxxx
> OK
> 
> xxxx at xxxx-testproxy01:~# /usr/lib/squid/ext_ldap_group_acl -b
> "dc=xxxx,dc=local" -D testuser at xxxx.local -W /etc/squid/squid.secrets -f
> "(&(sAMAccountName=%v)(memberOf=cn=%a,cn=Users,dc=xxxx,dc=local))" -h
> 172.30.0.36
> testuser webusers
> OK
> 
> How can I match the requested URL against the Blacklists without SquidGuard?
> I still need to match it against the Blacklist, and then it has to get
> decided if he needs to authenticate or not.


It depends on exactly what format the blacklist is. If it is just a list
of domains, you can load it into a dstdomain ACL.
Like so:
 acl bad dstdomain "/etc/squid/blacklist.domains"

Or, if it has regex patterns one of the regex ACLs. There are a bunch
that can do full-URL, domain, or path-only regex matching. Though regex
is kind of slow so if you can avoid that it helps with performance.
 <http://www.squid-cache.org/Doc/config/acl/>

Or, using a more up to date helper than SG for the external lookup, as
mentioned above.

The benefit from doing the lists outside if squid.conf ACLs is ability
to change them easily without reconfiguring Squid. That comes in handy
for large lists.

Amos



From squid3 at treenet.co.nz  Thu Apr  6 16:07:03 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 7 Apr 2017 04:07:03 +1200
Subject: [squid-users] What squid should do with RFC non-compliant
 response header?
In-Reply-To: <024f01d2ae43$4ce4f180$e6aed480$@ngtech.co.il>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJAi8qAYKFtBkRXMK4znJhMBANlTnCJhprtFudq2LHCBs8EBACQA//8AABAAAAC8VZQ2Fuc5RoNjBks5ZDAMAQAAAAA=@ngtech.co.il>
 <58E5431E.2000609@tlinx.org> <024f01d2ae43$4ce4f180$e6aed480$@ngtech.co.il>
Message-ID: <f0a8e957-80c2-881c-7bd4-8f4494e35756@treenet.co.nz>

On 6/04/2017 7:32 a.m., Eliezer  Croitoru wrote:
> Thanks for the reponse.
> Actually browsers ignore the header as a response header and do not show it at all.
> (at least firefox)
> Technically I would expect squid to pass it but it's might have the potential for a CVE in some casese.
> 

There is actually a CVE problem "HTTP request/response smuggling" in all
cases of the type you described.

I dont know why you are asking for votes or opinions on this. Once the
message formatting has been violated there is exactly zero ways for
software to tell where that broken header ends. What any particular
person expects does not enter into it. Zero is zero.


All the rest of the bytes received from the sender may be part of that
single broken header.  That includes the ':' that you *assumed* was end
of header name, and CRLF bytes which would in real HTTP syntax normally
signify end of header and/or end of message. The header is not HTTP
syntax, therefore HTTP syntax no longer applies and the CRLF plus other
lines that look on the surface like HTTP syntax could all be part of its
middle.
 Thus the smuggling CVE applies to all cases where the headers are
invalid at the syntax/format level.

There are exactly two things that can be done by a proxy when this type
of error is encountered:

 1) what the RFC says to do (and should be expected from any HTTP proxy)
- deliver the client a 4xx for broken requests or 5xx for broken
responses. Terminating the connection when the error is sent.

or
  2) truncate the message at the CRLF before the garbage and drop all
other bytes received on that connection. Terminate the connection when
the HTTP transaction is "completed".


Doing (2) might sound attractive in terms of getting something to the
user at any cost. But what the user actually sees is a range of bad
behaviour from incomplete web pages, to broken web applications, to
plain wrong responses coming back. With no indication of what is going
wrong.
 To give a clear idea of what is broken and where the problems is - the
best option for a proxy is (1). To do the same thing as a browser is
just creating harm.


FYI: The HTTP RFCs are based squarely in running code implementations
with decades of testing behind them now. Going against what is written
there is exactly the best way to cause yourself (and users) trouble and
pain when interacting with other HTTP software.

Amos



From squid3 at treenet.co.nz  Thu Apr  6 16:12:02 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 7 Apr 2017 04:12:02 +1200
Subject: [squid-users] Custom Error Messages
In-Reply-To: <YTOPR01MB0476A869BB14BACC493511D1DF320@YTOPR01MB0476.CANPRD01.PROD.OUTLOOK.COM>
References: <YTOPR01MB0476E160CCC5CB6E23C176C9DF320@YTOPR01MB0476.CANPRD01.PROD.OUTLOOK.COM>
 <YTOPR01MB0476A869BB14BACC493511D1DF320@YTOPR01MB0476.CANPRD01.PROD.OUTLOOK.COM>
Message-ID: <116eca70-5b87-3e50-c17b-3b96a1b60376@treenet.co.nz>

On 29/03/2017 6:28 a.m., Waldon, Cooper wrote:
> Nevermind, I found the path.
> 
> For anyone else who need it it's:
> 
> /usr/share/squid/
> 

Aye, that is OS dependant though so YMMV.

For the record; using an absolute-path for the deny_info filename should
have worked on systems where '/' is the path initial character. Some
older Squid had a bug but I expect 3.4+ to work with that.

Amos



From eliezer at ngtech.co.il  Thu Apr  6 16:30:32 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Thu, 6 Apr 2017 19:30:32 +0300
Subject: [squid-users] Windows Updates a Caching Stub zone,
	A windows updates store.
In-Reply-To: <1491489566256-4682002.post@n4.nabble.com>
References: <004a01d1daf3$e6c4a490$b44dedb0$@ngtech.co.il>
 <1491489566256-4682002.post@n4.nabble.com>
Message-ID: <05ce01d2aef3$1cb537d0$561fa770$@ngtech.co.il>

I am not using it daily but I know that MS updates have more then one language support and it's pretty simple to verify the subject.
Just send me privately the tar of the requests and headers files and I will try to see if something got changed or not.
I do not believe that MS will change their system to such extent but I have not issue looking at the subject and try to verify what is causing for the load on your side.
Just so you know that it might take me time to verify the issue.

Also what is busy for you?
Are you using a lock file ?( it might be possible that your server is downloading in some loop and this is what causing this load)
Did you upgraded to the latest version?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Omid Kosari
Sent: Thursday, April 6, 2017 5:39 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Windows Updates a Caching Stub zone, A windows updates store.

Hey Eliezer,

Recently i have found that the fetcher script is very busy and it is always downloading . It seems that microsoft changed something . I am not sure and it is just a guess . 

Whats up at your servers ?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Windows-Updates-a-Caching-Stub-zone-A-windows-updates-store-tp4678454p4682002.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Thu Apr  6 16:41:51 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Thu, 6 Apr 2017 19:41:51 +0300
Subject: [squid-users] Squid Authentication if URL is on a Blacklist
	from SquidGuard
In-Reply-To: <640ad9a7-15c3-34a0-73a5-2676d4216b8e@treenet.co.nz>
References: <1490948531197-4681950.post@n4.nabble.com>
 <640ad9a7-15c3-34a0-73a5-2676d4216b8e@treenet.co.nz>
Message-ID: <05d001d2aef4$b13e9e90$13bbdbb0$@ngtech.co.il>

A copy of the message which includes the script and the relevant details at: http://www.ngtech.co.il/paste/1758/raw/

Or on the list archives:
http://lists.squid-cache.org/pipermail/squid-users/2016-June/011047.html

Or on the next gist:
https://gist.github.com/elico/865938620fb7a61ce5293bbce0b2bb06

Eliezer

* Should I add it to the wiki?... this is a 3 Clause  BSD licensed piece of code

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Tuesday, April 4, 2017 9:18 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid Authentication if URL is on a Blacklist from SquidGuard

On 31/03/2017 9:22 p.m., CrossfireAUT wrote:
> Hello Squid-Community!
> 
> I need your help with a rather non-standard config.
> My aim is as following:
> -> Users that use my proxy (will deploy it via group policy in AD) should be
> able to use my proxy without authentication

If you have such a thing as AD and the ability to push Group Policy to
the users there is no need to avoid authentication.

Perhapse the client is actually asking to get away from lots of annoying
popups the browsers are forcing on them? if that is happening it is a
strong sign that the authentication system needs fixing. When it works
there should be zero popups.


> -> if a user invokes SquidGuard (he wants to call up a URL on my
> blacklists), he should get prompted for his username and password
> -> only users of the AD-group webusers should be able to continue and go to
> this site on the blacklist
> I know, it isn't the best way to use SquidGuard, but a customer wants it
> that way.

Ewww. Okay. See below....


> 
> My current config is as following:
> auth_param basic program /usr/lib/squid/basic_ldap_auth -R -b
> "dc=xxxx,dc=local" -D testuser at xxxx.local -W /etc/squid/squid.secrets -f
> sAMAccountName=%s -h 172.30.0.36
> auth_param basic children 10
> auth_param basic realm xxxx
> auth_param basic credentialsttl 2 hours
> 
> external_acl_type webusers %LOGIN /usr/lib/squid/ext_ldap_group_acl -b
> "dc=xxxx,dc=local" -D testuser at xxxx.local -W /etc/squid/squid.secrets -f
> "(&(sAMAccountName=%v)(memberOf=cn=%a,cn=Users,dc=xxxx,dc=local))" -h
> 172.30.0.36
> 
> authenticate_ip_ttl 1 second
> 

Er, credentials are valid for 2 hours, but the "users" are jumping
around between IPs every second?

NP: the authenticate_ip_* stuff is irrelevant unless a maxuserip type
ACL is being used.

> 
> acl auth proxy_auth REQUIRED
> acl no_webusers dstdomain .xxxx.at
> acl ldapgroup_webusers external webusers webusers
> 
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl CONNECT method CONNECT
> 
> 
> http_access deny !Safe_ports
> http_access deny CONNECT !SSL_ports
> http_access allow localhost manager
> http_access deny manager
> 
> http_access deny !auth
> http_access allow no_webusers
> 
> http_access allow ldapgroup_webuser
> 
> http_access deny all
> 
> http_port 3128
> 
> 
> url_rewrite_program /usr/bin/squidGuard -c /etc/squidguard/squidGuard.conf
> url_rewrite_children 4
> 
> 
> 
> 
> So my users get prompted for their username/passwords everytime they restart
> their browser.

Funky.
 Have you check that is not simple the browser "Password Manager"
feature requesting access to their machine or AD "Domain login" details?

I have seen a few computer-illiterate people confuse their browser
"master password" as some form of password associated with their default
homepage website. This can be particularly bad when that is set the
homepage to some popular social media site or search engine.


> If they call up a domain on my blacklists, they get ACCESS DENIED.
> 
> Does anyone know how you can achieve this?
> Until know, I tried really hard, thought it would be a good idea to ask the
> user-list!

So ignoring SG for now the problem is a matter of access control. That
means the right way to do it is with ACLs in http_access.


To use SG as requested you need to make an external_acl_type helper that
receives the same things SG needs and passes them on to it, mapping the
result back to an OK/ERR result for Squid ACL use.
 [ IIRC Eliezer has posted a helper that does that to the list . ]

Then you can do something like:
  external_acl_type sgMapper ...
  acl testWithSg external sgMapper

  http_access allow testWithSG
  http_access deny !auth
  ...

Note that this does not involve the url_rewrite_* API. You can drop that
entirely. Unless you want some traffic to still be redirected/rewritten
by SG. In which case you need url_rewrite_access to define which traffic
SG applies to.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Thu Apr  6 17:44:41 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 6 Apr 2017 11:44:41 -0600
Subject: [squid-users] What squid should do with RFC non-compliant
 response header?
In-Reply-To: <f0a8e957-80c2-881c-7bd4-8f4494e35756@treenet.co.nz>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJAi8qAYKFtBkRXMK4znJhMBANlTnCJhprtFudq2LHCBs8EBACQA//8AABAAAAC8VZQ2Fuc5RoNjBks5ZDAMAQAAAAA=@ngtech.co.il>
 <58E5431E.2000609@tlinx.org> <024f01d2ae43$4ce4f180$e6aed480$@ngtech.co.il>
 <f0a8e957-80c2-881c-7bd4-8f4494e35756@treenet.co.nz>
Message-ID: <eedfa788-20a0-3324-6aba-9191d634b345@measurement-factory.com>

On 04/06/2017 10:07 AM, Amos Jeffries wrote:
> On 6/04/2017 7:32 a.m., Eliezer  Croitoru wrote:
>> Technically I would expect squid to pass it but it's might have the potential for a CVE in some casese.


> There is actually a CVE problem "HTTP request/response smuggling" in all
> cases of the type you described.


> There are exactly two things that can be done by a proxy when this type
> of error is encountered:

>  1) [send an error message]
>  2) truncate the message at the CRLF before the garbage

There are many other reasonable things a proxy can do, with admin
permission, but it is pointless to discuss their details on squid-users
IMO. And yes, pretty much all of them may cause HTTP message smuggling.
They are useful as temporary compatibility workarounds, not universal
default solutions.

Alex.



From Sebastien.Boulianne at cpu.ca  Thu Apr  6 21:49:35 2017
From: Sebastien.Boulianne at cpu.ca (Sebastien.Boulianne at cpu.ca)
Date: Thu, 6 Apr 2017 17:49:35 -0400
Subject: [squid-users] netdbExchangeHandleReply: corrupt data, aborting
Message-ID: <5FE0959288C73D448BB44CB7E9CC320F5E30ABE2F7@CPUMAIL2.cpu.qc.ca>

Hi,

Anyone can explain me how to fix that when I do "service squid status" please ?
netdbExchangeHandleReply: corrupt data, aborting

Thanks

S?bastien
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170406/1f013e4e/attachment.htm>

From rafael.akchurin at diladele.com  Fri Apr  7 09:13:24 2017
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Fri, 7 Apr 2017 09:13:24 +0000
Subject: [squid-users] Howto fix
	X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY Squid error
Message-ID: <DB6PR0401MB26806B37B92412FCAA36059A8F0C0@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Hello everyone,

Added new article for intermediate certificates and X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY error when bumping SSL.
Hopefully will be helpful/interesting for someone https://docs.diladele.com/faq/squid/fix_unable_to_get_issuer_cert_locally.html

Best regards,
Rafael Akchurin
Diladele B.V.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170407/8501b054/attachment.htm>

From juandebas at gmail.com  Fri Apr  7 11:36:05 2017
From: juandebas at gmail.com (Juande)
Date: Fri, 7 Apr 2017 04:36:05 -0700 (PDT)
Subject: [squid-users] Using client certificate for all connection
In-Reply-To: <ef5a44f1-860f-e691-edbc-826e9f206ce3@treenet.co.nz>
References: <1490892909667-4681942.post@n4.nabble.com>
 <201703302252.25018.Antony.Stone@squid.open.source.it>
 <1490949541069-4681951.post@n4.nabble.com>
 <ef5a44f1-860f-e691-edbc-826e9f206ce3@treenet.co.nz>
Message-ID: <1491564965851-4682016.post@n4.nabble.com>

Hi Amos, thanks for answering.

Im using Squid 3.5.12

I tried using the line:

sslproxy_client_certificate  /home/ubuntu/Documents/cert.pem

The pem was generated from .pfx using, 

openssl pkcs12 -in cert.pfx -out cert.pem -nodes

So it should contain the private key.

But my server still asking me for the certificate.^

Any ideas?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Using-client-certificate-for-all-connection-tp4681942p4682016.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Fri Apr  7 11:47:14 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 7 Apr 2017 23:47:14 +1200
Subject: [squid-users] netdbExchangeHandleReply: corrupt data, aborting
In-Reply-To: <5FE0959288C73D448BB44CB7E9CC320F5E30ABE2F7@CPUMAIL2.cpu.qc.ca>
References: <5FE0959288C73D448BB44CB7E9CC320F5E30ABE2F7@CPUMAIL2.cpu.qc.ca>
Message-ID: <d6ba21ab-70e9-cb49-eef8-9d4c40a8fa01@treenet.co.nz>

On 7/04/2017 9:49 a.m., Sebastien.Boulianne wrote:
> Hi,
> 
> Anyone can explain me how to fix that when I do "service squid status" please ?
> netdbExchangeHandleReply: corrupt data, aborting
> 

Are you using Squid-4 ?

The way Squid-3 and older operate causes horrible confusion inside
systemd. Only the start/stop commands have any success, and then only
with certain careful setups.

Amos



From Sebastien.Boulianne at cpu.ca  Fri Apr  7 12:43:41 2017
From: Sebastien.Boulianne at cpu.ca (Sebastien.Boulianne at cpu.ca)
Date: Fri, 7 Apr 2017 08:43:41 -0400
Subject: [squid-users] Squid 4.0.x = SNI Support
Message-ID: <5FE0959288C73D448BB44CB7E9CC320F5E30ABE30F@CPUMAIL2.cpu.qc.ca>

Hi all,

Anyone can confirm me if Squid 4.0.x support SNI ?

Thanks for all your answers.

S?bastien.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170407/973d98c4/attachment.htm>

From Sebastien.Boulianne at cpu.ca  Fri Apr  7 12:44:48 2017
From: Sebastien.Boulianne at cpu.ca (Sebastien.Boulianne at cpu.ca)
Date: Fri, 7 Apr 2017 08:44:48 -0400
Subject: [squid-users] netdbExchangeHandleReply: corrupt data, aborting
In-Reply-To: <d6ba21ab-70e9-cb49-eef8-9d4c40a8fa01@treenet.co.nz>
References: <5FE0959288C73D448BB44CB7E9CC320F5E30ABE2F7@CPUMAIL2.cpu.qc.ca>
 <d6ba21ab-70e9-cb49-eef8-9d4c40a8fa01@treenet.co.nz>
Message-ID: <5FE0959288C73D448BB44CB7E9CC320F5E30ABE310@CPUMAIL2.cpu.qc.ca>

Hi,

No, I have using Squid 3.5.24.

S?bastien 

-----Message d'origine-----
De?: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Amos Jeffries
Envoy??: 7 avril 2017 07:47
??: squid-users at lists.squid-cache.org
Objet?: Re: [squid-users] netdbExchangeHandleReply: corrupt data, aborting

On 7/04/2017 9:49 a.m., Sebastien.Boulianne wrote:
> Hi,
> 
> Anyone can explain me how to fix that when I do "service squid status" please ?
> netdbExchangeHandleReply: corrupt data, aborting
> 

Are you using Squid-4 ?

The way Squid-3 and older operate causes horrible confusion inside systemd. Only the start/stop commands have any success, and then only with certain careful setups.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From Ralf.Hildebrandt at charite.de  Fri Apr  7 12:50:07 2017
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Fri, 7 Apr 2017 14:50:07 +0200
Subject: [squid-users] Squid 4.0.x = SNI Support
In-Reply-To: <5FE0959288C73D448BB44CB7E9CC320F5E30ABE30F@CPUMAIL2.cpu.qc.ca>
References: <5FE0959288C73D448BB44CB7E9CC320F5E30ABE30F@CPUMAIL2.cpu.qc.ca>
Message-ID: <20170407125007.r4uau5dibwzamdon@charite.de>

* Sebastien.Boulianne at cpu.ca <Sebastien.Boulianne at cpu.ca>:
> Hi all,
> 
> Anyone can confirm me if Squid 4.0.x support SNI ?

SNI when doing what? ssl bump?

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
https://www.charite.de             Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From acctforjunk at yahoo.com  Fri Apr  7 13:01:15 2017
From: acctforjunk at yahoo.com (j m)
Date: Fri, 7 Apr 2017 13:01:15 +0000 (UTC)
Subject: [squid-users] General security and usage questions
References: <1838121436.3106912.1491570075225.ref@mail.yahoo.com>
Message-ID: <1838121436.3106912.1491570075225@mail.yahoo.com>

I have a Ubuntu server set up that does various things in addition to being a web proxy (squid 3.3.8) to use remotely over the internet. ?This allows me to directly access internal devices with a web page on my LAN since my employer, like most, blocks VPN connections. ?My intention is to have the squid service running at all times, with a login, so I can use it any time. ?However, there's a few things I have not been able to answer/resolve through my own research:
1. I am not able to SSH into my server from my employer. ?It's rare I'd need to do this, but ethical considerations aside, could this work with PuTTY over the squid proxy? ?I'm confused over how or if this would work using the Connection -> Proxy config in PuTTY. ?I can successfully use my proxy from a web browser, but have had no luck with SSH despite entering the proxy info into PuTTY. ?Supposedly the proxy needs to support the CONNECT method, but I'm unclear what this is or how to enable this. ?As an aside, I have experimented with shellinabox, but abandoned it when I learned it's not encrypted by default.

2. How good is squid's security as far as leaving its port open to the Internet, which I obviously have to do in my case? ?I found it interesting that if I enter http://myip:myport?from over the Internet, it responds with a "The requested URL could not be retrieved" page, along with information that identifies it as squid, along with the version number and server name, without asking for a login. ?Being unfamiliar with web proxies, this might be the norm for all I know. ?If I set up a browser to use it as a proxy, it does ask for a login. ?It appears the error pages are in?/usr/share/squid/errors, but is there a way for it to be more discrete, preferably to not respond at all or ask for a login?
Below is my squid.conf. ?I removed all the commented lines, and pieced one together from information online. ?My goal is to have it proxy basically anything thrown at it if authenticated, be as secure as reasonably possible, absolutely no caching, and enable SSH connections through it, if possible.
Thanks in advance.
auth_param basic program /usr/lib/squid3/basic_ncsa_auth /etc/squid3/passwordsauth_param basic realm proxyacl authenticated proxy_auth REQUIREDhttp_access allow authenticated
# Choose the port you want. Below we set it to default 3128.http_port 8092cache deny allaccess_log none
acl CONNECT method CONNECT??
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170407/60cc9430/attachment.htm>

From Sebastien.Boulianne at cpu.ca  Fri Apr  7 13:05:01 2017
From: Sebastien.Boulianne at cpu.ca (Sebastien.Boulianne at cpu.ca)
Date: Fri, 7 Apr 2017 09:05:01 -0400
Subject: [squid-users] Squid 4.0.x = SNI Support
In-Reply-To: <20170407125007.r4uau5dibwzamdon@charite.de>
References: <5FE0959288C73D448BB44CB7E9CC320F5E30ABE30F@CPUMAIL2.cpu.qc.ca>
 <20170407125007.r4uau5dibwzamdon@charite.de>
Message-ID: <5FE0959288C73D448BB44CB7E9CC320F5E30ABE315@CPUMAIL2.cpu.qc.ca>

Reverse proxy.

S?bastien 

-----Message d'origine-----
De?: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Ralf Hildebrandt
Envoy??: 7 avril 2017 08:50
??: squid-users at lists.squid-cache.org
Objet?: Re: [squid-users] Squid 4.0.x = SNI Support

* Sebastien.Boulianne at cpu.ca <Sebastien.Boulianne at cpu.ca>:
> Hi all,
> 
> Anyone can confirm me if Squid 4.0.x support SNI ?

SNI when doing what? ssl bump?

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
https://www.charite.de             Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155 _______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From eliezer at ngtech.co.il  Fri Apr  7 13:21:27 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Fri, 7 Apr 2017 16:21:27 +0300
Subject: [squid-users] What squid should do with RFC non-compliant
	response header?
In-Reply-To: <eedfa788-20a0-3324-6aba-9191d634b345@measurement-factory.com>
References: <!&!AAAAAAAAAAAuAAAAAAAAAJAi8qAYKFtBkRXMK4znJhMBANlTnCJhprtFudq2LHCBs8EBACQA//8AABAAAAC8VZQ2Fuc5RoNjBks5ZDAMAQAAAAA=@ngtech.co.il>
 <58E5431E.2000609@tlinx.org> <024f01d2ae43$4ce4f180$e6aed480$@ngtech.co.il>
 <f0a8e957-80c2-881c-7bd4-8f4494e35756@treenet.co.nz>
 <eedfa788-20a0-3324-6aba-9191d634b345@measurement-factory.com>
Message-ID: <066901d2afa1$dce275f0$96a761d0$@ngtech.co.il>

Thanks Amos and Alex,

I have seen a scenario like that but while working with haproxy.
I believe that there is a difference between a "security" proxy appliance to some other kinds.
The enforcement of the RFC for headers computability seems like the right way to go for any general http proxy.
The issue may arise when some developer might do some mistake in php or another customisd service. Php doesn't enforce the header syntax and it is possible that a developer will run broken code.

For the case with haproxy it returned a 500 wrong response.
To test the issue I had to compare two\three cases such as:
- plain text file
- plain html file
- simple phpinfo() php script

When testing these the conclusion was that there is something wrong with the php code that the developer wrote.
At least I can say that I have not seen such an error in any open source web application that is based on php. So I believe that they have some hidden quality to do things the right way.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Alex Rousskov
Sent: Thursday, April 6, 2017 8:45 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] What squid should do with RFC non-compliant response header?

On 04/06/2017 10:07 AM, Amos Jeffries wrote:
> On 6/04/2017 7:32 a.m., Eliezer  Croitoru wrote:
>> Technically I would expect squid to pass it but it's might have the potential for a CVE in some casese.


> There is actually a CVE problem "HTTP request/response smuggling" in 
> all cases of the type you described.


> There are exactly two things that can be done by a proxy when this 
> type of error is encountered:

>  1) [send an error message]
>  2) truncate the message at the CRLF before the garbage

There are many other reasonable things a proxy can do, with admin permission, but it is pointless to discuss their details on squid-users IMO. And yes, pretty much all of them may cause HTTP message smuggling.
They are useful as temporary compatibility workarounds, not universal default solutions.

Alex.

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Fri Apr  7 14:26:23 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 8 Apr 2017 02:26:23 +1200
Subject: [squid-users] [squid-announce] Squid 3.5.25 is available
Message-ID: <8fecd9c1-d550-67a7-4b1e-de1ff48b1dfc@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-3.5.25 release!


This release is a bug fix release resolving several issues found in the
prior Squid releases.


The major changes to be aware of:

* Bug 4508: Host forgery stalls intercepted being-spliced connections.

This bug shows up as SSL-Bumped connections being stuck in various TCP
open or half-open states and not closing until the TCP timeouts are reached.

Note, there are still other issues leading to the same behaviour and not
necessarily SSL-Bump related. This release works around the most common
issues affecting recent Squid-3 releases, but some remain and a better
long-term solution will be implemented later.


* Native FTP relay: NAT and TPROXY interception fixes

FTP Native relay is now able to cope with active-mode FTP DATA
connections when intercepting FTP traffic. Previously Squid would use
incorrect IP:port details which would not work with many clients.


* Bump SSL client on [more] errors encountered before ssl_bump evaluation

This bug shows up as error responses for issues encountered early in the
TLS/SSL handling being sent to clients unencrypted when Squid should
have bumped and delivered them encrypted.



 All users of Squid-3 with SSL-Bump functionallity are encouraged to
upgrade to this release as soon as possible.

 All other users of Squid-3 are encouraged to upgrade to this release as
time permits.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v3/3.5/RELEASENOTES.html
when you are ready to make the switch to Squid-3.5

Upgrade tip:
  "squid -k parse" is starting to display even more
   useful hints about squid.conf changes.

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v3/3.5/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/3.5/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries

_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From squid3 at treenet.co.nz  Fri Apr  7 15:54:43 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 8 Apr 2017 03:54:43 +1200
Subject: [squid-users] [squid-announce] Squid 4.0.19 beta is available
Message-ID: <9ce29697-8a09-348d-ebae-d8f642626690@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-4.0.19 release!


This release is a bug fix release resolving several issues found in the
prior Squid releases.


The major changes to be aware of:

* Bug #4671: various GCC 7 compile errors

GCC 7 adds a number of new warnings and behaviour checking that prevents
building older releases easily. This release fixes most of the issues
and should build most features. However, some more have been found since
release bundling.


* Fix two read-ahead problems related to delay pools (or lack of thereof).

Squid delays reading from the server after buffering read_ahead_gap
bytes that are not yet sent to the client. A delayed read is normally
resumed after Squid sends more buffered bytes to the client. However,
Squid was not resuming the delayed read after all Store clients were gone.


* Crypto-NG: initial GnuTLS support for encrypted server connections

This release adds support for servicing https:// URLs received from
clients, and TLS connections to cache_peer when built with GnuTLS.

Advanced GnuTLS TLS options= strings in squid.conf are significantly
different from OpenSSL options. See the release notes and squid.conf
documentation for specific details.

NOTE: https_port and SSL-Bump features are not yet supported with GnuTLS.


 All users of Squid-4.x are urged to upgrade to this release as
soon as possible.

 All users of Squid-3 are encouraged to test this release out and plan
for upgrades where possible.


 See the ChangeLog for the full list of changes in this and earlier
 releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

 http://www.squid-cache.org/Versions/v4/
 ftp://ftp.squid-cache.org/pub/squid/
 ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

 http://www.squid-cache.org/Download/http-mirrors.html
 http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From yvoinov at gmail.com  Fri Apr  7 16:15:39 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 7 Apr 2017 22:15:39 +0600
Subject: [squid-users] Howto fix
 X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY Squid error
In-Reply-To: <DB6PR0401MB26806B37B92412FCAA36059A8F0C0@DB6PR0401MB2680.eurprd04.prod.outlook.com>
References: <DB6PR0401MB26806B37B92412FCAA36059A8F0C0@DB6PR0401MB2680.eurprd04.prod.outlook.com>
Message-ID: <2208d27f-b092-e03e-ef5c-64c5fbeee258@gmail.com>

I would not install intermediate certificates in the system store. They
have a much shorter validity period - this time, and two - there is a
SQUID functionality that supports adding missing intermediate
certificates from a separate file. For security reasons, intermediate
certificates require additional administrator attention, and they should
be kept separate.


07.04.2017 15:13, Rafael Akchurin ?????:
>
> Hello everyone,
>
> Added new article for intermediate certificates and
> X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY error when bumping SSL.
> Hopefully will be helpful/interesting for someone
> https://docs.diladele.com/faq/squid/fix_unable_to_get_issuer_cert_locally.html
>
>  
>
> Best regards,
> Rafael Akchurin
>
> Diladele B.V.
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170407/919fee9e/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170407/919fee9e/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170407/919fee9e/attachment.sig>

From yvoinov at gmail.com  Fri Apr  7 16:18:54 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 7 Apr 2017 22:18:54 +0600
Subject: [squid-users] Howto fix
 X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY Squid error
In-Reply-To: <DB6PR0401MB26806B37B92412FCAA36059A8F0C0@DB6PR0401MB2680.eurprd04.prod.outlook.com>
References: <DB6PR0401MB26806B37B92412FCAA36059A8F0C0@DB6PR0401MB2680.eurprd04.prod.outlook.com>
Message-ID: <a6adc64c-cec4-33f8-3b93-d04e978f1135@gmail.com>

#  TAG: sslproxy_foreign_intermediate_certs
#    Many origin servers fail to send their full server certificate
#    chain for verification, assuming the client already has or can
#    easily locate any missing intermediate certificates.
#
#    Squid uses the certificates from the specified file to fill in
#    these missing chains when trying to validate origin server
#    certificate chains.
#
#    The file is expected to contain zero or more PEM-encoded
#    intermediate certificates. These certificates are not treated
#    as trusted root certificates, and any self-signed certificate in
#    this file will be ignored.
#Default:
# none

Heh?


07.04.2017 15:13, Rafael Akchurin ?????:
>
> Hello everyone,
>
> Added new article for intermediate certificates and
> X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY error when bumping SSL.
> Hopefully will be helpful/interesting for someone
> https://docs.diladele.com/faq/squid/fix_unable_to_get_issuer_cert_locally.html
>
>  
>
> Best regards,
> Rafael Akchurin
>
> Diladele B.V.
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170407/7149fef6/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170407/7149fef6/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170407/7149fef6/attachment.sig>

From rafael.akchurin at diladele.com  Fri Apr  7 16:44:27 2017
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Fri, 7 Apr 2017 16:44:27 +0000
Subject: [squid-users] Howto fix
 X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY Squid error
In-Reply-To: <a6adc64c-cec4-33f8-3b93-d04e978f1135@gmail.com>
References: <DB6PR0401MB26806B37B92412FCAA36059A8F0C0@DB6PR0401MB2680.eurprd04.prod.outlook.com>,
 <a6adc64c-cec4-33f8-3b93-d04e978f1135@gmail.com>
Message-ID: <E5738E0D-B6A3-4DCA-B07D-1A98F1B628B7@diladele.com>

Hello Yuri,

Yes this is much better solution!

Best regards,
Rafael Akchurin

Op 7 apr. 2017 om 18:20 heeft Yuri Voinov <yvoinov at gmail.com<mailto:yvoinov at gmail.com>> het volgende geschreven:


#  TAG: sslproxy_foreign_intermediate_certs
#    Many origin servers fail to send their full server certificate
#    chain for verification, assuming the client already has or can
#    easily locate any missing intermediate certificates.
#
#    Squid uses the certificates from the specified file to fill in
#    these missing chains when trying to validate origin server
#    certificate chains.
#
#    The file is expected to contain zero or more PEM-encoded
#    intermediate certificates. These certificates are not treated
#    as trusted root certificates, and any self-signed certificate in
#    this file will be ignored.
#Default:
# none


Heh?

07.04.2017 15:13, Rafael Akchurin ?????:
Hello everyone,

Added new article for intermediate certificates and X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY error when bumping SSL.
Hopefully will be helpful/interesting for someone https://docs.diladele.com/faq/squid/fix_unable_to_get_issuer_cert_locally.html

Best regards,
Rafael Akchurin
Diladele B.V.



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users


--
Bugs to the Future
<0x613DEC46.asc>
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170407/86b52146/attachment.htm>

From yvoinov at gmail.com  Fri Apr  7 16:45:29 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 7 Apr 2017 22:45:29 +0600
Subject: [squid-users] Howto fix
 X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY Squid error
In-Reply-To: <E5738E0D-B6A3-4DCA-B07D-1A98F1B628B7@diladele.com>
References: <DB6PR0401MB26806B37B92412FCAA36059A8F0C0@DB6PR0401MB2680.eurprd04.prod.outlook.com>
 <a6adc64c-cec4-33f8-3b93-d04e978f1135@gmail.com>
 <E5738E0D-B6A3-4DCA-B07D-1A98F1B628B7@diladele.com>
Message-ID: <80222917-9d7e-2ef9-ff49-4044187103dd@gmail.com>

;-)

No problem, Raf. This is really much better solution ;-)

07.04.2017 22:44, Rafael Akchurin ?????:
> Hello Yuri,
>
> Yes this is much better solution!
>
> Best regards,
> Rafael Akchurin
>
> Op 7 apr. 2017 om 18:20 heeft Yuri Voinov <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com>> het volgende geschreven:
>
>> #  TAG: sslproxy_foreign_intermediate_certs
>> #    Many origin servers fail to send their full server certificate
>> #    chain for verification, assuming the client already has or can
>> #    easily locate any missing intermediate certificates.
>> #
>> #    Squid uses the certificates from the specified file to fill in
>> #    these missing chains when trying to validate origin server
>> #    certificate chains.
>> #
>> #    The file is expected to contain zero or more PEM-encoded
>> #    intermediate certificates. These certificates are not treated
>> #    as trusted root certificates, and any self-signed certificate in
>> #    this file will be ignored.
>> #Default:
>> # none
>>
>> Heh?
>>
>>
>> 07.04.2017 15:13, Rafael Akchurin ?????:
>>>
>>> Hello everyone,
>>>
>>> Added new article for intermediate certificates and
>>> X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY error when bumping SSL.
>>> Hopefully will be helpful/interesting for someone
>>> https://docs.diladele.com/faq/squid/fix_unable_to_get_issuer_cert_locally.html
>>>
>>>  
>>>
>>> Best regards,
>>> Rafael Akchurin
>>>
>>> Diladele B.V.
>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> -- 
>> Bugs to the Future
>> <0x613DEC46.asc>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> <mailto:squid-users at lists.squid-cache.org>
>> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170407/d029dc11/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170407/d029dc11/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170407/d029dc11/attachment.sig>

From squid3 at treenet.co.nz  Fri Apr  7 16:47:59 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 8 Apr 2017 04:47:59 +1200
Subject: [squid-users] Squid 4.0.x = SNI Support
In-Reply-To: <5FE0959288C73D448BB44CB7E9CC320F5E30ABE315@CPUMAIL2.cpu.qc.ca>
References: <5FE0959288C73D448BB44CB7E9CC320F5E30ABE30F@CPUMAIL2.cpu.qc.ca>
 <20170407125007.r4uau5dibwzamdon@charite.de>
 <5FE0959288C73D448BB44CB7E9CC320F5E30ABE315@CPUMAIL2.cpu.qc.ca>
Message-ID: <e27ed7b3-516e-31cf-e644-c4bac677e0be@treenet.co.nz>

On 8/04/2017 1:05 a.m., Sebastien.Boulianne wrote:
> Reverse proxy.
> 
> S?bastien 
> 
> -----Message d'origine-----
> De : Ralf Hildebrandt
> 
> * Sebastien.Boulianne:
>> Hi all,
>>
>> Anyone can confirm me if Squid 4.0.x support SNI ?
> 
> SNI when doing what? ssl bump?
> 

Maybe, but I don't think its working properly yet. I have been laying
the background foundations for things like that with the GnuTLS support
changes so OpenSSL code may have picked up some ability (at least for
configuring multiple certs). But the https_port parts are not finished
yet and the other dev have been focussing on improving SSL-Bump.

Amos



From omidkosari at yahoo.com  Sat Apr  8 12:27:41 2017
From: omidkosari at yahoo.com (Omid Kosari)
Date: Sat, 8 Apr 2017 05:27:41 -0700 (PDT)
Subject: [squid-users] Windows Updates a Caching Stub zone,
	A windows updates store.
In-Reply-To: <05ce01d2aef3$1cb537d0$561fa770$@ngtech.co.il>
References: <004a01d1daf3$e6c4a490$b44dedb0$@ngtech.co.il>
 <1491489566256-4682002.post@n4.nabble.com>
 <05ce01d2aef3$1cb537d0$561fa770$@ngtech.co.il>
Message-ID: <1491654461829-4682033.post@n4.nabble.com>

Thanks for reply.


Eliezer Croitoru wrote
> Also what is busy for you?

The fetcher script is always downloading . For example right now i can see
that a fetcher script is running for more than 3 days and it is downloading
files one by one .


Eliezer Croitoru wrote
> Also what is busy for you?
> Are you using a lock file ?( it might be possible that your server is
> downloading in some loop and this is what causing this load)

Yes . Everything looks fine in that mean .


Eliezer Croitoru wrote
> Did you upgraded to the latest version?

Yes


I will send you the files .

Thanks




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Windows-Updates-a-Caching-Stub-zone-A-windows-updates-store-tp4678454p4682033.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From bosscb.chrisbren at gmail.com  Sat Apr  8 13:32:20 2017
From: bosscb.chrisbren at gmail.com (christian brendan)
Date: Sat, 8 Apr 2017 14:32:20 +0100
Subject: [squid-users] IP Subnet Redirect
Message-ID: <CAHptoxonEmFSVwsbNC57FhAuYND84aHdYN9p9U_h39dJ-y7aEQ@mail.gmail.com>

Hello

i have install squid and its working fine.
I have created expired IP pool: 192.168.2.0/24  and i want all client on
that subnet to be directed to my my website, eg: mycompany/expired.htm
Please how do i make this possible?

Best regards
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170408/7567af7a/attachment.htm>

From squid3 at treenet.co.nz  Sat Apr  8 15:04:58 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 9 Apr 2017 03:04:58 +1200
Subject: [squid-users] IP Subnet Redirect
In-Reply-To: <CAHptoxonEmFSVwsbNC57FhAuYND84aHdYN9p9U_h39dJ-y7aEQ@mail.gmail.com>
References: <CAHptoxonEmFSVwsbNC57FhAuYND84aHdYN9p9U_h39dJ-y7aEQ@mail.gmail.com>
Message-ID: <6de769dd-5bb5-6ec0-b5f1-49122a76da54@treenet.co.nz>

On 9/04/2017 1:32 a.m., christian brendan wrote:
> Hello
> 
> i have install squid and its working fine.
> I have created expired IP pool: 192.168.2.0/24  and i want all client on
> that subnet to be directed to my my website, eg: mycompany/expired.htm
> Please how do i make this possible?
> 

Place these lines above any "http_access allow" rules that you have:

  acl expired src 192.168.2.0/24
  acl expiredAllowed dstdomain mycompany.local
  deny_info 302:http://mycompany.local/expired.htm expired
  http_access deny !expiredAllowed expired

Amos



From turgut at kalfaoglu.com  Sun Apr  9 05:13:22 2017
From: turgut at kalfaoglu.com (=?UTF-8?Q?turgut_kalfao=c4=9flu?=)
Date: Sun, 9 Apr 2017 08:13:22 +0300
Subject: [squid-users] need an SSL example conf
Message-ID: <6dea26c0-ccb6-10ae-fdbe-0a788fe7cb11@kalfaoglu.com>

Hi there. I need help setting up SSL caching -- just for facebook.

It's a small LAN; and I would like to speed up the internet by caching 
facebook junk.

I tried to cache all SSL connections --- but connecting to bank web 
sites gave us headaches - they are apparently more strict somehow.

Does anyone have anything similar they can share?

Many thanks, -turgut




From timor at iinet.net.au  Mon Apr 10 01:36:55 2017
From: timor at iinet.net.au (daveh)
Date: Sun, 9 Apr 2017 18:36:55 -0700 (PDT)
Subject: [squid-users] https log message formatting help
In-Reply-To: <79584cf7-57f4-7deb-8558-d41d600c2bc1@treenet.co.nz>
References: <1491372053249-4681994.post@n4.nabble.com>
 <79584cf7-57f4-7deb-8558-d41d600c2bc1@treenet.co.nz>
Message-ID: <1491788215888-4682037.post@n4.nabble.com>

Thanks for the reply.

Im parsing squid logs to send to a SIEM to identify IOCs. The SIEM agent
requires a URL to be formatted with http|https://<URI>

It knows then that it can break the string out into various components such
as request URL authority, host etc

Your comment on logging https connections is not what I have found. I would
expect that typing https://something.net will return that extact string in
the log. Every https connection is logged as a CONNECT with the FQDN
appended the :443. Is there something in the config to force this to happen?
DOesnt seem to be a way of doing it with log formatting

Im simply rewriting to strip the 443 port and prepending https://. Doesn't
matter to me if CONNECT != HTTPS I simply need my url to be properly formed
in the logs



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/https-log-message-formatting-help-tp4681994p4682037.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Mon Apr 10 02:30:33 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 10 Apr 2017 14:30:33 +1200
Subject: [squid-users] need an SSL example conf
In-Reply-To: <6dea26c0-ccb6-10ae-fdbe-0a788fe7cb11@kalfaoglu.com>
References: <6dea26c0-ccb6-10ae-fdbe-0a788fe7cb11@kalfaoglu.com>
Message-ID: <ecc13125-a7a1-8108-9237-aa7f27ded4fc@treenet.co.nz>

On 9/04/2017 5:13 p.m., turgut kalfao?lu wrote:
> Hi there. I need help setting up SSL caching -- just for facebook.
> 
> It's a small LAN; and I would like to speed up the internet by caching
> facebook junk.
> 
> I tried to cache all SSL connections --- but connecting to bank web
> sites gave us headaches - they are apparently more strict somehow.
> 
> Does anyone have anything similar they can share?

You mean like ...

 acl monitoredSites ssl::server_name .facebook.com
 ssl_bump bump monitoredSites
 ssl_bump peek all
 ssl_bump splice all

That is the second config example under "Basic Splicing and Bumping" at
<http://wiki.squid-cache.org/Features/SslPeekAndSplice>.

Amos



From squid3 at treenet.co.nz  Mon Apr 10 03:35:56 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 10 Apr 2017 15:35:56 +1200
Subject: [squid-users] https log message formatting help
In-Reply-To: <1491788215888-4682037.post@n4.nabble.com>
References: <1491372053249-4681994.post@n4.nabble.com>
 <79584cf7-57f4-7deb-8558-d41d600c2bc1@treenet.co.nz>
 <1491788215888-4682037.post@n4.nabble.com>
Message-ID: <21716d8f-0027-f61f-c5e1-9305cbdfb354@treenet.co.nz>

On 10/04/2017 1:36 p.m., daveh wrote:
> Thanks for the reply.
> 
> Im parsing squid logs to send to a SIEM to identify IOCs. The SIEM agent
> requires a URL to be formatted with http|https://<URI>
> 
> It knows then that it can break the string out into various components such
> as request URL authority, host etc

So it can understand *URL* format. But that is not what is being logged.
Squid technically logs a URI, and this log processing is one of the
cases were the difference between URI and URL matters.


> 
> Your comment on logging https connections is not what I have found. I would

I think you misread what I wrote. There are only two ways to get Squid
to know what the https:// URL was - neither of them are normal proxy usage.

> expect that typing https://something.net will return that extact string in
> the log. Every https connection is logged as a CONNECT with the FQDN
> appended the :443.

You expect wrong.

The URL you entered into some client software starts with the schema
"https://" ... which requires that the fetching of that URL is done
securely. The last thing you should expect is that URL being sent over
plain-text / "in the clear" to some external software.


To do HTTPS the client software has to setup multiple layers of
protocols and security.

1) First it has to open a TCP connection to the proxy.

2) It does then have to tell the proxy where it is going to. But no more
than that. Thus the CONNECT request. As per
<https://tools.ietf.org/html/rfc7230#section-5.3.3> all that any
plain-text connection to a proxy contains is:

 CONNECT www.example.com:443 HTTP/1.1


3) Then it has to setup TLS/SSL encryption over those two TCP
connections. So the crypto happens directly between the client and the
server (as if the proxy were not there).

4) Then, and only then, after all that has been successful does it start
to send the first (or potentially many, hundreds, thousands...) of HTTP
requests over the connection:

  GET /index.html HTTP/1.1
  Host: example.com
   ...


If you look closely at that #4 layer request there is no "https://"
there. Nor any way to reconstruct it.
 It might even be another CONNECT (thought TOR invented onion routing?
HTTPS beat it by decades).

That meme from The Matrix "there is no spoon" has never been more apt.
There is no "https://" - at least, not once the client interprets its
input URL. It vanishes right there and then.



> Is there something in the config to force this to happen?

There is no simple config option. In fact we go out of our way to ensure
data accuracy. So the log contains reality and log interpreters can make
whatever assumptions you want it to about what they read there.

p-PS. I find it particularly odd that you would be trying to feed false
information into a SIEM system - security event detection depends on
accuracy of inputs. But its your neck.


> DOesnt seem to be a way of doing it with log formatting
> 

There is that logformat directive and the codes I gave in my earlier
mail. <http://www.squid-cache.org/Doc/config/logformat/> and
"%>rs://%>rd:%>rP%>rp"

If the %>rs is not producing a scheme for CONNECT transactions you could
hard-code "https". Either way its a good idea to log these faked-up
records to a different log all of their own.

Use the access_log directive to setup multiple outputs:
 <http://www.squid-cache.org/Doc/config/access_log/>


Amos



From fredbmail at free.fr  Mon Apr 10 07:52:08 2017
From: fredbmail at free.fr (FredB)
Date: Mon, 10 Apr 2017 09:52:08 +0200 (CEST)
Subject: [squid-users] Squid 3.5.23 X-forwader and log bug ?
In-Reply-To: <163809610.93463015.1491809784611.JavaMail.root@zimbra4-e1>
Message-ID: <1169327818.93509211.1491810728073.JavaMail.root@zimbra4-e1>

Hello, 

I'm debugging e2guardian and I found something in squid log the X-forwarwed IP seems not always recorded? I saw nothing particular with tcpdumd so I made a change in code (e2guardian) to show the header passed 

------------------- With problem -------------
E2 Debug:
Apr 10 09:07:49 proxytest1 e2guardian[27726]: Client: 192.168.0.5 START-------------------------------
Apr 10 09:07:49 proxytest1 e2guardian[27726]: OUT: Client IP at 192.168.0.5 header: CONNECT avissec.centprod.com:443 HTTP/1.0
Apr 10 09:07:49 proxytest1 e2guardian[27726]: OUT: Client IP at 192.168.0.5 header: User-Agent: Mozilla/5.0 (Windows NT 6.3; WOW64; rv:45.0) Gecko/20100101 Firefox/45.0
Apr 10 09:07:49 proxytest1 e2guardian[27726]: OUT: Client IP at 192.168.0.5 header: Connection: close
Apr 10 09:07:49 proxytest1 e2guardian[27726]: OUT: Client IP at 192.168.0.5 header: Connection: keep-alive
Apr 10 09:07:49 proxytest1 e2guardian[27726]: OUT: Client IP at 192.168.0.5 header: Host: avissec.centprod.com
Apr 10 09:07:49 proxytest1 e2guardian[27726]: OUT: Client IP at 192.168.0.5 header: Proxy-Authorization: Digest username="test", realm="PROXY", nonce="RS/rWAAAAADwSIzYAQAAADkmpUgAAAA", uri="avissec.centprod.com:443", response="b02fa966d373a2aaf06c43bc24a180b2", qop=auth, nc=00000001, cnonce="750b04766a809d18"
Apr 10 09:07:49 proxytest1 e2guardian[27726]: OUT: Client IP at 192.168.0.5 header: X-Forwarded-For: 192.168.0.5
Apr 10 09:07:49 proxytest1 e2guardian[27726]: Client: 192.168.0.5 END-------------------------------
 
Squid log:
127.0.0.1 - test [10/Apr/2017:09:07:54 +0200] "CONNECT avissec.centprod.com:443 HTTP/1.1" 200 33960 451 TCP_TUNNEL:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.3; WOW64; rv:45.0) Gecko/20100101 Firefox/45.0"
-------------------------------------------

-------------------- Without problem ------

E2:
Apr 10 09:07:45 proxytest1 e2guardian[27726]: Client: 192.16.0.2 START-------------------------------
Apr 10 09:07:45 proxytest1 e2guardian[27726]: OUT: Client IP at 192.16.0.2 header: CONNECT 0.client-channel.google.com:443 HTTP/1.0
Apr 10 09:07:45 proxytest1 e2guardian[27726]: OUT: Client IP at 192.16.0.2 header: User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:45.0) Gecko/20100101 Firefox/45.0
Apr 10 09:07:45 proxytest1 e2guardian[27726]: OUT: Client IP at 192.16.0.2 header: Connection: close
Apr 10 09:07:45 proxytest1 e2guardian[27726]: OUT: Client IP at 192.16.0.2 header: Connection: keep-alive
Apr 10 09:07:45 proxytest1 e2guardian[27726]: OUT: Client IP at 192.16.0.2 header: Host: 0.client-channel.google.com
Apr 10 09:07:45 proxytest1 e2guardian[27726]: OUT: Client IP at 192.16.0.2 header: Proxy-Authorization: Digest username="test", realm="PROXY", nonce="NC/rWAAAAAAgRqZUAQAAAKXVAHcAAAA", uri="0.client-channel.google.com:443", response="ec5d46ce223d987f95393e2a35557bd0", qop=auth, nc=00000036, cnonce="877bd5e852b857c5"
Apr 10 09:07:45 proxytest1 e2guardian[27726]: OUT: Client IP at 192.16.0.2 header: X-Forwarded-For: 192.16.0.2
Apr 10 09:07:45 proxytest1 e2guardian[27726]: Client: 192.16.0.2 END-------------------------------

Squid log:
192.16.0.2 - test [10/Apr/2017:09:07:16 +0200] "CONNECT 0.client-channel.google.com:443 HTTP/1.0" 200 62701 486 TCP_TUNNEL:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:45.0) Gecko/20100101 Firefox/45.0"

------------------------------------------

This not related with user, the same machine have no problem at all every day but sometime one request is logged as 127.0.0.1, of course exactly the same request have not problem at another time.
More strange there is no problem at all with HTTP requests, only HTTPS

I'm not using SSLBump just basic proxy chaining 

strip_query_terms off
logformat mylog %>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st %>st %Ss:%Sh "%{User-Agent}>h"
access_log stdio:/var/log/squid/access.log mylog
cache_log /var/log/squid/cache.log
logfile_daemon /var/log/squid/log_file_daemon
log_icp_queries off
shutdown_lifetime 1 second

coredump_dir /home/squid

pid_filename /var/run/squid.pid

follow_x_forwarded_for allow all
forwarded_for off
cache_store_log none
buffered_logs on

request_header_access X-Forwarded-For deny all
request_header_access Via deny all

acl_uses_indirect_client on
log_uses_indirect_client on
client_db off
half_closed_clients off
quick_abort_min 0 KB
quick_abort_max 0 KB

Perhaps 2/5 % of requests are wrong. 

What do you think, I open a bug ticket ?

Fred


From willsznet at gmail.com  Mon Apr 10 08:26:39 2017
From: willsznet at gmail.com (Willsz.net)
Date: Mon, 10 Apr 2017 15:26:39 +0700
Subject: [squid-users] Squid Redirection Scripting
Message-ID: <44aacabe-66a1-d9e3-07a0-2df2cd6fd9ef@gmail.com>


Hi, folks

Hi, I used Perl Scripting for 1 year couple ago. But this script doesn't 
work with new version Squid.

root:~# uname -smrm
FreeBSD 9.3-STABLE i386

root:~# squid -v
Squid Cache: Version 3.5.24
Service Name: squid
configure options:  '--prefix=/usr/local' 
'--includedir=/usr/local/include' '--bindir=/usr/local/sbin' 
'--libexecdir=/usr/local/libexec/squid' 
'--sysconfdir=/usr/local/etc/squid' '--with-default-user=squid' 
'--localstatedir=/var/cache/squid' '--libdir=/usr/local/lib' 
'--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid' 
'--with-swapdir=/var/cache/squid' '--without-gnutls' 
'--enable-build-info' '--enable-loadable-modules' 
'--enable-removal-policies=lru,heap' '--disable-epoll' 
'--disable-linux-netfilter' '--disable-linux-tproxy' 
'--disable-translation' '--disable-arch-native' 
'--mandir=/usr/local/man' '--infodir=/usr/local/info' '--disable-wccp' 
'--disable-wccpv2' '--enable-ipfw-transparent' '--enable-ssl-crtd' 
'--with-openssl' '--with-large-files' '--disable-htcp' '--disable-eui' 
'--enable-cachemgr-hostname=ip.proxy-cache.willsz.net' 
'--disable-auth-negotiate' --enable-ltdl-convenience

Here's my script:

#!/usr/local/bin/perl

$|=1;

while (<>) {
chomp;
@X = split;
$url = $X[0];

     if ( $url =~ m{ ^https?://(?:
         ad[0-9]?        |
         ad[szvx]?[0-9]? |
         ads[0-9]?       |
         adsbox          |
         adserver        |
         adservices?     |
         adserving       |
         adv             |
         advertising     |
         banners?        |
         adserver)\.(.*) }x ) {
             print "http://somedomain.com/null.png\n";
     }

     else {
         print "$url\n";
     }
}

Anyone guide me to make it work?

Thank you.


From squid3 at treenet.co.nz  Tue Apr 11 00:52:07 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 11 Apr 2017 12:52:07 +1200
Subject: [squid-users] Squid 3.5.23 X-forwader and log bug ?
In-Reply-To: <1169327818.93509211.1491810728073.JavaMail.root@zimbra4-e1>
References: <1169327818.93509211.1491810728073.JavaMail.root@zimbra4-e1>
Message-ID: <fd9ab48c-e931-8884-6cdd-c49a66044ac9@treenet.co.nz>

On 10/04/2017 7:52 p.m., FredB wrote:
> Hello, 
> 
> I'm debugging e2guardian and I found something in squid log the X-forwarwed IP seems not always recorded? I saw nothing particular with tcpdumd so I made a change in code (e2guardian) to show the header passed 
> 
> ------------------- With problem -------------
> E2 Debug:
> Apr 10 09:07:49 proxytest1 e2guardian[27726]: Client: 192.168.0.5 START-------------------------------
> Apr 10 09:07:49 proxytest1 e2guardian[27726]: OUT: Client IP at 192.168.0.5 header: CONNECT avissec.centprod.com:443 HTTP/1.0
> Apr 10 09:07:49 proxytest1 e2guardian[27726]: OUT: Client IP at 192.168.0.5 header: User-Agent: Mozilla/5.0 (Windows NT 6.3; WOW64; rv:45.0) Gecko/20100101 Firefox/45.0
> Apr 10 09:07:49 proxytest1 e2guardian[27726]: OUT: Client IP at 192.168.0.5 header: Connection: close
> Apr 10 09:07:49 proxytest1 e2guardian[27726]: OUT: Client IP at 192.168.0.5 header: Connection: keep-alive
> Apr 10 09:07:49 proxytest1 e2guardian[27726]: OUT: Client IP at 192.168.0.5 header: Host: avissec.centprod.com
> Apr 10 09:07:49 proxytest1 e2guardian[27726]: OUT: Client IP at 192.168.0.5 header: Proxy-Authorization: Digest username="test", realm="PROXY", nonce="RS/rWAAAAADwSIzYAQAAADkmpUgAAAA", uri="avissec.centprod.com:443", response="b02fa966d373a2aaf06c43bc24a180b2", qop=auth, nc=00000001, cnonce="750b04766a809d18"
> Apr 10 09:07:49 proxytest1 e2guardian[27726]: OUT: Client IP at 192.168.0.5 header: X-Forwarded-For: 192.168.0.5
> Apr 10 09:07:49 proxytest1 e2guardian[27726]: Client: 192.168.0.5 END-------------------------------
>  
> Squid log:
> 127.0.0.1 - test [10/Apr/2017:09:07:54 +0200] "CONNECT avissec.centprod.com:443 HTTP/1.1" 200 33960 451 TCP_TUNNEL:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.3; WOW64; rv:45.0) Gecko/20100101 Firefox/45.0"
> -------------------------------------------
> 
> -------------------- Without problem ------
> 
> E2:
> Apr 10 09:07:45 proxytest1 e2guardian[27726]: Client: 192.16.0.2 START-------------------------------
> Apr 10 09:07:45 proxytest1 e2guardian[27726]: OUT: Client IP at 192.16.0.2 header: CONNECT 0.client-channel.google.com:443 HTTP/1.0
> Apr 10 09:07:45 proxytest1 e2guardian[27726]: OUT: Client IP at 192.16.0.2 header: User-Agent: Mozilla/5.0 (Windows NT 6.1; WOW64; rv:45.0) Gecko/20100101 Firefox/45.0
> Apr 10 09:07:45 proxytest1 e2guardian[27726]: OUT: Client IP at 192.16.0.2 header: Connection: close
> Apr 10 09:07:45 proxytest1 e2guardian[27726]: OUT: Client IP at 192.16.0.2 header: Connection: keep-alive
> Apr 10 09:07:45 proxytest1 e2guardian[27726]: OUT: Client IP at 192.16.0.2 header: Host: 0.client-channel.google.com
> Apr 10 09:07:45 proxytest1 e2guardian[27726]: OUT: Client IP at 192.16.0.2 header: Proxy-Authorization: Digest username="test", realm="PROXY", nonce="NC/rWAAAAAAgRqZUAQAAAKXVAHcAAAA", uri="0.client-channel.google.com:443", response="ec5d46ce223d987f95393e2a35557bd0", qop=auth, nc=00000036, cnonce="877bd5e852b857c5"
> Apr 10 09:07:45 proxytest1 e2guardian[27726]: OUT: Client IP at 192.16.0.2 header: X-Forwarded-For: 192.16.0.2
> Apr 10 09:07:45 proxytest1 e2guardian[27726]: Client: 192.16.0.2 END-------------------------------
> 
> Squid log:
> 192.16.0.2 - test [10/Apr/2017:09:07:16 +0200] "CONNECT 0.client-channel.google.com:443 HTTP/1.0" 200 62701 486 TCP_TUNNEL:HIER_DIRECT "Mozilla/5.0 (Windows NT 6.1; WOW64; rv:45.0) Gecko/20100101 Firefox/45.0"
> 

When doing this debugging *the* most critical thing is to get the
correlation between logs correct.

a) e2guardian records are not loggig their UTC offset. Your correlation
may be off by up to 4 hrs judging by the Squid offset.

b) you are not logging milliseconds in either log. Since transactions
can take place fully within 1ms that is important, or you will in
best-case be off in the logs by 1 second (over 2000 requests).

c) you are not logging duration for any of these transactions. Since
Squid logs on completion that means these transactions may be off by up
to a week, or when you last restarted Squid - whichever is smaller.

 - at the very least esure e2guardian is logging on send to Squid and
have Squid log the %tr value.


So in aggregate the above Squid log entry may be for any request
e2guardian logged in the 1 week 4 hours 1 seconds beforehand.

(Realistically its only in the time since you restarted e2guardian or
Squid, but taking it to the extreme there I hope demonstrates the
reasons Squid does not log in human local time - and no other program
recording machine activity should either.)


> ------------------------------------------
> 
> This not related with user, the same machine have no problem at all every day but sometime one request is logged as 127.0.0.1, of course exactly the same request have not problem at another time.

Until you fix the above correlation issue your statement of "exact same
request" is not possible to be known.

> More strange there is no problem at all with HTTP requests, only HTTPS
> 
> I'm not using SSLBump just basic proxy chaining 
> 
> strip_query_terms off
> logformat mylog %>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st %>st %Ss:%Sh "%{User-Agent}>h"
> access_log stdio:/var/log/squid/access.log mylog
> cache_log /var/log/squid/cache.log
> logfile_daemon /var/log/squid/log_file_daemon
> log_icp_queries off
> shutdown_lifetime 1 second
> 
> coredump_dir /home/squid
> 
> pid_filename /var/run/squid.pid
> 
> follow_x_forwarded_for allow all

This is extremely dangerous. Any client can send an X-Forwarded-For
header and have Squid trust it. See
<http://www.squid-cache.org/Doc/config/follow_x_forwarded_for/> for more
details, pay attention to the "SECURITY CONSIDERATIONS" note.

The proper use of this directive is to create a src ACL that matches the
IPs Squid is supposed to be directly receiving traffic from. Then *only*
allow traffic matching that ACL to be 'followed'. As per the config
example in that documentation page.

As far as I know right now that ACL should only contain the IP
address(es) used by your e2guardian to send to Squid.


NP: When you are adjusting the e2guardian logs you may also want to
record the X-Forwaded-For headers so it records the details this
directive is trying to cope with.


> forwarded_for off
> cache_store_log none
> buffered_logs on
> 
> request_header_access X-Forwarded-For deny all
> request_header_access Via deny all
> 

FYI, the above two line are a complex and slow way of performing:

 forwarded_for delete
 via off

... especially bad since your earlier use of "forwarded_for off" is
expicitly adding an "X-Forwarded-For: unknown" header to outgoing
request traffic.


> acl_uses_indirect_client on
> log_uses_indirect_client on
> client_db off
> half_closed_clients off
> quick_abort_min 0 KB
> quick_abort_max 0 KB
> 
> Perhaps 2/5 % of requests are wrong. 
> 
> What do you think, I open a bug ticket ?

Firstly fix your squid.conf and your logging. The re-evaluate.

One other thing to consider is whether the '127.0.0.1' request is an
internal request being made by e2guardian or Squid, or some service on
the Squid machine. If it can be tracked down to any of those cases -
then it is not a bug.

Amos



From squid3 at treenet.co.nz  Tue Apr 11 01:48:58 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 11 Apr 2017 13:48:58 +1200
Subject: [squid-users] Squid Redirection Scripting
In-Reply-To: <44aacabe-66a1-d9e3-07a0-2df2cd6fd9ef@gmail.com>
References: <44aacabe-66a1-d9e3-07a0-2df2cd6fd9ef@gmail.com>
Message-ID: <69e500ef-3730-1fca-ba98-c772b2eddff2@treenet.co.nz>

On 10/04/2017 8:26 p.m., Willsz.net wrote:
> 
> Hi, folks
> 
> Hi, I used Perl Scripting for 1 year couple ago. But this script doesn't
> work with new version Squid.

Please explain "doesn't work".
Does it make all your traffic divert to cat pictures now?
  something else?


What was your previous version of Squid.
 2.7?  3.5.23?  something else?


> 
> root:~# uname -smrm
> FreeBSD 9.3-STABLE i386
> 
> root:~# squid -v
> Squid Cache: Version 3.5.24
> Service Name: squid
...
>  '--with-openssl'

NP: Since this is a self-build with OpenSSL I recommend upgrade to
3.5.25. For other reasons that your current problem, but it may solve both.


> 
> Here's my script:
> 
> #!/usr/local/bin/perl
> 
> $|=1;
> 
> while (<>) {
> chomp;
> @X = split;
> $url = $X[0];
> 
>     if ( $url =~ m{ ^https?://(?:
>         ad[0-9]?        |
>         ad[szvx]?[0-9]? |
>         ads[0-9]?       |
>         adsbox          |
>         adserver        |
>         adservices?     |
>         adserving       |
>         adv             |
>         advertising     |
>         banners?        |
>         adserver)\.(.*) }x ) {

Does that regex actually work?

1) I've never known URLs to contain long series of whitespaces like that.

2) ad[szvx]?[0-9]? matches the same things as ad[0-9]? and ads[0-9]? and
adv.



>             print "http://somedomain.com/null.png\n";
>     }
> 
>     else {
>         print "$url\n";
>     }
> }
> 
> Anyone guide me to make it work?
> 

>From the overall structure and output I am guessing that this is a Squid
URL re-writer or Store-ID helper.


IMO you should replace this simple helper with ACLs. Like so:

squid.conf:
 acl adverts_domain dtsdom_regex "/etc/squid/adverts_domain.regex"
 deny_info 302:http://somedomain.com/null.png adverts_domain
 http_access deny adverts_domain

/etc/squid/adverts_domain.regex:
   ad[szvx]?[0-9]?\.
   adsbox\.
   adserv(er|ing|ices?)\.
   adv(ertising)?\.
   banners?\.


Amos



From squid3 at treenet.co.nz  Tue Apr 11 02:52:20 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 11 Apr 2017 14:52:20 +1200
Subject: [squid-users] General security and usage questions
In-Reply-To: <1838121436.3106912.1491570075225@mail.yahoo.com>
References: <1838121436.3106912.1491570075225.ref@mail.yahoo.com>
 <1838121436.3106912.1491570075225@mail.yahoo.com>
Message-ID: <481b6136-1160-7c57-aa03-904bdce383d5@treenet.co.nz>

On 8/04/2017 1:01 a.m., j m wrote:
> I have a Ubuntu server set up that does various things in addition to
> being a web proxy (squid 3.3.8) to use remotely over the internet.
> This allows me to directly access internal devices with a web page on
> my LAN since my employer, like most, blocks VPN connections.

Please upgrade to a current Ubuntu (Xenial or later) - that will give
you access to a much better version of Squid.


>  My
> intention is to have the squid service running at all times, with a
> login, so I can use it any time.  However, there's a few things I
> have not been able to answer/resolve through my own research:

> 1. I am
> not able to SSH into my server from my employer.  It's rare I'd need
> to do this, but ethical considerations aside, could this work with
> PuTTY over the squid proxy?  I'm confused over how or if this would
> work using the Connection -> Proxy config in PuTTY.  I can
> successfully use my proxy from a web browser, but have had no luck
> with SSH despite entering the proxy info into PuTTY.  Supposedly the
> proxy needs to support the CONNECT method, but I'm unclear what this
> is or how to enable this.  As an aside, I have experimented with
> shellinabox, but abandoned it when I learned it's not encrypted by
> default.

PuTTY should be doable. You just have to configure it to use an HTTP proxy.

Then you have to configure your squid.conf to allow those requests. You
do that by:

 1) adding port 22 to the SSL_Ports and Safe_ports ACLs.

 2) adding extra custom rules to permit CONNECT to port 22 from the
IP(s) your PuTTY connections will be coming from.

 3) explicitly deny all other port 22 connections since the default
securuty lines no longer do that for you.

PuTTY should now be able to go through the proxy to wherever, the rest
is up to the server permissions at the destination.

I highly recommend that you use client cert verification and good cert
crypto rather than user:pass login - the login method would be visible
across the whole Internet to (and from) the proxy.


> 
> 2. How good is squid's security as far as leaving its port open to
> the Internet, which I obviously have to do in my case?

Depends on what you are meaning by "security".

Squid can be used as a relay to reach anywhere your http_access rules
permit. That is why the very first things we do is close off ports
0-1024 tight as possible.

So treat it as being an open hole in your network firewall to *any*
machines port 22.



>  I found it
> interesting that if I enter http://myip:myport from over the
> Internet, it responds with a "The requested URL could not be
> retrieved" page, along with information that identifies it as squid,
> along with the version number and server name, without asking for a
> login. Being unfamiliar with web proxies, this might be the norm for
> all I know.  If I set up a browser to use it as a proxy, it does ask
> for a login.  It appears the error pages are in
> /usr/share/squid/errors, but is there a way for it to be more
> discrete, preferably to not respond at all or ask for a login? Below
> is my squid.conf.  I removed all the commented lines, and pieced one
> together from information online.  My goal is to have it proxy
> basically anything thrown at it if authenticated,

That is not possible. As my most frequent comment says "Squid is an HTTP
proxy".

Meaning it only proxies/relays the protocols it understands - primary
HTTP, nowdays also FTP. Nothing else.

Any other protocol must use an HTTP CONNECT request to get through
reliably, and that depend on the sending software being aware of the
proxy being an HTTP one. Which is why the default behaviour is to
respond with an HTTP error page - so smart senders can use that info to
switch to HTTP.


> be as secure as
> reasonably possible,

FYI: Proxying anything and being secure are opposites. You only get to
pick one.


> absolutely no caching, and enable SSH
> connections through it, if possible. Thanks in advance. auth_param
> basic program /usr/lib/squid3/basic_ncsa_auth
> /etc/squid3/passwordsauth_param basic realm proxyacl authenticated
> proxy_auth REQUIREDhttp_access allow authenticated # Choose the port
> you want. Below we set it to default 3128.http_port 8092cache deny
> allaccess_log none acl CONNECT method CONNECT
> 

Please use at minimum the config file lines shown here for your current
Squid version:
 <http://wiki.squid-cache.org/Squid-3.3>
(or if you upgrade the relevant wiki page for that series)

Your own customisations should be added to those, not replacing.

NP: while debugging this new configuration it is a good idea to
re-enable the access.log outputs so you can see what is actually going
on. There is no way to decide if something is actually correct if you
cannot see it happening.

Amos


From timor at iinet.net.au  Tue Apr 11 05:33:31 2017
From: timor at iinet.net.au (daveh)
Date: Mon, 10 Apr 2017 22:33:31 -0700 (PDT)
Subject: [squid-users] https log message formatting help
In-Reply-To: <21716d8f-0027-f61f-c5e1-9305cbdfb354@treenet.co.nz>
References: <1491372053249-4681994.post@n4.nabble.com>
 <79584cf7-57f4-7deb-8558-d41d600c2bc1@treenet.co.nz>
 <1491788215888-4682037.post@n4.nabble.com>
 <21716d8f-0027-f61f-c5e1-9305cbdfb354@treenet.co.nz>
Message-ID: <1491888811130-4682048.post@n4.nabble.com>

Thanks again for the explanation


I'm not changing the raw squid log, only the normalised event. I'm simply
pulling out the url host (the FQDN) from the URL as my SIEM agent doesn't
natively understand how to parse these CONNECT messages.  It doesnt matter
to me if CONNECT requests are not always https requests. For my purposes I
need to compare the FQDN to a list of IOCs.

If I have a use case specific to the use of CONNECT requests in the future,
I still have all of that  information as is, from the proxy.





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/https-log-message-formatting-help-tp4681994p4682048.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From willsznet at gmail.com  Tue Apr 11 05:51:32 2017
From: willsznet at gmail.com (Willsz.net)
Date: Tue, 11 Apr 2017 12:51:32 +0700
Subject: [squid-users] Squid Redirection Scripting
In-Reply-To: <69e500ef-3730-1fca-ba98-c772b2eddff2@treenet.co.nz>
References: <44aacabe-66a1-d9e3-07a0-2df2cd6fd9ef@gmail.com>
 <69e500ef-3730-1fca-ba98-c772b2eddff2@treenet.co.nz>
Message-ID: <f1419129-c6c2-3044-b384-0f654ada3d1a@gmail.com>

On 11/04/2017 8:48, Amos Jeffries wrote:
> On 10/04/2017 8:26 p.m., Willsz.net wrote:
>>
>> Hi, folks
>>
>> Hi, I used Perl Scripting for 1 year couple ago. But this script doesn't
>> work with new version Squid.
>
> Please explain "doesn't work".
> Does it make all your traffic divert to cat pictures now?
>   something else?

Thank Amos,

Let me explain more detail, something like this:

root:~# cat /usr/local/bin/squid-rdr
#!/usr/local/bin/perl

$|=1;

while (<>) {
chomp;
@X = split;
$url = $X[0];

     if ( $url =~ m{ ^https?://(?:
         ad[0-9]?        |
         ad[szvx]?[0-9]? |
         ads[0-9]?       |
         adsbox          |
         adserver        |
         adservices?     |
         adserving       |
         adv             |
         advertising     |
         banners?        |
         adserver)\.(.*) }x ) {
             print "http://somedomain.com/null.png\n";
     }

     else {
         print "$url\n";
     }
}

root:~# chown squid:squid /usr/local/bin/squid-rdr
root:~# chmod 755 /usr/local/bin/squid-rdr

Afterward, I add in /usr/local/etc/squid/squid.conf:

url_rewrite_program /usr/local/bin/squid-rdr
url_rewrite_children 32 startup=0 idle=1 concurrency=0
url_rewrite_bypass on

root:~# /usr/local/etc/rc.d/squid.sh reload
Reload proxy system...

Trying to browse some URL, so I get this error message and I failed to 
retrieve web-page.

root:~# tail /var/log/squid/cache.log
2017/04/11 12:24:38 kid1| helperOpenServers: Starting 1/32 'squid-rdr' 
processes
2017/04/11 12:24:38 kid1| assertion failed: ../src/base/Lock.h:30: 
"count_ == 0"


> What was your previous version of Squid.
>  2.7?  3.5.23?  something else?

Sorry, I forgot exactly version, maybe squid-3.5.13/squid-3.5.14. Which 
I remember at that time, I was hit by DDoS. So I change to latest version.

>> Here's my script:
>>
>> #!/usr/local/bin/perl
>>
>> $|=1;
>>
>> while (<>) {
>> chomp;
>> @X = split;
>> $url = $X[0];
>>
>>     if ( $url =~ m{ ^https?://(?:
>>         ad[0-9]?        |
>>         ad[szvx]?[0-9]? |
>>         ads[0-9]?       |
>>         adsbox          |
>>         adserver        |
>>         adservices?     |
>>         adserving       |
>>         adv             |
>>         advertising     |
>>         banners?        |
>>         adserver)\.(.*) }x ) {
>
> Does that regex actually work?
>
> 1) I've never known URLs to contain long series of whitespaces like that.
>
> 2) ad[szvx]?[0-9]? matches the same things as ad[0-9]? and ads[0-9]? and
> adv.

Yes, that script work in previous version of Squid.

>
>>             print "http://somedomain.com/null.png\n";
>>     }
>>
>>     else {
>>         print "$url\n";
>>     }
>> }
>>
>> Anyone guide me to make it work?
>>
>
> From the overall structure and output I am guessing that this is a Squid
> URL re-writer or Store-ID helper.
>
>
> IMO you should replace this simple helper with ACLs. Like so:
>
> squid.conf:
>  acl adverts_domain dtsdom_regex "/etc/squid/adverts_domain.regex"
>  deny_info 302:http://somedomain.com/null.png adverts_domain
>  http_access deny adverts_domain
>
> /etc/squid/adverts_domain.regex:
>    ad[szvx]?[0-9]?\.
>    adsbox\.
>    adserv(er|ing|ices?)\.
>    adv(ertising)?\.
>    banners?\.

OK, let me try first. Thank you Amos.




From bosscb.chrisbren at gmail.com  Tue Apr 11 10:28:48 2017
From: bosscb.chrisbren at gmail.com (christian brendan)
Date: Tue, 11 Apr 2017 11:28:48 +0100
Subject: [squid-users] IP Subnet Redirect
Message-ID: <CAHptoxpWe57HZ4g8kchbNg48h4R-5t8oP_Fm=JP=E3Tar1aL4A@mail.gmail.com>

On Sun, Apr 9, 2017 at 1:00 PM, <squid-users-request at lists.squid-cache.org>
wrote:

> Send squid-users mailing list submissions to
>         squid-users at lists.squid-cache.org
>
> To subscribe or unsubscribe via the World Wide Web, visit
>         http://lists.squid-cache.org/listinfo/squid-users
> or, via email, send a message with subject or body 'help' to
>         squid-users-request at lists.squid-cache.org
>
> You can reach the person managing the list at
>         squid-users-owner at lists.squid-cache.org
>
> When replying, please edit your Subject line so it is more specific
> than "Re: Contents of squid-users digest..."
>
>
> Today's Topics:
>
>    1. Re: Windows Updates a Caching Stub zone,  A windows updates
>       store. (Omid Kosari)
>    2. IP Subnet Redirect (christian brendan)
>    3. Re: IP Subnet Redirect (Amos Jeffries)
>    4. need an SSL example conf (turgut kalfao?lu)
>
>
> ----------------------------------------------------------------------
>
> Message: 1
> Date: Sat, 8 Apr 2017 05:27:41 -0700 (PDT)
> From: Omid Kosari <omidkosari at yahoo.com>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Windows Updates a Caching Stub zone, A
>         windows updates store.
> Message-ID: <1491654461829-4682033.post at n4.nabble.com>
> Content-Type: text/plain; charset=us-ascii
>
> Thanks for reply.
>
>
> Eliezer Croitoru wrote
> > Also what is busy for you?
>
> The fetcher script is always downloading . For example right now i can see
> that a fetcher script is running for more than 3 days and it is downloading
> files one by one .
>
>
> Eliezer Croitoru wrote
> > Also what is busy for you?
> > Are you using a lock file ?( it might be possible that your server is
> > downloading in some loop and this is what causing this load)
>
> Yes . Everything looks fine in that mean .
>
>
> Eliezer Croitoru wrote
> > Did you upgraded to the latest version?
>
> Yes
>
>
> I will send you the files .
>
> Thanks
>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.
> 1019090.n4.nabble.com/Windows-Updates-a-Caching-Stub-zone-A-
> windows-updates-store-tp4678454p4682033.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
>
>
> ------------------------------
>
> Message: 2
> Date: Sat, 8 Apr 2017 14:32:20 +0100
> From: christian brendan <bosscb.chrisbren at gmail.com>
> To: squid-users at lists.squid-cache.org,
>         squid-users-owner at lists.squid-cache.org
> Subject: [squid-users] IP Subnet Redirect
> Message-ID:
>         <CAHptoxonEmFSVwsbNC57FhAuYND84aHdYN9p9U_h39dJ-y7aEQ at mail.
> gmail.com>
> Content-Type: text/plain; charset="utf-8"
>
> Hello
>
> i have install squid and its working fine.
> I have created expired IP pool: 192.168.2.0/24  and i want all client on
> that subnet to be directed to my my website, eg: mycompany/expired.htm
> Please how do i make this possible?
>
> Best regards
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: <http://lists.squid-cache.org/pipermail/squid-users/
> attachments/20170408/7567af7a/attachment-0001.html>
>
> ------------------------------
>
> Message: 3
> Date: Sun, 9 Apr 2017 03:04:58 +1200
> From: Amos Jeffries <squid3 at treenet.co.nz>
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] IP Subnet Redirect
> Message-ID: <6de769dd-5bb5-6ec0-b5f1-49122a76da54 at treenet.co.nz>
> Content-Type: text/plain; charset=utf-8
>
> On 9/04/2017 1:32 a.m., christian brendan wrote:
> > Hello
> >
> > i have install squid and its working fine.
> > I have created expired IP pool: 192.168.2.0/24  and i want all client on
> > that subnet to be directed to my my website, eg: mycompany/expired.htm
> > Please how do i make this possible?
> >
>
> Place these lines above any "http_access allow" rules that you have:
>
>   acl expired src 192.168.2.0/24
>   acl expiredAllowed dstdomain mycompany.local
>   deny_info 302:http://mycompany.local/expired.htm expired
>   http_access deny !expiredAllowed expired
>
> Amos
>
>
>
> ------------------------------
>
> Message: 4
> Date: Sun, 9 Apr 2017 08:13:22 +0300
> From: turgut kalfao?lu <turgut at kalfaoglu.com>
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] need an SSL example conf
> Message-ID: <6dea26c0-ccb6-10ae-fdbe-0a788fe7cb11 at kalfaoglu.com>
> Content-Type: text/plain; charset=utf-8; format=flowed
>
> Hi there. I need help setting up SSL caching -- just for facebook.
>
> It's a small LAN; and I would like to speed up the internet by caching
> facebook junk.
>
> I tried to cache all SSL connections --- but connecting to bank web
> sites gave us headaches - they are apparently more strict somehow.
>
> Does anyone have anything similar they can share?
>
> Many thanks, -turgut
>
>
>
>
> ------------------------------
>
> Subject: Digest Footer
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> ------------------------------
>
> End of squid-users Digest, Vol 32, Issue 15
> *******************************************
>


@Amos Jeffries Thanks alot for your prompt response, i will try your conf
over the weekend and provide feedback.?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170411/08651dc1/attachment.htm>

From maik.linnemann at modelco.de  Tue Apr 11 10:44:55 2017
From: maik.linnemann at modelco.de (Maik Linnemann)
Date: Tue, 11 Apr 2017 10:44:55 +0000
Subject: [squid-users] Squid 3.4.8 Reverse with multiple SSL Sites and
 multiple Certs/Domains
Message-ID: <E8C0D58036A98440B317EA23130CF55B67947A@ms-exchange-01.provit.info>



Dear List, 

i use squid3 as reverse Proxy since a while for multiple sites, hosted on different targets. All those sites work with SSL they use a wildcard cert. It works well so far. Now i need to host another site, with a different domain and another ssl certificate. Can i configure squid to use cert by the requested url likewise? i just tried to copy my existing stuff and edit it to another cert, but this doesnt take me far as squid always takes the main cert file. my config is like:

<FROM HERE I AM GOOD>

https_port <IP>:443 accel vhost defaultsite=webmail.somedomain.info cert=/etc/squid3/certs/wildcard/wirldcard.crt key=/etc/squid3/certs/wildcard/wildcard.key
cache_peer 192.168.111.20 parent 443 0 proxy-only no-query no-digest login=PASS connection-auth=off ssl sslflags=DONT_VERIFY_PEER,DONT_VERIFY_DOMAIN originserver name=webmail
cache_peer_domain webmail ssl webmail.somedomain.info
acl url_allow url_regex -i ^https://webmail.somedomain.info/owa.*$
acl url_allow url_regex -i ^https://webmail.somedomain.info/ecp.*$

cache_peer 192.168.111.51 parent 443 0 proxy-only no-query no-digest login=PASS connection-auth=off ssl sslflags=DONT_VERIFY_PEER,DONT_VERIFY_DOMAIN originserver name=git
cache_peer_domain git ssl git.somedomain.info
acl url_allow url_regex -i ^https://git.somedomain.info/.*$

<UNTIL HERE I AM GOOD>

<THIS IS NOT REALLY WORKING>

https_port www.anotherdomain.de:443 accel vhost defaultsite=anotherdomain.de cert=/etc/ssl/certs-anotherdomain.de/anotherdomain.de.pem key=/etc/ssl/private-anotherdomain.de/anotherdomain.de.key
cache_peer 192.168.1.1 parent 443 0 proxy-only no-query no-digest login=PASS connection-auth=off ssl sslflags=DONT_VERIFY_PEER,DONT_VERIFY_DOMAIN originserver name=anotherdomain

<THIS IS NOT REALLY WORKING>

How can i host multiple Sites and tell squid to use the cert i attach to each site or domain?

thanks in advance, 

with regards,


From bhoslepu at gmail.com  Tue Apr 11 11:38:16 2017
From: bhoslepu at gmail.com (prashantbhosale)
Date: Tue, 11 Apr 2017 04:38:16 -0700 (PDT)
Subject: [squid-users] Squid SSL Intercept have issues apps on iOS
Message-ID: <1491910696185-4682052.post@n4.nabble.com>

I was trying to setup Squid transparent SSLBump and its working. But it
giving problem for Apple apps. 
According to threads on mailing list excluded domains (.apple.com
.icloud.com .mzstatic.com .akamaihd.net .dropbox.com) then App Store works
(browsing apps, searching apps) but app installation(from App store) fails
with below squid access log:
1491910115.715     51 10.99.1.1 TAG_NONE/200 0 CONNECT 17.154.66.226:443 -
ORIGINAL_DST/17.154.66.226 -
1491910116.537     52 10.99.1.1 TAG_NONE/200 0 CONNECT 17.154.66.74:443 -
ORIGINAL_DST/17.154.66.74 -

Same issue is happening with Dropbox also, Dropbox app not syncing with
server.


Conf:
http_port 3128 intercept ssl-bump \
  cert=/etc/squid/ssl_cert/myCA.pem \
  generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

acl local-servers dstdomain "/etc/squid/allowed.txt"

ssl_bump peek step1
ssl_bump splice local-servers
ssl_bump bump all
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER

Is anybody has working conf for sslbump with exclude the HTTP Public Key
Pinning (HPKP) mechanism.




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-SSL-Intercept-have-issues-apps-on-iOS-tp4682052.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Tue Apr 11 18:09:52 2017
From: chip_pop at hotmail.com (joseph)
Date: Tue, 11 Apr 2017 11:09:52 -0700 (PDT)
Subject: [squid-users] purge cmd and headers ??
Message-ID: <1491934192581-4682053.post@n4.nabble.com>

by using purge command 
is there a way just to  search for headers that contain specific info
like  CF-RAY  and purge all ????????? 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/purge-cmd-and-headers-tp4682053.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Tue Apr 11 18:31:19 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 11 Apr 2017 20:31:19 +0200
Subject: [squid-users] purge cmd and headers ??
In-Reply-To: <1491934192581-4682053.post@n4.nabble.com>
References: <1491934192581-4682053.post@n4.nabble.com>
Message-ID: <201704112031.19453.Antony.Stone@squid.open.source.it>

On Tuesday 11 April 2017 at 20:09:52, joseph wrote:

> by using purge command
> is there a way just to  search for headers that contain specific info
> like  CF-RAY  and purge all ?????????

Why do you feel the need to purge items selectively from your cache?

If the objects are requested again, you've lost the opportunity to save some 
bandwidth.

If the objects are not requested again, what does it matter that they're in 
the cache?

Old objects will get expired anyway - your cache doesn't grow indefinitely.


Antony.

-- 
You can spend the whole of your life trying to be popular,
but at the end of the day the size of the crowd at your funeral
will be largely dictated by the weather.

 - Frank Skinner

                                                   Please reply to the list;
                                                         please *don't* CC me.


From chip_pop at hotmail.com  Tue Apr 11 18:35:50 2017
From: chip_pop at hotmail.com (joseph)
Date: Tue, 11 Apr 2017 11:35:50 -0700 (PDT)
Subject: [squid-users] purge cmd and headers ??
In-Reply-To: <201704112031.19453.Antony.Stone@squid.open.source.it>
References: <1491934192581-4682053.post@n4.nabble.com>
 <201704112031.19453.Antony.Stone@squid.open.source.it>
Message-ID: <1491935750173-4682055.post@n4.nabble.com>

>Why do you feel the need to purge items selectively from your cache?
i do not feel the need
>If the objects are requested again, you've lost the opportunity to save
some 
>bandwidth.
i know wat im doing this is why im in control lol
huge videos data my old provider has bluecoat behind my real bandwidth wish
is now bad cached item
the reason  i keep them very long in cache i need to get rid off
now no bluecoat so the headers changed  they will be miss
>Old objects will get expired anyway - your cache doesn't grow indefinitely.
ya that i know after a year or so lol very bad and i do keep video that ppl
use all the time same same same 





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/purge-cmd-and-headers-tp4682053p4682055.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed Apr 12 01:22:19 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 12 Apr 2017 13:22:19 +1200
Subject: [squid-users] Squid 3.4.8 Reverse with multiple SSL Sites and
 multiple Certs/Domains
In-Reply-To: <E8C0D58036A98440B317EA23130CF55B67947A@ms-exchange-01.provit.info>
References: <E8C0D58036A98440B317EA23130CF55B67947A@ms-exchange-01.provit.info>
Message-ID: <cda05731-6239-6358-1dee-aacaeb747f6a@treenet.co.nz>

On 11/04/2017 10:44 p.m., Maik Linnemann wrote:
> 
> 
> Dear List,
> 
> i use squid3 as reverse Proxy since a while for multiple sites,
> hosted on different targets. All those sites work with SSL they use a
> wildcard cert. It works well so far. Now i need to host another site,
> with a different domain and another ssl certificate. Can i configure
> squid to use cert by the requested url likewise?

Yes, but currently it requires multiple https_port lines, one for each
certificate. That means you will required multiple IPs since the port
values are both 443.


Amos



From squid3 at treenet.co.nz  Wed Apr 12 01:39:38 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 12 Apr 2017 13:39:38 +1200
Subject: [squid-users] Squid SSL Intercept have issues apps on iOS
In-Reply-To: <1491910696185-4682052.post@n4.nabble.com>
References: <1491910696185-4682052.post@n4.nabble.com>
Message-ID: <92175640-6d77-f170-bca3-6a731fa8f56a@treenet.co.nz>

On 11/04/2017 11:38 p.m., prashantbhosale wrote:
> I was trying to setup Squid transparent SSLBump and its working. But it
> giving problem for Apple apps. 
> According to threads on mailing list excluded domains (.apple.com
> .icloud.com .mzstatic.com .akamaihd.net .dropbox.com) then App Store works
> (browsing apps, searching apps) but app installation(from App store) fails
> with below squid access log:
> 1491910115.715     51 10.99.1.1 TAG_NONE/200 0 CONNECT 17.154.66.226:443 -
> ORIGINAL_DST/17.154.66.226 -
> 1491910116.537     52 10.99.1.1 TAG_NONE/200 0 CONNECT 17.154.66.74:443 -
> ORIGINAL_DST/17.154.66.74 -

Please read
<http://wiki.squid-cache.org/Features/SslPeekAndSplice#Processing_steps>

The above log enties look like the step 1.i CONNECT requests to me.
TLS/SSL has not started at that point and ssl_bump has not even been
considered.

Later on ...

> sslproxy_cert_error allow all

... you have disabled all errors from being visible to anyone.
*including you*.

> sslproxy_flags DONT_VERIFY_PEER

... and you have disabled all TLS security protections.

> 
> Is anybody has working conf for sslbump with exclude the HTTP Public Key
> Pinning (HPKP) mechanism.

There is no way to know whether the pinning is being used, nor even what
software was being used. Some client IP connects and signals that it
needs TLS. Then exists as soon as TLS is sent ot it. End of story.

There are a large number of things that could be going on when a client
simply disappears like that. As humans we can know a lot of contextual
information about the whole situation and decide that its HPKP - but the
software on the spot when it happened does not have any of that extra
info to work with.

Amos



From maik.linnemann at modelco.de  Wed Apr 12 08:05:30 2017
From: maik.linnemann at modelco.de (Maik Linnemann)
Date: Wed, 12 Apr 2017 08:05:30 +0000
Subject: [squid-users] Squid 3.4.8 Reverse with multiple SSL Sites and
 multiple Certs/Domains
In-Reply-To: <cda05731-6239-6358-1dee-aacaeb747f6a@treenet.co.nz>
References: <E8C0D58036A98440B317EA23130CF55B67947A@ms-exchange-01.provit.info>,
 <cda05731-6239-6358-1dee-aacaeb747f6a@treenet.co.nz>
Message-ID: <E8C0D58036A98440B317EA23130CF55B67FBFD@ms-exchange-01.provit.info>

Thanks Amos. Unfortunately i only have one public IP to use for the reverse squid. I thought there might be an equivalent to apaches name based hosts or similar. 
________________________________________
Von: squid-users [squid-users-bounces at lists.squid-cache.org]&quot; im Auftrag von &quot;Amos Jeffries [squid3 at treenet.co.nz]
Gesendet: Mittwoch, 12. April 2017 03:22
An: squid-users at lists.squid-cache.org
Betreff: Re: [squid-users] Squid 3.4.8 Reverse with multiple SSL Sites and multiple Certs/Domains

On 11/04/2017 10:44 p.m., Maik Linnemann wrote:
>
>
> Dear List,
>
> i use squid3 as reverse Proxy since a while for multiple sites,
> hosted on different targets. All those sites work with SSL they use a
> wildcard cert. It works well so far. Now i need to host another site,
> with a different domain and another ssl certificate. Can i configure
> squid to use cert by the requested url likewise?

Yes, but currently it requires multiple https_port lines, one for each
certificate. That means you will required multiple IPs since the port
values are both 443.


Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From irakli.gobejishvili at gmail.com  Wed Apr 12 14:24:31 2017
From: irakli.gobejishvili at gmail.com (Irakli Gobejishvili)
Date: Wed, 12 Apr 2017 18:24:31 +0400
Subject: [squid-users] Squid 3.5.15 - ERR_CONNECTION_REFUSED while accessing
 blocked non-HTTPS pages.
Message-ID: <CAMAVjKSSNScNaNCshh-k94MRX7SPxU+JfHAHvahcj1_n9yVR+Q@mail.gmail.com>

Hello everyone.

I am successfully filtering HTTPS traffic with intercept/PBR setup and
users get my custom ERR_ACCESS_DENIED page from Squid. Permitted pages
(both HTTP/HTTPS) also work absolutely fine.

The problem is, when users try to access filtered page with HTTP request,
then they get ERR_CONNECTION_REFUSED in their browsers, instead of seeing
that custom deny page and I see nothing in access.log, as if Squid never
even got the request. If I remove that domain from deny ACL or access it
via HTTPS, then it works fine and can be seen in access.log. What can I do
to fix this?


Relevant fragment from configuration:

acl CONNECT method CONNECT
reply_header_access Alternate-Protocol deny all

ssl_bump stare all
ssl_bump bump all
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER

acl BADSITES ssl::server_name "/etc/squid/BADSITES"
acl USERS src 10.10.80.0/24

http_access deny BADSITES USERS
http_access allow USERS

http_port 3128
https_port 3130 intercept ssl-bump connection-auth=off
generate-host-certificates=on dynamic_cert_mem_cache_size=8MB
cert=/etc/squid/ssl_cert/CA.pem
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170412/acfc83a8/attachment.htm>

From squid3 at treenet.co.nz  Wed Apr 12 16:13:01 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 13 Apr 2017 04:13:01 +1200
Subject: [squid-users] Squid 3.4.8 Reverse with multiple SSL Sites and
 multiple Certs/Domains
In-Reply-To: <E8C0D58036A98440B317EA23130CF55B67EBD1@ms-exchange-01.provit.info>
References: <E8C0D58036A98440B317EA23130CF55B67947A@ms-exchange-01.provit.info>
 <cda05731-6239-6358-1dee-aacaeb747f6a@treenet.co.nz>
 <E8C0D58036A98440B317EA23130CF55B67EBD1@ms-exchange-01.provit.info>
Message-ID: <06b6bafc-9892-31f3-3fe6-8e52e29cbf84@treenet.co.nz>

On 12/04/2017 7:58 p.m., Maik Linnemann wrote:
> Thanks Amos. Unfortunately i only have one public IP to use for the reverse squid. I thought there might be an equivalent to apaches name based hosts or similar. 

TLS protocol does contain SNI feature, but support for that in
reverse-proxy is not yet complete.

You have a few other options that are less pleasing:

 * using a different port number instead of different IP, or

 * finding someone to complete the SNI reverse-proxy code in Squid, or

 * using a non-Squid proxy temporarily in front of Squid to split the
traffic on SNI.

Amos



From squid3 at treenet.co.nz  Wed Apr 12 16:17:13 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 13 Apr 2017 04:17:13 +1200
Subject: [squid-users] Squid 3.5.15 - ERR_CONNECTION_REFUSED while
 accessing blocked non-HTTPS pages.
In-Reply-To: <CAMAVjKSSNScNaNCshh-k94MRX7SPxU+JfHAHvahcj1_n9yVR+Q@mail.gmail.com>
References: <CAMAVjKSSNScNaNCshh-k94MRX7SPxU+JfHAHvahcj1_n9yVR+Q@mail.gmail.com>
Message-ID: <c6e4918d-3a93-19ac-4ecb-feeca7208585@treenet.co.nz>

SSL-Bump featres in Squid are still very volatile. What appear to be
minor change can have big behaviour differences and security fixes
between any two releases. It is not worth anyones time (including yours)
re-debugging and re-fixing an older release for things that have already
been fixed.

So, Rule #1 when using those features is to follow new releases. If any
problems are encountered try the very latest to see if it is fixed.
Today that is 3.5.25, or if 3.5 is still affected the 4.0.19 beta.


On 13/04/2017 2:24 a.m., Irakli Gobejishvili wrote:
> Hello everyone.
> 
> I am successfully filtering HTTPS traffic with intercept/PBR setup and
> users get my custom ERR_ACCESS_DENIED page from Squid. Permitted pages
> (both HTTP/HTTPS) also work absolutely fine.
> 
> The problem is, when users try to access filtered page with HTTP request,
> then they get ERR_CONNECTION_REFUSED in their browsers, instead of seeing
> that custom deny page and I see nothing in access.log, as if Squid never
> even got the request. If I remove that domain from deny ACL or access it
> via HTTPS, then it works fine and can be seen in access.log. What can I do
> to fix this?

What is the exact traffic behaviour that is going on?

"filtering HTTPS traffic with intercept/PBR setup" tells us nothing
about the tiny but critical input details that the security systems huge
differences in correct vs wrong behaviour hinge on.

 and what do you think Squid is doing in reaction to that?



> 
> Relevant fragment from configuration:
> 
> acl CONNECT method CONNECT
> reply_header_access Alternate-Protocol deny all
> 
> ssl_bump stare all
> ssl_bump bump all
> sslproxy_cert_error allow all
> sslproxy_flags DONT_VERIFY_PEER

Ah, sure. Things can look like they are working well when you hide all
possible TLS/SSL errors from yourself (and the users).

Anything major could be going on and you simply not seeing it.


> 
> acl BADSITES ssl::server_name "/etc/squid/BADSITES"
> acl USERS src 10.10.80.0/24
> 

Missing:
 http_access deny !Safe_ports
 http_access deny CONNECT !SSL_Ports
 http_acecss deny !localhost manager

> http_access deny BADSITES USERS
> http_access allow USERS
> 

Missing:
 http_access deny all


> http_port 3128
> https_port 3130 intercept ssl-bump connection-auth=off
> generate-host-certificates=on dynamic_cert_mem_cache_size=8MB
> cert=/etc/squid/ssl_cert/CA.pem
> 

Amos



From eliezer at ngtech.co.il  Wed Apr 12 18:15:39 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Wed, 12 Apr 2017 21:15:39 +0300
Subject: [squid-users] Squid 3.4.8 Reverse with multiple SSL Sites and
	multiple Certs/Domains
In-Reply-To: <06b6bafc-9892-31f3-3fe6-8e52e29cbf84@treenet.co.nz>
References: <E8C0D58036A98440B317EA23130CF55B67947A@ms-exchange-01.provit.info>
 <cda05731-6239-6358-1dee-aacaeb747f6a@treenet.co.nz>
 <E8C0D58036A98440B317EA23130CF55B67EBD1@ms-exchange-01.provit.info>
 <06b6bafc-9892-31f3-3fe6-8e52e29cbf84@treenet.co.nz>
Message-ID: <026001d2b3b8$ca33c330$5e9b4990$@ngtech.co.il>

You can try to use haproxy, nginx, varnish or any other proxy.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Wednesday, April 12, 2017 7:13 PM
To: Maik Linnemann <maik.linnemann at provit.info>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid 3.4.8 Reverse with multiple SSL Sites and multiple Certs/Domains

On 12/04/2017 7:58 p.m., Maik Linnemann wrote:
> Thanks Amos. Unfortunately i only have one public IP to use for the reverse squid. I thought there might be an equivalent to apaches name based hosts or similar. 

TLS protocol does contain SNI feature, but support for that in reverse-proxy is not yet complete.

You have a few other options that are less pleasing:

 * using a different port number instead of different IP, or

 * finding someone to complete the SNI reverse-proxy code in Squid, or

 * using a non-Squid proxy temporarily in front of Squid to split the traffic on SNI.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Wed Apr 12 18:16:36 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 13 Apr 2017 06:16:36 +1200
Subject: [squid-users] [RFC] Changes to http_access defaults
Message-ID: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>

When I implemented the major changes to squid.conf in 3.1/3.2  there
were a lot of installations placing custom config rules above the lines
I describe now as "default security checks". The !Safe_ports and
!SSL_ports deny lines.

At the time I also believed reverse-proxy config had to go above that to
work properly. Which was the major argument behind leaving them manually
configured.

That reverse-proxy reason has turned out to be incorrect and over the
years since I have become convinced that Squid always checks those
security rules, then do the custom access rules. All other orderings
seem to have turned out to be problematic and security-buggy in some
edge cases or another.


What are peoples opinions about making the following items built-in
defaults?

 acl Safe_ports port 21 80 443
 acl CONNECT_ports port 443
 acl CONNECT method CONNECT

 http_acces deny !Safe_ports
 http_access deny CONNECT !CONNECT_ports


This makes the three protocols Squid-4/5 can officially support (HTTP,
HTTPS, FTP) acceptable by default.

I have excluded the other protocols that are safe, but usually not
necessary to proxy in modern traffic. They can remain 'recommended'
configurable defaults like today.

Likewise the manager rules (for now) since local conditions can
sometimes allow them to be optimized better than our current recommended
default.


The above change will have some effect on installations that try to use
an empty squid.conf. If the proposal goes ahead some extra additions
would be included to retain that default-reject behaviour.

Ideas? opinions?


Amos


From maik.linnemann at modelco.de  Wed Apr 12 19:13:15 2017
From: maik.linnemann at modelco.de (Maik Linnemann)
Date: Wed, 12 Apr 2017 19:13:15 +0000
Subject: [squid-users] Squid 3.4.8 Reverse with multiple SSL Sites
	and	multiple Certs/Domains
In-Reply-To: <026001d2b3b8$ca33c330$5e9b4990$@ngtech.co.il>
References: <E8C0D58036A98440B317EA23130CF55B67947A@ms-exchange-01.provit.info>
 <cda05731-6239-6358-1dee-aacaeb747f6a@treenet.co.nz>
 <E8C0D58036A98440B317EA23130CF55B67EBD1@ms-exchange-01.provit.info>
 <06b6bafc-9892-31f3-3fe6-8e52e29cbf84@treenet.co.nz>
 <026001d2b3b8$ca33c330$5e9b4990$@ngtech.co.il>
Message-ID: <E8C0D58036A98440B317EA23130CF55B67FC3E@ms-exchange-01.provit.info>

I figured out that nginx is able to do what i want, at least SNI and multiple certs. I am forced to try that in the meantime. Also i will check varnish. Is there any realistic date when SNI is available in reverse proxy with squid? Is there anyone coding at all for that feature?

-----Urspr?ngliche Nachricht-----
Von: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] Im Auftrag von Eliezer Croitoru
Gesendet: Mittwoch, 12. April 2017 20:16
An: 'Amos Jeffries' <squid3 at treenet.co.nz>; Maik Linnemann <maik.linnemann at modelco.de>; squid-users at lists.squid-cache.org
Betreff: Re: [squid-users] Squid 3.4.8 Reverse with multiple SSL Sites and multiple Certs/Domains

You can try to use haproxy, nginx, varnish or any other proxy.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Wednesday, April 12, 2017 7:13 PM
To: Maik Linnemann <maik.linnemann at provit.info>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid 3.4.8 Reverse with multiple SSL Sites and multiple Certs/Domains

On 12/04/2017 7:58 p.m., Maik Linnemann wrote:
> Thanks Amos. Unfortunately i only have one public IP to use for the reverse squid. I thought there might be an equivalent to apaches name based hosts or similar. 

TLS protocol does contain SNI feature, but support for that in reverse-proxy is not yet complete.

You have a few other options that are less pleasing:

 * using a different port number instead of different IP, or

 * finding someone to complete the SNI reverse-proxy code in Squid, or

 * using a non-Squid proxy temporarily in front of Squid to split the traffic on SNI.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From squid3 at treenet.co.nz  Wed Apr 12 22:56:22 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 13 Apr 2017 10:56:22 +1200
Subject: [squid-users] Squid 3.4.8 Reverse with multiple SSL Sites and
 multiple Certs/Domains
In-Reply-To: <E8C0D58036A98440B317EA23130CF55B67FC3E@ms-exchange-01.provit.info>
References: <E8C0D58036A98440B317EA23130CF55B67947A@ms-exchange-01.provit.info>
 <cda05731-6239-6358-1dee-aacaeb747f6a@treenet.co.nz>
 <E8C0D58036A98440B317EA23130CF55B67EBD1@ms-exchange-01.provit.info>
 <06b6bafc-9892-31f3-3fe6-8e52e29cbf84@treenet.co.nz>
 <026001d2b3b8$ca33c330$5e9b4990$@ngtech.co.il>
 <E8C0D58036A98440B317EA23130CF55B67FC3E@ms-exchange-01.provit.info>
Message-ID: <bbc405d8-e3b4-f4d0-a74f-d96264430f87@treenet.co.nz>

On 13/04/2017 7:13 a.m., Maik Linnemann wrote:
> I figured out that nginx is able to do what i want, at least SNI and
> multiple certs. I am forced to try that in the meantime. Also i will
> check varnish. Is there any realistic date when SNI is available in
> reverse proxy with squid? Is there anyone coding at all for that
> feature?
> 

I've been working on it as part of the  GnuTLS support in Squid-4.
https_port can now be configured with multiple cert= key= parameter
pairs. But loading any past the first pair with OpenSSL builds is still
missing.

I _think_ all that is left now (for OpenSSL builds) is to alter that
logic loading cert= files into the server context. But I have not
investigated those details closely yet.

My focus in the 'free' work is getting GnuTLS working for Debian/Ubuntu
and refactoring for more easy porting to other backend libraries in
future (Fedora, RHEL and Apple want other libraries). I intend for SNI
to be usable out of the box with GnuTLS builds. Someone may do OpenSSL
changes to match by the time it goes public - I cannot test it so that
depends on others.

Amos



From rousskov at measurement-factory.com  Thu Apr 13 01:15:22 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 12 Apr 2017 19:15:22 -0600
Subject: [squid-users] [squid-dev] [RFC] Changes to http_access defaults
In-Reply-To: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>
References: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>
Message-ID: <9c01ab9e-6f7f-2e82-b3e2-9e1220c26d30@measurement-factory.com>

On 04/12/2017 12:16 PM, Amos Jeffries wrote:

> Changes to http_access defaults

Clearly stating what you are trying to accomplish with these changes may
help others evaluate your proposal. Your initial email focuses on _how_
you are going to accomplish some implied/vague goal. What is the goal here?


> I have become convinced that Squid always checks those
> security rules, then do the custom access rules. All other orderings
> seem to have turned out to be problematic and security-buggy in some
> edge cases or another.

s/Squid always checks/Squid should always check/


> What are peoples opinions about making the following items built-in
> defaults?
> 
>  acl Safe_ports port 21 80 443
>  acl CONNECT_ports port 443
>  acl CONNECT method CONNECT
> 
>  http_acces deny !Safe_ports
>  http_access deny CONNECT !CONNECT_ports

> The above change will have some effect on installations that try to use
> an empty squid.conf.

And on many other existing installations, of course, especially on those
with complex access rules which are usually the most difficult to
modify/adjust. In other words, this is a pretty serious change.


> If the proposal goes ahead some extra additions
> would be included to retain that default-reject behaviour.

It is difficult to properly evaluate your proposal until it details how
one would be able to override the proposed defaults. These defaults, in
some shape or form, make sense for most installations, of course. The
difficult parts are:

* minimizing surprises (e.g, when the hidden defaults change, are wrong,
and/or interact with deny_info rules in surprising ways);

* avoiding configurations that compute essentially the same rules
multiple times (hidden defaults + explicit defaults); and

* designing a configuration approach to overwrite defaults without
either screwing up a lot of admins or virtually eliminating the positive
effect of those defaults in new configurations.


To address the last bullet, we could add a

  deny_unsafe_ports <on|off>

directive.

If that directive is "on" by default [for any squid.conf that does not
define a Safe_ports ACL??], then it does not address the first two
bullets well.

Perhaps it should be off by default but explicitly added (and turned
"on") to every newly generated squid.conf.default?


Also, how will the http_access rules in newly generated
squid.conf.default look like if we add default http_access rules?


I am worried that adding hidden default http_access rules will make
things overall worse rather than solving the problem you are trying to
solve. I wonder if fiddling with http_access internals might be the
wrong direction here.


Thank you,

Alex.



From maik.linnemann at modelco.de  Thu Apr 13 07:43:06 2017
From: maik.linnemann at modelco.de (Maik Linnemann)
Date: Thu, 13 Apr 2017 07:43:06 +0000
Subject: [squid-users] Squid 3.4.8 Reverse with multiple SSL Sites and
 multiple Certs/Domains
In-Reply-To: <bbc405d8-e3b4-f4d0-a74f-d96264430f87@treenet.co.nz>
References: <E8C0D58036A98440B317EA23130CF55B67947A@ms-exchange-01.provit.info>
 <cda05731-6239-6358-1dee-aacaeb747f6a@treenet.co.nz>
 <E8C0D58036A98440B317EA23130CF55B67EBD1@ms-exchange-01.provit.info>
 <06b6bafc-9892-31f3-3fe6-8e52e29cbf84@treenet.co.nz>
 <026001d2b3b8$ca33c330$5e9b4990$@ngtech.co.il>
 <E8C0D58036A98440B317EA23130CF55B67FC3E@ms-exchange-01.provit.info>,
 <bbc405d8-e3b4-f4d0-a74f-d96264430f87@treenet.co.nz>
Message-ID: <E8C0D58036A98440B317EA23130CF55B680C72@ms-exchange-01.provit.info>

Thanks for clarification and support the free work/world! i already tried nginx and it seems doing its job. I will keep an eye on squid 4 and what was said about the issues. 
________________________________________
Von: Amos Jeffries [squid3 at treenet.co.nz]
Gesendet: Donnerstag, 13. April 2017 00:56
An: Maik Linnemann; squid-users at lists.squid-cache.org
Betreff: Re: AW: [squid-users] Squid 3.4.8 Reverse with multiple SSL Sites and multiple Certs/Domains

On 13/04/2017 7:13 a.m., Maik Linnemann wrote:
> I figured out that nginx is able to do what i want, at least SNI and
> multiple certs. I am forced to try that in the meantime. Also i will
> check varnish. Is there any realistic date when SNI is available in
> reverse proxy with squid? Is there anyone coding at all for that
> feature?
>

I've been working on it as part of the  GnuTLS support in Squid-4.
https_port can now be configured with multiple cert= key= parameter
pairs. But loading any past the first pair with OpenSSL builds is still
missing.

I _think_ all that is left now (for OpenSSL builds) is to alter that
logic loading cert= files into the server context. But I have not
investigated those details closely yet.

My focus in the 'free' work is getting GnuTLS working for Debian/Ubuntu
and refactoring for more easy porting to other backend libraries in
future (Fedora, RHEL and Apple want other libraries). I intend for SNI
to be usable out of the box with GnuTLS builds. Someone may do OpenSSL
changes to match by the time it goes public - I cannot test it so that
depends on others.

Amos



From acctforjunk at yahoo.com  Thu Apr 13 11:41:41 2017
From: acctforjunk at yahoo.com (j m)
Date: Thu, 13 Apr 2017 11:41:41 +0000 (UTC)
Subject: [squid-users] General security and usage questions
In-Reply-To: <481b6136-1160-7c57-aa03-904bdce383d5@treenet.co.nz>
References: <1838121436.3106912.1491570075225.ref@mail.yahoo.com>
 <1838121436.3106912.1491570075225@mail.yahoo.com>
 <481b6136-1160-7c57-aa03-904bdce383d5@treenet.co.nz>
Message-ID: <1425630951.1187338.1492083701241@mail.yahoo.com>

Thanks for the reply. ?You've convinced me to upgrade to 16.04, and I will be doing that when possible. ?Then I will work on these issues and take the suggestions you give.

      From: Amos Jeffries <squid3 at treenet.co.nz>
 To: squid-users at lists.squid-cache.org 
 Sent: Monday, April 10, 2017 9:52 PM
 Subject: Re: [squid-users] General security and usage questions
   
On 8/04/2017 1:01 a.m., j m wrote:
> I have a Ubuntu server set up that does various things in addition to
> being a web proxy (squid 3.3.8) to use remotely over the internet.
> This allows me to directly access internal devices with a web page on
> my LAN since my employer, like most, blocks VPN connections.

Please upgrade to a current Ubuntu (Xenial or later) - that will give
you access to a much better version of Squid.


>? My
> intention is to have the squid service running at all times, with a
> login, so I can use it any time.? However, there's a few things I
> have not been able to answer/resolve through my own research:

> 1. I am
> not able to SSH into my server from my employer.? It's rare I'd need
> to do this, but ethical considerations aside, could this work with
> PuTTY over the squid proxy?? I'm confused over how or if this would
> work using the Connection -> Proxy config in PuTTY.? I can
> successfully use my proxy from a web browser, but have had no luck
> with SSH despite entering the proxy info into PuTTY.? Supposedly the
> proxy needs to support the CONNECT method, but I'm unclear what this
> is or how to enable this.? As an aside, I have experimented with
> shellinabox, but abandoned it when I learned it's not encrypted by
> default.

PuTTY should be doable. You just have to configure it to use an HTTP proxy.

Then you have to configure your squid.conf to allow those requests. You
do that by:

 1) adding port 22 to the SSL_Ports and Safe_ports ACLs.

 2) adding extra custom rules to permit CONNECT to port 22 from the
IP(s) your PuTTY connections will be coming from.

 3) explicitly deny all other port 22 connections since the default
securuty lines no longer do that for you.

PuTTY should now be able to go through the proxy to wherever, the rest
is up to the server permissions at the destination.

I highly recommend that you use client cert verification and good cert
crypto rather than user:pass login - the login method would be visible
across the whole Internet to (and from) the proxy.


> 
> 2. How good is squid's security as far as leaving its port open to
> the Internet, which I obviously have to do in my case?

Depends on what you are meaning by "security".

Squid can be used as a relay to reach anywhere your http_access rules
permit. That is why the very first things we do is close off ports
0-1024 tight as possible.

So treat it as being an open hole in your network firewall to *any*
machines port 22.



>? I found it
> interesting that if I enter http://myip:myport from over the
> Internet, it responds with a "The requested URL could not be
> retrieved" page, along with information that identifies it as squid,
> along with the version number and server name, without asking for a
> login. Being unfamiliar with web proxies, this might be the norm for
> all I know.? If I set up a browser to use it as a proxy, it does ask
> for a login.? It appears the error pages are in
> /usr/share/squid/errors, but is there a way for it to be more
> discrete, preferably to not respond at all or ask for a login? Below
> is my squid.conf.? I removed all the commented lines, and pieced one
> together from information online.? My goal is to have it proxy
> basically anything thrown at it if authenticated,

That is not possible. As my most frequent comment says "Squid is an HTTP
proxy".

Meaning it only proxies/relays the protocols it understands - primary
HTTP, nowdays also FTP. Nothing else.

Any other protocol must use an HTTP CONNECT request to get through
reliably, and that depend on the sending software being aware of the
proxy being an HTTP one. Which is why the default behaviour is to
respond with an HTTP error page - so smart senders can use that info to
switch to HTTP.


> be as secure as
> reasonably possible,

FYI: Proxying anything and being secure are opposites. You only get to
pick one.


> absolutely no caching, and enable SSH
> connections through it, if possible. Thanks in advance. auth_param
> basic program /usr/lib/squid3/basic_ncsa_auth
> /etc/squid3/passwordsauth_param basic realm proxyacl authenticated
> proxy_auth REQUIREDhttp_access allow authenticated # Choose the port
> you want. Below we set it to default 3128.http_port 8092cache deny
> allaccess_log none acl CONNECT method CONNECT
> 

Please use at minimum the config file lines shown here for your current
Squid version:
 <http://wiki.squid-cache.org/Squid-3.3>
(or if you upgrade the relevant wiki page for that series)

Your own customisations should be added to those, not replacing.

NP: while debugging this new configuration it is a good idea to
re-enable the access.log outputs so you can see what is actually going
on. There is no way to decide if something is actually correct if you
cannot see it happening.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170413/1d265fbc/attachment.htm>

From arsalan at preston.edu.pk  Thu Apr 13 11:46:52 2017
From: arsalan at preston.edu.pk (Arsalan Hussain)
Date: Thu, 13 Apr 2017 16:46:52 +0500
Subject: [squid-users] Squid Proxy with simple iptable rule ...
Message-ID: <CAMwDxM3ADo_ToEhbJvvCo8yOsU=zJ9EOLXVR5opqL7dbWMbyWQ@mail.gmail.com>

Dear All,

I am facing problem with iptable rules for squid 3.5.23. my simple squid
configuration is attached and also iptable rules.

It works fine when i restart squid, iptables, network services but after a
while it give problem of slow speed or even rejecting packets in squid
access.log

 0 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 -HIER_NONE/- -
 0 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 - HIER_NONE/- -

when these kind entries shows in access.log websites do not open to user
and they received message refused by proxy. (a routine access.log entries
attached).

If somebody assists me in this problem to solve it.

With Regards,


*Arsalan Hussain*
*If you are too lazy to plow now, don't expect a harvest, later*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170413/33a77556/attachment.htm>
-------------- next part --------------
1492082727.375 126331 192.168.5.178 TCP_TUNNEL/200 1185 CONNECT apis.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492082733.497 317889 192.168.5.178 TCP_TUNNEL/200 5638 CONNECT 4-edge-chat.facebook.com:443 - HIER_DIRECT/157.240.7.20 -
1492082734.141   1354 192.168.6.130 TCP_TUNNEL/200 467 CONNECT clients4.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492082741.315  35003 192.168.6.130 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492082741.315  33013 192.168.6.130 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492082741.315  33514 192.168.6.129 TAG_NONE/503 0 CONNECT r15---sn-25g7sner.googlevideo.com:443 - HIER_NONE/- -
1492082741.708  25111 192.168.5.165 TAG_NONE/500 0 CONNECT server21902.teamviewer.com:443 - HIER_DIRECT/217.146.8.3 -
1492082741.709  19092 192.168.5.165 TAG_NONE/500 0 CONNECT server21902.teamviewer.com:443 - HIER_DIRECT/217.146.8.3 -
1492082741.712  10060 192.168.5.165 TAG_NONE/500 0 CONNECT server21902.teamviewer.com:443 - HIER_DIRECT/217.146.8.3 -
1492082743.561 242726 192.168.6.129 TCP_TUNNEL/200 724 CONNECT youtubei.youtube.com:443 - HIER_DIRECT/172.217.23.142 -
1492082743.896  31001 192.168.6.129 TCP_TUNNEL/200 0 CONNECT r2---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.13 -
1492082751.850  28155 192.168.6.129 TCP_TUNNEL/200 151 CONNECT r2---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.13 -
1492082764.166   9420 192.168.6.130 TCP_TUNNEL/200 1938 CONNECT scontent-iad3-1.xx.fbcdn.net:443 - HIER_DIRECT/31.13.69.203 -
1492082764.166   3917 192.168.6.130 TCP_TUNNEL/200 952 CONNECT notifications.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492082767.311      0 192.168.6.130 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492082769.326      0 192.168.6.130 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492082774.180   3883 192.168.6.130 TCP_TUNNEL/200 724 CONNECT clients6.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492082774.180   3398 192.168.6.130 TCP_TUNNEL/200 1399 CONNECT clients6.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492082775.299      0 192.168.5.178 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492082779.316      0 192.168.6.130 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492082781.319      0 192.168.6.130 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492082790.654      0 148.153.44.86 TAG_NONE/400 3987 GET / - HIER_NONE/- text/html
1492082794.210   2908 192.168.6.130 TCP_TUNNEL/200 1171 CONNECT googleads.g.doubleclick.net:443 - HIER_DIRECT/74.125.24.157 -
1492082794.210   7898 192.168.6.130 TCP_TUNNEL/200 4981 CONNECT www.youtube.com:443 - HIER_DIRECT/172.217.23.142 -
1492082798.320 119980 192.168.5.178 TCP_TUNNEL/200 4791 CONNECT apps.skype.com:443 - HIER_DIRECT/104.88.201.172 -
1492082805.251 118554 192.168.5.178 TCP_TUNNEL/200 5878 CONNECT mobile.pipe.aria.microsoft.com:443 - HIER_DIRECT/40.114.149.220 -
1492082811.161 124461 192.168.5.178 TCP_TUNNEL/200 5979 CONNECT mobile.pipe.aria.microsoft.com:443 - HIER_DIRECT/40.114.149.220 -
1492082816.898  86006 192.168.6.129 TCP_TUNNEL/200 6120423 CONNECT r2---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.13 -
1492082817.469 609736 192.168.6.129 TCP_TUNNEL/200 204106 CONNECT i1.ytimg.com:443 - HIER_DIRECT/172.217.23.142 -
1492082817.798 327546 192.168.6.129 TCP_TUNNEL/200 828 CONNECT securepubads.g.doubleclick.net:443 - HIER_DIRECT/172.217.24.98 -
1492082817.883 609479 192.168.6.129 TCP_TUNNEL/200 1285 CONNECT www.youtube-nocookie.com:443 - HIER_DIRECT/172.217.23.142 -
1492082818.494 609913 192.168.6.129 TCP_TUNNEL/200 1046 CONNECT clients1.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492082818.605 538832 192.168.6.129 TCP_TUNNEL/200 611021 CONNECT i.ytimg.com:443 - HIER_DIRECT/172.217.23.142 -
1492082818.713 654038 192.168.6.129 TCP_TUNNEL/200 288016 CONNECT yt3.ggpht.com:443 - HIER_DIRECT/74.125.24.132 -
1492082818.902 517858 192.168.6.129 TCP_TUNNEL/200 2231 CONNECT www.googleadservices.com:443 - HIER_DIRECT/74.125.24.156 -
1492082819.224 610547 192.168.6.129 TCP_TUNNEL/200 9851 CONNECT googleads.g.doubleclick.net:443 - HIER_DIRECT/74.125.200.156 -
1492082819.393 505039 192.168.6.129 TCP_TUNNEL/200 3226 CONNECT www.google.com:443 - HIER_DIRECT/172.217.23.132 -
1492082819.436 504569 192.168.6.129 TCP_TUNNEL/200 1089 CONNECT www.google.com.pk:443 - HIER_DIRECT/110.93.194.34 -
1492082819.860 457539 192.168.6.130 TCP_TUNNEL/200 13067 CONNECT 3-edge-chat.facebook.com:443 - HIER_DIRECT/157.240.7.20 -
1492082823.361 531425 192.168.5.178 TCP_TUNNEL/200 4729 CONNECT clients6.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492082823.362 214739 192.168.5.178 TCP_TUNNEL/200 18622 CONNECT ssl.gstatic.com:443 - HIER_DIRECT/110.93.194.53 -
1492082828.592 528160 192.168.6.129 TCP_TUNNEL/200 3588 CONNECT youtubei.youtube.com:443 - HIER_DIRECT/172.217.23.142 -
1492082832.815  98765 192.168.6.129 TCP_TUNNEL/200 7026667 CONNECT r2---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.13 -
1492082834.787  30003 192.168.5.178 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492082834.787   5473 192.168.6.130 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492082834.787   7333 192.168.6.130 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492082835.301      0 192.168.5.178 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492082838.588 901034 192.168.5.178 TCP_TUNNEL/200 3092 CONNECT dub407-m.hotmail.com:443 - HIER_DIRECT/157.56.194.24 -
1492082844.304  16850 192.168.6.130 TCP_TUNNEL/200 211 CONNECT 3-edge-chat.facebook.com:443 - HIER_DIRECT/157.240.13.14 -
1492082852.444 483407 192.168.6.129 TCP_TUNNEL/200 5299 CONNECT s.youtube.com:443 - HIER_DIRECT/172.217.23.142 -
1492082855.841 116003 192.168.5.178 TCP_TUNNEL/200 1218 CONNECT 4-edge-chat.facebook.com:443 - HIER_DIRECT/157.240.7.20 -
1492082857.295  31975 192.168.6.130 TCP_TUNNEL/200 798 CONNECT 3-edge-chat.facebook.com:443 - HIER_DIRECT/157.240.13.14 -
1492082860.100  67009 192.168.5.178 TCP_TUNNEL/200 1299 CONNECT play.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492082860.265 118600 192.168.5.165 TCP_TUNNEL/200 100 CONNECT server21902.teamviewer.com:443 - HIER_DIRECT/217.146.8.3 -
1492082874.326  17022 192.168.6.130 TCP_TUNNEL/200 211 CONNECT 3-edge-chat.facebook.com:443 - HIER_DIRECT/157.240.13.14 -
1492082874.327  17019 192.168.6.130 TCP_TUNNEL/200 211 CONNECT 3-edge-chat.facebook.com:443 - HIER_DIRECT/157.240.13.14 -
1492082874.327   1417 192.168.6.130 TCP_TUNNEL/200 1042 CONNECT clients6.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492082874.327  17035 192.168.6.130 TCP_TUNNEL/200 755 CONNECT clients6.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492082882.354 240493 192.168.5.178 TCP_TUNNEL/200 5653 CONNECT clients4.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492082887.451  35004 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 - HIER_NONE/- -
1492082887.451   5006 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 - HIER_NONE/- -
1492082887.451  20003 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 - HIER_NONE/- -
1492082887.451  35000 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 - HIER_NONE/- -
1492082887.451  34630 192.168.6.130 TAG_NONE/503 0 CONNECT safebrowsing.google.com:443 - HIER_NONE/- -
1492082888.293      0 192.168.6.130 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492082890.304      0 192.168.6.130 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492082897.449      0 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 - HIER_NONE/- -
1492082902.454  33774 192.168.5.178 TAG_NONE/503 0 CONNECT 4-edge-chat.facebook.com:443 - HIER_NONE/- -
1492082902.454  23773 192.168.5.178 TAG_NONE/503 0 CONNECT 4-edge-chat.facebook.com:443 - HIER_NONE/- -
1492082902.798 424788 192.168.6.129 TCP_TUNNEL/200 1188 CONNECT safebrowsing.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492082914.372  31513 192.168.6.130 TCP_TUNNEL/200 5832 CONNECT alt1-safebrowsing.google.com:443 - HIER_DIRECT/172.217.19.46 -
1492082914.372   6194 192.168.6.130 TCP_TUNNEL/200 8895 CONNECT safebrowsing-cache.google.com:443 - HIER_DIRECT/172.217.22.14 -
1492082920.042  59772 192.168.5.165 TAG_NONE/503 0 CONNECT server21902.teamviewer.com:443 - HIER_NONE/- -
1492082922.452      0 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 - HIER_NONE/- -
1492082927.448      0 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 - HIER_NONE/- -
1492082928.746      0 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 - HIER_NONE/- -
1492082928.748      0 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 - HIER_NONE/- -
1492082934.399   8815 192.168.6.130 TCP_TUNNEL/200 1023 CONNECT chatenabled.mail.google.com:443 - HIER_DIRECT/172.217.23.135 -
1492082937.080      0 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 - HIER_NONE/- -
1492082937.083      0 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 - HIER_NONE/- -
1492082937.297      0 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 - HIER_NONE/- -
1492082939.290      0 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 - HIER_NONE/- -
1492082942.630 309324 192.168.5.178 TCP_TUNNEL/200 4317 CONNECT apps.skype.com:443 - HIER_DIRECT/104.88.201.172 -
1492082943.357      0 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 - HIER_NONE/- -
1492082950.026  12474 192.168.6.129 TCP_TUNNEL/200 234 CONNECT yt3.ggpht.com:443 - HIER_DIRECT/74.125.68.132 -
1492082950.027  12467 192.168.6.129 TCP_TUNNEL/200 234 CONNECT yt3.ggpht.com:443 - HIER_DIRECT/74.125.68.132 -
1492082950.027  12466 192.168.6.129 TCP_TUNNEL/200 234 CONNECT yt3.ggpht.com:443 - HIER_DIRECT/74.125.68.132 -
1492082954.426   4643 192.168.6.130 TCP_TUNNEL/200 698 CONNECT play.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492082954.427   5149 192.168.6.130 TCP_TUNNEL/200 1921 CONNECT www.facebook.com:443 - HIER_DIRECT/157.240.7.35 -
1492082954.427   5118 192.168.6.130 TCP_TUNNEL/200 676 CONNECT play.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492082973.073  36089 192.168.6.129 TCP_TUNNEL/200 455603 CONNECT r1---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.12 -
1492082983.702 900663 192.168.5.178 TCP_TUNNEL/200 542 CONNECT www.google.com.pk:443 - HIER_DIRECT/110.93.194.34 -
1492082985.275  48292 192.168.6.129 TCP_TUNNEL/200 7775728 CONNECT r1---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.12 -
1492082988.098 121808 192.168.5.165 TCP_TUNNEL/200 100 CONNECT server21902.teamviewer.com:443 - HIER_DIRECT/217.146.8.3 -
1492082997.239  59922 192.168.6.129 TAG_NONE/503 0 CONNECT r3---sn-aigllndd.googlevideo.com:443 - HIER_NONE/- -
1492083001.484 1018349 192.168.5.178 TCP_TUNNEL/200 62228 CONNECT www.google.com.pk:443 - HIER_DIRECT/110.93.194.53 -
1492083002.391  64080 192.168.6.129 TCP_TUNNEL/200 2494 CONNECT googleads.g.doubleclick.net:443 - HIER_DIRECT/74.125.68.157 -
1492083012.281  21596 192.168.6.129 TCP_TUNNEL/200 14631 CONNECT r1---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.12 -
1492083016.282  31001 192.168.6.129 TCP_TUNNEL/200 0 CONNECT r1---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.12 -
1492083018.344  15193 192.168.5.165 TAG_NONE/500 0 CONNECT server21902.teamviewer.com:443 - HIER_DIRECT/217.146.8.3 -
1492083019.312  31196 192.168.5.165 TAG_NONE/500 0 CONNECT server21902.teamviewer.com:443 - HIER_DIRECT/217.146.8.3 -
1492083020.218 1201078 192.168.5.178 TCP_TUNNEL/200 3583 CONNECT qa.sockets.stackexchange.com:443 - HIER_DIRECT/198.252.206.25 -
1492083021.688  31001 192.168.6.129 TCP_TUNNEL/200 0 CONNECT r1---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.12 -
1492083021.689  31001 192.168.6.129 TCP_TUNNEL/200 0 CONNECT r1---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.12 -
1492083024.549  13252 192.168.6.130 TCP_TUNNEL/200 211 CONNECT www.facebook.com:443 - HIER_DIRECT/157.240.13.35 -
1492083024.550  15254 192.168.6.130 TCP_TUNNEL/200 211 CONNECT www.facebook.com:443 - HIER_DIRECT/157.240.13.35 -
1492083024.550  13397 192.168.6.130 TCP_TUNNEL/200 11339 CONNECT www.facebook.com:443 - HIER_DIRECT/157.240.13.35 -
1492083025.337  31196 192.168.5.165 TAG_NONE/500 0 CONNECT server21902.teamviewer.com:443 - HIER_DIRECT/217.146.8.3 -
1492083029.980  28496 192.168.6.129 TCP_TUNNEL/200 151 CONNECT r1---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.12 -
1492083029.980  16239 192.168.6.129 TCP_TUNNEL/200 151 CONNECT r1---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.12 -
1492083054.589   6273 192.168.6.130 TCP_TUNNEL/200 1055 CONNECT play.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492083074.621   3168 192.168.6.130 TCP_TUNNEL/200 1035 CONNECT play.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492083074.621   4347 192.168.6.130 TCP_TUNNEL/200 1887 CONNECT www.facebook.com:443 - HIER_DIRECT/157.240.13.35 -
1492083091.432  87951 192.168.6.129 TCP_TUNNEL/200 14894626 CONNECT r1---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.12 -
1492083091.432 903450 192.168.5.178 TCP_TUNNEL/200 8296 CONNECT clients2.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492083106.457 900855 192.168.6.129 TCP_TUNNEL/200 4250 CONNECT s.ytimg.com:443 - HIER_DIRECT/172.217.23.142 -
1492083107.237 159902 192.168.6.129 TCP_TUNNEL/200 1761 CONNECT s.youtube.com:443 - HIER_DIRECT/172.217.23.142 -
1492083121.014 903583 192.168.6.129 TCP_TUNNEL/200 1176 CONNECT www.googleapis.com:443 - HIER_DIRECT/172.217.21.202 -
1492083122.009 902063 192.168.6.129 TCP_TUNNEL/200 695 CONNECT pagead2.googlesyndication.com:443 - HIER_DIRECT/74.125.200.154 -
1492083122.437  31000 192.168.6.129 TCP_TUNNEL/200 0 CONNECT r1---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.12 -
1492083127.840  31002 192.168.6.129 TCP_TUNNEL/200 0 CONNECT r1---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.12 -
1492083132.446  11990 192.168.5.178 TCP_TUNNEL/200 227 CONNECT 4-edge-chat.facebook.com:443 - HIER_DIRECT/157.240.7.20 -
1492083134.707   4424 192.168.6.130 TCP_TUNNEL/200 1897 CONNECT www.facebook.com:443 - HIER_DIRECT/157.240.7.35 -
1492083138.018  30773 192.168.6.129 TCP_TUNNEL/200 234 CONNECT s.youtube.com:443 - HIER_DIRECT/172.217.23.142 -
1492083138.018  30777 192.168.6.129 TCP_TUNNEL/200 234 CONNECT s.youtube.com:443 - HIER_DIRECT/172.217.23.142 -
1492083138.018  30775 192.168.6.129 TCP_TUNNEL/200 234 CONNECT s.youtube.com:443 - HIER_DIRECT/172.217.23.142 -
1492083151.256  34211 192.168.6.129 TCP_TUNNEL/200 933500 CONNECT r1---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.12 -
1492083177.586 240473 192.168.6.129 TCP_TUNNEL/200 45489 CONNECT i1.ytimg.com:443 - HIER_DIRECT/172.217.23.142 -
1492083178.061 240502 192.168.6.129 TCP_TUNNEL/200 656 CONNECT www.youtube-nocookie.com:443 - HIER_DIRECT/172.217.23.142 -
1492083178.836 240608 192.168.6.129 TCP_TUNNEL/200 457 CONNECT clients1.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492083179.053 241753 192.168.6.129 TCP_TUNNEL/200 688 CONNECT securepubads.g.doubleclick.net:443 - HIER_DIRECT/172.217.27.2 -
1492083180.168 260582 192.168.6.129 TCP_TUNNEL/200 148889 CONNECT i.ytimg.com:443 - HIER_DIRECT/172.217.23.142 -
1492083180.301 242746 192.168.6.129 TCP_TUNNEL/200 320366 CONNECT yt3.ggpht.com:443 - HIER_DIRECT/74.125.68.132 -
1492083186.084 242725 192.168.6.129 TCP_TUNNEL/200 1143 CONNECT www.googleadservices.com:443 - HIER_DIRECT/74.125.200.154 -
1492083186.548 284355 192.168.5.178 TCP_TUNNEL/200 7100 CONNECT 5-edge-chat.facebook.com:443 - HIER_DIRECT/157.240.13.14 -
1492083187.018  79380 192.168.6.129 TCP_TUNNEL/200 7631273 CONNECT r1---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.12 -
1492083190.980 240949 192.168.6.129 TCP_TUNNEL/200 1156 CONNECT youtubei.youtube.com:443 - HIER_DIRECT/172.217.23.142 -
1492083193.966 241850 192.168.6.129 TCP_TUNNEL/200 665 CONNECT www.google.com:443 - HIER_DIRECT/172.217.23.132 -
1492083197.881  65433 192.168.5.178 TCP_TUNNEL/200 4410 CONNECT 0-edge-chat.facebook.com:443 - HIER_DIRECT/157.240.7.20 -
1492083208.546 242688 192.168.6.129 TCP_TUNNEL/200 522 CONNECT clients4.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492083219.232 101994 192.168.6.129 TCP_TUNNEL/200 5663 CONNECT s.youtube.com:443 - HIER_DIRECT/172.217.23.142 -
1492083226.277  35002 192.168.6.130 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492083226.277  32976 192.168.6.130 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492083227.329   9271 192.168.6.129 TCP_REFRESH_MODIFIED/200 843 GET http://egamesplanet.com/watchme.php - HIER_DIRECT/198.54.114.145 text/html
1492083229.190    546 192.168.6.129 TCP_MISS/200 342 GET http://egamesplanet.com/set.php? - HIER_DIRECT/198.54.114.145 text/html
1492083242.624 122487 192.168.5.178 TCP_TUNNEL/200 2589 CONNECT scontent.fisb1-1.fna.fbcdn.net:443 - HIER_DIRECT/115.186.133.81 -
1492083252.272      0 192.168.6.130 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492083253.295      0 192.168.6.130 TAG_NONE/503 0 CONNECT www.facebook.com:443 - HIER_NONE/- -
1492083294.899   3614 192.168.6.130 TCP_TUNNEL/200 404 CONNECT clients4.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492083303.227 207823 192.168.5.178 TCP_TUNNEL/200 1090 CONNECT play.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492083314.922   2642 192.168.6.130 TCP_TUNNEL/200 1888 CONNECT www.facebook.com:443 - HIER_DIRECT/157.240.7.35 -
1492083356.524 244128 192.168.6.129 TCP_TUNNEL/200 5294 CONNECT googleads.g.doubleclick.net:443 - HIER_DIRECT/74.125.68.157 -
1492083359.580 1071878 192.168.6.129 TCP_TUNNEL/200 245376 CONNECT www.youtube.com:443 - HIER_DIRECT/172.217.23.142 -
1492083361.912  10349 192.168.5.178 TCP_TUNNEL/200 0 CONNECT safebrowsing-cache.google.com:443 - HIER_DIRECT/172.217.22.14 -
1492083362.163 240608 192.168.5.178 TCP_TUNNEL/200 779 CONNECT safebrowsing.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492083362.714 180646 192.168.5.178 TCP_TUNNEL/200 1199 CONNECT apis.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492083384.992   9708 192.168.6.130 TCP_TUNNEL/200 211 CONNECT www.facebook.com:443 - HIER_DIRECT/157.240.13.35 -
1492083384.992  11726 192.168.6.130 TCP_TUNNEL/200 1920 CONNECT www.facebook.com:443 - HIER_DIRECT/157.240.13.35 -
1492083397.894 199825 192.168.5.178 TCP_TUNNEL/200 947 CONNECT ssl.gstatic.com:443 - HIER_DIRECT/110.93.194.29 -
1492083406.517 240463 192.168.6.129 TCP_TUNNEL/200 1464 CONNECT safebrowsing.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492083407.483 240961 192.168.6.129 TCP_TUNNEL/200 4527 CONNECT safebrowsing-cache.google.com:443 - HIER_DIRECT/172.217.22.14 -
1492083409.473  14259 192.168.6.129 TCP_TUNNEL/200 4613 CONNECT i.ytimg.com:443 - HIER_DIRECT/172.217.23.142 -
1492083409.474  14256 192.168.6.129 TCP_TUNNEL/200 4613 CONNECT i.ytimg.com:443 - HIER_DIRECT/172.217.23.142 -
1492083409.474  14272 192.168.6.129 TCP_TUNNEL/200 4612 CONNECT i.ytimg.com:443 - HIER_DIRECT/172.217.23.142 -
1492083415.029   8743 192.168.6.130 TCP_TUNNEL/200 871 CONNECT notifications.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492083420.633   1689 192.168.6.129 TCP_TUNNEL/200 10935 CONNECT r3---sn-o097znld.googlevideo.com:443 - HIER_DIRECT/74.125.166.201 -
1492083424.328  30773 192.168.6.129 TCP_TUNNEL/200 133458 CONNECT r2---sn-o5t5uxa-pncl.googlevideo.com:443 - HIER_DIRECT/203.99.50.13 -
1492083424.664  31111 192.168.6.129 TCP_TUNNEL/200 70608 CONNECT r2---sn-o5t5uxa-pncl.googlevideo.com:443 - HIER_DIRECT/203.99.50.13 -
1492083425.482  30044 192.168.6.129 TCP_TUNNEL/200 70392 CONNECT r2---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.13 -
1492083435.064   1777 192.168.6.130 TCP_TUNNEL/200 1584 CONNECT www.facebook.com:443 - HIER_DIRECT/157.240.13.35 -
1492083443.342  12774 192.168.6.129 TCP_TUNNEL/200 151 CONNECT r2---sn-o5t5uxa-pncl.googlevideo.com:443 - HIER_DIRECT/203.99.50.13 -
1492083444.502  49063 192.168.6.129 TCP_TUNNEL/200 3696560 CONNECT r2---sn-o5t5uxa-pncs.googlevideo.com:443 - HIER_DIRECT/124.109.34.13 -
1492083445.077   8804 192.168.6.130 TCP_TUNNEL/200 1615 CONNECT www.facebook.com:443 - HIER_DIRECT/157.240.13.35 -
1492083466.769  37169 192.168.6.129 TCP_TUNNEL/200 1401663 CONNECT r2---sn-o5t5uxa-pncl.googlevideo.com:443 - HIER_DIRECT/203.99.50.13 -
1492083467.987  38500 192.168.6.129 TCP_TUNNEL/200 4391642 CONNECT r2---sn-o5t5uxa-pncl.googlevideo.com:443 - HIER_DIRECT/203.99.50.13 -
1492083476.794 125854 192.168.5.178 TCP_TUNNEL/200 1335 CONNECT safebrowsing.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492083493.763      0 148.153.34.126 TAG_NONE/400 3988 GET / - HIER_NONE/- text/html
1492083494.203      0 148.153.34.126 TAG_NONE/400 3988 GET / - HIER_NONE/- text/html
1492083495.135    872 192.168.6.130 TCP_TUNNEL/200 1586 CONNECT www.facebook.com:443 - HIER_DIRECT/157.240.7.35 -
^C
[root at squid3 sysconfig]# ^C
[root at squid3 sysconfig]# tail -f /var/log/squid/access.log
1492083476.794 125854 192.168.5.178 TCP_TUNNEL/200 1335 CONNECT safebrowsing.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492083493.763      0 148.153.34.126 TAG_NONE/400 3988 GET / - HIER_NONE/- text/html
1492083494.203      0 148.153.34.126 TAG_NONE/400 3988 GET / - HIER_NONE/- text/html
1492083495.135    872 192.168.6.130 TCP_TUNNEL/200 1586 CONNECT www.facebook.com:443 - HIER_DIRECT/157.240.7.35 -
1492083498.995  31001 192.168.6.129 TCP_TUNNEL/200 0 CONNECT r2---sn-o5t5uxa-pncl.googlevideo.com:443 - HIER_DIRECT/203.99.50.13 -
1492083505.149   7876 192.168.6.130 TCP_TUNNEL/200 1583 CONNECT www.facebook.com:443 - HIER_DIRECT/157.240.7.35 -
1492083505.149   9567 192.168.6.130 TCP_TUNNEL/200 1025 CONNECT chatenabled.mail.google.com:443 - HIER_DIRECT/172.217.23.135 -
1492083507.386  28586 192.168.6.129 TCP_TUNNEL/200 151 CONNECT r2---sn-o5t5uxa-pncl.googlevideo.com:443 - HIER_DIRECT/203.99.50.13 -
1492083507.387  28588 192.168.6.129 TCP_TUNNEL/200 151 CONNECT r2---sn-o5t5uxa-pncl.googlevideo.com:443 - HIER_DIRECT/203.99.50.13 -
1492083526.774  53381 192.168.6.129 TCP_TUNNEL/200 1760876 CONNECT r2---sn-o5t5uxa-pncl.googlevideo.com:443 - HIER_DIRECT/203.99.50.13 -
1492083565.236   9980 192.168.6.130 TCP_TUNNEL/200 1916 CONNECT www.facebook.com:443 - HIER_DIRECT/157.240.7.35 -
1492083567.901  89099 192.168.6.129 TCP_TUNNEL/200 12873572 CONNECT r2---sn-o5t5uxa-pncl.googlevideo.com:443 - HIER_DIRECT/203.99.50.13 -
1492083573.365 177579 192.168.5.178 TCP_TUNNEL/200 1116 CONNECT play.google.com:443 - HIER_DIRECT/172.217.23.142 -
1492083576.566 563387 192.168.5.165 TCP_TUNNEL/200 292 CONNECT server21902.teamviewer.com:443 - HIER_DIRECT/217.146.8.3 -
1492083578.566   1291 192.168.5.178 TCP_MISS_ABORTED/000 0 POST http://lists.squid-cache.org/confirm/squid-users - HIER_NONE/- -
1492083593.787 374552 192.168.6.129 TCP_TUNNEL/200 4362 CONNECT s.youtube.com:443 - HIER_DIRECT/172.217.23.142 -
1492083595.028 573166 192.168.5.178 TCP_TUNNEL/200 3645 CONNECT qa.sockets.stackexchange.com:443 - HIER_DIRECT/198.252.206.25 -
1492083598.312  15712 192.168.5.165 TAG_NONE/500 0 CONNECT server21902.teamviewer.com:443 - HIER_DIRECT/217.146.8.3 -
1492083598.316  21738 192.168.5.165 TAG_NONE/500 0 CONNECT server21902.teamviewer.com:443 - HIER_DIRECT/217.146.8.3 -
1492083598.317   6640 192.168.5.165 TAG_NONE/500 0 CONNECT server21902.teamviewer.com:443 - HIER_DIRECT/217.146.8.3 -
1492083598.829  21609 192.168.5.178 TCP_REFRESH_MODIFIED/200 5729 GET http://lists.squid-cache.org/pipermail/squid-users/2016-April/009987.html - HIER_DIRECT/104.130.201.120 text/html
1492083598.910  31002 192.168.6.129 TCP_TUNNEL/200 0 CONNECT r2---sn-o5t5uxa-pncl.googlevideo.com:443 - HIER_DIRECT/203.99.50.13 -
1492083598.979  21717 192.168.5.178 TCP_REFRESH_MODIFIED/200 59175 GET http://squid-users.squid-cache.narkive.com/2z0JzDEK/bypassed-proxy - HIER_DIRECT/85.17.190.158 text/html
1492083599.016    330 192.168.5.178 TCP_REFRESH_UNMODIFIED/304 429 GET http://85.17.190.158/s/style.eu.4.min.css - HIER_DIRECT/85.17.190.158 -
1492083599.028    341 192.168.5.178 TCP_REFRESH_UNMODIFIED/304 429 GET http://85.17.190.158/s/script.en.min.js - HIER_DIRECT/85.17.190.158 -
1492083599.126   3294 192.168.5.178 TCP_TUNNEL/200 3587 CONNECT qa.sockets.stackexchange.com:443 - HIER_DIRECT/198.252.206.25 -
1492083599.139  21922 192.168.5.178 TCP_MISS/200 18887 GET http://unix.stackexchange.com/questions/240895/transparent-https-squid-proxy-with-upstream-parent - HIER_DIRECT/151.101.65.69 text/html
1492083599.309    622 192.168.5.178 TCP_REFRESH_UNMODIFIED/304 413 GET http://ajax.googleapis.com/ajax/libs/jquery/1.11.2/jquery.min.js - HIER_DIRECT/172.217.18.170 -
1492083599.819      8 192.168.5.178 TCP_MISS/200 5048 GET http://edge.quantserve.com/quant.js - HIER_DIRECT/115.186.131.208 application/x-javascript
1492083599.821      9 192.168.5.178 TCP_MISS/200 1345 GET http://b.scorecardresearch.com/beacon.js - HIER_DIRECT/115.186.131.203 application/x-javascript
1492083599.849      5 192.168.5.178 TCP_MISS/204 409 GET http://b.scorecardresearch.com/b? - HIER_DIRECT/115.186.131.203 -
1492083600.266    363 192.168.5.178 TCP_REFRESH_UNMODIFIED/304 518 GET http://rules.quantcount.com/rules-p-c1rF4kxgLUzNc.js - HIER_DIRECT/54.192.229.62 -
1492083600.319    510 192.168.5.178 TCP_REFRESH_UNMODIFIED/304 857 GET http://static.adzerk.net/ados.js - HIER_DIRECT/104.17.27.15 -
1492083600.461    413 192.168.5.178 TCP_MISS/204 567 GET http://unix.stackexchange.com/posts/240895/ivc/c808? - HIER_DIRECT/151.101.65.69 text/plain
1492083600.637    318 192.168.5.178 TCP_MISS/200 453 GET http://pixel.quantserve.com/pixel;r=541027050;a=p-c1rF4kxgLUzNc;rf=0;fpan=0;fpa=P0-26441444-1491452776581;ns=0;ce=1;cm=;je=0;sr=1366x768x24;enc=n;dst=0;et=1492083993303;tzo=-300;ref=https%3A%2F%2Fwww.google.com.pk%2F;url=http%3A%2F%2Funix.stackexchange.com%2Fquestions%2F240895%2Ftransparent-https-squid-proxy-with-upstream-parent;ogl=type.website%2Cimage.https%3A%2F%2Fcdn%252Esstatic%252Enet%2FSites%2Funix%2Fimg%2Fapple-touch-icon%402%252Epng%3Fv%3D32fb07f7ce26%2Ctitle.Transparent%20HTTPS%20Squid%20proxy%20with%20upstream%20parent%2Cdescription.I've%20got%20a%20network%20without%20direct%20internet%20access%20where%20I%20have%20Squid%203%252E5%252E9%20as%20a%20%2Curl.http%3A%2F%2Funix%252Estackexchange%252Ecom%2Fquestions%2F240895%2Ftransparent-https-squid-proxy-wit - HIER_DIRECT/95.172.94.42 image/gif
1492083600.638    337 192.168.5.178 TCP_MISS/200 450 GET http://squid-users.squid-cache.narkive.com/ajax/threadviewcounter? - HIER_DIRECT/85.17.190.158 text/html
1492083600.641    341 192.168.5.178 TCP_REFRESH_UNMODIFIED/304 428 GET http://85.17.190.158/s/header_sprite.png - HIER_DIRECT/85.17.190.158 -
1492083600.934    559 192.168.5.178 TCP_MISS/200 3187 GET http://engine.adzerk.net/ados? - HIER_DIRECT/107.22.198.94 application/javascript
1492083601.484    304 192.168.5.178 TCP_REFRESH_UNMODIFIED/304 869 GET http://static.adzerk.net/Extensions/adFeedback.js - HIER_DIRECT/104.17.27.15 -
1492083601.799    618 192.168.5.178 TCP_REFRESH_UNMODIFIED/304 869 GET http://static.adzerk.net/Extensions/adFeedback.css - HIER_DIRECT/104.17.27.15 -
1492083602.053    252 192.168.5.178 TCP_MISS/200 858 GET http://engine.adzerk.net/i.gif? - HIER_DIRECT/107.22.198.94 image/gif
1492083602.152    801 192.168.5.178 TCP_MISS/200 1917 GET http://stackexchange.com/ads/beta-question/js? - HIER_DIRECT/151.101.1.69 text/javascript
1492083602.319 745019 192.168.6.130 TCP_TUNNEL/200 6795 CONNECT 3-edge-chat.facebook.com:443 - HIER_DIRECT/157.240.13.14 -
1492083602.330    529 192.168.5.178 TCP_MISS/200 858 GET http://engine.adzerk.net/i.gif? - HIER_DIRECT/107.22.198.94 image/gif
1492083602.373   2612 192.168.5.178 TCP_TUNNEL/200 3932 CONNECT ssum-sec.casalemedia.com:443 - HIER_DIRECT/104.117.131.126 -
1492083602.435    635 192.168.5.178 TCP_MISS/200 23059 GET http://static.adzerk.net/Advertisers/a974a5c0b5ff4c189585aea35c671f69.png - HIER_DIRECT/104.17.27.15 image/png
1492083603.793  30895 192.168.5.178 TCP_REFRESH_MODIFIED/200 4920 GET http://bazaar.launchpad.net/~squid/squid/5/revision/14769 - HIER_DIRECT/91.189.95.84 text/html
^C
-------------- next part --------------
A non-text attachment was scrubbed...
Name: iptables 10-04-2017 Final SSL bump
Type: application/octet-stream
Size: 1123 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170413/33a77556/attachment.obj>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: squid ssl bump final.conf
Type: application/octet-stream
Size: 3051 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170413/33a77556/attachment-0001.obj>

From arsalan at preston.edu.pk  Thu Apr 13 12:39:47 2017
From: arsalan at preston.edu.pk (Arsalan Hussain)
Date: Thu, 13 Apr 2017 17:39:47 +0500
Subject: [squid-users] Squid Proxy with simple iptable rule ...
In-Reply-To: <CAMwDxM3ADo_ToEhbJvvCo8yOsU=zJ9EOLXVR5opqL7dbWMbyWQ@mail.gmail.com>
References: <CAMwDxM3ADo_ToEhbJvvCo8yOsU=zJ9EOLXVR5opqL7dbWMbyWQ@mail.gmail.com>
Message-ID: <CAMwDxM2WG_51TSFAEoLDWRKV8AcnRQzMuDjZr64+DXLpmB-1KA@mail.gmail.com>

Dear All,

Two things i want to share what i observed but didn't understand.

1-  it happens to HTTPS 443 websites like facebook, youtube, google mail
2-  it is squid configuration problem, because when i stop iptables the
same problem arise.

as given below access.log entries.  website give Error:
1492086861.068  33508 192.168.5.178 TAG_NONE/503 0 CONNECT
plus.google.com:443 - HIER_NONE/- -
1492086861.068  33506 192.168.5.178 TAG_NONE/503 0 CONNECT
connect.facebook.net:443 - HIER_NONE/- -
1492086861.068  32960 192.168.5.178 TAG_NONE/503 0 CONNECT
www.youtube.com:443 - HIER_NONE/- -
1492086861.068  30685 192.168.5.178 TAG_NONE/503 0 CONNECT
www.centos.org:443 - HIER_NONE/- -
1492086861.068  30659 192.168.5.178 TAG_NONE/503 0 CONNECT m.addthis.com:443
- HIER_NONE/- -
1492086861.068  30658 192.168.5.178 TAG_NONE/503 0 CONNECT
www.spinics.net:443 - HIER_NONE/- -


Interesting fact is that, after next refresh or open in new tab
(Mozila/Chrome) , The same website gets open fine after a while.

Really confusing one because sometime working and some time problem.

On Thu, Apr 13, 2017 at 4:46 PM, Arsalan Hussain <arsalan at preston.edu.pk>
wrote:

> Dear All,
>
> I am facing problem with iptable rules for squid 3.5.23. my simple squid
> configuration is attached and also iptable rules.
>
> It works fine when i restart squid, iptables, network services but after a
> while it give problem of slow speed or even rejecting packets in squid
> access.log
>
>  0 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 -HIER_NONE/- -
>  0 192.168.6.129 TAG_NONE/503 0 CONNECT s.youtube.com:443 - HIER_NONE/- -
>
> when these kind entries shows in access.log websites do not open to user
> and they received message refused by proxy. (a routine access.log entries
> attached).
>
> If somebody assists me in this problem to solve it.
>
> With Regards,
>
>
> *Arsalan Hussain*
> *If you are too lazy to plow now, don't expect a harvest, later*
>



-- 
With Regards,


*Arsalan Hussain*
*Assistant Director, Networks & Information System*

*PRESTON UNIVERSITY*
Add: Plot: 85, Street No: 3, Sector H-8/1, Islamabad, Pakistan
Cell: +92-322-5018611
UAN: (51) 111-707-808 (Ext: 443)
*If you are too lazy to plow now, don't expect a harvest, later*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170413/88cca156/attachment.htm>

From dan at djph.net  Thu Apr 13 15:14:14 2017
From: dan at djph.net (Dan Purgert)
Date: Thu, 13 Apr 2017 11:14:14 -0400
Subject: [squid-users] [squid-dev] [RFC] Changes to http_access defaults
In-Reply-To: <9c01ab9e-6f7f-2e82-b3e2-9e1220c26d30@measurement-factory.com>
References: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>
 <9c01ab9e-6f7f-2e82-b3e2-9e1220c26d30@measurement-factory.com>
Message-ID: <20170413111414.Horde.xLtNThbtK50MUyRLMNz-uWn@192.168.10.20>

Quoting Alex Rousskov <rousskov at measurement-factory.com>:

> On 04/12/2017 12:16 PM, Amos Jeffries wrote:
>
>> Changes to http_access defaults
>
> Clearly stating what you are trying to accomplish with these changes may
> help others evaluate your proposal. Your initial email focuses on _how_
> you are going to accomplish some implied/vague goal. What is the goal here?
>
>
>> I have become convinced that Squid always checks those
>> security rules, then do the custom access rules. All other orderings
>> seem to have turned out to be problematic and security-buggy in some
>> edge cases or another.
>
> s/Squid always checks/Squid should always check/
>
>
>> What are peoples opinions about making the following items built-in
>> defaults?
>>
>>  acl Safe_ports port 21 80 443
>>  acl CONNECT_ports port 443
>>  acl CONNECT method CONNECT
>>
>>  http_acces deny !Safe_ports
>>  http_access deny CONNECT !CONNECT_ports
>
>> The above change will have some effect on installations that try to use
>> an empty squid.conf.
>
> And on many other existing installations, of course, especially on those
> with complex access rules which are usually the most difficult to
> modify/adjust. In other words, this is a pretty serious change.
>
>

How would a "built-in default" alter an existing setup? I mean, in  
every other instance that I can think of, if the config file includes  
the directive, the config file's version overrides the default ...

-- 
|_|O|_| Registered Linux user #585947
|_|_|O| Github: https://github.com/dpurgert
|O|O|O| PGP: 05CA 9A50 3F2E 1335 4DC5  4AEE 8E11 DDF3 1279 A281
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-keys
Size: 1734 bytes
Desc: PGP Public Key
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170413/2751abee/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 473 bytes
Desc: PGP Digital Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170413/2751abee/attachment.sig>

From yvoinov at gmail.com  Thu Apr 13 15:58:44 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 13 Apr 2017 21:58:44 +0600
Subject: [squid-users] [squid-dev] [RFC] Changes to http_access defaults
In-Reply-To: <20170413111414.Horde.xLtNThbtK50MUyRLMNz-uWn@192.168.10.20>
References: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>
 <9c01ab9e-6f7f-2e82-b3e2-9e1220c26d30@measurement-factory.com>
 <20170413111414.Horde.xLtNThbtK50MUyRLMNz-uWn@192.168.10.20>
Message-ID: <934bffcd-b53b-bf39-8b44-89672d76bdb3@gmail.com>



13.04.2017 21:14, Dan Purgert ?????:
> Quoting Alex Rousskov <rousskov at measurement-factory.com>:
>
>> On 04/12/2017 12:16 PM, Amos Jeffries wrote:
>>
>>> Changes to http_access defaults
>>
>> Clearly stating what you are trying to accomplish with these changes may
>> help others evaluate your proposal. Your initial email focuses on _how_
>> you are going to accomplish some implied/vague goal. What is the goal
>> here?
>>
>>
>>> I have become convinced that Squid always checks those
>>> security rules, then do the custom access rules. All other orderings
>>> seem to have turned out to be problematic and security-buggy in some
>>> edge cases or another.
>>
>> s/Squid always checks/Squid should always check/
>>
>>
>>> What are peoples opinions about making the following items built-in
>>> defaults?
>>>
>>>  acl Safe_ports port 21 80 443
>>>  acl CONNECT_ports port 443
>>>  acl CONNECT method CONNECT
>>>
>>>  http_acces deny !Safe_ports
>>>  http_access deny CONNECT !CONNECT_ports
>>
>>> The above change will have some effect on installations that try to use
>>> an empty squid.conf.
>>
>> And on many other existing installations, of course, especially on those
>> with complex access rules which are usually the most difficult to
>> modify/adjust. In other words, this is a pretty serious change.
>>
>>
>
> How would a "built-in default" alter an existing setup? I mean, in
> every other instance that I can think of, if the config file includes
> the directive, the config file's version overrides the default ...
This is normal behaviour. System administrator should have possibility
to override ANY default.
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170413/f62ec81b/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170413/f62ec81b/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170413/f62ec81b/attachment.sig>

From rousskov at measurement-factory.com  Thu Apr 13 16:39:35 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 13 Apr 2017 10:39:35 -0600
Subject: [squid-users] [squid-dev] [RFC] Changes to http_access defaults
In-Reply-To: <934bffcd-b53b-bf39-8b44-89672d76bdb3@gmail.com>
References: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>
 <9c01ab9e-6f7f-2e82-b3e2-9e1220c26d30@measurement-factory.com>
 <20170413111414.Horde.xLtNThbtK50MUyRLMNz-uWn@192.168.10.20>
 <934bffcd-b53b-bf39-8b44-89672d76bdb3@gmail.com>
Message-ID: <09a5855c-39bc-f5d5-bec7-899ba2c58158@measurement-factory.com>

On 04/13/2017 09:58 AM, Yuri Voinov wrote:
> 13.04.2017 21:14, Dan Purgert ?????:

>> How would a "built-in default" alter an existing setup? I mean, in
>> every other instance that I can think of, if the config file includes
>> the directive, the config file's version overrides the default ...

> This is normal behaviour. System administrator should have possibility
> to override ANY default.

That much is understood. What is not yet clear are the exact conditions
under which those defaults disappear. This is one of the two primary
questions the RFC does not answer yet (the other one being what exactly
this change is actually trying to accomplish).

"Normally", foo_bar defaults disappear at the first sign of an explicit
foo_bar rule in squid.conf. However, that will probably defeat the
(unspecified) purpose of supporting http_access defaults because every
Squid needs non-default http_access rules!

The suspected uselessness of "normal" behavior is exactly why those two
questions must be answered in the updated version of the RFC.

My earlier response sketched one way to add http_access defaults that do
not disappear so easily that they become useless (see
deny_unsafe_ports), but that idea has its own serious flaws. The "many
folks misconfigure access rules" problem may not have a good solution
(under Squid control); we should be careful not to make things worse
while not solving the unsolvable problem.

Alex.



From rousskov at measurement-factory.com  Thu Apr 13 16:52:58 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 13 Apr 2017 10:52:58 -0600
Subject: [squid-users] [RFC] Changes to http_access defaults
In-Reply-To: <09a5855c-39bc-f5d5-bec7-899ba2c58158@measurement-factory.com>
References: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>
 <9c01ab9e-6f7f-2e82-b3e2-9e1220c26d30@measurement-factory.com>
 <20170413111414.Horde.xLtNThbtK50MUyRLMNz-uWn@192.168.10.20>
 <934bffcd-b53b-bf39-8b44-89672d76bdb3@gmail.com>
 <09a5855c-39bc-f5d5-bec7-899ba2c58158@measurement-factory.com>
Message-ID: <e46d4371-ccb9-c2e3-f9bc-8a4b179c4c2a@measurement-factory.com>

On 04/13/2017 10:39 AM, Alex Rousskov wrote:

> The "many folks misconfigure access rules" problem may not have a
> good solution (under Squid control); we should be careful not to make
> things worse while not solving the unsolvable problem.


Here is an alternative idea: Instead of adding default http_access rules
inside Squid, add an optional squid.conf lint/checker. For many
configurations, especially the simple ones used by new Squid admins, it
is fairly easy to _automatically_ check whether these default rules are
violated.

If these rules are violated, Squid will log a startup warning like this:

  WARNING: Your http_access rules allow CONNECT to unsafe port XXX.
  More info at http://...?warning=xyz&port=XXX.

The URL will detail the dangers and also explain how to disable this
specific warning or linting as a whole.

I can discuss/detail this further if there is consensus that automated
checking is overall better than built-in http_access defaults.
Unfortunately, I do not have the time to volunteer an implementation.


HTH,

Alex.



From oliver at lennox-it.uk  Thu Apr 13 16:57:18 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Thu, 13 Apr 2017 16:57:18 +0000 (UTC)
Subject: [squid-users] HTTPS woes
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
Message-ID: <53345162.1369836.1492102638758@mail.yahoo.com>

Hi There,

I've been battling for the last few days on a little project to setup a Raspberry PI device as a small parental blocking server. I've managed to configure the device to work as a transparent proxy using squid which is assigned as the default gateway via DHCP and after a lot of messing about I've finally got to the point where it's routing traffic correctly, proxying and blocking unwanted websites over HTTP.

The problem I have is that for the life of me I cannot get things to work over HTTPS. It's working over the older, insecure web browsers where anything goes but the more modern browsers will not accept the SSL certificates and fail with insecure messages. I've tried various ways of generating a cert and also generating a CA cert and signing my other cert with it to no avail. I've had a mixture of errors back from the browser from WEAK_ALGORITHM to BAD_AUTHORITY to INVALID_CERT.

I've been using openssl to generate self-signed certificates and create a der file. Below is a recent attempt but I've tried lots of different approaches:

------------
openssl req -x509 -nodes -sha256 -days 3650 -newkey rsa:2048 -keyout squid.key -out squid.crt 
openssl req -new -x509 -key squid.key -out squid.pem 
openssl x509 -in squid.pem -inform pem -out squid.der -outform der
------------


Then my config in Squid is like this, the dhparams file I generated as per instructions in the squid wiki:

------------
http_port 3128 intercept
https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3 dhparams=/etc/squid3/ssl_cert/dhparam.pem 

#always_direct allow all 
ssl_bump server-first all 
sslproxy_cert_error allow all 
sslproxy_flags DONT_VERIFY_PEER 
sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS 

------------

The only routing rules I'm using are to forward port 80/443 to 3128/2129 respectively and also a POST_ROUTING "masquerade" rule which I got from a guide (and I'm not sure I 100% understand!)
 

Can anyone tell me where I'm going wrong? This is only for use on very small networks (home router + 2 or 3 trusted devices and users) so security between the rPI and the client is not a major concern - I just want it to work in the most simple and foolproof way possible.


Any advice would be very welcome.

Thanks,

Olly
oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252


From yvoinov at gmail.com  Thu Apr 13 18:00:48 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 14 Apr 2017 00:00:48 +0600
Subject: [squid-users] HTTPS woes
In-Reply-To: <53345162.1369836.1492102638758@mail.yahoo.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
Message-ID: <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>



13.04.2017 22:57, Olly Lennox ?????:
> Hi There,
>
> I've been battling for the last few days on a little project to setup a Raspberry PI device as a small parental blocking server. I've managed to configure the device to work as a transparent proxy using squid which is assigned as the default gateway via DHCP and after a lot of messing about I've finally got to the point where it's routing traffic correctly, proxying and blocking unwanted websites over HTTP.
>
> The problem I have is that for the life of me I cannot get things to work over HTTPS. It's working over the older, insecure web browsers where anything goes but the more modern browsers will not accept the SSL certificates and fail with insecure messages. I've tried various ways of generating a cert and also generating a CA cert and signing my other cert with it to no avail. I've had a mixture of errors back from the browser from WEAK_ALGORITHM to BAD_AUTHORITY to INVALID_CERT.
>
> I've been using openssl to generate self-signed certificates and create a der file. Below is a recent attempt but I've tried lots of different approaches:
>
> ------------
> openssl req -x509 -nodes -sha256 -days 3650 -newkey rsa:2048 -keyout squid.key -out squid.crt 
> openssl req -new -x509 -key squid.key -out squid.pem 
> openssl x509 -in squid.pem -inform pem -out squid.der -outform der
> ------------
>
>
> Then my config in Squid is like this, the dhparams file I generated as per instructions in the squid wiki:
First of all: what's Squid's version?
>
> ------------
> http_port 3128 intercept
> https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3 dhparams=/etc/squid3/ssl_cert/dhparam.pem 
You squid's built with interception support? show squid -v output.
>
> ssl_bump server-first all 
This  ^^^^^^^^^^^^^^^^^^^^^ option valid only up to Squid 3.4. If you
using 3.5.x, you should use new peek-n-splice rules.
> sslproxy_cert_error allow all 
> sslproxy_flags DONT_VERIFY_PEER 
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ Don't do this. Never. This force
squid to ignore (and hide) all security issues with SSL from user and
from you.
> sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS 
>
> ------------
>
> The only routing rules I'm using are to forward port 80/443 to 3128/2129 respectively and also a POST_ROUTING "masquerade" rule which I got from a guide (and I'm not sure I 100% understand!)
80/443 should be NATed to squid's box on squid's box.
>  
>
> Can anyone tell me where I'm going wrong? This is only for use on very small networks (home router + 2 or 3 trusted devices and users) so security between the rPI and the client is not a major concern - I just want it to work in the most simple and foolproof way possible.
You doing wrong only one: you not give any important to resolve issue
information.
At least squid's version and build options.
>
> Any advice would be very welcome.
>
> Thanks,
>
> Olly
> oliver at lennox-it.uk
> lennox-it.uk
> tel: 07900 648 252
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170414/2facccdb/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170414/2facccdb/attachment.sig>

From chip_pop at hotmail.com  Fri Apr 14 10:19:08 2017
From: chip_pop at hotmail.com (joseph)
Date: Fri, 14 Apr 2017 03:19:08 -0700 (PDT)
Subject: [squid-users] [RFC] Changes to http_access defaults
In-Reply-To: <e46d4371-ccb9-c2e3-f9bc-8a4b179c4c2a@measurement-factory.com>
References: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>
 <9c01ab9e-6f7f-2e82-b3e2-9e1220c26d30@measurement-factory.com>
 <20170413111414.Horde.xLtNThbtK50MUyRLMNz-uWn@192.168.10.20>
 <934bffcd-b53b-bf39-8b44-89672d76bdb3@gmail.com>
 <09a5855c-39bc-f5d5-bec7-899ba2c58158@measurement-factory.com>
 <e46d4371-ccb9-c2e3-f9bc-8a4b179c4c2a@measurement-factory.com>
Message-ID: <1492165148895-4682087.post@n4.nabble.com>

Alex Rousskov wrote
> On 04/13/2017 10:39 AM, Alex Rousskov wrote:
> 
>> The "many folks misconfigure access rules" problem may not have a
>> good solution (under Squid control); we should be careful not to make
>> things worse while not solving the unsolvable problem.
> 
> 
> Here is an alternative idea: Instead of adding default http_access rules
> inside Squid, add an optional squid.conf lint/checker. For many
> configurations, especially the simple ones used by new Squid admins, it
> is fairly easy to _automatically_ check whether these default rules are
> violated.
> 
> If these rules are violated, Squid will log a startup warning like this:
> 
>   WARNING: Your http_access rules allow CONNECT to unsafe port XXX.
>   More info at http://...?warning=xyz&port=XXX.
> 
> The URL will detail the dangers and also explain how to disable this
> specific warning or linting as a whole.
> 
> I can discuss/detail this further if there is consensus that automated
> checking is overall better than built-in http_access defaults.
> Unfortunately, I do not have the time to volunteer an implementation.
> 
> 
> HTH,
> 
> Alex.
> 
> _______________________________________________
> squid-users mailing list

> squid-users at .squid-cache

> http://lists.squid-cache.org/listinfo/squid-users

agreed on the warning part only  :)
 as yuri said --> System administrator should have possibility to override
ANY default.
{ANY == ANY}



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/RFC-Changes-to-http-access-defaults-tp4682073p4682087.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Fri Apr 14 11:28:58 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 14 Apr 2017 23:28:58 +1200
Subject: [squid-users] Squid Proxy with simple iptable rule ...
In-Reply-To: <CAMwDxM3ADo_ToEhbJvvCo8yOsU=zJ9EOLXVR5opqL7dbWMbyWQ@mail.gmail.com>
References: <CAMwDxM3ADo_ToEhbJvvCo8yOsU=zJ9EOLXVR5opqL7dbWMbyWQ@mail.gmail.com>
Message-ID: <a2c7576f-f1ef-450e-8377-11b32c632567@treenet.co.nz>

On 13/04/2017 11:46 p.m., Arsalan Hussain wrote:
> Dear All,
> 
> I am facing problem with iptable rules for squid 3.5.23. my simple squid
> configuration is attached and also iptable rules.
> 
> It works fine when i restart squid, iptables, network services but after a
> while it give problem of slow speed or even rejecting packets in squid
> access.log

Your squid.conf first line says that Browsers are configured to use the
proxy. That means iptables doing NAT is not relevant.

You also have a mix of a many very different and half-setup proxying
configurations in your configs.


First get that sorted out. Telling us what do you actually want the
traffic to be doing might be a good start.

What is going wrong is clear, but "I am facing a problem" does not tell
what we should advise to fix that and in this case your config is so
mixed its not easy to even make a good guess.

Amos



From squid3 at treenet.co.nz  Fri Apr 14 11:36:52 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 14 Apr 2017 23:36:52 +1200
Subject: [squid-users] HTTPS woes
In-Reply-To: <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
Message-ID: <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>

On 14/04/2017 6:00 a.m., Yuri Voinov wrote:
> 
> 
> 13.04.2017 22:57, Olly Lennox ?????:
>> Hi There,
>>
>> I've been battling for the last few days on a little project to setup a Raspberry PI device as a small parental blocking server. I've managed to configure the device to work as a transparent proxy using squid which is assigned as the default gateway via DHCP and after a lot of messing about I've finally got to the point where it's routing traffic correctly, proxying and blocking unwanted websites over HTTP.
>>
>> The problem I have is that for the life of me I cannot get things to work over HTTPS. It's working over the older, insecure web browsers where anything goes but the more modern browsers will not accept the SSL certificates and fail with insecure messages. I've tried various ways of generating a cert and also generating a CA cert and signing my other cert with it to no avail. I've had a mixture of errors back from the browser from WEAK_ALGORITHM to BAD_AUTHORITY to INVALID_CERT.
>>
>> I've been using openssl to generate self-signed certificates and create a der file. Below is a recent attempt but I've tried lots of different approaches:
>>
>> ------------
>> openssl req -x509 -nodes -sha256 -days 3650 -newkey rsa:2048 -keyout squid.key -out squid.crt 
>> openssl req -new -x509 -key squid.key -out squid.pem 
>> openssl x509 -in squid.pem -inform pem -out squid.der -outform der
>> ------------
>>
>>
>> Then my config in Squid is like this, the dhparams file I generated as per instructions in the squid wiki:
> First of all: what's Squid's version?

And secondly; are you sufficiently capable with Debian to (cross-)build
your own Squid package that can run on Raspian?

The Debian squid/squid3 packages do not have TLS/SSL/HTTPS support. So
you will be building your own to get the bumping features.

Amos



From rafael.akchurin at diladele.com  Fri Apr 14 11:39:57 2017
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Fri, 14 Apr 2017 11:39:57 +0000
Subject: [squid-users] HTTPS woes
In-Reply-To: <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
Message-ID: <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>

>>> Then my config in Squid is like this, the dhparams file I generated as per instructions in the squid wiki:
>> First of all: what's Squid's version?

> And secondly; are you sufficiently capable with Debian to (cross-)build your own Squid package that can run on Raspian?
> The Debian squid/squid3 packages do not have TLS/SSL/HTTPS support. So you will be building your own to get the bumping features.

When you decide to recompile on Raspbian, please be sure to take a look at https://docs.diladele.com/administrator_guide_5_0/install/rpi/squid.html - it describes one way of doing this  *on* RPI (without cross compiling). But it is slooowwww.

From oliver at lennox-it.uk  Fri Apr 14 11:52:08 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Fri, 14 Apr 2017 11:52:08 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
Message-ID: <123378366.262123.1492170728064@mail.yahoo.com>

I've tried building it and it seems to have make install -ed correctly but I'm getting "command not found" when I try to execute squid3. Is there a step I'm missing??oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252

      From: Rafael Akchurin <rafael.akchurin at diladele.com>
 To: "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Friday, 14 April 2017, 12:40
 Subject: Re: [squid-users] HTTPS woes
   
>>> Then my config in Squid is like this, the dhparams file I generated as per instructions in the squid wiki:
>> First of all: what's Squid's version?

> And secondly; are you sufficiently capable with Debian to (cross-)build your own Squid package that can run on Raspian?
> The Debian squid/squid3 packages do not have TLS/SSL/HTTPS support. So you will be building your own to get the bumping features.

When you decide to recompile on Raspbian, please be sure to take a look at https://docs.diladele.com/administrator_guide_5_0/install/rpi/squid.html - it describes one way of doing this? *on* RPI (without cross compiling). But it is slooowwww.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170414/716b2aae/attachment.htm>

From squid3 at treenet.co.nz  Fri Apr 14 11:57:39 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 14 Apr 2017 23:57:39 +1200
Subject: [squid-users] HTTPS woes
In-Reply-To: <123378366.262123.1492170728064@mail.yahoo.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <123378366.262123.1492170728064@mail.yahoo.com>
Message-ID: <3499dbf7-32aa-abe0-34ad-bc88b58c0bed@treenet.co.nz>

On 14/04/2017 11:52 p.m., Olly Lennox wrote:
> I've tried building it and it seems to have make install -ed
> correctly but I'm getting "command not found" when I try to execute
> squid3. Is there a step I'm missing?

Debian latest and custom builds use the binary name 'squid' for versions
3.5+.

Amos



From Antony.Stone at squid.open.source.it  Fri Apr 14 11:58:14 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 14 Apr 2017 13:58:14 +0200
Subject: [squid-users] HTTPS woes
In-Reply-To: <123378366.262123.1492170728064@mail.yahoo.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <123378366.262123.1492170728064@mail.yahoo.com>
Message-ID: <201704141358.14704.Antony.Stone@squid.open.source.it>

On Friday 14 April 2017 at 13:52:08, Olly Lennox wrote:

> I've tried building it and it seems to have make install -ed correctly but
> I'm getting "command not found" when I try to execute squid3.

Well, what command are you trying to run (the one which is "not found")?

And what do you from "whereis squid"?

If that second command shows nothing, what do you get from:
"find / -type f -name squid"?


Antony.

>       From: Rafael Akchurin <rafael.akchurin at diladele.com>
>  To: "squid-users at lists.squid-cache.org"
> <squid-users at lists.squid-cache.org> Sent: Friday, 14 April 2017, 12:40
>  Subject: Re: [squid-users] HTTPS woes
> 
> >>> Then my config in Squid is like this, the dhparams file I generated as per 
instructions in the squid wiki:
> >> First of all: what's Squid's version?
> > 
> > And secondly; are you sufficiently capable with Debian to (cross-)build
> > your own Squid package that can run on Raspian? The Debian squid/squid3
> > packages do not have TLS/SSL/HTTPS support. So you will be building your
> > own to get the bumping features.
> 
> When you decide to recompile on Raspbian, please be sure to take a look at
> https://docs.diladele.com/administrator_guide_5_0/install/rpi/squid.html -
> it describes one way of doing this  *on* RPI (without cross compiling).
> But it is slooowwww. _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"I think both KDE and Gnome suck - I'm quite unbiased in that, because I use a 
Mac."

 - Jason Isitt

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Fri Apr 14 12:15:04 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 15 Apr 2017 00:15:04 +1200
Subject: [squid-users] [squid-dev] [RFC] Changes to http_access defaults
In-Reply-To: <20170413111414.Horde.xLtNThbtK50MUyRLMNz-uWn@192.168.10.20>
References: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>
 <9c01ab9e-6f7f-2e82-b3e2-9e1220c26d30@measurement-factory.com>
 <20170413111414.Horde.xLtNThbtK50MUyRLMNz-uWn@192.168.10.20>
Message-ID: <7e856cc6-67d0-3cfc-a176-18cfffacbd0b@treenet.co.nz>

On 14/04/2017 3:14 a.m., Dan Purgert wrote:
> Quoting Alex Rousskov <rousskov at measurement-factory.com>:
> 
>> On 04/12/2017 12:16 PM, Amos Jeffries wrote:
>>
>>> Changes to http_access defaults
>>
>> Clearly stating what you are trying to accomplish with these changes may
>> help others evaluate your proposal. Your initial email focuses on _how_
>> you are going to accomplish some implied/vague goal. What is the goal
>> here?
>>
>>
>>> I have become convinced that Squid always checks those
>>> security rules, then do the custom access rules. All other orderings
>>> seem to have turned out to be problematic and security-buggy in some
>>> edge cases or another.
>>
>> s/Squid always checks/Squid should always check/
>>
>>
>>> What are peoples opinions about making the following items built-in
>>> defaults?
>>>
>>>  acl Safe_ports port 21 80 443
>>>  acl CONNECT_ports port 443
>>>  acl CONNECT method CONNECT
>>>
>>>  http_acces deny !Safe_ports
>>>  http_access deny CONNECT !CONNECT_ports
>>
>>> The above change will have some effect on installations that try to use
>>> an empty squid.conf.
>>
>> And on many other existing installations, of course, especially on those
>> with complex access rules which are usually the most difficult to
>> modify/adjust. In other words, this is a pretty serious change.
>>
>>
> 
> How would a "built-in default" alter an existing setup? I mean, in every
> other instance that I can think of, if the config file includes the
> directive, the config file's version overrides the default ...
> 

The way built-in's are generally done in Squid is to have a set of lines
that are hard-coded and treated as existing "above" the first line of
squid.conf.

For existing setups where non-443 ports were desired with CONNECT this
approach would mean admin have to list them in SSL_ports/CONNECT_ports
instead of simply removing all lines mentioning "SSL_Ports".

That is really a practice people should be doing anyway, so is this
change from whatever you are doing to a way that enforces best-practice
going to be a major issue for anyone?


[That is part of the reason I've sent this RFC to all of squid-users,
instead of just squid-dev. To see what sort of issues people will have
with that kind of change, and how widespread the trouble would be.]

Amos



From oliver at lennox-it.uk  Fri Apr 14 12:15:41 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Fri, 14 Apr 2017 12:15:41 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <1678068035.308198.1492171790343@mail.yahoo.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <123378366.262123.1492170728064@mail.yahoo.com>
 <201704141358.14704.Antony.Stone@squid.open.source.it>
 <1678068035.308198.1492171790343@mail.yahoo.com>
Message-ID: <820496486.320844.1492172141961@mail.yahoo.com>

(Sorry, reposted because first email was too big I've edited out some bits)


No I'm not getting much luck finding these, This is the result of my make install, has it installed right?



result of make 

-----


Making all in compat

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/compat'

make[1]: Nothing to be done for 'all'.

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/compat'

Making all in lib

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/lib'

Making all in libTrie

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/lib/libTrie'

Making all in .

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/lib/libTrie'

make[3]: Nothing to be done for 'all-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/lib/libTrie'

Making all in test

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/lib/libTrie/test'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/lib/libTrie/test'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/lib/libTrie'

Making all in snmplib

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/lib/snmplib'

make[2]: Nothing to be done for 'all'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/lib/snmplib'

Making all in rfcnb

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/lib/rfcnb'

make[2]: Nothing to be done for 'all'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/lib/rfcnb'

Making all in smblib

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/lib/smblib'

make[2]: Nothing to be done for 'all'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/lib/smblib'

Making all in ntlmauth

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/lib/ntlmauth'

make[2]: Nothing to be done for 'all'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/lib/ntlmauth'

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/lib'

make[2]: Nothing to be done for 'all-am'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/lib'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/lib'

Making all in libltdl

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/libltdl'

make  all-am

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/libltdl'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/libltdl'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/libltdl'

Making all in scripts

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/scripts'

make[1]: Nothing to be done for 'all'.

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/scripts'

Making all in icons

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/icons'

make[1]: Nothing to be done for 'all'.

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/icons'

Making all in errors

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/errors'

make[1]: Nothing to be done for 'all'.

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/errors'

Making all in doc

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/doc'

Making all in manuals

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/doc/manuals'

make[2]: Nothing to be done for 'all'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/doc/manuals'

Making all in release-notes

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/doc/release-notes'

make[2]: Nothing to be done for 'all'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/doc/release-notes'

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/doc'

make[2]: Nothing to be done for 'all-am'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/doc'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/doc'

Making all in helpers

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/helpers'

Making all in basic_auth

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth'

Making all in DB

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/DB'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/DB'

Making all in fake

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/fake'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/fake'

Making all in getpwnam

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/getpwnam'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/getpwnam'

Making all in LDAP

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/LDAP'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/LDAP'

Making all in NCSA

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/NCSA'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/NCSA'

Making all in NIS

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/NIS'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/NIS'

Making all in PAM

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/PAM'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/PAM'

Making all in POP3

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/POP3'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/POP3'

Making all in RADIUS

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/RADIUS'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/RADIUS'

Making all in SASL

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/SASL'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/SASL'

Making all in SMB

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/SMB'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/SMB'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth'

make[3]: Nothing to be done for 'all-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth'

Making all in digest_auth

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth'

Making all in file

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth/file'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth/file'

Making all in LDAP

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth/LDAP'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth/LDAP'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth'

make[3]: Nothing to be done for 'all-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth'

Making all in external_acl

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl'

Making all in file_userip

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/file_userip'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/file_userip'

Making all in kerberos_ldap_group

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/kerberos_ldap_group'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/kerberos_ldap_group'

make[4]: Nothing to be done for 'all-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/kerberos_ldap_group'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/kerberos_ldap_group'

Making all in LDAP_group

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/LDAP_group'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/LDAP_group'

Making all in session

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/session'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/session'

Making all in SQL_session

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/SQL_session'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/SQL_session'

Making all in unix_group

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/unix_group'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/unix_group'

Making all in wbinfo_group

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/wbinfo_group'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/wbinfo_group'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl'

make[3]: Nothing to be done for 'all-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl'

Making all in log_daemon

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon'

Making all in DB

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon/DB'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon/DB'

Making all in file

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon/file'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon/file'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon'

make[3]: Nothing to be done for 'all-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon'

Making all in negotiate_auth

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth'

Making all in kerberos

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth/kerberos'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth/kerberos'

make[4]: Nothing to be done for 'all-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth/kerberos'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth/kerberos'

Making all in wrapper

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth/wrapper'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth/wrapper'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth'

make[3]: Nothing to be done for 'all-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth'

Making all in url_rewrite

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/url_rewrite'

Making all in fake

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/url_rewrite/fake'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/url_rewrite/fake'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/url_rewrite'

make[3]: Nothing to be done for 'all-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/url_rewrite'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/url_rewrite'

Making all in storeid_rewrite

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/storeid_rewrite'

Making all in file

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/storeid_rewrite/file'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/storeid_rewrite/file'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/storeid_rewrite'

make[3]: Nothing to be done for 'all-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/storeid_rewrite'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/storeid_rewrite'

Making all in ntlm_auth

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth'

Making all in fake

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth/fake'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth/fake'

Making all in smb_lm

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth/smb_lm'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth/smb_lm'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth'

make[3]: Nothing to be done for 'all-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth'

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers'

make[2]: Nothing to be done for 'all-am'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers'

Making all in src

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/src'

make  all-recursive

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/src'

Making all in base

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/base'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/base'

Making all in anyp

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/anyp'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/anyp'

Making all in helper

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/helper'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/helper'

Making all in ftp

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/ftp'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/ftp'

Making all in parser

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/parser'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/parser'

Making all in comm

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/comm'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/comm'

Making all in eui

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/eui'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/eui'

Making all in acl

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/acl'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/acl'

Making all in format

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/format'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/format'

Making all in clients

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/clients'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/clients'

Making all in servers

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/servers'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/servers'

Making all in fs

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/fs'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/fs'

Making all in repl

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/repl'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/repl'

Making all in auth

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth'

Making all in basic

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth/basic'

make[4]: Nothing to be done for 'all'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth/basic'

Making all in digest

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth/digest'

make[4]: Nothing to be done for 'all'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth/digest'

Making all in negotiate

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth/negotiate'

make[4]: Nothing to be done for 'all'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth/negotiate'

Making all in ntlm

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth/ntlm'

make[4]: Nothing to be done for 'all'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth/ntlm'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth'

make[4]: Nothing to be done for 'all-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth'

Making all in http

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/http'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/http'

Making all in ip

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/ip'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/ip'

Making all in icmp

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/icmp'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/icmp'

Making all in ident

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/ident'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/ident'

Making all in log

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/log'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/log'

Making all in ipc

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/ipc'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/ipc'

Making all in mgr

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/mgr'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/mgr'

Making all in snmp

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/snmp'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/snmp'

Making all in adaptation

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/adaptation'

Making all in icap

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/adaptation/icap'

make[4]: Nothing to be done for 'all'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/adaptation/icap'

Making all in ecap

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/adaptation/ecap'

make[4]: Nothing to be done for 'all'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/adaptation/ecap'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/adaptation'

make[4]: Nothing to be done for 'all-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/adaptation'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/adaptation'

Making all in esi

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/esi'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/esi'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src'

make[3]: Nothing to be done for 'all-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/src'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/src'

Making all in tools

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/tools'

Making all in purge

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/tools/purge'

make[2]: Nothing to be done for 'all'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/tools/purge'

Making all in squidclient

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/tools/squidclient'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/tools/squidclient'

make[3]: Nothing to be done for 'all-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/tools/squidclient'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/tools/squidclient'

Making all in systemd

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/tools/systemd'

make[2]: Nothing to be done for 'all'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/tools/systemd'

Making all in sysvinit

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/tools/sysvinit'

make[2]: Nothing to be done for 'all'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/tools/sysvinit'

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/tools'

make[2]: Nothing to be done for 'all-am'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/tools'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/tools'

Making all in test-suite

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/test-suite'

make[1]: Nothing to be done for 'all'.

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/test-suite'

make[1]: Entering directory '/usr/src/squid/squid-3.5.25'

make[1]: Nothing to be done for 'all-am'.

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25'



------


result of make install


-------------


Making install in compat

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/compat'

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/compat'

make[2]: Nothing to be done for 'install-exec-am'.

make[2]: Nothing to be done for 'install-data-am'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/compat'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/compat'

Making install in lib

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/lib'

Making all in libTrie

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/lib/libTrie'

Making all in .

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/lib/libTrie'

make[3]: Nothing to be done for 'all-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/lib/libTrie'

Making all in test

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/lib/libTrie/test'

make[3]: Nothing to be done for 'all'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/lib/libTrie/test'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/lib/libTrie'

Making all in snmplib

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/lib/snmplib'

make[2]: Nothing to be done for 'all'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/lib/snmplib'

Making all in rfcnb

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/lib/rfcnb'

make[2]: Nothing to be done for 'all'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/lib/rfcnb'

Making all in smblib

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/lib/smblib'

make[2]: Nothing to be done for 'all'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/lib/smblib'

Making all in ntlmauth

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/lib/ntlmauth'

make[2]: Nothing to be done for 'all'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/lib/ntlmauth'

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/lib'

make[2]: Nothing to be done for 'all-am'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/lib'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/lib'

Making install in libltdl

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/libltdl'

make  install-am

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/libltdl'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/libltdl'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/libltdl'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/libltdl'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/libltdl'

Making install in scripts

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/scripts'

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/scripts'

make[2]: Nothing to be done for 'install-exec-am'.

make[2]: Nothing to be done for 'install-data-am'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/scripts'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/scripts'

Making install in icons

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/icons'

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/icons'

make[2]: Nothing to be done for 'install-exec-am'.

/bin/mkdir -p '/usr/share/squid3/icons/silk'

/usr/bin/install -c -m 644 silk/application.png silk/arrow_up.png silk/bomb.png silk/box.png silk/bricks.png silk/bullet_red.png silk/cd.png silk/chart_line.png silk/compress.png silk/computer_link.png silk/css.png silk/cup.png silk/database.png silk/database_table.png silk/drive_disk.png silk/film_key.png silk/film.png silk/folder.png silk/folder_table.png silk/image.png silk/information.png silk/layers.png silk/layout.png silk/link.png silk/music.png silk/package_go.png silk/package.png silk/page_code.png silk/page_excel.png silk/page_green.png silk/page_white_acrobat.png silk/page_white_cplusplus.png silk/page_white_c.png silk/page_white_flash.png silk/page_white_magnify.png silk/page_white_picture.png silk/page_white.png silk/page_white_powerpoint.png silk/page_white_stack.png silk/page_white_text.png '/usr/share/squid3/icons/silk'

/usr/bin/install -c -m 644 silk/page_white_word.png silk/page_white_zip.png silk/page_world.png silk/photo.png silk/picture.png silk/plugin_add.png silk/plugin.png silk/script_gear.png silk/script_palette.png silk/script.png '/usr/share/squid3/icons/silk'

/usr/bin/install -c -m 644 ./SN.png "/usr/share/squid3/icons/"

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/icons'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/icons'

Making install in errors

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/errors'

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/errors'

if test -f /etc/squid3/errorpage.css ; then \

echo "install-exec-local will not overwrite existing /etc/squid3/errorpage.css" ; \

else \

/bin/bash /usr/src/squid/squid-3.5.25/cfgaux/install-sh -d `dirname /etc/squid3/errorpage.css` ; \

echo "/usr/bin/install -c -m 644 ./errorpage.css /etc/squid3/errorpage.css"; \

/usr/bin/install -c -m 644 ./errorpage.css /etc/squid3/errorpage.css; \

fi

install-exec-local will not overwrite existing /etc/squid3/errorpage.css

/bin/bash /usr/src/squid/squid-3.5.25/cfgaux/install-sh -d /usr/share/squid3/errors ; \

for l in af.lang ar.lang az.lang bg.lang ca.lang cs.lang da.lang de.lang el.lang en.lang es.lang et.lang fa.lang fi.lang fr.lang he.lang hu.lang hy.lang id.lang it.lang ja.lang ka.lang ko.lang lt.lang lv.lang ms.lang nl.lang oc.lang pl.lang pt-br.lang pt.lang ro.lang ru.lang sk.lang sl.lang sr-cyrl.lang sr-latn.lang sv.lang th.lang tr.lang uk.lang uz.lang vi.lang zh-hans.lang zh-hant.lang  templates; do \

    l=`basename $l .lang`; \

    echo "Located $l for install..."; \

    if test -d ./$l || test -d ./$l; then \

/bin/bash /usr/src/squid/squid-3.5.25/cfgaux/install-sh -d /usr/share/squid3/errors/$l; \

    fi; \

    for f in templates/ERR_ACCESS_DENIED templates/ERR_ACL_TIME_QUOTA_EXCEEDED templates/ERR_AGENT_CONFIGURE templates/ERR_AGENT_WPAD templates/ERR_CACHE_ACCESS_DENIED templates/ERR_CACHE_MGR_ACCESS_DENIED templates/ERR_CANNOT_FORWARD templates/ERR_CONFLICT_HOST templates/ERR_CONNECT_FAIL templates/ERR_DIR_LISTING templates/ERR_DNS_FAIL templates/ERR_ESI templates/ERR_FORWARDING_DENIED templates/ERR_FTP_DISABLED templates/ERR_FTP_FAILURE templates/ERR_FTP_FORBIDDEN templates/ERR_FTP_NOT_FOUND templates/ERR_FTP_PUT_CREATED templates/ERR_FTP_PUT_ERROR templates/ERR_FTP_PUT_MODIFIED templates/ERR_FTP_UNAVAILABLE templates/ERR_GATEWAY_FAILURE templates/ERR_ICAP_FAILURE templates/ERR_INVALID_REQ templates/ERR_INVALID_RESP templates/ERR_INVALID_URL templates/ERR_LIFETIME_EXP templates/ERR_NO_RELAY templates/ERR_ONLY_IF_CACHED_MISS templates/ERR_PRECONDITION_FAILED templates/ERR_READ_ERROR templates/ERR_READ_TIMEOUT templates/ERR_SECURE_CONNECT_FAIL templates/ERR_SHUTTING_DOWN templates/ERR_SOCKET_FAILURE templates/ERR_TOO_BIG templates/ERR_UNSUP_HTTPVERSION templates/ERR_UNSUP_REQ templates/ERR_URN_RESOLVE templates/ERR_WRITE_ERROR templates/ERR_ZERO_SIZE_OBJECT  templates/error-details.txt; do \

page=`basename $f`; \

if test -f ./$l/$page; then \

   echo "/usr/bin/install -c -m 644 ./$l/$page /usr/share/squid3/errors/$l"; \

   /usr/bin/install -c -m 644 ./$l/$page /usr/share/squid3/errors/$l; \

elif test -f ./$l/$page; then \

   echo "/usr/bin/install -c -m 644 ./$l/$page /usr/share/squid3/errors/$l"; \

   /usr/bin/install -c -m 644 ./$l/$page /usr/share/squid3/errors/$l; \

fi; \

    done; \

done; \

/usr/bin/install -c -m 644 ./TRANSLATORS /usr/share/squid3/errors/TRANSLATORS; \

/usr/bin/install -c -m 644 ./COPYRIGHT /usr/share/squid3/errors/COPYRIGHT; \

/usr/bin/install -c -m 644 ./errorpage.css /etc/squid3/errorpage.css.default; \

/bin/bash ./alias-link.sh "/bin/ln" "/bin/rm -f" "/usr/share/squid3/errors" "./aliases" || exit 1 ;

Located af for install...

/usr/bin/install -c -m 644 ./af/ERR_ACCESS_DENIED /usr/share/squid3/errors/af


...
<lots of errors>
...
/usr/bin/install -c -m 644 ./templates/ERR_ZERO_SIZE_OBJECT /usr/share/squid3/errors/templates

/usr/bin/install -c -m 644 ./templates/error-details.txt /usr/share/squid3/errors/templates

WARNING: ## translations do not exist. Nothing to do for: Copyright (C) 1996-2017 The Squid Software Foundation and contributors

WARNING: ## translations do not exist. Nothing to do for: 

WARNING: ## translations do not exist. Nothing to do for: Squid software is distributed under GPLv2+ license and includes

WARNING: ## translations do not exist. Nothing to do for: contributions from numerous individuals and organizations.

WARNING: ## translations do not exist. Nothing to do for: Please see the COPYING and CONTRIBUTORS files for details.

WARNING: ## translations do not exist. Nothing to do for: 

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/errors'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/errors'

Making install in doc

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/doc'

Making install in manuals

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/doc/manuals'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/doc/manuals'

make[3]: Nothing to be done for 'install-exec-am'.

make[3]: Nothing to be done for 'install-data-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/doc/manuals'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/doc/manuals'

Making install in release-notes

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/doc/release-notes'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/doc/release-notes'

make[3]: Nothing to be done for 'install-exec-am'.

make[3]: Nothing to be done for 'install-data-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/doc/release-notes'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/doc/release-notes'

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/doc'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/doc'

make[3]: Nothing to be done for 'install-exec-am'.

make[3]: Nothing to be done for 'install-data-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/doc'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/doc'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/doc'

Making install in helpers

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/helpers'

Making install in basic_auth

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth'

Making install in DB

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/DB'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/DB'

/bin/mkdir -p '/lib/squid3'

/usr/bin/install -c basic_db_auth '/lib/squid3'

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 basic_db_auth.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/DB'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/DB'

Making install in fake

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/fake'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/fake'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c basic_fake_auth '/lib/squid3'

libtool: install: /usr/bin/install -c basic_fake_auth /lib/squid3/basic_fake_auth

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/fake'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/fake'

Making install in getpwnam

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/getpwnam'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/getpwnam'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c basic_getpwnam_auth '/lib/squid3'

libtool: install: /usr/bin/install -c basic_getpwnam_auth /lib/squid3/basic_getpwnam_auth

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 basic_getpwnam_auth.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/getpwnam'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/getpwnam'

Making install in LDAP

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/LDAP'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/LDAP'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c basic_ldap_auth '/lib/squid3'

libtool: install: /usr/bin/install -c basic_ldap_auth /lib/squid3/basic_ldap_auth

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 basic_ldap_auth.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/LDAP'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/LDAP'

Making install in NCSA

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/NCSA'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/NCSA'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c basic_ncsa_auth '/lib/squid3'

libtool: install: /usr/bin/install -c basic_ncsa_auth /lib/squid3/basic_ncsa_auth

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 basic_ncsa_auth.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/NCSA'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/NCSA'

Making install in NIS

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/NIS'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/NIS'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c basic_nis_auth '/lib/squid3'

libtool: install: /usr/bin/install -c basic_nis_auth /lib/squid3/basic_nis_auth

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/NIS'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/NIS'

Making install in PAM

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/PAM'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/PAM'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c basic_pam_auth '/lib/squid3'

libtool: install: /usr/bin/install -c basic_pam_auth /lib/squid3/basic_pam_auth

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 basic_pam_auth.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/PAM'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/PAM'

Making install in POP3

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/POP3'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/POP3'

/bin/mkdir -p '/lib/squid3'

/usr/bin/install -c basic_pop3_auth '/lib/squid3'

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 basic_pop3_auth.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/POP3'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/POP3'

Making install in RADIUS

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/RADIUS'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/RADIUS'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c basic_radius_auth '/lib/squid3'

libtool: install: /usr/bin/install -c basic_radius_auth /lib/squid3/basic_radius_auth

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 basic_radius_auth.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/RADIUS'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/RADIUS'

Making install in SASL

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/SASL'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/SASL'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c basic_sasl_auth '/lib/squid3'

libtool: install: /usr/bin/install -c basic_sasl_auth /lib/squid3/basic_sasl_auth

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 basic_sasl_auth.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/SASL'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/SASL'

Making install in SMB

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/SMB'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/SMB'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c basic_smb_auth '/lib/squid3'

libtool: install: /usr/bin/install -c basic_smb_auth /lib/squid3/basic_smb_auth

/bin/mkdir -p '/lib/squid3'

/usr/bin/install -c basic_smb_auth.sh '/lib/squid3'

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/SMB'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth/SMB'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/basic_auth'

Making install in digest_auth

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth'

Making install in file

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth/file'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth/file'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c digest_file_auth '/lib/squid3'

libtool: install: /usr/bin/install -c digest_file_auth /lib/squid3/digest_file_auth

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 digest_file_auth.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth/file'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth/file'

Making install in LDAP

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth/LDAP'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth/LDAP'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c digest_ldap_auth '/lib/squid3'

libtool: install: /usr/bin/install -c digest_ldap_auth /lib/squid3/digest_ldap_auth

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth/LDAP'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth/LDAP'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/digest_auth'

Making install in external_acl

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl'

Making install in file_userip

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/file_userip'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/file_userip'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c ext_file_userip_acl '/lib/squid3'

libtool: install: /usr/bin/install -c ext_file_userip_acl /lib/squid3/ext_file_userip_acl

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 ext_file_userip_acl.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/file_userip'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/file_userip'

Making install in kerberos_ldap_group

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/kerberos_ldap_group'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/kerberos_ldap_group'

make[5]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/kerberos_ldap_group'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c ext_kerberos_ldap_group_acl '/lib/squid3'

libtool: install: /usr/bin/install -c ext_kerberos_ldap_group_acl /lib/squid3/ext_kerberos_ldap_group_acl

/bin/mkdir -p '/lib/squid3'

/usr/bin/install -c cert_tool '/lib/squid3'

make[5]: Nothing to be done for 'install-data-am'.

make[5]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/kerberos_ldap_group'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/kerberos_ldap_group'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/kerberos_ldap_group'

Making install in LDAP_group

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/LDAP_group'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/LDAP_group'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c ext_ldap_group_acl '/lib/squid3'

libtool: install: /usr/bin/install -c ext_ldap_group_acl /lib/squid3/ext_ldap_group_acl

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 ext_ldap_group_acl.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/LDAP_group'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/LDAP_group'

Making install in session

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/session'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/session'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c ext_session_acl '/lib/squid3'

libtool: install: /usr/bin/install -c ext_session_acl /lib/squid3/ext_session_acl

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 ext_session_acl.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/session'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/session'

Making install in SQL_session

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/SQL_session'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/SQL_session'

/bin/mkdir -p '/lib/squid3'

/usr/bin/install -c ext_sql_session_acl '/lib/squid3'

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 ext_sql_session_acl.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/SQL_session'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/SQL_session'

Making install in unix_group

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/unix_group'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/unix_group'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c ext_unix_group_acl '/lib/squid3'

libtool: install: /usr/bin/install -c ext_unix_group_acl /lib/squid3/ext_unix_group_acl

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 ext_unix_group_acl.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/unix_group'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/unix_group'

Making install in wbinfo_group

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/wbinfo_group'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/wbinfo_group'

/bin/mkdir -p '/lib/squid3'

/usr/bin/install -c ext_wbinfo_group_acl '/lib/squid3'

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 ext_wbinfo_group_acl.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/wbinfo_group'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl/wbinfo_group'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/external_acl'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/external_acl'

Making install in log_daemon

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon'

Making install in DB

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon/DB'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon/DB'

/bin/mkdir -p '/lib/squid3'

/usr/bin/install -c log_db_daemon '/lib/squid3'

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 log_db_daemon.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon/DB'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon/DB'

Making install in file

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon/file'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon/file'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c log_file_daemon '/lib/squid3'

libtool: install: /usr/bin/install -c log_file_daemon /lib/squid3/log_file_daemon

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon/file'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon/file'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/log_daemon'

Making install in negotiate_auth

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth'

Making install in kerberos

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth/kerberos'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth/kerberos'

make[5]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth/kerberos'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c negotiate_kerberos_auth negotiate_kerberos_auth_test '/lib/squid3'

libtool: install: /usr/bin/install -c negotiate_kerberos_auth /lib/squid3/negotiate_kerberos_auth

libtool: install: /usr/bin/install -c negotiate_kerberos_auth_test /lib/squid3/negotiate_kerberos_auth_test

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 negotiate_kerberos_auth.8 '/usr/share/man/man8'

make[5]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth/kerberos'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth/kerberos'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth/kerberos'

Making install in wrapper

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth/wrapper'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth/wrapper'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c negotiate_wrapper_auth '/lib/squid3'

libtool: install: /usr/bin/install -c negotiate_wrapper_auth /lib/squid3/negotiate_wrapper_auth

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth/wrapper'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth/wrapper'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/negotiate_auth'

Making install in url_rewrite

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/url_rewrite'

Making install in fake

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/url_rewrite/fake'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/url_rewrite/fake'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c url_fake_rewrite '/lib/squid3'

libtool: install: /usr/bin/install -c url_fake_rewrite /lib/squid3/url_fake_rewrite

/bin/mkdir -p '/lib/squid3'

/usr/bin/install -c url_fake_rewrite.sh '/lib/squid3'

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/url_rewrite/fake'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/url_rewrite/fake'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/url_rewrite'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/url_rewrite'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/url_rewrite'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/url_rewrite'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/url_rewrite'

Making install in storeid_rewrite

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/storeid_rewrite'

Making install in file

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/storeid_rewrite/file'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/storeid_rewrite/file'

/bin/mkdir -p '/lib/squid3'

/usr/bin/install -c storeid_file_rewrite '/lib/squid3'

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 storeid_file_rewrite.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/storeid_rewrite/file'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/storeid_rewrite/file'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/storeid_rewrite'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/storeid_rewrite'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/storeid_rewrite'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/storeid_rewrite'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/storeid_rewrite'

Making install in ntlm_auth

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth'

Making install in fake

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth/fake'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth/fake'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c ntlm_fake_auth '/lib/squid3'

libtool: install: /usr/bin/install -c ntlm_fake_auth /lib/squid3/ntlm_fake_auth

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth/fake'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth/fake'

Making install in smb_lm

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth/smb_lm'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth/smb_lm'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../../libtool   --mode=install /usr/bin/install -c ntlm_smb_lm_auth '/lib/squid3'

libtool: install: /usr/bin/install -c ntlm_smb_lm_auth /lib/squid3/ntlm_smb_lm_auth

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth/smb_lm'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth/smb_lm'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers/ntlm_auth'

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/helpers'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/helpers'

make[3]: Nothing to be done for 'install-exec-am'.

make[3]: Nothing to be done for 'install-data-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/helpers'

Making install in src

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/src'

make  install-recursive

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/src'

Making install in base

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/base'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/base'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/base'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/base'

Making install in anyp

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/anyp'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/anyp'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/anyp'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/anyp'

Making install in helper

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/helper'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/helper'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/helper'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/helper'

Making install in ftp

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/ftp'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/ftp'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/ftp'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/ftp'

Making install in parser

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/parser'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/parser'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/parser'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/parser'

Making install in comm

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/comm'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/comm'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/comm'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/comm'

Making install in eui

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/eui'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/eui'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/eui'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/eui'

Making install in acl

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/acl'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/acl'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/acl'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/acl'

Making install in format

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/format'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/format'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/format'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/format'

Making install in clients

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/clients'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/clients'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/clients'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/clients'

Making install in servers

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/servers'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/servers'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/servers'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/servers'

Making install in fs

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/fs'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/fs'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/fs'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/fs'

Making install in repl

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/repl'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/repl'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/repl'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/repl'

Making install in auth

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth'

Making install in basic

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth/basic'

make[5]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth/basic'

make[5]: Nothing to be done for 'install-exec-am'.

make[5]: Nothing to be done for 'install-data-am'.

make[5]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth/basic'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth/basic'

Making install in digest

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth/digest'

make[5]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth/digest'

make[5]: Nothing to be done for 'install-exec-am'.

make[5]: Nothing to be done for 'install-data-am'.

make[5]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth/digest'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth/digest'

Making install in negotiate

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth/negotiate'

make[5]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth/negotiate'

make[5]: Nothing to be done for 'install-exec-am'.

make[5]: Nothing to be done for 'install-data-am'.

make[5]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth/negotiate'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth/negotiate'

Making install in ntlm

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth/ntlm'

make[5]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth/ntlm'

make[5]: Nothing to be done for 'install-exec-am'.

make[5]: Nothing to be done for 'install-data-am'.

make[5]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth/ntlm'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth/ntlm'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth'

make[5]: Entering directory '/usr/src/squid/squid-3.5.25/src/auth'

make[5]: Nothing to be done for 'install-exec-am'.

make[5]: Nothing to be done for 'install-data-am'.

make[5]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/auth'

Making install in http

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/http'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/http'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/http'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/http'

Making install in ip

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/ip'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/ip'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/ip'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/ip'

Making install in icmp

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/icmp'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/icmp'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../../libtool   --mode=install /usr/bin/install -c pinger '/lib/squid3'

libtool: install: /usr/bin/install -c pinger /lib/squid3/pinger

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/icmp'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/icmp'

Making install in ident

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/ident'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/ident'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/ident'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/ident'

Making install in log

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/log'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/log'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/log'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/log'

Making install in ipc

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/ipc'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/ipc'

make[4]: Nothing to be done for 'install-exec-am'.

/bin/bash /usr/src/squid/squid-3.5.25/cfgaux/install-sh -d /var/run/squid;

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/ipc'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/ipc'

Making install in mgr

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/mgr'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/mgr'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/mgr'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/mgr'

Making install in snmp

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/snmp'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/snmp'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/snmp'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/snmp'

Making install in adaptation

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/adaptation'

Making install in icap

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/adaptation/icap'

make[5]: Entering directory '/usr/src/squid/squid-3.5.25/src/adaptation/icap'

make[5]: Nothing to be done for 'install-exec-am'.

make[5]: Nothing to be done for 'install-data-am'.

make[5]: Leaving directory '/usr/src/squid/squid-3.5.25/src/adaptation/icap'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/adaptation/icap'

Making install in ecap

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/adaptation/ecap'

make[5]: Entering directory '/usr/src/squid/squid-3.5.25/src/adaptation/ecap'

make[5]: Nothing to be done for 'install-exec-am'.

make[5]: Nothing to be done for 'install-data-am'.

make[5]: Leaving directory '/usr/src/squid/squid-3.5.25/src/adaptation/ecap'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/adaptation/ecap'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/adaptation'

make[5]: Entering directory '/usr/src/squid/squid-3.5.25/src/adaptation'

make[5]: Nothing to be done for 'install-exec-am'.

make[5]: Nothing to be done for 'install-data-am'.

make[5]: Leaving directory '/usr/src/squid/squid-3.5.25/src/adaptation'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/adaptation'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/adaptation'

Making install in esi

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src/esi'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src/esi'

make[4]: Nothing to be done for 'install-exec-am'.

make[4]: Nothing to be done for 'install-data-am'.

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src/esi'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src/esi'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/src'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/src'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../libtool   --mode=install /usr/bin/install -c DiskIO/DiskDaemon/diskd unlinkd '/lib/squid3'

libtool: install: /usr/bin/install -c DiskIO/DiskDaemon/diskd /lib/squid3/diskd

libtool: install: /usr/bin/install -c unlinkd /lib/squid3/unlinkd

/bin/mkdir -p '/usr/sbin'

  /bin/bash ../libtool   --mode=install /usr/bin/install -c squid '/usr/sbin'

libtool: install: /usr/bin/install -c squid /usr/sbin/squid

/bin/mkdir -p '/etc/squid3'

/usr/bin/install -c -m 644 squid.conf.default squid.conf.documented mime.conf.default '/etc/squid3'

/bin/mkdir -p '/usr/share/squid3'

/usr/bin/install -c -m 644 mib.txt '/usr/share/squid3'

install-data-local will not overwrite existing /etc/squid3/mime.conf

install-data-local will not overwrite existing /etc/squid3/squid.conf

echo "/usr/bin/install -c -m 644 squid.conf.default /etc/squid3/squid.conf.default"; \

/usr/bin/install -c -m 644 squid.conf.default /etc/squid3/squid.conf.default; \

echo "/usr/bin/install -c -m 644 squid.conf.documented /etc/squid3/squid.conf.documented"; \

/usr/bin/install -c -m 644 squid.conf.documented /etc/squid3/squid.conf.documented; \

/bin/bash /usr/src/squid/squid-3.5.25/cfgaux/install-sh -d /var/log/squid3; \

/bin/bash /usr/src/squid/squid-3.5.25/cfgaux/install-sh -d /var/spool/squid3; \

/bin/bash /usr/src/squid/squid-3.5.25/cfgaux/install-sh -d `dirname /var/run/squid3.pid`

/usr/bin/install -c -m 644 squid.conf.default /etc/squid3/squid.conf.default

/usr/bin/install -c -m 644 squid.conf.documented /etc/squid3/squid.conf.documented

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 squid.8 '/usr/share/man/man8'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/src'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/src'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/src'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/src'

Making install in tools

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/tools'

Making install in purge

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/tools/purge'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/tools/purge'

/bin/mkdir -p '/usr/bin'

  /bin/bash ../../libtool   --mode=install /usr/bin/install -c purge '/usr/bin'

libtool: install: /usr/bin/install -c purge /usr/bin/purge

make[3]: Nothing to be done for 'install-data-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/tools/purge'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/tools/purge'

Making install in squidclient

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/tools/squidclient'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/tools/squidclient'

make[4]: Entering directory '/usr/src/squid/squid-3.5.25/tools/squidclient'

/bin/mkdir -p '/usr/bin'

  /bin/bash ../../libtool   --mode=install /usr/bin/install -c squidclient '/usr/bin'

libtool: install: /usr/bin/install -c squidclient /usr/bin/squidclient

/bin/mkdir -p '/usr/share/man/man1'

/usr/bin/install -c -m 644 squidclient.1 '/usr/share/man/man1'

make[4]: Leaving directory '/usr/src/squid/squid-3.5.25/tools/squidclient'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/tools/squidclient'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/tools/squidclient'

Making install in systemd

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/tools/systemd'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/tools/systemd'

make[3]: Nothing to be done for 'install-exec-am'.

make[3]: Nothing to be done for 'install-data-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/tools/systemd'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/tools/systemd'

Making install in sysvinit

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/tools/sysvinit'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/tools/sysvinit'

make[3]: Nothing to be done for 'install-exec-am'.

make[3]: Nothing to be done for 'install-data-am'.

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/tools/sysvinit'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/tools/sysvinit'

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/tools'

make[3]: Entering directory '/usr/src/squid/squid-3.5.25/tools'

/bin/mkdir -p '/lib/squid3'

  /bin/bash ../libtool   --mode=install /usr/bin/install -c cachemgr.cgi '/lib/squid3'

libtool: install: /usr/bin/install -c cachemgr.cgi /lib/squid3/cachemgr.cgi

/bin/mkdir -p '/lib/squid3'

/usr/bin/install -c helper-mux.pl '/lib/squid3'

/usr/bin/install -c -m 644 ./cachemgr.conf /etc/squid3/cachemgr.conf.default

install-data-local will not overwrite existing /etc/squid3/cachemgr.conf

/bin/mkdir -p '/usr/share/man/man8'

/usr/bin/install -c -m 644 cachemgr.cgi.8 '/usr/share/man/man8'

make[3]: Leaving directory '/usr/src/squid/squid-3.5.25/tools'

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/tools'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/tools'

Making install in test-suite

make[1]: Entering directory '/usr/src/squid/squid-3.5.25/test-suite'

make[2]: Entering directory '/usr/src/squid/squid-3.5.25/test-suite'

make[2]: Nothing to be done for 'install-exec-am'.

make[2]: Nothing to be done for 'install-data-am'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25/test-suite'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25/test-suite'

make[1]: Entering directory '/usr/src/squid/squid-3.5.25'

make[2]: Entering directory '/usr/src/squid/squid-3.5.25'

make[2]: Nothing to be done for 'install-exec-am'.

make[2]: Nothing to be done for 'install-data-am'.

make[2]: Leaving directory '/usr/src/squid/squid-3.5.25'

make[1]: Leaving directory '/usr/src/squid/squid-3.5.25'



oliver at lennox-it.uk

lennox-it.uk

tel: 07900 648 252




________________________________

From: Antony Stone <Antony.Stone at squid.open.source.it>

To: "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 

Sent: Friday, 14 April 2017, 12:58

Subject: Re: [squid-users] HTTPS woes




On Friday 14 April 2017 at 13:52:08, Olly Lennox wrote:


> I've tried building it and it seems to have make install -ed correctly but

> I'm getting "command not found" when I try to execute squid3.


Well, what command are you trying to run (the one which is "not found")?


And what do you from "whereis squid"?


If that second command shows nothing, what do you get from:

"find / -type f -name squid"?



Antony.


>       From: Rafael Akchurin <rafael.akchurin at diladele.com>

>  To: "squid-users at lists.squid-cache.org"

> <squid-users at lists.squid-cache.org> Sent: Friday, 14 April 2017, 12:40

>  Subject: Re: [squid-users] HTTPS woes

> 

> >>> Then my config in Squid is like this, the dhparams file I generated as per 

instructions in the squid wiki:

> >> First of all: what's Squid's version?

> > 

> > And secondly; are you sufficiently capable with Debian to (cross-)build

> > your own Squid package that can run on Raspian? The Debian squid/squid3

> > packages do not have TLS/SSL/HTTPS support. So you will be building your

> > own to get the bumping features.

> 

> When you decide to recompile on Raspbian, please be sure to take a look at

> https://docs.diladele.com/administrator_guide_5_0/install/rpi/squid.html -

> it describes one way of doing this  *on* RPI (without cross compiling).

> But it is slooowwww. _______________________________________________

> squid-users mailing list

> squid-users at lists.squid-cache.org

> http://lists.squid-cache.org/listinfo/squid-users


-- 

"I think both KDE and Gnome suck - I'm quite unbiased in that, because I use a 

Mac."


- Jason Isitt


                                                   Please reply to the list;

                                                         please *don't* CC me.


_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org

http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Fri Apr 14 12:22:48 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 15 Apr 2017 00:22:48 +1200
Subject: [squid-users] [squid-dev] [RFC] Changes to http_access defaults
In-Reply-To: <934bffcd-b53b-bf39-8b44-89672d76bdb3@gmail.com>
References: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>
 <9c01ab9e-6f7f-2e82-b3e2-9e1220c26d30@measurement-factory.com>
 <20170413111414.Horde.xLtNThbtK50MUyRLMNz-uWn@192.168.10.20>
 <934bffcd-b53b-bf39-8b44-89672d76bdb3@gmail.com>
Message-ID: <b75c27f2-bdb1-6131-d104-eb8bef2c9c3d@treenet.co.nz>

On 14/04/2017 3:58 a.m., Yuri Voinov wrote:
> 
> 
> 13.04.2017 21:14, Dan Purgert ?????:
>> Quoting Alex Rousskov <rousskov at measurement-factory.com>:
>>
>>> On 04/12/2017 12:16 PM, Amos Jeffries wrote:
>>>
>>>> Changes to http_access defaults
>>>
>>> Clearly stating what you are trying to accomplish with these changes may
>>> help others evaluate your proposal. Your initial email focuses on _how_
>>> you are going to accomplish some implied/vague goal. What is the goal
>>> here?
>>>
>>>
>>>> I have become convinced that Squid always checks those
>>>> security rules, then do the custom access rules. All other orderings
>>>> seem to have turned out to be problematic and security-buggy in some
>>>> edge cases or another.
>>>
>>> s/Squid always checks/Squid should always check/
>>>
>>>
>>>> What are peoples opinions about making the following items built-in
>>>> defaults?
>>>>
>>>>  acl Safe_ports port 21 80 443
>>>>  acl CONNECT_ports port 443
>>>>  acl CONNECT method CONNECT
>>>>
>>>>  http_acces deny !Safe_ports
>>>>  http_access deny CONNECT !CONNECT_ports
>>>
>>>> The above change will have some effect on installations that try to use
>>>> an empty squid.conf.
>>>
>>> And on many other existing installations, of course, especially on those
>>> with complex access rules which are usually the most difficult to
>>> modify/adjust. In other words, this is a pretty serious change.
>>>
>>>
>>
>> How would a "built-in default" alter an existing setup? I mean, in
>> every other instance that I can think of, if the config file includes
>> the directive, the config file's version overrides the default ...
> This is normal behaviour. System administrator should have possibility
> to override ANY default.

Yes, and override remains possible. Just in a way that does not involve
deleting lines from squid.conf.

To override the propsed default you *add* ports to the Safe_ports and
CONNECT_ports (ala SSL_Ports) lines to make them no longer be denied.

For example;

 today to make Squid an open proxy you _erase_ these lines:

  http_access deny !Safe_ports
  http_access deny CONNECT !SSL_ports

Alternatively you can also *add* these lines:

 acl Safe_ports port 0-65535
 acl SSL_Ports port 0-65535

That second way will work both before and after the proposed change.
(Module the proposed rename of SSL_ports to CONNECT_ports). This makes
it a little but harder for newbies or naive people to get themselves
into trouble, without removing ability for advanced needs.


As Alex pointed out it does mean change for anyone with those advanced
configs. So it is a matter of whether the pain is too great or there is
a better way. Thus 'RFC' to everyone.

Amos



From oliver at lennox-it.uk  Fri Apr 14 13:06:36 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Fri, 14 Apr 2017 13:06:36 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
Message-ID: <1123675527.318473.1492175196442@mail.yahoo.com>

Thanks Rafael,
I'm trying this out now, have had to enable the stretch repos but seems to be building!?oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252

      From: Rafael Akchurin <rafael.akchurin at diladele.com>
 To: "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Friday, 14 April 2017, 12:40
 Subject: Re: [squid-users] HTTPS woes
   
>>> Then my config in Squid is like this, the dhparams file I generated as per instructions in the squid wiki:
>> First of all: what's Squid's version?

> And secondly; are you sufficiently capable with Debian to (cross-)build your own Squid package that can run on Raspian?
> The Debian squid/squid3 packages do not have TLS/SSL/HTTPS support. So you will be building your own to get the bumping features.

When you decide to recompile on Raspbian, please be sure to take a look at https://docs.diladele.com/administrator_guide_5_0/install/rpi/squid.html - it describes one way of doing this? *on* RPI (without cross compiling). But it is slooowwww.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170414/6fd7b351/attachment.htm>

From squid3 at treenet.co.nz  Fri Apr 14 13:15:38 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 15 Apr 2017 01:15:38 +1200
Subject: [squid-users] [squid-dev] [RFC] Changes to http_access defaults
In-Reply-To: <9c01ab9e-6f7f-2e82-b3e2-9e1220c26d30@measurement-factory.com>
References: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>
 <9c01ab9e-6f7f-2e82-b3e2-9e1220c26d30@measurement-factory.com>
Message-ID: <b5848e92-cce4-83c8-ef86-9b0811833ee9@treenet.co.nz>

On 13/04/2017 1:15 p.m., Alex Rousskov wrote:
> On 04/12/2017 12:16 PM, Amos Jeffries wrote:
> 
>> Changes to http_access defaults
> 
> Clearly stating what you are trying to accomplish with these changes may
> help others evaluate your proposal. Your initial email focuses on _how_
> you are going to accomplish some implied/vague goal. What is the goal here?
> 

I've have two goals here:

1) reduce peoples ability to shoot themselves in the foot.

 This is an ongoing problem with newbies and even with more experienced
naive people.
 But there are some few cases where foot shooting is the local sport and
we have to let it happen.


2) further reduce the things people are required to manually configure
in squid.conf to get a usable Squid.

Telling people where to put their custom rules in relation to these
settings is getting to be a rather monotonous problem.

ALso, sometimes it is not easy to find the right words to describe the
location when language/knowledge barriers or previous screwing up of
squid.conf contents gets in the way.


I have the idea that we can do this porposal or something equivalent to
get rid of these problems with a technical fix for the long-term.

> 
>> I have become convinced that Squid always checks those
>> security rules, then do the custom access rules. All other orderings
>> seem to have turned out to be problematic and security-buggy in some
>> edge cases or another.
> 
> s/Squid always checks/Squid should always check/
> 

Oops. Yes. Thank you for that.

> 
>> What are peoples opinions about making the following items built-in
>> defaults?
>>
>>  acl Safe_ports port 21 80 443
>>  acl CONNECT_ports port 443
>>  acl CONNECT method CONNECT
>>
>>  http_acces deny !Safe_ports
>>  http_access deny CONNECT !CONNECT_ports
> 
>> The above change will have some effect on installations that try to use
>> an empty squid.conf.
> 
> And on many other existing installations, of course, especially on those
> with complex access rules which are usually the most difficult to
> modify/adjust. In other words, this is a pretty serious change.
> 
> 
>> If the proposal goes ahead some extra additions
>> would be included to retain that default-reject behaviour.
> 
> It is difficult to properly evaluate your proposal until it details how
> one would be able to override the proposed defaults.

Okay. As I mentioned to yuri's post:

 acl Safe_ports port 0-65535
 acl CONNECT_ports port 0-65535


NP: s/CONNECT_pors/SSL_ports/ depending on whether the name change there
happens or not. I had initially the idea that detecting the SSL_ports
existence as a way to determine between old and new configs. Similar to
the deny_unsafe_ports approach you propose below.


> These defaults, in
> some shape or form, make sense for most installations, of course. The
> difficult parts are:
> 
> * minimizing surprises (e.g, when the hidden defaults change, are wrong,
> and/or interact with deny_info rules in surprising ways);
> 
> * avoiding configurations that compute essentially the same rules
> multiple times (hidden defaults + explicit defaults); and
> 
> * designing a configuration approach to overwrite defaults without
> either screwing up a lot of admins or virtually eliminating the positive
> effect of those defaults in new configurations.
> 
> 
> To address the last bullet, we could add a
> 
>   deny_unsafe_ports <on|off>
> 
> directive.
> 
> If that directive is "on" by default [for any squid.conf that does not
> define a Safe_ports ACL??], then it does not address the first two
> bullets well.
> 
> Perhaps it should be off by default but explicitly added (and turned
> "on") to every newly generated squid.conf.default?
> 

If it is on by default unless we have reason to turn it off, we have
trouble with all the intentional open-proxy or similar configs.

If it is off by default unless we have reason to turn it on. That does
not help at all for newbie admin installs which most need it to be on by
default.


With Safe_ports being a default too, the detect would have to be based
on SSL_ports. In which case, we may as well use an internal boolean
check for SSL_ports as the detection of old installation instead of
putting anything confusing in front of newbie admin.
 - this will also catch the case of newbie cut-n-pasting old configs.

However, that still leaves us with trouble for all the intentional
open-proxy or similar configs. They will still have surprise blocking of
unsafe traffic until config gets adjusted.

> 
> Also, how will the http_access rules in newly generated
> squid.conf.default look like if we add default http_access rules?
> 

I expect it would look like it does now but without the top two deny rules:

  http_access allow localhost manager
  http_access deny manager

  #
  # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
  #

  http_access allow localnet
  http_access allow localhost
  http_access deny all


> 
> I am worried that adding hidden default http_access rules will make
> things overall worse rather than solving the problem you are trying to
> solve. I wonder if fiddling with http_access internals might be the
> wrong direction here.
> 
> 
> Thank you,
> 
> Alex.
> 

Noted. Thank you for the feedback.

Amos




From mohammedjk89 at gmail.com  Fri Apr 14 13:17:11 2017
From: mohammedjk89 at gmail.com (Mohammed al-jakry)
Date: Fri, 14 Apr 2017 16:17:11 +0300
Subject: [squid-users] Squid proxy with ssl-bump - unrecognized: 'ssl-bump'
	error
Message-ID: <58f0cbd8.27a9df0a.ae13.c77b@mx.google.com>




Dears, 

Thanks for adding me to the list?


I would like to install squid proxy with SSL bump, I am working on my Virtual lab and once everything is ok I will Test it on the real network. I already created I directory for the cert and generated the cert as below:
#Generate Private Key
openssl genrsa -out MSY.com.private 2048  

# Create Certificate Signing Request
openssl req -new -key MSY.com.private -out MSY.com.csr

# Sign Certificate
openssl x509 -req -days 3652 -in MSY.com.csr -signkey MSY.com.private -out 
MSY.com.cert
# Generate certificate cache
/usr/lib64/squid/ssl_crtd -c -s /var/lib/ssl_db
# Change ownership of the certificate cache
chown squid: /var/lib/ssl_db
then I fill the info and put the 'Common Name' something other than the domain or server_name. in addition, please find the below lines from the squid configuration file:
# Squid listen Port
http_port 3128  
ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB key=/etc/squid/MSY.com.private cert=/etc/squid/MSY.com.cert  
# SSL Bump Config
always_direct allow all  
ssl_bump server-first all  
sslproxy_cert_error deny all  
sslproxy_flags DONT_VERIFY_PEER  
sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB sslcrtd_children 8 startup=1 idle=1 
and it?s not working with SSL bump configuration, it work only when I remove the ssl bump configuration but for sure without ssl certificate.
also i check the?journalctl -xe?and found the below error:
/etc/squid/squid.conf:3 unrecognized: 'ssl-bump'
any ideas ?


Regards
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170414/0908918c/attachment.htm>

From squid3 at treenet.co.nz  Fri Apr 14 13:18:00 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 15 Apr 2017 01:18:00 +1200
Subject: [squid-users] HTTPS woes
In-Reply-To: <820496486.320844.1492172141961@mail.yahoo.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <123378366.262123.1492170728064@mail.yahoo.com>
 <201704141358.14704.Antony.Stone@squid.open.source.it>
 <1678068035.308198.1492171790343@mail.yahoo.com>
 <820496486.320844.1492172141961@mail.yahoo.com>
Message-ID: <34e7310a-07e4-fd8e-e42a-4ec1c96facca@treenet.co.nz>

On 15/04/2017 12:15 a.m., Olly Lennox wrote:
> libtool: install: /usr/bin/install -c squid /usr/sbin/squid


So, like I said the binary name is just "squid", not 'squid3'

Amos



From serhatkoroglu at outlook.com  Fri Apr 14 13:25:58 2017
From: serhatkoroglu at outlook.com (Serhat Koroglu)
Date: Fri, 14 Apr 2017 13:25:58 +0000
Subject: [squid-users] Multiple http_access Logic At the same time
Message-ID: <DB6PR0502MB3045AF938F0EEBA77385F207B4050@DB6PR0502MB3045.eurprd05.prod.outlook.com>

Hello,

I'm trying to manage squid users to access the proxy if they logged in and the site url is allowed in my url list. They are running one by one. If logged in accesses but not check the url and vice versa. But I want both of them. Here is my config part.


auth_param basic program /usr/bin/php /var/www/html/sqauth.php
auth_param basic children 20
auth_param basic realm Username and password
auth_param basic credentialsttl 5 hours

acl AuthenticatedUsers proxy_auth REQUIRED

acl allowed_sites dstdomain "/etc/squid/allowedsites.txt"
acl all_others dst 0.0.0.0/0.0.0.0

http_access allow allowed_sites
http_access deny all_others
http_access allow AuthenticatedUsers


Thank you,
Serhat
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170414/437aeb51/attachment.htm>

From serhatkoroglu at outlook.com  Fri Apr 14 13:30:27 2017
From: serhatkoroglu at outlook.com (Serhat Koroglu)
Date: Fri, 14 Apr 2017 13:30:27 +0000
Subject: [squid-users] Multiple http_access logic at the same time
In-Reply-To: <DB6PR0502MB3045AF938F0EEBA77385F207B4050@DB6PR0502MB3045.eurprd05.prod.outlook.com>
References: <DB6PR0502MB3045AF938F0EEBA77385F207B4050@DB6PR0502MB3045.eurprd05.prod.outlook.com>
Message-ID: <DB6PR0502MB3045C01E3386A0EF78D16809B4050@DB6PR0502MB3045.eurprd05.prod.outlook.com>

Hello,

I'm trying to manage squid users to access the proxy if they logged in and the site url is allowed in my url list. They are running one by one. If logged in accesses but not check the url and vice versa. But I want both of them. Here is my config part.


auth_param basic program /usr/bin/php /var/www/html/sqauth.php
auth_param basic children 20
auth_param basic realm Username and password
auth_param basic credentialsttl 5 hours

acl AuthenticatedUsers proxy_auth REQUIRED

acl allowed_sites dstdomain "/etc/squid/allowedsites.txt"
acl all_others dst 0.0.0.0/0.0.0.0

http_access allow allowed_sites
http_access deny all_others
http_access allow AuthenticatedUsers


Thank you,
Serhat
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170414/d62890db/attachment.htm>

From squid3 at treenet.co.nz  Fri Apr 14 13:32:43 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 15 Apr 2017 01:32:43 +1200
Subject: [squid-users] Squid proxy with ssl-bump - unrecognized:
 'ssl-bump' error
In-Reply-To: <58f0cbd8.27a9df0a.ae13.c77b@mx.google.com>
References: <58f0cbd8.27a9df0a.ae13.c77b@mx.google.com>
Message-ID: <9fc0edda-d810-e7c2-0994-a59b836fdf14@treenet.co.nz>

On 15/04/2017 1:17 a.m., Mohammed al-jakry wrote:
> 
> 
> 
> Dears, 
> 
> Thanks for adding me to the list?
> 
> 
> I would like to install squid proxy with SSL bump, I am working on my Virtual lab and once everything is ok I will Test it on the real network. I already created I directory for the cert and generated the cert as below:
> #Generate Private Key
> openssl genrsa -out MSY.com.private 2048  
> 
> # Create Certificate Signing Request
> openssl req -new -key MSY.com.private -out MSY.com.csr
> 
> # Sign Certificate
> openssl x509 -req -days 3652 -in MSY.com.csr -signkey MSY.com.private -out 
> MSY.com.cert
> # Generate certificate cache
> /usr/lib64/squid/ssl_crtd -c -s /var/lib/ssl_db
> # Change ownership of the certificate cache
> chown squid: /var/lib/ssl_db
> then I fill the info and put the 'Common Name' something other than the domain or server_name. in addition, please find the below lines from the squid configuration file:
> # Squid listen Port
> http_port 3128  
> ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB key=/etc/squid/MSY.com.private cert=/etc/squid/MSY.com.cert  
> # SSL Bump Config
> always_direct allow all  
> ssl_bump server-first all  

> sslproxy_cert_error deny all  
> sslproxy_flags DONT_VERIFY_PEER  

The above two lines are actively dangerous.


NOTE that "Just for testing" is not a good excuse either. They actively
hide TLS problems, testing will "work fine" and production use of the
same config fail with horrible results - or worse; production "work
perfectly" and the horrible results happening invisibly anyway.

When testing, let Squid tell you about errors. Resolve them in other
ways (ie properly) and then you wont need these setting in production
use either. :-)


> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB sslcrtd_children 8 startup=1 idle=1 
> and it?s not working with SSL bump configuration, it work only when I remove the ssl bump configuration but for sure without ssl certificate.
> also i check the journalctl -xe and found the below error:
> /etc/squid/squid.conf:3 unrecognized: 'ssl-bump'
> any ideas ?

Either the line(s) you mentioned above:

> http_port 3128
> ssl-bump generate-host-certificates=on ...

are actually two lines in your config file instead of an email line
wrapping mistake.

Or, the squid binary being run is not built with OpenSSL support.


Probably the former, but what is the output of the command "squid -v"
anyway ?


Amos


From squid3 at treenet.co.nz  Fri Apr 14 14:06:20 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 15 Apr 2017 02:06:20 +1200
Subject: [squid-users] Multiple http_access Logic At the same time
In-Reply-To: <DB6PR0502MB3045AF938F0EEBA77385F207B4050@DB6PR0502MB3045.eurprd05.prod.outlook.com>
References: <DB6PR0502MB3045AF938F0EEBA77385F207B4050@DB6PR0502MB3045.eurprd05.prod.outlook.com>
Message-ID: <461bf429-7188-6c65-4314-8b5e65c4f250@treenet.co.nz>

On 15/04/2017 1:25 a.m., Serhat Koroglu wrote:
> Hello,
> 
> I'm trying to manage squid users to access the proxy if they logged
> in and the site url is allowed in my url list. They are running one
> by one. If logged in accesses but not check the url and vice versa.
> But I want both of them. Here is my config part.
> 

First some concepts:

You do not have any "url list" in the displayed config settings.

You do have a file that is supposed to contain *only* domain names.
Those may have wildcard sub-domains in dstdomain format (domin name
started with a '.'), but URLs and other things are not valid in that file.


Also, http_access does not allow/deny "URLs". It can best be described
as allowing or denying *use of the proxy*. Use of the proxy is a very
different concept to 'URL'.

That is very important to get straight in your head since it directly
affects your understanding of what the ACLs do.




> 
> auth_param basic program /usr/bin/php /var/www/html/sqauth.php
> auth_param basic children 20
> auth_param basic realm Username and password
> auth_param basic credentialsttl 5 hours
> 
> acl AuthenticatedUsers proxy_auth REQUIRED
> 
> acl allowed_sites dstdomain "/etc/squid/allowedsites.txt"
> acl all_others dst 0.0.0.0/0.0.0.0

Contrary to what you may think the above "all_others" ACL does not deny
access to everywhere.

It is a bad way to configure:

  acl all_others dst ipv4


Also be aware that it can only match IPv4 addresses. So any IPv6-only
domain will happily skip past your denial rule. This has nothing to do
with whether your client or your local network is IPv4-only. It depends
solely on the DNS listed IPs of the destination domain, clients
requesting IPv6-only domains will be allowed to use your proxy.

Use the provided/built-in ACL called "all" when you want to match
everything.


> 
> http_access allow allowed_sites
> http_access deny all_others
> http_access allow AuthenticatedUsers
> 

When you fix the "deny all_others" stuff so it working as you appear to
intend. Your authentication will "break".

Please read
<http://wiki.squid-cache.org/SquidFaq/SquidAcl#Common_Mistakes> for why,
and that should also teach you how to solve your described problem.

Amos



From squid3 at treenet.co.nz  Fri Apr 14 14:08:31 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 15 Apr 2017 02:08:31 +1200
Subject: [squid-users] [RFC] Changes to http_access defaults
In-Reply-To: <e46d4371-ccb9-c2e3-f9bc-8a4b179c4c2a@measurement-factory.com>
References: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>
 <9c01ab9e-6f7f-2e82-b3e2-9e1220c26d30@measurement-factory.com>
 <20170413111414.Horde.xLtNThbtK50MUyRLMNz-uWn@192.168.10.20>
 <934bffcd-b53b-bf39-8b44-89672d76bdb3@gmail.com>
 <09a5855c-39bc-f5d5-bec7-899ba2c58158@measurement-factory.com>
 <e46d4371-ccb9-c2e3-f9bc-8a4b179c4c2a@measurement-factory.com>
Message-ID: <96b3188b-c50a-6ffd-817b-92fc663b82ca@treenet.co.nz>

On 14/04/2017 4:52 a.m., Alex Rousskov wrote:
> On 04/13/2017 10:39 AM, Alex Rousskov wrote:
> 
>> The "many folks misconfigure access rules" problem may not have a
>> good solution (under Squid control); we should be careful not to make
>> things worse while not solving the unsolvable problem.
> 
> 
> Here is an alternative idea: Instead of adding default http_access rules
> inside Squid, add an optional squid.conf lint/checker.

We have a lint checker in "-k parse" and "-k check" anyway. That is not
going away and these kind of checks are a good idea regardless of what
the built-in default config is.

So that is not an exclusive alternative. It is something we will need to
do along with (or before) the config changes.


> For many
> configurations, especially the simple ones used by new Squid admins, it
> is fairly easy to _automatically_ check whether these default rules are
> violated.
> 
> If these rules are violated, Squid will log a startup warning like this:
> 
>   WARNING: Your http_access rules allow CONNECT to unsafe port XXX.
>   More info at http://...?warning=xyz&port=XXX.
> 
> The URL will detail the dangers and also explain how to disable this
> specific warning or linting as a whole.
> 
> I can discuss/detail this further if there is consensus that automated
> checking is overall better than built-in http_access defaults.
> Unfortunately, I do not have the time to volunteer an implementation.
> 
> 
> HTH,
> 
> Alex.
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From rousskov at measurement-factory.com  Fri Apr 14 14:38:35 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 14 Apr 2017 08:38:35 -0600
Subject: [squid-users] [RFC] Changes to http_access defaults
In-Reply-To: <1492165148895-4682087.post@n4.nabble.com>
References: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>
 <9c01ab9e-6f7f-2e82-b3e2-9e1220c26d30@measurement-factory.com>
 <20170413111414.Horde.xLtNThbtK50MUyRLMNz-uWn@192.168.10.20>
 <934bffcd-b53b-bf39-8b44-89672d76bdb3@gmail.com>
 <09a5855c-39bc-f5d5-bec7-899ba2c58158@measurement-factory.com>
 <e46d4371-ccb9-c2e3-f9bc-8a4b179c4c2a@measurement-factory.com>
 <1492165148895-4682087.post@n4.nabble.com>
Message-ID: <eac3ba8a-dd84-a89b-e43e-9fcf5bedc0c4@measurement-factory.com>

On 04/14/2017 04:19 AM, joseph wrote:

> System administrator should have possibility to override ANY default.

I do not know why you are saying the above. AFAIK, everybody is in
agreement that admins should be able to overwrite any defaults, at least
at the level of the configured Squid functionality.

Folks may object to hidden http_access rules that admins can configure
to do nothing (i.e., have no effect on Squid functionality) but cannot
_remove_, but I do not think you are talking about that aspect. I
certainly was not.

Alex.



From uhlar at fantomas.sk  Fri Apr 14 15:22:31 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Fri, 14 Apr 2017 17:22:31 +0200
Subject: [squid-users] [RFC] Changes to http_access defaults
In-Reply-To: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>
References: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>
Message-ID: <20170414152231.GA18364@fantomas.sk>

On 13.04.17 06:16, Amos Jeffries wrote:
>What are peoples opinions about making the following items built-in
>defaults?
>
> acl Safe_ports port 21 80 443
> acl CONNECT_ports port 443
> acl CONNECT method CONNECT

shouldn't that be more like following?

acl Safe_ports port 80
acl CONNECT_ports port 21 443

> http_acces deny !Safe_ports
> http_access deny CONNECT !CONNECT_ports



-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
(R)etry, (A)bort, (C)ancer


From rousskov at measurement-factory.com  Fri Apr 14 15:47:57 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 14 Apr 2017 09:47:57 -0600
Subject: [squid-users] [RFC] Changes to http_access defaults
In-Reply-To: <b75c27f2-bdb1-6131-d104-eb8bef2c9c3d@treenet.co.nz>
References: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>
 <9c01ab9e-6f7f-2e82-b3e2-9e1220c26d30@measurement-factory.com>
 <20170413111414.Horde.xLtNThbtK50MUyRLMNz-uWn@192.168.10.20>
 <934bffcd-b53b-bf39-8b44-89672d76bdb3@gmail.com>
 <b75c27f2-bdb1-6131-d104-eb8bef2c9c3d@treenet.co.nz>
Message-ID: <a027e213-30e6-9c95-09c1-b314d3d02a9d@measurement-factory.com>

On 04/14/2017 06:22 AM, Amos Jeffries wrote:

> To override the propsed default you *add* ports to the Safe_ports and
> CONNECT_ports (ala SSL_Ports) lines to make them no longer be denied.

>  acl Safe_ports port 0-65535
>  acl SSL_Ports port 0-65535

Thank you for sharing this important detail! I like this clever design
and agree that this approach allows admins to overwrite the proposed
default behavior/functionality.

This approach carries the following overwriting price:

* For every access, Squid will pointlessly evaluate the following:
  http_access deny !all_ports
  http_access deny CONNECT !all_ports

Is this an acceptable price to pay?

(The evaluation is pointless because the rules never match (because
all_ports always matches). In this context, the admin wants the rules to
never match, so that she can insert her own rules overwriting the
default. So the functionality is correct, but the default rules cannot
be removed and are evaluated.)

We could add a rule optimizer that will detect and remove some
never-matching rules, including the above ones. If the overwriting price
is too high, adding such an optimizer may become a precondition. The
optimizing logic is straightforward, but things like deny_info will
complicate implementation.

All other alternatives proposed so far do not have this performance penalty.


> I've have two goals here:
> 
> 1) reduce peoples ability to shoot themselves in the foot.
> 2) further reduce the things people are required to manually configure

All three proposed options satisfy #1.

All three proposed options satisfy #2 if "manual configuration" is
defined as editing squid.conf.default. The lint option does not satisfy
#2 if "manual configuration" is defined as editing squid.conf.empty. How
should we define "manual configuration" in this context so that we can
compare options using a common set of criteria?


> I expect [squid.conf.default to look like this]:

>   http_access allow localhost manager
>   http_access deny manager
> 
>   # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> 
>   http_access allow localnet
>   http_access allow localhost
>   http_access deny all

I think the proposal would be a lot more attractive if it results in
elimination of all of the http_access rules from squid.conf.default. As
it currently stands, the changes imply many headaches, but still do not
solve the "reasonable default access restrictions" problem. In other
words, we are already paying a lot but still gaining little.

What if we raise the bar and declare reaching the "reasonable default
access restrictions" as the goal? Can we solve that problem instead,
with comparable headache severity of the original proposal?

For example, Squid could automatically add something like the following:

  # always added at the top of user-configured http_access rules
  http_access deny usuallyDenied
  http_access allow manager

  # always added at the bottom of user-configured http_access rules
  http_access allow usuallyAllowed
  http_access deny all

And remove all of the http_access rules from squid.conf.default.

The admin will be able to adjust usuallyDenied, usuallyAllowed, and
manager any-of ACLs to effectively disable them (just like in your
proposal). And we can add an optimizer to remove effectively disabled ACLs.


> the proposed rename of SSL_ports to CONNECT_ports

Let's discuss the exact ACL names later (when/if there is a principle
agreement to implement the proposed changes). For now, I will only note
that we should not use ACL names that might clash with those used by
existing configurations (for hopefully obvious reasons).


Thank you,

Alex.



From chip_pop at hotmail.com  Fri Apr 14 21:30:23 2017
From: chip_pop at hotmail.com (joseph)
Date: Fri, 14 Apr 2017 14:30:23 -0700 (PDT)
Subject: [squid-users] skipLeadingSpace
Message-ID: <1492205423044-4682110.post@n4.nabble.com>

is this correct ??

char *
skipLeadingSpace(char *aString)
{
    char *result = aString;

    while (xisspace(*aString))
        ++aString;

    return result;
}



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/skipLeadingSpace-tp4682110.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From oliver at lennox-it.uk  Fri Apr 14 21:59:48 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Fri, 14 Apr 2017 21:59:48 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <1123675527.318473.1492175196442@mail.yahoo.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <1123675527.318473.1492175196442@mail.yahoo.com>
Message-ID: <1759621537.629779.1492207188325@mail.yahoo.com>

Hi Guys.
I'm still struggling with this. I'm trying to build a version of 3.5 but I just can't get it to work. I'm currently attempting to rebuild the stretch package with SSL enabled but build keeps failing with the following:
../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not declared in this scope?typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?^~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:83:61: error: template argument 3 is invalid?typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?^../../src/ssl/gadgets.h:89:53: error: ?CRYPTO_LOCK_EVP_PKEY? was not declared in this scope?typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?^~~~~~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:89:73: error: template argument 3 is invalid?typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?^../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not declared in this scope?typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?^~~~~~~~~~~~~~~../../src/ssl/gadgets.h:116:58: error: template argument 3 is invalid?typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^
Any ideas?
Thanks?oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252

      From: Olly Lennox <oliver at lennox-it.uk>
 To: Rafael Akchurin <rafael.akchurin at diladele.com>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Friday, 14 April 2017, 14:07
 Subject: Re: [squid-users] HTTPS woes
   
Thanks Rafael,
I'm trying this out now, have had to enable the stretch repos but seems to be building!?oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252

      From: Rafael Akchurin <rafael.akchurin at diladele.com>
 To: "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Friday, 14 April 2017, 12:40
 Subject: Re: [squid-users] HTTPS woes
  
>>> Then my config in Squid is like this, the dhparams file I generated as per instructions in the squid wiki:
>> First of all: what's Squid's version?

> And secondly; are you sufficiently capable with Debian to (cross-)build your own Squid package that can run on Raspian?
> The Debian squid/squid3 packages do not have TLS/SSL/HTTPS support. So you will be building your own to get the bumping features.

When you decide to recompile on Raspbian, please be sure to take a look at https://docs.diladele.com/administrator_guide_5_0/install/rpi/squid.html - it describes one way of doing this? *on* RPI (without cross compiling). But it is slooowwww.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   _______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170414/ec5355bd/attachment.htm>

From rousskov at measurement-factory.com  Fri Apr 14 22:27:24 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 14 Apr 2017 16:27:24 -0600
Subject: [squid-users] skipLeadingSpace
In-Reply-To: <1492205423044-4682110.post@n4.nabble.com>
References: <1492205423044-4682110.post@n4.nabble.com>
Message-ID: <ab3f59d4-8fc0-4da4-c35b-7f75ed8c4171@measurement-factory.com>

On 04/14/2017 03:30 PM, joseph wrote:
> is this correct ??
> 
> char *
> skipLeadingSpace(char *aString)
> {
>     char *result = aString;
> 
>     while (xisspace(*aString))
>         ++aString;
> 
>     return result;
> }

No, the above code is incorrect. It does nothing [useful]. The bug was
introduced in r5698 "Client side refactoring - no functionality changes".

Fortunately, this bug has no effect in recent code because this buggy
function is unused. It should be removed.


Thank you,

Alex.
P.S. You should discuss Squid code on squid-dev not squid-users.



From omidkosari at yahoo.com  Sat Apr 15 11:52:25 2017
From: omidkosari at yahoo.com (Omid Kosari)
Date: Sat, 15 Apr 2017 04:52:25 -0700 (PDT)
Subject: [squid-users] Windows Updates a Caching Stub zone,
	A windows updates store.
In-Reply-To: <05ce01d2aef3$1cb537d0$561fa770$@ngtech.co.il>
References: <004a01d1daf3$e6c4a490$b44dedb0$@ngtech.co.il>
 <1491489566256-4682002.post@n4.nabble.com>
 <05ce01d2aef3$1cb537d0$561fa770$@ngtech.co.il>
Message-ID: <1492257145655-4682113.post@n4.nabble.com>

Hello,

I have sent the files you mentioned to your email 2 days ago . 

A little more investigation shows that some big files (~ 2GB ) are
downloading slowly ( ~ 100KBytes/s) while some others downloading very
faster. The problem is related to networking (BGP and IXP ) stuff and the
fetcher script can not solve that .

But is there a way to run more than one fetcher script at the same time to
parallel downloading and not one by one ? There is free bandwidth but
fetcher script takes a long time for some downloads .

Thanks again for you support



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Windows-Updates-a-Caching-Stub-zone-A-windows-updates-store-tp4678454p4682113.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Sat Apr 15 22:04:33 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 16 Apr 2017 10:04:33 +1200
Subject: [squid-users] [RFC] Changes to http_access defaults
In-Reply-To: <20170414152231.GA18364@fantomas.sk>
References: <f4299bf2-bea5-b242-e6a6-91dbd9c96a79@treenet.co.nz>
 <20170414152231.GA18364@fantomas.sk>
Message-ID: <43e83ae5-d531-857f-38d1-41fb0854e84e@treenet.co.nz>

On 15/04/2017 3:22 a.m., Matus UHLAR - fantomas wrote:
> On 13.04.17 06:16, Amos Jeffries wrote:
>> What are peoples opinions about making the following items built-in
>> defaults?
>>
>> acl Safe_ports port 21 80 443
>> acl CONNECT_ports port 443
>> acl CONNECT method CONNECT
> 
> shouldn't that be more like following?
> 
> acl Safe_ports port 80
> acl CONNECT_ports port 21 443
> 
>> http_acces deny !Safe_ports
>> http_access deny CONNECT !CONNECT_ports
> 
> 

No. The !Safe_ports would deny port 21 and 443 usage.

SSL_ports/CONNECT_ports is a sub-set of safe ports whre CONNECT is also
potentially permitted.

Amos




From squid3 at treenet.co.nz  Sat Apr 15 22:07:28 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 16 Apr 2017 10:07:28 +1200
Subject: [squid-users] HTTPS woes
In-Reply-To: <1759621537.629779.1492207188325@mail.yahoo.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <1123675527.318473.1492175196442@mail.yahoo.com>
 <1759621537.629779.1492207188325@mail.yahoo.com>
Message-ID: <d09589e1-9c03-67b6-8ef9-a43538da750c@treenet.co.nz>

On 15/04/2017 9:59 a.m., Olly Lennox wrote:
> Hi Guys.
> I'm still struggling with this. I'm trying to build a version of 3.5 but I just can't get it to work. I'm currently attempting to rebuild the stretch package with SSL enabled but build keeps failing with the following:
> ../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not declared in this scope typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;                                             ^~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:83:61: error: template argument 3 is invalid typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;                                                             ^../../src/ssl/gadgets.h:89:53: error: ?CRYPTO_LOCK_EVP_PKEY? was not declared in this scope typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;                                                     ^~~~~~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:89:73: error: template argument 3 is invalid typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;                                                                         ^../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not declared in this scope typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;                                           ^~~~~~~~~~~~~~~../../src/ssl/gadgets.h:116:58: error: template argument 3 is invalid typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;                                                          ^
> Any ideas?



On Jesse/stable:

 apt-get build-dep squid3
 apt-get install libss-dev


On stretch/testing/unstable:

 apt-get build-dep squid
 apt-get install libss1.0-dev


That should do it for you.

Amos


From oliver at lennox-it.uk  Sun Apr 16 08:30:46 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Sun, 16 Apr 2017 08:30:46 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <d09589e1-9c03-67b6-8ef9-a43538da750c@treenet.co.nz>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <1123675527.318473.1492175196442@mail.yahoo.com>
 <1759621537.629779.1492207188325@mail.yahoo.com>
 <d09589e1-9c03-67b6-8ef9-a43538da750c@treenet.co.nz>
Message-ID: <394541827.1187028.1492331446922@mail.yahoo.com>

Thanks Amos, it's finally built but I had to disabled ecap, for whatever reason this kept failing (with version 1.0.1 installed). It failed on a reference to the Area function I think but I don't have the error message copied. I'm trying now to configure the ssl stare/peek and will let you know how it goes.
Olly?oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252

      From: Amos Jeffries <squid3 at treenet.co.nz>
 To: squid-users at lists.squid-cache.org 
 Sent: Saturday, 15 April 2017, 23:07
 Subject: Re: [squid-users] HTTPS woes
   
On 15/04/2017 9:59 a.m., Olly Lennox wrote:
> Hi Guys.
> I'm still struggling with this. I'm trying to build a version of 3.5 but I just can't get it to work. I'm currently attempting to rebuild the stretch package with SSL enabled but build keeps failing with the following:
> ../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not declared in this scope typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:83:61: error: template argument 3 is invalid typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^../../src/ssl/gadgets.h:89:53: error: ?CRYPTO_LOCK_EVP_PKEY? was not declared in this scope typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^~~~~~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:89:73: error: template argument 3 is invalid typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not declared in this scope typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^~~~~~~~~~~~~~~../../src/ssl/gadgets.h:116:58: error: template argument 3 is invalid typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^
> Any ideas?



On Jesse/stable:

 apt-get build-dep squid3
 apt-get install libss-dev


On stretch/testing/unstable:

 apt-get build-dep squid
 apt-get install libss1.0-dev


That should do it for you.

Amos

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170416/c2d5ec6e/attachment.htm>

From mohammedjk89 at gmail.com  Sun Apr 16 13:47:03 2017
From: mohammedjk89 at gmail.com (Mohammed al-jakry)
Date: Sun, 16 Apr 2017 16:47:03 +0300
Subject: [squid-users] Squid SSL-bump - Not working - No errors
Message-ID: <CADHjJ6+AaaTg-WXaB99a_-WBQMPayG91Rs4F8H0Bcq-wx5JGbA@mail.gmail.com>

Dears,



I am setting the SSL-bump for squid 3.5 on CentOS 7, I already generated
ssl certificate with the below commands:



*OPENSSL=/usr/bin/openssl*

*SSLDIR=/etc/mydlp/ssl*

*mkdir -p $SSLDIR || exit 1*

*rm -rf $SSLDIR/**

*[ -e $SSLDIR/private.pem ] || $OPENSSL genrsa 4096 > $SSLDIR/private.pem*

*[ -e $SSLDIR/public.pem ] || (echo -e
"TR\nAnkara\nTechnopolis\nMyDLP\nMyDLP\n*\nsupport at mydlp.com
<nsupport at mydlp.com>\n"| $OPENSSL req -new -x509 -days 3650 -key
$SSLDIR/private.pem -out $SSLDIR/public.pem)*

*[ -e $SSLDIR/user.der ] || $OPENSSL x509 -in $SSLDIR/public.pem -outform
DER -out $SSLDIR/user.der*



In addition, below you can find snippet from squid.conf file:



http_port 3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB key=/etc/mydlp/ssl/private.pem
cert=/etc/mydlp/ssl/public.pem

always_direct allow all
ssl_bump allow all
sslproxy_cert_error allow all
# Or may be deny all according to your company policy
# sslproxy_cert_error deny all
sslproxy_flags DONT_VERIFY_PEER
sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
sslcrtd_children 5



In addition, I added user.der file in the certificate authority for the
user machine. The problem that it?s not working. Moreover, Squid service
restart without any issues. Also, please find the attached result for the
squid configuration test.



Appreciate your assistant.



Mohammed M AlJakri
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170416/8243f6f3/attachment.htm>
-------------- next part --------------
[root at localhost ]# squid -k parse
2017/04/17 05:15:29| Startup: Initializing Authentication Schemes ...
2017/04/17 05:15:29| Startup: Initialized Authentication Scheme 'basic'
2017/04/17 05:15:29| Startup: Initialized Authentication Scheme 'digest'
2017/04/17 05:15:29| Startup: Initialized Authentication Scheme 'negotiate'
2017/04/17 05:15:29| Startup: Initialized Authentication Scheme 'ntlm'
2017/04/17 05:15:29| Startup: Initialized Authentication.
2017/04/17 05:15:29| Processing Configuration File: /etc/squid/squid.conf (depth 0)
2017/04/17 05:15:29| Processing: acl localnet src 192.168.10.0/24       # RFC1918 possible internal network
2017/04/17 05:15:29| Processing: acl localnet src 172.16.0.0/12 # RFC1918 possible internal network
2017/04/17 05:15:29| Processing: acl localnet src 192.168.1.0/24        # RFC1918 possible internal network
2017/04/17 05:15:29| Processing: acl localnet src fc00::/7       # RFC 4193 local private network range
2017/04/17 05:15:29| Processing: acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
2017/04/17 05:15:29| Processing: acl SSL_ports port 443
2017/04/17 05:15:29| Processing: acl Safe_ports port 80         # http
2017/04/17 05:15:29| Processing: acl Safe_ports port 21         # ftp
2017/04/17 05:15:29| Processing: acl Safe_ports port 443                # https
2017/04/17 05:15:29| Processing: acl Safe_ports port 70         # gopher
2017/04/17 05:15:29| Processing: acl Safe_ports port 210                # wais
2017/04/17 05:15:29| Processing: acl Safe_ports port 1025-65535 # unregistered ports
2017/04/17 05:15:29| Processing: acl Safe_ports port 280                # http-mgmt
2017/04/17 05:15:29| Processing: acl Safe_ports port 488                # gss-http
2017/04/17 05:15:29| Processing: acl Safe_ports port 591                # filemaker
2017/04/17 05:15:29| Processing: acl Safe_ports port 777                # multiling http
2017/04/17 05:15:29| Processing: acl CONNECT method CONNECT
2017/04/17 05:15:29| Processing: http_access deny !Safe_ports
2017/04/17 05:15:29| Processing: http_access deny CONNECT !SSL_ports
2017/04/17 05:15:29| Processing: http_access allow localhost manager
2017/04/17 05:15:29| Processing: http_access deny manager
2017/04/17 05:15:29| Processing: http_access allow localnet
2017/04/17 05:15:29| Processing: http_access allow localhost
2017/04/17 05:15:29| Processing: http_access allow all
2017/04/17 05:15:29| Processing: http_port 3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB key=/etc/mydlp/ssl/private.pem cert=/etc/mydlp/ssl/public.pem
2017/04/17 05:15:29| Processing: always_direct allow all
2017/04/17 05:15:29| Processing: ssl_bump allow all
2017/04/17 05:15:29| SECURITY NOTICE: auto-converting deprecated "ssl_bump allow <acl>" to "ssl_bump client-first <acl>" which is usually inferior to the newer server-first bumping mode. Update your ssl_bump rules.
2017/04/17 05:15:29| Processing: sslproxy_cert_error allow all
2017/04/17 05:15:29| Processing: sslproxy_flags DONT_VERIFY_PEER
2017/04/17 05:15:29| Processing: sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
2017/04/17 05:15:29| Processing: sslcrtd_children 5
2017/04/17 05:15:29| Processing: coredump_dir /var/spool/squid
2017/04/17 05:15:29| Processing: refresh_pattern ^ftp:          1440    20%     10080
2017/04/17 05:15:29| Processing: refresh_pattern ^gopher:       1440    0%      1440
2017/04/17 05:15:29| Processing: refresh_pattern -i (/cgi-bin/|\?) 0    0%      0
2017/04/17 05:15:29| Processing: refresh_pattern .              0       20%     4320
2017/04/17 05:15:29| Initializing https proxy context
2017/04/17 05:15:29| Initializing http_port [::]:3128 SSL context
2017/04/17 05:15:29| Using certificate in /etc/mydlp/ssl/public.pem

From serhatkoroglu at outlook.com  Mon Apr 17 06:35:28 2017
From: serhatkoroglu at outlook.com (Serhat Koroglu)
Date: Mon, 17 Apr 2017 06:35:28 +0000
Subject: [squid-users] Multiple http_access logic at the same time
Message-ID: <DB6PR0502MB3045D0B4E6B24A4B372C0E5CB4060@DB6PR0502MB3045.eurprd05.prod.outlook.com>

Hello,
I'm trying to manage squid users to access the proxy if they logged in and the site url is allowed in my url list. They are running one by one. If logged in accesses but not check the url and vice versa. But I want both of them. Here is my config part.

auth_param basic program /usr/bin/php /var/www/html/sqauth.php
auth_param basic children 20
auth_param basic realm Username and password
auth_param basic credentialsttl 5 hours

acl AuthenticatedUsers proxy_auth REQUIRED

acl allowed_sites dstdomain "/etc/squid/allowedsites.txt"
acl all_others dst 0.0.0.0/0.0.0.0


http_access allow allowed_sites
http_access deny all_others
http_access allow AuthenticatedUsers


Thank you,
Serhat

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170417/93ed071a/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Apr 17 08:31:20 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 17 Apr 2017 10:31:20 +0200
Subject: [squid-users] Multiple http_access logic at the same time
In-Reply-To: <DB6PR0502MB3045D0B4E6B24A4B372C0E5CB4060@DB6PR0502MB3045.eurprd05.prod.outlook.com>
References: <DB6PR0502MB3045D0B4E6B24A4B372C0E5CB4060@DB6PR0502MB3045.eurprd05.prod.outlook.com>
Message-ID: <201704171031.21278.Antony.Stone@squid.open.source.it>

On Monday 17 April 2017 at 08:35:28, Serhat Koroglu wrote:

> Hello,
> I'm trying to manage squid users to access the proxy if they logged in and
> the site url is allowed in my url list. They are running one by one. If
> logged in accesses but not check the url and vice versa.

So, are you saying that the users must be logged in, *and* the URL they are 
accessing is on your list, otherwise the request is denied?

> But I want both of them. Here is my config part.
> 
> auth_param basic program /usr/bin/php /var/www/html/sqauth.php
> auth_param basic children 20
> auth_param basic realm Username and password
> auth_param basic credentialsttl 5 hours
> 
> acl AuthenticatedUsers proxy_auth REQUIRED
> 
> acl allowed_sites dstdomain "/etc/squid/allowedsites.txt"
> acl all_others dst 0.0.0.0/0.0.0.0
> 
> http_access allow allowed_sites
> http_access deny all_others
> http_access allow AuthenticatedUsers

That last line can never be executed, because the one before "deny all_others" 
simply blocks everything.

I think what you want is simply:

	http_access allow AuthenticatedUsers allowed_sites
	http_access deny all_others


Antony.

-- 
I just got a new mobile phone, and I called it Titanic.  It's already syncing.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Mon Apr 17 12:19:27 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 18 Apr 2017 00:19:27 +1200
Subject: [squid-users] Squid SSL-bump - Not working - No errors
In-Reply-To: <CADHjJ6+AaaTg-WXaB99a_-WBQMPayG91Rs4F8H0Bcq-wx5JGbA@mail.gmail.com>
References: <CADHjJ6+AaaTg-WXaB99a_-WBQMPayG91Rs4F8H0Bcq-wx5JGbA@mail.gmail.com>
Message-ID: <e96850d0-dc33-66b5-9045-db89d6251c48@treenet.co.nz>

The first problem is that you are using a broken config from Squid-3.1 
in a version 3.5 proxy.

Please reset your squid.conf and set it up as described by 
<http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit>

Amos



From arsalan at preston.edu.pk  Mon Apr 17 12:45:55 2017
From: arsalan at preston.edu.pk (Arsalan Hussain)
Date: Mon, 17 Apr 2017 17:45:55 +0500
Subject: [squid-users] Squid Proxy with simple iptable rule ...
In-Reply-To: <a2c7576f-f1ef-450e-8377-11b32c632567@treenet.co.nz>
References: <CAMwDxM3ADo_ToEhbJvvCo8yOsU=zJ9EOLXVR5opqL7dbWMbyWQ@mail.gmail.com>
 <a2c7576f-f1ef-450e-8377-11b32c632567@treenet.co.nz>
Message-ID: <CAMwDxM3W3pPkhd+OwaRWmKf3ZgJL6HSbGdKuHhve84r-v_D12A@mail.gmail.com>

Dear Sir Amos

I had reconfigured Squid 3.5 and it works fine. but i want to protect WAN
interface through IPTABLES

1- can you help me chain rule of simple iptable which drop all trafic from
WAN eth0 to secure and allow squid user request from LAN eth1 only.   (my
WAN send flood by public and it waste my all bandwidth)

For Example:
-A INPUT -j LOG
-A INPUT -j DROP

Then allow
-A INPUT-i eth1 -j ACCEPT
-A FORWARD -i eth1 -j ACCEPT

but its block traffic. Can you please help me what allow rule will works
for Squid 3.5 when i secure my WAN.

On Fri, Apr 14, 2017 at 4:28 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 13/04/2017 11:46 p.m., Arsalan Hussain wrote:
> > Dear All,
> >
> > I am facing problem with iptable rules for squid 3.5.23. my simple squid
> > configuration is attached and also iptable rules.
> >
> > It works fine when i restart squid, iptables, network services but after
> a
> > while it give problem of slow speed or even rejecting packets in squid
> > access.log
>
> Your squid.conf first line says that Browsers are configured to use the
> proxy. That means iptables doing NAT is not relevant.
>
> You also have a mix of a many very different and half-setup proxying
> configurations in your configs.
>
>
> First get that sorted out. Telling us what do you actually want the
> traffic to be doing might be a good start.
>
> What is going wrong is clear, but "I am facing a problem" does not tell
> what we should advise to fix that and in this case your config is so
> mixed its not easy to even make a good guess.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
With Regards,


*Arsalan Hussain*
*Assistant Director, Networks & Information System*

*PRESTON UNIVERSITY*
Add: Plot: 85, Street No: 3, Sector H-8/1, Islamabad, Pakistan
Cell: +92-322-5018611
UAN: (51) 111-707-808 (Ext: 443)
*If you are too lazy to plow now, don't expect a harvest, later*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170417/a3f83450/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Apr 17 12:53:30 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 17 Apr 2017 14:53:30 +0200
Subject: [squid-users] Squid Proxy with simple iptable rule ...
In-Reply-To: <CAMwDxM3W3pPkhd+OwaRWmKf3ZgJL6HSbGdKuHhve84r-v_D12A@mail.gmail.com>
References: <CAMwDxM3ADo_ToEhbJvvCo8yOsU=zJ9EOLXVR5opqL7dbWMbyWQ@mail.gmail.com>
 <a2c7576f-f1ef-450e-8377-11b32c632567@treenet.co.nz>
 <CAMwDxM3W3pPkhd+OwaRWmKf3ZgJL6HSbGdKuHhve84r-v_D12A@mail.gmail.com>
Message-ID: <201704171453.31035.Antony.Stone@squid.open.source.it>

On Monday 17 April 2017 at 14:45:55, Arsalan Hussain wrote:

> Dear Sir Amos

	:)

> I had reconfigured Squid 3.5 and it works fine. but i want to protect WAN
> interface through IPTABLES
> 
> 1- can you help me chain rule of simple iptable which drop all trafic from
> WAN eth0 to secure and allow squid user request from LAN eth1 only.   (my
> WAN send flood by public and it waste my all bandwidth)
> 
> For Example:
> -A INPUT -j LOG

Do you really want to log every packet hitting your machine?

What use is that information?

> -A INPUT -j DROP

That will prevent ALL packets from entering the machine - nothing can work.

You need to allow ESTABLISHED and RELATED packets before DROPping anything.

> Then allow
> -A INPUT-i eth1 -j ACCEPT

There's no point putting a rule like this after "INPUT -j DROP".  Everything 
has been DROPped already, whether it came from eth1 or not...

Remember that IPtables rules work on a "first match wins" basis.

> -A FORWARD -i eth1 -j ACCEPT

Er, wait, is this a forwarding router, or a Squid server accepting requests on 
eth1 and sending them out on eth0?

> but its block traffic. Can you please help me what allow rule will works
> for Squid 3.5 when i secure my WAN.

Please give us more details of your network - I understand that the machien 
running Squid has two interfaces, but is it only ascting as a proxy, or is it 
also a forwarding router for other traffic?

Also, have you read any documantation on IPtables, to get some examples of 
standard configurations?


And finally, you numbered the question above with a "1".  Is there a "2"?


Antony.

-- 
Most people have more than the average number of legs.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From shanmuga_karna at yahoo.com  Mon Apr 17 14:38:52 2017
From: shanmuga_karna at yahoo.com (Shanmugam Sundaram)
Date: Mon, 17 Apr 2017 14:38:52 +0000 (UTC)
Subject: [squid-users] Squid generated certificate for IP rather than domain
 when using ssl_bump
References: <803880255.1827853.1492439932286.ref@mail.yahoo.com>
Message-ID: <803880255.1827853.1492439932286@mail.yahoo.com>

Hi,
I'm new to Squid, and having trouble getting SSL filtering work.
I have a blanket block setup with Squid as Transparent proxy where access it allowed only to github.com. But, squid generates certificates for IP address instead of domain name and SSL validation fails.Squid version: 3.5.25-20170408-r14154When I use curl (I have imported my self signed SSL to the certificate store)
curl: (51) SSL: certificate subject name (192.30.255.112) does not match target host name 'github.com
How to configure properly to splice a whitelist and block all other domains. Below is my current configurationhttp_port 3128
http_port 3129 intercept
https_port 3130intercept ssl-bump enerate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
cert=/etc/squid/ssl_certs/myca.pem key=/etc/squid/ssl_certs/myca.pem

acl whitelist ssl::server_name .github.com
acl step1 at_step SslBump1

ssl_bump peek step1
ssl_bump splice whitelist
ssl_bump bump all

Please help me fixing the issue.
thanks,Shan
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170417/3475f5ce/attachment.htm>

From rousskov at measurement-factory.com  Mon Apr 17 16:40:19 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 17 Apr 2017 10:40:19 -0600
Subject: [squid-users] Squid generated certificate for IP rather than
 domain when using ssl_bump
In-Reply-To: <803880255.1827853.1492439932286@mail.yahoo.com>
References: <803880255.1827853.1492439932286.ref@mail.yahoo.com>
 <803880255.1827853.1492439932286@mail.yahoo.com>
Message-ID: <fdfd6c26-94fa-0dc7-44fb-834ce8d0e9bf@measurement-factory.com>

On 04/17/2017 08:38 AM, Shanmugam Sundaram wrote:

> I have a blanket block setup with Squid as Transparent proxy where
> access it allowed only to github.com. But, squid generates certificates
> for IP address instead of domain name and SSL validation fails.

> Squid version: |3.5.25-20170408-r14154|
> When I use curl
> |curl: (51) SSL: certificate subject name (192.30.255.112) does not
> match target host name 'github.com|
> 
> How to configure properly to splice a whitelist and block all other
> domains. Below is my current configuration
> 
> http_port 3128
> http_port 3129 intercept
> https_port 3130intercept ssl-bump enerate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
> cert=/etc/squid/ssl_certs/myca.pem key=/etc/squid/ssl_certs/myca.pem
> 
> acl whitelist ssl::server_name .github.com
> acl step1 at_step SslBump1
> 
> ssl_bump peek step1
> ssl_bump splice whitelist
> ssl_bump bump all
> 
> Please help me fixing the issue.

Any http_access rules? Is it possible that Squid denies the fake CONNECT
request during step1 (before looking up SNI during step2)?

What does access.log say?

Alex.



From shanmuga_karna at yahoo.com  Mon Apr 17 16:55:16 2017
From: shanmuga_karna at yahoo.com (Shanmugam Sundaram)
Date: Mon, 17 Apr 2017 16:55:16 +0000 (UTC)
Subject: [squid-users] Squid generated certificate for IP rather than
 domain when using ssl_bump
References: <1705972538.1946203.1492448116523.ref@mail.yahoo.com>
Message-ID: <1705972538.1946203.1492448116523@mail.yahoo.com>

Hi Alex, 

Thank you. Yes, there are http_access rules

I have included the entire configuration file (Sorry, I'm new to Squid)The goal is to splice only whitelist (github.com) and terminate all other domains.

http_port 3128
http_port 3129 intercept
https_port 3130 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_certs/myca.pem key=/etc/squid/ssl_certs/myca.pem

visible_hostname squid.internal

acl localnet src 172.16.0.0/16
acl http_whitelist dstdomain .github.comacl whitelist ssl::server_name .github.com

acl SSL_ports port 443
acl Safe_ports port 80????????? # http
acl Safe_ports port 21????????? # ftp
acl Safe_ports port 443???????? # https
acl Safe_ports port 70????????? # gopher
acl Safe_ports port 210???????? # wais
acl Safe_ports port 280???????? # http-mgmt
acl Safe_ports port 488???????? # gss-http
acl Safe_ports port 591???????? # filemaker
acl Safe_ports port 777???????? # multiling http
acl Safe_ports port 1025-65535? # unregistered ports
acl step1 at_step SslBump1
acl step2 at_step SslBump2

acl CONNECT method CONNECT
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager

http_access allow http_whitelist localnethttp_access deny all

acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump splice whitelist
ssl_bump bump all
via offforwarded_for off
request_header_access Allow allow all
request_header_access Authorization allow all
request_header_access WWW-Authenticate allow all
request_header_access Proxy-Authorization allow all
request_header_access Proxy-Authenticate allow all
request_header_access Cache-Control allow all
request_header_access Content-Encoding allow all
request_header_access Content-Length allow all
request_header_access Content-Type allow all
request_header_access Date allow all
request_header_access Expires allow all
request_header_access Host allow all
request_header_access If-Modified-Since allow all
request_header_access Last-Modified allow all
request_header_access Location allow all
request_header_access Pragma allow all
request_header_access Accept allow all
request_header_access Accept-Charset allow all
request_header_access Accept-Encoding allow all
request_header_access Accept-Language allow all
request_header_access Content-Language allow all
request_header_access Mime-Version allow all
request_header_access Retry-After allow all
request_header_access Title allow all
request_header_access Connection allow all
request_header_access Proxy-Connection allow all
request_header_access User-Agent allow all
request_header_access Cookie allow all
request_header_access All deny all
?-Shan 

    On Monday, April 17, 2017 10:10 PM, Alex Rousskov <rousskov at measurement-factory.com> wrote:
 

 On 04/17/2017 08:38 AM, Shanmugam Sundaram wrote:

> I have a blanket block setup with Squid as Transparent proxy where
> access it allowed only to github.com. But, squid generates certificates
> for IP address instead of domain name and SSL validation fails.

> Squid version: |3.5.25-20170408-r14154|
> When I use curl
> |curl: (51) SSL: certificate subject name (192.30.255.112) does not
> match target host name 'github.com|
> 
> How to configure properly to splice a whitelist and block all other
> domains. Below is my current configuration
> 
> http_port 3128
> http_port 3129 intercept
> https_port 3130intercept ssl-bump enerate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
> cert=/etc/squid/ssl_certs/myca.pem key=/etc/squid/ssl_certs/myca.pem
> 
> acl whitelist ssl::server_name .github.com
> acl step1 at_step SslBump1
> 
> ssl_bump peek step1
> ssl_bump splice whitelist
> ssl_bump bump all
> 
> Please help me fixing the issue.

Any http_access rules? Is it possible that Squid denies the fake CONNECT
request during step1 (before looking up SNI during step2)?

What does access.log say?

Alex.



   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170417/a98451dc/attachment.htm>

From rousskov at measurement-factory.com  Mon Apr 17 17:13:16 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 17 Apr 2017 11:13:16 -0600
Subject: [squid-users] Squid generated certificate for IP rather than
 domain when using ssl_bump
In-Reply-To: <1705972538.1946203.1492448116523@mail.yahoo.com>
References: <1705972538.1946203.1492448116523.ref@mail.yahoo.com>
 <1705972538.1946203.1492448116523@mail.yahoo.com>
Message-ID: <0c98ba64-fe1b-7e6a-e800-1eacfc3bfc8b@measurement-factory.com>

On 04/17/2017 10:55 AM, Shanmugam Sundaram wrote:

> The goal is to splice only whitelist (github.com) and terminate all
> other domains.

FYI: I do not know what you mean by "terminate", but if you mean "close
the client-to-Squid connection _without_ serving a Squid-generated error
response to the user", then your ssl_bump configuration does not reflect
your intent. It is easier to terminate non-github connections than to
respond with blocking error messages to non-github requests.


> acl http_whitelist dstdomain .github.com
> acl whitelist ssl::server_name .github.com

> http_access allow http_whitelist localnet
> http_access deny all
> 
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump splice whitelist
> ssl_bump bump all


Your Squid probably denies the fake CONNECT request during step1 (before
looking up SNI during step2). That fake CONNECT does not (and cannot)
have a host name (because you intercept) so it does not match your
"http_whitelist" ACL in the "http_access allow" rule quoted above,
following through to the "deny all" rule that always matches.

An access log may be used to confirm or descard the above theory. This
is why I have asked you about access log records in my previous email.

Alex.



From shanmuga_karna at yahoo.com  Mon Apr 17 17:20:50 2017
From: shanmuga_karna at yahoo.com (Shanmugam Sundaram)
Date: Mon, 17 Apr 2017 17:20:50 +0000 (UTC)
Subject: [squid-users] Squid generated certificate for IP rather than
 domain when using ssl_bump
In-Reply-To: <0c98ba64-fe1b-7e6a-e800-1eacfc3bfc8b@measurement-factory.com>
References: <1705972538.1946203.1492448116523.ref@mail.yahoo.com>
 <1705972538.1946203.1492448116523@mail.yahoo.com>
 <0c98ba64-fe1b-7e6a-e800-1eacfc3bfc8b@measurement-factory.com>
Message-ID: <1998280947.1979424.1492449650954@mail.yahoo.com>

Hi Alex,
Thank you and Sorry for not including the access log earlier.
1492449506.087???? 16 172.27.3.236 TCP_DENIED/200 0 CONNECT 192.30.255.113:443 - HIER_NONE/- -
1492449521.807????? 5 172.27.3.236 TCP_DENIED/200 0 CONNECT 192.30.255.112:443 - HIER_NONE/- -
1492449528.794???? 41 172.27.3.236 TCP_MISS/301 280 GET http://github.com/ - ORIGINAL_DST/192.30.255.113 -
1492449528.799????? 0 172.27.3.236 TCP_DENIED/200 0 CONNECT 192.30.255.113:443 - HIER_NONE/- -

Seems to be the case. Please help me with getting the correct configuration.
Thanks you very much. 

-Shan 

    On Monday, April 17, 2017 10:43 PM, Alex Rousskov <rousskov at measurement-factory.com> wrote:
 

 On 04/17/2017 10:55 AM, Shanmugam Sundaram wrote:

> The goal is to splice only whitelist (github.com) and terminate all
> other domains.

FYI: I do not know what you mean by "terminate", but if you mean "close
the client-to-Squid connection _without_ serving a Squid-generated error
response to the user", then your ssl_bump configuration does not reflect
your intent. It is easier to terminate non-github connections than to
respond with blocking error messages to non-github requests.


> acl http_whitelist dstdomain .github.com
> acl whitelist ssl::server_name .github.com

> http_access allow http_whitelist localnet
> http_access deny all
> 
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump splice whitelist
> ssl_bump bump all


Your Squid probably denies the fake CONNECT request during step1 (before
looking up SNI during step2). That fake CONNECT does not (and cannot)
have a host name (because you intercept) so it does not match your
"http_whitelist" ACL in the "http_access allow" rule quoted above,
following through to the "deny all" rule that always matches.

An access log may be used to confirm or descard the above theory. This
is why I have asked you about access log records in my previous email.

Alex.



   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170417/75216b1f/attachment.htm>

From arsalan at preston.edu.pk  Mon Apr 17 17:31:34 2017
From: arsalan at preston.edu.pk (Arsalan Hussain)
Date: Mon, 17 Apr 2017 22:31:34 +0500
Subject: [squid-users] Squid Proxy with simple iptable rule ...
In-Reply-To: <201704171453.31035.Antony.Stone@squid.open.source.it>
References: <CAMwDxM3ADo_ToEhbJvvCo8yOsU=zJ9EOLXVR5opqL7dbWMbyWQ@mail.gmail.com>
 <a2c7576f-f1ef-450e-8377-11b32c632567@treenet.co.nz>
 <CAMwDxM3W3pPkhd+OwaRWmKf3ZgJL6HSbGdKuHhve84r-v_D12A@mail.gmail.com>
 <201704171453.31035.Antony.Stone@squid.open.source.it>
Message-ID: <CAMwDxM0G_3yBjXnmVzzXYhmf7oCHc7+ZiJbYUdEpdn+qiui3pQ@mail.gmail.com>

Dear Antony Stone,

In fact I recently converted Squid 3.1 and less idea of iptable rules used
there, it was also working as router for internet so i confused with normal
proxy.

> -A INPUT -j LOG

Do you really want to log every packet hitting your machine?

What use is that information?

*@---  You are right, i don't need it *

> -A INPUT -j DROP

That will prevent ALL packets from entering the machine - nothing can work.

You need to allow ESTABLISHED and RELATED packets before DROPping anything.

*@-  correct, i will add established related rule here*

*-A INPUT -i eth0 -m state --state RELATED,ESTABLISHED -j ACCEPT *

> Then allow
> -A INPUT-i eth1 -j ACCEPT

There's no point putting a rule like this after "INPUT -j DROP".  Everything
has been DROPped already, whether it came from eth1 or not...

Remember that IPtables rules work on a "first match wins" basis.

*@-  my mistake, it was before drop rule to access SSH, from LAN*

> -A FORWARD -i eth1 -j ACCEPT

Er, wait, is this a forwarding router, or a Squid server accepting requests
on
eth1 and sending them out on eth0?

@-  i dont need, will remove it

> but its block traffic. Can you please help me what allow rule will works
> for Squid 3.5 when i secure my WAN.

Please give us more details of your network - I understand that the machien
running Squid has two interfaces, but is it only ascting as a proxy, or is
it
also a forwarding router for other traffic?

*@- it is only working as squid, LAN side is consists of two vlans and we
will configure 100 users to use internet. we will limit 2 MB per user @
maximum bandwidth while 1 MB for only FB/Youtube users.*

Squid 3.5 is working fine, but i want to secure  WAN eth0  for any
unauthentic user access .
I only need to configure simple iptables rules to secure it.

On Mon, Apr 17, 2017 at 5:53 PM, Antony Stone <
Antony.Stone at squid.open.source.it> wrote:

> On Monday 17 April 2017 at 14:45:55, Arsalan Hussain wrote:
>
> > Dear Sir Amos
>
>         :)
>
> > I had reconfigured Squid 3.5 and it works fine. but i want to protect WAN
> > interface through IPTABLES
> >
> > 1- can you help me chain rule of simple iptable which drop all trafic
> from
> > WAN eth0 to secure and allow squid user request from LAN eth1 only.   (my
> > WAN send flood by public and it waste my all bandwidth)
> >
> > For Example:
> > -A INPUT -j LOG
>
> Do you really want to log every packet hitting your machine?
>
> What use is that information?
>
> > -A INPUT -j DROP
>
> That will prevent ALL packets from entering the machine - nothing can work.
>
> You need to allow ESTABLISHED and RELATED packets before DROPping anything.
>
> > Then allow
> > -A INPUT-i eth1 -j ACCEPT
>
> There's no point putting a rule like this after "INPUT -j DROP".
> Everything
> has been DROPped already, whether it came from eth1 or not...
>
> Remember that IPtables rules work on a "first match wins" basis.
>
> > -A FORWARD -i eth1 -j ACCEPT
>
> Er, wait, is this a forwarding router, or a Squid server accepting
> requests on
> eth1 and sending them out on eth0?
>
> > but its block traffic. Can you please help me what allow rule will works
> > for Squid 3.5 when i secure my WAN.
>
> Please give us more details of your network - I understand that the machien
> running Squid has two interfaces, but is it only ascting as a proxy, or is
> it
> also a forwarding router for other traffic?
>
> Also, have you read any documantation on IPtables, to get some examples of
> standard configurations?
>
>
> And finally, you numbered the question above with a "1".  Is there a "2"?
>
>
> Antony.
>
> --
> Most people have more than the average number of legs.
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
With Regards,


*Arsalan Hussain*
*Assistant Director, Networks & Information System*

*PRESTON UNIVERSITY*
Add: Plot: 85, Street No: 3, Sector H-8/1, Islamabad, Pakistan
Cell: +92-322-5018611
UAN: (51) 111-707-808 (Ext: 443)
*If you are too lazy to plow now, don't expect a harvest, later*
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170417/1c90b304/attachment.htm>

From turgut at kalfaoglu.com  Tue Apr 18 04:50:25 2017
From: turgut at kalfaoglu.com (=?UTF-8?Q?turgut_kalfao=c4=9flu?=)
Date: Tue, 18 Apr 2017 07:50:25 +0300
Subject: [squid-users] option to auto-recreate the ssl db ?
Message-ID: <e18e5e92-8361-b668-14e1-0ff6c4e4ab50@kalfaoglu.com>

Hi there.. Could we have an option to auto re-create the ssl database?

For some reason, out of nowhere, I start getting these in the cache.log:
security_file_certgen helper database '/var/lib/ssl_db' failed: Failed 
to open file /var/lib/ssl_db/index.txt
security_file_certgen helper database '/var/lib/ssl_db' failed: Failed 
to open file /var/lib/ssl_db/index.txt
security_file_certgen helper database '/var/lib/ssl_db' failed: Failed 
to open file /var/lib/ssl_db/index.txt
security_file_certgen helper database '/var/lib/ssl_db' failed: Failed 
to open file /var/lib/ssl_db/index.txt

# rpm -qa|grep squid
squid-4.0.17-1.fc25.x86_64

Many thanks, -turgut




From eric.veirasgalisson at gmail.com  Tue Apr 18 09:29:35 2017
From: eric.veirasgalisson at gmail.com (Eric Veiras Galisson)
Date: Tue, 18 Apr 2017 11:29:35 +0200
Subject: [squid-users] HTTPS reverse proxy: SSL Certficate verification
	failed
In-Reply-To: <0c4a898b-2854-3f00-8745-f3724ca416fa@treenet.co.nz>
References: <CAJmUcmbfVqJGWpetdEqtFxfMpfbgVi7niRU+cr1_Fk9wNVAwaQ@mail.gmail.com>
 <a9bc23dc-5638-7512-0d2f-738c954caef3@treenet.co.nz>
 <CAJmUcmarAkwGX7f7Gw4iBPBTA-Yc-b-OAeiLMXgpg9cQZGPmYA@mail.gmail.com>
 <7e8eeb8e-0b3d-fdd0-472c-76cb1b06743b@treenet.co.nz>
 <CAJmUcmbvetHjMpdwxUHQ67=e3VHTFvCRkG4rw9f7obamBMN=iA@mail.gmail.com>
 <0c4a898b-2854-3f00-8745-f3724ca416fa@treenet.co.nz>
Message-ID: <CAJmUcmbpdtgvqBd6WAw7fACMaFF-nDqjxwdf+feFVP3WpS5twQ@mail.gmail.com>

I'm back with more information about my problem.

I put squid in front of https://fr.wikipedia.org, I generated a false
certificate for my test to avoid problems with my browser and... I still
have a problem with squid, the same as before.

I'm thinking that my problem does not come from the upstream certificate
itself (which could be the case with ours, but I don't think about
wikipedia's ;) and that the root cause is my custom squid build.

I'm running squid Debian Jessie version 3.4.8-6+deb8u4 and I recompiled
adding the following options:
- --enable-ssl --with-open-ssl="/etc/ssl/openssl.cnf"
- --enable-ssl --with-open-ssl
- --enable-ssl
- --enable-ssl --with-open-ssl --with-ssl-crtd

I tried these combinations and none of them solve my problem. I think I may
be missing some important compilation option but I can't find which.

Output of squid -v

Squid Cache: Version 3.4.8
Debian linux
configure options:  '--build=x86_64-linux-gnu' '--prefix=/usr'
'--includedir=${prefix}/include' '--mandir=${prefix}/share/man'
'--infodir=${prefix}/share/info' '--sysconfdir=/etc' '--localstatedir=/var'
'--libexecdir=${prefix}/lib/squid3' '--srcdir=.'
'--disable-maintainer-mode' '--disable-dependency-tracking'
'--disable-silent-rules' '--datadir=/usr/share/squid3'
'--sysconfdir=/etc/squid3' '--mandir=/usr/share/man' '--enable-inline'
'--disable-arch-native' '--enable-async-io=8'
'--enable-storeio=ufs,aufs,diskd,rock' '--enable-removal-policies=lru,heap'
'--enable-delay-pools' '--enable-cache-digests' '--enable-icap-client'
'--enable-follow-x-forwarded-for'
'--enable-auth-basic=DB,fake,getpwnam,LDAP,MSNT,MSNT-multi-domain,NCSA,NIS,PAM,POP3,RADIUS,SASL,SMB'
'--enable-auth-digest=file,LDAP' '--enable-auth-negotiate=kerberos,wrapper'
'--enable-auth-ntlm=fake,smb_lm'
'--enable-external-acl-helpers=file_userip,kerberos_ldap_group,LDAP_group,session,SQL_session,unix_group,wbinfo_group'
'--enable-url-rewrite-helpers=fake' '--enable-eui' '--enable-esi'
'--enable-icmp' '--enable-zph-qos' '--enable-ecap' '--enable-ssl'
'--with-open-ssl' '--enable-ssl-crtd' '--disable-translation'
'--with-swapdir=/var/spool/squid3' '--with-logdir=/var/log/squid3'
'--with-pidfile=/var/run/squid3.pid' '--with-filedescriptors=65536'
'--with-large-files' '--with-default-user=proxy'
'--enable-build-info=Debian linux' '--enable-linux-netfilter'
'build_alias=x86_64-linux-gnu' 'CFLAGS=-g -O2 -fPIE
-fstack-protector-strong -Wformat -Werror=format-security -Wall'
'LDFLAGS=-fPIE -pie -Wl,-z,relro -Wl,-z,now' 'CPPFLAGS=-D_FORTIFY_SOURCE=2'
'CXXFLAGS=-g -O2 -fPIE -fstack-protector-strong -Wformat
-Werror=format-security'


On Tue, Apr 4, 2017 at 2:14 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 3/04/2017 8:38 p.m., Eric Veiras Galisson wrote:
> > On Sun, Apr 2, 2017 at 10:27 AM, Amos Jeffries wrote:
> >
> >> That Squid->server connection has zero difference between the browser
> >> and the command line tool connecting to a reverse-proxy, or when both
> >> are using opaque (non-Bumped) CONNECT tunnels. So one working and the
> >> other not is impossible.
> >>
> >
> > Yes, I understand this. My problem now is finding what is failing in my
> > setup.
> >
> > Eric.
> >
>
> I think you are going to have to resort to packet tracing with wireshark
> on the Squid->server connection. :-( good luck.
>
> Amos
>
>


-- 
Eric Veiras Galisson
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170418/ef4e5204/attachment.htm>

From squid3 at treenet.co.nz  Tue Apr 18 10:42:40 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 18 Apr 2017 22:42:40 +1200
Subject: [squid-users] HTTPS reverse proxy: SSL Certficate verification
 failed
In-Reply-To: <CAJmUcmbpdtgvqBd6WAw7fACMaFF-nDqjxwdf+feFVP3WpS5twQ@mail.gmail.com>
References: <CAJmUcmbfVqJGWpetdEqtFxfMpfbgVi7niRU+cr1_Fk9wNVAwaQ@mail.gmail.com>
 <a9bc23dc-5638-7512-0d2f-738c954caef3@treenet.co.nz>
 <CAJmUcmarAkwGX7f7Gw4iBPBTA-Yc-b-OAeiLMXgpg9cQZGPmYA@mail.gmail.com>
 <7e8eeb8e-0b3d-fdd0-472c-76cb1b06743b@treenet.co.nz>
 <CAJmUcmbvetHjMpdwxUHQ67=e3VHTFvCRkG4rw9f7obamBMN=iA@mail.gmail.com>
 <0c4a898b-2854-3f00-8745-f3724ca416fa@treenet.co.nz>
 <CAJmUcmbpdtgvqBd6WAw7fACMaFF-nDqjxwdf+feFVP3WpS5twQ@mail.gmail.com>
Message-ID: <12fed859-6644-1717-789f-b8f1c5be1de1@treenet.co.nz>

On 18/04/17 21:29, Eric Veiras Galisson wrote:
> I'm back with more information about my problem.
>
> I put squid in front of https://fr.wikipedia.org, I generated a false 
> certificate for my test to avoid problems with my browser and... I 
> still have a problem with squid, the same as before.
>
> I'm thinking that my problem does not come from the upstream 
> certificate itself (which could be the case with ours, but I don't 
> think about wikipedia's ;) and that the root cause is my custom squid 
> build.
>
> I'm running squid Debian Jessie version 3.4.8-6+deb8u4 and I 
> recompiled adding the following options:
> - --enable-ssl --with-open-ssl="/etc/ssl/openssl.cnf"
> - --enable-ssl --with-open-ssl
> - --enable-ssl
> - --enable-ssl --with-open-ssl --with-ssl-crtd
>
> I tried these combinations and none of them solve my problem. I think 
> I may be missing some important compilation option but I can't find which.

You should use: --enable-ssl-crtd --with-openssl


The --enable-ssl option is obsolete.

The --with-openssl option takes a path to where the openssl development 
files are installed. Somehow I doubt that you have a library installed 
as /etc/ssl/openssl.cnf/openssl/libssl.a. When building against the 
systems default openssl installation you can omit the path. You only 
need it if you are building a custom Squid against a custom openssl.


Amos



From oliver at lennox-it.uk  Tue Apr 18 12:46:37 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Tue, 18 Apr 2017 12:46:37 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <394541827.1187028.1492331446922@mail.yahoo.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <1123675527.318473.1492175196442@mail.yahoo.com>
 <1759621537.629779.1492207188325@mail.yahoo.com>
 <d09589e1-9c03-67b6-8ef9-a43538da750c@treenet.co.nz>
 <394541827.1187028.1492331446922@mail.yahoo.com>
Message-ID: <72028742.2640554.1492519597289@mail.yahoo.com>

Hi All,

Still having problems here. This is my https config now:


---------------------------------https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3 dhparams=/etc/squid3/ssl_cert/dhparam.pem

acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all 
sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/lib/ssl_db -M 4MB
sslcrtd_children 8 startup=1 idle=1

--------------------------------- 


I'm running version 3.5.23 with openssl 1.0. I've had to disable libecap because I couldn't build 3.5 with ecap enabled. I'm getting the following error when trying to connect with SSL:

---------------------------------

The following error was encountered while trying to retrieve the URL: https://www.google.co.uk/* 

Failed to establish a secure connection to 216.58.198.67 

The system returned: 

(71) Protocol error (TLS code: X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY) 
SSL Certficate error: certificate issuer (CA) not known: /C=US/O=Equifax/OU=Equifax Secure Certificate Authority 

This proxy and the remote host failed to negotiate a mutually acceptable security settings for handling your request. It is possible that the remote host does not support secure connections, or the proxy is not satisfied with the host security credentials. 

Your cache administrator is webmaster. 

Generated Tue, 18 Apr 2017 12:23:40 GMT by raspberrypi (squid/3.5.23)
---------------------------------

The CA is always listed as not known not matter what site I try I always get this error.

Any ideas?

Thanks,

Olly

________________________________
From: Olly Lennox <oliver at lennox-it.uk>
To: Amos Jeffries <squid3 at treenet.co.nz>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
Sent: Sunday, 16 April 2017, 9:31
Subject: Re: [squid-users] HTTPS woes



Thanks Amos, it's finally built but I had to disabled ecap, for whatever reason this kept failing (with version 1.0.1 installed). It failed on a reference to the Area function I think but I don't have the error message copied. I'm trying now to configure the ssl stare/peek and will let you know how it goes.

Olly
 
oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252



________________________________
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org 
Sent: Saturday, 15 April 2017, 23:07
Subject: Re: [squid-users] HTTPS woes



On 15/04/2017 9:59 a.m., Olly Lennox wrote:
> Hi Guys.
> I'm still struggling with this. I'm trying to build a version of 3.5 but I just can't get it to work. I'm currently attempting to rebuild the stretch package with SSL enabled but build keeps failing with the following:
> ../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not declared in this scope typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;                                             ^~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:83:61: error: template argument 3 is invalid typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;                                                             ^../../src/ssl/gadgets.h:89:53: error: ?CRYPTO_LOCK_EVP_PKEY? was not declared in this scope typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;                                                     ^~~~~~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:89:73: error: template argument 3 is invalid typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;                                                                         ^../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not declared in this scope typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;                                           ^~~~~~~~~~~~~~~../../src/ssl/gadgets.h:116:58: error: template argument 3 is invalid typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;                                                          ^
> Any ideas?



On Jesse/stable:

apt-get build-dep squid3
apt-get install libss-dev


On stretch/testing/unstable:

apt-get build-dep squid
apt-get install libss1.0-dev


That should do it for you.

Amos


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From yvoinov at gmail.com  Tue Apr 18 12:51:29 2017
From: yvoinov at gmail.com (Yuri)
Date: Tue, 18 Apr 2017 18:51:29 +0600
Subject: [squid-users] HTTPS woes
In-Reply-To: <72028742.2640554.1492519597289@mail.yahoo.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <1123675527.318473.1492175196442@mail.yahoo.com>
 <1759621537.629779.1492207188325@mail.yahoo.com>
 <d09589e1-9c03-67b6-8ef9-a43538da750c@treenet.co.nz>
 <394541827.1187028.1492331446922@mail.yahoo.com>
 <72028742.2640554.1492519597289@mail.yahoo.com>
Message-ID: <8b05527e-0890-993c-2f0b-aa4333354295@gmail.com>

Try to specify roots CA bundle/dir explicity by specifying one of this 
params:


#  TAG: sslproxy_cafile
#    file containing CA certificates to use when verifying server
#    certificates while proxying https:// URLs
#Default:
# none

#  TAG: sslproxy_capath
#    directory containing CA certificates to use when verifying
#    server certificates while proxying https:// URLs
#Default:
# none



18.04.2017 18:46, Olly Lennox ?????:
> Hi All,
>
> Still having problems here. This is my https config now:
>
>
> ---------------------------------https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3 dhparams=/etc/squid3/ssl_cert/dhparam.pem
>
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump bump all
> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
> sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>
> sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/lib/ssl_db -M 4MB
> sslcrtd_children 8 startup=1 idle=1
>
> ---------------------------------
>
>
> I'm running version 3.5.23 with openssl 1.0. I've had to disable libecap because I couldn't build 3.5 with ecap enabled. I'm getting the following error when trying to connect with SSL:
>
> ---------------------------------
>
> The following error was encountered while trying to retrieve the URL: https://www.google.co.uk/*
>
> Failed to establish a secure connection to 216.58.198.67
>
> The system returned:
>
> (71) Protocol error (TLS code: X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
> SSL Certficate error: certificate issuer (CA) not known: /C=US/O=Equifax/OU=Equifax Secure Certificate Authority
>
> This proxy and the remote host failed to negotiate a mutually acceptable security settings for handling your request. It is possible that the remote host does not support secure connections, or the proxy is not satisfied with the host security credentials.
>
> Your cache administrator is webmaster.
>
> Generated Tue, 18 Apr 2017 12:23:40 GMT by raspberrypi (squid/3.5.23)
> ---------------------------------
>
> The CA is always listed as not known not matter what site I try I always get this error.
>
> Any ideas?
>
> Thanks,
>
> Olly
>
> ________________________________
> From: Olly Lennox <oliver at lennox-it.uk>
> To: Amos Jeffries <squid3 at treenet.co.nz>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org>
> Sent: Sunday, 16 April 2017, 9:31
> Subject: Re: [squid-users] HTTPS woes
>
>
>
> Thanks Amos, it's finally built but I had to disabled ecap, for whatever reason this kept failing (with version 1.0.1 installed). It failed on a reference to the Area function I think but I don't have the error message copied. I'm trying now to configure the ssl stare/peek and will let you know how it goes.
>
> Olly
>   
> oliver at lennox-it.uk
> lennox-it.uk
> tel: 07900 648 252
>
>
>
> ________________________________
> From: Amos Jeffries <squid3 at treenet.co.nz>
> To: squid-users at lists.squid-cache.org
> Sent: Saturday, 15 April 2017, 23:07
> Subject: Re: [squid-users] HTTPS woes
>
>
>
> On 15/04/2017 9:59 a.m., Olly Lennox wrote:
>> Hi Guys.
>> I'm still struggling with this. I'm trying to build a version of 3.5 but I just can't get it to work. I'm currently attempting to rebuild the stretch package with SSL enabled but build keeps failing with the following:
>> ../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not declared in this scope typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;                                             ^~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:83:61: error: template argument 3 is invalid typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;                                                             ^../../src/ssl/gadgets.h:89:53: error: ?CRYPTO_LOCK_EVP_PKEY? was not declared in this scope typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;                                                     ^~~~~~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:89:73: error: template argument 3 is invalid typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;                                                                         ^../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not declared in this scope typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;                                           ^~~~~~~~~~~~~~~../../src/ssl/gadgets.h:116:58: error: template argument 3 is invalid typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;                                                          ^
>> Any ideas?
>
>
> On Jesse/stable:
>
> apt-get build-dep squid3
> apt-get install libss-dev
>
>
> On stretch/testing/unstable:
>
> apt-get build-dep squid
> apt-get install libss1.0-dev
>
>
> That should do it for you.
>
> Amos
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users




From oliver at lennox-it.uk  Tue Apr 18 12:56:30 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Tue, 18 Apr 2017 12:56:30 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <8b05527e-0890-993c-2f0b-aa4333354295@gmail.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <1123675527.318473.1492175196442@mail.yahoo.com>
 <1759621537.629779.1492207188325@mail.yahoo.com>
 <d09589e1-9c03-67b6-8ef9-a43538da750c@treenet.co.nz>
 <394541827.1187028.1492331446922@mail.yahoo.com>
 <72028742.2640554.1492519597289@mail.yahoo.com>
 <8b05527e-0890-993c-2f0b-aa4333354295@gmail.com>
Message-ID: <1319111330.2659089.1492520191012@mail.yahoo.com>

I'm using?
sslproxy_foreign_intermediate_certs
Is this the same thing??
Also is there anywhere to get a bundle of all the major CA intermdiate certs or do you have to download them all manually?
Cheers,?oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252

      From: Yuri <yvoinov at gmail.com>
 To: squid-users at lists.squid-cache.org 
 Sent: Tuesday, 18 April 2017, 13:51
 Subject: Re: [squid-users] HTTPS woes
   
Try to specify roots CA bundle/dir explicity by specifying one of this 
params:


#? TAG: sslproxy_cafile
#? ? file containing CA certificates to use when verifying server
#? ? certificates while proxying https:// URLs
#Default:
# none

#? TAG: sslproxy_capath
#? ? directory containing CA certificates to use when verifying
#? ? server certificates while proxying https:// URLs
#Default:
# none



18.04.2017 18:46, Olly Lennox ?????:
> Hi All,
>
> Still having problems here. This is my https config now:
>
>
> ---------------------------------https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3 dhparams=/etc/squid3/ssl_cert/dhparam.pem
>
> acl step1 at_step SslBump1
> ssl_bump peek step1
> ssl_bump bump all
> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
> sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>
> sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/lib/ssl_db -M 4MB
> sslcrtd_children 8 startup=1 idle=1
>
> ---------------------------------
>
>
> I'm running version 3.5.23 with openssl 1.0. I've had to disable libecap because I couldn't build 3.5 with ecap enabled. I'm getting the following error when trying to connect with SSL:
>
> ---------------------------------
>
> The following error was encountered while trying to retrieve the URL: https://www.google.co.uk/*
>
> Failed to establish a secure connection to 216.58.198.67
>
> The system returned:
>
> (71) Protocol error (TLS code: X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
> SSL Certficate error: certificate issuer (CA) not known: /C=US/O=Equifax/OU=Equifax Secure Certificate Authority
>
> This proxy and the remote host failed to negotiate a mutually acceptable security settings for handling your request. It is possible that the remote host does not support secure connections, or the proxy is not satisfied with the host security credentials.
>
> Your cache administrator is webmaster.
>
> Generated Tue, 18 Apr 2017 12:23:40 GMT by raspberrypi (squid/3.5.23)
> ---------------------------------
>
> The CA is always listed as not known not matter what site I try I always get this error.
>
> Any ideas?
>
> Thanks,
>
> Olly
>
> ________________________________
> From: Olly Lennox <oliver at lennox-it.uk>
> To: Amos Jeffries <squid3 at treenet.co.nz>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org>
> Sent: Sunday, 16 April 2017, 9:31
> Subject: Re: [squid-users] HTTPS woes
>
>
>
> Thanks Amos, it's finally built but I had to disabled ecap, for whatever reason this kept failing (with version 1.0.1 installed). It failed on a reference to the Area function I think but I don't have the error message copied. I'm trying now to configure the ssl stare/peek and will let you know how it goes.
>
> Olly
>? 
> oliver at lennox-it.uk
> lennox-it.uk
> tel: 07900 648 252
>
>
>
> ________________________________
> From: Amos Jeffries <squid3 at treenet.co.nz>
> To: squid-users at lists.squid-cache.org
> Sent: Saturday, 15 April 2017, 23:07
> Subject: Re: [squid-users] HTTPS woes
>
>
>
> On 15/04/2017 9:59 a.m., Olly Lennox wrote:
>> Hi Guys.
>> I'm still struggling with this. I'm trying to build a version of 3.5 but I just can't get it to work. I'm currently attempting to rebuild the stretch package with SSL enabled but build keeps failing with the following:
>> ../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not declared in this scope typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:83:61: error: template argument 3 is invalid typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^../../src/ssl/gadgets.h:89:53: error: ?CRYPTO_LOCK_EVP_PKEY? was not declared in this scope typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^~~~~~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:89:73: error: template argument 3 is invalid typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not declared in this scope typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^~~~~~~~~~~~~~~../../src/ssl/gadgets.h:116:58: error: template argument 3 is invalid typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^
>> Any ideas?
>
>
> On Jesse/stable:
>
> apt-get build-dep squid3
> apt-get install libss-dev
>
>
> On stretch/testing/unstable:
>
> apt-get build-dep squid
> apt-get install libss1.0-dev
>
>
> That should do it for you.
>
> Amos
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170418/91aacd83/attachment.htm>

From yvoinov at gmail.com  Tue Apr 18 13:03:19 2017
From: yvoinov at gmail.com (Yuri)
Date: Tue, 18 Apr 2017 19:03:19 +0600
Subject: [squid-users] HTTPS woes
In-Reply-To: <1319111330.2659089.1492520191012@mail.yahoo.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <1123675527.318473.1492175196442@mail.yahoo.com>
 <1759621537.629779.1492207188325@mail.yahoo.com>
 <d09589e1-9c03-67b6-8ef9-a43538da750c@treenet.co.nz>
 <394541827.1187028.1492331446922@mail.yahoo.com>
 <72028742.2640554.1492519597289@mail.yahoo.com>
 <8b05527e-0890-993c-2f0b-aa4333354295@gmail.com>
 <1319111330.2659089.1492520191012@mail.yahoo.com>
Message-ID: <cad1fc14-3f0e-3eb0-7ae2-523f7b552506@gmail.com>



18.04.2017 18:56, Olly Lennox ?????:
> I'm using
>
> sslproxy_foreign_intermediate_certs
>
> Is this the same thing?
No. You firstly required CA roots available for squid. CA roots and 
intermediate is the different things.
>
> Also is there anywhere to get a bundle of all the major CA intermdiate 
> certs or do you have to download them all manually?
No. You should build it by yourself.
>
> Cheers,
> oliver at lennox-it.uk
> lennox-it.uk <http://lennox-it.uk/>
> tel: 07900 648 252
>
>
> ------------------------------------------------------------------------
> *From:* Yuri <yvoinov at gmail.com>
> *To:* squid-users at lists.squid-cache.org
> *Sent:* Tuesday, 18 April 2017, 13:51
> *Subject:* Re: [squid-users] HTTPS woes
>
> Try to specify roots CA bundle/dir explicity by specifying one of this
> params:
>
>
> #  TAG: sslproxy_cafile
> #    file containing CA certificates to use when verifying server
> #    certificates while proxying https:// URLs
> #Default:
> # none
>
> #  TAG: sslproxy_capath
> #    directory containing CA certificates to use when verifying
> #    server certificates while proxying https:// URLs
> #Default:
> # none
>
>
>
> 18.04.2017 18:46, Olly Lennox ?????:
> > Hi All,
> >
> > Still having problems here. This is my https config now:
> >
> >
> > ---------------------------------https_port 3129 intercept ssl-bump 
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
> cert=/etc/squid3/ssl_cert/squid.crt key=/etc/squid3/ssl_cert/squid.key 
> options=NO_SSLv3 dhparams=/etc/squid3/ssl_cert/dhparam.pem
> >
> > acl step1 at_step SslBump1
> > ssl_bump peek step1
> > ssl_bump bump all
> > sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
> > sslproxy_cipher 
> EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
> >
> > sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/lib/ssl_db -M 4MB
> > sslcrtd_children 8 startup=1 idle=1
> >
> > ---------------------------------
> >
> >
> > I'm running version 3.5.23 with openssl 1.0. I've had to disable 
> libecap because I couldn't build 3.5 with ecap enabled. I'm getting 
> the following error when trying to connect with SSL:
> >
> > ---------------------------------
> >
> > The following error was encountered while trying to retrieve the 
> URL: https://www.google.co.uk/*
> >
> > Failed to establish a secure connection to 216.58.198.67
> >
> > The system returned:
> >
> > (71) Protocol error (TLS code: 
> X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
> > SSL Certficate error: certificate issuer (CA) not known: 
> /C=US/O=Equifax/OU=Equifax Secure Certificate Authority
> >
> > This proxy and the remote host failed to negotiate a mutually 
> acceptable security settings for handling your request. It is possible 
> that the remote host does not support secure connections, or the proxy 
> is not satisfied with the host security credentials.
> >
> > Your cache administrator is webmaster.
> >
> > Generated Tue, 18 Apr 2017 12:23:40 GMT by raspberrypi (squid/3.5.23)
> > ---------------------------------
> >
> > The CA is always listed as not known not matter what site I try I 
> always get this error.
> >
> > Any ideas?
> >
> > Thanks,
> >
> > Olly
> >
> > ________________________________
> > From: Olly Lennox <oliver at lennox-it.uk <mailto:oliver at lennox-it.uk>>
> > To: Amos Jeffries <squid3 at treenet.co.nz 
> <mailto:squid3 at treenet.co.nz>>; "squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>" 
> <squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>>
> > Sent: Sunday, 16 April 2017, 9:31
> > Subject: Re: [squid-users] HTTPS woes
> >
> >
> >
> > Thanks Amos, it's finally built but I had to disabled ecap, for 
> whatever reason this kept failing (with version 1.0.1 installed). It 
> failed on a reference to the Area function I think but I don't have 
> the error message copied. I'm trying now to configure the ssl 
> stare/peek and will let you know how it goes.
> >
> > Olly
> >
> > oliver at lennox-it.uk <mailto:oliver at lennox-it.uk>
> > lennox-it.uk
> > tel: 07900 648 252
> >
> >
> >
> > ________________________________
> > From: Amos Jeffries <squid3 at treenet.co.nz <mailto:squid3 at treenet.co.nz>>
> > To: squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>
> > Sent: Saturday, 15 April 2017, 23:07
> > Subject: Re: [squid-users] HTTPS woes
> >
> >
> >
> > On 15/04/2017 9:59 a.m., Olly Lennox wrote:
> >> Hi Guys.
> >> I'm still struggling with this. I'm trying to build a version of 
> 3.5 but I just can't get it to work. I'm currently attempting to 
> rebuild the stretch package with SSL enabled but build keeps failing 
> with the following:
> >> ../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not 
> declared in this scope typedef LockingPointer<X509, X509_free_cpp, 
> CRYPTO_LOCK_X509> X509_Pointer; 
> ^~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:83:61: error: template 
> argument 3 is invalid typedef LockingPointer<X509, X509_free_cpp, 
> CRYPTO_LOCK_X509> X509_Pointer; ^../../src/ssl/gadgets.h:89:53: error: 
> ?CRYPTO_LOCK_EVP_PKEY? was not declared in this scope typedef 
> LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> 
> EVP_PKEY_Pointer; ^~~~~~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:89:73: 
> error: template argument 3 is invalid typedef LockingPointer<EVP_PKEY, 
> EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;       
> ^../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not 
> declared in this scope typedef LockingPointer<SSL, SSL_free_cpp, 
> CRYPTO_LOCK_SSL> SSL_Pointer; 
> ^~~~~~~~~~~~~~~../../src/ssl/gadgets.h:116:58: error: template 
> argument 3 is invalid typedef LockingPointer<SSL, SSL_free_cpp, 
> CRYPTO_LOCK_SSL> SSL_Pointer;                                     ^
> >> Any ideas?
> >
> >
> > On Jesse/stable:
> >
> > apt-get build-dep squid3
> > apt-get install libss-dev
> >
> >
> > On stretch/testing/unstable:
> >
> > apt-get build-dep squid
> > apt-get install libss1.0-dev
> >
> >
> > That should do it for you.
> >
> > Amos
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>
> > http://lists.squid-cache.org/listinfo/squid-users
> >
> >
> >
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>
> > http://lists.squid-cache.org/listinfo/squid-users
>
> > _______________________________________________
> > squid-users mailing list
> > squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>
> > http://lists.squid-cache.org/listinfo/squid-users
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org 
> <mailto:squid-users at lists.squid-cache.org>
> http://lists.squid-cache.org/listinfo/squid-users
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170418/6759453c/attachment.htm>

From oliver at lennox-it.uk  Tue Apr 18 13:35:50 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Tue, 18 Apr 2017 13:35:50 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <cad1fc14-3f0e-3eb0-7ae2-523f7b552506@gmail.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <1123675527.318473.1492175196442@mail.yahoo.com>
 <1759621537.629779.1492207188325@mail.yahoo.com>
 <d09589e1-9c03-67b6-8ef9-a43538da750c@treenet.co.nz>
 <394541827.1187028.1492331446922@mail.yahoo.com>
 <72028742.2640554.1492519597289@mail.yahoo.com>
 <8b05527e-0890-993c-2f0b-aa4333354295@gmail.com>
 <1319111330.2659089.1492520191012@mail.yahoo.com>
 <cad1fc14-3f0e-3eb0-7ae2-523f7b552506@gmail.com>
Message-ID: <1954807168.2701725.1492522550674@mail.yahoo.com>

So anyone who wants to use Squid over HTTPS in the way has to build this repository themselves by manually downloading all the CA bundles??


      From: Yuri <yvoinov at gmail.com>
 To: Olly Lennox <oliver at lennox-it.uk>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Tuesday, 18 April 2017, 14:03
 Subject: Re: [squid-users] HTTPS woes
   
 
  
 18.04.2017 18:56, Olly Lennox ?????:
  
  I'm using? 
  sslproxy_foreign_intermediate_certs 
  Is this the same thing? 
   
 No. You firstly required CA roots available for squid. CA roots and intermediate is the different things.
 
  
  Also is there anywhere to get a bundle of all the major CA intermdiate certs or do you have to download them all manually?  
 No. You should build it by yourself.
 
  
  Cheers, ? oliver at lennox-it.uk
 lennox-it.uk
 tel: 07900 648 252 
 
        From: Yuri <yvoinov at gmail.com>
 To: squid-users at lists.squid-cache.org 
 Sent: Tuesday, 18 April 2017, 13:51
 Subject: Re: [squid-users] HTTPS woes
  
 Try to specify roots CA bundle/dir explicity by specifying one of this 
 params:
 
 
 #? TAG: sslproxy_cafile
 #? ? file containing CA certificates to use when verifying server
 #? ? certificates while proxying https:// URLs
 #Default:
 # none
 
 #? TAG: sslproxy_capath
 #? ? directory containing CA certificates to use when verifying
 #? ? server certificates while proxying https:// URLs
 #Default:
 # none
 
 
 
 18.04.2017 18:46, Olly Lennox ?????:
 > Hi All,
 >
 > Still having problems here. This is my https config now:
 >
 >
 > ---------------------------------https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB  cert=/etc/squid3/ssl_cert/squid.crt key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3 dhparams=/etc/squid3/ssl_cert/dhparam.pem
 >
 > acl step1 at_step SslBump1
 > ssl_bump peek step1
 > ssl_bump bump all
 > sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
 > sslproxy_cipherEECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
 >
 > sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/lib/ssl_db -M 4MB
 > sslcrtd_children 8 startup=1 idle=1
 >
 > ---------------------------------
 >
 >
 > I'm running version 3.5.23 with openssl 1.0. I've had to disable libecap because I couldn't build 3.5 with ecap enabled. I'm getting the following error when trying to connect with SSL:
 >
 > ---------------------------------
 >
 > The following error was encountered while trying to retrieve the URL: https://www.google.co.uk/*
 >
 > Failed to establish a secure connection to 216.58.198.67
 >
 > The system returned:
 >
 > (71) Protocol error (TLS code: X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
 > SSL Certficate error: certificate issuer (CA) not known: /C=US/O=Equifax/OU=Equifax Secure Certificate Authority
 >
 > This proxy and the remote host failed to negotiate a mutually acceptable security settings for handling your request. It is possible that the remote host does not support secure connections, or the proxy is not satisfied with the host security credentials.
 >
 > Your cache administrator is webmaster.
 >
 > Generated Tue, 18 Apr 2017 12:23:40 GMT by raspberrypi (squid/3.5.23)
 > ---------------------------------
 >
 > The CA is always listed as not known not matter what site I try I always get this error.
 >
 > Any ideas?
 >
 > Thanks,
 >
 > Olly
 >
 > ________________________________
 > From: Olly Lennox <oliver at lennox-it.uk>
 > To: Amos Jeffries <squid3 at treenet.co.nz>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org>
 > Sent: Sunday, 16 April 2017, 9:31
 > Subject: Re: [squid-users] HTTPS woes
 >
 >
 >
 > Thanks Amos, it's finally built but I had to disabled ecap, for whatever reason this kept failing (with version 1.0.1 installed). It failed on a reference to the Area function I think but I don't have the error message copied. I'm trying now to configure the ssl stare/peek and will let you know how it goes.
 >
 > Olly
 >? 
 > oliver at lennox-it.uk
 > lennox-it.uk
 > tel: 07900 648 252
 >
 >
 >
 > ________________________________
 > From: Amos Jeffries <squid3 at treenet.co.nz>
 > To: squid-users at lists.squid-cache.org
 > Sent: Saturday, 15 April 2017, 23:07
 > Subject: Re: [squid-users] HTTPS woes
 >
 >
 >
 > On 15/04/2017 9:59 a.m., Olly Lennox wrote:
 >> Hi Guys.
 >> I'm still struggling with this. I'm trying to build a version of 3.5 but I just can't get it to work. I'm currently attempting to rebuild the stretch package with SSL enabled but build keeps failing with the following:
 >> ../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not declared in this scope typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:83:61: error: template argument 3 is invalid typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^../../src/ssl/gadgets.h:89:53: error: ?CRYPTO_LOCK_EVP_PKEY? was not declared in this scope typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^~~~~~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:89:73: error: template argument 3 is invalid typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not declared in this scope typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^~~~~~~~~~~~~~~../../src/ssl/gadgets.h:116:58: error: template argument 3 is invalid typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^
 >> Any ideas?
 >
 >
 > On Jesse/stable:
 >
 > apt-get build-dep squid3
 > apt-get install libss-dev
 >
 >
 > On stretch/testing/unstable:
 >
 > apt-get build-dep squid
 > apt-get install libss1.0-dev
 >
 >
 > That should do it for you.
 >
 > Amos
 >
 >
 > _______________________________________________
 > squid-users mailing list
 > squid-users at lists.squid-cache.org
 > http://lists.squid-cache.org/listinfo/squid-users
 >
 >
 >
 > _______________________________________________
 > squid-users mailing list
 > squid-users at lists.squid-cache.org
 > http://lists.squid-cache.org/listinfo/squid-users 
 > _______________________________________________
 > squid-users mailing list
 > squid-users at lists.squid-cache.org
 > http://lists.squid-cache.org/listinfo/squid-users
 
 
 _______________________________________________
 squid-users mailing list
 squid-users at lists.squid-cache.org
 http://lists.squid-cache.org/listinfo/squid-users
   
 
      
 
 

   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170418/810d8e3f/attachment.htm>

From yvoinov at gmail.com  Tue Apr 18 13:43:22 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 18 Apr 2017 19:43:22 +0600
Subject: [squid-users] HTTPS woes
In-Reply-To: <1954807168.2701725.1492522550674@mail.yahoo.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <1123675527.318473.1492175196442@mail.yahoo.com>
 <1759621537.629779.1492207188325@mail.yahoo.com>
 <d09589e1-9c03-67b6-8ef9-a43538da750c@treenet.co.nz>
 <394541827.1187028.1492331446922@mail.yahoo.com>
 <72028742.2640554.1492519597289@mail.yahoo.com>
 <8b05527e-0890-993c-2f0b-aa4333354295@gmail.com>
 <1319111330.2659089.1492520191012@mail.yahoo.com>
 <cad1fc14-3f0e-3eb0-7ae2-523f7b552506@gmail.com>
 <1954807168.2701725.1492522550674@mail.yahoo.com>
Message-ID: <bcb5461b-09be-9c9e-f6fb-ac0babd607a0@gmail.com>

You talked about two different things.

1. root CA usually built-in in clients. For standalone use, root CA
(from Mozilla) usually distributes with openssl distributions. If you
need (or your openssl distribution does not contains root CAs), you can
find separately distributed Mozilla CA's by short googling:

https://www.google.com/search?q=Mozilla+CA+bundle

2. Intermediate CA's is subordinate for roots CA. It does not exists by
gouverned repository (because of supporting it is work, manual work and
should be do by somebody), moreover, it spreaded across CA authorities.
There is no automated tool to support this _intermediate_list. The
problem also: intermediate CA's usuallu has much short validity period
instead of roots, and should supports all time at time.

Finally - it you want to use Squid with SSL Bump, you should understand
PKI infrastructure and yes - you should support root CA & intermediate
CAs on proxy by yourself all time. There is no free or payment basis
service which is do it for you.


18.04.2017 19:35, Olly Lennox ?????:
> So anyone who wants to use Squid over HTTPS in the way has to build
> this repository themselves by manually downloading all the CA bundles?
>  
>
>
>
> ------------------------------------------------------------------------
> *From:* Yuri <yvoinov at gmail.com>
> *To:* Olly Lennox <oliver at lennox-it.uk>;
> "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org>
> *Sent:* Tuesday, 18 April 2017, 14:03
> *Subject:* Re: [squid-users] HTTPS woes
>
>
>
> 18.04.2017 18:56, Olly Lennox ?????:
>> I'm using 
>>
>> sslproxy_foreign_intermediate_certs
>>
>> Is this the same thing?
> No. You firstly required CA roots available for squid. CA roots and
> intermediate is the different things.
>>
>> Also is there anywhere to get a bundle of all the major CA
>> intermdiate certs or do you have to download them all manually?
> No. You should build it by yourself.
>
>>
>> Cheers,
>>  
>> oliver at lennox-it.uk <mailto:oliver at lennox-it.uk>
>> lennox-it.uk <http://lennox-it.uk/>
>> tel: 07900 648 252
>>
>>
>> ------------------------------------------------------------------------
>> *From:* Yuri <yvoinov at gmail.com> <mailto:yvoinov at gmail.com>
>> *To:* squid-users at lists.squid-cache.org
>> <mailto:squid-users at lists.squid-cache.org>
>> *Sent:* Tuesday, 18 April 2017, 13:51
>> *Subject:* Re: [squid-users] HTTPS woes
>>
>> Try to specify roots CA bundle/dir explicity by specifying one of this
>> params:
>>
>>
>> #  TAG: sslproxy_cafile
>> #    file containing CA certificates to use when verifying server
>> #    certificates while proxying https:// URLs
>> #Default:
>> # none
>>
>> #  TAG: sslproxy_capath
>> #    directory containing CA certificates to use when verifying
>> #    server certificates while proxying https:// URLs
>> #Default:
>> # none
>>
>>
>>
>> 18.04.2017 18:46, Olly Lennox ?????:
>> > Hi All,
>> >
>> > Still having problems here. This is my https config now:
>> >
>> >
>> > ---------------------------------https_port 3129 intercept ssl-bump
>> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>> cert=/etc/squid3/ssl_cert/squid.crt
>> key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3
>> dhparams=/etc/squid3/ssl_cert/dhparam.pem
>> >
>> > acl step1 at_step SslBump1
>> > ssl_bump peek step1
>> > ssl_bump bump all
>> > sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>> > sslproxy_cipher
>> EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>> >
>> > sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/lib/ssl_db -M 4MB
>> > sslcrtd_children 8 startup=1 idle=1
>> >
>> > ---------------------------------
>> >
>> >
>> > I'm running version 3.5.23 with openssl 1.0. I've had to disable
>> libecap because I couldn't build 3.5 with ecap enabled. I'm getting
>> the following error when trying to connect with SSL:
>> >
>> > ---------------------------------
>> >
>> > The following error was encountered while trying to retrieve the
>> URL: https://www.google.co.uk/*
>> >
>> > Failed to establish a secure connection to 216.58.198.67
>> >
>> > The system returned:
>> >
>> > (71) Protocol error (TLS code:
>> X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
>> > SSL Certficate error: certificate issuer (CA) not known:
>> /C=US/O=Equifax/OU=Equifax Secure Certificate Authority
>> >
>> > This proxy and the remote host failed to negotiate a mutually
>> acceptable security settings for handling your request. It is
>> possible that the remote host does not support secure connections, or
>> the proxy is not satisfied with the host security credentials.
>> >
>> > Your cache administrator is webmaster.
>> >
>> > Generated Tue, 18 Apr 2017 12:23:40 GMT by raspberrypi (squid/3.5.23)
>> > ---------------------------------
>> >
>> > The CA is always listed as not known not matter what site I try I
>> always get this error.
>> >
>> > Any ideas?
>> >
>> > Thanks,
>> >
>> > Olly
>> >
>> > ________________________________
>> > From: Olly Lennox <oliver at lennox-it.uk <mailto:oliver at lennox-it.uk>>
>> > To: Amos Jeffries <squid3 at treenet.co.nz
>> <mailto:squid3 at treenet.co.nz>>; "squid-users at lists.squid-cache.org
>> <mailto:squid-users at lists.squid-cache.org>"
>> <squid-users at lists.squid-cache.org
>> <mailto:squid-users at lists.squid-cache.org>>
>> > Sent: Sunday, 16 April 2017, 9:31
>> > Subject: Re: [squid-users] HTTPS woes
>> >
>> >
>> >
>> > Thanks Amos, it's finally built but I had to disabled ecap, for
>> whatever reason this kept failing (with version 1.0.1 installed). It
>> failed on a reference to the Area function I think but I don't have
>> the error message copied. I'm trying now to configure the ssl
>> stare/peek and will let you know how it goes.
>> >
>> > Olly
>> > 
>> > oliver at lennox-it.uk <mailto:oliver at lennox-it.uk>
>> > lennox-it.uk
>> > tel: 07900 648 252
>> >
>> >
>> >
>> > ________________________________
>> > From: Amos Jeffries <squid3 at treenet.co.nz
>> <mailto:squid3 at treenet.co.nz>>
>> > To: squid-users at lists.squid-cache.org
>> <mailto:squid-users at lists.squid-cache.org>
>> > Sent: Saturday, 15 April 2017, 23:07
>> > Subject: Re: [squid-users] HTTPS woes
>> >
>> >
>> >
>> > On 15/04/2017 9:59 a.m., Olly Lennox wrote:
>> >> Hi Guys.
>> >> I'm still struggling with this. I'm trying to build a version of
>> 3.5 but I just can't get it to work. I'm currently attempting to
>> rebuild the stretch package with SSL enabled but build keeps failing
>> with the following:
>> >> ../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not
>> declared in this scope typedef LockingPointer<X509, X509_free_cpp,
>> CRYPTO_LOCK_X509> X509_Pointer;                                     
>>       ^~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:83:61: error: template
>> argument 3 is invalid typedef LockingPointer<X509, X509_free_cpp,
>> CRYPTO_LOCK_X509> X509_Pointer;                                     
>>                       ^../../src/ssl/gadgets.h:89:53: error:
>> ?CRYPTO_LOCK_EVP_PKEY? was not declared in this scope typedef
>> LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY>
>> EVP_PKEY_Pointer;                                                   
>> ^~~~~~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:89:73: error: template
>> argument 3 is invalid typedef LockingPointer<EVP_PKEY,
>> EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;           
>>                                                            
>> ^../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not
>> declared in this scope typedef LockingPointer<SSL, SSL_free_cpp,
>> CRYPTO_LOCK_SSL> SSL_Pointer;                                       
>>   ^~~~~~~~~~~~~~~../../src/ssl/gadgets.h:116:58: error: template
>> argument 3 is invalid typedef LockingPointer<SSL, SSL_free_cpp,
>> CRYPTO_LOCK_SSL> SSL_Pointer;                                       
>>                   ^
>> >> Any ideas?
>> >
>> >
>> > On Jesse/stable:
>> >
>> > apt-get build-dep squid3
>> > apt-get install libss-dev
>> >
>> >
>> > On stretch/testing/unstable:
>> >
>> > apt-get build-dep squid
>> > apt-get install libss1.0-dev
>> >
>> >
>> > That should do it for you.
>> >
>> > Amos
>> >
>> >
>> > _______________________________________________
>> > squid-users mailing list
>> > squid-users at lists.squid-cache.org
>> <mailto:squid-users at lists.squid-cache.org>
>> > http://lists.squid-cache.org/listinfo/squid-users
>> >
>> >
>> >
>> > _______________________________________________
>> > squid-users mailing list
>> > squid-users at lists.squid-cache.org
>> <mailto:squid-users at lists.squid-cache.org>
>> > http://lists.squid-cache.org/listinfo/squid-users
>>
>> > _______________________________________________
>> > squid-users mailing list
>> > squid-users at lists.squid-cache.org
>> <mailto:squid-users at lists.squid-cache.org>
>> > http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> <mailto:squid-users at lists.squid-cache.org>
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>
>
>

-- 
Bugs to the Future
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170418/e77804f9/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170418/e77804f9/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170418/e77804f9/attachment.sig>

From oliver at lennox-it.uk  Tue Apr 18 14:17:20 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Tue, 18 Apr 2017 14:17:20 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <bcb5461b-09be-9c9e-f6fb-ac0babd607a0@gmail.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <1123675527.318473.1492175196442@mail.yahoo.com>
 <1759621537.629779.1492207188325@mail.yahoo.com>
 <d09589e1-9c03-67b6-8ef9-a43538da750c@treenet.co.nz>
 <394541827.1187028.1492331446922@mail.yahoo.com>
 <72028742.2640554.1492519597289@mail.yahoo.com>
 <8b05527e-0890-993c-2f0b-aa4333354295@gmail.com>
 <1319111330.2659089.1492520191012@mail.yahoo.com>
 <cad1fc14-3f0e-3eb0-7ae2-523f7b552506@gmail.com>
 <1954807168.2701725.1492522550674@mail.yahoo.com>
 <bcb5461b-09be-9c9e-f6fb-ac0babd607a0@gmail.com>
Message-ID: <1779924576.2690948.1492525040924@mail.yahoo.com>

Thanks Yuri! The Mozilla Bundle has worked!! Most of the major sites seem to be working which is all we need. How often do these certificates refresh? Would they need updating every month or so??oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252

      From: Yuri Voinov <yvoinov at gmail.com>
 To: Olly Lennox <oliver at lennox-it.uk>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Tuesday, 18 April 2017, 14:43
 Subject: Re: [squid-users] HTTPS woes
   
 You talked about two different things. 1. root CA usually built-in in clients. For standalone use, root CA (from Mozilla) usually distributes with openssl distributions. If you need (or your openssl distribution does not contains root CAs), you can find separately distributed Mozilla CA's by short googling: 
  https://www.google.com/search?q=Mozilla+CA+bundle 2. Intermediate CA's is subordinate for roots CA. It does not exists by gouverned repository (because of supporting it is work, manual work and should be do by somebody), moreover, it spreaded across CA authorities. There is no automated tool to support this _intermediate_list. The problem also: intermediate CA's usuallu has much short validity period instead of roots, and should supports all time at time. Finally - it you want to use Squid with SSL Bump, you should understand PKI infrastructure and yes - you should support root CA & intermediate CAs on proxy by yourself all time. There is no free or payment basis service which is do it for you.
  
 18.04.2017 19:35, Olly Lennox ?????:
  
  So anyone who wants to use Squid over HTTPS in the way has to build this repository themselves by manually downloading all the CA bundles? ? 
  
 
        From: Yuri <yvoinov at gmail.com>
 To: Olly Lennox <oliver at lennox-it.uk>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Tuesday, 18 April 2017, 14:03
 Subject: Re: [squid-users] HTTPS woes
  
   
  
 18.04.2017 18:56, Olly Lennox ?????:
  
  I'm using? 
  sslproxy_foreign_intermediate_certs 
  Is this the same thing? 
   
 No. You firstly required CA roots available for squid. CA roots and intermediate is the different things.
 
  
  Also is there anywhere to get a bundle of all the major CA intermdiate certs or do you have to download them all manually?  
 No. You should build it by yourself. 
 
  
  Cheers, ? oliver at lennox-it.uk
 lennox-it.uk
 tel: 07900 648 252 
 
         From: Yuri <yvoinov at gmail.com>
 To: squid-users at lists.squid-cache.org 
 Sent: Tuesday, 18 April 2017, 13:51
 Subject: Re: [squid-users] HTTPS woes
  
 Try to specify roots CA bundle/dir explicity by specifying one of this 
 params:
 
 
 #? TAG: sslproxy_cafile
 #? ? file containing CA certificates to use when verifying server
 #? ? certificates while proxying https:// URLs
 #Default:
 # none
 
 #? TAG: sslproxy_capath
 #? ? directory containing CA certificates to use when verifying
 #? ? server certificates while proxying https:// URLs
 #Default:
 # none
 
 
 
 18.04.2017 18:46, Olly Lennox ?????:
 > Hi All,
 >
 > Still having problems here. This is my https config now:
 >
 >
 > ---------------------------------https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt  key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3 dhparams=/etc/squid3/ssl_cert/dhparam.pem
 >
 > acl step1 at_step SslBump1
 > ssl_bump peek step1
 > ssl_bump bump all
 > sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
 > sslproxy_cipherEECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
 >
 > sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/lib/ssl_db -M 4MB
 > sslcrtd_children 8 startup=1 idle=1
 >
 > ---------------------------------
 >
 >
 > I'm running version 3.5.23 with openssl 1.0. I've had to disable libecap because I couldn't build 3.5  with ecap enabled. I'm getting the following error when trying to connect with SSL:
 >
 > ---------------------------------
 >
 > The following error was encountered while trying to retrieve the URL: https://www.google.co.uk/*
 >
 > Failed to establish a secure connection to 216.58.198.67
 >
 > The system returned:
 >
 > (71) Protocol error (TLS code:X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
 > SSL Certficate error: certificate issuer (CA) not known: /C=US/O=Equifax/OU=Equifax Secure  Certificate Authority
 >
 > This proxy and the remote host failed to negotiate a mutually acceptable security settings for  handling your request. It is possible that the remote host does not support secure connections, or the proxy is not satisfied with the host security credentials.
 >
 > Your cache administrator is webmaster.
 >
 > Generated Tue, 18 Apr 2017 12:23:40 GMT by raspberrypi (squid/3.5.23)
 > ---------------------------------
 >
 > The CA is always listed as not known not matter what site I try I always get this error.
 >
 > Any ideas?
 >
 > Thanks,
 >
 > Olly
 >
 > ________________________________
 > From: Olly Lennox <oliver at lennox-it.uk>
 > To: Amos Jeffries <squid3 at treenet.co.nz>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org>
 > Sent: Sunday, 16 April 2017, 9:31
 > Subject: Re: [squid-users] HTTPS woes
 >
 >
 >
 > Thanks Amos, it's finally built but I had to disabled ecap, for whatever reason this kept failing  (with version 1.0.1 installed). It failed on a reference to the Area function I think but I don't have the error message copied. I'm trying now to configure the ssl stare/peek  and will let you know how it goes.
 >
 > Olly
 >? 
 > oliver at lennox-it.uk
 > lennox-it.uk
 > tel: 07900 648 252
 >
 >
 >
 > ________________________________
 > From: Amos Jeffries <squid3 at treenet.co.nz>
 > To: squid-users at lists.squid-cache.org
 > Sent: Saturday, 15 April 2017, 23:07
 > Subject: Re: [squid-users] HTTPS woes
 >
 >
 >
 > On 15/04/2017 9:59 a.m., Olly Lennox wrote:
 >> Hi Guys.
 >> I'm still struggling with this. I'm trying to build a version of 3.5 but I just can't get it to  work. I'm currently attempting to rebuild the stretch package with SSL enabled but build keeps failing with the following:
 >> ../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not declared in this scope typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:83:61: error: template argument 3 is  invalid typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^../../src/ssl/gadgets.h:89:53: error: ?CRYPTO_LOCK_EVP_PKEY? was not declared in this scope typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^~~~~~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:89:73: error: template argument 3 is  invalid typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not declared in this scope typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^~~~~~~~~~~~~~~../../src/ssl/gadgets.h:116:58: error: template argument 3 is  invalid typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^
 >> Any ideas?
 >
 >
 > On Jesse/stable:
 >
 > apt-get build-dep squid3
 > apt-get install libss-dev
 >
 >
 > On stretch/testing/unstable:
 >
 > apt-get build-dep squid
 > apt-get install libss1.0-dev
 >
 >
 > That should do it for you.
 >
 > Amos
 >
 >
 > _______________________________________________
 > squid-users mailing list
 > squid-users at lists.squid-cache.org
 > http://lists.squid-cache.org/listinfo/squid-users
 >
 >
 >
 > _______________________________________________
 > squid-users mailing list
 > squid-users at lists.squid-cache.org
 > http://lists.squid-cache.org/listinfo/squid-users 
 > _______________________________________________
 > squid-users mailing list
 > squid-users at lists.squid-cache.org
 > http://lists.squid-cache.org/listinfo/squid-users
 
 
_______________________________________________
 squid-users mailing list
 squid-users at lists.squid-cache.org
 http://lists.squid-cache.org/listinfo/squid-users
   
 
      
 
    
 
      
 
 -- 
 Bugs to the Future 

   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170418/88600b4e/attachment.htm>

From yvoinov at gmail.com  Tue Apr 18 14:59:28 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Tue, 18 Apr 2017 20:59:28 +0600
Subject: [squid-users] HTTPS woes
In-Reply-To: <1779924576.2690948.1492525040924@mail.yahoo.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <1123675527.318473.1492175196442@mail.yahoo.com>
 <1759621537.629779.1492207188325@mail.yahoo.com>
 <d09589e1-9c03-67b6-8ef9-a43538da750c@treenet.co.nz>
 <394541827.1187028.1492331446922@mail.yahoo.com>
 <72028742.2640554.1492519597289@mail.yahoo.com>
 <8b05527e-0890-993c-2f0b-aa4333354295@gmail.com>
 <1319111330.2659089.1492520191012@mail.yahoo.com>
 <cad1fc14-3f0e-3eb0-7ae2-523f7b552506@gmail.com>
 <1954807168.2701725.1492522550674@mail.yahoo.com>
 <bcb5461b-09be-9c9e-f6fb-ac0babd607a0@gmail.com>
 <1779924576.2690948.1492525040924@mail.yahoo.com>
Message-ID: <29fb1aea-2e43-4033-380a-a913261f4668@gmail.com>

I have automated cron job to refresh Mozilla CA's bundle by monthly basis.

Intermediate CA's, however, requires non-scheduled maintenance. I've
maintain it by demand.


18.04.2017 20:17, Olly Lennox ?????:
> Thanks Yuri! The Mozilla Bundle has worked!! Most of the major sites
> seem to be working which is all we need. How often do these
> certificates refresh? Would they need updating every month or so?
>  
> oliver at lennox-it.uk
> lennox-it.uk <http://lennox-it.uk/>
> tel: 07900 648 252
>
>
> ------------------------------------------------------------------------
> *From:* Yuri Voinov <yvoinov at gmail.com>
> *To:* Olly Lennox <oliver at lennox-it.uk>;
> "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org>
> *Sent:* Tuesday, 18 April 2017, 14:43
> *Subject:* Re: [squid-users] HTTPS woes
>
> You talked about two different things.
> 1. root CA usually built-in in clients. For standalone use, root CA
> (from Mozilla) usually distributes with openssl distributions. If you
> need (or your openssl distribution does not contains root CAs), you
> can find separately distributed Mozilla CA's by short googling:
> https://www.google.com/search?q=Mozilla+CA+bundle
> 2. Intermediate CA's is subordinate for roots CA. It does not exists
> by gouverned repository (because of supporting it is work, manual work
> and should be do by somebody), moreover, it spreaded across CA
> authorities. There is no automated tool to support this
> _intermediate_list. The problem also: intermediate CA's usuallu has
> much short validity period instead of roots, and should supports all
> time at time.
> Finally - it you want to use Squid with SSL Bump, you should
> understand PKI infrastructure and yes - you should support root CA &
> intermediate CAs on proxy by yourself all time. There is no free or
> payment basis service which is do it for you.
>
> 18.04.2017 19:35, Olly Lennox ?????:
>> So anyone who wants to use Squid over HTTPS in the way has to build
>> this repository themselves by manually downloading all the CA bundles?
>>  
>>
>>
>>
>> ------------------------------------------------------------------------
>> *From:* Yuri <yvoinov at gmail.com> <mailto:yvoinov at gmail.com>
>> *To:* Olly Lennox <oliver at lennox-it.uk> <mailto:oliver at lennox-it.uk>;
>> "squid-users at lists.squid-cache.org"
>> <mailto:squid-users at lists.squid-cache.org>
>> <squid-users at lists.squid-cache.org>
>> <mailto:squid-users at lists.squid-cache.org>
>> *Sent:* Tuesday, 18 April 2017, 14:03
>> *Subject:* Re: [squid-users] HTTPS woes
>>
>>
>>
>> 18.04.2017 18:56, Olly Lennox ?????:
>>> I'm using 
>>>
>>> sslproxy_foreign_intermediate_certs
>>>
>>> Is this the same thing?
>> No. You firstly required CA roots available for squid. CA roots and
>> intermediate is the different things.
>>>
>>> Also is there anywhere to get a bundle of all the major CA
>>> intermdiate certs or do you have to download them all manually?
>> No. You should build it by yourself.
>>
>>>
>>> Cheers,
>>>  
>>> oliver at lennox-it.uk <mailto:oliver at lennox-it.uk>
>>> lennox-it.uk <http://lennox-it.uk/>
>>> tel: 07900 648 252
>>>
>>>
>>> ------------------------------------------------------------------------
>>> *From:* Yuri <yvoinov at gmail.com> <mailto:yvoinov at gmail.com>
>>> *To:* squid-users at lists.squid-cache.org
>>> <mailto:squid-users at lists.squid-cache.org>
>>> *Sent:* Tuesday, 18 April 2017, 13:51
>>> *Subject:* Re: [squid-users] HTTPS woes
>>>
>>> Try to specify roots CA bundle/dir explicity by specifying one of this
>>> params:
>>>
>>>
>>> #  TAG: sslproxy_cafile
>>> #    file containing CA certificates to use when verifying server
>>> #    certificates while proxying https:// URLs
>>> #Default:
>>> # none
>>>
>>> #  TAG: sslproxy_capath
>>> #    directory containing CA certificates to use when verifying
>>> #    server certificates while proxying https:// URLs
>>> #Default:
>>> # none
>>>
>>>
>>>
>>> 18.04.2017 18:46, Olly Lennox ?????:
>>> > Hi All,
>>> >
>>> > Still having problems here. This is my https config now:
>>> >
>>> >
>>> > ---------------------------------https_port 3129 intercept
>>> ssl-bump generate-host-certificates=on
>>> dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt
>>> key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3
>>> dhparams=/etc/squid3/ssl_cert/dhparam.pem
>>> >
>>> > acl step1 at_step SslBump1
>>> > ssl_bump peek step1
>>> > ssl_bump bump all
>>> > sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>>> > sslproxy_cipher
>>> EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>>> >
>>> > sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/lib/ssl_db -M 4MB
>>> > sslcrtd_children 8 startup=1 idle=1
>>> >
>>> > ---------------------------------
>>> >
>>> >
>>> > I'm running version 3.5.23 with openssl 1.0. I've had to disable
>>> libecap because I couldn't build 3.5 with ecap enabled. I'm getting
>>> the following error when trying to connect with SSL:
>>> >
>>> > ---------------------------------
>>> >
>>> > The following error was encountered while trying to retrieve the
>>> URL: https://www.google.co.uk/*
>>> >
>>> > Failed to establish a secure connection to 216.58.198.67
>>> >
>>> > The system returned:
>>> >
>>> > (71) Protocol error (TLS code:
>>> X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
>>> > SSL Certficate error: certificate issuer (CA) not known:
>>> /C=US/O=Equifax/OU=Equifax Secure Certificate Authority
>>> >
>>> > This proxy and the remote host failed to negotiate a mutually
>>> acceptable security settings for handling your request. It is
>>> possible that the remote host does not support secure connections,
>>> or the proxy is not satisfied with the host security credentials.
>>> >
>>> > Your cache administrator is webmaster.
>>> >
>>> > Generated Tue, 18 Apr 2017 12:23:40 GMT by raspberrypi (squid/3.5.23)
>>> > ---------------------------------
>>> >
>>> > The CA is always listed as not known not matter what site I try I
>>> always get this error.
>>> >
>>> > Any ideas?
>>> >
>>> > Thanks,
>>> >
>>> > Olly
>>> >
>>> > ________________________________
>>> > From: Olly Lennox <oliver at lennox-it.uk <mailto:oliver at lennox-it.uk>>
>>> > To: Amos Jeffries <squid3 at treenet.co.nz
>>> <mailto:squid3 at treenet.co.nz>>; "squid-users at lists.squid-cache.org
>>> <mailto:squid-users at lists.squid-cache.org>"
>>> <squid-users at lists.squid-cache.org
>>> <mailto:squid-users at lists.squid-cache.org>>
>>> > Sent: Sunday, 16 April 2017, 9:31
>>> > Subject: Re: [squid-users] HTTPS woes
>>> >
>>> >
>>> >
>>> > Thanks Amos, it's finally built but I had to disabled ecap, for
>>> whatever reason this kept failing (with version 1.0.1 installed). It
>>> failed on a reference to the Area function I think but I don't have
>>> the error message copied. I'm trying now to configure the ssl
>>> stare/peek and will let you know how it goes.
>>> >
>>> > Olly
>>> > 
>>> > oliver at lennox-it.uk <mailto:oliver at lennox-it.uk>
>>> > lennox-it.uk
>>> > tel: 07900 648 252
>>> >
>>> >
>>> >
>>> > ________________________________
>>> > From: Amos Jeffries <squid3 at treenet.co.nz
>>> <mailto:squid3 at treenet.co.nz>>
>>> > To: squid-users at lists.squid-cache.org
>>> <mailto:squid-users at lists.squid-cache.org>
>>> > Sent: Saturday, 15 April 2017, 23:07
>>> > Subject: Re: [squid-users] HTTPS woes
>>> >
>>> >
>>> >
>>> > On 15/04/2017 9:59 a.m., Olly Lennox wrote:
>>> >> Hi Guys.
>>> >> I'm still struggling with this. I'm trying to build a version of
>>> 3.5 but I just can't get it to work. I'm currently attempting to
>>> rebuild the stretch package with SSL enabled but build keeps failing
>>> with the following:
>>> >> ../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not
>>> declared in this scope typedef LockingPointer<X509, X509_free_cpp,
>>> CRYPTO_LOCK_X509> X509_Pointer;                                     
>>>       ^~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:83:61: error: template
>>> argument 3 is invalid typedef LockingPointer<X509, X509_free_cpp,
>>> CRYPTO_LOCK_X509> X509_Pointer;                                     
>>>                       ^../../src/ssl/gadgets.h:89:53: error:
>>> ?CRYPTO_LOCK_EVP_PKEY? was not declared in this scope typedef
>>> LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY>
>>> EVP_PKEY_Pointer;                                                   
>>> ^~~~~~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:89:73: error: template
>>> argument 3 is invalid typedef LockingPointer<EVP_PKEY,
>>> EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;         
>>>                                                              
>>> ^../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not
>>> declared in this scope typedef LockingPointer<SSL, SSL_free_cpp,
>>> CRYPTO_LOCK_SSL> SSL_Pointer;                                       
>>>   ^~~~~~~~~~~~~~~../../src/ssl/gadgets.h:116:58: error: template
>>> argument 3 is invalid typedef LockingPointer<SSL, SSL_free_cpp,
>>> CRYPTO_LOCK_SSL> SSL_Pointer;                                       
>>>                   ^
>>> >> Any ideas?
>>> >
>>> >
>>> > On Jesse/stable:
>>> >
>>> > apt-get build-dep squid3
>>> > apt-get install libss-dev
>>> >
>>> >
>>> > On stretch/testing/unstable:
>>> >
>>> > apt-get build-dep squid
>>> > apt-get install libss1.0-dev
>>> >
>>> >
>>> > That should do it for you.
>>> >
>>> > Amos
>>> >
>>> >
>>> > _______________________________________________
>>> > squid-users mailing list
>>> > squid-users at lists.squid-cache.org
>>> <mailto:squid-users at lists.squid-cache.org>
>>> > http://lists.squid-cache.org/listinfo/squid-users
>>> >
>>> >
>>> >
>>> > _______________________________________________
>>> > squid-users mailing list
>>> > squid-users at lists.squid-cache.org
>>> <mailto:squid-users at lists.squid-cache.org>
>>> > http://lists.squid-cache.org/listinfo/squid-users
>>>
>>> > _______________________________________________
>>> > squid-users mailing list
>>> > squid-users at lists.squid-cache.org
>>> <mailto:squid-users at lists.squid-cache.org>
>>> > http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> <mailto:squid-users at lists.squid-cache.org>
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>
>>
>>
>
> -- 
> Bugs to the Future
>
>

-- 
Bugs to the Future
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170418/a588205a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170418/a588205a/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170418/a588205a/attachment.sig>

From oliver at lennox-it.uk  Tue Apr 18 15:10:08 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Tue, 18 Apr 2017 15:10:08 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <29fb1aea-2e43-4033-380a-a913261f4668@gmail.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <1123675527.318473.1492175196442@mail.yahoo.com>
 <1759621537.629779.1492207188325@mail.yahoo.com>
 <d09589e1-9c03-67b6-8ef9-a43538da750c@treenet.co.nz>
 <394541827.1187028.1492331446922@mail.yahoo.com>
 <72028742.2640554.1492519597289@mail.yahoo.com>
 <8b05527e-0890-993c-2f0b-aa4333354295@gmail.com>
 <1319111330.2659089.1492520191012@mail.yahoo.com>
 <cad1fc14-3f0e-3eb0-7ae2-523f7b552506@gmail.com>
 <1954807168.2701725.1492522550674@mail.yahoo.com>
 <bcb5461b-09be-9c9e-f6fb-ac0babd607a0@gmail.com>
 <1779924576.2690948.1492525040924@mail.yahoo.com>
 <29fb1aea-2e43-4033-380a-a913261f4668@gmail.com>
Message-ID: <1349286026.2749280.1492528208940@mail.yahoo.com>

Would you mind sharing the script you use??oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252

      From: Yuri Voinov <yvoinov at gmail.com>
 To: Olly Lennox <oliver at lennox-it.uk>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Tuesday, 18 April 2017, 16:00
 Subject: Re: [squid-users] HTTPS woes
   
 I have automated cron job to refresh Mozilla CA's bundle by monthly basis. Intermediate CA's, however, requires non-scheduled maintenance. I've maintain it by demand.
  
 18.04.2017 20:17, Olly Lennox ?????:
  
  Thanks Yuri! The Mozilla Bundle has worked!! Most of the major sites seem to be working which is all we need. How often do these certificates refresh? Would they need updating every month or so? ? oliver at lennox-it.uk
 lennox-it.uk
 tel: 07900 648 252 
 
        From: Yuri Voinov <yvoinov at gmail.com>
 To: Olly Lennox <oliver at lennox-it.uk>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Tuesday, 18 April 2017, 14:43
 Subject: Re: [squid-users] HTTPS woes
  
   You talked about two different things. 1. root CA usually built-in in clients. For standalone use, root CA (from Mozilla) usually distributes with openssl distributions. If you need (or your openssl distribution does not contains root CAs), you can find separately distributed Mozilla CA's by short googling: 
  https://www.google.com/search?q=Mozilla+CA+bundle 2. Intermediate CA's is subordinate for roots CA. It does not exists by gouverned repository (because of supporting it is work, manual work and should be do by somebody), moreover, it spreaded across CA authorities. There is no automated tool to  support this _intermediate_list. The problem also: intermediate CA's usuallu has much short validity period instead of roots, and should supports all time at time. Finally - it you want to use Squid with SSL Bump, you should understand PKI infrastructure and yes - you should support root CA & intermediate CAs on proxy by yourself all time. There is no free or payment basis service which is do it for you.
  
 18.04.2017 19:35, Olly Lennox ?????:
   
  So anyone who wants to use Squid over HTTPS in the way has to build this repository themselves by  manually downloading all the CA bundles? ? 
  
 
         From: Yuri <yvoinov at gmail.com>
 To: Olly Lennox <oliver at lennox-it.uk>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
 Sent: Tuesday, 18 April 2017, 14:03
 Subject: Re: [squid-users] HTTPS woes
  
   
  
 18.04.2017 18:56, Olly Lennox ?????:
  
  I'm using? 
  sslproxy_foreign_intermediate_certs 
  Is this the same thing? 
   
 No. You firstly required CA roots available for squid. CA roots and  intermediate is the different things.
 
  
  Also is there anywhere to get a bundle of all the major CA  intermdiate certs or do you have to download them all manually?  
 No. You should build it by yourself. 
 
  
  Cheers, ? oliver at lennox-it.uk
 lennox-it.uk
 tel: 07900 648 252 
 
         From: Yuri <yvoinov at gmail.com>
 To: squid-users at lists.squid-cache.org 
 Sent: Tuesday, 18 April 2017, 13:51
 Subject: Re: [squid-users] HTTPS woes
  
 Try to specify roots CA bundle/dir  explicity by specifying one of this 
 params:
 
 
 #? TAG: sslproxy_cafile
 #? ? file containing CA certificates to  use when verifying server
 #? ? certificates while proxying https:// URLs
 #Default:
 # none
 
 #? TAG: sslproxy_capath
 #? ? directory containing CA certificates to  use when verifying
 #? ? server certificates while proxying https:// URLs
 #Default:
 # none
 
 
 
 18.04.2017 18:46, Olly Lennox ?????:
 > Hi All,
 >
 > Still having problems here. This is my https  config now:
 >
 >
 > ---------------------------------https_port 3129 intercept  ssl-bump generate-host-certificates=ondynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3 dhparams=/etc/squid3/ssl_cert/dhparam.pem
 >
 > acl step1 at_step SslBump1
 > ssl_bump peek step1
 > ssl_bump bump all
 > sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
 > sslproxy_cipherEECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
 >
 > sslcrtd_program /usr/lib/squid3/ssl_crtd  -s /var/lib/ssl_db -M 4MB
 > sslcrtd_children 8 startup=1 idle=1
 >
 > ---------------------------------
 >
 >
 > I'm running version 3.5.23 with openssl 1.0.  I've had to disable libecap because I couldn't build 3.5 with ecap enabled. I'm  getting the following error when trying to  connect with SSL:
 >
 > ---------------------------------
 >
 > The following error was encountered while  trying to retrieve the URL: https://www.google.co.uk/*
 >
 > Failed to establish a secure connection to  216.58.198.67
 >
 > The system returned:
 >
 > (71) Protocol error (TLS code:X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
 > SSL Certficate error: certificate issuer  (CA) not known: /C=US/O=Equifax/OU=Equifax Secure Certificate Authority
 >
 > This proxy and the remote host failed to  negotiate a mutually acceptable  security settings for handling your  request. It is possible that the remote host does  not support secure connections, or the proxy is not satisfied with the host security  credentials.
 >
 > Your cache administrator is webmaster.
 >
 > Generated Tue, 18 Apr 2017 12:23:40 GMT by  raspberrypi (squid/3.5.23)
 > ---------------------------------
 >
 > The CA is always listed as not known not  matter what site I try I always get this error.
 >
 > Any ideas?
 >
 > Thanks,
 >
 > Olly
 >
 > ________________________________
 > From: Olly Lennox <oliver at lennox-it.uk>
 > To: Amos Jeffries <squid3 at treenet.co.nz>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org>
 > Sent: Sunday, 16 April 2017, 9:31
 > Subject: Re: [squid-users] HTTPS woes
 >
 >
 >
 > Thanks Amos, it's finally built but I had to  disabled ecap, for whatever reason this kept failing (with version 1.0.1 installed).  It failed on a reference to the Area function I think but I don't have the error  message copied. I'm trying now to configure the ssl  stare/peek and will let you know  how it goes.
 >
 > Olly
 >? 
 > oliver at lennox-it.uk
 > lennox-it.uk
 > tel: 07900 648 252
 >
 >
 >
 > ________________________________
 > From: Amos Jeffries <squid3 at treenet.co.nz>
 > To: squid-users at lists.squid-cache.org
 > Sent: Saturday, 15 April 2017, 23:07
 > Subject: Re: [squid-users] HTTPS woes
 >
 >
 >
 > On 15/04/2017 9:59 a.m., Olly Lennox wrote:
 >> Hi Guys.
 >> I'm still struggling with this. I'm trying  to build a version of 3.5 but I just can't get it to work. I'm currently  attempting to rebuild the stretch package  with SSL enabled but build keeps failing with the following:
 >> ../../src/ssl/gadgets.h:83:45: error:  ?CRYPTO_LOCK_X509? was not declared in this scope typedef LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:83:61: error: template  argument 3 is invalid typedef  LockingPointer<X509, X509_free_cpp, CRYPTO_LOCK_X509> X509_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?^../../src/ssl/gadgets.h:89:53: error: ?CRYPTO_LOCK_EVP_PKEY? was not declared in this  scope typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp,CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^~~~~~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:89:73: error: template  argument 3 is invalid typedef  LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp,CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^../../src/ssl/gadgets.h:116:43: error:  ?CRYPTO_LOCK_SSL? was not declared in this scope typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?^~~~~~~~~~~~~~~../../src/ssl/gadgets.h:116:58: error: template argument 3 is invalid  typedef LockingPointer<SSL, SSL_free_cpp, CRYPTO_LOCK_SSL> SSL_Pointer;? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ^
 >> Any ideas?
 >
 >
 > On Jesse/stable:
 >
 > apt-get build-dep squid3
 > apt-get install libss-dev
 >
 >
 > On stretch/testing/unstable:
 >
 > apt-get build-dep squid
 > apt-get install libss1.0-dev
 >
 >
 > That should do it for you.
 >
 > Amos
 >
 >
 > _______________________________________________
 > squid-users mailing list
 > squid-users at lists.squid-cache.org
 > http://lists.squid-cache.org/listinfo/squid-users
 >
 >
 >
 > _______________________________________________
 > squid-users mailing list
 > squid-users at lists.squid-cache.org
 > http://lists.squid-cache.org/listinfo/squid-users 
 > _______________________________________________
 > squid-users mailing list
 > squid-users at lists.squid-cache.org
 > http://lists.squid-cache.org/listinfo/squid-users
 
 
_______________________________________________
 squid-users mailing list
 squid-users at lists.squid-cache.org
 http://lists.squid-cache.org/listinfo/squid-users
   
 
      
 
    
 
      
  
 -- 
 Bugs to the Future   
 
      
 
 -- 
 Bugs to the Future 

   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170418/597e3b89/attachment.htm>

From eliezer at ngtech.co.il  Tue Apr 18 19:45:36 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Tue, 18 Apr 2017 22:45:36 +0300
Subject: [squid-users] Windows Updates a Caching Stub zone,
	A windows updates store.
In-Reply-To: <1492257145655-4682113.post@n4.nabble.com>
References: <004a01d1daf3$e6c4a490$b44dedb0$@ngtech.co.il>
 <1491489566256-4682002.post@n4.nabble.com>
 <05ce01d2aef3$1cb537d0$561fa770$@ngtech.co.il>
 <1492257145655-4682113.post@n4.nabble.com>
Message-ID: <018f01d2b87c$59a02a50$0ce07ef0$@ngtech.co.il>

Did you got my answer?
You should be able to dispatch more  then one fetcher but you should somehow manage them and restrict their amount and dispatch rate.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Omid Kosari
Sent: Saturday, April 15, 2017 2:52 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Windows Updates a Caching Stub zone, A windows updates store.

Hello,

I have sent the files you mentioned to your email 2 days ago . 

A little more investigation shows that some big files (~ 2GB ) are downloading slowly ( ~ 100KBytes/s) while some others downloading very faster. The problem is related to networking (BGP and IXP ) stuff and the fetcher script can not solve that .

But is there a way to run more than one fetcher script at the same time to parallel downloading and not one by one ? There is free bandwidth but fetcher script takes a long time for some downloads .

Thanks again for you support



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Windows-Updates-a-Caching-Stub-zone-A-windows-updates-store-tp4678454p4682113.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From dan at getbusi.com  Wed Apr 19 01:12:24 2017
From: dan at getbusi.com (Dan Charlesworth)
Date: Wed, 19 Apr 2017 11:12:24 +1000
Subject: [squid-users] Access-Control-* headers missing when going through
	squid
Message-ID: <9BA9BBFF-4737-4F5B-8C1B-98BAEBEC7869@getbusi.com>

Hi everyone,

This is a super weird one!

This Pressreader site (http://sheppartonnews.pressreader.com/shepparton-news) gets a totally different (erroneous) response from the server when accessing it through squid on a particular school's network.

It doesn?t happen through any other squid box on any other network I?ve tried, yet at this site you bypass squid through the same gateway and its fine; you use squid and it fails.

The only errors I can see in the browser (that happen when it fails) are CORS errors on several of the requests. Comparing the headers it looks like the erroneous requests lack these from the response:

Access-Control-Allow-Credentials: true
Access-Control-Allow-Origin: http://sheppartonnews.pressreader.com
Access-Control-Expose-Headers: ndstate,X-PD-AProfile,X-PD-Profile,X-PD-Ticket,X-PD-Auth,X-PD-PAuth,X-PD-Token

No, the squid config we?re using never touches headers. Every HTTP/S request from the client is being allowed and is a 200/304 in both situations.

(see attached for the full request response headers)

Make any sense to anyone?

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: erroneous.txt
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170419/f748710e/attachment.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: normal.txt
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170419/f748710e/attachment-0001.txt>

From squid3 at treenet.co.nz  Wed Apr 19 04:21:53 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 19 Apr 2017 16:21:53 +1200
Subject: [squid-users] HTTPS woes
In-Reply-To: <1349286026.2749280.1492528208940@mail.yahoo.com>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <1123675527.318473.1492175196442@mail.yahoo.com>
 <1759621537.629779.1492207188325@mail.yahoo.com>
 <d09589e1-9c03-67b6-8ef9-a43538da750c@treenet.co.nz>
 <394541827.1187028.1492331446922@mail.yahoo.com>
 <72028742.2640554.1492519597289@mail.yahoo.com>
 <8b05527e-0890-993c-2f0b-aa4333354295@gmail.com>
 <1319111330.2659089.1492520191012@mail.yahoo.com>
 <cad1fc14-3f0e-3eb0-7ae2-523f7b552506@gmail.com>
 <1954807168.2701725.1492522550674@mail.yahoo.com>
 <bcb5461b-09be-9c9e-f6fb-ac0babd607a0@gmail.com>
 <1779924576.2690948.1492525040924@mail.yahoo.com>
 <29fb1aea-2e43-4033-380a-a913261f4668@gmail.com>
 <1349286026.2749280.1492528208940@mail.yahoo.com>
Message-ID: <45db6b90-8f31-776e-97d8-452a84e5967a@treenet.co.nz>

Olly,  Debian provides a ca-certificates package containing the Mozilla 
CA list. It is updated whenever the CA set changes. Though of course you 
should have apt connected to the relevant security repository 
(jesse-security?) for regular updates.


Amos

On 19/04/17 03:10, Olly Lennox wrote:
> Would you mind sharing the script you use?
> oliver at lennox-it.uk
> lennox-it.uk <http://lennox-it.uk/>
> tel: 07900 648 252
>
>
> ------------------------------------------------------------------------
> *From:* Yuri Voinov <yvoinov at gmail.com>
> *To:* Olly Lennox <oliver at lennox-it.uk>; 
> "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org>
> *Sent:* Tuesday, 18 April 2017, 16:00
> *Subject:* Re: [squid-users] HTTPS woes
>
> I have automated cron job to refresh Mozilla CA's bundle by monthly basis.
> Intermediate CA's, however, requires non-scheduled maintenance. I've 
> maintain it by demand.
>
> 18.04.2017 20:17, Olly Lennox ?????:
>> Thanks Yuri! The Mozilla Bundle has worked!! Most of the major sites 
>> seem to be working which is all we need. How often do these 
>> certificates refresh? Would they need updating every month or so?
>> oliver at lennox-it.uk <mailto:oliver at lennox-it.uk>
>> lennox-it.uk <http://lennox-it.uk/>
>> tel: 07900 648 252
>>
>>
>> ------------------------------------------------------------------------
>> *From:* Yuri Voinov <yvoinov at gmail.com> <mailto:yvoinov at gmail.com>
>> *To:* Olly Lennox <oliver at lennox-it.uk> <mailto:oliver at lennox-it.uk>; 
>> "squid-users at lists.squid-cache.org" 
>> <mailto:squid-users at lists.squid-cache.org> 
>> <squid-users at lists.squid-cache.org> 
>> <mailto:squid-users at lists.squid-cache.org>
>> *Sent:* Tuesday, 18 April 2017, 14:43
>> *Subject:* Re: [squid-users] HTTPS woes
>>
>> You talked about two different things.
>> 1. root CA usually built-in in clients. For standalone use, root CA 
>> (from Mozilla) usually distributes with openssl distributions. If you 
>> need (or your openssl distribution does not contains root CAs), you 
>> can find separately distributed Mozilla CA's by short googling:
>> https://www.google.com/search?q=Mozilla+CA+bundle
>> 2. Intermediate CA's is subordinate for roots CA. It does not exists 
>> by gouverned repository (because of supporting it is work, manual 
>> work and should be do by somebody), moreover, it spreaded across CA 
>> authorities. There is no automated tool to support this 
>> _intermediate_list. The problem also: intermediate CA's usuallu has 
>> much short validity period instead of roots, and should supports all 
>> time at time.
>> Finally - it you want to use Squid with SSL Bump, you should 
>> understand PKI infrastructure and yes - you should support root CA & 
>> intermediate CAs on proxy by yourself all time. There is no free or 
>> payment basis service which is do it for you.
>>
>> 18.04.2017 19:35, Olly Lennox ?????:
>>> So anyone who wants to use Squid over HTTPS in the way has to build 
>>> this repository themselves by manually downloading all the CA bundles?
>>>
>>>
>>>
>>> ------------------------------------------------------------------------
>>> *From:* Yuri <yvoinov at gmail.com> <mailto:yvoinov at gmail.com>
>>> *To:* Olly Lennox <oliver at lennox-it.uk> 
>>> <mailto:oliver at lennox-it.uk>; "squid-users at lists.squid-cache.org" 
>>> <mailto:squid-users at lists.squid-cache.org> 
>>> <squid-users at lists.squid-cache.org> 
>>> <mailto:squid-users at lists.squid-cache.org>
>>> *Sent:* Tuesday, 18 April 2017, 14:03
>>> *Subject:* Re: [squid-users] HTTPS woes
>>>
>>>
>>>
>>> 18.04.2017 18:56, Olly Lennox ?????:
>>>> I'm using
>>>>
>>>> sslproxy_foreign_intermediate_certs
>>>>
>>>> Is this the same thing?
>>> No. You firstly required CA roots available for squid. CA roots and 
>>> intermediate is the different things.
>>>>
>>>> Also is there anywhere to get a bundle of all the major CA 
>>>> intermdiate certs or do you have to download them all manually?
>>> No. You should build it by yourself.
>>>
>>>>
>>>> Cheers,
>>>> oliver at lennox-it.uk <mailto:oliver at lennox-it.uk>
>>>> lennox-it.uk <http://lennox-it.uk/>
>>>> tel: 07900 648 252
>>>>
>>>>
>>>> ------------------------------------------------------------------------
>>>> *From:* Yuri <yvoinov at gmail.com> <mailto:yvoinov at gmail.com>
>>>> *To:* squid-users at lists.squid-cache.org 
>>>> <mailto:squid-users at lists.squid-cache.org>
>>>> *Sent:* Tuesday, 18 April 2017, 13:51
>>>> *Subject:* Re: [squid-users] HTTPS woes
>>>>
>>>> Try to specify roots CA bundle/dir explicity by specifying one of this
>>>> params:
>>>>
>>>>
>>>> #  TAG: sslproxy_cafile
>>>> #    file containing CA certificates to use when verifying server
>>>> # certificates while proxying https:// URLs
>>>> #Default:
>>>> # none
>>>>
>>>> #  TAG: sslproxy_capath
>>>> #    directory containing CA certificates to use when verifying
>>>> #    server certificates while proxying https:// URLs
>>>> #Default:
>>>> # none
>>>>
>>>>
>>>>
>>>> 18.04.2017 18:46, Olly Lennox ?????:
>>>> > Hi All,
>>>> >
>>>> > Still having problems here. This is my https config now:
>>>> >
>>>> >
>>>> > ---------------------------------https_port 3129 intercept 
>>>> ssl-bump generate-host-certificates=on 
>>>> dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt 
>>>> key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3 
>>>> dhparams=/etc/squid3/ssl_cert/dhparam.pem
>>>> >
>>>> > acl step1 at_step SslBump1
>>>> > ssl_bump peek step1
>>>> > ssl_bump bump all
>>>> > sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>>>> > sslproxy_cipher 
>>>> EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>>>> >
>>>> > sslcrtd_program /usr/lib/squid3/ssl_crtd -s /var/lib/ssl_db -M 4MB
>>>> > sslcrtd_children 8 startup=1 idle=1
>>>> >
>>>> > ---------------------------------
>>>> >
>>>> >
>>>> > I'm running version 3.5.23 with openssl 1.0. I've had to disable 
>>>> libecap because I couldn't build 3.5 with ecap enabled. I'm getting 
>>>> the following error when trying to connect with SSL:
>>>> >
>>>> > ---------------------------------
>>>> >
>>>> > The following error was encountered while trying to retrieve the 
>>>> URL: https://www.google.co.uk/*
>>>> >
>>>> > Failed to establish a secure connection to 216.58.198.67
>>>> >
>>>> > The system returned:
>>>> >
>>>> > (71) Protocol error (TLS code: 
>>>> X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
>>>> > SSL Certficate error: certificate issuer (CA) not known: 
>>>> /C=US/O=Equifax/OU=Equifax Secure Certificate Authority
>>>> >
>>>> > This proxy and the remote host failed to negotiate a mutually 
>>>> acceptable security settings for handling your request. It is 
>>>> possible that the remote host does not support secure connections, 
>>>> or the proxy is not satisfied with the host security credentials.
>>>> >
>>>> > Your cache administrator is webmaster.
>>>> >
>>>> > Generated Tue, 18 Apr 2017 12:23:40 GMT by raspberrypi (squid/3.5.23)
>>>> > ---------------------------------
>>>> >
>>>> > The CA is always listed as not known not matter what site I try I 
>>>> always get this error.
>>>> >
>>>> > Any ideas?
>>>> >
>>>> > Thanks,
>>>> >
>>>> > Olly
>>>> >
>>>> > ________________________________
>>>> > From: Olly Lennox <oliver at lennox-it.uk <mailto:oliver at lennox-it.uk>>
>>>> > To: Amos Jeffries <squid3 at treenet.co.nz 
>>>> <mailto:squid3 at treenet.co.nz>>; "squid-users at lists.squid-cache.org 
>>>> <mailto:squid-users at lists.squid-cache.org>" 
>>>> <squid-users at lists.squid-cache.org 
>>>> <mailto:squid-users at lists.squid-cache.org>>
>>>> > Sent: Sunday, 16 April 2017, 9:31
>>>> > Subject: Re: [squid-users] HTTPS woes
>>>> >
>>>> >
>>>> >
>>>> > Thanks Amos, it's finally built but I had to disabled ecap, for 
>>>> whatever reason this kept failing (with version 1.0.1 installed). 
>>>> It failed on a reference to the Area function I think but I don't 
>>>> have the error message copied. I'm trying now to configure the ssl 
>>>> stare/peek and will let you know how it goes.
>>>> >
>>>> > Olly
>>>> >
>>>> > oliver at lennox-it.uk <mailto:oliver at lennox-it.uk>
>>>> > lennox-it.uk
>>>> > tel: 07900 648 252
>>>> >
>>>> >
>>>> >
>>>> > ________________________________
>>>> > From: Amos Jeffries <squid3 at treenet.co.nz 
>>>> <mailto:squid3 at treenet.co.nz>>
>>>> > To: squid-users at lists.squid-cache.org 
>>>> <mailto:squid-users at lists.squid-cache.org>
>>>> > Sent: Saturday, 15 April 2017, 23:07
>>>> > Subject: Re: [squid-users] HTTPS woes
>>>> >
>>>> >
>>>> >
>>>> > On 15/04/2017 9:59 a.m., Olly Lennox wrote:
>>>> >> Hi Guys.
>>>> >> I'm still struggling with this. I'm trying to build a version of 
>>>> 3.5 but I just can't get it to work. I'm currently attempting to 
>>>> rebuild the stretch package with SSL enabled but build keeps 
>>>> failing with the following:
>>>> >> ../../src/ssl/gadgets.h:83:45: error: ?CRYPTO_LOCK_X509? was not 
>>>> declared in this scope typedef LockingPointer<X509, X509_free_cpp, 
>>>> CRYPTO_LOCK_X509> X509_Pointer; 
>>>> ^~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:83:61: error: template 
>>>> argument 3 is invalid typedef LockingPointer<X509, X509_free_cpp, 
>>>> CRYPTO_LOCK_X509> X509_Pointer; ^../../src/ssl/gadgets.h:89:53: 
>>>> error: ?CRYPTO_LOCK_EVP_PKEY? was not declared in this scope 
>>>> typedef LockingPointer<EVP_PKEY, EVP_PKEY_free_cpp, 
>>>> CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer; 
>>>> ^~~~~~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:89:73: error: template 
>>>> argument 3 is invalid typedef LockingPointer<EVP_PKEY, 
>>>> EVP_PKEY_free_cpp, CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer; 
>>>> ^../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not 
>>>> declared in this scope typedef LockingPointer<SSL, SSL_free_cpp, 
>>>> CRYPTO_LOCK_SSL> SSL_Pointer; 
>>>> ^~~~~~~~~~~~~~~../../src/ssl/gadgets.h:116:58: error: template 
>>>> argument 3 is invalid typedef LockingPointer<SSL, SSL_free_cpp, 
>>>> CRYPTO_LOCK_SSL> SSL_Pointer;     ^
>>>> >> Any ideas?
>>>> >
>>>> >
>>>> > On Jesse/stable:
>>>> >
>>>> > apt-get build-dep squid3
>>>> > apt-get install libss-dev
>>>> >
>>>> >
>>>> > On stretch/testing/unstable:
>>>> >
>>>> > apt-get build-dep squid
>>>> > apt-get install libss1.0-dev
>>>> >
>>>> >
>>>> > That should do it for you.
>>>> >
>>>> > Amos
>>>> >
>>>> >
>>>> > _______________________________________________
>>>> > squid-users mailing list
>>>> > squid-users at lists.squid-cache.org 
>>>> <mailto:squid-users at lists.squid-cache.org>
>>>> > http://lists.squid-cache.org/listinfo/squid-users
>>>> >
>>>> >
>>>> >
>>>> > _______________________________________________
>>>> > squid-users mailing list
>>>> > squid-users at lists.squid-cache.org 
>>>> <mailto:squid-users at lists.squid-cache.org>
>>>> > http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>> > _______________________________________________
>>>> > squid-users mailing list
>>>> > squid-users at lists.squid-cache.org 
>>>> <mailto:squid-users at lists.squid-cache.org>
>>>> > http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org 
>>>> <mailto:squid-users at lists.squid-cache.org>
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>>
>>>
>>>
>>>
>>
>> -- 
>> Bugs to the Future
>>
>>
>
> -- 
> Bugs to the Future
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170419/17159c1c/attachment.htm>

From squid3 at treenet.co.nz  Wed Apr 19 04:41:08 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 19 Apr 2017 16:41:08 +1200
Subject: [squid-users] Access-Control-* headers missing when going
 through squid
In-Reply-To: <9BA9BBFF-4737-4F5B-8C1B-98BAEBEC7869@getbusi.com>
References: <9BA9BBFF-4737-4F5B-8C1B-98BAEBEC7869@getbusi.com>
Message-ID: <0b3b3fb5-5699-f17b-429f-ea790f9babcd@treenet.co.nz>

On 19/04/17 13:12, Dan Charlesworth wrote:
> Hi everyone,
>
> This is a super weird one!
>
> This Pressreader site (http://sheppartonnews.pressreader.com/shepparton-news) gets a totally different (erroneous) response from the server when accessing it through squid on a particular school's network.
>
> It doesn?t happen through any other squid box on any other network I?ve tried, yet at this site you bypass squid through the same gateway and its fine; you use squid and it fails.
>
> The only errors I can see in the browser (that happen when it fails) are CORS errors on several of the requests. Comparing the headers it looks like the erroneous requests lack these from the response:
>
> Access-Control-Allow-Credentials: true
> Access-Control-Allow-Origin: http://sheppartonnews.pressreader.com
> Access-Control-Expose-Headers: ndstate,X-PD-AProfile,X-PD-Profile,X-PD-Ticket,X-PD-Auth,X-PD-PAuth,X-PD-Token
>
> No, the squid config we?re using never touches headers. Every HTTP/S request from the client is being allowed and is a 200/304 in both situations.
>
> (see attached for the full request response headers)
>
> Make any sense to anyone?

Squid does not touch these headers itself unless you configure it to. So 
something there is altering them. It may be external MITM stuff, or 
Squid coping with broken input.

Try adding "debug_options 11,2" to see what is actually arriving and 
leaving that proxy.


Amos



From squid3 at treenet.co.nz  Wed Apr 19 05:38:03 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 19 Apr 2017 17:38:03 +1200
Subject: [squid-users] option to auto-recreate the ssl db ?
In-Reply-To: <e18e5e92-8361-b668-14e1-0ff6c4e4ab50@kalfaoglu.com>
References: <e18e5e92-8361-b668-14e1-0ff6c4e4ab50@kalfaoglu.com>
Message-ID: <927c0cc1-2b5a-a9ba-8bb5-4a34dfd5de79@treenet.co.nz>


On 18/04/17 16:50, turgut kalfao?lu wrote:
> Hi there.. Could we have an option to auto re-create the ssl database?
>
> For some reason, out of nowhere, I start getting these in the cache.log:
> security_file_certgen helper database '/var/lib/ssl_db' failed: Failed 
> to open file /var/lib/ssl_db/index.txt
> security_file_certgen helper database '/var/lib/ssl_db' failed: Failed 
> to open file /var/lib/ssl_db/index.txt
> security_file_certgen helper database '/var/lib/ssl_db' failed: Failed 
> to open file /var/lib/ssl_db/index.txt
> security_file_certgen helper database '/var/lib/ssl_db' failed: Failed 
> to open file /var/lib/ssl_db/index.txt
>

4.0 is beta software. I think its better to find and fix this type of 
problem before it becomes a stable release, yes?

If it happens again can you please make a backup copy of the broken 
/var/lib/ssl_db folder and report a bug. We will need at least tehat 
index.txt fiel attached, the whole-folder backup is just in case the 
person who looks into it needs more data from it. Anything you can 
figure out about the problem and/or that index.txt file would be worth 
mentioning there too.

Thanks
Amos


From turgut at kalfaoglu.com  Wed Apr 19 06:49:59 2017
From: turgut at kalfaoglu.com (=?UTF-8?Q?turgut_kalfao=c4=9flu?=)
Date: Wed, 19 Apr 2017 09:49:59 +0300
Subject: [squid-users] Unliked SSL cipher
Message-ID: <6db288b5-bce3-67f6-e8ed-b0b53b39bf8e@kalfaoglu.com>

Hi. Can I ask for assistance solving this problem. Many thanks!

Fedora # rpm -qa|grep squid
squid-4.0.17-1.fc25.x86_64
# uname -a
Linux www.kalfaoglu.net 4.10.10-200.fc25.x86_64 #1 SMP Thu Apr 13 
01:11:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux


  ERROR


    The requested URL could not be retrieved

------------------------------------------------------------------------

The following error was encountered while trying to retrieve the URL: 
https://91.198.174.192/*

    *Failed to establish a secure connection to 91.198.174.192*

The system returned:

    (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)

    Handshake with SSL server failed: error:140920F8:SSL
    routines:ssl3_get_server_hello:unknown cipher returned

This proxy and the remote host failed to negotiate a mutually acceptable 
security settings for handling your request. It is possible that the 
remote host does not support secure connections, or the proxy is not 
satisfied with the host security credentials.

Your cache administrator is root 
<mailto:root?subject=CacheErrorInfo%20-%20ERR_SECURE_CONNECT_FAIL&body=CacheHost%3A%20proxy%0D%0AErrPage%3A%20ERR_SECURE_CONNECT_FAIL%0D%0AErr%3A%20%2871%29%20Protocol%20error%0D%0ATimeStamp%3A%20Wed,%2019%20Apr%202017%2006%3A46%3A00%20GMT%0D%0A%0D%0AClientIP%3A%20192.168.1.194%0D%0AServerIP%3A%2091.198.174.192%0D%0A%0D%0AHTTP%20Request%3A%0D%0ACONNECT%20%2F%20HTTP%2F1.1%0AHost%3A%2091.198.174.192%0D%0A%0D%0A%0D%0A>.


------------------------------------------------------------------------

Generated Wed, 19 Apr 2017 06:46:00 GMT by proxy (squid/4.0.17)


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170419/96497fa8/attachment.htm>

From oliver at lennox-it.uk  Wed Apr 19 09:22:12 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Wed, 19 Apr 2017 09:22:12 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <45db6b90-8f31-776e-97d8-452a84e5967a@treenet.co.nz>
References: <53345162.1369836.1492102638758.ref@mail.yahoo.com>
 <53345162.1369836.1492102638758@mail.yahoo.com>
 <f15c4b67-8462-4260-d7c7-1f8dbd3e9b97@gmail.com>
 <bbc3984a-3830-8f45-2100-36c39aae26e0@treenet.co.nz>
 <VI1PR0401MB2685DBDC988BE3E1B87783508F050@VI1PR0401MB2685.eurprd04.prod.outlook.com>
 <1123675527.318473.1492175196442@mail.yahoo.com>
 <1759621537.629779.1492207188325@mail.yahoo.com>
 <d09589e1-9c03-67b6-8ef9-a43538da750c@treenet.co.nz>
 <394541827.1187028.1492331446922@mail.yahoo.com>
 <72028742.2640554.1492519597289@mail.yahoo.com>
 <8b05527e-0890-993c-2f0b-aa4333354295@gmail.com>
 <1319111330.2659089.1492520191012@mail.yahoo.com>
 <cad1fc14-3f0e-3eb0-7ae2-523f7b552506@gmail.com>
 <1954807168.2701725.1492522550674@mail.yahoo.com>
 <bcb5461b-09be-9c9e-f6fb-ac0babd607a0@gmail.com>
 <1779924576.2690948.1492525040924@mail.yahoo.com>
 <29fb1aea-2e43-4033-380a-a913261f4668@gmail.com>
 <1349286026.2749280.1492528208940@mail.yahoo.com>
 <45db6b90-8f31-776e-97d8-452a84e5967a@treenet.co.nz>
Message-ID: <2103521410.3479563.1492593732223@mail.yahoo.com>

Thanks Amos, I'll install this. One last question if I may! Squid is working fine now with both HTTP and HTTPS but for some reason it is refusing to launch on boot. 

It works perfectly when started with "service squid start" but not boot. The error is:
squid.service - LSB: Squid HTTP Proxy version 3.x
   Loaded: loaded (/etc/init.d/squid; generated; vendor preset: enabled)
   Active: failed (Result: resources) since Wed 2017-04-19 10:19:18 BST; 53s ago
     Docs: man:systemd-sysv-generator(8)
  Process: 598 ExecStart=/etc/init.d/squid start (code=exited, status=0/SUCCESS)

Apr 19 10:19:13 raspberrypi (squid-1)[1606]: Ipc::Mem::Segment::open failed to shm_open(/squid-ssl_session_cache.shm): (2) No such file or direct
Apr 19 10:19:13 raspberrypi squid[1283]: Squid Parent: (squid-1) process 1606 exited with status 1
Apr 19 10:19:16 raspberrypi squid[1283]: Squid Parent: (squid-1) process 1633 started
Apr 19 10:19:18 raspberrypi squid[1283]: Squid Parent: (squid-1) process 1633 exited with status 1
Apr 19 10:19:18 raspberrypi squid[1283]: Squid Parent: (squid-1) process 1633 will not be restarted due to repeated, frequent failures
Apr 19 10:19:18 raspberrypi squid[1283]: Exiting due to repeated, frequent failures
Apr 19 10:19:18 raspberrypi systemd[1]: squid.service: Daemon never wrote its PID file. Failing.
Apr 19 10:19:18 raspberrypi systemd[1]: Failed to start LSB: Squid HTTP Proxy version 3.x.
Apr 19 10:19:18 raspberrypi systemd[1]: squid.service: Unit entered failed state.
Apr 19 10:19:18 raspberrypi systemd[1]: squid.service: Failed with result 'resources'.

Any ideas?



________________________________
From: Amos Jeffries <squid3 at treenet.co.nz>
To: squid-users at lists.squid-cache.org 
Sent: Wednesday, 19 April 2017, 5:22
Subject: Re: [squid-users] HTTPS woes



Olly,  Debian provides a ca-certificates package containing the Mozilla CA list. It is updated whenever the CA set changes. Though of course you should have apt connected to the relevant security repository (jesse-security?) for regular updates.


Amos


On 19/04/17 03:10, Olly Lennox wrote:

Would you mind sharing the script you use?
> 
>oliver at lennox-it.uk
>lennox-it.uk
>tel: 07900 648 252
>
>
>
>
>________________________________
> From: Yuri Voinov <yvoinov at gmail.com>
>To: Olly Lennox <oliver at lennox-it.uk>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
>Sent: Tuesday, 18 April 2017, 16:00
>Subject: Re: [squid-users] HTTPS woes
>
>
>
>I have automated cron job to refresh Mozilla CA's bundle by monthly basis.
>Intermediate CA's, however, requires non-scheduled maintenance. I've maintain it by demand.
>
>
>18.04.2017 20:17, Olly Lennox ?????:
>
>Thanks Yuri! The Mozilla Bundle has worked!! Most of the major sites seem to be working which is all we need. How often do these certificates refresh? Would they need updating every month or so?
>> 
>>oliver at lennox-it.uk
>>lennox-it.uk
>>tel: 07900 648 252
>>
>>
>>
>> 
>>________________________________
>> From: Yuri Voinov <yvoinov at gmail.com>
>>To: Olly Lennox <oliver at lennox-it.uk>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
>>Sent: Tuesday, 18 April 2017, 14:43
>>Subject: Re: [squid-users] HTTPS woes
>>
>>
>>
>>You talked about two different things.
>>1. root CA usually built-in in clients. For standalone use, root CA (from Mozilla) usually distributes with openssl distributions. If you need (or your openssl distribution does not contains root CAs), you can find separately distributed Mozilla CA's by short googling: 
>>
>>https://www.google.com/search?q=Mozilla+CA+bundle
>>2. Intermediate CA's is subordinate for roots CA. It does not exists by gouverned repository (because of supporting it is work, manual work and should be do by somebody), moreover, it spreaded across CA authorities. There is no automated tool to support this _intermediate_list. The problem also: intermediate CA's usuallu has much short validity period instead of roots, and should supports all time at time.
>>Finally - it you want to use Squid with SSL Bump, you should understand PKI infrastructure and yes - you should support root CA & intermediate CAs on proxy by yourself all time. There is no free or payment basis service which is do it for you.
>>
>>
>>18.04.2017 19:35, Olly Lennox ?????:
>>
>>So anyone who wants to use Squid over HTTPS in the way has to build this repository themselves by manually downloading all the CA bundles?
>>> 
>>>
>>>
>>>
>>>
>>>
>>> 
>>>________________________________
>>> From: Yuri <yvoinov at gmail.com>
>>>To: Olly Lennox <oliver at lennox-it.uk>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org> 
>>>Sent: Tuesday, 18 April 2017, 14:03
>>>Subject: Re: [squid-users] HTTPS woes
>>>
>>>
>>>
>>>
>>>
>>>
>>>18.04.2017 18:56, Olly Lennox ?????:
>>>
>>>I'm using 
>>>>
>>>>
>>>>sslproxy_foreign_intermediate_certs
>>>>
>>>>
>>>>Is this the same thing? 
>>>>
No. You firstly required CA roots available for squid. CA roots and intermediate is the different things.
>>>
>>>
>>>>
>>>>Also is there anywhere to get a bundle of all the major CA intermdiate certs or do you have to download them all manually?
No. You should build it by yourself. 
>>>
>>>
>>>
>>>>
>>>>Cheers,
>>>> 
>>>>oliver at lennox-it.uk
>>>>lennox-it.uk
>>>>tel: 07900 648
                                       252
>>>>
>>>>
>>>>
>>>> 
>>>>________________________________
>>>> From: Yuri <yvoinov at gmail.com>
>>>>To: squid-users at lists.squid-cache.org 
>>>>Sent: Tuesday, 18 April 2017, 13:51
>>>>Subject: Re: [squid-users] HTTPS woes
>>>>
>>>>
>>>>
>>>>Try to specify roots CA bundle/dir explicity by specifying one of this 
>>>>params:
>>>>
>>>>
>>>>#  TAG:
                                       sslproxy_cafile
>>>>#    file
                                       containing CA
                                       certificates
                                       to use when
                                       verifying
                                       server
>>>>#   
                                       certificates
                                       while proxying https:// URLs
>>>>#Default:
>>>># none
>>>>
>>>>#  TAG:
                                       sslproxy_capath
>>>>#    directory
                                       containing CA
                                       certificates
                                       to use when
                                       verifying
>>>>#    server
                                       certificates
                                       while proxying https:// URLs
>>>>#Default:
>>>># none
>>>>
>>>>
>>>>
>>>>18.04.2017
                                       18:46, Olly
                                       Lennox ?????:
>>>>> Hi All,
>>>>>
>>>>> Still
                                       having
                                       problems here.
                                       This is my
                                       https config
                                       now:
>>>>>
>>>>>
>>>>>
                                       ---------------------------------https_port
                                       3129 intercept
                                       ssl-bump
                                       generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt
                                       key=/etc/squid3/ssl_cert/squid.key
options=NO_SSLv3 dhparams=/etc/squid3/ssl_cert/dhparam.pem
>>>>>
>>>>> acl step1
                                       at_step
                                       SslBump1
>>>>> ssl_bump
                                       peek step1
>>>>> ssl_bump
                                       bump all
>>>>>
                                       sslproxy_options
NO_SSLv2,NO_SSLv3,SINGLE_DH_USE
>>>>>
                                       sslproxy_cipher
EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS
>>>>>
>>>>>
                                       sslcrtd_program
/usr/lib/squid3/ssl_crtd -s /var/lib/ssl_db -M 4MB
>>>>>
                                       sslcrtd_children
                                       8 startup=1
                                       idle=1
>>>>>
>>>>>
                                       ---------------------------------
>>>>>
>>>>>
>>>>> I'm
                                       running
                                       version 3.5.23
                                       with openssl
                                       1.0. I've had
                                       to disable
                                       libecap
                                       because I
                                       couldn't build
                                       3.5 with ecap
                                       enabled. I'm
                                       getting the
                                       following
                                       error when
                                       trying to
                                       connect with
                                       SSL:
>>>>>
>>>>>
                                       ---------------------------------
>>>>>
>>>>> The
                                       following
                                       error was
                                       encountered
                                       while trying
                                       to retrieve
                                       the URL: https://www.google.co.uk/*
>>>>>
>>>>> Failed to
                                       establish a
                                       secure
                                       connection to
                                       216.58.198.67
>>>>>
>>>>> The
                                       system
                                       returned:
>>>>>
>>>>> (71)
                                       Protocol error
                                       (TLS code:
X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
>>>>> SSL
                                       Certficate
                                       error:
                                       certificate
                                       issuer (CA)
                                       not known:
                                       /C=US/O=Equifax/OU=Equifax
                                       Secure
                                       Certificate
                                       Authority
>>>>>
>>>>> This
                                       proxy and the
                                       remote host
                                       failed to
                                       negotiate a
                                       mutually
                                       acceptable
                                       security
                                       settings for
                                       handling your
                                       request. It is
                                       possible that
                                       the remote
                                       host does not
                                       support secure
                                       connections,
                                       or the proxy
                                       is not
                                       satisfied with
                                       the host
                                       security
                                       credentials.
>>>>>
>>>>> Your
                                       cache
                                       administrator
                                       is webmaster.
>>>>>
>>>>> Generated
                                       Tue, 18 Apr
                                       2017 12:23:40
                                       GMT by
                                       raspberrypi
                                       (squid/3.5.23)
>>>>>
                                       ---------------------------------
>>>>>
>>>>> The CA is
                                       always listed
                                       as not known
                                       not matter
                                       what site I
                                       try I always
                                       get this
                                       error.
>>>>>
>>>>> Any
                                       ideas?
>>>>>
>>>>> Thanks,
>>>>>
>>>>> Olly
>>>>>
>>>>>
                                       ________________________________
>>>>> From:
                                       Olly Lennox
                                       <oliver at lennox-it.uk>
>>>>> To: Amos
                                       Jeffries <squid3 at treenet.co.nz>; "squid-users at lists.squid-cache.org" <squid-users at lists.squid-cache.org>
>>>>> Sent:
                                       Sunday, 16
                                       April 2017,
                                       9:31
>>>>> Subject:
                                       Re:
                                       [squid-users]
                                       HTTPS woes
>>>>>
>>>>>
>>>>>
>>>>> Thanks
                                       Amos, it's
                                       finally built
                                       but I had to
                                       disabled ecap,
                                       for whatever
                                       reason this
                                       kept failing
                                       (with version
                                       1.0.1
                                       installed). It
                                       failed on a
                                       reference to
                                       the Area
                                       function I
                                       think but I
                                       don't have the
                                       error message
                                       copied. I'm
                                       trying now to
                                       configure the
                                       ssl stare/peek
                                       and will let
                                       you know how
                                       it goes.
>>>>>
>>>>> Olly
>>>>>  
>>>>> oliver at lennox-it.uk
>>>>>
                                       lennox-it.uk
>>>>> tel:
                                       07900 648 252
>>>>>
>>>>>
>>>>>
>>>>>
                                       ________________________________
>>>>> From:
                                       Amos Jeffries
                                       <squid3 at treenet.co.nz>
>>>>> To: squid-users at lists.squid-cache.org
>>>>> Sent:
                                       Saturday, 15
                                       April 2017,
                                       23:07
>>>>> Subject:
                                       Re:
                                       [squid-users]
                                       HTTPS woes
>>>>>
>>>>>
>>>>>
>>>>> On
                                       15/04/2017
                                       9:59 a.m.,
                                       Olly Lennox
                                       wrote:
>>>>>> Hi
                                       Guys.
>>>>>> I'm
                                       still
                                       struggling
                                       with this. I'm
                                       trying to
                                       build a
                                       version of 3.5
                                       but I just
                                       can't get it
                                       to work. I'm
                                       currently
                                       attempting to
                                       rebuild the
                                       stretch
                                       package with
                                       SSL enabled
                                       but build
                                       keeps failing
                                       with the
                                       following:
>>>>>>
                                       ../../src/ssl/gadgets.h:83:45:
                                       error:
                                       ?CRYPTO_LOCK_X509?
                                       was not
                                       declared in
                                       this scope
                                       typedef
                                       LockingPointer<X509,
                                       X509_free_cpp,
CRYPTO_LOCK_X509> X509_Pointer;                                     
                                            
                                       ^~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:83:61:
                                       error:
                                       template
                                       argument 3 is
                                       invalid
                                       typedef
                                       LockingPointer<X509,
                                       X509_free_cpp,
CRYPTO_LOCK_X509> X509_Pointer;                                     
                                                    
                                              
^../../src/ssl/gadgets.h:89:53: error: ?CRYPTO_LOCK_EVP_PKEY? was not
                                       declared in
                                       this scope
                                       typedef
                                       LockingPointer<EVP_PKEY,
EVP_PKEY_free_cpp,
CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;                             
                                                    
                                              
                                       ^~~~~~~~~~~~~~~~~~~~../../src/ssl/gadgets.h:89:73:
                                       error:
                                       template
                                       argument 3 is
                                       invalid
                                       typedef
                                       LockingPointer<EVP_PKEY,
EVP_PKEY_free_cpp,
CRYPTO_LOCK_EVP_PKEY> EVP_PKEY_Pointer;                             
                                                    
                                                    
                                                    
^../../src/ssl/gadgets.h:116:43: error: ?CRYPTO_LOCK_SSL? was not
                                       declared in
                                       this scope
                                       typedef
                                       LockingPointer<SSL,
                                       SSL_free_cpp,
CRYPTO_LOCK_SSL> SSL_Pointer;                                       
                                        
^~~~~~~~~~~~~~~../../src/ssl/gadgets.h:116:58: error: template argument
                                       3 is invalid
                                       typedef
                                       LockingPointer<SSL,
                                       SSL_free_cpp,
CRYPTO_LOCK_SSL> SSL_Pointer;                                       
                                                    
                                           ^
>>>>>> Any
                                       ideas?
>>>>>
>>>>>
>>>>> On
                                       Jesse/stable:
>>>>>
>>>>> apt-get
                                       build-dep
                                       squid3
>>>>> apt-get
                                       install
                                       libss-dev
>>>>>
>>>>>
>>>>> On
                                       stretch/testing/unstable:
>>>>>
>>>>> apt-get
                                       build-dep
                                       squid
>>>>> apt-get
                                       install
                                       libss1.0-dev
>>>>>
>>>>>
>>>>> That
                                       should do it
                                       for you.
>>>>>
>>>>> Amos
>>>>>
>>>>>
>>>>>
                                       _______________________________________________
>>>>>
                                       squid-users
                                       mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>
>>>>>
>>>>>
>>>>>
                                       _______________________________________________
>>>>>
                                       squid-users
                                       mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> http://lists.squid-cache.org/listinfo/squid-users 
>>>>
>>>>>
                                       _______________________________________________
>>>>>
                                       squid-users
                                       mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>>
>>>>_______________________________________________
>>>>squid-users
                                       mailing list
>>>>squid-users at lists.squid-cache.org
>>>>http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>>
>>>>
>>>
>>>
>>>
>>
>>-- 
>>Bugs to the Future
>>
>>
>
>-- 
>Bugs to the Future
>
>
>
>
>_______________________________________________
squid-users mailing list squid-users at lists.squid-cache.org http://lists.squid-cache.org/listinfo/squid-users 

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From belle at bazuin.nl  Wed Apr 19 10:05:18 2017
From: belle at bazuin.nl (=?windows-1252?Q?L.P.H._van_Belle?=)
Date: Wed, 19 Apr 2017 12:05:18 +0200
Subject: [squid-users] HTTPS woes
In-Reply-To: <2103521410.3479563.1492593732223@mail.yahoo.com>
References: <45db6b90-8f31-776e-97d8-452a84e5967a@treenet.co.nz>
Message-ID: <vmime.58f7365e.6a88.12d3c892e14e93e@ms249-lin-003.rotterdam.bazuin.nl>

Hai, 

Im guess, squid is starting to soon, or there is not /dev/shm 

Check/Try adding, if not already in /etc/fstab 

none      /dev/shm        tmpfs   defaults        0 0 

And reboot the server. 


Or, i dont know and someone else can tell you. ;-) 
But on my jessie with squid 3.5.24+ssl i dont see this problem. 

A small tip about the certificates on debian or ubuntu. 
Install ca-certificates ( apt-get install ca-certificates ) 
And read : https://www.brightbox.com/blog/2014/03/04/add-cacert-ubuntu-debian/ 



Greetz, 

Louis





 

> -----Oorspronkelijk bericht-----
> Van: squid-users 
> [mailto:squid-users-bounces at lists.squid-cache.org] Namens Olly Lennox
> Verzonden: woensdag 19 april 2017 11:22
> Aan: Amos Jeffries; squid-users at lists.squid-cache.org
> Onderwerp: Re: [squid-users] HTTPS woes
> 
> Thanks Amos, I'll install this. One last question if I may! 
> Squid is working fine now with both HTTP and HTTPS but for 
> some reason it is refusing to launch on boot. 
> 
> It works perfectly when started with "service squid start" 
> but not boot. The error is:
> squid.service - LSB: Squid HTTP Proxy version 3.x
>    Loaded: loaded (/etc/init.d/squid; generated; vendor 
> preset: enabled)
>    Active: failed (Result: resources) since Wed 2017-04-19 
> 10:19:18 BST; 53s ago
>      Docs: man:systemd-sysv-generator(8)
>   Process: 598 ExecStart=/etc/init.d/squid start 
> (code=exited, status=0/SUCCESS)
> 
> Apr 19 10:19:13 raspberrypi (squid-1)[1606]: 
> Ipc::Mem::Segment::open failed to 
> shm_open(/squid-ssl_session_cache.shm): (2) No such file or 
> direct Apr 19 10:19:13 raspberrypi squid[1283]: Squid Parent: 
> (squid-1) process 1606 exited with status 1 Apr 19 10:19:16 
> raspberrypi squid[1283]: Squid Parent: (squid-1) process 1633 
> started Apr 19 10:19:18 raspberrypi squid[1283]: Squid 
> Parent: (squid-1) process 1633 exited with status 1 Apr 19 
> 10:19:18 raspberrypi squid[1283]: Squid Parent: (squid-1) 
> process 1633 will not be restarted due to repeated, frequent 
> failures Apr 19 10:19:18 raspberrypi squid[1283]: Exiting due 
> to repeated, frequent failures Apr 19 10:19:18 raspberrypi 
> systemd[1]: squid.service: Daemon never wrote its PID file. Failing.
> Apr 19 10:19:18 raspberrypi systemd[1]: Failed to start LSB: 
> Squid HTTP Proxy version 3.x.
> Apr 19 10:19:18 raspberrypi systemd[1]: squid.service: Unit 
> entered failed state.
> Apr 19 10:19:18 raspberrypi systemd[1]: squid.service: Failed 
> with result 'resources'.
> 
> Any ideas?
> 
> 
> 
> ________________________________
> From: Amos Jeffries <squid3 at treenet.co.nz>
> To: squid-users at lists.squid-cache.org
> Sent: Wednesday, 19 April 2017, 5:22
> Subject: Re: [squid-users] HTTPS woes
> 
> 
> 
> Olly,  Debian provides a ca-certificates package containing 
> the Mozilla CA list. It is updated whenever the CA set 
> changes. Though of course you should have apt connected to 
> the relevant security repository (jesse-security?) for 
> regular updates.
> 
> 
> Amos
> 
> 
> On 19/04/17 03:10, Olly Lennox wrote:
> 
> Would you mind sharing the script you use?
> > 
> >oliver at lennox-it.uk
> >lennox-it.uk
> >tel: 07900 648 252
> >
> 



From oliver at lennox-it.uk  Wed Apr 19 11:24:17 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Wed, 19 Apr 2017 11:24:17 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <vmime.58f7365e.6a88.12d3c892e14e93e@ms249-lin-003.rotterdam.bazuin.nl>
References: <45db6b90-8f31-776e-97d8-452a84e5967a@treenet.co.nz>
 <2103521410.3479563.1492593732223@mail.yahoo.com>
 <vmime.58f7365e.6a88.12d3c892e14e93e@ms249-lin-003.rotterdam.bazuin.nl>
Message-ID: <104419362.3527255.1492601057652@mail.yahoo.com>

Hi Louis,

Thanks a lot for the link, I'll implement that once I get this problem fixed. Sadly the change hasn't worked. My current /etc/fstab looks like this:


proc            /proc           proc    defaults          0       0 
PARTUUID=0d001852-01  /boot           vfat    defaults          0       2 
PARTUUID=0d001852-02  /               ext4    defaults,noatime  0       1 
# a swapfile is not a swap partition, no line here 
#   use  dphys-swapfile swap[on|off]  for that 
tmpfs /cache tmpfs defaults,noatime,nosuid,size=8000m 0 0 
none      /dev/shm        tmpfs  defaults        0 0 

could the existing tmpfs line be causing problems?

oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252



________________________________
From: L. P. H.  van Belle <belle at bazuin.nl>
To: "squid-users at squid-cache. org" <squid-users at squid-cache.org> 
Sent: Wednesday, 19 April 2017, 11:05
Subject: Re: [squid-users] HTTPS woes



Hai, 


Im guess, squid is starting to soon, or there is not /dev/shm 


Check/Try adding, if not already in /etc/fstab 


none      /dev/shm        tmpfs   defaults        0 0 


And reboot the server. 



Or, i dont know and someone else can tell you. ;-) 

But on my jessie with squid 3.5.24+ssl i dont see this problem. 


A small tip about the certificates on debian or ubuntu. 

Install ca-certificates ( apt-get install ca-certificates ) 

And read : https://www.brightbox.com/blog/2014/03/04/add-cacert-ubuntu-debian/ 




Greetz, 


Louis








> -----Oorspronkelijk bericht-----

> Van: squid-users 

> [mailto:squid-users-bounces at lists.squid-cache.org] Namens Olly Lennox

> Verzonden: woensdag 19 april 2017 11:22

> Aan: Amos Jeffries; squid-users at lists.squid-cache.org

> Onderwerp: Re: [squid-users] HTTPS woes

> 

> Thanks Amos, I'll install this. One last question if I may! 

> Squid is working fine now with both HTTP and HTTPS but for 

> some reason it is refusing to launch on boot. 

> 

> It works perfectly when started with "service squid start" 

> but not boot. The error is:

> squid.service - LSB: Squid HTTP Proxy version 3.x

>    Loaded: loaded (/etc/init.d/squid; generated; vendor 

> preset: enabled)

>    Active: failed (Result: resources) since Wed 2017-04-19 

> 10:19:18 BST; 53s ago

>      Docs: man:systemd-sysv-generator(8)

>   Process: 598 ExecStart=/etc/init.d/squid start 

> (code=exited, status=0/SUCCESS)

> 

> Apr 19 10:19:13 raspberrypi (squid-1)[1606]: 

> Ipc::Mem::Segment::open failed to 

> shm_open(/squid-ssl_session_cache.shm): (2) No such file or 

> direct Apr 19 10:19:13 raspberrypi squid[1283]: Squid Parent: 

> (squid-1) process 1606 exited with status 1 Apr 19 10:19:16 

> raspberrypi squid[1283]: Squid Parent: (squid-1) process 1633 

> started Apr 19 10:19:18 raspberrypi squid[1283]: Squid 

> Parent: (squid-1) process 1633 exited with status 1 Apr 19 

> 10:19:18 raspberrypi squid[1283]: Squid Parent: (squid-1) 

> process 1633 will not be restarted due to repeated, frequent 

> failures Apr 19 10:19:18 raspberrypi squid[1283]: Exiting due 

> to repeated, frequent failures Apr 19 10:19:18 raspberrypi 

> systemd[1]: squid.service: Daemon never wrote its PID file. Failing.

> Apr 19 10:19:18 raspberrypi systemd[1]: Failed to start LSB: 

> Squid HTTP Proxy version 3.x.

> Apr 19 10:19:18 raspberrypi systemd[1]: squid.service: Unit 

> entered failed state.

> Apr 19 10:19:18 raspberrypi systemd[1]: squid.service: Failed 

> with result 'resources'.

> 

> Any ideas?

> 

> 

> 

> ________________________________

> From: Amos Jeffries <squid3 at treenet.co.nz>

> To: squid-users at lists.squid-cache.org

> Sent: Wednesday, 19 April 2017, 5:22

> Subject: Re: [squid-users] HTTPS woes

> 

> 

> 

> Olly,  Debian provides a ca-certificates package containing 

> the Mozilla CA list. It is updated whenever the CA set 

> changes. Though of course you should have apt connected to 

> the relevant security repository (jesse-security?) for 

> regular updates.

> 

> 

> Amos

> 

> 

> On 19/04/17 03:10, Olly Lennox wrote:

> 

> Would you mind sharing the script you use?

> > 

> >oliver at lennox-it.uk

> >lennox-it.uk

> >tel: 07900 648 252

> >

> 


_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org

http://lists.squid-cache.org/listinfo/squid-users


From oliver at lennox-it.uk  Wed Apr 19 15:28:46 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Wed, 19 Apr 2017 15:28:46 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <104419362.3527255.1492601057652@mail.yahoo.com>
References: <45db6b90-8f31-776e-97d8-452a84e5967a@treenet.co.nz>
 <2103521410.3479563.1492593732223@mail.yahoo.com>
 <vmime.58f7365e.6a88.12d3c892e14e93e@ms249-lin-003.rotterdam.bazuin.nl>
 <104419362.3527255.1492601057652@mail.yahoo.com>
Message-ID: <1735871564.3698915.1492615726204@mail.yahoo.com>

Never mind I've sorted it! The issue was due to the /var/run directory and the program not being able to create squid.pid. I amended the permissions and seems to be working fine now?oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252

      From: Olly Lennox <oliver at lennox-it.uk>
 To: L. P. H. van Belle <belle at bazuin.nl>; "squid-users at squid-cache. org" <squid-users at squid-cache.org> 
 Sent: Wednesday, 19 April 2017, 12:24
 Subject: Re: [squid-users] HTTPS woes
   
Hi Louis,

Thanks a lot for the link, I'll implement that once I get this problem fixed. Sadly the change hasn't worked. My current /etc/fstab looks like this:


proc? ? ? ? ? ? /proc? ? ? ? ? proc? ? defaults? ? ? ? ? 0? ? ? 0 
PARTUUID=0d001852-01? /boot? ? ? ? ? vfat? ? defaults? ? ? ? ? 0? ? ? 2 
PARTUUID=0d001852-02? /? ? ? ? ? ? ? ext4? ? defaults,noatime? 0? ? ? 1 
# a swapfile is not a swap partition, no line here 
#? use? dphys-swapfile swap[on|off]? for that 
tmpfs /cache tmpfs defaults,noatime,nosuid,size=8000m 0 0 
none? ? ? /dev/shm? ? ? ? tmpfs? defaults? ? ? ? 0 0 

could the existing tmpfs line be causing problems?

oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252



________________________________
From: L. P. H.? van Belle <belle at bazuin.nl>
To: "squid-users at squid-cache. org" <squid-users at squid-cache.org> 
Sent: Wednesday, 19 April 2017, 11:05
Subject: Re: [squid-users] HTTPS woes



Hai, 


Im guess, squid is starting to soon, or there is not /dev/shm 


Check/Try adding, if not already in /etc/fstab 


none? ? ? /dev/shm? ? ? ? tmpfs? defaults? ? ? ? 0 0 


And reboot the server. 



Or, i dont know and someone else can tell you. ;-) 

But on my jessie with squid 3.5.24+ssl i dont see this problem. 


A small tip about the certificates on debian or ubuntu. 

Install ca-certificates ( apt-get install ca-certificates ) 

And read : https://www.brightbox.com/blog/2014/03/04/add-cacert-ubuntu-debian/ 




Greetz, 


Louis








> -----Oorspronkelijk bericht-----

> Van: squid-users 

> [mailto:squid-users-bounces at lists.squid-cache.org] Namens Olly Lennox

> Verzonden: woensdag 19 april 2017 11:22

> Aan: Amos Jeffries; squid-users at lists.squid-cache.org

> Onderwerp: Re: [squid-users] HTTPS woes

> 

> Thanks Amos, I'll install this. One last question if I may! 

> Squid is working fine now with both HTTP and HTTPS but for 

> some reason it is refusing to launch on boot. 

> 

> It works perfectly when started with "service squid start" 

> but not boot. The error is:

> squid.service - LSB: Squid HTTP Proxy version 3.x

>? ? Loaded: loaded (/etc/init.d/squid; generated; vendor 

> preset: enabled)

>? ? Active: failed (Result: resources) since Wed 2017-04-19 

> 10:19:18 BST; 53s ago

>? ? ? Docs: man:systemd-sysv-generator(8)

>? Process: 598 ExecStart=/etc/init.d/squid start 

> (code=exited, status=0/SUCCESS)

> 

> Apr 19 10:19:13 raspberrypi (squid-1)[1606]: 

> Ipc::Mem::Segment::open failed to 

> shm_open(/squid-ssl_session_cache.shm): (2) No such file or 

> direct Apr 19 10:19:13 raspberrypi squid[1283]: Squid Parent: 

> (squid-1) process 1606 exited with status 1 Apr 19 10:19:16 

> raspberrypi squid[1283]: Squid Parent: (squid-1) process 1633 

> started Apr 19 10:19:18 raspberrypi squid[1283]: Squid 

> Parent: (squid-1) process 1633 exited with status 1 Apr 19 

> 10:19:18 raspberrypi squid[1283]: Squid Parent: (squid-1) 

> process 1633 will not be restarted due to repeated, frequent 

> failures Apr 19 10:19:18 raspberrypi squid[1283]: Exiting due 

> to repeated, frequent failures Apr 19 10:19:18 raspberrypi 

> systemd[1]: squid.service: Daemon never wrote its PID file. Failing.

> Apr 19 10:19:18 raspberrypi systemd[1]: Failed to start LSB: 

> Squid HTTP Proxy version 3.x.

> Apr 19 10:19:18 raspberrypi systemd[1]: squid.service: Unit 

> entered failed state.

> Apr 19 10:19:18 raspberrypi systemd[1]: squid.service: Failed 

> with result 'resources'.

> 

> Any ideas?

> 

> 

> 

> ________________________________

> From: Amos Jeffries <squid3 at treenet.co.nz>

> To: squid-users at lists.squid-cache.org

> Sent: Wednesday, 19 April 2017, 5:22

> Subject: Re: [squid-users] HTTPS woes

> 

> 

> 

> Olly,? Debian provides a ca-certificates package containing 

> the Mozilla CA list. It is updated whenever the CA set 

> changes. Though of course you should have apt connected to 

> the relevant security repository (jesse-security?) for 

> regular updates.

> 

> 

> Amos

> 

> 

> On 19/04/17 03:10, Olly Lennox wrote:

> 

> Would you mind sharing the script you use?

> > 

> >oliver at lennox-it.uk

> >lennox-it.uk

> >tel: 07900 648 252

> >

> 


_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org

http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170419/79396af0/attachment.htm>

From squid3 at treenet.co.nz  Wed Apr 19 15:35:29 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 20 Apr 2017 03:35:29 +1200
Subject: [squid-users] Unliked SSL cipher
In-Reply-To: <6db288b5-bce3-67f6-e8ed-b0b53b39bf8e@kalfaoglu.com>
References: <6db288b5-bce3-67f6-e8ed-b0b53b39bf8e@kalfaoglu.com>
Message-ID: <df77a56b-0c41-5f1b-c8ca-6207f1bc00e8@treenet.co.nz>



On 19/04/17 18:49, turgut kalfao?lu wrote:
>
> Hi. Can I ask for assistance solving this problem. Many thanks!
>
> Fedora # rpm -qa|grep squid
> squid-4.0.17-1.fc25.x86_64
> # uname -a
> Linux www.kalfaoglu.net 4.10.10-200.fc25.x86_64 #1 SMP Thu Apr 13 
> 01:11:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
>
>

>   ERROR
>
>
>     The requested URL could not be retrieved
>
> ------------------------------------------------------------------------
>
> The following error was encountered while trying to retrieve the URL: 
> https://91.198.174.192/*
>
>     *Failed to establish a secure connection to 91.198.174.192*
>
> The system returned:
>
>     (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
>
>     Handshake with SSL server failed: error:140920F8:SSL
>     routines:ssl3_get_server_hello:unknown cipher returned
>
>

The OpenSSL library being used by the proxy does not know what the 
cipher(s) being offered by the server is/are. It is probably needing an 
upgrade.

Amos
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170420/6e619c77/attachment.htm>

From dijxie at gmail.com  Wed Apr 19 15:44:43 2017
From: dijxie at gmail.com (dijxie at gmail.com)
Date: Wed, 19 Apr 2017 17:44:43 +0200
Subject: [squid-users] Unliked SSL cipher
In-Reply-To: <6db288b5-bce3-67f6-e8ed-b0b53b39bf8e@kalfaoglu.com>
References: <6db288b5-bce3-67f6-e8ed-b0b53b39bf8e@kalfaoglu.com>
Message-ID: <c290452d-2493-68f7-341b-39f55c2e2cde@gmail.com>

Do you recieve the same error while connecting to  
https://www.wikipedia.org?

If you connect to https://91.198.174.192/* directly, your browser 
schould warn you about ssl issue; that is because of:

CN = *.wikipedia.org

SAN=
*.wikipedia.org
wikipedia.org
*.m.wikipedia.org
*.zero.wikipedia.org
wikimedia.org
*.wikimedia.org
*.m.wikimedia.org
*.planet.wikimedia.org
mediawiki.org

This certificate is not allowed to be used with IP address (which is 
common) and that is the issue I suppose. Certificate is V3 sha256, which 
is... perfectly normal.

On 2017-04-19 08:49, turgut kalfao?lu wrote:
>
> Hi. Can I ask for assistance solving this problem. Many thanks!
>
> Fedora # rpm -qa|grep squid
> squid-4.0.17-1.fc25.x86_64
> # uname -a
> Linux www.kalfaoglu.net 4.10.10-200.fc25.x86_64 #1 SMP Thu Apr 13 
> 01:11:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
>
>
>   ERROR
>
>
>     The requested URL could not be retrieved
>
> ------------------------------------------------------------------------
>
> The following error was encountered while trying to retrieve the URL: 
> https://91.198.174.192/*
>
>     *Failed to establish a secure connection to 91.198.174.192*
>
> The system returned:
>
>     (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
>
>     Handshake with SSL server failed: error:140920F8:SSL
>     routines:ssl3_get_server_hello:unknown cipher returned
>
> This proxy and the remote host failed to negotiate a mutually 
> acceptable security settings for handling your request. It is possible 
> that the remote host does not support secure connections, or the proxy 
> is not satisfied with the host security credentials.
>
> Your cache administrator is root 
> <mailto:root?subject=CacheErrorInfo%20-%20ERR_SECURE_CONNECT_FAIL&body=CacheHost%3A%20proxy%0D%0AErrPage%3A%20ERR_SECURE_CONNECT_FAIL%0D%0AErr%3A%20%2871%29%20Protocol%20error%0D%0ATimeStamp%3A%20Wed,%2019%20Apr%202017%2006%3A46%3A00%20GMT%0D%0A%0D%0AClientIP%3A%20192.168.1.194%0D%0AServerIP%3A%2091.198.174.192%0D%0A%0D%0AHTTP%20Request%3A%0D%0ACONNECT%20%2F%20HTTP%2F1.1%0AHost%3A%2091.198.174.192%0D%0A%0D%0A%0D%0A>.
>
>
> ------------------------------------------------------------------------
>
> Generated Wed, 19 Apr 2017 06:46:00 GMT by proxy (squid/4.0.17)
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-- 



From oliver at lennox-it.uk  Wed Apr 19 16:30:07 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Wed, 19 Apr 2017 16:30:07 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <1735871564.3698915.1492615726204@mail.yahoo.com>
References: <45db6b90-8f31-776e-97d8-452a84e5967a@treenet.co.nz>
 <2103521410.3479563.1492593732223@mail.yahoo.com>
 <vmime.58f7365e.6a88.12d3c892e14e93e@ms249-lin-003.rotterdam.bazuin.nl>
 <104419362.3527255.1492601057652@mail.yahoo.com>
 <1735871564.3698915.1492615726204@mail.yahoo.com>
Message-ID: <1705244303.3763617.1492619407976@mail.yahoo.com>

Sorry it's back,


I've narrowed down the problem, hopefully someone can help. When Squid starts it creates the directory /var/run/squid as user proxy:proxy. 

If I remove this or leave it as is then the application won't launch on subsequent reboots.

If I chown the directory as root:root then the application will launch on boot but proxy:proxy takes back ownership and it won't launch again on subsequent reboots.

I'm guessing this is something to do with the running processes, does anyone know what's going wrong?

Cheers,

Olly


------------
 



Never mind I've sorted it! The issue was due to the /var/run directory and the program not being able to create squid.pid. I amended the permissions and seems to be working fine now
 

Thanks a lot for the link, I'll implement that once I get this problem fixed. Sadly the change hasn't worked. My current /etc/fstab looks like this:


proc            /proc           proc    defaults          0       0 
PARTUUID=0d001852-01  /boot           vfat    defaults          0       2 
PARTUUID=0d001852-02  /               ext4    defaults,noatime  0       1 
# a swapfile is not a swap partition, no line here 
#   use  dphys-swapfile swap[on|off]  for that 
tmpfs /cache tmpfs defaults,noatime,nosuid,size=8000m 0 0 
none      /dev/shm        tmpfs  defaults        0 0 

could the existing tmpfs line be causing problems?

oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252



________________________________
From: L. P. H.  van Belle <belle at bazuin.nl>
To: "squid-users at squid-cache. org" <squid-users at squid-cache.org> 
Sent: Wednesday, 19 April 2017, 11:05
Subject: Re: [squid-users] HTTPS woes



Hai, 


Im guess, squid is starting to soon, or there is not /dev/shm 


Check/Try adding, if not already in /etc/fstab 


none      /dev/shm        tmpfs   defaults        0 0 


And reboot the server. 



Or, i dont know and someone else can tell you. ;-) 

But on my jessie with squid 3.5.24+ssl i dont see this problem. 


A small tip about the certificates on debian or ubuntu. 

Install ca-certificates ( apt-get install ca-certificates ) 

And read : https://www.brightbox.com/blog/2014/03/04/add-cacert-ubuntu-debian/ 




Greetz, 


Louis








> -----Oorspronkelijk bericht-----

> Van: squid-users 

> [mailto:squid-users-bounces at lists.squid-cache.org] Namens Olly Lennox

> Verzonden: woensdag 19 april 2017 11:22

> Aan: Amos Jeffries; squid-users at lists.squid-cache.org

> Onderwerp: Re: [squid-users] HTTPS woes

> 

> Thanks Amos, I'll install this. One last question if I may! 

> Squid is working fine now with both HTTP and HTTPS but for 

> some reason it is refusing to launch on boot. 

> 

> It works perfectly when started with "service squid start" 

> but not boot. The error is:

> squid.service - LSB: Squid HTTP Proxy version 3.x

>    Loaded: loaded (/etc/init.d/squid; generated; vendor 

> preset: enabled)

>    Active: failed (Result: resources) since Wed 2017-04-19 

> 10:19:18 BST; 53s ago

>      Docs: man:systemd-sysv-generator(8)

>   Process: 598 ExecStart=/etc/init.d/squid start 

> (code=exited, status=0/SUCCESS)

> 

> Apr 19 10:19:13 raspberrypi (squid-1)[1606]: 

> Ipc::Mem::Segment::open failed to 

> shm_open(/squid-ssl_session_cache.shm): (2) No such file or 

> direct Apr 19 10:19:13 raspberrypi squid[1283]: Squid Parent: 

> (squid-1) process 1606 exited with status 1 Apr 19 10:19:16 

> raspberrypi squid[1283]: Squid Parent: (squid-1) process 1633 

> started Apr 19 10:19:18 raspberrypi squid[1283]: Squid 

> Parent: (squid-1) process 1633 exited with status 1 Apr 19 

> 10:19:18 raspberrypi squid[1283]: Squid Parent: (squid-1) 

> process 1633 will not be restarted due to repeated, frequent 

> failures Apr 19 10:19:18 raspberrypi squid[1283]: Exiting due 

> to repeated, frequent failures Apr 19 10:19:18 raspberrypi 

> systemd[1]: squid.service: Daemon never wrote its PID file. Failing.

> Apr 19 10:19:18 raspberrypi systemd[1]: Failed to start LSB: 

> Squid HTTP Proxy version 3.x.

> Apr 19 10:19:18 raspberrypi systemd[1]: squid.service: Unit 

> entered failed state.

> Apr 19 10:19:18 raspberrypi systemd[1]: squid.service: Failed 

> with result 'resources'.

> 

> Any ideas?

> 

> 

> 

> ________________________________

> From: Amos Jeffries <squid3 at treenet.co.nz>

> To: squid-users at lists.squid-cache.org

> Sent: Wednesday, 19 April 2017, 5:22

> Subject: Re: [squid-users] HTTPS woes

> 

> 

> 

> Olly,  Debian provides a ca-certificates package containing 

> the Mozilla CA list. It is updated whenever the CA set 

> changes. Though of course you should have apt connected to 

> the relevant security repository (jesse-security?) for 

> regular updates.

> 

> 

> Amos

> 

> 

> On 19/04/17 03:10, Olly Lennox wrote:

> 

> Would you mind sharing the script you use?

> > 

> >oliver at lennox-it.uk

> >lennox-it.uk

> >tel: 07900 648 252

> >

> 


_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org

http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From squid3 at treenet.co.nz  Wed Apr 19 16:39:24 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 20 Apr 2017 04:39:24 +1200
Subject: [squid-users] Unliked SSL cipher
In-Reply-To: <c290452d-2493-68f7-341b-39f55c2e2cde@gmail.com>
References: <6db288b5-bce3-67f6-e8ed-b0b53b39bf8e@kalfaoglu.com>
 <c290452d-2493-68f7-341b-39f55c2e2cde@gmail.com>
Message-ID: <38329215-ec78-37ff-88bd-eeef6046a338@treenet.co.nz>



On 20/04/17 03:44, dijxie at gmail.com wrote:
> Do you recieve the same error while connecting to 
> https://www.wikipedia.org?
>
> If you connect to https://91.198.174.192/* directly, your browser 
> schould warn you about ssl issue; that is because of:
>
> CN = *.wikipedia.org
>
> SAN=
> *.wikipedia.org
> wikipedia.org
> *.m.wikipedia.org
> *.zero.wikipedia.org
> wikimedia.org
> *.wikimedia.org
> *.m.wikimedia.org
> *.planet.wikimedia.org
> mediawiki.org
>
> This certificate is not allowed to be used with IP address (which is 
> common) and that is the issue I suppose. Certificate is V3 sha256, 
> which is... perfectly normal.

Huh? With raw-IP there is no SNI, that is all. The TLS is not getting 
far enough for the HTTPS message inside the encryption to have any 
relevance to the TLS<->Host validation situation.

It is the server cipher being complained about. And with a particular 
"unknown" error rather than the more usual "none negotiable" we see a 
lot of when configs mis-match.

Amos



From squid3 at treenet.co.nz  Wed Apr 19 16:52:46 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 20 Apr 2017 04:52:46 +1200
Subject: [squid-users] HTTPS woes
In-Reply-To: <1705244303.3763617.1492619407976@mail.yahoo.com>
References: <45db6b90-8f31-776e-97d8-452a84e5967a@treenet.co.nz>
 <2103521410.3479563.1492593732223@mail.yahoo.com>
 <vmime.58f7365e.6a88.12d3c892e14e93e@ms249-lin-003.rotterdam.bazuin.nl>
 <104419362.3527255.1492601057652@mail.yahoo.com>
 <1735871564.3698915.1492615726204@mail.yahoo.com>
 <1705244303.3763617.1492619407976@mail.yahoo.com>
Message-ID: <cde17e4d-d046-28bd-f2bf-34ffb538a365@treenet.co.nz>

On 20/04/17 04:30, Olly Lennox wrote:
> Sorry it's back,
>
>
> I've narrowed down the problem, hopefully someone can help. When Squid starts it creates the directory /var/run/squid as user proxy:proxy.
>
> If I remove this or leave it as is then the application won't launch on subsequent reboots.
>
> If I chown the directory as root:root then the application will launch on boot but proxy:proxy takes back ownership and it won't launch again on subsequent reboots.
>
> I'm guessing this is something to do with the running processes, does anyone know what's going wrong?
>

/var/run/squid/* is where the FHS standard requires Squid's run-time 
dynamic data to be stored. The exception on some systems is the PID file 
- though it should really be in there too. The Squid init script on 
Debian is enforcing that.

If you have SELinux on the system it may be breaking access to HTTPS 
related things since the OpenSSL features are not part of Debian 
normally. For example, after initializing the ssl_db directory and 
ensuring it has the correct permissions you may need to run 'restorecon 
-R' on it.

Amos



From eliezer at ngtech.co.il  Wed Apr 19 21:24:01 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Thu, 20 Apr 2017 00:24:01 +0300
Subject: [squid-users] HTTPS woes
In-Reply-To: <1705244303.3763617.1492619407976@mail.yahoo.com>
References: <45db6b90-8f31-776e-97d8-452a84e5967a@treenet.co.nz>
 <2103521410.3479563.1492593732223@mail.yahoo.com>
 <vmime.58f7365e.6a88.12d3c892e14e93e@ms249-lin-003.rotterdam.bazuin.nl>
 <104419362.3527255.1492601057652@mail.yahoo.com>
 <1735871564.3698915.1492615726204@mail.yahoo.com>
 <1705244303.3763617.1492619407976@mail.yahoo.com>
Message-ID: <020901d2b953$43f1cd30$cbd56790$@ngtech.co.il>

What OS are you using?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Olly Lennox
Sent: Wednesday, April 19, 2017 7:30 PM
To: Olly Lennox <oliver at lennox-it.uk>; L. P. H. van Belle <belle at bazuin.nl>; squid-users at squid-cache. org <squid-users at squid-cache.org>
Subject: Re: [squid-users] HTTPS woes

Sorry it's back,


I've narrowed down the problem, hopefully someone can help. When Squid starts it creates the directory /var/run/squid as user proxy:proxy. 

If I remove this or leave it as is then the application won't launch on subsequent reboots.

If I chown the directory as root:root then the application will launch on boot but proxy:proxy takes back ownership and it won't launch again on subsequent reboots.

I'm guessing this is something to do with the running processes, does anyone know what's going wrong?

Cheers,

Olly


------------
 



Never mind I've sorted it! The issue was due to the /var/run directory and the program not being able to create squid.pid. I amended the permissions and seems to be working fine now
 

Thanks a lot for the link, I'll implement that once I get this problem fixed. Sadly the change hasn't worked. My current /etc/fstab looks like this:


proc            /proc           proc    defaults          0       0 
PARTUUID=0d001852-01  /boot           vfat    defaults          0       2 
PARTUUID=0d001852-02  /               ext4    defaults,noatime  0       1 
# a swapfile is not a swap partition, no line here 
#   use  dphys-swapfile swap[on|off]  for that 
tmpfs /cache tmpfs defaults,noatime,nosuid,size=8000m 0 0 
none      /dev/shm        tmpfs  defaults        0 0 

could the existing tmpfs line be causing problems?

oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252



________________________________
From: L. P. H.  van Belle <belle at bazuin.nl>
To: "squid-users at squid-cache. org" <squid-users at squid-cache.org> 
Sent: Wednesday, 19 April 2017, 11:05
Subject: Re: [squid-users] HTTPS woes



Hai, 


Im guess, squid is starting to soon, or there is not /dev/shm 


Check/Try adding, if not already in /etc/fstab 


none      /dev/shm        tmpfs   defaults        0 0 


And reboot the server. 



Or, i dont know and someone else can tell you. ;-) 

But on my jessie with squid 3.5.24+ssl i dont see this problem. 


A small tip about the certificates on debian or ubuntu. 

Install ca-certificates ( apt-get install ca-certificates ) 

And read : https://www.brightbox.com/blog/2014/03/04/add-cacert-ubuntu-debian/ 




Greetz, 


Louis








> -----Oorspronkelijk bericht-----

> Van: squid-users 

> [mailto:squid-users-bounces at lists.squid-cache.org] Namens Olly Lennox

> Verzonden: woensdag 19 april 2017 11:22

> Aan: Amos Jeffries; squid-users at lists.squid-cache.org

> Onderwerp: Re: [squid-users] HTTPS woes

> 

> Thanks Amos, I'll install this. One last question if I may! 

> Squid is working fine now with both HTTP and HTTPS but for 

> some reason it is refusing to launch on boot. 

> 

> It works perfectly when started with "service squid start" 

> but not boot. The error is:

> squid.service - LSB: Squid HTTP Proxy version 3.x

>    Loaded: loaded (/etc/init.d/squid; generated; vendor 

> preset: enabled)

>    Active: failed (Result: resources) since Wed 2017-04-19 

> 10:19:18 BST; 53s ago

>      Docs: man:systemd-sysv-generator(8)

>   Process: 598 ExecStart=/etc/init.d/squid start 

> (code=exited, status=0/SUCCESS)

> 

> Apr 19 10:19:13 raspberrypi (squid-1)[1606]: 

> Ipc::Mem::Segment::open failed to 

> shm_open(/squid-ssl_session_cache.shm): (2) No such file or 

> direct Apr 19 10:19:13 raspberrypi squid[1283]: Squid Parent: 

> (squid-1) process 1606 exited with status 1 Apr 19 10:19:16 

> raspberrypi squid[1283]: Squid Parent: (squid-1) process 1633 

> started Apr 19 10:19:18 raspberrypi squid[1283]: Squid 

> Parent: (squid-1) process 1633 exited with status 1 Apr 19 

> 10:19:18 raspberrypi squid[1283]: Squid Parent: (squid-1) 

> process 1633 will not be restarted due to repeated, frequent 

> failures Apr 19 10:19:18 raspberrypi squid[1283]: Exiting due 

> to repeated, frequent failures Apr 19 10:19:18 raspberrypi 

> systemd[1]: squid.service: Daemon never wrote its PID file. Failing.

> Apr 19 10:19:18 raspberrypi systemd[1]: Failed to start LSB: 

> Squid HTTP Proxy version 3.x.

> Apr 19 10:19:18 raspberrypi systemd[1]: squid.service: Unit 

> entered failed state.

> Apr 19 10:19:18 raspberrypi systemd[1]: squid.service: Failed 

> with result 'resources'.

> 

> Any ideas?

> 

> 

> 

> ________________________________

> From: Amos Jeffries <squid3 at treenet.co.nz>

> To: squid-users at lists.squid-cache.org

> Sent: Wednesday, 19 April 2017, 5:22

> Subject: Re: [squid-users] HTTPS woes

> 

> 

> 

> Olly,  Debian provides a ca-certificates package containing 

> the Mozilla CA list. It is updated whenever the CA set 

> changes. Though of course you should have apt connected to 

> the relevant security repository (jesse-security?) for 

> regular updates.

> 

> 

> Amos

> 

> 

> On 19/04/17 03:10, Olly Lennox wrote:

> 

> Would you mind sharing the script you use?

> > 

> >oliver at lennox-it.uk

> >lennox-it.uk

> >tel: 07900 648 252

> >

> 


_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org

http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From oliver at lennox-it.uk  Wed Apr 19 22:48:44 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Wed, 19 Apr 2017 22:48:44 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <020901d2b953$43f1cd30$cbd56790$@ngtech.co.il>
References: <45db6b90-8f31-776e-97d8-452a84e5967a@treenet.co.nz>
 <2103521410.3479563.1492593732223@mail.yahoo.com>
 <vmime.58f7365e.6a88.12d3c892e14e93e@ms249-lin-003.rotterdam.bazuin.nl>
 <104419362.3527255.1492601057652@mail.yahoo.com>
 <1735871564.3698915.1492615726204@mail.yahoo.com>
 <1705244303.3763617.1492619407976@mail.yahoo.com>
 <020901d2b953$43f1cd30$cbd56790$@ngtech.co.il>
Message-ID: <2043293620.4077015.1492642124107@mail.yahoo.com>

Raspberry Pi (3) / Stretch repository (requird to build 3.5) / Squid  3.5.23

After further investigation the problem is something to do with permissions related to ssl_crtd. I can run squid as root but using the default account (proxy?) it won't run and is giving this error in cache.log:

2017/04/19 23:43:54 kid1| helperOpenServers: Starting 1/8 'ssl_crtd' processes
FATAL: Ipc::Mem::Segment::open failed to shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory


I've checked the file and folder permissions across all aspects of squid and everything I can see is owned by proxy:proxy so not sure where it is failing. My config is now as follows:


acl SSL_ports port 443 
acl Safe_ports port 80        # http 
acl Safe_ports port 21        # ftp 
acl Safe_ports port 443        # https 
acl Safe_ports port 70        # gopher 
acl Safe_ports port 210        # wais 
acl Safe_ports port 1025-65535    # unregistered ports 
acl Safe_ports port 280        # http-mgmt 
acl Safe_ports port 488        # gss-http 
acl Safe_ports port 591        # filemaker 
acl Safe_ports port 777        # multiling http 
acl CONNECT method CONNECT 

http_access deny !Safe_ports 
http_access deny CONNECT !SSL_ports 
http_access allow all 

http_port 3130 

http_port 3128 intercept 
https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3 dhparams=/etc/squid3/ssl_cert/dhparam.pem 

acl step1 at_step SslBump1 
ssl_bump peek step1 
ssl_bump bump all 
sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE 
sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS 
sslproxy_cafile /etc/squid/ssl_cert/mozcacert.pem 

sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/spool/squid_ssldb -M 4MB 
sslcrtd_children 8 startup=1 idle=1 

coredump_dir /var/spool/squid 

# Add any of your own refresh_pattern entries above these. 
refresh_pattern ^ftp:        1440    20%    10080 
refresh_pattern ^gopher:    1440    0%    1440 
refresh_pattern -i (/cgi-bin/|\?) 0    0%    0 
refresh_pattern .        0    20%    4320 

cache_dir ufs /cache 400 16 256 



oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252



________________________________
From: Eliezer Croitoru <eliezer at ngtech.co.il>
To: "'squid-users at squid-cache. org'" <squid-users at squid-cache.org> 
Cc: 'Olly Lennox' <oliver at lennox-it.uk>; 'L. P. H. van Belle' <belle at bazuin.nl>
Sent: Wednesday, 19 April 2017, 22:24
Subject: RE: [squid-users] HTTPS woes



What OS are you using?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Olly Lennox
Sent: Wednesday, April 19, 2017 7:30 PM
To: Olly Lennox <oliver at lennox-it.uk>; L. P. H. van Belle <belle at bazuin.nl>; squid-users at squid-cache. org <squid-users at squid-cache.org>
Subject: Re: [squid-users] HTTPS woes

Sorry it's back,


I've narrowed down the problem, hopefully someone can help. When Squid starts it creates the directory /var/run/squid as user proxy:proxy. 

If I remove this or leave it as is then the application won't launch on subsequent reboots.

If I chown the directory as root:root then the application will launch on boot but proxy:proxy takes back ownership and it won't launch again on subsequent reboots.

I'm guessing this is something to do with the running processes, does anyone know what's going wrong?

Cheers,

Olly


------------




Never mind I've sorted it! The issue was due to the /var/run directory and the program not being able to create squid.pid. I amended the permissions and seems to be working fine now


Thanks a lot for the link, I'll implement that once I get this problem fixed. Sadly the change hasn't worked. My current /etc/fstab looks like this:


proc            /proc           proc    defaults          0       0 
PARTUUID=0d001852-01  /boot           vfat    defaults          0       2 
PARTUUID=0d001852-02  /               ext4    defaults,noatime  0       1 
# a swapfile is not a swap partition, no line here 
#   use  dphys-swapfile swap[on|off]  for that 
tmpfs /cache tmpfs defaults,noatime,nosuid,size=8000m 0 0 
none      /dev/shm        tmpfs  defaults        0 0 

could the existing tmpfs line be causing problems?

oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252



________________________________
From: L. P. H.  van Belle <belle at bazuin.nl>
To: "squid-users at squid-cache. org" <squid-users at squid-cache.org> 
Sent: Wednesday, 19 April 2017, 11:05
Subject: Re: [squid-users] HTTPS woes



Hai, 


Im guess, squid is starting to soon, or there is not /dev/shm 


Check/Try adding, if not already in /etc/fstab 


none      /dev/shm        tmpfs   defaults        0 0 


And reboot the server. 



Or, i dont know and someone else can tell you. ;-) 

But on my jessie with squid 3.5.24+ssl i dont see this problem. 


A small tip about the certificates on debian or ubuntu. 

Install ca-certificates ( apt-get install ca-certificates ) 

And read : https://www.brightbox.com/blog/2014/03/04/add-cacert-ubuntu-debian/ 




Greetz, 


Louis








> -----Oorspronkelijk bericht-----

> Van: squid-users 

> [mailto:squid-users-bounces at lists.squid-cache.org] Namens Olly Lennox

> Verzonden: woensdag 19 april 2017 11:22

> Aan: Amos Jeffries; squid-users at lists.squid-cache.org

> Onderwerp: Re: [squid-users] HTTPS woes

> 

> Thanks Amos, I'll install this. One last question if I may! 

> Squid is working fine now with both HTTP and HTTPS but for 

> some reason it is refusing to launch on boot. 

> 

> It works perfectly when started with "service squid start" 

> but not boot. The error is:

> squid.service - LSB: Squid HTTP Proxy version 3.x

>    Loaded: loaded (/etc/init.d/squid; generated; vendor 

> preset: enabled)

>    Active: failed (Result: resources) since Wed 2017-04-19 

> 10:19:18 BST; 53s ago

>      Docs: man:systemd-sysv-generator(8)

>   Process: 598 ExecStart=/etc/init.d/squid start 

> (code=exited, status=0/SUCCESS)

> 

> Apr 19 10:19:13 raspberrypi (squid-1)[1606]: 

> Ipc::Mem::Segment::open failed to 

> shm_open(/squid-ssl_session_cache.shm): (2) No such file or 

> direct Apr 19 10:19:13 raspberrypi squid[1283]: Squid Parent: 

> (squid-1) process 1606 exited with status 1 Apr 19 10:19:16 

> raspberrypi squid[1283]: Squid Parent: (squid-1) process 1633 

> started Apr 19 10:19:18 raspberrypi squid[1283]: Squid 

> Parent: (squid-1) process 1633 exited with status 1 Apr 19 

> 10:19:18 raspberrypi squid[1283]: Squid Parent: (squid-1) 

> process 1633 will not be restarted due to repeated, frequent 

> failures Apr 19 10:19:18 raspberrypi squid[1283]: Exiting due 

> to repeated, frequent failures Apr 19 10:19:18 raspberrypi 

> systemd[1]: squid.service: Daemon never wrote its PID file. Failing.

> Apr 19 10:19:18 raspberrypi systemd[1]: Failed to start LSB: 

> Squid HTTP Proxy version 3.x.

> Apr 19 10:19:18 raspberrypi systemd[1]: squid.service: Unit 

> entered failed state.

> Apr 19 10:19:18 raspberrypi systemd[1]: squid.service: Failed 

> with result 'resources'.

> 

> Any ideas?

> 

> 

> 

> ________________________________

> From: Amos Jeffries <squid3 at treenet.co.nz>

> To: squid-users at lists.squid-cache.org

> Sent: Wednesday, 19 April 2017, 5:22

> Subject: Re: [squid-users] HTTPS woes

> 

> 

> 

> Olly,  Debian provides a ca-certificates package containing 

> the Mozilla CA list. It is updated whenever the CA set 

> changes. Though of course you should have apt connected to 

> the relevant security repository (jesse-security?) for 

> regular updates.

> 

> 

> Amos

> 

> 

> On 19/04/17 03:10, Olly Lennox wrote:

> 

> Would you mind sharing the script you use?

> > 

> >oliver at lennox-it.uk

> >lennox-it.uk

> >tel: 07900 648 252

> >

> 


_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org

http://lists.squid-cache.org/listinfo/squid-users


_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From rousskov at measurement-factory.com  Wed Apr 19 23:13:33 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 19 Apr 2017 17:13:33 -0600
Subject: [squid-users] HTTPS woes
In-Reply-To: <2043293620.4077015.1492642124107@mail.yahoo.com>
References: <45db6b90-8f31-776e-97d8-452a84e5967a@treenet.co.nz>
 <2103521410.3479563.1492593732223@mail.yahoo.com>
 <vmime.58f7365e.6a88.12d3c892e14e93e@ms249-lin-003.rotterdam.bazuin.nl>
 <104419362.3527255.1492601057652@mail.yahoo.com>
 <1735871564.3698915.1492615726204@mail.yahoo.com>
 <1705244303.3763617.1492619407976@mail.yahoo.com>
 <020901d2b953$43f1cd30$cbd56790$@ngtech.co.il>
 <2043293620.4077015.1492642124107@mail.yahoo.com>
Message-ID: <1a4b2bbf-74fd-b018-a590-3c72a243b3e5@measurement-factory.com>

On 04/19/2017 04:48 PM, Olly Lennox wrote:

> After further investigation the problem is something to do with permissions related to ssl_crtd.

No, it is not (or at least not yet).


> I can run squid as root but using the default account (proxy?) it
> won't run and is giving this error in cache.log:

> 2017/04/19 23:43:54 kid1| helperOpenServers: Starting 1/8 'ssl_crtd' processes
> FATAL: Ipc::Mem::Segment::open failed to shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory

The FATAL line is unrelated to the ssl_crtd line above it (this is one
of several problems with FATAL error handling in Squid).


> I've checked the file and folder permissions across all aspects of
> squid and everything I can see is owned by proxy:proxy so not sure
> where it is failing.

Squid is failing when trying to open a shared memory segment used for
storing SSL sessions. This probably means two things:

1. Your OS environment is not compatible with Squid shared memory needs
(e.g., missing /dev/shm/ or equivalent). More info at
http://wiki.squid-cache.org/Features/SmpScale#Ipc::Mem::Segment::create_failed_to_shm_open.28....29:_.282.29_No_such_file_or_directory

2. There is a bug in Squid: Squid should not create shared memory
segments when running in non-SMP mode. Please consider reporting this
bug if it has not been reported already. At the expense of losing SSL
session resumption capabilities, you should be able to work around this
bug by disabling the session cache:
http://www.squid-cache.org/Doc/config/sslproxy_session_cache_size/


HTH,

Alex.


> acl SSL_ports port 443 
> acl Safe_ports port 80        # http 
> acl Safe_ports port 21        # ftp 
> acl Safe_ports port 443        # https 
> acl Safe_ports port 70        # gopher 
> acl Safe_ports port 210        # wais 
> acl Safe_ports port 1025-65535    # unregistered ports 
> acl Safe_ports port 280        # http-mgmt 
> acl Safe_ports port 488        # gss-http 
> acl Safe_ports port 591        # filemaker 
> acl Safe_ports port 777        # multiling http 
> acl CONNECT method CONNECT 
> 
> http_access deny !Safe_ports 
> http_access deny CONNECT !SSL_ports 
> http_access allow all 
> 
> http_port 3130 
> 
> http_port 3128 intercept 
> https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3 dhparams=/etc/squid3/ssl_cert/dhparam.pem 
> 
> acl step1 at_step SslBump1 
> ssl_bump peek step1 
> ssl_bump bump all 
> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE 
> sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS 
> sslproxy_cafile /etc/squid/ssl_cert/mozcacert.pem 
> 
> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/spool/squid_ssldb -M 4MB 
> sslcrtd_children 8 startup=1 idle=1 
> 
> coredump_dir /var/spool/squid 
> 
> # Add any of your own refresh_pattern entries above these. 
> refresh_pattern ^ftp:        1440    20%    10080 
> refresh_pattern ^gopher:    1440    0%    1440 
> refresh_pattern -i (/cgi-bin/|\?) 0    0%    0 
> refresh_pattern .        0    20%    4320 
> 
> cache_dir ufs /cache 400 16 256 



From oliver at lennox-it.uk  Wed Apr 19 23:35:38 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Wed, 19 Apr 2017 23:35:38 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <1a4b2bbf-74fd-b018-a590-3c72a243b3e5@measurement-factory.com>
References: <45db6b90-8f31-776e-97d8-452a84e5967a@treenet.co.nz>
 <2103521410.3479563.1492593732223@mail.yahoo.com>
 <vmime.58f7365e.6a88.12d3c892e14e93e@ms249-lin-003.rotterdam.bazuin.nl>
 <104419362.3527255.1492601057652@mail.yahoo.com>
 <1735871564.3698915.1492615726204@mail.yahoo.com>
 <1705244303.3763617.1492619407976@mail.yahoo.com>
 <020901d2b953$43f1cd30$cbd56790$@ngtech.co.il>
 <2043293620.4077015.1492642124107@mail.yahoo.com>
 <1a4b2bbf-74fd-b018-a590-3c72a243b3e5@measurement-factory.com>
Message-ID: <57862982.49199.1492644938626@mail.yahoo.com>

Hi Alex,


Thanks for your response. I can confirm that disabling the ssl sesison cache seems to have resolved the issue. I found another post which references this patch to resolve the issue:

http://www.squid-cache.org/Versions/v4/changesets/squid-4-13984.patch

I've checked the source in main.cc and this seems quite different to what I have in 3.5.23 so I guess it would involve an upgrade to version 4? After the blood and tears I have gone through to get 3.5 working I don't think I'm read to make that leap yet!!

I check and the /dev/shm directory does exist with 777 permissions so from what I can see the OS should support it. I'm out of my depth here so maybe there is more to it but I can't see why squid couldn't write to this location. 
oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252



________________________________
From: Alex Rousskov <rousskov at measurement-factory.com>
To: "'squid-users at squid-cache. org'" <squid-users at squid-cache.org> 
Cc: Olly Lennox <oliver at lennox-it.uk>
Sent: Thursday, 20 April 2017, 0:13
Subject: Re: [squid-users] HTTPS woes



On 04/19/2017 04:48 PM, Olly Lennox wrote:

> After further investigation the problem is something to do with permissions related to ssl_crtd.

No, it is not (or at least not yet).


> I can run squid as root but using the default account (proxy?) it
> won't run and is giving this error in cache.log:

> 2017/04/19 23:43:54 kid1| helperOpenServers: Starting 1/8 'ssl_crtd' processes
> FATAL: Ipc::Mem::Segment::open failed to shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory

The FATAL line is unrelated to the ssl_crtd line above it (this is one
of several problems with FATAL error handling in Squid).


> I've checked the file and folder permissions across all aspects of
> squid and everything I can see is owned by proxy:proxy so not sure
> where it is failing.

Squid is failing when trying to open a shared memory segment used for
storing SSL sessions. This probably means two things:

1. Your OS environment is not compatible with Squid shared memory needs
(e.g., missing /dev/shm/ or equivalent). More info at
http://wiki.squid-cache.org/Features/SmpScale#Ipc::Mem::Segment::create_failed_to_shm_open.28....29:_.282.29_No_such_file_or_directory

2. There is a bug in Squid: Squid should not create shared memory
segments when running in non-SMP mode. Please consider reporting this
bug if it has not been reported already. At the expense of losing SSL
session resumption capabilities, you should be able to work around this
bug by disabling the session cache:
http://www.squid-cache.org/Doc/config/sslproxy_session_cache_size/


HTH,

Alex.



> acl SSL_ports port 443 
> acl Safe_ports port 80        # http 
> acl Safe_ports port 21        # ftp 
> acl Safe_ports port 443        # https 
> acl Safe_ports port 70        # gopher 
> acl Safe_ports port 210        # wais 
> acl Safe_ports port 1025-65535    # unregistered ports 
> acl Safe_ports port 280        # http-mgmt 
> acl Safe_ports port 488        # gss-http 
> acl Safe_ports port 591        # filemaker 
> acl Safe_ports port 777        # multiling http 
> acl CONNECT method CONNECT 
> 
> http_access deny !Safe_ports 
> http_access deny CONNECT !SSL_ports 
> http_access allow all 
> 
> http_port 3130 
> 
> http_port 3128 intercept 
> https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3 dhparams=/etc/squid3/ssl_cert/dhparam.pem 
> 
> acl step1 at_step SslBump1 
> ssl_bump peek step1 
> ssl_bump bump all 
> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE 
> sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS 
> sslproxy_cafile /etc/squid/ssl_cert/mozcacert.pem 
> 
> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/spool/squid_ssldb -M 4MB 
> sslcrtd_children 8 startup=1 idle=1 
> 
> coredump_dir /var/spool/squid 
> 
> # Add any of your own refresh_pattern entries above these. 
> refresh_pattern ^ftp:        1440    20%    10080 
> refresh_pattern ^gopher:    1440    0%    1440 
> refresh_pattern -i (/cgi-bin/|\?) 0    0%    0 
> refresh_pattern .        0    20%    4320 
> 
> cache_dir ufs /cache 400 16 256 


From rousskov at measurement-factory.com  Thu Apr 20 00:21:05 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 19 Apr 2017 18:21:05 -0600
Subject: [squid-users] HTTPS woes
In-Reply-To: <57862982.49199.1492644938626@mail.yahoo.com>
References: <45db6b90-8f31-776e-97d8-452a84e5967a@treenet.co.nz>
 <2103521410.3479563.1492593732223@mail.yahoo.com>
 <vmime.58f7365e.6a88.12d3c892e14e93e@ms249-lin-003.rotterdam.bazuin.nl>
 <104419362.3527255.1492601057652@mail.yahoo.com>
 <1735871564.3698915.1492615726204@mail.yahoo.com>
 <1705244303.3763617.1492619407976@mail.yahoo.com>
 <020901d2b953$43f1cd30$cbd56790$@ngtech.co.il>
 <2043293620.4077015.1492642124107@mail.yahoo.com>
 <1a4b2bbf-74fd-b018-a590-3c72a243b3e5@measurement-factory.com>
 <57862982.49199.1492644938626@mail.yahoo.com>
Message-ID: <145ccebd-a726-eb72-3f4a-536cae5fa050@measurement-factory.com>

On 04/19/2017 05:35 PM, Olly Lennox wrote:

> I can confirm that disabling the ssl sesison cache seems to have resolved the issue.

Great!


> I found another post which references this patch to resolve the issue:
> http://www.squid-cache.org/Versions/v4/changesets/squid-4-13984.patch

I am not sure that patch is related to any issues I have talked about.
What "another post" did you find?


> I check and the /dev/shm directory does exist with 777 permissions so
> from what I can see the OS should support it. I'm out of my depth
> here so maybe there is more to it but I can't see why squid couldn't
> write to this location.

Forget about my "OS environment is not compatible" theory (at least for
now). I now see that Squid is failing while trying to _open_ that memory
segment as opposed to failing while _creating_ it.

Did Squid try to create it? Set debug_options to "ALL,3 54,9" and search
for "shm_" and "ssl_session_cache" in cache.log for more clues.

Alex.



> ________________________________
> From: Alex Rousskov <rousskov at measurement-factory.com>
> To: "'squid-users at squid-cache. org'" <squid-users at squid-cache.org> 
> Cc: Olly Lennox <oliver at lennox-it.uk>
> Sent: Thursday, 20 April 2017, 0:13
> Subject: Re: [squid-users] HTTPS woes
> 
> 
> 
> On 04/19/2017 04:48 PM, Olly Lennox wrote:
> 
>> After further investigation the problem is something to do with permissions related to ssl_crtd.
> 
> No, it is not (or at least not yet).
> 
> 
>> I can run squid as root but using the default account (proxy?) it
>> won't run and is giving this error in cache.log:
> 
>> 2017/04/19 23:43:54 kid1| helperOpenServers: Starting 1/8 'ssl_crtd' processes
>> FATAL: Ipc::Mem::Segment::open failed to shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
> 
> The FATAL line is unrelated to the ssl_crtd line above it (this is one
> of several problems with FATAL error handling in Squid).
> 
> 
>> I've checked the file and folder permissions across all aspects of
>> squid and everything I can see is owned by proxy:proxy so not sure
>> where it is failing.
> 
> Squid is failing when trying to open a shared memory segment used for
> storing SSL sessions. This probably means two things:
> 
> 1. Your OS environment is not compatible with Squid shared memory needs
> (e.g., missing /dev/shm/ or equivalent). More info at
> http://wiki.squid-cache.org/Features/SmpScale#Ipc::Mem::Segment::create_failed_to_shm_open.28....29:_.282.29_No_such_file_or_directory
> 
> 2. There is a bug in Squid: Squid should not create shared memory
> segments when running in non-SMP mode. Please consider reporting this
> bug if it has not been reported already. At the expense of losing SSL
> session resumption capabilities, you should be able to work around this
> bug by disabling the session cache:
> http://www.squid-cache.org/Doc/config/sslproxy_session_cache_size/
> 
> 
> HTH,
> 
> Alex.
> 
> 
> 
>> acl SSL_ports port 443 
>> acl Safe_ports port 80        # http 
>> acl Safe_ports port 21        # ftp 
>> acl Safe_ports port 443        # https 
>> acl Safe_ports port 70        # gopher 
>> acl Safe_ports port 210        # wais 
>> acl Safe_ports port 1025-65535    # unregistered ports 
>> acl Safe_ports port 280        # http-mgmt 
>> acl Safe_ports port 488        # gss-http 
>> acl Safe_ports port 591        # filemaker 
>> acl Safe_ports port 777        # multiling http 
>> acl CONNECT method CONNECT 
>>
>> http_access deny !Safe_ports 
>> http_access deny CONNECT !SSL_ports 
>> http_access allow all 
>>
>> http_port 3130 
>>
>> http_port 3128 intercept 
>> https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3 dhparams=/etc/squid3/ssl_cert/dhparam.pem 
>>
>> acl step1 at_step SslBump1 
>> ssl_bump peek step1 
>> ssl_bump bump all 
>> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE 
>> sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS 
>> sslproxy_cafile /etc/squid/ssl_cert/mozcacert.pem 
>>
>> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/spool/squid_ssldb -M 4MB 
>> sslcrtd_children 8 startup=1 idle=1 
>>
>> coredump_dir /var/spool/squid 
>>
>> # Add any of your own refresh_pattern entries above these. 
>> refresh_pattern ^ftp:        1440    20%    10080 
>> refresh_pattern ^gopher:    1440    0%    1440 
>> refresh_pattern -i (/cgi-bin/|\?) 0    0%    0 
>> refresh_pattern .        0    20%    4320 
>>
>> cache_dir ufs /cache 400 16 256 



From dan at getbusi.com  Thu Apr 20 02:07:54 2017
From: dan at getbusi.com (Dan Charlesworth)
Date: Thu, 20 Apr 2017 12:07:54 +1000
Subject: [squid-users] Access-Control-* headers missing when going
 through squid
In-Reply-To: <0b3b3fb5-5699-f17b-429f-ea790f9babcd@treenet.co.nz>
References: <9BA9BBFF-4737-4F5B-8C1B-98BAEBEC7869@getbusi.com>
 <0b3b3fb5-5699-f17b-429f-ea790f9babcd@treenet.co.nz>
Message-ID: <19319EAE-FF7D-432D-B712-C3086D37ACFD@getbusi.com>

Thanks Amos.

As far as I can tell the only device upstream of the proxy is a relatively basic gateway/firewall. I doubt it's capable of messing with HTTP headers (and loading the site directly, as opposed to using the proxy lets it load fine behind the same gateway).

I?ve attached the debug output you suggested. Looks like the headers in the browser are the same as what arriving and leaving the proxy?



Best,
Dan

> On 19 Apr 2017, at 2:41 pm, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> Squid does not touch these headers itself unless you configure it to. So something there is altering them. It may be external MITM stuff, or Squid coping with broken input.
> 
> Try adding "debug_options 11,2" to see what is actually arriving and leaving that proxy.
> 
> 
> Amos

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170420/b69b3484/attachment.htm>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: pr-squid-debug-erroneous.txt
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170420/b69b3484/attachment.txt>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170420/b69b3484/attachment-0001.htm>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: pr-squid-debug-normal.txt
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170420/b69b3484/attachment-0001.txt>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170420/b69b3484/attachment-0002.htm>

From turgut at kalfaoglu.com  Thu Apr 20 04:44:21 2017
From: turgut at kalfaoglu.com (=?UTF-8?Q?turgut_kalfao=c4=9flu?=)
Date: Thu, 20 Apr 2017 07:44:21 +0300
Subject: [squid-users] Unliked SSL cipher
In-Reply-To: <c290452d-2493-68f7-341b-39f55c2e2cde@gmail.com>
References: <6db288b5-bce3-67f6-e8ed-b0b53b39bf8e@kalfaoglu.com>
 <c290452d-2493-68f7-341b-39f55c2e2cde@gmail.com>
Message-ID: <7964d10c-f91d-58f6-e20c-3585c1a35edc@kalfaoglu.com>

On 04/19/2017 06:44 PM, dijxie at gmail.com wrote:
> Do you recieve the same error while connecting to 
> https://www.wikipedia.org?
Yes I do.

I also tried to connect to the IP address as well; and that gives me the 
same error.
The browser didn't say anything; it was squid that complained.
Regards,
  -turgut


>
> If you connect to https://91.198.174.192/* directly, your browser 
> schould warn you about ssl issue; that is because of:
>
> CN = *.wikipedia.org
>
> SAN=
> *.wikipedia.org
> wikipedia.org
> *.m.wikipedia.org
> *.zero.wikipedia.org
> wikimedia.org
> *.wikimedia.org
> *.m.wikimedia.org
> *.planet.wikimedia.org
> mediawiki.org
>
> This certificate is not allowed to be used with IP address (which is 
> common) and that is the issue I suppose. Certificate is V3 sha256, 
> which is... perfectly normal.
>
> On 2017-04-19 08:49, turgut kalfao?lu wrote:
>>
>> Hi. Can I ask for assistance solving this problem. Many thanks!
>>
>> Fedora # rpm -qa|grep squid
>> squid-4.0.17-1.fc25.x86_64
>> # uname -a
>> Linux www.kalfaoglu.net 4.10.10-200.fc25.x86_64 #1 SMP Thu Apr 13 
>> 01:11:51 UTC 2017 x86_64 x86_64 x86_64 GNU/Linux
>>
>>
>>   ERROR
>>
>>
>>     The requested URL could not be retrieved
>>
>> ------------------------------------------------------------------------
>>
>> The following error was encountered while trying to retrieve the URL: 
>> https://91.198.174.192/*
>>
>>     *Failed to establish a secure connection to 91.198.174.192*
>>
>> The system returned:
>>
>>     (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
>>
>>     Handshake with SSL server failed: error:140920F8:SSL
>>     routines:ssl3_get_server_hello:unknown cipher returned
>>
>> This proxy and the remote host failed to negotiate a mutually 
>> acceptable security settings for handling your request. It is 
>> possible that the remote host does not support secure connections, or 
>> the proxy is not satisfied with the host security credentials.
>>
>> Your cache administrator is root 
>> <mailto:root?subject=CacheErrorInfo%20-%20ERR_SECURE_CONNECT_FAIL&body=CacheHost%3A%20proxy%0D%0AErrPage%3A%20ERR_SECURE_CONNECT_FAIL%0D%0AErr%3A%20%2871%29%20Protocol%20error%0D%0ATimeStamp%3A%20Wed,%2019%20Apr%202017%2006%3A46%3A00%20GMT%0D%0A%0D%0AClientIP%3A%20192.168.1.194%0D%0AServerIP%3A%2091.198.174.192%0D%0A%0D%0AHTTP%20Request%3A%0D%0ACONNECT%20%2F%20HTTP%2F1.1%0AHost%3A%2091.198.174.192%0D%0A%0D%0A%0D%0A>.
>>
>>
>> ------------------------------------------------------------------------
>>
>> Generated Wed, 19 Apr 2017 06:46:00 GMT by proxy (squid/4.0.17)
>>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>



From oliver at lennox-it.uk  Thu Apr 20 13:39:10 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Thu, 20 Apr 2017 13:39:10 +0000 (UTC)
Subject: [squid-users] HTTPS woes
In-Reply-To: <145ccebd-a726-eb72-3f4a-536cae5fa050@measurement-factory.com>
References: <45db6b90-8f31-776e-97d8-452a84e5967a@treenet.co.nz>
 <2103521410.3479563.1492593732223@mail.yahoo.com>
 <vmime.58f7365e.6a88.12d3c892e14e93e@ms249-lin-003.rotterdam.bazuin.nl>
 <104419362.3527255.1492601057652@mail.yahoo.com>
 <1735871564.3698915.1492615726204@mail.yahoo.com>
 <1705244303.3763617.1492619407976@mail.yahoo.com>
 <020901d2b953$43f1cd30$cbd56790$@ngtech.co.il>
 <2043293620.4077015.1492642124107@mail.yahoo.com>
 <1a4b2bbf-74fd-b018-a590-3c72a243b3e5@measurement-factory.com>
 <57862982.49199.1492644938626@mail.yahoo.com>
 <145ccebd-a726-eb72-3f4a-536cae5fa050@measurement-factory.com>
Message-ID: <1853580132.454651.1492695550555@mail.yahoo.com>

After two and a bit weeks on this I finally have the Raspberry Pi working as a transparent proxy server utilising Diladele to provide web filtering. I'm going to trial it all for the next few weeks to ensure that it's stable but so far the results have been positive and its working with HTTP and HTTPS across Windows, IOS and Android devices. 

I wanted to say a big thank you to everyone who has responded to my many messages.I'm sure there will be more to come but I wouldn't have got this far without your help so thank you very much. 

FYI the following steps have been necessary:


HTTPS Squid on Raspberry Pi 3:
1. The stretch repositories are required to build squid 3.5 and should be enabled
2. after running apt-get update you should downgrade to openssl v1.0 (from v1.1) to avoid build failures
3. You must disable ecap functionality to avoid build failures, I couldn't get squid 3.5.23 to build with ecap regardless of the version of libecap I used.
4. download the 3.5.23 source from stretch and follow a guide online to configure, make, and install the packages with ssl and ssl_crtd enabled (careful with the flags if you're following a guide for an older version of squid as the syntax changed)
5. follow a guide online to install / configure squid 3.5 - specifically creating the cache folders and setting up ssl_crtd and the ssl cache
6. download the mozilla ca certs bundle (https://curl.haxx.se/ca/cacert.pem or google) which are required for HTTPS to work 
7. ensure sslproxy_session_cache_size is disabled (example config below). Squid will not load on boot with this setting enabled.

8. check permissions across your squid installation (specifically cache, ssl_crtd and cerificate cache/locations) to ensure the proxy:proxy account has access
9. be careful of the runtime directories which are used. The default location on Rpi is /squid3 but this approach will move everything in /squid so be sure that you use the right one in your config
10. Ensure you generate your self-signed CA certificate/key with SHA-256 (as a minimum) to avoid cert failures in the browser. 
11. Bear in mind that your CA certificate will need to be installed/trusted on any device that you wish to use HTTPS on the network

My Config:

acl SSL_ports port 443 
acl Safe_ports port 80        # http 
acl Safe_ports port 21        # ftp 
acl Safe_ports port 443        # https 
acl Safe_ports port 70        # gopher 
acl Safe_ports port 210        # wais 
acl Safe_ports port 1025-65535    # unregistered ports 
acl Safe_ports port 280        # http-mgmt 
acl Safe_ports port 488        # gss-http 
acl Safe_ports port 591        # filemaker 
acl Safe_ports port 777        # multiling http 
acl CONNECT method CONNECT 

http_access deny !Safe_ports 
http_access deny CONNECT !SSL_ports 
http_access allow all 

http_port 3130 
http_port 3128 intercept 
https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3 

acl step1 at_step SslBump1 
ssl_bump peek step1 
ssl_bump bump all 
sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE 
sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS 
sslproxy_cafile /etc/squid/ssl_cert/mozcacert.pem 

sslproxy_session_cache_size 0 
sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/spool/squid_ssldb -M 4MB 
sslcrtd_children 8 startup=1 idle=1 

coredump_dir /var/spool/squid 

# Add any of your own refresh_pattern entries above these. 
refresh_pattern ^ftp:        1440    20%    10080 
refresh_pattern ^gopher:    1440    0%    1440 
refresh_pattern -i (/cgi-bin/|\?) 0    0%    0 
refresh_pattern .        0    20%    4320 

cache_dir ufs /cache 400 16 256 


----------------

It's worth noting that I could not get udhcpd to start on boot with the Raspberry Pi (which seemed to be the recommended DHCP server online) and had to switch to ISC to get DHCP to work. Bind works fine though and the Diladele filter also installed without a hitch so it's only really DHCP that can trip you up. 

Hope this helps someone

Olly

 
oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252



________________________________
From: Alex Rousskov <rousskov at measurement-factory.com>
To: "'squid-users at squid-cache. org'" <squid-users at squid-cache.org> 
Cc: Olly Lennox <oliver at lennox-it.uk>
Sent: Thursday, 20 April 2017, 1:21
Subject: Re: [squid-users] HTTPS woes



On 04/19/2017 05:35 PM, Olly Lennox wrote:

> I can confirm that disabling the ssl sesison cache seems to have resolved the issue.

Great!


> I found another post which references this patch to resolve the issue:
> http://www.squid-cache.org/Versions/v4/changesets/squid-4-13984.patch

I am not sure that patch is related to any issues I have talked about.
What "another post" did you find?


> I check and the /dev/shm directory does exist with 777 permissions so
> from what I can see the OS should support it. I'm out of my depth
> here so maybe there is more to it but I can't see why squid couldn't
> write to this location.

Forget about my "OS environment is not compatible" theory (at least for
now). I now see that Squid is failing while trying to _open_ that memory
segment as opposed to failing while _creating_ it.

Did Squid try to create it? Set debug_options to "ALL,3 54,9" and search
for "shm_" and "ssl_session_cache" in cache.log for more clues.


Alex.



> ________________________________
> From: Alex Rousskov <rousskov at measurement-factory.com>
> To: "'squid-users at squid-cache. org'" <squid-users at squid-cache.org> 
> Cc: Olly Lennox <oliver at lennox-it.uk>
> Sent: Thursday, 20 April 2017, 0:13
> Subject: Re: [squid-users] HTTPS woes
> 
> 
> 
> On 04/19/2017 04:48 PM, Olly Lennox wrote:
> 
>> After further investigation the problem is something to do with permissions related to ssl_crtd.
> 
> No, it is not (or at least not yet).
> 
> 
>> I can run squid as root but using the default account (proxy?) it
>> won't run and is giving this error in cache.log:
> 
>> 2017/04/19 23:43:54 kid1| helperOpenServers: Starting 1/8 'ssl_crtd' processes
>> FATAL: Ipc::Mem::Segment::open failed to shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory
> 
> The FATAL line is unrelated to the ssl_crtd line above it (this is one
> of several problems with FATAL error handling in Squid).
> 
> 
>> I've checked the file and folder permissions across all aspects of
>> squid and everything I can see is owned by proxy:proxy so not sure
>> where it is failing.
> 
> Squid is failing when trying to open a shared memory segment used for
> storing SSL sessions. This probably means two things:
> 
> 1. Your OS environment is not compatible with Squid shared memory needs
> (e.g., missing /dev/shm/ or equivalent). More info at
> http://wiki.squid-cache.org/Features/SmpScale#Ipc::Mem::Segment::create_failed_to_shm_open.28....29:_.282.29_No_such_file_or_directory
> 
> 2. There is a bug in Squid: Squid should not create shared memory
> segments when running in non-SMP mode. Please consider reporting this
> bug if it has not been reported already. At the expense of losing SSL
> session resumption capabilities, you should be able to work around this
> bug by disabling the session cache:
> http://www.squid-cache.org/Doc/config/sslproxy_session_cache_size/
> 
> 
> HTH,
> 
> Alex.
> 
> 
> 
>> acl SSL_ports port 443 
>> acl Safe_ports port 80        # http 
>> acl Safe_ports port 21        # ftp 
>> acl Safe_ports port 443        # https 
>> acl Safe_ports port 70        # gopher 
>> acl Safe_ports port 210        # wais 
>> acl Safe_ports port 1025-65535    # unregistered ports 
>> acl Safe_ports port 280        # http-mgmt 
>> acl Safe_ports port 488        # gss-http 
>> acl Safe_ports port 591        # filemaker 
>> acl Safe_ports port 777        # multiling http 
>> acl CONNECT method CONNECT 
>>
>> http_access deny !Safe_ports 
>> http_access deny CONNECT !SSL_ports 
>> http_access allow all 
>>
>> http_port 3130 
>>
>> http_port 3128 intercept 
>> https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3 dhparams=/etc/squid3/ssl_cert/dhparam.pem 
>>
>> acl step1 at_step SslBump1 
>> ssl_bump peek step1 
>> ssl_bump bump all 
>> sslproxy_options NO_SSLv2,NO_SSLv3,SINGLE_DH_USE 
>> sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS 
>> sslproxy_cafile /etc/squid/ssl_cert/mozcacert.pem 
>>
>> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/spool/squid_ssldb -M 4MB 
>> sslcrtd_children 8 startup=1 idle=1 
>>
>> coredump_dir /var/spool/squid 
>>
>> # Add any of your own refresh_pattern entries above these. 
>> refresh_pattern ^ftp:        1440    20%    10080 
>> refresh_pattern ^gopher:    1440    0%    1440 
>> refresh_pattern -i (/cgi-bin/|\?) 0    0%    0 
>> refresh_pattern .        0    20%    4320 
>>
>> cache_dir ufs /cache 400 16 256 


From cheemeng at function.com  Thu Apr 20 16:16:34 2017
From: cheemeng at function.com (Chee M Gui)
Date: Thu, 20 Apr 2017 09:16:34 -0700
Subject: [squid-users] Squid stopped working after cache.log and
 access.log rotation
In-Reply-To: <097b01d2a418$588f1c70$09ad5550$@ngtech.co.il>
References: <CAMyAatDzxB=+zNcB-jvc8vb+hse44Ne80tiaNUHgT_yQgM1iPg@mail.gmail.com>
 <097b01d2a418$588f1c70$09ad5550$@ngtech.co.il>
Message-ID: <CAMyAatDW3uHp-v6+v8PP_6Rkv0-CjT=iaRLwhWXiUJAinodgfw@mail.gmail.com>

Hi Eliezer

Thank you for the response, and sorry for the late reply.

As requested, here are the output of the commands you suggested:
root at paproxy:/# systemctl status squid
? squid.service - LSB: Squid HTTP Proxy version 3.x
   Loaded: loaded (/etc/init.d/squid; bad; vendor preset: enabled)
   Active: active (running) since Wed 2017-03-15 14:47:53 PDT; 1 months 5
days ago
     Docs: man:systemd-sysv-generator(8)
    Tasks: 4
   Memory: 54.4M
      CPU: 2min 38.957s
   CGroup: /system.slice/squid.service
           ??25482 /usr/sbin/squid -YC -f /etc/squid/squid.conf
           ??25484 (squid-1) -YC -f /etc/squid/squid.conf
           ??25485 (logfile-daemon) /var/log/squid/access.log
           ??25486 (unlinkd)

Warning: Journal has been rotated since unit was started. Log output is
incomplete or unavailable.
root at paproxy:/#



top - 09:11:45 up 54 days, 23:51,  2 users,  load average: 0.00, 0.00, 0.00
Tasks: 141 total,   1 running, 140 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.0 us,  0.0 sy,  0.0 ni, 99.9 id,  0.0 wa,  0.0 hi,  0.0 si,
 0.0 st
KiB Mem :  6043140 total,  4844728 free,   135292 used,  1063120 buff/cache
KiB Swap:  6222844 total,  6222844 free,        0 used.  5556300 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
23355 root      20   0   41668   3776   3236 R   6.7  0.1   0:00.01 top
    1 root      20   0   37884   5968   4020 S   0.0  0.1   0:27.20 systemd
    2 root      20   0       0      0      0 S   0.0  0.0   0:00.22 kthreadd
    3 root      20   0       0      0      0 S   0.0  0.0   0:01.01
ksoftirqd/0
    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
kworker/0:0H
    7 root      20   0       0      0      0 S   0.0  0.0   1:28.65
rcu_sched
    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh
    9 root      rt   0       0      0      0 S   0.0  0.0   0:00.14
migration/0
   10 root      rt   0       0      0      0 S   0.0  0.0   0:05.53
watchdog/0
   11 root      rt   0       0      0      0 S   0.0  0.0   0:05.75
watchdog/1
   12 root      rt   0       0      0      0 S   0.0  0.0   0:00.14
migration/1
   13 root      20   0       0      0      0 S   0.0  0.0   0:02.48
ksoftirqd/1
   15 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
kworker/1:0H
   16 root      20   0       0      0      0 S   0.0  0.0   0:00.00
kdevtmpfs
   17 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 netns
   18 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 perf
   19 root      20   0       0      0      0 S   0.0  0.0   0:01.26
khungtaskd
   20 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
writeback


root at paproxy:/# ps -aux | grep squid
root     23358  0.0  0.0  14224   976 pts/0    S+   09:12   0:00 grep
--color=auto squid
root     25482  0.0  0.1 109272  6416 ?        Ss   Mar15   0:00
/usr/sbin/squid -YC -f /etc/squid/squid.conf
proxy    25484  0.0  0.7 166684 45184 ?        S    Mar15   2:27 (squid-1)
-YC -f /etc/squid/squid.conf
proxy    25485  0.0  0.0  13280  1648 ?        S    Mar15   0:03
(logfile-daemon) /var/log/squid/access.log
root at paproxy:/#


root at paproxy:/# df -h
Filesystem      Size  Used Avail Use% Mounted on
udev            2.9G     0  2.9G   0% /dev
tmpfs           591M   60M  531M  11% /run
/dev/sda1       911G  1.9G  863G   1% /
tmpfs           2.9G   12K  2.9G   1% /dev/shm
tmpfs           5.0M     0  5.0M   0% /run/lock
tmpfs           2.9G     0  2.9G   0% /sys/fs/cgroup
tmpfs           591M     0  591M   0% /run/user/1000
tmpfs           591M     0  591M   0% /run/user/0
root at paproxy:/#



root at paproxy:/# df -h
Filesystem      Size  Used Avail Use% Mounted on
udev            2.9G     0  2.9G   0% /dev
tmpfs           591M   60M  531M  11% /run
/dev/sda1       911G  1.9G  863G   1% /
tmpfs           2.9G   12K  2.9G   1% /dev/shm
tmpfs           5.0M     0  5.0M   0% /run/lock
tmpfs           2.9G     0  2.9G   0% /sys/fs/cgroup
tmpfs           591M     0  591M   0% /run/user/1000
tmpfs           591M     0  591M   0% /run/user/0
root at paproxy:/#


root at paproxy:/# lsof -n|egrep "proxy|squid" | more
squid     25482                  root  cwd       DIR                8,1
4096          2 /
squid     25482                  root  rtd       DIR                8,1
4096          2 /
squid     25482                  root  txt       REG                8,1
 6430816   41946763 /usr/sbin/squid
squid     25482                  root  mem       REG                8,1
 47648   10093387 /lib/x86_64-linux-gnu/libnss_nis-2.23.
so
squid     25482                  root  mem       REG                8,1
 93128   10093399 /lib/x86_64-linux-gnu/libnsl-2.23.so
squid     25482                  root  mem       REG                8,1
 35688   10093400 /lib/x86_64-linux-gnu/libnss_compat-2.
23.so
squid     25482                  root  mem       REG                8,1
 47600   10093403 /lib/x86_64-linux-gnu/libnss_files-2.2
3.so
squid     25482                  root  mem       REG                8,1
25913104   41944015 /usr/lib/x86_64-linux-gnu/libicudata.s
o.55.1
squid     25482                  root  mem       REG                8,1
 22520   10093098 /lib/x86_64-linux-gnu/libmnl.so.0.1.0
squid     25482                  root  mem       REG                8,1
 26248   41948589 /usr/lib/x86_64-linux-gnu/libnfnetlink
.so.0.2.0


Thank you once again

CM



On Thu, Mar 23, 2017 at 1:59 PM, Eliezer Croitoru <eliezer at ngtech.co.il>
wrote:

> There is another option!
> The log rotate script is doing something nasty or the systemd service file
> start up squid in a weird way.
> The output of:
> $ systemctl status squid
> $ top -n1 -b
> $ ps aux
> $ df -h
> $ netstat -ntulp
> $ lsof -n|egrep "proxy|squid"
>
> How many clients this system has?
> Is the system facing the Internet directly or behind some nat(aws or
> another provider)?
>
> The above are the basic required data to understand the situation.
>
> All The Bests,
> Eliezer
>
> ----
> http://ngtech.co.il/lmgtfy/
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Chee M Gui
> Sent: Wednesday, March 22, 2017 5:18 PM
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Squid stopped working after cache.log and
> access.log rotation
>
>
>
> Hi All
>
> We recently installed Squid 3.5.12-1ubuntu7.3 on Ubuntu 16.04.2 LTS.  It
> ran fine at first but stopped working after a while.   telnet server 3128
> still works, i.e., opens a blank window, but Squid is just not accepting
> requests.    Then we realized that there is no new access.log file.   The
> access.log file stopped rotated at 6:24AM on 3/17/2017.    It looks like
> Squid wasn't able to create a new access.log?  We could not find any error
> message in syslog or the cache.log.      We haven't rebooted the server
> because we want to know what went wrong.   It isn't the firewall blocking
> Squid because Squid was working fine all the while until recently.  Also
> after it stopped working, we disabled the firewall to see if it would work
> but it still didn't work.
>
> root at paproxy:/var/log/squid# ls -alt
> total 15536
> drwxr-xr-x 2 proxy proxy      4096 Mar 21 06:25 .
> -rw-r----- 1 proxy proxy        63 Mar 21 06:25 cache.log
> drwxrwxr-x 9 root  syslog     4096 Mar 21 06:25 ..
> -rw-r----- 1 proxy proxy        63 Mar 20 06:25 cache.log.1
> -rw-r----- 1 proxy proxy        83 Mar 19 06:25 cache.log.2.gz
> -rw-r----- 1 proxy proxy  15759111 Mar 17 06:24 access.log.1
> -rw-r----- 1 proxy proxy    117223 Mar 17 05:52 netdb.state
>
> Any ideas what went wrong?
>
> Thank you very much in anticipation.
>
> Gui
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
Chee Meng Gui
Function Engineering
650-833-0660
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170420/90f15222/attachment.htm>

From eliezer at ngtech.co.il  Thu Apr 20 19:24:21 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Thu, 20 Apr 2017 22:24:21 +0300
Subject: [squid-users] Squid stopped working after cache.log and
	access.log rotation
In-Reply-To: <CAMyAatDW3uHp-v6+v8PP_6Rkv0-CjT=iaRLwhWXiUJAinodgfw@mail.gmail.com>
References: <CAMyAatDzxB=+zNcB-jvc8vb+hse44Ne80tiaNUHgT_yQgM1iPg@mail.gmail.com>
 <097b01d2a418$588f1c70$09ad5550$@ngtech.co.il>
 <CAMyAatDW3uHp-v6+v8PP_6Rkv0-CjT=iaRLwhWXiUJAinodgfw@mail.gmail.com>
Message-ID: <02a001d2ba0b$b64f69b0$22ee3d10$@ngtech.co.il>

Hey CM,

>From the output I understand that there wasn't a change in squid packaging for 16.04 and they still use rc\init.d startup scripts.
Also they probably use the same logrotate scripts from very long ago.
We first must understand if squid is running and it seems that systemd sees it as running.
I do not see in lsof output any port listening mentioned so I assume this is the reason for the issue in hands.
The first thing I would do is run a crontab that will check if squid is alive using a cache manager info page fetch and check if it's listening using netstat or ss.
(did you tried to see if squid is listening using netstat or ss??)
The next step would be to check your squid roatate script and to verify it's doing what it suppose to do.
After all this I would recommend changing from the rc\init.d startup script to a real system based one and abandon the old rotation scripts of Ubuntu or fix them.

If you are looking for a fix it's one path and if you are looking to get the work done properly by Ubuntu it's a whole new wagon.
I have been working on squid packages for Ubuntu and Debian that uses system scripts but the packages are not perfected yet.

Let me know the path you want to choose and also your approach to things and I will try to help you with which of the options you will choose to resolve the issues.

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Chee M Gui [mailto:cheemeng at function.com] 
Sent: Thursday, April 20, 2017 7:17 PM
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid stopped working after cache.log and access.log rotation

Hi Eliezer

Thank you for the response, and sorry for the late reply.

As requested, here are the output of the commands you suggested:
root at paproxy:/# systemctl status squid
? squid.service - LSB: Squid HTTP Proxy version 3.x
   Loaded: loaded (/etc/init.d/squid; bad; vendor preset: enabled)
   Active: active (running) since Wed 2017-03-15 14:47:53 PDT; 1 months 5 days ago
     Docs: man:systemd-sysv-generator(8)
    Tasks: 4
   Memory: 54.4M
      CPU: 2min 38.957s
   CGroup: /system.slice/squid.service
           ??25482 /usr/sbin/squid -YC -f /etc/squid/squid.conf
           ??25484 (squid-1) -YC -f /etc/squid/squid.conf
           ??25485 (logfile-daemon) /var/log/squid/access.log
           ??25486 (unlinkd)

Warning: Journal has been rotated since unit was started. Log output is incomplete or unavailable.
root at paproxy:/#



top - 09:11:45 up 54 days, 23:51,  2 users,  load average: 0.00, 0.00, 0.00
Tasks: 141 total,   1 running, 140 sleeping,   0 stopped,   0 zombie
%Cpu(s):  0.0 us,  0.0 sy,  0.0 ni, 99.9 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
KiB Mem :  6043140 total,  4844728 free,   135292 used,  1063120 buff/cache
KiB Swap:  6222844 total,  6222844 free,        0 used.  5556300 avail Mem

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
23355 root      20   0   41668   3776   3236 R   6.7  0.1   0:00.01 top
    1 root      20   0   37884   5968   4020 S   0.0  0.1   0:27.20 systemd
    2 root      20   0       0      0      0 S   0.0  0.0   0:00.22 kthreadd
    3 root      20   0       0      0      0 S   0.0  0.0   0:01.01 ksoftirqd/0
    5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H
    7 root      20   0       0      0      0 S   0.0  0.0   1:28.65 rcu_sched
    8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh
    9 root      rt   0       0      0      0 S   0.0  0.0   0:00.14 migration/0
   10 root      rt   0       0      0      0 S   0.0  0.0   0:05.53 watchdog/0
   11 root      rt   0       0      0      0 S   0.0  0.0   0:05.75 watchdog/1
   12 root      rt   0       0      0      0 S   0.0  0.0   0:00.14 migration/1
   13 root      20   0       0      0      0 S   0.0  0.0   0:02.48 ksoftirqd/1
   15 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/1:0H
   16 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kdevtmpfs
   17 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 netns
   18 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 perf
   19 root      20   0       0      0      0 S   0.0  0.0   0:01.26 khungtaskd
   20 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 writeback


root at paproxy:/# ps -aux | grep squid
root     23358  0.0  0.0  14224   976 pts/0    S+   09:12   0:00 grep --color=auto squid
root     25482  0.0  0.1 109272  6416 ?        Ss   Mar15   0:00 /usr/sbin/squid -YC -f /etc/squid/squid.conf
proxy    25484  0.0  0.7 166684 45184 ?        S    Mar15   2:27 (squid-1) -YC -f /etc/squid/squid.conf
proxy    25485  0.0  0.0  13280  1648 ?        S    Mar15   0:03 (logfile-daemon) /var/log/squid/access.log
root at paproxy:/#


root at paproxy:/# df -h
Filesystem      Size  Used Avail Use% Mounted on
udev            2.9G     0  2.9G   0% /dev
tmpfs           591M   60M  531M  11% /run
/dev/sda1       911G  1.9G  863G   1% /
tmpfs           2.9G   12K  2.9G   1% /dev/shm
tmpfs           5.0M     0  5.0M   0% /run/lock
tmpfs           2.9G     0  2.9G   0% /sys/fs/cgroup
tmpfs           591M     0  591M   0% /run/user/1000
tmpfs           591M     0  591M   0% /run/user/0
root at paproxy:/#



root at paproxy:/# df -h
Filesystem      Size  Used Avail Use% Mounted on
udev            2.9G     0  2.9G   0% /dev
tmpfs           591M   60M  531M  11% /run
/dev/sda1       911G  1.9G  863G   1% /
tmpfs           2.9G   12K  2.9G   1% /dev/shm
tmpfs           5.0M     0  5.0M   0% /run/lock
tmpfs           2.9G     0  2.9G   0% /sys/fs/cgroup
tmpfs           591M     0  591M   0% /run/user/1000
tmpfs           591M     0  591M   0% /run/user/0
root at paproxy:/#


root at paproxy:/# lsof -n|egrep "proxy|squid" | more
squid     25482                  root  cwd       DIR                8,1     4096          2 /
squid     25482                  root  rtd       DIR                8,1     4096          2 /
squid     25482                  root  txt       REG                8,1  6430816   41946763 /usr/sbin/squid
squid     25482                  root  mem       REG                8,1    47648   10093387 /lib/x86_64-linux-gnu/libnss_nis-2.23.
so
squid     25482                  root  mem       REG                8,1    93128   10093399 /lib/x86_64-linux-gnu/http://libnsl-2.23.so
squid     25482                  root  mem       REG                8,1    35688   10093400 /lib/x86_64-linux-gnu/libnss_compat-2.
23.so
squid     25482                  root  mem       REG                8,1    47600   10093403 /lib/x86_64-linux-gnu/libnss_files-2.2
3.so
squid     25482                  root  mem       REG                8,1 25913104   41944015 /usr/lib/x86_64-linux-gnu/libicudata.s
o.55.1
squid     25482                  root  mem       REG                8,1    22520   10093098 /lib/x86_64-linux-gnu/libmnl.so.0.1.0
squid     25482                  root  mem       REG                8,1    26248   41948589 /usr/lib/x86_64-linux-gnu/libnfnetlink
.so.0.2.0


Thank you once again

CM



On Thu, Mar 23, 2017 at 1:59 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:
There is another option!
The log rotate script is doing something nasty or the systemd service file start up squid in a weird way.
The output of:
$ systemctl status squid
$ top -n1 -b
$ ps aux
$ df -h
$ netstat -ntulp
$ lsof -n|egrep "proxy|squid"

How many clients this system has?
Is the system facing the Internet directly or behind some nat(aws or another provider)?

The above are the basic required data to understand the situation.

All The Bests,
Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: tel:%2B972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: squid-users [mailto:mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Chee M Gui
Sent: Wednesday, March 22, 2017 5:18 PM
To: mailto:squid-users at lists.squid-cache.org
Subject: [squid-users] Squid stopped working after cache.log and access.log rotation


Hi All

We recently installed Squid 3.5.12-1ubuntu7.3 on Ubuntu 16.04.2 LTS.  It ran fine at first but stopped working after a while.   telnet server 3128 still works, i.e., opens a blank window, but Squid is just not accepting requests.    Then we realized that there is no new access.log file.   The access.log file stopped rotated at 6:24AM on 3/17/2017.    It looks like Squid wasn't able to create a new access.log?  We could not find any error message in syslog or the cache.log.      We haven't rebooted the server because we want to know what went wrong.   It isn't the firewall blocking Squid because Squid was working fine all the while until recently.  Also after it stopped working, we disabled the firewall to see if it would work but it still didn't work.

root at paproxy:/var/log/squid# ls -alt
total 15536
drwxr-xr-x 2 proxy proxy      4096 Mar 21 06:25 .
-rw-r----- 1 proxy proxy        63 Mar 21 06:25 cache.log
drwxrwxr-x 9 root  syslog     4096 Mar 21 06:25 ..
-rw-r----- 1 proxy proxy        63 Mar 20 06:25 cache.log.1
-rw-r----- 1 proxy proxy        83 Mar 19 06:25 cache.log.2.gz
-rw-r----- 1 proxy proxy  15759111 Mar 17 06:24 access.log.1
-rw-r----- 1 proxy proxy    117223 Mar 17 05:52 netdb.state

Any ideas what went wrong?

Thank you very much in anticipation.

Gui
_______________________________________________
squid-users mailing list
mailto:squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users




-- 
Chee Meng Gui
Function Engineering
650-833-0660



From squid3 at treenet.co.nz  Thu Apr 20 20:19:04 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 21 Apr 2017 08:19:04 +1200
Subject: [squid-users] Access-Control-* headers missing when going
 through squid
In-Reply-To: <19319EAE-FF7D-432D-B712-C3086D37ACFD@getbusi.com>
References: <9BA9BBFF-4737-4F5B-8C1B-98BAEBEC7869@getbusi.com>
 <0b3b3fb5-5699-f17b-429f-ea790f9babcd@treenet.co.nz>
 <19319EAE-FF7D-432D-B712-C3086D37ACFD@getbusi.com>
Message-ID: <64f8faaf-1780-ae59-7607-649c37e4ef28@treenet.co.nz>

On 20/04/17 14:07, Dan Charlesworth wrote:
> Thanks Amos.
>
> As far as I can tell the only device upstream of the proxy is a 
> relatively basic gateway/firewall. I doubt it's capable of messing 
> with HTTP headers (and loading the site directly, as opposed to using 
> the proxy lets it load fine behind the same gateway).
>
> I?ve attached the debug output you suggested. Looks like the headers 
> in the browser are the same as what arriving and leaving the proxy?

Yes. Good proof there that Squid is not doing any breakage. The server 
is itself producing that output.

Amos



From squid3 at treenet.co.nz  Thu Apr 20 20:24:51 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 21 Apr 2017 08:24:51 +1200
Subject: [squid-users] Unliked SSL cipher
In-Reply-To: <7964d10c-f91d-58f6-e20c-3585c1a35edc@kalfaoglu.com>
References: <6db288b5-bce3-67f6-e8ed-b0b53b39bf8e@kalfaoglu.com>
 <c290452d-2493-68f7-341b-39f55c2e2cde@gmail.com>
 <7964d10c-f91d-58f6-e20c-3585c1a35edc@kalfaoglu.com>
Message-ID: <44b027fc-f2f2-d76c-9967-aace72b04129@treenet.co.nz>

On 20/04/17 16:44, turgut kalfao?lu wrote:
> On 04/19/2017 06:44 PM, dijxie wrote:
>> Do you recieve the same error while connecting to 
>> https://www.wikipedia.org?
> Yes I do.
>
> I also tried to connect to the IP address as well; and that gives me 
> the same error.
> The browser didn't say anything; it was squid that complained.


I've now looked into the ciphers being advertised.

The server insists on EDCSA with ChaCha-Poly1305 cipher. The OpenSSL 
1.0.2 provided by FC25 does not support those. You need to upgrade your 
OpenSSL library.

Amos



From cheemeng at function.com  Thu Apr 20 21:34:15 2017
From: cheemeng at function.com (Chee M Gui)
Date: Thu, 20 Apr 2017 14:34:15 -0700
Subject: [squid-users] Squid stopped working after cache.log and
 access.log rotation
In-Reply-To: <02a001d2ba0b$b64f69b0$22ee3d10$@ngtech.co.il>
References: <CAMyAatDzxB=+zNcB-jvc8vb+hse44Ne80tiaNUHgT_yQgM1iPg@mail.gmail.com>
 <097b01d2a418$588f1c70$09ad5550$@ngtech.co.il>
 <CAMyAatDW3uHp-v6+v8PP_6Rkv0-CjT=iaRLwhWXiUJAinodgfw@mail.gmail.com>
 <02a001d2ba0b$b64f69b0$22ee3d10$@ngtech.co.il>
Message-ID: <CAMyAatD61nN-vMoL6+okxr2-HogJ1+SAm8xYe0zF11J5t3k20A@mail.gmail.com>

Hi Eliezer

Thank you for the fast reply.
Squid is listening on 3128 on the server.    See netstat output below.
We would like to fix the logrotate script (if this is being used?) rather
that wait for Ubuntu to fix the Squid package (which may take a while).
There is no cron job under root or proxy or any other users on the server.
The logrotate file in  /etc/cron.daily is also a very old one.

Thank you once again

CMG


root at paproxy:/etc/logrotate.d# netstat -an | more

Active Internet connections (servers and established)
Proto Recv-Q Send-Q Local Address           Foreign Address         State
tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN
tcp        0      0 0.0.0.0:3128            0.0.0.0:*               LISTEN
tcp    13382      0 192.168.5.244:3128      192.168.5.103:49953
CLOSE_WAIT
tcp       90      0 198.27.136.41:52652     198.252.206.25:443
 CLOSE_WAIT
tcp      232      0 192.168.5.244:3128      192.168.5.126:63442
CLOSE_WAIT
tcp      440      0 192.168.5.244:3128      192.168.5.126:63423
CLOSE_WAIT
tcp      221      0 192.168.5.244:3128      192.168.5.103:54521
CLOSE_WAIT


root at paproxy:/etc/logrotate.d# crontab -l
no crontab for root



root at paproxy:/etc/logrotate.d# crontab -u proxy -l
no crontab for proxy


root at paproxy:/etc/logrotate.d# vi squid
#
#       Logrotate fragment for squid.
#
/var/log/squid/*.log {
        daily
        compress
        delaycompress
        rotate 2
        missingok
        nocreate
        sharedscripts
        prerotate
                test ! -x /usr/sbin/sarg-reports || /usr/sbin/sarg-reports
        endscript
        postrotate
                test ! -e /var/run/squid.pid || test ! -x /usr/sbin/squid
|| /usr/sbin/squid -k rotate
        endscript
}




root at paproxy:/etc/logrotate.d# dpkg -s squid
Package: squid
Status: install ok installed
Priority: optional
Section: web
Installed-Size: 7464
Maintainer: Ubuntu Developers <ubuntu-devel-discuss at lists.ubuntu.com>
Architecture: amd64
Source: squid3
Version: 3.5.12-1ubuntu7.3
Replaces: squid3 (<< 3.5.12-1ubuntu1~)
Depends: libc6 (>= 2.15), libcap2 (>= 1:2.10), libcomerr2 (>= 1.01),
libdb5.3, libecap3 (>= 1.0.1), libexpat1 (>= 2.0.1), libgcc1 (>= 1:3.0),
libgssapi-krb5-2 (>= 1.10+dfsg~), libkrb5-3 (>= 1.10+dfsg~), libldap-2.4-2
(>= 2.4.7), libltdl7 (>= 2.4.6), libnetfilter-conntrack3, libnettle6,
libpam0g (>= 0.99.7.1), libsasl2-2, libstdc++6 (>= 5.2), libxml2 (>=
2.7.4), netbase, logrotate (>= 3.5.4-1), squid-common (=
3.5.12-1ubuntu7.3), lsb-base, ssl-cert, init-system-helpers (>> 1.22ubuntu5)
Pre-Depends: adduser
Suggests: squidclient, squid-cgi, squid-purge, resolvconf (>= 0.40),
smbclient, ufw, winbindd, apparmor
Breaks: squid3 (<< 3.5.12-1ubuntu1~), ufw (<< 0.35-0ubuntu2~)
Conffiles:
 /etc/apparmor.d/usr.sbin.squid 08e05266f0ef7a9a4ac2c62be29a3ef2
 /etc/init.d/squid f67c63ce21e0ac57a4d16e90909b3e34
 /etc/logrotate.d/squid 2be386088ead3641de5401a9c73a7a57
 /etc/resolvconf/update-libc.d/squid 9968dc6f2fcde9f38a6faea7dfe95dd1
 /etc/squid/errorpage.css 7f1cc06116c222d49d641f0e830ff615
 /etc/squid/squid.conf e73b82ed9d76b47c8b5963175f0ada1e
 /etc/ufw/applications.d/squid 710e7b8ded49bbcd41eb072a0fe1691f
Description: Full featured Web Proxy cache (HTTP proxy)
 Squid is a high-performance proxy caching server for web clients,
supporting
 FTP, gopher, ICY and HTTP data objects.
 .
 Squid version 3 is a major rewrite of Squid in C++ and introduces a number
of
 new features including ICAP and ESI support.
Homepage: http://www.squid-cache.org
Original-Maintainer: Luigi Gangitano <luigi at debian.org>
root at paproxy:/etc/logrotate.d#




root at paproxy:/etc/logrotate.d# ls -al /etc/cron.daily
total 56
drwxr-xr-x  2 root root 4096 Mar 13 16:30 .
drwxr-xr-x 91 root root 4096 Apr  3 13:43 ..
-rwxr-xr-x  1 root root  376 Mar 31  2016 apport
-rwxr-xr-x  1 root root 1474 Oct 31 07:31 apt-compat
-rwxr-xr-x  1 root root  355 May 22  2012 bsdmainutils
-rwxr-xr-x  1 root root 1597 Nov 26  2015 dpkg
-rwxr-xr-x  1 root root  372 May  5  2015 logrotate
-rwxr-xr-x  1 root root 1293 Nov  6  2015 man-db
-rwxr-xr-x  1 root root  539 Jul 16  2014 mdadm
-rwxr-xr-x  1 root root  435 Nov 17  2014 mlocate
-rwxr-xr-x  1 root root  249 Nov 12  2015 passwd
-rw-r--r--  1 root root  102 Apr  5  2016 .placeholder
-rwxr-xr-x  1 root root 3449 Feb 26  2016 popularity-contest
-rwxr-xr-x  1 root root  214 May 24  2016 update-notifier-common








On Thu, Apr 20, 2017 at 12:24 PM, Eliezer Croitoru <eliezer at ngtech.co.il>
wrote:

> Hey CM,
>
> From the output I understand that there wasn't a change in squid packaging
> for 16.04 and they still use rc\init.d startup scripts.
> Also they probably use the same logrotate scripts from very long ago.
> We first must understand if squid is running and it seems that systemd
> sees it as running.
> I do not see in lsof output any port listening mentioned so I assume this
> is the reason for the issue in hands.
> The first thing I would do is run a crontab that will check if squid is
> alive using a cache manager info page fetch and check if it's listening
> using netstat or ss.
> (did you tried to see if squid is listening using netstat or ss??)
> The next step would be to check your squid roatate script and to verify
> it's doing what it suppose to do.
> After all this I would recommend changing from the rc\init.d startup
> script to a real system based one and abandon the old rotation scripts of
> Ubuntu or fix them.
>
> If you are looking for a fix it's one path and if you are looking to get
> the work done properly by Ubuntu it's a whole new wagon.
> I have been working on squid packages for Ubuntu and Debian that uses
> system scripts but the packages are not perfected yet.
>
> Let me know the path you want to choose and also your approach to things
> and I will try to help you with which of the options you will choose to
> resolve the issues.
>
> Eliezer
>
> ----
> http://ngtech.co.il/lmgtfy/
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> From: Chee M Gui [mailto:cheemeng at function.com]
> Sent: Thursday, April 20, 2017 7:17 PM
> To: Eliezer Croitoru <eliezer at ngtech.co.il>
> Cc: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid stopped working after cache.log and
> access.log rotation
>
> Hi Eliezer
>
> Thank you for the response, and sorry for the late reply.
>
> As requested, here are the output of the commands you suggested:
> root at paproxy:/# systemctl status squid
> ? squid.service - LSB: Squid HTTP Proxy version 3.x
>    Loaded: loaded (/etc/init.d/squid; bad; vendor preset: enabled)
>    Active: active (running) since Wed 2017-03-15 14:47:53 PDT; 1 months 5
> days ago
>      Docs: man:systemd-sysv-generator(8)
>     Tasks: 4
>    Memory: 54.4M
>       CPU: 2min 38.957s
>    CGroup: /system.slice/squid.service
>            ??25482 /usr/sbin/squid -YC -f /etc/squid/squid.conf
>            ??25484 (squid-1) -YC -f /etc/squid/squid.conf
>            ??25485 (logfile-daemon) /var/log/squid/access.log
>            ??25486 (unlinkd)
>
> Warning: Journal has been rotated since unit was started. Log output is
> incomplete or unavailable.
> root at paproxy:/#
>
>
>
> top - 09:11:45 up 54 days, 23:51,  2 users,  load average: 0.00, 0.00, 0.00
> Tasks: 141 total,   1 running, 140 sleeping,   0 stopped,   0 zombie
> %Cpu(s):  0.0 us,  0.0 sy,  0.0 ni, 99.9 id,  0.0 wa,  0.0 hi,  0.0 si,
> 0.0 st
> KiB Mem :  6043140 total,  4844728 free,   135292 used,  1063120 buff/cache
> KiB Swap:  6222844 total,  6222844 free,        0 used.  5556300 avail Mem
>
>   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
> 23355 root      20   0   41668   3776   3236 R   6.7  0.1   0:00.01 top
>     1 root      20   0   37884   5968   4020 S   0.0  0.1   0:27.20 systemd
>     2 root      20   0       0      0      0 S   0.0  0.0   0:00.22
> kthreadd
>     3 root      20   0       0      0      0 S   0.0  0.0   0:01.01
> ksoftirqd/0
>     5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
> kworker/0:0H
>     7 root      20   0       0      0      0 S   0.0  0.0   1:28.65
> rcu_sched
>     8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh
>     9 root      rt   0       0      0      0 S   0.0  0.0   0:00.14
> migration/0
>    10 root      rt   0       0      0      0 S   0.0  0.0   0:05.53
> watchdog/0
>    11 root      rt   0       0      0      0 S   0.0  0.0   0:05.75
> watchdog/1
>    12 root      rt   0       0      0      0 S   0.0  0.0   0:00.14
> migration/1
>    13 root      20   0       0      0      0 S   0.0  0.0   0:02.48
> ksoftirqd/1
>    15 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
> kworker/1:0H
>    16 root      20   0       0      0      0 S   0.0  0.0   0:00.00
> kdevtmpfs
>    17 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 netns
>    18 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 perf
>    19 root      20   0       0      0      0 S   0.0  0.0   0:01.26
> khungtaskd
>    20 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
> writeback
>
>
> root at paproxy:/# ps -aux | grep squid
> root     23358  0.0  0.0  14224   976 pts/0    S+   09:12   0:00 grep
> --color=auto squid
> root     25482  0.0  0.1 109272  6416 ?        Ss   Mar15   0:00
> /usr/sbin/squid -YC -f /etc/squid/squid.conf
> proxy    25484  0.0  0.7 166684 45184 ?        S    Mar15   2:27 (squid-1)
> -YC -f /etc/squid/squid.conf
> proxy    25485  0.0  0.0  13280  1648 ?        S    Mar15   0:03
> (logfile-daemon) /var/log/squid/access.log
> root at paproxy:/#
>
>
> root at paproxy:/# df -h
> Filesystem      Size  Used Avail Use% Mounted on
> udev            2.9G     0  2.9G   0% /dev
> tmpfs           591M   60M  531M  11% /run
> /dev/sda1       911G  1.9G  863G   1% /
> tmpfs           2.9G   12K  2.9G   1% /dev/shm
> tmpfs           5.0M     0  5.0M   0% /run/lock
> tmpfs           2.9G     0  2.9G   0% /sys/fs/cgroup
> tmpfs           591M     0  591M   0% /run/user/1000
> tmpfs           591M     0  591M   0% /run/user/0
> root at paproxy:/#
>
>
>
> root at paproxy:/# df -h
> Filesystem      Size  Used Avail Use% Mounted on
> udev            2.9G     0  2.9G   0% /dev
> tmpfs           591M   60M  531M  11% /run
> /dev/sda1       911G  1.9G  863G   1% /
> tmpfs           2.9G   12K  2.9G   1% /dev/shm
> tmpfs           5.0M     0  5.0M   0% /run/lock
> tmpfs           2.9G     0  2.9G   0% /sys/fs/cgroup
> tmpfs           591M     0  591M   0% /run/user/1000
> tmpfs           591M     0  591M   0% /run/user/0
> root at paproxy:/#
>
>
> root at paproxy:/# lsof -n|egrep "proxy|squid" | more
> squid     25482                  root  cwd       DIR                8,1
>  4096          2 /
> squid     25482                  root  rtd       DIR                8,1
>  4096          2 /
> squid     25482                  root  txt       REG                8,1
> 6430816   41946763 /usr/sbin/squid
> squid     25482                  root  mem       REG                8,1
> 47648   10093387 /lib/x86_64-linux-gnu/libnss_nis-2.23.
> so
> squid     25482                  root  mem       REG                8,1
> 93128   10093399 /lib/x86_64-linux-gnu/http://libnsl-2.23.so
> squid     25482                  root  mem       REG                8,1
> 35688   10093400 /lib/x86_64-linux-gnu/libnss_compat-2.
> 23.so
> squid     25482                  root  mem       REG                8,1
> 47600   10093403 /lib/x86_64-linux-gnu/libnss_files-2.2
> 3.so
> squid     25482                  root  mem       REG                8,1
> 25913104   41944015 /usr/lib/x86_64-linux-gnu/libicudata.s
> o.55.1
> squid     25482                  root  mem       REG                8,1
> 22520   10093098 /lib/x86_64-linux-gnu/libmnl.so.0.1.0
> squid     25482                  root  mem       REG                8,1
> 26248   41948589 /usr/lib/x86_64-linux-gnu/libnfnetlink
> .so.0.2.0
>
>
> Thank you once again
>
> CM
>
>
>
> On Thu, Mar 23, 2017 at 1:59 PM, Eliezer Croitoru <mailto:
> eliezer at ngtech.co.il> wrote:
> There is another option!
> The log rotate script is doing something nasty or the systemd service file
> start up squid in a weird way.
> The output of:
> $ systemctl status squid
> $ top -n1 -b
> $ ps aux
> $ df -h
> $ netstat -ntulp
> $ lsof -n|egrep "proxy|squid"
>
> How many clients this system has?
> Is the system facing the Internet directly or behind some nat(aws or
> another provider)?
>
> The above are the basic required data to understand the situation.
>
> All The Bests,
> Eliezer
>
> ----
> http://ngtech.co.il/lmgtfy/
> Linux System Administrator
> Mobile: tel:%2B972-5-28704261
> Email: mailto:eliezer at ngtech.co.il
>
>
> From: squid-users [mailto:mailto:squid-users-bounces at lists.squid-cache.org]
> On Behalf Of Chee M Gui
> Sent: Wednesday, March 22, 2017 5:18 PM
> To: mailto:squid-users at lists.squid-cache.org
> Subject: [squid-users] Squid stopped working after cache.log and
> access.log rotation
>
>
> Hi All
>
> We recently installed Squid 3.5.12-1ubuntu7.3 on Ubuntu 16.04.2 LTS.  It
> ran fine at first but stopped working after a while.   telnet server 3128
> still works, i.e., opens a blank window, but Squid is just not accepting
> requests.    Then we realized that there is no new access.log file.   The
> access.log file stopped rotated at 6:24AM on 3/17/2017.    It looks like
> Squid wasn't able to create a new access.log?  We could not find any error
> message in syslog or the cache.log.      We haven't rebooted the server
> because we want to know what went wrong.   It isn't the firewall blocking
> Squid because Squid was working fine all the while until recently.  Also
> after it stopped working, we disabled the firewall to see if it would work
> but it still didn't work.
>
> root at paproxy:/var/log/squid# ls -alt
> total 15536
> drwxr-xr-x 2 proxy proxy      4096 Mar 21 06:25 .
> -rw-r----- 1 proxy proxy        63 Mar 21 06:25 cache.log
> drwxrwxr-x 9 root  syslog     4096 Mar 21 06:25 ..
> -rw-r----- 1 proxy proxy        63 Mar 20 06:25 cache.log.1
> -rw-r----- 1 proxy proxy        83 Mar 19 06:25 cache.log.2.gz
> -rw-r----- 1 proxy proxy  15759111 Mar 17 06:24 access.log.1
> -rw-r----- 1 proxy proxy    117223 Mar 17 05:52 netdb.state
>
> Any ideas what went wrong?
>
> Thank you very much in anticipation.
>
> Gui
> _______________________________________________
> squid-users mailing list
> mailto:squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
>
> --
> Chee Meng Gui
> Function Engineering
> 650-833-0660
>
>


-- 
Chee Meng Gui
Function Engineering
650-833-0660
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170420/112f1330/attachment.htm>

From cheemeng at function.com  Thu Apr 20 21:54:03 2017
From: cheemeng at function.com (Chee M Gui)
Date: Thu, 20 Apr 2017 14:54:03 -0700
Subject: [squid-users] Squid stopped working after cache.log and
 access.log rotation
In-Reply-To: <CAMyAatD61nN-vMoL6+okxr2-HogJ1+SAm8xYe0zF11J5t3k20A@mail.gmail.com>
References: <CAMyAatDzxB=+zNcB-jvc8vb+hse44Ne80tiaNUHgT_yQgM1iPg@mail.gmail.com>
 <097b01d2a418$588f1c70$09ad5550$@ngtech.co.il>
 <CAMyAatDW3uHp-v6+v8PP_6Rkv0-CjT=iaRLwhWXiUJAinodgfw@mail.gmail.com>
 <02a001d2ba0b$b64f69b0$22ee3d10$@ngtech.co.il>
 <CAMyAatD61nN-vMoL6+okxr2-HogJ1+SAm8xYe0zF11J5t3k20A@mail.gmail.com>
Message-ID: <CAMyAatDNZ2H8R56y50yr+r7bnekH3knLMegfE_cYQ0pwzOHW0g@mail.gmail.com>

Some more info:


cache.log is able to rotate.
Only access.log not rotating

root at paproxy:/# ls -alt /var/log/squid
total 15540
drwxrwxr-x 9 root  syslog     4096 Apr 20 14:42 ..
drwxr-xr-x 2 proxy proxy      4096 Apr 20 06:25 .
-rw-r----- 1 proxy proxy        63 Apr 20 06:25 cache.log
-rw-r----- 1 proxy proxy        63 Apr 19 06:25 cache.log.1
-rw-r----- 1 proxy proxy        83 Apr 18 06:25 cache.log.2.gz
-rw-r----- 1 proxy proxy        63 Mar 19 06:25 cache.log.2
-rw-r----- 1 proxy proxy  15759111 Mar 17 06:24 access.log.1
-rw-r----- 1 proxy proxy    117223 Mar 17 05:52 netdb.state
root at paproxy:/#


We installed squid on 3/15/2017/



root at paproxy:/etc/logrotate.d# date +%s
1492724638
root at paproxy:/etc/logrotate.d# more /var/log/squid/access.log.1
1489614186.653      6 192.168.5.103 TCP_MISS/503 3992 GET
http://ipv6.msftncsi.com/ncsi.txt - HIER_DIRECT/2001:5a8:100::b817:9fae
text/html
1489614186.668     21 192.168.5.103 TCP_MISS/200 280 GET
http://www.msftncsi.com/ncsi.txt - HIER_DIRECT/184.23.159.169 text/plain
1489614186.997    214 192.168.5.103 TCP_MISS/200 617 GET
http://login.live.com/ppcrlcheck.srf - HIER_DIRECT/131.253.61.66 text/htm
l



1489757088.048  10750 192.168.5.103 TCP_TUNNEL/200 5454 CONNECT
p.ebdr2.com:443 - HIER_DIRECT/74.217.250.5 -
1489757099.057  10783 192.168.5.103 TCP_TUNNEL/200 5454 CONNECT
p.ebdr2.com:443 - HIER_DIRECT/74.217.250.5 -


First entry in the access.log.1 file
https://www.epochconverter.com/
GMT: Wed, 15 Mar 2017 21:43:06 GMT
Your time zone: 3/15/2017, 2:43:06 PM GMT-7:00 DST

Last entry in the access.log.1 file
GMT: Fri, 17 Mar 2017 13:24:59 GMT
Your time zone: 3/17/2017, 6:24:59 AM GMT-7:00 DST


Squid was installed on 3/15/2017 on the server.


https://bugs.launchpad.net/ubuntu/+source/squid-deb-proxy/+bug/1544719

https://bugs.launchpad.net/ubuntu/+source/logrotate/+bug/1414754


On Thu, Apr 20, 2017 at 2:34 PM, Chee M Gui <cheemeng at function.com> wrote:

> Hi Eliezer
>
> Thank you for the fast reply.
> Squid is listening on 3128 on the server.    See netstat output below.
> We would like to fix the logrotate script (if this is being used?) rather
> that wait for Ubuntu to fix the Squid package (which may take a while).
> There is no cron job under root or proxy or any other users on the server.
> The logrotate file in  /etc/cron.daily is also a very old one.
>
> Thank you once again
>
> CMG
>
>
> root at paproxy:/etc/logrotate.d# netstat -an | more
>
> Active Internet connections (servers and established)
> Proto Recv-Q Send-Q Local Address           Foreign Address         State
> tcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN
> tcp        0      0 0.0.0.0:3128            0.0.0.0:*               LISTEN
> tcp    13382      0 192.168.5.244:3128      192.168.5.103:49953
> CLOSE_WAIT
> tcp       90      0 198.27.136.41:52652     198.252.206.25:443
>  CLOSE_WAIT
> tcp      232      0 192.168.5.244:3128      192.168.5.126:63442
> CLOSE_WAIT
> tcp      440      0 192.168.5.244:3128      192.168.5.126:63423
> CLOSE_WAIT
> tcp      221      0 192.168.5.244:3128      192.168.5.103:54521
> CLOSE_WAIT
>
>
> root at paproxy:/etc/logrotate.d# crontab -l
> no crontab for root
>
>
>
> root at paproxy:/etc/logrotate.d# crontab -u proxy -l
> no crontab for proxy
>
>
> root at paproxy:/etc/logrotate.d# vi squid
> #
> #       Logrotate fragment for squid.
> #
> /var/log/squid/*.log {
>         daily
>         compress
>         delaycompress
>         rotate 2
>         missingok
>         nocreate
>         sharedscripts
>         prerotate
>                 test ! -x /usr/sbin/sarg-reports || /usr/sbin/sarg-reports
>         endscript
>         postrotate
>                 test ! -e /var/run/squid.pid || test ! -x /usr/sbin/squid
> || /usr/sbin/squid -k rotate
>         endscript
> }
>
>
>
>
> root at paproxy:/etc/logrotate.d# dpkg -s squid
> Package: squid
> Status: install ok installed
> Priority: optional
> Section: web
> Installed-Size: 7464
> Maintainer: Ubuntu Developers <ubuntu-devel-discuss at lists.ubuntu.com>
> Architecture: amd64
> Source: squid3
> Version: 3.5.12-1ubuntu7.3
> Replaces: squid3 (<< 3.5.12-1ubuntu1~)
> Depends: libc6 (>= 2.15), libcap2 (>= 1:2.10), libcomerr2 (>= 1.01),
> libdb5.3, libecap3 (>= 1.0.1), libexpat1 (>= 2.0.1), libgcc1 (>= 1:3.0),
> libgssapi-krb5-2 (>= 1.10+dfsg~), libkrb5-3 (>= 1.10+dfsg~), libldap-2.4-2
> (>= 2.4.7), libltdl7 (>= 2.4.6), libnetfilter-conntrack3, libnettle6,
> libpam0g (>= 0.99.7.1), libsasl2-2, libstdc++6 (>= 5.2), libxml2 (>=
> 2.7.4), netbase, logrotate (>= 3.5.4-1), squid-common (=
> 3.5.12-1ubuntu7.3), lsb-base, ssl-cert, init-system-helpers (>> 1.22ubuntu5)
> Pre-Depends: adduser
> Suggests: squidclient, squid-cgi, squid-purge, resolvconf (>= 0.40),
> smbclient, ufw, winbindd, apparmor
> Breaks: squid3 (<< 3.5.12-1ubuntu1~), ufw (<< 0.35-0ubuntu2~)
> Conffiles:
>  /etc/apparmor.d/usr.sbin.squid 08e05266f0ef7a9a4ac2c62be29a3ef2
>  /etc/init.d/squid f67c63ce21e0ac57a4d16e90909b3e34
>  /etc/logrotate.d/squid 2be386088ead3641de5401a9c73a7a57
>  /etc/resolvconf/update-libc.d/squid 9968dc6f2fcde9f38a6faea7dfe95dd1
>  /etc/squid/errorpage.css 7f1cc06116c222d49d641f0e830ff615
>  /etc/squid/squid.conf e73b82ed9d76b47c8b5963175f0ada1e
>  /etc/ufw/applications.d/squid 710e7b8ded49bbcd41eb072a0fe1691f
> Description: Full featured Web Proxy cache (HTTP proxy)
>  Squid is a high-performance proxy caching server for web clients,
> supporting
>  FTP, gopher, ICY and HTTP data objects.
>  .
>  Squid version 3 is a major rewrite of Squid in C++ and introduces a
> number of
>  new features including ICAP and ESI support.
> Homepage: http://www.squid-cache.org
> Original-Maintainer: Luigi Gangitano <luigi at debian.org>
> root at paproxy:/etc/logrotate.d#
>
>
>
>
> root at paproxy:/etc/logrotate.d# ls -al /etc/cron.daily
> total 56
> drwxr-xr-x  2 root root 4096 Mar 13 16:30 .
> drwxr-xr-x 91 root root 4096 Apr  3 13:43 ..
> -rwxr-xr-x  1 root root  376 Mar 31  2016 apport
> -rwxr-xr-x  1 root root 1474 Oct 31 07:31 apt-compat
> -rwxr-xr-x  1 root root  355 May 22  2012 bsdmainutils
> -rwxr-xr-x  1 root root 1597 Nov 26  2015 dpkg
> -rwxr-xr-x  1 root root  372 May  5  2015 logrotate
> -rwxr-xr-x  1 root root 1293 Nov  6  2015 man-db
> -rwxr-xr-x  1 root root  539 Jul 16  2014 mdadm
> -rwxr-xr-x  1 root root  435 Nov 17  2014 mlocate
> -rwxr-xr-x  1 root root  249 Nov 12  2015 passwd
> -rw-r--r--  1 root root  102 Apr  5  2016 .placeholder
> -rwxr-xr-x  1 root root 3449 Feb 26  2016 popularity-contest
> -rwxr-xr-x  1 root root  214 May 24  2016 update-notifier-common
>
>
>
>
>
>
>
>
> On Thu, Apr 20, 2017 at 12:24 PM, Eliezer Croitoru <eliezer at ngtech.co.il>
> wrote:
>
>> Hey CM,
>>
>> From the output I understand that there wasn't a change in squid
>> packaging for 16.04 and they still use rc\init.d startup scripts.
>> Also they probably use the same logrotate scripts from very long ago.
>> We first must understand if squid is running and it seems that systemd
>> sees it as running.
>> I do not see in lsof output any port listening mentioned so I assume this
>> is the reason for the issue in hands.
>> The first thing I would do is run a crontab that will check if squid is
>> alive using a cache manager info page fetch and check if it's listening
>> using netstat or ss.
>> (did you tried to see if squid is listening using netstat or ss??)
>> The next step would be to check your squid roatate script and to verify
>> it's doing what it suppose to do.
>> After all this I would recommend changing from the rc\init.d startup
>> script to a real system based one and abandon the old rotation scripts of
>> Ubuntu or fix them.
>>
>> If you are looking for a fix it's one path and if you are looking to get
>> the work done properly by Ubuntu it's a whole new wagon.
>> I have been working on squid packages for Ubuntu and Debian that uses
>> system scripts but the packages are not perfected yet.
>>
>> Let me know the path you want to choose and also your approach to things
>> and I will try to help you with which of the options you will choose to
>> resolve the issues.
>>
>> Eliezer
>>
>> ----
>> http://ngtech.co.il/lmgtfy/
>> Linux System Administrator
>> Mobile: +972-5-28704261
>> Email: eliezer at ngtech.co.il
>>
>>
>> From: Chee M Gui [mailto:cheemeng at function.com]
>> Sent: Thursday, April 20, 2017 7:17 PM
>> To: Eliezer Croitoru <eliezer at ngtech.co.il>
>> Cc: squid-users at lists.squid-cache.org
>> Subject: Re: [squid-users] Squid stopped working after cache.log and
>> access.log rotation
>>
>> Hi Eliezer
>>
>> Thank you for the response, and sorry for the late reply.
>>
>> As requested, here are the output of the commands you suggested:
>> root at paproxy:/# systemctl status squid
>> ? squid.service - LSB: Squid HTTP Proxy version 3.x
>>    Loaded: loaded (/etc/init.d/squid; bad; vendor preset: enabled)
>>    Active: active (running) since Wed 2017-03-15 14:47:53 PDT; 1 months 5
>> days ago
>>      Docs: man:systemd-sysv-generator(8)
>>     Tasks: 4
>>    Memory: 54.4M
>>       CPU: 2min 38.957s
>>    CGroup: /system.slice/squid.service
>>            ??25482 /usr/sbin/squid -YC -f /etc/squid/squid.conf
>>            ??25484 (squid-1) -YC -f /etc/squid/squid.conf
>>            ??25485 (logfile-daemon) /var/log/squid/access.log
>>            ??25486 (unlinkd)
>>
>> Warning: Journal has been rotated since unit was started. Log output is
>> incomplete or unavailable.
>> root at paproxy:/#
>>
>>
>>
>> top - 09:11:45 up 54 days, 23:51,  2 users,  load average: 0.00, 0.00,
>> 0.00
>> Tasks: 141 total,   1 running, 140 sleeping,   0 stopped,   0 zombie
>> %Cpu(s):  0.0 us,  0.0 sy,  0.0 ni, 99.9 id,  0.0 wa,  0.0 hi,  0.0 si,
>> 0.0 st
>> KiB Mem :  6043140 total,  4844728 free,   135292 used,  1063120
>> buff/cache
>> KiB Swap:  6222844 total,  6222844 free,        0 used.  5556300 avail Mem
>>
>>   PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+
>> COMMAND
>> 23355 root      20   0   41668   3776   3236 R   6.7  0.1   0:00.01 top
>>     1 root      20   0   37884   5968   4020 S   0.0  0.1   0:27.20
>> systemd
>>     2 root      20   0       0      0      0 S   0.0  0.0   0:00.22
>> kthreadd
>>     3 root      20   0       0      0      0 S   0.0  0.0   0:01.01
>> ksoftirqd/0
>>     5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
>> kworker/0:0H
>>     7 root      20   0       0      0      0 S   0.0  0.0   1:28.65
>> rcu_sched
>>     8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh
>>     9 root      rt   0       0      0      0 S   0.0  0.0   0:00.14
>> migration/0
>>    10 root      rt   0       0      0      0 S   0.0  0.0   0:05.53
>> watchdog/0
>>    11 root      rt   0       0      0      0 S   0.0  0.0   0:05.75
>> watchdog/1
>>    12 root      rt   0       0      0      0 S   0.0  0.0   0:00.14
>> migration/1
>>    13 root      20   0       0      0      0 S   0.0  0.0   0:02.48
>> ksoftirqd/1
>>    15 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
>> kworker/1:0H
>>    16 root      20   0       0      0      0 S   0.0  0.0   0:00.00
>> kdevtmpfs
>>    17 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 netns
>>    18 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 perf
>>    19 root      20   0       0      0      0 S   0.0  0.0   0:01.26
>> khungtaskd
>>    20 root       0 -20       0      0      0 S   0.0  0.0   0:00.00
>> writeback
>>
>>
>> root at paproxy:/# ps -aux | grep squid
>> root     23358  0.0  0.0  14224   976 pts/0    S+   09:12   0:00 grep
>> --color=auto squid
>> root     25482  0.0  0.1 109272  6416 ?        Ss   Mar15   0:00
>> /usr/sbin/squid -YC -f /etc/squid/squid.conf
>> proxy    25484  0.0  0.7 166684 45184 ?        S    Mar15   2:27
>> (squid-1) -YC -f /etc/squid/squid.conf
>> proxy    25485  0.0  0.0  13280  1648 ?        S    Mar15   0:03
>> (logfile-daemon) /var/log/squid/access.log
>> root at paproxy:/#
>>
>>
>> root at paproxy:/# df -h
>> Filesystem      Size  Used Avail Use% Mounted on
>> udev            2.9G     0  2.9G   0% /dev
>> tmpfs           591M   60M  531M  11% /run
>> /dev/sda1       911G  1.9G  863G   1% /
>> tmpfs           2.9G   12K  2.9G   1% /dev/shm
>> tmpfs           5.0M     0  5.0M   0% /run/lock
>> tmpfs           2.9G     0  2.9G   0% /sys/fs/cgroup
>> tmpfs           591M     0  591M   0% /run/user/1000
>> tmpfs           591M     0  591M   0% /run/user/0
>> root at paproxy:/#
>>
>>
>>
>> root at paproxy:/# df -h
>> Filesystem      Size  Used Avail Use% Mounted on
>> udev            2.9G     0  2.9G   0% /dev
>> tmpfs           591M   60M  531M  11% /run
>> /dev/sda1       911G  1.9G  863G   1% /
>> tmpfs           2.9G   12K  2.9G   1% /dev/shm
>> tmpfs           5.0M     0  5.0M   0% /run/lock
>> tmpfs           2.9G     0  2.9G   0% /sys/fs/cgroup
>> tmpfs           591M     0  591M   0% /run/user/1000
>> tmpfs           591M     0  591M   0% /run/user/0
>> root at paproxy:/#
>>
>>
>> root at paproxy:/# lsof -n|egrep "proxy|squid" | more
>> squid     25482                  root  cwd       DIR                8,1
>>    4096          2 /
>> squid     25482                  root  rtd       DIR                8,1
>>    4096          2 /
>> squid     25482                  root  txt       REG                8,1
>> 6430816   41946763 /usr/sbin/squid
>> squid     25482                  root  mem       REG                8,1
>>   47648   10093387 /lib/x86_64-linux-gnu/libnss_nis-2.23.
>> so
>> squid     25482                  root  mem       REG                8,1
>>   93128   10093399 /lib/x86_64-linux-gnu/http://libnsl-2.23.so
>> squid     25482                  root  mem       REG                8,1
>>   35688   10093400 /lib/x86_64-linux-gnu/libnss_compat-2.
>> 23.so
>> squid     25482                  root  mem       REG                8,1
>>   47600   10093403 /lib/x86_64-linux-gnu/libnss_files-2.2
>> 3.so
>> squid     25482                  root  mem       REG                8,1
>> 25913104   41944015 /usr/lib/x86_64-linux-gnu/libicudata.s
>> o.55.1
>> squid     25482                  root  mem       REG                8,1
>>   22520   10093098 /lib/x86_64-linux-gnu/libmnl.so.0.1.0
>> squid     25482                  root  mem       REG                8,1
>>   26248   41948589 /usr/lib/x86_64-linux-gnu/libnfnetlink
>> .so.0.2.0
>>
>>
>> Thank you once again
>>
>> CM
>>
>>
>>
>> On Thu, Mar 23, 2017 at 1:59 PM, Eliezer Croitoru <mailto:
>> eliezer at ngtech.co.il> wrote:
>> There is another option!
>> The log rotate script is doing something nasty or the systemd service
>> file start up squid in a weird way.
>> The output of:
>> $ systemctl status squid
>> $ top -n1 -b
>> $ ps aux
>> $ df -h
>> $ netstat -ntulp
>> $ lsof -n|egrep "proxy|squid"
>>
>> How many clients this system has?
>> Is the system facing the Internet directly or behind some nat(aws or
>> another provider)?
>>
>> The above are the basic required data to understand the situation.
>>
>> All The Bests,
>> Eliezer
>>
>> ----
>> http://ngtech.co.il/lmgtfy/
>> Linux System Administrator
>> Mobile: tel:%2B972-5-28704261
>> Email: mailto:eliezer at ngtech.co.il
>>
>>
>> From: squid-users [mailto:mailto:squid-users-bou
>> nces at lists.squid-cache.org] On Behalf Of Chee M Gui
>> Sent: Wednesday, March 22, 2017 5:18 PM
>> To: mailto:squid-users at lists.squid-cache.org
>> Subject: [squid-users] Squid stopped working after cache.log and
>> access.log rotation
>>
>>
>> Hi All
>>
>> We recently installed Squid 3.5.12-1ubuntu7.3 on Ubuntu 16.04.2 LTS.  It
>> ran fine at first but stopped working after a while.   telnet server 3128
>> still works, i.e., opens a blank window, but Squid is just not accepting
>> requests.    Then we realized that there is no new access.log file.   The
>> access.log file stopped rotated at 6:24AM on 3/17/2017.    It looks like
>> Squid wasn't able to create a new access.log?  We could not find any error
>> message in syslog or the cache.log.      We haven't rebooted the server
>> because we want to know what went wrong.   It isn't the firewall blocking
>> Squid because Squid was working fine all the while until recently.  Also
>> after it stopped working, we disabled the firewall to see if it would work
>> but it still didn't work.
>>
>> root at paproxy:/var/log/squid# ls -alt
>> total 15536
>> drwxr-xr-x 2 proxy proxy      4096 Mar 21 06:25 .
>> -rw-r----- 1 proxy proxy        63 Mar 21 06:25 cache.log
>> drwxrwxr-x 9 root  syslog     4096 Mar 21 06:25 ..
>> -rw-r----- 1 proxy proxy        63 Mar 20 06:25 cache.log.1
>> -rw-r----- 1 proxy proxy        83 Mar 19 06:25 cache.log.2.gz
>> -rw-r----- 1 proxy proxy  15759111 Mar 17 06:24 access.log.1
>> -rw-r----- 1 proxy proxy    117223 Mar 17 05:52 netdb.state
>>
>> Any ideas what went wrong?
>>
>> Thank you very much in anticipation.
>>
>> Gui
>> _______________________________________________
>> squid-users mailing list
>> mailto:squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
>>
>> --
>> Chee Meng Gui
>> Function Engineering
>> 650-833-0660
>>
>>
>
>
> --
> Chee Meng Gui
> Function Engineering
> 650-833-0660 <(650)%20833-0660>
>



-- 
Chee Meng Gui
Function Engineering
650-833-0660
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170420/fabb995b/attachment.htm>

From richard.qian at magicwifi.com.cn  Fri Apr 21 03:37:17 2017
From: richard.qian at magicwifi.com.cn (=?utf-8?B?6ZKx5Zu95q2j?=)
Date: Fri, 21 Apr 2017 11:37:17 +0800
Subject: [squid-users] Can squid work as http response parse  only ?
Message-ID: <tencent_0F2EF7DA169FAAD04B0C0506@qq.com>

I know squid+ecap can modify http response with a relatively fast speed, and I have done that before.
But, in real environment, there is a lot of reqeusts, that don't need processs http response, which would make network slow.
So I am thinking whether I can use libnetfilter_queue to judge that http response has content-type with text/html , if it has such
things, we can redirect the packet to squid or some http parser, then modify it and send it to client.


I don't know whether it can work, if not, can anyone give me some advice.
if it can work like that, how to configure ?
Thanks a lot.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170421/a3be3a2f/attachment.htm>

From squid3 at treenet.co.nz  Fri Apr 21 05:34:03 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 21 Apr 2017 17:34:03 +1200
Subject: [squid-users] Can squid work as http response parse only ?
In-Reply-To: <tencent_0F2EF7DA169FAAD04B0C0506@qq.com>
References: <tencent_0F2EF7DA169FAAD04B0C0506@qq.com>
Message-ID: <57569f7e-f89d-ddbb-c3a7-15f848046214@treenet.co.nz>

On 21/04/17 15:37, ??? wrote:
> I know squid+ecap can modify http response with a relatively fast 
> speed, and I have done that before.
> But, in real environment, there is a lot of reqeusts, that don't need 
> processs http response, which would make network slow.
> So I am thinking whether I can use libnetfilter_queue to judge that 
> http response has content-type with text/html , if it has such
> things, we can redirect the packet to squid or some http parser, then 
> modify it and send it to client.
>
> I don't know whether it can work, if not, can anyone give me some advice.

It cannot. If the request is not sent through Squid there is no way it 
can correctly handle the response.

Amos



From marko.cupac at mimar.rs  Fri Apr 21 12:29:34 2017
From: marko.cupac at mimar.rs (Marko =?UTF-8?B?Q3VwYcSH?=)
Date: Fri, 21 Apr 2017 14:29:34 +0200
Subject: [squid-users] ssl bump and chrome 58
Message-ID: <20170421142934.241ce2cf@efreet-freebsd.kappastar.com>

Hi,

I have squid setup with ssl bump which worked fine, but since I updated
chrome to 58 it won't display any https sites, throwing
NTT:ERR_CERT_COMMON_NAME_INVALID. https sites still work in previous
chrome version, as well as in IE.

Anything I can do in squid config to get ssl-bumped sites in chrome
again?

Thank you in advance,
-- 
Before enlightenment - chop wood, draw water.
After  enlightenment - chop wood, draw water.

Marko Cupa?
https://www.mimar.rs/


From yvoinov at gmail.com  Fri Apr 21 13:35:15 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 21 Apr 2017 19:35:15 +0600
Subject: [squid-users] ssl bump and chrome 58
In-Reply-To: <20170421142934.241ce2cf@efreet-freebsd.kappastar.com>
References: <20170421142934.241ce2cf@efreet-freebsd.kappastar.com>
Message-ID: <f822ef50-731e-ec12-3b1f-144ce1f48347@gmail.com>

I see no problem with it on all five SSL Bump-aware servers with new
Chrome. So fare so good.


21.04.2017 18:29, Marko Cupa? ?????:
> Hi,
>
> I have squid setup with ssl bump which worked fine, but since I updated
> chrome to 58 it won't display any https sites, throwing
> NTT:ERR_CERT_COMMON_NAME_INVALID. https sites still work in previous
> chrome version, as well as in IE.
>
> Anything I can do in squid config to get ssl-bumped sites in chrome
> again?
>
> Thank you in advance,

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170421/9a8d419e/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170421/9a8d419e/attachment.sig>

From rousskov at measurement-factory.com  Fri Apr 21 14:39:24 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 21 Apr 2017 08:39:24 -0600
Subject: [squid-users] Can squid work as http response parse only ?
In-Reply-To: <57569f7e-f89d-ddbb-c3a7-15f848046214@treenet.co.nz>
References: <tencent_0F2EF7DA169FAAD04B0C0506@qq.com>
 <57569f7e-f89d-ddbb-c3a7-15f848046214@treenet.co.nz>
Message-ID: <4a56a77d-47f2-db8a-889f-d5e621b37b4b@measurement-factory.com>

On 04/20/2017 11:34 PM, Amos Jeffries wrote:
> On 21/04/17 15:37, ??? wrote:
>> I know squid+ecap can modify http response with a relatively fast
>> speed, and I have done that before.
>> But, in real environment, there is a lot of reqeusts, that don't need
>> processs http response, which would make network slow.
>> So I am thinking whether I can use libnetfilter_queue to judge that
>> http response has content-type with text/html , if it has such
>> things, we can redirect the packet to squid or some http parser, then
>> modify it and send it to client.

>> I don't know whether it can work, if not, can anyone give me some advice.

> It cannot.

The "or some http parser" part can work AFAICT, but it would be very
difficult to do serious text/html adaptations at the TCP packet level.
Configuring Squid to be more selective about adaptations, and making
Squid generally faster may be a better overall direction.


> If the request is not sent through Squid there is no way it
> can correctly handle the response.

Agreed. That "some http parser" alternative would have to make
libnetfilter an eCAP host application (essentially), completely
bypassing Squid.

Alex.



From rafael.akchurin at diladele.com  Sat Apr 22 11:56:38 2017
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Sat, 22 Apr 2017 11:56:38 +0000
Subject: [squid-users] Squid 3.5.25 for Microsoft Windows 64-bit is available
Message-ID: <DB6PR0401MB268022492985354C62DC8B288F1D0@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Greetings everyone,

The CygWin based build of Squid proxy for Microsoft Windows version 3.5.25 is now available (amd64 only!).

* Original release notes are at http://www.squid-cache.org/Versions/v3/3.5/squid-3.5.25-RELEASENOTES.html .
* Ready to use MSI package can be downloaded from http://squid.diladele.com .
* List of open issues for the installer - https://github.com/diladele/squid-windows/issues

Thanks a lot for Squid developers for making this great software!

Please join our humble efforts to provide ready to run MSI installer for Squid on Microsoft Windows with all required dependencies at GitHub -
https://github.com/diladele/squid-windows . Please report all issues/bugs/feature requests at GitHub project. Issues about the *MSI installer only* can also be reported to support at diladele.com<mailto:support at diladele.com> .

Best regards,
Rafael Akchurin
Diladele B.V.
https://www.diladele.com

--
Please take a look at Web Safety - our ICAP based web filter server for Squid proxy.


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170422/bf5f6874/attachment.htm>

From chiasa.men at web.de  Sat Apr 22 16:32:03 2017
From: chiasa.men at web.de (chiasa.men)
Date: Sat, 22 Apr 2017 18:32:03 +0200
Subject: [squid-users] https_port Connection reset by peer; http_port works
Message-ID: <2548465.APt4bHOcTO@march>

Hello folks

I tried to encrypt the connection between client and squid. Therefore I 
generated certificates which are accepted by the clients and configured squid 
as followed:

Squid.conf
  https_port 10.0.13.10:8443 cert=/cert.pem key=/cert.key
  http_port 10.0.13.10:8080
  http_access allow all

My following tests show that I can use the http port for internet access but 
the https port wont work. 
  openssl s_client -connect proxy:8443 
  # Verify return code: 0 (ok)

  export https_proxy="proxy:8443"
  export http_proxy="proxy:8080" 
  curl https://www.google.de
  # curl: (56) Recv failure: Connection reset by peer
  curl http://www.google.de
  # works
  
  export https_proxy="proxy:8443"
  export http_proxy="$https_proxy" 
  curl https://www.google.de
  # curl: (56) Recv failure: Connection reset by peer
  curl http://www.google.de
  # curl: (56) Recv failure: Connection reset by peer
  
  export http_proxy="proxy:8080" 
  export https_proxy="$http_proxy" 
  curl https://www.google.de
  # works
  curl http://www.google.de
  # works

What did I wrong? Do I misunderstand something regarding the configuration 
options?

Regards Chia


From augustus_meyer at gmx.net  Sat Apr 22 18:05:29 2017
From: augustus_meyer at gmx.net (reinerotto)
Date: Sat, 22 Apr 2017 11:05:29 -0700 (PDT)
Subject: [squid-users] Can squid work as http response parse  only ?
In-Reply-To: <tencent_0F2EF7DA169FAAD04B0C0506@qq.com>
References: <tencent_0F2EF7DA169FAAD04B0C0506@qq.com>
Message-ID: <1492884329212-4682180.post@n4.nabble.com>

Having developed a commercial stand-alone proxy for content adaption, usually
it is set up as a parent proxy to squid, which only forwards 'suitable'
traffic to this parent, by means of ACLs. 
Other traffic is directly forwarded to origin server, like requests for
*.jpg, for example.
You can set up a similar scenario with 2 squids, one of these doing content
adaption via ecap.





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Can-squid-work-as-http-response-parse-only-tp4682159p4682180.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chiasa.men at web.de  Sun Apr 23 11:25:51 2017
From: chiasa.men at web.de (chiasa.men at web.de)
Date: Sun, 23 Apr 2017 13:25:51 +0200
Subject: [squid-users] =?utf-8?q?=28no_subject=29?=
Message-ID: <trinity-3602572c-8333-41eb-a8ca-303df9eff1f7-1492946751598@3capp-webde-bap06>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170423/d3d9df98/attachment.htm>

From chiasa.men at web.de  Sun Apr 23 11:27:20 2017
From: chiasa.men at web.de (chiasa.men at web.de)
Date: Sun, 23 Apr 2017 13:27:20 +0200
Subject: [squid-users] cache_peer ssl: AH01991: SSL input filter read failed
Message-ID: <trinity-4be482e3-fe6e-4f10-bbd0-0b018b7961ba-1492946840300@3capp-webde-bap06>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170423/d7ab52b4/attachment.htm>

From squid3 at treenet.co.nz  Sun Apr 23 15:57:52 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 24 Apr 2017 03:57:52 +1200
Subject: [squid-users] (no subject)
In-Reply-To: <trinity-3602572c-8333-41eb-a8ca-303df9eff1f7-1492946751598@3capp-webde-bap06>
References: <trinity-3602572c-8333-41eb-a8ca-303df9eff1f7-1492946751598@3capp-webde-bap06>
Message-ID: <42de2bce-9528-439b-e2a3-2e7957213bc6@treenet.co.nz>

On 23/04/17 23:25, chiasa.men at web.de wrote:
>
> Hello
>
> my squid.conf looks like that:
>
> https_port 3128 accel cert=/cert.pem key=/cert.key
>
> defaultsite=ww1.example.com vhost
>
> acl server20_domains dstdomain ww1.example.com ww2.example.com
>
> http_access allow server20_domains
>
> cache_peer server20 parent 443 0 no-query originserver name=server20
>
> login=PASSTHRU ssl sslversion=6
>
> cache_peer_access server20 allow server20_domains
>
> cache_peer_access server20 deny all
>
> The idea was to send ww1 and ww2 to server20 which is hosting an apache
>
> webservice for both sites.
>

That looks fine.

> You can see that approximately after 5s the timeout happens. Is it a 
> message
>
> to worry about? (it is just "info" labled) Why does it occur?
>
>

Unknown. This is an Apache problem. The Squid portion of things appears 
to be working if I'm reading that weird  access.log correctly.

Amos
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170424/76a8176a/attachment.htm>

From squid3 at treenet.co.nz  Sun Apr 23 16:03:25 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 24 Apr 2017 04:03:25 +1200
Subject: [squid-users] https_port Connection reset by peer;
 http_port works
In-Reply-To: <2548465.APt4bHOcTO@march>
References: <2548465.APt4bHOcTO@march>
Message-ID: <0ab52c0a-7546-b803-1855-8a3bfd63adee@treenet.co.nz>



On 23/04/17 04:32, chiasa.men wrote:
> Hello folks
>
> I tried to encrypt the connection between client and squid. Therefore I
> generated certificates which are accepted by the clients and configured squid
> as followed:
>
> Squid.conf
>    https_port 10.0.13.10:8443 cert=/cert.pem key=/cert.key
>    http_port 10.0.13.10:8080
>    http_access allow all
>
> My following tests show that I can use the http port for internet access but
> the https port wont work.
>    openssl s_client -connect proxy:8443
>    # Verify return code: 0 (ok)
>
>    export https_proxy="proxy:8443"
>    export http_proxy="proxy:8080"
>    curl https://www.google.de
>    # curl: (56) Recv failure: Connection reset by peer
>    curl http://www.google.de
>    # works
>    
>    export https_proxy="proxy:8443"
>    export http_proxy="$https_proxy"
>    curl https://www.google.de
>    # curl: (56) Recv failure: Connection reset by peer
>    curl http://www.google.de
>    # curl: (56) Recv failure: Connection reset by peer
>    
>    export http_proxy="proxy:8080"
>    export https_proxy="$http_proxy"
>    curl https://www.google.de
>    # works
>    curl http://www.google.de
>    # works
>
> What did I wrong? Do I misunderstand something regarding the configuration
> options?

You appear not to be using curl correctly.

Test #1 and #3 show that curl is probably sending the https:// requests 
through port 8080 on your proxy as a CONNECT request. Check that in your 
Squid log to confirm.

Test #2 is misconfigured. port 8443 on your proxy is not able to accept 
plain-text traffic.


AFAIK the "https_proxy" environment variable is a custom things invented 
by Google in part of their insistence not to allow users to configure 
TLS to a proxy via the Chrome GUI. It is not part of the normal POSIX 
environment like http_proxy is. So you cannot rely on non-Browser tools 
like curl supporting it.

Amos



From chiasa.men at web.de  Sun Apr 23 19:39:46 2017
From: chiasa.men at web.de (chiasa.men)
Date: Sun, 23 Apr 2017 21:39:46 +0200
Subject: [squid-users] https_port Connection reset by peer;
	http_port works
In-Reply-To: <0ab52c0a-7546-b803-1855-8a3bfd63adee@treenet.co.nz>
References: <2548465.APt4bHOcTO@march>
 <0ab52c0a-7546-b803-1855-8a3bfd63adee@treenet.co.nz>
Message-ID: <4254384.PYBvqD0rGS@march>

Am Sonntag, 23. April 2017, 18:03:25 CEST schrieb Amos Jeffries:
> You appear not to be using curl correctly.
> 

> Test #1 and #3 show that curl is probably sending the https:// requests
> through port 8080 on your proxy as a CONNECT request. Check that in your
> Squid log to confirm.

I wasn't aware of that thx, but nevertheless the problem still exists


curl -x 'proxy:8443'  https://www.google.de
  curl: (56) Recv failure: Connection reset by peer
# no log entry
curl -x 'proxy:8443'  http://www.google.de                                                                                                                                                                                                                
  curl: (56) Recv failure: Connection reset by peer
# no log entry

curl -x 'proxy:8080'  http://www.google.de
  # no output
[23/Apr/2017:19:28:53 +0000] "GET http://www.google.de/ HTTP/1.1" 301 206 "-" 
"curl/7.47.0" TCP_DENIED:HIER_NONE

curl -x 'proxy:8080'  https://www.google.de
  # works
[23/Apr/2017:19:29:27 +0000] "CONNECT www.google.de:443 HTTP/1.1" 200 15157 
"-" "curl/7.47.0" TCP_TUNNEL:HIER_DIRECT


The corresponding tcpdumps are here to be found: https://nopaste.me/view/
1e07d687



From rousskov at measurement-factory.com  Sun Apr 23 23:09:15 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 23 Apr 2017 17:09:15 -0600
Subject: [squid-users] https_port Connection reset by peer;
 http_port works
In-Reply-To: <0ab52c0a-7546-b803-1855-8a3bfd63adee@treenet.co.nz>
References: <2548465.APt4bHOcTO@march>
 <0ab52c0a-7546-b803-1855-8a3bfd63adee@treenet.co.nz>
Message-ID: <241a1637-2f35-ef5e-663e-15ae85c69bbc@measurement-factory.com>

On 04/23/2017 10:03 AM, Amos Jeffries wrote:

> you cannot rely on non-Browser tools like curl supporting [https_proxy environment variable].

... and to tell curl to use an HTTPS proxy (instead of an HTTP proxy),
use "https://" as the proxy scheme (instead of "http://" or no scheme at
all): https://daniel.haxx.se/blog/2016/11/26/https-proxy-with-curl/

HTH,

Alex.



From squid-users at filter.luko.org  Mon Apr 24 02:12:22 2017
From: squid-users at filter.luko.org (squid-users at filter.luko.org)
Date: Mon, 24 Apr 2017 12:12:22 +1000
Subject: [squid-users] Cache peer selection with duplicate host names
Message-ID: <000101d2bca0$3552be10$9ff83a30$@filter.luko.org>

Hi Squid users,

I'm having some trouble understanding Squid's peer selection algorithms, in
a configuration where multiple cache_peer lines reference the same host.

The background to this is that we wish to present cache service using
multiple accounts at an upstream provider, with account selection taking
place based on the local TCP port (8080, 8181, 8282) the request arrived on.

First we define the cache peers:

cache_peer proxy.myisp.net parent 8080 0 login=staffuser:abc123 no-query
no-digest no-netdb-exchange connect-timeout=1 connect-fail-limit=2
name=Staff
cache_peer proxy.myisp.net parent 8080 0 login=guestuser:abc123 no-query
no-digest no-netdb-exchange connect-timeout=1 connect-fail-limit=2
name=Guest
cache_peer proxy.myisp.net parent 8080 0 login=PASS no-query no-digest
no-netdb-exchange connect-timeout=1 connect-fail-limit=2 name=Student

Then lock access down:

acl localport_Staff localport 8282
acl localport_Guest localport 8181
acl localport_Student localport 8080
cache_peer_access Staff allow localport_Staff !localport_Guest
!localport_Student
cache_peer_access Guest allow localport_Guest !localport_Staff
!localport_Student
cache_peer_access Student allow localport_Student !localport_Guest
!localport_Staff

To reproduce the error, first a connection is made with wget to tcp port
8282:

  http_proxy=http://10.159.192.24:8282/ wget www.monash.edu --delete-after

Squid selects the Staff profile as expected:

  1492999376.993    811 10.159.192.26 TCP_MISS/200 780195 GET
http://www.monash.edu/ - FIRSTUP_PARENT/Staff text/html "EDU%20%20%20en"
"Wget/1.12 (linux-gnu)"

Then another connection is made, this time to port 8080:

  http_proxy=http://10.159.192.24:8080/ wget www.monash.edu --delete-after

But instead of the desired Student profile being selected, the Staff profile
is still used instead:

  1492999405.953    338 10.159.192.26 TCP_MISS/200 780195 GET
http://www.monash.edu/ - FIRSTUP_PARENT/Staff text/html "EDU%20%20%20en"
"Wget/1.12 (linux-gnu)"

I had a look in the cache.log with debug_options 44,6 enabled.  None of the
messages reference the contents of the name= parameter in the cache_peer
lines; only hostnames and IP addresses are mentioned.  I suspect that the
peer selection algorithms have changed since Squid 3.1, whereby peers are
now selected based on hostname (or IP address) rather than the name defined
in the cache_peer line.  Is this correct?  If so, is there any other way to
achieve the functionality outlined above (hit different usernames on an
upstream peer based on which localport the request arrived on?)

Cheers
Luke




From squid3 at treenet.co.nz  Mon Apr 24 02:57:45 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 24 Apr 2017 14:57:45 +1200
Subject: [squid-users] Cache peer selection with duplicate host names
In-Reply-To: <000101d2bca0$3552be10$9ff83a30$@filter.luko.org>
References: <000101d2bca0$3552be10$9ff83a30$@filter.luko.org>
Message-ID: <a0f234b9-1686-dc04-97e4-95b566c7793d@treenet.co.nz>

On 24/04/17 14:12, squid-users wrote:
> Hi Squid users,
>
> I'm having some trouble understanding Squid's peer selection algorithms, in
> a configuration where multiple cache_peer lines reference the same host.
>
> The background to this is that we wish to present cache service using
> multiple accounts at an upstream provider, with account selection taking
> place based on the local TCP port (8080, 8181, 8282) the request arrived on.
>
> First we define the cache peers:
>
> cache_peer proxy.myisp.net parent 8080 0 login=staffuser:abc123 no-query
> no-digest no-netdb-exchange connect-timeout=1 connect-fail-limit=2
> name=Staff
> cache_peer proxy.myisp.net parent 8080 0 login=guestuser:abc123 no-query
> no-digest no-netdb-exchange connect-timeout=1 connect-fail-limit=2
> name=Guest
> cache_peer proxy.myisp.net parent 8080 0 login=PASS no-query no-digest
> no-netdb-exchange connect-timeout=1 connect-fail-limit=2 name=Student
>
> Then lock access down:
>
> acl localport_Staff localport 8282
> acl localport_Guest localport 8181
> acl localport_Student localport 8080

localport is taken from the TCP connection arriving into Squid. It may 
be different to the Squid listening port.

So what are your http(s)_port lines ?


> cache_peer_access Staff allow localport_Staff !localport_Guest
> !localport_Student
> cache_peer_access Guest allow localport_Guest !localport_Staff
> !localport_Student
> cache_peer_access Student allow localport_Student !localport_Guest
> !localport_Staff

You do not need these !blah pieces. No single TCP connection can have 
multiple destination ports. So when one of your ACLs matches the others 
cannot be matches.


> To reproduce the error, first a connection is made with wget to tcp port
> 8282:
>
>    http_proxy=http://10.159.192.24:8282/ wget www.monash.edu --delete-after
>
> Squid selects the Staff profile as expected:
>
>    1492999376.993    811 10.159.192.26 TCP_MISS/200 780195 GET
> http://www.monash.edu/ - FIRSTUP_PARENT/Staff text/html "EDU%20%20%20en"
> "Wget/1.12 (linux-gnu)"
>
> Then another connection is made, this time to port 8080:
>
>    http_proxy=http://10.159.192.24:8080/ wget www.monash.edu --delete-after
>
> But instead of the desired Student profile being selected, the Staff profile
> is still used instead:
>
>    1492999405.953    338 10.159.192.26 TCP_MISS/200 780195 GET
> http://www.monash.edu/ - FIRSTUP_PARENT/Staff text/html "EDU%20%20%20en"
> "Wget/1.12 (linux-gnu)"
>
> I had a look in the cache.log with debug_options 44,6 enabled.  None of the
> messages reference the contents of the name= parameter in the cache_peer
> lines; only hostnames and IP addresses are mentioned.  I suspect that the
> peer selection algorithms have changed since Squid 3.1, whereby peers are
> now selected based on hostname (or IP address) rather than the name defined
> in the cache_peer line.  Is this correct?

No the peer selection still works based on the name.  But that name now 
gets translated to a list of IP:port destinations that can be tried by 
the forwarding logic.

I think what you are seeing is the side effect of the peers all having 
the same IP:port details versus HTTP persistent connections. When the 
forwarding logic looks for an open persistent connection for the Student 
IP:port it might get handed the existing Staff connection - since they 
both have the same IP:port they are the same server as far as HTTP is 
concerned.

You could try turning persistence to servers off
<http://www.squid-cache.org/Doc/config/server_persistent_connections/>

... or using a different port for each of the cache_peer lines and 
NAPT'ing them on the outgoing TCP connections back to what the upstream 
peer actually uses.


Amos



From omidkosari at yahoo.com  Mon Apr 24 07:33:02 2017
From: omidkosari at yahoo.com (Omid Kosari)
Date: Mon, 24 Apr 2017 00:33:02 -0700 (PDT)
Subject: [squid-users] Windows Updates a Caching Stub zone,
	A windows updates store.
In-Reply-To: <018f01d2b87c$59a02a50$0ce07ef0$@ngtech.co.il>
References: <004a01d1daf3$e6c4a490$b44dedb0$@ngtech.co.il>
 <1491489566256-4682002.post@n4.nabble.com>
 <05ce01d2aef3$1cb537d0$561fa770$@ngtech.co.il>
 <1492257145655-4682113.post@n4.nabble.com>
 <018f01d2b87c$59a02a50$0ce07ef0$@ngtech.co.il>
Message-ID: <1493019182595-4682189.post@n4.nabble.com>

Hello,

Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Windows-Updates-a-Caching-Stub-zone-A-windows-updates-store-tp4678454p4682189.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From nil_fergi at hotmail.com  Mon Apr 24 12:40:36 2017
From: nil_fergi at hotmail.com (Nil Nik)
Date: Mon, 24 Apr 2017 12:40:36 +0000
Subject: [squid-users] Huge memory required for squid 3.5
Message-ID: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>

Hello,

I am using squid 3.5.23, with heavy HTTPS load squid using almost 2GB of memory. I want to restrict this usages to maximum to 1 GB. This high usages seems due to ssl_bump. If I change 'generate-host-certificates' to 'off' then squid usages around 800 MB of memory. Previously i was using squid 3.3.9 and i never observed such behavior.

Please help me to use/fix high memory usages problem. Thanks in advance.

Regards,
Nil

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170424/e0fd4b66/attachment.htm>

From oliver at lennox-it.uk  Mon Apr 24 16:50:40 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Mon, 24 Apr 2017 16:50:40 +0000 (UTC)
Subject: [squid-users] Transparent Squidding Teething Issues
References: <2080294681.3302809.1493052640777.ref@mail.yahoo.com>
Message-ID: <2080294681.3302809.1493052640777@mail.yahoo.com>

Hi All,

First week testing the transparent squid proxy on the Raspberry Pi is going well so far but I've hit a few snags that I was hoping someone might be able to advise on. My current (SSL) config is:


------------------------http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow all

http_port 3130

http_port 3128 intercept 
https_port 3129 intercept ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/etc/squid3/ssl_cert/squid.crt key=/etc/squid3/ssl_cert/squid.key options=NO_SSLv3 dhparams=/etc/squid3/ssl_cert/dhparam.pem

acl nobumpserver ssl::server_name src "/etc/squid/nobump"
acl step1 at_step SslBump1

ssl_bump peek nobumpserver
ssl_bump splice nobumpserver

ssl_bump stare step1 !nobumpserver
ssl_bump bump !nobumpserver

sslproxy_cafile /etc/squid/ssl_cert/ca-bundle.crt

sslproxy_session_cache_size 0
sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/spool/squid_ssldb -M 4MB
sslcrtd_children 8 startup=1 idle=1
sslproxy_cert_error allow all
sslproxy_flags DONT_VERIFY_PEER
sslproxy_cipher EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384:EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:!RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS

I've also disabled caching for now since the little pi wasn't quite coping with it (I think the flash memory cards they use are a bit slow) and overall internet performance was suffering.

-----------------------

My questions are:

1. Are there any techniques / acls to handle streaming content? Ideally I'd like all streaming content to be spliced not bumped

2. There seems to be a problem with sending larger content over bumped HTTPS (receiving is fine). For example WhatsApp and Snapchat receive messages and rich content fine and you can send messages fine but trying to send rich content like video or images fails with connection errors.

3. Skype doesn't seem to work unless you specify explicit proxy settings in the config (point it at the proxy server / 3130 port). Is this to be expected or could it be fixed in the config?

4. Sorry I know this is probably in the wiki but is there an acl for source (client) address? For devices like Smart TV where it is difficult to install the certificate it would be useful to set these to always splice 

Thanks very much!

Olly
 
oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252


From rousskov at measurement-factory.com  Tue Apr 25 14:31:35 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 25 Apr 2017 08:31:35 -0600
Subject: [squid-users] Cache peer selection with duplicate host names
In-Reply-To: <a0f234b9-1686-dc04-97e4-95b566c7793d@treenet.co.nz>
References: <000101d2bca0$3552be10$9ff83a30$@filter.luko.org>
 <a0f234b9-1686-dc04-97e4-95b566c7793d@treenet.co.nz>
Message-ID: <09985f13-f4d0-6bb9-dffb-8cf4f355d500@measurement-factory.com>

On 04/23/2017 08:57 PM, Amos Jeffries wrote:

> When the
> forwarding logic looks for an open persistent connection for the Student
> IP:port it might get handed the existing Staff connection

FWIW, this behavior is a Squid bug: Since a peer has several
traffic-affecting properties besides its address, the connection
selection logic must obey peer selection choices, even if all peers have
the same addresses. The same underlying problem might result in the
wrong peer used after a hot reconfiguration, even if all peers have
distinct addresses.

Please report this bug to Squid bugzilla. This bug does not have a
trivial fix but hopefully somebody will volunteer to provide or sponsor one.


Thank you,

Alex.
P.S. Workarounds and workload cleanup suggested by Amos is good advice.
I just wanted clearly classify this as a bug (rather than desirable
behavior), so providing or facilitating a quality fix would be welcomed.



From squid3 at treenet.co.nz  Tue Apr 25 14:45:04 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 26 Apr 2017 02:45:04 +1200
Subject: [squid-users] Huge memory required for squid 3.5
In-Reply-To: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
References: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
Message-ID: <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>

On 25/04/17 00:40, Nil Nik wrote:
> Hello,
>
> I am using squid 3.5.23, with heavy HTTPS load squid using almost 2GB 
> of memory. I want to restrict this usages to maximum to 1 GB. This 
> high usages seems due to ssl_bump. If I change 
> 'generate-host-certificates' to 'off' then squid usages around 800 MB 
> of memory. Previously i was using squid 3.3.9 and i never observed 
> such behavior.
>
> Please help me to use/fix high memory usages problem. Thanks in advance.

Try adding this parameter to your http(s)_port lines:
   sslflags=NO_DEFAULT_CA


Amos

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170426/643e7b50/attachment.htm>

From yvoinov at gmail.com  Tue Apr 25 21:58:26 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 26 Apr 2017 03:58:26 +0600
Subject: [squid-users] Huge memory required for squid 3.5
In-Reply-To: <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>
References: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
 <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>
Message-ID: <9df6619a-0155-1494-9321-f05d919e48b5@gmail.com>

Seriously? 2 Gb RAM for default CA?!


25.04.2017 20:45, Amos Jeffries ?????:
> On 25/04/17 00:40, Nil Nik wrote:
>> Hello,
>>
>> I am using squid 3.5.23, with heavy HTTPS load squid using almost 2GB
>> of memory. I want to restrict this usages to maximum to 1 GB. This
>> high usages seems due to ssl_bump. If I change
>> 'generate-host-certificates' to 'off' then squid usages around 800 MB
>> of memory. Previously i was using squid 3.3.9 and i never observed
>> such behavior.
>>
>> Please help me to use/fix high memory usages problem. Thanks in advance.
>
> Try adding this parameter to your http(s)_port lines:
>   sslflags=NO_DEFAULT_CA
>
>
> Amos
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170426/1f25184b/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170426/1f25184b/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170426/1f25184b/attachment.sig>

From squid3 at treenet.co.nz  Tue Apr 25 22:29:03 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 26 Apr 2017 10:29:03 +1200
Subject: [squid-users] Huge memory required for squid 3.5
In-Reply-To: <9df6619a-0155-1494-9321-f05d919e48b5@gmail.com>
References: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
 <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>
 <9df6619a-0155-1494-9321-f05d919e48b5@gmail.com>
Message-ID: <deb8451f-98de-426d-f3a0-e952f803e6c7@treenet.co.nz>

On 26/04/17 09:58, Yuri Voinov wrote:
>
> Seriously? 2 Gb RAM for default CA?!
>
>

600 (number of default CAs) x 2048 (minimum size of CA cert)  -> ~1 MB

All it would take is ~2000 TLS sessions.

Since the session remains cached in OpenSSL after the TCP connection is 
gone ... 2GB is not that much.


Amos



From yvoinov at gmail.com  Tue Apr 25 22:48:36 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 26 Apr 2017 04:48:36 +0600
Subject: [squid-users] Huge memory required for squid 3.5
In-Reply-To: <deb8451f-98de-426d-f3a0-e952f803e6c7@treenet.co.nz>
References: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
 <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>
 <9df6619a-0155-1494-9321-f05d919e48b5@gmail.com>
 <deb8451f-98de-426d-f3a0-e952f803e6c7@treenet.co.nz>
Message-ID: <7976b3f5-52c2-b6e5-28c4-f7e9ec2d0735@gmail.com>

Ah, shi........ (goes to set flag)


26.04.2017 4:29, Amos Jeffries ?????:
> On 26/04/17 09:58, Yuri Voinov wrote:
>>
>> Seriously? 2 Gb RAM for default CA?!
>>
>>
>
> 600 (number of default CAs) x 2048 (minimum size of CA cert)  -> ~1 MB
>
> All it would take is ~2000 TLS sessions.
>
> Since the session remains cached in OpenSSL after the TCP connection
> is gone ... 2GB is not that much.
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170426/ab2f95e2/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170426/ab2f95e2/attachment.sig>

From yvoinov at gmail.com  Tue Apr 25 22:53:30 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 26 Apr 2017 04:53:30 +0600
Subject: [squid-users] Huge memory required for squid 3.5
In-Reply-To: <deb8451f-98de-426d-f3a0-e952f803e6c7@treenet.co.nz>
References: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
 <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>
 <9df6619a-0155-1494-9321-f05d919e48b5@gmail.com>
 <deb8451f-98de-426d-f3a0-e952f803e6c7@treenet.co.nz>
Message-ID: <215c7b2a-f034-5913-f0fe-00c2f4511b72@gmail.com>

Ok, but how NO_DEFAULT_CA should help with this?


26.04.2017 4:29, Amos Jeffries ?????:
> On 26/04/17 09:58, Yuri Voinov wrote:
>>
>> Seriously? 2 Gb RAM for default CA?!
>>
>>
>
> 600 (number of default CAs) x 2048 (minimum size of CA cert)  -> ~1 MB
>
> All it would take is ~2000 TLS sessions.
>
> Since the session remains cached in OpenSSL after the TCP connection
> is gone ... 2GB is not that much.
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170426/f8ee9300/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170426/f8ee9300/attachment.sig>

From squid3 at treenet.co.nz  Wed Apr 26 03:08:41 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 26 Apr 2017 15:08:41 +1200
Subject: [squid-users] Huge memory required for squid 3.5
In-Reply-To: <215c7b2a-f034-5913-f0fe-00c2f4511b72@gmail.com>
References: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
 <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>
 <9df6619a-0155-1494-9321-f05d919e48b5@gmail.com>
 <deb8451f-98de-426d-f3a0-e952f803e6c7@treenet.co.nz>
 <215c7b2a-f034-5913-f0fe-00c2f4511b72@gmail.com>
Message-ID: <123f43b6-4d76-9493-32c7-a0b05a794618@treenet.co.nz>

On 26/04/17 10:53, Yuri Voinov wrote:
> Ok, but how NO_DEFAULT_CA should help with this?

It prevents OpenSSL copying that 1MB into each incoming client 
connections memory. The CAs are only useful there when you have some of 
the global CAs as root for client certificates - in which case you still 
only want to trust the roots you paid for service and not all of them.

Just something to try if there are huge memory issues with TLS/SSL 
proxying. The default behaviour is fixed for Squid-4 with the config 
options changes. But due to being a major surprise for anyone already 
relying on global roots for client certs it remains a problem in 3.5.

Amos



From sabu.thaliyath at gmail.com  Wed Apr 26 07:00:53 2017
From: sabu.thaliyath at gmail.com (Sabu Thaliyath)
Date: Wed, 26 Apr 2017 12:30:53 +0530
Subject: [squid-users] Huge memory required for squid 3.5
In-Reply-To: <123f43b6-4d76-9493-32c7-a0b05a794618@treenet.co.nz>
References: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
 <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>
 <9df6619a-0155-1494-9321-f05d919e48b5@gmail.com>
 <deb8451f-98de-426d-f3a0-e952f803e6c7@treenet.co.nz>
 <215c7b2a-f034-5913-f0fe-00c2f4511b72@gmail.com>
 <123f43b6-4d76-9493-32c7-a0b05a794618@treenet.co.nz>
Message-ID: <CAC=ab-_6AYGdE1zV5qMRq=UrW=zh3rmwPWHUB+DtrGMZe9WLhg@mail.gmail.com>

Hi,

I have the same issue as Nil. I have set No_DEFAULT_CA and also did
"generate-host-certificates=off".  I see with these changes it takes more
time reach 2GB but it does reach there (in about 6 hours for me with peak
usage).

These were my settings.

https_port 192.168.0.10:3129 generate-host-certificates=off
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/myserver.pem intercept
ssl-bump sslflags=NO_DEFAULT_CA
https_port 192.168.0.10:3128 generate-host-certificates=off
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/myserver.pem intercept
ssl-bump sslflags=NO_DEFAULT_CA

I did a 10 minutes test to compare the behavior in Squid 3.3 and squid 3.5.
My test scenario was kept exactly same except for following diff in squid
3.5.

acl exceptions ssl::server_name_regex "/etc/squid/exception_list.txt"
acl step1 at_step SslBump1
acl step2 at_step SslBump2
ssl_bump peek step1 all !exceptions
ssl_bump splice step2 !exceptions

Here are the results after 10mins -

1. When I didn't use NO_DEFAULT_CA and generate-host-certificates=on

Squid 3.3 = 550MB
Squid 3.5 = 1.1GB

2. When I use NO_DEFAULT_CA and generate-host-certificates=off

Squid 3.3 = 402MB
Squid 3.5 = 560MB

So it looks like Squid 3.5 have higher mem usage than 3.3 in both cases
which makes me wonder, is it that more CAs are being loaded into cache in
3.5 ?

Also, is there any more change  I can do to my config to arrest the memory
growth to 2GB  in 3.5 in my production system ? I got only 4Gb RAM.


Thanks and Regards,
Davis

On Wed, Apr 26, 2017 at 8:38 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 26/04/17 10:53, Yuri Voinov wrote:
>
>> Ok, but how NO_DEFAULT_CA should help with this?
>>
>
> It prevents OpenSSL copying that 1MB into each incoming client connections
> memory. The CAs are only useful there when you have some of the global CAs
> as root for client certificates - in which case you still only want to
> trust the roots you paid for service and not all of them.
>
> Just something to try if there are huge memory issues with TLS/SSL
> proxying. The default behaviour is fixed for Squid-4 with the config
> options changes. But due to being a major surprise for anyone already
> relying on global roots for client certs it remains a problem in 3.5.
>
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170426/c4154640/attachment.htm>

From bhoslepu at gmail.com  Wed Apr 26 12:04:18 2017
From: bhoslepu at gmail.com (prashantbhosale)
Date: Wed, 26 Apr 2017 05:04:18 -0700 (PDT)
Subject: [squid-users] Squid with MySQL auth not denying pages with
Message-ID: <1493208258327-4682200.post@n4.nabble.com>

I am setting up simple squid server for denying URL's. Below is my squid
config, URL's are getting blocked and TCP_DENIED/403 seen in access.log
file. 
But not showing error message/page shown in browser.

Another main task that I want to do is Squid authentication with MySQL.
Followed the instructions provided on
http://wiki.squid-cache.org/ConfigExamples/Authenticate/Mysql#Squid_Installation
Auth is working. But one problem is now the denied log is with
TCP_DENIED/407 instead of TCP_DENIED/403
and no user is specified in log.
1493126753.944      0 x.x.x.x TCP_DENIED/407 4510 GET
http://tg.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBRVuMwyhZnBGWkFKlkeoNe9zdlbSwQUK5o1rgEYODDhcHoF4BF2o869kBQCED3fM9dlZGIkaXhmllPjYgM%3D
- HIER_NONE/- text/html


Below is config with MySQL auth: 
ubuntu at proxy:~$ cat /etc/squid/squid.conf
auth_param basic program /usr/lib/squid3/basic_db_auth --user root
--password pass at 123 --plaintext  --persist
auth_param basic children 5 startup=5 idle=1
auth_param basic realm Squid proxy-caching web server
auth_param basic credentialsttl 2 hours

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports

http_access allow localhost manager
http_access deny manager

#acl db-auth proxy_auth REQUIRED
#http_access allow db-auth

acl addomain dstdomain "/etc/squid/addomains.acl"
http_access deny addomain

acl easyprivacy-regex url_regex -i "/etc/squid/easyprivacy.txt"
acl easylist-regex url_regex -i "/etc/squid/easylist.txt"
http_access deny easylist-regex
http_access deny easyprivacy-regex

http_access allow all
http_access allow localhost

http_port 3128 

coredump_dir /var/spool/squid

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern (Release|Packages(.gz)*)$      0       20%     2880

refresh_pattern .               0       20%     4320


Advanced Thanks for help!!!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-with-MySQL-auth-not-denying-pages-with-tp4682200.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed Apr 26 13:21:21 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 27 Apr 2017 01:21:21 +1200
Subject: [squid-users] Squid with MySQL auth not denying pages with
In-Reply-To: <1493208258327-4682200.post@n4.nabble.com>
References: <1493208258327-4682200.post@n4.nabble.com>
Message-ID: <c4fd8ecf-7239-bb71-53d5-9146678f9b08@treenet.co.nz>

On 27/04/17 00:04, prashantbhosale wrote:
> I am setting up simple squid server for denying URL's. Below is my squid
> config, URL's are getting blocked and TCP_DENIED/403 seen in access.log
> file.
> But not showing error message/page shown in browser.
>
> Another main task that I want to do is Squid authentication with MySQL.
> Followed the instructions provided on
> http://wiki.squid-cache.org/ConfigExamples/Authenticate/Mysql#Squid_Installation
> Auth is working. But one problem is now the denied log is with
> TCP_DENIED/407 instead of TCP_DENIED/403
> and no user is specified in log.

This usually means the browser did not send any credentials at all to 
Squid. The 407 is Squid telling the browser it needs to login.

> 1493126753.944      0 x.x.x.x TCP_DENIED/407 4510 GET
> http://tg.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBRVuMwyhZnBGWkFKlkeoNe9zdlbSwQUK5o1rgEYODDhcHoF4BF2o869kBQCED3fM9dlZGIkaXhmllPjYgM%3D
> - HIER_NONE/- text/html
> Below is config with MySQL auth:
> ubuntu at proxy:~$ cat /etc/squid/squid.conf
> auth_param basic program /usr/lib/squid3/basic_db_auth --user root
> --password pass at 123 --plaintext  --persist

Okay ... assuming the defaults: your database name is 'squid', table 
name is 'passwd', and has an 'enabled' column containing '1' for the 
user account being tested.

If not then the 407 is authentication will fail due to the SQL query not 
returning any useful credentials to compare with those given by the 
browser(if any).

...
> #acl db-auth proxy_auth REQUIRED
> #http_access allow db-auth

The above (when uncommented) will only allow authenticated users. Any 
clients sending bad credentials will just skip to the next lines... 
eventually reaching that "allow all". So much for requiring login.

Better security practice is to perform checks that do not require login, 
then:
   http_access deny !db-login

then to do any allow/deny things for authenticated users.

> acl addomain dstdomain "/etc/squid/addomains.acl"
> http_access deny addomain
>
> acl easyprivacy-regex url_regex -i "/etc/squid/easyprivacy.txt"
> acl easylist-regex url_regex -i "/etc/squid/easylist.txt"
> http_access deny easylist-regex
> http_access deny easyprivacy-regex
>
> http_access allow all

Any http_access lines following this "allow all" are unreachable and 
pointless.

> http_access allow localhost
>
> http_port 3128
>


Amos


From yvoinov at gmail.com  Wed Apr 26 15:35:04 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 26 Apr 2017 21:35:04 +0600
Subject: [squid-users] Huge memory required for squid 3.5
In-Reply-To: <123f43b6-4d76-9493-32c7-a0b05a794618@treenet.co.nz>
References: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
 <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>
 <9df6619a-0155-1494-9321-f05d919e48b5@gmail.com>
 <deb8451f-98de-426d-f3a0-e952f803e6c7@treenet.co.nz>
 <215c7b2a-f034-5913-f0fe-00c2f4511b72@gmail.com>
 <123f43b6-4d76-9493-32c7-a0b05a794618@treenet.co.nz>
Message-ID: <73c06bc6-87b6-d8c9-0d93-eeb6645cb1ac@gmail.com>

Amos, stupid question.

Why sessions can't share CA's data cached in memory? shared_ptr invented
already.

This is openssl issue or squid's?


26.04.2017 9:08, Amos Jeffries ?????:
> On 26/04/17 10:53, Yuri Voinov wrote:
>> Ok, but how NO_DEFAULT_CA should help with this?
>
> It prevents OpenSSL copying that 1MB into each incoming client
> connections memory. The CAs are only useful there when you have some
> of the global CAs as root for client certificates - in which case you
> still only want to trust the roots you paid for service and not all of
> them.
>
> Just something to try if there are huge memory issues with TLS/SSL
> proxying. The default behaviour is fixed for Squid-4 with the config
> options changes. But due to being a major surprise for anyone already
> relying on global roots for client certs it remains a problem in 3.5.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170426/c4f50458/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170426/c4f50458/attachment.sig>

From squid3 at treenet.co.nz  Wed Apr 26 15:47:50 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 27 Apr 2017 03:47:50 +1200
Subject: [squid-users] Huge memory required for squid 3.5
In-Reply-To: <73c06bc6-87b6-d8c9-0d93-eeb6645cb1ac@gmail.com>
References: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
 <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>
 <9df6619a-0155-1494-9321-f05d919e48b5@gmail.com>
 <deb8451f-98de-426d-f3a0-e952f803e6c7@treenet.co.nz>
 <215c7b2a-f034-5913-f0fe-00c2f4511b72@gmail.com>
 <123f43b6-4d76-9493-32c7-a0b05a794618@treenet.co.nz>
 <73c06bc6-87b6-d8c9-0d93-eeb6645cb1ac@gmail.com>
Message-ID: <9201d533-7e24-9355-47f0-b3492cd644dd@treenet.co.nz>

On 27/04/17 03:35, Yuri Voinov wrote:
> Amos, stupid question.
>
> Why sessions can't share CA's data cached in memory? shared_ptr invented
> already.
>
> This is openssl issue or squid's?

It is in OpenSSL. We use shared_ptr etc in Squid for the things we are 
responsible for.

Amos



From yvoinov at gmail.com  Wed Apr 26 15:53:19 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Wed, 26 Apr 2017 21:53:19 +0600
Subject: [squid-users] Huge memory required for squid 3.5
In-Reply-To: <9201d533-7e24-9355-47f0-b3492cd644dd@treenet.co.nz>
References: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
 <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>
 <9df6619a-0155-1494-9321-f05d919e48b5@gmail.com>
 <deb8451f-98de-426d-f3a0-e952f803e6c7@treenet.co.nz>
 <215c7b2a-f034-5913-f0fe-00c2f4511b72@gmail.com>
 <123f43b6-4d76-9493-32c7-a0b05a794618@treenet.co.nz>
 <73c06bc6-87b6-d8c9-0d93-eeb6645cb1ac@gmail.com>
 <9201d533-7e24-9355-47f0-b3492cd644dd@treenet.co.nz>
Message-ID: <32dd8255-2aa9-3d2a-1343-070bfe72eaea@gmail.com>



26.04.2017 21:47, Amos Jeffries ?????:
> On 27/04/17 03:35, Yuri Voinov wrote:
>> Amos, stupid question.
>>
>> Why sessions can't share CA's data cached in memory? shared_ptr invented
>> already.
>>
>> This is openssl issue or squid's?
>
> It is in OpenSSL. We use shared_ptr etc in Squid for the things we are
> responsible for.
Wwwwwwww. As I tought. So, in other versions of squid we're have the
same issue, right? Up to 5.x?
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170426/84cf3757/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170426/84cf3757/attachment.sig>

From rousskov at measurement-factory.com  Wed Apr 26 19:37:37 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 26 Apr 2017 13:37:37 -0600
Subject: [squid-users] Huge memory required for squid 3.5
In-Reply-To: <73c06bc6-87b6-d8c9-0d93-eeb6645cb1ac@gmail.com>
References: <BY1PR10MB035749313DCF1A119188D86D841F0@BY1PR10MB0357.namprd10.prod.outlook.com>
 <50abe60c-8559-c559-afce-9f03a28032f8@treenet.co.nz>
 <9df6619a-0155-1494-9321-f05d919e48b5@gmail.com>
 <deb8451f-98de-426d-f3a0-e952f803e6c7@treenet.co.nz>
 <215c7b2a-f034-5913-f0fe-00c2f4511b72@gmail.com>
 <123f43b6-4d76-9493-32c7-a0b05a794618@treenet.co.nz>
 <73c06bc6-87b6-d8c9-0d93-eeb6645cb1ac@gmail.com>
Message-ID: <35f15acb-9b86-edc7-1152-a53dfaabfc22@measurement-factory.com>

On 04/26/2017 09:35 AM, Yuri Voinov wrote:

> This is openssl issue or squid's?

AFAIK, the underlying issue (i.e., bug #4005) is mostly a Squid problem:
Squid is caching SSL contexts (instead of certificates) and does a poor
job maintaining that cache.

Earlier OpenSSL versions (that had to be used when the original code was
written) complicated solving this problem. OpenSSL v1.0.1+ added APIs
that simplify some aspects of the anticipated fix. Certain OpenSSL
aspects will continue to hurt Squid, even with OpenSSL v1.0.1, but if
you want to blame a single project (instead of both), blame Squid.


> Why sessions can't share CA's data cached in memory? shared_ptr invented
> already.

OpenSSL knew how to share things well before std::shared_ptr became
available. However, it is the responsibility of the application to tell
OpenSSL what to create from scratch and what to share. A part of the
problem is that Squid tells OpenSSL to create many large things from
scratch and then caches those large things while underestimating their
size by several(?) orders of magnitude (and probably also missing many
cache hits).

More details, including the difference between problems associated with
from-client and to-server connections, are documented in the "Memory
Usage" section of http://wiki.squid-cache.org/Features/SslBump

FWIW, we have spent a lot of resources on triaging this problem and
drafting possible solutions (in various overlapping areas), but there is
currently no sponsor to finalize and implement any of the fixes. AFAIK,
bug #4005 is stuck.

I am glad that NO_DEFAULT_CA helps mitigate some of the problems in some
environments.


HTH,

Alex.


> 26.04.2017 9:08, Amos Jeffries ?????:
>> On 26/04/17 10:53, Yuri Voinov wrote:
>>> Ok, but how NO_DEFAULT_CA should help with this?
>>
>> It prevents OpenSSL copying that 1MB into each incoming client
>> connections memory. The CAs are only useful there when you have some
>> of the global CAs as root for client certificates - in which case you
>> still only want to trust the roots you paid for service and not all of
>> them.
>>
>> Just something to try if there are huge memory issues with TLS/SSL
>> proxying. The default behaviour is fixed for Squid-4 with the config
>> options changes. But due to being a major surprise for anyone already
>> relying on global roots for client certs it remains a problem in 3.5.
>>
>> Amos
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From bhoslepu at gmail.com  Thu Apr 27 04:01:05 2017
From: bhoslepu at gmail.com (prashantbhosale)
Date: Wed, 26 Apr 2017 21:01:05 -0700 (PDT)
Subject: [squid-users] Squid with MySQL auth not denying pages with
In-Reply-To: <c4fd8ecf-7239-bb71-53d5-9146678f9b08@treenet.co.nz>
References: <1493208258327-4682200.post@n4.nabble.com>
 <c4fd8ecf-7239-bb71-53d5-9146678f9b08@treenet.co.nz>
Message-ID: <1493265665008-4682206.post@n4.nabble.com>

Thanks Amos for reply!!!

>>On 27/04/17 00:04, prashantbhosale wrote:

>> I am setting up simple squid server for denying URL's. Below is my squid
>> config, URL's are getting blocked and TCP_DENIED/403 seen in access.log
>> file.
>> But not showing error message/page shown in browser.
>>
>> Another main task that I want to do is Squid authentication with MySQL.
>> Followed the instructions provided on
>> http://wiki.squid-cache.org/ConfigExamples/Authenticate/Mysql#Squid_Installation
>> Auth is working. But one problem is now the denied log is with
>> TCP_DENIED/407 instead of TCP_DENIED/403
>> and no user is specified in log.
>This usually means the browser did not send any credentials at all to
Squid. The 407 is Squid telling the browser it needs to login.

I agree with this, but I am authenticated on browser and these
TCP_DENIED/407 logs for the ad URL's that are present on viewing page.

>> 1493126753.944      0 x.x.x.x TCP_DENIED/407 4510 GET
>> http://tg.symcd.com/MFEwTzBNMEswSTAJBgUrDgMCGgUABBRVuMwyhZnBGWkFKlkeoNe9zdlbSwQUK5o1rgEYODDhcHoF4BF2o869kBQCED3fM9dlZGIkaXhmllPjYgM%3D
>> - HIER_NONE/- text/html
>> Below is config with MySQL auth:
>> ubuntu at proxy:~$ cat /etc/squid/squid.conf
>> auth_param basic program /usr/lib/squid3/basic_db_auth --user root
>> --password pass at 123 --plaintext  --persist
>Okay ... assuming the defaults: your database name is 'squid', table
name is 'passwd', and has an 'enabled' column containing '1' for the
user account being tested.

Yes, using defaults and I have tested login on command-line also aas
ubuntu at ip-172-31-33-25:~$ /usr/lib/squid3/basic_db_auth --user root
--password pass at 123 --plaintext --persist
test pass
OK


>If not then the 407 is authentication will fail due to the SQL query not
returning any useful credentials to compare with those given by the
browser(if any).

...
>> #acl db-auth proxy_auth REQUIRED
>> #http_access allow db-auth
>The above (when uncommented) will only allow authenticated users. Any
clients sending bad credentials will just skip to the next lines...
eventually reaching that "allow all". So much for requiring login.
>Better security practice is to perform checks that do not require login,
then:
   http_access deny !db-login
>then to do any allow/deny things for authenticated users.

Will give try to this.

>> acl addomain dstdomain "/etc/squid/addomains.acl"
>> http_access deny addomain
>>
>> acl easyprivacy-regex url_regex -i "/etc/squid/easyprivacy.txt"
>> acl easylist-regex url_regex -i "/etc/squid/easylist.txt"
>> http_access deny easylist-regex
>> http_access deny easyprivacy-regex
>>
>> http_access allow all
>Any http_access lines following this "allow all" are unreachable and
pointless.

I agree.

>> http_access allow localhost
>>
>> http_port 3128
>>

>Amos
_______________________________________________
>>squid-users mailing list
>>[hidden email]
>>http://lists.squid-cache.org/listinfo/squid-users



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-with-MySQL-auth-not-denying-pages-with-user-details-tp4682200p4682206.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From flashdown at data-core.org  Thu Apr 27 16:16:39 2017
From: flashdown at data-core.org (Flashdown)
Date: Thu, 27 Apr 2017 18:16:39 +0200
Subject: [squid-users] ssl bump and chrome 58
In-Reply-To: <f822ef50-731e-ec12-3b1f-144ce1f48347@gmail.com>
References: <20170421142934.241ce2cf@efreet-freebsd.kappastar.com>
 <f822ef50-731e-ec12-3b1f-144ce1f48347@gmail.com>
Message-ID: <e12127951db2c3923f57ba0b4af8de78@data-core.org>

Hello together,

Suddenly I am facing the same issue when users Chrome has been updated 
to V58. I am running Squid 3.5.23.

This is the reason: 
https://www.thesslstore.com/blog/security-changes-in-chrome-58/
Short: Common Name Support Removed in Chrome 58 and Squid does not 
create certs with DNS-Alternatives names in it. Because of that it 
fails.

Chrome says:
1. Subject Alternative Name Missing - The certificate for this site does 
not contain a Subject Alternative Name extension containing a domain 
name or IP address.
2. Certificate Error - There are issues with the site's certificate 
chain (net::ERR_CERT_COMMON_NAME_INVALID).

Can we get Squid to add the DNS-Alternative Name to the generated certs? 
Since this is what I believe is now required in Chrome 58+

Best regards,
Enrico


Am 2017-04-21 15:35, schrieb Yuri Voinov:
> I see no problem with it on all five SSL Bump-aware servers with new
> Chrome. So fare so good.
> 
> 
> 21.04.2017 18:29, Marko Cupa? ?????:
>> Hi,
>> 
>> I have squid setup with ssl bump which worked fine, but since I 
>> updated
>> chrome to 58 it won't display any https sites, throwing
>> NTT:ERR_CERT_COMMON_NAME_INVALID. https sites still work in previous
>> chrome version, as well as in IE.
>> 
>> Anything I can do in squid config to get ssl-bumped sites in chrome
>> again?
>> 
>> Thank you in advance,
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From flashdown at data-core.org  Thu Apr 27 16:34:38 2017
From: flashdown at data-core.org (Flashdown)
Date: Thu, 27 Apr 2017 18:34:38 +0200
Subject: [squid-users] ssl bump and chrome 58
In-Reply-To: <e12127951db2c3923f57ba0b4af8de78@data-core.org>
References: <20170421142934.241ce2cf@efreet-freebsd.kappastar.com>
 <f822ef50-731e-ec12-3b1f-144ce1f48347@gmail.com>
 <e12127951db2c3923f57ba0b4af8de78@data-core.org>
Message-ID: <3e7c47a85eca33d1f2cd3331ab782857@data-core.org>

Hello together,

here is a workaround that you could use in the meanwhile.

https://www.chromium.org/administrators/policy-list-3#EnableCommonNameFallbackForLocalAnchors

Source: 
https://www.chromium.org/administrators/policy-list-3#EnableCommonNameFallbackForLocalAnchors
>>>>> BEGIN
EnableCommonNameFallbackForLocalAnchors
Whether to allow certificates issued by local trust anchors that are 
missing the subjectAlternativeName extension

Data type:
     Boolean [Windows:REG_DWORD]
Windows registry location:
     
Software\Policies\Google\Chrome\EnableCommonNameFallbackForLocalAnchors
Mac/Linux preference name:
     EnableCommonNameFallbackForLocalAnchors
Android restriction name:
     EnableCommonNameFallbackForLocalAnchors
Supported on:

         Google Chrome (Linux, Mac, Windows) since version 58 until 
version 65
         Google Chrome OS (Google Chrome OS) since version 58 until 
version 65
         Google Chrome (Android) since version 58 until version 65

Supported features:
     Dynamic Policy Refresh: Yes, Per Profile: No
Description:

     When this setting is enabled, Google Chrome will use the commonName 
of a server certificate to match a hostname if the certificate is 
missing a subjectAlternativeName extension, as long as it successfully 
validates and chains to a locally-installed CA certificates.

     Note that this is not recommended, as this may allow bypassing the 
nameConstraints extension that restricts the hostnames that a given 
certificate can be authorized for.

     If this policy is not set, or is set to false, server certificates 
that lack a subjectAlternativeName extension containing either a DNS 
name or IP address will not be trusted.
Example value:
     0x00000000 (Windows), false (Linux), false (Android), <false /> 
(Mac)
<<<<<<<<<<<< END



Am 2017-04-27 18:16, schrieb Flashdown:
> Hello together,
> 
> Suddenly I am facing the same issue when users Chrome has been updated
> to V58. I am running Squid 3.5.23.
> 
> This is the reason:
> https://www.thesslstore.com/blog/security-changes-in-chrome-58/
> Short: Common Name Support Removed in Chrome 58 and Squid does not
> create certs with DNS-Alternatives names in it. Because of that it
> fails.
> 
> Chrome says:
> 1. Subject Alternative Name Missing - The certificate for this site
> does not contain a Subject Alternative Name extension containing a
> domain name or IP address.
> 2. Certificate Error - There are issues with the site's certificate
> chain (net::ERR_CERT_COMMON_NAME_INVALID).
> 
> Can we get Squid to add the DNS-Alternative Name to the generated
> certs? Since this is what I believe is now required in Chrome 58+
> 
> Best regards,
> Enrico
> 
> 
> Am 2017-04-21 15:35, schrieb Yuri Voinov:
>> I see no problem with it on all five SSL Bump-aware servers with new
>> Chrome. So fare so good.
>> 
>> 
>> 21.04.2017 18:29, Marko Cupa? ?????:
>>> Hi,
>>> 
>>> I have squid setup with ssl bump which worked fine, but since I 
>>> updated
>>> chrome to 58 it won't display any https sites, throwing
>>> NTT:ERR_CERT_COMMON_NAME_INVALID. https sites still work in previous
>>> chrome version, as well as in IE.
>>> 
>>> Anything I can do in squid config to get ssl-bumped sites in chrome
>>> again?
>>> 
>>> Thank you in advance,
>> 
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From flashdown at data-core.org  Thu Apr 27 16:41:48 2017
From: flashdown at data-core.org (Flashdown)
Date: Thu, 27 Apr 2017 18:41:48 +0200
Subject: [squid-users] ssl bump and chrome 58
In-Reply-To: <3e7c47a85eca33d1f2cd3331ab782857@data-core.org>
References: <20170421142934.241ce2cf@efreet-freebsd.kappastar.com>
 <f822ef50-731e-ec12-3b1f-144ce1f48347@gmail.com>
 <e12127951db2c3923f57ba0b4af8de78@data-core.org>
 <3e7c47a85eca33d1f2cd3331ab782857@data-core.org>
Message-ID: <a6ee678d1e41241f678c71380c05862a@data-core.org>

I've tested the registry setting and it worked out. You can copy the 
below lines in a .reg file and execute it.

Windows Registry Editor Version 5.00

[HKEY_LOCAL_MACHINE\SOFTWARE\Policies\Google\Chrome]
"EnableCommonNameFallbackForLocalAnchors"=dword:00000001


Best regards,
Flashdown

Am 2017-04-27 18:34, schrieb Flashdown:
> Hello together,
> 
> here is a workaround that you could use in the meanwhile.
> 
> https://www.chromium.org/administrators/policy-list-3#EnableCommonNameFallbackForLocalAnchors
> 
> Source:
> https://www.chromium.org/administrators/policy-list-3#EnableCommonNameFallbackForLocalAnchors
>>>>>> BEGIN
> EnableCommonNameFallbackForLocalAnchors
> Whether to allow certificates issued by local trust anchors that are
> missing the subjectAlternativeName extension
> 
> Data type:
>     Boolean [Windows:REG_DWORD]
> Windows registry location:
>     
> Software\Policies\Google\Chrome\EnableCommonNameFallbackForLocalAnchors
> Mac/Linux preference name:
>     EnableCommonNameFallbackForLocalAnchors
> Android restriction name:
>     EnableCommonNameFallbackForLocalAnchors
> Supported on:
> 
>         Google Chrome (Linux, Mac, Windows) since version 58 until 
> version 65
>         Google Chrome OS (Google Chrome OS) since version 58 until 
> version 65
>         Google Chrome (Android) since version 58 until version 65
> 
> Supported features:
>     Dynamic Policy Refresh: Yes, Per Profile: No
> Description:
> 
>     When this setting is enabled, Google Chrome will use the
> commonName of a server certificate to match a hostname if the
> certificate is missing a subjectAlternativeName extension, as long as
> it successfully validates and chains to a locally-installed CA
> certificates.
> 
>     Note that this is not recommended, as this may allow bypassing the
> nameConstraints extension that restricts the hostnames that a given
> certificate can be authorized for.
> 
>     If this policy is not set, or is set to false, server certificates
> that lack a subjectAlternativeName extension containing either a DNS
> name or IP address will not be trusted.
> Example value:
>     0x00000000 (Windows), false (Linux), false (Android), <false /> 
> (Mac)
> <<<<<<<<<<<< END
> 
> 
> 
> Am 2017-04-27 18:16, schrieb Flashdown:
>> Hello together,
>> 
>> Suddenly I am facing the same issue when users Chrome has been updated
>> to V58. I am running Squid 3.5.23.
>> 
>> This is the reason:
>> https://www.thesslstore.com/blog/security-changes-in-chrome-58/
>> Short: Common Name Support Removed in Chrome 58 and Squid does not
>> create certs with DNS-Alternatives names in it. Because of that it
>> fails.
>> 
>> Chrome says:
>> 1. Subject Alternative Name Missing - The certificate for this site
>> does not contain a Subject Alternative Name extension containing a
>> domain name or IP address.
>> 2. Certificate Error - There are issues with the site's certificate
>> chain (net::ERR_CERT_COMMON_NAME_INVALID).
>> 
>> Can we get Squid to add the DNS-Alternative Name to the generated
>> certs? Since this is what I believe is now required in Chrome 58+
>> 
>> Best regards,
>> Enrico
>> 
>> 
>> Am 2017-04-21 15:35, schrieb Yuri Voinov:
>>> I see no problem with it on all five SSL Bump-aware servers with new
>>> Chrome. So fare so good.
>>> 
>>> 
>>> 21.04.2017 18:29, Marko Cupa? ?????:
>>>> Hi,
>>>> 
>>>> I have squid setup with ssl bump which worked fine, but since I 
>>>> updated
>>>> chrome to 58 it won't display any https sites, throwing
>>>> NTT:ERR_CERT_COMMON_NAME_INVALID. https sites still work in previous
>>>> chrome version, as well as in IE.
>>>> 
>>>> Anything I can do in squid config to get ssl-bumped sites in chrome
>>>> again?
>>>> 
>>>> Thank you in advance,
>>> 
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From david at articatech.com  Thu Apr 27 16:47:42 2017
From: david at articatech.com (David Touzeau)
Date: Thu, 27 Apr 2017 18:47:42 +0200
Subject: [squid-users] 3.5.25: (71) Protocol error (TLS code:
	SQUID_ERR_SSL_HANDSHAKE)
Message-ID: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>


Hi,
I'm unable to access to https://www.boutique.afnor.org website.
I would like to know if this issue cannot be fixed and must deny bump
website to fix it.
Without Squid the website is correctly displayed 

Squid claim an error page with "(71) Protocol error (TLS code:
SQUID_ERR_SSL_HANDSHAKE)"

In cache.log: "Error negotiating SSL on FD 17:
error:00000000:lib(0):func(0):reason(0) (5/0/0)"

Using the following configuration:

http_port 0.0.0.0:3128  name=MyPortNameID20 ssl-bump
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
cert=/etc/squid3/ssl/0c451f46b4d05031560d8195f30165cb.dyn
sslproxy_foreign_intermediate_certs /etc/squid3/intermediate_ca.pem
sslcrtd_program /lib/squid3/ssl_crtd -s /var/lib/squid/session/ssl/ssl_db -M
8MB
sslcrtd_children 16 startup=5 idle=1
acl FakeCert ssl::server_name .apple.com
acl FakeCert ssl::server_name .icloud.com
acl FakeCert ssl::server_name .mzstatic.com
acl FakeCert ssl::server_name .dropbox.com
acl ssl_step1 at_step SslBump1
acl ssl_step2 at_step SslBump2
acl ssl_step3 at_step SslBump3
ssl_bump peek ssl_step1
ssl_bump splice FakeCert
ssl_bump bump ssl_step2 all
ssl_bump splice all

sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression
sslproxy_cipher
ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:!aNULL
:!eNULL
sslproxy_flags DONT_VERIFY_PEER
sslproxy_cert_error allow all



Openssl info 
----------------------------------------------------------------------------
----------------------------------------------------------------------------
---

openssl s_client -connect 195.115.26.58:443 -showcerts

CONNECTED(00000003)
depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, OU = "(c)
2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class 3 Public
Primary Certification Authority - G5
verify return:1
depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust Network, CN =
Symantec Class 3 Secure Server CA - G4
verify return:1
depth=0 C = FR, ST = Seine Saint Denis, L = ST DENIS, O = ASSOCIATION
FRANCAISE DE NORMALISATION, OU = ASSOCIATION FRANCAISE DE NORMALISATION, CN
= www.boutique.afnor.org
verify return:1
---
Certificate chain
 0 s:/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE DE
NORMALISATION/OU=ASSOCIATION FRANCAISE DE
NORMALISATION/CN=www.boutique.afnor.org
   i:/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec
Class 3 Secure Server CA - G4
-----BEGIN CERTIFICATE-----
../..
-----END CERTIFICATE-----
 1 s:/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec
Class 3 Secure Server CA - G4
   i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006 VeriSign,
Inc. - For authorized use only/CN=VeriSign Class 3 Public Primary
Certification Authority - G5
-----BEGIN CERTIFICATE-----
../..
-----END CERTIFICATE-----
---
Server certificate
subject=/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE DE
NORMALISATION/OU=ASSOCIATION FRANCAISE DE
NORMALISATION/CN=www.boutique.afnor.org
issuer=/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec
Class 3 Secure Server CA - G4
---
No client certificate CA names sent
---
SSL handshake has read 3105 bytes and written 616 bytes
---
New, TLSv1/SSLv3, Cipher is AES128-SHA
Server public key is 2048 bit
Secure Renegotiation IS supported
Compression: NONE
Expansion: NONE
SSL-Session:
    Protocol  : TLSv1
    Cipher    : AES128-SHA
    Session-ID:
833B0000A2346F50C5AAFC6B5188B4EBD9304CD25411BECFF0713F8D76C65D9D
    Session-ID-ctx:
    Master-Key:
D2DF6C62264D03D7D44AF44EB8C0B1B7AD0E650D34DF6EBEB1CBEBFE4F30CB9C6F5080AA94F5
D6B5955DD8DF06608416
    Key-Arg   : None
    PSK identity: None
    PSK identity hint: None
    SRP username: None
    Start Time: 1493311275
    Timeout   : 300 (sec)
    Verify return code: 0 (ok)
---
read:errno=0





From william.lima at hscbrasil.com.br  Thu Apr 27 16:50:28 2017
From: william.lima at hscbrasil.com.br (William Lima)
Date: Thu, 27 Apr 2017 13:50:28 -0300 (BRT)
Subject: [squid-users] ssl bump and chrome 58
In-Reply-To: <a6ee678d1e41241f678c71380c05862a@data-core.org>
Message-ID: <1022307122.778.1493311828131.JavaMail.root@hscbrasil.com.br>

Hi,

The problem occurs due to some ssl_bump directive actions, so Squid cannot get all information (X.509 v3 extensions) to mimic. "ssl_bump server-first all" should work.

William Lima

----- Original Message -----
From: "Flashdown" <flashdown at data-core.org>
To: "Yuri Voinov" <yvoinov at gmail.com>
Cc: squid-users at lists.squid-cache.org
Sent: Thursday, April 27, 2017 1:41:48 PM
Subject: Re: [squid-users] ssl bump and chrome 58

I've tested the registry setting and it worked out. You can copy the 
below lines in a .reg file and execute it.

Windows Registry Editor Version 5.00

[HKEY_LOCAL_MACHINE\SOFTWARE\Policies\Google\Chrome]
"EnableCommonNameFallbackForLocalAnchors"=dword:00000001


Best regards,
Flashdown

Am 2017-04-27 18:34, schrieb Flashdown:
> Hello together,
> 
> here is a workaround that you could use in the meanwhile.
> 
> https://www.chromium.org/administrators/policy-list-3#EnableCommonNameFallbackForLocalAnchors
> 
> Source:
> https://www.chromium.org/administrators/policy-list-3#EnableCommonNameFallbackForLocalAnchors
>>>>>> BEGIN
> EnableCommonNameFallbackForLocalAnchors
> Whether to allow certificates issued by local trust anchors that are
> missing the subjectAlternativeName extension
> 
> Data type:
>     Boolean [Windows:REG_DWORD]
> Windows registry location:
>     
> Software\Policies\Google\Chrome\EnableCommonNameFallbackForLocalAnchors
> Mac/Linux preference name:
>     EnableCommonNameFallbackForLocalAnchors
> Android restriction name:
>     EnableCommonNameFallbackForLocalAnchors
> Supported on:
> 
>         Google Chrome (Linux, Mac, Windows) since version 58 until 
> version 65
>         Google Chrome OS (Google Chrome OS) since version 58 until 
> version 65
>         Google Chrome (Android) since version 58 until version 65
> 
> Supported features:
>     Dynamic Policy Refresh: Yes, Per Profile: No
> Description:
> 
>     When this setting is enabled, Google Chrome will use the
> commonName of a server certificate to match a hostname if the
> certificate is missing a subjectAlternativeName extension, as long as
> it successfully validates and chains to a locally-installed CA
> certificates.
> 
>     Note that this is not recommended, as this may allow bypassing the
> nameConstraints extension that restricts the hostnames that a given
> certificate can be authorized for.
> 
>     If this policy is not set, or is set to false, server certificates
> that lack a subjectAlternativeName extension containing either a DNS
> name or IP address will not be trusted.
> Example value:
>     0x00000000 (Windows), false (Linux), false (Android), <false /> 
> (Mac)
> <<<<<<<<<<<< END
> 
> 
> 
> Am 2017-04-27 18:16, schrieb Flashdown:
>> Hello together,
>> 
>> Suddenly I am facing the same issue when users Chrome has been updated
>> to V58. I am running Squid 3.5.23.
>> 
>> This is the reason:
>> https://www.thesslstore.com/blog/security-changes-in-chrome-58/
>> Short: Common Name Support Removed in Chrome 58 and Squid does not
>> create certs with DNS-Alternatives names in it. Because of that it
>> fails.
>> 
>> Chrome says:
>> 1. Subject Alternative Name Missing - The certificate for this site
>> does not contain a Subject Alternative Name extension containing a
>> domain name or IP address.
>> 2. Certificate Error - There are issues with the site's certificate
>> chain (net::ERR_CERT_COMMON_NAME_INVALID).
>> 
>> Can we get Squid to add the DNS-Alternative Name to the generated
>> certs? Since this is what I believe is now required in Chrome 58+
>> 
>> Best regards,
>> Enrico
>> 
>> 
>> Am 2017-04-21 15:35, schrieb Yuri Voinov:
>>> I see no problem with it on all five SSL Bump-aware servers with new
>>> Chrome. So fare so good.
>>> 
>>> 
>>> 21.04.2017 18:29, Marko Cupa? ?????:
>>>> Hi,
>>>> 
>>>> I have squid setup with ssl bump which worked fine, but since I 
>>>> updated
>>>> chrome to 58 it won't display any https sites, throwing
>>>> NTT:ERR_CERT_COMMON_NAME_INVALID. https sites still work in previous
>>>> chrome version, as well as in IE.
>>>> 
>>>> Anything I can do in squid config to get ssl-bumped sites in chrome
>>>> again?
>>>> 
>>>> Thank you in advance,
>>> 
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


From oliver at lennox-it.uk  Thu Apr 27 16:53:29 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Thu, 27 Apr 2017 16:53:29 +0000 (UTC)
Subject: [squid-users] 3.5.25: (71) Protocol error (TLS
	code:	SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>
References: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>
Message-ID: <1221336131.6185573.1493312009233@mail.yahoo.com>

Hi David,

I'm battling with similar problems at the moment. One thing that I've found is that the system seems happier when you don't peek prior to a bump, my current config is:

acl nobumpserver ssl::server_name "/etc/squid/nobump"
acl ignoreclients src "/etc/squid/nobumpclients"
acl step1 at_step SslBump1

ssl_bump peek nobumpserver step1
ssl_bump peek ignoreclients step1
ssl_bump splice nobumpserver
ssl_bump splice ignoreclients 

ssl_bump stare step1 !nobumpserver !ignoreclients 

ssl_bump bump !nobumpserver !ignoreclients

where nobump is a list of regex domains (like .apple.com) and nobumpclients is a list of IPs I never want to bump. I'm still battling with errors and sites not always working but of all the configurations I've tried this one seems to work for the majority of sites

Cheers, 
oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252



________________________________
From: David Touzeau <david at articatech.com>
To: squid-users at lists.squid-cache.org 
Sent: Thursday, 27 April 2017, 17:48
Subject: [squid-users] 3.5.25: (71) Protocol error (TLS code:    SQUID_ERR_SSL_HANDSHAKE)




Hi,

I'm unable to access to https://www.boutique.afnor.org website.

I would like to know if this issue cannot be fixed and must deny bump

website to fix it.

Without Squid the website is correctly displayed 


Squid claim an error page with "(71) Protocol error (TLS code:

SQUID_ERR_SSL_HANDSHAKE)"


In cache.log: "Error negotiating SSL on FD 17:

error:00000000:lib(0):func(0):reason(0) (5/0/0)"


Using the following configuration:


http_port 0.0.0.0:3128  name=MyPortNameID20 ssl-bump

generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

cert=/etc/squid3/ssl/0c451f46b4d05031560d8195f30165cb.dyn

sslproxy_foreign_intermediate_certs /etc/squid3/intermediate_ca.pem

sslcrtd_program /lib/squid3/ssl_crtd -s /var/lib/squid/session/ssl/ssl_db -M

8MB

sslcrtd_children 16 startup=5 idle=1

acl FakeCert ssl::server_name .apple.com

acl FakeCert ssl::server_name .icloud.com

acl FakeCert ssl::server_name .mzstatic.com

acl FakeCert ssl::server_name .dropbox.com

acl ssl_step1 at_step SslBump1

acl ssl_step2 at_step SslBump2

acl ssl_step3 at_step SslBump3

ssl_bump peek ssl_step1

ssl_bump splice FakeCert

ssl_bump bump ssl_step2 all

ssl_bump splice all


sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression

sslproxy_cipher

ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:!aNULL

:!eNULL

sslproxy_flags DONT_VERIFY_PEER

sslproxy_cert_error allow all




Openssl info 

----------------------------------------------------------------------------

----------------------------------------------------------------------------

---


openssl s_client -connect 195.115.26.58:443 -showcerts


CONNECTED(00000003)

depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, OU = "(c)

2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class 3 Public

Primary Certification Authority - G5

verify return:1

depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust Network, CN =

Symantec Class 3 Secure Server CA - G4

verify return:1

depth=0 C = FR, ST = Seine Saint Denis, L = ST DENIS, O = ASSOCIATION

FRANCAISE DE NORMALISATION, OU = ASSOCIATION FRANCAISE DE NORMALISATION, CN

= www.boutique.afnor.org

verify return:1

---

Certificate chain

0 s:/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE DE

NORMALISATION/OU=ASSOCIATION FRANCAISE DE

NORMALISATION/CN=www.boutique.afnor.org

   i:/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec

Class 3 Secure Server CA - G4

-----BEGIN CERTIFICATE-----

../..

-----END CERTIFICATE-----

1 s:/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec

Class 3 Secure Server CA - G4

   i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006 VeriSign,

Inc. - For authorized use only/CN=VeriSign Class 3 Public Primary

Certification Authority - G5

-----BEGIN CERTIFICATE-----

../..

-----END CERTIFICATE-----

---

Server certificate

subject=/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE DE

NORMALISATION/OU=ASSOCIATION FRANCAISE DE

NORMALISATION/CN=www.boutique.afnor.org

issuer=/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec

Class 3 Secure Server CA - G4

---

No client certificate CA names sent

---

SSL handshake has read 3105 bytes and written 616 bytes

---

New, TLSv1/SSLv3, Cipher is AES128-SHA

Server public key is 2048 bit

Secure Renegotiation IS supported

Compression: NONE

Expansion: NONE

SSL-Session:

    Protocol  : TLSv1

    Cipher    : AES128-SHA

    Session-ID:

833B0000A2346F50C5AAFC6B5188B4EBD9304CD25411BECFF0713F8D76C65D9D

    Session-ID-ctx:

    Master-Key:

D2DF6C62264D03D7D44AF44EB8C0B1B7AD0E650D34DF6EBEB1CBEBFE4F30CB9C6F5080AA94F5

D6B5955DD8DF06608416

    Key-Arg   : None

    PSK identity: None

    PSK identity hint: None

    SRP username: None

    Start Time: 1493311275

    Timeout   : 300 (sec)

    Verify return code: 0 (ok)

---

read:errno=0




_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org

http://lists.squid-cache.org/listinfo/squid-users


From yvoinov at gmail.com  Thu Apr 27 17:25:37 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 27 Apr 2017 23:25:37 +0600
Subject: [squid-users] ssl bump and chrome 58
In-Reply-To: <1022307122.778.1493311828131.JavaMail.root@hscbrasil.com.br>
References: <1022307122.778.1493311828131.JavaMail.root@hscbrasil.com.br>
Message-ID: <135bfd38-bca5-0e50-b18a-c4729c1d408f@gmail.com>

3.5 and above have "server-first" only for backward compatibility.


27.04.2017 22:50, William Lima ?????:
> Hi,
>
> The problem occurs due to some ssl_bump directive actions, so Squid cannot get all information (X.509 v3 extensions) to mimic. "ssl_bump server-first all" should work.
>
> William Lima
>
> ----- Original Message -----
> From: "Flashdown" <flashdown at data-core.org>
> To: "Yuri Voinov" <yvoinov at gmail.com>
> Cc: squid-users at lists.squid-cache.org
> Sent: Thursday, April 27, 2017 1:41:48 PM
> Subject: Re: [squid-users] ssl bump and chrome 58
>
> I've tested the registry setting and it worked out. You can copy the 
> below lines in a .reg file and execute it.
>
> Windows Registry Editor Version 5.00
>
> [HKEY_LOCAL_MACHINE\SOFTWARE\Policies\Google\Chrome]
> "EnableCommonNameFallbackForLocalAnchors"=dword:00000001
>
>
> Best regards,
> Flashdown
>
> Am 2017-04-27 18:34, schrieb Flashdown:
>> Hello together,
>>
>> here is a workaround that you could use in the meanwhile.
>>
>> https://www.chromium.org/administrators/policy-list-3#EnableCommonNameFallbackForLocalAnchors
>>
>> Source:
>> https://www.chromium.org/administrators/policy-list-3#EnableCommonNameFallbackForLocalAnchors
>>>>>>> BEGIN
>> EnableCommonNameFallbackForLocalAnchors
>> Whether to allow certificates issued by local trust anchors that are
>> missing the subjectAlternativeName extension
>>
>> Data type:
>>     Boolean [Windows:REG_DWORD]
>> Windows registry location:
>>     
>> Software\Policies\Google\Chrome\EnableCommonNameFallbackForLocalAnchors
>> Mac/Linux preference name:
>>     EnableCommonNameFallbackForLocalAnchors
>> Android restriction name:
>>     EnableCommonNameFallbackForLocalAnchors
>> Supported on:
>>
>>         Google Chrome (Linux, Mac, Windows) since version 58 until 
>> version 65
>>         Google Chrome OS (Google Chrome OS) since version 58 until 
>> version 65
>>         Google Chrome (Android) since version 58 until version 65
>>
>> Supported features:
>>     Dynamic Policy Refresh: Yes, Per Profile: No
>> Description:
>>
>>     When this setting is enabled, Google Chrome will use the
>> commonName of a server certificate to match a hostname if the
>> certificate is missing a subjectAlternativeName extension, as long as
>> it successfully validates and chains to a locally-installed CA
>> certificates.
>>
>>     Note that this is not recommended, as this may allow bypassing the
>> nameConstraints extension that restricts the hostnames that a given
>> certificate can be authorized for.
>>
>>     If this policy is not set, or is set to false, server certificates
>> that lack a subjectAlternativeName extension containing either a DNS
>> name or IP address will not be trusted.
>> Example value:
>>     0x00000000 (Windows), false (Linux), false (Android), <false /> 
>> (Mac)
>> <<<<<<<<<<<< END
>>
>>
>>
>> Am 2017-04-27 18:16, schrieb Flashdown:
>>> Hello together,
>>>
>>> Suddenly I am facing the same issue when users Chrome has been updated
>>> to V58. I am running Squid 3.5.23.
>>>
>>> This is the reason:
>>> https://www.thesslstore.com/blog/security-changes-in-chrome-58/
>>> Short: Common Name Support Removed in Chrome 58 and Squid does not
>>> create certs with DNS-Alternatives names in it. Because of that it
>>> fails.
>>>
>>> Chrome says:
>>> 1. Subject Alternative Name Missing - The certificate for this site
>>> does not contain a Subject Alternative Name extension containing a
>>> domain name or IP address.
>>> 2. Certificate Error - There are issues with the site's certificate
>>> chain (net::ERR_CERT_COMMON_NAME_INVALID).
>>>
>>> Can we get Squid to add the DNS-Alternative Name to the generated
>>> certs? Since this is what I believe is now required in Chrome 58+
>>>
>>> Best regards,
>>> Enrico
>>>
>>>
>>> Am 2017-04-21 15:35, schrieb Yuri Voinov:
>>>> I see no problem with it on all five SSL Bump-aware servers with new
>>>> Chrome. So fare so good.
>>>>
>>>>
>>>> 21.04.2017 18:29, Marko Cupa? ?????:
>>>>> Hi,
>>>>>
>>>>> I have squid setup with ssl bump which worked fine, but since I 
>>>>> updated
>>>>> chrome to 58 it won't display any https sites, throwing
>>>>> NTT:ERR_CERT_COMMON_NAME_INVALID. https sites still work in previous
>>>>> chrome version, as well as in IE.
>>>>>
>>>>> Anything I can do in squid config to get ssl-bumped sites in chrome
>>>>> again?
>>>>>
>>>>> Thank you in advance,
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170427/6560be29/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170427/6560be29/attachment.sig>

From yvoinov at gmail.com  Thu Apr 27 17:28:34 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Thu, 27 Apr 2017 23:28:34 +0600
Subject: [squid-users] 3.5.25: (71) Protocol error (TLS code:
 SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>
References: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>
Message-ID: <7b204020-8394-b61d-6545-57d8c7d9bd49@gmail.com>

This one?

http://i.imgur.com/kI9SxiN.png

It's works under bump.


27.04.2017 22:47, David Touzeau ?????:
> Hi,
> I'm unable to access to https://www.boutique.afnor.org website.
> I would like to know if this issue cannot be fixed and must deny bump
> website to fix it.
> Without Squid the website is correctly displayed 
>
> Squid claim an error page with "(71) Protocol error (TLS code:
> SQUID_ERR_SSL_HANDSHAKE)"
>
> In cache.log: "Error negotiating SSL on FD 17:
> error:00000000:lib(0):func(0):reason(0) (5/0/0)"
>
> Using the following configuration:
>
> http_port 0.0.0.0:3128  name=MyPortNameID20 ssl-bump
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

> cert=/etc/squid3/ssl/0c451f46b4d05031560d8195f30165cb.dyn
What's is this? Which certificate?
> sslproxy_foreign_intermediate_certs /etc/squid3/intermediate_ca.pem
> sslcrtd_program /lib/squid3/ssl_crtd -s /var/lib/squid/session/ssl/ssl_db -M
> 8MB
> sslcrtd_children 16 startup=5 idle=1
> acl FakeCert ssl::server_name .apple.com
> acl FakeCert ssl::server_name .icloud.com
> acl FakeCert ssl::server_name .mzstatic.com
> acl FakeCert ssl::server_name .dropbox.com
> acl ssl_step1 at_step SslBump1
> acl ssl_step2 at_step SslBump2
> acl ssl_step3 at_step SslBump3
> ssl_bump peek ssl_step1
> ssl_bump splice FakeCert
> ssl_bump bump ssl_step2 all
> ssl_bump splice all
>
> sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression
> sslproxy_cipher
> ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:!aNULL
> :!eNULL
> sslproxy_flags DONT_VERIFY_PEER
> sslproxy_cert_error allow all
>
>
>
> Openssl info 
> ----------------------------------------------------------------------------
> ----------------------------------------------------------------------------
> ---
>
> openssl s_client -connect 195.115.26.58:443 -showcerts
>
> CONNECTED(00000003)
> depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, OU = "(c)
> 2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class 3 Public
> Primary Certification Authority - G5
> verify return:1
> depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust Network, CN =
> Symantec Class 3 Secure Server CA - G4
> verify return:1
> depth=0 C = FR, ST = Seine Saint Denis, L = ST DENIS, O = ASSOCIATION
> FRANCAISE DE NORMALISATION, OU = ASSOCIATION FRANCAISE DE NORMALISATION, CN
> = www.boutique.afnor.org
> verify return:1
> ---
> Certificate chain
>  0 s:/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE DE
> NORMALISATION/OU=ASSOCIATION FRANCAISE DE
> NORMALISATION/CN=www.boutique.afnor.org
>    i:/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec
> Class 3 Secure Server CA - G4
> -----BEGIN CERTIFICATE-----
> ../..
> -----END CERTIFICATE-----
>  1 s:/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec
> Class 3 Secure Server CA - G4
>    i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006 VeriSign,
> Inc. - For authorized use only/CN=VeriSign Class 3 Public Primary
> Certification Authority - G5
> -----BEGIN CERTIFICATE-----
> ../..
> -----END CERTIFICATE-----
> ---
> Server certificate
> subject=/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE DE
> NORMALISATION/OU=ASSOCIATION FRANCAISE DE
> NORMALISATION/CN=www.boutique.afnor.org
> issuer=/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec
> Class 3 Secure Server CA - G4
> ---
> No client certificate CA names sent
> ---
> SSL handshake has read 3105 bytes and written 616 bytes
> ---
> New, TLSv1/SSLv3, Cipher is AES128-SHA
> Server public key is 2048 bit
> Secure Renegotiation IS supported
> Compression: NONE
> Expansion: NONE
> SSL-Session:
>     Protocol  : TLSv1
>     Cipher    : AES128-SHA
>     Session-ID:
> 833B0000A2346F50C5AAFC6B5188B4EBD9304CD25411BECFF0713F8D76C65D9D
>     Session-ID-ctx:
>     Master-Key:
> D2DF6C62264D03D7D44AF44EB8C0B1B7AD0E650D34DF6EBEB1CBEBFE4F30CB9C6F5080AA94F5
> D6B5955DD8DF06608416
>     Key-Arg   : None

>     PSK identity: None
>     PSK identity hint: None
>     SRP username: None
>     Start Time: 1493311275
>     Timeout   : 300 (sec)
>     Verify return code: 0 (ok)
> ---
> read:errno=0
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170427/e6003008/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170427/e6003008/attachment.sig>

From yvoinov at gmail.com  Thu Apr 27 20:09:28 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 28 Apr 2017 02:09:28 +0600
Subject: [squid-users] 3.5.25: (71) Protocol error (TLS code:
 SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>
References: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>
Message-ID: <c088c83f-ac6b-f463-7948-47463d0703a3@gmail.com>

Look. It can be intermediate certificates issue.

Does Squid have Symantec intermediate certificates?


27.04.2017 22:47, David Touzeau ?????:
> Hi,
> I'm unable to access to https://www.boutique.afnor.org website.
> I would like to know if this issue cannot be fixed and must deny bump
> website to fix it.
> Without Squid the website is correctly displayed 
>
> Squid claim an error page with "(71) Protocol error (TLS code:
> SQUID_ERR_SSL_HANDSHAKE)"
>
> In cache.log: "Error negotiating SSL on FD 17:
> error:00000000:lib(0):func(0):reason(0) (5/0/0)"
>
> Using the following configuration:
>
> http_port 0.0.0.0:3128  name=MyPortNameID20 ssl-bump
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> cert=/etc/squid3/ssl/0c451f46b4d05031560d8195f30165cb.dyn
> sslproxy_foreign_intermediate_certs /etc/squid3/intermediate_ca.pem
> sslcrtd_program /lib/squid3/ssl_crtd -s /var/lib/squid/session/ssl/ssl_db -M
> 8MB
> sslcrtd_children 16 startup=5 idle=1
> acl FakeCert ssl::server_name .apple.com
> acl FakeCert ssl::server_name .icloud.com
> acl FakeCert ssl::server_name .mzstatic.com
> acl FakeCert ssl::server_name .dropbox.com
> acl ssl_step1 at_step SslBump1
> acl ssl_step2 at_step SslBump2
> acl ssl_step3 at_step SslBump3
> ssl_bump peek ssl_step1
> ssl_bump splice FakeCert
> ssl_bump bump ssl_step2 all
> ssl_bump splice all
>
> sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression
> sslproxy_cipher
> ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:!aNULL
> :!eNULL
> sslproxy_flags DONT_VERIFY_PEER
> sslproxy_cert_error allow all
>
>
>
> Openssl info 
> ----------------------------------------------------------------------------
> ----------------------------------------------------------------------------
> ---
>
> openssl s_client -connect 195.115.26.58:443 -showcerts
>
> CONNECTED(00000003)
> depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, OU = "(c)
> 2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class 3 Public
> Primary Certification Authority - G5
> verify return:1
> depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust Network, CN =
> Symantec Class 3 Secure Server CA - G4
> verify return:1
> depth=0 C = FR, ST = Seine Saint Denis, L = ST DENIS, O = ASSOCIATION
> FRANCAISE DE NORMALISATION, OU = ASSOCIATION FRANCAISE DE NORMALISATION, CN
> = www.boutique.afnor.org
> verify return:1
> ---
> Certificate chain
>  0 s:/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE DE
> NORMALISATION/OU=ASSOCIATION FRANCAISE DE
> NORMALISATION/CN=www.boutique.afnor.org
>    i:/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec
> Class 3 Secure Server CA - G4
> -----BEGIN CERTIFICATE-----
> ../..
> -----END CERTIFICATE-----
>  1 s:/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec
> Class 3 Secure Server CA - G4
>    i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006 VeriSign,
> Inc. - For authorized use only/CN=VeriSign Class 3 Public Primary
> Certification Authority - G5
> -----BEGIN CERTIFICATE-----
> ../..
> -----END CERTIFICATE-----
> ---
> Server certificate
> subject=/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE DE
> NORMALISATION/OU=ASSOCIATION FRANCAISE DE
> NORMALISATION/CN=www.boutique.afnor.org
> issuer=/C=US/O=Symantec Corporation/OU=Symantec Trust Network/CN=Symantec
> Class 3 Secure Server CA - G4
> ---
> No client certificate CA names sent
> ---
> SSL handshake has read 3105 bytes and written 616 bytes
> ---
> New, TLSv1/SSLv3, Cipher is AES128-SHA
> Server public key is 2048 bit
> Secure Renegotiation IS supported
> Compression: NONE
> Expansion: NONE
> SSL-Session:
>     Protocol  : TLSv1
>     Cipher    : AES128-SHA
>     Session-ID:
> 833B0000A2346F50C5AAFC6B5188B4EBD9304CD25411BECFF0713F8D76C65D9D
>     Session-ID-ctx:
>     Master-Key:
> D2DF6C62264D03D7D44AF44EB8C0B1B7AD0E650D34DF6EBEB1CBEBFE4F30CB9C6F5080AA94F5
> D6B5955DD8DF06608416
>     Key-Arg   : None
>     PSK identity: None
>     PSK identity hint: None
>     SRP username: None
>     Start Time: 1493311275
>     Timeout   : 300 (sec)
>     Verify return code: 0 (ok)
> ---
> read:errno=0
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170428/70ae3331/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170428/70ae3331/attachment.sig>

From david at articatech.com  Thu Apr 27 20:27:47 2017
From: david at articatech.com (David Touzeau)
Date: Thu, 27 Apr 2017 22:27:47 +0200
Subject: [squid-users] 3.5.25: (71) Protocol error (TLS code:
	SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <c088c83f-ac6b-f463-7948-47463d0703a3@gmail.com>
References: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>
 <c088c83f-ac6b-f463-7948-47463d0703a3@gmail.com>
Message-ID: <073901d2bf94$bceb2dc0$36c18940$@articatech.com>

Hi yuri

I did not know if squid have Symantec intermediate certificate
Squid is installed as default...
Any howto ?


-----Message d'origine-----
De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Yuri Voinov
Envoy? : jeudi 27 avril 2017 22:09
? : squid-users at lists.squid-cache.org
Objet : Re: [squid-users] 3.5.25: (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)

Look. It can be intermediate certificates issue.

Does Squid have Symantec intermediate certificates?


27.04.2017 22:47, David Touzeau ?????:
> Hi,
> I'm unable to access to https://www.boutique.afnor.org website.
> I would like to know if this issue cannot be fixed and must deny bump 
> website to fix it.
> Without Squid the website is correctly displayed
>
> Squid claim an error page with "(71) Protocol error (TLS code:
> SQUID_ERR_SSL_HANDSHAKE)"
>
> In cache.log: "Error negotiating SSL on FD 17:
> error:00000000:lib(0):func(0):reason(0) (5/0/0)"
>
> Using the following configuration:
>
> http_port 0.0.0.0:3128  name=MyPortNameID20 ssl-bump 
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
> cert=/etc/squid3/ssl/0c451f46b4d05031560d8195f30165cb.dyn
> sslproxy_foreign_intermediate_certs /etc/squid3/intermediate_ca.pem 
> sslcrtd_program /lib/squid3/ssl_crtd -s 
> /var/lib/squid/session/ssl/ssl_db -M 8MB sslcrtd_children 16 startup=5 
> idle=1 acl FakeCert ssl::server_name .apple.com acl FakeCert 
> ssl::server_name .icloud.com acl FakeCert ssl::server_name 
> .mzstatic.com acl FakeCert ssl::server_name .dropbox.com acl ssl_step1 
> at_step SslBump1 acl ssl_step2 at_step SslBump2 acl ssl_step3 at_step 
> SslBump3 ssl_bump peek ssl_step1 ssl_bump splice FakeCert ssl_bump 
> bump ssl_step2 all ssl_bump splice all
>
> sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression sslproxy_cipher 
> ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:
> !aNULL
> :!eNULL
> sslproxy_flags DONT_VERIFY_PEER
> sslproxy_cert_error allow all
>
>
>
> Openssl info
> ----------------------------------------------------------------------
> ------
> ----------------------------------------------------------------------
> ------
> ---
>
> openssl s_client -connect 195.115.26.58:443 -showcerts
>
> CONNECTED(00000003)
> depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, OU 
> = "(c)
> 2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class 3 
> Public Primary Certification Authority - G5 verify return:1
> depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust Network, 
> CN = Symantec Class 3 Secure Server CA - G4 verify return:1
> depth=0 C = FR, ST = Seine Saint Denis, L = ST DENIS, O = ASSOCIATION 
> FRANCAISE DE NORMALISATION, OU = ASSOCIATION FRANCAISE DE 
> NORMALISATION, CN = www.boutique.afnor.org verify return:1
> ---
> Certificate chain
>  0 s:/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE DE 
> NORMALISATION/OU=ASSOCIATION FRANCAISE DE 
> NORMALISATION/CN=www.boutique.afnor.org
>    i:/C=US/O=Symantec Corporation/OU=Symantec Trust 
> Network/CN=Symantec Class 3 Secure Server CA - G4 -----BEGIN 
> CERTIFICATE----- ../..
> -----END CERTIFICATE-----
>  1 s:/C=US/O=Symantec Corporation/OU=Symantec Trust 
> Network/CN=Symantec Class 3 Secure Server CA - G4
>    i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006 
> VeriSign, Inc. - For authorized use only/CN=VeriSign Class 3 Public 
> Primary Certification Authority - G5 -----BEGIN CERTIFICATE----- ../..
> -----END CERTIFICATE-----
> ---
> Server certificate
> subject=/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE 
> DE NORMALISATION/OU=ASSOCIATION FRANCAISE DE 
> NORMALISATION/CN=www.boutique.afnor.org
> issuer=/C=US/O=Symantec Corporation/OU=Symantec Trust 
> Network/CN=Symantec Class 3 Secure Server CA - G4
> ---
> No client certificate CA names sent
> ---
> SSL handshake has read 3105 bytes and written 616 bytes
> ---
> New, TLSv1/SSLv3, Cipher is AES128-SHA Server public key is 2048 bit 
> Secure Renegotiation IS supported
> Compression: NONE
> Expansion: NONE
> SSL-Session:
>     Protocol  : TLSv1
>     Cipher    : AES128-SHA
>     Session-ID:
> 833B0000A2346F50C5AAFC6B5188B4EBD9304CD25411BECFF0713F8D76C65D9D
>     Session-ID-ctx:
>     Master-Key:
> D2DF6C62264D03D7D44AF44EB8C0B1B7AD0E650D34DF6EBEB1CBEBFE4F30CB9C6F5080
> AA94F5
> D6B5955DD8DF06608416
>     Key-Arg   : None
>     PSK identity: None
>     PSK identity hint: None
>     SRP username: None
>     Start Time: 1493311275
>     Timeout   : 300 (sec)
>     Verify return code: 0 (ok)
> ---
> read:errno=0
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

--
Bugs to the Future



From yvoinov at gmail.com  Thu Apr 27 20:51:38 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 28 Apr 2017 02:51:38 +0600
Subject: [squid-users] 3.5.25: (71) Protocol error (TLS code:
 SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <073901d2bf94$bceb2dc0$36c18940$@articatech.com>
References: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>
 <c088c83f-ac6b-f463-7948-47463d0703a3@gmail.com>
 <073901d2bf94$bceb2dc0$36c18940$@articatech.com>
Message-ID: <216c9a91-c4e5-896a-7dbe-f5e955258cc9@gmail.com>

Squid can't have any intermediate certificates. As by as root CA's.

You can use this:

#  TAG: sslproxy_foreign_intermediate_certs
#    Many origin servers fail to send their full server certificate
#    chain for verification, assuming the client already has or can
#    easily locate any missing intermediate certificates.
#
#    Squid uses the certificates from the specified file to fill in
#    these missing chains when trying to validate origin server
#    certificate chains.
#
#    The file is expected to contain zero or more PEM-encoded
#    intermediate certificates. These certificates are not treated
#    as trusted root certificates, and any self-signed certificate in
#    this file will be ignored.
#Default:
# none

However, you should identiry and collect them by yourself.

The biggest problem:

Instead of root CA's, which can be taken from Mozilla's, intermediate
CAs spreaded over CA's providers, have much shorter valid period (most
cases up to 5-7 years) and, by this reason, should be continiously
maintained by proxy admin.

Also, remove this:

sslproxy_flags DONT_VERIFY_PEER
sslproxy_cert_error allow all

From your config. Don't. Never. This is completely disable ANY security checks for certificates, which leads to giant vulnerability to your users.
ssl_proxy_cert_error should be restricted by very specific ACL(s) in your config only for number of sites you trust.

28.04.2017 2:27, David Touzeau ?????:
> Hi yuri
>
> I did not know if squid have Symantec intermediate certificate
> Squid is installed as default...
> Any howto ?
>
>
> -----Message d'origine-----
> De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De la part de Yuri Voinov
> Envoy? : jeudi 27 avril 2017 22:09
> ? : squid-users at lists.squid-cache.org
> Objet : Re: [squid-users] 3.5.25: (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
>
> Look. It can be intermediate certificates issue.
>
> Does Squid have Symantec intermediate certificates?
>
>
> 27.04.2017 22:47, David Touzeau ?????:
>> Hi,
>> I'm unable to access to https://www.boutique.afnor.org website.
>> I would like to know if this issue cannot be fixed and must deny bump 
>> website to fix it.
>> Without Squid the website is correctly displayed
>>
>> Squid claim an error page with "(71) Protocol error (TLS code:
>> SQUID_ERR_SSL_HANDSHAKE)"
>>
>> In cache.log: "Error negotiating SSL on FD 17:
>> error:00000000:lib(0):func(0):reason(0) (5/0/0)"
>>
>> Using the following configuration:
>>
>> http_port 0.0.0.0:3128  name=MyPortNameID20 ssl-bump 
>> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
>> cert=/etc/squid3/ssl/0c451f46b4d05031560d8195f30165cb.dyn
>> sslproxy_foreign_intermediate_certs /etc/squid3/intermediate_ca.pem 
>> sslcrtd_program /lib/squid3/ssl_crtd -s 
>> /var/lib/squid/session/ssl/ssl_db -M 8MB sslcrtd_children 16 startup=5 
>> idle=1 acl FakeCert ssl::server_name .apple.com acl FakeCert 
>> ssl::server_name .icloud.com acl FakeCert ssl::server_name 
>> .mzstatic.com acl FakeCert ssl::server_name .dropbox.com acl ssl_step1 
>> at_step SslBump1 acl ssl_step2 at_step SslBump2 acl ssl_step3 at_step 
>> SslBump3 ssl_bump peek ssl_step1 ssl_bump splice FakeCert ssl_bump 
>> bump ssl_step2 all ssl_bump splice all
>>
>> sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression sslproxy_cipher 
>> ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:
>> !aNULL
>> :!eNULL
>> sslproxy_flags DONT_VERIFY_PEER
>> sslproxy_cert_error allow all
>>
>>
>>
>> Openssl info
>> ----------------------------------------------------------------------
>> ------
>> ----------------------------------------------------------------------
>> ------
>> ---
>>
>> openssl s_client -connect 195.115.26.58:443 -showcerts
>>
>> CONNECTED(00000003)
>> depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, OU 
>> = "(c)
>> 2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class 3 
>> Public Primary Certification Authority - G5 verify return:1
>> depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust Network, 
>> CN = Symantec Class 3 Secure Server CA - G4 verify return:1
>> depth=0 C = FR, ST = Seine Saint Denis, L = ST DENIS, O = ASSOCIATION 
>> FRANCAISE DE NORMALISATION, OU = ASSOCIATION FRANCAISE DE 
>> NORMALISATION, CN = www.boutique.afnor.org verify return:1
>> ---
>> Certificate chain
>>  0 s:/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE DE 
>> NORMALISATION/OU=ASSOCIATION FRANCAISE DE 
>> NORMALISATION/CN=www.boutique.afnor.org
>>    i:/C=US/O=Symantec Corporation/OU=Symantec Trust 
>> Network/CN=Symantec Class 3 Secure Server CA - G4 -----BEGIN 
>> CERTIFICATE----- ../..
>> -----END CERTIFICATE-----
>>  1 s:/C=US/O=Symantec Corporation/OU=Symantec Trust 
>> Network/CN=Symantec Class 3 Secure Server CA - G4
>>    i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006 
>> VeriSign, Inc. - For authorized use only/CN=VeriSign Class 3 Public 
>> Primary Certification Authority - G5 -----BEGIN CERTIFICATE----- ../..
>> -----END CERTIFICATE-----
>> ---
>> Server certificate
>> subject=/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE 
>> DE NORMALISATION/OU=ASSOCIATION FRANCAISE DE 
>> NORMALISATION/CN=www.boutique.afnor.org
>> issuer=/C=US/O=Symantec Corporation/OU=Symantec Trust 
>> Network/CN=Symantec Class 3 Secure Server CA - G4
>> ---
>> No client certificate CA names sent
>> ---
>> SSL handshake has read 3105 bytes and written 616 bytes
>> ---
>> New, TLSv1/SSLv3, Cipher is AES128-SHA Server public key is 2048 bit 
>> Secure Renegotiation IS supported
>> Compression: NONE
>> Expansion: NONE
>> SSL-Session:
>>     Protocol  : TLSv1
>>     Cipher    : AES128-SHA
>>     Session-ID:
>> 833B0000A2346F50C5AAFC6B5188B4EBD9304CD25411BECFF0713F8D76C65D9D
>>     Session-ID-ctx:
>>     Master-Key:
>> D2DF6C62264D03D7D44AF44EB8C0B1B7AD0E650D34DF6EBEB1CBEBFE4F30CB9C6F5080
>> AA94F5
>> D6B5955DD8DF06608416
>>     Key-Arg   : None
>>     PSK identity: None
>>     PSK identity hint: None
>>     SRP username: None
>>     Start Time: 1493311275
>>     Timeout   : 300 (sec)
>>     Verify return code: 0 (ok)
>> ---
>> read:errno=0
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> --
> Bugs to the Future
>

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170428/845bffbd/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170428/845bffbd/attachment.sig>

From david at articatech.com  Thu Apr 27 21:12:07 2017
From: david at articatech.com (David Touzeau)
Date: Thu, 27 Apr 2017 23:12:07 +0200
Subject: [squid-users] 3.5.25: (71) Protocol error (TLS code:
	SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <216c9a91-c4e5-896a-7dbe-f5e955258cc9@gmail.com>
References: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>
 <c088c83f-ac6b-f463-7948-47463d0703a3@gmail.com>
 <073901d2bf94$bceb2dc0$36c18940$@articatech.com>
 <216c9a91-c4e5-896a-7dbe-f5e955258cc9@gmail.com>
Message-ID: <074301d2bf9a$ed55aed0$c8010c70$@articatech.com>

Thanks Yuri

 ! but i have still have the error " Error negotiating SSL on FD 13: 
error:00000000:lib(0):func(0):reason(0) (5/0/0) " and cannot browse to site 
( as i seen you can with your squid...??? )

Created a file /etc/squid3/cabundle.pem

Added Symantec certificates available here:
https://knowledge.symantec.com/kb/index?page=content&actp=CROSSLINK&id=INFO2047

add

sslproxy_foreign_intermediate_certs  /etc/squid3/cabundle.pem

and perform a squid -k reconfigure

Missing something ???

Best regards

-----Message d'origine-----
De : Yuri Voinov [mailto:yvoinov at gmail.com]
Envoy? : jeudi 27 avril 2017 22:52
? : David Touzeau <david at articatech.com>; squid-users at lists.squid-cache.org
Objet : Re: [squid-users] 3.5.25: (71) Protocol error (TLS code: 
SQUID_ERR_SSL_HANDSHAKE)

Squid can't have any intermediate certificates. As by as root CA's.

You can use this:

#  TAG: sslproxy_foreign_intermediate_certs
#    Many origin servers fail to send their full server certificate
#    chain for verification, assuming the client already has or can
#    easily locate any missing intermediate certificates.
#
#    Squid uses the certificates from the specified file to fill in
#    these missing chains when trying to validate origin server
#    certificate chains.
#
#    The file is expected to contain zero or more PEM-encoded
#    intermediate certificates. These certificates are not treated
#    as trusted root certificates, and any self-signed certificate in
#    this file will be ignored.
#Default:
# none

However, you should identiry and collect them by yourself.

The biggest problem:

Instead of root CA's, which can be taken from Mozilla's, intermediate CAs 
spreaded over CA's providers, have much shorter valid period (most cases up 
to 5-7 years) and, by this reason, should be continiously maintained by 
proxy admin.

Also, remove this:

sslproxy_flags DONT_VERIFY_PEER
sslproxy_cert_error allow all

>From your config. Don't. Never. This is completely disable ANY security 
checks for certificates, which leads to giant vulnerability to your users.
ssl_proxy_cert_error should be restricted by very specific ACL(s) in your 
config only for number of sites you trust.

28.04.2017 2:27, David Touzeau ?????:
> Hi yuri
>
> I did not know if squid have Symantec intermediate certificate Squid
> is installed as default...
> Any howto ?
>
>
> -----Message d'origine-----
> De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De
> la part de Yuri Voinov Envoy? : jeudi 27 avril 2017 22:09 ? :
> squid-users at lists.squid-cache.org Objet : Re: [squid-users] 3.5.25:
> (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
>
> Look. It can be intermediate certificates issue.
>
> Does Squid have Symantec intermediate certificates?
>
>
> 27.04.2017 22:47, David Touzeau ?????:
>> Hi,
>> I'm unable to access to https://www.boutique.afnor.org website.
>> I would like to know if this issue cannot be fixed and must deny bump
>> website to fix it.
>> Without Squid the website is correctly displayed
>>
>> Squid claim an error page with "(71) Protocol error (TLS code:
>> SQUID_ERR_SSL_HANDSHAKE)"
>>
>> In cache.log: "Error negotiating SSL on FD 17:
>> error:00000000:lib(0):func(0):reason(0) (5/0/0)"
>>
>> Using the following configuration:
>>
>> http_port 0.0.0.0:3128  name=MyPortNameID20 ssl-bump
>> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>> cert=/etc/squid3/ssl/0c451f46b4d05031560d8195f30165cb.dyn
>> sslproxy_foreign_intermediate_certs /etc/squid3/intermediate_ca.pem
>> sslcrtd_program /lib/squid3/ssl_crtd -s
>> /var/lib/squid/session/ssl/ssl_db -M 8MB sslcrtd_children 16
>> startup=5
>> idle=1 acl FakeCert ssl::server_name .apple.com acl FakeCert
>> ssl::server_name .icloud.com acl FakeCert ssl::server_name
>> .mzstatic.com acl FakeCert ssl::server_name .dropbox.com acl
>> ssl_step1 at_step SslBump1 acl ssl_step2 at_step SslBump2 acl
>> ssl_step3 at_step
>> SslBump3 ssl_bump peek ssl_step1 ssl_bump splice FakeCert ssl_bump
>> bump ssl_step2 all ssl_bump splice all
>>
>> sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression sslproxy_cipher
>> ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:
>> !aNULL
>> :!eNULL
>> sslproxy_flags DONT_VERIFY_PEER
>> sslproxy_cert_error allow all
>>
>>
>>
>> Openssl info
>> ---------------------------------------------------------------------
>> -
>> ------
>> ---------------------------------------------------------------------
>> -
>> ------
>> ---
>>
>> openssl s_client -connect 195.115.26.58:443 -showcerts
>>
>> CONNECTED(00000003)
>> depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, OU
>> = "(c)
>> 2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class 3
>> Public Primary Certification Authority - G5 verify return:1
>> depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust
>> Network, CN = Symantec Class 3 Secure Server CA - G4 verify return:1
>> depth=0 C = FR, ST = Seine Saint Denis, L = ST DENIS, O = ASSOCIATION
>> FRANCAISE DE NORMALISATION, OU = ASSOCIATION FRANCAISE DE
>> NORMALISATION, CN = www.boutique.afnor.org verify return:1
>> ---
>> Certificate chain
>>  0 s:/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE DE
>> NORMALISATION/OU=ASSOCIATION FRANCAISE DE
>> NORMALISATION/CN=www.boutique.afnor.org
>>    i:/C=US/O=Symantec Corporation/OU=Symantec Trust
>> Network/CN=Symantec Class 3 Secure Server CA - G4 -----BEGIN
>> CERTIFICATE----- ../..
>> -----END CERTIFICATE-----
>>  1 s:/C=US/O=Symantec Corporation/OU=Symantec Trust
>> Network/CN=Symantec Class 3 Secure Server CA - G4
>>    i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006
>> VeriSign, Inc. - For authorized use only/CN=VeriSign Class 3 Public
>> Primary Certification Authority - G5 -----BEGIN CERTIFICATE----- ../..
>> -----END CERTIFICATE-----
>> ---
>> Server certificate
>> subject=/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE
>> DE NORMALISATION/OU=ASSOCIATION FRANCAISE DE
>> NORMALISATION/CN=www.boutique.afnor.org
>> issuer=/C=US/O=Symantec Corporation/OU=Symantec Trust
>> Network/CN=Symantec Class 3 Secure Server CA - G4
>> ---
>> No client certificate CA names sent
>> ---
>> SSL handshake has read 3105 bytes and written 616 bytes
>> ---
>> New, TLSv1/SSLv3, Cipher is AES128-SHA Server public key is 2048 bit
>> Secure Renegotiation IS supported
>> Compression: NONE
>> Expansion: NONE
>> SSL-Session:
>>     Protocol  : TLSv1
>>     Cipher    : AES128-SHA
>>     Session-ID:
>> 833B0000A2346F50C5AAFC6B5188B4EBD9304CD25411BECFF0713F8D76C65D9D
>>     Session-ID-ctx:
>>     Master-Key:
>> D2DF6C62264D03D7D44AF44EB8C0B1B7AD0E650D34DF6EBEB1CBEBFE4F30CB9C6F508
>> 0
>> AA94F5
>> D6B5955DD8DF06608416
>>     Key-Arg   : None
>>     PSK identity: None
>>     PSK identity hint: None
>>     SRP username: None
>>     Start Time: 1493311275
>>     Timeout   : 300 (sec)
>>     Verify return code: 0 (ok)
>> ---
>> read:errno=0
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
> --
> Bugs to the Future
>

--
Bugs to the Future



From chip_pop at hotmail.com  Thu Apr 27 21:14:46 2017
From: chip_pop at hotmail.com (joseph)
Date: Thu, 27 Apr 2017 14:14:46 -0700 (PDT)
Subject: [squid-users] concurrency  with ecap
Message-ID: <1493327686061-4682219.post@n4.nabble.com>

is it possible in future  to change  the ecap to use concurrency like the
store-id
so we can benefit from that ????????????



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/concurrency-with-ecap-tp4682219.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Thu Apr 27 21:26:10 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 28 Apr 2017 03:26:10 +0600
Subject: [squid-users] 3.5.25: (71) Protocol error (TLS code:
 SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <074301d2bf9a$ed55aed0$c8010c70$@articatech.com>
References: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>
 <c088c83f-ac6b-f463-7948-47463d0703a3@gmail.com>
 <073901d2bf94$bceb2dc0$36c18940$@articatech.com>
 <216c9a91-c4e5-896a-7dbe-f5e955258cc9@gmail.com>
 <074301d2bf9a$ed55aed0$c8010c70$@articatech.com>
Message-ID: <6b4e8f6b-b2b4-2243-aace-e5d907c918cb@gmail.com>

Be careful with intermediate CA's you grabbed. Check they validity,
fingerprints and attributes.

Proxying SSL requires much more work with Squid.


28.04.2017 3:12, David Touzeau ?????:
> Thanks Yuri
>
>  ! but i have still have the error " Error negotiating SSL on FD 13: 
> error:00000000:lib(0):func(0):reason(0) (5/0/0) " and cannot browse to site 
> ( as i seen you can with your squid...??? )
Yes. With two different versions.
>
> Created a file /etc/squid3/cabundle.pem
>
> Added Symantec certificates available here:
> https://knowledge.symantec.com/kb/index?page=content&actp=CROSSLINK&id=INFO2047
>
> add
>
> sslproxy_foreign_intermediate_certs  /etc/squid3/cabundle.pem
>
> and perform a squid -k reconfigure
>
> Missing something ???
May be. I'm recommend to re-initialize mimic certificates DB also and
restart Squid, not reconfigure.

Keep in mind, that SSL bump critical important for success. For example,
AFAIK stare often opposite to bump (in most cases). Read wiki article,
but also remember this functionality still evolving, and can changed
without notices. So, experiment.
>
> Best regards
>
> -----Message d'origine-----
> De : Yuri Voinov [mailto:yvoinov at gmail.com]
> Envoy? : jeudi 27 avril 2017 22:52
> ? : David Touzeau <david at articatech.com>; squid-users at lists.squid-cache.org
> Objet : Re: [squid-users] 3.5.25: (71) Protocol error (TLS code: 
> SQUID_ERR_SSL_HANDSHAKE)
>
> Squid can't have any intermediate certificates. As by as root CA's.
>
> You can use this:
>
> #  TAG: sslproxy_foreign_intermediate_certs
> #    Many origin servers fail to send their full server certificate
> #    chain for verification, assuming the client already has or can
> #    easily locate any missing intermediate certificates.
> #
> #    Squid uses the certificates from the specified file to fill in
> #    these missing chains when trying to validate origin server
> #    certificate chains.
> #
> #    The file is expected to contain zero or more PEM-encoded
> #    intermediate certificates. These certificates are not treated
> #    as trusted root certificates, and any self-signed certificate in
> #    this file will be ignored.
> #Default:
> # none
>
> However, you should identiry and collect them by yourself.
>
> The biggest problem:
>
> Instead of root CA's, which can be taken from Mozilla's, intermediate CAs 
> spreaded over CA's providers, have much shorter valid period (most cases up 
> to 5-7 years) and, by this reason, should be continiously maintained by 
> proxy admin.
>
> Also, remove this:
>
> sslproxy_flags DONT_VERIFY_PEER
> sslproxy_cert_error allow all
>
> From your config. Don't. Never. This is completely disable ANY security 
> checks for certificates, which leads to giant vulnerability to your users.
> ssl_proxy_cert_error should be restricted by very specific ACL(s) in your 
> config only for number of sites you trust.
>
> 28.04.2017 2:27, David Touzeau ?????:
>> Hi yuri
>>
>> I did not know if squid have Symantec intermediate certificate Squid
>> is installed as default...
>> Any howto ?
>>
>>
>> -----Message d'origine-----
>> De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] De
>> la part de Yuri Voinov Envoy? : jeudi 27 avril 2017 22:09 ? :
>> squid-users at lists.squid-cache.org Objet : Re: [squid-users] 3.5.25:
>> (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
>>
>> Look. It can be intermediate certificates issue.
>>
>> Does Squid have Symantec intermediate certificates?
>>
>>
>> 27.04.2017 22:47, David Touzeau ?????:
>>> Hi,
>>> I'm unable to access to https://www.boutique.afnor.org website.
>>> I would like to know if this issue cannot be fixed and must deny bump
>>> website to fix it.
>>> Without Squid the website is correctly displayed
>>>
>>> Squid claim an error page with "(71) Protocol error (TLS code:
>>> SQUID_ERR_SSL_HANDSHAKE)"
>>>
>>> In cache.log: "Error negotiating SSL on FD 17:
>>> error:00000000:lib(0):func(0):reason(0) (5/0/0)"
>>>
>>> Using the following configuration:
>>>
>>> http_port 0.0.0.0:3128  name=MyPortNameID20 ssl-bump
>>> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>>> cert=/etc/squid3/ssl/0c451f46b4d05031560d8195f30165cb.dyn
>>> sslproxy_foreign_intermediate_certs /etc/squid3/intermediate_ca.pem
>>> sslcrtd_program /lib/squid3/ssl_crtd -s
>>> /var/lib/squid/session/ssl/ssl_db -M 8MB sslcrtd_children 16
>>> startup=5
>>> idle=1 acl FakeCert ssl::server_name .apple.com acl FakeCert
>>> ssl::server_name .icloud.com acl FakeCert ssl::server_name
>>> .mzstatic.com acl FakeCert ssl::server_name .dropbox.com acl
>>> ssl_step1 at_step SslBump1 acl ssl_step2 at_step SslBump2 acl
>>> ssl_step3 at_step
>>> SslBump3 ssl_bump peek ssl_step1 ssl_bump splice FakeCert ssl_bump
>>> bump ssl_step2 all ssl_bump splice all
>>>
>>> sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression sslproxy_cipher
>>> ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:
>>> !aNULL
>>> :!eNULL
>>> sslproxy_flags DONT_VERIFY_PEER
>>> sslproxy_cert_error allow all
>>>
>>>
>>>
>>> Openssl info
>>> ---------------------------------------------------------------------
>>> -
>>> ------
>>> ---------------------------------------------------------------------
>>> -
>>> ------
>>> ---
>>>
>>> openssl s_client -connect 195.115.26.58:443 -showcerts
>>>
>>> CONNECTED(00000003)
>>> depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, OU
>>> = "(c)
>>> 2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class 3
>>> Public Primary Certification Authority - G5 verify return:1
>>> depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust
>>> Network, CN = Symantec Class 3 Secure Server CA - G4 verify return:1
>>> depth=0 C = FR, ST = Seine Saint Denis, L = ST DENIS, O = ASSOCIATION
>>> FRANCAISE DE NORMALISATION, OU = ASSOCIATION FRANCAISE DE
>>> NORMALISATION, CN = www.boutique.afnor.org verify return:1
>>> ---
>>> Certificate chain
>>>  0 s:/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE DE
>>> NORMALISATION/OU=ASSOCIATION FRANCAISE DE
>>> NORMALISATION/CN=www.boutique.afnor.org
>>>    i:/C=US/O=Symantec Corporation/OU=Symantec Trust
>>> Network/CN=Symantec Class 3 Secure Server CA - G4 -----BEGIN
>>> CERTIFICATE----- ../..
>>> -----END CERTIFICATE-----
>>>  1 s:/C=US/O=Symantec Corporation/OU=Symantec Trust
>>> Network/CN=Symantec Class 3 Secure Server CA - G4
>>>    i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006
>>> VeriSign, Inc. - For authorized use only/CN=VeriSign Class 3 Public
>>> Primary Certification Authority - G5 -----BEGIN CERTIFICATE----- ../..
>>> -----END CERTIFICATE-----
>>> ---
>>> Server certificate
>>> subject=/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE
>>> DE NORMALISATION/OU=ASSOCIATION FRANCAISE DE
>>> NORMALISATION/CN=www.boutique.afnor.org
>>> issuer=/C=US/O=Symantec Corporation/OU=Symantec Trust
>>> Network/CN=Symantec Class 3 Secure Server CA - G4
>>> ---
>>> No client certificate CA names sent
>>> ---
>>> SSL handshake has read 3105 bytes and written 616 bytes
>>> ---
>>> New, TLSv1/SSLv3, Cipher is AES128-SHA Server public key is 2048 bit
>>> Secure Renegotiation IS supported
>>> Compression: NONE
>>> Expansion: NONE
>>> SSL-Session:
>>>     Protocol  : TLSv1
>>>     Cipher    : AES128-SHA
>>>     Session-ID:
>>> 833B0000A2346F50C5AAFC6B5188B4EBD9304CD25411BECFF0713F8D76C65D9D
>>>     Session-ID-ctx:
>>>     Master-Key:
>>> D2DF6C62264D03D7D44AF44EB8C0B1B7AD0E650D34DF6EBEB1CBEBFE4F30CB9C6F508
>>> 0
>>> AA94F5
>>> D6B5955DD8DF06608416
>>>     Key-Arg   : None
>>>     PSK identity: None
>>>     PSK identity hint: None
>>>     SRP username: None
>>>     Start Time: 1493311275
>>>     Timeout   : 300 (sec)
>>>     Verify return code: 0 (ok)
>>> ---
>>> read:errno=0
>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> --
>> Bugs to the Future
>>
> --
> Bugs to the Future
>

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170428/7b56d6e8/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170428/7b56d6e8/attachment.sig>

From rousskov at measurement-factory.com  Thu Apr 27 21:29:24 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 27 Apr 2017 15:29:24 -0600
Subject: [squid-users] concurrency with ecap
In-Reply-To: <1493327686061-4682219.post@n4.nabble.com>
References: <1493327686061-4682219.post@n4.nabble.com>
Message-ID: <70fd5023-da37-8b78-8282-ac492468893a@measurement-factory.com>

On 04/27/2017 03:14 PM, joseph wrote:
> is it possible in future  to change  the ecap to use concurrency like the
> store-id so we can benefit from that ????????????

eCAP supports concurrent adaptations by design. No configuration is
required to enable that support.

Alex.



From yvoinov at gmail.com  Thu Apr 27 21:33:46 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 28 Apr 2017 03:33:46 +0600
Subject: [squid-users] concurrency with ecap
In-Reply-To: <70fd5023-da37-8b78-8282-ac492468893a@measurement-factory.com>
References: <1493327686061-4682219.post@n4.nabble.com>
 <70fd5023-da37-8b78-8282-ac492468893a@measurement-factory.com>
Message-ID: <9371b257-1ad6-df4c-dc8f-7f057a9c0497@gmail.com>

Alex,

is it possible to get comprehensive example?

Adapter sample is non-obvious, not complete (non-obvious where to put
mutex locking) and contains C-style rudiments (like external call,
pthread.h etc.).

I think, this will be actual in 2017, with CMT world around.

WBR, Yuri.


28.04.2017 3:29, Alex Rousskov ?????:
> On 04/27/2017 03:14 PM, joseph wrote:
>> is it possible in future  to change  the ecap to use concurrency like the
>> store-id so we can benefit from that ????????????
> eCAP supports concurrent adaptations by design. No configuration is
> required to enable that support.
>
> Alex.
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170428/827af2dd/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170428/827af2dd/attachment.sig>

From rousskov at measurement-factory.com  Fri Apr 28 00:03:00 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 27 Apr 2017 18:03:00 -0600
Subject: [squid-users] concurrency with ecap
In-Reply-To: <9371b257-1ad6-df4c-dc8f-7f057a9c0497@gmail.com>
References: <1493327686061-4682219.post@n4.nabble.com>
 <70fd5023-da37-8b78-8282-ac492468893a@measurement-factory.com>
 <9371b257-1ad6-df4c-dc8f-7f057a9c0497@gmail.com>
Message-ID: <fbb481fa-acaa-d2e4-28f7-6fc84e41d352@measurement-factory.com>

On 04/27/2017 03:33 PM, Yuri Voinov wrote:

> is it possible to get comprehensive example?

FYI: This is an eCAP question, not a Squid-specific question; you also
start discussing development. Such questions are better asked via eCAP
support channels[1] rather than on squid-users:

  [1] http://www.e-cap.org/Support

Virtually any eCAP adapter supports concurrent transactions. Concurrency
is built into the API. Many adapters do not make costly/lengthy
decisions so they do not need "threads" (just like many Squids do not
need threads to process thousands of transactions concurrently). Some
adapters that do make those lengthy decisions block the application
process while others use multiple threads (or multiple processes) to
minimize blocking.

IIRC, the eCAP ClamAV adapter[2] uses threads to minimize blocking. You
may use it as a comprehensive example.

  [2] http://www.e-cap.org/Downloads


> Adapter sample is non-obvious, not complete (non-obvious where to put
> mutex locking) and contains C-style rudiments (like external call,
> pthread.h etc.).
> 
> I think, this will be actual in 2017, with CMT world around.

I doubt there are high-quality public adapters that use C++11 threading
interfaces (if that is what you are looking for). Several aspects
contribute to that, including:

* There were no stable host applications that supported C++11 until
recently and few are going to rewrite older working adapters just to add
C++11 bells and whistles.

* IIRC, initial attempts to use C++11 thread-related atomic APIs in
Squid have failed due to poor compiler support (this is not related to
eCAP but illustrates that you are talking about state-of-the-art
features rather than something that is widely supported, used, and
understood like pthreads).

* The official libecap library itself is still using a couple of
pre-C++11 components (and changing that is difficult[3,4]!).

  [3] https://bugs.launchpad.net/ecap/+bug/1595488
  [4] https://bugs.launchpad.net/ecap/+bug/1595562

In summary, it may take some time for that C++11 threading technology to
surface in eCAP adapters.


HTH,

Alex.



From marcel at baltruschat.net  Fri Apr 28 09:00:33 2017
From: marcel at baltruschat.net (mbaltruschat)
Date: Fri, 28 Apr 2017 02:00:33 -0700 (PDT)
Subject: [squid-users] Squid proxy without name resolution for internet
 adresses behind parent proxy
Message-ID: <1493370033619-4682225.post@n4.nabble.com>

Hello everybody,

i am trying to migrate my old squid 2.7 to 3.5 and are getting stuck, the
new proxy is very slow, requests need very long until they open, i guess ist
a name resolution problem, because the proxy cant resolve internet domain
names by itself, the name resolution is done by the parent proxy of our
Network Provider. If i look at the statistics by "mgr:info" i see that the
median Service times for dns are around 30 seconds. I guess the old 2.7 just
"ignored" the name resolution because i didnt give him a nameserver to use
and although didnt configure dnshelper.

How can i configure squid not to resolve the names by itself?

Many thanks in advance
Best regards
M. Baltruschat



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-proxy-without-name-resolution-for-internet-adresses-behind-parent-proxy-tp4682225.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From dijxie at gmail.com  Fri Apr 28 09:38:41 2017
From: dijxie at gmail.com (Dijxie)
Date: Fri, 28 Apr 2017 11:38:41 +0200
Subject: [squid-users] Squid proxy without name resolution for internet
 adresses behind parent proxy
In-Reply-To: <1493370033619-4682225.post@n4.nabble.com>
References: <1493370033619-4682225.post@n4.nabble.com>
Message-ID: <f6d4410e-32af-de08-b875-c4c34efd8f4a@gmail.com>

W dniu 28.04.2017 o 11:00, mbaltruschat pisze:
> Hello everybody,
>
> i am trying to migrate my old squid 2.7 to 3.5 and are getting stuck, the
> new proxy is very slow, requests need very long until they open, i guess ist
> a name resolution problem, because the proxy cant resolve internet domain
> names by itself, the name resolution is done by the parent proxy of our
> Network Provider. If i look at the statistics by "mgr:info" i see that the
> median Service times for dns are around 30 seconds. I guess the old 2.7 just
> "ignored" the name resolution because i didnt give him a nameserver to use
> and although didnt configure dnshelper.
>
> How can i configure squid not to resolve the names by itself?
>
> Many thanks in advance
> Best regards
> M. Baltruschat
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-proxy-without-name-resolution-for-internet-adresses-behind-parent-proxy-tp4682225.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Hi,

By "by itself" you ment squid-cache or squid host machine?

I'm using dnsmasq along with squid on the same machine. Dnsmasq has 250 
cache enabled and neg-cache disabled and 4-6 DNS configured. AFAIR 
dnsmasq asks all configured DNS at once an replies if any of them reply. 
But in mgr:dns, it is still squid asking 127.0.0.1.

By the way, what's going on in mgr:dns in your squid-cache? If it's name 
resolution problem, it will be there. If your OS uses resolf.conf order, 
than it is possible that at list 1st DNS server has problem and you will 
see than in mgr:dns stats.

-- 
Pozdrawiam, Remik



From david at articatech.com  Fri Apr 28 10:14:16 2017
From: david at articatech.com (David Touzeau)
Date: Fri, 28 Apr 2017 12:14:16 +0200
Subject: [squid-users] 3.5.25: (71) Protocol error (TLS code:
	SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <6b4e8f6b-b2b4-2243-aace-e5d907c918cb@gmail.com>
References: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>
 <c088c83f-ac6b-f463-7948-47463d0703a3@gmail.com>
 <073901d2bf94$bceb2dc0$36c18940$@articatech.com>
 <216c9a91-c4e5-896a-7dbe-f5e955258cc9@gmail.com>
 <074301d2bf9a$ed55aed0$c8010c70$@articatech.com>
 <6b4e8f6b-b2b4-2243-aace-e5d907c918cb@gmail.com>
Message-ID: <0dcb01d2c008$316500e0$942f02a0$@articatech.com>

I'm fighting to find the correct certificate chain for this website:
https://www.boutique.afnor.org

I have also added all certificates included in this package:
https://packages.debian.org/fr/sid/ca-certificates


Do you have any tips to help ?

Best regards

-----Message d'origine-----
De : Yuri Voinov [mailto:yvoinov at gmail.com] 
Envoy? : jeudi 27 avril 2017 23:26
? : David Touzeau <david at articatech.com>; squid-users at lists.squid-cache.org
Objet : Re: [squid-users] 3.5.25: (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)

Be careful with intermediate CA's you grabbed. Check they validity, fingerprints and attributes.

Proxying SSL requires much more work with Squid.


28.04.2017 3:12, David Touzeau ?????:
> Thanks Yuri
>
>  ! but i have still have the error " Error negotiating SSL on FD 13: 
> error:00000000:lib(0):func(0):reason(0) (5/0/0) " and cannot browse to 
> site ( as i seen you can with your squid...??? )
Yes. With two different versions.
>
> Created a file /etc/squid3/cabundle.pem
>
> Added Symantec certificates available here:
> https://knowledge.symantec.com/kb/index?page=content&actp=CROSSLINK&id
> =INFO2047
>
> add
>
> sslproxy_foreign_intermediate_certs  /etc/squid3/cabundle.pem
>
> and perform a squid -k reconfigure
>
> Missing something ???
May be. I'm recommend to re-initialize mimic certificates DB also and restart Squid, not reconfigure.

Keep in mind, that SSL bump critical important for success. For example, AFAIK stare often opposite to bump (in most cases). Read wiki article, but also remember this functionality still evolving, and can changed without notices. So, experiment.
>
> Best regards
>
> -----Message d'origine-----
> De : Yuri Voinov [mailto:yvoinov at gmail.com] Envoy? : jeudi 27 avril 
> 2017 22:52 ? : David Touzeau <david at articatech.com>; 
> squid-users at lists.squid-cache.org Objet : Re: [squid-users] 3.5.25: 
> (71) Protocol error (TLS code:
> SQUID_ERR_SSL_HANDSHAKE)
>
> Squid can't have any intermediate certificates. As by as root CA's.
>
> You can use this:
>
> #  TAG: sslproxy_foreign_intermediate_certs
> #    Many origin servers fail to send their full server certificate
> #    chain for verification, assuming the client already has or can
> #    easily locate any missing intermediate certificates.
> #
> #    Squid uses the certificates from the specified file to fill in
> #    these missing chains when trying to validate origin server
> #    certificate chains.
> #
> #    The file is expected to contain zero or more PEM-encoded
> #    intermediate certificates. These certificates are not treated
> #    as trusted root certificates, and any self-signed certificate in
> #    this file will be ignored.
> #Default:
> # none
>
> However, you should identiry and collect them by yourself.
>
> The biggest problem:
>
> Instead of root CA's, which can be taken from Mozilla's, intermediate 
> CAs spreaded over CA's providers, have much shorter valid period (most 
> cases up to 5-7 years) and, by this reason, should be continiously 
> maintained by proxy admin.
>
> Also, remove this:
>
> sslproxy_flags DONT_VERIFY_PEER
> sslproxy_cert_error allow all
>
> From your config. Don't. Never. This is completely disable ANY 
> security checks for certificates, which leads to giant vulnerability to your users.
> ssl_proxy_cert_error should be restricted by very specific ACL(s) in 
> your config only for number of sites you trust.
>
> 28.04.2017 2:27, David Touzeau ?????:
>> Hi yuri
>>
>> I did not know if squid have Symantec intermediate certificate Squid 
>> is installed as default...
>> Any howto ?
>>
>>
>> -----Message d'origine-----
>> De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
>> De la part de Yuri Voinov Envoy? : jeudi 27 avril 2017 22:09 ? :
>> squid-users at lists.squid-cache.org Objet : Re: [squid-users] 3.5.25:
>> (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
>>
>> Look. It can be intermediate certificates issue.
>>
>> Does Squid have Symantec intermediate certificates?
>>
>>
>> 27.04.2017 22:47, David Touzeau ?????:
>>> Hi,
>>> I'm unable to access to https://www.boutique.afnor.org website.
>>> I would like to know if this issue cannot be fixed and must deny 
>>> bump website to fix it.
>>> Without Squid the website is correctly displayed
>>>
>>> Squid claim an error page with "(71) Protocol error (TLS code:
>>> SQUID_ERR_SSL_HANDSHAKE)"
>>>
>>> In cache.log: "Error negotiating SSL on FD 17:
>>> error:00000000:lib(0):func(0):reason(0) (5/0/0)"
>>>
>>> Using the following configuration:
>>>
>>> http_port 0.0.0.0:3128  name=MyPortNameID20 ssl-bump 
>>> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
>>> cert=/etc/squid3/ssl/0c451f46b4d05031560d8195f30165cb.dyn
>>> sslproxy_foreign_intermediate_certs /etc/squid3/intermediate_ca.pem 
>>> sslcrtd_program /lib/squid3/ssl_crtd -s 
>>> /var/lib/squid/session/ssl/ssl_db -M 8MB sslcrtd_children 16
>>> startup=5
>>> idle=1 acl FakeCert ssl::server_name .apple.com acl FakeCert 
>>> ssl::server_name .icloud.com acl FakeCert ssl::server_name 
>>> .mzstatic.com acl FakeCert ssl::server_name .dropbox.com acl
>>> ssl_step1 at_step SslBump1 acl ssl_step2 at_step SslBump2 acl
>>> ssl_step3 at_step
>>> SslBump3 ssl_bump peek ssl_step1 ssl_bump splice FakeCert ssl_bump 
>>> bump ssl_step2 all ssl_bump splice all
>>>
>>> sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression sslproxy_cipher
>>> ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:
>>> !aNULL
>>> :!eNULL
>>> sslproxy_flags DONT_VERIFY_PEER
>>> sslproxy_cert_error allow all
>>>
>>>
>>>
>>> Openssl info
>>> --------------------------------------------------------------------
>>> -
>>> -
>>> ------
>>> --------------------------------------------------------------------
>>> -
>>> -
>>> ------
>>> ---
>>>
>>> openssl s_client -connect 195.115.26.58:443 -showcerts
>>>
>>> CONNECTED(00000003)
>>> depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, 
>>> OU = "(c)
>>> 2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class 
>>> 3 Public Primary Certification Authority - G5 verify return:1
>>> depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust 
>>> Network, CN = Symantec Class 3 Secure Server CA - G4 verify return:1
>>> depth=0 C = FR, ST = Seine Saint Denis, L = ST DENIS, O = 
>>> ASSOCIATION FRANCAISE DE NORMALISATION, OU = ASSOCIATION FRANCAISE 
>>> DE NORMALISATION, CN = www.boutique.afnor.org verify return:1
>>> ---
>>> Certificate chain
>>>  0 s:/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE 
>>> DE NORMALISATION/OU=ASSOCIATION FRANCAISE DE 
>>> NORMALISATION/CN=www.boutique.afnor.org
>>>    i:/C=US/O=Symantec Corporation/OU=Symantec Trust 
>>> Network/CN=Symantec Class 3 Secure Server CA - G4 -----BEGIN
>>> CERTIFICATE----- ../..
>>> -----END CERTIFICATE-----
>>>  1 s:/C=US/O=Symantec Corporation/OU=Symantec Trust 
>>> Network/CN=Symantec Class 3 Secure Server CA - G4
>>>    i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006 
>>> VeriSign, Inc. - For authorized use only/CN=VeriSign Class 3 Public 
>>> Primary Certification Authority - G5 -----BEGIN CERTIFICATE----- ../..
>>> -----END CERTIFICATE-----
>>> ---
>>> Server certificate
>>> subject=/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION 
>>> FRANCAISE DE NORMALISATION/OU=ASSOCIATION FRANCAISE DE 
>>> NORMALISATION/CN=www.boutique.afnor.org
>>> issuer=/C=US/O=Symantec Corporation/OU=Symantec Trust 
>>> Network/CN=Symantec Class 3 Secure Server CA - G4
>>> ---
>>> No client certificate CA names sent
>>> ---
>>> SSL handshake has read 3105 bytes and written 616 bytes
>>> ---
>>> New, TLSv1/SSLv3, Cipher is AES128-SHA Server public key is 2048 bit 
>>> Secure Renegotiation IS supported
>>> Compression: NONE
>>> Expansion: NONE
>>> SSL-Session:
>>>     Protocol  : TLSv1
>>>     Cipher    : AES128-SHA
>>>     Session-ID:
>>> 833B0000A2346F50C5AAFC6B5188B4EBD9304CD25411BECFF0713F8D76C65D9D
>>>     Session-ID-ctx:
>>>     Master-Key:
>>> D2DF6C62264D03D7D44AF44EB8C0B1B7AD0E650D34DF6EBEB1CBEBFE4F30CB9C6F50
>>> 8
>>> 0
>>> AA94F5
>>> D6B5955DD8DF06608416
>>>     Key-Arg   : None
>>>     PSK identity: None
>>>     PSK identity hint: None
>>>     SRP username: None
>>>     Start Time: 1493311275
>>>     Timeout   : 300 (sec)
>>>     Verify return code: 0 (ok)
>>> ---
>>> read:errno=0
>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> --
>> Bugs to the Future
>>
> --
> Bugs to the Future
>

--
Bugs to the Future



From Antony.Stone at squid.open.source.it  Fri Apr 28 10:24:00 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 28 Apr 2017 11:24:00 +0100
Subject: [squid-users] 3.5.25: (71) Protocol error (TLS code:
	SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <0dcb01d2c008$316500e0$942f02a0$@articatech.com>
References: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>
 <6b4e8f6b-b2b4-2243-aace-e5d907c918cb@gmail.com>
 <0dcb01d2c008$316500e0$942f02a0$@articatech.com>
Message-ID: <201704281124.00921.Antony.Stone@squid.open.source.it>

On Friday 28 April 2017 at 11:14:16, David Touzeau wrote:

> I'm fighting to find the correct certificate chain for this website:
> https://www.boutique.afnor.org

$ openssl s_client -host www.boutique.afnor.org -port 443 -prexit -showcerts
CONNECTED(00000003)

depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, OU = "(c) 
2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class 3 Public 
Primary Certification Authority - G5
verify return:1

depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust Network, CN = 
Symantec Class 3 Secure Server CA - G4
verify return:1

depth=0 C = FR, ST = Seine Saint Denis, L = ST DENIS, O = ASSOCIATION 
FRANCAISE DE NORMALISATION, OU = ASSOCIATION FRANCAISE DE NORMALISATION, CN = 
www.boutique.afnor.org
verify return:1


Antony.

-- 
"When you talk about Linux versus Windows, you're talking about which 
operating system is the best value for money and fit for purpose. That's a very 
basic decision customers can make if they have the information available to 
them. Quite frankly if we lose to Linux because our customers say it's better 
value for money, tough luck for us."

 - Steve Vamos, MD of Microsoft Australia

                                                   Please reply to the list;
                                                         please *don't* CC me.


From marcel at baltruschat.net  Fri Apr 28 10:48:51 2017
From: marcel at baltruschat.net (mbaltruschat)
Date: Fri, 28 Apr 2017 03:48:51 -0700 (PDT)
Subject: [squid-users] Squid proxy without name resolution for internet
 adresses behind parent proxy
In-Reply-To: <f6d4410e-32af-de08-b875-c4c34efd8f4a@gmail.com>
References: <1493370033619-4682225.post@n4.nabble.com>
 <f6d4410e-32af-de08-b875-c4c34efd8f4a@gmail.com>
Message-ID: <1493376531696-4682229.post@n4.nabble.com>

Hello,

with by-itself i mean the squid-cache and/or the host-machine, neither of
them is able to resolve internet hostnames, our dns is just internal. Only
the parent proxy from the Network provider is able to resolve internet
names. So i just want all my request beeing forwarwed without name
resolution.

If i didnt configure a nameserver i dont get any results in mgr:idns, if i
configure it, i get many hits on rcode 0 attempt1 (which i dont understand
since external names cant be resolved) and several "non-existent-Domain"

best regards
M. Baltruschat



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-proxy-without-name-resolution-for-internet-adresses-behind-parent-proxy-tp4682225p4682229.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From oliver at lennox-it.uk  Fri Apr 28 11:49:54 2017
From: oliver at lennox-it.uk (Olly Lennox)
Date: Fri, 28 Apr 2017 11:49:54 +0000 (UTC)
Subject: [squid-users] 3.5.25: (71) Protocol error (TLS
	code:	SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <0dcb01d2c008$316500e0$942f02a0$@articatech.com>
References: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>
 <c088c83f-ac6b-f463-7948-47463d0703a3@gmail.com>
 <073901d2bf94$bceb2dc0$36c18940$@articatech.com>
 <216c9a91-c4e5-896a-7dbe-f5e955258cc9@gmail.com>
 <074301d2bf9a$ed55aed0$c8010c70$@articatech.com>
 <6b4e8f6b-b2b4-2243-aace-e5d907c918cb@gmail.com>
 <0dcb01d2c008$316500e0$942f02a0$@articatech.com>
Message-ID: <1683013866.6740786.1493380194604@mail.yahoo.com>

Have you tried the CA bundle here:
https://raw.githubusercontent.com/bagder/ca-bundle/master/ca-bundle.crt

referenced in the config with:
sslproxy_cafile /etc/squid/ca-bundle.crt

This fixed a lot of the cert errors I experienced.?oliver at lennox-it.uk
lennox-it.uk
tel: 07900 648 252

      From: David Touzeau <david at articatech.com>
 To: 'Yuri Voinov' <yvoinov at gmail.com>; squid-users at lists.squid-cache.org 
 Sent: Friday, 28 April 2017, 11:14
 Subject: Re: [squid-users] 3.5.25: (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
   
I'm fighting to find the correct certificate chain for this website:
https://www.boutique.afnor.org

I have also added all certificates included in this package:
https://packages.debian.org/fr/sid/ca-certificates


Do you have any tips to help ?

Best regards

-----Message d'origine-----
De : Yuri Voinov [mailto:yvoinov at gmail.com] 
Envoy? : jeudi 27 avril 2017 23:26
? : David Touzeau <david at articatech.com>; squid-users at lists.squid-cache.org
Objet : Re: [squid-users] 3.5.25: (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)

Be careful with intermediate CA's you grabbed. Check they validity, fingerprints and attributes.

Proxying SSL requires much more work with Squid.


28.04.2017 3:12, David Touzeau ?????:
> Thanks Yuri
>
>? ! but i have still have the error " Error negotiating SSL on FD 13: 
> error:00000000:lib(0):func(0):reason(0) (5/0/0) " and cannot browse to 
> site ( as i seen you can with your squid...??? )
Yes. With two different versions.
>
> Created a file /etc/squid3/cabundle.pem
>
> Added Symantec certificates available here:
> https://knowledge.symantec.com/kb/index?page=content&actp=CROSSLINK&id
> =INFO2047
>
> add
>
> sslproxy_foreign_intermediate_certs? /etc/squid3/cabundle.pem
>
> and perform a squid -k reconfigure
>
> Missing something ???
May be. I'm recommend to re-initialize mimic certificates DB also and restart Squid, not reconfigure.

Keep in mind, that SSL bump critical important for success. For example, AFAIK stare often opposite to bump (in most cases). Read wiki article, but also remember this functionality still evolving, and can changed without notices. So, experiment.
>
> Best regards
>
> -----Message d'origine-----
> De : Yuri Voinov [mailto:yvoinov at gmail.com] Envoy? : jeudi 27 avril 
> 2017 22:52 ? : David Touzeau <david at articatech.com>; 
> squid-users at lists.squid-cache.org Objet : Re: [squid-users] 3.5.25: 
> (71) Protocol error (TLS code:
> SQUID_ERR_SSL_HANDSHAKE)
>
> Squid can't have any intermediate certificates. As by as root CA's.
>
> You can use this:
>
> #? TAG: sslproxy_foreign_intermediate_certs
> #? ? Many origin servers fail to send their full server certificate
> #? ? chain for verification, assuming the client already has or can
> #? ? easily locate any missing intermediate certificates.
> #
> #? ? Squid uses the certificates from the specified file to fill in
> #? ? these missing chains when trying to validate origin server
> #? ? certificate chains.
> #
> #? ? The file is expected to contain zero or more PEM-encoded
> #? ? intermediate certificates. These certificates are not treated
> #? ? as trusted root certificates, and any self-signed certificate in
> #? ? this file will be ignored.
> #Default:
> # none
>
> However, you should identiry and collect them by yourself.
>
> The biggest problem:
>
> Instead of root CA's, which can be taken from Mozilla's, intermediate 
> CAs spreaded over CA's providers, have much shorter valid period (most 
> cases up to 5-7 years) and, by this reason, should be continiously 
> maintained by proxy admin.
>
> Also, remove this:
>
> sslproxy_flags DONT_VERIFY_PEER
> sslproxy_cert_error allow all
>
> From your config. Don't. Never. This is completely disable ANY 
> security checks for certificates, which leads to giant vulnerability to your users.
> ssl_proxy_cert_error should be restricted by very specific ACL(s) in 
> your config only for number of sites you trust.
>
> 28.04.2017 2:27, David Touzeau ?????:
>> Hi yuri
>>
>> I did not know if squid have Symantec intermediate certificate Squid 
>> is installed as default...
>> Any howto ?
>>
>>
>> -----Message d'origine-----
>> De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
>> De la part de Yuri Voinov Envoy? : jeudi 27 avril 2017 22:09 ? :
>> squid-users at lists.squid-cache.org Objet : Re: [squid-users] 3.5.25:
>> (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
>>
>> Look. It can be intermediate certificates issue.
>>
>> Does Squid have Symantec intermediate certificates?
>>
>>
>> 27.04.2017 22:47, David Touzeau ?????:
>>> Hi,
>>> I'm unable to access to https://www.boutique.afnor.org website.
>>> I would like to know if this issue cannot be fixed and must deny 
>>> bump website to fix it.
>>> Without Squid the website is correctly displayed
>>>
>>> Squid claim an error page with "(71) Protocol error (TLS code:
>>> SQUID_ERR_SSL_HANDSHAKE)"
>>>
>>> In cache.log: "Error negotiating SSL on FD 17:
>>> error:00000000:lib(0):func(0):reason(0) (5/0/0)"
>>>
>>> Using the following configuration:
>>>
>>> http_port 0.0.0.0:3128? name=MyPortNameID20 ssl-bump 
>>> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
>>> cert=/etc/squid3/ssl/0c451f46b4d05031560d8195f30165cb.dyn
>>> sslproxy_foreign_intermediate_certs /etc/squid3/intermediate_ca.pem 
>>> sslcrtd_program /lib/squid3/ssl_crtd -s 
>>> /var/lib/squid/session/ssl/ssl_db -M 8MB sslcrtd_children 16
>>> startup=5
>>> idle=1 acl FakeCert ssl::server_name .apple.com acl FakeCert 
>>> ssl::server_name .icloud.com acl FakeCert ssl::server_name 
>>> .mzstatic.com acl FakeCert ssl::server_name .dropbox.com acl
>>> ssl_step1 at_step SslBump1 acl ssl_step2 at_step SslBump2 acl
>>> ssl_step3 at_step
>>> SslBump3 ssl_bump peek ssl_step1 ssl_bump splice FakeCert ssl_bump 
>>> bump ssl_step2 all ssl_bump splice all
>>>
>>> sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression sslproxy_cipher
>>> ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:
>>> !aNULL
>>> :!eNULL
>>> sslproxy_flags DONT_VERIFY_PEER
>>> sslproxy_cert_error allow all
>>>
>>>
>>>
>>> Openssl info
>>> --------------------------------------------------------------------
>>> -
>>> -
>>> ------
>>> --------------------------------------------------------------------
>>> -
>>> -
>>> ------
>>> ---
>>>
>>> openssl s_client -connect 195.115.26.58:443 -showcerts
>>>
>>> CONNECTED(00000003)
>>> depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, 
>>> OU = "(c)
>>> 2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class 
>>> 3 Public Primary Certification Authority - G5 verify return:1
>>> depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust 
>>> Network, CN = Symantec Class 3 Secure Server CA - G4 verify return:1
>>> depth=0 C = FR, ST = Seine Saint Denis, L = ST DENIS, O = 
>>> ASSOCIATION FRANCAISE DE NORMALISATION, OU = ASSOCIATION FRANCAISE 
>>> DE NORMALISATION, CN = www.boutique.afnor.org verify return:1
>>> ---
>>> Certificate chain
>>>? 0 s:/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE 
>>> DE NORMALISATION/OU=ASSOCIATION FRANCAISE DE 
>>> NORMALISATION/CN=www.boutique.afnor.org
>>>? ? i:/C=US/O=Symantec Corporation/OU=Symantec Trust 
>>> Network/CN=Symantec Class 3 Secure Server CA - G4 -----BEGIN
>>> CERTIFICATE----- ../..
>>> -----END CERTIFICATE-----
>>>? 1 s:/C=US/O=Symantec Corporation/OU=Symantec Trust 
>>> Network/CN=Symantec Class 3 Secure Server CA - G4
>>>? ? i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006 
>>> VeriSign, Inc. - For authorized use only/CN=VeriSign Class 3 Public 
>>> Primary Certification Authority - G5 -----BEGIN CERTIFICATE----- ../..
>>> -----END CERTIFICATE-----
>>> ---
>>> Server certificate
>>> subject=/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION 
>>> FRANCAISE DE NORMALISATION/OU=ASSOCIATION FRANCAISE DE 
>>> NORMALISATION/CN=www.boutique.afnor.org
>>> issuer=/C=US/O=Symantec Corporation/OU=Symantec Trust 
>>> Network/CN=Symantec Class 3 Secure Server CA - G4
>>> ---
>>> No client certificate CA names sent
>>> ---
>>> SSL handshake has read 3105 bytes and written 616 bytes
>>> ---
>>> New, TLSv1/SSLv3, Cipher is AES128-SHA Server public key is 2048 bit 
>>> Secure Renegotiation IS supported
>>> Compression: NONE
>>> Expansion: NONE
>>> SSL-Session:
>>>? ? Protocol? : TLSv1
>>>? ? Cipher? ? : AES128-SHA
>>>? ? Session-ID:
>>> 833B0000A2346F50C5AAFC6B5188B4EBD9304CD25411BECFF0713F8D76C65D9D
>>>? ? Session-ID-ctx:
>>>? ? Master-Key:
>>> D2DF6C62264D03D7D44AF44EB8C0B1B7AD0E650D34DF6EBEB1CBEBFE4F30CB9C6F50
>>> 8
>>> 0
>>> AA94F5
>>> D6B5955DD8DF06608416
>>>? ? Key-Arg? : None
>>>? ? PSK identity: None
>>>? ? PSK identity hint: None
>>>? ? SRP username: None
>>>? ? Start Time: 1493311275
>>>? ? Timeout? : 300 (sec)
>>>? ? Verify return code: 0 (ok)
>>> ---
>>> read:errno=0
>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> --
>> Bugs to the Future
>>
> --
> Bugs to the Future
>

--
Bugs to the Future

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users


   
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170428/e1a48671/attachment.htm>

From rafael.akchurin at diladele.com  Fri Apr 28 16:00:53 2017
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Fri, 28 Apr 2017 16:00:53 +0000
Subject: [squid-users] 3.5.25: (71) Protocol error (TLS
	code:	SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <0dcb01d2c008$316500e0$942f02a0$@articatech.com>
References: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>
 <c088c83f-ac6b-f463-7948-47463d0703a3@gmail.com>
 <073901d2bf94$bceb2dc0$36c18940$@articatech.com>
 <216c9a91-c4e5-896a-7dbe-f5e955258cc9@gmail.com>
 <074301d2bf9a$ed55aed0$c8010c70$@articatech.com>
 <6b4e8f6b-b2b4-2243-aace-e5d907c918cb@gmail.com>
 <0dcb01d2c008$316500e0$942f02a0$@articatech.com>
Message-ID: <DB6PR0401MB2680AD61BF3A94BD9026061B8F130@DB6PR0401MB2680.eurprd04.prod.outlook.com>

Hello David and all,

According to https://www.ssllabs.com/ssltest/analyze.html?d=www.boutique.afnor.org&hideResults=on you do not need to add any intermediate certificates  to system storage - site seems to be sending the whole chain as it should...

BUT the overall site SSL rating is so bad..

Raf

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of David Touzeau
Sent: Friday, April 28, 2017 10:14 AM
To: 'Yuri Voinov'; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] 3.5.25: (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)

I'm fighting to find the correct certificate chain for this website:
https://www.boutique.afnor.org

I have also added all certificates included in this package:
https://packages.debian.org/fr/sid/ca-certificates


Do you have any tips to help ?

Best regards

-----Message d'origine-----
De : Yuri Voinov [mailto:yvoinov at gmail.com] Envoy? : jeudi 27 avril 2017 23:26 ? : David Touzeau <david at articatech.com>; squid-users at lists.squid-cache.org Objet : Re: [squid-users] 3.5.25: (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)

Be careful with intermediate CA's you grabbed. Check they validity, fingerprints and attributes.

Proxying SSL requires much more work with Squid.


28.04.2017 3:12, David Touzeau ?????:
> Thanks Yuri
>
>  ! but i have still have the error " Error negotiating SSL on FD 13: 
> error:00000000:lib(0):func(0):reason(0) (5/0/0) " and cannot browse to 
> site ( as i seen you can with your squid...??? )
Yes. With two different versions.
>
> Created a file /etc/squid3/cabundle.pem
>
> Added Symantec certificates available here:
> https://knowledge.symantec.com/kb/index?page=content&actp=CROSSLINK&id
> =INFO2047
>
> add
>
> sslproxy_foreign_intermediate_certs  /etc/squid3/cabundle.pem
>
> and perform a squid -k reconfigure
>
> Missing something ???
May be. I'm recommend to re-initialize mimic certificates DB also and restart Squid, not reconfigure.

Keep in mind, that SSL bump critical important for success. For example, AFAIK stare often opposite to bump (in most cases). Read wiki article, but also remember this functionality still evolving, and can changed without notices. So, experiment.
>
> Best regards
>
> -----Message d'origine-----
> De : Yuri Voinov [mailto:yvoinov at gmail.com] Envoy? : jeudi 27 avril
> 2017 22:52 ? : David Touzeau <david at articatech.com>; 
> squid-users at lists.squid-cache.org Objet : Re: [squid-users] 3.5.25:
> (71) Protocol error (TLS code:
> SQUID_ERR_SSL_HANDSHAKE)
>
> Squid can't have any intermediate certificates. As by as root CA's.
>
> You can use this:
>
> #  TAG: sslproxy_foreign_intermediate_certs
> #    Many origin servers fail to send their full server certificate
> #    chain for verification, assuming the client already has or can
> #    easily locate any missing intermediate certificates.
> #
> #    Squid uses the certificates from the specified file to fill in
> #    these missing chains when trying to validate origin server
> #    certificate chains.
> #
> #    The file is expected to contain zero or more PEM-encoded
> #    intermediate certificates. These certificates are not treated
> #    as trusted root certificates, and any self-signed certificate in
> #    this file will be ignored.
> #Default:
> # none
>
> However, you should identiry and collect them by yourself.
>
> The biggest problem:
>
> Instead of root CA's, which can be taken from Mozilla's, intermediate 
> CAs spreaded over CA's providers, have much shorter valid period (most 
> cases up to 5-7 years) and, by this reason, should be continiously 
> maintained by proxy admin.
>
> Also, remove this:
>
> sslproxy_flags DONT_VERIFY_PEER
> sslproxy_cert_error allow all
>
> From your config. Don't. Never. This is completely disable ANY 
> security checks for certificates, which leads to giant vulnerability to your users.
> ssl_proxy_cert_error should be restricted by very specific ACL(s) in 
> your config only for number of sites you trust.
>
> 28.04.2017 2:27, David Touzeau ?????:
>> Hi yuri
>>
>> I did not know if squid have Symantec intermediate certificate Squid 
>> is installed as default...
>> Any howto ?
>>
>>
>> -----Message d'origine-----
>> De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
>> De la part de Yuri Voinov Envoy? : jeudi 27 avril 2017 22:09 ? :
>> squid-users at lists.squid-cache.org Objet : Re: [squid-users] 3.5.25:
>> (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
>>
>> Look. It can be intermediate certificates issue.
>>
>> Does Squid have Symantec intermediate certificates?
>>
>>
>> 27.04.2017 22:47, David Touzeau ?????:
>>> Hi,
>>> I'm unable to access to https://www.boutique.afnor.org website.
>>> I would like to know if this issue cannot be fixed and must deny 
>>> bump website to fix it.
>>> Without Squid the website is correctly displayed
>>>
>>> Squid claim an error page with "(71) Protocol error (TLS code:
>>> SQUID_ERR_SSL_HANDSHAKE)"
>>>
>>> In cache.log: "Error negotiating SSL on FD 17:
>>> error:00000000:lib(0):func(0):reason(0) (5/0/0)"
>>>
>>> Using the following configuration:
>>>
>>> http_port 0.0.0.0:3128  name=MyPortNameID20 ssl-bump 
>>> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
>>> cert=/etc/squid3/ssl/0c451f46b4d05031560d8195f30165cb.dyn
>>> sslproxy_foreign_intermediate_certs /etc/squid3/intermediate_ca.pem 
>>> sslcrtd_program /lib/squid3/ssl_crtd -s 
>>> /var/lib/squid/session/ssl/ssl_db -M 8MB sslcrtd_children 16
>>> startup=5
>>> idle=1 acl FakeCert ssl::server_name .apple.com acl FakeCert 
>>> ssl::server_name .icloud.com acl FakeCert ssl::server_name 
>>> .mzstatic.com acl FakeCert ssl::server_name .dropbox.com acl
>>> ssl_step1 at_step SslBump1 acl ssl_step2 at_step SslBump2 acl
>>> ssl_step3 at_step
>>> SslBump3 ssl_bump peek ssl_step1 ssl_bump splice FakeCert ssl_bump 
>>> bump ssl_step2 all ssl_bump splice all
>>>
>>> sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression sslproxy_cipher
>>> ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:
>>> !aNULL
>>> :!eNULL
>>> sslproxy_flags DONT_VERIFY_PEER
>>> sslproxy_cert_error allow all
>>>
>>>
>>>
>>> Openssl info
>>> --------------------------------------------------------------------
>>> -
>>> -
>>> ------
>>> --------------------------------------------------------------------
>>> -
>>> -
>>> ------
>>> ---
>>>
>>> openssl s_client -connect 195.115.26.58:443 -showcerts
>>>
>>> CONNECTED(00000003)
>>> depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, 
>>> OU = "(c)
>>> 2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class
>>> 3 Public Primary Certification Authority - G5 verify return:1
>>> depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust 
>>> Network, CN = Symantec Class 3 Secure Server CA - G4 verify return:1
>>> depth=0 C = FR, ST = Seine Saint Denis, L = ST DENIS, O = 
>>> ASSOCIATION FRANCAISE DE NORMALISATION, OU = ASSOCIATION FRANCAISE 
>>> DE NORMALISATION, CN = www.boutique.afnor.org verify return:1
>>> ---
>>> Certificate chain
>>>  0 s:/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE 
>>> DE NORMALISATION/OU=ASSOCIATION FRANCAISE DE 
>>> NORMALISATION/CN=www.boutique.afnor.org
>>>    i:/C=US/O=Symantec Corporation/OU=Symantec Trust 
>>> Network/CN=Symantec Class 3 Secure Server CA - G4 -----BEGIN
>>> CERTIFICATE----- ../..
>>> -----END CERTIFICATE-----
>>>  1 s:/C=US/O=Symantec Corporation/OU=Symantec Trust 
>>> Network/CN=Symantec Class 3 Secure Server CA - G4
>>>    i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006 
>>> VeriSign, Inc. - For authorized use only/CN=VeriSign Class 3 Public 
>>> Primary Certification Authority - G5 -----BEGIN CERTIFICATE----- ../..
>>> -----END CERTIFICATE-----
>>> ---
>>> Server certificate
>>> subject=/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION 
>>> FRANCAISE DE NORMALISATION/OU=ASSOCIATION FRANCAISE DE 
>>> NORMALISATION/CN=www.boutique.afnor.org
>>> issuer=/C=US/O=Symantec Corporation/OU=Symantec Trust 
>>> Network/CN=Symantec Class 3 Secure Server CA - G4
>>> ---
>>> No client certificate CA names sent
>>> ---
>>> SSL handshake has read 3105 bytes and written 616 bytes
>>> ---
>>> New, TLSv1/SSLv3, Cipher is AES128-SHA Server public key is 2048 bit 
>>> Secure Renegotiation IS supported
>>> Compression: NONE
>>> Expansion: NONE
>>> SSL-Session:
>>>     Protocol  : TLSv1
>>>     Cipher    : AES128-SHA
>>>     Session-ID:
>>> 833B0000A2346F50C5AAFC6B5188B4EBD9304CD25411BECFF0713F8D76C65D9D
>>>     Session-ID-ctx:
>>>     Master-Key:
>>> D2DF6C62264D03D7D44AF44EB8C0B1B7AD0E650D34DF6EBEB1CBEBFE4F30CB9C6F50
>>> 8
>>> 0
>>> AA94F5
>>> D6B5955DD8DF06608416
>>>     Key-Arg   : None
>>>     PSK identity: None
>>>     PSK identity hint: None
>>>     SRP username: None
>>>     Start Time: 1493311275
>>>     Timeout   : 300 (sec)
>>>     Verify return code: 0 (ok)
>>> ---
>>> read:errno=0
>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>> --
>> Bugs to the Future
>>
> --
> Bugs to the Future
>

--
Bugs to the Future

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From yvoinov at gmail.com  Fri Apr 28 17:30:35 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Fri, 28 Apr 2017 23:30:35 +0600
Subject: [squid-users] 3.5.25: (71) Protocol error (TLS code:
 SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <DB6PR0401MB2680AD61BF3A94BD9026061B8F130@DB6PR0401MB2680.eurprd04.prod.outlook.com>
References: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>
 <c088c83f-ac6b-f463-7948-47463d0703a3@gmail.com>
 <073901d2bf94$bceb2dc0$36c18940$@articatech.com>
 <216c9a91-c4e5-896a-7dbe-f5e955258cc9@gmail.com>
 <074301d2bf9a$ed55aed0$c8010c70$@articatech.com>
 <6b4e8f6b-b2b4-2243-aace-e5d907c918cb@gmail.com>
 <0dcb01d2c008$316500e0$942f02a0$@articatech.com>
 <DB6PR0401MB2680AD61BF3A94BD9026061B8F130@DB6PR0401MB2680.eurprd04.prod.outlook.com>
Message-ID: <e2a48bce-4a04-fffa-0907-022296a3d811@gmail.com>

Raf,

intermediate CAs required anyway. Not all good good webmasters - just a
focus of the world's Good - add intermediate certificates to the chain. ;-)

Evil proxy administrators - the focus of the world's Evil - must do this
manually. Still :-D

28.04.2017 22:00, Rafael Akchurin ?????:
> Hello David and all,
>
> According to https://www.ssllabs.com/ssltest/analyze.html?d=www.boutique.afnor.org&hideResults=on you do not need to add any intermediate certificates  to system storage - site seems to be sending the whole chain as it should...
>
> BUT the overall site SSL rating is so bad..
>
> Raf
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of David Touzeau
> Sent: Friday, April 28, 2017 10:14 AM
> To: 'Yuri Voinov'; squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] 3.5.25: (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
>
> I'm fighting to find the correct certificate chain for this website:
> https://www.boutique.afnor.org
>
> I have also added all certificates included in this package:
> https://packages.debian.org/fr/sid/ca-certificates
>
>
> Do you have any tips to help ?
>
> Best regards
>
> -----Message d'origine-----
> De : Yuri Voinov [mailto:yvoinov at gmail.com] Envoy? : jeudi 27 avril 2017 23:26 ? : David Touzeau <david at articatech.com>; squid-users at lists.squid-cache.org Objet : Re: [squid-users] 3.5.25: (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
>
> Be careful with intermediate CA's you grabbed. Check they validity, fingerprints and attributes.
>
> Proxying SSL requires much more work with Squid.
>
>
> 28.04.2017 3:12, David Touzeau ?????:
>> Thanks Yuri
>>
>>  ! but i have still have the error " Error negotiating SSL on FD 13: 
>> error:00000000:lib(0):func(0):reason(0) (5/0/0) " and cannot browse to 
>> site ( as i seen you can with your squid...??? )
> Yes. With two different versions.
>> Created a file /etc/squid3/cabundle.pem
>>
>> Added Symantec certificates available here:
>> https://knowledge.symantec.com/kb/index?page=content&actp=CROSSLINK&id
>> =INFO2047
>>
>> add
>>
>> sslproxy_foreign_intermediate_certs  /etc/squid3/cabundle.pem
>>
>> and perform a squid -k reconfigure
>>
>> Missing something ???
> May be. I'm recommend to re-initialize mimic certificates DB also and restart Squid, not reconfigure.
>
> Keep in mind, that SSL bump critical important for success. For example, AFAIK stare often opposite to bump (in most cases). Read wiki article, but also remember this functionality still evolving, and can changed without notices. So, experiment.
>> Best regards
>>
>> -----Message d'origine-----
>> De : Yuri Voinov [mailto:yvoinov at gmail.com] Envoy? : jeudi 27 avril
>> 2017 22:52 ? : David Touzeau <david at articatech.com>; 
>> squid-users at lists.squid-cache.org Objet : Re: [squid-users] 3.5.25:
>> (71) Protocol error (TLS code:
>> SQUID_ERR_SSL_HANDSHAKE)
>>
>> Squid can't have any intermediate certificates. As by as root CA's.
>>
>> You can use this:
>>
>> #  TAG: sslproxy_foreign_intermediate_certs
>> #    Many origin servers fail to send their full server certificate
>> #    chain for verification, assuming the client already has or can
>> #    easily locate any missing intermediate certificates.
>> #
>> #    Squid uses the certificates from the specified file to fill in
>> #    these missing chains when trying to validate origin server
>> #    certificate chains.
>> #
>> #    The file is expected to contain zero or more PEM-encoded
>> #    intermediate certificates. These certificates are not treated
>> #    as trusted root certificates, and any self-signed certificate in
>> #    this file will be ignored.
>> #Default:
>> # none
>>
>> However, you should identiry and collect them by yourself.
>>
>> The biggest problem:
>>
>> Instead of root CA's, which can be taken from Mozilla's, intermediate 
>> CAs spreaded over CA's providers, have much shorter valid period (most 
>> cases up to 5-7 years) and, by this reason, should be continiously 
>> maintained by proxy admin.
>>
>> Also, remove this:
>>
>> sslproxy_flags DONT_VERIFY_PEER
>> sslproxy_cert_error allow all
>>
>> From your config. Don't. Never. This is completely disable ANY 
>> security checks for certificates, which leads to giant vulnerability to your users.
>> ssl_proxy_cert_error should be restricted by very specific ACL(s) in 
>> your config only for number of sites you trust.
>>
>> 28.04.2017 2:27, David Touzeau ?????:
>>> Hi yuri
>>>
>>> I did not know if squid have Symantec intermediate certificate Squid 
>>> is installed as default...
>>> Any howto ?
>>>
>>>
>>> -----Message d'origine-----
>>> De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
>>> De la part de Yuri Voinov Envoy? : jeudi 27 avril 2017 22:09 ? :
>>> squid-users at lists.squid-cache.org Objet : Re: [squid-users] 3.5.25:
>>> (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
>>>
>>> Look. It can be intermediate certificates issue.
>>>
>>> Does Squid have Symantec intermediate certificates?
>>>
>>>
>>> 27.04.2017 22:47, David Touzeau ?????:
>>>> Hi,
>>>> I'm unable to access to https://www.boutique.afnor.org website.
>>>> I would like to know if this issue cannot be fixed and must deny 
>>>> bump website to fix it.
>>>> Without Squid the website is correctly displayed
>>>>
>>>> Squid claim an error page with "(71) Protocol error (TLS code:
>>>> SQUID_ERR_SSL_HANDSHAKE)"
>>>>
>>>> In cache.log: "Error negotiating SSL on FD 17:
>>>> error:00000000:lib(0):func(0):reason(0) (5/0/0)"
>>>>
>>>> Using the following configuration:
>>>>
>>>> http_port 0.0.0.0:3128  name=MyPortNameID20 ssl-bump 
>>>> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
>>>> cert=/etc/squid3/ssl/0c451f46b4d05031560d8195f30165cb.dyn
>>>> sslproxy_foreign_intermediate_certs /etc/squid3/intermediate_ca.pem 
>>>> sslcrtd_program /lib/squid3/ssl_crtd -s 
>>>> /var/lib/squid/session/ssl/ssl_db -M 8MB sslcrtd_children 16
>>>> startup=5
>>>> idle=1 acl FakeCert ssl::server_name .apple.com acl FakeCert 
>>>> ssl::server_name .icloud.com acl FakeCert ssl::server_name 
>>>> .mzstatic.com acl FakeCert ssl::server_name .dropbox.com acl
>>>> ssl_step1 at_step SslBump1 acl ssl_step2 at_step SslBump2 acl
>>>> ssl_step3 at_step
>>>> SslBump3 ssl_bump peek ssl_step1 ssl_bump splice FakeCert ssl_bump 
>>>> bump ssl_step2 all ssl_bump splice all
>>>>
>>>> sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression sslproxy_cipher
>>>> ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:
>>>> !aNULL
>>>> :!eNULL
>>>> sslproxy_flags DONT_VERIFY_PEER
>>>> sslproxy_cert_error allow all
>>>>
>>>>
>>>>
>>>> Openssl info
>>>> --------------------------------------------------------------------
>>>> -
>>>> -
>>>> ------
>>>> --------------------------------------------------------------------
>>>> -
>>>> -
>>>> ------
>>>> ---
>>>>
>>>> openssl s_client -connect 195.115.26.58:443 -showcerts
>>>>
>>>> CONNECTED(00000003)
>>>> depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, 
>>>> OU = "(c)
>>>> 2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class
>>>> 3 Public Primary Certification Authority - G5 verify return:1
>>>> depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust 
>>>> Network, CN = Symantec Class 3 Secure Server CA - G4 verify return:1
>>>> depth=0 C = FR, ST = Seine Saint Denis, L = ST DENIS, O = 
>>>> ASSOCIATION FRANCAISE DE NORMALISATION, OU = ASSOCIATION FRANCAISE 
>>>> DE NORMALISATION, CN = www.boutique.afnor.org verify return:1
>>>> ---
>>>> Certificate chain
>>>>  0 s:/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE 
>>>> DE NORMALISATION/OU=ASSOCIATION FRANCAISE DE 
>>>> NORMALISATION/CN=www.boutique.afnor.org
>>>>    i:/C=US/O=Symantec Corporation/OU=Symantec Trust 
>>>> Network/CN=Symantec Class 3 Secure Server CA - G4 -----BEGIN
>>>> CERTIFICATE----- ../..
>>>> -----END CERTIFICATE-----
>>>>  1 s:/C=US/O=Symantec Corporation/OU=Symantec Trust 
>>>> Network/CN=Symantec Class 3 Secure Server CA - G4
>>>>    i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006 
>>>> VeriSign, Inc. - For authorized use only/CN=VeriSign Class 3 Public 
>>>> Primary Certification Authority - G5 -----BEGIN CERTIFICATE----- ../..
>>>> -----END CERTIFICATE-----
>>>> ---
>>>> Server certificate
>>>> subject=/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION 
>>>> FRANCAISE DE NORMALISATION/OU=ASSOCIATION FRANCAISE DE 
>>>> NORMALISATION/CN=www.boutique.afnor.org
>>>> issuer=/C=US/O=Symantec Corporation/OU=Symantec Trust 
>>>> Network/CN=Symantec Class 3 Secure Server CA - G4
>>>> ---
>>>> No client certificate CA names sent
>>>> ---
>>>> SSL handshake has read 3105 bytes and written 616 bytes
>>>> ---
>>>> New, TLSv1/SSLv3, Cipher is AES128-SHA Server public key is 2048 bit 
>>>> Secure Renegotiation IS supported
>>>> Compression: NONE
>>>> Expansion: NONE
>>>> SSL-Session:
>>>>     Protocol  : TLSv1
>>>>     Cipher    : AES128-SHA
>>>>     Session-ID:
>>>> 833B0000A2346F50C5AAFC6B5188B4EBD9304CD25411BECFF0713F8D76C65D9D
>>>>     Session-ID-ctx:
>>>>     Master-Key:
>>>> D2DF6C62264D03D7D44AF44EB8C0B1B7AD0E650D34DF6EBEB1CBEBFE4F30CB9C6F50
>>>> 8
>>>> 0
>>>> AA94F5
>>>> D6B5955DD8DF06608416
>>>>     Key-Arg   : None
>>>>     PSK identity: None
>>>>     PSK identity hint: None
>>>>     SRP username: None
>>>>     Start Time: 1493311275
>>>>     Timeout   : 300 (sec)
>>>>     Verify return code: 0 (ok)
>>>> ---
>>>> read:errno=0
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>> --
>>> Bugs to the Future
>>>
>> --
>> Bugs to the Future
>>
> --
> Bugs to the Future
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170428/1aad92ae/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170428/1aad92ae/attachment.sig>

From david at articatech.com  Sat Apr 29 00:18:21 2017
From: david at articatech.com (David Touzeau)
Date: Sat, 29 Apr 2017 02:18:21 +0200
Subject: [squid-users] 3.5.25: (71) Protocol error (TLS code:
	SQUID_ERR_SSL_HANDSHAKE)
In-Reply-To: <e2a48bce-4a04-fffa-0907-022296a3d811@gmail.com>
References: <051c01d2bf75$fe6115e0$fb2341a0$@articatech.com>
 <c088c83f-ac6b-f463-7948-47463d0703a3@gmail.com>
 <073901d2bf94$bceb2dc0$36c18940$@articatech.com>
 <216c9a91-c4e5-896a-7dbe-f5e955258cc9@gmail.com>
 <074301d2bf9a$ed55aed0$c8010c70$@articatech.com>
 <6b4e8f6b-b2b4-2243-aace-e5d907c918cb@gmail.com>
 <0dcb01d2c008$316500e0$942f02a0$@articatech.com>
 <DB6PR0401MB2680AD61BF3A94BD9026061B8F130@DB6PR0401MB2680.eurprd04.prod.outlook.com>
 <e2a48bce-4a04-fffa-0907-022296a3d811@gmail.com>
Message-ID: <28a801d2c07e$1d1df300$5759d900$@articatech.com>

Added

Symantec Class 3 Secure Server CA - G4
VeriSign Class 3 Public Primary Certification Authority - G5

Same issue :=(



-----Message d'origine-----
De : Yuri Voinov [mailto:yvoinov at gmail.com] 
Envoy? : vendredi 28 avril 2017 19:31
? : Rafael Akchurin <rafael.akchurin at diladele.com>; David Touzeau <david at articatech.com>; squid-users at lists.squid-cache.org
Objet : Re: [squid-users] 3.5.25: (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)

Raf,

intermediate CAs required anyway. Not all good good webmasters - just a focus of the world's Good - add intermediate certificates to the chain. ;-)

Evil proxy administrators - the focus of the world's Evil - must do this manually. Still :-D

28.04.2017 22:00, Rafael Akchurin ?????:
> Hello David and all,
>
> According to https://www.ssllabs.com/ssltest/analyze.html?d=www.boutique.afnor.org&hideResults=on you do not need to add any intermediate certificates  to system storage - site seems to be sending the whole chain as it should...
>
> BUT the overall site SSL rating is so bad..
>
> Raf
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] 
> On Behalf Of David Touzeau
> Sent: Friday, April 28, 2017 10:14 AM
> To: 'Yuri Voinov'; squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] 3.5.25: (71) Protocol error (TLS code: 
> SQUID_ERR_SSL_HANDSHAKE)
>
> I'm fighting to find the correct certificate chain for this website:
> https://www.boutique.afnor.org
>
> I have also added all certificates included in this package:
> https://packages.debian.org/fr/sid/ca-certificates
>
>
> Do you have any tips to help ?
>
> Best regards
>
> -----Message d'origine-----
> De : Yuri Voinov [mailto:yvoinov at gmail.com] Envoy? : jeudi 27 avril 
> 2017 23:26 ? : David Touzeau <david at articatech.com>; 
> squid-users at lists.squid-cache.org Objet : Re: [squid-users] 3.5.25: 
> (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
>
> Be careful with intermediate CA's you grabbed. Check they validity, fingerprints and attributes.
>
> Proxying SSL requires much more work with Squid.
>
>
> 28.04.2017 3:12, David Touzeau ?????:
>> Thanks Yuri
>>
>>  ! but i have still have the error " Error negotiating SSL on FD 13: 
>> error:00000000:lib(0):func(0):reason(0) (5/0/0) " and cannot browse 
>> to site ( as i seen you can with your squid...??? )
> Yes. With two different versions.
>> Created a file /etc/squid3/cabundle.pem
>>
>> Added Symantec certificates available here:
>> https://knowledge.symantec.com/kb/index?page=content&actp=CROSSLINK&i
>> d
>> =INFO2047
>>
>> add
>>
>> sslproxy_foreign_intermediate_certs  /etc/squid3/cabundle.pem
>>
>> and perform a squid -k reconfigure
>>
>> Missing something ???
> May be. I'm recommend to re-initialize mimic certificates DB also and restart Squid, not reconfigure.
>
> Keep in mind, that SSL bump critical important for success. For example, AFAIK stare often opposite to bump (in most cases). Read wiki article, but also remember this functionality still evolving, and can changed without notices. So, experiment.
>> Best regards
>>
>> -----Message d'origine-----
>> De : Yuri Voinov [mailto:yvoinov at gmail.com] Envoy? : jeudi 27 avril
>> 2017 22:52 ? : David Touzeau <david at articatech.com>; 
>> squid-users at lists.squid-cache.org Objet : Re: [squid-users] 3.5.25:
>> (71) Protocol error (TLS code:
>> SQUID_ERR_SSL_HANDSHAKE)
>>
>> Squid can't have any intermediate certificates. As by as root CA's.
>>
>> You can use this:
>>
>> #  TAG: sslproxy_foreign_intermediate_certs
>> #    Many origin servers fail to send their full server certificate
>> #    chain for verification, assuming the client already has or can
>> #    easily locate any missing intermediate certificates.
>> #
>> #    Squid uses the certificates from the specified file to fill in
>> #    these missing chains when trying to validate origin server
>> #    certificate chains.
>> #
>> #    The file is expected to contain zero or more PEM-encoded
>> #    intermediate certificates. These certificates are not treated
>> #    as trusted root certificates, and any self-signed certificate in
>> #    this file will be ignored.
>> #Default:
>> # none
>>
>> However, you should identiry and collect them by yourself.
>>
>> The biggest problem:
>>
>> Instead of root CA's, which can be taken from Mozilla's, intermediate 
>> CAs spreaded over CA's providers, have much shorter valid period 
>> (most cases up to 5-7 years) and, by this reason, should be 
>> continiously maintained by proxy admin.
>>
>> Also, remove this:
>>
>> sslproxy_flags DONT_VERIFY_PEER
>> sslproxy_cert_error allow all
>>
>> From your config. Don't. Never. This is completely disable ANY 
>> security checks for certificates, which leads to giant vulnerability to your users.
>> ssl_proxy_cert_error should be restricted by very specific ACL(s) in 
>> your config only for number of sites you trust.
>>
>> 28.04.2017 2:27, David Touzeau ?????:
>>> Hi yuri
>>>
>>> I did not know if squid have Symantec intermediate certificate Squid 
>>> is installed as default...
>>> Any howto ?
>>>
>>>
>>> -----Message d'origine-----
>>> De : squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
>>> De la part de Yuri Voinov Envoy? : jeudi 27 avril 2017 22:09 ? :
>>> squid-users at lists.squid-cache.org Objet : Re: [squid-users] 3.5.25:
>>> (71) Protocol error (TLS code: SQUID_ERR_SSL_HANDSHAKE)
>>>
>>> Look. It can be intermediate certificates issue.
>>>
>>> Does Squid have Symantec intermediate certificates?
>>>
>>>
>>> 27.04.2017 22:47, David Touzeau ?????:
>>>> Hi,
>>>> I'm unable to access to https://www.boutique.afnor.org website.
>>>> I would like to know if this issue cannot be fixed and must deny 
>>>> bump website to fix it.
>>>> Without Squid the website is correctly displayed
>>>>
>>>> Squid claim an error page with "(71) Protocol error (TLS code:
>>>> SQUID_ERR_SSL_HANDSHAKE)"
>>>>
>>>> In cache.log: "Error negotiating SSL on FD 17:
>>>> error:00000000:lib(0):func(0):reason(0) (5/0/0)"
>>>>
>>>> Using the following configuration:
>>>>
>>>> http_port 0.0.0.0:3128  name=MyPortNameID20 ssl-bump 
>>>> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
>>>> cert=/etc/squid3/ssl/0c451f46b4d05031560d8195f30165cb.dyn
>>>> sslproxy_foreign_intermediate_certs /etc/squid3/intermediate_ca.pem 
>>>> sslcrtd_program /lib/squid3/ssl_crtd -s 
>>>> /var/lib/squid/session/ssl/ssl_db -M 8MB sslcrtd_children 16
>>>> startup=5
>>>> idle=1 acl FakeCert ssl::server_name .apple.com acl FakeCert 
>>>> ssl::server_name .icloud.com acl FakeCert ssl::server_name 
>>>> .mzstatic.com acl FakeCert ssl::server_name .dropbox.com acl
>>>> ssl_step1 at_step SslBump1 acl ssl_step2 at_step SslBump2 acl
>>>> ssl_step3 at_step
>>>> SslBump3 ssl_bump peek ssl_step1 ssl_bump splice FakeCert ssl_bump 
>>>> bump ssl_step2 all ssl_bump splice all
>>>>
>>>> sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression sslproxy_cipher
>>>> ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:
>>>> !aNULL
>>>> :!eNULL
>>>> sslproxy_flags DONT_VERIFY_PEER
>>>> sslproxy_cert_error allow all
>>>>
>>>>
>>>>
>>>> Openssl info
>>>> -------------------------------------------------------------------
>>>> -
>>>> -
>>>> -
>>>> ------
>>>> -------------------------------------------------------------------
>>>> -
>>>> -
>>>> -
>>>> ------
>>>> ---
>>>>
>>>> openssl s_client -connect 195.115.26.58:443 -showcerts
>>>>
>>>> CONNECTED(00000003)
>>>> depth=2 C = US, O = "VeriSign, Inc.", OU = VeriSign Trust Network, 
>>>> OU = "(c)
>>>> 2006 VeriSign, Inc. - For authorized use only", CN = VeriSign Class
>>>> 3 Public Primary Certification Authority - G5 verify return:1
>>>> depth=1 C = US, O = Symantec Corporation, OU = Symantec Trust 
>>>> Network, CN = Symantec Class 3 Secure Server CA - G4 verify 
>>>> return:1
>>>> depth=0 C = FR, ST = Seine Saint Denis, L = ST DENIS, O = 
>>>> ASSOCIATION FRANCAISE DE NORMALISATION, OU = ASSOCIATION FRANCAISE 
>>>> DE NORMALISATION, CN = www.boutique.afnor.org verify return:1
>>>> ---
>>>> Certificate chain
>>>>  0 s:/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION FRANCAISE 
>>>> DE NORMALISATION/OU=ASSOCIATION FRANCAISE DE 
>>>> NORMALISATION/CN=www.boutique.afnor.org
>>>>    i:/C=US/O=Symantec Corporation/OU=Symantec Trust 
>>>> Network/CN=Symantec Class 3 Secure Server CA - G4 -----BEGIN
>>>> CERTIFICATE----- ../..
>>>> -----END CERTIFICATE-----
>>>>  1 s:/C=US/O=Symantec Corporation/OU=Symantec Trust 
>>>> Network/CN=Symantec Class 3 Secure Server CA - G4
>>>>    i:/C=US/O=VeriSign, Inc./OU=VeriSign Trust Network/OU=(c) 2006 
>>>> VeriSign, Inc. - For authorized use only/CN=VeriSign Class 3 Public 
>>>> Primary Certification Authority - G5 -----BEGIN CERTIFICATE----- ../..
>>>> -----END CERTIFICATE-----
>>>> ---
>>>> Server certificate
>>>> subject=/C=FR/ST=Seine Saint Denis/L=ST DENIS/O=ASSOCIATION 
>>>> FRANCAISE DE NORMALISATION/OU=ASSOCIATION FRANCAISE DE 
>>>> NORMALISATION/CN=www.boutique.afnor.org
>>>> issuer=/C=US/O=Symantec Corporation/OU=Symantec Trust 
>>>> Network/CN=Symantec Class 3 Secure Server CA - G4
>>>> ---
>>>> No client certificate CA names sent
>>>> ---
>>>> SSL handshake has read 3105 bytes and written 616 bytes
>>>> ---
>>>> New, TLSv1/SSLv3, Cipher is AES128-SHA Server public key is 2048 
>>>> bit Secure Renegotiation IS supported
>>>> Compression: NONE
>>>> Expansion: NONE
>>>> SSL-Session:
>>>>     Protocol  : TLSv1
>>>>     Cipher    : AES128-SHA
>>>>     Session-ID:
>>>> 833B0000A2346F50C5AAFC6B5188B4EBD9304CD25411BECFF0713F8D76C65D9D
>>>>     Session-ID-ctx:
>>>>     Master-Key:
>>>> D2DF6C62264D03D7D44AF44EB8C0B1B7AD0E650D34DF6EBEB1CBEBFE4F30CB9C6F5
>>>> 0
>>>> 8
>>>> 0
>>>> AA94F5
>>>> D6B5955DD8DF06608416
>>>>     Key-Arg   : None
>>>>     PSK identity: None
>>>>     PSK identity hint: None
>>>>     SRP username: None
>>>>     Start Time: 1493311275
>>>>     Timeout   : 300 (sec)
>>>>     Verify return code: 0 (ok)
>>>> ---
>>>> read:errno=0
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>> --
>>> Bugs to the Future
>>>
>> --
>> Bugs to the Future
>>
> --
> Bugs to the Future
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

--
Bugs to the Future



From squid3 at treenet.co.nz  Sat Apr 29 10:39:40 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 29 Apr 2017 22:39:40 +1200
Subject: [squid-users] Squid proxy without name resolution for internet
 adresses behind parent proxy
In-Reply-To: <1493376531696-4682229.post@n4.nabble.com>
References: <1493370033619-4682225.post@n4.nabble.com>
 <f6d4410e-32af-de08-b875-c4c34efd8f4a@gmail.com>
 <1493376531696-4682229.post@n4.nabble.com>
Message-ID: <f4bcea5d-8681-dbb4-3cd3-ffacf5adbfc6@treenet.co.nz>

On 28/04/17 22:48, mbaltruschat wrote:
> Hello,
>
> with by-itself i mean the squid-cache and/or the host-machine, neither of
> them is able to resolve internet hostnames, our dns is just internal. Only
> the parent proxy from the Network provider is able to resolve internet
> names. So i just want all my request beeing forwarwed without name
> resolution.

How are clients reaching this proxy? the relevance of DNS is directly 
impacted by that. Squid is a network service and DNS access is not 
optional for networked machines. Whether Squid needs that DNS to resolve 
public domains or not depends on the traffic arriving (how and what) and 
your exact configuration settings.


> If i didnt configure a nameserver i dont get any results in mgr:idns, if i
> configure it, i get many hits on rcode 0 attempt1 (which i dont understand
> since external names cant be resolved) and several "non-existent-Domain"

Success comes in both positive and negative forms. rcode-0 simply means 
no errors occured.

What do you mean exactly by "configure it" ?

Details are required if you want any useful help. The topic you are 
asking about is rather complex.


Amos



From marcel at baltruschat.net  Sat Apr 29 20:07:30 2017
From: marcel at baltruschat.net (mbaltruschat)
Date: Sat, 29 Apr 2017 13:07:30 -0700 (PDT)
Subject: [squid-users] Squid proxy without name resolution for internet
 adresses behind parent proxy
In-Reply-To: <f4bcea5d-8681-dbb4-3cd3-ffacf5adbfc6@treenet.co.nz>
References: <1493370033619-4682225.post@n4.nabble.com>
 <f6d4410e-32af-de08-b875-c4c34efd8f4a@gmail.com>
 <1493376531696-4682229.post@n4.nabble.com>
 <f4bcea5d-8681-dbb4-3cd3-ffacf5adbfc6@treenet.co.nz>
Message-ID: <1493496450559-4682235.post@n4.nabble.com>

Hello Amos,

many thanks for your reply, to your first question, here are some details
about our network structure and how the clients connect to the proxy:

We have a corporate network, which has a firewall to the internet, which we
use as parent proxy for our own proxy servers.
The DNS Servers in the corporate network dont resolve public adresses, and
there is no routing to public adresses, the only way to access the internet
is by the corporate firewall.

At each bigger location weve got a squid proxy, at the moment Versions from
2.6 to 2.7 in different releases, running on Windows 2003 and 2008R2
Servers.
These squids are configured with no dns Server entries, the underlying
Windows machines of these proxys are configured with our corporate AD-DNS
Servers.

The clients (Windows 7 and 10) are getting their proxy settings for Internet
Explorer and Firefox by GPO. These settings are the aliasname for the proxy
and the port, which is 8080, and some proxy exclusions for corporate
applications servers. The clients are members in an AD Domain and get there
DNS Server entries by DHCP. The clients can successfully resolve the aliases
and hostnames of the proxys to their ip-adresses an can communicate with
them.
These proxys, lets call them "old proxys" are working fine.

To get rid of Server 2003 and squid 2.6/2.7, i installed a Ubuntu 16.04.2
LTS and Squid3.5, an rewrote the config from one of the old proxys,
and basically, the proxy was functional, but all request are very, very,
slow, like the proxy waits for some timeout at each request.

To your second question, i am from germany, sorry, with "configure it" or
"configure it not" i meant that i configured squid to use a dns server in
the conf or not, and in the case of the operating system, had set a dns
server to use, or not, in the network config of ubuntu.

If you need further infos please ask, i am also preparing my configs (old /
new) to post them here, but i have to anonymize them before posting, i think
i can handle this until tomorrow.

Best Regards
Marcel







--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-proxy-without-name-resolution-for-internet-adresses-behind-parent-proxy-tp4682225p4682235.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From thesnable at gmail.com  Sun Apr 30 05:59:34 2017
From: thesnable at gmail.com (snable snable)
Date: Sun, 30 Apr 2017 07:59:34 +0200
Subject: [squid-users] squid 4.0.19 bin question
In-Reply-To: <CADYcWGTuy8wK+USs_+aJrJ5XtiH-TuU2h3GDAHoKCkOQXiNY9w@mail.gmail.com>
References: <CADYcWGQD+kksRdP6wCEnJcZCLAyUaLToMEDpHNcm-pQEPtgWHw@mail.gmail.com>
 <CADYcWGTRYMCP-4ZdZZmxfnJpY6si0WAYn3udNtwW9DG=QPOnmg@mail.gmail.com>
 <CADYcWGTuy8wK+USs_+aJrJ5XtiH-TuU2h3GDAHoKCkOQXiNY9w@mail.gmail.com>
Message-ID: <CADYcWGTsYW+5fF9aW6_zQMgCYo39tC096Ua+7Z7Tf5uQXppirw@mail.gmail.com>

hallo,

I see the the following works for my site

ssl_bump server-first mysite_acl

whether
ssl_bump bump mysite_acl
gives me a corrupted site.

any idea? i see that server-first shouldnt be used for squid4. why?

how can i fix it?

ty
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170430/ccbfda03/attachment.htm>

From thesnable at gmail.com  Sun Apr 30 06:02:38 2017
From: thesnable at gmail.com (snable snable)
Date: Sun, 30 Apr 2017 08:02:38 +0200
Subject: [squid-users] squid 4.0.19 error with certificates
In-Reply-To: <CADYcWGQdGf_ftnD1MpVY=D_4w=-MiP4Xa6ZqZcqNEM3cKqNULA@mail.gmail.com>
References: <CADYcWGTAiKcNR=nO4aCCNXw+8w2Jf4Eng_q4qdTTHo=uTUYdMw@mail.gmail.com>
 <CADYcWGRLK+KKWsxuOZ_22hFpr0hwEF-phGu7f0LVLYnV+S1D8w@mail.gmail.com>
 <CADYcWGQdGf_ftnD1MpVY=D_4w=-MiP4Xa6ZqZcqNEM3cKqNULA@mail.gmail.com>
Message-ID: <CADYcWGR1ntWdqG9vvuDHCO30Pu02MW+TY2rRU=Xu5VpvM2aQ1w@mail.gmail.com>

hello

i am using squid on a external box.
i forward all traffic from my openwrt router to it
htto works fine
https with youtube app doesnt work
i get:

 Error negotiating SSL connection on FD 73: error:14094416
:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

errors

other sites work well so far

i heard that squid4 auto downloads intermediate certificates.. maybe thats
the issue?

i workarounded this with a white list of sites that work. but i wanna
rollout this for all sites. (also see my other question)

thanks!
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170430/7e955ebf/attachment.htm>

From eliezer at ngtech.co.il  Sun Apr 30 06:50:42 2017
From: eliezer at ngtech.co.il (Eliezer  Croitoru)
Date: Sun, 30 Apr 2017 09:50:42 +0300
Subject: [squid-users] Squid proxy without name resolution for internet
	adresses behind parent proxy
In-Reply-To: <1493496450559-4682235.post@n4.nabble.com>
References: <1493370033619-4682225.post@n4.nabble.com>
 <f6d4410e-32af-de08-b875-c4c34efd8f4a@gmail.com>
 <1493376531696-4682229.post@n4.nabble.com>
 <f4bcea5d-8681-dbb4-3cd3-ffacf5adbfc6@treenet.co.nz>
 <1493496450559-4682235.post@n4.nabble.com>
Message-ID: <00e201d2c17e$16067e10$42137a30$@ngtech.co.il>

Can you try to add the next to your squid.conf:
dns_v4_first on

and see if it helps?

Eliezer

* http://www.squid-cache.org/Doc/config/dns_v4_first/

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of mbaltruschat
Sent: Saturday, April 29, 2017 11:08 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid proxy without name resolution for internet adresses behind parent proxy

Hello Amos,

many thanks for your reply, to your first question, here are some details
about our network structure and how the clients connect to the proxy:

We have a corporate network, which has a firewall to the internet, which we
use as parent proxy for our own proxy servers.
The DNS Servers in the corporate network dont resolve public adresses, and
there is no routing to public adresses, the only way to access the internet
is by the corporate firewall.

At each bigger location weve got a squid proxy, at the moment Versions from
2.6 to 2.7 in different releases, running on Windows 2003 and 2008R2
Servers.
These squids are configured with no dns Server entries, the underlying
Windows machines of these proxys are configured with our corporate AD-DNS
Servers.

The clients (Windows 7 and 10) are getting their proxy settings for Internet
Explorer and Firefox by GPO. These settings are the aliasname for the proxy
and the port, which is 8080, and some proxy exclusions for corporate
applications servers. The clients are members in an AD Domain and get there
DNS Server entries by DHCP. The clients can successfully resolve the aliases
and hostnames of the proxys to their ip-adresses an can communicate with
them.
These proxys, lets call them "old proxys" are working fine.

To get rid of Server 2003 and squid 2.6/2.7, i installed a Ubuntu 16.04.2
LTS and Squid3.5, an rewrote the config from one of the old proxys,
and basically, the proxy was functional, but all request are very, very,
slow, like the proxy waits for some timeout at each request.

To your second question, i am from germany, sorry, with "configure it" or
"configure it not" i meant that i configured squid to use a dns server in
the conf or not, and in the case of the operating system, had set a dns
server to use, or not, in the network config of ubuntu.

If you need further infos please ask, i am also preparing my configs (old /
new) to post them here, but i have to anonymize them before posting, i think
i can handle this until tomorrow.

Best Regards
Marcel







--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-proxy-without-name-resolution-for-internet-adresses-behind-parent-proxy-tp4682225p4682235.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From marcel at baltruschat.net  Sun Apr 30 11:58:00 2017
From: marcel at baltruschat.net (mbaltruschat)
Date: Sun, 30 Apr 2017 04:58:00 -0700 (PDT)
Subject: [squid-users] Squid proxy without name resolution for internet
 adresses behind parent proxy
In-Reply-To: <f4bcea5d-8681-dbb4-3cd3-ffacf5adbfc6@treenet.co.nz>
References: <1493370033619-4682225.post@n4.nabble.com>
 <f6d4410e-32af-de08-b875-c4c34efd8f4a@gmail.com>
 <1493376531696-4682229.post@n4.nabble.com>
 <f4bcea5d-8681-dbb4-3cd3-ffacf5adbfc6@treenet.co.nz>
Message-ID: <1493553480333-4682239.post@n4.nabble.com>

Hello Amos,

thats the configuration of the new squid. As i said, its anonymized, so the
hostnames maybe are a bit
"strange".

Maybe a few words to the parent proxys:

192.168.1.1 and 192.168.2.1 are the ips of the Firewall, second one is a
backup ip

192.168.3.1 and 192.168.4.1 are parent Proxys for accessing apps inside the
corporate Network
which cannot be accessed "DIRECT", only by internal proxy

Regards
Marcel

---------------------------
http_port 8080
icp_port 0
check_hostnames off
ssl_unclean_shutdown on
dns_nameservers 192.168.50.2
cache_mgr support at dept3.corporate.net

error_directory /usr/local/squid/share/errors/de-de
logfile_rotate 7

# Logb?cher einschalten
cache_access_log /var/log/squid/access.log
cache_log /var/log/squid/cache.log
cache_store_log /var/log/squid/store.log

acl SSL_ports port 443
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
acl CONNECT method CONNECT
acl Bastion dstdomain 192.168.1.1
### 2014-03-20 ###
acl Bastion dstdomain 192.168.2.1
acl APPONE dstdomain app1.publicwebsite.de
acl APPONE dstdomain APP2.publicwebsite.de
acl APPONE dstdomain www.publicwebsite.de
acl DEPT2 dstdomain www.dept2.corporate.net # Intranet DEPT2
###
### 2015-11-05 ###
acl APPTWOPROXY dstdomain 192.168.3.1
acl APPTWO dstdomain 192.168.100.3 # Verbindungen in die Firewall zum
APPTWO-Server  - Developement
acl APPTWO dstdomain 192.168.100.4 # Verbindungen in die Firewall zum
APPTWO-Server  - Testing
acl APPTWO dstdomain 192.168.100.5 # Verbindungen in die Firewall zum
APPTWO-Server  - Produtcion
acl APPTWO dstdomain APPTWOent.corporate.net # Verbindungen in die Firewall
zum APPTWO-Server  - Development
acl APPTWO dstdomain APPTWOqas.corporate.net # Verbindungen in die Firewall
zum APPTWO-Server  - Testing
acl APPTWO dstdomain APPTWOdbp1.corporate.net # Verbindungen in die Firewall
zum APPTWO-Server  - Production
##################
acl CORP dstdomain .corporate.net
acl empfang src 192.168.4.55
acl local src 192.168.50.0/23

#Test f?r WSUS Range Header Problem  mit Windows 10 Upgrades
acl windowsupdate dstdomain windowsupdate.microsoft.com
acl windowsupdate dstdomain .update.microsoft.com
acl windowsupdate dstdomain download.windowsupdate.com
acl windowsupdate dstdomain redir.metaservices.microsoft.com
acl windowsupdate dstdomain images.metaservices.microsoft.com
acl windowsupdate dstdomain c.microsoft.com
acl windowsupdate dstdomain www.download.windowsupdate.com
acl windowsupdate dstdomain wustat.windows.com
acl windowsupdate dstdomain crl.microsoft.com
acl windowsupdate dstdomain sls.microsoft.com
acl windowsupdate dstdomain productactivation.one.microsoft.com
acl windowsupdate dstdomain ntservicepack.microsoft.com

#for proxychain test
#cache_peer 192.168.50.19 parent 8080 7 proxy-only no-query no-digest
Default

### 2014-03-20 ###
cache_peer 192.168.1.1 parent 80 7 proxy-only no-query no-digest Default
cache_peer 192.168.2.1 parent 80 7 proxy-only no-query no-digest
cache_peer 192.168.3.1 parent 80 7 proxy-only no-query no-digest
cache_peer 192.168.4.1 parent 3128 7 proxy-only no-query no-digest


cache_peer_domain 192.168.1.1 !CORP
cache_peer_domain 192.168.2.1 !CORP
cache_peer_domain 192.168.3.1 APPTWO !CORP
cache_peer_domain 192.168.2.1 www.app1.publicwebsite2.de
cache_peer_domain 192.168.2.1 app1.publicwebsite.de
cache_peer_domain 192.168.2.1 APP1.publicwebsite.de
cache_peer_domain 192.168.2.1 www.publicwebsite.de
cache_peer_domain 192.168.4.1 www.min.mk.corporate.net
cache_peer_domain 192.168.3.1 APPTWOent.APPTWO.corporate.net
cache_peer_domain 192.168.3.1 APPTWOqas.APPTWO.corporate.net
cache_peer_domain 192.168.3.1 APPTWOdbp1.APPTWO.corporate.net
cache_peer_domain 192.168.3.1 192.168.100.3
cache_peer_domain 192.168.3.1 192.168.100.4
cache_peer_domain 192.168.3.1 192.168.100.5


cache_peer_access 192.168.1.1 allow !CORP !APP1 !APPTWO
cache_peer_access 192.168.2.1 allow APP1 !CORP !APPTWO
cache_peer_access 192.168.4.1 allow DEPT2 !CORP !APPTWO
cache_peer_access 192.168.3.1 allow APPTWO

##################
http_access deny empfang
http_access allow manager localhost
http_access deny manager
http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow CORP
http_access allow Bastion
http_access allow APP1
http_access allow DEPT2

### 2015-11-05 ###
http_access allow APPTWOPROXY
http_access allow APPTWO
http_access allow all


#Test f?r WSUS Range Header Problem mit Windows 10 Upgrades
range_offset_limit 200 MB windowsupdate
maximum_object_size 2048 MB
quick_abort_min -1


always_direct allow CORP
always_direct allow APPTWOPROXY
never_direct allow APP1
never_direct allow DEPT2
never_direct allow APPTWO
never_direct allow !CORP




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-proxy-without-name-resolution-for-internet-adresses-behind-parent-proxy-tp4682225p4682239.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sun Apr 30 13:34:15 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 30 Apr 2017 19:34:15 +0600
Subject: [squid-users] squid 4.0.19 bin question
In-Reply-To: <CADYcWGTsYW+5fF9aW6_zQMgCYo39tC096Ua+7Z7Tf5uQXppirw@mail.gmail.com>
References: <CADYcWGQD+kksRdP6wCEnJcZCLAyUaLToMEDpHNcm-pQEPtgWHw@mail.gmail.com>
 <CADYcWGTRYMCP-4ZdZZmxfnJpY6si0WAYn3udNtwW9DG=QPOnmg@mail.gmail.com>
 <CADYcWGTuy8wK+USs_+aJrJ5XtiH-TuU2h3GDAHoKCkOQXiNY9w@mail.gmail.com>
 <CADYcWGTsYW+5fF9aW6_zQMgCYo39tC096Ua+7Z7Tf5uQXppirw@mail.gmail.com>
Message-ID: <6b7d626a-1201-b9aa-6e9e-18accbde1214@gmail.com>



30.04.2017 11:59, snable snable ?????:
> hallo,
>
> I see the the following works for my site
>
> ssl_bump server-first mysite_acl
>
> whether 
> ssl_bump bump mysite_acl 
> gives me a corrupted site.
Details. "Corrupted site" is about nothing.
>
> any idea? i see that server-first shouldnt be used for squid4. why?
Idea for what? If you read squid.conf.documented, you know, why. BTW,
"server-first" is obsolete till 3.5.x and remains only for backward
compatibility.
>
> how can i fix it?
Fix what?
>
> ty
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170430/625d4ba4/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170430/625d4ba4/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170430/625d4ba4/attachment.sig>

From yvoinov at gmail.com  Sun Apr 30 13:35:04 2017
From: yvoinov at gmail.com (Yuri Voinov)
Date: Sun, 30 Apr 2017 19:35:04 +0600
Subject: [squid-users] squid 4.0.19 error with certificates
In-Reply-To: <CADYcWGR1ntWdqG9vvuDHCO30Pu02MW+TY2rRU=Xu5VpvM2aQ1w@mail.gmail.com>
References: <CADYcWGTAiKcNR=nO4aCCNXw+8w2Jf4Eng_q4qdTTHo=uTUYdMw@mail.gmail.com>
 <CADYcWGRLK+KKWsxuOZ_22hFpr0hwEF-phGu7f0LVLYnV+S1D8w@mail.gmail.com>
 <CADYcWGQdGf_ftnD1MpVY=D_4w=-MiP4Xa6ZqZcqNEM3cKqNULA@mail.gmail.com>
 <CADYcWGR1ntWdqG9vvuDHCO30Pu02MW+TY2rRU=Xu5VpvM2aQ1w@mail.gmail.com>
Message-ID: <c28c97e5-d2b7-fbb4-a42e-91c1eb21c72d@gmail.com>

Check this. It seems this is the issue:

http://bugs.squid-cache.org/show_bug.cgi?id=4711


30.04.2017 12:02, snable snable ?????:
> hello
>
> i am using squid on a external box.
> i forward all traffic from my openwrt router to it
> htto works fine
> https with youtube app doesnt work
> i get:
>
>  Error negotiating SSL connection on FD 73: error:14094416
> :SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
>
> errors
>
> other sites work well so far
>
> i heard that squid4 auto downloads intermediate certificates.. maybe
> thats the issue?
>
> i workarounded this with a white list of sites that work. but i wanna
> rollout this for all sites. (also see my other question)
>
> thanks!
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Bugs to the Future
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170430/be9c506f/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 0x613DEC46.asc
Type: application/pgp-keys
Size: 2437 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170430/be9c506f/attachment.key>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170430/be9c506f/attachment.sig>

