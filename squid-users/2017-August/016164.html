<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] Content Adaptation with HTTPs
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20Content%20Adaptation%20with%20HTTPs&In-Reply-To=%3C87bfe45a-e492-e321-17aa-959611ccdefd%40leviacomm.net%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="016160.html">
   <LINK REL="Next"  HREF="016172.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] Content Adaptation with HTTPs</H1>
    <B>Christopher Ahrens</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20Content%20Adaptation%20with%20HTTPs&In-Reply-To=%3C87bfe45a-e492-e321-17aa-959611ccdefd%40leviacomm.net%3E"
       TITLE="[squid-users] Content Adaptation with HTTPs">christopher at leviacomm.net
       </A><BR>
    <I>Sun Aug 20 20:06:27 UTC 2017</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="016160.html">[squid-users] Content Adaptation with HTTPs
</A></li>
        <LI>Next message (by thread): <A HREF="016172.html">[squid-users] Content Adaptation with HTTPs
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#16164">[ date ]</a>
              <a href="thread.html#16164">[ thread ]</a>
              <a href="subject.html#16164">[ subject ]</a>
              <a href="author.html#16164">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>Amos Jeffries wrote:
&gt;<i> On 20/08/17 16:05, Christopher Ahrens wrote:
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> The current solution doesn't work for me since it only supports a very
</I>&gt;&gt;<i> limited number of clients.  I am working with a charity that provides
</I>&gt;&gt;<i> internet services to those with impaired vision, the intention of my
</I>&gt;&gt;<i> project was to set up a semi-public proxy for recipient of the charity
</I>&gt;&gt;<i> (EG, we would install DD-WRT like routers within their homes that
</I>&gt;&gt;<i> would create a tunnel into our network so that they could browse the
</I>&gt;&gt;<i> internet using off-the-shelf systems.  We recently received a large
</I>&gt;&gt;<i> number of tablets form a corporate donor, the tablets themselves will
</I>&gt;&gt;<i> work for our recipients, but unfortunately the internet at large does
</I>&gt;&gt;<i> not.
</I>&gt;<i>
</I>&gt;<i> FYI: If you can get the adaptation part to be small enough a non-caching
</I>&gt;<i> Squid should be able to run on those WRT-like devices with under 32 MB
</I>&gt;<i> of RAM needed. So the tunnel may not be necessary, just a way to update
</I>&gt;<i> the software and its config.
</I>
Part of it is to pre-shrink the size of the pages to prevent saturating 
the tunnel.  A lot of our recipients have low-cost internet connections 
(Usually between 1-5 Mbps).  From my personal experiences, the 
transformation are probably cutting about 75%-80% of excess garbage from 
website.

We're also looking at possibly building tiny x86 or ARM-based boxes that 
can be deployed to their homes to do caching to further reduce the load 
on their internet connections.  The biggest complaint we have is why it 
takes so long to load pictures and words especially since a lot of the 
pictures are the same page-to-page (I am having a very hard time arguing 
with them...)

We can get a lot of hardware from local companies, but not so much in 
the way of software or services

&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> We've looked into commercial systems in the past, but we cannot afford
</I>&gt;&gt;<i> the cost of commercial systems, especially since we are unsure about
</I>&gt;&gt;<i> the exact licensing that would be needed for our endeavor.  We have
</I>&gt;&gt;<i> also been burnt in the past with commercial software where the project
</I>&gt;&gt;<i> either goes dead, begins to require insanely expensive appliances, or
</I>&gt;&gt;<i> the license price is sent sky-high.
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> Would it be possible to use a setup of Squid &lt;-&gt; Privoxy &lt;-&gt; Squid to
</I>&gt;&gt;<i> execute this?  I figure we'd build an internal instance that will
</I>&gt;&gt;<i> handle the client&lt;-&gt;proxy part, Privoxy handles the content
</I>&gt;&gt;<i> modification, then a second Squid instance to handle the web
</I>&gt;&gt;<i> server&lt;-&gt;proxy part.
</I>&gt;<i>
</I>&gt;<i> Squid will only send SSL-Bump'ed HTTPS traffic over encrypted
</I>&gt;<i> connections. So that is only possible if privoxy accepts TLS connections
</I>&gt;<i> from Squid. In which case you probably do not need the second Squid, as
</I>&gt;<i> privoxy would also be doing the HTTPS to-server part easily enough itself.
</I>&gt;<i>
</I>
Unfortunately Privoxy doesn't do HTTPs.  We looked into using it, but it 
can only do domain blocking for HTTPs, not content manipulation.


&gt;<i>
</I>&gt;&gt;<i>
</I>&gt;&gt;<i> SO it looks like the solution would be to find a developer to write an
</I>&gt;&gt;<i> ECAP to cycle through regexes to replace/remove HTML/CSS content.  So
</I>&gt;&gt;<i> time to dig out my old C++ books and get to work...
</I>&gt;<i>
</I>&gt;<i> If the existing ICAP/eCAP options are not suitable, then yes a custom
</I>&gt;<i> one would be needed.
</I>&gt;<i>
</I>&gt;<i> It is not as easy as a few regex replacements though. Adaptors are
</I>&gt;<i> streamed the full on-wire HTTP message format with only minor
</I>&gt;<i> sanitization by Squids parser. To alter the content you will have to
</I>&gt;<i> deal with data encodings, object ranges, partially received objects. And
</I>&gt;<i> it is best to assume everything is of infinite length unless explicitly
</I>&gt;<i> told otherwise - so no buffer-then-adapt code.
</I>&gt;<i>  eCAP is simpler than ICAP, but still has to deal with these HTTP features.
</I>&gt;<i>
</I>&gt;<i> Those are a big part of why available software is so sparse. The other
</I>&gt;<i> part being that HTTP traffic payloads are copyright content, so there
</I>&gt;<i> are legal issues with selling software for the purpose of altering
</I>&gt;<i> copyright content sans authors permission.
</I>&gt;<i>
</I>
Yeah, I was a bit afraid that would be the case.  I was planning on 
seeing how GreaseMonkey and ABP handle data streams since they seem to 
be able to handle streaming media.  Or dig into Privoxy to see how 
things are done in there. Might find it to be easier to adapt it as an 
ICAP/ECAP by changing its input / output functions to be ICAP/ECAP 
interface rather than TCP.

For now, I'm thinking that I'll just let HTTPS pass through without 
modification and let Privoxy handle http.  Seems to be the easiest way 
to do things.

&gt;<i> Amos
</I>&gt;<i> _______________________________________________
</I>&gt;<i> squid-users mailing list
</I>&gt;<i> <A HREF="https://lists.squid-cache.org/listinfo/squid-users">squid-users at lists.squid-cache.org</A>
</I>&gt;<i> <A HREF="http://lists.squid-cache.org/listinfo/squid-users">http://lists.squid-cache.org/listinfo/squid-users</A>
</I>

</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="016160.html">[squid-users] Content Adaptation with HTTPs
</A></li>
	<LI>Next message (by thread): <A HREF="016172.html">[squid-users] Content Adaptation with HTTPs
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#16164">[ date ]</a>
              <a href="thread.html#16164">[ thread ]</a>
              <a href="subject.html#16164">[ subject ]</a>
              <a href="author.html#16164">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
