From squid3 at treenet.co.nz  Fri Dec  1 07:16:55 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 1 Dec 2017 20:16:55 +1300
Subject: [squid-users] squid - kid registration timed out
In-Reply-To: <1512066741917-0.post@n4.nabble.com>
References: <1512066741917-0.post@n4.nabble.com>
Message-ID: <d3d37cfc-1b12-e083-a7b6-37fa6015330f@treenet.co.nz>

On 01/12/17 07:32, carlos wrote:
> Hi all,
> 
> I m new to squid and i m installing it i na RHEL 7.4, squid version 3.5.20.
> 
> I have a setup with 3 squid instances listening in 3 diferent ports (but
> other than they are basically the same), each instance have 4 workers.
> 

By "basically the same" I hope you have accounted for all the directives 
mentioned in <https://wiki.squid-cache.org/MultipleInstances> which have 
mandatory differences.


> The problem is when i restart the squid ou after some random time i get :
> 
> in cache log:
> FATAL: kid3 registration timed out
> Squid Cache (Version 3.5.20): Terminated abnormally.
> CPU Usage: 0.030 seconds = 0.020 user + 0.010 sys
> Maximum Resident Size: 67648 KB
> Page faults with physical i/o: 0
> 
> in messages log:
>   (squid-3): kid3 registration timed out

The worker is taking too long to startup. Something you have configured 
(or not configured correctly) is making the process too long for the SMP 
coordinator to cope with.

Amos


From fredbmail at free.fr  Fri Dec  1 09:32:28 2017
From: fredbmail at free.fr (FredB)
Date: Fri, 1 Dec 2017 10:32:28 +0100 (CET)
Subject: [squid-users] filtering HTTPS sites with transparent child Squid
In-Reply-To: <21809ecd-81f6-9765-a2c6-79a347f3a394@treenet.co.nz>
Message-ID: <1706791862.681835895.1512120748432.JavaMail.root@zimbra4-e1>


> > 
> > I?ve set up a Squid as a transparent child-proxy. Every request is
> > redirected to another Squid with the content filtering add-on
> > e2guardian. I encounter the problem that the transparent child
> > Squid
> > only forwards IP-Addresses to the e2guardian when HTTPS is used and
> > so
> > e2guardian cant filter anything because it can only filter by URL.
> > 
> 


In your case enable SSLMITM in e2guardian


> A good demonstration of why calling a URL-rewrite helper a "content
> filter" is completely wrong.


Actually E2guardian is also a proxy, proxy chaining mode   


> 
> Real content filters receive the actual content and can filter it.
> ICAP
> and eCAP exist for that and get passed the decrypted HTTPS messages
> (if
> any).
> 

Next version, soon, very soon :)

Fred


From erdosain9 at gmail.com  Fri Dec  1 16:34:06 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Fri, 1 Dec 2017 09:34:06 -0700 (MST)
Subject: [squid-users] Error page or redirect just to a user
Message-ID: <1512146046765-0.post@n4.nabble.com>

Hi.
I want to do a redirect to a user. 
For example if the user want to go to google, i redirect to some particular
web.
Can you tell me how??

i have config the http access trough user (with kerberos).

Thanks to all



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From jlay at slave-tothe-box.net  Fri Dec  1 18:05:14 2017
From: jlay at slave-tothe-box.net (James Lay)
Date: Fri, 01 Dec 2017 11:05:14 -0700
Subject: [squid-users] Working peek/splice no longer functioning on some
 sites
In-Reply-To: <7e3e81c9-0949-9f16-f1f8-7efc052dae78@treenet.co.nz>
References: <1511551841.2392.5.camel@slave-tothe-box.net>
 <2ea83011-92bc-f134-e662-2f1fd34fce89@treenet.co.nz>
 <1511610749.2338.1.camel@slave-tothe-box.net>
 <57c8c167-dfae-6579-8f75-c65ae3160c0e@treenet.co.nz>
 <1511613959.2338.6.camel@slave-tothe-box.net>
 <CABMULtJZUh+i+QSNOYP6tPhS6Y57d+WVQPidCMyNQ7b6GR-UzQ@mail.gmail.com>
 <1511794211.2147.4.camel@slave-tothe-box.net>
 <7e3e81c9-0949-9f16-f1f8-7efc052dae78@treenet.co.nz>
Message-ID: <7512b52427c65ed6a0364885bc359d48@localhost>

On 2017-11-29 07:29, Amos Jeffries wrote:
> On 28/11/17 03:50, James Lay wrote:
>> On Sun, 2017-11-26 at 09:50 +0200, Alex K wrote:
>>> Perhaps an alternative is to peek only on step1:
>>> 
>>> acl step1 at_step SslBump1
>>> 
>>> ssl_bump peek step1
>>> acl allowed_https_sites ssl::server_name_regex 
>>> "/opt/etc/squid/http_url.txt"
>>> ssl_bump splice allowed_https_sites
>>> ssl_bump terminate all
>> 
>> Hrmm...wouldn't that negate the ability to read the cert on step2?
>> 
> 
> Yes it would.
> 
>> In layman's terms I'm thinking:
>> "peek at step1"
>> "splice acl allow matched sni's"
>> "peek at step2"
>> "splice acl allow'd matched certs"
>> "terminate the rest"
>> 
>> Would that work Amos?
>> 
> 
> This is essentially what I suggested at the beginning.
> 
> Placing splice action and your ACLs on the first ssl_bump line ensures
> that at each step if enough details are known to splice it will
> happen.
> 
> The second line being "peek all" make peek happen at every step for
> which it is possible (step 1 and step 2 - not step 3).
> 
> "terminate all" being last makes it happen for "all the rest", aka
> step 3 if Squid gets that far without splicing.
> 
> 
> The only difference is that my suggested way would also allow splicing
> the CONNECT if it happens to be presented with a host name in the
> authority-URI. Which cannot happen on your proxy unless your port 3128
> happens to be intercepting traffic between clients and another proxy.

Ah...ok so this is my lack of understanding then of peek/splice.  Sounds 
like this is what I can try:

ssl_bump splice all
acl allowed_https_sites ssl::server_name_regex 
"/opt/etc/squid/http_url.txt"
ssl_bump splice allowed_https_sites
ssl_bump terminate all

Is that what you're meaning Amos?  Thanks again.

James

> 
> 
> BTW please do not use port 3128 for intercept. It is officially
> registered for HTTP proxy traffic and so qualifies as "well known".
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From ahmed.zaeem at netstream.ps  Sun Dec  3 09:00:44 2017
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Sun, 3 Dec 2017 11:00:44 +0200
Subject: [squid-users] change action of squid -v  on squid
Message-ID: <CF5ADB26-2D5E-47BA-B0B0-9EE2B85ADBDD@netstream.ps>

Hello folks 

i just need to change the action of squid 

if i do squid -v it shoes squid version
how about if i want to disable that thing and don?t show the compile options ?

how about if i put other message to be shown ?


cheers 

From robertkwild at gmail.com  Sun Dec  3 18:50:55 2017
From: robertkwild at gmail.com (robert k Wild)
Date: Sun, 3 Dec 2017 18:50:55 +0000
Subject: [squid-users] installing squidClamAV - check if blocking viruses
Message-ID: <CAGU_Ci+rQZ0vpKSoOxi705=Kngah43HZe8p+kd_VFrH9yy4HyQ@mail.gmail.com>

hi all,

i have installed squidclamav via this guide -

http://squidclamav.darold.net/installv6.html

i only installed the below, i didnt install squidGuard

yum install -y squid clamav

and i extrated these tars and for each i did configure/make/make install
like the guide says to do

https://sourceforge.net/projects/squidclamav/files/latest/download

http://sourceforge.net/projects/c-icap/files/c-icap/0.5.x/c_icap-0.5.2.tar.gz/download

i dont know what squid config files to copy/paste in my squid.conf file

do i use 3.4.x
3.1.x
3.0.x

bear in mind when i did the yum install squid, it installed 3.5.20

once installed, i test it, in my browser i change to manual proxy and
change ip/port to my proxy server

when i go to websites all works and i can see the logs here -

watch -n 0.5 tail /usr/local/c-icap/var/log/server.log

but how do i check if its blocking viruses?

many thanks in advanced

rob

-- 
Regards,

Robert K Wild.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171203/4a4342fc/attachment.htm>

From Antony.Stone at squid.open.source.it  Sun Dec  3 19:09:54 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sun, 3 Dec 2017 20:09:54 +0100
Subject: [squid-users] installing squidClamAV - check if blocking viruses
In-Reply-To: <CAGU_Ci+rQZ0vpKSoOxi705=Kngah43HZe8p+kd_VFrH9yy4HyQ@mail.gmail.com>
References: <CAGU_Ci+rQZ0vpKSoOxi705=Kngah43HZe8p+kd_VFrH9yy4HyQ@mail.gmail.com>
Message-ID: <201712032009.54507.Antony.Stone@squid.open.source.it>

On Sunday 03 December 2017 at 19:50:55, robert k Wild wrote:

> how do i check if its blocking viruses?

Try downloading something containing the EICAR test file.

http://www.eicar.org/86-0-Intended-use.html

That page itself contains the EICAR string, so in principle it should trigger 
ClamAV, however strictly speaking the string should be the start of the "file", 
therefore you may find one of http://www.eicar.org/85-0-Download.html a better 
way of testing.


Antony.

-- 
If you were ploughing a field, which would you rather use - two strong oxen or 
1024 chickens?

 - Seymour Cray, pioneer of supercomputing

                                                   Please reply to the list;
                                                         please *don't* CC me.


From rousskov at measurement-factory.com  Sun Dec  3 20:11:20 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Sun, 3 Dec 2017 13:11:20 -0700
Subject: [squid-users] change action of squid -v on squid
In-Reply-To: <CF5ADB26-2D5E-47BA-B0B0-9EE2B85ADBDD@netstream.ps>
References: <CF5ADB26-2D5E-47BA-B0B0-9EE2B85ADBDD@netstream.ps>
Message-ID: <23bc704c-a59a-9701-d380-21c24968a73b@measurement-factory.com>

On 12/03/2017 02:00 AM, --Ahmad-- wrote:

> if i do squid -v it shoes squid version
> how about if i want to disable that thing and don?t show the compile options ?

For that, you need to

* either modify Squid source code (the details are outside of the
squid-users discussion scope but you may be able to get help on squid-dev)

* or wrap Squid executable into your own wrapper script/program (a
simple sysadmin action not specific to Squid).

FWIW, it is usually pointless to hide squid-v info. Consider double
checking your requirements.


> how about if i put other message to be shown ?

Use --enable-build-info option with Squid ./configure script:


>   --enable-build-info="build info string"
>                           Add an additional string in the output of "squid
>                           -v". Default is not to add anything. If the string
>                           is not specified, tries to determine nick and
>                           revision number of the current bazaar branch

FWIW, using --enable-build-info is the right way to add custom
information to squid-v output.


HTH,

Alex.


From squid3 at treenet.co.nz  Sun Dec  3 21:16:46 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 4 Dec 2017 10:16:46 +1300
Subject: [squid-users] Error page or redirect just to a user
In-Reply-To: <1512146046765-0.post@n4.nabble.com>
References: <1512146046765-0.post@n4.nabble.com>
Message-ID: <226136c8-43cb-dbe9-04bb-d5a597499047@treenet.co.nz>

On 02/12/17 05:34, erdosain9 wrote:
> Hi.
> I want to do a redirect to a user.
> For example if the user want to go to google, i redirect to some particular
> web.
> Can you tell me how??
> 


   acl bob proxy_auth Bob
   deny_info 302:http://example.com/ bob
   http_access deny bob


Amos


From squid3 at treenet.co.nz  Sun Dec  3 21:18:18 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 4 Dec 2017 10:18:18 +1300
Subject: [squid-users] Working peek/splice no longer functioning on some
 sites
In-Reply-To: <7512b52427c65ed6a0364885bc359d48@localhost>
References: <1511551841.2392.5.camel@slave-tothe-box.net>
 <2ea83011-92bc-f134-e662-2f1fd34fce89@treenet.co.nz>
 <1511610749.2338.1.camel@slave-tothe-box.net>
 <57c8c167-dfae-6579-8f75-c65ae3160c0e@treenet.co.nz>
 <1511613959.2338.6.camel@slave-tothe-box.net>
 <CABMULtJZUh+i+QSNOYP6tPhS6Y57d+WVQPidCMyNQ7b6GR-UzQ@mail.gmail.com>
 <1511794211.2147.4.camel@slave-tothe-box.net>
 <7e3e81c9-0949-9f16-f1f8-7efc052dae78@treenet.co.nz>
 <7512b52427c65ed6a0364885bc359d48@localhost>
Message-ID: <fc698c26-ea16-2a0c-f83b-e4b1609f0aaa@treenet.co.nz>

On 02/12/17 07:05, James Lay wrote:
> On 2017-11-29 07:29, Amos Jeffries wrote:
>> On 28/11/17 03:50, James Lay wrote:
>>> On Sun, 2017-11-26 at 09:50 +0200, Alex K wrote:
>>>> Perhaps an alternative is to peek only on step1:
>>>>
>>>> acl step1 at_step SslBump1
>>>>
>>>> ssl_bump peek step1
>>>> acl allowed_https_sites ssl::server_name_regex 
>>>> "/opt/etc/squid/http_url.txt"
>>>> ssl_bump splice allowed_https_sites
>>>> ssl_bump terminate all
>>>
>>> Hrmm...wouldn't that negate the ability to read the cert on step2?
>>>
>>
>> Yes it would.
>>
>>> In layman's terms I'm thinking:
>>> "peek at step1"
>>> "splice acl allow matched sni's"
>>> "peek at step2"
>>> "splice acl allow'd matched certs"
>>> "terminate the rest"
>>>
>>> Would that work Amos?
>>>
>>
>> This is essentially what I suggested at the beginning.
>>
>> Placing splice action and your ACLs on the first ssl_bump line ensures
>> that at each step if enough details are known to splice it will
>> happen.
>>
>> The second line being "peek all" make peek happen at every step for
>> which it is possible (step 1 and step 2 - not step 3).
>>
>> "terminate all" being last makes it happen for "all the rest", aka
>> step 3 if Squid gets that far without splicing.
>>
>>
>> The only difference is that my suggested way would also allow splicing
>> the CONNECT if it happens to be presented with a host name in the
>> authority-URI. Which cannot happen on your proxy unless your port 3128
>> happens to be intercepting traffic between clients and another proxy.
> 
> Ah...ok so this is my lack of understanding then of peek/splice.? Sounds 
> like this is what I can try:
> 
> ssl_bump splice all

ITYM 'peek all' there.

> acl allowed_https_sites ssl::server_name_regex 
> "/opt/etc/squid/http_url.txt"
> ssl_bump splice allowed_https_sites
> ssl_bump terminate all
> 
> Is that what you're meaning Amos?? Thanks again.
> 
> James
> 

Amos


From carlosd2002 at hotmail.com  Mon Dec  4 08:58:28 2017
From: carlosd2002 at hotmail.com (carlos)
Date: Mon, 4 Dec 2017 01:58:28 -0700 (MST)
Subject: [squid-users] squid - kid registration timed out
In-Reply-To: <d3d37cfc-1b12-e083-a7b6-37fa6015330f@treenet.co.nz>
References: <1512066741917-0.post@n4.nabble.com>
 <d3d37cfc-1b12-e083-a7b6-37fa6015330f@treenet.co.nz>
Message-ID: <1512377908581-0.post@n4.nabble.com>

Hi Amos,

Yes i think i did all the adjustments, different pid file, log dirs,
proccess names, listening port... 

it also happens after startup, sometimes after a random time, load is not
the problem since the server is not taking requests yet.

The config is this (i swapped real values for X):

acl all src all
acl SSL_ports port X X X
acl Safe_ports port X-X
acl CONNECT method CONNECT

http_access allow CONNECT SSL_ports all
http_access allow CONNECT Safe_ports all

acl ftp proto FTP
always_direct allow FTP
http_reply_access allow all
http_access allow ftp
icp_access allow all

http_access allow localhost
http_access allow all


pid_filename /var/run/squid.pid

http_port 80

http_access allow manager localhost
http_access deny manager

logfile_rotate 30

visible_hostname squid_8080_${process_number}

cache deny all

logformat access       %{%d-%m-%Y %H:%M:%S}tl.%tu %<pt %<tt %>a %Ss/%03>Hs
%<st %rm %>ru %un %Sh/%<a %mt
access_log /var/log/squid/access8080_${process_number}.log logformat=access
cache_log /var/log/squid/cachelog8080_${process_number}.log

acl XXXX dstdomain xxxxx.zzz
url_rewrite_access allow XXXX
url_rewrite_access deny !XXXX
url_rewrite_program /bin/rewrite


workers 4


Do you see anything wrong?

Thanks,
Carlos



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From christophe.colle at ac-nancy-metz.fr  Mon Dec  4 15:42:30 2017
From: christophe.colle at ac-nancy-metz.fr (Colle Christophe)
Date: Mon, 04 Dec 2017 16:42:30 +0100
Subject: [squid-users] Secure basic authentication on Squid
Message-ID: <3347390832acd6f7.5a257af6@ac-nancy-metz.fr>

Hello!

I am currently using Squid for internet access. Currently, "basic" authentication on an LDAP directory is configured to identify users. The problem is that the password is sent in clear (base64) and I am looking for a solution to secure it.

I tested the "Digest" mode, but the result is inconclusive because you have to modify the LDAP directory with an attribute containing the hash of the password. The directory can not be modified in our case.

Is there a solution to secure the "basic" authentication of squid? (with an SSL certificate for example).

Thank you !

<signaturebeforequotedtext></signaturebeforequotedtext><signatureafterquotedtext>-- 
	
 
  
Chris.


</signatureafterquotedtext>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171204/31d10a61/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Dec  4 15:49:36 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 4 Dec 2017 16:49:36 +0100
Subject: [squid-users] Secure basic authentication on Squid
In-Reply-To: <3347390832acd6f7.5a257af6@ac-nancy-metz.fr>
References: <3347390832acd6f7.5a257af6@ac-nancy-metz.fr>
Message-ID: <201712041649.36718.Antony.Stone@squid.open.source.it>

On Monday 04 December 2017 at 16:42:30, Colle Christophe wrote:

> Is there a solution to secure the "basic" authentication of squid? (with an
> SSL certificate for example).

https://wiki.squid-cache.org/ConfigExamples/Authenticate/Ldap section 
"SSL/TLS_adjustments"?


Antony.

-- 
"Linux is going to be part of the future. It's going to be like Unix was."

 - Peter Moore, Asia-Pacific general manager, Microsoft

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Mon Dec  4 16:02:50 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 5 Dec 2017 05:02:50 +1300
Subject: [squid-users] squid - kid registration timed out
In-Reply-To: <1512377908581-0.post@n4.nabble.com>
References: <1512066741917-0.post@n4.nabble.com>
 <d3d37cfc-1b12-e083-a7b6-37fa6015330f@treenet.co.nz>
 <1512377908581-0.post@n4.nabble.com>
Message-ID: <4ad562d1-f38d-3876-6df0-18ffa8c8404a@treenet.co.nz>



On 04/12/17 21:58, carlos wrote:
> Hi Amos,
> 
> Yes i think i did all the adjustments, different pid file, log dirs,
> proccess names, listening port...
> 
> it also happens after startup, sometimes after a random time, load is not
> the problem since the server is not taking requests yet.
> 
> The config is this (i swapped real values for X):
> 
> acl all src all
> acl SSL_ports port X X X
> acl Safe_ports port X-X
> acl CONNECT method CONNECT
> 
> http_access allow CONNECT SSL_ports all
> http_access allow CONNECT Safe_ports all
> 
> acl ftp proto FTP
> always_direct allow FTP
> http_reply_access allow all
> http_access allow ftp
> icp_access allow all
> 
> http_access allow localhost
> http_access allow all
> 
> 
> pid_filename /var/run/squid.pid
> 
> http_port 80
> 
> http_access allow manager localhost
> http_access deny manager
> 
> logfile_rotate 30
> 
> visible_hostname squid_8080_${process_number}
> 
> cache deny all
> 
> logformat access       %{%d-%m-%Y %H:%M:%S}tl.%tu %<pt %<tt %>a %Ss/%03>Hs
> %<st %rm %>ru %un %Sh/%<a %mt
> access_log /var/log/squid/access8080_${process_number}.log logformat=access
> cache_log /var/log/squid/cachelog8080_${process_number}.log
> 
> acl XXXX dstdomain xxxxx.zzz
> url_rewrite_access allow XXXX
> url_rewrite_access deny !XXXX
> url_rewrite_program /bin/rewrite
> 
> 
> workers 4
> 
> 
> Do you see anything wrong?
> 


I see a few things that indicate you are confusing instance and process.

"squid" is a daemon manager *already* wrangling a whole collection of 
processes 
(<https://wiki.squid-cache.org/Features/SmpScale#Terminology>). The 
${process_*} macros are a temporary workaround for distinguishing how 
those SMP worker processes interpret a config line and has nothing to do 
with multi-instance Squid.

To run multiple *instances* with Squid-3+ you need to us the -n command 
line option and assign a unique service name to each instance. That must 
be used by all scripts and manual commands you run. That is sort of a 
weak sandbox for the instances' SMP things to work within. If you omit 
that option on the command line you are using the default "squid" namespace.

In squid.conf the ${service_name} macro is replaced with that -n 
assigned name to make values for the directives that need to be unique 
without having to make multiple squid.conf.

For example; the pid_filename directive default value in Squid-4 has become:
  pid_filename /var/run/${service_name}.pid


If you do not use -n option then the SMP workers will be registering 
themselves to the wrong coordinators and re-arranging each others shared 
memory spaces randomly. Quite a nasty mess happens.

As a result Squid-3 versions which are SMP-enabled but not supporting -n 
service names cannot be used in a multi-instance environment. That means 
all Squid-3.1 through 3.4.

Amos


From squid3 at treenet.co.nz  Mon Dec  4 16:06:03 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 5 Dec 2017 05:06:03 +1300
Subject: [squid-users] Secure basic authentication on Squid
In-Reply-To: <201712041649.36718.Antony.Stone@squid.open.source.it>
References: <3347390832acd6f7.5a257af6@ac-nancy-metz.fr>
 <201712041649.36718.Antony.Stone@squid.open.source.it>
Message-ID: <8de86dfc-6d1e-a7ba-4911-9d2c91d180b6@treenet.co.nz>

On 05/12/17 04:49, Antony Stone wrote:
> On Monday 04 December 2017 at 16:42:30, Colle Christophe wrote:
> 
>> Is there a solution to secure the "basic" authentication of squid? (with an
>> SSL certificate for example).
> 
> https://wiki.squid-cache.org/ConfigExamples/Authenticate/Ldap section
> "SSL/TLS_adjustments"?
> 

That is only for securing the connection between Squid and the LDAP 
server. It does not affect the credentials themselves.

Amos


From Antony.Stone at squid.open.source.it  Mon Dec  4 16:11:12 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 4 Dec 2017 17:11:12 +0100
Subject: [squid-users] Secure basic authentication on Squid
In-Reply-To: <8de86dfc-6d1e-a7ba-4911-9d2c91d180b6@treenet.co.nz>
References: <3347390832acd6f7.5a257af6@ac-nancy-metz.fr>
 <201712041649.36718.Antony.Stone@squid.open.source.it>
 <8de86dfc-6d1e-a7ba-4911-9d2c91d180b6@treenet.co.nz>
Message-ID: <201712041711.13036.Antony.Stone@squid.open.source.it>

On Monday 04 December 2017 at 17:06:03, Amos Jeffries wrote:

> On 05/12/17 04:49, Antony Stone wrote:
> > On Monday 04 December 2017 at 16:42:30, Colle Christophe wrote:
> >> Is there a solution to secure the "basic" authentication of squid? (with
> >> an SSL certificate for example).
> > 
> > https://wiki.squid-cache.org/ConfigExamples/Authenticate/Ldap section
> > "SSL/TLS_adjustments"?
> 
> That is only for securing the connection between Squid and the LDAP
> server. It does not affect the credentials themselves.

Right.

Since the original question stated that "the problem is that the password is 
sent in clear (base64) and I am looking for a solution to secure it" I assumed 
it was the transmission in the clear which needed to be secured.


Antony.

-- 
"It would appear we have reached the limits of what it is possible to achieve 
with computer technology, although one should be careful with such statements; 
they tend to sound pretty silly in five years."

 - John von Neumann (1949)

                                                   Please reply to the list;
                                                         please *don't* CC me.


From christophe.colle at ac-nancy-metz.fr  Mon Dec  4 16:13:00 2017
From: christophe.colle at ac-nancy-metz.fr (Colle Christophe)
Date: Mon, 04 Dec 2017 17:13:00 +0100
Subject: [squid-users] Secure basic authentication on Squid
In-Reply-To: <201712041649.36718.Antony.Stone@squid.open.source.it>
References: <3347390832acd6f7.5a257af6@ac-nancy-metz.fr>
 <201712041649.36718.Antony.Stone@squid.open.source.it>
Message-ID: <3d9cb71755166345.5a25821c@ac-nancy-metz.fr>


Hi Anthony,

Thank you for your answer.

That this only secures the traffic Squid<->LDAP Server, not browsers<->Squid.

Is there a solution to secure communication between the browser and the proxy?



Chris.

Le 04/12/17 16:49, Antony Stone  <Antony.Stone at squid.open.source.it> a ?crit : 
> 
> On Monday 04 December 2017 at 16:42:30, Colle Christophe wrote:
> 
> > Is there a solution to secure the "basic" authentication of squid? (with an
> > SSL certificate for example).
> 
> https://wiki.squid-cache.org/ConfigExamples/Authenticate/Ldap section 
> "SSL/TLS_adjustments"?
> 
> 
> Antony.
> 
> -- 
> "Linux is going to be part of the future. It's going to be like Unix was."
> 
> ?- Peter Moore, Asia-Pacific general manager, Microsoft
> 
>  Please reply to the list;
>  please *don't* CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171204/1f2dc9e6/attachment.htm>

From mathieu.peltier at gmail.com  Mon Dec  4 17:05:11 2017
From: mathieu.peltier at gmail.com (Mathieu Peltier)
Date: Mon, 4 Dec 2017 18:05:11 +0100
Subject: [squid-users] Enable native ftp proxying with authentification
Message-ID: <CACjeFCAFiLkgEYMDTkd69BdJzxkGKxF5Xe0Xt45bPPGJZAAACQ@mail.gmail.com>

Hi,
I am trying to enable native ftp proxying with authentification (squid
3.5, centos 7):

  acl password proxy_auth REQUIRED
  http_access allow FTP password
  ftp_port 21

Does it make sense ? How am I supposed to login into the proxy?

  ftp proxy.domain.org
  login: proxyuser at anonymous@ftp.free.fr
  -> KO
  451-ERR_CACHE_ACCESS_DENIED
  451 Proxy Authentication Required
  Login failed.

  ftp proxy.domain.org
  login: proxyuser
  -> KO
  501 Missing host
  Login failed.

It works without authentification (http_access allow FTP).
Thanks in advance,
Mathieu


From squid3 at treenet.co.nz  Mon Dec  4 17:05:45 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 5 Dec 2017 06:05:45 +1300
Subject: [squid-users] Secure basic authentication on Squid
In-Reply-To: <3347390832acd6f7.5a257af6@ac-nancy-metz.fr>
References: <3347390832acd6f7.5a257af6@ac-nancy-metz.fr>
Message-ID: <4d62b3e7-447d-09ea-e562-1ec884c597e1@treenet.co.nz>

On 05/12/17 04:42, Colle Christophe wrote:
> Hello!
> 
> I am currently using Squid for internet access. Currently, "basic" 
> authentication on an LDAP directory is configured to identify users. The 
> problem is that the password is sent in clear (base64) and I am looking 
> for a solution to secure it.
> 
> I tested the "Digest" mode, but the result is inconclusive because you 
> have to modify the LDAP directory with an attribute containing the hash 
> of the password. The directory can not be modified in our case.

Should not have to. The helper should be able to treat the LDAP as 
containing the username+password in clear text and do all the hashing 
itself as needed.

(NP: I'm not sure why some of the documentation for digest_ldap_auth 
says "(REQUIRED)" on the -e option. It is an option because you get to 
choose whether it is done that way or not.)


> 
> Is there a solution to secure the "basic" authentication of squid? (with 
> an SSL certificate for example).

Plain text username+password is what "Basic" means. There are ways to 
secure the credentials values by using one-time passwords but it is very 
rare for client software to support that kind of thing. Normally they 
only support the standard Basic credentials.


"Digest" is an entirely different authentication protocol which has 
several modes of use from very weak to reasonably strong security. 
Though in my experience Browsers screw up quite often with the strong 
security mode.


"SSL certificate" - if by that you mean TLS client certificates, is part 
of TLS and has nothing to do with HTTP. Squid does support those for 
securing TLS connections to the proxy, but I'm not sure how well using 
them as user credentials is.

Amos


From ahmed.zaeem at netstream.ps  Mon Dec  4 17:21:07 2017
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Mon, 4 Dec 2017 19:21:07 +0200
Subject: [squid-users] change action of squid -v on squid
In-Reply-To: <23bc704c-a59a-9701-d380-21c24968a73b@measurement-factory.com>
References: <CF5ADB26-2D5E-47BA-B0B0-9EE2B85ADBDD@netstream.ps>
 <23bc704c-a59a-9701-d380-21c24968a73b@measurement-factory.com>
Message-ID: <1A54AFC2-E00B-4FE2-82A1-E7715DD277A9@netstream.ps>

actually i guess its in somewhere in C++ files and i though it gonna be easy .

anyway thanks i will check dev guys 


cheer s

> On Dec 3, 2017, at 10:11 PM, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
>> --enable-build-info="build info string"

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171204/31b6024b/attachment.htm>

From squid3 at treenet.co.nz  Mon Dec  4 17:49:51 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 5 Dec 2017 06:49:51 +1300
Subject: [squid-users] change action of squid -v on squid
In-Reply-To: <1A54AFC2-E00B-4FE2-82A1-E7715DD277A9@netstream.ps>
References: <CF5ADB26-2D5E-47BA-B0B0-9EE2B85ADBDD@netstream.ps>
 <23bc704c-a59a-9701-d380-21c24968a73b@measurement-factory.com>
 <1A54AFC2-E00B-4FE2-82A1-E7715DD277A9@netstream.ps>
Message-ID: <9dfaf080-6ac9-9657-d3e1-1ba1beefa27a@treenet.co.nz>

On 05/12/17 06:21, --Ahmad-- wrote:
> actually i guess its in somewhere in C++ files and i though it gonna be 
> easy .
> 
> anyway thanks i will check dev guys
> 

We two are "the dev guys" for the most part :-P

So my question is *why* are you going to such lengths?

Squid requires root privileges to run from command line. As Alex said it 
is usually pointless to hide the -v info, since only the most trusted of 
users can see it anyway.

Amos


From rousskov at measurement-factory.com  Mon Dec  4 17:57:24 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 4 Dec 2017 10:57:24 -0700
Subject: [squid-users] Secure basic authentication on Squid
In-Reply-To: <4d62b3e7-447d-09ea-e562-1ec884c597e1@treenet.co.nz>
References: <3347390832acd6f7.5a257af6@ac-nancy-metz.fr>
 <4d62b3e7-447d-09ea-e562-1ec884c597e1@treenet.co.nz>
Message-ID: <52632da7-f109-3b6a-d933-979d42833ad1@measurement-factory.com>

On 12/04/2017 10:05 AM, Amos Jeffries wrote:
> On 05/12/17 04:42, Colle Christophe wrote:
>> I am currently using Squid for internet access. Currently, "basic"
>> authentication on an LDAP directory is configured to identify users.
>> The problem is that the password is sent in clear (base64) and I am
>> looking for a solution to secure it.

>> Is there a solution to secure the "basic" authentication of squid?
>> (with an SSL certificate for example).


> Plain text username+password is what "Basic" means.

One can have HTTP Basic authentication inside a TLS connection.

There are several mostly independent pieces here:

1. Basic authentication:

S1. Squid definitely supports HTTP Basic authentication. That code works
in production.

B1. Popular browsers definitely support HTTP Basic authentication.


2. HTTPS proxy:

S2. Squid definitely supports TLS connections between an HTTP browser
and Squid. That code works in production. It can be tested using modern
cURL command line tool versions:
https://daniel.haxx.se/blog/2016/11/26/https-proxy-with-curl/

B2. Popular browsers claim to support TLS connections to HTTP proxies,
but that support is difficult to enable in the browser. Please do not
confuse this support with CONNECT requests. HTTP CONNECT is about TLS
connections to origin servers, not proxies.


3. TLS client certificate authentication:

S3. Squid also supports authentication based on TLS client certificates.
AFAIK, that code works in production.

B3. I do not know whether popular browsers support sending TLS client
certificates, but I would expect that at least some of them do.


Combining the above pieces:

Squid probably supports the combination of S1 and S2. I would not be
surprised if the combination of S1, S2, and S3 also works.

Popular browsers should support the combination of B1 and B2. If they
do, then I would expect them to support the combination of B1, B2, and B3.


Alex.


From yvoinov at gmail.com  Mon Dec  4 18:01:29 2017
From: yvoinov at gmail.com (Yuri)
Date: Tue, 5 Dec 2017 00:01:29 +0600
Subject: [squid-users] change action of squid -v on squid
In-Reply-To: <9dfaf080-6ac9-9657-d3e1-1ba1beefa27a@treenet.co.nz>
References: <CF5ADB26-2D5E-47BA-B0B0-9EE2B85ADBDD@netstream.ps>
 <23bc704c-a59a-9701-d380-21c24968a73b@measurement-factory.com>
 <1A54AFC2-E00B-4FE2-82A1-E7715DD277A9@netstream.ps>
 <9dfaf080-6ac9-9657-d3e1-1ba1beefa27a@treenet.co.nz>
Message-ID: <766a4c6a-e0df-dff6-99ee-a5c35e87b760@gmail.com>



04.12.2017 23:49, Amos Jeffries ?????:
> On 05/12/17 06:21, --Ahmad-- wrote:
>> actually i guess its in somewhere in C++ files and i though it gonna
>> be easy .
>>
>> anyway thanks i will check dev guys
>>
>
> We two are "the dev guys" for the most part :-P
Indeed :-P
>
> So my question is *why* are you going to such lengths?
>
> Squid requires root privileges to run from command line. As Alex said
> it is usually pointless to hide the -v info, since only the most
> trusted of users can see it anyway.
Exactly :-!
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171205/27cd76ca/attachment.sig>

From carlosd2002 at hotmail.com  Mon Dec  4 19:04:12 2017
From: carlosd2002 at hotmail.com (carlos)
Date: Mon, 4 Dec 2017 12:04:12 -0700 (MST)
Subject: [squid-users] squid - kid registration timed out
In-Reply-To: <4ad562d1-f38d-3876-6df0-18ffa8c8404a@treenet.co.nz>
References: <1512066741917-0.post@n4.nabble.com>
 <d3d37cfc-1b12-e083-a7b6-37fa6015330f@treenet.co.nz>
 <1512377908581-0.post@n4.nabble.com>
 <4ad562d1-f38d-3876-6df0-18ffa8c8404a@treenet.co.nz>
Message-ID: <1512414252018-0.post@n4.nabble.com>

>From your post and like i have 3.5.20 i should fine with this version.

Like i have worker > 1 its an SMP setup , correct?

Probably i should be missing the -n, that config is the config file of the
first instance, the other instance is more or less the same, but:
 pid_filename (/var/run/squid.pid vs /var/run/squid81.pid)
 http_port (80 vs 81)
 visible_hostname (squid_80_${process_number} vs squid_81_${process_number})
 access_log (/var/log/squid-80/access80_${process_number} vs
/var/log/squid-81/access81_${process_number} )
 cache_log (/var/log/squid-80/cachelog80_${process_number} vs
/var/log/squid-81/cachelog81_${process_number})

In RHEL i start squid with systemctl start squid.service and  systemctl
start squid81.service.
This is multi-instance, correct?
i think i followed https://wiki.squid-cache.org/MultipleInstances.

Can you confirm that in squid config is OK? You pointed to me "-n" i don't
have it anywere...

In /usr/lib/systemd/system/squid.service (i have another squid81.service) i
have:
...
 EnvironmentFile=/etc/sysconfig/squid
 ExecStart=/usr/sbin/squid $SQUID_OPTS -f $SQUID_CONF
...

the EnvironmentFile:
# default squid options
SQUID_OPTS=""
...
# default squid conf file
SQUID_CONF="/etc/squid/squid.conf"


If understood what you said i must put in SQUID_OPTS "-n squid" and "-n
squid81" in the other instance startup script.

Did i understand correctly?

Thanks,
Carlos






--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Mon Dec  4 20:00:45 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 4 Dec 2017 13:00:45 -0700
Subject: [squid-users] squid - kid registration timed out
In-Reply-To: <1512414252018-0.post@n4.nabble.com>
References: <1512066741917-0.post@n4.nabble.com>
 <d3d37cfc-1b12-e083-a7b6-37fa6015330f@treenet.co.nz>
 <1512377908581-0.post@n4.nabble.com>
 <4ad562d1-f38d-3876-6df0-18ffa8c8404a@treenet.co.nz>
 <1512414252018-0.post@n4.nabble.com>
Message-ID: <d081a079-173d-d6a6-e875-978f71b2fc9b@measurement-factory.com>

On 12/04/2017 12:04 PM, carlos wrote:

> Like i have worker > 1 its an SMP setup , correct?

Correct. "worker > 1" is sufficient (but not necessary) to enable SMP.


> Probably i should be missing the -n

The -n command line option is essentially required to run multiple SMP
instances using the same Squid binary. -n can also make it easier for
multiple SMP instances to share the same squid.conf, but that
simplification is a side effect.


> that config is the config file of the
> first instance, the other instance is more or less the same, but:
>  pid_filename (/var/run/squid.pid vs /var/run/squid81.pid)
>  http_port (80 vs 81)
>  visible_hostname (squid_80_${process_number} vs squid_81_${process_number})
>  access_log (/var/log/squid-80/access80_${process_number} vs
> /var/log/squid-81/access81_${process_number} )
>  cache_log (/var/log/squid-80/cachelog80_${process_number} vs
> /var/log/squid-81/cachelog81_${process_number})

FYI: You may be able to use the same squid.conf for both instances if
you use something like "-n 80" and "-n 81" to start your two Squid
instances and replace 80 and 81 in squid.conf with ${service_name} as
Amos suggested. Again, that unification is sometimes nice to have, but
-n is actually needed for other reasons -- it affects various SMP paths
that cannot be configured via squid.conf.


> In RHEL i start squid with systemctl start squid.service and  systemctl
> start squid81.service.
> This is multi-instance, correct?

Correct.


> i think i followed https://wiki.squid-cache.org/MultipleInstances.

The SMP section in that document needs adjustment: It currently focuses
on what -n means. It should focus on specifying that -n is *required*
for running multi-instance SMP Squids using the same binary (and
referring elsewhere for -n documentation).


> Can you confirm that in squid config is OK? 

It may be OK, but you need -n to make it work.


HTH,

Alex.


From erdosain9 at gmail.com  Mon Dec  4 20:51:50 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 4 Dec 2017 13:51:50 -0700 (MST)
Subject: [squid-users] Block a web just for a group inside another group,
	or how?
Message-ID: <1512420710839-0.post@n4.nabble.com>

Hi to all.
I want to block web.whatsapp.com in some users.
But i already have those users in other group.
I suppose this is not a problem if i put the acl in some order... but its
not working.

For example, i have group
I-FULL: user1, user2, user3

I-RESTRINGIDOS: user1

This is my config file

####GRUPOS DE IP
acl sin_autenticacion src "/etc/squid/listas/sin_autenticacion.lst" 



###Kerberos Auth with ActiveDirectory###
auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -s
HTTP/squid.domain.lan at DOMAIN.LAN
auth_param negotiate children 35 startup=0 idle=1
auth_param basic credentialsttl 2 hours
auth_param negotiate keep_alive on

external_acl_type i-restringidos %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -g i-restringidos at DOMAIN.LAN
external_acl_type i-full %LOGIN /usr/lib64/squid/ext_kerberos_ldap_group_acl
-g i-full at DOMAIN.LAN
external_acl_type i-limitado %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -g i-limitado at DOMAIN.LAN

#GRUPOS
acl i-restringidos external i-restringidos
acl i-full external i-full
acl i-limitado external i-limitado

####Bloquea Publicidad ( http://pgl.yoyo.org/adservers/ )
acl ads dstdom_regex "/etc/squid/listas/ad_block.lst"
http_access deny ads
#deny_info TCP_RESET ads

####Streaming
acl youtube url_regex -i \.flv$
acl youtube url_regex -i \.mp4$
acl youtube url_regex -i watch?
acl youtube url_regex -i youtube
acl facebook url_regex -i facebook
acl facebook url_regex -i fbcdn\.net\/v\/(.*\.mp4)\?
acl facebook url_regex -i fbcdn\.net\/v\/(.*\.jpg)\? 
acl facebook url_regex -i akamaihd\.net\/v\/(.*\.mp4)\?
acl facebook url_regex -i akamaihd\.net\/v\/(.*\.jpg)\?

##Dominios denegados
*acl restringidos dstdomain "/etc/squid/listas/restringidos.lst" (here is
.whatsapp.com)
*acl dominios_denegados dstdomain "/etc/squid/listas/dominios_denegados.lst"


#Puertos
acl SSL_ports port 443
acl SSL_ports port 4443
acl SSL_ports port 8443
acl SSL_ports port 8080
acl SSL_ports port 20000
acl SSL_ports port 10000
acl SSL_ports port 2083

acl Safe_ports port 631         # httpCUPS
acl Safe_ports port 85
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 4443        # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 8443        # httpsalt
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 8080        # edesur y otros
acl Safe_ports port 2199	# radio
acl CONNECT method CONNECT


#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow sin_autenticacion
*http_access allow i-restringidos !restringidos 
*http_access allow i-limitado !dominios_denegados 
*http_access allow i-full !dominios_denegados 
*http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 127.0.0.1:3128
http_port 192.168.1.215:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem
key=/etc/squid/ssl_cert/myca.pem 

acl step1 at_step SslBump1 

acl excludeSSL ssl::server_name_regex "/etc/squid/listas/excluidosSSL.lst"

ssl_bump peek step1 
ssl_bump splice excludeSSL 
ssl_bump bump all 

#tcp_outgoing_address  

# Uncomment and adjust the following to add a disk cache directory.
cache_dir diskd /var/spool/squid 15000 16 256
cache_mem 500 MB
#maximum_object_size_in_memory 1 MB

cache_swap_low 70
cache_swap_high 85

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid


#Your refresh_pattern
refresh_pattern -i \.jpg$ 30 0% 30 ignore-no-cache ignore-no-store
ignore-private
refresh_pattern -i ^http:\/\/www\.google\.com\/$ 0 20% 360 override-expire
override-lastmod ignore-reload ignore-no-cache ignore-no-store
reload-into-ims ignore-must-revalidate
#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320

###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
via off
forwarded_for delete

request_header_access From deny all
request_header_access Server deny all
request_header_access WWW-Authenticate deny all
request_header_access Link deny all
request_header_access Cache-Control deny all
request_header_access Proxy-Connection deny all
request_header_access X-Cache deny all
request_header_access X-Cache-Lookup deny all
request_header_access Via deny all
request_header_access X-Forwarded-For deny all
request_header_access Pragma deny all
request_header_access Keep-Alive deny all

###

#Pools para ancho de banda
delay_pools 5

#Ancho de Youtube
delay_class 1 2 
delay_parameters 1 1000000/1000000 10000/100000
delay_access 1 allow i-limitado youtube !facebook
delay_access 1 deny all

#Ancho de Facebook
delay_class 2 2 
delay_parameters 2 1000000/1000000 50000/256000
delay_access 2 allow i-limitado facebook !youtube
delay_access 2 deny all

#Ancho de banda YOUTUBE FULL
delay_class 3 1
delay_parameters 3 1000000/1000000
delay_access 3 allow i-full youtube !facebook
delay_access 3 deny all

#Ancho de banda LIMITADO
delay_class 4 2 
delay_parameters 4 4000000/4000000 100000/500000
delay_access 4 allow i-limitado !youtube !facebook
delay_access 4 deny all

#Ancho de banda FULL
delay_class 5 2
delay_parameters 5 4000000/4000000 500000/1000000
delay_access 5 allow i-full !youtube !facebook
delay_access 5 deny all

dns_nameservers 192.168.1.10 192.168.1.22
visible_hostname squid.domain.lan

# try connecting to first 25 ips of a domain name
forward_max_tries 25

# fix some ipv6 errors (recommended to comment out) 
dns_v4_first on


Can somebody give me a hand??
Thanks!





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From erdosain9 at gmail.com  Mon Dec  4 22:17:20 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 4 Dec 2017 15:17:20 -0700 (MST)
Subject: [squid-users] Block a web just for a group inside another group,
	or how?
In-Reply-To: <1512420710839-0.post@n4.nabble.com>
References: <1512420710839-0.post@n4.nabble.com>
Message-ID: <1512425840181-0.post@n4.nabble.com>

I dont know if i explain well myself... 
i just want block some web access (facebook, web.whatsapp, etc.) to just a
few users from a large group.
Thanks



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From yvoinov at gmail.com  Mon Dec  4 22:20:10 2017
From: yvoinov at gmail.com (Yuri)
Date: Tue, 5 Dec 2017 04:20:10 +0600
Subject: [squid-users] Block a web just for a group inside another group, or how?
In-Reply-To: <1512425840181-0.post@n4.nabble.com>
References: <1512420710839-0.post@n4.nabble.com>
 <1512425840181-0.post@n4.nabble.com>
Message-ID: <b4d55a92-cc61-2550-d33d-61a040c88858@gmail.com>

Indeed.

Just enumerate this users in acl and put this acl above group acl.

05.12.2017 4:17, erdosain9 ?????:
> I dont know if i explain well myself... 
> i just want block some web access (facebook, web.whatsapp, etc.) to just a
> few users from a large group.
> Thanks
>
>
>
> --
> Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171205/6b122d74/attachment.sig>

From erdosain9 at gmail.com  Mon Dec  4 22:38:16 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 4 Dec 2017 15:38:16 -0700 (MST)
Subject: [squid-users] Block a web just for a group inside another group,
	or how?
In-Reply-To: <b4d55a92-cc61-2550-d33d-61a040c88858@gmail.com>
References: <1512420710839-0.post@n4.nabble.com>
 <1512425840181-0.post@n4.nabble.com>
 <b4d55a92-cc61-2550-d33d-61a040c88858@gmail.com>
Message-ID: <1512427096940-0.post@n4.nabble.com>

Sorry, i dont understand.
Just enumerate the user in a acl?

a common acl or a kerberos acl??

can you put me a example please?

Thanks



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From yvoinov at gmail.com  Mon Dec  4 22:43:14 2017
From: yvoinov at gmail.com (Yuri)
Date: Tue, 5 Dec 2017 04:43:14 +0600
Subject: [squid-users] Block a web just for a group inside another group, or how?
In-Reply-To: <1512427096940-0.post@n4.nabble.com>
References: <1512420710839-0.post@n4.nabble.com>
 <1512425840181-0.post@n4.nabble.com>
 <b4d55a92-cc61-2550-d33d-61a040c88858@gmail.com>
 <1512427096940-0.post@n4.nabble.com>
Message-ID: <8405a07d-9119-e8e1-2e0d-baacf77766cb@gmail.com>



05.12.2017 4:38, erdosain9 ?????:
> Sorry, i dont understand.
> Just enumerate the user in a acl?
Not just. You will have an subset of users which will fires first on
specific URL.
Same like any firewall works, squid process acls from top to bottom.
>
> a common acl or a kerberos acl??
No matter. All acls works identically. From top to bottom.
>
> can you put me a example please?
No, sorry. I dont use any auth in my proxies (they are all transparent).
But your can trivially do it yourself. At least, you can check it and
prove. (Yes, we're not administering your systems ;))
>
> Thanks
>
>
>
> --
> Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171205/86e8d444/attachment.sig>

From yvoinov at gmail.com  Mon Dec  4 22:54:47 2017
From: yvoinov at gmail.com (Yuri)
Date: Tue, 5 Dec 2017 04:54:47 +0600
Subject: [squid-users] Block a web just for a group inside another group, or how?
In-Reply-To: <1512427096940-0.post@n4.nabble.com>
References: <1512420710839-0.post@n4.nabble.com>
 <1512425840181-0.post@n4.nabble.com>
 <b4d55a92-cc61-2550-d33d-61a040c88858@gmail.com>
 <1512427096940-0.post@n4.nabble.com>
Message-ID: <e26433c6-35a2-152c-6414-5a070c6e86ee@gmail.com>

Well, something like this (just to illustrate principe, dont copy and
paste ;)):

# Subset who don't have access to web whatsapp
acl no_web_whatsapp src IP1 IP2 IP3 IP4
acl web_whatsapp dstdomain web.whatsapp.com
# Group incouding IP1-IP4; the rest of group has access to web whatsapp
acl your_group src IP1 IP2 IP3 IP4 IP5 IP6 IP7 IP8 IP9 IP10 IP11

http_access deny no_web_whatsapp web_whatsapp
http_access allow your_group

The idea is: First ACL wotks only for subset of IP for one specific
site. All requests not satisfy deny rule pass to next allow rule.

05.12.2017 4:38, erdosain9 ?????:
> Sorry, i dont understand.
> Just enumerate the user in a acl?
>
> a common acl or a kerberos acl??
>
> can you put me a example please?
>
> Thanks
>
>
>
> --
> Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171205/d18dd2bf/attachment.sig>

From erdosain9 at gmail.com  Mon Dec  4 22:59:07 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 4 Dec 2017 15:59:07 -0700 (MST)
Subject: [squid-users] Block a web just for a group inside another group,
	or how?
In-Reply-To: <8405a07d-9119-e8e1-2e0d-baacf77766cb@gmail.com>
References: <1512420710839-0.post@n4.nabble.com>
 <1512425840181-0.post@n4.nabble.com>
 <b4d55a92-cc61-2550-d33d-61a040c88858@gmail.com>
 <1512427096940-0.post@n4.nabble.com>
 <8405a07d-9119-e8e1-2e0d-baacf77766cb@gmail.com>
Message-ID: <1512428347108-0.post@n4.nabble.com>

But, that's exactly the problem.

Thats what i do.
I do a have this large group
i-full
and a small group with a few users from i-full, the small group is called
i-restringidos.

And put i-restringidos in the top... (as you can see in my config file)

But, is not working. They can go trough the web i try to block.
If i delete the user from i-full, then yes, works... (the users then is just
in i-restringidos).



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From erdosain9 at gmail.com  Mon Dec  4 23:06:30 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 4 Dec 2017 16:06:30 -0700 (MST)
Subject: [squid-users] Block a web just for a group inside another group,
	or how?
In-Reply-To: <e26433c6-35a2-152c-6414-5a070c6e86ee@gmail.com>
References: <1512420710839-0.post@n4.nabble.com>
 <1512425840181-0.post@n4.nabble.com>
 <b4d55a92-cc61-2550-d33d-61a040c88858@gmail.com>
 <1512427096940-0.post@n4.nabble.com>
 <e26433c6-35a2-152c-6414-5a070c6e86ee@gmail.com>
Message-ID: <1512428790420-0.post@n4.nabble.com>

mmm

Ok, thanks
i do that but, with users (calling a new group in the domain). Instead of
this i can do a list of users in a file??
Anyway, i do that, but instead of 
http access deny acl acl

i do 

http access allow acl !acl

This will be the problem? or is the same? (the same "in other words")

Thanks for your time




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From yvoinov at gmail.com  Mon Dec  4 23:12:32 2017
From: yvoinov at gmail.com (Yuri)
Date: Tue, 5 Dec 2017 05:12:32 +0600
Subject: [squid-users] Block a web just for a group inside another group, or how?
In-Reply-To: <1512428790420-0.post@n4.nabble.com>
References: <1512420710839-0.post@n4.nabble.com>
 <1512425840181-0.post@n4.nabble.com>
 <b4d55a92-cc61-2550-d33d-61a040c88858@gmail.com>
 <1512427096940-0.post@n4.nabble.com>
 <e26433c6-35a2-152c-6414-5a070c6e86ee@gmail.com>
 <1512428790420-0.post@n4.nabble.com>
Message-ID: <e44607bc-b4fb-e29f-4320-30dad9cb7c00@gmail.com>

05.12.2017 5:06, erdosain9 ?????:
> mmm
>
> Ok, thanks
> i do that but, with users (calling a new group in the domain). Instead of
> this i can do a list of users in a file??
> Anyway, i do that, but instead of 
> http access deny acl acl
>
> i do 
>
> http access allow acl !acl
>
> This will be the problem? or is the same? (the same "in other words")
>
> Thanks for your time
>
Usually, if one subgroup should be deny and the rest of group should allow,
deny should fires first.

In firewalls, if rule above fires, no other rules process for sessions
which catched by fired rules (of course, if specific appropriate
keyword, yes).

I'm not sure, how squid process ACLs. AFAIK, first fired rule should
overlap others for current session and next acls should not process.
>
>
> --
> Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171205/1b7d35d1/attachment.sig>

From squid3 at treenet.co.nz  Mon Dec  4 23:16:43 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 5 Dec 2017 12:16:43 +1300
Subject: [squid-users] Block a web just for a group inside another group, or how?
In-Reply-To: <1512428347108-0.post@n4.nabble.com>
References: <1512420710839-0.post@n4.nabble.com>
 <1512425840181-0.post@n4.nabble.com>
 <b4d55a92-cc61-2550-d33d-61a040c88858@gmail.com>
 <1512427096940-0.post@n4.nabble.com>
 <8405a07d-9119-e8e1-2e0d-baacf77766cb@gmail.com>
 <1512428347108-0.post@n4.nabble.com>
Message-ID: <26bbbac4-a1de-28e8-de83-2c9a750db55a@treenet.co.nz>

On 05/12/17 11:59, erdosain9 wrote:
> But, that's exactly the problem.
> 
> Thats what i do.
> I do a have this large group
> i-full
> and a small group with a few users from i-full, the small group is called
> i-restringidos.
> 
> And put i-restringidos in the top... (as you can see in my config file)
> 
> But, is not working. They can go trough the web i try to block.
> If i delete the user from i-full, then yes, works... (the users then is just
> in i-restringidos).
> 


So lets look at your config. These are the relevant lines:

 > http_access allow sin_autenticacion
 > http_access allow i-restringidos !restringidos
 > http_access allow i-limitado !dominios_denegados
 > http_access allow i-full !dominios_denegados
 > http_access allow localhost


The first thing you do is ALLOW for anyone who can login. End of story. 
Nothing more to check, they are allowed.

*otherwise* ... (for clients who are not authenticated) their group 
i-restringidos is checked. Group for a not-authenticated client is 
impossible. Go to next line.

*otherwise* ... group i-limitado is checked. Group for a 
not-authenticated client is impossible. Go to next line.

*otherwise* ... group i-full is checked. Group for a not-authenticated 
client is impossible. Go to next line.

*otherwise* ALLOW if the client is on localhost.



Do you understand what is going wrong there?

Amos


From yvoinov at gmail.com  Mon Dec  4 23:19:49 2017
From: yvoinov at gmail.com (Yuri)
Date: Tue, 5 Dec 2017 05:19:49 +0600
Subject: [squid-users] Block a web just for a group inside another group, or how?
In-Reply-To: <26bbbac4-a1de-28e8-de83-2c9a750db55a@treenet.co.nz>
References: <1512420710839-0.post@n4.nabble.com>
 <1512425840181-0.post@n4.nabble.com>
 <b4d55a92-cc61-2550-d33d-61a040c88858@gmail.com>
 <1512427096940-0.post@n4.nabble.com>
 <8405a07d-9119-e8e1-2e0d-baacf77766cb@gmail.com>
 <1512428347108-0.post@n4.nabble.com>
 <26bbbac4-a1de-28e8-de83-2c9a750db55a@treenet.co.nz>
Message-ID: <6eb74970-0c96-3356-376a-c2b414941b01@gmail.com>

Amos, you are as always deep and brief. I did not look carefully at the
list of rules;)


05.12.2017 5:16, Amos Jeffries ?????:
> On 05/12/17 11:59, erdosain9 wrote:
>> But, that's exactly the problem.
>>
>> Thats what i do.
>> I do a have this large group
>> i-full
>> and a small group with a few users from i-full, the small group is
>> called
>> i-restringidos.
>>
>> And put i-restringidos in the top... (as you can see in my config file)
>>
>> But, is not working. They can go trough the web i try to block.
>> If i delete the user from i-full, then yes, works... (the users then
>> is just
>> in i-restringidos).
>>
>
>
> So lets look at your config. These are the relevant lines:
>
> > http_access allow sin_autenticacion
> > http_access allow i-restringidos !restringidos
> > http_access allow i-limitado !dominios_denegados
> > http_access allow i-full !dominios_denegados
> > http_access allow localhost
>
>
> The first thing you do is ALLOW for anyone who can login. End of
> story. Nothing more to check, they are allowed.
>
> *otherwise* ... (for clients who are not authenticated) their group
> i-restringidos is checked. Group for a not-authenticated client is
> impossible. Go to next line.
>
> *otherwise* ... group i-limitado is checked. Group for a
> not-authenticated client is impossible. Go to next line.
>
> *otherwise* ... group i-full is checked. Group for a not-authenticated
> client is impossible. Go to next line.
>
> *otherwise* ALLOW if the client is on localhost.
>
>
>
> Do you understand what is going wrong there?
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171205/1d72e0e5/attachment.sig>

From erdosain9 at gmail.com  Tue Dec  5 00:07:05 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 4 Dec 2017 17:07:05 -0700 (MST)
Subject: [squid-users] Block a web just for a group inside another group,
	or how?
In-Reply-To: <26bbbac4-a1de-28e8-de83-2c9a750db55a@treenet.co.nz>
References: <1512420710839-0.post@n4.nabble.com>
 <1512425840181-0.post@n4.nabble.com>
 <b4d55a92-cc61-2550-d33d-61a040c88858@gmail.com>
 <1512427096940-0.post@n4.nabble.com>
 <8405a07d-9119-e8e1-2e0d-baacf77766cb@gmail.com>
 <1512428347108-0.post@n4.nabble.com>
 <26bbbac4-a1de-28e8-de83-2c9a750db55a@treenet.co.nz>
Message-ID: <1512432425879-0.post@n4.nabble.com>

Thanks Amos.

Let's be clear ... this configuration was working exactly as I wanted it to.
The users in each of those groups (i-full, sin_autenticacion, i-limitados)
navigated without problems. So that they did not navigate, I simply took
them out of one of those groups, period. Everything works as I want except
this related to the group "i-restricted" which is composed of some users of
"i-full".

Thats because i need to "deny"? that group to navigate to the acl of
web.whatsapp, etc.??

Let's be clear... because im not :-)

Do you understand what is going wrong there? 

Nop................

Sorry..... i dont get it.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From carlosd2002 at hotmail.com  Tue Dec  5 00:34:33 2017
From: carlosd2002 at hotmail.com (carlos)
Date: Mon, 4 Dec 2017 17:34:33 -0700 (MST)
Subject: [squid-users] squid - kid registration timed out
In-Reply-To: <d081a079-173d-d6a6-e875-978f71b2fc9b@measurement-factory.com>
References: <1512066741917-0.post@n4.nabble.com>
 <d3d37cfc-1b12-e083-a7b6-37fa6015330f@treenet.co.nz>
 <1512377908581-0.post@n4.nabble.com>
 <4ad562d1-f38d-3876-6df0-18ffa8c8404a@treenet.co.nz>
 <1512414252018-0.post@n4.nabble.com>
 <d081a079-173d-d6a6-e875-978f71b2fc9b@measurement-factory.com>
Message-ID: <1512434073333-0.post@n4.nabble.com>

Hi Alex,

Thanks for the confirmation. 

I just added the -n squid80, etc to SQUID_OPTS, now it restart just fine!
I will wait until tomorrow to see if all squid instances have all the
workers, but reading for post it should be solved for sure!

Yes, i can optimize the config using ${service_name}, probably just one
config would be enought.

I totally miss:
Squid-3.5 provides the -n command line option to configure a unique service
name for each Squid instance started. Each set of SMP-aware processes will
interact only with other processes using the same service name. A service
name is always present, the default service name is squid is used when the
-n option is absent from the command line.


Thanks both of you to point me the direction.

Cheers,
Carlos



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From bgs at bgs.hu  Tue Dec  5 12:14:39 2017
From: bgs at bgs.hu (Bgs)
Date: Tue, 5 Dec 2017 12:14:39 +0000
Subject: [squid-users] Block a web just for a group inside another group, or how?
In-Reply-To: <1512420710839-0.post@n4.nabble.com>
References: <1512420710839-0.post@n4.nabble.com>
Message-ID: <e2a0fb83-263d-80b6-d099-781ccc3ea06b@bgs.hu>


 ?Hi,

In general, the basic idea is this:

ACLs:

LARGEGROUP (eg. all users)
SMALLGROUP (subset of LARGEGROUP you want to further filter)

SMALLBLACKLIST (site list for SMALLGROUP)

http_access deny SMALLGROUP SMALLBLACKLIST
http_access allow LARGEGROUP [whatever]
http_access deny all

You could technically do this too:

http_access allow SMALLGROUP !SMALLBLACKLIST [whatever]
http_access allow LARGEGROUP !SMALLGROUP [whatever]
http_access deny all

But it's more difficult to follow and maintain. (For instance, you need 
to specify the 'whatever' logic twice, instead of once. Also, if 
'whatever' is achieved on multiple lines, things are further complicated.)

When handling exceptions, handle them first, then the more general ones.

Cheers,
Bgs


On 04/12/2017 20:51, erdosain9 wrote:
> Hi to all.
> I want to block web.whatsapp.com in some users.
> But i already have those users in other group.
> I suppose this is not a problem if i put the acl in some order... but its
> not working.
>
> For example, i have group
> I-FULL: user1, user2, user3
>
> I-RESTRINGIDOS: user1
>
> This is my config file
>
> ####GRUPOS DE IP
> acl sin_autenticacion src "/etc/squid/listas/sin_autenticacion.lst"
>
>
>
> ###Kerberos Auth with ActiveDirectory###
> auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -s
> HTTP/squid.domain.lan at DOMAIN.LAN
> auth_param negotiate children 35 startup=0 idle=1
> auth_param basic credentialsttl 2 hours
> auth_param negotiate keep_alive on
>
> external_acl_type i-restringidos %LOGIN
> /usr/lib64/squid/ext_kerberos_ldap_group_acl -g i-restringidos at DOMAIN.LAN
> external_acl_type i-full %LOGIN /usr/lib64/squid/ext_kerberos_ldap_group_acl
> -g i-full at DOMAIN.LAN
> external_acl_type i-limitado %LOGIN
> /usr/lib64/squid/ext_kerberos_ldap_group_acl -g i-limitado at DOMAIN.LAN
>
> #GRUPOS
> acl i-restringidos external i-restringidos
> acl i-full external i-full
> acl i-limitado external i-limitado
>
> ####Bloquea Publicidad ( http://pgl.yoyo.org/adservers/ )
> acl ads dstdom_regex "/etc/squid/listas/ad_block.lst"
> http_access deny ads
> #deny_info TCP_RESET ads
>
> ####Streaming
> acl youtube url_regex -i \.flv$
> acl youtube url_regex -i \.mp4$
> acl youtube url_regex -i watch?
> acl youtube url_regex -i youtube
> acl facebook url_regex -i facebook
> acl facebook url_regex -i fbcdn\.net\/v\/(.*\.mp4)\?
> acl facebook url_regex -i fbcdn\.net\/v\/(.*\.jpg)\?
> acl facebook url_regex -i akamaihd\.net\/v\/(.*\.mp4)\?
> acl facebook url_regex -i akamaihd\.net\/v\/(.*\.jpg)\?
>
> ##Dominios denegados
> *acl restringidos dstdomain "/etc/squid/listas/restringidos.lst" (here is
> .whatsapp.com)
> *acl dominios_denegados dstdomain "/etc/squid/listas/dominios_denegados.lst"
>
>
> #Puertos
> acl SSL_ports port 443
> acl SSL_ports port 4443
> acl SSL_ports port 8443
> acl SSL_ports port 8080
> acl SSL_ports port 20000
> acl SSL_ports port 10000
> acl SSL_ports port 2083
>
> acl Safe_ports port 631         # httpCUPS
> acl Safe_ports port 85
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 4443        # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 8443        # httpsalt
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl Safe_ports port 8080        # edesur y otros
> acl Safe_ports port 2199	# radio
> acl CONNECT method CONNECT
>
>
> #
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
>
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
>
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
>
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> http_access deny to_localhost
>
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
>
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow sin_autenticacion
> *http_access allow i-restringidos !restringidos
> *http_access allow i-limitado !dominios_denegados
> *http_access allow i-full !dominios_denegados
> *http_access allow localhost
>
> # And finally deny all other access to this proxy
> http_access deny all
>
> # Squid normally listens to port 3128
> http_port 127.0.0.1:3128
> http_port 192.168.1.215:3128 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem
> key=/etc/squid/ssl_cert/myca.pem
>
> acl step1 at_step SslBump1
>
> acl excludeSSL ssl::server_name_regex "/etc/squid/listas/excluidosSSL.lst"
>
> ssl_bump peek step1
> ssl_bump splice excludeSSL
> ssl_bump bump all
>
> #tcp_outgoing_address
>
> # Uncomment and adjust the following to add a disk cache directory.
> cache_dir diskd /var/spool/squid 15000 16 256
> cache_mem 500 MB
> #maximum_object_size_in_memory 1 MB
>
> cache_swap_low 70
> cache_swap_high 85
>
> # Leave coredumps in the first cache dir
> coredump_dir /var/spool/squid
>
>
> #Your refresh_pattern
> refresh_pattern -i \.jpg$ 30 0% 30 ignore-no-cache ignore-no-store
> ignore-private
> refresh_pattern -i ^http:\/\/www\.google\.com\/$ 0 20% 360 override-expire
> override-lastmod ignore-reload ignore-no-cache ignore-no-store
> reload-into-ims ignore-must-revalidate
> #
> # Add any of your own refresh_pattern entries above these.
> #
> refresh_pattern ^ftp:		1440	20%	10080
> refresh_pattern ^gopher:	1440	0%	1440
> refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
> refresh_pattern .		0	20%	4320
>
> ###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
> via off
> forwarded_for delete
>
> request_header_access From deny all
> request_header_access Server deny all
> request_header_access WWW-Authenticate deny all
> request_header_access Link deny all
> request_header_access Cache-Control deny all
> request_header_access Proxy-Connection deny all
> request_header_access X-Cache deny all
> request_header_access X-Cache-Lookup deny all
> request_header_access Via deny all
> request_header_access X-Forwarded-For deny all
> request_header_access Pragma deny all
> request_header_access Keep-Alive deny all
>
> ###
>
> #Pools para ancho de banda
> delay_pools 5
>
> #Ancho de Youtube
> delay_class 1 2
> delay_parameters 1 1000000/1000000 10000/100000
> delay_access 1 allow i-limitado youtube !facebook
> delay_access 1 deny all
>
> #Ancho de Facebook
> delay_class 2 2
> delay_parameters 2 1000000/1000000 50000/256000
> delay_access 2 allow i-limitado facebook !youtube
> delay_access 2 deny all
>
> #Ancho de banda YOUTUBE FULL
> delay_class 3 1
> delay_parameters 3 1000000/1000000
> delay_access 3 allow i-full youtube !facebook
> delay_access 3 deny all
>
> #Ancho de banda LIMITADO
> delay_class 4 2
> delay_parameters 4 4000000/4000000 100000/500000
> delay_access 4 allow i-limitado !youtube !facebook
> delay_access 4 deny all
>
> #Ancho de banda FULL
> delay_class 5 2
> delay_parameters 5 4000000/4000000 500000/1000000
> delay_access 5 allow i-full !youtube !facebook
> delay_access 5 deny all
>
> dns_nameservers 192.168.1.10 192.168.1.22
> visible_hostname squid.domain.lan
>
> # try connecting to first 25 ips of a domain name
> forward_max_tries 25
>
> # fix some ipv6 errors (recommended to comment out)
> dns_v4_first on
>
>
> Can somebody give me a hand??
> Thanks!
>
>
>
>
>
> --
> Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From erdosain9 at gmail.com  Tue Dec  5 15:50:28 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 5 Dec 2017 08:50:28 -0700 (MST)
Subject: [squid-users] net::err_cert_common_name_invalid just in squid page
 with dstdomain block
Message-ID: <1512489028475-0.post@n4.nabble.com>

Hi to all.
I block some webs for a group of users.

That users can use internet without problem, but... i block some web (social
networks).
In firefox, all work fine, when someone try to go to facebook for example,
they found with "access denied" (web from squid).
But, in Chrome.. they get this error "net::err_cert_common_name_invalid".

Why??
If all is working (they can use internet with https without problem, why
with the page from squid they have that error)???
All the users use Chrome so, this is a problem for me.
Somebody can help me??

Thanks to all!

This is my config file

####GRUPOS DE IP
acl sin_autenticacion src "/etc/squid/listas/sin_autenticacion.lst"



###Kerberos Auth with ActiveDirectory###
auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -s
HTTP/[hidden email]
auth_param negotiate children 35 startup=0 idle=1
auth_param basic credentialsttl 2 hours
auth_param negotiate keep_alive on

external_acl_type i-restringidos %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -g [hidden email]
external_acl_type i-full %LOGIN /usr/lib64/squid/ext_kerberos_ldap_group_acl
-g [hidden email]
external_acl_type i-limitado %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -g [hidden email]

#GRUPOS
acl i-restringidos external i-restringidos
acl i-full external i-full
acl i-limitado external i-limitado

####Bloquea Publicidad ( http://pgl.yoyo.org/adservers/ )
acl ads dstdom_regex "/etc/squid/listas/ad_block.lst"
http_access deny ads
#deny_info TCP_RESET ads

####Streaming
acl youtube url_regex -i \.flv$
acl youtube url_regex -i \.mp4$
acl youtube url_regex -i watch?
acl youtube url_regex -i youtube
acl facebook url_regex -i facebook
acl facebook url_regex -i fbcdn\.net\/v\/(.*\.mp4)\?
acl facebook url_regex -i fbcdn\.net\/v\/(.*\.jpg)\?
acl facebook url_regex -i akamaihd\.net\/v\/(.*\.mp4)\?
acl facebook url_regex -i akamaihd\.net\/v\/(.*\.jpg)\?

##Dominios denegados
*acl restringidos dstdomain "/etc/squid/listas/restringidos.lst" (here is
.whatsapp.com)
*acl dominios_denegados dstdomain "/etc/squid/listas/dominios_denegados.lst"


#Puertos
acl SSL_ports port 443
acl SSL_ports port 4443
acl SSL_ports port 8443
acl SSL_ports port 8080
acl SSL_ports port 20000
acl SSL_ports port 10000
acl SSL_ports port 2083

acl Safe_ports port 631         # httpCUPS
acl Safe_ports port 85
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 4443        # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 8443        # httpsalt
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 8080        # edesur y otros
acl Safe_ports port 2199 # radio
acl CONNECT method CONNECT


#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow sin_autenticacion
http_access deny i-restringidos !restringidos
http_access allow i-limitado !dominios_denegados
http_access allow i-full !dominios_denegados
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 127.0.0.1:3128
http_port 192.168.1.215:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem
key=/etc/squid/ssl_cert/myca.pem

acl step1 at_step SslBump1

acl excludeSSL ssl::server_name_regex "/etc/squid/listas/excluidosSSL.lst"

ssl_bump peek step1
ssl_bump splice excludeSSL
ssl_bump bump all

#tcp_outgoing_address  

# Uncomment and adjust the following to add a disk cache directory.
cache_dir diskd /var/spool/squid 15000 16 256
cache_mem 500 MB
#maximum_object_size_in_memory 1 MB

cache_swap_low 70
cache_swap_high 85

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid


#Your refresh_pattern
refresh_pattern -i \.jpg$ 30 0% 30 ignore-no-cache ignore-no-store
ignore-private
refresh_pattern -i ^http:\/\/www\.google\.com\/$ 0 20% 360 override-expire
override-lastmod ignore-reload ignore-no-cache ignore-no-store
reload-into-ims ignore-must-revalidate
#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp: 1440 20% 10080
refresh_pattern ^gopher: 1440 0% 1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern . 0 20% 4320

###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
via off
forwarded_for delete

request_header_access From deny all
request_header_access Server deny all
request_header_access WWW-Authenticate deny all
request_header_access Link deny all
request_header_access Cache-Control deny all
request_header_access Proxy-Connection deny all
request_header_access X-Cache deny all
request_header_access X-Cache-Lookup deny all
request_header_access Via deny all
request_header_access X-Forwarded-For deny all
request_header_access Pragma deny all
request_header_access Keep-Alive deny all

###

#Pools para ancho de banda
delay_pools 5

#Ancho de Youtube
delay_class 1 2
delay_parameters 1 1000000/1000000 10000/100000
delay_access 1 allow i-limitado youtube !facebook
delay_access 1 deny all

#Ancho de Facebook
delay_class 2 2
delay_parameters 2 1000000/1000000 50000/256000
delay_access 2 allow i-limitado facebook !youtube
delay_access 2 deny all

#Ancho de banda YOUTUBE FULL
delay_class 3 1
delay_parameters 3 1000000/1000000
delay_access 3 allow i-full youtube !facebook
delay_access 3 deny all

#Ancho de banda LIMITADO
delay_class 4 2
delay_parameters 4 4000000/4000000 100000/500000
delay_access 4 allow i-limitado !youtube !facebook
delay_access 4 deny all

#Ancho de banda FULL
delay_class 5 2
delay_parameters 5 4000000/4000000 500000/1000000
delay_access 5 allow i-full !youtube !facebook
delay_access 5 deny all

dns_nameservers 192.168.1.10 192.168.1.22
visible_hostname squid.domain.lan

# try connecting to first 25 ips of a domain name
forward_max_tries 25

# fix some ipv6 errors (recommended to comment out)
dns_v4_first on



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Tue Dec  5 16:36:35 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 5 Dec 2017 09:36:35 -0700
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <1512489028475-0.post@n4.nabble.com>
References: <1512489028475-0.post@n4.nabble.com>
Message-ID: <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>

On 12/05/2017 08:50 AM, erdosain9 wrote:
> i block some web (social networks).
> In firefox, all work fine, when someone try to go to facebook for example,
> they found with "access denied" (web from squid).
> But, in Chrome.. they get this error "net::err_cert_common_name_invalid".

Does that error match the generated certificate sent by Squid to a
blocked Chrome user? In other words, does that certificate have an
invalid common name (CN) field?


> Why??

To answer that question, I suggest comparing the following two certificates:

  * the certificate sent by Squid to a blocked FireFox user
  * the certificate sent by Squid to a blocked Chrome user

I also suggest comparing the following access.log entries:

  * the line(s) corresponding to the blocked FireFox user request
  * the line(s) corresponding to the blocked Chrome user request

The differences (if any) may help you answer the question.


HTH,

Alex.


> If all is working (they can use internet with https without problem, why
> with the page from squid they have that error)???
> All the users use Chrome so, this is a problem for me.
> Somebody can help me??
> 
> Thanks to all!
> 
> This is my config file
> 
> ####GRUPOS DE IP
> acl sin_autenticacion src "/etc/squid/listas/sin_autenticacion.lst"
> 
> 
> 
> ###Kerberos Auth with ActiveDirectory###
> auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -s
> HTTP/[hidden email]
> auth_param negotiate children 35 startup=0 idle=1
> auth_param basic credentialsttl 2 hours
> auth_param negotiate keep_alive on
> 
> external_acl_type i-restringidos %LOGIN
> /usr/lib64/squid/ext_kerberos_ldap_group_acl -g [hidden email]
> external_acl_type i-full %LOGIN /usr/lib64/squid/ext_kerberos_ldap_group_acl
> -g [hidden email]
> external_acl_type i-limitado %LOGIN
> /usr/lib64/squid/ext_kerberos_ldap_group_acl -g [hidden email]
> 
> #GRUPOS
> acl i-restringidos external i-restringidos
> acl i-full external i-full
> acl i-limitado external i-limitado
> 
> ####Bloquea Publicidad ( http://pgl.yoyo.org/adservers/ )
> acl ads dstdom_regex "/etc/squid/listas/ad_block.lst"
> http_access deny ads
> #deny_info TCP_RESET ads
> 
> ####Streaming
> acl youtube url_regex -i \.flv$
> acl youtube url_regex -i \.mp4$
> acl youtube url_regex -i watch?
> acl youtube url_regex -i youtube
> acl facebook url_regex -i facebook
> acl facebook url_regex -i fbcdn\.net\/v\/(.*\.mp4)\?
> acl facebook url_regex -i fbcdn\.net\/v\/(.*\.jpg)\?
> acl facebook url_regex -i akamaihd\.net\/v\/(.*\.mp4)\?
> acl facebook url_regex -i akamaihd\.net\/v\/(.*\.jpg)\?
> 
> ##Dominios denegados
> *acl restringidos dstdomain "/etc/squid/listas/restringidos.lst" (here is
> .whatsapp.com)
> *acl dominios_denegados dstdomain "/etc/squid/listas/dominios_denegados.lst"
> 
> 
> #Puertos
> acl SSL_ports port 443
> acl SSL_ports port 4443
> acl SSL_ports port 8443
> acl SSL_ports port 8080
> acl SSL_ports port 20000
> acl SSL_ports port 10000
> acl SSL_ports port 2083
> 
> acl Safe_ports port 631         # httpCUPS
> acl Safe_ports port 85
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 4443        # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 8443        # httpsalt
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl Safe_ports port 8080        # edesur y otros
> acl Safe_ports port 2199 # radio
> acl CONNECT method CONNECT
> 
> 
> #
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
> 
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
> 
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> http_access deny to_localhost
> 
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> 
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow sin_autenticacion
> http_access deny i-restringidos !restringidos
> http_access allow i-limitado !dominios_denegados
> http_access allow i-full !dominios_denegados
> http_access allow localhost
> 
> # And finally deny all other access to this proxy
> http_access deny all
> 
> # Squid normally listens to port 3128
> http_port 127.0.0.1:3128
> http_port 192.168.1.215:3128 ssl-bump generate-host-certificates=on
> dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem
> key=/etc/squid/ssl_cert/myca.pem
> 
> acl step1 at_step SslBump1
> 
> acl excludeSSL ssl::server_name_regex "/etc/squid/listas/excluidosSSL.lst"
> 
> ssl_bump peek step1
> ssl_bump splice excludeSSL
> ssl_bump bump all
> 
> #tcp_outgoing_address  
> 
> # Uncomment and adjust the following to add a disk cache directory.
> cache_dir diskd /var/spool/squid 15000 16 256
> cache_mem 500 MB
> #maximum_object_size_in_memory 1 MB
> 
> cache_swap_low 70
> cache_swap_high 85
> 
> # Leave coredumps in the first cache dir
> coredump_dir /var/spool/squid
> 
> 
> #Your refresh_pattern
> refresh_pattern -i \.jpg$ 30 0% 30 ignore-no-cache ignore-no-store
> ignore-private
> refresh_pattern -i ^http:\/\/www\.google\.com\/$ 0 20% 360 override-expire
> override-lastmod ignore-reload ignore-no-cache ignore-no-store
> reload-into-ims ignore-must-revalidate
> #
> # Add any of your own refresh_pattern entries above these.
> #
> refresh_pattern ^ftp: 1440 20% 10080
> refresh_pattern ^gopher: 1440 0% 1440
> refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
> refresh_pattern . 0 20% 4320
> 
> ###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
> via off
> forwarded_for delete
> 
> request_header_access From deny all
> request_header_access Server deny all
> request_header_access WWW-Authenticate deny all
> request_header_access Link deny all
> request_header_access Cache-Control deny all
> request_header_access Proxy-Connection deny all
> request_header_access X-Cache deny all
> request_header_access X-Cache-Lookup deny all
> request_header_access Via deny all
> request_header_access X-Forwarded-For deny all
> request_header_access Pragma deny all
> request_header_access Keep-Alive deny all
> 
> ###
> 
> #Pools para ancho de banda
> delay_pools 5
> 
> #Ancho de Youtube
> delay_class 1 2
> delay_parameters 1 1000000/1000000 10000/100000
> delay_access 1 allow i-limitado youtube !facebook
> delay_access 1 deny all
> 
> #Ancho de Facebook
> delay_class 2 2
> delay_parameters 2 1000000/1000000 50000/256000
> delay_access 2 allow i-limitado facebook !youtube
> delay_access 2 deny all
> 
> #Ancho de banda YOUTUBE FULL
> delay_class 3 1
> delay_parameters 3 1000000/1000000
> delay_access 3 allow i-full youtube !facebook
> delay_access 3 deny all
> 
> #Ancho de banda LIMITADO
> delay_class 4 2
> delay_parameters 4 4000000/4000000 100000/500000
> delay_access 4 allow i-limitado !youtube !facebook
> delay_access 4 deny all
> 
> #Ancho de banda FULL
> delay_class 5 2
> delay_parameters 5 4000000/4000000 500000/1000000
> delay_access 5 allow i-full !youtube !facebook
> delay_access 5 deny all
> 
> dns_nameservers 192.168.1.10 192.168.1.22
> visible_hostname squid.domain.lan
> 
> # try connecting to first 25 ips of a domain name
> forward_max_tries 25
> 
> # fix some ipv6 errors (recommended to comment out)
> dns_v4_first on
> 
> 
> 
> --
> Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 



From erdosain9 at gmail.com  Tue Dec  5 17:05:48 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 5 Dec 2017 10:05:48 -0700 (MST)
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
Message-ID: <1512493548544-0.post@n4.nabble.com>

"Does that error match the generated certificate sent by Squid to a
blocked Chrome user? In other words, does that certificate have an
invalid common name (CN) field? "

No, is the same certificate. 

"I suggest comparing the following two certificates:
  * the certificate sent by Squid to a blocked FireFox user
  * the certificate sent by Squid to a blocked Chrome user "

Is the same certificate.

"I also suggest comparing the following access.log entries:

  * the line(s) corresponding to the blocked FireFox user request
  * the line(s) corresponding to the blocked Chrome user request "

Line corresponding to blocked Chrome

1512493257.523    175 192.168.1.121 TCP_DENIED/200 0 CONNECT
es-la.facebook.com:443 user at DOMAIN.LAN HIER_NONE/- -
1512493257.716    169 192.168.1.121 TCP_MISS/204 193 GET
http://www.gstatic.com/generate_204 user at DOMAIN.LAN
HIER_DIRECT/172.217.30.163 -


Line corresponding to blocked Firefox

1512493386.314     43 192.168.1.121 TCP_DENIED/200 0 CONNECT
es-la.facebook.com:443 user at DOMAIN.LAN HIER_NONE/- -
1512493386.317      0 192.168.1.121 TAG_NONE/403 6569 GET
https://es-la.facebook.com/ user at DOMAIN.LAN HIER_NONE/- text/html
1512493386.370    173 192.168.1.121 TAG_NONE/200 0 CONNECT
www.google.com.ar:443 user at DOMAIN.LAN HIER_DIRECT/216.58.222.163 -
1512493386.397     45 192.168.1.121 TCP_DENIED/200 0 CONNECT
es-la.facebook.com:443 user at DOMAIN.LAN HIER_NONE/- -
1512493386.400      0 192.168.1.121 TAG_NONE/403 6561 GET
http://squid.DOMAIN.lan:3128/squid-internal-static/icons/SN.png
user at DOMAIN.LAN HIER_NONE/- text/html


Is strange that from Firefox the "answer" is instantaneous, from chrome not.

Thanks to all.




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Tue Dec  5 17:29:18 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 5 Dec 2017 10:29:18 -0700
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <1512493548544-0.post@n4.nabble.com>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
 <1512493548544-0.post@n4.nabble.com>
Message-ID: <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>

On 12/05/2017 10:05 AM, erdosain9 wrote:
> "Does that error match the generated certificate sent by Squid to a
> blocked Chrome user? In other words, does that certificate have an
> invalid common name (CN) field? "

> No, is the same certificate. 

Your statement does not answer my question. I can ask a different
question if you prefer: What is is common name (CN) field of the
generated certificate sent by Squid to a blocked Chrome user?


> "I suggest comparing the following two certificates:
>   * the certificate sent by Squid to a blocked FireFox user
>   * the certificate sent by Squid to a blocked Chrome user "
> 
> Is the same certificate.

How do you compare the two certificates?


> "I also suggest comparing the following access.log entries:
> 
>   * the line(s) corresponding to the blocked FireFox user request
>   * the line(s) corresponding to the blocked Chrome user request "


> Line corresponding to blocked Chrome
> 
> 1512493257.523    175 192.168.1.121 TCP_DENIED/200 0 CONNECT es-la.facebook.com:443 user at DOMAIN.LAN HIER_NONE/- -
> 1512493257.716    169 192.168.1.121 TCP_MISS/204 193 GET http://www.gstatic.com/generate_204 user at DOMAIN.LAN HIER_DIRECT/172.217.30.163 -

The allowed GET request looks out of place here. It is possible that
that request was sent by Chrome after (or during) Chrome error page
generation and, hence, should be ignored during this analysis. To make
sure you look at requests on one TCP connection, log the source TCP port
number of the client connection to Squid (%>p).


> Line corresponding to blocked Firefox

> 1512493386.314     43 192.168.1.121 TCP_DENIED/200 0 CONNECT es-la.facebook.com:443 user at DOMAIN.LAN HIER_NONE/- -
> 1512493386.317      0 192.168.1.121 TAG_NONE/403 6569 GET https://es-la.facebook.com/ user at DOMAIN.LAN HIER_NONE/- text/html

This group looks OK to me: The CONNECT request was denied (without
letting the browser know). The following GET request (presumably on the
same TCP connection) was bumped to serve the denial error page to the
browser.


> 1512493386.397     45 192.168.1.121 TCP_DENIED/200 0 CONNECT es-la.facebook.com:443 user at DOMAIN.LAN HIER_NONE/- -
> 1512493386.400      0 192.168.1.121 TAG_NONE/403 6561 GET http://squid.DOMAIN.lan:3128/squid-internal-static/icons/SN.png
> user at DOMAIN.LAN HIER_NONE/- text/html

Something went wrong here. The denied GET request is (logged as) a plain
HTTP request (no "https://"). Perhaps it is unrelated to the denied
CONNECT attempt, but then why did that GET get a 403 response? The above
%>p logging suggestion applies here as well.

Alex.


From erdosain9 at gmail.com  Tue Dec  5 19:33:56 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 5 Dec 2017 12:33:56 -0700 (MST)
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
 <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
Message-ID: <1512502436344-0.post@n4.nabble.com>

Hi, and thanks.

But, i dont get it, how this is possible, if the bumping is working well. I
mean, if all https is working with my certificate, except for those that i
block (from chrome). But the bumping is working well in Chrome and Firefox.

This is log from Chrome with port 

1512501177.181     33 192.168.1.121 TCP_MISS/204 459 POST
https://www.google.com.ar/gen_204? user at mydomain.LAN HIER_DIRECT/- text/html
443
1512501177.182     35 192.168.1.121 TCP_MISS/204 459 POST
https://www.google.com.ar/gen_204? user at mydomain.LAN HIER_DIRECT/- text/html
443
1512501177.186     40 192.168.1.121 TCP_MISS/200 815 POST
https://www.google.com.ar/url? user at mydomain.LAN HIER_DIRECT/- text/html 443
1512501177.252     59 192.168.1.121 TCP_DENIED/200 0 CONNECT
web.whatsapp.com:443 user at mydomain.LAN HIER_NONE/- - 443
1512501177.338     80 192.168.1.121 TCP_MISS/204 193 GET
http://www.gstatic.com/generate_204 user at mydomain.LAN
HIER_DIRECT/www.gstatic.com - 80


This is the log from firefox with port 

1512501278.321     41 192.168.1.121 TCP_MISS/200 813 GET
https://www.google.com.ar/url? user at mydomain.LAN HIER_DIRECT/- text/html 443
1512501278.684    185 192.168.1.121 TCP_DENIED/200 0 CONNECT
www.whatsapp.com:443 user at mydomain.LAN HIER_NONE/- - 443
1512501278.875      3 192.168.1.121 TAG_NONE/403 6567 GET
https://www.whatsapp.com/? user at mydomain.LAN HIER_NONE/- text/html 443
1512501278.916     35 192.168.1.121 TCP_MISS/204 459 POST
https://www.google.com.ar/gen_204? user at mydomain.LAN HIER_DIRECT/- text/html
443
1512501279.160    877 192.168.1.121 TAG_NONE/200 0 CONNECT
www.google.com.ar:443 user at mydomain.LAN HIER_DIRECT/www.google.com.ar - 443
1512501279.278     52 192.168.1.121 TCP_MISS/204 459 POST
https://www.google.com.ar/gen_204? user at mydomain.LAN HIER_DIRECT/- text/html
443
1512501279.529    608 192.168.1.121 TCP_DENIED/200 0 CONNECT
www.whatsapp.com:443 user at mydomain.LAN HIER_NONE/- - 443
1512501279.746      2 192.168.1.121 TAG_NONE/403 6569 GET
http://squid.mydomain.lan:3128/squid-internal-static/icons/SN.png
user at mydomain.LAN HIER_NONE/- text/html 3128
1512501279.832     75 192.168.1.121 TCP_DENIED/200 0 CONNECT
www.whatsapp.com:443 user at mydomain.LAN HIER_NONE/- - 443
1512501279.838      0 192.168.1.121 TAG_NONE/403 6571 GET
https://www.whatsapp.com/favicon.ico user at mydomain.LAN HIER_NONE/- text/html
443

"How do you compare the two certificates? "

I see the certificate, and look detail (both, firefox and chrome).
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t376870/Captura_de_pantalla_de_2017-12-05_16-25-48.png> 

is the same CN :squid.mydomain.lan

And, again, this error just happend from Chrome when there is time to show a
"web from squid" (no route to host, error, access denied,  etc.)

For example if i see the certificate from facebook (trough squid https
bumping) i see my certificate... so why when i block the web Chrome give
that problem....

Thanks again
(sorry i dont speak english very well)



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rafael.akchurin at diladele.com  Tue Dec  5 19:38:05 2017
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 5 Dec 2017 19:38:05 +0000
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <1512502436344-0.post@n4.nabble.com>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
 <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>,
 <1512502436344-0.post@n4.nabble.com>
Message-ID: <8E50647E-9A8A-4C30-BF7B-BC77A397A530@diladele.com>

May it be https://docs.diladele.com/faq/squid/chrome_ssl_filter/dns_does_not_exist.html ?

Best regards,
Rafael Akchurin

Op 5 dec. 2017 om 20:34 heeft erdosain9 <erdosain9 at gmail.com<mailto:erdosain9 at gmail.com>> het volgende geschreven:

Hi, and thanks.

But, i dont get it, how this is possible, if the bumping is working well. I
mean, if all https is working with my certificate, except for those that i
block (from chrome). But the bumping is working well in Chrome and Firefox.

This is log from Chrome with port

1512501177.181     33 192.168.1.121 TCP_MISS/204 459 POST
https://www.google.com.ar/gen_204? user at mydomain.LAN<mailto:user at mydomain.LAN> HIER_DIRECT/- text/html
443
1512501177.182     35 192.168.1.121 TCP_MISS/204 459 POST
https://www.google.com.ar/gen_204? user at mydomain.LAN<mailto:user at mydomain.LAN> HIER_DIRECT/- text/html
443
1512501177.186     40 192.168.1.121 TCP_MISS/200 815 POST
https://www.google.com.ar/url? user at mydomain.LAN<mailto:user at mydomain.LAN> HIER_DIRECT/- text/html 443
1512501177.252     59 192.168.1.121 TCP_DENIED/200 0 CONNECT
web.whatsapp.com:443<http://web.whatsapp.com:443> user at mydomain.LAN<mailto:user at mydomain.LAN> HIER_NONE/- - 443
1512501177.338     80 192.168.1.121 TCP_MISS/204 193 GET
http://www.gstatic.com/generate_204 user at mydomain.LAN<mailto:user at mydomain.LAN>
HIER_DIRECT/www.gstatic.com<http://www.gstatic.com> - 80


This is the log from firefox with port

1512501278.321     41 192.168.1.121 TCP_MISS/200 813 GET
https://www.google.com.ar/url? user at mydomain.LAN<mailto:user at mydomain.LAN> HIER_DIRECT/- text/html 443
1512501278.684    185 192.168.1.121 TCP_DENIED/200 0 CONNECT
www.whatsapp.com:443<http://www.whatsapp.com:443> user at mydomain.LAN<mailto:user at mydomain.LAN> HIER_NONE/- - 443
1512501278.875      3 192.168.1.121 TAG_NONE/403 6567 GET
https://www.whatsapp.com/? user at mydomain.LAN<mailto:user at mydomain.LAN> HIER_NONE/- text/html 443
1512501278.916     35 192.168.1.121 TCP_MISS/204 459 POST
https://www.google.com.ar/gen_204? user at mydomain.LAN<mailto:user at mydomain.LAN> HIER_DIRECT/- text/html
443
1512501279.160    877 192.168.1.121 TAG_NONE/200 0 CONNECT
www.google.com.ar:443<http://www.google.com.ar:443> user at mydomain.LAN<mailto:user at mydomain.LAN> HIER_DIRECT/www.google.com.ar<http://www.google.com.ar> - 443
1512501279.278     52 192.168.1.121 TCP_MISS/204 459 POST
https://www.google.com.ar/gen_204? user at mydomain.LAN<mailto:user at mydomain.LAN> HIER_DIRECT/- text/html
443
1512501279.529    608 192.168.1.121 TCP_DENIED/200 0 CONNECT
www.whatsapp.com:443<http://www.whatsapp.com:443> user at mydomain.LAN<mailto:user at mydomain.LAN> HIER_NONE/- - 443
1512501279.746      2 192.168.1.121 TAG_NONE/403 6569 GET
http://squid.mydomain.lan:3128/squid-internal-static/icons/SN.png
user at mydomain.LAN<mailto:user at mydomain.LAN> HIER_NONE/- text/html 3128
1512501279.832     75 192.168.1.121 TCP_DENIED/200 0 CONNECT
www.whatsapp.com:443<http://www.whatsapp.com:443> user at mydomain.LAN<mailto:user at mydomain.LAN> HIER_NONE/- - 443
1512501279.838      0 192.168.1.121 TAG_NONE/403 6571 GET
https://www.whatsapp.com/favicon.ico user at mydomain.LAN<mailto:user at mydomain.LAN> HIER_NONE/- text/html
443

"How do you compare the two certificates? "

I see the certificate, and look detail (both, firefox and chrome).
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t376870/Captura_de_pantalla_de_2017-12-05_16-25-48.png>

is the same CN :squid.mydomain.lan

And, again, this error just happend from Chrome when there is time to show a
"web from squid" (no route to host, error, access denied,  etc.)

For example if i see the certificate from facebook (trough squid https
bumping) i see my certificate... so why when i block the web Chrome give
that problem....

Thanks again
(sorry i dont speak english very well)



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171205/6debe29a/attachment.htm>

From squid3 at treenet.co.nz  Tue Dec  5 19:46:51 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 6 Dec 2017 08:46:51 +1300
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
 <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
Message-ID: <7f9bf856-17ae-ce7b-249e-b96d038036b4@treenet.co.nz>

On 06/12/17 06:29, Alex Rousskov wrote:
> On 12/05/2017 10:05 AM, erdosain9 wrote:
>> "Does that error match the generated certificate sent by Squid to a
>> blocked Chrome user? In other words, does that certificate have an
>> invalid common name (CN) field? "
> 
>> No, is the same certificate.
> 
> Your statement does not answer my question. I can ask a different
> question if you prefer: What is is common name (CN) field of the
> generated certificate sent by Squid to a blocked Chrome user?
> 
> 
>> "I suggest comparing the following two certificates:
>>    * the certificate sent by Squid to a blocked FireFox user
>>    * the certificate sent by Squid to a blocked Chrome user "
>>
>> Is the same certificate.
> 
> How do you compare the two certificates?
> 
> 
>> "I also suggest comparing the following access.log entries:
>>
>>    * the line(s) corresponding to the blocked FireFox user request
>>    * the line(s) corresponding to the blocked Chrome user request "
> 
> 
>> Line corresponding to blocked Chrome
>>
>> 1512493257.523    175 192.168.1.121 TCP_DENIED/200 0 CONNECT es-la.facebook.com:443 user at DOMAIN.LAN HIER_NONE/- -
>> 1512493257.716    169 192.168.1.121 TCP_MISS/204 193 GET http://www.gstatic.com/generate_204 user at DOMAIN.LAN HIER_DIRECT/172.217.30.163 -
> 
> The allowed GET request looks out of place here. It is possible that
> that request was sent by Chrome after (or during) Chrome error page
> generation and, hence, should be ignored during this analysis. To make
> sure you look at requests on one TCP connection, log the source TCP port
> number of the client connection to Squid (%>p).

That URI is Chrome testing for Internet access.

> 
>> Line corresponding to blocked Firefox
> 
>> 1512493386.314     43 192.168.1.121 TCP_DENIED/200 0 CONNECT es-la.facebook.com:443 user at DOMAIN.LAN HIER_NONE/- -
>> 1512493386.317      0 192.168.1.121 TAG_NONE/403 6569 GET https://es-la.facebook.com/ user at DOMAIN.LAN HIER_NONE/- text/html
> 
> This group looks OK to me: The CONNECT request was denied (without
> letting the browser know). The following GET request (presumably on the
> same TCP connection) was bumped to serve the denial error page to the
> browser.
> 
> 
>> 1512493386.397     45 192.168.1.121 TCP_DENIED/200 0 CONNECT es-la.facebook.com:443 user at DOMAIN.LAN HIER_NONE/- -
>> 1512493386.400      0 192.168.1.121 TAG_NONE/403 6561 GET http://squid.DOMAIN.lan:3128/squid-internal-static/icons/SN.png
>> user at DOMAIN.LAN HIER_NONE/- text/html
> 
> Something went wrong here. The denied GET request is (logged as) a plain
> HTTP request (no "https://"). Perhaps it is unrelated to the denied
> CONNECT attempt, but then why did that GET get a 403 response? The above
> %>p logging suggestion applies here as well.

It is the icon on a Squid error page. I doubt it has anything to do with 
the second CONNECT line directly above it, but is probably the result of 
the 403 being delivered by Squid two lines previously.


Amos


From erdosain9 at gmail.com  Tue Dec  5 20:01:00 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 5 Dec 2017 13:01:00 -0700 (MST)
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <8E50647E-9A8A-4C30-BF7B-BC77A397A530@diladele.com>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
 <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
 <1512502436344-0.post@n4.nabble.com>
 <8E50647E-9A8A-4C30-BF7B-BC77A397A530@diladele.com>
Message-ID: <1512504060575-0.post@n4.nabble.com>

When i put the in Chrome
https://wwww.sdfasdfasdfasdfasd.com

it produces the same error...
but this just happend with  "https" and with chrome.............. not with
firefox.

With firefox i get the error web pager from squid

    Unable to determine IP address from host name
"www.sdfasdfasdfasdfasf.com"

But... i dont get, why this problem if web.whatsapp.com, facebook.com, etc.
exist... in the other hand why this when squid is trying to show the
informative page (access denied). Because like i say, bumping is working
well.

Thanks all.





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Tue Dec  5 20:11:01 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 6 Dec 2017 09:11:01 +1300
Subject: [squid-users] Block a web just for a group inside another group, or how?
In-Reply-To: <1512432425879-0.post@n4.nabble.com>
References: <1512420710839-0.post@n4.nabble.com>
 <1512425840181-0.post@n4.nabble.com>
 <b4d55a92-cc61-2550-d33d-61a040c88858@gmail.com>
 <1512427096940-0.post@n4.nabble.com>
 <8405a07d-9119-e8e1-2e0d-baacf77766cb@gmail.com>
 <1512428347108-0.post@n4.nabble.com>
 <26bbbac4-a1de-28e8-de83-2c9a750db55a@treenet.co.nz>
 <1512432425879-0.post@n4.nabble.com>
Message-ID: <82b26024-50d4-985c-c2c7-1104752ab1f9@treenet.co.nz>

On 05/12/17 13:07, erdosain9 wrote:
> Thanks Amos.
> 
> Let's be clear ... this configuration was working exactly as I wanted it to.
> The users in each of those groups (i-full, sin_autenticacion, i-limitados)
> navigated without problems. So that they did not navigate, I simply took
> them out of one of those groups, period. Everything works as I want except
> this related to the group "i-restricted" which is composed of some users of
> "i-full".


So what do you think happens for them?

You are currently only specifying allow permissions. *One* of their 
groups allows the transaction.

Amos


From squid3 at treenet.co.nz  Tue Dec  5 20:30:54 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 6 Dec 2017 09:30:54 +1300
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <1512504060575-0.post@n4.nabble.com>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
 <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
 <1512502436344-0.post@n4.nabble.com>
 <8E50647E-9A8A-4C30-BF7B-BC77A397A530@diladele.com>
 <1512504060575-0.post@n4.nabble.com>
Message-ID: <7f09d187-c5fc-439f-352a-89b628682ade@treenet.co.nz>

On 06/12/17 09:01, erdosain9 wrote:
> When i put the in Chrome
> https://wwww.sdfasdfasdfasdfasd.com
> 
> it produces the same error...
> but this just happend with  "https" and with chrome.............. not with
> firefox.
> 
> With firefox i get the error web pager from squid
> 
>      Unable to determine IP address from host name
> "www.sdfasdfasdfasdfasf.com"
> 
> But... i dont get, why this problem if web.whatsapp.com, facebook.com, etc.
> exist... in the other hand why this when squid is trying to show the
> informative page (access denied). Because like i say, bumping is working
> well.

You are asking the wrong people here. The Chrome developers decided 
Chrome should act that way.

Amos


From rousskov at measurement-factory.com  Tue Dec  5 21:08:51 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 5 Dec 2017 14:08:51 -0700
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <1512502436344-0.post@n4.nabble.com>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
 <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
 <1512502436344-0.post@n4.nabble.com>
Message-ID: <f79d0f42-90d3-ddc1-f4ac-507318591860@measurement-factory.com>

On 12/05/2017 12:33 PM, erdosain9 wrote:

> i dont get it, how this is possible, if the bumping is working well. 

Depending on your configuration and traffic, Squid may have more origin
server information when generating certificates for (future)
successfully bumped connections compared to when generating certificates
for (future) error responses. Lack of information often leads to bumping
failures.


> This is log from Chrome with port 

I did not find the client source port in your access log lines. 80 and
443 are server ports. If you were using the correct %>p code, try the
opposite one (%<p) and file a bug report. You can always log both, of
course.

Also, to reduce analysis time in the future, while working on this
specific thread/question, please post only access log lines related to a
single problematic TCP connection that starts with a CONNECT request.
There is no need to post other/unrelated traffic.


> "How do you compare the two certificates? "
> 
> I see the certificate, and look detail (both, firefox and chrome).
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t376870/Captura_de_pantalla_de_2017-12-05_16-25-48.png> 

That screenshot does not show the certificate detail, so I cannot
confirm or deny your claim that the CN is the same in both FireFox and
Chrome cases. To see certificate details, you need to (at least) click
on the "View Certificate" button shown on that screenshot.


> is the same CN :squid.mydomain.lan

That CN is wrong for bumped connections to Facebook (or WhatsApp). If
that is indeed the certificate CN for the error response connection, and
that connection was trying to get to Facebook (or WhatsApp), then Chrome
may be telling you the truth!

Alex.


From yvoinov at gmail.com  Tue Dec  5 23:17:06 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 6 Dec 2017 05:17:06 +0600
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <f79d0f42-90d3-ddc1-f4ac-507318591860@measurement-factory.com>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
 <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
 <1512502436344-0.post@n4.nabble.com>
 <f79d0f42-90d3-ddc1-f4ac-507318591860@measurement-factory.com>
Message-ID: <426ba648-4c6e-4cfe-7f09-7df5a010390f@gmail.com>

Everything can be much simpler. If the deny is redirected to the local
web server with https, and the server certificate does not have the
correct CN - or there is no subjectAltName - Chrome will give such an error.


06.12.2017 3:08, Alex Rousskov ?????:
> On 12/05/2017 12:33 PM, erdosain9 wrote:
>
>> i dont get it, how this is possible, if the bumping is working well. 
> Depending on your configuration and traffic, Squid may have more origin
> server information when generating certificates for (future)
> successfully bumped connections compared to when generating certificates
> for (future) error responses. Lack of information often leads to bumping
> failures.
>
>
>> This is log from Chrome with port 
> I did not find the client source port in your access log lines. 80 and
> 443 are server ports. If you were using the correct %>p code, try the
> opposite one (%<p) and file a bug report. You can always log both, of
> course.
>
> Also, to reduce analysis time in the future, while working on this
> specific thread/question, please post only access log lines related to a
> single problematic TCP connection that starts with a CONNECT request.
> There is no need to post other/unrelated traffic.
>
>
>> "How do you compare the two certificates? "
>>
>> I see the certificate, and look detail (both, firefox and chrome).
>> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t376870/Captura_de_pantalla_de_2017-12-05_16-25-48.png> 
> That screenshot does not show the certificate detail, so I cannot
> confirm or deny your claim that the CN is the same in both FireFox and
> Chrome cases. To see certificate details, you need to (at least) click
> on the "View Certificate" button shown on that screenshot.
>
>
>> is the same CN :squid.mydomain.lan
> That CN is wrong for bumped connections to Facebook (or WhatsApp). If
> that is indeed the certificate CN for the error response connection, and
> that connection was trying to get to Facebook (or WhatsApp), then Chrome
> may be telling you the truth!
>
> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171206/9ad76ef5/attachment.sig>

From yvoinov at gmail.com  Tue Dec  5 23:24:50 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 6 Dec 2017 05:24:50 +0600
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <426ba648-4c6e-4cfe-7f09-7df5a010390f@gmail.com>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
 <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
 <1512502436344-0.post@n4.nabble.com>
 <f79d0f42-90d3-ddc1-f4ac-507318591860@measurement-factory.com>
 <426ba648-4c6e-4cfe-7f09-7df5a010390f@gmail.com>
Message-ID: <8962948e-7c6c-a18b-1738-22b3d646fd40@gmail.com>

PS. And, of course, both CN/subjectAltName should be resolvable by
client. If not - you will get such an error.

This, automatically, point us to DNS (internal) which must have local
zone to internal resolving resources such as proxy, local web, etc.


06.12.2017 5:17, Yuri ?????:
> Everything can be much simpler. If the deny is redirected to the local
> web server with https, and the server certificate does not have the
> correct CN - or there is no subjectAltName - Chrome will give such an error.
>
>
> 06.12.2017 3:08, Alex Rousskov ?????:
>> On 12/05/2017 12:33 PM, erdosain9 wrote:
>>
>>> i dont get it, how this is possible, if the bumping is working well. 
>> Depending on your configuration and traffic, Squid may have more origin
>> server information when generating certificates for (future)
>> successfully bumped connections compared to when generating certificates
>> for (future) error responses. Lack of information often leads to bumping
>> failures.
>>
>>
>>> This is log from Chrome with port 
>> I did not find the client source port in your access log lines. 80 and
>> 443 are server ports. If you were using the correct %>p code, try the
>> opposite one (%<p) and file a bug report. You can always log both, of
>> course.
>>
>> Also, to reduce analysis time in the future, while working on this
>> specific thread/question, please post only access log lines related to a
>> single problematic TCP connection that starts with a CONNECT request.
>> There is no need to post other/unrelated traffic.
>>
>>
>>> "How do you compare the two certificates? "
>>>
>>> I see the certificate, and look detail (both, firefox and chrome).
>>> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t376870/Captura_de_pantalla_de_2017-12-05_16-25-48.png> 
>> That screenshot does not show the certificate detail, so I cannot
>> confirm or deny your claim that the CN is the same in both FireFox and
>> Chrome cases. To see certificate details, you need to (at least) click
>> on the "View Certificate" button shown on that screenshot.
>>
>>
>>> is the same CN :squid.mydomain.lan
>> That CN is wrong for bumped connections to Facebook (or WhatsApp). If
>> that is indeed the certificate CN for the error response connection, and
>> that connection was trying to get to Facebook (or WhatsApp), then Chrome
>> may be telling you the truth!
>>
>> Alex.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171206/656fb4c3/attachment.sig>

From yvoinov at gmail.com  Tue Dec  5 23:27:21 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 6 Dec 2017 05:27:21 +0600
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <8962948e-7c6c-a18b-1738-22b3d646fd40@gmail.com>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
 <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
 <1512502436344-0.post@n4.nabble.com>
 <f79d0f42-90d3-ddc1-f4ac-507318591860@measurement-factory.com>
 <426ba648-4c6e-4cfe-7f09-7df5a010390f@gmail.com>
 <8962948e-7c6c-a18b-1738-22b3d646fd40@gmail.com>
Message-ID: <c714c721-c627-f398-7fe4-e550c005d848@gmail.com>

PPS. I want to add an obvious thing. Blocking https pages should also be
redirected to the https page. This is obvious and required by the RFC.
As I know. And the https page for the https deny must be opened
correctly by the client browser. It's simple.


06.12.2017 5:24, Yuri ?????:
> PS. And, of course, both CN/subjectAltName should be resolvable by
> client. If not - you will get such an error.
>
> This, automatically, point us to DNS (internal) which must have local
> zone to internal resolving resources such as proxy, local web, etc.
>
>
> 06.12.2017 5:17, Yuri ?????:
>> Everything can be much simpler. If the deny is redirected to the local
>> web server with https, and the server certificate does not have the
>> correct CN - or there is no subjectAltName - Chrome will give such an error.
>>
>>
>> 06.12.2017 3:08, Alex Rousskov ?????:
>>> On 12/05/2017 12:33 PM, erdosain9 wrote:
>>>
>>>> i dont get it, how this is possible, if the bumping is working well. 
>>> Depending on your configuration and traffic, Squid may have more origin
>>> server information when generating certificates for (future)
>>> successfully bumped connections compared to when generating certificates
>>> for (future) error responses. Lack of information often leads to bumping
>>> failures.
>>>
>>>
>>>> This is log from Chrome with port 
>>> I did not find the client source port in your access log lines. 80 and
>>> 443 are server ports. If you were using the correct %>p code, try the
>>> opposite one (%<p) and file a bug report. You can always log both, of
>>> course.
>>>
>>> Also, to reduce analysis time in the future, while working on this
>>> specific thread/question, please post only access log lines related to a
>>> single problematic TCP connection that starts with a CONNECT request.
>>> There is no need to post other/unrelated traffic.
>>>
>>>
>>>> "How do you compare the two certificates? "
>>>>
>>>> I see the certificate, and look detail (both, firefox and chrome).
>>>> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/t376870/Captura_de_pantalla_de_2017-12-05_16-25-48.png> 
>>> That screenshot does not show the certificate detail, so I cannot
>>> confirm or deny your claim that the CN is the same in both FireFox and
>>> Chrome cases. To see certificate details, you need to (at least) click
>>> on the "View Certificate" button shown on that screenshot.
>>>
>>>
>>>> is the same CN :squid.mydomain.lan
>>> That CN is wrong for bumped connections to Facebook (or WhatsApp). If
>>> that is indeed the certificate CN for the error response connection, and
>>> that connection was trying to get to Facebook (or WhatsApp), then Chrome
>>> may be telling you the truth!
>>>
>>> Alex.
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171206/c96cb020/attachment.sig>

From jason_haar at trimble.com  Wed Dec  6 06:01:23 2017
From: jason_haar at trimble.com (Jason Haar)
Date: Wed, 6 Dec 2017 19:01:23 +1300
Subject: [squid-users] Secure basic authentication on Squid
In-Reply-To: <3d9cb71755166345.5a25821c@ac-nancy-metz.fr>
References: <3347390832acd6f7.5a257af6@ac-nancy-metz.fr>
 <201712041649.36718.Antony.Stone@squid.open.source.it>
 <3d9cb71755166345.5a25821c@ac-nancy-metz.fr>
Message-ID: <CAFChrgLWwDbf5OPYMK+xG6eMjFXo2LYD4soX4x2PFwDp+j4egA@mail.gmail.com>

To reiterate Alex, "yes you can".

Squid supports "proxy over TLS" as well as the old/default "proxy over TCP"
- you use the https_port option

...but getting browsers to support it is challenging. The best way would be
to create a WPAD file that tells browsers to use "HTTPS" instead of
"PROXY". Then you can just use Proxy-Authentication using Basic and you'd
be all set. BTW, Basic has MAJOR performance benefits over any other form
of authentication IMHO. Basic over TLS is the way to go...


eg something like this

---------------- wpad.dat ----------

function FindProxyForURL(url, host)
{
  // see how I used 443? If you're going to run a TLS-encrypted proxy, make
it totally appear as a HTTPS server and run it on port 443...
  //


if (isPlainHostName(host) ||  dnsDomainIs(host,"localhost.localdomain") ) {
return "DIRECT";
} else if (isInNet(host, "127.0.0.0", "255.0.0.0") || isInNet(host,
"10.0.0.0", "255.0.0.0") || isInNet(host, "172.16.0.0", "255.240.0.0")  ||
isInNet(host, "192.168.0.0", "255.255.0.0") ) {
return "DIRECT";
} else {
//
return "HTTPS secure-squid.com:443";
  }
}


On Tue, Dec 5, 2017 at 5:13 AM, Colle Christophe <
christophe.colle at ac-nancy-metz.fr> wrote:

> Hi Anthony,
>
> Thank you for your answer.
>
> That this only secures the traffic Squid<->LDAP Server, not
> browsers<->Squid.
>
> Is there a solution to secure communication between the browser and the
> proxy?
>
>
> Chris.
>
> Le 04/12/17 16:49, *Antony Stone * <Antony.Stone at squid.open.source.it> a
> ?crit :
>
> On Monday 04 December 2017 at 16:42:30, Colle Christophe wrote:
>
> > Is there a solution to secure the "basic" authentication of squid? (with
> an
> > SSL certificate for example).
>
> https://wiki.squid-cache.org/ConfigExamples/Authenticate/Ldap section
> "SSL/TLS_adjustments"?
>
>
> Antony.
>
> --
> "Linux is going to be part of the future. It's going to be like Unix was."
>
>  - Peter Moore, Asia-Pacific general manager, Microsoft
>
>                                                    Please reply to the
> list;
>                                                          please *don't*
> CC me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>


-- 
Cheers

Jason Haar
Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171206/4eb1b805/attachment.htm>

From 747620227 at qq.com  Wed Dec  6 08:07:21 2017
From: 747620227 at qq.com (=?gb18030?B?R35Efkx1bmF0aWM=?=)
Date: Wed, 6 Dec 2017 16:07:21 +0800
Subject: [squid-users] 503 issue after accessing https svn
Message-ID: <tencent_03D7B75DA9F92AE086F52489CFB275346009@qq.com>

my squid is a transparent proxy. and the problem is that i can't access the svn server.
the access.log shows that 
1512545348.844    380 192.168.51.15 TAG_NONE/200 0 CONNECT 192.168.52.6:443 - ORIGINAL_DST/192.168.52.6 -
1512545348.920      0 192.168.51.15 TAG_NONE/503 4324 OPTIONS https://192.168.52.6/svn/WATMdev/trunk/development/third_period/icapServer - HIER_NONE/- text/html

but when i use splice step . the access is normal.  so i want to know  what's the problem.  


Here is my configure

https_port 192.168.51.200:3129 intercept ssl-bump connection-auth=off generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/ssl_cert/myCA.pem key=/usr/local/squid/ssl_cert/myCA.pem options=NO_SSLv3,NO_SSLv2


acl broken_sites ssl::server_name matchweb.sports.qq.com
acl ssl_step1 at_step SslBump1
acl ssl_step2 at_step SslBump2
acl ssl_step3 at_step SslBump3
ssl_bump splice broken_sites
#ssl_bump splice all
ssl_bump stare ssl_step1
ssl_bump bump ssl_step2
ssl_bump terminate ssl_step3
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171206/88ce51bb/attachment.htm>

From mathieu.peltier at gmail.com  Wed Dec  6 08:32:42 2017
From: mathieu.peltier at gmail.com (Mathieu Peltier)
Date: Wed, 6 Dec 2017 09:32:42 +0100
Subject: [squid-users] Secure basic authentication on Squid
In-Reply-To: <CAFChrgLWwDbf5OPYMK+xG6eMjFXo2LYD4soX4x2PFwDp+j4egA@mail.gmail.com>
References: <3347390832acd6f7.5a257af6@ac-nancy-metz.fr>
 <201712041649.36718.Antony.Stone@squid.open.source.it>
 <3d9cb71755166345.5a25821c@ac-nancy-metz.fr>
 <CAFChrgLWwDbf5OPYMK+xG6eMjFXo2LYD4soX4x2PFwDp+j4egA@mail.gmail.com>
Message-ID: <CACjeFCD4a-NCk+EedPuDFh7+hFvUFOwX1r_HXthO3D1aHoOkBw@mail.gmail.com>

On Wed, Dec 6, 2017 at 7:01 AM, Jason Haar <jason_haar at trimble.com> wrote:
> To reiterate Alex, "yes you can".
>
> Squid supports "proxy over TLS" as well as the old/default "proxy over TCP"
> - you use the https_port option
>
> ...but getting browsers to support it is challenging. The best way would be
> to create a WPAD file that tells browsers to use "HTTPS" instead of "PROXY".
> Then you can just use Proxy-Authentication using Basic and you'd be all set.

Hi,
Is this secure proxy well supported by other applications than
browsers in general (eg: wget, curl, yum, git, svn, php, ...)?
Thanks,
-- 
Mathieu Peltier


From squid3 at treenet.co.nz  Wed Dec  6 09:58:28 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 6 Dec 2017 22:58:28 +1300
Subject: [squid-users] Secure basic authentication on Squid
In-Reply-To: <CACjeFCD4a-NCk+EedPuDFh7+hFvUFOwX1r_HXthO3D1aHoOkBw@mail.gmail.com>
References: <3347390832acd6f7.5a257af6@ac-nancy-metz.fr>
 <201712041649.36718.Antony.Stone@squid.open.source.it>
 <3d9cb71755166345.5a25821c@ac-nancy-metz.fr>
 <CAFChrgLWwDbf5OPYMK+xG6eMjFXo2LYD4soX4x2PFwDp+j4egA@mail.gmail.com>
 <CACjeFCD4a-NCk+EedPuDFh7+hFvUFOwX1r_HXthO3D1aHoOkBw@mail.gmail.com>
Message-ID: <4fbaa8d1-ff63-5f0b-7c2a-1da30f218e82@treenet.co.nz>

On 06/12/17 21:32, Mathieu Peltier wrote:
> On Wed, Dec 6, 2017 at 7:01 AM, Jason Haar wrote:
>> To reiterate Alex, "yes you can".
>>
>> Squid supports "proxy over TLS" as well as the old/default "proxy over TCP"
>> - you use the https_port option
>>
>> ...but getting browsers to support it is challenging. The best way would be
>> to create a WPAD file that tells browsers to use "HTTPS" instead of "PROXY".
>> Then you can just use Proxy-Authentication using Basic and you'd be all set.
> 
> Hi,
> Is this secure proxy well supported by other applications than
> browsers in general (eg: wget, curl, yum, git, svn, php, ...)?
> Thanks,
> 

Most of the non-Browser tools have been supporting TLS explicit proxies 
for decades already and have comparativly easy control over it. Browsers 
are the latecomers here.

Amos


From squid3 at treenet.co.nz  Wed Dec  6 10:18:35 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 6 Dec 2017 23:18:35 +1300
Subject: [squid-users] 503 issue after accessing https svn
In-Reply-To: <tencent_03D7B75DA9F92AE086F52489CFB275346009@qq.com>
References: <tencent_03D7B75DA9F92AE086F52489CFB275346009@qq.com>
Message-ID: <8894a268-4e5d-22ff-44a8-47b0f5d56d76@treenet.co.nz>

On 06/12/17 21:07, G~D~Lunatic wrote:
> my squid is a transparent proxy. and the problem is that i can't access 
> the svn server.
> the access.log shows that
> 1512545348.844??? 380 192.168.51.15 TAG_NONE/200 0 CONNECT 
> 192.168.52.6:443 - ORIGINAL_DST/192.168.52.6 -
> 1512545348.920????? 0 192.168.51.15 TAG_NONE/503 4324 OPTIONS 
> https://192.168.52.6/svn/WATMdev/trunk/development/third_period/icapServer 
> - HIER_NONE/- text/html
> 
> but when i use splice step . the access is normal. so i want to know  
> what's the problem.
> 

You will have to check the 503 that Squid is delivering there.

There does not appear to be any server name known, which might have 
something to do with it. Its not easy to generate a proper server 
certificate without a server name.



> Here is my configure
> 
> https_port 192.168.51.200:3129 intercept ssl-bump connection-auth=off 
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
> cert=/usr/local/squid/ssl_cert/myCA.pem 
> key=/usr/local/squid/ssl_cert/myCA.pem options=NO_SSLv3,NO_SSLv2
> 

It may have something to with these restrictions against SSLv2 and v3.

Do you have anything similar on the sslproxy_* options?

> 
> acl broken_sites ssl::server_name matchweb.sports.qq.com
> acl ssl_step1 at_step SslBump1
> acl ssl_step2 at_step SslBump2
> acl ssl_step3 at_step SslBump3
> ssl_bump splice broken_sites
> #ssl_bump splice all
> ssl_bump stare ssl_step1

<https://wiki.squid-cache.org/Features/SslPeekAndSplice#Limitations>
The splice above is likely not possible to be done with the step1 or 
step2 data after this stare happens.
  Note that is a *maybe*. You will have to check the traffic, the error 
messages etc to know for sure what is going on.

> ssl_bump bump ssl_step2
> ssl_bump terminate ssl_step3
> 

Amos


From uhlar at fantomas.sk  Wed Dec  6 10:57:30 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 6 Dec 2017 11:57:30 +0100
Subject: [squid-users] Secure basic authentication on Squid
In-Reply-To: <4fbaa8d1-ff63-5f0b-7c2a-1da30f218e82@treenet.co.nz>
References: <3347390832acd6f7.5a257af6@ac-nancy-metz.fr>
 <201712041649.36718.Antony.Stone@squid.open.source.it>
 <3d9cb71755166345.5a25821c@ac-nancy-metz.fr>
 <CAFChrgLWwDbf5OPYMK+xG6eMjFXo2LYD4soX4x2PFwDp+j4egA@mail.gmail.com>
 <CACjeFCD4a-NCk+EedPuDFh7+hFvUFOwX1r_HXthO3D1aHoOkBw@mail.gmail.com>
 <4fbaa8d1-ff63-5f0b-7c2a-1da30f218e82@treenet.co.nz>
Message-ID: <20171206105730.GB4940@fantomas.sk>

>>On Wed, Dec 6, 2017 at 7:01 AM, Jason Haar wrote:
>>>To reiterate Alex, "yes you can".
>>>
>>>Squid supports "proxy over TLS" as well as the old/default "proxy over TCP"
>>>- you use the https_port option
>>>
>>>...but getting browsers to support it is challenging. The best way would be
>>>to create a WPAD file that tells browsers to use "HTTPS" instead of "PROXY".
>>>Then you can just use Proxy-Authentication using Basic and you'd be all set.

>On 06/12/17 21:32, Mathieu Peltier wrote:
>>Is this secure proxy well supported by other applications than
>>browsers in general (eg: wget, curl, yum, git, svn, php, ...)?
>>Thanks,

On 06.12.17 22:58, Amos Jeffries wrote:
>Most of the non-Browser tools have been supporting TLS explicit 
>proxies for decades already and have comparativly easy control over 
>it. Browsers are the latecomers here.

but they mostly do not support WPAD, because they do not support javascript.

there is sw called libproxy that supports at least the part needed for WPAD
but I'm not sure how many of those tools support it.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Honk if you love peace and quiet. 


From yvoinov at gmail.com  Wed Dec  6 12:10:44 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 6 Dec 2017 18:10:44 +0600
Subject: [squid-users] Secure basic authentication on Squid
In-Reply-To: <20171206105730.GB4940@fantomas.sk>
References: <3347390832acd6f7.5a257af6@ac-nancy-metz.fr>
 <201712041649.36718.Antony.Stone@squid.open.source.it>
 <3d9cb71755166345.5a25821c@ac-nancy-metz.fr>
 <CAFChrgLWwDbf5OPYMK+xG6eMjFXo2LYD4soX4x2PFwDp+j4egA@mail.gmail.com>
 <CACjeFCD4a-NCk+EedPuDFh7+hFvUFOwX1r_HXthO3D1aHoOkBw@mail.gmail.com>
 <4fbaa8d1-ff63-5f0b-7c2a-1da30f218e82@treenet.co.nz>
 <20171206105730.GB4940@fantomas.sk>
Message-ID: <26767ea7-7f55-b18c-0493-8962225519ec@gmail.com>



06.12.2017 16:57, Matus UHLAR - fantomas ?????:
>>> On Wed, Dec 6, 2017 at 7:01 AM, Jason Haar wrote:
>>>> To reiterate Alex, "yes you can".
>>>>
>>>> Squid supports "proxy over TLS" as well as the old/default "proxy
>>>> over TCP"
>>>> - you use the https_port option
>>>>
>>>> ...but getting browsers to support it is challenging. The best way
>>>> would be
>>>> to create a WPAD file that tells browsers to use "HTTPS" instead of
>>>> "PROXY".
>>>> Then you can just use Proxy-Authentication using Basic and you'd be
>>>> all set.
>
>> On 06/12/17 21:32, Mathieu Peltier wrote:
>>> Is this secure proxy well supported by other applications than
>>> browsers in general (eg: wget, curl, yum, git, svn, php, ...)?
>>> Thanks,
>
> On 06.12.17 22:58, Amos Jeffries wrote:
>> Most of the non-Browser tools have been supporting TLS explicit
>> proxies for decades already and have comparativly easy control over
>> it. Browsers are the latecomers here.
>
> but they mostly do not support WPAD, because they do not support
> javascript.
>
> there is sw called libproxy that supports at least the part needed for
> WPAD
> but I'm not sure how many of those tools support it.
>
.... however CLI tools often understand http_proxy/https_proxy
environment variables.....

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171206/1c890631/attachment.sig>

From aismel.valle at museomusica.cult.cu  Wed Dec  6 14:59:42 2017
From: aismel.valle at museomusica.cult.cu (aismel.valle at museomusica.cult.cu)
Date: Wed, 6 Dec 2017 09:59:42 -0500
Subject: [squid-users] Problem using auth digest
Message-ID: <1fc11f9230e9aeb921f415aa0379d439.squirrel@192.168.100.13>

Hi guys,

well i implement the auth digest and work's fine only with the browser,
when i config the internet download manager for download files have
problems always show me the form authentication and don't accept the
credentials i know the data is fine because when i use the seem
credentials in the browser it's work.

Ideas???

Thanks any help

Best regards





From hugo.saavedra.oteiza at gmail.com  Wed Dec  6 16:38:24 2017
From: hugo.saavedra.oteiza at gmail.com (Hugo Saavedra)
Date: Wed, 6 Dec 2017 13:38:24 -0300
Subject: [squid-users] SSL TAG_NONE/503 errors
Message-ID: <CAL+iNzg5ca4KHQ6XTmMc=Dj0w6+W-oKRJo8foJbb+VQX3cj9Nw@mail.gmail.com>

Hi All,

We have the following setup of a transparent squid box:
OS: CentOS release 6.9 (Final)
Squid Cache: Version 3.5.26-20170625-r14174
Compile options:
   '--with-included-ltdl' '--enable-icap-client'
'--enable-delay-pools' '--with-openssl' '--enable-ssl-crtd'
'--enable-icmp' '--enable-snmp' '--prefix=/usr'
'--includedir=/usr/include' '--datadir=/usr/share'
'--bindir=/usr/sbin' '--libexecdir=/usr/lib/squid'
'--localstatedir=/var' '--sysconfdir=/etc/squid'
--enable-ltdl-convenience

Endpoints are redirected to the Squid box using a policy route for
TCP80/443 on a Fortigate firewall. All http/80 traffic works well. We
are using ssl bump for ssl, but there is an strange behavior, some
websites opens well, but some ones breaks and getting TAG_NONE/503
errors in the access log:

1512561423.930      1 192.168.1.108 TAG_NONE/503 31435 POST
https://api.chatlio.com/v1/p/visitor/session/new - HIER_NONE/-
text/html
1512562220.870      1 192.168.1.158 TAG_NONE/503 12386 GET
https://tile-service.weather.microsoft.com/es-CL/livetile/front/-33.44,-70.65?
- HIER_NONE/- text/html
1512562220.870      1 192.168.1.158 TAG_NONE/503 12386 GET
https://service.weather.microsoft.com/appex/DesktopTile/Badge? -
HIER_NONE/- text/html
1512566858.355    186 192.168.1.104 TAG_NONE/503 31436 GET
https://www.mercantil.com/empresa/reac-importadora-spa/estaci%C3%B3n-central/300469639/esp
- HIER_NONE/- text/html

In the same time-range, other websites loads well

1512561134.548    306 192.168.1.112 TCP_MISS/302 572 GET
https://loadm.exelator.com/load/? - ORIGINAL_DST/63.251.252.12
image/gif
1512561139.701    216 192.168.1.148 TCP_MISS/200 386 POST
https://cloud-ecs.gravityzone.bitdefender.com/hydra-
ORIGINAL_DST/107.20.215.8 application/json
1512561142.180     13 192.168.1.112 TCP_MISS/200 419 GET
https://www.facebook.com/tr/? - ORIGINAL_DST/179.60.193.35 image/gif
1512561142.410    243 192.168.1.112 TCP_MISS/200 286 GET
https://bam.nr-data.net/1/ef1706da28? - ORIGINAL_DST/162.247.242.21
text/javascript


IPTABLES CONFIGURATION
=======================
# PREROUTING INTERCEPT PBR

*nat
:PREROUTING ACCEPT [0:0]
:POSTROUTING ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]
-A PREROUTING -i eth0 -p tcp -m tcp --dport 8080 -j REDIRECT --to-ports 3128
-A PREROUTING -i eth0 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 3128
-A PREROUTING -i eth0 -p tcp -m tcp --dport 443 -j REDIRECT --to-ports 3129
COMMIT

*filter
:INPUT ACCEPT [0:0]
:FORWARD ACCEPT [0:0]
:OUTPUT ACCEPT [0:0]

#WEB
-A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
--dport 80 -j ACCEPT
-A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
--dport 443 -j ACCEPT

-A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
--dport 3128 -j ACCEPT
-A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
--dport 3129 -j ACCEPT
-A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
--dport 3130 -j ACCEPT
-A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
--dport 3131 -j ACCEPT

#default
-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
-A INPUT -p icmp -j ACCEPT
-A INPUT -i lo -j ACCEPT
-A INPUT -j REJECT --reject-with icmp-host-prohibited
-A FORWARD -j REJECT --reject-with icmp-host-prohibited
COMMIT


SQUID CONFIGURATION
====================

#WHITE LIST
acl exclWL url_regex "/etc/squid/white_url.squid"
acl neoWL url_regex "/etc/squid/neowl.squid"
http_access allow exclWL
http_access allow neoWL
cache deny exclWL
cache deny neoWL
always_direct allow exclWL
always_direct allow neoWL

#Malicious URLs
acl dom url_regex "/etc/squid/dom.squid"
acl cc url_regex "/etc/squid/cc.squid"
http_access deny dom
http_access deny cc

#BLACK LIST
acl exclBL url_regex "/etc/squid/black_url.squid"
acl neoBL url_regex "/etc/squid/neobl.squid"
http_access deny exclBL
http_access deny neoBL

#ACLS BASE
acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly
plugged) machines
acl SSL_ports port 443
acl SSL_ports port 3129
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT
acl HTTPS proto HTTPS

include /etc/squid/acls_whitelist.conf
acl useragent browser "/etc/squid/useragent.squid"
range_offset_limit 0 !useragent
minimum_object_size 0 bytes
maximum_object_size 3 GB
quick_abort_min -1
delay_pools 1
delay_class 1 1
delay_parameters 1 128000/128000
delay_access 1 deny SSL_ports
delay_access 1 allow !useragent
delay_access 1 deny all

#cache conf
max_filedescriptors 24576
memory_cache_mode disk
cache_mem 0 MB
cache allow all
minimum_object_size 0 bytes
maximum_object_size 20 MB
sslproxy_flags DONT_VERIFY_PEER
connect_timeout 8 seconds

http_access deny !Safe_ports
http_access deny CONNECT !SSL_ports
http_access allow localhost manager
http_access deny manager
http_access allow localnet
http_access allow localhost
http_access deny all
reply_header_access Alternate-Protocol deny all

http_port 3130
http_port 3131 ssl-bump cert=/etc/squid/ssl_cert/SIC.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
http_port 3128 intercept
https_port 3129 intercept ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=16MB cert=/etc/squid/ssl_cert/SIC.pem

cache_dir ufs /var/cache/squid 9000 16 256
cache_store_log /var/log/squid/store.log
cache_effective_user squid
visible_hostname Proxy

refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 2     20%     10
refresh_pattern .               2       20%     10      ignore-reload
override-expire ignore-no-cache ignore-no-store store-stale
ignore-private ignore-must-revalidate ignore-auth
refresh_pattern -i
\.(dmg|msi|deb|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff|pdf)$ 1
20% 4 override-expire ignore-no-cache ignore-no-store ignore-private
reload-into-ims


#SSL BUMP
include /etc/squid/ssl.conf

#LOGGING
access_log /var/log/squid/access.log
access_log /var/log/squid/access_c2.log cc
access_log /var/log/squid/access_c2.log dom
access_log /var/log/squid/splc.log excludeSSL
cache_log /dev/null
coredump_dir /var/cache/squid

#ICAP
icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_header X-Authenticated-User
icap_service service_req reqmod_precache bypass=1
icap://127.0.0.1:1344/squidclamav
adaptation_access service_req allow useragent
icap_service service_resp respmod_precache bypass=1
icap://127.0.0.1:1344/squidclamav
adaptation_access service_resp allow useragent

#X FORWARDED FOR
forwarded_for on

SSL.conf
=======

sslproxy_foreign_intermediate_certs /etc/squid/intermediate_ca.pem
sslproxy_cafile /etc/squid/intermediate_ca.pem
sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 16MB
sslcrtd_children 16 startup=5 idle=1

acl FakeCert ssl::server_name .apple.com
acl FakeCert ssl::server_name .icloud.com
acl FakeCert ssl::server_name .mzstatic.com
acl FakeCert ssl::server_name .dropbox.com
acl ssl_step1 at_step SslBump1
acl ssl_step2 at_step SslBump2
acl ssl_step3 at_step SslBump3

ssl_bump peek ssl_step1
ssl_bump splice GlobalWhitelistDSTNet
ssl_bump splice GlobalWhitelistDomainsRx
ssl_bump splice GlobalWhitelistDomains
ssl_bump splice FakeCert
ssl_bump bump ssl_step2 all
ssl_bump splice all
sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression
sslproxy_cipher
ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:!aNULL:!eNULL
sslproxy_flags DONT_VERIFY_PEER
sslproxy_cert_error allow all
sslproxy_cert_error deny all

acls_whitelist.conf
=============

acl WindowsUpdates dstdomain officecdn.microsoft.com
acl WindowsUpdates dstdomain windowsupdate.microsoft.com
acl WindowsUpdates dstdomain ntservicepack.microsoft.com
acl WindowsUpdates dstdomain download.microsoft.com
acl WindowsUpdates dstdomain .windowsupdate.com
acl WindowsUpdates dstdomain .windowsupdate.net
acl WindowsUpdates dstdomain .update.microsoft.com
acl WindowsUpdates dstdomain .mp.microsoft.com
acl WindowsUpdates dstdomain .ws.microsoft.com
acl GlobalWhitelistDomains dstdomain "/etc/squid/acls_whitelist.dstdomain.conf"
acl GlobalWhitelistDSTNet dst "/etc/squid/acls_whitelist.dst.conf"
acl GlobalWhitelistDomainsRx dstdom_regex -i
"/etc/squid/acls_whitelist.dstdom_regex.conf"
acl GlobalWhitelistBrowsers browser -i "/etc/squid/acls_whitelist.browser.conf"
http_access allow GlobalWhitelistDomains
url_rewrite_access deny GlobalWhitelistDomains
http_access allow GlobalWhitelistDSTNet
url_rewrite_access deny GlobalWhitelistDSTNet
http_access allow GlobalWhitelistDomainsRx
url_rewrite_access deny GlobalWhitelistDomainsRx
http_access allow GlobalWhitelistBrowsers


Any one with the same TAG_NONE/503 error, please help!?

Regards,
Hugo


From flashdown at data-core.org  Wed Dec  6 17:51:45 2017
From: flashdown at data-core.org (Enrico Heine)
Date: Wed, 06 Dec 2017 18:51:45 +0100
Subject: [squid-users] SSL TAG_NONE/503 errors
In-Reply-To: <CAL+iNzg5ca4KHQ6XTmMc=Dj0w6+W-oKRJo8foJbb+VQX3cj9Nw@mail.gmail.com>
References: <CAL+iNzg5ca4KHQ6XTmMc=Dj0w6+W-oKRJo8foJbb+VQX3cj9Nw@mail.gmail.com>
Message-ID: <0ED074EB-141F-42C6-B332-9AE8F9F92813@data-core.org>

Hi,

Can you confirm that squid is able to resolve these hostnames? If not try browsing to them without https and check if squid gives you an error message.

Did you check the cache.log as well?

Br Enrico

Am 6. Dezember 2017 17:38:24 MEZ schrieb Hugo Saavedra <hugo.saavedra.oteiza at gmail.com>:
>Hi All,
>
>We have the following setup of a transparent squid box:
>OS: CentOS release 6.9 (Final)
>Squid Cache: Version 3.5.26-20170625-r14174
>Compile options:
>   '--with-included-ltdl' '--enable-icap-client'
>'--enable-delay-pools' '--with-openssl' '--enable-ssl-crtd'
>'--enable-icmp' '--enable-snmp' '--prefix=/usr'
>'--includedir=/usr/include' '--datadir=/usr/share'
>'--bindir=/usr/sbin' '--libexecdir=/usr/lib/squid'
>'--localstatedir=/var' '--sysconfdir=/etc/squid'
>--enable-ltdl-convenience
>
>Endpoints are redirected to the Squid box using a policy route for
>TCP80/443 on a Fortigate firewall. All http/80 traffic works well. We
>are using ssl bump for ssl, but there is an strange behavior, some
>websites opens well, but some ones breaks and getting TAG_NONE/503
>errors in the access log:
>
>1512561423.930      1 192.168.1.108 TAG_NONE/503 31435 POST
>https://api.chatlio.com/v1/p/visitor/session/new - HIER_NONE/-
>text/html
>1512562220.870      1 192.168.1.158 TAG_NONE/503 12386 GET
>https://tile-service.weather.microsoft.com/es-CL/livetile/front/-33.44,-70.65?
>- HIER_NONE/- text/html
>1512562220.870      1 192.168.1.158 TAG_NONE/503 12386 GET
>https://service.weather.microsoft.com/appex/DesktopTile/Badge? -
>HIER_NONE/- text/html
>1512566858.355    186 192.168.1.104 TAG_NONE/503 31436 GET
>https://www.mercantil.com/empresa/reac-importadora-spa/estaci%C3%B3n-central/300469639/esp
>- HIER_NONE/- text/html
>
>In the same time-range, other websites loads well
>
>1512561134.548    306 192.168.1.112 TCP_MISS/302 572 GET
>https://loadm.exelator.com/load/? - ORIGINAL_DST/63.251.252.12
>image/gif
>1512561139.701    216 192.168.1.148 TCP_MISS/200 386 POST
>https://cloud-ecs.gravityzone.bitdefender.com/hydra-
>ORIGINAL_DST/107.20.215.8 application/json
>1512561142.180     13 192.168.1.112 TCP_MISS/200 419 GET
>https://www.facebook.com/tr/? - ORIGINAL_DST/179.60.193.35 image/gif
>1512561142.410    243 192.168.1.112 TCP_MISS/200 286 GET
>https://bam.nr-data.net/1/ef1706da28? - ORIGINAL_DST/162.247.242.21
>text/javascript
>
>
>IPTABLES CONFIGURATION
>=======================
># PREROUTING INTERCEPT PBR
>
>*nat
>:PREROUTING ACCEPT [0:0]
>:POSTROUTING ACCEPT [0:0]
>:OUTPUT ACCEPT [0:0]
>-A PREROUTING -i eth0 -p tcp -m tcp --dport 8080 -j REDIRECT --to-ports
>3128
>-A PREROUTING -i eth0 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports
>3128
>-A PREROUTING -i eth0 -p tcp -m tcp --dport 443 -j REDIRECT --to-ports
>3129
>COMMIT
>
>*filter
>:INPUT ACCEPT [0:0]
>:FORWARD ACCEPT [0:0]
>:OUTPUT ACCEPT [0:0]
>
>#WEB
>-A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>--dport 80 -j ACCEPT
>-A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>--dport 443 -j ACCEPT
>
>-A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>--dport 3128 -j ACCEPT
>-A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>--dport 3129 -j ACCEPT
>-A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>--dport 3130 -j ACCEPT
>-A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>--dport 3131 -j ACCEPT
>
>#default
>-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
>-A INPUT -p icmp -j ACCEPT
>-A INPUT -i lo -j ACCEPT
>-A INPUT -j REJECT --reject-with icmp-host-prohibited
>-A FORWARD -j REJECT --reject-with icmp-host-prohibited
>COMMIT
>
>
>SQUID CONFIGURATION
>====================
>
>#WHITE LIST
>acl exclWL url_regex "/etc/squid/white_url.squid"
>acl neoWL url_regex "/etc/squid/neowl.squid"
>http_access allow exclWL
>http_access allow neoWL
>cache deny exclWL
>cache deny neoWL
>always_direct allow exclWL
>always_direct allow neoWL
>
>#Malicious URLs
>acl dom url_regex "/etc/squid/dom.squid"
>acl cc url_regex "/etc/squid/cc.squid"
>http_access deny dom
>http_access deny cc
>
>#BLACK LIST
>acl exclBL url_regex "/etc/squid/black_url.squid"
>acl neoBL url_regex "/etc/squid/neobl.squid"
>http_access deny exclBL
>http_access deny neoBL
>
>#ACLS BASE
>acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
>acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
>acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
>acl localnet src fc00::/7       # RFC 4193 local private network range
>acl localnet src fe80::/10      # RFC 4291 link-local (directly
>plugged) machines
>acl SSL_ports port 443
>acl SSL_ports port 3129
>acl Safe_ports port 80          # http
>acl Safe_ports port 21          # ftp
>acl Safe_ports port 443         # https
>acl Safe_ports port 70          # gopher
>acl Safe_ports port 210         # wais
>acl Safe_ports port 1025-65535  # unregistered ports
>acl Safe_ports port 280         # http-mgmt
>acl Safe_ports port 488         # gss-http
>acl Safe_ports port 591         # filemaker
>acl Safe_ports port 777         # multiling http
>acl CONNECT method CONNECT
>acl HTTPS proto HTTPS
>
>include /etc/squid/acls_whitelist.conf
>acl useragent browser "/etc/squid/useragent.squid"
>range_offset_limit 0 !useragent
>minimum_object_size 0 bytes
>maximum_object_size 3 GB
>quick_abort_min -1
>delay_pools 1
>delay_class 1 1
>delay_parameters 1 128000/128000
>delay_access 1 deny SSL_ports
>delay_access 1 allow !useragent
>delay_access 1 deny all
>
>#cache conf
>max_filedescriptors 24576
>memory_cache_mode disk
>cache_mem 0 MB
>cache allow all
>minimum_object_size 0 bytes
>maximum_object_size 20 MB
>sslproxy_flags DONT_VERIFY_PEER
>connect_timeout 8 seconds
>
>http_access deny !Safe_ports
>http_access deny CONNECT !SSL_ports
>http_access allow localhost manager
>http_access deny manager
>http_access allow localnet
>http_access allow localhost
>http_access deny all
>reply_header_access Alternate-Protocol deny all
>
>http_port 3130
>http_port 3131 ssl-bump cert=/etc/squid/ssl_cert/SIC.pem
>generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>http_port 3128 intercept
>https_port 3129 intercept ssl-bump generate-host-certificates=on
>dynamic_cert_mem_cache_size=16MB cert=/etc/squid/ssl_cert/SIC.pem
>
>cache_dir ufs /var/cache/squid 9000 16 256
>cache_store_log /var/log/squid/store.log
>cache_effective_user squid
>visible_hostname Proxy
>
>refresh_pattern ^ftp:           1440    20%     10080
>refresh_pattern ^gopher:        1440    0%      1440
>refresh_pattern -i (/cgi-bin/|\?) 2     20%     10
>refresh_pattern .               2       20%     10      ignore-reload
>override-expire ignore-no-cache ignore-no-store store-stale
>ignore-private ignore-must-revalidate ignore-auth
>refresh_pattern -i
>\.(dmg|msi|deb|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff|pdf)$ 1
>20% 4 override-expire ignore-no-cache ignore-no-store ignore-private
>reload-into-ims
>
>
>#SSL BUMP
>include /etc/squid/ssl.conf
>
>#LOGGING
>access_log /var/log/squid/access.log
>access_log /var/log/squid/access_c2.log cc
>access_log /var/log/squid/access_c2.log dom
>access_log /var/log/squid/splc.log excludeSSL
>cache_log /dev/null
>coredump_dir /var/cache/squid
>
>#ICAP
>icap_enable on
>icap_send_client_ip on
>icap_send_client_username on
>icap_client_username_header X-Authenticated-User
>icap_service service_req reqmod_precache bypass=1
>icap://127.0.0.1:1344/squidclamav
>adaptation_access service_req allow useragent
>icap_service service_resp respmod_precache bypass=1
>icap://127.0.0.1:1344/squidclamav
>adaptation_access service_resp allow useragent
>
>#X FORWARDED FOR
>forwarded_for on
>
>SSL.conf
>=======
>
>sslproxy_foreign_intermediate_certs /etc/squid/intermediate_ca.pem
>sslproxy_cafile /etc/squid/intermediate_ca.pem
>sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 16MB
>sslcrtd_children 16 startup=5 idle=1
>
>acl FakeCert ssl::server_name .apple.com
>acl FakeCert ssl::server_name .icloud.com
>acl FakeCert ssl::server_name .mzstatic.com
>acl FakeCert ssl::server_name .dropbox.com
>acl ssl_step1 at_step SslBump1
>acl ssl_step2 at_step SslBump2
>acl ssl_step3 at_step SslBump3
>
>ssl_bump peek ssl_step1
>ssl_bump splice GlobalWhitelistDSTNet
>ssl_bump splice GlobalWhitelistDomainsRx
>ssl_bump splice GlobalWhitelistDomains
>ssl_bump splice FakeCert
>ssl_bump bump ssl_step2 all
>ssl_bump splice all
>sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression
>sslproxy_cipher
>ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:!aNULL:!eNULL
>sslproxy_flags DONT_VERIFY_PEER
>sslproxy_cert_error allow all
>sslproxy_cert_error deny all
>
>acls_whitelist.conf
>=============
>
>acl WindowsUpdates dstdomain officecdn.microsoft.com
>acl WindowsUpdates dstdomain windowsupdate.microsoft.com
>acl WindowsUpdates dstdomain ntservicepack.microsoft.com
>acl WindowsUpdates dstdomain download.microsoft.com
>acl WindowsUpdates dstdomain .windowsupdate.com
>acl WindowsUpdates dstdomain .windowsupdate.net
>acl WindowsUpdates dstdomain .update.microsoft.com
>acl WindowsUpdates dstdomain .mp.microsoft.com
>acl WindowsUpdates dstdomain .ws.microsoft.com
>acl GlobalWhitelistDomains dstdomain
>"/etc/squid/acls_whitelist.dstdomain.conf"
>acl GlobalWhitelistDSTNet dst "/etc/squid/acls_whitelist.dst.conf"
>acl GlobalWhitelistDomainsRx dstdom_regex -i
>"/etc/squid/acls_whitelist.dstdom_regex.conf"
>acl GlobalWhitelistBrowsers browser -i
>"/etc/squid/acls_whitelist.browser.conf"
>http_access allow GlobalWhitelistDomains
>url_rewrite_access deny GlobalWhitelistDomains
>http_access allow GlobalWhitelistDSTNet
>url_rewrite_access deny GlobalWhitelistDSTNet
>http_access allow GlobalWhitelistDomainsRx
>url_rewrite_access deny GlobalWhitelistDomainsRx
>http_access allow GlobalWhitelistBrowsers
>
>
>Any one with the same TAG_NONE/503 error, please help!?
>
>Regards,
>Hugo
>_______________________________________________
>squid-users mailing list
>squid-users at lists.squid-cache.org
>http://lists.squid-cache.org/listinfo/squid-users

-- 
Diese Nachricht wurde von meinem Android-Ger?t mit K-9 Mail gesendet.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171206/76130600/attachment.htm>

From hugo.saavedra.oteiza at gmail.com  Wed Dec  6 18:45:27 2017
From: hugo.saavedra.oteiza at gmail.com (Hugo Saavedra)
Date: Wed, 6 Dec 2017 15:45:27 -0300
Subject: [squid-users] SSL TAG_NONE/503 errors
In-Reply-To: <0ED074EB-141F-42C6-B332-9AE8F9F92813@data-core.org>
References: <CAL+iNzg5ca4KHQ6XTmMc=Dj0w6+W-oKRJo8foJbb+VQX3cj9Nw@mail.gmail.com>
 <0ED074EB-141F-42C6-B332-9AE8F9F92813@data-core.org>
Message-ID: <CAL+iNzj9ySoJQSssmiHak59ga7vmz-sFKe0tw6Q9WKX64VW6nA@mail.gmail.com>

Hi,
yes, squid is able to resolve those domains. Currently we have
cache.log disabled for performance. any clues?

Regards,
Hugo

2017-12-06 14:51 GMT-03:00 Enrico Heine <flashdown at data-core.org>:
> Hi,
>
> Can you confirm that squid is able to resolve these hostnames? If not try
> browsing to them without https and check if squid gives you an error
> message.
>
> Did you check the cache.log as well?
>
> Br Enrico
>
> Am 6. Dezember 2017 17:38:24 MEZ schrieb Hugo Saavedra
> <hugo.saavedra.oteiza at gmail.com>:
>>
>> Hi All,
>>
>> We have the following setup of a transparent squid box:
>> OS: CentOS release 6.9 (Final)
>> Squid Cache: Version 3.5.26-20170625-r14174
>> Compile options:
>>    '--with-included-ltdl' '--enable-icap-client'
>> '--enable-delay-pools' '--with-openssl' '--enable-ssl-crtd'
>> '--enable-icmp' '--enable-snmp' '--prefix=/usr'
>> '--includedir=/usr/include' '--datadir=/usr/share'
>> '--bindir=/usr/sbin' '--libexecdir=/usr/lib/squid'
>> '--localstatedir=/var' '--sysconfdir=/etc/squid'
>> --enable-ltdl-convenience
>>
>> Endpoints are redirected to the Squid box using a policy route for
>> TCP80/443 on a Fortigate firewall. All http/80 traffic works well. We
>> are using ssl bump for ssl, but there is an strange behavior, some
>> websites opens well, but some ones breaks and getting TAG_NONE/503
>> errors in the access log:
>>
>> 1512561423.930      1 192.168.1.108 TAG_NONE/503 31435 POST
>> https://api.chatlio.com/v1/p/visitor/session/new - HIER_NONE/-
>> text/html
>> 1512562220.870      1 192.168.1.158 TAG_NONE/503 12386 GET
>>
>> https://tile-service.weather.microsoft.com/es-CL/livetile/front/-33.44,-70.65?
>> - HIER_NONE/- text/html
>> 1512562220.870      1 192.168.1.158 TAG_NONE/503 12386 GET
>> https://service.weather.microsoft.com/appex/DesktopTile/Badge? -
>> HIER_NONE/- text/html
>> 1512566858.355    186 192.168.1.104 TAG_NONE/503 31436 GET
>>
>> https://www.mercantil.com/empresa/reac-importadora-spa/estaci%C3%B3n-central/300469639/esp
>> - HIER_NONE/- text/html
>>
>> In the same time-range, other websites loads well
>>
>> 1512561134.548    306 192.168.1.112 TCP_MISS/302 572 GET
>> https://loadm.exelator.com/load/? - ORIGINAL_DST/63.251.252.12
>> image/gif
>> 1512561139.701    216 192.168.1.148 TCP_MISS/200 386 POST
>> https://cloud-ecs.gravityzone.bitdefender.com/hydra-
>> ORIGINAL_DST/107.20.215.8 application/json
>> 1512561142.180     13 192.168.1.112 TCP_MISS/200 419 GET
>> https://www.facebook.com/tr/? - ORIGINAL_DST/179.60.193.35 image/gif
>> 1512561142.410    243 192.168.1.112 TCP_MISS/200 286 GET
>> https://bam.nr-data.net/1/ef1706da28? - ORIGINAL_DST/162.247.242.21
>> text/javascript
>>
>>
>> IPTABLES CONFIGURATION
>> =======================
>> # PREROUTING INTERCEPT PBR
>>
>> *nat
>> :PREROUTING ACCEPT [0:0]
>> :POSTROUTING ACCEPT [0:0]
>> :OUTPUT ACCEPT [0:0]
>> -A PREROUTING -i eth0 -p tcp -m tcp --dport 8080 -j REDIRECT --to-ports
>> 3128
>> -A PREROUTING -i eth0 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 3128
>> -A PREROUTING -i eth0 -p tcp -m tcp --dport 443 -j REDIRECT --to-ports
>> 3129
>> COMMIT
>>
>> *filter
>> :INPUT ACCEPT [0:0]
>> :FORWARD ACCEPT [0:0]
>> :OUTPUT ACCEPT [0:0]
>>
>> #WEB
>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>> --dport 80 -j ACCEPT
>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>> --dport 443 -j ACCEPT
>>
>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>> --dport 3128 -j ACCEPT
>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>> --dport 3129 -j ACCEPT
>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>> --dport 3130 -j ACCEPT
>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>> --dport 3131 -j ACCEPT
>>
>> #default
>> -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
>> -A INPUT -p icmp -j ACCEPT
>> -A INPUT -i lo -j ACCEPT
>> -A INPUT -j REJECT --reject-with icmp-host-prohibited
>> -A FORWARD -j REJECT --reject-with icmp-host-prohibited
>> COMMIT
>>
>>
>> SQUID CONFIGURATION
>> ====================
>>
>> #WHITE LIST
>> acl exclWL url_regex "/etc/squid/white_url.squid"
>> acl neoWL url_regex "/etc/squid/neowl.squid"
>> http_access allow exclWL
>> http_access allow neoWL
>> cache deny exclWL
>> cache deny neoWL
>> always_direct allow exclWL
>> always_direct allow neoWL
>>
>> #Malicious URLs
>> acl dom url_regex "/etc/squid/dom.squid"
>> acl cc url_regex "/etc/squid/cc.squid"
>> http_access deny dom
>> http_access deny cc
>>
>> #BLACK LIST
>> acl exclBL url_regex "/etc/squid/black_url.squid"
>> acl neoBL url_regex "/etc/squid/neobl.squid"
>> http_access deny exclBL
>> http_access deny neoBL
>>
>> #ACLS BASE
>> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
>> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
>> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
>> acl localnet src fc00::/7       # RFC 4193 local private network range
>> acl localnet src fe80::/10      # RFC 4291 link-local (directly
>> plugged) machines
>> acl SSL_ports port 443
>> acl SSL_ports port 3129
>> acl Safe_ports port 80          # http
>> acl Safe_ports port 21          # ftp
>> acl Safe_ports port 443         # https
>> acl Safe_ports port 70          # gopher
>> acl Safe_ports port 210         # wais
>> acl Safe_ports port 1025-65535  # unregistered ports
>> acl Safe_ports port 280         # http-mgmt
>> acl Safe_ports port 488         # gss-http
>> acl Safe_ports port 591         # filemaker
>> acl Safe_ports port 777         # multiling http
>> acl CONNECT method CONNECT
>> acl HTTPS proto HTTPS
>>
>> include /etc/squid/acls_whitelist.conf
>> acl useragent browser "/etc/squid/useragent.squid"
>> range_offset_limit 0 !useragent
>> minimum_object_size 0 bytes
>> maximum_object_size 3 GB
>> quick_abort_min -1
>> delay_pools 1
>> delay_class 1 1
>> delay_parameters 1 128000/128000
>> delay_access 1 deny SSL_ports
>> delay_access 1 allow !useragent
>> delay_access 1 deny all
>>
>> #cache conf
>> max_filedescriptors 24576
>> memory_cache_mode disk
>> cache_mem 0 MB
>> cache allow all
>> minimum_object_size 0 bytes
>> maximum_object_size 20 MB
>> sslproxy_flags DONT_VERIFY_PEER
>> connect_timeout 8 seconds
>>
>> http_access deny !Safe_ports
>> http_access deny CONNECT !SSL_ports
>> http_access allow localhost manager
>> http_access deny manager
>> http_access allow localnet
>> http_access allow localhost
>> http_access deny all
>> reply_header_access Alternate-Protocol deny all
>>
>> http_port 3130
>> http_port 3131 ssl-bump cert=/etc/squid/ssl_cert/SIC.pem
>> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>> http_port 3128 intercept
>> https_port 3129 intercept ssl-bump generate-host-certificates=on
>> dynamic_cert_mem_cache_size=16MB cert=/etc/squid/ssl_cert/SIC.pem
>>
>> cache_dir ufs /var/cache/squid 9000 16 256
>> cache_store_log /var/log/squid/store.log
>> cache_effective_user squid
>> visible_hostname Proxy
>>
>> refresh_pattern ^ftp:           1440    20%     10080
>> refresh_pattern ^gopher:        1440    0%      1440
>> refresh_pattern -i (/cgi-bin/|\?) 2     20%     10
>> refresh_pattern .               2       20%     10      ignore-reload
>> override-expire ignore-no-cache ignore-no-store store-stale
>> ignore-private ignore-must-revalidate ignore-auth
>> refresh_pattern -i
>> \.(dmg|msi|deb|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff|pdf)$ 1
>> 20% 4 override-expire ignore-no-cache ignore-no-store ignore-private
>> reload-into-ims
>>
>>
>> #SSL BUMP
>> include /etc/squid/ssl.conf
>>
>> #LOGGING
>> access_log /var/log/squid/access.log
>> access_log /var/log/squid/access_c2.log cc
>> access_log /var/log/squid/access_c2.log dom
>> access_log /var/log/squid/splc.log excludeSSL
>> cache_log /dev/null
>> coredump_dir /var/cache/squid
>>
>> #ICAP
>> icap_enable on
>> icap_send_client_ip on
>> icap_send_client_username on
>> icap_client_username_header X-Authenticated-User
>> icap_service service_req reqmod_precache bypass=1
>> icap://127.0.0.1:1344/squidclamav
>> adaptation_access service_req allow useragent
>> icap_service service_resp respmod_precache bypass=1
>> icap://127.0.0.1:1344/squidclamav
>> adaptation_access service_resp allow useragent
>>
>> #X FORWARDED FOR
>> forwarded_for on
>>
>> SSL.conf
>> =======
>>
>> sslproxy_foreign_intermediate_certs /etc/squid/intermediate_ca.pem
>> sslproxy_cafile /etc/squid/intermediate_ca.pem
>> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 16MB
>> sslcrtd_children 16 startup=5 idle=1
>>
>> acl FakeCert ssl::server_name .apple.com
>> acl FakeCert ssl::server_name .icloud.com
>> acl FakeCert ssl::server_name .mzstatic.com
>> acl FakeCert ssl::server_name .dropbox.com
>> acl ssl_step1 at_step SslBump1
>> acl ssl_step2 at_step SslBump2
>> acl ssl_step3 at_step SslBump3
>>
>> ssl_bump peek ssl_step1
>> ssl_bump splice GlobalWhitelistDSTNet
>> ssl_bump splice GlobalWhitelistDomainsRx
>> ssl_bump splice GlobalWhitelistDomains
>> ssl_bump splice FakeCert
>> ssl_bump bump ssl_step2 all
>> ssl_bump splice all
>> sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression
>> sslproxy_cipher
>>
>> ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:!aNULL:!eNULL
>> sslproxy_flags DONT_VERIFY_PEER
>> sslproxy_cert_error allow all
>> sslproxy_cert_error deny all
>>
>> acls_whitelist.conf
>> =============
>>
>> acl WindowsUpdates dstdomain officecdn.microsoft.com
>> acl WindowsUpdates dstdomain windowsupdate.microsoft.com
>> acl WindowsUpdates dstdomain ntservicepack.microsoft.com
>> acl WindowsUpdates dstdomain download.microsoft.com
>> acl WindowsUpdates dstdomain .windowsupdate.com
>> acl WindowsUpdates dstdomain .windowsupdate.net
>> acl WindowsUpdates dstdomain .update.microsoft.com
>> acl WindowsUpdates dstdomain .mp.microsoft.com
>> acl WindowsUpdates dstdomain .ws.microsoft.com
>> acl GlobalWhitelistDomains dstdomain
>> "/etc/squid/acls_whitelist.dstdomain.conf"
>> acl GlobalWhitelistDSTNet dst "/etc/squid/acls_whitelist.dst.conf"
>> acl GlobalWhitelistDomainsRx dstdom_regex -i
>> "/etc/squid/acls_whitelist.dstdom_regex.conf"
>> acl GlobalWhitelistBrowsers browser -i
>> "/etc/squid/acls_whitelist.browser.conf"
>> http_access allow GlobalWhitelistDomains
>> url_rewrite_access deny GlobalWhitelistDomains
>> http_access allow GlobalWhitelistDSTNet
>> url_rewrite_access deny GlobalWhitelistDSTNet
>> http_access allow GlobalWhitelistDomainsRx
>> url_rewrite_access deny GlobalWhitelistDomainsRx
>> http_access allow GlobalWhitelistBrowsers
>>
>>
>> Any one with the same TAG_NONE/503 error, please help!?
>>
>> Regards,
>> Hugo
>> ________________________________
>>
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
>
> --
> Diese Nachricht wurde von meinem Android-Ger?t mit K-9 Mail gesendet.



-- 
Saludos,
Hugo Saavedra


From rousskov at measurement-factory.com  Wed Dec  6 18:54:20 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 6 Dec 2017 11:54:20 -0700
Subject: [squid-users] SSL TAG_NONE/503 errors
In-Reply-To: <CAL+iNzj9ySoJQSssmiHak59ga7vmz-sFKe0tw6Q9WKX64VW6nA@mail.gmail.com>
References: <CAL+iNzg5ca4KHQ6XTmMc=Dj0w6+W-oKRJo8foJbb+VQX3cj9Nw@mail.gmail.com>
 <0ED074EB-141F-42C6-B332-9AE8F9F92813@data-core.org>
 <CAL+iNzj9ySoJQSssmiHak59ga7vmz-sFKe0tw6Q9WKX64VW6nA@mail.gmail.com>
Message-ID: <a1a0e0d8-e85d-2d24-dfae-464a258b2cec@measurement-factory.com>

On 12/06/2017 11:45 AM, Hugo Saavedra wrote:

> Currently we have cache.log disabled for performance. 

With default debug_options, cache.log should not affect performance. If
it does in your setup, then there is probably a problem that you should
solve (without disabling cache.log).


> any clues?

You are probably not supplying enough information for others to guess
what the problem is. Enabling cache.log may be the best next step. You
can also try logging %err_code/%err_detail to access.log but not all
errors populate those two logformat %codes so YMMV.

Alex.


> 2017-12-06 14:51 GMT-03:00 Enrico Heine <flashdown at data-core.org>:
>> Hi,
>>
>> Can you confirm that squid is able to resolve these hostnames? If not try
>> browsing to them without https and check if squid gives you an error
>> message.
>>
>> Did you check the cache.log as well?
>>
>> Br Enrico
>>
>> Am 6. Dezember 2017 17:38:24 MEZ schrieb Hugo Saavedra
>> <hugo.saavedra.oteiza at gmail.com>:
>>>
>>> Hi All,
>>>
>>> We have the following setup of a transparent squid box:
>>> OS: CentOS release 6.9 (Final)
>>> Squid Cache: Version 3.5.26-20170625-r14174
>>> Compile options:
>>>    '--with-included-ltdl' '--enable-icap-client'
>>> '--enable-delay-pools' '--with-openssl' '--enable-ssl-crtd'
>>> '--enable-icmp' '--enable-snmp' '--prefix=/usr'
>>> '--includedir=/usr/include' '--datadir=/usr/share'
>>> '--bindir=/usr/sbin' '--libexecdir=/usr/lib/squid'
>>> '--localstatedir=/var' '--sysconfdir=/etc/squid'
>>> --enable-ltdl-convenience
>>>
>>> Endpoints are redirected to the Squid box using a policy route for
>>> TCP80/443 on a Fortigate firewall. All http/80 traffic works well. We
>>> are using ssl bump for ssl, but there is an strange behavior, some
>>> websites opens well, but some ones breaks and getting TAG_NONE/503
>>> errors in the access log:
>>>
>>> 1512561423.930      1 192.168.1.108 TAG_NONE/503 31435 POST
>>> https://api.chatlio.com/v1/p/visitor/session/new - HIER_NONE/-
>>> text/html
>>> 1512562220.870      1 192.168.1.158 TAG_NONE/503 12386 GET
>>>
>>> https://tile-service.weather.microsoft.com/es-CL/livetile/front/-33.44,-70.65?
>>> - HIER_NONE/- text/html
>>> 1512562220.870      1 192.168.1.158 TAG_NONE/503 12386 GET
>>> https://service.weather.microsoft.com/appex/DesktopTile/Badge? -
>>> HIER_NONE/- text/html
>>> 1512566858.355    186 192.168.1.104 TAG_NONE/503 31436 GET
>>>
>>> https://www.mercantil.com/empresa/reac-importadora-spa/estaci%C3%B3n-central/300469639/esp
>>> - HIER_NONE/- text/html
>>>
>>> In the same time-range, other websites loads well
>>>
>>> 1512561134.548    306 192.168.1.112 TCP_MISS/302 572 GET
>>> https://loadm.exelator.com/load/? - ORIGINAL_DST/63.251.252.12
>>> image/gif
>>> 1512561139.701    216 192.168.1.148 TCP_MISS/200 386 POST
>>> https://cloud-ecs.gravityzone.bitdefender.com/hydra-
>>> ORIGINAL_DST/107.20.215.8 application/json
>>> 1512561142.180     13 192.168.1.112 TCP_MISS/200 419 GET
>>> https://www.facebook.com/tr/? - ORIGINAL_DST/179.60.193.35 image/gif
>>> 1512561142.410    243 192.168.1.112 TCP_MISS/200 286 GET
>>> https://bam.nr-data.net/1/ef1706da28? - ORIGINAL_DST/162.247.242.21
>>> text/javascript
>>>
>>>
>>> IPTABLES CONFIGURATION
>>> =======================
>>> # PREROUTING INTERCEPT PBR
>>>
>>> *nat
>>> :PREROUTING ACCEPT [0:0]
>>> :POSTROUTING ACCEPT [0:0]
>>> :OUTPUT ACCEPT [0:0]
>>> -A PREROUTING -i eth0 -p tcp -m tcp --dport 8080 -j REDIRECT --to-ports
>>> 3128
>>> -A PREROUTING -i eth0 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 3128
>>> -A PREROUTING -i eth0 -p tcp -m tcp --dport 443 -j REDIRECT --to-ports
>>> 3129
>>> COMMIT
>>>
>>> *filter
>>> :INPUT ACCEPT [0:0]
>>> :FORWARD ACCEPT [0:0]
>>> :OUTPUT ACCEPT [0:0]
>>>
>>> #WEB
>>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>>> --dport 80 -j ACCEPT
>>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>>> --dport 443 -j ACCEPT
>>>
>>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>>> --dport 3128 -j ACCEPT
>>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>>> --dport 3129 -j ACCEPT
>>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>>> --dport 3130 -j ACCEPT
>>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>>> --dport 3131 -j ACCEPT
>>>
>>> #default
>>> -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
>>> -A INPUT -p icmp -j ACCEPT
>>> -A INPUT -i lo -j ACCEPT
>>> -A INPUT -j REJECT --reject-with icmp-host-prohibited
>>> -A FORWARD -j REJECT --reject-with icmp-host-prohibited
>>> COMMIT
>>>
>>>
>>> SQUID CONFIGURATION
>>> ====================
>>>
>>> #WHITE LIST
>>> acl exclWL url_regex "/etc/squid/white_url.squid"
>>> acl neoWL url_regex "/etc/squid/neowl.squid"
>>> http_access allow exclWL
>>> http_access allow neoWL
>>> cache deny exclWL
>>> cache deny neoWL
>>> always_direct allow exclWL
>>> always_direct allow neoWL
>>>
>>> #Malicious URLs
>>> acl dom url_regex "/etc/squid/dom.squid"
>>> acl cc url_regex "/etc/squid/cc.squid"
>>> http_access deny dom
>>> http_access deny cc
>>>
>>> #BLACK LIST
>>> acl exclBL url_regex "/etc/squid/black_url.squid"
>>> acl neoBL url_regex "/etc/squid/neobl.squid"
>>> http_access deny exclBL
>>> http_access deny neoBL
>>>
>>> #ACLS BASE
>>> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
>>> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
>>> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
>>> acl localnet src fc00::/7       # RFC 4193 local private network range
>>> acl localnet src fe80::/10      # RFC 4291 link-local (directly
>>> plugged) machines
>>> acl SSL_ports port 443
>>> acl SSL_ports port 3129
>>> acl Safe_ports port 80          # http
>>> acl Safe_ports port 21          # ftp
>>> acl Safe_ports port 443         # https
>>> acl Safe_ports port 70          # gopher
>>> acl Safe_ports port 210         # wais
>>> acl Safe_ports port 1025-65535  # unregistered ports
>>> acl Safe_ports port 280         # http-mgmt
>>> acl Safe_ports port 488         # gss-http
>>> acl Safe_ports port 591         # filemaker
>>> acl Safe_ports port 777         # multiling http
>>> acl CONNECT method CONNECT
>>> acl HTTPS proto HTTPS
>>>
>>> include /etc/squid/acls_whitelist.conf
>>> acl useragent browser "/etc/squid/useragent.squid"
>>> range_offset_limit 0 !useragent
>>> minimum_object_size 0 bytes
>>> maximum_object_size 3 GB
>>> quick_abort_min -1
>>> delay_pools 1
>>> delay_class 1 1
>>> delay_parameters 1 128000/128000
>>> delay_access 1 deny SSL_ports
>>> delay_access 1 allow !useragent
>>> delay_access 1 deny all
>>>
>>> #cache conf
>>> max_filedescriptors 24576
>>> memory_cache_mode disk
>>> cache_mem 0 MB
>>> cache allow all
>>> minimum_object_size 0 bytes
>>> maximum_object_size 20 MB
>>> sslproxy_flags DONT_VERIFY_PEER
>>> connect_timeout 8 seconds
>>>
>>> http_access deny !Safe_ports
>>> http_access deny CONNECT !SSL_ports
>>> http_access allow localhost manager
>>> http_access deny manager
>>> http_access allow localnet
>>> http_access allow localhost
>>> http_access deny all
>>> reply_header_access Alternate-Protocol deny all
>>>
>>> http_port 3130
>>> http_port 3131 ssl-bump cert=/etc/squid/ssl_cert/SIC.pem
>>> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>>> http_port 3128 intercept
>>> https_port 3129 intercept ssl-bump generate-host-certificates=on
>>> dynamic_cert_mem_cache_size=16MB cert=/etc/squid/ssl_cert/SIC.pem
>>>
>>> cache_dir ufs /var/cache/squid 9000 16 256
>>> cache_store_log /var/log/squid/store.log
>>> cache_effective_user squid
>>> visible_hostname Proxy
>>>
>>> refresh_pattern ^ftp:           1440    20%     10080
>>> refresh_pattern ^gopher:        1440    0%      1440
>>> refresh_pattern -i (/cgi-bin/|\?) 2     20%     10
>>> refresh_pattern .               2       20%     10      ignore-reload
>>> override-expire ignore-no-cache ignore-no-store store-stale
>>> ignore-private ignore-must-revalidate ignore-auth
>>> refresh_pattern -i
>>> \.(dmg|msi|deb|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff|pdf)$ 1
>>> 20% 4 override-expire ignore-no-cache ignore-no-store ignore-private
>>> reload-into-ims
>>>
>>>
>>> #SSL BUMP
>>> include /etc/squid/ssl.conf
>>>
>>> #LOGGING
>>> access_log /var/log/squid/access.log
>>> access_log /var/log/squid/access_c2.log cc
>>> access_log /var/log/squid/access_c2.log dom
>>> access_log /var/log/squid/splc.log excludeSSL
>>> cache_log /dev/null
>>> coredump_dir /var/cache/squid
>>>
>>> #ICAP
>>> icap_enable on
>>> icap_send_client_ip on
>>> icap_send_client_username on
>>> icap_client_username_header X-Authenticated-User
>>> icap_service service_req reqmod_precache bypass=1
>>> icap://127.0.0.1:1344/squidclamav
>>> adaptation_access service_req allow useragent
>>> icap_service service_resp respmod_precache bypass=1
>>> icap://127.0.0.1:1344/squidclamav
>>> adaptation_access service_resp allow useragent
>>>
>>> #X FORWARDED FOR
>>> forwarded_for on
>>>
>>> SSL.conf
>>> =======
>>>
>>> sslproxy_foreign_intermediate_certs /etc/squid/intermediate_ca.pem
>>> sslproxy_cafile /etc/squid/intermediate_ca.pem
>>> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 16MB
>>> sslcrtd_children 16 startup=5 idle=1
>>>
>>> acl FakeCert ssl::server_name .apple.com
>>> acl FakeCert ssl::server_name .icloud.com
>>> acl FakeCert ssl::server_name .mzstatic.com
>>> acl FakeCert ssl::server_name .dropbox.com
>>> acl ssl_step1 at_step SslBump1
>>> acl ssl_step2 at_step SslBump2
>>> acl ssl_step3 at_step SslBump3
>>>
>>> ssl_bump peek ssl_step1
>>> ssl_bump splice GlobalWhitelistDSTNet
>>> ssl_bump splice GlobalWhitelistDomainsRx
>>> ssl_bump splice GlobalWhitelistDomains
>>> ssl_bump splice FakeCert
>>> ssl_bump bump ssl_step2 all
>>> ssl_bump splice all
>>> sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression
>>> sslproxy_cipher
>>>
>>> ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:!aNULL:!eNULL
>>> sslproxy_flags DONT_VERIFY_PEER
>>> sslproxy_cert_error allow all
>>> sslproxy_cert_error deny all
>>>
>>> acls_whitelist.conf
>>> =============
>>>
>>> acl WindowsUpdates dstdomain officecdn.microsoft.com
>>> acl WindowsUpdates dstdomain windowsupdate.microsoft.com
>>> acl WindowsUpdates dstdomain ntservicepack.microsoft.com
>>> acl WindowsUpdates dstdomain download.microsoft.com
>>> acl WindowsUpdates dstdomain .windowsupdate.com
>>> acl WindowsUpdates dstdomain .windowsupdate.net
>>> acl WindowsUpdates dstdomain .update.microsoft.com
>>> acl WindowsUpdates dstdomain .mp.microsoft.com
>>> acl WindowsUpdates dstdomain .ws.microsoft.com
>>> acl GlobalWhitelistDomains dstdomain
>>> "/etc/squid/acls_whitelist.dstdomain.conf"
>>> acl GlobalWhitelistDSTNet dst "/etc/squid/acls_whitelist.dst.conf"
>>> acl GlobalWhitelistDomainsRx dstdom_regex -i
>>> "/etc/squid/acls_whitelist.dstdom_regex.conf"
>>> acl GlobalWhitelistBrowsers browser -i
>>> "/etc/squid/acls_whitelist.browser.conf"
>>> http_access allow GlobalWhitelistDomains
>>> url_rewrite_access deny GlobalWhitelistDomains
>>> http_access allow GlobalWhitelistDSTNet
>>> url_rewrite_access deny GlobalWhitelistDSTNet
>>> http_access allow GlobalWhitelistDomainsRx
>>> url_rewrite_access deny GlobalWhitelistDomainsRx
>>> http_access allow GlobalWhitelistBrowsers
>>>
>>>
>>> Any one with the same TAG_NONE/503 error, please help!?
>>>
>>> Regards,
>>> Hugo
>>> ________________________________
>>>
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>> --
>> Diese Nachricht wurde von meinem Android-Ger?t mit K-9 Mail gesendet.
> 
> 
> 



From hugo.saavedra.oteiza at gmail.com  Wed Dec  6 19:06:36 2017
From: hugo.saavedra.oteiza at gmail.com (Hugo Saavedra)
Date: Wed, 6 Dec 2017 16:06:36 -0300
Subject: [squid-users] SSL TAG_NONE/503 errors
In-Reply-To: <a1a0e0d8-e85d-2d24-dfae-464a258b2cec@measurement-factory.com>
References: <CAL+iNzg5ca4KHQ6XTmMc=Dj0w6+W-oKRJo8foJbb+VQX3cj9Nw@mail.gmail.com>
 <0ED074EB-141F-42C6-B332-9AE8F9F92813@data-core.org>
 <CAL+iNzj9ySoJQSssmiHak59ga7vmz-sFKe0tw6Q9WKX64VW6nA@mail.gmail.com>
 <a1a0e0d8-e85d-2d24-dfae-464a258b2cec@measurement-factory.com>
Message-ID: <CAL+iNzjyTzZKbW2fPVbtPMmq3kUN4RvYB0w7xbVuS0Qoi5i_qg@mail.gmail.com>

ok,
Alex, this are the errors on cache.log (for 2 different tests)

2017/12/06 16:01:52 kid1| Error negotiating SSL on FD 18:
error:14077410:SSL routines:SSL23_GET_SERVER_HELLO:sslv3 alert
handshake failure (1/-1/0)
2017/12/06 16:01:52 kid1| Error negotiating SSL on FD 25:
error:14077410:SSL routines:SSL23_GET_SERVER_HELLO:sslv3 alert
handshake failure (1/-1/0)
2017/12/06 16:01:52 kid1| Error negotiating SSL on FD 26:
error:14077410:SSL routines:SSL23_GET_SERVER_HELLO:sslv3 alert
handshake failure (1/-1/0)
2017/12/06 16:02:10 kid1| send: (111) Connection refused
2017/12/06 16:02:10 kid1| Closing Pinger socket on FD 36
2017/12/06 16:02:23 kid1| Starting new ssl_crtd helpers...
2017/12/06 16:02:23 kid1| helperOpenServers: Starting 1/16 'ssl_crtd' processes
2017/12/06 16:02:23 kid1| helperOpenServers: Starting 1/16 'ssl_crtd' processes
2017/12/06 16:02:23 kid1| Error negotiating SSL on FD 67:
error:00000000:lib(0): func(0):reason(0) (5/0/0)
2017/12/06 16:02:23 kid1| Error negotiating SSL on FD 68:
error:00000000:lib(0): func(0):reason(0) (5/0/0)
2017/12/06 16:02:23 kid1| Error negotiating SSL on FD 70:
error:00000000:lib(0): func(0):reason(0) (5/0/0)
2017/12/06 16:02:23 kid1| Error negotiating SSL on FD 69:
error:00000000:lib(0): func(0):reason(0) (5/0/0)
2017/12/06 16:02:23 kid1| Error negotiating SSL on FD 75:
error:00000000:lib(0): func(0):reason(0) (5/0/0)
2017/12/06 16:02:23 kid1| Error negotiating SSL on FD 74:
error:00000000:lib(0): func(0):reason(0) (5/0/0)
2017/12/06 16:02:23 kid1| Starting new ssl_crtd helpers...
2017/12/06 16:02:23 kid1| helperOpenServers: Starting 1/16 'ssl_crtd' processes
2017/12/06 16:02:23 kid1| Starting new ssl_crtd helpers...
2017/12/06 16:02:23 kid1| helperOpenServers: Starting 1/16 'ssl_crtd' processes
2017/12/06 16:02:23 kid1| Starting new ssl_crtd helpers...
2017/12/06 16:02:23 kid1| helperOpenServers: Starting 1/16 'ssl_crtd' processes
2017/12/06 16:02:23 kid1| Starting new ssl_crtd helpers...
2017/12/06 16:02:23 kid1| helperOpenServers: Starting 1/16 'ssl_crtd' processes
2017/12/06 16:02:37 kid1| Error negotiating SSL connection on FD 61:
error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca
(1/0)

Best,
Hugo

2017-12-06 15:54 GMT-03:00 Alex Rousskov <rousskov at measurement-factory.com>:
> On 12/06/2017 11:45 AM, Hugo Saavedra wrote:
>
>> Currently we have cache.log disabled for performance.
>
> With default debug_options, cache.log should not affect performance. If
> it does in your setup, then there is probably a problem that you should
> solve (without disabling cache.log).
>
>
>> any clues?
>
> You are probably not supplying enough information for others to guess
> what the problem is. Enabling cache.log may be the best next step. You
> can also try logging %err_code/%err_detail to access.log but not all
> errors populate those two logformat %codes so YMMV.
>
> Alex.
>
>
>> 2017-12-06 14:51 GMT-03:00 Enrico Heine <flashdown at data-core.org>:
>>> Hi,
>>>
>>> Can you confirm that squid is able to resolve these hostnames? If not try
>>> browsing to them without https and check if squid gives you an error
>>> message.
>>>
>>> Did you check the cache.log as well?
>>>
>>> Br Enrico
>>>
>>> Am 6. Dezember 2017 17:38:24 MEZ schrieb Hugo Saavedra
>>> <hugo.saavedra.oteiza at gmail.com>:
>>>>
>>>> Hi All,
>>>>
>>>> We have the following setup of a transparent squid box:
>>>> OS: CentOS release 6.9 (Final)
>>>> Squid Cache: Version 3.5.26-20170625-r14174
>>>> Compile options:
>>>>    '--with-included-ltdl' '--enable-icap-client'
>>>> '--enable-delay-pools' '--with-openssl' '--enable-ssl-crtd'
>>>> '--enable-icmp' '--enable-snmp' '--prefix=/usr'
>>>> '--includedir=/usr/include' '--datadir=/usr/share'
>>>> '--bindir=/usr/sbin' '--libexecdir=/usr/lib/squid'
>>>> '--localstatedir=/var' '--sysconfdir=/etc/squid'
>>>> --enable-ltdl-convenience
>>>>
>>>> Endpoints are redirected to the Squid box using a policy route for
>>>> TCP80/443 on a Fortigate firewall. All http/80 traffic works well. We
>>>> are using ssl bump for ssl, but there is an strange behavior, some
>>>> websites opens well, but some ones breaks and getting TAG_NONE/503
>>>> errors in the access log:
>>>>
>>>> 1512561423.930      1 192.168.1.108 TAG_NONE/503 31435 POST
>>>> https://api.chatlio.com/v1/p/visitor/session/new - HIER_NONE/-
>>>> text/html
>>>> 1512562220.870      1 192.168.1.158 TAG_NONE/503 12386 GET
>>>>
>>>> https://tile-service.weather.microsoft.com/es-CL/livetile/front/-33.44,-70.65?
>>>> - HIER_NONE/- text/html
>>>> 1512562220.870      1 192.168.1.158 TAG_NONE/503 12386 GET
>>>> https://service.weather.microsoft.com/appex/DesktopTile/Badge? -
>>>> HIER_NONE/- text/html
>>>> 1512566858.355    186 192.168.1.104 TAG_NONE/503 31436 GET
>>>>
>>>> https://www.mercantil.com/empresa/reac-importadora-spa/estaci%C3%B3n-central/300469639/esp
>>>> - HIER_NONE/- text/html
>>>>
>>>> In the same time-range, other websites loads well
>>>>
>>>> 1512561134.548    306 192.168.1.112 TCP_MISS/302 572 GET
>>>> https://loadm.exelator.com/load/? - ORIGINAL_DST/63.251.252.12
>>>> image/gif
>>>> 1512561139.701    216 192.168.1.148 TCP_MISS/200 386 POST
>>>> https://cloud-ecs.gravityzone.bitdefender.com/hydra-
>>>> ORIGINAL_DST/107.20.215.8 application/json
>>>> 1512561142.180     13 192.168.1.112 TCP_MISS/200 419 GET
>>>> https://www.facebook.com/tr/? - ORIGINAL_DST/179.60.193.35 image/gif
>>>> 1512561142.410    243 192.168.1.112 TCP_MISS/200 286 GET
>>>> https://bam.nr-data.net/1/ef1706da28? - ORIGINAL_DST/162.247.242.21
>>>> text/javascript
>>>>
>>>>
>>>> IPTABLES CONFIGURATION
>>>> =======================
>>>> # PREROUTING INTERCEPT PBR
>>>>
>>>> *nat
>>>> :PREROUTING ACCEPT [0:0]
>>>> :POSTROUTING ACCEPT [0:0]
>>>> :OUTPUT ACCEPT [0:0]
>>>> -A PREROUTING -i eth0 -p tcp -m tcp --dport 8080 -j REDIRECT --to-ports
>>>> 3128
>>>> -A PREROUTING -i eth0 -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 3128
>>>> -A PREROUTING -i eth0 -p tcp -m tcp --dport 443 -j REDIRECT --to-ports
>>>> 3129
>>>> COMMIT
>>>>
>>>> *filter
>>>> :INPUT ACCEPT [0:0]
>>>> :FORWARD ACCEPT [0:0]
>>>> :OUTPUT ACCEPT [0:0]
>>>>
>>>> #WEB
>>>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>>>> --dport 80 -j ACCEPT
>>>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>>>> --dport 443 -j ACCEPT
>>>>
>>>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>>>> --dport 3128 -j ACCEPT
>>>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>>>> --dport 3129 -j ACCEPT
>>>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>>>> --dport 3130 -j ACCEPT
>>>> -A INPUT -m state --state NEW,RELATED,ESTABLISHED -m tcp -p tcp
>>>> --dport 3131 -j ACCEPT
>>>>
>>>> #default
>>>> -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT
>>>> -A INPUT -p icmp -j ACCEPT
>>>> -A INPUT -i lo -j ACCEPT
>>>> -A INPUT -j REJECT --reject-with icmp-host-prohibited
>>>> -A FORWARD -j REJECT --reject-with icmp-host-prohibited
>>>> COMMIT
>>>>
>>>>
>>>> SQUID CONFIGURATION
>>>> ====================
>>>>
>>>> #WHITE LIST
>>>> acl exclWL url_regex "/etc/squid/white_url.squid"
>>>> acl neoWL url_regex "/etc/squid/neowl.squid"
>>>> http_access allow exclWL
>>>> http_access allow neoWL
>>>> cache deny exclWL
>>>> cache deny neoWL
>>>> always_direct allow exclWL
>>>> always_direct allow neoWL
>>>>
>>>> #Malicious URLs
>>>> acl dom url_regex "/etc/squid/dom.squid"
>>>> acl cc url_regex "/etc/squid/cc.squid"
>>>> http_access deny dom
>>>> http_access deny cc
>>>>
>>>> #BLACK LIST
>>>> acl exclBL url_regex "/etc/squid/black_url.squid"
>>>> acl neoBL url_regex "/etc/squid/neobl.squid"
>>>> http_access deny exclBL
>>>> http_access deny neoBL
>>>>
>>>> #ACLS BASE
>>>> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
>>>> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
>>>> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
>>>> acl localnet src fc00::/7       # RFC 4193 local private network range
>>>> acl localnet src fe80::/10      # RFC 4291 link-local (directly
>>>> plugged) machines
>>>> acl SSL_ports port 443
>>>> acl SSL_ports port 3129
>>>> acl Safe_ports port 80          # http
>>>> acl Safe_ports port 21          # ftp
>>>> acl Safe_ports port 443         # https
>>>> acl Safe_ports port 70          # gopher
>>>> acl Safe_ports port 210         # wais
>>>> acl Safe_ports port 1025-65535  # unregistered ports
>>>> acl Safe_ports port 280         # http-mgmt
>>>> acl Safe_ports port 488         # gss-http
>>>> acl Safe_ports port 591         # filemaker
>>>> acl Safe_ports port 777         # multiling http
>>>> acl CONNECT method CONNECT
>>>> acl HTTPS proto HTTPS
>>>>
>>>> include /etc/squid/acls_whitelist.conf
>>>> acl useragent browser "/etc/squid/useragent.squid"
>>>> range_offset_limit 0 !useragent
>>>> minimum_object_size 0 bytes
>>>> maximum_object_size 3 GB
>>>> quick_abort_min -1
>>>> delay_pools 1
>>>> delay_class 1 1
>>>> delay_parameters 1 128000/128000
>>>> delay_access 1 deny SSL_ports
>>>> delay_access 1 allow !useragent
>>>> delay_access 1 deny all
>>>>
>>>> #cache conf
>>>> max_filedescriptors 24576
>>>> memory_cache_mode disk
>>>> cache_mem 0 MB
>>>> cache allow all
>>>> minimum_object_size 0 bytes
>>>> maximum_object_size 20 MB
>>>> sslproxy_flags DONT_VERIFY_PEER
>>>> connect_timeout 8 seconds
>>>>
>>>> http_access deny !Safe_ports
>>>> http_access deny CONNECT !SSL_ports
>>>> http_access allow localhost manager
>>>> http_access deny manager
>>>> http_access allow localnet
>>>> http_access allow localhost
>>>> http_access deny all
>>>> reply_header_access Alternate-Protocol deny all
>>>>
>>>> http_port 3130
>>>> http_port 3131 ssl-bump cert=/etc/squid/ssl_cert/SIC.pem
>>>> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>>>> http_port 3128 intercept
>>>> https_port 3129 intercept ssl-bump generate-host-certificates=on
>>>> dynamic_cert_mem_cache_size=16MB cert=/etc/squid/ssl_cert/SIC.pem
>>>>
>>>> cache_dir ufs /var/cache/squid 9000 16 256
>>>> cache_store_log /var/log/squid/store.log
>>>> cache_effective_user squid
>>>> visible_hostname Proxy
>>>>
>>>> refresh_pattern ^ftp:           1440    20%     10080
>>>> refresh_pattern ^gopher:        1440    0%      1440
>>>> refresh_pattern -i (/cgi-bin/|\?) 2     20%     10
>>>> refresh_pattern .               2       20%     10      ignore-reload
>>>> override-expire ignore-no-cache ignore-no-store store-stale
>>>> ignore-private ignore-must-revalidate ignore-auth
>>>> refresh_pattern -i
>>>> \.(dmg|msi|deb|rpm|exe|zip|tar|tgz|ram|rar|bin|ppt|doc|tiff|pdf)$ 1
>>>> 20% 4 override-expire ignore-no-cache ignore-no-store ignore-private
>>>> reload-into-ims
>>>>
>>>>
>>>> #SSL BUMP
>>>> include /etc/squid/ssl.conf
>>>>
>>>> #LOGGING
>>>> access_log /var/log/squid/access.log
>>>> access_log /var/log/squid/access_c2.log cc
>>>> access_log /var/log/squid/access_c2.log dom
>>>> access_log /var/log/squid/splc.log excludeSSL
>>>> cache_log /dev/null
>>>> coredump_dir /var/cache/squid
>>>>
>>>> #ICAP
>>>> icap_enable on
>>>> icap_send_client_ip on
>>>> icap_send_client_username on
>>>> icap_client_username_header X-Authenticated-User
>>>> icap_service service_req reqmod_precache bypass=1
>>>> icap://127.0.0.1:1344/squidclamav
>>>> adaptation_access service_req allow useragent
>>>> icap_service service_resp respmod_precache bypass=1
>>>> icap://127.0.0.1:1344/squidclamav
>>>> adaptation_access service_resp allow useragent
>>>>
>>>> #X FORWARDED FOR
>>>> forwarded_for on
>>>>
>>>> SSL.conf
>>>> =======
>>>>
>>>> sslproxy_foreign_intermediate_certs /etc/squid/intermediate_ca.pem
>>>> sslproxy_cafile /etc/squid/intermediate_ca.pem
>>>> sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 16MB
>>>> sslcrtd_children 16 startup=5 idle=1
>>>>
>>>> acl FakeCert ssl::server_name .apple.com
>>>> acl FakeCert ssl::server_name .icloud.com
>>>> acl FakeCert ssl::server_name .mzstatic.com
>>>> acl FakeCert ssl::server_name .dropbox.com
>>>> acl ssl_step1 at_step SslBump1
>>>> acl ssl_step2 at_step SslBump2
>>>> acl ssl_step3 at_step SslBump3
>>>>
>>>> ssl_bump peek ssl_step1
>>>> ssl_bump splice GlobalWhitelistDSTNet
>>>> ssl_bump splice GlobalWhitelistDomainsRx
>>>> ssl_bump splice GlobalWhitelistDomains
>>>> ssl_bump splice FakeCert
>>>> ssl_bump bump ssl_step2 all
>>>> ssl_bump splice all
>>>> sslproxy_options NO_SSLv2,NO_SSLv3,No_Compression
>>>> sslproxy_cipher
>>>>
>>>> ALL:!SSLv2:!SSLv3:!ADH:!DSS:!MD5:!EXP:!DES:!PSK:!SRP:!RC4:!IDEA:!SEED:!aNULL:!eNULL
>>>> sslproxy_flags DONT_VERIFY_PEER
>>>> sslproxy_cert_error allow all
>>>> sslproxy_cert_error deny all
>>>>
>>>> acls_whitelist.conf
>>>> =============
>>>>
>>>> acl WindowsUpdates dstdomain officecdn.microsoft.com
>>>> acl WindowsUpdates dstdomain windowsupdate.microsoft.com
>>>> acl WindowsUpdates dstdomain ntservicepack.microsoft.com
>>>> acl WindowsUpdates dstdomain download.microsoft.com
>>>> acl WindowsUpdates dstdomain .windowsupdate.com
>>>> acl WindowsUpdates dstdomain .windowsupdate.net
>>>> acl WindowsUpdates dstdomain .update.microsoft.com
>>>> acl WindowsUpdates dstdomain .mp.microsoft.com
>>>> acl WindowsUpdates dstdomain .ws.microsoft.com
>>>> acl GlobalWhitelistDomains dstdomain
>>>> "/etc/squid/acls_whitelist.dstdomain.conf"
>>>> acl GlobalWhitelistDSTNet dst "/etc/squid/acls_whitelist.dst.conf"
>>>> acl GlobalWhitelistDomainsRx dstdom_regex -i
>>>> "/etc/squid/acls_whitelist.dstdom_regex.conf"
>>>> acl GlobalWhitelistBrowsers browser -i
>>>> "/etc/squid/acls_whitelist.browser.conf"
>>>> http_access allow GlobalWhitelistDomains
>>>> url_rewrite_access deny GlobalWhitelistDomains
>>>> http_access allow GlobalWhitelistDSTNet
>>>> url_rewrite_access deny GlobalWhitelistDSTNet
>>>> http_access allow GlobalWhitelistDomainsRx
>>>> url_rewrite_access deny GlobalWhitelistDomainsRx
>>>> http_access allow GlobalWhitelistBrowsers
>>>>
>>>>
>>>> Any one with the same TAG_NONE/503 error, please help!?
>>>>
>>>> Regards,
>>>> Hugo
>>>> ________________________________
>>>>
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>> --
>>> Diese Nachricht wurde von meinem Android-Ger?t mit K-9 Mail gesendet.
>>
>>
>>
>



-- 
Saludos,
Hugo Saavedra


From rousskov at measurement-factory.com  Wed Dec  6 19:21:56 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 6 Dec 2017 12:21:56 -0700
Subject: [squid-users] SSL TAG_NONE/503 errors
In-Reply-To: <CAL+iNzjyTzZKbW2fPVbtPMmq3kUN4RvYB0w7xbVuS0Qoi5i_qg@mail.gmail.com>
References: <CAL+iNzg5ca4KHQ6XTmMc=Dj0w6+W-oKRJo8foJbb+VQX3cj9Nw@mail.gmail.com>
 <0ED074EB-141F-42C6-B332-9AE8F9F92813@data-core.org>
 <CAL+iNzj9ySoJQSssmiHak59ga7vmz-sFKe0tw6Q9WKX64VW6nA@mail.gmail.com>
 <a1a0e0d8-e85d-2d24-dfae-464a258b2cec@measurement-factory.com>
 <CAL+iNzjyTzZKbW2fPVbtPMmq3kUN4RvYB0w7xbVuS0Qoi5i_qg@mail.gmail.com>
Message-ID: <9e7f7560-82e0-902d-4ac9-b9159c1d4403@measurement-factory.com>

On 12/06/2017 12:06 PM, Hugo Saavedra wrote:
> 2017/12/06 16:02:37 kid1| Error negotiating SSL connection on FD 61:
> error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca
> (1/0)

You may be able to fix this problem by updating your collection of
public CA certificates. Squid uses CA certificates to validate
certificates presented by origin servers. You may be able to confirm
that your collection is stale and know more (e.g., which CA certificate
is unknown) if you can map the above error to an access.log entry that
would give you the origin server name to interrogate.

Similar reasoning applies to other SSL-related cache.log errors as well,
but troubleshooting them may require more efforts (e.g., starting with a
higher debugging levels and/or packet captures).

Alex.


From yvoinov at gmail.com  Wed Dec  6 19:39:14 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 7 Dec 2017 01:39:14 +0600
Subject: [squid-users] SSL TAG_NONE/503 errors
In-Reply-To: <9e7f7560-82e0-902d-4ac9-b9159c1d4403@measurement-factory.com>
References: <CAL+iNzg5ca4KHQ6XTmMc=Dj0w6+W-oKRJo8foJbb+VQX3cj9Nw@mail.gmail.com>
 <0ED074EB-141F-42C6-B332-9AE8F9F92813@data-core.org>
 <CAL+iNzj9ySoJQSssmiHak59ga7vmz-sFKe0tw6Q9WKX64VW6nA@mail.gmail.com>
 <a1a0e0d8-e85d-2d24-dfae-464a258b2cec@measurement-factory.com>
 <CAL+iNzjyTzZKbW2fPVbtPMmq3kUN4RvYB0w7xbVuS0Qoi5i_qg@mail.gmail.com>
 <9e7f7560-82e0-902d-4ac9-b9159c1d4403@measurement-factory.com>
Message-ID: <c39c02b3-2ee5-485f-ea60-53bed392ab9a@gmail.com>

Not necessarily certificates. Exactly the same code gives the SSL pinning.


07.12.2017 1:21, Alex Rousskov ?????:
> On 12/06/2017 12:06 PM, Hugo Saavedra wrote:
>> 2017/12/06 16:02:37 kid1| Error negotiating SSL connection on FD 61:
>> error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca
>> (1/0)
> You may be able to fix this problem by updating your collection of
> public CA certificates. Squid uses CA certificates to validate
> certificates presented by origin servers. You may be able to confirm
> that your collection is stale and know more (e.g., which CA certificate
> is unknown) if you can map the above error to an access.log entry that
> would give you the origin server name to interrogate.
>
> Similar reasoning applies to other SSL-related cache.log errors as well,
> but troubleshooting them may require more efforts (e.g., starting with a
> higher debugging levels and/or packet captures).
>
> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171207/756ae251/attachment.sig>

From hugo.saavedra.oteiza at gmail.com  Wed Dec  6 19:56:37 2017
From: hugo.saavedra.oteiza at gmail.com (Hugo Saavedra)
Date: Wed, 6 Dec 2017 16:56:37 -0300
Subject: [squid-users] SSL TAG_NONE/503 errors
In-Reply-To: <9e7f7560-82e0-902d-4ac9-b9159c1d4403@measurement-factory.com>
References: <CAL+iNzg5ca4KHQ6XTmMc=Dj0w6+W-oKRJo8foJbb+VQX3cj9Nw@mail.gmail.com>
 <0ED074EB-141F-42C6-B332-9AE8F9F92813@data-core.org>
 <CAL+iNzj9ySoJQSssmiHak59ga7vmz-sFKe0tw6Q9WKX64VW6nA@mail.gmail.com>
 <a1a0e0d8-e85d-2d24-dfae-464a258b2cec@measurement-factory.com>
 <CAL+iNzjyTzZKbW2fPVbtPMmq3kUN4RvYB0w7xbVuS0Qoi5i_qg@mail.gmail.com>
 <9e7f7560-82e0-902d-4ac9-b9159c1d4403@measurement-factory.com>
Message-ID: <CAL+iNzjEjR7UBZS33TVfoUjkRLpnPgLkbu4npTkarvWgf7Zj=Q@mail.gmail.com>

solution finded: we commented the sslproxy_cipher line and it works!
is there any security issues if we left the default options for this variable?

thanks
Hugo

2017-12-06 16:21 GMT-03:00 Alex Rousskov <rousskov at measurement-factory.com>:
> On 12/06/2017 12:06 PM, Hugo Saavedra wrote:
>> 2017/12/06 16:02:37 kid1| Error negotiating SSL connection on FD 61:
>> error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca
>> (1/0)
>
> You may be able to fix this problem by updating your collection of
> public CA certificates. Squid uses CA certificates to validate
> certificates presented by origin servers. You may be able to confirm
> that your collection is stale and know more (e.g., which CA certificate
> is unknown) if you can map the above error to an access.log entry that
> would give you the origin server name to interrogate.
>
> Similar reasoning applies to other SSL-related cache.log errors as well,
> but troubleshooting them may require more efforts (e.g., starting with a
> higher debugging levels and/or packet captures).
>
> Alex.



-- 
Saludos,
Hugo Saavedra


From yvoinov at gmail.com  Wed Dec  6 19:59:57 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 7 Dec 2017 01:59:57 +0600
Subject: [squid-users] SSL TAG_NONE/503 errors
In-Reply-To: <CAL+iNzjEjR7UBZS33TVfoUjkRLpnPgLkbu4npTkarvWgf7Zj=Q@mail.gmail.com>
References: <CAL+iNzg5ca4KHQ6XTmMc=Dj0w6+W-oKRJo8foJbb+VQX3cj9Nw@mail.gmail.com>
 <0ED074EB-141F-42C6-B332-9AE8F9F92813@data-core.org>
 <CAL+iNzj9ySoJQSssmiHak59ga7vmz-sFKe0tw6Q9WKX64VW6nA@mail.gmail.com>
 <a1a0e0d8-e85d-2d24-dfae-464a258b2cec@measurement-factory.com>
 <CAL+iNzjyTzZKbW2fPVbtPMmq3kUN4RvYB0w7xbVuS0Qoi5i_qg@mail.gmail.com>
 <9e7f7560-82e0-902d-4ac9-b9159c1d4403@measurement-factory.com>
 <CAL+iNzjEjR7UBZS33TVfoUjkRLpnPgLkbu4npTkarvWgf7Zj=Q@mail.gmail.com>
Message-ID: <9ca064c9-bcd9-8860-c7eb-46cfac7ba44e@gmail.com>

RC4, may be.

In practice, too restrictive security usually leads various issues, ever
for big vendor site, like MS (some of this sites AFAIK still using RC4).

To be related to your questions - yes, in theory it is possible to get
security issue in this case. But it is require deep investigation. If
you are concerned - just take a look onto default openssl cipher's list.
And compare it with recommended forefront security.

07.12.2017 1:56, Hugo Saavedra ?????:
> solution finded: we commented the sslproxy_cipher line and it works!
> is there any security issues if we left the default options for this variable?
>
> thanks
> Hugo
>
> 2017-12-06 16:21 GMT-03:00 Alex Rousskov <rousskov at measurement-factory.com>:
>> On 12/06/2017 12:06 PM, Hugo Saavedra wrote:
>>> 2017/12/06 16:02:37 kid1| Error negotiating SSL connection on FD 61:
>>> error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca
>>> (1/0)
>> You may be able to fix this problem by updating your collection of
>> public CA certificates. Squid uses CA certificates to validate
>> certificates presented by origin servers. You may be able to confirm
>> that your collection is stale and know more (e.g., which CA certificate
>> is unknown) if you can map the above error to an access.log entry that
>> would give you the origin server name to interrogate.
>>
>> Similar reasoning applies to other SSL-related cache.log errors as well,
>> but troubleshooting them may require more efforts (e.g., starting with a
>> higher debugging levels and/or packet captures).
>>
>> Alex.
>
>

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171207/5e79e826/attachment.sig>

From hugo.saavedra.oteiza at gmail.com  Wed Dec  6 23:40:55 2017
From: hugo.saavedra.oteiza at gmail.com (Hugo Saavedra)
Date: Wed, 6 Dec 2017 20:40:55 -0300
Subject: [squid-users] SSL TAG_NONE/503 errors
In-Reply-To: <CAL+iNzjEjR7UBZS33TVfoUjkRLpnPgLkbu4npTkarvWgf7Zj=Q@mail.gmail.com>
References: <CAL+iNzg5ca4KHQ6XTmMc=Dj0w6+W-oKRJo8foJbb+VQX3cj9Nw@mail.gmail.com>
 <0ED074EB-141F-42C6-B332-9AE8F9F92813@data-core.org>
 <CAL+iNzj9ySoJQSssmiHak59ga7vmz-sFKe0tw6Q9WKX64VW6nA@mail.gmail.com>
 <a1a0e0d8-e85d-2d24-dfae-464a258b2cec@measurement-factory.com>
 <CAL+iNzjyTzZKbW2fPVbtPMmq3kUN4RvYB0w7xbVuS0Qoi5i_qg@mail.gmail.com>
 <9e7f7560-82e0-902d-4ac9-b9159c1d4403@measurement-factory.com>
 <CAL+iNzjEjR7UBZS33TVfoUjkRLpnPgLkbu4npTkarvWgf7Zj=Q@mail.gmail.com>
Message-ID: <CAL+iNzjB636s5hh3o4GbRJs6GB-ttnqOcM2_Tzx9PKs6QT_NhA@mail.gmail.com>

ooops!, we have another problem here, anyone knows what is this?

2017/12/06 19:30:23 kid1| SECURITY ALERT: on URL: login.live.com:443
2017/12/06 19:30:23 kid1| SECURITY ALERT: Host header forgery detected
on local=131.253.61.100:443 remote=192.168.10.2:59041 FD 126 flags=33
(local IP does not match any domain IP)
2017/12/06 19:30:23 kid1| SECURITY ALERT: on URL: login.live.com:443
2017/12/06 19:30:37 kid1| SECURITY ALERT: Host header forgery detected
on local=131.253.61.100:443 remote=192.168.10.2:59042 FD 106 flags=33
(local IP does not match any domain IP)
2017/12/06 19:30:37 kid1| SECURITY ALERT: on URL: login.live.com:443
2017/12/06 19:30:37 kid1| SECURITY ALERT: Host header forgery detected
on local=131.253.61.100:443 remote=192.168.10.2:59043 FD 107 flags=33
(local IP does not match any domain IP)
2017/12/06 19:30:37 kid1| SECURITY ALERT: on URL: login.live.com:443

Thanks

2017-12-06 16:56 GMT-03:00 Hugo Saavedra <hugo.saavedra.oteiza at gmail.com>:
> solution finded: we commented the sslproxy_cipher line and it works!
> is there any security issues if we left the default options for this variable?
>
> thanks
> Hugo
>
> 2017-12-06 16:21 GMT-03:00 Alex Rousskov <rousskov at measurement-factory.com>:
>> On 12/06/2017 12:06 PM, Hugo Saavedra wrote:
>>> 2017/12/06 16:02:37 kid1| Error negotiating SSL connection on FD 61:
>>> error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca
>>> (1/0)
>>
>> You may be able to fix this problem by updating your collection of
>> public CA certificates. Squid uses CA certificates to validate
>> certificates presented by origin servers. You may be able to confirm
>> that your collection is stale and know more (e.g., which CA certificate
>> is unknown) if you can map the above error to an access.log entry that
>> would give you the origin server name to interrogate.
>>
>> Similar reasoning applies to other SSL-related cache.log errors as well,
>> but troubleshooting them may require more efforts (e.g., starting with a
>> higher debugging levels and/or packet captures).
>>
>> Alex.
>
>
>
> --
> Saludos,
> Hugo Saavedra



-- 
Saludos,
Hugo Saavedra


From yvoinov at gmail.com  Wed Dec  6 23:42:26 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 7 Dec 2017 05:42:26 +0600
Subject: [squid-users] SSL TAG_NONE/503 errors
In-Reply-To: <CAL+iNzjB636s5hh3o4GbRJs6GB-ttnqOcM2_Tzx9PKs6QT_NhA@mail.gmail.com>
References: <CAL+iNzg5ca4KHQ6XTmMc=Dj0w6+W-oKRJo8foJbb+VQX3cj9Nw@mail.gmail.com>
 <0ED074EB-141F-42C6-B332-9AE8F9F92813@data-core.org>
 <CAL+iNzj9ySoJQSssmiHak59ga7vmz-sFKe0tw6Q9WKX64VW6nA@mail.gmail.com>
 <a1a0e0d8-e85d-2d24-dfae-464a258b2cec@measurement-factory.com>
 <CAL+iNzjyTzZKbW2fPVbtPMmq3kUN4RvYB0w7xbVuS0Qoi5i_qg@mail.gmail.com>
 <9e7f7560-82e0-902d-4ac9-b9159c1d4403@measurement-factory.com>
 <CAL+iNzjEjR7UBZS33TVfoUjkRLpnPgLkbu4npTkarvWgf7Zj=Q@mail.gmail.com>
 <CAL+iNzjB636s5hh3o4GbRJs6GB-ttnqOcM2_Tzx9PKs6QT_NhA@mail.gmail.com>
Message-ID: <416ea13f-452f-b13c-e7a8-8ccd09cbfa04@gmail.com>

https://wiki.squid-cache.org/KnowledgeBase/HostHeaderForgery


07.12.2017 5:40, Hugo Saavedra ?????:
> ooops!, we have another problem here, anyone knows what is this?
>
> 2017/12/06 19:30:23 kid1| SECURITY ALERT: on URL: login.live.com:443
> 2017/12/06 19:30:23 kid1| SECURITY ALERT: Host header forgery detected
> on local=131.253.61.100:443 remote=192.168.10.2:59041 FD 126 flags=33
> (local IP does not match any domain IP)
> 2017/12/06 19:30:23 kid1| SECURITY ALERT: on URL: login.live.com:443
> 2017/12/06 19:30:37 kid1| SECURITY ALERT: Host header forgery detected
> on local=131.253.61.100:443 remote=192.168.10.2:59042 FD 106 flags=33
> (local IP does not match any domain IP)
> 2017/12/06 19:30:37 kid1| SECURITY ALERT: on URL: login.live.com:443
> 2017/12/06 19:30:37 kid1| SECURITY ALERT: Host header forgery detected
> on local=131.253.61.100:443 remote=192.168.10.2:59043 FD 107 flags=33
> (local IP does not match any domain IP)
> 2017/12/06 19:30:37 kid1| SECURITY ALERT: on URL: login.live.com:443
>
> Thanks
>
> 2017-12-06 16:56 GMT-03:00 Hugo Saavedra <hugo.saavedra.oteiza at gmail.com>:
>> solution finded: we commented the sslproxy_cipher line and it works!
>> is there any security issues if we left the default options for this variable?
>>
>> thanks
>> Hugo
>>
>> 2017-12-06 16:21 GMT-03:00 Alex Rousskov <rousskov at measurement-factory.com>:
>>> On 12/06/2017 12:06 PM, Hugo Saavedra wrote:
>>>> 2017/12/06 16:02:37 kid1| Error negotiating SSL connection on FD 61:
>>>> error:14094418:SSL routines:SSL3_READ_BYTES:tlsv1 alert unknown ca
>>>> (1/0)
>>> You may be able to fix this problem by updating your collection of
>>> public CA certificates. Squid uses CA certificates to validate
>>> certificates presented by origin servers. You may be able to confirm
>>> that your collection is stale and know more (e.g., which CA certificate
>>> is unknown) if you can map the above error to an access.log entry that
>>> would give you the origin server name to interrogate.
>>>
>>> Similar reasoning applies to other SSL-related cache.log errors as well,
>>> but troubleshooting them may require more efforts (e.g., starting with a
>>> higher debugging levels and/or packet captures).
>>>
>>> Alex.
>>
>>
>> --
>> Saludos,
>> Hugo Saavedra
>
>

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171207/d2e0f5bc/attachment.sig>

From squid3 at treenet.co.nz  Thu Dec  7 05:06:36 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Dec 2017 18:06:36 +1300
Subject: [squid-users] Problem using auth digest
In-Reply-To: <1fc11f9230e9aeb921f415aa0379d439.squirrel@192.168.100.13>
References: <1fc11f9230e9aeb921f415aa0379d439.squirrel@192.168.100.13>
Message-ID: <e924320c-b713-9443-54cc-bca54ab08583@treenet.co.nz>

On 07/12/17 03:59, aismel.valle wrote:
> Hi guys,
> 
> well i implement the auth digest and work's fine only with the browser,
> when i config the internet download manager for download files have
> problems always show me the form authentication and don't accept the
> credentials i know the data is fine because when i use the seem
> credentials in the browser it's work.
> 
> Ideas???
> 


What do you mean by "download manager" ?
  do you know what it is doing with HTTP ?

Amos


From 747620227 at qq.com  Thu Dec  7 07:47:02 2017
From: 747620227 at qq.com (=?gb18030?B?R35Efkx1bmF0aWM=?=)
Date: Thu, 7 Dec 2017 15:47:02 +0800
Subject: [squid-users] SSL3_GET_SERVER_CERTIFICATE failed
Message-ID: <tencent_8A21EB69105365D769E8AC63BBC6F0EDC00A@qq.com>

my squid is a transparent proxy. 
the cache.log shows that 
2017/12/07 15:42:53 kid1| Error negotiating SSL connection on FD 175: Closed by client
2017/12/07 15:42:54 kid1| Error negotiating SSL on FD 95: error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/12/07 15:42:55 kid1| Error negotiating SSL connection on FD 124: Closed by client
2017/12/07 15:42:56 kid1| Error negotiating SSL on FD 52: error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)


what's the problem? thank you
 


Here is my configure

https_port 192.168.51.200:3129 intercept ssl-bump connection-auth=off generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/ssl_cert/myCA.pem key=/usr/local/squid/ssl_cert/myCA.pem options=NO_SSLv3,NO_SSLv2


acl broken_sites ssl::server_name matchweb.sports.qq.com
acl ssl_step1 at_step SslBump1
acl ssl_step2 at_step SslBump2
acl ssl_step3 at_step SslBump3
ssl_bump splice broken_sites
#ssl_bump splice all
ssl_bump stare ssl_step1
ssl_bump bump ssl_step2
ssl_bump terminate ssl_step3
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171207/a264590c/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec  7 08:14:35 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 7 Dec 2017 21:14:35 +1300
Subject: [squid-users] SSL3_GET_SERVER_CERTIFICATE failed
In-Reply-To: <tencent_8A21EB69105365D769E8AC63BBC6F0EDC00A@qq.com>
References: <tencent_8A21EB69105365D769E8AC63BBC6F0EDC00A@qq.com>
Message-ID: <55470b16-f7ea-957a-e249-a974fe655f55@treenet.co.nz>

On 07/12/17 20:47, G~D~Lunatic wrote:
> my squid is a transparent proxy.
> the cache.log shows that
> 2017/12/07 15:42:53 kid1| Error negotiating SSL connection on FD 175: 
> Closed by client
> 2017/12/07 15:42:54 kid1| Error negotiating SSL on FD 95: 
> error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate 
> verify failed (1/-1/0)
> 2017/12/07 15:42:55 kid1| Error negotiating SSL connection on FD 124: 
> Closed by client
> 2017/12/07 15:42:56 kid1| Error negotiating SSL on FD 52: 
> error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate 
> verify failed (1/-1/0)
> 
> 
> what's the problem? thank you

Four log lines talking about four different connections (FD's).

Two of them are "Closed by client".

Two of them "certificate verify failed" for the remote server certificate.


For those server certificates the relevant options are the sslproxy_* or 
tls_outgoing_options directives in your squid.conf.

* Maybe your system CA certificates are outdated, check for that and update.

* Maybe the server cert is missing intermediates certs from its chain. 
In Squid-3.5 use sslproxy_foreign_intermediate_certs to inform squid of 
extra intermediate certs that might be missing.

* Maybe the server cert is actually invalid. That happens a lot, 
especially on dodgy traffic.


Amos


From Ralf.Hildebrandt at charite.de  Thu Dec  7 12:19:50 2017
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Thu, 7 Dec 2017 13:19:50 +0100
Subject: [squid-users] Logging/stats for Delay Pools Under Squid?
Message-ID: <20171207121950.uuvd7tvqn2t5riai@charite.de>

I do know how to set-up delay pools, but how can I verify that they're
working? Are there any logs or statictics?

-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
https://www.charite.de             Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From aismel.valle at museomusica.cult.cu  Thu Dec  7 13:52:19 2017
From: aismel.valle at museomusica.cult.cu (aismel.valle at museomusica.cult.cu)
Date: Thu, 7 Dec 2017 08:52:19 -0500
Subject: [squid-users] [Fwd: Re:  Problem using auth digest]
Message-ID: <fe482e1148750f159948b01093b9eb5c.squirrel@192.168.100.13>


when i try to use a external application like Firefox.. Ex: Internet
Download Manager, Putty, etc..

I config the proxy option and the proxy always refuse the credentials..

Best regards

--------------------------------------------------------------------------

On 07/12/17 03:59, aismel.valle wrote:
> Hi guys,
>
> well i implement the auth digest and work's fine only with the browser,
> when i config the internet download manager for download files have
> problems always show me the form authentication and don't accept the
> credentials i know the data is fine because when i use the seem
> credentials in the browser it's work.
>
> Ideas???
>


What do you mean by "download manager" ?
  do you know what it is doing with HTTP ?

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users




From squid3 at treenet.co.nz  Thu Dec  7 14:26:54 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 8 Dec 2017 03:26:54 +1300
Subject: [squid-users] Logging/stats for Delay Pools Under Squid?
In-Reply-To: <20171207121950.uuvd7tvqn2t5riai@charite.de>
References: <20171207121950.uuvd7tvqn2t5riai@charite.de>
Message-ID: <dd54961a-c55d-46d0-423c-10dc27fe99e1@treenet.co.nz>

On 08/12/17 01:19, Ralf Hildebrandt wrote:
> I do know how to set-up delay pools, but how can I verify that they're
> working? Are there any logs or statictics?
> 

The cache manager report "delay" lists details of the pools.
The 'active_requests' listing also shows for each request which pool(s) 
it is assigned to.

Amos


From erdosain9 at gmail.com  Thu Dec  7 15:05:05 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 7 Dec 2017 08:05:05 -0700 (MST)
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <8962948e-7c6c-a18b-1738-22b3d646fd40@gmail.com>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
 <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
 <1512502436344-0.post@n4.nabble.com>
 <f79d0f42-90d3-ddc1-f4ac-507318591860@measurement-factory.com>
 <426ba648-4c6e-4cfe-7f09-7df5a010390f@gmail.com>
 <8962948e-7c6c-a18b-1738-22b3d646fd40@gmail.com>
Message-ID: <1512659105185-0.post@n4.nabble.com>

Yes, Chrome tell this when i look the certificate

"The certificate for this site does not contain a Subject Alternative Name
extension containing a domain name or IP address."

So, my certificate does not have a Subject Alternative Name.
But, this is not a problem with Firefox.

I have to change my certificate?? t
There is a way to tell Chrome "dont look for this"???
Thanks





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From uhlar at fantomas.sk  Thu Dec  7 15:27:41 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 7 Dec 2017 16:27:41 +0100
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <1512659105185-0.post@n4.nabble.com>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
 <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
 <1512502436344-0.post@n4.nabble.com>
 <f79d0f42-90d3-ddc1-f4ac-507318591860@measurement-factory.com>
 <426ba648-4c6e-4cfe-7f09-7df5a010390f@gmail.com>
 <8962948e-7c6c-a18b-1738-22b3d646fd40@gmail.com>
 <1512659105185-0.post@n4.nabble.com>
Message-ID: <20171207152741.GA26641@fantomas.sk>

On 07.12.17 08:05, erdosain9 wrote:
>Yes, Chrome tell this when i look the certificate
>
>"The certificate for this site does not contain a Subject Alternative Name
>extension containing a domain name or IP address."

are you aware that this is not a squid problem?

>So, my certificate does not have a Subject Alternative Name.
>But, this is not a problem with Firefox.

only with certificates issued after some date, not sure when, but it will
come.

>I have to change my certificate?? t
>There is a way to tell Chrome "dont look for this"???

only by using chrome <58

the CommonName does not have documented format, the SubjectAlternativeName
does.


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
He who laughs last thinks slowest. 


From rousskov at measurement-factory.com  Thu Dec  7 17:45:53 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 7 Dec 2017 10:45:53 -0700
Subject: [squid-users] Logging/stats for Delay Pools Under Squid?
In-Reply-To: <dd54961a-c55d-46d0-423c-10dc27fe99e1@treenet.co.nz>
References: <20171207121950.uuvd7tvqn2t5riai@charite.de>
 <dd54961a-c55d-46d0-423c-10dc27fe99e1@treenet.co.nz>
Message-ID: <2217fd50-68f9-0e42-546f-331060ef6865@measurement-factory.com>

On 12/07/2017 07:26 AM, Amos Jeffries wrote:
> On 08/12/17 01:19, Ralf Hildebrandt wrote:
>> I do know how to set-up delay pools, but how can I verify that they're
>> working? Are there any logs or statictics?

> The cache manager report "delay" lists details of the pools.
> The 'active_requests' listing also shows for each request which pool(s)
> it is assigned to.

And access.log fields can be used to reconstruct individual transfer
rates (and, with more work, even aggregates).

Ideally, you should use external-to-Squid tools to verify that Squid is
working correctly. Simple clients like cURL or wget can be used for
basic single-transaction tests. Web Polygraph can be used for complex
tests involving many concurrent transactions tickling many delay pools
at once.

Alex.


From rousskov at measurement-factory.com  Thu Dec  7 17:56:48 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 7 Dec 2017 10:56:48 -0700
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <1512659105185-0.post@n4.nabble.com>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
 <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
 <1512502436344-0.post@n4.nabble.com>
 <f79d0f42-90d3-ddc1-f4ac-507318591860@measurement-factory.com>
 <426ba648-4c6e-4cfe-7f09-7df5a010390f@gmail.com>
 <8962948e-7c6c-a18b-1738-22b3d646fd40@gmail.com>
 <1512659105185-0.post@n4.nabble.com>
Message-ID: <f0329ce7-5080-9ac8-a07a-db332833001a@measurement-factory.com>

On 12/07/2017 08:05 AM, erdosain9 wrote:
> Yes, Chrome tell this when i look the certificate
> 
> "The certificate for this site does not contain a Subject Alternative Name
> extension containing a domain name or IP address."

That is not the only error reported by your Chrome, but you can try to
solve one error at a time.

The first step is to understand which certificate the browser is talking
about. Is that a Squid-generated certificate or an origin server
certificate? If it is a Squid-generated certificate, does it mimic an
erroneous property of the origin server certificate? Or did Squid fail
to (or decided not to) mimic something?

The next step, for this specific error, would be to make sure that your
Squid version has as fix for Bug 4711:

> bug 4711: SubjectAlternativeNames is missing in some generated certificates
> 
> Squid may generate certificates which have a Common Name, but do not have
> a subjectAltName extension. For example when squid generated certificates
> do not mimic an origin certificate or when the certificate adaptation
> algorithm sslproxy_cert_adapt/setCommonName is used.
> 
> This is causes problems to some browsers, which validates a certificate using
> the SubjectAlternativeNames but ignore the CommonName field.
> 
> This patch fixes squid to always add a SubjectAlternativeNames extension in
> generated certificates which do not mimic an origin certificate.
> 
> Squid still will not add a subjectAltName extension when mimicking an origin
> server certificate, even if that origin server certificate does not include
> the subjectAltName extension. Such origin server may have problems when
> talking directly to browsers, and patched Squid is not trying to fix those
> problems.
> 
> This is a Measurement Factory project
> 
> Fixes: http://bugs.squid-cache.org/show_bug.cgi?id=4711 fixed
> Bzr-Reference: master r15131

If your Squid does not have the above fix, then it might explain the
second problem reported by Chrome as well, provided the origin server
certificate lacks any CN for Squid to mimic.


> So, my certificate does not have a Subject Alternative Name.
> But, this is not a problem with Firefox.

Yes, different browsers (and different browser versions) may impose
different requirements on certificates (and other traffic parameters).

Alex.


From erdosain9 at gmail.com  Thu Dec  7 18:18:05 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 7 Dec 2017 11:18:05 -0700 (MST)
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <f0329ce7-5080-9ac8-a07a-db332833001a@measurement-factory.com>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
 <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
 <1512502436344-0.post@n4.nabble.com>
 <f79d0f42-90d3-ddc1-f4ac-507318591860@measurement-factory.com>
 <426ba648-4c6e-4cfe-7f09-7df5a010390f@gmail.com>
 <8962948e-7c6c-a18b-1738-22b3d646fd40@gmail.com>
 <1512659105185-0.post@n4.nabble.com>
 <f0329ce7-5080-9ac8-a07a-db332833001a@measurement-factory.com>
Message-ID: <1512670685051-0.post@n4.nabble.com>

Ok, thanks for your time.

This "fix" the problem...

reg add HKLM\Software\Policies\Google\Chrome /v
EnableCommonNameFallbackForLocalAnchors /t REG_DWORD /d 1

When i wrote that command, the problem is gone.

but, i want to know about that fix that you are telling me.
Im using this version Squid Cache: Version 3.5.20

How i know if this is patched (probably not)... and, more important, how i
cant apply that patch (sorry i never do that).
Im working on a Centos 7.

Thanks for your time.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From yvoinov at gmail.com  Thu Dec  7 18:33:36 2017
From: yvoinov at gmail.com (Yuri)
Date: Fri, 8 Dec 2017 00:33:36 +0600
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <20171207152741.GA26641@fantomas.sk>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
 <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
 <1512502436344-0.post@n4.nabble.com>
 <f79d0f42-90d3-ddc1-f4ac-507318591860@measurement-factory.com>
 <426ba648-4c6e-4cfe-7f09-7df5a010390f@gmail.com>
 <8962948e-7c6c-a18b-1738-22b3d646fd40@gmail.com>
 <1512659105185-0.post@n4.nabble.com> <20171207152741.GA26641@fantomas.sk>
Message-ID: <8009b7b2-2ffb-0836-025e-1033036ed79e@gmail.com>



07.12.2017 21:27, Matus UHLAR - fantomas ?????:
> On 07.12.17 08:05, erdosain9 wrote:
>> Yes, Chrome tell this when i look the certificate
>>
>> "The certificate for this site does not contain a Subject Alternative
>> Name
>> extension containing a domain name or IP address."
>
> are you aware that this is not a squid problem?
>
>> So, my certificate does not have a Subject Alternative Name.
So what? Re-issue cert with openssl and add this field. This is trivial.
>> But, this is not a problem with Firefox.
Firefox uses not so restrictive SSL handling.
>
> only with certificates issued after some date, not sure when, but it will
> come.
>
>> I have to change my certificate?? t
>> There is a way to tell Chrome "dont look for this"???
>
> only by using chrome <58
Not only. It is exists registry hack for Chrome to workaround this. Not
sure it will still works.

Windows Registry Editor Version 5.00

[HKEY_LOCAL_MACHINE\SOFTWARE\Policies\Google\Chrome]
"EnableCommonNameFallbackForLocalAnchors"=dword:00000001
"EnableDeprecatedWebBasedSignin"=dword:00000000

It's easy to JFGI this hack as .reg-file, if any difficults to make this
by manual.
>
> the CommonName does not have documented format, the
> SubjectAlternativeName
> does.
>
It is documented in openssl man pages. Also it is documented in Google
technical documentation. JFGI.

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171208/d221250e/attachment.sig>

From ppmartell at eleka.co.cu  Thu Dec  7 19:12:16 2017
From: ppmartell at eleka.co.cu (Ing. Pedro Pablo Delgado Martell)
Date: Thu, 7 Dec 2017 14:12:16 -0500
Subject: [squid-users] =?utf-8?q?=28no_subject=29?=
Message-ID: <a9428783-db77-7b6f-e5bf-44893bd8d29f@eleka.co.cu>

I have been reading about the difference between a KB and a KiB, 
Kilobyte and Kibibyte respectively. According to several websites, also 
Google,? 1KB = 1000 bytes and 1KiB = 1024 bytes. However, you guys say 
on /etc/squid/squid.conf this:

"Units accepted by Squid are:

 ??? ??? bytes - byte

 ??? ??? KB - Kilobyte (*1024 bytes*)

 ??? ??? ...

 ??? ??? ...

"

This email is not for criticize your work, I'm only looking for some 
clearance because right now I'm confused about how Squid is really 
measuring files.


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171207/b4215980/attachment.htm>

From yvoinov at gmail.com  Thu Dec  7 19:29:04 2017
From: yvoinov at gmail.com (Yuri)
Date: Fri, 8 Dec 2017 01:29:04 +0600
Subject: [squid-users] (no subject)
In-Reply-To: <a9428783-db77-7b6f-e5bf-44893bd8d29f@eleka.co.cu>
References: <a9428783-db77-7b6f-e5bf-44893bd8d29f@eleka.co.cu>
Message-ID: <53317a39-2505-1386-5d9d-63a57258986d@gmail.com>

https://i.imgur.com/bDw1O2b.png


08.12.2017 1:12, Ing. Pedro Pablo Delgado Martell ?????:
>
> I have been reading about the difference between a KB and a KiB,
> Kilobyte and Kibibyte respectively. According to several websites,
> also Google,? 1KB = 1000 bytes and 1KiB = 1024 bytes. However, you
> guys say on /etc/squid/squid.conf this:
>
> "Units accepted by Squid are:
>
> ??? ??? bytes - byte
>
> ??? ??? KB - Kilobyte (*1024 bytes*)
>
> ??? ??? ...
>
> ??? ??? ...
>
> "
>
> This email is not for criticize your work, I'm only looking for some
> clearance because right now I'm confused about how Squid is really
> measuring files.
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171208/ac802b8d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171208/ac802b8d/attachment.sig>

From yvoinov at gmail.com  Thu Dec  7 19:34:22 2017
From: yvoinov at gmail.com (Yuri)
Date: Fri, 8 Dec 2017 01:34:22 +0600
Subject: [squid-users] (no subject)
In-Reply-To: <53317a39-2505-1386-5d9d-63a57258986d@gmail.com>
References: <a9428783-db77-7b6f-e5bf-44893bd8d29f@eleka.co.cu>
 <53317a39-2505-1386-5d9d-63a57258986d@gmail.com>
Message-ID: <16f0b30a-ce78-2820-a501-bdf32cc77a8e@gmail.com>

In our kilobyte - one thousand twenty-four bytes. :)

PS. And in our zettabayte - ten in the twenty-first degree byte. :)


08.12.2017 1:29, Yuri ?????:
>
> https://i.imgur.com/bDw1O2b.png
>
>
> 08.12.2017 1:12, Ing. Pedro Pablo Delgado Martell ?????:
>>
>> I have been reading about the difference between a KB and a KiB,
>> Kilobyte and Kibibyte respectively. According to several websites,
>> also Google,? 1KB = 1000 bytes and 1KiB = 1024 bytes. However, you
>> guys say on /etc/squid/squid.conf this:
>>
>> "Units accepted by Squid are:
>>
>> ??? ??? bytes - byte
>>
>> ??? ??? KB - Kilobyte (*1024 bytes*)
>>
>> ??? ??? ...
>>
>> ??? ??? ...
>>
>> "
>>
>> This email is not for criticize your work, I'm only looking for some
>> clearance because right now I'm confused about how Squid is really
>> measuring files.
>>
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>
> -- 
> "Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
> --Jamie Zawinsk
>
> **************************
> * C++: Bug to the future *
> **************************

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171208/5329c88c/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171208/5329c88c/attachment.sig>

From yvoinov at gmail.com  Thu Dec  7 19:35:14 2017
From: yvoinov at gmail.com (Yuri)
Date: Fri, 8 Dec 2017 01:35:14 +0600
Subject: [squid-users] (no subject)
In-Reply-To: <16f0b30a-ce78-2820-a501-bdf32cc77a8e@gmail.com>
References: <a9428783-db77-7b6f-e5bf-44893bd8d29f@eleka.co.cu>
 <53317a39-2505-1386-5d9d-63a57258986d@gmail.com>
 <16f0b30a-ce78-2820-a501-bdf32cc77a8e@gmail.com>
Message-ID: <cd1bb03e-9125-6100-a409-ff553e830505@gmail.com>

Oooops! zetta-byte :)


08.12.2017 1:34, Yuri ?????:
>
> In our kilobyte - one thousand twenty-four bytes. :)
>
> PS. And in our zettabayte - ten in the twenty-first degree byte. :)
>
>
> 08.12.2017 1:29, Yuri ?????:
>>
>> https://i.imgur.com/bDw1O2b.png
>>
>>
>> 08.12.2017 1:12, Ing. Pedro Pablo Delgado Martell ?????:
>>>
>>> I have been reading about the difference between a KB and a KiB,
>>> Kilobyte and Kibibyte respectively. According to several websites,
>>> also Google,? 1KB = 1000 bytes and 1KiB = 1024 bytes. However, you
>>> guys say on /etc/squid/squid.conf this:
>>>
>>> "Units accepted by Squid are:
>>>
>>> ??? ??? bytes - byte
>>>
>>> ??? ??? KB - Kilobyte (*1024 bytes*)
>>>
>>> ??? ??? ...
>>>
>>> ??? ??? ...
>>>
>>> "
>>>
>>> This email is not for criticize your work, I'm only looking for some
>>> clearance because right now I'm confused about how Squid is really
>>> measuring files.
>>>
>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> -- 
>> "Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
>> --Jamie Zawinsk
>>
>> **************************
>> * C++: Bug to the future *
>> **************************
>
> -- 
> "Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
> --Jamie Zawinsk
>
> **************************
> * C++: Bug to the future *
> **************************

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171208/67b4e16a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171208/67b4e16a/attachment.sig>

From yvoinov at gmail.com  Thu Dec  7 19:36:43 2017
From: yvoinov at gmail.com (Yuri)
Date: Fri, 8 Dec 2017 01:36:43 +0600
Subject: [squid-users] (no subject)
In-Reply-To: <cd1bb03e-9125-6100-a409-ff553e830505@gmail.com>
References: <a9428783-db77-7b6f-e5bf-44893bd8d29f@eleka.co.cu>
 <53317a39-2505-1386-5d9d-63a57258986d@gmail.com>
 <16f0b30a-ce78-2820-a501-bdf32cc77a8e@gmail.com>
 <cd1bb03e-9125-6100-a409-ff553e830505@gmail.com>
Message-ID: <4ddb68b3-2e65-4770-6a41-3ea03ee00cbf@gmail.com>

We are in trouble with bugs that do not close for years, they excite us,
and you're here with units of measurement :)


08.12.2017 1:35, Yuri ?????:
>
> Oooops! zetta-byte :)
>
>
> 08.12.2017 1:34, Yuri ?????:
>>
>> In our kilobyte - one thousand twenty-four bytes. :)
>>
>> PS. And in our zettabayte - ten in the twenty-first degree byte. :)
>>
>>
>> 08.12.2017 1:29, Yuri ?????:
>>>
>>> https://i.imgur.com/bDw1O2b.png
>>>
>>>
>>> 08.12.2017 1:12, Ing. Pedro Pablo Delgado Martell ?????:
>>>>
>>>> I have been reading about the difference between a KB and a KiB,
>>>> Kilobyte and Kibibyte respectively. According to several websites,
>>>> also Google,? 1KB = 1000 bytes and 1KiB = 1024 bytes. However, you
>>>> guys say on /etc/squid/squid.conf this:
>>>>
>>>> "Units accepted by Squid are:
>>>>
>>>> ??? ??? bytes - byte
>>>>
>>>> ??? ??? KB - Kilobyte (*1024 bytes*)
>>>>
>>>> ??? ??? ...
>>>>
>>>> ??? ??? ...
>>>>
>>>> "
>>>>
>>>> This email is not for criticize your work, I'm only looking for
>>>> some clearance because right now I'm confused about how Squid is
>>>> really measuring files.
>>>>
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>> -- 
>>> "Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
>>> --Jamie Zawinsk
>>>
>>> **************************
>>> * C++: Bug to the future *
>>> **************************
>>
>> -- 
>> "Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
>> --Jamie Zawinsk
>>
>> **************************
>> * C++: Bug to the future *
>> **************************
>
> -- 
> "Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
> --Jamie Zawinsk
>
> **************************
> * C++: Bug to the future *
> **************************

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171208/2dd3e6cf/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171208/2dd3e6cf/attachment.sig>

From Antony.Stone at squid.open.source.it  Thu Dec  7 19:40:29 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 7 Dec 2017 20:40:29 +0100
Subject: [squid-users] (no subject)
In-Reply-To: <16f0b30a-ce78-2820-a501-bdf32cc77a8e@gmail.com>
References: <a9428783-db77-7b6f-e5bf-44893bd8d29f@eleka.co.cu>
 <53317a39-2505-1386-5d9d-63a57258986d@gmail.com>
 <16f0b30a-ce78-2820-a501-bdf32cc77a8e@gmail.com>
Message-ID: <201712072040.29696.Antony.Stone@squid.open.source.it>

On Thursday 07 December 2017 at 20:34:22, Yuri wrote:

> In our kilobyte - one thousand twenty-four bytes. :)

This has been the definition since the earliest days of computing (or at least, 
as soon as any computer had 1024 of anything...)

This (rather stupid-sounding, in my opinion) kibibyte stuff is a much more 
recently introduced term, and is basically only needed for marketing people.

2^10 is a much more natural quantity of anything to have in computer terms 
(since the whole system is based on binary) than 10^3 is, however 10^3 is a 
smaller number, therefore the marketing people can tell you that the product 
contains more of them.


Antony.

> 08.12.2017 1:29, Yuri ?????:
> > https://i.imgur.com/bDw1O2b.png
> > 
> > 08.12.2017 1:12, Ing. Pedro Pablo Delgado Martell ?????:
> >> I have been reading about the difference between a KB and a KiB,
> >> Kilobyte and Kibibyte respectively. According to several websites,
> >> also Google,  1KB = 1000 bytes and 1KiB = 1024 bytes. However, you
> >> guys say on /etc/squid/squid.conf this:
> >> 
> >> "Units accepted by Squid are:
> >> 
> >>         bytes - byte
> >> 
> >>         KB - Kilobyte (*1024 bytes*)
> >> "
> >> 
> >> This email is not for criticize your work, I'm only looking for some
> >> clearance because right now I'm confused about how Squid is really
> >> measuring files.

-- 
Software development can be quick, high quality, or low cost.

The customer gets to pick any two out of three.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Thu Dec  7 19:41:52 2017
From: yvoinov at gmail.com (Yuri)
Date: Fri, 8 Dec 2017 01:41:52 +0600
Subject: [squid-users] (no subject)
In-Reply-To: <201712072040.29696.Antony.Stone@squid.open.source.it>
References: <a9428783-db77-7b6f-e5bf-44893bd8d29f@eleka.co.cu>
 <53317a39-2505-1386-5d9d-63a57258986d@gmail.com>
 <16f0b30a-ce78-2820-a501-bdf32cc77a8e@gmail.com>
 <201712072040.29696.Antony.Stone@squid.open.source.it>
Message-ID: <b4adbd5e-cb65-07f2-b49a-0faa45f4045e@gmail.com>

I love power of 2 :)

And in our kilometer is 1024 m ;)


08.12.2017 1:40, Antony Stone ?????:
> On Thursday 07 December 2017 at 20:34:22, Yuri wrote:
>
>> In our kilobyte - one thousand twenty-four bytes. :)
> This has been the definition since the earliest days of computing (or at least, 
> as soon as any computer had 1024 of anything...)
>
> This (rather stupid-sounding, in my opinion) kibibyte stuff is a much more 
> recently introduced term, and is basically only needed for marketing people.
>
> 2^10 is a much more natural quantity of anything to have in computer terms 
> (since the whole system is based on binary) than 10^3 is, however 10^3 is a 
> smaller number, therefore the marketing people can tell you that the product 
> contains more of them.
>
>
> Antony.
>
>> 08.12.2017 1:29, Yuri ?????:
>>> https://i.imgur.com/bDw1O2b.png
>>>
>>> 08.12.2017 1:12, Ing. Pedro Pablo Delgado Martell ?????:
>>>> I have been reading about the difference between a KB and a KiB,
>>>> Kilobyte and Kibibyte respectively. According to several websites,
>>>> also Google,  1KB = 1000 bytes and 1KiB = 1024 bytes. However, you
>>>> guys say on /etc/squid/squid.conf this:
>>>>
>>>> "Units accepted by Squid are:
>>>>
>>>>         bytes - byte
>>>>
>>>>         KB - Kilobyte (*1024 bytes*)
>>>> "
>>>>
>>>> This email is not for criticize your work, I'm only looking for some
>>>> clearance because right now I'm confused about how Squid is really
>>>> measuring files.

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171208/1ac1ce8d/attachment.sig>

From ppmartell at eleka.co.cu  Thu Dec  7 19:43:52 2017
From: ppmartell at eleka.co.cu (Ing. Pedro Pablo Delgado Martell)
Date: Thu, 7 Dec 2017 14:43:52 -0500
Subject: [squid-users] =?utf-8?q?=28no_subject=29?=
Message-ID: <5c3f3d58-5e6d-1921-3384-a475be1c47d5@eleka.co.cu>

"In our kilobyte - one thousand twenty-four bytes."

Your kilobyte???? Ok, let's move on, there is no point.



From Antony.Stone at squid.open.source.it  Thu Dec  7 19:48:34 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 7 Dec 2017 20:48:34 +0100
Subject: [squid-users] (no subject)
In-Reply-To: <5c3f3d58-5e6d-1921-3384-a475be1c47d5@eleka.co.cu>
References: <5c3f3d58-5e6d-1921-3384-a475be1c47d5@eleka.co.cu>
Message-ID: <201712072048.35033.Antony.Stone@squid.open.source.it>

On Thursday 07 December 2017 at 20:43:52, Ing. Pedro Pablo Delgado Martell 
wrote:

> "In our kilobyte - one thousand twenty-four bytes."
> 
> Your kilobyte???? Ok, let's move on, there is no point.

https://en.wikipedia.org/wiki/Kilobyte

"In historical usage in some areas of information technology, particularly in 
reference to digital memory capacity, kilobyte denotes 1024 (2^10) bytes. This 
arises from the powers-of-two sizing common to memory circuit design. In this 
context, the symbols K and KB are often used."

"The kilobyte has traditionally been used to refer to 1024 bytes (2^10 B), a 
usage still common. The usage of the metric prefix kilo for binary multiples 
arose as a convenience, because 1000 approximates 1024."

"The binary representation of 1024 bytes typically uses the symbol KB, with an 
uppercase letter K. The B is often omitted in informal use. For example, a 
processor with 65,536 bytes of cache memory might be said to have "64K" of 
cache. In this convention, one thousand and twenty-four kilobytes (1024 KB) is 
equal to one megabyte (1 MB), where 1 MB is 1024^2 bytes."

Hope that helps,


Antony.

-- 
Wanted: telepath.   You know where to apply.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From yvoinov at gmail.com  Thu Dec  7 19:50:27 2017
From: yvoinov at gmail.com (Yuri)
Date: Fri, 8 Dec 2017 01:50:27 +0600
Subject: [squid-users] (no subject)
In-Reply-To: <201712072048.35033.Antony.Stone@squid.open.source.it>
References: <5c3f3d58-5e6d-1921-3384-a475be1c47d5@eleka.co.cu>
 <201712072048.35033.Antony.Stone@squid.open.source.it>
Message-ID: <8cf4a638-a105-53c5-da21-17a8fd300ca7@gmail.com>

Antonio, enough.

I do not believe that no one here has a sense of humor. Are you serious
about discussing it with animal seriousness?


08.12.2017 1:48, Antony Stone ?????:
> On Thursday 07 December 2017 at 20:43:52, Ing. Pedro Pablo Delgado Martell 
> wrote:
>
>> "In our kilobyte - one thousand twenty-four bytes."
>>
>> Your kilobyte???? Ok, let's move on, there is no point.
> https://en.wikipedia.org/wiki/Kilobyte
>
> "In historical usage in some areas of information technology, particularly in 
> reference to digital memory capacity, kilobyte denotes 1024 (2^10) bytes. This 
> arises from the powers-of-two sizing common to memory circuit design. In this 
> context, the symbols K and KB are often used."
>
> "The kilobyte has traditionally been used to refer to 1024 bytes (2^10 B), a 
> usage still common. The usage of the metric prefix kilo for binary multiples 
> arose as a convenience, because 1000 approximates 1024."
>
> "The binary representation of 1024 bytes typically uses the symbol KB, with an 
> uppercase letter K. The B is often omitted in informal use. For example, a 
> processor with 65,536 bytes of cache memory might be said to have "64K" of 
> cache. In this convention, one thousand and twenty-four kilobytes (1024 KB) is 
> equal to one megabyte (1 MB), where 1 MB is 1024^2 bytes."
>
> Hope that helps,
>
>
> Antony.
>

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171208/09fc29eb/attachment.sig>

From Antony.Stone at squid.open.source.it  Thu Dec  7 20:01:23 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 7 Dec 2017 21:01:23 +0100
Subject: [squid-users] (no subject)
In-Reply-To: <8cf4a638-a105-53c5-da21-17a8fd300ca7@gmail.com>
References: <5c3f3d58-5e6d-1921-3384-a475be1c47d5@eleka.co.cu>
 <201712072048.35033.Antony.Stone@squid.open.source.it>
 <8cf4a638-a105-53c5-da21-17a8fd300ca7@gmail.com>
Message-ID: <201712072101.23526.Antony.Stone@squid.open.source.it>

On Thursday 07 December 2017 at 20:50:27, Yuri wrote:

> Antonio, enough.
> 
> I do not believe that no one here has a sense of humor.

I think I agree with that sentence (although it's a little hard to be sure).

> Are you serious about discussing it with animal seriousness?

The question appeared to be asked seriously in the first place.  I apologise if 
it was in fact a joke and I did not realise.

Antony.

> 08.12.2017 1:48, Antony Stone ?????:
> > On Thursday 07 December 2017 at 20:43:52, Ing. Pedro Pablo Delgado
> > Martell wrote:
> >> "In our kilobyte - one thousand twenty-four bytes."
> >> 
> >> Your kilobyte???? Ok, let's move on, there is no point.
> > 
> > https://en.wikipedia.org/wiki/Kilobyte
> > 
> > "In historical usage in some areas of information technology,
> > particularly in reference to digital memory capacity, kilobyte denotes
> > 1024 (2^10) bytes. This arises from the powers-of-two sizing common to
> > memory circuit design. In this context, the symbols K and KB are often
> > used."
> > 
> > "The kilobyte has traditionally been used to refer to 1024 bytes (2^10
> > B), a usage still common. The usage of the metric prefix kilo for binary
> > multiples arose as a convenience, because 1000 approximates 1024."
> > 
> > "The binary representation of 1024 bytes typically uses the symbol KB,
> > with an uppercase letter K. The B is often omitted in informal use. For
> > example, a processor with 65,536 bytes of cache memory might be said to
> > have "64K" of cache. In this convention, one thousand and twenty-four
> > kilobytes (1024 KB) is equal to one megabyte (1 MB), where 1 MB is
> > 1024^2 bytes."
> > 
> > Hope that helps,
> > 
> > 
> > Antony.

-- 
#define SIX 1+5
#define NINE 8+1

int main() {
    printf("%d\n", SIX * NINE);
}
	- thanks to ECB for bringing this to my attention

                                                   Please reply to the list;
                                                         please *don't* CC me.


From ppmartell at eleka.co.cu  Thu Dec  7 20:11:38 2017
From: ppmartell at eleka.co.cu (Ing. Pedro Pablo Delgado Martell)
Date: Thu, 7 Dec 2017 15:11:38 -0500
Subject: [squid-users] =?utf-8?q?=28no_subject=29?=
Message-ID: <8fe49450-78ae-a3b5-d912-51e4397ba8be@eleka.co.cu>

"We are in trouble with bugs that do not close for years, they excite us,
and you're here with units of measurement"

With all due respect bug over years has nothing to do with my question, I asked because had a doubt. As I said, there is no point. I will treat "your kilobyte" as 1024 because 1024 bytes will always be 1024 bytes. I'm not here to debate the way we call it. Honestly, and nothing to do with this "debate" I really hope you guys have those bugs solved for good.



From johnrefwe at mail.com  Thu Dec  7 20:56:26 2017
From: johnrefwe at mail.com (John Refwe)
Date: Thu, 7 Dec 2017 21:56:26 +0100
Subject: [squid-users] squidclient parsing
Message-ID: <trinity-74cb6c8c-3830-4ba1-95dc-d90039655ef9-1512680186039@3c-app-mailcom-lxa04>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171207/c1e74f6c/attachment.htm>

From rousskov at measurement-factory.com  Thu Dec  7 21:14:35 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 7 Dec 2017 14:14:35 -0700
Subject: [squid-users] KB vs KiB
In-Reply-To: <a9428783-db77-7b6f-e5bf-44893bd8d29f@eleka.co.cu>
References: <a9428783-db77-7b6f-e5bf-44893bd8d29f@eleka.co.cu>
Message-ID: <033ce664-4f0f-cc53-41a7-cfa0e91485d1@measurement-factory.com>

On 12/07/2017 12:12 PM, Ing. Pedro Pablo Delgado Martell wrote:
> I have been reading about the difference between a KB and a KiB,
> Kilobyte and Kibibyte respectively. According to several websites, also
> Google,? 1KB = 1000 bytes and 1KiB = 1024 bytes. However, you guys say
> on /etc/squid/squid.conf this:
> 
> "Units accepted by Squid are:
> 
> ??? ??? bytes - byte
> 
> ??? ??? KB - Kilobyte (*1024 bytes*)
> "
> 
> This email is not for criticize your work, I'm only looking for some
> clearance because right now I'm confused about how Squid is really
> measuring files.
 The statement in squid.conf.documented is accurate: When parsing
size-related options that support units, Squid interprets the KB suffix
as 1024 bytes. This classic/legacy interpretation predates and violates
some of the modern conventions/standards. I do not anticipate changes in
this area because it is not trivial to make such changes
backwards-compatible, and because we should solve much bigger problems
first.

Please note that Squid may use a different KB definition in other
contexts, especially in various reports and cache.log messages.

Alex.


From gkinkie at gmail.com  Thu Dec  7 22:21:29 2017
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Thu, 7 Dec 2017 23:21:29 +0100
Subject: [squid-users] KB vs KiB
In-Reply-To: <033ce664-4f0f-cc53-41a7-cfa0e91485d1@measurement-factory.com>
References: <a9428783-db77-7b6f-e5bf-44893bd8d29f@eleka.co.cu>
 <033ce664-4f0f-cc53-41a7-cfa0e91485d1@measurement-factory.com>
Message-ID: <3B775D7B-A03C-4CD2-A3A7-654DE16E4CED@gmail.com>



> On Dec 7, 2017, at 22:14, Alex Rousskov <rousskov at measurement-factory.com> wrote:
> 
> On 12/07/2017 12:12 PM, Ing. Pedro Pablo Delgado Martell wrote:
>> I have been reading about the difference between a KB and a KiB,
>> Kilobyte and Kibibyte respectively. According to several websites, also
>> Google,  1KB = 1000 bytes and 1KiB = 1024 bytes. However, you guys say
>> on /etc/squid/squid.conf this:
>> 
>> "Units accepted by Squid are:
>> 
>>         bytes - byte
>> 
>>         KB - Kilobyte (*1024 bytes*)
>> "
>> 
>> This email is not for criticize your work, I'm only looking for some
>> clearance because right now I'm confused about how Squid is really
>> measuring files.
> The statement in squid.conf.documented is accurate: When parsing
> size-related options that support units, Squid interprets the KB suffix
> as 1024 bytes. This classic/legacy interpretation predates and violates
> some of the modern conventions/standards. I do not anticipate changes in
> this area because it is not trivial to make such changes
> backwards-compatible, and because we should solve much bigger problems
> first.
> 
> Please note that Squid may use a different KB definition in other
> contexts, especially in various reports and cache.log messages.


I?d add that patches or pull requests aiming to add uniformity to how these values are interpreted and printed are welcome; in this case however backwards compatibility should be guaranteed: this change doesn?t in my opinion meet the standard required for changing the behavior of deployed configurations.

	Francesco

From gkinkie at gmail.com  Thu Dec  7 22:25:06 2017
From: gkinkie at gmail.com (Francesco Chemolli)
Date: Thu, 7 Dec 2017 23:25:06 +0100
Subject: [squid-users] squidclient parsing
In-Reply-To: <trinity-74cb6c8c-3830-4ba1-95dc-d90039655ef9-1512680186039@3c-app-mailcom-lxa04>
References: <trinity-74cb6c8c-3830-4ba1-95dc-d90039655ef9-1512680186039@3c-app-mailcom-lxa04>
Message-ID: <27E9AD2F-7007-4B78-B8A4-7D16F1328567@gmail.com>



> On Dec 7, 2017, at 21:56, John Refwe <johnrefwe at mail.com> wrote:
> 
> Hi!
Hi John
 
> I am trying to automate using certain statistics from the squidclient. I had two questions.
>  
> 1) Is it possible to ask squid to respond in a different format than the text dump it currently gives back? For example, JSON or XML response

An effort to add multi-format output has been stared a few years back; it failed to deliver any useful results.

> 2) If the answer to number 1 is no, are there any recommendations for how to parse the response?

Responses are formatted, and they require relatively little context for interpretation. It depends on what you need to do, really.

> 2) Are there any off the shelf tools/libraries (like cURL or python requests library) that are able to use the squid_cache:// protocol?

Recent squid versions also offer cachemgr output on http:// protocol. IIRC you need to request http://name.of.squid.server/squid-internal-mgr/<page> <http://name.of.squid.server/squid-internal-mgr/%3Cpage%3E> 
The cache_object:// protocol is HTTP anyway.

HTH,
  Francesco
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171207/755dd0a5/attachment.htm>

From squid3 at treenet.co.nz  Fri Dec  8 06:20:32 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 8 Dec 2017 19:20:32 +1300
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <1512670685051-0.post@n4.nabble.com>
References: <1512489028475-0.post@n4.nabble.com>
 <1366aaaf-970a-a1f4-7a15-109c64ee3e61@measurement-factory.com>
 <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
 <1512502436344-0.post@n4.nabble.com>
 <f79d0f42-90d3-ddc1-f4ac-507318591860@measurement-factory.com>
 <426ba648-4c6e-4cfe-7f09-7df5a010390f@gmail.com>
 <8962948e-7c6c-a18b-1738-22b3d646fd40@gmail.com>
 <1512659105185-0.post@n4.nabble.com>
 <f0329ce7-5080-9ac8-a07a-db332833001a@measurement-factory.com>
 <1512670685051-0.post@n4.nabble.com>
Message-ID: <0c014387-37ad-8eaf-a1e3-c9124a6234ce@treenet.co.nz>

On 08/12/17 07:18, erdosain9 wrote:
> Ok, thanks for your time.
> 
> This "fix" the problem...
> 
> reg add HKLM\Software\Policies\Google\Chrome /v
> EnableCommonNameFallbackForLocalAnchors /t REG_DWORD /d 1
> 
> When i wrote that command, the problem is gone.
> 
> but, i want to know about that fix that you are telling me.
> Im using this version Squid Cache: Version 3.5.20
> 
> How i know if this is patched (probably not)... and, more important, how i
> cant apply that patch (sorry i never do that).
> Im working on a Centos 7.
> 

Eliezers repository contains RPMs for more up to date 3.5.27 releases. 
The 'beta' area also contains Squid-4 releases.

<https://wiki.squid-cache.org/KnowledgeBase/CentOS>


Amos


From uhlar at fantomas.sk  Fri Dec  8 09:21:39 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Fri, 8 Dec 2017 10:21:39 +0100
Subject: [squid-users] (no subject)
In-Reply-To: <a9428783-db77-7b6f-e5bf-44893bd8d29f@eleka.co.cu>
References: <a9428783-db77-7b6f-e5bf-44893bd8d29f@eleka.co.cu>
Message-ID: <20171208092139.GA25971@fantomas.sk>

On 07.12.17 14:12, Ing. Pedro Pablo Delgado Martell wrote:
>I have been reading about the difference between a KB and a KiB, 

the kilo (1000) uses lowercase 'k' as defined by SI prefixes.

... when learning about computers some 30 years ago, we have used
capital 'K' that was meant to be 1024.

later I was told that some people (apparently mostly at electrical
engineering) used upper case K, M and G to measure multiples, while lower
case m, u and n were meant for fractions.

Ki, Mi and Gi were introduced later in order to provide more precise
in computing environment.

HDD manufacturers still use decimal prefixes - it looks better to have 5000
gigabyte HDDs than 4656 Gigabyte...

>Kilobyte and Kibibyte respectively. According to several websites, 
>also Google,? 1KB = 1000 bytes and 1KiB = 1024 bytes. However, you 
>guys say on /etc/squid/squid.conf this:

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Depression is merely anger without enthusiasm. 


From listas_quijada at hotmail.com  Fri Dec  8 21:08:33 2017
From: listas_quijada at hotmail.com (Edwin Quijada)
Date: Fri, 8 Dec 2017 21:08:33 +0000
Subject: [squid-users] Groups and authorizaction SQUID
Message-ID: <BN6PR15MB1203D51EC21557CF8BC47441E3300@BN6PR15MB1203.namprd15.prod.outlook.com>

Hi!
I am a newbie using SQUID and I have a question :

I have 4 different groups in my company each group has access different but I dont know how create an ACL to give access for each group.


These groups and users are in a remote server that I use with a webservice so with I have created a helper for authorization the problem is how can i do this ACL


Thks In advance

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171208/0a7138f1/attachment.htm>

From Antony.Stone at squid.open.source.it  Fri Dec  8 22:50:51 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 8 Dec 2017 23:50:51 +0100
Subject: [squid-users] Groups and authorizaction SQUID
In-Reply-To: <BN6PR15MB1203D51EC21557CF8BC47441E3300@BN6PR15MB1203.namprd15.prod.outlook.com>
References: <BN6PR15MB1203D51EC21557CF8BC47441E3300@BN6PR15MB1203.namprd15.prod.outlook.com>
Message-ID: <201712082350.51217.Antony.Stone@squid.open.source.it>

On Friday 08 December 2017 at 22:08:33, Edwin Quijada wrote:

> Hi!
> I am a newbie using SQUID and I have a question :
> 
> I have 4 different groups in my company each group has access different

Please explain what "access different" means.

> but I dont know how create an ACL to give access for each group.
> 
> 
> These groups and users are in a remote server

What sort of server?  How are the groups defined?

> that I use with a webservice

What does "webservice" mean?

> so with I have created a helper for authorization

Tell us how this helper works.

How does it identify one group fron another?

> the problem is how can i do this ACL

No idea, until you give us more information about how your user groupss are 
differentiated from one another, and what information Squid might have 
available to it to be able to treat them differently.


Antony.

-- 
APL [is a language], in which you can write a program to simulate shuffling a 
deck of cards and then dealing them out to several players, in four 
characters, none of which appear on a standard keyboard.

 - David Given

                                                   Please reply to the list;
                                                         please *don't* CC me.


From listas_quijada at hotmail.com  Sat Dec  9 14:35:51 2017
From: listas_quijada at hotmail.com (Edwin Quijada)
Date: Sat, 9 Dec 2017 14:35:51 +0000
Subject: [squid-users] Groups and authorizaction SQUID
In-Reply-To: <201712082350.51217.Antony.Stone@squid.open.source.it>
References: <BN6PR15MB1203D51EC21557CF8BC47441E3300@BN6PR15MB1203.namprd15.prod.outlook.com>,
 <201712082350.51217.Antony.Stone@squid.open.source.it>
Message-ID: <BN6PR15MB12039E5921388CCC0B44D46CE3310@BN6PR15MB1203.namprd15.prod.outlook.com>



On Friday 08 December 2017 at 22:08:33, Edwin Quijada wrote:

> Hi!
> I am a newbie using SQUID and I have a question :
>
> I have 4 different groups in my company each group has access different

Please explain what "access different" means.

The first group has accees to 2 pages, second 3 differents pages and  3 and 4 everything

> but I dont know how create an ACL to give access for each group.
>
>
> These groups and users are in a remote server

What sort of server?  How are the groups defined?

It is a web server

> that I use with a webservice

What does "webservice" mean?
 Remote method/function that respond me when I sent  user/pass this respond me with the group that user belongs
I have another method/function/script by http that respond me what is the group that user belongs

> so with I have created a helper for authorization

Tell us how this helper works.

I thought that using a helper for autorization I can restricted the pages used for each member group

How does it identify one group fron another?

Uhm...the structere are differents , really there are in different tables in my DB that is in the server

> the problem is how can i do this ACL

No idea, until you give us more information about how your user groupss are
differentiated from one another, and what information Squid might have
available to it to be able to treat them differently.

Thks, sorry my bad english.
I hope the info can You answer your question


Antony.

--
APL [is a language], in which you can write a program to simulate shuffling a
deck of cards and then dealing them out to several players, in four
characters, none of which appear on a standard keyboard.

 - David Given

                                                   Please reply to the list;
                                                         please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
squid-users Info Page<http://lists.squid-cache.org/listinfo/squid-users>
lists.squid-cache.org
squid-users -- General discussion relating to Squid. The membership of this list is thousands of Squid users from around the world About squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171209/b1bf85b5/attachment.htm>

From Antony.Stone at squid.open.source.it  Sat Dec  9 15:57:51 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sat, 9 Dec 2017 16:57:51 +0100
Subject: [squid-users] Groups and authorization SQUID
In-Reply-To: <BN6PR15MB12039E5921388CCC0B44D46CE3310@BN6PR15MB1203.namprd15.prod.outlook.com>
References: <BN6PR15MB1203D51EC21557CF8BC47441E3300@BN6PR15MB1203.namprd15.prod.outlook.com>
 <201712082350.51217.Antony.Stone@squid.open.source.it>
 <BN6PR15MB12039E5921388CCC0B44D46CE3310@BN6PR15MB1203.namprd15.prod.outlook.com>
Message-ID: <201712091657.52150.Antony.Stone@squid.open.source.it>

On Saturday 09 December 2017 at 15:35:51, Edwin Quijada wrote:

> > On Friday 08 December 2017 at 22:08:33, Edwin Quijada wrote:
> > 
> > > I have 4 different groups in my company each group has access different
> >
> > Please explain what "access different" means.
> 
> The first group has accees to 2 pages, second 3 differents pages and  3 and
> 4 everything

Okay, understood.

> > > These groups and users are in a remote server
> >
> > What sort of server?  How are the groups defined?
> 
> It is a web server

Er, okay...

> > > that I use with a webservice
> 
> > What does "webservice" mean?
>
> Remote method/function that respond me when I sent  user/pass this respond
> me with the group that user belongs I have another method/function/script
> by http that respond me what is the group that user belongs

Okay, I guess it might be possible to get Squid to use ACLs based on the 
result of an HTTP request, but I've never seen it done like this before.

Maybe someone else on the list can suggest how this might be made to work.

> > > so with I have created a helper for authorization
> >
> > Tell us how this helper works.
> 
> I thought that using a helper for autorization I can restricted the pages
> used for each member group

Have you created a helper, or not?

If you have created one, please tell us how it works.

> > How does it identify one group from another?
> 
> Uhm...the structere are differents , really there are in different tables
> in my DB that is in the server

So, you're doing an HTTP request to a web server, which then looks up the user 
in a database, and returns a result as an HTTP response...

Surely it would be easier (and quicker / more efficient) to get Squid to 
interrogate the database?

> > > the problem is how can i do this ACL

I wouldn't start from there, so I hope someone else here can suggest a way of 
getting this to work.


What made you start with this approach in the first place?


Antony.

-- 
Atheism is a non-prophet-making organisation.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Sun Dec 10 05:39:14 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 10 Dec 2017 18:39:14 +1300
Subject: [squid-users] [squid-announce] Squid 4.0.22 beta is available
Message-ID: <31d55d26-1bd0-c53e-c8ec-59b293770e75@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-4.0.22 release!


This release is a bug fix release resolving several issues found in the
prior Squid releases.


The major changes to be aware of:

* Regression: Relay peer CONNECT error status line and headers to clients

Our CVE-2015-5400 fix was aggressive -- it hid all peer errors behind a 
generic 502 (Bad Gateway) response. The intent was never to have that 
situation be permanent.

Subsequent changes to the CONNECT handling now allow us to safely relay 
client response status and header - but not yet the message payloads. 
The clients TCP connection will continue to be closed immediately after 
the initial message headers are delivered, allowing clients to safely 
detect the missing response payload (if any) as a connection error in 
addition to any HTTP error indicated by the response status.

This should resolve a lot of client issues


* Bug 4767: SMP breaks IPv6 SNMP and cache manager queries

This rather nasty bug appears as a Squid with SMP workers crashing 
whenever SNMP or cache manager queries are received over IPv6.


* Bug 4648: object revalidation for HTTPS scheme

Previous Squid have not been performing cache revalidation for responses 
to https:// URL requests. As can be expected with the increased use of 
revalidation in HTTP/1.1 this leads to rather low caching efficiency and 
extra bandwidth consumption on a lot of traffic.


* Bug 4616: store_client.cc:92: "mem" assertion

This crash occurs primarily when Collapsed Forwarding was used, though 
may also occur at other rare times.


* Bug 2821: ignore Content-Range in non-206 responses

Squid used to honor Content-Range header in HTTP 200 OK (and possibly 
other non-206) responses, truncating (and possibly enlarging) some 
response bodies. RFC 7233 declares Content-Range meaningless for 
standard HTTP status codes other than 206 and 416. Squid now relays 
meaningless Content-Range as is, without using its value on these responses.


* TLS: certificate validation improvements


The experimental auto-download feature for missing CA certificates has 
now been optimized to skip downloading if the CA certificate has 
previously been downloaded, or can be validated using another issuer CA.

Also, when Squid or its helper could not validate a downloaded 
intermediate certificate (or the root certificate), Squid error page 
contained '[Not available]' instead of the broken certificate details, 
and '-1' instead of depth of broken certificate in logs.


* TLS: certificate generator improvements

SSL-Bump was found to be ignoring some origin server certificate changes 
or differences, incorrectly using the previously cached fake certificate 
(mimicking now-stale properties or properties of a slightly different 
certificate). Also, Squid was not detecting key collisions inside 
certificate caches.


* Fix backwards compatibility for Squid-3.5 external_acl_type formats

Previous Squid-4 releases omitted support for several external_acl_type 
format codes available in Squid-3. This has now been resolved and 
Squid-3 external_acl_type format configurations should remain working 
across an upgrade.


* Do not die silently when dying early

Squid previously could terminate silently- no log entries in cache.log 
nor syslog. If the reason for termination was due to some environment 
condition and discovered during the process environment setup. Squid 
should now catch these types of issues and deliver an error to the best 
available log output - usually that would syslog or the OS 'messages' 
log due to cache.log not being setup. If -X command line parameter is 
used stderr will be used instead.


* Docs: update translation files

As we are closing in on the final bug fixes for Squid-4 the i18n 
translation texts have been updated. This and other routine 
documentation additions form the majority of the size of this release 
difference from the previous release.


  All users of Squid-4.x are encouraged to upgrade to this release as
soon as possible.

  All users of Squid-3 are encouraged to test this release out and plan
for upgrades where possible.


  See the ChangeLog for the full list of changes in this and earlier
  releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

  http://www.squid-cache.org/Versions/v4/
  ftp://ftp.squid-cache.org/pub/squid/
  ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

  http://www.squid-cache.org/Download/http-mirrors.html
  http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From 747620227 at qq.com  Mon Dec 11 01:06:06 2017
From: 747620227 at qq.com (=?gb18030?B?R35Efkx1bmF0aWM=?=)
Date: Mon, 11 Dec 2017 09:06:06 +0800
Subject: [squid-users] SSL3_GET_SERVER_CERTIFICATE failed
Message-ID: <tencent_C3FDC8758E0F1D0E5D8F8F98217B55C36805@qq.com>

my squid is a transparent proxy. 
when i use WeChat client upload file or picture, it failed.
the access.log shows that
1512953345.798     75 192.168.51.15 TAG_NONE/200 0 CONNECT 111.206.23.97:443 - ORIGINAL_DST/111.206.23.97 -
1512953345.805      0 192.168.51.15 TAG_NONE/503 4380 POST https://msg.71.am/v5/ypt/hcdn_multicurl - HIER_NONE/- text/html
1512953349.713     10 192.168.51.15 TAG_NONE/200 0 CONNECT 101.226.152.108:443 - HIER_NONE/- -
1512953350.931     10 192.168.51.15 TAG_NONE/200 0 CONNECT 123.151.76.49:443 - HIER_NONE/- -
1512953354.059     11 192.168.51.15 TAG_NONE/200 0 CONNECT 123.151.76.49:443 - HIER_NONE/- -

i used wireshark catch the package, Encrypted Alert was shown.
i want to know where the problem or how i can do.
Here is my configure

https_port 192.168.51.200:3129 intercept ssl-bump connection-auth=off generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/usr/local/squid/ssl_cert/myCA.pem key=/usr/local/squid/ssl_cert/myCA.pem options=NO_SSLv3,NO_SSLv2


acl broken_sites ssl::server_name matchweb.sports.qq.com
acl ssl_step1 at_step SslBump1
acl ssl_step2 at_step SslBump2
acl ssl_step3 at_step SslBump3
ssl_bump splice broken_sites
#ssl_bump splice all
ssl_bump stare ssl_step1
ssl_bump bump ssl_step2
ssl_bump terminate ssl_step3
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171211/cc56dd84/attachment.htm>

From squid3 at treenet.co.nz  Mon Dec 11 02:24:09 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 11 Dec 2017 15:24:09 +1300
Subject: [squid-users] SSL3_GET_SERVER_CERTIFICATE failed
In-Reply-To: <tencent_C3FDC8758E0F1D0E5D8F8F98217B55C36805@qq.com>
References: <tencent_C3FDC8758E0F1D0E5D8F8F98217B55C36805@qq.com>
Message-ID: <8465a21e-a41d-3fa3-22ba-36b51630d7f8@treenet.co.nz>

On 11/12/17 14:06, G~D~Lunatic wrote:
> my squid is a transparent proxy.

You have an interception proxy. It is modifying the TCP/IP packets with 
NAT and the TLS handshakes with SSL-Bump stare+bump.
<https://tools.ietf.org/html/rfc3040#section-2.1>
<https://tools.ietf.org/html/rfc3040#section-2.5>

To be properly a "transparent proxy" requires use of TPROXY interception 
on the http_port and peek+splice on the ssl_bump.


> when i use WeChat client upload file or picture, it failed.

Please explain "it failed".
  What does the client receive ?
  What is received when it does not fail ?

Please also be aware that securely written App's use "certificate 
pinning" or similar mechanisms to ensure their traffic is not 
intercepted / bump'ed. There is nothing Squid can do about those - they 
*will* fail if bumping is attempted.


> the access.log shows that
> 1512953345.798???? 75 192.168.51.15 TAG_NONE/200 0 CONNECT 
> 111.206.23.97:443 - ORIGINAL_DST/111.206.23.97 -

The above is a TCP connection reaching SSL-Bump step2 bump'ing. No TLS 
SNI was provided by the client.


> 1512953345.805????? 0 192.168.51.15 TAG_NONE/503 4380 POST 
> https://msg.71.am/v5/ypt/hcdn_multicurl - HIER_NONE/- text/html

The above looks like Squid delivering an error about something going 
wrong in the TLS handshake. IIRC Alex already mentioned to you that 
Squid bump's these TLS handshakes with invalid certs to deliver errors 
in a way that Browsers will display.

It may or may not be related to the earlier CONNECT line. Details of the 
error are found within the encrypted 503 response itself, not logged.


The below are all different TCP connections being stare'd at step1.


> 1512953349.713???? 10 192.168.51.15 TAG_NONE/200 0 CONNECT 
> 101.226.152.108:443 - HIER_NONE/- -
> 1512953350.931???? 10 192.168.51.15 TAG_NONE/200 0 CONNECT 
> 123.151.76.49:443 - HIER_NONE/- -
> 1512953354.059???? 11 192.168.51.15 TAG_NONE/200 0 CONNECT 
> 123.151.76.49:443 - HIER_NONE/- -
> 
> i used wireshark catch the package, Encrypted Alert was shown.
> i want to know where the problem or how i can do.

The only int of a problem is that 503 being generated by Squid due to 
something unknown. No details of what might be causing that are visible 
in any of the info you provided.


> Here is my configure
> 
> https_port 192.168.51.200:3129 intercept ssl-bump connection-auth=off 
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB 
> cert=/usr/local/squid/ssl_cert/myCA.pem 
> key=/usr/local/squid/ssl_cert/myCA.pem options=NO_SSLv3,NO_SSLv2
> 

When cert= and key= are the same file, you do not have to configure the 
key= option.

The dynamic_cert_mem_cache_size=4MB is the default value, no need to 
configure defaults explicitly like that.

One test to try is removing that options= setting. If the problem goes 
away then the client TLS handshake is requiring SSL. Use of that 
protocol is bad, but still sometimes unavoidable.


> 
> acl broken_sites ssl::server_name matchweb.sports.qq.com
> acl ssl_step1 at_step SslBump1
> acl ssl_step2 at_step SslBump2
> acl ssl_step3 at_step SslBump3
> ssl_bump splice broken_sites
> #ssl_bump splice all
> ssl_bump stare ssl_step1
> ssl_bump bump ssl_step2
> ssl_bump terminate ssl_step3
> 

The absence of a stare at step2 prohibits the ability of Squid to mimic 
server details in the TLS handshake it delivers to the client. Without 
mimic the chances of TLS failure get *much* greater.

Amos


From yvoinov at gmail.com  Mon Dec 11 11:59:22 2017
From: yvoinov at gmail.com (Yuri)
Date: Mon, 11 Dec 2017 17:59:22 +0600
Subject: [squid-users] SSL3_GET_SERVER_CERTIFICATE failed
In-Reply-To: <tencent_C3FDC8758E0F1D0E5D8F8F98217B55C36805@qq.com>
References: <tencent_C3FDC8758E0F1D0E5D8F8F98217B55C36805@qq.com>
Message-ID: <fa40a85e-401d-d653-7ff6-9c29b7e56864@gmail.com>

In practice POST url always better to get splice. This prevents much errors.

SSL3_GET_SERVER_CERTIFICATE itself means that some client application
trying to establish secure connection uses old SSLv3 protocol. This
applications also better to splice, if not possible to upgrade
applications (often it is not possible).


11.12.2017 7:06, G~D~Lunatic ?????:
> my squid is a transparent proxy.
> when i use WeChat client upload file or picture, it failed.
> the access.log shows that
> 1512953345.798???? 75 192.168.51.15 TAG_NONE/200 0 CONNECT
> 111.206.23.97:443 - ORIGINAL_DST/111.206.23.97 -
> 1512953345.805????? 0 192.168.51.15 TAG_NONE/503 4380 POST
> https://msg.71.am/v5/ypt/hcdn_multicurl - HIER_NONE/- text/html
> 1512953349.713???? 10 192.168.51.15 TAG_NONE/200 0 CONNECT
> 101.226.152.108:443 - HIER_NONE/- -
> 1512953350.931???? 10 192.168.51.15 TAG_NONE/200 0 CONNECT
> 123.151.76.49:443 - HIER_NONE/- -
> 1512953354.059???? 11 192.168.51.15 TAG_NONE/200 0 CONNECT
> 123.151.76.49:443 - HIER_NONE/- -
>
> i used wireshark catch the package, Encrypted Alert was shown.
> i want to know where the problem or how i can do.
> Here is my configure
>
> https_port 192.168.51.200:3129 intercept ssl-bump connection-auth=off
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> cert=/usr/local/squid/ssl_cert/myCA.pem
> key=/usr/local/squid/ssl_cert/myCA.pem options=NO_SSLv3,NO_SSLv2
>
>
> acl broken_sites ssl::server_name matchweb.sports.qq.com
> acl ssl_step1 at_step SslBump1
> acl ssl_step2 at_step SslBump2
> acl ssl_step3 at_step SslBump3
> ssl_bump splice broken_sites
> #ssl_bump splice all
> ssl_bump stare ssl_step1
> ssl_bump bump ssl_step2
> ssl_bump terminate ssl_step3
>
>
>
>
>
>
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171211/a6b88f7a/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171211/a6b88f7a/attachment.sig>

From listas_quijada at hotmail.com  Mon Dec 11 20:48:04 2017
From: listas_quijada at hotmail.com (Edwin Quijada)
Date: Mon, 11 Dec 2017 20:48:04 +0000
Subject: [squid-users] Groups and authorization SQUID
In-Reply-To: <201712091657.52150.Antony.Stone@squid.open.source.it>
References: <BN6PR15MB1203D51EC21557CF8BC47441E3300@BN6PR15MB1203.namprd15.prod.outlook.com>
 <201712082350.51217.Antony.Stone@squid.open.source.it>
 <BN6PR15MB12039E5921388CCC0B44D46CE3310@BN6PR15MB1203.namprd15.prod.outlook.com>,
 <201712091657.52150.Antony.Stone@squid.open.source.it>
Message-ID: <BN6PR15MB12037091515BEB05BA12F701E3370@BN6PR15MB1203.namprd15.prod.outlook.com>




________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Antony Stone <Antony.Stone at squid.open.source.it>
Sent: Saturday, December 9, 2017 3:57 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Groups and authorization SQUID

On Saturday 09 December 2017 at 15:35:51, Edwin Quijada wrote:

> > On Friday 08 December 2017 at 22:08:33, Edwin Quijada wrote:
> >
> > > I have 4 different groups in my company each group has access different
> >
> > Please explain what "access different" means.
>
> The first group has accees to 2 pages, second 3 differents pages and  3 and
> 4 everything

Okay, understood.

> > > These groups and users are in a remote server
> >
> > What sort of server?  How are the groups defined?
>
> It is a web server

Er, okay...

> > > that I use with a webservice
>
> > What does "webservice" mean?
>
> Remote method/function that respond me when I sent  user/pass this respond
> me with the group that user belongs I have another method/function/script
> by http that respond me what is the group that user belongs

Okay, I guess it might be possible to get Squid to use ACLs based on the
result of an HTTP request, but I've never seen it done like this before.

This part is not a problem for me.

Maybe someone else on the list can suggest how this might be made to work.

> > > so with I have created a helper for authorization
> >
> > Tell us how this helper works.
>
> I thought that using a helper for autorization I can restricted the pages
> used for each member group

Have you created a helper, or not?
Yes!!

If you have created one, please tell us how it works.

This helper that I created
<?php

$f = fopen("php://stdin", "r");
while (!(feof($f))) {
    $line = fgets($f);
    if ($line) {
        $fields = explode(' ', trim($line));
        $username = rawurldecode($fields[0]);
        $password = rawurldecode($fields[1]);
//
        if ($username=="edwin" &&  $password=="1234")
              fwrite(STDOUT, "OK\n");
        else
             fwrite(STDOUT, "ERR\n");
    }
}
?>
This helper is just for testing , but when I tested it doent work

> > How does it identify one group from another?
>
> Uhm...the structere are differents , really there are in different tables
> in my DB that is in the server

So, you're doing an HTTP request to a web server, which then looks up the user
in a database, and returns a result as an HTTP response...

Surely it would be easier (and quicker / more efficient) to get Squid to
interrogate the database?

> > > the problem is how can i do this ACL

I wouldn't start from there, so I hope someone else here can suggest a way of
getting this to work.


What made you start with this approach in the first place?

Now, I changed the approach , I just want one group for everything and other, localnet restricted,instead of use 4 groups just 2 one for admin, other for


Antony.

--
Atheism is a non-prophet-making organisation.

                                                   Please reply to the list;
                                                         please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
squid-users Info Page<http://lists.squid-cache.org/listinfo/squid-users>
lists.squid-cache.org
squid-users -- General discussion relating to Squid. The membership of this list is thousands of Squid users from around the world About squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171211/e96677aa/attachment.htm>

From listas_quijada at hotmail.com  Mon Dec 11 21:19:53 2017
From: listas_quijada at hotmail.com (Edwin Quijada)
Date: Mon, 11 Dec 2017 21:19:53 +0000
Subject: [squid-users] Helper doent authentify
Message-ID: <BN6PR15MB12033035509FF8207A94BD28E3370@BN6PR15MB1203.namprd15.prod.outlook.com>

Hi!
I am trying to do a helper for use with Squid. I did my helper but it doesnt authentify

<?php

$f = fopen("php://stdin", "r");
while (!(feof($f)))
{
    $line = fgets($f);
    if ($line)
     {
        $fields = explode(' ', trim($line));
        $username = rawurldecode($fields[0]);
        $password = rawurldecode($fields[1]);

        if ($username=="edwin" &&  $password=="1234")
         fwrite(STDOUT, "OK\n");
        else
         fwrite(STDOUT, "ERR\n");
    }
}
?>

when I put the values it continues asked me user/password


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171211/502d09e6/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Dec 11 21:27:56 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 11 Dec 2017 22:27:56 +0100
Subject: [squid-users] Helper doent authentify
In-Reply-To: <BN6PR15MB12033035509FF8207A94BD28E3370@BN6PR15MB1203.namprd15.prod.outlook.com>
References: <BN6PR15MB12033035509FF8207A94BD28E3370@BN6PR15MB1203.namprd15.prod.outlook.com>
Message-ID: <201712112227.56547.Antony.Stone@squid.open.source.it>

On Monday 11 December 2017 at 22:19:53, Edwin Quijada wrote:

> Hi!
> I am trying to do a helper for use with Squid. I did my helper but it
> doesnt authentify
> 
> <?php
> 
> $f = fopen("php://stdin", "r");
> while (!(feof($f)))
> {
>     $line = fgets($f);
>     if ($line)
>      {
>         $fields = explode(' ', trim($line));
>         $username = rawurldecode($fields[0]);
>         $password = rawurldecode($fields[1]);
> 
>         if ($username=="edwin" &&  $password=="1234")
>          fwrite(STDOUT, "OK\n");
>         else
>          fwrite(STDOUT, "ERR\n");
>     }
> }
> ?>
> 
> when I put the values it continues asked me user/password

I think "$f" might be your problem.

See http://freesoftwaremagazine.com/articles/authentication_with_squid/ for 
what might be a clue (sorry, I'm not really a PHP coder).


Antony.

-- 
Why is "dylexia" so difficult to spell, and why can I never remember "aphasia" 
when I want to?

                                                   Please reply to the list;
                                                         please *don't* CC me.


From listas_quijada at hotmail.com  Mon Dec 11 21:56:16 2017
From: listas_quijada at hotmail.com (Edwin Quijada)
Date: Mon, 11 Dec 2017 21:56:16 +0000
Subject: [squid-users] Helper doent authentify
In-Reply-To: <201712112227.56547.Antony.Stone@squid.open.source.it>
References: <BN6PR15MB12033035509FF8207A94BD28E3370@BN6PR15MB1203.namprd15.prod.outlook.com>,
 <201712112227.56547.Antony.Stone@squid.open.source.it>
Message-ID: <BN6PR15MB12031A469F4C927964F22005E3370@BN6PR15MB1203.namprd15.prod.outlook.com>




________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Antony Stone <Antony.Stone at squid.open.source.it>
Sent: Monday, December 11, 2017 9:27 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Helper doent authentify

On Monday 11 December 2017 at 22:19:53, Edwin Quijada wrote:

> Hi!
> I am trying to do a helper for use with Squid. I did my helper but it
> doesnt authentify
>
> <?php
>
> $f = fopen("php://stdin", "r");
> while (!(feof($f)))
> {
>     $line = fgets($f);
>     if ($line)
>      {
>         $fields = explode(' ', trim($line));
>         $username = rawurldecode($fields[0]);
>         $password = rawurldecode($fields[1]);
>
>         if ($username=="edwin" &&  $password=="1234")
>          fwrite(STDOUT, "OK\n");
>         else
>          fwrite(STDOUT, "ERR\n");
>     }
> }
> ?>
>
> when I put the values it continues asked me user/password

I think "$f" might be your problem.

See http://freesoftwaremagazine.com/articles/authentication_with_squid/ for


I copied my example from this page. ?
If I run the script it works fine , returns OK or ERR that is suppose to receive

How to build squid authentication helpers<http://freesoftwaremagazine.com/articles/authentication_with_squid/>
freesoftwaremagazine.com
Have you ever tried to figure out how to make Squid authenticate users according to your own exotic rules? Users are in a DB? Are you using an ActiveDirectory?


what might be a clue (sorry, I'm not really a PHP coder).


Antony.

--
Why is "dylexia" so difficult to spell, and why can I never remember "aphasia"
when I want to?

                                                   Please reply to the list;
                                                         please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
squid-users Info Page<http://lists.squid-cache.org/listinfo/squid-users>
lists.squid-cache.org
squid-users -- General discussion relating to Squid. The membership of this list is thousands of Squid users from around the world About squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171211/947ab760/attachment.htm>

From listas_quijada at hotmail.com  Mon Dec 11 22:01:30 2017
From: listas_quijada at hotmail.com (Edwin Quijada)
Date: Mon, 11 Dec 2017 22:01:30 +0000
Subject: [squid-users] Helper doent authentify
In-Reply-To: <201712112227.56547.Antony.Stone@squid.open.source.it>
References: <BN6PR15MB12033035509FF8207A94BD28E3370@BN6PR15MB1203.namprd15.prod.outlook.com>,
 <201712112227.56547.Antony.Stone@squid.open.source.it>
Message-ID: <BN6PR15MB1203C8DB883C7F0F3B61D98DE3370@BN6PR15MB1203.namprd15.prod.outlook.com>

This is my squid3.conf

#Recommended minimum configuration:

#acl manager proto cache_object
http_port 3128
cache_dir ufs /var/spool/squid3 2048 16 256
maximum_object_size 100 MB
cache_swap_low 90
cache_swap_high 95

#--------------- Reglas de Autorizacion -------------
auth_param basic program  /usr/bin/php /root/squid_helper2.php
auth_param basic children 20
auth_param basic realm Proxy Quijada Usuario Y Clave
auth_param basic credentialsttl 5 hours
#----------------------------------------------------
acl AuthenticatedUsers proxy_auth REQUIRED
http_access allow AuthenticatedUsers
#-------------------- ACL Puertos --------------------
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http

acl CONNECT method CONNECT

#---------------------- HTTP ACCES DEFAULT-------------
#http_access allow manager localhost
#http_access deny manager
#http_access deny !Safe_ports

#http_access deny to_localhost
#icp_access deny all
#htcp_access deny all






________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Antony Stone <Antony.Stone at squid.open.source.it>
Sent: Monday, December 11, 2017 9:27 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Helper doent authentify

On Monday 11 December 2017 at 22:19:53, Edwin Quijada wrote:

> Hi!
> I am trying to do a helper for use with Squid. I did my helper but it
> doesnt authentify
>
> <?php
>
> $f = fopen("php://stdin", "r");
> while (!(feof($f)))
> {
>     $line = fgets($f);
>     if ($line)
>      {
>         $fields = explode(' ', trim($line));
>         $username = rawurldecode($fields[0]);
>         $password = rawurldecode($fields[1]);
>
>         if ($username=="edwin" &&  $password=="1234")
>          fwrite(STDOUT, "OK\n");
>         else
>          fwrite(STDOUT, "ERR\n");
>     }
> }
> ?>
>
> when I put the values it continues asked me user/password

I think "$f" might be your problem.

See http://freesoftwaremagazine.com/articles/authentication_with_squid/ for
How to build squid authentication helpers<http://freesoftwaremagazine.com/articles/authentication_with_squid/>
freesoftwaremagazine.com
Have you ever tried to figure out how to make Squid authenticate users according to your own exotic rules? Users are in a DB? Are you using an ActiveDirectory?


what might be a clue (sorry, I'm not really a PHP coder).


Antony.

--
Why is "dylexia" so difficult to spell, and why can I never remember "aphasia"
when I want to?

                                                   Please reply to the list;
                                                         please *don't* CC me.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
squid-users Info Page<http://lists.squid-cache.org/listinfo/squid-users>
lists.squid-cache.org
squid-users -- General discussion relating to Squid. The membership of this list is thousands of Squid users from around the world About squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171211/d3a10f5e/attachment.htm>

From Antony.Stone at squid.open.source.it  Mon Dec 11 22:02:39 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 11 Dec 2017 23:02:39 +0100
Subject: [squid-users] Helper doent authentify
In-Reply-To: <BN6PR15MB12031A469F4C927964F22005E3370@BN6PR15MB1203.namprd15.prod.outlook.com>
References: <BN6PR15MB12033035509FF8207A94BD28E3370@BN6PR15MB1203.namprd15.prod.outlook.com>
 <201712112227.56547.Antony.Stone@squid.open.source.it>
 <BN6PR15MB12031A469F4C927964F22005E3370@BN6PR15MB1203.namprd15.prod.outlook.com>
Message-ID: <201712112302.39206.Antony.Stone@squid.open.source.it>

On Monday 11 December 2017 at 22:56:16, Edwin Quijada wrote:

> From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of
> Antony Stone <Antony.Stone at squid.open.source.it> Sent: Monday, December
> 11, 2017 9:27 PM
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Helper doent authentify
> 
> On Monday 11 December 2017 at 22:19:53, Edwin Quijada wrote:
> > Hi!
> > I am trying to do a helper for use with Squid. I did my helper but it
> > doesnt authentify

....

> I think "$f" might be your problem.
> 
> See http://freesoftwaremagazine.com/articles/authentication_with_squid/ for
> 
> I copied my example from this page. ?

Well, no, you didn't.

You may have used it as an example, but you changed it, and I think that 
change may be significant.

Try replacing "$f" in your script with "STDIN" as shown in the example, and 
see if this helps.

Incidentally, please reply only to the list and do not CC me (see my sigs).

Thanks,


Antony.

-- 
Normal people think "If it ain't broke, don't fix it".
Engineers think "If it ain't broke, it doesn't have enough features yet".

                                                   Please reply to the list;
                                                         please *don't* CC me.


From phackmann at gmail.com  Mon Dec 11 22:04:53 2017
From: phackmann at gmail.com (Paul Hackmann)
Date: Mon, 11 Dec 2017 16:04:53 -0600
Subject: [squid-users] squid asking for authentication repeatedly
Message-ID: <CADQL5rOea3c5RbvdrRtyB7dYpEsPmUfmu8XDjfOXApRwUTAYhw@mail.gmail.com>

Has anyone had the instance where the proxy will ask the user to
authenticate several times as they are browsing the web?  I have been
seeing this as a random occurrence for some of the users on the server.  It
will pop up a login prompt in the browser repeatedly for a minute or two.
Then it will settle down and be fine for hours.  I'm trying to track it
down, but I can't find anything amiss.  The access logs haven't shown
anything unusual.  I am using basic authentication with the proxy settings
set in firefox.  Is this something that a spike in traffic on the server
could cause?  Anybody have any suggestions?  The server is linux based.

PH
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171211/c5d9fe81/attachment.htm>

From alex at nanogherkin.com  Mon Dec 11 22:16:54 2017
From: alex at nanogherkin.com (Alex Crow)
Date: Mon, 11 Dec 2017 22:16:54 +0000
Subject: [squid-users] squid asking for authentication repeatedly
In-Reply-To: <CADQL5rOea3c5RbvdrRtyB7dYpEsPmUfmu8XDjfOXApRwUTAYhw@mail.gmail.com>
References: <CADQL5rOea3c5RbvdrRtyB7dYpEsPmUfmu8XDjfOXApRwUTAYhw@mail.gmail.com>
Message-ID: <8b4a6b3a-8ba8-4711-94f6-8513d25828e3@nanogherkin.com>

Firefox is not great at Auth. Chrome works better imho. FF seems ok with digest, ie AD. 

?Sent from TypeApp ?

On 11 Dec 2017, 22:05, at 22:05, Paul Hackmann <phackmann at gmail.com> wrote:
>Has anyone had the instance where the proxy will ask the user to
>authenticate several times as they are browsing the web?  I have been
>seeing this as a random occurrence for some of the users on the server.
> It
>will pop up a login prompt in the browser repeatedly for a minute or
>two.
>Then it will settle down and be fine for hours.  I'm trying to track it
>down, but I can't find anything amiss.  The access logs haven't shown
>anything unusual.  I am using basic authentication with the proxy
>settings
>set in firefox.  Is this something that a spike in traffic on the
>server
>could cause?  Anybody have any suggestions?  The server is linux based.
>
>PH
>
>
>------------------------------------------------------------------------
>
>_______________________________________________
>squid-users mailing list
>squid-users at lists.squid-cache.org
>http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171211/ff5336fa/attachment.htm>

From squid3 at treenet.co.nz  Tue Dec 12 01:03:22 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 12 Dec 2017 14:03:22 +1300
Subject: [squid-users] Groups and authorization SQUID
In-Reply-To: <BN6PR15MB12037091515BEB05BA12F701E3370@BN6PR15MB1203.namprd15.prod.outlook.com>
References: <BN6PR15MB1203D51EC21557CF8BC47441E3300@BN6PR15MB1203.namprd15.prod.outlook.com>
 <201712082350.51217.Antony.Stone@squid.open.source.it>
 <BN6PR15MB12039E5921388CCC0B44D46CE3310@BN6PR15MB1203.namprd15.prod.outlook.com>
 <201712091657.52150.Antony.Stone@squid.open.source.it>
 <BN6PR15MB12037091515BEB05BA12F701E3370@BN6PR15MB1203.namprd15.prod.outlook.com>
Message-ID: <8eb9c36c-3880-1bda-78d3-9412d8eed02c@treenet.co.nz>

On 12/12/17 09:48, Edwin Quijada wrote:
> 
> ------------------------------------------------------------------------
> *From:* Antony Stone
> On Saturday 09 December 2017 at 15:35:51, Edwin Quijada wrote:
> 
>> > On Friday 08 December 2017 at 22:08:33, Edwin Quijada wrote:
>> > 
>> > > I have 4 different groups in my company each group has access different
>> >
>> > Please explain what "access different" means.
>> 
>> The first group has accees to 2 pages, second 3 differents pages and? 3 and
>> 4 everything
> 
> Okay, understood.
> 

FYI: please be aware that HTTP has no concept of "page". That is a human 
UI concept. Squid and HTTP deal only with messages about URLs. A "page" 
as we know it can be many different transactions and URL messages.

We can get into that more later when you have auth working, just be 
aware for now that there is no natural connection between auth 
credentials and "page".


>> > > These groups and users are in a remote server
>> >
>> > What sort of server?? How are the groups defined?
>> 
>> It is a web server
> 
> Er, okay...
> 
>> > > that I use with a webservice
>> 
>> > What does "webservice" mean?
>>
>> Remote method/function that respond me when I sent? user/pass this respond
>> me with the group that user belongs I have another method/function/script
>> by http that respond me what is the group that user belongs
> 
> Okay, I guess it might be possible to get Squid to use ACLs based on the
> result of an HTTP request, but I've never seen it done like this before.
> 
> This part is not a problem for me.
> 
> Maybe someone else on the list can suggest how this might be made to work.
> 
>> > > so with I have created a helper for authorization
>> >
>> > Tell us how this helper works.
>> 
>> I thought that using a helper for autorization I can restricted the pages
>> used for each member group
> 
> Have you created a helper, or not?
> Yes!!
> 
> If you have created one, please tell us how it works.
> 
> This helper that I created
> <?php
> 
> $f = fopen("php://stdin", "r");
> while (!(feof($f))) {
>  ??? $line = fgets($f);
>  ??? if ($line) {
>  ??????? $fields = explode(' ', trim($line));
>  ??????? $username = rawurldecode($fields[0]);
>  ??????? $password = rawurldecode($fields[1]);
> //
>  ??????? if ($username=="edwin" &&? $password=="1234")
>  ????????????? fwrite(STDOUT, "OK\n");
>  ??????? else
>  ???????????? fwrite(STDOUT, "ERR\n");
>  ??? }
> }
> ?>
> This helper is just for testing , but when I tested it doent work
> 

What are your squid.conf settings using that helper?


FYI: PHP has known problems that prevent it being a successful helper 
language most of the time 
<https://wiki.squid-cache.org/Features/AddonHelpers#What_language_are_helper_meant_to_be_written_in.3F>

Squid bundles with *_fake_auth helpers you can base your code on when 
developing a custom helper. They handle the I/O with Squid properly for 
their matching Squid version and should be easily extended for doing 
actual auth checks.


>> > How does it identify one group from another?
>> 
>> Uhm...the structere are differents , really there are in different tables
>> in my DB that is in the server
> 
> So, you're doing an HTTP request to a web server, which then looks up 
> the user
> in a database, and returns a result as an HTTP response...
> 
> Surely it would be easier (and quicker / more efficient) to get Squid to
> interrogate the database?
> 
>> > > the problem is how can i do this ACL
> 
> I wouldn't start from there, so I hope someone else here can suggest a 
> way of
> getting this to work.
> 
> 
> What made you start with this approach in the first place?
> 
> Now, I changed the approach , I just want one group for everything and 
> other, localnet restricted,instead of use 4 groups just 2 one for admin, 
> other for
> 

The weird thing is this use of a web server as an intermediary between 
Squid and the actual user/group database. What made you use it in the 
first place instead of connecting Squid to the database?

[ I am one of the people who can help you get it to work, but it is only 
with the trouble doing at all if there is a good reason. Auth is a 
complex enough topic already just by itself. ]

Amos


From squid3 at treenet.co.nz  Tue Dec 12 01:16:17 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 12 Dec 2017 14:16:17 +1300
Subject: [squid-users] squid asking for authentication repeatedly
In-Reply-To: <CADQL5rOea3c5RbvdrRtyB7dYpEsPmUfmu8XDjfOXApRwUTAYhw@mail.gmail.com>
References: <CADQL5rOea3c5RbvdrRtyB7dYpEsPmUfmu8XDjfOXApRwUTAYhw@mail.gmail.com>
Message-ID: <3eb1226d-9dc8-33e9-0495-8ba902747596@treenet.co.nz>

On 12/12/17 11:04, Paul Hackmann wrote:
> Has anyone had the instance where the proxy will ask the user to 
> authenticate several times as they are browsing the web?? I have been 
> seeing this as a random occurrence for some of the users on the server.  
> It will pop up a login prompt in the browser repeatedly for a minute or 
> two.? Then it will settle down and be fine for hours.? I'm trying to 
> track it down, but I can't find anything amiss.? The access logs haven't 
> shown anything unusual.? I am using basic authentication with the proxy 
> settings set in firefox.? Is this something that a spike in traffic on 
> the server could cause?? Anybody have any suggestions?? The server is 
> linux based.
> 

What version of Squid?
What ACLs and http_access configuration?

Amos


From rafael.akchurin at diladele.com  Tue Dec 12 09:54:05 2017
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 12 Dec 2017 09:54:05 +0000
Subject: [squid-users] [icap] Web Safety RC 6.0 ICAP web filter plugin for
 Squid proxy is now Release Candidate
Message-ID: <AM4PR0401MB2194488F109FD115AEDA1CFC8F340@AM4PR0401MB2194.eurprd04.prod.outlook.com>

Greetings all,

We would like to announce the next version of Web Safety ICAP web filter for Squid proxy (version 6.0.0.EF8F, built on December 12, 2017) as Release Candidate.

This version contains the following fixes and improvements:


*        Added ability to block comments and related videos on YouTube.

*        Admin UI updated from Django 1.8.17 to Django 1.11.7 (breaking change!)

*        The backup/restore functionality was completely redesigned. It is now possible to directly import configuration backup from older version of the product into UI.

*        Added special community build of the product. This build is based on FOSS components and is completely free. Squid proxy, Admin UI to manage it, Traffic Monitor and ClamAV eCAP antivirus are included into the preconfigured virtual appliance based on Ubuntu 16 http://packages.diladele.com/websafety/6.0.0.EF8F/va/ubuntu16/websafety.zip .

*        Added support for haproxy's PROXY protocol, now it is possible to know the user's IP in cluster deployments. Policies can be applied by the IP address/range/subnet and not by only Active Directory authenticated user name/group.

*        Kerberos REALM field is moved to UI/Squid/Auth/Kerberos. Now is possible to use NTLM or LDAP authentication without configuring any Kerberos setting at all.

The version is available from https://www.diladele.com/download_next_version.html . It is recommended to use Ubuntu 16 and CentOS 7 based virtual appliances in production. Direct links to virtual appliances are:


*        http://packages.diladele.com/websafety/6.0.0.EF8F/va/ubuntu16/websafety.zip

*        http://packages.diladele.com/websafety/6.0.0.EF8F/va/centos7/websafety.zip

The final release is expected to take place at the end of January 2018. We are now slowly updating our docs site and all integration tutorials and continue acceptance tests on all platforms.

Please use this build in non critical production deployments. Your questions/issues/bugs are welcome at support at diladele.com<mailto:support at diladele.com>. Next version will include Google Safe Browsing protection as URL rewriter. Join our community to get early access to next development builds (see https://www.diladele.com/community.html).

Thanks to all of you for making this possible!

Rafael Akchurin
Diladele B.V.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171212/96442aa9/attachment.htm>

From ahmed.zaeem at netstream.ps  Tue Dec 12 13:52:08 2017
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 12 Dec 2017 15:52:08 +0200
Subject: [squid-users] question in :src/cf.data.pre "
Message-ID: <A88F7289-A293-435C-9CAE-1F127A71CE78@netstream.ps>

Hello folks .
wanna ask if possible to add  some directives to be by default added to the squid config file and when the squid run after compilation to take effect even i don?t add them to squid .conf 

id there a way to add them one shot in that file ?
src/cf.data.pre ??


i had a look and found like a formula like default value , name , doc stat , doc end ? etc


thanks 



From squid3 at treenet.co.nz  Tue Dec 12 14:06:10 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 13 Dec 2017 03:06:10 +1300
Subject: [squid-users] question in :src/cf.data.pre "
In-Reply-To: <A88F7289-A293-435C-9CAE-1F127A71CE78@netstream.ps>
References: <A88F7289-A293-435C-9CAE-1F127A71CE78@netstream.ps>
Message-ID: <0427fb71-a6ab-69b7-bbbc-b1f965618315@treenet.co.nz>

On 13/12/17 02:52, --Ahmad-- wrote:
> Hello folks .
> wanna ask if possible to add  some directives to be by default added to the squid config file and when the squid run after compilation to take effect even i don?t add them to squid .conf
> 

Directives to do what?

Amos


From ahmed.zaeem at netstream.ps  Tue Dec 12 14:31:45 2017
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 12 Dec 2017 16:31:45 +0200
Subject: [squid-users] question in :src/cf.data.pre "
In-Reply-To: <0427fb71-a6ab-69b7-bbbc-b1f965618315@treenet.co.nz>
References: <A88F7289-A293-435C-9CAE-1F127A71CE78@netstream.ps>
 <0427fb71-a6ab-69b7-bbbc-b1f965618315@treenet.co.nz>
Message-ID: <B0BF73AC-7EC8-476A-9949-4494A259B0B0@netstream.ps>

as an example i want directives to be added automatically without adding them to squid.conf 

look below :

acl ip1 myip 1.2.3.4
http_access allow ip1
http_port 6532

so above i want them to be added to squid.conf without add them there 

so i run squid in terminal it will contact default squid.conf which has no config 

but it will have the config above added automatically 

make sense ?



cheers 

> On Dec 12, 2017, at 4:06 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 13/12/17 02:52, --Ahmad-- wrote:
>> Hello folks .
>> wanna ask if possible to add  some directives to be by default added to the squid config file and when the squid run after compilation to take effect even i don?t add them to squid .conf
> 
> Directives to do what?
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From heiler.bemerguy at cinbesa.com.br  Tue Dec 12 14:46:22 2017
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Tue, 12 Dec 2017 11:46:22 -0300
Subject: [squid-users] Android client flooding squid
Message-ID: <f6f9d063-ff95-2994-7e4f-ce11c07a1c7b@cinbesa.com.br>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171212/dccb0fd1/attachment.htm>

From Antony.Stone at squid.open.source.it  Tue Dec 12 14:59:19 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 12 Dec 2017 15:59:19 +0100
Subject: [squid-users] question in :src/cf.data.pre "
In-Reply-To: <A88F7289-A293-435C-9CAE-1F127A71CE78@netstream.ps>
References: <A88F7289-A293-435C-9CAE-1F127A71CE78@netstream.ps>
Message-ID: <201712121559.19679.Antony.Stone@squid.open.source.it>

On Tuesday 12 December 2017 at 14:52:08, --Ahmad-- wrote:

> Hello folks .
> wanna ask if possible to add  some directives to be by default added to the
> squid config file and when the squid run after compilation to take effect
> even i don?t add them to squid .conf

http://lists.squid-cache.org/pipermail/squid-users/2016-July/011732.html

Was there anything about the reply you got then which doesn't answer your 
current question?


Antony.

-- 
"640 kilobytes (of RAM) should be enough for anybody."

 - Bill Gates

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Tue Dec 12 15:06:34 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 13 Dec 2017 04:06:34 +1300
Subject: [squid-users] question in :src/cf.data.pre "
In-Reply-To: <B0BF73AC-7EC8-476A-9949-4494A259B0B0@netstream.ps>
References: <A88F7289-A293-435C-9CAE-1F127A71CE78@netstream.ps>
 <0427fb71-a6ab-69b7-bbbc-b1f965618315@treenet.co.nz>
 <B0BF73AC-7EC8-476A-9949-4494A259B0B0@netstream.ps>
Message-ID: <0337158a-a59f-ce07-9061-b6ea6b17b158@treenet.co.nz>

On 13/12/17 03:31, --Ahmad-- wrote:
> as an example i want directives to be added automatically without adding them to squid.conf
> 
> look below :
> 
> acl ip1 myip 1.2.3.4
> http_access allow ip1
> http_port 6532
> 
> so above i want them to be added to squid.conf without add them there
> 
> so i run squid in terminal it will contact default squid.conf which has no config
> 
> but it will have the config above added automatically
> 
> make sense ?
> 

Sort of. See should be able to see how to add fixed default values for 
those directives are already being defined for how to add fixed values.

Your problem will be that the default config is loaded *before* Squid 
starts receiving traffic. The myip value is very dynamic and changes or 
only identifiable *after* Squid is fully running. It can even change 
between TCP connections arriving if the machines NIC assignments change.


Since your values are fixed at compile time and cannot be changed 
dynamically you may do better to have a squid.conf with those settings 
that gets loaded always and uses the include directive to load any other 
user configurable content.

Have a look at the way I'm doing separation between Squid packages 
config and admin config for Debian Squid-4 packages:
 
<https://alioth.debian.org/plugins/scmgit/cgi-bin/gitweb.cgi?p=pkg-squid/pkg-squid.git;a=commitdiff;h=3a068f640abdc87df8a767e8625289534c81ea69>
 
<https://alioth.debian.org/plugins/scmgit/cgi-bin/gitweb.cgi?p=pkg-squid/pkg-squid.git;a=commitdiff;h=586d19bb0ad644c6599407696a7a137af1575f93>


Amos


From ahmed.zaeem at netstream.ps  Tue Dec 12 15:08:22 2017
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 12 Dec 2017 17:08:22 +0200
Subject: [squid-users] question in :src/cf.data.pre "
In-Reply-To: <B0BF73AC-7EC8-476A-9949-4494A259B0B0@netstream.ps>
References: <A88F7289-A293-435C-9CAE-1F127A71CE78@netstream.ps>
 <0427fb71-a6ab-69b7-bbbc-b1f965618315@treenet.co.nz>
 <B0BF73AC-7EC8-476A-9949-4494A259B0B0@netstream.ps>
Message-ID: <693C77E3-F261-4EA7-875E-B6AC218F4385@netstream.ps>

you correct .

but I?m asking about something different like non config in the file :



acl ip1 myip 1.2.3.4
http_access allow ip1
http_port 6532





i know the pre.cc file has some config 

but i want to add something different 

thanks 
> On Dec 12, 2017, at 4:31 PM, --Ahmad-- <ahmed.zaeem at netstream.ps> wrote:
> 
> acl ip1 myip 1.2.3.4
> http_access allow ip1
> http_port 6532

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171212/0a1b08e6/attachment.htm>

From phackmann at gmail.com  Tue Dec 12 15:09:40 2017
From: phackmann at gmail.com (Paul Hackmann)
Date: Tue, 12 Dec 2017 09:09:40 -0600
Subject: [squid-users] squid asking for authentication repeatedly
In-Reply-To: <8b4a6b3a-8ba8-4711-94f6-8513d25828e3@nanogherkin.com>
References: <CADQL5rOea3c5RbvdrRtyB7dYpEsPmUfmu8XDjfOXApRwUTAYhw@mail.gmail.com>
 <8b4a6b3a-8ba8-4711-94f6-8513d25828e3@nanogherkin.com>
Message-ID: <CADQL5rMgcbg0L4HBez4NACLDb0htpV0PWK1x7dDG3-Gr23Pjnw@mail.gmail.com>

Alex,

That is certainly something I can test.  It was never a problem before, so
I wonder if one of the recent updates (pre-quantum) has introduced a new
issue with firefox.  Thanks.
PH

On Mon, Dec 11, 2017 at 4:16 PM, Alex Crow <alex at nanogherkin.com> wrote:

> Firefox is not great at Auth. Chrome works better imho. FF seems ok with
> digest, ie AD.
>
> Sent from TypeApp <http://www.typeapp.com/r?b=11347>
> On 11 Dec 2017, at 22:05, Paul Hackmann <phackmann at gmail.com> wrote:
>>
>> Has anyone had the instance where the proxy will ask the user to
>> authenticate several times as they are browsing the web?  I have been
>> seeing this as a random occurrence for some of the users on the server.  It
>> will pop up a login prompt in the browser repeatedly for a minute or two.
>> Then it will settle down and be fine for hours.  I'm trying to track it
>> down, but I can't find anything amiss.  The access logs haven't shown
>> anything unusual.  I am using basic authentication with the proxy settings
>> set in firefox.  Is this something that a spike in traffic on the server
>> could cause?  Anybody have any suggestions?  The server is linux based.
>>
>> PH
>>
>> ------------------------------
>>
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171212/f00e6f29/attachment.htm>

From phackmann at gmail.com  Tue Dec 12 15:10:28 2017
From: phackmann at gmail.com (Paul Hackmann)
Date: Tue, 12 Dec 2017 09:10:28 -0600
Subject: [squid-users] squid asking for authentication repeatedly
In-Reply-To: <3eb1226d-9dc8-33e9-0495-8ba902747596@treenet.co.nz>
References: <CADQL5rOea3c5RbvdrRtyB7dYpEsPmUfmu8XDjfOXApRwUTAYhw@mail.gmail.com>
 <3eb1226d-9dc8-33e9-0495-8ba902747596@treenet.co.nz>
Message-ID: <CADQL5rN5md1g9_-BrGz4AybZ79dNm8GYHB_u=VBmunQQ9EVL3w@mail.gmail.com>

Amos,

The squid version is 3.1.19.  The network is set up with a 192.168.0.X
network on the lan side, and a 192.168.1.x network on the internet side.
Both ports 3120 and 4120 require authentication, but port 4120 is meant to
be restricted to only the whitelisted sites which are in a separate file.
Port 3120 allows access to any site.  The browser causing trouble is
configured for port 3120, not 4120.  Here is my squid.conf file:

http_port 3120
http_port 4120 intercept

cache_dir ufs /var/spool/squid3 500 16 256

#not sure what this block is for
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320

acl whitelist dstdomain "/etc/squid3/whitelist.conf"

auth_param basic program /usr/lib/squid3/ncsa_auth /etc/squid3/passwd
auth_param basic children 6
auth_param basic realm Squid proxy-caching web server
auth_param basic credentialsttl 4 hours
auth_param basic casesensitive off

acl ncsa_users proxy_auth REQUIRED

#not sure what this line does
acl manager url_regex -i ^cache_object:// +i ^https?://[^/]+/squid-
internal-mgr/

acl localhost src 127.0.0.1/32 ::1
acl to_localhost dst 127.0.0.0/8 0.0.0.0/32 ::1

acl localnet src 10.0.0.0/8     # RFC 1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC 1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC 1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines

#acl http proto http
acl SSL_ports port 443
acl port_80 port 80
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http

#list of computers that have access by ip address
acl allowed_clients src 192.168.0.9-192.168.0.45 192.168.0.53 192.168.0.65
192.168.0.83 192.168.0.90 192.168.0.91 192.168.0.179 192.168.0.186
192.168.0.220 192.168.0.221 192.168.0.244

acl portX myportname 4120
http_access allow portX whitelist
http_access deny portX

acl deny_websites dstdomain "/etc/squid3/deny_websites.conf"
acl CONNECT method CONNECT
#acl wuCONNECT dstdomain "/etc/squid3/whitelist.conf"
#acl wuCONNECT dstdomain sls.microsoft.com

#rule allowing nonauthenticated users
#http_access allow http port_80 whitelist
http_access allow CONNECT SSL_ports whitelist

#other access rules
#http_access deny !ncsa_users
http_access allow CONNECT localnet
http_access deny deny_websites
http_access allow allowed_clients ncsa_users
http_access deny !allowed_clients
#http_access allow ncsa_users
http_access allow manager localhost
http_access deny manager
http_access deny !Safe_ports
#http_access deny CONNECT !SSL_ports
http_access allow localhost
#http_access allow localnet

http_access deny all

If the conf file is a mess, or has some problems, feel free to say so, as I
don't know what all of the directives in it are for.  I marked a couple of
lines I don't understand.  I would be happy for it to be optimized more if
anyone has ideas.

Thanks,
PH

On Mon, Dec 11, 2017 at 7:16 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 12/12/17 11:04, Paul Hackmann wrote:
>
>> Has anyone had the instance where the proxy will ask the user to
>> authenticate several times as they are browsing the web?  I have been
>> seeing this as a random occurrence for some of the users on the server.  It
>> will pop up a login prompt in the browser repeatedly for a minute or two.
>> Then it will settle down and be fine for hours.  I'm trying to track it
>> down, but I can't find anything amiss.  The access logs haven't shown
>> anything unusual.  I am using basic authentication with the proxy settings
>> set in firefox.  Is this something that a spike in traffic on the server
>> could cause?  Anybody have any suggestions?  The server is linux based.
>>
>>
> What version of Squid?
> What ACLs and http_access configuration?
>
> Amos
> _______________________________________________
>
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171212/4464a336/attachment.htm>

From ahmed.zaeem at netstream.ps  Tue Dec 12 15:12:59 2017
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 12 Dec 2017 17:12:59 +0200
Subject: [squid-users] question in :src/cf.data.pre "
In-Reply-To: <B0BF73AC-7EC8-476A-9949-4494A259B0B0@netstream.ps>
References: <A88F7289-A293-435C-9CAE-1F127A71CE78@netstream.ps>
 <0427fb71-a6ab-69b7-bbbc-b1f965618315@treenet.co.nz>
 <B0BF73AC-7EC8-476A-9949-4494A259B0B0@netstream.ps>
Message-ID: <48D506BE-EA40-4E56-86C0-30305E36ADFE@netstream.ps>

@amos about your question .

i think ?include option ? is ok , but i also need it to be hidden and not added to squid.conf 

say like :

include /var/test.cc

would like this is loaded automatically and don?t need to add it in squid.conf ???


i mean each time i run squid it will load like include other file .

i tried to add into pre file below config :

NAME: include
TYPE: string
LOC: Config.include
DEFAULT: /var/test.cc
DOC_START
    Hello
DOC_END


i guess it will load the line built in squid.conf like ==> include /var/test.cc

and then i can add what i like into the file ==>  /var/test.cc


but i got fail during compilation process .

may be my point above help ?





> On Dec 12, 2017, at 4:31 PM, --Ahmad-- <ahmed.zaeem at netstream.ps> wrote:
> 
> acl ip1 myip 1.2.3.4
> http_access allow ip1
> http_port 6532

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171212/0ff3e4f8/attachment.htm>

From Antony.Stone at squid.open.source.it  Tue Dec 12 15:20:23 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 12 Dec 2017 16:20:23 +0100
Subject: [squid-users] question in :src/cf.data.pre "
In-Reply-To: <48D506BE-EA40-4E56-86C0-30305E36ADFE@netstream.ps>
References: <A88F7289-A293-435C-9CAE-1F127A71CE78@netstream.ps>
 <B0BF73AC-7EC8-476A-9949-4494A259B0B0@netstream.ps>
 <48D506BE-EA40-4E56-86C0-30305E36ADFE@netstream.ps>
Message-ID: <201712121620.23518.Antony.Stone@squid.open.source.it>

On Tuesday 12 December 2017 at 16:12:59, --Ahmad-- wrote:

> @amos about your question .
> 
> i think ?include option ? is ok , but i also need it to be hidden and not
> added to squid.conf

Who are you trying to hide this from?

Antony.

-- 
In Heaven, the beer is Belgian, the chefs are Italian, the supermarkets are 
British, the mechanics are German, the lovers are French, the entertainment is 
American, and everything is organised by the Swiss.

In Hell, the beer is American, the chefs are British, the supermarkets are 
German, the mechanics are French, the lovers are Swiss, the entertainment is 
Belgian, and everything is organised by the Italians.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From ahmed.zaeem at netstream.ps  Tue Dec 12 15:30:47 2017
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Tue, 12 Dec 2017 17:30:47 +0200
Subject: [squid-users] question in :src/cf.data.pre "
In-Reply-To: <48D506BE-EA40-4E56-86C0-30305E36ADFE@netstream.ps>
References: <A88F7289-A293-435C-9CAE-1F127A71CE78@netstream.ps>
 <0427fb71-a6ab-69b7-bbbc-b1f965618315@treenet.co.nz>
 <B0BF73AC-7EC8-476A-9949-4494A259B0B0@netstream.ps>
 <48D506BE-EA40-4E56-86C0-30305E36ADFE@netstream.ps>
Message-ID: <3B0B3776-A9BF-4070-9892-4E76E22D3867@netstream.ps>

@antony 

i will wait amos reply  !

thanks for your time 

cheers 

> On Dec 12, 2017, at 5:12 PM, --Ahmad-- <ahmed.zaeem at netstream.ps> wrote:
> 
> @amos about your question .
> 
> i think ?include option ? is ok , but i also need it to be hidden and not added to squid.conf 
> 
> say like :
> 
> include /var/test.cc <http://test.cc/>
> 
> would like this is loaded automatically and don?t need to add it in squid.conf ???
> 
> 
> i mean each time i run squid it will load like include other file .
> 
> i tried to add into pre file below config :
> 
> NAME: include
> TYPE: string
> LOC: Config.include
> DEFAULT: /var/test.cc <http://test.cc/>
> DOC_START
>     Hello
> DOC_END
> 
> 
> i guess it will load the line built in squid.conf like ==> include /var/test.cc <http://test.cc/>
> 
> and then i can add what i like into the file ==>  /var/test.cc <http://test.cc/>
> 
> 
> but i got fail during compilation process .
> 
> may be my point above help ?
> 
> 
> 
> 
> 
>> On Dec 12, 2017, at 4:31 PM, --Ahmad-- <ahmed.zaeem at netstream.ps <mailto:ahmed.zaeem at netstream.ps>> wrote:
>> 
>> acl ip1 myip 1.2.3.4
>> http_access allow ip1
>> http_port 6532
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171212/6ac828c3/attachment.htm>

From squid3 at treenet.co.nz  Tue Dec 12 15:35:59 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 13 Dec 2017 04:35:59 +1300
Subject: [squid-users] Android client flooding squid
In-Reply-To: <f6f9d063-ff95-2994-7e4f-ce11c07a1c7b@cinbesa.com.br>
References: <f6f9d063-ff95-2994-7e4f-ce11c07a1c7b@cinbesa.com.br>
Message-ID: <bc7ec792-65c9-9d8d-5cdc-55bd1ed4e888@treenet.co.nz>

On 13/12/17 03:46, Heiler Bemerguy wrote:
> 
> Hi guys,
> 
> Everyday I get tons of these GETs, a lot from the same IP, then a lot 
> from other IPs of our local intranet (we have some APs plugged on our 
> intranet). This is happening since forever, but I'm trying to 
> understand/get rid of it.
> 
> Any ideas?
> 

The client software is broken.

1) using explicit URLs with raw-IPv4 to make its requests, and ..

2) performing Host header forgery. www.google.com is hosted in Googles 
servers assigned the 216/8 IP range not the 172/8 range. And ..

3) not obeying the clear instruction that the given Domain is *only* 
available when fetched by name (not by raw-IP).


Your options are to either;

  get the client software fixed

OR,
  configure ACLs detecting when such clients deliver those raw-IP URLs 
and reject them with a 403 instead of a 301,

That can be done with an external ACL helper in http_reply_access that 
tracks 301 + Content-Location and which client they were sent to. 
Rejecting them with a 403 after an arbitrary number of repeats.


Amos


From jascha.sticher at tds.fujitsu.com  Tue Dec 12 15:51:05 2017
From: jascha.sticher at tds.fujitsu.com (Sticher, Jascha)
Date: Tue, 12 Dec 2017 15:51:05 +0000
Subject: [squid-users] FTP proxy chain with native ftp
Message-ID: <E286ADE35F919742812E3076A36122E701BFC7EADF@tdsnsumbx2vp>

Hi,

we're currently upgrading our proxy environment to squid 3.5.23 (Debian Stretch) and would like to use the native FTP proxy feature to replace our old FTP proxy solution (frox).

Due to some design choices, we have a proxy hierarchy for HTTP as well as FTP traffic. Is there a way (yet) to tell my first squid instance to use another squid as a forward proxy with native FTP?

IIRC, the cache_peer directive always uses HTTP requests, so this seems as a dead end.



Mit freundlichen Gr??en / Kind regards,

Jascha Sticher



From squid3 at treenet.co.nz  Tue Dec 12 16:30:39 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 13 Dec 2017 05:30:39 +1300
Subject: [squid-users] squid asking for authentication repeatedly
In-Reply-To: <CADQL5rN5md1g9_-BrGz4AybZ79dNm8GYHB_u=VBmunQQ9EVL3w@mail.gmail.com>
References: <CADQL5rOea3c5RbvdrRtyB7dYpEsPmUfmu8XDjfOXApRwUTAYhw@mail.gmail.com>
 <3eb1226d-9dc8-33e9-0495-8ba902747596@treenet.co.nz>
 <CADQL5rN5md1g9_-BrGz4AybZ79dNm8GYHB_u=VBmunQQ9EVL3w@mail.gmail.com>
Message-ID: <37faddcb-b809-9d30-5fd5-503b64f529f8@treenet.co.nz>

On 13/12/17 04:10, Paul Hackmann wrote:
> Amos,
> 
> The squid version is 3.1.19.

Please upgrade. There have been a *lot* of authentication related issues 
that got solved in the years since that version was released. IIRC 
several involved nasty things like the looping you described.

All current OS distributions have more recent Squid versions available. 
Or worst-case custom building is not very hard.


>? The network is set up with a 192.168.0.X 
> network on the lan side, and a 192.168.1.x network on the internet 
> side.? Both ports 3120 and 4120 require authentication,


NOTE: port 4120 is an intercepted port. HTTP Proxy Authentication on 
traffic arriving there is prohibited, since the HTTP traffic syntax is 
origin-form.

However that said, your config displayed below contradicts what you 
wrote above. Port 41290 traffic does *not* use authentication - the only 
restriction on port 4120 traffic is that it be going to one of the 
whitelisted domains. Period. There is absolutely no restriction on what 
happens or can be done when going to those domains.



> but port 4120 is 
> meant to be restricted to only the whitelisted sites which are in a 
> separate file.? Port 3120 allows access to any site.? The browser 
> causing trouble is configured for port 3120, not 4120.? Here is my 
> squid.conf file:
> 
...
> 
> #not sure what this line does
> acl manager url_regex -i ^cache_object:// +i 
> ^https?://[^/]+/squid-internal-mgr/
> 

The above line defines an ACL which matches requests for Squids internal 
cache management reports. For both the Squid-2+ and Squid-3.4+ 
management APIs.

Your Squid version requires this to be configured. Current releases 
provide it as a built-in default ACL so you don't need to track or fix 
its definition changes during upgrade.

...
> http_access allow CONNECT localnet

Bad. All LAN clients are allowed to open arbitrary TCP connections 
(CONNECT tunnels) through the proxy *to anywhere* absolutely zero 
restrictions.

The entire point of the "deny CONNECT !SSL_ports" and other default 
security rules is to prohibit attackers and infected LAN clients from 
using the proxy to spread nasty traffic around.

To be useful those default security measure must be placed *first* in 
the http_access ordering and written exactly as provided in the default 
installation. Your own rules should be applied to the traffic which gets 
past those basic precautions.


> http_access deny deny_websites
> http_access allow allowed_clients ncsa_users
> http_access deny !allowed_clients
> #http_access allow ncsa_users
> http_access allow manager localhost
> http_access deny manager
> http_access deny !Safe_ports
> #http_access deny CONNECT !SSL_ports
> http_access allow localhost
> #http_access allow localnet
> 
> http_access deny all
> 
> If the conf file is a mess, or has some problems, feel free to say so, 
> as I don't know what all of the directives in it are for.? I marked a 
> couple of lines I don't understand.? I would be happy for it to be 
> optimized more if anyone has ideas.
> 

I recommend you write your http_access something like so:


  http_access deny !Safe_ports
  http_access deny CONNECT !SSL_ports
  http_access allow manager localhost
  http_access deny manager

  # domains in deny_websites are DENIED for everybody.
  http_access deny deny_websites

  # domains in whitelist are ALLOWED for everybody
  http_access allow whitelist

  # port 4120 traffic is restricted to the above whitelisted domains
  http_access deny portX

  # otherwise; for port 3120 traffic ...

  # only specific clients with whitelisted IPs can use the proxy ...
  http_access deny !allowed_clients

  # ... and must also login
  http_access deny !ncsa_users

  http_access allow localnet

  http_access deny all


If the above still has the looping issue then I think the problem is 
related to how the Browser is using its TCP connections.

Some Browsers used to open many parallel TCP connections and start 
requesting stuff immediately. But their internal credential handling 
seemed not to cope with the parallelism, treating the 2nd through Nth 
auth challenges as a sign that the 1st connections credentials were invalid.

This was particularly bad for any Browsers configured to auto-load many 
tabs on startup. I've not heard of it happening in quite a while though, 
so it may be fixed in current Browsers. Or maybe they just handle tabs 
differently that does not trigger so easily.

Amos


From squid3 at treenet.co.nz  Tue Dec 12 16:42:39 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 13 Dec 2017 05:42:39 +1300
Subject: [squid-users] question in :src/cf.data.pre "
In-Reply-To: <48D506BE-EA40-4E56-86C0-30305E36ADFE@netstream.ps>
References: <A88F7289-A293-435C-9CAE-1F127A71CE78@netstream.ps>
 <0427fb71-a6ab-69b7-bbbc-b1f965618315@treenet.co.nz>
 <B0BF73AC-7EC8-476A-9949-4494A259B0B0@netstream.ps>
 <48D506BE-EA40-4E56-86C0-30305E36ADFE@netstream.ps>
Message-ID: <5328d938-1438-60dc-03df-92711f1388ae@treenet.co.nz>

On 13/12/17 04:12, --Ahmad-- wrote:
> @amos about your question .
> 
> i think ?include option ? is ok , but i also need it to be hidden and 
> not added to squid.conf
> 
> say like :
> 
> include /var/test.cc
> 
> would like this is loaded automatically and don?t need to add it in 
> squid.conf ???
> 
> 
> i mean each time i run squid it will load like include other file .
> 
> i tried to add into pre file below config :
> 
> NAME: include
> TYPE: string
> LOC: Config.include
> DEFAULT: /var/test.cc <http://test.cc>
> DOC_START
>  ? ? Hello
> DOC_END
> 

Not like this. "include" is a hard-coded behaviour, not a normal 
directive. It needs to be used like the Debian patch does, with 
"squid.conf" file being the pre-determined settings and users in control 
of the other stuff pulled in by 'include' from somewhere else.


OR, you just use the -f command line option to point at your custom 
config file when you run Squid "from terminal".


I wasn't going to bother asking for a fourth time, but since Anthony did 
"who are you trying to hide this from?" is still unanswered. Anyone who 
might see these settings in the config file can also find them by other 
means (ie looking at the machines open ports). So the lengths you are 
going to hide them is very weird.


Amos


From rousskov at measurement-factory.com  Tue Dec 12 16:52:51 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 12 Dec 2017 09:52:51 -0700
Subject: [squid-users] FTP proxy chain with native ftp
In-Reply-To: <E286ADE35F919742812E3076A36122E701BFC7EADF@tdsnsumbx2vp>
References: <E286ADE35F919742812E3076A36122E701BFC7EADF@tdsnsumbx2vp>
Message-ID: <302e7fd2-acb7-6935-3c7e-157599165000@measurement-factory.com>

On 12/12/2017 08:51 AM, Sticher, Jascha wrote:

> Is there a way (yet) to tell my first squid instance to use another squid as a forward proxy with native FTP?

> IIRC, the cache_peer directive always uses HTTP requests, so this seems as a dead end.

You are probably right. IIRC, the FTP client inside Squid does not
support FTP proxies. I am not aware of any work being done in that area.

Alex.


From squid3 at treenet.co.nz  Tue Dec 12 16:56:08 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 13 Dec 2017 05:56:08 +1300
Subject: [squid-users] FTP proxy chain with native ftp
In-Reply-To: <E286ADE35F919742812E3076A36122E701BFC7EADF@tdsnsumbx2vp>
References: <E286ADE35F919742812E3076A36122E701BFC7EADF@tdsnsumbx2vp>
Message-ID: <8b6d84f8-a085-588d-2136-8b366406af7d@treenet.co.nz>

On 13/12/17 04:51, Sticher, Jascha wrote:
> Hi,
> 
> we're currently upgrading our proxy environment to squid 3.5.23 (Debian Stretch) and would like to use the native FTP proxy feature to replace our old FTP proxy solution (frox).
> 
> Due to some design choices, we have a proxy hierarchy for HTTP as well as FTP traffic. Is there a way (yet) to tell my first squid instance to use another squid as a forward proxy with native FTP?
> 
> IIRC, the cache_peer directive always uses HTTP requests, so this seems as a dead end.
> 


The FTP traffic arriving at Squids ftp_port is converted from a stream 
of FTP messages to a stream of HTTP messages for handling.

AFAIK those resulting HTTP messages can be routed through a cache_peer 
same as any other HTTP traffic. BUT at very least the peer needs to also 
have the same "native FTP" implementation to successfully convert them 
from HTTP back to FTP native messages on the outgoing server connections 
at the other side of the cache hierarchy.

There may be other internal state checks on the HTTP messages to make 
them get the "native FTP" conversion on outgoing. So YMMV.

If the peer delivery does not work you may be required to do the same 
workaround SSL-Bump sometimes requires. Do allow the front-end Squid to 
re-FTP the traffic to the appropriate server then intercept it 
independently into the backend with its own ftp_port accepting the 
"native FTP" coming out of the frontend.

FYI: I do know there are conversion issues with FTP <-> HTTP 
authentication recently uncovered and not yet resolved. So if you need 
proxy auth at all staying with Frox would be better for now.

Amos


From rousskov at measurement-factory.com  Tue Dec 12 17:13:52 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 12 Dec 2017 10:13:52 -0700
Subject: [squid-users] FTP proxy chain with native ftp
In-Reply-To: <8b6d84f8-a085-588d-2136-8b366406af7d@treenet.co.nz>
References: <E286ADE35F919742812E3076A36122E701BFC7EADF@tdsnsumbx2vp>
 <8b6d84f8-a085-588d-2136-8b366406af7d@treenet.co.nz>
Message-ID: <4287fdf6-49e5-81b9-f559-ec0121dd4ed9@measurement-factory.com>

On 12/12/2017 09:56 AM, Amos Jeffries wrote:
> On 13/12/17 04:51, Sticher, Jascha wrote:
>> Is there a way (yet) to tell my first squid instance
>> to use another squid as a forward proxy with native FTP?


> The FTP traffic arriving at Squids ftp_port is converted from a stream
> of FTP messages to a stream of HTTP messages for handling.

> AFAIK those resulting HTTP messages can be routed through a cache_peer
> same as any other HTTP traffic. 

I hope such routing is not possible today, but I do not know for sure.
AFAIK, no peer would be able to convert those wrapper HTTP messages back
into FTP. I hope the wrapper messages are always routed to FTP Client
code inside Squid using pinned Squid-FTP-server connections or something
like that.


> BUT at very least the peer needs to also
> have the same "native FTP" implementation to successfully convert them
> from HTTP back to FTP native messages on the outgoing server connections
> at the other side of the cache hierarchy.

* The "native FTP" Server implementation inside Squid does not convert
HTTP wrapper messages into FTP native messages. It converts FTP commands
into HTTP wrapper messages.

* The native FTP Client implementation inside Squid does the opposite
conversion, but it partners with the FTP Server implementation inside
Squid, not the HTTP Server implementation inside Squid.

* If wrapper HTTP messages reach a Squid peer, they will be handled by
the HTTP Server implementation inside peer Squid.

Thus, one cannot use another Squid to unwrap HTTP wrapper messages sent
by the child Squid, even if the routing code allows for those wrapper
messages to escape a Squid instance. The pieces required for everything
to work together are missing.


> Do allow the front-end Squid to
> re-FTP the traffic to the appropriate server then intercept it
> independently into the backend with its own ftp_port accepting the
> "native FTP" coming out of the frontend.

Good idea! Interception should work indeed. The "child" Squid will not
know what is going on, but both Squids will receive and send native FTP
traffic.


CHeers,

Alex.


From erdosain9 at gmail.com  Tue Dec 12 18:55:34 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 12 Dec 2017 11:55:34 -0700 (MST)
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <0c014387-37ad-8eaf-a1e3-c9124a6234ce@treenet.co.nz>
References: <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
 <1512502436344-0.post@n4.nabble.com>
 <f79d0f42-90d3-ddc1-f4ac-507318591860@measurement-factory.com>
 <426ba648-4c6e-4cfe-7f09-7df5a010390f@gmail.com>
 <8962948e-7c6c-a18b-1738-22b3d646fd40@gmail.com>
 <1512659105185-0.post@n4.nabble.com>
 <f0329ce7-5080-9ac8-a07a-db332833001a@measurement-factory.com>
 <1512670685051-0.post@n4.nabble.com>
 <0c014387-37ad-8eaf-a1e3-c9124a6234ce@treenet.co.nz>
Message-ID: <1513104934635-0.post@n4.nabble.com>

Thanks.
I update to  3.5.27 and now i dont have this problem.
But, i have this doubt... so, this was a problem of my certificate or a bug
from squid???

Thanks



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From yvoinov at gmail.com  Tue Dec 12 21:10:35 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 13 Dec 2017 03:10:35 +0600
Subject: [squid-users] net::err_cert_common_name_invalid just in squid
 page with dstdomain block
In-Reply-To: <1513104934635-0.post@n4.nabble.com>
References: <1512493548544-0.post@n4.nabble.com>
 <74418a25-e6b2-844a-91bf-dd600498bf15@measurement-factory.com>
 <1512502436344-0.post@n4.nabble.com>
 <f79d0f42-90d3-ddc1-f4ac-507318591860@measurement-factory.com>
 <426ba648-4c6e-4cfe-7f09-7df5a010390f@gmail.com>
 <8962948e-7c6c-a18b-1738-22b3d646fd40@gmail.com>
 <1512659105185-0.post@n4.nabble.com>
 <f0329ce7-5080-9ac8-a07a-db332833001a@measurement-factory.com>
 <1512670685051-0.post@n4.nabble.com>
 <0c014387-37ad-8eaf-a1e3-c9124a6234ce@treenet.co.nz>
 <1513104934635-0.post@n4.nabble.com>
Message-ID: <6235b437-e5bc-05f2-3d19-41ec1bd85c9f@gmail.com>

Probably, both.

Also squid fastly changes (especially in SSL part), so in any case when
in doubt first consider upgrade.


13.12.2017 0:55, erdosain9 ?????:
> Thanks.
> I update to  3.5.27 and now i dont have this problem.
> But, i have this doubt... so, this was a problem of my certificate or a bug
> from squid???
>
> Thanks
>
>
>
> --
> Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171213/5dee4766/attachment.sig>

From listas_quijada at hotmail.com  Tue Dec 12 21:48:23 2017
From: listas_quijada at hotmail.com (Edwin Quijada)
Date: Tue, 12 Dec 2017 21:48:23 +0000
Subject: [squid-users] Groups and authorization SQUID
In-Reply-To: <8eb9c36c-3880-1bda-78d3-9412d8eed02c@treenet.co.nz>
References: <BN6PR15MB1203D51EC21557CF8BC47441E3300@BN6PR15MB1203.namprd15.prod.outlook.com>
 <201712082350.51217.Antony.Stone@squid.open.source.it>
 <BN6PR15MB12039E5921388CCC0B44D46CE3310@BN6PR15MB1203.namprd15.prod.outlook.com>
 <201712091657.52150.Antony.Stone@squid.open.source.it>
 <BN6PR15MB12037091515BEB05BA12F701E3370@BN6PR15MB1203.namprd15.prod.outlook.com>,
 <8eb9c36c-3880-1bda-78d3-9412d8eed02c@treenet.co.nz>
Message-ID: <BN6PR15MB1203A8F78C56178C3EB18992E3340@BN6PR15MB1203.namprd15.prod.outlook.com>




________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Amos Jeffries <squid3 at treenet.co.nz>
Sent: Tuesday, December 12, 2017 1:03 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Groups and authorization SQUID

On 12/12/17 09:48, Edwin Quijada wrote:
>
> ------------------------------------------------------------------------
> *From:* Antony Stone
> On Saturday 09 December 2017 at 15:35:51, Edwin Quijada wrote:
>
>> > On Friday 08 December 2017 at 22:08:33, Edwin Quijada wrote:
>> >
>> > > I have 4 different groups in my company each group has access different
>> >
>> > Please explain what "access different" means.
>>
>> The first group has accees to 2 pages, second 3 differents pages and  3 and
>> 4 everything
>
> Okay, understood.
>

FYI: please be aware that HTTP has no concept of "page". That is a human
UI concept. Squid and HTTP deal only with messages about URLs. A "page"
as we know it can be many different transactions and URL messages.

We can get into that more later when you have auth working, just be
aware for now that there is no natural connection between auth
credentials and "page".

OK, I understood. My problem then is when Squid shows the authorization screen I put the credentials but doenst work ,
This is a simple helper but doesnt work, it continues ask me for user/pass


> This helper that I created
> <?php
>
> $f = fopen("php://stdin", "r");
> while (!(feof($f))) {
>      $line = fgets($f);
>      if ($line) {
>          $fields = explode(' ', trim($line));
>          $username = rawurldecode($fields[0]);
>          $password = rawurldecode($fields[1]);
> //
>          if ($username=="edwin" &&  $password=="1234")
>                fwrite(STDOUT, "OK\n");
>          else
>               fwrite(STDOUT, "ERR\n");
>      }
> }
> ?>
> This helper is just for testing , but when I tested it doent work
>

What are your squid.conf settings using that helper?

#acl manager proto cache_object
http_port 3128
cache_dir ufs /var/spool/squid3 2048 16 256
maximum_object_size 100 MB
cache_swap_low 90
cache_swap_high 95

#--------------- Reglas de Autorizacion -------------
auth_param basic program  /usr/bin/php /root/squid_helper2.php
auth_param basic children 20
auth_param basic realm Proxy Quijada Usuario Y Clave
auth_param basic credentialsttl 5 hours
#----------------------------------------------------
#------------- ACL de accesos para los usuarios------
#----------------------------------------------------
#
#
acl AuthenticatedUsers proxy_auth REQUIRED
http_access allow AuthenticatedUsers
#-------------------- ACL Puertos --------------------
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http

acl CONNECT method CONNECT

#---------------------- HTTP ACCES DEFAULT-------------
#http_access allow manager localhost
#http_access deny manager
#http_access deny !Safe_ports

#http_access deny to_localhost
#icp_access deny all
#htcp_access deny all

#---------------------- HTTP_ACCESS DE USUARIOS---------


#======================================================================

#Suggested default:
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
refresh_pattern .               0       20%     4320




FYI: PHP has known problems that prevent it being a successful helper
language most of the time
<https://wiki.squid-cache.org/Features/AddonHelpers#What_language_are_helper_meant_to_be_written_in.3F>
Features/AddonHelpers - Squid Web Proxy Wiki<https://wiki.squid-cache.org/Features/AddonHelpers#What_language_are_helper_meant_to_be_written_in.3F>
wiki.squid-cache.org
Perl, Python : Certain methods of writing output to stdout automatically append newline characters. Care must be taken that only one set of newlines are output with ...



Squid bundles with *_fake_auth helpers you can base your code on when
developing a custom helper. They handle the I/O with Squid properly for
their matching Squid version and should be easily extended for doing
actual auth checks.


>> > How does it identify one group from another?
>>
>> Uhm...the structere are differents , really there are in different tables
>> in my DB that is in the server
>
> So, you're doing an HTTP request to a web server, which then looks up
> the user
> in a database, and returns a result as an HTTP response...
>
> Surely it would be easier (and quicker / more efficient) to get Squid to
> interrogate the database?
>
>> > > the problem is how can i do this ACL
>
> I wouldn't start from there, so I hope someone else here can suggest a
> way of
> getting this to work.
>
>
> What made you start with this approach in the first place?
>
> Now, I changed the approach , I just want one group for everything and
> other, localnet restricted,instead of use 4 groups just 2 one for admin,
> other for
>

The weird thing is this use of a web server as an intermediary between
Squid and the actual user/group database. What made you use it in the
first place instead of connecting Squid to the database?

It just why the database is in another server and this DB doesnt have external access . IN this server just has an API responding request so I wanna use this for authorization. I cant connect directly to DB

[ I am one of the people who can help you get it to work, but it is only
with the trouble doing at all if there is a good reason. Auth is a
complex enough topic already just by itself. ]

Thks for your help, I will continue trying to authorize with Squid


Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
squid-users Info Page<http://lists.squid-cache.org/listinfo/squid-users>
lists.squid-cache.org
squid-users -- General discussion relating to Squid. The membership of this list is thousands of Squid users from around the world About squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171212/3094d4be/attachment.htm>

From jun357572957zhao at hotmail.com  Wed Dec 13 01:11:52 2017
From: jun357572957zhao at hotmail.com (=?gb2312?B?1dQgv6E=?=)
Date: Wed, 13 Dec 2017 01:11:52 +0000
Subject: [squid-users] =?utf-8?q?=28no_subject=29?=
Message-ID: <CY4PR22MB0360A9C5936782CB924191FB98350@CY4PR22MB0360.namprd22.prod.outlook.com>

Hi,

When I access SVN ,I want to bump SVN connection.


Error like this:


The following error was encountered while trying to retrieve the URL: https://WIN-BEOUENL2N6U/*<https://win-beouenl2n6u/*>

Failed to establish a secure connection to 192.168.52.6

The system returned:

(71) Protocol error (TLS code: X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)

SSL Certficate error: certificate issuer (CA) not known: /CN=WIN-BEOUENL2N6U

This proxy and the remote host failed to negotiate a mutually acceptable security settings for handling your request. It is possible that the remote host does not support secure connections, or the proxy is not satisfied with the host security credentials.


My squid.conf :

acl ssl_step1 at_step SslBump1
acl ssl_step2 at_step SslBump2
acl ssl_step3 at_step SslBump3

ssl_bump stare ssl_step1
ssl_bump bump ssl_step2
ssl_bump terminate ssl_step3


May  i  solve this problem,if I go to the official certification  organization certificating myCA ?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171213/c05a1ceb/attachment.htm>

From squid3 at treenet.co.nz  Wed Dec 13 02:53:55 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 13 Dec 2017 15:53:55 +1300
Subject: [squid-users] (no subject)
In-Reply-To: <CY4PR22MB0360A9C5936782CB924191FB98350@CY4PR22MB0360.namprd22.prod.outlook.com>
References: <CY4PR22MB0360A9C5936782CB924191FB98350@CY4PR22MB0360.namprd22.prod.outlook.com>
Message-ID: <d1f89445-d24f-5718-536b-580c9a53403f@treenet.co.nz>

On 13/12/17 14:11, ? ? wrote:
> Hi,
> 
> When?I access SVN ,I want to bump SVN connection.
> 
> 
> Error like this:
> 
> 
> The following error was encountered while trying to retrieve the URL: 
> https://WIN-BEOUENL2N6U/*
> 
>     *Failed to establish a secure connection to 192.168.52.6*
> 
> The system returned:
> 
>     (71) Protocol error (TLS code: X509_V_ERR_UNABLE_TO_GET_ISSUER_CERT_LOCALLY)
> 
>     SSL Certficate error: certificate issuer (CA) not known:
>     /CN=WIN-BEOUENL2N6U
> 
> This proxy and the remote host failed to negotiate a mutually acceptable 
> security settings for handling your request. It is possible that the 
> remote host does not support secure connections, or the proxy is not 
> satisfied with the host security credentials.
> 
> 
> My squid.conf :
> 
> acl ssl_step1 at_step SslBump1
> acl ssl_step2 at_step SslBump2
> acl ssl_step3 at_step SslBump3
> 
> ssl_bump stare ssl_step1
> ssl_bump bump ssl_step2
> ssl_bump terminate ssl_step3
> 
> May? i? solve this problem,if I go to the official certification  
> organization?certificating myCA??
> 

Not really. There are two problems;

The first problem is that you are using host names instead of domain name.
 
<https://superuser.com/questions/59093/difference-between-host-name-and-domain-name/59094>


The second problem is that you are bumping at SSL-Bump step #2 before 
any of the real server details are available to Squid.


Amos


From squid3 at treenet.co.nz  Wed Dec 13 02:55:42 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 13 Dec 2017 15:55:42 +1300
Subject: [squid-users] Groups and authorization SQUID
In-Reply-To: <BN6PR15MB1203A8F78C56178C3EB18992E3340@BN6PR15MB1203.namprd15.prod.outlook.com>
References: <BN6PR15MB1203D51EC21557CF8BC47441E3300@BN6PR15MB1203.namprd15.prod.outlook.com>
 <201712082350.51217.Antony.Stone@squid.open.source.it>
 <BN6PR15MB12039E5921388CCC0B44D46CE3310@BN6PR15MB1203.namprd15.prod.outlook.com>
 <201712091657.52150.Antony.Stone@squid.open.source.it>
 <BN6PR15MB12037091515BEB05BA12F701E3370@BN6PR15MB1203.namprd15.prod.outlook.com>
 <8eb9c36c-3880-1bda-78d3-9412d8eed02c@treenet.co.nz>
 <BN6PR15MB1203A8F78C56178C3EB18992E3340@BN6PR15MB1203.namprd15.prod.outlook.com>
Message-ID: <bdc90c5f-2efc-4ce8-4aa9-9a22da9143c8@treenet.co.nz>

Why are you just re-posting what I already posted, but with your name on 
it as author?

Amos


From zhongzhe at lvmama.com  Wed Dec 13 07:30:46 2017
From: zhongzhe at lvmama.com (zhongzhe at lvmama.com)
Date: Wed, 13 Dec 2017 15:30:46 +0800
Subject: [squid-users] TCP_MISS_ABORTED
Message-ID: <20171213152306992405165@lvmama.com>+A59FC13781366A76

Hi, All
    I used httpclient to imitate a request to squid , but the response page had not stored by squid although response header is 200. I had tried many times with three different pages . only one can be stored by the squid cache. and the others must need to send requset by brower then they were cached.  I had checked the access.log , it show me like this.
    1513148548.653   9172 10.112.4.54 TCP_MISS_ABORTED/200 106197 GET http://youlun.lvmama.com/ship_front/youlun/1012487 - FIRSTUP_PARENT/10.112.4.54 text/html

do you know what's wrong of my squid.conf ? need your help !
    below is my squid.conf
    
acl gsrc src 10.112.4.54 10.113.10.191
acl gdst dst 10.112.4.54 10.113.10.191
http_access allow gsrc
http_access allow gdst

acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines

acl purge method PURGE
acl clientServers src 10.112.4.54
http_access allow purge clientServers
http_access deny purge

acl gat method GET
acl clientS src 10.112.4.54 10.113.10.190
http_access allow gat clientS
#http_access deny gat

acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 3130        # icp
acl Safe_ports port 3128
acl CONNECT method CONNECT

http_access deny !Safe_ports

http_access deny CONNECT !SSL_ports

http_access allow localhost manager
http_access deny manager

http_access allow localnet
http_access allow localhost

http_port 80 accel defaultsite=youlun.lvmama.com no-vhost

cache_dir aufs /var/spool/squid 8198 16 256
cache_mem 5120 MB
cache_swap_low 90
cache_swap_high 95
cache_mgr zhongzhe at lvmama.com

visible_hostname cache190

#cache_peer 10.113.10.191 sibling 80 3130 allow-miss proxy-only name=cache.neighbor
#cache_peer_access cache.neighbor allow all

#acl fromPeer src 10.113.10.191
#cache_peer_access cache.neighbor deny fromPeer

coredump_dir  /var/spool/squid

via off
maximum_object_size 500 KB

icp_port 3130
icp_access allow all
icp_query_timeout 2000

cache_peer 10.112.4.54 parent 8090 0 no-query originserver name=youlun
acl mysites dstdomain youlun.lvmama.com
http_access allow mysites
cache_peer_access youlun allow all
cache_peer_access youlun deny all

refresh_pattern -i .*/youlun/([0-9]+) 1440 100% 10080 ignore-no-store ignore-must-revalidate store-stale ignore-reload

refresh_pattern ^ftp:          1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320

cache_log /var/log/squid/cache.log
cache_access_log /var/log/squid/access.log
cache_store_log /var/log/squid/store.log

log_icp_queries off

http_access allow all
http_access deny all



zhongzhe at lvmama.com 

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171213/35510485/attachment.htm>

From jun357572957zhao at hotmail.com  Wed Dec 13 08:19:00 2017
From: jun357572957zhao at hotmail.com (=?gb2312?B?1dQgv6E=?=)
Date: Wed, 13 Dec 2017 08:19:00 +0000
Subject: [squid-users] =?utf-8?q?=28no_subject=29?=
Message-ID: <CY4PR22MB03608A18ECDBF0A5E5DADB6198350@CY4PR22MB0360.namprd22.prod.outlook.com>

 >> When I access SVN ,I want to bump SVN connection.

>> My squid.conf :
>>
>> acl ssl_step1 at_step SslBump1
>>acl ssl_step2 at_step SslBump2
>> acl ssl_step3 at_step SslBump3
>>
>> ssl_bump stare ssl_step1
>> ssl_bump bump ssl_step2
>>ssl_bump terminate ssl_step3
>>
>> May  i  solve this problem,if I go to the official certification
>> organization certificating myCA ?





>The second problem is that you are bumping at SSL-Bump step #2 before
> any of the real server details are available to Squid.

I want to know which step to bump and which action at SSL-Bump step#1?





-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171213/6a4eccba/attachment.htm>

From ahmed.zaeem at netstream.ps  Wed Dec 13 10:13:00 2017
From: ahmed.zaeem at netstream.ps (--Ahmad--)
Date: Wed, 13 Dec 2017 12:13:00 +0200
Subject: [squid-users] question in :src/cf.data.pre "
In-Reply-To: <5328d938-1438-60dc-03df-92711f1388ae@treenet.co.nz>
References: <A88F7289-A293-435C-9CAE-1F127A71CE78@netstream.ps>
 <0427fb71-a6ab-69b7-bbbc-b1f965618315@treenet.co.nz>
 <B0BF73AC-7EC8-476A-9949-4494A259B0B0@netstream.ps>
 <48D506BE-EA40-4E56-86C0-30305E36ADFE@netstream.ps>
 <5328d938-1438-60dc-03df-92711f1388ae@treenet.co.nz>
Message-ID: <4DF4FE07-93EC-447B-885E-954DBFFDD99A@netstream.ps>

ok great point amos .
is there a way to change the default config squid file for squid ?

i mean i want to change the default location  from /etc/squid/squid.conf to something else 
?

can i change that from code cc before compile ?


cheers 


> On Dec 12, 2017, at 6:42 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
> On 13/12/17 04:12, --Ahmad-- wrote:
>> @amos about your question .
>> i think ?include option ? is ok , but i also need it to be hidden and not added to squid.conf
>> say like :
>> include /var/test.cc
>> would like this is loaded automatically and don?t need to add it in squid.conf ???
>> i mean each time i run squid it will load like include other file .
>> i tried to add into pre file below config :
>> NAME: include
>> TYPE: string
>> LOC: Config.include
>> DEFAULT: /var/test.cc <http://test.cc>
>> DOC_START
>>     Hello
>> DOC_END
> 
> Not like this. "include" is a hard-coded behaviour, not a normal directive. It needs to be used like the Debian patch does, with "squid.conf" file being the pre-determined settings and users in control of the other stuff pulled in by 'include' from somewhere else.
> 
> 
> OR, you just use the -f command line option to point at your custom config file when you run Squid "from terminal".
> 
> 
> I wasn't going to bother asking for a fourth time, but since Anthony did "who are you trying to hide this from?" is still unanswered. Anyone who might see these settings in the config file can also find them by other means (ie looking at the machines open ports). So the lengths you are going to hide them is very weird.
> 
> 
> Amos



From mkraju123 at gmail.com  Wed Dec 13 12:13:10 2017
From: mkraju123 at gmail.com (Raju M K)
Date: Wed, 13 Dec 2017 17:43:10 +0530
Subject: [squid-users] Warning in Cache.log
Message-ID: <CAGycgFhzUQ7Tu7j26WvtRP+cC7TovdKraWhsMcuVzK6AT6PgMA@mail.gmail.com>

Dear Team,
I installed squid 3.5.25 on Ubuntu and in windows 10 with Diladele MSI.
In both cache.log files, I am getting below warning.
Few users got the same error but no solution for this.

2017/12/13 10:38:04 kid1| helperOpenServers: Starting 1/32 'ssl_crtd'
processes
*2017/12/13 10:38:04 kid1| WARNING: no_suid: setuid(0): (22) Invalid
argument *

Above warning getting while starting helpers only.
I Installed the same squid ver 3..5.25 on  CentOS 7 but no Warnings with
the same config.
But we need some solution for OS also like Ubuntu and widows.
-- 
Regards,
M K Raju.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171213/d5986649/attachment.htm>

From yvoinov at gmail.com  Wed Dec 13 12:14:57 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 13 Dec 2017 18:14:57 +0600
Subject: [squid-users] Warning in Cache.log
In-Reply-To: <CAGycgFhzUQ7Tu7j26WvtRP+cC7TovdKraWhsMcuVzK6AT6PgMA@mail.gmail.com>
References: <CAGycgFhzUQ7Tu7j26WvtRP+cC7TovdKraWhsMcuVzK6AT6PgMA@mail.gmail.com>
Message-ID: <e48e6d54-2c3d-8f68-eabf-6a17e5014975@gmail.com>

This warning does not prevent it from working normally. Has not broken -
do not fix.


13.12.2017 18:13, Raju M K ?????:
> Dear Team,
> I installed squid 3.5.25 on Ubuntu and in windows 10 with Diladele MSI.
> In both cache.log files, I am getting below warning.
> Few users got the same error but no solution for this.
>
> 2017/12/13 10:38:04 kid1| helperOpenServers: Starting 1/32 'ssl_crtd'
> processes
> *2017/12/13 10:38:04 kid1| WARNING: no_suid: setuid(0): (22) Invalid
> argument?*
>
> Above warning getting while starting helpers only.
> I Installed the same squid ver 3..5.25 on? CentOS 7 but no Warnings
> with the same config.
> But we need some solution for OS also like Ubuntu and widows.
> -- 
> Regards,
> M K Raju.
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
"Some people, when confronted with a problem, think ?I know, I'll use regular expressions.? Now they have two problems."
--Jamie Zawinsk

**************************
* C++: Bug to the future *
**************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171213/e909ebac/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 512 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171213/e909ebac/attachment.sig>

From uhlar at fantomas.sk  Wed Dec 13 13:14:45 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 13 Dec 2017 14:14:45 +0100
Subject: [squid-users] question in :src/cf.data.pre "
In-Reply-To: <4DF4FE07-93EC-447B-885E-954DBFFDD99A@netstream.ps>
References: <A88F7289-A293-435C-9CAE-1F127A71CE78@netstream.ps>
 <0427fb71-a6ab-69b7-bbbc-b1f965618315@treenet.co.nz>
 <B0BF73AC-7EC8-476A-9949-4494A259B0B0@netstream.ps>
 <48D506BE-EA40-4E56-86C0-30305E36ADFE@netstream.ps>
 <5328d938-1438-60dc-03df-92711f1388ae@treenet.co.nz>
 <4DF4FE07-93EC-447B-885E-954DBFFDD99A@netstream.ps>
Message-ID: <20171213131445.GB22873@fantomas.sk>

On 13.12.17 12:13, --Ahmad-- wrote:
>ok great point amos .
>is there a way to change the default config squid file for squid ?
>
>i mean i want to change the default location  from /etc/squid/squid.conf to something else
>?
>
>can i change that from code cc before compile ?

https://wiki.squid-cache.org/SquidFaq/CompilingSquid

you can define --sysconfdir at compile time.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Emacs is a complicated operating system without good text editor.


From erdosain9 at gmail.com  Wed Dec 13 13:46:34 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 13 Dec 2017 06:46:34 -0700 (MST)
Subject: [squid-users] Some things in the log
Message-ID: <1513172794872-0.post@n4.nabble.com>

Hi to all.
Im having some things in the log.
Like this:

-Vary object loop
-Could not parse headers from on disk object
-varyEvaluateMatch: Oops

ipcacheParse No Address records in response to (i supposed this is not a
problem)

And a lot more as you can see.

2017/12/12 16:09:50 kid1| ipcacheParse No Address records in response to
'notifications-4.mercadolibre.com'
2017/12/12 16:09:50 kid1| ipcacheParse No Address records in response to
'notifications-4.mercadolibre.com'
2017/12/12 16:09:54 kid1| Error negotiating SSL on FD 701:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/12/12 16:11:00 kid1| Error negotiating SSL on FD 246:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/12/12 16:11:10 kid1| Error negotiating SSL on FD 246:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/12/12 16:11:35 kid1| Error negotiating SSL on FD 404:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/12/12 16:11:45 kid1| Error negotiating SSL on FD 369:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/12/12 16:11:49 kid1| Error negotiating SSL on FD 194:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/12/12 16:12:33 kid1| ipcacheParse No Address records in response to
'notifications-6.mercadolibre.com'
2017/12/12 16:12:33 kid1| ipcacheParse No Address records in response to
'notifications-6.mercadolibre.com'
2017/12/12 16:12:42 kid1| Could not parse headers from on disk object
*2017/12/12 16:12:42 kid1| varyEvaluateMatch: Oops. Not a Vary object on
second attempt,
'https://www.airbnb.es/?eluid=5&euid=136f93f9-c827-7b74-55a7-af773e8b4a16'
'accept-encoding="gzip,%20deflate,%20br"'
2017/12/12 16:12:42 kid1| clientProcessHit: Vary object loop!*
2017/12/12 16:15:24 kid1| Error negotiating SSL on FD 232:
error:00000000:lib(0):func(0):reason(0) (5/-1/104)
2017/12/12 16:18:21 kid1| Error negotiating SSL on FD 603:
error:00000000:lib(0):func(0):reason(0) (5/-1/104)
2017/12/12 16:19:45 kid1| urlParse: URL too large (9283 bytes)
2017/12/12 16:20:23 kid1| urlParse: URL too large (9328 bytes)
2017/12/12 16:20:24 kid1| urlParse: URL too large (9286 bytes)
2017/12/12 16:26:04 kid1| ipcacheParse No Address records in response to
'notifications-6.mercadolibre.com'
2017/12/12 16:26:04 kid1| ipcacheParse No Address records in response to
'notifications-6.mercadolibre.com'
2017/12/12 16:28:13 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/12 16:28:13 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/12 16:28:13 kid1| NETDB state saved; 0 entries, 3 msec
2017/12/12 16:32:08 kid1| Error negotiating SSL on FD 247:
error:00000000:lib(0):func(0):reason(0) (5/-1/104)
2017/12/12 16:34:52 kid1| urlParse: URL too large (8304 bytes)
2017/12/12 16:37:47 kid1| Error negotiating SSL on FD 559:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/12/12 16:37:47 kid1| Error negotiating SSL on FD 558:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
*2017/12/12 16:41:46 kid1| ipcacheParse No Address records in response to
'notifications-14.mercadolibre.com'
2017/12/12 16:41:46 kid1| ipcacheParse No Address records in response to
'notifications-14.mercadolibre.com'
2017/12/12 16:43:00 kid1| ipcacheParse No Address records in response to
'notifications-6.mercadolibre.com'*
2017/12/12 16:43:00 kid1| ipcacheParse No Address records in response to
'notifications-6.mercadolibre.com'
2017/12/12 16:43:00 kid1| ipcacheParse No Address records in response to
'notifications-6.mercadolibre.com'
2017/12/12 16:43:00 kid1| ipcacheParse No Address records in response to
'notifications-6.mercadolibre.com'
2017/12/12 16:43:00 kid1| ipcacheParse No Address records in response to
'notifications-6.mercadolibre.com'
2017/12/12 16:43:00 kid1| ipcacheParse No Address records in response to
'notifications-6.mercadolibre.com'
2017/12/12 16:43:07 kid1| ipcacheParse No Address records in response to
'notifications-5.mercadolibre.com'
2017/12/12 16:43:07 kid1| ipcacheParse No Address records in response to
'notifications-5.mercadolibre.com'
2017/12/12 16:43:45 kid1| ipcacheParse No Address records in response to
'notifications-11.mercadolibre.com'
2017/12/12 16:43:45 kid1| ipcacheParse No Address records in response to
'notifications-11.mercadolibre.com'
2017/12/12 16:43:58 kid1| ipcacheParse No Address records in response to
'notifications-14.mercadolibre.com'
2017/12/12 16:43:58 kid1| ipcacheParse No Address records in response to
'notifications-14.mercadolibre.com'
2017/12/12 16:45:58 kid1| ipcacheParse No Address records in response to
'notifications-11.mercadolibre.com'
2017/12/12 16:45:58 kid1| ipcacheParse No Address records in response to
'notifications-11.mercadolibre.com'
2017/12/12 16:46:10 kid1| ipcacheParse No Address records in response to
'notifications-10.mercadolibre.com'
2017/12/12 16:46:10 kid1| ipcacheParse No Address records in response to
'notifications-10.mercadolibre.com'
2017/12/12 16:46:25 kid1| ipcacheParse No Address records in response to
'notifications-2.mercadolibre.com'
2017/12/12 16:46:25 kid1| ipcacheParse No Address records in response to
'notifications-2.mercadolibre.com'
2017/12/12 16:46:42 kid1| ipcacheParse No Address records in response to
'notifications-1.mercadolibre.com'
2017/12/12 16:46:42 kid1| ipcacheParse No Address records in response to
'notifications-1.mercadolibre.com'
2017/12/12 16:47:00 kid1| ipcacheParse No Address records in response to
'notifications-4.mercadolibre.com'
2017/12/12 16:47:00 kid1| ipcacheParse No Address records in response to
'notifications-4.mercadolibre.com'
2017/12/12 16:47:17 kid1| ipcacheParse No Address records in response to
'notifications-11.mercadolibre.com'
2017/12/12 16:47:17 kid1| ipcacheParse No Address records in response to
'notifications-11.mercadolibre.com'
2017/12/12 16:48:29 kid1| ipcacheParse No Address records in response to
'notifications-14.mercadolibre.com'
2017/12/12 16:48:29 kid1| ipcacheParse No Address records in response to
'notifications-14.mercadolibre.com'
2017/12/12 16:59:15 kid1| Error negotiating SSL on FD 382:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/12/12 17:00:17 kid1| ipcacheParse No Address records in response to
'fbstatic-a.akamaihd.net'
2017/12/12 17:00:17 kid1| ipcacheParse No Address records in response to
'fbstatic-a.akamaihd.net'
2017/12/12 17:04:00 kid1| WARNING: All 35/35 negotiateauthenticator
processes are busy.
2017/12/12 17:04:00 kid1| WARNING: 35 pending requests queued
2017/12/12 17:04:00 kid1| WARNING: Consider increasing the number of
negotiateauthenticator processes in your config file.
2017/12/12 17:06:00 kid1| ipcacheParse No Address records in response to
'fbstatic-a.akamaihd.net'
2017/12/12 17:06:00 kid1| ipcacheParse No Address records in response to
'fbstatic-a.akamaihd.net'
2017/12/12 17:12:37 kid1| urlParse: URL too large (17816 bytes)
2017/12/12 17:15:59 kid1| WARNING: All 35/35 negotiateauthenticator
processes are busy.
2017/12/12 17:15:59 kid1| WARNING: 35 pending requests queued
2017/12/12 17:15:59 kid1| WARNING: Consider increasing the number of
negotiateauthenticator processes in your config file.
2017/12/12 17:16:36 kid1| urlParse: URL too large (18940 bytes)
2017/12/12 17:17:58 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://mail.yahoo.com/d/gemini_api/?adCount=1&sectionId=5421583&publisherInfo=%7C%7C159601009%7CSTRM%7C&creativeCode=STRM%2CSTRM_VIDEO&contentType=video%2Fmp4%2Capplication%2Fvnd.apple.mpegurl&ymreqid=e6042b69-4eb0-a3ab-1c13-28000b015b00&appId=YMailNorrin&crumb=ZOrYbHUg1Wq
AKA
mail.yahoo.com/d/gemini_api/?adCount=1&sectionId=5421583&publisherInfo=%7C%7C159601009%7CSTRM%7C&creativeCode=STRM%2CSTRM_VIDEO&contentType=video%2Fmp4%2Capplication%2Fvnd.apple.mpegurl&ymreqid=e6042b69-4eb0-a3ab-1c13-28000b015b00&appId=YMailNorrin&crumb=ZOrYbHUg1Wq
2017/12/12 17:27:42 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/12 17:27:42 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/12 17:27:42 kid1| NETDB state saved; 0 entries, 0 msec
2017/12/12 17:29:02 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://r2---sn-ja5gv5g-x1xl.googlevideo.com/videoplayback?mt=1513107272&mv=m&ms=au&dur=4190.701&mm=31&source=youtube&clen=74978190&mn=sn-ja5gv5g-x1xl&lmt=1449650990431377&ipbits=0&mime=audio%2Fwebm&itag=251&key=yt6&keepalive=yes&pl=20&requiressl=yes&expire=1513128991&gir=yes&initcwndbps=206250&id=o-AP5MeSNMCkmpBTN4s_Si7cz9XLisZHWU2D009pN61N_i&sparams=clen%2Cdur%2Cei%2Cgir%2Cid%2Cinitcwndbps%2Cip%2Cipbits%2Citag%2Ckeepalive%2Clmt%2Cmime%2Cmm%2Cmn%2Cms%2Cmv%2Cpl%2Crequiressl%2Csource%2Cexpire&ei=vi8wWvykM4jGwwSf4KfwCw&ip=190.3.119.197&alr=yes&signature=DCBB0572710D94F14DCE602C36E600C3F57E5136.496DC7AF86BF32EDEF1706D94C71E017C8A0C5DC&cpn=ZQ53cy53_BICpUtH&c=WEB&cver=1.20171211&range=62361226-62901545&rn=177&rbuf=512198
AKA
r2---sn-ja5gv5g-x1xl.googlevideo.com/videoplayback?mt=1513107272&mv=m&ms=au&dur=4190.701&mm=31&source=youtube&clen=74978190&mn=sn-ja5gv5g-x1xl&lmt=1449650990431377&ipbits=0&mime=audio%2Fwebm&itag=251&key=yt6&keepalive=yes&pl=20&requiressl=yes&expire=1513128991&gir=yes&initcwndbps=206250&id=o-AP5MeSNMCkmpBTN4s_Si7cz9XLisZHWU2D009pN61N_i&sparams=clen%2Cdur%2Cei%2Cgir%2Cid%2Cinitcwndbps%2Cip%2Cipbits%2Citag%2Ckeepalive%2Clmt%2Cmime%2Cmm%2Cmn%2Cms%2Cmv%2Cpl%2Crequiressl%2Csource%2Cexpire&ei=vi8wWvykM4jGwwSf4KfwCw&ip=190.3.119.197&alr=yes&signature=DCBB0572710D94F14DCE602C36E600C3F57E5136.496DC7AF86BF32EDEF1706D94C71E017C8A0C5DC&cpn=ZQ53cy53_BICpUtH&c=WEB&cver=1.20171211&range=62361226-62901545&rn=177&rbuf=512198
2017/12/12 17:31:42 kid1| Could not parse headers from on disk object
2017/12/12 17:31:42 kid1| varyEvaluateMatch: Oops. Not a Vary object on
second attempt,
'https://drive.google.com/_/drive_fe/_/js/k=drive_fe.main.es.Umc-Z5UHqzQ.O/m=core,registry_module,change,dataservice_debug,account,sy2s,act,sy2u,sy2v,sy2w,sy2t,sy2z,activity,sy31,sy30,sy37,sy3f,sy34,sy35,sy36,sy39,sy38,sy3a,sy3b,sy3c,sy3d,sy3e,sy3g,sy3h,sy33,sy3i,sy3j,sy3k,sy32,sy3l,approvals,sy3v,sy3m,sy3o,sy3p,sy3q,sy3r,sy3s,sy3t,sy3u,sy3n,sy3w,sy3x,sy3y,sy3z,sy45,sy44,sy46,sy49,sy4a,sy41,sy47,sy4b,sy48,sy4c,sy4d,sy43,sy4f,sy4e,sy40,sy42,sy4g,sy4h,apps,sy4i,sy4j,sy4l,sy4k,sy4m,cap,customization,sy4n,contacts,sy4o,sy4p,sy4q,sy4r,debug,sy4t,sy4u,sy4v,sy4x,sy1,sy3,sy4z,sy4y,sy4w,sy4s,details,sy50,sy51,sy52,sy53,sy54,sy55,backups,sy8h,emj,sy6l,sy6k,sy5y,sy8g,sy68,sy6g,sy6j,sy6h,sy6i,sy6f,sy6e,sy6b,eme,sy8y,sy8z,sy90,emf,sy6t,sy8k,emi,sy6u,sy6v,sy8e,sy8f,emm,sy6w,sy9v,emn,sy6z,emk,sy71,sy5t,sy8i,eml,sy6m,sy63,sy69,sy6a,sy66,sy5s,sy5f,sy76,sy5d,sy5c,sy5l,sy7a,sy5q,sy74,sy75,sy77,sy5v,sy5w,sy72,sy5x,sy5z,sy6q,sy6x,sy6y,sy73,sy6r,sy6s,sy60,sy61,sy8c,emo,sy8m,emd,syc,sy65,sy67,sy58,sy5e,sy5g,sy5h,sy5i,sy5j,sy5k,sy5m,sy5n,sy5o,sy5r,sy5p,sy7e,sy78,sy7g,sy7f,sy79,sy7b,sy7c,sy6n,sy5u,sy62,sy6c,sy6d,sy64,sy6o,sy6p,sy7o,sy7s,sy7i,sy7r,sy7h,sy7j,sy7k,sy8p,sy8o,sy8r,sy8n,sy8x,sy8v,sy8u,sy8q,sy7l,sy7n,sy7m,sy7p,sy7q,sy7t,sy7w,sy7v,sy7x,sy7y,sy7u,sy7z,sy91,sy92,sy9,sya,syb,sy2,sy6,sy93,sy94,sy9c,sy95,sy96,sy97,sy98,sy99,sy9a,sy9b,sy9d,sy9e,sy9f,sy9g,sy9h,sy9i,sy9j,sy9k,sy9l,sy9m,sy9n,sy9o,sy9p,sy9q,sy9r,sy9s,sy9u,sy9t,sy80,sy83,sy81,sy82,sy87,sy86,sy88,sy89,sy8a,sy85,sy84,sy8b,sy8d,sy8l,sy9x,sy9w,dl,sya1,sy9y,sya0,sy9z,sya2,org,sya3,sya4,docs,sya5,sya7,sya6,download,sya8,help,ibml,isb,net,ol,syaa,pp,prefs,syab,syac,syad,afp,syaf,syae,fup,udp,ww,syag,qa,syah,rv,syai,srch,settings,share,density,upload,syaj,urip,opmd,qfNSff,UgAtXe,xiqEse,DsWmu,Y9atKf,nlY2Lb,q0xTif,syal,syam,syan,syak,sVMbm,hc6Ubd,syao,FEWD7,RMhBfe,PrPYRd,QIhFr,syap,HXvZFd,NTMZac,IZT63,syaq,syat,syar,syas,pxq3x,IC9Ief,syau,tfTN8c,syav,zemu5,syaw,syb1,syay,syb2,syb3,syax,fgj8Rb,TmoW9b,syb4,HDvRde,syb5,iN16H,syb6,VwDzFe,syb7,iTsyac,UpgCub,hk1Xbf,HLo3Ef,syb9,syba,sybb,syb8,A4UTCb,sybc,VXdfxd,M9OQnf,aKx2Ve,sybd,wI7Sfc,sybe,L1AAkb,ws9Tlc,O6y8ed,sybf,VBe3Tb,aW3pY,wGM7Jc,V3dDOb,v2P8cc,Fbbake,yDXup,pA3VNb,JNoxi,ZwDk9d,w9hDv,HT8XDe,sybg,SM1lmd,Uas9Hd,sybh,pB6Zqd,sybi,e5qFLc,sybj,o02Jie,SpsfSb,zbML3c,sybk,CBlRxf,PVlQOd,sybl,doKs4c,XVMNvd,rODCz,sybm,N5Lqpc,nRT6Ke,gZjhIf,sybn,sybo,egt3Hc,sybp,YOOtDc,w56Zfd,sybq,Yfm1Qb,SuiCqd,uLja6e,kuYo4c,sybr,yu6wmd,sybs,a5Lkrc,JHWICe,sybt,sybw,sybv,sybu,sybx,aHhRQd,nJSzbf,PUPpX,OFDlTc,syby,hkuzDf,XwoRHc,am2kad,oRC5wf,k5wRCb,g6DRlb,Pe1Sfd,LpwLf,YG7xj,k42Ixd,gek6de,xmu6Id,gZ86qd,Yiemid,HCYJHb,PuJtwe,fPxN5b,OaYr0b,NcjlGe,jGoVDf,sybz,RoZ0ud,syc0,wz3Hjc,syc1,YaE3Oc,poRgdb,syc2,syc3,sye,syc4,syc6,emp,emq,syc5,AuBwMe,sf1xDf,Qt2zkd,eITZXb,xCvw0e,Y0n5Q,syc7,psEsxb,syc8,M1zqPe,syc9,lTRIwe,syd,h74rbe,hJDwEc,zNm7zc,sycb,sycc,sycf,sycg,sych,syci,sycj,syck,sycl,syca,U3dEG,gewHbe,aNz4G,sycm,sycn,I4eEwe,syco,cY8dYd,sycp,P3hcNc,sycq,zQdOjc,UZy8zb,pxtbwb,jH2Pd,qk0th,tugWWe,q8ZSqd,sycr,sFFm5c,sycs,J37NDc,syct,STaVd,ygbDTc,iswTEc,EbpBi,sy5,sy4,V2Llp,l5vY7c,dwl57c,sycu,K9dnjc,JaleGe,Q2sP6e,sycv,hBr2ed,sycw,sycx,kLOGwc,sycy,fG2bFb,EbxVWc,XhrMg,lMeEtd,LDnxHc,UsnrGd,sycz,zhBrQd,syd1,syd0,MvreT,syd2,C6c9D,LIvsUc,syd3,Hdx5lb,syd4,fjl26e,XTVNze,XIbjEe,HO2Hh,Q542Vd,syd5,h4bcVd,L1i58c,xJp5jb,afJfGb,MGhLO,JXf0Q,syd6,AXVOyf,syd7,b6IFNd,KWtqWd,D4Qmod,syd8,ZbqRid,HaBcGf,syd9,q2lkmb,syda,tWZR8e,sydb,LXplPb,sydc,sydd,KwlET,g8hfOb,sy8,FhAIjb,PiMr9,QRPc0d,syde,BIvdIe,DuXzPb,sydf,sydg,V3i5Gb,MRBrWc,eRjZne,UX428,jSTmtd,sydh,kdMCwd,ll7Tte,ZCGDLb,um4q1c,ggqG0d/am=bVahaDAUnOI/rt=j/d=1/rs=AFB8gsxnHZvMXDuiS92sbZwPgjlacyx9_Q'
'accept-encoding="gzip,%20deflate,%20br"'
2017/12/12 17:31:42 kid1|* clientProcessHit: Vary object loop!*
2017/12/12 17:45:33 kid1| urlParse: URL too large (18859 bytes)
2017/12/12 17:45:58 kid1| urlParse: URL too large (18561 bytes)
2017/12/12 17:53:23 kid1| urlParse: URL too large (18963 bytes)
2017/12/12 18:00:22 kid1| urlParse: URL too large (18821 bytes)
2017/12/12 18:02:16 kid1| urlParse: URL too large (18833 bytes)
2017/12/12 18:18:08 kid1| urlParse: URL too large (17879 bytes)
2017/12/12 18:25:53 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/12 18:25:53 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/12 18:25:53 kid1| NETDB state saved; 0 entries, 20 msec
2017/12/12 18:34:14 kid1| Error negotiating SSL on FD 303:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/12/12 18:52:04 kid1| Error negotiating SSL connection on FD 80: (104)
Connection reset by peer
2017/12/12 18:52:04 kid1| Error negotiating SSL connection on FD 85: (104)
Connection reset by peer
2017/12/12 19:39:08 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/12 19:39:08 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/12 19:39:08 kid1| NETDB state saved; 0 entries, 3 msec
2017/12/12 20:33:02 kid1| Error negotiating SSL on FD 95:
error:00000000:lib(0):func(0):reason(0) (5/-1/104)
2017/12/12 20:36:07 kid1| Error negotiating SSL on FD 202:
error:00000000:lib(0):func(0):reason(0) (5/-1/104)
2017/12/12 20:41:51 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/12 20:41:51 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/12 20:41:51 kid1| NETDB state saved; 0 entries, 2 msec
2017/12/12 21:07:02 kid1| Error negotiating SSL on FD 123:
error:00000000:lib(0):func(0):reason(0) (5/-1/104)
2017/12/12 21:16:30 kid1| WARNING: HTTP: Invalid Response: No object data
received for https://www.nireleku.com/favicon.ico AKA
www.nireleku.com/favicon.ico
2017/12/12 21:19:10 kid1| SSL unknown certificate error -3 in
/C=US/ST=California/L=San Francisco/O=Twitter, Inc./OU=tsa_d Point of
Presence/CN=syndication.twitter.com
2017/12/12 21:19:10 kid1| Error negotiating SSL on FD 72: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/12/12 21:23:53 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/12 21:23:53 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/12 21:23:53 kid1| NETDB state saved; 0 entries, 0 msec
2017/12/12 22:04:38 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/12 22:04:38 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/12 22:04:38 kid1| NETDB state saved; 0 entries, 6 msec
2017/12/12 22:54:44 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/12 22:54:44 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/12 22:54:44 kid1| NETDB state saved; 0 entries, 0 msec
2017/12/12 23:17:10 kid1| SSL unknown certificate error -3 in
/C=US/ST=California/L=San Francisco/O=Twitter, Inc./OU=tsa_c Point of
Presence/CN=syndication.twitter.com
2017/12/12 23:17:10 kid1| Error negotiating SSL on FD 74: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/12/12 23:19:10 kid1| SSL unknown certificate error -3 in
/C=US/ST=California/L=San Francisco/O=Twitter, Inc./OU=tsa_d Point of
Presence/CN=syndication.twitter.com
2017/12/12 23:19:10 kid1| Error negotiating SSL on FD 79: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/12/13 00:09:46 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/13 00:09:46 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/13 00:09:46 kid1| NETDB state saved; 0 entries, 4 msec
2017/12/13 01:26:35 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/13 01:26:35 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/13 01:26:35 kid1| NETDB state saved; 0 entries, 0 msec
2017/12/13 02:14:07 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/13 02:14:07 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/13 02:14:07 kid1| NETDB state saved; 0 entries, 0 msec
2017/12/13 02:16:09 kid1| SSL unknown certificate error -3 in
/C=US/ST=California/L=San Francisco/O=Twitter, Inc./OU=tsa_c Point of
Presence/CN=syndication.twitter.com
2017/12/13 02:16:09 kid1| Error negotiating SSL on FD 75: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/12/13 02:18:10 kid1| SSL unknown certificate error -3 in
/C=US/ST=California/L=San Francisco/O=Twitter, Inc./OU=tsa_d Point of
Presence/CN=syndication.twitter.com
2017/12/13 02:18:10 kid1| Error negotiating SSL on FD 76: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/12/13 03:29:34 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/13 03:29:34 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/13 03:29:34 kid1| NETDB state saved; 0 entries, 0 msec
2017/12/13 04:12:39 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/13 04:12:39 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/13 04:12:39 kid1| NETDB state saved; 0 entries, 0 msec
2017/12/13 04:16:09 kid1| SSL unknown certificate error -3 in
/C=US/ST=California/L=San Francisco/O=Twitter, Inc./OU=tsa_c Point of
Presence/CN=syndication.twitter.com
2017/12/13 04:16:09 kid1| Error negotiating SSL on FD 44: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/12/13 04:18:09 kid1| SSL unknown certificate error -3 in
/C=US/ST=California/L=San Francisco/O=Twitter, Inc./OU=tsa_d Point of
Presence/CN=syndication.twitter.com
2017/12/13 04:18:09 kid1| Error negotiating SSL on FD 79: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/12/13 05:32:02 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/13 05:32:02 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/13 05:32:02 kid1| NETDB state saved; 0 entries, 0 msec
2017/12/13 06:16:09 kid1| SSL unknown certificate error -3 in
/C=US/ST=California/L=San Francisco/O=Twitter, Inc./OU=tsa_c Point of
Presence/CN=syndication.twitter.com
2017/12/13 06:16:09 kid1| Error negotiating SSL on FD 12: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/12/13 06:18:09 kid1| SSL unknown certificate error -3 in
/C=US/ST=California/L=San Francisco/O=Twitter, Inc./OU=tsa_d Point of
Presence/CN=syndication.twitter.com
2017/12/13 06:18:09 kid1| Error negotiating SSL on FD 99: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/12/13 06:47:48 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/13 06:47:48 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/13 06:47:48 kid1| NETDB state saved; 0 entries, 0 msec
2017/12/13 07:37:56 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/13 07:37:56 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/13 07:37:56 kid1| NETDB state saved; 0 entries, 0 msec
2017/12/13 08:33:04 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/13 08:33:04 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/13 08:33:04 kid1| NETDB state saved; 0 entries, 4 msec
2017/12/13 09:01:20 kid1| Error negotiating SSL on FD 188:
error:00000000:lib(0):func(0):reason(0) (5/-1/104)
2017/12/13 09:03:27 kid1| Error negotiating SSL on FD 86:
error:00000000:lib(0):func(0):reason(0) (5/-1/104)
2017/12/13 09:05:34 kid1| Error negotiating SSL on FD 260:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/12/13 09:05:35 kid1| Error negotiating SSL on FD 261:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/12/13 09:15:09 kid1| SSL unknown certificate error -3 in
/C=US/ST=California/L=San Francisco/O=Twitter, Inc./OU=tsa_c Point of
Presence/CN=syndication.twitter.com
2017/12/13 09:15:09 kid1| Error negotiating SSL on FD 141:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/12/13 09:18:09 kid1| SSL unknown certificate error -3 in
/C=US/ST=California/L=San Francisco/O=Twitter, Inc./OU=tsa_d Point of
Presence/CN=syndication.twitter.com
2017/12/13 09:18:09 kid1| Error negotiating SSL on FD 94: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/12/13 09:25:37 kid1| Error negotiating SSL connection on FD 201: (104)
Connection reset by peer
2017/12/13 09:25:37 kid1| Error negotiating SSL connection on FD 291: (104)
Connection reset by peer
2017/12/13 09:25:37 kid1| Error negotiating SSL connection on FD 150: (104)
Connection reset by peer
2017/12/13 09:25:38 kid1| Error negotiating SSL connection on FD 201: (104)
Connection reset by peer
2017/12/13 09:25:38 kid1| Error negotiating SSL connection on FD 113: (104)
Connection reset by peer
2017/12/13 09:25:39 kid1| Error negotiating SSL connection on FD 216: (104)
Connection reset by peer
2017/12/13 09:25:39 kid1| Error negotiating SSL connection on FD 106: (104)
Connection reset by peer
2017/12/13 09:25:39 kid1| Error negotiating SSL connection on FD 231: (104)
Connection reset by peer
2017/12/13 09:39:54 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br10.zopim.com/s/W/xdds/4zb5GwOVozDpxD41/p/1513168729521 AKA
br10.zopim.com/s/W/xdds/4zb5GwOVozDpxD41/p/1513168729521
2017/12/13 09:40:18 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/13 09:40:18 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/13 09:40:18 kid1| NETDB state saved; 0 entries, 0 msec
2017/12/13 09:49:39 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://mundotkmglobal-grupovida.netdna-ssl.com/2017/03/positiva1-1-505x283.jpg
AKA mundotkmglobal-grupovida.netdna-ssl.com/2017/03/positiva1-1-505x283.jpg
2017/12/13 09:51:58 kid1| ipcacheParse No Address records in response to
'notifications-6.mercadolibre.com'
2017/12/13 09:51:58 kid1| ipcacheParse No Address records in response to
'notifications-6.mercadolibre.com'
2017/12/13 09:51:59 kid1| ipcacheParse No Address records in response to
'notifications-13.mercadolibre.com'
2017/12/13 09:51:59 kid1| ipcacheParse No Address records in response to
'notifications-13.mercadolibre.com'
2017/12/13 09:51:59 kid1| ipcacheParse No Address records in response to
'notifications-13.mercadolibre.com'
2017/12/13 09:51:59 kid1| ipcacheParse No Address records in response to
'notifications-13.mercadolibre.com'
2017/12/13 09:51:59 kid1| ipcacheParse No Address records in response to
'notifications-13.mercadolibre.com'
2017/12/13 09:51:59 kid1| ipcacheParse No Address records in response to
'notifications-13.mercadolibre.com'
2017/12/13 09:52:04 kid1| ipcacheParse No Address records in response to
'notifications-12.mercadolibre.com'
2017/12/13 09:52:04 kid1| ipcacheParse No Address records in response to
'notifications-12.mercadolibre.com'
2017/12/13 10:16:09 kid1| SSL unknown certificate error -3 in
/C=US/ST=California/L=San Francisco/O=Twitter, Inc./OU=tsa_c Point of
Presence/CN=syndication.twitter.com
2017/12/13 10:16:09 kid1| Error negotiating SSL on FD 82: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/12/13 10:18:09 kid1| SSL unknown certificate error -3 in
/C=US/ST=California/L=San Francisco/O=Twitter, Inc./OU=tsa_d Point of
Presence/CN=syndication.twitter.com
2017/12/13 10:18:09 kid1| Error negotiating SSL on FD 128:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/12/13 10:20:33 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/12/13 10:20:33 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/12/13 10:20:33 kid1| NETDB state saved; 0 entries, 0 msec
2017/12/13 10:23:45 kid1| Error negotiating SSL on FD 118:
error:00000000:lib(0):func(0):reason(0) (5/-1/104)
2017/12/13 10:25:26 kid1| ipcacheParse No Address records in response to
'notifications-13.mercadolibre.com'
2017/12/13 10:25:26 kid1| ipcacheParse No Address records in response to
'notifications-13.mercadolibre.com'
2017/12/13 10:25:34 kid1| ipcacheParse No Address records in response to
'notifications-5.mercadolibre.com'
2017/12/13 10:25:34 kid1| ipcacheParse No Address records in response to
'notifications-5.mercadolibre.com'
2017/12/13 10:25:38 kid1| ipcacheParse No Address records in response to
'notifications-7.mercadolibre.com'
2017/12/13 10:25:38 kid1| ipcacheParse No Address records in response to
'notifications-7.mercadolibre.com'
2017/12/13 10:27:50 kid1| ipcacheParse No Address records in response to
'notifications-7.mercadolibre.com'
2017/12/13 10:27:50 kid1| ipcacheParse No Address records in response to
'notifications-7.mercadolibre.com'
2017/12/13 10:29:44 kid1| ipcacheParse No Address records in response to
'notifications-13.mercadolibre.com'
2017/12/13 10:29:44 kid1| ipcacheParse No Address records in response to
'notifications-13.mercadolibre.com'
2017/12/13 10:29:44 kid1| ipcacheParse No Address records in response to
'notifications-13.mercadolibre.com'
2017/12/13 10:29:44 kid1| ipcacheParse No Address records in response to
'notifications-13.mercadolibre.com'
2017/12/13 10:29:44 kid1| ipcacheParse No Address records in response to
'notifications-13.mercadolibre.com'
2017/12/13 10:29:44 kid1| ipcacheParse No Address records in response to
'notifications-13.mercadolibre.com'
2017/12/13 10:32:26 kid1| *Could not parse headers from on disk object*
2017/12/13 10:32:26 kid1| *varyEvaluateMatch: Oops. Not a Vary object on
second attempt, 'https://es.airbnb.com/'
'accept-encoding="gzip,%20deflate,%20br"'
2017/12/13 10:32:26 kid1| clientProcessHit: Vary object loop!*
2017/12/13 10:32:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://t1.musthird.com/fp/check.js;CIS3SID=967043735A626CFADAAE106A4992ADB9?org_id=kfgn8s24&session_id=1513171955--d8d2b1d1e5446f8306000f7f&nonce=35407913d6bb83f6&pageid=1
AKA
t1.musthird.com/fp/check.js;CIS3SID=967043735A626CFADAAE106A4992ADB9?org_id=kfgn8s24&session_id=1513171955--d8d2b1d1e5446f8306000f7f&nonce=35407913d6bb83f6&pageid=1
2017/12/13 10:35:00 kid1| Could not parse headers from on disk object
2017/12/13 10:35:00 kid1| varyEvaluateMatch: Oops. Not a Vary object on
second attempt, 'https://es.airbnb.com/'
'accept-encoding="gzip,%20deflate,%20br"'
2017/12/13 10:35:00 kid1| clientProcessHit: Vary object loop!



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From erdosain9 at gmail.com  Wed Dec 13 14:12:58 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 13 Dec 2017 07:12:58 -0700 (MST)
Subject: [squid-users] WARNING: HTTP requires the use of Via
Message-ID: <1513174378075-0.post@n4.nabble.com>

Im having this warning in the log.
I dont find anything related to this in google, so.

What could be??
this is my config


####GRUPOS DE IP
acl sin_autenticacion src "/etc/squid/listas/sin_autenticacion.lst" 


###Kerberos Auth with ActiveDirectory###
auth_param negotiate program /lib64/squid/negotiate_kerberos_auth -s
HTTP/squid.mydomain.lan at mydomain.LAN
auth_param negotiate children 35 startup=0 idle=1
auth_param basic credentialsttl 2 hours
auth_param negotiate keep_alive on




external_acl_type i-restringidos %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -g i-restringidos at mydomain.LAN
external_acl_type i-full %LOGIN /usr/lib64/squid/ext_kerberos_ldap_group_acl
-g i-full at mydomain.LAN
external_acl_type i-limitado %LOGIN
/usr/lib64/squid/ext_kerberos_ldap_group_acl -g i-limitado at mydomain.LAN


#GRUPOS
acl i-restringidos external i-restringidos
acl i-full external i-full
acl i-limitado external i-limitado


####Bloquea Publicidad ( http://pgl.yoyo.org/adservers/ )
acl ads dstdom_regex "/etc/squid/listas/ad_block.lst"
http_access deny ads


####Streaming
acl youtube url_regex -i \.flv$
acl youtube url_regex -i \.mp4$
acl youtube url_regex -i watch?
acl youtube url_regex -i youtube
acl facebook url_regex -i facebook
acl facebook url_regex -i fbcdn\.net\/v\/(.*\.mp4)\?
acl facebook url_regex -i fbcdn\.net\/v\/(.*\.jpg)\? 
acl facebook url_regex -i akamaihd\.net\/v\/(.*\.mp4)\?
acl facebook url_regex -i akamaihd\.net\/v\/(.*\.jpg)\?

##Dominios denegados
acl restringidos dstdomain "/etc/squid/listas/restringidos.lst"
acl dominios_denegados dstdomain "/etc/squid/listas/dominios_denegados.lst"


#Puertos
acl SSL_ports port 443
acl SSL_ports port 4443
acl SSL_ports port 8443
acl SSL_ports port 8080
acl SSL_ports port 20000
acl SSL_ports port 10000
acl SSL_ports port 2083

acl Safe_ports port 631         # httpCUPS
acl Safe_ports port 85
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 4443        # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 8443        # httpsalt
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 8080        # edesur y otros
acl Safe_ports port 2199	# radio
acl CONNECT method CONNECT


#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow sin_autenticacion
http_access deny i-restringidos restringidos
http_access allow i-limitado !dominios_denegados 
http_access allow i-full !dominios_denegados 
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 127.0.0.1:3128
http_port 192.168.1.215:3128 ssl-bump generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB cert=/etc/squid/ssl_cert/myca.pem
key=/etc/squid/ssl_cert/myca.pem 

acl step1 at_step SslBump1 

acl excludeSSL ssl::server_name_regex "/etc/squid/listas/excluidosSSL.lst"

ssl_bump peek step1 
ssl_bump splice excludeSSL 
ssl_bump bump all 

#tcp_outgoing_address  

# Uncomment and adjust the following to add a disk cache directory.
cache_dir diskd /var/spool/squid 15000 16 256
cache_mem 500 MB
#maximum_object_size_in_memory 1 MB

cache_swap_low 70
cache_swap_high 85

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid


#Your refresh_pattern
#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320

###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
via off
forwarded_for delete


###

#Pools para ancho de banda
delay_pools 5

#Ancho de Youtube
delay_class 1 2 
delay_parameters 1 1000000/1000000 10000/100000
delay_access 1 allow i-limitado youtube !facebook
delay_access 1 deny all

#Ancho de Facebook
delay_class 2 2 
delay_parameters 2 1000000/1000000 50000/256000
delay_access 2 allow i-limitado facebook !youtube
delay_access 2 deny all

#Ancho de banda YOUTUBE FULL
delay_class 3 1
delay_parameters 3 1000000/1000000
delay_access 3 allow i-full youtube !facebook
delay_access 3 deny all

#Ancho de banda LIMITADO
delay_class 4 2 
delay_parameters 4 4000000/4000000 100000/500000
delay_access 4 allow i-limitado !youtube !facebook
delay_access 4 deny all

#Ancho de banda FULL
delay_class 5 2
delay_parameters 5 4000000/4000000 500000/1000000
delay_access 5 allow i-full !youtube !facebook
delay_access 5 deny all

dns_nameservers 192.168.1.107 192.168.1.222
visible_hostname squid.mydomain.lan

# try connecting to first 25 ips of a domain name
forward_max_tries 25


Thanks to all!



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Wed Dec 13 15:28:28 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 13 Dec 2017 08:28:28 -0700
Subject: [squid-users] Warning in Cache.log
In-Reply-To: <CAGycgFhzUQ7Tu7j26WvtRP+cC7TovdKraWhsMcuVzK6AT6PgMA@mail.gmail.com>
References: <CAGycgFhzUQ7Tu7j26WvtRP+cC7TovdKraWhsMcuVzK6AT6PgMA@mail.gmail.com>
Message-ID: <da84d9cd-9cd8-4841-18b8-2335d06a9782@measurement-factory.com>

On 12/13/2017 05:13 AM, Raju M K wrote:
> I installed squid 3.5.25 on Ubuntu and in windows 10 with Diladele MSI.
> In both cache.log files, I am getting below warning.
> Few users got the same error but no solution for this.
> 
> 2017/12/13 10:38:04 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
> 
> Above warning getting while starting helpers only.
> I Installed the same squid ver 3..5.25 on? CentOS 7 but no Warnings with
> the same config.
> But we need some solution for OS also like Ubuntu and widows.

If this warning is pointless or wrong, then it would be good to fix
Squid to get rid of it. If the warning is correct (i.e., setuid(0)
failure may affect Squid operation in some cases), then it would be good
to add some wiki documentation explaining what is going on.

I do not know which of the above two conditions is true, but if you have
the resources to make Squid better, then do not ignore the warning even
if (or just because) Squid appears to work despite the warning.

N.B. It is not clear whether your "Few users got the same error" refers
to Squid administrators running your Squid (makes sense) or end users
proxying their traffic through Squid (does not make sense because end
users do not see cache.log messages). If you were talking about some end
user error, then please clarify.

Alex.
P.S. IIRC, there was a similar problem with setuid(0) failures on
FreeBSD. It had a known excuse/explanation (which I do not recall).


From mysql.jorge at decimal.pt  Wed Dec 13 16:52:51 2017
From: mysql.jorge at decimal.pt (Jorge Bastos)
Date: Wed, 13 Dec 2017 16:52:51 -0000
Subject: [squid-users] Website bypass with always-direct
Message-ID: <05b201d37432$d0a22370$71e66a50$@decimal.pt>

Howdy,

I'm trying to use always-direct, but maybe I'm doing something wrong.
I have:

acl local-servers dstdomain www.myweb.eu
always_direct allow local-servers

but the website still appears in the logs, and not doing bypass.
What could I be doing wrong?
For what I see in the docs it's correct.

tHanks in advanced,




From squid3 at treenet.co.nz  Wed Dec 13 17:03:22 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Dec 2017 06:03:22 +1300
Subject: [squid-users] WARNING: HTTP requires the use of Via
In-Reply-To: <1513174378075-0.post@n4.nabble.com>
References: <1513174378075-0.post@n4.nabble.com>
Message-ID: <6471d8ca-7776-b686-e081-95f31e0db61a@treenet.co.nz>

On 14/12/17 03:12, erdosain9 wrote:
> Im having this warning in the log.
> I dont find anything related to this in google, so.
> 
> What could be??

You have configured "via off".

HTTP specification RFC 7230 section 5.7.1:
"
    A proxy MUST send an appropriate Via header field, as described
    below, in each message that it forwards.
"

Thus the *warning*. Things can go horribly wrong if it is disabled.

Via headers' purpose is to reveal which transport protocols an HTTP 
message is traveling over so the client and server endpoints can 
automatically determine which HTTP mechanisms will (or not) work.

If used properly it can avoid multiple round-trips of 4xx and 5xx errors 
or message timeouts occuring - with all the bandwidth, CPU and delays 
involved with those.


> this is my config
...
> 
> ###ACTIVAR EN CASO DE "Connection reset by peer" EN MUCHOS HOST
> via off
> forwarded_for delete
> 

Amos


From listas_quijada at hotmail.com  Wed Dec 13 17:03:31 2017
From: listas_quijada at hotmail.com (Edwin Quijada)
Date: Wed, 13 Dec 2017 17:03:31 +0000
Subject: [squid-users] Doesnt authorize with Squid
Message-ID: <BN6PR15MB12037A3BA3D76C849C281408E3350@BN6PR15MB1203.namprd15.prod.outlook.com>

Hi!
I have installed a debian server with Squid3 to authorize surf for internet. My problem is when I get the screen for credentials I put my rigth credentials and always I get denied.

I have used a different helpers for authentication and I did my own using C

but the authorization is continue


There is a way to see or debug the autorization process?


It is the squid.conf. The helper just takes the values but always autorize, Always print OK

#Recommended minimum configuration:
http_port 3128
cache_dir ufs /var/spool/squid3 2048 16 256
maximum_object_size 100 MB
cache_swap_low 90
cache_swap_high 95

#--------------- Reglas de Autorizacion -------------
auth_param basic program   /root/squid_helper3
auth_param basic children 20
auth_param basic casesensitive off
auth_param basic realm Proxy Test --> Usuario Y Clave
auth_param basic credentialsttl 5 hours
#----------------------------------------------------
#
acl AuthenticatedUsers proxy_auth REQUIRED
http_access allow AuthenticatedUsers
#-------------------- ACL Puertos --------------------
acl SSL_ports port 443
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http

acl CONNECT method CONNECT

#---------------------- HTTP ACCES DEFAULT-------------
#http_access allow manager localhost
#http_access deny manager
http_access deny !Safe_ports

Any help ?



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171213/a792d994/attachment.htm>

From listas_quijada at hotmail.com  Wed Dec 13 17:10:43 2017
From: listas_quijada at hotmail.com (Edwin Quijada)
Date: Wed, 13 Dec 2017 17:10:43 +0000
Subject: [squid-users] Groups and authorization SQUID
In-Reply-To: <bdc90c5f-2efc-4ce8-4aa9-9a22da9143c8@treenet.co.nz>
References: <BN6PR15MB1203D51EC21557CF8BC47441E3300@BN6PR15MB1203.namprd15.prod.outlook.com>
 <201712082350.51217.Antony.Stone@squid.open.source.it>
 <BN6PR15MB12039E5921388CCC0B44D46CE3310@BN6PR15MB1203.namprd15.prod.outlook.com>
 <201712091657.52150.Antony.Stone@squid.open.source.it>
 <BN6PR15MB12037091515BEB05BA12F701E3370@BN6PR15MB1203.namprd15.prod.outlook.com>
 <8eb9c36c-3880-1bda-78d3-9412d8eed02c@treenet.co.nz>
 <BN6PR15MB1203A8F78C56178C3EB18992E3340@BN6PR15MB1203.namprd15.prod.outlook.com>,
 <bdc90c5f-2efc-4ce8-4aa9-9a22da9143c8@treenet.co.nz>
Message-ID: <BN6PR15MB12034D84A5AF20C040AD6B1AE3350@BN6PR15MB1203.namprd15.prod.outlook.com>

I answered the comments that you wrote, I think


________________________________
From: squid-users <squid-users-bounces at lists.squid-cache.org> on behalf of Amos Jeffries <squid3 at treenet.co.nz>
Sent: Wednesday, December 13, 2017 2:55 AM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Groups and authorization SQUID

Why are you just re-posting what I already posted, but with your name on
it as author?

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
squid-users Info Page<http://lists.squid-cache.org/listinfo/squid-users>
lists.squid-cache.org
squid-users -- General discussion relating to Squid. The membership of this list is thousands of Squid users from around the world About squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171213/0f79397f/attachment.htm>

From squid3 at treenet.co.nz  Wed Dec 13 17:12:27 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Dec 2017 06:12:27 +1300
Subject: [squid-users] Website bypass with always-direct
In-Reply-To: <05b201d37432$d0a22370$71e66a50$@decimal.pt>
References: <05b201d37432$d0a22370$71e66a50$@decimal.pt>
Message-ID: <57b6df0b-dc0b-f3a6-ce42-8c366770e29c@treenet.co.nz>

On 14/12/17 05:52, Jorge Bastos wrote:
> Howdy,
> 
> I'm trying to use always-direct, but maybe I'm doing something wrong.
> I have:
> 
> acl local-servers dstdomain www.myweb.eu
> always_direct allow local-servers
> 
> but the website still appears in the logs, and not doing bypass.
> What could I be doing wrong?
> For what I see in the docs it's correct.

Your understanding of the docs is wrong.

Once a message arrives at Squid is *cannot* "bypass the proxy" or 
whatever you want to call it. It MUST be serviced by the proxy.

"always_direct allow ..." tells Squid to always use DIRECT access to the 
origin server IPs indicated in DNS records for the URL being fetched. 
Squid is prohibited from using any cache_peer server connection to 
service that transaction.

Its counterpart is the "never_direct allow ..." which tells Squid DNS 
records MUST NOT be considered, only cache_peer connections are permitted.

If both of those are "denied" (aka both DNS and cache_peer are 
permitted) the prefer_direct setting tells Squid whether to try the 
cache_peer or the DIRECT IPs first.


The cache_peer_access controls which peers (from multiple) are permitted 
(or not) to be used for a given transaction.

Amos


From squid3 at treenet.co.nz  Wed Dec 13 18:04:30 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Dec 2017 07:04:30 +1300
Subject: [squid-users] TCP_MISS_ABORTED
In-Reply-To: <20171213152306992405165@lvmama.com>
References: <20171213152306992405165@lvmama.com>
Message-ID: <6573abf7-b7bb-bfbb-a651-b3a92e8c2507@treenet.co.nz>

On 13/12/17 20:30, zhongzhe at lvmama.com wrote:
> Hi, All
>  ? ? I used httpclient to imitate a request to squid , but the response 
> page had not stored by squid although response?header is?200. I had 
> tried many times with three different pages . only one can be stored by 
> the squid cache. and the others must need to send requset by brower then 
> they were cached. ?I had checked the access.log , it show me like this.
> 1513148548.653???9172?10.112.4.54?TCP_MISS_ABORTED/200?106197?GET?http://youlun.lvmama.com/ship_front/youlun/1012487?-?FIRSTUP_PARENT/10.112.4.54?text/html
> 
> do you know what's wrong of my squid.conf ? need your help !\

There seem to be many things. But none of them have much to do with te 
above.

What the above says is that a client at 10.112.4.54 requested 
http://youlun.lvmama.com/ship_front/youlun/1012487 and disconnected 
after 9 seconds.

The fact that ~100KB of traffic happened in that transaction implies 
that everything was going okay for a while at least. So there is no 
visible problem with Squid in that log entry. The ABORTED simply means 
one of the endpoints (probably the client) decided to disconnect early.



Back to your squid.conf;




>  ? ? below is my squid.conf
> acl?gsrc?src?10.112.4.54?10.113.10.191
> acl?gdst?dst?10.112.4.54?10.113.10.191
> http_access?allow?gsrc
> http_access?allow?gdst

What is the above supposed to mean?

> 
> acl?localnet?src?10.0.0.0/8?????#?RFC1918?possible?internal?network
> acl?localnet?src?172.16.0.0/12??#?RFC1918?possible?internal?network
> acl?localnet?src?192.168.0.0/16?#?RFC1918?possible?internal?network
> acl?localnet?src?fc00::/7???????#?RFC?4193?local?private?network?range
> acl?localnet?src?fe80::/10??????#?RFC?4291?link-local?(directly?plugged)?machines
> 
> acl?purge?method?PURGE
> acl?clientServers?src?10.112.4.54
> http_access?allow?purge?clientServers
> http_access?deny?purge
> 
> acl?gat?method?GET
> acl?clientS?src?10.112.4.54?10.113.10.190
> http_access?allow?gat?clientS
> #http_access?deny?gat

The localnet ACL defines 10.*/8 as allowed and your rules below specify 
that all localnet traffic is allowed.

So the above four lines of config seem pointless.


You have configured the machines 10.112.4.54 and 10.113.10.190 as your 
cache_peer servers. So why are they listed as "src" ?

In a reverse-proxy "src" is the IP of a client requesting a URL.

"dst" is the destination server - as determined by DNS records for the 
URL domain being fetched. In a reverse-proxy those DNS records should 
hold the proxies own IP address. So dst-IP is rarely ever useful and are 
downright dangerous to make use of in the reverse-proxy.



> 
> acl?SSL_ports?port?443
> acl?Safe_ports?port?80??????????#?http
> acl?Safe_ports?port?21??????????#?ftp
> acl?Safe_ports?port?443?????????#?https
> acl?Safe_ports?port?70??????????#?gopher
> acl?Safe_ports?port?210?????????#?wais
> acl?Safe_ports?port?1025-65535??#?unregistered?ports
> acl?Safe_ports?port?280?????????#?http-mgmt
> acl?Safe_ports?port?488?????????#?gss-http
> acl?Safe_ports?port?591?????????#?filemaker
> acl?Safe_ports?port?777?????????#?multiling?http
> acl?Safe_ports?port?3130????????#?icp
> acl?Safe_ports?port?3128
> acl?CONNECT?method?CONNECT
> 
> http_access?deny?!Safe_ports
> 
> http_access?deny?CONNECT?!SSL_ports
> 
> http_access?allow?localhost?manager
> http_access?deny?manager
> 

As the default config file says:

"
#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
"


> http_access?allow?localnet
> http_access?allow?localhost
> 
> http_port?80?accel?defaultsite=youlun.lvmama.com?no-vhost
> 
> cache_dir?aufs?/var/spool/squid?8198?16?256
> cache_mem?5120?MB
> cache_swap_low?90
> cache_swap_high?95
> cache_mgr?zhongzhe at lvmama.com
> 
> visible_hostname?cache190
> 

So the domain name Squid announces to your clients is "cache190" as in 
http://cache190/ship_front/youlun/1012487.


> coredump_dir??/var/spool/squid
> 
> via?off

At least while debugging peering issues set "via on". Only turn it off 
if you really have to and *after* you have a fully working proxy hierarchy.


> maximum_object_size?500?KB
> 
> icp_port?3130
> icp_access?allow?all
> icp_query_timeout?2000
> 
> cache_peer?10.112.4.54?parent?8090?0?no-query?originserver?name=youlun
> acl?mysites?dstdomain?youlun.lvmama.com
> http_access?allow?mysites
> cache_peer_access?youlun?allow?all
> cache_peer_access?youlun?deny?all

The default for cache_peer_access is to allow. No need to specify that 
"allow all". What you need to do to allow everything to reach that peer 
server is *not* specify "deny all".

Though the normal thing is to use an ACL (eg your "mysites" one) to 
allow the domains an origin server is known to supply and to deny other 
things. Since it is not even worth trying that peer for things it is not 
known to be capable of serving.

So:
   http_access allow mysites
   cache_peer_access youlun allow mysites
   cache_peer_access youlun deny all


Also be aware that all of this peer and http_access config needs to be 
located up where it says " INSERT YOUR OWN RULE(S) HERE " etc.



> 
> refresh_pattern?-i?.*/youlun/([0-9]+)?1440?100%?10080?ignore-no-store?ignore-must-revalidate?store-stale?ignore-reload
> 

Why? if your server is not producing correct cacheability headers then 
everyone trying to use your site will be having problems. "Fixing" it 
for only your proxy by ignoring required things is the worst possible 
action to take.

Your proxy is a reverse-proxy (aka CDN), it advertises its Surrogate 
abilities to the origin server so your proxy cache can be given custom 
values different from the general public. If you need


> refresh_pattern?^ftp:??????????1440????20%?????10080
> refresh_pattern?^gopher:????????1440????0%??????1440
> refresh_pattern?-i?(/cgi-bin/|\?)?0?????0%??????0
> refresh_pattern?.???????????????0???????20%?????4320
> 
> cache_log?/var/log/squid/cache.log
> cache_access_log?/var/log/squid/access.log

The directive name is "access_log"

> cache_store_log?/var/log/squid/store.log
> 
> log_icp_queries?off
> 
> http_access?allow?all

Do not do that "allow all".

> http_access?deny?all
> 


Amos


From mysql.jorge at decimal.pt  Wed Dec 13 18:19:55 2017
From: mysql.jorge at decimal.pt (Jorge Bastos)
Date: Wed, 13 Dec 2017 18:19:55 -0000
Subject: [squid-users] website bypass with always-direct
Message-ID: <05da01d3743e$f9f9ac00$eded0400$@decimal.pt>

Howdy,

I'm trying to use always-direct, but maybe I'm doing something wrong.
I have:

acl local-servers dstdomain http://www.myweb.eu always_direct allow
local-servers

but the website still appears in the logs, and not doing bypass.
What could I be doing wrong?
For what I see in the docs it's correct.

tHanks in advanced,




From squid3 at treenet.co.nz  Wed Dec 13 18:30:45 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Dec 2017 07:30:45 +1300
Subject: [squid-users] Warning in Cache.log
In-Reply-To: <da84d9cd-9cd8-4841-18b8-2335d06a9782@measurement-factory.com>
References: <CAGycgFhzUQ7Tu7j26WvtRP+cC7TovdKraWhsMcuVzK6AT6PgMA@mail.gmail.com>
 <da84d9cd-9cd8-4841-18b8-2335d06a9782@measurement-factory.com>
Message-ID: <2cca92c2-eda1-822c-10c5-d6a53b081e26@treenet.co.nz>

On 14/12/17 04:28, Alex Rousskov wrote:
> On 12/13/2017 05:13 AM, Raju M K wrote:
>> I installed squid 3.5.25 on Ubuntu and in windows 10 with Diladele MSI.
>> In both cache.log files, I am getting below warning.
>> Few users got the same error but no solution for this.
>>
>> 2017/12/13 10:38:04 kid1| WARNING: no_suid: setuid(0): (22) Invalid argument
>>
...
> Alex.
> P.S. IIRC, there was a similar problem with setuid(0) failures on
> FreeBSD. It had a known excuse/explanation (which I do not recall).


IIRC,  FreeBSD setuid() implementation produces their "error" if the 
process attempting to drop privileges has already dropped down to 
no-privileges before the setuid() call. Squid drops privileges both 
before and after fork()'ing a helper - so FreeBSD helpers always see it 
happen on helper startup.

Linux (CentOS and Ubuntu) handles that double-up silently - so when 
messages do show up there is always a security privilege problem going 
on. I'm not sure of Windows, but never heard of it happening there either.


Raju;

"Invalid Argument" apparently means either the privileges selected are 
not known to the OS kernel or the user account does not exist.

The privileges are being set to 0, so that value should be known to the 
kernel.

That leaves the user account name. The default name built into Squid is 
not a valid account on Linux or Windows (it is a FreeBSD standard name), 
so you do need to compile using --with-default-user=... and ensure the 
account mentioned there is valid on the machine Squid runs on.

Amos


From squid3 at treenet.co.nz  Wed Dec 13 18:31:39 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Dec 2017 07:31:39 +1300
Subject: [squid-users] website bypass with always-direct
In-Reply-To: <05da01d3743e$f9f9ac00$eded0400$@decimal.pt>
References: <05da01d3743e$f9f9ac00$eded0400$@decimal.pt>
Message-ID: <a293b5ce-b1d0-625c-cfee-cd2f922ed7d8@treenet.co.nz>

See the reply to your previous identical post.

Amos


From squid3 at treenet.co.nz  Wed Dec 13 18:35:33 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Dec 2017 07:35:33 +1300
Subject: [squid-users] (no subject)
In-Reply-To: <CY4PR22MB03608A18ECDBF0A5E5DADB6198350@CY4PR22MB0360.namprd22.prod.outlook.com>
References: <CY4PR22MB03608A18ECDBF0A5E5DADB6198350@CY4PR22MB0360.namprd22.prod.outlook.com>
Message-ID: <e8218fdd-b2e7-9e1c-9b5f-9ac195fb0e1c@treenet.co.nz>

On 13/12/17 21:19, ? ? wrote:
>>>  When?I access SVN ,I want to bump SVN connection.
> 
>>> My squid.conf :
>>> 
>>> acl ssl_step1 at_step SslBump1
>>>acl ssl_step2 at_step SslBump2
>>> acl ssl_step3 at_step SslBump3
>>> 
>>> ssl_bump stare ssl_step1
>>> ssl_bump bump ssl_step2
>>>ssl_bump terminate ssl_step3
>>>
>>> May? i? solve this problem,if I go to the official certification  
>>> organization?certificating myCA??
> 
> 
> 
> 
>>The second problem is that you are bumping at SSL-Bump  step #2 before
>>?any of the real server details are available to Squid.
> 
> I want to know which step to bump and?which?action at SSL-Bump step#1?
> 
> 

To avoid problems you need mimic to happen. So bump at step 3. Stare at 
step 2. Step 1 can be a peek or stare at you choice.

Amos


From erdosain9 at gmail.com  Wed Dec 13 18:52:02 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 13 Dec 2017 11:52:02 -0700 (MST)
Subject: [squid-users] reference_age 1 week
Message-ID: <1513191122445-0.post@n4.nabble.com>

Hi.
I want to put that command
reference_age 1 week

i see that in a lot of tutorial, but... squid give me a error, and stop the
service.
dont recognice the command... that command doesnt exist anymore??

Thanks

pd:there is another way to tell squid how manage the time for the cache
objets??



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Wed Dec 13 19:26:22 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 13 Dec 2017 12:26:22 -0700
Subject: [squid-users] (no subject)
In-Reply-To: <e8218fdd-b2e7-9e1c-9b5f-9ac195fb0e1c@treenet.co.nz>
References: <CY4PR22MB03608A18ECDBF0A5E5DADB6198350@CY4PR22MB0360.namprd22.prod.outlook.com>
 <e8218fdd-b2e7-9e1c-9b5f-9ac195fb0e1c@treenet.co.nz>
Message-ID: <2e593c97-596f-5ab5-7080-7fbae7a2807a@measurement-factory.com>

On 12/13/2017 11:35 AM, Amos Jeffries wrote:
> Step 1 can be a peek or stare at you choice.

... and that choice will determine whether Squid bumps or splices the
connections at step2 in the unlikely event no ssl_bump rules match
during step2. It is best to avoid such situations, of course.

Alex.


From phackmann at gmail.com  Wed Dec 13 22:32:45 2017
From: phackmann at gmail.com (Paul Hackmann)
Date: Wed, 13 Dec 2017 16:32:45 -0600
Subject: [squid-users] squid asking for authentication repeatedly
In-Reply-To: <37faddcb-b809-9d30-5fd5-503b64f529f8@treenet.co.nz>
References: <CADQL5rOea3c5RbvdrRtyB7dYpEsPmUfmu8XDjfOXApRwUTAYhw@mail.gmail.com>
 <3eb1226d-9dc8-33e9-0495-8ba902747596@treenet.co.nz>
 <CADQL5rN5md1g9_-BrGz4AybZ79dNm8GYHB_u=VBmunQQ9EVL3w@mail.gmail.com>
 <37faddcb-b809-9d30-5fd5-503b64f529f8@treenet.co.nz>
Message-ID: <CADQL5rOVmb0AwKK-+E4vsRHx1Tbo2oOkhae7V0k=T9q_ZEbgFQ@mail.gmail.com>

Amos,

I will do an update to the most recent version and see if that helps.  It
was one of those situations where if it ain't broke, don't fix it.  And up
until now, it has worked very well.

You are right, I had brain fade about port 4120.  It should NOT ask for
authentication ever, and only connect to whitelisted sites, which is what I
want.

I've made the changes you recommended to the conf file.  So far, everything
seems to be working as I expect it to.  Thank you!

One more question if you don't mind.  I am trying to add some ip addresses
as whitelisted for port 4120.  I guess I can't add those to the whitelist
file, because it's formatting doesn't work with IP addresses?  I read that
you can add them into the conf file.  I've created the following acl line:

acl 8x8 dst 8.5.248.0/23 8.28.0.0/22 63.209.12.0/24 162.221.236.0/23
162.221.238.0/23 192.84.16.0/22

and I tried to add 8x8 to the the http_access line:

http_access allow whitelist 8x8

but when I did that, the 4120 port started asking for authentication, which
is wrong. Can you tell me how to open those ip address ranges for port 4120?

Thanks very much
PH

On Tue, Dec 12, 2017 at 10:30 AM, Amos Jeffries <squid3 at treenet.co.nz>
wrote:

> On 13/12/17 04:10, Paul Hackmann wrote:
>
>> Amos,
>>
>> The squid version is 3.1.19.
>>
>
> Please upgrade. There have been a *lot* of authentication related issues
> that got solved in the years since that version was released. IIRC several
> involved nasty things like the looping you described.
>
> All current OS distributions have more recent Squid versions available. Or
> worst-case custom building is not very hard.
>
>
>   The network is set up with a 192.168.0.X network on the lan side, and a
>> 192.168.1.x network on the internet side.  Both ports 3120 and 4120 require
>> authentication,
>>
>
>
> NOTE: port 4120 is an intercepted port. HTTP Proxy Authentication on
> traffic arriving there is prohibited, since the HTTP traffic syntax is
> origin-form.
>
> However that said, your config displayed below contradicts what you wrote
> above. Port 41290 traffic does *not* use authentication - the only
> restriction on port 4120 traffic is that it be going to one of the
> whitelisted domains. Period. There is absolutely no restriction on what
> happens or can be done when going to those domains.
>
>
>
> but port 4120 is meant to be restricted to only the whitelisted sites
>> which are in a separate file.  Port 3120 allows access to any site.  The
>> browser causing trouble is configured for port 3120, not 4120.  Here is my
>> squid.conf file:
>>
>> ...
>
>>
>> #not sure what this line does
>> acl manager url_regex -i ^cache_object:// +i
>> ^https?://[^/]+/squid-internal-mgr/
>>
>>
> The above line defines an ACL which matches requests for Squids internal
> cache management reports. For both the Squid-2+ and Squid-3.4+ management
> APIs.
>
> Your Squid version requires this to be configured. Current releases
> provide it as a built-in default ACL so you don't need to track or fix its
> definition changes during upgrade.
>
> ...
>
>> http_access allow CONNECT localnet
>>
>
> Bad. All LAN clients are allowed to open arbitrary TCP connections
> (CONNECT tunnels) through the proxy *to anywhere* absolutely zero
> restrictions.
>
> The entire point of the "deny CONNECT !SSL_ports" and other default
> security rules is to prohibit attackers and infected LAN clients from using
> the proxy to spread nasty traffic around.
>
> To be useful those default security measure must be placed *first* in the
> http_access ordering and written exactly as provided in the default
> installation. Your own rules should be applied to the traffic which gets
> past those basic precautions.
>
>
> http_access deny deny_websites
>> http_access allow allowed_clients ncsa_users
>> http_access deny !allowed_clients
>> #http_access allow ncsa_users
>> http_access allow manager localhost
>> http_access deny manager
>> http_access deny !Safe_ports
>> #http_access deny CONNECT !SSL_ports
>> http_access allow localhost
>> #http_access allow localnet
>>
>> http_access deny all
>>
>> If the conf file is a mess, or has some problems, feel free to say so, as
>> I don't know what all of the directives in it are for.  I marked a couple
>> of lines I don't understand.  I would be happy for it to be optimized more
>> if anyone has ideas.
>>
>>
> I recommend you write your http_access something like so:
>
>
>  http_access deny !Safe_ports
>  http_access deny CONNECT !SSL_ports
>  http_access allow manager localhost
>  http_access deny manager
>
>  # domains in deny_websites are DENIED for everybody.
>  http_access deny deny_websites
>
>  # domains in whitelist are ALLOWED for everybody
>  http_access allow whitelist
>
>  # port 4120 traffic is restricted to the above whitelisted domains
>  http_access deny portX
>
>  # otherwise; for port 3120 traffic ...
>
>  # only specific clients with whitelisted IPs can use the proxy ...
>  http_access deny !allowed_clients
>
>  # ... and must also login
>  http_access deny !ncsa_users
>
>  http_access allow localnet
>
>  http_access deny all
>
>
> If the above still has the looping issue then I think the problem is
> related to how the Browser is using its TCP connections.
>
> Some Browsers used to open many parallel TCP connections and start
> requesting stuff immediately. But their internal credential handling seemed
> not to cope with the parallelism, treating the 2nd through Nth auth
> challenges as a sign that the 1st connections credentials were invalid.
>
> This was particularly bad for any Browsers configured to auto-load many
> tabs on startup. I've not heard of it happening in quite a while though, so
> it may be fixed in current Browsers. Or maybe they just handle tabs
> differently that does not trigger so easily.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171213/35e3c218/attachment.htm>

From mysql.jorge at decimal.pt  Wed Dec 13 23:10:39 2017
From: mysql.jorge at decimal.pt (Jorge Bastos)
Date: Wed, 13 Dec 2017 23:10:39 +0000
Subject: [squid-users] Website bypass with always-direct
In-Reply-To: <57b6df0b-dc0b-f3a6-ce42-8c366770e29c@treenet.co.nz>
References: <05b201d37432$d0a22370$71e66a50$@decimal.pt>
 <57b6df0b-dc0b-f3a6-ce42-8c366770e29c@treenet.co.nz>
Message-ID: <700896e3a372e0621037e3cd57201108@decimal.pt>

On 2017-12-13 17:12, Amos Jeffries wrote:

> On 14/12/17 05:52, Jorge Bastos wrote: 
> 
>> Howdy,
>> 
>> I'm trying to use always-direct, but maybe I'm doing something wrong.
>> I have:
>> 
>> acl local-servers dstdomain www.myweb.eu [1]
>> always_direct allow local-servers
>> 
>> but the website still appears in the logs, and not doing bypass.
>> What could I be doing wrong?
>> For what I see in the docs it's correct.
> 
> Your understanding of the docs is wrong.
> 
> Once a message arrives at Squid is *cannot* "bypass the proxy" or whatever you want to call it. It MUST be serviced by the proxy.
> 
> "always_direct allow ..." tells Squid to always use DIRECT access to the origin server IPs indicated in DNS records for the URL being fetched. Squid is prohibited from using any cache_peer server connection to service that transaction.
> 
> Its counterpart is the "never_direct allow ..." which tells Squid DNS records MUST NOT be considered, only cache_peer connections are permitted.
> 
> If both of those are "denied" (aka both DNS and cache_peer are permitted) the prefer_direct setting tells Squid whether to try the cache_peer or the DIRECT IPs first.
> 
> The cache_peer_access controls which peers (from multiple) are permitted (or not) to be used for a given transaction.

hi Amos, 

sorry for the dup, it was my fantastic email client fault (outlook
2016). 

Ok, so what would be the directive to allow what i want to achieve? I've
been trying and having no success, 

 

Links:
------
[1] http://www.myweb.eu
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171213/df4d0f35/attachment.htm>

From rousskov at measurement-factory.com  Thu Dec 14 00:08:06 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 13 Dec 2017 17:08:06 -0700
Subject: [squid-users] Website bypass with always-direct
In-Reply-To: <700896e3a372e0621037e3cd57201108@decimal.pt>
References: <05b201d37432$d0a22370$71e66a50$@decimal.pt>
 <57b6df0b-dc0b-f3a6-ce42-8c366770e29c@treenet.co.nz>
 <700896e3a372e0621037e3cd57201108@decimal.pt>
Message-ID: <0f86de81-76eb-2a4e-ddca-483f457f643a@measurement-factory.com>

On 12/13/2017 04:10 PM, Jorge Bastos wrote:
> On 2017-12-13 17:12, Amos Jeffries wrote:
>> On?14/12/17?05:52,?Jorge?Bastos?wrote:

>>> I'm?trying?to?use?always-direct, [...]
>>> but?the?website?still?appears?in?the?logs,?and?not?doing?bypass.
>>> What?could?I?be?doing?wrong?
>>> For?what?I?see?in?the?docs?it's?correct.


>> Your?understanding?of?the?docs?is?wrong.
>>
>> Once a message arrives at Squid is *cannot* "bypass the proxy" or
>> whatever you want to call it. It MUST be serviced by the proxy.


> Ok, so what would be the directive to allow what i want to achieve?


What do you want to achieve?

Earlier, you implied that you do not want to see a request in Squid
logs. As Amos have said, Squid cannot "unsee" the transaction: Once the
transaction reaches Squid, Squid will handle it (forward, block, delay,
mangle, log, etc.). If you want Squid to not see a transaction, then all
the solutions will be outside of Squid and its directives. Please
explain what you want with this fact in mind.

Alex.


From squid3 at treenet.co.nz  Thu Dec 14 01:35:07 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Dec 2017 14:35:07 +1300
Subject: [squid-users] squid asking for authentication repeatedly
In-Reply-To: <CADQL5rOVmb0AwKK-+E4vsRHx1Tbo2oOkhae7V0k=T9q_ZEbgFQ@mail.gmail.com>
References: <CADQL5rOea3c5RbvdrRtyB7dYpEsPmUfmu8XDjfOXApRwUTAYhw@mail.gmail.com>
 <3eb1226d-9dc8-33e9-0495-8ba902747596@treenet.co.nz>
 <CADQL5rN5md1g9_-BrGz4AybZ79dNm8GYHB_u=VBmunQQ9EVL3w@mail.gmail.com>
 <37faddcb-b809-9d30-5fd5-503b64f529f8@treenet.co.nz>
 <CADQL5rOVmb0AwKK-+E4vsRHx1Tbo2oOkhae7V0k=T9q_ZEbgFQ@mail.gmail.com>
Message-ID: <d51393d6-c991-b131-9881-97eafbb3f504@treenet.co.nz>

On 14/12/17 11:32, Paul Hackmann wrote:
> Amos,
> 
> I will do an update to the most recent version and see if that helps.  
> It was one of those situations where if it ain't broke, don't fix it.  
> And up until now, it has worked very well.
> 
> You are right, I had brain fade about port 4120.? It should NOT ask for 
> authentication ever, and only connect to whitelisted sites, which is 
> what I want.
> 
> I've made the changes you recommended to the conf file.? So far, 
> everything seems to be working as I expect it to.? Thank you!
> 
> One more question if you don't mind.? I am trying to add some ip 
> addresses as whitelisted for port 4120.? I guess I can't add those to 
> the whitelist file, because it's formatting doesn't work with IP 
> addresses?

Sort of. dstdomain can accept IPs for matching against raw-IP text 
strings in URLs where domain should have been. But does not do ranges 
like you need there.

So yes dst is the one to use there.

However, be aware that it will match if *any* IPs for the domain being 
fetched is in your whitelist set. It has nothing to do with whether that 
matching dst-IP is actually used by Squid on the server connection.
To workaround that is where explicitly configuring "never_direct allow 
all" comes in handy.


>? I read that you can add them into the conf file.? I've 
> created the following acl line:
> 
> acl 8x8 dst 8.5.248.0/23 8.28.0.0/22 63.209.12.0/24 
> 162.221.236.0/23 162.221.238.0/23 192.84.16.0/22
> 
> and I tried to add 8x8 to the the http_access line:
> 
> http_access allow whitelist 8x8
> 
> but when I did that, the 4120 port started asking for authentication, 
> which is wrong. Can you tell me how to open those ip address ranges for 
> port 4120?
> 

Your use of http_access is not quite right.

see <https://wiki.squid-cache.org/SquidFaq/SquidAcl#Common_Mistakes>


Amos


From squid3 at treenet.co.nz  Thu Dec 14 01:46:40 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Dec 2017 14:46:40 +1300
Subject: [squid-users] reference_age 1 week
In-Reply-To: <1513191122445-0.post@n4.nabble.com>
References: <1513191122445-0.post@n4.nabble.com>
Message-ID: <115d52bf-9925-f18e-6a57-f08bb993350c@treenet.co.nz>

On 14/12/17 07:52, erdosain9 wrote:
> Hi.
> I want to put that command
> reference_age 1 week
> 
> i see that in a lot of tutorial, but... squid give me a error, and stop the
> service.
> dont recognice the command... that command doesnt exist anymore??
> 

Correct. It does not exist since the date 2000-05-15.

Please find some more relevant tutorials. Perhapse the 
<http://wiki.squid-cache.org/ConfigExamples/> ones already document what 
you need.



> Thanks
> 
> pd:there is another way to tell squid how manage the time for the cache
> objets??

Time is what it is. The server tells Squid how old an object was when 
delivered. Squid itself tracks the time between that delivery and the 
current operation being performed. Those are facts not subject to any 
humans wishes.

What you do get to decide is some default parameters to use when the 
server does not supply enough details for the heuristic caching 
algorithm (defined in <https://tools.ietf.org/html/rfc7234#section-4.2>) 
that are used *if* the server and client do not provided them.
  The refresh_pattern directive is used for supplying those parameters.
  <http://www.squid-cache.org/Doc/config/refresh_pattern/>


Amos


From zhongzhe at lvmama.com  Thu Dec 14 03:48:35 2017
From: zhongzhe at lvmama.com (zhongzhe at lvmama.com)
Date: Thu, 14 Dec 2017 11:48:35 +0800
Subject: [squid-users] TCP_MISS_ABORTED
References: <20171213152306992405165@lvmama.com>, 
 <6573abf7-b7bb-bfbb-a651-b3a92e8c2507@treenet.co.nz>
Message-ID: <2017121411483493862453@lvmama.com>+5A775B3C1BFA7129

Hi, Amos
    Thanks a lot for your reply.  In my conf, squid is not only a reverse-proxy server, but also a cache server. And that is important to me.  In fact , it does't normally for my product environment.  10.112.4.54 is the apache server(been agent by squid) , and my request is also sent by it(such as browser request and mimetic of httpclient request by java).  10.113.10.191 is the peer squid server, And is closed now. 10.113.10.190, as you see, is the
current  reverse-proxy server. 
    Whole proceess like this:
        10.112.4.54(browser)  send request   10.113.10.190 if not cached, forward the requset to apache server   10.112.4.54(apache server)  return the response page to browser  10.112.4.54(browser)
                                                                                            if cached, return the page                                             10.112.4.54(browser)

>      below is my squid.conf
> acl gsrc src 10.112.4.54 10.113.10.191
> acl gdst dst 10.112.4.54 10.113.10.191
> http_access allow gsrc
> http_access allow gdst
 
>>What is the above supposed to mean?

>
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
>
> acl purge method PURGE
> acl clientServers src 10.112.4.54
> http_access allow purge clientServers
> http_access deny purge
>
> acl gat method GET
> acl clientS src 10.112.4.54 10.113.10.190
> http_access allow gat clientS
> #http_access deny gat
 
>>The localnet ACL defines 10.*/8 as allowed and your rules below specify
>>that all localnet traffic is allowed.
>> 
>>So the above four lines of config seem pointless.
>>
>>You have configured the machines 10.112.4.54 and 10.113.10.190 as your
>>cache_peer servers. So why are they listed as "src" ?
>>
>>In a reverse-proxy "src" is the IP of a client requesting a URL.
>>
>>"dst" is the destination server - as determined by DNS records for the
>>URL domain being fetched. In a reverse-proxy those DNS records should
>>hold the proxies own IP address. So dst-IP is rarely ever useful and are
>>downright dangerous to make use of in the reverse-proxy.
 

ICP requset cannot sent to peer server at first. So I add it to try to solve it .  
 



>
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl Safe_ports port 3130        # icp
> acl Safe_ports port 3128
> acl CONNECT method CONNECT
>
> http_access deny !Safe_ports
>
> http_access deny CONNECT !SSL_ports
>
> http_access allow localhost manager
> http_access deny manager
>

As the default config file says:
"
#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
"

thanks a lot, I'll delete the needless port info. 
 


> http_access allow localnet
> http_access allow localhost
>
> http_port 80 accel defaultsite=youlun.lvmama.com no-vhost
>
> cache_dir aufs /var/spool/squid 8198 16 256
> cache_mem 5120 MB
> cache_swap_low 90
> cache_swap_high 95
> cache_mgr zhongzhe at lvmama.com
>
> visible_hostname cache190
>

So the domain name Squid announces to your clients is "cache190" as in
http://cache190/ship_front/youlun/1012487.
 

I think my domain name is youlun.lvmama.com. cache190 is just a individual name to distinguish with squid server 10.113.10.191.
 




> coredump_dir  /var/spool/squid
>
> via off
 
At least while debugging peering issues set "via on". Only turn it off
if you really have to and *after* you have a fully working proxy hierarchy.
 

agree with your.
 


> maximum_object_size 500 KB
>
> icp_port 3130
> icp_access allow all
> icp_query_timeout 2000
>
> cache_peer 10.112.4.54 parent 8090 0 no-query originserver name=youlun
> acl mysites dstdomain youlun.lvmama.com
> http_access allow mysites
> cache_peer_access youlun allow all
> cache_peer_access youlun deny all
 
The default for cache_peer_access is to allow. No need to specify that
"allow all". What you need to do to allow everything to reach that peer
server is *not* specify "deny all".
 
Though the normal thing is to use an ACL (eg your "mysites" one) to
allow the domains an origin server is known to supply and to deny other
things. Since it is not even worth trying that peer for things it is not
known to be capable of serving.
 
So:
   http_access allow mysites
   cache_peer_access youlun allow mysites
   cache_peer_access youlun deny all
 
 
Also be aware that all of this peer and http_access config needs to be
located up where it says " INSERT YOUR OWN RULE(S) HERE " etc.
 
 
Thanks , I had delete it.

 
>
> refresh_pattern -i .*/youlun/([0-9]+) 1440 100% 10080 ignore-no-store ignore-must-revalidate store-stale ignore-reload
>
 
Why? if your server is not producing correct cacheability headers then
everyone trying to use your site will be having problems. "Fixing" it
for only your proxy by ignoring required things is the worst possible
action to take.
 
Your proxy is a reverse-proxy (aka CDN), it advertises its Surrogate
abilities to the origin server so your proxy cache can be given custom
values different from the general public. If you need
 

I want to squid server response a cache page to the request if it's exit .

 
> refresh_pattern ^ftp:          1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
>
> cache_log /var/log/squid/cache.log
> cache_access_log /var/log/squid/access.log
 
The directive name is "access_log"

Changed.
 
> cache_store_log /var/log/squid/store.log
>
> log_icp_queries off
>
> http_access allow all
 
Do not do that "allow all".
 
Been deleted.

> http_access deny all



zhongzhe at lvmama.com
 
From: Amos Jeffries
Date: 2017-12-14 02:04
To: squid-users
Subject: Re: [squid-users] TCP_MISS_ABORTED
On 13/12/17 20:30, zhongzhe at lvmama.com wrote:
> Hi, All
>      I used httpclient to imitate a request to squid , but the response 
> page had not stored by squid although response header is 200. I had 
> tried many times with three different pages . only one can be stored by 
> the squid cache. and the others must need to send requset by brower then 
> they were cached.  I had checked the access.log , it show me like this.
> 1513148548.653   9172 10.112.4.54 TCP_MISS_ABORTED/200 106197 GET http://youlun.lvmama.com/ship_front/youlun/1012487 - FIRSTUP_PARENT/10.112.4.54 text/html
> 
> do you know what's wrong of my squid.conf ? need your help !\
 
There seem to be many things. But none of them have much to do with te 
above.
 
What the above says is that a client at 10.112.4.54 requested 
http://youlun.lvmama.com/ship_front/youlun/1012487 and disconnected 
after 9 seconds.
 
The fact that ~100KB of traffic happened in that transaction implies 
that everything was going okay for a while at least. So there is no 
visible problem with Squid in that log entry. The ABORTED simply means 
one of the endpoints (probably the client) decided to disconnect early.
 
 
 
Back to your squid.conf;
 
 
 
 
>      below is my squid.conf
> acl gsrc src 10.112.4.54 10.113.10.191
> acl gdst dst 10.112.4.54 10.113.10.191
> http_access allow gsrc
> http_access allow gdst
 
What is the above supposed to mean?
 
> 
> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
> 
> acl purge method PURGE
> acl clientServers src 10.112.4.54
> http_access allow purge clientServers
> http_access deny purge
> 
> acl gat method GET
> acl clientS src 10.112.4.54 10.113.10.190
> http_access allow gat clientS
> #http_access deny gat
 
The localnet ACL defines 10.*/8 as allowed and your rules below specify 
that all localnet traffic is allowed.
 
So the above four lines of config seem pointless.
 
 
You have configured the machines 10.112.4.54 and 10.113.10.190 as your 
cache_peer servers. So why are they listed as "src" ?
 
In a reverse-proxy "src" is the IP of a client requesting a URL.
 
"dst" is the destination server - as determined by DNS records for the 
URL domain being fetched. In a reverse-proxy those DNS records should 
hold the proxies own IP address. So dst-IP is rarely ever useful and are 
downright dangerous to make use of in the reverse-proxy.
 
 
 
> 
> acl SSL_ports port 443
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl Safe_ports port 3130        # icp
> acl Safe_ports port 3128
> acl CONNECT method CONNECT
> 
> http_access deny !Safe_ports
> 
> http_access deny CONNECT !SSL_ports
> 
> http_access allow localhost manager
> http_access deny manager
> 
 
As the default config file says:
 
"
#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#
"
 
 
> http_access allow localnet
> http_access allow localhost
> 
> http_port 80 accel defaultsite=youlun.lvmama.com no-vhost
> 
> cache_dir aufs /var/spool/squid 8198 16 256
> cache_mem 5120 MB
> cache_swap_low 90
> cache_swap_high 95
> cache_mgr zhongzhe at lvmama.com
> 
> visible_hostname cache190
> 
 
So the domain name Squid announces to your clients is "cache190" as in 
http://cache190/ship_front/youlun/1012487.
 
 
> coredump_dir  /var/spool/squid
> 
> via off
 
At least while debugging peering issues set "via on". Only turn it off 
if you really have to and *after* you have a fully working proxy hierarchy.
 
 
> maximum_object_size 500 KB
> 
> icp_port 3130
> icp_access allow all
> icp_query_timeout 2000
> 
> cache_peer 10.112.4.54 parent 8090 0 no-query originserver name=youlun
> acl mysites dstdomain youlun.lvmama.com
> http_access allow mysites
> cache_peer_access youlun allow all
> cache_peer_access youlun deny all
 
The default for cache_peer_access is to allow. No need to specify that 
"allow all". What you need to do to allow everything to reach that peer 
server is *not* specify "deny all".
 
Though the normal thing is to use an ACL (eg your "mysites" one) to 
allow the domains an origin server is known to supply and to deny other 
things. Since it is not even worth trying that peer for things it is not 
known to be capable of serving.
 
So:
   http_access allow mysites
   cache_peer_access youlun allow mysites
   cache_peer_access youlun deny all
 
 
Also be aware that all of this peer and http_access config needs to be 
located up where it says " INSERT YOUR OWN RULE(S) HERE " etc.
 
 
 
> 
> refresh_pattern -i .*/youlun/([0-9]+) 1440 100% 10080 ignore-no-store ignore-must-revalidate store-stale ignore-reload
> 
 
Why? if your server is not producing correct cacheability headers then 
everyone trying to use your site will be having problems. "Fixing" it 
for only your proxy by ignoring required things is the worst possible 
action to take.
 
Your proxy is a reverse-proxy (aka CDN), it advertises its Surrogate 
abilities to the origin server so your proxy cache can be given custom 
values different from the general public. If you need
 
 
> refresh_pattern ^ftp:          1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> 
> cache_log /var/log/squid/cache.log
> cache_access_log /var/log/squid/access.log
 
The directive name is "access_log"
 
> cache_store_log /var/log/squid/store.log
> 
> log_icp_queries off
> 
> http_access allow all
 
Do not do that "allow all".
 
> http_access deny all
> 
 
 
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171214/00ddc906/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec 14 04:02:11 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Dec 2017 17:02:11 +1300
Subject: [squid-users] Doesnt authorize with Squid
In-Reply-To: <BN6PR15MB12037A3BA3D76C849C281408E3350@BN6PR15MB1203.namprd15.prod.outlook.com>
References: <BN6PR15MB12037A3BA3D76C849C281408E3350@BN6PR15MB1203.namprd15.prod.outlook.com>
Message-ID: <cb86f1ba-926c-e712-2c4e-ab16503f8d66@treenet.co.nz>

On 14/12/17 06:03, Edwin Quijada wrote:
> Hi!
> I have installed a debian server with Squid3 to authorize surf for 
> internet. My problem is when I get the screen for credentials I put my 
> rigth credentials and always I get denied.
> 

Is this "screen" a popup box or an actual visual page displayed?
HTTP auth popups should be relatively small and grey outlined, asking 
only for username and password with the proxy Realm string as the title 
or initial text.


> I have used a different helpers for authentication and I did my own using C
> 
> but the authorization is continue
> 

Whether to show the popup is a Browser decision. Properly working you 
should only ever see 0 or 1 of them.

> 
> There is a way to see or debug the autorization process?
> 

The available helpers should all provide a -d command line option for 
testing and troubleshooting. You can configure that in their 'auth_param 
... program' squid.conf line. Squid logs the debug info from helpers to 
cache.log.

Your custom helper is up to you how it gets debugged. Anything it sends 
to stderr is sent to cache.log so you can use that instead of having to 
worry about custom log files yourself.


> 
> It is the squid.conf. The helper just takes the values but always 
> autorize, Always print OK
> 
> 
> #Recommended minimum configuration:
> http_port 3128
> cache_dir ufs /var/spool/squid3 2048 16 256
> maximum_object_size 100 MB
> cache_swap_low 90
> cache_swap_high 95
> 
> #--------------- Reglas de Autorizacion -------------
> auth_param basic program?? /root/squid_helper3
> auth_param basic children 20
> auth_param basic casesensitive off
> auth_param basic realm Proxy Test --> Usuario Y Clave
> auth_param basic credentialsttl 5 hours

That credentialsttl setting is how long Squid remembers helper responses 
about credentials. Once credentials are given an OK/ERR result no 
further changes to the auth system for that credential pair (eg, user 
account addition, removal or password changes) are noticed by Squid 
until that TTL expires and a fresh lookup performed.

This is a value you should tune to be short, but long enough not to 
overload the helpers and slow your clients traffic down at peak times.

For initial testing of auth leave it *very* short until you are sure the 
auth is working okay. Then test longer timings until you are happy with 
the performance vs security tradeoff.


> #----------------------------------------------------
> #
> acl AuthenticatedUsers proxy_auth REQUIRED
> http_access allow AuthenticatedUsers

The best way to perform auth is to deny non-authenticated users. That 
includes the ones with *invalid* credentials (attackers or forgotten 
passwords etc.).

Then further access controls can rely on credentials being both present 
and valid and do allows for various reasons. For example; client being 
on the LAN / localnet.


> #-------------------- ACL Puertos --------------------
> acl SSL_ports port 443
> acl Safe_ports port 80????????? # http
> acl Safe_ports port 21????????? # ftp
> acl Safe_ports port 443???????? # https
> acl Safe_ports port 70????????? # gopher
> acl Safe_ports port 210???????? # wais
> acl Safe_ports port 1025-65535? # unregistered ports
> acl Safe_ports port 280???????? # http-mgmt
> acl Safe_ports port 488???????? # gss-http
> acl Safe_ports port 591???????? # filemaker
> acl Safe_ports port 777???????? # multiling http
> 
> acl CONNECT method CONNECT
> 
> #---------------------- HTTP ACCES DEFAULT-------------
> #http_access allow manager localhost
> #http_access deny manager
> http_access deny !Safe_ports
> 
> Any help ?
> 

Your custom rules should all be down below the !Safe_Ports and "CONNECT 
!SSL_Ports" protections. So attacks using those DoS methods cannot 
overload your auth system and more complicated ACL things.


While the http_access rules are not great they should still have 
"worked" for the request(s) after you entered the credentials.

What I'd do along with enabling debug in the auth helper is to also 
configure "debug_options 11,2" in squid.conf to get a trace of whet the 
HTTP messages contain. That may show some clues about where the problem 
is starting.

Amos


From squid3 at treenet.co.nz  Thu Dec 14 05:31:07 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Dec 2017 18:31:07 +1300
Subject: [squid-users] TCP_MISS_ABORTED
In-Reply-To: <2017121411483493862453@lvmama.com>
References: <20171213152306992405165@lvmama.com>
 <6573abf7-b7bb-bfbb-a651-b3a92e8c2507@treenet.co.nz>
 <2017121411483493862453@lvmama.com>
Message-ID: <e15b4e5b-e49a-398b-caa9-c03c2215ffa5@treenet.co.nz>

On 14/12/17 16:48, zhongzhe at lvmama.com wrote:
> Hi, Amos
>  ? ? Thanks a lot for your reply. ?In my conf, squid is not only a 
> reverse-proxy server, but also a cache server. And that is important to 
> me.

Sure. Those two functions of proxying are independent of each other.

* Anything going through a caching proxy is cached regardless of how it 
arrived or where it will end up in the network.

* The reverse-proxy is all about how traffic is routed when it goes over 
network connections.


One thing to be aware of when testing with a Browser is that Browsers 
also cache, and they usually get the same instructions as the proxy gets 
and the can lead to an illusion in the visible behaviour:

It goes like this:

1)  When the browser makes its first request, the object is not stored 
in either browser nor proxy caches. So they both MISS and the 
transaction fetches from the origin server.

2) when the object eventually becomes stale in the Browser cache is 
fetches or revalidates against teh proxy copy.

*** Since the test Browser and the proxy got the content at identical 
times it also becomes stale in the proxy cache at the same time it went 
stale in the browser cache.

3) the proxy content (now also stale) gets MISS or REFRESH since the 
origin server needs to be contacted again.

As you can see the proxy *is* caching between steps #1 and #2. But you 
may not ever see it HIT in the testing unless you are careful to clear 
the browser cache between every test lookup so that the browser and 
proxy cache contents becomes different.

In production this is not usually a problem since multiple users cause 
the proxy content to be updated irregularly. But it can still happen in 
some situations with low number of clients all with very different 
browsing habits.




> ?In fact , it does't normally for my product environment. 
> 10.112.4.54 is the apache server(been agent by squid) , and my request 
> is also sent by it(such as browser request and mimetic of httpclient 
> request by java).
> 10.113.10.191 is the peer squid server, And is closed 
> now. 10.113.10.190, as you see,?is the
> current reverse-proxy server.
>  ? ? Whole proceess like this:
> 10.112.4.54(browser) _send request_//10.113.10.190 _if not cached, 

Small mistake there. Browser uses DNS to find out where 
yourdomain.example.com IP address is - DNS tells it 10.113.10.190.
  The Browser contacts 10.113.10.190 and asks for 
http://youlun.lvmama.com/something.

The proxy receives that URL and sees the dstdomain == 
"youlun.lvmama.com" as a reason to send it on to the origin server OR 
the cache. Whichever is faster - local RAM and disk by definition being 
faster to access than networking to another machine.

NP: the above is important for your requested process. Since it should 
now be clear that a reverse-proxy http_access permissions do not need 
anything about who the client is (src-IP), or where the domain is hosted 
(dst-IP).


> forward the requset to apache server_10.112.4.54(apache server)_return 
> the response page to browser_ 10.112.4.54(browser)
> _if cached, return the page_10.112.4.54(browser)

I see. In which case there are more problems with your config than I 
initially thought.

> 
>  >? ? ? below is my squid.conf
>  > acl?gsrc?src?10.112.4.54?10.113.10.191
>  > acl?gdst?dst?10.112.4.54?10.113.10.191
>  > http_access?allow?gsrc
>  > http_access?allow?gdst
>  >>What is the above supposed to mean?

For your desired process. Do not do the above at all. Remove them 
completely.

> 
>  >
>  > acl?localnet?src?10.0.0.0/8?????#?RFC1918?possible?internal?network
>  > acl?localnet?src?172.16.0.0/12??#?RFC1918?possible?internal?network
>  > acl?localnet?src?192.168.0.0/16?#?RFC1918?possible?internal?network
>  > acl?localnet?src?fc00::/7???????#?RFC?4193?local?private?network?range
>  > 
> acl?localnet?src?fe80::/10??????#?RFC?4291?link-local?(directly?plugged)?machines
>  >
>  > acl?purge?method?PURGE
>  > acl?clientServers?src?10.112.4.54
>  > http_access?allow?purge?clientServers
>  > http_access?deny?purge
>  >
>  > acl?gat?method?GET
>  > acl?clientS?src?10.112.4.54?10.113.10.190
>  > http_access?allow?gat?clientS
>  > #http_access?deny?gat
>  >>The localnet ACL defines 10.*/8 as allowed and your rules below specify
>  >>that all localnet traffic is allowed.
>  >>
>  >>So the above four lines of config seem pointless.
>>>
>>>You have configured the machines 10.112.4.54 and 10.113.10.190 as your
>>>cache_peer servers. So why are they listed as "src" ?
>>>
>>>In a reverse-proxy "src" is the IP of a client requesting a URL.
>>>
>>>"dst" is the destination server - as determined by DNS records for the
>>>URL domain being fetched. In a reverse-proxy those DNS records should
>>>hold the proxies own IP address. So dst-IP is rarely ever useful and are
>>>downright dangerous to make use of in the reverse-proxy.
> 
> ICP requset cannot sent to peer server at first. So I add it to try to 
> solve it .
> 

The above has nothing to do with ICP. It is some ACLs being used to 
control *HTTP* request messages arriving into the proxy. It is deciding 
whether Squid processes that request *at all*, or rejects the client 
with a 403.

For your desired process. Do not do those gat or clientS ACL checks at 
all. Remove them completely and the http_access lines they are used in.



> 
>  >
>  > acl?SSL_ports?port?443
>  > acl?Safe_ports?port?80??????????#?http
>  > acl?Safe_ports?port?21??????????#?ftp
>  > acl?Safe_ports?port?443?????????#?https
>  > acl?Safe_ports?port?70??????????#?gopher
>  > acl?Safe_ports?port?210?????????#?wais
>  > acl?Safe_ports?port?1025-65535??#?unregistered?ports
>  > acl?Safe_ports?port?280?????????#?http-mgmt
>  > acl?Safe_ports?port?488?????????#?gss-http
>  > acl?Safe_ports?port?591?????????#?filemaker
>  > acl?Safe_ports?port?777?????????#?multiling?http
>  > acl?Safe_ports?port?3130????????#?icp
>  > acl?Safe_ports?port?3128
>  > acl?CONNECT?method?CONNECT
>  >
>  > http_access?deny?!Safe_ports
>  >
>  > http_access?deny?CONNECT?!SSL_ports
>  >
>  > http_access?allow?localhost?manager
>  > http_access?deny?manager
>  >
> 
> As the default config file says:
> "
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> "
> 
> thanks a lot, I'll delete the needless port info.
> 

Port info? I did not mention removing any of that.

Whether you should edit Safe_ports or SSL_ports values is determined by 
whether you want the proxy to be exclusively a reverse-proxy (with 
caching), or to be both a reverse-proxy AND a forward/explicit proxy 
(both with caching).

TO be exclusively a reverse-proxy it is find to remove all by port 80 
(and maybe 443) ports from those ACL definitions.

To retain forward-propxy behaviour you do need the default config lines. 
And may even have to add extra ports depending on what the Browsers and 
clients need access to.

What I was trying to point out was that your custom http_access rules 
should all be there. Maybe with the extra custom things like your 
cache_peer_* rules.


For your desired process. The only thing you need to have is the 
cache_peer* and http_access reverse-proxy lines right here in this 
potsition of squid.conf. That is *all* of it.


> 
>  > http_access?allow?localnet
>  > http_access?allow?localhost
>  >
>  > http_port?80?accel?defaultsite=youlun.lvmama.com?no-vhost
>  >
>  > cache_dir?aufs?/var/spool/squid?8198?16?256
>  > cache_mem?5120?MB
>  > cache_swap_low?90
>  > cache_swap_high?95
>  > cache_mgr?zhongzhe at lvmama.com
>  >
>  > visible_hostname?cache190
>  >
> 
> So the domain name Squid announces to your clients is "cache190" as in
> http://cache190/ship_front/youlun/1012487.
> 
> I think my domain name is youlun.lvmama.com. cache190 is just a 
> individual name to distinguish with squid server 10.113.10.191.
> 

Fine, but it should in any case be a FQDN which can be publicly resolved 
by a lookup in DNS. Current Squid versions should all be able to 
auto-detect what their machines unique hostname is. So usually no need 
to set these at all.

The visible_hostname (note the word "visible") is what Squid places in 
any URLs it has to auto-generate and send to clients. Since this is a 
reverse-proxy it is sort of best to set the *public* name to be the 
served domain name (eg "visible_hostname youlun.lvmama.com") and use 
unique_hostname to set the proxies unique FQDN.


> 
>  > coredump_dir??/var/spool/squid
>  >
>  > via?off
> At least while debugging peering issues set "via on". Only turn it off
> if you really have to and *after* you have a fully working proxy hierarchy.
> 
> agree with your.
> 
> 
>  > maximum_object_size?500?KB
>  >
>  > icp_port?3130
>  > icp_access?allow?all
>  > icp_query_timeout?2000
>  >
>  > cache_peer?10.112.4.54?parent?8090?0?no-query?originserver?name=youlun
>  > acl?mysites?dstdomain?youlun.lvmama.com
>  > http_access?allow?mysites
>  > cache_peer_access?youlun?allow?all
>  > cache_peer_access?youlun?deny?all
> The default for cache_peer_access is to allow. No need to specify that
> "allow all". What you need to do to allow everything to reach that peer
> server is *not* specify "deny all".
> Though the normal thing is to use an ACL (eg your "mysites" one) to
> allow the domains an origin server is known to supply and to deny other
> things. Since it is not even worth trying that peer for things it is not
> known to be capable of serving.
> So:
>  ?? http_access allow mysites
>  ?? cache_peer_access youlun allow mysites
>  ?? cache_peer_access youlun deny all
> Also be aware that all of this peer and http_access config needs to be
> located up where it says " INSERT YOUR OWN RULE(S) HERE " etc.
> Thanks , I had delete it.
> 
>  >
>  > 
> refresh_pattern?-i?.*/youlun/([0-9]+)?1440?100%?10080?ignore-no-store?ignore-must-revalidate?store-stale?ignore-reload
>  >
> Why? if your server is not producing correct cacheability headers then
> everyone trying to use your site will be having problems. "Fixing" it
> for only your proxy by ignoring required things is the worst possible
> action to take.
> Your proxy is a reverse-proxy (aka CDN), it advertises its Surrogate
> abilities to the origin server so your proxy cache can be given custom
> values different from the general public. If you need
> 
> I want to squid server response a cache page to the request if it's exit .

Squid caches by default the refresh_pattern below indicate 4320 minutes 
(1 week) storage time _unless_ the server tells Squid anything more 
specific (can be longer or shorter).

That said current Squid cache in memory instead of on-disk unless you 
configure a cache_dir line to say where that disk cache should be put.



Amos


From squid3 at treenet.co.nz  Thu Dec 14 05:37:08 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 14 Dec 2017 18:37:08 +1300
Subject: [squid-users] Some things in the log
In-Reply-To: <1513172794872-0.post@n4.nabble.com>
References: <1513172794872-0.post@n4.nabble.com>
Message-ID: <00b2f0b3-05d7-e836-deca-cf0d18b94631@treenet.co.nz>

On 14/12/17 02:46, erdosain9 wrote:
> Hi to all.
> Im having some things in the log.
> Like this:
> 
> -Vary object loop

When Squid looked up a URL in cache it finds that there are Vary headers 
to be accounted for in the storage key/ID. Doing the appropriate changes 
to add that Vary info Squid again finds that there are *different* Vary 
changes to do contradictory to the initial ones.

Cache key collisions happen sometimes and objects get replaced without 
affecting the Vary objects referencing them. So it can happen 
occasionally just from normal operations. But constant repeating of that 
message is a problem and IIRC there are some bugs leading to that which 
are not yet resolved.

> -Could not parse headers from on disk object

Something has mangled up the HTTP message headers in the disk copy of a 
cached object.

IIRC This can happen if you are using rock cache_dir type and the 
message headers exceed a single database cell/slot size.

But for UFS/AUFS/diskd caches it tends to only happen due to HDD failure 
or some other process fiddling with the disk storage.


> -varyEvaluateMatch: Oops
> 

In all of the above cases Squid handles the problem by ignoring the 
cache contents and fetching fresh data from online. Which replaces the 
broken cache contents so that particular instance of the problem(s) 
disappear immediately.


> ipcacheParse No Address records in response to (i supposed this is not a
> problem)

It is a minor problem. A domain name required to service some 
transaction is not correctly setup in DNS. But there is likely nothing 
you can do about it. Squid reports this type of thing so you can see 
what happened if any clients complain, and/or report the problem to 
someone who may be able to fix it properly.


FYI: A quick check of the domains your log snippet mentions shows they 
mostly have CNAME references pointing at CloudFlare server aliases that 
do not exist. Or similar for other CDN services. So Squid is quite 
correct - there are zero IP addresses for those domain names.

The DNS is incorrect because a CNAME should not exist pointing at 
non-existent server name. The domain owner need to fix that so services 
like Squid get a proper NXDOMAIN result instead of a "success" CNAME 
with zero IPs.

Also, why a client is trying to fetch URLs from a non-existent server is 
probably a good thing to look into if you want to investigate further.


> 2017/12/12 16:09:54 kid1| Error negotiating SSL on FD 701:
> error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
> failed (1/-1/0)

Exactly what it says. The TLS/SSL certificate presented by a server 
could not be validated. It could be *actually* invalid (that happens 
rather a lot) or just missing some issuer cert - an intermediate CA cert 
from the handshake or root CA from your system trusted CA set.

Seeing how often these cert messages are occuring if you have a Squid 
older than Squid-4 latest beta you might want to try that release out 
and see if these disappear or at least reduce significantly. It can 
auto-download those missing intermediate certs instead of erroring out.

NP: that may also reduce the loudness of those no-IPs messages.



Amos


From mysql.jorge at decimal.pt  Thu Dec 14 10:21:52 2017
From: mysql.jorge at decimal.pt (Jorge Bastos)
Date: Thu, 14 Dec 2017 10:21:52 -0000
Subject: [squid-users] Website bypass with always-direct
In-Reply-To: <0f86de81-76eb-2a4e-ddca-483f457f643a@measurement-factory.com>
References: <05b201d37432$d0a22370$71e66a50$@decimal.pt>	<57b6df0b-dc0b-f3a6-ce42-8c366770e29c@treenet.co.nz>	<700896e3a372e0621037e3cd57201108@decimal.pt>
 <0f86de81-76eb-2a4e-ddca-483f457f643a@measurement-factory.com>
Message-ID: <!&!AAAAAAAAAAAuAAAAAAAAAEyFxthbLrRGtNvSuZJnoIoBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAA2AR/dJWpPSL/Z6HswVAx/AQAAAAA=@decimal.pt>

Alex,

> Ok, so what would be the directive to allow what i want to achieve?


What do you want to achieve?

Earlier, you implied that you do not want to see a request in Squid logs. As
Amos have said, Squid cannot "unsee" the transaction: Once the transaction
reaches Squid, Squid will handle it (forward, block, delay, mangle, log,
etc.). If you want Squid to not see a transaction, then all the solutions
will be outside of Squid and its directives. Please explain what you want
with this fact in mind.

It's what I want,
I thought squid would be able to do that bypass!
I have to do it with iptables then,



From m_zouhairy at skno.by  Thu Dec 14 10:30:57 2017
From: m_zouhairy at skno.by (Vacheslav)
Date: Thu, 14 Dec 2017 13:30:57 +0300
Subject: [squid-users] Website bypass with always-direct
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAEyFxthbLrRGtNvSuZJnoIoBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAA2AR/dJWpPSL/Z6HswVAx/AQAAAAA=@decimal.pt>
References: <05b201d37432$d0a22370$71e66a50$@decimal.pt>	<57b6df0b-dc0b-f3a6-ce42-8c366770e29c@treenet.co.nz>	<700896e3a372e0621037e3cd57201108@decimal.pt>
 <0f86de81-76eb-2a4e-ddca-483f457f643a@measurement-factory.com>
 <!&!AAAAAAAAAAAuAAAAAAAAAEyFxthbLrRGtNvSuZJnoIoBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAA2AR/dJWpPSL/Z6HswVAx/AQAAAAA=@decimal.pt>
Message-ID: <008701d374c6$a12305d0$e3691170$@skno.by>

What if we think from the heart?

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Jorge Bastos
Sent: Thursday, December 14, 2017 1:22 PM
To: 'Alex Rousskov' <rousskov at measurement-factory.com>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Website bypass with always-direct

Alex,

> Ok, so what would be the directive to allow what i want to achieve?


What do you want to achieve?

Earlier, you implied that you do not want to see a request in Squid logs. As Amos have said, Squid cannot "unsee" the transaction: Once the transaction reaches Squid, Squid will handle it (forward, block, delay, mangle, log, etc.). If you want Squid to not see a transaction, then all the solutions will be outside of Squid and its directives. Please explain what you want with this fact in mind.

It's what I want,
I thought squid would be able to do that bypass!
I have to do it with iptables then,

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users




From Antony.Stone at squid.open.source.it  Thu Dec 14 11:07:58 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 14 Dec 2017 12:07:58 +0100
Subject: [squid-users] Website bypass with always-direct
In-Reply-To: <!&!AAAAAAAAAAAuAAAAAAAAAEyFxthbLrRGtNvSuZJnoIoBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAA2AR/dJWpPSL/Z6HswVAx/AQAAAAA=@decimal.pt>
References: <05b201d37432$d0a22370$71e66a50$@decimal.pt>
 <0f86de81-76eb-2a4e-ddca-483f457f643a@measurement-factory.com>
 <!&!AAAAAAAAAAAuAAAAAAAAAEyFxthbLrRGtNvSuZJnoIoBAMO2jhD3dRHOtM0AqgC7tuYAAAAAAA4AABAAAAA2AR/dJWpPSL/Z6HswVAx/AQAAAAA=@decimal.pt>
Message-ID: <201712141207.58378.Antony.Stone@squid.open.source.it>

On Thursday 14 December 2017 at 11:21:52, Jorge Bastos wrote:

> Alex,
> 
> > > Ok, so what would be the directive to allow what i want to achieve?
> >
> > What do you want to achieve?
> >
> > Earlier, you implied that you do not want to see a request in Squid logs.
> > As Amos have said, Squid cannot "unsee" the transaction: Once the
> > transaction reaches Squid, Squid will handle it (forward, block, delay,
> > mangle, log, etc.). If you want Squid to not see a transaction, then all
> > the solutions will be outside of Squid and its directives. Please explain
> > what you want with this fact in mind.
> 
> It's what I want,
> I thought squid would be able to do that bypass!
> I have to do it with iptables then,

1. What type of accesses do you want to avoid having in the Squid logs (and 
incidentally, why - what's wrong with these requests going through Squid)?

2. The only way I can think of you being able to do this with Squid would be 
to set up a hierarchy - one "front-end" Squid server which does no caching 
(I'm assuming this is part of what you want to achieve), and then either does 
"direct" accesses to the origin server (for the requests you don't want Squid 
to process), or "parent" accesses to the "back-end" caching Squid server, for 
the ones you are happy to go through Squid.  You then regard the "back-end" 
server as your "real Squid server" and treat the "front-end" machine as just a 
way of routing the requests according to your rules.

3. Is the thing you are really trying to achieve "not having the requests show 
up in Squid's log files" or "not being processed by Squid"?  What's the reason 
for whichever one this is - what is the problem with the way things are 
working now which you are trying to solve?


Antony.

-- 
Python is executable pseudocode.
Perl is executable line noise.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From ppmartell at eleka.co.cu  Thu Dec 14 13:52:08 2017
From: ppmartell at eleka.co.cu (Ing. Pedro Pablo Delgado Martell)
Date: Thu, 14 Dec 2017 08:52:08 -0500
Subject: [squid-users] Secure Squid authentication
Message-ID: <7bae00fd-0b09-ae48-53d3-df2ae6ac25ac@eleka.co.cu>

The place I was working before this one was a center with several Wi-Fi 
hotspots. I didn't designed the structure of the network nor had the 
privileges to change core functionalities on the network. Squid was 
running as a web proxy server receiving all the traffic coming from the 
Wi-Fi hotspots to the internet. When I started working there I was asked 
to do a assessment job and I realized that authentication between user 
and squid was non-secure (*plaintext*). This is a critical secure breach 
because with a network scanner as wireshark you could easily get users 
password. On a totally wired network this could be harder to achive but 
on Wi-Fi hotspots you could get all the data running your device in 
monitor mode. My question is:

- ?Is there any how to tutorial about implementing SSL authentication on 
squid? I guess this already has been done so a link should be enough in 
order to save you guys some time.

- Second and less important, even off-topic. Putting squid out of the 
ecuation, is there another way to secure the data being transmitted 
between user device and Wi-Fi hotspot?

Thanks in advance!



From squid at bloms.de  Fri Dec 15 10:53:46 2017
From: squid at bloms.de (Dieter Bloms)
Date: Fri, 15 Dec 2017 11:53:46 +0100
Subject: [squid-users] native ftp and proxy authentication
Message-ID: <20171215105346.qeixjtinnyapojog@bloms.de>

Hello,

I use the native ftp support of squid-4.0.22 and it works well without proxy
authentication.
I want to enable the proxy authentication, but don't know how to login
to the proxy with the native ftp client.

Without proxy authentication the string ftpuser at ftpserver works fine.
When I enable proxy-authentication, then I have to enter the proxy
credentials, but don't know how to do it.
I tried "proxyuser at ftpuser@ftpserver" for username, but it doesn't work.

Is there any support for native ftp protocol and proxy authentication ?


-- 
Regards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
>From field.


From rousskov at measurement-factory.com  Fri Dec 15 16:07:50 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 15 Dec 2017 09:07:50 -0700
Subject: [squid-users] native ftp and proxy authentication
In-Reply-To: <20171215105346.qeixjtinnyapojog@bloms.de>
References: <20171215105346.qeixjtinnyapojog@bloms.de>
Message-ID: <70a82422-3e27-d6a6-8dfa-1c24cbac22a3@measurement-factory.com>

On 12/15/2017 03:53 AM, Dieter Bloms wrote:

> I use the native ftp support of squid-4.0.22 and it works well without proxy
> authentication.

> I want to enable the proxy authentication, but don't know how to login
> to the proxy with the native ftp client.

Does your native FTP client support FTP proxy authentication?


> Without proxy authentication the string ftpuser at ftpserver works fine.
> When I enable proxy-authentication, then I have to enter the proxy
> credentials, but don't know how to do it.

"How to give FTP client credentials for proxy authentication" seems like
a question for your FTP client support forum, not squid-users. We do not
even know what FTP client you use. Did I misunderstand the question?


> I tried "proxyuser at ftpuser@ftpserver" for username, but it doesn't work.

IIRC, proxyuser at ftpuser@ftpserver tells Squid to go to ftpserver using
proxyuser at ftpuser as the user name/login.


> Is there any support for native ftp protocol and proxy authentication ?

I doubt there is native FTP proxy authentication support in Squid, but
to be sure, it would be great to know how that works from the FTP client
point of view. In other words, when an FTP client supports FTP proxy
authentication, what does it send to the FTP proxy (i.e., to Squid)?


Cheers,

Alex.


From phackmann at gmail.com  Fri Dec 15 21:23:55 2017
From: phackmann at gmail.com (Paul Hackmann)
Date: Fri, 15 Dec 2017 15:23:55 -0600
Subject: [squid-users] squid asking for authentication repeatedly
In-Reply-To: <d51393d6-c991-b131-9881-97eafbb3f504@treenet.co.nz>
References: <CADQL5rOea3c5RbvdrRtyB7dYpEsPmUfmu8XDjfOXApRwUTAYhw@mail.gmail.com>
 <3eb1226d-9dc8-33e9-0495-8ba902747596@treenet.co.nz>
 <CADQL5rN5md1g9_-BrGz4AybZ79dNm8GYHB_u=VBmunQQ9EVL3w@mail.gmail.com>
 <37faddcb-b809-9d30-5fd5-503b64f529f8@treenet.co.nz>
 <CADQL5rOVmb0AwKK-+E4vsRHx1Tbo2oOkhae7V0k=T9q_ZEbgFQ@mail.gmail.com>
 <d51393d6-c991-b131-9881-97eafbb3f504@treenet.co.nz>
Message-ID: <CADQL5rPY7jYt3jZfn1cDc3AgQQdtgPrswTTXxiXvt-pWMCnRqw@mail.gmail.com>

Amos,

Understood.  I think it is all working correctly now.  Thank you!

PH

On Wed, Dec 13, 2017 at 7:35 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 14/12/17 11:32, Paul Hackmann wrote:
>
>> Amos,
>>
>> I will do an update to the most recent version and see if that helps.  It
>> was one of those situations where if it ain't broke, don't fix it.  And up
>> until now, it has worked very well.
>>
>> You are right, I had brain fade about port 4120.  It should NOT ask for
>> authentication ever, and only connect to whitelisted sites, which is what I
>> want.
>>
>> I've made the changes you recommended to the conf file.  So far,
>> everything seems to be working as I expect it to.  Thank you!
>>
>> One more question if you don't mind.  I am trying to add some ip
>> addresses as whitelisted for port 4120.  I guess I can't add those to the
>> whitelist file, because it's formatting doesn't work with IP addresses?
>>
>
> Sort of. dstdomain can accept IPs for matching against raw-IP text strings
> in URLs where domain should have been. But does not do ranges like you need
> there.
>
> So yes dst is the one to use there.
>
> However, be aware that it will match if *any* IPs for the domain being
> fetched is in your whitelist set. It has nothing to do with whether that
> matching dst-IP is actually used by Squid on the server connection.
> To workaround that is where explicitly configuring "never_direct allow
> all" comes in handy.
>
>
>   I read that you can add them into the conf file.  I've created the
>> following acl line:
>>
>> acl 8x8 dst 8.5.248.0/23 8.28.0.0/22 63.209.12.0/24 162.221.236.0/23
>> 162.221.238.0/23 192.84.16.0/22
>>
>> and I tried to add 8x8 to the the http_access line:
>>
>> http_access allow whitelist 8x8
>>
>> but when I did that, the 4120 port started asking for authentication,
>> which is wrong. Can you tell me how to open those ip address ranges for
>> port 4120?
>>
>>
> Your use of http_access is not quite right.
>
> see <https://wiki.squid-cache.org/SquidFaq/SquidAcl#Common_Mistakes>
>
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171215/74656c59/attachment.htm>

From squid at bloms.de  Sat Dec 16 20:02:41 2017
From: squid at bloms.de (Dieter Bloms)
Date: Sat, 16 Dec 2017 21:02:41 +0100
Subject: [squid-users] native ftp and proxy authentication
In-Reply-To: <70a82422-3e27-d6a6-8dfa-1c24cbac22a3@measurement-factory.com>
References: <20171215105346.qeixjtinnyapojog@bloms.de>
 <70a82422-3e27-d6a6-8dfa-1c24cbac22a3@measurement-factory.com>
Message-ID: <20171216200241.gnc7j4k36xofbtkv@bloms.de>

Hello Alex,

thank you for your answer!

On Fri, Dec 15, Alex Rousskov wrote:

> On 12/15/2017 03:53 AM, Dieter Bloms wrote:
> 
> > I use the native ftp support of squid-4.0.22 and it works well without proxy
> > authentication.
> 
> > I want to enable the proxy authentication, but don't know how to login
> > to the proxy with the native ftp client.
> 
> Does your native FTP client support FTP proxy authentication?

No it doesn't.
So it would be nice to have a solution, which works with every ftp
client.
I think about an option in squid.conf where I can configure the login
schema, like proxyuser at ftpuser@ftpserver for the user login and
proxypass at ftppass for the password.

> > Without proxy authentication the string ftpuser at ftpserver works fine.
> > When I enable proxy-authentication, then I have to enter the proxy
> > credentials, but don't know how to do it.
> 
> "How to give FTP client credentials for proxy authentication" seems like
> a question for your FTP client support forum, not squid-users. We do not
> even know what FTP client you use. Did I misunderstand the question?

I want a genric solution, so that every ftp client can use the ftp proxy
support of squid.
At the moment I have to use a commercial ftp client which doesn't
have any proxy option.

> > I tried "proxyuser at ftpuser@ftpserver" for username, but it doesn't work.
> 
> IIRC, proxyuser at ftpuser@ftpserver tells Squid to go to ftpserver using
> proxyuser at ftpuser as the user name/login.

Yes, and it would be nice to configure squid, so squid extract the proxy
authentication from this string.

> > Is there any support for native ftp protocol and proxy authentication ?
> 
> I doubt there is native FTP proxy authentication support in Squid, but
> to be sure, it would be great to know how that works from the FTP client
> point of view. In other words, when an FTP client supports FTP proxy
> authentication, what does it send to the FTP proxy (i.e., to Squid)?

It doesn't have proxy support, it only sends the USER and PASS string.



-- 
Regards

  Dieter

--
I do not get viruses because I do not use MS software.
If you use Outlook then please do not put my email address in your
address-book so that WHEN you get a virus it won't use my address in the
>From field.


From nick-liste at posteo.eu  Mon Dec 18 07:07:11 2017
From: nick-liste at posteo.eu (Nicola Ferrari (#554252))
Date: Mon, 18 Dec 2017 08:07:11 +0100
Subject: [squid-users] Secure Squid authentication
In-Reply-To: <7bae00fd-0b09-ae48-53d3-df2ae6ac25ac@eleka.co.cu>
References: <7bae00fd-0b09-ae48-53d3-df2ae6ac25ac@eleka.co.cu>
Message-ID: <p17pb4$lp6$1@blaine.gmane.org>

Hi!

You may find this recent post useful:
http://lists.squid-cache.org/pipermail/squid-users/2017-December/017060.html

Cheers,
N

-- 
+---------------------+
| Linux User  #554252 |
+---------------------+



From rentorbuy at yahoo.com  Mon Dec 18 08:02:49 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Mon, 18 Dec 2017 08:02:49 +0000 (UTC)
Subject: [squid-users] TCP out of memory
References: <122875663.418224.1513584169532.ref@mail.yahoo.com>
Message-ID: <122875663.418224.1513584169532@mail.yahoo.com>

Hi,

I need to restart Squid once a week because I see "TCP out of memory" messages in syslog.

I see lots of open file descriptors of type "127.0.0.1:1344".

There could be an issue with the c-icap service.

As suggested previously, I dumped a packet trace here:

https://drive.google.com/file/d/1qCkH6YYa7fgeYzm-AoJEpXTDVpzILCQ9/view?usp=sharing

Can anyone please take a look at it? I'm trying to determine whether c-icap is closing connections properly.
Maybe the dump's time range is too short to see anything useful?
I also tried looking at the c-icap logs, but unfortunately I don't see anything (or I don't know how to interpret them correctly).


Vieri


From squid3 at treenet.co.nz  Mon Dec 18 08:56:06 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 18 Dec 2017 21:56:06 +1300
Subject: [squid-users] TCP out of memory
In-Reply-To: <122875663.418224.1513584169532@mail.yahoo.com>
References: <122875663.418224.1513584169532.ref@mail.yahoo.com>
 <122875663.418224.1513584169532@mail.yahoo.com>
Message-ID: <a77fe8ea-6fa4-b0bf-fbf1-44a49366c77a@treenet.co.nz>

On 18/12/17 21:02, Vieri wrote:
> Hi,
> 
> I need to restart Squid once a week because I see "TCP out of memory" messages in syslog.
> 
> I see lots of open file descriptors of type "127.0.0.1:1344".
> 
> There could be an issue with the c-icap service.
> 
> As suggested previously, I dumped a packet trace here:
> 
> https://drive.google.com/file/d/1qCkH6YYa7fgeYzm-AoJEpXTDVpzILCQ9/view?usp=sharing
> 
> Can anyone please take a look at it? I'm trying to determine whether c-icap is closing connections properly.
> Maybe the dump's time range is too short to see anything useful?
> I also tried looking at the c-icap logs, but unfortunately I don't see anything (or I don't know how to interpret them correctly).
> 

What is your ICAP configuration in squid.conf?

Amos


From rentorbuy at yahoo.com  Mon Dec 18 12:05:30 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Mon, 18 Dec 2017 12:05:30 +0000 (UTC)
Subject: [squid-users] TCP out of memory
In-Reply-To: <a77fe8ea-6fa4-b0bf-fbf1-44a49366c77a@treenet.co.nz>
References: <122875663.418224.1513584169532.ref@mail.yahoo.com>
 <122875663.418224.1513584169532@mail.yahoo.com>
 <a77fe8ea-6fa4-b0bf-fbf1-44a49366c77a@treenet.co.nz>
Message-ID: <1144896516.490815.1513598730737@mail.yahoo.com>


________________________________
From: Amos Jeffries <squid3 at treenet.co.nz>
>
> What is your ICAP configuration in squid.conf?


icap_enable on
icap_send_client_ip on
icap_send_client_username on
icap_client_username_encode off
icap_client_username_header X-Authenticated-User
icap_preview_enable on
icap_preview_size 1024
icap_service squidclamav respmod_precache bypass=0 icap://127.0.0.1:1344/clamav
adaptation_access squidclamav allow all

icap_service_failure_limit -1


From akash.kumar.patel at appdirect.com  Mon Dec 18 19:26:54 2017
From: akash.kumar.patel at appdirect.com (tappdint)
Date: Mon, 18 Dec 2017 12:26:54 -0700 (MST)
Subject: [squid-users] Squid configuration not working to set up connection
 between local and remote hosts
Message-ID: <1513625214122-0.post@n4.nabble.com>

For some context I have a squid proxy  container
<https://hub.docker.com/r/datadog/squid/>   running on my local computer as
well as my app. There is another "app" (Selenium) on another host that runs
test on my local app and needs to be on the same network to access the app.
This is what I use squid for, to have both the remote an local apps on the
same docker network.

With my current default configuration, the remote app starts up a chrome
browser to run the tests but then gives a ERR_PROXY_CONNECTION_FAILED error
message when trying to access the app host. This leads me to believe that my
squid proxy's configuration is not set up correctly. The docker hub states
that /"the configuration available with the container is set for local
access, you may need to tweak it if your network scenario is different."/.
I'm not sure exactly what I should be looking into to tweak the config. When
I had the external app running in a vm locally the proxy was able to set up
the connection between the two properly but this remote host does not have
the same results.

Here is my configuration, its just the basic config provided with the image
with all the extra clutter/comments removed.
/
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl CONNECT method CONNECT

# Recommended minimum Access Permission configuration:
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

http_access deny to_localhost

http_access allow localnet
http_access allow localhost
# And finally deny all other access to this proxy
http_access deny all


# Squid normally listens to port 3128
http_port 3128

debug_options rotate=1 ALL,2/

Any ideas what I should look at for more information? Thanks!



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Mon Dec 18 20:28:57 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 19 Dec 2017 09:28:57 +1300
Subject: [squid-users] Squid configuration not working to set up
 connection between local and remote hosts
In-Reply-To: <1513625214122-0.post@n4.nabble.com>
References: <1513625214122-0.post@n4.nabble.com>
Message-ID: <39c03805-eab8-eadd-10b2-c0cfbb66012d@treenet.co.nz>

On 19/12/17 08:26, tappdint wrote:
> For some context I have a squid proxy  container
> <https://hub.docker.com/r/datadog/squid/>   running on my local computer as
> well as my app. There is another "app" (Selenium) on another host that runs
> test on my local app and needs to be on the same network to access the app.
> This is what I use squid for, to have both the remote an local apps on the
> same docker network.
> 
> With my current default configuration, the remote app starts up a chrome
> browser to run the tests but then gives a ERR_PROXY_CONNECTION_FAILED error
> message when trying to access the app host. This leads me to believe that my
> squid proxy's configuration is not set up correctly. The docker hub states
> that /"the configuration available with the container is set for local
> access, you may need to tweak it if your network scenario is different."/.
> I'm not sure exactly what I should be looking into to tweak the config. When
> I had the external app running in a vm locally the proxy was able to set up
> the connection between the two properly but this remote host does not have
> the same results.
> 
> Here is my configuration, its just the basic config provided with the image
> with all the extra clutter/comments removed.
> /
...
> 
> http_access allow localnet
> http_access allow localhost

^^ localnet and localhost are permitted, nothing else.

You need to find out what other access Selenium requires and how it can 
reliably be identified. Then add http_access rules here to allow it.


> # And finally deny all other access to this proxy
> http_access deny all
> 
> 
> # Squid normally listens to port 3128
> http_port 3128
> 
> debug_options rotate=1 ALL,2/
> 
> Any ideas what I should look at for more information? Thanks!
> 


The access.log records the connection details for the failed requests. 
You should usually be able to find most of the details necessary there.

Amos


From akash.kumar.patel at appdirect.com  Mon Dec 18 20:45:08 2017
From: akash.kumar.patel at appdirect.com (tappdint)
Date: Mon, 18 Dec 2017 13:45:08 -0700 (MST)
Subject: [squid-users] Squid configuration not working to set up
 connection between local and remote hosts
In-Reply-To: <39c03805-eab8-eadd-10b2-c0cfbb66012d@treenet.co.nz>
References: <1513625214122-0.post@n4.nabble.com>
 <39c03805-eab8-eadd-10b2-c0cfbb66012d@treenet.co.nz>
Message-ID: <1513629908211-0.post@n4.nabble.com>

Amos Jeffries wrote
> ^^ localnet and localhost are permitted, nothing else.
> 
> You need to find out what other access Selenium requires and how it can 
> reliably be identified. Then add http_access rules here to allow it.
> 
> 
>> # And finally deny all other access to this proxy
>> http_access deny all
>> 
>> 
>> # Squid normally listens to port 3128
>> http_port 3128
>> 
>> debug_options rotate=1 ALL,2/
>> 
>> Any ideas what I should look at for more information? Thanks!
>> 
> 
> 
> The access.log records the connection details for the failed requests. 
> You should usually be able to find most of the details necessary there.

Sorry could you clarify what is meant by /what other access Selenium
requires and how it can 
reliably be identified/? In order for Selenium to run the tests I have to
set up the proxy address in the java code that creates the driver.  In that
code I use my inet address that I get from ifconfig. So the proxy address is
"INET_IP:3128". The script that runs the test requires the host and port
where Selenium is located (external_host_address with port 443 since it is
https). As for the logs, I tried to look at the access logs after the tests
failed to run but unfortunately access.log was empty.



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From squid3 at treenet.co.nz  Mon Dec 18 22:28:52 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 19 Dec 2017 11:28:52 +1300
Subject: [squid-users] Squid configuration not working to set up
 connection between local and remote hosts
In-Reply-To: <1513629908211-0.post@n4.nabble.com>
References: <1513625214122-0.post@n4.nabble.com>
 <39c03805-eab8-eadd-10b2-c0cfbb66012d@treenet.co.nz>
 <1513629908211-0.post@n4.nabble.com>
Message-ID: <9fc99492-e347-2fa9-6a63-d71063dd2b89@treenet.co.nz>

On 19/12/17 09:45, tappdint wrote:
> Amos Jeffries wrote
>> ^^ localnet and localhost are permitted, nothing else.
>>
>> You need to find out what other access Selenium requires and how it can
>> reliably be identified. Then add http_access rules here to allow it.
>>
>>
>>> # And finally deny all other access to this proxy
>>> http_access deny all
>>>
>>>
>>> # Squid normally listens to port 3128
>>> http_port 3128
>>>
>>> debug_options rotate=1 ALL,2/
>>>
>>> Any ideas what I should look at for more information? Thanks!
>>>
>>
>>
>> The access.log records the connection details for the failed requests.
>> You should usually be able to find most of the details necessary there.
> 
> Sorry could you clarify what is meant by /what other access Selenium
> requires and how it can
> reliably be identified/?

To let something through the proxy, you need to know what that thing is 
and either what its TCP connections or HTTP messages look like when it 
contacts the proxy.

Whatever those details are is what you need to find out before you can 
make any meaningful squid.conf changes.

(I don't know that test system to be any more specific.)


> In order for Selenium to run the tests I have to
> set up the proxy address in the java code that creates the driver.  In that
> code I use my inet address that I get from ifconfig. So the proxy address is
> "INET_IP:3128". The script that runs the test requires the host and port
> where Selenium is located (external_host_address with port 443 since it is
> https). As for the logs, I tried to look at the access logs after the tests
> failed to run but unfortunately access.log was empty.

Empty access.log means it is not going through the proxy. Or maybe using 
a CONNECT tunnel which is still open when you checked.

Amos


From yvoinov at gmail.com  Mon Dec 18 22:33:13 2017
From: yvoinov at gmail.com (Yuri)
Date: Tue, 19 Dec 2017 04:33:13 +0600
Subject: [squid-users] Squid configuration not working to set up
 connection between local and remote hosts
In-Reply-To: <9fc99492-e347-2fa9-6a63-d71063dd2b89@treenet.co.nz>
References: <1513625214122-0.post@n4.nabble.com>
 <39c03805-eab8-eadd-10b2-c0cfbb66012d@treenet.co.nz>
 <1513629908211-0.post@n4.nabble.com>
 <9fc99492-e347-2fa9-6a63-d71063dd2b89@treenet.co.nz>
Message-ID: <42db54d8-ae82-369b-2cec-1b0a974cd7bb@gmail.com>

Most probably firewall issues. ALso not fact virtualized invironments
permit TCP exchange between apps/instances without special settings.


19.12.2017 04:28, Amos Jeffries ?????:
> On 19/12/17 09:45, tappdint wrote:
>> Amos Jeffries wrote
>>> ^^ localnet and localhost are permitted, nothing else.
>>>
>>> You need to find out what other access Selenium requires and how it can
>>> reliably be identified. Then add http_access rules here to allow it.
>>>
>>>
>>>> # And finally deny all other access to this proxy
>>>> http_access deny all
>>>>
>>>>
>>>> # Squid normally listens to port 3128
>>>> http_port 3128
>>>>
>>>> debug_options rotate=1 ALL,2/
>>>>
>>>> Any ideas what I should look at for more information? Thanks!
>>>>
>>>
>>>
>>> The access.log records the connection details for the failed requests.
>>> You should usually be able to find most of the details necessary there.
>>
>> Sorry could you clarify what is meant by /what other access Selenium
>> requires and how it can
>> reliably be identified/?
>
> To let something through the proxy, you need to know what that thing
> is and either what its TCP connections or HTTP messages look like when
> it contacts the proxy.
>
> Whatever those details are is what you need to find out before you can
> make any meaningful squid.conf changes.
>
> (I don't know that test system to be any more specific.)
>
>
>> In order for Selenium to run the tests I have to
>> set up the proxy address in the java code that creates the driver.?
>> In that
>> code I use my inet address that I get from ifconfig. So the proxy
>> address is
>> "INET_IP:3128". The script that runs the test requires the host and port
>> where Selenium is located (external_host_address with port 443 since
>> it is
>> https). As for the logs, I tried to look at the access logs after the
>> tests
>> failed to run but unfortunately access.log was empty.
>
> Empty access.log means it is not going through the proxy. Or maybe
> using a CONNECT tunnel which is still open when you checked.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171219/fe981dca/attachment.sig>

From carlopmart at gmail.com  Tue Dec 19 08:02:27 2017
From: carlopmart at gmail.com (C. L. Martinez)
Date: Tue, 19 Dec 2017 08:02:27 +0000
Subject: [squid-users] SQUID + TOR
Message-ID: <CAEjQA5+pSWJZjogMfURZ__bHeFyDkY5YCqLYMh=keQ+ywwbbiQ@mail.gmail.com>

Hi all,

 As Squid's wiki shows:
https://wiki.squid-cache.org/ConfigExamples/Strange/TorifiedSquid, is it
really needed to install privoxy to use squid as a proxy to access .onion
domains? Is not possible to install only squid+tor an put the following:

cache_peer   localhost    parent   9040   7   no-query default

in squid.conf (9040 port is the port configured as a transportport in torrc)?

Thanks.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171219/eb17f794/attachment.htm>

From webmaster at squidblacklist.org  Tue Dec 19 08:19:59 2017
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Tue, 19 Dec 2017 02:19:59 -0600
Subject: [squid-users] SQUID + TOR
Message-ID: <s6ash2i8df2m90mc2yrcby7g.1513671599396@email.android.com>

Looks like the ssl certs expired or revoked for the official squid wiki.?

Signed,
Benjamin E. Nichols1-405-301-9516http://www.squidblacklist.org
-------- Original message --------From: "C. L. Martinez" <carlopmart at gmail.com> Date: 12/19/17  2:02 AM  (GMT-06:00) To: squid-users at lists.squid-cache.org Subject: [squid-users] SQUID + TOR 
Hi all,

?As Squid's wiki shows: https://wiki.squid-cache.org/ConfigExamples/Strange/TorifiedSquid, is it really needed to install privoxy to use squid as a proxy to access .onion domains? Is not possible to install only squid+tor an put the following:

cache_peer   localhost    parent   9040   7   no-query default

in squid.conf (9040 port is the port configured as a transportport in torrc)?

Thanks.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171219/1fac1497/attachment.htm>

From squid3 at treenet.co.nz  Tue Dec 19 10:28:57 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 19 Dec 2017 23:28:57 +1300
Subject: [squid-users] SQUID + TOR
In-Reply-To: <CAEjQA5+pSWJZjogMfURZ__bHeFyDkY5YCqLYMh=keQ+ywwbbiQ@mail.gmail.com>
References: <CAEjQA5+pSWJZjogMfURZ__bHeFyDkY5YCqLYMh=keQ+ywwbbiQ@mail.gmail.com>
Message-ID: <f38f9db9-03b7-3d51-8f55-3dad734ab55d@treenet.co.nz>

On 19/12/17 21:02, C. L. Martinez wrote:
> Hi all,
> 
>  ?As Squid's wiki shows: 
> https://wiki.squid-cache.org/ConfigExamples/Strange/TorifiedSquid, is it 
> really needed to install privoxy to use squid as a proxy to access 
> .onion domains?

Or some other HTTP<->TOR gateway proxy.


> Is not possible to install only squid+tor an put the 
> following:
> 
> cache_peer localhost parent 9040 7 no-query default
> 
> in squid.conf (9040 port is the port configured as a transportport in 
> torrc)?


Unless something has changed TOR only presents a SOCKS interface which 
privoxy uses, not an HTTP one. So Squid will need *at least* working 
SOCKS support on peer connections before the above behaviour can happen.

The current state of SOCKS support in Squid is detailed at 
<https://wiki.squid-cache.org/Features/Socks> that project is still 
blocked by the testing issues mentioned at the bottom of the page. 
Mostly due to lack of time availability from myself and some others who 
showed interest over the years.

Amos


From sekarit at gmail.com  Tue Dec 19 10:33:02 2017
From: sekarit at gmail.com (Sekar Duraisamy)
Date: Tue, 19 Dec 2017 16:03:02 +0530
Subject: [squid-users] How to enable caching for https websites on Squid
Message-ID: <CADfQnU1Hx16+2DsZQHQjNk0Xat6fNVVhQuWG=TuSzcE9PZ4Xcw@mail.gmail.com>

Hi Team,

Please let me know how to enable caching for https websites and can we
configure squid proxy to maintain anonymous as we can configure for
http?


From vedavyas.vayalpadu at accenture.com  Wed Dec 20 10:52:46 2017
From: vedavyas.vayalpadu at accenture.com (Vayalpadu, Vedavyas)
Date: Wed, 20 Dec 2017 10:52:46 +0000
Subject: [squid-users] FTP Issues in Proxy
Message-ID: <MWHP114MB0160A47F00BFCEC2D932DB5D8F0C0@MWHP114MB0160.NAMP114.PROD.OUTLOOK.COM>

Hello Guys,

I need help in configuring FTP services in squid Proxy server.

Issue is: From application FTP requests are coming to squid proxy, but from Proxy it is not going to the Firewall.
We are able to telnet the Firewall netted IP from the reverse proxy.

Are there any FTP configuration settings we need to do in squid proxy server ?




Best regards,

Vyas  (vedavyas vayalpadu )
IBM-AIX-UNIX Support
vedavyas.vayalpadu at accenture.com<mailto:mogens.kjaer at carlsberg.com>


________________________________

This message is for the designated recipient only and may contain privileged, proprietary, or otherwise confidential information. If you have received it in error, please notify the sender immediately and delete the original. Any other use of the e-mail by you is prohibited. Where allowed by local law, electronic communications with Accenture and its affiliates, including e-mail and instant messaging (including content), may be scanned by our systems for the purposes of information security and assessment of internal compliance with Accenture policy.
______________________________________________________________________________________

www.accenture.com
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171220/5b961113/attachment.htm>

From uhlar at fantomas.sk  Wed Dec 20 11:10:44 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 20 Dec 2017 12:10:44 +0100
Subject: [squid-users] FTP Issues in Proxy
In-Reply-To: <MWHP114MB0160A47F00BFCEC2D932DB5D8F0C0@MWHP114MB0160.NAMP114.PROD.OUTLOOK.COM>
References: <MWHP114MB0160A47F00BFCEC2D932DB5D8F0C0@MWHP114MB0160.NAMP114.PROD.OUTLOOK.COM>
Message-ID: <20171220111044.GA17304@fantomas.sk>

On 20.12.17 10:52, Vayalpadu, Vedavyas wrote:
>I need help in configuring FTP services in squid Proxy server.
>
>Issue is: From application FTP requests are coming to squid proxy,

How? do you divert port 21 to squid?

> but from Proxy it is not going to the Firewall.\

what's in squid logs?

>We are able to telnet the Firewall netted IP from the reverse proxy.
>
>Are there any FTP configuration settings we need to do in squid proxy server ?


>Vyas  (vedavyas vayalpadu )
>IBM-AIX-UNIX Support
>vedavyas.vayalpadu at accenture.com<mailto:mogens.kjaer at carlsberg.com>

funny mail address, text says one (vedavyas.vayalpadu at accenture.com) but the
html link says else (mogens.kjaer at carlsberg.com).

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
We are but packets in the Internet of life (userfriendly.org)


From squid3 at treenet.co.nz  Wed Dec 20 12:10:29 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 Dec 2017 01:10:29 +1300
Subject: [squid-users] How to enable caching for https websites on Squid
In-Reply-To: <CADfQnU1Hx16+2DsZQHQjNk0Xat6fNVVhQuWG=TuSzcE9PZ4Xcw@mail.gmail.com>
References: <CADfQnU1Hx16+2DsZQHQjNk0Xat6fNVVhQuWG=TuSzcE9PZ4Xcw@mail.gmail.com>
Message-ID: <1b1626a3-e210-fad2-2fa3-b80fdadab9b3@treenet.co.nz>

On 19/12/17 23:33, Sekar Duraisamy wrote:
> Hi Team,
> 
> Please let me know how to enable caching for https websites and can we
> configure squid proxy to maintain anonymous as we can configure for
> http?

To cache encryption protected content you must first remove the 
encryption. That destroys the "anonymous" part completely.

Also, when a service uses TLS properly it is not possible to decrypt in 
a proxy.

If you accept the above limitations, look into the SSL-Bump feature of 
Squid for details on how to configure decrypting of HTTPS content.


Once Squid is handling decrypted content the caching should "just 
happen", same as with HTTP traffic going through the proxy.

Amos


From uhlar at fantomas.sk  Wed Dec 20 12:23:41 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 20 Dec 2017 13:23:41 +0100
Subject: [squid-users] How to enable caching for https websites on Squid
In-Reply-To: <1b1626a3-e210-fad2-2fa3-b80fdadab9b3@treenet.co.nz>
References: <CADfQnU1Hx16+2DsZQHQjNk0Xat6fNVVhQuWG=TuSzcE9PZ4Xcw@mail.gmail.com>
 <1b1626a3-e210-fad2-2fa3-b80fdadab9b3@treenet.co.nz>
Message-ID: <20171220122341.GB17304@fantomas.sk>

>On 19/12/17 23:33, Sekar Duraisamy wrote:
>>Please let me know how to enable caching for https websites and can we
>>configure squid proxy to maintain anonymous as we can configure for
>>http?

On 21.12.17 01:10, Amos Jeffries wrote:
>To cache encryption protected content you must first remove the 
>encryption. That destroys the "anonymous" part completely.
>
>Also, when a service uses TLS properly it is not possible to decrypt 
>in a proxy.
>
>If you accept the above limitations, look into the SSL-Bump feature 
>of Squid for details on how to configure decrypting of HTTPS content.
>
>
>Once Squid is handling decrypted content the caching should "just 
>happen", same as with HTTP traffic going through the proxy.

and I think you should read the last paragraph as:

  "caching often will not happen, since most of web developers don't know hot
   so use and benefit of it thus they try to disable caching globally"
-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
I'm not interested in your website anymore.
If you need cookies, bake them yourself.


From squid3 at treenet.co.nz  Wed Dec 20 13:20:36 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 Dec 2017 02:20:36 +1300
Subject: [squid-users] How to enable caching for https websites on Squid
In-Reply-To: <20171220122341.GB17304@fantomas.sk>
References: <CADfQnU1Hx16+2DsZQHQjNk0Xat6fNVVhQuWG=TuSzcE9PZ4Xcw@mail.gmail.com>
 <1b1626a3-e210-fad2-2fa3-b80fdadab9b3@treenet.co.nz>
 <20171220122341.GB17304@fantomas.sk>
Message-ID: <29d95c57-7c83-8790-9d2f-fe42bddba829@treenet.co.nz>

On 21/12/17 01:23, Matus UHLAR - fantomas wrote:
>> On 19/12/17 23:33, Sekar Duraisamy wrote:
>>> Please let me know how to enable caching for https websites and can we
>>> configure squid proxy to maintain anonymous as we can configure for
>>> http?
> 
> On 21.12.17 01:10, Amos Jeffries wrote:
>> To cache encryption protected content you must first remove the 
>> encryption. That destroys the "anonymous" part completely.
>>
>> Also, when a service uses TLS properly it is not possible to decrypt 
>> in a proxy.
>>
>> If you accept the above limitations, look into the SSL-Bump feature of 
>> Squid for details on how to configure decrypting of HTTPS content.
>>
>>
>> Once Squid is handling decrypted content the caching should "just 
>> happen", same as with HTTP traffic going through the proxy.
> 
> and I think you should read the last paragraph as:
> 
>  ?"caching often will not happen, since most of web developers don't 
> know hot
>  ? so use and benefit of it thus they try to disable caching globally"

That is nothing special for HTTPS, it happens worse in regular HTTP.

Amos


From rich.andrews at gmail.com  Wed Dec 20 13:27:20 2017
From: rich.andrews at gmail.com (richard-tx)
Date: Wed, 20 Dec 2017 06:27:20 -0700 (MST)
Subject: [squid-users] Squid 3.4.8 Reverse with multiple SSL Sites and
 multiple Certs/Domains
In-Reply-To: <E8C0D58036A98440B317EA23130CF55B680C72@ms-exchange-01.provit.info>
References: <E8C0D58036A98440B317EA23130CF55B67947A@ms-exchange-01.provit.info>
 <cda05731-6239-6358-1dee-aacaeb747f6a@treenet.co.nz>
 <06b6bafc-9892-31f3-3fe6-8e52e29cbf84@treenet.co.nz>
 <026001d2b3b8$ca33c330$5e9b4990$@ngtech.co.il>
 <E8C0D58036A98440B317EA23130CF55B67FC3E@ms-exchange-01.provit.info>
 <bbc405d8-e3b4-f4d0-a74f-d96264430f87@treenet.co.nz>
 <E8C0D58036A98440B317EA23130CF55B680C72@ms-exchange-01.provit.info>
Message-ID: <1513776440892-0.post@n4.nabble.com>

I came up with a solution.  What I did was to get one cert that covers
multiple https websites.  Letsencrypt.com permits you to have multiple
hostnames.  The software certbot allows you to put multiple FQDNs in a
single request or to extend any existing cert.  The certs from
letsencrypt.com is not tied to an IP address, so if your external facing IP
address changes, that presents no issues.

On the plus side, since all communications between squid and the server are
over http, that relieves the already busy webserver from the jobs of
encrypting/decrypting and places it on the reverse proxy.  Starting next
year, letsencrypt will start issuing wildcard certs.  





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From uhlar at fantomas.sk  Wed Dec 20 13:41:33 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 20 Dec 2017 14:41:33 +0100
Subject: [squid-users] How to enable caching for https websites on Squid
In-Reply-To: <29d95c57-7c83-8790-9d2f-fe42bddba829@treenet.co.nz>
References: <CADfQnU1Hx16+2DsZQHQjNk0Xat6fNVVhQuWG=TuSzcE9PZ4Xcw@mail.gmail.com>
 <1b1626a3-e210-fad2-2fa3-b80fdadab9b3@treenet.co.nz>
 <20171220122341.GB17304@fantomas.sk>
 <29d95c57-7c83-8790-9d2f-fe42bddba829@treenet.co.nz>
Message-ID: <20171220134133.GA23710@fantomas.sk>

>On 21/12/17 01:23, Matus UHLAR - fantomas wrote:
>>and I think you should read the last paragraph as:
>>
>> ?"caching often will not happen, since most of web developers 
>>don't know hot
>> ? so use and benefit of it thus they try to disable caching globally"

On 21.12.17 02:20, Amos Jeffries wrote:
>That is nothing special for HTTPS, it happens worse in regular HTTP.

do you want to say that breaking into https can cause http caching more
efficient?
do you have any evidence of that?

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
M$ Win's are shit, do not use it !


From squid3 at treenet.co.nz  Wed Dec 20 13:43:19 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 Dec 2017 02:43:19 +1300
Subject: [squid-users] Squid 3.4.8 Reverse with multiple SSL Sites and
 multiple Certs/Domains
In-Reply-To: <1513776440892-0.post@n4.nabble.com>
References: <E8C0D58036A98440B317EA23130CF55B67947A@ms-exchange-01.provit.info>
 <cda05731-6239-6358-1dee-aacaeb747f6a@treenet.co.nz>
 <06b6bafc-9892-31f3-3fe6-8e52e29cbf84@treenet.co.nz>
 <026001d2b3b8$ca33c330$5e9b4990$@ngtech.co.il>
 <E8C0D58036A98440B317EA23130CF55B67FC3E@ms-exchange-01.provit.info>
 <bbc405d8-e3b4-f4d0-a74f-d96264430f87@treenet.co.nz>
 <E8C0D58036A98440B317EA23130CF55B680C72@ms-exchange-01.provit.info>
 <1513776440892-0.post@n4.nabble.com>
Message-ID: <e5b5ee54-2b4d-2944-4f7e-46cb1d8884ed@treenet.co.nz>

On 21/12/17 02:27, richard-tx wrote:
> I came up with a solution.  What I did was to get one cert that covers
> multiple https websites.  Letsencrypt.com permits you to have multiple
> hostnames.  The software certbot allows you to put multiple FQDNs in a
> single request or to extend any existing cert.  The certs from
> letsencrypt.com is not tied to an IP address, so if your external facing IP
> address changes, that presents no issues.
> 
> On the plus side, since all communications between squid and the server are
> over http, that relieves the already busy webserver from the jobs of
> encrypting/decrypting and places it on the reverse proxy.  Starting next
> year, letsencrypt will start issuing wildcard certs.
> 

Good to know both of those, because since my last reply investigation of 
the way OpenSSL API loads certificates is presenting bad news for being 
able to load multiple certs any time soon.

Amos


From squid3 at treenet.co.nz  Wed Dec 20 15:12:26 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 Dec 2017 04:12:26 +1300
Subject: [squid-users] How to enable caching for https websites on Squid
In-Reply-To: <20171220134133.GA23710@fantomas.sk>
References: <CADfQnU1Hx16+2DsZQHQjNk0Xat6fNVVhQuWG=TuSzcE9PZ4Xcw@mail.gmail.com>
 <1b1626a3-e210-fad2-2fa3-b80fdadab9b3@treenet.co.nz>
 <20171220122341.GB17304@fantomas.sk>
 <29d95c57-7c83-8790-9d2f-fe42bddba829@treenet.co.nz>
 <20171220134133.GA23710@fantomas.sk>
Message-ID: <565b24e8-8448-31fb-bc52-123f0536080f@treenet.co.nz>

On 21/12/17 02:41, Matus UHLAR - fantomas wrote:
>> On 21/12/17 01:23, Matus UHLAR - fantomas wrote:
>>> and I think you should read the last paragraph as:
>>>
>>> ?"caching often will not happen, since most of web developers don't 
>>> know hot
>>> ? so use and benefit of it thus they try to disable caching globally"
> 
> On 21.12.17 02:20, Amos Jeffries wrote:
>> That is nothing special for HTTPS, it happens worse in regular HTTP.
> 
> do you want to say that breaking into https can cause http caching more
> efficient?
> do you have any evidence of that?
> 

No, I am saying that the problem you pointed at is a _larger_ problem in 
http:// because those dev are having to actively prevent caching. Many 
are also under the false impression that https:// goes end-to-end and 
caching does not happen there other than Browser cache. So those who 
develop sites with HTTPS in mind do not go to quite such extremes to 
block proxies caching.

HTTPS has _other_ problems that impact on caching efficiency.

Amos


From rich.andrews at gmail.com  Wed Dec 20 16:31:07 2017
From: rich.andrews at gmail.com (richard-tx)
Date: Wed, 20 Dec 2017 09:31:07 -0700 (MST)
Subject: [squid-users] Squid 3.4.8 Reverse with multiple SSL Sites and
 multiple Certs/Domains
In-Reply-To: <e5b5ee54-2b4d-2944-4f7e-46cb1d8884ed@treenet.co.nz>
References: <E8C0D58036A98440B317EA23130CF55B67947A@ms-exchange-01.provit.info>
 <cda05731-6239-6358-1dee-aacaeb747f6a@treenet.co.nz>
 <06b6bafc-9892-31f3-3fe6-8e52e29cbf84@treenet.co.nz>
 <026001d2b3b8$ca33c330$5e9b4990$@ngtech.co.il>
 <E8C0D58036A98440B317EA23130CF55B67FC3E@ms-exchange-01.provit.info>
 <bbc405d8-e3b4-f4d0-a74f-d96264430f87@treenet.co.nz>
 <E8C0D58036A98440B317EA23130CF55B680C72@ms-exchange-01.provit.info>
 <1513776440892-0.post@n4.nabble.com>
 <e5b5ee54-2b4d-2944-4f7e-46cb1d8884ed@treenet.co.nz>
Message-ID: <1513787467002-0.post@n4.nabble.com>

SNI on squid isn't likely to happen tomorrow but if you think about it, one
cert for all of your sites isn't a bad idea.  Makes life easier.  Next year,
wildcard certs will be another way to resolve the issue.  

I am not sure how many sites can be in one cert.  I did 4.  

All the best

Rich





--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From medya.gh at gmail.com  Thu Dec 21 00:20:11 2017
From: medya.gh at gmail.com (Medya)
Date: Thu, 21 Dec 2017 00:20:11 +0000
Subject: [squid-users] Will Squid Proxy work if it is offline
Message-ID: <CANekvnUGqgfcCn9Oqmu6YF_B0b5v5wFDjV4h6vyq3=JAL8Z5FA@mail.gmail.com>

Hi here is my first post in this mailing list, hopefully it is the right
place to ask.

Let say I access an image http:///example.com/image1.png
<http://example.com/image1.png> and squid proxy caches it,
if I disconnect internet and I try to acesss http:///example.com/image1.png
<http://example.com/image1.png> in the browser. will it get the image?

so my general question is, if I have a URL in my cache, will it make any
connection to the remote hosting server at all?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171221/a8f26812/attachment.htm>

From yvoinov at gmail.com  Thu Dec 21 00:22:31 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 21 Dec 2017 06:22:31 +0600
Subject: [squid-users] Will Squid Proxy work if it is offline
In-Reply-To: <CANekvnUGqgfcCn9Oqmu6YF_B0b5v5wFDjV4h6vyq3=JAL8Z5FA@mail.gmail.com>
References: <CANekvnUGqgfcCn9Oqmu6YF_B0b5v5wFDjV4h6vyq3=JAL8Z5FA@mail.gmail.com>
Message-ID: <12c51a0b-5ce0-9cc0-f097-6ea3a238e3f4@gmail.com>

You abstractly ask? Purely academically? Or are you pursuing a goal?

It's easier to take and try.

21.12.2017 06:20, Medya ?????:
> Hi here is my first post in this mailing list, hopefully it is the
> right place to ask.
>
> Let say I access an image?http:///example.com/image1.png
> <http://example.com/image1.png>?and squid proxy caches it,
> if I disconnect internet and I try to
> acesss?http:///example.com/image1.png
> <http://example.com/image1.png>?in the browser. will it get the image?
>
> so my general question is, if I have a URL in my cache, will it make
> any connection to the remote hosting server at all?
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171221/9cb2a79b/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171221/9cb2a79b/attachment.sig>

From yvoinov at gmail.com  Thu Dec 21 00:29:41 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 21 Dec 2017 06:29:41 +0600
Subject: [squid-users] Will Squid Proxy work if it is offline
In-Reply-To: <CANekvnUGqgfcCn9Oqmu6YF_B0b5v5wFDjV4h6vyq3=JAL8Z5FA@mail.gmail.com>
References: <CANekvnUGqgfcCn9Oqmu6YF_B0b5v5wFDjV4h6vyq3=JAL8Z5FA@mail.gmail.com>
Message-ID: <810e7f5d-40b9-2a57-6882-5d06be40df4b@gmail.com>

In detail: if the picture is in the cache, and the time of its
validation has not arrived - some time will show. In case of all
required DNS queries and, especially, answers is also cached.

Harsh reality: Own Squid's DNS cache? is too tiny by default to store
half of the Internet addresses. Only few people think of combining it
with a caching DNS server of a decent class (at least Unbound).

ALso, just in practice, a disconnected from Internet Squid cache usually
shows no more than 20% of content for several sites. That, in fact,
corresponds to its real degree of caching.

FInally - no, Squid can't replace cutted Internet.

21.12.2017 06:20, Medya ?????:
> Hi here is my first post in this mailing list, hopefully it is the
> right place to ask.
>
> Let say I access an image?http:///example.com/image1.png
> <http://example.com/image1.png>?and squid proxy caches it,
> if I disconnect internet and I try to
> acesss?http:///example.com/image1.png
> <http://example.com/image1.png>?in the browser. will it get the image?
>
> so my general question is, if I have a URL in my cache, will it make
> any connection to the remote hosting server at all?
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
*****************************
* C++20 : Bug to the future *
*****************************

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171221/91defd6e/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 659 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171221/91defd6e/attachment.sig>

From medya.gh at gmail.com  Thu Dec 21 00:39:52 2017
From: medya.gh at gmail.com (Medya)
Date: Thu, 21 Dec 2017 00:39:52 +0000
Subject: [squid-users] Will Squid Proxy work if it is offline
In-Reply-To: <810e7f5d-40b9-2a57-6882-5d06be40df4b@gmail.com>
References: <CANekvnUGqgfcCn9Oqmu6YF_B0b5v5wFDjV4h6vyq3=JAL8Z5FA@mail.gmail.com>
 <810e7f5d-40b9-2a57-6882-5d06be40df4b@gmail.com>
Message-ID: <CANekvnVbf+3ezPTxvVj3txOAn8AEC0C9HrMokZP43LC1MWF0qA@mail.gmail.com>

I meant in pure academic sense, not for using in real world.  what is the
default validation date, let say we own our own network, can we tell it
never expire, or expire in 1 year? so we cache all the photos,and all our
private network users can just access the same photo without ever going to
public internet?

On Wed, Dec 20, 2017 at 6:29 PM Yuri <yvoinov at gmail.com> wrote:

> In detail: if the picture is in the cache, and the time of its validation
> has not arrived - some time will show. In case of all required DNS queries
> and, especially, answers is also cached.
>
> Harsh reality: Own Squid's DNS cache  is too tiny by default to store
> half of the Internet addresses. Only few people think of combining it
> with a caching DNS server of a decent class (at least Unbound).
>
> ALso, just in practice, a disconnected from Internet Squid cache usually
> shows no more than 20% of content for several sites. That, in fact,
> corresponds to its real degree of caching.
> FInally - no, Squid can't replace cutted Internet.
>
>
> 21.12.2017 06:20, Medya ?????:
>
> Hi here is my first post in this mailing list, hopefully it is the right
> place to ask.
>
>
> Let say I access an image http:///example.com/image1.png
> <http://example.com/image1.png> and squid proxy caches it,
> if I disconnect internet and I try to acesss
> http:///example.com/image1.png <http://example.com/image1.png> in the
> browser. will it get the image?
>
> so my general question is, if I have a URL in my cache, will it make any
> connection to the remote hosting server at all?
>
> _______________________________________________
> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>
>
> --
> *****************************
> * C++20 : Bug to the future *
> *****************************
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171221/5869d44e/attachment.htm>

From zerbey at gmail.com  Thu Dec 21 02:53:28 2017
From: zerbey at gmail.com (Chris Horry)
Date: Wed, 20 Dec 2017 21:53:28 -0500
Subject: [squid-users] Trouble getting SNMP to work in Squid 5
Message-ID: <CA+gVyU-swiL6XvXxYdQFaTuY+MW7N40ejxZ+-pa69Djk9i_9Pg@mail.gmail.com>

Hello all,

I'm using the following configuration for SNMP:

acl horry src 192.168.0.0/16
...
snmp_port 3401
acl snmppublic snmp_community <snip>
snmp_access allow snmppublic horry localhost
snmp_incoming_address 0.0.0.0
snmp_outgoing_address 0.0.0.0



Squid is compiled with the --enable-snmp option.

$ squid --version
Squid Cache: Version 5.0.0-20171215-rb7c260f
Service Name: squid
configure options:  '--enable-ssl' '--enable-linux-netfilter'
'--enable-htcp' '--enable-snmp' '--enable-storeio=ufs,diskd,aufs'
'--enable-async-io' '--with-aio' '--with-large-files'
'--enable-removal-policies=heap'

However, when I try to query SNMP:

$ snmpwalk -m ../share/mib.txt -v2c -Cc -c <snip> localhost:3401
MIB search path:
/home/zerbey/.snmp/mibs:/usr/share/snmp/mibs:/usr/share/snmp/mibs/iana:/usr/share/snmp/mibs/ietf:/usr/share/mibs/site:/usr/share/snmp/mibs:/usr/share/mibs/iana:/usr/share/mibs/ietf:/usr/share/mibs/netsnmp
Cannot find module (SNMPv2-SMI): At line 8 in ../share/mib.txt
Cannot find module (SNMPv2-TC): At line 11 in ../share/mib.txt
Cannot find module (INET-ADDRESS-MIB): At line 14 in ../share/mib.txt
Did not find 'enterprises' in module #-1 (../share/mib.txt)
Did not find 'DisplayString' in module #-1 (../share/mib.txt)
Did not find 'InetAddressType' in module #-1 (../share/mib.txt)
Did not find 'InetAddress' in module #-1 (../share/mib.txt)
Unlinked OID in SQUID-MIB: nlanr ::= { enterprises 3495 }
Undefined identifier: enterprises near line 50 of ../share/mib.txt
Cannot adopt OID in SQUID-MIB: cacheCurrentFileDescrMax ::= { cacheSysPerf
13 }
...this continues for many lines, but the gist is it doesn't get any
data... ending on...
Cannot adopt OID in SQUID-MIB: cacheIpCache ::= { cacheNetwork 1 }


Tried various iterations of snmpwalk including from other hosts and with
udp/tcp.  Never get any response.

Not sure where to go from here, is there any other debugging I can enable
or is SNMP configured differently in v5?

Thanks!

Chris




-- 
Chris Horry
Ham Radio - KG4TSM
zerbey at gmail.com
http://twitter.com/zerbey
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171220/d33e662b/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec 21 05:13:39 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 Dec 2017 18:13:39 +1300
Subject: [squid-users] Trouble getting SNMP to work in Squid 5
In-Reply-To: <CA+gVyU-swiL6XvXxYdQFaTuY+MW7N40ejxZ+-pa69Djk9i_9Pg@mail.gmail.com>
References: <CA+gVyU-swiL6XvXxYdQFaTuY+MW7N40ejxZ+-pa69Djk9i_9Pg@mail.gmail.com>
Message-ID: <337fb047-3224-e3b6-a372-ffca629a0718@treenet.co.nz>



On 21/12/17 15:53, Chris Horry wrote:
> Hello all,
> 
> I'm using the following configuration for SNMP:
> 
> acl horry src 192.168.0.0/16 <http://192.168.0.0/16>
> ...
> snmp_port 3401
> acl snmppublic snmp_community <snip>
> snmp_access allow snmppublic horry localhost

NP: src-IP address cannot simultaneously be 127.0.0.1 and a 192.168.*.* 
IP. So requests will be denied, but that is not your current problem.

> snmp_incoming_address 0.0.0.0
> snmp_outgoing_address 0.0.0.0
> 
> 
> 
> Squid is compiled with the --enable-snmp option.
> 
> $ squid --version
> Squid Cache: Version 5.0.0-20171215-rb7c260f
> Service Name: squid
> configure options:? '--enable-ssl' '--enable-linux-netfilter' 
> '--enable-htcp' '--enable-snmp' '--enable-storeio=ufs,diskd,aufs' 
> '--enable-async-io' '--with-aio' '--with-large-files' 
> '--enable-removal-policies=heap'
> 
> However, when I try to query SNMP:
> 
> $ snmpwalk -m ../share/mib.txt -v2c -Cc -c <snip> localhost:3401

You will need to use 127.0.0.1 explicitly or the localhost-ip4 name if 
you hosts file defines one. "localhost:3401" also resolves to [::1]:3401 
which you have closed.


> MIB search path: 
> /home/zerbey/.snmp/mibs:/usr/share/snmp/mibs:/usr/share/snmp/mibs/iana:/usr/share/snmp/mibs/ietf:/usr/share/mibs/site:/usr/share/snmp/mibs:/usr/share/mibs/iana:/usr/share/mibs/ietf:/usr/share/mibs/netsnmp
> Cannot find module (SNMPv2-SMI): At line 8 in ../share/mib.txt
> Cannot find module (SNMPv2-TC): At line 11 in ../share/mib.txt
> Cannot find module (INET-ADDRESS-MIB): At line 14 in ../share/mib.txt
> Did not find 'enterprises' in module #-1 (../share/mib.txt)
> Did not find 'DisplayString' in module #-1 (../share/mib.txt)
> Did not find 'InetAddressType' in module #-1 (../share/mib.txt)
> Did not find 'InetAddress' in module #-1 (../share/mib.txt)
> Unlinked OID in SQUID-MIB: nlanr ::= { enterprises 3495 }
> Undefined identifier: enterprises near line 50 of ../share/mib.txt
> Cannot adopt OID in SQUID-MIB: cacheCurrentFileDescrMax ::= { 
> cacheSysPerf 13 }
> ...this continues for many lines, but the gist is it doesn't get any 
> data... ending on...
> Cannot adopt OID in SQUID-MIB: cacheIpCache ::= { cacheNetwork 1 }
> 

Are you sure your system snmp is installed correctly? That looks like 
the basic system MIB files are missing or unreadable.


> 
> Tried various iterations of snmpwalk including from other hosts and with 
> udp/tcp.? Never get any response.
> 
> Not sure where to go from here, is there any other debugging I can 
> enable or is SNMP configured differently in v5?

It's the same in all v3+.


Amos


From squid3 at treenet.co.nz  Thu Dec 21 05:36:46 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 21 Dec 2017 18:36:46 +1300
Subject: [squid-users] Will Squid Proxy work if it is offline
In-Reply-To: <CANekvnVbf+3ezPTxvVj3txOAn8AEC0C9HrMokZP43LC1MWF0qA@mail.gmail.com>
References: <CANekvnUGqgfcCn9Oqmu6YF_B0b5v5wFDjV4h6vyq3=JAL8Z5FA@mail.gmail.com>
 <810e7f5d-40b9-2a57-6882-5d06be40df4b@gmail.com>
 <CANekvnVbf+3ezPTxvVj3txOAn8AEC0C9HrMokZP43LC1MWF0qA@mail.gmail.com>
Message-ID: <14023f05-c3f9-6109-5d1c-59e2ce749706@treenet.co.nz>

On 21/12/17 13:39, Medya wrote:
> I meant in pure academic sense, not for using in real world.? what is 
> the default validation date, let say we own our own network, can we tell 
> it never expire, or expire in 1 year? so we cache all the photos,and all 
> our private network users can just access the same photo without ever 
> going to public internet?

For academic answers I suggest you read through RFC 7234 and 7232.
  <https://tools.ietf.org/html/rfc7234>
  <https://tools.ietf.org/html/rfc7232>


Squid provides the refresh_pattern directive where you can supply custom 
default parameters for the heuristic caching algorithm for responses 
which lack sufficient details. The default squid.conf refresh_pattern 
definition provides parameters for up to 1 week of caching.

refresh_pattern directive also provides some overrides to make those 
heuristics be applied to responses where it SHOULD NOT be used. Be 
conservative using those, the person who designed the site has a lot 
better knowledge of what could or does go wrong. Everything choice of 
theirs you override risks breakage in subtle ways you may not be aware 
of nor able to detect easily.
  eg did you ever consider that "photos" includes Captcha and bioprint 
authentication details?
  or that content in HTTP/1.1 changes based on which Browser clients are 
using?


Amos


From rentorbuy at yahoo.com  Thu Dec 21 08:25:07 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Thu, 21 Dec 2017 08:25:07 +0000 (UTC)
Subject: [squid-users] TCP out of memory
In-Reply-To: <a77fe8ea-6fa4-b0bf-fbf1-44a49366c77a@treenet.co.nz>
References: <122875663.418224.1513584169532.ref@mail.yahoo.com>
 <122875663.418224.1513584169532@mail.yahoo.com>
 <a77fe8ea-6fa4-b0bf-fbf1-44a49366c77a@treenet.co.nz>
Message-ID: <307535512.2159006.1513844707201@mail.yahoo.com>

BTW, I set icap_service_failure_limit -1 because If I don't the HTTP clients get the ERR_ICAP_FAILURE page for *a very long time* if I restart the c-icap service.
I have no idea how much they would have to wait because I can't afford users seeing this page for more than a minute.
The following test was done in 2 minutes with the default icap_service_failure_limit:

# /etc/init.d/squid reload

# /etc/init.d/c-icap restart

# squidclient mgr:info
HTTP/1.1 200 OK
Server: squid
Mime-Version: 1.0
Date: Thu, 21 Dec 2017 08:07:07 GMT
Content-Type: text/plain;charset=utf-8
Expires: Thu, 21 Dec 2017 08:07:07 GMT
Last-Modified: Thu, 21 Dec 2017 08:07:07 GMT
X-Cache: MISS from inf-fw2
X-Cache-Lookup: MISS from inf-fw2:3128
Connection: close

Squid Object Cache: Version 3.5.27-20171101-re69e56c
Build Info:
Service Name: squid
Start Time:     Mon, 18 Dec 2017 08:29:33 GMT
Current Time:   Thu, 21 Dec 2017 08:07:07 GMT
Connection information for squid:
Number of clients accessing cache:      569
Number of HTTP requests received:       3381083
Number of ICP messages received:        0
Number of ICP messages sent:    0
Number of queued ICP replies:   0
Number of HTCP messages received:       0
Number of HTCP messages sent:   0
Request failure ratio:   0.00
Average HTTP requests per minute since start:   786.7
Average ICP messages per minute since start:    0.0
Select loop called: 93431818 times, 2.760 ms avg
Cache information for squid:
Hits as % of all requests:      5min: 0.9%, 60min: 2.0%
Hits as % of bytes sent:        5min: 5.2%, 60min: 9.5%
Memory hits as % of hit requests:       5min: 88.4%, 60min: 60.2%
Disk hits as % of hit requests: 5min: 0.0%, 60min: 0.1%
Storage Swap size:      29156 KB
Storage Swap capacity:  89.0% used, 11.0% free
Storage Mem size:       30648 KB
Storage Mem capacity:   93.5% used,  6.5% free
Mean Object Size:       18.03 KB
Requests given to unlinkd:      49975
Median Service Times (seconds)  5 min    60 min:
HTTP Requests (All):   0.05633  0.04047
Cache Misses:          0.10281  0.11465
Cache Hits:            0.00000  0.00000
Near Hits:             0.01745  0.01955
Not-Modified Replies:  0.00000  0.00000
DNS Lookups:           0.04048  0.03868
ICP Queries:           0.00000  0.00000
Resource usage for squid:
UP Time:        257853.454 seconds
CPU Time:       6005.270 seconds
CPU Usage:      2.33%
CPU Usage, 5 minute avg:        6.76%
CPU Usage, 60 minute avg:       2.99%
Maximum Resident Size: 5549424 KB
Page faults with physical i/o: 0
Memory accounted for:
Total accounted:       1004217 KB
memPoolAlloc calls: 980681181
memPoolFree calls:  999432183
File descriptor usage for squid:
Maximum number of file descriptors:   65536
Largest file desc currently in use:   4399
Number of file desc currently in use: 4052
Files queued for open:                   0
Available number of file descriptors: 61484
Reserved number of file descriptors:   100
Store Disk files open:                   0
Internal Data Structures:
2074 StoreEntries
1911 StoreEntries with MemObjects
1687 Hot Object Cache Items
1617 on-disk objects

Two minutes later and clients are still seeing ERR_ICAP_FAILURE, so I'm setting back to icap_service_failure_limit -1.

# /etc/init.d/squid reload

# squidclient mgr:info
HTTP/1.1 200 OK
Server: squid
Mime-Version: 1.0
Date: Thu, 21 Dec 2017 08:09:26 GMT
Content-Type: text/plain;charset=utf-8
Expires: Thu, 21 Dec 2017 08:09:26 GMT
Last-Modified: Thu, 21 Dec 2017 08:09:26 GMT
X-Cache: MISS from inf-fw2
X-Cache-Lookup: MISS from inf-fw2:3128
Connection: close

Squid Object Cache: Version 3.5.27-20171101-re69e56c
Build Info:
Service Name: squid
Start Time:     Mon, 18 Dec 2017 08:29:33 GMT
Current Time:   Thu, 21 Dec 2017 08:09:26 GMT
Connection information for squid:
Number of clients accessing cache:      569
Number of HTTP requests received:       3382478
Number of ICP messages received:        0
Number of ICP messages sent:    0
Number of queued ICP replies:   0
Number of HTCP messages received:       0
Number of HTCP messages sent:   0
Request failure ratio:   0.00
Average HTTP requests per minute since start:   786.6
Average ICP messages per minute since start:    0.0
Select loop called: 93457469 times, 2.761 ms avg
Cache information for squid:
Hits as % of all requests:      5min: 1.2%, 60min: 2.0%
Hits as % of bytes sent:        5min: 10.9%, 60min: 9.7%
Memory hits as % of hit requests:       5min: 88.3%, 60min: 60.1%
Disk hits as % of hit requests: 5min: 0.0%, 60min: 0.1%
Storage Swap size:      29156 KB
Storage Swap capacity:  89.0% used, 11.0% free
Storage Mem size:       30648 KB
Storage Mem capacity:   93.5% used,  6.5% free
Mean Object Size:       18.03 KB
Requests given to unlinkd:      49975
Median Service Times (seconds)  5 min    60 min:
HTTP Requests (All):   0.05046  0.04047
Cache Misses:          0.11465  0.11465
Cache Hits:            0.00000  0.00000
Near Hits:             0.00000  0.01955
Not-Modified Replies:  0.00000  0.00000
DNS Lookups:           0.04237  0.03868
ICP Queries:           0.00000  0.00000
Resource usage for squid:
UP Time:        257992.456 seconds
CPU Time:       6009.530 seconds
CPU Usage:      2.33%
CPU Usage, 5 minute avg:        4.90%
CPU Usage, 60 minute avg:       2.98%
Maximum Resident Size: 5549728 KB
Page faults with physical i/o: 0
Memory accounted for:
Total accounted:       997578 KB
memPoolAlloc calls: 980907766
memPoolFree calls:  999669215
File descriptor usage for squid:
Maximum number of file descriptors:   65536
Largest file desc currently in use:   4399
Number of file desc currently in use: 3676
Files queued for open:                   0
Available number of file descriptors: 61860
Reserved number of file descriptors:   100
Store Disk files open:                   0
Internal Data Structures:
1895 StoreEntries
1732 StoreEntries with MemObjects
1687 Hot Object Cache Items
1617 on-disk objects


Clients are now browsing, and squid/c-icap are apparently communicating.

Vieri


From squid3 at treenet.co.nz  Fri Dec 22 01:56:38 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 22 Dec 2017 14:56:38 +1300
Subject: [squid-users] Trouble getting SNMP to work in Squid 5
Message-ID: <9b5523314b98b592ab749b384d74cbc5@treenet.co.nz>

On 2017-12-22 03:50, Chris Horry wrote:
> On Thu, Dec 21, 2017 at 12:13 AM, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
> 
>> On 21/12/17 15:53, Chris Horry wrote:
>> 
>>> Hello all,
>>> 
>>> I'm using the following configuration for SNMP:
>>> 
>>> acl horry src 192.168.0.0/16 [1] <http://192.168.0.0/16>
>>> ...
>>> snmp_port 3401
>>> acl snmppublic snmp_community <snip>
>>> snmp_access allow snmppublic horry localhost
>> 
>> NP: src-IP address cannot simultaneously be 127.0.0.1 and a
>> 192.168.*.* IP. So requests will be denied, but that is not your
>> current problem.
> 
> Could you explain this a little better?  I'm trying to allow SNMP
> requests from a different host in my 192.168/16 subnet.  Queries from
> that host fail too even with the mib file in place. I removed
> localhost from the acl and still no dice.  Perhaps I'm
> misunderstanding how the ACL works.

The ACLs "horry localhost" you had requires that the clients IP (src) be 
127.0.0.1 AND in the range 192.168.0.0/16. So even if Squid received the 
SNMP request it would have rejected the query.

The MIB problem is happening inside snmpwalk itself and Squid is not 
involved with any of that.

> 
>  $ snmpwalk -m /home/zerbey/mib.txt -v2c -Cc -c monstersinc
> uwwwcache.horry.org:3401 [2]
> MIB search path:
> /home/zerbey/.snmp/mibs:/usr/share/snmp/mibs:/usr/share/snmp/mibs/iana:/usr/share/snmp/mibs/ietf:/usr/share/mibs/site:/usr/share/snmp/mibs:/usr/share/mibs/iana:/usr/share/mibs/ietf:/usr/share/mibs/netsnmp
> Cannot find module (SNMPv2-SMI): At line 8 in /home/zerbey/mib.txt
> Cannot find module (SNMPv2-TC): At line 11 in /home/zerbey/mib.txt
> Cannot find module (INET-ADDRESS-MIB): At line 14 in
> /home/zerbey/mib.txt
> Did not find 'enterprises' in module #-1 (/home/zerbey/mib.txt)
> Did not find 'DisplayString' in module #-1 (/home/zerbey/mib.txt)
> Did not find 'InetAddressType' in module #-1 (/home/zerbey/mib.txt)
> Did not find 'InetAddress' in module #-1 (/home/zerbey/mib.txt)
...

> 
> The mib.txt is taken directly from the squid source.

The Squid MIB is being loaded, its the system ones which do the type 
definitions used by Squid that are not loading properly.

> 
> Note: SNMP is properly installed, I'm monitoring multiple other
> systems on my network with no issues whatsoever.  Is there some more
> detailed logging I can enable to see if squid is even receiving the
> queries?
> 

Weird. It works for me.

It is definitely a problem with the MIB files and snmpwalk itself 
though. It should work if you just use the raw OID values (omit the -m 
parameter) and walk the tree Squid produces.
  https://wiki.squid-cache.org/Features/Snmp#Squid_OIDs

Amos


From eliezer at ngtech.co.il  Sun Dec 24 05:27:42 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 24 Dec 2017 07:27:42 +0200
Subject: [squid-users] Squid 4.0.22 beta RPM's are available
Message-ID: <051201d37c77$ec2cfc80$c486f580$@ngtech.co.il>

Hey Everybody,

I finished packaging the latest squid 4 beta RPM's and I am releasing a special SpeedTest RPM with it.
The version of this speedtest is based on another person work and if you will use it you will have the link to the github repository of it.
But there is one nice feature that I added to the service to prevent DOS or DDOS attack on the speedtest service.

More details about it at the post:
http://www1.ngtech.co.il/wpe/2017/12/24/squid-cache-4-0-22-rpms-released-speedtest-service-for-free/

All The Bests,
Eliezer

* I will probably won't have too much time to participate Squid-Cache like in the past so just contact me directly.

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



From rentorbuy at yahoo.com  Wed Dec 27 06:59:55 2017
From: rentorbuy at yahoo.com (Vieri)
Date: Wed, 27 Dec 2017 06:59:55 +0000 (UTC)
Subject: [squid-users] browser acl
References: <1244012691.4208631.1514357995142.ref@mail.yahoo.com>
Message-ID: <1244012691.4208631.1514357995142@mail.yahoo.com>

Hi,

Which one of the two examples below is syntactically correct?

acl UA browser Firefox/

acl UA browser Firefox\/

Thanks,

Vieri


From squid3 at treenet.co.nz  Wed Dec 27 13:53:40 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 28 Dec 2017 02:53:40 +1300
Subject: [squid-users] browser acl
In-Reply-To: <1244012691.4208631.1514357995142@mail.yahoo.com>
References: <1244012691.4208631.1514357995142.ref@mail.yahoo.com>
 <1244012691.4208631.1514357995142@mail.yahoo.com>
Message-ID: <06c2659e11cfcca8b4ef7458cb1218c4@treenet.co.nz>

On 2017-12-27 19:59, Vieri wrote:
> Hi,
> 
> Which one of the two examples below is syntactically correct?
> 
> acl UA browser Firefox/
> 
> acl UA browser Firefox\/
> 

Both, depending on your regex library. The syntax above are just text 
strings passed from Squid to your regex library as-is.

\-escaping is only supported by Squid-3.5+ when inside ""-quoted 
parameters. Older versions do not unescape it at all.

Amos


From rousskov at measurement-factory.com  Wed Dec 27 15:21:12 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 27 Dec 2017 08:21:12 -0700
Subject: [squid-users] browser acl
In-Reply-To: <06c2659e11cfcca8b4ef7458cb1218c4@treenet.co.nz>
References: <1244012691.4208631.1514357995142.ref@mail.yahoo.com>
 <1244012691.4208631.1514357995142@mail.yahoo.com>
 <06c2659e11cfcca8b4ef7458cb1218c4@treenet.co.nz>
Message-ID: <2446920f-508e-7cda-bd26-f946fd93c082@measurement-factory.com>

On 12/27/2017 06:53 AM, Amos Jeffries wrote:

> \-escaping is only supported by Squid-3.5+ when inside ""-quoted
> parameters. Older versions do not unescape it at all.
 And, for backward compatibility reasons, only a few directives actually
support "quoted parameters" unless configuration_includes_quoted_values
is on (it is off by default).

http://www.squid-cache.org/Doc/config/configuration_includes_quoted_values/

Alex.


From mauriciogaravaglia at gmail.com  Wed Dec 27 18:53:05 2017
From: mauriciogaravaglia at gmail.com (Mauricio Garavaglia)
Date: Wed, 27 Dec 2017 15:53:05 -0300
Subject: [squid-users] Caching HTTPS with a parent squid
Message-ID: <CAKTzdV2ojjVLo-qQKWmGhsbPMSYwbzF2gchHuTdvnm6bB0FGmw@mail.gmail.com>

Hello! I have a squid 3.5 caching HTTPS doing BumpSSL, everything works ok
butI need to add another one as a parent (bigger storage and but different
SLA...) of the first one, while still allowing it to go direct if the
parent is not available.

[Client]---->[Squid 1]----->[Squid 2]---->[Origin Server]

To proper cache both, I would need to bump, but that's not available per
https://github.com/squid-cache/squid/blob/v3.5/src/FwdState.cc#L813

What would be the correct way to accomplish that? Tried making the first
one to just peek but I still want to allow to cache the responses and not
just bypass the connection.
Thanks!

Mauricio
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171227/d337ebe3/attachment.htm>

From squid3 at treenet.co.nz  Thu Dec 28 03:44:46 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 28 Dec 2017 16:44:46 +1300
Subject: [squid-users] Caching HTTPS with a parent squid
In-Reply-To: <CAKTzdV2ojjVLo-qQKWmGhsbPMSYwbzF2gchHuTdvnm6bB0FGmw@mail.gmail.com>
References: <CAKTzdV2ojjVLo-qQKWmGhsbPMSYwbzF2gchHuTdvnm6bB0FGmw@mail.gmail.com>
Message-ID: <6df7f3359b94affec0e898ffbd77d4b2@treenet.co.nz>

On 2017-12-28 07:53, Mauricio Garavaglia wrote:
> Hello! I have a squid 3.5 caching HTTPS doing BumpSSL, everything
> works ok butI need to add another one as a parent (bigger storage and
> but different SLA...) of the first one, while still allowing it to go
> direct if the parent is not available.
> 
> [Client]---->[Squid 1]----->[Squid 2]---->[Origin Server]
> 
> To proper cache both, I would need to bump, but that's not available
> per
> https://github.com/squid-cache/squid/blob/v3.5/src/FwdState.cc#L813
> 
> What would be the correct way to accomplish that? Tried making the
> first one to just peek but I still want to allow to cache the
> responses and not just bypass the connection.


The way to do this is to use MARK or TOS to label the child proxy 
outgoing traffic so routing can send it to the parent proxy where it 
gets re-bumped. Both proxies otherwise operate as stand-alone 
interceptors.

DO NOT use cache_peer originserver connections between them - while this 
can appear to work for some traffic it removes TLS properties needed by 
many modern clients.

Amos


From mauriciogaravaglia at gmail.com  Thu Dec 28 20:42:51 2017
From: mauriciogaravaglia at gmail.com (Mauricio Garavaglia)
Date: Thu, 28 Dec 2017 17:42:51 -0300
Subject: [squid-users] Caching HTTPS with a parent squid
In-Reply-To: <6df7f3359b94affec0e898ffbd77d4b2@treenet.co.nz>
References: <CAKTzdV2ojjVLo-qQKWmGhsbPMSYwbzF2gchHuTdvnm6bB0FGmw@mail.gmail.com>
 <6df7f3359b94affec0e898ffbd77d4b2@treenet.co.nz>
Message-ID: <CAKTzdV2pLGRyYiqL5N1yUjLeTM6GU0fhtRhUxB6dueYJ+RoPFQ@mail.gmail.com>

Thanks for the reply!
I'm not sure I'm following. Are you suggesting to remove cache_peer in the
child, use qos_flows to mark the cache miss traffic, and then configure
routing policies to direct that to the parent squid?
Anything I could read to get more info about that approach?


On Thu, Dec 28, 2017 at 12:44 AM, Amos Jeffries <squid3 at treenet.co.nz>
wrote:

> On 2017-12-28 07:53, Mauricio Garavaglia wrote:
>
>> Hello! I have a squid 3.5 caching HTTPS doing BumpSSL, everything
>> works ok butI need to add another one as a parent (bigger storage and
>> but different SLA...) of the first one, while still allowing it to go
>> direct if the parent is not available.
>>
>> [Client]---->[Squid 1]----->[Squid 2]---->[Origin Server]
>>
>> To proper cache both, I would need to bump, but that's not available
>> per
>> https://github.com/squid-cache/squid/blob/v3.5/src/FwdState.cc#L813
>>
>> What would be the correct way to accomplish that? Tried making the
>> first one to just peek but I still want to allow to cache the
>> responses and not just bypass the connection.
>>
>
>
> The way to do this is to use MARK or TOS to label the child proxy outgoing
> traffic so routing can send it to the parent proxy where it gets re-bumped.
> Both proxies otherwise operate as stand-alone interceptors.
>
> DO NOT use cache_peer originserver connections between them - while this
> can appear to work for some traffic it removes TLS properties needed by
> many modern clients.
>
> Amos
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171228/cd6b5af4/attachment.htm>

From ermalwa1 at gmail.com  Thu Dec 28 22:59:20 2017
From: ermalwa1 at gmail.com (squidnoob)
Date: Thu, 28 Dec 2017 15:59:20 -0700 (MST)
Subject: [squid-users] Help with UA filtering in https connections
Message-ID: <1514501960304-0.post@n4.nabble.com>

Hi there,

I'm a squid noob. I have been trying to configure squid for the past 3 days
looking high and low on the interwebs and have not found exactly what i'm
looking for. 

Here's the context:
- the squid server is running in a server environment. It will not serve
end-users, but servers.
- privacy in regards to ssl interception is not a concern in this
environment.
- running squid: 3.5.23 on Ubuntu 16.04


Here are my goals:
- whitelist approach for domains. i.e. i only want a handful of domains to
be accessible. 
- i want to allow certain UA's to bypass the whitelist rules. I know that
user agents are easy to spoof, but in this context and environment, it
doesn't matter. 


I've pieced together the following configuration and have not been able to
figure this out. Any help is greatly appreciated! 

---------------------------------------------squid.conf-------------------------------------------------
visible_hostname squid

acl CONNECT method CONNECT

access_log daemon:/var/log/squid/access.log combined

#Handling HTTP requests
http_port 3129 intercept
acl allowed_http_sites dstdomain "/etc/squid/http_allow_domains.txt"
http_access allow allowed_http_sites

#Handling HTTPS requests
https_port 3130 ssl-bump intercept cert=/etc/squid/ssl_cert/myCA.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB


acl SSL_port port 443
http_access allow SSL_port

## This route does not work with UA processing below, but properly
terminates non-whitelisted sites
# The ssl::server_name ACL will not work outside of the ssl_bump directive. 
acl allowed_https_sites ssl::server_name "/etc/squid/http_allow_domains.txt"
acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3
ssl_bump peek step1 all
ssl_bump peek step2 allowed_https_sites
ssl_bump splice step3 allowed_https_sites
ssl_bump terminate step2 all
##


## This route does not work at all at preventing non-whitelisted sites
#acl allowed_https_sites ssl::server_name
"/etc/squid/http_allow_domains.txt"
#acl step1 at_step SslBump1
#acl step2 at_step SslBump2
#acl step3 at_step SslBump3
#ssl_bump peek step1 all
#ssl_bump peek step2 allowed_https_sites
#ssl_bump splice step3 allowed_https_sites
#ssl_bump bump all
##
 

## Bypass the proxy by UA
acl proxy_bypass_ua browser ^python-requests.*$
http_access allow proxy_bypass_ua



# And finally deny all other access to this proxy
http_access deny all







--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rousskov at measurement-factory.com  Thu Dec 28 23:18:18 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 28 Dec 2017 16:18:18 -0700
Subject: [squid-users] Help with UA filtering in https connections
In-Reply-To: <1514501960304-0.post@n4.nabble.com>
References: <1514501960304-0.post@n4.nabble.com>
Message-ID: <ecaab75f-7375-b641-0fea-582be9e33669@measurement-factory.com>

On 12/28/2017 03:59 PM, squidnoob wrote:

> Here are my goals:
> - i only want a handful of domains to be accessible. 
> - i want to allow certain UA's to bypass the whitelist rules.

Since you appear to have full control over the environment, have you
tried bumping everything and applying your access rules to bumped (or
plain) traffic?


  # bump everything
  ssl_bump stare all
  ssl_bump bump all

  # delay filtering decisions until we get to bumped requests
  http_access allow CONNECT toSafePorts
  http_access deny CONNECT

  # filter plain and bumped requests
  http_access allow certainUserAgents
  http_access allow handfulOfDomains
  http_access deny all


The above allows all (safe) CONNECTs in case some CONNECT requests do
not have User-Agent headers or lack other details important for your
certainUserAgents and handfulOfDomains ACLs. Since you are bumping all
those allowed CONNECTs and validating all "real" requests inside bumped
tunnels, allowing all (safe) CONNECTs does not contradict your goals AFAICT.


HTH,

Alex.


From squid3 at treenet.co.nz  Thu Dec 28 23:26:32 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 29 Dec 2017 12:26:32 +1300
Subject: [squid-users] Help with UA filtering in https connections
In-Reply-To: <1514501960304-0.post@n4.nabble.com>
References: <1514501960304-0.post@n4.nabble.com>
Message-ID: <dad757a8179e1e4ef8859849659d097e@treenet.co.nz>

On 2017-12-29 11:59, squidnoob wrote:
> Hi there,
> 
> I'm a squid noob. I have been trying to configure squid for the past 3 
> days
> looking high and low on the interwebs and have not found exactly what 
> i'm
> looking for.
> 
> Here's the context:
> - the squid server is running in a server environment. It will not 
> serve
> end-users, but servers.

Is that server<->server traffic you are talking about here?
or the proxy acting as CDN frontend for some servers?

The difference will determine what config is applicable.


Amos


From dratdestroyer-dec2017 at yahoo.com  Thu Dec 28 23:38:15 2017
From: dratdestroyer-dec2017 at yahoo.com (Emal user)
Date: Thu, 28 Dec 2017 23:38:15 +0000 (UTC)
Subject: [squid-users] Limiting amount of Bandwidth Squid gets data from the
 outside internet
References: <1268250978.9858878.1514504295079.ref@mail.yahoo.com>
Message-ID: <1268250978.9858878.1514504295079@mail.yahoo.com>

Hello,

My internet connection is 200 KiloBytes a second.

I use squid on OpenSUSE 42.3.

I use Squid Cache: Version 3.5.21


Squid is working correctly.  It gets and caches images from an online game perfectly.  Cached images from Squid get sent to the game very fast making it usable.


Squid uses all the available internet bandwidth so other users in the house get no bandwidth.

I would like Squid to not ever use more than about 50 Kilobytes of internet bandwidth.


Can spmebody please suggest a soloution?

Thanks,


Regards, Terry.


From leeb at ratnaling.org  Thu Dec 28 23:54:55 2017
From: leeb at ratnaling.org (Lee Brown)
Date: Thu, 28 Dec 2017 15:54:55 -0800
Subject: [squid-users] Limiting amount of Bandwidth Squid gets data from
 the outside internet
In-Reply-To: <1268250978.9858878.1514504295079@mail.yahoo.com>
References: <1268250978.9858878.1514504295079.ref@mail.yahoo.com>
 <1268250978.9858878.1514504295079@mail.yahoo.com>
Message-ID: <CAFPNf58Y69gPtihwygt4AXQThmvOdFdMyJX1s6ouerQScQ-qPw@mail.gmail.com>

You either employ delay pools
<https://wiki.squid-cache.org/Features/DelayPools>, or manage that
separately on the firewall/router itself.

On Thu, Dec 28, 2017 at 3:38 PM, Emal user <dratdestroyer-dec2017 at yahoo.com>
wrote:

> Hello,
>
> My internet connection is 200 KiloBytes a second.
>
> I use squid on OpenSUSE 42.3.
>
> I use Squid Cache: Version 3.5.21
>
>
> Squid is working correctly.  It gets and caches images from an online game
> perfectly.  Cached images from Squid get sent to the game very fast making
> it usable.
>
>
> Squid uses all the available internet bandwidth so other users in the
> house get no bandwidth.
>
> I would like Squid to not ever use more than about 50 Kilobytes of
> internet bandwidth.
>
>
> Can spmebody please suggest a soloution?
>
> Thanks,
>
>
> Regards, Terry.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20171228/e0f540e4/attachment.htm>

From sekarit at gmail.com  Fri Dec 29 07:08:32 2017
From: sekarit at gmail.com (Sekar Duraisamy)
Date: Fri, 29 Dec 2017 12:38:32 +0530
Subject: [squid-users] How to enable caching for https websites on Squid
In-Reply-To: <565b24e8-8448-31fb-bc52-123f0536080f@treenet.co.nz>
References: <CADfQnU1Hx16+2DsZQHQjNk0Xat6fNVVhQuWG=TuSzcE9PZ4Xcw@mail.gmail.com>
 <1b1626a3-e210-fad2-2fa3-b80fdadab9b3@treenet.co.nz>
 <20171220122341.GB17304@fantomas.sk>
 <29d95c57-7c83-8790-9d2f-fe42bddba829@treenet.co.nz>
 <20171220134133.GA23710@fantomas.sk>
 <565b24e8-8448-31fb-bc52-123f0536080f@treenet.co.nz>
Message-ID: <CADfQnU3rE+m9992_PbCNrbTePbeNgxirqaBGTb2Vuh1A9AV=-Q@mail.gmail.com>

Hi Amos,

Thanks for your reply .

"To cache encryption protected content you must first remove the
encryption. That destroys the "anonymous" part completely."

Could you please provide little more details about this line about it
destroys the anonymous while we decrypt the encryption and enable
caching for https?

 https caching for anonymous proxy is not recommended?

On Wed, Dec 20, 2017 at 8:42 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> On 21/12/17 02:41, Matus UHLAR - fantomas wrote:
>>>
>>> On 21/12/17 01:23, Matus UHLAR - fantomas wrote:
>>>>
>>>> and I think you should read the last paragraph as:
>>>>
>>>>  "caching often will not happen, since most of web developers don't know
>>>> hot
>>>>   so use and benefit of it thus they try to disable caching globally"
>>
>>
>> On 21.12.17 02:20, Amos Jeffries wrote:
>>>
>>> That is nothing special for HTTPS, it happens worse in regular HTTP.
>>
>>
>> do you want to say that breaking into https can cause http caching more
>> efficient?
>> do you have any evidence of that?
>>
>
> No, I am saying that the problem you pointed at is a _larger_ problem in
> http:// because those dev are having to actively prevent caching. Many are
> also under the false impression that https:// goes end-to-end and caching
> does not happen there other than Browser cache. So those who develop sites
> with HTTPS in mind do not go to quite such extremes to block proxies
> caching.
>
> HTTPS has _other_ problems that impact on caching efficiency.
>
> Amos
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From uhlar at fantomas.sk  Fri Dec 29 09:34:14 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Fri, 29 Dec 2017 10:34:14 +0100
Subject: [squid-users] Limiting amount of Bandwidth Squid gets data from
 the outside internet
In-Reply-To: <1268250978.9858878.1514504295079@mail.yahoo.com>
References: <1268250978.9858878.1514504295079.ref@mail.yahoo.com>
 <1268250978.9858878.1514504295079@mail.yahoo.com>
Message-ID: <20171229093413.GC12921@fantomas.sk>

On 28.12.17 23:38, Emal user wrote:
>My internet connection is 200 KiloBytes a second.

>Squid uses all the available internet bandwidth so other users in the house get no bandwidth.
>
>I would like Squid to not ever use more than about 50 Kilobytes of internet bandwidth.

what other users? Aren't they allowed to use squid? Or aren't they using
squid traffic?

apparently the main problem is that squid opens much more connections that
other users, and TCP streams tend to get equal speed - who opens more
connections, gets more speed.

the correct solution should be router with fair shaping that provides each
user the same bandwidth.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
LSD will make your ECS screen display 16.7 million colors


From uhlar at fantomas.sk  Fri Dec 29 09:47:03 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Fri, 29 Dec 2017 10:47:03 +0100
Subject: [squid-users] How to enable caching for https websites on Squid
In-Reply-To: <CADfQnU3rE+m9992_PbCNrbTePbeNgxirqaBGTb2Vuh1A9AV=-Q@mail.gmail.com>
References: <CADfQnU1Hx16+2DsZQHQjNk0Xat6fNVVhQuWG=TuSzcE9PZ4Xcw@mail.gmail.com>
 <1b1626a3-e210-fad2-2fa3-b80fdadab9b3@treenet.co.nz>
 <20171220122341.GB17304@fantomas.sk>
 <29d95c57-7c83-8790-9d2f-fe42bddba829@treenet.co.nz>
 <20171220134133.GA23710@fantomas.sk>
 <565b24e8-8448-31fb-bc52-123f0536080f@treenet.co.nz>
 <CADfQnU3rE+m9992_PbCNrbTePbeNgxirqaBGTb2Vuh1A9AV=-Q@mail.gmail.com>
Message-ID: <20171229094703.GD12921@fantomas.sk>

On 29.12.17 12:38, Sekar Duraisamy wrote:
>"To cache encryption protected content you must first remove the
>encryption. That destroys the "anonymous" part completely."
>
>Could you please provide little more details about this line about it
>destroys the anonymous while we decrypt the encryption and enable
>caching for https?

the whole point of SSL and HTTPS is that nobody between client (browser) and
the final server knows what's inside. This logically prevents caching, since
you can not know what is the content you are transferring, so you can't know
if you can provide the contant from cache.

you need to break into https - behave as the final server, provide your
own certificate instead (because you can't fake the real server's) and look
into content.

Note that many clients will complain about your certificate - you need to
import your proxy's certificate to clients' browsers to avoid that,

and still, some clients will detect that they are not communicating to
final server and refuse to work (this has been reported a few times here).

> https caching for anonymous proxy is not recommended?

your customer may look anonymous to the world (hidden behind your proxy)
even without breaking HTTPS. 

But by decrypting https they will lose privacy.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Windows found: (R)emove, (E)rase, (D)elete


From sekarit at gmail.com  Fri Dec 29 11:17:11 2017
From: sekarit at gmail.com (Sekar Duraisamy)
Date: Fri, 29 Dec 2017 16:47:11 +0530
Subject: [squid-users] How to enable caching for https websites on Squid
In-Reply-To: <20171229094703.GD12921@fantomas.sk>
References: <CADfQnU1Hx16+2DsZQHQjNk0Xat6fNVVhQuWG=TuSzcE9PZ4Xcw@mail.gmail.com>
 <1b1626a3-e210-fad2-2fa3-b80fdadab9b3@treenet.co.nz>
 <20171220122341.GB17304@fantomas.sk>
 <29d95c57-7c83-8790-9d2f-fe42bddba829@treenet.co.nz>
 <20171220134133.GA23710@fantomas.sk>
 <565b24e8-8448-31fb-bc52-123f0536080f@treenet.co.nz>
 <CADfQnU3rE+m9992_PbCNrbTePbeNgxirqaBGTb2Vuh1A9AV=-Q@mail.gmail.com>
 <20171229094703.GD12921@fantomas.sk>
Message-ID: <CADfQnU2K1-Ek-hV+00f6tO1xJjONmDTcbdf4TYCmLqX7YpoKFg@mail.gmail.com>

Thanks for your reply.

So the same proxy certificate will be expose for all the requests even
though we are sending more requests through load-balancing of more IP
addresses from the server which will be an anonymity risk?


On Fri, Dec 29, 2017 at 3:17 PM, Matus UHLAR - fantomas
<uhlar at fantomas.sk> wrote:
> On 29.12.17 12:38, Sekar Duraisamy wrote:
>>
>> "To cache encryption protected content you must first remove the
>> encryption. That destroys the "anonymous" part completely."
>>
>> Could you please provide little more details about this line about it
>> destroys the anonymous while we decrypt the encryption and enable
>> caching for https?
>
>
> the whole point of SSL and HTTPS is that nobody between client (browser) and
> the final server knows what's inside. This logically prevents caching, since
> you can not know what is the content you are transferring, so you can't know
> if you can provide the contant from cache.
>
> you need to break into https - behave as the final server, provide your
> own certificate instead (because you can't fake the real server's) and look
> into content.
>
> Note that many clients will complain about your certificate - you need to
> import your proxy's certificate to clients' browsers to avoid that,
>
> and still, some clients will detect that they are not communicating to
> final server and refuse to work (this has been reported a few times here).
>
>> https caching for anonymous proxy is not recommended?
>
>
> your customer may look anonymous to the world (hidden behind your proxy)
> even without breaking HTTPS.
> But by decrypting https they will lose privacy.
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> Windows found: (R)emove, (E)rase, (D)elete
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From rejaine at bhz.jamef.com.br  Fri Dec 29 12:00:57 2017
From: rejaine at bhz.jamef.com.br (Rejaine Monteiro)
Date: Fri, 29 Dec 2017 10:00:57 -0200
Subject: [squid-users] Squid high CPU usage after uprade to squid-3.4.4
Message-ID: <1ed23145-add5-cf63-1537-8c967636c506@bhz.jamef.com.br>

Hello people,

We had a server running SLES11 with SQUID-2.1.7and everything has always 
worked very well.

After reinstalled server to OpenSuSE 13.2 with SQUID-3.4.4 (keeping the 
same configuration/squid.conf), the proxy experience high CPU after a 
certain time of use... squid load goes up until it stops responding ...

I run a squid -k reconfigure or reload and everything returns to normal, 
until the load goes up again gradually...

In the cache.log I found this alert:

   | WARNING! Your cache is running out of filedescriptors

Searching, I found a tip asking to increase fs_max_descriptor (both in 
OS and in squid.conf), but I do not know this would be the most correct 
action (I'm still testing) I've also read that this version would have a 
bug and that maybe need to downgrade ...

Does anyone confirm whether there is a bug in this version or if there 
is any other configuration tip to solve this problem definitively?

Thank you very much in advance!





From eduardoocarneiro at gmail.com  Fri Dec 29 12:30:55 2017
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Fri, 29 Dec 2017 05:30:55 -0700 (MST)
Subject: [squid-users] Squid high CPU usage after uprade to squid-3.4.4
In-Reply-To: <1ed23145-add5-cf63-1537-8c967636c506@bhz.jamef.com.br>
References: <1ed23145-add5-cf63-1537-8c967636c506@bhz.jamef.com.br>
Message-ID: <1514550655372-0.post@n4.nabble.com>

Hello Rejaine. First of all, are you Brazilian? It's always good to have
Brazilians around here. :D

About your issue, squid.conf's "max_filedescriptors" parameter will solve
your problem. Due to the large number of hits that I have, I also had to
increase the number of squid's file descriptors.

I also remember that you need to increase the number of descriptors in both
Squid and the Operating System.

I use Ubuntu and I had to change the /etc/sysctl.conf and
/etc/security/limits.conf.

I hope I've helped!



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rejaine at bhz.jamef.com.br  Fri Dec 29 13:46:41 2017
From: rejaine at bhz.jamef.com.br (Rejaine Monteiro)
Date: Fri, 29 Dec 2017 11:46:41 -0200
Subject: [squid-users] Squid high CPU usage after uprade to squid-3.4.4
In-Reply-To: <1514550655372-0.post@n4.nabble.com>
References: <1ed23145-add5-cf63-1537-8c967636c506@bhz.jamef.com.br>
 <1514550655372-0.post@n4.nabble.com>
Message-ID: <dd1d5879-2130-bf15-41e3-e55f7148dfaa@bhz.jamef.com.br>


Hi Eduardo, yes i'm brazilian, from Belo Horizonte / MG

I increased the value of max_filedescriptors "in squid.conf to 409 and 
put  in /etc/security/limits.conf the following configuration:

squid     hard  nofile    4096
squid     soft    nofile    4096

And run a 'ulimit -n 4096' to changevalue globaly without reboot

The /proc/sys/fs/file-max is 6557385, so I think dont need to increase 
it ..

Now I will follow up and see if that solves ..

Thank you for your attention!
Em 29-12-2017 10:30, Eduardo Carneiro escreveu:
> Hello Rejaine. First of all, are you Brazilian? It's always good to have
> Brazilians around here. :D
>
> About your issue, squid.conf's "max_filedescriptors" parameter will solve
> your problem. Due to the large number of hits that I have, I also had to
> increase the number of squid's file descriptors.
>
> I also remember that you need to increase the number of descriptors in both
> Squid and the Operating System.
>
> I use Ubuntu and I had to change the /etc/sysctl.conf and
> /etc/security/limits.conf.
>
> I hope I've helped!
>
>
>
> --
> Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Rejaine da Silveira Monteiro
Suporte - Tecnologia Digital
Tel: (31) 2102-8854
Jamef Encomendas Urgentes - Matriz - Belo Horizonte/MG
www.jamef.com.br



From eduardoocarneiro at gmail.com  Fri Dec 29 14:04:08 2017
From: eduardoocarneiro at gmail.com (Eduardo Carneiro)
Date: Fri, 29 Dec 2017 07:04:08 -0700 (MST)
Subject: [squid-users] Squid high CPU usage after uprade to squid-3.4.4
In-Reply-To: <dd1d5879-2130-bf15-41e3-e55f7148dfaa@bhz.jamef.com.br>
References: <1ed23145-add5-cf63-1537-8c967636c506@bhz.jamef.com.br>
 <1514550655372-0.post@n4.nabble.com>
 <dd1d5879-2130-bf15-41e3-e55f7148dfaa@bhz.jamef.com.br>
Message-ID: <1514556248545-0.post@n4.nabble.com>

Ok Rejaine. Remember to use squidclient to see the amount of real-time used
file descriptors:

# squidclient -h localhost -p 8080 mgr:info | grep "file descriptors"

So you increment as needed


Eduardo Carneiro



--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From rejaine at bhz.jamef.com.br  Fri Dec 29 14:09:34 2017
From: rejaine at bhz.jamef.com.br (Rejaine Monteiro)
Date: Fri, 29 Dec 2017 12:09:34 -0200
Subject: [squid-users] Squid high CPU usage after uprade to squid-3.4.4
In-Reply-To: <1514556248545-0.post@n4.nabble.com>
References: <1ed23145-add5-cf63-1537-8c967636c506@bhz.jamef.com.br>
 <1514550655372-0.post@n4.nabble.com>
 <dd1d5879-2130-bf15-41e3-e55f7148dfaa@bhz.jamef.com.br>
 <1514556248545-0.post@n4.nabble.com>
Message-ID: <01b3fd81-4199-e2a3-f19d-a20d833a507d@bhz.jamef.com.br>


Okay, I'll do that, thanks for the tips!


Em 29-12-2017 12:04, Eduardo Carneiro escreveu:
> Ok Rejaine. Remember to use squidclient to see the amount of real-time used
> file descriptors:
>
> # squidclient -h localhost -p 8080 mgr:info | grep "file descriptors"
>
> So you increment as needed
>
>
> Eduardo Carneiro
>
>
>
> --
> Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-- 
Rejaine da Silveira Monteiro
Suporte - Tecnologia Digital
Tel: (31) 2102-8854
Jamef Encomendas Urgentes - Matriz - Belo Horizonte/MG
www.jamef.com.br



From rousskov at measurement-factory.com  Fri Dec 29 15:57:37 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 29 Dec 2017 08:57:37 -0700
Subject: [squid-users] Squid high CPU usage after uprade to squid-3.4.4
In-Reply-To: <1ed23145-add5-cf63-1537-8c967636c506@bhz.jamef.com.br>
References: <1ed23145-add5-cf63-1537-8c967636c506@bhz.jamef.com.br>
Message-ID: <c7ca1235-4585-f109-67f8-3c93abbd93f8@measurement-factory.com>

On 12/29/2017 05:00 AM, Rejaine Monteiro wrote:

> After reinstalled server to OpenSuSE 13.2 with SQUID-3.4.4

Please note that you are upgrading to an unsupported and rather buggy
Squid version. It is your decision which Squid version to run, and I
understand that it may be easier to run what your OS provides, but
please do take the lack of the official v3.4 support into account when
making that decision.

Please also note that Squid v3+ is "slower" (i.e., needs more resources
to handle the same amount of traffic) than Squid v2- in many environments.

Alex.


From ermalwa1 at gmail.com  Fri Dec 29 16:32:38 2017
From: ermalwa1 at gmail.com (squidnoob)
Date: Fri, 29 Dec 2017 09:32:38 -0700 (MST)
Subject: [squid-users] Help with UA filtering in https connections
In-Reply-To: <ecaab75f-7375-b641-0fea-582be9e33669@measurement-factory.com>
References: <1514501960304-0.post@n4.nabble.com>
 <ecaab75f-7375-b641-0fea-582be9e33669@measurement-factory.com>
Message-ID: <1514565158717-0.post@n4.nabble.com>

Ahh that's it! Thank you for your help!

For anyone interested, i'm posting the working config i'm using. Hopefully
this helps someone.


#
# Working on squid version: 3.5.23
#
# The general purpose of this configuration is:
# - only allow a set of whitelisted domains through the proxy
# - option to allow specific browser user agents to bypass the domains
whitelist
# - option to allow specific hosts to bypass the domains whitelist
# - option to allow speicfic host + user agent to bypass the domains
whitelist
#
# Useful in a restricted environment, like a server environment with
restricted egress requirements.
# 
# Requirements for this to work properly
# 
# On proxy host: 
#   iptables rules to support redirection to appropriate ports
#     iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port
3129
#     iptables -t nat -A PREROUTING -p tcp --dport 443 -j REDIRECT --to-port
3130
#
#   Self-signed cert route:
#     openssl req -newkey rsa:4096 -x509 -keyout
/etc/squid/ssl_cert/mySquidCA.pem -out /etc/squid/mySquidCA.pem -days 1825
-nodes
# 
# On clients
#   For self-signed cert route:
#     Add public key of mySquidCA cert to appropriate stores
#     e.g. Ubuntu 16.04, add public key of the .pem file to:
/usr/local/share/ca-certificates/mySquidCA.crt and then run sudo
update-ca-certs
#
#     If running python, may need to update appropriate package cert stores:
#     e.g. /usr/local/lib/python2.7/dist-packages/requests/cacert.pem
#
# Refs
#   - install 3.5.23:
https://docs.diladele.com/howtos/build_squid_ubuntu16/index.html
#   - example:
https://aws.amazon.com/blogs/security/how-to-add-dns-filtering-to-your-nat-instance-with-squid/ 
#   - http://www.squid-cache.org/Doc/
# 

visible_hostname squid

# The default log formats available (which do not need re-defining) are:
#logformat combined   %>a %[ui %[un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st
"%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
access_log daemon:/var/log/squid/access.log combined


# acls for ports allowed
acl safe_ports port 80          # http
acl safe_ports port 443         # https

# acl for whitelisting domains
acl whitelist_domains dstdomain "/etc/squid/whitelist_domains.txt"

# acl for browser user agents 
acl useragent_bypass browser "/etc/squid/useragents_bypass_regex.txt"

# acl for hosts
acl host_bypass src "/etc/squid/hosts_bypass.txt"

# acls for use with host AND user agent combo rule
acl host_and_useragent_ualist_bypass browser
"/etc/squid/host_AND_useragent_useragentlist_bypass.txt"
acl host_and_useragent_hostlist_bypass src
"/etc/squid/host_AND_useragent_hostlist_bypass.txt"


acl CONNECT method CONNECT



#Handling HTTP requests
#http_port 3128         # will need this live for squid v4
http_port 3129 intercept

#Handling HTTPS requests
# transparent proxy option
#https_port 3130 cert=/etc/squid/ssl/squid.pem ssl-bump intercept

# full ssl intercept option
https_port 3130 ssl-bump intercept cert=/etc/squid/ssl_cert/mySquidCA.pem
generate-host-certificates=on dynamic_cert_mem_cache_size=10MB
sslcrtd_program /usr/lib/squid/ssl_crtd -s /var/lib/ssl_db -M 10MB

# for ver 4.x
#sslcrtd_program /usr/lib/squid/security_file_certgen -s /var/lib/ssl_db -M
10MB


# bump everything 
ssl_bump stare all
ssl_bump bump all

# delay filtering decisions until we get to bumped requests 
http_access allow CONNECT safe_ports
http_access deny CONNECT

# filter plain and bumped requests 
# allow specified hosts to bypass
http_access allow host_bypass

# allow specified useragents to bypass
http_access allow useragent_bypass

# allow combo of host + useragent to bypass
http_access allow host_and_useragent_ualist_bypass
host_and_useragent_hostlist_bypass

# allow only whitelisted domains if above rules haven't bypassed it yet
http_access allow whitelist_domains

# finally, deny all other access to this proxy
http_access deny all




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


From ermalwa1 at gmail.com  Fri Dec 29 16:35:02 2017
From: ermalwa1 at gmail.com (squidnoob)
Date: Fri, 29 Dec 2017 09:35:02 -0700 (MST)
Subject: [squid-users] Help with UA filtering in https connections
In-Reply-To: <dad757a8179e1e4ef8859849659d097e@treenet.co.nz>
References: <1514501960304-0.post@n4.nabble.com>
 <dad757a8179e1e4ef8859849659d097e@treenet.co.nz>
Message-ID: <1514565302230-0.post@n4.nabble.com>

Yes to clarify, this is basically trying to filter server egress traffic to
the internet. It's not for internal server to other internal server traffic. 




--
Sent from: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-Users-f1019091.html


