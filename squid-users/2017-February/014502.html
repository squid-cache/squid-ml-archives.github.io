<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<HTML>
 <HEAD>
   <TITLE> [squid-users] help me optimising caching or increasing hit ratio
   </TITLE>
   <LINK REL="Index" HREF="index.html" >
   <LINK REL="made" HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20help%20me%20optimising%20caching%20or%20increasing%20hit%20ratio&In-Reply-To=%3Cf8e2e882-b9b7-6461-3233-dddd5fbcba9b%40treenet.co.nz%3E">
   <META NAME="robots" CONTENT="index,nofollow">
   <style type="text/css">
       pre {
           white-space: pre-wrap;       /* css-2.1, curent FF, Opera, Safari */
           }
   </style>
   <META http-equiv="Content-Type" content="text/html; charset=us-ascii">
   <LINK REL="Previous"  HREF="014498.html">
   <LINK REL="Next"  HREF="014515.html">
 </HEAD>
 <BODY BGCOLOR="#ffffff">
   <H1>[squid-users] help me optimising caching or increasing hit ratio</H1>
    <B>Amos Jeffries</B> 
    <A HREF="mailto:squid-users%40lists.squid-cache.org?Subject=Re%3A%20%5Bsquid-users%5D%20help%20me%20optimising%20caching%20or%20increasing%20hit%20ratio&In-Reply-To=%3Cf8e2e882-b9b7-6461-3233-dddd5fbcba9b%40treenet.co.nz%3E"
       TITLE="[squid-users] help me optimising caching or increasing hit ratio">squid3 at treenet.co.nz
       </A><BR>
    <I>Tue Feb 21 21:57:47 UTC 2017</I>
    <P><UL>
        <LI>Previous message (by thread): <A HREF="014498.html">[squid-users] help me optimising caching or increasing hit ratio
</A></li>
        <LI>Next message (by thread): <A HREF="014515.html">[squid-users] help me optimising caching or increasing hit ratio
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#14502">[ date ]</a>
              <a href="thread.html#14502">[ thread ]</a>
              <a href="subject.html#14502">[ subject ]</a>
              <a href="author.html#14502">[ author ]</a>
         </LI>
       </UL>
    <HR>  
<!--beginarticle-->
<PRE>On 22/02/2017 3:42 a.m., --Ahmad-- wrote:
&gt;<i> I&#8217;m using squid 3.5.2
</I>
Please ugrade to at least 3.5.19 (current release is 3.5.24). There have
been quite a few security issues fixed, and the 3.5 does caching a *lot*
better than it did in those early releases.


&gt;<i> and I&#8217;m browsing the same website many times but no &#8220;HIT&#8221; in logs !!!
</I>&gt;<i> 
</I>&gt;<i> already enabled https and cert imported .
</I>&gt;<i> 
</I>&gt;<i> plz help me why i don&#8217;t see HITs in my access.log ?
</I>&gt;<i> 
</I>

3.5 supports HTTP/1.1 caching nowdays. The days of determining
performance from &quot;HIT&quot; being in the logs is long ago past - majority of
cached data transactison involves &quot;REFRESH&quot; actions these days.

If you want to see what your caching performance is like you need to use
a log analysis tool that understands the REFRESH codes, or use the
cachemgr 'info' report summary of HIT-ratio's.


&gt;<i> there are some sites I&#8217;m very interested with like ==&gt; <A HREF="https://www.ruzivodigitallearning.co.zw.com">https://www.ruzivodigitallearning.co.zw.com</A>
</I>&gt;<i> 
</I>&gt;<i> plz have a look on my config below and advise me with best options to optimise caching and hit ratio increase
</I>&gt;<i> 
</I>&gt;<i> cheers 
</I>&gt;<i> 
</I>&gt;<i> ==============
</I>&gt;<i> here is my config 
</I>&gt;<i> <A HREF="https://lists.squid-cache.org/listinfo/squid-users">root at portablecloud-3011</A>:~# cat /etc/squid/squid.conf
</I>&gt;<i> acl wu dstdom_regex \.download\.windowsupdate\.com$
</I>&gt;<i> acl wu-rejects dstdom_regex stats
</I>&gt;<i> acl GET method GET
</I>&gt;<i> cache_peer 127.0.0.1 parent 8080 0 proxy-only no-tproxy no-digest no-query no-netdb-exchange name=ms1
</I>&gt;<i> cache_peer_access ms1 allow GET wu !wu-rejects
</I>&gt;<i> cache_peer_access ms1 deny all
</I>&gt;<i> never_direct allow GET wu !wu-rejects
</I>&gt;<i> never_direct deny all
</I>&gt;<i> 
</I>&gt;<i> ########################################
</I>&gt;<i> visible_hostname pcloud
</I>&gt;<i> acl ip1 myip 10.1.0.1
</I>&gt;<i> acl ip2 myip 192.168.10.210
</I>&gt;<i> tcp_outgoing_address 192.168.10.210 ip1
</I>&gt;<i> tcp_outgoing_address 192.168.10.210 ip2
</I>&gt;<i> #
</I>&gt;<i> # Recommended minimum configuration:
</I>&gt;<i> #
</I>&gt;<i> 
</I>&gt;<i> # Example rule allowing access from your local networks.
</I>&gt;<i> # Adapt to list your (internal) IP networks from where browsing
</I>&gt;<i> # should be allowed
</I>&gt;<i> acl localnet src 10.0.0.0/8     # RFC1918 possible internal network
</I>&gt;<i> acl localnet src 172.16.0.0/12  # RFC1918 possible internal network
</I>&gt;<i> acl localnet src 192.168.0.0/16 # RFC1918 possible internal network
</I>&gt;<i> acl localnet src fc00::/7       # RFC 4193 local private network range
</I>&gt;<i> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) machines
</I>&gt;<i> 
</I>&gt;<i> acl SSL_ports port 443
</I>&gt;<i> acl Safe_ports port 80          # http
</I>&gt;<i> acl Safe_ports port 21          # ftp
</I>&gt;<i> acl Safe_ports port 443         # https
</I>&gt;<i> acl Safe_ports port 70          # gopher
</I>&gt;<i> acl Safe_ports port 210         # wais
</I>&gt;<i> acl Safe_ports port 1025-65535  # unregistered ports
</I>&gt;<i> acl Safe_ports port 280         # http-mgmt
</I>&gt;<i> acl Safe_ports port 488         # gss-http
</I>&gt;<i> acl Safe_ports port 591         # filemaker
</I>&gt;<i> acl Safe_ports port 777         # multiling http
</I>&gt;<i> acl CONNECT method CONNECT
</I>&gt;<i> 
</I>&gt;<i> #
</I>&gt;<i> # Recommended minimum Access Permission configuration:
</I>&gt;<i> #
</I>&gt;<i> # Deny requests to certain unsafe ports
</I>&gt;<i> http_access deny !Safe_ports
</I>&gt;<i> 
</I>&gt;<i> # Deny CONNECT to other than secure SSL ports
</I>&gt;<i> http_access deny CONNECT !SSL_ports
</I>&gt;<i> http_access allow  CONNECT 
</I>&gt;<i> # Only allow cachemgr access from localhost
</I>&gt;<i> http_access allow localhost manager
</I>&gt;<i> http_access deny manager
</I>&gt;<i> 
</I>&gt;<i> # We strongly recommend the following be uncommented to protect innocent
</I>&gt;<i> # web applications running on the proxy server who think the only
</I>&gt;<i> # one who can access services on &quot;localhost&quot; is a local user
</I>&gt;<i> #http_access deny to_localhost
</I>&gt;<i> 
</I>&gt;<i> #
</I>&gt;<i> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
</I>&gt;<i> #
</I>&gt;<i> 
</I>&gt;<i> # Example rule allowing access from your local networks.
</I>&gt;<i> # Adapt localnet in the ACL section to list your (internal) IP networks
</I>&gt;<i> # from where browsing should be allowed
</I>&gt;<i> http_access allow localnet
</I>&gt;<i> http_access allow localhost
</I>&gt;<i> 
</I>&gt;<i> # And finally deny all other access to this proxy
</I>&gt;<i> http_access deny all
</I>&gt;<i> 
</I>&gt;<i> # Squid normally listens to port 3128
</I>&gt;<i> http_port 3128
</I>&gt;<i> 
</I>&gt;<i> # Uncomment and adjust the following to add a disk cache directory.
</I>&gt;<i> #cache_dir ufs /var/cache/squid 100 16 256
</I>&gt;<i> 
</I>&gt;<i> # Leave coredumps in the first cache dir
</I>&gt;<i> #coredump_dir /var/cache/squid
</I>&gt;<i> 
</I>&gt;<i> #
</I>&gt;<i> # Add any of your own refresh_pattern entries above these.
</I>&gt;<i> #
</I>
Please note what that line says &quot;above&quot;. It is the default config
comment for the final three refresh_pattern lines way, way down below.
 You can either erase it entirely, or move it back to its proper
position under your custom patterns.


Also, a note on the % values in all the refresh_pattern lines;

 One of the reasons to upgrade is that they are actually better when
used with values &gt;100%. Some releases before 3.5.12 complained about the
% incorrectly. That bug has been fixed in the current Squid versions.

 For example; An object which is 2 hours old having a 100% pt value
configured. Has an LMF calculation indicating its cacheable for 2hrs
from time received. This sounds great, but a lot of traffic is quote
young, ie. milliseconds, and 100% of a few milliseconds is not very much
time before the object needs updating again. Values upwards to 1000% may
be useful in a busy proxy cache.



&gt;<i> #
</I>&gt;<i> refresh_pattern -i \.htm 120 50% 10080 reload-into-ims
</I>&gt;<i> refresh_pattern -i \.html 120 50% 10080 reload-into-ims
</I>&gt;<i> refresh_pattern ^<A HREF="http://*.facebook.com/*">http://*.facebook.com/*</A> 720 100% 4320
</I>
Where did you copy-and-paste these patterns from? they are all very,
very broken. The above will not match what you probably think it does.

1) The &quot;/*.&quot; near the start means 0 or more _slash_ ('/') characters
followed by _only one_ character whose existence is mandatory but can
have any value.


 How many URLs you seen with &quot;http:/blah&quot; or &quot;<A HREF="http:///////blah">http:///////blah</A>&quot; ?

 If this &quot;works&quot; at all it is probably because the regex library
interprets the facebook URL as having 0 '/' characters for (3) and one
charater (a '/') for the mandatory position.

AFAIK a regex library that does that is buggy though. So I think this
line will never match unless you are being passed phishing-like attack
URLs where the domain &quot;facebook.com&quot; is prefixed with some obscure
character like &quot;1facebook.com&quot; to fool people into clicking links
thinking its Facebook.

The '*' at the end also means 0 or more '/' characters. This is
pointless in terms of being a wildcard. There is an implicit '.*'
pattern at the ends unless you use the special anchor code '$' to mark
the URL ending.
 But this pattern does not need that either. So you might as well erase
the whole '/*' part on the end.

Worst case you might be thinking this pattern matches only
&quot;facebook.com&quot; domain name because the domain is followed by a '/'.
  However since the final '*' allows omitting that '/' delimiter this
pattern _actually_ matches any URL with a *subdomain* similar to
&quot;.facebook.com&quot;

Such as &quot;<A HREF="http://_facebook_com.example.com.bwaahahaha/">http://_facebook_com.example.com.bwaahahaha/</A>&quot;


==&gt; If that was the behaviour you actually wanted, fair enough. But I
suggest in that case adding a comment to say it is there to catch some
attack URLs, not actual facebook.com traffic.

To retain the current behaviour the correct pattern should be:
  ^<A HREF="http://*.facebook.com">http://*.facebook.com</A>

To fix the behaviour to only match facebook.com and sub-domains, the
correct pattern would be:
  ^<A HREF="http://.*\.facebook\.com/">http://.*\.facebook\.com/</A>

Also, I suggest adding 's?' after the '^http' bit (as demo'd below), so
the one pattern matches both HTTP and HTTPS URLs.

Also, I suggest using the -i flag. Scheme and domain are
case-insensitive URL segments. Squid should be normalizing them to lower
case, but may not.


&gt;<i> refresh_pattern ^<A HREF="https://*.ruzivodigitallearning.co.zw.com/*">https://*.ruzivodigitallearning.co.zw.com/*</A> 720 100% 4320
</I>&gt;<i> refresh_pattern ^<A HREF="http://*.ruzivodigitallearning.co.zw.com/*">http://*.ruzivodigitallearning.co.zw.com/*</A> 720 100% 4320
</I>
You can merge the above two lines into one by using the regex pattern:

  ^https?://.*\.ruzivodigitallearning\.co\.zw\.com/

Note that I have corrected for the same issues the facebook pattern had.

BTW: is that .com supposed to be there? I looked up the URL in redbot to
check cachability and the .com was not found, but there is a .co.zw ccTLD.


&gt;<i> refresh_pattern ^<A HREF="http://mail.yahoo.com/.*">http://mail.yahoo.com/.*</A> 720 100% 4320
</I>&gt;<i> refresh_pattern ^<A HREF="http://*.yahoo.*/.*">http://*.yahoo.*/.*</A> 720 100% 4320
</I>&gt;<i> refresh_pattern ^<A HREF="http://*.yimg.*/.*">http://*.yimg.*/.*</A> 720 100% 4320
</I>&gt;<i> refresh_pattern ^<A HREF="http://*.gmail.*/.*">http://*.gmail.*/.*</A> 720 100% 4320
</I>&gt;<i> refresh_pattern ^<A HREF="http://*.google.*/.*">http://*.google.*/.*</A> 720 100% 4320
</I>&gt;<i> refresh_pattern ^<A HREF="http://*.kaskus.*/.*">http://*.kaskus.*/.*</A> 720 100% 4320
</I>&gt;<i> refresh_pattern ^<A HREF="http://*.googlesyndication.*/.*">http://*.googlesyndication.*/.*</A> 720 100% 4320
</I>&gt;<i> refresh_pattern ^<A HREF="http://*.plasa.*/.*">http://*.plasa.*/.*</A> 720 100% 4320
</I>&gt;<i> refresh_pattern ^<A HREF="http://*.telkom.*/.*">http://*.telkom.*/.*</A> 720 100% 4320
</I>
A useful rule of thumb is that fewer refresh_pattern lines leads to
better peformance.

So a redux of the above into a single regex pattern will be faster. Do
it with (a|b|c) compounding like the &quot;file extension&quot; patterns below.



If you want to improve performance remove all the override-lastmod.
Last-Modified is part of HTTP/1.1 which lets Squid perform fast
revalidation - without it some (most?) things can only MISS, and it
breaks the reload-into-ims operations.

Simplify your config by removing all the 'ignore-no-cache'. It has no
effect since Squid-3.2

Also, I recommend removing the ignore-private. Squid-3.5 can store the
data relatively safely, but if the revalidation does not work well it
can also lead to users manualy forcing reloads.



&gt;<i> ##################################################
</I>&gt;<i> refresh_pattern -i \.fbcdn.net.*\.(jpg|gif|png|swf|mp3)                  10800 80% 10800 ignore-reload  override-expire ignore-no-cache
</I>&gt;<i> refresh_pattern  static\.ak\.fbcdn\.net*\.(jpg|gif|png)                  10800 80% 10800 ignore-reload  override-expire ignore-no-cache
</I>&gt;<i> refresh_pattern ^http:\/\/profile\.ak\.fbcdn.net*\.(jpg|gif|png)      10800 80% 10800 ignore-reload  override-expire ignore-no-cache
</I>
Er. these last two lines are sub-sets of the tope line. I think you can
erase those 'static' and 'profile' lines.


Also, once you remove the overrides as mentioend above. You are left
with &quot;reload-into-ims&quot; as the only difference between the parameters of
patterns above and the patterns below which match those same
file-extensions. So you can probably improve performance a bit more by
just erasing the above lines.

However, before they went all-HTTPS facebook were becoming one of the
better sites in terms of HTTP cacheability. I do not think that has
changed, its just the HTTPS/TLS wrapper preventing most of their traffic
going to caches now.
 So override-expires is probably making things *worse* for all that
fbcdn traffic nowdays.


&gt;<i> ##############
</I>&gt;<i> refresh_pattern -i \.(3gp|7z|ace|asx|avi|bin|cab|dat|deb|divx|dvr-ms)      10800 80% 10800 ignore-no-cache  ignore-private override-expire override-lastmod reload-into-ims
</I>&gt;<i> refresh_pattern -i \.(rar|jar|gz|tgz|bz2|iso|m1v|m2(v|p)|mo(d|v))          10800 80% 10800 ignore-no-cache  ignore-private override-expire override-lastmod reload-into-ims
</I>&gt;<i> refresh_pattern -i \.(jp(e?g|e|2)|gif|pn[pg]|bm?|tiff?|ico|swf|css|js)     10800 80% 10800 ignore-no-cache  ignore-private override-expire override-lastmod reload-into-ims
</I>&gt;<i> refresh_pattern -i \.(mp(e?g|a|e|1|2|3|4)|mk(a|v)|ms(i|u|p)|og(x|v|a|g)|rar|rm|r(a|p)m|snd|vob|wav) 10800 80% 10800 ignore-no-cache ignore-private override-expire override-lastmod reload-into-ims
</I>&gt;<i> refresh_pattern -i \.(pp(s|t)|wax|wm(a|v)|wmx|wpl|zip|cb(r|z|t))     10800 80% 10800 ignore-no-cache ignore-private override-expire override-lastmod reload-into-ims
</I>
Something to beware of:
 The above patterns will match *anywhere* within the whole URL.

So the start of domain names (aka &quot;www.raring.com&quot; -&gt; \.rar ) will be
cached using these refresh parameters.
 As will any URL that happens to have a similar match in the
query-string portion. That is kind of useful if there is a filename in
the query parameters, but also dangerous since you cannot know when or
where that matching will happen.
 Note that you are caching *private* responses whenever one of these
matches. The risk you are taking is large.

If that is a problem, you can work around it by adjusting the patterns
like this:
 ^https?://[^/]+/[^?]+\.(rar|jar|gz|tgz|bz2|iso|m1v|m2(v|p)|mo(d|v))

NP: If you like them to still match inside the query portion of URLs
replace the &quot;[^?]&quot; with a dot &quot;.&quot;


PS. 'rar' is listed in the 2nd and 4th lines. One of them is redundant.



&gt;<i>  #############################
</I>&gt;<i> refresh_pattern (cgi-bin|\?)       0      0%      0
</I>
This above regex is broken. It requires the -i and the '/' path
delimiters as seen in the below refresh_pattern lines for the correct
CGI regex.


&gt;<i> refresh_pattern ^gopher:    1440    0%    1440
</I>&gt;<i> refresh_pattern ^ftp:         10080     95%     10800 override-lastmod reload-into-ims
</I>&gt;<i> refresh_pattern         .     180     95% 10800 override-lastmod reload-into-ims
</I>&gt;<i> #################
</I>&gt;<i> minimum_object_size 0 bytes
</I>&gt;<i> maximum_object_size_in_memory 500 MB
</I>
You have placed alternative ftp, gopher and '.' refresh_patterns above.
Remove the below refresh_pattern lines.

&gt;<i> refresh_pattern ^ftp:           1440    20%     10080
</I>&gt;<i> refresh_pattern ^gopher:        1440    0%      1440
</I>&gt;<i> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
</I>&gt;<i> refresh_pattern .               0       20%     4320
</I>&gt;<i> 
</I>&gt;<i> http_port 3126
</I>&gt;<i> #http_port 3128
</I>&gt;<i> #######################################
</I>&gt;<i> cache_swap_low 90
</I>&gt;<i> cache_swap_high 95
</I>&gt;<i> ############################
</I>&gt;<i> cache_effective_user squid
</I>&gt;<i> cache_effective_group squid
</I>&gt;<i> memory_replacement_policy lru
</I>&gt;<i> cache_replacement_policy heap LFUDA
</I>&gt;<i> ########################
</I>&gt;<i> maximum_object_size 10000 MB
</I>&gt;<i> cache_mem 5000 MB
</I>&gt;<i> maximum_object_size_in_memory 10 MB
</I>&gt;<i> #########################
</I>&gt;<i> logfile_rotate 2
</I>&gt;<i> max_filedescriptors 131072
</I>&gt;<i> ###############################
</I>&gt;<i> #cache_dir ufs /root/cache3 600000 64 128
</I>&gt;<i> ############
</I>&gt;<i> cache_dir aufs /var/cache/squid 600000 64 128
</I>

Amos


</PRE>

<!--endarticle-->
    <HR>
    <P><UL>
        <!--threads-->
	<LI>Previous message (by thread): <A HREF="014498.html">[squid-users] help me optimising caching or increasing hit ratio
</A></li>
	<LI>Next message (by thread): <A HREF="014515.html">[squid-users] help me optimising caching or increasing hit ratio
</A></li>
         <LI> <B>Messages sorted by:</B> 
              <a href="date.html#14502">[ date ]</a>
              <a href="thread.html#14502">[ thread ]</a>
              <a href="subject.html#14502">[ subject ]</a>
              <a href="author.html#14502">[ author ]</a>
         </LI>
       </UL>

<hr>
<a href="https://lists.squid-cache.org/listinfo/squid-users">More information about the squid-users
mailing list</a><br>
</body></html>
