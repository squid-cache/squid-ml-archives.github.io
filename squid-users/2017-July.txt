From sadegian at gmail.com  Sat Jul  1 10:48:49 2017
From: sadegian at gmail.com (nima sadeghian)
Date: Sat, 1 Jul 2017 14:18:49 +0330
Subject: [squid-users] No DNS Records Error
Message-ID: <CACocj3W=gmFat0AOJ6bRCM3cEQbiJ9LuR=8hnaUjE+GFefJ16A@mail.gmail.com>

Hi
a few days ago working properly squid server ( for more than 15 years)
suddenly got a ERROR in user sides.
they can`t open any site and get NO DNS RECORDS error on browser.
after restarting squid service for a little short time squid works but
after that there is no site browsing.
Squid Service works on ubuntu box too but no browsing.
why it can happen suddenly without any change to server?
regards
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170701/bd8cfdf2/attachment.htm>

From Antony.Stone at squid.open.source.it  Sat Jul  1 11:11:16 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Sat, 1 Jul 2017 13:11:16 +0200
Subject: [squid-users] No DNS Records Error
In-Reply-To: <CACocj3W=gmFat0AOJ6bRCM3cEQbiJ9LuR=8hnaUjE+GFefJ16A@mail.gmail.com>
References: <CACocj3W=gmFat0AOJ6bRCM3cEQbiJ9LuR=8hnaUjE+GFefJ16A@mail.gmail.com>
Message-ID: <201707011311.16483.Antony.Stone@squid.open.source.it>

On Saturday 01 July 2017 at 12:48:49, nima sadeghian wrote:

> Hi
> a few days ago working properly squid server ( for more than 15 years)

Has Squid been upgraded during that time?

What version is it running, and on what operating system / version?

> suddenly got a ERROR in user sides.
> they can`t open any site and get NO DNS RECORDS error on browser.

Where do the user machines point to for DNS resolution?

> after restarting squid service for a little short time squid works but
> after that there is no site browsing.

What makes you think that a DNS resolution problem is caused by Squid, and 
that restarting Squid might help?

> Squid Service works on ubuntu box too but no browsing.

What do you mean by "Squid works" "but no browsing"?  What does "Squid works" 
mean if people cannot browser websites?

> why it can happen suddenly without any change to server?

I would guess there has been a change elsewhere.


1. Does web browsing work if you bypass Squid and connect to the Internet 
directly?

2. What are the user machines pointing at for their DNS resolution?

3. What does the Squid machine point to for its DNS resolution?

4. Can you resolve hostnames at the command line on the Squid machine?

5. Give us a bit of information about your network - what's the IP address of 
the Squid server, how does it connect to the Internet, what's the IP range of 
your client machines, what are you using for a router, do you run your own DNS 
server on the network, anything else you think might be helpful.


Regards,


Antony.

-- 
I bought a book about anti-gravity.  The reviews say you can't put it down.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From enghooda at yandex.com  Sat Jul  1 20:55:03 2017
From: enghooda at yandex.com (Eng Hooda)
Date: Sat, 01 Jul 2017 22:55:03 +0200
Subject: [squid-users] =?utf-8?q?=28no_subject=29?=
Message-ID: <4666591498942503@web40j.yandex.ru>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170701/e174717b/attachment.htm>

From enghooda at yandex.com  Sat Jul  1 20:58:09 2017
From: enghooda at yandex.com (Eng Hooda)
Date: Sat, 01 Jul 2017 22:58:09 +0200
Subject: [squid-users] Squid and active directory
In-Reply-To: <4666591498942503@web40j.yandex.ru>
Message-ID: <4486631498942689@web9g.yandex.ru>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170701/f2fc9aa9/attachment.htm>

From yvoinov at gmail.com  Sat Jul  1 21:28:08 2017
From: yvoinov at gmail.com (Yuri)
Date: Sun, 2 Jul 2017 03:28:08 +0600
Subject: [squid-users] Squid and active directory
In-Reply-To: <4486631498942689@web9g.yandex.ru>
References: <4486631498942689@web9g.yandex.ru>
Message-ID: <e2095509-5f82-84f7-0efb-73693e3172d4@gmail.com>

http://www.squid-cache.org/Versions/v3/3.1/manuals/squid_ldap_group.html

http://lists.squid-cache.org/pipermail/squid-users/2015-October/007445.html

http://www.squid-cache.org/mail-archive/squid-users/200210/0725.html

http://www.squid-cache.org/mail-archive/squid-users/200309/0053.html

http://wiki.squid-cache.org/ConfigExamples/Authenticate/WindowsActiveDirectory

This, heh?


02.07.2017 2:58, Eng Hooda ?????:
> Hello Every Body,
> I am trying to get squid3 (latest on debain 8 repositories ) to
> authenticate clients using active directory .
>  
> I used the tutorial recommend for debian :
> http://wiki.bitbinary.com/index.php/Active_Directory_Integrated_Squid_Proxy#Configure_Squid
>  
> and after a lot of tweaks to several steps machine joined the domain
> and now what remains is configuring squid .
>  
> I installed negotiate_wrapper as described .
>  
> But the file required :
>  
> /usr/lib/squid3/squid_ldap_group 
> is not present in the path specified.
>  
> I searched a lot for an updated tutorial without luck.
>  
> Any ideas ?
>  
> Thanks and BR.
>  
> Eng Hooda
>  
> -------- End of forwarded message --------
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170702/44ddfd3d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170702/44ddfd3d/attachment.sig>

From rafael.akchurin at diladele.com  Sat Jul  1 22:01:28 2017
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Sat, 1 Jul 2017 22:01:28 +0000
Subject: [squid-users] Squid and active directory
In-Reply-To: <e2095509-5f82-84f7-0efb-73693e3172d4@gmail.com>
References: <4486631498942689@web9g.yandex.ru>
 <e2095509-5f82-84f7-0efb-73693e3172d4@gmail.com>
Message-ID: <DB6PR0401MB26801C4DD7A77352D93B4E528FD00@DB6PR0401MB2680.eurprd04.prod.outlook.com>

And this as alternative
https://docs.diladele.com/administrator_guide_5_1/active_directory/index.html

Raf

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri
Sent: Saturday, July 1, 2017 11:28 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid and active directory


http://www.squid-cache.org/Versions/v3/3.1/manuals/squid_ldap_group.html

http://lists.squid-cache.org/pipermail/squid-users/2015-October/007445.html

http://www.squid-cache.org/mail-archive/squid-users/200210/0725.html

http://www.squid-cache.org/mail-archive/squid-users/200309/0053.html

http://wiki.squid-cache.org/ConfigExamples/Authenticate/WindowsActiveDirectory

This, heh?

02.07.2017 2:58, Eng Hooda ?????:
Hello Every Body,
I am trying to get squid3 (latest on debain 8 repositories ) to authenticate clients using active directory .

I used the tutorial recommend for debian :
http://wiki.bitbinary.com/index.php/Active_Directory_Integrated_Squid_Proxy#Configure_Squid

and after a lot of tweaks to several steps machine joined the domain and now what remains is configuring squid .

I installed negotiate_wrapper as described .

But the file required :


/usr/lib/squid3/squid_ldap_group
is not present in the path specified.

I searched a lot for an updated tutorial without luck.

Any ideas ?

Thanks and BR.

Eng Hooda

-------- End of forwarded message --------




_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170701/074af90f/attachment.htm>

From sss at sss.chaoslab.ru  Sun Jul  2 02:51:19 2017
From: sss at sss.chaoslab.ru (Alexandr)
Date: Sun, 02 Jul 2017 05:51:19 +0300
Subject: [squid-users] [Fwd: sponsorship for ssl-bump support for upstream
 proxy in transparent mode]
References: <1498963661.13931.1.camel@sss.chaoslab.ru>
Message-ID: <1498963879.13931.2.camel@sss.chaoslab.ru>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

- -------- ???????????? ????????? --------
??: Alexandr <sss at sss.chaoslab.ru>
????: squid-users at lists.squid-cache.org
????: sponsorship for ssl-bump support for upstream proxy in
transparent mode
????: Sun, 02 Jul 2017 05:47:41 +0300

good day all.
few days ago i have posted  this: http://lists.squid-cache.org/pipermai
l/squid-dev/2017-June/009072.html
one of developers replyed and ready to do the job for $1250 in 90days.
$1250 is too much for me, so i write to other users to help collect
this amount of money.
currently i am ready to pay 0.2btc via bitcoin (this is something like
~$450).
-----BEGIN PGP SIGNATURE-----

iQIzBAEBCgAdFiEEl/sA7WQg6czXWI/dsEApXVthX7wFAllYX6cACgkQsEApXVth
X7xMEw/+Ktv5U6J8aC9lMsOEM3heH0LR//80giLR4M17ONZnyCc8DSTP/Xgc1+as
AmiW/fVPDxJzt2dwVmz7ClyJkUcDIdQfbTxoZQAgWyLj2vBivNie6Ibjb2i/cbC5
uRXsBZuTBgmZPF+HCPRanOgEQ2mF+i20rJOL8bk5UnIQUgXDMBR+Z3s+/V6Tc5BL
OioDHlI1uQNC4wJb6APiMockRqgH4x40ayHndhgw8teWwxwahP8Fc3WnztO7apQn
HNu9n4iVgZHvdVjPLNcDiwB3VMwkMI8qWl2TgYQEQLaMHd+fWJ0BFjrhy95/SD4U
ELW2K/LEtXtmHYlTWrfaSMesvEFaBiCuSErtrz2q6pxwjgnKlJ9d1Qu72ROSIkA5
aWfv5v7D1zgKC21AOOo/1sFzprGpK9jj6l727eOxfQrNIXb3+aHQpTk6JPRXwlKZ
DQ9ozK2cs+ZQ4QEIX/FrAS0GmRs0OQPMNnySFNCVxIg2x7PQ4MvhylYT5SW3HcDG
+ZeYnDjkdFMZAaZJwSaySJdJHjl7n28/LYemAx4iIQs5REDw6Hy38YQywPCDTpMc
hD1/beHFsAFqJmLYx1LxoVAq4DH3o9hJt0TY9tRQh6tjapwXPYJNqyKlYtyzin7d
s+pAjyPCyz3hD0eKjrYMLRV4lleGlLz8NgFqJRW4ayqx4RacCak=
=k/n2
-----END PGP SIGNATURE-----



From rtpearson at yahoo.com  Mon Jul  3 07:43:35 2017
From: rtpearson at yahoo.com (Todd Pearson)
Date: Mon, 3 Jul 2017 07:43:35 +0000 (UTC)
Subject: [squid-users] Has anyone seen v3.5.x.x authenication work in an all
 windows environment?
References: <111642404.3970659.1499067815362.ref@mail.yahoo.com>
Message-ID: <111642404.3970659.1499067815362@mail.yahoo.com>


I have spent the past few days working to get the latest version working in an all windows environment. ?I am unable to get kerberos authentication to work. ?I am struggling with getting the keytab file correct. ?Wondering if there is anyone who has seen it actually work in an all windows environment. ?I have had earlier version (v2.X stable) with NTLM authentication, but unfortunately I do not have the binaries to implement in v3.5.x.x.
I continue to struggle to find the secret forumula for SPN and keytab. ?
Thanks,Todd
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170703/6a719da7/attachment.htm>

From eliezer at ngtech.co.il  Mon Jul  3 08:09:03 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 3 Jul 2017 11:09:03 +0300
Subject: [squid-users] How long this object should be left in the cache?
Message-ID: <1d0e01d2f3d3$a23b73e0$e6b25ba0$@ngtech.co.il>

I had to tune up couple things and I have a question about a HEAD request I
have seen since something doesn't make sense in them.
I have the following line in the access log:
1499068883.928    163 192.168.168.102 TCP_MISS/200 522 HEAD
http://download.windowsupdate.com/d/msdownload/update/software/updt/2016/03/
windows6.1-kb3147071-x64_18992bd5fa0424684c4872e1c10f5663b6d3aa52.psf -
HIER_DIRECT/8.253.70.46 application/octet-stream Q-CC: "-" "-" Q-P: "-" "-"
REP-CC: "public,max-age=172800" REP-EXP: "Sat, 05 Nov 2016 03:50:11 GMT"
VARY: "-" 52:54:00:bc:e3:78 CacheHeader: "MISS from localhost.localdomain"

And I am using this logformat to get it:
logformat cache_headers %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un
%Sh/%<a %mt Q-CC: "%{Cache-Control}>h" "%{Cache-Control}>ha" Q-P:
"%{Pragma}>h" "%{Pragma}>ha" REP-CC: "%{Cache-Control}<h" REP-EXP:
"%{Expires}<h" VARY: "%{Vary}<h" %>eui CacheHeader: "%{X-Cache}<h"
access_log daemon:/var/log/squid/access.log cache_headers

I am not sure if I am seeing right or wrong and if these are real, what is
expected or how it should be treated since:
- the expires header is I the past.... 
- and against to this it's a public object with a very long maximum age.

How should squid handle this request what is expected from squid in this
confusing situation?

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il






From eliezer at ngtech.co.il  Mon Jul  3 09:34:06 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 3 Jul 2017 12:34:06 +0300
Subject: [squid-users] Has anyone seen v3.5.x.x authenication work in an
	all windows environment?
In-Reply-To: <111642404.3970659.1499067815362@mail.yahoo.com>
References: <111642404.3970659.1499067815362.ref@mail.yahoo.com>
 <111642404.3970659.1499067815362@mail.yahoo.com>
Message-ID: <1d7d01d2f3df$84252890$8c6f79b0$@ngtech.co.il>

Is this of any help?
https://docs.diladele.com/administrator_guide_5_1/active_directory/index.html

Also specify what version of windows Server and Windows clients you are using.

Thank,
Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Todd Pearson
Sent: Monday, July 3, 2017 10:44
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Has anyone seen v3.5.x.x authenication work in an all windows environment?


I have spent the past few days working to get the latest version working in an all windows environment.  I am unable to get kerberos authentication to work.  I am struggling with getting the keytab file correct.  
Wondering if there is anyone who has seen it actually work in an all windows environment.  I have had earlier version (v2.X stable) with NTLM authentication, but unfortunately I do not have the binaries to implement in v3.5.x.x.

I continue to struggle to find the secret forumula for SPN and keytab.  

Thanks,
Todd



From dijxie at gmail.com  Mon Jul  3 11:33:31 2017
From: dijxie at gmail.com (Dijxie)
Date: Mon, 3 Jul 2017 13:33:31 +0200
Subject: [squid-users] Has anyone seen v3.5.x.x authenication work in an
 all windows environment?
In-Reply-To: <111642404.3970659.1499067815362@mail.yahoo.com>
References: <111642404.3970659.1499067815362.ref@mail.yahoo.com>
 <111642404.3970659.1499067815362@mail.yahoo.com>
Message-ID: <bb56f829-1ef4-6ddf-45e3-c7f5780871fe@gmail.com>

W dniu 03.07.2017 o 09:43, Todd Pearson pisze:
>
> I have spent the past few days working to get the latest version 
> working in an all windows environment.  I am unable to get kerberos 
> authentication to work.  I am struggling with getting the keytab file 
> correct.
> Wondering if there is anyone who has seen it actually work in an all 
> windows environment.  I have had earlier version (v2.X stable) with 
> NTLM authentication, but unfortunately I do not have the binaries to 
> implement in v3.5.x.x.
>
> I continue to struggle to find the secret forumula for SPN and keytab.
>
> Thanks,
> Todd
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


Hi,

I have 4 squid serves, 3 of them are 3.5.9 @centos 7.x. Everything is 
working fine, both pure NTLM and NEGOTIATE helpers are working 
flawlessly. I've created local group on squid servers like 
keytab-readers, then:
chown root:keytab-readers /etc/krb5.keytab
chmod 740 /etc/keytab-readers
and added squid to keytab-readers.

Squid clients are windows workstations, mostly 8.1 and 10.

Why do you need to have Squid on Windows server so badly? Less 
documentation, less support. And nowadays, my guess is  almost every MS 
security update can brake things down.

My guess is when you're using squid on Windows server, you have to, 
alternatively:
1. Run squid on NT AUTHORITY/SYSTEM or NT AUTHORITY/NETWORK SERVICE 
account and put SPN  squid_accessible_name to AD machine account. So, if 
Your squid DNS name is squidproxy.corpo.local and your server name is 
srvSquid01.corpo.local, machine account srvSquid01$ has to have 
HOST/squidproxy SPN also.
2. Run squid on dedicated domain account (user account). Create user 
like "squid01", give it all nessecary permissions on squid server and 
then give this user SPN. And there's the problem: what kind of SPN in 
this configuration... I would say that HTTP/squidproxy, and then in DNS 
you'll have to have presumably CNAME (not A) pointing squidproxy to 
srvSquid01.corpo.local. And domain user squid01 will have to read acces 
to keytab, as well as keytab will have to have apropriate content (it 
should be a user, not machine keytab).

https://support.microsoft.com/en-us/help/929650/how-to-use-spns-when-you-configure-web-applications-that-are-hosted-on 


-- 
Greets, Dijx

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170703/f7428a0e/attachment.htm>

From squid3 at treenet.co.nz  Mon Jul  3 14:41:49 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 4 Jul 2017 02:41:49 +1200
Subject: [squid-users] How long this object should be left in the cache?
In-Reply-To: <1d0e01d2f3d3$a23b73e0$e6b25ba0$@ngtech.co.il>
References: <1d0e01d2f3d3$a23b73e0$e6b25ba0$@ngtech.co.il>
Message-ID: <7b13167f-d4d5-8693-f6b4-6644cc139839@treenet.co.nz>

On 03/07/17 20:09, Eliezer Croitoru wrote:
> I had to tune up couple things and I have a question about a HEAD request I
> have seen since something doesn't make sense in them.
> I have the following line in the access log:
> 1499068883.928    163 192.168.168.102 TCP_MISS/200 522 HEAD
> http://download.windowsupdate.com/d/msdownload/update/software/updt/2016/03/
> windows6.1-kb3147071-x64_18992bd5fa0424684c4872e1c10f5663b6d3aa52.psf -
> HIER_DIRECT/8.253.70.46 application/octet-stream Q-CC: "-" "-" Q-P: "-" "-"
> REP-CC: "public,max-age=172800" REP-EXP: "Sat, 05 Nov 2016 03:50:11 GMT"
> VARY: "-" 52:54:00:bc:e3:78 CacheHeader: "MISS from localhost.localdomain"
> 
> And I am using this logformat to get it:
> logformat cache_headers %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un
> %Sh/%<a %mt Q-CC: "%{Cache-Control}>h" "%{Cache-Control}>ha" Q-P:
> "%{Pragma}>h" "%{Pragma}>ha" REP-CC: "%{Cache-Control}<h" REP-EXP:
> "%{Expires}<h" VARY: "%{Vary}<h" %>eui CacheHeader: "%{X-Cache}<h"
> access_log daemon:/var/log/squid/access.log cache_headers
> 
> I am not sure if I am seeing right or wrong and if these are real, what is
> expected or how it should be treated since:
> - the expires header is I the past....
> - and against to this it's a public object with a very long maximum age.
> 
> How should squid handle this request what is expected from squid in this
> confusing situation?

It is a HEAD request for something not in cache. What might not be "real"?

IIRC Squid lacks the ability to cache the reply unless there is an 
existing object to update the headers for. So it should just relay the 
messages instead.

Amos


From eliezer at ngtech.co.il  Mon Jul  3 14:45:16 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 3 Jul 2017 17:45:16 +0300
Subject: [squid-users] How long this object should be left in the cache?
In-Reply-To: <7b13167f-d4d5-8693-f6b4-6644cc139839@treenet.co.nz>
References: <1d0e01d2f3d3$a23b73e0$e6b25ba0$@ngtech.co.il>
 <7b13167f-d4d5-8693-f6b4-6644cc139839@treenet.co.nz>
Message-ID: <1edc01d2f40a$fc7ee2b0$f57ca810$@ngtech.co.il>

Hey Amos,

>From what I remember there is an object for HEAD and GET responses.
I am talking only about the HEAD one.
Are you saying that there is no HEAD caching at all? Or that it depends on the GET one?

I am not sure if I understood correctly your response.
Would you be able to clear my doubts?

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Monday, July 3, 2017 17:42
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] How long this object should be left in the cache?

On 03/07/17 20:09, Eliezer Croitoru wrote:
> I had to tune up couple things and I have a question about a HEAD request I
> have seen since something doesn't make sense in them.
> I have the following line in the access log:
> 1499068883.928    163 192.168.168.102 TCP_MISS/200 522 HEAD
> http://download.windowsupdate.com/d/msdownload/update/software/updt/2016/03/
> windows6.1-kb3147071-x64_18992bd5fa0424684c4872e1c10f5663b6d3aa52.psf -
> HIER_DIRECT/8.253.70.46 application/octet-stream Q-CC: "-" "-" Q-P: "-" "-"
> REP-CC: "public,max-age=172800" REP-EXP: "Sat, 05 Nov 2016 03:50:11 GMT"
> VARY: "-" 52:54:00:bc:e3:78 CacheHeader: "MISS from localhost.localdomain"
> 
> And I am using this logformat to get it:
> logformat cache_headers %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un
> %Sh/%<a %mt Q-CC: "%{Cache-Control}>h" "%{Cache-Control}>ha" Q-P:
> "%{Pragma}>h" "%{Pragma}>ha" REP-CC: "%{Cache-Control}<h" REP-EXP:
> "%{Expires}<h" VARY: "%{Vary}<h" %>eui CacheHeader: "%{X-Cache}<h"
> access_log daemon:/var/log/squid/access.log cache_headers
> 
> I am not sure if I am seeing right or wrong and if these are real, what is
> expected or how it should be treated since:
> - the expires header is I the past....
> - and against to this it's a public object with a very long maximum age.
> 
> How should squid handle this request what is expected from squid in this
> confusing situation?

It is a HEAD request for something not in cache. What might not be "real"?

IIRC Squid lacks the ability to cache the reply unless there is an 
existing object to update the headers for. So it should just relay the 
messages instead.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From erdosain9 at gmail.com  Mon Jul  3 15:37:10 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Mon, 3 Jul 2017 08:37:10 -0700 (PDT)
Subject: [squid-users] open failed to shm_open(/squid-ssl_session_cache.shm)
Message-ID: <1499096230019-4682961.post@n4.nabble.com>

Hi.
What's going on here?
Can somebody give me a hand?
I dont make any change.... so... what's going on??

2017/07/03 12:44:41 kid1| Error negotiating SSL on FD 481:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
fai
led (1/-1/0)
2017/07/03 12:45:38 kid1| Closing HTTP port 127.0.0.1:3128
2017/07/03 12:45:38 kid1| Closing HTTP port 192.168.1.215:3128
2017/07/03 12:45:38 kid1| storeDirWriteCleanLogs: Starting...
2017/07/03 12:45:38 kid1|     65536 entries written so far.
2017/07/03 12:45:38 kid1|    131072 entries written so far.
2017/07/03 12:45:38 kid1|    196608 entries written so far.
2017/07/03 12:45:38 kid1|    262144 entries written so far.
2017/07/03 12:45:38 kid1|    327680 entries written so far.
2017/07/03 12:45:38 kid1|    393216 entries written so far.
2017/07/03 12:45:38 kid1|    458752 entries written so far.
2017/07/03 12:45:38 kid1|    524288 entries written so far.
2017/07/03 12:45:38 kid1|   Finished.  Wrote 583448 entries.
2017/07/03 12:45:38 kid1|   Took 0.39 seconds (1489679.82 entries/sec).
FATAL: Too many queued negotiateauthenticator requests
Squid Cache (Version 3.5.20): Terminated abnormally.
CPU Usage: 1922.935 seconds = 1731.880 user + 191.054 sys
Maximum Resident Size: 8584000 KB
Page faults with physical i/o: 11
2017/07/03 12:45:45 kid1| Set Current Directory to /var/spool/squid
2017/07/03 12:45:45 kid1| Starting Squid Cache version 3.5.20 for
x86_64-redhat-linux-gnu...
2017/07/03 12:45:45 kid1| Service Name: squid
2017/07/03 12:45:45 kid1| Process ID 4455
2017/07/03 12:45:45 kid1| Process Roles: worker
2017/07/03 12:45:45 kid1| With 16384 file descriptors available
2017/07/03 12:45:45 kid1| Initializing IP Cache...
2017/07/03 12:45:45 kid1| DNS Socket created at [::], FD 9
2017/07/03 12:45:45 kid1| DNS Socket created at 0.0.0.0, FD 10
2017/07/03 12:45:45 kid1| Adding nameserver 192.168.1.107 from squid.conf
2017/07/03 12:45:45 kid1| Adding nameserver 192.168.1.222 from squid.conf
2017/07/03 12:45:45 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
processes
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory

Squid Cache (Version 3.5.20): Terminated abnormally.
CPU Usage: 0.101 seconds = 0.078 user + 0.022 sys
Maximum Resident Size: 133856 KB
Page faults with physical i/o: 6
2017/07/03 12:45:48 kid1| Set Current Directory to /var/spool/squid
2017/07/03 12:45:48 kid1| Starting Squid Cache version 3.5.20 for
x86_64-redhat-linux-gnu...
2017/07/03 12:45:48 kid1| Service Name: squid
2017/07/03 12:45:48 kid1| Process ID 4494
2017/07/03 12:45:48 kid1| Process Roles: worker
2017/07/03 12:45:48 kid1| With 16384 file descriptors available
2017/07/03 12:45:48 kid1| Initializing IP Cache...
2017/07/03 12:45:48 kid1| DNS Socket created at [::], FD 9
2017/07/03 12:45:48 kid1| DNS Socket created at 0.0.0.0, FD 10
2017/07/03 12:45:48 kid1| Adding nameserver 192.168.1.107 from squid.conf
2017/07/03 12:45:48 kid1| Adding nameserver 192.168.1.222 from squid.conf
2017/07/03 12:45:48 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
processes
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory

Squid Cache (Version 3.5.20): Terminated abnormally.
CPU Usage: 0.118 seconds = 0.084 user + 0.033 sys
Maximum Resident Size: 133872 KB
Page faults with physical i/o: 0
2017/07/03 12:45:51 kid1| Set Current Directory to /var/spool/squid
2017/07/03 12:45:51 kid1| Starting Squid Cache version 3.5.20 for
x86_64-redhat-linux-gnu...
2017/07/03 12:45:51 kid1| Service Name: squid
2017/07/03 12:45:51 kid1| Process ID 4501
2017/07/03 12:45:51 kid1| Process Roles: worker
2017/07/03 12:45:51 kid1| With 16384 file descriptors available
2017/07/03 12:45:51 kid1| Initializing IP Cache...
2017/07/03 12:45:51 kid1| DNS Socket created at [::], FD 9
2017/07/03 12:45:51 kid1| DNS Socket created at 0.0.0.0, FD 10
2017/07/03 12:45:51 kid1| Adding nameserver 192.168.1.107 from squid.conf
2017/07/03 12:45:51 kid1| Adding nameserver 192.168.1.222 from squid.conf
2017/07/03 12:45:51 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
processes
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory





--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/open-failed-to-shm-open-squid-ssl-session-cache-shm-tp4682961.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Mon Jul  3 21:07:34 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 3 Jul 2017 15:07:34 -0600
Subject: [squid-users] open failed to
 shm_open(/squid-ssl_session_cache.shm)
In-Reply-To: <1499096230019-4682961.post@n4.nabble.com>
References: <1499096230019-4682961.post@n4.nabble.com>
Message-ID: <886bfaba-68c1-8ca3-20df-8f531d809263@measurement-factory.com>

On 07/03/2017 09:37 AM, erdosain9 wrote:

> What's going on here?

There are two problems. One probably exposes the other:


> FATAL: Too many queued negotiateauthenticator requests
> Squid Cache (Version 3.5.20): Terminated abnormally.

Your Squid has received more concurrent negotiateauthenticator requests
than it is configured to handle. FWIW, Squid v4+ can be configured to
drop extra requests (on-persistent-overload=ERR) instead of killing the
affected worker (on-persistent-overload=die).


> FATAL: Ipc::Mem::Segment::open failed to
> shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory

Your Squid worker failed to restart after the previous failure. Most
likely, there were race conditions (or bugs) during initial Squid
startup that erased some shared memory segments prematurely (or
needlessly). These problems have been fixed in Squid v4+.


HTH,

Alex.


From eliezer at ngtech.co.il  Mon Jul  3 21:35:18 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 4 Jul 2017 00:35:18 +0300
Subject: [squid-users] open failed to
	shm_open(/squid-ssl_session_cache.shm)
In-Reply-To: <1499096230019-4682961.post@n4.nabble.com>
References: <1499096230019-4682961.post@n4.nabble.com>
Message-ID: <1fed01d2f444$446440a0$cd2cc1e0$@ngtech.co.il>

Hey,

What OS are you using?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Monday, July 3, 2017 18:37
To: squid-users at lists.squid-cache.org
Subject: [squid-users] open failed to shm_open(/squid-ssl_session_cache.shm)

Hi.
What's going on here?
Can somebody give me a hand?
I dont make any change.... so... what's going on??

2017/07/03 12:44:41 kid1| Error negotiating SSL on FD 481:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
fai
led (1/-1/0)
2017/07/03 12:45:38 kid1| Closing HTTP port 127.0.0.1:3128
2017/07/03 12:45:38 kid1| Closing HTTP port 192.168.1.215:3128
2017/07/03 12:45:38 kid1| storeDirWriteCleanLogs: Starting...
2017/07/03 12:45:38 kid1|     65536 entries written so far.
2017/07/03 12:45:38 kid1|    131072 entries written so far.
2017/07/03 12:45:38 kid1|    196608 entries written so far.
2017/07/03 12:45:38 kid1|    262144 entries written so far.
2017/07/03 12:45:38 kid1|    327680 entries written so far.
2017/07/03 12:45:38 kid1|    393216 entries written so far.
2017/07/03 12:45:38 kid1|    458752 entries written so far.
2017/07/03 12:45:38 kid1|    524288 entries written so far.
2017/07/03 12:45:38 kid1|   Finished.  Wrote 583448 entries.
2017/07/03 12:45:38 kid1|   Took 0.39 seconds (1489679.82 entries/sec).
FATAL: Too many queued negotiateauthenticator requests
Squid Cache (Version 3.5.20): Terminated abnormally.
CPU Usage: 1922.935 seconds = 1731.880 user + 191.054 sys
Maximum Resident Size: 8584000 KB
Page faults with physical i/o: 11
2017/07/03 12:45:45 kid1| Set Current Directory to /var/spool/squid
2017/07/03 12:45:45 kid1| Starting Squid Cache version 3.5.20 for
x86_64-redhat-linux-gnu...
2017/07/03 12:45:45 kid1| Service Name: squid
2017/07/03 12:45:45 kid1| Process ID 4455
2017/07/03 12:45:45 kid1| Process Roles: worker
2017/07/03 12:45:45 kid1| With 16384 file descriptors available
2017/07/03 12:45:45 kid1| Initializing IP Cache...
2017/07/03 12:45:45 kid1| DNS Socket created at [::], FD 9
2017/07/03 12:45:45 kid1| DNS Socket created at 0.0.0.0, FD 10
2017/07/03 12:45:45 kid1| Adding nameserver 192.168.1.107 from squid.conf
2017/07/03 12:45:45 kid1| Adding nameserver 192.168.1.222 from squid.conf
2017/07/03 12:45:45 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
processes
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory

Squid Cache (Version 3.5.20): Terminated abnormally.
CPU Usage: 0.101 seconds = 0.078 user + 0.022 sys
Maximum Resident Size: 133856 KB
Page faults with physical i/o: 6
2017/07/03 12:45:48 kid1| Set Current Directory to /var/spool/squid
2017/07/03 12:45:48 kid1| Starting Squid Cache version 3.5.20 for
x86_64-redhat-linux-gnu...
2017/07/03 12:45:48 kid1| Service Name: squid
2017/07/03 12:45:48 kid1| Process ID 4494
2017/07/03 12:45:48 kid1| Process Roles: worker
2017/07/03 12:45:48 kid1| With 16384 file descriptors available
2017/07/03 12:45:48 kid1| Initializing IP Cache...
2017/07/03 12:45:48 kid1| DNS Socket created at [::], FD 9
2017/07/03 12:45:48 kid1| DNS Socket created at 0.0.0.0, FD 10
2017/07/03 12:45:48 kid1| Adding nameserver 192.168.1.107 from squid.conf
2017/07/03 12:45:48 kid1| Adding nameserver 192.168.1.222 from squid.conf
2017/07/03 12:45:48 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
processes
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory

Squid Cache (Version 3.5.20): Terminated abnormally.
CPU Usage: 0.118 seconds = 0.084 user + 0.033 sys
Maximum Resident Size: 133872 KB
Page faults with physical i/o: 0
2017/07/03 12:45:51 kid1| Set Current Directory to /var/spool/squid
2017/07/03 12:45:51 kid1| Starting Squid Cache version 3.5.20 for
x86_64-redhat-linux-gnu...
2017/07/03 12:45:51 kid1| Service Name: squid
2017/07/03 12:45:51 kid1| Process ID 4501
2017/07/03 12:45:51 kid1| Process Roles: worker
2017/07/03 12:45:51 kid1| With 16384 file descriptors available
2017/07/03 12:45:51 kid1| Initializing IP Cache...
2017/07/03 12:45:51 kid1| DNS Socket created at [::], FD 9
2017/07/03 12:45:51 kid1| DNS Socket created at 0.0.0.0, FD 10
2017/07/03 12:45:51 kid1| Adding nameserver 192.168.1.107 from squid.conf
2017/07/03 12:45:51 kid1| Adding nameserver 192.168.1.222 from squid.conf
2017/07/03 12:45:51 kid1| helperOpenServers: Starting 5/32 'ssl_crtd'
processes
FATAL: Ipc::Mem::Segment::open failed to
shm_open(/squid-ssl_session_cache.shm): (2) No such file or directory



From squid3 at treenet.co.nz  Tue Jul  4 02:22:46 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 4 Jul 2017 14:22:46 +1200
Subject: [squid-users] How long this object should be left in the cache?
In-Reply-To: <1edc01d2f40a$fc7ee2b0$f57ca810$@ngtech.co.il>
References: <1d0e01d2f3d3$a23b73e0$e6b25ba0$@ngtech.co.il>
 <7b13167f-d4d5-8693-f6b4-6644cc139839@treenet.co.nz>
 <1edc01d2f40a$fc7ee2b0$f57ca810$@ngtech.co.il>
Message-ID: <16da5db0-c295-b342-34bc-49483abc47fe@treenet.co.nz>

On 04/07/17 02:45, Eliezer Croitoru wrote:
> Hey Amos,
> 
>  From what I remember there is an object for HEAD and GET responses.
> I am talking only about the HEAD one.
> Are you saying that there is no HEAD caching at all? Or that it depends on the GET one?
>

I'm not completely sure, but IIRC the HEAD response being expired 
already makes it not worth caching. Since in order to reply to even 
another HEAD request Squid would have to revalidate / fetch new headers.

Amos


From charlesprem at kggroup.com  Tue Jul  4 04:36:41 2017
From: charlesprem at kggroup.com (Charles Prem)
Date: Tue, 4 Jul 2017 10:06:41 +0530
Subject: [squid-users] Reg: AIX Support
Message-ID: <00cd01d2f47f$21c57ba0$655072e0$@kggroup.com>

Hi,

 

We are using squid 2.6 in IBM AIX Server. Do you have any latest RPM for IBM
AIX?

 

Please advise.

 

With Regards

F. Charles Prem

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170704/5d1638e8/attachment.htm>

From erdosain9 at gmail.com  Tue Jul  4 12:50:03 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 4 Jul 2017 05:50:03 -0700 (PDT)
Subject: [squid-users] open failed to
	shm_open(/squid-ssl_session_cache.shm)
In-Reply-To: <1fed01d2f444$446440a0$cd2cc1e0$@ngtech.co.il>
References: <1499096230019-4682961.post@n4.nabble.com>
 <1fed01d2f444$446440a0$cd2cc1e0$@ngtech.co.il>
Message-ID: <1499172603067-4682967.post@n4.nabble.com>

Hi. 

Im using  CentOS Linux release 7.2.1511 (Core)

"Your Squid has received more concurrent negotiateauthenticator requests
than it is configured to handle. FWIW, Squid v4+ can be configured to
drop extra requests"... are you telling me it's time to update??? :-(



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/open-failed-to-shm-open-squid-ssl-session-cache-shm-tp4682961p4682967.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Tue Jul  4 13:08:09 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 5 Jul 2017 01:08:09 +1200
Subject: [squid-users] Reg: AIX Support
In-Reply-To: <00cd01d2f47f$21c57ba0$655072e0$@kggroup.com>
References: <00cd01d2f47f$21c57ba0$655072e0$@kggroup.com>
Message-ID: <27e7bb9f-01d8-40c0-9ed8-bb0b80997515@treenet.co.nz>

On 04/07/17 16:36, Charles Prem wrote:
> Hi,
> 
> We are using squid 2.6 in IBM AIX Server. Do you have any latest RPM for 
> IBM AIX?
> 
> Please advise.
> 

FWIW; I remember some emails from people running Squid on AIX when 2.7 
and 3.1 were current. But my lists (in the Squid wiki) do not include 
any details of where to get any packages newer than 2.6 or who might be 
making them.

If anyone is making AIX packages that can be shared around please get in 
touch with me.

Alternatively if anyone is successfully running packages built for some 
other OS on AIX systems that would be useful info for the wiki.


Charles;
  If nothing comes up specifically for AIX then I expect Eliezer's RPMs 
for CentOS, RHEL or Solaris should be usable. Though you may need to 
re-build from the SRPM to account for OS library differences.

HTH
Amos


From eliezer at ngtech.co.il  Tue Jul  4 13:21:32 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 4 Jul 2017 16:21:32 +0300
Subject: [squid-users] open failed
	to	shm_open(/squid-ssl_session_cache.shm)
In-Reply-To: <1499172603067-4682967.post@n4.nabble.com>
References: <1499096230019-4682961.post@n4.nabble.com>
 <1fed01d2f444$446440a0$cd2cc1e0$@ngtech.co.il>
 <1499172603067-4682967.post@n4.nabble.com>
Message-ID: <21ea01d2f4c8$73eacd10$5bc06730$@ngtech.co.il>

Or tuneup things...
Can you get the squid cache manager info dump?
This might help us to understand what is the load on the server and how many client's it's handling.
In any case it would be good to update to 3.5.26 but let's leave this aside and see what can be done right now and not in the long term.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Tuesday, July 4, 2017 15:50
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] open failed to shm_open(/squid-ssl_session_cache.shm)

Hi. 

Im using  CentOS Linux release 7.2.1511 (Core)

"Your Squid has received more concurrent negotiateauthenticator requests than it is configured to handle. FWIW, Squid v4+ can be configured to drop extra requests"... are you telling me it's time to update??? :-(



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/open-failed-to-shm-open-squid-ssl-session-cache-shm-tp4682961p4682967.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Tue Jul  4 13:23:01 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Tue, 4 Jul 2017 16:23:01 +0300
Subject: [squid-users] Reg: AIX Support
In-Reply-To: <27e7bb9f-01d8-40c0-9ed8-bb0b80997515@treenet.co.nz>
References: <00cd01d2f47f$21c57ba0$655072e0$@kggroup.com>
 <27e7bb9f-01d8-40c0-9ed8-bb0b80997515@treenet.co.nz>
Message-ID: <21ec01d2f4c8$a936e7b0$fba4b710$@ngtech.co.il>

Let me know if you need any help with things.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Tuesday, July 4, 2017 16:08
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Reg: AIX Support

On 04/07/17 16:36, Charles Prem wrote:
> Hi,
> 
> We are using squid 2.6 in IBM AIX Server. Do you have any latest RPM for 
> IBM AIX?
> 
> Please advise.
> 

FWIW; I remember some emails from people running Squid on AIX when 2.7 
and 3.1 were current. But my lists (in the Squid wiki) do not include 
any details of where to get any packages newer than 2.6 or who might be 
making them.

If anyone is making AIX packages that can be shared around please get in 
touch with me.

Alternatively if anyone is successfully running packages built for some 
other OS on AIX systems that would be useful info for the wiki.


Charles;
  If nothing comes up specifically for AIX then I expect Eliezer's RPMs 
for CentOS, RHEL or Solaris should be usable. Though you may need to 
re-build from the SRPM to account for OS library differences.

HTH
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Tue Jul  4 15:42:58 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 4 Jul 2017 09:42:58 -0600
Subject: [squid-users] open failed to
 shm_open(/squid-ssl_session_cache.shm)
In-Reply-To: <1499172603067-4682967.post@n4.nabble.com>
References: <1499096230019-4682961.post@n4.nabble.com>
 <1fed01d2f444$446440a0$cd2cc1e0$@ngtech.co.il>
 <1499172603067-4682967.post@n4.nabble.com>
Message-ID: <bb69c323-a118-b84d-c7c0-f2e80fffa14b@measurement-factory.com>

On 07/04/2017 06:50 AM, erdosain9 wrote:

> "Your Squid has received more concurrent negotiateauthenticator requests
> than it is configured to handle. FWIW, Squid v4+ can be configured to
> drop extra requests"... are you telling me it's time to update??? :-(

Nope, just answering your questions. What you do with the information is
your call. In general, the options obviously(?) include but are not
limited to:

* reducing Squid load via external means,
* changing Squid configuration to handle more concurrent
negotiateauthenticator requests,
* backporting v4 changes, and/or
* upgrading Squid to a version that can be configured drop extra requests.

Alex.


From muhd.usman87 at gmail.com  Tue Jul  4 18:56:34 2017
From: muhd.usman87 at gmail.com (Muhammad Usman)
Date: Tue, 4 Jul 2017 23:56:34 +0500
Subject: [squid-users] Get calling User Details on server
Message-ID: <CAHfqhMm7m=FrX0pmqtuTQqYNNwnvbo7bWX+PQVyZMgAejVG2oA@mail.gmail.com>

Hi,
I have configured Squid and Dansguardian successfully on Ubuntu. I want to
inject ads in user browsing (with user consent).
I want to get details about the user like their IP etc but I dont know how
to get this in Squid and then pass on to dansguardian. Any help would be
appreciated. Thanks
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170704/506c544e/attachment.htm>

From yvoinov at gmail.com  Tue Jul  4 20:49:43 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 5 Jul 2017 02:49:43 +0600
Subject: [squid-users] Get calling User Details on server
In-Reply-To: <CAHfqhMm7m=FrX0pmqtuTQqYNNwnvbo7bWX+PQVyZMgAejVG2oA@mail.gmail.com>
References: <CAHfqhMm7m=FrX0pmqtuTQqYNNwnvbo7bWX+PQVyZMgAejVG2oA@mail.gmail.com>
Message-ID: <ffdab29e-69d3-ad0d-2435-23ee722bec63@gmail.com>

Let's open squid's default access.log:

1499201177.345    155 *172.16.100.3* TCP_MISS/200 633 GET
https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID -
ORIGINAL_DST/95.85.19.244 application/json

third (.....|awk {'print $3'}) is exactly client IP.

How to get it in redirector? Read manual of yours redirector, I think.
Usually this data exactly present in redirector logs because of this is
_most_ interesting data.

;-)

05.07.2017 0:56, Muhammad Usman ?????:
> Hi,
> I have configured Squid and Dansguardian successfully on Ubuntu. I
> want to inject ads in user browsing (with user consent). 
> I want to get details about the user like their IP etc but I dont know
> how to get this in Squid and then pass on to dansguardian. Any help
> would be appreciated. Thanks
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/78cbbd32/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/78cbbd32/attachment.sig>

From muhd.usman87 at gmail.com  Tue Jul  4 20:54:10 2017
From: muhd.usman87 at gmail.com (Muhammad Usman)
Date: Wed, 5 Jul 2017 01:54:10 +0500
Subject: [squid-users] Get calling User Details on server
In-Reply-To: <ffdab29e-69d3-ad0d-2435-23ee722bec63@gmail.com>
References: <CAHfqhMm7m=FrX0pmqtuTQqYNNwnvbo7bWX+PQVyZMgAejVG2oA@mail.gmail.com>
 <ffdab29e-69d3-ad0d-2435-23ee722bec63@gmail.com>
Message-ID: <CAHfqhMnqu+rB3T-kY7bzutj2=oA=f24g4stsEKrwCPZ0qEOm8Q@mail.gmail.com>

Thanks a lot for your reply.
Can you please confirm if it is possible to receive custom attributes in
header and if yes, then how can I use those attributes like MAC etc?

On Wed, Jul 5, 2017 at 1:49 AM, Yuri <yvoinov at gmail.com> wrote:

> Let's open squid's default access.log:
>
> 1499201177.345    155 *172.16.100.3* TCP_MISS/200 633 GET
> https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID - ORIGINAL_DST/
> 95.85.19.244 application/json
>
> third (.....|awk {'print $3'}) is exactly client IP.
>
> How to get it in redirector? Read manual of yours redirector, I think.
> Usually this data exactly present in redirector logs because of this is
> _most_ interesting data.
> ;-)
>
> 05.07.2017 0:56, Muhammad Usman ?????:
>
> Hi,
> I have configured Squid and Dansguardian successfully on Ubuntu. I want to
> inject ads in user browsing (with user consent).
> I want to get details about the user like their IP etc but I dont know how
> to get this in Squid and then pass on to dansguardian. Any help would be
> appreciated. Thanks
>
>
> _______________________________________________
> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/687adc9b/attachment.htm>

From yvoinov at gmail.com  Tue Jul  4 20:59:21 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 5 Jul 2017 02:59:21 +0600
Subject: [squid-users] Get calling User Details on server
In-Reply-To: <CAHfqhMnqu+rB3T-kY7bzutj2=oA=f24g4stsEKrwCPZ0qEOm8Q@mail.gmail.com>
References: <CAHfqhMm7m=FrX0pmqtuTQqYNNwnvbo7bWX+PQVyZMgAejVG2oA@mail.gmail.com>
 <ffdab29e-69d3-ad0d-2435-23ee722bec63@gmail.com>
 <CAHfqhMnqu+rB3T-kY7bzutj2=oA=f24g4stsEKrwCPZ0qEOm8Q@mail.gmail.com>
Message-ID: <30181b60-2fb6-27af-9551-0bc6b59bf7f6@gmail.com>



05.07.2017 2:54, Muhammad Usman ?????:
> Thanks a lot for your reply.
> Can you please confirm if it is possible to receive custom attributes
> in header and if yes, then how can I use those attributes like MAC etc?
http://wiki.squid-cache.org/Features/LogFormat
http://www.squid-cache.org/Doc/config/logformat/

I guess Squid's doc answers all.
>
> On Wed, Jul 5, 2017 at 1:49 AM, Yuri <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com>> wrote:
>
>     Let's open squid's default access.log:
>
>     1499201177.345    155 *172.16.100.3* TCP_MISS/200 633 GET
>     https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID
>     <https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID> -
>     ORIGINAL_DST/95.85.19.244 <http://95.85.19.244> application/json
>
>     third (.....|awk {'print $3'}) is exactly client IP.
>
>     How to get it in redirector? Read manual of yours redirector, I
>     think. Usually this data exactly present in redirector logs
>     because of this is _most_ interesting data.
>
>     ;-)
>
>     05.07.2017 0:56, Muhammad Usman ?????:
>>     Hi,
>>     I have configured Squid and Dansguardian successfully on Ubuntu.
>>     I want to inject ads in user browsing (with user consent). 
>>     I want to get details about the user like their IP etc but I dont
>>     know how to get this in Squid and then pass on to dansguardian.
>>     Any help would be appreciated. Thanks
>>
>>
>>     _______________________________________________
>>     squid-users mailing list
>>     squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org>
>>     http://lists.squid-cache.org/listinfo/squid-users
>>     <http://lists.squid-cache.org/listinfo/squid-users>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/2a709523/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/2a709523/attachment.sig>

From yvoinov at gmail.com  Tue Jul  4 21:04:36 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 5 Jul 2017 03:04:36 +0600
Subject: [squid-users] Get calling User Details on server
In-Reply-To: <CAHfqhMnqu+rB3T-kY7bzutj2=oA=f24g4stsEKrwCPZ0qEOm8Q@mail.gmail.com>
References: <CAHfqhMm7m=FrX0pmqtuTQqYNNwnvbo7bWX+PQVyZMgAejVG2oA@mail.gmail.com>
 <ffdab29e-69d3-ad0d-2435-23ee722bec63@gmail.com>
 <CAHfqhMnqu+rB3T-kY7bzutj2=oA=f24g4stsEKrwCPZ0qEOm8Q@mail.gmail.com>
Message-ID: <36f61aa4-6c7b-5757-9b88-97acfc9fbbdf@gmail.com>

However HTTP headers is yet another story. To work with them on the fly
- partially, for injecting Ads into pages - you require a bit another
tool, named Content Adaptation (ICAP/eCAP).

So, finally. Logs is one thing, header/content manipulation - another.

What do you want to achieve exactly?


05.07.2017 2:54, Muhammad Usman ?????:
> Thanks a lot for your reply.
> Can you please confirm if it is possible to receive custom attributes
> in header and if yes, then how can I use those attributes like MAC etc? 
>
> On Wed, Jul 5, 2017 at 1:49 AM, Yuri <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com>> wrote:
>
>     Let's open squid's default access.log:
>
>     1499201177.345    155 *172.16.100.3* TCP_MISS/200 633 GET
>     https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID
>     <https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID> -
>     ORIGINAL_DST/95.85.19.244 <http://95.85.19.244> application/json
>
>     third (.....|awk {'print $3'}) is exactly client IP.
>
>     How to get it in redirector? Read manual of yours redirector, I
>     think. Usually this data exactly present in redirector logs
>     because of this is _most_ interesting data.
>
>     ;-)
>
>     05.07.2017 0:56, Muhammad Usman ?????:
>>     Hi,
>>     I have configured Squid and Dansguardian successfully on Ubuntu.
>>     I want to inject ads in user browsing (with user consent). 
>>     I want to get details about the user like their IP etc but I dont
>>     know how to get this in Squid and then pass on to dansguardian.
>>     Any help would be appreciated. Thanks
>>
>>
>>     _______________________________________________
>>     squid-users mailing list
>>     squid-users at lists.squid-cache.org
>>     <mailto:squid-users at lists.squid-cache.org>
>>     http://lists.squid-cache.org/listinfo/squid-users
>>     <http://lists.squid-cache.org/listinfo/squid-users>
>
>
>     _______________________________________________
>     squid-users mailing list
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     http://lists.squid-cache.org/listinfo/squid-users
>     <http://lists.squid-cache.org/listinfo/squid-users>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/32c5024d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/32c5024d/attachment.sig>

From muhd.usman87 at gmail.com  Tue Jul  4 21:12:15 2017
From: muhd.usman87 at gmail.com (Muhammad Usman)
Date: Wed, 5 Jul 2017 02:12:15 +0500
Subject: [squid-users] Get calling User Details on server
In-Reply-To: <36f61aa4-6c7b-5757-9b88-97acfc9fbbdf@gmail.com>
References: <CAHfqhMm7m=FrX0pmqtuTQqYNNwnvbo7bWX+PQVyZMgAejVG2oA@mail.gmail.com>
 <ffdab29e-69d3-ad0d-2435-23ee722bec63@gmail.com>
 <CAHfqhMnqu+rB3T-kY7bzutj2=oA=f24g4stsEKrwCPZ0qEOm8Q@mail.gmail.com>
 <36f61aa4-6c7b-5757-9b88-97acfc9fbbdf@gmail.com>
Message-ID: <CAHfqhMmsDZ2u6JCgnWadGWJee22U0tvjoGfJYHxWW6qnoBrqDg@mail.gmail.com>

Thanks again.
I have trying to setup hotspots and I want to pass all user traffic through
the proxy server and inject ads (through injection of a JS script in html).
I want to pass some parameters like AP MAC and Customer MAC as parameters
to the JS script, in order to keep track at user level.
Can I achieve all this through Squid or do I need to add other software's
as well.


On Wed, Jul 5, 2017 at 2:04 AM, Yuri <yvoinov at gmail.com> wrote:

> However HTTP headers is yet another story. To work with them on the fly -
> partially, for injecting Ads into pages - you require a bit another tool,
> named Content Adaptation (ICAP/eCAP).
>
> So, finally. Logs is one thing, header/content manipulation - another.
>
> What do you want to achieve exactly?
>
> 05.07.2017 2:54, Muhammad Usman ?????:
>
> Thanks a lot for your reply.
> Can you please confirm if it is possible to receive custom attributes in
> header and if yes, then how can I use those attributes like MAC etc?
>
> On Wed, Jul 5, 2017 at 1:49 AM, Yuri <yvoinov at gmail.com> wrote:
>
>> Let's open squid's default access.log:
>>
>> 1499201177.345    155 *172.16.100.3* TCP_MISS/200 633 GET
>> https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID - ORIGINAL_DST/
>> 95.85.19.244 application/json
>>
>> third (.....|awk {'print $3'}) is exactly client IP.
>>
>> How to get it in redirector? Read manual of yours redirector, I think.
>> Usually this data exactly present in redirector logs because of this is
>> _most_ interesting data.
>> ;-)
>>
>> 05.07.2017 0:56, Muhammad Usman ?????:
>>
>> Hi,
>> I have configured Squid and Dansguardian successfully on Ubuntu. I want
>> to inject ads in user browsing (with user consent).
>> I want to get details about the user like their IP etc but I dont know
>> how to get this in Squid and then pass on to dansguardian. Any help would
>> be appreciated. Thanks
>>
>>
>> _______________________________________________
>> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/6d18f1e2/attachment.htm>

From muhd.usman87 at gmail.com  Tue Jul  4 21:13:35 2017
From: muhd.usman87 at gmail.com (Muhammad Usman)
Date: Wed, 5 Jul 2017 02:13:35 +0500
Subject: [squid-users] Get calling User Details on server
In-Reply-To: <CAHfqhMmsDZ2u6JCgnWadGWJee22U0tvjoGfJYHxWW6qnoBrqDg@mail.gmail.com>
References: <CAHfqhMm7m=FrX0pmqtuTQqYNNwnvbo7bWX+PQVyZMgAejVG2oA@mail.gmail.com>
 <ffdab29e-69d3-ad0d-2435-23ee722bec63@gmail.com>
 <CAHfqhMnqu+rB3T-kY7bzutj2=oA=f24g4stsEKrwCPZ0qEOm8Q@mail.gmail.com>
 <36f61aa4-6c7b-5757-9b88-97acfc9fbbdf@gmail.com>
 <CAHfqhMmsDZ2u6JCgnWadGWJee22U0tvjoGfJYHxWW6qnoBrqDg@mail.gmail.com>
Message-ID: <CAHfqhM=eNfbhBT8woJ10DK9mjmb-0fW3D5-Tb+pfmT9HX6SCXg@mail.gmail.com>

This assumes that AP will send its MAC and Customer MAC while proxying
traffic to the server. Otherwise I can pass Source IP as parameter as well.

On Wed, Jul 5, 2017 at 2:12 AM, Muhammad Usman <muhd.usman87 at gmail.com>
wrote:

> Thanks again.
> I have trying to setup hotspots and I want to pass all user traffic
> through the proxy server and inject ads (through injection of a JS script
> in html). I want to pass some parameters like AP MAC and Customer MAC as
> parameters to the JS script, in order to keep track at user level.
> Can I achieve all this through Squid or do I need to add other software's
> as well.
>
>
> On Wed, Jul 5, 2017 at 2:04 AM, Yuri <yvoinov at gmail.com> wrote:
>
>> However HTTP headers is yet another story. To work with them on the fly -
>> partially, for injecting Ads into pages - you require a bit another tool,
>> named Content Adaptation (ICAP/eCAP).
>>
>> So, finally. Logs is one thing, header/content manipulation - another.
>>
>> What do you want to achieve exactly?
>>
>> 05.07.2017 2:54, Muhammad Usman ?????:
>>
>> Thanks a lot for your reply.
>> Can you please confirm if it is possible to receive custom attributes in
>> header and if yes, then how can I use those attributes like MAC etc?
>>
>> On Wed, Jul 5, 2017 at 1:49 AM, Yuri <yvoinov at gmail.com> wrote:
>>
>>> Let's open squid's default access.log:
>>>
>>> 1499201177.345    155 *172.16.100.3* TCP_MISS/200 633 GET
>>> https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID -
>>> ORIGINAL_DST/95.85.19.244 application/json
>>>
>>> third (.....|awk {'print $3'}) is exactly client IP.
>>>
>>> How to get it in redirector? Read manual of yours redirector, I think.
>>> Usually this data exactly present in redirector logs because of this is
>>> _most_ interesting data.
>>> ;-)
>>>
>>> 05.07.2017 0:56, Muhammad Usman ?????:
>>>
>>> Hi,
>>> I have configured Squid and Dansguardian successfully on Ubuntu. I want
>>> to inject ads in user browsing (with user consent).
>>> I want to get details about the user like their IP etc but I dont know
>>> how to get this in Squid and then pass on to dansguardian. Any help would
>>> be appreciated. Thanks
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/e5113add/attachment.htm>

From yvoinov at gmail.com  Tue Jul  4 21:17:45 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 5 Jul 2017 03:17:45 +0600
Subject: [squid-users] Get calling User Details on server
In-Reply-To: <CAHfqhMmsDZ2u6JCgnWadGWJee22U0tvjoGfJYHxWW6qnoBrqDg@mail.gmail.com>
References: <CAHfqhMm7m=FrX0pmqtuTQqYNNwnvbo7bWX+PQVyZMgAejVG2oA@mail.gmail.com>
 <ffdab29e-69d3-ad0d-2435-23ee722bec63@gmail.com>
 <CAHfqhMnqu+rB3T-kY7bzutj2=oA=f24g4stsEKrwCPZ0qEOm8Q@mail.gmail.com>
 <36f61aa4-6c7b-5757-9b88-97acfc9fbbdf@gmail.com>
 <CAHfqhMmsDZ2u6JCgnWadGWJee22U0tvjoGfJYHxWW6qnoBrqDg@mail.gmail.com>
Message-ID: <4bb93a0e-304a-c783-b771-41c26b2db3fc@gmail.com>



05.07.2017 3:12, Muhammad Usman ?????:
> Thanks again.
> I have trying to setup hotspots and I want to pass all user traffic
> through the proxy server and inject ads (through injection of a JS
> script in html). I want to pass some parameters like AP MAC and
> Customer MAC as parameters to the JS script, in order to keep track at
> user level.
> Can I achieve all this through Squid or do I need to add other
> software's as well.
Yes. It's possible.

Some part of solution:

http://wiki.squid-cache.org/ConfigExamples/Portal/Splash

and this:

http://wiki.squid-cache.org/Features/ICAP

However, content adaptation part is not so simple and can require some
programming (up to C/C++ level), because of I don't know any
ready-to-use and free solution to inject ads (Which is understandable,
given that advertising is money).

>
>
> On Wed, Jul 5, 2017 at 2:04 AM, Yuri <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com>> wrote:
>
>     However HTTP headers is yet another story. To work with them on
>     the fly - partially, for injecting Ads into pages - you require a
>     bit another tool, named Content Adaptation (ICAP/eCAP).
>
>     So, finally. Logs is one thing, header/content manipulation - another.
>
>     What do you want to achieve exactly?
>
>
>     05.07.2017 2:54, Muhammad Usman ?????:
>>     Thanks a lot for your reply.
>>     Can you please confirm if it is possible to receive custom
>>     attributes in header and if yes, then how can I use those
>>     attributes like MAC etc? 
>>
>>     On Wed, Jul 5, 2017 at 1:49 AM, Yuri <yvoinov at gmail.com
>>     <mailto:yvoinov at gmail.com>> wrote:
>>
>>         Let's open squid's default access.log:
>>
>>         1499201177.345    155 *172.16.100.3* TCP_MISS/200 633 GET
>>         https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID
>>         <https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID> -
>>         ORIGINAL_DST/95.85.19.244 <http://95.85.19.244> application/json
>>
>>         third (.....|awk {'print $3'}) is exactly client IP.
>>
>>         How to get it in redirector? Read manual of yours redirector,
>>         I think. Usually this data exactly present in redirector logs
>>         because of this is _most_ interesting data.
>>
>>         ;-)
>>
>>         05.07.2017 0:56, Muhammad Usman ?????:
>>>         Hi,
>>>         I have configured Squid and Dansguardian successfully on
>>>         Ubuntu. I want to inject ads in user browsing (with user
>>>         consent). 
>>>         I want to get details about the user like their IP etc but I
>>>         dont know how to get this in Squid and then pass on
>>>         to dansguardian. Any help would be appreciated. Thanks
>>>
>>>
>>>         _______________________________________________
>>>         squid-users mailing list
>>>         squid-users at lists.squid-cache.org
>>>         <mailto:squid-users at lists.squid-cache.org>
>>>         http://lists.squid-cache.org/listinfo/squid-users
>>>         <http://lists.squid-cache.org/listinfo/squid-users>
>>
>>
>>         _______________________________________________
>>         squid-users mailing list
>>         squid-users at lists.squid-cache.org
>>         <mailto:squid-users at lists.squid-cache.org>
>>         http://lists.squid-cache.org/listinfo/squid-users
>>         <http://lists.squid-cache.org/listinfo/squid-users>
>>
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/770c0b8d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/770c0b8d/attachment.sig>

From yvoinov at gmail.com  Tue Jul  4 21:21:54 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 5 Jul 2017 03:21:54 +0600
Subject: [squid-users] Get calling User Details on server
In-Reply-To: <CAHfqhM=eNfbhBT8woJ10DK9mjmb-0fW3D5-Tb+pfmT9HX6SCXg@mail.gmail.com>
References: <CAHfqhMm7m=FrX0pmqtuTQqYNNwnvbo7bWX+PQVyZMgAejVG2oA@mail.gmail.com>
 <ffdab29e-69d3-ad0d-2435-23ee722bec63@gmail.com>
 <CAHfqhMnqu+rB3T-kY7bzutj2=oA=f24g4stsEKrwCPZ0qEOm8Q@mail.gmail.com>
 <36f61aa4-6c7b-5757-9b88-97acfc9fbbdf@gmail.com>
 <CAHfqhMmsDZ2u6JCgnWadGWJee22U0tvjoGfJYHxWW6qnoBrqDg@mail.gmail.com>
 <CAHfqhM=eNfbhBT8woJ10DK9mjmb-0fW3D5-Tb+pfmT9HX6SCXg@mail.gmail.com>
Message-ID: <169c4003-1060-2800-1af5-4a5db10c53bc@gmail.com>



05.07.2017 3:13, Muhammad Usman ?????:
> This assumes that AP will send its MAC and Customer MAC while proxying
> traffic to the server. Otherwise I can pass Source IP as parameter as
> well.
Something like, yes.
>
> On Wed, Jul 5, 2017 at 2:12 AM, Muhammad Usman <muhd.usman87 at gmail.com
> <mailto:muhd.usman87 at gmail.com>> wrote:
>
>     Thanks again.
>     I have trying to setup hotspots and I want to pass all user
>     traffic through the proxy server and inject ads (through injection
>     of a JS script in html). I want to pass some parameters like AP
>     MAC and Customer MAC as parameters to the JS script, in order to
>     keep track at user level.
>     Can I achieve all this through Squid or do I need to add other
>     software's as well.
>
>
>     On Wed, Jul 5, 2017 at 2:04 AM, Yuri <yvoinov at gmail.com
>     <mailto:yvoinov at gmail.com>> wrote:
>
>         However HTTP headers is yet another story. To work with them
>         on the fly - partially, for injecting Ads into pages - you
>         require a bit another tool, named Content Adaptation (ICAP/eCAP).
>
>         So, finally. Logs is one thing, header/content manipulation -
>         another.
>
>         What do you want to achieve exactly?
>
>
>         05.07.2017 2:54, Muhammad Usman ?????:
>>         Thanks a lot for your reply.
>>         Can you please confirm if it is possible to receive custom
>>         attributes in header and if yes, then how can I use those
>>         attributes like MAC etc? 
>>
>>         On Wed, Jul 5, 2017 at 1:49 AM, Yuri <yvoinov at gmail.com
>>         <mailto:yvoinov at gmail.com>> wrote:
>>
>>             Let's open squid's default access.log:
>>
>>             1499201177.345    155 *172.16.100.3* TCP_MISS/200 633 GET
>>             https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID
>>             <https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID>
>>             - ORIGINAL_DST/95.85.19.244 <http://95.85.19.244>
>>             application/json
>>
>>             third (.....|awk {'print $3'}) is exactly client IP.
>>
>>             How to get it in redirector? Read manual of yours
>>             redirector, I think. Usually this data exactly present in
>>             redirector logs because of this is _most_ interesting data.
>>
>>             ;-)
>>
>>             05.07.2017 0:56, Muhammad Usman ?????:
>>>             Hi,
>>>             I have configured Squid and Dansguardian successfully on
>>>             Ubuntu. I want to inject ads in user browsing (with user
>>>             consent). 
>>>             I want to get details about the user like their IP etc
>>>             but I dont know how to get this in Squid and then pass
>>>             on to dansguardian. Any help would be appreciated. Thanks
>>>
>>>
>>>             _______________________________________________
>>>             squid-users mailing list
>>>             squid-users at lists.squid-cache.org
>>>             <mailto:squid-users at lists.squid-cache.org>
>>>             http://lists.squid-cache.org/listinfo/squid-users
>>>             <http://lists.squid-cache.org/listinfo/squid-users>
>>
>>
>>             _______________________________________________
>>             squid-users mailing list
>>             squid-users at lists.squid-cache.org
>>             <mailto:squid-users at lists.squid-cache.org>
>>             http://lists.squid-cache.org/listinfo/squid-users
>>             <http://lists.squid-cache.org/listinfo/squid-users>
>>
>>
>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/06bffed8/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/06bffed8/attachment.sig>

From muhd.usman87 at gmail.com  Tue Jul  4 21:24:09 2017
From: muhd.usman87 at gmail.com (Muhammad Usman)
Date: Wed, 5 Jul 2017 02:24:09 +0500
Subject: [squid-users] Get calling User Details on server
In-Reply-To: <4bb93a0e-304a-c783-b771-41c26b2db3fc@gmail.com>
References: <CAHfqhMm7m=FrX0pmqtuTQqYNNwnvbo7bWX+PQVyZMgAejVG2oA@mail.gmail.com>
 <ffdab29e-69d3-ad0d-2435-23ee722bec63@gmail.com>
 <CAHfqhMnqu+rB3T-kY7bzutj2=oA=f24g4stsEKrwCPZ0qEOm8Q@mail.gmail.com>
 <36f61aa4-6c7b-5757-9b88-97acfc9fbbdf@gmail.com>
 <CAHfqhMmsDZ2u6JCgnWadGWJee22U0tvjoGfJYHxWW6qnoBrqDg@mail.gmail.com>
 <4bb93a0e-304a-c783-b771-41c26b2db3fc@gmail.com>
Message-ID: <CAHfqhMmET9B4j-BvG6y=R_jOAFFs1i9+6GWbt8E4HskHL1mTpA@mail.gmail.com>

I dont want to redirect them to some splash page, I want to continuously
inject my JS script in their session. Currently I am able to do this
using dansguardian.
The only part pending is to send IP & other information as parameter.

<script type="text/javascript" apmac="11-22-33-44-55-66"
data-cusip="10.1.0.1" request="" src="http://mysite.com/js"></script>


On Wed, Jul 5, 2017 at 2:17 AM, Yuri <yvoinov at gmail.com> wrote:

>
>
> 05.07.2017 3:12, Muhammad Usman ?????:
>
> Thanks again.
> I have trying to setup hotspots and I want to pass all user traffic
> through the proxy server and inject ads (through injection of a JS script
> in html). I want to pass some parameters like AP MAC and Customer MAC as
> parameters to the JS script, in order to keep track at user level.
> Can I achieve all this through Squid or do I need to add other software's
> as well.
>
> Yes. It's possible.
>
> Some part of solution:
>
> http://wiki.squid-cache.org/ConfigExamples/Portal/Splash
>
> and this:
>
> http://wiki.squid-cache.org/Features/ICAP
>
> However, content adaptation part is not so simple and can require some
> programming (up to C/C++ level), because of I don't know any ready-to-use
> and free solution to inject ads (Which is understandable, given that
> advertising is money).
>
>
>
>
> On Wed, Jul 5, 2017 at 2:04 AM, Yuri <yvoinov at gmail.com> wrote:
>
>> However HTTP headers is yet another story. To work with them on the fly -
>> partially, for injecting Ads into pages - you require a bit another tool,
>> named Content Adaptation (ICAP/eCAP).
>>
>> So, finally. Logs is one thing, header/content manipulation - another.
>>
>> What do you want to achieve exactly?
>>
>> 05.07.2017 2:54, Muhammad Usman ?????:
>>
>> Thanks a lot for your reply.
>> Can you please confirm if it is possible to receive custom attributes in
>> header and if yes, then how can I use those attributes like MAC etc?
>>
>> On Wed, Jul 5, 2017 at 1:49 AM, Yuri <yvoinov at gmail.com> wrote:
>>
>>> Let's open squid's default access.log:
>>>
>>> 1499201177.345    155 *172.16.100.3* TCP_MISS/200 633 GET
>>> https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID -
>>> ORIGINAL_DST/95.85.19.244 application/json
>>>
>>> third (.....|awk {'print $3'}) is exactly client IP.
>>>
>>> How to get it in redirector? Read manual of yours redirector, I think.
>>> Usually this data exactly present in redirector logs because of this is
>>> _most_ interesting data.
>>> ;-)
>>>
>>> 05.07.2017 0:56, Muhammad Usman ?????:
>>>
>>> Hi,
>>> I have configured Squid and Dansguardian successfully on Ubuntu. I want
>>> to inject ads in user browsing (with user consent).
>>> I want to get details about the user like their IP etc but I dont know
>>> how to get this in Squid and then pass on to dansguardian. Any help would
>>> be appreciated. Thanks
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>>
>>> _______________________________________________
>>> squid-users mailing list
>>> squid-users at lists.squid-cache.org
>>> http://lists.squid-cache.org/listinfo/squid-users
>>>
>>>
>>
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/e34819b3/attachment.htm>

From yvoinov at gmail.com  Tue Jul  4 21:27:18 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 5 Jul 2017 03:27:18 +0600
Subject: [squid-users] Get calling User Details on server
In-Reply-To: <CAHfqhMmET9B4j-BvG6y=R_jOAFFs1i9+6GWbt8E4HskHL1mTpA@mail.gmail.com>
References: <CAHfqhMm7m=FrX0pmqtuTQqYNNwnvbo7bWX+PQVyZMgAejVG2oA@mail.gmail.com>
 <ffdab29e-69d3-ad0d-2435-23ee722bec63@gmail.com>
 <CAHfqhMnqu+rB3T-kY7bzutj2=oA=f24g4stsEKrwCPZ0qEOm8Q@mail.gmail.com>
 <36f61aa4-6c7b-5757-9b88-97acfc9fbbdf@gmail.com>
 <CAHfqhMmsDZ2u6JCgnWadGWJee22U0tvjoGfJYHxWW6qnoBrqDg@mail.gmail.com>
 <4bb93a0e-304a-c783-b771-41c26b2db3fc@gmail.com>
 <CAHfqhMmET9B4j-BvG6y=R_jOAFFs1i9+6GWbt8E4HskHL1mTpA@mail.gmail.com>
Message-ID: <60bec6f7-7cc3-a194-4f21-080bb2e71817@gmail.com>

This is a solution, too. But more better to do this with specific tool,
designed for this tasks exactly.


05.07.2017 3:24, Muhammad Usman ?????:
> I dont want to redirect them to some splash page, I want to
> continuously inject my JS script in their session. Currently I am able
> to do this using dansguardian. 
> The only part pending is to send IP & other information as parameter.
>
> <script type="text/javascript" apmac="11-22-33-44-55-66" data-cusip="10.1.0.1" request="" src="http://mysite.com/js"></script>
>
> On Wed, Jul 5, 2017 at 2:17 AM, Yuri <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com>> wrote:
>
>
>
>     05.07.2017 3:12, Muhammad Usman ?????:
>>     Thanks again.
>>     I have trying to setup hotspots and I want to pass all user
>>     traffic through the proxy server and inject ads (through
>>     injection of a JS script in html). I want to pass some parameters
>>     like AP MAC and Customer MAC as parameters to the JS script, in
>>     order to keep track at user level.
>>     Can I achieve all this through Squid or do I need to add other
>>     software's as well.
>     Yes. It's possible.
>
>     Some part of solution:
>
>     http://wiki.squid-cache.org/ConfigExamples/Portal/Splash
>     <http://wiki.squid-cache.org/ConfigExamples/Portal/Splash>
>
>     and this:
>
>     http://wiki.squid-cache.org/Features/ICAP
>     <http://wiki.squid-cache.org/Features/ICAP>
>
>     However, content adaptation part is not so simple and can require
>     some programming (up to C/C++ level), because of I don't know any
>     ready-to-use and free solution to inject ads (Which is
>     understandable, given that advertising is money).
>
>
>>
>>
>>     On Wed, Jul 5, 2017 at 2:04 AM, Yuri <yvoinov at gmail.com
>>     <mailto:yvoinov at gmail.com>> wrote:
>>
>>         However HTTP headers is yet another story. To work with them
>>         on the fly - partially, for injecting Ads into pages - you
>>         require a bit another tool, named Content Adaptation (ICAP/eCAP).
>>
>>         So, finally. Logs is one thing, header/content manipulation -
>>         another.
>>
>>         What do you want to achieve exactly?
>>
>>
>>         05.07.2017 2:54, Muhammad Usman ?????:
>>>         Thanks a lot for your reply.
>>>         Can you please confirm if it is possible to receive custom
>>>         attributes in header and if yes, then how can I use those
>>>         attributes like MAC etc? 
>>>
>>>         On Wed, Jul 5, 2017 at 1:49 AM, Yuri <yvoinov at gmail.com
>>>         <mailto:yvoinov at gmail.com>> wrote:
>>>
>>>             Let's open squid's default access.log:
>>>
>>>             1499201177.345    155 *172.16.100.3* TCP_MISS/200 633
>>>             GET
>>>             https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID
>>>             <https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID>
>>>             - ORIGINAL_DST/95.85.19.244 <http://95.85.19.244>
>>>             application/json
>>>
>>>             third (.....|awk {'print $3'}) is exactly client IP.
>>>
>>>             How to get it in redirector? Read manual of yours
>>>             redirector, I think. Usually this data exactly present
>>>             in redirector logs because of this is _most_ interesting
>>>             data.
>>>
>>>             ;-)
>>>
>>>             05.07.2017 0:56, Muhammad Usman ?????:
>>>>             Hi,
>>>>             I have configured Squid and Dansguardian successfully
>>>>             on Ubuntu. I want to inject ads in user browsing (with
>>>>             user consent). 
>>>>             I want to get details about the user like their IP etc
>>>>             but I dont know how to get this in Squid and then pass
>>>>             on to dansguardian. Any help would be appreciated. Thanks
>>>>
>>>>
>>>>             _______________________________________________
>>>>             squid-users mailing list
>>>>             squid-users at lists.squid-cache.org
>>>>             <mailto:squid-users at lists.squid-cache.org>
>>>>             http://lists.squid-cache.org/listinfo/squid-users
>>>>             <http://lists.squid-cache.org/listinfo/squid-users>
>>>
>>>
>>>             _______________________________________________
>>>             squid-users mailing list
>>>             squid-users at lists.squid-cache.org
>>>             <mailto:squid-users at lists.squid-cache.org>
>>>             http://lists.squid-cache.org/listinfo/squid-users
>>>             <http://lists.squid-cache.org/listinfo/squid-users>
>>>
>>>
>>
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/9a63648d/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/9a63648d/attachment.sig>

From muhd.usman87 at gmail.com  Tue Jul  4 21:31:56 2017
From: muhd.usman87 at gmail.com (Muhammad Usman)
Date: Wed, 5 Jul 2017 02:31:56 +0500
Subject: [squid-users] Get calling User Details on server
In-Reply-To: <60bec6f7-7cc3-a194-4f21-080bb2e71817@gmail.com>
References: <CAHfqhMm7m=FrX0pmqtuTQqYNNwnvbo7bWX+PQVyZMgAejVG2oA@mail.gmail.com>
 <ffdab29e-69d3-ad0d-2435-23ee722bec63@gmail.com>
 <CAHfqhMnqu+rB3T-kY7bzutj2=oA=f24g4stsEKrwCPZ0qEOm8Q@mail.gmail.com>
 <36f61aa4-6c7b-5757-9b88-97acfc9fbbdf@gmail.com>
 <CAHfqhMmsDZ2u6JCgnWadGWJee22U0tvjoGfJYHxWW6qnoBrqDg@mail.gmail.com>
 <4bb93a0e-304a-c783-b771-41c26b2db3fc@gmail.com>
 <CAHfqhMmET9B4j-BvG6y=R_jOAFFs1i9+6GWbt8E4HskHL1mTpA@mail.gmail.com>
 <60bec6f7-7cc3-a194-4f21-080bb2e71817@gmail.com>
Message-ID: <CAHfqhMnrkFgi9G5OOm6jS5uU0W0DJUrvcMECSm5AtyEWj6iPWg@mail.gmail.com>

Can you please recommend tools designed for this?

On Wed, Jul 5, 2017 at 2:27 AM, Yuri <yvoinov at gmail.com> wrote:

> This is a solution, too. But more better to do this with specific tool,
> designed for this tasks exactly.
>
> 05.07.2017 3:24, Muhammad Usman ?????:
>
> I dont want to redirect them to some splash page, I want to continuously
> inject my JS script in their session. Currently I am able to do this
> using dansguardian.
> The only part pending is to send IP & other information as parameter.
>
> <script type="text/javascript" apmac="11-22-33-44-55-66" data-cusip="10.1.0.1" request="" src="http://mysite.com/js"></script>
>
>
> On Wed, Jul 5, 2017 at 2:17 AM, Yuri <yvoinov at gmail.com> wrote:
>
>>
>>
>> 05.07.2017 3:12, Muhammad Usman ?????:
>>
>> Thanks again.
>> I have trying to setup hotspots and I want to pass all user traffic
>> through the proxy server and inject ads (through injection of a JS script
>> in html). I want to pass some parameters like AP MAC and Customer MAC as
>> parameters to the JS script, in order to keep track at user level.
>> Can I achieve all this through Squid or do I need to add other software's
>> as well.
>>
>> Yes. It's possible.
>>
>> Some part of solution:
>>
>> http://wiki.squid-cache.org/ConfigExamples/Portal/Splash
>>
>> and this:
>>
>> http://wiki.squid-cache.org/Features/ICAP
>>
>> However, content adaptation part is not so simple and can require some
>> programming (up to C/C++ level), because of I don't know any ready-to-use
>> and free solution to inject ads (Which is understandable, given that
>> advertising is money).
>>
>>
>>
>>
>> On Wed, Jul 5, 2017 at 2:04 AM, Yuri <yvoinov at gmail.com> wrote:
>>
>>> However HTTP headers is yet another story. To work with them on the fly
>>> - partially, for injecting Ads into pages - you require a bit another tool,
>>> named Content Adaptation (ICAP/eCAP).
>>>
>>> So, finally. Logs is one thing, header/content manipulation - another.
>>>
>>> What do you want to achieve exactly?
>>>
>>> 05.07.2017 2:54, Muhammad Usman ?????:
>>>
>>> Thanks a lot for your reply.
>>> Can you please confirm if it is possible to receive custom attributes in
>>> header and if yes, then how can I use those attributes like MAC etc?
>>>
>>> On Wed, Jul 5, 2017 at 1:49 AM, Yuri <yvoinov at gmail.com> wrote:
>>>
>>>> Let's open squid's default access.log:
>>>>
>>>> 1499201177.345    155 *172.16.100.3* TCP_MISS/200 633 GET
>>>> https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID -
>>>> ORIGINAL_DST/95.85.19.244 application/json
>>>>
>>>> third (.....|awk {'print $3'}) is exactly client IP.
>>>>
>>>> How to get it in redirector? Read manual of yours redirector, I think.
>>>> Usually this data exactly present in redirector logs because of this is
>>>> _most_ interesting data.
>>>> ;-)
>>>>
>>>> 05.07.2017 0:56, Muhammad Usman ?????:
>>>>
>>>> Hi,
>>>> I have configured Squid and Dansguardian successfully on Ubuntu. I want
>>>> to inject ads in user browsing (with user consent).
>>>> I want to get details about the user like their IP etc but I dont know
>>>> how to get this in Squid and then pass on to dansguardian. Any help would
>>>> be appreciated. Thanks
>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>>
>>>>
>>>> _______________________________________________
>>>> squid-users mailing list
>>>> squid-users at lists.squid-cache.org
>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>
>>>>
>>>
>>>
>>
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/c1554084/attachment.htm>

From yvoinov at gmail.com  Tue Jul  4 21:42:22 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 5 Jul 2017 03:42:22 +0600
Subject: [squid-users] Get calling User Details on server
In-Reply-To: <CAHfqhMnrkFgi9G5OOm6jS5uU0W0DJUrvcMECSm5AtyEWj6iPWg@mail.gmail.com>
References: <CAHfqhMm7m=FrX0pmqtuTQqYNNwnvbo7bWX+PQVyZMgAejVG2oA@mail.gmail.com>
 <ffdab29e-69d3-ad0d-2435-23ee722bec63@gmail.com>
 <CAHfqhMnqu+rB3T-kY7bzutj2=oA=f24g4stsEKrwCPZ0qEOm8Q@mail.gmail.com>
 <36f61aa4-6c7b-5757-9b88-97acfc9fbbdf@gmail.com>
 <CAHfqhMmsDZ2u6JCgnWadGWJee22U0tvjoGfJYHxWW6qnoBrqDg@mail.gmail.com>
 <4bb93a0e-304a-c783-b771-41c26b2db3fc@gmail.com>
 <CAHfqhMmET9B4j-BvG6y=R_jOAFFs1i9+6GWbt8E4HskHL1mTpA@mail.gmail.com>
 <60bec6f7-7cc3-a194-4f21-080bb2e71817@gmail.com>
 <CAHfqhMnrkFgi9G5OOm6jS5uU0W0DJUrvcMECSm5AtyEWj6iPWg@mail.gmail.com>
Message-ID: <81c102d0-9e29-1fad-70de-ce3ad48b1162@gmail.com>

Sure,

http://c-icap.sourceforge.net/

http://e-cap.org/

however remember: you still require to write required module by
yourself. ;-)

05.07.2017 3:31, Muhammad Usman ?????:
> Can you please recommend tools designed for this?
>
> On Wed, Jul 5, 2017 at 2:27 AM, Yuri <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com>> wrote:
>
>     This is a solution, too. But more better to do this with specific
>     tool, designed for this tasks exactly.
>
>
>     05.07.2017 3:24, Muhammad Usman ?????:
>>     I dont want to redirect them to some splash page, I want to
>>     continuously inject my JS script in their session. Currently I am
>>     able to do this using dansguardian. 
>>     The only part pending is to send IP & other information as parameter.
>>
>>     <script type="text/javascript" apmac="11-22-33-44-55-66" data-cusip="10.1.0.1" request="" src="http://mysite.com/js"></script>
>>
>>     On Wed, Jul 5, 2017 at 2:17 AM, Yuri <yvoinov at gmail.com
>>     <mailto:yvoinov at gmail.com>> wrote:
>>
>>
>>
>>         05.07.2017 3:12, Muhammad Usman ?????:
>>>         Thanks again.
>>>         I have trying to setup hotspots and I want to pass all user
>>>         traffic through the proxy server and inject ads (through
>>>         injection of a JS script in html). I want to pass some
>>>         parameters like AP MAC and Customer MAC as parameters to the
>>>         JS script, in order to keep track at user level.
>>>         Can I achieve all this through Squid or do I need to add
>>>         other software's as well.
>>         Yes. It's possible.
>>
>>         Some part of solution:
>>
>>         http://wiki.squid-cache.org/ConfigExamples/Portal/Splash
>>         <http://wiki.squid-cache.org/ConfigExamples/Portal/Splash>
>>
>>         and this:
>>
>>         http://wiki.squid-cache.org/Features/ICAP
>>         <http://wiki.squid-cache.org/Features/ICAP>
>>
>>         However, content adaptation part is not so simple and can
>>         require some programming (up to C/C++ level), because of I
>>         don't know any ready-to-use and free solution to inject ads
>>         (Which is understandable, given that advertising is money).
>>
>>
>>>
>>>
>>>         On Wed, Jul 5, 2017 at 2:04 AM, Yuri <yvoinov at gmail.com
>>>         <mailto:yvoinov at gmail.com>> wrote:
>>>
>>>             However HTTP headers is yet another story. To work with
>>>             them on the fly - partially, for injecting Ads into
>>>             pages - you require a bit another tool, named Content
>>>             Adaptation (ICAP/eCAP).
>>>
>>>             So, finally. Logs is one thing, header/content
>>>             manipulation - another.
>>>
>>>             What do you want to achieve exactly?
>>>
>>>
>>>             05.07.2017 2:54, Muhammad Usman ?????:
>>>>             Thanks a lot for your reply.
>>>>             Can you please confirm if it is possible to receive
>>>>             custom attributes in header and if yes, then how can I
>>>>             use those attributes like MAC etc? 
>>>>
>>>>             On Wed, Jul 5, 2017 at 1:49 AM, Yuri <yvoinov at gmail.com
>>>>             <mailto:yvoinov at gmail.com>> wrote:
>>>>
>>>>                 Let's open squid's default access.log:
>>>>
>>>>                 1499201177.345    155 *172.16.100.3* TCP_MISS/200
>>>>                 633 GET
>>>>                 https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID
>>>>                 <https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID>
>>>>                 - ORIGINAL_DST/95.85.19.244 <http://95.85.19.244>
>>>>                 application/json
>>>>
>>>>                 third (.....|awk {'print $3'}) is exactly client IP.
>>>>
>>>>                 How to get it in redirector? Read manual of yours
>>>>                 redirector, I think. Usually this data exactly
>>>>                 present in redirector logs because of this is
>>>>                 _most_ interesting data.
>>>>
>>>>                 ;-)
>>>>
>>>>                 05.07.2017 0:56, Muhammad Usman ?????:
>>>>>                 Hi,
>>>>>                 I have configured Squid and
>>>>>                 Dansguardian successfully on Ubuntu. I want to
>>>>>                 inject ads in user browsing (with user consent). 
>>>>>                 I want to get details about the user like their IP
>>>>>                 etc but I dont know how to get this in Squid and
>>>>>                 then pass on to dansguardian. Any help would be
>>>>>                 appreciated. Thanks
>>>>>
>>>>>
>>>>>                 _______________________________________________
>>>>>                 squid-users mailing list
>>>>>                 squid-users at lists.squid-cache.org
>>>>>                 <mailto:squid-users at lists.squid-cache.org>
>>>>>                 http://lists.squid-cache.org/listinfo/squid-users
>>>>>                 <http://lists.squid-cache.org/listinfo/squid-users>
>>>>
>>>>
>>>>                 _______________________________________________
>>>>                 squid-users mailing list
>>>>                 squid-users at lists.squid-cache.org
>>>>                 <mailto:squid-users at lists.squid-cache.org>
>>>>                 http://lists.squid-cache.org/listinfo/squid-users
>>>>                 <http://lists.squid-cache.org/listinfo/squid-users>
>>>>
>>>>
>>>
>>>
>>
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/512401f7/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/512401f7/attachment.sig>

From muhd.usman87 at gmail.com  Tue Jul  4 21:46:48 2017
From: muhd.usman87 at gmail.com (Muhammad Usman)
Date: Wed, 5 Jul 2017 02:46:48 +0500
Subject: [squid-users] Get calling User Details on server
In-Reply-To: <81c102d0-9e29-1fad-70de-ce3ad48b1162@gmail.com>
References: <CAHfqhMm7m=FrX0pmqtuTQqYNNwnvbo7bWX+PQVyZMgAejVG2oA@mail.gmail.com>
 <ffdab29e-69d3-ad0d-2435-23ee722bec63@gmail.com>
 <CAHfqhMnqu+rB3T-kY7bzutj2=oA=f24g4stsEKrwCPZ0qEOm8Q@mail.gmail.com>
 <36f61aa4-6c7b-5757-9b88-97acfc9fbbdf@gmail.com>
 <CAHfqhMmsDZ2u6JCgnWadGWJee22U0tvjoGfJYHxWW6qnoBrqDg@mail.gmail.com>
 <4bb93a0e-304a-c783-b771-41c26b2db3fc@gmail.com>
 <CAHfqhMmET9B4j-BvG6y=R_jOAFFs1i9+6GWbt8E4HskHL1mTpA@mail.gmail.com>
 <60bec6f7-7cc3-a194-4f21-080bb2e71817@gmail.com>
 <CAHfqhMnrkFgi9G5OOm6jS5uU0W0DJUrvcMECSm5AtyEWj6iPWg@mail.gmail.com>
 <81c102d0-9e29-1fad-70de-ce3ad48b1162@gmail.com>
Message-ID: <CAHfqhMm2Epo_-poochbinynBZ-JTaUevmKj_Sv6JH-aod5W2fg@mail.gmail.com>

Thanks a lot..

On Wed, Jul 5, 2017 at 2:42 AM, Yuri <yvoinov at gmail.com> wrote:

> Sure,
>
> http://c-icap.sourceforge.net/
>
> http://e-cap.org/
> however remember: you still require to write required module by yourself.
> ;-)
>
> 05.07.2017 3:31, Muhammad Usman ?????:
>
> Can you please recommend tools designed for this?
>
> On Wed, Jul 5, 2017 at 2:27 AM, Yuri <yvoinov at gmail.com> wrote:
>
>> This is a solution, too. But more better to do this with specific tool,
>> designed for this tasks exactly.
>>
>> 05.07.2017 3:24, Muhammad Usman ?????:
>>
>> I dont want to redirect them to some splash page, I want to continuously
>> inject my JS script in their session. Currently I am able to do this
>> using dansguardian.
>> The only part pending is to send IP & other information as parameter.
>>
>> <script type="text/javascript" apmac="11-22-33-44-55-66" data-cusip="10.1.0.1" request="" src="http://mysite.com/js"></script>
>>
>>
>> On Wed, Jul 5, 2017 at 2:17 AM, Yuri <yvoinov at gmail.com> wrote:
>>
>>>
>>>
>>> 05.07.2017 3:12, Muhammad Usman ?????:
>>>
>>> Thanks again.
>>> I have trying to setup hotspots and I want to pass all user traffic
>>> through the proxy server and inject ads (through injection of a JS script
>>> in html). I want to pass some parameters like AP MAC and Customer MAC as
>>> parameters to the JS script, in order to keep track at user level.
>>> Can I achieve all this through Squid or do I need to add other
>>> software's as well.
>>>
>>> Yes. It's possible.
>>>
>>> Some part of solution:
>>>
>>> http://wiki.squid-cache.org/ConfigExamples/Portal/Splash
>>>
>>> and this:
>>>
>>> http://wiki.squid-cache.org/Features/ICAP
>>>
>>> However, content adaptation part is not so simple and can require some
>>> programming (up to C/C++ level), because of I don't know any ready-to-use
>>> and free solution to inject ads (Which is understandable, given that
>>> advertising is money).
>>>
>>>
>>>
>>>
>>> On Wed, Jul 5, 2017 at 2:04 AM, Yuri <yvoinov at gmail.com> wrote:
>>>
>>>> However HTTP headers is yet another story. To work with them on the fly
>>>> - partially, for injecting Ads into pages - you require a bit another tool,
>>>> named Content Adaptation (ICAP/eCAP).
>>>>
>>>> So, finally. Logs is one thing, header/content manipulation - another.
>>>>
>>>> What do you want to achieve exactly?
>>>>
>>>> 05.07.2017 2:54, Muhammad Usman ?????:
>>>>
>>>> Thanks a lot for your reply.
>>>> Can you please confirm if it is possible to receive custom attributes
>>>> in header and if yes, then how can I use those attributes like MAC etc?
>>>>
>>>> On Wed, Jul 5, 2017 at 1:49 AM, Yuri <yvoinov at gmail.com> wrote:
>>>>
>>>>> Let's open squid's default access.log:
>>>>>
>>>>> 1499201177.345    155 *172.16.100.3* TCP_MISS/200 633 GET
>>>>> https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID -
>>>>> ORIGINAL_DST/95.85.19.244 application/json
>>>>>
>>>>> third (.....|awk {'print $3'}) is exactly client IP.
>>>>>
>>>>> How to get it in redirector? Read manual of yours redirector, I think.
>>>>> Usually this data exactly present in redirector logs because of this is
>>>>> _most_ interesting data.
>>>>> ;-)
>>>>>
>>>>> 05.07.2017 0:56, Muhammad Usman ?????:
>>>>>
>>>>> Hi,
>>>>> I have configured Squid and Dansguardian successfully on Ubuntu. I
>>>>> want to inject ads in user browsing (with user consent).
>>>>> I want to get details about the user like their IP etc but I dont know
>>>>> how to get this in Squid and then pass on to dansguardian. Any help would
>>>>> be appreciated. Thanks
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> squid-users mailing listsquid-users at lists.squid-cache.orghttp://lists.squid-cache.org/listinfo/squid-users
>>>>>
>>>>>
>>>>>
>>>>> _______________________________________________
>>>>> squid-users mailing list
>>>>> squid-users at lists.squid-cache.org
>>>>> http://lists.squid-cache.org/listinfo/squid-users
>>>>>
>>>>>
>>>>
>>>>
>>>
>>>
>>
>>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/18511330/attachment.htm>

From yvoinov at gmail.com  Tue Jul  4 21:47:24 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 5 Jul 2017 03:47:24 +0600
Subject: [squid-users] Get calling User Details on server
In-Reply-To: <CAHfqhMm2Epo_-poochbinynBZ-JTaUevmKj_Sv6JH-aod5W2fg@mail.gmail.com>
References: <CAHfqhMm7m=FrX0pmqtuTQqYNNwnvbo7bWX+PQVyZMgAejVG2oA@mail.gmail.com>
 <ffdab29e-69d3-ad0d-2435-23ee722bec63@gmail.com>
 <CAHfqhMnqu+rB3T-kY7bzutj2=oA=f24g4stsEKrwCPZ0qEOm8Q@mail.gmail.com>
 <36f61aa4-6c7b-5757-9b88-97acfc9fbbdf@gmail.com>
 <CAHfqhMmsDZ2u6JCgnWadGWJee22U0tvjoGfJYHxWW6qnoBrqDg@mail.gmail.com>
 <4bb93a0e-304a-c783-b771-41c26b2db3fc@gmail.com>
 <CAHfqhMmET9B4j-BvG6y=R_jOAFFs1i9+6GWbt8E4HskHL1mTpA@mail.gmail.com>
 <60bec6f7-7cc3-a194-4f21-080bb2e71817@gmail.com>
 <CAHfqhMnrkFgi9G5OOm6jS5uU0W0DJUrvcMECSm5AtyEWj6iPWg@mail.gmail.com>
 <81c102d0-9e29-1fad-70de-ce3ad48b1162@gmail.com>
 <CAHfqhMm2Epo_-poochbinynBZ-JTaUevmKj_Sv6JH-aod5W2fg@mail.gmail.com>
Message-ID: <488035ea-f9df-8ed1-69c5-e82b4c77da59@gmail.com>

You are welcome :-)


05.07.2017 3:46, Muhammad Usman ?????:
> Thanks a lot..
>
> On Wed, Jul 5, 2017 at 2:42 AM, Yuri <yvoinov at gmail.com
> <mailto:yvoinov at gmail.com>> wrote:
>
>     Sure,
>
>     http://c-icap.sourceforge.net/
>
>     http://e-cap.org/
>
>     however remember: you still require to write required module by
>     yourself. ;-)
>
>     05.07.2017 3:31, Muhammad Usman ?????:
>>     Can you please recommend tools designed for this?
>>
>>     On Wed, Jul 5, 2017 at 2:27 AM, Yuri <yvoinov at gmail.com
>>     <mailto:yvoinov at gmail.com>> wrote:
>>
>>         This is a solution, too. But more better to do this with
>>         specific tool, designed for this tasks exactly.
>>
>>
>>         05.07.2017 3:24, Muhammad Usman ?????:
>>>         I dont want to redirect them to some splash page, I want to
>>>         continuously inject my JS script in their session. Currently
>>>         I am able to do this using dansguardian. 
>>>         The only part pending is to send IP & other information as
>>>         parameter.
>>>
>>>         <script type="text/javascript" apmac="11-22-33-44-55-66" data-cusip="10.1.0.1" request="" src="http://mysite.com/js"></script>
>>>
>>>         On Wed, Jul 5, 2017 at 2:17 AM, Yuri <yvoinov at gmail.com
>>>         <mailto:yvoinov at gmail.com>> wrote:
>>>
>>>
>>>
>>>             05.07.2017 3:12, Muhammad Usman ?????:
>>>>             Thanks again.
>>>>             I have trying to setup hotspots and I want to pass all
>>>>             user traffic through the proxy server and inject ads
>>>>             (through injection of a JS script in html). I want to
>>>>             pass some parameters like AP MAC and Customer MAC as
>>>>             parameters to the JS script, in order to keep track at
>>>>             user level.
>>>>             Can I achieve all this through Squid or do I need to
>>>>             add other software's as well.
>>>             Yes. It's possible.
>>>
>>>             Some part of solution:
>>>
>>>             http://wiki.squid-cache.org/ConfigExamples/Portal/Splash
>>>             <http://wiki.squid-cache.org/ConfigExamples/Portal/Splash>
>>>
>>>             and this:
>>>
>>>             http://wiki.squid-cache.org/Features/ICAP
>>>             <http://wiki.squid-cache.org/Features/ICAP>
>>>
>>>             However, content adaptation part is not so simple and
>>>             can require some programming (up to C/C++ level),
>>>             because of I don't know any ready-to-use and free
>>>             solution to inject ads (Which is understandable, given
>>>             that advertising is money).
>>>
>>>
>>>>
>>>>
>>>>             On Wed, Jul 5, 2017 at 2:04 AM, Yuri <yvoinov at gmail.com
>>>>             <mailto:yvoinov at gmail.com>> wrote:
>>>>
>>>>                 However HTTP headers is yet another story. To work
>>>>                 with them on the fly - partially, for injecting Ads
>>>>                 into pages - you require a bit another tool, named
>>>>                 Content Adaptation (ICAP/eCAP).
>>>>
>>>>                 So, finally. Logs is one thing, header/content
>>>>                 manipulation - another.
>>>>
>>>>                 What do you want to achieve exactly?
>>>>
>>>>
>>>>                 05.07.2017 2:54, Muhammad Usman ?????:
>>>>>                 Thanks a lot for your reply.
>>>>>                 Can you please confirm if it is possible to
>>>>>                 receive custom attributes in header and if yes,
>>>>>                 then how can I use those attributes like MAC etc? 
>>>>>
>>>>>                 On Wed, Jul 5, 2017 at 1:49 AM, Yuri
>>>>>                 <yvoinov at gmail.com <mailto:yvoinov at gmail.com>> wrote:
>>>>>
>>>>>                     Let's open squid's default access.log:
>>>>>
>>>>>                     1499201177.345    155 *172.16.100.3*
>>>>>                     TCP_MISS/200 633 GET
>>>>>                     https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID
>>>>>                     <https://discovery-v4-4.syncthing.net/v2/?device=DEVICE_ID>
>>>>>                     - ORIGINAL_DST/95.85.19.244
>>>>>                     <http://95.85.19.244> application/json
>>>>>
>>>>>                     third (.....|awk {'print $3'}) is exactly
>>>>>                     client IP.
>>>>>
>>>>>                     How to get it in redirector? Read manual of
>>>>>                     yours redirector, I think. Usually this data
>>>>>                     exactly present in redirector logs because of
>>>>>                     this is _most_ interesting data.
>>>>>
>>>>>                     ;-)
>>>>>
>>>>>                     05.07.2017 0:56, Muhammad Usman ?????:
>>>>>>                     Hi,
>>>>>>                     I have configured Squid and
>>>>>>                     Dansguardian successfully on Ubuntu. I want
>>>>>>                     to inject ads in user browsing (with user
>>>>>>                     consent). 
>>>>>>                     I want to get details about the user like
>>>>>>                     their IP etc but I dont know how to get this
>>>>>>                     in Squid and then pass on to dansguardian.
>>>>>>                     Any help would be appreciated. Thanks
>>>>>>
>>>>>>
>>>>>>                     _______________________________________________
>>>>>>                     squid-users mailing list
>>>>>>                     squid-users at lists.squid-cache.org
>>>>>>                     <mailto:squid-users at lists.squid-cache.org>
>>>>>>                     http://lists.squid-cache.org/listinfo/squid-users
>>>>>>                     <http://lists.squid-cache.org/listinfo/squid-users>
>>>>>
>>>>>
>>>>>                     _______________________________________________
>>>>>                     squid-users mailing list
>>>>>                     squid-users at lists.squid-cache.org
>>>>>                     <mailto:squid-users at lists.squid-cache.org>
>>>>>                     http://lists.squid-cache.org/listinfo/squid-users
>>>>>                     <http://lists.squid-cache.org/listinfo/squid-users>
>>>>>
>>>>>
>>>>
>>>>
>>>
>>>
>>
>>
>
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/c6748032/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170705/c6748032/attachment.sig>

From charlesprem at kggroup.com  Wed Jul  5 04:16:45 2017
From: charlesprem at kggroup.com (Charles Prem)
Date: Wed, 5 Jul 2017 09:46:45 +0530
Subject: [squid-users] Reg: AIX Support
In-Reply-To: <21ec01d2f4c8$a936e7b0$fba4b710$@ngtech.co.il>
References: <00cd01d2f47f$21c57ba0$655072e0$@kggroup.com>
 <27e7bb9f-01d8-40c0-9ed8-bb0b80997515@treenet.co.nz>
 <21ec01d2f4c8$a936e7b0$fba4b710$@ngtech.co.il>
Message-ID: <014d01d2f545$83cca0a0$8b65e1e0$@kggroup.com>

Dear Eliezer,

We are using squid 2.6 in AIX 7.1. Last week the vendor performed the penetration test. In that few vulnerability in the report. The recommendation is upgrade the latest version of Squid. 

I have searched squid latest RPM in the internet but I couldn?t get it. 

With Regards
F. Charles Prem 

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Eliezer Croitoru
Sent: Tuesday, July 4, 2017 6:53 PM
To: 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Reg: AIX Support

Let me know if you need any help with things.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Tuesday, July 4, 2017 16:08
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Reg: AIX Support

On 04/07/17 16:36, Charles Prem wrote:
> Hi,
> 
> We are using squid 2.6 in IBM AIX Server. Do you have any latest RPM 
> for IBM AIX?
> 
> Please advise.
> 

FWIW; I remember some emails from people running Squid on AIX when 2.7 and 3.1 were current. But my lists (in the Squid wiki) do not include any details of where to get any packages newer than 2.6 or who might be making them.

If anyone is making AIX packages that can be shared around please get in touch with me.

Alternatively if anyone is successfully running packages built for some other OS on AIX systems that would be useful info for the wiki.


Charles;
  If nothing comes up specifically for AIX then I expect Eliezer's RPMs 
for CentOS, RHEL or Solaris should be usable. Though you may need to 
re-build from the SRPM to account for OS library differences.

HTH
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Wed Jul  5 08:59:10 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 5 Jul 2017 11:59:10 +0300
Subject: [squid-users] Reg: AIX Support
In-Reply-To: <014d01d2f545$83cca0a0$8b65e1e0$@kggroup.com>
References: <00cd01d2f47f$21c57ba0$655072e0$@kggroup.com>
 <27e7bb9f-01d8-40c0-9ed8-bb0b80997515@treenet.co.nz>
 <21ec01d2f4c8$a936e7b0$fba4b710$@ngtech.co.il>
 <014d01d2f545$83cca0a0$8b65e1e0$@kggroup.com>
Message-ID: <24b401d2f56c$f751ec20$e5f5c460$@ngtech.co.il>

You can find the SRPMS for newer versions at:
http://ngtech.co.il/repo/centos/

I never worked with AIX so I don't know to what CentOS branch it's the most similar.
Do you have a compiling machine which you can try to build the latest or a newer squid version?

All The Bests,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: Charles Prem [mailto:charlesprem at kggroup.com] 
Sent: Wednesday, July 5, 2017 07:17
To: 'Eliezer Croitoru' <eliezer at ngtech.co.il>; 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: RE: [squid-users] Reg: AIX Support

Dear Eliezer,

We are using squid 2.6 in AIX 7.1. Last week the vendor performed the penetration test. In that few vulnerability in the report. The recommendation is upgrade the latest version of Squid. 

I have searched squid latest RPM in the internet but I couldn?t get it. 

With Regards
F. Charles Prem 

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Eliezer Croitoru
Sent: Tuesday, July 4, 2017 6:53 PM
To: 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Reg: AIX Support

Let me know if you need any help with things.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Tuesday, July 4, 2017 16:08
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Reg: AIX Support

On 04/07/17 16:36, Charles Prem wrote:
> Hi,
> 
> We are using squid 2.6 in IBM AIX Server. Do you have any latest RPM 
> for IBM AIX?
> 
> Please advise.
> 

FWIW; I remember some emails from people running Squid on AIX when 2.7 and 3.1 were current. But my lists (in the Squid wiki) do not include any details of where to get any packages newer than 2.6 or who might be making them.

If anyone is making AIX packages that can be shared around please get in touch with me.

Alternatively if anyone is successfully running packages built for some other OS on AIX systems that would be useful info for the wiki.


Charles;
  If nothing comes up specifically for AIX then I expect Eliezer's RPMs 
for CentOS, RHEL or Solaris should be usable. Though you may need to 
re-build from the SRPM to account for OS library differences.

HTH
Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users




From eliezer at ngtech.co.il  Wed Jul  5 09:25:02 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 5 Jul 2017 12:25:02 +0300
Subject: [squid-users] Can I use an external ACL helper for "cache allow x"
	or "cache deny y" ?
Message-ID: <24c901d2f570$94c8b710$be5a2530$@ngtech.co.il>

Hey,

I was wondering to myself:
We have lots of acls but I am not sure if it's possible or not.
I want to cache specific files only after a specific amount of times that
they were downloaded requested over a specific period of time.
Now what I want to try is to write an external ACL helper that will work
with a counter in a DB and that will count each url hit.
Then if a specific URL is being hit more then let say 5 times per a period
of time which garbage collection runs or memcached or redis with an
expiration time,
this object will be allowed to be cached.

It's a lot of data on a busy systems but for specific domains it's useful.

Can an external acl helper be used for "cache deny x" or "cache allow y"?

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il






From rousskov at measurement-factory.com  Wed Jul  5 14:36:52 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 5 Jul 2017 08:36:52 -0600
Subject: [squid-users] Can I use an external ACL helper for "cache allow
 x" or "cache deny y" ?
In-Reply-To: <24c901d2f570$94c8b710$be5a2530$@ngtech.co.il>
References: <24c901d2f570$94c8b710$be5a2530$@ngtech.co.il>
Message-ID: <dba90ddc-2d1e-74e8-2503-85ba8d2f2a2f@measurement-factory.com>

On 07/05/2017 03:25 AM, Eliezer Croitoru wrote:

> Can an external acl helper be used for "cache deny x" or "cache allow y"?

Yes, the "cache" directive supports "slow" ACLs, and an external ACL is
a slow ACL:

>From http://www.squid-cache.org/Doc/config/cache

> * cache: Checked before Squid makes a hit/miss determination.
> 		No access to reply information!
> 		Denies both serving a hit and storing a miss.
> 		Supports both fast and slow ACLs.

>From http://www.squid-cache.org/Doc/config/acl

> acl aclname external class_name [arguments...]
> 	  # external ACL lookup via a helper class defined by the
> 	  # external_acl_type directive [slow]

Alex.


From erdosain9 at gmail.com  Wed Jul  5 14:30:44 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Wed, 5 Jul 2017 07:30:44 -0700 (PDT)
Subject: [squid-users] open failed to
	shm_open(/squid-ssl_session_cache.shm)
In-Reply-To: <1499259740565-4682990.post@n4.nabble.com>
References: <1499096230019-4682961.post@n4.nabble.com>
 <1499259740565-4682990.post@n4.nabble.com>
Message-ID: <1499265044439-4682992.post@n4.nabble.com>

Hi.
Why you say "This is because you use two commands"? 
i use systemctl reload squid. or systemctl stop, start....

This is the cache.log

Thanks to all.

2017/07/05 07:41:07 kid1| Error negotiating SSL on FD 161:
error:00000000:lib(0):func(0):reason(0) (5/-1/104)
2017/07/05 07:42:29 kid1| Error negotiating SSL on FD 93:
error:00000000:lib(0):func(0):reason(0) (5/-1/104)
2017/07/05 08:13:28 kid1| Error negotiating SSL on FD 136:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 08:13:28 kid1| Error negotiating SSL on FD 136:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 08:13:29 kid1| Error negotiating SSL on FD 136:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 08:13:29 kid1| Error negotiating SSL on FD 112:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 08:13:29 kid1| Error negotiating SSL on FD 112:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 08:13:30 kid1| Error negotiating SSL on FD 112:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 08:22:26 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 08:22:26 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 08:22:26 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 08:22:26 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 08:22:26 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 08:22:26 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 08:22:26 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 08:22:26 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 08:22:26 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 08:45:23 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/07/05 08:45:23 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/07/05 08:45:23 kid1| NETDB state saved; 0 entries, 0 msec
2017/07/05 09:08:44 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br08.zopim.com/s/W/xdds/Aep43AMeh1O8Vlwe/p/1499256649501 AKA
br08.zopim.com/s/W/xdds/Aep43AMeh1O8Vlwe/p/1499256649501
2017/07/05 09:10:45 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br08.zopim.com/s/W/xdds/Aep43AMeh1O8Vlwe/p/1499256770077 AKA
br08.zopim.com/s/W/xdds/Aep43AMeh1O8Vlwe/p/1499256770077
2017/07/05 09:12:45 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br08.zopim.com/s/W/xdds/Aep43AMeh1O8Vlwe/p/1499256890082 AKA
br08.zopim.com/s/W/xdds/Aep43AMeh1O8Vlwe/p/1499256890082
2017/07/05 09:14:28 kid1| Error negotiating SSL on FD 119:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 09:14:39 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br02.zopim.com/s/W/xdds/7mNYAXLNdYVGN3KW/p/1499257004386 AKA
br02.zopim.com/s/W/xdds/7mNYAXLNdYVGN3KW/p/1499257004386
2017/07/05 09:16:39 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br02.zopim.com/s/W/xdds/7mNYAXLNdYVGN3KW/p/1499257124091 AKA
br02.zopim.com/s/W/xdds/7mNYAXLNdYVGN3KW/p/1499257124091
2017/07/05 09:18:39 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br02.zopim.com/s/W/xdds/7mNYAXLNdYVGN3KW/p/1499257244092 AKA
br02.zopim.com/s/W/xdds/7mNYAXLNdYVGN3KW/p/1499257244092
2017/07/05 09:20:31 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://ct-m-fbx.fbsbx.com/fp/clear.png?org_id=j8ck72di&session_id=araflybsfmbnfree&je=333126247f6d6070766b5d636c7665726e636c5d61783f333b3a2c3b343a2e312e333134
AKA
ct-m-fbx.fbsbx.com/fp/clear.png?org_id=j8ck72di&session_id=araflybsfmbnfree&je=333126247f6d6070766b5d636c7665726e636c5d61783f333b3a2c3b343a2e312e333134
2017/07/05 09:22:35 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br02.zopim.com/s/W/xdds/RwyggWx9nKXxEZRw/p/1499257480125 AKA
br02.zopim.com/s/W/xdds/RwyggWx9nKXxEZRw/p/1499257480125
2017/07/05 09:24:04 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br02.zopim.com/s/W/xdds/U7YAcQjwdF8M8Ofg/p/1499257569147 AKA
br02.zopim.com/s/W/xdds/U7YAcQjwdF8M8Ofg/p/1499257569147
2017/07/05 09:25:24 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/07/05 09:25:24 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/07/05 09:25:24 kid1| NETDB state saved; 0 entries, 0 msec
2017/07/05 09:27:40 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SVG7iMq7HssfDa0o/p/1499257785136 AKA
br06.zopim.com/s/W/xdds/SVG7iMq7HssfDa0o/p/1499257785136
2017/07/05 09:30:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/KT9+mfNqZMpcQY44/p/1499257982679 AKA
br06.zopim.com/s/W/xdds/KT9+mfNqZMpcQY44/p/1499257982679
2017/07/05 09:32:58 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/KT9+mfNqZMpcQY44/p/1499258103075 AKA
br06.zopim.com/s/W/xdds/KT9+mfNqZMpcQY44/p/1499258103075
2017/07/05 09:34:04 kid1| urlParse: URL too large (9586 bytes)
2017/07/05 09:34:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/KT9+mfNqZMpcQY44/p/1499258222639 AKA
br06.zopim.com/s/W/xdds/KT9+mfNqZMpcQY44/p/1499258222639
2017/07/05 09:36:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/KT9+mfNqZMpcQY44/p/1499258342641 AKA
br06.zopim.com/s/W/xdds/KT9+mfNqZMpcQY44/p/1499258342641
2017/07/05 09:38:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/KT9+mfNqZMpcQY44/p/1499258462643 AKA
br06.zopim.com/s/W/xdds/KT9+mfNqZMpcQY44/p/1499258462643
2017/07/05 09:39:18 kid1| Error negotiating SSL on FD 261:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 09:40:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/KT9+mfNqZMpcQY44/p/1499258582646 AKA
br06.zopim.com/s/W/xdds/KT9+mfNqZMpcQY44/p/1499258582646
2017/07/05 09:42:41 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/m5wchgbydLaNImyt/p/1499258686194 AKA
br06.zopim.com/s/W/xdds/m5wchgbydLaNImyt/p/1499258686194
2017/07/05 09:44:11 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/m5wchgbydLaNImyt/p/1499258776437 AKA
br06.zopim.com/s/W/xdds/m5wchgbydLaNImyt/p/1499258776437
2017/07/05 09:46:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499258942145 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499258942145
2017/07/05 09:48:56 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499259061227 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499259061227
2017/07/05 09:50:56 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499259181212 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499259181212
2017/07/05 09:52:56 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499259301215 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499259301215
2017/07/05 09:54:56 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499259421219 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499259421219
2017/07/05 09:56:56 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499259541222 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499259541222
2017/07/05 09:58:56 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499259661220 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499259661220
2017/07/05 10:00:56 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499259781229 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499259781229
2017/07/05 10:02:56 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499259901228 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499259901228
2017/07/05 10:04:56 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260021244 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260021244
2017/07/05 10:05:47 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:05:47 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:06:17 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:06:17 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:06:49 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:06:49 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:06:56 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260141240 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260141240
2017/07/05 10:08:01 kid1| Error negotiating SSL connection on FD 171: (104)
Connection reset by peer
2017/07/05 10:08:56 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260261242 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260261242
2017/07/05 10:09:12 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'NTLM
TlRMTVNTUAABAAAAB7IIogYABgAvAAAABwAHACgAAAAGAbEdAAAAD1BZQS1HLTNFTVBEREg='
2017/07/05 10:09:12 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'NTLM
TlRMTVNTUAABAAAAB7IIogYABgAvAAAABwAHACgAAAAGAbEdAAAAD1BZQS1HLTNFTVBEREg='
2017/07/05 10:09:12 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'NTLM
TlRMTVNTUAABAAAAB7IIogYABgAvAAAABwAHACgAAAAGAbEdAAAAD1BZQS1HLTNFTVBEREg='
2017/07/05 10:09:12 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'NTLM
TlRMTVNTUAABAAAAB7IIogYABgAvAAAABwAHACgAAAAGAbEdAAAAD1BZQS1HLTNFTVBEREg='
2017/07/05 10:09:12 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'NTLM
TlRMTVNTUAABAAAAB7IIogYABgAvAAAABwAHACgAAAAGAbEdAAAAD1BZQS1HLTNFTVBEREg='
2017/07/05 10:09:12 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'NTLM
TlRMTVNTUAABAAAAB7IIogYABgAvAAAABwAHACgAAAAGAbEdAAAAD1BZQS1HLTNFTVBEREg='
2017/07/05 10:10:56 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260381249 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260381249
2017/07/05 10:12:56 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260501256 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260501256
2017/07/05 10:14:56 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260621264 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260621264
2017/07/05 10:16:56 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260741255 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260741255
2017/07/05 10:18:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260862166 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260862166
2017/07/05 10:20:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260982158 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499260982158
2017/07/05 10:22:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499261102151 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499261102151
2017/07/05 10:24:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499261222143 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499261222143
2017/07/05 10:26:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499261342136 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499261342136
2017/07/05 10:27:16 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://ct-m-fbx.fbsbx.com/fp/clear.png?org_id=j8ck72di&session_id=araspsmvs5pexiht&je=393b2670643f5e4c413a3539383a244150413a373235312e56563a35313b31267266743f36313b31312d313339243d3930322d33313324373b30312d303824353932322f343724373b30332d3f3f2433333a392f393724373037392d3e3924353931392f3534
AKA
ct-m-fbx.fbsbx.com/fp/clear.png?org_id=j8ck72di&session_id=araspsmvs5pexiht&je=393b2670643f5e4c413a3539383a244150413a373235312e56563a35313b31267266743f36313b31312d313339243d3930322d33313324373b30312d303824353932322f343724373b30332d3f3f2433333a392f393724373037392d3e3924353931392f3534
2017/07/05 10:28:53 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/07/05 10:28:53 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/07/05 10:28:53 kid1| NETDB state saved; 0 entries, 0 msec
2017/07/05 10:28:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499261462129 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499261462129
2017/07/05 10:30:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499261582127 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499261582127
2017/07/05 10:32:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499261702132 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499261702132
2017/07/05 10:34:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499261822138 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499261822138
2017/07/05 10:35:10 kid1| Error negotiating SSL connection on FD 31: (104)
Connection reset by peer
2017/07/05 10:35:22 kid1| Error negotiating SSL connection on FD 53: (104)
Connection reset by peer
2017/07/05 10:36:05 kid1| Error negotiating SSL connection on FD 227: (104)
Connection reset by peer
2017/07/05 10:36:05 kid1| Error negotiating SSL connection on FD 223: (104)
Connection reset by peer
2017/07/05 10:36:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499261942144 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499261942144
2017/07/05 10:37:26 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'Basic Og=='
2017/07/05 10:37:26 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'Basic Og=='
2017/07/05 10:37:26 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'Basic Og=='
2017/07/05 10:37:26 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'Basic Og=='
2017/07/05 10:37:26 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'Basic Og=='
2017/07/05 10:37:26 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'Basic Og=='
2017/07/05 10:37:26 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:26 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:26 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:26 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:26 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:26 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:26 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:27 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:27 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:27 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:27 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:27 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:27 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:27 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:27 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:27 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:28 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:28 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:28 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:28 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:28 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:28 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:28 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:28 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:28 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:29 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:29 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:29 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:29 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:29 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:29 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:29 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:29 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:29 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:30 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:30 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:30 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:30 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:30 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:30 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:30 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:30 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:30 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:31 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:31 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:31 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:31 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:31 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:31 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:31 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:31 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:31 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:32 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:32 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:32 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:32 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:32 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:32 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:32 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:32 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:32 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:33 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:33 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:33 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:33 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:33 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:33 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:33 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:33 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:33 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:34 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:34 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:34 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:34 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:34 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:34 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:34 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:34 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:34 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:35 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:35 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:35 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:35 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:35 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:35 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:35 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:35 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:35 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:36 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:36 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:36 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:36 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:36 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:36 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:36 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:36 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:36 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:37 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:37 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:37 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:37 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:37 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:37 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:37 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:37 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:38 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:38 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:38 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:38 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:38 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:38 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:38 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:38 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:38 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:39 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:39 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:39 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:39 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:39 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:39 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:39 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:39 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:39 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:40 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:40 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:40 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:40 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:40 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:40 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:40 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:40 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:40 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:40 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:41 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:41 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:41 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:41 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:41 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:41 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:41 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:41 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:41 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:42 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:42 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:42 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:42 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:42 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:42 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:42 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:42 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:43 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:43 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:43 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:43 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:43 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:43 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:43 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:43 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:44 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:44 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:44 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:44 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:44 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:44 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:44 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:44 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:44 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:45 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:45 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:45 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:45 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:45 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:45 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:45 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:45 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:45 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:46 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:46 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:46 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:46 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:46 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:46 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:46 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:46 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:46 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:47 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:47 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:47 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:47 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:47 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:47 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:47 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:47 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:47 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:48 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:48 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:48 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:48 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:48 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:48 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:48 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:48 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:48 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:49 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:49 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:49 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:49 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:49 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:49 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:49 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:49 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:50 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:50 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:50 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:50 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:50 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:50 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:50 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:50 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:50 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:51 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:51 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:51 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:51 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:51 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:51 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:51 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:51 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:51 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:52 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:52 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:52 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:52 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:52 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:52 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:52 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:52 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:52 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:53 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:53 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:53 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:53 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:53 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:53 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:53 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:53 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:53 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:54 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:54 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:54 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:54 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:54 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:54 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:54 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:54 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:54 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:55 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:55 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:55 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:37:55 kid1| ERROR: Negotiate Authentication validating user.
Result: {result=BH, notes={message: received type 1 NTLM token; }}
2017/07/05 10:38:04 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://ct-m-fbx.fbsbx.com/fp/clear.png?org_id=j8ck72di&session_id=arayr8nlrus6vkpb&je=3731267a66352c7a66743f34313933312d37382437313a382f35342e373330332d36302437313a3a2f363a2e373330312d343824313b32312f3133322e3f3235392f35392e3d333b3b2d3b34
AKA
ct-m-fbx.fbsbx.com/fp/clear.png?org_id=j8ck72di&session_id=arayr8nlrus6vkpb&je=3731267a66352c7a66743f34313933312d37382437313a382f35342e373330332d36302437313a3a2f363a2e373330312d343824313b32312f3133322e3f3235392f35392e3d333b3b2d3b34
2017/07/05 10:38:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499262062148 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499262062148
2017/07/05 10:40:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499262182154 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499262182154
2017/07/05 10:42:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499262302160 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499262302160
2017/07/05 10:43:32 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:43:32 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:44:02 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:44:02 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:44:33 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:44:33 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:44:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499262422165 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499262422165
2017/07/05 10:45:02 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:45:02 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:45:32 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:45:32 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:46:02 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:46:02 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:46:32 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:46:32 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:46:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499262542168 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499262542168
2017/07/05 10:47:02 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:47:02 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:47:33 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:47:33 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:47:56 kid1| WARNING: Closing client connection due to lifetime
timeout
2017/07/05 10:47:56 kid1| 	wer.microsoft.com:443
2017/07/05 10:48:03 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:48:03 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:48:26 kid1| WARNING: Closing client connection due to lifetime
timeout
2017/07/05 10:48:26 kid1| 	wer.microsoft.com:443
2017/07/05 10:48:32 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:48:32 kid1| ipcacheParse: No Address records in response to
'wer.microsoft.com'
2017/07/05 10:48:56 kid1| WARNING: Closing client connection due to lifetime
timeout
2017/07/05 10:48:56 kid1| 	wer.microsoft.com:443
2017/07/05 10:48:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499262662173 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499262662173
2017/07/05 10:49:26 kid1| WARNING: Closing client connection due to lifetime
timeout
2017/07/05 10:49:26 kid1| 	wer.microsoft.com:443
2017/07/05 10:49:56 kid1| WARNING: Closing client connection due to lifetime
timeout
2017/07/05 10:49:56 kid1| 	wer.microsoft.com:443
2017/07/05 10:50:25 kid1| Error negotiating SSL on FD 593:
error:00000000:lib(0):func(0):reason(0) (5/-1/104)
2017/07/05 10:50:26 kid1| WARNING: Closing client connection due to lifetime
timeout
2017/07/05 10:50:26 kid1| 	wer.microsoft.com:443
2017/07/05 10:50:44 kid1| urlParse: URL too large (10619 bytes)
2017/07/05 10:50:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499262782178 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499262782178
2017/07/05 10:52:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499262902184 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499262902184
2017/07/05 10:54:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263022191 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263022191
2017/07/05 10:56:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263142195 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263142195
2017/07/05 10:58:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263262199 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263262199
2017/07/05 10:59:37 kid1| WARNING: Closing client connection due to lifetime
timeout
2017/07/05 10:59:37 kid1| 	wer.microsoft.com:443
2017/07/05 11:00:07 kid1| WARNING: Closing client connection due to lifetime
timeout
2017/07/05 11:00:07 kid1| 	wer.microsoft.com:443
2017/07/05 11:00:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263382204 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263382204
2017/07/05 11:02:02 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://content.mercadolibre.com/fp/clear.png?org_id=jk96mpy0&session=0b15f89e-d8d4-452d-b3d5-cc08cf1aa62f&ja=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&jb=313133266e79354d677a616c6c6925324435263227323020556b6e6c6d75732532324c56253030362c3921253a304970706465576762436b7625324e3731372631342532302a494a544f4c25304b2d32386c616b652d323045656b696d29253a3241687a6d6f65253244373b2e322e33323f392e39313d253238536164617a6b2732463d31352e3b34
AKA
content.mercadolibre.com/fp/clear.png?org_id=jk96mpy0&session=0b15f89e-d8d4-452d-b3d5-cc08cf1aa62f&ja=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&jb=313133266e79354d677a616c6c6925324435263227323020556b6e6c6d75732532324c56253030362c3921253a304970706465576762436b7625324e3731372631342532302a494a544f4c25304b2d32386c616b652d323045656b696d29253a3241687a6d6f65253244373b2e322e33323f392e39313d253238536164617a6b2732463d31352e3b34
2017/07/05 11:02:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263502210 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263502210
2017/07/05 11:04:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263622216 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263622216
2017/07/05 11:04:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263622216 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263622216
2017/07/05 11:05:49 kid1| urlParse: URL too large (9250 bytes)
2017/07/05 11:06:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263742220 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263742220
2017/07/05 11:08:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263862226 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263862226
2017/07/05 11:09:38 kid1| Error negotiating SSL on FD 569:
error:00000000:lib(0):func(0):reason(0) (5/-1/104)
2017/07/05 11:09:57 kid1| Logfile: opening log
stdio:/var/log/squid/netdb.state
2017/07/05 11:09:57 kid1| Logfile: closing log
stdio:/var/log/squid/netdb.state
2017/07/05 11:09:57 kid1| NETDB state saved; 0 entries, 0 msec
2017/07/05 11:10:57 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263982232 AKA
br06.zopim.com/s/W/xdds/SwSJ1pFwPt6pKYO3/p/1499263982232
2017/07/05 11:13:15 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/Uazkp-B-XltgUtQl/p/1499264120263 AKA
br06.zopim.com/s/W/xdds/Uazkp-B-XltgUtQl/p/1499264120263
2017/07/05 11:15:14 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/Uazkp-B-XltgUtQl/p/1499264239304 AKA
br06.zopim.com/s/W/xdds/Uazkp-B-XltgUtQl/p/1499264239304
2017/07/05 11:16:15 kid1| Error negotiating SSL on FD 421:
error:00000000:lib(0):func(0):reason(0) (5/-1/104)
2017/07/05 11:16:46 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499264331256 AKA
br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499264331256
2017/07/05 11:17:09 kid1| urlParse: URL too large (26073 bytes)
2017/07/05 11:18:45 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499264450347 AKA
br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499264450347
2017/07/05 11:18:57 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'NTLM
TlRMTVNTUAABAAAAB7IIogYABgAyAAAACgAKACgAAAAGAbEdAAAAD1BSRS1JU0xBLTNFTVBEREg='
2017/07/05 11:18:57 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'NTLM
TlRMTVNTUAABAAAAB7IIogYABgAyAAAACgAKACgAAAAGAbEdAAAAD1BSRS1JU0xBLTNFTVBEREg='
2017/07/05 11:18:57 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'NTLM
TlRMTVNTUAABAAAAB7IIogYABgAyAAAACgAKACgAAAAGAbEdAAAAD1BSRS1JU0xBLTNFTVBEREg='
2017/07/05 11:18:57 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'NTLM
TlRMTVNTUAABAAAAB7IIogYABgAyAAAACgAKACgAAAAGAbEdAAAAD1BSRS1JU0xBLTNFTVBEREg='
2017/07/05 11:18:57 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'NTLM
TlRMTVNTUAABAAAAB7IIogYABgAyAAAACgAKACgAAAAGAbEdAAAAD1BSRS1JU0xBLTNFTVBEREg='
2017/07/05 11:18:57 kid1| WARNING: Unsupported or unconfigured/inactive
proxy-auth scheme, 'NTLM
TlRMTVNTUAABAAAAB7IIogYABgAyAAAACgAKACgAAAAGAbEdAAAAD1BSRS1JU0xBLTNFTVBEREg='
2017/07/05 11:20:45 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499264570355 AKA
br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499264570355
2017/07/05 11:22:37 kid1| SSL unknown certificate error -3 in
/C=US/ST=California/L=Mountain View/O=Google Inc/CN=*.googleusercontent.com
2017/07/05 11:22:37 kid1| Error negotiating SSL on FD 385:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:22:45 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499264690353 AKA
br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499264690353
2017/07/05 11:24:45 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499264810349 AKA
br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499264810349
2017/07/05 11:25:54 kid1| Error negotiating SSL on FD 644:
error:00000000:lib(0):func(0):reason(0) (5/-1/104)
2017/07/05 11:26:45 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499264930346 AKA
br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499264930346
2017/07/05 11:28:45 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499265050334 AKA
br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499265050334
2017/07/05 11:30:32 kid1| ipcacheParse: No Address records in response to
'go.microsoft.com'
2017/07/05 11:30:32 kid1| ipcacheParse: No Address records in response to
'go.microsoft.com'
2017/07/05 11:30:45 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499265170326 AKA
br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499265170326
2017/07/05 11:30:49 kid1| Error negotiating SSL on FD 532:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:30:49 kid1| Error negotiating SSL on FD 532:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:30:51 kid1| Error negotiating SSL on FD 186:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:30:51 kid1| Error negotiating SSL on FD 75: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:31:55 kid1| Error negotiating SSL on FD 380:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:31:55 kid1| Error negotiating SSL on FD 380:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:31:55 kid1| Error negotiating SSL on FD 380:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:31:55 kid1| Error negotiating SSL on FD 380:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:31:56 kid1| Error negotiating SSL on FD 380:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:31:56 kid1| Error negotiating SSL on FD 380:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:32:45 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499265290318 AKA
br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499265290318
2017/07/05 11:33:36 kid1| Error negotiating SSL on FD 236:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:34:45 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499265410313 AKA
br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499265410313
2017/07/05 11:36:45 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499265530314 AKA
br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499265530314
2017/07/05 11:36:52 kid1| WARNING: HTTP: Invalid Response: No object data
received for https://www.iberiaplus25.com/js/select2-dist.js AKA
www.iberiaplus25.com/js/select2-dist.js
2017/07/05 11:38:45 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499265650332 AKA
br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499265650332
2017/07/05 11:40:07 kid1| Error negotiating SSL on FD 596:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:07 kid1| Error negotiating SSL on FD 596:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:08 kid1| Error negotiating SSL on FD 590:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:08 kid1| Error negotiating SSL on FD 590:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:09 kid1| Error negotiating SSL on FD 216:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:09 kid1| Error negotiating SSL on FD 25: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:40:09 kid1| Error negotiating SSL on FD 25: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:40:10 kid1| Error negotiating SSL on FD 25: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:40:10 kid1| Error negotiating SSL on FD 25: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:40:12 kid1| Error negotiating SSL on FD 25: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:40:12 kid1| Error negotiating SSL on FD 25: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:40:13 kid1| Error negotiating SSL on FD 25: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:40:13 kid1| Error negotiating SSL on FD 25: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:40:13 kid1| Error negotiating SSL on FD 25: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:40:14 kid1| Error negotiating SSL on FD 25: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:40:28 kid1| Error negotiating SSL on FD 779:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:29 kid1| Error negotiating SSL on FD 779:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:29 kid1| Error negotiating SSL on FD 355:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:29 kid1| Error negotiating SSL on FD 355:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:30 kid1| Error negotiating SSL on FD 355:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:30 kid1| Error negotiating SSL on FD 355:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:30 kid1| Error negotiating SSL on FD 355:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:31 kid1| Error negotiating SSL on FD 355:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:31 kid1| Error negotiating SSL on FD 355:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:32 kid1| Error negotiating SSL on FD 355:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:32 kid1| Error negotiating SSL on FD 355:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:32 kid1| Error negotiating SSL on FD 184:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:33 kid1| Error negotiating SSL on FD 184:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:33 kid1| Error negotiating SSL on FD 184:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:33 kid1| Error negotiating SSL on FD 184:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:45 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499265770306 AKA
br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499265770306
2017/07/05 11:40:52 kid1| Error negotiating SSL on FD 688:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:53 kid1| Error negotiating SSL on FD 688:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:53 kid1| Error negotiating SSL on FD 688:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:54 kid1| Error negotiating SSL on FD 688:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:54 kid1| Error negotiating SSL on FD 600:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:54 kid1| Error negotiating SSL on FD 600:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:55 kid1| Error negotiating SSL on FD 187:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:55 kid1| Error negotiating SSL on FD 121:
error:14090086:SSL routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify
failed (1/-1/0)
2017/07/05 11:40:55 kid1| Error negotiating SSL on FD 68: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:40:56 kid1| Error negotiating SSL on FD 68: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:40:56 kid1| Error negotiating SSL on FD 68: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:40:57 kid1| Error negotiating SSL on FD 68: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:40:57 kid1| Error negotiating SSL on FD 68: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:40:57 kid1| Error negotiating SSL on FD 68: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:40:58 kid1| Error negotiating SSL on FD 68: error:14090086:SSL
routines:SSL3_GET_SERVER_CERTIFICATE:certificate verify failed (1/-1/0)
2017/07/05 11:42:45 kid1| WARNING: HTTP: Invalid Response: No object data
received for
https://br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499265890319 AKA
br06.zopim.com/s/W/xdds/TU+MsTUur3ul8iE6/p/1499265890319






--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/open-failed-to-shm-open-squid-ssl-session-cache-shm-tp4682961p4682992.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From webmaster at squidblacklist.org  Wed Jul  5 18:19:49 2017
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Wed, 5 Jul 2017 13:19:49 -0500
Subject: [squid-users] Gratis Domain Whitelists Now Available -
	Squidblacklist.org
Message-ID: <72dfbfe0-cc87-686f-e001-582b498ea631@squidblacklist.org>

For those in this community who are filtering content, I Just wanted to 
give you guys a heads  up, we now have a gratis domain whitelist area of 
our website.

Files can be found at the following url,

http://www.squidblacklist.org/downloads/whitelists/

As time progresses we will be adding more, and more lists.

Thank you.

-- 

Signed,

Benjamin E. Nichols
http://www.squidblacklist.org



From eliezer at ngtech.co.il  Wed Jul  5 19:07:47 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 5 Jul 2017 22:07:47 +0300
Subject: [squid-users] Can I use an external ACL helper for "cache allow
	x" or "cache deny y" ?
In-Reply-To: <dba90ddc-2d1e-74e8-2503-85ba8d2f2a2f@measurement-factory.com>
References: <24c901d2f570$94c8b710$be5a2530$@ngtech.co.il>
 <dba90ddc-2d1e-74e8-2503-85ba8d2f2a2f@measurement-factory.com>
Message-ID: <26a801d2f5c1$fd3cd000$f7b67000$@ngtech.co.il>

Thanks Alex,

I will start with a simple example which supports concurrency.
I will start with a Ruby+memcache\redis simple helper and will move on towards a full blown GoLang based one.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: Alex Rousskov [mailto:rousskov at measurement-factory.com] 
Sent: Wednesday, July 5, 2017 17:37
To: Eliezer Croitoru <eliezer at ngtech.co.il>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Can I use an external ACL helper for "cache allow x" or "cache deny y" ?

On 07/05/2017 03:25 AM, Eliezer Croitoru wrote:

> Can an external acl helper be used for "cache deny x" or "cache allow y"?

Yes, the "cache" directive supports "slow" ACLs, and an external ACL is
a slow ACL:

>From http://www.squid-cache.org/Doc/config/cache

> * cache: Checked before Squid makes a hit/miss determination.
> 		No access to reply information!
> 		Denies both serving a hit and storing a miss.
> 		Supports both fast and slow ACLs.

>From http://www.squid-cache.org/Doc/config/acl

> acl aclname external class_name [arguments...]
> 	  # external ACL lookup via a helper class defined by the
> 	  # external_acl_type directive [slow]

Alex.



From erdosain9 at gmail.com  Thu Jul  6 13:08:32 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 6 Jul 2017 06:08:32 -0700 (PDT)
Subject: [squid-users] The best way to start | stop | reload | status
Message-ID: <1499346512484-4682998.post@n4.nabble.com>

Hi.
mmm... im having a doubt.
I usually use Systemctl for start, stop, reload, and status; but sometimes i
heard that it was not the best way to do these actions.
Way? I heard something wrong?
And if not the best way, what would it be?

1) squid -z
2) squid

???

And from there, how i can stop and reload, status??
And, if this is the best way, how do I start Squid automatically when the
system boots?

(Or is it really not relevant?)

Thanks to all!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/The-best-way-to-start-stop-reload-status-tp4682998.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Thu Jul  6 13:22:48 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 6 Jul 2017 06:22:48 -0700 (PDT)
Subject: [squid-users] Dstdomain "there are more than 100 regular
	expressions"
Message-ID: <1499347368854-4682999.post@n4.nabble.com>

Hi. I have this in my cache.log

ad_block, is a list for block publicity. 

there is a best way to do that??

2017/07/06 10:35:49| /etc/squid/squid.conf line 55: acl ads dstdom_regex
"/etc/squid/listas/ad_block.lst"
2017/07/06 10:35:49| WARNING: there are more than 100 regular expressions.
Consider using less REs or use rules without expressions like 'dstdomain'.


Thanks to all.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Dstdomain-there-are-more-than-100-regular-expressions-tp4682999.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From dijxie at gmail.com  Thu Jul  6 14:11:44 2017
From: dijxie at gmail.com (Dijxie)
Date: Thu, 6 Jul 2017 16:11:44 +0200
Subject: [squid-users] The best way to start | stop | reload | status
In-Reply-To: <1499346512484-4682998.post@n4.nabble.com>
References: <1499346512484-4682998.post@n4.nabble.com>
Message-ID: <42070a22-d7a6-c77e-e23c-b932b363d288@gmail.com>

W dniu 06.07.2017 o 15:08, erdosain9 pisze:
> Hi.
> mmm... im having a doubt.
> I usually use Systemctl for start, stop, reload, and status; but sometimes i
> heard that it was not the best way to do these actions.
> Way? I heard something wrong?
> And if not the best way, what would it be?
>
> 1) squid -z
> 2) squid
>
> ???
>
> And from there, how i can stop and reload, status??
> And, if this is the best way, how do I start Squid automatically when the
> system boots?
>
> (Or is it really not relevant?)
>
> Thanks to all!
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/The-best-way-to-start-stop-reload-status-tp4682998.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

squid -k check|reconfigure etc for interaction with squid process. 
Reconfigure is for reload config files, external ACL files, as well as 
for i.e. refreshing cached group members in case if external ACL used.
Usually, the best way to start/stop/restart squid is to use your init, 
i.e. systemctl stop squid, service squid stop, /etc/init.d/squid stop. 
Depending of distro, squid usually has systemd-unit-file or upstart/init 
script. For reload configuration, personally I always use squid -k 
reconfigure.

But if you want to/need to, you do not have to run squid as a 
daemon/service, you can start it via cron or whatever you like. Init is 
usually the best way, since it handles things like order, dependiencies, 
runlevels etc. - that is what is it for.

-- 
Greets, Dijx.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170706/6a9bbe0e/attachment.htm>

From dijxie at gmail.com  Thu Jul  6 14:31:14 2017
From: dijxie at gmail.com (Dijxie)
Date: Thu, 6 Jul 2017 16:31:14 +0200
Subject: [squid-users] Dstdomain "there are more than 100 regular
 expressions"
In-Reply-To: <1499347368854-4682999.post@n4.nabble.com>
References: <1499347368854-4682999.post@n4.nabble.com>
Message-ID: <ed523fb4-c2d5-7198-ff1f-ecec6861a0e7@gmail.com>

W dniu 06.07.2017 o 15:22, erdosain9 pisze:
> Hi. I have this in my cache.log
>
> ad_block, is a list for block publicity.
>
> there is a best way to do that??
>
> 2017/07/06 10:35:49| /etc/squid/squid.conf line 55: acl ads dstdom_regex
> "/etc/squid/listas/ad_block.lst"
> 2017/07/06 10:35:49| WARNING: there are more than 100 regular expressions.
> Consider using less REs or use rules without expressions like 'dstdomain'.
>
>
> Thanks to all.
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Dstdomain-there-are-more-than-100-regular-expressions-tp4682999.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

I think best answer will be: ignore that if your squid is running fine, 
or look for external filtering solution like Eliezer's squidblocker or 
squidguard (slow and somehow obsolete, as for me)

Here is good explenation by Amos:
http://squid-web-proxy-cache.1019090.n4.nabble.com/WARNING-there-are-more-than-100-regular-expressions-tp4668529p4668573.html

-- 
Greets, Dijx.

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170706/ca4a0c31/attachment.htm>

From squid3 at treenet.co.nz  Thu Jul  6 14:52:47 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 7 Jul 2017 02:52:47 +1200
Subject: [squid-users] The best way to start | stop | reload | status
In-Reply-To: <1499346512484-4682998.post@n4.nabble.com>
References: <1499346512484-4682998.post@n4.nabble.com>
Message-ID: <9b91cf07-9ea6-2eda-2293-93ecb4ba9a3e@treenet.co.nz>

On 07/07/17 01:08, erdosain9 wrote:
> Hi.
> mmm... im having a doubt.
> I usually use Systemctl for start, stop, reload, and status; but sometimes i
> heard that it was not the best way to do these actions.
> Way? I heard something wrong?

Because systemctl is a daemon manager. The "squid" binary is also a 
daemon manager. Having a daemon manager manage another daemon manager 
leads to some very odd behaviours.

People are finding out the hard way what those problems are since 
systemd merged daemon management into the init system on many OS.

NP: In Squid-4 we have completely redesigned the way Squid processes 
integrate so that it can be run under a different daemon manager.


> And if not the best way, what would it be?
> 
> 1) squid -z
> 2) squid
> 
> ???
> 

The squid -k options. See 
<http://www.squid-cache.org/Versions/v3/3.5/manuals/squid.html>

NP: -z is to format or repair the cache_dir storage area(s).


> And from there, how i can stop and reload, status??

"squid -k check" for status, it will exit with an error message if Squid 
is not running, and succeed if one is running.

The others should be obvious from the above documentation manual.


> And, if this is the best way, how do I start Squid automatically when the
> system boots?

If you are using a packaged binary the vendor should have setup 
appropriate integration to be installed already.

Otherwise, the tools/ directory in Squid source bundles contain whatever 
is needed for integration into the various init systems that version of 
Squid can be used with. For Squid-3 that is any init system that 
supports rc.d scripting.

Amos


From squid3 at treenet.co.nz  Thu Jul  6 15:16:15 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 7 Jul 2017 03:16:15 +1200
Subject: [squid-users] open failed to
 shm_open(/squid-ssl_session_cache.shm)
In-Reply-To: <1499265044439-4682992.post@n4.nabble.com>
References: <1499096230019-4682961.post@n4.nabble.com>
 <1499259740565-4682990.post@n4.nabble.com>
 <1499265044439-4682992.post@n4.nabble.com>
Message-ID: <86a990d2-7fe9-cc98-9186-26ceec9069f9@treenet.co.nz>

On 06/07/17 02:30, erdosain9 wrote:
> Hi.
> Why you say "This is because you use two commands"?
> i use systemctl reload squid. or systemctl stop, start....
> 

You appear to be posting through Nabble and responding to someone who is 
not a member of the Squid mailing lists. If you do that, please at least 
quote the details you are responding to.

Amos


From bloggerrazorcross at gmail.com  Thu Jul  6 15:41:46 2017
From: bloggerrazorcross at gmail.com (Razor Cross)
Date: Thu, 6 Jul 2017 10:41:46 -0500
Subject: [squid-users] Squid caching bad objects
In-Reply-To: <CANRy4AVDOhpG6X-u2OKkPEMC0fhDmPvjubDwNU_fSHo3kzJeQw@mail.gmail.com>
References: <CANRy4AV5n4m8PC7fKQJfaZboKxyUG7o7ASuJABRhVfFFfmzjhg@mail.gmail.com>
 <a494df2a-eb3d-acd4-ea08-2bc615348c45@measurement-factory.com>
 <CANRy4AU=5VR+8kmcFdKLbpnxbdTgUCvRopxHV5ypD+0JmujOAA@mail.gmail.com>
 <bdb4c8bc-8d14-b442-53d0-e39ac4b5470e@measurement-factory.com>
 <CANRy4AVDOhpG6X-u2OKkPEMC0fhDmPvjubDwNU_fSHo3kzJeQw@mail.gmail.com>
Message-ID: <CANRy4AXzq7j=vd+TQCcdqRqOvnRCF7cg22sd0ciTTsEO6hqyng@mail.gmail.com>

Hi Amos,
Do you have any insights on the below issue? Is it fixed on latest squid
release?  Your inputs would be really helpful




On Tue, Jun 27, 2017 at 12:04 PM, Razor Cross <bloggerrazorcross at gmail.com>
wrote:

>
>
> On Tue, Jun 27, 2017 at 11:34 AM, Alex Rousskov <
> rousskov at measurement-factory.com> wrote:
>
>> On 06/27/2017 10:11 AM, Razor Cross wrote:
>> > On Mon, Jun 26, 2017 at 12:06 PM, Alex Rousskov wrote:
>>
>> >     >I suspect that the COMPLETE_NONPERSISTENT_MSG case in
>> >     >HttpStateData::processReplyBody() should be changed to call
>> >     >StoreEntry::lengthWentBad("missing last-chunk") when lastChunk is
>> false
>> >     >and HttpStateData::flags.chunked is true.
>>
>> >       We are able to reproduce the issue . If server socket is closed
>> > after sending first chunk of data, squid is caching the partial object
>> > even though it did not receive the remaining chunks.
>>
>> If you are not going to fix this yourself, please consider filing a bug
>> report, citing this email thread.
>>
>>
>> > I feel it has to
>> > make sure that lastchunk has received before caching the data.
>>
>> That is impossible in general (the response may be too big to buffer)
>> but is also unnecessary in most cases (because Squid can stop caching
>> and delete the being-cached object in-flight). My paragraph quoted above
>> has the blueprint for a possible fix.
>>
>> Thanks for your inputs..
> I just want to hear from squid official forum/owner whether it has fixed
> in any recent squid releases so that we can upgrade/patch the fix.
>
>

> - Cross
>
>>
>>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170706/5f09f8de/attachment.htm>

From erdosain9 at gmail.com  Thu Jul  6 18:36:45 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 6 Jul 2017 11:36:45 -0700 (PDT)
Subject: [squid-users] The best way to start | stop | reload | status
In-Reply-To: <9b91cf07-9ea6-2eda-2293-93ecb4ba9a3e@treenet.co.nz>
References: <1499346512484-4682998.post@n4.nabble.com>
 <9b91cf07-9ea6-2eda-2293-93ecb4ba9a3e@treenet.co.nz>
Message-ID: <1499366205201-4683005.post@n4.nabble.com>

Ok, thank you all!



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/The-best-way-to-start-stop-reload-status-tp4682998p4683005.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Fri Jul  7 01:01:38 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 7 Jul 2017 13:01:38 +1200
Subject: [squid-users] Squid caching bad objects
In-Reply-To: <CANRy4AXzq7j=vd+TQCcdqRqOvnRCF7cg22sd0ciTTsEO6hqyng@mail.gmail.com>
References: <CANRy4AV5n4m8PC7fKQJfaZboKxyUG7o7ASuJABRhVfFFfmzjhg@mail.gmail.com>
 <a494df2a-eb3d-acd4-ea08-2bc615348c45@measurement-factory.com>
 <CANRy4AU=5VR+8kmcFdKLbpnxbdTgUCvRopxHV5ypD+0JmujOAA@mail.gmail.com>
 <bdb4c8bc-8d14-b442-53d0-e39ac4b5470e@measurement-factory.com>
 <CANRy4AVDOhpG6X-u2OKkPEMC0fhDmPvjubDwNU_fSHo3kzJeQw@mail.gmail.com>
 <CANRy4AXzq7j=vd+TQCcdqRqOvnRCF7cg22sd0ciTTsEO6hqyng@mail.gmail.com>
Message-ID: <33337f8f-7de2-256d-80c4-2a7a9337b82f@treenet.co.nz>

On 07/07/17 03:41, Razor Cross wrote:
> Hi Amos,
> Do you have any insights on the below issue? Is it fixed on latest squid 
> release?  Your inputs would be really helpful
>

If that means you consider me Squid "owner" or official spokesperson. 
Well, I am one such, but so is Alex. If it helps 
<http://wiki.squid-cache.org/WhoWeAre> lists the people most central to 
Squid Project and what their roles are. I defer to Alex most of the time 
when it comes to the internal cache/store operations since his Factory 
team have done the most recent and extensive redesign work for that code.


As to the problem;

AFAIK Squid currently should not be caching these objects at all. Or 
when it does use the disk cache as a temporary storage (eg for very 
large objects) marking them for immediate discard when the abort 
happens. That is being tracked by 
<http://bugs.squid-cache.org/show_bug.cgi?id=424>.

If that situation has changed and these objects are now being stored 
incorrectly, that would be a new bug which is both a regression on the 
old safe cache behaviour and blocking the 424 bug. I second Alexs' comments.


Amos


From xeron.oskom at gmail.com  Fri Jul  7 01:55:48 2017
From: xeron.oskom at gmail.com (Ivan Larionov)
Date: Thu, 6 Jul 2017 18:55:48 -0700
Subject: [squid-users] Huge amount of time_wait connections after
 upgrade from v2 to v3
In-Reply-To: <ca593b00-8727-c816-8169-d6c528c51d93@treenet.co.nz>
References: <CAHvB88x+nNYMtmNZWqrZo-p==UykYDj5dZF+5N1eC3rGR8ybGw@mail.gmail.com>
 <ca593b00-8727-c816-8169-d6c528c51d93@treenet.co.nz>
Message-ID: <CAHvB88w4a6n3uoQZ5UZOi4NH0cpYtoVBD3dZtO5sFcDbRY_Bag@mail.gmail.com>

Hi. Sorry that I'm answering to the old thread. I was on vacation and
didn't have a chance to test the proposed solution.

Dieter, yes, I'm on the old CentOS 6 based OS (Amazon Linux) but with a new
kernel 4.9.27.

Amos, thank you for the suggestions about configure flags and squid config
options, I fixed all issues you pointed to.

Unfortunately following workarounds didn't help:

* client_idle_pconn_timeout 30 seconds
* half_closed_clients on
* client_persistent_connections off
* server_persistent_connections off

However I assumed that this is a bug and that I can find older version
which worked fine. I started testing from 3.1.x all the way to 3.5.26 and
this is what I found:

* All versions until 3.5.21 work fine. There no issues with huge amount of
TIME_WAIT connections under load.
* 3.5.20 is the latest stable version.
* 3.5.21 is the first broken version.
* 3.5.23, 3.5.25, 3.5.26 are broken as well.

This effectively means that bug is somewhere in between 3.5.20 and 3.5.21.

I hope this helps and I hope you'll be able to find an issue. If you can
create a bug report based on this information and post it here it would be
awesome.

Thank you.

On Wed, Jun 7, 2017 at 4:34 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 07/06/17 12:13, Ivan Larionov wrote:
>
>> Hi!
>>
>> We recently updated from squid v2 to v3 and now see huge increase in
>> connections in TIME_WAIT state on our squid servers (verified that this is
>> clients connections).
>>
>
> The biggest change between 2.7 and 3.5 in this area is that 2.7 was
> HTTP/1.0 which closed TCP connections after each request by default, and
> 3.5 is HTTP/1.1 which does not. So connections are more likely to persist
> until they hit some TCP timeout then enter the slow TIME_WAIT process.
>
> There were also some other bugs identified in older 3.5 releases which
> increased the TIME_WAIT specifically. I thought those were almost all fixed
> by now, but YMMV whether you hit the remaining issues.
>  A workaround it to set <http://www.squid-cache.org/Do
> c/config/client_idle_pconn_timeout/> to a shorter value than the default
> 2min. eg you might want it to be 30sec or so.
>
>
>
>
>> See versions and amount of such connections under the same load with the
>> same configs (except some incompatible stuff):
>>
>> squid 2.7.STABLE9
>>
>> configure options:  '--program-prefix=' '--prefix=/usr'
>> '--exec-prefix=/usr' '--bindir=/usr/bin' '--sbindir=/usr/sbin'
>> '--sysconfdir=/etc' '--includedir=/usr/include' '--libdir=/usr/lib'
>> '--libexecdir=/usr/libexec' '--sharedstatedir=/usr/com'
>> '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--exec_prefix=/usr'
>> '--bindir=/usr/sbin' '--libexecdir=/usr/lib/squid' '--localstatedir=/var'
>> '--datadir=/usr/share' '--sysconfdir=/etc/squid' '--enable-epoll'
>> '--enable-removal-policies=heap,lru' '--enable-storeio=aufs'
>> '--enable-delay-pools' '--with-pthreads' '--enable-cache-digests'
>> '--enable-useragent-log' '--enable-referer-log' '--with-large-files'
>> '--with-maxfd=16384' '--enable-err-languages=English'
>>
>> # netstat -tn | grep TIME_WAIT | grep 3128 | wc -l
>> 95
>>
>> squid 3.5.25
>>
>> configure options:  '--program-prefix=' '--prefix=/usr'
>> '--exec-prefix=/usr' '--bindir=/usr/sbin' '--sbindir=/usr/sbin'
>> '--sysconfdir=/etc/squid' '--libdir=/usr/lib' '--libexecdir=/usr/lib/squid'
>> '--includedir=/usr/include' '--datadir=/usr/share'
>> '--sharedstatedir=/usr/com' '--localstatedir=/var'
>> '--mandir=/usr/share/man' '--infodir=/usr/share/info' '--enable-epoll'
>> '--enable-removal-policies=heap,lru' '--enable-storeio=aufs'
>> '--enable-delay-pools' '--with-pthreads' '--enable-cache-digests'
>> '--enable-useragent-log' '--enable-referer-log' '--with-large-files'
>> '--with-maxfd=16384' '--enable-err-languages=English' '--enable-htcp'
>>
>
> FYI, these options are not doing anything for Squid-3:
>   '--enable-useragent-log' '--enable-referer-log'
> '--enable-err-languages=English'
>
>
>
>> # netstat -tn | grep TIME_WAIT | grep 3128 | wc -l
>> 11277
>>
>> Config:
>>
>> http_port 0.0.0.0:3128 <http://0.0.0.0:3128>
>>
>> acl localnet src 10.0.0.0/8 <http://10.0.0.0/8>     # RFC1918 possible
>> internal network
>> acl localnet src 172.16.0.0/12 <http://172.16.0.0/12>  # RFC1918
>> possible internal network
>> acl localnet src 192.168.0.0/16 <http://192.168.0.0/16> # RFC1918
>> possible internal network
>>
>> acl localnet src fc00::/7       # RFC 4193 local private network range
>> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
>> machines
>>
>> acl SSL_ports port 443
>>
>> acl Safe_ports port 80          # http
>> acl Safe_ports port 21          # ftp
>> acl Safe_ports port 443         # https
>> acl Safe_ports port 70          # gopher
>> acl Safe_ports port 210         # wais
>> acl Safe_ports port 280         # http-mgmt
>> acl Safe_ports port 488         # gss-http
>> acl Safe_ports port 591         # filemaker
>> acl Safe_ports port 777         # multiling http
>> acl Safe_ports port 1025-65535  # unregistered ports
>>
>> acl CONNECT method CONNECT
>>
>> ### START CUSTOM
>> acl Purge_method method PURGE
>>
>> # Allow localhost to selectively flush the cache
>> http_access allow localhost Purge_method
>> http_access deny Purge_method
>> ### END CUSTOM
>>
>> ### ALLOW ACCESS TO ALL PORTS
>> # http_access deny !Safe_ports
>> http_access deny CONNECT !SSL_ports
>> http_access allow localhost manager
>> http_access deny manager
>>
>> http_access allow localnet
>> http_access allow localhost
>> http_access deny all
>>
>> ### START CUSTOM
>> # Disable icp
>> icp_port 0
>> # Allow ICP queries from local networks only
>> icp_access allow localnet
>> icp_access allow localhost
>> icp_access deny all
>>
>> # Disable htcp
>> htcp_port 0
>> # Allow HTCP queries from local networks only
>> htcp_access allow localnet
>> htcp_access allow localhost
>> htcp_access deny all
>>
>
> FYI: setting icp_access and htcp_access is pointless when the relevant
> port is 0. That port 0 disables the entire component.
>
>
>> # Check for custom request header
>> acl custom_acl req_header x-use-custom-proxy -i true
>> # Check for x-use-new-proxy request header
>> acl custom_new_acl req_header x-use-new-proxy -i true
>>
>> # first_proxy
>> cache_peer 127.0.0.1 parent 18070 0 no-query no-digest name=first_proxy
>> cache_peer_access first_proxy deny custom_acl
>> cache_peer_access first_proxy deny custom_new_acl
>>
>> # second_proxy
>> cache_peer 127.0.0.1 parent 18079 0 no-query no-digest name=second_proxy
>> cache_peer_access second_proxy allow custom_acl
>> cache_peer_access second_proxy allow custom_new_acl
>> cache_peer_access second_proxy deny all
>>
>> never_direct allow all
>>
>> cache_mem 4620591 KB
>> maximum_object_size_in_memory 8 KB
>> memory_replacement_policy heap LRU
>> cache_replacement_policy heap LRU
>>
>> cache_dir aufs /mnt/services/squid/cache 891289 16 256
>>
>> minimum_object_size 64 bytes # none-zero so we dont cache mistakes
>> maximum_object_size 102400 KB
>>
>> logformat combined %>a %ui %un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st %tr
>> "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
>> logformat squid %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %un %Sh/%<A %mt
>>
>
> Please do not re-define these formats. If you want to use the default
> format they are defined internally by Squid3, if you want any
> customizations use a different format name.
>
>
>> access_log stdio:/var/log/squid/access.log combined
>> cache_log /var/log/squid/cache.log
>> cache_store_log none
>> logfile_rotate 0
>>
>> client_db off
>>
>> pid_filename /var/run/squid.pid
>>
>>
>> coredump_dir /var/cache
>> ### END CUSTOM
>>
>> refresh_pattern ^ftp:           1440    20%     10080
>> refresh_pattern ^gopher:        1440    0%      1440
>> # refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
>>
>
> Please do not remove that cgi-bin pattern. It is there to protect the
> cache against servers with broken/ancient CGI engines. It is designed
> explicitly so modern dynamic sites that provide proper cacheability headers
> can still be stored. So no harm and only benefits from in leaving it there.
>
>
> Amos
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>



-- 
With best regards, Ivan Larionov.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170706/1fd9e614/attachment.htm>

From rousskov at measurement-factory.com  Fri Jul  7 03:09:55 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 6 Jul 2017 21:09:55 -0600
Subject: [squid-users] Squid caching bad objects
In-Reply-To: <33337f8f-7de2-256d-80c4-2a7a9337b82f@treenet.co.nz>
References: <CANRy4AV5n4m8PC7fKQJfaZboKxyUG7o7ASuJABRhVfFFfmzjhg@mail.gmail.com>
 <a494df2a-eb3d-acd4-ea08-2bc615348c45@measurement-factory.com>
 <CANRy4AU=5VR+8kmcFdKLbpnxbdTgUCvRopxHV5ypD+0JmujOAA@mail.gmail.com>
 <bdb4c8bc-8d14-b442-53d0-e39ac4b5470e@measurement-factory.com>
 <CANRy4AVDOhpG6X-u2OKkPEMC0fhDmPvjubDwNU_fSHo3kzJeQw@mail.gmail.com>
 <CANRy4AXzq7j=vd+TQCcdqRqOvnRCF7cg22sd0ciTTsEO6hqyng@mail.gmail.com>
 <33337f8f-7de2-256d-80c4-2a7a9337b82f@treenet.co.nz>
Message-ID: <00b44675-f47e-1d37-1eb3-e0be23276746@measurement-factory.com>

On 07/06/2017 07:01 PM, Amos Jeffries wrote:

> AFAIK Squid currently should not be caching these objects at all. Or
> when it does use the disk cache as a temporary storage (eg for very
> large objects) marking them for immediate discard when the abort
> happens. 

Yes, and the corresponding bug report, with a solution blueprint is at
http://bugs.squid-cache.org/show_bug.cgi?id=4735


> That is being tracked by
> <http://bugs.squid-cache.org/show_bug.cgi?id=424>.

While implementing partial object caching feature would also address
this alleged bug, that implementation requires a lot more work and,
depending on the specifics, the resulting feature may be optional so the
bug fix may still be required anyway.

Alex.


From sergeig.public at gmail.com  Fri Jul  7 03:40:44 2017
From: sergeig.public at gmail.com (Sergei G)
Date: Thu, 6 Jul 2017 20:40:44 -0700
Subject: [squid-users] youtube videos and squid
Message-ID: <CAFLLzCPu8J38S-X9tba1bVfWCxkc7G5eQtqLpMBQ66OvicaomQ@mail.gmail.com>

Hi guys,

I have a very specific scenario in mind to use squid for.

I have 2 kids (2.5 and 4 years old) that are watching iPads and really
using available Comcast bandwidth.  It does not help that they sometimes
just leave those iPads running.

They tend to re-watch youtube videos (click on the same icon that they
liked before).  And that makes me think that squid could help me with
caching off youtube content.  Am I correct?

If not then I have no reason to bother you anymore :)

If squid could help me, then could you point me to a an example
configuration that would work?

As far as hardware I have 2 options:

1. I can install squid on a Raspberry PI 3, if package is readily
available.  that's my preferred solution.
2. I have an old server hardware with more power than RPI 3, but I don't
like to run it, because it is noisy.  It has FreeBSD 10 installed and I can
upgrade it to latest FreeBSD (11?) and isntall squid application that way.


Does squid run on RPI3?  FreeBSD?


Thank you
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170706/c5d1b473/attachment.htm>

From bloggerrazorcross at gmail.com  Fri Jul  7 04:06:47 2017
From: bloggerrazorcross at gmail.com (Razor Cross)
Date: Thu, 6 Jul 2017 23:06:47 -0500
Subject: [squid-users] Squid caching bad objects
In-Reply-To: <00b44675-f47e-1d37-1eb3-e0be23276746@measurement-factory.com>
References: <CANRy4AV5n4m8PC7fKQJfaZboKxyUG7o7ASuJABRhVfFFfmzjhg@mail.gmail.com>
 <a494df2a-eb3d-acd4-ea08-2bc615348c45@measurement-factory.com>
 <CANRy4AU=5VR+8kmcFdKLbpnxbdTgUCvRopxHV5ypD+0JmujOAA@mail.gmail.com>
 <bdb4c8bc-8d14-b442-53d0-e39ac4b5470e@measurement-factory.com>
 <CANRy4AVDOhpG6X-u2OKkPEMC0fhDmPvjubDwNU_fSHo3kzJeQw@mail.gmail.com>
 <CANRy4AXzq7j=vd+TQCcdqRqOvnRCF7cg22sd0ciTTsEO6hqyng@mail.gmail.com>
 <33337f8f-7de2-256d-80c4-2a7a9337b82f@treenet.co.nz>
 <00b44675-f47e-1d37-1eb3-e0be23276746@measurement-factory.com>
Message-ID: <CANRy4AUzBmWWipJ_YuebnypftHT5TxtntMpPf1e=so1KUVruFA@mail.gmail.com>

Thanks Alex and Amos for your inputs.

A basic question -
We have disabled eCAP support as part of squid compilation . Is it related
to this issue ?

On Thu, Jul 6, 2017 at 10:09 PM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 07/06/2017 07:01 PM, Amos Jeffries wrote:
>
> > AFAIK Squid currently should not be caching these objects at all. Or
> > when it does use the disk cache as a temporary storage (eg for very
> > large objects) marking them for immediate discard when the abort
> > happens.
>
> Yes, and the corresponding bug report, with a solution blueprint is at
> http://bugs.squid-cache.org/show_bug.cgi?id=4735
>
>
> > That is being tracked by
> > <http://bugs.squid-cache.org/show_bug.cgi?id=424>.
>
> While implementing partial object caching feature would also address
> this alleged bug, that implementation requires a lot more work and,
> depending on the specifics, the resulting feature may be optional so the
> bug fix may still be required anyway.
>
> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170706/8b08ecf2/attachment.htm>

From rousskov at measurement-factory.com  Fri Jul  7 05:40:23 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 6 Jul 2017 23:40:23 -0600
Subject: [squid-users] Squid caching bad objects
In-Reply-To: <CANRy4AUzBmWWipJ_YuebnypftHT5TxtntMpPf1e=so1KUVruFA@mail.gmail.com>
References: <CANRy4AV5n4m8PC7fKQJfaZboKxyUG7o7ASuJABRhVfFFfmzjhg@mail.gmail.com>
 <a494df2a-eb3d-acd4-ea08-2bc615348c45@measurement-factory.com>
 <CANRy4AU=5VR+8kmcFdKLbpnxbdTgUCvRopxHV5ypD+0JmujOAA@mail.gmail.com>
 <bdb4c8bc-8d14-b442-53d0-e39ac4b5470e@measurement-factory.com>
 <CANRy4AVDOhpG6X-u2OKkPEMC0fhDmPvjubDwNU_fSHo3kzJeQw@mail.gmail.com>
 <CANRy4AXzq7j=vd+TQCcdqRqOvnRCF7cg22sd0ciTTsEO6hqyng@mail.gmail.com>
 <33337f8f-7de2-256d-80c4-2a7a9337b82f@treenet.co.nz>
 <00b44675-f47e-1d37-1eb3-e0be23276746@measurement-factory.com>
 <CANRy4AUzBmWWipJ_YuebnypftHT5TxtntMpPf1e=so1KUVruFA@mail.gmail.com>
Message-ID: <8b35b779-9a8d-5b81-88ee-3dcd29e8e835@measurement-factory.com>

On 07/06/2017 10:06 PM, Razor Cross wrote:
> We have disabled eCAP support as part of squid compilation . Is it
> related to this issue ?

No: Assuming my guess about the underlying problem is correct, eCAP is
irrelevant here.

Alex.


> On Thu, Jul 6, 2017 at 10:09 PM, Alex Rousskov wrote:
> 
>     On 07/06/2017 07:01 PM, Amos Jeffries wrote:
> 
>     > AFAIK Squid currently should not be caching these objects at all. Or
>     > when it does use the disk cache as a temporary storage (eg for very
>     > large objects) marking them for immediate discard when the abort
>     > happens.
> 
>     Yes, and the corresponding bug report, with a solution blueprint is at
>     http://bugs.squid-cache.org/show_bug.cgi?id=4735


From heiler.bemerguy at cinbesa.com.br  Fri Jul  7 06:22:29 2017
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Fri, 07 Jul 2017 03:22:29 -0300
Subject: [squid-users] /var/run/squid gone on every reboot?!
Message-ID: <20170707062234.C1E233137@mailer.cinbesa.com.br>

3.5. Everytime I must recreate this. What I'm missing? 

From Antony.Stone at squid.open.source.it  Fri Jul  7 08:00:54 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Fri, 7 Jul 2017 10:00:54 +0200
Subject: [squid-users] /var/run/squid gone on every reboot?!
In-Reply-To: <20170707062234.C1E233137@mailer.cinbesa.com.br>
References: <20170707062234.C1E233137@mailer.cinbesa.com.br>
Message-ID: <201707071000.54889.Antony.Stone@squid.open.source.it>

On Friday 07 July 2017 at 08:22:29, Heiler Bemerguy wrote:

> 3.5. Everytime I must recreate this. What I'm missing?

Hm, dunno.

Give us a clue...

What operating system are you running under, and how did you install squid?

How does squid (try to) start at boot time?



Antony.

-- 
How I want a drink, alcoholic of course, after the heavy chapters involving 
quantum mechanics.

 - mnemonic for 3.14159265358979

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Fri Jul  7 08:10:30 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 7 Jul 2017 20:10:30 +1200
Subject: [squid-users] Huge amount of time_wait connections after
 upgrade from v2 to v3
In-Reply-To: <CAHvB88w4a6n3uoQZ5UZOi4NH0cpYtoVBD3dZtO5sFcDbRY_Bag@mail.gmail.com>
References: <CAHvB88x+nNYMtmNZWqrZo-p==UykYDj5dZF+5N1eC3rGR8ybGw@mail.gmail.com>
 <ca593b00-8727-c816-8169-d6c528c51d93@treenet.co.nz>
 <CAHvB88w4a6n3uoQZ5UZOi4NH0cpYtoVBD3dZtO5sFcDbRY_Bag@mail.gmail.com>
Message-ID: <f418e53a-ed5f-e4db-9654-2aa31ad83c57@treenet.co.nz>

On 07/07/17 13:55, Ivan Larionov wrote:
> Hi. Sorry that I'm answering to the old thread. I was on vacation and 
> didn't have a chance to test the proposed solution.
> 
> Dieter, yes, I'm on the old CentOS 6 based OS (Amazon Linux) but with a 
> new kernel 4.9.27.
> 
> Amos, thank you for the suggestions about configure flags and squid 
> config options, I fixed all issues you pointed to.
> 
> Unfortunately following workarounds didn't help:
> 
> * client_idle_pconn_timeout 30 seconds
> * half_closed_clients on
> * client_persistent_connections off
> * server_persistent_connections off
> 

TIME_WAIT is a sign that Squid is following the normal TCP process for 
closing connections, and doing so before the remote endpoint closes.

Disabling persistent connections increases the number of connections 
going through that process. So you definitely want those settings ON to 
reduce the WAIT states.

If the remote end is the one doing the closure, then you will see less 
TIME_WAIT, but CLOSE_WAIT will increase instead. The trick is in finding 
the right balance of timeouts on both client and server idle pconn to 
get the minimum of total WAIT states. That is network dependent.

Generally though forward/explicit and intercept proxies want 
client_idle_pconn_timeout to be shorter than server_idle_pconn_timeout. 
Reverse proxy want the opposite.



> However I assumed that this is a bug and that I can find older version 
> which worked fine. I started testing from 3.1.x all the way to 3.5.26 
> and this is what I found:
> 
> * All versions until 3.5.21 work fine. There no issues with huge amount 
> of TIME_WAIT connections under load.
> * 3.5.20 is the latest stable version.
> * 3.5.21 is the first broken version.
> * 3.5.23, 3.5.25, 3.5.26 are broken as well.
> 
> This effectively means that bug is somewhere in between 3.5.20 and 3.5.21.
> 
> I hope this helps and I hope you'll be able to find an issue. If you can 
> create a bug report based on this information and post it here it would 
> be awesome.

The changes in 3.5.21 were fixes to some common crashes and better 
caching behaviour. So I expect at least some of the change is due to 
higher traffic throughput on proxies previously restricted by those 
problems.

Amos


From squid3 at treenet.co.nz  Fri Jul  7 08:32:15 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 7 Jul 2017 20:32:15 +1200
Subject: [squid-users] youtube videos and squid
In-Reply-To: <CAFLLzCPu8J38S-X9tba1bVfWCxkc7G5eQtqLpMBQ66OvicaomQ@mail.gmail.com>
References: <CAFLLzCPu8J38S-X9tba1bVfWCxkc7G5eQtqLpMBQ66OvicaomQ@mail.gmail.com>
Message-ID: <6bbcb4cd-a318-8ba7-3a30-192a436da954@treenet.co.nz>

On 07/07/17 15:40, Sergei G wrote:
> Hi guys,
> 
> I have a very specific scenario in mind to use squid for.
> 
> I have 2 kids (2.5 and 4 years old) that are watching iPads and really 
> using available Comcast bandwidth.  It does not help that they sometimes 
> just leave those iPads running.
> 
> They tend to re-watch youtube videos (click on the same icon that they 
> liked before).  And that makes me think that squid could help me with 
> caching off youtube content.  Am I correct?

Possibly. Google have actively been making it more difficult every year 
for quite a while.

These days it requires intercepting the YouTube HTTPS connections. That 
is only possible if the clients are not using Chrome or other Google 
apps to fetch the videos - otherwise you run up against the cert pinning 
wall.

After that you need some extra helper software to track the YT video 
fetching process and decipher what the actual video URL is from the mess 
of session traffic. That is being kept a bit of a secret these days, 
since every time G find out how it is being done they change the process 
to make it more obtuse and harder to do :-(

Eliezer has been trying to get a helper for that going most recently. 
There are also some other products I forget the name of right now 
(videobooster maybe), but should be easy to find that cache YouTube content.


> 
> If not then I have no reason to bother you anymore :)
> 
> If squid could help me, then could you point me to a an example 
> configuration that would work?
> 
> As far as hardware I have 2 options:
> 
> 1. I can install squid on a Raspberry PI 3, if package is readily 
> available.  that's my preferred solution.
> 2. I have an old server hardware with more power than RPI 3, but I don't 
> like to run it, because it is noisy.  It has FreeBSD 10 installed and I 
> can upgrade it to latest FreeBSD (11?) and isntall squid application 
> that way.
> 
> 
> Does squid run on RPI3?  FreeBSD?

Yes to both, and at the small scale you need the RPi3 should be able to 
cope with it.

Amos


From xeron.oskom at gmail.com  Fri Jul  7 14:06:46 2017
From: xeron.oskom at gmail.com (Ivan Larionov)
Date: Fri, 7 Jul 2017 07:06:46 -0700
Subject: [squid-users] Huge amount of time_wait connections after
	upgrade from v2 to v3
In-Reply-To: <f418e53a-ed5f-e4db-9654-2aa31ad83c57@treenet.co.nz>
References: <CAHvB88x+nNYMtmNZWqrZo-p==UykYDj5dZF+5N1eC3rGR8ybGw@mail.gmail.com>
 <ca593b00-8727-c816-8169-d6c528c51d93@treenet.co.nz>
 <CAHvB88w4a6n3uoQZ5UZOi4NH0cpYtoVBD3dZtO5sFcDbRY_Bag@mail.gmail.com>
 <f418e53a-ed5f-e4db-9654-2aa31ad83c57@treenet.co.nz>
Message-ID: <22125AC6-0C7D-459E-8BF1-6C9F4EE7A92C@gmail.com>

Thank you for the fast reply.

> On Jul 7, 2017, at 01:10, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
>> On 07/07/17 13:55, Ivan Larionov wrote:
>> Hi. Sorry that I'm answering to the old thread. I was on vacation and didn't have a chance to test the proposed solution.
>> Dieter, yes, I'm on the old CentOS 6 based OS (Amazon Linux) but with a new kernel 4.9.27.
>> Amos, thank you for the suggestions about configure flags and squid config options, I fixed all issues you pointed to.
>> Unfortunately following workarounds didn't help:
>> * client_idle_pconn_timeout 30 seconds
>> * half_closed_clients on
>> * client_persistent_connections off
>> * server_persistent_connections off
> 
> TIME_WAIT is a sign that Squid is following the normal TCP process for closing connections, and doing so before the remote endpoint closes.
> 
> Disabling persistent connections increases the number of connections going through that process. So you definitely want those settings ON to reduce the WAIT states.
> 

I understand that. I just wrote that I tried this options and they had no effect. They didn't increase nor decrease number of TIME_WAIT connections. I removed them when I started testing older versions.

> If the remote end is the one doing the closure, then you will see less TIME_WAIT, but CLOSE_WAIT will increase instead. The trick is in finding the right balance of timeouts on both client and server idle pconn to get the minimum of total WAIT states. That is network dependent.
> 
> Generally though forward/explicit and intercept proxies want client_idle_pconn_timeout to be shorter than server_idle_pconn_timeout. Reverse proxy want the opposite.
> 
> 
> 
>> However I assumed that this is a bug and that I can find older version which worked fine. I started testing from 3.1.x all the way to 3.5.26 and this is what I found:
>> * All versions until 3.5.21 work fine. There no issues with huge amount of TIME_WAIT connections under load.
>> * 3.5.20 is the latest stable version.
>> * 3.5.21 is the first broken version.
>> * 3.5.23, 3.5.25, 3.5.26 are broken as well.
>> This effectively means that bug is somewhere in between 3.5.20 and 3.5.21.
>> I hope this helps and I hope you'll be able to find an issue. If you can create a bug report based on this information and post it here it would be awesome.
> 
> The changes in 3.5.21 were fixes to some common crashes and better caching behaviour. So I expect at least some of the change is due to higher traffic throughput on proxies previously restricted by those problems.
> 

I can't imagine how throughput increase could result in 500 times more TIME_WAIT connections count.

In our prod environment when we updated from 2.7.x to 3.5.25 we saw increase from 100 to 10000. This is 100x.

When I was load testing different versions yesterday I was always sending the same amount of RPS to them. Update from 3.5.20 to 3.5.21 resulted in jump from 20 to 10000 TIME_WAIT count. This is 500x.

I know that time_wait is fine in general. Until you have too many of them.

> Amos


From eliezer at ngtech.co.il  Fri Jul  7 14:15:56 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 7 Jul 2017 17:15:56 +0300
Subject: [squid-users] youtube videos and squid
In-Reply-To: <6bbcb4cd-a318-8ba7-3a30-192a436da954@treenet.co.nz>
References: <CAFLLzCPu8J38S-X9tba1bVfWCxkc7G5eQtqLpMBQ66OvicaomQ@mail.gmail.com>
 <6bbcb4cd-a318-8ba7-3a30-192a436da954@treenet.co.nz>
Message-ID: <00ff01d2f72b$8ccb8c10$a662a430$@ngtech.co.il>

Hey Amos, Sergei,

I managed to write an ICAP service which works with a ruby\golang StorID helper and a redis DB that can help with the caching of YouTube videos.
However despite to the fact that I am able to tag urls with StoreID  squid is still not responding with a cache HIT but fetching from the original sources.

There are couple obstacles in this field and this specific solution I wrote is designed for PC and not IPAD or Andorid Based devices.
There is an issue with Android 6+(7..) and IOS 10 based devices which for some reason do not cope with SSL traffic interception.
If you do have a tiny server and you can run a tiny http service with nginx\apache I would recommend you to download the videos and serve them locally using chrome or another browser which works.
I found it more useful then intercepting and caching also, kids are usually enjoying from a more "stable" stash of movies\videos then others.
They can watch the same video over and over and it would be fun for them.
The teenagers are having issue's watching the same video over and over so..
I can recommend on a nice wordpress theme which can fit a "VOD" site and a video downloader which you can use to download specific videos or playlists.

This solution would be something like "netflix on a stick" and is very effective with a raspberry pi 3 with some external USB HDD. 

I would be happy to get any response to any of the ideas.

Thanks In Advance,
Eliezer

 * If you are willing to devote some time to debug the issue with the current helpers let me know and bump me if you think I missed an email and didn't responded(it happens when you have kids...)
----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Friday, July 7, 2017 11:32
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] youtube videos and squid

On 07/07/17 15:40, Sergei G wrote:
> Hi guys,
> 
> I have a very specific scenario in mind to use squid for.
> 
> I have 2 kids (2.5 and 4 years old) that are watching iPads and really 
> using available Comcast bandwidth.  It does not help that they sometimes 
> just leave those iPads running.
> 
> They tend to re-watch youtube videos (click on the same icon that they 
> liked before).  And that makes me think that squid could help me with 
> caching off youtube content.  Am I correct?

Possibly. Google have actively been making it more difficult every year 
for quite a while.

These days it requires intercepting the YouTube HTTPS connections. That 
is only possible if the clients are not using Chrome or other Google 
apps to fetch the videos - otherwise you run up against the cert pinning 
wall.

After that you need some extra helper software to track the YT video 
fetching process and decipher what the actual video URL is from the mess 
of session traffic. That is being kept a bit of a secret these days, 
since every time G find out how it is being done they change the process 
to make it more obtuse and harder to do :-(

Eliezer has been trying to get a helper for that going most recently. 
There are also some other products I forget the name of right now 
(videobooster maybe), but should be easy to find that cache YouTube content.


> 
> If not then I have no reason to bother you anymore :)
> 
> If squid could help me, then could you point me to a an example 
> configuration that would work?
> 
> As far as hardware I have 2 options:
> 
> 1. I can install squid on a Raspberry PI 3, if package is readily 
> available.  that's my preferred solution.
> 2. I have an old server hardware with more power than RPI 3, but I don't 
> like to run it, because it is noisy.  It has FreeBSD 10 installed and I 
> can upgrade it to latest FreeBSD (11?) and isntall squid application 
> that way.
> 
> 
> Does squid run on RPI3?  FreeBSD?

Yes to both, and at the small scale you need the RPi3 should be able to 
cope with it.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Fri Jul  7 14:20:56 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 7 Jul 2017 17:20:56 +0300
Subject: [squid-users] Huge amount of time_wait connections
	after	upgrade from v2 to v3
In-Reply-To: <22125AC6-0C7D-459E-8BF1-6C9F4EE7A92C@gmail.com>
References: <CAHvB88x+nNYMtmNZWqrZo-p==UykYDj5dZF+5N1eC3rGR8ybGw@mail.gmail.com>
 <ca593b00-8727-c816-8169-d6c528c51d93@treenet.co.nz>
 <CAHvB88w4a6n3uoQZ5UZOi4NH0cpYtoVBD3dZtO5sFcDbRY_Bag@mail.gmail.com>
 <f418e53a-ed5f-e4db-9654-2aa31ad83c57@treenet.co.nz>
 <22125AC6-0C7D-459E-8BF1-6C9F4EE7A92C@gmail.com>
Message-ID: <010101d2f72c$3ff66620$bfe33260$@ngtech.co.il>

Hey Ivan,

How do you run these tests?
With what application "ab" ?

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Ivan Larionov
Sent: Friday, July 7, 2017 17:07
To: Amos Jeffries <squid3 at treenet.co.nz>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Huge amount of time_wait connections after upgrade from v2 to v3

Thank you for the fast reply.

> On Jul 7, 2017, at 01:10, Amos Jeffries <squid3 at treenet.co.nz> wrote:
> 
>> On 07/07/17 13:55, Ivan Larionov wrote:
>> Hi. Sorry that I'm answering to the old thread. I was on vacation and didn't have a chance to test the proposed solution.
>> Dieter, yes, I'm on the old CentOS 6 based OS (Amazon Linux) but with a new kernel 4.9.27.
>> Amos, thank you for the suggestions about configure flags and squid config options, I fixed all issues you pointed to.
>> Unfortunately following workarounds didn't help:
>> * client_idle_pconn_timeout 30 seconds
>> * half_closed_clients on
>> * client_persistent_connections off
>> * server_persistent_connections off
> 
> TIME_WAIT is a sign that Squid is following the normal TCP process for closing connections, and doing so before the remote endpoint closes.
> 
> Disabling persistent connections increases the number of connections going through that process. So you definitely want those settings ON to reduce the WAIT states.
> 

I understand that. I just wrote that I tried this options and they had no effect. They didn't increase nor decrease number of TIME_WAIT connections. I removed them when I started testing older versions.

> If the remote end is the one doing the closure, then you will see less TIME_WAIT, but CLOSE_WAIT will increase instead. The trick is in finding the right balance of timeouts on both client and server idle pconn to get the minimum of total WAIT states. That is network dependent.
> 
> Generally though forward/explicit and intercept proxies want client_idle_pconn_timeout to be shorter than server_idle_pconn_timeout. Reverse proxy want the opposite.
> 
> 
> 
>> However I assumed that this is a bug and that I can find older version which worked fine. I started testing from 3.1.x all the way to 3.5.26 and this is what I found:
>> * All versions until 3.5.21 work fine. There no issues with huge amount of TIME_WAIT connections under load.
>> * 3.5.20 is the latest stable version.
>> * 3.5.21 is the first broken version.
>> * 3.5.23, 3.5.25, 3.5.26 are broken as well.
>> This effectively means that bug is somewhere in between 3.5.20 and 3.5.21.
>> I hope this helps and I hope you'll be able to find an issue. If you can create a bug report based on this information and post it here it would be awesome.
> 
> The changes in 3.5.21 were fixes to some common crashes and better caching behaviour. So I expect at least some of the change is due to higher traffic throughput on proxies previously restricted by those problems.
> 

I can't imagine how throughput increase could result in 500 times more TIME_WAIT connections count.

In our prod environment when we updated from 2.7.x to 3.5.25 we saw increase from 100 to 10000. This is 100x.

When I was load testing different versions yesterday I was always sending the same amount of RPS to them. Update from 3.5.20 to 3.5.21 resulted in jump from 20 to 10000 TIME_WAIT count. This is 500x.

I know that time_wait is fine in general. Until you have too many of them.

> Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Fri Jul  7 14:28:46 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 7 Jul 2017 17:28:46 +0300
Subject: [squid-users] Dstdomain "there are more than 100
	regular	expressions"
In-Reply-To: <1499347368854-4682999.post@n4.nabble.com>
References: <1499347368854-4682999.post@n4.nabble.com>
Message-ID: <011701d2f72d$58041fe0$080c5fa0$@ngtech.co.il>

Hey,

The choice to work with regular expressions on domain names is kind of weird to me.
I would try to explain why I am thinking this way.
Let say I have a domain such as:
p.ngtech.co.il
and this domain has many sub domains and I want to catch each and every one of these domains how would I block them using a regex?
^s1\.p\.ngtech\.co\.il$
Or
^s[0-9]+\.p.ngtech\.co\.il$

What did I earned if the whole ngtech.co.il domain contains content that I don?t want?
There are very specific cases which regex are good for domains blacklisting but if you need them so much then just split them into two groups of 90 to overcome the squid warning.
If you are using a blacklist which offers you a blacklist with regex then I think you are using the wrong one or using it the wrong way.

If you want me to help you with this matter we can findout together if there is a much smarter and better way to block these sites then first making sure that the domain is not a match for more then 100 regex.

All The Bests,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Thursday, July 6, 2017 16:23
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Dstdomain "there are more than 100 regular expressions"

Hi. I have this in my cache.log

ad_block, is a list for block publicity. 

there is a best way to do that??

2017/07/06 10:35:49| /etc/squid/squid.conf line 55: acl ads dstdom_regex "/etc/squid/listas/ad_block.lst"
2017/07/06 10:35:49| WARNING: there are more than 100 regular expressions.
Consider using less REs or use rules without expressions like 'dstdomain'.


Thanks to all.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Dstdomain-there-are-more-than-100-regular-expressions-tp4682999.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From xeron.oskom at gmail.com  Fri Jul  7 14:54:10 2017
From: xeron.oskom at gmail.com (Ivan Larionov)
Date: Fri, 7 Jul 2017 07:54:10 -0700
Subject: [squid-users] Huge amount of time_wait connections
	after	upgrade from v2 to v3
In-Reply-To: <010101d2f72c$3ff66620$bfe33260$@ngtech.co.il>
References: <CAHvB88x+nNYMtmNZWqrZo-p==UykYDj5dZF+5N1eC3rGR8ybGw@mail.gmail.com>
 <ca593b00-8727-c816-8169-d6c528c51d93@treenet.co.nz>
 <CAHvB88w4a6n3uoQZ5UZOi4NH0cpYtoVBD3dZtO5sFcDbRY_Bag@mail.gmail.com>
 <f418e53a-ed5f-e4db-9654-2aa31ad83c57@treenet.co.nz>
 <22125AC6-0C7D-459E-8BF1-6C9F4EE7A92C@gmail.com>
 <010101d2f72c$3ff66620$bfe33260$@ngtech.co.il>
Message-ID: <CA465832-CD82-4E11-AB06-8F21C0596A63@gmail.com>


> On Jul 7, 2017, at 07:20, Eliezer Croitoru <eliezer at ngtech.co.il> wrote:
> 
> Hey Ivan,
> 
> How do you run these tests?
> With what application "ab" ?
> 

Apache Jmeter with test case written by our load test engineer. I'm not at work right now so can't say the exact scenario but afaik we were trying to reproduce our production load so it should be somehow close to the real life traffic.

> Thanks,
> Eliezer
> 
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
> 
> 
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Ivan Larionov
> Sent: Friday, July 7, 2017 17:07
> To: Amos Jeffries <squid3 at treenet.co.nz>
> Cc: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Huge amount of time_wait connections after upgrade from v2 to v3
> 
> Thank you for the fast reply.
> 
>>> On Jul 7, 2017, at 01:10, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>> 
>>> On 07/07/17 13:55, Ivan Larionov wrote:
>>> Hi. Sorry that I'm answering to the old thread. I was on vacation and didn't have a chance to test the proposed solution.
>>> Dieter, yes, I'm on the old CentOS 6 based OS (Amazon Linux) but with a new kernel 4.9.27.
>>> Amos, thank you for the suggestions about configure flags and squid config options, I fixed all issues you pointed to.
>>> Unfortunately following workarounds didn't help:
>>> * client_idle_pconn_timeout 30 seconds
>>> * half_closed_clients on
>>> * client_persistent_connections off
>>> * server_persistent_connections off
>> 
>> TIME_WAIT is a sign that Squid is following the normal TCP process for closing connections, and doing so before the remote endpoint closes.
>> 
>> Disabling persistent connections increases the number of connections going through that process. So you definitely want those settings ON to reduce the WAIT states.
>> 
> 
> I understand that. I just wrote that I tried this options and they had no effect. They didn't increase nor decrease number of TIME_WAIT connections. I removed them when I started testing older versions.
> 
>> If the remote end is the one doing the closure, then you will see less TIME_WAIT, but CLOSE_WAIT will increase instead. The trick is in finding the right balance of timeouts on both client and server idle pconn to get the minimum of total WAIT states. That is network dependent.
>> 
>> Generally though forward/explicit and intercept proxies want client_idle_pconn_timeout to be shorter than server_idle_pconn_timeout. Reverse proxy want the opposite.
>> 
>> 
>> 
>>> However I assumed that this is a bug and that I can find older version which worked fine. I started testing from 3.1.x all the way to 3.5.26 and this is what I found:
>>> * All versions until 3.5.21 work fine. There no issues with huge amount of TIME_WAIT connections under load.
>>> * 3.5.20 is the latest stable version.
>>> * 3.5.21 is the first broken version.
>>> * 3.5.23, 3.5.25, 3.5.26 are broken as well.
>>> This effectively means that bug is somewhere in between 3.5.20 and 3.5.21.
>>> I hope this helps and I hope you'll be able to find an issue. If you can create a bug report based on this information and post it here it would be awesome.
>> 
>> The changes in 3.5.21 were fixes to some common crashes and better caching behaviour. So I expect at least some of the change is due to higher traffic throughput on proxies previously restricted by those problems.
>> 
> 
> I can't imagine how throughput increase could result in 500 times more TIME_WAIT connections count.
> 
> In our prod environment when we updated from 2.7.x to 3.5.25 we saw increase from 100 to 10000. This is 100x.
> 
> When I was load testing different versions yesterday I was always sending the same amount of RPS to them. Update from 3.5.20 to 3.5.21 resulted in jump from 20 to 10000 TIME_WAIT count. This is 500x.
> 
> I know that time_wait is fine in general. Until you have too many of them.
> 
>> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 


From erdosain9 at gmail.com  Fri Jul  7 16:14:50 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Fri, 7 Jul 2017 09:14:50 -0700 (PDT)
Subject: [squid-users] Squid as gateway
Message-ID: <1499444090379-4683022.post@n4.nabble.com>

Hi.
It's possible to put the squid server as gateway??? and config to ear in
port 80 instead of 3128? This will work?
Thanks to all.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-as-gateway-tp4683022.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Fri Jul  7 18:13:47 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 8 Jul 2017 06:13:47 +1200
Subject: [squid-users] Squid as gateway
In-Reply-To: <1499444090379-4683022.post@n4.nabble.com>
References: <1499444090379-4683022.post@n4.nabble.com>
Message-ID: <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>

On 08/07/17 04:14, erdosain9 wrote:
> Hi.
> It's possible to put the squid server as gateway??? and config to ear in
> port 80 instead of 3128? This will work?


Yes. See <http://wiki.squid-cache.org/SquidFaq/ReverseProxy>.

Like that page name most of the documentation can be found by looking 
for the term "reverse proxy" rather than gateway.

Amos


From willsznet at gmail.com  Sat Jul  8 11:18:13 2017
From: willsznet at gmail.com (Willsz.net)
Date: Sat, 8 Jul 2017 18:18:13 +0700
Subject: [squid-users] Build Squid-3.5.26 failure in FreeBSD 10.3-STABLE
Message-ID: <000001d2f7db$e5b8aeb0$b12a0c10$@com>

Hi,

I got some problem with this squid version after last night decide to
upgrading FreeBSD from FreeBSD 9.3-STABLE to FreeBSD 10.3-STABLE. Here's
some error output:

root:/usr/local/src/squid-3.5.26# uname -srm
FreeBSD 10.3-STABLE i386

root:/usr/local/src/squid-3.5.26# cat squid.configure
--prefix=/usr/local --includedir=/usr/local/include --bindir=/usr/local/sbin
--libexecdir=/usr/local/libexec/squid --sysconfdir=/usr/local/etc/squid
--with-default-user=squid --localstatedir=/var/cache/squid
--libdir=/usr/local/lib --with-logdir=/var/log/squid
--with-pidfile=/var/run/squid.pid --with-swapdir=/var/cache/squid
--without-gnutls --enable-build-info --enable-loadable-modules
--enable-removal-policies=lru,heap --disable-epoll --disable-linux-netfilter
--disable-linux-tproxy --disable-translation --disable-arch-native
--mandir=/usr/local/man --infodir=/usr/local/info --disable-wccp
--disable-wccpv2 --enable-ipfw-transparent --with-large-files --disable-htcp
--disable-eui --enable-cachemgr-hostname=ip.proxy-cache.willsz.net
--disable-auth-negotiate

root:/usr/local/src/squid-3.5.26# ./configure `cat squid.configure` > log
Segmentation fault (core dumped)
Segmentation fault (core dumped)
Segmentation fault (core dumped)
Segmentation fault (core dumped)
Segmentation fault (core dumped)
Segmentation fault (core dumped)
Segmentation fault (core dumped)
configure: WARNING: Neither SASL nor SASL2 found
configure: WARNING: Samba smbclient not found in default location.
basic_smb_auth may not work on this machine
configure: WARNING: Neither SASL nor SASL2 found
configure: WARNING: Samba wbinfo not found in default location.
ext_wbinfo_group_acl may not work on this machine
configure: WARNING: cppunit does not appear to be installed. squid does not
require this, but code testing with 'make check' will fail.

root:/usr/local/src/squid-3.5.26# cat log
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... cfgaux/install-sh -c -d
checking for gawk... no
checking for mawk... no
checking for nawk... nawk
checking whether make sets $(MAKE)... yes
checking whether make supports nested variables... yes
checking whether UID '0' is supported by ustar format... yes
checking whether GID '0' is supported by ustar format... yes
checking how to create a ustar tar archive... gnutar
checking whether to enable maintainer-specific portions of Makefiles... no
checking for gcc... gcc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking whether gcc understands -c and -o together... yes
checking for style of include used by make... GNU
checking dependency style of gcc... gcc3
checking for g++... g++
checking whether we are using the GNU C++ compiler... yes
checking whether g++ accepts -g... yes
checking dependency style of g++... gcc3
checking build system type... i386-unknown-freebsd10.3
checking host system type... i386-unknown-freebsd10.3
configure: CPU arch native optimization enabled: no
checking simplified host os... freebsd (version 10.3)
checking what kind of compiler we're using... gcc
checking whether g++ supports C++11 features by default... no
checking whether g++ supports C++11 features with -std=c++11... yes
checking for ranlib... ranlib
checking how to run the C preprocessor... gcc -E
checking whether ln -s works... yes
checking for egrep... /usr/bin/egrep
checking for sh... /bin/sh
checking for false... /usr/bin/false
checking for true... /usr/bin/true
checking for mv... /bin/mv
checking for mkdir... /bin/mkdir
checking for ln... /bin/ln
checking for chmod... /bin/chmod
checking for tr... /usr/bin/tr
checking for rm... /bin/rm
checking for cppunit-config... false
checking for perl... /usr/local/bin/perl
checking for pod2man... /usr/local/bin/pod2man
checking for ar... /usr/bin/ar
checking for linuxdoc... /usr/bin/false
configure: strict error checking enabled: yes
checking whether to use loadable modules... yes
checking how to print strings... printf
checking for a sed that does not truncate output... /usr/bin/sed
checking for fgrep... /usr/bin/fgrep
checking for ld used by gcc... /usr/local/bin/ld
checking if the linker (/usr/local/bin/ld) is GNU ld... yes
checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
checking the name lister (/usr/bin/nm -B) interface... BSD nm
checking the maximum length of command line arguments... 196608
checking how to convert i386-unknown-freebsd10.3 file names to
i386-unknown-freebsd10.3 format... func_convert_file_noop
checking how to convert i386-unknown-freebsd10.3 file names to toolchain
format... func_convert_file_noop
checking for /usr/local/bin/ld option to reload object files... -r
checking for objdump... objdump
checking how to recognize dependent libraries... pass_all
checking for dlltool... no
checking how to associate runtime and link libraries... printf %s\n
checking for archiver @FILE support... no
checking for strip... strip
checking for ranlib... (cached) ranlib
checking command to parse /usr/bin/nm -B output from gcc object... ok
checking for sysroot... no
checking for a working dd... /bin/dd
checking how to truncate binary pipes... /bin/dd bs=4096 count=1
checking for mt... mt
checking if mt is a manifest tool... no
checking for dlfcn.h... yes
checking for objdir... .libs
checking if gcc supports -fno-rtti -fno-exceptions... no
checking for gcc option to produce PIC... -fPIC -DPIC
checking if gcc PIC flag -fPIC -DPIC works... yes
checking if gcc static flag -static works... yes
checking if gcc supports -c -o file.o... yes
checking if gcc supports -c -o file.o... (cached) yes
checking whether the gcc linker (/usr/local/bin/ld) supports shared
libraries... yes
checking whether -lc should be explicitly linked in... no
checking dynamic linker characteristics... freebsd10.3 ld.so
checking how to hardcode library paths into programs... immediate
checking for shl_load... no
checking for shl_load in -ldld... no
checking for dlopen... yes
checking whether a program can dlopen itself... yes
checking whether a statically linked program can dlopen itself... no
checking whether stripping libraries is possible... yes
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... yes
checking how to run the C++ preprocessor... g++ -E
checking for ld used by g++... /usr/local/bin/ld
checking if the linker (/usr/local/bin/ld) is GNU ld... yes
checking whether the g++ linker (/usr/local/bin/ld) supports shared
libraries... yes
checking for g++ option to produce PIC... -fPIC -DPIC
checking if g++ PIC flag -fPIC -DPIC works... yes
checking if g++ static flag -static works... yes
checking if g++ supports -c -o file.o... yes
checking if g++ supports -c -o file.o... (cached) yes
checking whether the g++ linker (/usr/local/bin/ld) supports shared
libraries... yes
checking dynamic linker characteristics... freebsd10.3 ld.so
checking how to hardcode library paths into programs... immediate
checking what extension is used for runtime loadable modules... .so
checking what variable specifies run-time module search path...
LD_LIBRARY_PATH
checking for the default library search path... /lib /usr/lib
checking for library containing dlopen... none required
checking for dlerror... yes
checking for shl_load... (cached) no
checking for shl_load in -ldld... (cached) no
checking for dld_link in -ldld... no
checking for _ prefix in compiled symbols... no
checking whether deplibs are loaded by dlopen... yes
checking for argz.h... no
checking for error_t... no
checking for argz_add... no
checking for argz_append... no
checking for argz_count... no
checking for argz_create_sep... no
checking for argz_insert... no
checking for argz_next... no
checking for argz_stringify... no
checking whether libtool supports -dlopen/-dlpreopen... yes
checking for ltdl.h... yes
checking whether lt_dlinterface_register is declared... yes
checking for lt_dladvise_preload in -lltdl... yes
checking where to find libltdl headers... 
checking where to find libltdl library... -lltdl
checking for unistd.h... yes
checking for dl.h... no
checking for sys/dl.h... no
checking for dld.h... no
checking for mach-o/dyld.h... no
checking for dirent.h... yes
checking for closedir... yes
checking for opendir... yes
checking for readdir... yes
checking for strlcat... yes
checking for strlcpy... yes
checking for library containing dlopen... (cached) none required
checking for dlerror... (cached) yes
checking for shl_load... (cached) no
checking for shl_load in -ldld... (cached) no
checking for dld_link in -ldld... (cached) no
checking for compiler variant... gcc
configure: inlining optimizations enabled: yes
checking for GNU atomic operations support... no
configure: cbdata debugging enabled: no
configure: xmalloc stats display: no
checking for library containing shm_open... none required
checking for DiskIO modules to be enabled...  AIO Blocking DiskDaemon
DiskThreads IpcIo Mmapped
checking aio.h usability... yes
checking aio.h presence... yes
checking for aio.h... yes
checking for aio_read in -lrt... yes
configure: Native POSIX AIO support detected.
configure: Enabling AIO DiskIO module
configure: Enabling Blocking DiskIO module
configure: Enabling DiskDaemon DiskIO module
configure: Enabling DiskThreads DiskIO module
configure: Enabling IpcIo DiskIO module
configure: Enabling Mmapped DiskIO module
configure: IO Modules built:  AIO Blocking DiskDaemon DiskThreads IpcIo
Mmapped
checking for available StoreIO modules...  aufs diskd rock ufs
configure: Store modules built:  aufs diskd rock ufs
configure: Removal policies to build: lru heap
configure: Disabling ESI processor
checking whether to support eCAP... no, implicitly
checking for pkg-config... no
configure: Web Cache Coordination Protocol enabled: no
configure: Web Cache Coordination V2 Protocol enabled: no
configure: Kill parent on shutdown hack enabled: no
configure: SNMP support enabled: yes
configure: Cachemgr default hostname set to ip.proxy-cache.willsz.net
configure: EUI (MAC address) controls enabled: no
configure: HTCP support enabled: no
checking for nettle_md5_init in -lnettle... yes
checking nettle/md5.h usability... yes
checking nettle/md5.h presence... yes
checking for nettle/md5.h... yes
configure: Using Nettle cryptographic library: yes
checking for crypt in -lcrypt... yes
checking for MD5Init in -lmd5... no
configure: GnuTLS library support: no  
configure: OpenSSL library support: no  
checking for krb5-config... /usr/bin/krb5-config
checking for krb5-config... (cached) /usr/bin/krb5-config
checking for LIB_KRB5... no
configure: Use krb5-config to get CXXFLAGS and LIBS
configure: Try to find Kerberos headers in given path
checking gssapi.h usability... yes
checking gssapi.h presence... yes
checking for gssapi.h... yes
checking gssapi/gssapi.h usability... yes
checking gssapi/gssapi.h presence... yes
checking for gssapi/gssapi.h... yes
checking gssapi/gssapi_krb5.h usability... yes
checking gssapi/gssapi_krb5.h presence... yes
checking for gssapi/gssapi_krb5.h... yes
checking krb5.h usability... yes
checking krb5.h presence... yes
checking for krb5.h... yes
checking com_err.h usability... yes
checking com_err.h presence... yes
checking for com_err.h... yes
checking et/com_err.h usability... no
checking et/com_err.h presence... no
checking for et/com_err.h... no
checking for broken Heimdal krb5.h... no
checking for error_message in -lcom_err... yes
checking for krb5_get_err_text in -lkrb5... yes
checking for krb5_get_error_message in -lkrb5... yes
checking for krb5_free_error_message in -lkrb5... yes
checking for krb5_free_error_string in -lkrb5... yes
checking whether krb5_kt_free_entry is declared... yes
checking for krb5_pac... yes
checking for krb5_kt_free_entry in -lkrb5... yes
checking for krb5_get_init_creds_keytab in -lkrb5... yes
checking for krb5_get_max_time_skew in -lkrb5... yes
checking for krb5_get_profile in -lkrb5... no
checking for profile_get_integer in -lkrb5... no
checking for profile_release in -lkrb5... no
checking for krb5_get_renewed_creds in -lkrb5... yes
checking for krb5_principal_get_realm in -lkrb5... yes
checking for krb5_get_init_creds_opt_alloc in -lkrb5... yes
checking for krb5_get_init_creds_free requires krb5_context... yes
checking for gss_map_name_to_any... no
checking for gsskrb5_extract_authz_data_from_sec_context... yes
checking for memory cache... no
checking for memory keytab... no
checking for working gssapi... no
configure: Check Runtime library path !
checking for spnego support... no
checking for working krb5... no
configure: Check Runtime library path !
configure: Heimdal Kerberos library support: yes  -L/usr/lib -lgssapi
-lgssapi_krb5 -lheimntlm -lkrb5 -lhx509 -lcom_err -lcrypto -lasn1 -lwind
-lheimbase -lroken -lcrypt -pthread -L/usr/lib -lkrb5 -lhx509 -lcom_err
-lcrypto -lasn1 -lwind -lheimbase -lroken -lcrypt -pthread
checking for ldap_init in -lldap... no
checking for ber_init in -llber... no
checking for ldap_init in -lldap60... no
checking for prldap_init in -lprldap60... no
checking for ldapssl_init in -lssldap60... no
checking ldap.h usability... no
checking ldap.h presence... no
checking for ldap.h... no
checking lber.h usability... no
checking lber.h presence... no
checking for lber.h... no
checking mozldap/ldap.h usability... no
checking mozldap/ldap.h presence... no
checking for mozldap/ldap.h... no
checking for LDAP_OPT_DEBUG_LEVEL... no
checking for working ldap... no
checking for OpenLDAP... no
checking for Sun LDAP SDK... no
checking for Mozilla LDAP SDK... no
checking for LDAP_REBINDPROC_CALLBACK... no
checking for LDAP_REBIND_PROC... no
checking for LDAP_REBIND_FUNCTION... no
checking for LDAP_SCOPE_DEFAULT... no
checking for struct ldap_url_desc.lud_scheme... no
checking for ldapssl_client_init in -lldap... no
checking for ldap_url_desc2str in -lldap... no
checking for ldap_url_parse in -lldap... no
checking for ldap_start_tls_s in -lldap... no
configure: Forw/Via database enabled: no
configure: Cache Digests enabled: no
configure: enabling select syscall for net I/O: auto
configure: enabling poll syscall for net I/O: auto
checking sys/event.h usability... yes
checking sys/event.h presence... yes
checking for sys/event.h... yes
checking for kqueue... yes
configure: enabling kqueue for net I/O: auto
configure: enabling epoll syscall for net I/O: no
configure: enabling /dev/poll for net I/O: auto
checking for ioctl... yes
checking for write... yes
checking sys/devpoll.h usability... no
checking sys/devpoll.h presence... no
checking for sys/devpoll.h... no
configure: HTTP violations support enabled: yes
configure: FreeBSD IPFW-based transparent proxying enabled: yes
configure: IPF-based transparent proxying requested: no
configure: PF-based transparent proxying requested: no
configure: NAT lookups via /dev/pf: no
configure: Linux Netfilter support requested: no
configure: Linux Netfilter Conntrack support requested: auto
checking for library containing nfct_query... no
checking libnetfilter_conntrack/libnetfilter_conntrack.h usability... no
checking libnetfilter_conntrack/libnetfilter_conntrack.h presence... no
checking for libnetfilter_conntrack/libnetfilter_conntrack.h... no
checking libnetfilter_conntrack/libnetfilter_conntrack_tcp.h usability... no
checking libnetfilter_conntrack/libnetfilter_conntrack_tcp.h presence... no
checking for libnetfilter_conntrack/libnetfilter_conntrack_tcp.h... no
checking size of long... 4
configure: Using POSIX_V6_ILP32_OFFBIG build environment
configure: Leak Finder enabled: no
configure: Support for X-Forwarded-For enabled: yes
configure: Support for Ident lookups enabled: yes
configure: Default hosts file set to: /etc/hosts
configure: Authentication support enabled: yes
checking for ldap.h... (cached) no
checking winldap.h usability... no
checking winldap.h presence... no
checking for winldap.h... no
configure: Basic auth helper LDAP ... found but cannot be built
checking for crypt... yes
checking for sys/types.h... yes
checking for rpc/rpc.h... yes
checking for rpcsvc/ypclnt.h... yes
checking for rpcsvc/yp_prot.h... yes
checking for crypt.h... no
configure: Basic auth helper NIS ... found but cannot be built
checking security/pam_appl.h usability... yes
checking security/pam_appl.h presence... yes
checking for security/pam_appl.h... yes
checking for PAM conversation struct signature type... linux
checking sasl/sasl.h usability... no
checking sasl/sasl.h presence... no
checking for sasl/sasl.h... no
checking sasl.h usability... no
checking sasl.h presence... no
checking for sasl.h... no
checking for sasl_errstring in -lsasl2... no
checking for sasl_errstring in -lsasl... no
configure: Basic auth helper SASL ... found but cannot be built
checking for smbclient... no
checking w32api/windows.h usability... no
checking w32api/windows.h presence... no
checking for w32api/windows.h... no
checking windows.h usability... no
checking windows.h presence... no
checking for windows.h... no
checking for w32api/windows.h... (cached) no
checking for windows.h... (cached) no
configure: Basic auth helper SSPI ... found but cannot be built
checking pwd.h usability... yes
checking pwd.h presence... yes
checking for pwd.h... yes
checking for crypt... (cached) yes
checking for unistd.h... (cached) yes
checking for crypt.h... (cached) no
checking shadow.h usability... no
checking shadow.h presence... no
checking for shadow.h... no
configure: Basic auth helpers to be built:  DB MSNT-multi-domain NCSA PAM
POP3 RADIUS SMB SMB_LM fake getpwnam
checking for ldap.h... (cached) no
checking for winldap.h... (cached) no
configure: Digest auth helper LDAP ... found but cannot be built
checking for ldap.h... (cached) no
checking for winldap.h... (cached) no
configure: Digest auth helper eDirectory ... found but cannot be built
configure: Digest auth helpers to be built:  file
configure: Negotiate auth helpers to be built: 
checking for w32api/windows.h... (cached) no
checking for windows.h... (cached) no
configure: NTLM auth helper SSPI ... found but cannot be built
checking for w32api/windows.h... (cached) no
checking for windows.h... (cached) no
configure: NTLM auth helpers to be built:  fake smb_lm
checking machine/byte_swap.h usability... no
checking machine/byte_swap.h presence... no
checking for machine/byte_swap.h... no
checking sys/bswap.h usability... no
checking sys/bswap.h presence... no
checking for sys/bswap.h... no
checking endian.h usability... no
checking endian.h presence... no
checking for endian.h... no
checking sys/endian.h usability... yes
checking sys/endian.h presence... yes
checking for sys/endian.h... yes
checking for bswap_16... no
checking for bswap16... no
checking for bswap_32... no
checking for bswap32... no
checking for htole16... no
checking for __htole16... no
checking for htole32... no
checking for __htole32... no
checking for le16toh... no
checking for __le16toh... no
checking for le32toh... no
checking for __le32toh... no
configure: Log daemon helpers to be built:  DB file
configure: external acl helper AD_group ... found but cannot be built
checking for ldap.h... (cached) no
checking for winldap.h... (cached) no
configure: external acl helper LDAP_group ... found but cannot be built
checking for w32api/windows.h... (cached) no
checking for windows.h... (cached) no
configure: external acl helper LM_group ... found but cannot be built
checking for ldap.h... (cached) no
checking for winldap.h... (cached) no
configure: external acl helper eDirectory_userip ... found but cannot be
built
checking sys/socket.h usability... yes
checking sys/socket.h presence... yes
checking for sys/socket.h... yes
checking for sasl/sasl.h... (cached) no
checking for sasl.h... (cached) no
checking for sasl_errstring in -lsasl2... (cached) no
checking for sasl_errstring in -lsasl... (cached) no
configure: external acl helper session ... found but cannot be built
checking db_185.h usability... no
checking db_185.h presence... no
checking for db_185.h... no
checking for pwd.h... (cached) yes
checking for wbinfo... no
configure: External acl helpers to be built:  SQL_session delayer
file_userip kerberos_ldap_group time_quota unix_group wbinfo_group
configure: URL rewrite helper candidates: fake
configure: URL rewrite helpers to be built:  fake
configure: Store-ID rewrite helper candidates: file
configure: Store-ID rewrite helpers to be built:  file
configure: Valgrind debug support enabled: no
configure: MS Windows service mode enabled: no
configure: unlinkd enabled: yes
configure: Automatically print stack trace on fatal errors: no
configure: CPU profiling enabled: no
configure: X-Accelerator-Vary support enabled: no
checking cppunit/extensions/HelperMacros.h usability... no
checking cppunit/extensions/HelperMacros.h presence... no
checking for cppunit/extensions/HelperMacros.h... no
checking for dirent.h that defines DIR... yes
checking for library containing opendir... none required
checking for ANSI C header files... yes
checking arpa/inet.h usability... yes
checking arpa/inet.h presence... yes
checking for arpa/inet.h... yes
checking arpa/nameser.h usability... yes
checking arpa/nameser.h presence... yes
checking for arpa/nameser.h... yes
checking assert.h usability... yes
checking assert.h presence... yes
checking for assert.h... yes
checking bstring.h usability... no
checking bstring.h presence... no
checking for bstring.h... no
checking for crypt.h... (cached) no
checking ctype.h usability... yes
checking ctype.h presence... yes
checking for ctype.h... yes
checking direct.h usability... no
checking direct.h presence... no
checking for direct.h... no
checking errno.h usability... yes
checking errno.h presence... yes
checking for errno.h... yes
checking execinfo.h usability... yes
checking execinfo.h presence... yes
checking for execinfo.h... yes
checking fcntl.h usability... yes
checking fcntl.h presence... yes
checking for fcntl.h... yes
checking fnmatch.h usability... yes
checking fnmatch.h presence... yes
checking for fnmatch.h... yes
checking getopt.h usability... yes
checking getopt.h presence... yes
checking for getopt.h... yes
checking glob.h usability... yes
checking glob.h presence... yes
checking for glob.h... yes
checking gnumalloc.h usability... no
checking gnumalloc.h presence... no
checking for gnumalloc.h... no
checking grp.h usability... yes
checking grp.h presence... yes
checking for grp.h... yes
checking ipl.h usability... no
checking ipl.h presence... no
checking for ipl.h... no
checking for lber.h... (cached) no
checking for ldap.h... (cached) no
checking libc.h usability... no
checking libc.h presence... no
checking for libc.h... no
checking limits.h usability... yes
checking limits.h presence... yes
checking for limits.h... yes
checking linux/posix_types.h usability... no
checking linux/posix_types.h presence... no
checking for linux/posix_types.h... no
checking linux/types.h usability... no
checking linux/types.h presence... no
checking for linux/types.h... no
checking malloc.h usability... no
checking malloc.h presence... no
checking for malloc.h... no
checking math.h usability... yes
checking math.h presence... yes
checking for math.h... yes
checking memory.h usability... yes
checking memory.h presence... yes
checking for memory.h... yes
checking mount.h usability... no
checking mount.h presence... no
checking for mount.h... no
checking netdb.h usability... yes
checking netdb.h presence... yes
checking for netdb.h... yes
checking netinet/in.h usability... yes
checking netinet/in.h presence... yes
checking for netinet/in.h... yes
checking netinet/in_systm.h usability... yes
checking netinet/in_systm.h presence... yes
checking for netinet/in_systm.h... yes
checking netinet/tcp.h usability... yes
checking netinet/tcp.h presence... yes
checking for netinet/tcp.h... yes
checking paths.h usability... yes
checking paths.h presence... yes
checking for paths.h... yes
checking poll.h usability... yes
checking poll.h presence... yes
checking for poll.h... yes
checking for pwd.h... (cached) yes
checking regex.h usability... yes
checking regex.h presence... yes
checking for regex.h... yes
checking sched.h usability... yes
checking sched.h presence... yes
checking for sched.h... yes
checking siginfo.h usability... no
checking siginfo.h presence... no
checking for siginfo.h... no
checking signal.h usability... yes
checking signal.h presence... yes
checking for signal.h... yes
checking stdarg.h usability... yes
checking stdarg.h presence... yes
checking for stdarg.h... yes
checking stdbool.h usability... yes
checking stdbool.h presence... yes
checking for stdbool.h... yes
checking stddef.h usability... yes
checking stddef.h presence... yes
checking for stddef.h... yes
checking stdio.h usability... yes
checking stdio.h presence... yes
checking for stdio.h... yes
checking stdlib.h usability... yes
checking stdlib.h presence... yes
checking for stdlib.h... yes
checking string.h usability... yes
checking string.h presence... yes
checking for string.h... yes
checking strings.h usability... yes
checking strings.h presence... yes
checking for strings.h... yes
checking sys/bitypes.h usability... no
checking sys/bitypes.h presence... no
checking for sys/bitypes.h... no
checking sys/file.h usability... yes
checking sys/file.h presence... yes
checking for sys/file.h... yes
checking sys/ioctl.h usability... yes
checking sys/ioctl.h presence... yes
checking for sys/ioctl.h... yes
checking sys/ipc.cc usability... no
checking sys/ipc.cc presence... no
checking for sys/ipc.cc... no
checking sys/param.h usability... yes
checking sys/param.h presence... yes
checking for sys/param.h... yes
checking sys/prctl.h usability... no
checking sys/prctl.h presence... no
checking for sys/prctl.h... no
checking sys/md5.h usability... yes
checking sys/md5.h presence... yes
checking for sys/md5.h... yes
checking sys/mman.h usability... yes
checking sys/mman.h presence... yes
checking for sys/mman.h... yes
checking sys/msg.h usability... yes
checking sys/msg.h presence... yes
checking for sys/msg.h... yes
checking sys/resource.h usability... yes
checking sys/resource.h presence... yes
checking for sys/resource.h... yes
checking sys/select.h usability... yes
checking sys/select.h presence... yes
checking for sys/select.h... yes
checking sys/shm.h usability... yes
checking sys/shm.h presence... yes
checking for sys/shm.h... yes
checking for sys/socket.h... (cached) yes
checking sys/stat.h usability... yes
checking sys/stat.h presence... yes
checking for sys/stat.h... yes
checking syscall.h usability... no
checking syscall.h presence... no
checking for syscall.h... no
checking sys/syscall.h usability... yes
checking sys/syscall.h presence... yes
checking for sys/syscall.h... yes
checking sys/time.h usability... yes
checking sys/time.h presence... yes
checking for sys/time.h... yes
checking for sys/types.h... (cached) yes
checking sys/uio.h usability... yes
checking sys/uio.h presence... yes
checking for sys/uio.h... yes
checking sys/un.h usability... yes
checking sys/un.h presence... yes
checking for sys/un.h... yes
checking sys/vfs.h usability... no
checking sys/vfs.h presence... no
checking for sys/vfs.h... no
checking sys/wait.h usability... yes
checking sys/wait.h presence... yes
checking for sys/wait.h... yes
checking syslog.h usability... yes
checking syslog.h presence... yes
checking for syslog.h... yes
checking time.h usability... yes
checking time.h presence... yes
checking for time.h... yes
checking for unistd.h... (cached) yes
checking utime.h usability... yes
checking utime.h presence... yes
checking for utime.h... yes
checking varargs.h usability... no
checking varargs.h presence... no
checking for varargs.h... no
checking byteswap.h usability... no
checking byteswap.h presence... no
checking for byteswap.h... no
checking glib.h usability... no
checking glib.h presence... no
checking for glib.h... no
checking stdint.h usability... yes
checking stdint.h presence... yes
checking for stdint.h... yes
checking inttypes.h usability... yes
checking inttypes.h presence... yes
checking for inttypes.h... yes
checking db.h usability... yes
checking db.h presence... yes
checking for db.h... yes
checking for db_185.h... (cached) no
checking wchar.h usability... yes
checking wchar.h presence... yes
checking for wchar.h... yes
checking for linux/netfilter_ipv4.h... no
checking for linux/netfilter_ipv6/ip6_tables.h... no
checking for net/if.h... yes
checking for netinet/if_ether.h... yes
checking for netinet/icmp6.h... yes
checking for netinet/in.h... (cached) yes
checking for netinet/ip.h... yes
checking for netinet/ip6.h... yes
checking for netinet/ip_icmp.h... yes
checking for netinet/ipl.h... yes
checking for net/pf/pfvar.h... no
checking for net/pfvar.h... yes
checking for sys/mount.h... yes
checking for resolv.h... yes
checking for an ANSI C-conforming const... yes
checking whether byte ordering is bigendian... no
checking whether struct tm is in sys/time.h or time.h... time.h
checking for struct tm.tm_gmtoff... yes
checking for struct rusage... yes
checking for struct iphdr.ip_hl... yes
checking size of void *... 4
checking for int8_t... yes
checking for uint8_t... yes
checking for int16_t... yes
checking for uint16_t... yes
checking for int32_t... yes
checking for uint32_t... yes
checking for int64_t... yes
checking for uint64_t... yes
checking for pid_t... yes
checking for size_t... yes
checking for ssize_t... yes
checking for off_t... yes
checking for uid_t in sys/types.h... yes
checking for bool... yes
checking size of int64_t... 8
checking size of long... (cached) 4
checking size of size_t... 4
checking size of off_t... 8
checking size of size_t... (cached) 4
checking whether nullptr is supported... yes
checking whether nullptr_t is supported... yes
checking whether std::unique_ptr<T> is supported... yes
checking for pad128_t... no
checking for upad128_t... no
checking for mode_t... yes
checking for fd_mask... yes
checking for socklen_t... yes
checking for mtyp_t... no
checking for compiler %zu support... yes
checking for working alloca.h... no
checking for alloca... yes
checking sys/capability.h usability... yes
checking sys/capability.h presence... yes
checking for sys/capability.h... yes
checking for cap_clear_flag in -lcap... no
checking for operational libcap2 headers... no
configure: libcap support enabled: no
configure: libcap2 headers are ok: no
checking for library containing gethostbyname... none required
checking for library containing res_init... none required
checking for library containing __res_search... none required
checking for library containing bind... none required
checking for library containing opcom_stack_trace... no
checking for library containing strlcpy... none required
checking for library containing yp_match... none required
checking for unix domain sockets... yes
checking for malloc in -lgnumalloc... no
configure: skipping libmalloc check for i386-unknown-freebsd10.3
checking for library containing rint... -lm
checking for library containing log... none required
checking Default FD_SETSIZE value... 1024
checking for setrlimit... yes
checking Maximum number of filedescriptors we can open... 32768
configure: Default number of fieldescriptors: 32768
checking whether to enable IPv6... yes
checking for sin6_len field in struct sockaddr_in6... yes
checking for ss_len field in struct sockaddr_storage... yes
checking for sin_len field in struct sockaddr_in... yes
checking whether dbopen is declared... yes
checking if dbopen needs -ldb... no
checking for backtrace_symbols_fd... no
checking for bcopy... yes
checking for eui64_aton... yes
checking for fchmod... yes
checking for getdtablesize... yes
checking for getpagesize... yes
checking for getpass... yes
checking for getrlimit... yes
checking for getrusage... yes
checking for getspnam... no
checking for gettimeofday... yes
checking for glob... yes
checking for lrand48... yes
checking for mallocblksize... no
checking for mallopt... no
checking for memcpy... yes
checking for memmove... yes
checking for memrchr... yes
checking for memset... yes
checking for mkstemp... yes
checking for mktime... yes
checking for mstats... no
checking for poll... yes
checking for prctl... no
checking for pthread_attr_setschedparam... yes
checking for pthread_attr_setscope... yes
checking for pthread_setschedparam... yes
checking for pthread_sigmask... yes
checking for putenv... yes
checking for random... yes
checking for regcomp... yes
checking for regexec... yes
checking for regfree... yes
checking for res_init... yes
checking for __res_init... yes
checking for rint... yes
checking for sched_getaffinity... no
checking for sched_setaffinity... no
checking for select... yes
checking for seteuid... yes
checking for setgroups... yes
checking for setpgrp... yes
checking for setsid... yes
checking for sigaction... yes
checking for snprintf... yes
checking for socketpair... yes
checking for srand48... yes
checking for srandom... yes
checking for sysconf... yes
checking for syslog... yes
checking for timegm... yes
checking for vsnprintf... yes
checking for drand48... yes
checking for initgroups... yes
checking for psignal... yes
checking for strerror... yes
checking for strtoll... yes
checking for tempnam... yes
checking whether getaddrinfo is declared... yes
checking whether getnameinfo is declared... yes
checking whether inet_ntop is declared... yes
checking whether inet_pton is declared... yes
configure: choosing user-specified net I/O API kqueue
configure: Using kqueue for the IO loop.
checking if setresuid is actually implemented... yes
checking mswsock.h usability... no
checking mswsock.h presence... no
checking for mswsock.h... no
checking for constant CMSG_SPACE... no
checking for struct cmsghdr... yes
checking for struct iovec... yes
checking for struct msghdr... yes
checking for struct sockaddr_un... yes
checking if strnstr is well implemented... no
checking if va_copy is implemented... yes
checking if __va_copy is implemented... yes
configure: IPF-based transparent proxying enabled: no
configure: Support for Netfilter-based interception proxy requested: no
configure: Linux Netfilter Conntrack support enabled: no 
configure: ZPH QOS enabled: yes
configure: QOS netfilter mark preservation enabled: no
checking for regexec in -lregex... no
checking if the system-supplied regex lib actually works... yes
checking if GNUregex needs to be compiled... no
checking Default UDP send buffer size... 9216
checking Default UDP receive buffer size... 41600
checking Default TCP send buffer size... 32768
checking Default TCP receive buffer size... 65536
configure: Limiting receive buffer size to 64K
checking whether recv takes a pointer to void or char as second argument...
char*
char
checking if sys_errlist is already defined... yes
checking for system-provided MAXPATHLEN... yes
checking for libresolv _dns_ttl_ hack... no
checking for _res_ext.nsaddr_list... no
checking for _res._u._ext.nsaddrs... no
checking for _res.nsaddr_list... yes
checking for _res.ns_list... no
checking sys/statvfs.h usability... yes
checking sys/statvfs.h presence... yes
checking for sys/statvfs.h... yes
checking for working statvfs() interface... yes
configure: Multi-Language support enabled: yes
configure: BUILD LIBRARIES: 
configure: BUILD EXTRA LIBRARIES: -lm
configure: BUILD OBJECTS: 
configure: BUILD EXTRA OBJECTS: 
configure: BUILD C FLAGS:  -Wall -g -O2 -I/usr/local/include
configure: BUILD EXTRA C FLAGS: -Wall -Wpointer-arith -Wwrite-strings
-Wmissing-prototypes -Wmissing-declarations -Wcomments -Wshadow -Werror
-pipe -D_REENTRANT
configure: BUILD C++ FLAGS:  -g -O2 -std=c++11 -I/usr/local/include
configure: BUILD EXTRA C++ FLAGS: -Wall -Wpointer-arith -Wwrite-strings
-Wcomments -Wshadow -Woverloaded-virtual -Werror -pipe -D_REENTRANT
configure: BUILD Tools C++ FLAGS:   -g -O2 -std=c++11 -I/usr/local/include
checking that generated files are newer than configure... done
configure: creating ./config.status
config.status: creating Makefile
config.status: creating compat/Makefile
config.status: creating lib/Makefile
config.status: creating lib/ntlmauth/Makefile
config.status: creating lib/libTrie/Makefile
config.status: creating lib/libTrie/test/Makefile
config.status: creating lib/profiler/Makefile
config.status: creating lib/rfcnb/Makefile
config.status: creating lib/smblib/Makefile
config.status: creating lib/snmplib/Makefile
config.status: creating scripts/Makefile
config.status: creating src/Makefile
config.status: creating src/anyp/Makefile
config.status: creating src/ftp/Makefile
config.status: creating src/base/Makefile
config.status: creating src/acl/Makefile
config.status: creating src/clients/Makefile
config.status: creating src/servers/Makefile
config.status: creating src/fs/Makefile
config.status: creating src/repl/Makefile
config.status: creating src/auth/Makefile
config.status: creating src/auth/basic/Makefile
config.status: creating src/auth/digest/Makefile
config.status: creating src/auth/negotiate/Makefile
config.status: creating src/auth/ntlm/Makefile
config.status: creating src/adaptation/Makefile
config.status: creating src/adaptation/icap/Makefile
config.status: creating src/adaptation/ecap/Makefile
config.status: creating src/comm/Makefile
config.status: creating src/esi/Makefile
config.status: creating src/eui/Makefile
config.status: creating src/format/Makefile
config.status: creating src/helper/Makefile
config.status: creating src/http/Makefile
config.status: creating src/icmp/Makefile
config.status: creating src/ident/Makefile
config.status: creating src/ip/Makefile
config.status: creating src/log/Makefile
config.status: creating src/ipc/Makefile
config.status: creating src/ssl/Makefile
config.status: creating src/mgr/Makefile
config.status: creating src/parser/Makefile
config.status: creating src/snmp/Makefile
config.status: creating contrib/Makefile
config.status: creating icons/Makefile
config.status: creating errors/Makefile
config.status: creating test-suite/Makefile
config.status: creating doc/Makefile
config.status: creating doc/manuals/Makefile
config.status: creating doc/release-notes/Makefile
config.status: creating helpers/Makefile
config.status: creating helpers/basic_auth/Makefile
config.status: creating helpers/basic_auth/DB/Makefile
config.status: creating helpers/basic_auth/fake/Makefile
config.status: creating helpers/basic_auth/getpwnam/Makefile
config.status: creating helpers/basic_auth/LDAP/Makefile
config.status: creating helpers/basic_auth/MSNT-multi-domain/Makefile
config.status: creating helpers/basic_auth/NCSA/Makefile
config.status: creating helpers/basic_auth/NIS/Makefile
config.status: creating helpers/basic_auth/PAM/Makefile
config.status: creating helpers/basic_auth/POP3/Makefile
config.status: creating helpers/basic_auth/RADIUS/Makefile
config.status: creating helpers/basic_auth/SASL/Makefile
config.status: creating helpers/basic_auth/SMB/Makefile
config.status: creating helpers/basic_auth/SMB_LM/Makefile
config.status: creating helpers/basic_auth/SSPI/Makefile
config.status: creating helpers/digest_auth/Makefile
config.status: creating helpers/digest_auth/eDirectory/Makefile
config.status: creating helpers/digest_auth/file/Makefile
config.status: creating helpers/digest_auth/LDAP/Makefile
config.status: creating helpers/ntlm_auth/Makefile
config.status: creating helpers/ntlm_auth/fake/Makefile
config.status: creating helpers/ntlm_auth/smb_lm/Makefile
config.status: creating helpers/ntlm_auth/SSPI/Makefile
config.status: creating helpers/negotiate_auth/Makefile
config.status: creating helpers/negotiate_auth/kerberos/Makefile
config.status: creating helpers/negotiate_auth/SSPI/Makefile
config.status: creating helpers/negotiate_auth/wrapper/Makefile
config.status: creating helpers/external_acl/Makefile
config.status: creating helpers/external_acl/AD_group/Makefile
config.status: creating helpers/external_acl/delayer/Makefile
config.status: creating helpers/external_acl/eDirectory_userip/Makefile
config.status: creating helpers/external_acl/file_userip/Makefile
config.status: creating helpers/external_acl/kerberos_ldap_group/Makefile
config.status: creating helpers/external_acl/LDAP_group/Makefile
config.status: creating helpers/external_acl/LM_group/Makefile
config.status: creating helpers/external_acl/session/Makefile
config.status: creating helpers/external_acl/SQL_session/Makefile
config.status: creating helpers/external_acl/unix_group/Makefile
config.status: creating helpers/external_acl/wbinfo_group/Makefile
config.status: creating helpers/external_acl/time_quota/Makefile
config.status: creating helpers/log_daemon/Makefile
config.status: creating helpers/log_daemon/DB/Makefile
config.status: creating helpers/log_daemon/file/Makefile
config.status: creating helpers/url_rewrite/Makefile
config.status: creating helpers/url_rewrite/fake/Makefile
config.status: creating helpers/ssl/Makefile
config.status: creating helpers/storeid_rewrite/Makefile
config.status: creating helpers/storeid_rewrite/file/Makefile
config.status: creating tools/Makefile
config.status: creating tools/purge/Makefile
config.status: creating tools/squidclient/Makefile
config.status: creating tools/systemd/Makefile
config.status: creating tools/sysvinit/Makefile
config.status: creating include/autoconf.h
config.status: include/autoconf.h is unchanged
config.status: executing depfiles commands
config.status: executing libtool commands
=== configuring in libltdl (/usr/local/src/squid-3.5.26/libltdl)
configure: running /bin/sh ./configure --disable-option-checking
'--prefix=/usr/local'  '--includedir=/usr/local/include'
'--bindir=/usr/local/sbin' '--libexecdir=/usr/local/libexec/squid'
'--sysconfdir=/usr/local/etc/squid' '--with-default-user=squid'
'--localstatedir=/var/cache/squid' '--libdir=/usr/local/lib'
'--with-logdir=/var/log/squid' '--with-pidfile=/var/run/squid.pid'
'--with-swapdir=/var/cache/squid' '--without-gnutls' '--enable-build-info'
'--enable-loadable-modules' '--enable-removal-policies=lru,heap'
'--disable-epoll' '--disable-linux-netfilter' '--disable-linux-tproxy'
'--disable-translation' '--disable-arch-native' '--mandir=/usr/local/man'
'--infodir=/usr/local/info' '--disable-wccp' '--disable-wccpv2'
'--enable-ipfw-transparent' '--with-large-files' '--disable-htcp'
'--disable-eui' '--enable-cachemgr-hostname=ip.proxy-cache.willsz.net'
'--disable-auth-negotiate' --cache-file=/dev/null --srcdir=.
checking for a BSD-compatible install... /usr/bin/install -c
checking whether build environment is sane... yes
checking for a thread-safe mkdir -p... ../cfgaux/install-sh -c -d
checking for gawk... no
checking for mawk... no
checking for nawk... nawk
checking whether make sets $(MAKE)... yes
checking whether make supports nested variables... yes
checking whether make supports nested variables... (cached) yes
checking build system type... i386-unknown-freebsd10.3
checking host system type... i386-unknown-freebsd10.3
checking how to print strings... printf
checking for style of include used by make... GNU
checking for gcc... gcc
checking whether the C compiler works... yes
checking for C compiler default output file name... a.out
checking for suffix of executables... 
checking whether we are cross compiling... no
checking for suffix of object files... o
checking whether we are using the GNU C compiler... yes
checking whether gcc accepts -g... yes
checking for gcc option to accept ISO C89... none needed
checking whether gcc understands -c and -o together... yes
checking dependency style of gcc... gcc3
checking for a sed that does not truncate output... /usr/bin/sed
checking for grep that handles long lines and -e... /usr/bin/grep
checking for egrep... /usr/bin/grep -E
checking for fgrep... /usr/bin/grep -F
checking for ld used by gcc... /usr/local/bin/ld
checking if the linker (/usr/local/bin/ld) is GNU ld... yes
checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B
checking the name lister (/usr/bin/nm -B) interface... BSD nm
checking whether ln -s works... yes
checking the maximum length of command line arguments... 196608
checking how to convert i386-unknown-freebsd10.3 file names to
i386-unknown-freebsd10.3 format... func_convert_file_noop
checking how to convert i386-unknown-freebsd10.3 file names to toolchain
format... func_convert_file_noop
checking for /usr/local/bin/ld option to reload object files... -r
checking for objdump... objdump
checking how to recognize dependent libraries... pass_all
checking for dlltool... no
checking how to associate runtime and link libraries... printf %s\n
checking for ar... ar
checking for archiver @FILE support... no
checking for strip... strip
checking for ranlib... ranlib
checking command to parse /usr/bin/nm -B output from gcc object... ok
checking for sysroot... no
checking for a working dd... /bin/dd
checking how to truncate binary pipes... /bin/dd bs=4096 count=1
checking for mt... mt
checking if mt is a manifest tool... no
checking how to run the C preprocessor... gcc -E
checking for ANSI C header files... yes
checking for sys/types.h... yes
checking for sys/stat.h... yes
checking for stdlib.h... yes
checking for string.h... yes
checking for memory.h... yes
checking for strings.h... yes
checking for inttypes.h... yes
checking for stdint.h... yes
checking for unistd.h... yes
checking for dlfcn.h... yes
checking for objdir... .libs
checking if gcc supports -fno-rtti -fno-exceptions... no
checking for gcc option to produce PIC... -fPIC -DPIC
checking if gcc PIC flag -fPIC -DPIC works... yes
checking if gcc static flag -static works... yes
checking if gcc supports -c -o file.o... yes
checking if gcc supports -c -o file.o... (cached) yes
checking whether the gcc linker (/usr/local/bin/ld) supports shared
libraries... yes
checking whether -lc should be explicitly linked in... no
checking dynamic linker characteristics... freebsd10.3 ld.so
checking how to hardcode library paths into programs... immediate
checking for shl_load... no
checking for shl_load in -ldld... no
checking for dlopen... yes
checking whether a program can dlopen itself... yes
checking whether a statically linked program can dlopen itself... no
checking whether stripping libraries is possible... yes
checking if libtool supports shared libraries... yes
checking whether to build shared libraries... yes
checking whether to build static libraries... yes
checking what extension is used for runtime loadable modules... .so
checking what variable specifies run-time module search path...
LD_LIBRARY_PATH
checking for the default library search path... /lib /usr/lib
checking for library containing dlopen... none required
checking for dlerror... yes
checking for shl_load... (cached) no
checking for shl_load in -ldld... (cached) no
checking for dld_link in -ldld... no
checking for _ prefix in compiled symbols... no
checking whether deplibs are loaded by dlopen... yes
checking for argz.h... no
checking for error_t... no
checking for argz_add... no
checking for argz_append... no
checking for argz_count... no
checking for argz_create_sep... no
checking for argz_insert... no
checking for argz_next... no
checking for argz_stringify... no
checking whether libtool supports -dlopen/-dlpreopen... yes
checking for unistd.h... (cached) yes
checking for dl.h... no
checking for sys/dl.h... no
checking for dld.h... no
checking for mach-o/dyld.h... no
checking for dirent.h... yes
checking for closedir... yes
checking for opendir... yes
checking for readdir... yes
checking for strlcat... yes
checking for strlcpy... yes
checking that generated files are newer than configure... done
configure: creating ./config.status
config.status: creating Makefile
config.status: creating config.h
config.status: config.h is unchanged
config.status: executing depfiles commands
config.status: executing libtool commands

root:/usr/local/src/squid-3.5.26# make check
/bin/sh ../libtool  --tag=CXX    --mode=link g++ -Wall -Wpointer-arith
-Wwrite-strings -Wcomments -Wshadow -Woverloaded-virtual -Werror -pipe
-D_REENTRANT  -g -O2 -std=c++11 -I/usr/local/include  -g -L/usr/local/lib
-Wl,-R/usr/local/lib -pthread -o libcompat-squid.la  assert.lo compat.lo
debug.lo  eui64_aton.lo getaddrinfo.lo getnameinfo.lo GnuRegex.lo
inet_ntop.lo inet_pton.lo memrchr.lo shm.lo statvfs.lo  strnstr.lo
strnrchr.lo xalloc.lo xstrerror.lo xstring.lo  xstrto.lo mswindows.lo
libtool: link: /usr/bin/ar cru .libs/libcompat-squid.a .libs/assert.o
.libs/compat.o .libs/debug.o .libs/eui64_aton.o .libs/getaddrinfo.o
.libs/getnameinfo.o .libs/GnuRegex.o .libs/inet_ntop.o .libs/inet_pton.o
.libs/memrchr.o .libs/shm.o .libs/statvfs.o .libs/strnstr.o .libs/strnrchr.o
.libs/xalloc.o .libs/xstrerror.o .libs/xstring.o .libs/xstrto.o
.libs/mswindows.o
libtool: link: ranlib .libs/libcompat-squid.a
libtool: link: ( cd ".libs" && rm -f "libcompat-squid.la" && ln -s
"../libcompat-squid.la" "libcompat-squid.la" )
make  testPreCompiler
depbase=`echo testPreCompiler.o | sed 's|[^/]*$|.deps/&|;s|\.o$||'`; g++
-DHAVE_CONFIG_H    -I.. -I../include  -I../lib -I../src  -I../include
-I/usr/include  -I/usr/include    -Wall -Wpointer-arith -Wwrite-strings
-Wcomments -Wshadow -Woverloaded-virtual -Werror -pipe -D_REENTRANT -g -O2
-std=c++11 -I/usr/local/include -MT testPreCompiler.o -MD -MP -MF
$depbase.Tpo -c -o testPreCompiler.o testPreCompiler.cc && mv -f
$depbase.Tpo $depbase.Po
In file included from testPreCompiler.cc:10:0:
testPreCompiler.h:12:45: fatal error: cppunit/extensions/HelperMacros.h: No
such file or directory
compilation terminated.
*** Error code 1

Stop.
make[2]: stopped in /usr/local/src/squid-3.5.26/compat
*** Error code 1

Stop.
make[1]: stopped in /usr/local/src/squid-3.5.26/compat
*** Error code 1

Stop.
make: stopped in /usr/local/src/squid-3.5.26

Thank You


---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus



From squid3 at treenet.co.nz  Sat Jul  8 11:45:54 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 8 Jul 2017 23:45:54 +1200
Subject: [squid-users] Build Squid-3.5.26 failure in FreeBSD 10.3-STABLE
In-Reply-To: <000001d2f7db$e5b8aeb0$b12a0c10$@com>
References: <000001d2f7db$e5b8aeb0$b12a0c10$@com>
Message-ID: <296b6911-592e-de3b-4276-24f46dbdd786@treenet.co.nz>

On 08/07/17 23:18, Willsz.net wrote:
> Hi,
> 
> I got some problem with this squid version after last night decide to
> upgrading FreeBSD from FreeBSD 9.3-STABLE to FreeBSD 10.3-STABLE. Here's
> some error output:
> 


> root:/usr/local/src/squid-3.5.26# ./configure `cat squid.configure` > log
> Segmentation fault (core dumped)
> Segmentation fault (core dumped)
> Segmentation fault (core dumped)
> Segmentation fault (core dumped)
> Segmentation fault (core dumped)
> Segmentation fault (core dumped)
> Segmentation fault (core dumped)
> configure: WARNING: Neither SASL nor SASL2 found
> configure: WARNING: Samba smbclient not found in default location.
> basic_smb_auth may not work on this machine
> configure: WARNING: Neither SASL nor SASL2 found
> configure: WARNING: Samba wbinfo not found in default location.
> ext_wbinfo_group_acl may not work on this machine
> configure: WARNING: cppunit does not appear to be installed. squid does not
> require this, but code testing with 'make check' will fail.
> 

Did you read those warnings? take the last one for example.


> 
> root:/usr/local/src/squid-3.5.26# make check
...
> In file included from testPreCompiler.cc:10:0:
> testPreCompiler.h:12:45: fatal error: cppunit/extensions/HelperMacros.h: No
> such file or directory
> compilation terminated.

... surprise.

Amos


From squid3 at treenet.co.nz  Sat Jul  8 12:46:48 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 9 Jul 2017 00:46:48 +1200
Subject: [squid-users] Huge amount of time_wait connections after
 upgrade from v2 to v3
In-Reply-To: <22125AC6-0C7D-459E-8BF1-6C9F4EE7A92C@gmail.com>
References: <CAHvB88x+nNYMtmNZWqrZo-p==UykYDj5dZF+5N1eC3rGR8ybGw@mail.gmail.com>
 <ca593b00-8727-c816-8169-d6c528c51d93@treenet.co.nz>
 <CAHvB88w4a6n3uoQZ5UZOi4NH0cpYtoVBD3dZtO5sFcDbRY_Bag@mail.gmail.com>
 <f418e53a-ed5f-e4db-9654-2aa31ad83c57@treenet.co.nz>
 <22125AC6-0C7D-459E-8BF1-6C9F4EE7A92C@gmail.com>
Message-ID: <4c09a163-186c-83c5-30a6-489f1ba1b67c@treenet.co.nz>

On 08/07/17 02:06, Ivan Larionov wrote:
> Thank you for the fast reply.
> 
>> On Jul 7, 2017, at 01:10, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>
>>> On 07/07/17 13:55, Ivan Larionov wrote:
 >>>
>>> However I assumed that this is a bug and that I can find older version which worked fine. I started testing from 3.1.x all the way to 3.5.26 and this is what I found:
>>> * All versions until 3.5.21 work fine. There no issues with huge amount of TIME_WAIT connections under load.
>>> * 3.5.20 is the latest stable version.
>>> * 3.5.21 is the first broken version.
>>> * 3.5.23, 3.5.25, 3.5.26 are broken as well.
>>> This effectively means that bug is somewhere in between 3.5.20 and 3.5.21.
>>> I hope this helps and I hope you'll be able to find an issue. If you can create a bug report based on this information and post it here it would be awesome.
>>
>> The changes in 3.5.21 were fixes to some common crashes and better caching behaviour. So I expect at least some of the change is due to higher traffic throughput on proxies previously restricted by those problems.
>>
> 
> I can't imagine how throughput increase could result in 500 times more TIME_WAIT connections count.
> 

More requests per second generally means more TCP connections churning.

Also when going from Squid-2 to Squid-3 there is a change from HTTP/1.0 
to HTTP/1.1 and the accompanying switch from MISS to near-HIT 
revalidations. Revalidations usually only have headers without payload 
so the same bytes/sec can contain orders more magnitude of those than 
MISS - which is the point of having them.


> In our prod environment when we updated from 2.7.x to 3.5.25 we saw increase from 100 to 10000. This is 100x.
> 

Compared to what RPS change? Given the above traffic change this may be 
reasonable for a v2 to v3 jump. Or own very rough tests on old hardware 
lab tests have shown rates for Squid-2 at ~900 RPS and Squid-3 at around 
1900 RPS.


> When I was load testing different versions yesterday I was always sending the same amount of RPS to them. Update from 3.5.20 to 3.5.21 resulted in jump from 20 to 10000 TIME_WAIT count. This is 500x.
> 
> I know that time_wait is fine in general. Until you have too many of them.
> 

At this point I'd check that your testing software supports HTTP/1.1 
pipelines. It may be giving you worst-case results with per-message TCP 
churn rather than what will occur normally (pipelines of N requests per 
TCP connection).
Though seeing such a jump between Squid-3 releases is worrying.

Amos


From xeron.oskom at gmail.com  Sat Jul  8 16:51:50 2017
From: xeron.oskom at gmail.com (Ivan Larionov)
Date: Sat, 8 Jul 2017 09:51:50 -0700
Subject: [squid-users] Huge amount of time_wait connections after
 upgrade from v2 to v3
In-Reply-To: <4c09a163-186c-83c5-30a6-489f1ba1b67c@treenet.co.nz>
References: <CAHvB88x+nNYMtmNZWqrZo-p==UykYDj5dZF+5N1eC3rGR8ybGw@mail.gmail.com>
 <ca593b00-8727-c816-8169-d6c528c51d93@treenet.co.nz>
 <CAHvB88w4a6n3uoQZ5UZOi4NH0cpYtoVBD3dZtO5sFcDbRY_Bag@mail.gmail.com>
 <f418e53a-ed5f-e4db-9654-2aa31ad83c57@treenet.co.nz>
 <22125AC6-0C7D-459E-8BF1-6C9F4EE7A92C@gmail.com>
 <4c09a163-186c-83c5-30a6-489f1ba1b67c@treenet.co.nz>
Message-ID: <CAHvB88wSq6=nT6FPNdbopiAxfiZhz5zqOAvfa4_aoiYmAq8QKQ@mail.gmail.com>

RPS didn't change. Throughput didn't change. Our prod load is 200-700 RPS
per server (changes during the day) and my load test load was constant 470
RPS.

Clients didn't change. Doesn't matter if they use HTTP 1.1 or 1.0, because
the only thing which changed is squid version. And as I figured out, it's
not actually about 2.7 to 3.5 update, it's all about difference between
3.5.20 and 3.5.21.

I'm sorry but anything you say about throughput doesn't make any sense.
Load pattern didn't change. Squid still handles the same amount of requests.

I think I'm going to load test every patch applied to 3.5.21 from this
page:
http://www.squid-cache.org/Versions/v3/3.5/changesets/SQUID_3_5_21.html so
I'll be able to point to exact change which introduced this behavior. I'll
try to do it during the weekend or may be on Monday.

On Sat, Jul 8, 2017 at 5:46 AM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 08/07/17 02:06, Ivan Larionov wrote:
>
>> Thank you for the fast reply.
>>
>> On Jul 7, 2017, at 01:10, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>>
>>> On 07/07/17 13:55, Ivan Larionov wrote:
>>>>
>>> >>>
>
>> However I assumed that this is a bug and that I can find older version
>>>> which worked fine. I started testing from 3.1.x all the way to 3.5.26 and
>>>> this is what I found:
>>>> * All versions until 3.5.21 work fine. There no issues with huge amount
>>>> of TIME_WAIT connections under load.
>>>> * 3.5.20 is the latest stable version.
>>>> * 3.5.21 is the first broken version.
>>>> * 3.5.23, 3.5.25, 3.5.26 are broken as well.
>>>> This effectively means that bug is somewhere in between 3.5.20 and
>>>> 3.5.21.
>>>> I hope this helps and I hope you'll be able to find an issue. If you
>>>> can create a bug report based on this information and post it here it would
>>>> be awesome.
>>>>
>>>
>>> The changes in 3.5.21 were fixes to some common crashes and better
>>> caching behaviour. So I expect at least some of the change is due to higher
>>> traffic throughput on proxies previously restricted by those problems.
>>>
>>>
>> I can't imagine how throughput increase could result in 500 times more
>> TIME_WAIT connections count.
>>
>>
> More requests per second generally means more TCP connections churning.
>
> Also when going from Squid-2 to Squid-3 there is a change from HTTP/1.0 to
> HTTP/1.1 and the accompanying switch from MISS to near-HIT revalidations.
> Revalidations usually only have headers without payload so the same
> bytes/sec can contain orders more magnitude of those than MISS - which is
> the point of having them.
>
>
> In our prod environment when we updated from 2.7.x to 3.5.25 we saw
>> increase from 100 to 10000. This is 100x.
>>
>>
> Compared to what RPS change? Given the above traffic change this may be
> reasonable for a v2 to v3 jump. Or own very rough tests on old hardware lab
> tests have shown rates for Squid-2 at ~900 RPS and Squid-3 at around 1900
> RPS.
>
>
> When I was load testing different versions yesterday I was always sending
>> the same amount of RPS to them. Update from 3.5.20 to 3.5.21 resulted in
>> jump from 20 to 10000 TIME_WAIT count. This is 500x.
>>
>> I know that time_wait is fine in general. Until you have too many of them.
>>
>>
> At this point I'd check that your testing software supports HTTP/1.1
> pipelines. It may be giving you worst-case results with per-message TCP
> churn rather than what will occur normally (pipelines of N requests per TCP
> connection).
> Though seeing such a jump between Squid-3 releases is worrying.
>
> Amos
>



-- 
With best regards, Ivan Larionov.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170708/32dfc8a6/attachment.htm>

From eliezer at ngtech.co.il  Sat Jul  8 21:47:41 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 9 Jul 2017 00:47:41 +0300
Subject: [squid-users] YouTube Videos rating lists
Message-ID: <02ab01d2f833$d2f5cb70$78e16250$@ngtech.co.il>

Hey All,

I have been working for quite some time on a basic YouTube videos filtering
integration into SquidBlocker.
I have a video and images analysis and categorizing system that I can use to
rate the videos and the images but I am lacking one thing:
YouTube URLS feeds.

I have a running server that is dedicated to receive youtube videos urls for
analysis and then que them for testing.
For this to work I added a feature for the an external_acl helper I wrote
which is called a "feeder" mode which first answers the request with and ERR
and in the background sends the url to the remote system.
The end result would be a publically available rating lists which will be
categorized in a similar way to what Netflix rate ie:
https://help.netflix.com/en/node/2064

ie:
Movies and TV:
Little Kids 	Older Kids 	Teens 	Adults
All 		     7+	    	  13+	16+

I found that Netflix sometimes misses the exact match and adults content
being treated for "7+" I hope that I will not have this issue.
At the first step I will have the API set and the helper released with it's
sources.
When these will be ready I hope to start analyzing and categorizing youtube
videos for white and black listing.
After I will have a base line of black and white lists I will move on to a
weight based categorizing which will also return the matching age which the
video is allow to be watched by.

I need some help from anyone who is willing to send only specific url
patterns and leave the analysis and categorizing to the automated system.

Thanks In Advance,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il





From marcus.kool at urlfilterdb.com  Sat Jul  8 22:24:40 2017
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Sat, 8 Jul 2017 19:24:40 -0300
Subject: [squid-users] YouTube Videos rating lists
In-Reply-To: <02ab01d2f833$d2f5cb70$78e16250$@ngtech.co.il>
References: <02ab01d2f833$d2f5cb70$78e16250$@ngtech.co.il>
Message-ID: <b0fbf4ab-c54c-b779-8a78-2079db1d201b@urlfilterdb.com>

Hi Eliezer,
what is the analyzer looking at?
Does it detect gambling and support other languages than English ?
Thanks
Marcus

On 08/07/17 18:47, Eliezer Croitoru wrote:
> Hey All,
> 
> I have been working for quite some time on a basic YouTube videos filtering
> integration into SquidBlocker.
> I have a video and images analysis and categorizing system that I can use to
> rate the videos and the images but I am lacking one thing:
> YouTube URLS feeds.
> 
> I have a running server that is dedicated to receive youtube videos urls for
> analysis and then que them for testing.
> For this to work I added a feature for the an external_acl helper I wrote
> which is called a "feeder" mode which first answers the request with and ERR
> and in the background sends the url to the remote system.
> The end result would be a publically available rating lists which will be
> categorized in a similar way to what Netflix rate ie:
> https://help.netflix.com/en/node/2064
> 
> ie:
> Movies and TV:
> Little Kids 	Older Kids 	Teens 	Adults
> All 		     7+	    	  13+	16+
> 
> I found that Netflix sometimes misses the exact match and adults content
> being treated for "7+" I hope that I will not have this issue.
> At the first step I will have the API set and the helper released with it's
> sources.
> When these will be ready I hope to start analyzing and categorizing youtube
> videos for white and black listing.
> After I will have a base line of black and white lists I will move on to a
> weight based categorizing which will also return the matching age which the
> video is allow to be watched by.
> 
> I need some help from anyone who is willing to send only specific url
> patterns and leave the analysis and categorizing to the automated system.
> 
> Thanks In Advance,
> Eliezer
> 
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 


From eliezer at ngtech.co.il  Sat Jul  8 22:59:28 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 9 Jul 2017 01:59:28 +0300
Subject: [squid-users] YouTube Videos rating lists
In-Reply-To: <b0fbf4ab-c54c-b779-8a78-2079db1d201b@urlfilterdb.com>
References: <02ab01d2f833$d2f5cb70$78e16250$@ngtech.co.il>
 <b0fbf4ab-c54c-b779-8a78-2079db1d201b@urlfilterdb.com>
Message-ID: <02c101d2f83d$da13a620$8e3af260$@ngtech.co.il>

Hey Marcus,

The analyzer is a full blown video and image analysis system of a company I work with(lots of GPUs and CPUs..).
I do not know the exact details about gambling since their product was designed to lookup mainly for pornography but I have seen that they can identify gambling in more then one case.
>From my point of view this system is a black box which I throw videos at and it spits a response which can be one of couple.
I don't care if they have couple monkeys clicking the mouse or a keyboard doing this job.

And I will add the source code and initialization scripts repository at:
http://gogs.ngtech.co.il/elicro/squid-external-acl-by-url.git

I have tested it to work with CentOS, Ubuntu, Debian and couple others.
The initialization script was written for amd64 binaries but can be changed accordingly to any of the offered binaries.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Marcus Kool
Sent: Sunday, July 9, 2017 01:25
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] YouTube Videos rating lists

Hi Eliezer,
what is the analyzer looking at?
Does it detect gambling and support other languages than English ?
Thanks
Marcus

On 08/07/17 18:47, Eliezer Croitoru wrote:
> Hey All,
> 
> I have been working for quite some time on a basic YouTube videos filtering
> integration into SquidBlocker.
> I have a video and images analysis and categorizing system that I can use to
> rate the videos and the images but I am lacking one thing:
> YouTube URLS feeds.
> 
> I have a running server that is dedicated to receive youtube videos urls for
> analysis and then que them for testing.
> For this to work I added a feature for the an external_acl helper I wrote
> which is called a "feeder" mode which first answers the request with and ERR
> and in the background sends the url to the remote system.
> The end result would be a publically available rating lists which will be
> categorized in a similar way to what Netflix rate ie:
> https://help.netflix.com/en/node/2064
> 
> ie:
> Movies and TV:
> Little Kids 	Older Kids 	Teens 	Adults
> All 		     7+	    	  13+	16+
> 
> I found that Netflix sometimes misses the exact match and adults content
> being treated for "7+" I hope that I will not have this issue.
> At the first step I will have the API set and the helper released with it's
> sources.
> When these will be ready I hope to start analyzing and categorizing youtube
> videos for white and black listing.
> After I will have a base line of black and white lists I will move on to a
> weight based categorizing which will also return the matching age which the
> video is allow to be watched by.
> 
> I need some help from anyone who is willing to send only specific url
> patterns and leave the analysis and categorizing to the automated system.
> 
> Thanks In Advance,
> Eliezer
> 
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
> 
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Fri Jul  7 12:35:37 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 8 Jul 2017 00:35:37 +1200
Subject: [squid-users] [squid-announce] Squid 4.0.21 beta is available
Message-ID: <aa547311-e974-0320-871d-232cc8b3a629@treenet.co.nz>

The Squid HTTP Proxy team is very pleased to announce the availability
of the Squid-4.0.21 release!


This release is a bug fix release resolving several issues found in the
prior Squid releases.


The major changes to be aware of:

* Regression Bug 4492: Chunk extension parser is too pedantic

With this fix Squid is back to ignoring some unusual message whitespace 
padding that senders should not have been doing, but which are generally 
harmless to the protocol. It is a regression specific to the Squid-4 
release series, not affecting any other installations.


* Bug 1961 partial: Redesign urlParse API

The core changes for redesign work is largely finished now. As a result 
this release should have much lower memory use on url_rewrite API 
lookups which choose not to rewrite the URL.


* Collapse security_file_certgen requests

This helper API now collapses identical parallel lookups into a single 
helper message to reduce load, latency and as a result reduce pressure 
on the system crypto services. It still has some issues, but should now 
cope a lot better with sudden load peaks as seen from Browsers starting up.


* SSL-Bump: tproxy does not spoof spliced connections

This release now performs TPROXY spoofing properly when SSL-Bump logic 
selects splice action. Prior SSL-Bump would behave as if NAT intercept 
was being used, by replacing the sender IP as Squid one.


* Add a basic apparmour profile

This release bundles a basic apparmour profile contributed by Ubuntu 
developers. As with init system scripts this profile is not installed by 
default, packagers wishing to use it should pull the file from the 
sources during packaging.


Several major bug fixes shared with the future Squid-3.5.27 release are 
also worth mentioning:

* Bug 4464: Reduce "!Comm::MonitorsRead(serverConnection->fd)" assertions.

In Squid-3 this bug appeared as "fd_table[conn->fd].halfClosedReader != 
NULL" assertions.

Admin who have used the various config workarounds or patches to 
suppress those assertions will need to re-asses those temporary measures 
after upgrading to this release.


* Bug 2833: collapsed forwarding doesn't work with NOT MODIFIED response

The security fix for CVE-2016-10003 had a negative effect on collapsed 
forwarding. All "private" entries were considered automatically 
non-shareable among collapsed clients. However this is not true: there 
are many situations when collapsed forwarding should work despite of 
"private" (non-cacheable) entry status: 304/5xx responses are good 
examples of that.

This release adds a mechanism to mark some non-cached responses as being 
able to share with collapsed forwarding.

These changes also involved fixing incorrect delivery of 304 responses 
to a client when Squid was the agent performing revalidation instead of 
the client.


* Bug 4112: ssl_engine does not accept cryptodev

This directive has been broken for quite a long time, failing to 
recognize any of the default OpenSSL engines. This release restores 
support for the OpenSSL engines feature.


* Fix SMP query handoff to Coordinator.

Several issues related to SMP messages to the coordinator process have 
been fixed. Some of these are likely to have been resulting in hung 
connections for SNMP and mgr transactions. Others were resulting in 
garbage messages arriving at the coordinator.



  All users of Squid-4.x are encouraged to upgrade to this release as
soon as possible.

  All users of Squid-3 are encouraged to test this release out and plan
for upgrades where possible.


  See the ChangeLog for the full list of changes in this and earlier
  releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

  http://www.squid-cache.org/Versions/v4/
  ftp://ftp.squid-cache.org/pub/squid/
  ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

  http://www.squid-cache.org/Download/http-mirrors.html
  http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce

From bugreporter2017 at gmail.com  Sun Jul  9 16:59:00 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Sun, 9 Jul 2017 09:59:00 -0700 (PDT)
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
Message-ID: <1499619540869-4683033.post@n4.nabble.com>

Hi,

Is it allowed (supported) to chain icap and ecap services (using
/adaptation_service_chain/)? I get a "FATAL: Received Segment
Violation...dying." when trying to do it with some websites (www.linguee.com
for instance). Each of those services works very well separately.

Maybe this has never been tested before and I'm on a wrong way... But if (in
theory) it's supported can someone help me to build the right squid
configuration? I'll give more details on my configuration if the answer to
the above question is YES.

In a few words I'm trying to chain *c_icap/clamav* with  *squid-ecap-gzip*.
Below my configuration:





-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Sun Jul  9 17:28:23 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 9 Jul 2017 20:28:23 +0300
Subject: [squid-users] Squid 4.0.21 beta RPM's are out.
Message-ID: <03d601d2f8d8$c43a5fb0$4caf1f10$@ngtech.co.il>

Squid 4.0.21 beta RPM's are out for:
CentOS 7, Oracle Enterprise Linux 7, SLES 12SP1

http://ngtech.co.il/repo/centos/7/beta/
http://ngtech.co.il/repo/oracle/7/beta/
http://ngtech.co.il/repo/sles/12sp1/beta/

With hope that it will help to move faster from beta to stable.

All The Bests,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Friday, July 7, 2017 15:36
To: squid-announce at lists.squid-cache.org
Subject: [squid-users] [squid-announce] Squid 4.0.21 beta is available

The Squid HTTP Proxy team is very pleased to announce the availability of the Squid-4.0.21 release!


This release is a bug fix release resolving several issues found in the prior Squid releases.


The major changes to be aware of:

* Regression Bug 4492: Chunk extension parser is too pedantic

With this fix Squid is back to ignoring some unusual message whitespace padding that senders should not have been doing, but which are generally harmless to the protocol. It is a regression specific to the Squid-4 release series, not affecting any other installations.


* Bug 1961 partial: Redesign urlParse API

The core changes for redesign work is largely finished now. As a result this release should have much lower memory use on url_rewrite API lookups which choose not to rewrite the URL.


* Collapse security_file_certgen requests

This helper API now collapses identical parallel lookups into a single helper message to reduce load, latency and as a result reduce pressure on the system crypto services. It still has some issues, but should now cope a lot better with sudden load peaks as seen from Browsers starting up.


* SSL-Bump: tproxy does not spoof spliced connections

This release now performs TPROXY spoofing properly when SSL-Bump logic selects splice action. Prior SSL-Bump would behave as if NAT intercept was being used, by replacing the sender IP as Squid one.


* Add a basic apparmour profile

This release bundles a basic apparmour profile contributed by Ubuntu developers. As with init system scripts this profile is not installed by default, packagers wishing to use it should pull the file from the sources during packaging.


Several major bug fixes shared with the future Squid-3.5.27 release are also worth mentioning:

* Bug 4464: Reduce "!Comm::MonitorsRead(serverConnection->fd)" assertions.

In Squid-3 this bug appeared as "fd_table[conn->fd].halfClosedReader != NULL" assertions.

Admin who have used the various config workarounds or patches to suppress those assertions will need to re-asses those temporary measures after upgrading to this release.


* Bug 2833: collapsed forwarding doesn't work with NOT MODIFIED response

The security fix for CVE-2016-10003 had a negative effect on collapsed forwarding. All "private" entries were considered automatically non-shareable among collapsed clients. However this is not true: there are many situations when collapsed forwarding should work despite of "private" (non-cacheable) entry status: 304/5xx responses are good examples of that.

This release adds a mechanism to mark some non-cached responses as being able to share with collapsed forwarding.

These changes also involved fixing incorrect delivery of 304 responses to a client when Squid was the agent performing revalidation instead of the client.


* Bug 4112: ssl_engine does not accept cryptodev

This directive has been broken for quite a long time, failing to recognize any of the default OpenSSL engines. This release restores support for the OpenSSL engines feature.


* Fix SMP query handoff to Coordinator.

Several issues related to SMP messages to the coordinator process have been fixed. Some of these are likely to have been resulting in hung connections for SNMP and mgr transactions. Others were resulting in garbage messages arriving at the coordinator.



  All users of Squid-4.x are encouraged to upgrade to this release as soon as possible.

  All users of Squid-3 are encouraged to test this release out and plan for upgrades where possible.


  See the ChangeLog for the full list of changes in this and earlier
  releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

  http://www.squid-cache.org/Versions/v4/
  ftp://ftp.squid-cache.org/pub/squid/
  ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

  http://www.squid-cache.org/Download/http-mirrors.html
  http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Sun Jul  9 17:44:21 2017
From: yvoinov at gmail.com (Yuri)
Date: Sun, 9 Jul 2017 23:44:21 +0600
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <1499619540869-4683033.post@n4.nabble.com>
References: <1499619540869-4683033.post@n4.nabble.com>
Message-ID: <503494af-d2e4-db06-91fc-c5efa039d35e@gmail.com>

Details. Squid's version, OS version, compiler version, core dump contents.


09.07.2017 22:59, bugreporter ?????:
> Hi,
>
> Is it allowed (supported) to chain icap and ecap services (using
> /adaptation_service_chain/)? I get a "FATAL: Received Segment
> Violation...dying." when trying to do it with some websites (www.linguee.com
> for instance). Each of those services works very well separately.
>
> Maybe this has never been tested before and I'm on a wrong way... But if (in
> theory) it's supported can someone help me to build the right squid
> configuration? I'll give more details on my configuration if the answer to
> the above question is YES.
>
> In a few words I'm trying to chain *c_icap/clamav* with  *squid-ecap-gzip*.
> Below my configuration:
>
>
>
>
>
> -----
> Bug Reporter Contributor
> OpenSource = Open-Minded
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170709/1b81711d/attachment.sig>

From bugreporter2017 at gmail.com  Sun Jul  9 18:54:41 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Sun, 9 Jul 2017 11:54:41 -0700 (PDT)
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <503494af-d2e4-db06-91fc-c5efa039d35e@gmail.com>
References: <1499619540869-4683033.post@n4.nabble.com>
 <503494af-d2e4-db06-91fc-c5efa039d35e@gmail.com>
Message-ID: <1499626481926-4683036.post@n4.nabble.com>

Thank you for your prompt response Yuri. Below information that you have
requested:

- Squid 3.5.26
- Linux kernel 3.10.100 on an LFS (Linux From Scratch)
- gcc-4.8.1, glibc-2.18

Don't yet have a core dump. Are you interested in having the log file in
debug mode?
Cheers



-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033p4683036.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sun Jul  9 19:17:09 2017
From: yvoinov at gmail.com (Yuri)
Date: Mon, 10 Jul 2017 01:17:09 +0600
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <1499626481926-4683036.post@n4.nabble.com>
References: <1499619540869-4683033.post@n4.nabble.com>
 <503494af-d2e4-db06-91fc-c5efa039d35e@gmail.com>
 <1499626481926-4683036.post@n4.nabble.com>
Message-ID: <76956f64-240f-ebbb-a02b-a8331e4571c0@gmail.com>



10.07.2017 0:54, bugreporter ?????:
> Thank you for your prompt response Yuri. Below information that you have
> requested:
>
> - Squid 3.5.26
> - Linux kernel 3.10.100 on an LFS (Linux From Scratch)
> - gcc-4.8.1, glibc-2.18
>
> Don't yet have a core dump. Are you interested in having the log file in
> debug mode?
In addition to core backtrace - yes.

 Set up your OS for save process cores, I guess this fatal produce
squid's core. Better to build squid's first with debug symbols (-g
compiler option) and backtrace resulting core with debugger.
> Cheers
I suggest old adaptation subsystem bug (still opened), which is not
reproduces in 4.x/5.x squid's.  But to make sure it is require to take a
look on core.
>
>
>
> -----
> Bug Reporter Contributor
> OpenSource = Open-Minded
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033p4683036.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170710/b83cab55/attachment.sig>

From yvoinov at gmail.com  Sun Jul  9 21:54:56 2017
From: yvoinov at gmail.com (Yuri)
Date: Mon, 10 Jul 2017 03:54:56 +0600
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <1499626481926-4683036.post@n4.nabble.com>
References: <1499619540869-4683033.post@n4.nabble.com>
 <503494af-d2e4-db06-91fc-c5efa039d35e@gmail.com>
 <1499626481926-4683036.post@n4.nabble.com>
Message-ID: <ba01d93c-d8d5-30b4-26c7-6145cdda6c77@gmail.com>

Also it can be issue with ecap-gzip adapter itself. AFAIK it has opened
issue with segfault on some sites.

Public version has not close this bug because of author abandoned project.


10.07.2017 0:54, bugreporter ?????:
> Thank you for your prompt response Yuri. Below information that you have
> requested:
>
> - Squid 3.5.26
> - Linux kernel 3.10.100 on an LFS (Linux From Scratch)
> - gcc-4.8.1, glibc-2.18
>
> Don't yet have a core dump. Are you interested in having the log file in
> debug mode?
> Cheers
>
>
>
> -----
> Bug Reporter Contributor
> OpenSource = Open-Minded
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033p4683036.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170710/e8506073/attachment.sig>

From bugreporter2017 at gmail.com  Sun Jul  9 22:22:45 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Sun, 9 Jul 2017 15:22:45 -0700 (PDT)
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <ba01d93c-d8d5-30b4-26c7-6145cdda6c77@gmail.com>
References: <1499619540869-4683033.post@n4.nabble.com>
 <503494af-d2e4-db06-91fc-c5efa039d35e@gmail.com>
 <1499626481926-4683036.post@n4.nabble.com>
 <ba01d93c-d8d5-30b4-26c7-6145cdda6c77@gmail.com>
Message-ID: <1499638965067-4683039.post@n4.nabble.com>

Yes I had some issue with ecap-gzip (related to chunked content) that I have
already resolved by bypassing chunked content (I modified the code). Now I
have no issue with ecap-gzip when it's used alone (without being in a
chain).

Herewith the log file (debug_options ALL,3):
squid.gz
<http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4683039/squid.gz>  



-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033p4683039.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From bugreporter2017 at gmail.com  Sun Jul  9 22:29:42 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Sun, 9 Jul 2017 15:29:42 -0700 (PDT)
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <ba01d93c-d8d5-30b4-26c7-6145cdda6c77@gmail.com>
References: <1499619540869-4683033.post@n4.nabble.com>
 <503494af-d2e4-db06-91fc-c5efa039d35e@gmail.com>
 <1499626481926-4683036.post@n4.nabble.com>
 <ba01d93c-d8d5-30b4-26c7-6145cdda6c77@gmail.com>
Message-ID: <1499639382856-4683040.post@n4.nabble.com>

And the gd backtrace:



Warm Regards,





-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033p4683040.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Sun Jul  9 22:58:10 2017
From: yvoinov at gmail.com (Yuri)
Date: Mon, 10 Jul 2017 04:58:10 +0600
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <1499638965067-4683039.post@n4.nabble.com>
References: <1499619540869-4683033.post@n4.nabble.com>
 <503494af-d2e4-db06-91fc-c5efa039d35e@gmail.com>
 <1499626481926-4683036.post@n4.nabble.com>
 <ba01d93c-d8d5-30b4-26c7-6145cdda6c77@gmail.com>
 <1499638965067-4683039.post@n4.nabble.com>
Message-ID: <1ed45ea6-376c-105c-d808-94d7af9c75d0@gmail.com>

Hmmmm. Bases on this log, issue occurs in ICAP processing.

Most close to this:

http://bugs.squid-cache.org/show_bug.cgi?id=4597

As I can remember, this bug occurs on ECAP, not with ICAP. Configuration
was like you, chained ecap+icap services. Sadly, I can't show patch for
3.5, especially it was platform-specific dirty hack ;)

Can you try to reproduce this on 4.0.x Squid? This time I have not 3.5.x
running servers.

AFAIK, this issue was not occurs neither on 4.x nor on 5.x Squid's.


10.07.2017 4:22, bugreporter ?????:
> Yes I had some issue with ecap-gzip (related to chunked content) that I have
> already resolved by bypassing chunked content (I modified the code). Now I
> have no issue with ecap-gzip when it's used alone (without being in a
> chain).
>
> Herewith the log file (debug_options ALL,3):
> squid.gz
> <http://squid-web-proxy-cache.1019090.n4.nabble.com/file/n4683039/squid.gz>  
>
>
>
> -----
> Bug Reporter Contributor
> OpenSource = Open-Minded
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033p4683039.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170710/43261365/attachment.sig>

From bugreporter2017 at gmail.com  Mon Jul 10 07:45:47 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Mon, 10 Jul 2017 00:45:47 -0700 (PDT)
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <1ed45ea6-376c-105c-d808-94d7af9c75d0@gmail.com>
References: <1499619540869-4683033.post@n4.nabble.com>
 <503494af-d2e4-db06-91fc-c5efa039d35e@gmail.com>
 <1499626481926-4683036.post@n4.nabble.com>
 <ba01d93c-d8d5-30b4-26c7-6145cdda6c77@gmail.com>
 <1499638965067-4683039.post@n4.nabble.com>
 <1ed45ea6-376c-105c-d808-94d7af9c75d0@gmail.com>
Message-ID: <1499672747720-4683042.post@n4.nabble.com>

Hi Yuri
,
Below the gdb backtrace. I hope that it could help you resolving the issue.

Regarding Squid-4.0 my understanding is that it is a beta version while I
need a stable version. Actually at this stage upgrading to 4.0  would
represent a lot of integration, testing and validation work. Therefore,
either I abandon the idea to have ecap and icap at the same time or the bug
can be fixed (or at least we can find a workaround).

8<-----------------------------------------------------------------------------------------------------------------------------------------
GNU gdb (GDB) 7.5
Copyright (C) 2012 Free Software Foundation, Inc.
License GPLv3+: GNU GPL version 3 or later
<http://gnu.org/licenses/gpl.html>
This is free software: you are free to change and redistribute it.
There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
and "show warranty" for details.
This GDB was configured as "x86_64-unknown-linux-gnu".
For bug reporting instructions, please see:
<http://www.gnu.org/software/gdb/bugs/>...
Reading symbols from /sbin/squid...done.
[New LWP 4452]

warning: Could not load shared library symbols for linux-vdso.so.1.
Do you need "set solib-search-path" or "set sysroot"?
[Thread debugging using libthread_db enabled]
Using host libthread_db library "/lib/libthread_db.so.1".
Core was generated by `(squid-1) -f /etc/squid.conf'.
Program terminated with signal 6, Aborted.
#0  0x00007fc47fa6a3a9 in raise () from /lib/libc.so.6
(gdb) bt full
#0  0x00007fc47fa6a3a9 in raise () from /lib/libc.so.6
No symbol table info available.
#1  0x00007fc47fa6b7a8 in abort () from /lib/libc.so.6
No symbol table info available.
#2  0x000000000066186e in death (sig=<optimized out>) at tools.cc:356
No locals.
#3  <signal handler called>
No symbol table info available.
#4  0x00007fc45cfc8bb0 in Adapter::Xaction::noteVbContentDone
(this=0x25c8cb0, atEnd=<optimized out>) at adapter_gzip.cc:533
No locals.
#5  0x00000000007eff28 in
Adaptation::Ecap::XactionRep::noteBodyProductionEnded (this=0x25bd928,
bp=...) at XactionRep.cc:657
No locals.
#6  0x000000000057332d in UnaryMemFunT<BodyConsumer, RefCount&lt;BodyPipe>,
RefCount<BodyPipe> >::doDial (this=0x261c880) at base/AsyncJobCalls.h:121
No locals.
#7  0x00000000005737f9 in JobDialer<BodyConsumer>::dial (this=0x261c880,
call=...) at base/AsyncJobCalls.h:174
        __FUNCTION__ = "dial"
#8  0x00000000006e45a7 in AsyncCall::make (this=0x261c850) at
AsyncCall.cc:40
        __FUNCTION__ = "make"
#9  0x00000000006e8722 in AsyncCallQueue::fireNext
(this=this at entry=0x1d94e20) at AsyncCallQueue.cc:56
        call = {p_ = 0x261c850}
        __FUNCTION__ = "fireNext"
#10 0x00000000006e8b60 in AsyncCallQueue::fire (this=0x1d94e20) at
AsyncCallQueue.cc:42
        made = true
#11 0x000000000058b109 in dispatchCalls (this=0x7ffd7f0c0e20) at
EventLoop.cc:143
        dispatchedSome = <optimized out>
#12 EventLoop::runOnce (this=this at entry=0x7ffd7f0c0e20) at EventLoop.cc:120
        sawActivity = <optimized out>
        waitingEngine = 0x7ffd7f0c0db0
#13 0x000000000058b1f0 in EventLoop::run (this=0x7ffd7f0c0e20) at
EventLoop.cc:82
No locals.
#14 0x00000000005ee425 in SquidMain (argc=<optimized out>, argv=<optimized
out>) at main.cc:1541
        __FUNCTION__ = "SquidMain"
        signalEngine = {<AsyncEngine> = {_vptr.AsyncEngine = 0x8829d0
<vtable for SignalEngine+16>}, <No data fields>}
        store_engine = {<AsyncEngine> = {_vptr.AsyncEngine = 0x882990
<vtable for StoreRootEngine+16>}, <No data fields>}
        comm_engine = {<AsyncEngine> = {_vptr.AsyncEngine = 0xb68ab0 <vtable
for CommSelectEngine+16>}, <No data fields>}
        mainLoop = {errcount = 0, static Running = 0x7ffd7f0c0e20, last_loop
= false, engines = {<std::_Vector_base&lt;AsyncEngine*,
std::allocator&lt;AsyncEngine*> >> = {
              _M_impl = {<std::allocator&lt;AsyncEngine*>> =
{<__gnu_cxx::new_allocator<AsyncEngine*>> = {<No data fields>}, <No data
fields>}, _M_start = 0x2202150, _M_finish = 0x2202170, 
                _M_end_of_storage = 0x2202170}}, <No data fields>},
timeService = 0x7ffd7f0c0dc0, primaryEngine = 0x7ffd7f0c0db0, loop_delay =
0, error = false, runOnceResult = false}
        time_engine = {_vptr.TimeEngine = 0x892550 <vtable for
TimeEngine+16>}
#15 0x00000000005082cb in SquidMainSafe (argv=<optimized out>,
argc=<optimized out>) at main.cc:1265
No locals.
#16 main (argc=<optimized out>, argv=<optimized out>) at main.cc:1258
No locals.
(gdb)                                                                                                                                                                                                                                                                                                                                                                                                                                   
8<-----------------------------------------------------------------------------------------------------------------------------------------

Warm Regards, 




-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033p4683042.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From dvl at 2scale.net  Mon Jul 10 12:58:09 2017
From: dvl at 2scale.net (Dirk Vleugels)
Date: Mon, 10 Jul 2017 14:58:09 +0200
Subject: [squid-users] tcp_outgoing_mark via runtime lookup
Message-ID: <25BB732F-D07E-4390-9C26-89C8ED1970AD@2scale.net>

Hello,

we?re looking for a way to set tcp_outgoing_mark based on runtime information - e.g. via external_acl_helper. 

Currently, we use a static mapping (requests coming in via personalized IPSec tunnel):

acl ten_zero   src 10.0.0.0/16

tcp_outgoing_mark 0x0a ten_zero

to route outgoing traffic to the destination tunnel. In the future we?ll have to obtain the ?configured? source-ip for a customer from a 3rd party service (rest interface most likely).

Is this feasible at all?

Regards,
Dirk 



From yvoinov at gmail.com  Mon Jul 10 13:50:33 2017
From: yvoinov at gmail.com (Yuri)
Date: Mon, 10 Jul 2017 19:50:33 +0600
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <1499672747720-4683042.post@n4.nabble.com>
References: <1499619540869-4683033.post@n4.nabble.com>
 <503494af-d2e4-db06-91fc-c5efa039d35e@gmail.com>
 <1499626481926-4683036.post@n4.nabble.com>
 <ba01d93c-d8d5-30b4-26c7-6145cdda6c77@gmail.com>
 <1499638965067-4683039.post@n4.nabble.com>
 <1ed45ea6-376c-105c-d808-94d7af9c75d0@gmail.com>
 <1499672747720-4683042.post@n4.nabble.com>
Message-ID: <749fadf0-6b34-f1cc-9c1c-5f3c2304e3b4@gmail.com>

Yup, seems this is

http://bugs.squid-cache.org/show_bug.cgi?id=4597


10.07.2017 13:45, bugreporter ?????:
> Hi Yuri
> ,
> Below the gdb backtrace. I hope that it could help you resolving the issue.
>
> Regarding Squid-4.0 my understanding is that it is a beta version while I
> need a stable version. Actually at this stage upgrading to 4.0  would
> represent a lot of integration, testing and validation work. Therefore,
> either I abandon the idea to have ecap and icap at the same time or the bug
> can be fixed (or at least we can find a workaround).
>
> 8<-----------------------------------------------------------------------------------------------------------------------------------------
> GNU gdb (GDB) 7.5
> Copyright (C) 2012 Free Software Foundation, Inc.
> License GPLv3+: GNU GPL version 3 or later
> <http://gnu.org/licenses/gpl.html>
> This is free software: you are free to change and redistribute it.
> There is NO WARRANTY, to the extent permitted by law.  Type "show copying"
> and "show warranty" for details.
> This GDB was configured as "x86_64-unknown-linux-gnu".
> For bug reporting instructions, please see:
> <http://www.gnu.org/software/gdb/bugs/>...
> Reading symbols from /sbin/squid...done.
> [New LWP 4452]
>
> warning: Could not load shared library symbols for linux-vdso.so.1.
> Do you need "set solib-search-path" or "set sysroot"?
> [Thread debugging using libthread_db enabled]
> Using host libthread_db library "/lib/libthread_db.so.1".
> Core was generated by `(squid-1) -f /etc/squid.conf'.
> Program terminated with signal 6, Aborted.
> #0  0x00007fc47fa6a3a9 in raise () from /lib/libc.so.6
> (gdb) bt full
> #0  0x00007fc47fa6a3a9 in raise () from /lib/libc.so.6
> No symbol table info available.
> #1  0x00007fc47fa6b7a8 in abort () from /lib/libc.so.6
> No symbol table info available.
> #2  0x000000000066186e in death (sig=<optimized out>) at tools.cc:356
> No locals.
> #3  <signal handler called>
> No symbol table info available.
> #4  0x00007fc45cfc8bb0 in Adapter::Xaction::noteVbContentDone
> (this=0x25c8cb0, atEnd=<optimized out>) at adapter_gzip.cc:533
> No locals.
> #5  0x00000000007eff28 in
> Adaptation::Ecap::XactionRep::noteBodyProductionEnded (this=0x25bd928,
> bp=...) at XactionRep.cc:657
> No locals.
> #6  0x000000000057332d in UnaryMemFunT<BodyConsumer, RefCount&lt;BodyPipe>,
> RefCount<BodyPipe> >::doDial (this=0x261c880) at base/AsyncJobCalls.h:121
> No locals.
> #7  0x00000000005737f9 in JobDialer<BodyConsumer>::dial (this=0x261c880,
> call=...) at base/AsyncJobCalls.h:174
>          __FUNCTION__ = "dial"
> #8  0x00000000006e45a7 in AsyncCall::make (this=0x261c850) at
> AsyncCall.cc:40
>          __FUNCTION__ = "make"
> #9  0x00000000006e8722 in AsyncCallQueue::fireNext
> (this=this at entry=0x1d94e20) at AsyncCallQueue.cc:56
>          call = {p_ = 0x261c850}
>          __FUNCTION__ = "fireNext"
> #10 0x00000000006e8b60 in AsyncCallQueue::fire (this=0x1d94e20) at
> AsyncCallQueue.cc:42
>          made = true
> #11 0x000000000058b109 in dispatchCalls (this=0x7ffd7f0c0e20) at
> EventLoop.cc:143
>          dispatchedSome = <optimized out>
> #12 EventLoop::runOnce (this=this at entry=0x7ffd7f0c0e20) at EventLoop.cc:120
>          sawActivity = <optimized out>
>          waitingEngine = 0x7ffd7f0c0db0
> #13 0x000000000058b1f0 in EventLoop::run (this=0x7ffd7f0c0e20) at
> EventLoop.cc:82
> No locals.
> #14 0x00000000005ee425 in SquidMain (argc=<optimized out>, argv=<optimized
> out>) at main.cc:1541
>          __FUNCTION__ = "SquidMain"
>          signalEngine = {<AsyncEngine> = {_vptr.AsyncEngine = 0x8829d0
> <vtable for SignalEngine+16>}, <No data fields>}
>          store_engine = {<AsyncEngine> = {_vptr.AsyncEngine = 0x882990
> <vtable for StoreRootEngine+16>}, <No data fields>}
>          comm_engine = {<AsyncEngine> = {_vptr.AsyncEngine = 0xb68ab0 <vtable
> for CommSelectEngine+16>}, <No data fields>}
>          mainLoop = {errcount = 0, static Running = 0x7ffd7f0c0e20, last_loop
> = false, engines = {<std::_Vector_base&lt;AsyncEngine*,
> std::allocator&lt;AsyncEngine*> >> = {
>                _M_impl = {<std::allocator&lt;AsyncEngine*>> =
> {<__gnu_cxx::new_allocator<AsyncEngine*>> = {<No data fields>}, <No data
> fields>}, _M_start = 0x2202150, _M_finish = 0x2202170,
>                  _M_end_of_storage = 0x2202170}}, <No data fields>},
> timeService = 0x7ffd7f0c0dc0, primaryEngine = 0x7ffd7f0c0db0, loop_delay =
> 0, error = false, runOnceResult = false}
>          time_engine = {_vptr.TimeEngine = 0x892550 <vtable for
> TimeEngine+16>}
> #15 0x00000000005082cb in SquidMainSafe (argv=<optimized out>,
> argc=<optimized out>) at main.cc:1265
> No locals.
> #16 main (argc=<optimized out>, argv=<optimized out>) at main.cc:1258
> No locals.
> (gdb)
> 8<-----------------------------------------------------------------------------------------------------------------------------------------
>
> Warm Regards,
>
>
>
>
> -----
> Bug Reporter Contributor
> OpenSource = Open-Minded
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033p4683042.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users



From heiler.bemerguy at cinbesa.com.br  Mon Jul 10 14:12:12 2017
From: heiler.bemerguy at cinbesa.com.br (Heiler Bemerguy)
Date: Mon, 10 Jul 2017 11:12:12 -0300
Subject: [squid-users] /var/run/squid gone on every reboot?!
In-Reply-To: <201707071000.54889.Antony.Stone@squid.open.source.it>
References: <20170707062234.C1E233137@mailer.cinbesa.com.br>
 <201707071000.54889.Antony.Stone@squid.open.source.it>
Message-ID: <8562e1fc-2d89-6fac-9718-af82af97b326@cinbesa.com.br>

Debian 9

Squid Cache: Version 3.5.26
Service Name: squid
configure options:  '--enable-htcp' '--disable-maintainer-mode' 
'--disable-dependency-tracking' '--disable-wccp' '--disable-snmp' 
'--enable-inline' '--enable-async-io=32' '--enable-storeio=aufs,rock' 
'--enable-underscores' '--enable-removal-policies=lru,heap' 
'--enable-http-violations' '--disable-ident-lookups' 
'--with-large-files' '--enable-ssl' '--enable-ltdl-convenience' 
'--prefix=/usr' '--localstatedir=/var' '--libexecdir=/lib/squid' 
'--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' 
'--with-default-user=proxy' '--with-logdir=/var/log' 
'--with-pidfile=/var/run/squid.pid' '--with-filedescriptors=16384' 
'--with-aufs-threads=32' '--disable-translation' 'CFLAGS=-march=native 
-g -Ofast -pipe -Wformat -Werror=format-security -Wall' 
'CXXFLAGS=-march=native -g -Ofast -pipe -Wformat -Werror=format-security'

It has a squid.rc inside "init.d" borrowed from "tools/sysvinit", but 
even if we try to start it manually after rebooting, it gives a lot of 
mixed errors and won't work till someone re-creates /var/run/squid with 
proxy:proxy permission


-- 
Atenciosamente / Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751


Em 07/07/2017 05:00, Antony Stone escreveu:
> On Friday 07 July 2017 at 08:22:29, Heiler Bemerguy wrote:
>
>> 3.5. Everytime I must recreate this. What I'm missing?
> Hm, dunno.
>
> Give us a clue...
>
> What operating system are you running under, and how did you install squid?
>
> How does squid (try to) start at boot time?
>
>
>
> Antony.
>



From eliezer at ngtech.co.il  Mon Jul 10 14:25:13 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 10 Jul 2017 17:25:13 +0300
Subject: [squid-users] /var/run/squid gone on every reboot?!
In-Reply-To: <8562e1fc-2d89-6fac-9718-af82af97b326@cinbesa.com.br>
References: <20170707062234.C1E233137@mailer.cinbesa.com.br>
 <201707071000.54889.Antony.Stone@squid.open.source.it>
 <8562e1fc-2d89-6fac-9718-af82af97b326@cinbesa.com.br>
Message-ID: <063c01d2f988$5863ce10$092b6a30$@ngtech.co.il>

Have you tried to use the Debian 9 default squid and see if it acts the same?
If not you can use their sysv init script for your version.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Heiler Bemerguy
Sent: Monday, July 10, 2017 17:12
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] /var/run/squid gone on every reboot?!

Debian 9

Squid Cache: Version 3.5.26
Service Name: squid
configure options:  '--enable-htcp' '--disable-maintainer-mode' 
'--disable-dependency-tracking' '--disable-wccp' '--disable-snmp' 
'--enable-inline' '--enable-async-io=32' '--enable-storeio=aufs,rock' 
'--enable-underscores' '--enable-removal-policies=lru,heap' 
'--enable-http-violations' '--disable-ident-lookups' 
'--with-large-files' '--enable-ssl' '--enable-ltdl-convenience' 
'--prefix=/usr' '--localstatedir=/var' '--libexecdir=/lib/squid' 
'--srcdir=.' '--datadir=/usr/share/squid' '--sysconfdir=/etc/squid' 
'--with-default-user=proxy' '--with-logdir=/var/log' 
'--with-pidfile=/var/run/squid.pid' '--with-filedescriptors=16384' 
'--with-aufs-threads=32' '--disable-translation' 'CFLAGS=-march=native 
-g -Ofast -pipe -Wformat -Werror=format-security -Wall' 
'CXXFLAGS=-march=native -g -Ofast -pipe -Wformat -Werror=format-security'

It has a squid.rc inside "init.d" borrowed from "tools/sysvinit", but 
even if we try to start it manually after rebooting, it gives a lot of 
mixed errors and won't work till someone re-creates /var/run/squid with 
proxy:proxy permission


-- 
Atenciosamente / Best Regards,

Heiler Bemerguy
Network Manager - CINBESA
55 91 98151-4894/3184-1751


Em 07/07/2017 05:00, Antony Stone escreveu:
> On Friday 07 July 2017 at 08:22:29, Heiler Bemerguy wrote:
>
>> 3.5. Everytime I must recreate this. What I'm missing?
> Hm, dunno.
>
> Give us a clue...
>
> What operating system are you running under, and how did you install squid?
>
> How does squid (try to) start at boot time?
>
>
>
> Antony.
>

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From rousskov at measurement-factory.com  Mon Jul 10 14:50:27 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 10 Jul 2017 08:50:27 -0600
Subject: [squid-users] tcp_outgoing_mark via runtime lookup
In-Reply-To: <25BB732F-D07E-4390-9C26-89C8ED1970AD@2scale.net>
References: <25BB732F-D07E-4390-9C26-89C8ED1970AD@2scale.net>
Message-ID: <59ef21a6-27e6-1f61-7e27-1e7566f9fd0b@measurement-factory.com>

On 07/10/2017 06:58 AM, Dirk Vleugels wrote:

> we?re looking for a way to set tcp_outgoing_mark based on runtime information - e.g. via external_acl_helper. 

> Is this feasible at all?
Sure. Use an "external" ACL type to annotate the transaction, and use
transaction annotation(s) to select the right tcp_outgoing_mark via a
"note" ACL.

Alex.


From rousskov at measurement-factory.com  Mon Jul 10 17:23:59 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Mon, 10 Jul 2017 11:23:59 -0600
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <1499619540869-4683033.post@n4.nabble.com>
References: <1499619540869-4683033.post@n4.nabble.com>
Message-ID: <cb368bae-ebe8-9005-0c32-e21a52ab695b@measurement-factory.com>

On 07/09/2017 10:59 AM, bugreporter wrote:

> Is it allowed (supported) to chain icap and ecap services (using
> /adaptation_service_chain/)?

Yes, it is allowed and supported.


> I get a "FATAL: Received Segment
> Violation...dying." when trying to do it with some websites (www.linguee.com
> for instance). Each of those services works very well separately.

AFAICT, the bug is most likely in the eCAP adapter that you are using.
Yes, I understand that the same adapter seems to work OK in other
configurations. The Squid Project cannot help you with fixing that
unofficial adapter. Your options include finding somebody who can fix
the broken adapter, replacing that broken adapter with something better,
or not using the adapter at all.

The above conclusion is based on all the information you have provided
so far (thank you!). If you discover new information that points the
finger back at Squid, consider filing a Squid bug report with that new
information. I do not recommend using bug #4597 for your problem because
the stack traces look different, you are using rather than disabling
ICAP, and your are using Linux rather than Solaris.

Alex.


From harariboy at gmail.com  Mon Jul 10 19:25:15 2017
From: harariboy at gmail.com (avi_h)
Date: Mon, 10 Jul 2017 12:25:15 -0700 (PDT)
Subject: [squid-users] Does squid generates/adds additional HTTP headers?
Message-ID: <1499714715550-4683050.post@n4.nabble.com>

Hi,

Does squid generates/adds additional HTTP headers be default?
If so, are they being sent to the Web server or only to the client?

Thanks in advance,
Avi



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Does-squid-generates-adds-additional-HTTP-headers-tp4683050.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Mon Jul 10 22:23:54 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 11 Jul 2017 10:23:54 +1200
Subject: [squid-users] Does squid generates/adds additional HTTP headers?
In-Reply-To: <1499714715550-4683050.post@n4.nabble.com>
References: <1499714715550-4683050.post@n4.nabble.com>
Message-ID: <95f8cb8f-168b-1804-3501-091cc1333c02@treenet.co.nz>

On 11/07/17 07:25, avi_h wrote:
> Hi,
> 
> Does squid generates/adds additional HTTP headers be default?

Squid generates all outgoing message headers. They may or may not be 
based on (or identical in many cases) to the received message headers.

Why do you ask?


> If so, are they being sent to the Web server or only to the client?
> 

Yes. More specific depends on how you configured Squid, eg which 
features are being used.

Amos


From harariboy at gmail.com  Mon Jul 10 23:52:53 2017
From: harariboy at gmail.com (avi_h)
Date: Mon, 10 Jul 2017 16:52:53 -0700 (PDT)
Subject: [squid-users] Does squid generates/adds additional HTTP headers?
In-Reply-To: <95f8cb8f-168b-1804-3501-091cc1333c02@treenet.co.nz>
References: <1499714715550-4683050.post@n4.nabble.com>
 <95f8cb8f-168b-1804-3501-091cc1333c02@treenet.co.nz>
Message-ID: <1499730773838-4683052.post@n4.nabble.com>

Hi Amos,

Thanks for the prompt reply.
I'm trying to get squid to use the same headers as it received (to make it
more transparent) so I would like to understand how it works so I can figure
out how to configure it that way.
After looking up online I configured the following:

request_header_access Authorization allow all
request_header_access Proxy-Authorization allow all
request_header_access Cache-Control deny all
request_header_access Content-Length allow all
request_header_access Content-Type allow all
request_header_access Date allow all
request_header_access Host allow all
request_header_access If-Modified-Since allow all
request_header_access Pragma allow all
request_header_access Accept allow all
request_header_access Accept-Charset allow all
request_header_access Accept-Encoding allow all
request_header_access Accept-Language allow all
request_header_access Connection allow all
request_header_access All deny all

I also have the following configs in addition:

via off
forwarded_for delete

Is there any way to have squid generate the exact same headers as it
received?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Does-squid-generates-adds-additional-HTTP-headers-tp4683050p4683052.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Tue Jul 11 13:35:01 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 11 Jul 2017 06:35:01 -0700 (PDT)
Subject: [squid-users] Squid as gateway
In-Reply-To: <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
References: <1499444090379-4683022.post@n4.nabble.com>
 <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
Message-ID: <1499780101757-4683053.post@n4.nabble.com>

Hi, and thanks.
Maybe i dont explain well.
I just want this:

 WanRouter-------Squid---------switch------PC

I want to declare in "PC" IP, MASK, AND GATEWAY, instead of the WanRouter, i
want that PC have for gateway the ip of the Squid.

I do this by now.

sudo iptables -A PREROUTING -t nat -s 192.168.1.0/24 -p tcp --dport 80 -j
REDIRECT --to-port 3128

[root at squid ~]# iptables -L -n
Chain INPUT (policy ACCEPT)
target     prot opt source               destination         
ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:3128
ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:443
ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:80
ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0            state
RELATED,ESTABLISHED
ACCEPT     icmp --  0.0.0.0/0            0.0.0.0/0           
ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0           
ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            state NEW tcp
dpt:22
REJECT     all  --  0.0.0.0/0            0.0.0.0/0            reject-with
icmp-host-prohibited

Chain FORWARD (policy ACCEPT)
target     prot opt source               destination         
REJECT     all  --  0.0.0.0/0            0.0.0.0/0            reject-with
icmp-host-prohibited

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination         


 iptables -t nat --line-numbers -L
Chain PREROUTING (policy ACCEPT)
num  target     prot opt source               destination         
1    REDIRECT   tcp  --  192.168.1.0/24       anywhere             tcp
dpt:http redir ports 3128


And in squid.conf 
i have
http 192.168.1.35:3128 intercept

But... this is not working... so
Can anyone give me a hand?

Thanks to all.

 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-as-gateway-tp4683022p4683053.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Tue Jul 11 14:11:21 2017
From: yvoinov at gmail.com (Yuri)
Date: Tue, 11 Jul 2017 20:11:21 +0600
Subject: [squid-users] Squid as gateway
In-Reply-To: <1499780101757-4683053.post@n4.nabble.com>
References: <1499444090379-4683022.post@n4.nabble.com>
 <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
 <1499780101757-4683053.post@n4.nabble.com>
Message-ID: <53dbba46-eacc-53a4-276e-6ed57b568870@gmail.com>

Feel free to take a look inside wiki:

http://wiki.squid-cache.org/SquidFaq/InterceptionProxy

http://wiki.squid-cache.org/ConfigExamples/Intercept


11.07.2017 19:35, erdosain9 ?????:
> Hi, and thanks.
> Maybe i dont explain well.
> I just want this:
>
>  WanRouter-------Squid---------switch------PC
>
> I want to declare in "PC" IP, MASK, AND GATEWAY, instead of the WanRouter, i
> want that PC have for gateway the ip of the Squid.
>
> I do this by now.
>
> sudo iptables -A PREROUTING -t nat -s 192.168.1.0/24 -p tcp --dport 80 -j
> REDIRECT --to-port 3128
>
> [root at squid ~]# iptables -L -n
> Chain INPUT (policy ACCEPT)
> target     prot opt source               destination         
> ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:3128
> ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:443
> ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:80
> ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0            state
> RELATED,ESTABLISHED
> ACCEPT     icmp --  0.0.0.0/0            0.0.0.0/0           
> ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0           
> ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            state NEW tcp
> dpt:22
> REJECT     all  --  0.0.0.0/0            0.0.0.0/0            reject-with
> icmp-host-prohibited
>
> Chain FORWARD (policy ACCEPT)
> target     prot opt source               destination         
> REJECT     all  --  0.0.0.0/0            0.0.0.0/0            reject-with
> icmp-host-prohibited
>
> Chain OUTPUT (policy ACCEPT)
> target     prot opt source               destination         
>
>
>  iptables -t nat --line-numbers -L
> Chain PREROUTING (policy ACCEPT)
> num  target     prot opt source               destination         
> 1    REDIRECT   tcp  --  192.168.1.0/24       anywhere             tcp
> dpt:http redir ports 3128
>
>
> And in squid.conf 
> i have
> http 192.168.1.35:3128 intercept
>
> But... this is not working... so
> Can anyone give me a hand?
>
> Thanks to all.
>
>  
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-as-gateway-tp4683022p4683053.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170711/af0bc77b/attachment.sig>

From erdosain9 at gmail.com  Tue Jul 11 14:25:15 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 11 Jul 2017 07:25:15 -0700 (PDT)
Subject: [squid-users] WARNING: Disk space over limit
Message-ID: <1499783115167-4683055.post@n4.nabble.com>

Hi to all.
Im having this warning

2017/07/11 11:37:44 kid1| WARNING: Disk space over limit: 17241692.00 KB >
15360000 KB
2017/07/11 11:37:56 kid1| WARNING: Disk space over limit: 16800692.00 KB >
15360000 KB
2017/07/11 11:38:07 kid1| WARNING: Disk space over limit: 16466860.00 KB >
15360000 KB
2017/07/11 11:38:19 kid1| WARNING: Disk space over limit: 16152960.00 KB >
15360000 KB
2017/07/11 11:38:30 kid1| WARNING: Disk space over limit: 15905772.00 KB >
15360000 KB
2017/07/11 11:38:41 kid1| WARNING: Disk space over limit: 15664684.00 KB >
15360000 KB
2017/07/11 11:38:52 kid1| WARNING: Disk space over limit: 15499404.00 KB >
15360000 KB


Why is this happening?? why is over limit??

[root at squid ~]# df -h
S.ficheros              Tama?o Usados  Disp Uso% Montado en
/dev/mapper/centos-root    48G    17G   31G  36% /
devtmpfs                  1,9G      0  1,9G   0% /dev
tmpfs                     1,9G   2,1M  1,9G   1% /dev/shm
tmpfs                     1,9G   8,5M  1,9G   1% /run
tmpfs                     1,9G      0  1,9G   0% /sys/fs/cgroup
/dev/sda1                 497M   143M  355M  29% /boot
tmpfs                     380M      0  380M   0% /run/user/0

SQUID.CONF

cache_dir diskd /var/spool/squid 15000 16 256
cache_mem 1000 MB
maximum_object_size_in_memory 1 MB

cache_swap_low 90
cache_swap_high 95

Yes, it is over cache_dir... but why?? and how i correct this?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/WARNING-Disk-space-over-limit-tp4683055.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From erdosain9 at gmail.com  Tue Jul 11 15:26:32 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 11 Jul 2017 08:26:32 -0700 (PDT)
Subject: [squid-users] Squid as gateway
In-Reply-To: <53dbba46-eacc-53a4-276e-6ed57b568870@gmail.com>
References: <1499444090379-4683022.post@n4.nabble.com>
 <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
 <1499780101757-4683053.post@n4.nabble.com>
 <53dbba46-eacc-53a4-276e-6ed57b568870@gmail.com>
Message-ID: <1499786792585-4683056.post@n4.nabble.com>

Thanks
Yes, im looking the wiki and follow this
http://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxDnat

And, it is not working. Nothing it is going to squid.

I can go to internet because 

# Controls IP packet forwarding
net.ipv4.ip_forward = 1

but, nothing throug squid.

What can be? Another wiki???



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-as-gateway-tp4683022p4683056.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Tue Jul 11 15:47:45 2017
From: yvoinov at gmail.com (Yuri)
Date: Tue, 11 Jul 2017 21:47:45 +0600
Subject: [squid-users] Squid as gateway
In-Reply-To: <1499786792585-4683056.post@n4.nabble.com>
References: <1499444090379-4683022.post@n4.nabble.com>
 <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
 <1499780101757-4683053.post@n4.nabble.com>
 <53dbba46-eacc-53a4-276e-6ed57b568870@gmail.com>
 <1499786792585-4683056.post@n4.nabble.com>
Message-ID: <1efe582d-86ad-6387-f935-bbfe7f25e2c6@gmail.com>

Squid should be configured and built with interception support.

Re-read more carefully.

11.07.2017 21:26, erdosain9 ?????:
> Thanks
> Yes, im looking the wiki and follow this
> http://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxDnat
>
> And, it is not working. Nothing it is going to squid.
>
> I can go to internet because 
>
> # Controls IP packet forwarding
> net.ipv4.ip_forward = 1
>
> but, nothing throug squid.
>
> What can be? Another wiki???
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-as-gateway-tp4683022p4683056.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170711/aaf862e6/attachment.sig>

From erdosain9 at gmail.com  Tue Jul 11 15:40:41 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Tue, 11 Jul 2017 08:40:41 -0700 (PDT)
Subject: [squid-users] Squid as gateway
In-Reply-To: <1efe582d-86ad-6387-f935-bbfe7f25e2c6@gmail.com>
References: <1499444090379-4683022.post@n4.nabble.com>
 <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
 <1499780101757-4683053.post@n4.nabble.com>
 <53dbba46-eacc-53a4-276e-6ed57b568870@gmail.com>
 <1499786792585-4683056.post@n4.nabble.com>
 <1efe582d-86ad-6387-f935-bbfe7f25e2c6@gmail.com>
Message-ID: <1499787641981-4683058.post@n4.nabble.com>

Ok Yuri, im re re re reading....... :-)

And probe another configs, like this
http://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect

and nothing, i dont get where i fail.

Squid, it is config in interception mode.

cache.log

2017/07/11 14:15:43 kid1| Accepting HTTP Socket connections at
local=[::]:3128 remote=[::] FD 14 flags=9
2017/07/11 14:15:43 kid1| Accepting NAT intercepted HTTP Socket connections
at local=[::]:3129 remote=[::] FD 15 flags=41

So......................... yes, yes, i keep reading. 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-as-gateway-tp4683022p4683058.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Tue Jul 11 16:12:09 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 11 Jul 2017 10:12:09 -0600
Subject: [squid-users] Does squid generates/adds additional HTTP headers?
In-Reply-To: <1499730773838-4683052.post@n4.nabble.com>
References: <1499714715550-4683050.post@n4.nabble.com>
 <95f8cb8f-168b-1804-3501-091cc1333c02@treenet.co.nz>
 <1499730773838-4683052.post@n4.nabble.com>
Message-ID: <74f1a422-56f2-87c8-cc57-132f6d6c4855@measurement-factory.com>

On 07/10/2017 05:52 PM, avi_h wrote:

> I'm trying to get squid to use the same headers as it received (to make it
> more transparent) 

To improve your chances of arriving at a usable solution (or quickly
abandoning a futile search), I suggest detailing/narrowing your goal:
"Make it more transparent" to whom and in what way? What specific
problems are you trying to solve? For example:

* Do you want to configure Squid to become invisible to a knowledgeable
human observer?

* Do you want to configure Squid to make some server(s) think that the
request is coming directly from a user agent (e.g., browser)? What do
those servers use to detect proxies now?

Etc. etc. You probably know exactly what you need to achieve. Narrow it
down for us as much as possible.


> After looking up online I configured the following:
> 
> request_header_access Cache-Control deny all

Denying general-purpose headers makes no sense if you want Squid to
forward as many original headers as possible. Yes, Squid may generate
new Cache-Control headers but that does not mean that Squid does not
forward client Cache-Control headers as well. The task of preserving
original headers may feel trivial to you, but the actual complexity of
what you are asking is one of the reasons we need you to come up with a
narrower goal.


> Is there any way to have squid generate the exact same headers as it
> received?

No. However, you probably do not actually need that. You probably need
something else that Squid may be able to do (with or without code
modifications).

Alex.


From rafael.akchurin at diladele.com  Tue Jul 11 16:20:50 2017
From: rafael.akchurin at diladele.com (Rafael Akchurin)
Date: Tue, 11 Jul 2017 16:20:50 +0000
Subject: [squid-users] Squid as gateway
In-Reply-To: <1499787641981-4683058.post@n4.nabble.com>
References: <1499444090379-4683022.post@n4.nabble.com>
 <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
 <1499780101757-4683053.post@n4.nabble.com>
 <53dbba46-eacc-53a4-276e-6ed57b568870@gmail.com>
 <1499786792585-4683056.post@n4.nabble.com>
 <1efe582d-86ad-6387-f935-bbfe7f25e2c6@gmail.com>
 <1499787641981-4683058.post@n4.nabble.com>
Message-ID: <DB6PR0401MB268005878EFFB4A6858B90E88FAE0@DB6PR0401MB2680.eurprd04.prod.outlook.com>

May be this will be of any help - https://docs.diladele.com/tutorials/transparent_proxy_ubuntu/index.html


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Tuesday, July 11, 2017 5:41 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid as gateway

Ok Yuri, im re re re reading....... :-)

And probe another configs, like this
http://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect

and nothing, i dont get where i fail.

Squid, it is config in interception mode.

cache.log

2017/07/11 14:15:43 kid1| Accepting HTTP Socket connections at
local=[::]:3128 remote=[::] FD 14 flags=9
2017/07/11 14:15:43 kid1| Accepting NAT intercepted HTTP Socket connections at local=[::]:3129 remote=[::] FD 15 flags=41

So......................... yes, yes, i keep reading. 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-as-gateway-tp4683022p4683058.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From sonyaroy75 at gmail.com  Tue Jul 11 16:36:20 2017
From: sonyaroy75 at gmail.com (Sonya Roy)
Date: Tue, 11 Jul 2017 22:06:20 +0530
Subject: [squid-users] Does squid generates/adds additional HTTP headers?
Message-ID: <CALSaDe2dts+i++bc1p6mrnmwrdSBbsi9gTDFdLquDfjui5TZgw@mail.gmail.com>

As Alex mentioned its not possible to do with squid. I modified the squid
source code to do this a month ago. Its not hard to do, you will only need
to modify http.cc and client_side.cc a bit.

On Tue, Jul 11, 2017 at 9:42 PM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 07/10/2017 05:52 PM, avi_h wrote:
>
> > I'm trying to get squid to use the same headers as it received (to make
> it
> > more transparent)
>
> To improve your chances of arriving at a usable solution (or quickly
> abandoning a futile search), I suggest detailing/narrowing your goal:
> "Make it more transparent" to whom and in what way? What specific
> problems are you trying to solve? For example:
>
> * Do you want to configure Squid to become invisible to a knowledgeable
> human observer?
>
> * Do you want to configure Squid to make some server(s) think that the
> request is coming directly from a user agent (e.g., browser)? What do
> those servers use to detect proxies now?
>
> Etc. etc. You probably know exactly what you need to achieve. Narrow it
> down for us as much as possible.
>
>
> > After looking up online I configured the following:
> >
> > request_header_access Cache-Control deny all
>
> Denying general-purpose headers makes no sense if you want Squid to
> forward as many original headers as possible. Yes, Squid may generate
> new Cache-Control headers but that does not mean that Squid does not
> forward client Cache-Control headers as well. The task of preserving
> original headers may feel trivial to you, but the actual complexity of
> what you are asking is one of the reasons we need you to come up with a
> narrower goal.
>
>
> > Is there any way to have squid generate the exact same headers as it
> > received?
>
> No. However, you probably do not actually need that. You probably need
> something else that Squid may be able to do (with or without code
> modifications).
>
> Alex.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170711/33ff9671/attachment.htm>

From harariboy at gmail.com  Tue Jul 11 19:00:34 2017
From: harariboy at gmail.com (avi_h)
Date: Tue, 11 Jul 2017 12:00:34 -0700 (PDT)
Subject: [squid-users] Does squid generates/adds additional HTTP headers?
In-Reply-To: <74f1a422-56f2-87c8-cc57-132f6d6c4855@measurement-factory.com>
References: <1499714715550-4683050.post@n4.nabble.com>
 <95f8cb8f-168b-1804-3501-091cc1333c02@treenet.co.nz>
 <1499730773838-4683052.post@n4.nabble.com>
 <74f1a422-56f2-87c8-cc57-132f6d6c4855@measurement-factory.com>
Message-ID: <1499799634513-4683062.post@n4.nabble.com>

Hi Alex,

Thanks for this.
I can narrow it down, as you mentioned, I want to configure Squid to make
some server(s) think that the 
request is coming directly from a user agent (e.g., browser).
However, I don't know what those servers use to detect proxies, any idea on
how I can figure it out?
Ideally, I would like to find a solution that would fit all (or the most
popular) detection mechanisms, if that's possible.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Does-squid-generates-adds-additional-HTTP-headers-tp4683050p4683062.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Tue Jul 11 20:23:15 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 11 Jul 2017 14:23:15 -0600
Subject: [squid-users] Does squid generates/adds additional HTTP headers?
In-Reply-To: <1499799634513-4683062.post@n4.nabble.com>
References: <1499714715550-4683050.post@n4.nabble.com>
 <95f8cb8f-168b-1804-3501-091cc1333c02@treenet.co.nz>
 <1499730773838-4683052.post@n4.nabble.com>
 <74f1a422-56f2-87c8-cc57-132f6d6c4855@measurement-factory.com>
 <1499799634513-4683062.post@n4.nabble.com>
Message-ID: <a29134d9-68cb-96ca-44d7-4d2a7acd3265@measurement-factory.com>

On 07/11/2017 01:00 PM, avi_h wrote:

> I want to configure Squid to make some server(s) think that the 
> request is coming directly from a user agent (e.g., browser).
> However, I don't know what those servers use to detect proxies,

Understood. We are still where we used to be then: Without a known
detection vector, it is impossible to recommend a specific solution (or
to declare the problem unsolvable).


> any idea on how I can figure it out?

I can suggest two complementary approaches:

* Experimentation: Send HTTP requests using some highly-configurable
client tool and vary header composition to move from a "browser request"
to "Squid request", one header (or group of headers) at a time. One may
be able to reverse engineer (parts of) the server algorithm this way.

* Asking specific questions: Ask about specific servers your Squid does
not work with. Perhaps others (on this or other mailing lists) know more
about those servers. You already got a response from Sonya Roy
indicating that some Squid modifications helped them. Perhaps Sonya Roy
and/or others know about your servers as well.


> Ideally, I would like to find a solution that would fit all (or the most
> popular) detection mechanisms, if that's possible.

I do not know what all (or the most popular) detection mechanisms are so
I cannot answer this question, but perhaps others on this list can.
Needless to say, if you succeed, then once those servers discover that
their detection mechanism stopped working, they are likely to change it.

This is why we can't have nice things,

Alex.


From eliezer at ngtech.co.il  Tue Jul 11 21:25:46 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 12 Jul 2017 00:25:46 +0300
Subject: [squid-users] WARNING: Disk space over limit
In-Reply-To: <1499783115167-4683055.post@n4.nabble.com>
References: <1499783115167-4683055.post@n4.nabble.com>
Message-ID: <0ba101d2fa8c$429c9850$c7d5c8f0$@ngtech.co.il>

Hey,

If you are using a single process ie not SMP(default) use aufs instead of diskd cache_dir.
It's much more stable and efficient then diskd(to my knowledge).

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Tuesday, July 11, 2017 17:25
To: squid-users at lists.squid-cache.org
Subject: [squid-users] WARNING: Disk space over limit

Hi to all.
Im having this warning

2017/07/11 11:37:44 kid1| WARNING: Disk space over limit: 17241692.00 KB >
15360000 KB
2017/07/11 11:37:56 kid1| WARNING: Disk space over limit: 16800692.00 KB >
15360000 KB
2017/07/11 11:38:07 kid1| WARNING: Disk space over limit: 16466860.00 KB >
15360000 KB
2017/07/11 11:38:19 kid1| WARNING: Disk space over limit: 16152960.00 KB >
15360000 KB
2017/07/11 11:38:30 kid1| WARNING: Disk space over limit: 15905772.00 KB >
15360000 KB
2017/07/11 11:38:41 kid1| WARNING: Disk space over limit: 15664684.00 KB >
15360000 KB
2017/07/11 11:38:52 kid1| WARNING: Disk space over limit: 15499404.00 KB >
15360000 KB


Why is this happening?? why is over limit??

[root at squid ~]# df -h
S.ficheros              Tama?o Usados  Disp Uso% Montado en
/dev/mapper/centos-root    48G    17G   31G  36% /
devtmpfs                  1,9G      0  1,9G   0% /dev
tmpfs                     1,9G   2,1M  1,9G   1% /dev/shm
tmpfs                     1,9G   8,5M  1,9G   1% /run
tmpfs                     1,9G      0  1,9G   0% /sys/fs/cgroup
/dev/sda1                 497M   143M  355M  29% /boot
tmpfs                     380M      0  380M   0% /run/user/0

SQUID.CONF

cache_dir diskd /var/spool/squid 15000 16 256
cache_mem 1000 MB
maximum_object_size_in_memory 1 MB

cache_swap_low 90
cache_swap_high 95

Yes, it is over cache_dir... but why?? and how i correct this?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/WARNING-Disk-space-over-limit-tp4683055.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Tue Jul 11 22:34:37 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 12 Jul 2017 04:34:37 +0600
Subject: [squid-users] WARNING: Disk space over limit
In-Reply-To: <0ba101d2fa8c$429c9850$c7d5c8f0$@ngtech.co.il>
References: <1499783115167-4683055.post@n4.nabble.com>
 <0ba101d2fa8c$429c9850$c7d5c8f0$@ngtech.co.il>
Message-ID: <421e8a11-dcfb-a352-e5bf-6eca1268fe9a@gmail.com>



12.07.2017 3:25, Eliezer Croitoru ?????:
> Hey,
>
> If you are using a single process ie not SMP(default) use aufs instead of diskd cache_dir.
> It's much more stable and efficient then diskd(to my knowledge).
Not sure about you knowledge. Diskd is simple designed for another OS
than Linux. On appropriate platform it is not only stable, but quite
efficient than aufs. :)
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
> Sent: Tuesday, July 11, 2017 17:25
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] WARNING: Disk space over limit
>
> Hi to all.
> Im having this warning
>
> 2017/07/11 11:37:44 kid1| WARNING: Disk space over limit: 17241692.00 KB >
> 15360000 KB
> 2017/07/11 11:37:56 kid1| WARNING: Disk space over limit: 16800692.00 KB >
> 15360000 KB
> 2017/07/11 11:38:07 kid1| WARNING: Disk space over limit: 16466860.00 KB >
> 15360000 KB
> 2017/07/11 11:38:19 kid1| WARNING: Disk space over limit: 16152960.00 KB >
> 15360000 KB
> 2017/07/11 11:38:30 kid1| WARNING: Disk space over limit: 15905772.00 KB >
> 15360000 KB
> 2017/07/11 11:38:41 kid1| WARNING: Disk space over limit: 15664684.00 KB >
> 15360000 KB
> 2017/07/11 11:38:52 kid1| WARNING: Disk space over limit: 15499404.00 KB >
> 15360000 KB
>
>
> Why is this happening?? why is over limit??
>
> [root at squid ~]# df -h
> S.ficheros              Tama?o Usados  Disp Uso% Montado en
> /dev/mapper/centos-root    48G    17G   31G  36% /
> devtmpfs                  1,9G      0  1,9G   0% /dev
> tmpfs                     1,9G   2,1M  1,9G   1% /dev/shm
> tmpfs                     1,9G   8,5M  1,9G   1% /run
> tmpfs                     1,9G      0  1,9G   0% /sys/fs/cgroup
> /dev/sda1                 497M   143M  355M  29% /boot
> tmpfs                     380M      0  380M   0% /run/user/0
Where's the /var mountpoint?

>
> SQUID.CONF
>
> cache_dir diskd /var/spool/squid 15000 16 256
You specified 15000 megabytes for cache. So, reasonable

WARNING: Disk space over limit: 17241692.00 KB >
15360000 KB

Squid tries to save more than you specified.
> cache_mem 1000 MB
> maximum_object_size_in_memory 1 MB
>
> cache_swap_low 90
> cache_swap_high 95
and if you take a look onto your swap_hi/low values you can see it's not
do replacement to the end of specified store limit.
>
> Yes, it is over cache_dir... but why?? and how i correct this?
Try to do two things. First - increase cache_dir formal size. Second -
return

cache_swap_low

to it's default value.

Because of "Premature optimization is root of all evils".

>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/WARNING-Disk-space-over-limit-tp4683055.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170712/0e6f29b6/attachment.sig>

From yvoinov at gmail.com  Tue Jul 11 22:47:01 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 12 Jul 2017 04:47:01 +0600
Subject: [squid-users] WARNING: Disk space over limit
In-Reply-To: <421e8a11-dcfb-a352-e5bf-6eca1268fe9a@gmail.com>
References: <1499783115167-4683055.post@n4.nabble.com>
 <0ba101d2fa8c$429c9850$c7d5c8f0$@ngtech.co.il>
 <421e8a11-dcfb-a352-e5bf-6eca1268fe9a@gmail.com>
Message-ID: <1c69ff4d-2b9c-ef13-3e22-fd3008c5113c@gmail.com>



12.07.2017 4:34, Yuri ?????:
>
> 12.07.2017 3:25, Eliezer Croitoru ?????:
>> Hey,
>>
>> If you are using a single process ie not SMP(default) use aufs instead of diskd cache_dir.
>> It's much more stable and efficient then diskd(to my knowledge).
> Not sure about you knowledge. Diskd is simple designed for another OS
> than Linux. On appropriate platform it is not only stable, but quite
> efficient than aufs. :)
>> Eliezer
>>
>> ----
>> Eliezer Croitoru
>> Linux System Administrator
>> Mobile: +972-5-28704261
>> Email: eliezer at ngtech.co.il
>>
>>
>>
>> -----Original Message-----
>> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
>> Sent: Tuesday, July 11, 2017 17:25
>> To: squid-users at lists.squid-cache.org
>> Subject: [squid-users] WARNING: Disk space over limit
>>
>> Hi to all.
>> Im having this warning
>>
>> 2017/07/11 11:37:44 kid1| WARNING: Disk space over limit: 17241692.00 KB >
>> 15360000 KB
>> 2017/07/11 11:37:56 kid1| WARNING: Disk space over limit: 16800692.00 KB >
>> 15360000 KB
>> 2017/07/11 11:38:07 kid1| WARNING: Disk space over limit: 16466860.00 KB >
>> 15360000 KB
>> 2017/07/11 11:38:19 kid1| WARNING: Disk space over limit: 16152960.00 KB >
>> 15360000 KB
>> 2017/07/11 11:38:30 kid1| WARNING: Disk space over limit: 15905772.00 KB >
>> 15360000 KB
>> 2017/07/11 11:38:41 kid1| WARNING: Disk space over limit: 15664684.00 KB >
>> 15360000 KB
>> 2017/07/11 11:38:52 kid1| WARNING: Disk space over limit: 15499404.00 KB >
>> 15360000 KB
>>
>>
>> Why is this happening?? why is over limit??
>>
>> [root at squid ~]# df -h
>> S.ficheros              Tama?o Usados  Disp Uso% Montado en
>> /dev/mapper/centos-root    48G    17G   31G  36% /
>> devtmpfs                  1,9G      0  1,9G   0% /dev
>> tmpfs                     1,9G   2,1M  1,9G   1% /dev/shm
>> tmpfs                     1,9G   8,5M  1,9G   1% /run
>> tmpfs                     1,9G      0  1,9G   0% /sys/fs/cgroup
>> /dev/sda1                 497M   143M  355M  29% /boot
>> tmpfs                     380M      0  380M   0% /run/user/0
> Where's the /var mountpoint?
>
>> SQUID.CONF
>>
>> cache_dir diskd /var/spool/squid 15000 16 256
> You specified 15000 megabytes for cache. So, reasonable
>
> WARNING: Disk space over limit: 17241692.00 KB >
> 15360000 KB
>
> Squid tries to save more than you specified.
>> cache_mem 1000 MB
>> maximum_object_size_in_memory 1 MB
>>
>> cache_swap_low 90
>> cache_swap_high 95
> and if you take a look onto your swap_hi/low values you can see it's not
> do replacement to the end of specified store limit.
>> Yes, it is over cache_dir... but why?? and how i correct this?
> Try to do two things. First - increase cache_dir formal size. Second -
> return
>
> cache_swap_low
>
> to it's default value.
>
> Because of "Premature optimization is root of all evils".
Ooooops, it default value is 90 :) My bad, too much nightly work :)

Well. Let's read squid.conf.documented:

#  TAG: cache_swap_low    (percent, 0-100)
#    The low-water mark for AUFS/UFS/diskd cache object eviction by
#    the cache_replacement_policy algorithm.
#
#    Removal begins when the swap (disk) usage of a cache_dir is
#    above this low-water mark and attempts to maintain utilization
#    near the low-water mark.
#
#    As swap utilization increases towards the high-water mark set
#    by cache_swap_high object eviction becomes more agressive.
#
#    The value difference in percentages between low- and high-water
#    marks represent an eviction rate of 300 objects per second and
#    the rate continues to scale in agressiveness by multiples of
#    this above the high-water mark.
#
#    Defaults are 90% and 95%. If you have a large cache, 5% could be
#    hundreds of MB. If this is the case you may wish to set these
#    numbers closer together.
#
#    See also cache_swap_high and cache_replacement_policy

Eviction starts when you cache achieves cache_swap_low. So, may be you
traffic is more than squid can be replaced between 90 and 95%. So, you
can try to decrease cache_swap_low. Or, review your caching policy to be
less aggressive. Or, increase cache_dir limit. Or all together.


>
>>
>>
>> --
>> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/WARNING-Disk-space-over-limit-tp4683055.html
>> Sent from the Squid - Users mailing list archive at Nabble.com.
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170712/3d4b5fab/attachment.sig>

From squid3 at treenet.co.nz  Wed Jul 12 06:57:47 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 12 Jul 2017 18:57:47 +1200
Subject: [squid-users] WARNING: Disk space over limit
In-Reply-To: <421e8a11-dcfb-a352-e5bf-6eca1268fe9a@gmail.com>
References: <1499783115167-4683055.post@n4.nabble.com>
 <0ba101d2fa8c$429c9850$c7d5c8f0$@ngtech.co.il>
 <421e8a11-dcfb-a352-e5bf-6eca1268fe9a@gmail.com>
Message-ID: <445e00dd-d596-8e1e-5b50-6f222bd04d52@treenet.co.nz>

On 12/07/17 10:34, Yuri wrote:
> 
> 
> 12.07.2017 3:25, Eliezer Croitoru ?????:
>> Hey,
>>
>> If you are using a single process ie not SMP(default) use aufs instead of diskd cache_dir.
>> It's much more stable and efficient then diskd(to my knowledge).
 >
> Not sure about you knowledge. Diskd is simple designed for another OS
> than Linux. On appropriate platform it is not only stable, but quite
> efficient than aufs. :)
>>

Not quite. AUFS was supposed to succeed diskd since it allows far 
greater parallelism, however it often does not work very well on 
BSD-like systems and nobody managed to fix it yet.

The latest BSDs threading does handle AUFS better than older ones do 
though so YMMV.

Amos


From squid3 at treenet.co.nz  Wed Jul 12 07:25:30 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 12 Jul 2017 19:25:30 +1200
Subject: [squid-users] WARNING: Disk space over limit
In-Reply-To: <1c69ff4d-2b9c-ef13-3e22-fd3008c5113c@gmail.com>
References: <1499783115167-4683055.post@n4.nabble.com>
 <0ba101d2fa8c$429c9850$c7d5c8f0$@ngtech.co.il>
 <421e8a11-dcfb-a352-e5bf-6eca1268fe9a@gmail.com>
 <1c69ff4d-2b9c-ef13-3e22-fd3008c5113c@gmail.com>
Message-ID: <5480ea5c-cf69-8902-c13e-232ff01f29dd@treenet.co.nz>

On 12/07/17 10:47, Yuri wrote:
> 
> Well. Let's read squid.conf.documented:
> 
> #  TAG: cache_swap_low    (percent, 0-100)
> #    The low-water mark for AUFS/UFS/diskd cache object eviction by
> #    the cache_replacement_policy algorithm.
> #
> #    Removal begins when the swap (disk) usage of a cache_dir is
> #    above this low-water mark and attempts to maintain utilization
> #    near the low-water mark.
> #
> #    As swap utilization increases towards the high-water mark set
> #    by cache_swap_high object eviction becomes more agressive.
> #
> #    The value difference in percentages between low- and high-water
> #    marks represent an eviction rate of 300 objects per second and
> #    the rate continues to scale in agressiveness by multiples of
> #    this above the high-water mark.
> #
> #    Defaults are 90% and 95%. If you have a large cache, 5% could be
> #    hundreds of MB. If this is the case you may wish to set these
> #    numbers closer together.
> #
> #    See also cache_swap_high and cache_replacement_policy
> 
> Eviction starts when you cache achieves cache_swap_low. So, may be you
> traffic is more than squid can be replaced between 90 and 95%. So, you
> can try to decrease cache_swap_low. Or, review your caching policy to be
> less aggressive. Or, increase cache_dir limit. Or all together.
> 

Or adjust the maximum object size that cache can store.

Since the warnings are clearly decreasing in overage value things seem 
to be recovering properly. The warning is to alert you that it happened 
in the first place, so traffic may need re-evaluation. Your proxy seems 
to be able to evict ~400 MB/cycle from disk.


Additional to traffic rate, it is rare but can happen that one or more 
very large objects are fetched very close together. Squid then discovers 
it has to throw away GB of objects to make room for them, even though 
they may not have fully arrived yet. This may exceed the eviction rate 
for a while, depending on your disk I/O speed.




The math if you are interested:

At your total cache size, the 5% high-low gap is only 750 MB, and the 
warning occurs at 100% - just another 750 MB above that gap. Giving a 
total burst size of 1.5 GB of object(s) necessary to trigger it.

NP: that 1.5GB needs to be above the regular eviction rate per garbage 
cycle. If you are having trouble the fix is to a) get faster RPM disks, 
b) spread the load over more proxies,


I notice that the overage value in the trace is only 2.2 GB which is 
within realm for DVD images, HD movies, Windows 10 updates, etc.
If you are intending to cache those you need; multiple cache disks, 
lower high/low percentages.

  You can also ensure the physical disk has a sufficient buffer of space 
to not worry about occasional of these warnings. That is effectivively 
the same as lowering the low watermark but prohibits Squid from using 
that space when traffic is not being such a problem.


Amos


From bugreporter2017 at gmail.com  Wed Jul 12 09:55:36 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Wed, 12 Jul 2017 02:55:36 -0700 (PDT)
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <749fadf0-6b34-f1cc-9c1c-5f3c2304e3b4@gmail.com>
References: <1499619540869-4683033.post@n4.nabble.com>
 <503494af-d2e4-db06-91fc-c5efa039d35e@gmail.com>
 <1499626481926-4683036.post@n4.nabble.com>
 <ba01d93c-d8d5-30b4-26c7-6145cdda6c77@gmail.com>
 <1499638965067-4683039.post@n4.nabble.com>
 <1ed45ea6-376c-105c-d808-94d7af9c75d0@gmail.com>
 <1499672747720-4683042.post@n4.nabble.com>
 <749fadf0-6b34-f1cc-9c1c-5f3c2304e3b4@gmail.com>
Message-ID: <1499853336151-4683069.post@n4.nabble.com>

Thank you Yuri,

The least I can say is that the conversation at
http://bugs.squid-cache.org/show_bug.cgi?id=4597 makes me laugh a lot. My
opinion is that if you modify the source code of an open source program
without publishing your modifications your are in contradiction with GPL v2.
Your sponsor may have *serious blame* from the open source community (and
also *legal problems*). 10 days of hard working is not nothing and I can
understand your position. But What do you think that we do all of us (open
source developers) ? My own Open Source project represents 1700 days of
(very) hard working... But I always respect the GPL. 

Anyway... Thank you for your help. At least, now I'm not going to
investigate for nothing.

Kind Regards,



-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033p4683069.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From bugreporter2017 at gmail.com  Wed Jul 12 10:01:01 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Wed, 12 Jul 2017 03:01:01 -0700 (PDT)
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <cb368bae-ebe8-9005-0c32-e21a52ab695b@measurement-factory.com>
References: <1499619540869-4683033.post@n4.nabble.com>
 <cb368bae-ebe8-9005-0c32-e21a52ab695b@measurement-factory.com>
Message-ID: <1499853661156-4683070.post@n4.nabble.com>

Hi Alex,

Thank you for your post. I do appreciate your help and recommendations.

By chance, do you know another adapter that I can use to replace
squid-ecap-gzip. Actually I'm looking for an adapter capable to compress
HTTP contents.

Warm Reagrds,




-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033p4683070.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Antony.Stone at squid.open.source.it  Wed Jul 12 10:34:46 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 12 Jul 2017 11:34:46 +0100
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
	Segment Violation...dying.
In-Reply-To: <1499853336151-4683069.post@n4.nabble.com>
References: <1499619540869-4683033.post@n4.nabble.com>
 <749fadf0-6b34-f1cc-9c1c-5f3c2304e3b4@gmail.com>
 <1499853336151-4683069.post@n4.nabble.com>
Message-ID: <201707121134.46511.Antony.Stone@squid.open.source.it>

On Wednesday 12 July 2017 at 10:55:36, bugreporter wrote:

> Thank you Yuri,
> 
> The least I can say is that the conversation at
> http://bugs.squid-cache.org/show_bug.cgi?id=4597 makes me laugh a lot. My
> opinion is that if you modify the source code of an open source program
> without publishing your modifications your are in contradiction with GPL
> v2.

That depends entirely on whether the modified version has been distributed or 
not.

If whoever has done the modifications uses the modified version only for their 
own use, that is entirely in keeping with the GPL.

The GPL only says that you must make available the source code of your 
modifications for any modified version which you distribute to others.

> Your sponsor may have *serious blame* from the open source community
> (and also *legal problems*). 10 days of hard working is not nothing and I
> can understand your position. But What do you think that we do all of us
> (open source developers) ? My own Open Source project represents 1700 days
> of (very) hard working... But I always respect the GPL.

Please read it more closely, specifically sections 2 and 6, paying attention to 
the word "distribute".

https://www.gnu.org/licenses/old-licenses/gpl-2.0.en.html


Regards,


Antony.

-- 
Pavlov is in the pub enjoying a pint.
The barman rings for last orders, and Pavlov jumps up exclaiming "Damn!  I 
forgot to feed the dog!"

                                                   Please reply to the list;
                                                         please *don't* CC me.


From bugreporter2017 at gmail.com  Wed Jul 12 10:31:34 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Wed, 12 Jul 2017 03:31:34 -0700 (PDT)
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
Message-ID: <1499855494036-4683072.post@n4.nabble.com>

Hi,

Can anybody help me to confirm my understanding of the memory usage vs the
persistent cache capacity? Below my understanding:

According to http://wiki.squid-cache.org/SquidFaq/SquidMemory:

1- We need 14 MB of memory per 1 GB on disk for 64-bit Squid.The wiki is
there since I know squid (ie. i'm very old now). Is this information still
valid?

2- Is this assumption based on the default value of 13 KB for
*store_avg_object_size*?

3- If answers to questions above are both YES, can we deduce that we need 
*182* bytes in memory per object in the persistent cache on 64x system?
[*182* = (14 * 1024 * 1024) / (1024 * 1024 / store_avg_object_size)]

4- Today the *store_avg_object_size* should be really greater than 13 KB.
The mean object size I can see on my own cache is about 100 KB. Can anybody
refer me to a website where I can find fresh information?

5- If I'm completely on a wrong way, can anybody help me to find a formula
that can help me to deduce the required RAM for a given HDD capacity (and
vice versa).

Warm Regards,



-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/HDD-RAM-Capacity-vs-store-avg-object-size-tp4683072.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Wed Jul 12 10:55:46 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 12 Jul 2017 13:55:46 +0300
Subject: [squid-users] WARNING: Disk space over limit
In-Reply-To: <445e00dd-d596-8e1e-5b50-6f222bd04d52@treenet.co.nz>
References: <1499783115167-4683055.post@n4.nabble.com>
 <0ba101d2fa8c$429c9850$c7d5c8f0$@ngtech.co.il>
 <421e8a11-dcfb-a352-e5bf-6eca1268fe9a@gmail.com>
 <445e00dd-d596-8e1e-5b50-6f222bd04d52@treenet.co.nz>
Message-ID: <0da601d2fafd$6a23d9d0$3e6b8d70$@ngtech.co.il>

Just wondering what or who is required to make this fix happen?
A donation? A programmer? A Tester?

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Wednesday, July 12, 2017 09:58
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] WARNING: Disk space over limit

On 12/07/17 10:34, Yuri wrote:
> 
> 
> 12.07.2017 3:25, Eliezer Croitoru ?????:
>> Hey,
>>
>> If you are using a single process ie not SMP(default) use aufs instead of diskd cache_dir.
>> It's much more stable and efficient then diskd(to my knowledge).
 >
> Not sure about you knowledge. Diskd is simple designed for another OS
> than Linux. On appropriate platform it is not only stable, but quite
> efficient than aufs. :)
>>

Not quite. AUFS was supposed to succeed diskd since it allows far 
greater parallelism, however it often does not work very well on 
BSD-like systems and nobody managed to fix it yet.

The latest BSDs threading does handle AUFS better than older ones do 
though so YMMV.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Wed Jul 12 11:59:38 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 12 Jul 2017 14:59:38 +0300
Subject: [squid-users] Squid as gateway
In-Reply-To: <1499780101757-4683053.post@n4.nabble.com>
References: <1499444090379-4683022.post@n4.nabble.com>
 <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
 <1499780101757-4683053.post@n4.nabble.com>
Message-ID: <0ded01d2fb06$5665bf90$03313eb0$@ngtech.co.il>

Hey,

The text doesn't contains enough details to understand where squid sitting in the network and how it all should work.
Please describe every IP address in the network and network CIDR's.
What is the IP of the WANRouter and other components.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Tuesday, July 11, 2017 16:35
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid as gateway

Hi, and thanks.
Maybe i dont explain well.
I just want this:

 WanRouter-------Squid---------switch------PC

I want to declare in "PC" IP, MASK, AND GATEWAY, instead of the WanRouter, i
want that PC have for gateway the ip of the Squid.

I do this by now.

sudo iptables -A PREROUTING -t nat -s 192.168.1.0/24 -p tcp --dport 80 -j
REDIRECT --to-port 3128

[root at squid ~]# iptables -L -n
Chain INPUT (policy ACCEPT)
target     prot opt source               destination         
ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:3128
ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:443
ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            tcp dpt:80
ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0            state
RELATED,ESTABLISHED
ACCEPT     icmp --  0.0.0.0/0            0.0.0.0/0           
ACCEPT     all  --  0.0.0.0/0            0.0.0.0/0           
ACCEPT     tcp  --  0.0.0.0/0            0.0.0.0/0            state NEW tcp
dpt:22
REJECT     all  --  0.0.0.0/0            0.0.0.0/0            reject-with
icmp-host-prohibited

Chain FORWARD (policy ACCEPT)
target     prot opt source               destination         
REJECT     all  --  0.0.0.0/0            0.0.0.0/0            reject-with
icmp-host-prohibited

Chain OUTPUT (policy ACCEPT)
target     prot opt source               destination         


 iptables -t nat --line-numbers -L
Chain PREROUTING (policy ACCEPT)
num  target     prot opt source               destination         
1    REDIRECT   tcp  --  192.168.1.0/24       anywhere             tcp
dpt:http redir ports 3128


And in squid.conf 
i have
http 192.168.1.35:3128 intercept

But... this is not working... so
Can anyone give me a hand?

Thanks to all.

 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-as-gateway-tp4683022p4683053.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Wed Jul 12 12:02:01 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 12 Jul 2017 15:02:01 +0300
Subject: [squid-users] Squid 4.0.21 beta RPM's are out.
In-Reply-To: <03d601d2f8d8$c43a5fb0$4caf1f10$@ngtech.co.il>
References: <03d601d2f8d8$c43a5fb0$4caf1f10$@ngtech.co.il>
Message-ID: <0def01d2fb06$ab81ed00$0285c700$@ngtech.co.il>

I have added a dedicated line for the repo at:
http://faster.ngtech.co.il/repo/

It has between 3-10 Mbps upload speed Please try to use it since it's for you:
http://faster.ngtech.co.il/repo/centos/7/beta/
http://faster.ngtech.co.il/repo/oracle/7/beta/
http://faster.ngtech.co.il/repo/sles/12sp1/beta/

All The Bests,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Eliezer Croitoru
Sent: Sunday, July 9, 2017 20:28
To: 'Amos Jeffries' <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: [squid-users] Squid 4.0.21 beta RPM's are out.

Squid 4.0.21 beta RPM's are out for:
CentOS 7, Oracle Enterprise Linux 7, SLES 12SP1

http://ngtech.co.il/repo/centos/7/beta/
http://ngtech.co.il/repo/oracle/7/beta/
http://ngtech.co.il/repo/sles/12sp1/beta/

With hope that it will help to move faster from beta to stable.

All The Bests,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Friday, July 7, 2017 15:36
To: squid-announce at lists.squid-cache.org
Subject: [squid-users] [squid-announce] Squid 4.0.21 beta is available

The Squid HTTP Proxy team is very pleased to announce the availability of the Squid-4.0.21 release!


This release is a bug fix release resolving several issues found in the prior Squid releases.


The major changes to be aware of:

* Regression Bug 4492: Chunk extension parser is too pedantic

With this fix Squid is back to ignoring some unusual message whitespace padding that senders should not have been doing, but which are generally harmless to the protocol. It is a regression specific to the Squid-4 release series, not affecting any other installations.


* Bug 1961 partial: Redesign urlParse API

The core changes for redesign work is largely finished now. As a result this release should have much lower memory use on url_rewrite API lookups which choose not to rewrite the URL.


* Collapse security_file_certgen requests

This helper API now collapses identical parallel lookups into a single helper message to reduce load, latency and as a result reduce pressure on the system crypto services. It still has some issues, but should now cope a lot better with sudden load peaks as seen from Browsers starting up.


* SSL-Bump: tproxy does not spoof spliced connections

This release now performs TPROXY spoofing properly when SSL-Bump logic selects splice action. Prior SSL-Bump would behave as if NAT intercept was being used, by replacing the sender IP as Squid one.


* Add a basic apparmour profile

This release bundles a basic apparmour profile contributed by Ubuntu developers. As with init system scripts this profile is not installed by default, packagers wishing to use it should pull the file from the sources during packaging.


Several major bug fixes shared with the future Squid-3.5.27 release are also worth mentioning:

* Bug 4464: Reduce "!Comm::MonitorsRead(serverConnection->fd)" assertions.

In Squid-3 this bug appeared as "fd_table[conn->fd].halfClosedReader != NULL" assertions.

Admin who have used the various config workarounds or patches to suppress those assertions will need to re-asses those temporary measures after upgrading to this release.


* Bug 2833: collapsed forwarding doesn't work with NOT MODIFIED response

The security fix for CVE-2016-10003 had a negative effect on collapsed forwarding. All "private" entries were considered automatically non-shareable among collapsed clients. However this is not true: there are many situations when collapsed forwarding should work despite of "private" (non-cacheable) entry status: 304/5xx responses are good examples of that.

This release adds a mechanism to mark some non-cached responses as being able to share with collapsed forwarding.

These changes also involved fixing incorrect delivery of 304 responses to a client when Squid was the agent performing revalidation instead of the client.


* Bug 4112: ssl_engine does not accept cryptodev

This directive has been broken for quite a long time, failing to recognize any of the default OpenSSL engines. This release restores support for the OpenSSL engines feature.


* Fix SMP query handoff to Coordinator.

Several issues related to SMP messages to the coordinator process have been fixed. Some of these are likely to have been resulting in hung connections for SNMP and mgr transactions. Others were resulting in garbage messages arriving at the coordinator.



  All users of Squid-4.x are encouraged to upgrade to this release as soon as possible.

  All users of Squid-3 are encouraged to test this release out and plan for upgrades where possible.


  See the ChangeLog for the full list of changes in this and earlier
  releases.

Please refer to the release notes at
http://www.squid-cache.org/Versions/v4/RELEASENOTES.html
when you are ready to make the switch to Squid-4

This new release can be downloaded from our HTTP or FTP servers

  http://www.squid-cache.org/Versions/v4/
  ftp://ftp.squid-cache.org/pub/squid/
  ftp://ftp.squid-cache.org/pub/archive/4/

or the mirrors. For a list of mirror sites see

  http://www.squid-cache.org/Download/http-mirrors.html
  http://www.squid-cache.org/Download/mirrors.html

If you encounter any issues with this release please file a bug report.
http://bugs.squid-cache.org/


Amos Jeffries
_______________________________________________
squid-announce mailing list
squid-announce at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-announce
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Wed Jul 12 12:41:10 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 13 Jul 2017 00:41:10 +1200
Subject: [squid-users] WARNING: Disk space over limit
In-Reply-To: <0da601d2fafd$6a23d9d0$3e6b8d70$@ngtech.co.il>
References: <1499783115167-4683055.post@n4.nabble.com>
 <0ba101d2fa8c$429c9850$c7d5c8f0$@ngtech.co.il>
 <421e8a11-dcfb-a352-e5bf-6eca1268fe9a@gmail.com>
 <445e00dd-d596-8e1e-5b50-6f222bd04d52@treenet.co.nz>
 <0da601d2fafd$6a23d9d0$3e6b8d70$@ngtech.co.il>
Message-ID: <4de487bb-0dba-2ad6-aff8-9b1d5f197ce1@treenet.co.nz>

On 12/07/17 22:55, Eliezer Croitoru wrote:
> Just wondering what or who is required to make this fix happen?
> A donation? A programmer? A Tester?

AFAIK, someone with knowledge of multi-threaded process design and both 
Linux and BSD kernel disk I/O. Adrian was that person for Squid-2 and 
IIRC had a theory that it was related to the thread blocking behaviour 
of the kernel somehow.

Amos


From squid3 at treenet.co.nz  Wed Jul 12 13:10:26 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 13 Jul 2017 01:10:26 +1200
Subject: [squid-users] Squid as gateway
In-Reply-To: <DB6PR0401MB268005878EFFB4A6858B90E88FAE0@DB6PR0401MB2680.eurprd04.prod.outlook.com>
References: <1499444090379-4683022.post@n4.nabble.com>
 <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
 <1499780101757-4683053.post@n4.nabble.com>
 <53dbba46-eacc-53a4-276e-6ed57b568870@gmail.com>
 <1499786792585-4683056.post@n4.nabble.com>
 <1efe582d-86ad-6387-f935-bbfe7f25e2c6@gmail.com>
 <1499787641981-4683058.post@n4.nabble.com>
 <DB6PR0401MB268005878EFFB4A6858B90E88FAE0@DB6PR0401MB2680.eurprd04.prod.outlook.com>
Message-ID: <a722909a-6ce5-815a-40a4-f0552af8243b@treenet.co.nz>

On 12/07/17 04:20, Rafael Akchurin wrote:
> May be this will be of any help - https://docs.diladele.com/tutorials/transparent_proxy_ubuntu/index.html
> 


erdosain9: the above should be what you need.

If not, then you may still be distracted by thinking that Squid has any 
relevance to the "gateway".

What you need to start with is that the machine which will _later_ be 
running Squid - be _first_ setup as a gateway router on your network. 
That has nothing to do with Squid and the details should be available in 
any general networking sysadmin guide.

The key thing is that all your clients traffic routing should be 
operational and going through that machine *before* you go anywhere near 
even installing Squid on that machine.

Only after that gateway is setup and operational do you install Squid 
and add the iptables bits to get the traffic into Squid. The Squid wiki 
examples are intended for use by someone already somewhat familiar with 
network configuration and wanting to do that extra step with the proxy.

The Diladele page(s) go through much more of the full process of setting 
up the gateway machine, but remember that most of what you are wanting 
is not about Squid at all - so don't skip parts thinking they are 
irrelevant to your proxy.

HTH
Amos


From squid3 at treenet.co.nz  Wed Jul 12 14:13:31 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 13 Jul 2017 02:13:31 +1200
Subject: [squid-users] Does squid generates/adds additional HTTP headers?
In-Reply-To: <1499799634513-4683062.post@n4.nabble.com>
References: <1499714715550-4683050.post@n4.nabble.com>
 <95f8cb8f-168b-1804-3501-091cc1333c02@treenet.co.nz>
 <1499730773838-4683052.post@n4.nabble.com>
 <74f1a422-56f2-87c8-cc57-132f6d6c4855@measurement-factory.com>
 <1499799634513-4683062.post@n4.nabble.com>
Message-ID: <8ea43151-0de9-16fc-6cfd-9f9e7eb45f59@treenet.co.nz>

On 12/07/17 07:00, avi_h wrote:
> Hi Alex,
> 
> Thanks for this.
> I can narrow it down, as you mentioned, I want to configure Squid to make
> some server(s) think that the
> request is coming directly from a user agent (e.g., browser).
> However, I don't know what those servers use to detect proxies, any idea on
> how I can figure it out?

I start with a copy of the HTTP traffic. Both the messages coming from 
the client and the ones going to the serve. For both the proxied and 
non-proxy traffic.

I then run a set of scripts I've built up over the years to see how the 
server responds to various of the header changes the proxy does, and 
some possible alternatives. That usually leads to identifying what the 
server will accept and what makes it crash or produce errors. Usually 
server crashing with uncommon normal inputs are the real problem, not 
the proxy "breaking" traffic.

If you will list the websites you are having trouble with and what 
behaviour you want to see happen vs what they currently do that would be 
a good start.


> Ideally, I would like to find a solution that would fit all (or the most
> popular) detection mechanisms, if that's possible.

The solution is usually to accept that there is not actually a problem.

The average web object goes through something like 4-6 intermediaries 
(ie. proxy) before it arrives at an end users Browser. You have a proxy, 
everybody else does too. Nothing to gain by hiding.

In fact, hiding the proxy means literally revealing its users and some 
of your internal network structure to any web server they visit. Loosing 
privacy and a bit of security too. It is a lose-lose situation.

Amos


From squid3 at treenet.co.nz  Wed Jul 12 14:13:49 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 13 Jul 2017 02:13:49 +1200
Subject: [squid-users] Does squid generates/adds additional HTTP headers?
In-Reply-To: <CALSaDe2dts+i++bc1p6mrnmwrdSBbsi9gTDFdLquDfjui5TZgw@mail.gmail.com>
References: <CALSaDe2dts+i++bc1p6mrnmwrdSBbsi9gTDFdLquDfjui5TZgw@mail.gmail.com>
Message-ID: <96be5c39-361f-100d-9c23-f6ef302cc141@treenet.co.nz>

On 12/07/17 04:36, Sonya Roy wrote:
> As Alex mentioned its not possible to do with squid. I modified the 
> squid source code to do this a month ago. Its not hard to do, you will 
> only need to modify http.cc and client_side.cc a bit.
> 

What you did and what avi_h is asking about does not match what avi_h 
says they want to happen.


On 12/07/17 07:00, avi_h wrote:
 > make
 > some server(s) think that the
 > request is coming directly from a user agent



Even sending the entire HTTP headers as-is through to the server cannot 
prevent proxy detection if the server is actively trying to detect it. 
Some naive services look only at the headers, others inject code into 
the client to scan the Browsers view of the network environment and send 
that back to the server for comparison of what the server environment 
contains - yelling "proxy" if anything appears different, regardless of 
whether a proxy actually exists.


So as Alex hinted but did not state - what would help is info about the 
specific websites/services one is trying to work around. Narrowing the 
problem down to certain sites, and what behaviour you want to stop them 
having would be a great first step.


FWIW; in my experience most of the real traffic problems are not caused 
by proxy detection at all. That seems to be purely users/admin getting 
thrown off by other equally broken problem-detection websites, or 
blaming the proxy when something else is causing problems.

The real problem is usually servers dying in horrible ways when 
unexpected HTTP headers are given to them - even fully standardized 
headers like Via (RFC 2068, 2616, 7231) with standard values is beyond 
some server scripts ability to parse.

Not many web dev seems to understand that HTTP headers can contain 
arbitrary-length comments. "via off" is not so much preventing the proxy 
causing problems, but preventing clients behind the proxy injecting 
bogus XSS code into the server script through it - by granting any 
attacker more complete anonimity to do other attacks.

(sorry for the rant - I'm just tired of people thinking that hiding 
their proxy actually helps).

Amos


From eliezer at ngtech.co.il  Wed Jul 12 14:38:24 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 12 Jul 2017 17:38:24 +0300
Subject: [squid-users] YouTube and IMDB video ID counter\stats helper
Message-ID: <0eb101d2fb1c$84364190$8ca2c4b0$@ngtech.co.il>

As part of my work with YouTube and couple other sites I wrote a nice
counter\stats tool that can a help an admin if to add a specific YouTube
video to a locally hosted VOD solution.
The help is now being posted as a ruby helper and later I will try to add a
GoLang helper which supports concurrency and can take the load of big
systems with a small amount of running helpers.
The ruby helper source is at:
http://wiki.squid-cache.org/EliezerCroitoru/Helpers/YT-Watch-Stats

And later the GoLang helper will be added to this page.

The helper is designed to run as an external_acl helper which receives only
specific http requests ie POST\GET and only http urls.
It connects to a local redis DB and using this the admin can fetch using
another tool(that I will probably publish)  the stats and decide what to do.

I am using this tool to analyze what videos the users watch the most and if
I have downloaded the video I can redirect the clients from the video page
to a locally hosted one.
The user will have a button in the top of the page "get me the original
page" and he will be able to get into direct access for the YouTube page.
It was designed for desktop traffic and not mobile such as android or other
devices.

Eliezer 

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il






From rousskov at measurement-factory.com  Wed Jul 12 15:51:45 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 12 Jul 2017 09:51:45 -0600
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <1499853661156-4683070.post@n4.nabble.com>
References: <1499619540869-4683033.post@n4.nabble.com>
 <cb368bae-ebe8-9005-0c32-e21a52ab695b@measurement-factory.com>
 <1499853661156-4683070.post@n4.nabble.com>
Message-ID: <28b463b2-1cbc-892a-3fe1-42b14837ece2@measurement-factory.com>

On 07/12/2017 04:01 AM, bugreporter wrote:

> By chance, do you know another adapter that I can use to replace
> squid-ecap-gzip. Actually I'm looking for an adapter capable to compress
> HTTP contents.

I do not know of any free adapters that do that. FWIW, one of the
Factory adapters can be configured to compress message bodies, but the
primary purpose of that adapter is content injection, and I am not 100%
sure that it works well for pure compression purposes (because nobody I
know deploys that adapter for those purposes).

Please feel free to post an RFP to the eCAP Users list:
http://www.e-cap.org/Support

Alex.


From rousskov at measurement-factory.com  Wed Jul 12 16:08:02 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 12 Jul 2017 10:08:02 -0600
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <1499855494036-4683072.post@n4.nabble.com>
References: <1499855494036-4683072.post@n4.nabble.com>
Message-ID: <242089e0-4c34-3661-9343-7c54be7587f4@measurement-factory.com>

On 07/12/2017 04:31 AM, bugreporter wrote:

> Can anybody help me to confirm my understanding of the memory usage vs the
> persistent cache capacity? Below my understanding:
> 
> According to http://wiki.squid-cache.org/SquidFaq/SquidMemory:
> 
> 1- We need 14 MB of memory per 1 GB on disk for 64-bit Squid.The wiki is
> there since I know squid (ie. i'm very old now). Is this information still
> valid?
> 
> 2- Is this assumption based on the default value of 13 KB for
> *store_avg_object_size*?
> 
> 3- If answers to questions above are both YES, can we deduce that we need 
> *182* bytes in memory per object in the persistent cache on 64x system?
> [*182* = (14 * 1024 * 1024) / (1024 * 1024 / store_avg_object_size)]
> 
> 4- Today the *store_avg_object_size* should be really greater than 13 KB.
> The mean object size I can see on my own cache is about 100 KB. Can anybody
> refer me to a website where I can find fresh information?
> 
> 5- If I'm completely on a wrong way, can anybody help me to find a formula
> that can help me to deduce the required RAM for a given HDD capacity (and
> vice versa).

I cannot answer your questions without doing research, but I can supply
the following additional information:

* The amount of RAM used for shared (rock) cache_dirs is usually very
different from the amount of RAM used for SMP-unaware ufs-based
cache_dirs. The wiki page was written before Rock support was added.

* For ufs, you can test any formula/hypothesis by filling a disk cache
(with dummy/test objects) and measuring Squid RAM usage. The RAM usage
growth due to cache_dir index should be linear so it is fairly easy to
measure.

* For rock, you can test any formula/hypothesis by configuring your disk
caches and starting SMP Squid. The shared memory tables are created at
start time so, if you know what you are doing, you can probably see how
big they are without filling the disk cache.


Please update the wiki if you find any documentation bugs.

Alex.


From squid3 at treenet.co.nz  Wed Jul 12 16:11:56 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 13 Jul 2017 04:11:56 +1200
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <1499855494036-4683072.post@n4.nabble.com>
References: <1499855494036-4683072.post@n4.nabble.com>
Message-ID: <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>

On 12/07/17 22:31, bugreporter wrote:
> Hi,
> 
> Can anybody help me to confirm my understanding of the memory usage vs the
> persistent cache capacity? Below my understanding:
> 
> According to http://wiki.squid-cache.org/SquidFaq/SquidMemory:
> 
> 1- We need 14 MB of memory per 1 GB on disk for 64-bit Squid.The wiki is
> there since I know squid (ie. i'm very old now). Is this information still
> valid?

Yes. It is a rough estimate based on the size of code objects used to 
store each request message - they have not changed in at least the past 
10 years. There may be some variance based on extra headers modern HTTP 
contains. But that is not a huge amount and the number is a rough 
estimate to begin with.



> 
> 2- Is this assumption based on the default value of 13 KB for
> *store_avg_object_size*?

No.

That avg object size is for the full object with payload. Those payloads 
are stored inside cache_mem or cache_dir, and do not take up index 
space. So have a total limit of whatever you configure those storage 
areas to be.

Squid uses the above directive for its startup initialization of the 
index's hash table. The table can be changed dynamically, but that is 
quite expensive in terms of CPU cycles and would delay some requests so 
this is a nice shortcut to avoid most pauses.


The 10 or 14 MB is purely for the metadata necessary to index those 
cached objects. Which is the HTTP message header text plus a bunch of 
Squid code objects.


> 
> 3- If answers to questions above are both YES, can we deduce that we need
> *182* bytes in memory per object in the persistent cache on 64x system?
> [*182* = (14 * 1024 * 1024) / (1024 * 1024 / store_avg_object_size)]

If you want to re-do the calculations for your own proxy start with the 
values from the cachemgr "mem" report.

To get the metadata size add the per-object sizes (first number column) 
of HttpReply + MemObject + HttpHeaderEntry + all objects whose name 
starts with HttpHdr* + StoreEntry + all objects whose name starts with 
StoreMeta*.

The rest is harder. You need to do a scan of a disk cache separating the 
message headers - both counting the number of items found and total size 
of the headers processed. Multiplying the metadata size by the number of 
objects in the cache and adding the total message header size.

You now have total index size and total cache size for a given cache. 
Getting the N per GB from that should be easy and obvious.



NP: The mgr:mem "In Use" count of StoreEntry gives you approximately the 
number of currently indexed objects. Though it does includes some 
non-cacheable objects being replied to currently so not completely 
accurate. You can use that to see how the index memory use compares to 
the memory use for extra in-transit data.



> 4- Today the *store_avg_object_size* should be really greater than 13 KB.
> The mean object size I can see on my own cache is about 100 KB. Can anybody
> refer me to a website where I can find fresh information?

The value for your particular Squid can be found in the cachemgr "info" 
report. It is listed as "Mean Object Size".

It varies between proxies, and is directly dependent on what your 
particular cache settings are compared to the traffic that proxy sees. 
So even two proxies receiving the same traffic might show very different 
values and it is unlikely that any reference material you find by other 
people will be anything more than a rough approximation.


For example; my test proxy caching ISP-type traffic, with a fair bit of 
Facebook, YouTube etc. going through it:
"
	Mean Object Size:	106.08 KB
"

and a production CDN proxy in front of mostly Wordpress sites:
"
	Mean Object Size:	19.20 KB
"

Both with a 200 GB cache_dir and otherwise default cache settings.



> 
> 5- If I'm completely on a wrong way, can anybody help me to find a formula
> that can help me to deduce the required RAM for a given HDD capacity (and
> vice versa).
> 

Still the same one listed in the wiki page.

Though nowdays the 2^27 objects per cache_dir limitation is proving to 
be far more restrictive than the RAM index size. So depending on your 
"Mean Object Size" you may find yourself limited to only using 100 GB or 
less of a TB HDD.

Amos


From rousskov at measurement-factory.com  Wed Jul 12 16:38:07 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Wed, 12 Jul 2017 10:38:07 -0600
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
References: <1499855494036-4683072.post@n4.nabble.com>
 <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
Message-ID: <214668d4-013a-d8e2-1874-90fb499c85d1@measurement-factory.com>

On 07/12/2017 10:11 AM, Amos Jeffries wrote:
> On 12/07/17 22:31, bugreporter wrote:
>> Hi,
>>
>> Can anybody help me to confirm my understanding of the memory usage vs
>> the
>> persistent cache capacity? Below my understanding:
>>
>> According to http://wiki.squid-cache.org/SquidFaq/SquidMemory:
>>
>> 1- We need 14 MB of memory per 1 GB on disk for 64-bit Squid.The wiki is
>> there since I know squid (ie. i'm very old now). Is this information
>> still
>> valid?
> 
> Yes. It is a rough estimate based on the size of code objects used to
> store each request message - they have not changed in at least the past
> 10 years.

For the record, the StoreEntry object has changed, but I do not know how
much those (minor!) changes affect the rough estimate. It is likely that
they do not.


>> 2- Is this assumption based on the default value of 13 KB for
>> *store_avg_object_size*?
> 
> No.

Actually, the answer is probably "yes" or "yes, that or a similar mean
object size value".


> That avg object size is for the full object with payload.

... which is used to estimate how many cache_dir index entries Squid
will need to create for a cache_dir of a given size.


> The 10 or 14 MB is purely for the metadata necessary to index those
> cached objects. Which is the HTTP message header text plus a bunch of
> Squid code objects.

HTTP headers are not a part of the in-memory cache_dir index. StoreEntry
and LruNode (or equivalent) are pretty much the only structures we place
in the cache_dir index. A "bunch of Squid code objects" are not created
for that index (but get created during a cache hit and may remain in RAM
for some time after that).


> To get the metadata size add the per-object sizes (first number column)
> of HttpReply + MemObject + HttpHeaderEntry + all objects whose name
> starts with HttpHdr* + StoreEntry + all objects whose name starts with
> StoreMeta*.

AFAICT, StoreEntry and LruNode (or equivalent) are the only structures
created for the cache_dir index. All other structures are not relevant
in that scope.


> Though nowdays the 2^27 objects per cache_dir limitation is proving to
> be far more restrictive than the RAM index size. 

Agreed, but YMMV.


> So depending on your
> "Mean Object Size" you may find yourself limited to only using 100 GB or
> less of a TB HDD.

... unless you use multiple cache_dirs per HDD.

Alex.


From bloggerrazorcross at gmail.com  Wed Jul 12 22:08:03 2017
From: bloggerrazorcross at gmail.com (Razor Cross)
Date: Wed, 12 Jul 2017 17:08:03 -0500
Subject: [squid-users] Squid caching bad objects
In-Reply-To: <8b35b779-9a8d-5b81-88ee-3dcd29e8e835@measurement-factory.com>
References: <CANRy4AV5n4m8PC7fKQJfaZboKxyUG7o7ASuJABRhVfFFfmzjhg@mail.gmail.com>
 <a494df2a-eb3d-acd4-ea08-2bc615348c45@measurement-factory.com>
 <CANRy4AU=5VR+8kmcFdKLbpnxbdTgUCvRopxHV5ypD+0JmujOAA@mail.gmail.com>
 <bdb4c8bc-8d14-b442-53d0-e39ac4b5470e@measurement-factory.com>
 <CANRy4AVDOhpG6X-u2OKkPEMC0fhDmPvjubDwNU_fSHo3kzJeQw@mail.gmail.com>
 <CANRy4AXzq7j=vd+TQCcdqRqOvnRCF7cg22sd0ciTTsEO6hqyng@mail.gmail.com>
 <33337f8f-7de2-256d-80c4-2a7a9337b82f@treenet.co.nz>
 <00b44675-f47e-1d37-1eb3-e0be23276746@measurement-factory.com>
 <CANRy4AUzBmWWipJ_YuebnypftHT5TxtntMpPf1e=so1KUVruFA@mail.gmail.com>
 <8b35b779-9a8d-5b81-88ee-3dcd29e8e835@measurement-factory.com>
Message-ID: <CANRy4AUmS7TM3RZ57fVFfUWZHigKxXPQS5Sj0dERYO_mV_+7EQ@mail.gmail.com>

Thanks Alex. Is there any way we can prevent squid from caching chunked
encoding response?

On Fri, Jul 7, 2017 at 12:40 AM, Alex Rousskov <
rousskov at measurement-factory.com> wrote:

> On 07/06/2017 10:06 PM, Razor Cross wrote:
> > We have disabled eCAP support as part of squid compilation . Is it
> > related to this issue ?
>
> No: Assuming my guess about the underlying problem is correct, eCAP is
> irrelevant here.
>
> Alex.
>
>
> > On Thu, Jul 6, 2017 at 10:09 PM, Alex Rousskov wrote:
> >
> >     On 07/06/2017 07:01 PM, Amos Jeffries wrote:
> >
> >     > AFAIK Squid currently should not be caching these objects at all.
> Or
> >     > when it does use the disk cache as a temporary storage (eg for very
> >     > large objects) marking them for immediate discard when the abort
> >     > happens.
> >
> >     Yes, and the corresponding bug report, with a solution blueprint is
> at
> >     http://bugs.squid-cache.org/show_bug.cgi?id=4735
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170712/26dd86c0/attachment.htm>

From squid3 at treenet.co.nz  Wed Jul 12 22:17:14 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 13 Jul 2017 10:17:14 +1200
Subject: [squid-users] Squid caching bad objects
In-Reply-To: <CANRy4AUmS7TM3RZ57fVFfUWZHigKxXPQS5Sj0dERYO_mV_+7EQ@mail.gmail.com>
References: <CANRy4AV5n4m8PC7fKQJfaZboKxyUG7o7ASuJABRhVfFFfmzjhg@mail.gmail.com>
 <a494df2a-eb3d-acd4-ea08-2bc615348c45@measurement-factory.com>
 <CANRy4AU=5VR+8kmcFdKLbpnxbdTgUCvRopxHV5ypD+0JmujOAA@mail.gmail.com>
 <bdb4c8bc-8d14-b442-53d0-e39ac4b5470e@measurement-factory.com>
 <CANRy4AVDOhpG6X-u2OKkPEMC0fhDmPvjubDwNU_fSHo3kzJeQw@mail.gmail.com>
 <CANRy4AXzq7j=vd+TQCcdqRqOvnRCF7cg22sd0ciTTsEO6hqyng@mail.gmail.com>
 <33337f8f-7de2-256d-80c4-2a7a9337b82f@treenet.co.nz>
 <00b44675-f47e-1d37-1eb3-e0be23276746@measurement-factory.com>
 <CANRy4AUzBmWWipJ_YuebnypftHT5TxtntMpPf1e=so1KUVruFA@mail.gmail.com>
 <8b35b779-9a8d-5b81-88ee-3dcd29e8e835@measurement-factory.com>
 <CANRy4AUmS7TM3RZ57fVFfUWZHigKxXPQS5Sj0dERYO_mV_+7EQ@mail.gmail.com>
Message-ID: <4b496d41-89c1-59f2-a24a-9a649010c45e@treenet.co.nz>

On 13/07/17 10:08, Razor Cross wrote:
> Thanks Alex. Is there any way we can prevent squid from caching chunked 
> encoding response?
> 

This should do that:

  acl chunked rep_header Transfer-Encoding chunked
  store_miss deny chunked

Amos


From bugreporter2017 at gmail.com  Wed Jul 12 23:13:46 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Wed, 12 Jul 2017 16:13:46 -0700 (PDT)
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <201707121134.46511.Antony.Stone@squid.open.source.it>
References: <1499619540869-4683033.post@n4.nabble.com>
 <503494af-d2e4-db06-91fc-c5efa039d35e@gmail.com>
 <1499626481926-4683036.post@n4.nabble.com>
 <ba01d93c-d8d5-30b4-26c7-6145cdda6c77@gmail.com>
 <1499638965067-4683039.post@n4.nabble.com>
 <1ed45ea6-376c-105c-d808-94d7af9c75d0@gmail.com>
 <1499672747720-4683042.post@n4.nabble.com>
 <749fadf0-6b34-f1cc-9c1c-5f3c2304e3b4@gmail.com>
 <1499853336151-4683069.post@n4.nabble.com>
 <201707121134.46511.Antony.Stone@squid.open.source.it>
Message-ID: <1499901226113-4683087.post@n4.nabble.com>

Hi Antony,

If they effectively don't *distribute* their modifications... But we don't
know. Thank you so much for the clarification.

Kind Regards,



-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033p4683087.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From yvoinov at gmail.com  Wed Jul 12 23:36:56 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 13 Jul 2017 05:36:56 +0600
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <1499901226113-4683087.post@n4.nabble.com>
References: <1499619540869-4683033.post@n4.nabble.com>
 <503494af-d2e4-db06-91fc-c5efa039d35e@gmail.com>
 <1499626481926-4683036.post@n4.nabble.com>
 <ba01d93c-d8d5-30b4-26c7-6145cdda6c77@gmail.com>
 <1499638965067-4683039.post@n4.nabble.com>
 <1ed45ea6-376c-105c-d808-94d7af9c75d0@gmail.com>
 <1499672747720-4683042.post@n4.nabble.com>
 <749fadf0-6b34-f1cc-9c1c-5f3c2304e3b4@gmail.com>
 <1499853336151-4683069.post@n4.nabble.com>
 <201707121134.46511.Antony.Stone@squid.open.source.it>
 <1499901226113-4683087.post@n4.nabble.com>
Message-ID: <8f716d77-df9b-f268-b72d-e4df5219988f@gmail.com>



13.07.2017 5:13, bugreporter ?????:
> Hi Antony,
>
> If they effectively don't *distribute* their modifications... But we don't
> know. Thank you so much for the clarification.
We're not so brainless. Even we not threat GPL as religious dogma, we're
never distribute our solutions. Especially, as I said, this seems as
very close platform-specific (and platform is marginal), also, in fact,
this bug is gone in later branches. So we're don't care on this bug.
>
> Kind Regards,
>
>
>
> -----
> Bug Reporter Contributor
> OpenSource = Open-Minded
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033p4683087.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170713/a18cf968/attachment.sig>

From yvoinov at gmail.com  Wed Jul 12 23:48:44 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 13 Jul 2017 05:48:44 +0600
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <1499901226113-4683087.post@n4.nabble.com>
References: <1499619540869-4683033.post@n4.nabble.com>
 <503494af-d2e4-db06-91fc-c5efa039d35e@gmail.com>
 <1499626481926-4683036.post@n4.nabble.com>
 <ba01d93c-d8d5-30b4-26c7-6145cdda6c77@gmail.com>
 <1499638965067-4683039.post@n4.nabble.com>
 <1ed45ea6-376c-105c-d808-94d7af9c75d0@gmail.com>
 <1499672747720-4683042.post@n4.nabble.com>
 <749fadf0-6b34-f1cc-9c1c-5f3c2304e3b4@gmail.com>
 <1499853336151-4683069.post@n4.nabble.com>
 <201707121134.46511.Antony.Stone@squid.open.source.it>
 <1499901226113-4683087.post@n4.nabble.com>
Message-ID: <2b070782-1476-d771-99a0-750f91931ff6@gmail.com>



13.07.2017 5:13, bugreporter ?????:
> Hi Antony,
>
> If they effectively don't *distribute* their modifications... But we don't
> know. Thank you so much for the clarification.
And in general, making such statements, you need to be ready to prove
them in court.

When you can prove that we are distributing software for commercial
purposes with patches that are not given to the community, then you will
throw such statements.

Until this is proven - I suggest you apologize.
>
> Kind Regards,
>
>
>
> -----
> Bug Reporter Contributor
> OpenSource = Open-Minded
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033p4683087.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170713/0413e06b/attachment.sig>

From bugreporter2017 at gmail.com  Thu Jul 13 07:38:19 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Thu, 13 Jul 2017 00:38:19 -0700 (PDT)
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <2b070782-1476-d771-99a0-750f91931ff6@gmail.com>
References: <1499626481926-4683036.post@n4.nabble.com>
 <ba01d93c-d8d5-30b4-26c7-6145cdda6c77@gmail.com>
 <1499638965067-4683039.post@n4.nabble.com>
 <1ed45ea6-376c-105c-d808-94d7af9c75d0@gmail.com>
 <1499672747720-4683042.post@n4.nabble.com>
 <749fadf0-6b34-f1cc-9c1c-5f3c2304e3b4@gmail.com>
 <1499853336151-4683069.post@n4.nabble.com>
 <201707121134.46511.Antony.Stone@squid.open.source.it>
 <1499901226113-4683087.post@n4.nabble.com>
 <2b070782-1476-d771-99a0-750f91931ff6@gmail.com>
Message-ID: <1499931499439-4683090.post@n4.nabble.com>

Dear Yuri,

My goal is not to hurt anybody here and if you consider that I offended you
(or rather your "sponsor") I apologize. So sorry! The fact of the matter is
that the conversation at http://bugs.squid-cache.org/show_bug.cgi?id=4597
caught my attention and it was the first time I saw such a discussion on an
open source technical forum.

Thanks to you and exchanges with others I understand better the GPL today.

Kind Regards,



-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033p4683090.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From skupko.sk at gmail.com  Thu Jul 13 09:21:15 2017
From: skupko.sk at gmail.com (Peter Viskup)
Date: Thu, 13 Jul 2017 11:21:15 +0200
Subject: [squid-users] Log to syslog issues with syslog priority
Message-ID: <CAPa6PsHhXdmnC7X=Xv-d2tiFZ9v1GntZYQcY535HcV5uHj2Fkw@mail.gmail.com>

Tried to configure logging to syslog directly and experiencing issues
with not accepted syslog priority assigned in config files.

This is the configuration:
~# grep -E '^access_log|^icap_log|logstrmfilter' /etc/squid3/squid.conf
access_log syslog:local7.notice logformat=combined3
acl logstrmfilter http_status 403 500-
acl logstrmfilter2 http_status 200 404 300-304
access_log syslog:local7.err logformat=squidstrm logstrmfilter
access_log syslog:local7.warning logformat=squidstrm !logstrmfilter2
icap_log syslog:local7.info icap_squid

With aim to log all access entries to local7.notice, some errors to
local7.err and not retrievable requests to local7.warning in addition
to log ICAP to local7.info.

But the syslog receives access logs at local7.debug, ICAP and the
error filtered logs together at local7.info.
Squid version 3.5.21.
I want to forward those messages to remote syslog server for further
processing. This is the motivation of this setup.

Is there something I misunderstood in the access_log documentation?
Seems there is no ACL filtering effective for syslog module.

Peter


From yvoinov at gmail.com  Thu Jul 13 10:22:45 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 13 Jul 2017 16:22:45 +0600
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <1499931499439-4683090.post@n4.nabble.com>
References: <1499626481926-4683036.post@n4.nabble.com>
 <ba01d93c-d8d5-30b4-26c7-6145cdda6c77@gmail.com>
 <1499638965067-4683039.post@n4.nabble.com>
 <1ed45ea6-376c-105c-d808-94d7af9c75d0@gmail.com>
 <1499672747720-4683042.post@n4.nabble.com>
 <749fadf0-6b34-f1cc-9c1c-5f3c2304e3b4@gmail.com>
 <1499853336151-4683069.post@n4.nabble.com>
 <201707121134.46511.Antony.Stone@squid.open.source.it>
 <1499901226113-4683087.post@n4.nabble.com>
 <2b070782-1476-d771-99a0-750f91931ff6@gmail.com>
 <1499931499439-4683090.post@n4.nabble.com>
Message-ID: <7539e5d0-f6df-efa1-6b26-9a0cf91fd53e@gmail.com>

Apologies are accepted. No problems. We ourselves were not pleased that
we did not have enough time to write the correct and beautiful patch. At
that time it was quite an unpleasant problem. The bottom line is that
it's very specific and for me it's a big surprise that something similar
happened again on another platform. Fortunately, on current versions
there is no problem.


13.07.2017 13:38, bugreporter ?????:
> Dear Yuri,
>
> My goal is not to hurt anybody here and if you consider that I offended you
> (or rather your "sponsor") I apologize. So sorry! The fact of the matter is
> that the conversation at http://bugs.squid-cache.org/show_bug.cgi?id=4597
> caught my attention and it was the first time I saw such a discussion on an
> open source technical forum.
>
> Thanks to you and exchanges with others I understand better the GPL today.
>
> Kind Regards,
>
>
>
> -----
> Bug Reporter Contributor
> OpenSource = Open-Minded
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033p4683090.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170713/de0b8e77/attachment.sig>

From bugreporter2017 at gmail.com  Thu Jul 13 13:27:17 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Thu, 13 Jul 2017 06:27:17 -0700 (PDT)
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <7539e5d0-f6df-efa1-6b26-9a0cf91fd53e@gmail.com>
References: <1499638965067-4683039.post@n4.nabble.com>
 <1ed45ea6-376c-105c-d808-94d7af9c75d0@gmail.com>
 <1499672747720-4683042.post@n4.nabble.com>
 <749fadf0-6b34-f1cc-9c1c-5f3c2304e3b4@gmail.com>
 <1499853336151-4683069.post@n4.nabble.com>
 <201707121134.46511.Antony.Stone@squid.open.source.it>
 <1499901226113-4683087.post@n4.nabble.com>
 <2b070782-1476-d771-99a0-750f91931ff6@gmail.com>
 <1499931499439-4683090.post@n4.nabble.com>
 <7539e5d0-f6df-efa1-6b26-9a0cf91fd53e@gmail.com>
Message-ID: <1499952437725-4683093.post@n4.nabble.com>

I can fully understand!
Warm Regards,



-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Chaining-icap-and-ecap-services-FATAL-Received-Segment-Violation-dying-tp4683033p4683093.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From bugreporter2017 at gmail.com  Thu Jul 13 15:09:11 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Thu, 13 Jul 2017 08:09:11 -0700 (PDT)
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
References: <1499855494036-4683072.post@n4.nabble.com>
 <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
Message-ID: <1499958551698-4683094.post@n4.nabble.com>

Hi Amos,

Thank you so much for your guidance. You have no idea how the *key*
information you shared here is important to me. As your recommendation I'll
do my own calculation based on my own cache ASAP.

But before doing my own calculation as you answered *No* to my second
question, I just wanted to better understand the rough estimation on that
wiki page. I think that I know the difference between the index space size
in RAM, the cache_mem size (in RAM) and stored objects size in cache_dir(s)
(on Disks). Now if the rough estimation is still valid and it is not based
on the default value for store_avg_object_size (13 K), on what (stored on
disk) average value is it based?

Regarding my question 4, regardless of the squid configuration do, you have
an idea about the average size of an object on the Web? Suppose that we
don't have a cache at all. The mean object size on my own cache is very
close to yours : 101 KB. According to a small ISP the average object size
that they can observe is about 850 KB... According to some statistics on
some website the average object size on the Web is about 24 KB today. I'm
lost...

Kind Regards,




-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/HDD-RAM-Capacity-vs-store-avg-object-size-tp4683072p4683094.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From bugreporter2017 at gmail.com  Thu Jul 13 16:13:44 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Thu, 13 Jul 2017 09:13:44 -0700 (PDT)
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
References: <1499855494036-4683072.post@n4.nabble.com>
 <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
Message-ID: <1499962424384-4683095.post@n4.nabble.com>

Hi Amos,

When you say:

/"The rest is harder. You need to do a scan of a disk cache separating the 
message headers - both counting the number of items found and total size 
of the headers processed. Multiplying the metadata size by the number of 
objects in the cache and adding the total message header size."
/
What do you mean by message header in this context? Just the first line in
each file or all HTTP headers (head of each file until the first \r\n)? If
you mean all HTTP headers and if I correctly understood what Alex says, HTTP
headers are not taken into the consideration in this context. Therefore
should I eliminate them in the calculation?

Warm Regards,



-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/HDD-RAM-Capacity-vs-store-avg-object-size-tp4683072p4683095.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From bugreporter2017 at gmail.com  Thu Jul 13 16:17:40 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Thu, 13 Jul 2017 09:17:40 -0700 (PDT)
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <214668d4-013a-d8e2-1874-90fb499c85d1@measurement-factory.com>
References: <1499855494036-4683072.post@n4.nabble.com>
 <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
 <214668d4-013a-d8e2-1874-90fb499c85d1@measurement-factory.com>
Message-ID: <1499962660577-4683096.post@n4.nabble.com>

Hi Alex,

Thank you for your contribution to this post. I see that you answered
roughly YES to my question #2. I think that we agree... But what is this
mean value size? Do you have any update to share please?

According to your answer, HTTP headers are not part of the in-memory index
and we have to consider StoreEntry and LruNode (or equivalent) only. Can you
please be more specific about what inputs of cachemgr "mem" report should we
take into account?

Warm Regards,



-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/HDD-RAM-Capacity-vs-store-avg-object-size-tp4683072p4683096.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Thu Jul 13 17:03:20 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Thu, 13 Jul 2017 11:03:20 -0600
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <1499962660577-4683096.post@n4.nabble.com>
References: <1499855494036-4683072.post@n4.nabble.com>
 <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
 <214668d4-013a-d8e2-1874-90fb499c85d1@measurement-factory.com>
 <1499962660577-4683096.post@n4.nabble.com>
Message-ID: <04583e1e-11ef-6d73-706d-9049ad7d5897@measurement-factory.com>

On 07/13/2017 10:17 AM, bugreporter wrote:

> But what is this mean value size? Do you have any update to share please?

I do not know what value the wiki page authors used, but I suspect it
was close to 13K. I believe Amos has already suggested that you use the
actual cachable response size mean from your environment, and I agree
with that suggestion (although it is not trivial to follow). There is no
and cannot be an "authoritative" mean value that works well for all
environments.


> According to your answer, HTTP headers are not part of the in-memory index
> and we have to consider StoreEntry and LruNode (or equivalent) only. Can you
> please be more specific about what inputs of cachemgr "mem" report should we
> take into account?

Not without doing research. I also hesitate recommending mgr:mem output
for folks that cannot or do not want to find answers about it by
studying the associated code themselves -- it is just too easy to
misinterpret those low-level stats!

You may be able to figure it out on your own without relying on
low-level stats by disabling the memory cache, filling your disk cache
with, say, 1'000, 10'000, and then 100'000 identical or similar objects,
and measuring memory usage growth. You can then try to confirm your
findings by comparing them with the previously collected mgr:info,
mgr:storedir, and mgr:mem output for each stage of the experiment.

Alex.


From bugreporter2017 at gmail.com  Fri Jul 14 08:11:44 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Fri, 14 Jul 2017 01:11:44 -0700 (PDT)
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <04583e1e-11ef-6d73-706d-9049ad7d5897@measurement-factory.com>
References: <1499855494036-4683072.post@n4.nabble.com>
 <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
 <214668d4-013a-d8e2-1874-90fb499c85d1@measurement-factory.com>
 <1499962660577-4683096.post@n4.nabble.com>
 <04583e1e-11ef-6d73-706d-9049ad7d5897@measurement-factory.com>
Message-ID: <1500019904462-4683098.post@n4.nabble.com>

Hi Alex,

By doing so I'll get a new (or the same) rough estimation which is not what
I'm really looking for. Actually I need to have a formula based on the mean
object size so I can periodically (with a cron) get the mean object size and
with the help of that formula reconfigure Squid accordingly. The
reconfiguration will be as follow:

- If the mean object size is too low compared to the RAM/HDD ratio then I
can reduce the HDD usage by Squid (cache_dir ...  Low-Mbytes-Size ...). A
reload of the new squid configuration should be sufficient. Isn't it? Or
I'll need to restart Squid?

- If the mean object size is to high compared to the RAM/HDD ratio then I
can fully use the HDD for Squid and do some optimizations (for instance as
the RAM will not be fully used by the in-memory index I can use it for the
cache_mem).

I need this industrialization to be able to install Squid on heterogenous
environments (with different mean object size) so I'll not have to propose a
new configuration whenever I install Squid.

Kind Regards,



-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/HDD-RAM-Capacity-vs-store-avg-object-size-tp4683072p4683098.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Fri Jul 14 12:37:27 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 14 Jul 2017 15:37:27 +0300
Subject: [squid-users] What would be the maximum ufs\aufs cache_dir objects?
Message-ID: <06f501d2fc9d$f39292a0$dab7b7e0$@ngtech.co.il>

What would be the maximum ufs\aufs cache_dir objects?
Let say I have unlimited disk space and inodes and RAM, what would be the
maximum objects I can store on a single ufs\aufs cache_dir?
It's very easy to test but first I want to understand what might be the
limit?
I am asking since the structure is top level dirs and sub level dirs, so if
I want to get the maximum object capacity (assuming each one would use
0.5kb)?
If there is a known number I want to know it.

Thanks in advance,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il






From max at jjoplc.com  Fri Jul 14 15:11:54 2017
From: max at jjoplc.com (Max Ashton)
Date: Fri, 14 Jul 2017 15:11:54 +0000
Subject: [squid-users] Squid Proxy Server ssl-bump blocking Web Socket
	connections
In-Reply-To: <HE1PR0501MB27808C7605D14D3CC76F913CD1AD0@HE1PR0501MB2780.eurprd05.prod.outlook.com>
References: <HE1PR0501MB27808C7605D14D3CC76F913CD1AD0@HE1PR0501MB2780.eurprd05.prod.outlook.com>
Message-ID: <HE1PR0501MB278009D2F9031E87CD899A8DD1AD0@HE1PR0501MB2780.eurprd05.prod.outlook.com>

Dear squid-users,

I have just set up Squid Server 3.5.26 on Ubuntu 16.04.2 LTS configured with SSL-bump. Http and Https is working fine but any web services that requires Web Sockets fails with the error:

WebSocket connection to 'ws://speedtest.b4rn.org.uk:8080/ws' failed: Error during WebSocket handshake: net::ERR_CONNECTION_RESET

For example, a broadband speed test.

>From the mail list archive I found a post relating to whatsapp web sockets, sadly the suggested configuration did not work for me.

I have added the following lines to my squid configuration in an attempt to force a direct connection and prevent SSL caching for web socket connections.

#Temporarily allow all connections for debugging http_access allow all

acl bump-bypass dstdomain 192.168.0.245 .speedtest.net # URL's contains ws, most web socket urls do, allowing all for testing acl ssl-web-sockets SSL::server_name_regex \/ws

ssl_bump step1 at_step SslBump1
ssl_bump peek step1
ssl_bump splice bump-bypass ssl-web-sockets tcp-web-sockets

#I Read that there was a bug in bump that required !explicity #for splice to work for web sockets ssl_bump bump !ssl-web-sockets all

#just bump all doesn't work either
#ssl_bump bump all

If I disable ssl-bump  and don't decrypt encrypted traffic (http_port 3128 instead of http_port 3128 ssl-bump ...) everything works fine.

How can I configure squid to allow web socket connections?

Thanks

Kind Regards
Max 


From squid3 at treenet.co.nz  Fri Jul 14 15:58:11 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 15 Jul 2017 03:58:11 +1200
Subject: [squid-users] Squid Proxy Server ssl-bump blocking Web Socket
 connections
In-Reply-To: <HE1PR0501MB278009D2F9031E87CD899A8DD1AD0@HE1PR0501MB2780.eurprd05.prod.outlook.com>
References: <HE1PR0501MB27808C7605D14D3CC76F913CD1AD0@HE1PR0501MB2780.eurprd05.prod.outlook.com>
 <HE1PR0501MB278009D2F9031E87CD899A8DD1AD0@HE1PR0501MB2780.eurprd05.prod.outlook.com>
Message-ID: <491fb718-5c5d-2097-2fac-39a163a48e63@treenet.co.nz>

On 15/07/17 03:11, Max Ashton wrote:
> Dear squid-users,
> 
> I have just set up Squid Server 3.5.26 on Ubuntu 16.04.2 LTS configured with SSL-bump. Http and Https is working fine but any web services that requires Web Sockets fails with the error:

To support intercepting non-HTTP traffic on port 443 you need Squid-4 
which provides the 
<http://www.squid-cache.org/Doc/config/on_unsupported_protocol/> feature.

Amos


From rousskov at measurement-factory.com  Fri Jul 14 16:11:45 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 14 Jul 2017 10:11:45 -0600
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <1500019904462-4683098.post@n4.nabble.com>
References: <1499855494036-4683072.post@n4.nabble.com>
 <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
 <214668d4-013a-d8e2-1874-90fb499c85d1@measurement-factory.com>
 <1499962660577-4683096.post@n4.nabble.com>
 <04583e1e-11ef-6d73-706d-9049ad7d5897@measurement-factory.com>
 <1500019904462-4683098.post@n4.nabble.com>
Message-ID: <af876c61-59fb-f43e-30af-f97ae975a65d@measurement-factory.com>

On 07/14/2017 02:11 AM, bugreporter wrote:

> By doing so I'll get a new (or the same) rough estimation which is not what
> I'm really looking for.

You will get an accurate-enough formula, which is what you should be
looking for.


> Actually I need to have a formula based on the mean object size

That is what I am trying to give you. Sorry if I was not explicit
enough. Idle Squid memory requirements can be computed using the
following formula:

    RAM used for HTTP caching purposes =
        RAM used by all cache indexes (cache_dirs and cache_mem) +
        cache_mem

where

    RAM used by a single cache index = C + v*n

where

    C is an unknown constant representing the size of in-RAM overhead
      of having a single (empty) cache (cache_dir or cache_mem).
      C depends on Squid build and configuration.
      C is normally a lot less than v*n so you might just ignore it.

    v is an unknown constant representing the size of in-RAM overhead
      of indexing a single cache object
      v depends on Squid build (e.g., 32 vs 64bit)
      v should be close to the sum of StoreEntry and LruNode sizes.

    n is the number of objects in the cache, which you can estimate by
      dividing the cache size by the mean cached object size.

The experiments I suggested can be used to estimate the C and v
constants required to compute the "RAM used by cache indexes" component.
You can measure/estimate/configure/control everything else in the formula.

The formula works well for large numbers of n, where various rounding
effects become negligible.

How you use this formula/model is up to you.

If your experiments prove the formula wrong, please discuss!


Thank you,

Alex.
P.S. Please note that a busy Squid also consumes memory for in-transit
transactions and other caches. If you know how much Squid consumes for
HTTP caching, then you can effectively measure other overheads, which
will also vary from one deployment environment to another.


From rousskov at measurement-factory.com  Fri Jul 14 16:17:47 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 14 Jul 2017 10:17:47 -0600
Subject: [squid-users] What would be the maximum ufs\aufs cache_dir
 objects?
In-Reply-To: <06f501d2fc9d$f39292a0$dab7b7e0$@ngtech.co.il>
References: <06f501d2fc9d$f39292a0$dab7b7e0$@ngtech.co.il>
Message-ID: <29bf2281-8d48-09cb-3de9-100c21f14ba1@measurement-factory.com>

On 07/14/2017 06:37 AM, Eliezer Croitoru wrote:
> What would be the maximum ufs\aufs cache_dir objects?

The maximum number of objects currently supported by any single
cache_dir (rock or ufs-based) is approximately 16777215.

> src/store/forward.h:enum { SwapFilenMax = 0xFFFFFF }; // keep in sync with StoreEntry::swap_filen


There is no practical limit for the number of cache_dirs although Squid
does use linear search through cache_dirs in some cases/configurations.

Alex.


From squid3 at treenet.co.nz  Fri Jul 14 16:47:07 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 15 Jul 2017 04:47:07 +1200
Subject: [squid-users] What would be the maximum ufs\aufs cache_dir
 objects?
In-Reply-To: <06f501d2fc9d$f39292a0$dab7b7e0$@ngtech.co.il>
References: <06f501d2fc9d$f39292a0$dab7b7e0$@ngtech.co.il>
Message-ID: <e0d12d09-4d0e-3ea9-d442-e14163a5d271@treenet.co.nz>

On 15/07/17 00:37, Eliezer Croitoru wrote:
> What would be the maximum ufs\aufs cache_dir objects? > Let say I have unlimited disk space and inodes and RAM, what would be the
> maximum objects I can store on a single ufs\aufs cache_dir?


One UFS cache_dir can hold a maximum of (2^27)-1 safely.

Technically it does not need the -1, but the old C code uses a mess of 
signed and unsigned types to store the has ID value. Some (not all) 
people hit assertions when the cache reaches that boundary.


> It's very easy to test but first I want to understand what might be the
> limit?

The index hash entries are stored as a 32-bit bitmask (sfileno) - with 5 
bits for cache_dir ID and 27 bits for hash of the file details.


> I am asking since the structure is top level dirs and sub level dirs, so if
> I want to get the maximum object capacity (assuming each one would use
> 0.5kb)?

The L1/L2 separation is to cope with old filesystems that had limited 
number of files in a directory.

Apparently, that limitation is no longer relevant with the current 
generation of filesystems.


Amos


From squid3 at treenet.co.nz  Fri Jul 14 16:53:18 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 15 Jul 2017 04:53:18 +1200
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <1499962424384-4683095.post@n4.nabble.com>
References: <1499855494036-4683072.post@n4.nabble.com>
 <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
 <1499962424384-4683095.post@n4.nabble.com>
Message-ID: <d80d0cee-bd31-4336-d37c-3dba876820a5@treenet.co.nz>

On 14/07/17 04:13, bugreporter wrote:
> Hi Amos,
> 
> When you say:
> 
> /"The rest is harder. You need to do a scan of a disk cache separating the
> message headers - both counting the number of items found and total size
> of the headers processed. Multiplying the metadata size by the number of
> objects in the cache and adding the total message header size."
> /
> What do you mean by message header in this context? Just the first line in
> each file or all HTTP headers (head of each file until the first \r\n)? If
> you mean all HTTP headers and if I correctly understood what Alex says, HTTP
> headers are not taken into the consideration in this context. Therefore
> should I eliminate them in the calculation?
> 

Thats what I meant, but as Alex pointed out I was wrong. StoreEntry only 
pulls a small bit of the cached meta stuff into the index, and that is 
counted directly in the StoreEntry object size. The rest of it is only 
pulled in when things are moved to the cache_mem space for delivery to a 
client.

Amos


From squid3 at treenet.co.nz  Fri Jul 14 17:17:33 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 15 Jul 2017 05:17:33 +1200
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <7539e5d0-f6df-efa1-6b26-9a0cf91fd53e@gmail.com>
References: <1499626481926-4683036.post@n4.nabble.com>
 <ba01d93c-d8d5-30b4-26c7-6145cdda6c77@gmail.com>
 <1499638965067-4683039.post@n4.nabble.com>
 <1ed45ea6-376c-105c-d808-94d7af9c75d0@gmail.com>
 <1499672747720-4683042.post@n4.nabble.com>
 <749fadf0-6b34-f1cc-9c1c-5f3c2304e3b4@gmail.com>
 <1499853336151-4683069.post@n4.nabble.com>
 <201707121134.46511.Antony.Stone@squid.open.source.it>
 <1499901226113-4683087.post@n4.nabble.com>
 <2b070782-1476-d771-99a0-750f91931ff6@gmail.com>
 <1499931499439-4683090.post@n4.nabble.com>
 <7539e5d0-f6df-efa1-6b26-9a0cf91fd53e@gmail.com>
Message-ID: <8b0e0a1f-ce1f-d6ca-089c-62250c946185@treenet.co.nz>

On 13/07/17 22:22, Yuri wrote:
> Apologies are accepted. No problems. We ourselves were not pleased that
> we did not have enough time to write the correct and beautiful patch. At
> that time it was quite an unpleasant problem. The bottom line is that
> it's very specific and for me it's a big surprise that something similar
> happened again on another platform. Fortunately, on current versions
> there is no problem.
> 

That reminds me. I've been meaning to get you to confirm the 4.0.19 you 
said worked was without the extra patch applied.

If that is the case then the bug 4597 report can finally be closed.

Amos


From rousskov at measurement-factory.com  Fri Jul 14 17:48:58 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Fri, 14 Jul 2017 11:48:58 -0600
Subject: [squid-users] What would be the maximum ufs\aufs cache_dir
 objects?
In-Reply-To: <e0d12d09-4d0e-3ea9-d442-e14163a5d271@treenet.co.nz>
References: <06f501d2fc9d$f39292a0$dab7b7e0$@ngtech.co.il>
 <e0d12d09-4d0e-3ea9-d442-e14163a5d271@treenet.co.nz>
Message-ID: <d08145b1-6c4c-0b1e-26b3-78559563f4ed@measurement-factory.com>

On 07/14/2017 10:47 AM, Amos Jeffries wrote:

> One UFS cache_dir can hold a maximum of (2^27)-1 safely. 

You probably meant to say (2^25)-1 but the actual number is (2^24)-1
because the sfileno is signed. This is why you get 16'777'215 (a.k.a.
0xFFFFFF) as the actual limit.


> The index hash entries are stored as a 32-bit bitmask (sfileno) - with 5
> bits for cache_dir ID and 27 bits for hash of the file details.

The cache index entries are hashed on their keys, not file numbers (of
any kind). The index entry is using 25 bits for the file number, but
IIRC, those 25 bits are never merged/combined with the 7 bits of the
cache_dir ID in any meaningful way.


Alex.

> typedef signed_int32_t sfileno;>     sfileno swap_filen:25; // keep in sync with SwapFilenMax
>     sdirno swap_dirn:7;
> enum { SwapFilenMax = 0xFFFFFF }; // keep in sync with StoreEntry::swap_filen



From yvoinov at gmail.com  Fri Jul 14 21:44:08 2017
From: yvoinov at gmail.com (Yuri)
Date: Sat, 15 Jul 2017 03:44:08 +0600
Subject: [squid-users] Chaining icap and ecap services - FATAL: Received
 Segment Violation...dying.
In-Reply-To: <8b0e0a1f-ce1f-d6ca-089c-62250c946185@treenet.co.nz>
References: <1499626481926-4683036.post@n4.nabble.com>
 <ba01d93c-d8d5-30b4-26c7-6145cdda6c77@gmail.com>
 <1499638965067-4683039.post@n4.nabble.com>
 <1ed45ea6-376c-105c-d808-94d7af9c75d0@gmail.com>
 <1499672747720-4683042.post@n4.nabble.com>
 <749fadf0-6b34-f1cc-9c1c-5f3c2304e3b4@gmail.com>
 <1499853336151-4683069.post@n4.nabble.com>
 <201707121134.46511.Antony.Stone@squid.open.source.it>
 <1499901226113-4683087.post@n4.nabble.com>
 <2b070782-1476-d771-99a0-750f91931ff6@gmail.com>
 <1499931499439-4683090.post@n4.nabble.com>
 <7539e5d0-f6df-efa1-6b26-9a0cf91fd53e@gmail.com>
 <8b0e0a1f-ce1f-d6ca-089c-62250c946185@treenet.co.nz>
Message-ID: <f569098b-6984-d635-fa60-3411bcc4df6d@gmail.com>



14.07.2017 23:17, Amos Jeffries ?????:
> On 13/07/17 22:22, Yuri wrote:
>> Apologies are accepted. No problems. We ourselves were not pleased that
>> we did not have enough time to write the correct and beautiful patch. At
>> that time it was quite an unpleasant problem. The bottom line is that
>> it's very specific and for me it's a big surprise that something similar
>> happened again on another platform. Fortunately, on current versions
>> there is no problem.
>>
>
> That reminds me. I've been meaning to get you to confirm the 4.0.19
> you said worked was without the extra patch applied.
>
> If that is the case then the bug 4597 report can finally be closed.
>
> Amos
Yup, Amos. Both 4.0.19+ and 5.x works without this issue. Seems ok.
AFAIK after discovering code - should never occurs again.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170715/00b9b309/attachment.sig>

From xeron.oskom at gmail.com  Fri Jul 14 23:28:52 2017
From: xeron.oskom at gmail.com (Ivan Larionov)
Date: Fri, 14 Jul 2017 16:28:52 -0700
Subject: [squid-users] Huge amount of time_wait connections after
 upgrade from v2 to v3
In-Reply-To: <CAHvB88wSq6=nT6FPNdbopiAxfiZhz5zqOAvfa4_aoiYmAq8QKQ@mail.gmail.com>
References: <CAHvB88x+nNYMtmNZWqrZo-p==UykYDj5dZF+5N1eC3rGR8ybGw@mail.gmail.com>
 <ca593b00-8727-c816-8169-d6c528c51d93@treenet.co.nz>
 <CAHvB88w4a6n3uoQZ5UZOi4NH0cpYtoVBD3dZtO5sFcDbRY_Bag@mail.gmail.com>
 <f418e53a-ed5f-e4db-9654-2aa31ad83c57@treenet.co.nz>
 <22125AC6-0C7D-459E-8BF1-6C9F4EE7A92C@gmail.com>
 <4c09a163-186c-83c5-30a6-489f1ba1b67c@treenet.co.nz>
 <CAHvB88wSq6=nT6FPNdbopiAxfiZhz5zqOAvfa4_aoiYmAq8QKQ@mail.gmail.com>
Message-ID: <CAHvB88yjPnXOv2qPFhErhLiW=TmqJpvfotsvDGFiSU7x2pQfXQ@mail.gmail.com>

Ok, mystery solved.

Patch "HTTP: do not allow Proxy-Connection to override Connection header"
changes the behavior. And we indeed send from our clients:

Connection: close
Proxy-Connection: Keep-Alive


On Sat, Jul 8, 2017 at 9:51 AM, Ivan Larionov <xeron.oskom at gmail.com> wrote:

> RPS didn't change. Throughput didn't change. Our prod load is 200-700 RPS
> per server (changes during the day) and my load test load was constant 470
> RPS.
>
> Clients didn't change. Doesn't matter if they use HTTP 1.1 or 1.0, because
> the only thing which changed is squid version. And as I figured out, it's
> not actually about 2.7 to 3.5 update, it's all about difference between
> 3.5.20 and 3.5.21.
>
> I'm sorry but anything you say about throughput doesn't make any sense.
> Load pattern didn't change. Squid still handles the same amount of requests.
>
> I think I'm going to load test every patch applied to 3.5.21 from this
> page: http://www.squid-cache.org/Versions/v3/3.5/
> changesets/SQUID_3_5_21.html so I'll be able to point to exact change
> which introduced this behavior. I'll try to do it during the weekend or may
> be on Monday.
>
> On Sat, Jul 8, 2017 at 5:46 AM, Amos Jeffries <squid3 at treenet.co.nz>
> wrote:
>
>> On 08/07/17 02:06, Ivan Larionov wrote:
>>
>>> Thank you for the fast reply.
>>>
>>> On Jul 7, 2017, at 01:10, Amos Jeffries <squid3 at treenet.co.nz> wrote:
>>>>
>>>> On 07/07/17 13:55, Ivan Larionov wrote:
>>>>>
>>>> >>>
>>
>>> However I assumed that this is a bug and that I can find older version
>>>>> which worked fine. I started testing from 3.1.x all the way to 3.5.26 and
>>>>> this is what I found:
>>>>> * All versions until 3.5.21 work fine. There no issues with huge
>>>>> amount of TIME_WAIT connections under load.
>>>>> * 3.5.20 is the latest stable version.
>>>>> * 3.5.21 is the first broken version.
>>>>> * 3.5.23, 3.5.25, 3.5.26 are broken as well.
>>>>> This effectively means that bug is somewhere in between 3.5.20 and
>>>>> 3.5.21.
>>>>> I hope this helps and I hope you'll be able to find an issue. If you
>>>>> can create a bug report based on this information and post it here it would
>>>>> be awesome.
>>>>>
>>>>
>>>> The changes in 3.5.21 were fixes to some common crashes and better
>>>> caching behaviour. So I expect at least some of the change is due to higher
>>>> traffic throughput on proxies previously restricted by those problems.
>>>>
>>>>
>>> I can't imagine how throughput increase could result in 500 times more
>>> TIME_WAIT connections count.
>>>
>>>
>> More requests per second generally means more TCP connections churning.
>>
>> Also when going from Squid-2 to Squid-3 there is a change from HTTP/1.0
>> to HTTP/1.1 and the accompanying switch from MISS to near-HIT
>> revalidations. Revalidations usually only have headers without payload so
>> the same bytes/sec can contain orders more magnitude of those than MISS -
>> which is the point of having them.
>>
>>
>> In our prod environment when we updated from 2.7.x to 3.5.25 we saw
>>> increase from 100 to 10000. This is 100x.
>>>
>>>
>> Compared to what RPS change? Given the above traffic change this may be
>> reasonable for a v2 to v3 jump. Or own very rough tests on old hardware lab
>> tests have shown rates for Squid-2 at ~900 RPS and Squid-3 at around 1900
>> RPS.
>>
>>
>> When I was load testing different versions yesterday I was always sending
>>> the same amount of RPS to them. Update from 3.5.20 to 3.5.21 resulted in
>>> jump from 20 to 10000 TIME_WAIT count. This is 500x.
>>>
>>> I know that time_wait is fine in general. Until you have too many of
>>> them.
>>>
>>>
>> At this point I'd check that your testing software supports HTTP/1.1
>> pipelines. It may be giving you worst-case results with per-message TCP
>> churn rather than what will occur normally (pipelines of N requests per TCP
>> connection).
>> Though seeing such a jump between Squid-3 releases is worrying.
>>
>> Amos
>>
>
>
>
> --
> With best regards, Ivan Larionov.
>



-- 
With best regards, Ivan Larionov.
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170714/57761b3f/attachment.htm>

From squid3 at treenet.co.nz  Sat Jul 15 18:06:33 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 16 Jul 2017 06:06:33 +1200
Subject: [squid-users] Huge amount of time_wait connections after
 upgrade from v2 to v3
In-Reply-To: <CAHvB88yjPnXOv2qPFhErhLiW=TmqJpvfotsvDGFiSU7x2pQfXQ@mail.gmail.com>
References: <CAHvB88x+nNYMtmNZWqrZo-p==UykYDj5dZF+5N1eC3rGR8ybGw@mail.gmail.com>
 <ca593b00-8727-c816-8169-d6c528c51d93@treenet.co.nz>
 <CAHvB88w4a6n3uoQZ5UZOi4NH0cpYtoVBD3dZtO5sFcDbRY_Bag@mail.gmail.com>
 <f418e53a-ed5f-e4db-9654-2aa31ad83c57@treenet.co.nz>
 <22125AC6-0C7D-459E-8BF1-6C9F4EE7A92C@gmail.com>
 <4c09a163-186c-83c5-30a6-489f1ba1b67c@treenet.co.nz>
 <CAHvB88wSq6=nT6FPNdbopiAxfiZhz5zqOAvfa4_aoiYmAq8QKQ@mail.gmail.com>
 <CAHvB88yjPnXOv2qPFhErhLiW=TmqJpvfotsvDGFiSU7x2pQfXQ@mail.gmail.com>
Message-ID: <6d39bdf1-53aa-46ba-42de-daade6e654d1@treenet.co.nz>

On 15/07/17 11:28, Ivan Larionov wrote:
> Ok, mystery solved.
> 
> Patch "HTTP: do not allow Proxy-Connection to override Connection 
> header" changes the behavior. And we indeed send from our clients:
> 
> Connection: close
> Proxy-Connection: Keep-Alive
> 

Ah. Yes that would lead to trouble.

If you have any influence with the authors of that client software 
please get them to remove the Proxy-Connection header. It should never 
be used in HTTP/1.1 traffic. At the very least, if the clients are 
HTTP/1.0 still it should mirror the Connection value to have consistent 
behaviour from proxies.

If you need a more authoritative reference:
<https://tools.ietf.org/html/rfc7230#appendix-A.1.2>

Amos


From omidkosari at yahoo.com  Sun Jul 16 09:45:32 2017
From: omidkosari at yahoo.com (Omid Kosari)
Date: Sun, 16 Jul 2017 02:45:32 -0700 (PDT)
Subject: [squid-users] range_offset_limit not working as expected
In-Reply-To: <1444ed08-fc1b-d7b9-f54d-39a94d727346@treenet.co.nz>
References: <1473083169343-4679355.post@n4.nabble.com>
 <d6e5127b-8c07-3218-a722-78eb53b12ab4@treenet.co.nz>
 <1473153290520-4679362.post@n4.nabble.com>
 <1444ed08-fc1b-d7b9-f54d-39a94d727346@treenet.co.nz>
Message-ID: <1500198332127-4683112.post@n4.nabble.com>

Amos Jeffries wrote
> Squid DNS system can be updated to do things better.

 Hi,

Any news or updates ? 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/range-offset-limit-not-working-as-expected-tp4679355p4683112.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Sun Jul 16 10:16:29 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sun, 16 Jul 2017 22:16:29 +1200
Subject: [squid-users] range_offset_limit not working as expected
In-Reply-To: <1500198332127-4683112.post@n4.nabble.com>
References: <1473083169343-4679355.post@n4.nabble.com>
 <d6e5127b-8c07-3218-a722-78eb53b12ab4@treenet.co.nz>
 <1473153290520-4679362.post@n4.nabble.com>
 <1444ed08-fc1b-d7b9-f54d-39a94d727346@treenet.co.nz>
 <1500198332127-4683112.post@n4.nabble.com>
Message-ID: <82c4d53e-2172-a1b2-7a2b-1feb491784c6@treenet.co.nz>

On 16/07/17 21:45, Omid Kosari wrote:
> Amos Jeffries wrote
>> Squid DNS system can be updated to do things better.
> 
>   Hi,
> 
> Any news or updates ?
> 

Alex has been doing some of the necessary DNS redesign to get "Happy 
Eyeballs" behaviour going better. So we are a few steps closer now in 
Squid-5, but not quite there yet.

Amos


From bugreporter2017 at gmail.com  Mon Jul 17 12:01:43 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Mon, 17 Jul 2017 05:01:43 -0700 (PDT)
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <af876c61-59fb-f43e-30af-f97ae975a65d@measurement-factory.com>
References: <1499855494036-4683072.post@n4.nabble.com>
 <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
 <214668d4-013a-d8e2-1874-90fb499c85d1@measurement-factory.com>
 <1499962660577-4683096.post@n4.nabble.com>
 <04583e1e-11ef-6d73-706d-9049ad7d5897@measurement-factory.com>
 <1500019904462-4683098.post@n4.nabble.com>
 <af876c61-59fb-f43e-30af-f97ae975a65d@measurement-factory.com>
Message-ID: <1500292903499-4683114.post@n4.nabble.com>

Hi,

Thank you for this clarification. Can you please tell me what is the best
method to measure the RAM used by Squid? Can I trust *top* and/or *ps* and
look at the RSS? Or you suggest another method (maybe using the manager)?

For instance on a 64x when I start squid without cache_dir and a cache_mem
of 0MB, the  "*top*" command gives me the following:
  
/PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND
10996 root        0 -20   70436   3504   1000 S  0.0  0.2   0:00.00 squid
10999 squid      0 -20  624472 144052   6152 S  0.0  7.0   0:03.34 squid/

But the output of "squidclient -h localhost -p 3128 mgr:info' gives me this:

/Resource usage for squid:
...
Maximum Resident Size: 576208 KB
/
Can you please give me advice about that?

Kind Regards,



-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/HDD-RAM-Capacity-vs-store-avg-object-size-tp4683072p4683114.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Mon Jul 17 14:12:28 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 18 Jul 2017 02:12:28 +1200
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <1500292903499-4683114.post@n4.nabble.com>
References: <1499855494036-4683072.post@n4.nabble.com>
 <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
 <214668d4-013a-d8e2-1874-90fb499c85d1@measurement-factory.com>
 <1499962660577-4683096.post@n4.nabble.com>
 <04583e1e-11ef-6d73-706d-9049ad7d5897@measurement-factory.com>
 <1500019904462-4683098.post@n4.nabble.com>
 <af876c61-59fb-f43e-30af-f97ae975a65d@measurement-factory.com>
 <1500292903499-4683114.post@n4.nabble.com>
Message-ID: <14131ade-8257-b31a-9ed7-f9270afd76aa@treenet.co.nz>

On 18/07/17 00:01, bugreporter wrote:
> Hi,
> 
> Thank you for this clarification. Can you please tell me what is the best
> method to measure the RAM used by Squid? Can I trust *top* and/or *ps* and
> look at the RSS? Or you suggest another method (maybe using the manager)?
> 
> For instance on a 64x when I start squid without cache_dir and a cache_mem
> of 0MB, the  "*top*" command gives me the following:
>    
> /PID USER      PR  NI    VIRT    RES    SHR S %CPU %MEM     TIME+ COMMAND
> 10996 root        0 -20   70436   3504   1000 S  0.0  0.2   0:00.00 squid
> 10999 squid      0 -20  624472 144052   6152 S  0.0  7.0   0:03.34 squid/
> 
> But the output of "squidclient -h localhost -p 3128 mgr:info' gives me this:
> 
> /Resource usage for squid:
> ...
> Maximum Resident Size: 576208 KB
> /
> Can you please give me advice about that?

Thats is maximum under the highest peak this Squid has apparently 
encountered. The value comes directly from the getrusage() syscall, 
Squid is not maintaining that value itself.

HTH
Amos


From bugreporter2017 at gmail.com  Mon Jul 17 14:56:09 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Mon, 17 Jul 2017 07:56:09 -0700 (PDT)
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <14131ade-8257-b31a-9ed7-f9270afd76aa@treenet.co.nz>
References: <1499855494036-4683072.post@n4.nabble.com>
 <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
 <214668d4-013a-d8e2-1874-90fb499c85d1@measurement-factory.com>
 <1499962660577-4683096.post@n4.nabble.com>
 <04583e1e-11ef-6d73-706d-9049ad7d5897@measurement-factory.com>
 <1500019904462-4683098.post@n4.nabble.com>
 <af876c61-59fb-f43e-30af-f97ae975a65d@measurement-factory.com>
 <1500292903499-4683114.post@n4.nabble.com>
 <14131ade-8257-b31a-9ed7-f9270afd76aa@treenet.co.nz>
Message-ID: <1500303369015-4683116.post@n4.nabble.com>

Thank you Amos,

OK so how can I accurately measure the memory usage?

Kind Regards,



-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/HDD-RAM-Capacity-vs-store-avg-object-size-tp4683072p4683116.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Mon Jul 17 17:34:15 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 17 Jul 2017 20:34:15 +0300
Subject: [squid-users] What would be the maximum ufs\aufs cache_dir
	objects?
In-Reply-To: <d08145b1-6c4c-0b1e-26b3-78559563f4ed@measurement-factory.com>
References: <06f501d2fc9d$f39292a0$dab7b7e0$@ngtech.co.il>
 <e0d12d09-4d0e-3ea9-d442-e14163a5d271@treenet.co.nz>
 <d08145b1-6c4c-0b1e-26b3-78559563f4ed@measurement-factory.com>
Message-ID: <0e4e01d2ff22$e99f5530$bcddff90$@ngtech.co.il>

So basically from I understand the limit of the AUFS\UFS cache_dir is at:
16,777,215 Objects.
So for a very loaded system it might be pretty "small".

I have asked since:
I have seen the mongodb ecap adapter that stores chunks and I didn't liked it.
In the other way I wrote a cache_dir in GoLang which I am using for the windows updates caching proxy and for now it's surpassing the AUFS\UFS limits.

Based on the success of the Windows Updates Cache proxy which strives to cache only public objects, I was thinking about writing something similar for a more global usage.
The basic constrain on what would be cached is only If the object has Cache-Control "public".
The first step would be an ICAP service (respmod) which will log requests and response and will decide what GET results are worthy of later fetch.
Squid currently does things on-the-fly while the client transaction is fetched by the client.
For an effective cache I believe we can compromise on another approach which relays or statistics.
The first rule is: Not everything worth caching!!!
Then after understanding and configuring this we can move on to fetch *Public* only objects when they get a high repeated downloads.
This is actually how google cache and other similar cache systems work.
They first let traffic reach the "DB" or "DATASTORE" if it's the first time seen.
Then after more the a specific threshold they object is being fetched by the cache system without any connection to the transaction which the clients consume.
It might not be the most effective caching "method" for specific very loaded systems or specific big files and *very* high cost up-stream connections but for many it will be fine.
And the actual logic and implementation can be each of couple algorithms like LRU as the default and couple others as an option.

I believe that this logic will be good for specific systems and will remove all sort of weird store\cache_dir limitations.
I already have a ready to use system which I named "YouTube-Store" that allows the admin to download and serve specific YouTube videos to a local web-service.
It can be utilized together with an external_acl helper that will redirect clients to a special page that hosts cached\stored video with an option to bypass the cached version.

I hope to publish this system soon under BSD license.

Thanks,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Alex Rousskov
Sent: Friday, July 14, 2017 20:49
To: Amos Jeffries <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] What would be the maximum ufs\aufs cache_dir objects?

On 07/14/2017 10:47 AM, Amos Jeffries wrote:

> One UFS cache_dir can hold a maximum of (2^27)-1 safely. 

You probably meant to say (2^25)-1 but the actual number is (2^24)-1
because the sfileno is signed. This is why you get 16'777'215 (a.k.a.
0xFFFFFF) as the actual limit.


> The index hash entries are stored as a 32-bit bitmask (sfileno) - with 5
> bits for cache_dir ID and 27 bits for hash of the file details.

The cache index entries are hashed on their keys, not file numbers (of
any kind). The index entry is using 25 bits for the file number, but
IIRC, those 25 bits are never merged/combined with the 7 bits of the
cache_dir ID in any meaningful way.


Alex.

> typedef signed_int32_t sfileno;>     sfileno swap_filen:25; // keep in sync with SwapFilenMax
>     sdirno swap_dirn:7;
> enum { SwapFilenMax = 0xFFFFFF }; // keep in sync with StoreEntry::swap_filen

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From sergeig.public at gmail.com  Mon Jul 17 20:05:10 2017
From: sergeig.public at gmail.com (Sergei G)
Date: Mon, 17 Jul 2017 13:05:10 -0700
Subject: [squid-users] youtube videos and squid
In-Reply-To: <00ff01d2f72b$8ccb8c10$a662a430$@ngtech.co.il>
References: <CAFLLzCPu8J38S-X9tba1bVfWCxkc7G5eQtqLpMBQ66OvicaomQ@mail.gmail.com>
 <6bbcb4cd-a318-8ba7-3a30-192a436da954@treenet.co.nz>
 <00ff01d2f72b$8ccb8c10$a662a430$@ngtech.co.il>
Message-ID: <CAFLLzCMp53br76SsR+sUP1eCOSHiYd5DRqfcso60XiEP6KXh+g@mail.gmail.com>

Thank you for saving me time and effort.

I ended up following advice of downloading youtube movies to home computer
and serving from it.

My choice was EMBY server for windows https://emby.media/windows-server.html
although a couple others were good options as well.

I bought Emby app for iPad and I use a download extension for Chrome to get
720p resolution videos.  The content is static, but my drive is big and I
feel that this way I can approve some of the content.  It certainly costs
my time go get content to Emby server.

I could try installing Emby on Raspberry PI 3, but I decided against it.
It was more work, the download workflow had a more complicated step of
moving video from PC to RPI.  I was not sure if RPI could be responsive
with its decoding.

The setup works.

On Fri, Jul 7, 2017 at 7:15 AM, Eliezer Croitoru <eliezer at ngtech.co.il>
wrote:

> Hey Amos, Sergei,
>
> I managed to write an ICAP service which works with a ruby\golang StorID
> helper and a redis DB that can help with the caching of YouTube videos.
> However despite to the fact that I am able to tag urls with StoreID  squid
> is still not responding with a cache HIT but fetching from the original
> sources.
>
> There are couple obstacles in this field and this specific solution I
> wrote is designed for PC and not IPAD or Andorid Based devices.
> There is an issue with Android 6+(7..) and IOS 10 based devices which for
> some reason do not cope with SSL traffic interception.
> If you do have a tiny server and you can run a tiny http service with
> nginx\apache I would recommend you to download the videos and serve them
> locally using chrome or another browser which works.
> I found it more useful then intercepting and caching also, kids are
> usually enjoying from a more "stable" stash of movies\videos then others.
> They can watch the same video over and over and it would be fun for them.
> The teenagers are having issue's watching the same video over and over so..
> I can recommend on a nice wordpress theme which can fit a "VOD" site and a
> video downloader which you can use to download specific videos or playlists.
>
> This solution would be something like "netflix on a stick" and is very
> effective with a raspberry pi 3 with some external USB HDD.
>
> I would be happy to get any response to any of the ideas.
>
> Thanks In Advance,
> Eliezer
>
>  * If you are willing to devote some time to debug the issue with the
> current helpers let me know and bump me if you think I missed an email and
> didn't responded(it happens when you have kids...)
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Amos Jeffries
> Sent: Friday, July 7, 2017 11:32
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] youtube videos and squid
>
> On 07/07/17 15:40, Sergei G wrote:
> > Hi guys,
> >
> > I have a very specific scenario in mind to use squid for.
> >
> > I have 2 kids (2.5 and 4 years old) that are watching iPads and really
> > using available Comcast bandwidth.  It does not help that they sometimes
> > just leave those iPads running.
> >
> > They tend to re-watch youtube videos (click on the same icon that they
> > liked before).  And that makes me think that squid could help me with
> > caching off youtube content.  Am I correct?
>
> Possibly. Google have actively been making it more difficult every year
> for quite a while.
>
> These days it requires intercepting the YouTube HTTPS connections. That
> is only possible if the clients are not using Chrome or other Google
> apps to fetch the videos - otherwise you run up against the cert pinning
> wall.
>
> After that you need some extra helper software to track the YT video
> fetching process and decipher what the actual video URL is from the mess
> of session traffic. That is being kept a bit of a secret these days,
> since every time G find out how it is being done they change the process
> to make it more obtuse and harder to do :-(
>
> Eliezer has been trying to get a helper for that going most recently.
> There are also some other products I forget the name of right now
> (videobooster maybe), but should be easy to find that cache YouTube
> content.
>
>
> >
> > If not then I have no reason to bother you anymore :)
> >
> > If squid could help me, then could you point me to a an example
> > configuration that would work?
> >
> > As far as hardware I have 2 options:
> >
> > 1. I can install squid on a Raspberry PI 3, if package is readily
> > available.  that's my preferred solution.
> > 2. I have an old server hardware with more power than RPI 3, but I don't
> > like to run it, because it is noisy.  It has FreeBSD 10 installed and I
> > can upgrade it to latest FreeBSD (11?) and isntall squid application
> > that way.
> >
> >
> > Does squid run on RPI3?  FreeBSD?
>
> Yes to both, and at the small scale you need the RPi3 should be able to
> cope with it.
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170717/7f4e37e9/attachment.htm>

From pablo.ruben.maldonado at gmail.com  Mon Jul 17 20:31:50 2017
From: pablo.ruben.maldonado at gmail.com (Pablo Ruben Maldonado)
Date: Mon, 17 Jul 2017 17:31:50 -0300
Subject: [squid-users] Squid box for two networks
Message-ID: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>

Hello, I have a squid box 3.5 working without problems for the lan
192.168.110.0/24 for several months. Now I want setup to another lan
192.168.115.0/24 but I cannot. Tcpdump inform me that the packages come to
squid box. But in Squid's log I do not see anything. Can they give me some
tip?
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170717/d9a4e819/attachment.htm>

From Tommy.Craddock at bicgraphic.com  Mon Jul 17 20:43:35 2017
From: Tommy.Craddock at bicgraphic.com (Craddock, Tommy)
Date: Mon, 17 Jul 2017 20:43:35 +0000
Subject: [squid-users] Squid box for two networks
In-Reply-To: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
Message-ID: <CA86A9283AA07E478F6B0629521FFEE778656D@CLWSEXCMBX02.na.bicworld.com>

Hello,




Hello, I have a squid box 3.5 working without problems for the lan 192.168.110.0/24<http://192.168.110.0/24> for several months. Now I want setup to another lan 192.168.115.0/24<http://192.168.115.0/24> but I cannot. Tcpdump inform me that the packages come to squid box. But in Squid's log I do not see anything. Can they give me some tip?

We need more info on your config.  Either post your squid.conf, or link to it from a site like pastebin.

Off the top of my head, did you create an ACL allowing this new subnet to use the proxy?



______________________________________________________________________
This email has been scanned by the Symantec Email Security.cloud service.
For more information please visit http://www.symanteccloud.com
______________________________________________________________________
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170717/ff14455b/attachment.htm>

From eliezer at ngtech.co.il  Mon Jul 17 20:48:56 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 17 Jul 2017 23:48:56 +0300
Subject: [squid-users] youtube videos and squid
In-Reply-To: <CAFLLzCMp53br76SsR+sUP1eCOSHiYd5DRqfcso60XiEP6KXh+g@mail.gmail.com>
References: <CAFLLzCPu8J38S-X9tba1bVfWCxkc7G5eQtqLpMBQ66OvicaomQ@mail.gmail.com>
 <6bbcb4cd-a318-8ba7-3a30-192a436da954@treenet.co.nz>
 <00ff01d2f72b$8ccb8c10$a662a430$@ngtech.co.il>
 <CAFLLzCMp53br76SsR+sUP1eCOSHiYd5DRqfcso60XiEP6KXh+g@mail.gmail.com>
Message-ID: <0f2301d2ff3e$1ba1a7c0$52e4f740$@ngtech.co.il>

Hey Sergei,

Thanks for sharing.
This is the first time I have seen EMBY server and client and it seems pretty decent\good and contains many very nice features.

I have been working on a solution that will be hosted on a Linux Server which I named "YouTube-Store".
It's working and I wrote installation scripts for CentOS 7, Ubuntu 16.04, Debian 9.

The concept of the service is like this:
You have a main menu and admin menu.(more pages can be added to store categories with list of movie etc)
The main menu has a search bar which you can use to search the locally hosted videos by their YouTube ID or Their YouTube title.
The Server have a scheduled "fetcher" which downloads videos from a "queue" that is managed by the service admin.(or a script)
There is an API which you(The admin, or a script) can send to it one the next: YouTube link, youtu.be link, YouTube video ID(..watch?v=ID).
The queue is being managed from the web interface and you have the option to add videos to the queue, blacklist or remove from the queue.
( it's very simple to add\remove\disable\hide etc videos)

The goal is to have the option to host a local video "store" which is based on YouTube.
The missing piece in all of this is the IPAD\ANDROID app, but I believe that it's possible to web CMS system to overcome this "gap".
And one last thing is the option to redirect Squid-Cache clients requests to a YouTube video into the locally hosted version(if the video already downloaded).

This is the git repository of the project:
http://gogs.ngtech.co.il/elicro/youtube-store

which is in the beta testing phase.

Thanks For the progress update and also for sharing EMBY,
Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: Sergei G [mailto:sergeig.public at gmail.com] 
Sent: Monday, July 17, 2017 23:05
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: Amos Jeffries <squid3 at treenet.co.nz>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] youtube videos and squid

Thank you for saving me time and effort.

I ended up following advice of downloading youtube movies to home computer and serving from it.

My choice was EMBY server for windows https://emby.media/windows-server.html although a couple others were good options as well.

I bought Emby app for iPad and I use a download extension for Chrome to get 720p resolution videos.  The content is static, but my drive is big and I feel that this way I can approve some of the content.  It certainly costs my time go get content to Emby server.

I could try installing Emby on Raspberry PI 3, but I decided against it.  It was more work, the download workflow had a more complicated step of moving video from PC to RPI.  I was not sure if RPI could be responsive with its decoding.

The setup works.

On Fri, Jul 7, 2017 at 7:15 AM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:
Hey Amos, Sergei,

I managed to write an ICAP service which works with a ruby\golang StorID helper and a redis DB that can help with the caching of YouTube videos.
However despite to the fact that I am able to tag urls with StoreID  squid is still not responding with a cache HIT but fetching from the original sources.

There are couple obstacles in this field and this specific solution I wrote is designed for PC and not IPAD or Andorid Based devices.
There is an issue with Android 6+(7..) and IOS 10 based devices which for some reason do not cope with SSL traffic interception.
If you do have a tiny server and you can run a tiny http service with nginx\apache I would recommend you to download the videos and serve them locally using chrome or another browser which works.
I found it more useful then intercepting and caching also, kids are usually enjoying from a more "stable" stash of movies\videos then others.
They can watch the same video over and over and it would be fun for them.
The teenagers are having issue's watching the same video over and over so..
I can recommend on a nice wordpress theme which can fit a "VOD" site and a video downloader which you can use to download specific videos or playlists.

This solution would be something like "netflix on a stick" and is very effective with a raspberry pi 3 with some external USB HDD.

I would be happy to get any response to any of the ideas.

Thanks In Advance,
Eliezer

 * If you are willing to devote some time to debug the issue with the current helpers let me know and bump me if you think I missed an email and didn't responded(it happens when you have kids...)
----
Eliezer Croitoru
Linux System Administrator
Mobile: tel:%2B972-5-28704261
Email: mailto:eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Friday, July 7, 2017 11:32
To: mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] youtube videos and squid

On 07/07/17 15:40, Sergei G wrote:
> Hi guys,
>
> I have a very specific scenario in mind to use squid for.
>
> I have 2 kids (2.5 and 4 years old) that are watching iPads and really
> using available Comcast bandwidth.  It does not help that they sometimes
> just leave those iPads running.
>
> They tend to re-watch youtube videos (click on the same icon that they
> liked before).  And that makes me think that squid could help me with
> caching off youtube content.  Am I correct?

Possibly. Google have actively been making it more difficult every year
for quite a while.

These days it requires intercepting the YouTube HTTPS connections. That
is only possible if the clients are not using Chrome or other Google
apps to fetch the videos - otherwise you run up against the cert pinning
wall.

After that you need some extra helper software to track the YT video
fetching process and decipher what the actual video URL is from the mess
of session traffic. That is being kept a bit of a secret these days,
since every time G find out how it is being done they change the process
to make it more obtuse and harder to do :-(

Eliezer has been trying to get a helper for that going most recently.
There are also some other products I forget the name of right now
(videobooster maybe), but should be easy to find that cache YouTube content.


>
> If not then I have no reason to bother you anymore :)
>
> If squid could help me, then could you point me to a an example
> configuration that would work?
>
> As far as hardware I have 2 options:
>
> 1. I can install squid on a Raspberry PI 3, if package is readily
> available.  that's my preferred solution.
> 2. I have an old server hardware with more power than RPI 3, but I don't
> like to run it, because it is noisy.  It has FreeBSD 10 installed and I
> can upgrade it to latest FreeBSD (11?) and isntall squid application
> that way.
>
>
> Does squid run on RPI3?  FreeBSD?

Yes to both, and at the small scale you need the RPi3 should be able to
cope with it.

Amos
_______________________________________________
squid-users mailing list
mailto:squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

_______________________________________________
squid-users mailing list
mailto:squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users




From Antony.Stone at squid.open.source.it  Mon Jul 17 21:57:13 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Mon, 17 Jul 2017 22:57:13 +0100
Subject: [squid-users] Squid box for two networks
In-Reply-To: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
Message-ID: <201707172257.14263.Antony.Stone@squid.open.source.it>

On Monday 17 July 2017 at 21:31:50, Pablo Ruben Maldonado wrote:

> Hello, I have a squid box 3.5 working without problems for the lan
> 192.168.110.0/24 for several months. Now I want setup to another lan
> 192.168.115.0/24 but I cannot. Tcpdump inform me that the packages come to
> squid box. But in Squid's log I do not see anything. Can they give me some
> tip?

How is that new subnet connected to the Squid box?

Is it connected on a second network card in the Squid machine, or is it routed 
via a separate gateway connecting the two networks?


Antony.

-- 
All generalisations are inaccurate.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Tue Jul 18 07:07:40 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 18 Jul 2017 19:07:40 +1200
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <1500303369015-4683116.post@n4.nabble.com>
References: <1499855494036-4683072.post@n4.nabble.com>
 <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
 <214668d4-013a-d8e2-1874-90fb499c85d1@measurement-factory.com>
 <1499962660577-4683096.post@n4.nabble.com>
 <04583e1e-11ef-6d73-706d-9049ad7d5897@measurement-factory.com>
 <1500019904462-4683098.post@n4.nabble.com>
 <af876c61-59fb-f43e-30af-f97ae975a65d@measurement-factory.com>
 <1500292903499-4683114.post@n4.nabble.com>
 <14131ade-8257-b31a-9ed7-f9270afd76aa@treenet.co.nz>
 <1500303369015-4683116.post@n4.nabble.com>
Message-ID: <343e4cc4-7768-7b91-4e63-e64aeb461553@treenet.co.nz>

On 18/07/17 02:56, bugreporter wrote:
> Thank you Amos,
> 
> OK so how can I accurately measure the memory usage?
> 

I don't have an answer to that one sorry.

I personally just use the top values.

Amos


From uhlar at fantomas.sk  Tue Jul 18 11:11:58 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 18 Jul 2017 13:11:58 +0200
Subject: [squid-users] Squid box for two networks
In-Reply-To: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
Message-ID: <20170718111157.GA3704@fantomas.sk>

On 17.07.17 17:31, Pablo Ruben Maldonado wrote:
>Hello, I have a squid box 3.5 working without problems for the lan
>192.168.110.0/24 for several months. Now I want setup to another lan
>192.168.115.0/24 but I cannot. Tcpdump inform me that the packages come to
>squid box. But in Squid's log I do not see anything. Can they give me some
>tip?

local firewall on the squid box probably?


-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Linux is like a teepee: no Windows, no Gates and an apache inside...


From Antony.Stone at squid.open.source.it  Tue Jul 18 11:15:32 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 18 Jul 2017 12:15:32 +0100
Subject: [squid-users] Squid box for two networks
In-Reply-To: <20170718111157.GA3704@fantomas.sk>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
 <20170718111157.GA3704@fantomas.sk>
Message-ID: <201707181215.32923.Antony.Stone@squid.open.source.it>

On Tuesday 18 July 2017 at 12:11:58, Matus UHLAR - fantomas wrote:

> On 17.07.17 17:31, Pablo Ruben Maldonado wrote:
> >Hello, I have a squid box 3.5 working without problems for the lan
> >192.168.110.0/24 for several months. Now I want setup to another lan
> >192.168.115.0/24 but I cannot. Tcpdump inform me that the packages come to
> >squid box. But in Squid's log I do not see anything. Can they give me some
> >tip?
> 
> local firewall on the squid box probably?

Can you SSH from a machine on 192.168.115.0/24 to the Squid server?

For that matter, can you ping it?

Does the Squid server have an appropriate route to get back to machines on 
192.168.115.0/24?


Antony.

-- 
This is not a rehearsal.
This is Real Life.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From pablo.ruben.maldonado at gmail.com  Tue Jul 18 12:09:31 2017
From: pablo.ruben.maldonado at gmail.com (Pablo Ruben Maldonado)
Date: Tue, 18 Jul 2017 09:09:31 -0300
Subject: [squid-users] Squid box for two networks
In-Reply-To: <20170718111157.GA3704@fantomas.sk>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
 <20170718111157.GA3704@fantomas.sk>
Message-ID: <CAEUQ6HXqDUnGZbvHcDAOE9K3Agqvy+B6W1yewd+0xi+Qtaz2rQ@mail.gmail.com>

The iptables only follow configuration:

-A PREROUTING -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 3128
-A PREROUTING -p tcp -m tcp --dport 443 -j REDIRECT --to-ports 3129

On Tue, Jul 18, 2017 at 8:11 AM, Matus UHLAR - fantomas <uhlar at fantomas.sk>
wrote:

> On 17.07.17 17:31, Pablo Ruben Maldonado wrote:
>
>> Hello, I have a squid box 3.5 working without problems for the lan
>> 192.168.110.0/24 for several months. Now I want setup to another lan
>> 192.168.115.0/24 but I cannot. Tcpdump inform me that the packages come
>> to
>> squid box. But in Squid's log I do not see anything. Can they give me some
>> tip?
>>
>
> local firewall on the squid box probably?
>
>
> --
> Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
> Warning: I wish NOT to receive e-mail advertising to this address.
> Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
> Linux is like a teepee: no Windows, no Gates and an apache inside...
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170718/86583541/attachment.htm>

From Antony.Stone at squid.open.source.it  Tue Jul 18 12:28:00 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 18 Jul 2017 13:28:00 +0100
Subject: [squid-users] Squid box for two networks
In-Reply-To: <CAEUQ6HXqDUnGZbvHcDAOE9K3Agqvy+B6W1yewd+0xi+Qtaz2rQ@mail.gmail.com>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
 <20170718111157.GA3704@fantomas.sk>
 <CAEUQ6HXqDUnGZbvHcDAOE9K3Agqvy+B6W1yewd+0xi+Qtaz2rQ@mail.gmail.com>
Message-ID: <201707181328.00476.Antony.Stone@squid.open.source.it>

On Tuesday 18 July 2017 at 13:09:31, Pablo Ruben Maldonado wrote:

> The iptables only follow configuration:
> 
> -A PREROUTING -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 3128
> -A PREROUTING -p tcp -m tcp --dport 443 -j REDIRECT --to-ports 3129

Oh, you didn't say this was an intercepting proxy - that sort of thing does 
make a difference...

Maybe you could also answer my questions:

On Monday 17 July 2017 at 22:57:13, Antony Stone wrote:

> How is that new subnet connected to the Squid box?
> 
> Is it connected on a second network card in the Squid machine, or is it
> routed via a separate gateway connecting the two networks?

Given what you've now told us, that this machine is an intercepting proxy, 
please give us a network map - how are the following interconnected with each 
other:

 - the subnet 192.168.110.0/24
 - the subnet 192.168.115.0/24
 - the Squid server
 - the Internet-facing router

On Tuesday 18 July 2017 at 12:15:32, Antony Stone wrote:

> Can you SSH from a machine on 192.168.115.0/24 to the Squid server?
> 
> For that matter, can you ping it?
> 
> Does the Squid server have an appropriate route to get back to machines on
> 192.168.115.0/24?

If you can give us more information about your network and your Squid 
configuration, this may well make it easier for us to guess what is going on.


Antony.

-- 
Numerous psychological studies over the years have demonstrated that the 
majority of people genuinely believe they are not like the majority of people.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From walter.h at mathemainzel.info  Tue Jul 18 12:29:04 2017
From: walter.h at mathemainzel.info (Walter H.)
Date: Tue, 18 Jul 2017 14:29:04 +0200
Subject: [squid-users] Packets logged as blocked even Firewall (IPtables)
	accepts them ...
Message-ID: <9f5b64baa348d726e9c0da763361be9c.1500380944@squirrel.mail>

Hello,

my Router Box runs a CentOS 6, with the EPEL squid34 RPM package

this the iptables
<BEGIN /etc/sysconfig/iptables>
*filter
:INPUT DROP [0:0]
:FORWARD DROP [0:0]
:OUTPUT DROP [0:0]

# Allow multicast
-A INPUT -d 224.0.0.0/4 -j ACCEPT
-A OUTPUT -d 224.0.0.0/4 -j ACCEPT

# Allow anything on the local link
-A INPUT -i lo -j ACCEPT
-A OUTPUT -o lo -j ACCEPT

# Allow anything out on LAN
-A OUTPUT -o br0 -j ACCEPT
# Allow established, related packets back in
-A INPUT -i br0 -m state --state ESTABLISHED,RELATED -j ACCEPT

# Enable DHCP for LAN
-A INPUT -i br0 -m udp -p udp --sport 67:68 --dport 67:68 -j ACCEPT

# Enable DNS-Cache for LAN
-A INPUT -i br0 -m tcp -p tcp --dport 53 -m state --state NEW -j ACCEPT
-A INPUT -i br0 -m udp -p udp --dport 53 -j ACCEPT

# Enable SSH from LAN
-A INPUT -i br0 -m tcp -p tcp --dport 22 -m state --state NEW -j ACCEPT

# Enable HTTP/HTTPS from LAN (some gui interface)
-A INPUT -i br0 -m tcp -p tcp --dport 80 -m state --state NEW -j ACCEPT
-A INPUT -i br0 -m tcp -p tcp --dport 443 -m state --state NEW -j ACCEPT

# Enable Squid-Proxy from LAN
-A INPUT -i br0 -m tcp -p tcp --dport 3128 -m state --state NEW -j ACCEPT

# Block STUN
-A FORWARD -i br0 -o eth1 -m udp -p udp --dport 3478 -j REJECT
# Block TEREDO
-A FORWARD -i br0 -o eth1 -m udp -p udp --dport 3544 -j REJECT

# Allow Forwarding to WAN interface
-A FORWARD -i br0 -o eth1 -j ACCEPT
# Allow established, related packets back through
-A FORWARD -i eth1 -o br0 -m state --state ESTABLISHED,RELATED -j ACCEPT

# Only the lan is allowed to ping me without restriction
-A INPUT -i br0 -p icmp -j ACCEPT
# Else only pings with restricted icmp are allowed
-A INPUT -i eth1 -p icmp -m limit --limit 2/sec --limit-burst 4 -j ACCEPT

# Enable TRACEroute to me from LAN
-A INPUT -i br0 -p udp --sport 32769:65535 --dport 33434:33523 -j ACCEPT
# Enable TRACEroute to me from internet
-A INPUT -i eth1 -p udp --sport 32769:65535 --dport 33434:33523 -j ACCEPT

# Log all other
-A INPUT -j LOG --log-prefix "IP[IN]: " --log-level 7
-A FORWARD -j LOG  --log-prefix "IP[FWD]: " --log-level 7
-A OUTPUT -j LOG  --log-prefix "IP[OUT]: " --log-level 7

COMMIT
<END /etc/sysconfig/iptables>

and these are logged entries:
(only partial, as they are many)

<BEGIN dmesg>
[17-Jul-2017; 19:49:13.590130] IP[IN]: IN=br0 OUT=
MAC=24:01:00:00:01:24:24:00:08:01:05:24:08:00 SRC=192.168.0.10
DST=192.168.0.1 LEN=40 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP
SPT=54916 DPT=3128 WINDOW=0 RES=0x00 RST URGP=0
[17-Jul-2017; 19:49:13.590236] IP[IN]: IN=br0 OUT=
MAC=24:01:00:00:01:24:24:00:08:01:05:24:08:00 SRC=192.168.0.10
DST=192.168.0.1 LEN=40 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP
SPT=54916 DPT=3128 WINDOW=0 RES=0x00 RST URGP=0
[18-Jul-2017; 13:02:19.162684] IP[IN]: IN=br0 OUT=
MAC=24:01:00:00:01:24:24:ff:ff:ff:ff:24:08:00 SRC=192.168.0.2
DST=192.168.0.1 LEN=40 TOS=0x00 PREC=0x00 TTL=128 ID=28792 DF PROTO=TCP
SPT=1219 DPT=3128 WINDOW=65125 RES=0x00 ACK FIN URGP=0
[18-Jul-2017; 13:02:19.593099] IP[IN]: IN=br0 OUT=
MAC=24:01:00:00:01:24:24:ff:ff:ff:ff:24:08:00 SRC=192.168.0.2
DST=192.168.0.1 LEN=109 TOS=0x00 PREC=0x00 TTL=128 ID=28797 DF PROTO=TCP
SPT=1219 DPT=3128 WINDOW=65125 RES=0x00 ACK PSH FIN URGP=0
<END dmesg>

192.168.0.1  is the router itself
192.168.0.10  is a VM running another squid, using the router box as
parent proxy
192.168.0.2   is my windows box

why are these packets blocked?

by the way the router box has of course more interfaces
a br0 (LAN) and eth1 (WAN), where can I ensure that squid only listens to
the LAN IP?

<BEGIN squid.conf>
acl localnet src 192.168.0.0/24

acl SSL_ports port 443
acl Safe_ports port 80                # http
acl Safe_ports port 21                # ftp
acl Safe_ports port 443                # https
acl Safe_ports port 70                # gopher
acl Safe_ports port 1025-65535        # unregistered ports
acl CONNECT method CONNECT

http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

http_access deny to_localhost

http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# and finally allow by default
http_reply_access allow all

# Squid normally listens to port 3128
http_port 3128

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/spool/squid 16400 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

acl crl-mime rep_mime_type application/x-pkcs7-crl
no_cache deny crl-mime

icon_directory /usr/share/squid/icons
error_directory /etc/squid/errors

logformat combined %>A %[ui %[un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st
"%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh
access_log /var/log/squid/access.log combined

refresh_pattern ^ftp:                1440        20%        10080
refresh_pattern ^gopher:        1440        0%        1440
refresh_pattern -i (/cgi-bin/|\?) 0        0%        0
refresh_pattern .                0        20%        4320
<END squid.conf>

Thanks,
Walter



From Antony.Stone at squid.open.source.it  Tue Jul 18 12:47:14 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 18 Jul 2017 13:47:14 +0100
Subject: [squid-users] Packets logged as blocked even Firewall
	(IPtables) accepts them ...
In-Reply-To: <9f5b64baa348d726e9c0da763361be9c.1500380944@squirrel.mail>
References: <9f5b64baa348d726e9c0da763361be9c.1500380944@squirrel.mail>
Message-ID: <201707181347.14154.Antony.Stone@squid.open.source.it>

On Tuesday 18 July 2017 at 13:29:04, Walter H. wrote:

> Hello,
> 
> my Router Box runs a CentOS 6, with the EPEL squid34 RPM package
> 
> this the iptables
> <BEGIN /etc/sysconfig/iptables>

Does the output of "iptables -L -nvx" match the ruleset you've quoted here?

I'm just wondering whether the rules have got loaded properly.


Antony.

-- 
Anyone that's normal doesn't really achieve much.

 - Mark Blair, Australian rocket engineer

                                                   Please reply to the list;
                                                         please *don't* CC me.


From iziz1 at poczta.wp.pl  Tue Jul 18 12:56:16 2017
From: iziz1 at poczta.wp.pl (=?UTF-8?Q?Kurczewski=2c_Bart=c5=82omiej_=28WP.PL=29?=)
Date: Tue, 18 Jul 2017 14:56:16 +0200
Subject: [squid-users] Problem with login to website by Squid web proxy
	3.5.20 on Centos 7
Message-ID: <bbb86484-cef7-e6cb-8e07-36f3768ec0bd@poczta.wp.pl>

Hi,
I have a problem to login to one website (http://intouch.techdata.com)
using Squid 3.5.20 on Centos 7 with default Squid configuration, which
is acting as web proxy (non-transparent) on 3128 port in my network:

--------------------------------------------------------------------------
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
acl localnet src 172.16.0.0/12	# RFC1918 possible internal network
acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines

acl SSL_ports port 443
acl Safe_ports port 80		# http
acl Safe_ports port 21		# ftp
acl Safe_ports port 443		# https
acl Safe_ports port 70		# gopher
acl Safe_ports port 210		# wais
acl Safe_ports port 1025-65535	# unregistered ports
acl Safe_ports port 280		# http-mgmt
acl Safe_ports port 488		# gss-http
acl Safe_ports port 591		# filemaker
acl Safe_ports port 777		# multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 3128

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /var/spool/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320
------------------------------------------------------------------------------


In a FF browser with my Squid server settings I put correct password on
techdata website, but webpage redirect me to the same web form and
doesn't allow to login. The password is correct, because when I put
wrong password I got JavaScript alert from this website that password is
incorrect.

When I disable using Squid proxy in FF and use normal PAT connection via
my Juniper firewall everything works perfect on the same machine and I
can login to TechData website.
I Squid access.log I can see only this:

-----------------------------------------------------------------
1500364995.497    140 10.48.22.33 TCP_MISS/302 735 GET
http://intouch.techdata.com/intouch/Home.aspx? -
HIER_DIRECT/192.230.78.204 text/html
-----------------------------------------------------------------

I suspect some problems with redirection on TechData website, but spend
hours in Internet to find solution, unfortunately without success....
Maybe you can help me?

Regards,
iziz1



From uhlar at fantomas.sk  Tue Jul 18 13:28:48 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Tue, 18 Jul 2017 15:28:48 +0200
Subject: [squid-users] Packets logged as blocked even Firewall
 (IPtables) accepts them ...
In-Reply-To: <9f5b64baa348d726e9c0da763361be9c.1500380944@squirrel.mail>
References: <9f5b64baa348d726e9c0da763361be9c.1500380944@squirrel.mail>
Message-ID: <20170718132848.GB3704@fantomas.sk>

On 18.07.17 14:29, Walter H. wrote:
>-A INPUT -i br0 -m state --state ESTABLISHED,RELATED -j ACCEPT

>-A INPUT -i br0 -m tcp -p tcp --dport 3128 -m state --state NEW -j ACCEPT

>-A INPUT -j LOG --log-prefix "IP[IN]: " --log-level 7

>[17-Jul-2017; 19:49:13.590130] IP[IN]: IN=br0 OUT=
>MAC=24:01:00:00:01:24:24:00:08:01:05:24:08:00 SRC=192.168.0.10
>DST=192.168.0.1 LEN=40 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP
>SPT=54916 DPT=3128 WINDOW=0 RES=0x00 RST URGP=0

it's a RST packet, apparently for connection that was already closed and
thus is not ESTABLISHED,RELATED nor NEW

logging state INVALID could explain

>by the way the router box has of course more interfaces
>a br0 (LAN) and eth1 (WAN), where can I ensure that squid only listens to
>the LAN IP?

here:
># Squid normally listens to port 3128
>http_port 3128

see http://www.squid-cache.org/Doc/config/http_port/

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Microsoft dick is soft to do no harm


From walter.h at mathemainzel.info  Tue Jul 18 13:37:03 2017
From: walter.h at mathemainzel.info (Walter H.)
Date: Tue, 18 Jul 2017 15:37:03 +0200
Subject: [squid-users] Packets logged as blocked even Firewall
 (IPtables) accepts them ...
In-Reply-To: <20170718132848.GB3704@fantomas.sk>
References: <9f5b64baa348d726e9c0da763361be9c.1500380944@squirrel.mail>
 <20170718132848.GB3704@fantomas.sk>
Message-ID: <4db5fcb31640bc453d258e06b6b81188.1500385023@squirrel.mail>

On Tue, July 18, 2017 15:28, Matus UHLAR - fantomas wrote:
> On 18.07.17 14:29, Walter H. wrote:
>>-A INPUT -i br0 -m state --state ESTABLISHED,RELATED -j ACCEPT
>
>>-A INPUT -i br0 -m tcp -p tcp --dport 3128 -m state --state NEW -j ACCEPT
>
>>-A INPUT -j LOG --log-prefix "IP[IN]: " --log-level 7
>
>>[17-Jul-2017; 19:49:13.590130] IP[IN]: IN=br0 OUT=
>>MAC=24:01:00:00:01:24:24:00:08:01:05:24:08:00 SRC=192.168.0.10
>>DST=192.168.0.1 LEN=40 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP
>>SPT=54916 DPT=3128 WINDOW=0 RES=0x00 RST URGP=0
>
> it's a RST packet, apparently for connection that was already closed and
> thus is not ESTABLISHED,RELATED nor NEW
>
> logging state INVALID could explain

how would I do this?

Thanks,
Walter




From walter.h at mathemainzel.info  Tue Jul 18 13:42:21 2017
From: walter.h at mathemainzel.info (Walter H.)
Date: Tue, 18 Jul 2017 15:42:21 +0200
Subject: [squid-users] This list generates a forward loop ...
Message-ID: <31cb999478ff31663df9dbfe85f107a5.1500385341@squirrel.mail>

Hello,

On every post I get an error mail back:

<BEGIN>
Subject:   	Undelivered Mail Returned to Sender
From:   	"Mail Delivery System" <MAILER-DAEMON at squid-cache.org>
Date:   	Tue, July 18, 2017 15:36
To:   	        ...
Priority:   	Normal

This is the mail system at host lists.squid-cache.org.

I'm sorry to have to inform you that your message could not
be delivered to one or more recipients. It's attached below.

For further assistance, please send mail to postmaster.

If you do so, please include this problem report. You can
delete your own text from the attached returned message.

                   The mail system

<squid-users at squid-cache.org> (expanded from
    <squid-users at lists.squid-cache.org>): mail forwarding loop for
    squid-users at squid-cache.org
<END>

Why?

Thanks,
Walter



From Antony.Stone at squid.open.source.it  Tue Jul 18 13:57:39 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Tue, 18 Jul 2017 14:57:39 +0100
Subject: [squid-users] This list generates a forward loop ...
In-Reply-To: <31cb999478ff31663df9dbfe85f107a5.1500385341@squirrel.mail>
References: <31cb999478ff31663df9dbfe85f107a5.1500385341@squirrel.mail>
Message-ID: <201707181457.39934.Antony.Stone@squid.open.source.it>

On Tuesday 18 July 2017 at 14:42:21, Walter H. wrote:

> Hello,
> 
> On every post I get an error mail back

What's the difference between the posts which generate an error, and this one 
which got through?

Are you sending all from the same address, through the same mail server?


Antony.

-- 
"Once you have a panic, things tend to become rather undefined."

 - murble

                                                   Please reply to the list;
                                                         please *don't* CC me.


From marcus.kool at urlfilterdb.com  Tue Jul 18 17:02:46 2017
From: marcus.kool at urlfilterdb.com (Marcus Kool)
Date: Tue, 18 Jul 2017 14:02:46 -0300
Subject: [squid-users] debugging ssl-bump
Message-ID: <1f31b469-8029-83a6-9d97-387f00974554@urlfilterdb.com>


I am trying to debug ssl-bump and am looking specifically for decisions that Squid takes with regard to bumping, splicing and unsupported protocol.

The config file for Squid 4.0.21 has

debug_options ALL,1 33,9 83,9

http_port 10.10.10.1:3230        ssl-bump ...

acl tls_is_skype ssl::server_name "/var/ufdbguard/blacklists/chat/skype/iplist"
acl tls_is_skype ssl::server_name .skype.com
acl tls_allowed_hsts ssl::server_name www.google.com
acl tls_urlfilterdb ssl::server_name www.urlfilterdb.com
acl tls_server_is_bank ssl::server_name .abnamro.nl
acl tls_server_is_bank ssl::server_name .abnamro.com
acl tls_to_splice any-of tls_allowed_hsts tls_urlfilterdb tls_server_is_bank tls_is_skype

ssl_bump splice tls_to_splice
ssl_bump stare  all
ssl_bump bump   all

on_unsupported_protocol tunnel all

But I fail to see in cache.log anything that gives a clue about
- squid decided to splice
- squid decided to bump
- squid decided to treat a connection as "unsupported protocol".

Are there other debug sections than 33 and 83 that need an increased debug level ?
what strings do I have to look for in cache.log to understand the above decisions that Squid takes ?

Thanks
Marcus


From bugreporter2017 at gmail.com  Tue Jul 18 18:32:10 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Tue, 18 Jul 2017 11:32:10 -0700 (PDT)
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <af876c61-59fb-f43e-30af-f97ae975a65d@measurement-factory.com>
References: <1499855494036-4683072.post@n4.nabble.com>
 <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
 <214668d4-013a-d8e2-1874-90fb499c85d1@measurement-factory.com>
 <1499962660577-4683096.post@n4.nabble.com>
 <04583e1e-11ef-6d73-706d-9049ad7d5897@measurement-factory.com>
 <1500019904462-4683098.post@n4.nabble.com>
 <af876c61-59fb-f43e-30af-f97ae975a65d@measurement-factory.com>
Message-ID: <1500402730924-4683136.post@n4.nabble.com>

Hi Alex & Amos. Below results:

On a x64 machine:
v ~ 207 Bytes

On a x86 machine:
v ~ 116

Warm Regards,



-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/HDD-RAM-Capacity-vs-store-avg-object-size-tp4683072p4683136.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From rousskov at measurement-factory.com  Tue Jul 18 20:12:58 2017
From: rousskov at measurement-factory.com (Alex Rousskov)
Date: Tue, 18 Jul 2017 14:12:58 -0600
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <1500402730924-4683136.post@n4.nabble.com>
References: <1499855494036-4683072.post@n4.nabble.com>
 <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
 <214668d4-013a-d8e2-1874-90fb499c85d1@measurement-factory.com>
 <1499962660577-4683096.post@n4.nabble.com>
 <04583e1e-11ef-6d73-706d-9049ad7d5897@measurement-factory.com>
 <1500019904462-4683098.post@n4.nabble.com>
 <af876c61-59fb-f43e-30af-f97ae975a65d@measurement-factory.com>
 <1500402730924-4683136.post@n4.nabble.com>
Message-ID: <33db1e6f-fd06-00ec-2c99-19b6430a3457@measurement-factory.com>

On 07/18/2017 12:32 PM, bugreporter wrote:
> Hi Alex & Amos. Below results:
> 
> On a x64 machine:
> v ~ 207 Bytes

For the record, sizeof(StoreEntry) + sizeof(LruNode) = 104 + 24 = 128
bytes (for Squid v5 on an x64 host).

If your results are correct, we cannot account for ~80 bytes, which is
~50 bytes too many to attribute to various index storage overheads IMO.
This is not important for you (you should use the numbers you got as
long as you trust them), but a developer should investigate where that
memory goes.


>> According to http://wiki.squid-cache.org/SquidFaq/SquidMemory:
>> We need 14 MB of memory per 1 GB on disk for 64-bit Squid


Assuming 13KB mean object size would give us another x64 data point:
v ~ 182


> On a x86 machine:
> v ~ 116


Alex.


From squid3 at treenet.co.nz  Wed Jul 19 01:01:17 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 19 Jul 2017 13:01:17 +1200
Subject: [squid-users] Squid box for two networks
In-Reply-To: <201707181328.00476.Antony.Stone@squid.open.source.it>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
 <20170718111157.GA3704@fantomas.sk>
 <CAEUQ6HXqDUnGZbvHcDAOE9K3Agqvy+B6W1yewd+0xi+Qtaz2rQ@mail.gmail.com>
 <201707181328.00476.Antony.Stone@squid.open.source.it>
Message-ID: <66841dc7-9cf4-3976-7d1d-e6d2c5a7bd78@treenet.co.nz>

On 19/07/17 00:28, Antony Stone wrote:
> 
> Maybe you could also answer my questions:
> 

In addition to those answers, please also post at least the http_port 
and https_port lines from your squid.conf.

Amos


From squid3 at treenet.co.nz  Wed Jul 19 01:21:19 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 19 Jul 2017 13:21:19 +1200
Subject: [squid-users] Packets logged as blocked even Firewall
 (IPtables) accepts them ...
In-Reply-To: <4db5fcb31640bc453d258e06b6b81188.1500385023@squirrel.mail>
References: <9f5b64baa348d726e9c0da763361be9c.1500380944@squirrel.mail>
 <20170718132848.GB3704@fantomas.sk>
 <4db5fcb31640bc453d258e06b6b81188.1500385023@squirrel.mail>
Message-ID: <9da3ffd2-c346-ee8b-1a22-a6642b382e03@treenet.co.nz>

On 19/07/17 01:37, Walter H. wrote:
> On Tue, July 18, 2017 15:28, Matus UHLAR - fantomas wrote:
>> On 18.07.17 14:29, Walter H. wrote:
>>> -A INPUT -i br0 -m state --state ESTABLISHED,RELATED -j ACCEPT
>>
>>> -A INPUT -i br0 -m tcp -p tcp --dport 3128 -m state --state NEW -j ACCEPT
>>
>>> -A INPUT -j LOG --log-prefix "IP[IN]: " --log-level 7
>>
>>> [17-Jul-2017; 19:49:13.590130] IP[IN]: IN=br0 OUT=
>>> MAC=24:01:00:00:01:24:24:00:08:01:05:24:08:00 SRC=192.168.0.10
>>> DST=192.168.0.1 LEN=40 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP
>>> SPT=54916 DPT=3128 WINDOW=0 RES=0x00 RST URGP=0
>>
>> it's a RST packet, apparently for connection that was already closed and
>> thus is not ESTABLISHED,RELATED nor NEW
>>
>> logging state INVALID could explain
> 
> how would I do this?


Add this line in your iptables config above the generic log ones:

  -A INPUT -i br0 -m state --state INVALID -j LOG --log-prefix "IP[IN] 
INVALID]: " --log-level 7

(If you are newbie with iptables or not having a major 'Doh!' moment 
reading the above config line, then I suggest you find some tutorials 
and read up about using netfilter / iptables some starters can be found 
at <http://netfilter.org/documentation/index.html>. You are likely to 
find out a lot of little tips and tricks that are useful way beyond this 
specific question and answers).


PS. This thread seems to have nothing to do with Squid. 
<http://netfilter.org/mailinglists.html#ml-user> would be a more 
appropriate place to seek this type of help in future.

Amos


From bugreporter2017 at gmail.com  Wed Jul 19 06:20:39 2017
From: bugreporter2017 at gmail.com (bugreporter)
Date: Tue, 18 Jul 2017 23:20:39 -0700 (PDT)
Subject: [squid-users] HDD/RAM Capacity vs store_avg_object_size
In-Reply-To: <33db1e6f-fd06-00ec-2c99-19b6430a3457@measurement-factory.com>
References: <1499855494036-4683072.post@n4.nabble.com>
 <912bf264-27e5-e486-6e1a-78cd2748bd94@treenet.co.nz>
 <214668d4-013a-d8e2-1874-90fb499c85d1@measurement-factory.com>
 <1499962660577-4683096.post@n4.nabble.com>
 <04583e1e-11ef-6d73-706d-9049ad7d5897@measurement-factory.com>
 <1500019904462-4683098.post@n4.nabble.com>
 <af876c61-59fb-f43e-30af-f97ae975a65d@measurement-factory.com>
 <1500402730924-4683136.post@n4.nabble.com>
 <33db1e6f-fd06-00ec-2c99-19b6430a3457@measurement-factory.com>
Message-ID: <1500445239385-4683140.post@n4.nabble.com>

Hi,

FYI I had the same object (an image) duplicated x1000, x10000, x30000,
x60000, x100000, x130000, x160000 and finally x200000. The real size of my
object was ~ 45 KB (48 KB for squid as in counts headers + fs structure I
guess).

The growth was almost linear and values I posted here is an average.

Kind Regards,  



-----
Bug Reporter Contributor
OpenSource = Open-Minded
--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/HDD-RAM-Capacity-vs-store-avg-object-size-tp4683072p4683140.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed Jul 19 06:54:14 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 19 Jul 2017 18:54:14 +1200
Subject: [squid-users] This list generates a forward loop ...
In-Reply-To: <31cb999478ff31663df9dbfe85f107a5.1500385341@squirrel.mail>
References: <31cb999478ff31663df9dbfe85f107a5.1500385341@squirrel.mail>
Message-ID: <0b5c9cec-68ee-e238-fb1a-4885b7408361@treenet.co.nz>

On 19/07/17 01:42, Walter H. wrote:
> 
> <squid-users at squid-cache.org> (expanded from
>      <squid-users at lists.squid-cache.org>): mail forwarding loop for
>      squid-users at squid-cache.org
> <END>
> 
> Why?


You sent a mail to the address squid-users at squid-cache.*

The mailing list address is squid-users at lists.*


Amos


From uhlar at fantomas.sk  Wed Jul 19 08:22:34 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Wed, 19 Jul 2017 10:22:34 +0200
Subject: [squid-users] This list generates a forward loop ...
In-Reply-To: <0b5c9cec-68ee-e238-fb1a-4885b7408361@treenet.co.nz>
References: <31cb999478ff31663df9dbfe85f107a5.1500385341@squirrel.mail>
 <0b5c9cec-68ee-e238-fb1a-4885b7408361@treenet.co.nz>
Message-ID: <20170719082234.GA6528@fantomas.sk>

>On 19/07/17 01:42, Walter H. wrote:
>><squid-users at squid-cache.org> (expanded from
>>     <squid-users at lists.squid-cache.org>): mail forwarding loop for
>>     squid-users at squid-cache.org

On 19.07.17 18:54, Amos Jeffries wrote:
>You sent a mail to the address squid-users at squid-cache.*
>
>The mailing list address is squid-users at lists.*

however this should not cause troubles of that kind.
Only if someone/something resends messages to To/Cc addresses.

look onto headers of the mail attached (if there's any) in the error message
could explain it.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
REALITY.SYS corrupted. Press any key to reboot Universe.


From walter.h at mathemainzel.info  Wed Jul 19 09:16:30 2017
From: walter.h at mathemainzel.info (Walter H.)
Date: Wed, 19 Jul 2017 11:16:30 +0200
Subject: [squid-users] Packets logged as blocked even Firewall
 (IPtables) accepts them ...
In-Reply-To: <9da3ffd2-c346-ee8b-1a22-a6642b382e03@treenet.co.nz>
References: <9f5b64baa348d726e9c0da763361be9c.1500380944@squirrel.mail>
 <20170718132848.GB3704@fantomas.sk>
 <4db5fcb31640bc453d258e06b6b81188.1500385023@squirrel.mail>
 <9da3ffd2-c346-ee8b-1a22-a6642b382e03@treenet.co.nz>
Message-ID: <012dd488cc97ff077b6bd09f4723b517.1500455790@squirrel.mail>

On Wed, July 19, 2017 03:21, Amos Jeffries wrote:
> On 19/07/17 01:37, Walter H. wrote:
>> On Tue, July 18, 2017 15:28, Matus UHLAR - fantomas wrote:
>>> On 18.07.17 14:29, Walter H. wrote:
>>>> -A INPUT -i br0 -m state --state ESTABLISHED,RELATED -j ACCEPT
>>>
>>>> -A INPUT -i br0 -m tcp -p tcp --dport 3128 -m state --state NEW -j
>>>> ACCEPT
>>>
>>>> -A INPUT -j LOG --log-prefix "IP[IN]: " --log-level 7
>>>
>>>> [17-Jul-2017; 19:49:13.590130] IP[IN]: IN=br0 OUT=
>>>> MAC=24:01:00:00:01:24:24:00:08:01:05:24:08:00 SRC=192.168.0.10
>>>> DST=192.168.0.1 LEN=40 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP
>>>> SPT=54916 DPT=3128 WINDOW=0 RES=0x00 RST URGP=0
>>>
>>> it's a RST packet, apparently for connection that was already closed
>>> and
>>> thus is not ESTABLISHED,RELATED nor NEW
>>>
>>> logging state INVALID could explain
>>
>> how would I do this?
>
>
> Add this line in your iptables config above the generic log ones:
>
>   -A INPUT -i br0 -m state --state INVALID -j LOG --log-prefix "IP[IN]
> INVALID]: " --log-level 7

I added these rules, and will see which packets are caught

-A INPUT -m state --state INVALID -j LOG --log-prefix "IP[IN(invalid)]: "
--log-level 7
-A FORWARD -m state --state INVALID -j LOG --log-prefix "IP[FWD(invalid)]:
" --log-level 7
-A OUTPUT -m state --state INVALID -j LOG --log-prefix "IP[OUT(invalid)]:
" --log-level 7

and not by these after:

-A INPUT -j LOG --log-prefix "IP[IN]: " --log-level 7
-A FORWARD -j LOG --log-prefix "IP[FWD]: " --log-level 7
-A OUTPUT -j LOG --log-prefix "IP[OUT]: " --log-level 7




From Antony.Stone at squid.open.source.it  Wed Jul 19 09:31:32 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 19 Jul 2017 10:31:32 +0100
Subject: [squid-users] Packets logged as blocked even Firewall
	(IPtables) accepts them ...
In-Reply-To: <012dd488cc97ff077b6bd09f4723b517.1500455790@squirrel.mail>
References: <9f5b64baa348d726e9c0da763361be9c.1500380944@squirrel.mail>
 <9da3ffd2-c346-ee8b-1a22-a6642b382e03@treenet.co.nz>
 <012dd488cc97ff077b6bd09f4723b517.1500455790@squirrel.mail>
Message-ID: <201707191031.33078.Antony.Stone@squid.open.source.it>

On Wednesday 19 July 2017 at 10:16:30, Walter H. wrote:

> I added these rules, and will see which packets are caught
> 
> -A INPUT -m state --state INVALID -j LOG --log-prefix "IP[IN(invalid)]: "
> --log-level 7
> -A FORWARD -m state --state INVALID -j LOG --log-prefix "IP[FWD(invalid)]:
> " --log-level 7
> -A OUTPUT -m state --state INVALID -j LOG --log-prefix "IP[OUT(invalid)]:
> " --log-level 7
> 
> and not by these after:
> 
> -A INPUT -j LOG --log-prefix "IP[IN]: " --log-level 7
> -A FORWARD -j LOG --log-prefix "IP[FWD]: " --log-level 7
> -A OUTPUT -j LOG --log-prefix "IP[OUT]: " --log-level 7

Note that any packets caught by the first rules will *also* be caught by the 
second rules (since there is no DROP in between, and the second rule does not 
exclude INVALID), so don't be surprised when you see log entries from both 
rules for the same packet.


Antony.

-- 
Python is executable pseudocode.
Perl is executable line noise.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From walter.h at mathemainzel.info  Wed Jul 19 09:40:36 2017
From: walter.h at mathemainzel.info (Walter H.)
Date: Wed, 19 Jul 2017 11:40:36 +0200
Subject: [squid-users] Packets logged as blocked even Firewall
 (IPtables) accepts them ...
In-Reply-To: <201707191031.33078.Antony.Stone@squid.open.source.it>
References: <9f5b64baa348d726e9c0da763361be9c.1500380944@squirrel.mail>
 <9da3ffd2-c346-ee8b-1a22-a6642b382e03@treenet.co.nz>
 <012dd488cc97ff077b6bd09f4723b517.1500455790@squirrel.mail>
 <201707191031.33078.Antony.Stone@squid.open.source.it>
Message-ID: <3a4eacf0628a7a4c61c3b633fefa0194.1500457236@squirrel.mail>

On Wed, July 19, 2017 11:31, Antony Stone wrote:
> On Wednesday 19 July 2017 at 10:16:30, Walter H. wrote:
>
>> I added these rules, and will see which packets are caught
>>
>> -A INPUT -m state --state INVALID -j LOG --log-prefix "IP[IN(invalid)]:
>> "
>> --log-level 7
>> -A FORWARD -m state --state INVALID -j LOG --log-prefix
>> "IP[FWD(invalid)]:
>> " --log-level 7
>> -A OUTPUT -m state --state INVALID -j LOG --log-prefix
>> "IP[OUT(invalid)]:
>> " --log-level 7
>>
>> and not by these after:
>>
>> -A INPUT -j LOG --log-prefix "IP[IN]: " --log-level 7
>> -A FORWARD -j LOG --log-prefix "IP[FWD]: " --log-level 7
>> -A OUTPUT -j LOG --log-prefix "IP[OUT]: " --log-level 7
>
> Note that any packets caught by the first rules will *also* be caught by
> the
> second rules (since there is no DROP in between, and the second rule does
> not
> exclude INVALID),

how would I exclude INVALID in the second rules?




From Ralf.Hildebrandt at charite.de  Wed Jul 19 09:52:12 2017
From: Ralf.Hildebrandt at charite.de (Ralf Hildebrandt)
Date: Wed, 19 Jul 2017 11:52:12 +0200
Subject: [squid-users] Squid-5 ETA?
Message-ID: <20170719095211.t7f37zidq6bjch25@charite.de>

Is there any ETA for squid5? 
-- 
Ralf Hildebrandt                   Charite Universit?tsmedizin Berlin
ralf.hildebrandt at charite.de        Campus Benjamin Franklin
https://www.charite.de             Hindenburgdamm 30, 12203 Berlin
Gesch?ftsbereich IT, Abt. Netzwerk fon: +49-30-450.570.155


From Antony.Stone at squid.open.source.it  Wed Jul 19 09:53:46 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 19 Jul 2017 10:53:46 +0100
Subject: [squid-users] Packets logged as blocked even Firewall
	(IPtables) accepts them ...
In-Reply-To: <3a4eacf0628a7a4c61c3b633fefa0194.1500457236@squirrel.mail>
References: <9f5b64baa348d726e9c0da763361be9c.1500380944@squirrel.mail>
 <201707191031.33078.Antony.Stone@squid.open.source.it>
 <3a4eacf0628a7a4c61c3b633fefa0194.1500457236@squirrel.mail>
Message-ID: <201707191053.46927.Antony.Stone@squid.open.source.it>

On Wednesday 19 July 2017 at 10:40:36, Walter H. wrote:

> On Wed, July 19, 2017 11:31, Antony Stone wrote:
> > On Wednesday 19 July 2017 at 10:16:30, Walter H. wrote:
> >> I added these rules, and will see which packets are caught
> >> 
> >> -A INPUT -m state --state INVALID -j LOG --log-prefix "IP[IN(invalid)]:
> >> " --log-level 7
> >> -A FORWARD -m state --state INVALID -j LOG --log-prefix
> >> "IP[FWD(invalid)]: " --log-level 7
> >> -A OUTPUT -m state --state INVALID -j LOG --log-prefix
> >> "IP[OUT(invalid)]: " --log-level 7
> >> 
> >> and not by these after:
> >> 
> >> -A INPUT -j LOG --log-prefix "IP[IN]: " --log-level 7
> >> -A FORWARD -j LOG --log-prefix "IP[FWD]: " --log-level 7
> >> -A OUTPUT -j LOG --log-prefix "IP[OUT]: " --log-level 7
> > 
> > Note that any packets caught by the first rules will *also* be caught by
> > the second rules (since there is no DROP in between, and the second rule
> > does not exclude INVALID),
> 
> how would I exclude INVALID in the second rules?

If you really want to:

-A INPUT -m state ! --state INVALID -j LOG  --log-prefix....

Depending on how you enter this rule, you may need to shell-escape the ! so 
that it doesn't get interpreted by bash etc.

The alternative (IMHO uglier) way of doing it would be:

-A INPUT -m state --state NEW,ESTABLISHED,RELATED -j LOG --log-prefix....


Quoting from the iptables man page:

"   state
       This module, when combined with connection tracking, allows access to 
the connection tracking state for this packet.

       [!] --state state
              Where state is a comma separated list of the connection states 
to match.  Possible states are INVALID meaning that the packet could not be 
identified for some reason which includes running out of memory and ICMP errors 
which don't correspond to any known connection, ESTABLISHED meaning that the 
packet is associated  with  a  connection which  has  seen packets in both 
directions, NEW meaning that the packet has started a new connection, or 
otherwise associated with a connection which has not seen packets in both 
directions, and RELATED meaning that the packet is starting a new connection, 
but is associated with an existing connection, such as an FTP data transfer, 
or an ICMP error.  UNTRACKED meaning that the packet is not tracked at all, 
which happens if you use the NOTRACK target in raw table."


Antony.

-- 
This email was created using 100% recycled electrons.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From Antony.Stone at squid.open.source.it  Wed Jul 19 09:58:47 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Wed, 19 Jul 2017 10:58:47 +0100
Subject: [squid-users] Squid-5 ETA?
In-Reply-To: <20170719095211.t7f37zidq6bjch25@charite.de>
References: <20170719095211.t7f37zidq6bjch25@charite.de>
Message-ID: <201707191058.47604.Antony.Stone@squid.open.source.it>

On Wednesday 19 July 2017 at 10:52:12, Ralf Hildebrandt wrote:

> Is there any ETA for squid5?

I can't help but quote one of my mail sigs here:

	Software development can be quick, high quality, or low cost.

	The customer gets to pick any two out of three.

Note: I am not a Squid developer; this is not an official statement :)


Antony.

-- 
"The problem with television is that the people must sit and keep their eyes 
glued on a screen; the average American family hasn't time for it."

 - New York Times, following a demonstration at the 1939 World's Fair.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From squid3 at treenet.co.nz  Wed Jul 19 12:19:46 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 20 Jul 2017 00:19:46 +1200
Subject: [squid-users] Squid-5 ETA?
In-Reply-To: <20170719095211.t7f37zidq6bjch25@charite.de>
References: <20170719095211.t7f37zidq6bjch25@charite.de>
Message-ID: <10c8f4b0-a621-89ae-87bb-8afcc5144654@treenet.co.nz>

On 19/07/17 21:52, Ralf Hildebrandt wrote:
> Is there any ETA for squid5?
> 

If I'm optimistic and assume that development gets back into the old 
rythmn we had going for most of 3.x, then sometime late 2018 or early 2019.

Or did you mean v4 stable? when the last few bugs are fixed. I'm hopeful 
soon, but these last ones are proving quite difficult to even track down.


HTH
Amos


From squid3 at treenet.co.nz  Wed Jul 19 13:38:27 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 20 Jul 2017 01:38:27 +1200
Subject: [squid-users] What would be the maximum ufs\aufs cache_dir
 objects?
In-Reply-To: <0e4e01d2ff22$e99f5530$bcddff90$@ngtech.co.il>
References: <06f501d2fc9d$f39292a0$dab7b7e0$@ngtech.co.il>
 <e0d12d09-4d0e-3ea9-d442-e14163a5d271@treenet.co.nz>
 <d08145b1-6c4c-0b1e-26b3-78559563f4ed@measurement-factory.com>
 <0e4e01d2ff22$e99f5530$bcddff90$@ngtech.co.il>
Message-ID: <e0bcf3db-4da7-cb6e-8ae6-969e092d57e0@treenet.co.nz>

On 18/07/17 05:34, Eliezer Croitoru wrote:
> So basically from I understand the limit of the AUFS\UFS cache_dir is at:
> 16,777,215 Objects.
> So for a very loaded system it might be pretty "small".
> 
> I have asked since:
> I have seen the mongodb ecap adapter that stores chunks and I didn't liked it.
> In the other way I wrote a cache_dir in GoLang which I am using for the windows updates caching proxy and for now it's surpassing the AUFS\UFS limits.
> 
> Based on the success of the Windows Updates Cache proxy which strives to cache only public objects, I was thinking about writing something similar for a more global usage.
> The basic constrain on what would be cached is only If the object has Cache-Control "public".

You would end up with only a small sub-set of HTTP every being cached.

CC:public's main reason for existence is to re-enable cacheability of 
responses that contain security credentials - which is prevented by 
default as a security fail-safe.

I know a fair number of servers still send it when they should not. But 
that is declining as content gets absorbed by CDN who take more care 
with their bandwidth expenditure.



> The first step would be an ICAP service (respmod) which will log requests and response and will decide what GET results are worthy of later fetch.
> Squid currently does things on-the-fly while the client transaction is fetched by the client.

What things are you speaking about here?

How do you define "later"? is that 1 nanosecond or 64 years?
  and what makes 1 nanosecond difference in request timing for a 6GB 
object any less costly than 1 second?

Most of what Squid does and the timing of it have good reasons behind 
them. Not saying change is bad, but to make real improvements instead of 
re-inventing some long lost wheel design one has to know those reasons 
to avoid them becoming problems.
  eg. the often laughed at square wheel is a real and useful design for 
some circumstances. And their lesser bretheren cogwheels and the like 
are an age proven design in rail history for places where roundness 
actively inhibits movement.


> For an effective cache I believe we can compromise on another approach which relays or statistics.
> The first rule is: Not everything worth caching!!!
> Then after understanding and configuring this we can move on to fetch *Public* only objects when they get a high repeated downloads.
> This is actually how google cache and other similar cache systems work.
> They first let traffic reach the "DB" or "DATASTORE" if it's the first time seen.

FYI: that is the model Squid is trying to move away from - because it 
slows down traffic processing. As far as I'm aware G has a farm of 
servers to throw at any task - unlike most sysadmin trying to stand up a 
cache.


> Then after more the a specific threshold they object is being fetched by the cache system without any connection to the transaction which the clients consume.

Introducing the slow-loris attack.

It has several variants:
1) client sends a request, very , very, ... very slowly. many thousands 
of bots all do this at once, or building up over time.
   -> an unwary server gets crushed under the weight of open TCP 
sockets, and its normal clients get pushed out into DoS.

2) client sends a request. then ACK's delivery, very, very, ... very slowly.
   -> an unwary server gets crushed under the weight of open TCP 
sockets, and its normal clients get pushed out into DoS. AND suffers for 
each byte of bandwidth it spent fetching content for that client.

3) both of the above.

The slower a server is at detecting this attack the more damage can be 
done. This is magnified by whatever amount of resource expenditure the 
server goes to before detection can kick in - RAM, disk I/O, CPU time, 
TCP sockets, and of most relevant here: upstream bandwidth.

Also, Loris and clients on old tech like 6K modems or worse are 
indistinguishable.

To help resolve this problem Squid does the _opposite_ to what you 
propose above. It makes the client delivery and the server fetch align 
to avoid mistakes detecting these attacks and disconnecting legitimate 
clients.
  The read_ahead_gap directive configures the threshold amount of server 
fetch which can be done at full server-connection speed before slowing 
down to client speed. The various I/O timeouts can be tuned to what a 
sysadmin knows about their clients expected I/O capabilities.


> It might not be the most effective caching "method" for specific very loaded systems or specific big files and *very* high cost up-stream connections but for many it will be fine.
> And the actual logic and implementation can be each of couple algorithms like LRU as the default and couple others as an option.
> 
> I believe that this logic will be good for specific systems and will remove all sort of weird store\cache_dir limitations.

Which weird limitations are you referring to?

The limits you started this thread about are caused directly by the size 
of a specific integer representation and the mathematical properties 
inherent in a hashing algorithm.

Those types of limit can be eliminated or changed in the relevant code 
without redesigning how HTTP protocol caching behaves.


Amos


From ncherukuri at partycity.com  Wed Jul 19 13:46:20 2017
From: ncherukuri at partycity.com (Cherukuri, Naresh)
Date: Wed, 19 Jul 2017 13:46:20 +0000
Subject: [squid-users] Squid Version 3.5.20
Message-ID: <89638057A560FB458C01C197F81C7F5D13F320C5@PACERS.amscan.corp>

Hi All,

I installed Squid version 3.5.20 on RHEL 7 and generated self-signed CA certificates,  My users are complaining about certificate errors. When I looked at cache.log I see so many error messages like below. Below is my squid.conf file. Any ideas how to address below errors.

Squid.conf:

max_filedesc 4096
visible_hostname pctysqd2prod
logfile_rotate 10

access_log stdio:/var/log/squid/access.log squid

acl localnet src 172.16.0.0/16
acl backoffice_users src 10.136.0.0/13
acl hcity_backoffice_users src 10.142.0.0/15
acl register_users src 10.128.0.0/13
acl hcity_register_users src 10.134.0.0/15
acl partycity url_regex partycity

acl SSL_ports port 443
acl Safe_ports port 80          # http
#acl Safe_ports port 21         # ftp
acl Safe_ports port 443         # https
#acl Safe_ports port 70         # gopher
#acl Safe_ports port 210                # wais
#acl Safe_ports port 1025-65535 # unregistered ports
#acl Safe_ports port 280                # http-mgmt
#acl Safe_ports port 488                # gss-http
#acl Safe_ports port 591                # filemaker
#acl Safe_ports port 777                # multiling http
acl CONNECT method CONNECT
#acl allowed_sites {dst|dstdomain|dstdom_regex|url_regex) "/path/to/file"
acl backoffice_allowed_sites url_regex "/etc/squid/backoffice_allowed_sites"
acl hcity_backoffice_allowed_sites url_regex "/etc/squid/backoffice_allowed_sites"
acl backoffice_blocked_sites url_regex "/etc/squid/backoffice_blocklist"
acl hcity_backoffice_blocked_sites url_regex "/etc/squid/backoffice_blocklist"
acl register_allowed_sites url_regex "/etc/squid/register_allowed_sites"
acl hcity_register_allowed_sites url_regex "/etc/squid/hcity_register_allowed_sites"

http_access allow localnet register_allowed_sites
http_access deny backoffice_users backoffice_blocked_sites
http_access deny hcity_backoffice_users backoffice_blocked_sites
http_access allow backoffice_users backoffice_allowed_sites
http_access allow hcity_backoffice_users backoffice_allowed_sites
http_access allow register_users register_allowed_sites
http_access allow hcity_register_users hcity_register_allowed_sites
no_cache deny partycity
http_access deny all

#http_access allow manager localhost
#http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
#http_access deny CONNECT !SSL_ports
http_access  allow CONNECT SSL_ports
# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
http_access deny to_localhost


# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 3128 ssl-bump \
key=/etc/squid/pctysquid2sslcerts/pctysquid2prod.pkey \
cert=/etc/squid/pctysquid2sslcerts/pctysquid2prod.crt \
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all

sslproxy_cert_error allow all
always_direct allow all
sslproxy_flags DONT_VERIFY_PEER

sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB sslcrtd_children 8 startup=1 idle=1

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /cache/squid 10000 16 256

# Leave coredumps in the first cache dir
#rdescoredump_dir /var/spool/squid
coredump_dir /var/log/squid/squid

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320

#url_rewrite_access allow all
#url_rewrite_program /usr/bin/squidGuard -c /etc/squid/squidguard.conf

Cache.log

2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 689: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 1114: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
2017/07/18 16:05:37 kid1| Error negotiating SSL connection on FD 146: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 252: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 36: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170719/9dab7862/attachment.htm>

From ncherukuri at partycity.com  Wed Jul 19 15:34:18 2017
From: ncherukuri at partycity.com (Cherukuri, Naresh)
Date: Wed, 19 Jul 2017 15:34:18 +0000
Subject: [squid-users] Squid Version 3.5.20 Any Ideas
Message-ID: <89638057A560FB458C01C197F81C7F5D13F32404@PACERS.amscan.corp>

Hi All,

I installed Squid version 3.5.20 on RHEL 7 and generated self-signed CA certificates,  My users are complaining about certificate errors. When I looked at cache.log I see so many error messages like below. Below is my squid.conf file. Any ideas how to address below errors.

Squid.conf:

max_filedesc 4096
visible_hostname pctysqd2prod
logfile_rotate 10

access_log stdio:/var/log/squid/access.log squid

acl localnet src 172.16.0.0/16
acl backoffice_users src 10.136.0.0/13
acl hcity_backoffice_users src 10.142.0.0/15
acl register_users src 10.128.0.0/13
acl hcity_register_users src 10.134.0.0/15
acl partycity url_regex partycity

acl SSL_ports port 443
acl Safe_ports port 80          # http
#acl Safe_ports port 21         # ftp
acl Safe_ports port 443         # https
#acl Safe_ports port 70         # gopher
#acl Safe_ports port 210                # wais
#acl Safe_ports port 1025-65535 # unregistered ports
#acl Safe_ports port 280                # http-mgmt
#acl Safe_ports port 488                # gss-http
#acl Safe_ports port 591                # filemaker
#acl Safe_ports port 777                # multiling http
acl CONNECT method CONNECT
#acl allowed_sites {dst|dstdomain|dstdom_regex|url_regex) "/path/to/file"
acl backoffice_allowed_sites url_regex "/etc/squid/backoffice_allowed_sites"
acl hcity_backoffice_allowed_sites url_regex "/etc/squid/backoffice_allowed_sites"
acl backoffice_blocked_sites url_regex "/etc/squid/backoffice_blocklist"
acl hcity_backoffice_blocked_sites url_regex "/etc/squid/backoffice_blocklist"
acl register_allowed_sites url_regex "/etc/squid/register_allowed_sites"
acl hcity_register_allowed_sites url_regex "/etc/squid/hcity_register_allowed_sites"

http_access allow localnet register_allowed_sites
http_access deny backoffice_users backoffice_blocked_sites
http_access deny hcity_backoffice_users backoffice_blocked_sites
http_access allow backoffice_users backoffice_allowed_sites
http_access allow hcity_backoffice_users backoffice_allowed_sites
http_access allow register_users register_allowed_sites
http_access allow hcity_register_users hcity_register_allowed_sites
no_cache deny partycity
http_access deny all

#http_access allow manager localhost
#http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
#http_access deny CONNECT !SSL_ports
http_access  allow CONNECT SSL_ports
# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
http_access deny to_localhost


# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 3128 ssl-bump \
key=/etc/squid/pctysquid2sslcerts/pctysquid2prod.pkey \
cert=/etc/squid/pctysquid2sslcerts/pctysquid2prod.crt \
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all

sslproxy_cert_error allow all
always_direct allow all
sslproxy_flags DONT_VERIFY_PEER

sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB sslcrtd_children 8 startup=1 idle=1

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /cache/squid 10000 16 256

# Leave coredumps in the first cache dir
#rdescoredump_dir /var/spool/squid
coredump_dir /var/log/squid/squid

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320

#url_rewrite_access allow all
#url_rewrite_program /usr/bin/squidGuard -c /etc/squid/squidguard.conf

Cache.log

2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 689: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 1114: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
2017/07/18 16:05:37 kid1| Error negotiating SSL connection on FD 146: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 252: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 36: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170719/292de47f/attachment.htm>

From yvoinov at gmail.com  Wed Jul 19 15:36:24 2017
From: yvoinov at gmail.com (Yuri)
Date: Wed, 19 Jul 2017 21:36:24 +0600
Subject: [squid-users] Squid Version 3.5.20 Any Ideas
In-Reply-To: <89638057A560FB458C01C197F81C7F5D13F32404@PACERS.amscan.corp>
References: <89638057A560FB458C01C197F81C7F5D13F32404@PACERS.amscan.corp>
Message-ID: <e653374f-020d-c213-6a0f-12dda8ebce32@gmail.com>

http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit

http://i.imgur.com/A153C7A.png


19.07.2017 21:34, Cherukuri, Naresh ?????:
>
> Hi All,
>
>  
>
> I installed Squid version 3.5.20 on RHEL 7 and generated self-signed
> CA certificates,  My users are complaining about certificate errors.
> When I looked at cache.log I see so many error messages like below.
> Below is my squid.conf file. Any ideas how to address below errors.
>
>  
>
> Squid.conf:
>
>  
>
> max_filedesc 4096
>
> visible_hostname pctysqd2prod
>
> logfile_rotate 10
>
>  
>
> access_log stdio:/var/log/squid/access.log squid
>
>  
>
> acl localnet src 172.16.0.0/16
>
> acl backoffice_users src 10.136.0.0/13
>
> acl hcity_backoffice_users src 10.142.0.0/15
>
> acl register_users src 10.128.0.0/13
>
> acl hcity_register_users src 10.134.0.0/15
>
> acl partycity url_regex partycity
>
>  
>
> acl SSL_ports port 443
>
> acl Safe_ports port 80          # http
>
> #acl Safe_ports port 21         # ftp
>
> acl Safe_ports port 443         # https
>
> #acl Safe_ports port 70         # gopher
>
> #acl Safe_ports port 210                # wais
>
> #acl Safe_ports port 1025-65535 # unregistered ports
>
> #acl Safe_ports port 280                # http-mgmt
>
> #acl Safe_ports port 488                # gss-http
>
> #acl Safe_ports port 591                # filemaker
>
> #acl Safe_ports port 777                # multiling http
>
> acl CONNECT method CONNECT
>
> #acl allowed_sites {dst|dstdomain|dstdom_regex|url_regex) "/path/to/file"
>
> acl backoffice_allowed_sites url_regex
> "/etc/squid/backoffice_allowed_sites"
>
> acl hcity_backoffice_allowed_sites url_regex
> "/etc/squid/backoffice_allowed_sites"
>
> acl backoffice_blocked_sites url_regex "/etc/squid/backoffice_blocklist"
>
> acl hcity_backoffice_blocked_sites url_regex
> "/etc/squid/backoffice_blocklist"
>
> acl register_allowed_sites url_regex "/etc/squid/register_allowed_sites"
>
> acl hcity_register_allowed_sites url_regex
> "/etc/squid/hcity_register_allowed_sites"
>
>  
>
> http_access allow localnet register_allowed_sites
>
> http_access deny backoffice_users backoffice_blocked_sites
>
> http_access deny hcity_backoffice_users backoffice_blocked_sites
>
> http_access allow backoffice_users backoffice_allowed_sites
>
> http_access allow hcity_backoffice_users backoffice_allowed_sites
>
> http_access allow register_users register_allowed_sites
>
> http_access allow hcity_register_users hcity_register_allowed_sites
>
> no_cache deny partycity
>
> http_access deny all
>
>  
>
> #http_access allow manager localhost
>
> #http_access deny manager
>
>  
>
> # Deny requests to certain unsafe ports
>
> http_access deny !Safe_ports
>
>  
>
> # Deny CONNECT to other than secure SSL ports
>
> #http_access deny CONNECT !SSL_ports
>
> http_access  allow CONNECT SSL_ports
>
> # We strongly recommend the following be uncommented to protect innocent
>
> # web applications running on the proxy server who think the only
>
> # one who can access services on "localhost" is a local user
>
> http_access deny to_localhost
>
>  
>
>  
>
> # Example rule allowing access from your local networks.
>
> # Adapt localnet in the ACL section to list your (internal) IP networks
>
> # from where browsing should be allowed
>
> #http_access allow localnet
>
> http_access allow localhost
>
>  
>
> # And finally deny all other access to this proxy
>
> http_access deny all
>
>  
>
> # Squid normally listens to port 3128
>
> http_port 3128 ssl-bump \
>
> key=/etc/squid/pctysquid2sslcerts/pctysquid2prod.pkey \
>
> cert=/etc/squid/pctysquid2sslcerts/pctysquid2prod.crt \
>
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
>
>  
>
> acl step1 at_step SslBump1
>
> ssl_bump peek step1
>
> ssl_bump bump all
>
>  
>
> sslproxy_cert_error allow all
>
> always_direct allow all
>
> sslproxy_flags DONT_VERIFY_PEER
>
>  
>
> sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
> sslcrtd_children 8 startup=1 idle=1
>
>  
>
> # Uncomment and adjust the following to add a disk cache directory.
>
> #cache_dir ufs /cache/squid 10000 16 256
>
>  
>
> # Leave coredumps in the first cache dir
>
> #rdescoredump_dir /var/spool/squid
>
> coredump_dir /var/log/squid/squid
>
>  
>
> # Add any of your own refresh_pattern entries above these.
>
> refresh_pattern ^ftp:           1440    20%     10080
>
> refresh_pattern ^gopher:        1440    0%      1440
>
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
>
> refresh_pattern .               0       20%     4320
>
>  
>
> #url_rewrite_access allow all
>
> #url_rewrite_program /usr/bin/squidGuard -c /etc/squid/squidguard.conf
>
>  
>
> Cache.log
>
>  
>
> 2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 689:
> error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate
> unknown (1/0)
>
> 2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 1114:
> error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate
> unknown (1/0)
>
> 2017/07/18 16:05:37 kid1| Error negotiating SSL connection on FD 146:
> error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate
> unknown (1/0)
>
> 2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 252:
> error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate
> unknown (1/0)
>
> 2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 36:
> error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate
> unknown (1/0)
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170719/9f554715/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170719/9f554715/attachment.sig>

From Walter.H at mathemainzel.info  Wed Jul 19 17:30:36 2017
From: Walter.H at mathemainzel.info (Walter H.)
Date: Wed, 19 Jul 2017 19:30:36 +0200
Subject: [squid-users] Squid Version 3.5.20 Any Ideas
In-Reply-To: <e653374f-020d-c213-6a0f-12dda8ebce32@gmail.com>
References: <89638057A560FB458C01C197F81C7F5D13F32404@PACERS.amscan.corp>
 <e653374f-020d-c213-6a0f-12dda8ebce32@gmail.com>
Message-ID: <596F973C.7040603@mathemainzel.info>

Hello,

this seems not to be the problem, as the error messages are in 
cache.log, which is not a browser problem ...

the question: are the SSL bumped sites in intranet, which use a self 
signed CA cert itself, which squid doesn't know?

On 19.07.2017 17:36, Yuri wrote:
>
> http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
>
> http://i.imgur.com/A153C7A.png
>
>
> 19.07.2017 21:34, Cherukuri, Naresh ?????:
>>
>> Hi All,
>>
>> I installed Squid version 3.5.20 on RHEL 7 and generated self-signed 
>> CA certificates,  My users are complaining about certificate errors. 
>> When I looked at cache.log I see so many error messages like below. 
>> Below is my squid.conf file. Any ideas how to address below errors.
>>
>>

>> Cache.log
>>
>> 2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 689: 
>> error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate 
>> unknown (1/0)
>>
>> 2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 
>> 1114: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert 
>> certificate unknown (1/0)
>>
>> 2017/07/18 16:05:37 kid1| Error negotiating SSL connection on FD 146: 
>> error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate 
>> unknown (1/0)
>>
>> 2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 252: 
>> error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate 
>> unknown (1/0)
>>
>> 2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 36: 
>> error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate 
>> unknown (1/0)
>>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170719/35518248/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3491 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170719/35518248/attachment.bin>

From ncherukuri at partycity.com  Wed Jul 19 17:36:31 2017
From: ncherukuri at partycity.com (Cherukuri, Naresh)
Date: Wed, 19 Jul 2017 17:36:31 +0000
Subject: [squid-users] Squid Version 3.5.20
Message-ID: <89638057A560FB458C01C197F81C7F5D13F32713@PACERS.amscan.corp>

Walter,

Thanks for quick turner below is my squid.conf file and errors I seen in cache.log.

From: Cherukuri, Naresh
Sent: Wednesday, July 19, 2017 9:46 AM
To: 'squid-users at lists.squid-cache.org'
Subject: RE: Squid Version 3.5.20

Hi All,

I installed Squid version 3.5.20 on RHEL 7 and generated self-signed CA certificates,  My users are complaining about certificate errors. When I looked at cache.log I see so many error messages like below. Below is my squid.conf file. Any ideas how to address below errors.

Squid.conf:

max_filedesc 4096
visible_hostname pctysqd2prod
logfile_rotate 10

access_log stdio:/var/log/squid/access.log squid

acl localnet src 172.16.0.0/16
acl backoffice_users src 10.136.0.0/13
acl hcity_backoffice_users src 10.142.0.0/15
acl register_users src 10.128.0.0/13
acl hcity_register_users src 10.134.0.0/15
acl partycity url_regex partycity

acl SSL_ports port 443
acl Safe_ports port 80          # http
#acl Safe_ports port 21         # ftp
acl Safe_ports port 443         # https
#acl Safe_ports port 70         # gopher
#acl Safe_ports port 210                # wais
#acl Safe_ports port 1025-65535 # unregistered ports
#acl Safe_ports port 280                # http-mgmt
#acl Safe_ports port 488                # gss-http
#acl Safe_ports port 591                # filemaker
#acl Safe_ports port 777                # multiling http
acl CONNECT method CONNECT
#acl allowed_sites {dst|dstdomain|dstdom_regex|url_regex) "/path/to/file"
acl backoffice_allowed_sites url_regex "/etc/squid/backoffice_allowed_sites"
acl hcity_backoffice_allowed_sites url_regex "/etc/squid/backoffice_allowed_sites"
acl backoffice_blocked_sites url_regex "/etc/squid/backoffice_blocklist"
acl hcity_backoffice_blocked_sites url_regex "/etc/squid/backoffice_blocklist"
acl register_allowed_sites url_regex "/etc/squid/register_allowed_sites"
acl hcity_register_allowed_sites url_regex "/etc/squid/hcity_register_allowed_sites"

http_access allow localnet register_allowed_sites
http_access deny backoffice_users backoffice_blocked_sites
http_access deny hcity_backoffice_users backoffice_blocked_sites
http_access allow backoffice_users backoffice_allowed_sites
http_access allow hcity_backoffice_users backoffice_allowed_sites
http_access allow register_users register_allowed_sites
http_access allow hcity_register_users hcity_register_allowed_sites
no_cache deny partycity
http_access deny all

#http_access allow manager localhost
#http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
#http_access deny CONNECT !SSL_ports
http_access  allow CONNECT SSL_ports
# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
http_access deny to_localhost


# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 3128 ssl-bump \
key=/etc/squid/pctysquid2sslcerts/pctysquid2prod.pkey \
cert=/etc/squid/pctysquid2sslcerts/pctysquid2prod.crt \
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all

sslproxy_cert_error allow all
always_direct allow all
sslproxy_flags DONT_VERIFY_PEER

sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB sslcrtd_children 8 startup=1 idle=1

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /cache/squid 10000 16 256

# Leave coredumps in the first cache dir
#rdescoredump_dir /var/spool/squid
coredump_dir /var/log/squid/squid

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320

#url_rewrite_access allow all
#url_rewrite_program /usr/bin/squidGuard -c /etc/squid/squidguard.conf

Cache.log

2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 689: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 1114: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
2017/07/18 16:05:37 kid1| Error negotiating SSL connection on FD 146: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 252: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 36: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170719/a0c0b380/attachment.htm>

From eliezer at ngtech.co.il  Wed Jul 19 17:40:01 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 19 Jul 2017 20:40:01 +0300
Subject: [squid-users] Squid Version 3.5.20
In-Reply-To: <89638057A560FB458C01C197F81C7F5D13F320C5@PACERS.amscan.corp>
References: <89638057A560FB458C01C197F81C7F5D13F320C5@PACERS.amscan.corp>
Message-ID: <167d01d300b6$0caa6da0$25ff48e0$@ngtech.co.il>

Hey,

I have not published the RHEL packages on the squid-cache wiki at:
http://wiki.squid-cache.org/KnowledgeBase/RedHat

And will try to add the details there in the next days.
You can try to use the RHEL which is similar to the centos and on the same
server which is mentioned in this page:
http://wiki.squid-cache.org/KnowledgeBase/CentOS#Squid-3.5

But replace the centos with rhel ie:
baseurl=http://www1.ngtech.co.il/repo/rhel/$releasever/$basearch/

There is an up-to-date 3.5.26 package which you should try to use in any
case.
I don?t know why you encounter this issue but it is a good time to know that
there is an up-to-date squid rpm for RHEL 7.

All The Bests,
Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
Behalf Of Cherukuri, Naresh
Sent: Wednesday, July 19, 2017 16:46
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid Version 3.5.20

Hi All,

I installed Squid version 3.5.20 on RHEL 7 and generated self-signed CA
certificates, ?My users are complaining about certificate errors. When I
looked at cache.log I see so many error messages like below. Below is my
squid.conf file. Any ideas how to address below errors.

Squid.conf:

max_filedesc 4096
visible_hostname pctysqd2prod
logfile_rotate 10

access_log stdio:/var/log/squid/access.log squid

acl localnet src 172.16.0.0/16
acl backoffice_users src 10.136.0.0/13
acl hcity_backoffice_users src 10.142.0.0/15
acl register_users src 10.128.0.0/13
acl hcity_register_users src 10.134.0.0/15
acl partycity url_regex partycity

acl SSL_ports port 443
acl Safe_ports port 80????????? # http
#acl Safe_ports port 21???????? # ftp
acl Safe_ports port 443???????? # https
#acl Safe_ports port 70???????? # gopher
#acl Safe_ports port 210??????????????? # wais
#acl Safe_ports port 1025-65535 # unregistered ports
#acl Safe_ports port 280??????????????? # http-mgmt
#acl Safe_ports port 488??????????????? # gss-http
#acl Safe_ports port 591??????????????? # filemaker
#acl Safe_ports port 777??????????????? # multiling http
acl CONNECT method CONNECT
#acl allowed_sites {dst|dstdomain|dstdom_regex|url_regex) "/path/to/file"
acl backoffice_allowed_sites url_regex "/etc/squid/backoffice_allowed_sites"
acl hcity_backoffice_allowed_sites url_regex
"/etc/squid/backoffice_allowed_sites"
acl backoffice_blocked_sites url_regex "/etc/squid/backoffice_blocklist"
acl hcity_backoffice_blocked_sites url_regex
"/etc/squid/backoffice_blocklist"
acl register_allowed_sites url_regex "/etc/squid/register_allowed_sites"
acl hcity_register_allowed_sites url_regex
"/etc/squid/hcity_register_allowed_sites"

http_access allow localnet register_allowed_sites
http_access deny backoffice_users backoffice_blocked_sites
http_access deny hcity_backoffice_users backoffice_blocked_sites
http_access allow backoffice_users backoffice_allowed_sites
http_access allow hcity_backoffice_users backoffice_allowed_sites
http_access allow register_users register_allowed_sites
http_access allow hcity_register_users hcity_register_allowed_sites
no_cache deny partycity
http_access deny all

#http_access allow manager localhost
#http_access deny manager

# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
#http_access deny CONNECT !SSL_ports
http_access? allow CONNECT SSL_ports
# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
http_access deny to_localhost


# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
#http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 3128 ssl-bump \
key=/etc/squid/pctysquid2sslcerts/pctysquid2prod.pkey \
cert=/etc/squid/pctysquid2sslcerts/pctysquid2prod.crt \
generate-host-certificates=on dynamic_cert_mem_cache_size=4MB

acl step1 at_step SslBump1
ssl_bump peek step1
ssl_bump bump all

sslproxy_cert_error allow all
always_direct allow all
sslproxy_flags DONT_VERIFY_PEER

sslcrtd_program /usr/lib64/squid/ssl_crtd -s /var/lib/ssl_db -M 4MB
sslcrtd_children 8 startup=1 idle=1

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /cache/squid 10000 16 256

# Leave coredumps in the first cache dir
#rdescoredump_dir /var/spool/squid
coredump_dir /var/log/squid/squid

# Add any of your own refresh_pattern entries above these.
refresh_pattern ^ftp:?????????? 1440??? 20%???? 10080
refresh_pattern ^gopher:??????? 1440??? 0%????? 1440
refresh_pattern -i (/cgi-bin/|\?) 0???? 0%????? 0
refresh_pattern .?????????????? 0?????? 20%???? 4320

#url_rewrite_access allow all
#url_rewrite_program /usr/bin/squidGuard -c /etc/squid/squidguard.conf

Cache.log

2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 689:
error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
(1/0)
2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 1114:
error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
(1/0)
2017/07/18 16:05:37 kid1| Error negotiating SSL connection on FD 146:
error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
(1/0)
2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 252:
error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
(1/0)
2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 36:
error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
(1/0)



From eliezer at ngtech.co.il  Wed Jul 19 18:03:43 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 19 Jul 2017 21:03:43 +0300
Subject: [squid-users] Packets logged as blocked even Firewall
	(IPtables)	accepts them ...
In-Reply-To: <9f5b64baa348d726e9c0da763361be9c.1500380944@squirrel.mail>
References: <9f5b64baa348d726e9c0da763361be9c.1500380944@squirrel.mail>
Message-ID: <168b01d300b9$5beb8db0$13c2a910$@ngtech.co.il>

Hey Walter,

Can you please paste the output of "iptables-save" for me?
It's easier for me to read plain iptables-save then iptables -Lnv or any other format.
Then I would be able to send you a file that you can just pull into iptables-restore which should work.

And just to clear out my doubts on the scenario:
Is the RST packets coming from the gateway(192.168.0.1) but for request from the local proxy(192.168.0.10).
To eliminate couple things, can you test the next rule on the GW:
Iptables -I INPUT -s 192.168.0.10 -j ACCEPT

And see if it changes anything at all?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Walter H.
Sent: Tuesday, July 18, 2017 15:29
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Packets logged as blocked even Firewall (IPtables) accepts them ...

Hello,

my Router Box runs a CentOS 6, with the EPEL squid34 RPM package

this the iptables
<BEGIN /etc/sysconfig/iptables>
*filter
:INPUT DROP [0:0]
:FORWARD DROP [0:0]
:OUTPUT DROP [0:0]

# Allow multicast
-A INPUT -d 224.0.0.0/4 -j ACCEPT
-A OUTPUT -d 224.0.0.0/4 -j ACCEPT

# Allow anything on the local link
-A INPUT -i lo -j ACCEPT
-A OUTPUT -o lo -j ACCEPT

# Allow anything out on LAN
-A OUTPUT -o br0 -j ACCEPT
# Allow established, related packets back in -A INPUT -i br0 -m state --state ESTABLISHED,RELATED -j ACCEPT

# Enable DHCP for LAN
-A INPUT -i br0 -m udp -p udp --sport 67:68 --dport 67:68 -j ACCEPT

# Enable DNS-Cache for LAN
-A INPUT -i br0 -m tcp -p tcp --dport 53 -m state --state NEW -j ACCEPT -A INPUT -i br0 -m udp -p udp --dport 53 -j ACCEPT

# Enable SSH from LAN
-A INPUT -i br0 -m tcp -p tcp --dport 22 -m state --state NEW -j ACCEPT

# Enable HTTP/HTTPS from LAN (some gui interface) -A INPUT -i br0 -m tcp -p tcp --dport 80 -m state --state NEW -j ACCEPT -A INPUT -i br0 -m tcp -p tcp --dport 443 -m state --state NEW -j ACCEPT

# Enable Squid-Proxy from LAN
-A INPUT -i br0 -m tcp -p tcp --dport 3128 -m state --state NEW -j ACCEPT

# Block STUN
-A FORWARD -i br0 -o eth1 -m udp -p udp --dport 3478 -j REJECT # Block TEREDO -A FORWARD -i br0 -o eth1 -m udp -p udp --dport 3544 -j REJECT

# Allow Forwarding to WAN interface
-A FORWARD -i br0 -o eth1 -j ACCEPT
# Allow established, related packets back through -A FORWARD -i eth1 -o br0 -m state --state ESTABLISHED,RELATED -j ACCEPT

# Only the lan is allowed to ping me without restriction -A INPUT -i br0 -p icmp -j ACCEPT # Else only pings with restricted icmp are allowed -A INPUT -i eth1 -p icmp -m limit --limit 2/sec --limit-burst 4 -j ACCEPT

# Enable TRACEroute to me from LAN
-A INPUT -i br0 -p udp --sport 32769:65535 --dport 33434:33523 -j ACCEPT # Enable TRACEroute to me from internet -A INPUT -i eth1 -p udp --sport 32769:65535 --dport 33434:33523 -j ACCEPT

# Log all other
-A INPUT -j LOG --log-prefix "IP[IN]: " --log-level 7 -A FORWARD -j LOG  --log-prefix "IP[FWD]: " --log-level 7 -A OUTPUT -j LOG  --log-prefix "IP[OUT]: " --log-level 7

COMMIT
<END /etc/sysconfig/iptables>

and these are logged entries:
(only partial, as they are many)

<BEGIN dmesg>
[17-Jul-2017; 19:49:13.590130] IP[IN]: IN=br0 OUT=
MAC=24:01:00:00:01:24:24:00:08:01:05:24:08:00 SRC=192.168.0.10
DST=192.168.0.1 LEN=40 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP
SPT=54916 DPT=3128 WINDOW=0 RES=0x00 RST URGP=0 [17-Jul-2017; 19:49:13.590236] IP[IN]: IN=br0 OUT=
MAC=24:01:00:00:01:24:24:00:08:01:05:24:08:00 SRC=192.168.0.10
DST=192.168.0.1 LEN=40 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP
SPT=54916 DPT=3128 WINDOW=0 RES=0x00 RST URGP=0 [18-Jul-2017; 13:02:19.162684] IP[IN]: IN=br0 OUT=
MAC=24:01:00:00:01:24:24:ff:ff:ff:ff:24:08:00 SRC=192.168.0.2
DST=192.168.0.1 LEN=40 TOS=0x00 PREC=0x00 TTL=128 ID=28792 DF PROTO=TCP
SPT=1219 DPT=3128 WINDOW=65125 RES=0x00 ACK FIN URGP=0 [18-Jul-2017; 13:02:19.593099] IP[IN]: IN=br0 OUT=
MAC=24:01:00:00:01:24:24:ff:ff:ff:ff:24:08:00 SRC=192.168.0.2
DST=192.168.0.1 LEN=109 TOS=0x00 PREC=0x00 TTL=128 ID=28797 DF PROTO=TCP
SPT=1219 DPT=3128 WINDOW=65125 RES=0x00 ACK PSH FIN URGP=0 <END dmesg>

192.168.0.1  is the router itself
192.168.0.10  is a VM running another squid, using the router box as parent proxy
192.168.0.2   is my windows box

why are these packets blocked?

by the way the router box has of course more interfaces a br0 (LAN) and eth1 (WAN), where can I ensure that squid only listens to the LAN IP?

<BEGIN squid.conf>
acl localnet src 192.168.0.0/24

acl SSL_ports port 443
acl Safe_ports port 80                # http
acl Safe_ports port 21                # ftp
acl Safe_ports port 443                # https
acl Safe_ports port 70                # gopher
acl Safe_ports port 1025-65535        # unregistered ports
acl CONNECT method CONNECT

http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports http_access deny CONNECT !SSL_ports

http_access deny to_localhost

http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy http_access deny all

# and finally allow by default
http_reply_access allow all

# Squid normally listens to port 3128
http_port 3128

# Uncomment and adjust the following to add a disk cache directory.
cache_dir ufs /var/spool/squid 16400 16 256

# Leave coredumps in the first cache dir coredump_dir /var/spool/squid

acl crl-mime rep_mime_type application/x-pkcs7-crl no_cache deny crl-mime

icon_directory /usr/share/squid/icons
error_directory /etc/squid/errors

logformat combined %>A %[ui %[un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh access_log /var/log/squid/access.log combined

refresh_pattern ^ftp:                1440        20%        10080
refresh_pattern ^gopher:        1440        0%        1440
refresh_pattern -i (/cgi-bin/|\?) 0        0%        0
refresh_pattern .                0        20%        4320
<END squid.conf>

Thanks,
Walter

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From eliezer at ngtech.co.il  Wed Jul 19 18:08:31 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 19 Jul 2017 21:08:31 +0300
Subject: [squid-users] Problem with login to website by Squid web
	proxy	3.5.20 on Centos 7
In-Reply-To: <bbb86484-cef7-e6cb-8e07-36f3768ec0bd@poczta.wp.pl>
References: <bbb86484-cef7-e6cb-8e07-36f3768ec0bd@poczta.wp.pl>
Message-ID: <168d01d300ba$07678c20$1636a460$@ngtech.co.il>

Hey iziz1,

Can you try to add squid.conf the next and see if it affects anything:
forwarded_for delete
via off

http://www.squid-cache.org/Doc/config/via/
http://www.squid-cache.org/Doc/config/forwarded_for/

And see if it changes anything?

Let Me Know if something changes,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Kurczewski, Bart?omiej (WP.PL)
Sent: Tuesday, July 18, 2017 15:56
To: squid-users at lists.squid-cache.org
Subject: [squid-users] Problem with login to website by Squid web proxy 3.5.20 on Centos 7

Hi,
I have a problem to login to one website (http://intouch.techdata.com)
using Squid 3.5.20 on Centos 7 with default Squid configuration, which
is acting as web proxy (non-transparent) on 3128 port in my network:

--------------------------------------------------------------------------
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
acl localnet src 172.16.0.0/12	# RFC1918 possible internal network
acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines

acl SSL_ports port 443
acl Safe_ports port 80		# http
acl Safe_ports port 21		# ftp
acl Safe_ports port 443		# https
acl Safe_ports port 70		# gopher
acl Safe_ports port 210		# wais
acl Safe_ports port 1025-65535	# unregistered ports
acl Safe_ports port 280		# http-mgmt
acl Safe_ports port 488		# gss-http
acl Safe_ports port 591		# filemaker
acl Safe_ports port 777		# multiling http
acl CONNECT method CONNECT

#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 3128

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /var/spool/squid 100 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:		1440	20%	10080
refresh_pattern ^gopher:	1440	0%	1440
refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
refresh_pattern .		0	20%	4320
------------------------------------------------------------------------------


In a FF browser with my Squid server settings I put correct password on
techdata website, but webpage redirect me to the same web form and
doesn't allow to login. The password is correct, because when I put
wrong password I got JavaScript alert from this website that password is
incorrect.

When I disable using Squid proxy in FF and use normal PAT connection via
my Juniper firewall everything works perfect on the same machine and I
can login to TechData website.
I Squid access.log I can see only this:

-----------------------------------------------------------------
1500364995.497    140 10.48.22.33 TCP_MISS/302 735 GET
http://intouch.techdata.com/intouch/Home.aspx? -
HIER_DIRECT/192.230.78.204 text/html
-----------------------------------------------------------------

I suspect some problems with redirection on TechData website, but spend
hours in Internet to find solution, unfortunately without success....
Maybe you can help me?

Regards,
iziz1

_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From yvoinov at gmail.com  Wed Jul 19 18:15:00 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 20 Jul 2017 00:15:00 +0600
Subject: [squid-users] Squid Version 3.5.20 Any Ideas
In-Reply-To: <596F973C.7040603@mathemainzel.info>
References: <89638057A560FB458C01C197F81C7F5D13F32404@PACERS.amscan.corp>
 <e653374f-020d-c213-6a0f-12dda8ebce32@gmail.com>
 <596F973C.7040603@mathemainzel.info>
Message-ID: <514983a6-9274-612d-5301-868c67b578a4@gmail.com>

This simple seems op does not installed proxy CA's public in clients. No
more.

And errors in cache.log (as well as client complaints) are unambiguously
shown.

All other ideas are your nonsense.


19.07.2017 23:30, Walter H. ?????:
> Hello,
>
> this seems not to be the problem, as the error messages are in
> cache.log, which is not a browser problem ...
>
> the question: are the SSL bumped sites in intranet, which use a self
> signed CA cert itself, which squid doesn't know?
>
> On 19.07.2017 17:36, Yuri wrote:
>>
>> http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
>>
>> http://i.imgur.com/A153C7A.png
>>
>>
>> 19.07.2017 21:34, Cherukuri, Naresh ?????:
>>>
>>> Hi All,
>>>
>>>  
>>>
>>> I installed Squid version 3.5.20 on RHEL 7 and generated self-signed
>>> CA certificates,  My users are complaining about certificate errors.
>>> When I looked at cache.log I see so many error messages like below.
>>> Below is my squid.conf file. Any ideas how to address below errors.
>>>
>>>
>
>>> Cache.log
>>>
>>>  
>>>
>>> 2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD
>>> 689: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert
>>> certificate unknown (1/0)
>>>
>>> 2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD
>>> 1114: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert
>>> certificate unknown (1/0)
>>>
>>> 2017/07/18 16:05:37 kid1| Error negotiating SSL connection on FD
>>> 146: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert
>>> certificate unknown (1/0)
>>>
>>> 2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD
>>> 252: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert
>>> certificate unknown (1/0)
>>>
>>> 2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 36:
>>> error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate
>>> unknown (1/0)
>>>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/e2ac2633/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/e2ac2633/attachment.sig>

From yvoinov at gmail.com  Wed Jul 19 18:25:26 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 20 Jul 2017 00:25:26 +0600
Subject: [squid-users] Squid Version 3.5.20 Any Ideas
In-Reply-To: <596F973C.7040603@mathemainzel.info>
References: <89638057A560FB458C01C197F81C7F5D13F32404@PACERS.amscan.corp>
 <e653374f-020d-c213-6a0f-12dda8ebce32@gmail.com>
 <596F973C.7040603@mathemainzel.info>
Message-ID: <6bb20814-f8ce-a04a-1ee4-5aeb71bf1f9c@gmail.com>

One out of two. Either the Squid does not see the OpenSSL/system root
CAs bundle, or the proxy CA's public key is not installed in the
clients. It's all.


19.07.2017 23:30, Walter H. ?????:
> Hello,
>
> this seems not to be the problem, as the error messages are in
> cache.log, which is not a browser problem ...
>
> the question: are the SSL bumped sites in intranet, which use a self
> signed CA cert itself, which squid doesn't know?
>
> On 19.07.2017 17:36, Yuri wrote:
>>
>> http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
>>
>> http://i.imgur.com/A153C7A.png
>>
>>
>> 19.07.2017 21:34, Cherukuri, Naresh ?????:
>>>
>>> Hi All,
>>>
>>>  
>>>
>>> I installed Squid version 3.5.20 on RHEL 7 and generated self-signed
>>> CA certificates,  My users are complaining about certificate errors.
>>> When I looked at cache.log I see so many error messages like below.
>>> Below is my squid.conf file. Any ideas how to address below errors.
>>>
>>>
>
>>> Cache.log
>>>
>>>  
>>>
>>> 2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD
>>> 689: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert
>>> certificate unknown (1/0)
>>>
>>> 2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD
>>> 1114: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert
>>> certificate unknown (1/0)
>>>
>>> 2017/07/18 16:05:37 kid1| Error negotiating SSL connection on FD
>>> 146: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert
>>> certificate unknown (1/0)
>>>
>>> 2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD
>>> 252: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert
>>> certificate unknown (1/0)
>>>
>>> 2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 36:
>>> error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate
>>> unknown (1/0)
>>>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/be8be0fa/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/be8be0fa/attachment.sig>

From Walter.H at mathemainzel.info  Wed Jul 19 18:37:53 2017
From: Walter.H at mathemainzel.info (Walter H.)
Date: Wed, 19 Jul 2017 20:37:53 +0200
Subject: [squid-users] Packets logged as blocked even Firewall
 (IPtables) accepts them ...
In-Reply-To: <168b01d300b9$5beb8db0$13c2a910$@ngtech.co.il>
References: <9f5b64baa348d726e9c0da763361be9c.1500380944@squirrel.mail>
 <168b01d300b9$5beb8db0$13c2a910$@ngtech.co.il>
Message-ID: <596FA701.60502@mathemainzel.info>

Hello Eliezer,

it is just this:

# Generated by iptables-save v1.4.7 on Wed Jul 19 20:25:22 2017
*filter
:INPUT DROP [0:0]
:FORWARD DROP [0:0]
:OUTPUT DROP [0:0]
-A INPUT -d 224.0.0.0/4 -j ACCEPT
-A INPUT -i lo -j ACCEPT
-A INPUT -i br0 -m state --state RELATED,ESTABLISHED -j ACCEPT
-A INPUT -i br0 -p udp -m udp --sport 67:68 --dport 67:68 -j ACCEPT
-A INPUT -i br0 -p tcp -m tcp --dport 53 -m state --state NEW -j ACCEPT
-A INPUT -i br0 -p udp -m udp --dport 53 -j ACCEPT
-A INPUT -i br0 -p tcp -m tcp --dport 22 -m state --state NEW -j ACCEPT
-A INPUT -i br0 -p tcp -m tcp --dport 80 -m state --state NEW -j ACCEPT
-A INPUT -i br0 -p tcp -m tcp --dport 443 -m state --state NEW -j ACCEPT
-A INPUT -i br0 -p tcp -m tcp --dport 3128 -m state --state NEW -j ACCEPT
-A INPUT -i eth1 -m state --state RELATED,ESTABLISHED -j ACCEPT
-A INPUT -i br0 -p icmp -j ACCEPT
-A INPUT -i eth1 -p icmp -m limit --limit 2/sec --limit-burst 4 -j ACCEPT
-A INPUT -i br0 -p udp -m udp --sport 32769:65535 --dport 33434:33523 -j 
ACCEPT
-A INPUT -i eth1 -p udp -m udp --sport 32769:65535 --dport 33434:33523 
-j ACCEPT
-A INPUT -j LOG --log-prefix "IP[IN]: " --log-level 7
-A FORWARD -i br0 -o eth1 -p udp -m udp --dport 3478 -j REJECT 
--reject-with icmp-port-unreachable
-A FORWARD -i br0 -o eth1 -p udp -m udp --dport 3544 -j REJECT 
--reject-with icmp-port-unreachable
-A FORWARD -j LOG --log-prefix "IP[FWD]: " --log-level 7
-A OUTPUT -d 224.0.0.0/4 -j ACCEPT
-A OUTPUT -o lo -j ACCEPT
-A OUTPUT -o br0 -j ACCEPT
-A OUTPUT -o eth1 -j ACCEPT
-A OUTPUT -j LOG --log-prefix "IP[OUT]: " --log-level 7
COMMIT
# Completed on Wed Jul 19 20:25:22 2017

Walter

On 19.07.2017 20:03, Eliezer Croitoru wrote:
> Hey Walter,
>
> Can you please paste the output of "iptables-save" for me?
> It's easier for me to read plain iptables-save then iptables -Lnv or any other format.
> Then I would be able to send you a file that you can just pull into iptables-restore which should work.
>
> And just to clear out my doubts on the scenario:
> Is the RST packets coming from the gateway(192.168.0.1) but for request from the local proxy(192.168.0.10).
> To eliminate couple things, can you test the next rule on the GW:
> Iptables -I INPUT -s 192.168.0.10 -j ACCEPT
>
> And see if it changes anything at all?
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Walter H.
> Sent: Tuesday, July 18, 2017 15:29
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Packets logged as blocked even Firewall (IPtables) accepts them ...
>
> Hello,
>
> my Router Box runs a CentOS 6, with the EPEL squid34 RPM package
>
> this the iptables
> <BEGIN /etc/sysconfig/iptables>
> *filter
> :INPUT DROP [0:0]
> :FORWARD DROP [0:0]
> :OUTPUT DROP [0:0]
>
> # Allow multicast
> -A INPUT -d 224.0.0.0/4 -j ACCEPT
> -A OUTPUT -d 224.0.0.0/4 -j ACCEPT
>
> # Allow anything on the local link
> -A INPUT -i lo -j ACCEPT
> -A OUTPUT -o lo -j ACCEPT
>
> # Allow anything out on LAN
> -A OUTPUT -o br0 -j ACCEPT
> # Allow established, related packets back in -A INPUT -i br0 -m state --state ESTABLISHED,RELATED -j ACCEPT
>
> # Enable DHCP for LAN
> -A INPUT -i br0 -m udp -p udp --sport 67:68 --dport 67:68 -j ACCEPT
>
> # Enable DNS-Cache for LAN
> -A INPUT -i br0 -m tcp -p tcp --dport 53 -m state --state NEW -j ACCEPT -A INPUT -i br0 -m udp -p udp --dport 53 -j ACCEPT
>
> # Enable SSH from LAN
> -A INPUT -i br0 -m tcp -p tcp --dport 22 -m state --state NEW -j ACCEPT
>
> # Enable HTTP/HTTPS from LAN (some gui interface) -A INPUT -i br0 -m tcp -p tcp --dport 80 -m state --state NEW -j ACCEPT -A INPUT -i br0 -m tcp -p tcp --dport 443 -m state --state NEW -j ACCEPT
>
> # Enable Squid-Proxy from LAN
> -A INPUT -i br0 -m tcp -p tcp --dport 3128 -m state --state NEW -j ACCEPT
>
> # Block STUN
> -A FORWARD -i br0 -o eth1 -m udp -p udp --dport 3478 -j REJECT # Block TEREDO -A FORWARD -i br0 -o eth1 -m udp -p udp --dport 3544 -j REJECT
>
> # Allow Forwarding to WAN interface
> -A FORWARD -i br0 -o eth1 -j ACCEPT
> # Allow established, related packets back through -A FORWARD -i eth1 -o br0 -m state --state ESTABLISHED,RELATED -j ACCEPT
>
> # Only the lan is allowed to ping me without restriction -A INPUT -i br0 -p icmp -j ACCEPT # Else only pings with restricted icmp are allowed -A INPUT -i eth1 -p icmp -m limit --limit 2/sec --limit-burst 4 -j ACCEPT
>
> # Enable TRACEroute to me from LAN
> -A INPUT -i br0 -p udp --sport 32769:65535 --dport 33434:33523 -j ACCEPT # Enable TRACEroute to me from internet -A INPUT -i eth1 -p udp --sport 32769:65535 --dport 33434:33523 -j ACCEPT
>
> # Log all other
> -A INPUT -j LOG --log-prefix "IP[IN]: " --log-level 7 -A FORWARD -j LOG  --log-prefix "IP[FWD]: " --log-level 7 -A OUTPUT -j LOG  --log-prefix "IP[OUT]: " --log-level 7
>
> COMMIT
> <END /etc/sysconfig/iptables>
>
> and these are logged entries:
> (only partial, as they are many)
>
> <BEGIN dmesg>
> [17-Jul-2017; 19:49:13.590130] IP[IN]: IN=br0 OUT=
> MAC=24:01:00:00:01:24:24:00:08:01:05:24:08:00 SRC=192.168.0.10
> DST=192.168.0.1 LEN=40 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP
> SPT=54916 DPT=3128 WINDOW=0 RES=0x00 RST URGP=0 [17-Jul-2017; 19:49:13.590236] IP[IN]: IN=br0 OUT=
> MAC=24:01:00:00:01:24:24:00:08:01:05:24:08:00 SRC=192.168.0.10
> DST=192.168.0.1 LEN=40 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP
> SPT=54916 DPT=3128 WINDOW=0 RES=0x00 RST URGP=0 [18-Jul-2017; 13:02:19.162684] IP[IN]: IN=br0 OUT=
> MAC=24:01:00:00:01:24:24:ff:ff:ff:ff:24:08:00 SRC=192.168.0.2
> DST=192.168.0.1 LEN=40 TOS=0x00 PREC=0x00 TTL=128 ID=28792 DF PROTO=TCP
> SPT=1219 DPT=3128 WINDOW=65125 RES=0x00 ACK FIN URGP=0 [18-Jul-2017; 13:02:19.593099] IP[IN]: IN=br0 OUT=
> MAC=24:01:00:00:01:24:24:ff:ff:ff:ff:24:08:00 SRC=192.168.0.2
> DST=192.168.0.1 LEN=109 TOS=0x00 PREC=0x00 TTL=128 ID=28797 DF PROTO=TCP
> SPT=1219 DPT=3128 WINDOW=65125 RES=0x00 ACK PSH FIN URGP=0<END dmesg>
>
> 192.168.0.1  is the router itself
> 192.168.0.10  is a VM running another squid, using the router box as parent proxy
> 192.168.0.2   is my windows box
>
> why are these packets blocked?
>
> by the way the router box has of course more interfaces a br0 (LAN) and eth1 (WAN), where can I ensure that squid only listens to the LAN IP?
>
> <BEGIN squid.conf>
> acl localnet src 192.168.0.0/24
>
> acl SSL_ports port 443
> acl Safe_ports port 80                # http
> acl Safe_ports port 21                # ftp
> acl Safe_ports port 443                # https
> acl Safe_ports port 70                # gopher
> acl Safe_ports port 1025-65535        # unregistered ports
> acl CONNECT method CONNECT
>
> http_access deny !Safe_ports
>
> # Deny CONNECT to other than secure SSL ports http_access deny CONNECT !SSL_ports
>
> http_access deny to_localhost
>
> http_access allow localnet
> http_access allow localhost
>
> # And finally deny all other access to this proxy http_access deny all
>
> # and finally allow by default
> http_reply_access allow all
>
> # Squid normally listens to port 3128
> http_port 3128
>
> # Uncomment and adjust the following to add a disk cache directory.
> cache_dir ufs /var/spool/squid 16400 16 256
>
> # Leave coredumps in the first cache dir coredump_dir /var/spool/squid
>
> acl crl-mime rep_mime_type application/x-pkcs7-crl no_cache deny crl-mime
>
> icon_directory /usr/share/squid/icons
> error_directory /etc/squid/errors
>
> logformat combined %>A %[ui %[un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh access_log /var/log/squid/access.log combined
>
> refresh_pattern ^ftp:                1440        20%        10080
> refresh_pattern ^gopher:        1440        0%        1440
> refresh_pattern -i (/cgi-bin/|\?) 0        0%        0
> refresh_pattern .                0        20%        4320
> <END squid.conf>
>
> Thanks,
> Walter
>


-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3491 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170719/d6e7485b/attachment.bin>

From eliezer at ngtech.co.il  Wed Jul 19 19:47:47 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Wed, 19 Jul 2017 22:47:47 +0300
Subject: [squid-users] Packets logged as blocked even Firewall
	(IPtables) accepts them ...
In-Reply-To: <596FA701.60502@mathemainzel.info>
References: <9f5b64baa348d726e9c0da763361be9c.1500380944@squirrel.mail>
 <168b01d300b9$5beb8db0$13c2a910$@ngtech.co.il>
 <596FA701.60502@mathemainzel.info>
Message-ID: <16d701d300c7$e5eaf970$b1c0ec50$@ngtech.co.il>

Hey Walter,

Something is still missing to me about the network and network interfaces.
I need the output of:
ip a
brctl show br0

And try to apply the next iptables rules to see if it works OK for you:
http://ngtech.co.il/paste/1782/raw/

>From what I understand the proxy is just another machine in the network so the I do not understand what for the br0 and what is eth1...
If eth1 is under br0 you should not apply any rules on the eth1 and remove any ip address from eth1.
Also the FORWARD rules should not be required unless you are using the squid machine as a Gateway and from your description it's not the goal so a simple DROP all should be fine.
Also if you have followed some tutorial to setup your iptables and\or squid It will help me to see these since for squid as far as I know you don't need:
-A INPUT -d 224.0.0.0/4 -j ACCEPT

Or similar rules.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: Walter H. [mailto:Walter.H at mathemainzel.info] 
Sent: Wednesday, July 19, 2017 21:38
To: Eliezer Croitoru <eliezer at ngtech.co.il>
Cc: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Packets logged as blocked even Firewall (IPtables) accepts them ...

Hello Eliezer,

it is just this:

# Generated by iptables-save v1.4.7 on Wed Jul 19 20:25:22 2017
*filter
:INPUT DROP [0:0]
:FORWARD DROP [0:0]
:OUTPUT DROP [0:0]
-A INPUT -d 224.0.0.0/4 -j ACCEPT
-A INPUT -i lo -j ACCEPT
-A INPUT -i br0 -m state --state RELATED,ESTABLISHED -j ACCEPT
-A INPUT -i br0 -p udp -m udp --sport 67:68 --dport 67:68 -j ACCEPT
-A INPUT -i br0 -p tcp -m tcp --dport 53 -m state --state NEW -j ACCEPT
-A INPUT -i br0 -p udp -m udp --dport 53 -j ACCEPT
-A INPUT -i br0 -p tcp -m tcp --dport 22 -m state --state NEW -j ACCEPT
-A INPUT -i br0 -p tcp -m tcp --dport 80 -m state --state NEW -j ACCEPT
-A INPUT -i br0 -p tcp -m tcp --dport 443 -m state --state NEW -j ACCEPT
-A INPUT -i br0 -p tcp -m tcp --dport 3128 -m state --state NEW -j ACCEPT
-A INPUT -i eth1 -m state --state RELATED,ESTABLISHED -j ACCEPT
-A INPUT -i br0 -p icmp -j ACCEPT
-A INPUT -i eth1 -p icmp -m limit --limit 2/sec --limit-burst 4 -j ACCEPT
-A INPUT -i br0 -p udp -m udp --sport 32769:65535 --dport 33434:33523 -j 
ACCEPT
-A INPUT -i eth1 -p udp -m udp --sport 32769:65535 --dport 33434:33523 
-j ACCEPT
-A INPUT -j LOG --log-prefix "IP[IN]: " --log-level 7
-A FORWARD -i br0 -o eth1 -p udp -m udp --dport 3478 -j REJECT 
--reject-with icmp-port-unreachable
-A FORWARD -i br0 -o eth1 -p udp -m udp --dport 3544 -j REJECT 
--reject-with icmp-port-unreachable
-A FORWARD -j LOG --log-prefix "IP[FWD]: " --log-level 7
-A OUTPUT -d 224.0.0.0/4 -j ACCEPT
-A OUTPUT -o lo -j ACCEPT
-A OUTPUT -o br0 -j ACCEPT
-A OUTPUT -o eth1 -j ACCEPT
-A OUTPUT -j LOG --log-prefix "IP[OUT]: " --log-level 7
COMMIT
# Completed on Wed Jul 19 20:25:22 2017

Walter

On 19.07.2017 20:03, Eliezer Croitoru wrote:
> Hey Walter,
>
> Can you please paste the output of "iptables-save" for me?
> It's easier for me to read plain iptables-save then iptables -Lnv or any other format.
> Then I would be able to send you a file that you can just pull into iptables-restore which should work.
>
> And just to clear out my doubts on the scenario:
> Is the RST packets coming from the gateway(192.168.0.1) but for request from the local proxy(192.168.0.10).
> To eliminate couple things, can you test the next rule on the GW:
> Iptables -I INPUT -s 192.168.0.10 -j ACCEPT
>
> And see if it changes anything at all?
>
> Eliezer
>
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
>
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Walter H.
> Sent: Tuesday, July 18, 2017 15:29
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Packets logged as blocked even Firewall (IPtables) accepts them ...
>
> Hello,
>
> my Router Box runs a CentOS 6, with the EPEL squid34 RPM package
>
> this the iptables
> <BEGIN /etc/sysconfig/iptables>
> *filter
> :INPUT DROP [0:0]
> :FORWARD DROP [0:0]
> :OUTPUT DROP [0:0]
>
> # Allow multicast
> -A INPUT -d 224.0.0.0/4 -j ACCEPT
> -A OUTPUT -d 224.0.0.0/4 -j ACCEPT
>
> # Allow anything on the local link
> -A INPUT -i lo -j ACCEPT
> -A OUTPUT -o lo -j ACCEPT
>
> # Allow anything out on LAN
> -A OUTPUT -o br0 -j ACCEPT
> # Allow established, related packets back in -A INPUT -i br0 -m state --state ESTABLISHED,RELATED -j ACCEPT
>
> # Enable DHCP for LAN
> -A INPUT -i br0 -m udp -p udp --sport 67:68 --dport 67:68 -j ACCEPT
>
> # Enable DNS-Cache for LAN
> -A INPUT -i br0 -m tcp -p tcp --dport 53 -m state --state NEW -j ACCEPT -A INPUT -i br0 -m udp -p udp --dport 53 -j ACCEPT
>
> # Enable SSH from LAN
> -A INPUT -i br0 -m tcp -p tcp --dport 22 -m state --state NEW -j ACCEPT
>
> # Enable HTTP/HTTPS from LAN (some gui interface) -A INPUT -i br0 -m tcp -p tcp --dport 80 -m state --state NEW -j ACCEPT -A INPUT -i br0 -m tcp -p tcp --dport 443 -m state --state NEW -j ACCEPT
>
> # Enable Squid-Proxy from LAN
> -A INPUT -i br0 -m tcp -p tcp --dport 3128 -m state --state NEW -j ACCEPT
>
> # Block STUN
> -A FORWARD -i br0 -o eth1 -m udp -p udp --dport 3478 -j REJECT # Block TEREDO -A FORWARD -i br0 -o eth1 -m udp -p udp --dport 3544 -j REJECT
>
> # Allow Forwarding to WAN interface
> -A FORWARD -i br0 -o eth1 -j ACCEPT
> # Allow established, related packets back through -A FORWARD -i eth1 -o br0 -m state --state ESTABLISHED,RELATED -j ACCEPT
>
> # Only the lan is allowed to ping me without restriction -A INPUT -i br0 -p icmp -j ACCEPT # Else only pings with restricted icmp are allowed -A INPUT -i eth1 -p icmp -m limit --limit 2/sec --limit-burst 4 -j ACCEPT
>
> # Enable TRACEroute to me from LAN
> -A INPUT -i br0 -p udp --sport 32769:65535 --dport 33434:33523 -j ACCEPT # Enable TRACEroute to me from internet -A INPUT -i eth1 -p udp --sport 32769:65535 --dport 33434:33523 -j ACCEPT
>
> # Log all other
> -A INPUT -j LOG --log-prefix "IP[IN]: " --log-level 7 -A FORWARD -j LOG  --log-prefix "IP[FWD]: " --log-level 7 -A OUTPUT -j LOG  --log-prefix "IP[OUT]: " --log-level 7
>
> COMMIT
> <END /etc/sysconfig/iptables>
>
> and these are logged entries:
> (only partial, as they are many)
>
> <BEGIN dmesg>
> [17-Jul-2017; 19:49:13.590130] IP[IN]: IN=br0 OUT=
> MAC=24:01:00:00:01:24:24:00:08:01:05:24:08:00 SRC=192.168.0.10
> DST=192.168.0.1 LEN=40 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP
> SPT=54916 DPT=3128 WINDOW=0 RES=0x00 RST URGP=0 [17-Jul-2017; 19:49:13.590236] IP[IN]: IN=br0 OUT=
> MAC=24:01:00:00:01:24:24:00:08:01:05:24:08:00 SRC=192.168.0.10
> DST=192.168.0.1 LEN=40 TOS=0x00 PREC=0x00 TTL=64 ID=0 DF PROTO=TCP
> SPT=54916 DPT=3128 WINDOW=0 RES=0x00 RST URGP=0 [18-Jul-2017; 13:02:19.162684] IP[IN]: IN=br0 OUT=
> MAC=24:01:00:00:01:24:24:ff:ff:ff:ff:24:08:00 SRC=192.168.0.2
> DST=192.168.0.1 LEN=40 TOS=0x00 PREC=0x00 TTL=128 ID=28792 DF PROTO=TCP
> SPT=1219 DPT=3128 WINDOW=65125 RES=0x00 ACK FIN URGP=0 [18-Jul-2017; 13:02:19.593099] IP[IN]: IN=br0 OUT=
> MAC=24:01:00:00:01:24:24:ff:ff:ff:ff:24:08:00 SRC=192.168.0.2
> DST=192.168.0.1 LEN=109 TOS=0x00 PREC=0x00 TTL=128 ID=28797 DF PROTO=TCP
> SPT=1219 DPT=3128 WINDOW=65125 RES=0x00 ACK PSH FIN URGP=0<END dmesg>
>
> 192.168.0.1  is the router itself
> 192.168.0.10  is a VM running another squid, using the router box as parent proxy
> 192.168.0.2   is my windows box
>
> why are these packets blocked?
>
> by the way the router box has of course more interfaces a br0 (LAN) and eth1 (WAN), where can I ensure that squid only listens to the LAN IP?
>
> <BEGIN squid.conf>
> acl localnet src 192.168.0.0/24
>
> acl SSL_ports port 443
> acl Safe_ports port 80                # http
> acl Safe_ports port 21                # ftp
> acl Safe_ports port 443                # https
> acl Safe_ports port 70                # gopher
> acl Safe_ports port 1025-65535        # unregistered ports
> acl CONNECT method CONNECT
>
> http_access deny !Safe_ports
>
> # Deny CONNECT to other than secure SSL ports http_access deny CONNECT !SSL_ports
>
> http_access deny to_localhost
>
> http_access allow localnet
> http_access allow localhost
>
> # And finally deny all other access to this proxy http_access deny all
>
> # and finally allow by default
> http_reply_access allow all
>
> # Squid normally listens to port 3128
> http_port 3128
>
> # Uncomment and adjust the following to add a disk cache directory.
> cache_dir ufs /var/spool/squid 16400 16 256
>
> # Leave coredumps in the first cache dir coredump_dir /var/spool/squid
>
> acl crl-mime rep_mime_type application/x-pkcs7-crl no_cache deny crl-mime
>
> icon_directory /usr/share/squid/icons
> error_directory /etc/squid/errors
>
> logformat combined %>A %[ui %[un [%tl] "%rm %ru HTTP/%rv" %>Hs %<st "%{Referer}>h" "%{User-Agent}>h" %Ss:%Sh access_log /var/log/squid/access.log combined
>
> refresh_pattern ^ftp:                1440        20%        10080
> refresh_pattern ^gopher:        1440        0%        1440
> refresh_pattern -i (/cgi-bin/|\?) 0        0%        0
> refresh_pattern .                0        20%        4320
> <END squid.conf>
>
> Thanks,
> Walter
>





From ncherukuri at partycity.com  Wed Jul 19 20:49:02 2017
From: ncherukuri at partycity.com (Cherukuri, Naresh)
Date: Wed, 19 Jul 2017 20:49:02 +0000
Subject: [squid-users] Squid Version 3.5.20 Any Ideas
In-Reply-To: <6bb20814-f8ce-a04a-1ee4-5aeb71bf1f9c@gmail.com>
References: <89638057A560FB458C01C197F81C7F5D13F32404@PACERS.amscan.corp>
 <e653374f-020d-c213-6a0f-12dda8ebce32@gmail.com>
 <596F973C.7040603@mathemainzel.info>
 <6bb20814-f8ce-a04a-1ee4-5aeb71bf1f9c@gmail.com>
Message-ID: <89638057A560FB458C01C197F81C7F5D13F32BF9@PACERS.amscan.corp>

Thanks Yuri for quick turnover!

We inly installed root certificate on all clients. We didn?t install proxy CA?s public key on clients. So you suggestion fix that we need to install both certificate and proxy ca?s public key on clients.

Thanks,
Naresh

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri
Sent: Wednesday, July 19, 2017 2:25 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid Version 3.5.20 Any Ideas


One out of two. Either the Squid does not see the OpenSSL/system root CAs bundle, or the proxy CA's public key is not installed in the clients. It's all.

19.07.2017 23:30, Walter H. ?????:
Hello,

this seems not to be the problem, as the error messages are in cache.log, which is not a browser problem ...

the question: are the SSL bumped sites in intranet, which use a self signed CA cert itself, which squid doesn't know?

On 19.07.2017 17:36, Yuri wrote:

http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit

http://i.imgur.com/A153C7A.png

19.07.2017 21:34, Cherukuri, Naresh ?????:

Hi All,



I installed Squid version 3.5.20 on RHEL 7 and generated self-signed CA certificates,  My users are complaining about certificate errors. When I looked at cache.log I see so many error messages like below. Below is my squid.conf file. Any ideas how to address below errors.




Cache.log



2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 689: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 1114: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

2017/07/18 16:05:37 kid1| Error negotiating SSL connection on FD 146: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 252: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 36: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)





_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

http://lists.squid-cache.org/listinfo/squid-users

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170719/6fa26d19/attachment.htm>

From yvoinov at gmail.com  Wed Jul 19 20:55:23 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 20 Jul 2017 02:55:23 +0600
Subject: [squid-users] Squid Version 3.5.20 Any Ideas
In-Reply-To: <89638057A560FB458C01C197F81C7F5D13F32BF9@PACERS.amscan.corp>
References: <89638057A560FB458C01C197F81C7F5D13F32404@PACERS.amscan.corp>
 <e653374f-020d-c213-6a0f-12dda8ebce32@gmail.com>
 <596F973C.7040603@mathemainzel.info>
 <6bb20814-f8ce-a04a-1ee4-5aeb71bf1f9c@gmail.com>
 <89638057A560FB458C01C197F81C7F5D13F32BF9@PACERS.amscan.corp>
Message-ID: <dce8f67e-a340-ffa0-0e42-1968e5b05fca@gmail.com>

No. Only proxy's CA public key. Private should remains on proxy only.


20.07.2017 2:49, Cherukuri, Naresh ?????:
>
> Thanks Yuri for quick turnover!
>
>  
>
> We inly installed root certificate on all clients. We didn?t install
> proxy CA?s public key on clients. So you suggestion fix that we need
> to install both certificate and proxy ca?s public key on clients.
>
>  
>
> Thanks,
>
> Naresh
>
>  
>
> *From:*squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
> *On Behalf Of *Yuri
> *Sent:* Wednesday, July 19, 2017 2:25 PM
> *To:* squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Squid Version 3.5.20 Any Ideas
>
>  
>
> One out of two. Either the Squid does not see the OpenSSL/system root
> CAs bundle, or the proxy CA's public key is not installed in the
> clients. It's all.
>
>  
>
> 19.07.2017 23:30, Walter H. ?????:
>
>     Hello,
>
>     this seems not to be the problem, as the error messages are in
>     cache.log, which is not a browser problem ...
>
>     the question: are the SSL bumped sites in intranet, which use a
>     self signed CA cert itself, which squid doesn't know?
>
>     On 19.07.2017 17:36, Yuri wrote:
>
>     http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
>
>     http://i.imgur.com/A153C7A.png
>
>      
>
>     19.07.2017 21:34, Cherukuri, Naresh ?????:
>
>         Hi All,
>
>          
>
>         I installed Squid version 3.5.20 on RHEL 7 and generated
>         self-signed CA certificates,  My users are complaining about
>         certificate errors. When I looked at cache.log I see so many
>         error messages like below. Below is my squid.conf file. Any
>         ideas how to address below errors.
>
>          
>
>
>
>         Cache.log
>
>          
>
>         2017/07/18 16:05:34 kid1| Error negotiating SSL connection on
>         FD 689: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3
>         alert certificate unknown (1/0)
>
>         2017/07/18 16:05:34 kid1| Error negotiating SSL connection on
>         FD 1114: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3
>         alert certificate unknown (1/0)
>
>         2017/07/18 16:05:37 kid1| Error negotiating SSL connection on
>         FD 146: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3
>         alert certificate unknown (1/0)
>
>         2017/07/18 16:05:41 kid1| Error negotiating SSL connection on
>         FD 252: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3
>         alert certificate unknown (1/0)
>
>         2017/07/18 16:05:41 kid1| Error negotiating SSL connection on
>         FD 36: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert
>         certificate unknown (1/0)
>
>
>
>
>
>     _______________________________________________
>
>     squid-users mailing list
>
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>  
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/3cfce1a3/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/3cfce1a3/attachment.sig>

From ncherukuri at partycity.com  Wed Jul 19 21:04:37 2017
From: ncherukuri at partycity.com (Cherukuri, Naresh)
Date: Wed, 19 Jul 2017 21:04:37 +0000
Subject: [squid-users] Squid Version 3.5.20 Any Ideas
In-Reply-To: <dce8f67e-a340-ffa0-0e42-1968e5b05fca@gmail.com>
References: <89638057A560FB458C01C197F81C7F5D13F32404@PACERS.amscan.corp>
 <e653374f-020d-c213-6a0f-12dda8ebce32@gmail.com>
 <596F973C.7040603@mathemainzel.info>
 <6bb20814-f8ce-a04a-1ee4-5aeb71bf1f9c@gmail.com>
 <89638057A560FB458C01C197F81C7F5D13F32BF9@PACERS.amscan.corp>
 <dce8f67e-a340-ffa0-0e42-1968e5b05fca@gmail.com>
Message-ID: <89638057A560FB458C01C197F81C7F5D13F32CA3@PACERS.amscan.corp>

Yuri,

I am sorry I didn?t get you I already installed certificate on all clients(trusted root certificate authorities). You want me install proxy public key also on clients, if so were should I put the proxy public key. Below is my squid.conf file.

Squid.conf
key=/etc/squid/pctysquid2sslcerts/pctysquid2prod.pkey \ proxy ca public key??
cert=/etc/squid/pctysquid2sslcerts/pctysquid2prod.crt \ (installed certificate on IE all clients as a trusted root certificate authorities)


From: Yuri [mailto:yvoinov at gmail.com]
Sent: Wednesday, July 19, 2017 4:55 PM
To: Cherukuri, Naresh; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid Version 3.5.20 Any Ideas


No. Only proxy's CA public key. Private should remains on proxy only.

20.07.2017 2:49, Cherukuri, Naresh ?????:
Thanks Yuri for quick turnover!

We inly installed root certificate on all clients. We didn?t install proxy CA?s public key on clients. So you suggestion fix that we need to install both certificate and proxy ca?s public key on clients.

Thanks,
Naresh

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri
Sent: Wednesday, July 19, 2017 2:25 PM
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Squid Version 3.5.20 Any Ideas


One out of two. Either the Squid does not see the OpenSSL/system root CAs bundle, or the proxy CA's public key is not installed in the clients. It's all.

19.07.2017 23:30, Walter H. ?????:
Hello,

this seems not to be the problem, as the error messages are in cache.log, which is not a browser problem ...

the question: are the SSL bumped sites in intranet, which use a self signed CA cert itself, which squid doesn't know?

On 19.07.2017 17:36, Yuri wrote:

http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit

http://i.imgur.com/A153C7A.png

19.07.2017 21:34, Cherukuri, Naresh ?????:

Hi All,



I installed Squid version 3.5.20 on RHEL 7 and generated self-signed CA certificates,  My users are complaining about certificate errors. When I looked at cache.log I see so many error messages like below. Below is my squid.conf file. Any ideas how to address below errors.





Cache.log



2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 689: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 1114: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

2017/07/18 16:05:37 kid1| Error negotiating SSL connection on FD 146: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 252: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 36: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)






_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170719/903107a5/attachment.htm>

From yvoinov at gmail.com  Wed Jul 19 21:06:22 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 20 Jul 2017 03:06:22 +0600
Subject: [squid-users] Squid Version 3.5.20 Any Ideas
In-Reply-To: <89638057A560FB458C01C197F81C7F5D13F32BF9@PACERS.amscan.corp>
References: <89638057A560FB458C01C197F81C7F5D13F32404@PACERS.amscan.corp>
 <e653374f-020d-c213-6a0f-12dda8ebce32@gmail.com>
 <596F973C.7040603@mathemainzel.info>
 <6bb20814-f8ce-a04a-1ee4-5aeb71bf1f9c@gmail.com>
 <89638057A560FB458C01C197F81C7F5D13F32BF9@PACERS.amscan.corp>
Message-ID: <640e364a-fd61-b699-c2da-87da9eceb438@gmail.com>

Related OpenSSL public CA bundle - in theory it should be installed
together with OpenSSL.


20.07.2017 2:49, Cherukuri, Naresh ?????:
>
> Thanks Yuri for quick turnover!
>
>  
>
> We inly installed root certificate on all clients. We didn?t install
> proxy CA?s public key on clients. So you suggestion fix that we need
> to install both certificate and proxy ca?s public key on clients.
>
>  
>
> Thanks,
>
> Naresh
>
>  
>
> *From:*squid-users [mailto:squid-users-bounces at lists.squid-cache.org]
> *On Behalf Of *Yuri
> *Sent:* Wednesday, July 19, 2017 2:25 PM
> *To:* squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Squid Version 3.5.20 Any Ideas
>
>  
>
> One out of two. Either the Squid does not see the OpenSSL/system root
> CAs bundle, or the proxy CA's public key is not installed in the
> clients. It's all.
>
>  
>
> 19.07.2017 23:30, Walter H. ?????:
>
>     Hello,
>
>     this seems not to be the problem, as the error messages are in
>     cache.log, which is not a browser problem ...
>
>     the question: are the SSL bumped sites in intranet, which use a
>     self signed CA cert itself, which squid doesn't know?
>
>     On 19.07.2017 17:36, Yuri wrote:
>
>     http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
>
>     http://i.imgur.com/A153C7A.png
>
>      
>
>     19.07.2017 21:34, Cherukuri, Naresh ?????:
>
>         Hi All,
>
>          
>
>         I installed Squid version 3.5.20 on RHEL 7 and generated
>         self-signed CA certificates,  My users are complaining about
>         certificate errors. When I looked at cache.log I see so many
>         error messages like below. Below is my squid.conf file. Any
>         ideas how to address below errors.
>
>          
>
>
>
>         Cache.log
>
>          
>
>         2017/07/18 16:05:34 kid1| Error negotiating SSL connection on
>         FD 689: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3
>         alert certificate unknown (1/0)
>
>         2017/07/18 16:05:34 kid1| Error negotiating SSL connection on
>         FD 1114: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3
>         alert certificate unknown (1/0)
>
>         2017/07/18 16:05:37 kid1| Error negotiating SSL connection on
>         FD 146: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3
>         alert certificate unknown (1/0)
>
>         2017/07/18 16:05:41 kid1| Error negotiating SSL connection on
>         FD 252: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3
>         alert certificate unknown (1/0)
>
>         2017/07/18 16:05:41 kid1| Error negotiating SSL connection on
>         FD 36: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert
>         certificate unknown (1/0)
>
>
>
>
>
>     _______________________________________________
>
>     squid-users mailing list
>
>     squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>
>     http://lists.squid-cache.org/listinfo/squid-users
>
>  
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/826a31ac/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/826a31ac/attachment.sig>

From ncherukuri at partycity.com  Wed Jul 19 21:09:28 2017
From: ncherukuri at partycity.com (Cherukuri, Naresh)
Date: Wed, 19 Jul 2017 21:09:28 +0000
Subject: [squid-users] Squid Version 3.5.20 Any Ideas
In-Reply-To: <640e364a-fd61-b699-c2da-87da9eceb438@gmail.com>
References: <89638057A560FB458C01C197F81C7F5D13F32404@PACERS.amscan.corp>
 <e653374f-020d-c213-6a0f-12dda8ebce32@gmail.com>
 <596F973C.7040603@mathemainzel.info>
 <6bb20814-f8ce-a04a-1ee4-5aeb71bf1f9c@gmail.com>
 <89638057A560FB458C01C197F81C7F5D13F32BF9@PACERS.amscan.corp>
 <640e364a-fd61-b699-c2da-87da9eceb438@gmail.com>
Message-ID: <89638057A560FB458C01C197F81C7F5D13F32CE8@PACERS.amscan.corp>

Yuri,

I am new to squid I learned it through searching google. My question is I generated self-signed SSL certificates and install certificates on IE all clients. I didn?t install proxy public key. Can you tell me where  I have to put proxy public key on clients. Appreciate you help!

Thanks,
Naresh

From: Yuri [mailto:yvoinov at gmail.com]
Sent: Wednesday, July 19, 2017 5:06 PM
To: Cherukuri, Naresh; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid Version 3.5.20 Any Ideas


Related OpenSSL public CA bundle - in theory it should be installed together with OpenSSL.

20.07.2017 2:49, Cherukuri, Naresh ?????:
Thanks Yuri for quick turnover!

We inly installed root certificate on all clients. We didn?t install proxy CA?s public key on clients. So you suggestion fix that we need to install both certificate and proxy ca?s public key on clients.

Thanks,
Naresh

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri
Sent: Wednesday, July 19, 2017 2:25 PM
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Squid Version 3.5.20 Any Ideas


One out of two. Either the Squid does not see the OpenSSL/system root CAs bundle, or the proxy CA's public key is not installed in the clients. It's all.

19.07.2017 23:30, Walter H. ?????:
Hello,

this seems not to be the problem, as the error messages are in cache.log, which is not a browser problem ...

the question: are the SSL bumped sites in intranet, which use a self signed CA cert itself, which squid doesn't know?

On 19.07.2017 17:36, Yuri wrote:

http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit

http://i.imgur.com/A153C7A.png

19.07.2017 21:34, Cherukuri, Naresh ?????:

Hi All,



I installed Squid version 3.5.20 on RHEL 7 and generated self-signed CA certificates,  My users are complaining about certificate errors. When I looked at cache.log I see so many error messages like below. Below is my squid.conf file. Any ideas how to address below errors.





Cache.log



2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 689: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 1114: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

2017/07/18 16:05:37 kid1| Error negotiating SSL connection on FD 146: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 252: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 36: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)






_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

http://lists.squid-cache.org/listinfo/squid-users


-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170719/ebdb9b56/attachment.htm>

From yvoinov at gmail.com  Wed Jul 19 21:10:10 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 20 Jul 2017 03:10:10 +0600
Subject: [squid-users] Squid Version 3.5.20 Any Ideas
In-Reply-To: <89638057A560FB458C01C197F81C7F5D13F32CA3@PACERS.amscan.corp>
References: <89638057A560FB458C01C197F81C7F5D13F32404@PACERS.amscan.corp>
 <e653374f-020d-c213-6a0f-12dda8ebce32@gmail.com>
 <596F973C.7040603@mathemainzel.info>
 <6bb20814-f8ce-a04a-1ee4-5aeb71bf1f9c@gmail.com>
 <89638057A560FB458C01C197F81C7F5D13F32BF9@PACERS.amscan.corp>
 <dce8f67e-a340-ffa0-0e42-1968e5b05fca@gmail.com>
 <89638057A560FB458C01C197F81C7F5D13F32CA3@PACERS.amscan.corp>
Message-ID: <f7da4b60-02f5-71ea-e7ff-23244b0f6b62@gmail.com>

Aha,


20.07.2017 3:04, Cherukuri, Naresh ?????:
>
> Yuri,
>
>  
>
> I am sorry I didn?t get you I already installed certificate on all
> clients(trusted root certificate authorities). You want me install
> proxy public key also on clients, if so were should I put the proxy
> public key. Below is my squid.conf file.
>
>  
>
> Squid.conf
>
> key=/etc/squid/pctysquid2sslcerts/pctysquid2prod.pkey \ proxy ca
> public key??
>
This is proxy private key AFAIK.
>
> cert=/etc/squid/pctysquid2sslcerts/pctysquid2prod.crt \(installed
> certificate on IE all clients as a trusted root certificate authorities)
>
Yes, if it installed into clients - this is ok.

So. The only reason I can see - proxy can't see OpenSSL CA's bundle.

To make it work you should add to your squid's config one of this:

#  TAG: sslproxy_cafile
#    file containing CA certificates to use when verifying server
#    certificates while proxying https:// URLs
#Default:
# none

#  TAG: sslproxy_capath
#    directory containing CA certificates to use when verifying
#    server certificates while proxying https:// URLs
#Default:
# none

Proxy also should know about CA's uses for connection verification.

>  
>
>  
>
> *From:*Yuri [mailto:yvoinov at gmail.com]
> *Sent:* Wednesday, July 19, 2017 4:55 PM
> *To:* Cherukuri, Naresh; squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Squid Version 3.5.20 Any Ideas
>
>  
>
> No. Only proxy's CA public key. Private should remains on proxy only.
>
>  
>
> 20.07.2017 2:49, Cherukuri, Naresh ?????:
>
>     Thanks Yuri for quick turnover!
>
>      
>
>     We inly installed root certificate on all clients. We didn?t
>     install proxy CA?s public key on clients. So you suggestion fix
>     that we need to install both certificate and proxy ca?s public key
>     on clients.
>
>      
>
>     Thanks,
>
>     Naresh
>
>      
>
>     *From:*squid-users
>     [mailto:squid-users-bounces at lists.squid-cache.org] *On Behalf Of *Yuri
>     *Sent:* Wednesday, July 19, 2017 2:25 PM
>     *To:* squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     *Subject:* Re: [squid-users] Squid Version 3.5.20 Any Ideas
>
>      
>
>     One out of two. Either the Squid does not see the OpenSSL/system
>     root CAs bundle, or the proxy CA's public key is not installed in
>     the clients. It's all.
>
>      
>
>     19.07.2017 23:30, Walter H. ?????:
>
>         Hello,
>
>         this seems not to be the problem, as the error messages are in
>         cache.log, which is not a browser problem ...
>
>         the question: are the SSL bumped sites in intranet, which use
>         a self signed CA cert itself, which squid doesn't know?
>
>         On 19.07.2017 17:36, Yuri wrote:
>
>         http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
>
>         http://i.imgur.com/A153C7A.png
>
>          
>
>         19.07.2017 21:34, Cherukuri, Naresh ?????:
>
>             Hi All,
>
>              
>
>             I installed Squid version 3.5.20 on RHEL 7 and generated
>             self-signed CA certificates,  My users are complaining
>             about certificate errors. When I looked at cache.log I see
>             so many error messages like below. Below is my squid.conf
>             file. Any ideas how to address below errors.
>
>              
>
>
>
>
>             Cache.log
>
>              
>
>             2017/07/18 16:05:34 kid1| Error negotiating SSL connection
>             on FD 689: error:14094416:SSL
>             routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
>             (1/0)
>
>             2017/07/18 16:05:34 kid1| Error negotiating SSL connection
>             on FD 1114: error:14094416:SSL
>             routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
>             (1/0)
>
>             2017/07/18 16:05:37 kid1| Error negotiating SSL connection
>             on FD 146: error:14094416:SSL
>             routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
>             (1/0)
>
>             2017/07/18 16:05:41 kid1| Error negotiating SSL connection
>             on FD 252: error:14094416:SSL
>             routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
>             (1/0)
>
>             2017/07/18 16:05:41 kid1| Error negotiating SSL connection
>             on FD 36: error:14094416:SSL
>             routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
>             (1/0)
>
>
>
>
>
>
>         _______________________________________________
>
>         squid-users mailing list
>
>         squid-users at lists.squid-cache.org
>         <mailto:squid-users at lists.squid-cache.org>
>
>         http://lists.squid-cache.org/listinfo/squid-users
>
>      
>
>  
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/053a3e65/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/053a3e65/attachment.sig>

From yvoinov at gmail.com  Wed Jul 19 21:15:14 2017
From: yvoinov at gmail.com (Yuri)
Date: Thu, 20 Jul 2017 03:15:14 +0600
Subject: [squid-users] Squid Version 3.5.20 Any Ideas
In-Reply-To: <89638057A560FB458C01C197F81C7F5D13F32CE8@PACERS.amscan.corp>
References: <89638057A560FB458C01C197F81C7F5D13F32404@PACERS.amscan.corp>
 <e653374f-020d-c213-6a0f-12dda8ebce32@gmail.com>
 <596F973C.7040603@mathemainzel.info>
 <6bb20814-f8ce-a04a-1ee4-5aeb71bf1f9c@gmail.com>
 <89638057A560FB458C01C197F81C7F5D13F32BF9@PACERS.amscan.corp>
 <640e364a-fd61-b699-c2da-87da9eceb438@gmail.com>
 <89638057A560FB458C01C197F81C7F5D13F32CE8@PACERS.amscan.corp>
Message-ID: <59772fe8-6c62-3d5d-efc1-e0e600188e8e@gmail.com>



20.07.2017 3:09, Cherukuri, Naresh ?????:
>
> Yuri,
>
>  
>
> I am new to squid I learned it through searching google. My question
> is I generated self-signed SSL certificates and install certificates
> on IE all clients. I didn?t install proxy public key. Can you tell me
> where  I have to put proxy public key on clients. Appreciate you help!
>
Ah. Based on my experience,

you require to take *public* proxy key (not private, your use keypair to
setup ssl-bump configuration; do not mistake it) and install it at least
into two places on client's PC:

1. Into system trusted CA storage (uses by IE/Chrome/some IM etc.)
2. Into Firefox own storage (if applicable).
3. Sometimes it is also required to setup proxy's CA public key into old
JRE existing on clients. But AFAIK modern JRE uses system CA's storage
and no more required this step.

Actually, this should be enough.
>
>  
>
> Thanks,
>
> Naresh
>
>  
>
> *From:*Yuri [mailto:yvoinov at gmail.com]
> *Sent:* Wednesday, July 19, 2017 5:06 PM
> *To:* Cherukuri, Naresh; squid-users at lists.squid-cache.org
> *Subject:* Re: [squid-users] Squid Version 3.5.20 Any Ideas
>
>  
>
> Related OpenSSL public CA bundle - in theory it should be installed
> together with OpenSSL.
>
>  
>
> 20.07.2017 2:49, Cherukuri, Naresh ?????:
>
>     Thanks Yuri for quick turnover!
>
>      
>
>     We inly installed root certificate on all clients. We didn?t
>     install proxy CA?s public key on clients. So you suggestion fix
>     that we need to install both certificate and proxy ca?s public key
>     on clients.
>
>      
>
>     Thanks,
>
>     Naresh
>
>      
>
>     *From:*squid-users
>     [mailto:squid-users-bounces at lists.squid-cache.org] *On Behalf Of *Yuri
>     *Sent:* Wednesday, July 19, 2017 2:25 PM
>     *To:* squid-users at lists.squid-cache.org
>     <mailto:squid-users at lists.squid-cache.org>
>     *Subject:* Re: [squid-users] Squid Version 3.5.20 Any Ideas
>
>      
>
>     One out of two. Either the Squid does not see the OpenSSL/system
>     root CAs bundle, or the proxy CA's public key is not installed in
>     the clients. It's all.
>
>      
>
>     19.07.2017 23:30, Walter H. ?????:
>
>         Hello,
>
>         this seems not to be the problem, as the error messages are in
>         cache.log, which is not a browser problem ...
>
>         the question: are the SSL bumped sites in intranet, which use
>         a self signed CA cert itself, which squid doesn't know?
>
>         On 19.07.2017 17:36, Yuri wrote:
>
>         http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit
>
>         http://i.imgur.com/A153C7A.png
>
>          
>
>         19.07.2017 21:34, Cherukuri, Naresh ?????:
>
>             Hi All,
>
>              
>
>             I installed Squid version 3.5.20 on RHEL 7 and generated
>             self-signed CA certificates,  My users are complaining
>             about certificate errors. When I looked at cache.log I see
>             so many error messages like below. Below is my squid.conf
>             file. Any ideas how to address below errors.
>
>              
>
>
>
>
>             Cache.log
>
>              
>
>             2017/07/18 16:05:34 kid1| Error negotiating SSL connection
>             on FD 689: error:14094416:SSL
>             routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
>             (1/0)
>
>             2017/07/18 16:05:34 kid1| Error negotiating SSL connection
>             on FD 1114: error:14094416:SSL
>             routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
>             (1/0)
>
>             2017/07/18 16:05:37 kid1| Error negotiating SSL connection
>             on FD 146: error:14094416:SSL
>             routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
>             (1/0)
>
>             2017/07/18 16:05:41 kid1| Error negotiating SSL connection
>             on FD 252: error:14094416:SSL
>             routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
>             (1/0)
>
>             2017/07/18 16:05:41 kid1| Error negotiating SSL connection
>             on FD 36: error:14094416:SSL
>             routines:SSL3_READ_BYTES:sslv3 alert certificate unknown
>             (1/0)
>
>
>
>
>
>
>         _______________________________________________
>
>         squid-users mailing list
>
>         squid-users at lists.squid-cache.org
>         <mailto:squid-users at lists.squid-cache.org>
>
>         http://lists.squid-cache.org/listinfo/squid-users
>
>      
>
>  
>

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/7635a217/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 473 bytes
Desc: OpenPGP digital signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/7635a217/attachment.sig>

From squid3 at treenet.co.nz  Thu Jul 20 00:04:43 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 20 Jul 2017 12:04:43 +1200
Subject: [squid-users] Problem with login to website by Squid web proxy
 3.5.20 on Centos 7
In-Reply-To: <168d01d300ba$07678c20$1636a460$@ngtech.co.il>
References: <bbb86484-cef7-e6cb-8e07-36f3768ec0bd@poczta.wp.pl>
 <168d01d300ba$07678c20$1636a460$@ngtech.co.il>
Message-ID: <8a273212-8565-1d34-3a15-3c2a29a19756@treenet.co.nz>

On 20/07/17 06:08, Eliezer Croitoru wrote:
> Hey iziz1,
> 
> Can you try to add squid.conf the next and see if it affects anything:
> forwarded_for delete
> via off
> 
> http://www.squid-cache.org/Doc/config/via/
> http://www.squid-cache.org/Doc/config/forwarded_for/
> 
> And see if it changes anything?
> 

Er, try those one at a time.

If the forwarded_for delete works, also try "forwarded_for transparent" 
and use just that if sufficient.

Amos


From squid3 at treenet.co.nz  Thu Jul 20 00:42:35 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 20 Jul 2017 12:42:35 +1200
Subject: [squid-users] Squid Version 3.5.20
In-Reply-To: <89638057A560FB458C01C197F81C7F5D13F32713@PACERS.amscan.corp>
References: <89638057A560FB458C01C197F81C7F5D13F32713@PACERS.amscan.corp>
Message-ID: <18ea1407-e454-3cb5-296c-1ba05c30a653@treenet.co.nz>

pPS: please respond to the list, responding to people on-list directly 
and cc'ing the list makes the thread view and web forum view all screwed up.

Below is a free audit of your config lines. I suspect  know where your 
problem is, but will followup in the tread where Yuri is posting rather 
than this detatched side-posting.


On 20/07/17 05:36, Cherukuri, Naresh wrote:>
> *From:*Cherukuri, Naresh
> *Sent:* Wednesday, July 19, 2017 9:46 AM
> 
> Hi All,
> 
> I installed Squid version 3.5.20 on RHEL 7 and generated self-signed CA 
> certificates,  My users are complaining about certificate errors. When I 
> looked at cache.log I see so many error messages like below. Below is my 
> squid.conf file. Any ideas how to address below errors.
> 
> Squid.conf:
> 
> max_filedesc 4096
> 

The directive name should be max_filedescriptors.


> visible_hostname pctysqd2prod
> 

That directive should contain a FQDN, not just a host name.

> logfile_rotate 10
> 
> access_log stdio:/var/log/squid/access.log squid
> 

Above are default values, no need to configure in Squid-3+.

> acl localnet src 172.16.0.0/16
> 
> acl backoffice_users src 10.136.0.0/13
> 
> acl hcity_backoffice_users src 10.142.0.0/15
> 
> acl register_users src 10.128.0.0/13
> 
> acl hcity_register_users src 10.134.0.0/15
> 

If your localnet / LAN ranges are only 172.16/16 what are 10/8 addresses 
doing contacting your proxy?


> acl partycity url_regex partycity
> 
> acl SSL_ports port 443
> 
> acl Safe_ports port 80          # http
> 
> #acl Safe_ports port 21         # ftp
> 
> acl Safe_ports port 443         # https
> 
> #acl Safe_ports port 70         # gopher
> 
> #acl Safe_ports port 210                # wais
> 
> #acl Safe_ports port 1025-65535 # unregistered ports
> 
> #acl Safe_ports port 280                # http-mgmt
> 
> #acl Safe_ports port 488                # gss-http
> 
> #acl Safe_ports port 591                # filemaker
> 
> #acl Safe_ports port 777                # multiling http
> 
> acl CONNECT method CONNECT
> 
> #acl allowed_sites {dst|dstdomain|dstdom_regex|url_regex) "/path/to/file"
> 
> acl backoffice_allowed_sites url_regex "/etc/squid/backoffice_allowed_sites"
> 
> acl hcity_backoffice_allowed_sites url_regex 
> "/etc/squid/backoffice_allowed_sites"
> 
> acl backoffice_blocked_sites url_regex "/etc/squid/backoffice_blocklist"
> 
> acl hcity_backoffice_blocked_sites url_regex 
> "/etc/squid/backoffice_blocklist"
> 
> acl register_allowed_sites url_regex "/etc/squid/register_allowed_sites"
> 
> acl hcity_register_allowed_sites url_regex 
> "/etc/squid/hcity_register_allowed_sites"

Hmm, the word "sites" in all these ACL names indicates that you are 
trying to match whole domains / websites - not just a few URLs within 
those sites that happen to match a regex.
  To match a domain use dstdomain, it is MUCH faster than regex.


> 
> http_access allow localnet register_allowed_sites
> 
> http_access deny backoffice_users backoffice_blocked_sites
> 
> http_access deny hcity_backoffice_users backoffice_blocked_sites
> 
> http_access allow backoffice_users backoffice_allowed_sites
> 
> http_access allow hcity_backoffice_users backoffice_allowed_sites
> 
> http_access allow register_users register_allowed_sites
> 
> http_access allow hcity_register_users hcity_register_allowed_sites
> 
> no_cache deny partycity

The directive name is "cache". Also...

Since Squid-3.5 if you actually want to prevent caching of those 
partycity URLs please use "store_miss deny partycity" instead.

If you want to *allow* the partycity URLs to cache, you need not 
configure cache / no_cache / store_miss.


> 
> http_access deny all
> 

Nothing below this lines will have any effect at all. Sadly you have 
move the most critical security controls down below here.


> #http_access allow manager localhost
> 
> #http_access deny manager
> 
> # Deny requests to certain unsafe ports
> 
> http_access deny !Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> 
> #http_access deny CONNECT !SSL_ports
> 
> http_access  allow CONNECT SSL_ports
> 
> # We strongly recommend the following be uncommented to protect innocent
> 
> # web applications running on the proxy server who think the only
> 
> # one who can access services on "localhost" is a local user
> 
> http_access deny to_localhost
> 
> # Example rule allowing access from your local networks.
> 
> # Adapt localnet in the ACL section to list your (internal) IP networks
> 
> # from where browsing should be allowed
> 
> #http_access allow localnet
> 
> http_access allow localhost

All your http_access rules should be in here around the localnet and 
localhost allow lines. Then you can also remove the above "deny all" 
line and make the one below do what it is supposed to do.

> 
> # And finally deny all other access to this proxy
> 
> http_access deny all
> 
> # Squid normally listens to port 3128
> 
> http_port 3128 ssl-bump \
> 
> key=/etc/squid/pctysquid2sslcerts/pctysquid2prod.pkey \
> 
> cert=/etc/squid/pctysquid2sslcerts/pctysquid2prod.crt \
> 
> generate-host-certificates=on dynamic_cert_mem_cache_size=4MB
> 
> acl step1 at_step SslBump1
> 
> ssl_bump peek step1
> 
> ssl_bump bump all
> 

Okay so TLS ClientHello gets peeked at, then everything gets bumped.

Fine, but be aware that any sites or client Apps using cert pinning (eg. 
chrome when contacting Google, mobile apps calling their home site, 
etc). will completely cease to work through your proxy.

Also, no ssl_bump lines below this one will do anything.


> sslproxy_cert_error allow all
> 
> always_direct allow all
> 
> sslproxy_flags DONT_VERIFY_PEER
> 

Please remove the above completely from your config. It is all based on 
temporary hacks from Squid-3.0 era or complete wrong misunderstanding 
about how TLS works.

You should expect that change to show *more* errors than you are seeing 
right now. Those are problems that do need fixing rather than just 
hiding from your logs (they still screw people over, just not logged).

You may find that you have to "sslproxy_cert_error allow" for some 
errors, but *ONLY* allow specific ones as needed - do not allow anything 
to happen silently like above does.


Cheers
Amos


From squid3 at treenet.co.nz  Thu Jul 20 00:55:09 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 20 Jul 2017 12:55:09 +1200
Subject: [squid-users] Squid Version 3.5.20 Any Ideas
In-Reply-To: <f7da4b60-02f5-71ea-e7ff-23244b0f6b62@gmail.com>
References: <89638057A560FB458C01C197F81C7F5D13F32404@PACERS.amscan.corp>
 <e653374f-020d-c213-6a0f-12dda8ebce32@gmail.com>
 <596F973C.7040603@mathemainzel.info>
 <6bb20814-f8ce-a04a-1ee4-5aeb71bf1f9c@gmail.com>
 <89638057A560FB458C01C197F81C7F5D13F32BF9@PACERS.amscan.corp>
 <dce8f67e-a340-ffa0-0e42-1968e5b05fca@gmail.com>
 <89638057A560FB458C01C197F81C7F5D13F32CA3@PACERS.amscan.corp>
 <f7da4b60-02f5-71ea-e7ff-23244b0f6b62@gmail.com>
Message-ID: <95daaf62-11e1-283f-8c24-81f53323626f@treenet.co.nz>

On 20/07/17 09:10, Yuri wrote:
> Aha,
> 
> 
> 20.07.2017 3:04, Cherukuri, Naresh ?????:
>>
>> Yuri,
>>
>> I am sorry I didn?t get you I already installed certificate on all 
>> clients(trusted root certificate authorities). You want me install 
>> proxy public key also on clients, if so were should I put the proxy 
>> public key. Below is my squid.conf file.
>>
>> Squid.conf
>>
>> key=/etc/squid/pctysquid2sslcerts/pctysquid2prod.pkey \ proxy ca 
>> public key??
>>
> This is proxy private key AFAIK.

Correct. It should be the proxy private key. If the public key is put in 
there and startup actually succeeds I'm not sure what broken runtime 
errors will occur - nothing good anyhow.

Also, note that cert= parameter should be configured *before* the key= 
parameter so Squid loads them from the right place. The very latest 
releases (v4+) will fail to start if the ordering is wrong, so best to 
prepare for that now.


I suspect that part of the problem here is what is being configured in 
that cert= parameter. For SSL-Bump ports in current Squid it needs to 
contains the self-signed *CA* certificate that Squid is using to 
generate other certs from, the key= being the private key of that CA cert.

If you generate a regular proxy cert and load it there (like normal 
proxy cert= would use) the bumping process will get all broken.


The ConfigExample page Yuri linked to earlier had the exact and full 
process to follow for setting up the multiple different certs, keys and 
file types involved with SSL-Bump.


>>
>> cert=/etc/squid/pctysquid2sslcerts/pctysquid2prod.crt \(installed 
>> certificate on IE all clients as a trusted root certificate authorities)
>>
> Yes, if it installed into clients - this is ok.
> 
> So. The only reason I can see - proxy can't see OpenSSL CA's bundle.
> 
> To make it work you should add to your squid's config one of this:
> 
> #  TAG: sslproxy_cafile
> #    file containing CA certificates to use when verifying server
> #    certificates while proxying https:// URLs
> #Default:
> # none
> 
> #  TAG: sslproxy_capath
> #    directory containing CA certificates to use when verifying
> #    server certificates while proxying https:// URLs
> #Default:
> # none

Er, those are for Squid->server connections. You were correct about the 
errors referring to client->Squid connections, so these are irrelevant.

If anything, the  cafile= parameter of the ssl-bump port might be 
needed. Then it should point at the same CA's found in the cert= 
parameter (bit weird, but that is bugs in the SSL-Bump config design).

FTR: those particular errors occur when Squid accepts a connection from 
a client, begins the TLS handshake and the client suddenly disconnects 
before the handshake is complete.
  The "certificate unknown" seems to be saying that either 1) the client 
sent a client-cert to Squid and OpenSSL did not accept it, or 2) that 
the client did not accept the auto-generated cert Squid sent.

If (1) is happening it s because the browser was not correctly 
configured with the self-signed CA public cert.

If (2) is happening, then probably the cert=, key=, cafile= parameters 
on the ssl-bump port are not configured right, OR browser was not 
correctly configured with the self-signed CA public cert.

Or, maybe bugs in that particular Squid release SSL-Bump code. We are 
constantly fixing them and 3.5.20 is now a whole year behind with 
SSL-Bump fixes - many of them rather major behaviour fixes.


==> Best Practice to follow with SSL-Bump is that when having *any* 
problems with the SSL-Bump process try the latest Squid release first 
before spending time trying to figure it out.

Amos


From squid3 at treenet.co.nz  Thu Jul 20 01:40:26 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 20 Jul 2017 13:40:26 +1200
Subject: [squid-users] debugging ssl-bump
In-Reply-To: <1f31b469-8029-83a6-9d97-387f00974554@urlfilterdb.com>
References: <1f31b469-8029-83a6-9d97-387f00974554@urlfilterdb.com>
Message-ID: <cfda3eac-18bb-df88-5510-b0ac434c9240@treenet.co.nz>


On 19/07/17 05:02, Marcus Kool wrote:
> 
> I am trying to debug ssl-bump and am looking specifically for decisions 
> that Squid takes with regard to bumping, splicing and unsupported protocol.
> 
> The config file for Squid 4.0.21 has
> 
> debug_options ALL,1 33,9 83,9
> 

Section 28 is probably where you want to look for the splice detail 
since it is an access control action decision point.

There are a few TLS details going to 81, but mostly for server connections.

You may also want to include the TCP level I/O details in section 5 if 
the section 83 OpenSSL BIO is not enough.

And the 11,2 trace of when HTTP(S) messages are arriving can be useful 
to trace when and what Squid is managing to decrypt.

And section 26 for CONNECT tunnel handling. Which may show when/how 
splice or on_unsupported_protocol are being handled.

Amos



> http_port 10.10.10.1:3230        ssl-bump ...
> 
> acl tls_is_skype ssl::server_name 
> "/var/ufdbguard/blacklists/chat/skype/iplist"
> acl tls_is_skype ssl::server_name .skype.com
> acl tls_allowed_hsts ssl::server_name www.google.com
> acl tls_urlfilterdb ssl::server_name www.urlfilterdb.com
> acl tls_server_is_bank ssl::server_name .abnamro.nl
> acl tls_server_is_bank ssl::server_name .abnamro.com
> acl tls_to_splice any-of tls_allowed_hsts tls_urlfilterdb 
> tls_server_is_bank tls_is_skype
> 
> ssl_bump splice tls_to_splice
> ssl_bump stare  all
> ssl_bump bump   all
> 
> on_unsupported_protocol tunnel all
> 
> But I fail to see in cache.log anything that gives a clue about
> - squid decided to splice
> - squid decided to bump
> - squid decided to treat a connection as "unsupported protocol".
> 
> Are there other debug sections than 33 and 83 that need an increased 
> debug level ?
> what strings do I have to look for in cache.log to understand the above 
> decisions that Squid takes ?

The regular ACL checklist and results I think for that particular 
tracing. The TLS parser and bumping logic is not all debug traced due to 
performance-first reasons. Where debugs exist it is usually at a 
problem/error handling code path initiation.

Amos


From Walter.H at mathemainzel.info  Thu Jul 20 03:35:28 2017
From: Walter.H at mathemainzel.info (Walter H.)
Date: Thu, 20 Jul 2017 05:35:28 +0200
Subject: [squid-users] This list generates a forward loop ...
In-Reply-To: <0b5c9cec-68ee-e238-fb1a-4885b7408361@treenet.co.nz>
References: <31cb999478ff31663df9dbfe85f107a5.1500385341@squirrel.mail>
 <0b5c9cec-68ee-e238-fb1a-4885b7408361@treenet.co.nz>
Message-ID: <59702500.2000303@mathemainzel.info>

On 19.07.2017 08:54, Amos Jeffries wrote:
> On 19/07/17 01:42, Walter H. wrote:
>>
>> <squid-users at squid-cache.org> (expanded from
>> <squid-users at lists.squid-cache.org>): mail forwarding loop for
>>      squid-users at squid-cache.org
>> <END>
>>
>> Why?
>
>
> You sent a mail to the address squid-users at squid-cache.*
>
> The mailing list address is squid-users at lists.*
>
No, see the log of my outgoing Mail server ...

<BEGIN /var/log/maillog>
Jul 18 14:29:05 smtpout postfix/smtp[7177]: 537DB66: 
to=<squid-users at lists.squid-cache.org>, 
relay=smtp.world4you.com[81.19.149.200]:587, delay=0.68, 
delays=0.02/0.1/0.21/0.36, dsn=2.0.0, status=sent (250 OK 
id=1dXRce-0008Hp-LA)
Jul 18 15:37:04 smtpout postfix/smtp[8973]: 85ED0FA: 
to=<squid-users at lists.squid-cache.org>, 
relay=smtp.world4you.com[81.19.149.200]:587, delay=0.5, 
delays=0.01/0.03/0.33/0.13, dsn=2.0.0, status=sent (250 OK 
id=1dXSgR-0007G1-UM)
Jul 18 15:42:22 smtpout postfix/smtp[9121]: AB859FA: 
to=<squid-users at lists.squid-cache.org>, 
relay=smtp.world4you.com[81.19.149.200]:587, delay=0.47, 
delays=0.01/0.04/0.33/0.09, dsn=2.0.0, status=sent (250 OK 
id=1dXSla-00008Z-2r)
Jul 19 11:16:30 smtpout postfix/smtp[8824]: 51E02FA: 
to=<squid-users at lists.squid-cache.org>, 
relay=smtp.world4you.com[81.19.149.200]:587, delay=0.54, 
delays=0.02/0.07/0.23/0.22, dsn=2.0.0, status=sent (250 OK 
id=1dXl5q-0002Io-Nu)
Jul 19 11:40:36 smtpout postfix/smtp[9466]: 534C9FA: 
to=<squid-users at lists.squid-cache.org>, 
relay=smtp.world4you.com[81.19.149.200]:587, delay=0.35, 
delays=0.02/0.03/0.2/0.1, dsn=2.0.0, status=sent (250 OK 
id=1dXlTA-0006eh-JU)
Jul 19 19:30:41 smtpout postfix/smtp[21871]: 96E3FFA: 
to=<squid-users at lists.squid-cache.org>, 
relay=smtp.world4you.com[81.19.149.200]:587, delay=0.51, 
delays=0.02/0.07/0.27/0.15, dsn=2.0.0, status=sent (250 OK 
id=1dXso4-00027Q-Ux)
Jul 19 20:37:54 smtpout postfix/smtp[23635]: DF09966: 
to=<squid-users at lists.squid-cache.org>, 
relay=smtp.world4you.com[81.19.149.200]:587, delay=0.45, 
delays=0.03/0.07/0.23/0.12, dsn=2.0.0, status=sent (250 OK 
id=1dXtr8-0007MA-7f)
<END /var/log/maillog>

the log entry of this mail is of course not included ...

I got back 5 error mails last night ...

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3491 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/53315fbc/attachment.bin>

From Walter.H at mathemainzel.info  Thu Jul 20 03:53:14 2017
From: Walter.H at mathemainzel.info (Walter H.)
Date: Thu, 20 Jul 2017 05:53:14 +0200
Subject: [squid-users] This list generates a forward loop ...
In-Reply-To: <59702500.2000303@mathemainzel.info>
References: <31cb999478ff31663df9dbfe85f107a5.1500385341@squirrel.mail>
 <0b5c9cec-68ee-e238-fb1a-4885b7408361@treenet.co.nz>
 <59702500.2000303@mathemainzel.info>
Message-ID: <5970292A.9060405@mathemainzel.info>

On 20.07.2017 05:35, Walter H. wrote:
> On 19.07.2017 08:54, Amos Jeffries wrote:
>> On 19/07/17 01:42, Walter H. wrote:
>>>
>>> <squid-users at squid-cache.org> (expanded from
>>> <squid-users at lists.squid-cache.org>): mail forwarding loop for
>>>      squid-users at squid-cache.org
>>> <END>
>>>
>>> Why?
>>
>>
>> You sent a mail to the address squid-users at squid-cache.*
>>
>> The mailing list address is squid-users at lists.*
>>
> No, see the log of my outgoing Mail server ...
>
> <BEGIN /var/log/maillog>
> Jul 18 14:29:05 smtpout postfix/smtp[7177]: 537DB66: 
> to=<squid-users at lists.squid-cache.org>, 
> relay=smtp.world4you.com[81.19.149.200]:587, delay=0.68, 
> delays=0.02/0.1/0.21/0.36, dsn=2.0.0, status=sent (250 OK 
> id=1dXRce-0008Hp-LA)
> Jul 18 15:37:04 smtpout postfix/smtp[8973]: 85ED0FA: 
> to=<squid-users at lists.squid-cache.org>, 
> relay=smtp.world4you.com[81.19.149.200]:587, delay=0.5, 
> delays=0.01/0.03/0.33/0.13, dsn=2.0.0, status=sent (250 OK 
> id=1dXSgR-0007G1-UM)
> Jul 18 15:42:22 smtpout postfix/smtp[9121]: AB859FA: 
> to=<squid-users at lists.squid-cache.org>, 
> relay=smtp.world4you.com[81.19.149.200]:587, delay=0.47, 
> delays=0.01/0.04/0.33/0.09, dsn=2.0.0, status=sent (250 OK 
> id=1dXSla-00008Z-2r)
> Jul 19 11:16:30 smtpout postfix/smtp[8824]: 51E02FA: 
> to=<squid-users at lists.squid-cache.org>, 
> relay=smtp.world4you.com[81.19.149.200]:587, delay=0.54, 
> delays=0.02/0.07/0.23/0.22, dsn=2.0.0, status=sent (250 OK 
> id=1dXl5q-0002Io-Nu)
> Jul 19 11:40:36 smtpout postfix/smtp[9466]: 534C9FA: 
> to=<squid-users at lists.squid-cache.org>, 
> relay=smtp.world4you.com[81.19.149.200]:587, delay=0.35, 
> delays=0.02/0.03/0.2/0.1, dsn=2.0.0, status=sent (250 OK 
> id=1dXlTA-0006eh-JU)
> Jul 19 19:30:41 smtpout postfix/smtp[21871]: 96E3FFA: 
> to=<squid-users at lists.squid-cache.org>, 
> relay=smtp.world4you.com[81.19.149.200]:587, delay=0.51, 
> delays=0.02/0.07/0.27/0.15, dsn=2.0.0, status=sent (250 OK 
> id=1dXso4-00027Q-Ux)
> Jul 19 20:37:54 smtpout postfix/smtp[23635]: DF09966: 
> to=<squid-users at lists.squid-cache.org>, 
> relay=smtp.world4you.com[81.19.149.200]:587, delay=0.45, 
> delays=0.03/0.07/0.23/0.12, dsn=2.0.0, status=sent (250 OK 
> id=1dXtr8-0007MA-7f)
> <END /var/log/maillog>
>
> the log entry of this mail is of course not included ...
>
> I got back 5 error mails last night ...
here is the complete error mail, that was replied to this last mail ...

<BEGIN>Return-Path: <>
Received: from storage.mail ([unix socket])
      by storage.mail (Cyrus v2.3.16-Fedora-RPM-2.3.16-15.el6) with LMTPA;
      Thu, 20 Jul 2017 05:47:11 +0200
X-Sieve: CMU Sieve 2.3
Received: from filter.mail by storage.mail (Postfix) with ESMTP id 
E379F60034
Received: by filter.mail (Postfix) id D82723CA4
Delivered-To: walter at filter.mail
Received: from filter.mail [local] by filter.mail (Postfix) with ESMTP 
id B23E3451
Received: by filter.mail (Postfix, userid 500) id 9BF3A3CA8
X-Spam-Checker-Version: SpamAssassin 3.3.1 (2010-03-16) on filter.mail
X-Spam-Status: No, score=0.0 required=4.0 tests=none autolearn=ham
     version=3.3.1
Received: from filter.mail by filter.mail (Postfix) with ESMTP id DA0AF451
Envelope-to: Walter.H at mathemainzel.info
Delivery-date: Thu, 20 Jul 2017 05:44:37 +0200
Received: from [w4y-pop-server] by filter.mail with POP3 (fetchmail-6.3.17)
Received: from [81.19.149.115] (helo=mx05lb.world4you.com)
     by mail12.world4you.com with esmtps 
(TLSv1.2:ECDHE-RSA-AES256-GCM-SHA384:256)
     (Exim 4.89)
     id 1dY2OD-0003V6-LA
     for Walter.H at mathemainzel.info; Thu, 20 Jul 2017 05:44:37 +0200
Received: from [104.130.201.120] (helo=lists.squid-cache.org)
     by mx05lb.world4you.com with esmtp (Exim 4.84_2)
     id 1dY2OB-0004mf-Ud
     for Walter.H at mathemainzel.info; Thu, 20 Jul 2017 05:44:37 +0200
Received: by lists.squid-cache.org (Postfix)
     id C409FE23A1; Thu, 20 Jul 2017 03:44:49 +0000 (UTC)
Date: Thu, 20 Jul 2017 03:44:49 +0000 (UTC)
From: MAILER-DAEMON at squid-cache.org (Mail Delivery System)
To: Walter.H at mathemainzel.info
Auto-Submitted: auto-replied
MIME-Version: 1.0
Content-Type: multipart/report; report-type=delivery-status;
     boundary="15AD7E1196.1500522289/lists.squid-cache.org"
Message-Id: <20170720034449.C409FE23A1 at lists.squid-cache.org>
X-SA-Exim-Connect-IP: 104.130.201.120
X-SA-Exim-Mail-From:
Subject: Undelivered Mail Returned to Sender
X-SA-Exim-Version: 4.2.1 (built Thu, 31 Mar 2016 16:22:20 +0200)
X-SA-Exim-Scanned: Yes (on mx05lb.world4you.com)
X-AV-Scanned: ClamAV using ClamSMTP (filter.mail)

This is a MIME-encapsulated message.

--15AD7E1196.1500522289/lists.squid-cache.org
Content-Description: Notification
Content-Type: text/plain; charset=us-ascii

This is the mail system at host lists.squid-cache.org.

I'm sorry to have to inform you that your message could not
be delivered to one or more recipients. It's attached below.

For further assistance, please send mail to postmaster.

If you do so, please include this problem report. You can
delete your own text from the attached returned message.

                    The mail system

<squid-users at squid-cache.org> (expanded from
<squid-users at lists.squid-cache.org>): mail forwarding loop for
     squid-users at squid-cache.org

--15AD7E1196.1500522289/lists.squid-cache.org
Content-Description: Delivery report
Content-Type: message/delivery-status

Reporting-MTA: dns; lists.squid-cache.org
X-Postfix-Queue-ID: 15AD7E1196
X-Postfix-Sender: rfc822; Walter.H at mathemainzel.info
Arrival-Date: Thu, 20 Jul 2017 03:44:49 +0000 (UTC)

Final-Recipient: rfc822; squid-users at squid-cache.org
Original-Recipient: rfc822;squid-users at lists.squid-cache.org
Action: failed
Status: 5.4.6
Diagnostic-Code: X-Postfix; mail forwarding loop for
     squid-users at squid-cache.org

--15AD7E1196.1500522289/lists.squid-cache.org
Content-Description: Undelivered Message
Content-Type: message/rfc822

Return-Path: <Walter.H at mathemainzel.info>
Received: from ScrolloutF1.linguitronics.com 
(203-74-122-103.HINET-IP.hinet.net [203.74.122.103])
     by lists.squid-cache.org (Postfix) with ESMTPS id 15AD7E1196
     for <squid-users at lists.squid-cache.org>; Thu, 20 Jul 2017 03:44:49 
+0000 (UTC)
Authentication-Results: lists.squid-cache.org; dkim=fail
     reason="verification failed; unprotected key"
     header.d=mathemainzel.info header.i=@mathemainzel.info
     header.b=Z+/SVz0j; dkim-adsp=discard (unprotected policy);
     dkim-atps=neutral
Received: by ScrolloutF1.linguitronics.com (Postfix, from userid 0)
     id 3xCfsX5v6DzHpF4; Thu, 20 Jul 2017 11:44:32 +0800 (CST)
Delivered-To: unknown
Received: from 192.168.1.204 (192.168.1.204:143) by
   mailgateway.linguitronics.com with IMAP4; 20 Jul 2017 03:44:32 -0000
X-Original-To: spam at linguitronics.com
Delivered-To: spam at linguitronics.com
Received: from ScrolloutF1.linguitronics.com (unknown [192.168.1.205])
     by tw.linguitronics.com (Postfix) with ESMTP id 5A3E64023A
     for <spam at linguitronics.com>; Thu, 20 Jul 2017 11:35:56 +0800 (CST)
Authentication-Results: tw.linguitronics.com;
     dkim=fail reason="signature verification failed" (1024-bit key) 
header.d=mathemainzel.info header.i=@mathemainzel.info header.b="Z+/SVz0j"
Received: from localhost (localhost [127.0.0.1])
     by ScrolloutF1.linguitronics.com (Postfix) with ESMTP id 
3xCfgc5PKRzHr9d
     for <spam at linguitronics.com>; Thu, 20 Jul 2017 11:35:56 +0800 (CST)
X-Envelope-To: <akong at linguitronics.com>
X-Envelope-To-Blocked: <akong at linguitronics.com>
X-Quarantine-ID: <uAebWOExfOQd>
X-Spam-Score: 98.401
X-Spam-Status: No, score=-100.0 required=5.0 tests=SPF_PASS,T_DKIM_INVALID,
     UNPARSEABLE_RELAY,USER_IN_ALL_SPAM_TO autolearn=unavailable
     autolearn_force=no version=3.4.0
Authentication-Results: scrolloutf1.linguitronics.com (amavisd-new);
     dkim=fail (1024-bit key) reason="fail (message has been altered)"
     header.d=mathemainzel.info
Received: from ScrolloutF1.linguitronics.com ([127.0.0.1])
     by localhost (scrolloutf1.linguitronics.com [127.0.0.1]) 
(amavisd-new, port 10024)
     with LMTP id uAebWOExfOQd for <akong at linguitronics.com>;
     Thu, 20 Jul 2017 11:35:55 +0800 (CST)
Received-SPF: Pass (sender SPF authorized) identity=mailfrom; 
client-ip=104.130.201.120; helo=lists.squid-cache.org; 
envelope-from=squid-users-bounces at lists.squid-cache.org; 
receiver=akong at linguitronics.com
Received: from lists.squid-cache.org (lists.squid-cache.org 
[104.130.201.120])
     by ScrolloutF1.linguitronics.com (Postfix) with ESMTP id 
3xCfgP4p5LzHr9b
     for <akong at linguitronics.com>; Thu, 20 Jul 2017 11:35:39 +0800 (CST)
Received: from master.squid-cache.org (ip6-localhost [127.0.0.1])
     by lists.squid-cache.org (Postfix) with ESMTP id BA427E239B;
     Thu, 20 Jul 2017 03:35:47 +0000 (UTC)
X-Original-To: squid-users at lists.squid-cache.org
Delivered-To: squid-users at squid-cache.org
Received: from mx02lb.world4you.com (mx02lb.world4you.com [81.19.149.112])
  by lists.squid-cache.org (Postfix) with ESMTPS id 2705DE1193
  for <squid-users at lists.squid-cache.org>; Thu, 20 Jul 2017 03:35:45 
+0000 (UTC)
DKIM-Signature: v=1; a=rsa-sha256; q=dns/txt; c=relaxed/relaxed;
  d=mathemainzel.info; s=dkim11;
  h=Content-Type:In-Reply-To:References:Subject:To:MIME-Version:From:Date:Message-ID;
  bh=I9buaZEqIEKxwYTujfGAfgA9MLZUQZwd6uzO8hXcwVY=;
  b=Z+/SVz0jPiFGlzrXhnjW/qoyw+ekMYxPz1xbxz2Tz13sMoNRKH3xNUudSVT4ImRnnkveGEPvZ0tMiwJNAZNOfH2wFFAZaK0wbx6B9Ubu7QYrLJm6Y/lwgk24wkiz6PpB5VgRVxL5/GH5QVck0o6tf3VygCpRJFvmtw11fbbphpQ=;
Received: from [90.146.55.206] (helo=home.mail)
  by mx02lb.world4you.com with esmtpsa 
(TLSv1.2:DHE-RSA-AES256-GCM-SHA384:256)
  (Exim 4.84_2) (envelope-from <Walter.H at mathemainzel.info>)
  id 1dY2FN-0002r0-5R
  for squid-users at lists.squid-cache.org; Thu, 20 Jul 2017 05:35:29 +0200
Message-ID: <59702500.2000303 at mathemainzel.info>
Date: Thu, 20 Jul 2017 05:35:28 +0200
From: "Walter H." <Walter.H at mathemainzel.info>
Organization: Home
User-Agent: Mozilla/5.0 (UNIX; U; Cray X-MP/48; en-US;
  rv:2.70) Gecko/20110929 Communicator/7.20
MIME-Version: 1.0
To: squid-users at lists.squid-cache.org
References: <31cb999478ff31663df9dbfe85f107a5.1500385341 at squirrel.mail>
<0b5c9cec-68ee-e238-fb1a-4885b7408361 at treenet.co.nz>
In-Reply-To: <0b5c9cec-68ee-e238-fb1a-4885b7408361 at treenet.co.nz>
X-SA-Do-Not-Run: Yes
X-AV-Do-Run: Yes
X-SA-Exim-Connect-IP: 90.146.55.206
X-SA-Exim-Mail-From: Walter.H at mathemainzel.info
X-SA-Exim-Scanned: No (on mx02lb.world4you.com);
  SAEximRunCond expanded to false
X-Spam-Status: No, score=-100.0 required=5.0 tests=T_DKIM_INVALID,
  UNPARSEABLE_RELAY,USER_IN_ALL_SPAM_TO autolearn=unavailable
  autolearn_force=no version=3.4.0
X-Spam-Checker-Version: SpamAssassin 3.4.0 (2014-02-07) on
     master.squid-cache.org
Subject: Re: [squid-users] This list generates a forward loop ...
X-BeenThere: squid-users at lists.squid-cache.org
X-Mailman-Version: 2.1.16
Precedence: list
List-Id: "General discussion relating to Squid. The membership of this 
list is
  thousands of Squid users from around the world"
<squid-users.lists.squid-cache.org>
List-Unsubscribe: <http://lists.squid-cache.org/options/squid-users>,
<mailto:squid-users-request at lists.squid-cache.org?subject=unsubscribe>
List-Archive: <http://lists.squid-cache.org/pipermail/squid-users/>
List-Post: <mailto:squid-users at lists.squid-cache.org>
List-Help: <mailto:squid-users-request at lists.squid-cache.org?subject=help>
List-Subscribe: <http://lists.squid-cache.org/listinfo/squid-users>,
<mailto:squid-users-request at lists.squid-cache.org?subject=subscribe>
Content-Type: multipart/mixed; 
boundary="===============7862228297507396546=="
Errors-To: squid-users-bounces at lists.squid-cache.org
Sender: "squid-users" <squid-users-bounces at lists.squid-cache.org>
X-getmail-retrieved-from-mailbox: GOOD
X-Virus-Scanned: clamav-milter 0.99.2 at master.squid-cache.org
X-Virus-Status: Clean

This is a cryptographically signed message in MIME format.

--===============7862228297507396546==
Content-Type: multipart/signed; protocol="application/pkcs7-signature"; 
micalg=sha1; boundary="------------ms000506090802020601030308"

This is a cryptographically signed message in MIME format.

--------------ms000506090802020601030308
Content-Type: text/plain; charset=UTF-8; format=flowed
Content-Transfer-Encoding: quoted-printable

On 19.07.2017 08:54, Amos Jeffries wrote:
 > On 19/07/17 01:42, Walter H. wrote:
 >>
 >> <squid-users at squid-cache.org> (expanded from
 >> <squid-users at lists.squid-cache.org>): mail forwarding loop for
 >>      squid-users at squid-cache.org
 >> <END>
 >>
 >> Why?
 >
 >
 > You sent a mail to the address squid-users at squid-cache.*
 >
 > The mailing list address is squid-users at lists.*
 >
No, see the log of my outgoing Mail server ...


<BEGIN /var/log/maillog>
Jul 18 14:29:05 smtpout postfix/smtp[7177]: 537DB66:=20
to=3D<squid-users at lists.squid-cache.org>,=20
relay=3Dsmtp.world4you.com[81.19.149.200]:587, delay=3D0.68,=20
delays=3D0.02/0.1/0.21/0.36, dsn=3D2.0.0, status=3Dsent (250 OK=20
id=3D1dXRce-0008Hp-LA)
Jul 18 15:37:04 smtpout postfix/smtp[8973]: 85ED0FA:=20
to=3D<squid-users at lists.squid-cache.org>,=20
relay=3Dsmtp.world4you.com[81.19.149.200]:587, delay=3D0.5,=20
delays=3D0.01/0.03/0.33/0.13, dsn=3D2.0.0, status=3Dsent (250 OK=20
id=3D1dXSgR-0007G1-UM)
Jul 18 15:42:22 smtpout postfix/smtp[9121]: AB859FA:=20
to=3D<squid-users at lists.squid-cache.org>,=20
relay=3Dsmtp.world4you.com[81.19.149.200]:587, delay=3D0.47,=20
delays=3D0.01/0.04/0.33/0.09, dsn=3D2.0.0, status=3Dsent (250 OK=20
id=3D1dXSla-00008Z-2r)
Jul 19 11:16:30 smtpout postfix/smtp[8824]: 51E02FA:=20
to=3D<squid-users at lists.squid-cache.org>,=20
relay=3Dsmtp.world4you.com[81.19.149.200]:587, delay=3D0.54,=20
delays=3D0.02/0.07/0.23/0.22, dsn=3D2.0.0, status=3Dsent (250 OK=20
id=3D1dXl5q-0002Io-Nu)
Jul 19 11:40:36 smtpout postfix/smtp[9466]: 534C9FA:=20
to=3D<squid-users at lists.squid-cache.org>,=20
relay=3Dsmtp.world4you.com[81.19.149.200]:587, delay=3D0.35,=20
delays=3D0.02/0.03/0.2/0.1, dsn=3D2.0.0, status=3Dsent (250 OK=20
id=3D1dXlTA-0006eh-JU)
Jul 19 19:30:41 smtpout postfix/smtp[21871]: 96E3FFA:=20
to=3D<squid-users at lists.squid-cache.org>,=20
relay=3Dsmtp.world4you.com[81.19.149.200]:587, delay=3D0.51,=20
delays=3D0.02/0.07/0.27/0.15, dsn=3D2.0.0, status=3Dsent (250 OK=20
id=3D1dXso4-00027Q-Ux)
Jul 19 20:37:54 smtpout postfix/smtp[23635]: DF09966:=20
to=3D<squid-users at lists.squid-cache.org>,=20
relay=3Dsmtp.world4you.com[81.19.149.200]:587, delay=3D0.45,=20
delays=3D0.03/0.07/0.23/0.12, dsn=3D2.0.0, status=3Dsent (250 OK=20
id=3D1dXtr8-0007MA-7f)
<END /var/log/maillog>

the log entry of this mail is of course not included ...

I got back 5 error mails last night ...


--------------ms000506090802020601030308
Content-Type: application/pkcs7-signature; name="smime.p7s"
Content-Transfer-Encoding: base64
Content-Disposition: attachment; filename="smime.p7s"
Content-Description: S/MIME Cryptographic Signature
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--------------ms000506090802020601030308--

--===============7862228297507396546==
Content-Type: text/plain; charset="utf-8"
MIME-Version: 1.0
Content-Transfer-Encoding: base64
Content-Disposition: inline

X19fX19fX19fX19fX19fX19fX19fX19fX19fX19fX19fX19fX19fX19fX19fX18Kc3F1aWQtdXNl
cnMgbWFpbGluZyBsaXN0CnNxdWlkLXVzZXJzQGxpc3RzLnNxdWlkLWNhY2hlLm9yZwpodHRwOi8v
bGlzdHMuc3F1aWQtY2FjaGUub3JnL2xpc3RpbmZvL3NxdWlkLXVzZXJzCg==

--===============7862228297507396546==--

--15AD7E1196.1500522289/lists.squid-cache.org--
<END>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: smime.p7s
Type: application/pkcs7-signature
Size: 3491 bytes
Desc: S/MIME Cryptographic Signature
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/255930d8/attachment.bin>

From squid3 at treenet.co.nz  Thu Jul 20 05:16:57 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 20 Jul 2017 17:16:57 +1200
Subject: [squid-users] This list generates a forward loop ...
In-Reply-To: <5970292A.9060405@mathemainzel.info>
References: <31cb999478ff31663df9dbfe85f107a5.1500385341@squirrel.mail>
 <0b5c9cec-68ee-e238-fb1a-4885b7408361@treenet.co.nz>
 <59702500.2000303@mathemainzel.info> <5970292A.9060405@mathemainzel.info>
Message-ID: <31ce9094-5f98-ca75-c06e-dd43faf5b685@treenet.co.nz>


Your DKIM signature covers the Subject and To headers. Any normal 
mailing list will modify those, so your server cannot do that on list 
postings. Content-Type is also changed sometimes by our listserver due 
to the list policy on binary attachments, I dont know whether that is a 
common practice too but I suspect it might be. The others should be fine 
AFAIK.


 > DKIM-Signature: v=1; a=rsa-sha256; q=dns/txt; c=relaxed/relaxed;
 >   d=mathemainzel.info; s=dkim11;
 > 
h=Content-Type:In-Reply-To:References:Subject:To:MIME-Version:From:Date:Message-ID;
 >   bh=I9buaZEqIEKxwYTujfGAfgA9MLZUQZwd6uzO8hXcwVY=;
 > 
b=Z+/SVz0jPiFGlzrXhnjW/qoyw+ekMYxPz1xbxz2Tz13sMoNRKH3xNUudSVT4ImRnnkveGEPvZ0tMiwJNAZNOfH2wFFAZaK0wbx6B9Ubu7QYrLJm6Y/lwgk24wkiz6PpB5VgRVxL5/GH5QVck0o6tf3VygCpRJFvmtw11fbbphpQ=;



On a side note:
  What I see in these headers is a fight going on between your 
mailserver sending crypto assertions and another list members server 
actually verifying them - which of course fail because Subject/To get 
changed by the list server, and the PGP signature is currently being 
stripped.

The other members mailserver does something unusually nasty - it simply 
loops the message back at the list instead of bouncing with a proper 
error to you. And since your address is still the envelope sender our 
server rejects with that loop error bouncing back at you.

[yes I wish our sysadmin could stop that bouncing, but the tools seem to 
be limited].

Amos


From iziz1 at poczta.wp.pl  Thu Jul 20 07:20:26 2017
From: iziz1 at poczta.wp.pl (=?UTF-8?Q?Kurczewski=2c_Bart=c5=82omiej_=28WP.PL=29?=)
Date: Thu, 20 Jul 2017 09:20:26 +0200
Subject: [squid-users] Problem with login to website by Squid web proxy
 3.5.20 on Centos 7
In-Reply-To: <168d01d300ba$07678c20$1636a460$@ngtech.co.il>
References: <bbb86484-cef7-e6cb-8e07-36f3768ec0bd@poczta.wp.pl>
 <168d01d300ba$07678c20$1636a460$@ngtech.co.il>
Message-ID: <3252e911-e8f0-b842-5948-0567560b1f7e@poczta.wp.pl>

Hi Eliezer,
First of all I would like to thank you for fast answer.
And my second "thanks" is for your help.
Your solution works, and the problem has been solved.

Regards,
iziz1

W dniu 2017-07-19 o 20:08, Eliezer Croitoru pisze:
> Hey iziz1,
> 
> Can you try to add squid.conf the next and see if it affects anything:
> forwarded_for delete
> via off
> 
> http://www.squid-cache.org/Doc/config/via/
> http://www.squid-cache.org/Doc/config/forwarded_for/
> 
> And see if it changes anything?
> 
> Let Me Know if something changes,
> Eliezer
> 
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
> 
> 
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Kurczewski, Bart?omiej (WP.PL)
> Sent: Tuesday, July 18, 2017 15:56
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Problem with login to website by Squid web proxy 3.5.20 on Centos 7
> 
> Hi,
> I have a problem to login to one website (http://intouch.techdata.com)
> using Squid 3.5.20 on Centos 7 with default Squid configuration, which
> is acting as web proxy (non-transparent) on 3128 port in my network:
> 
> --------------------------------------------------------------------------
> #
> # Recommended minimum configuration:
> #
> 
> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
> acl localnet src 172.16.0.0/12	# RFC1918 possible internal network
> acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
> machines
> 
> acl SSL_ports port 443
> acl Safe_ports port 80		# http
> acl Safe_ports port 21		# ftp
> acl Safe_ports port 443		# https
> acl Safe_ports port 70		# gopher
> acl Safe_ports port 210		# wais
> acl Safe_ports port 1025-65535	# unregistered ports
> acl Safe_ports port 280		# http-mgmt
> acl Safe_ports port 488		# gss-http
> acl Safe_ports port 591		# filemaker
> acl Safe_ports port 777		# multiling http
> acl CONNECT method CONNECT
> 
> #
> # Recommended minimum Access Permission configuration:
> #
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
> 
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
> 
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> #http_access deny to_localhost
> 
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> 
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
> 
> # And finally deny all other access to this proxy
> http_access deny all
> 
> # Squid normally listens to port 3128
> http_port 3128
> 
> # Uncomment and adjust the following to add a disk cache directory.
> #cache_dir ufs /var/spool/squid 100 16 256
> 
> # Leave coredumps in the first cache dir
> coredump_dir /var/spool/squid
> 
> #
> # Add any of your own refresh_pattern entries above these.
> #
> refresh_pattern ^ftp:		1440	20%	10080
> refresh_pattern ^gopher:	1440	0%	1440
> refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
> refresh_pattern .		0	20%	4320
> ------------------------------------------------------------------------------
> 
> 
> In a FF browser with my Squid server settings I put correct password on
> techdata website, but webpage redirect me to the same web form and
> doesn't allow to login. The password is correct, because when I put
> wrong password I got JavaScript alert from this website that password is
> incorrect.
> 
> When I disable using Squid proxy in FF and use normal PAT connection via
> my Juniper firewall everything works perfect on the same machine and I
> can login to TechData website.
> I Squid access.log I can see only this:
> 
> -----------------------------------------------------------------
> 1500364995.497    140 10.48.22.33 TCP_MISS/302 735 GET
> http://intouch.techdata.com/intouch/Home.aspx? -
> HIER_DIRECT/192.230.78.204 text/html
> -----------------------------------------------------------------
> 
> I suspect some problems with redirection on TechData website, but spend
> hours in Internet to find solution, unfortunately without success....
> Maybe you can help me?
> 
> Regards,
> iziz1
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> 


From iziz1 at poczta.wp.pl  Thu Jul 20 07:24:18 2017
From: iziz1 at poczta.wp.pl (=?UTF-8?Q?Kurczewski=2c_Bart=c5=82omiej_=28WP.PL=29?=)
Date: Thu, 20 Jul 2017 09:24:18 +0200
Subject: [squid-users] Problem with login to website by Squid web proxy
 3.5.20 on Centos 7
In-Reply-To: <8a273212-8565-1d34-3a15-3c2a29a19756@treenet.co.nz>
References: <bbb86484-cef7-e6cb-8e07-36f3768ec0bd@poczta.wp.pl>
 <168d01d300ba$07678c20$1636a460$@ngtech.co.il>
 <8a273212-8565-1d34-3a15-3c2a29a19756@treenet.co.nz>
Message-ID: <aaf652aa-1356-601c-c663-6b29cfa60bff@poczta.wp.pl>

Hi Amos,
As I wrote to Eliezer, his solution works.
Thank you for your help as well.

Rgrds,
iziz1

W dniu 2017-07-20 o 02:04, Amos Jeffries pisze:
> On 20/07/17 06:08, Eliezer Croitoru wrote:
>> Hey iziz1,
>>
>> Can you try to add squid.conf the next and see if it affects anything:
>> forwarded_for delete
>> via off
>>
>> http://www.squid-cache.org/Doc/config/via/
>> http://www.squid-cache.org/Doc/config/forwarded_for/
>>
>> And see if it changes anything?
>>
> 
> Er, try those one at a time.
> 
> If the forwarded_for delete works, also try "forwarded_for transparent"
> and use just that if sufficient.
> 
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users


From eliezer at ngtech.co.il  Thu Jul 20 08:04:56 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 20 Jul 2017 11:04:56 +0300
Subject: [squid-users] Problem with login to website by Squid web proxy
	3.5.20 on Centos 7
In-Reply-To: <3252e911-e8f0-b842-5948-0567560b1f7e@poczta.wp.pl>
References: <bbb86484-cef7-e6cb-8e07-36f3768ec0bd@poczta.wp.pl>
 <168d01d300ba$07678c20$1636a460$@ngtech.co.il>
 <3252e911-e8f0-b842-5948-0567560b1f7e@poczta.wp.pl>
Message-ID: <00cd01d3012e$e040e8b0$a0c2ba10$@ngtech.co.il>

Hey iziz1,

Try to work with what Amos suggested.
Try to first turn on the via ie:
via on

and see if still works fine.
If indeed it works fine then try to change the 
forwarded_for delete
into
forwarded_for transparent

and see what works for you.
It?s better to leave the via on and not off.
But from what I understand it seems that this site(is it a bank?) is broken and their webmaster and security personal should be aware of your findings for their sake.
It can cause their system act in a very weird way.

All The Bests,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: Kurczewski, Bart?omiej (WP.PL) [mailto:iziz1 at poczta.wp.pl] 
Sent: Thursday, July 20, 2017 10:20
To: Eliezer Croitoru <eliezer at ngtech.co.il>; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Problem with login to website by Squid web proxy 3.5.20 on Centos 7

Hi Eliezer,
First of all I would like to thank you for fast answer.
And my second "thanks" is for your help.
Your solution works, and the problem has been solved.

Regards,
iziz1

W dniu 2017-07-19 o 20:08, Eliezer Croitoru pisze:
> Hey iziz1,
> 
> Can you try to add squid.conf the next and see if it affects anything:
> forwarded_for delete
> via off
> 
> http://www.squid-cache.org/Doc/config/via/
> http://www.squid-cache.org/Doc/config/forwarded_for/
> 
> And see if it changes anything?
> 
> Let Me Know if something changes,
> Eliezer
> 
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
> 
> 
> -----Original Message-----
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Kurczewski, Bart?omiej (WP.PL)
> Sent: Tuesday, July 18, 2017 15:56
> To: squid-users at lists.squid-cache.org
> Subject: [squid-users] Problem with login to website by Squid web proxy 3.5.20 on Centos 7
> 
> Hi,
> I have a problem to login to one website (http://intouch.techdata.com)
> using Squid 3.5.20 on Centos 7 with default Squid configuration, which
> is acting as web proxy (non-transparent) on 3128 port in my network:
> 
> --------------------------------------------------------------------------
> #
> # Recommended minimum configuration:
> #
> 
> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
> acl localnet src 172.16.0.0/12	# RFC1918 possible internal network
> acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
> machines
> 
> acl SSL_ports port 443
> acl Safe_ports port 80		# http
> acl Safe_ports port 21		# ftp
> acl Safe_ports port 443		# https
> acl Safe_ports port 70		# gopher
> acl Safe_ports port 210		# wais
> acl Safe_ports port 1025-65535	# unregistered ports
> acl Safe_ports port 280		# http-mgmt
> acl Safe_ports port 488		# gss-http
> acl Safe_ports port 591		# filemaker
> acl Safe_ports port 777		# multiling http
> acl CONNECT method CONNECT
> 
> #
> # Recommended minimum Access Permission configuration:
> #
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
> 
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
> 
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> #http_access deny to_localhost
> 
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> 
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
> 
> # And finally deny all other access to this proxy
> http_access deny all
> 
> # Squid normally listens to port 3128
> http_port 3128
> 
> # Uncomment and adjust the following to add a disk cache directory.
> #cache_dir ufs /var/spool/squid 100 16 256
> 
> # Leave coredumps in the first cache dir
> coredump_dir /var/spool/squid
> 
> #
> # Add any of your own refresh_pattern entries above these.
> #
> refresh_pattern ^ftp:		1440	20%	10080
> refresh_pattern ^gopher:	1440	0%	1440
> refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
> refresh_pattern .		0	20%	4320
> ------------------------------------------------------------------------------
> 
> 
> In a FF browser with my Squid server settings I put correct password on
> techdata website, but webpage redirect me to the same web form and
> doesn't allow to login. The password is correct, because when I put
> wrong password I got JavaScript alert from this website that password is
> incorrect.
> 
> When I disable using Squid proxy in FF and use normal PAT connection via
> my Juniper firewall everything works perfect on the same machine and I
> can login to TechData website.
> I Squid access.log I can see only this:
> 
> -----------------------------------------------------------------
> 1500364995.497    140 10.48.22.33 TCP_MISS/302 735 GET
> http://intouch.techdata.com/intouch/Home.aspx? -
> HIER_DIRECT/192.230.78.204 text/html
> -----------------------------------------------------------------
> 
> I suspect some problems with redirection on TechData website, but spend
> hours in Internet to find solution, unfortunately without success....
> Maybe you can help me?
> 
> Regards,
> iziz1
> 
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
> 
> 
> 



From iziz1 at poczta.wp.pl  Thu Jul 20 08:24:20 2017
From: iziz1 at poczta.wp.pl (=?UTF-8?Q?Kurczewski=2c_Bart=c5=82omiej_=28WP.PL=29?=)
Date: Thu, 20 Jul 2017 10:24:20 +0200
Subject: [squid-users] Problem with login to website by Squid web proxy
 3.5.20 on Centos 7
In-Reply-To: <00cd01d3012e$e040e8b0$a0c2ba10$@ngtech.co.il>
References: <bbb86484-cef7-e6cb-8e07-36f3768ec0bd@poczta.wp.pl>
 <168d01d300ba$07678c20$1636a460$@ngtech.co.il>
 <3252e911-e8f0-b842-5948-0567560b1f7e@poczta.wp.pl>
 <00cd01d3012e$e040e8b0$a0c2ba10$@ngtech.co.il>
Message-ID: <69f71f5a-ecfb-6301-3130-02b9431fa879@poczta.wp.pl>

Hi Eliezer,
According to your and Amos suggestions I have change squid.conf by
making "via on" and setting only "forwarded_for transparent".
And I can login to TechData website (which is not a bank, but IT
technology distributor) without any problems.
Thank you for you advice and help.

Rgdrs,
iziz1

W dniu 2017-07-20 o 10:04, Eliezer Croitoru pisze:
> Hey iziz1,
> 
> Try to work with what Amos suggested.
> Try to first turn on the via ie:
> via on
> 
> and see if still works fine.
> If indeed it works fine then try to change the 
> forwarded_for delete
> into
> forwarded_for transparent
> 
> and see what works for you.
> It?s better to leave the via on and not off.
> But from what I understand it seems that this site(is it a bank?) is broken and their webmaster and security personal should be aware of your findings for their sake.
> It can cause their system act in a very weird way.
> 
> All The Bests,
> Eliezer
> 
> ----
> Eliezer Croitoru
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
> 
> 
> 
> -----Original Message-----
> From: Kurczewski, Bart?omiej (WP.PL) [mailto:iziz1 at poczta.wp.pl] 
> Sent: Thursday, July 20, 2017 10:20
> To: Eliezer Croitoru <eliezer at ngtech.co.il>; squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Problem with login to website by Squid web proxy 3.5.20 on Centos 7
> 
> Hi Eliezer,
> First of all I would like to thank you for fast answer.
> And my second "thanks" is for your help.
> Your solution works, and the problem has been solved.
> 
> Regards,
> iziz1
> 
> W dniu 2017-07-19 o 20:08, Eliezer Croitoru pisze:
>> Hey iziz1,
>>
>> Can you try to add squid.conf the next and see if it affects anything:
>> forwarded_for delete
>> via off
>>
>> http://www.squid-cache.org/Doc/config/via/
>> http://www.squid-cache.org/Doc/config/forwarded_for/
>>
>> And see if it changes anything?
>>
>> Let Me Know if something changes,
>> Eliezer
>>
>> ----
>> Eliezer Croitoru
>> Linux System Administrator
>> Mobile: +972-5-28704261
>> Email: eliezer at ngtech.co.il
>>
>>
>>
>> -----Original Message-----
>> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Kurczewski, Bart?omiej (WP.PL)
>> Sent: Tuesday, July 18, 2017 15:56
>> To: squid-users at lists.squid-cache.org
>> Subject: [squid-users] Problem with login to website by Squid web proxy 3.5.20 on Centos 7
>>
>> Hi,
>> I have a problem to login to one website (http://intouch.techdata.com)
>> using Squid 3.5.20 on Centos 7 with default Squid configuration, which
>> is acting as web proxy (non-transparent) on 3128 port in my network:
>>
>> --------------------------------------------------------------------------
>> #
>> # Recommended minimum configuration:
>> #
>>
>> # Example rule allowing access from your local networks.
>> # Adapt to list your (internal) IP networks from where browsing
>> # should be allowed
>> acl localnet src 10.0.0.0/8	# RFC1918 possible internal network
>> acl localnet src 172.16.0.0/12	# RFC1918 possible internal network
>> acl localnet src 192.168.0.0/16	# RFC1918 possible internal network
>> acl localnet src fc00::/7       # RFC 4193 local private network range
>> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
>> machines
>>
>> acl SSL_ports port 443
>> acl Safe_ports port 80		# http
>> acl Safe_ports port 21		# ftp
>> acl Safe_ports port 443		# https
>> acl Safe_ports port 70		# gopher
>> acl Safe_ports port 210		# wais
>> acl Safe_ports port 1025-65535	# unregistered ports
>> acl Safe_ports port 280		# http-mgmt
>> acl Safe_ports port 488		# gss-http
>> acl Safe_ports port 591		# filemaker
>> acl Safe_ports port 777		# multiling http
>> acl CONNECT method CONNECT
>>
>> #
>> # Recommended minimum Access Permission configuration:
>> #
>> # Deny requests to certain unsafe ports
>> http_access deny !Safe_ports
>>
>> # Deny CONNECT to other than secure SSL ports
>> http_access deny CONNECT !SSL_ports
>>
>> # Only allow cachemgr access from localhost
>> http_access allow localhost manager
>> http_access deny manager
>>
>> # We strongly recommend the following be uncommented to protect innocent
>> # web applications running on the proxy server who think the only
>> # one who can access services on "localhost" is a local user
>> #http_access deny to_localhost
>>
>> #
>> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
>> #
>>
>> # Example rule allowing access from your local networks.
>> # Adapt localnet in the ACL section to list your (internal) IP networks
>> # from where browsing should be allowed
>> http_access allow localnet
>> http_access allow localhost
>>
>> # And finally deny all other access to this proxy
>> http_access deny all
>>
>> # Squid normally listens to port 3128
>> http_port 3128
>>
>> # Uncomment and adjust the following to add a disk cache directory.
>> #cache_dir ufs /var/spool/squid 100 16 256
>>
>> # Leave coredumps in the first cache dir
>> coredump_dir /var/spool/squid
>>
>> #
>> # Add any of your own refresh_pattern entries above these.
>> #
>> refresh_pattern ^ftp:		1440	20%	10080
>> refresh_pattern ^gopher:	1440	0%	1440
>> refresh_pattern -i (/cgi-bin/|\?) 0	0%	0
>> refresh_pattern .		0	20%	4320
>> ------------------------------------------------------------------------------
>>
>>
>> In a FF browser with my Squid server settings I put correct password on
>> techdata website, but webpage redirect me to the same web form and
>> doesn't allow to login. The password is correct, because when I put
>> wrong password I got JavaScript alert from this website that password is
>> incorrect.
>>
>> When I disable using Squid proxy in FF and use normal PAT connection via
>> my Juniper firewall everything works perfect on the same machine and I
>> can login to TechData website.
>> I Squid access.log I can see only this:
>>
>> -----------------------------------------------------------------
>> 1500364995.497    140 10.48.22.33 TCP_MISS/302 735 GET
>> http://intouch.techdata.com/intouch/Home.aspx? -
>> HIER_DIRECT/192.230.78.204 text/html
>> -----------------------------------------------------------------
>>
>> I suspect some problems with redirection on TechData website, but spend
>> hours in Internet to find solution, unfortunately without success....
>> Maybe you can help me?
>>
>> Regards,
>> iziz1
>>
>> _______________________________________________
>> squid-users mailing list
>> squid-users at lists.squid-cache.org
>> http://lists.squid-cache.org/listinfo/squid-users
>>
>>
>>
> 
> 
> 


From uhlar at fantomas.sk  Thu Jul 20 09:43:52 2017
From: uhlar at fantomas.sk (Matus UHLAR - fantomas)
Date: Thu, 20 Jul 2017 11:43:52 +0200
Subject: [squid-users] This list generates a forward loop ...
In-Reply-To: <31ce9094-5f98-ca75-c06e-dd43faf5b685@treenet.co.nz>
References: <31cb999478ff31663df9dbfe85f107a5.1500385341@squirrel.mail>
 <0b5c9cec-68ee-e238-fb1a-4885b7408361@treenet.co.nz>
 <59702500.2000303@mathemainzel.info>
 <5970292A.9060405@mathemainzel.info>
 <31ce9094-5f98-ca75-c06e-dd43faf5b685@treenet.co.nz>
Message-ID: <20170720094352.GA16947@fantomas.sk>

On 20.07.17 17:16, Amos Jeffries wrote:
>Your DKIM signature covers the Subject and To headers. Any normal 
>mailing list will modify those,

I disagree - IMHO sane listservers don't modify those headers.

> so your server cannot do that on list 
>postings. Content-Type is also changed sometimes by our listserver 
>due to the list policy on binary attachments, I dont know whether 
>that is a common practice too but I suspect it might be. The others 
>should be fine AFAIK.

This is a better example. However, mailserver supporting DKIM should strip
the DKIM header if it's going to modify anything signed.
Other solution is to refuse message (when the signer domain SKIM policy is
signall).

>The other members mailserver does something unusually nasty - it 
>simply loops the message back at the list instead of bouncing with a 
>proper error to you. And since your address is still the envelope 
>sender our server rejects with that loop error bouncing back at you.

which is exactly what I have guessed :-)
And this is why header of original attached message were useful:

Received: from ScrolloutF1.linguitronics.com (203-74-122-103.HINET-IP.hinet.net [203.74.122.103])
     by lists.squid-cache.org (Postfix) with ESMTPS id 15AD7E1196
     for <squid-users at lists.squid-cache.org>; Thu, 20 Jul 2017 03:44:49 +0000 (UTC)
Received: by ScrolloutF1.linguitronics.com (Postfix, from userid 0)
     id 3xCfsX5v6DzHpF4; Thu, 20 Jul 2017 11:44:32 +0800 (CST)
Received: from 192.168.1.204 (192.168.1.204:143) by
   mailgateway.linguitronics.com with IMAP4; 20 Jul 2017 03:44:32 -0000

Received: from ScrolloutF1.linguitronics.com (unknown [192.168.1.205])
     by tw.linguitronics.com (Postfix) with ESMTP id 5A3E64023A
     for <spam at linguitronics.com>; Thu, 20 Jul 2017 11:35:56 +0800 (CST)
Received: from localhost (localhost [127.0.0.1])
     by ScrolloutF1.linguitronics.com (Postfix) with ESMTP id 3xCfgc5PKRzHr9d
     for <spam at linguitronics.com>; Thu, 20 Jul 2017 11:35:56 +0800 (CST)
Received: from ScrolloutF1.linguitronics.com ([127.0.0.1])
     by localhost (scrolloutf1.linguitronics.com [127.0.0.1]) (amavisd-new, port 10024)
     with LMTP id uAebWOExfOQd for <akong at linguitronics.com>;
     Thu, 20 Jul 2017 11:35:55 +0800 (CST)
Received: from lists.squid-cache.org (lists.squid-cache.org [104.130.201.120])
     by ScrolloutF1.linguitronics.com (Postfix) with ESMTP id 3xCfgP4p5LzHr9b
     for <akong at linguitronics.com>; Thu, 20 Jul 2017 11:35:39 +0800 (CST)

>[yes I wish our sysadmin could stop that bouncing, but the tools seem 
>to be limited].

removing akong at linguitronics.com from recipients should fix the problem.
I'm sending Cc: there so the culprit knows what to fix on their side.

-- 
Matus UHLAR - fantomas, uhlar at fantomas.sk ; http://www.fantomas.sk/
Warning: I wish NOT to receive e-mail advertising to this address.
Varovanie: na tuto adresu chcem NEDOSTAVAT akukolvek reklamnu postu.
Chernobyl was an Windows 95 beta test site.


From squid3 at treenet.co.nz  Thu Jul 20 10:36:50 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 20 Jul 2017 22:36:50 +1200
Subject: [squid-users] Problem with login to website by Squid web proxy
 3.5.20 on Centos 7
In-Reply-To: <aaf652aa-1356-601c-c663-6b29cfa60bff@poczta.wp.pl>
References: <bbb86484-cef7-e6cb-8e07-36f3768ec0bd@poczta.wp.pl>
 <168d01d300ba$07678c20$1636a460$@ngtech.co.il>
 <8a273212-8565-1d34-3a15-3c2a29a19756@treenet.co.nz>
 <aaf652aa-1356-601c-c663-6b29cfa60bff@poczta.wp.pl>
Message-ID: <bef85e53-d08a-e37f-ddb5-dc4fc4edf7f6@treenet.co.nz>

On 20/07/17 19:24, Kurczewski, Bart?omiej (WP.PL) wrote:
> Hi Amos,
> As I wrote to Eliezer, his solution works.
> Thank you for your help as well.
> 

Eliezers 'solution' was to outright delete the headers HTTP uses to 
protect your server against forwarding loops (Via), and to allow 
back-tracking of abusive transactions (X-Forwarded-For / Forwarded).

Both quite important things to leave working if you can. Which is why I 
suggested trying them one at a time and using the least amount of 
traffic manipulation that would actually fix the problem.

FWIW a lot of the server-side brokenness regarding those headers is a 
result of beginner web developers never having encountered such headers 
in their narrow periods of time looking at headers. The more experience 
that can be thrown in their direction through real traffic the more 
benefits we all get as proxy admin - through less broken site codes.

Amos


From squid3 at treenet.co.nz  Thu Jul 20 11:05:21 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 20 Jul 2017 23:05:21 +1200
Subject: [squid-users] This list generates a forward loop ...
In-Reply-To: <20170720094352.GA16947@fantomas.sk>
References: <31cb999478ff31663df9dbfe85f107a5.1500385341@squirrel.mail>
 <0b5c9cec-68ee-e238-fb1a-4885b7408361@treenet.co.nz>
 <59702500.2000303@mathemainzel.info> <5970292A.9060405@mathemainzel.info>
 <31ce9094-5f98-ca75-c06e-dd43faf5b685@treenet.co.nz>
 <20170720094352.GA16947@fantomas.sk>
Message-ID: <baa743f5-6ef4-06a1-5042-651d81d812e3@treenet.co.nz>

On 20/07/17 21:43, Matus UHLAR - fantomas wrote:
> On 20.07.17 17:16, Amos Jeffries wrote:
>> Your DKIM signature covers the Subject and To headers. Any normal 
>> mailing list will modify those,
> 
> I disagree - IMHO sane listservers don't modify those headers.
> 

Sadly, sane != normal. I'm referring to the common popular list servers. 
We have used several of them over the years.


>> so your server cannot do that on list postings. Content-Type is also 
>> changed sometimes by our listserver due to the list policy on binary 
>> attachments, I dont know whether that is a common practice too but I 
>> suspect it might be. The others should be fine AFAIK.
> 
> This is a better example. However, mailserver supporting DKIM should strip
> the DKIM header if it's going to modify anything signed.
> Other solution is to refuse message (when the signer domain SKIM policy is
> signall).
> 


<https://wiki.list.org/DEV/DKIM> and the discussions it links to explain 
the issues around DKIM in a fair bit of detail, including why even 
removal does not work.

(/me reading that page is brining on a greybeard moment. DKIM vs SPF was 
the hot topic when I switched from mail to proxy focused work. Heck, 10 
years of Squid).

Amos


From pablo.ruben.maldonado at gmail.com  Thu Jul 20 13:08:27 2017
From: pablo.ruben.maldonado at gmail.com (Pablo Ruben Maldonado)
Date: Thu, 20 Jul 2017 10:08:27 -0300
Subject: [squid-users] Squid box for two networks
In-Reply-To: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
Message-ID: <CAEUQ6HXDfWbgRF_pUQSHCqt_ya2XiHAHq=QDhPdyDc8cE3LwsA@mail.gmail.com>

Hi, i add information missing in original post. Thanks for assistance:

The Squid Box has setup for Intercept Mode. Iptables rules here:

-A PREROUTING -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 3128
-A PREROUTING -p tcp -m tcp --dport 443 -j REDIRECT --to-ports 3129

The config paste in https://pastebin.com/Witg3cG1

Thanks

On Mon, Jul 17, 2017 at 5:31 PM, Pablo Ruben Maldonado <
pablo.ruben.maldonado at gmail.com> wrote:

> Hello, I have a squid box 3.5 working without problems for the lan
> 192.168.110.0/24 for several months. Now I want setup to another lan
> 192.168.115.0/24 but I cannot. Tcpdump inform me that the packages come
> to squid box. But in Squid's log I do not see anything. Can they give me
> some tip?
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/e336d605/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Network map.pdf
Type: application/pdf
Size: 22149 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/e336d605/attachment.pdf>

From Antony.Stone at squid.open.source.it  Thu Jul 20 13:27:10 2017
From: Antony.Stone at squid.open.source.it (Antony Stone)
Date: Thu, 20 Jul 2017 14:27:10 +0100
Subject: [squid-users] Squid box for two networks
In-Reply-To: <CAEUQ6HXDfWbgRF_pUQSHCqt_ya2XiHAHq=QDhPdyDc8cE3LwsA@mail.gmail.com>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
 <CAEUQ6HXDfWbgRF_pUQSHCqt_ya2XiHAHq=QDhPdyDc8cE3LwsA@mail.gmail.com>
Message-ID: <201707201427.10884.Antony.Stone@squid.open.source.it>

On Thursday 20 July 2017 at 14:08:27, Pablo Ruben Maldonado wrote:

> Hi, i add information missing in original post. Thanks for assistance:
> 
> The Squid Box has setup for Intercept Mode. Iptables rules here:
> 
> -A PREROUTING -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 3128
> -A PREROUTING -p tcp -m tcp --dport 443 -j REDIRECT --to-ports 3129

How are you routing the packets from the firewall to Squid?

> The config paste in https://pastebin.com/Witg3cG1
> 
> Thanks
> 
> On Mon, Jul 17, 2017 at 5:31 PM, Pablo Ruben Maldonado <
> 
> pablo.ruben.maldonado at gmail.com> wrote:
> > Hello, I have a squid box 3.5 working without problems for the lan
> > 192.168.110.0/24 for several months. Now I want setup to another lan
> > 192.168.115.0/24 but I cannot. Tcpdump inform me that the packages come
> > to squid box. But in Squid's log I do not see anything. Can they give me
> > some tip?

Can you give us any examples of packets as seen by tcpdump on the Squid box:

a) from 192.168.110.0/24

b) from 192.168.115.0/24


Antony.

-- 
BASIC is to computer languages what Roman numerals are to arithmetic.

                                                   Please reply to the list;
                                                         please *don't* CC me.


From pablo.ruben.maldonado at gmail.com  Thu Jul 20 13:40:52 2017
From: pablo.ruben.maldonado at gmail.com (Pablo Ruben Maldonado)
Date: Thu, 20 Jul 2017 10:40:52 -0300
Subject: [squid-users] Squid box for two networks
In-Reply-To: <201707201427.10884.Antony.Stone@squid.open.source.it>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
 <CAEUQ6HXDfWbgRF_pUQSHCqt_ya2XiHAHq=QDhPdyDc8cE3LwsA@mail.gmail.com>
 <201707201427.10884.Antony.Stone@squid.open.source.it>
Message-ID: <CAEUQ6HXteNPyUaDyB+3-eqN+Hgc9B7y8LrZmHxf4P0FHWGq8ng@mail.gmail.com>

The packets are routing using a mark and later routing rules inside my
principal router (Mikrotik). Attach images with examples of packets
arriving to Squid box.

On Thu, Jul 20, 2017 at 10:27 AM, Antony Stone <
Antony.Stone at squid.open.source.it> wrote:

> On Thursday 20 July 2017 at 14:08:27, Pablo Ruben Maldonado wrote:
>
> > Hi, i add information missing in original post. Thanks for assistance:
> >
> > The Squid Box has setup for Intercept Mode. Iptables rules here:
> >
> > -A PREROUTING -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 3128
> > -A PREROUTING -p tcp -m tcp --dport 443 -j REDIRECT --to-ports 3129
>
> How are you routing the packets from the firewall to Squid?
>
> > The config paste in https://pastebin.com/Witg3cG1
> >
> > Thanks
> >
> > On Mon, Jul 17, 2017 at 5:31 PM, Pablo Ruben Maldonado <
> >
> > pablo.ruben.maldonado at gmail.com> wrote:
> > > Hello, I have a squid box 3.5 working without problems for the lan
> > > 192.168.110.0/24 for several months. Now I want setup to another lan
> > > 192.168.115.0/24 but I cannot. Tcpdump inform me that the packages
> come
> > > to squid box. But in Squid's log I do not see anything. Can they give
> me
> > > some tip?
>
> Can you give us any examples of packets as seen by tcpdump on the Squid
> box:
>
> a) from 192.168.110.0/24
>
> b) from 192.168.115.0/24
>
>
> Antony.
>
> --
> BASIC is to computer languages what Roman numerals are to arithmetic.
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/75dee7de/attachment.htm>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 192168110.net.png
Type: image/png
Size: 19044 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/75dee7de/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 192168115.net.png
Type: image/png
Size: 4754 bytes
Desc: not available
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/75dee7de/attachment-0001.png>

From eliezer at ngtech.co.il  Thu Jul 20 17:11:53 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 20 Jul 2017 20:11:53 +0300
Subject: [squid-users] Squid box for two networks
In-Reply-To: <CAEUQ6HXteNPyUaDyB+3-eqN+Hgc9B7y8LrZmHxf4P0FHWGq8ng@mail.gmail.com>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
 <CAEUQ6HXDfWbgRF_pUQSHCqt_ya2XiHAHq=QDhPdyDc8cE3LwsA@mail.gmail.com>
 <201707201427.10884.Antony.Stone@squid.open.source.it>
 <CAEUQ6HXteNPyUaDyB+3-eqN+Hgc9B7y8LrZmHxf4P0FHWGq8ng@mail.gmail.com>
Message-ID: <031601d3017b$48d96bd0$da8c4370$@ngtech.co.il>

Hey Pablo,

I am working as a tech support for MikroTik devices and the tcpdump dumps are leaving couple things unknown.
Can you share the MikroTik rules PBR rules you are using?
Are you using any kind of connection marking and tracking in the mix or just plain source based routing?
I am pretty sure that the issue is in the reverse path and not backwards.
If you can export your MikroTik configuration I might be able to try and help you find the right rules if these are wrong.
Also make sure that the squid box has reverse path filtering disabled using:
http://wiki.squid-cache.org/EliezerCroitoru/Drafts/MwanLB#Set_Reverse_Path_Filter_machine_globally_script

And also take a peek at:
http://wiki.squid-cache.org/ConfigExamples/UbuntuTproxy4Wccp2#Linux_and_Squid_Configuration

I planned to add into the wiki an article\tutorial how to setup squid with MikroTik since there are more than a dozen of articles\tutorials that just do not do it the right way.

Eliezer

* you can send me the configuration privately if these are sensitive 

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Pablo Ruben Maldonado
Sent: Thursday, July 20, 2017 16:41
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid box for two networks

The packets are routing using a mark and later routing rules inside my principal router (Mikrotik). Attach images with examples of packets arriving to Squid box.

On Thu, Jul 20, 2017 at 10:27 AM, Antony Stone <mailto:Antony.Stone at squid.open.source.it> wrote:
On Thursday 20 July 2017 at 14:08:27, Pablo Ruben Maldonado wrote:

> Hi, i add information missing in original post. Thanks for assistance:
>
> The Squid Box has setup for Intercept Mode. Iptables rules here:
>
> -A PREROUTING -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 3128
> -A PREROUTING -p tcp -m tcp --dport 443 -j REDIRECT --to-ports 3129

How are you routing the packets from the firewall to Squid?

> The config paste in https://pastebin.com/Witg3cG1
>
> Thanks
>
> On Mon, Jul 17, 2017 at 5:31 PM, Pablo Ruben Maldonado <
>
> mailto:pablo.ruben.maldonado at gmail.com> wrote:
> > Hello, I have a squid box 3.5 working without problems for the lan
> > http://192.168.110.0/24 for several months. Now I want setup to another lan
> > http://192.168.115.0/24 but I cannot. Tcpdump inform me that the packages come
> > to squid box. But in Squid's log I do not see anything. Can they give me
> > some tip?

Can you give us any examples of packets as seen by tcpdump on the Squid box:

a) from http://192.168.110.0/24

b) from http://192.168.115.0/24


Antony.

--
BASIC is to computer languages what Roman numerals are to arithmetic.

                                                   Please reply to the list;
                                                         please *don't* CC me.
_______________________________________________
squid-users mailing list
mailto:squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users




From pablo.ruben.maldonado at gmail.com  Thu Jul 20 18:50:40 2017
From: pablo.ruben.maldonado at gmail.com (Pablo Ruben Maldonado)
Date: Thu, 20 Jul 2017 15:50:40 -0300
Subject: [squid-users] Squid box for two networks
In-Reply-To: <031601d3017b$48d96bd0$da8c4370$@ngtech.co.il>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
 <CAEUQ6HXDfWbgRF_pUQSHCqt_ya2XiHAHq=QDhPdyDc8cE3LwsA@mail.gmail.com>
 <201707201427.10884.Antony.Stone@squid.open.source.it>
 <CAEUQ6HXteNPyUaDyB+3-eqN+Hgc9B7y8LrZmHxf4P0FHWGq8ng@mail.gmail.com>
 <031601d3017b$48d96bd0$da8c4370$@ngtech.co.il>
Message-ID: <CAEUQ6HX1qLv4nLszCDm5ckfqq+5vhug+rBE=TqR=hMmBGV6zsw@mail.gmail.com>

Hi Eliezer, thanks for you reply.

I'm marking and routing traffic to port 80 from my lan's 192.168.110.0/24
(Work!) and 192.168.115.0/24 (Fail!). The mark line in Mangle is:

add action=mark-connection chain=prerouting comment="TCP 80: Tr\E1fico HTTP
de\
    sde la red WIFI. Se marca la conexi\F3n para QoS y Policy Routing.
Ser\E1 \
    routeado hacia Proxy03" !connection-bytes !connection-limit \
    connection-mark=no-mark !connection-nat-state !connection-rate \
    !connection-state !connection-type !content disabled=no !dscp \
    !dst-address !dst-address-list !dst-address-type !dst-limit dst-port=80
\
    !fragment !hotspot !icmp-options !in-bridge-port in-interface=eth4-wifi
\
    !ingress-priority !ipsec-policy !ipv4-options !layer7-protocol !limit \
    log=no log-prefix="" new-connection-mark=conn_proxy !nth
!out-bridge-port \
    !out-interface !p2p !packet-mark !packet-size passthrough=yes \
    !per-connection-classifier !port !priority protocol=tcp !psd !random \
    !routing-mark !routing-table src-address=192.168.115.0/24
!src-address-list \
    !src-address-type !src-mac-address !src-port !tcp-flags !tcp-mss !time \
    !ttl

The packet mark and route lines:

add action=mark-packet chain=prerouting comment=\
    "TCP 80: Se marca el paquete para Queue Tree (Up)" !connection-bytes \
    !connection-limit connection-mark=conn_proxy !connection-nat-state \
    !connection-rate !connection-state !connection-type !content
disabled=no \
    !dscp !dst-address !dst-address-list !dst-address-type !dst-limit \
    !dst-port !fragment !hotspot !icmp-options !in-bridge-port
!in-interface \
    !ingress-priority !ipsec-policy !ipv4-options !layer7-protocol !limit \
    log=no log-prefix="" new-packet-mark=up_tcp_80_pkt !nth
!out-bridge-port \
    !out-interface !p2p !packet-mark !packet-size passthrough=yes \
    !per-connection-classifier !port !priority !protocol !psd !random \
    !routing-mark !routing-table !src-address !src-address-list \
    !src-address-type !src-mac-address !src-port !tcp-flags !tcp-mss time=\
    0s-1d,sun,mon,tue,wed,thu,fri,sat !ttl
add action=mark-routing chain=prerouting comment=\
    "TCP 80: Se ejecuta el Policy Routing hacia Proxy03" !connection-bytes \
    !connection-limit !connection-mark !connection-nat-state
!connection-rate \
    !connection-state !connection-type !content disabled=no !dscp \
    !dst-address dst-address-list=!clientslist !dst-address-type !dst-limit
\
    !dst-port !fragment !hotspot !icmp-options !in-bridge-port
!in-interface \
    !ingress-priority !ipsec-policy !ipv4-options !layer7-protocol !limit \
    log=no log-prefix="" new-routing-mark=route_toproxy03 !nth \
    !out-bridge-port !out-interface !p2p packet-mark=up_tcp_80_pkt \
    !packet-size passthrough=no !per-connection-classifier !port !priority \
    !protocol !psd !random !routing-mark !routing-table !src-address \
    !src-address-list !src-address-type !src-mac-address !src-port
!tcp-flags \
    !tcp-mss !time !ttl

Thanks

On Thu, Jul 20, 2017 at 2:11 PM, Eliezer Croitoru <eliezer at ngtech.co.il>
wrote:

> Hey Pablo,
>
> I am working as a tech support for MikroTik devices and the tcpdump dumps
> are leaving couple things unknown.
> Can you share the MikroTik rules PBR rules you are using?
> Are you using any kind of connection marking and tracking in the mix or
> just plain source based routing?
> I am pretty sure that the issue is in the reverse path and not backwards.
> If you can export your MikroTik configuration I might be able to try and
> help you find the right rules if these are wrong.
> Also make sure that the squid box has reverse path filtering disabled
> using:
> http://wiki.squid-cache.org/EliezerCroitoru/Drafts/MwanLB#
> Set_Reverse_Path_Filter_machine_globally_script
>
> And also take a peek at:
> http://wiki.squid-cache.org/ConfigExamples/UbuntuTproxy4Wccp2#Linux_and_
> Squid_Configuration
>
> I planned to add into the wiki an article\tutorial how to setup squid with
> MikroTik since there are more than a dozen of articles\tutorials that just
> do not do it the right way.
>
> Eliezer
>
> * you can send me the configuration privately if these are sensitive
>
> ----
> http://ngtech.co.il/lmgtfy/
> Linux System Administrator
> Mobile: +972-5-28704261
> Email: eliezer at ngtech.co.il
>
>
> From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On
> Behalf Of Pablo Ruben Maldonado
> Sent: Thursday, July 20, 2017 16:41
> To: squid-users at lists.squid-cache.org
> Subject: Re: [squid-users] Squid box for two networks
>
> The packets are routing using a mark and later routing rules inside my
> principal router (Mikrotik). Attach images with examples of packets
> arriving to Squid box.
>
> On Thu, Jul 20, 2017 at 10:27 AM, Antony Stone <mailto:Antony.Stone at squid.
> open.source.it> wrote:
> On Thursday 20 July 2017 at 14:08:27, Pablo Ruben Maldonado wrote:
>
> > Hi, i add information missing in original post. Thanks for assistance:
> >
> > The Squid Box has setup for Intercept Mode. Iptables rules here:
> >
> > -A PREROUTING -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 3128
> > -A PREROUTING -p tcp -m tcp --dport 443 -j REDIRECT --to-ports 3129
>
> How are you routing the packets from the firewall to Squid?
>
> > The config paste in https://pastebin.com/Witg3cG1
> >
> > Thanks
> >
> > On Mon, Jul 17, 2017 at 5:31 PM, Pablo Ruben Maldonado <
> >
> > mailto:pablo.ruben.maldonado at gmail.com> wrote:
> > > Hello, I have a squid box 3.5 working without problems for the lan
> > > http://192.168.110.0/24 for several months. Now I want setup to
> another lan
> > > http://192.168.115.0/24 but I cannot. Tcpdump inform me that the
> packages come
> > > to squid box. But in Squid's log I do not see anything. Can they give
> me
> > > some tip?
>
> Can you give us any examples of packets as seen by tcpdump on the Squid
> box:
>
> a) from http://192.168.110.0/24
>
> b) from http://192.168.115.0/24
>
>
> Antony.
>
> --
> BASIC is to computer languages what Roman numerals are to arithmetic.
>
>                                                    Please reply to the
> list;
>                                                          please *don't* CC
> me.
> _______________________________________________
> squid-users mailing list
> mailto:squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
>
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/5ec23554/attachment.htm>

From ncherukuri at partycity.com  Thu Jul 20 19:02:37 2017
From: ncherukuri at partycity.com (Cherukuri, Naresh)
Date: Thu, 20 Jul 2017 19:02:37 +0000
Subject: [squid-users] Squid Version 3.5.20 Any Ideas
In-Reply-To: <95daaf62-11e1-283f-8c24-81f53323626f@treenet.co.nz>
References: <89638057A560FB458C01C197F81C7F5D13F32404@PACERS.amscan.corp>
 <e653374f-020d-c213-6a0f-12dda8ebce32@gmail.com>
 <596F973C.7040603@mathemainzel.info>
 <6bb20814-f8ce-a04a-1ee4-5aeb71bf1f9c@gmail.com>
 <89638057A560FB458C01C197F81C7F5D13F32BF9@PACERS.amscan.corp>
 <dce8f67e-a340-ffa0-0e42-1968e5b05fca@gmail.com>
 <89638057A560FB458C01C197F81C7F5D13F32CA3@PACERS.amscan.corp>
 <f7da4b60-02f5-71ea-e7ff-23244b0f6b62@gmail.com>
 <95daaf62-11e1-283f-8c24-81f53323626f@treenet.co.nz>
Message-ID: <89638057A560FB458C01C197F81C7F5D13F579EA@ROCKETS.amscan.corp>

Thank you Amos! Appreciate your help.

-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Wednesday, July 19, 2017 8:55 PM
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid Version 3.5.20 Any Ideas

On 20/07/17 09:10, Yuri wrote:
> Aha,
> 
> 
> 20.07.2017 3:04, Cherukuri, Naresh ?????:
>>
>> Yuri,
>>
>> I am sorry I didn?t get you I already installed certificate on all 
>> clients(trusted root certificate authorities). You want me install 
>> proxy public key also on clients, if so were should I put the proxy 
>> public key. Below is my squid.conf file.
>>
>> Squid.conf
>>
>> key=/etc/squid/pctysquid2sslcerts/pctysquid2prod.pkey \ proxy ca 
>> public key??
>>
> This is proxy private key AFAIK.

Correct. It should be the proxy private key. If the public key is put in there and startup actually succeeds I'm not sure what broken runtime errors will occur - nothing good anyhow.

Also, note that cert= parameter should be configured *before* the key= parameter so Squid loads them from the right place. The very latest releases (v4+) will fail to start if the ordering is wrong, so best to prepare for that now.


I suspect that part of the problem here is what is being configured in that cert= parameter. For SSL-Bump ports in current Squid it needs to contains the self-signed *CA* certificate that Squid is using to generate other certs from, the key= being the private key of that CA cert.

If you generate a regular proxy cert and load it there (like normal proxy cert= would use) the bumping process will get all broken.


The ConfigExample page Yuri linked to earlier had the exact and full 
process to follow for setting up the multiple different certs, keys and 
file types involved with SSL-Bump.


>>
>> cert=/etc/squid/pctysquid2sslcerts/pctysquid2prod.crt \(installed 
>> certificate on IE all clients as a trusted root certificate authorities)
>>
> Yes, if it installed into clients - this is ok.
> 
> So. The only reason I can see - proxy can't see OpenSSL CA's bundle.
> 
> To make it work you should add to your squid's config one of this:
> 
> #  TAG: sslproxy_cafile
> #    file containing CA certificates to use when verifying server
> #    certificates while proxying https:// URLs
> #Default:
> # none
> 
> #  TAG: sslproxy_capath
> #    directory containing CA certificates to use when verifying
> #    server certificates while proxying https:// URLs
> #Default:
> # none

Er, those are for Squid->server connections. You were correct about the 
errors referring to client->Squid connections, so these are irrelevant.

If anything, the  cafile= parameter of the ssl-bump port might be 
needed. Then it should point at the same CA's found in the cert= 
parameter (bit weird, but that is bugs in the SSL-Bump config design).

FTR: those particular errors occur when Squid accepts a connection from 
a client, begins the TLS handshake and the client suddenly disconnects 
before the handshake is complete.
  The "certificate unknown" seems to be saying that either 1) the client 
sent a client-cert to Squid and OpenSSL did not accept it, or 2) that 
the client did not accept the auto-generated cert Squid sent.

If (1) is happening it s because the browser was not correctly 
configured with the self-signed CA public cert.

If (2) is happening, then probably the cert=, key=, cafile= parameters 
on the ssl-bump port are not configured right, OR browser was not 
correctly configured with the self-signed CA public cert.

Or, maybe bugs in that particular Squid release SSL-Bump code. We are 
constantly fixing them and 3.5.20 is now a whole year behind with 
SSL-Bump fixes - many of them rather major behaviour fixes.


==> Best Practice to follow with SSL-Bump is that when having *any* 
problems with the SSL-Bump process try the latest Squid release first 
before spending time trying to figure it out.

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users

From ncherukuri at partycity.com  Thu Jul 20 19:02:57 2017
From: ncherukuri at partycity.com (Cherukuri, Naresh)
Date: Thu, 20 Jul 2017 19:02:57 +0000
Subject: [squid-users] Squid Version 3.5.20 Any Ideas
In-Reply-To: <59772fe8-6c62-3d5d-efc1-e0e600188e8e@gmail.com>
References: <89638057A560FB458C01C197F81C7F5D13F32404@PACERS.amscan.corp>
 <e653374f-020d-c213-6a0f-12dda8ebce32@gmail.com>
 <596F973C.7040603@mathemainzel.info>
 <6bb20814-f8ce-a04a-1ee4-5aeb71bf1f9c@gmail.com>
 <89638057A560FB458C01C197F81C7F5D13F32BF9@PACERS.amscan.corp>
 <640e364a-fd61-b699-c2da-87da9eceb438@gmail.com>
 <89638057A560FB458C01C197F81C7F5D13F32CE8@PACERS.amscan.corp>
 <59772fe8-6c62-3d5d-efc1-e0e600188e8e@gmail.com>
Message-ID: <89638057A560FB458C01C197F81C7F5D13F579F1@ROCKETS.amscan.corp>

Thank you Yuri! Appreciate your help.

From: Yuri [mailto:yvoinov at gmail.com]
Sent: Wednesday, July 19, 2017 5:15 PM
To: Cherukuri, Naresh; squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid Version 3.5.20 Any Ideas




20.07.2017 3:09, Cherukuri, Naresh ?????:
Yuri,

I am new to squid I learned it through searching google. My question is I generated self-signed SSL certificates and install certificates on IE all clients. I didn?t install proxy public key. Can you tell me where  I have to put proxy public key on clients. Appreciate you help!
Ah. Based on my experience,

you require to take *public* proxy key (not private, your use keypair to setup ssl-bump configuration; do not mistake it) and install it at least into two places on client's PC:

1. Into system trusted CA storage (uses by IE/Chrome/some IM etc.)
2. Into Firefox own storage (if applicable).
3. Sometimes it is also required to setup proxy's CA public key into old JRE existing on clients. But AFAIK modern JRE uses system CA's storage and no more required this step.

Actually, this should be enough.


Thanks,
Naresh

From: Yuri [mailto:yvoinov at gmail.com]
Sent: Wednesday, July 19, 2017 5:06 PM
To: Cherukuri, Naresh; squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Squid Version 3.5.20 Any Ideas


Related OpenSSL public CA bundle - in theory it should be installed together with OpenSSL.

20.07.2017 2:49, Cherukuri, Naresh ?????:
Thanks Yuri for quick turnover!

We inly installed root certificate on all clients. We didn?t install proxy CA?s public key on clients. So you suggestion fix that we need to install both certificate and proxy ca?s public key on clients.

Thanks,
Naresh

From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Yuri
Sent: Wednesday, July 19, 2017 2:25 PM
To: squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>
Subject: Re: [squid-users] Squid Version 3.5.20 Any Ideas


One out of two. Either the Squid does not see the OpenSSL/system root CAs bundle, or the proxy CA's public key is not installed in the clients. It's all.

19.07.2017 23:30, Walter H. ?????:
Hello,

this seems not to be the problem, as the error messages are in cache.log, which is not a browser problem ...

the question: are the SSL bumped sites in intranet, which use a self signed CA cert itself, which squid doesn't know?

On 19.07.2017 17:36, Yuri wrote:

http://wiki.squid-cache.org/ConfigExamples/Intercept/SslBumpExplicit

http://i.imgur.com/A153C7A.png

19.07.2017 21:34, Cherukuri, Naresh ?????:

Hi All,



I installed Squid version 3.5.20 on RHEL 7 and generated self-signed CA certificates,  My users are complaining about certificate errors. When I looked at cache.log I see so many error messages like below. Below is my squid.conf file. Any ideas how to address below errors.






Cache.log



2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 689: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

2017/07/18 16:05:34 kid1| Error negotiating SSL connection on FD 1114: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

2017/07/18 16:05:37 kid1| Error negotiating SSL connection on FD 146: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 252: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)

2017/07/18 16:05:41 kid1| Error negotiating SSL connection on FD 36: error:14094416:SSL routines:SSL3_READ_BYTES:sslv3 alert certificate unknown (1/0)







_______________________________________________

squid-users mailing list

squid-users at lists.squid-cache.org<mailto:squid-users at lists.squid-cache.org>

http://lists.squid-cache.org/listinfo/squid-users



-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/c61d0463/attachment.htm>

From erdosain9 at gmail.com  Thu Jul 20 19:07:48 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Thu, 20 Jul 2017 12:07:48 -0700 (PDT)
Subject: [squid-users] Squid as gateway
In-Reply-To: <0ded01d2fb06$5665bf90$03313eb0$@ngtech.co.il>
References: <1499444090379-4683022.post@n4.nabble.com>
 <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
 <1499780101757-4683053.post@n4.nabble.com>
 <0ded01d2fb06$5665bf90$03313eb0$@ngtech.co.il>
Message-ID: <1500577668855-4683192.post@n4.nabble.com>

Hi, and thank you all.

Well this is the diagram.



INTERNET
+
+
FIREWALL (10.1.158.1/24)
+
+
+
SQUID (2 interfaces) 10.1.158.2/24
                                192.168.1.20/24
+
+
+
ROUTERWIFI( WAN----static ip 192.168.1.40/24 gw 192.168.1.20) LAN
192.168.0.1/24)

squid config:

acl red1 src 192.168.1.0/24

acl SSL_ports port 443
acl SSL_ports port 8443
acl SSL_ports port 8080
acl SSL_ports port 20000
acl SSL_ports port 10000
acl SSL_ports port 2083

acl Safe_ports port 631         # httpCUPS
acl Safe_ports port 85
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 8443        # httpsalt
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 8080        # edesur y otros
acl CONNECT method CONNECT


#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports
http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

http_access allow localhost
http_access allow red1

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
http_port 192.168.1.20:3128
http_port 192.168.1.20:3129 intercept

# Uncomment and adjust the following to add a disk cache directory.
cache_dir diskd /var/spool/squid 15000 16 256
cache_mem 256 MB

cache_swap_low 90
cache_swap_high 95

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid


#Your refresh_pattern
refresh_pattern -i \.jpg$ 30 0% 30 ignore-no-cache ignore-no-store
ignore-private

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320

dns_nameservers 8.8.8.8 8.8.4.4
visible_hostname squid.xxxxxxxxxx.lan

-----------------------------------------------------------------------

I probe this, nothing work..............
---------------------------------------------------------------------------------------------------------------------------------------------

iptables -t nat -A PREROUTING -s 192.168.1.20 -p tcp --dport 80 -j ACCEPT
iptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to-destination
192.168.1.20:3129
iptables -t nat -A POSTROUTING -j MASQUERADE
iptables -t mangle -A PREROUTING -p tcp --dport 3129 -j DROP 

------------------------------------------------------------------------------------------------------------------------------------------------

iptables -t nat -A PREROUTING -s 192.168.1.20 -p tcp --dport 80 -j ACCEPT
iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 3129
iptables -t nat -A POSTROUTING -j MASQUERADE
iptables -t mangle -A PREROUTING -p tcp --dport 3129 -j DROP

-----------------------------------------------------------------------------------------------------------------------------------------------

A hand....??
Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-as-gateway-tp4683022p4683192.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Thu Jul 20 19:49:43 2017
From: chip_pop at hotmail.com (joseph)
Date: Thu, 20 Jul 2017 12:49:43 -0700 (PDT)
Subject: [squid-users] Squid box for two networks
In-Reply-To: <CAEUQ6HX1qLv4nLszCDm5ckfqq+5vhug+rBE=TqR=hMmBGV6zsw@mail.gmail.com>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
 <CAEUQ6HXDfWbgRF_pUQSHCqt_ya2XiHAHq=QDhPdyDc8cE3LwsA@mail.gmail.com>
 <201707201427.10884.Antony.Stone@squid.open.source.it>
 <CAEUQ6HXteNPyUaDyB+3-eqN+Hgc9B7y8LrZmHxf4P0FHWGq8ng@mail.gmail.com>
 <031601d3017b$48d96bd0$da8c4370$@ngtech.co.il>
 <CAEUQ6HX1qLv4nLszCDm5ckfqq+5vhug+rBE=TqR=hMmBGV6zsw@mail.gmail.com>
Message-ID: <1500580183647-4683193.post@n4.nabble.com>

 you might need his configuration

/ip firewall address-list
add address=192.168.110.0/24 comment="one route port 80" list=http-route
add address=192.168.115.0/24 comment="two route port 80" list=http-route

/ip firewall mangle
add action=mark-routing chain=prerouting comment=\
    "Clients HTTP route to cache" dst-port=80 \
    new-routing-mark=http passthrough=yes protocol=tcp
src-address-list=http-route
	
/ip route
add comment="Cache route" distance=1 gateway=192.168.1.1 routing-mark=http	

using squid as gateway 
ps.... 192.168.10.1  is squid box so put yours




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-box-for-two-networks-tp4683119p4683193.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From chip_pop at hotmail.com  Thu Jul 20 20:02:19 2017
From: chip_pop at hotmail.com (joseph)
Date: Thu, 20 Jul 2017 13:02:19 -0700 (PDT)
Subject: [squid-users] Squid as gateway
In-Reply-To: <1500577668855-4683192.post@n4.nabble.com>
References: <1499444090379-4683022.post@n4.nabble.com>
 <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
 <1499780101757-4683053.post@n4.nabble.com>
 <0ded01d2fb06$5665bf90$03313eb0$@ngtech.co.il>
 <1500577668855-4683192.post@n4.nabble.com>
Message-ID: <1500580939899-4683194.post@n4.nabble.com>

>> ROUTERWIFI( WAN----static ip 192.168.1.40/24 gw 192.168.1.20) LAN
192.168.0.1/24) 
is it mikrotik or other specify pls



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-as-gateway-tp4683022p4683194.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From pablo.ruben.maldonado at gmail.com  Thu Jul 20 20:27:02 2017
From: pablo.ruben.maldonado at gmail.com (Pablo Ruben Maldonado)
Date: Thu, 20 Jul 2017 17:27:02 -0300
Subject: [squid-users] Squid box for two networks
In-Reply-To: <1500580183647-4683193.post@n4.nabble.com>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
 <CAEUQ6HXDfWbgRF_pUQSHCqt_ya2XiHAHq=QDhPdyDc8cE3LwsA@mail.gmail.com>
 <201707201427.10884.Antony.Stone@squid.open.source.it>
 <CAEUQ6HXteNPyUaDyB+3-eqN+Hgc9B7y8LrZmHxf4P0FHWGq8ng@mail.gmail.com>
 <031601d3017b$48d96bd0$da8c4370$@ngtech.co.il>
 <CAEUQ6HX1qLv4nLszCDm5ckfqq+5vhug+rBE=TqR=hMmBGV6zsw@mail.gmail.com>
 <1500580183647-4683193.post@n4.nabble.com>
Message-ID: <CAEUQ6HXpWQYaq2Yn9WPPbkUvmjjSReDMZNCA3zKU7S-=UHRk2w@mail.gmail.com>

Joseph, these lines already exists in my setup. Thanks.

Remember you what my Squid box work for my primary lan (192.168.110.0/24)
but don't work to the second lan (192.168.115.0/24)

On Thu, Jul 20, 2017 at 4:49 PM, joseph <chip_pop at hotmail.com> wrote:

>  you might need his configuration
>
> /ip firewall address-list
> add address=192.168.110.0/24 comment="one route port 80" list=http-route
> add address=192.168.115.0/24 comment="two route port 80" list=http-route
>
> /ip firewall mangle
> add action=mark-routing chain=prerouting comment=\
>     "Clients HTTP route to cache" dst-port=80 \
>     new-routing-mark=http passthrough=yes protocol=tcp
> src-address-list=http-route
>
> /ip route
> add comment="Cache route" distance=1 gateway=192.168.1.1 routing-mark=http
>
> using squid as gateway
> ps.... 192.168.10.1  is squid box so put yours
>
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.
> 1019090.n4.nabble.com/Squid-box-for-two-networks-tp4683119p4683193.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170720/2e7477d4/attachment.htm>

From eliezer at ngtech.co.il  Thu Jul 20 20:29:30 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Thu, 20 Jul 2017 23:29:30 +0300
Subject: [squid-users] Squid box for two networks
In-Reply-To: <CAEUQ6HX1qLv4nLszCDm5ckfqq+5vhug+rBE=TqR=hMmBGV6zsw@mail.gmail.com>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
 <CAEUQ6HXDfWbgRF_pUQSHCqt_ya2XiHAHq=QDhPdyDc8cE3LwsA@mail.gmail.com>
 <201707201427.10884.Antony.Stone@squid.open.source.it>
 <CAEUQ6HXteNPyUaDyB+3-eqN+Hgc9B7y8LrZmHxf4P0FHWGq8ng@mail.gmail.com>
 <031601d3017b$48d96bd0$da8c4370$@ngtech.co.il>
 <CAEUQ6HX1qLv4nLszCDm5ckfqq+5vhug+rBE=TqR=hMmBGV6zsw@mail.gmail.com>
Message-ID: <03eb01d30196$e402fe80$ac08fb80$@ngtech.co.il>

First take joseph advice.
This is the right way of doing things.
And since I have here couple MikroTik devices sitting I took one to create the same scenario that you have and the full configuration can be seen at:
http://wiki.squid-cache.org/EliezerCroitoru/Drafts/MikroTik-Route-To-Intercept-Squid

And on my site at:
http://ngtech.co.il/paste/1786/raw/

Technically since the px is on the same segment as the MikroTik it's better to accept traffic(in both the mangle and the filter tables) by the mac address of the px rather then the ip but for your case the ip should play fine with the combination of the interface which the traffic from the px flows in\at.
When it will all work for you as expected I will add this scenario with your network diagram as an example to the wiki(if it's fine with you that the project will use the diagram..).

Thanks,
Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Pablo Ruben Maldonado
Sent: Thursday, July 20, 2017 21:51
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid box for two networks

Hi Eliezer, thanks for you reply.

I'm marking and routing traffic to port 80 from my lan's http://192.168.110.0/24 (Work!) and http://192.168.115.0/24 (Fail!). The mark line in Mangle is:

add action=mark-connection chain=prerouting comment="TCP 80: Tr\E1fico HTTP de\
    sde la red WIFI. Se marca la conexi\F3n para QoS y Policy Routing. Ser\E1 \
    routeado hacia Proxy03" !connection-bytes !connection-limit \
    connection-mark=no-mark !connection-nat-state !connection-rate \
    !connection-state !connection-type !content disabled=no !dscp \
    !dst-address !dst-address-list !dst-address-type !dst-limit dst-port=80 \
    !fragment !hotspot !icmp-options !in-bridge-port in-interface=eth4-wifi \
    !ingress-priority !ipsec-policy !ipv4-options !layer7-protocol !limit \
    log=no log-prefix="" new-connection-mark=conn_proxy !nth !out-bridge-port \
    !out-interface !p2p !packet-mark !packet-size passthrough=yes \
    !per-connection-classifier !port !priority protocol=tcp !psd !random \
    !routing-mark !routing-table src-address=http://192.168.115.0/24 !src-address-list \
    !src-address-type !src-mac-address !src-port !tcp-flags !tcp-mss !time \
    !ttl

The packet mark and route lines:

add action=mark-packet chain=prerouting comment=\
    "TCP 80: Se marca el paquete para Queue Tree (Up)" !connection-bytes \
    !connection-limit connection-mark=conn_proxy !connection-nat-state \
    !connection-rate !connection-state !connection-type !content disabled=no \
    !dscp !dst-address !dst-address-list !dst-address-type !dst-limit \
    !dst-port !fragment !hotspot !icmp-options !in-bridge-port !in-interface \
    !ingress-priority !ipsec-policy !ipv4-options !layer7-protocol !limit \
    log=no log-prefix="" new-packet-mark=up_tcp_80_pkt !nth !out-bridge-port \
    !out-interface !p2p !packet-mark !packet-size passthrough=yes \
    !per-connection-classifier !port !priority !protocol !psd !random \
    !routing-mark !routing-table !src-address !src-address-list \
    !src-address-type !src-mac-address !src-port !tcp-flags !tcp-mss time=\
    0s-1d,sun,mon,tue,wed,thu,fri,sat !ttl
add action=mark-routing chain=prerouting comment=\
    "TCP 80: Se ejecuta el Policy Routing hacia Proxy03" !connection-bytes \
    !connection-limit !connection-mark !connection-nat-state !connection-rate \
    !connection-state !connection-type !content disabled=no !dscp \
    !dst-address dst-address-list=!clientslist !dst-address-type !dst-limit \
    !dst-port !fragment !hotspot !icmp-options !in-bridge-port !in-interface \
    !ingress-priority !ipsec-policy !ipv4-options !layer7-protocol !limit \
    log=no log-prefix="" new-routing-mark=route_toproxy03 !nth \
    !out-bridge-port !out-interface !p2p packet-mark=up_tcp_80_pkt \
    !packet-size passthrough=no !per-connection-classifier !port !priority \
    !protocol !psd !random !routing-mark !routing-table !src-address \
    !src-address-list !src-address-type !src-mac-address !src-port !tcp-flags \
    !tcp-mss !time !ttl

Thanks

On Thu, Jul 20, 2017 at 2:11 PM, Eliezer Croitoru <mailto:eliezer at ngtech.co.il> wrote:
Hey Pablo,

I am working as a tech support for MikroTik devices and the tcpdump dumps are leaving couple things unknown.
Can you share the MikroTik rules PBR rules you are using?
Are you using any kind of connection marking and tracking in the mix or just plain source based routing?
I am pretty sure that the issue is in the reverse path and not backwards.
If you can export your MikroTik configuration I might be able to try and help you find the right rules if these are wrong.
Also make sure that the squid box has reverse path filtering disabled using:
http://wiki.squid-cache.org/EliezerCroitoru/Drafts/MwanLB#Set_Reverse_Path_Filter_machine_globally_script

And also take a peek at:
http://wiki.squid-cache.org/ConfigExamples/UbuntuTproxy4Wccp2#Linux_and_Squid_Configuration

I planned to add into the wiki an article\tutorial how to setup squid with MikroTik since there are more than a dozen of articles\tutorials that just do not do it the right way.

Eliezer

* you can send me the configuration privately if these are sensitive

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: mailto:eliezer at ngtech.co.il


From: squid-users [mailto:mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Pablo Ruben Maldonado
Sent: Thursday, July 20, 2017 16:41
To: mailto:squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid box for two networks

The packets are routing using a mark and later routing rules inside my principal router (Mikrotik). Attach images with examples of packets arriving to Squid box.

On Thu, Jul 20, 2017 at 10:27 AM, Antony Stone <mailto:mailto:Antony.Stone at squid.open.source.it> wrote:
On Thursday 20 July 2017 at 14:08:27, Pablo Ruben Maldonado wrote:

> Hi, i add information missing in original post. Thanks for assistance:
>
> The Squid Box has setup for Intercept Mode. Iptables rules here:
>
> -A PREROUTING -p tcp -m tcp --dport 80 -j REDIRECT --to-ports 3128
> -A PREROUTING -p tcp -m tcp --dport 443 -j REDIRECT --to-ports 3129

How are you routing the packets from the firewall to Squid?

> The config paste in https://pastebin.com/Witg3cG1
>
> Thanks
>
> On Mon, Jul 17, 2017 at 5:31 PM, Pablo Ruben Maldonado <
>
> mailto:mailto:pablo.ruben.maldonado at gmail.com> wrote:
> > Hello, I have a squid box 3.5 working without problems for the lan
> > http://192.168.110.0/24 for several months. Now I want setup to another lan
> > http://192.168.115.0/24 but I cannot. Tcpdump inform me that the packages come
> > to squid box. But in Squid's log I do not see anything. Can they give me
> > some tip?

Can you give us any examples of packets as seen by tcpdump on the Squid box:

a) from http://192.168.110.0/24

b) from http://192.168.115.0/24


Antony.

--
BASIC is to computer languages what Roman numerals are to arithmetic.

                                                   Please reply to the list;
                                                         please *don't* CC me.
_______________________________________________
squid-users mailing list
mailto:mailto:squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users





From chip_pop at hotmail.com  Thu Jul 20 20:13:24 2017
From: chip_pop at hotmail.com (joseph)
Date: Thu, 20 Jul 2017 13:13:24 -0700 (PDT)
Subject: [squid-users] Squid box for two networks
In-Reply-To: <CAEUQ6HXpWQYaq2Yn9WPPbkUvmjjSReDMZNCA3zKU7S-=UHRk2w@mail.gmail.com>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
 <CAEUQ6HXDfWbgRF_pUQSHCqt_ya2XiHAHq=QDhPdyDc8cE3LwsA@mail.gmail.com>
 <201707201427.10884.Antony.Stone@squid.open.source.it>
 <CAEUQ6HXteNPyUaDyB+3-eqN+Hgc9B7y8LrZmHxf4P0FHWGq8ng@mail.gmail.com>
 <031601d3017b$48d96bd0$da8c4370$@ngtech.co.il>
 <CAEUQ6HX1qLv4nLszCDm5ckfqq+5vhug+rBE=TqR=hMmBGV6zsw@mail.gmail.com>
 <1500580183647-4683193.post@n4.nabble.com>
 <CAEUQ6HXpWQYaq2Yn9WPPbkUvmjjSReDMZNCA3zKU7S-=UHRk2w@mail.gmail.com>
Message-ID: <1500581604172-4683197.post@n4.nabble.com>

well this work almost 10 year

an u can do 2 mark if you want to   make shur u use same marking
new-routing-mark=http 
on each range 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-box-for-two-networks-tp4683119p4683197.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From eliezer at ngtech.co.il  Fri Jul 21 09:11:54 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 21 Jul 2017 12:11:54 +0300
Subject: [squid-users] Squid as gateway
In-Reply-To: <1500577668855-4683192.post@n4.nabble.com>
References: <1499444090379-4683022.post@n4.nabble.com>
 <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
 <1499780101757-4683053.post@n4.nabble.com>
 <0ded01d2fb06$5665bf90$03313eb0$@ngtech.co.il>
 <1500577668855-4683192.post@n4.nabble.com>
Message-ID: <054e01d30201$65895c00$309c1400$@ngtech.co.il>

Hey,

What you describe is possible... and is recommended for many scenarios.
You just need to take into account that what you would want is to make sure your have a static route from the squid machine to the WIFI network via the WIFI Router.
Also you should use NAT(source nat \ masquerade) on the squid box if you want other traffic then port 80 to be allowed to access the internet(DNS, ICMP etc..).
This combination of:
http://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxRedirect?highlight=%28masquerade%29

http://wiki.squid-cache.org/ConfigExamples/Intercept/LinuxDnat?highlight=%28sysctl%29#A.2Fetc.2Fsysctl.conf_Configuration

http://wiki.squid-cache.org/KnowledgeBase/TransparentProxySelectiveBypass?highlight=%28masquerade%29

might help you to get started.

What machine are you using the linux box for squid?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Thursday, July 20, 2017 22:08
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid as gateway

Hi, and thank you all.

Well this is the diagram.



INTERNET
+
+
FIREWALL (10.1.158.1/24)
+
+
+
SQUID (2 interfaces) 10.1.158.2/24
                                192.168.1.20/24
+
+
+
ROUTERWIFI( WAN----static ip 192.168.1.40/24 gw 192.168.1.20) LAN
192.168.0.1/24)

squid config:

acl red1 src 192.168.1.0/24

acl SSL_ports port 443
acl SSL_ports port 8443
acl SSL_ports port 8080
acl SSL_ports port 20000
acl SSL_ports port 10000
acl SSL_ports port 2083

acl Safe_ports port 631         # httpCUPS
acl Safe_ports port 85
acl Safe_ports port 80          # http
acl Safe_ports port 21          # ftp
acl Safe_ports port 443         # https
acl Safe_ports port 70          # gopher
acl Safe_ports port 210         # wais
acl Safe_ports port 8443        # httpsalt
acl Safe_ports port 1025-65535  # unregistered ports
acl Safe_ports port 280         # http-mgmt
acl Safe_ports port 488         # gss-http
acl Safe_ports port 591         # filemaker
acl Safe_ports port 777         # multiling http
acl Safe_ports port 8080        # edesur y otros
acl CONNECT method CONNECT


#
# Deny requests to certain unsafe ports
http_access deny !Safe_ports

# Deny CONNECT to other than secure SSL ports http_access deny CONNECT !SSL_ports

# Only allow cachemgr access from localhost http_access allow localhost manager http_access deny manager

http_access allow localhost
http_access allow red1

# And finally deny all other access to this proxy http_access deny all

# Squid normally listens to port 3128
http_port 192.168.1.20:3128
http_port 192.168.1.20:3129 intercept

# Uncomment and adjust the following to add a disk cache directory.
cache_dir diskd /var/spool/squid 15000 16 256 cache_mem 256 MB

cache_swap_low 90
cache_swap_high 95

# Leave coredumps in the first cache dir coredump_dir /var/spool/squid


#Your refresh_pattern
refresh_pattern -i \.jpg$ 30 0% 30 ignore-no-cache ignore-no-store ignore-private

#
# Add any of your own refresh_pattern entries above these.
#
refresh_pattern ^ftp:           1440    20%     10080
refresh_pattern ^gopher:        1440    0%      1440
refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
refresh_pattern .               0       20%     4320

dns_nameservers 8.8.8.8 8.8.4.4
visible_hostname squid.xxxxxxxxxx.lan

-----------------------------------------------------------------------

I probe this, nothing work..............
---------------------------------------------------------------------------------------------------------------------------------------------

iptables -t nat -A PREROUTING -s 192.168.1.20 -p tcp --dport 80 -j ACCEPT iptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to-destination
192.168.1.20:3129
iptables -t nat -A POSTROUTING -j MASQUERADE iptables -t mangle -A PREROUTING -p tcp --dport 3129 -j DROP 

------------------------------------------------------------------------------------------------------------------------------------------------

iptables -t nat -A PREROUTING -s 192.168.1.20 -p tcp --dport 80 -j ACCEPT iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 3129 iptables -t nat -A POSTROUTING -j MASQUERADE iptables -t mangle -A PREROUTING -p tcp --dport 3129 -j DROP

-----------------------------------------------------------------------------------------------------------------------------------------------

A hand....??
Thanks



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-as-gateway-tp4683022p4683192.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Fri Jul 21 13:18:52 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 22 Jul 2017 01:18:52 +1200
Subject: [squid-users] Squid as gateway
In-Reply-To: <1500577668855-4683192.post@n4.nabble.com>
References: <1499444090379-4683022.post@n4.nabble.com>
 <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
 <1499780101757-4683053.post@n4.nabble.com>
 <0ded01d2fb06$5665bf90$03313eb0$@ngtech.co.il>
 <1500577668855-4683192.post@n4.nabble.com>
Message-ID: <b0bb8266-7f7d-bd89-13b5-e1a096444653@treenet.co.nz>

On 21/07/17 07:07, erdosain9 wrote:
> Hi, and thank you all.
> 
> Well this is the diagram.
> 
> 
> 
> INTERNET
> +
> +
> FIREWALL (10.1.158.1/24)
> +
> +
> +
> SQUID (2 interfaces) 10.1.158.2/24
>                                  192.168.1.20/24

This machine called SQUID need to be configured as a router.

You mentioned the GW route for the device below, but what are the two GW 
routes (10/8 gw ??? , and 192.168/16 gw ???) this SQUID machine should have?


> +
> +
> ROUTERWIFI( WAN----static ip 192.168.1.40/24 gw 192.168.1.20) LAN
> 192.168.0.1/24)

That looks okay.

But double-check that this machine is *NOT* performing NAT on any of the 
outgoing packets sent to 192.168.1.20.


> 
> squid config:
> 
> acl red1 src 192.168.1.0/24

That permits the ROUTERWIFI machine to send traffic from itself (only) 
to Squid. Such traffic should be an extreme rarity - usually just you 
testing HTTP connectivity from that machine manually.

This Squid should be expecting to receive traffic from 192.168.0.0/24 
machines. If you do not change this I expect you will start to see 
DENIED lines being logged by Squid when you fix the packet arrival problem.


> 
> acl SSL_ports port 443
> acl SSL_ports port 8443
> acl SSL_ports port 8080
> acl SSL_ports port 20000
> acl SSL_ports port 10000
> acl SSL_ports port 2083
> 
> acl Safe_ports port 631         # httpCUPS
> acl Safe_ports port 85
> acl Safe_ports port 80          # http
> acl Safe_ports port 21          # ftp
> acl Safe_ports port 443         # https
> acl Safe_ports port 70          # gopher
> acl Safe_ports port 210         # wais
> acl Safe_ports port 8443        # httpsalt
> acl Safe_ports port 1025-65535  # unregistered ports
> acl Safe_ports port 280         # http-mgmt
> acl Safe_ports port 488         # gss-http
> acl Safe_ports port 591         # filemaker
> acl Safe_ports port 777         # multiling http
> acl Safe_ports port 8080        # edesur y otros

NP: those 8080 and 8443 are included in the 1025-65535 entry above.

> #
> # Deny requests to certain unsafe ports
> http_access deny !Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> http_access deny CONNECT !SSL_ports
> 
> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
> 
> http_access allow localhost
> http_access allow red1
> 
> # And finally deny all other access to this proxy
> http_access deny all
> 
> # Squid normally listens to port 3128
> http_port 192.168.1.20:3128
> http_port 192.168.1.20:3129 intercept

You should not have to specify any IP address here.
eg.
   http_port 3128
   http_port 3129 intercept

Squid will then be able to receive the NAT'd traffic no matter what 
system NAT rules contain.


> 
...
> #Your refresh_pattern
> refresh_pattern -i \.jpg$ 30 0% 30 ignore-no-cache ignore-no-store
> ignore-private

NP: ignore-no-cache is no longer existing.

SECURITY WARNING: using ignore-no-store for images will cache Captcha 
images, user avatar icons, personal content from private accounts (think 
snapchat and facebook photos type of stuff).
  ignore-private is not so bad in the latest Squid releases as it used 
to be, but it will not cause much of a HIT ratio increase over default 
behaviour either.


> 
> #
> # Add any of your own refresh_pattern entries above these.
> #
> refresh_pattern ^ftp:           1440    20%     10080
> refresh_pattern ^gopher:        1440    0%      1440
> refresh_pattern -i (/cgi-bin/|\?) 0     0%      0
> refresh_pattern .               0       20%     4320
> 
> dns_nameservers 8.8.8.8 8.8.4.4

Use of 8.8.8.8 and 8.8.4.4 in a Squid which is intercepting traffic 
causes a lot of problems - mostly in the form of "Host verify" security 
alerts and major reduction in HTTP traffic caching.

To work around those problems you need a local DNS server which both 
your client machines and Squid use for recursive resolving. That DNS 
server can use 8.8.8.8 and 8.8.4.4 as its upstream forwarders if you 
actually still need it - having your own local resolver pretty much 
obsoletes all the benefits 8.8.8.8 claim to provide.


> 
> -----------------------------------------------------------------------
> 
> I probe this, nothing work..............
> ---------------------------------------------------------------------------------------------------------------------------------------------
> 
> iptables -t nat -A PREROUTING -s 192.168.1.20 -p tcp --dport 80 -j ACCEPT
> iptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to-destination
> 192.168.1.20:3129
> iptables -t nat -A POSTROUTING -j MASQUERADE
> iptables -t mangle -A PREROUTING -p tcp --dport 3129 -j DROP
> 
> ------------------------------------------------------------------------------------------------------------------------------------------------
> 
> iptables -t nat -A PREROUTING -s 192.168.1.20 -p tcp --dport 80 -j ACCEPT
> iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 3129
> iptables -t nat -A POSTROUTING -j MASQUERADE
> iptables -t mangle -A PREROUTING -p tcp --dport 3129 -j DROP
> 
> -----------------------------------------------------------------------------------------------------------------------------------------------
> 

Both of those look fine for the NAT rules on SQUID box - they only do 
the NAT part, not any of the packet routing.

The problem I think is in the routing setup on the SQUID machine, and 
maybe the ROUTERWIFI.

Amos


From erdosain9 at gmail.com  Fri Jul 21 14:18:50 2017
From: erdosain9 at gmail.com (erdosain9)
Date: Fri, 21 Jul 2017 07:18:50 -0700 (PDT)
Subject: [squid-users] Squid as gateway
In-Reply-To: <b0bb8266-7f7d-bd89-13b5-e1a096444653@treenet.co.nz>
References: <1499444090379-4683022.post@n4.nabble.com>
 <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
 <1499780101757-4683053.post@n4.nabble.com>
 <0ded01d2fb06$5665bf90$03313eb0$@ngtech.co.il>
 <1500577668855-4683192.post@n4.nabble.com>
 <b0bb8266-7f7d-bd89-13b5-e1a096444653@treenet.co.nz>
Message-ID: <1500646730708-4683200.post@n4.nabble.com>

Hi, and thanks

The ROUTERWIFI is a TpLink TL-WR940N.... i dont see in this router any Nat
option :-(

This is the router table of the SquidBox

Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use
Iface
0.0.0.0         10.1.158.1      0.0.0.0         UG    0      0        0
ens192
10.1.158.0      0.0.0.0         255.255.255.0   U     0      0        0
ens192
169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0
ens160
169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0
ens192
192.168.0.0     192.168.1.40    255.255.255.0   UG    0      0        0
ens160
192.168.1.0     0.0.0.0         255.255.255.0   U     0      0        0
ens160
192.168.2.0     192.168.1.1     255.255.255.0   UG    0      0        0
ens160
192.168.6.0     192.168.1.1     255.255.255.0   UG    0      0        0
ens160

If i enable ipv4 forwarding in SquidBox, the clients of the ROUTERWIFI can
access internet, so i think the router table it's ok.... the clients can go
to internet but just because ipv4 forwarding is enable (the squid service is
not getting anything, i dont see nothing in the access.log...) if i disable
ipv4 forwarding the clients dont go anyway.

This is iptables

[root at squid ~]# iptables -nvL -t nat
Chain PREROUTING (policy ACCEPT 383 packets, 42336 bytes)
 pkts bytes target     prot opt in     out     source              
destination         
    0     0 ACCEPT     tcp  --  *      *       192.168.1.20       0.0.0.0/0           
tcp dpt:80
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0           
0.0.0.0/0            tcp dpt:80 to:192.168.1.20:3129

Chain INPUT (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source              
destination         

Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source              
destination         

Chain POSTROUTING (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source              
destination         
    0     0 MASQUERADE  all  --  *      *       0.0.0.0/0           
0.0.0.0/0 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-as-gateway-tp4683022p4683200.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Fri Jul 21 16:01:17 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 22 Jul 2017 04:01:17 +1200
Subject: [squid-users] Squid as gateway
In-Reply-To: <1500646730708-4683200.post@n4.nabble.com>
References: <1499444090379-4683022.post@n4.nabble.com>
 <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
 <1499780101757-4683053.post@n4.nabble.com>
 <0ded01d2fb06$5665bf90$03313eb0$@ngtech.co.il>
 <1500577668855-4683192.post@n4.nabble.com>
 <b0bb8266-7f7d-bd89-13b5-e1a096444653@treenet.co.nz>
 <1500646730708-4683200.post@n4.nabble.com>
Message-ID: <bfae5f8f-6ffb-f0b9-ee15-5d136b0ea3b7@treenet.co.nz>

On 22/07/17 02:18, erdosain9 wrote:
> Hi, and thanks
> 
> The ROUTERWIFI is a TpLink TL-WR940N.... i dont see in this router any Nat
> option :-(
> 
> This is the router table of the SquidBox
> 
> Kernel IP routing table
> Destination     Gateway         Genmask         Flags Metric Ref    Use
> Iface
> 0.0.0.0         10.1.158.1      0.0.0.0         UG    0      0        0
> ens192
> 10.1.158.0      0.0.0.0         255.255.255.0   U     0      0        0
> ens192
> 169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0
> ens160
> 169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0
> ens192
> 192.168.0.0     192.168.1.40    255.255.255.0   UG    0      0        0
> ens160
> 192.168.1.0     0.0.0.0         255.255.255.0   U     0      0        0
> ens160
> 192.168.2.0     192.168.1.1     255.255.255.0   UG    0      0        0
> ens160
> 192.168.6.0     192.168.1.1     255.255.255.0   UG    0      0        0
> ens160

That seems okay. Assuming that 192.168.1.1 is reachable through 
192.168.1.40 - but they should be irrelevant for the 192.168.0.0/24 
clients even if broken.

> 
> If i enable ipv4 forwarding in SquidBox, the clients of the ROUTERWIFI can
> access internet, so i think the router table it's ok.... the clients can go
> to internet but just because ipv4 forwarding is enable (the squid service is
> not getting anything, i dont see nothing in the access.log...) if i disable
> ipv4 forwarding the clients dont go anyway.

What setting exactly are you changing for this "ipv4 forwarding" 
enable/disable?

Clients should be fully able to access and use the Internet / WAN 
connectivity _through_ the machine called SQUID in your network when the 
NAT rules from the Squid wiki config example are omitted.

One thing we have not mentioned AFAIK, is that the FIREWALL machine 
needs to have 192.168.0.0/16 gw 192.168.1.20 as its LAN gateway setting 
to pass the Internet response traffic back through SQUID machine.


Amos


From eliezer at ngtech.co.il  Fri Jul 21 16:04:03 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Fri, 21 Jul 2017 19:04:03 +0300
Subject: [squid-users] Squid as gateway
In-Reply-To: <1500646730708-4683200.post@n4.nabble.com>
References: <1499444090379-4683022.post@n4.nabble.com>
 <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
 <1499780101757-4683053.post@n4.nabble.com>
 <0ded01d2fb06$5665bf90$03313eb0$@ngtech.co.il>
 <1500577668855-4683192.post@n4.nabble.com>
 <b0bb8266-7f7d-bd89-13b5-e1a096444653@treenet.co.nz>
 <1500646730708-4683200.post@n4.nabble.com>
Message-ID: <06df01d3023a$f91ea450$eb5becf0$@ngtech.co.il>

Hey,

Let's split the scenario into two different issues.
- interception
- routing

Since the squidbox is a router you need to first enable it to be a router and also to do NAT for DNS and other services to work.
Means that the MASQUARADE rule is fine but you should limit it only to the specific outgoing interface of the WAN side ie: ens192

And you should define the right iptables rules of the intercept ie:
This is wrong:
pkts bytes target     prot opt in     out     source              
destination         
    0     0 ACCEPT     tcp  --  *      *       192.168.1.20       0.0.0.0/0           
tcp dpt:80
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0           
0.0.0.0/0            tcp dpt:80 to:192.168.1.20:3129


Please post using a send the complete "iptables-save"
So I would be able to see what I'm suspecting.
Technically what you shoul have in the nat table is the next rule:
iptables -t nat -A PREROUTING -I ens192 -p tcp --dport 80 -j REDIRECT --to-port 3129

Then you can try to see using " watch -d iptables -t nat -L -nv" if the rules are being "hit" by the counter.
If the rule doesn't catch the traffic it should be accounted at the POLICY ACCEPT rule.

Let me know if it helps,
Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of erdosain9
Sent: Friday, July 21, 2017 17:19
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] Squid as gateway

Hi, and thanks

The ROUTERWIFI is a TpLink TL-WR940N.... i dont see in this router any Nat
option :-(

This is the router table of the SquidBox

Kernel IP routing table
Destination     Gateway         Genmask         Flags Metric Ref    Use
Iface
0.0.0.0         10.1.158.1      0.0.0.0         UG    0      0        0
ens192
10.1.158.0      0.0.0.0         255.255.255.0   U     0      0        0
ens192
169.254.0.0     0.0.0.0         255.255.0.0     U     1002   0        0
ens160
169.254.0.0     0.0.0.0         255.255.0.0     U     1003   0        0
ens192
192.168.0.0     192.168.1.40    255.255.255.0   UG    0      0        0
ens160
192.168.1.0     0.0.0.0         255.255.255.0   U     0      0        0
ens160
192.168.2.0     192.168.1.1     255.255.255.0   UG    0      0        0
ens160
192.168.6.0     192.168.1.1     255.255.255.0   UG    0      0        0
ens160

If i enable ipv4 forwarding in SquidBox, the clients of the ROUTERWIFI can
access internet, so i think the router table it's ok.... the clients can go
to internet but just because ipv4 forwarding is enable (the squid service is
not getting anything, i dont see nothing in the access.log...) if i disable
ipv4 forwarding the clients dont go anyway.

This is iptables

[root at squid ~]# iptables -nvL -t nat
Chain PREROUTING (policy ACCEPT 383 packets, 42336 bytes)
 pkts bytes target     prot opt in     out     source              
destination         
    0     0 ACCEPT     tcp  --  *      *       192.168.1.20       0.0.0.0/0           
tcp dpt:80
    0     0 DNAT       tcp  --  *      *       0.0.0.0/0           
0.0.0.0/0            tcp dpt:80 to:192.168.1.20:3129

Chain INPUT (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source              
destination         

Chain OUTPUT (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source              
destination         

Chain POSTROUTING (policy ACCEPT 0 packets, 0 bytes)
 pkts bytes target     prot opt in     out     source              
destination         
    0     0 MASQUERADE  all  --  *      *       0.0.0.0/0           
0.0.0.0/0 



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Squid-as-gateway-tp4683022p4683200.html
Sent from the Squid - Users mailing list archive at Nabble.com.
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Fri Jul 21 16:09:45 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Sat, 22 Jul 2017 04:09:45 +1200
Subject: [squid-users] Squid as gateway
In-Reply-To: <1500646730708-4683200.post@n4.nabble.com>
References: <1499444090379-4683022.post@n4.nabble.com>
 <1bb12674-d335-5052-8721-4e3aed1525e2@treenet.co.nz>
 <1499780101757-4683053.post@n4.nabble.com>
 <0ded01d2fb06$5665bf90$03313eb0$@ngtech.co.il>
 <1500577668855-4683192.post@n4.nabble.com>
 <b0bb8266-7f7d-bd89-13b5-e1a096444653@treenet.co.nz>
 <1500646730708-4683200.post@n4.nabble.com>
Message-ID: <7ddb02f2-b859-6777-d8f0-91587080bd01@treenet.co.nz>

On 22/07/17 02:18, erdosain9 wrote:
> Hi, and thanks
> 
> The ROUTERWIFI is a TpLink TL-WR940N.... i dont see in this router any Nat
> option :-(
> 

Ah. Home router. These devices usually have things vastly simplified so 
they don't get screwed up by non-technical users. If you have been using 
what the GUI there calls "IP Forwarding" with a tickbox - that is NAT :-(.

I highly recommend having two physical NIC on the SQUID machine when 
home routers/modems are involved; one plugged into that router and the 
other plugged into the FIREWALL machine. So there is no possible way any 
packets can end up going straight between ROUTERWIFI and FIREWALL 
machines. That avoids a huge amount of trouble fiddling with the home 
routers UI getting DMZ setups working.


Amos


From pablo.ruben.maldonado at gmail.com  Fri Jul 21 20:04:24 2017
From: pablo.ruben.maldonado at gmail.com (Pablo Ruben Maldonado)
Date: Fri, 21 Jul 2017 17:04:24 -0300
Subject: [squid-users] Squid box for two networks
In-Reply-To: <1500581604172-4683197.post@n4.nabble.com>
References: <CAEUQ6HV+VcreJ+bcsUQQmFaWcZJtJYiC816Bid8Mw1a1hJEAuQ@mail.gmail.com>
 <CAEUQ6HXDfWbgRF_pUQSHCqt_ya2XiHAHq=QDhPdyDc8cE3LwsA@mail.gmail.com>
 <201707201427.10884.Antony.Stone@squid.open.source.it>
 <CAEUQ6HXteNPyUaDyB+3-eqN+Hgc9B7y8LrZmHxf4P0FHWGq8ng@mail.gmail.com>
 <031601d3017b$48d96bd0$da8c4370$@ngtech.co.il>
 <CAEUQ6HX1qLv4nLszCDm5ckfqq+5vhug+rBE=TqR=hMmBGV6zsw@mail.gmail.com>
 <1500580183647-4683193.post@n4.nabble.com>
 <CAEUQ6HXpWQYaq2Yn9WPPbkUvmjjSReDMZNCA3zKU7S-=UHRk2w@mail.gmail.com>
 <1500581604172-4683197.post@n4.nabble.com>
Message-ID: <CAEUQ6HWOMZeaF+nBU78FApLyMSw2_h5SCu2fv77XTJbdUO79cQ@mail.gmail.com>

Thanks to all for your help.

Eliezer, certainly that can use my graph.

I could confirm that my problem is in rules mark connection and mark packet
that i use to stop the big downloads across the port 80. But this it is my
problem. Even I have it pending.

On Thu, Jul 20, 2017 at 5:13 PM, joseph <chip_pop at hotmail.com> wrote:

> well this work almost 10 year
>
> an u can do 2 mark if you want to   make shur u use same marking
> new-routing-mark=http
> on each range
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.
> 1019090.n4.nabble.com/Squid-box-for-two-networks-tp4683119p4683197.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170721/0be870d3/attachment.htm>

From eliezer at ngtech.co.il  Sat Jul 22 21:17:27 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 23 Jul 2017 00:17:27 +0300
Subject: [squid-users] What would be the maximum ufs\aufs cache_dir
	objects?
In-Reply-To: <e0bcf3db-4da7-cb6e-8ae6-969e092d57e0@treenet.co.nz>
References: <06f501d2fc9d$f39292a0$dab7b7e0$@ngtech.co.il>
 <e0d12d09-4d0e-3ea9-d442-e14163a5d271@treenet.co.nz>
 <d08145b1-6c4c-0b1e-26b3-78559563f4ed@measurement-factory.com>
 <0e4e01d2ff22$e99f5530$bcddff90$@ngtech.co.il>
 <e0bcf3db-4da7-cb6e-8ae6-969e092d57e0@treenet.co.nz>
Message-ID: <095601d3032f$ebeab490$c3c01db0$@ngtech.co.il>

OK so time for a response!

I want to first describe the different "cache" models which are similar to real world scenarios.
The first and basic example would be the local small "Store" which is supplying food or basic things you need like work tools such as a screw driver and many other small things for basic house maintenance.
In these type of stores you have "on-demand"  order which is separated into the "fast" or the "slow" supply time.
And compared to these there is the "Warehouse" or some big place which in some cases just supply what they "have" or "sell" like ikea or similar brands.
And of-course in the world of workshops it's everything "on-demand" and almost nothing is on the shelf while these supply their services for almost anyone they also store basic standard materials which can be used for each order.

In the world of proxies we have a "storage" system but it's not 100% similar to any of the real world scenarios of "storage" in stores.
For this reason it's hard to just pick a specific model like "LRU" which local food stores uses most of the time but with a "pre-fetch" flavour.

For a cache admin there are couple things to think about before implementing any cache:
- purpose
- available resources(bandwidth, storage space, etc...)
- funding for the system\project

So for example some admins just try blindly to force the usage of caching on their clients while they harm themselves and their clients(what squid 3.3+ fixed).
They just don't get it that the only time when you want to cache is when you need it and not when you want it.
If you have limited amount of bandwidth and your clients knows it but blindly "steal" the whole line from others forcibly the real measures to enforce the bandwidth policy is not using a cache but by a QOS system.
There are solutions which can help admins to give their clients the best Internet experience.
I know that on some ships for example that have expensive Satellite Internet links you pay per MB and Windows 10 updates download are out of the question and Microsoft sites and updates should be blocked by default and should only be allowed for specific major bug fixes cases.
For places which have lots of users but limited bandwidth, cache might not be the right solution for every scenario and you(admin) need a bandwidth policy rather than a cache.
A cache is something I can call "luxury" and it only an enhancement of a network.
In today Internet there is so much content out there that we actually need to kind "limit" our usage and consumption to something reasonable compared to our environment.
With all my desire to watch some YouTube video in 720p HD or 1080p HD it's not the right choice if someone else in my network needs to use the Internet link for medical related things.

With all the above in mind I believe that the Squid way of doing things is good and fit for most of the harshest environments and 3.5 does good job restricting the admin from caching what is dangerous to be cached.
This is one of the things I consider in squid as Stable!

And now related to the statement "cache only public" is divided into two types:
- Everything that worth caching and is permitted by law and will not do harm
- Caching what is required to be cached

For example: Why should I cache a 13KB object if I have a 10Gbit line to the WAN?

>From my experience with caching there is no "general" solution and the job of a cache admin should be a task that can take time to tune the system for the right purpose.
For example if squid will cache every new object there is an option that the clients way of using the internet will fill up the disk and then will start a cycle of cache cleanup and population that will never end and there will be a circular situation of an "egg and a chicken" and the cache will never even serve one hit because of the admin tries to "catch all".

So now cache public objects might take another thing than "CC =~ public" and the successor of the tiny technical term will become a "smarter" one that defines "public" to what is really should be cached and that have a chance to being re-fetched and re-downloaded more than once and will not cause the cache to cycle around and just write+cleanup over and over again.

Squid currently does "things"(analyses requests and responses and populates the cache) on-the-fly and gives the users a very "Active"' part in the population of the cache..
So the admin have the means to control the cache server and how much the users have influence but most of these I know tend to just spin a cache instance and maybe google for couple useless "refresh_pattern" and then use them, causing this endless loop of store..cleanup...

Squid is a great  product but the combination of:
- Greed
- Lust
- Pressure 
- Budget
- Lack of experience
- Laziness

Leads cache systems around the world to less effective than they would have been with a bit more effort to understand the subject practically.

You have asked about "later"  and the definition is admin dependent.
Of-course that for a costly links such as Satellite later might not be cheaper.. but it can be effective.
Depends on the scenario later would be the right way of doing things while in many other cases it might not and the cache admin needs to do some digging understand what he does.
A cache is actually  a shelf product and if you need something that will work "in-line" ie both transparent and "on-the-fly" and "user-driven" it might be a good idea to pay on it to somebody that can give results.
As was mentioned here(list) in the past, when you calculate the hours of a sysadmin compared to a ready to use product there are scenarios which a working product is the better choice from all the aspects that was mentioned up here in this email.

I am pretty sure I understand why squid timing for the download is working as it is...( I am working in a big ISP after all, one of the top 10 in the whole area).
But I want to clear out that I don't want to invent a wheel but to give response to some specific cases which I already do.
For example the MS updates caching proxy will not work for other domains that these of ms updates.
Also I just want to mention that MS updates has a very remarkable way of making sure that the client will receive the file and insure it's integrity, MS deserve a big respect for their way of implementing the CIA!!!
(Despite to the fact that many describe why and how much they dislike MS)

Indeed G has more than one server farms that helps with "harvesting, rendering, analyzing, categorizing etc" which many doesn't have and I claim that for specific targeted things I can offer a free solutions that might help many ISP's that are already using squid.
Also I believe that offering video tutorials from a Squid Developer might help cache admins to understand how to tune their systems without creating this "cycle" I mentioned earlier.
(I do intent to release couple tutorials and I would like to get recommendations for some key points that needs to be said)

About the mentioned cons\attacks that the server would be vulnerable to...
The service I am offering would work with squid as an ICAP service and it will not download just any request over and over again.
Also it's good you mentioned these specific attacks pattern because the solution should eventually be integrated with squid logs analysis to find out how many unique requests have been made for a specific url\object and it will help to mitigate some of these attacks.

I do like the read ahead gap and I liked the concept but we are talking about couple things eventually:
- Understand the scenario and the requirements from the cache
- Limit the cache "Scope"
- Allow an object to be fetched only once and based on statistics.
- Allow squid to cache what it can and the ICAP service will act as an "Addon" for squid helping the admin with specific scenarios like MS updates, YouTube, Vimeo and couple other sites of interest.

Currently squid cannot use AUFS\UFS cache_dir for SMP and the cache store system I wrote utilizes the FS and has the option to choose between hashing algorithm like instead of MD5 such as SHA256\512..
I believe that it's a time that we start to think about more then MD5 ie SHA256 and maybe make it configurable as we talked a year or more ago.(I cannot do this and I do not have a funder for this..)

And just to grasp the differences, the caching service I am running for MS updates utilizes less CPU, balance the CPU and get very high number of cache HIT's and throughput.

@bold@ My solutions are act as addons to Squid and not replacing it.. at bold@
So if squid is vulnerable to something it will be hit before my service.

Currently I am just finishing a solution for YouTube local Store for public videos only.
It consists of couple modules:
- Queue and fetch system
- Storage system (NFS)
- Web Server(Apache, PHP)
- Object storage server
- Squid traffic analysis utilities
- External acl helper that will help to redirect traffic from the YouTube Page into the locally cached version( will have an option to bypass the cached version)

I indeed wrote some things from scratch but the concept was there for a very long time and was built over time.
>From my testing MS updates are a pain in the neck in the last few years but I have seen improvement with them.
I noticed that Akamai services are sometimes broken and MS systems tends to start fetching the object form Akamai and then starts to stream it directly from a MS farm directly so....
CDN are nice but if you implement then in the wrong way the can "block" the traffic.
This specific issue I have seen with MS updates spanned over couple countries and I didn't managed to contact any of Akamai personal sing the public emails contacts for a while..
So they just don't get paid from MS due to their lack of effort to make their service one level up.

I hope that couple things were cleared out.
If you have any more comments I'm here for them.

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il



-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Wednesday, July 19, 2017 16:38
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] What would be the maximum ufs\aufs cache_dir objects?

On 18/07/17 05:34, Eliezer Croitoru wrote:
> So basically from I understand the limit of the AUFS\UFS cache_dir is at:
> 16,777,215 Objects.
> So for a very loaded system it might be pretty "small".
> 
> I have asked since:
> I have seen the mongodb ecap adapter that stores chunks and I didn't liked it.
> In the other way I wrote a cache_dir in GoLang which I am using for the windows updates caching proxy and for now it's surpassing the AUFS\UFS limits.
> 
> Based on the success of the Windows Updates Cache proxy which strives to cache only public objects, I was thinking about writing something similar for a more global usage.
> The basic constrain on what would be cached is only If the object has Cache-Control "public".

You would end up with only a small sub-set of HTTP every being cached.

CC:public's main reason for existence is to re-enable cacheability of 
responses that contain security credentials - which is prevented by 
default as a security fail-safe.

I know a fair number of servers still send it when they should not. But 
that is declining as content gets absorbed by CDN who take more care 
with their bandwidth expenditure.



> The first step would be an ICAP service (respmod) which will log requests and response and will decide what GET results are worthy of later fetch.
> Squid currently does things on-the-fly while the client transaction is fetched by the client.

What things are you speaking about here?

How do you define "later"? is that 1 nanosecond or 64 years?
  and what makes 1 nanosecond difference in request timing for a 6GB 
object any less costly than 1 second?

Most of what Squid does and the timing of it have good reasons behind 
them. Not saying change is bad, but to make real improvements instead of 
re-inventing some long lost wheel design one has to know those reasons 
to avoid them becoming problems.
  eg. the often laughed at square wheel is a real and useful design for 
some circumstances. And their lesser bretheren cogwheels and the like 
are an age proven design in rail history for places where roundness 
actively inhibits movement.


> For an effective cache I believe we can compromise on another approach which relays or statistics.
> The first rule is: Not everything worth caching!!!
> Then after understanding and configuring this we can move on to fetch *Public* only objects when they get a high repeated downloads.
> This is actually how google cache and other similar cache systems work.
> They first let traffic reach the "DB" or "DATASTORE" if it's the first time seen.

FYI: that is the model Squid is trying to move away from - because it 
slows down traffic processing. As far as I'm aware G has a farm of 
servers to throw at any task - unlike most sysadmin trying to stand up a 
cache.


> Then after more the a specific threshold they object is being fetched by the cache system without any connection to the transaction which the clients consume.

Introducing the slow-loris attack.

It has several variants:
1) client sends a request, very , very, ... very slowly. many thousands 
of bots all do this at once, or building up over time.
   -> an unwary server gets crushed under the weight of open TCP 
sockets, and its normal clients get pushed out into DoS.

2) client sends a request. then ACK's delivery, very, very, ... very slowly.
   -> an unwary server gets crushed under the weight of open TCP 
sockets, and its normal clients get pushed out into DoS. AND suffers for 
each byte of bandwidth it spent fetching content for that client.

3) both of the above.

The slower a server is at detecting this attack the more damage can be 
done. This is magnified by whatever amount of resource expenditure the 
server goes to before detection can kick in - RAM, disk I/O, CPU time, 
TCP sockets, and of most relevant here: upstream bandwidth.

Also, Loris and clients on old tech like 6K modems or worse are 
indistinguishable.

To help resolve this problem Squid does the _opposite_ to what you 
propose above. It makes the client delivery and the server fetch align 
to avoid mistakes detecting these attacks and disconnecting legitimate 
clients.
  The read_ahead_gap directive configures the threshold amount of server 
fetch which can be done at full server-connection speed before slowing 
down to client speed. The various I/O timeouts can be tuned to what a 
sysadmin knows about their clients expected I/O capabilities.


> It might not be the most effective caching "method" for specific very loaded systems or specific big files and *very* high cost up-stream connections but for many it will be fine.
> And the actual logic and implementation can be each of couple algorithms like LRU as the default and couple others as an option.
> 
> I believe that this logic will be good for specific systems and will remove all sort of weird store\cache_dir limitations.

Which weird limitations are you referring to?

The limits you started this thread about are caused directly by the size 
of a specific integer representation and the mathematical properties 
inherent in a hashing algorithm.

Those types of limit can be eliminated or changed in the relevant code 
without redesigning how HTTP protocol caching behaves.


Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From leiwen14 at gmail.com  Tue Jul 25 22:56:32 2017
From: leiwen14 at gmail.com (Lei Wen)
Date: Tue, 25 Jul 2017 15:56:32 -0700
Subject: [squid-users] How to tell HTTPS traffic is using cache from
 access.log in 3.5.x when using ssl_bump
Message-ID: <CAPu9cN6omb+m8JMsNmJtSRD8z-oPRSRm1cSWo5YHNG0LbU4J4A@mail.gmail.com>

Hi,



I am setting up a transparent proxy that is doing whitelist work, and at
the same time, doing the cache work.


The whitelist works fine, HTTP cache verifed work cause I see TCP_MEM_HIT
using this squid.conf, but don't see any HTTPS MEM HIT related log, every
time seems a new connection.


For HTTPS traffic, I am getting TCP_TUNNEL/200 all the time, the question
is, how can I tell that a HTTPS traffic is actually using cache, or in this
case, it's not using cache at all for HTTPS. I am using forward-proxy port
in cache_peer.


I understand that there is logformat to make access.log show hostname
instead of ip, but this should not effect the MEM HIT log, right?



Meanwhile, I am also trying to setup the sibling cache cluster, not sure if
this related to HTTPS cache, I am also getting TCP_DENIED/403
for squid-internal-dynamic/netdb - HIER_NONE/- text/html. I do see sibling
hit for HTTP site.




Here is my squid version:

Squid Cache: Version 3.5.25

Service Name: squid

configure options:  '--prefix=/usr' '--includedir=/include'
'--mandir=/share/man' '--infodir=/share/info' '--sysconfdir=/etc'
'--localstatedir=/var' '--libexecdir=/lib/squid3' '--srcdir=.'
'--without-libcap' '--sysconfdir=/etc/squid3' '--mandir=/usr/share/man'
'--enable-inline' '--enable-async-io' '--enable-icmp'
'--enable-useragent-log' '--enable-snmp' '--enable-cache-digests'
'--enable-follow-x-forwarded-for' '--enable-storeio=aufs'
'--enable-removal-policies=heap,lru' '--with-maxfd=16384' '--enable-poll'
'--disable-ident-lookups' '--with-openssl' '--enable-ssl-crtd'
'--with-default-user=proxy' '--with-swapdir=/var/spool/squid3'
'--with-logdir=/var/log/squid3' '--with-pidfile=/var/run/squid3.pid'
'--enable-linux-netfilter'



And my squid.conf

# Squid normally listens to port 3128

http_port 3130


http_port 3128 intercept

acl allowed_http_sites dstdomain "/etc/squid3/whitelist.txt"

http_access allow allowed_http_sites


https_port 3129 cert=/etc/squid3/squid.crt key=/etc/squid3/squid.key
ssl-bump intercept generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB

acl SSL_port port 443

http_access allow SSL_port

acl allowed_https_sites ssl::server_name "/etc/squid3/ssl_sites.txt"



#sslcrtd_program /usr/local/squid/libexec/ssl_crtd -s /var/lib/ssl_db -M 4MB

sslcrtd_program /lib/squid3/ssl_crtd -s /var/lib/ssl_db -M 4MB



acl step1 at_step SslBump1

acl step2 at_step SslBump2

acl step3 at_step SslBump3

ssl_bump peek step1 all

ssl_bump peek step2 allowed_https_sites

ssl_bump splice step3 allowed_https_sites

ssl_bump terminate step2 all


acl container_net src 172.18.0.0/24

tcp_outgoing_address 10.0.8.41 container_net

udp_outgoing_address 10.0.8.41 container_net

http_access allow container_net


icp_port 3131

icp_access allow all

#never_direct allow all

cache_peer 10.0.8.48 sibling 3128 3131 proxy-only

#cache_peer_access 10.0.8.48 allow all



# Uncomment and adjust the following to add a disk cache directory.

hosts_file /etc/hosts

cache_replacement_policy heap LFUDA


cache_dir aufs /var/spool/squid3 4000 16 256

log_icp_queries off


# Leave coredumps in the first cache dir

coredump_dir /var/spool/squid3


#refresh_pattern ^https://.*\.raw.githubusercontent\.com/ 120000 100% 43200

refresh_pattern .               12000       90%     43200


http_access deny all




Thanks,

Lei
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170725/70f635df/attachment.htm>

From bear410hk at gmail.com  Wed Jul 26 01:49:44 2017
From: bear410hk at gmail.com (Alex Tang)
Date: Wed, 26 Jul 2017 09:49:44 +0800
Subject: [squid-users] Delay_pools problem in Squid 3.5.20
Message-ID: <CAESqrS7+DTb6mvJgn2yv95yeBD64ZhHZ8sBwJCdc43Fp3bSaLg@mail.gmail.com>

Dear All,

I had installed a squid 3.5.20 on Centos7. I'm also setting up a
delay_pools and cache_peer function on this squid server .

but I don't know why delay_pools function not working now. before I tested
is OK and I can limit user download less then 512 kb. but now, all user
download is over 512kb and can't control. I tried reboot the squid or use
the other delay_pools command to try to test which part has problem to
cause the delay_pools problem. I've checked my config file seem OK (this is
my first time to install and use squid proxy server) , would you mind tell
me is it my config problem or squid bug (maybe)

here is my full config file.

====================================================
#
# Recommended minimum configuration:
#

# Example rule allowing access from your local networks.
# Adapt to list your (internal) IP networks from where browsing
# should be allowed
acl localnet src 10.0.0.0/8 # RFC1918 possible internal network
acl localnet src 111.11.0.0/12 # RFC1918 possible internal network
acl localnet src 11.123.0.0/16 # RFC1918 possible internal network
acl localnet src fc00::/7       # RFC 4193 local private network range
acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged)
machines

acl SSL_ports port 443 563
acl Safe_ports port 80 # http
acl Safe_ports port 21 # ftp
#acl Safe_ports port 443 # https
acl Safe_ports port 70 # gopher
acl Safe_ports port 210 # wais
#acl Safe_ports port 1025-65535 # unregistered ports
acl Safe_ports port 280 # http-mgmt
acl Safe_ports port 488 # gss-http
acl Safe_ports port 591 # filemaker
acl Safe_ports port 777 # multiling http
#acl CONNECT method CONNECT



#
# Recommended minimum Access Permission configuration:
#
# Deny requests to certain unsafe ports
#http_access allow !Safe_ports

# Deny CONNECT to other than secure SSL ports
#http_access allow CONNECT !SSL_ports

# Only allow cachemgr access from localhost
http_access allow localhost manager
http_access deny manager

# We strongly recommend the following be uncommented to protect innocent
# web applications running on the proxy server who think the only
# one who can access services on "localhost" is a local user
#http_access deny to_localhost

#
# INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
#

# Example rule allowing access from your local networks.
# Adapt localnet in the ACL section to list your (internal) IP networks
# from where browsing should be allowed
http_access allow localnet
http_access allow localhost
#log_fqdn on

# And finally deny all other access to this proxy
http_access deny all

# Squid normally listens to port 3128
#http_port 8000
#http_port 8001
icp_port 3130

# Uncomment and adjust the following to add a disk cache directory.
#cache_dir ufs /var/spool/squid 1500 16 256

# Leave coredumps in the first cache dir
coredump_dir /var/spool/squid

#
# Add any of your own refresh_pattern entries above these.
#
#refresh_pattern ^ftp: 1440 20% 10080
#refresh_pattern ^gopher: 1440 0% 1440
#refresh_pattern -i (/cgi-bin/|\?) 0 0% 0
#refresh_pattern . 0 20% 4320

http_port 8000 name=port_8000
http_port 8001 name=port_8001

nonhierarchical_direct off

acl port_8000_acl myportname port_8000
acl port_8001_acl myportname port_8001

always_direct deny port_8000_acl
always_direct deny port_8001_acl

never_direct allow port_8000_acl
never_direct allow port_8001_acl

# 8000
cache_peer xxx.xxxx.com parent 8000 3130 weight=20 no-digest no-query
name=proxy8000
cache_peer_access proxy8000 allow port_8000_acl
cache_peer_access proxy8000 deny all

# 8001
cache_peer xxx.xxxx.com parent 8001 3130 weight=20 no-digest no-query
name=proxy8001
cache_peer_access proxy8001 allow port_8001_acl
cache_peer_access proxy8001 deny all

cache_mem 100 MB
cache_swap_low 90
cache_swap_high 95


acl work_day time MTWHFAS 09:00-18:30
acl BBHK src 11.123.0.0/16
delay_pools 1
delay_class 1 2
delay_parameters 1 -1/-1 512000/512000
delay_access 1 allow work_day
delay_access 1 allow BBHK


acl QUERY urlpath_regex cgi-bin \?
no_cache deny QUERY
maximum_object_size 2048 KB
ipcache_size 1024
ipcache_low 90
ipcache_high 95
fqdncache_size 1024
logformat squid      %ts.%03tu %6tr %>A %Ss/%03>Hs %<st %rm %ru %[un
%Sh/%<a %mt
cache_access_log /var/log/squid/access.log
cache_log /var/log/squid/cache.log
cache_store_log none
pid_filename /var/run/squid.pid
auth_param ntlm program /usr/bin/ntlm_auth
--helper-protocol=squid-2.5-ntlmssp
auth_param ntlm children 30
auth_param basic program /usr/bin/ntlm_auth
--helper-protocol=squid-2.5-basic
auth_param basic children 30
auth_param basic realm Squid proxy-caching web server
auth_param basic credentialsttl 2 hours
request_body_max_size 15 MB



acl AuthorizedUsers proxy_auth REQUIRED
acl shockwaveplayer browser Shockwave
acl Java browser Java/1.4 Java/1.5 Java/1.6
acl BBhknet src "/etc/squid/ACL/allow_net"
acl allow_ip src "/etc/squid/ACL/allow_ip"
#acl deny_ip src "/etc/squid/ACL/deny_ip"
#acl DenyUsers proxy_auth "/etc/squid/ACL/deny_users"
acl allow_pattern dstdom_regex "/etc/squid/ACL/allow_domain"

acl allow_sites url_regex "/etc/squid/ACL/allow_url"
#http_access allow allow_sites

acl deny_site url_regex "/etc/squid/ACL/deny_url"
#http_access deny deny_site

acl deny_pattern dstdom_regex "/etc/squid/ACL/deny_domain"
#http_access deny deny_pattern

acl deny_domain dstdom_regex "/etc/squid/ACL/deny_domain"
acl deny_url url_regex "/etc/squid/ACL/deny_url"

acl fwdurl dstdomain .salesforce.com .force.com
never_direct allow fwdurl

acl fwdhkpurl dstdomain "/etc/squid/ACL/fwdhkpdomain"
never_direct allow fwdhkpurl


http_access allow fwdurl
http_access allow fwdhkpurl
http_access allow shockwaveplayer
http_access allow Java
http_access allow allow_ip
http_access allow allow_pattern
http_access allow allow_sites
http_access deny deny_domain
http_access allow BBhknet
http_access allow BBHK
http_access deny all


http_reply_access allow all
icp_access allow all
miss_access allow all
cache_mgr BBHK Network Admin Email
cache_effective_user squid
cache_effective_group squid
visible_hostname proxy6.hkg.xerox.com
max_filedesc 4096
never_direct allow all
error_directory /usr/share/squid/errors/English
coredump_dir /var/spool/squid

=======================================================

Thanks all

Alex
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170726/636e48a4/attachment.htm>

From squid3 at treenet.co.nz  Wed Jul 26 04:42:06 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 26 Jul 2017 16:42:06 +1200
Subject: [squid-users] How to tell HTTPS traffic is using cache from
 access.log in 3.5.x when using ssl_bump
In-Reply-To: <CAPu9cN6omb+m8JMsNmJtSRD8z-oPRSRm1cSWo5YHNG0LbU4J4A@mail.gmail.com>
References: <CAPu9cN6omb+m8JMsNmJtSRD8z-oPRSRm1cSWo5YHNG0LbU4J4A@mail.gmail.com>
Message-ID: <688b3f4f-c479-9750-56f5-5e6072c4359b@treenet.co.nz>

On 26/07/17 10:56, Lei Wen wrote:
> Hi,
> 
> I am setting up a transparent proxy that is doing whitelist work, and at 
> the same time, doing the cache work.
> 
> 
> The whitelist works fine, HTTP cache verifed work cause I see 
> TCP_MEM_HIT using this squid.conf, but don't see any HTTPS MEM HIT 
> related log, every time seems a new connection.


Nod. HIT and REFRESH log entries show cache usage. Squid versions with 
SSL-Bump support are more likely to show REFRESH.


> 
> For HTTPS traffic, I am getting TCP_TUNNEL/200 all the time, the 
> question is, how can I tell that a HTTPS traffic is actually using 
> cache, or in this case, it's not using cache at all for HTTPS. I am 
> using forward-proxy port in cache_peer.

That TUNNEL shows SSL-Bump splice action happening, or SSL-Bump not even 
being considered (ie traffic received in your Squids' port 3130 and 3128).


> 
> I understand that there is logformat to make access.log show hostname 
> instead of ip, but this should not effect the MEM HIT log, right?
> 
> Meanwhile, I am also trying to setup the sibling cache cluster, not sure 
> if this related to HTTPS cache, I am also getting TCP_DENIED/403 
> for squid-internal-dynamic/netdb - HIER_NONE/- text/html. I do see 
> sibling hit for HTTP site.
> 

You have configured splice or terminate. No bumping / decryption will 
ever happen, so the cache is never even considered for use.


> And my squid.conf
> 
> # Squid normally listens to port 3128
> 
> http_port 3130
> 
> 
> http_port 3128 intercept
> 
> acl allowed_http_sites dstdomain "/etc/squid3/whitelist.txt"
> 
> http_access allow allowed_http_sites
> 
> 
> https_port 3129 cert=/etc/squid3/squid.crt key=/etc/squid3/squid.key 
> ssl-bump intercept generate-host-certificates=on 
> dynamic_cert_mem_cache_size=4MB
> 
> acl SSL_port port 443
> 
> http_access allow SSL_port
> 

There are now almost no restrictions on port 443. Anyone can get through 
it so long as they claim to be contacting one of the allowed_https_sites 
(a the HTTP CONNECT level, not the TLS is unrestricted).
That includes traffic in the ports 3130 and 3128 which are not 
considered for ssl_bump processing.



> acl allowed_https_sites ssl::server_name "/etc/squid3/ssl_sites.txt"
> 
> #sslcrtd_program /usr/local/squid/libexec/ssl_crtd -s /var/lib/ssl_db -M 4MB
> 
> sslcrtd_program /lib/squid3/ssl_crtd -s /var/lib/ssl_db -M 4MB
> 
> 
> 
> acl step1 at_step SslBump1
> 
> acl step2 at_step SslBump2
> 
> acl step3 at_step SslBump3
> 
> ssl_bump peek step1 all
> 
> ssl_bump peek step2 allowed_https_sites

dstdomain ACL is not reliable in ssl_bump. It uses the HTTP URI domain 
from the previous CONNECT instead of the actual TLS details.
Use ssl::server_name ACL type instead.

> 
> ssl_bump splice step3 allowed_https_sites
> 
> ssl_bump terminate step2 all

So what happens when the server TLS cert reveals it is not actually 
serving up one of the allowed_https_sites? nothing, the traffic is 
allowed through.


Note the terminate line only gets used at step2 (ie. based on client SNI 
claims alone). The peek at step2 has precluded / prohibited bump from 
happening at step3, which only leaves splice as being possible.


Amos


From squid3 at treenet.co.nz  Wed Jul 26 05:35:50 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Wed, 26 Jul 2017 17:35:50 +1200
Subject: [squid-users] Delay_pools problem in Squid 3.5.20
In-Reply-To: <CAESqrS7+DTb6mvJgn2yv95yeBD64ZhHZ8sBwJCdc43Fp3bSaLg@mail.gmail.com>
References: <CAESqrS7+DTb6mvJgn2yv95yeBD64ZhHZ8sBwJCdc43Fp3bSaLg@mail.gmail.com>
Message-ID: <4add0902-bac9-98bb-bc27-067de05be028@treenet.co.nz>

On 26/07/17 13:49, Alex Tang wrote:
> Dear All,
> 
> I had installed a squid 3.5.20 on Centos7. I'm also setting up a 
> delay_pools and cache_peer function on this squid server .
> 
> but I don't know why delay_pools function not working now. before I 
> tested is OK and I can limit user download less then 512 kb. but now, 
> all user download is over 512kb and can't control. I tried reboot the 
> squid or use the other delay_pools command to try to test which part has 
> problem to cause the delay_pools problem. I've checked my config file 
> seem OK (this is my first time to install and use squid proxy server) , 
> would you mind tell me is it my config problem or squid bug (maybe)
> 

What do you mean exactly by "before I tested is OK". The same Squid 
version? the same config file?



> here is my full config file.
> 
> ====================================================
> #
> # Recommended minimum configuration:
> #
> 
> # Example rule allowing access from your local networks.
> # Adapt to list your (internal) IP networks from where browsing
> # should be allowed
> acl localnet src 10.0.0.0/8 <http://10.0.0.0/8># RFC1918 possible 
> internal network
> acl localnet src 111.11.0.0/12 <http://111.11.0.0/12># RFC1918 possible 
> internal network
> acl localnet src 11.123.0.0/16 <http://11.123.0.0/16># RFC1918 possible 
> internal network

Ah, 111/8 and 11/8 are not RFC 1918 network ranges. If you have been 
assigned those ranges and are using them internally that is fine, but 
remove the RFC1918 comment to avoid confusing anyone about them.


> acl localnet src fc00::/7       # RFC 4193 local private network range
> acl localnet src fe80::/10      # RFC 4291 link-local (directly plugged) 
> machines
> 
> acl SSL_ports port 443 563
> acl Safe_ports port 80# http
> acl Safe_ports port 21# ftp
> #acl Safe_ports port 443# https
> acl Safe_ports port 70# gopher
> acl Safe_ports port 210# wais
> #acl Safe_ports port 1025-65535# unregistered ports
> acl Safe_ports port 280# http-mgmt
> acl Safe_ports port 488# gss-http
> acl Safe_ports port 591# filemaker
> acl Safe_ports port 777# multiling http
> #acl CONNECT method CONNECT
> 
> 
> 
> #
> # Recommended minimum Access Permission configuration:
> #
> # Deny requests to certain unsafe ports
> #http_access allow !Safe_ports
> 
> # Deny CONNECT to other than secure SSL ports
> #http_access allow CONNECT !SSL_ports
> 

Do not do the above commenting-out of those lines. They are the basic 
security protection against certain types of DoS and attacks on your 
proxy. Which is also why they should always be first.


> # Only allow cachemgr access from localhost
> http_access allow localhost manager
> http_access deny manager
> 
> # We strongly recommend the following be uncommented to protect innocent
> # web applications running on the proxy server who think the only
> # one who can access services on "localhost" is a local user
> #http_access deny to_localhost
> 
> #
> # INSERT YOUR OWN RULE(S) HERE TO ALLOW ACCESS FROM YOUR CLIENTS
> #
> 
> # Example rule allowing access from your local networks.
> # Adapt localnet in the ACL section to list your (internal) IP networks
> # from where browsing should be allowed
> http_access allow localnet
> http_access allow localhost
> 
> # And finally deny all other access to this proxy
> http_access deny all
> 
> icp_port 3130
 >
> # Leave coredumps in the first cache dir
> coredump_dir /var/spool/squid
> 
> #
> # Add any of your own refresh_pattern entries above these.
> #
> #refresh_pattern ^ftp:144020%10080
> #refresh_pattern ^gopher:14400%1440
> #refresh_pattern -i (/cgi-bin/|\?) 00%0
> #refresh_pattern .020%4320

The above refresh_pattern lines are tuned specifically for HTTP/1.1 
required behaviour with dynamic content. If you are caching I highly 
recommend leaving them active. If you are not using caching they are 
irrelevant.

> 
> http_port 8000 name=port_8000
> http_port 8001 name=port_8001
> 
> nonhierarchical_direct off
> 
> acl port_8000_acl myportname port_8000
> acl port_8001_acl myportname port_8001
> 
> always_direct deny port_8000_acl
> always_direct deny port_8001_acl
> 
> never_direct allow port_8000_acl
> never_direct allow port_8001_acl
> 

The above are redundant. always_direct overrides never_direct. The 
normal practice is to use only never_direct to forbid use of DNS 
identified origin servers and leave the cache_peer as an available routing.


> # 8000
> cache_peer xxx.xxxx.com parent 8000 3130 weight=20 
> no-digest no-query name=proxy8000
> cache_peer_access proxy8000 allow port_8000_acl
> cache_peer_access proxy8000 deny all
> 
> # 8001
> cache_peer xxx.xxxx.com parent 8001 3130 weight=20 
> no-digest no-query name=proxy8001
> cache_peer_access proxy8001 allow port_8001_acl
> cache_peer_access proxy8001 deny all
> 
> cache_mem 100 MB
> cache_swap_low 90
> cache_swap_high 95
> 
> 
> acl work_day time MTWHFAS 09:00-18:30
> acl BBHK src 11.123.0.0/16
> delay_pools 1
> delay_class 1 2
> delay_parameters 1 -1/-1 512000/512000
> delay_access 1 allow work_day
> delay_access 1 allow BBHK


Three things to be careful about. I order them here based on the 
likelihood that they are your problem:

  1) the work_day times are in 'local time', according to whatever the 
local wall-clock of your Squid machine is set to.

   This local time detail can catch people out if the production proxy 
is set to use UTC as its local time, or is hosted in another timezone 
(ie cloud service).

  2) delay pools operate by limiting Squid->server connection traffic. 
That means that cache HITs are not delayed. Also, HTTP/1.1 revalidations 
use very much less server connection bytes compared to client connection 
bytes. So the delay may have the appearance of not working, even when 
working perfectly.
   For proper bandwidth shaping it is best to use your system QoS 
functionality, not Squid delay pools. Especially given your criteria 
does not actually use any HTTP layer details to classify the traffic for 
delay.



  3) these lines form an OR condition. The BBHK are *always* delayed, 
and so is every client during the work_day times.

Check carefully where (from what client IPs to what proxy IPs), how, and 
when your previous working tests were done compared to the current 
non-working situation.


  4) the delay pools measure traffic in Bytes (KB or kB) not bits (Kb or 
kb). KB/sec limits are 8x larger than kb/sec.

I assume your "kb" word was just sloppy typing. But if you did mean bits 
this could be affecting your measurement results.


> 
> acl QUERY urlpath_regex cgi-bin \?
> no_cache deny QUERY

The above is a misconfiguration in Squid-3. The refresh_pattern which 
you commented out are the correct way to prevent broken dynamic content 
caching.

> maximum_object_size 2048 KB
> ipcache_size 1024
> ipcache_low 90
> ipcache_high 95
> fqdncache_size 1024
> logformat squid      %ts.%03tu %6tr %>A %Ss/%03>Hs %<st %rm %ru %[un 
> %Sh/%<a %mt

Please do not re-define the "squid" format name. Current Squid releases 
will ignore your definition, and the log will not end up with what you 
want in it (the real built-in format does not have the exact output in 
some cases as those %-codes perform).
  Either use the built-in format (removing those above line), or use a 
different format name for your custom format.


> cache_access_log /var/log/squid/access.log

cache_access_log is long ago deprecated.

Use access_log instead, like so:
  access_log stdio:/var/log/access.log

or for better performance:
  access_log daemon:/var/log/access.log


> cache_log /var/log/squid/cache.log
> cache_store_log none
> pid_filename /var/run/squid.pid
> auth_param ntlm program /usr/bin/ntlm_auth 
> --helper-protocol=squid-2.5-ntlmssp
> auth_param ntlm children 30
> auth_param basic program /usr/bin/ntlm_auth 
> --helper-protocol=squid-2.5-basic
> auth_param basic children 30
> auth_param basic realm Squid proxy-caching web server
> auth_param basic credentialsttl 2 hours
> request_body_max_size 15 MB
> 

NTLM plus delay pools. Ouch.

> 
> acl AuthorizedUsers proxy_auth REQUIRED
> acl shockwaveplayer browser Shockwave
> acl Java browser Java/1.4 Java/1.5 Java/1.6
> acl BBhknet src "/etc/squid/ACL/allow_net"
> acl allow_ip src "/etc/squid/ACL/allow_ip"
> #acl deny_ip src "/etc/squid/ACL/deny_ip"
> #acl DenyUsers proxy_auth "/etc/squid/ACL/deny_users"
> acl allow_pattern dstdom_regex "/etc/squid/ACL/allow_domain"
> 
> acl allow_sites url_regex "/etc/squid/ACL/allow_url"
> #http_access allow allow_sites
> 
> acl deny_site url_regex "/etc/squid/ACL/deny_url"
> #http_access deny deny_site
> 
> acl deny_pattern dstdom_regex "/etc/squid/ACL/deny_domain"
> #http_access deny deny_pattern
> 
> acl deny_domain dstdom_regex "/etc/squid/ACL/deny_domain"
> acl deny_url url_regex "/etc/squid/ACL/deny_url"
> 
> acl fwdurl dstdomain .salesforce.com <http://salesforce.com> .force.com 
> <http://force.com>
> never_direct allow fwdurl
> 
> acl fwdhkpurl dstdomain "/etc/squid/ACL/fwdhkpdomain"
> never_direct allow fwdhkpurl
> 
> 
> http_access allow fwdurl
> http_access allow fwdhkpurl

Note: The fwdurl and fwdhkpurl ACL are the same type, and used together 
for exactly the same things. You can simplify your config by merging 
them into one ACL name like so:
  acl fwdurl dstdomain .salesforce.com .force.com
  acl fwdurl dstdomain "/etc/squid/ACL/fwdhkpdomain"

then removing the *_access lines using fwdhkpurl.


> http_access allow shockwaveplayer
> http_access allow Java
> http_access allow allow_ip
> http_access allow allow_pattern
> http_access allow allow_sites
> http_access deny deny_domain
> http_access allow BBhknet
> http_access allow BBHK
> http_access deny all
> 
> 
> http_reply_access allow all
> icp_access allow all
> miss_access allow all
> cache_mgr BBHK Network Admin Email > cache_effective_user squid
> cache_effective_group squid
> visible_hostname proxy6.hkg.xerox.com
> max_filedesc 4096
> never_direct allow all
> error_directory /usr/share/squid/errors/English
> coredump_dir /var/spool/squid

Most of the above are default config settings. You can simplify your 
config by removing the default lines.

squid -k parse should give you a lot of hints about improvements as 
well. That is always being improved, so a quick -k parse after upgrades 
is recommended best practice.

Amos


From omidkosari at yahoo.com  Wed Jul 26 10:07:41 2017
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 26 Jul 2017 03:07:41 -0700 (PDT)
Subject: [squid-users] What would be the maximum ufs\aufs cache_dir
	objects?
In-Reply-To: <095601d3032f$ebeab490$c3c01db0$@ngtech.co.il>
References: <06f501d2fc9d$f39292a0$dab7b7e0$@ngtech.co.il>
 <e0d12d09-4d0e-3ea9-d442-e14163a5d271@treenet.co.nz>
 <d08145b1-6c4c-0b1e-26b3-78559563f4ed@measurement-factory.com>
 <0e4e01d2ff22$e99f5530$bcddff90$@ngtech.co.il>
 <e0bcf3db-4da7-cb6e-8ae6-969e092d57e0@treenet.co.nz>
 <095601d3032f$ebeab490$c3c01db0$@ngtech.co.il>
Message-ID: <1501063661228-4683213.post@n4.nabble.com>

Interesting because i was going to create a new topic like this but Eliezer
read my mind ;)

Nowadays i can see that the http traffic is going fewer and fewer and every
day i am thinking about retiring the squid . 

But currently is see that most of the remaining http traffic which worth
caching is 
Microsoft ( Windows Updates + App Updates ) 
Apple (IOS updates + App Updates )
Game Consoles (Playstation + Xbox + Game Updates )
Google ( Android Apps + Chrome Apps )
Samsung (Firmware Update + AppUpdates )
CDNs (Akamai + llnwd )
Antivirus Updates

The international HTTP traffic is less than 20% of all international traffic
. The sites mentioned above include more than 60% of international http
traffic so they are more than 10% of all international traffic .

Now i prefer to only cache mentioned sites . But each line needs a special
customization like what Eliezer tool for windows updates .

Squid is an advance general caching software/platform and customizing for
each website is far from its roadmap . So i think supporting others like
Eliezer to create custom helpers/services for each website may help Squid be
more popular and active.



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/What-would-be-the-maximum-ufs-aufs-cache-dir-objects-tp4683100p4683213.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From omidkosari at yahoo.com  Wed Jul 26 11:24:55 2017
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 26 Jul 2017 04:24:55 -0700 (PDT)
Subject: [squid-users] Cache poisoning vulnerability 3.5.23
Message-ID: <1501068295901-4683215.post@n4.nabble.com>

Hello,

Recently i have seen some Cache poisoning specially on android captive
portal detection sites .
My squid was 3.5.19 (from https://packages.debian.org/stretch/squid) on
Ubuntu Linux 16.04 . Then i have upgraded to latest version 3.5.23 (from
https://packages.debian.org/stretch/squid) and purged specific pages but
again i can see cache poisoning on same pages .

http://connectivitycheck.gstatic.com/generate_204
http://clients3.google.com/generate_204
http://172.217.20.206/generate_204
http://clients1.google.com/generate_204
http://google.com/generate_204




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Cache-poisoning-vulnerability-3-5-23-tp4683215.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From omidkosari at yahoo.com  Wed Jul 26 11:33:44 2017
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 26 Jul 2017 04:33:44 -0700 (PDT)
Subject: [squid-users] Cache poisoning vulnerability 3.5.23
In-Reply-To: <1501068295901-4683215.post@n4.nabble.com>
References: <1501068295901-4683215.post@n4.nabble.com>
Message-ID: <1501068824462-4683216.post@n4.nabble.com>

By my experience if you see any output from following command you may be a
victim

grep -a 'generate_204' /var/log/squid/access.log | grep -v '/204 ' | grep -v
'/000' | grep -v opera | grep -v ucweb | grep -v apple



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Cache-poisoning-vulnerability-3-5-23-tp4683215p4683216.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From squid3 at treenet.co.nz  Wed Jul 26 20:09:57 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 27 Jul 2017 08:09:57 +1200
Subject: [squid-users] Cache poisoning vulnerability 3.5.23
In-Reply-To: <1501068824462-4683216.post@n4.nabble.com>
References: <1501068295901-4683215.post@n4.nabble.com>
 <1501068824462-4683216.post@n4.nabble.com>
Message-ID: <81501429-9fe5-8414-e02d-3506eb0a5fa1@treenet.co.nz>

On 26/07/17 23:33, Omid Kosari wrote:
> By my experience if you see any output from following command you may be a
> victim
> 
> grep -a 'generate_204' /var/log/squid/access.log | grep -v '/204 ' | grep -v
> '/000' | grep -v opera | grep -v ucweb | grep -v apple
> 

OR, you have Android clients on your network doing network 
troubleshooting tests.

Cache poisoning (if it is that) is a serious security issue. Please 
bring the details of security problems to the *squid-bugs* mailing list 
so it can be investigated and solved, rather than blind-siding everyone 
with a public announcement like this.

Amos


From webmaster at squidblacklist.org  Wed Jul 26 20:13:58 2017
From: webmaster at squidblacklist.org (Benjamin E. Nichols)
Date: Wed, 26 Jul 2017 15:13:58 -0500
Subject: [squid-users] July 25 2017 - #RIP Urlblacklist.com closed down.
Message-ID: <96bfb8df-16b5-fc37-3884-84b5c1d712ac@squidblacklist.org>

This is a courtesy message to inform Squid Proxy users who may be using 
blacklists  by urlblacklist.com

On July 25 2017,   Blacklist provider Urlblacklist.com has closed down, 
shut of its website, and thrown in the towel, they have refunded current 
subscribers and closed up shop.


Also July 25th was my Birthday. #Celebration

-- 
--

Signed,

Benjamin E. Nichols
http://www.squidblacklist.org

1-405-397-1360 - Call Anytime.



From leiwen14 at gmail.com  Wed Jul 26 21:54:04 2017
From: leiwen14 at gmail.com (Lei Wen)
Date: Wed, 26 Jul 2017 14:54:04 -0700
Subject: [squid-users] How to tell HTTPS traffic is using cache from
 access.log in 3.5.x when using ssl_bump
In-Reply-To: <688b3f4f-c479-9750-56f5-5e6072c4359b@treenet.co.nz>
References: <CAPu9cN6omb+m8JMsNmJtSRD8z-oPRSRm1cSWo5YHNG0LbU4J4A@mail.gmail.com>
 <688b3f4f-c479-9750-56f5-5e6072c4359b@treenet.co.nz>
Message-ID: <CAPu9cN7PWEzC436UPK=NiYK0eLX=6Bce8q7YYTy8_J8XJ-_4uw@mail.gmail.com>

Hi Amos,

Thanks a lot.
It is my splice thing is blocking proxy in the middle, after using stare
instead of peek, seems work though, terminal in this case is not blocking
proxy in the middle?

I made some change on my squid.conf, it work for http/https caching and
http/https whitelist.
It is working for http sibling cache as well, but has some issue with
https/ssl sibling cache.
in cache_peer, which port number should I use as forward-proxy port?
3130/3128/3129?

I am trying to set up a sibling cache pool, there is no parent or gateway
sort of thing in this hierarchy.
Each instance can have their own whitelist, but they share the same cache
pool.
On each instance host, squid is actually doing it's whitelist and caching
job for a container group on the same host.


http_port 3130

http_port 3128 intercept
acl allowed_http_sites dstdomain "/etc/squid3/whitelist.txt"
http_access allow allowed_http_sites

https_port 3129 cert=/etc/squid3/squid.crt key=/etc/squid3/squid.key
ssl-bump intercept generate-host-certificates=on
dynamic_cert_mem_cache_size=4MB
acl SSL_port port 443
http_access allow SSL_port
acl allowed_https_sites ssl::server_name "/etc/squid3/ssl_sites.txt"

http_access deny all

acl step1 at_step SslBump1
acl step2 at_step SslBump2
acl step3 at_step SslBump3
ssl_bump stare step1 all
ssl_bump stare step2 allowed_https_sites
#ssl_bump bump step3
ssl_bump terminate step2 all

icp_port 3131
icp_access allow all
cache_peer 10.0.8.48 sibling 3130 3131 proxy-only



Thanks,
Lei

On Tue, Jul 25, 2017 at 9:42 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 26/07/17 10:56, Lei Wen wrote:
>
>> Hi,
>>
>> I am setting up a transparent proxy that is doing whitelist work, and at
>> the same time, doing the cache work.
>>
>>
>> The whitelist works fine, HTTP cache verifed work cause I see TCP_MEM_HIT
>> using this squid.conf, but don't see any HTTPS MEM HIT related log, every
>> time seems a new connection.
>>
>
>
> Nod. HIT and REFRESH log entries show cache usage. Squid versions with
> SSL-Bump support are more likely to show REFRESH.
>
>
>
>> For HTTPS traffic, I am getting TCP_TUNNEL/200 all the time, the question
>> is, how can I tell that a HTTPS traffic is actually using cache, or in this
>> case, it's not using cache at all for HTTPS. I am using forward-proxy port
>> in cache_peer.
>>
>
> That TUNNEL shows SSL-Bump splice action happening, or SSL-Bump not even
> being considered (ie traffic received in your Squids' port 3130 and 3128).
>
>
>
>> I understand that there is logformat to make access.log show hostname
>> instead of ip, but this should not effect the MEM HIT log, right?
>>
>> Meanwhile, I am also trying to setup the sibling cache cluster, not sure
>> if this related to HTTPS cache, I am also getting TCP_DENIED/403 for
>> squid-internal-dynamic/netdb - HIER_NONE/- text/html. I do see sibling hit
>> for HTTP site.
>>
>>
> You have configured splice or terminate. No bumping / decryption will ever
> happen, so the cache is never even considered for use.
>
>
> And my squid.conf
>>
>> # Squid normally listens to port 3128
>>
>> http_port 3130
>>
>>
>> http_port 3128 intercept
>>
>> acl allowed_http_sites dstdomain "/etc/squid3/whitelist.txt"
>>
>> http_access allow allowed_http_sites
>>
>>
>> https_port 3129 cert=/etc/squid3/squid.crt key=/etc/squid3/squid.key
>> ssl-bump intercept generate-host-certificates=on
>> dynamic_cert_mem_cache_size=4MB
>>
>> acl SSL_port port 443
>>
>> http_access allow SSL_port
>>
>>
> There are now almost no restrictions on port 443. Anyone can get through
> it so long as they claim to be contacting one of the allowed_https_sites (a
> the HTTP CONNECT level, not the TLS is unrestricted).
> That includes traffic in the ports 3130 and 3128 which are not considered
> for ssl_bump processing.
>
>
>
> acl allowed_https_sites ssl::server_name "/etc/squid3/ssl_sites.txt"
>>
>> #sslcrtd_program /usr/local/squid/libexec/ssl_crtd -s /var/lib/ssl_db -M
>> 4MB
>>
>> sslcrtd_program /lib/squid3/ssl_crtd -s /var/lib/ssl_db -M 4MB
>>
>>
>>
>> acl step1 at_step SslBump1
>>
>> acl step2 at_step SslBump2
>>
>> acl step3 at_step SslBump3
>>
>> ssl_bump peek step1 all
>>
>> ssl_bump peek step2 allowed_https_sites
>>
>
> dstdomain ACL is not reliable in ssl_bump. It uses the HTTP URI domain
> from the previous CONNECT instead of the actual TLS details.
> Use ssl::server_name ACL type instead.
>
>
>> ssl_bump splice step3 allowed_https_sites
>>
>> ssl_bump terminate step2 all
>>
>
> So what happens when the server TLS cert reveals it is not actually
> serving up one of the allowed_https_sites? nothing, the traffic is allowed
> through.
>
>
> Note the terminate line only gets used at step2 (ie. based on client SNI
> claims alone). The peek at step2 has precluded / prohibited bump from
> happening at step3, which only leaves splice as being possible.
>
>
> Amos
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170726/291a47dd/attachment.htm>

From squid3 at treenet.co.nz  Wed Jul 26 22:30:54 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Thu, 27 Jul 2017 10:30:54 +1200
Subject: [squid-users] How to tell HTTPS traffic is using cache from
 access.log in 3.5.x when using ssl_bump
In-Reply-To: <CAPu9cN7PWEzC436UPK=NiYK0eLX=6Bce8q7YYTy8_J8XJ-_4uw@mail.gmail.com>
References: <CAPu9cN6omb+m8JMsNmJtSRD8z-oPRSRm1cSWo5YHNG0LbU4J4A@mail.gmail.com>
 <688b3f4f-c479-9750-56f5-5e6072c4359b@treenet.co.nz>
 <CAPu9cN7PWEzC436UPK=NiYK0eLX=6Bce8q7YYTy8_J8XJ-_4uw@mail.gmail.com>
Message-ID: <6d753d7a-a9c6-3ca2-5fef-8d606418eb47@treenet.co.nz>

On 27/07/17 09:54, Lei Wen wrote:
> Hi Amos,
> 
> Thanks a lot.
> It is my splice thing is blocking proxy in the middle,

Sort of, yes.

> after using stare 
> instead of peek, seems work though, terminal in this case is not 
> blocking proxy in the middle?
> 

Not sure what you are asking there. Squid *is* the proxy in the middle, 
so terminate does a TCP close().


> I made some change on my squid.conf, it work for http/https caching and 
> http/https whitelist.
> It is working for http sibling cache as well, but has some issue with 
> https/ssl sibling cache.
> in cache_peer, which port number should I use as forward-proxy port? 
> 3130/3128/3129?

Squid does not support relaying decrypted https:// requests over an 
insecure connection. So HTTP cache_peer connections will be refused.

Also, when TLS cache_peer is used Squid is unable to tell the difference 
between the peer TLS server details an origin. So any server-cert 
forging uses the cache_peer's server cert instead of the origin.

In Squid-3.5 (and v4) explicit/forward proxy it is best not to use 
cache_peer for decrypted content. The most working way for now is to let 
it go 'DIRECT' and repeat the intercept at the peer.


> 
> I am trying to set up a sibling cache pool, there is no parent or 
> gateway sort of thing in this hierarchy.
> Each instance can have their own whitelist, but they share the same 
> cache pool.
> On each instance host, squid is actually doing it's whitelist and 
> caching job for a container group on the same host.
> 

Are you trying to describe something like a CARP hierarchy?
<http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster>

They suffer from the above problem. There is no good solution for that 
in current Squid versions which do SSL-Bump.


> 
> acl step1 at_step SslBump1
> acl step2 at_step SslBump2
> acl step3 at_step SslBump3
> ssl_bump stare step1 all
> ssl_bump stare step2 allowed_https_sites
> #ssl_bump bump step3
> ssl_bump terminate step2 all
> 


Up to you, but I would do this:

  ssl_bump peek step1

  ssl_bump stare step2 allowed_https_sites
  ssl_bump terminate step2

  # decrypt with server-cert forging
  ssl_bump bump step3


That peek at step1 allows Squid can splice if things to badly at the 
step2 staring. A peek at step1 will not prevent a step3 bump.

And the explicit line with 'bump' ensures that Squid actually does a 
bump, the default behaviour is a little bit too variable depending on 
what bugs are present in the SSL-Bump code.


Amos


From omidkosari at yahoo.com  Thu Jul 27 06:06:09 2017
From: omidkosari at yahoo.com (Omid Kosari)
Date: Wed, 26 Jul 2017 23:06:09 -0700 (PDT)
Subject: [squid-users] Cache poisoning vulnerability 3.5.23
In-Reply-To: <81501429-9fe5-8414-e02d-3506eb0a5fa1@treenet.co.nz>
References: <1501068295901-4683215.post@n4.nabble.com>
 <1501068824462-4683216.post@n4.nabble.com>
 <81501429-9fe5-8414-e02d-3506eb0a5fa1@treenet.co.nz>
Message-ID: <1501135569233-4683221.post@n4.nabble.com>

Amos Jeffries wrote
> Cache poisoning (if it is that) is a serious security issue. Please 
> bring the details of security problems to the *squid-bugs* mailing list 
> so it can be investigated and solved, rather than blind-siding everyone 
> with a public announcement like this.
> 
> Amos

I tried it before posting here but my message did not accepted after hours ,
so then i posted here . 
I'll try again there .




--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Cache-poisoning-vulnerability-3-5-23-tp4683215p4683221.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From Wahaj_Ali at symantec.com  Thu Jul 27 07:51:57 2017
From: Wahaj_Ali at symantec.com (Wahaj Ali)
Date: Thu, 27 Jul 2017 07:51:57 +0000
Subject: [squid-users] SSL options on different http_port resolving into a
 single config for all ports
Message-ID: <CY4PR16MB1688F38DB046710D7483AE6CE1BE0@CY4PR16MB1688.namprd16.prod.outlook.com>

With squid 3.5.25, I have two http_port configs, on one of which I want to disable SSLv3 while leaving it enabled on the other. Here is part of that config:

http_port 3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/home/madmin/certs/elastica-ca.pem key=/home/madmin/certs/ca.key cipher=ALL:!DES-CBC-SHA:!EXP-DES-CBC-SHA:!EXP-RC4-MD5:!EXP-RC2-CBC-MD5:@STRENGTH options=NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE tls-dh=prime256v1:/etc/ssl/private/el-dhparams.pem

http_port 443 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/home/madmin/certs/elastica-ca.pem key=/home/madmin/certs/ca.key cipher=ALL:!DES-CBC-SHA:!EXP-DES-CBC-SHA:!EXP-RC4-MD5:!EXP-RC2-CBC-MD5:@STRENGTH options=SINGLE_ECDH_USE tls-dh=prime256v1:/etc/ssl/private/el-dhparams.pem

If I first proxy my traffic to port 443, it seems to apply the port 443 config on all other ports from here on. On the other hand if my first request goes through port 3128, then squid sets whatever SSL version is supported on 3128 for all the other ports as well.

First request going to port 3128
root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:3128<http://127.0.0.1:3128/>" root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com<https://uatmail02.cimb.com/> -ssl3 * About to connect() to proxy 127.0.0.1 port 3128 (#0) * Trying 127.0.0.1... connected * Establish HTTP proxy tunnel to uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > CONNECT uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> HTTP/1.1 > Host: uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Proxy-Connection: Keep-Alive > < HTTP/1.1 200 Connection established < * Proxy replied OK to CONNECT request * successfully set certificate verify locations: * CAfile: none CApath: /etc/ssl/certs * SSLv3, TLS handshake, Client hello (1): * SSLv3, TLS alert, Server hello (2): * error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure * Closing connection #0 * root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:443<http://127.0.0.1:443/>" root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com<https://uatmail02.cimb.com/> -ssl3 * About to connect() to proxy 127.0.0.1 port 443 (#0) * Trying 127.0.0.1... connected * Establish HTTP proxy tunnel to uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > CONNECT uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> HTTP/1.1 > Host: uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Proxy-Connection: Keep-Alive > < HTTP/1.1 200 Connection established < * Proxy replied OK to CONNECT request * successfully set certificate verify locations: * CAfile: none CApath: /etc/ssl/certs * SSLv3, TLS handshake, Client hello (1): * SSLv3, TLS alert, Server hello (2): * error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure * Closing connection #0

First request hitting 443:
root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:443<http://127.0.0.1:443/>" root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com<https://uatmail02.cimb.com/> -ssl3 * About to connect() to proxy 127.0.0.1 port 443 (#0) * Trying 127.0.0.1... connected * Establish HTTP proxy tunnel to uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > CONNECT uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> HTTP/1.1 > Host: uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Proxy-Connection: Keep-Alive > < HTTP/1.1 200 Connection established < * Proxy replied OK to CONNECT request * successfully set certificate verify locations: * CAfile: none CApath: /etc/ssl/certs * SSLv3, TLS handshake, Client hello (1): * SSLv3, TLS handshake, Server hello (2): * SSLv3, TLS handshake, CERT (11): * SSLv3, TLS handshake, Server key exchange (12): * SSLv3, TLS handshake, Server finished (14): * SSLv3, TLS handshake, Client key exchange (16): * SSLv3, TLS change cipher, Client hello (1): * SSLv3, TLS handshake, Finished (20): * SSLv3, TLS change cipher, Client hello (1): * SSLv3, TLS handshake, Finished (20): * SSL connection using ECDHE-RSA-AES256-SHA * Server certificate: * subject: C=MY; ST=CIMB Bank Berhad ; L=Kuala Lumpur ; OU=CIMB Bank Berhad; CN=uatmail02.cimb.com<http://uatmail02.cimb.com/> * start date: 2017-07-03 09:00:37 GMT * expire date: 2019-07-04 09:00:37 GMT * common name: uatmail02.cimb.com<http://uatmail02.cimb.com/> (matched) * issuer: C=US; ST=California; L=San Jose; O=Elastica Inc; OU=Development; emailAddress=service-engineering at elastica.co<mailto:service-engineering at elastica.co>; CN=Elastica * SSL certificate verify ok. > GET / HTTP/1.1 > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Host: uatmail02.cimb.com<http://uatmail02.cimb.com/> > Accept: */* > < HTTP/1.1 302 Found < Date: Wed, 26 Jul 2017 10:12:48 GMT < Location: http://127.0.0.1:7999/gateway_auth/?__eln__=1468917241090744452&elastica_relay=https%3A%2F%2Fuatmail02.cimb.com%2F < Server: elastica-gateway-service/v1.0 < Connection: close < * SSLv3, TLS alert, Client hello (1): * Closing connection #0 * SSLv3, TLS alert, Client hello (1): root at madmin-VirtualBox:/home/madmin# root at madmin-VirtualBox:/home/madmin# root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:3128<http://127.0.0.1:3128/>" root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com<https://uatmail02.cimb.com/> -ssl3 * About to connect() to proxy 127.0.0.1 port 3128 (#0) * Trying 127.0.0.1... connected * Establish HTTP proxy tunnel to uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > CONNECT uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> HTTP/1.1 > Host: uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Proxy-Connection: Keep-Alive > < HTTP/1.1 200 Connection established < * Proxy replied OK to CONNECT request * successfully set certificate verify locations: * CAfile: none CApath: /etc/ssl/certs * SSLv3, TLS handshake, Client hello (1): * SSLv3, TLS handshake, Server hello (2): * SSLv3, TLS handshake, CERT (11): * SSLv3, TLS handshake, Server key exchange (12): * SSLv3, TLS handshake, Server finished (14): * SSLv3, TLS handshake, Client key exchange (16): * SSLv3, TLS change cipher, Client hello (1): * SSLv3, TLS handshake, Finished (20): * SSLv3, TLS change cipher, Client hello (1): * SSLv3, TLS handshake, Finished (20): * SSL connection using ECDHE-RSA-AES256-SHA * Server certificate: * subject: C=MY; ST=CIMB Bank Berhad ; L=Kuala Lumpur ; OU=CIMB Bank Berhad; CN=uatmail02.cimb.com<http://uatmail02.cimb.com/> * start date: 2017-07-03 09:00:37 GMT * expire date: 2019-07-04 09:00:37 GMT * common name: uatmail02.cimb.com<http://uatmail02.cimb.com/> (matched) * issuer: C=US; ST=California; L=San Jose; O=Elastica Inc; OU=Development; emailAddress=service-engineering at elastica.co<mailto:service-engineering at elastica.co>; CN=Elastica * SSL certificate verify ok. > GET / HTTP/1.1 > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Host: uatmail02.cimb.com<http://uatmail02.cimb.com/> > Accept: */* > < HTTP/1.1 302 Found < Date: Wed, 26 Jul 2017 10:12:58 GMT < Location: http://127.0.0.1:7999/gateway_auth/?__eln__=2303332476459826439&elastica_relay=https%3A%2F%2Fuatmail02.cimb.com%2F < Server: elastica-gateway-service/v1.0 < Connection: close < * SSLv3, TLS alert, Client hello (1): * Closing connection #0 * SSLv3, TLS alert, Client hello (1):


In the first case, SSLv3 fails on both ports, while in the second it works for both. My expectation was that I can configure the ports independently to use different SSL versions. Wonder if this is a bug?

Regards,

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170727/969b2d8d/attachment.htm>

From Wahaj_Ali at symantec.com  Thu Jul 27 07:57:14 2017
From: Wahaj_Ali at symantec.com (Wahaj Ali)
Date: Thu, 27 Jul 2017 07:57:14 +0000
Subject: [squid-users] SSL options on different http_port resolving into
 a single config for all ports
In-Reply-To: <CY4PR16MB1688F38DB046710D7483AE6CE1BE0@CY4PR16MB1688.namprd16.prod.outlook.com>
References: <CY4PR16MB1688F38DB046710D7483AE6CE1BE0@CY4PR16MB1688.namprd16.prod.outlook.com>
Message-ID: <CY4PR16MB1688F4C0D88C1F350B83576EE1BE0@CY4PR16MB1688.namprd16.prod.outlook.com>

Resending the logs as they were not formatted correctly:


First request going to port 3128
root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:3128"
root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com -ssl3
* About to connect() to proxy 127.0.0.1 port 3128 (#0)
*   Trying 127.0.0.1... connected
* Establish HTTP proxy tunnel to uatmail02.cimb.com:443
> CONNECT uatmail02.cimb.com:443 HTTP/1.1
> Host: uatmail02.cimb.com:443
> User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4 libidn/1.23 librtmp/2.3
> Proxy-Connection: Keep-Alive
>
< HTTP/1.1 200 Connection established
<
* Proxy replied OK to CONNECT request
* successfully set certificate verify locations:
*   CAfile: none
  CApath: /etc/ssl/certs
* SSLv3, TLS handshake, Client hello (1):
* SSLv3, TLS alert, Server hello (2):
* error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure
* Closing connection #0

Now hit port 443:

root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:443"
root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com -ssl3
* About to connect() to proxy 127.0.0.1 port 443 (#0)
*   Trying 127.0.0.1... connected
* Establish HTTP proxy tunnel to uatmail02.cimb.com:443
> CONNECT uatmail02.cimb.com:443 HTTP/1.1
> Host: uatmail02.cimb.com:443
> User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4 libidn/1.23 librtmp/2.3
> Proxy-Connection: Keep-Alive
>
< HTTP/1.1 200 Connection established
<
* Proxy replied OK to CONNECT request
* successfully set certificate verify locations:
*   CAfile: none
  CApath: /etc/ssl/certs
* SSLv3, TLS handshake, Client hello (1):
* SSLv3, TLS alert, Server hello (2):
* error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure
* Closing connection #0

Restart squid, then send first request on port 443 (which has ssl3 enabled):

root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:443"
root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com -ssl3
* About to connect() to proxy 127.0.0.1 port 443 (#0)
*   Trying 127.0.0.1... connected
* Establish HTTP proxy tunnel to uatmail02.cimb.com:443
> CONNECT uatmail02.cimb.com:443 HTTP/1.1
> Host: uatmail02.cimb.com:443
> User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4 libidn/1.23 librtmp/2.3
> Proxy-Connection: Keep-Alive
>
< HTTP/1.1 200 Connection established
<
* Proxy replied OK to CONNECT request
* successfully set certificate verify locations:
*   CAfile: none
  CApath: /etc/ssl/certs
* SSLv3, TLS handshake, Client hello (1):
* SSLv3, TLS handshake, Server hello (2):
* SSLv3, TLS handshake, CERT (11):
* SSLv3, TLS handshake, Server key exchange (12):
* SSLv3, TLS handshake, Server finished (14):
* SSLv3, TLS handshake, Client key exchange (16):
* SSLv3, TLS change cipher, Client hello (1):
* SSLv3, TLS handshake, Finished (20):
* SSLv3, TLS change cipher, Client hello (1):
* SSLv3, TLS handshake, Finished (20):
* SSL connection using ECDHE-RSA-AES256-SHA
* Server certificate:
* subject: C=MY; ST=CIMB Bank Berhad ; L=Kuala Lumpur   ; OU=CIMB Bank Berhad; CN=uatmail02.cimb.com
* start date: 2017-07-03 09:00:37 GMT
* expire date: 2019-07-04 09:00:37 GMT
* common name: uatmail02.cimb.com (matched)
* issuer: C=US; ST=California; L=San Jose; O=Elastica Inc; OU=Development; emailAddress=service-engineering at elastica.co; CN=Elastica
* SSL certificate verify ok.
> GET / HTTP/1.1
> User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4 libidn/1.23 librtmp/2.3
> Host: uatmail02.cimb.com
> Accept: */*
>
< HTTP/1.1 302 Found
< Date: Wed, 26 Jul 2017 10:12:48 GMT
< Location: http://127.0.0.1:7999/gateway_auth/?__eln__=1468917241090744452&elastica_relay=https%3A%2F%2Fuatmail02.cimb.com%2F
< Server: elastica-gateway-service/v1.0
< Connection: close
<
* SSLv3, TLS alert, Client hello (1):
* Closing connection #0
* SSLv3, TLS alert, Client hello (1):

Now send the same request on port 3128, which has ssl3 disabled:

root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:3128"
root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com -ssl3
* About to connect() to proxy 127.0.0.1 port 3128 (#0)
*   Trying 127.0.0.1... connected
* Establish HTTP proxy tunnel to uatmail02.cimb.com:443
> CONNECT uatmail02.cimb.com:443 HTTP/1.1
> Host: uatmail02.cimb.com:443
> User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4 libidn/1.23 librtmp/2.3
> Proxy-Connection: Keep-Alive
>
< HTTP/1.1 200 Connection established
<
* Proxy replied OK to CONNECT request
* successfully set certificate verify locations:
*   CAfile: none
  CApath: /etc/ssl/certs
* SSLv3, TLS handshake, Client hello (1):
* SSLv3, TLS handshake, Server hello (2):
* SSLv3, TLS handshake, CERT (11):
* SSLv3, TLS handshake, Server key exchange (12):
* SSLv3, TLS handshake, Server finished (14):
* SSLv3, TLS handshake, Client key exchange (16):
* SSLv3, TLS change cipher, Client hello (1):
* SSLv3, TLS handshake, Finished (20):
* SSLv3, TLS change cipher, Client hello (1):
* SSLv3, TLS handshake, Finished (20):
* SSL connection using ECDHE-RSA-AES256-SHA
* Server certificate:
* subject: C=MY; ST=CIMB Bank Berhad ; L=Kuala Lumpur   ; OU=CIMB Bank Berhad; CN=uatmail02.cimb.com
* start date: 2017-07-03 09:00:37 GMT
* expire date: 2019-07-04 09:00:37 GMT
* common name: uatmail02.cimb.com (matched)
* issuer: C=US; ST=California; L=San Jose; O=Elastica Inc; OU=Development; emailAddress=service-engineering at elastica.co; CN=Elastica
* SSL certificate verify ok.
> GET / HTTP/1.1
> User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4 libidn/1.23 librtmp/2.3
> Host: uatmail02.cimb.com
> Accept: */*
>
< HTTP/1.1 302 Found
< Date: Wed, 26 Jul 2017 10:12:58 GMT
< Location: http://127.0.0.1:7999/gateway_auth/?__eln__=2303332476459826439&elastica_relay=https%3A%2F%2Fuatmail02.cimb.com%2F
< Server: elastica-gateway-service/v1.0
< Connection: close
<
* SSLv3, TLS alert, Client hello (1):
* Closing connection #0
* SSLv3, TLS alert, Client hello (1):


________________________________
From: Wahaj Ali
Sent: Thursday, July 27, 2017 12:51:57 PM
To: squid-users at lists.squid-cache.org
Subject: SSL options on different http_port resolving into a single config for all ports


With squid 3.5.25, I have two http_port configs, on one of which I want to disable SSLv3 while leaving it enabled on the other. Here is part of that config:

http_port 3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/home/madmin/certs/elastica-ca.pem key=/home/madmin/certs/ca.key cipher=ALL:!DES-CBC-SHA:!EXP-DES-CBC-SHA:!EXP-RC4-MD5:!EXP-RC2-CBC-MD5:@STRENGTH options=NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE tls-dh=prime256v1:/etc/ssl/private/el-dhparams.pem

http_port 443 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/home/madmin/certs/elastica-ca.pem key=/home/madmin/certs/ca.key cipher=ALL:!DES-CBC-SHA:!EXP-DES-CBC-SHA:!EXP-RC4-MD5:!EXP-RC2-CBC-MD5:@STRENGTH options=SINGLE_ECDH_USE tls-dh=prime256v1:/etc/ssl/private/el-dhparams.pem

If I first proxy my traffic to port 443, it seems to apply the port 443 config on all other ports from here on. On the other hand if my first request goes through port 3128, then squid sets whatever SSL version is supported on 3128 for all the other ports as well.

First request going to port 3128
root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:3128<http://127.0.0.1:3128/>" root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com<https://uatmail02.cimb.com/> -ssl3 * About to connect() to proxy 127.0.0.1 port 3128 (#0) * Trying 127.0.0.1... connected * Establish HTTP proxy tunnel to uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > CONNECT uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> HTTP/1.1 > Host: uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Proxy-Connection: Keep-Alive > < HTTP/1.1 200 Connection established < * Proxy replied OK to CONNECT request * successfully set certificate verify locations: * CAfile: none CApath: /etc/ssl/certs * SSLv3, TLS handshake, Client hello (1): * SSLv3, TLS alert, Server hello (2): * error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure * Closing connection #0 * root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:443<http://127.0.0.1:443/>" root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com<https://uatmail02.cimb.com/> -ssl3 * About to connect() to proxy 127.0.0.1 port 443 (#0) * Trying 127.0.0.1... connected * Establish HTTP proxy tunnel to uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > CONNECT uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> HTTP/1.1 > Host: uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Proxy-Connection: Keep-Alive > < HTTP/1.1 200 Connection established < * Proxy replied OK to CONNECT request * successfully set certificate verify locations: * CAfile: none CApath: /etc/ssl/certs * SSLv3, TLS handshake, Client hello (1): * SSLv3, TLS alert, Server hello (2): * error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure * Closing connection #0

First request hitting 443:
root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:443<http://127.0.0.1:443/>" root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com<https://uatmail02.cimb.com/> -ssl3 * About to connect() to proxy 127.0.0.1 port 443 (#0) * Trying 127.0.0.1... connected * Establish HTTP proxy tunnel to uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > CONNECT uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> HTTP/1.1 > Host: uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Proxy-Connection: Keep-Alive > < HTTP/1.1 200 Connection established < * Proxy replied OK to CONNECT request * successfully set certificate verify locations: * CAfile: none CApath: /etc/ssl/certs * SSLv3, TLS handshake, Client hello (1): * SSLv3, TLS handshake, Server hello (2): * SSLv3, TLS handshake, CERT (11): * SSLv3, TLS handshake, Server key exchange (12): * SSLv3, TLS handshake, Server finished (14): * SSLv3, TLS handshake, Client key exchange (16): * SSLv3, TLS change cipher, Client hello (1): * SSLv3, TLS handshake, Finished (20): * SSLv3, TLS change cipher, Client hello (1): * SSLv3, TLS handshake, Finished (20): * SSL connection using ECDHE-RSA-AES256-SHA * Server certificate: * subject: C=MY; ST=CIMB Bank Berhad ; L=Kuala Lumpur ; OU=CIMB Bank Berhad; CN=uatmail02.cimb.com<http://uatmail02.cimb.com/> * start date: 2017-07-03 09:00:37 GMT * expire date: 2019-07-04 09:00:37 GMT * common name: uatmail02.cimb.com<http://uatmail02.cimb.com/> (matched) * issuer: C=US; ST=California; L=San Jose; O=Elastica Inc; OU=Development; emailAddress=service-engineering at elastica.co<mailto:service-engineering at elastica.co>; CN=Elastica * SSL certificate verify ok. > GET / HTTP/1.1 > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Host: uatmail02.cimb.com<http://uatmail02.cimb.com/> > Accept: */* > < HTTP/1.1 302 Found < Date: Wed, 26 Jul 2017 10:12:48 GMT < Location: http://127.0.0.1:7999/gateway_auth/?__eln__=1468917241090744452&elastica_relay=https%3A%2F%2Fuatmail02.cimb.com%2F < Server: elastica-gateway-service/v1.0 < Connection: close < * SSLv3, TLS alert, Client hello (1): * Closing connection #0 * SSLv3, TLS alert, Client hello (1): root at madmin-VirtualBox:/home/madmin# root at madmin-VirtualBox:/home/madmin# root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:3128<http://127.0.0.1:3128/>" root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com<https://uatmail02.cimb.com/> -ssl3 * About to connect() to proxy 127.0.0.1 port 3128 (#0) * Trying 127.0.0.1... connected * Establish HTTP proxy tunnel to uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > CONNECT uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> HTTP/1.1 > Host: uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Proxy-Connection: Keep-Alive > < HTTP/1.1 200 Connection established < * Proxy replied OK to CONNECT request * successfully set certificate verify locations: * CAfile: none CApath: /etc/ssl/certs * SSLv3, TLS handshake, Client hello (1): * SSLv3, TLS handshake, Server hello (2): * SSLv3, TLS handshake, CERT (11): * SSLv3, TLS handshake, Server key exchange (12): * SSLv3, TLS handshake, Server finished (14): * SSLv3, TLS handshake, Client key exchange (16): * SSLv3, TLS change cipher, Client hello (1): * SSLv3, TLS handshake, Finished (20): * SSLv3, TLS change cipher, Client hello (1): * SSLv3, TLS handshake, Finished (20): * SSL connection using ECDHE-RSA-AES256-SHA * Server certificate: * subject: C=MY; ST=CIMB Bank Berhad ; L=Kuala Lumpur ; OU=CIMB Bank Berhad; CN=uatmail02.cimb.com<http://uatmail02.cimb.com/> * start date: 2017-07-03 09:00:37 GMT * expire date: 2019-07-04 09:00:37 GMT * common name: uatmail02.cimb.com<http://uatmail02.cimb.com/> (matched) * issuer: C=US; ST=California; L=San Jose; O=Elastica Inc; OU=Development; emailAddress=service-engineering at elastica.co<mailto:service-engineering at elastica.co>; CN=Elastica * SSL certificate verify ok. > GET / HTTP/1.1 > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Host: uatmail02.cimb.com<http://uatmail02.cimb.com/> > Accept: */* > < HTTP/1.1 302 Found < Date: Wed, 26 Jul 2017 10:12:58 GMT < Location: http://127.0.0.1:7999/gateway_auth/?__eln__=2303332476459826439&elastica_relay=https%3A%2F%2Fuatmail02.cimb.com%2F < Server: elastica-gateway-service/v1.0 < Connection: close < * SSLv3, TLS alert, Client hello (1): * Closing connection #0 * SSLv3, TLS alert, Client hello (1):


In the first case, SSLv3 fails on both ports, while in the second it works for both. My expectation was that I can configure the ports independently to use different SSL versions. Wonder if this is a bug?

Regards,

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170727/ca234222/attachment.htm>

From wehategrey at gmail.com  Thu Jul 27 08:27:07 2017
From: wehategrey at gmail.com (Grey)
Date: Thu, 27 Jul 2017 01:27:07 -0700 (PDT)
Subject: [squid-users] Kerberos access denied and reauthentication
Message-ID: <1501144027034-4683224.post@n4.nabble.com>

Hi,
I'm trying to setup a proxy server using Squid 3.5.23 on Debian 9; I've
successfully setup Kerberos authentication generating the keytab file with
ktutil and manually setting the required SPN on my Windows domain
controller.
The problem I'm encountering is that sometimes (right now I'm the only one
using this proxy and it happens a couple times every day at random times)
while visiting random sites an authentication prompt appears asking for
credentials. Hitting Ok makes the prompt reappear and leads to a loop, while
hitting the cancel button makes the prompt go away and the page display an
error saying "Access denied. Authentication required." (white page with
black font; I'm not 100% sure that's the exact message, I'll come back and
update it as soon as it happens again); refreshing the page lets it load
normally and then everything works ok.

I'm posting the relevant configuration hoping that someone can help me or at
least point me in the right direction. Keep in mind that right now basic
authentication is disabled for testing sake, I'll later enable it when I've
worked out where the problem with Kerberos is.

###

auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -r
auth_param negotiate children 150
auth_param negotiate keep_alive off

acl whitelist dstdomain "/etc/squid/whitelist"
acl blacklist dstdomain "/etc/squid/blacklist"

acl AUTH proxy_auth REQUIRED
http_access deny !AUTH all

http_access deny !Safe_ports all
http_access deny CONNECT !SSL_ports all
http_access allow localhost manager
http_access deny manager all
http_access allow localhost all

acl destsquid dstdomain .squid1 .squid2
http_access allow destsquid all

http_access allow whitelist all
http_access deny blacklist all
acl test_account proxy_auth test_account
http_access allow test_account all
http_access deny all



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Kerberos-access-denied-and-reauthentication-tp4683224.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From dijxie at gmail.com  Thu Jul 27 12:54:02 2017
From: dijxie at gmail.com (Dijxie)
Date: Thu, 27 Jul 2017 14:54:02 +0200
Subject: [squid-users] Kerberos access denied and reauthentication
In-Reply-To: <1501144027034-4683224.post@n4.nabble.com>
References: <1501144027034-4683224.post@n4.nabble.com>
Message-ID: <8da798ed-0038-0bba-9a70-b213bb43bc69@gmail.com>

On 2017-07-27 10:27, Grey wrote:
> Hi,
> I'm trying to setup a proxy server using Squid 3.5.23 on Debian 9; I've
> successfully setup Kerberos authentication generating the keytab file with
> ktutil and manually setting the required SPN on my Windows domain
> controller.
> The problem I'm encountering is that sometimes (right now I'm the only one
> using this proxy and it happens a couple times every day at random times)
> while visiting random sites an authentication prompt appears asking for
> credentials. Hitting Ok makes the prompt reappear and leads to a loop, while
> hitting the cancel button makes the prompt go away and the page display an
> error saying "Access denied. Authentication required." (white page with
> black font; I'm not 100% sure that's the exact message, I'll come back and
> update it as soon as it happens again); refreshing the page lets it load
> normally and then everything works ok.
>
> I'm posting the relevant configuration hoping that someone can help me or at
> least point me in the right direction. Keep in mind that right now basic
> authentication is disabled for testing sake, I'll later enable it when I've
> worked out where the problem with Kerberos is.
>
> ###
>
> auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -r
> auth_param negotiate children 150
> auth_param negotiate keep_alive off
>
> acl whitelist dstdomain "/etc/squid/whitelist"
> acl blacklist dstdomain "/etc/squid/blacklist"
>
> acl AUTH proxy_auth REQUIRED
> http_access deny !AUTH all
>
> http_access deny !Safe_ports all
> http_access deny CONNECT !SSL_ports all
> http_access allow localhost manager
> http_access deny manager all
> http_access allow localhost all
>
> acl destsquid dstdomain .squid1 .squid2
> http_access allow destsquid all
>
> http_access allow whitelist all
> http_access deny blacklist all
> acl test_account proxy_auth test_account
> http_access allow test_account all
> http_access deny all
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Kerberos-access-denied-and-reauthentication-tp4683224.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Hi,

Could You please check and post a portion of cache.log? You may also 
want to temporary modify squid.conf: by adding -d to this line:

auth_param negotiate program /usr/lib/squid/negotiate_kerberos_auth -r -d

That should put negotiate_kerberos_auth in debug mode. Be aware that 
kerberos ticket will be added to log, so before posting in You may want 
to alterate your log.
Also, squidklient output for mgr:kerberosauthenticator may be helpful, 
although I'm not sure is that the right name for this module, so check 
mgr:menu for correct name.

-- 
Greets, Dijx



From max at jjoplc.com  Thu Jul 27 16:15:08 2017
From: max at jjoplc.com (Max Ashton)
Date: Thu, 27 Jul 2017 16:15:08 +0000
Subject: [squid-users] ntml winbindd_privileged permission issue
Message-ID: <HE1PR0501MB2780A304D31AA0BDAE26CBF3D1BE0@HE1PR0501MB2780.eurprd05.prod.outlook.com>

Hi guys,

I have just configured our squid proxy to use ntlm authentication.

I am failing to find correct file permission for the /var/lib/samba/winbindd_privileged folder. Squid failed to authenticate using winbind when the following file permissions are set 750, I get the following error in the log.

NTLM Authentication validating user. Result: {result=BH, notes={message: NT_STATUS_UNSUCCESSFUL NT_STATUS_UNSUCCESSFUL;

If I then change the permissions on winbindd_privileged to 757 everything works fine. However, this is not good practice and if the server restarts then winbind fails to start throwing the error "incorrect permissions set, 757 should be 750". Changing the permissions back allows winbind to start but squid then stops authenticating.

My first though is that the squid user is not in the correct group, so I add the proxy user into the winbindd_priv group using

sudo usermod -a -G winbindd_priv proxy

Check this with members winbindd_priv, indeed proxy is a member.

I then check that winbindd_priv is the assigned group for the folder, first I

Sudo chown root:winbindd_priv /var/lib/samba/winbindd_privileged/

to assigns it.

Then

Sudo ls -l root:winbindd_priv /var/lib/samba

drwxr-x---  2 root winbindd_priv    4096 Jul 27 15:27 winbindd_privileged

It appears my proxy is not running as the "proxy" user ( I compiled squid with  --with-default-user=proxy \)

As a note I have tried adding every user to winbindd_priv, same issue occurs.

Any ideas or suggestions on how I can get ntlm working without the 777 file permission would be great

Kind Regards
Max Ashton
JJO plc IT

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170727/d752c00a/attachment.htm>

From dijxie at gmail.com  Thu Jul 27 17:16:23 2017
From: dijxie at gmail.com (Dijxie)
Date: Thu, 27 Jul 2017 19:16:23 +0200
Subject: [squid-users] ntml winbindd_privileged permission issue
In-Reply-To: <HE1PR0501MB2780A304D31AA0BDAE26CBF3D1BE0@HE1PR0501MB2780.eurprd05.prod.outlook.com>
References: <HE1PR0501MB2780A304D31AA0BDAE26CBF3D1BE0@HE1PR0501MB2780.eurprd05.prod.outlook.com>
Message-ID: <e15f66f3-21ec-3522-34fa-16aac29c4d2d@gmail.com>

On 2017-07-27 18:15, Max Ashton wrote:
> Hi guys,
>
> I have just configured our squid proxy to use ntlm authentication.
>
> I am failing to find correct file permission for the /var/lib/samba/winbindd_privileged folder. Squid failed to authenticate using winbind when the following file permissions are set 750, I get the following error in the log.
>
> NTLM Authentication validating user. Result: {result=BH, notes={message: NT_STATUS_UNSUCCESSFUL NT_STATUS_UNSUCCESSFUL;
>
> If I then change the permissions on winbindd_privileged to 757 everything works fine. However, this is not good practice and if the server restarts then winbind fails to start throwing the error "incorrect permissions set, 757 should be 750". Changing the permissions back allows winbind to start but squid then stops authenticating.
>
> My first though is that the squid user is not in the correct group, so I add the proxy user into the winbindd_priv group using
>
> sudo usermod -a -G winbindd_priv proxy
>
> Check this with members winbindd_priv, indeed proxy is a member.
>
> I then check that winbindd_priv is the assigned group for the folder, first I
>
> Sudo chown root:winbindd_priv /var/lib/samba/winbindd_privileged/
>
> to assigns it.
>
> Then
>
> Sudo ls -l root:winbindd_priv /var/lib/samba
>
> drwxr-x---  2 root winbindd_priv    4096 Jul 27 15:27 winbindd_privileged
>
> It appears my proxy is not running as the "proxy" user ( I compiled squid with  --with-default-user=proxy \)
>
> As a note I have tried adding every user to winbindd_priv, same issue occurs.
>
> Any ideas or suggestions on how I can get ntlm working without the 777 file permission would be great
>
> Kind Regards
> Max Ashton
> JJO plc IT
>
>
>
>
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

So what user are your squid running as?
There is a config directive "cache_effective_user" - 
http://www.squid-cache.org/Doc/config/cache_effective_user/
On centOS, squid is running as 'squid' by default; adding squid to group 
'wbpriv' - default centOS-winbind group - allows to run NTLM/negotiate 
authenticator without issue.

What OS? Is selinux enabled and enforcing policy applied?

-- 
Greets, Dijx

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170727/7312a8c1/attachment.htm>

From leiwen14 at gmail.com  Thu Jul 27 22:32:45 2017
From: leiwen14 at gmail.com (Lei Wen)
Date: Thu, 27 Jul 2017 15:32:45 -0700
Subject: [squid-users] How to tell HTTPS traffic is using cache from
 access.log in 3.5.x when using ssl_bump
In-Reply-To: <6d753d7a-a9c6-3ca2-5fef-8d606418eb47@treenet.co.nz>
References: <CAPu9cN6omb+m8JMsNmJtSRD8z-oPRSRm1cSWo5YHNG0LbU4J4A@mail.gmail.com>
 <688b3f4f-c479-9750-56f5-5e6072c4359b@treenet.co.nz>
 <CAPu9cN7PWEzC436UPK=NiYK0eLX=6Bce8q7YYTy8_J8XJ-_4uw@mail.gmail.com>
 <6d753d7a-a9c6-3ca2-5fef-8d606418eb47@treenet.co.nz>
Message-ID: <CAPu9cN7f478uYBs+dUTW+6v1eW_eSTM_2XftGLF_Tg9a9tLEEw@mail.gmail.com>

Hi Amos,

*Squid does not support relaying decrypted https:// requests over an
> insecure connection. So HTTP cache_peer connections will be refused.*

Do you mean HTTPS cache_peer connections will be refused?


*Also, when TLS cache_peer is used Squid is unable to tell the difference
> between the peer TLS server details an origin. So any server-cert forging
> uses the cache_peer's server cert instead of the origin.*
>
I am using the same cert on every host, so it doesn't matter if it picks
the peer's cert. Besides, I have all sibling relation in this pool, only
parent will start the request for peer, right?



> *In Squid-3.5 (and v4) explicit/forward proxy it is best not to use
> cache_peer for decrypted content. The most working way for now is to let it
> go 'DIRECT' and repeat the intercept at the peer.*

Which directive do you mean by 'DIRECT' as a replacement of cache_peer?


My setup doesn't have many layers like a CARP cluster, it's just a squid
host pool, and they are all siblings with each other, no
parent/frontend/backend concept, each squid host is also a container host,
all containers on different host are doing similar job, so they can share
cache between different hosts. This is our initial idea for this project if
you know there are better hierarchy and can give me some suggest I am
really appreciate.



Thanks,
Lei


On Wed, Jul 26, 2017 at 3:30 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 27/07/17 09:54, Lei Wen wrote:
>
>> Hi Amos,
>>
>> Thanks a lot.
>> It is my splice thing is blocking proxy in the middle,
>>
>
> Sort of, yes.
>
> after using stare instead of peek, seems work though, terminal in this
>> case is not blocking proxy in the middle?
>>
>>
> Not sure what you are asking there. Squid *is* the proxy in the middle, so
> terminate does a TCP close().
>
>
> I made some change on my squid.conf, it work for http/https caching and
>> http/https whitelist.
>> It is working for http sibling cache as well, but has some issue with
>> https/ssl sibling cache.
>> in cache_peer, which port number should I use as forward-proxy port?
>> 3130/3128/3129?
>>
>
> Squid does not support relaying decrypted https:// requests over an
> insecure connection. So HTTP cache_peer connections will be refused.
>
> Also, when TLS cache_peer is used Squid is unable to tell the difference
> between the peer TLS server details an origin. So any server-cert forging
> uses the cache_peer's server cert instead of the origin.
>
> In Squid-3.5 (and v4) explicit/forward proxy it is best not to use
> cache_peer for decrypted content. The most working way for now is to let it
> go 'DIRECT' and repeat the intercept at the peer.
>
>
>
>> I am trying to set up a sibling cache pool, there is no parent or gateway
>> sort of thing in this hierarchy.
>> Each instance can have their own whitelist, but they share the same cache
>> pool.
>> On each instance host, squid is actually doing it's whitelist and caching
>> job for a container group on the same host.
>>
>>
> Are you trying to describe something like a CARP hierarchy?
> <http://wiki.squid-cache.org/ConfigExamples/SmpCarpCluster>
>
> They suffer from the above problem. There is no good solution for that in
> current Squid versions which do SSL-Bump.
>
>
>
>> acl step1 at_step SslBump1
>> acl step2 at_step SslBump2
>> acl step3 at_step SslBump3
>> ssl_bump stare step1 all
>> ssl_bump stare step2 allowed_https_sites
>> #ssl_bump bump step3
>> ssl_bump terminate step2 all
>>
>>
>
> Up to you, but I would do this:
>
>  ssl_bump peek step1
>
>  ssl_bump stare step2 allowed_https_sites
>  ssl_bump terminate step2
>
>  # decrypt with server-cert forging
>  ssl_bump bump step3
>
>
> That peek at step1 allows Squid can splice if things to badly at the step2
> staring. A peek at step1 will not prevent a step3 bump.
>
> And the explicit line with 'bump' ensures that Squid actually does a bump,
> the default behaviour is a little bit too variable depending on what bugs
> are present in the SSL-Bump code.
>
>
> Amos
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170727/56ea2859/attachment.htm>

From squid3 at treenet.co.nz  Fri Jul 28 02:56:36 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 28 Jul 2017 14:56:36 +1200
Subject: [squid-users] ntml winbindd_privileged permission issue
In-Reply-To: <e15f66f3-21ec-3522-34fa-16aac29c4d2d@gmail.com>
References: <HE1PR0501MB2780A304D31AA0BDAE26CBF3D1BE0@HE1PR0501MB2780.eurprd05.prod.outlook.com>
 <e15f66f3-21ec-3522-34fa-16aac29c4d2d@gmail.com>
Message-ID: <cc08d596-42bd-83a2-5e68-730d7443f146@treenet.co.nz>

On 28/07/17 05:16, Dijxie wrote:
> On 2017-07-27 18:15, Max Ashton wrote:
>> Hi guys,
>>
>> I have just configured our squid proxy to use ntlm authentication.
>>
>> I am failing to find correct file permission for the /var/lib/samba/winbindd_privileged folder. Squid failed to authenticate using winbind when the following file permissions are set 750, I get the following error in the log.

Leave the privileges of that folder alone.

The correct setup for Squid is detailed at 
<http://wiki.squid-cache.org/ConfigExamples/Authenticate/Ntlm#winbind_privileged_pipe_permissions>


Amos


From squid3 at treenet.co.nz  Fri Jul 28 03:36:51 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 28 Jul 2017 15:36:51 +1200
Subject: [squid-users] How to tell HTTPS traffic is using cache from
 access.log in 3.5.x when using ssl_bump
In-Reply-To: <CAPu9cN7f478uYBs+dUTW+6v1eW_eSTM_2XftGLF_Tg9a9tLEEw@mail.gmail.com>
References: <CAPu9cN6omb+m8JMsNmJtSRD8z-oPRSRm1cSWo5YHNG0LbU4J4A@mail.gmail.com>
 <688b3f4f-c479-9750-56f5-5e6072c4359b@treenet.co.nz>
 <CAPu9cN7PWEzC436UPK=NiYK0eLX=6Bce8q7YYTy8_J8XJ-_4uw@mail.gmail.com>
 <6d753d7a-a9c6-3ca2-5fef-8d606418eb47@treenet.co.nz>
 <CAPu9cN7f478uYBs+dUTW+6v1eW_eSTM_2XftGLF_Tg9a9tLEEw@mail.gmail.com>
Message-ID: <8b776e55-b5a1-dcbb-e859-a69250069d7d@treenet.co.nz>

On 28/07/17 10:32, Lei Wen wrote:
> Hi Amos,
> 
>     /Squid does not support relaying decrypted https:// requests over an
>     insecure connection. So HTTP cache_peer connections will be refused./
> 
> Do you mean HTTPS cache_peer connections will be refused?

No, I mean un-encrypted cache_peer connections will be refused.

Encrypted peers might be used, BUT the peer cert is used for the 
fake-cert generation. Usually the end user then encounters 'invalid 
cert' problems. One also has to be very careful not to introduce other 
MITM or downgrade vulnerabilities on the connections to those peers.


> 
>     /Also, when TLS cache_peer is used Squid is unable to tell the
>     difference between the peer TLS server details an origin. So any
>     server-cert forging uses the cache_peer's server cert instead of the
>     origin./
> 
> I am using the same cert on every host, so it doesn't matter if it picks 
> the peer's cert. Besides, I have all sibling relation in this pool, only 
> parent will start the request for peer, right?

No, any sibling may pass the request on to any other. If the first proxy 
to handle a request thinks that a peer has the response and that peer in 
fact does not, it may be passed on to a third sibling, etc.


It does not matter if the certs on the proxies are identical or not. The 
SSL-Bump is ideally not sending that particular cert to the clients. It 
is generating a fake cert specific for each HTTPS domain being visited - 
based on that domains real official cert.
To do that Squid expected to receive that origin servers cert on its 
next-hop connection.


> 
>     /In Squid-3.5 (and v4) explicit/forward proxy it is best not to use
>     cache_peer for decrypted content. The most working way for now is to
>     let it go 'DIRECT' and repeat the intercept at the peer./
> 
> Which directive do you mean by 'DIRECT' as a replacement of cache_peer?
> 

"DIRECT" in caching hierarchy, means the proxy handling the request uses 
DNS records to identify the origin server and goes directly to that (not 
through a cache_peer).


> 
> My setup doesn't have many layers like a CARP cluster, it's just a squid 
> host pool, and they are all siblings with each other, no 
> parent/frontend/backend concept, each squid host is also a container 
> host, all containers on different host are doing similar job, so they 
> can share cache between different hosts. This is our initial idea for 
> this project if you know there are better hierarchy and can give me some 
> suggest I am really appreciate.

Okay, understood.

You might be able to get a sort-of workable situation with the following 
parameters. I'd still expect a lot of annoying problems though.


  cache_peer sibling.example.com sibling 3128 3130 \
    ssl sslcafile=/path/to/ca.pem \
    sslflags=NO_DEFAULT_CA ssloptions=NO_SSLv3


The /path/to/ca.pem should contain the public cert of the CA used to 
sign the peers cert. Do this whether it is a self-signed CA or a public 
Trusted CA.

[avoid the DONT_VERIFY_* settings, they are deadly].


Amos


From squid3 at treenet.co.nz  Fri Jul 28 04:24:42 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Fri, 28 Jul 2017 16:24:42 +1200
Subject: [squid-users] SSL options on different http_port resolving into
 a single config for all ports
In-Reply-To: <CY4PR16MB1688F4C0D88C1F350B83576EE1BE0@CY4PR16MB1688.namprd16.prod.outlook.com>
References: <CY4PR16MB1688F38DB046710D7483AE6CE1BE0@CY4PR16MB1688.namprd16.prod.outlook.com>
 <CY4PR16MB1688F4C0D88C1F350B83576EE1BE0@CY4PR16MB1688.namprd16.prod.outlook.com>
Message-ID: <fa982de3-3b2e-7fd5-1488-eb1ec3eab663@treenet.co.nz>

On 27/07/17 19:57, Wahaj Ali wrote:
> Resending the logs as they were not formatted correctly:
> 
> 
> First request going to port 3128
> root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:3128"

AFAIK, the above is in valid value for the https_proxy variable. It is 
missing the URL scheme which tells curl whether HTTP or TLS is used to 
connect to the proxy.



Since you are sending identical plain-text CONNECT requests in the two 
ports the first one to receive the request forms the security context 
used by the TLS server connection.

I believe what you are seeing is a result of the fake server 
certificates being cached. The client requested domain is identical for 
all tests, so the cached cert should be identical. However curl is 
rejecting the certificate generated from SSLv3-enabled server connections.

Try with the dynamic_cert_mem_cache_size=0 option to disable cert caching.


Also, I highly recommend leaving port 443 for encrypted connections 
(https_port directive). Using plain-text over it (http_port directive) 
can be extremely problematic.


Amos


From wehategrey at gmail.com  Fri Jul 28 08:46:11 2017
From: wehategrey at gmail.com (Grey)
Date: Fri, 28 Jul 2017 01:46:11 -0700 (PDT)
Subject: [squid-users] Kerberos access denied and reauthentication
In-Reply-To: <8da798ed-0038-0bba-9a70-b213bb43bc69@gmail.com>
References: <1501144027034-4683224.post@n4.nabble.com>
 <8da798ed-0038-0bba-9a70-b213bb43bc69@gmail.com>
Message-ID: <1501231571078-4683232.post@n4.nabble.com>

Shoul I wait for the error to appear and post the section relevant to the
time when it occurs?



--
View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Kerberos-access-denied-and-reauthentication-tp4683224p4683232.html
Sent from the Squid - Users mailing list archive at Nabble.com.


From dijxie at gmail.com  Fri Jul 28 14:19:15 2017
From: dijxie at gmail.com (Dijxie)
Date: Fri, 28 Jul 2017 16:19:15 +0200
Subject: [squid-users] Kerberos access denied and reauthentication
In-Reply-To: <1501231571078-4683232.post@n4.nabble.com>
References: <1501144027034-4683224.post@n4.nabble.com>
 <8da798ed-0038-0bba-9a70-b213bb43bc69@gmail.com>
 <1501231571078-4683232.post@n4.nabble.com>
Message-ID: <a0b261a5-7506-06ee-39cd-82b07c20d6de@gmail.com>

W dniu 28.07.2017 o 10:46, Grey pisze:
> Shoul I wait for the error to appear and post the section relevant to the
> time when it occurs?
>
>
>
> --
> View this message in context: http://squid-web-proxy-cache.1019090.n4.nabble.com/Kerberos-access-denied-and-reauthentication-tp4683224p4683232.html
> Sent from the Squid - Users mailing list archive at Nabble.com.
> _______________________________________________
> squid-users mailing list
> squid-users at lists.squid-cache.org
> http://lists.squid-cache.org/listinfo/squid-users

Or check older entries, grep cache.log for time you know the problem 
already occured - most important informations should be there even 
without debugging mode. Something like (z)cat /var/log/squid/cache.log | 
grep -iE "error|warning"

-- 
Greets, Dijx

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170728/6eedbdfb/attachment.htm>

From mohsen at pahlevanzadeh.org  Sat Jul 29 21:39:39 2017
From: mohsen at pahlevanzadeh.org (Mohsen Pahlevanzadeh)
Date: Sun, 30 Jul 2017 02:09:39 +0430
Subject: [squid-users] How to conceal my country
Message-ID: <dc40ecad-7a56-4ee1-029c-ab2a8df8aeac@pahlevanzadeh.org>

An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170730/fbb5f50f/attachment.htm>

From jason_haar at trimble.com  Sun Jul 30 10:02:54 2017
From: jason_haar at trimble.com (Jason Haar)
Date: Sun, 30 Jul 2017 22:02:54 +1200
Subject: [squid-users] dumb question: how to get http server IP into logs?
Message-ID: <CAFChrgLAjpRyrYeH5yj1OdZ+jQ6g4nMZm5-bjVtJxEKuVtvbQQ@mail.gmail.com>

Hi there

We're running squid-3.5.23 and use ICAP (if that makes a difference)

We also use logformat to include certain details in the logs - but I can't
see an option for including the actual IP address that squid uses when
attempting to fulfil an URL request. eg squid gets told to go to twitter.com,
resolves that to 4 IPs, tries 1st - fails, tries 2nd - succeeds. I'd like
to record that IP in the logs along with everything else. I can see
variables for recording the client and squid-server IP - but not the web
server?

Is that possible? I'm sure older (3.2) squid used to do that by default?
(DIRECT/1.2.3.4?). All our logs are now "HIER_DIRECT"

Thanks

-- 
Cheers

Jason Haar
Information Security Manager, Trimble Navigation Ltd.
Phone: +1 408 481 8171
PGP Fingerprint: 7A2E 0407 C9A6 CAF6 2B9F 8422 C063 5EBB FE1D 66D1
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170730/66298ecd/attachment.htm>

From eliezer at ngtech.co.il  Sun Jul 30 18:59:08 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Sun, 30 Jul 2017 21:59:08 +0300
Subject: [squid-users] How to conceal my country
In-Reply-To: <dc40ecad-7a56-4ee1-029c-ab2a8df8aeac@pahlevanzadeh.org>
References: <dc40ecad-7a56-4ee1-029c-ab2a8df8aeac@pahlevanzadeh.org>
Message-ID: <096101d30965$ec5f45d0$c51dd170$@ngtech.co.il>

Hey,

You need a VPN solution.
I have seen couple of these around.
I gathered a list of proxy servers which might help you to workaround some of your issues, take a peek at:
http://www1.ngtech.co.il/wpe/?p=239 (A Proxy for each Internet user! The future!)

Eliezer

----
http://ngtech.co.il/lmgtfy/
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Mohsen Pahlevanzadeh
Sent: Sunday, July 30, 2017 00:40
To: squid-users at lists.squid-cache.org
Subject: [squid-users] How to conceal my country

Dear all,

I have hub.docker.com , It blocked some country such as Iran, 
Then I have A server in CA->LA , my client is in Tehran, 

I have a Squid in A server, When I initialize http_proxy variable to my server , It can't handle & docker can know me, How can I configure squid as anonymous.

Best regards
Mohsen



From Wahaj_Ali at symantec.com  Mon Jul 31 07:27:44 2017
From: Wahaj_Ali at symantec.com (Wahaj Ali)
Date: Mon, 31 Jul 2017 07:27:44 +0000
Subject: [squid-users] SSL options on different http_port resolving into
 a single config for all ports
In-Reply-To: <CY4PR16MB1688F4C0D88C1F350B83576EE1BE0@CY4PR16MB1688.namprd16.prod.outlook.com>
References: <CY4PR16MB1688F38DB046710D7483AE6CE1BE0@CY4PR16MB1688.namprd16.prod.outlook.com>,
 <CY4PR16MB1688F4C0D88C1F350B83576EE1BE0@CY4PR16MB1688.namprd16.prod.outlook.com>
Message-ID: <CY4PR16MB168858038D565606B7726BF6E1B20@CY4PR16MB1688.namprd16.prod.outlook.com>

Thanks for the reply, Amos. A few follow up questions:

1) Setting dynamic_cert_mem_cache_size=0 does solve the issue. However, I fail to understand why caching the cert allows the connection to continue on SSLv3, on a port that I've disabled it. Isn't cert exchange done after the protocol has been selected. I don't think curl is rejecting the cert, but rather the ssl connection fails to establish before the cert exchange, since I also tried with the following command, which ignores cert errors:

curl -k -vv -x https://127.0.0.1:3128 https://uatmail02.cimb.com -ssl3


root at madmin-VirtualBox:/home/madmin/# curl -k -vv -x https://127.0.0.1:3128 https://uatmail02.cimb.com -ssl3
* About to connect() to proxy 127.0.0.1 port 3128 (#0)
*   Trying 127.0.0.1... connected
* Establish HTTP proxy tunnel to uatmail02.cimb.com:443
> CONNECT uatmail02.cimb.com:443 HTTP/1.1
> Host: uatmail02.cimb.com:443
> User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4 libidn/1.23 librtmp/2.3
> Proxy-Connection: Keep-Alive
>
< HTTP/1.1 200 Connection established
<
* Proxy replied OK to CONNECT request
* successfully set certificate verify locations:
*   CAfile: none
  CApath: /etc/ssl/certs
* SSLv3, TLS handshake, Client hello (1):
* SSLv3, TLS alert, Server hello (2):
* error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure
* Closing connection #0


2) You mentioned "leaving port 443 for encrypted connections", can you please elaborate on why it might be problematic to use "http_port" directive - i.e. have both plain-text and SSL connections?


Thanks.

________________________________
From: Wahaj Ali
Sent: Thursday, July 27, 2017 12:57:14 PM
To: squid-users at lists.squid-cache.org
Subject: Re: SSL options on different http_port resolving into a single config for all ports


Resending the logs as they were not formatted correctly:


First request going to port 3128
root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:3128"
root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com -ssl3
* About to connect() to proxy 127.0.0.1 port 3128 (#0)
*   Trying 127.0.0.1... connected
* Establish HTTP proxy tunnel to uatmail02.cimb.com:443
> CONNECT uatmail02.cimb.com:443 HTTP/1.1
> Host: uatmail02.cimb.com:443
> User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4 libidn/1.23 librtmp/2.3
> Proxy-Connection: Keep-Alive
>
< HTTP/1.1 200 Connection established
<
* Proxy replied OK to CONNECT request
* successfully set certificate verify locations:
*   CAfile: none
  CApath: /etc/ssl/certs
* SSLv3, TLS handshake, Client hello (1):
* SSLv3, TLS alert, Server hello (2):
* error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure
* Closing connection #0

Now hit port 443:

root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:443"
root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com -ssl3
* About to connect() to proxy 127.0.0.1 port 443 (#0)
*   Trying 127.0.0.1... connected
* Establish HTTP proxy tunnel to uatmail02.cimb.com:443
> CONNECT uatmail02.cimb.com:443 HTTP/1.1
> Host: uatmail02.cimb.com:443
> User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4 libidn/1.23 librtmp/2.3
> Proxy-Connection: Keep-Alive
>
< HTTP/1.1 200 Connection established
<
* Proxy replied OK to CONNECT request
* successfully set certificate verify locations:
*   CAfile: none
  CApath: /etc/ssl/certs
* SSLv3, TLS handshake, Client hello (1):
* SSLv3, TLS alert, Server hello (2):
* error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure
* Closing connection #0

Restart squid, then send first request on port 443 (which has ssl3 enabled):

root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:443"
root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com -ssl3
* About to connect() to proxy 127.0.0.1 port 443 (#0)
*   Trying 127.0.0.1... connected
* Establish HTTP proxy tunnel to uatmail02.cimb.com:443
> CONNECT uatmail02.cimb.com:443 HTTP/1.1
> Host: uatmail02.cimb.com:443
> User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4 libidn/1.23 librtmp/2.3
> Proxy-Connection: Keep-Alive
>
< HTTP/1.1 200 Connection established
<
* Proxy replied OK to CONNECT request
* successfully set certificate verify locations:
*   CAfile: none
  CApath: /etc/ssl/certs
* SSLv3, TLS handshake, Client hello (1):
* SSLv3, TLS handshake, Server hello (2):
* SSLv3, TLS handshake, CERT (11):
* SSLv3, TLS handshake, Server key exchange (12):
* SSLv3, TLS handshake, Server finished (14):
* SSLv3, TLS handshake, Client key exchange (16):
* SSLv3, TLS change cipher, Client hello (1):
* SSLv3, TLS handshake, Finished (20):
* SSLv3, TLS change cipher, Client hello (1):
* SSLv3, TLS handshake, Finished (20):
* SSL connection using ECDHE-RSA-AES256-SHA
* Server certificate:
* subject: C=MY; ST=CIMB Bank Berhad ; L=Kuala Lumpur   ; OU=CIMB Bank Berhad; CN=uatmail02.cimb.com
* start date: 2017-07-03 09:00:37 GMT
* expire date: 2019-07-04 09:00:37 GMT
* common name: uatmail02.cimb.com (matched)
* issuer: C=US; ST=California; L=San Jose; O=Elastica Inc; OU=Development; emailAddress=service-engineering at elastica.co; CN=Elastica
* SSL certificate verify ok.
> GET / HTTP/1.1
> User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4 libidn/1.23 librtmp/2.3
> Host: uatmail02.cimb.com
> Accept: */*
>
< HTTP/1.1 302 Found
< Date: Wed, 26 Jul 2017 10:12:48 GMT
< Location: http://127.0.0.1:7999/gateway_auth/?__eln__=1468917241090744452&elastica_relay=https%3A%2F%2Fuatmail02.cimb.com%2F
< Server: elastica-gateway-service/v1.0
< Connection: close
<
* SSLv3, TLS alert, Client hello (1):
* Closing connection #0
* SSLv3, TLS alert, Client hello (1):

Now send the same request on port 3128, which has ssl3 disabled:

root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:3128"
root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com -ssl3
* About to connect() to proxy 127.0.0.1 port 3128 (#0)
*   Trying 127.0.0.1... connected
* Establish HTTP proxy tunnel to uatmail02.cimb.com:443
> CONNECT uatmail02.cimb.com:443 HTTP/1.1
> Host: uatmail02.cimb.com:443
> User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4 libidn/1.23 librtmp/2.3
> Proxy-Connection: Keep-Alive
>
< HTTP/1.1 200 Connection established
<
* Proxy replied OK to CONNECT request
* successfully set certificate verify locations:
*   CAfile: none
  CApath: /etc/ssl/certs
* SSLv3, TLS handshake, Client hello (1):
* SSLv3, TLS handshake, Server hello (2):
* SSLv3, TLS handshake, CERT (11):
* SSLv3, TLS handshake, Server key exchange (12):
* SSLv3, TLS handshake, Server finished (14):
* SSLv3, TLS handshake, Client key exchange (16):
* SSLv3, TLS change cipher, Client hello (1):
* SSLv3, TLS handshake, Finished (20):
* SSLv3, TLS change cipher, Client hello (1):
* SSLv3, TLS handshake, Finished (20):
* SSL connection using ECDHE-RSA-AES256-SHA
* Server certificate:
* subject: C=MY; ST=CIMB Bank Berhad ; L=Kuala Lumpur   ; OU=CIMB Bank Berhad; CN=uatmail02.cimb.com
* start date: 2017-07-03 09:00:37 GMT
* expire date: 2019-07-04 09:00:37 GMT
* common name: uatmail02.cimb.com (matched)
* issuer: C=US; ST=California; L=San Jose; O=Elastica Inc; OU=Development; emailAddress=service-engineering at elastica.co; CN=Elastica
* SSL certificate verify ok.
> GET / HTTP/1.1
> User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4 libidn/1.23 librtmp/2.3
> Host: uatmail02.cimb.com
> Accept: */*
>
< HTTP/1.1 302 Found
< Date: Wed, 26 Jul 2017 10:12:58 GMT
< Location: http://127.0.0.1:7999/gateway_auth/?__eln__=2303332476459826439&elastica_relay=https%3A%2F%2Fuatmail02.cimb.com%2F
< Server: elastica-gateway-service/v1.0
< Connection: close
<
* SSLv3, TLS alert, Client hello (1):
* Closing connection #0
* SSLv3, TLS alert, Client hello (1):


________________________________
From: Wahaj Ali
Sent: Thursday, July 27, 2017 12:51:57 PM
To: squid-users at lists.squid-cache.org
Subject: SSL options on different http_port resolving into a single config for all ports


With squid 3.5.25, I have two http_port configs, on one of which I want to disable SSLv3 while leaving it enabled on the other. Here is part of that config:

http_port 3128 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/home/madmin/certs/elastica-ca.pem key=/home/madmin/certs/ca.key cipher=ALL:!DES-CBC-SHA:!EXP-DES-CBC-SHA:!EXP-RC4-MD5:!EXP-RC2-CBC-MD5:@STRENGTH options=NO_SSLv2,NO_SSLv3,SINGLE_ECDH_USE tls-dh=prime256v1:/etc/ssl/private/el-dhparams.pem

http_port 443 ssl-bump generate-host-certificates=on dynamic_cert_mem_cache_size=4MB cert=/home/madmin/certs/elastica-ca.pem key=/home/madmin/certs/ca.key cipher=ALL:!DES-CBC-SHA:!EXP-DES-CBC-SHA:!EXP-RC4-MD5:!EXP-RC2-CBC-MD5:@STRENGTH options=SINGLE_ECDH_USE tls-dh=prime256v1:/etc/ssl/private/el-dhparams.pem

If I first proxy my traffic to port 443, it seems to apply the port 443 config on all other ports from here on. On the other hand if my first request goes through port 3128, then squid sets whatever SSL version is supported on 3128 for all the other ports as well.

First request going to port 3128
root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:3128<http://127.0.0.1:3128/>" root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com<https://uatmail02.cimb.com/> -ssl3 * About to connect() to proxy 127.0.0.1 port 3128 (#0) * Trying 127.0.0.1... connected * Establish HTTP proxy tunnel to uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > CONNECT uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> HTTP/1.1 > Host: uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Proxy-Connection: Keep-Alive > < HTTP/1.1 200 Connection established < * Proxy replied OK to CONNECT request * successfully set certificate verify locations: * CAfile: none CApath: /etc/ssl/certs * SSLv3, TLS handshake, Client hello (1): * SSLv3, TLS alert, Server hello (2): * error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure * Closing connection #0 * root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:443<http://127.0.0.1:443/>" root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com<https://uatmail02.cimb.com/> -ssl3 * About to connect() to proxy 127.0.0.1 port 443 (#0) * Trying 127.0.0.1... connected * Establish HTTP proxy tunnel to uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > CONNECT uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> HTTP/1.1 > Host: uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Proxy-Connection: Keep-Alive > < HTTP/1.1 200 Connection established < * Proxy replied OK to CONNECT request * successfully set certificate verify locations: * CAfile: none CApath: /etc/ssl/certs * SSLv3, TLS handshake, Client hello (1): * SSLv3, TLS alert, Server hello (2): * error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure * Closing connection #0

First request hitting 443:
root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:443<http://127.0.0.1:443/>" root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com<https://uatmail02.cimb.com/> -ssl3 * About to connect() to proxy 127.0.0.1 port 443 (#0) * Trying 127.0.0.1... connected * Establish HTTP proxy tunnel to uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > CONNECT uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> HTTP/1.1 > Host: uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Proxy-Connection: Keep-Alive > < HTTP/1.1 200 Connection established < * Proxy replied OK to CONNECT request * successfully set certificate verify locations: * CAfile: none CApath: /etc/ssl/certs * SSLv3, TLS handshake, Client hello (1): * SSLv3, TLS handshake, Server hello (2): * SSLv3, TLS handshake, CERT (11): * SSLv3, TLS handshake, Server key exchange (12): * SSLv3, TLS handshake, Server finished (14): * SSLv3, TLS handshake, Client key exchange (16): * SSLv3, TLS change cipher, Client hello (1): * SSLv3, TLS handshake, Finished (20): * SSLv3, TLS change cipher, Client hello (1): * SSLv3, TLS handshake, Finished (20): * SSL connection using ECDHE-RSA-AES256-SHA * Server certificate: * subject: C=MY; ST=CIMB Bank Berhad ; L=Kuala Lumpur ; OU=CIMB Bank Berhad; CN=uatmail02.cimb.com<http://uatmail02.cimb.com/> * start date: 2017-07-03 09:00:37 GMT * expire date: 2019-07-04 09:00:37 GMT * common name: uatmail02.cimb.com<http://uatmail02.cimb.com/> (matched) * issuer: C=US; ST=California; L=San Jose; O=Elastica Inc; OU=Development; emailAddress=service-engineering at elastica.co<mailto:service-engineering at elastica.co>; CN=Elastica * SSL certificate verify ok. > GET / HTTP/1.1 > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Host: uatmail02.cimb.com<http://uatmail02.cimb.com/> > Accept: */* > < HTTP/1.1 302 Found < Date: Wed, 26 Jul 2017 10:12:48 GMT < Location: http://127.0.0.1:7999/gateway_auth/?__eln__=1468917241090744452&elastica_relay=https%3A%2F%2Fuatmail02.cimb.com%2F < Server: elastica-gateway-service/v1.0 < Connection: close < * SSLv3, TLS alert, Client hello (1): * Closing connection #0 * SSLv3, TLS alert, Client hello (1): root at madmin-VirtualBox:/home/madmin# root at madmin-VirtualBox:/home/madmin# root at madmin-VirtualBox:/home/madmin# export https_proxy="127.0.0.1:3128<http://127.0.0.1:3128/>" root at madmin-VirtualBox:/home/madmin# curl -v https://uatmail02.cimb.com<https://uatmail02.cimb.com/> -ssl3 * About to connect() to proxy 127.0.0.1 port 3128 (#0) * Trying 127.0.0.1... connected * Establish HTTP proxy tunnel to uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > CONNECT uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> HTTP/1.1 > Host: uatmail02.cimb.com:443<http://uatmail02.cimb.com:443/> > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Proxy-Connection: Keep-Alive > < HTTP/1.1 200 Connection established < * Proxy replied OK to CONNECT request * successfully set certificate verify locations: * CAfile: none CApath: /etc/ssl/certs * SSLv3, TLS handshake, Client hello (1): * SSLv3, TLS handshake, Server hello (2): * SSLv3, TLS handshake, CERT (11): * SSLv3, TLS handshake, Server key exchange (12): * SSLv3, TLS handshake, Server finished (14): * SSLv3, TLS handshake, Client key exchange (16): * SSLv3, TLS change cipher, Client hello (1): * SSLv3, TLS handshake, Finished (20): * SSLv3, TLS change cipher, Client hello (1): * SSLv3, TLS handshake, Finished (20): * SSL connection using ECDHE-RSA-AES256-SHA * Server certificate: * subject: C=MY; ST=CIMB Bank Berhad ; L=Kuala Lumpur ; OU=CIMB Bank Berhad; CN=uatmail02.cimb.com<http://uatmail02.cimb.com/> * start date: 2017-07-03 09:00:37 GMT * expire date: 2019-07-04 09:00:37 GMT * common name: uatmail02.cimb.com<http://uatmail02.cimb.com/> (matched) * issuer: C=US; ST=California; L=San Jose; O=Elastica Inc; OU=Development; emailAddress=service-engineering at elastica.co<mailto:service-engineering at elastica.co>; CN=Elastica * SSL certificate verify ok. > GET / HTTP/1.1 > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 OpenSSL/1.0.1 zlib/1.2.3.4<http://1.2.3.4/> libidn/1.23 librtmp/2.3 > Host: uatmail02.cimb.com<http://uatmail02.cimb.com/> > Accept: */* > < HTTP/1.1 302 Found < Date: Wed, 26 Jul 2017 10:12:58 GMT < Location: http://127.0.0.1:7999/gateway_auth/?__eln__=2303332476459826439&elastica_relay=https%3A%2F%2Fuatmail02.cimb.com%2F < Server: elastica-gateway-service/v1.0 < Connection: close < * SSLv3, TLS alert, Client hello (1): * Closing connection #0 * SSLv3, TLS alert, Client hello (1):


In the first case, SSLv3 fails on both ports, while in the second it works for both. My expectation was that I can configure the ports independently to use different SSL versions. Wonder if this is a bug?

Regards,

-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170731/a4c0a67b/attachment.htm>

From squid3 at treenet.co.nz  Mon Jul 31 10:22:24 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Mon, 31 Jul 2017 22:22:24 +1200
Subject: [squid-users] dumb question: how to get http server IP into
	logs?
In-Reply-To: <CAFChrgLAjpRyrYeH5yj1OdZ+jQ6g4nMZm5-bjVtJxEKuVtvbQQ@mail.gmail.com>
References: <CAFChrgLAjpRyrYeH5yj1OdZ+jQ6g4nMZm5-bjVtJxEKuVtvbQQ@mail.gmail.com>
Message-ID: <3e39f0df-f883-1fec-86d3-fa92a43e7b95@treenet.co.nz>

On 30/07/17 22:02, Jason Haar wrote:
> Hi there
> 
> We're running squid-3.5.23 and use ICAP (if that makes a difference)
> 
> We also use logformat to include certain details in the logs - but I 
> can't see an option for including the actual IP address that squid uses 
> when attempting to fulfil an URL request. eg squid gets told to go to 
> twitter.com <http://twitter.com>, resolves that to 4 IPs, tries 1st - 
> fails, tries 2nd - succeeds. I'd like to record that IP in the logs 
> along with everything else. I can see variables for recording the client 
> and squid-server IP - but not the web server?
> 
> Is that possible? I'm sure older (3.2) squid used to do that by default? 
> (DIRECT/1.2.3.4? <http://1.2.3.4?>). All our logs are now "HIER_DIRECT"
> 

The code you are looking for is %<a .
<http://www.squid-cache.org/Doc/config/logformat/>
"Server IP address of the last server or peer connection"

Amos


From eliezer at ngtech.co.il  Mon Jul 31 11:49:31 2017
From: eliezer at ngtech.co.il (Eliezer Croitoru)
Date: Mon, 31 Jul 2017 14:49:31 +0300
Subject: [squid-users] dumb question: how to get http server IP
	into	logs?
In-Reply-To: <3e39f0df-f883-1fec-86d3-fa92a43e7b95@treenet.co.nz>
References: <CAFChrgLAjpRyrYeH5yj1OdZ+jQ6g4nMZm5-bjVtJxEKuVtvbQQ@mail.gmail.com>
 <3e39f0df-f883-1fec-86d3-fa92a43e7b95@treenet.co.nz>
Message-ID: <0b7301d309f3$12a2fa10$37e8ee30$@ngtech.co.il>

I looked at:
http://www.squid-cache.org/Doc/config/logformat/

and the default squid logformat:
logformat squid      %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un %Sh/%<a %mt

Seems to contain the desired pattern.
Am I missing something?

Eliezer

----
Eliezer Croitoru
Linux System Administrator
Mobile: +972-5-28704261
Email: eliezer at ngtech.co.il


-----Original Message-----
From: squid-users [mailto:squid-users-bounces at lists.squid-cache.org] On Behalf Of Amos Jeffries
Sent: Monday, July 31, 2017 13:22
To: squid-users at lists.squid-cache.org
Subject: Re: [squid-users] dumb question: how to get http server IP into logs?

On 30/07/17 22:02, Jason Haar wrote:
> Hi there
> 
> We're running squid-3.5.23 and use ICAP (if that makes a difference)
> 
> We also use logformat to include certain details in the logs - but I 
> can't see an option for including the actual IP address that squid uses 
> when attempting to fulfil an URL request. eg squid gets told to go to 
> twitter.com <http://twitter.com>, resolves that to 4 IPs, tries 1st - 
> fails, tries 2nd - succeeds. I'd like to record that IP in the logs 
> along with everything else. I can see variables for recording the client 
> and squid-server IP - but not the web server?
> 
> Is that possible? I'm sure older (3.2) squid used to do that by default? 
> (DIRECT/1.2.3.4? <http://1.2.3.4?>). All our logs are now "HIER_DIRECT"
> 

The code you are looking for is %<a .
<http://www.squid-cache.org/Doc/config/logformat/>
"Server IP address of the last server or peer connection"

Amos
_______________________________________________
squid-users mailing list
squid-users at lists.squid-cache.org
http://lists.squid-cache.org/listinfo/squid-users



From squid3 at treenet.co.nz  Mon Jul 31 13:08:11 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 1 Aug 2017 01:08:11 +1200
Subject: [squid-users] SSL options on different http_port resolving into
 a single config for all ports
In-Reply-To: <CY4PR16MB168858038D565606B7726BF6E1B20@CY4PR16MB1688.namprd16.prod.outlook.com>
References: <CY4PR16MB1688F38DB046710D7483AE6CE1BE0@CY4PR16MB1688.namprd16.prod.outlook.com>
 <CY4PR16MB1688F4C0D88C1F350B83576EE1BE0@CY4PR16MB1688.namprd16.prod.outlook.com>
 <CY4PR16MB168858038D565606B7726BF6E1B20@CY4PR16MB1688.namprd16.prod.outlook.com>
Message-ID: <9613cbed-bfc2-d093-83a9-450eb29b9a5e@treenet.co.nz>

On 31/07/17 19:27, Wahaj Ali wrote:
> Thanks for the reply, Amos. A few follow up questions:
> 
> 1) Setting dynamic_cert_mem_cache_size=0 does solve the issue. However, 
> I fail to understand why caching the cert allows the connection to 
> continue on SSLv3, on a port that I've disabled it. Isn't cert exchange 
> done after the protocol has been selected. I don't think curl is 
> rejecting the cert, but rather the ssl connection fails to establish 
> before the cert exchange, since I also tried with the following command, 
> which ignores cert errors:
> > curl -k -vv -x https://127.0.0.1:3128 https://uatmail02.cimb.com -ssl3
> 

Are you referring to the -k ?

That option disables security validation procedures for the cert keys - 
like Squid's DONT_VERIFY_PEER option. That is all.

It cannot prevent OpenSSL *parsing* the cert and rejecting it on grounds 
that TLS-only things are being used on an SSLv3 connection, or SSL 
things are being on a TLS-only connection.


> 
> root at madmin-VirtualBox:/home/madmin/# curl -k -vv -x 
> https://127.0.0.1:3128 https://uatmail02.cimb.com -ssl3
> * About to connect() to proxy 127.0.0.1 port 3128 (#0)
> *   Trying 127.0.0.1... connected
> * Establish HTTP proxy tunnel to uatmail02.cimb.com:443
>  > CONNECT uatmail02.cimb.com:443 HTTP/1.1
>  > Host: uatmail02.cimb.com:443
>  > User-Agent: curl/7.22.0 (x86_64-pc-linux-gnu) libcurl/7.22.0 
> OpenSSL/1.0.1 zlib/1.2.3.4 libidn/1.23 librtmp/2.3
>  > Proxy-Connection: Keep-Alive
>  >
> < HTTP/1.1 200 Connection established
> <
> * Proxy replied OK to CONNECT request
> * successfully set certificate verify locations:
> *   CAfile: none
>    CApath: /etc/ssl/certs
> * SSLv3, TLS handshake, Client hello (1):

The protocol version is decided here. By the server - based partially on 
what framing syntax that ClientHello used, and partially on what the 
client indicates it can support.

If the protocol itself could not be agreed to the server would terminate 
and I'd expect curl to either show an alert received now, or complain 
about early closure.


> * SSLv3, TLS alert, Server hello (2):

Here curl is receiving the ServerHello - which contains the cert and the 
servers chosen cyphers etc.


> * error:14094410:SSL routines:SSL3_READ_BYTES:sslv3 alert handshake failure > * Closing connection #0

So, curl is aborting willingly when processing that cert etc.

That "error:" line is produced by OpenSSL, not curl.

It might also abort due to cipher or extension issues, but IIRC the 
messages OpenSSL prints there explicitly contain the words cipher or 
extension respectively.


> 
> 2) You mentioned "leaving port 443 for encrypted connections", can you 
> please elaborate on why it might be problematic to use "http_port" 
> directive - i.e. have both plain-text and SSL connections?
> 

Because of problems like the one you are clearly showing by the way you 
worded that question. As if you think SSL connections are arriving at 
that port.

  ... it *does not* accept SSL connections.

The octet values for TLS and plain-text messages are incompatible. They 
can be interpreted by either one - with various results which are 
different to how they are supposed to be handled, and usually not nice 
results.


The "http_" part of the directive name indicates what protocol the 
parser attached to that port accepts. In this case plain-text HTTP. 
There are a few other protocols that can arrive there but they do so by 
using the plain-text HTTP syntax.


To receive port 443 traffic use the https_port. The "https_" part of 
that directive name means the bytes arriving to that port get shuffled 
through a TLS parser (eg OpenSSL) before going to the HTTP parser.

If you were thinking that ssl-bump option on the port made it accept 
SSL/TLS connections you would be wrong. SSL-Bump on an http_port is 
about applying a TLS parser *after* the HTTP parser - and only for the 
payload of plain-text HTTP CONNECT messages.


Other plain-text protocols which Squid supports that don't use the 
message HTTP-syntax have to use different port directives. For example; 
ftp_port directive for native FTP protocol.

Amos


From squid3 at treenet.co.nz  Mon Jul 31 13:48:05 2017
From: squid3 at treenet.co.nz (Amos Jeffries)
Date: Tue, 1 Aug 2017 01:48:05 +1200
Subject: [squid-users] dumb question: how to get http server IP into
	logs?
In-Reply-To: <0b7301d309f3$12a2fa10$37e8ee30$@ngtech.co.il>
References: <CAFChrgLAjpRyrYeH5yj1OdZ+jQ6g4nMZm5-bjVtJxEKuVtvbQQ@mail.gmail.com>
 <3e39f0df-f883-1fec-86d3-fa92a43e7b95@treenet.co.nz>
 <0b7301d309f3$12a2fa10$37e8ee30$@ngtech.co.il>
Message-ID: <9e1d8113-66eb-e501-725f-f8547dc9cbcc@treenet.co.nz>

On 31/07/17 23:49, Eliezer Croitoru wrote:
> I looked at:
> http://www.squid-cache.org/Doc/config/logformat/
> 
> and the default squid logformat:
> logformat squid      %ts.%03tu %6tr %>a %Ss/%03>Hs %<st %rm %ru %[un %Sh/%<a %mt
> 
> Seems to contain the desired pattern.
> Am I missing something?

Jason's using a custom format. Sounds to me like they did not simply 
copy the example and add bits, but rather made a fully custom one with 
only their desired fields.

Amos


From leiwen14 at gmail.com  Mon Jul 31 23:32:13 2017
From: leiwen14 at gmail.com (Lei Wen)
Date: Mon, 31 Jul 2017 16:32:13 -0700
Subject: [squid-users] How to tell HTTPS traffic is using cache from
 access.log in 3.5.x when using ssl_bump
In-Reply-To: <8b776e55-b5a1-dcbb-e859-a69250069d7d@treenet.co.nz>
References: <CAPu9cN6omb+m8JMsNmJtSRD8z-oPRSRm1cSWo5YHNG0LbU4J4A@mail.gmail.com>
 <688b3f4f-c479-9750-56f5-5e6072c4359b@treenet.co.nz>
 <CAPu9cN7PWEzC436UPK=NiYK0eLX=6Bce8q7YYTy8_J8XJ-_4uw@mail.gmail.com>
 <6d753d7a-a9c6-3ca2-5fef-8d606418eb47@treenet.co.nz>
 <CAPu9cN7f478uYBs+dUTW+6v1eW_eSTM_2XftGLF_Tg9a9tLEEw@mail.gmail.com>
 <8b776e55-b5a1-dcbb-e859-a69250069d7d@treenet.co.nz>
Message-ID: <CAPu9cN60whmvwGOe53hqF8DHs4pjjepvwtEm+ErzdZ0d=+NzbA@mail.gmail.com>

Hi Amos,

I tried your suggestion tried to tuned with some other options, no matter
what I've done, seems HTTPS traffic will not look at sibling cache? it only
look into it's own cache if there are only siblings in the group?


Thanks,
Lei

On Thu, Jul 27, 2017 at 8:36 PM, Amos Jeffries <squid3 at treenet.co.nz> wrote:

> On 28/07/17 10:32, Lei Wen wrote:
>
>> Hi Amos,
>>
>>     /Squid does not support relaying decrypted https:// requests over an
>>     insecure connection. So HTTP cache_peer connections will be refused./
>>
>> Do you mean HTTPS cache_peer connections will be refused?
>>
>
> No, I mean un-encrypted cache_peer connections will be refused.
>
> Encrypted peers might be used, BUT the peer cert is used for the fake-cert
> generation. Usually the end user then encounters 'invalid cert' problems.
> One also has to be very careful not to introduce other MITM or downgrade
> vulnerabilities on the connections to those peers.
>
>
>
>>     /Also, when TLS cache_peer is used Squid is unable to tell the
>>     difference between the peer TLS server details an origin. So any
>>     server-cert forging uses the cache_peer's server cert instead of the
>>     origin./
>>
>> I am using the same cert on every host, so it doesn't matter if it picks
>> the peer's cert. Besides, I have all sibling relation in this pool, only
>> parent will start the request for peer, right?
>>
>
> No, any sibling may pass the request on to any other. If the first proxy
> to handle a request thinks that a peer has the response and that peer in
> fact does not, it may be passed on to a third sibling, etc.
>
>
> It does not matter if the certs on the proxies are identical or not. The
> SSL-Bump is ideally not sending that particular cert to the clients. It is
> generating a fake cert specific for each HTTPS domain being visited - based
> on that domains real official cert.
> To do that Squid expected to receive that origin servers cert on its
> next-hop connection.
>
>
>
>>     /In Squid-3.5 (and v4) explicit/forward proxy it is best not to use
>>     cache_peer for decrypted content. The most working way for now is to
>>     let it go 'DIRECT' and repeat the intercept at the peer./
>>
>> Which directive do you mean by 'DIRECT' as a replacement of cache_peer?
>>
>>
> "DIRECT" in caching hierarchy, means the proxy handling the request uses
> DNS records to identify the origin server and goes directly to that (not
> through a cache_peer).
>
>
>
>> My setup doesn't have many layers like a CARP cluster, it's just a squid
>> host pool, and they are all siblings with each other, no
>> parent/frontend/backend concept, each squid host is also a container host,
>> all containers on different host are doing similar job, so they can share
>> cache between different hosts. This is our initial idea for this project if
>> you know there are better hierarchy and can give me some suggest I am
>> really appreciate.
>>
>
> Okay, understood.
>
> You might be able to get a sort-of workable situation with the following
> parameters. I'd still expect a lot of annoying problems though.
>
>
>  cache_peer sibling.example.com sibling 3128 3130 \
>    ssl sslcafile=/path/to/ca.pem \
>    sslflags=NO_DEFAULT_CA ssloptions=NO_SSLv3
>
>
> The /path/to/ca.pem should contain the public cert of the CA used to sign
> the peers cert. Do this whether it is a self-signed CA or a public Trusted
> CA.
>
> [avoid the DONT_VERIFY_* settings, they are deadly].
>
>
> Amos
>
-------------- next part --------------
An HTML attachment was scrubbed...
URL: <http://lists.squid-cache.org/pipermail/squid-users/attachments/20170731/f2785794/attachment.htm>

